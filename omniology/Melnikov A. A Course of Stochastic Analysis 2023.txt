Canadian
Mathematical Society
Société mathématique
du Canada
CMS/CAIMS Books in Mathematics
Alexander Melnikov
A Course 
of Stochastic 
Analysis

CMS/CAIMS Books in Mathematics
Volume 6
Series Editors
Karl Dilcher
Department of Mathematics and Statistics, Dalhousie University, Halifax,
NS, Canada
Frithjof Lutscher
Department of Mathematics, University of Ottawa, Ottawa, ON, Canada
Nilima Nigam
Department of Mathematics, Simon Fraser University, Burnaby, BC, Canada
Keith Taylor
Department of Mathematics and Statistics, Dalhousie University, Halifax,
NS, Canada
Associate Editors
Ben Adcock
Department of Mathematics, Simon Fraser University, Burnaby, BC, Canada
Martin Barlow
University of British Columbia, Vancouver, BC, Canada
Heinz H. Bauschke
University of British Columbia, Kelowna, BC, Canada
Matt Davison
Department of Statistical and Actuarial Science, Western University, London,
ON, Canada
Leah Keshet
Department of Mathematics, University of British Columbia, Vancouver,
BC, Canada
Niky Kamran
Department of Mathematics and Statistics, McGill University, Montreal,
QC, Canada
Mikhail Kotchetov
Memorial University of Newfoundland, St. John’s, Canada
Raymond J. Spiteri
Department of Computer Science, University of Saskatchewan, Saskatoon,
SK, Canada

CMS/CAIMS Books in Mathematics is a collection of monographs and graduate-
level textbooks published in cooperation jointly with the Canadian Mathematical
Society-Societé mathématique du Canada and the Canadian Applied and Industrial
Mathematics Society-Societé Canadienne de Mathématiques Appliquées et Indus-
trielles. This series offers authors the joint advantage of publishing with two major
mathematical societies and with a leading academic publishing company. The se-
ries is edited by Karl Dilcher, Frithjof Lutscher, Nilima Nigam, and Keith Taylor.
The series publishes high-impact works across the breadth of mathematics and its
applications. Books in this series will appeal to all mathematicians, students and
established researchers. The series replaces the CMS Books in Mathematics series
that successfully published over 45 volumes in 20 years.

Alexander Melnikov
A Course of Stochastic
Analysis
123

Alexander Melnikov
Department of Mathematical
and Statistical Sciences
University of Alberta
Edmonton, AB, Canada
ISSN 2730-650X
ISSN 2730-6518
(electronic)
CMS/CAIMS Books in Mathematics
ISBN 978-3-031-25325-6
ISBN 978-3-031-25326-3
(eBook)
https://doi.org/10.1007/978-3-031-25326-3
Mathematics Subject Classiﬁcation: 60, 62
© The Editor(s) (if applicable) and The Author(s), under exclusive license to Springer Nature
Switzerland AG 2023
This work is subject to copyright. All rights are solely and exclusively licensed by the Publisher, whether
the whole or part of the material is concerned, speciﬁcally the rights of translation, reprinting, reuse of
illustrations, recitation, broadcasting, reproduction on microﬁlms or in any other physical way, and
transmission or information storage and retrieval, electronic adaptation, computer software, or by similar
or dissimilar methodology now known or hereafter developed.
The use of general descriptive names, registered names, trademarks, service marks, etc. in this
publication does not imply, even in the absence of a speciﬁc statement, that such names are exempt from
the relevant protective laws and regulations and therefore free for general use.
The publisher, the authors, and the editors are safe to assume that the advice and information in this
book are believed to be true and accurate at the date of publication. Neither the publisher nor the
authors or the editors give a warranty, expressed or implied, with respect to the material contained
herein or for any errors or omissions that may have been made. The publisher remains neutral with regard
to jurisdictional claims in published maps and institutional afﬁliations.
This Springer imprint is published by the registered company Springer Nature Switzerland AG
The registered company address is: Gewerbestrasse 11, 6330 Cham, Switzerland

Preface
The foundation of the modern probability theory was done by A. N. Kolmogorov in
his monograph appeared as “Grundbegriffe der Wahrscheinlichkeitsrechtung” in
1933. Since that time we use the notion of a probability space (X; F ; P), where X is
an abstract set of elementary outcomes x of a random experiment, F is a family of
events, and P is a probability measure deﬁned on F . In that book, there is a special
remark about the property of independence as a speciﬁc feature of the theory of
probability. Due to this property, one can use deterministic numerical characteris-
tics like mean and variance to describe the behavior of families of random variables.
It was later recognized that dynamics of random events can be exhaustively
determined considering t and x together and a random process as a function
of these two variables on the basis of information ﬂow Ft, t  0.
The fruitful idea was extremely important for a general theory of random pro-
cesses initiated in the middle of the twentieth century. The central notion of this
theory is a stochastic basis (X; F ; ðFtÞ; P), i.e. a probability space equipped with an
information ﬂow or ﬁltration (Ft). In such a setting, deterministic numerical char-
acteristics induced by the independence property are replaced by their conditional
versions with respect to ﬁltration (Ft). So, a predictability has appeared as a driver
of extension of stochastic calculus to the biggest possible class of processes called
semimartingales. These processes admit the full description in predictable terms.
Moreover, they unify processes with discrete and continuous time. As a result, we
arrive to a nice transformation of the theory of probability and stochastic processes
to a wider area which is called stochastic analysis.
The primary goal of the book is to deliver basic notions, facts, and methods of
stochastic analysis using a uniﬁed methodology, sufﬁciently strong and complete,
and giving interesting and valuable implementations in mathematical ﬁnance and
statistics of random processes. There are a lot of examples considered to illustrate
theoretical concepts discussed in line with problems for students aligned with
material. Moreover, the list of supplementary problems with hints and solutions,
covering both important theoretical statements and purely technical problems
intended to motivate a deeper understanding of stochastic analysis is provided at the
end of the book. The book can be considered as a textbook for both senior
v

undergraduate and graduate courses on stochastic analysis/stochastic processes. It
certainly can be helpful for undergraduate and graduate students, instructors as well
as for experts in stochastic analysis and its applications.
The book is based on the lecturers given by the author in different times at
Lomonosov
Moscow
State
University,
State
University-Higher
School
of
Economics, University of Copenhagen, and at the University of Alberta. The author
is grateful to his Ph.D. students Ilia Vasilev, Andrey Pak, and Pounch Mohammadi
Nejad at the Mathematical Finance Program of the University of Alberta for their
kind help preparation of this book.
Edmonton, Canada
Alexander Melnikov
vi
Preface

Contents
1
Probabilistic Foundations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
1
1.1
Classical theory and the Kolmogorov axiomatics . . . . . . . . . . .
1
1.2
Probabilistic distributions and the Kolmogorov consistency
theorem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
6
2
Random variables and their quantitative characteristics . . . . . . . . .
13
2.1
Distributions of random variables . . . . . . . . . . . . . . . . . . . . . .
13
2.2
Expectations of random variables . . . . . . . . . . . . . . . . . . . . . . .
18
3
Expectations and convergence of sequences of random
variables . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
21
3.1
Limit behavior of sequences of random variables
in terms of their expected values . . . . . . . . . . . . . . . . . . . . . . .
21
3.2
Probabilistic inequalities and interconnections between
types of convergence of random variables. . . . . . . . . . . . . . . . .
26
4
Weak convergence of sequences of random variables . . . . . . . . . . .
31
4.1
Weak convergence and its description in terms
of distributions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
31
4.2
Weak convergence and Central Limit Theorem. . . . . . . . . . . . .
34
5
Absolute continuity of probability measures and conditional
expectations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
41
5.1
Absolute continuity of measures and the Radon-Nikodym
theorem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
41
5.2
Conditional expectations and their properties . . . . . . . . . . . . . .
43
6
Discrete time stochastic analysis: basic results . . . . . . . . . . . . . . . .
49
6.1
Basic notions: stochastic basis, predictability
and martingales. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
49
6.2
Martingales on ﬁnite time interval . . . . . . . . . . . . . . . . . . . . . .
55
6.3
Martingales on inﬁnite time interval . . . . . . . . . . . . . . . . . . . . .
59
vii

7
Discrete time stochastic analysis: further results
and applications . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
65
7.1
Limiting behavior of martingales with statistical
applications . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
65
7.2
Martingales and absolute continuity of measures. Discrete
time Girsanov theorem and its ﬁnancial application . . . . . . . . .
74
7.3
Asymptotic martingales and other extensions of martingales . . .
76
8
Elements of classical theory of stochastic processes . . . . . . . . . . . . .
81
8.1
Stochastic processes: deﬁnitions, properties and classical
examples . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
81
8.2
Stochastic integrals with respect to a Wiener process . . . . . . . .
91
8.3
The Ito processes: Formula of changing of variables,
theorem of Girsanov, representation of martingales . . . . . . . . . .
98
9
Stochastic differential equations, diffusion processes
and their applications . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
107
9.1
Stochastic differential equations . . . . . . . . . . . . . . . . . . . . . . . .
107
9.2
Diffusion processes and their connection with SDEs
and PDEs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
117
9.3
Applications to Mathematical Finance and Statistics
of Random Processes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
126
9.4
Controlled diffusion processes and applications to option
pricing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
132
10
General theory of stochastic processes under
“usual conditions” . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
139
10.1
Basic elements of martingale theory . . . . . . . . . . . . . . . . . . . . .
139
10.2
Extension of martingale theory by localization
of stochastic processes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
151
10.3
On stochastic calculus for semimartingales . . . . . . . . . . . . . . . .
159
10.4
The Doob-Meyer decomposition: proof and related remarks . . .
169
11
General theory of stochastic processes in applications . . . . . . . . . .
175
11.1
Stochastic mathematical ﬁnance . . . . . . . . . . . . . . . . . . . . . . . .
175
11.2
Stochastic Regression Analysis . . . . . . . . . . . . . . . . . . . . . . . .
182
12
Supplementary problems. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
189
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
203
Index . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
205
viii
Contents

Acronyms and Notation
ðX; F; PÞ
Probability space
ðFnÞn¼0;1...
Filtration
ðX; F; ðFnÞ; PÞ
Stochastic basis
Rd
d-dimensional Euclidian space
B(Rd)
Borel r-algebra on Rd
(Rd, B(Rd))
Borel space
A þ
Class of increasing integrable processes
A
Class of processes with integrable variation
Aloc
+
Class of increasing locally integrable processes
Aloc
Class of processes with locally integrable variation
V
Class of processes with ﬁnite variation
LP
Space of random variables with ﬁnite p-moment
O
Optional r-algebra
P
Predictable r-algebra
M
Set of uniformly integrable martingales
M2
Set of square integrable martingales
Mloc
Set of local martingales
Mloc
2
Set of locally square integrable martingales
EX
Expected value of random variable X
Var(X )
Variance of X
E(X|A)
Conditional expected value of random variable X with respect to
r-algebra A
Xn !
P X
Convergence in probability
Xn ! X(a.s.)
Convergence almost surely
Xn !
d X
Convergence in distribution
Xn !
Lp
X
Convergence in LP space
Xn !
w X
Weak convergence
ix

LawP(X)
Distribution of X w.r. to P
Law(X, P)
Distribution of X with respect to measure P
~P << P
Absolute continuity of measure ~P with respect to P
~P * P
Equivalence of measures ~P and P
n
k


¼ Ck
n
Number of combinations from n by k
hX; Yi
Joined quadratic characteristic of X and Y
[X, Y]
Joined quadratic bracket X and Y
½½s; r
Stochastic integral with ﬁnite limits s and r
½½s
Graph of s
V+
Class of increasing processes
hX; Xi
Quadratic characteristic (compensator) of X
conv(f1, f2, …)
Linear convolution of vectors f1, f2, …
A [ B
Union of sets A and B
A \ B
Intersection of sets A and B
Ac
Complement of set A
P(A)
Probability of set A
e(X)
Stochastic exponent of X
P(A|A)
Conditional probability of A w.r. to r-algebra A
cov(X, Y)
Covariance of random variables X and Y
a ^ b
Min(a, b)
a _ b
Max(a, b)
a+
Max(a, 0)
a−
Max(−a, 0)
k:kP
Norm in space LP
lX(t,a)
Local time of W at level a during [0, t]
{x : Xt !}
Set of x for which there exists a ﬁnite limit limt! ∞Xt (x)
x
Acronyms and Notation

Chapter 1
Probabilistic Foundations
Abstract In the ﬁrst chapter, Kolmogorov’s axioms of the theory of probability are
presented. The choice of the system of the axioms is explained in context of the
Caratheodory theorem. Diﬀerent probability spaces as well as probability distribu-
tions are introduced too. The famous Kolmogorov consistency theorem is formu-
lated, and as a consequence, a brief construction of the Wiener measure is shown
(see [1], [6], [7], [10], [15], [19], [40], and [45]).
1.1
Classical theory and the Kolmogorov axiomatics
Classical theory of probability deals with a ﬁnite probability space, i.e. it creates a
mathematical model for any random (stochastic) experiment with ﬁnite number of
possible outcomes (elementary events, results) ω ∈Ω, |Ω| = N < ∞, where Ω is the
whole set of outcomes.
Any other events A, B, and C are simply called events. We cannot be certain
of the event A under consideration before a random experiment. Nevertheless, we
expect to have a quantitative measure of such a possibility. In classical probability,
the problem of ﬁnding this measure can be solved perfectly.
Denote ω1, ..., ωN elementary outcomes and deﬁne p1, ..., pN corresponding pos-
sibilities for them. Any other and more complicated event A can be reconstructed
with the help of ω1, ..., ωN. Hence, to determine a measure of possibility for event
A, one can put
P(A) =

i:ωi ∈A
pi.
The situation is diﬀerent if Ω is not ﬁnite. Consider the well-known random exper-
iment called Inﬁnite coin trial with outcomes H(head) and T(tail), and with the
probability of success (H) p, p ∈(0, 1).
It is quite clear that in this case the set Ω can be chosen as follows
Ω = {ω : ω = (a1, a2, ...), ai = 0 or 1}.
© The Author(s), under exclusive license to Springer Nature Switzerland AG 2023
A. Melnikov, A Course of Stochastic Analysis, CMS/CAIMS Books in Mathematics 6,
https://doi.org/10.1007/978-3-031-25326-3_1
1

2
1
Probabilistic Foundations
The natural question arises: How big is this set? Mathematically speaking, we should
ﬁnd the power |Ω| of this set.
It is well-known that any real number a ∈[0, 1) can be represented uniquely in
the form
a = a1
2 + a2
22 + ...,
this representation provides a one-to-one correspondence between [0, 1) and Ω:
a ∈[0, 1) ⇔ω = (a1, a2, ...) ∈Ω.
If we follow to the classical probability theory we should ﬁnd the way to deﬁne the
probability for any elementary event ω. It is equivalent to a random choice of a point
from the semi-interval [0, 1). Taking into account a symmetry of such trials, we must
conclude that all elementary events ω are uniformly possible, hence,
p = p(ω) = const = c.
Further, we have
1 = |[0, 1)| = Probability of Ω =

ω∈Ω
p(ω) = ∞
because the set Ω is not countable. So, we must deﬁne p(ω) = c = 0, however, this
choice is not satisfactory because, for example, for A = [0, 1/2) we have
1/2 = Probability of A = P(A) =

ω∈A
p(ω),
and we arrive to a contradiction again.
Based on these considerations, one can conclude that the approach of classical
theory of probability must be seriously transformed:
The probability should be well-deﬁned instead of elementary outcomes for a
reasonable collection of events of Ω.
The natural candidate for this type of collection is given in the following deﬁnition.
Deﬁnition 1.1 A collection A of subsets of given set Ω is called an algebra if the
following conditions are fulﬁlled
1. Ω ∈A,
2. A, B ∈A ⇒A ∪B ∈A, A ∩B ∈A,
3. A ∈A ⇒Ac = ¯A = Ω \ A ∈A.
Using this deﬁnition we can realize the idea described above as follows.
Deﬁnition 1.2 A function μ : A →[0, ∞] is a ﬁnite-additive measure on A, if for
any disjoint sets A, B ∈A :
μ(A ∪B) = μ(A) + μ(B).

1.1
Classical theory and the Kolmogorov axiomatics
3
In case of μ(Ω) < ∞this measure is called ﬁnite. In particular case μ(Ω) = 1 such
a measure is called a (ﬁnite-additive) probability measure. If there is a partition of
Ω = ∪∞
n=1Ωn, Ωk ∩Ωm = ∅, k  m, Ωn ∈A such that μ(Ωn) < ∞, n = 1, 2, ..., then
μ is σ-ﬁnite.
Based on these deﬁnitions we arrive to the ﬁrst probability model that will be
called a probability space of the ﬁrst level:
(Ω, A, P), where A is an algebra, and P is a probability (ﬁnite-additive measure
with P(Ω) = 1).
Assume that a ﬁnite additive probability P on the probability space of the ﬁrst
level (Ω, A, P) is countably additive (σ-additive). It means that for any sequence of
disjoint events An ∈A with ∪∞
n=1An ∈A the following equality holds:
P(∪∞
n=1An) =
∞

n=1
P(An).
In this case we call this measure a probability (probability measure). Let us count a
list of natural properties of probability:
1. ∅∈A ⇒P(∅) = 0;
2. A, B ∈A ⇒P(A ∪B) = P(A) + P(B) −P(A ∩B);
3. A, B ∈A, A ⊆B ⇒P(A) ≤P(B);
4. An ∈A, n = 1, 2, ..., ∪∞
n=1An ∈A ⇒P(∪∞
n=1An) ≤∞
n=1 P(An).
Problem 1.1 Prove the properties (1)–(4).
The idea of the proof is shown here in case of property (1): For any A ∈A we have
∅∩A ∈A. Further, using the ﬁnite-additivity of P and equality ∅∪Ω = Ω we obtain
1 = P(∅∪Ω = Ω) = P(∅) + P(Ω) = P(∅) + 1,
and, hence, P(∅) = 0.
The following theorem contains conditions under which a ﬁnite-additive proba-
bility measure is countable-additive.
Theorem 1.1 Let P be a ﬁnitely additive set function on the algebra A with P(Ω) =
1. Then the following sentences are equivalent:
1. P is a probability (σ-additive);
2. P is continuous from below:
P(∪∞
n=1An) = lim
n→∞P(An) f or A1 ⊆A2 ⊆..., ∪∞
n=1An ∈A;
3. P is continuous from above:
P(∩∞
n=1An) = lim
n→∞P(An) f or A1 ⊇A2 ⊇..., ∩∞
n=1An ∈A;
4. P is continuous at ∅:

4
1
Probabilistic Foundations
lim
n→∞P(An) = 0 f or A1 ⊇A2 ⊇..., ∩∞
n=1An = ∅.
Proof We only show the implication (1) ⇒(2) because the other statements can be
proved in a similar way.
Let us represent ∪∞
n=1An = A1 ∪(A2 \ A1) ∪(A3 \ A2) ∪... as a union of disjoint
events. Therefore,
P(∪∞
n=1An) = P(A1) + P(A2) −P(A1) + ... = lim
n→∞P(An).
The ﬁrst probability model (Ω, A, P) looks very constructive. But in the frame-
work of this model we cannot operate with events which are combinations of count-
able numbers of these events. To avoid the disadvantages of the probability space of
the ﬁrst level we introduce the following notions.
Deﬁnition 1.3 A system F of subsets of Ω is called a σ-algebra (sigma-algebra)
if F is an algebra and for any sequence An ∈F, n = 1, 2, ..., their unions and
intersections belong to F :
An ∈F ⇒∪∞
n=1An and ∩∞
n=1 An ∈F .
The couple (Ω, F ) is called a measurable space. Let us investigate interconnections
of algebras and σ-algebras. First, we note that
F∗= {∅, Ω} and F ∗= {A, A ⊆Ω} = {all subsets of Ω}
are both algebras and σ−algebras. Second, we can ﬁx a set A ⊆Ω and deﬁne another
algebra (and a σ-algebra also) FA = {A, Ac, ∅, Ω}, which is generated by event A.
This way of construction of algebras and σ−algebras admits a natural generalization.
Lemma 1.1 Let E be a collection of sets in Ω, then there are the smallest algebra
and the smallest σ−algebra containing E.
Idea of the proof. It is clear that E ⊆F ∗. Therefore, there exist at least one algebra
and one σ−algebra with the desirable property. Deﬁne α(E) and σ(E) as a collection
of sets that belong to every algebra (correspondently, σ−algebra) containing E.
Deﬁnition 1.4 A collection of subsets of Ω is called a monotonic class if for any
increasing (decreasing) sequence of events their union (intersection) belong to this
class.
Denote μ(E) a minimal monotonic class containing E. It turns out, an algebra A
is a σ-algebra if and only if it is a monotonic class.
Idea of the proof. The direct implication of this statement is clear because
σ−algebra is a monotonic class. The inverse implication can be proved as fol-
lows. If (An)n=1,2,... is an arbitrary sequence of subsets Ω from a monotonic class
A, we can deﬁne a monotonic class A, and a monotonic sequence (Bn)n=1,2,... with
Bn = ∪n
i=1Ai ∈A, and then Bn ↑∪∞
i=1Ai ∈A. Using this statement we can easily
prove that μ(A) = σ(A) if A is an algebra.

1.1
Classical theory and the Kolmogorov axiomatics
5
Example 1.1 (Borel space). Let us take R = R1 = (−∞, ∞) as Ω, and consider subin-
tervals
(a, b] = {x ∈R : a < x ≤b} for −∞≤a < b < ∞,
Let A be a system of subsets A of the form:
A =
n

i=1
(ai, bi] = ∪n
i=1(ai, bi], n = 1, 2, ...
Including to A the empty set ∅, we can see that A is an algebra. Moreover, we can
easily deﬁne a measure on A : l0(A) = n
i=1(bi −ai). In particular,
l0((a, b]) = b −a = the length of (a, b].
We note also that A is not a σ-algebra because An = (0, 1 −1/n] ∈A, but the union
∪∞
n=1An = (0, 1)  A.
Even in the framework of this example the following problem arises:
Determine a minimal σ-algebra B(R) containing A and a measure on the measur-
able space (R, B(R)) which is called the Borel space.
Problem 1.2 Prove that
1. B(R) is equivalent to a minimal σ−algebra containing all intervals (a, b];
2. B(R) contains (a, b), [a, b], {a}.
Existence of B(R) is obvious, but an extension of l0 from A to B(R) is a real math-
ematical problem, and its solution is the famous Lebesgue measure l on (R, B(R)).
To avoid real technical diﬃculties we would like to get a solution of this problem
from the fundamental theorem of Caratheodory:
Theorem 1.2 If Ω is a space with an algebra A and with a σ-additive measure μ0
on (Ω, A), then there exists a unique measure μ on (Ω, σ(A)) such that
μ(A) = μ0(A) for all A ∈A.
Based on all these preparations and theorems 1.1 and 1.2 one can arrive to the
following natural axioms proposed by Kolmogorov for deﬁnition of the probability
space of the second level (or simply, probability space):
An ordered triple (Ω, F, P) with Ω as a set of elements ω, F as a σ−algebra on
Ω, P as a probability measure (probability) on F .
To go further we give some other examples of measurable spaces playing an
important role in many our further constructions and statements.
Example 1.2 (Rd, B(Rd)) is a multidimensional (d ≥1) Borel space.
Take a set I = d
i=1 Ii, Ii = (ai, bi], i = 1, ..., d, which is called a rectangle with
sides Ii. The smallest σ−algebra containing all such sets is denoted B(Rd).

6
1
Probabilistic Foundations
Instead of rectangels I, one can consider the sets B = d
i=1 Bi, Bi ∈B(R1), i =
1, 2, ..., d. The minimal σ−algebra containing all such sets is
B(Rd) = B(R1) ⊗... ⊗B(R1)

d
.
Problem 1.3 Using an induction method, prove the above equality.
Example 1.3 Denote
R∞= {x = (x1, x2, ...), −∞< xi < +∞},
C(I) = C(I1 × ... × In) = {x : x = (x1, x2, ...), x1 ∈I1, ..., xn ∈In}.
It is clear that the cylinders C satisfy the consistency property
C(I1 × ... × In) = C(I1 × ... × In × R).
In this case, the system of the cylinders is an algebra. The smallest σ−algebra
containing all cylinders is B(R∞), and we arrive to a measurable space (R∞, B(R∞)).
Example 1.4 For T = [0, ∞) we deﬁne RT the space of all real-valued functions
x, and Ct1,...,tn(I1 × ... × In) = {x : xt1 ∈I1, ..., xtn ∈In}. The smallest σ-algebra
containing all such cylinders is B(RT). So, we arrive to the measurable space
(RT, B(RT)). Let us note a structural property of this space: For any A ∈B(RT)
there exist t1 < t2 < . . . and a Borel set B ∈B(R∞) such that
A = {x : (xt1, xt2, . . .) ∈B}.
1.2
Probabilistic distributions and the Kolmogorov
consistency theorem
After these theoretical considerations and the examples given above, we can put the
problem:
How to construct a probability measure on given measurable space?
In the framework of Example 1.1 one can take a Borel set A ∈B(R) in the form
A = (−∞, x], x ∈R1,
and deﬁne the function
F(x) = P((−∞, x]),
where P is a probability measure on the Borel space.
We can note that the function F = F(x) satisﬁes the following obvious properties
1. F is non-decreasing,

1.2
Probabilistic distributions and the Kolmogorov consistency theorem
7
2. F(−∞) = limx→−∞F(x) = 0,
F(+∞) = limx→+∞F(x) = 1,
3. F is a right-continuous function with ﬁnite left-limits.
Such a function, i.e. satisfying (1)-(3), is called a distribution function.
It is now clear that the problem of a construction of the probability can be solved
if we have a distribution function F. In this case we can deﬁne a ﬁnite additive set
function P0 on algebra A :
P0(A) =
n

i=1
(F(bi) −F(ai)),
A =
n

i=1
(ai, bi] ∈A.
We can prove that P0 is σ−additive, and according to the Caratheodory theorem P0
admits a unique extension P to the whole space (R1, B(R1)).
In particular, we can consider the measurable space ([0, 1], B([0, 1])) and the
distribution function
F(x) =
⎧⎪⎪⎪⎨
⎪⎪⎪⎩
0,
x < 0,
x,
x ∈[0, 1],
1,
x > 1.
Then the set function l((a, b]) = F(b) −F(a) = b −a is the length of the interval
(a, b] presents the Lebesgue measure on this space.
Further, starting at the distribution function F = F(x) which is a piecewise con-
stant with change in values at points x1, x2, . . ., ΔF(xi) > 0, we deﬁne
pi = P({xi}) = ΔF(xi) > 0,
∞

i=1
P({xi}) = 1.
This is a measure concentrated at x1, x2, . . ., and usually the sequence (p1, p2, . . . )
is called a discrete distribution. Sometimes, the table
 p1 . . . pn . . .
x1 . . . xn . . .

is also called a discrete distribution. The corresponding distribution function F is
also called discrete. Below we have the most well-known discrete distributions:
1. Uniform discrete distribution:

x1 . . . xN
1/N . . . 1/N

;
2. Bernoulli distribution:
 x1 x2
p1 p2

, p1 + p2 = 1;
3. Binomial distribution with parameter p:

0 . . . i . . . n
n
i
pi(1 −p)n−i

, p ∈(0, 1);

8
1
Probabilistic Foundations
4. Poisson distribution with parameter λ:
 0 . . . i . . . n . . .
λi
i! e−λ

, λ > 0.
If the distribution function F admits the integral representation
F(x) =
∫x
−∞
f (y)dy,
where a non-negative function (density) f (y) satisﬁes the integral condition
∫∞
−∞f (y)dy = 1, then the distribution and its distribution function are absolute con-
tinuous.
Let us count the most important absolute continuous distributions as examples:
1. Uniform distribution on [a, b] :
f (y) =
1
b −a, y ∈[a, b];
2. Normal distribution with parameters μ and σ2 (N ∼(μ, σ2)) :
f (y) = (2πσ2)−1/2exp

−(y −μ)2
2σ2

, μ ∈R1, σ > 0, y ∈R1;
3. Gamma distribution:
f (y) = yα−1e−y/β
Γ(α)βα , y ≥0, α > 0, β > 0;
In particular, for β = 1/λ, and α = 1, we get an exponential distribution with
parameter
λ ≥0 : f (y) = λe−λy, y ≥0;
for α = n/2, and β = 2, we get the Chi-squared distribution with
f (y) = 2−n/2yn/2−1e−y/2/Γ(n/2), y ≥0, n = 1, 2, . . . ;
4. Student distribution (t-distribution):
f (y) = Γ((n + 1)/2)
(nπ)1/2Γ(n/2)(1 + y2/n)−(n+1)/2, y ∈R1, n = 1, 2, . . . ;
5. Cauchy distribution with parameter θ :
f (y) =
θ
π(y2 + θ2), y ∈R1, θ > 0.
Besides discrete and absolute continuous distribution functions (measures, dis-
tributions) there are distribution functions which are continuous, but the set of their
points of increasing has the Lebesgue measure zero. These types of distributions
(measures) are called singular.

1.2
Probabilistic distributions and the Kolmogorov consistency theorem
9
Let us explain it here with the help of the famous Cantor function. We deﬁne the
functions
F1(x) =
⎧⎪⎪⎪⎨
⎪⎪⎪⎩
linear function,
between (0, 0) and (1/3, 1/2),
1/2,
x ∈[1/3, 2/3],
linear function,
between (2/3, 1/2) and (1, 1), x ∈[2/3, 1],
F2(x) =
⎧⎪⎪⎪⎪⎪⎪⎪⎪⎨
⎪⎪⎪⎪⎪⎪⎪⎪⎩
linear function,
between (0, 0) and (1/9, 1/4), x ∈[0, 1/9],
1/4,
x ∈[1/9, 2/9],
linear function,
between (2/9, 1/4) and (1/3, 1/2), x ∈(2/9, 1/3),
1/2,
x ∈[1/3, 2/3],
On (2/3, 1)
is similar to the interval (0, 1/3),
and so on. The sequence (Fn) converges to a non-decreasing continuous function
FC(x), called the Cantor function. We can calculate the length of intervals on which
FC(x) is constant and ﬁnd
1
3 + 2
9 + 4
27 + . . . = 1
3
∞

n=0
2
3
n
= 1.
So, the Lebesgue measure l(N) = 0, where N is the set of points of increasing of
FC.
Denote μ the measure, generated by the Cantor function FC and ﬁnd that μ(N) = 1
because μ(N) = FC(1) = 1. It means that μ and l are singular, and this fact is denoted
as l⊥μ.
It is possible to give a general description of arbitrary distribution functions F :
F(x) = α1F1(x) + α2F2(x) + α3F3(x),
where αi ≥0, i = 1, 2, and 3, 3
i=1 αi = 1, F1 is discrete, F2 is absolutely continu-
ous, and F3 is singular.
Let us pay our attention to a d-dimensional Borel space (Rd, B(Rd)). If P is
a probability measure on this space, we can deﬁne the d-dimensional distribution
function:
Fd(x1, . . ., xd) = P((−∞, x1] × . . . × (−∞, xd]) = P((−∞, x]).
Problem 1.4 Prove that
1. Fd(+∞, . . ., +∞) = 1;
2. Fd(x1, . . ., xd) →0 if at least one of x1, . . ., xd converges to −∞;
3. Deﬁne operator (for i = 1, . . ., d, ai < bi)
Δai,bi Fd(x1, . . ., xd) = Fd(x1, . . ., bi, . . ., xd) −Fd(x1, . . ., ai, . . ., xd),
then

10
1
Probabilistic Foundations
Δa1,b1 . . . Δad,bd Fd(x1, . . ., xd) = P((a, b]),
where (a, b] = (a1, b1] × . . . × (ad, bd].
In fact, there is a one-to-one correspondence between d-dimensional distribution
functions and probabilities on the space (Rd, B(Rd)).
Let us give some examples of multidimensional distribution functions:
1. If F1, . . ., Fd are the distribution functions on R1, then Fd(x1 . . . xd) =
d
i=1 Fi(xi) deﬁnes a d-dimensional distribution function.
2. If
Fi(xi) =
⎧⎪⎪⎪⎨
⎪⎪⎪⎩
0,
xi < 0,
xi,
0 ≤xi ≤1,
1,
xi > 1,
then Fd(x1, . . ., xd) = x1 . . . xd corresponds to the d-dimensional Lebesgue mea-
sure.
3. A d-dimensional absolute continuous distribution function Fd(x1 . . . xd) is
deﬁned by the same manner as in the real line case:
Fd(x1, . . ., xd) =
∫x1
−∞
. . .
∫xd
−∞
fd(y1 . . . yd)dy1 . . . dyd,
where fd isthedensityfunction,i.e. fd ≥0and
∫∞
−∞. . .
∫∞
−∞fd(y1 . . . yd)dy1 . . . dyd =
1.
The most important case is the multidimensional Normal distribution function. It
is deﬁned by the density
fd(x1 . . . xd) = (det A)1/2
(2π)d/2 exp
⎧⎪⎨
⎪⎩
−1
2

1≤i,j ≤d
aij(xi −μi)(xj −μj)
⎫⎪⎬
⎪⎭
,
where A = (aij) is the inverse matrix of a symmetric positive deﬁnite matrix B.
In particular, in case d = 2, we have
f2(x1, x2) =
1
2πσ1σ2(1 −ρ2)1/2 exp

−
1
2(1 −ρ2)

(x1 −μ1)2
σ2
1
−2ρ (x1 −μ1)(x2 −μ2)
σ1σ2
+ (x2 −μ2)2
σ2
2

where σ1, σ2 > 0, μ1, μ2 ∈R1, |ρ| < 1.
Now we need to consider the case of space (R∞, B(R∞)). Let us take a set
B ∈B(Rn) and consider a cylinder
Cn(B) = {x ∈R∞: (x1, . . ., xn) ∈B}.
If P is a probability measure on (R∞, B(R∞)), we can deﬁne Pn(B) =
P(Cn(B)), n = 1, 2, . . . a sequence of probability measures on space (Rn, B(Rn)).
By construction we have
Pn+1(B × R1) = Pn(B),

1.2
Probabilistic distributions and the Kolmogorov consistency theorem
11
which is called the consistency condition. Now we can formulate the famous theorem
of Kolmogorov which is fundamental for foundations of probability theory.
Theorem 1.3 (Consistency theorem of Kolmogorov). Let (Pn)n=1,2,... be a system
of probability measures on (Rn, B(Rn)) correspondingly, n = 1, 2, . . ., satisfying
the consistency property. Then there exists a unique probability measure P on
(R∞, B(R∞)) such that
P(Cn(B)) = Pn(B).
We can give an example how to construct this sequence (Pn). To do this we start
with the sequence of 1-dimensional distribution functions (Fn(x))n=1,2,..., x ∈R1.
Further, we construct another sequence of distribution functions as follows
F1(x1) = F1(x1), x1 ∈R1;
F2(x1, x2) = F1(x1) · F2(x2), x1, x2 ∈R1; etc.
Denote P1, P2, . . . probability measures on (R1, B(R1)), (R2, B(R2)), . . ., which
correspond to the distribution functions F1, F2, . . ..
We can also consider the space (R[0,∞), B(R[0,∞))) for which one can state a
version of consistency theorem in the same way as before. Using this theorem one
can construct an extremely important measure, called the Wiener measure.
Denote (φt(y|x))t ≥0 a family of Normal (Gaussian) densities of y for a ﬁxed x :
φt(y|x) =
1
(2πt)1/2 exp

−(y −x)2
2t

, y ∈R1.
For each t1 < t2 < . . . < tn and B = n
i=1 Ii, Ii = (ai, bi], ai < bi, we deﬁne the
measure
P(t1,t2,...,tn)(B) =
∫
I1
. . .
∫
In
φt1(x1|0)φt2−t1(x2|x1) . . . φtn−tn−1(xn|xn−1)dx1 . . . dxn.
Furthermore, the measure P on cylinder sets can be deﬁned as follows:
P(Ct1...tn(I1 × . . . × In)) = P(t1...tn)(I1 × . . . × In)),
The family of measures (P(t1...tn))n=1,2,... is consistent. Hence, according to The-
orem 1.3 the measure P can be extended from cylinder sets to the whole space
(R[0,∞), B(R[0,∞)).

Chapter 2
Random variables and their quantitative
characteristics
Abstract In the second chapter random variables are introduced and investigated
in the framework of axiomatic of Kolmogorov. It is shown a connection of proba-
bility distributions and distributions of random variables as well as their distribution
functions. The notion of the Lebesgue integral is given in context of deﬁnition of
moments of random variables (see [1], [7], [10], [15], [19], [21], [40], and [45]).
2.1
Distributions of random variables
P. L. Chebyshev was the ﬁrst who introduced the notion of random variables as
functions of elementary outcomes in the theory of probability. Here we develop this
topic in the framework of probability spaces of the second level.
Deﬁnition 2.1 Let (Ω, F, P) be a probability space and (R1, B(R1)) be a Borel space.
Consider a mapping
X : (Ω, F ) →(R1, B(R1)).
For a given set B ∈B(R1) the set X−1(B) = {ω : X(ω) ∈B} is called the inverse
image of B.
The mapping X is called a random variable (measurable function) if for any
B ∈B(R1) :
X−1(B) ∈F .
(2.1)
Let us note that it is useful to allow to X can take values ±∞. In this case we call a
random variable as an extended random variable.
The notion of random variables is very productive as illustrated in the following
example.
Example 2.1 Let us ﬁx a set A ∈F and deﬁne the indicator of A as follows:
© The Author(s), under exclusive license to Springer Nature Switzerland AG 2023
A. Melnikov, A Course of Stochastic Analysis, CMS/CAIMS Books in Mathematics 6,
https://doi.org/10.1007/978-3-031-25326-3_2
13

14
2
Random variables and their quantitative characteristics
IA(ω) =

1,
ω ∈A,
0,
ω ∈Ac.
Deﬁnitely, IA is a mapping from the space (Ω, F ) to (R1, B(R1)). Then for any Borel
set B we have

{ω : IA(ω) ∈B} = A ∈F if B contains 1 only,
{ω : IA(ω) ∈B} = Ac ∈F if B contains 0 only,
otherwise, we have ∅or Ω. Hence, the condition (2.1) is fulﬁlled for IA, and this
mapping is a random variable taking two values 0 and 1. Therefore, the set of all
random events is included to the set of random variables.
Problem 2.1 Assume A1, . . ., An are disjoint events from F such that ∪n
i=1Ai =
n
i=1 Ai = Ω. Deﬁne a mapping X with values x1, . . ., xn on the sets A1, . . ., An,
correspondingly. Prove that X = n
i=1 xiIAi is a random variable. Let us call X a
simple random variable.
Further, if X takes countable numbers of values x1, . . ., xn, . . . on disjoint sets
A1, . . ., An, . . . with ∞
1 xiIAi, then X = ∞
1 xiIAi is called a discrete random vari-
able.
Condition (2.1) can be relaxed with the help of the next useful lemma.
Lemma 2.1 Assume E is a system of subsets such that σ(E) = B(R1). Then mapping
X is a random variable if and only if
X−1(E) ∈F for all E ∈E.
Proof The direct implication is trivial. To prove the inverse implication we deﬁne a
system Y of those Borel sets B for which X−1 ∈F . Further, we have equalities
X−1(∪αBα) = ∪α(X−1(Bα)),
X−1(∩αBα) = ∩α(X−1(Bα)),
(X−1(Bα))c = X−1(Bc
α).
It follows from here that Y is a σ-algebra and E ⊆B(R1). Hence, B(R1) = σ(E) ⊆
σ(Y) = Y and Lemma is proved.
□
Based on Lemma 2.1 and the previous description of the Borel space we arrive
to the corollary.
Corollary 2.1 The function X is a random variable ⇔X−1((−∞, x]) ∈F for all
x ∈R1. This statement is true if we replace (−∞, x] to (−∞, x).
Now we arrive to deﬁnition of the most important quantitative characteristic of
random variable X.

2.1
Distributions of random variables
15
Deﬁnition 2.2 Probability measure PX on a Borel space (R1, B(R1)) deﬁned as
PX(B) = P(X−1(B)), B ∈B(R1),
(2.2)
is called a distribution (probability distribution) of X.
Applying equality (2.2) to the set B = (−∞, x], x ∈R1, we arrive to the distribu-
tion function (cumulative distribution function) of X:
FX(x) = P{ω : X(ω) ≤x}.
(2.3)
In the previous sections we already studied arbitrary distributions on (R1, B(R1)). A
very similar illustration can be found in the context of random variables.
Example 2.2 1. For discrete random variable X :
PX(B) =

i:xi ∈B
p(xi), p(xi) = P(ω : X(ω) = xi) = ΔFX(xi), B ∈B(R1);
2. For continuous random variable X its distribution function FX(x) is continuous;
3. For absolute continuous random variable X its distribution function FX(x) has
an integral representation with the density fX(x):
FX(x) =
∫x
−∞
fX(y)dy.
Usually, any measurable function
ϕ : (R1, B(R1)) →(R1, B(R1)),
is called Borelian. Using Borelian functions and a random variable, one can construct
many other random variables. This is the essence of the next important lemma.
Lemma 2.2 Let ϕ be a Borelian function and X be a random variable on a proba-
bility space (Ω, F, P), then the mapping
Y = ϕ ◦X = ϕ(X),
is a random variable.
Proof For an arbitrary B ∈B(R1) we have
{ω : Y(ω) ∈B} = {ω : ϕ(X(ω)) ∈B} =
{ω : X(ω) ∈ϕ−1(B)} ∈F .
□
It means that Y is a random variable. In particular, the functions x+, x−, |x| etc. are
random variables.
Let us note that there is a necessity to study multidimensional random variables
or random vectors.

16
2
Random variables and their quantitative characteristics
The corresponding deﬁnition is straightforward. This is a measurable mapping
X : (Ω, F ) →(Rd, B(Rd)), d ≥1.
In this case we have
X(ω) = (X1(ω), . . ., Xd(ω)),
where Xi, i = 1, . . ., d, are one-dimensional random variables. We can deﬁne a dis-
tribution function of X as follows
FX(x1, . . ., xd) = P(ω : X1(ω) ≤x1, . . ., Xd(ω) ≤xd).
Deﬁnition 2.3 We say that X1, . . ., Xd are independent if
FX(x1, . . ., xd) =
d

i=1
FXi(xi).
The following theorem is very important in providing many probabilistic construc-
tions.
Theorem 2.1 For any random variable (extended random variable) X there exists
a sequence of simple random variables X1, X2, . . ., |Xi| ≤|X| such that Xn(ω) →
X(ω) for all ω ∈Ω. For a non-negative X such a sequence (Xn)n=1,2,... can be
constructed as a non-decreasing sequence.
Proof Assume X ≥0 and deﬁne for n = 1, 2, . . . simple random variables as follows
Xn(ω) =
n·2n

i=1
i −1
2n Ii,n(ω) + nI{X(ω)≥n}(ω),
(2.4)
where Ii,n = I{ω: i−1
2n ≤X(ω)< i
2n }.
The general case follows from here if we represent X = X+ −X−.
□
Problem 2.2 Prove that for (extended) random variables X1, X2, . . . the mappings
supn Xn, infn Xn, lim infn Xn, lim supn Xn are (extended) random variables.
As a hint to the corresponding solution we note that for supn Xn we have
{ω : sup
n
Xn > x} = ∪n{ω : Xn > x} ∈F, x ∈R1.
Theorem 2.2 Let (Xn)n=1,2,... be a sequence of (extended) random variables. Then
X(ω) = limn→∞Xn(ω) is an (extended) random variable.
Proof Follows from Problem 2.2 and the next equalities: for any x ∈R1

2.1
Distributions of random variables
17
{ω : X(ω) < x} ={ω : lim
n→∞Xn(ω) < x}
={ω : lim sup
n
Xn(ω) = lim inf
n
Xn(ω)} ∩{ω : lim sup
n
Xn(ω) < x}
=Ω ∩{ω : lim sup
n
Xn(ω) < x}
={ω : lim sup
n
Xn(ω) < x} ∈F .
Combining previous facts about limiting approximation of given (extended) random
variables X andY with the help of sequences of simple random variables (Xn)n=1,2,...
and (Yn)n=1,2,... correspondingly, we can prove the following convergence properties:
1. limn→∞(Xn(ω) ± Yn(ω)) = X(ω) ± Y(ω), ω ∈Ω;
2. limn→∞(Xn(ω) · Yn(ω)) = X(ω) · Y(ω), ω ∈Ω;
3. limn→∞(Xn(ω) · ˜Y−1
n (ω)) = X(ω) · Y−1(ω), ω ∈Ω,
where
˜Yn(ω) = Yn(ω) +
1
n I{ω:Yn(ω)=0}.
Now, we focus on the question of how one random variable can be represented by
another.
Deﬁnition 2.4 For a given random variable X the family of events
((ω : X(ω) ∈B))B∈B(R1),
is called a σ-algebra FX generated by X.
Problem 2.3 Prove that FX is a σ−algebra.
Theorem 2.3 Assume a random variableY is measurable with respect to σ-algebra
FX. Then there exists a Borelian function ϕ such that
Y = ϕ ◦X.
Proof Consider the set of FX-measurable functions Y = Y(ω). Denote ˜DX the set
of FX-measurable functions of the form ϕ ◦X. It is clear that ˜DX ⊆DX. To prove
the inverse inclusion, DX ⊆˜DX, consider a set A ∈FX and Y(ω) = IA(ω).
Note that A = X−1(B) for some B ∈B(R1), and Y = IA(ω) = IB(X(ω)) ∈˜DX.
Further, we consider functions Y of the form n
i=1 ciIAi, where ci ∈R1, Ai ∈FX,
and ﬁnd that Y ∈˜DX.
For an arbitrary FX-measurable functionY we construct a sequence of simple FX-
measurable functions Yn such that Y = limn Yn. We already know that Yn = ϕn(X)
for some Borelian functions ϕn and ϕn(X) →Y(ω) as n →∞. Now, we take the set
B = {x : limn→∞ϕn(x) exists} ∈B(R1) and deﬁne a Borelian function
ϕ(x) =

limn ϕn(x),
x ∈B,
0,
x  B.

18
2
Random variables and their quantitative characteristics
ThenY(ω) = limn→∞ϕn(X(ω)) = ϕ(X(ω)) for all ω ∈Ω and we obtain ˜DX ⊆DX.
□
2.2
Expectations of random variables
In this section we provide a construction of another important and convenient quan-
titative characteristic of a random variable X on a probability space (Ω, F, P).
We start such a construction from the simplest case when
X(ω) =
n

i=1
xi · IAi(ω),
n

i=1
Ai = Ω, xi ∈R1.
(2.5)
Deﬁnition 2.5 For the simple random variable X with representation (2.5) we deﬁne
its expected value (expectation) EX as follows
EX =
n

i=1
xiP(Ai).
Problem 2.4 a) For simple random variables X1, . . ., Xm and real numbers
a1, . . ., am we have E m
i=1 aiXi = m
i=1 aiEXi (linearity of expected values).
b) For two simple random variables X ≤Y we have EX ≤EY (monotonicity of
expected values).
Let X be a non-negative random variable. According to Theorem 2.1 one can
construct a sequence of simple random variables X(ω)
n
→X(ω), n →∞, for all
ω ∈Ω. Further, due to Problem 2.4, the sequence of expected values (EXn)n=1,2,...
is non-decreasing, and therefore limn→∞EXn does exist (ﬁnite number or +∞). It
gives a possibility to give the following deﬁnition.
Deﬁnition 2.6 The expected value (expectation) of a non-negative random variable
X is deﬁned as
EX = lim
n→∞EXn.
Problem 2.5 1) If there exists another sequence of simple random variables
˜Xn(ω) ↑X(ω), n ↑∞, ω ∈Ω; then limn→∞E ˜Xn = EX.
2) If 0 ≤X(ω) ≤Y(ω) for all ω ∈Ω, then EX ≤EY.
There is a standard way of expected value extensions to random variables tak-
ing both positive and negative values. We can represent X as diﬀerence of its
positive and negative parts: X = X+ −X−, where as usual X+ = max(0, X) and
X−= max(−X, 0). In this case, we say that EX does exist if EX+ or EX−< ∞and
EX = EX+ −EX−.
One can say that EX is ﬁnite if both EX± < ∞, and E|X| = E(X+ + X−) = EX+ +
EX−< ∞. In this case we also call X integrable.

2.2
Expectations of random variables
19
There is another denotation for expected values:
EX =
∫
Ω
XdP.
This denotation came from functional analysis, where the notion of expected value of
a measurable function X is called the Lebesgue integral. As a matter of fact we note
that the Lebesgue integral generalizes the Riemann integral at least in two directions:
1. It is constructed on the measurable space without any metric structure.
2. It is well deﬁned for any measurable bounded function X. But construction of the
Riemann integral and its existence depends on the power of the set of discontinuity
DX of X, and the set DX should have the Lebesgue measure zero.
A standard example of function “integrable by Lebesgue and non-integrable by
Riemann” is the Dirichlet function on [0, 1] :
X(ω) =

1
i f ω ∈Q,
0
i f ω ∈R \ Q,
where Q is the set of rational numbers.
Let us formulate several natural properties of expected values as a problem
because their proofs are straightforward.
Problem 2.6 1) Ec · X = cEX if EX does exist and c ∈R.
2) EX ≤EY if X(ω) ≤Y(ω), ω ∈Ω, EX > −∞or EY < ∞.
3) |EX| ≤E|X| if EX does exist.
4) If EX exists, then EX · IA exists for each A ∈F . Moreover, if EX is ﬁnite, then
EXIA is ﬁnite too.
5) If X and Y are non-negative or integrable, then E(X + Y) = EX + EY.
Toformulateotherimportantpropertiesofexpectationsweneedthenextdeﬁnition.
Deﬁnition 2.7 We say that a property holds almost surely (a.s.) if there exists a set
N ∈F such that
a) the property holds for every element ω ∈Ω \ N,
b) P(N) = 0.
6) If X = 0 (a.s.), then EX = 0.
7) If X = Y (a.s.) and E|X| < ∞, then E|Y| < ∞and EX = EY.
8) If X ≥0 and EX = 0, then X = 0 (a.s.).
9) If X and Y are integrable and EX · IA ≤EY · IA for all A ∈F, then X ≤Y (a.s.).
Let us give a solution of subproblem 8 in the above list of Problem 2.6:
Denote A = {ω : X(ω) > 0} and An = {ω : X(ω) ≥1
n } ↑A as n →∞.
We note that 0 ≤XIAn ≤XIA, and hence EXIAn ≤EX = 0. Next, we have 0 =
EXIAn ≥1
n P(An). Hence, P(An) = 0, n = 1, 2, . . ., and P(A) = limn→∞P(An) = 0.
Another useful property is the formula of change of variables in the Lebesgue
integral. Let X be a random variables and φ be a Borelian function which is integrable

20
2
Random variables and their quantitative characteristics
with respect to the distribution PX of X. Then for any B ∈B(R) the formula of change
of variables is true:
∫
B
φ(x)dPX =
∫
X−1(B)
φ(X(ω))dP.
(2.6)
In particular, the formula (2.6) for B = R1 is reduced to the formula for calculation
of expectation of X :
Eφ(x) =
∫
Ω
φ(X)dP =
∫∞
−∞
φ(x)dPX =
∫∞
−∞
φ(x)dFX,
(2.7)
where FX is a distribution function of X and the integral
∫∞
−∞φ(x)dFX is the
Lebesgue-Stiltjes integral.
Scheme of the proof of the formula (2.6) is below
Take φ(x) = IC(x), C ∈B(R1), and (2.6) is reduced to PX(B ∩C) = P(X−1(B) ∩
X−1(C)) which follows from the deﬁnition of PX and the equality:
X−1(B) ∩X−1(C) = X−1(B ∩C).
Next steps are obvious: a non-negative simple function φ etc.
If φ(x) = xk, k = 1, 2, . . ., the expectation EXk is called the k-th moment of X
with the help of its distribution and its distribution function. Suppose EX = μ and
φ(x) = (x −μ)k, then corresponding moments are called centered moments. The
second centered moment is called the variance of X :
Var(X) = E(X −μ)2,
and it is one of the key measures of the dispersion of values of X around the mean
value μ.
The other common measures of this type are
skewness = E(X −μ)3
(Var(x))3/2
and
kurtosis = E(X −μ)4
(Var(X))2 .
Problem 2.7 Let X be a normal random variable with parameters μ and σ2. Find
EX,Var(X), skewness and kurtosis of X.

Chapter 3
Expectations and convergence of
sequences of random variables
Abstract In the third chapter asymptotic properties of sequences of random vari-
ables are studied. Lemma of Fatou and the Lebesgue dominated convergence theorem
are presented as permanent technical tools of stochastic analysis. It is also emphasized
the role of a uniform integrability condition of families of random variables. Classi-
cal probabilistic inequalities of Chebyshev, Jensen and Cauchy-Schwartz are proved.
It is shown how these inequalities work to investigate interconnections between dif-
ferent types of convergence of sequences of random variables. In particular, the large
numbers law (LNL) is derived for the case of independent identically distributed
random variables (see [1], [7], [10], [15], [19], [40], and [45]).
3.1
Limit behavior of sequences of random variables in
terms of their expected values
One of the main questions here is how to take the limit under the sign of expectation.
The ﬁrst result exploits a monotonicity assumption. That is why the corresponding
claim is called Monotonicity convergence theorem.
Theorem 3.1 Let (Xn)n=1,2,... be a sequence of random variables then we have
1. if there are random variables X andY such that Xn ≥Y, EY > −∞, Xn ↑X, n ↑
∞, then EXn ↑EX, n ↑∞;
2. if therearerandomvariables X andY suchthat Xn ≤Y, EY < ∞, Xn ↓X, n ↑∞,
then EXn ↓EX, n ↑∞.
Proof Let us only prove the ﬁrst part of the theorem because the second part can
be derived in the same way. Consider only case Y ≥0, and approximate Xi for
each i = 1, 2, . . . by a sequence (Xn
i )n=1,2,... of simple random variables. Deﬁne
Xn = max1≤i≤n Xn
i and note that
Xn−1 ≤Xn = max
1≤i≤n Xn
i ≤max
1≤i≤n Xi = Xn.
© The Author(s), under exclusive license to Springer Nature Switzerland AG 2023
A. Melnikov, A Course of Stochastic Analysis, CMS/CAIMS Books in Mathematics 6,
https://doi.org/10.1007/978-3-031-25326-3_3
21

22
3
Expectations and convergence of sequences of random variables
Denote Z = limn→∞Xn and ﬁnd that X = Z because Xi ≤Z ≤X for all i = 1, 2, . . . .
This inequality follows from Xn
i ≤Xn ≤Xn, i = 1, . . ., n, by taking the limit as
n →∞. The random variables (Xn)n=1,2,... are simple, then
EX = EZ = lim
n→∞EXn ≤lim
n→∞EXn.
On the other hand, since Xn ≤Xn+1 ≤X we have that
EX ≥lim
n→∞EXn
and, hence,
EX = lim
n→∞EXn.
Problem 3.1 Give the proof in general case when Xn ≥Y and EY > −∞.
The next theorem is the most exploited result about taking the limit under the
expectation sign. It is called the Fatou Lemma.
Theorem 3.2
1. Assume Xn ≥Y and EY > −∞, then
E lim inf
n→∞Xn ≤lim inf
n→∞EXn.
2. Assume Xn ≤Y and EY < ∞, then
lim sup
n→∞
EXn ≤E lim sup
n→∞
Xn.
3. Assume |Xn| ≤Y and EY < ∞, then
E lim inf
n→∞Xn ≤lim inf
n→∞EXn ≤lim sup
n→∞
EXn ≤E lim sup
n→∞
Xn.
Proof In case (1) we deﬁne a sequence of random variables Zn = infm≥n Xm and
ﬁnd that Zn ↑lim infn→∞Xn = sup infm≥n Xn and Zn ≥Y. Further we have that
lim inf
n→∞Xn = lim inf
m≥n Xm = lim
n→∞Zn,
and applying Theorem 3.1 we get the ﬁrst claim of the Theorem.
The case (2) is derived in a similar way. The case (3) is just a combination of (1)
and (2).
□
Let us give the following deﬁnition of convergence of almost surely (a.s).
Deﬁnition 3.1 We say that sequence (Xn)n=1,2,... converges to a random variable X
almost surely (a.s.), if
P(ω : Xn(ω) −−−−→
n→∞X(ω)) = 1.

3.1
Limit behavior of sequences of random variables in terms of their expected values
23
We introduce the following denotations in this case: Xn
a.s.
−−−−→
n→∞X or Xn −−−−→
n→∞
X (a.s.).
The following natural question arises here:
Under what conditions one can provide convergence of expected values if Xn →
X(a.s.)?
The classical result is the dominated convergence theorem of Lebesgue.
Theorem 3.3 Assume that Xn −−−−→
n→∞X (a.s.) and |Xn| ≤Y, EY < ∞. Then E|X| <
∞, and EXn →EX, n →∞. Moreover, the sequence (Xn)n=1,2,... converges to X in
space L1, i.e., E|Xn −X| →0, n →∞.
Proof Using the Fatou Lemma we obtain E lim infn→∞Xn = lim infn→∞EXn =
lim supn→∞EXn = E lim supn→∞Xn = EX. It is clear that |X| ≤Y, and therefore
E|X| < ∞. Taking into account inequality |Xn −X| ≤2Y and applying the Fatou
Lemma again, we obtain the last statement of the theorem.
□
Nowweintroducetheweakestconditiontoprovidetheconvergenceofexpectedvalues.
Deﬁnition 3.2 A sequence of random variables (Xn)n=1,2,... is uniformly integrable,
if
sup
n
E|Xn|I{ω:|Xn |>c} →0, c →∞.
(3.1)
Problem 3.2 If a sequence of |Xn| ≤Y, n = 1, 2, . . ., EY < ∞, then (Xn)n=1,2,... is
uniformly integrable.
Theorem 3.4 If a sequence (Xn)n=1,2,... is uniformly integrable, then
1. E lim infn→∞Xn ≤lim infn→∞EXn ≤lim supn→∞EXn ≤E lim supn→∞Xn.
2. if also Xn →X (a.s.), n →∞, then E|X| < ∞and EXn →EX and E|Xn −
X| →0, n →∞.
Proof To prove (1) we take c > 0 and ﬁnd that
EXn = EXnI{Xn<−c} + EXnI{Xn ≥−c}.
(3.2)
Using (3.1) for ϵ > 0 we obtain
sup
n
|EXnI{Xn<−c}| < ϵ.
Let us apply the Fatou Lemma to the second term of (3.2) and get
lim inf
n
EXnI{Xn ≥−c} ≥E lim inf XnI{Xn ≥−c}.
(3.3)
Taking into account that
XnI{Xn ≥−c} ≥Xn,
we obtain from (3.3) the following inequality

24
3
Expectations and convergence of sequences of random variables
lim inf
n
EXn ≥E lim inf
n
Xn −ϵ.
The proof of part (2) is similar to the proof of Theorem 3.3.
□
Theorem 3.5 Assume the sequence of integrable non-negative random variables
(Xn)n=1,2,... converges to a random variable X. Then EXn →EX < ∞, n →∞, if
and only if (Xn)n=1,2,... is uniformly integrable.
Proof The inverse implication follows from Theorem 3.4. To prove the direct impli-
cation we consider the set A = {a ∈R1 : P(ω : X(ω) = a) > 0} and ﬁnd that
XnI{Xn<a} →XI{X<a}, n →∞,
for each a ∈A and (XnI{Xn<a})n=1,2,... is uniformly integrable.
By Theorem 3.4 we obtain
EXnI{Xn<a} →EXI{X<a},
for a ∈A and hence,
EXnI{Xn ≥a} →EXI{X ≥a},
for a  A.
For each ϵ > 0 we take a0  A large enough that
EXI{X ≥a0 } < ϵ/2.
Choose N0 so large to provide inequalities (for all n ≥N0):
EXnI{Xn ≥a0 } ≤EXI{X ≥a0 } + ϵ/2,
and EXnI{Xn ≥a0 } ≤ϵ. Now we choose a1 ≥a0 large enough to have the following
inequality (for all n ≤N0):
EXnI{Xn ≥a1 } ≤ϵ.
Finally, we obtain
sup
n
EXnI{Xn ≥a1 } ≤ϵ,
which means the condition (3.1).
Let us note the following necessary condition of (3.1).
Problem 3.3 If the sequence (Xn)n=1,2,... is uniformly integrable, then
sup
n
E|Xn| < ∞.
The following problem provides a convenient suﬃcient condition for (3.1).
Problem 3.4 Let (Xn)n=1,2,... be a sequence of integrable random variables and
G = G(u), u ≥0, be a non-negative increasing function such that

3.1
Limit behavior of sequences of random variables in terms of their expected values
25
lim
u→∞
G(u)
u
= ∞, sup
n
EG(|Xn|) < ∞.
Then (Xn)n=1,2,... is uniformly integrable.
Hint. Let ϵ > 0 and G = supn EG(Xn). For large enough c and t ≥c, G(t)/t ≥
G/ϵ. Then E|Xn|I{|Xn |≥c} ≤ϵ
G EG(|Xn|)I{|Xn |≥c} ≤ϵ.
To conclude our discussion of the notion of uniform integrability, we present
another necessary and suﬃcient condition in the following theorem.
Theorem 3.6 A sequence of random variables (Xn)n=1,2,... is uniformly integrable
if and only if (3.3) is true and
sup
n
E|Xn|IA →0 as P(A) →0.
(3.4)
Proof The direct implication follows from the next considerations. For c > 0 we
have
E|Xn|IA =E|Xn|IA∩{|Xn |≥c} + E|Xn|IA∩{|Xn |<c}
≤E|Xn|I{|Xn |≥c} + cP(A).
Taking c large enough, we obtain for a ﬁxed ϵ > 0 :
sup
n
E|Xn|IA∩{|Xn |≥c} ≤ϵ/2.
(3.5)
From (3.5) with P(A) ≤ϵ/(2c) we get
sup
n
E|Xn|IA ≤ϵ,
which means (3.4). To prove the inverse implication we take P(A) < δ so that
E|Xn|IA ≤ϵ uniformly over n = 1, 2, . . . . Let us note that
E|Xn| ≥E|Xn|IA∩{|Xn |≥c} ≥cP(|Xn| ≥c).
Then
sup
n
P(|Xn| ≥c) ≤1
c sup
n
E|Xn| →0, c →∞.
So, we can take as A = {|Xn| ≥c} for large enough c and get
sup
n
E|Xn|I{|Xn |≥c} ≤ϵ,
which is equivalent to (3.1).
□

26
3
Expectations and convergence of sequences of random variables
3.2
Probabilistic inequalities and interconnections between
types of convergence of random variables
We start with some important and well-known probabilistic inequalities.
Chebyshev inequality: For a non-negative random variable X
P(ω : X(ω) ≥ϵ) ≤EX
ϵ , ϵ > 0.
In particular, for arbitrary random variable X with ﬁnite EX and Var(X) :
P(ω : X(ω) ≥ϵ) ≤EX2
ϵ2
and
P(ω : |X(ω) −EX| ≥ϵ) ≤Var(X)
ϵ2
.
For the proof we just note that
EX ≥EXI{X ≥ϵ } ≥ϵEI{X ≥ϵ } = ϵP(ω : X ≥ϵ).
Cauchy-Schwartz inequality: Let X and Y be random variables which are inte-
grable in square: EX2 < ∞, EY2 < ∞, i.e. X,Y ∈L2. Then E|XY| < ∞and
E|XY| ≤(EX2EY2)1/2.
Proof Without loss of generality we assume that EX2 > 0 and EY2 > 0. Consider
transformed random variables
˜X = X/(EX2)1/2, ˜Y = Y/(EY2)1/2.
Note that
2| ˜X ˜Y| ≤˜X2 + ˜Y2,
and obtain
2E| ˜X ˜Y| ≤E ˜X2 + E ˜Y2 = 2,
or E| ˜X ˜Y| ≤1.
□
Jensen inequality: Let a Borelian function g = g(x) be convex downward and
Eg(|X|) < ∞. Then
g(EX) ≤Eg(X).
Proof Let us consider only the case of smooth function g ∈C2 with g′(x) ≥0 for
all x ∈R1. Using the Taylor decomposition at μ = EX, we have
g(x) = g(μ) + g′(μ)(x −μ) + g′′(θ)(x −μ)2
2
,
(3.6)
where θ is between x and μ.

3.2
Probabilistic inequalities and interconnections . . .
27
Putting x = X and taking expectation in (3.6) we get the desirable inequality. □
In context of the Cauchy-Schwartz inequality we want to emphasize one important
case when the inequality is transformed to equality.
Theorem 3.7 Let X and Y be integrable independent random variables, i.e.
FXY(x, y) = FX(x) · FY(y). Then E|XY| < ∞and
EXY = EXEY.
(3.7)
Proof We start with non-negative X and Y, constructing sequences (Xn)n=1,2,... and
(Yn)n=1,2,... of discrete random variables such that
Xn =
∞

m=0
m
n I{ m
n ≤X(ω)< m+1
n
}, n = 1, 2, . . .
(Yn is similar)
Xn ≤X, Yn ≤Y, |Xn −X| ≤1
n, |Yn −Y| ≤1
n.
Since X and Y are integrable we get that EXn →EX, EYn →EY, n →∞, by the
Lebesgue dominated convergence theorem. Due to the independence assumption we
have
EXnYn =

m,l
ml
n2 EI{ m
n ≤X(ω)< m+1
n
}I{ l
n ≤Y(ω)< l+1
n }
=

m,l
ml
n2 EI{ m
n ≤X(ω)< m+1
n
}EI{ l
n ≤Y(ω)< l+1
n }
=EXnEYn.
Let us note that for n = 1, 2, . . .
|EXY −EXnYn| ≤E|XY −XnYn|
≤E|X||Y −Yn| + E|Yn||X −Xn|
≤EX
n + E(Y + 1/n)
n
→0 as n →∞.
Therefore,
EXY = lim
n EXnYn = lim
n EXn lim
n EYn = EXEY < ∞.
General case (3.7) can be treated in a similar way if we note equalities: X = X+ −
X−, Y = Y+ −Y−, XY = X+Y+ −X−Y+ −X+Y−+ X−Y−.
□

28
3
Expectations and convergence of sequences of random variables
The brilliant Chebyshev inequality has a lot of applications, and one of the most
important corollaries is the Large Numbers Law (LNL).
Theorem 3.8 Let (Yn)n=1,2,... be a sequence of identically distributed independent
random variables with mean μ and variance σ2, and Sn = n
i=1 Yi. Then for any
ϵ > 0
P

ω :

Sn
n −μ
 ≥ϵ

→0, n →∞.
(3.8)
The proof of (3.8) follows from the Chebyshev inequality and Theorem 3.6.
Denoting ˜Yi = Yi −μ, i = 1, 2, . . ., we calculate
E
 Sn
n −μ
2
= 1
n2 E
 n

i=1
˜Yi
2
= 1
n2
	
E
n

i=1
˜Y2
i +

ij
E ˜Yi ˜Yj

= 1
n2
	
nσ2 +

ij
E ˜Yi ˜Yj

= σ2
n .
and obtain that
P

ω :

Sn
n −μ
 ≥ϵ

≤
E

Sn
n −μ
2
ϵ2
= σ2
nϵ2 →0, n →∞.
Let us give the following deﬁnition.
Deﬁnition 3.3 A sequence of random variables (Xn)n=1,2,... converges to a random
variable X in probability, if for any ϵ > 0
P(ω : |Xn −X| ≥ϵ) →0, n →∞.
(3.9)
We denote it as follows Xn
P−→
n X or Xn
P−→X, n →∞.
Using this deﬁnition one can reformulate Theorem 3.8 as convergence in proba-
bility of normed sums Xn = Sn/n to the constant μ as n →∞.
We also introduce two types of convergence of random variables (Xn)n=1,2,... to a
random variable X involving expected values.
Deﬁnition 3.4 We say that (Xn) converges to X weakly (weak convergence), if for
any bounded continuous function f :
E f (Xn) →E f (X), n →∞.
(3.10)
Deﬁnition 3.5 Assume Xn, n = 1, 2, . . . and X belongs to the space Lp with ﬁnite
p-moment, i.e. E|Xn|p < ∞, E|X|p < ∞. We say that Xn converges to X in space

3.2
Probabilistic inequalities and interconnections . . .
29
Lp, if E|Xn −X|p →0, n →∞. This convergence is denoted as Xn
Lp
−−→
n
or Xn
Lp
−−→,
n →∞.
Now we are ready to discuss how the convergence (a.s.) (or convergence with
probability 1), deﬁned before and these convergences are related to each other.
It is not diﬃcult to construct a sequence (Xn)n=1,2,... of random variables which
converges to X for all ω ∈Ω, and hence, almost surely.
For example, if X is a random variable and (an)n=1,2,... is a sequence of positive
numbers converges to zero, then a sequence Xn(ω) = (1 −an)X(ω) converges to X
for all ω ∈Ω.
Further, convergence with probability one provides both convergence in proba-
bility and the weak convergence.
If Xn →X (a.s.), n →∞, then |Xn −X| →0 (a.s.), n →∞, and for ϵ > 0
I{ω:|Xn−X |≥ϵ } →0 (a.s.) as well. Taking expectation we obtain P(ω : |Xn −X| ≥
ϵ) = EI{ω:|Xn−X |≥ϵ } →0, n →∞.
The weak convergence follows due to deﬁnition and the Lebesgue dominated
convergence theorem.
Convergence in space Lp is failed when the moment of p-th order does not exist.
Convergence in probability implies the weak convergence.
To prove it assume that Xn
P−→
n X, f is a bounded continuous function, | f (x)| ≤
c, x ∈R1, ϵ > 0. We can choose a big enough N such that P(|X| > N) ≤ϵ/(4c).
Take δ > 0 so that | f (x) −f (y)| ≤ϵ/(2c) for |x| ≤N and |x −y| < δ. Then
|E f (Xn) −E f (X)| ≤E| f (Xn) −f (X)|I{ω:|Xn−X |>δ} + E| f (Xn) −f (X)|I{ω:|Xn−X |≤δ}.
(3.11)
The ﬁrst term in the right hand side of (3.10) is dominated by 2cP(ω : |Xn −X| >
δ) →0, n →∞.
E| f (Xn) −f (X)|I{ω:|Xn−X |≤δ} =E| f (Xn) −f (X)|I{ω:|Xn−X |≤δ}I{ω:|X |≤N }
+ E| f (Xn) −f (X)|I{ω:|Xn−X |≤δ}I{ω:|X |>N }
≤ϵ + 2cP(ω : |Xn −X| > δ) < 2ϵ
for a large enough n.

Chapter 4
Weak convergence of sequences of
random variables
Abstract The chapter four is devoted in a systematic study of a weak convergence
of sequences of random variables. It is shown the equivalence between a weak con-
vergence and convergence in distribution. It is shown that a weak compactness and
tightness for families of probability distributions (Prokhorov’s theorem) are equiva-
lent. It is discussed a connection between characteristic functions and distributions
of random variables. The method of characteristic functions is applied to prove
the Central Limit Theorem (CLT) for sums of independent identically distributed
random variables (see [6], [15], [21], and [40]).
4.1
Weak convergence and its description in terms of
distributions
In the previous section we recognized that weak convergence corresponds to the word
“weak” because all other types of convergence provide the weak one. It turns out
this type of convergence plays the most signiﬁcant role in the theory of probability.
This is why we study it here in more details.
We start with the following considerations. Let (Xn)n=1,2,... be a sequence of
independent Bernoulli’s random variables taking values 1 and 0 with probabilities p
and q, p + q = 1, correspondingly. In this case, the law of large numbers (Theorem
3.7) is reduced to the following
¯Sn = Sn
n
P−→p, n →∞.
(4.1)
Let us deﬁne distribution functions
Fn(x) = P(ω : ¯Sn ≤x) and F(x) =

1, x ≥p,
0, x < p,
x ∈R1.
© The Author(s), under exclusive license to Springer Nature Switzerland AG 2023
A. Melnikov, A Course of Stochastic Analysis, CMS/CAIMS Books in Mathematics 6,
https://doi.org/10.1007/978-3-031-25326-3_4
31

32
4
Weak convergence of sequences of random variables
We know also from the previous section that
E f ( ¯Sn) →E f (p), n →∞,
(4.2)
for any bounded continuous function f .
Further, denote PFn and PF the distributions on (R1, B(R1)) which correspond to
Fn and F, respectively. Using formula of change of variables in expectations (2.7),
we can rewrite (4.2) in two equivalent forms:
∫
R1 f (x)dPFn →
∫
R1 f (x)dPF, n →∞,
∫
R1 f (x)dFn →
∫
R1 f (x)dF, n →∞,
(4.3)
for any bounded continuous function f .
The limit relations (4.3) allow to speak about the weak convergence of distribu-
tions PFn and distribution functions Fn to PF and F in the sense (4.3).
We also note that
Fn(x) →F(x), n →∞,
(4.4)
for all x ∈R1 \ {p}, and hence, the weak convergence can be characterized with the
help of distribution functions as their convergence (4.4) generalized in certain way.
Namely, for an arbitrary sequence of random variables (Xn)n=1,2,... and a ran-
dom variable X with distribution functions (Fn)n=1,2,... and F we may consider a
convergence
Fn(x) →F(x), n →∞,
for all points of continuity of F, x ∈R1.
Such type of convergence of Xn to X we will call a convergence in distribution
or convergence in law and denote Xn
d−→X, n →∞.
Theorem 4.1
Xn
w−→X, n →∞⇔Xn
d−→X, n →∞.
Proof We show the direct implication only. The inverse implication is the Helly’s
selection principle application. That is why we omit it here.
For ﬁxed x ∈R1 and for each integer α ≥1 we deﬁne two bounded continuous
functions
fα = fα(y) =
⎧⎪⎪⎪⎨
⎪⎪⎪⎩
1,
y ≤x,
α(x −y) + 1,
x < y < x + α−1,
0,
x + α−1 ≤y,
f −
α = f −
α (y) =
⎧⎪⎪⎪⎨
⎪⎪⎪⎩
1,
x −α−1 ≥y,
α(x −y),
x −α−1 < y ≤x,
0,
x ≤y.
Functions fα and f −
α admit the limits:

4.1
Weak convergence and its description in terms of distributions
33
lim
α→∞fα(y) = I(−∞,x](y) and lim
α→∞f −
α (y) = I(−∞,x)(y).
(4.5)
Moreover, applying the Lebesgue dominated convergence theorem we get
lim
α→∞E fα(X) =EI(−∞,x](X) = P(ω : X(ω) ≤x) = F(x),
lim
α→∞E f −
α (X) =EI(−∞,x)(X) = P(ω : X(ω) < x) = F(x−).
(4.6)
Further, due to Xn
w−→X, n →∞, we have for fα and f −
α the limiting relations:
lim
n→∞E fα(Xn) =E fα(X),
lim
n→∞E f −
α (Xn) =E f −
α (X).
By construction of fα and f −
α we obtain
E f −
α (Xn) ≤Fn(x) ≤E fα(Xn).
Hence, for any α ≥1 the following inequalities are true:
E f −
α (X) ≤lim inf
n→∞Fn(x) ≤lim sup
n→∞
Fn(x) ≤E fα(X).
(4.7)
Combining (4.5)-(4.7) we arrive to the inequalities
F(x−) ≤lim inf
n→∞Fn(x) ≤lim sup
n→∞
Fn(x) ≤F(x).
which provide convergence Fn(x) →F(x), n →∞, if x is a point of continuity of
F.
□
Let us pay also a brief attention to a characterization of weak convergence of prob-
ability distributions (Pn)n=1,2,... on space (R1, B(R1)).
We start with a very simple observation. Let P and ˜P be two diﬀerent probability
measures on (R1, B(R1)). Deﬁne a sequence of probability measures (Pn)n=1,2,... as
follows
P2n = P and P2n+1 = ˜P,
and we arrive to conclusion that such a sequence (Pn)n=1,2,... does not converge
weakly.
Another observation: we deﬁne a sequence of probability measures such that
Pn({n}) = 1 and, hence, Pn(R1) = 1. On the other hand, limn→∞Pn((a, b]) = 0 for
any a < b ∈R1.
What does it mean in terms of distribution functions?
Obviously, Pn has the distribution function
Fn(x) =

1,
x ≥n,
0,
x < n, n = 1, 2, . . .,

34
4
Weak convergence of sequences of random variables
and for every x ∈R1
lim
n→∞Fn(x) = G(x) = 0.
Therefore, the limit above is not a distribution function. It means that the set
of distribution functions is not compact. These observations lead us to the next
deﬁnitions.
Deﬁnition 4.1 A collection of probability measures (Pα) is relatively compact,
if every sequence of measures from this collection admits a subsequence which
converges weakly to a probability measure.
Deﬁnition 4.2 A collection of probability measures (Pα) is tight, if for every ϵ > 0
there exists a compact set K ⊆R1 such that
sup
α
Pα(R1 \ K) ≤ϵ.
Similar deﬁnitions can be reproduced word by word for a collection of distribution
functions (Fα).
The classical Prokhorov theorem below speaks us that both these notions are
equivalent.
Theorem 4.2 Let (Pα) be a family of probability measures on (R1, B(R1)). Then
this family is relatively compact if and only if it is tight.
Proof We give the proof of the direct implication only. Assume that (Pα) is not tight.
Hence, there exist ϵ > 0 such that for any compact K ⊆R1 :
sup
α
Pα(R1 \ K) > ϵ.
Taking as K compact intervals In = [−n, n], n = 1, 2, . . ., we arrive to a sequence of
measures (Pαn) such that Pαn(R1 \ In) > ϵ, n = 1, 2, . . . .
Further, since (Pα) is relatively compact, we can select from (Pαn) a subse-
quence (Pαn k ) such that (Pαn k )
w−→˜P, k →∞, where ˜P is a probability measure on
(R1, B(R1)).
Now we have
ϵ ≤lim sup
k→∞
Pαn k (R1 \ In) ≤˜P(R1 \ In),
but it is not possible as n →∞and ˜P is a probability measure.
□
4.2
Weak convergence and Central Limit Theorem
We already know that distribution function F is a key quantitative characteristics of
a random variable on given probability space (Ω, F, P). Moreover, it is clear from

4.2
Weak convergence and Central Limit Theorem
35
the Kolmogorov consistency theorem that there always exist such a probability space
and a random variable with given distribution. To be more illustrative we would like
to describe a particular way how this procedure can be realized.
We assume for simplicity that F(x) is strictly increasing. Then we choose the space
([0, 1], B([0, 1]), l) as a probability space. Let us deﬁne the following random variable
X(ω) =

F−1(ω)
if ω ∈[0, 1], ω = F(x)
0 if ω < 0 or ω > 1.
It is clear that X is B([0, 1])−measurable and if ω′ ↔x′ and ω ↔x, we obtain
P(ω′ : X(ω′) ≤x) = P(ω′ : F−1(ω′) ≤x) =
= P(ω′ : ω′ ≤F(x)) = P(ω′ : ω′ ≤ω) = F(x),
i.e. X has the distribution function F(x).
We also want to emphasize the following additional properties of expectations
and variances.
Problem 4.1 Prove that
1. E n
i=1 aiXi = n
i=1 aiEXi for integrable random variables X1, . . ., Xn and real
numbers a1, . . ., an, n = 1, 2, . . .
2. E 	n
i=1 aiXi = 	n
i=1 aiEXi for independent random variables X1, . . ., Xn, n =
1, 2, . . .
3. Var(aX + b) = a2 Var(X) for a random variable X with well-deﬁned variance
and real numbers a, b
4. Var(n
i=1 aiXi) = n
i=1 a2
i Var(Xi) for independent random variables X1, . . ., Xn
and real numbers a1, . . ., an, n = 1, 2, . . .
Let us pay more attention to normal (or Gaussian) random variables. Denote
p(x) = pμ,σ2(x) =
1
√
2πσ
exp

−(x −μ)2
2σ2

the density of a normal random variable with parameters μ and σ2, i.e. N(μ, σ2).
We note the following:
1. If μ = 0 and σ2 = 1, then the random variable Z = N(0, 1) is called standard.
2. The integral
∫∞
−∞e−x2/2dx =
√
2π is known as the Poisson integral. Therefore,
∫∞
−∞p0,1(x)dx =
1
√
2π
√
2π = 1, which means that p0,1 is the density of some prob-
ability distribution.
3. EZ =
∫∞
−∞xp0,1(x)dx = 0 because h(x) = x is the odd function, and
∫∞
−∞y2e−y2/2
dy =
√
2π for the even function h(x) = x2.
Hence,
Var(Z) = EZ2 −(EZ)2 = EZ2 =
1
√
2π
∫∞
−∞
y2e−y2/2dy = 1.

36
4
Weak convergence of sequences of random variables
4. Standardization procedure.
A random variable X = N(μ, σ2) = σZ + μ or, equivalently, Z = X−μ
σ . Hence,
EX = E(σZ + μ) = σEZ + μ = μ and Var(X) = Var(σZ + μ) = σ2Var(Z) =
σ2, and we get a nice probabilistic interpretation of parameters μ and σ2 as
mean and variance of X.
5. Let X be a normal random variable with parameters μ and σ2. Consider its
exponential transformationY = eX. This equality can be rewritten in a logarithmic
form X = lnY.
In this case Y is called log-normal, and its density has the form
l(y) =
1
√
2πσ
exp

−(ln y −μ)2
2σ2

y−1, y ∈(0, ∞).
Problem 4.2 Denote μY and σ2
Y the mean, and variance of Y respectively. Prove
that
μY =EY = exp(μ + σ2/2),
σ2
Y =Var(Y) = exp(2μ + σ2)(eσ2 −1).
To give an alternative description of moments of a random variable and its distribu-
tion function we introduce the notion of characteristic function.
Deﬁnition 4.3 Let X be a random variable. Then the function φX(t) = EeiX, i =
√
−1, is called a characteristic function of X.
To simplify our further considerations we assume that the distribution function
FX(x) = F(x) admits a density fX(x). Now we note the following:
First, the characteristics function does exist because of
E|eitx| =
∫∞
−∞
|eitx| fX(x)dx =
∫∞
−∞
fX(x)dx = 1 < ∞.
Second, if E|X|m < ∞, m = 1, 2, . . ., then the characteristic function admits m con-
tinuous derivatives such that
EX = iφ′
X(0), EX2 = −φ′′
X(0), . . ., EXm = imφ(m)
X (0).
(4.8)
Relations (4.8) follow from direct calculations of the corresponding integrals:
φ′
X(t) =
∫∞
−∞
ixeitx fX(x)dx
and, hence,
φ′
X(0) = i
∫∞
−∞
xei·0·x fX(x)dx = iEX etc.
Example 4.1
1. For the Bernoulli random variable X taking values 1 and 0 with
probabilities p and q respectively, p + q = 1, we have

4.2
Weak convergence and Central Limit Theorem
37
φX(t) = eit·0q + eit·1p = peit + q.
Hence, φ′
X(t) = peit · i and φ′
X(0) = ip.
2. For the Poisson random variable with parameter λ > 0 we have
φX(t) = EeitX =
∞

m=0
eitmP(ω : X(ω) = m) =
=
∞

m=0
eitm λm
mW e−λ =
∞

m=0
(λeit)m
mW e−λ =
= e−λeλeit = eλ(eit −1)
and φ′
X(0) = λi.
3. For the normal random variable X with parameters μ and σ2 we have using
standardized random variable Z :
φZ(t) =
∫∞
−∞
eitx
1
√
2π
e−x2/2dx
=
∫∞
−∞
cos(tx)
√
2π
e−x2/2dx + i
∫∞
−∞
sin(tx)
√
2π
e−x2/2dx
= 1
√
2π
∫∞
−∞
cos(tx)e−x2/2dx
(4.9)
Diﬀerentiating both side of (4.9) and using the integration by parts we obtain
φ′
Z(t) = 1
√
2π
∫∞
−∞
(−x sin(tx))e−x2/2dx
= −1
√
2π
∫∞
−∞
t cos(tx)e−x2/2dx = −tφZ(t).
Hence,
φ′
Z(t)/φZ(t) = −t.
(4.10)
Integrating the equation (4.10), we get ln φZ(t) = −t2/2 + c, c = const, and
therefore, φZ(t) = ece−t2/2 with ec = 1 due to φZ(0) = 1. Finally, we have
φZ(t) = e−t2/2.
The case of arbitrary X = N(μ, σ2) is considered with the help of standardization
procedure X = μ + σZ. As a result, we arrive to the formula
φX(t) = exp

itμ −t2σ2
2

.

38
4
Weak convergence of sequences of random variables
Now we want to discuss a correspondence between weak convergence (convergence
in distribution, in law) and the convergence of characteristic functions.
There is a simple suﬃcient condition for convergence in distribution. Namely,
assume ( fn)n=1,2,... is a sequence of densities of random variables (Xn)n=1,2,... such
that fn(x) →f (x), n →∞, implies the convergence of their distribution functions
Fn(x) →F(x), n →∞. In fact, this result from Calculus is true for any bounded
function h(x) :
∫∞
−∞
h(x) fn(x)dx →
∫∞
−∞
h(x) f (x)dx, n →∞.
Taking h(x) = eitx in (4.11) we get
φXn(t) →φX(t), n →∞.
The result (4.12) implies the convergence Fn(x) →F(x), n →∞, too. Summarizing
all these ﬁndings we arrive to the following methodology to prove the Central Limit
Theorem (CLT) of the Theory of Probability.
Theorem 4.3 Let (Xn)n=1,2,... be a sequence of independent identically distributed
(iid) random variables with EXn = μ and VarXn = σ2. Denote
Sn =
n

m=1
Xm, Yn = Sn −nμ
σ√n .
Then
Yn
d−→Y, n →∞,
(4.11)
where Y is a standard normal random variable N(0, 1).
This is a version of the CLT for iid random variables.
Proof First of all, we note that the characteristic function of the sum of independent
random variables is equal to the product of characteristic functions of these random
variables. Using this property, we have
φYn(t) =φ
1
σ√n
n
m=1(Xm−μ)(t) = φn
m=1(Xm−μ)(t/σ√n)
=
n

m=1
φZXm−μ(t/σ√n)
=(φ(t/σ√n))n, n = 1, 2, . . .
(4.12)
Further, E(Xm −μ) = 0, E(Xm −μ)2 = σ2 and
φ′(t) = iE(Xm −μ)eit(Xm−μ), φ′(0) = 0,
φ′′(t) = −E(Xm −μ)2eit(Xm−μ), φ′′(0) = −σ2.

4.2
Weak convergence and Central Limit Theorem
39
Hence, we can expand φ in a Taylor expansion at point t = 0 and ﬁnd that
φ(t) = 1 + 0 −σ2t2
2
+ t2Δ(t),
where Δ(t) →0, t →0. Therefore, using (4.14) we get
φYn(t) = φn(t/σ√n) = exp(n log φ(t/σ√n)) = exp(n log(1 −t2
2n + t2
nσ2 Δ(t)),
and hence limn→∞φYn(t)e−t2/2 which is the characteristics function of N(0, 1).
□
A more general version of the CLT is usually formulated under the Lindeberg
Condition (L).
Let (Xn)n=1,2,... be a sequence of independent random variables with EXn =
μn, VarXn = σ2
n. We say that the sequence (Xn)n=1,2,... satisﬁes the condition (L) if
for any ϵ > 0
 n

m=1
σ2
m
−1
n

m=1
∫

x:|x−μm |≥ϵ(n
m=1 σ2m)
1/2(x −μm)2dFXm(x) →0, n →∞.
Under the conditions above
Sn −ESn
(VarSn)1/2
d−→N(0, 1), n →∞.
The proof of this version of the CLT is provided by the same method as the proof of
Theorem 4.3.

Chapter 5
Absolute continuity of probability
measures and conditional expectations
Abstract In this chapter a special attention is devoted to the absolute continuity
of measures. It is shown how this notion and the Radon-Nikodym theorem work to
deﬁne conditional expectations. The list of properties of conditional expectations are
given here. In particular, it is emphasized the optimality in the mean-square sense
of conditional expectations (see [7], [15], [19], [40], [41] and [45]).
5.1
Absolute continuity of measures and the
Radon-Nikodym theorem
Let (Ω, F, P) be a probability space and X be a random non-negative variable. Deﬁne
a set function
˜P(A) =
∫
A
XdP = EXIA, A ∈F .
(5.1)
Let us take A = ∪∞
i=1Ai, Ai ∩Aj = ∅, i  j. Using a linearity of expected values we
ﬁnd that ˜P from (5.1) is a ﬁnite-additive measure. Further, with the help of monotonic
convergence theorem we have
˜P(A) =EXIA = EXI∪∞
i=1 Ai =
=E
∞

n=1
XIAn =
∞

n=1
EXIAn =
∞

n=1
˜P(An),
and therefore ˜P is countable additive.
In case of arbitrary random variable we can use the standard representation
X = X+ −X−. Assume that one of expected values EX+ or EX−is ﬁnite. In such a
case one can deﬁne the following signed-measure
© The Author(s), under exclusive license to Springer Nature Switzerland AG 2023
A. Melnikov, A Course of Stochastic Analysis, CMS/CAIMS Books in Mathematics 6,
https://doi.org/10.1007/978-3-031-25326-3_5
41

42
5
Absolute continuity of probability measures and conditional expectations
˜P(A) =
∫
A
X+dP −
∫
A
X−dP = ˜P+(A) −˜P−(A), A ∈F,
(5.2)
that satisﬁes the next property
P(A) = 0 ⇒˜P(A) = 0.
(5.3)
Theproof of (5.3) is standard. For simplerandomvariablewithvalues x1, . . ., xn, X =
n
i=1 xiIAi we have
˜P(A) = EXIA =
n

i=1
xiP(Ai ∩A) = 0, P(A) = 0.
For arbitrary random variable X we monotonically approximate X by a sequence of
simple random variables Xn ↑X, n →∞, and take a limit according to monotonic
convergence theorem:
˜P(A) = EXIA = lim
n→∞EXnIA = 0.
Deﬁnition 5.1 Relation (5.3) between two measures P and ˜P (not necessarily prob-
ability measures) is called the absolute continuity of ˜P with respect to P, and denoted
˜P ≪P. Moreover, if P ≪˜P then measures P and ˜P are equivalent (P ∼˜P).
It turns out, one can characterize the absolute continuity property with the help of
relations (5.1)-(5.2). This fundamental fact is known as Radon-Nikodym theorem.
Theorem 5.1 Let (Ω, F ) be a measurable space. Let μ be a σ-additive measure
and λ be a signed measure which is absolute continuous with respect to μ, λ =
λ1 −λ2, where one of λ1 or λ2 is ﬁnite. Then there exists F -measurable function
Z = Z(ω), ω ∈Ω, with values in [−∞, +∞] such that
λ(A) =
∫
A
Z(ω)dμ, A ∈F .
(5.4)
Moreover, the function Z is uniquely deﬁned up to sets of μ-measure zero.
In representation (5.4) the function Z is called the Radon-Nikodym density or
derivative and denoted Z = dλ
dμ .
As the ﬁrst consequence of Theorem 5.1 we get a convenient rule of changing
of measure in expected values. Let X be a random variable on a probability space
(Ω, F, P) and ˜P ≪P with the Radon-Nikodym density Z. Then we formally obtain:
˜EX =
∫
Ω
Xd ˜P =
∫
Ω
X d ˜P
dP dP =
∫
Ω
XZdP = EXZ.

5.2
Conditional expectations and their properties
43
5.2
Conditional expectations and their properties
Now we are ready to introduce the conditional expected value of random variable X
with respect to a σ-algebra Y ⊆F . In this case we also call Y sub-σ-algebra of F .
Deﬁnition 5.2 Let X be a non-negative random variable and Y be a sub-σ-algebra
of F . Then a random variable E(X|Y) is called the conditional expectation of X
with respect to Y if E(X|Y) is Y-measurable and
EXIA = E (E(X|Y)IA)
(5.5)
for every A ∈Y.
In general case, we decompose X = X+ −X−and assume that one of random vari-
ables E(X+|Y) and E(X−|Y) is ﬁnite, and deﬁne
E(X|Y) = E(X+|Y) −E(X−|Y).
(5.6)
Existence of E(X|Y) in (5.6) follows from the Radon-Nikodym theorem. To prove it
we deﬁne a (signed) measure ˜P(A) = EXIA on a measurable space (Ω, Y) such that
˜P ≪P. According to Theorem 5.1 there exists a unique Radon-Nikodym density
which can be denoted here E(X|Y):
˜P(A) =
∫
A
E(X|Y)dP.
Let us note that the above equality coincides with (5.5).
Using deﬁnition of E(X|Y) we can easily deﬁne:
Conditional Probability w.r. to Y
P(B|Y) = E(IB|Y), B ∈F,
conditional variance w.r. to Y
Var(X|Y) = E

(X −E(X|Y))2|Y

.
It is often the σ-algebra Y is generated by another random variable Y. Therefore,
we can deﬁne conditional expected value and conditional probability X w.r. to Y as
follows
E(X|Y) = E(X|Y), P(B|Y) = P(B|Y), B ∈F,
where Y = YY.
Let us count the list of properties of conditional expectations.
1. If X = c (a.s.), then E(X|Y) = c (a.s.),
2. If X ≤Y (a.s.), then E(X|Y) ≤E(Y|Y) (a.s.),
3. |E(X|Y)| ≤E(|X| |Y) (a.s.),

44
5
Absolute continuity of probability measures and conditional expectations
4. For random variables X and Y and constants a and b we have
E(aX + bY|Y) = aE(X|Y) + bE(Y|Y) (a.s.),
5. E(X|F∗) = EX (a.s.),
6. E(X|F ) = X (a.s.),
7. EE(X|Y) = EX,
8. If sub-σ-algebras Y1 ⊆Y2, then
E (E(X|Y2)|Y1) = E(X|Y1) (a.s.),
9. If sub-σ-algebras Y2 ⊆Y1, then
E (E(X|Y2)|Y1) = E(X|Y2) (a.s.),
10. We say that two sub-σ-algebras Y1 and Y2 are independent, if for any B1 ∈Y1
and B2 ∈Y2 we have P(B1 ∩B2) = P(B1)P(B2),
For a random variable X and a sub-σ-algebra Y we say that X does not depend
on Y if YX and Y are independent. In this case we have
E(X|Y) = EX (a.s.),
if EX is well-deﬁned.
11. For random variables X andY such thatY is Y-measurable, E|X| < ∞, E|XY| <
∞, we have
E(XY|Y) = YE(X|Y) (a.s.)
12. For
a
(generalized)
sequence
of
random
variables
(Xn)n=1,2,...
such
that
|Xn| ≤Y,
n = 1, 2, . . .,
EY < ∞
and
Xn →X,
n →∞,
a.s.
We
have E(Xn|Y) →E(X|Y), (a.s.) n →∞,
13. If
Xn ≥Y,
EY > −∞
and
Xn ↑X,
n →∞,
a.s.,
then
E(Xn|Y) ↑
E(X|Y), (a.s.) n →∞,
14. If
Xn ≤Y,
EY < ∞
and
Xn ↓X,
n →∞,
a.s.,
then
E(Xn|Y) ↓
E(X|Y), (a.s.) n →∞,
15. If Xn ≥Y, EY > −∞, then
E(lim inf
n→∞Xn|Y) ≤lim inf
n→∞E(Xn|Y), (a.s.)
16. For a non-negative random variables (Xn)n=1,2,... we have
E
 ∞

n=1
Xn|Y

=
∞

n=1
E(Xn|Y) (a.s.)
Let us show ways of proof of such properties. In case 2) we have for any A ∈Y that
∫
A
XdP ≤
∫
A
YdP.

5.2
Conditional expectations and their properties
45
Therefore, we get from (5.5) that
∫
A
E(X|Y)dP ≤
∫
A
E(Y|Y)dP,
which means that E(X|Y) ≤E(Y|Y) (a.s.)
In case (8) we have for any A ∈Y1 ⊆Y2 that
∫
A
E(X|Y1)dP =
∫
A
XdP =
∫
A
E(X|Y2) =
∫
A
E (E(X|Y2)|Y1) dP,
which certiﬁes the statement in (8).
Below we provide some comments and detailed calculations of conditional expec-
tations.
Consider E(X|Y) for two (integrable) random variables X and Y. According to
our deﬁnition E(X|Y) is YY-measurable, and by the representation theorem there
exists a Borelian function φ(·) such that
φ(Y(ω)) = E(X|Y)(ω), ω ∈Ω.
(5.7)
For A ∈YY we get from (5.7):
∫
A
XdP =
∫
A
E(X|Y)dP =
∫
A
φ(Y)dP.
(5.8)
Further, taking A = Y−1(B), B ∈B(R1) we have
∫
Y−1(B)
φ(Y)dP =
∫
B
φ(y)dPY,
and hence
∫
Y−1(B)
XdP =
∫
B
φ(y)dPY.
(5.9)
Having equalities (5.7)-(5.9) we can take φ(y) = E(X|Y = y), y ∈R1.
To provide more details one can consider a special case when the pair (X,Y)
admits a joint density fXY(x, y). In such a case we can put
fX |Y(x|y) = fxy(x, y)
fY(y)
and ﬁnd that for C ∈B(R1)
P(X ∈C|Y = y) =
∫
C
fX |Y(x|y)dx
and
E(X|Y = y) =
∫
R1 x fX |Y(x|y)dx.

46
5
Absolute continuity of probability measures and conditional expectations
This is a reason that the function fX |Y(x|y) is called a density of a conditional
distribution (conditional density).
In case of discrete random variables X and Y with values x1, x2, . . . and y1, y2, . . .
correspondingly, denote Y = σ(Y) = YY and (ω : Y(ω) = yi) = Di, i = 1, 2, . . .
Sets Di, i = 1, 2, . . . are atoms for P in the sense that P(Di) > 0 and any subset
A ⊆Di has a probability zero or its completion to Di (i.e. Di \ A) has a probability
zero. We can deﬁne
E(X|Di) = EXIDi
P(Di) , i = 1, 2, . . .
Then the calculation of E(X|Y) is reduced to the claim:
E(X|Y) = E(X|YY) = E(X|Di) (a.s.)
on the atom Di, i = 1, 2, . . .
To connect these deﬁnitions and results to the general deﬁnition we need to check
(5.5). In particular, we have
EE(X|Y) =
∞

i=1
E(X|Di)P(Di)
=
∞

i=1
E(XIDi) =
∞

i=1
∞

j=1
xjP(X = xj,Y = yi)
=
∞

j=1
∞

i=1
xjP(X = xj,Y = yi)
=
∞

j=1
xj
∞

i=1
P(X = xj,Y = yi) =
∞

j=1
xjP(X = xj)
=EX.
Let’s take note of that calculations of E(X|Y1, . . .,Yn) can be given in the same way.
Finally, we demonstrate an important application of E(X|Y). We will interpret Y
as an observable variable and X as a non-observable. This is a typical situation in
many areas, including option pricing theory, where X is a pay-oﬀof option and Y is
a stock price.
How can we estimate X based on observations of Y to provide the optimality of
the estimate?
A satisfactory solution of the problem can be given as follows.
Let φ = φ(x), x ∈R1, be a Borelian function. Taking φ(Y) we get an estimate for
X, and we should choose from a variety of such estimates an optimal estimate. As a
criteria we can take E(X −φ(Y))2 and deﬁne the optimal estimate φ∗(Y) as follows
E(X −φ∗(Y))2 = inf
φ E(X −φ(Y))2,
where we assume EX2 < ∞and Eφ2(Y) < ∞.

5.2
Conditional expectations and their properties
47
Theorem 5.2 The
optimal
estimate
has
the
following
representation
φ∗(x) = E(X|Y = x).
Proof Taking φ∗(Y) = E(X|Y) we have for any other estimate φ :
E(X −φ(Y))2 =E
	
(X −φ∗(Y)) + (φ∗(Y) −φ(Y))

2
=E(X −φ∗(Y))2 + 2E(X −φ∗(Y))(φ∗(Y) −φ(Y)) + E(φ∗(Y) −φ(Y))2
=E(X −φ∗(Y))2 + E(φ∗(Y) −φ(Y))2 + 2E
	
E (X −φ∗(Y))(φ∗(Y) −φ(Y)) |Y

=E(X −φ∗(Y))2 + E(φ∗(Y) −φ(Y))2
≥E(X −φ∗(Y))2.

Chapter 6
Discrete time stochastic analysis: basic
results
Abstract Chapter 6 is completely devoted to a discrete time stochastic analysis.
It contains the key notions adapted to discrete time like stochastic basis, ﬁltration,
predictability, stopping times, martingales, sub- and supermartingales, local densities
of probability measures, discrete stochastic integrals and stochastic exponents. It
is stated the Doob decomposition for stochastic sequences, maximal inequalities,
and other Doob’s theorems. The developed martingale technique is further applied
to prove several asymptotical properties for martingales and submartingales (see
[1], [7], [8], [10], [15], [40], and [45]).
6.1
Basic notions: stochastic basis, predictability and
martingales
We have seen already that a sequence of random variables X1, X2, . . ., Xn can be
interpreted as a n-times repetition (realization) of the underlying random experiment.
One can note that the order of appearance of new information is important. For
example, such order and such information are valuable in stock exchange trading.
One can also observe that a numeration of Xi may not be directly connected to
real (physical) time, because an operation time is often exploited instead of real
time in ﬁnance. As we know, to provide an accurate work with random variables
we need to assume that these random variables are deﬁned on some probability
space (Ω, F, P). In this setting, for each ﬁxed outcome ω ∈Ω one can observe
a sequence of numbers X1(ω), X2(ω), . . ., Xn(ω), . . ., called a trajectory or sample
path. It may present a behavior of stock prices or indexes over given time interval. So,
thinking in this way, we must emphasize the diﬀerence between probability theory
and stochastic/random processes. It can be roughly explained as follows. If theory of
probability studies probabilities of occurrence of random events, including the events
connected to random variables, theory of stochastic processes considers probabilities
of occurrence of trajectories and families of trajectories of stochastic processes. Such
a diﬀerence calls for a “supplementary equipment” of given probability space with
© The Author(s), under exclusive license to Springer Nature Switzerland AG 2023
A. Melnikov, A Course of Stochastic Analysis, CMS/CAIMS Books in Mathematics 6,
https://doi.org/10.1007/978-3-031-25326-3_6
49

50
6
Discrete time stochastic analysis: basic results
an information ﬂow or ﬁltration. It is a non-decreasing family (Fn)n=0,1,... together
with (Ω, F, (Fn)n=0,1,..., P) called a stochastic basis. Usually, the main σ-algebra
F is determined by the ﬁltration (Fn)n=0,1,... in the sense that F∞= σ(∪nFn) = F .
We sometimes will count that F0 is trivial, i.e. F0 = {∅, Ω}. Filtration creates a
new class of random variables, called stopping times. A random variable τ : Ω →
{0, 1, . . ., n, . . ., ∞} is called a stopping time if for each n = 0, 1, . . .
{ω : τ(ω) ≤n} ∈Fn,
i.e. each value n is taken based on information until time n without having information
from the future time.
We can interpret a stopping time τ as a random time, and therefore we can speak
about information Fτ before this time τ. It is formally realized as follows:
Fτ = {A ∈F∞: A ∩{ω : τ(ω) ≤n} ∈Fn},
and Fτ is a σ-algebra.
If two stopping times τ and σ are connected to each other through inequality
τ ≤σ (a.s.), then obviously Fτ ⊆Fσ.
Now if (Xn)n=0,1,... is a sequence of random variables on (Ω, F, (Fn)n=0,1,..., P)
with information ﬂow (Fn) and Xn −Fn−measurable for each n = 0, 1, . . .. In this
case we will call (Xn) adapted to (Fn)n=0,1,..., or stochastic.
For a stochastic sequence (Xn)n=0,1,... and a stopping time τ we deﬁne
Xτ =
∞

n=0
XnI{τ=n} + X∞I{τ=∞},
where X∞may be a ﬁxed constant or X∞= limn→∞= Xn (a.s.), if the limit does
exist.
The random variable Xτ is a “superposition” of a stochastic sequence and τ, and
hence, Xτ −Fτ−measurable. We can go even further if we take a stochastic sequence
(Xn)n=0,1,... and a non-decreasing sequence of stopping times (τn)n=0,1,... and deﬁne
a new sequence of random variables
Yn = Xτn, τn ≤τn+1.
It is quite natural to call (τn) as a time change and (Yn) as a time changed sequence.
The idea of “time change” is very productive for Stochastic Analysis. For example,
in Mathematical Finance this type of time change is often based on market volatility,
and is called the “operation time”.
Problem 6.1 Prove that
1. τ is a stopping time if and only if {τ = n} ∈Fn for all n.
2. Fτ is a σ−algebra, if τ is a stopping time.
3. Fτ ⊆Fσ if stopping times τ ≤σ(ω) (a.s.).
4. Xτ is Fτ-measurable if τ is a stopping time.
5. τ ∧σ is a stopping time.

6.1
Basic notions: stochastic basis, predictability and martingales
51
We can also consider (Ω, F, (Fn), P) as a system of probability spaces
(Ω, F0, P0), (Ω, F1, P1), . . ., where P0 on F0 is just a restriction of P to F0 and
so on. In this framework we can consider another probability measure ˜P and ˜Pn as
its restriction to Fn. Assume that ˜Pn ≪Pn, n = 0, 1, . . . and denote Zn = d ˜Pn
dPn the
density of ˜Pn with respect to Pn, n = 0, 1, . . . . The sequence (Zn)n=0,1,... is called a
local density of ˜P with respect to P, and for each n = 0, 1, . . . we have
EZn =
∫
Ω
ZndP =
∫
Ω
ZndPn = ˜Pn(Ω) = 1.
Further, for any A ∈Fn−1 we formally have that
∫
A
ZndP =
∫
A
ZndPn =
∫
A
d ˜Pn
dPn
dPn = ˜Pn(A) = ˜Pn−1(A) =
∫
A
Zn−1dP.
It means that (a.s.)
E(Zn|Fn−1) = Zn−1, n = 1, 2, . . .
(6.1)
We can also ask the question:
Is it possible to calculate for some integrable random variable Y the conditional
expectation ˜E(Y|Fn−1) via E(Y|Fn−1)?
Again, take A ∈Fn−1 and ﬁnd that
∫
A
E(Y Zn|Fn−1)dP =
∫
A
Y ZndP =
∫
A
Yd ˜Pn
=
∫
A
Yd ˜Pn−1 =
∫
A
˜E(Y|Fn−1)d ˜Pn−1
=
∫
A
˜E(Y|Fn−1)dPn−1 =
∫
A
˜E(Y|Fn−1)Zn−1dP,
and hence,
˜E(Y|Fn−1) = Z−1
n−1E(Y Zn|Fn−1) (a.s.)
(6.2)
Relation (6.2) is called a rule of change of probability in conditional expectations.
Besides adapted sequences of random variables, we can introduce sequences of
random variables which are in between deterministic and stochastic sequences. We
say that an adapted sequence (An)n=0,1,... is predictable, if An-Fn−1-measurable for
n = 1, 2, . . .. We also can take the property (6.1) to introduce the whole class of
stochastic sequences called martingales. We say that an integrable adapted sequence
(Mn)n=0,1,... is a martingale, if
E(Mn|Fn−1) = Mn−1 (a.s.) f or n = 1, 2, . . . .
(6.3)
Relation (6.3) can be rewritten as follows E(Mn −Mn−1|Fn−1) = 0 (a.s.) It means
the sequence Yn = Mn −Mn−1 presents so-called a martingale-diﬀerence.

52
6
Discrete time stochastic analysis: basic results
We can see also that the local density (Zn)n=0,1,... in (6.1) is a martingale
with respect to P. These two types of stochastic sequences is a natural basis
for many others. To demonstrate this claim, we consider an arbitrary integrable
stochastic sequence (Xn)n=0,1,... with X0 = 0 (a.s.) for simplicity. Deﬁne for each
n = 1, 2, . . ., ΔXn = Xn −Xn−1 and write an obvious equality
ΔXn = ΔXn −E(ΔXn|Fn−1) + E(ΔXn|Fn−1) = ΔMn + ΔAn;
(6.4)
where
ΔMn = ΔXn −E(ΔXn|Fn−1),
ΔAn = E(ΔXn|Fn−1).
It is clear from (6.4) that for n = 0, 1, . . .
Xn = Mn + An,
(6.5)
where Mn = 
i≤n ΔMi and An = 
i≤n ΔAi; and therefore, (Mn)n=0,1,... is a martin-
gale and (An)n=0,1,... is predictable.
Such a unique decomposition (6.5) is called the Doob decomposition of
(Xn)n=0,1,... In particular, it is true for sequences (Xn)n=0,1,... satisfying conditions
E(Xn|Fn−1) ≥Xn−1 (a.s.)
and
E(Xn|Fn−1) ≤Xn−1 (a.s.)
Such sequences are called submartingales and supermartingales and in their decom-
positions (6.5) ΔAn ≥0 and ΔAn ≤0 (a.s.), n = 1, 2, . . ., correspondingly.
Remark 6.1 Given a martingale (Xn)n=0,1,... there is a simple way of constructing
submartingales (supermartingales). Suppose φ is a convex downward measurable
function such that E|φ(Xn)| < ∞, n = 0, 1, . . . Then Jensen’s inequality implies that
(φ(Xn))n=0,1,... is a submartingale.
Let us consider a martingale (Mn)n=0,1,... such that EM2
n < ∞, n = 0, 1, . . ., then
it is called square-integrable. Further, due to the Jensen’s inequality Xn = M2
n is a
submartingale. Using the Doob decomposition (6.5) one can conclude that
M2
n = mn + ⟨M, M⟩n, n = 0, 1, . . .,
where (mn)n=0,1,... is a martingale and (⟨M, M⟩n)n=0,1,... is a non-decreasing pre-
dictable sequence called the quadratic characteristic (compensator) of M. More-
over,
⟨M, M⟩n =
n

i=1
E((ΔMi)2|Fi−1), ⟨M, M⟩0 = 0,

6.1
Basic notions: stochastic basis, predictability and martingales
53
and
E

(Mk −Ml)2|Fl

=E(M2
k −M2
l |Fl)
=E(⟨M, M⟩k −⟨M, M⟩l|Fl), l ≤k,
and EM2
n = E⟨M, M⟩n, n = 0, 1, . . .. It is possible to deﬁne a measure of correlation
between two square-integrable martingales (Mn)n=0,1,... and (Nn)n=0,1,... :
⟨M, N⟩n = 1
4{⟨M + N, M + N⟩n −⟨M −N, M −N⟩n},
n = 0, 1, . . ., which is called the joint quadratic characteristic of (Mn)n=0,1,... and
(Nn)n=0,1,....
It is almost obvious to show that the sequence (MnNn −⟨M, N⟩n)n=0,1,... is a
martingale, and if ⟨M, N⟩n = 0 for all n = 0, 1, . . ., then such martingales are called
orthogonal.
Further, the following property that connects the martingale property and absolute
continuity of probability measures is related to formula (6.2) and can be referred to
as a discrete time version of the Girsanov theorem.
Let (Mn)n=0,1,..., M0 = 0, be a martingale with respect to the original measure
P and assume E|ZnZ−1
n−1ΔMn| < ∞, n = 1, 2, . . .. Deﬁne ( ˜Mn)n=0,1,..., ˜M0 = 0, by
relations
Δ ˜Mn = ΔMn −E(ZnZ−1
n−1ΔMn|Fn−1), n = 1, 2, . . . .
Using the rule of change of measure (6.2), we obtain
˜E(Δ ˜Mn|Fn−1) = ˜E(ΔMn −E(ZnZ−1
n−1ΔMn|Fn−1)|Fn−1)
= ˜E(ΔMn|Fn−1) −˜E(ΔMn|Fn−1) = 0 (a.s.),
which implies that ( ˜Mn)n=0,1,... is a martingale with respect to ˜P ≪P with the local
density (Zn)n=0,1,....
Let us use predictable and martingale stochastic sequences to construct more
complicated objects. For a predictable (Hn)n=0,1,... and a martingale (mn)n=0,1,...
deﬁne a discrete stochastic integral
H ∗mn =
n

i=0
HiΔmi.
(6.6)
If martingale (mn)n=0,1,... is square-integrable, sequence (Hn)n=0,1,... is predictable
and EH2
nΔ⟨m, m, ⟩n < ∞, n = 0, 1, . . ., then (H ∗Mn)n=0,1,... is a square-integrable
martingale with quadratic characteristic
⟨H ∗m, H ∗m⟩n =
n

i=0
H2
i Δ⟨m, m⟩i.

54
6
Discrete time stochastic analysis: basic results
Further, let (Mn)n=0,1,... be a ﬁxed square-integrable martingale, then one
can consider all square-integrable martingales (Nn)n=0,1,... that are orthogonal to
(Mn)n=0,1,.... Introduce a family of square-integrable martingales of the form
Xn = Mn + Nn.
(6.7)
On the other hand, any square-integrable martingale (Xn)n=0,1,... can be written in the
form (6.7), where the orthogonal term (Nn)n=0,1,... satisﬁes (6.6) with the martingale
(mn)n=0,1,... that is orthogonal to the given martingale (Mn)n=0,1,.... Such a version
of decomposition (6.7) is referred to as the Kunita-Watanabe decomposition.
Discrete stochastic integrals are related to discrete stochastic diﬀerential equa-
tions. Solutions of such equations are used in modeling the dynamics of asset prices
in ﬁnancial markets.
Consider a stochastic sequence (Un)n=0,1,... with U0 = 0 and deﬁne a new stochas-
tic sequence (Xn)n=0,1,... with X0 = 1 by
ΔXn = Xn−1ΔUn, n = 1, 2, . . . .
(6.8)
Solution of (6.8) has the form
Xn =
n

i=1
(1 + ΔUi) = En(U), n = 1, 2, . . .,
and is called a stochastic exponential.
One can consider a non-homogeneous version of equation (6.8)
ΔXn = ΔNn + Xn−1ΔUn, X0 = N0,
(6.9)
where (Nn)n=0,1,... is a given sequence.
Solution of (6.9) is determined with the help of stochastic exponential as follows
Xn = En(U)

N0 +
n

i=1
E−1
i (U)ΔUi
	
.
Let us list very helpful properties of stochastic exponentials.
1. E−1
n (U) = En(−U∗), where ΔU∗
n =
ΔUn
1+ΔUn, ΔUn  −1;
2. (En(U))n=0,1,... is a martingale if and only if (Un)n=0,1,... is a martingale;
3. En(U) = 0 (a.s.) for n ≥τ0 = inf(i : Ei(U) = 0);
4. For two stochastic sequences (Un) and (Vn) the next multiplication rule of stochas-
tic exponentials is true:
En(U)En(V) = En(U + V + [U,V]),
where Δ[U,V]n = ΔUnΔVn.

6.2
Martingales on ﬁnite time interval
55
6.2
Martingales on ﬁnite time interval
Here we study stochastic sequences on the interval [0, N] = {0, 1, . . ., N}. The ﬁrst
important theorem is devoted to an interesting characterization of the notion of a
martingale.
Theorem 6.1 Let (Xn)n=0,1,...,N be an integrable stochastic sequence on a stochastic
basis (Ω, F, (Fn)n=0,1,...,N, P). Then the following statements are true
1) The sequence (Xn)n=0,1,...,N is a martingale if and only if Xn = E(XN |Fn) (a.s.)
for all n = 0, 1, . . ., N.
2) If for all stopping times τ the equality EXτ = EX0 is fulﬁlled then (Xn)n=0,1,...,N
is a martingale.
Proof 1) For a direct implication, using the deﬁnition of conditional expectations
and their telescopic property, we have that (a.s.)
E(XN |FN−2) = E (E(XN |FN−1)|FN−2) = E(XN−1|FN−2) = XN−2, etc.
For an inverse implication we also use the deﬁnition and the telescopic property and
ﬁnd that for all n (a.s.)
E(XN |FN−1) = E (E(XN |FN)|FN−1) = E(XN |FN−1) = XN−1, etc.
2) For a ﬁxed n ≤N and A ∈Fn we deﬁne the following stopping time
τA(ω) =

n
i f ω ∈A,
N
i f ω  A.
According to the assumption we have
EX0 = EXτA =EXτAIA + EXτAIAc
=EXnIA + EXN IAc .
It means that E(XN |Fn) = Xn (a.s.) and by (a) we conclude that (Xn)n=0,1,...,N is a
martingale.
□
Theorem 6.1 gives us an understanding about a strong connection between martin-
gales and stopping times. The next statement which has a special name as “optional
sampling theorem” of Doob tells us more about these connections.
Theorem 6.2 Let (Xn)n=0,1,...,N be a martingale (submartingale, supermartingale)
and τ1 ≤τ2 (a.s.) are stopping times, then
E(Xτ2|Fτ1) = Xτ1 (a.s.)

56
6
Discrete time stochastic analysis: basic results
(E(Xτ2|Fτ1) ≥Xτ1 and E(Xτ2|Fτ1) ≤Xτ1 (a.s.), respectively). In particular EXτ1 =
EXτ2.
Proof of this theorem, which generalizes the obvious property for deterministic
times, readily follows from next considerations.
For A ∈Fτ1, n ≤N and B = A ∩{τ1 = n} in order to prove
∫
A Xτ2dP =
∫
A Xτ1dP
we need to prove that ∫
B∩{τ2 ≥n}
Xτ2dP =
∫
B∩{τ2 ≥n}
XndP.
It follows from the next equalities
∫
B∩{τ2 ≥n}
XndP =
∫
B∩{τ2=n}
XndP +
∫
B∩{τ2>n}
XndP
=
∫
B∩{τ2=n}
XndP +
∫
B∩{τ2>n}
E(Xn+1|Fn)dP
=
∫
B∩{τ2=n}
XndP +
∫
B∩{τ2>n}
Xn+1dP
=
∫
B∩{n≤τ2 ≤n+1}
XndP +
∫
B∩{τ2 ≥n+2}
Xn+2dP = . . . =
=
∫
B∩{τ2 ≥n}
Xτ2dP.
It turns out for martingales (submartingales, supermartingales) one can get inequal-
ities called maximal (or the Kolmogorov-Doob inequalities) which are stronger than
the Chebyshev inequality.
Theorem 6.3 1. If (Xn)n=0,1,...,N is a submartingale, then for any λ > 0 :
P(ω : max
n≤N Xn ≥λ) ≤EX+
N
λ
.
2. If (Xn)n=0,1,...,N is a supermartingale, then for any λ > 0 :
P(ω : max
n≤N Xn ≥λ) ≤EX0 + EX−
N
λ
.
3. If (Xn)n=0,1,...,N is a martingale, then for any λ > 0 :
P(ω : max
n≤N |Xn| ≥λ) ≤E|XN |
λ
.
Proof Let us deﬁne the following stopping time
τ = inf{n ≤N : Xn ≥λ},

6.2
Martingales on ﬁnite time interval
57
where we put τ = N if the set in brackets above is ∅.
Denote A = {ω : maxn≤N Xn ≥λ} and ﬁnd that
A ∩{τ = n} = {τ = n} ∈Fn,
if n < N and
A ∩{τ = N} ∈FN,
due to A ∈FN.
Hence, A ∈Fτ.
To prove the statement (1) of the theorem we derive from Theorem 6.2 that
EXτIA ≤EXN IA
because stopping time τ ≤N.
If the event A occurs, then Xτ ≥λ and XτIA ≥λIA. Therefore,
λP(A) ≤EXN IA ≤EX+
N IA ≤EX+
N,
and we obtain (1).
Further, due to 0 ≤τ ≤N we have from Theorem 6.2
EX0 ≥EXτ = EXτIA + EXτIAc ≥EXτIA + EXN IAc .
Hence, we get statement (2) after next calculations
λP(A) ≤EXτIA ≤EX0 −EXN IAc
=EX0 + E(−XN)IAc ≤EX0 + E(−XN)+IAc
≤EX0 + EX−
N.
The last statement (3) is a combination of (1) and (2).
□
We ﬁnish this section by the well-known and helpful results of Doob about estima-
tion of number of upcrossings (downcrossings) of given interval by submartingales
and supermartingales.
Let a < b be real numbers and (Xn)n=0,1,...,N be a stochastic sequence. Deﬁne the
following sequence of stopping times:
τ0 = 0, τ1 = inf{n > 0 : Xn ≤a},
τ2 = inf{n > τ1 : Xn ≥b}, . . .,
τ2m−1 = inf{n > τ2m−2 : Xn ≤a},
τ2m = inf{n > τ2m−1 : Xn ≥b},
where τk = N if the set in brackets above is ∅.

58
6
Discrete time stochastic analysis: basic results
It is clear that between τ2m−1 and τ2m that is an upcrossing of the interval (a, b)
by the sequence (Xn) occurs.
Deﬁne the following random variable
βX
+ (N, a, b) =

0,
i f τ2 > N,
max{m : τ2m ≤N},
i f τ2 ≤N,
which is called the number of upcrossings of (a, b) by the sequence (Xn) during the
time interval [0, N].
Deﬁnition of notion of downcrossings is given in a similar way. Denote the
corresponding number of downcrossings by βX
−(N, a, b).
Theorem 6.4 Let (Xn)n=0,1,...,N be a submartingale and βX
± (N, a, b) be the number
of upcrossings (downcrossings) of the interval (a, b). Then
EβX
+ (N, a, b) ≤E(XN −a)+
b −a
,
(6.10)
EβX
−(N, a, b) ≤E(XN −b)+
b −a
.
(6.11)
Proof We prove only (6.10) in view a symmetry of formulas (6.10) and (6.11). Let us
reduce the initial problem to estimation of number of upcrossings by a non-negative
submartingale ((Xn −a)+)n=0,1,...,N of the interval (0, b −a). Moreover, we can put
a = 0 and prove that
EβX
+ (N, 0, b) ≤EXN
b
,
(6.12)
for a non-negative submartingale (Xn)n=0,1,2,...,N, X0 = 0.
Deﬁne for i = 1, 2, . . . a sequence of random variables:
φi =

1,
i f τm < i ≤τm+1 for some non-even m,
0,
i f τm < i ≤τm+1 for some even m.
It follows from deﬁnitions of βX
+ (N, a, b) and φi that
bβX
+ (N, 0, b) ≤
N

i=1
φi(Xi −Xi−1).
Let us note that
{φi = 1} = ∪non−even m({τm < i}  {τm+1 < i}) ∈Fi−1,
and therefore by properties of conditional expected values and submartingales

6.3
Martingales on inﬁnite time interval
59
bEβX
+ (N, 0, b) ≤E
N

i=1
φi(Xi −Xi−1)
=
N

i=1
∫
{φi }
(Xi −Xi−1)dP
=
N

i=1
∫
{φi }
E(Xi −Xi−1|Fi−1)dP
≤
N

i=1
EE(Xi −Xi−1|Fi−1)
=(EX1 −EX0) + (EX2 −EX1) + . . . + (EXN −EXN−1) = EXN.
and we arrive to (6.12), and further to (6.10).
□
Corollary 6.1 Let (Xn)n=0,1,...,N be a supermartingale and αX
+ (N, a, b) be the num-
ber of upcrossings of the interval (a, b). Then
EαX
+ (N, a, b) ≤E(a −XN)+
b −a
.
(6.13)
Proof The inequality (6.13) follows from (6.11) because αX
+ (N, a, b) can be inter-
preted as the number of downcrossings of the interval (−b, −a) by the submartingale
(−Xn)n=0,1,...,N :
EαX
+ (N, a, b) = Eβ−X
−(N, −b, −a) ≤E(−XN −(−a))+
(−a) −(−b)
= E(a −XN)+
b −a
.
□
6.3
Martingales on inﬁnite time interval
Here
martingales
(submartingales,
supermartingales)
are
studied
for
Z+ = {0, 1, . . ., n, . . .}. Statements of Theorem 6.3 and Theorem 6.4 are transformed
by taking the limits as N →∞, and we get the following list of inequalities (6.14)-
(6.19):
P(ω : sup
n
Xn ≥λ) ≤supn EX+
n
λ
, λ > 0,
(6.14)
for a submartingale (Xn)n=0,1,... with supn EX+
n < ∞;
P(ω : sup
n
Xn ≥λ) ≤EX0 + supn EX−
n
λ
, λ > 0,
(6.15)

60
6
Discrete time stochastic analysis: basic results
for a supermartingale (Xn)n=0,1,... with supn EX−
n < ∞;
P(ω : sup
n
|Xn| ≥λ) ≤supn E|X|n
λ
, λ > 0,
(6.16)
for a martingale (Xn)n=0,1,...,N with supn E|X|n < ∞;
EβX
+ (∞, a, b) ≤supn E(Xn −a)+
b −a
,
(6.17)
for a submartingale (Xn)n=0,1,... with supn E(Xn −a)+ < ∞;
EβX
−(∞, a, b) ≤supn E(Xn −b)+
b −a
.
(6.18)
for a submartingale (Xn)n=0,1,... with supn E(Xn −b)+ < ∞;
EαX
+ (∞, a, b) ≤supn E(a −Xn)+
b −a
.
(6.19)
for a supermartingale (Xn)n=0,1,... with supn E(a −Xn)+ < ∞.
The Doob optional stopping (sampling) theorem admits a natural extension to Z+
too.
Theorem 6.5 Let (Xn)n=0,1,... be a uniformly integrable martingale (submartingale,
supermartingale) and τ be a ﬁnite stopping time. Then E|Xτ| < ∞and
EXτ = EX0 (EXτ ≥EX0, EXτ ≤EX0).
(6.20)
Moreover, for ﬁnite stopping times τ ≤σ (a.s.):
E(Xσ|Fτ) = Xτ (a.s.), (E(Xσ|Fτ) ≥Xτ (a.s.), E(Xσ|Fτ) ≤Xτ (a.s.)). (6.21)
Proof Both formulas (6.20) and (6.21) are proved with the help of limit arguments.
Let us only provide the proof of (6.20).
For a ﬁxed N denote τN = τ ∧N which is a bounded stopping time, and by
Theorem 6.2 we have
EX0 = EXτN .
(6.22)
Let us note from (6.22) that
EXτN = 2EX+
τN −EXτN ≤2EX+
τN −EX0.
(6.23)
Further, using (6.23) and a submartingale property of (X+
n )n=0,1,... we obtain that

6.3
Martingales on inﬁnite time interval
61
EX+
τN =
N

j=0
EX+
j I{τN =j } +
∫
{τ>N }
X+
N dP
≤
N

j=0
EX+
j I{τN =j } + EX+
N I{τ>N }
=EX+
N ≤E|XN | ≤sup
n
E|Xn|,
and, hence,
E|XτN | ≤3 sup
n
E|Xn| < ∞.
(6.24)
Using (6.24) and the Fatou lemma we get
E|Xτ| ≤lim sup
N
E|XτN | ≤4 sup
n
E|Xn| < ∞.
Let us note that for a ﬁnite stopping time τ we have
lim
n→∞E|Xn|I{τ>n} = 0,
(6.25)
because (Xn)n=0,1,... is uniformly integrable and P(ω : τ(ω) > n) →0, n →∞.
We can write a decomposition
Xτ = Xτ∧n + (Xτ −Xn)I{τ>n},
and its average
EXτ = EXτ∧n + EXτI{τ>n} −EXnI{τ>n},
(6.26)
In the equation (6.26) EXτ∧n = EX0, because (Xτ∧n) is a martingale.
The second term of (6.26)
E(Xτ)I{τ>n} =
∞

i=n+1
EXiI{τ=i} →0, n →∞,
because the series
EXτ =
∞

i=0
EXiI{τ=i} converges.
The third term of (6.26) converges to zero because (6.25).
□
Let us prove a key theorem of Doob about (a.s.)-convergence of submartingales.
Theorem 6.6 Let (Xn)n=0,1,... be a submartingale satisfying condition
sup
n
E|Xn| < ∞.
(6.27)
Then there exists an integrable random variable X∞= limn→∞Xn (a.s.).

62
6
Discrete time stochastic analysis: basic results
Proof Assume that this limit does not exist. It means that
P(ω : lim sup
n→∞
Xn(ω) > lim inf
n→∞Xn(ω)) > 0.
(6.28)
The set in (6.28) can be written
{ω : lim sup
n
Xn > lim inf
n
Xn} = ∪a<b,a,b∈Q{ω : lim sup
n
Xn > b > a > lim inf
n
Xn},
(6.29)
where Q ⊆R1 is the set of rational numbers.
It follows from (6.28)-(6.29) that for some rational numbers a < b we have
P(ω : lim sup
n
Xn > b > a > lim inf
n
Xn) > 0.
(6.30)
We also note that for each n ∈Z
EX+
n ≤E|Xn| = 2EX+
n −EXn ≤2EX+
n −EX0,
and ﬁnd that for submartingale (Xn)n∈Z the following conditions are equivalent:
sup
n
E|Xn| < ∞⇔sup
n
EX+
n < ∞.
(6.31)
Applying (6.17) together with (6.31) we obtain
EβX
+ (∞, a, b) ≤supn EX+
n + |a|
b −a
< ∞.
(6.32)
Condition (6.32) is a contradiction with the assumption (6.30) and (6.28). Hence,
there exists X∞= limn→∞Xn (a.s.) which is integrable by the Fatou lemma and
E|X∞| ≤supn E|Xn| < ∞.
□
Corollary 6.2 (a) If (Xn)n=0,1,... is a non-negative martingale, then supn E|Xn| =
supn EXn = EX0 < ∞and therefore there exists integrable X∞= limn→∞Xn (a.s.).
(b) If (Xn)n=0,1,... is a non-positive submartingale, then there exists integrable
X∞= limn→∞Xn (a.s.) and (Xn, Fn)n=0,1,...,∞is also submartingale, where F∞=
σ(∪∞
n=1Fn).
Proof Statement (a) is obvious. In case (b) one can apply the Fatou lemma and get
EX∞= E lim
n Xn ≥lim sup
n
EXn ≥EX0 > −∞.
The submartingale property follows from relations:
E(X∞|Fm) = E(lim
n Xn|Fm) ≥lim sup
n
E(Xn|Fm) ≥Xm (a.s.), m = 0, 1, . . . .
□
To study another type of convergence of martingales (submartingales, supermartin-
gales) which is L1-convergence we give the following example.

6.3
Martingales on inﬁnite time interval
63
Example 6.1 Let (Yn)n=0,1,... be a sequence of independent random variables such
that
Yn =

2
with probability 1/2,
0
with probability 1/2.
Deﬁne Xn = n
i=0 Yi and Fn = σ(Y0, . . .,Yn). It is clear that (Xn)n=0,1,... is a martin-
gale with EXn = 1, and hence, Xn →X∞= 0 (a.s.).
At the same time we have E|Xn −X∞| = EXn = 1 and therefore, this martingale
does not converge in space L1.
It means that the condition supn E|Xn| < ∞, appeared in Doob’s theorem about
(a.s.)-convergence, is not enough to achieve L1-convergence.
Theorem 6.7 If (Xn)n=0,1,... is a uniformly integrable submartingale, then there exi-
sts an integrable random variable X∞such that Xn −−−−→
n→∞X∞(a.s.) and in space L1.
Moreover, (Xn)n=0,1,...,∞will be a submartingale with respect to (Fn)n=0,1,...,∞,
where F∞= σ(∪∞
n=1Fn).
Proof Existence of X∞and convergence (a.s.) follows from Theorem 6.6. Further,
take c > 0 and represent
EXn = EXnI{Xn<−c} + EXnI{Xn ≥−c}.
(6.33)
For any ϵ > 0 due to uniform integrability (Xn) we can choose c > 0 large enough
to provide inequality
sup
n
|EXnI{Xn<−c}| < ϵ,
(6.34)
for the ﬁrst term in (6.33).
We also note that
XnI{Xn ≥−c} ≥Xn,
and by the Fatou lemma we obtain that
lim inf
n
EXnI{Xn ≥−c} ≥E lim inf
n
XnI{Xn ≥−c} ≥E lim inf
n
Xn.
Hence, due to (6.34) we get from the above inequalities
lim inf
n
EXn ≥E lim inf
n
Xn −ϵ.
We can prove in a similar way
lim sup
n
EXn ≤E lim sup
n
Xn,
and further just repeat the same steps of the proof of the Lebesgue dominated
convergence theorem and ﬁnd that E|Xn −X∞| →0, n →∞.
To ﬁnish the proof we take A ∈Fn, and for m ≥n we have
EIA|Xm −X∞| →0, m →∞,

64
6
Discrete time stochastic analysis: basic results
∫
A
XmdP →
∫
A
X∞dP, m →∞,
{
∫
A XmdP}m≥n is non-decreasing.
Hence, for any A ∈Fn we have
∫
A
XndP ≤
∫
A
XmdP ≤
∫
A
X∞dP =
∫
A
E(X∞|Fn)dP,
which certiﬁes a submartingale property.
□
Corollary 6.3 Let (Xn)n=0,1,... be a submartingale with supn E|Xn|p < ∞, p > 1.
Then there exists an integrable random variable X∞such that Xn →X∞, n →∞,
(a.s.) and in L1.
Theorem 6.8 (Levy’s theorem). Consider an integrable random variable X on
stochastic basis (Ω, F, (F )n=0,1,..., P). Then
E(X|Fn) −−−−→
n→∞E(X|F∞) (a.s.) and in L1.
Proof Denote Xn = E(X|Fn), n = 0, 1, . . . and ﬁnd for a > 0 and b > 0 that
∫
{|Xn |≥a
|Xn|dP ≤
∫
{|Xn |≥a
E(|Xn||Fn)dP =
∫
{|Xn |≥a}
|X|dP
=
∫
{|Xn |≥a}∩{|Xn |≤b}
|X|dP +
∫
{|Xn |≥a}∩{|Xn |>b}
|X|dP
≤bP(|Xn| ≥a) +
∫
{{|Xn |>b}
|X|dP
≤b
aE|X| +
∫
{{|Xn |>b}
|X|dP.
So, taking b →∞and after a →∞we get
lim
a→∞sup
n
E|Xn|I{|Xn |≥a} = 0,
which means that (Xn)n=0,1,... is uniformly integrable. Applying Theorem 6.7 we get
the statement of this theorem.
□
Corollary 6.4 A uniformly integrable stochastic sequence (Xn)n=0,1,... on stochastic
basis (Ω, F, (Fn)n=0,1,..., P) is a martingale ⇔there exists an integrable random
variable X such that Xn = E(X|Fn), n = 0, 1, . . ..
Proof The inverse implication ⇐is just the Levy theorem (Theorem 6.8). The direct
implication ⇒is just a consequence of Theorem 6.7 if we take X = X∞.
□
Problem 6.2 In Levy’s theorem prove that
X∞= E(X|F∞).

Chapter 7
Discrete time stochastic analysis: further
results and applications
Abstract In this chapter a characterization of sets of convergence of martingale is
given in predictable terms. As a consequence, the strong LNL for square-integrable
martingales is proved. This result is applied for derivation of strong consistency
of the least-squared estimates in the framework of regression model with martin-
gale errors. Moreover, the CLT for martingales is stated, and further this theorem
together with the martingale LNL is applied to derive the asymptotic normality
and strong consistency of martingale stochastic approximation procedures. A dis-
crete version of the Girsanov theorem is given here with its further application for
derivation of a discrete time Bachelier option pricing formula. In the last section,
the notion of a martingale is extended in several directions: from asymptotic mar-
tingales and local martingales to martingale transforms and generalized martingales
(see [4], [8], [12], [13], [15], [26], [30], [34], and [40]).
7.1
Limiting behavior of martingales with statistical
applications
Let us investigate limiting behavior of martingales. We start with some facts about
sets of convergence of martingales and submartingales.
Deﬁnition 7.1 Let (Xn)n=0,1,... be a stochastic sequence. Denote {ω : Xn →} the
set of those ω ∈Ω such that Xn(ω) converges to a ﬁnite limit as n →∞.
We also say that A ⊆B ∈F (a.s.), if P(A ∩Bc) = 0, and A = B (a.s.) if A ⊆B
(a.s.) and B ⊆A (a.s.).
Lemma 7.1 Let (Xn)n=0,1,... be a square integrable martingale. Then (a.s.)
{ω : ⟨X, X⟩∞< ∞} ⊆{ω : Xn →}
(7.1)
Proof For a positive a ∈R we deﬁne a stopping time
τa = inf{n : ⟨X, X⟩n+1 ≥a},
© The Author(s), under exclusive license to Springer Nature Switzerland AG 2023
A. Melnikov, A Course of Stochastic Analysis, CMS/CAIMS Books in Mathematics 6,
https://doi.org/10.1007/978-3-031-25326-3_7
65

66
7
Discrete time stochastic analysis: further results and applications
assuming that inf{∅} = ∞. One can observe that ⟨X, X⟩τa ≤a and the stopped
sequence (Xτa
n )n=0,1,... = (Xτa∧n)n=0,1,... is a square integrable martingale such that
E(Xτa∧n)2 = E(Xτa
n )2 = E⟨Xτn, Xτn⟩n = E⟨X, X⟩τa∧n ≤a.
According to Theorem 6.6, P{ω : Xτn
n
→} = 1. We also note that Xτn
n
= Xτa∧n = Xn
on the set {τa = ∞} = {ω : ⟨X, X⟩∞≤a}.
Further, (a.s.) {ω : τa = ∞} ⊆{ω : Xn →} and ∪a>0{τa = ∞} ⊆{ω : Xn →}.
Hence, (a.s.)
{ω : ⟨X, X⟩∞<∞}= ∪a>0 {ω : ⟨X, X⟩∞≤a} = ∪a>0{ω : τa = ∞} ⊆{ω : Xn →},
and we get (7.1).
□
Lemma 7.2 (Stochastic Kronecker’s lemma). Let (An)n=0,1,..., A0 > 0, be a pre-
dictable non-decreasing sequence, (Mn)n=0,1,... be a square integrable martingale
and
Nn =
n

i=0
A−1
i ΔMi.
Then (a.s.)
Ω′ = {ω : A∞= ∞} ∩{ω : Nn →} ⊆{ω : A−1
n Mn →}.
(7.2)
Proof First of all, we note the following formula of “summation by parts”:
AnXn = A0X0 +
n

i=1
AiΔXi +
n

i=1
Xi−1ΔAi,
(7.3)
for two stochastic sequences (An)n=0,1,... and (Xn)n=0,1,....
Applying the formula (7.3) to (An)n=0,1,... and (Nn)n=0,1,... we represent
n

i=1
AiΔNi = AnNn −
n

i=1
Ni−1ΔAi,
and using n
i=1 AiΔNi = Mn we obtain
A−1
n Mn = A−1
n
n

i=1
AiΔNi = A−1
n

AnNn −
n

i=1
Ni−1ΔAi

= A−1
n
n

i=1
(Nn −Ni−1)ΔAi.
(7.4)
Further, for ϵ > 0, deﬁne
nϵ =

sup{i : |N∞−Ni−1| ≤ϵ}
on the set {Nn →N∞},
0,
on Ω \ {Nn →N∞}.

7.1
Limiting behavior of martingales with statistical applications
67
By (7.4) on the set {ω : Nn →N∞} we have
|A−1
n Mn| =|A−1
n
n

i=1
(Nn −Ni−1)ΔAi|
≤A−1
n |
n

i=1
(Nn −Ni−1)ΔAi|
≤A−1
n
n∧nϵ

i=1
|Nn −Ni−1|ΔAi +
n

i=n∧nϵ
[|N∞−Nn| + |N∞−Ni−1|] ΔAi

≤A−1
n

const.Anϵ sup
i
|Ni| + const.An|N∞−Nn| + const.ϵ An

.
(7.5)
Hence, for almost all ω ∈Ω′ one can ﬁnd n′
ϵ(ω) such that in (7.5) for n ≥n′
ϵ(ω) :
|A−1
n Mn(ω)| ≤const.(ω) · ϵ, and therefore (7.2).
□
Theorem 7.1 (Strong LNL for martingales). Let (An)n=0,1,... be non-negative pre-
dictable non-decreasing sequence and (Mn)n=0,1,..., M0 = 0, be a square integrable
martingale such that (a.s.) A∞= ∞and (a.s.)
∞

n=1
Δ⟨M, M⟩n
A2n
< ∞.
(7.6)
Then A−1
n Mn →0 (a.s.), n →∞.
Proof Due to assumptions (7.6) and Lemma 7.1 we observe in Lemma 7.2 P(Ω′) = 1,
and, hence, we get the statement of the theorem.
□
Corollary 7.1 (Strong LNL of Kolmogorov). Let (Yn)n=1,2,... be a sequence of inde-
pendent random variables with EYn = 0 and σ2
n = EY2
n such that
∞

n=1
σ2
n
n2 < ∞.
(7.7)
Then for a sequence Xn = n
i=1 Yi the following strong large numbers law is true:
(a.s.) Xn
n →0, n →∞.
Proof We put An = n, Mn = Xn and ﬁnd that the Kolmogorov variance condition
(7.7) is transformed to the condition (7.6) of Theorem 7.1 and we get the claim.
□
Let us give an interesting and valuable application of strong LNL for martingales to
Regression Analysis.
Example 7.1 Suppose the observations are performed at times n = 0, 1, . . . and obey
the formula
xn = fnθ + en,
(7.8)

68
7
Discrete time stochastic analysis: further results and applications
where θ ∈R is an unknown parameter, (en)n=0,1,... is a martingale-diﬀerence and
( fn)n=0,1,... is a predictable regressor.
One can consider a structural least squares estimate (LS-estimate) in the frame-
work of regression model (7.8):
θn =
	 n

i=0
f 2
i

−1
n

i=0
fixi.
(7.9)
Denote Dn = E(e2
n|Fn−1) and Fn = n
i=0 f 2
i and assume that Fn →∞(a.s.), n →∞,
and ∞
i=0 F−2
i
Di < ∞(a.s.). Then according to Theorem 7.1 LS-estimate (7.9) is
strongly consistent in the sense that θn →θ (a.s.), n →∞.
Remark 7.1 If in the model (7.8) we take fn = xn−1, then we arrive to the ﬁrst
order autoregression model for which the condition ∞
1 x2
i−1 = ∞is well-known in
Regression Analysis as a standard guarantee for consistency of LS-estimates.
Below we give some additional facts about asymptotic behavior of martingales and
submartingales.
Deﬁnition 7.2 A stochastic sequence (Xn)n=0,1,... ∈C+, if for each τa = inf{n ≥
0 : Xn > a}, a > 0 :
E(ΔXτa)+I{ω:τa<∞} < ∞.
Problem 7.1 Prove that the condition C+ is true for any stochastic sequence with
E supn |ΔXn| < ∞.
Theorem 7.2 a) Assume a submartingale with its Doob decomposition Xn = X0 +
An + Mn, n = 0, 1, . . . belongs to a class C+, then (a.s.)
{Xn →} = {sup
n
Xn < ∞} ⊆{A∞< ∞}.
b) Assume a submartingale Xn = X0 + An + Mn, n = 0, 1, . . . is non-negative,
then (a.s.)
{A∞< ∞} ⊆{Xn →} ⊆{sup
n
Xn < ∞}.
c) If a non-negative submartingale belongs to C+, then (a.s.)
{A∞< ∞} = {Xn →} = {sup
n
Xn < ∞}.
d) Let (Yn)n=0,1,... be a non-negative stochastic sequence with the structure
Yn = Y0 + A′
n + Mn −A2
n, n = 0, 1, . . .,
where (A′
n)n=0,1,... and (A2
n)n=0,1,... are non-decreasing predictable sequences and
(Mn)n=0,1,... is a martingale. Then (a.s.)
{A′
∞< ∞} ⊆{Yn →} = {sup
n
A2
∞< ∞}.

7.1
Limiting behavior of martingales with statistical applications
69
Proof a) It is clear that (a.s.) {Xn →} ⊆{supn Xn < ∞}. To prove the inverse inclu-
sion, we have
sup
n
EX+
τa∧n ≤a + EX+
τa Iτa<∞≤2a + E(ΔXτa)+I{τa<∞} < ∞.
Hence, the stopped submartingale (Xτa
n )n=0,1,... = (Xτa∧n)n=0,1,... converges (a.s.) as
n →∞, and {τa = ∞} ⊆{Xn →} (a.s.).
Due to ∪a>0{τa = ∞} = {supn Xn < ∞} we get
{sup
n
Xn < ∞} = {Xn →} (a.s.).
b) Deﬁne σa = inf(n : An+1 > a), a > 0, and get
EXn∧σa = EAn∧σa ≤a.
Hence supn EXn∧σa ≤a < ∞, and due to positivity of (Xn)n=0,1,... we can apply the
Doob convergence theorem and ﬁnd that
{A∞≤a} ⊆{σa = ∞} = {Xn →} (a.s.)
and therefore,
{A∞< ∞} = ∪a>0{A∞≤a} ⊆{Xn →} (a.s.).
c) is a combination of (a) and (b).
d) Let us rewrite Yn = Xn −A2
n, n = 0, 1, . . . where Xn = X0 + A′
n + Mn.X0 = Y0,
is a non-negative submartingale due to 0 ≤Yn = Xn −A2
n, 0 ≤A2
n ≤Xn (a.s.), and
(a.s.) {A′
∞< ∞} ⊆{Xn →} ⊆{A2
∞< ∞} by (b). Hence, (a.s.) {A′
∞< ∞} ⊆{Yn →
} ∩{A2
∞< ∞}.
□
Corollary 7.2 Assume a martingale (Xn)n=0,1,... satisﬁes to the following condition
E supn |ΔXn| < ∞. Then (a.s.)
Ω = {Xn →} ∪{lim inf
n
Xn = −∞, lim sup
n
Xn = +∞}.
(7.10)
Proof We apply Theorem 7.2 to ±(Xn)n=0,1,... and get (a.s.)
{lim sup
n
Xn < ∞} = {sup
n
Xn < ∞} = {Xn →},
{lim inf
n
Xn > −∞} = {inf
n Xn > −∞} = {Xn →},
which leads to (7.10).
□
We already studied the Large Numbers Law for martingales and a very nice gen-
eralization of the corresponding results for sums of independent random variables
observed.
A natural question arises.

70
7
Discrete time stochastic analysis: further results and applications
Is it possible to get a similar version of the Central Limit Theorem (CLT) for
martingales?
The next theorem gives a positive answer to this question.
Theorem 7.3 Let(Xn)n=0,1,...beamartingale-diﬀerencesuchthat(a.s.)E(X2
n|Fn−1) =
1 and E(|Xn|3|Fn−1) ≤C < ∞. Then for a martingale Mn = n
i=1 Xi the CLT is true:
Yn = Mn
√n
d
−−−−→
n→∞Z ∼N(0, 1)
Proof Here, as in Chapter 4 for a random variable X we deﬁne its characteristic
function φX(t) = Eeitx, t ∈R, and denote
φn,j(t) = E

eit
Xj
√n |Fj−1

.
Let us write the Taylor decomposition
eit
Xj
√n = 1 + it Xj
√n −t2
2n X2
j −
it3
6n3/2 ¯X3
j ,
(7.11)
with a random reminder bounded as follows 0 ≤¯Xj ≤|Xj|.
Taking the conditional expectation in (7.11) and exploiting a martingale-
diﬀerence assumption we obtain the corresponding representation for φn,j(t) :
φn,j(t) = 1 + it E(Xj|Fj−1)
√n
−t2
2nE(X2
j |Fj−1) −
it3
6n3/2 E( ¯X3
j |Fj−1).
(7.12)
It follows from (7.12) that
φn,j(t) −1 −t2
2n =
t3
6n3/2 E( ¯X3
j |Fj−1).
Hence, for m ≤n we obtain from (7.10) that
Eeit Mm
√n = Eeit Mm−1
√n eit Xm
√n =E

eit Mm−1
√n E

eit Xm
√n |Fm−1

=Eeit Mm−1
√n φn,m(t)
=Eeit Mm−1
√n

1 −t2
2n −
it3
6n3/2 ¯X3
j

.
(7.13)
Let us rewrite (7.11) as follows
E

eit Mm
√n −(1 −t2
2neit Mm−1
√n

= Eeit Mm−1
√n
it3
6n3/2 ¯X3
j .
(7.14)
Using the boundedness of the third moment of (Xn)n=0,1,... we derive from (7.13)
that

7.1
Limiting behavior of martingales with statistical applications
71
E

eit Mm
√n −(1 −t2
2n)eit Mm−1
√n

≤E
eit Mm−1
√n

|t|3
6n3/2 E

|Xm|3|Fm−1

≤c |t|3
6n3/2 .
(7.15)
Let us ﬁx t ∈R and choose large enough n ≥t2
2 to provide the following inequality
0 ≤1 −t2/2n ≤1.
For such t and n we obtain from (7.13)-(7.15) that
(1 −t2
2n)n−mEeit Mm−1
√n
−(1 −t2
2n)n−m+1Eeit Mm−1
√n
 ≤c |t|3
6n3/2 .
(7.16)
Let us note that
Eeit Mm
√n −(1 −t2
2n)n =
n

m=1

(1 −t2
2n)n−mEeit Mm−1
√n
−(1 −t2
2n)n−m+1Eeit Mm−1
√n

.
(7.17)
Relations (7.16)-(7.17) for n ≥t2/2 lead to the following inequality
Eeit Mm
√n −(1 −t2
2n)n
 ≤nC |t|3
6n3/2 = C |t|3
6√n.
(7.18)
Due to the right hand side of (7.18) tends to zero, now one can conclude that
lim
n→∞Eeit Mm
√n = e−t2/2,
(7.19)
where we used the well-known fact that
lim
n→∞

1 −t2
2n
n
= e−t2/2.
Relation (7.19) shows that characteristic functions ofYn converge to the characteristic
function of N(0, 1). Hence, Yn
d
−−−−→
n→∞Z ∼N(0, 1).
□
Another area of applications of a martingale LNL and a martingale CLT is
stochastic approximation algorithms. The classical theory of stochastic approxima-
tion is concerned with the problem to construct a stochastic sequence (θn)n=0,1,... that
converges in some probabilistic sense to a unique root θ of the regression equation
R(θ) = 0, θ ∈R,
(7.20)
where R is a regression function.
An approximate solution of (7.20) is given by the Robbins-Monro procedure
θn = θn−1 −γnyn,
(7.21)

72
7
Discrete time stochastic analysis: further results and applications
with the sequence (yn) satisfying to equation
yn = R(θn−1) + en,
(7.22)
where (en)n=0,1,... are errors of observations usually modeled by a sequence of
independent random variables with mean zero and bounded variance, (γn)n=0,1,... is
a sequence of positive real numbers converging to 0.
The convergence of the procedure (7.21)-(7.22) for a continuous linearly bounded
regression function R(x) with R(x)(x −θ) > 0 for all x ∈R is guaranteed by the
following classical conditions:
∞

1
γk = ∞,
(7.23)
∞

1
γ2
k < ∞.
(7.24)
Let us demonstrate how the martingale technique and convergence work here and
how classical stochastic approximation results are extended to models (7.21)-(7.22)
with martingale errors (en)n=0,1,... and predictable sequences (γn)n=0,1,....
Example 7.2 We consider for simplicity the case of linear function R(x) = β(x −
θ), β > 0, assuming in (7.22) that (en)n=0,1,... is a martingale-diﬀerence with Een = 0
and E(e2
n|Fn−1) ≤ξ < ∞(a.s.). Regarding (γn) we assume that (γn) is predictable,
0 < γn ≤β−1 (a.s.) and conditions (7.23)-(7.24) are fulﬁlled almost surely. One can
rewrite the algorithm (7.21)-(7.22) as follows (θ = 0 for simplicity)
Δθn = −γnβθn−1 −γnen.
(7.25)
Moreover, (7.25) can be rewritten in the form of an inhomogeneous linear stochastic
diﬀerential equation (6.9) with Xn = θn, ΔNn = −γnen, ΔUn = −βγn, and En(−βγ)
is a stochastic exponential of sequence (Un).
In these denotations the solution of (7.25) is expressed as follows
θn = Xn =En(U)X0 + En(U)
n

1
E−1
i (U)ΔNi
=En(−βγ)θ0 + En(−βγ)
n

1
E−1
i (−βγ)γiei.
(7.26)
According to the assumption γn < β−1 (a.s.) the stochastic exponential En(−βγ) =
n
1(1 −βγi) is positive (a.s.) if (7.23) is fulﬁlled (a.s.).
Further, the ﬁrst term of the right hand side of (7.26) tends to zero (a.s.), n →∞,
because En(−βγ) →0 (a.s.), n →∞.
The structure of the second term of the right hand side of (7.26) is exactly
(see Theorem 7.1) as in the strong LNL for martingales with A−1
n = En(−βγ) and
Mn = n
1 E−1
i (−βγ)γiei.

7.1
Limiting behavior of martingales with statistical applications
73
So, we have to check the condition (7.6) in this case:
∞

1
A−2
n Δ⟨M, M⟩n =
n

1
E2
n(−βγ)E−2
n (−βγ)γ2
nE(e2
n|Fn−1) ≤ξ
∞

1
γ2
n < ∞(a.s.)
Applying Theorem 7.1 we get the convergence θn →θ (a.s.), n →∞.
Let us show how the martingale CLT (see Theorem 7.3) works to study asymptotic
normality properties of algorithms (7.21)-(7.22). Under some reasonable simpliﬁ-
cations, we will show it to avoid technical diﬃculties.
Example 7.3 We consider the linear model (7.21)-(7.22) assuming γn = α
n, α >
0, en ∼N(0, σ2) and independent, and n must be greater than αβ to provide a
positivity of En(−βγ).
Problem 7.2 Prove that under the assumptions above
En(−βγ) ≡En(−βα) ∼n−βα, n →∞.
(7.27)
To derive an asymptotic normality of the procedure (θn) we multiply (7.26) by n1/2
and obtain
√nθn = √nEn(−βα)θ0 −√nEn(−βα)
n

1
α
k E−1
k (−βα)ek.
(7.28)
It follows from (7.27) that √nEn(−βα) ∼n1/2−βα, and, hence, under additional
assumption 2βα > 1 we ﬁnd the ﬁrst term of the right side of (7.28) tends to zero
(a.s.), n →∞. The second term of (7.28) has a normal distribution. Therefore, we
need to calculate its limiting variance.
As n →∞we have
nE2
n(−βα)
n

1
E−2
k (−βα)α2σ2
k2
→
α2σ2
(2βα −1).
(7.29)
Thus we obtain from (7.29) that
√nθn
d
−−−−→
n→∞N

0,
α2σ2
2βα −1

.
Remark 7.2 One can develop this approach to a non-linear regression functions
R(x) = β(x −θ) + U(x), where U(x) = O((x −θ)2), and prove both strong consis-
tency and asymptotic normality of stochastic approximation procedures (7.21)-
(7.22). We note also that Lemma 7.2 works for such extension.

74
7
Discrete time stochastic analysis: further results and applications
7.2
Martingales and absolute continuity of measures.
Discrete time Girsanov theorem and its ﬁnancial
application
We start this section with a martingale characterization of absolute continuity
of a probability measure ˜P with respect to measure P on given stochastic basis
(Ω, F, (Fn)n=0,1,..., P). It was already shown in Section 6.1 that under assumption
of “local absolute continuity” ˜P ≪loc P the corresponding local density Zn = d ˜Pn
dPn
is a martingale w.r. to P. The next theorem states conditions under which a “local
absolute continuity” is transformed to “absolute continuity” of ˜P w.r. to P.
Theorem 7.4 Assume that ˜P ≪loc P and (Zn)n=0,1,..., Z0 = 1, is a local density
d ˜Pn
dPn . Then the following statements are equivalent:
1) ˜P ≪P,
2) (Zn)n=0,1,... is uniformly integrable,
3) ˜P(ω : supn Zn < ∞) = 1.
Proof (1) ⇒(3): According to Theorem 6.6 there exists Z∞= limn→∞Zn P-a.s.
Due to ˜P ≪P such a limit does exist ˜P-a.s.. Hence, ˜P(ω : supn Zn < ∞) = 1.
(3) ⇒(2): For a constant c > 0 we have
EZnI{ω:Zn>c} = ˜P(ω : Zn > c) ≤˜P(ω : sup
i
Zi > c) →0, c →∞.
(2) ⇒(1): Due to the uniform integrability of (Zn)n=0,1,... we can apply Theorem
6.7 and ﬁnd the existence Z∞= limn→∞Zn P-a.s., and E|Zn −Z∞| →0, n →∞.
Further, for any A ∈Fm and for n ≥m, we can write a martingale property of
(Zn)n=0,1,... as follows
˜P(A) = EIAZm = EIAZn.
(7.30)
It follows from L1-convergence that one can take a limit as n →∞in the equality
(7.30) and obtain
˜P(A) = EIAZ∞,
i.e. Z∞= d ˜P
dP .
□
Now we show a method of construction of probability measure ˜P and its (local)
density w.r. to P. Aiming it we formulate one of the simplest versions of the Girsanov
theorem.
Suppose (ϵn)n=0,1,... is a sequence of independent random variables ϵn ∼N(0, 1).
Deﬁne F0 = {∅, Ω},
Fn = σ(ϵ1, . . ., ϵn},
n = 1, 2, . . ., a bounded predictable
sequence (αn)n=0,1,... and Z0 = 1,
Zn = exp

−
n

1
αkϵk −1
2
n

1
α2
k

, n = 1, 2, . . .
(7.31)
Problem 7.3 Prove that (Zn)n=0,1,... is a martingle with EZn = 1.

7.2
Martingales and absolute continuity of measures. Discrete time . . .
75
Theorem 7.5 Deﬁne a new probability measure ˜PN(A) = EIAZN, A ∈FN. Then
˜ϵn = αn + ϵn, n = 1, . . ., N, is a sequence of independent standard normal random
variables w.r. to ˜PN.
Proof For real numbers (λn)n=1,...,N we have using the rule of changing of measures,
properties of conditional expectations and the form of characteristic function for
standard normal random variables:
˜ENei N
1 λn ˜ϵn =EZNei N
1 λn ˜ϵn
=E

ei N−1
1
λn ˜ϵn ZN−1E

eiλN (αN +ϵN )+αN ϵN −α2
N /2|FN−1

=E

ei N−1
1
λn ˜ϵn ZN−1

e−λ2
N /2 = . . . = e−1/2 N
1 λ2
n.
It means that characteristic function of N
1 λn ˜ϵn is a product of characteristic func-
tions of standard normal random variables and we get the statement of the theorem.
□
Remark 7.3 One can extend Theorem 7.5 to inﬁnite the time interval. According to
Theorem 7.4 we need provide a condition to guarantee that (Zn)n=0,1,... is uniformly
integrable. Usually, it is achieved with the help of the Novikov type condition
E exp(1/2 ∞
1 α2
n) < ∞.
Let us give an example of application of this theorem to Mathematical Finance.
Example 7.4 We assume that ﬁnancial market consists of two assets (Bn)n=0,1,...,N
and (Sn)n=0,1,...,N (bank account and stock prices relatively). We put for simplicity
that Bn ≡1 (interest rate is zero) and
ΔSn = Sn −Sn−1 = αn + ϵn, S0 > 0, n = 1, . . ., N.
(7.32)
We consider a standard ﬁnancial contract “call option” with a strike K. The holder
of the contract has the right to buy a stock share by the price K at the maturity date
N. In terms of having the right - he /she must pay a premium CN at time 0. The basic
problem here is to determine CN.
The market (7.32) can be considered as the discrete time Bachelier model with
unit volatility. It is well-established that the premium must be calculated to avoid
arbitrage. According to this ﬁnancial no-arbitrage principle CN is determined as
expected value of pay-oﬀ(SN −K)+ w.r. to a risk-neutral measure ˜PN given in the
Girsanov theorem.
To provide concrete calculations we formulate an auxiliary fact for a Normal
distribution as a problem.
Problem 7.4 Prove that
E(a + bϵ)+ = aΦ(a/b) −bφ(a/b),
(7.33)
where ϵ ∼N(0, 1), a ∈R, b > 0, φ = φ(x) is a standard normal density and Φ(x) =
∫x
−∞φ(y)dy.

76
7
Discrete time stochastic analysis: further results and applications
To calculate CN we apply (7.33) and obtain the following discrete time formula
of Bachelier
CN = ˜EN(SN −K)+ = ˜EN
	
S0 +
N

1
αi +
n

1
ϵi −K

+
=E
	
S0 −K +
N

1
ϵi

+
= E(S0 −K +
√
Nϵ)+
=(S0 −K)Φ
 S0 −K
√
N

+
√
Nφ
 S0 −K
√
N

.
7.3
Asymptotic martingales and other extensions of
martingales
We start with an idea to avoid conditional expected values to extend the notion of
martingale. Let us assume that (Ω, F, (Fn)n=0,1,..., P) be a stochastic basis on which
all stochastic sequences are considered. Denote Tb the set of all bounded stopping
times on this stochastic basis. We deﬁned before that two stopping times τ ≤σ if
τ(ω) ≤σ(ω) (a.s.). With this deﬁnition the set Tb is a directed set ﬁltering to the
right.
Deﬁnition 7.3 A stochastic sequence of integrable random variables (Xn)n=0,1,... is
called an asymptotic martingale (amart), if the family (net) (EXτ)τ∈Tb converges.
Remark 7.4 It follows from the deﬁnition of amart (Xn)n=0,1,... that the set (EXτ)τ∈Tb
is bounded. It is also clear that a linear combinations of amarts is an amart.
According to this deﬁnitions and Theorem 6.6 and Theorem 6.7, we can conclude
that martingales belong to the class of asymptotic martingales. In this case a natural
question arises:
“What elements of previously developed martingale theory can be extended to a
wider class of asymptotic martingales?”
If another ﬁltration (Gn)n=0,1,... is included to ﬁltration (Fn)n=0,1,... i.e. Gn ⊆Fn, n =
0, 1, . . ., then each stopping time w.r. to (Gn) will be a stopping time w.r. to (Fn).
Therefore, every amart (Xn)n=0,1,... w.r. to (Fn) will be amart w.r. to (Gn) if it is
adapted to (Gn). Moreover, from every (Fn)-amart (Xn) one can construct a (Gn)-
amart (Yn) if we put Yn = E(Xn|Gn), n = 0, 1, . . . because of EXτ = EYτ for all
τ ∈Tb.
Further, we have seen the role of “maximal inequalities” in martingale theory. It
turns out, such inequality can be stated in more general setting.
Lemma 7.3 Assume that a stochastic sequence (Xn)n=0,1,... such that supτ∈Tb
E|Xτ| < ∞. Then for λ > 0 :
P

sup
n
|Xn| > λ

≤λ−1 sup
τ∈Tb
E|Xτ|.
(7.34)

7.3
Asymptotic martingales and other extensions of martingales
77
Proof For a ﬁxed number N we deﬁne the set A = {ω : sup0≤n≤N |Xn| > λ} and a
bounded stopping time
σ(ω) =

inf(n ≤N : |Xn(ω)| > λ)
i f ω ∈A,
N
i f ω  A.
Then
sup
τ∈Tb
E|Xτ| ≥E|Xσ| ≥λP(A).
(7.35)
Taking the limit in (7.35) as N →∞we get (7.34).
□
Lemma 7.4 If (Xn)n=0,1,... and (Yn)n=0,1,... are L1-bounded amarts, then (max
(Xn,Yn))n=0,1,... and (min(Xn,Yn))n=0,1,... are amarts.
Proof We consider only the case of Zn = max(Xn,Yn) due to a symmetry. First of
all, we prove that the net (EZτ)τ∈Tb is bounded. To do it take an arbitrary τ ∈Tb and
choose n ≥τ. Deﬁne
τX =

τ,
i f Xτ ≥0,
n,
i f Xτ < 0.
τY =

τ,
i f Yτ ≥0,
n,
i f Yτ < 0.
and ﬁnd that
EZτ ≤EXτI{Xτ ≥0} + EYτI{Yτ ≥0}
=EXτX −EXnI{Xτ <0} + EYτY −EYnI{Yτ <0}
≤sup
σ∈Tb
EXσ + sup
m
E|Xm| + sup
σ∈Tb
EYσ + sup
m
E|Ym|,
and we arrive to the conclusion.
Let us prove now that (Zn)n=0,1,... is an amart. For ϵ > 0 we can choose τ0 ∈Tb
such that
|EXσ −EXτ| < ϵ, |EYσ −EYτ| < ϵ
(7.36)
for σ, τ ≥τ0. Further, due to the boundedness of (EZτ)τ∈Tb one can choose τ1 ≥τ0
such that if σ ≥τ0, then
EZσ ≤EZτ1 + ϵ.
(7.37)
For a bounded stopping time σ ≥τ1 we deﬁne A = {Xτ1 < Yτ1} and σ1 ∈Tb as
follows
σ1 =

τ1
on A,
σ
on Ac.
Then we obtain

78
7
Discrete time stochastic analysis: further results and applications
EXτ1 =EZτ1IAc + EXτ1IA,
(7.38)
EXσ1 =EXσIAc + EXτ1IA.
(7.39)
Subtracting (7.38) from (7.37) we get with the help of (7.35) that
EZτ1IAc = EXσIAc + EXτ1 −EXσ1 ≤EZσIAc + ϵ.
(7.40)
We can write the same relations as (7.38) and (7.39) for (Yn) :
EYτ1 =EZτ1IAc + EYτ1IA,
EYσ1 =EYσIAc + EYτ1IA.
and ﬁnd
EZτ1IA = EYσIA + EYτ1 −EYσ1 ≤EZσIA + ϵ.
(7.41)
Combining (7.40) and (7.41), we obtain inequality
EZτ1 ≤EZσ + 2ϵ
which leads together with (7.36) that
|EZσ −EZτ1| ≤2ϵ,
and, hence, the net (EZτ)τ∈Tb is the Cauchy net.
□
Applying Lemma 7.3 and Lemma 7.4 we arrive to the following theorem.
Theorem 7.6 Let (Xn)n=0,1,... be amart with supn E|Xn| < ∞. Then
1) its positive (negative) parts X+
n (X−
n ) and its absolute value |Xn| are
L1−bounded amarts,
2) for each λ ≥0 the sequence
Xλ
n = sign(Xn)λI|Xn |>λ + XnI|Xn |≤λ,
3) supτ∈Tb E|Xτ| < ∞and supn |Xn| < ∞(a.s.).
The next statement can be considered as a version of the optional sampling
theorem.
Theorem 7.7 Let (Xn)n=0,1,... be an amart for (Fn)n=0,1,... and let (τm)m=0,1,...
be a non-decreasing sequence of bounded stopping times for (Fn)n=0,1,.... Then
(Xτm)m=0,1,... is an amart for (Fτm)m=0,1,....
Proof For ﬁxed ϵ > 0 we can choose N such that |EXτ −EXτ′| < ϵ for all bounded
stopping times τ and τ′ ≥N. Denote τ∞= limm→∞τm (a.s.) and ﬁnd that Xτm∧N →
Xτ∞∧N (a.s.), m →∞, and
E sup
m
|Xτm∧N | ≤E max(|X1, |, . . ., |XN |) < ∞.

7.3
Asymptotic martingales and other extensions of martingales
79
Therefore, by the dominated convergence theorem the sequence (Xτm∧N)m=0,1,... is
an amart. Taking a big enough M so that |EXτσ∧N −EXτσ′∧N | for all bounded
stopping times σ and σ′ ≥M for (Fτm)m=0,1,... we have
|EXτσ −EXτσ′ | ≤|EXτσ∨N −EXτσ′∨N | + |EXτσ∧N −EXτσ′∧N | ≤ϵ + ϵ = 2ϵ.
□
Example 7.5 An integrable stochastic sequence (Xn)n=0,1,... is called a quasimartin-
gale if
∞

n=0
E|Xn −E(Xn+1|Fn)| < ∞.
(7.42)
Condition (7.42) is trivial in case of a martingale. In view (7.42) for given ϵ > 0 one
can ﬁnd a big enough N such that
∞

n=N
E|Xn −E(Xn+1|Fn)| ≤ϵ.
(7.43)
Take τ ∈Tb such that N ≤τ ≤M we have
|EXτ −EXM | =

M

m=N
E(Xm −XM)I{τ=m}

=

M

m=N
M−1

n=m
E(Xn −Xn+1)I{τ=m}

=
M−1

n=N
n

m=N
E |Xn −E(Xn+1|Fn))| I{τ=m}

≤
∞

n=N
E|Xn −E(Xn+1|Fn)| ≤ϵ.
If τ1, τ2 ≥N, then choose M ≥τ1 ∨τ2 and get
|EXτ1 −EXτ2| ≤|EXτ1 −EXM | + |EXτ2 −EXM | ≤2ϵ.
Hence, the net (EXτ)τ∈Tb is Cauchy and converges.
So, any quasimartingale is an amart.
The deﬁnition of amarts is certainly directed to provide their asymptotic behavior
similar to martingales. Below we conﬁrm these expectations.
Lemma 7.5 Let (Xn)n=0,1,... be a stochastic L1-bounded sequence. Then the follow-
ing are equivalent:
(1) (Xn)n=0,1,... converges (a.s.),
(2) (Xn)n=0,1,... is an amart.

80
7
Discrete time stochastic analysis: further results and applications
Proof the implication (1) ⇒(2) follows from the dominated convergence theorem.
To prove that (2) ⇒(1) we put X∗= lim sup Xn and X∗= lim infn Xn. Then we
can ﬁnd sequences τn, σn ∈Tb with τn ↑∞, σn ↑∞such that Xτn →X∗(a.s.) and
Xσn →X∗(a.s.). Applying again the dominated convergence theorem, we obtain
that
E(X∗−X∗) = lim
n E(Xτn −Xσn) = 0.
It means X∗= X∗(a.s.).
□
Theorem 7.8 Let (Xn)n=0,1,... be an amart with supn E|Xn| < ∞. Then (Xn)n=0,1,...
converges (a.s.).
Proof By Theorem 7.6, supn |Xn| < ∞(a.s.) and therefore P{ω : supn |Xn| > λ} is
arbitrary small if λ is big enough. By Theorem 7.7, Xλ
n is an amart, and by Lemma
7.5, it converges (a.s.). Taking λ ↑∞we get (a.s.)-convergence of (Xn).
□
In the end of this Section we would like to mention some other extensions of the
notion of martingales.
Deﬁnition 7.4 A stochastic sequence (Xn)n=0,1,..., X0 = 0, is a local martingale if
there exists a sequence of stopping times (τm)m=1,2,... increasing to +∞such that
(Xτm∧n)n=0,1,... is a martingale for each m = 1, 2, . . . . The sequence (τm) is called a
localizing sequence.
Deﬁnition 7.5 A stochastic sequence (Xn)n=0,1,..., X0 = 0, is a generalized martin-
gale if (a.s.)
{ω : E(X+
n |Fn−1) < ∞} ∪{ω : E(X−
n |Fn−1) < ∞} = Ω,
and for n = 1, 2, . . .
E(Xn|Fn−1) = Xn−1
(a.s.)
Deﬁnition 7.6 A stochastic sequence (Xn)n=0,1,..., X0 = 0, is a martingale transform
(stochastic integral) if it admits the following representation
Xn =
n

m=0
HmΔMm,
where (Mn)n=0,1,..., M0 = 0, is a martingale, (Hn)n=0,1,... is predictable, H0 = ΔM0 =
M0 = 0.
All these generalizations are directed to relax the condition of integrability of
stochastic sequences. All these classes of stochastic sequences are coincide. We omit
the proof of this statement here.

Chapter 8
Elements of classical theory of stochastic
processes
Abstract This chapter contains a general notion of random processes with continu-
ous time. It is given in context of the Kolmogorov consistency theorem. The notion of
a Wiener process with variety of its properties are also presented here. Its existence
is stated by two ways: with the help of the Kolmogorov theorem as well as with the
help of orthogonal functional systems. Besides the Wiener process as a basic process
for many others, the Poisson process is also considered here. Stochastic integration
with respect to Wiener process is developed for a class of progressively measurable
functions. It leads to the Ito processes, the Ito formula, the Girsanov theorem and
representation of martingales (see [5], [6], [14], [17], [21], [35], [41], and [44]).
8.1
Stochastic processes: deﬁnitions, properties and
classical examples
In classical theory the notion of a stochastic process is associated with a family
of random variables (Xt) on a probability space (Ω, F, P) with values in space
Rd, d ≥1, where parameter t ∈[0, ∞) = R+. Usually for simplicity we put d = 1. It
is supposed that for time parameter t ∈R+ we have a random variable Xt(ω), ω ∈
Ω. On the other hand, one can ﬁx ω ∈Ω and get a function X.(ω) : R+ →Rd,
which is called a trajectory. This point of view opens up the possibility of studying
stochastic processes that have been exhaustively determined by their distributions
as probability measures on the functional space (R[0,∞), B[0,∞)). Usually a family
of ﬁnite dimensional distributions Pt1,...,tn(B1, . . ., Bn), 0 ≤t < t1 < t2 < . . . < tn <
∞, Bi ∈B(Rd), i = 1, . . ., n, is exploited as the basic probabilistic characteristic of
a stochastic process. A natural question arises in this regard. Is there a stochastic
process (Xt(ω)) such that P(Xt1 ∈B1, . . ., Xtn ∈Bn) = Pt1,...,tn(B1, . . ., Bn). As it
was noted in Chapter 1, this question is solved with the help of the Kolmogorov
theorem if for the system (Pt1,...,tn) the following consistency conditions are fulﬁlled:
1. Pt1,...,tn(B1, . . ., Bi−1, ·, Bi+1, . . ., Bn), i = 1, 2, . . ., n, is a probability measure
on (Rd, B(Rd);
© The Author(s), under exclusive license to Springer Nature Switzerland AG 2023
A. Melnikov, A Course of Stochastic Analysis, CMS/CAIMS Books in Mathematics 6,
https://doi.org/10.1007/978-3-031-25326-3_8
81

82
8
Elements of classical theory of stochastic processes
2. Pt1,...,tn(B1, . . ., Bn) = Pti1,...,tin (Bi1, . . ., Bin), where (i1, . . ., in) is arbitrary
permutation of numbers (1, 2, . . ., n);
3. Pt1,...,tn−1,tn(B1, . . ., Bn−1, Rd) = Pt1,...,tn−1(B1, . . ., Bn−1). In such a case there
exists a probability measure PX in the functional space (R[0,∞), B[0,∞)) and the
process (Xt(ω)) is constructed as Xt(ω) = ωt, where ωt is the value of function
ω. ∈R[0,∞) at time t. Measure PX will be a distribution of (Xt(ω)) which has Pt1,...,tn
as a system of ﬁnite dimensional distributions of this process.
After these necessry explanations we introduce the notion of a Wiener process or
Brownian motion.
Deﬁnition 8.1 A stochastic process (Wt)t ≥0 such that
1) W0 = 0 (a.s.),
2) W.(ω) ∈C[0, ∞) for almost all ω ∈Ω,
3)
P(Wt1 ∈B1, . . ., Wtn ∈Bn) =
∫
B1 . . .
∫
Bn p(t, 0, x1)p(t2 −t1, x1, x2) . . . p(tn−
tn−1, xn−1, xn)dx1 . . . dxn,
for
arbitrary
0 < t1 < t2 < . . . tn,
B1, . . ., Bn ∈B(R),
where
p(t, x, y) =
1
√
2πt exp

−(x−y)2
2t

is called a Wiener process.
It follows directly from the deﬁnition that Wt ∼N(0, t) for every ﬁxed t ∈R+.
Let us formulate the ﬁrst properties of the process (Wt)t ≥0 :
(1) EWtWs = s ∧t for arbitrary s, t ∈R+;
(2) E(Wt −Ws)2 = |t −s|;
(3) E(Wt −Ws)4 = 3(t −s)2.
We only prove (2), leaving (1) and (3) as problems.
Problem 8.1 Prove properties (1) and (3) of (Wt)t ≥0.
Assume that s < t and ﬁnd that
EWsWt =
∫∞
−∞
∫∞
−∞
xyp(s, 0, x)p(t −s, x, y)dxdy
=
∫∞
−∞
xp(s, 0, x)
∫∞
−∞
yp(t −s, x, y)dy

dx
=
∫∞
−∞
xp(s, 0, x)
∫∞
−∞
(x + u)p(t −s, x, x + u)du

dx
=
∫∞
−∞
xp(s, 0, x)
∫∞
−∞
(x + u)p(t −s, 0, u)du

dx
=
∫∞
−∞
xp(s, 0, x)

x
∫∞
−∞
p(t −s, 0, u)du + u
∫∞
−∞
p(t −s, 0, u)du

dx
=
∫∞
−∞
xp(s, 0, x) (x + 0) dx
=
∫∞
−∞
x2p(s, 0, x)dx = s.
Now we calculate for s < t and B ∈B(R)

8.1
Stochastic processes: deﬁnitions, properties and classical examples
83
P(Wt −Ws ∈B) =
∫
{(x,y):y−x∈B}
p(s, 0, x)p(t −s, x, y)dxdy
=
∫∞
−∞
p(s, 0, x)
∫
{y:y−x∈B}
p(t −s, x, y)dy

dx
=
∫∞
−∞
p(s, 0, x)
∫
B
p(t −s, x, x + u)du

dx
=
∫∞
−∞
p(s, 0, x)
∫
B
p(t −s, 0, u)du

dx
=
∫∞
−∞
p(s, 0, x)dx
∫
B
p(t −s, 0, u)du =
∫
B
p(t −s, 0, u)du
and we obtain that Wt −Ws ∼N(0, t −s).
As a result, we arrive to the fourth property of Wt :
(4) For 0 =t 0 < t1 < . . . < tn the increments Wt1 −Wt0, . . ., Wtn −Wtn−1 of a
Wiener process are independent random variables.
Proof Due to a “normality” of increments we need to prove that they are uncorre-
lated. Let us take r < s < t < u and ﬁnd that
E(Wu −Wt) = EWuWs −EWtWs −EWuWr + EWtWr = s −s −r + r = 0.
□
To go further, we introduce ﬁltration, generated by a Wiener process Ft =
σ(Ws, s ≤t). We assume that Ft is complete, i.e. it contains all sets of P−measure
zero.
Deﬁnition 8.2 A process (Mt)t ≥0 satisfying conditions
1) Mt −Ft-measurable,
2) Mt is integrable,
3) E(Mt|Fs) = Ms (a.s.) for all s < t,
is called a martingale.
After this deﬁnition we formulate the martingale property of a Wiener process. If
in (3) the equality is replaced by the inequality ≥(≤), then (Mt) is a submartingale
(supermartingale).
(5) Processes (Wt)t ≥0 and (W2
t −t)t ≥0 are martingales w.r.to (F )t ≥0.
Remark 8.1 In fact, the inverse statement to (5) is well-known as Levy’s character-
ization of a Wiener process.
(6) The Doob maximal inequality for a Wiener process (Wt)t ≥0 has the following
form: for t > 0,
E max
s≤t |Ws|2 ≤4E|Wt|2.
(8.1)
To prove it we consider a subdivision of the interval [0, t] as of the interval [0, t] as
t(n)
k
= kt
2n, 0 ≤k ≤2n, and deﬁne a square integrable martingale with discrete time

84
8
Elements of classical theory of stochastic processes
Mk = Mn
k = W kt
2n , F n
k = F kt
2n , 0 ≤k ≤2n.
For (|Mk|) we have, using its submartingale property that
E(max
k
|Mk|)2 =2
∫∞
0
yP(max
k
|Mk| > y)dy
≤2
∫∞
0
E|M2n |I(maxk |Mk |≥y)dy
=2
∫∞
0
∫
(maxk |Mk |≥y)
|M2n |dP

dy
=2
∫
Ω
|Mk
2n
∫maxk |Mk |
0
dy

dP
=2
∫
Ω
|M2n | max
k
|Mk|dP = 2E|M2n | max
k
|Mk|
≤2(E(M2n)2)1/2

E(max
k
|Mk|)2
1/2
.
As a result, we obtain that
(E(max
k
|Mk|)2)1/2 ≤2(E(M2n)2)1/2,
and, hence,
E max
k
|Mn
k |2 ≤E(max
k
|Mn
k |)2 ≤4E(M2n)2 = 4E|Wt|2.
(8.2)
Taking the limit as n →∞in (8.2) and using the continuity of trajectories of a
Wiener process we arrive to inequality (8.1).
(7) For any positive constant c the process Wc
t = c−1Wc2t is a Wiener process.
This property of a Wiener process is called self-similarity.
To prove the self-similarity of a Wiener process one can use the Levy characteri-
zation of this process.
(8) Existence of a Wiener process follows from the consistency theorem of Kol-
mogorov (see Chapter 1). However, such a reference is incomplete because this
theorem guarantees existence of this process only in space (R[0,∞), B[0,∞)). To make
the proof complete one can use another theorem of Kolmogorov:
Suppose (Xt)t ≥0 is a stochastic process satisfying the following condition
E|Xt −Xs|α ≤C|t −s|1+β for all t, s ≥0,
and for some α > 0, β > 0, 0 < C < ∞. Then the process (Xt) admits a continuous
modiﬁcation i.e. there exists a continuous process (Yt) such that P(Xt = Yt) = 1 for
all t ∈R+.
Property (3) of a Wiener process (Wt) means that this theorem can be applied,
and therefore, the process (Wt) can be identiﬁed with its continuous modiﬁcation.

8.1
Stochastic processes: deﬁnitions, properties and classical examples
85
(9) Now we give some other characterizations of trajectories of (Wt)t ≥0. The con-
tinuity property brings an element of a regularity of trajectories. But this description
of sample paths properties is clearly incomplete as it is shown below.
Let us analyze the ﬁrst question of diﬀerentiability of trajectories of (Wt)t ≥0. We
take t ≥0 and consider the ratio RW
Δ (t) = Wt+Δt−Wt
Δt
, where Δt →0. One can easily
observe that
ERW
Δ (T) = EWt+Δt −EWt
Δt
= 0,
and
VarRW
Δ (t) = (Δt)−2Var(Wt+Δt −Wt) = (Δt)−2Δt = (Δt)−1 →∞as Δt →0.
It shows that W. is not diﬀerentiable in the L2−sense. Moreover, one can prove
that almost all trajectories of W are non-diﬀerentiable.
Let us analyze the second question of how vary the trajectories of (Wt)t ≥0 are.
This property is characterized with the help of the notion of p-variation of given
function f : [0,T] →R, p ≥1 :
We say that
lim sup
Δt→0
n

i=1
| f (ti) −f (ti−1)|p, 0 = t0 < t1 < . . . < tn = T,
is a p−variation of f on [0,T].
Usually, the ﬁrst and second variations are most important in this regard.
For the second variation of (Wt)t ≥0. We have the following observations.
In view of independent increments we obtain for 0 = t0 < t1 < . . . < tn = T that
E 	n
i=1(Wti −Wti−1)2 = 	n
i=1 E(Wti −Wti−1)2 = 	n
i=1 Var(Wti −Wti−1) = 	n
i=1
(ti −ti−1) = T.
Further, with the help of (3):
Var
n

i=1
(Wti −Wti−1)2 =
n

i=1
Var(Wti −Wti−1)2
=
n

i=1

E(Wti −Wti−1)4 −

E(Wti −Wti−1)22
=
n

i=1

3(ti −ti−1)2 −(ti −ti−1)2
=2
n

i=1
(ti −ti−1)2.
Therefore,

86
8
Elements of classical theory of stochastic processes
E
 n

i=1
(Wti −Wti−1)2 −T
2
= Var
 n

i=1
(Wti −Wti−1)2

=2
n

i=1
(ti −ti−1)2 ≤2T max
0<i≤n(ti −ti−1) →0,
and we conclude that the second variation of (Wt) on [0,T] converges to the length
of this interval in L2sense, and hence, in the sense of convergence in probability. To
investigate the ﬁrst variation of (Wt) we consider the probability P(ω : 	n
i=1 |Wti −
Wti−1| > N). First of all, we note that E 	n
i=1 |Wti −Wti−1| =

2
π
	n
i=1
√ti −ti−1 →
∞as max(ti −ti−1) →0, and
Var
n

i=1
|Wti −Wti−1| =
n

i=1
(1 −2
π )(ti −ti−1) = (1 −2
π )T.
Further, for E 	n
i=1 |Wti −Wti−1| > n with the help of the Chebyshev inequality
we get
P(ω :
n

i=1
|Wti −Wti−1 | ≤N) ≤P(ω :
n

i=1
|Wti −Wti−1 | −E
n

i=1
|Wti −Wti−1 | ≥E
n

i=1
|Wti −Wti−1 | −N)
≤Var(
n

i=1
|Wti −Wti−1 |)/(E
n

i=1
|Wti −Wti−1 | −N)2 →0,
as max(ti −ti−1) →0.
It means that the ﬁrst variation of (Wt) converges in probability to ∞.
Remark 8.2 It is possible to prove that all mentioned results are true in the sense of
(a.s.)-convergence.
Another process that plays an important role in both theory and applications is a
Poisson process.
Deﬁnition 8.3 The process (Nt)t ≥0 is called a Poisson process with parameter λ > 0,
if the following conditions are satisﬁed:
1) N0 = 0. (a.s.),
2) its increments Nt1 −Nt0, . . ., Ntn −Ntn−1 are independent random variables for
any sundivision 0 ≤t0 < t1 < . . . < tn < ∞,
3) Nt −Ns is a random variable that has a Poisson distribution with parameter
λ(t −s) :
P(ω : Nt −Ns = i) = e−λ(t−s) (λ(t −s))i
i!
, 0 ≤s ≤t < ∞, i = 0, 1, . . . .
Let us present some properties of sample paths of this process.

8.1
Stochastic processes: deﬁnitions, properties and classical examples
87
First of all, we note that its almost all trajectories are non-decreasing, because for
s ≤t :
P(ω : Nt −Ns ≥0) =
∞

i=0
P(ω : Nt −Ns = i) =
∞

i=0
e−λ(t−s) (λ(t −s))i
i!
= e−λ(t−s)
∞

i=0
(λ(t −s))i
i!
= e−λ(t−s)eλ(t−s) = 1.
The process (Nt)t ≥0 is stochastically continuous: in the sense Nt →Ns in proba-
bility as t →s. This property is an obvious consequence of the application of the
Chebyshev inequality. It is an interesting eﬀect when a jumping process satisﬁes a
continuity property. Moreover, one can say something about a diﬀerentiability of
trajectories of (Nt)t ≥0 in the sense of convergence in probability, i.e.
Nt+Δt −Nt
Δt
p
−−−−→
Δt→0 0.
(8.3)
Problem 8.2 Prove relation (8.3).
Further, one can derive from P(ω : Ns ≤Nt) = 1 for all s ≤t that there is a right-
continuous modiﬁcation of (Nt), almost all trajectories of which are non-decreasing
integer-valued functions with unit jumps.
Let us note a martingale property of (Nt)t ≥0. To do this we introduce a natural
ﬁltration (Ft)t ≥0, generated by (Nt)t ≥0 and completed by sets of P−measure zero.
We note that
ENt =
∞

i=0
iP(ω : Nt = i) =
∞

i=0
ie−λt (λt)i
i!
=(λt)e−λt
∞

i=1
(λt)i−1
(i −1)! = (λt)e−λteλt = λt.
Let us deﬁne a new process Mt = Nt −λt and ﬁnd that for s ≤t due to indepen-
dence (Nt −Ns) of Fs :
E(Mt|Fs) =E(Nt −λt|Fs) = E(Nt −Ns + Ns −λt|Fs)E(Nt −Ns|Fs) + Ns −λt
=E(Nt −Ns) + Ns −λt = λ(t −s) + Ns −λt = Ns −λs = Ms.
Hence, (Mt)t ≥0 is a martingale w.r.to (Ft)t ≥0.
We have seen that both processes (Wt)t ≥0 and (Nt) are stochastically continu-
ous processes with independent increments. The following example shows why a
consideration of stochastic processes with independent values is not productive.
Example 8.1 Let (Xt)t ≥0 be a family of independent random variables with the same
density f = f (x) ≥0,
∫∞
−∞f (x)dx = 1. Then for a ﬁxed s ≥0, and t  s, ϵ > 0 we
have that

88
8
Elements of classical theory of stochastic processes
P(ω : |Xt −Xs| ≥ϵ) =
∫∫
|x−y|≥ϵ
f (x) f (y)dxdy.
(8.4)
The integral in the right hand side of equality (8.4) converges (as ϵ →0) to
∫∫
xy
f (x) f (y)dxdy =
∫∞
−∞
∫∞
−∞
f (x) f (y)dxdy.
(8.5)
The relation (8.5) shows that for some ϵ > 0 the probability in the left hand side
of (8.4) does not converge to zero as t →s. It means the process with independent
values is not stochastically continuous even.
The existence of a Wiener process was derived from the Kolmogorov consistency
theorem. Such a derivation does not look constructive. That is why we want to
demonstrate a direct way of construction of a Wiener process, based on orthogonal
systems of functions of Haar and Schauder, and sequences of independent normal
random variables.
Let us deﬁne a system of functions (Hk(t))k=1,2,..., t ∈[0, 1], called the Haar
system:
H1(t), H2(t) = I[0,2−1](t) −I(2−1,1](t), . . .,
Hk(t) = 2n/2 
I(an,k, an,k + 2−n−1] −I(an,k+2−n−1,an,k+2−n](t)

where wn < k ≤2n+1, an,k = 2−n(k −2n −1), n = 1, 2, . . . .
In the space L2([0, 1], B(0, 1), dt) with the scalar product ⟨f, g⟩=
∫1
0 fsgsds,
f, g ∈L2, the system (Hk(t))k=1,2... is complete and orthogonal. Hence,
f =
∞

k=1
⟨f, Hk⟩Hk, g =
∞

k=1
⟨g, Hk⟩Hk, ⟨f, g⟩=
∞

k=1
⟨f, Hk⟩⟨g, Hk⟩.
Using the system (Hk(t))k=1,2,... one can construct the Schauder system
(Sk(t))k=1,2,... as follows
Sk(t) =
∫t
0
Hk(y)dy = ⟨I[0,t], Hk⟩, t ∈[0, 1].
Lemma 8.1 If a sequence of real numbers ak = O(kϵ), k →∞, for some ϵ ∈
(0, 1/2), then the series 	∞
k=1 akSk(t) converges uniformly on [0, 1], and, hence,
it is a continuous function.
Proof Denote Rm = supt
	
k>2m |ak|Sk(t), m = 1, 2, . . ., and note that |ak| ≤ckϵ
for all k ≥1 and some constant c > 0. Therefore, for all t and n = 1, 2, . . . we obtain
that

2n<k<2n+1
|ak|Sk(t) ≤c2(n+1)ϵ

2n<k<2n+1
Sk(t)
≤c2(n+1)ϵ2−n/2−1
≤c2ϵ−n(1/2−ϵ).
(8.6)

8.1
Stochastic processes: deﬁnitions, properties and classical examples
89
It follows from here that Rm ≤c2ϵ 	
n≥m 2−n(1/2−ϵ) →0 as m →∞.
□
Lemma 8.2 Let (ξk)k=1,2,... be a sequence of standard normal random variable on
a complete probability space (Ω, F, P). Then for every constant c >
√
2 and almost
all ω ∈Ω there exists a number N0 = N0(ω, c) such that |ξk(ω)| < c
√
ln k for all
k ≥N0.
Proof For a standard normal random variable ξ ∼N(0, 1) and x > 0 we have that
P(ω : ξ ≥x) =(2π)−1/2
∫∞
x
e−y2/2dy
=(2π)−1/2
∫∞
x

−1
y

de−y2/2
=(2π)−1/2

x−1e−x2/2 −
∫∞
x
y−2e−y2/2dy

≤x−1(2π)−1/2(x−1e−x2/2)
(8.7)
and, hence,
P(ω : |ξ| ≥x) ≤x−1(2π)1/2e−x2/2.
Applying the above inequality we can estimate the series below as follows

k ≥2
P

ω : |ξk| ≥c(ln k)1/2
≤c−1(2/π)1/2 
k ≥2
k−c2/2(ln k)−1/2 < ∞,
and the statement of Lemma 8.2 follows from the Borel-Cantelli lemma.
□
Theorem 8.1 Let (ξk)k=1,2,... be a sequence of independent standard normal random
variables (Ω, F, P). DeﬁneastochasticprocessWt = W(t, ω) = 	∞
k=1 ξk(ω)Sk(t), t ∈
[0, 1], ω ∈Ω. Then (Wt)t ∈[0,1] is a Wiener process.
Proof First of all, we note that (Wt) has continuous trjectories due to Lemma 8.1
and 8.2.
Denote Zn(t) = 	n
k=1 ξkSk(t), t ∈[0, 1], and ﬁnd that
E|Zn+m(t) −Zn(t)|2 =E

n+m

k=n+1
ξkSk(t)

2
=
n+m

k=n+1
n+m

l=n+1
Sk(t)Sl(t)Eξkξl
=
n+m

k=n+1
S2
k(t).
(8.8)
Further, 	∞
k=1 S2
k(t) ≤	∞
k=1
2−k/2−12 < ∞, and, hence, due to a completeness of
L2(Ω, F, P) we arrive to conclusion that there exists a limit Z(t) of Zn(t) in this
space such that

90
8
Elements of classical theory of stochastic processes
E|Zn(t) −Z(t)|2 →0, n →∞, t ∈[0, 1].
This limit Z(t) coincides with Wt up to equivalence and Zn(t)
t−→Wt in L2−sense.
Now due to EZn(t) = 0 we obtain that
|EWt| = |EWt −EZn(t)| ≤

E|Wt −Zn(t)|21/2
−−−−→
n→∞0,
which means that EWt = 0.
Using a continuity property of the scalar product we ﬁnd that
⟨Zn(s), Zn(t)⟩L2(Ω) →⟨Ws, Wt⟩L2(Ω) = EWsWt = Cov(Ws, Wt), s, t ∈[0, 1].
On the other hand, we can use the independence of (ξk)k=1,2,... and Eξk = 0, Eξ2
k = 1,
and observe that
⟨Zn(s), Zn(t)⟩L2(Ω) = EZn(s)Zn(t) =
n

k=1
Sk(s)Sk(t)Eξ2
k →
∞

k=1
Sk(t)Sk(t), n →∞.
Applying the Parseval equality for scalar products we ﬁnally derive that
∞

k=1
Sk(s)Sk(t) =
∞

k=1
⟨Hk, I[0,s]⟩⟨Hk, I[0,t]⟩= ⟨I[0,s], I[0,t]⟩= min(s, t) = Cov(Ws, Wt).
Let us prove that (Wt)t ∈[0,1] is a Gaussian process. Take μ = (μ1, . . ., μn) ∈
Rn, t1, . . ., tn ∈[0, 1] and deﬁne Y = 	n
m=1 μmWtm. We have now that
Y =
n

m=1
μm
∞

k=1
ξkSk(tm) =
∞

k=1
bkξk,
where bk = bk(μ1 . . . μn, t1, . . ., tn) = 	n
m=1 μmSk(tm). Consider YN = 	N
k=1 bkξk ∼
N(0, σ2
N), σ2
N = 	N
k=1 b2
k and ﬁnd that
EY2
N = σ2
N →EY2 = σ2, N →∞,
in the sense of L2(Ω). Therefore, we have also the convergence in distribution
YN −→
d Y, N →∞. Hence, we have that the convergence of
φY(λ) = exp(−σ2
Nλ2/2) →exp(−σ2λ2/2) = φY(λ), λ ∈R,
i.e. Y ∼N(0, sσ2).
Finally, we can extend this construction from the unit time interval to the whole
[0, ∞) as follows
W(t, ω) =

Wt = W(t, ω) = W1(t, ω),
t ∈[0, 1),
	k
j=1 Wj(1, ω) + Wk+1(t −k, ω),
t ∈[k, k + 1), k = 1, 2, . . .,

8.2
Stochastic integrals with respect to a Wiener process
91
where Wn = (Wn(t))t ∈[0,1] be a sequence of independent Wiener processes.
□
8.2
Stochastic integrals with respect to a Wiener process
Let (Ω, F, P) be a complete probability space, (Wt)t ≥0 be a Wiener process and
(Ft)t ≥0 be a complete ﬁltration generated by this process.
We describe here a scheme of construction of a stochastic integral
I( f ) =
∫∞
0
fs(ω)dWs
(8.9)
for any Ft-adapted and B(0, ∞) × F -measurable random function/process ft(ω) =
f (t, ω) integrable in square with respect to dt × dP :
E
∫∞
0
f 2
s ds < ∞.
(8.10)
The class of these random functions is denoted S2, and the stochastic integral
(8.9) must be a linear and isometric operator from L2(R+ × Ω, B(R+) × F, dt × dP)
to L2(Ω, F, dP). We start its construction from the class of step functions f ∈S2
0 ⊆
S2. For each function f there exists a subdivision 0 = t0 ≤t1 ≤. . . ≤tn < ∞such
that fti-Fti- measurable and square-integrable, and ft = fti for t ∈[ti, ti+1), i ≤n,
whereas ft = 0 for t ≥tn. Hence, the weighted sum
n−1

i=0
fti I[ti,ti+1)(t) = ft(ω).
(8.11)
For function ft(ω), deﬁned by (8.11) we introduce a stochastic integral I( f ) as
follows
I( f ) =
∫∞
0
fSdWs =
n−1

i=0
fti(Wti+1 −Wti).
(8.12)
It is almost obvious that the deﬁnition of I( f ) in (8.12) does not depend on changes
of subdivisions (ti), and it is a linear mapping from S2
0 to L2(Ω, F, P), i.e.
I(α f + βg) = αI( f ) + βI(g),
(8.13)
where α, β ∈R, f, g ∈S2
0.
Using properties (1)-(2) and (4) of a Wiener process (Wt)t ≥0 and properties of
conditional expected values, we obtain that

92
8
Elements of classical theory of stochastic processes
EI2(f ) =E
⎡⎢⎢⎢⎢⎣
n−1

i=0
f 2
ti (Wti+1 −Wti )2 + 2

j<i
ftj (Wtj+1 −Wtj )fti (Wti+1 −Wti )
⎤⎥⎥⎥⎥⎦
=E
⎡⎢⎢⎢⎢⎣
n−1

i=0
f 2
ti E

(Wti+1 −Wti )2 |Fti

+ 2

j<i
ftj (Wtj+1 −Wtj )fti E (Wti+1 −Wti )|Fti
⎤⎥⎥⎥⎥⎦
=
n−1

i=0
Ef 2
ti (ti+1 −ti) = E
∫∞
0
f 2
s ds.
(8.14)
The
isometry
relation
(8.14)
means
that
the
norms
||I( f )||L2(Ω,F,P)
and
|| f ||L2(R+×Ω,B(R+)×F,dtdP) are coincide. Using similar reasoning as in proving (8.14)
one can derive for f, g ∈S2
0 that
EI( f )I(g) = E
∫∞
0
fsgsds.
(8.15)
Equalities (8.13)-(8.15) show that the stochastic integral deﬁned in (8.12) is a
linear and isometric operator.
For function f ∈S2
0 we deﬁne a stochastic integral over interval [0, t), t > 0, as
follows
It( f ) = I(I[0,t) f ) =
∫t
0
fsdWs.
(8.16)
It turns out, (It( f ))t ≥0 is a martingale with respect to (Ft)t ≥0.
To prove it we ﬁx t > 0, and for simplicity, assume that t = tk.
Then we have
I[0,t) fs = 	n−1
i=0 fti I[ti,ti+1)(t)
and
It( f ) = 	n−1
i=0 fti(Wti+1 −Wti),
which
are
Ft−measurable. Further, if s ≤t and s = tu and t = tk, then
E(It( f ) −Is( f )|Fs) =
k−1

i=u
E  ftiE(Wti+1 −Wti |Fti)|Fs
 = 0.
For function f ∈S0 one can rewrite
It( f ) =
n−1

i=0
fti(Wti+1∧t −Wti∧t),
and notice that the process (It( f ))t ≥0 is continuous.
Now we take a monotonic sequence (sj) such that 0 ≤s0 ≤s1 ≤. . . ≤sm < ∞.
Then the sequence (Isj ( f ), Fj)j=0,...,m is a martingale for which the Doob inequality
is true
E sup
0≤j ≤m
I2
sj ( f ) ≤4EI2
sm( f ) ≤4E
∫sm
0
f 2
t dt ≤4E
∫∞
0
f 2
t dt.
(8.17)
Considering (sj) rational and using the continuity of the trajectories of It( f ), we
arrive to the Doob inequality for f ∈S2
0 taking sup over t ∈R+ in (8.17):

8.2
Stochastic integrals with respect to a Wiener process
93
E sup
t
I2
t ( f ) ≤4E
∫∞
0
f 2
t dt.
(8.18)
One can extend the operator It( f ) from S2
0 to its closure S2. Any function f ∈S2
can be approximated by a sequence fn ∈S2
0.
A concrete construction of such a sequence ( fn)n=1,2,... ∈S2
0 can be provided as
follows. For any function f ∈S2 we deﬁne
fn(t)=

n
∫k/n
(k−1)/n f (s)ds,
for t∈[k/n, (k + 1)/n), k=1, 2, . . ., n2 −1, n=1, 2, . . .
0,
otherwise.
Using the Jensen inequality we can ﬁnd that
∫(k+1)/n
k/n
| fn(t)|2dt = n

∫k/n
(k−1)/n
f (t)dt

2
≤
∫k/n
(k−1)/n
| f (t)|2dt, k = 1, 2, . . .
Hence, (a.s.)
∫∞
0
| fn(t)|2dt ≤
∫∞
0
| f (t)2dt < ∞,
∫∞
0
| f (t) −fn(t)|2dt ≤2
∫∞
0

| f (t)|2 + | fn(t)|2
dt ≤4
∫∞
0
| f (t)|2dt < ∞.
Now, for arbitrary N = 1, 2, . . . we easily observe that E
∫n
0 | f −fn(t)|2dt →
0, n →∞, by construction of ( fn)n=1,2,.... Further, we have
∫∞
0
| f (t) −fn(t)|2dt =
∫N
0
| f (t) −fn(t)|2dt +
∫∞
N
| f (t) −fn(t)|2dt
≤
∫N
0
| f (t) −fn(t)|2dt + 2
∫∞
N

| f (t)|2 + | fn(t)|2
dt
≤
∫N
0
| f (t) −fn(t)|2dt + 2
∫∞
N

| f (t)|2 +
∫∞
N−1/n
| fn(t)|2

dt
≤
∫N
0
| f (t) −fn(t)|2dt + 2
∫∞
N−1
| f (t)|2dt.
(8.19)
The term
∫∞
N−1 | f (t)|2dt →0 as N →∞, and by the dominated convergence theorem
E
∫∞
0
| f (t) −fn(t)|2dt →0 as n →∞.
Then for m and n ∈Z+ we have
||I( fm) −I( fn)||L2(Ω) = ||I( fm −fn)||L2(Ω) = || fm −fn||S2.
It means that (I( fn))n≥1 is a fundamental sequence in a complete space L2(Ω, F, P).
Hence, it converges to some element of this space:
I( f ) = lim
n→∞I( fn),
(8.20)

94
8
Elements of classical theory of stochastic processes
and we call I( f ) a stochastic integral of f ∈S2. We also deﬁne for t ≥0
∫t
0
fsdWs =
∫∞
0
I[0,t)(s) fsdWs,
(8.21)
and we prove that the stochastic integral (8.21) admits a continuous modiﬁcation.
To prove it we take a sequence fn = fn(t, ω) ∈S2
0 such that
E
∫∞
0
| f (s) −fn(s)|2ds ≤2−n, n = 1, 2, . . .,
For each t ≥0 we have in space L2(R+ × Ω, B(0, ∞) × F, dtdP) that
I[0,t)(s)( f ) = I[0,t)(s) f1 + . . . + I[0,t)(s)( fn+1 −fn) + . . .,
(8.22)
The equality (8.22) by continuity in the sense of this space is transformed to the next
one
∫t
0
f (s)dWs =
∫t
0
f1(s)dWs + . . . +
∫t
0
| fn+1(s) −fn(s))dWs + . . .,
(8.23)
In the right hand side of (8.23) each term is continuous as functions fn ∈S2
0. There-
fore, to prove the continuity of stochastic integral (8.21) it is enough to provide a
uniform convergence (a.s.) of series (8.21). First, due to the Doob inequality we
obtain that
E sup
t ≥0

∫t
0
( fn+1 −fn(s)) dWs

2
≤4E
∫∞
0
( fn+1(s) −fn(s))2 ds
(8.24)
≤16 · 2−n.
(8.25)
Second, combining (8.24) with the Chebyshev inequality, we get
P

sup
t

∫t
0
( fn+1(s) −fn(s)) dWs
 ≥n−2

≤16n42−n.
(8.26)
Application of (8.25) together with the Borel-Cantelli lemma certiﬁes that the series
(8.23) converges (a.s.).
Finally, we can conclude that the extension of It( f ) from space S2
0 to S2 leaves its
basic properties:
(1) Linearity,
(2) Isometry,
(3) Martingality,
(4) Continuity of trajectories.
Before starting to state other properties of stochastic integrals we introduce a
special class of random variables needed here.

8.2
Stochastic integrals with respect to a Wiener process
95
Let τ be a random variable taking values in [0, ∞]. We call it a stopping time
on a stochastic basis (Ω, F, (F )t ≥0, P), generated by a Wiener process (Wt)t ≥0, if
{ω : τ(ω) ≤t} ∈Ft for every t ∈R+.
A natural example is the ﬁrst hitting time of the point a by Wt :
τ =τa = inf{t : Wt ≥a},
τ =∞, if the set in brackets {.} is empty.
Indeed, one can observe that
{ω : τ(ω) ≤t} = Ω \ {ω : τ(ω) > t}.
(8.27)
Further, we have a relation
{ω : τ(ω) > t} = {ω : max
s≤t Ws(ω) < a}.
(8.28)
Let us note that
max
s≤t Ws =
sup
r ≤t,r ∈Q
Wr,
(8.29)
where Q is the set of rational numbers, and hence maxs≤t Ws is Ft−measurable.
Using continuity of trajectories of Wt and relations (8.27)-(8.29) we arrive to con-
clusion that {ω : τ(ω) ≤t} ∈Ft.
Let us connect a stochastic integral It( f ) = Xt =
∫t
0 fsdWs, f ∈S2, and a stopping
time τ. We have the two following equalities which are very useful:
Xτ =
∫∞
0
Is<τ fsdWs =
∫∞
0
Is≤τ fsdWs (a.s.),
(8.30)
E
∫τ
0
f sdWs
2
= E
∫τ
0
f 2
s ds (Wald’s identity),
(8.31)
To prove (8.30) we start with a stopping time τ taking discrete values t1, t2, . . .
and ﬁnd that Is<tk fs = Is<τ fs on the set {ω : τ = tk}.
On each such set (a.s.)
Xτ = Xtk =
∫∞
0
I(s<tk) fsdWs =
∫∞
0
I(s<τ) fsdWs.
Hence, it is true (a.s.) on Ω = ∪k{τ = tk}. To prove (8.30) for an arbitrary stopping
time τ we approximate τ by a sequence of discrete stopping times
τn = 2−2[2nτ] + 2−n,
such that τ ≤τn and τn −τ ≤2−n. Further, due to a continuity of Xt we get conver-
gence Xτn →Xτ (a.s.) and by the dominated convergence theorem

96
8
Elements of classical theory of stochastic processes
E
∫∞
0
I{s<τ} fsdWs −
∫∞
0
Is<τn fsdWs
2
= E
∫∞
0
I{τ≤s<τn } f 2
s ds →0, n →∞.
Therefore, we obtain (8.30), and using isometry property we get (8.31):
EX2
τ = E
∫∞
0
Is<τ f 2
s ds = E
∫τ
0
f 2
s ds.
It turns out a certain extension of the notion of a stochastic integral with respect
to a Wiener process can be done using the following localization procedure. It is
given with the help of stopping times.
Consider the set of B(0, ∞) × F −measurable adapted random functions f =
ft(ω) such that
∫T
0
f 2
s ds < ∞(a.s.) for all T ∈R+.
(8.32)
The family of such functions satisfying (8.32) is denoted by S.
We deﬁne a sequence of stopping time (τn)n=1,2,... such that
τn = inf

t :
∫t
0
f 2
s ds ≥n

.
One can easily observe that (a.s.)
∫τn
0
f 2
s ds ≤n
and
τn ↑∞, n ↑∞,
and
I{t<τn } f ∈S2
for
b = 1, 2, . . . .
It follows from here that
Xn
t =
∫t
0
I{s<τn } fsdWs,
is well deﬁned for n = 1, 2, . . . one can also note that
Xn
t (ω) = Xm
t (ω),
for m ≥n, 0 ≤t ≤τn(ω) and ω ∈Ω′, P(Ω′) = 1.
Moreover, the sequence (Xn
t )n=1,2,... converges uniformly on ﬁnite time intervals.
All arguments above give a possibility to deﬁne a stochastic integral for each
f ∈S as follows
∫t
0
fsdWs = lim
n→∞
∫t
0
Is<τn fsdWS.
(8.33)
Stochastic integral (8.33) for f ∈S admits a continuous modiﬁcation and saves a
linearity property. But it is not a martingale anymore. Nevertheless, the martingale
property is fulﬁlled locally:
∫t∧τn
0
fsdWs

t ≥0
is a square-integrable martingale for n = 1, 2, . . .

8.2
Stochastic integrals with respect to a Wiener process
97
Remark 8.3 Let us make a remark regarding ﬁnite-dimensional processes.
We say that (Wt) is a d−dimensional Wiener process ifWt = (W1
t , . . ., W d
t ), where
(Wi
t ), i = 1, . . ., d, are one-dimensional independent Wiener process.
For d−dimensional random function ft = ( f 1
t , . . ., f d
t ) with components from S
we deﬁne
∫t
0
fsdWs =
d

i=1
∫t
0
f i
s dWi
s.
As far as a stochastic integration of matrix-valued random functions σt = (σi
t ), i =
1, . . ., d, j = 1, . . ., d, and σij ∈S we deﬁne
∫t
0 σsdWs as a d−dimensional process
with the i−th coordinate 	d
j=1
∫t
0 σij
s dW j
s .
Remark 8.4 The construction of a stochastic integral developed in this section was
given by K. Ito. That is why this integral is often called the Ito integral. A similar
construction was given by R. Stratonovich who proposed to use a diﬀerent class of
integral sums:
N−1

i=0
f (t∗
i )(Wti+1iWti),
where t∗
i = 1
2(ti+1 + ti).
The corresponding stochastic integral is called the Stratonovich integral.
Remark 8.5 It is well-known that the construction of the Rieman integral as a limit
of the integral sums does not depend on the choice of intermediate points inside of
subdivision intervals. It was shown in Remark 8.4 that the construction of a stochastic
integral is not invariant with respect to such a choice. Let us give another example
of this type. Take f (t) = W(t) = Wt and consider a subdivision of [0,T] :
0 = t0 < t1 < . . . < tn = T, tj = T j
n , j = 1, . . ., n.
For this subdivision we deﬁne two integral sums as follows
I(n)
1
=
n

i=1
Wti−1(Wti −Wti−1) and I(n)
2
n

i=1
Wti(Wti −Wti−1).
For two real numbers a and b we note that a(b −a) = 1
2(b2 −a2) −1
2(a −b)2 and
b(b −a) = 1
2(b2 −a2) + 1
2(a −b)2.
Applying these elementary equalities to the integral sums we obtain that
I(n)
1
= 1
2
n

i=1
(W2
ti −W2
ti−1 −1
2
n

i=1
(Wti −Wti−1)2 = 1
2W2
T −1
2
n

i=1
(Wti −Wti−1)2,
I(n)
2
= 1
2
n

i=1
(W2
ti −W2
ti−1 −1
2
n

i=1
(Wti −Wti−1)2 = 1
2W2
T + 1
2
n

i=1
(Wti −Wti−1)2.

98
8
Elements of classical theory of stochastic processes
Hence,
EI(n)
1
= 1
2T −1
2E
n

i=1
(Wti −Wti−1)2 →T
2 −T
2 = 0, n →∞,
EI(n)
2
= 1
2T + 1
2E
n

i=1
(Wti −Wti−1)2 →T
2 + T
2 = T, n →∞,
and we observe that L2-limits of integral sums are diﬀerent.
Remark 8.6 It is very often another type of measurability of f is exploited in the
deﬁnition of stochastic integrals, i.e. f is progressively measurable in the sense: for
each t
f : ([0, t] × Ω, B(0, t) × Ft) →(R, B(R)).
Without loss of generality we can count S2
0, S2, S as classes of progressively measur-
able random functions.
8.3
The Ito processes: Formula of changing of variables,
theorem of Girsanov, representation of martingales
Let us take two progressively measurable (or Ft−adapted and B(0, ∞) × F −
measurable) (bt(ω))t ≥0 and (σt(ω))t ≥0 satisfying the next integrability conditions:
for each T > 0 (a.s.)
∫T
0
|bs(ω)|ds < ∞,
∫T
0
|σs(ω)|2ds < ∞.
(8.34)
Conditions (8.34) imply a possibility to deﬁne a new stochastic process
Xt = X0 +
∫t
0
bsds +
∫t
0
σsdWs,
(8.35)
where X0 is a ﬁnite (a.s.) random variable, (Wt)t ≥0 is a Wiener process generating
ﬁltration (Ft)t ≥0.
The process (Xt)t ≥0 is called the Ito process. It is very convenient to write equality
(8.35) in the following diﬀerential form
dXt = btdt + σtdWt.
(8.36)
In the above representation (8.36) we can speak about dXt as a stochastic diﬀer-
ential of (Xt)t ≥0.
We will study the class of the Ito processes using both form (8.35) and (8.36).
As the ﬁrst result playing a very important role in Stochastic Analysis is the formula
of changing of variables (the Ito formula) for the class of smooth functions F(t, x),

8.3
The Ito processes: Formula of changing of variables . . .
99
having one continuous derivative ∂F
∂t and two continuous derivatives ∂F
∂x and ∂2F
∂x2 ,
i.e. F ∈C1,2.
We start with the next lemma.
Lemma 8.3 Let (Wt)t ≥0 be a Wiener process, then for each t ≥0 (a.s.)
W2
t = 2
∫t
0
WsdWs + t.
(8.37)
Proof Without loss of generality we consider only t = 1 and ﬁnd that in the sense
of convergence in probability (P−lim):
∫t
0
WsdWs = lim
n→∞

k<n
W k
n

W k+1
n −W k
n

= lim
n→∞

k<n
1
2

W k+1
n + W k
n
 
W k+1
n −W k
n

−

k<n
1
2

W k+1
n −W k
n
2

.
(8.38)
It is clear that as n →∞
	
k<n
1
2

W k+1
n + W k
n
 
W k+1
n −W k
n

= 1
2
	
k<n

W2
k+1
n −W2
k
n

→1
2W2
1,
	
k<n

W k+1
n −W k
n
2
→1
2.
Hence, we can get from (8.38) the equality (8.37).
□
The next step is the formula for the product of two Ito’s processes (Xi
t )t ≥0, i = 1, 2,
with coeﬃcients bi, σi correspondingly.
Lemma 8.4 For each t ≥0 (a.s.)
dX1
t X2
t = X1
t dX2
t + X2
t dX1
t + σ1
t σ2
t dt.
(8.39)
Proof Dividing [0, t] with the help of a subdivision (tk)k ≤n with the diameter
maxk ≤n |tk −tk−1| →0, n →∞, we can reduce the proof to the “small” intervals
(tk, tk+1) of this subdivision.
For such small enough interval we have a discrete analog of (8.39):
X1
tk+1 X2
tk+1 −X1
tk X2
tk =
∫tk+1
tk
X1
s

b2
sds + σ2
s dWs

+
∫tk+1
tk
X2
s

b1
sds + σ1
s dWs

+
∫tk+1
tk
σ1
s σ2
s ds,
where we can think about bi, σi, i = 1, 2 as constants. Therefore, the problem is
reduced to the following four cases:
(1) X1
t = t, X2
t = t,

100
8
Elements of classical theory of stochastic processes
(2) X1
t = t, X2
t = Wt,
(3) X1
t = Wt, X2
t = t,
(4) X1
t = Wt, X2
t = Wt.
Case (1) is the usual diﬀerentiation case.
Case (4) is Lemma 8.3.
Case (2)-(3) are equivalent, and we need to show that for each t ≥0 (a.s.)
tWt =
∫t
0
Wsds +
∫t
0
sdWs,
which is true due to the following obvious relation: for t = 1
1 · W1 =P −lim
n→∞

k<n

 k + 1
n
W k+1
n −k
nW k
n

=P −lim
n→∞

k<n
k
n

W k+1
n −W k
n

+

k<n
1
nW k+1
n

.
So, we arrive to the equality (8.39).
□
Lemma 8.5 For any polynomial function Pn(x) of degree n = 1, 2, . . . we have
dPn(Wt) = P′
n(Wt)dWt + 1
2P′′
n (Wt)dt.
(8.40)
Proof It is suﬃcient to prove (8.40) for Pn(x) = xn. We can use the induction method
to prove that
dWn
t = nWn−1
t
dWt + n(n −1)
2
Wn−2
t
dt.
(8.41)
For n = 1 the formula (8.41) is trivial. Further, we take X1
t = Wn
t and X2
t = Wt, use
Lemma 8.4 with
b1
t = n(n −1)
2
Wn−1
t
, σ1
t = nWn−2
t
, b2
t = 0, σ2
t = 1,
and obtain (8.41):
dWn+1
t
=Wn
t dWt + Wt

nWn−1
t
dWt + n(n −1)
2
Wn−2
t
dt

+ nWn−1
t
dt
=(n + 1)Wn
t dWt + n(n + 1)
2
Wn−1
t
dt.
□
Corollary 8.1 If F = F(x) is a continuously diﬀerentiable function with continuous
derivatives F′(x) and F′′(x), then for t ≥0 (a.s.)

8.3
The Ito processes: Formula of changing of variables . . .
101
dF(Wt) = F′(Wt)dWt + 1
2F′′(Wt)dt.
(8.42)
To prove (8.42) we uniformly (on compact intervals) approximate F(x) by a sequence
of polynomials Pn such that
F(x) = lim
n→∞Pn(x), F′(x) = lim
n→∞P′
n(x), F′′(x) = lim
n→∞P′′
n (x)
and take the limit in the formula (8.40).
Corollary 8.2 Assume F : R+ × R →R is a function of class C1,2, then for t ≥0
(a.s.)
dF(t, Wt) =

 ∂F
∂t (t, Wt) + 1
2
∂2F
∂x2 (t, Wt)

dt + ∂F
∂x (t, Wt)dWt.
(8.43)
The ﬁrst step of the proof is the case F(t, x) = F1(t)F2(x). Then (8.43) follows
from Lemma 8.4 and Corollary 8.1. The general case of F can be derived by
approximation of F(t, x) by a sequence of functions Fn(t, x) = 	
k ≤n F1,n(t)F2,n(x)
with ∂Fn
∂t , ∂Fn
∂x , ∂2Fn
∂x2 converge uniformly on compact sets.
Remark 8.7 Let us deﬁne the local time of W at the level a during [0, t]:
lW(t, a) = lim
ϵ→0
1
2ϵ
∫t
0
I(a−ϵ,a+ϵ)(Ws)ds,
which exists (a.s.) and in the sense of L2-space. Using this notion, one can get a
version of the Ito formula for non-diﬀerentiable functions, say, F(x) = |x| :
|Wt −a| −|W0 −a| =
∫t
0
sgn(Ws −a)dWs + lW(t, a),
where
sgn(x) =
⎧⎪⎪⎪⎨
⎪⎪⎪⎩
1,
x > 0,
0,
x = 0,
−1,
x < 0.
Such a formula is called as the Tanaka formula.
The ﬁnal formula (for Ito’s processes) is given in the next theorem.
Theorem 8.2 Assume F ∈C1,2 and
dXt = bt(ω)dt + σt(ω)dWt.
Then for t ≥0 (a.s.)
dF(t, Xt) =

 ∂F
∂t (t, Xt) + bt
∂F
∂x (t, Xt) + σ2
t
2
∂2F
∂x2 (t, Xt)

dt + σt
∂F
∂x (t, Xt)dWt.
(8.44)

102
8
Elements of classical theory of stochastic processes
The formula (8.44) admits a generalization to a multidimensional case. Namely,
assume F : R+ × Rk →R of class C1,2, the process (Xt) in (8.35) is deﬁned by
a vector-function bt(ω) = b(t, ω) = (b1
t (ω, . . ., bk
t (ω)) and a matrix-value function
σt(ω) = σ(t, ω) = (σij
t (ω))i≤k,j ≤d:
Xi
t = Xi
0 +
∫t
0
bi
sds +
∫t
0
d

j=1
σij
s dW j
s, i = 1, . . ., k,
and Wt = (W1
t , . . ., W d
t ) is a d−dimensional Wiener process. Then for t ≥0 (a.s.)
dF(t, Xt) =

∂F
∂t (t, Xt) +
k

i=1
∂F
∂xi (t, Xt)bi
t + 1
2
k

i,j=1
∂2F
∂xi∂xj
(t, Xt)
(8.45)
×
d

l=1
σil
t σlj
t

dt +
d

j=1
 k

i=1
∂F
∂xi
(t, Xt)σij
t

dW j
t .
(8.46)
Example 8.2 (Stochastic exponential) Consider the Ito process (8.35). Deﬁne the
process
Et(X) = exp
!
Xt −1
2
∫t
0
σ2
s ds
"
.
(8.47)
Applying the Ito formula to function F(t, x) = e−σ2
2 tex, (t, x) ∈R+ × R, we ﬁnd that
dEt(X) = Et(X)dXt, E0(X) = 1.
(8.48)
We will call (Et(X))t ≥0 a stochastic exponent of process (Xt).
Let us count the following properties of stochastic exponentials (8.47)-(8.48).
Problem 8.3 1. Et(X) > 0 (a.s.), t ∈R+;
2.
1
Et(X) = Et( ˜X), (a.s.) t ∈R+, where ˜Xt = Xt −
∫t
0 σ2
s ds,
3. If bt = 0 a.s., t ∈R+, then (Et(X))t ≥0 is a (local) martingale;
4. Et(X1)Et(X2) = Et
X1 + X2 + [X1, X2] (a.s.), t ∈R+, where dXi
t = bi
tdt +
σidWt, d[X1, X2]t = σ1
t σ2
t dt, i = 1, 2, and this property is called a multiplication
rule of stochastic exponentials.
We already demonstrated how important and useful the Ito formula. The next
consideration has an incredible meaning for Stochastic Analysis and its applications.
Let us consider a d−dimensional random function bt = (b1
t, . . ., bd
t ) belonging to the
space S (or S2) and deﬁne a new process

8.3
The Ito processes: Formula of changing of variables . . .
103
Zt = exp
!∫t
0
bsdWs −1
2
∫t
0
|bs|2ds
"
= exp
 d

i=1
∫t
0
bi
sdWi
s −1
2
d

i=1
∫t
0

bi
s
2
ds
#
,
(8.49)
Z0 =1.
The process (8.49) satisﬁes the following properties
(1) dZt = ZtbtdWt, Z0 = 1;
(2) (Zt)t ≥0 is a supermartingale, which is a martingale, if (bt)t ≥0 is bounded or
EZt = 1, t ∈R+;
(3) if EZT = 1 for some T > 0, then (Zt)t ≤T is a martingale, and for any sequence
bn ∈S(S2) with the property
∫T
0 |bn −b|2ds →0, n →∞, (a.s.) the corresponding
sequence ZT(bn) converges to ZT(b) in the space L1.
To prove (1) we just apply the Ito formula. For the proof of (2) we consider a
sequence of stopping times
τn = inf

t :
∫t
0
|bs|2Z2
s ds ≥n

and ﬁnd that the process
∫t
0
I(s<τn)bsZsdWs

t ≥0
is a martingale, as well as (Zt∧τn)t ≥0.
For t1 ≤t2 we have (a.s.)
E Zt2∧τn |Ft1
 = Zt1∧τn, n=1,2,...
and as n →∞we get by Fatou’s Lemma that
E(Zt2|Ft1) ≤Zt1 (a.s.),
which certiﬁes that (Zt)t ≥0 is a supermartingale, and therefore
E exp
∫t
0
bsdWs −1
2
∫t
0
|bs|2ds

≤1.
(8.50)
To prove (3) we ﬁrst note that for |bs| ≤K < ∞we derive from (8.50) that

104
8
Elements of classical theory of stochastic processes
E
∫t
0
|bs|2Z2
s ds ≤K2E
∫t
0
Z2
Sds
=K2
∫t
0
EZ2
s (2b) exp
∫t
0
|bu|2du

ds
≤K2
∫t
0
eK2sds < ∞,
and conclude that
∫t
0 bsZsds

t ≥0 and (Zt)t ≥0 are martingales.
The claim (3) follows from claim (2) above, where EZT(b) = 1 and ZT(bn)
P−→
ZT(b), n →∞. As well as E|ZT(bn) −ZT(b)| →0, n →∞, and hence Zt(bn) =
E(ZT(bn)|Ft), t ≤T, a.s. Taking the limit in the above equality as n →∞we get the
martingale property of (Zt(b))t ≤T .
Now we are ready to formulate a beautiful Girsanov Theorem.
Theorem 8.3 Assume (Wt)t ≤T is a Wiener process on a probability space (Ω, F, P).
Let b be a random function from space S (or S2) such that EZT = 1. Deﬁne process
Xt = Wt −
∫t
0 bsds. Then
(1) a random variable ZT deﬁnes a new probability measure ˜P, equivalent to P,
i.e. ˜P << P and P << P with the density ZT = d ˜P
dP ;
(2) The process (Xt) is a Wiener process with respect to ˜P.
Proof. For simplicity, consider a bounded function (bt). For 0 ≤t0 ≤t1 ≤. . . ≤
tn = T and ﬁxed (λj)j=0,...,n−1 from Rd we deﬁne the process λs as iλj on [tj, tj+1).
Further, we obtain that
˜E exp
⎧⎪⎨
⎪⎩
i
n−1

j=0
λj(Xtj+1 −Xtj )
⎫⎪⎬
⎪⎭
=E exp
!∫T
0
λsdWs −
∫T
0
λsbsds
"
ZT(b)
=EZT(λ + b) exp
1
2
∫T
0
λ2
sds

=e1/2
∫T
0 λ2
sds
which corresponds to a Gaussian distribution. Taking into account X0 = 0, we arrive
to the claim (2) of the theorem.
To ﬁnish this section we study the structure of any martingale (Mt)t ≥0 on stochastic
basis (Ω, F, (Ft = F W
t
)t ≥0, P). It turns out, the set of all martingales on the stochastic
basis, generated by a Wiener process (Wt)t ≥0 is determined by stochastic integrals.
Namely, any square integrable martingale (Mt)t ≥0, M0 = 0, admits
Mt =
∫t
0
φsdWs (a.s.), t ≥0,
(8.51)
where (φt)t ≥0 is uniquely deﬁned progressively measurable function from space S2.
The relation (8.51) is called a martingale representation. Let us prove it for a ﬁnite

8.3
The Ito processes: Formula of changing of variables . . .
105
interval [0,T]. For a deterministic function β ∈L2(0,T) we deﬁne the Girsanov
exponent
Zt = Zt(β) = exp
!∫t
0
βudu −1
2
∫t
0
β2
udu
"
, Z0 = 1
Let us note that
Z2
t (β) = Zt(2β)exp
!∫t
0
β2
udu
"
,
and EZt(2β) ≤1 for all t ≤T.
Hence, we obtain
EZ2
t (β) ≤exp
!∫t
0
β2
udu
"
< ∞.
LetX2 be a class of random variables X from the space L2 = L2(Ω, F = F W
T , P) = L2
such that X =
∫T
0 φsdWs with a progressively measurable φ and
∫T
0 Eφ2
sds < ∞.
Further, if Y is an arbitrary random variable from L2 such that EY = 0 and Y ⊥X2 in
the L2-sense, then EY.ZT(β) = 0 for all β ∈L2(0,T). Therefore taking an arbitrary
subdivision (ti), i = 1, ..., n of the interval [0,T] and constructing an arbitrary step
function with (ti), we obtain that E(Y|Wt1, ...,Wtn) = 0. Hence, Y = 0 (a.s.) due to
FT = F W
T . The last step of the proof is clear. We take MT as X ∈X2 and using the
martingale and stochastic integral properties, obtain
Mt = E(MT |Ft) =
∫t
0
φsdWs.

Chapter 9
Stochastic diﬀerential equations,
diﬀusion processes and their applications
Abstract The chapter presents stochastic diﬀerential equations (SDEs) and their
connections with diﬀusion processes and partial diﬀerential equations (PDEs). The
existence and uniqueness of solutions of SDEs are proved under Lipschitz’s con-
ditions. Two important processes (Geometric Brownian Motion (GBM) and the
Ornstein-Uhlenbeck process) are constructed on this theoretical base. The diﬀer-
ence between ordinary diﬀerential equations and SDEs are discussed. As a part of
this discussion, the existence of a solution (weak solution) of any SDE with mea-
surable bounded drift coeﬃcient and unit diﬀusion is proved with the help of the
miracle Girsanov theorem. Moreover, it is shown by mean of the method of mono-
tonic approximations that such a solution will be strong if the grift coeﬃcient is
a bounded piece-wise smooth function. Diﬀusion processes are deﬁned as Markov
processes for which their transition densities satisfy the asymptotic properties of
Kolmogorov. The backward and forward equations of Kolmogorov are derived. A
connection between SDEs and PDEs are stated with the help of the Feynman-Kac
theorem. Absolute continuity of distributions of diﬀusion processes is studied with
the help of the Girsanov theorem. A special attention is paid to the class of controlled
diﬀusion processes for which the Hamilton-Jacobi-Bellman optimality equation is
derived. It is shown how the theory of diﬀusion processes and SDEs are helpful
in mathematical ﬁnance (Bachelier and Black-Scholes models) and in statistics of
random processes (see [3], [5], [14], [17], [21], [22], [23], [24], [25], [30], [35], [39],
[41], [42], and [44]).
9.1
Stochastic diﬀerential equations
Let b(t, x) and σ(t, x) be (t, x)−measurable locally bounded functions from R+ ×
R →R, i.e. these functions are bounded on each compact set of R+ × R.
If a continuous Ft-adapted process X(t, ω) = Xt(ω) such that for all t ≥0 (a.s.)
© The Author(s), under exclusive license to Springer Nature Switzerland AG 2023
A. Melnikov, A Course of Stochastic Analysis, CMS/CAIMS Books in Mathematics 6,
https://doi.org/10.1007/978-3-031-25326-3_9
107

108
9
Stochastic diﬀerential equations, diﬀusion processes and their applications
Xt(ω) = X0(ω) +
∫t
0
b(s, Xs)ds +
∫t
0
σ(s, Xs)dWs,
(9.1)
where X0(ω) is a ﬁnite random variable, measurable w.r. to F0, (Wt)t ≥0 is a Wiener
process, then it is called a solution of (9.1). We rewrite (9.1) in an equivalent
diﬀerential form
dXt = bt(Xt)dt + σt(Xt)dWt.
(9.2)
We say that such a solution is unique if for any other solution ( ˜Xt) we have
P(ω : sup
t
|Xt(ω) −˜Xt(ω)| > 0) = 0.
(9.3)
Theorem 9.1 Assume that coeﬃcients b(t, x) and σ(t, x) of stochastic equations
(9.1)-(9.2) satisfy the conditions:
1) For each T ≥0 there exists a constant kT such that
|b(t, x)| + |σ(t, x)| ≤kT(1 + |x|)
for (t, x) ∈[0,T] × R;
2) For all c > 0 there exists a constant lc > 0 such that
|b(t, x) −b(t, y)| + |σ(t, x) −σ(t, y)| ≤lc|x −y|
for all (t, x) ∈[0, c] × [−c, c].
Then the equation (9.1)-(9.2) admits one and only one solution.
Proof First, we note that conditions 1)-2) of this theorem are called a linear growth
and a local Lipschitz conditions, correspondingly. Second, we give the proof for
a standard Lipschitz condition (lc = l) and for a ﬁnite time interval [0,T], and for
X0(ω) = x ∈R.
Let us prove a uniqueness of solutions. Assume X(t, ω) and ˜X(t, ω) are two
solutions with the initial condition X(0, ω) = ˜X(0, ω) = x. Then we have
˜X(t) −X(t) =
∫t
0

b(s, ˜X(s)) −b(s, X(s))

ds +
∫t
0

σ(s, ˜X(s)) −σ(s, X(s))

dWs.
Further, using the Cauchy-Schwartz inequality and the isometry property, we obtain
for each t ∈[0,T] that

9.1
Stochastic diﬀerential equations
109
E| ˜X(t) −X(t)|2 ≤2E
∫t
0

b(s, ˜X(s)) −b(s, X(s))

ds
2
(9.4)
+ 2E
∫t
0

σ(s, ˜X(s)) −σ(s, X(s))

dWs
2
≤2tE
∫t
0

b(s, ˜X(s)) −b(s, X(s))
2 ds + 2E
∫t
0

σ(s, ˜X(s)) −σ(s, X(s))
2 ds
≤2(t + 1)l2
∫t
0
E| ˜X(s) −X(s)|2ds.
(9.5)
To continue we need the following Gronwall lemma:
If φ(t) ≥0 is an integrable function satisfying inequality for all t ≥0 and ﬁxed
constants A and B :
φ(t) ≤A + B
∫t
0
φ(s)ds.
(9.6)
Then φ(t) ≤AeBt for all t ≥0.
To prove Grownwall lemma we just diﬀerentiate the logarithm of the right hand
side of (9.6):

ln

A + B
∫t
0
φ(s)ds
′
=
Bφ(t)
A + B
∫t
0 φ(s)ds
≤B,
ln

A + B
∫t
0
φ(s)ds

≤ln A + Bt,
A + B
∫t
0
φ(s)ds ≤AeBt.
In relations (9.5) the function φ(t) = E| ˜X(t) −X(t)|2 and A = 0, B = 2(T + 1)l2.
Hence, by the Gronwall lemma we obtain E| ˜X(t) −X(t)|2 = 0. We derive from here
that for the set QT of rational numbers of [0,T] that
P

sup
t ∈QT
| ˜X(t) −X(t)| = 0
	
= 1.
Due to a continuity of processes X(t) and ˜X(t) we have
1 = P(sup
QT
| ˜X(t) −X(t)| = 0) = P( sup
t ∈[0,T]
| ˜X(t) −X(t)| = 0),
which means that X and ˜X are equivalent.
To prove the existence of a solution of (9.1)-(9.2), we apply the Picard method of
successive approximations:

110
9
Stochastic diﬀerential equations, diﬀusion processes and their applications
X0(t) =x,
Xn(t) =x +
∫t
0
b(s, Xn−1(s))ds +
∫t
0
σ(s, Xn−1(s))dWs.
(9.7)
For the sequence of approximations (9.7) we get for t ∈[0,T] that
|Xn(t)|2 ≤3|x|2 + 3




∫t
0
b(s, Xn−1(s))ds




2
+ 3
∫t
0
b(s, Xn−1(s)dWs
2
.
(9.8)
Inequality (9.8) implies for t ≤T that
E|Xn(t)|2 ≤3|x|2 + LT
∫t
0
E|Xn−1(s)|2ds,
(9.9)
where LT depends on kT .
Taking supk ≤n in (9.9) we derive from Gronwall’s Lemma that
sup
k ≤n
E|Xk(t)|2 ≤3|x|2eT LT, t ∈[0,T].
(9.10)
Further, we have that
Xn+1(t) −Xn(t) =
∫t
0

b(s, Xn(s)) −b(s, Xn−1(s))

ds
+
∫t
0

σ(s, Xn(s)) −σ(s, Xn−1(s))

dWs.
and applying a similar estimation as the proof of uniqueness, we get for t ≤T :
E|Xn+1(t) −Xn(t)|2 ≤KT
∫t
0
E|Xn(s) −Xn−1(s)|2ds,
(9.11)
E|X1(t) −X0(t)|2 ≤E
∫t
0
b(s, x))ds +
∫t
0
σ(s, x)dWs
2
≤CTt,
(9.12)
with some constants CT and KT .
Using the induction we derive from (9.11) -(9.12) that
E|Xn+1(t) −Xn(t)|2 ≤CT Kn
T
tn+1
(n + 1)!.
(9.13)
Due to (9.13) we conclude that the series
X0(t) +
∞

n=0

Xn+1(t) −Xn(t)

converges uniformly to continuous process X(t) in the L2-sense.
To prove that this process is a solution of (9.1)-(9.2) we note for t ∈[0,T] that

9.1
Stochastic diﬀerential equations
111
E
∫t
0
[b(s, X(s)) −b(s, Xn(s))] ds +
∫t
0
[σ(s, X(s)) −σXn(s))] dWs
2
≤KT
∫T
0
E|X(s) −Xn(s)|2ds.
Using this inequality, we obtain that
E

X(t) −x −
∫t
0
b(s, X(s))ds +
∫t
0
σ(s, X(s))dWs
2
≤2E|X(t) −Xn(t)|2
+ 2E
∫t
0
b(s, Xn−1(s))ds +
∫t
0
σ(s, Xn−1(s))dWs −
∫t
0
b(s, X(s))ds −
∫t
0
σ(s, X(s))dWs
2
≤2E|X(t) −Xn(t)|2 + 2KT E|X(t) −Xn−1(t)|2 →0,
as n →∞.
⊓⊔
Remark 9.1 To emphasize a dependence of the limit of successive approximations
from an initial point x (correspondently, y) denote it by Xx(t, ω) (correspondently,
Xy(t, ω)). Similar to inequality (9.10) one can derive for t ∈[0,T] :
E|Xx(t) −Xy(t)|2 ≤const(T)|x −y|2et·const(T),
E|Xx(t) −Xx(t + Δt)|2 ≤const(T)|1 + |x|2|2et·const(T).
Due to these inequalities the function Xx(t) can be chosen measurable w.r. to x.
Example 9.1 Consider a linear SDE
dXt = μXtdt + σXtdWt,
(9.14)
where X0 −F0-measurable ﬁnite random variable. According to Theorem 8.1 the
equation (9.14) has a unique solution. To ﬁnd a concrete formula for Xt we rewrite
(9.1) in the form
dXt = (c + σ2/2)Xtdt + σXtdWt,
(9.15)
where c = μ −σ2/2.
Applying the Ito formula to X0 exp{ct + σWt} = ˜Xt we ﬁnd that
d ˜Xt =d

X0ect+σWt

=

cX0ect+σWt + σ2
2 X0ect+σWt

dt + σX0ect+σWt dWt
=

c + σ2
2

˜Xtdt + σ ˜XtdWt.

112
9
Stochastic diﬀerential equations, diﬀusion processes and their applications
So, using the uniqueness of solution of (9.14) we arrive to conclusion that Xt = ˜Xt
(a.s.) for all t ≥0. Hence,
Xt = X0ect+σWt = X0e(μ−σ2/2)t+σWt,
(9.16)
which is called a Geometric Brownian Motion (GBM). The GBM (9.16) is exploited
as a stock price model in mathematical ﬁnance.
Example 9.2 Consider another linear stochastic diﬀerential equation
dXt = −αXtdt + σdWt,
(9.17)
X0 is F0-measurable ﬁnite random variable, α ∈R.
Let us transform (Xt) with the help of function f (t, x) = eαt.x, x ∈R. By the Ito
formula we can ﬁnd a stochastic diﬀerential of Yt = f (t, Xt) :
dYt =( f ′
t −αXt f ′
x + 1
2σ2 f ′′
xx)dt + σ f ′
xdWt
= αeαt Xt −αeαt Xt
 dt + σeαtdWt = σeαtdWt.
It leads to Yt = X0 + σ
∫t
0 eαsdWs and hence
Xt = e−αtYt = e−αt X0 + σe−αt
∫t
0
eαsdWs.
This is a famous Ornstein-Uhlenbeck process, which is called a Vasicek model for
interest rate modeling in mathematical ﬁnance.
We observed here that for SDEs with Lipschitz-type coeﬃcients existence and
uniqueness of solutions are stated in a similar way as for ordinary diﬀerential equa-
tions. A natural question arises:
Are there new results in this theory, which are diﬀerent from the deterministic theory?
We start our answer with the following nice result of Girsanov.
Theorem 9.2 Let b(t, x), (t, x) ∈[0,T] × Rd, d ≥1, be a bounded measurable func-
tion. Then there exists a probability space (Ω, F, P), a continuous process (Xt) and
a Wiener process on this space such that (Xt)t ≤T is a solution of the SDE
dXt = b(t, Xt)dt + dWt, X0 = 0, t ≤T.
(9.18)
Proof Take any probability space (Ω, F, ˜P) with a Wiener process (Xt)t ≤T . Deﬁne
another process
Wt = Xt −
∫t
0
b(s, Xs)ds,
(9.19)
and a new probability measure P with the density w.r.to ˜P:

9.1
Stochastic diﬀerential equations
113
dP
d ˜P = exp
∫T
0
b(s, Xs)dXs −1
2
∫T
0
|b(s, Xs)|2ds.

By the Girsanov theorem, the process (Wt)t ≤T is a Wiener process on the probability
space (Ω, F, P). Hence, if we rewrite the equality (9.19) as
Xt =
∫t
0
b(s, Xs)ds + Wt, t ≤T,
we arrive to conclusion that (Xt)t ≤T is a solution of (9.18).
⊓⊔
Remark 9.2 The result of Theorem 9.2 guarantees existence of a solution of (9.18)
for any bounded measurable function b(t, x). It is well-known that the ordinary
diﬀerential equation dxt = b(t, xt)dt does not admit a solution for any bounded
measurable function b(t, x).
Remark 9.3 Comparing solutions in Theorem 9.1 and 9.2 we can observe the fol-
lowing diﬀerence. The solution in Theorem 9.1 was constructed on given probability
space. On the other hand, the solution in Theorem 9.2 was built on some probability
space. They are naturally called strong and weak solutions, respectively, because any
strong solution will be also a weak solution, but not vice versa.
Example 9.3 Let (βt) be a Brownian Motion (BM) with β0 = y ∈R. Deﬁne a pro-
cess Bt =
∫t
0 sgn(βS)dβs, where
sgn(x) =

1,
x > 0,
−1,
x ≤0.
The process (Bt) is a BM by the Levy characterization. Further, we note that by a
property of stochastic integral
y +
∫t
0
sgn(βs)dBs =y +
∫t
0
(sgn(βs))2dβs
=y +
∫t
0
dβs = y + βt −y = βt.
Hence, (βt) solves the SDE
dXt = sgn(Xt)dBt, X0 = y,
(9.20)
in the “weak” sense. Moreover, any other solution will be again a BM, and in the
sense of its distribution such a solution is unique (weak uniqueness). But taking
y = 0 we ﬁnd that (βt) and (−βt) solve the equation (9.20) with some BM (Bt) and
X0 = 0. It means there is no uniqueness as (9.5).
Let us develop the method of monotonic approximations, which is powerful enough
to prove existence of strong solutions without the Lipschitz conditions. We start with
the simplest version of the comparison theorem of strong solutions of SDEs.

114
9
Stochastic diﬀerential equations, diﬀusion processes and their applications
Lemma 9.1 Assume that bi = bi(x), x ∈R, i = 1, 2, are bounded continuous func-
tions, and Xi, i = 1, 2, are strong (continuous) solutions of the equations
dXi
t = bi(Xi
t )dt + dWt, Xi
0 = 0, t ≥0.
Then the inequality b1(x) < b2(x) for all x ∈R implies that X1
t (ω) ≤X2
t (ω) for
almost all ω ∈Ω and all t ≥0.
Proof For each ω ∈˜Ω, P( ˜Ω) = 1, we deﬁne
θ =

inf{t > 0 : X1
t (ω) = X2
t (ω)},
∞otherwise.
Note that X2
t (ω) −X1
t (ω) =
∫t
0

b2(X2
s (ω)) −b1(X1
s (ω))

ds = Δt(ω). Due to con-
tinuity of bi(x), Xi
t (ω), i = 1, 2, and assumption b1(x) < b2(x), x ∈R, we ﬁnd
that Δ0(ω) > 0, Δt(ω) is continuous and Δt(ω) > 0 for all t < θ(ω). If θ(ω) = ∞,
then X2
t (ω) = X1
t (ω), and Lemma is proved. Otherwise, we have θ(ω) < ∞and
Δθ(ω) = X2
θ −X1
θ = 0. It gives a possibility to reproduce for θ the same consider-
ation as for t = 0 and ﬁnd that X2
t (ω) −X1
t (ω) = Δt(ω) > 0 for a neighborhood of
θ(ω), etc. Therefore, X2
t (ω) −X1
t (ω) = Δt(ω) > 0 for all t ≥0.
⊓⊔
Theorem 9.3 Consider a homogeneous SDE (9.18) and suppose that the drift coef-
ﬁcient bt(x) = b(x) satisﬁes the following conditions:
(1) b(x) has a ﬁnite number of points of discontinuity {x1, . . ., xN };
(2) b(x) is piece-wise smooth, i.e. for any x ∈R \ {x1, . . ., xN } the derivative
b′(x) exists;
(3) |b(x)| and |b′(x)| ≤K < ∞.
Then the equation (9.18) has a strong solution.
Proof The ﬁrst step is to show that b(x) can be approximated by a sequence of
functions bn(x) such that a strong solution of the equations
dXn(t, ω) = bn(Xn(t, ω))dt + dW(t, ω),
(9.21)
Xn(0, ω) = 0, t ∈[0,T], n = 1, 2, . . .,
does exist and is unique. Then the properties of these solutions are studied with
the aim to show that the sequence (Xn(t, ω))n=1,2,... converges to a continuous
Ft−adapted process X∞(t, ω) which is the desired solution of the limit equation
(9.18).
To construct the auxiliary sequence of functions (bn(x))n=1,2,... we take neigh-
borhoods Vr(xi) of the points x1 < . . . < xN of radius r ≤1
4 min1≤i≤N−1 |xi+1 −xi|
and set
˜bn(x) = b(x),
x ∈R \ ∪N
i=1Vr(xi).

9.1
Stochastic diﬀerential equations
115
It suﬃces now to build ˜bn(x) in the neighborhood Vr(xi), i = 1, 2, . . ., N. Consider
Vr(xi) and let b(xi−) > b(xi+) for limits from the left and right side of xi corre-
spondingly.
It follows from the smoothness of b(x) that there exists a deterministic sequence
(αi
n)n=1,2,... such that αi
n ∈Vr(xi), αi
n > xi, αi
n ↓xi as n →∞, while the continuous
function ˜bn(x) is determined as follows
˜bn(x) =b(x) for x ∈Vr(xi) ∩

(xi−1, xi) ∪[αi
n, xi+1)

,
˜bn(xi) =b(xi−),
˜bn(x) is linear on [xi, αi
n] satisfying the condition ˜bn(x) ≥b(x), x ∈(xi, αi
n).
If b(xi−) < b(xi+), the construction of ˜bn(x) in Vr(xi) is analogous. Finally, we
deﬁne bn(x) = ˜bn(x) + 1/n, n = 1, 2, . . ., with desirable properties for us:
bn(x) > bn+1(x), x ∈R,
bn(x) ↓b(x) as n →∞, x ∈R \ {x1, . . ., xN },
bn(x) satisﬁes a Lipschitz condition; and simultaneously for n = 1, 2, . . .
|bn(x)| ≤K + 1 < ∞.
Applying Theorem 9.1 to (9.21) with bn(x), constructed above, we get the existence
(and uniqueness) of strong solutions Xn(t), which are continuous and Ft−adapted.
Further, according to Lemma 9.1 we obtain the system of inequalities
X1(t, ω) ≥X2(t, ω) ≥. . . ≥Xn(t, ω) ≥. . . (a.s.), t ≤T.
Therefore, there exists a Ft-adapted process X∞(t, ω) such that X∞(t, ω) =
limn→∞Xn(t, ω) (a.s.), t ∈[0,T].
⊓⊔
Lemma 9.2 The family of continuous functions (Xn(·, ω))n=1,2,..., ω ∈˜Ω, P( ˜Ω) = 1,
is uniformly bounded and equicontinuous.
Proof For each ω from ˜Ω, P( ˜Ω) = 1, we have for all n = 1, 2, . . . that
|Xn(t, ω)| ≤




∫t
0
bn(Xn(s, ω))ds




 + |W(t, ω)|
(9.22)
≤
∫t
0
|bn(Xn(s, ω))|ds + |W(t, ω)|
(9.23)
≤(K + 1)T + max
0≤t ≤T |W(t, ω)|,
(9.24)
which means that (Xn(·, ω))n=1,2,... is uniformly bounded.
Further, for ω ∈˜Ω, P( ˜Ω) = 1, δ > 0, we obtain

116
9
Stochastic diﬀerential equations, diﬀusion processes and their applications
ωXn(·,ω)(δ) =
sup
s,t, |t−s|<δ
|Xn(t, ω) −Xn(s, ω)|
≤
sup
s,t, |t−s|<δ




∫t
s
bn(Xn(u, ω)du




 + |Wn(t, ω) −W(s, ω)|
≤(K + 1)δ + ωW(·,ω)(δ).
Hence, for almost all ω we have as δ →0 that supn ωXn(·,ω)(δ) ≤(K + 1)δ +
ωW(·,ω)(δ) →0.
In view of Lemma 9.2 and the Ascoli-Arzela test there exists (for ω ∈˜Ω, P( ˜Ω) = 1)
a subsequence n′(ω) such that
sup
0≤t ≤T
|Xn′(ω)(t, ω) −X∞(t, ω)| →0, n′(ω) →∞,
and therefore almost all paths of X∞(t, ω) are continuous on [0,T].
Nowweput φn(t, ω) = bn(W(t, ω)), n = 1, 2, . . ., φ∞(t, ω) = b(W(t, ω)) anddeﬁne
probability measures (Pn)n=1,2,... and P∞with the help of the Girsanov exponents:
dPn
dP = exp
∫T
0
φn(s, ω)dW(s, ω) −1
2
∫T
0
φ2
n(s, ω)ds

,
dP∞
dP = exp
∫T
0
φ∞(s, ω)dW(s, ω) −1
2
∫T
0
φ2
∞(s, ω)ds

.
Problem 9.1 Prove that for y ∈R and t ∈[0,T]
Pn(ω : W(t, ω) ≤y) = P(ω : Xn(t, ω) ≤y),
(9.25)
Pn(ω : W(t, ω) ≤y) −−−−→
n→∞P(ω : W(t, ω) ≤y),
(9.26)
Pn(ω : Xn(t, ω) ≤y) →P(ω : X∞(t, ω) ≤y).
(9.27)
Relations (9.25)-(9.27) yield
P(ω : X∞(t, ω) ≤y) →P∞(ω : W(t, ω) ≤y).
(9.28)
Lemma 9.3 If A is a Borel set in R with the Lebesgue measure zero (l(A) = 0), then
P(ω : l(t ∈[0,T] : X∞(t, ω) ∈A) = 0) = 1.
(9.29)
Proof For ﬁxed ϵ > 0 we ﬁrst apply Chebyshev’s inequality and Fubini’s theorem,
then we use (9.28) to derive that

9.2
Diﬀusion processes and their connection with SDEs and PDEs
117
P(ω : l(t ∈[0,T] : X∞(t, ω) ∈A) > ϵ) ≤ϵ−1E
∫T
0
I(t:X∞(t,ω)∈A)dt
=ϵ−1
∫T
0
EI(t:X∞(t,ω)∈A)dt
=ϵ−1
∫T
0
∫
Ω
I(t:X∞(t,ω)∈A)dP

dt
=ϵ−1
∫T
0
∫
Ω
I(t:W(t,ω)∈A)dP∞

dt
=ϵ−1
∫T
0
P∞(ω : W(t, ω) ∈A)dt = 0.
Since ϵ > 0 is arbitrary, we obtain (9.29).
⊓⊔
Let us deﬁne now the following process
X(t, ω) =
∫t
0
b(X∞(s, ω))ds + W(t, ω)
and consider the diﬀerence
Xn(t, ω) −X(t, ω) =
∫t
0
bn(Xn(s, ω))ds −
∫t
0
b(X∞(s, ω))ds.
Applying Lemma 9.3 with A = {x1, . . ., xN } we ﬁnd for almost all t ∈[0,T] w.r.to
the Lebesgue measure and almost all ω ∈Ω that
lim
n→∞bn(Xn(t, ω)) = b(X∞(t, ω)).
Further, we derive from here by using the Lebesgue dominated convergence theorem
that
∫t
0
bn(Xn(s, ω))ds −−−−→
n→∞
∫t
0
b(X∞(s, ω))ds,
and, hence, for t ∈[0,T] and P-a.s.
X(t, ω) = X∞(t, ω),
which completes the proof of Theorem 9.3.
9.2
Diﬀusion processes and their connection with SDEs and
PDEs
A general conception of a Markov process (Xt)t ≥0 on given stochastic basis
(Ω, F, (Ft)t ≥0, P) can be described as follows. The characteristic (Markov) property

118
9
Stochastic diﬀerential equations, diﬀusion processes and their applications
of such adapted process means that
P(ω : X(t, ω) ∈B|Fs) = P(ω : X(t, ω) ∈B|X(s, ω))
(9.30)
for every B ∈B(R) and all s < t.
It is convenient to treat (9.30) with the help of a transition probability function
P(s, x, t, B) satisfying conditions:
(1) It is a measurable function of x ∈R,
(2) It is a probability measure on (R, B(R)) such that P(s, x, s, B) = IB(x),
(3)
P(s, x, u, B) =
∫
P(s, x, t, dy)P(t, y, u, B).
(9.31)
for x ∈R, B ∈B(R), 0 ≤s < t < u.
The equation (9.31) is called the Kolmogorov-Chapman equation, and the process
(Xt)t ≥0 is a Markov random function (in a restricted sense). Substituting x by X(s, ω)
in (9.30) and using properties of conditional expectations we get
P(s, X(s, ω), u, B) = E(P(t, X(t, ω), u, B)|Fs) =
∫
P(t, y, u, B)P(s, X(s, ω), t, dy)
which coincides with (9.31) under x = X(s, ω)
We know that many properties of stochastic processes can be described using
their
ﬁnite-dimensional distributions. Let us derive the formula of a ﬁnite-
dimensional distribution of (X(t)) in terms of its transition probability function.
Putting Ik = IBk (X(tk, ω)), 0 ≤t1 < t2 < . . . < tk < . . . tn, Bk ∈B(R) we obtain by
backward integration:
P(ω : X(t1, ω) ∈B1, . . ., X(tn, ω) ∈Bn) =EI1 . . . In−1E(In |Ftn−1)
=EI1 . . . In−1
∫
Bn
P(tn−1, X(tn−1, ω), tn, dyn)
=EI1 . . . In−1
∫
Bn−1
P(tn−2, X(tn−2, ω), tn−1, dyn−1)
×
∫
Bn
P(tn−1, X(tn−1, ω), tn, dyn)
=EI1
∫
B2
P(t1, X(t1, ω), t2, dy2) × . . .
×
∫
Bn
P(tn−1, X(tn−1, ω), tn, dyn).
(9.32)
In the expression above we can treat
∫
B2
P(t1, X(t1, ω), t2, dy2) . . .
∫
Bn
P(tn−1, X(tn−1, ω), tn, dyn)
(9.33)

9.2
Diﬀusion processes and their connection with SDEs and PDEs
119
as a conditional expectation
P(ω : X(t2, ω)) ∈B2, . . ., X(tn, ω) ∈Bn|X(t1, ω) = x1).
The expressions (9.32)-(9.33) present a consistent system of ﬁnite-dimensional dis-
tributions of the process X(t, ω) for ﬁxed t1 and x1. So, to provide a full description
of this system it is reasonable to have a family of probability spaces (Ω, F, Pt,x).
So, in case (9.32)-(9.33) we arrive to the probabilities Pt,x(ω : X(t2, ω) ∈B2, . . .,
X(tn, ω) ∈Bn) expressed with the help of P(s, x, t, B). We also can see that the
process X(t, ω) can be started at each t ∈R+ from each point x ∈R. The process
(X(t, ω)) in such a framework is called a Markov family, but we will call it also a
Markov process. All these arguments speak us that in the theory of Markov processes
it is necessary to describe the class of transition probability functions.
Before further steps in developments of this theory we give some examples and
problems.
First of all, (Wt)t ≥0 presents an example of a Markov process, because its ﬁnite-
dimensional distributions were given in its deﬁnition via transition probability func-
tion.
Problem 9.2 Prove that (|Wt|)t ≥0 is a Markov process.
Hint. Its transition function:
P(s, x, t, B) =
1

2π(t −s)
∫
B

e−(y−x)2
2(t−s) + e
(y+x)2
2(t−s)

dy
Example 9.4 Let (Yn)n=1,2,... be a sequence of independent random variables with
a positive density p(x). Deﬁne X0 = 0, X1 = Y+
1 , X2 = (Y1 + Y2)+, . . . The process
(Xn)n=0,1,... is non-Markov. To show it we take x > 0 and consider the next conditional
probability
P(ω : X3 > 0|X2 = 0, X1 = x) =
∫0
−∞
∫∞
0
p(y −x)p(z −y)dydz.
This probability depends on x, and therefore, the process (Xn) can not be Markov.
Problem 9.3 Let (Yn)n=1,2,... be a sequence of independent r.v.’s with the density
p(x) > 0, x ∈R. Deﬁne the process (Y0 = 0)
Xt = (Y1 + . . . + Yk)(t −k) + (Y1 + . . . + Yk+1)(k + 1 −t)
for k ≤t ≤k + 1, t ≥0. Prove that such a process is not Markov.
Remark 9.4 The transition probability function P(s, x, t, B) is homogeneous, if
P(s + h, x, t + h, B) = P(s, x, t, B) for any positive h. Hence, P(·, ·, ·, ·) depends on
the diﬀerence (t −s) only and one can use another transition probability function
P(t, x, B) for which the Kolmogorov-Chapman equation has the form

120
9
Stochastic diﬀerential equations, diﬀusion processes and their applications
P(t + s, x, B) =
∫
R
P(t, x, dy)P(s, y, B).
Deﬁnition 9.1 Markov process X(t, ω) with its transition probability function
P(s, x, t, B) satisfying the properties (1)-(3) is called a diﬀusion process, if there
exist measurable functions b(t, x) and σ2(t, x), (t, ) ∈R+ × R such that for ϵ > 0 and
Vϵ = {y ∈R : |y −x| > ϵ}
lim
h→0
1
h P(t, x, t + h,Vϵ) = 0,
(9.34)
lim
h→0
1
h
∫
|y−x |≤ϵ
(y −x)P(t, x, t + h, dy) = b(t, x),
(9.35)
lim
h→0
1
h
∫
|y−x |≤ϵ
(y −x)2P(t, x, t + h, dy) = σ2(t, x).
(9.36)
Functions b(t, x) and σ2(t, x) are called drift and diﬀusion coeﬃcients.
It turns out relations (9.34)-(9.36) admit an adequate charazterization with the
help of the following diﬀerential operator (generator of X(t, ω)):
Ltφ(x) = a(t, x)∂φ(x)
∂x
+ 1
2σ(t, x)∂2φ(x)
∂x2
.
(9.37)
in class of twice continuously diﬀerentiable functions φ.
Lemma 9.4 For all bounded functions φ described above
∫
R
|φ(y) −φ(x)|P(t, x, t + h, dy) = hLtφ(x) + o(h)
(9.38)
is fulﬁlled ⇐⇒(9.34)-(9.36).
Proof To prove (9.38), we decompose function φ at point x : for |y −x| < ϵ
∫
R
|φ(y) −φ(x)|P(t, x, t + h, dy) = αϵ(h) + hLtφ(x) + hγϵ,
where Lt is deﬁned by (9.37), αϵ(h)h−1 →0, ϵ > 0, and γϵ →0 as ϵ →0.
Hence, we get (9.38). To prove the direct implication we take the function φx0(x) =
1 −exp −|x −x0|4 and ﬁnd that
∂
∂x φx0(x)|x=x0 = 0 and
∂2
∂x2 φx0(x)|x=x0 = 0.
It implies (9.34).
Now we take function φx0(y) = y −x0 for |y −x0| < 1 extending this function to
be a bounded twice continuously diﬀerentiable function. For such a function and
0 < ϵ < 1 we get
∫
|y−x0 |≤ϵ
(y −x0)P(t, x0, t + h, dy) = a(t, x)h + o(h)
(9.39)

9.2
Diﬀusion processes and their connection with SDEs and PDEs
121
and hence (9.35). To prove (9.36) we take a square of function in the previous
construction (9.39).
⊓⊔
Let us ﬁnd diﬀerential equations for transition probabilities of diﬀusion processes,
known as the Kolmogorov backward and forward equations.
For some bounded continuous function φ(x) and T > 0 we deﬁne the following
function
uT(t, x) =
∫
R
φ(y)P(t, x,T, dy).
Theorem 9.4 Assume that (9.34)-(9.36) are uniformly satisﬁed on bounded time
intervals with continuous functions b(t, x) and σ2(t, x). Let function uT(t, x) be (t, x)-
continuous together with derivatives ∂uT
∂x and ∂2uT
∂x2 . Then uT(t, x) has the derivative
w.r.to t and satisﬁes the equation
∂uT(t, x)
∂t
+ LtuT(t, x) = 0,
(9.40)
with the boundary condition uT(T, x) = φ(x).
Proof The boundary condition is fulﬁlled due to (9.34). Further, for h > 0 we have
by Lemma 8.4 that
uT(t −h, x) =
∫
R
uT(t, y)P(t −h, x, t, dy)
=uT(t, x) +
∫
R
[uT(t, y) −uT(t, x)] P(t −h, x, t, dy)
=hLt−huT(t, x) + uT(t, x) + o(h),
whence
1
h [uT(t −h, x) −uT(t, x)] = Lt−huT(t, x) + o(h)
h .
This implies (9.40).
⊓⊔
In fact, the equation (9.40) can be called as the Kolmogorov backward equation. But
usually it is formulated as the equation for the density p(s, z, t, y) of the transition
probability function P(s, x, t, B) :
p(s, x, t, y)dy = P(s, x, t, dy).
So, we arrive to the backward Kolmogorov equation for p(s, x, t, y) :
∂p(s, x, t, y)
∂s
+ b(s, x, )∂p(s, x, t, y)
∂x
+ σ2(s, x)
2
∂2p(s, x, t, y)
∂x2
= 0.
(9.41)
On the other hand, one can write also the forward Kolmogorov equation or the
Fokker-Planck equation:
∂p(s, x, t, y)
∂t
+ ∂
∂y (b(t, y)p(s, x, t, y)) −σ2
2∂y2

σ2(t, y)p(s, x, t, y)

= 0.
(9.42)

122
9
Stochastic diﬀerential equations, diﬀusion processes and their applications
So, the same function p(s, x, t, y) plays the role a fundamental solution for two
diﬀerential equations:
(9.41) as the function of (s, x) and
(9.42) as the function of (t, y).
Let us come back to the stochastic diﬀerential equation (9.1) and its solution X(t)
derived under the Lipschitz conditions in Theorem 9.1. Applying the same reasoning
as in Theorem 9.1 we can prove that there exists a unique solution Xs,x(t) of the
equation (t ≥s) :
Xs,x(t) = x +
∫t
s
b(u, Xs,x(u))du +
∫t
s
σ(u, Xs,x(u))dWu.
(9.43)
Putting for B ∈B(R)
P(s, x, t, B) = P(Xs,x(t) ∈B),
(9.44)
we arrive to conclusion that the solution X(t) of (9.1) is a Markov process with the
transition probability function (9.44).
To prove this claim we note that Xs,X(s)(t) is a solution of (9.43). We just note
from (9.1) and Remark 9.1 that
X(t, ω) −X(s, ω) =
∫t
s
b(u, X(u, ω)du +
∫t
s
σ(u, X(u, ω)dWu.
Thus, X(t, ω) = Xs,X(s,ω)(t). Further, the σ-algebra Fs is generated by Wu, u ≤s.
Let us take arbitrary bounded Fs-measurable r.v. θ. Then for any bounded function
g(x) we obtain that
Eθg(X(t, ω)) =Eθg Xs,X(s,ω)(t)
=EθE g Xs,x(t)
x=X(s,ω)
=Eθ
∫
R
g(y)P(s, x, t, dy)

x=X(s,ω)
=Eθ
∫
R
g(y)P(s, X(s, ω), t, dy),
where we used the independence of Xs,x(t) and Fs because Xs,x(t) depends on
W(u) −W(s) for u ≥s only. Hence,
E(g(X(t, ω))|Fs) =
∫
R
g(y)P(s, X(s, ω), t, dy),
and we get the claim.
Remark 9.5 As a methodological result one can conclude that diﬀusion processes
are described in two ways: as a class of Markov processes with transition probabilities
determined by the drift and diﬀusion coeﬃcients and as solutions of SDEs. Let us
discuss other interesting connections. We consider a stochastic diﬀerential equation

9.2
Diﬀusion processes and their connection with SDEs and PDEs
123
with coeﬃcients b = b(t, x) and σ = σ(t, x) :
dXt = b(t, Xt)dt + σ(t, Xt)dWt.
As before, we deﬁne the following diﬀerential operator based on functions b and σ :
Lφ = 1
2σ2 ∂2φ
∂x2 + b∂φ
∂x .
Having a smooth function F ∈C1,2 we can transform (Xt) with the help of the Ito
formula as follows
F(Xt) = F(X0) +
∫t
0
 ∂F
∂s + LF(Xs)

ds +
∫t
0
σ(s, Xs)∂F
∂x (Xs)dWs.
(9.45)
Equality (9.45) is a smooth transformation of the diﬀusion process (Xt). Such a
problem was ﬁrst formulated and solved by Kolmogorov in 1931: a new process
Yt = F(Xt) will be again a diﬀusion process with the drift bY = ∂F
∂t + LF(Xt) and
the diﬀusion coeﬃcient σY = σ ∂F
∂x (Xt). Putting together both these formulas we
arrive to the Ito formula in the form (9.45). That’s why the formula (9.45) can be
also called the Kolmogorov-Ito formula.
Remark 9.6 We can also put the Cauchy problem for the parabolic diﬀerential
equation: ﬁnd a smooth function v = v(t, x) : [0,T] × R →R such that
∂v
∂t + Lv = 0, (t, x) ∈[0,T] × R
with v(T, x) = f (x), x ∈R.
This boundary value problem is solved in the theory of partial diﬀerential equa-
tions (PDEs) under wide conditions. It turns out one can write a probabilistic form
of this solution using the theory of diﬀusion processes. We take a diﬀusion process
(Xt) with a generator L and
v(t, x) = Et,x f (XT), Xt = x.
(9.46)
To get formula (9.46), called the Feynman-Kac representation, we apply the Ito
formula to v(t, Xt) and obtain that
dv(t, Xt) =
 ∂v
∂t + Lv

dt + σ ∂v
∂x dWt.
It is clear that v(t, Xt) is a martingale, and therefore
v(t, Xt) = E( f (XT)|Ft) = Et,x f (XT)



x=Xt .
Let us investigate absolute continuity of distributions of diﬀusion processes. We
shall do it in the form of solutions of stochastic diﬀerential equations.

124
9
Stochastic diﬀerential equations, diﬀusion processes and their applications
Assume (X(t))t ≤T is a continuous random process on a probabilistic space
(Ω, F, P). Denote C[0,T] the space of continuous functions on [0,T] and B[0,t]
is a σ-algebra in this space, generated by cylinders. We deﬁne a distribution of
(X(t))t ≤T as the measure on (C[0,T], B[0,T])
μX(B) = P{ω : X(·, ω) ∈B}.
It means that the measure μX is just an image of P under mapping
X(·, ω) : Ω →C[0,T].
Assume, there is a probability measure ˜P << P, i.e. for A ∈F
˜P(A) =
∫
A
Z(ω)dP,
where Z is a measurable non-negative random variable such that
∫
Ω
Z(ω)dP = 1.
We can consider the process (Xt)t ≤T under a new measure ˜P, and denote this process
( ˜Xt)t ≤T . Then
dμ ˜X
dμX
(X(·, ω)) = E(Z(ω)|F X),
(9.47)
where F X is a σ-algebra, generated by the process (Xt)t ≤T . The equality (9.47) is
almost obvious because for A ∈B[0,T] we have
μ ˜X(A) = ˜P(ω : X(·, ω) ∈A)
=
∫
A
Z(ω)dP
=EZ(ω)IA(X(·, ω))
=EIA(X(·, ω))E(Z(ω)|F X)
=
∫
A
E(Z(ω)|F X)μX(dx).
Assume that two diﬀusion processes (Xi(t))t ≤T, i = 1, 2, satisfy the following stochas-
tic diﬀerential equations
dXt(t) =bi(t, Xi(t))dt + σ(t, Xi(t))dWt,
Xi(0) =x ∈R.
(9.48)
Theorem 9.5 Assume the coeﬃcients of equations (9.48) are bounded and satisfy
the Lipschitz conditions, and there exists a bounded continuous function θ = θ(t, x)
such that σ(t, x) > 0 and

9.2
Diﬀusion processes and their connection with SDEs and PDEs
125
b2(t, x) −b1(t, x) = θ(t, x)σ(t, x),
(t, x) ∈[0,T] × R. Then μX2 << μX1 and
dμX2
dμX1
(X1(·, ω)) = exp
∫T
0
θ(s, X1(s))dWs −1
2
∫T
0
θ2(s, X1(s))ds

.
(9.49)
Proof Obviously, we can apply here the Girsanov theorem with the measure ˜P and
Z(ω) = d ˜P
dP = exp
∫T
0
θ(s, X1)dWs −1
2
∫T
0
θ2(s, X1)ds

,
and due to boundedness of coeﬃcients EZ(ω) = 1.
Hence, ˜P(Ω) = 1 and the process
˜W(t) = W(t) −
∫t
0
θ(s, X1(s))ds
is a Wiener process w.r. to ˜P.
Let us rewrite the process (X1(t))t ≤T as follows, using (9.5):
X1(t) −x =
∫t
0
b1(s, X1)ds +
∫t
0
σ(s, X1)dWs
=
∫t
0
b1(s, X1)ds +
∫t
0
σ(s, X1)

d ˜Ws + θ(s, X1)ds

=
∫t
0
[b1(s, X1) + θ(s, X1)σ(s, X1)] ds +
∫t
0
σ(s, X1)d ˜Ws
=
∫t
0
b2(s, X1)ds +
∫t
0
σ(s, X1)d ˜Ws.
.
(9.50)
Representation (9.50) certiﬁes that (X1(t))t ≤T coincides with the solution of the
equation
d ˜X2(t) = b2(t, ˜X2(t))dt + σ(t, ˜X2(t))d ˜Wt
on the space (Ω, F, ˜P). Hence, distributions μ ˜X2 and μX2 are the same, and applying
(9.47) we obtain
dμX2
dμX1
(X1(·, ω)) = E

Z(ω)|F X1

.
(9.51)
Let us prove that Z(ω) is F X1-measurable and therefore the formula (9.49) is fulﬁlled.
To establish it we represent θ(t, x) as follows
θ(t, x) = b2(t, x) −b1(t, x)
σ(t, x)

126
9
Stochastic diﬀerential equations, diﬀusion processes and their applications
due to assumption σ(t, x) > 0 for (t, x) ∈[0,T] × R. Further, for a subdivision
0 = s0 < s1 < . . . < sn = t we have (in the sense of convergence in probability) that
Wt = lim
n→∞
n−1

i=0
σ−1(si, X1(si))

X1(si+1) −X1(si) −
∫si+1
si
b1(s, X1(s))ds

.
(9.52)
The relation (9.52) follows from observation that
n−1

i=0
σ−1(si, X1(si))

X1(si+1) −X1(si) −
∫si+1
si
b1(s, X1(s))ds

=
n−1

i=0
σ−1(si, X1(si))σ(s, X1(s))dWs,
which due to continuity of coeﬃcients tends to Wt in probability as maxi Δsi →0
by properties of stochastic integrals.
⊓⊔
Example 9.5 Consider processes Wt, Xt = 10 + Wt and Yt = 3Wt, t ∈[0, 1]. Let us
deﬁne a functional on C[0, 1], f (x(·)) = x(0). For the process Xt this functional
takes value 10 with probability 1, but for other processes Wt and Yt this functional
takes value 0 with probability one. Hence, μX is singular w.r.to μW and μY. We also
note that μW and μY are singular too. It follows from the fact that in probability
n
i=1(Wti −Wti−1)2 →1 as the diameter of subdivision 0 = t0 < t1 < . . . < tn = 1
tends to 1. A similar limit for (Yt) will be equal to 9.
Remark 9.7 As it was noted in Remark 8.3 for Ito’s processes, a similar theory of
stochastic diﬀerential equations with a multidimensional Wiener process, a vector-
valued coeﬃcient band a matrix-valued coeﬃcient σ can be developed. Respectively,
it is connected with diﬀusion processes with a vector-valued drift b, a matrix-valued
diﬀusion a = σσ∗and a generator Lu = 
i bi ∂u
∂xi + 1
2

i,j aij
∂2u
∂xi∂x j .
9.3
Applications to Mathematical Finance and Statistics of
Random Processes
In ﬁnancial context, a Wiener process was mathematically introduced and developed
by L. Bachelier. His model of price evolution of stocks has the following simple
form:
St = S0 + μt + σWt, t ≤T,
(9.53)
where μ ∈R, σ > 0, and (Wt) is a Wiener process on given stochastic basis
(Ω, F, (F W
t
), P).
Besides price dynamics of a risky asset (9.53) we assume for simplicity that
evolution of non-risky asset (bank account) is trivial, i.e. Bt = 1.

9.3
Applications to Mathematical Finance and Statistics of Random Processes
127
One of the main subject of Mathematical Finance is option pricing. We consider
only standard and the most exploited contracts which are called Call and Put options.
These derivative securities (or simply, derivatives) give the right to the holder to buy
(Call option) and to sell (Put option) a stock at maturity time T. To get such a
derivative it is necessary to buy it by some price at time t ≤T. Denote such prices
for call and put options for t = 0 by CT and PT, correspondently. It is convenient
to identify these options with their pay-oﬀfunctions at maturity time as (ST −K)+
and (K −ST)+. The problem is to ﬁnd so-called fair price CT(PT) in the beginning
(t = 0) of the contract period. According to the theory of option pricing such a price
CT (PT) is calculated as E∗(ST −K)+ (correspondingly, E∗(K −ST)+), where E∗is
the expectation with respect to a measure P∗such that the process (St)t ≤T is a P∗-
martingale. In case of the model (9.53) such martingale measure P∗is determined
by the Girsanov exponent
Z∗
T = exp

−μ
σWT −1
2
 μ
σ
2
T

,
and according to the Girsanov theorem, the process
W∗
t = Wt + μ
σ t
is a Wiener process w.r. to P∗. Hence, for distributions LawP∗and LawP w.r. to
measures P∗and P relatively we have equality
LawP∗(S0 + μt + σWt; t ≤T) = LawP(S0 + σWt; t ≤T).
(9.54)
Theorem 9.6 In the framework of the Bachelier model (9.53) the initial price of a
call option is determined by the formula
CT = (S0 −K)Φ
 S0 −K
σ
√
T

+ σ
√
Tφ
 S0 −K
σ
√
T

,
(9.55)
where Φ(x) =
∫x
∞φ(y)dy, φ(x) =
1
√
2π e−x2/2.
In particular, for S0 = K we have CT = σ

T
2π .
To prove (9.55) we use (9.54) and self-similarity property of (Wt) and rewrite CT
as follows
CT =E∗(ST −K)+ = E∗(S0 + μT + σWT −K)+ =
=E∗(S0 + σWT −K)+ = E∗(S0 + σ
√
TW1 −K)+
=E∗(S0 −K + σ
√
Tξ)+
(9.56)
where W1 = ξ ∼N(0, 1).

128
9
Stochastic diﬀerential equations, diﬀusion processes and their applications
Denote a = S0 −K and b = σ
√
T and obtain form (9.56) that
CT =E(a + bξ)+ =
∫∞
−a/b
(a + bx)φ(x)dx
=aΦ(a/b) + b
∫∞
−a/b
xφ(x)dx
=aΦ(a/b) −b
∫∞
−a/b
dφ(x)
=aΦ(a/b) + bφ(a/b)
=(S0 −K)Φ
 S0 −K
σ
√
T

+ σ
√
Tφ
 S0 −K
σ
√
T

.
Moreover, using the Markov property of (St) we can ﬁnd the price of call option
C(t, St) at any time t ≤T taking conditional expected value of (ST −K)+ with respect
to Ft :
C(t, St) =E∗(ST −K)+|Ft

=E∗(ST −K)+|St

=Et,x(ST −K)+


St=x
=E(at + btξ)+
=atΦ(at/bt) + btφ(at/bt),
where at = St −K, b = σ
√
T −t.
Therefore,
C(t, St) = (St −K)Φ
 St −K
σ
√
T −t

+ σ
√
T −tφ
 St −K
σ
√
T −t

.
(9.57)
Applying the Ito formula in (9.57) and using a martingale property of E∗((ST −
K)+|Ft) we arrive to
dC(t, St) = ∂C
∂St
dSt +
 ∂C
∂t + 1
2σ2 ∂2C
∂S2
t

dt
and a PDE
∂C
∂t (t, x) + 1
2σ2 ∂2C(t, x)
∂x2
= 0.
(9.58)
with the boundary condition
C(T, x) = (x −K)+.
The equation (9.58) gives the opportunity to apply methods of PDEs in pricing of
option.

9.3
Applications to Mathematical Finance and Statistics of Random Processes
129
Remark 9.8 As far as the put price PT it follows from the put-call parity: for r = 0
CT = PT + S0 −K.
(9.59)
The parity (9.59) follows from the next elementary equality
(x −K)+ = (K −x) + x −K, x, K ≥0.
(9.60)
Putting ST instead of x in (9.60), and taking expected value w.r.to P∗we arrive to
(9.59).
The Bachelier model (9.53) has at least one disadvantage that prices can take
negative values that contradicts their ﬁnancial sense. To make a reasonable improve-
ment of the model P. Samuelson (1965) proposed to transform (9.53) with the help
of an exponential function. The resulting model
St = S0 exp

(μ −σ2/2)t + σWt

(9.61)
became the name of Geometric Brownian Motion (GBM).
Applying the Ito formula to (9.61) we get
dSt = St(μdt + σdWt), S0 > 0.
(9.62)
The model of ﬁnancial market in the form (9.62) is called the Black-Scholes
model. As in case of the Bachelier model, we assume here Bt = 1 for simplicity.
As in the case of the Bachelier model, we use the Girsanov theorem with the same
Girsanov exponent Z∗
T, the martingale measure P∗and a Wiener process W∗
t w.r. to
P∗we can conclude that
LawP∗(σWt, t ≤T) = LawP∗(σW∗
t , t ≤T) = LawP(σWt, t ≤T)
and, hence,
LawP∗(St; t ≤T) = LawP

S0e−σ2/2t+σWt,t ≤T 
.
It gives a possibility to calculate the price CT of a Call option (ST −K)+ in the model
(9.62) taking expected value w.r. to P∗:
CT =E∗(ST −K)+ = E(S0e−σ2/2T+σWT −K)+
=E(S0e−σ2/2T+σ
√
TW1 −K)+
=E(aebξ−b2/2 −K)+
=aΦ

ln( a
K ) + 1
2b2
b
	
−KΦ

ln( a
K ) −1
2b2
b
	
,
(9.63)
where ξ ∼N(0, 1), a = S0, b = σ
√
T.
The formula (9.63) is the famous formula of Black and Scholes for call option. A
similar formula for put option is derived with the help of put-call parity.

130
9
Stochastic diﬀerential equations, diﬀusion processes and their applications
Example 9.6 To recognize how close prices of call options in the model of Bachelier
and the model of Black and Scholes we consider the simplest equations for them:
dSB
t =S0σdWt,
dSBS
t
=SBS
t
σdWT, t ≤T, σ > 0.
We put S0 = K, and in this case we compare prices CB
T and CBS
T , for which
0 ≤CB
T −CBS
T
≤
S0
12
√
2π
σ3T3/2 = O((σ
√
T)3).
(9.64)
To prove (9.64) we note the following inequalities: ey ≥1 + y for all y, and, hence,
y2/2 ≥1 −e−y2/2 for all y. Using these inequalities we obtain that
0 ≤CB
T −CBS
T
=
 S0
√
2π
x −S0

Φ
 x
2

−Φ

−x
2

x=σ
√
T
= S0
√
2π
∫x/2
−x/2

1 −e−y2/2
dy

x=σ
√
T
≤S0
√
2π
∫x/2
−x/2
y2/2dy



x=σ
√
T
= S0
√
2π
x3/12



x=σ
√
T
=
S0
12
√
2π
σ3T3/2 = O((σ
√
T)3).
Assuming σ
√
T << 1 in (9.64) we can observe that call prices in both models
are pretty close to each others. In particular, for T = 1/2 and σ = 2.4% we obtain
(σ
√
T)3 ≃5 · 10−7 and, therefore,
S0
12
√
2π −5 · 10−7 ≃1.6 · 10−8S0.
Let us show how methods of stochastic processes work in solving of statistical
problems.
Assume that the observation process has the following structure
Xt =
∫t
0
fsdsθ + Wt,
(9.65)
where ( ft)t ≥0 is a progressively measurable process for which P(ω :
∫t
0 f 2
s ds < ∞) =
1, t ≥0, θ ∈R is an unknown parameter to be estimated based on observations of
the process (Xt)t ≥0, and (Wt)t ≥0 is a Wiener process.
The model (9.65) is a continuous time version of of a regression model in discrete
time. So, it is quite natural to use the least squares estimates for estimation of θ. In
the case of model (9.65) such estimate has the following structure

9.3
Applications to Mathematical Finance and Statistics of Random Processes
131
θt =
∫t
0
f 2
s ds
−1 ∫t
0
fsdXs.
We need to investigate some properties of estimates (9.3). We demonstrate it in
the form of the following example.
Example 9.7 Assume that (a.s)
0 < c2 ≤f 2
t (ω) ≤C2 < ∞,
(9.66)
for every t > 0. We can provide a “stochastic representation” of θt using (9.65) as
follows
θt =
∫t
0
f 2
s ds
−1 ∫t
0
fsdXS
=
∫t
0
f 2
s ds
−1 ∫t
0
f 2
s dsθ +
∫t
0
f 2
s ds
−1 ∫t
0
fsdWs,
and ﬁnd that
θt −θ =
∫t
0
f 2
s ds
−1 ∫t
0
fsdWs.
(9.67)
Using representation (9.67), condition (9.66) and the Chebyshev inequality, we obtain
for ϵ > 0 that
P(ω : |θt −θ| ≥ϵ) ≤ϵ−2E
∫t
0
f 2
s ds
−1 ∫t
0
fsdWs
	2
≤ϵ−2c−4t−2E
∫t
0
fsdWs
2
=ϵ−2c−4t−2E
∫t
0
f 2
s ds
≤ϵ−2c−4t−2C2t
=ϵ−2 C2
c4 t−1 →0,
t →∞.
It means that θt is a consistent estimate of parameter θ.
Example 9.8 The least square estimate (9.3) is consistent, as was shown in the
previous Example, but it does not speak us about the accuracy of these estimates.
One can modify them with the help of a specially chosen stopping times to get an
estimate with ﬁxed accuracy. To do this we ﬁx a positive number H and deﬁne
τH = inf

t :
∫t
0
f 2
s ds ≥H

.
Assume
∫t
0 f 2
s ds →∞(a.s.) as t →∞, to prove that

132
9
Stochastic diﬀerential equations, diﬀusion processes and their applications
P(ω : τH(ω) < ∞) = 1.
Further, deﬁne a sequential least squares estimate
ˆθH = H−1
∫τH
0
fsdXs.
(9.68)
It follows from (9.68) that
E ˆθH =H−1E
∫τH
0
fsdXs
=H−1E
∫τH
0
f 2
s dsθ + H−1E
∫τH
0
fsdWs
=H−1Hθ + H · 0 = θ.
So, the estimate ˆθH is unbiased.
To estimate the accuracy of ˆθH we use its variance:
Var ˆθH =E( ˆθH −θ)2
=E

H−1
∫τH
0
fsdXs −θ
2
=H−2E
∫τH
0
fsdWs
2
=H−2E
∫τH
0
f 2
s ds
=H−2 · H = H−1.
(9.69)
The relation (9.69) shows that accuracy of the estimate ˆθH can be controlled with
the help of the level H.
9.4
Controlled diﬀusion processes and applications to
option pricing
Suppose there is a family of diﬀusion processes Xt = Xα
t
satisfying a stochastic
diﬀerential equation
dXt := dXα
t = bα(t, Xα
t )dt + σα(t, Xα
t )dWt, X0 = x.
(9.70)
Here bα and σα are functions satisfying some reasonable conditions for existence
and uniqueness of solutions of (9.70). Parameter α is a control process adapted to

9.4
Controlled diﬀusion processes and applications to option pricing
133
ﬁltration (Ft)t ≥0. The equation (9.70) is also called a stochastic control system. We
will call the process (Xt) a controlled diﬀusion process.
For estimating the quality of control α we introduce a function f α(t, x), (t, x) ∈
R+ × R. The process α takes values in a domain D ⊆R. Function f α can be inter-
preted as the density of the value ﬂow. Then the total value on the interval [0, t] will
be identiﬁed with
∫t
0 f α(Xα
s )ds which is assumed to be well deﬁned.
Let us put the problem and provide some heuristic explanations of its solution for
a time homogeneous stochastic control system (9.70). Denoting
vα(x) = E0,x
∫∞
0
f α(Xα
s )ds

= Ex
∫∞
0
f α(Xα
s )ds

,
we deﬁne the optimal control α∗, if
v(x) = sup
α
vα(x) = vα∗(x), x ∈R.
(9.71)
In the theory of controlled diﬀusion processes the following Hamilton-Jacobi-
Bellman principle of optimality is exploited to determine v(x) :
v(x) = sup
α
Ex
∫t
0
f α(Xα
s )ds + v(Xα
t )

.
(9.72)
Let us explain a motivation for using (9.72). We rewrite the total value using strategy
(control) α on [0, ∞) as follows
∫∞
0
f α(Xα
s )ds =
∫t
0
f α(Xα
s )ds +
∫∞
t
f α(Xα
s )ds.
(9.73)
If this strategy was used only up to moment t, then the ﬁrst term in the right-hand
side of (9.73) represents the value on the interval [0, t]. Suppose the controlled
process Xα
t = Xt has the value y = Xt at time t. If we wish to continue the control
process after time t with the goal of maximization of the value over the whole time
interval [0, ∞), then we have to maximize Ey
∫t
0 f α(Xα
s )ds

, where α also denotes
the continuation of the control process to [t, ∞). Changing variable s = t + u, u ≥0,
and using independence and stationarity of increments of the Wiener process W, we
obtain
EXt
∫∞
0
f α(Xα
s )ds = vα(Xt) ≤v(Xt).
Thus, a strategy that is optimal after time t, gives the average value such that
Ex
∫t
0
f α(Xα
s )ds ≥vα(x).
(9.74)
One can choose αs, s ≤t, so that the corresponding value is close enough to the
average value. Therefore, taking supremum of both sides (9.74), we arrive to the
HJB-principle of optimality (9.72), and we will call v(x) the value function.

134
9
Stochastic diﬀerential equations, diﬀusion processes and their applications
Moreover, one can rewrite (9.72) in a diﬀerential form if the value function is
smooth enough. Applying the Ito formula, we obtain
v(Xt) = v(x) +
∫t
0
 ∂v
∂x bα(Xs) + 1
2σ2
α
∂2v
∂x2 (Xs)

ds +
∫t
0
σα
∂v
∂x (Xs)dWs. (9.75)
Since the last term in the right-hand side of (9.75) is a martingale, then we get
from (9.72) that
v(x) = sup
α
Ex
∫t
0
 ∂v
∂x bα(Xs) + σ2
α
2
∂2v
∂x2 (Xs) + f α(Xs)

ds + v(x)

,
and hence,
sup
α
[Lαv(x) + f α(x)] = 0,
(9.76)
where Lαv = bα ∂v
∂x + 1
2σ2
α
∂2v
∂x2 .
The equation (9.76) is usually referred to as HJB-diﬀerential equation.
Keeping in mind an adequate application of stochastic control theory in option
pricing we would like reformulate it for the inhomogeneous case and for a ﬁnite
interval time [0,T]. We consider the following stochastic control system
dXs =bα(s, Xs)ds + σα(s, Xs)dWs,
Xt =x, s ∈[t,T],
(9.77)
where α is a D-valued adapted process. Then the optimal control problem is to
maximize (minimize) the value function
vα(t, x) =Et,x
∫T
t
f α(s, Xs)ds + g(XT)

,
v(t, x) = sup
α
vα(t, x),
(9.78)
where Xs = Xα
s satisﬁes (9.77) and function g determines the terminal value.
For system (9.77) with the value function (9.78) the corresponding HJB-equation
is derived in the form
∂v(t, x)
∂t
+ sup
α
Lαv(t, x) = 0,
v(T, x) = g(x), x ∈R.
(9.79)
Let us show how this mathematical technique works for option pricing. We start with
the Bachelier model with stochastic volatility (with interest rate r = 0):
St = S0 + μt + σtWt, t ∈[0,T],
(9.80)

9.4
Controlled diﬀusion processes and applications to option pricing
135
where S0, σ2
t = σ2 + (−1)Nt δσ2,
δσ2 < σ2,
(Nt)t ≤T is a Poisson process with
intensity λ > 0.
It is well-known that pricing of option with pay-oﬀfunction g leads to the interval
of non-arbitrage prices of option with end points
C∗= inf
P∗E∗g(ST) and C∗= sup
P∗E∗g(ST),
(9.81)
where P∗runs a family of martingale measures for the model (9.80).
Number C∗and C∗are called (initial) lower and upper price of option. For
arbitrary time t before maturity date T such prices are determined as follows
v(t, St) = sup
P∗E∗(g(ST)|Ft) and
u(t, St) = inf
P∗E∗(g(ST)|Ft).
(9.82)
Due to a Markov property of the process (Xt) from (9.80) and a parametrization
of martingale measures P∗= P∗(α), α2
t = σ2 + (−1)Nt δσ2, formulas (9.81)-(9.82)
can be rewritten as
v(t, St) = sup
α
E∗(g(ST)|St) and
u(t, St) = inf
α E∗(g(ST)|St).
(9.83)
Let us consider v(t, St) only because the case of the lower price u(t, St) (9.83) can be
treated in the same way. Now we rewrite model (9.80) via P∗(α) :
dSt = α(t, St)dW∗
t ,
(9.84)
where W∗is a Wiener process w.r. to P∗.
According the Ito formula we obtain
dv(t, St) =
 ∂v(t, St)
∂t
+ 1
2
∂2v(t, St)
∂x2
α2

dt + α ∂v(t, St)
∂x
dW∗
t .
Hence, the equality (9.83) can be rewritten as
v(t, St) = sup
α
Et,St

v(t, St) +
∫T
t
 ∂v
∂s + α2
2
∂2v
∂x2

+
∫T
t
α ∂v
∂x dW∗
s

.
(9.85)
Using the martingale property of the last term of (9.85) we arrive to the equation
0 = sup
α
E∗
t,St
∫T
t
 ∂v
∂s + α2
2
∂2v
∂x2

ds

(9.86)
Divide both sides of (9.86) by T −t and let T →t we get

136
9
Stochastic diﬀerential equations, diﬀusion processes and their applications
0 = sup
α
 ∂v(t, St)
∂t
+ α2
2
∂2v(t, St)
∂x2

.
(9.87)
Similarly, we can obtain that
0 = inf
α
 ∂u(t, St)
∂t
+ α2
2
∂2u(t, St)
∂x2

.
(9.88)
Putting to (9.87)-(9.88) α2 = σ2 + (−1)Nt δσ2, we determine D = (σ2 −δσ2,
σ2 + δσ2) and
0 =∂v(t, St)
∂t
+ 1
2
∂2v(t, St)
∂x2

σ2 + sgn
 ∂2v
∂x2 (t, St)

δσ2

0 =∂u(t, St)
∂t
+ 1
2
∂2u(t, St)
∂x2

σ2 −sgn
 ∂2u
∂x2 (t, St)

δσ2

.
So, we arrive to the following theorem of pricing of a call option in the model (9.80).
Theorem 9.7 The bounds of non-arbitrage prices of a call option for any t ≤T are
calculated as solutions of the HJB-equations:
∂v(t, St)
∂t
+ 1
2σ2 ∂2v(t, St)
∂x2
+ 1
2




∂2v
∂x2




 δσ2 = 0,
v(T, x) = (x −K)+;
(9.89)
∂u(t, St)
∂t
+ 1
2σ2 ∂2u(t, St)
∂x2
−1
2




∂2u
∂x2




 δσ2 = 0,
u(T, x) = (x −K)+.
(9.90)
The next theorem shows how equations (9.89) and (9.90) can be solved approxi-
mately by means of the small perturbations method.
Theorem 9.8 Assume that δσ2 << σ2, then the initial upper and lower prices of a
call option with strike price K admit approximations given by the formulas
ˆC∗= (S0 −K)Φ
 S0 −K
σ
√
T

+ σ
√
Tφ
 S0 −K
σ
√
T

+ δσ2
2σ
√
Tφ
 S0 −K
σ
√
T

,
(9.91)
ˆC∗= (S0 −K)Φ
 S0 −K
σ
√
T

+ σ
√
Tφ
 S0 −K
σ
√
T

−δσ2
2σ
√
Tφ
 S0 −K
σ
√
T

,
(9.92)
where φ(x) =
1
√
2π e−x2/2, Φ(x) =
∫x
−∞φ(y)dy.
Proof Both formulas (9.91) and (9.92) are derived in the same way using the method
of small perturbations from the PDEs theory. Deriving (9.91) only we represent v(t, x)
as follows
v(t, x) = v0(t, x) + v1(t, x)δσ2 + v2(t, x)(δσ2)2 + . . .
(9.93)

9.4
Controlled diﬀusion processes and applications to option pricing
137
Let us make a change of variable θ = σ2(T −t) and obtain v(t, x) = V(θ, x) and
∂v
∂t = −σ2 ∂V
∂θ .
Hence, the HJB-equation (9.89) is transformed to the following one
∂V
∂θ = 1
2
∂2V
∂x2 + δσ2
2σ2




∂2V
∂x2




, V(0, x) = (x −K)+.
(9.94)
To solve (9.94) we rewrite (9.93) in new variables ignoring terms of the order greater
one:
V(θ, x) = V0(θ, x) + V1(θ, x)δσ2 + o(δσ2)..
(9.95)
Plugging (9.95) to the equation (9.94) we get equations for V0 and V1 :
∂V0
∂θ =1
2
∂2V0
∂x2 , V0(0, x) = (x −K)+,
∂V1
∂θ =1
2
∂2V1
∂x2 +
1
2σ2




∂2V0
∂x2




, V1(0, x) = 0.
(9.96)
The ﬁrst equation in (9.96) is exactly the Bachelier equation, and we know its solution
(see, for example, (9.57)). Moreover, we have for derivatives of V0 that
∂V0
∂x =Φ
 x −K
√
θ

+ (x −K)φ
 x −K
√
θ
 1
√
θ
+ (x −K)φ
 x −K
√
θ
 −x + K
√
θ
= Φ
 x −K
√
θ

,
∂2V0
∂x2 =φ
 x −K
√
θ
 1
√
θ
≥0.
Therefore, the second equation in (9.96) is transformed to the next one
∂V1
∂θ = 1
2
∂2V1
∂x2 +
1
2σ2√
θ
φ
 x −K
√
θ

,
for which we ﬁnd that V1(θ, x) =
√
θ
2σ2 φ(θ, x).
Finally, we arrive to conclusion that
v(0, S0) ≈V(σ2T, S0) = (S0 −K)Φ
 S0 −K
σ
√
T

+ σ
√
Tφ
 S0 −K
σ
√
T

+ δσ2
2σ
√
Tφ
 S0 −K
σ
√
T

which proves the formula (9.91).
⊓⊔
Problem 9.4 Consider the Black-Scholes model with stochastic volatility and zero
interest rate
dSt =St (μdt + σtdWt), S0 > 0,
σ2
t =sσ2 + (−1)Nt δσ2, δσ2 < σ2, t ∈[0,T].
(9.97)

138
9
Stochastic diﬀerential equations, diﬀusion processes and their applications
Using a similar reasoning as in Theorem 9.7, derive the following HJB-equations
for the upper and lower call option prices
∂v
∂t + 1
2σ2x2 ∂2v
∂x2 + 1
2




∂2v
∂x2




 x2δσ2 = 0,
v(T, x) = (x −K)+;
∂u
∂t + 1
2σ2x2 ∂2u
∂x2 −1
2




∂2u
∂x2




 x2δσ2 = 0,
u(T, x) = (x −K)+.
Problem 9.5 Assuming in the model (9.97) that δσ2 << σ2, ﬁnd the ﬁrst order
approximations for initial lower and upper prices C∗and C∗of call option:
ˆC∗= S0Φ
 ln S0/K + σ2T/2
σ
√
T

−KΦ
 ln S0/K −σ2T/2
σ
√
T

+ Kδσ2
2σ2 σ
√
Tφ
 ln S0/K −σ2T/2
σ
√
T

,
ˆC∗= S0Φ
 ln S0/K + σ2T/2
σ
√
T

−KΦ
 ln S0/K −σ2T/2
σ
√
T

−Kδσ2
2σ2 σ
√
Tφ
 ln S0/K −σ2T/2
σ
√
T

.

Chapter 10
General theory of stochastic processes
under “usual conditions”
Abstract Chapter 10 is devoted to a systematic exposition of a continuous time
version of stochastic analysis under “usual conditions” with its standard notions like
a stochastic basis, ﬁltration, stopping times, random sets, predictable and optional
sigma-algebras etc. It is shown how the discrete time martingale theory as well as
a pure continuous time theory of diﬀusion processes are generalized for so-called
cadlag processes. Using the predictable notion of a compensator the fundamental
Doob-Meyer theorem is formulated for the class of sub- and supermartingales of class
D. The full version of stochastic integration of predictable processes with respect
to square-integrable martingale is developed. Moreover, diﬀerent decompositions of
such martingales are proved as well as the Kunuta-Watanabe inequality. It is shown
how the theory can be extended with the help of localization procedures (local
martingales, processes with locally integrable variation, semimartingales). The Ito
formula is proved for semimartingales. SDEs with respect to semimartingales are
studied including the existence and uniqueness of solutions of such equations with
the Lipschitz coeﬃcients (see [2], [8], [9], [16], [18], [20], [26], [33], [36], and [37]).
10.1
Basic elements of martingale theory
We will operate here with a complete probability space (Ω, F, P) equipped with a
non-decreasing family of σ-algebras Ft ⊆F satisfying the “usual conditions”:
1) Fs ⊆Ft, s ≤t, Ft = Ft+ = ∩ϵ>0Ft+ϵ;
2) Ft contains all the P-null sets of F .
Let us call such a stochastic basis (Ω, F, (F )t ≥0, P) standard.
In stochastic analysis, a special place is occupied by the set of stopping times.
That is why we study this notion in a more general setting as before.
Deﬁnition 10.1 A non-negative random variable τ : Ω →R+ ∪{∞} is a stopping
time, if for any t ≥0
{ω : τ(ω) ≤t} ∈Ft.
© The Author(s), under exclusive license to Springer Nature Switzerland AG 2023
A. Melnikov, A Course of Stochastic Analysis, CMS/CAIMS Books in Mathematics 6,
https://doi.org/10.1007/978-3-031-25326-3_10
139

140
10
General theory of stochastic processes under “usual conditions”
We also deﬁne a σ-algebra
Fτ = {A ∈F∞= σ (∪t ≥0Ft) : A ∩{τ ≤t} ∈Ft}
as a set of all events occurred before τ.
Let us formulate some properties of s.t.’s as the following problem.
Problem 10.1 1) If τ and σ are s.t.’s, then
τ ∨σ = max{τ, σ} and
τ ∧σ = min{τ, σ} are s.t.’s.
2) If (τn)n=1,2,... is a monotone sequence of s.t.’s, then
τ = lim
n→∞τn is a s.t.
3) If τ is a s.t., then Fτ is a σ-algebra.
4) For two s.t.’s τ ≤σ we have Fτ ⊆Fσ.
5) Let τ be a s.t. and A ∈Fτ, then
τA =

τ
on A,
∞
on Ac
is a s.t.
6) Let τ be a s.t., then there exists a monotonic sequence of s.t.’s τn > τ such that
limn→∞τn = τ (a.s.).
Deﬁnition 10.2 A s.t. τ is called predictable, if there exists a non-decreasing
sequence (τn)n=1,2,... of s.t.’s such that
lim
n→∞= τ (a.s.), τn < τ (a.s.) on {τ > 0}.
In this case we say that (τn)n=1,2,... announces τ. Moreover, we denote Fτ−=
σ ∪∞
n=1Fτn
 as a collection of events occurring strictly before τ.
Problem 10.2 1) If A ∈Fτ−, then τA is a predictable s.t.
2) If a.s. σ < τ, then
Fσ ⊆Fτ−⊆Fτ.
Deﬁnition 10.3 For a s.t. τ we deﬁne a subset of R+ × Ω
⟦τ⟧= {(t, ω) : t = τ(ω) < ∞}
as the graph of τ.
Deﬁnition 10.4 If the graph ⟦τ⟧can be embedded to a countable union of graphs
of predictable s.t.’s, then a s.t. τ is accessible. It means that Ω = ∪nAn, and on each

10.1
Basic elements of martingale theory
141
element An of such partition τ is announced by a sequence of s.t.’s (τn,m)m=1,2,.... So,
a s.t. τ will be predictable if the sequence (τn,m) can be chosen without dependence
on n.
If a s.t. τ such that P(ω : τ = σ < ∞) = 0 for every predictable s.t. σ, then τ is
totally inaccessible.
Let us note that every s.t. τ can be decomposed as follows. There exists a unique
(up to zero probability) set A ∈Fτ such that τA is accessible and τAc is totally
inaccessible, A ⊆{ω : τ(ω) < ∞}.
We need to connect these notion with the notion of a stochastic process. We
understand a stochastic process X = Xt(ω) = X(t, ω) as a mapping
X : R+ × Ω →Rd.
For simplicity we consider the case d = 1. Another stochastic process Y is a modiﬁ-
cation of X, if for arbitrary t ≥0 :
P{ω : Xt  Yt} = 0.
Two stochastic processes X and Y are indistinguishable, if
P{ω : Xt(ω) = Yt(ω) for all t} = 1.
Example 10.1 To demonstrate a diﬀerence between the notion “modiﬁcation” and
“indistinguishability” we give a standard example. Take Xt := 0 and
Yt =

0,
t  τ,
1,
t = τ,
where a r.v. τ is exponentially distributed with parameter λ > 0. Then for ﬁxed t0 we
have P(Xt0 = Yt0) = P(τ  t0) = 1, but P(Xt = Yt for all t) = 0.
Deﬁnition 10.5 If X is a measurable mapping from (R+ × Ω, B(R+) × F ) to
(R, B(R)), then such a stochastic process is measurable.
If for t ∈R+ a r.v. Xt is Ft-measurable, then the process X is adapted (to ﬁltration
(Ft)).
For each t ≥0 we can consider a restriction of X to the set [0, t] × Ω. If such
restriction is B([0, t]) × Ft-measurable, then the process X is called progressively
measurable. A family of sets A ⊆R+ × Ω such that the indicator process X(t, ω) =
IA(t, ω) is progressively measurable is a σ-algebra of progressively measurable sets
Π.
In case of a progressively measurable process X we have the following important
property: Xτ is Fτ-measurable for any s.t. τ, where X∞must be F∞-measurable .
Let us note that for any progressively measurable set A a random variable
DA(ω) = inf{t : (t, ω) ∈A},

142
10
General theory of stochastic processes under “usual conditions”
DA(ω) = ∞if the set {·} = ∅, is a stopping time which is called the debut of A.
One can note that every adapted and measurable process X admits a progressively
measurable modiﬁcation. It is convenient to operate with a stochastic process process
X almost all trajectories of which are right-continuous and admit left-limits at each
time. Such processes are called cadlag. It turns out such adapted cadlag process X is
progressively measurable. This fact follows from the next standard considerations.
For t > 0, n = 1, 2, . . ., i = 0, 1, . . ., 2n −1, s ≤t we put X(n)
0 (ω) = X0(ω)
X(n)
s (ω) = X (i+1)t
2n (ω) for it
2n < s ≤i + 1
2n t.
(10.1)
According to (10.1) we get X(n) which is B(0, t) × Ft-measurbale and due to the right-
continuity limn→∞X(n)
s (ω) = Xs(ω) for (s, ω) ∈[0, t] × Ω. Hence, X is progressively
measurable.
Further, deﬁne the random variables
τ1,0 = 0, τ1,1 = inf(t > 0 : |ΔXt| ≥1), τ1,2 = inf(t > τ1,1 : |ΔXt| ≥1), . . .
τk,0 = 0, . . ., τk,n = inf

t > τk,n−1 : 1
k ≤|ΔXt| <
1
k −1

, . . .,
(10.2)
where as usual ΔXt = Xt −Xt−.
These random variables are stopping times because (Xt) and (Xt−) are progres-
sively measurable. Moreover, the set
U = {(t, ω) : ΔXt(ω)  0} ⊆∪k ≥1,n≥1⟦τk,n⟧
and even can be embedded to the union of graphs ⟦σn⟧and ⟦τn⟧, where (σn) are
predictable s.t.’s, (τn) are totally inaccessible s.t.’s such that P(σn = σm < ∞) = 0
and P(τn = τm < ∞) = 0, n  m.
Besides Π we need to introduce two additional σ-algebras on the space [0, ∞) × Ω.
We shall do it with the help of the notion of stochastic intervals. These are examples
of random set related to the stopping times σ and τ :
⟦σ, τ⟦= {(t, ω) : σ(ω) ≤t < τ(ω)},
⟦σ, τ⟧= {(t, ω) : σ(ω) ≤t ≤τ(ω) < ∞},
and so on, and also their graphs ⟦σ⟧= ⟦σ, σ⟧, ⟦τ⟧= ⟦τ, τ⟧.
The ﬁltration (Ft)t ≥0 induces in [0, ∞) × Ω besides Π the predictable and the
optional σ-algebras P and O :
P =σ{⟦0A⟧, ⟦0, τ⟧: A ∈F0, τ is a s.t.}, ⟦0A⟧= {0} × A,
O =σ{⟦0, τ⟦: τ is a s.t.}.
The processes which are measurable w.r. to P (correspondently, O) are called pre-
dictable (optional).

10.1
Basic elements of martingale theory
143
Problem 10.3 Let (τi) is a non-decreasing sequence of s.t.’s and bounded random
functions φ∗
0 and φi are F0 and Fτi-measurable correspondently. Deﬁne a stochastic
process
Xt(ω)φ∗
0(ω)I{0}(t) +
n−1

i=0
φi(ω)I⟧τi,τi+1⟧(t, ω).
(10.3)
Prove that P is generated by all processes of type (10.3).
Remark 10.1 One can prove that P is generated by processes of type (10.3) with
deterministic τi = ti. Moreover, P is generated by all left-continuous (continuous)
adapted processes.
It is clear that for the left-continuous process X and a predictable s.t. τ XτI{τ<∞}-
Fτ−-measurable, and therefore such a statement will be true for all predictable
processes and times.
Remark 10.2 If A is a predictable set (A ∈P), then its debut is a s.t. Moreover, DA
is predictable and A \ ⟦DA, ∞⟦∈P, if ⟦DA⟧⊆A.
Remark 10.3 As far as the times τk,n of the n-th jump of size |ΔXt| ∈
 1
k,
1
k−1
	
, for an
adapted predictable process X (see (10.2)) they are predictable, U = ∪n≥1,k ≥1⟦τk,n⟧,
and Xτn,k -Fτn,k−-measurable, according to Remark 10.1.
To go further, we will study two classes of stochastic processes: processes with ﬁnite
variation and martingales.
Deﬁnition 10.6 1) The process A = (At)t ≥0 is increasing, if A0 = 0 (a.s.), adapted
and cadlag, As ≤At (a.s.) for s ≤t.
2) The process B = (Bt)t ≥0 is the process with ﬁnite variation, if B0 = 0 (a.s.),
adapted and cadlag, for each ω ∈Ω the trajectory B·(ω) has ﬁnite variation on each
compact interval.
Each process with ﬁnite variation can be decomposed into diﬀerence of two
increasing processes and vice versa. For any bounded (non-negative) Borel func-
tion f (s) one can deﬁne the Lebesgue-Stieltjes integral
∫t
0 f (s)dBs(ω). We denote
∫t
0 f (s)|dBs| the integral of f under the variation of B, and
∫t
0 |dBs| will be equal to
the variation of B on [0, t].
Deﬁnition 10.7 We call an increasing process A integrable if E
∫t
0 dAs < ∞. Cor-
respondently, a process B has integrable variation if E
∫∞
0
|dBs| < ∞. The corre-
sponding classes of such processes we denote A+ and A.
The process B with ﬁnite variation can be decomposed as follows
Bt = Bc
t +

s≤t
ΔBs,
(10.4)
where Bc is a continuous process with ﬁnite variation and 
s≤t |ΔBs| ≤
∫t
0 |dBs| <
∞.

144
10
General theory of stochastic processes under “usual conditions”
Moreover,
in
decomposition
(10.4)
its
discontinuous
part

s≤t ΔBs =

n≥1 ΔBτn I{τn ≤t } with some sequence of s.t.’s (τn)n≥1. If the process B is pre-
dictable, then τn are predictable too, and ΔBτn −Fτn−-measurable. Hence, any pre-
dictable process with ﬁnite variation admits the form (10.4) as
Bt = Bc
t +

n≥1
φnI{τn ≤t },
(10.5)
where φn −Fτn−-measurable and 
n≥1 |φn|I{τn ≤t } exists for all t ∈R+.
In fact, if B satisﬁes (10.5) then it is a predictable process with ﬁnite variation.
Deﬁnition 10.8 A martingale is an adapted integrable process M = (Mt)t ≥0 such
that
E(Mt|Fs) = Ms (a.s.) f or all t ≥s ≥0.
(10.6)
If in (10.6) the “=” is changed by “≥” (correspondently, “≤”), then we have a
submartingale (supermartingale).
Without loss of generality we always can count these processes cadlag, because under
“usual conditions” every submartingale admits the right-continuous modiﬁcation if
and only if its expected value is right-continuous.
We can transform any martingale (Mt)t ≥0 to a submartingale (φ(Mt))t ≥0 with
the help of a convex function φ such that E|φ(Mt)| < ∞, t ∈R+, using Jensen’s
inequality.
As in discrete time, we can deﬁne for given process X = (Xt)t ≥0 the following
notions. Let a < b be real numbers and F be a ﬁnite subset of R+. For each (restricted
to F) trajectory of process (Xt(ω))t ≥0 one can deﬁne the number of upcrossings
UF(a, b, X·(ω)) of the interval [a, b]. To do it we take
τ1(ω) = inf(t ∈F : Xt(ω) ≤a) and for j = 1, 2, . . .
σj(ω) = inf(t ∈F : t ≥τj(ω), Xt(ω) > b),
τj+1(ω) = inf(t ∈F : t ≥σj(ω), Xt(ω) < a),
and deﬁne UF(a, b, X·(ω)) the largest j such that σj(ω) < ∞.
For an inﬁnite set G ⊆R+ one can deﬁne
UG(a, b, X·(ω)) = sup{UF(a, b, X·(ω)) : F ⊆G, F is ﬁnite}.
Let us formulate the following Doob inequalities for continuous time submartingales.
Theorem 10.1 Assume X = (Xt)t ≥0 is a submartingale, [t1, t2] ⊆R+, λ > 0. Then
1) P

ω : supt1 ≤t ≤t2 Xt ≥λ

≤
EX+
t2
λ ;
2) P

ω : inft1 ≤t ≤t2 Xt ≤−λ

≤
EX+
t2EXt1
λ
;
3) EU[t1,t2](a, b, X·(ω)) ≤
EX+
t2+|a|
b−a
4)E

supt1 ≤t ≤t2 Xt
	 p
≤

p
p−1
	
EX p
t2, p > 1,
for a non-negative (Xt) wih EX p
t < ∞.

10.1
Basic elements of martingale theory
145
The derivation of inequalities of the above theorem is based on limiting arguments,
right-continuity of X and discrete time versions of these results.
Let us pay attention to other important results of martingale theory.
Theorem 10.2 If X = (Xt)t ≥0 is a submartingale with supt ≥0 EX+
t < ∞, then there
exists a r.v. X∞−F∞-measurable and integrable such that X∞(ω) = limt→∞Xt(ω)
(a.s.).
Proof For n = 1, 2, . . . and a < b ∈R we have from Theorem 9.1 that
EU[0,n](a, b, X·(ω)) ≤EX+
n + |a|
b −a
.
(10.7)
Taking the limit as n →∞in (10.7) we get
EU[0,∞[(a, b, X·(ω)) ≤supt EX+
n + |a|
b −a
.
(10.8)
Denote Aa,b = {ω : U[0,∞)(a, b, X·(ω)) = ∞} and ﬁnd from (10.8) that P(Aa,b) = 0.
Hence,
P(A) = P(∪a,b∈QAa,b) = 0.
The
set
A
contains
the
set
{ω : lim supt→∞Xt(ω) > lim inft→∞Xt(ω)}.
Now, for ω ∈Ω \ A there exists
X∞(ω) = lim
t→∞Xt(ω) (a.s.)
Due to E|Xt| = 2EX+
t −EXt ≤2 supt EX+
t −EX0 and Fatou’s lemma we obtain that
E|X∞| < ∞.
□
Corollary 10.1 Let X = (Xt)t ≥0 be a martingale. Then the following statements are
equivalent
1) (Xt)t ≥0 is uniformly integrable;
2) Xt converges to X∞in L1;
3) There exists X∞∈L1 such that Xt = E(X∞|Ft).
Corollary 10.2 Let X = (Xt)t ≥0 be a nonnegative supermartingale. Then there
exists an integrable r.v. X∞= limt→∞Xt (a.s.).
Corollary 10.3 Let X = (Xt)t ∈[0,∞] be a submartingale on extended real line R+ ∪
{∞}. Then for stopping times σ ≤τ
E(Xτ|Fσ) ≥Xσ(a.s.)
(10.9)
Proof Consider the following sequence of discrete stopping times
σn(ω) =

σ(ω),
σ = ∞,
kn
2 ,
k−1
2n ≤σ(ω) <
k
2n .
Similar sequence is constructed for τ, and by construction and conditions of the
theorem σn ≤τn, n = 1, 2, . . . . Applying (10.9) with σn and τn, we derive (10.9) by
taking the limit as n →∞.
□

146
10
General theory of stochastic processes under “usual conditions”
Corollary 10.4 Let X = (Xt)t ≥0 be a submartingale and σ ≤τ be stopping times.
Then
1) (Xτ∧t)t ≥0 is a submartingale w.r.to (Ft);
2) E(Xτ∧t|Fσ) ≥Xσ∧t (a.s.) for all t ≥0.
Corollary 10.5 If M = (Mt)t ≥0 is a uniformly integrable martingale and τ is a
predictable stopping time, then E(ΔMτ|Fτ−) = 0.
To prove it we consider a sequence of stopping times (τn)n=1,2,... announcing τ.
Applying Theorem 10.2 to this sequence we get Mτn = E(M∞|Fτn) = E(Mτ|Fτn).
Taking the limit in this equality we obtain (a.s.)
Mτ−= lim
n→∞Mτn = lim
n→∞E(Mτ|Fτn) = E(Mτ|Fτ−).
Denote M the class of uniformly integrable martingales.
Assume M ∈M and A ∈A+, then the process X = M −A is a supermartingale,
satisfying the condition (D), i.e. the class of random variables {XτI{τ<∞} : τ is a
s.t.} is uniformly integrable. Hence, such a construction leads to a supermartingale
X ∈D. The inverse statement is the famous Meyer’s theorem:
Any supermartingale X ∈D admits the following decomposition of Doob-Meyer:
for t ≥0 (a.s.)
Xt = Mt −At,
(10.10)
where M ∈M and A is a predictable process from A+. The decomposition (10.10)
is unique in the class of predictable increasing processes.
Remark 10.4 If a supermartingale X ∈D and B is the predictable increasing process
from the Doob-Meyer decomposition, then we can calculate the jumps of B as
follows. First of all, the moments of jumps of B are predictable. For any such a
moment τ we can apply Corollary 10.4 with the uniformly integrable martingale
X = M + B and get
0 = E(ΔMτ|Fτ−) = E(ΔXτ + ΔBτ|Fτ−) = E(ΔXτ|Fτ−) + ΔBτ,
and hence ΔBτ = −E(ΔXτ|Fτ−).
Let us note that for every A ∈A+ the process (−A) is a supermartingale of class
(D).
Applying to (−A) its Doob-Meyer decomposition, we ﬁnd a unique predictable
process B ∈A+ such that B −A ∈M.
Deﬁnition 10.9 The process B is called the compensator of A.
These considerations can be extended to the class V of processes with integrable
variation. Let A ∈V, then there exists a unique predictable process B ∈V with the
property: B −A ∈M. We will call B the compensator of A.
Remark 10.5 a) If τ is a totally inaccessible stopping time and φ is an integrable Fτ-
measurable function, then the compensator of At = φI{τ≤t } is a continuous process
from class V.

10.1
Basic elements of martingale theory
147
b) If τ is predictable and φ is an integrable Fτ-measurable function, then the
compensator of At = φI{τ≤t } is the process Bt = E(φ|Fτ−)I{τ≤t }.
The rest of this Section is devoted to square-integrable martingales.
Deﬁnition 10.10 A martingale M is square integrable if supt EM2
t < ∞. The class
of such martingales is denoted of M2.
We count some properties of such martingales in the following theorem.
Theorem 10.3 Let M ∈M2, then the next properties are fulﬁlled:
(1) (M2
t )t ≥0 is a submartingale;
(2) there exists M∞= limt→∞Mt (a.s.) and in L2;
(3)E supt M2
t ≤4 supt EM2
t = 4EM2
∞;
(4) E 
t(ΔMt)2 ≤lim inf(t1<...<tn) E (Mti −Mti−1)2 = EM2
∞< ∞.
Proof Statements (1)-(3) come from Jensen’s inequality and Theorem 10.1 and 10.2.
The last one 4) follows from the Fatou lemma, where liminf is provided via directed
sets if subdivisions (t1 < . . . < tn).
□
Let us note that due to the Doob inequality M2 is a submartingale from class
(D), and hence, by the Doob-Meyer decomposition there exists a unique predictable
A ∈A+ such that M2 −A ∈M.
The process A is denoted ⟨M, M⟩and is called a quadratic characteristic (com-
pensator) of M ∈M2.
Remark 10.6 We can cover the jumps of M ∈M2 by a sequence of predictable s.t.’s
(τn)n=1,2,... and a sequence of totally inaccessible s.t.’s (σn)n=1,2,...
For each n = 1, 2, . . . we deﬁne processes Cn
t = ΔMτn I{τn ≤t } and Dn
t =
ΔMσn I{σn ≤t }.
Due to Remark 10.5 in case Cn
t we have E(ΔMτn |Fτn−)I{τn ≤t } = 0 · I{τn ≤t } = 0,
and hence, it is a square integrable martingale. Another process Dn
t has a compensator
˜Dn
t which is a continuous process with integrable variation. So, ˆDn
t = Dn
t −˜Dn
t ∈M
and Δ ˆDn
σn = ΔMσn.
To investigate the structure of class M2 we need several auxiliary facts, which
we formulate as Lemmas.
Lemma 10.1 Let A and B ∈A, A −B be a martingale and φ be a bounded (non-
negative) predictable function. Then
E
∫∞
0
φsd(A −B)s = 0.
(10.11)
Proof It is clear that relation (10.11) is fulﬁlled for the step function (see (10.3) and
Remark 10.1)
φt = φ(t) = φ∗
0I(t)
{0} +
n−1

i=0
φi(ω)I(ti,ti+1](t),
and extension to predictable bounded functions is straightforward.
□

148
10
General theory of stochastic processes under “usual conditions”
Lemma 10.2 If a : R+ →R+ is the right-continuous increasing function, a(0) = 0,
and c(s) = inf(t : a(t) > s), then c(s) is the increasing right-continuous satisfying
the equality
∫∞
0
f (s)da(s) =
∫∞
0
f (c(s))I{c(s)<∞}ds
(10.12)
for any bounded (non-negative) measurable function f .
Again, the proof is standard. We check (10.12) for f (s) = I(0,t](s) and so on.
Lemma 10.3 For any bounded martingale M and process A ∈A the following
equality is true
EA∞M∞= E
∫∞
0
MsdAs.
(10.13)
Proof Using (10.12) with A and c, we obtain (10.13) from the following chain of
equalities
E
∫∞
0
MsdAs =E
∫∞
0
Mcs I{cs<∞}ds
=
∫∞
0
EMcs I{cs<∞}ds
=
∫∞
0
E M∞I{cs<∞}
 ds
=E
∫∞
0
M∞I{cs<∞}ds
=E
∫∞
0
M∞dAs
=EM∞dA∞.
The claim of the next Lemma was proved before for discrete time martingales.
Lemma 10.4 Let (Lt)t ∈[0,∞] be an uniformly integrable process, L0 = 0. If ELσ = 0
for any stopping time σ, then L is a martingale.
Proof We deﬁne a s.t.
σ =

t
on A,
∞
on Ac,
where A is a ﬁxed set from Ft. Then we obtain that
∫
A LtdP +
∫
Ac L∞dP = 0, which
can be transformed for σ = ∞to the equality
∫
A L∞dP +
∫
Ac L∞dP, i.e. (Lt) is a
martingale.
□
Lemma 10.5 For
M ∈M2
and
any
predictable
s.t.
τ
the
process
ΔCt = ΔMτI{τ≤t } ∈M2, and for any N ∈M2 the process
Lt = CtNt −ΔCτΔNτI{τ≤t } ∈M.

10.1
Basic elements of martingale theory
149
Proof The ﬁrst claim follows from Remark 10.6. Further, for the process (Lt) we
have
sup
t
|Lt| ≤sup
t
|Ct| sup
t
|Nt| + |ΔCτ||ΔNτ| ∈L1,
and for any s.t. σ and Nt∧σ = Nσ
t by Lemma 10.3
EC∞Nσ
∞N =ECσNσ = E
∫∞
0
Nσ
s dCs = ENσ
τ ΔCτ
=EΔNσ
τ ΔCτ = EΔNτΔCτI{σ≤τ},
where the equality ENτ
σ−ΔCσ = E

Nτ
σ−E(ΔCσ|Fσ−)

= 0 was used. We arrive to
conclusion that ELτ = 0 for any s.t. τ. Now the claim follows from Lemma 10.4. □
Lemma 10.6 Let M ∈M2 and σ be a totally inaccessible s.t. Let Dt = ΔMσI{σ}
with compensator ˜Dt and ˆDt = Dt −˜Dt. Then
(1) The process ˆD ∈M2 and E ˆD2
∞≤5E(ΔMσ)2;
(2) For any N ∈M2 the process
Lt = DtNt −ΔDσΔNσI{σ≤t } ∈M.
Proof (1) It is suﬃcient to consider Dt = φI{σ≤t } with non-negative function φ, Fσ-
measurable and from L2. Otherwise, one can consider separately ΔM+
σ and ΔM−
σ.
For function |φ| ≤a we have
E ˜D2
∞=2E
∫∞
0
˜Dsd ˜Ds = 2E
∫t
0
˜DsdDs
≤2E
∫∞
0
˜D∞dDs = 2Eφ ˜D∞≤2aE ˜D∞< ∞,
where the formula f 2(∞) = 2
∫∞
0
f (s)df (s) is used. Hence, ˜D∞∈L2 and E ˜D2
∞≤
2Eφ ˜D∞≤2||φ||L2|| ˜D∞||L2 and E ˜D2
∞≤4Eφ2 for a non-negative bounded function
φ.
In general case, we consider φn = φ ∧n and processes ˜Dn
t and Dn
t = φnI{σ≤t }.
Correspondently, ˜Dn+1
t
−˜Dn
t is the compensator of the increasing continuous process
we have
E( ˜Dn
∞)2 ≤4E(φn)2 ≤4Eφ2 < ∞.
(10.14)
The non-decreasing sequence ˜Dn
∞converges, and according to (10.14) the limit
B∞will be in L2, as in case Bt = limn ˜Dn
t . Each sample function ˜Dn
t (ω) converges to
Bt(ω) uniformly, as 0 ≤˜Dn+
t
−˜Dn
t ≤˜Dn+1
∞
−˜Dn
∞. Hence, the process Bt is continu-
ous, and by taking the limit in L1 in the equality E(Dn
t −˜Dn
t |Fs) = Dn
s −˜Dn
s, s ≤t,
we arrive to conclusion that Dt −Bt ∈M. Therefore, Bt = ˜Dt, and E ˜D2
∞= EB2
∞≤
4Eφ2 < ∞and the martingale ˆD = D −˜D ∈M2.
(2) As in Lemma 10.5, the process L is uniformly integrable. Take a stopping
time τ and applying Lemma 10.3 to ˆD and Nτ, we obtain

150
10
General theory of stochastic processes under “usual conditions”
E(Dτ −˜Dτ)Nτ = E
∫∞
0
Nτ
t d(D −˜D)t

= ENτ
σΔDσ −E
∫∞
0
Nτ
t d ˜Dt
= ENτ
σΔDσ −E
∫∞
0
Nτ−
t−d ˜Dt

= E

ΔNσΔDσI{σ≤t }

.
Finally, applying Lemma 10.4 we show that L is a martingale.
□
Deﬁnition 10.11 A martingale M ∈M2 is called purely discontinuous, if M0 = 0,
and if for any continuous martingale N ∈M2 their product M · N is a martingale.
Let us denote M2,c and M2,d subclasses of M2 of continuous and purely discon-
tinuous martingales. Now we are ready to formulate the key theorem for square
integrable martingales.
Theorem 10.4 Any martingale M ∈M2 admits the following unique decomposition
M = Mc + Md,
(10.15)
where Mc ∈M2,c and Md ∈M2,d.
Let us call Mc in (10.15) the continuous part of
M, and Md the compensated
sum of the jumps of M or the purely discontinuous part of M.
Proof Using Remark 10.6 with Lemma 10.5 and Lemma 10.6 we can see that
Cn ˆDn, Cn ˆDm, CnCm, ˆDn ˆDm (m  m) are martingales. Denote for N = 1, 2,
. . ., Y N
t
= N
1 Cn
t + N
1
ˆDn and ﬁnd from Lemma 10.5 and Lemma 10.6 that for
N ≤N ′ :
E(Y N′
∞−Y N
∞)2 = E
 N′

N+1
(Cn
∞)2 +
N′

N+1
( ˆDn
∞)2

≤5E
 N′

N+1

(ΔMτn)2 + (ΔMσn)2	
.
(10.16)
It follows from (10.16) and Theorem 9.4 that
E sup
t
(Y N′
t
−Y N
t )2 ≤5E
 N′

N+1

(ΔMτn)2 + (ΔMσn)2	
.
It implies 
N E supt |Y N+1
t
−Y N
t |2 < ∞for some subsequence (Y N), which we
denoted Y N again. By the Borel-Cantelli lemma, there exists Yt = limN Y N
t
(a.s.)
uniformly over t, and it is a limit in L2 too. So, the process Yt is cadlag with the same
jumps as M, and Y ∈M2.
□
Now for a continuous martingale X ∈M2 the process XY N is a martingale by
Lemma 10.5 and Lemma 10.6. The convergenceY N
t
toYt in L2 implies a convergence
XtY N
t
to XtYt in L1. Hence, it is a martingale, and Md = Y is a purely discontinuous
martingale. Finally, Mc = M −Md is a continuous martingale, and we get (10.15).
Toprovetheuniquenessofsuchdecomposition,weassumethattherearetwodecom-
positions M = Mc + Md = ¯Mc + ¯Md, and Mc −¯Mc = ¯Md −Md is continuous and
purely discontinuous. Hence, (Md
t −¯Md
t )2 = E(Md
0 −¯Md)2 = 0 for all t ≥0.

10.2
Extension of martingale theory by localization of stochastic processes
151
Deﬁnition 10.12 Let M ∈M2, M0 = 0, Mc and Md are its continuous and purely
discontinuous parts of M. Deﬁne [M, M]t = ⟨Mc, Mc⟩t + 
s≤t(ΔMs)2 and call it a
quadratic brackets of M.
We can note that (Mc
t )2 −⟨Mc, Mc⟩t, (Md
t )2 −
s≤t(ΔMs)2 and McMd belong
to M. Hence, M2 −[M, M] ∈M, and ⟨M, M⟩is the compensator of [M, M].
Remark 10.7 If M0  0, then we can think of M0 as the jump of M at t = 0 and
deﬁne
[M, M] = ⟨Mc −M0, Mc −M0⟩+ M2
0 +

s≤t
(ΔMs)2.
Remark 10.8 Let us list some properties such quadratic characteristics of square
integrable martingales.
Deﬁne for M, N ∈M, M0, N0 = 0, their joint quadratic characteristics (brackets,
compensators):
⟨M, N⟩t =1
2 (⟨M + N, M + N⟩t −⟨M, M⟩t −⟨N, N⟩t),
[M, N]t =1
2 ([M + N, M + N]t −[M, M]t −[N, N]t) .
(1) The process ⟨M, N⟩is the unique predictable process such that MN −
⟨M, N⟩∈M.
(2) For any stopping time τ we have
⟨Mτ, N⟩= ⟨M, Nτ⟩= ⟨Mτ, Nτ⟩= ⟨M, N⟩τ
and similar equalities are true for the quadratic brackets.
(3) [M, N] = ⟨Mc, Nc⟩+ 
s≤t ΔMsΔNs.
(4) MN −[M, N] ∈M.
Analysing class M of square integrable martingales we observe that a Wiener
process W does not belong to M, because EW2
t = t →∞as t →∞. In the next
section it will be shown how to extend M to include this key process to a bigger
class for which a very nice theory can be developed.
10.2
Extension of martingale theory by localization
of stochastic processes
We start with the following localization procedure. Let H be a class of stochastic
processes X = (Xt)t ≥0. Deﬁne Hloc the set of stochastic processes Y = (Yt)t ≥0 such
that for each of them we can ﬁnd a sequence of stopping times τn ↑∞, n →∞,
such that the process Yτn = (Yt∧τn)t ≥0 is in H for any n = 1, 2, . . . . The sequence
(τn)n=1,2,... is called localizing (fundamental) for the process Y. For example, in case
of classes Mloc and M2
loc we will call the corresponding processes local martingales
and locally square-integrable martingales.

152
10
General theory of stochastic processes under “usual conditions”
Deﬁnition 10.13 We say that a s.t. τ reduces M ∈Mloc if Mτ ∈M.
Problem 10.4 Prove that for M ∈Mloc the following statements are true:
(1) A s.t. σ reduces M ⇔Mσ ∈D.
(2) If a s.t. τ reduces M and a s.t. σ ≤τ, then σ reduces M.
(3) If s.t.’s σ and τ reduce M, then max(σ, τ) = σ ∨τ reduces M.
Hint: to prove (3) one can use the equality
Mσ∨τ = Mσ + Mτ −Mσ∧τ.
The next theorem shows that the localization does not expand the class of local
martingales.
Theorem 10.5 If M is locally a local martingale, then M is a local martingale.
Proof Denote a localizing sequence (τn)n=1,2,... such that Mτn is a local martingale.
Denote R the set of all stopping times τ reducing M, and γ = esssupτ∈R)τ. There
exists a sequence σn ∈R which converges to γ almost surely. Let us make the
sequence (σn)n=1,2,... non-decreasing with the help of (3) of Problem 10.4. By the
deﬁnition γ majorates τn →∞(n →∞), and, hence, γ = ∞(a.s.), and (σ)n≥1 is
fundamental for M.
□
Problem 10.5 (1) Let B be a process with locally integrable variation, i.e. B ∈Aloc.
Prove that there exists a unique predictable process A ∈Aloc such that B −A ∈
Mloc. We call A a compensator of B.
(2) Prove that the predictable process B with ﬁnite variation has a locally bounded
variation.
(3) A process with ﬁnite variation has a compensator ⇔its variation is locally
integrable.
Remark 10.9 There is a simple way to check that the variation is locally integrable.
Namely, if for the process A with ﬁnite variation there exists a localizing sequence
(τn) such that E sups≤τn |ΔAs| < ∞, n = 1, 2, . . ., then the variation of A is locally
integrable. To verify this test we deﬁne a sequence of s.t.’s
σn = τn ∧inf

t :
∫t
0
|dAs| ≥n

, n = 1, 2, . . .
and ﬁnd that
∫
⟦0,σn⟧
|dAs| ≤n + |ΔAσn | ≤n + sup
s≤τn
|ΔAs| ∈L1.
The next result plays a key role in many construction for local martingales. That
is why it is called a fundamental lemma in the literature.
Lemma 10.7 Let M ∈Mloc, then
(1) M∗
t = sups≤t |Mt| ∈A+
loc,
(2) Mt = Ut + Vt, where U ∈Mloc, |ΔUt| ≤1, t ≥0,V ∈Mloc ∩V.

10.2
Extension of martingale theory by localization of stochastic processes
153
Proof (1) Take a localizing sequence of s.t.’s (σn)n=1,2,... for M, and make elements
of this sequence ﬁnite as follows σn →σn ∧n, n = 1, 2, . . . . Further, deﬁne s.t.’s
˜σn = σn ∧inf{t : |Mt| ≥n} ≤σn, n = 1, 2, . . .,
and obtain that M ˜σn is integrable due to the uniform integrability of (Mσn∧t)t ≥0.
On. stochastic interval ⟦0, ˜σn ⟦we have |Mt| ≤n and M∗
˜σn ≤n + |M ˜σn | belongs to
L1. Hence, (M∗
t )t ≥0 is locally integrable.
(2) Denote (At) = 
s≤t ΔMsI{|ΔMs |>1/2} which is ﬁnite for almost all ω. Using
this process and (˜σn), we deﬁne a new sequence of s.t.’s
τn = ˜σn ∧inf{t :
∫t
0
|dAs| ≥n} ≤σn, n = 1, 2, . . . .
It is a localizing sequence such that
∫
⟦0,τn⟧
|dAt| ≤n + |ΔAτn | ≤n + 2M∗
τn ∈L1.
Therefore, there is a compensator B for A, and V = A −B ∈Mloc ∩V. Because
of predictability of B, its jumps are happen at predictable times τ only. Stopping
processes by sequence ˜σn we get now
|ΔB ˜σn
τ | =
E

ΔA ˜σn
τ |Fτ−
	
=
E

ΔM ˜σn
τ
−ΔM ˜σn
τ
I{|ΔMτ |<1/2}|Fτ−
	 ≤0 + 1/2.
Hence, the jumps of Ut = Mt −Vt verify the following inequalities
|ΔUt| ≤|Δ(M −A)t| + |ΔBt| ≤1.
Moreover, the sequence of stopping times deﬁned as ˜τn = inf{t : |Ut ≥n} is local-
izing, and |U ˜τn
t | ≤n + 1, n = 1, 2, . . . .
□
Below we use this fundamental lemma to prove a decomposition of any local
martingale into the sum of continuous and purely discontinuous if for any continuous
local martingale N ∈Mloc their product MN ∈Mloc.
Lemma 10.8 Let M ∈Mloc ∩V. Then
(1) Vt

s≤t ΔMs is a process with locally integrable variation and Mt = Vt −
˜Vt, t ≥0.
(2) For any bounded continuous martingale N, the product MN ∈Mloc.
Proof By Lemma 10.7 the process M∗
t ∈A+
loc. By Remark 10.9 the variation of
the process V is locally integrable. Therefore, there is a compensator ˜V for V,
and the local martingale M −(V −˜V) is continuous, and its variation is locally
integrable according to Lemma 10.7 and Remark 10.9. It means M −(V −˜V)

154
10
General theory of stochastic processes under “usual conditions”
admits a compensator, but due to a continuity of M −(V −˜V) it has to be zero as
M −(V −˜V) ∈Mloc. As a result, M = V −˜V.
(2) Let N be a bounded continuous martingale and let the variations of V and ˜V
are already integrable (otherwise, we can choose a localizing sequence of s.t.’s and
work with stopped processes). For a s.t. τ with the help of Lemma 10.1 and Lemma
10.3 we obtain
EMτNτ = EM∞Nτ
∞= E
∫∞
0
Nτ
s dMs
= E
∫∞
0
Nτ
s dVs −E
∫∞
0
Nτ
s d ˜Vs
= E
∫∞
0
Nτ
s dVs −E
∫∞
0
Nτ
s dVs
= 0.
By Lemma 10.4 we arrive to conclusion that MN is a martingale.
□
Theorem 10.6 Let M ∈Mloc, then
Mt = Mc
t + Md
t ,
(10.17)
where Mc ∈Mc
loc (continuous local martingales) and Md ∈Md
loc (a class of purely
discontinuous local martingales). The decomposition (10.17) is unique.
Proof According to the fundamental lemma we represent M = N + U with a locally
bounded local martingale N and a martingale with ﬁnite variation U. Taking a
localizing sequence of s.t.’s (τn) we get Nτn as a bounded martingale for each
n = 1, 2, . . . . Applying Theorem 10.5 we obtain Nτn = (Nτn)c + (Nτn)d, and using
the uniqueness of such decomposition, we obtain that (Nτn)c = (Nτn+1)c on ⟦0, τn⟧.
Now putting
Nc =
∞

n=1
(Nτn)cI⟧τn−1,τn⟧
we get a continuous local martingale as well as a purely discontinuous local
martingale Nd = N −Nc. As a result, we arrive to the following decomposition
M = Nc + (Nd + U), where Nd + U is a purely discontinuous local martingale due
to Lemma 10.8.
As far as the uniqueness of (10.17), we can assume that M = Xc + Xd = Mc +
Md. Then the equality Mc −Xc = Xd −Md leads to conclusion that locally Mc −
Xc = Xd −Md = 0 by Theorem 10.5.
□
Remark 10.10 For M ∈M ∈M2
loc we can apply the Doob-Meyer decomposition
(for M2) locally and construct its compensator ⟨M, M⟩∈A∗
loc, which is predictable
and M2 −⟨M, M⟩∈Mloc. In particular such compensator is well deﬁned for any
continuous local martingale because Mc
loc ⊆M2
loc.

10.2
Extension of martingale theory by localization of stochastic processes
155
The exact extension of this approach to the whole class of local martingales
is not possible. Nevertheless, one can deﬁne for M ∈Mloc a similar quadratic
characterization [M, M] as follows
[M, M]t = ⟨Mc, Mc⟩t +

s≤t
(ΔMs)2,
where Mc is a continuous part of M.
The formula (10.2) shows that the process [M, M] is increasing, M2 −[M, M] ∈
Mloc, but it is not predictable anymore.
To provide the correctness of the deﬁnition of process [M, M] by formula (10.2)
we need to prove that 
s≤t(ΔMs)2 converges for all t.
Again,weusethefundamentallemmatorepresent M = U + V.Further,
s≤t |ΔVs|
converges and therefore 
s≤t |ΔVs|2 converges too. Taking a localizing sequence (τn)
for U we obtain that E 
s≤τn |ΔUs|2 < ∞and for almost all ω

s≤τn
|ΔMs| ≤2

s≤τn
|ΔUs|2 + 2

s≤τn
|ΔVs|2
converges.
Let us join together classes of local martingales and processes with ﬁnite variation
to create a bigger family of stochastic processes.
Deﬁnition 10.14 A process X is called a semimartingale, if
X = X0 + M + A,
(10.18)
where X0 is an F0-measurable r.v., M ∈Mloc, A ∈V.
The next auxiliary result speaks us when the semimartingale admits a unique
representation in its deﬁnition.
Lemma 10.9 Assume X is a semimartingale with bounded jumps |ΔXt| ≤a < ∞.
Then X can be represented in a unique way as
X = X0 + M + A,
(10.19)
where X0 is an F0-measurable r.v., M ∈Mloc, A is a predictable process with ﬁnite
variation.
Proof Let us write the semimartingale X = X0 + N + B with N ∈Mloc and B ∈V,
and with the uniquely deﬁned r.v. X0-F0-measurable. We can estimate the jumps of
B as follows
|ΔBt| ≤|ΔNt| + |ΔXt| ≤2N∗
t + a, t ≥0.
So, the increasing process Yt = sups≤t |ΔBs| ∈A+
loc, and by Remark 10.9 the
variation of B is also locally integrable, and, hence, there exists its compensator A.
Let us put M = N + B −A ∈Mloc and ﬁnd that X = X0 + M + A. If there are two

156
10
General theory of stochastic processes under “usual conditions”
representations (10.19) for X = X0 + M + A = X0 + M′ + A′, then A −A′ ∈Mloc
and therefore A′ is a compensator of A and due to predictability A = A′.
Now we are ready to prove that the class of semimartingales can not be extended
by localization procedures.
Theorem 10.7 Any stochastic process X which is locally a semimartingale is a
semimartingale.
Proof Denote (τn)n=1,2,... a localizing sequence of stopping times, i.e. Xτn is a semi-
martingaleforeachn = 1, 2, . . .DeﬁnetheprocessYt = 
s≤t ΔXsI{ΔXs| ≥1andnote
thatY hasﬁnitevariation.Therefore,thediﬀerence Xτn −Yτn isasemimartingalewith
jumps bounded by one. Let us use Lemma 10.9 and write the unique representation
Xτn −Yτn = X0 + M(n) + A(n) with M(n) ∈Mloc, A(n) ∈V andpredictable.Further,
using the uniqueness of such representation we obtain on ⟦0.τn⟧that
A(n) = A(n+1)
and
M(n) = M(n+1).
So, we get the processes A = 
n A(n)I⟧τn−1,τn⟧and M = 
n M(n)I⟧τn−1,τn⟧.
□
The process A is predictable process with ﬁnite variation, M is locally a local
martingale, and according to Theorem 10.6 belongs to class Mloc. As a result, we
conclude that X is a semimartingale.
Another result of this type is presented in the following theorem.
Theorem 10.8 Let X be a cadlag adapted process and there exist a sequence of
s.t.’s (τn) and a sequence of semimartingales Y(n) such that
(1) limn→∞τn = ∞(a.s.)
(2) X = Y(n) on ⟦0, τn⟦, n = 1, 2, . . .
Then X is a semimartingale.
Proof For each n = 1, 2, . . . we have
Xt∧τn = Y(n)
t∧τn −Y(n)
τn I{τn ≤t } + Xτn I{τN ≤t },
and therefore, Xτn is a semimartingale. Now, if we can transform (τn) to an increas-
ing sequence, then we prove a semimartingale property of X according to Theorem
10.8. The trick to make it is standard. If τ and σ are s.t.’s, and Xσ and Xτ are semi-
martingales, then Xσ∧τ and Xσ∨τ = Xσ + Xτ −Xσ∧τ are both semimartingales
too.
□
Representation (10.18) for a semimartingale X may not be unique. Nevertheless,
there is a continuous martingale component of X which does not depend on such rep-
resentation.Itgivesapossibilitytodeﬁneaquadraticbracketof X thatisaveryhelpful
characteristic and tool for semimartingales. It is provided by the next theorem.
Theorem 10.9 Let X be a semimartingale with representation (10.18).
Then
(1) Mc in (10.18) does not depend on the particular representation (10.18);
(2) 
s≤t(ΔXs)2 converges a.s. for all t ≥0.

10.2
Extension of martingale theory by localization of stochastic processes
157
Proof (1) Indeed, if X = X0 + M + A = X0 + N + B with M, N ∈Mloc, A, B ∈V,
then the diﬀerence M −N ∈Mloc ∩V, and according to Lemma 10.8 M −N is
purely discontinuous and (M −N)c = 0. Therefore, Mc = Nc and we denote this
component Xc and call it the continuous local martingale part of X. The proof of
(2) is provided in the same way as for local martingales.
□
Deﬁnition 10.15 Let X be a semimartingale. Then the increasing process
[X, X]t = ⟨Xc, Xc⟩t +

s≤t
(ΔXs)2, t ≥0,
(10.20)
is well deﬁned and is called the quadratic bracket of X. If we have another semi-
martingale Y = (Yt)t ≥0, we can deﬁne a joint bracket
[X,Y]t = ⟨Xc,Y c⟩t +

s≤t
ΔXsΔYs
(10.21)
with similar properties.
Example 10.2 Let X be a supermartingale, then it is a semimartingale. To show it we
use Lemma 10.9. We consider the stepped supermartingale Xn
t = Xt∧n, n = 1, 2, . . .
which can be represented as follows
Xn
t = E(Xn|Ft) + Xn
t −E(Xn|Ft) = E(Xn|Ft) + Zt,
where Z is a non-negative supermartingale. For arbitrary s.t. σ we obtain E|Zσ| < ∞.
Moreover, deﬁne s.t.’s
τn = inf(t : Z∗
t ≥n) ∧n, Z∗
t = sup
s≤t
|Zs|
and on ⟦o, τn⟧we have Z∗
t ≤n + |Zτn | ∈L1, which certiﬁes that Z ∈D, and by the
Doob-Meyer decomposition (10.10) can be rewritten as Z = M −Awith a martingale
M and a predictable process A with ﬁnite variation. Hence, Z is a semimartingale,
and X is also a semimartingale.
Example 10.3 Assume X is a cadlag process with independent increments. Then
Zt = 
s≤t ΔXsI{ΔXs |≥1} is the process with independent increments and with ﬁnite
variation. Deﬁne Y = X −Z and observe that it has jumps bounded by one, and
again, the process with independent increments. Hence, Yt −EYt is a martingale,
and we arrive to conclusion: X is a semimartingale if and only if EYt has the ﬁnite
variation.
Example 10.4 Let X be an integrable right-continuous adapted process deﬁned on
[0, ∞]. We call it a quasimartingale on [0, ∞], if
Var(X) =
sup
0≤t0<...<tn ≤∞
E
 n

0
E(Xti+1 −Xti |Fti)


< ∞.

158
10
General theory of stochastic processes under “usual conditions”
The quasimartingale X admits the Fisk decomposition X = M + Y −Z, where M is
a martingale, Y and Z are non-negative supermartingales on [0, ∞]. Hence, it is a
semimartingale.
Now we want to discuss the question about semimartingales and change of equiv-
alent probability measures.
Theorem 10.10 If P and Q are equivalent probability measures on a measurable
space (Ω, F ), then each semimartingale with respect to P will be a semimartingale
w.r. to Q.
Proof is based on the following lemmas.
Lemma 10.10 Let N be a positive local martingale w.r. to Q. Then N−1 is a semi-
martingale w.r. to Q.
Proof If Nt ≥a > 0, then N−1
t
≤a−1, and therefore EN−1
t
< ∞, t ≥0. Note that
x−1 is convex. By the Jensen inequality N−1
t
will be a submartingale, and hence, it is
a semimartingale w.r. to Q by Example 10.2. In general case we consider a sequence
of convex functions fn(x) such that fn(x) = 1
x on [1/n, ∞) and [0, 1/n] the graph
of fn is the tangent to the curve y = 1/x at the point 1/n. For each t ≥0 we have
E fn(Nt) < ∞, which implies that Yn = fn(N) is a submartingale w.r. to Q for each
n = 1, 2, . . . . Taking s.t.’s τn = inf(t : Nt ≤1/n) we get a localizing sequence such
that Yn = 1/N on ⟦0, τn⟧. So, by Theorem 10.9 1/N is a semimartingale.
□
Lemma 10.11 The product of semimartingales is a semimartingales.
Proof Let us prove it (it is enough) for X2. We use X = M + V, where M is a
locally bounded martingale, and V is a process with ﬁnite variation, as stated in the
fundamental lemma.
Taking a localizing sequence (τn)n=1,2,... we get Mτn as a bounded martingale,
Vτn with bounded variation on ⟦0, 1/n⟧. Let us show that (Mτn + Bτn)2 is a semi-
martingale. The term (Mτn)2 is a submartingale. As far as (Vτn)2 we consider a
subdivision 0 ≤t0 < t1 < . . . < tn = t of [0, t] and ﬁnd that

i
(Vτn
ti+1)2 −(Vτn
ti )2 =

i
Vτn
ti+1 + Vτn
ti
 Vτn
ti+1 −Vτn
ti

≤2
∫t
0
dVτn
s


i
Vτn
ti+1 −Vτn
ti


≤2
∫t
0
dVτn
s

2
.
To treat the term MτnVτn, we note that Mτn
t
= E(M+
τn |Ft) −E(M−
τn |Ft) and Vτn
is the diﬀerence of two increasing processes. It means that we can consider only the
case of non-negative Mτn and Vτn. The process Mτn
t
Vτn
t
−ΔVτn I{τn ≤t }
 = Mτn
t Un
t
is a submartingale, and MτnVτn = MτnUn on ⟦0, τn⟧. The application of Theorem
10.9 completes the proof of Lemma.
□

10.3
On stochastic calculus for semimartingales
159
Let us come back to the proof of Theorem. Denote Z∞= dQ
dP on (Ω, F ) and
ﬁnd that Zt = EP(Z∞|Ft) is a martingale w.r. to P and Z∞is positive P and Q-a.s.
Obviously, X is a local martingale w.r. to P ⇔XZ−1 is a local martingale w.r. to Q.
Writing X as the product X
Z Z we get the statement from Lemma 10.10 and Lemma
10.11.
Remark 10.11 We deﬁned [X, X] by (10.20). It turns out one can prove that
[X, X]t = P −limn
n
1(Xti −Xti−1)2, and it is invariant regarding equivalent changes
of measures. Similar fact is true also for [X,Y] (see (10.21)).
10.3
On stochastic calculus for semimartingales
We extend here Ito’s calculus to bigger classes of processes deﬁned on a standard
stochastic basis (Ω, F, (Ft)t ≥0, P). A scheme of such extension will be presented
sequentially for square-intgerable martingales, local martingales and semimartin-
gales.
As we know (see, for example, Corollary 10.1 and Remark 10.7), any M ∈M2
is described as Mt = E(M∞|Ft), where M∞∈L2(Ω, F, P). It creates a possibility to
think about M2 as a Hilbert space with the scalar product (M, N) = EM∞N∞and
the norm ||M|| = (EM2
∞)1/2 for M, N ∈M2.
Let us ﬁx M ∈M2 and deﬁne
S2(M) =

φ : φ is predictable , E
∫∞
0
φ2
sd[M, M]s < ∞

with the norm ||φ||S2(M) =

E
∫∞
0 φ2
sd[M, M]s
	1/2
.
In this space we consider a subspace S2
step(M) of predictable processes of the
form
φ = φ∗
0I{0} +
n−1

i=1
φiI(ti,ti+1,
where φ∗
0 −F0-measurable, φi −Fti-measurable, i = 1, 2, . . ., n.
for φ ∈S2
step(M) we deﬁne the stochastic integral of φ w.r. to M as the process
of M2 :
(φ ◦M)t =
∫∞
0
I(s,t](s)φsdMs =
n

i=1
φi(Mti+1∧t −Mti∧t), t ≥0.
(10.22)
Using relation (10.22) we can easily obtain the following properties of φ ◦M :
(1) Isometry: ||φ ◦M|| = ||φ||S2(M).
(2) Continuity of (φ ◦M)t if M is continuous.
(3) Indistinguishability of jumps Δ(φ ◦M)t and φtΔMt, t > 0.

160
10
General theory of stochastic processes under “usual conditions”
The subspace S2
step(M) is dense in S2(M), and as in case of stochastic integration
w.t. to a Wiener process, one can extend the deﬁnition of φ ◦M to the whole space
S2(M) with the properties (1)-(3) above.
Now we want to provide a more tight connection of φ ◦M with quadratic brack-
ets of M and φ ◦M. Creating such a connection the following Kunite-Watanabe
inequality is useful.
Lemma 10.12 Let M and N ∈M2, and φ and ψ be bounded measurable processes.
Then
∫∞
0
|φs||ψs||d[M, N]s| ≤
∫∞
0
φ2
sd[M, M]s
1/2 ∫∞
0
ψ2
s d[N, N]s
1/2
. (10.23)
To prove (10.23), which is an analog of the Cauchy-Schwartz inequality, we consider
for λ ∈R and s ≤t the diﬀerence
[M + λN, M + λN]t −[M + λN, M + λN]s.
It is non-negative, and, hence,
|[M, N]t −[M, N]s|2 ≤([M, M]t −[M, M]s) ([N, N]t −[N, N]s) .
Take φ = n
i=1 φiI(ti,ti+1], ψ = m
j=1 ψjI(tj,tj+1] with bounded r.v.’s φi and ψj, we
obtain from the above inequality for brackets (10.23). After this we extend (10.23)
to the class of all bounded measurable functions φ and ψ using limit arguments, as
usual.
Theorem 10.11 For M ∈M2 and φ ∈S2(M) the stochastic integral φ ◦M is a
unique L ∈M2 such that for any N ∈M2 and any predictable bounded ψ
(1) [L, N] = φ ◦[M, N],
(2) ψ ◦[φ ◦M, N] = ψφ ◦[M, N] = [ψφ ◦M, N] and ψ ◦(φ ◦M) = ψφ ◦M,
(3) (φ ◦M)c = φ ◦Mc, (φ ◦M)d = φ ◦Md.
In particular, for a s.t. τ and process ψ = I⟧0,τ⟧we have equalities
(φ ◦M)τ =
∫τ
0
φsdMs = (ψ ◦(φ ◦M))∞= ((ψφ) ◦M)∞
=
∫∞
0
I⟧0,τ⟧φsdMs.
Proof Due
to the properties
of
φ ◦M
and
Lemma 10.12
the
mapping
φ →E

(φ ◦M)∞N∞−
∫∞
0 φsd[M, N]s
	
is continuous on S2(M) for any N ∈M2.
Further, It = (φ ◦M)tNt −
∫t
0 φsd[M, N]s is an uniformly integrable process,
and for any s.t. τ EIτ = 0. Hence, by Lemma 9.4 the process (It) is a martingale,
and we arrive to the statement (1). As far as the uniqueness, assume L and L′ ∈
M2 and [L, N] = φ ◦[M, N] for any N ∈M. Then we have [L −L′, N] = 0 and

10.3
On stochastic calculus for semimartingales
161
[L −L′, L −L′] = 0. Hence, (L −L′)2 is a martingale and we obtain equality L = L′.
Other statements (2)-(3) are almost obvious.
□
Now we show the way of construction of stochastic integral for M ∈Mloc and
a locally bounded predictable process φ, i.e. φτn I(τn>0) is bounded for a localizing
sequence of s.t.’s (τn)n=1,2,....
To deﬁne such a stochastic integral φ ◦M we use the fundamental lemma, when
M = U + V with U ∈M2
loc, V is a local martingale with bounded variation. Then
for a localizing sequence (τn)n=1,2,... for φ, U,V we deﬁne
(φ ◦M)t =
∫t
0
φτn
s dUτn
s
+
∫t
0
φτn
s dVτn
s
on ⟦0, τn⟧. To continue the construction we need the following lemma.
Lemma 10.13 (1) If V is a martingale with integrable variation and φ is predictable
with E
∫∞
0
|φs|dVs| < ∞, then the Lebesgue-Stieltjes integral
∫t
0 φsdVs ∈M.
(2) if V ∈M2 and φ is bounded, then the Stochastic integral (φ ◦V)t and the
Lebesgue-Stieltjes integral
∫t
0 φsdVs are indistinguishable.
Proof We prove statement (1) only because second statement can be proved
in a similar manner. Deﬁne S′(V) the set of predictable processes φ such that
E
∫∞
0
|φs|dVs| < ∞. Then ||φ||S′(V) = E
∫∞
0
|φs||dVs| deﬁnes the norm of this space.
If ||φn −φ||S′(V) →0, n →∞, then
E

sup
t

∫t
0
φn
s dVs −
∫t
0
φsdVs


≤E
∫∞
0
|φn
s −φs||dVs|
≤||φn −φ||S′(V) →0, n →∞.
Using these ﬁndings we make a transition from step-predictable functions to all
functions of space S′(V).
□
Coming back to the deﬁnition of φ ◦M by relation (10.3) one can concluded with
the help of Lemma 10.13 that φ ◦M ∈Mloc and its deﬁnition does not depend on
the decomposition M = U + V. Moreover, we arrive to statements which are similar
to (1)-(3) of Theorem 10.12 if we replace class M2 by Mloc.
The ﬁnal step of construction of stochastic integral is the case of semimartingale.
Assume φ is a predictable locally bounded process and X is a semimartingale of the
form
X = X0 + M + A,
(10.24)
where X0 is a ﬁnite F0-measurable r.v., M ∈Mloc, A ∈V.
Let us deﬁne
(φ ◦X)t = (φ ◦M)t +
∫t
0
φsdAs,
(10.25)
where
∫t
0 φsdAs is the Lebesgue-Stieltjes integral.

162
10
General theory of stochastic processes under “usual conditions”
According to Lemma 10.13 the deﬁnition (10.25) of (φ ◦X) does not depend on
the decomposition (10.24). As a result, let us formulate the list of natural properties
of φ ◦X :
(1) φ ◦X is a semimartingale,
(2) (φ ◦X)c = φ ◦Xc,
(3) jumps Δ(φ ◦X)t and φtΔXt are indistinguishable,
(4) (φ ◦X)τ =
∫∞
0
I⟧0,τ⟧φsdXs =
∫τ
0 φsdXs for any ﬁnite s.t. τ.
Remark 10.12 It is interesting to note that there is no hope to go beyond semimartin-
gales in extension of stochastic integration.
Let X1, . . ., Xd be d semimartingales taking the values in R. It is convenient
to collect them to a d-dimensional process Xt = (X1
t , . . ., Xd
t ), called a d-valued
semimartingale.
Let F : E = Rd →R, d ≥1, be a twice continuously diﬀerentiable function.
Then one can transform X with the help of this smooth function. It turns out the
transformed process F(Xt) will be a semimartingale satisfying the next generalized
Ito’s formula:
F(Xt) = F(X0) +
d

i=1
∫t
0
DiF(Xs−)dXi,c
s
+1
2

1≤i,j,≤d
∫t
0
DiDjF(Xs−)d[Xi,c, X j,c]s
+

s≤t

F(Xs) −F(Xs−) −
d

i=1
DiF(Xs−)ΔXi
s

,
(10.26)
where DiF(x) = ∂F(x)
∂i
= ∂F(x1,...,xd)
∂xi
, DiDjF(x) = ∂2F(x)
∂xi∂x j , i, j = 1, . . ., d.
Remark 10.13 Let us note that processes DiF(Xs−) and DiDjF(Xs−) are predictable
and locally bounded, and therefore all integrals in (10.26) are well-deﬁned.
Deﬁning the localizing sequence τn = inf{t : |Xt| ≥n}, we obtain that |Xt| and
|Xt−≤n on ⟦o, τn⟦, n = 1, 2, . . . Further, letting Kn = sup|x |≤n

i,j |DiDjF(x)|,
weget with the help of the Taylor decomposition that
|

s<τn
(F(Xs) −F(Xs−) −
d

i=1
DiF(Xs−)ΔXi
s)| ≤Kn
2

i

sτn
|ΔXi
s|2.
Hence, for almost all ω both series

s<τn
|F(Xs) −F(Xs−) −
d

i=1
DiF(Xs−)ΔXi
s)|
and

10.3
On stochastic calculus for semimartingales
163

s≤τn
|F(Xs) −F(Xs−) −
d

i=1
DiF(Xs−)ΔXi
s)|
converge, and we can conclude that

s≤t
|F(Xs) −F(Xs−) −
d

i=1
DiF(Xs−)ΔXi
s)|
converges for all t > 0.
This observation generates the idea that the formula (10.26) can be proved without
big technical diﬃculties in between moments of jumps, i.e. in a pure continuous case.
This is the reason that we prove (10.26) for a one-dimensional continuous semi-
martingale Xt = X0 + Mt + At, M ∈Mc
loc, A ∈V. Using a localization procedure
we can reduce the proof to the case when continuous processes M, A, [M, M] are
bounded as well as X0, F, F′ and F′′, and the upper bound for |F|, |F′|, |F′′| is
denoted by C.
Let us use the Taylor decomposition
F(y) −F(x) = (y −x)F′(x) + 1
2(y −x)2F′′(x) + o(x, y)
where o(x, y) ≤ϵ(|y −x|)|y −x|2 and ϵ
is a non-decreasing function with
limt→0 ϵ(t) = 0.
Take a > 0 and deﬁne a sequence of s.t.’s (τn)n=0,1,... as follows
τ0 = 0, . . ., τi+1 = t ∧(τi + a) ∧inf{s > τi : Ms −Mτi > a,
[M, M]s −[M, M]τi > a or |As −Aτi | > a}, . . .
Obviously, for each ω : τi(ω) = t except for a ﬁnite number of i, and we can write
the following equality using the Taylor formula above:
F(Xt) −F(X0) =

i
F(Xτi+1 −F(Xτi )
=

i

F′(Xτi )(Xτi+1 −Xτi ) + 1
2 F′′(Xτi+1)(Xτi+1 −Xτi )2 + o(Xτi, Xτi+1

.
(10.27)
For the martingale part of (10.27) we have

164
10
General theory of stochastic processes under “usual conditions”
E
∫t
0
F′(Xs)dMs −

i
F′(Xτi)(Mτi+1 −Mτi)
2
=E

i
∫τi+1
τi
F′(Xs) −F′(Xτi)2 d[M, M]s

≤E

sup
i
|F′(Xs) −F′(Xτi |2 · [M, M]t

→0
(10.28)
as a →0.
The term of (10.27) with process A can be treated similarly, and 
i F′(Xτi)(Aτi −
Aτi) converges to
∫t
0 F′(Xs)dAs in L1-sense.
The second term in (10.27) we represent as a sum of three components.
For the ﬁrst component we have
|

i
F′′(Xτi)(Aτi+1 −Aτi)2| ≤C sup
i
|Aτi+1 −Aτi |
∫t
0
|dAs|
≤Ca
∫t
0
|dAs| →0, a →.
(10.29)
for the second component we obtain
|

i
F′′(Xτi)(Aτi+1) −Aτi)(Mτi+1 −Mτi)| ≤C sup
i
|Mτi+1 −Mτi |
∫t
0
|dAs|
≤Ca
∫t
0
|dAs| →0, a →0.
(10.30)
Taking into account that M2 −[M, M] is a martingale, we get for the third component
that
E
⎡⎢⎢⎢⎢⎣

i
F′′(Xτi)(Mτi+1 −Mτi)2 −

i
F′′(Xτi)([M, M]τi+1 −[M, M]τi)
2⎤⎥⎥⎥⎥⎦
=

i
E

(F′′(Xτi))2 
(Mτi+1 −Mτi)2 −([M, M]τi+1 −[M, M]τi)
	2
≤2C2E

sup
i
|Mτi+1 −Mτi |2M2
t

+ 2C2E

sup
i
|[M, M]τi+1 −[M, M]τi | · [M, M]t

≤2C2a2EM2
t + 2C2aE[M, M]t →0, a →0.
(10.31)
The remaining term in (10.27) can be treated as follows

10.3
On stochastic calculus for semimartingales
165
E

i
o(Xτi, Xτi+1) ≤E

i
(Xτi+1 −Xτi)2ϵ(|Xτi+1 −Xτi |)

≤E

2ϵ(2a)

i
(Aτi+1 −Aτi)2 + 2ϵ(2a)

i
(Mτi+1 −Mτi)2

≤2ϵ(2a)E

a
∫t
0
|dAs| + M2
t

→0, a →0.
(10.32)
Putting together relations (10.28)-(10.32) we complete the proof.
Now we are ready to consider stochastic diﬀerential equations with respect to
semimartingale. The main result is contained in the next theorem.
Theorem 10.12 Let N = M + A be a semimartingale, M ∈Mloc, A ∈V. Assume
function F : R+ × Ω × R →R satisﬁes the conditions
(1) f (s, ω, ·) is a Lipschitz function with a constant K;
(2) f (s, ·, x) is Fs-measurable;
(3) f (·, ω, ·) is a continuous function.
Then the SDE w.r. to N
Xt(ω) = X0(ω) +
∫t
0
f (s, ω, Xs−(ω))dNs(ω)
(10.33)
has a unique solution as a cadlag adapted process with the initial value X0(ω) −F0-
measurable ﬁnite random variable.
Proof Obviously, (1)-(3) guarantee that the integral in the right-hand side of (10.33)
is well-deﬁned. The proof includes a couple of steps. We start with the assumption
that processes
[M, M]t and
∫t
0
|dAs| are bounded by b > 0
(10.34)
and
| f (t, ω, 0)| ≤c for all t, ω.
(10.35)
Let H be a class of cadlag processes X such that X∗= supt |Xt| ∈L2, X0 = 0.
Deﬁne the norm in this space ||X|| = ||X∗||L2.
Denote for x ∈H
U(X)t =
∫t
0
f (s, ω, Xs−)dNs.
Lemma 10.14 The process U(x) ∈H if X ∈H. Moreover, for processes X and
Y ∈H we have
||U(X) −U(Y)|| ≤h||X −Y||, h = K(2
√
b + b).
(10.36)

166
10
General theory of stochastic processes under “usual conditions”
Proof For zero-process we have
U(0)t =
∫t
0
f (s, ω, 0)dMs +
∫t
0
f (s, ω, 0)dAs = Lt + Vt.
Process L ∈Mloc, and due to (10.34)-(10.35)
[L, L]∞=
∫∞
0
f 2(s, ω, 0)d[M, M]s ≤c2b,
(10.37)
and E(L∗)2 ≤4c2b by Doob’s inequality.
□
For process Vt we get from (10.34)-(10.35) that
V∗≤
∫∞
0
|dVs| ≤
∫∞
0
| f (s, ω, 0)||dAs| ≤cb
(10.38)
and hence E(V∗)2 ≤c2b2. Relations (10.37)-(10.38) show that U(X) ∈H. Further,
denote Z = X −Y and ﬁnd that
U(X)t −U(Y)t =
∫t
0
( f (Xs−) −f (Ys−))dMs +
∫t
0
( f (Xs−) −f (Ys−))dAs
=L′
t + V ′
t , L′ ∈Mloc, V ′ ∈V.
Using similar reasonings as in (10.37)-(10.38) we obtain for processes L′ and V ′
that
□
[L′, L′]∞=
∫∞
0
( f (Xs−−f (Ys−))2d[M, M]s ≤K2b(Z∗)2,
(10.39)
E((L′)∗)2 ≤4K2bE(Z∗)2 and
V∗≤
∫∞
0
K|Zs||dAs| ≤KbZ∗.
(10.40)
It follows from (10.39)-(10.40) that
||U(X) −U(Y)|| ≤K||X −Y||(b + 2
√
b),
and we get (10.36).
Lemma 10.15 Assume conditions (10.34)-(10.35) are satisﬁed, and h = K(b +
2
√
b) < 1. Then there exists a unique cadlag adapted process X solving the equation
Xt =
∫t
0
f (s, ω, Xs−)dNs.
Proof Due to h < 1 there exists a unique solution X from space H. Let us note from
conditions (1)-(2) of the theorem that
|ΔNs| ≤|ΔMs| + |ΔAs| = (Δ[M, M]s)1/2 + |ΔAs| ≤
√
2b + b.

10.3
On stochastic calculus for semimartingales
167
So, if Z is a cadlag adapted process, Zt =
∫t
0 f (s, ω, Zs−)dNs, we can deﬁne stopping
times τZ
n = inf(t : |Zt| ≥n), n = 1, 2, . . ., and get
ΔZτZ
n = f (τZ
n , Zτz
n−)ΔNτZ
n and
|ΔZτZ
τn | ≤(c + nK)(2b +
√
2b).
Hence, the process Z is locally bounded and locally in space H. Due to uniqueness
in H we obtain Z = X.
□
Lemma 10.16 Assume that condition (10.34) is fulﬁlled and h = K(b + 2
√
b) < 1,
then there exists a unique cadlag adapted process X solving equation
Xt =
∫t
0
f (s, ω, Xs−)dNs.
Proof Let
τn = inf(t : | f (t, ω, 0)| ≥n),
n = 1, 2, . . .
and
fn(t, ω, x) =
f (t, ω, x)I{0<t ≤τn }. Obviously, functions fn satisfy (10.35) with c = n, and each
equationY n
t =
∫t
0 fn(s, ω,Y n
s−)dNs has a unique solution. Due to fn+1 = fn on ⟧0, τn⟧
we have Y n = Y n+1 on ⟦0, τn⟧.
Further, an adapted process X solves the equation Xt =
∫t
0 f (s, ω, Xs−)dNs ⇔
for each τn we have Xτn
t
=
∫t
0 f (s, ω, Xτn
s−Nτn
s . Let us deﬁne now the process X as
follows X = Y n on ⟦0, τn⟧, X0 = 0, and ﬁnd the unique solution.
□
Lemma 10.17 Assume a semimartingale N has jumps |ΔNt| ≤b/4 and both b, h =
K(b + 2
√
b) < 1. Then the equation Xt =
∫t
0 f (s, ω, Xs−)dNs has one and only one
solution.
Proof Under the conditions of Lemma we can write N = M + A, M ∈Mloc and A
is a predictable process with locally bounded variation. Without loss of generality
we can assume that M ∈M and predictable process A has integrable variation. Then
|ΔAτ| = |E(ΔNτ|Fτ−) −E(ΔMτ|Fτ−)| = |EΔNτ|Fτ−)| ≤b/4
and we have a boundedness of Δ[M, M]t = (ΔMT)2 and |ΔAt| by b/4. Denote
Dt =
∫t
0 |dAs| and put τ0 = 0, . . ., τn = inf(t > τn−1 : Dt −Dτn−1 ≥b/2). We have
∫
⟧τn,τn+1⟧d[M, M]s ≤b and
∫
⟧τn,τn+1⟧|dAs| ≤b for all n = 1, 2, . . .
By Lemma 9.16 there is one and only one solution on ⟦0, τ1⟧, and denote it by
X1. At the interval ⟧τ1, τ2⟧we have equation
Xt = X1
τ1 +
∫
⟧τ1,t⟧
f (s, ω, Xs−)dNs.
Obviously, X solves (86) ⇔Y = X −X1
τ1 is a solution of the equation
Yt =
∫t
0
f (s, ω,Ys−+ X1
τ1)dNs.

168
10
General theory of stochastic processes under “usual conditions”
So, we get a unique solution X2 at this interval and so on.
□
Let us come back to the proof of the theorem. We assume that b as in Lemma
10.17 and we have a non-decreasing sequence of s.t.’s τ1 ≤τ2 ≤. . . ≤τn ≤. . . at
which ΔNt| > b/4. Construct the following semimartingale
N1
t = MtI(t<τ1) + Nτ1−I(t ≥τ1).
A cadlag process X is a solution of (10.33) on ⟦0, τ1⟧⇔the process X1
t = XtI(t<τ1) +
Xτ1−I(t ≥τ1) is a solution on ⟦0, τ1⟧of the equation X1
t = X0
∫t
0 f (s, ω, X1
s−)dN1
s . On
the interval ⟦0, τ1⟧the process N1 satisﬁes the conditions of Lemma 10.17, and
hence the last SDE has a unique cadlag adapted solution X1 on ⟦0, τ1⟧. We can
continue this construction on ⟦τ1, τ2⟧and so on.
Example 10.5 Let us consider the linear SDE:
Zt = 1 +
∫t
0
Zs−dNs.
(10.41)
We know from Theorem 10.12 that a unique solution of the equation (10.41) exists.
It turns out it admits a special form which is similar to the Girsanov exponent:
Zt = exp{Nt −1
2[Nc, Nc]t}
 
s≤t
(1 + ΔNs)e−ΔNs .
(10.42)
The form of solution in (10.42) is called a stochastic exponent or the Doleans
exponent, denoted by Et(N). To prove this, we denoteYt = Nt −1
2[Nc, Nc]t and Xt =
!
s≤t(1 + ΔNs)e−ΔNs, and apply Ito’s formula to the function F(Yt, Xt) = exp(Yt)Xt.
Problem 10.6 Prove the properties of stochastic exponents w.r. to semimartingales:
(1) Let Et(N) be a stochastic exponent w.r. to a semimartingale N with ΔNt 
−1,
t ≥0. Then
1
Et(N) = Et(−N∗), where N∗
t = Nt −[Nc, Nc]t −
s≤t
(ΔNs)2
1+ΔNs .
stochastic exponent w.r. to a semimartingale N with ΔNt  −1, t ≥0. Then
1
Et(N) = Et(−N∗), where N∗
t = Nt −[Nc, Nc]t −
s≤t
(ΔNs)2
1+ΔNs .
(2) If N inMloc, then Et(N) ∈Mloc.
(3) Et(N) = 0 for (t, ω) ∈⟦τ, ∞⟦, where τ = inf(t : ΔNt = −1).
(4) Et(U)Et(V) = Et(U + V + [U,V]), where U and V are semimartingale. This
property is called the rule of multiplication of stochastic exponents.
Remark 10.14 The equation (10.33) admits further generalizations. One can prove
an analog of Theorem 9.13 for equation
dXt(ω) = b(t, ω, Xt−dAt + σ(t, ω, Xt−)dMt,
(10.43)
where M ∈Mloc, A ∈V, both coeﬃcients b and σ are Lipschitz’s functions, and
b(t, ω, x) is optional and σ(t, ω, x) is predictable as functions of (t, ω).

10.4
The Doob-Meyer decomposition: proof and related remarks
169
Let us note that the equation 10.43 can be also considered for a multidimensional
semimartingale X = A + M, and for matrix-valued coeﬃcients b and σ.
Remark 10.15 The equation (10.33) admits further important results. One can prove
an analog of comparison Lemma 9.1 for stochastic diﬀerential equations (10.43) with
a predictable increasing process A = (At)t ≥0.
Moreover the Ito’s formula (10.26) admits a further generalization to a class of convex
functions F. The corresponding formula is similar to (10.26) where the second term
in the right hand side is replaced by a continuous process V from V. The process V
admits a representation with the help of a local time of X.
10.4
The Doob-Meyer decomposition: proof and related
remarks
The leading idea of this short book as it was stated in preface dictates the way of
exposition avoiding too long proofs and too many technical details. That is why
the proof of the Doob-Meyer decomposition was omitted in Section 10.1. However,
the proof of this fundamental fact of stochastic analysis must be presented in an
appropriate manner.
It is necessary to note that the initial Doob-Meyer decomposition in continuous time
was given by Meyer in the form
Xt = X0 + Mt + At,
t ≥0,
(10.44)
where X = (Xt)t ≥0 is a submartingale of class (D), M = (Mt)t ≥0, M0 = 0, is a
martingale, A = (At)t ≥0, A0 = 0, is a “natural” increasing process.
The notion “natural” means that for every bounded cadlag martingale m = (mt)m≥0
on a standard stochastic basis (Ω, F, (Ft)t ≥0, P) on the following equality is satisﬁed
E
∫t
0
msdAs = E
∫t
0
ms−dAs.
(10.45)
This characterization of A looks very artiﬁcial in comparison with discrete time,
where A is predictable. Nevertheless, since that time there were done several proofs
of the Doob-Meyer decomposition in these terms, including the proof of Rao who
used the limiting arguments for transition from discrete time to continuous time
decomposition. Doleans was the ﬁrst who noted that the notions “natural” and
“predictable” are equivalent in (10.44).
This section is devoted to the proof of (10.44) in such a new fashion, and as in
many other books we work with this form only. Nevertheless, before providing the
proof which is based on the paper [2], we want to compare notions “natural” and
“predictable”.
First of all, one can show that Emt At = E
∫t
0 msdAs and therefore, the condition
(10.45) is equivalent to the next one

170
10
General theory of stochastic processes under “usual conditions”
Emt At = E
∫t
0
ms−dAs.
(10.46)
Problem 10.7 Prove (for discrete time) that an increasing process A is natural ⇐⇒
A is predictable, i.e. An-Fn−1-measurable, n ≥1.
Hint: We rewrite (10.46) for the discrete time case as follows
EmnAn = E
n

1
mk−1ΔAk.
It follows from this condition that Emn(An −E(An|Fn−1)) = 0 and even E|An −
E(An|Fn−1) = 0 which leads to predictability of A.
The opposite implication follows from the equality E n
1 AkΔmk = 0 and the repre-
sentation
n

1
AkΔmk = Anmn −mn−1ΔAn −mn−2ΔAn−1 −...
which leads to EAnmn = E n
1 mk−1ΔAk.
Let us show that the decomposition (10.44) is unique in the class of natural processes
A. To prove it we assume that there exist two such decompositions for X with
martingales M′, M′′, and with the natural increasing processes A′, and A′′. Hence,
M′
t + A′
t = M′′
t + A′′
t for all t ≥0. Deﬁne process Nt = A′
t −A′′
t = M′
t −M′′
t , which
is a martingale with ﬁnite variation.
Further, for every bounded martingale m = (mt)t ≥0, we have due to (10.46) that
Emt.(A′
t −A′′
t ) = E
∫t
0
ms−dNs = lim
n→∞E
kn

j
mt(n)
j−1(Nt(n)
j
−Nt(n)
j−1),
where (t(n)
k )k=0,...,kn is a sequence of subdivision of (0,T] with diameter Δt(n)
k
→
0, n →∞. Obviously, Emt(n)
j−1ΔNt(n)
j
= 0, and, hence, Emt.(A′
t −A′′
t ) = 0, t ≥0. To
ﬁnish the proof we take an arbitrary integrable random variable ζ and deﬁne a
martingale ζt = E(ζ|Ft). Then Eζ.(A′
t −A′′
t ) = 0 for every such random variable
which leads to conclusion that A′
t = A′′
t (a.s) for all t.
Let us prove the Doob-Meyer decomposition (10.44) assuming for simplicity that
t ∈[0, 1].
Denote D = {D1, D2, ..., Dn, ...}, where n = 1, 2, ..., Dn = {0, 1
2n, 2
2n, ..., j
2j , ...}, the
dyadic numbers of the interval [0, 1].
Consider the process X = (Xt)t ≥0 on this discrete time, and write the Doob-Meyer
decomposition for t ∈Dn:
Xt = Mn
t + An
t ,
(10.47)
An
t −An
t−1
2n = E(Xt −Xt−1
2n |Ft−1
2n ),
Mn
t = Xt −An
t .

10.4
The Doob-Meyer decomposition: proof and related remarks
171
Here Mn = (Mn
t )t ∈Dn is a martingale, An = (An
t )t ∈Dn is increasing and predictable
with respect to (Ft)t ∈Dn.
The idea is to take a limit in (10.47), and as a result, to obtain (10.44).
To make such limiting transition carefully we need the following lemma.
Lemma 10.18 Assume ( fn)n≥1 is a uniformly integrable sequence of random vari-
ables on the probability space (Ω, F, P). Then there exists gn ∈conv{ fn, fn+1, ...}
which converges in space L1(Ω, F, P).
We will use here a version of the Komlos Lemma:
If ( fn)n≥1 is a bounded sequence on a Hilbert space, then for each n one can pick
gn ∈conv{ fn, fn+1, ...} such that (gn)n≥1 will converge in the norm ∥.∥2 of this
space.
To Prove this lemma, we deﬁne the ﬁnite number
a = sup
n
inf{∥g∥2 : g ∈conv{ fn, fn+1, ...}}
For each n we can take some gn ∈conv{ fn, fn+1, ...} with the norm ∥gn∥2 ≤a + 1
n.
For a ﬁxed ε > 0, and a big enough n we obtain for all m, k ≥n that
∥(gk + gm)/2∥2 > a −ε.
We get that (gn) is fundamental due to
∥(gk −gm)∥2
2 = 2∥gk∥2
2 + 2∥gm∥2
2 −∥(gk + gm)∥2
2 ≤4(a + 1
n)2 −4(a −ε)2,
and therefore this sequence converges.
Proof of lemma 10.18: We truncate fn and denote truncated functions by f (i)
n
=
fn.I{|fn |≤i}, n = 1, 2, .... Then for every i we get a bounded sequence ( f (i)
n )n≥1 for
which the Komlos lemma can be applied in the following manner.
Problem 10.8 For each n = 1, 2, ... there exist convex weights (λn
n, ..., λn
Nn) such
that Nn
j=n λn
j f (i)
j
converge on space L2(Ω) for each i = 1, 2, ....
Hint: Use the Komlos lemma to ﬁnd convex weights λn
n, ..., λn
Nn with the convergent
sum Nn
j=n λn
j f (i)
j
as n →∞for i = 1, 2, ..., m and apply a diagonalization procedure
to get a desirable result.
Now using uniform integrability of ( fn) we obtain that f (i)
n converges uniformly in n
to fn in L1(Ω) as i →∞, and therefore uniformly in n:
Nn

j=n
λn
j f (i)
j
→
Nn

j=n
λn
j fj
in
L1(Ω)
as
i →∞.
Lemma 10.19 The sequence (Mn
1 )n≥1 is uniformly integrable.

172
10
General theory of stochastic processes under “usual conditions”
Proof Without loss of generality we can put X1 = 0 and Xt ≤0 for t ≤1, because
there is an obvious transition from Xt to Xt −E(X1|Ft). In such a case Mn
1 = −An
1
and
Xn
τ = −E(An
1 |Fτ) + An
τ
(10.48)
for every s.t. τ w.r. to (Ft)t ∈Dn.
Let us derive from assumption X ∈(D) that (An
1)n≥1 is uniformly integrable. Deﬁne
the following s.t.
τn(c) = inf{(j −1)/2n : An
j
2n > c} ∧1,
c > 0,
and note
{τn(c) < 1} ⊆{τn(c
2) < 1},
An
τn(c) ≤c.
It follows from (10.48) that
Xτn(c) ≤−E(An
1 |Fτn(c)) + c.
Thus,
EAn
1.I{An
1 >c} =EE(An
1 |Fτn(c)).I{τn(c)<1}
≤c.P(τn(c) < 1) −EXτn(c).I{τn(c)<1}
and by (10.48)
E(−Xτn( c
2 )).I{τn( c
2 )<1} =E(An
1 −An
τn( c
2 )).I{τn( c
2 )<1}
≥E(An
1 −An
τn( c
2 )).I{τn(c)<1}
≥c
2P{τn(c) < 1}.
These inequalities imply that
EAn
1.I{An
1 >c} ≤−2EXn
τn( c
2 ).I{τn(c)<1} −EXn
τn(c).I{τn(c)<1}.
(10.49)
We also note
P{τn(c) < 1} = P{An
1 > c} ≤1
c EAn
1 = −1
c E(Mn
1 ) = −1
c EX0,
and conclude that
lim
c→∞P(τn(c) < 1) = 0
uniformly in n.
Assumption X ∈(D) together with (10.49) imply that (An
1)n≥1 is uniformly inte-
grable as well as (Mn
1 )n≥1 = (X1 −An
1)n≥1.
Now we are ready for a limiting transition as n →∞in (10.47).
First we extend Mn to the whole interval [0, 1] by setting Mn
t = E(Mn
1 |Ft). Accord-
ing to Lemma 10.18 and Lemma 10.19 there exist M ∈L1(Ω) and convex weights

10.4
The Doob-Meyer decomposition: proof and related remarks
173
(λn
j )j=n,...,Nn such that Mn
1 (λ) = Nn
j=n λn
j M j
1 converges to M on space L1(Ω). More-
over, by Jensen’s inequality for each t ∈[0, 1]:
Mn
t (λ) →Mt = E(M1|Ft)
as
n →∞.
Secondly, we extend An to [0, 1] by setting An = 
t ∈Dn An
t .I(t−−1
2n ,t], t ∈[0, 1],n =
1, 2, ..., and denote An(λ) = Nn
j=n λn
j Aj.
Then the cadlag process
At = Xt −Mt,
where
t ∈[0, 1],
satisﬁes the following relations
An
t (λ) = (Xt −Mn
t (λ)) →(Xt −Mt) = At
in
L1(Ω)
for
t ∈D, n →∞.
So, we ﬁnd a subsequence Ank
t (λ) →At (a.s.) which we identify with An
t (λ) →At
(a.s.). These standard considerations lead us to conclude that A is (a.s.) increasing
on D, and therefore on the whole interval [0, 1] due to its right-continuity.
□
Lemma 10.20 Process A is predictable.
Proof: In fact we can restrict ourself by the proof that for all t ∈[0, 1] (a.s.)
lim
n sup An
t (λ) = At,
(10.50)
because the process An and An(λ) are left-continuous and adapted, and hence they
are predictable.
Problem 10.9 Let fn and f be increasing functions form [0, 1] to R1 such that f is
right-continuous and f (t) = limn→∞fn(t), t ∈D. Prove that
lim
n sup fn(t) ≤f (t)
for all
t ∈[0, 1],
(10.51)
lim
n fn(t) = f (t),
if f is continuous at
t ∈[0, 1].
(10.52)
Hint: By the right-continuity (tk ∈D, tk > t):
f (t) = lim
k→∞f (tk) = lim
k→∞( lim
n→∞fn(tk)) ≥lim
n sup fn(t),
since limn sup fn(tk) ≥limn sup fn(t).
Due to (10.51) and (10.52) the relation (10.50) can be broken at discontinuity points
of A only. The process A is cadlag, and as was shown in Section 10.1 the points of
jumps of A can be exhausted by a countable sequence of stopping times (see (10.2)
and related remarks). So, it is suﬃcient for (10.50) that limn sup An
τ(λ) = Aτ for all
s.t. τ.
By (10.51) limn
τ(λ) ≤Aτ and An
τ(λ) ≤An
1(λ) which converges to A, on space L1(Ω).
Hence, by Fatou’s lemma

174
10
General theory of stochastic processes under “usual conditions”
lim
n inf EAn
τ ≤lim
n sup EAn
τ(λ) ≤E lim
n sup An
τ(λ) ≤EAτ.
To prove that limn EAn
τ = EAτ we set σn = inf{t ∈Dn : t ≥τ}. Then σn ↓τ as
n →∞and An
τ = An
σn.
The process X belongs to class (D) and therefore
EAn
τ = An
σn = EXσn −EM0 →EXτ −EM0 = EAτ.
Lemma 10.20 is proved and hence the decomposition (10.44) is true with a martingale
M and an increasing predictable process A.

Chapter 11
General theory of stochastic processes in
applications
Abstract The main goal of this chapter is to show how the general theory developed
before can be applied to mathematical ﬁnance and statistics of random processes.
In the area of mathematical ﬁnance a semimartingale ﬁnancial market model is
introduced. Applying to this general model the technique of stochastic exponents the
fundamental questions of arbitrage and completeness of such a market are studied.
These results have a number of corollaries for modeling and option pricing (Black-
Scholes model and formula, Cox-Ross-Rubinstein model and formula etc). In the
area of statistics of random processes the technique developed above gives a possi-
bility to introduce semimartingale models. It is shown that classical discrete time and
continuous time models of stochastic approximation are embedded in a semimartin-
gale scheme. Moreover, it is proved that semimartingale stochastic approximation
procedures are strong consistent and asymptotically normal under very wide condi-
tions. In case of semimartingale regression the structural least-squared estimates are
strong consistent and their sequential versions satisfy the important ﬁxed accuracy
property (see [3], [4], [11], [13], [18], [23], [30], [31], [32], [34], and [43]).
11.1
Stochastic mathematical ﬁnance
Suppose that besides the original measure on a stochastic basis (Ω, F, (Ft)t ≥0, P),
we are given a measure ˜P locally equivalent to P and with local density (Zt)t ≥0.
The equivalence implies strict positivity of Zt (P-a.s.), t ≥0. Therefore, one can
deﬁne a local martingale N = (Nt)t ≥0 with respect to P as a stochastic integral
to P as a stochastic integral Nt =
∫t
0 Z−1
s−dZs. It leads to a stochastic exponent
form of Zt = Et(N). We already know that a local martingale is transformed to a
semimartingale (not a local martingale) under an equivalent change of measure. The
next lemma contains a result of this type. To formulate it we denote Mloc(P) and
Mloc( ˜P) classes of local martingales w.r. to P and ˜P correspondently.
© The Author(s), under exclusive license to Springer Nature Switzerland AG 2023
A. Melnikov, A Course of Stochastic Analysis, CMS/CAIMS Books in Mathematics 6,
https://doi.org/10.1007/978-3-031-25326-3_11
175

176
11
General theory of stochastic processes in applications
Lemma 11.1 Let X = (Xt)t ≥0 be a semimartingale on (Ω, F, (Ft)t ≥0, P), then
XZ ∈Mloc(P) ⇒X ∈Mloc( ˜P).
(11.1)
The proof of Lemma 11.1 can be given using a standard scheme. First, it is proved for
martingales. Second, using localization one can extend it to local martingales. The
ﬁrst step is given with the help of change of probability in conditional expectations,
which was stated before for a discrete time. A continuous time version of such change
of measure is proved in the same way.
In fact, we prove (11.1) below in the framework of a semimartingale model of
ﬁnancial markets. We deﬁne a (B, S)-market as a collection of two positive semi-
martingales B and S on given stochastic basis (Ω, F, (Ft)t ≥0, P). The values of Bt
and St are interpreted as the prices of a non-risky asset B and a risky asset S.
A pair πt = (βt, γt)t ≥0 of stochastic processes with a predictable second compo-
nent is deﬁned as a portfolio of investment strategy. The portfolio has a capital
Xπ
t = Xπ
t (x) = βtBt + γtSt, where Xπ
0 = β0B0 + γ0S0 = x ∈R, t ≥0.
The ratio Xt = St
Bt is called the discounted price of S, and the ratio X π
t
Bt is called
the discounted capital of the strategy π at the time t ≥0.
In the set of all strategies we distinguish those portfolios π such that
Xπ
t
Bt
=
Xπ
0
B0
+
∫t
0
γud
 S
B

u
.
(11.2)
We call them self-ﬁnancing and denote their collection SF. We say that (B, S)-
market admits an arbitrage at time T > 0 if there exists ˜π ∈SF such that X ˜π
0 =
0, X ˜π
t ≥0, t ≤T, P-a.s., and P(ω : X ˜π
T (ω) > 0) > 0. Such a strategy ˜π is called the
arbitrage strategy. Any probability measure ˜P locally equivalent to P is called a
local martingale measure, if the discounted price

St
Bt

∈Mloc( ˜P).
Denote the set of such measures M(X, P). It is well-known that for a semimartin-
gale (B, S)-market the absence of arbitrage is characterized as M(X, P)  ∅.
By a contingent claim with exercise time T, we understand any non-negtaive
FT-measurable random variable f . We remark that if such a claim f represents a
pay-oﬀof an option, then the option is called a European option. A strategy π ∈SF
is said to be a hedge (hedging strategy) for f (for the option with the pay-oﬀf ) if
Xπ
T (x) ≥f (a.s.) for some initial capital x. If in some class of hedging strategies π,
there is a strategy π∗such that Xπ∗
t
≤Xπ
t (a.s.) for all t ∈[0,T], then π∗is called a
minimal hedge (in this class). Usually, the minimal hedge coincides with a replicating
strategy π∗for which Xπ∗
T = f (a.s.). In this case, f is called attainable. The (B, S)-
market is said to be complete if any contingent claim is attainable. For many ﬁnancial
markets, this notion is equivalent to the uniqueness of a local martingale measure P∗,
i.e. M(X, P) = {P∗}. Otherwise, the market is called incomplete. Correspondingly,
pricing of an option with pay-oﬀf in complete and incomplete markets is achieved
with the help of martingale measures as follows:

11.1
Stochastic mathematical ﬁnance
177
C( f ) = E∗f
BT
and C∗( f ) =
sup
˜P∈M(X,P)
˜E f
B,
(11.3)
where C( f ) is the fair price and C∗( f ) is the so-called upper price of such an option.
So, we can see that an investigation of conditions under which ˜P ∈M(X, P) is
extremely important for Mathematical Finance. Let us show how it can be done for
a semimartingale (B, S)-market.
Suppose that a (B, S)-market is determined by the two equations
Bt =B0 +
∫t
0
Bu−dhu, Δhu > −1,
St =S0 +
∫t
0
Su−dHu, ΔHu > −1,
(11.4)
where h and H are given semimartingales.
Using stochastic exponents we can rewrite (11.4) as follows
Bt = B0Et(h) and St = S0Et(H).
The problem in the model (11.4) is to determine conditions under which a measure
P∗equivalent to P takes the process X = S
B into a local martingale, i.e.
P∗∈M(X, P) ⇔X = S
B ∈Mloc(P∗).
(11.5)
Let us check ﬁrst when measure P is a martingale one for the market (11.4). Using
the properties of stochastic exponents we have
Xt =X0Et(H)E−1
t (h) = X0Et(H)Et(−h∗)
=X0E

H −h + ⟨hc, hc⟩+
 (Δh)2
1 + Δh −⟨Hc, hc⟩−
 ΔHΔh
1 + Δh

=X0Et

H −h + ⟨hc, hc −Hc⟩+
 Δh(Δh −ΔH)
1 + Δh

.
(11.6)
Denote
Ψt(h, H) = HT −ht + ⟨hc, hc −Hc⟩t +

s≤t
Δh(Δh −ΔH)
1 + Δh
and rewrite (11.6) in the form of the following stochastic diﬀerential equation
Xt = X0 +
∫t
0
Xs−dΨs(h, H).
(11.7)

178
11
General theory of stochastic processes in applications
Hence, X ∈Mloc(P) if Ψ(h, H) ∈Mloc(P). These considerations generate the idea
how to ﬁnd conditions to provide that X ∈Mloc(P∗) for a local martingale measure
P∗with the local density
Zt = dP∗
t
dPt
= Et(N), Nt =
∫t
0
Z−1
s−dZs ∈Mloc(P).
We just need to recognize when XZ = XE(N) ∈Mloc(P), and apply (11.1) of
Lemma 11.1.
In view (11.6)-(11.7) we have
XtEt(N) = X0Et(Ψ(h, H))Et(N),
and by the properties of stochastic exponents obtain that
XtEt(N) = X0Et(Ψ(h, H, N)),
(11.8)
where
Ψt(h, H, N) = Ht −ht + Nt + ⟨(h −N)c, (h −H)c⟩t +

s≤t
(Δhs −ΔNs)(Δhs −ΔHs)
1 + Δhs
.
Using relation (11.8), we arrive to the following theorem.
Theorem 11.1 Let X = S
B in the model (11.4). Then the following claims are true
(1) If Ψ(h, H) ∈Mloc(P), then X ∈Mloc(P),
(2) If Ψ(h, H, N) ∈Mloc(P), then X ∈Mloc(P∗).
The above theorem presents a convenient methodology of ﬁnding of martingale
measures for the model (11.4). Let us demonstrate this methodology for several
partial cases of (11.4).
Example 11.1 The Black-Scholes model:
dBt =rBtdt, B0 = 1,
dSt =St(μdt + σdWt), S0 > 0,
(11.9)
where r, μ ∈R+, σ > 0, W = (Wt)t ≥0 is a Wiener process.
In the model (11.9), ht = rt, Ht = μt + σWt. Due to W is the sole source of
randomness, we take N in the form Nt = φWt. To use Theorem 11.1 we ﬁnd that
Ψ(h, H, N) =μt + σWt −rt + φWt + φσt
=(μ −r + φσ)t + (σ + φ)Wt.
Therefore, the condition (2) of Theorem 11.1 is satisﬁed if μ −r + φσ = 0 or φ =
−μ−r
σ , and we can construct the local density
Zt = dP∗
t
dPt
= Et(N) = exp
	
−μ −r
σ
Wt −1
2
 μ −r
σ
2
t

.
(11.10)

11.1
Stochastic mathematical ﬁnance
179
Using the Girsanov exponent (11.10) we ﬁnd the martingale measure P∗under
which W∗
t = Wt + μ−r
σ t will be a Wiener process by the Girsanov theorem. So, if
f = (ST −K)+ is a contingent claim, then its initial price C( f ) can be calculated as
follows
C( f ) = E∗(ST −K)+
erT
= S0Φ(d+) −Ke−rTΦ(d−),
(11.11)
d± = ln(S0/K)+(r±σ2/2)T
σ
√
T
, and we again arrive to the Black-Scholes formula.
Example 11.2 The Merton model:
dBt =rBtdt, B0 = 1,
dSt =St−(μdt −νdΠt),
(11.12)
where r, μ ∈R+, ν < 1, Π = (Πt)t ≥0 is a Poisson process with parameter λ > 0.
In the model (11.12) ht = rt, Ht = μt −νΠt, and the martingale Nt will be chosen
as Nt = ψ(Πt −λt). Further,
Ψ(h, H, N) =μt −νΠt −rt + ψ(Πt −λt) −ψνΠt
=(μ −r −νλ −ψνλ)t −ν(Πt −λt) + ψ(Πt −λt) −ψν(Πt −λt).
Hence, the condition (2) of Theorem 11.1 is fulﬁlled if μ −r −νλ −ψνλ = 0 or
ψ = μ−r
νλ −1 is the unique solution. The uniqueness means that a martingale measure
P∗is also unique, and its local density has the following exponential form
Zt = dP∗
t
dPt
= Et(N) = exp [(λ −λ∗)t + (ln λ∗−ln λ)Πt],
(11.13)
where λ∗= μ−r
ν
is a parameter of Πt under measure P∗.
Using (11.13) we calculate a call option price C in the model (11.12) as follows.
C = E∗(ST −K)+
erT
.
It is clear that
ST
BT
= S0
B0
exp [−νΠT + νλ∗T]

t ≤T
(1 −νΔΠt)eνΔΠt
= S0
B0
exp [ΠT ln(1 −ν) + νλ∗T] .
(11.14)
Using (11.14) we ﬁnd that

180
11
General theory of stochastic processes in applications
C =E∗
 ST
BT
−K
BT
+
=
∞

n=0
e−λ∗T (λ∗T)n
n!

S0en ln(1−ν)+νλ∗T −B−1
T K
+
.
(11.15)
Denote
n0 = inf

n : S0en ln(1−ν)+νλ∗T ≥K
BT

=
ln(K/S0) −μT
ln(1 −ν)

,
Ψp(x, y) =
∞

n=x
e−y yn
n! ,
and ﬁnd from (11.15) that
C =S0
∞

n=n0
e−λ∗T+λ∗νT en ln(1−ν) (λ∗T)n
n!
−Ke−rT Ψp(n0, λ∗T)
=S0
∞

n=n0
e−λ∗(ν−1)T (λ∗(1 −ν)T)n
n!
−Ke−rT Ψp(n0, λ∗T)
=S0Ψp(n0, λ∗(1 −ν)T) −Ke−rT Ψp(n0, λ∗T).
(11.16)
Formula (11.16) is called the Merton formula for the price of a call option in the
model (11.12).
Putting together models (11.9) and (11.12) we get a jump-diﬀusion market model:
Bt =rBtdt, B0 = 1,
dSt =St−(μdt + σdWt −νdΠt), S0 > 0.
(11.17)
To calculate process Ψ(h, H, N) in this case we choose Nt = φWt + ψΠt and ﬁnd
that
Ψt(h, H, N) = (μ −r −νλ + φσ −ψλ)t + martingale.
Hence, μ −r + φσ −λν(1 + ψ) = 0 to make Ψ(h, H, N) a martingale. But this
equation has inﬁnitely many solutions (φ, ψ), and therefore, the model (11.15) admits
inﬁnitely many martingale measures, i.e. the market (11.17) is incomplete.
Let us consider a discrete-time model, called a Binomial market or the Cox-Ross-
Rubinstein model. We show that such a model is embedded in the model (11.4).
Example 11.3 The model we are talking represents a kind of Binomial random walk:

11.1
Stochastic mathematical ﬁnance
181
ΔBn =Bn −Bn−1 = rBn−1, B0 > 0,
ΔSn =Sn −Sn−1 = ρnSn−1, S0 > 0,
(11.18)
where (ρn)n=1,2,... is a sequence of independent random variables taking two values
b > a with probabilities p and q = 1 −p, p ∈(0, 1).
Assume also that −1 < a < r < b. Putting Bt = Bn on [n, n + 1) (we do the same
with St, Ft, . . .), we transform (11.18) to the model (11.4). This standard procedure
allows to apply the theory developed for the semimartingale model.
In the case under consideration
Δhn = r, ΔHn = ρn, ΔNn = ψn(ρn −μ), μ = Eρn,
and
(1 + r)ΔΨn(h, H, N) = ΔHn −Δhn + ΔNn + ΔNnΔHn.
Hence, the martingality property Ψn means that
E(ρn −r + ψn(ρn −μ) + ψn(ρn −μ)ρn|Fn−1) = 0,
which leads to
ψn = −μ −r
σ2 ,
where σ2 = Var(ρn).
As a result, we can construct a local density of a martingale measure P∗here in
the form of stochastic exponent
Zn = En

−μ −r
σ2

(ρn −μ)

.
(11.19)
As in previous examples we want to derive the price of a call option (SN −K)+,
where N ≥1. According to the general theory the price C can be calculated as
C =E∗(1 + r)−N(SN −K)+
=(1 + r)−NE∗(SN −K)+
=(1 + r)−NEEN

−μ −r
σ2

(ρk −μ)

(SN −K)I{SN >K },
(11.20)
where we used (11.19).
Deﬁne k0 = min

k ≤N : S0(1 + b)k(1 + a)N−k > K

and ﬁnd that k0 ln(1 +
b) + (N −k0) ln(1 + a) > ln K
S0 or k0 =

ln
K
S0(1+a)N

ln 1+b
1+a

+ 1, where [x] is an
integer part of x ∈R.
Denote p∗= r−a
b−a and derive for the term with K in (11.20) using elementary
equalities μ = p(b −a) + a, σ2 = (b −a)2p(1 −p) that

182
11
General theory of stochastic processes in applications
(1 + r)−NEEN

−μ −r
σ2

(ρk −μ)

KI{SN >K }
=K(1 + r)−N
N

k=k0
N
k
 
1 −μ −r
σ2 (b −μ)
k
pk

1 −μ −r
σ2 (a −μ)
 N−k
(1 −p)N−k
=K(1 + r)−N
N

k=k0
N
k
  p∗
p
k
pk
 1 −p∗
1 −p
 N−k
(1 −p)N−k
=K(1 + r)−N
N

k=k0
N
k

(p∗)k(1 −p∗)N−k.
(11.21)
To calculate the term with SN = S0EN( ρk) in (11.20) we use a multiplication rule
of stochastic exponents:
(1 + r)−N EEN

−μ −r
σ2

(ρk −μ)

SN I{SN >K}
=S0(1 + r)−N EEN

−μ −r
σ2

(ρk −μ) +

ρk −μ −r
σ2

(ρk −μ)ρk

I{SN >K}
=S0(1 + r)−N
N

k=k0
N
k
 
1 −μ −r
σ2 (b −μ) + b −μ −r
σ2 (b −μ)b
k
pk
×

1 −μ −r
σ2 (a −μ) + a −μ −r
σ2 (a −μ)a
 N−k
(1 −p)N−k
=S0(1 + r)−N
N

k=k0
N
k
  p∗
p (1 + b)
k
pk
 1 −p∗
1 −p (1 + a)
 N−k
(1 −p)N−k
=S0(1 + r)−N
N

k=k0
N
k
 
p∗1 + b
1 + r
k 
(1 −p∗) 1 + a
1 + r
 N−k
.
(11.22)
Introducing the notations ˜p = 1+b
1+r p∗and B(j, N, p) = N
k=j
N
k
pk(1 −p)N−k and
putting together (11.21)-(11.22) we get from (11.20) the Cos-Ross-Rubinstein for-
mula for the initial price of a call option
C = S0B(k0, N, ˜p) −K(1 + r)−NB(k0, N, p∗).
11.2
Stochastic Regression Analysis
Proposed and developed below an extension of classical regression models and
techniques is based on those theoretical ﬁndings that was delivered in the previous
chapter, and can be called a Stochastic Regression Analysis.

11.2
Stochastic Regression Analysis
183
We start with the classical problem of stochastic approximation. It consists of a
construction of a stochastic sequence θn or a stochastic process θt that converges in
some probabilistic sense to unique root θ ∈R of the regression equation
R(θ) = 0,
(11.23)
where R is a regression function.
In classical theory, a solution to (11.23) is given by the Robbins-Monro procedure
θn = θn−1 −γnyn, n = 1, 2, . . .,
(11.24)
where the sequence of observations yn is such that
yn = R(θn−1) + ξn,
(11.25)
(ξn)n=1,2,... is a sequence of independent random variables or martingale-diﬀerences,
(γn)n=1,2,... is a numerical positive sequence converging to zero.
The convergence (a.s.) of the procedure (11.24)-(11.25) for a continuous linearly
bounded regression function R(x) such that
R(x)(x −θ) > 0 for all x  θ
is guaranteed by ﬁniteness of the variance (conditional variance) of observation
errors ξn and the following conditions:
∞

n=1
γn = ∞,
(11.26)
∞

n=1
γ2
n < ∞.
(11.27)
Diﬀusion analogues of (11.24)-(11.25) and (11.26)-(11.27) are
dθt = −γtR(θt)dt −γtdWt,,
(11.28)
∫∞
0
γsds = ∞,,
(11.29)
∫∞
0
γ2
sds < ∞,
(11.30)
where Wt is a Wiener process and γt is a positive deterministic function tending to
zero as t →∞.
Under conditions (11.29)-(11.30) the procedure θt converges to θ as t →∞.
The leading idea to generalize (11.24)-(11.25) and (11.28) consists in the possi-
bility of describing such stochastic algorithms as strong solutions of some special
classes of stochastic diﬀerential equations with respect to semimartingales. It leads

184
11
General theory of stochastic processes in applications
to a generalized Robbins-Monro procedure as a process θt satisfying the stochastic
diﬀerential equation
θt = θ0 −
∫t
0
γsR(θs−)das −
∫t
0
γsdms,
(11.31)
where θ0 is a ﬁnite F0-measurable random variable, a predictable process a ∈
A+
loc, m ∈M2
loc, and γ is a predictable process decreasing to zero (a.s.) as t →∞.
To simplify the demonstration how martingale methods work here we consider a
linear case only: R(x) = β(x −θ), β > 0.
In this case (11.31) is reduced to
θt −θ = θ0 −θ −
∫t
0
γsβ(θs−−θ)das −
∫t
0
γsdms.
(11.32)
Let us assume that (a.s.)
∫∞
0
γsdas = ∞,
(11.33)
∫∞
0
γ2
sd⟨m, m⟩s < ∞.
(11.34)
Deﬁne the following stochastic exponent
Et(−βγ · a) = Et

−β
∫
γsdas

,
and assume that βγtΔat < 1 to provide that Et(−βγ · a) > 0 (a.s.).
Applying the Ito formula to E−1
t (−βγ · a)(θt −θ) we arrive from (11.32) to
θt −θ = Et(−βγ · a)(θ0 −θ) −Et(−βγ · a)
∫t
0
γsE−1
s (−βγ · a)dms.
(11.35)
The ﬁrst term in the right-hand side of (11.35) converges to zero (a.s.) as t →∞
because of Et(−βγ · a) →0 (a.s.), t →∞. Second term in (11.35) is treated by
the arguments of the Large Numbers Law for square integrable martingales. Using
(11.34) we have that (a.s.)
∫∞
0
E2
s(−βγ · a)γ2
sE2
s(−βγ · a)d⟨m, m⟩s =
∫∞
0
γ2
sd⟨m, m⟩s < ∞.
Hence, the second term of (11.35) converges to zero (a.s.) as t →∞. As a result,
we get the convergence (a.s.) θt →θ as t →∞.
To investigate an asymptotic normality of the procedure (11.32) we simplify the
situation assuming that at is a deterministic function and mt is a Gaussian martingale
satisfying conditions:

11.2
Stochastic Regression Analysis
185
⟨m, m⟩t = σ2at, σ2 > 0, γt =
α
1 + at
, α > 0, βα < 1,
at ↑, t →∞,

0<s<∞
 Δas
1 + as
2
< ∞.
Under these conditions we have
Et(−βγ · a) = Et(−βα) ∼(1 + at)−βα as t →∞.
Multiplying (11.35) by (1 + at)1/2 we obtain
(1 + at)1/2(θt −θ) = (1 + at)1/2Et(−βα)(θ0 −θ)
−(1 + at)1/2Et(−βα)
∫t
0
α
1 + as
E−1
s (−βα)dms.
(11.36)
Let us note that
(1 + at)1/2Et(−βα) ∼(1 + at)1/2−βα as t →∞,
and therefore, under 2βα > 1 we obtain that the ﬁrst term of (11.36) converges to
zero (a.s.) as t →∞.
The second term of (11.36) has a Gaussian distribution, and hence, we need to
calculate the asymptotic value of the variance of this term:
(1 + at)E2
t (−βα)
∫t
0
E2
s(−βα) α2σ2
1 + as
das →
α2σ2
2βα −1 as t →∞.
(11.37)
Finally, we can arrive to conclusion that
(1 + at)1/2(θt −θ)
d
−−−−→
t→∞N

0,
α2σ2
2βα −1

.
(11.38)
As a consequence of (11.38) we get the well-known classical results from the theory
of stochastic approximation for discrete and continuous time (11.24)-(11.25) and
(11.28):
n1/2(θn −θ)
d
−−−−→
n→∞N

0,
α2σ2
2βα −1

,
t1/2(θt −θ)
d
−−−−→
t→∞N

0,
α2σ2
2βα −1

.
Another important problem of regression analysis is the problem of estimation of
the unknown parameter of a linear regression function.

186
11
General theory of stochastic processes in applications
Suppose we observe the process Xt having the following structure
Xt =
∫t
0
fsdasθ + Mt,
(11.39)
where a ∈A+
loc and predictable, M ∈M2
loc, a predictable function ft such that,
∫t
0 f 2
s das = Ft < ∞(a.s.), t ≥0, θ ∈R is an unknown parameter.
Deﬁne the following structural Least Squares estimate as follows
θt = F−1
t
∫t
0
fsdXs,
(11.40)
where we assume that Ft > 0 (a.s.) and Ft ∈A+
loc and predictable.
Assuming that Ft →∞(a.s.) as t →∞, we rewrite (11.40):
θt =F−1
t
∫t
0
f 2
s dasθ + F−1
t
∫t
0
fsdMs
=θ + F−1
t
∫t
0
fsdMs.
(11.41)
Obviously, we can study the asymptotic behaviour of θt with the help of the Large
Numbers Law. To apply such LNL we ﬁnd from (11.41) that (a.s.)
∫∞
0
F−2
s d
∫t
0
fsdMs,
∫t
0
fsdMs

=
∫∞
0
F−2
s
f 2
s d⟨M, M, ⟩s < ∞.
(11.42)
So, if Ft →∞(a.s.), t →∞, and (11.42) is fulﬁlled then θt →θ (a.s.) t →∞.
Let us continue our study of estimates (11.40), by considering their sequential
analog. To do this in the model (11.39) we assume that
d⟨M, M⟩t
dat
≤ξγt,
(11.43)
∫t
0
γ−1
s f 2
s das ∈A+
loc and predictable,
where ξ is a positive r.v. and γt is a positive predictable process.
Next, for H > 0 we put
τH = inf
	
t :
∫t
0
γ−1
s f 2
s das ≥H

with τH = ∞if the set in {·} is empty.
On the set {τH < ∞} we deﬁne a random variable βH by the relation
∫
(0,τH )
γ1
s f 2
s das + βHγ−1
τH f 2
τH ΔaτH = H,
(11.44)

11.2
Stochastic Regression Analysis
187
and we put βH = 0 on the set {τH = ∞}. Then βH ∈[0, 1) and it is a FτH−-measurable
random variable.
Let us deﬁne the following sequential Least Squares estimate
ˆθH = H−1
∫
(0,τH )
γ−1
s fsdXs + βHγ−1
τH fτH ΔXτH

.
(11.45)
The next theorem shows a nice property of ˆθH called a ﬁxed accuracy.
Theorem 11.2 Suppose (11.43)-(11.45) are fulﬁlled, Eξ < ∞and
∫∞
0 γ−1
s f 2
s das =
∞(a.s.). Then P{ω : τH < ∞} = 1, E ˆθH = θ, and
Var ˆθH ≤H−1Eξ.
(11.46)
Proof The
ﬁniteness
(a.s.)
of
τH
follows
from
the
relation
{τH ≤T} =

ω :
∫T
0 γ−1
s f 2
s das ≥H

. Using (11.45) we ﬁnd that
ˆθH = θ + H−1NτH,
(11.47)
where Nt =
∫t
0 I(s<τH )γ−1
s fsdMs + I{t=τH }βHγ−1
τH fτH ΔMτH .
Since the process Nt is a stochastic integral with respect to M ∈M2
loc, by the
properties of stochastic integrals we obtain that
⟨N, N⟩t =
∫t
0
I(s<τH )γ−1
s f 2
s d⟨M, M, ⟩s + I{t=τH }β2
Hγ−2
τH f 2
τH Δ⟨M, M⟩τH
(11.48)
Hence, by (11.44) we get
⟨N, N⟩τH = ξ
∫
(0,τH )
γ−1
s f 2
s das + βHγ−1
τH f 2
τH ΔaτH

= ξH,
and consequently, Nt∧τH ∈M ∩M2 and
ENτH = 0, EN2
τH = HEξ,
which leads to (11.46).
Example 11.4 Let us consider the ﬁrst order autoregression model:
xt = θxt−1 + et, x0 = 0, t = 1, 2, . . .,
where (et)t=1,2,... is a martingale-diﬀerence w.r. to (Ft) and E(e2
t |Ft−1) ≤ξ, Eξ < ∞.
Then (11.43) is fulﬁlled with γt = 1, and the estimate ˆθH takes the form

188
11
General theory of stochastic processes in applications
ˆθH =H−1
τH −1

k=1
xk xk−1 + βH xτH xτH −1

,
τH = inf

n :
n

k=1
x2
k−1 ≥H

,
βH =x−2
τH

H −
τH −1

k=1
x2
k

.
Embedding the present model in the general model (11.39) in a standard way, we get
E ˆθH = θ, Var ˆθH ≤H−1Eξ.

Chapter 12
Supplementary problems
Abstract The list below contains problems which are related to all chapters of the
book. Some of them are numerical and some others are pure theoretical, but in
any case they are helped for both students and instructors. Students can improve
their understanding and scope. Instructors can transform most of the problems for
teaching and examination purposes. The following references might be useful to
create detailed solutions (see [1], [5], [7], [10], [11], [13], [14], [15], [16], [17], [18],
[21], [22], [23], [24], [27], [28], [29], [30], [31], [35], [37], [43], [44], and [45]).
Problem 12.1 Let X be a standard normal random variable and Y be a Bernoulli random
variable such that P(Y = 1) = P(Y = −1) = 1
2, and X,Y are independent. Prove that
(a) Z = Y X ∼N(0, 1),
(b) Z and X are uncorrelated, but they are not independent.
Solution: The claim (a) is obvious. To prove (b) we calculate cov(X, Z) = E(XZ) =
EX2EY = 1 · 0 = 0.
Further,
P(X ≥1, Z ≥1) = P(X ≥1,Y = 1) = P(X ≥1) ·
P(Y = 1) = 1
2P(X ≥1). But P(X ≥1) · P(Z ≥1) = (P(X ≥1))2 and P(X ≥1) ≃
0.1587, and, hence, 1
2P(X ≥1)  (P(X ≥1))2.
■
Problem 12.2 Assume that stochastic process Xt = eWt , where W = (Wt)t ≥0 is a
standard Wiener process. Calculate the drift and diﬀusion coeﬃcients of process
X = (Xt)t ≥0:
b(x) = lim
h→0 h−1 [E(Xt+h −Xt|Xt = x)],
σ2(x) = lim
h→0 h−1 
E

(Xt+h −Xt)2|Xt = x

for t, x ∈R1
+
Hint: Use the fact that
Wt+h −Wt ∼N(0,
√
h),
h > 0
© The Author(s), under exclusive license to Springer Nature Switzerland AG 2023
A. Melnikov, A Course of Stochastic Analysis, CMS/CAIMS Books in Mathematics 6,
https://doi.org/10.1007/978-3-031-25326-3_12
189

190
12
Supplementary problems
■
Problem 12.3 Let Xi ∼N(μi, σ2
i ), i = 1, 2, and X1 + X2 ∼N(μ1 + μ2, σ2
1 + σ2
2 +
2ρσ1σ2). Then cov(X1, X2) = ρσ1σ2 and corr(X1, X2) = ρ.
Hint: Use the formula for bivariate normal distribution.
■
Problem 12.4 (Theorem of Slutsky)
Let r.v’s Xn
d
−−−−→
n→∞X and the sequence of real numbers an −→a ∈R1. Then Xn +
an
d
−−−−→
n→∞X + a and anXn
d
−−−−→
n→∞aX
Solution:
Let us note for ∀ε > 0, x ∈R1, that
P(Xn + an ≤x) =P(Xn + an ≤x, |an −a| < ε) + P(Xn + an ≤x, |an −a| ≥ε) ≤
≤P(Xn ≤x −a + ε) + P(|an −a| ≥ε).
It follows from here for all points x −a + ε of continuity of distribution function Fx
that
lim
n sup FXn+an(x) ≤Fx(x −a + ε).
So, due to arbitrary choice of ε > 0 we derive
lim
n→∞FXn+an(x) = FX(x −a) = FX+a(x)
for all x at which FX+a is continuous.
The second claim is proved in the same way.
■
Problem 12.5 Let Xn ∼N(μn, σ2
n) and μn →μ, σ2
n →σ2, n →∞. Then Xn
d
−−−−→
n→∞
X ∼N(μ, σ2).
Solution:
Denote Zn = Xn−μn
σn
∼N(0, 1) and, hence, Zn
d
−−−−→
n→∞Z ∼N(0, 1). Using Problem
12.4, we obtain that
Xn = σnZn + μn
d
−−−−→
n→∞X = σZ + μ.
■
Problem 12.6 (Borel-Cantelli lemma) Let (An)n=1,2,... be a sequence of events,
and C =
∞
m=1

n=m An. Then

12
Supplementary problems
191
1. P(C) = 0, if
∞
n=1
P(An) < ∞;
2. P(C) = 1, if (An)n=1,2,... are independent and
∞
n=1
P(An) = ∞.
Solution: 1. We have P(C) ≤P
	 ∞
n=m An

≤
∞
n=m P(An) for each n = 1, 2, ... Take
ε > 0 and ﬁnd Nε big enough that
∞
n=Nε
P(An) < ε. Hence, for all N > Nε we obtain
P(C) < ε.
2. Let us note that P((
∞
n=m An)c) ≤P(
∞
n=m Ac
n) ≤P(
m+M

n=m Ac
n) for any M > 0.
But (An) are independent, and, hence, P((
∞
n=m An)c) ≤
m+M

n=m (1 −P(An)) ≤
exp

−
m+M

n=m P(An)

, where we used the inequality 1 −x ≤e−x for x ∈[0, 1]. The
claim follows from the inequality above for probabilities.
■
Problem 12.7 Let μ =
∞
n=1
αnPn, where (Pn) and (αn) are sequences of probability
measures and positive numbers respectively. Deﬁne ν =
∞
n=1
βnQn, where (Qn) and
(βn) are sequences of probability measures Qn ≪Pn and non-negative numbers.
Prove that ν ≪μ
Solution:
For any A with μ(A) = 0 we have
∞
1
αnPn = μ(A) = 0 and, hence, Pn(A) = 0 for
all n. So, Qn(A) = 0 and therefore ν(A) =
∞
n=1
βnQn = 0 and we get ν ≪μ.
■
Problem 12.8 Let ([0, 1], B(0, 1), l) be a Borel space with the Lebesgue probability
measure l, and X and Y be random variables: X(ω) = 2ω2 and
Y(ω) =
⎧⎪⎪⎪⎨
⎪⎪⎪⎩
0, ω ∈[0, 1
3]
2, ω ∈[ 1
3, 2
3]
1, ω ∈[ 2
3, 1]
.
Find E(X|Y).
Solution: For ω ∈[0, 1
3] we have E(X|Y)(ω) =
1
3∫
0
xdP
P([0, 1
3 ]) = 1
1
3
∫1
3
0 2ω2dω = 2
27. Values
of E(X|Y) on other sets [ 1
3, 2
3] and [ 2
3, 1] can be determined in the same way: 14
27 and
38
27 correspondingly.
■

192
12
Supplementary problems
Problem 12.9 Let (εn)n=1,2,...,N be a sequence of independent random variables
with values +1 and −1 taking with probability 1
2. Deﬁne Xn = (−1)n cos π n
k=1 εk
 ,
n = 1, 2, ..., N and prove that (Xn)n=1···N is a martingale with respect to a natural
ﬁltration Fn = F ε
n = F X
n .
Solution:
We
represent
the
sequence
(Xn)
as
follows:
Xn = (−1)n 1
2

eiπ n
1 εk + e−iπ n
1 εk 
, i =
√
−1.
Using
independence
of
(εn)1···N
we
have
E(Xn|Fn−1) = 1
2(−1)n

Eeiπεn · eiπ n−1
1
εk + Ee−iπεn · e−iπ n−1
1
εk

.
Further, applying an obvious relation Eeiπεn = 1
2(eiπ + e−iπ) = −1 we obtain
E(Xn|Fn−1) = (−1)n−1
2

eiπ n−1
1
εk + e−iπ n−1
1
εk

= (−1)n−1cos

π
n−1

1
εk

= Xn−1.
■
Problem 12.10 Let values and joint distribution of random variables X and Y are
given in the table
X
Y
-0.1
0
0.1
-0.2
0.1
0
0.4
0.1
0.3
0.1
0.1
Find marginal distributions of X and Y, average of Y and E(Y|X).
Solution: We have from the table above that
P(X = −0.2) = 0.1 + 0.4 = 0.5,
P(X = 0.1) = 0.3 + 0.1 + 0.1 = 0.5,
P(Y = −0.1) = 0.1 + 0.3 = 0.4,
P(Y = 0) = 0.1, P(Y = 0.1) = 0.4 + 0.1 = 0.5
which give us marginal distributions. We also derive from the above equalities that
EY = −0.1 · 0.4 + 0.1 · 0.5 = 0.01.
To calculate the conditional expectation E(Y|X) we write
E(Y|X) = E(Y|X = −0.2) · I{X=−0.2} + E(Y|X = 0.1) · I{X=0.1}.
Calculating
E(Y|X = −0.2) = −0.1 · P(Y = −0.1|X = −0.2) + 0.1 · P(Y = 0.1|X = −0.2) =
=−0.1 · 0.1 + 0.1 · 0.4
0.5
= 0.06,
and similarly

12
Supplementary problems
193
E(Y|X = 0.1) = −0.1 · 0.3 + 0.1 · 0.1
0.5
= −0.04,
we obtain
E(Y|X) = 0.06 · I{X=−0.2} −0.04 · I{X=0.1}.
■
Problem 12.11 Let (Xn)n=1,2,··· be a sequence of independent random variables
such that P(Xn = 1) = p, P(Xn = −1) = 1 −p, 1 < p < 1
2. Show that the following
stochastic sequences are martingales with respect to a natural ﬁltration (Fn)n=1,2,···
generated by (Xn).
(a) Mn =
n
k=1
Xk −n · (2p −1);
(b) Yn = M2
n −4np(1 −p);
(c) Zn = ( 1−p
p )
n
1
Xk.
Hint: Check the martingale property.
■
Problem 12.12 Let X0 be a random variable such that P(X0 = 2) = P(X0 = 0) = 1
2.
Deﬁne Xn = n · Xn−1,
n = 1, 2, · · · and Mn = Xn −EXn. Prove that (Mn) is not a
martingale with respect to the natural ﬁltration (Fn).
Solution: We observe that E(Mn|Fn−1) = E(Xn|Fn−1) −n! = n · Xn−1 −n! =
n(Xn−1 −(n −1)!) = n · Mn−1  Mn−1.
■
Problem 12.13 Find a stochastic diﬀerential for the process Xt = (
√
123 + 1
2Wt)2,
where (Wt) is a Wiener process.
Solution: Here Xt = f (Wt) with the function f (x) = (
√
123 + 1
2 x)2. The ﬁrst and
second derivatives of this function are f ′(x) = 2(
√
123 + 1
2 x), f ′′(x) = 1. Therefore,
using the Ito formula, the stochastic diﬀerential of (Xt) is
dXt = f ′(Wt)dWt + 1
2 f ′′(Wt)dt
= 2(
√
123 + 1
2Wt)dWt + 1
2dt.
■
Problem 12.14 Let (Nt)t ≥0 be a Poisson process with intensity λ = 1. Prove that
(Nt −t)2 −t is a martingale with respect to natural ﬁltration generated by (Nt).
Calculate E
3∫
1
Ntdt ·
4∫
2
Ntdt

194
12
Supplementary problems
Hint: In the ﬁrst case, please, check a martingale property. In the second case the
answer is 34 1
3.
■
Problem 12.15 Check whether the processes are martingales
(a) Xt = W3
t −3tWt;
(b) Xt = Wt + 287t;
(c) Xt = e
t
2 sin(Wt),
where (Wt)t ≥0 is a Wiener process.
Solution:
(a) We have here Xt = f (t,Wt) with the function f (t, x) = x3 −3tx. This function
has the partial derivatives
∂
∂x f (t, x) = 3x2 −3t, ∂2 f (t, x)
∂x2
= 6x,
∂
∂t f (t, x) = −3x.
Therefore, using the Ito formula, we derive
dXt = (3W2
t −3t)dWt +
	
−3Wt + 1
2(6Wt)

dt = (3W2
t −3t)dWt.
Therefore, (Xt) is a martingale as a stochastic integral has a martingale property.
In case (b) we have EX0 = 0 and for instance EX1 = 287. This implies that (Xt)
cannot be a martingale, since martingales have constant expectations.
For (c) we have Xt = f (t, Wt) with function f (t, x) = e
t
2 · sin(x) and its partial
derivatives
∂
∂x f (t, x) = e
t
2 · cos(x), ∂2 f (t, x)
∂x2
= −e
t
2 · sin(x),
∂
∂t f (t, x) = 1
2e
t
2 · sin(x).
Using the Ito formula we get
dXt = e
t
2 · cos(Wt)dWt +
1
2e
t
2 · sin(Wt) + 1
2(−e
t
2 · sin(Wt))

dt =
= e
t
2 · cos(Wt)dWt
which certiﬁes that (Xt) is a martingale.
■
Problem 12.16 Provide a condition on the mapping ϕ : R1 −→R1 under which
ϕ(τ) remains a stopping time, where τ is a stopping time.
Solution: Suppose the mapping ϕ meets the following conditions:
(a) ϕ is injective,

12
Supplementary problems
195
(b) ϕ([0, ∞)) = [0, ∞),
(c) ϕ order-preserving and t ≤ϕ(t) for all t ∈[0, ∞).
Condition (a) ensures that the inverse mapping ϕ−1 : ϕ(R1) −→R1 is deﬁned. Con-
dition (b) ensures that ϕ−1(t) is well-deﬁned and positive for all t ≥0. Condition
(c) together with the previous two conditions (a) and (b) gives that whenever τ is a
stopping time
{ϕ(τ) ≤t} = {τ ≤ϕ−1(t)} ∈Fϕ−1(t) ⊆Ft.
For instance, if ϕ : [0, ∞) −→[0, ∞) is a strictly increasing function satisfying
t ≤ϕ(t) for all t ≥0, and ϕ is diﬀerentiable with ϕ′(t) ≥1 for all t, ϕ(0) = 0,
then by the mean value theorem we get ϕ(t) ≥ϕ′(c) · t ≥t, and the above holds.
■
Problem 12.17 Considerthefunctionp(t, x, y) =
1
√
2πt exp

−(x−y)2
2t

, x, y ∈R1, t ∈
R1
t , representing the transition density of a Wiener process (Wt). Prove the p(t, x, y)
satisﬁes to the PDE:
∂
∂t p(t, x, y) = 1
2
∂2
∂y2 p(t, x, y).
Solution: On one hand side we have
∂
∂t p(t, x, y) = p(t, x, y)

−1
2t + (x −y)2
2t

.
On the other hand, diﬀerentiating with respect to y, we get
∂2
∂y2 p(t, x, y) =p · (x −y)2
t
+ p · (−1
t )
=p(t, x, y)
(x −y)2
t
−1
t

.
Then it is clear that p(t, x, y) satisﬁes the above diﬀerential equation.
■
Problem 12.18 Prove that every non-negative local martingale is a supermartingale.
Hint: Apply the Fatou lemma.
■
Problem 12.19 Let (Xn)n=0,1,...,N be a submartingale with E(X+
N)p < ∞, p > 1.
Prove the Doob inequality
E(max
n
X+
n )p ≤(
p
p −1)
p
E(X+
N)p,
X+
N = max(0, XN).
Solution: Denote X∗
N = maxn≤N X+
N and note that
λ.P(X∗
N > λ) ≤EX+
N.I{X∗
N >λ},
λ > 0.

196
12
Supplementary problems
Multiplying the above inequality by λp−2 and integrating over (0, ∞), we obtain
∫∞
0
λp−1P(X∗
N > λ)dλ ≤EX+
N.
∫X∗
N
0
λp−2dλ ≤
1
p −1EX+
N.(X∗
N)p−1
Due
to
∫∞
0 λp−1P(X∗
N > λ)dλ = 1
p
∫∞
0 λpdP(X∗
N ≤λ)
we
get
E(X∗
N)p ≤
p
1−pEX+
N.(X∗
N)p−1, and with the help of the Hölder-inequality we derive
EX+
N.(X∗
N)p−1 ≤(E(X+
N)p)
1
p (E(X∗
N)p)
p−1
p
and hence
E(X∗
N)p ≤
p
p −1(E(X+
N)p)
1
p (E(X∗
N)p)
p−1
p .
It leads to the desirable inequality.
■
Problem 12.20 Give an example of a non-right-continuous ﬁltration and a martin-
gale which is not right-continuous.
Solution: For a positive real number a > 0 deﬁne Ω = {a, −a}, P(a) = P(−a) = 1
2,
and the Bernoulli random variable
X =

a
with probability
1
2,
−a
with probability
1
2.
Deﬁne Xt =

0
i f t ≤t0,
X
i f t > t0
, t ≥0, and Ft =

{∅, Ω}
i f t ≤t0,
FX = σ(X)
i f t > t0
.
Process (Xt) is a martingale w.r. to (Ft). Both (Xt) and (Ft) are not right-continious.
■
Problem 12.21 Let (An)n≥0 be a predictable (d × d)-matrix-valued sequence of
random variables such that ΔAn = An −An−1 is positive-deﬁned, n ≥1, λ min(A)
and λ max(A) are minimal and maximal eigenvalues of A. Let (Mn)n≥0 be a d-
dimensional square-martingale with the quadratic characteristic << M, M >>n=
(⟨Mi, M j⟩n)i,j=1,..,d. Prove an analog of lemma 7.1 for d-dimensional case: (a.s)
{ω : λmin(A∞) = ∞} ∩{ω : N →} ∩{ω : lim
n sup λ max
λ min (An) < ∞} ⊆{ω : A−1
n Mn →0}.
Hint: Adapt the proof of lemma 7.1 to this multidimensional case.
■
Problem 12.22 Let (An) and (Mn) be as in the previous problem, λ min(An) →∞
(a.s.), limn sup λ max
λ min (An) < ∞(a.s.), and (a.s.)
∞

n=1
tr (A−1
n )Δ<< M, M >>n(A−1
n ) < ∞.

12
Supplementary problems
197
Then (a.s.) A−1
n Mn →0, n →∞.
Hint: Adapt the proof of theorem 7.1 to this multidimensional case.
■
Problem 12.23 Let us consider a polynomial transformation Pn(t).Qm(wt) of a
Wiener process (wt)t ≥0, where Pn and Qm are polynomials of degrees n and m
relatively. Determine when this transformation leads to a martingale.
Hint: Use the Ito formula.
■
Problem 12.24 Let (Xn)n=1,2,... be a sequence of independent random variables
with the density
fa(x) =

e−ax
i f x ≥0,
0
i f x < 0.
Find the parameter a to provide that Zn = n
i=1 Xi is a martingale w.r. to a natural
ﬁltration (FX
n )n=1,2,....
Hint: Use the conditions
∫∞
0
fa(x)dx = 1 and EXn = 1.
■
Problem 12.25 Assume Xn ∼N(μn, σ2
n), n = 1, 2, ..., and Xn
L2
−−→X, n →∞. Then
X ∼N(μ, σ2), where μ = limn→∞μn, σ2 = limn→∞σ2
n.
Solution: It follows from the L2-convergence that μn →μ = EX and VarXn →
VarX = σ2, n →∞. Hence, for an arbitrary λ ∈R1 we obtain
EeiλX = lim
n→∞EeiλXn = lim
n→∞eiμnλ−σ2n
2 λ2 = eiμλ−σ2
2 λ2.
■
Problem 12.26 Let b = b(x) and σ = σ(x) be bounded functions from R1 to R1 such
thatb ∈C1(R1),σ ∈C2(R1).Assume(Wt)t ≥0 isawienerprocess.ThentheItoprocess
dXt = b(Xt)dt + σ(Xt).dWt,
can be rewritten in the form of the Stratonovich stochastic integral
dXt = (b(Xt) −1
2σ(Xt)σ′(Xt))dt + σ(Xt).dWt.
Show also that for Xt = Wt and F ∈C2(R1) the Ito formula F(Xt) −F(X0) =
∫t
0 F′(Xs)dXs + 1
2
∫t
0 F′′(Xs)ds admits the following form in terms of Stratonovich
integral F(Xt) −F(X0) =
∫t
0 F′(Xs).dXs.
Hint: Use deﬁnitions of these integrals.
■

198
12
Supplementary problems
Problem 12.27 Let us consider the exponential transformation of a probability
measure PT, T > 0 to a measure function P∗
T such that
dP∗
T
dPT
= eaW −
T +bT+c = ZT,
where (Wt)t ≤T is a Wiener process. Determine parameters a, b, and c under which
P∗
T will be a probability measure.
Hint: Use the condition EZT = 1.
■
Problem 12.28 ProvethattheﬁrstandsecondvariationsofaWienerprocess(Wt)t ≥0
converge (a.s.) to inﬁnity and to the length of time interval correspondingly.
Solution: For a ﬁxed T > 0 we deﬁne a subdivision tn
i = iT.2−n, i ≤2n, n ≥1 of
the interval [0,T]. Deﬁne
FVn =
2n−1

i=0
|Wtn
i+1 −Wtn
i | =
2n−1

i=0
|ΔWtn
i |
and
SVn =
2n−1

i=0
(ΔWtn
i )2,
n ≥1.
For SVn using properties of (Wt) we have
E(SVn −T)2 =E
2n−1

i=0

(ΔWn
ti)
2
−T.2−n2
=
2n−1

i=0
E

(ΔWn
ti)
2
−T.2−n2
=2n.2.(T.2−n)2
=2.T2.2−n
and
  
∞

n=1
|SVn −T|
  
L2 ≤
∞

n=1
∥SVn −T∥L2
≤
√
2T.
∞

n=1
2
−n
2 < ∞.
Hence, SVn →T (a.s.) as n →∞due to ∞
n=1 |SVn −T| < ∞(a.s.).
Regarding
FVn
for
each
ω ∈Ω
we
have
SVn(ω) ≤(maxi |ΔWtn
i (ω)|).
2n−1
i=0
|ΔWtn
i (ω)| ≤(maxi |ΔWtn
i (ω)|).FVn(ω). It follows from this inequality for
paths of (Wt)t ≥0 that limn→∞inf FVn(ω) cannot be ﬁnite, otherwise SVn −−−−→
n→∞0.

12
Supplementary problems
199
■
Problem 12.29 Let (Mt)t ≥0 be a continuous square integrable martingale with a
ﬁnite ﬁrst variation FVt(M). Show that Mt = M0 (a.s.) for all t ≥0.
Hint: Let (tn
j ) be a ﬁnite partition of [0, t] with maxj Δtn
j →0 as n →∞. Then (a.s.)

j
|ΔMtn
j |2 ≤FVt(M(ω)). max
j
|ΔMtn
j (ω)| →0,
n →∞,
and
< M, M >t= 0
(a.s.).
Hence, Mt = M0 (a.s.).
■
Problem 12.30 Let M = (Mt)t ≥0 be a continuous local martingale and
Zt(M) = exp{Mt −1
2 ⟨M, M⟩t},
t ∈[0, ∞].
Assume that (Krylov’s condition):
lim
ε→0 inf ε. log E exp{1 −ε
2
⟨M, M⟩∞} < ∞.
Prove that EZ∞(M) = 1, i.e. the exponential local martingale (Zt(M))t ≥0 is uniformly
integrable. Show that the condition above is wider than the Novikov condition
Ee
1
2 ⟨M,M ⟩∞< ∞.
Hint: First of all we note that EZ∞(M) ≤1 as a consequence of a supermartingale
property of (Zt(M)) and the Fatou lemma. Using the Hölder inequality we can derive
for a constant c > 0 that
1 = EZ∞((1 −ε)M) =Ee(1−ε)(M∞−1
2 ⟨M,M ⟩∞).e
(1−ε)ε
2
⟨M,M ⟩∞.I{⟨M,M ⟩∞≤c}
+Ee(1−ε)(M∞−1
2 ⟨M,M ⟩∞).e
(1−ε)ε
2
⟨M,M ⟩∞.I{⟨M,M ⟩∞>c}
≤(EZ∞(M))1−ε.

Ee
(1−ε)ε
2
⟨M,M ⟩∞.I{⟨M,M ⟩∞≤c}
ε
+(EZ∞(M).I{⟨M,M ⟩∞>c})1−ε.

Ee
(1−ε)ε
2
⟨M,M ⟩∞
ε
.
By taking the limit when ε →0 in the above inequality, we arrive to
1 ≤EZ∞(M) + const.EZ∞(M).I{⟨M,M ⟩∞>c}.
Taking the limit as c →∞, we get EZ∞(M) ≥1.
■
Problem 12.31 Show that every process (At) with ﬁnite variation can be represented
as the diﬀerence of two increasing processes.

200
12
Supplementary problems
Hint: Use the representation
At = 1
2(|A|t + At −1
2(|A|t −At)),
where |A|t is the variation of A on [0, t].
■
Problem 12.32 Let (Xt)t ≥0 be a semimartingale and let (At) be a process of ﬁnite
variation. Prove that
[X, A]t =

s≤t
(ΔXt)(ΔAs).
In particular, [X, A] = 0, if (At) or (Xt) is continuous.
Hint: Use the limiting arguments dividing [0, t] by a subdivision tn
j = jt2−n,
j = 0, ..., 2n, n ≥1.
■
Problem 12.33 Prove the Levy characterization of a Wiener process (Remark 8.1).
Solution: Let us prove that the following three statements are equivalent for a con-
tinuous martingale (Xt)t ≥0, X0 = 0:
(1) Process (Xt) is a standard Wiener process on the underlying stochastic basis;
(2) Process (X2
t −t)t ≥0 is a martingale;
(3) Process (Xt)t ≥0 has a quadratic variation [X, X]t = t.
To prove (1) ⇒(2) we just observe that E|X2
t −t| < ∞for each t ≥0 and for s ≤t,
E(X2
t −t|Fs) = E(X2
t −X2
s ) + X2
s −(t −s) −s|Fs
 = X2
s −s due to the properties
of a Wiener process (Xt).
For the proof of the second implication (2) ⇒(3) we note that (X2
t )t ≥0 is a submartin-
gale with the Doob-Meyer decomposition X2
t = (X2
t −t) + t. Hence, [X, X]t =<
X, X >t= t.
The third implication (3) ⇒(1) can be stated as follows. First, we prove that incre-
ments of (Xt)t ≥0 are Gaussian. Applying the Ito formula to eiλx+ λ2
2 t = f (t, x), t ≥0,
and λ > 0, we obtain
df (t, Xt) = ∂
∂t f (t, Xt)dt + ∂
∂x f (t, Xt)dXt + 1
2
∂2
∂x2 f (t, Xt)d[X, X]t
=1
2λ2 f (t, Xt)dt + iλ f (t, Xt)dXt + (−λ2
2 ) f (t, Xt)dt
=iλ f (t, Xt)dXt,
and therefore, ( f (t, Xt))t ≥0 is a martingale. Further
E(eiλXt+ 1
2 λ2t|Fs) = eiλXs+ 1
2 λ2s,
and
Eeiλ(Xt−Xs) = E(E(eiλ(Xt−Xs)|Fs)) = e−1
2 λ2(t−s),

12
Supplementary problems
201
which means that Xt −Xs ∼N(0, t −s), t ≥s.
To ﬁnish the proof we show that the increments Xt2 −Xt1, ..., Xtn −Xtn−1 are indepen-
dent for any subdivision of time 0 ≤t1 < t2 < t3 < ... < tn−1 < tn. We have
E(eiλ,Xt1+iλ2(Xt2−Xt1)+...+iλn(Xtn −Xtn−1)) = e−
λ2
1
2 t1 × ... × e−1
2 λ2
n(tn−tn−1),
which states independence of increments of (Xt). So, (Xt)t ≥0 is a Wiener process.
■
Problem 12.34 Prove that any submartingale X = (Xt)t ≥0 on a standard stochastic
basis (Ω, F, (Ft)t ≥0, P) admits the right-continuous modiﬁcation, if EXt is right-
continuous.
Hint: Using limiting arguments together with a submartingale property we have
Xt ≤E(Xt+|Ft) (a.s.), t ≤0. But Ft = Ft+, hence Xt ≤Xt+ (a.s.), and due to EXt =
EXt+ we get the result.
■
Problem 12.35 Let
M = (Mt)t ≥0
be
a
martingale
on
a
stochastic
basis
(Ω, F, (Ft)t ≥0, P). Show that a predictability property for the process φ = (φt) is
vital in getting the martingale property for a stochastic integral
∫t
0 φsdMs.
Hint: Take a rich enough probability space (Ω, F, P) to accommodate two random
variables: τ ≥0 with P(τ ≤t) = t ∧1 and a Bernoulli random variable Y such that
P(Y = 1) = P(Y = −1) = 1
2. Deﬁne Mt = Y.I{τ≤t } and ﬁltration Ft = FM
t . In this
case
∫t
0 MsdMs is not a martingale.
■
Problem 12.36 Let continuous processes A ∈A+
loc and M ∈Mloc are deﬁned on a
standard stochastic basis (Ω, F, (Ft)t ≥0, P). Assume that bi = bi(x), x ∈R1, i = 1, 2,
are bounded continuous functions and Xi, i = 1, 2, are (strong) continuous solutions
of the stochastic diﬀerential equations w.r. to a semimartingaleYt = At + Mt,Y0 = 0 :
dXi
t = bi(Xi
t )dAt + dMt,
where Xi
0 = x ∈R1.
Prove that the inequality b1(x) < b2(x) for all x ∈R1 implies X1
t (ω) ≤X2
t (ω) (a.s.)
for all t ≥0.
Hint: Apply the method of proof similar to Lemma 9.1.
■
Problem 12.37 Consider a stochastic diﬀerential equation as in problem 12.36
dXt = b(Xt)dAt + dMt,
where X0 = x ∈R1, t ≤T.
Assume that b1 = b(x), x ∈R1 satisﬁes conditions of Theorem 9.3 and A <<
⟨M, M⟩. Prove that this equation admits at least one (strong) solution.

202
12
Supplementary problems
Hint: Adapt the method of proof of Theorem 9.3 for this case.
■
Problem 12.38 Let dXt = μdt + σdWt + νdNt, where W and N be a Wiener pro-
cess and a Poisson process, respectively, with intensity λ > 0, μ, σ, ν ∈R1. Let (τi)
be the moments of the jumps of N. Prove the Ito formula for F ∈C2:
F(Xt) = F(X0) +
∫t
0
F′(Xs)dXs + 1
2
∫t
0
F′′(Xs−)σ2ds −
Nt

i=1
F′(Xτi−)ΔXτi +
Nt

i=1
(F(Xτi ) −F(Xτi−)).
Hint: Adapt the Ito formula for semimartingales in this case.
■
Problem 12.39 Let N = (Nt)t ≥0 be a Poisson process with intensity λ > 0 and
α = (αt) be a bounded deterministic function.
Deﬁne the process
Lt = exp{
∫t
0
αsd(Ns −λs) +
∫t
0
(1 + αs −eαs)λds}
and prove that L = (L0
t )t ≥0 is a martingale satisfying the equation
dLt = Lt−(eαt −1)d(Nt −λt).
Hint: Use the Ito formula.
■

References
1. Baldi P.: An introduction through theory and exercises.tochastic calculus. universitext, (2017)
2. Beiglboeck M., Schachermayer W., and Veliyev B.: A short proof of the doob-meyer theorem.
Stochastic Processes and their applications, vol. 122, no. 4, pp. 1204-1209, (2012)
3. Bishwal., Jaya PN.: Parameter Estimation in Stochastic Differential Equations. Springer-
Verlag, Berlin- Heidelberg, (2008)
4. Borkar., Vivek S.: Stochastic approximation: A dynamical systems viewpoint. Cambridge Uni-
versity Press, Cambridge, (2008)
5. Borodin., A. N.: Stochastic processes. Birkhauser, (2018)
6. Bulinski, A. V., Shiryayev, A. N.: Theory of stochastic processes. Fizmatlit, Moscow, (2005)
7. Çinlar, E.: Probability and Stochastics. Springer, vol. 261, (2011)
8. Cohen, S. N., Elliott, R. J.: Stochastic calculus and applications. 2nd Edition, Springer-Science,
(2015)
9. Doléans–Dade, C.: Stochastic processes and stochastic differential equations. in Stochastic
Differential Equations, Springer-Verlag, pp. 7-73, (2010)
10. Durrett, R.: Essentials of Stochastic Processes. 3rd Edition. Springer, (2018)
11. Eberlein, E., and Kallsen, J.: Mathematical Finance. Springer, (2019)
12. Edgar, G. A., Sucheston, L.: Amarts: A class of asymptotic martingales. a. discrete parameter.
Journal of Multivariate Analysis, vol. 6, pp. 193-221, (1976)
13. Etheridge, A.: A Course in Financial Calculus. Cambridge University Press, (2002)
14. Ikeda, N., and Watanabe, S.: Stochastic Differential Equations and Diffusion Processes. 2nd
Edition. North-Holland, (1989)
15. Jacod, J., and Protter, P.: Probability Essentials. 2nd Edition. Springer, (2003)
16. Kallianpur, G., and Karandikar, R. L.: Introduction to option pricing theory. Springer Science
& Business Media, (2012)
17. Karatzas, I., and Shreve, S.: Brownian motion and stochastic calculus. Springer, New York,
(1998)
18. Klebaner, F. C.: Introduction to stochastic calculus with applications. World Scientiﬁc Pub-
lishing Company, (2012)
19. Kolmogorov, A. N.: Foundations of the Theory of Probability. 2nd Edition. Chelsea, New York,
(1956)
20. Kruglov, V. M.: Stochastic Processes. Academy, Moscow, (2013)
21. Krylov, N. V.: Introduction to the theory of random processes. Providence: American Mathe-
matical Soc., (2002)
22. Krylov, N. V.: Controlled diffusion processes. Springer-Verlag, (1980)
© The Editor(s) (if applicable) and The Author(s), under exclusive license to
Springer Nature Switzerland AG 2023
A. Melnikov, A Course of Stochastic Analysis, CMS/CAIMS Books in Mathematics 6,
https://doi.org/10.1007/978-3-031-25326-3
203

204
References
23. Lamberton, D., and Lapeyre, B.: Introduction to Stochastic Calculus Applied to Finance. Chap-
man & Hall/CRC, (1996)
24. Le Gall, J.-F.: Brownian motion, martingales, and stochastic calculus. Springer, (2016)
25. Liptser, R. Sh., and Shiryaev, A. N.: Statistics of random processes. Springer, 2nd Ed, (2001)
26. Liptser, R. Sh, and Shiryaev, A. N.: Theory of martingales. Kluwer Academic Publishers,
(1989)
27. Melnikov, A. V.: On solutions of stochastic equations with driving semimartingales. Proceeding
of the third European young statisticians meeting, Catholic University, Leuven, pp. 120-124,
(1983)
28. Melnikov, A. V.: On strong solutions of stochastic differential equations with nonsmooth coef-
ﬁcients. Theory Probab. Appl., vol. 24, no. 1, pp. 146-149, (1979)
29. Melnikov, A. V.: On the theory of stochastic equations in components of semimartingles.
Sbornik Math, vol. 38, no. 3, pp. 381-394, (1981)
30. Melnikov,A.V.:Stochasticdifferentialequations:Singularityofcoefﬁcients,regressionmodels
and stochastic approximation. Russian Math Surveys, vol. 51, no. 5, pp. 43-136, (1996)
31. Melnikov, A. V., and Novikov, A. A.: Sequential inferences with ﬁxed accuracy for semimartin-
gales. Theory of Probability & Its Applications, vol. 33, no. 3, pp. 446-459, (1989)
32. Melnikov, A. V., and Shiryayev, A. N.: Criteria for the absence of arbitrage in the ﬁnancial
market. Frontiers in pure and applied probability II: proceedings of the Fourth Russian-Finnish
Symposium on Probability Theory and Mathematical Statistics, pp. 121-134, (1996)
33. Meyer, P.-A.: Probability and potential. Blaisdell Publ.Company, (1966)
34. Nevel’son, M. B., and Has’minskii, R. Z.: Stochastic approximation and recursive estimation.
AMS, Providence, (1976)
35. Øksendal, B.: Stochastic differential equations. 5th Edition. Springer, (2000)
36. Protter, P. E.: Stochastic Integration and Differential Equations. 2nd Edition. Springer, (2005)
37. Revuz, D., and Yor, M.: Continuous Martingales and Brownian Motion. 2nd Edition. Springer-
verlag, (1999)
38. Schachermayer, W., and Teichmann, J.: How close are the option pricing formulas of bachelier
and black-merton-scholes?. Mathematical Finance, vol. 18, no. 1, pp. 155-170, (2008)
39. Shiryaev, A. N.: Essentials of Stochastic Finance. World Scientiﬁc, (1999)
40. Shiryaev, A. N.: Probability. 2nd Edition. Springer, (1996)
41. Skorokhod, A. V.: Lectures on the theory of stochastic processes. Utrecht: VSP, (1996)
42. Tikhonov, A. N., Vasileva, A. B., and Sveshnikov, A. G.: Differential Equations. Springer,
(1985)
43. Valkeila, E., and Melnikov, A. V.: Martingale models of stochastic approximation and their
convergence. Theory of Probability & Its Applications, vol. 44, no. 2, pp. 333-360, (2000)
44. Wentzell, A. D.: A Course in the Theory of Stochastic Processes. McGraw-Hill, (1981)
45. Williams, D.: Probability and Martingales. Cambridge University Press, (1991)

Index
A
Absolute continuity, 41
local, 74
Absolute continuity of measures, 41
Accessible stopping time, 140
Algebra, 2
Atom, 46
Autoregression model, 68, 187
B
Bachelier
discrete model, 75
formula, 75
Bank account, 75
Bernoulli distribution, 7
Binomial market model, 180
Black-Scholes
formula, 129
model, 129
Borel function, 143
Borel space, 5, 13
Borel-Cantelli lemma, 89
Brownian motion, 82
C
Cadlag process, 142
Call option, 127, 128
Cantor function, 9
Capital of strategy, 176
Cauchy-Schwartz inequality, 27
Central Limit Theorem, 31
Change of measure, 53
Change of time, 50
Change of variables formula, 19
Characteristic function, 36
Chebyshev inequality, 26
Class D, 139
Comparison theorem, 113
Compensator, 52, 146, 147
Complete probability space, 83
Conditional expectation, 43
Controlled diffusion process, 132
Convergence
weak, 38
Convergence of Random Variables, 28
Cox-Ross-Rubinstein model, 180
Cylinder, 6
D
Debut, 142
Diffusion coefﬁcient, 120
Diffusion process, 120
Dirichlet function, 19
Discrete distribution, 7
Discrete stochastic integral, 53
Distribution
Bernoulli, 7
Binomial, 7
density function, 10
discrete, 7
ﬁnite-dimensional, 118
function, 7
Normal, 8
Poisson, 8
Uniform, 7, 8
Doleans exponent, 168
Doob decomposition, 52
Doob inequalities, 144
© The Editor(s) (if applicable) and The Author(s), under exclusive license to
Springer Nature Switzerland AG 2023
A. Melnikov, A Course of Stochastic Analysis, CMS/CAIMS Books in Mathematics 6,
https://doi.org/10.1007/978-3-031-25326-3
205

206
Index
Doob-Meyer decomposition, 146
Downcrossing, 58
Drift coefﬁcient, 114
E
Elementary event, outcome, 1
Equivalence of measures, 104
Existence of a solution, 109
Expectation, 18
Extended Random Variable, 13
F
Fair price, 127
Fatou lemma, 22
Feynman-Kac representation, 123
Filtration, 50
Financial market, 75, 129
Finite-additive measure, 2
Finite-dimensional
process, 97
Finite-dimensional distribution, 118
First variation, 86
Fisk decomposition, 158
Fixed accuracy property, 175
Fokker-Planck equation, 121
Formula
Bachelier, 76
Ito, 98
Merton, 180
Function
Borel, 15
Cantor, 9
characteristic, 36
Dirichlet, 19
Functional space, 81
Fundamental sequence, 93
G
Gaussian process, 90
General theory of stochastic processes, 139
Generalized martingale, 80
Generator, 120
Geometric Brownian Motion, 112, 129
Girsanov theorem, 74
Graph, 140
Gronwall lemma, 109
H
Haar system, 88
Hamilton-Jacobi-Bellman principle, 133
Hamilton-Jacoby-Bellman equation, 138
Helly principle, 32
I
Incomplete market, 176
Independent Random Variables, 16
Indicator, 13
Indistinguishable processes, 141
Inequality
Cauchy-Schwartz, 26
Chebyshev, 26
Jensen, 26
Kolmogorov-Doob, 56
Kunite-Watanabe, 160
Information ﬂow, 50
Integrable, 18
Integral
Lebesgue, 19
Interval of non-arbitrage prices, 135
Inverse image, 13
Isometric property, 92
Ito formula, 98
Ito process, 98
Ito stochastic integral, 97
J
Jensen inequality, 26
Joint Quadratic characteristic, 53
Jump-diffusion model, 180
K
Kolmogorov
backward, forward equation, 121
consistency theorem, 6
variance condition, 67
Kolmogorov-Chapman equation, 118
Kolmogorov-Doob inequality, 56
Kunita-Watanabe
decomposition, 54
inequality, 160
Kurtosis, 20
L
Large Numbers Law, 28
Least-squares estimate, 68
Lebesgue
dominated convergence theorem, 23
integral, 19
Lebesgue measure, 5
Levy theorem, 64

Index
207
Lindeberg condition, 39
Lipschitz condition, 108
Local Lipschitz conditions, 108
Local martingale, 80, 151
Localization, 96
Localizing sequence, 80
Locally square-integrable martingale, 151
Lower option price, 135
LS-estimate, 68
M
Markov process, 117
Martingale, 51
generalized, 80
local, 80, 151
locally square-integrable, 151
Square integrable, 52
Martingale difference, 51
Martingale measure, 127
Martingale representation, 104
Mathematical ﬁnance, 112, 126, 127
Maturity time, 127
Measurable
mapping, 16
Measurable space, 4
Measure, 1
ﬁnite-additive, 2
Lebesgue, 5
Martingale, 127
Wiener, 11
Merton formula, 180
Method of monotonic approximations, 113
Modiﬁcation
continuous, 84
right-continuous, 87
Monotonic class, 4
Multiplication rule, 182
N
Normal distribution, 8
Novikov condition, 75
O
Optimal control, 133
Option
call, 75
Optional Sampling Theorem, 55
Optional sigma-algebra, 142
Ornstein-Uhlenbeck process, 112
P
Parseval identity, 90
Partial Differential Equation, 123
Poisson distribution, 8
Polynomial, 101
Predictable process, 143
Predictable sequence, 52
Predictable sigma-algebra, 142
Predictable stopping time, 141
Principle of optimality, 133
Probability measure, 3
Probability space, 3, 5
Process with ﬁnite variation, 143
Progressively measurable, 98
Prokhorov theorem, 34
Purely discontinuous martingale, 150
Put-call parity, 129
Q
Quadratic bracket, 151
Quadratic characteristic, 52, 151
Quasimartingale, 79
R
Radon-Nikodym
density,derivative, 42
theorem, 42
Random set, 142
Random variable, 13
extended, 13
uniformly integrable, 23
Regression
analysis, 67
function, 71
Regression model, 68
Relative compactness, 34
Replicating strategy, 176
S
Sample path, 49
Scalar product, 88
Schauder system, 88
Semimartingale, 155
Sequential estimate, 132
Sigma-algebra, 4
optional, 142
predictable, 142
Singular distribution, measure, 8
Skewness, 20
Small perturbations method, 136
Step function, 91

208
Index
Stochastic Approximation, 71, 183
Stochastic basis, 55
Stochastic calculus, 159
Stochastic Differential Equation, 107
Stochastic exponential, 54, 168
multiplication rule, 168
Stochastic interval, 142
Stochastic Kronecker’s Lemma, 66
Stochastic regression analysis, 182
Stochastic volatility, 134
Stochastically continuous process, 87
Stock price, 46, 112
Stopped process, 154
Stopping time, 50
accessible, 140
graph, 140
predictable, 140
totally inaccessible, 141
Strategy, 176
Stratonovich integral, 97
Strong solution, 113
Subdivision, 83
Submartingale, 52
Supermartingale, 52
T
Theorem
Caratheodory, 5
CLT, 38
Comparison, 113
Girsanov, 74
Kolmogorov consistency, 6
Lebesgue dominated convergence, 27
Levy, 64
Optional Sampling, 55
Prokhorov, 34
Radon-Nikodym, 42
Theory of Probability, 1
Tightness, 34
Totally inaccessible stopping time, 141
Transition probability function, 118
U
Uniform distribution, 8
Uniformly integrable random variable, 23
Uniqueness of solutions, 112, 132
Upcrossing, 57
Upper option price, 135
Usual conditions, 139, 144
V
Value function, 133
Variance, 20
W
Wald identity, 95
Weak convergence, 38
Weak solution, 113
Wiener measure, 11

