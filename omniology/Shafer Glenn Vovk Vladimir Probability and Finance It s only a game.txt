Probability and 
Finance 

WILEY SERIES IN PROBABILITY AND STATISTICS 
FINANCIAL ENGINEERING SECTION 
Established by WALTER A. SHEWHART and SAMUEL S. WILKS 
Editors: Peter Bloorqfield, Noel A. C. Cressie, Nicholas 1. Fisher; 
Iuin M. John.stone, J. B. Kudane, Louise M. Ryan, David W Scott, 
Revnuid PY Silverman, Adrian E M. Smith, Jozef L. Teugels; 
Vic Burnett. Emeritus, Ralph A. Bradley, Emeritirs, 
J. Stztul-t Hiinter; Emeritus, David G. Kenclall, Emel-itits 
A complete list of the titles in this series appears at the end of this volume. 

Probability and 
Finance 
It’s Only a Game! 
GLENN SHAFER 
Rzitgers University 
Newark, New Jersey 
VLADIMIR VOVK 
Rqval Holloway, University of London 
Egharn, Surrey, England 
A Wiley-Interscience Publication 
JOHN WILEY & SONS, INC. 
NewYork 
Chichester 
Weinheim 
Brisbane 
Singapore 
Toronto 

This text is pi-inted on acid-free paper. @ 
Copyright C 2001 by John Wiley & Sons. Inc 
All rights reserved. Published simultaneously in Canada. 
No part of this publication may be reproduced. stored in a retrieval system or transmitted in any 
form or by any means, electronic, mechanical. photocopying. recording, scanning or othenvise. 
except as permitted under Section 107 or 108 of the 1976 United States Copyright Act, without 
either the prior written pemiission of the Publisher, or authorization through payment of the 
appropriate per-copy fee to the Copyright Clearance Center, 222 Rosewood Drive, Danvers, MA 
01923. (978) 750-8400. fax (978) 750-4744. Requests to the Publisher for pelmission should be 
addressed to the Permissions Department, John Wiley & Sons, Inc.. 605 Third Avenue, New York, 
NY 10158-0012. (212) 850-601 1. fax (212) 850-6008, E-Mail: PERMKEQ @! WILEY.COM. 
For ordering and customer service. call I-800-CALL WILEY. 
Library of Congress Catulojiing-iit-PNblicution Data: 
Shafer, Glenn. I 9 4 6  
Probability and finance : it's only a game! /Glenn Shafer and Vladimir Vovk 
Includes bibliographical references and index. 
ISBN 0-471-40226-5 (acid-free paper) 
1 .  Investments-Mathematics. 
2. Statistical decision. 3. Financial engineering. 
1. Vovk, 
p. cin. ~ 
(Wiley series in probability and statistics. Financial engineering section) 
Vladimir, 1960-. 
11. Title. 
111. Series. 
HG4S 15 3 .SS34 2001 
332'.01'1 -dc21 
Printed in the United States of America 
1 0 9 8 7 6 5 4 3 2 1  
2001024030 

Preface 
Contents 
1 Probability and Finance as a Game 
1.1 
A Game with the World 
1.2 
The Protocol for a Probability Game 
1.3 
The Fundamental Interpretative Hypothesis 
1.4 
The Many Interpretations of Probability 
1.5 
Game-Theoretic Probability in Finance 
Part I 
Probability without Measure 
2 The Historical Context 
2.1 
Probability before Kolmogorov 
2.2 
Kolmogorov 's Measure-Theoretic Framework 
2.3 
Realized Randomness 
2.4 
What is a Martingale? 
2.5 
2.6 
Neosubjectivism 
2.7 
Conclusion 
The Impossibility of a Gambling System 
ix 
1 
4 
9 
14 
19 
22 
27 
29 
30 
39 
46 
51 
55 
59 
60 
V 

Vi 
CONTENTS 
3 The Bounded Strong Law of Large Numbers 
3.1 
The Fair-Coin Game 
3.2 
Forecasting a Bounded Variable 
3.3 
Who Sets the Prices? 
3.4 
Asymmetric Bounded Forecasting Games 
3.5 
Appendix: The Computation of Strategies 
4 Kolmogorov’s Strong Law of Large Numbers 
4.1 
4.2 
Skeptic’s Strategy 
4.3 
Reality’s Strategy 
4.4 
4.5 
A Martingale Strong Law 
4.6 
Appendix: Martin’s Theorem 
Two Statements of Kolmogorov ’s Strong Law 
The Unbounded Upper Forecasting Protocol 
5 The Law of the Iterated Logarithm 
5.1 
Unbounded Forecasting Protocols 
5.2 
5.3 
5.4 
5.5 
Appendix: Historical Comments 
5.6 
The Validity of the Iterated-Logarithm Bound 
The Sharpness of the Iterated-Logarithm Bound 
A Martingale Law of the Iterated Logarithm 
Appendix: Kolmogorov ’s Finitary Interpretation 
6 The Weak Laws 
6.1 
Bernoulli’s Theorem 
6.2 
De Moivre’s Theorem 
6.3 
6.4 
Appendix: The Gaussian Distribution 
6.5 
A One-sided Central Limit Theorem 
Appendix: Stochastic Parabolic Potential Theory 
7 Lindeberg ’s Theorem 
7.1 
Lindeberg Protocols 
7.2 
7.3 
Examples of the Theorem 
7.4 
Statement and Proof of the Theorem 
Appendix: The Classical Central Limit Theorem 
61 
63 
65 
70 
72 
73 
75 
77 
81 
87 
89 
90 
94 
99 
101 
104 
108 
118 
118 
120 
121 
124 
126 
133 
143 
144 
147 
148 
153 
158 
164 

CONTENTS 
vii 
8 The Generality of Probability Games 
8.1 
8.2 
Coin Tossing 
8.3 
Game-Theoretic Price and Probability 
8.4 
Open ScientiJc Protocols 
8.5 
Appendix: Ville’s Theorem 
8.6 
Deriving the Measure-Theoretic Limit Theorems 
Appendix: A Brief Biography of Jean Ville 
Part II Finance without Probability 
9 Game-Theoretic Probability in Finance 
9.1 
9.2 
The Stochastic Black-Scholes Formula 
9.3 
9.4 
Informational Eficiency 
9.5 
9.6 
The Behavior of Stock-Market Prices 
A Purely Game-Theoretic Black-Scholes Formula 
Appendix: Tweaking the Black-Scholes Model 
Appendix: On the Stochastic Theory 
10 Games for Pricing Options in Discrete Time 
10.1 Bachelier’s Central Limit Theorem 
10.2 Bachelier Pricing in Discrete Time 
10.3 Black-Scholes Pricing in Discrete Time 
10.4 Hedging Error in Discrete Time 
10.5 Black-Scholes with Relative Variations for S 
10.6 Hedging Error with Relative Variations for S 
1 1 Games for Pricing Options in Continuous Time 
11 .I The Variation Spectrum 
11.2 Bachelier Pricing in Continuous Time 
11.3 Black-Scholes Pricing in Continuous Time 
11.4 The Game-Theoretic Source of the ddt Effect 
11.5 Appendix: Elements of Nonstandard Analysis 
11.6 Appendix: On the Diffusion Model 
167 
168 
177 
182 
189 
194 
197 
199 
201 
203 
215 
221 
226 
229 
231 
237 
239 
243 
249 
252 
259 
262 
2 71 
2 73 
2 75 
2 79 
281 
283 
287 

viii 
CONTENTS 
12 The Generality of Game-Theoretic Pricing 
293 
12.1 The Black-Scholes Formula with Interest 
294 
12.2 Better Instruments for Black-Scholes 
298 
12.3 Games for Price Processes with Jumps 
303 
12.4 Appendix: The Stable and Infinitely Divisible Laws 
31 1 
13 Games for American Options 
13. I Market Protocols 
13.2 Comparing Financial Instruments 
13.3 Weak and Strong Prices 
13.4 Pricing an American Option 
31 7 
31 8 
323 
328 
329 
14 Games for Diffusion Processes 
335 
14.2 It6 's Lemma 
340 
14.4 Appendix: The Nonstandard Interpretation 
346 
14.1 Game-Theoretic Dijfusion Processes 
337 
14.3 Game-Theoretic Black-Scholes Diffusion 
344 
14.5 Appendix: Related Stochastic Theory 
347 
15 The Game- Theoretic EfJicient-Market Hypothesis 
351 
15.1 A Strong Law for a Securities Market 
352 
15.2 The Iterated Logarithm for a Securities Market 
363 
15.3 Weak Laws for a Securities Market 
364 
15.4 Risk vs. Return 
367 
15.5 Other Forms of the E'cient-Market 
Hypothesis 
3 71 
References 
3 75 
Photograph Credits 
399 
Notation 
403 
Index 
405 

Preface 
This book shows how probability can be based on game theory, and how this can 
free many uses of probability, especially in finance, from distracting and confusing 
assumptions about randomness. 
The connection of probability with games is as old as probability itself, but the 
game-theoretic framework we present in this book is fresh and novel, and this has 
made the book exciting for us to write. We hope to have conveyed our sense of 
excitement and discovery to the reader. We have only begun to mine a very rich vein 
of ideas, and the purpose of the book is to put others in a position to join the effort. 
We have tried to communicate fully the power of the game-theoretic framework, 
but whenever a choice had to be made, we have chosen clarity and simplicity over 
completeness and generality. This is not a comprehensive treatise on a mature and 
finished mathematical theory, ready to be shelved for posterity. It is an invitation to 
participate. 
Our names as authors are listed in alphabetical order. This is an imperfect way 
of symbolizing the nature of our collaboration, for the book synthesizes points of 
view that the two of us developed independently in the 1980s and the early 1990s. 
The main mathematical content of the book derives from a series of papers Vovk 
completed in the mid-1990s. The idea of organizing these papers into a book, with a 
full account of the historical and philosophical setting of the ideas, emerged from a 
pleasant and productive seminar hosted by Aalborg University in June 1995. We are 
very grateful to Steffen Lauritzen for organizing that seminar and for persuading Vovk 
that his papers should be put into book form, with an enthusiasm that subsequently 
helped Vovk persuade Shafer to participate in the project. 

X 
PREFACE 
Shafer’s work on the topics of the book dates back to the late 1970s, when his 
study of Bayes’s argument for conditional probability [274] first led him to insist 
that protocols for the possible development of knowledge should be incorporated 
into the foundations of probability and conditional probability [275]. His recognition 
that such protocols are equally essential to objective and subjective interpretations 
of probability led to a series of articles in the early 1990s arguing for a foundation 
of probability that goes deeper than the established measure-theoretic foundation but 
serves a diversity of interpretations [276, 277, 278, 279, 2811. Later in the 1990s, 
Shafer used event trees to explore the representation of causality within probability 
theory [283, 284, 2851. 
Shafer’s work on the book itself was facilitated by his appointment as a Visiting 
Professor in Vovk’s department, the Department of Computer Science at Royal Hol- 
loway, University of London. Shafer and Vovk are grateful to Alex Gammerman, 
head of the department, for his hospitality and support of this project. Shafer’s 
work on the book also benefited from sabbatical leaves from Rutgers University in 
1996-1997 and 2000-2001. During the first of these leaves, he benefited from the 
hospitality of his colleagues in Paris: Bernadette Bouchon-Meunier and Jean-Yves 
Jaffray at the Laboratoire d’Informatique de I’UniversitC de Paris 6, and Bertrand 
Munier at the Ecole Normale Suptrieure de Cachan. During the second leave, he 
benefited from support from the German Fulbright Commission and from the hospi- 
tality of his colleague Hans-Joachim Lenz at the Free University of Berlin. During 
the 1999-2000 and 2000-2001 academic years, his research on the topics of the book 
was also supported by grant SES-9819116 from the National Science Foundation. 
Vovk’s work on the topics of the book evolved out of his work, first as an under- 
graduate and then as a doctoral student, with Andrei Kolmogorov, on Kolmogorov’s 
finitary version of von Mises’s approach to probability (see [319]). Vovk took his 
first steps towards a game-theoretic approach in the late 1980s, with his work on the 
law of the iterated logarithm [320, 3211. He argued for basing probability theory on 
the hypothesis of the impossibility of a gambling system in a discussion paper for 
the Royal Statistical Society, published in 1993. His paper on the game-theoretic 
Poisson process appeared in Test in 1993. Another, on a game-theoretic version 
of Kolmogorov’s law of large numbers, appeared in Theory of Probability and Its 
Applications in 1996. Other papers in the series that led to this book remain unpub- 
lished; they provided early proofs of game-theoretic versions of Lindeberg’s central 
limit theorem [328], Bachelier’s central limit theorem [325], and the Black-Scholes 
formula [327], as well as a finance-theoretic strong law of large numbers [326]. 
While working on the book, Vovk benefited from a fellowship at the Center for 
Advanced Studies in the Behavioral Sciences, from August 1995 to June 1996, and 
from a short fellowship at the Newton Institute, November 17-22,1997. Both venues 
provided excellent conditions for work. His work on the book has also benefited from 
several grants from EPSRC (GRL35812, GWM14937, and GR/M16856) and from 
visits to Rutgers. The earliest stages of his work were generously supported by 
George Soros’s International Science Foundation. He is grateful to all his colleagues 
in the Department of Computer Science at Royal Holloway for a stimulating research 

PREFACE 
xi 
environment and to his former Principal, Norman Gowar, for administrative and 
moral support. 
Because the ideas in the book have taken shape over several decades, we find 
it impossible to give a complete account of our relevant intellectual debts. We do 
wish to acknowledge, however, our very substantial debt to Phil Dawid. His work 
on what he calls the “prequential” framework for probability and statistics strongly 
influenced us both beginning in the 1980s. We have not retained his terminology, but 
his influence is pervasive. We also wish to acknowledge the influence of the many 
colleagues who have discussed aspects of the book’s ideas with us while we have 
been at work on it. Shashi Murthy helped us a great deal, beginning at a very early 
stage, as we sought to situate our ideas with respect to the existing finance literature. 
Others who have been exceptionally helpful at later stages include Steve Allen, Nick 
Bingham, Bernard Bru, Kaiwen Chen, Neil A. Chris, Pierre CrCpel, Joseph L. Doob, 
Didier Dubois, Adlai Fisher, Hans Follmer, Peter R. Gillett, Jean-Yves Jaffray, Phan 
Giang, Yuri Kalnichkan, Jack L. King, Eberhard Knobloch, Gabor Laszlo, Tony 
Martin, Nell Irvin Painter, Oded Palmon, Jan von Plato, Richard B. Scherl, Teddy 
Seidenfeld, J. Laurie Snell, Steve Stigler, Vladimir V’ yugin, Chris Watkins, and 
Robert E. Whaley. 
GLENN SHAFER 
Rutgers Univemiry, New Jersey, USA 
VLADIMIR VOVK 
Royal Hollowuy, Universiry of Landon, Surrey, UK 

1 
Introduction: Probabilitv 
and Finance as a Game 
We propose a framework for the theory and 
use of mathematical probability that rests 
more on game theory than on measure the- 
ory. This new framework merits attention 
on purely mathematical grounds, for it cap- 
tures the basic intuitions of probability sim- 
ply and effectively. It is also of philosophi- 
cal and practical interest. It goes deeper into 
probability’s conceptual roots than the estab- 
lished measure-theoretic framework, it is bet- 
ter adapted to many practical problems, and it 
clarifies the close relationship between prob- 
ability theory and finance theory. 
From the viewpoint of game theory, our 
framework is very simple. Its most essential 
Jean Ville (1910-1988) as a student at 
elements were already present in Jean Ville’s 
the t k o k  hbrmale SuPLrieure in Paris. 
colkctf, which introduced martingales into 
Our framework for probability. 
probability theory. Following Ville, we consider only two players. They alternate 
moves, each is immediately informed of the other’s moves, and one or the other wins. 
In such a game, one player has a winning strategy (§4.6), and so we do not need the 
subtle solution concepts now at the center of game theory in economics and the other 
social sciences. 
1939 book, ,&& critique de la notion de 
His study of martingales helped inspire 
1 
Probability and Finance: It’s Only a Game! Glenn Shafer, Vladimir Vovk 
Copyright 0 2001 John Wiley & Sons, Inc. 
ISBN: 0-471-40226-5 

2 
CHAPTER 1: PROBABILITY AND FINANCE AS A GAME 
Our framework is a straightforward but rigorous elaboration, with no extraneous 
mathematical or philosophical baggage, of two ideas that are fundamental to both 
probability and finance: 
0 The Principle of Pricing by Dynamic Hedging. When simple gambles can be 
combined over time to produce more complex gambles, prices for the simple 
gambles determine prices for the more complex gambles. 
0 The Hypothesis of the Impossibility of a Gambling System. Sometimes we 
hypothesize that no system for selecting gambles from those offered to us can 
both (1) be certain to avoid bankruptcy and (2) have a reasonable chance of 
making us rich. 
The principle of pricing by dynamic hedging can be discerned in the letters of Blaise 
Pascal to Pierre de Fermat in 1654, at the very beginning of mathematical probability, 
and it re-emerged in the last third of the twentieth century as one of the central ideas 
of finance theory. The hypothesis of the impossibility of a gambling system also has 
a long history in probability theory, dating back at least to Cournot, and it is related 
to the efficient-markets hypothesis, which has been studied in finance theory since 
the 1970s. We show that in a rigorous game-theoretic framework, these two ideas 
provide an adequate mathematical and philosophical starting point for probability 
and its use in finance and many other fields. No additional apparatus such as measure 
theory is needed to get probability off the ground mathematically, and no additional 
assumptions or philosophical explanations are needed to put probability to use in the 
world around us. 
Probability becomes game-theoretic as soon as we treat the expected values in a 
probability model as prices in a game. These prices may be offered to an imaginary 
player who stands outside the world and bets on what the world will do, or they may 
be offered to an investor whose participation in a market constitutes a bet on what the 
market will do. In both cases, we can learn a great deal by thinking in game-theoretic 
terms. Many of probability’s theorems turn out to be theorems about the existence of 
winning strategies for the player who is betting on what the world or market will do. 
The theorems are simpler and clearer in this form, and when they are in this form, 
we are in a position to reduce the assumptions we make-the 
number of prices we 
assume are offered-down to the minimum needed for the theorems to hold. This 
parsimony is potentially very valuable in practical work, for it allows and encourages 
clarity about the assumptions we need and are willing to take seriously. 
Defining a probability measure on a sample space means recommending a definite 
price for each uncertain payoff that can be defined on the sample space, a price at 
which one might buy or sell the payoff. Our framework requires much less than this. 
We may be given only a few prices, and some of them may be one-sided-certified 
only for selling, not for buying, or vice versa. From these given prices, using dynamic 
hedging, we may obtain two-sided prices for some additional payoffs, but only upper 
and lower prices for others. 
The measure-theoretic framework for probability, definitively formulated by An- 
drei Kolmogorov in 1933, has been praised for its philosophical neutrality: it can 

CHAPTER 1: PROBABILITY AND FINANCE AS A GAME 
3 
guide our mathematical work with probabilities no matter what meaning we want to 
give to these probabilities. Any numbers that satisfy the axioms of measure may be 
called probabilities, and it is up to the user whether to interpret them as frequencies, 
degrees of belief, or something else. Our game-theoretic framework is equally open 
to diverse interpretations, and its greater conceptual depth enriches these interpreta- 
tions. Interpretations and uses of probability differ not only in the source of prices but 
also in the role played by the hypothesis of the impossibility of a gambling system. 
Our framework differs most strikingly from the measure-theoretic framework 
in its ability to model open processes-processes 
that are open to influences we 
cannot model even probabilistically. This openness can, we believe, enhance the 
usefulness of probability theory in domains where our ability to control and predict 
is substantial but very limited in comparison with the sweep of a deterministic model 
or a probability measure. 
From a mathematical point of view, the first test of a framework for probability is 
how elegantly it allows us to formulate and prove the subject’s principal theorems, 
especially the classical limit theorems: the law of large numbers, the law of the 
iterated logarithm, and the central limit theorem. 
In Part I, we show how our 
game-theoretic framework meets this test. We contend that it does so better than 
the measure-theoretic framework. Our game-theoretic proofs sometimes differ little 
from standard measure-theoretic proofs, but they are more transparent. Our game- 
theoretic limit theorems are more widely applicable than their measure-theoretic 
counterparts, because they allow reality’s moves to be influenced by moves by other 
players, including experimenters, professionals, investors, and citizens. They are 
also mathematically more powerful; the measure-theoretic counterparts follow from 
them as easy corollaries. In the case of the central limit theorem, we also obtain an 
interesting one-sided generalization, applicable when we have only upper bounds on 
the variability of individual deviations. 
In Part 11, we explore the use of our framework in finance. We call Part I1 
“Finance without Probability” for two reasons. First, the two ideas that we consider 
fundamental to probability-the 
principle of pricing by dynamic hedging and the 
hypothesis of the impossibility of a gambling system-are 
also native to finance 
theory, and the exploitation of them in their native form in finance theory does 
not require extrinsic stochastic modeling. Second, we contend that the extrinsic 
stochastic modeling that does sometimes seem to be needed in finance theory can 
often be advantageously replaced by the further use of markets to set prices. Extrinsic 
stochastic modeling can also be accommodated in our framework, however, and Part 
I1 includes a game-theoretic treatment of diffusion processes, the extrinsic stochastic 
models that are most often used in finance and are equally important in a variety of 
other fields. 
In the remainder of this introduction, we elaborate our main ideas in a relatively 
informal way. We explain how dynamic hedging and the impossibility of a gambling 
system can be expressed in game-theoretic terms, and how this leads to game- 
theoretic formulations of the classical limit theorems. Then we discuss the diversity 
of ways in which game-theoretic probability can be used, and we summarize how 
our relentlessly game-theoretic point of view can strengthen the theory of finance. 

4 
CHAPTER 1: PROBABILITY AND FINANCE AS A GAME 
1.1 A GAME WITH THE WORLD 
At the center of our framework is a sequential game with two players. The game may 
have many-perhaps 
infinitely many-rounds 
of play. On each round, Player I bets 
on what will happen, and then Player I1 decides what will happen. Both players have 
perfect information; each knows about the other’s moves as soon as they are made. 
In order to make their roles easier to remember, we usually call our two players 
Skeptic and World. Skeptic is Player I; World is Player II. This terminology is 
inspired by the idea of testing a probabilistic theory. Skeptic, an imaginary scientist 
who does not interfere with what happens in the world, tests the theory by repeatedly 
gambling imaginary money at prices the theory offers. Each time, World decides 
what does happen and hence how Skeptic’s imaginary capital changes. If this capital 
becomes too large, doubt is cast on the theory. Of course, not all uses of mathematical 
probability, even outside of finance, are scientific. Sometimes the prices tested by 
Skeptic express personal choices rather than a scientific theory, or even serve merely 
as a straw man. But the idea of testing a scientific theory serves us well as a guiding 
example. 
In the case of finance, we sometimes substitute the names Investor and Market for 
Skeptic and World. Unlike Skeptic, Investor is a real player, risking real money. On 
each round of play, Investor decides what investments to hold, and Market decides 
how the prices of these investments change and hence how Investor’s capital changes. 
Dynamic Hedging 
The principle of pricing by dynamic hedging applies to both probability and finance, 
but the word “hedging” comes from finance. An investor hedges a risk by buying 
and selling at market prices, possibly over a period of time, in a way that balances the 
risk. In some cases, the risk can be eliminated entirely. If, for example, Investor has 
a financial commitment that depends on the prices of certain securities at some future 
time, then he may be able to cover the commitment exactly by investing shrewdly in 
the securities during the rounds of play leading up to that future time. If the initial 
Table 1.7 Instead of the uninformative names Player I and Player 11, we usually call our 
players Skeptic and World, because it is easy to remember that World decides while Skeptic 
only bets. In the case of finance, we often call the two players Investor and Market. 
PROBABILITY 
FINANCE 
Skeptic bets against the 
probabilistic predictions 
of a scientific theory. 
Player I bets on 
what will happen. 
Investor bets by choosing 
a portfolio of investments. 
Market decides how the 
price of each investment 
changes. 
Player I1 decides 
what happens. 
predictions come out. 
World decides how the 

1.1: A GAME WITH THE WORLD 
5 
capital required is $a, then we may say that Investor has a strategy for turning $a into 
the needed future payoff. Assuming, for simplicity, that the interest rate is zero, we 
may also say that $a is the game’s price for the payoff. This is the principle of pricing 
by dynamic hedging. (We assume throughout this chapter and in most of the rest of 
the book that the interest rate is zero. This makes our explanations and mathematics 
simpler, with no real loss in generality, because the resulting theory extends readily 
to the case where the interest rate is not zero: see $ 12.1 .) 
As it applies to probability, the principle of pricing by dynamic hedging says 
simply that the prices offered to Skeptic on each round of play can be compounded to 
obtain prices for payoffs that depend on more than one of World’s moves. The prices 
for each round may include probabilities for what World will do on that round, and 
the global prices may include probabilities for World’s whole sequence of play. We 
usually assume that the prices for each round are given either at the beginning of the 
game or as the game is played, and prices for longer-term gambles are derived. But 
when the idea of a probability game is used to study the world, prices may sometimes 
be derived in the opposite direction. The principle of pricing by dynamic hedging 
then becomes merely a principle of coherence, which tells us how prices at different 
times should fit together. 
We impose no general rules about how many gambles are offered to Skeptic on 
different rounds of the game. On some rounds, Skeptic may be offered gambles on 
every aspect of World’s next move, while on other rounds, he may be offered no 
gambles at all. Thus our framework always allows us to model what science models 
and to leave unmodeled what science leaves unmodeled. 
The Fundamental Interpretative Hypothesis 
In contrast to the principle of pricing by dynamic hedging, the hypothesis of the 
impossibility of a gambling system is optional in our framework. The hypothesis 
boils down, as we explain in $1.3, to the supposition that events with zero or low 
probability are unlikely to occur (or, more generally, that events with zero or low 
upper probability are unlikely to occur). This supposition is fundamental to many 
uses of probability, because it makes the game to which it is applied into a theory 
about the world. By adopting the hypothesis, we put ourselves in a position to test the 
prices in the game: if an event with zero or low probability does occur, then we can 
reject the game as a model of the world. But we do not always adopt the hypothesis. 
We do not always need it when the game is between Investor and Market, and we 
do not need it when we interpret probabilities subjectively, in the sense advocated by 
Bruno de Finetti. For de Finetti and his fellow neosubjectivists, a person’s subjective 
prices are nothing more than that; they are merely prices that systematize the person’s 
choices among risky options. See $1.4 and $2.6. 
We have a shorter name for the hypothesis of the impossibility of a gambling 
system: we call it the fundamental interpretative hypothesis of probability. It is 
interpretative because it tells us what the prices and probabilities in the game to 
which it is applied mean in the world. It is not part of our mathematics. It stands 
outside the mathematics, serving as a bridge between the mathematics and the world. 

6 
CHAPTER 1: PROBABlLlTY AND NNANCE AS A GAME 
THE FUNDAMENTAL 
INTERPRETATIVE 
HYPOTHESIS 
/ 
'\\ 
There is no real market. 
Because money is imaginary, 
/' 
Numiraire must be specified. 
Skeptic (imaginary player) 
or to Investor (real player). 
no numiraire is needed. 
Hypothesis applies to Skeptic 
an imaginary player. 
There is a real market. 
'\ 
Hypothesis may apply to 
, 
'\ 
,',' 
THE IMPOSSIBILITY 
OF A GAMBLING 
SYSTEM 
THE EFFICIENT 
MARKET 
HYPOTHESIS 
Fig. 7.7 
The fundamental interpretative hypothesis in probability and finance. 
When we are working in finance, where our game describes a real market, we 
use yet another name for our fundamental hypothesis: we call it the eficient-market 
hypothesis. The efficient-market hypothesis, as applied to a particular financial 
market, in which particular securities are bought and sold over time, says that an 
investor (perhaps a real investor named Investor, or perhaps an imaginary investor 
named Skeptic) cannot become rich trading in this market without risking bankruptcy. 
In order to make such a hypothesis precise, we must specify not only whether we are 
talking about Investor or Skeptic, but also the nume'ruire-the 
unit of measurement 
in which this player's capital is measured. We might measure this capital in nominal 
terms (making a monetary unit, such as a dollar or a ruble, the nume'ruire), we might 
measure it relative to the total value of the market (making some convenient fraction 
of this total value the nume'ruire), or we might measure it relative to a risk-free bond 
(which is then the nume'ruire), and so on. Thus the efficient-market hypothesis can 
take many forms. Whatever form it takes, it is subject to test, and it determines upper 
and lower probabilities that have empirical meaning. 
Since about 1970, economists have debated an efficient-markets hypothesis, with 
markets in the plural. This hypothesis says that financial markets are efficient in 
general, in the sense that they have already eliminated opportunities for easy gain. 
As we explain in Part I1 (59.4 and Chapter 15), our efficient-market hypothesis has 
the same rough rationale as the efficient-markets hypothesis and can often be tested in 
similar ways. But it is much more specific. It requires that we specify the particular 
securities that are to be included in the market, the exact rule for accumulating capital, 
and the nume'ruire for measuring this capital. 
Open Systems within the World 
Our austere picture of a game between Skeptic and World can be filled out in a 
great variety of ways. One of the most important aspects of its potential lies in the 

1.1: A GAME WITH THE WORLD 
7 
possibility of dividing World into several players. For example, we might divide 
World into three players: 
Experimenter, who decides what each round of play will be about. 
Forecaster, who sets the prices. 
Reality, who decides the outcomes. 
This division reveals the open character of our framework. The principle of pricing 
by dynamic hedging requires Forecaster to give coherent prices, and the fundamental 
interpretative hypothesis requires Reality to respect these prices, but otherwise all 
three players representing World may be open to external information and influence. 
Experimenter may have wide latitude in deciding what experiments to perform. 
Forecaster may use information from outside the game to set prices. Reality may 
also be influenced by unpredictable outside forces, as long as she acts within the 
constraints imposed by Forecaster. 
Many scientific models provide testable probabilistic predictions only subsequent 
to the determination of many unmodeled auxiliary factors. The presence of Ex- 
perimenter in our framework allows us to handle these models very naturally. For 
example, the standard mathematical formalization of quantum mechanics in terms 
of Hilbert spaces, due to John von Neumann, fits readily into our framework. The 
scientist who decides what observables to measure is Experimenter, and quantum 
theory is Forecaster ($8.4). 
Weather forecasting provides an example where information external to a model 
is used for prediction. Here Forecaster may be a person or a very complex computer 
program that escapes precise mathematical definition because it is constantly under 
development. In either case, Forecaster will use extensive external information- 
weather maps, past experience, etc. If Forecaster is required to announce every 
evening a probability for rain on the following day, then there is no need for Experi- 
menter; the game has only three players, who move in this order: 
Forecaster, Skeptic, Reality. 
Forecaster announces odds for rain the next day, Skeptic decides whether to bet for 
or against rain and how much, and Reality decides whether it rains. The fundamental 
interpretative hypothesis, which says that Skeptic cannot get rich, can be tested by 
any strategy for betting at Forecaster’s odds. 
It is more difficult to make sense of the weather forecasting problem in the 
measure-theoretic framework. The obvious approach is to regard the forecaster’s 
probabilities as conditional probabilities given what has happened so far. But be- 
cause the forecaster is expected to learn from his experience in giving probability 
forecasts, and because he uses very complex and unpredictable external information, 
it makes no sense to interpret his forecasts as conditional probabilities in a proba- 
bility distribution formulated at the outset. And the forecaster does not construct a 
probability distribution along the way; this would involve constructing probabilities 
for what will happen on the next day not only conditional on what has happened so 
far but also conditional on what might have happened so far. 

8 
CHAPTER 1: PROBABILITY AND FINANCE AS A GAME 
In the 1980s, A. Philip Dawid proposed that the forecasting success of a proba- 
bility distribution for a sequence of events should be evaluated using only the actual 
outcomes and the sequence of forecasts (conditional probabilities) to which these 
outcomes give rise, without reference to other aspects of the probability distribution. 
This is Dawid’s prequential principle [82]. In our game-theoretic framework, the 
prequential principle is satisfied automatically, because the probability forecasts pro- 
vided by Forecaster and the outcomes provided by Reality are all we have. So long 
as Forecaster does not adopt a strategy, no probability distribution is even defined. 
The explicit openness of our framework makes it well suited to modeling systems 
that are open to external influence and information, in the spirit of the nonpara- 
metric, semiparametric, and martingale models of modern statistics and the even 
looser predictive methods developed in the study of machine learning. It also fits 
the open spirit of modern science, as emphasized by Karl Popper [250]. In the 
nineteenth century, many scientists subscribed to a deterministic philosophy inspired 
by Newtonian physics: at every moment, every future aspect of the world should be 
predictable by a superior intelligence who knows initial conditions and the laws of 
nature. In the twentieth century, determinism was strongly called into question by 
further advances in physics, especially in quantum mechanics, which now insists that 
some fundamental phenomena can be predicted only probabilistically. Probabilists 
sometimes imagine that this defeat allows a retreat to a probabilistic generalization of 
determinism: science should give us probabilities for everything that might happen 
in the future. In fact, however, science now describes only islands of order in an 
unruly universe. Modern scientific theories make precise probabilistic predictions 
only about some aspects of the world, and often only after experiments have been 
designed and prepared. The game-theoretic framework asks for no more. 
Skeptic and World Always Alternate Moves 
Most of the mathematics in this book is developed for particular examples, and as we 
have just explained, many of these examples divide World into multiple players. It is 
important to notice that this division of World into multiple players does not invalidate 
the simple picture in which Skeptic and World alternate moves, with Skeptic betting 
on what World will do next, because we will continue to use this simple picture in 
our general discussions, in the next section and in later chapters. 
One way of seeing that the simple picture is preserved is to imagine that Skeptic 
moves just before each of the players who constitute World, but that only the move 
just before Reality can result in a nonzero payoff for Skeptic. Another way, which 
we will find convenient when World is divided into Forecaster and Reality, is to add 
just one dummy move by Skeptic, at the beginning of the game, and then to group 
each of Forecaster’s later moves with the preceding move by Reality, so that the order 
of play becomes 
Skeptic, Forecaster, Skeptic, (Reality, Forecaster), 
Skeptic, (Reality, Forecaster), . . . 
Either way, Skeptic alternates moves with World, 

1.2: THE PROTOCOL FOR A PROBABILITY GAME 
9 
The Science of Finance 
Other players sometimes intrude into the game between Investor and Market. Finance 
is not merely practice; there is a theory of finance, and our study of it will sometimes 
require that we bring Forecaster and Skeptic into the game. This happens in several 
different ways. In Chapter 14, where we give a game-theoretic reading of the usual 
stochastic treatment of option pricing, Forecaster represents a probabilistic theory 
about the behavior of the market, and Skeptic tests this theory. In our study of the 
efficient-market hypothesis (Chapter 1 3 ,  in contrast, the role of Forecaster is played 
by Opening Market, who sets the prices at which Investor, and perhaps also Skeptic, 
can buy securities. The role of Reality is then played by Closing Market, who decides 
how these investments come out. 
In much of Part 11, however, especially in Chapters 10-13, we study games 
that involve Investor and Market alone. These may be the most important market 
games that we study, because they allow conclusions based solely on the structure 
of the market, without appeal to any theory about the efficiency of the market or the 
stochastic behavior of prices. 
1.2 THE PROTOCOL FOR A PROBABILITY GAME 
Specifying a game fully means specifying the moves available to the players-we 
call this the protocol for the game-and 
the rule for determining the winner. Both of 
these elements can be varied in our game between Skeptic and World, leading to many 
different games, all of which we call probability games. The protocol determines the 
sample space and the prices (in general, upper and lower prices) for variables. The 
rule for determining the winner can be adapted to the particular theorem we want to 
prove or the particular problem where we want to use the framework. In this section 
we consider only the protocol. 
The general theory sketched in this section applies to most of the games studied 
in this book, including those where Investor is substituted for Skeptic and Market for 
World. (The main exceptions are the games we use in Chapter 13 to price American 
options.) We will develop this general theory in more detail in Chapters 7 and 8. 
The Sample Space 
The protocol for a probability game specifies the moves available to each player, 
Skeptic and World, on each round. This determines, in particular, the sequences of 
moves World may make. These sequences-the 
possible complete sequences of play 
by World-constitute the sample spuce for the game. We designate the sample space 
by 0, and we call its elements paths. The moves available to World may depend on 
moves he has previously made. But we assume that they do not depend on moves 
Skeptic has made. Skeptic’s bets do not affect what is possible in the world, although 
World may consider them in deciding what to do next. 

70 
CHAPTER I: PROBABlLlTY AND NNANCEASA GAME 
Change in price the 
day after the day 
after tomorrow 
Change in price thc 
day after tomorrow 
$0 
-3,-2 
~ 
~ 
~~ 
-3,-2,0 
Change in price 
-$2,, , 
tomorrow 
, 
-3 
<
:
.
 
$0 __- 
-3,2,0 
$2 
-3,2,2 
-3,2 -=A- 
-$3 ,//’ 
$2 
/ 
Fig. 7.2 An unrealistic sample space for changes in the price of a stock. The steps in the tree 
represent possible moves by World (in this case, the market). The nodes (situations) record 
the moves made by World so far. The initial situation is designated by 0. The terminal nodes 
record complete sequences of play by World and hence can be identified with the paths that 
constitute the sample space. The example is unrealistic because in a real stock market there is 
a wide range of possible changes for a stock’s price at each step, not just two or three. 
We can represent the dependence of World’s possible moves on his previous moves 
in terms of a tree whose paths form the sample space, as in Figure 1.2. Each node 
in the tree represents a situation, and the branches immediately to the right of a 
nonterminal situation represent the moves World may make in that situation. The 
initial situation is designated by 0. 
Figure 1.2 is finite: there are only finitely many paths, and every path terminates 
after a finite number of moves. We do not assume finiteness in general, but we do 
pay particular attention to the case where every path terminates; in this case we say 
the game is terminating. If there is a bound on the length of the paths, then we say 
the game has ajinite horizon. If none of the paths terminate, we say the game has an 
injinite horizon. 
In general, we think of a situation (a node in the tree) as the sequence of moves 
made by World so far, as explained in the caption of Figure 1.2. So in a terminating 
game, we may identify the terminal situation on each path with that path; both are 
the same sequence of moves by World. 
In measure-theoretic probability theory, a real-valued function on the sample 
space is called a random variable. Avoiding the implication that we have defined a 
probability measure on the sample space, and also whatever other ideas the reader 
may associate with the word “random”, we call such a function simply a variable. 
In the example of Figure 1.2, the variables include the prices for the stock for each 
of the next three days, the average of the three prices, the largest of the three prices, 

1.2: THE PROTOCOL FOR A PROBABILITY GAME 
11 
Fig. 1.3 Forming a nonnegative linear combination of two gambles. In the first gamble 
Skeptic pays ml in order to get a l ,  b l ,  or c1 in return, depending on how things come out. In 
the second gamble, he pays m2 in order to get u2. b2, or c2 in return. 
and so on. We also follow established terminology by calling a subset of the sample 
space an event. 
Moves and Strategies for Skeptic 
To complete the protocol for a probability game, we must also specify the moves 
Skeptic may make in each situation. Each move for Skeptic is a gamble, defined by a 
price to be paid immediately and a payoff that depends on World’s following move. 
The gambles among which Skeptic may choose may depend on the situation, but we 
always allow him to combine available gambles and to take any fraction or multiple 
of any available gamble. We also allow him to borrow money freely without paying 
interest. So he can take any nonnegative linear combination of any two available 
gambles, as indicated in Figure 1.3. 
We call the protocol symmetric if Skeptic is allowed to take either side of any 
available gamble. This means that whenever he can buy the payoff z at the price 
m, he can also sell z at the price rn. Selling z for m is the same as buying -z for 
-m (Figure 1.4). So a symmetric protocol is one in which the gambles available to 
Skeptic in each situation form a linear space; he may take any linear combination 
of the available gambles, whether or not the coefficients in the linear combination 
are nonnegative. If we neglect bid-ask spreads and transaction costs, then protocols 
based on market prices are symmetric, because one may buy as well as sell a security 
at its market price. Protocols corresponding to complete probability measures are 
also symmetric. But many of the protocols we will study in this book are asymmetric. 
A strategy for Skeptic is a plan for how to gamble in each nonterminal situation he 
might encounter. His strategy together with his initial capital determine his capital 
in every situation, including terminal situations. Given a strategy P and a situation t, 
we write Icp (t) for Skeptic’s capital in t if he starts with capital 0 and follows P. 
In 
the terminating case, we may also speak of the capital a strategy produces at the end 
of the game. Because we identify each path with its terminal situation, we may write 
KP([) for Skeptic’s final capital when he follows P and World takes the path [. 

72 
CHAPTER 1: PROBABILITY AND FINANCE AS A GAME 
fig. 7.4 Taking the gamble on the left means paying m and receiving a, b, or c in return. 
Taking the other side means receiving TTL and paying a, b, or c in return-Le., 
paying -m and 
receiving -a, 4, 
or -c in return. This is the same as taking the gamble on the right. 
Simulated 
by P if 
Meaning 
Net payoff 
satisfactorily 
Buy x for a 
Pay a, get 2 
x - a  
K p  > x - a  
Sell x for a 
Get a, pay x 
a-x 
K P > a - x  
Table 7.2 How a strategy P in a probability game can simulate the purchase or sale of a 
variable 2. 
Upper and Lower Prices 
By adopting different strategies in a probability game, Skeptic can simulate the 
purchase and sale of variables. We can price variables by considering when this 
succeeds. In order to explain this idea as clearly as possible, we make the simplifying 
assumption that the game is terminating. 
A strategy simulates a transaction satisfactorily for Skeptic if it produces at least 
as good a net payoff. Table 1.2 summarizes how this applies to buying and selling 
a variable x. As indicated there, P simulates buying x for a satisfactorily if K p  > 
x - a. This means that 
a 9  
> 40 - a 
for every path E in the sample space 0. When Skeptic has a strategy P satisfying 
K p  > x - a, we say he can buy x for a. Similarly, when he has a strategy P 
satisfying K p  2 a - x, we say he can sell x for a. These are two sides of the same 
coin: selling x for a is the same as buying -x for -a. 
Given a variable x ,  we set 
Ex:=inf{aI thereissomestrategyPsuchthatKp > z - a } . ’  
(1.1) 
We call E x  the upper price of x or the cost of x; it is the lowest price at which 
Skeptic can buy x. (Because we have made no compactness assumptions about 
the protocol-and 
will make none in the sequel-the 
infimum in (1.1) may not be 
attained, and so strictly speaking we can only be sure that Skeptic can buy x for 
‘We use := to mean “equal by definition”: the right-hand side of the equation is the definition of the 
left-hand side. 

1.2: THE PROTOCOL FOR A PROBABILITY GAME 
13 
- 
IE x + E for every E > 0. But it would be tedious to mention this constantly, and so we 
ask the reader to indulge the slight abuse of language involved in saying that Skeptic 
can buy x for z.) 
Similarly, we set 
- 
IE x := sup { a 1 there is some strategy P such that Icp 2 a - x} . 
(1.2) 
We call Ex the lower price of x or the scrap value of x; it is the highest price at 
which Skeptic can sell x. 
It follows from (1.1) and (1.2), and also directly from the fact that selling x for a 
is the same as buying -x for -a, that 
I E I I :  = -E[-x] 
for every variable 5. 
The idea of hedging provides another way of talking about upper and lower prices. 
If we have an obligation to pay something at the end of the game, then we hedge this 
obligation by trading in such a way as to cover the payment no matter what happens. 
So we say that the strategy P hedges the obligation y if 
(1.3) 
for every path < in the sample space s2. Selling a variable x for cy results in a net 
obligation of x - cy at the end of the game. So P hedges selling x for a if P hedges 
x - 0, that is, if P simulates buying x for a. Similarly, P hedges buying x for a 
if P simulates selling x for a. So E x  is the lowest price at which selling x can be 
hedged, and E x  is the highest price at which buying it can be hedged, as indicated 
in Table 1.3. 
These definitions implicitly place Skeptic at the beginning of the game, in the 
initial situation 0. They can also be applied, however, to any other situation; we 
simply consider Skeptic’s strategies for play from that situation onward. We write 
IE, 3: and IE, II: for the upper and lower price, respectively, of the variable x in the 
situation t. 
- 
Table 1.3 Upper and lower price described in terms of simulation and described in terms of 
hedging. Because hedging the sale of x is the same as simulating the purchase of z, and vice 
versa, the two descriptions are equivalent. 
Name 
Description in terms 
of the simulation of 
buying and selling 
Description in terms 
of hedging 
- 
Lowest price at which 
Lowest selling price for 
IE II: 
Upper price of x 
Skeptic can buy x 
x Skeptic can hedge 
Highest price at which 
Skeptic can sell II: 
Highest buying price for 
x Skeptic can hedge 
IE x 
Lower price of x 
- 

14 
CHAPTER 1: PROBABILITY AND FINANCE AS A GAME 
Upper and lower prices are interesting only if the gambles Skeptic is offered do 
not give him an opportunity to make money for certain, If this condition is satisfied 
in situation t, we say that the protocol is coherent in t. In this case, 
- 
for every variable x, and 
lEt 0 = IE, 0 = 0, 
where 0 denotes the variable whose value is 0 on every path in R. 
When IE, x = & x, we call their common value the exact price or simply the price 
for J: in t and designate it by & 2 .  Such prices have the properties of expected values 
in measure-theoretic probability theory, but we avoid the term “expected value” in 
order to avoid suggesting that we have defined a probability measure on our sample 
space. We do, however, use the word “variance”; when IEt x exists, we set 
- 
v,x := Et(x - Etx) 
and 
FJt x := &(x - IEt x ) ~ ,  
and we call them, respectively, the upper variance of x in t and the lower variance 
of x in t. If vt x and FJ, x are equal, we write Vt x for their common value; this is 
the (game-theoretic)variance of x in t. 
When the game is not terminating, definitions (1. l), (1.2), and (1.3) do not work, 
because P may fail to determine a final capital for Skeptic when World takes an 
infinite path; if there is no terminal situation on the path I, then K p ( t )  may or may 
not converge to a definite value as t moves along c$‘. 
Of the several ways to fix 
this, we prefer the simplest: we say that P hedges y if on every path 
the capital 
K? (t) eventually reaches y(E) and stays at or above it, and we similarly modify (1 .l) 
and (1.2). We will study this definition in 58.3. On the whole, we make relatively 
little use of upper and lower price for nonterminating probability games, but as we 
explain in the next section, we do pay great attention to one special case, the case of 
probabilities exactly equal to zero or one. 
1.3 THE FUNDAMENTAL INTERPRETATIVE HYPOTHESIS 
The fundamental interpretative hypothesis asserts that no strategy for Skeptic can both 
(1) be certain to avoid bankruptcy and (2) have a reasonable chance of making Skeptic 
rich. Because it contains the undefined term “reasonable chance”, this hypothesis 
is not a mathematical statement; it is neither an axiom nor a theorem. Rather it 
is an interpretative statement. It gives meaning in the world to the prices in the 
probability game. Once we have asserted that Skeptic does not have a reasonable 
chance of multiplying his initial capital substantially, we can identify other likely and 
unlikely events and calibrate just how likely or unlikely they are. An event is unlikely 
if its happening would give an opening for Skeptic to multiply his initial capital 
substantially, and it is the more unlikely the more substantial this multiplication is. 
We use two distinct versions of the fundamental interpretative hypothesis, one 
Jl’nitury and one infinitaty: 

1.3: THE FUNDAMENTAL INTERPRETATIVE HYPOTHESIS 
15 
0 The Finitary Hypothesis. No strategy for Skeptic can both (I) be certain to 
avoid bankruptcy and (2) have a reasonable chance of multiplying his initial 
capital by a large factor. (We usually use this version in terminating games.) 
0 The Infinitary Hypothesis. No strategy for Skeptic can both (1) be certain to 
avoid bankruptcy and (2) have a reasonable chance of making him infinitely 
rich. (We usually use this version in infinite-horizon games.) 
Because our experience with the world is finite, the finitary hypothesis is of more 
practical use, but the infinitary hypothesis often permits clearer and more elegant 
mathematical statements. As we will show in Part I, the two forms lead to the 
two types of classical limit theorems. The finitary hypothesis leads to the weak limit 
theorems: the weak law of large numbers and the central limit theorem. The infinitary 
hypothesis leads to the strong limit theorems: the strong law of large numbers and 
the law of the iterated logarithm. 
It i s  easy for World to satisfy the fundamental interpretative hypothesis in a 
probability game with a coherent protocol, for he can always move so that Skeptic 
does not make money. But becoming rich is not Skeptic’s only goal in the games we 
study. In many of these games, Skeptic wins either if he becomes rich or if World’s 
moves satisfy some other condition E. If Skeptic has a winning strategy in such a 
game, then the fundamental interpretative hypothesis authorizes us to conclude that 
E will happen. In order to keep Skeptic from becoming rich, World must move so 
as to satisfy E. 
Low Probability and High Probability 
In its finitary form, the fundamental interpretative hypothesis provides meaning to 
small upper probabilities and large lower probabilities. 
We can define upper and lower probabilities formally as soon as we have the 
concepts of upper and lower price. As we mentioned earlier, an event is a subset of 
the sample space. Given an event E ,  we define its indicator variable X E  by 
Then we define its upperprobability by 
Assuming the protocol is coherent, upper and lower probability obey 
and 
- 
PE=l-ifDEC. 

16 
CHAPTER 1: PROBABILITY AND FINANCE AS A GAME 
Jpw 
Jp {El 
1 
t - p - 4  
, 
1 
- ----+ 
Ip {El 
Ip {El 
No meaning except in conjunction 
with the probabilities of other events. 
E is unlikely 
Ip {El 
{El 
1 - - l t - -  
~ 
I 
} 
- -  
- 
4 1  
Ip {El 
Jp {El 
E is likely 
No meaning except in conjunction 
with the probabilities of other events 
Fig. 7.5 Only extreme probabilities have meaning in isolation 
Here EC is the complement of E in 0-the 
set of paths for World that are not in E, 
or the event that E does not happen. 
What meaning can be attached to E and E E? The fundamental interpretative 
hypothesis answers this question when the two numbers are very close to zero. 
Suppose, for example, that P E  = 0.001. (In this case, P E  is also close to zero; 
by (1.6), it is between 0 and 0.001.) Then Skeptic can buy j l ~  
for 0.001. Because 
1~ 2 0, the purchase does not open him to possible bankruptcy, and yet it results in a 
thousandfold increase in his investment if E happens. The fundamental interpretative 
hypothesis says that this increase is unlikely and hence implies that E is unlikely. 
Similarly, we may say that E is very likely to happen if E E and hence also P E 
are very close to one. Indeed, if E E  is close to one, then by (1.7), PE“ is close 
to zero, and hence it is unlikely that EC 
will happen-that 
is, it is likely that E will 
happen. 
These interpretations are summarized in Figure 1.5. If P E  and E E  are neither 
both close to zero nor both close to one, as on the right in the figure, then they have 
little or no meaning in isolation. But if they are both close to zero, then we may say 
that E has “low probability” and is unlikely to happen. And if they are both close to 
one, then we may say that E has “high probability” and is likely to happen. 
Strictly speaking, we should speak of the probability of E only if P E and E E 
are exactly equal, for then their common value may be called the (game-theoretic) 
probability of E. But as the figure indicates, it is much more meaningful for the two 
values to both be close to zero or both be close to one than for them to be exactly 
equal. 
The most important examples of low and high probability in this book occur in 
the two weak laws that we study in Chapters 6 and 7: the weak law of large numbers 
and the central limit theorem. The weak law of large numbers, in its simplest form, 
says that when Skeptic is offered even odds on each of a long sequence of events, 
the probability is high that the fraction of the events that happen will fall within 

1.3: THE FUNDAMENTAL INTERPRETATIVE HYPOTHESIS 
17 
a small interval around 1/2: an interval that may be narrowed as the number of 
the events increases. The central limit theorem gives numerical estimates of this 
high probability. According to our definition of high probability, these theorems say 
something about Skeptic’s opportunities to make money. The law of large numbers 
says that Skeptic has a winning strategy in a game that he wins if World either stays 
close to 1/2 or allows Skeptic to multiply his stake substantially, and the central limit 
theorem calibrates the tradeoff between how far World can stray from 1/2 and how 
much he can constrain Skeptic’s wealth. 
Middling probabilities, although they do not have meaning in isolation, can acquire 
collective meaning from the limit theorems. The law of large numbers tells us, for 
example, that many probabilities for successive events all equal to 1/2 produce a 
very high probability that the relative frequency of the events will approximate 1/2. 
Probability Zero and Probability One 
As we have just emphasized, the finitary version of our fundamental hypothesis gives 
meaning to probabilities very close to zero or one. Skeptic is unlikely to become 
very rich, and therefore an event with a very low probability is unlikely to occur. The 
infinitary version sharpens this by giving meaning to probabilities exactly equal to 
zero or one. It is practically impossible for Skeptic to become infinitely rich, and 
therefore an event that makes this possible is practically certain not to occur. 
Formally, we say that an event E is practically impossible if Skeptic, beginning 
with some finite positive capital, has a strategy that guarantees that 
0 his capital does not become negative (he does not go bankrupt), and 
0 if E happens, his capital increases without bound (he becomes infinitely rich). 
We say that an event E is practically certain, or that it happens almost surely, if 
its complement E“ is practically impossible. It follows immediately from these 
definitions that a practically impossible event has upper probability (and hence also 
lower probability) zero, and that a practically certain event has lower probability (and 
hence also upper probability) one (38.3). 
The size of Skeptic’s initial capital does not matter in the definitions of practical 
certainty and practical impossibility, provided it is positive. If the strategy P will do 
what is required when his initial capital is a, then the strategy $P will accomplish the 
same trick when his initial capital is b. Requiring that Skeptic’s capital not become 
negative is equivalent to forbidding him to borrow money, because if he dared to 
gamble on borrowed money, World could force his capital to become negative. 
The real condition, however, is not that he never borrow but that his borrowing be 
bounded. Managing on initial capital a together with borrowing limited to b is the 
same as managing on initial capital a + b. 
As we show in Chapters 3, 4, and 5, these definitions allow us to state and prove 
game-theoretic versions of the classical strong limit theorems-the 
strong law of 
large numbers and the law of the iterated logarithm. In its simplest form, the game- 
theoretic strong law of large numbers says that when Skeptic is offered even odds 

18 
CHAPTER 1: PROBABILITY AND FINANCE AS A GAME 
on each of an infinite sequence of events, the fraction of the events that happen will 
almost certainly converge to 1/2. The law of the iterated logarithm gives the best 
possible bound on the rate of convergence. 
Beyond Frequencies 
As we explain in some detail in Chapter 2, the law of large numbers, together with the 
empiricist philosophy of the time, led in the nineteenth and early twentieth centuries 
to a widespread conviction that the theory of probability should be founded on the 
concept of relative frequency. If many independent trials are made of an event with 
probability p ,  then the law of large numbers says that the event will happen p of the 
time and fail 1 - p of the time. This is true whether we consider all the trials, or 
only every other trial, or only some other subsequence selected in advance. And this 
appears to be the principal empirical meaning of probability. So why not turn the 
theory around, as Richard von Mises proposed in the 1920s, and say that a probability 
is merely a relative frequency that is invariant under selection of subsequences? 
As it turned out, von Mises was mistaken to emphasize frequency to the exclusion 
of other statistical regularities. The predictions about a sequence of events made 
by probability theory do not all follow from the invariant convergence of relative 
frequency. In the late 1930s, Jean Ville pointed out a very salient and decisive 
example: the predictions that the law of the iterated logarithm makes about the rate 
and oscillation of the convergence. Von Mises’s theory has now been superseded 
by the theory of algorithmic complexity, which is concerned with the properties of 
sequences whose complexity makes them difficult to predict, and invariant relative 
frequency is only one of many such properties. 
Frequency has also greatly receded in prominence within measure-theoretic prob- 
ability. Where independent identically distributed random variables were once the 
central object of study, we now study stochastic processes in which the probabilities 
of events depend on preceding outcomes in complex ways. These models sometimes 
make predictions about frequencies, but instead of relating a frequency to a single 
probability, they may predict that a frequency will approximate the average of a se- 
quence of probabilities. In general, emphasis has shifted from sums of independent 
random variables to martingales. 
For some decades, it has been clear to mathematical probabilists that martingales 
are fundamental to their subject. Martingales remain, however, only an advanced 
topic in measure-theoretic probability theory. Our game-theoretic framework puts 
what is fundamental at the beginning. Martingales come at the beginning, because 
they are the capital processes for Skeptic. The fundamental interpretative hypothesis, 
applied to a particular nonnegative martingale, says that the world will behave in such 
a way that the martingale remains bounded. And the many predictions that follow 
include the convergence of relative frequencies. 

1.4: THE MANY INTERPRETATIONS OF PROBABILITY 
19 
1.4 THE MANY INTERPRETATIONS OF PROBABILITY 
Contemporary philosophical discussions often divide probabilities into two broad 
classes: 
0 objective probabilities, which describe frequencies and other regularities in the 
world, and 
0 subjective probabilities, which describe a person’s preferences, real or hypo- 
thetical, in risk taking. 
Our game-theoretic framework accommodates both kinds of probabilities and en- 
riches our understanding of them, while opening up other possibilities as well. 
Three Major Interpretations 
From our point of view, it makes sense to distinguish three major ways of using the 
idea of a probability game, which differ in how prices are established and in the role 
of the fundamental interpretative hypothesis, as indicated in Table 1.4. 
Games of statistical regularity express the objective conception of probability 
within our framework. In a game of statistical regularity, the gambles offered to 
Skeptic may derive from a scientific theory, from frequencies observed in the past, or 
from some relatively poorly understood forecasting method. Whatever the source, we 
adopt the fundamental interpretative hypothesis, and this makes statistical regularity 
the ultimate authority: the prices and probabilities determined by the gambles offered 
to Skeptic must be validated by experience. We expect events assigned small upper 
probabilities not to happen, and we expect prices to be reflected in average values. 
Games of belief bring the neosubjectivist conception of probability into our frame- 
work. A game of belief may draw on scientific theories or statistical regularities to 
determine the gambles offered on individual rounds. But the presence of these gam- 
bles in the game derives from some individual’s commitment to use them to rank and 
choose among risks. The individual does not adopt the fundamental interpretative 
Table 1.4 Three classes of probability games. 
Authority for 
the Prices 
Interpretative Hypothesis 
Role of the Fundamental 
Adopted 
Games of Statistical 
Statistical 
Regularity 
regularities 
Games of Belief 
Personal choices 
among risks 
Not adopted 
Market Games 
Optional 
Market for 
financial securities 

20 
CHAPTER 1: PROBABILITY AND FINANCE AS A GAME 
hypothesis, and so his prices cannot be falsified by what actually happens. The upper 
and lower prices and probabilities in the game are not the individual’s hypotheses 
about what will happen; they merely indicate the risks he will take. A low probability 
does not mean the individual thinks an event will not happen; it merely means he is 
willing to bet heavily against it. 
Market games are distinguished by the source of their prices: these prices are 
determined by supply and demand in some market. We may or may not adopt the 
hypothesis that the market is efficient. If we do adopt it, then we may test it or use it 
to draw various conclusions (see, e.g., the discussion of the Iowa Electronic Markets 
on p. 71). If we do not adopt it, even provisionally, then the game can still be useful 
as a framework for understanding the hedging of market risks. 
Our understanding of objective and subjective probability in terms of probability 
games differs from the usual explanations of these concepts in its emphasis on sequen- 
tial experience. Objective probability is often understood in terms of a population, 
whose members are not necessarily examined in sequence, and most expositions of 
subjective probability emphasize the coherence of one’s belief about different events 
without regard to how those events might be arranged in time. But we do experi- 
ence the world through time, and so the game-theoretic framework offers valuable 
insights for both the objective and the subjective conceptions. Objective probabili- 
ties can only be tested over time, and the idea of a probability game imposes itself 
whenever we want to understand the testing process. The experience anticipated by 
subjective probabilities must also be arrayed in time, and probability games are the 
natural framework in which to understand how subjective probabilities change as that 
experience unfolds. 
Looking at Interpretations in Two Dimensions 
The uses and interpretations of probability are actually very diverse-so 
much so that 
we expect most readers to be uncomfortable with the standard dichotomy between 
objective and subjective probability and with the equally restrictive categories of 
Table 1.4. A more flexible categorization of the diverse possibilities for using the 
mathematical idea of a probability game can be developed by distinguishing uses 
along two dimensions: (1) the source of the prices, and (2) the attitude taken towards 
the fundamental interpretative hypothesis. This is illustrated in Figure 1.6. 
We use quantum mechanics as an example of a scientific theory for which the 
fundamental interpretative hypothesis is well supported. From a measure-theoretic 
point of view, quantum mechanics is sometimes seen as anomalous, because of the 
influence exercised on its probabilistic predictions by the selection of measurements 
by observers, and because its various potential predictions, before a measurement 
is selected, do not find simple expression in terms of a single probability measure. 
From our game-theoretic point of view, however, these features are prototypical rather 
than anomalous. No scientific theory can support probabilistic predictions without 
protocols for the interface between the phenomenon being predicted and the various 
observers, controllers, and other external agents who work to bring and keep the 
phenomenon into relation with the theory. 

1.4: THE MANY INTERPRETATIONS OF PROBABILITY 
21 
Personal 
Choices 
Scientific 
Theory 
SOURCE OF 
THE 
Observed 
Regularities 
Neosubjective 
Decision analysis 
probability 
Weather forecasting 
Quantum 
mechanics 
Hypothesis 
Statistical modeling 
testing 
and estimation 
Testing 
Inference based 
the EMH 
on the EMH 
Market 
Hedging 
~~ 
~ 
Well 
Supported 
STATUS OF THE FUNDAMENTAL INTERPRETATIVE 
HYPOTHESIS 
Believed 
Irrelevant 
Working 
Hypothesis 
Fig. 7.6 Some typical ways of using and interpreting a probability game, arrayed in two 
dimensions. (Here EMH is an acronym for the efficient-market hypothesis.) 
Statistical modeling, testing, and estimation, as practiced across the natural and 
social sciences, is represented in Figure 1.6 in the row labeled “observed regularities”. 
We speak of regularities rather than frequencies because the empirical information 
on which statistical models are based is usually too complex to be summarized by 
frequencies across identical or exchangeable circumstances. 
As we have already noted, the fundamental interpretative hypothesis is irrelevant 
to the neosubjectivist conception of probability, because a person has no obligation 
to take any stance concerning whether his or her subjective probabilities and prices 
satisfy the hypothesis. On the other hand, an individual might conjecture that his or 
her probabilities and prices do satisfy the hypothesis, with confidence ranging from 
“working hypothesis” to “well supported”. The probabilities used in decision analysis 
and weather forecasting can fall anywhere in this range. We must also consider 
another dimension, not indicated in the figure: With respect to whose knowledge is 
the fundamental interpretative hypothesis asserted? An individual might peers odds 
that he or she is not willing to offer to more knowledgeable observers. 
Finally, the bottom row of Figure 1.6 lists some uses of probability games in 
finance, a topic to which we will turn shortly. 
Folk Stochasticism 
In our listing of different ways probability theory can be used, we have not talked 
about using it to study stochastic mechanisms that generate phenomena in the world. 
Although quite popular, this way of talking is not encouraged by our framework. 
What is a stochastic mechanism? What does it mean to suppose that a phe- 
nomenon, say the weather at a particular time and place, is generated by chance 

22 
CHAPTER 1: PROBABILITY AND FINANCE AS A GAME 
according to a particular probability measure‘? Scientists and statisticians who use 
probability theory often answer this question with a self-consciously outlandish 
metaphor: A demigod tosses a coin or draws from a deck of cards to decide what the 
weather will be, and our job is to discover the bias of the coin or the proportions of 
different types of cards in the deck (see, e.g., [23], p. 5). 
In Realism and the Aim ofscience, Karl Popper argued that objective probabilities 
should be understood as the propensities of certain physical systems to produce certain 
results. Research workers who speak of stochastic mechanisms sometimes appeal to 
the philosophical literature on propensities, but more often they simply assume that 
the measure-theoretic framework authorizes their way of talking. It authorizes us to 
use probability measures to model the world, and what can a probability measure 
model other than a stochastic mechanism-something 
like a roulette wheel that 
produces random results? 
The idea of a probability game encourages a somewhat different understanding. 
Because the player who determines the outcome in a probability game does not 
necessarily do so by tossing a coin or drawing a card, we can get started without a 
complete probability measure, such as might be defined by a biased coin or a deck 
of cards. So we can accommodate the idea that the phenomenon we are modeling 
might have only limited regularities, which permit the pricing of only some of its 
uncertainties. 
The metaphor in which the flow of events is determined by chance drives statis- 
ticians to hypothesize full probability measures for the phenomena they study and 
to make these measures yet more extensive and complicated whenever their details 
are contradicted by empirical data. In contrast, our metaphor, in which outcomes 
are determined arbitrarily within constraints imposed by certain prices, encourages a 
minimalist philosophy. We may put forward only prices we consider well justified, 
and we may react to empirical refutation by withdrawing some of these prices rather 
than adding more. 
We do, however, use some of the language associated with the folk stochasticism 
we otherwise avoid. For example, we sometimes say that a phenomenon is governed 
by a probability measure or by some more restrained set of prices. This works in our 
framework, because government only sets limits or general directions; it does not 
determine all details. In our games, Reality is governed in this sense by the prices 
announced by Forecaster: these prices set boundaries that Reality must respect in 
order to avoid allowing Skeptic to become rich. In Chapter 14 we explain what it 
means for Reality to be governed in this sense by a stochastic differential equation. 
1.5 GAME-THEORETIC PROBABILITY IN FINANCE 
Our study of finance theory in Part I1 is a case study of our minimalist philosophy of 
proba “‘ty modeling. Finance is a particularly promising field for such a case study, 
because it starts with a copious supply of prices-market 
prices for stocks, bonds, 
futures, and other financial securities-with 
which we may be able to do something 
without hypothesizing additional prices based on observed regularities or theory. 

7.5: GAME-THEORETIC PROBABILITY IN FINANCE 
23 
We explore two distinct paths. The path along which we spend the most time takes 
us into the pricing of options. Along the other path, we investigate the hypothesis 
that market prices are efficient, in the sense that an investor cannot become very rich 
relative to the market without risking bankruptcy. This hypothesis is widely used in 
the existing literature, but always in combination with stochastic assumptions. We 
show that these assumptions are not always needed. For example, we show that 
market efficiency alone can justify the zdvice to hold the market portfolio. 
We conclude this introductory chapter with a brief preview of our approach to 
option pricing and with some comments about how our framework handles continuous 
time. A more extensive introduction to Part I1 is provided by Chapter 9. 
The Difficulty in Pricing Options 
The worldwide market in derivative financial securities has grown explosively in 
recent years. The total nominal value of transactions in this market now exceeds 
the total value of the goods and services the world produces. Many of these trans- 
actions are in organized exchanges, where prices for standardized derivatives are 
determined by supply and demand. A larger volume of transactions, however, is in 
over-the-counter derivatives, purchased directly by individuals and corporations from 
investment banks and other financial intermediaries. These transactions typically in- 
volve hedging by both parties. The individual or corporation buys the derivative (a 
future payoff that depends, for example, on future stock or bond prices or on future 
interest or currency exchange rates) in order to hedge a risk arising in the course 
of their business. The issuer of the derivative, say an investment banker, buys and 
sells other financial instruments in order to hedge the risk acquired by selling the 
derivative. The cost of the banker’s hedging determines the price of the derivative. 
The bulk of the derivatives business is in futures, forwards, and swaps, whose 
payoffs depend linearly on the future market value of existing securities or currencies. 
These derivatives are usually hedged without considerations of probability [ 1541. But 
there is also a substantial market in options, whose payoffs depend nonlinearly on 
future prices. An option must be hedged dynamically, over the period leading up to 
its maturity, and according to established theory, the success of such hedging depends 
on stochastic assumptions. (See [128], p. xii, for some recent statistics on the total 
sales of different types of derivatives.) 
For readers not yet familiar with options, the artificial examples in Figure 1.7 may 
be helpful. In both examples, we consider a stock that today sells for $8 a share and 
tomorrow will either (1) go down in price to $5, (2) go up in price to $10, or (3) 
(in Example 2) stay unchanged in price. Suppose you want to purchase an option to 
buy 50 shares tomorrow at today’s price of $8. If you buy this option and the price 
goes up, you will buy the stock at $8 and resell it at $10, netting $2 per share, or 
$100. What price should you pay today for the option? What is the value today of a 
payoff 2 that takes the value $100 if the price of the stock goes up and the value $0 
otherwise? As explained in the caption to the figure, z is worth $60 in Example 1, for 
this price can be hedged exactly. In Example 2, however, no price for x can be hedged 
exactly. The option in Example 1 can be priced because its payoff is actually a linear 

24 
CHAPTER 7: PROBABlLlTY AND FlNANCE AS A GAME 
Tomorrow’s 
Tomorrow’s 
$5 
$0 
,, $5 
Today’s 
share price 
Today’s 
share price 
share price 
$0 
share price 
~ 
$8 - 
~ 
$8 <-.- 
~- 
~ 
$8 
$0 
. $10 
$100 
-- $10 
$100 
. . 
Example 1 
Example 2 
Fig. 7.7 The price of a share is now $8. In Example 1, we assume that it will go up to $10 
or down to $5 tomorrow. In Example 2, its price is also permitted to stay unchanged. In both 
cases, we are interested in the value today of the derivative 2 .  In Example 1, z has a definite 
value: IE z = $60. This price for z can be hedged exactly by buying 20 shares of the stock. If 
the stock down from $8 to $5, the loss of $3 per share wipes out the $60, but if it goes up to 
$10, the gain of $2 per share is just enough to provide the additional $40 needed to provide x’s 
$100 payoff. In Example 2, no price for 2 can be hedged exactly. Instead we have Ez = $60 
and 
= $0. We should emphasize again that both examples are unrealistic. In a real 
financial market there is a whole range of possibilities-not 
just two or three possibilities-for 
how the price of a security can change over a single trading period. 
function of the stock price. When there are only two possible values for a stock price, 
any function of that price is linear and hence can be hedged. In Example 2, where 
the stock price has three possible values, the payoff of the option is nonlinear. In 
real stock markets, there is a whole range of possible values for the price of a stock 
at some future time, and hence there are many nonlinear derivatives that cannot be 
priced by hedging in the stock itself without additional assumptions. 
A range of possible values can be obtained by a sequence of binary branchings. 
This fact can be combined with the idea of dynamic hedging, as in Figure 1.8, to 
provide a misleadingly simple solution to our problem. The solution is so simple that 
we might be tempted to believe in some imaginary shadow market, speedier and more 
liquid than the real market, where changes in stock prices really are binary but produce 
the less restricted changes seen in the slower moving real market. Unfortunately, there 
is no traction in this idea, for we can hedge only in real markets. In real stock markets, 
many different price changes are possible over the time periods during which we hold 
stock, and so we can never hedge exactly. The best we can do is hedge in a way that 
works on average, counting on the errors to average out. This is why probabilistic 
assumptions are needed. 
The probabilistic models most widely used for option pricing are usually formu- 
lated, for mathematical tractability, in continuous time. These models include the 
celebrated Black-Scholes model, as well as models that permit jumps. As it turns 
out, binomial trees, although unrealistic as models of the market, can serve as com- 
putationally useful approximations to these widely used (although perhaps equally 
unrealistic, alas) continuous-time models. This point, first demonstrated in the late 
1970s [66,67, 2561, has made binomial trees a standard topic in textbooks on option 
pricing. 

1.5: GAME-THEORETIC PROBABILITY IN FINANCE 
25 
Tomorrow’s 
closing 
X 
Price at 
mice 
$0 
tomorrow 
$7 
, 
$5 
Today’s 
noon 
, 
, 
. . 
, 
price 
.- 
$8 
$0 
, 
$8 -=,” 
. 
$10 
$100 
. 
‘ 
r S 9 d - r  
Fig, 7.8 In this example, Ez = $25. To hedge this price, we first buy 25 shares of the stock 
today. We adjust this hedge at noon tomorrow, either by selling the 25 shares (if the price has 
gone down to $7) or by buying another 25 shares (if the price has gone up to $8). 
Making More Use of the Market 
The most common probability model for option pricing in continuous time, the Black- 
Scholes model, assumes that the underlying stock price follows a geometric Brownian 
motion. Under this assumption, options can be priced by a formula-the 
Black- 
Scholes formula-that 
contains a parameter representing the volatility of the stock 
price; the value of this parameter is usually estimated from past fluctuations. The 
assumption of geometric Brownian motion can be interpreted from our thoroughly 
game-theoretic point of view (Chapter 14). But if we are willing to make more use 
of the market, we can instead eliminate it (Chapters 10-13). The simplest options 
on some stocks now trade in sufficient volume that their prices are determined by 
supply and demand rather than by the Black-Scholes formula. We propose to rely 
on this trend, by having the market itself price one type of option, with a range of 
maturity dates. If this traded option pays a smooth and strictly convex function of the 
stock price at maturity, then other derivatives can be priced using the Black-Scholes 
formula, provided that we reinterpret the parameter in the formula and determine its 
value from the price of the traded option. Instead of assuming that the prices of the 
stock and the traded option are governed by some stochastic model, we assume only 
certain limits on the fluctuation of these prices. Our market approach also extends to 
the Poisson model forjumps (512.3). 
Probability Games in Continuous Time 
Our discussion of option pricing in Part I1 involves an issue that is important both 
for our treatment of probability and for our treatment of finance: how can the game- 
theoretic framework accommodate continuous time? Measure theory’s claim to 
serve as a foundation for probability has been based in part on its ability to deal with 
continuous time. In order to compete as a mathematical theory, our game-theoretic 
framework must also meet this challenge. 
It is not immediately clear how to make sense of the idea of a game in which two 
players alternate moves continuously. A real number does not have an immediate 

26 
CHAPTER 1: PROBABILITY AND FINANCE AS A GAME 
predecessor or an immediate successor, and hence we cannot divide a continuum of 
time into points where Skeptic moves and immediately following points where World 
moves. Fortunately, we now have at our disposal a rigorous approach to continuous 
mathematics-nonstandard 
analysis-that 
does allow us to think of continuous time 
as being composed of discrete infinitesimal steps, each with an immediate prede- 
cessor and an immediate successor. First introduced by Abraham Robinson in the 
1960s, long after the measure-theoretic framework for probability was established, 
nonstandard analysis is still unfamiliar and even intimidating for many applied math- 
ematicians. But it provides a ready framework for putting our probability games into 
continuous time, with the great advantage that it allows a very clear understanding 
of how the infinite depends on the finite. 
In Chapter 10, where we introduce our market approach to pricing options, we 
work in discrete time, just as real hedging does. Instead of obtaining an exact price 
for an option, we obtain upper and lower prices, both approximated by an expression 
similar to the familiar Black-Scholes formula. The accuracy of the approximation 
can be bounded in terms of the jaggedness of the market prices of the underlying 
security and the traded derivative. All this is very realistic but also unattractive and 
hard to follow because the approximations are crude, messy, and often arbitrary. In 
Chapter 11, we give a nonstandard version of the same theory. The nonstandard 
version, as it turns out, is simple and transparent. Moreover, the nonstandard version 
clearly says nothing that is not already in the discrete version, because it follows 
from the discrete version by the transfer principle, a general principle of nonstan- 
dard analysis that sometimes allows one to move between nonstandard and standard 
statements 11361. 
Some readers will see the need to appeal to nonstandard analysis as a shortcoming 
of our framework. There are unexpected benefits, however, in the clarity with which 
the transfer principle allows us to analyze the relation between discrete-time and 
continuous-time results. Although the discrete theory of Chapter 10 is very crude, 
its ability to calibrate the practical accuracy of our new purely game-theoretic Black- 
Scholes method goes well beyond what has been achieved by discrete-time analyses 
of the stochastic Black-Scholes method. 
After introducing our approach to continuous time in Chapter 11, we use it to 
elaborate and extend our methods for option pricing (Chapters 12-13) and to give a 
general game-theoretic account of diffusion processes (Chapter 14), without working 
through corresponding discrete theory. This is appropriate, because the discrete 
theory will depend on the details of particular problems where the ideas are put to 
use. Discrete theory should be developed, however, in conjunction with any effort to 
put these ideas into practice. In our view, discrete theory should always be developed 
when continuous-time models are used, so that the accuracy of the continuous-time 
results can be studied quantitatively. 

Part I 
Probability without 
Measure 
We turn now to consider what our game-theoretic framework does for probability. 
In Chapter 2, we show how it accommodates and extends the various viewpoints on 
the foundations and meaning of probability that have developed over the past three 
centuries. In Chapters 3-5, we formulate and prove game-theoretic versions of the 
classical strong limit theorems-the 
strong law of large numbers and the law of the 
iterated logarithm. In Chapters 6 and 7 we do the same for the classical weak limit 
theorems-the 
weak law of large numbers and the central limit theorem. 
Our historical review in Chapter 2 ranges from Pascal and Fermat in the seven- 
teenth century to von Mises, Kolmogorov, and de Finetti in the twentieth century. 
We emphasize the emergence of measure theory as a foundation for probability, 
Kolmogorov’s explanation of how measure-theoretic probability can be related to 
the world, and the development of the hypothesis of the impossibility of a gambling 
system. This review reveals that our framework combines elements used in the past 
by a variety of authors, whose viewpoints are often seen as sharply divergent. The 
keys to this catholicity are (1) our sharp distinction between the idea of pricing by 
hedging and the hypothesis of the impossibility of a gambling strategy and (2) our 
flexibility with regard to the latter. 
Using the simple case of bounded variables, Chapter 3 paints a reasonably full 
picture of how the game-theoretic framework handles strong laws. Chapter 4, which 
deals with Kolmogorov’s strong law, and Chapter 5, which deals with the law of the 
iterated logarithm, confirm that the approach extends to more challenging examples. 
Chapter 6 introduces our approach to the weak laws. In this chapter, we prove 
the central limit theorem for the simplest example: the fair coin. This simple setting 
permits a clear view of the martingale method of proof that we use repeatedly in 
later chapters, for central limit theorems and for option pricing. The method begins 
with a conjectured price as a function of time and an underlying process, verifies 
Probability and Finance: It’s Only a Game! Glenn Shafer, Vladimir Vovk 
Copyright 0 2001 John Wiley & Sons, Inc. 
ISBN: 0-471-40226-5 

28 
PART I: PROBABILITY WITHOUT MEASURE 
that the conjectured price satisfies a parabolic partial differential equation (the heat 
equation for the central limit theorem; most commonly the Black-Scholes equation 
for option pricing), expands the conjectured price in a Taplor’s series, and uses the 
differential equation to eliminate some of the leading terms of the Taylor’s series, so 
that the remaining leading terms reveal the price to be an approximate martingale as 
a function of time. 
When we toss a fair coin, coding heads as 1 and tails as -1, we know exactly 
how far the result of each toss will fall from the average value of 0. We can relax 
this certainty about the magnitude of each deviation by demanding only a variance 
for each deviation-a 
price for its square-and 
still prove a central limit theorem. At 
the end of Chapter 6, we show that something can be done with even less: we can 
obtain interesting upper prices for the size of the average deviation beginning only 
with upper bounds for each deviation. This idea leads us into parabolic potential 
theory-the 
same mathematics we will use in Part I1 to price American options. 
Chapter 6 is the most essential chapter in Part I for readers primarily interested 
in Part 11. Those who seek a fuller understanding of the game-theoretic central limit 
theorem will also be interested in Chapter 7, where we formulate and prove a game- 
theoretic version of Lindeberg’s central limit theorem. This theorem is more abstract 
than the main theorems of the preceding chapters; it is a statement about an arbitrary 
martingale in a symmetric probability game. 
In Chapter 8, we step back and take a broader look at our framework. We verify 
that the game-theoretic results derived in Chapters 3 through 7 imply their measure- 
theoretic counterparts, we compare the game-theoretic and measure-theoretic frame- 
works as generalizations of coin tossing, and we review some general properties of 
game-theoretic probability. 

The Game-Theoretic 
Framework in Historical 
Context 
The mathematical and philosophical foundations of probability have been debated 
ever since Blaise Pascal and Pierre de Fermat exchanged their letters in the seven- 
teenth century. Different authors have shown how probability can be understood in 
terms of price, belief, frequency, measure, and algorithmic complexity. In this chap- 
ter, we review the historical development of these different ways of understanding 
probability, with a view to placing our own framework in historical context. 
We begin with Pascal and Fermat’s discussion of the problem of points and the 
subsequent development of their ideas into a theory unifying the belief and frequency 
aspects of probability. We then recount the emergence of measure theory and review 
Andrei Kolmogorov’s definitive formulation of the measure-theoretic framework. 
After listing Kolmogorov’s axioms and definitions, we compare his explanation of 
how they are to be used in practice with the earlier thinking of Antoine Augustin 
Cournot and the later attitudes of Joseph L. Doob and other mathematical proba- 
bilists. We then review Richard von Mises’s collectives, Kolmogorov’s algorithmic 
complexity, Jean Ville’s martingales, A. Philip Dawid’s prequential principle, and 
Bruno de Finetti’s neosubjectivism. We also examine the history of the idea of the 
impossibility of a gambling system. 
The authors whose work we review in this chapter often disagreed sharply with 
each other, but the game-theoretic framework borrows from them all. Our dual 
emphasis on the coherence of pricing and the hypothesis of the impossibility of a 
gambling system is in a tradition that goes back to Cournot, and our placement of 
the hypothesis of the impossibility of a gambling system outside the mathematics 
of probability, in an interpretative role, makes our viewpoint remarkably compatible 
with both subjective and objective interpretations of probability. 
29 
Probability and Finance: It’s Only a Game! Glenn Shafer, Vladimir Vovk 
Copyright 0 2001 John Wiley & Sons, Inc. 
ISBN: 0-471-40226-5 
Probability and Finance: It’s Only a Game! Glenn Shafer, Vladimir Vovk 
Copyright 0 2001 John Wiley & Sons, Inc. 
ISBN: 0-471-40226-5 

30 
CHAPTER 2: THE HISTORICAL CONTEXT 
2.1 PROBABILITY BEFORE KOLMOGOROV 
Our story about the foundations of probability before Kolmogorov begins with Pascal 
and Fermat, extends through the invention of probability by Jacob Bernoulli, and 
locates the beginnings of measure theory's dominance in the late nineteenth century. 
The Precursors: Pascal and Fermat 
The beginning of mathematical 
probability is often dated from 
the correspondence in the sum- 
mer of 1654 between two French 
mathematicians, 
the Parisian 
Blaise Pascal and the Toulou- 
sian Pierre de Fermat. One of 
the problems they discussed was 
the problem of points--the prob- 
lem of dividing the stakes when 
a game is cut short before any 
of the players has enough points 
to win. Figure 2.1 poses a very 
simple example of the problem. 
Here the stakes total $100, and 
there are only two players, Peter 
and Paul, who lack one and two 
points, respectively. If play must 
be halted and the stakes divided, 
how much should Peter get and 
how much should Paul get? 
Blaise Pascal (1623-1662), 
as imagined by the 
began with the princi- 
nineteenth-century artist Hippolyte Flandrin. 
ple that it is fair for two players 
to contend on equal terms. Equal 
terms means, interalia, that the players make the same contribution to the total stakes. 
If Paul contributes $a, 
his opponent Peter must also contribute $a, 
and so the total 
stakes, which go to the winner, will be $2~2. Thus it is fair for Paul to pay $a for an 
Fig. 2.1 Paul wins $100 if he wins both of the next two rounds 
Peter 
$0 
~ 
$? ._ 
Peter , $0 
Paul . -. 
~ . 
~ 
~ . 
Paul' 
$100 

2.7: PROBABILITY BEFORE KOLMOGOROV 
31 
__, 
bi 
, 
hl + b2 ,, 
-< 
. 
. 
. 
1 
2 
= 
_, 
$0 
$a 
<'. 
By combination 
. $2a 
with a sure thing 
b2 
Fig. 2.2 Contending on equal terms. 
opportunity to get $ 2 ~  
if he defeats Peter and $0 if he loses to Peter, as indicated on 
the left of Figure 2.2. 
Suppose now that we propose to Paul that he receive b2 if he defeats Peter and bl 
if he loses to Peter, where bl < b2. What price can we fairly charge Paul for this 
opportunity? Pascal answered this question by recognizing that the payoff can be 
reproduced by combining two payoffs whose fair price is already established: 
0 Paul gets bl no matter what happens. It is surely fair to charge Paul bl for this. 
0 In addition, Paul gets b2 - bl if he defeats Peter and 0 if he loses to him. By 
the preceding argument, it is fair to charge Paul ( b ~  
- b1)/2 for this. 
So the fair price to charge Paul is bl + (bz - b1)/2, or (bl + b2)/2, as indicated on 
the right of Figure 2.2. 
Once the price (bl + b2)/2 is established, we can solve the problem of points 
recursively. Figure 2.3 displays the solution for the example of Figure 2.1. If Paul 
wins the first round, he will be on even terms with Peter, and so his position will be 
worth $50. So his present position, where he is contending for $0 or $50, is worth 
$25. 
In a pamphlet he published in 1657 to explain Pascal and Fermat's ideas, the 
Dutch mathematician Christiaan Huygens (1629-1 695) slightly simplified Pascal's 
justification for the price (bl + b2)/2. As Huygens pointed out, the players would 
be contending on equal terms if both paid this much, with the understanding that the 
winner would get b2 and the loser would get bl . 
In his response to Pascal, Fermat proposed an alternative combinatorial method. 
Imagine, he said, that the players continue for fixed number of rounds even if one 
player gains enough points to win before the last round is played, and count the 
number of combinations that favor each player. Because each combination has an 
Fig. 2.3 Paul's present position is worth $25. 
Peter _,- 
$0 
_,,, 
$50 <., 
PauT"- 
Peter 
$0 
.. 
,/-I- 
$25 -,-I:_- 
-._ 
Paul'-' 
$100 

32 
CHAPTER 2: THE HlSTORlCAL CONTEXT 
equal chance of happening, the stakes should be divided in this proportion. In our 
example, there are four combinations: 
Peter wins the first round; Peter wins the second. 
Peter wins the first round; Paul wins the second. 
Paul wins the first round; Peter wins the second. 
Paul wins the first round; Paul wins the second. 
The first three win the game for Peter, and only the fourth wins the game for Paul. 
So Peter should get $75 and Paul should get $25. 
Pascal acknowledged the validity of the combinatorial method, and his Trait6 du 
triangle arithme‘tique, which he shared with Fermat, was as concerned with combi- 
nations as with games of chance. Subsequent authors, including Jacob Bernoulli, 
Abraham De Moivre, Pierre de Montmort, and Nicholas Bernoulli, freely used both 
Fermat’s method (the enumeration of combinations) and Pascal’s method (recursive 
determination of fair price) to find odds in games of chance. In time, the combinatorial 
method came to be seen as more fundamental. 
In retrospect, the combinatorial method can be seen as a precursor of measure- 
theoretic probability, just as Pascal’s method can be seen as a precursor of our 
framework. Moreover, we share the eclectic attitude of the early authors: each 
approach has its advantages in different problems. Although we believe that our 
game-theoretic framework provides the best general understanding of probability, we 
have no desire to give up the mathematical tools that have developed within measure 
theory over the past century, and we believe that measure theory is more helpful than 
game theory for many problems and topics in probability. The basic ideas of ergodic 
theory, for example, seem to be essentially measure-theoretic. 
The best account of the work of Pascal is provided by A. W. F. Edwards; see 
also [ 143, 280, 3031. English translations of the letters between Pascal and Fermat 
are provided in [79] and [290]; the originals can be found in their respective collected 
works. Huygens’s pamphlet on games of chance was originally published in Latin 
and then in Dutch. The Dutch version, accompanied by a French translation, is in his 
collected works, along with his other writings on probability. The Latin version was 
reproduced in Jacob Bernoulli’s Ars Conjectandi. Early English translations were 
published by Arbuthnot and Browne. 
Belief and Frequency 
Pascal was not insensitive to the ambition of applying his ideas about games of chance 
to larger issues. He made a famous argument for wagering on the existence of God, 
and the Port Royal Logic, written by his friends at the Port Royal convent, argued for 
apportioning belief to the frequency with which events happen [8, 1411. But it was 
left to Jacob Bernoulli to clarify how price can serve as a foundation for numerical 
probability and how belief and frequency can be united in this concept. 
As Bernoulli explained in his Ars Conjectandi, published posthumously in 1713, 
a numerical probability is a degree of certainty, which can be merited by an argument 
just as a share of the stakes in a game of chance can be merited by a position in that 

2.1: PROBABILITY BEFORE KOLMOGOROV 
33 
game. As a degree of certainty, probability is subjective. Any imperfect certainty 
must be subjective, for all things are known to God with complete certainty. On the 
other hand, a probability is not necessarily known to us. Sometimes we must make 
extensive observations in order to learn its magnitude, and in this respect it has an 
objective reality-a 
meaning that goes beyond any particular person’s opinion. This 
uneasy balance between the objective and the subjective is encapsulated in Bernoulli’s 
phrase “equally possible”, which played an important role in his work and remained 
central to the foundations of probability for two centuries thereafter. We begin by 
counting the equally possible cases. The probability of an event is the proportion of 
these cases that favor it. 
Bernoulli’s greatest achievement was to represent within probability theory the 
idea that a probability can be learned from observation. Consider a game in which 
r of the equally possible cases lead to success and s to failure. Bernoulli’s theorem 
says that by playing sufficiently many rounds of the game, we can be as certain 
as we like that the numbers of successes and failures we observe, say y and z ,  
will be in approximately the same ratio as T and s. Christened the law of large 
numbers by Poisson, Bernoulli’s theorem is now usually formulated as a comparison 
of probability and frequency. If we write N for the total number of rounds played 
and p for the probability of success, so that N = y + z, p = r / ( r  + s), and the 
observed frequency of success is y/N, then the theorem says that for any E > 0 and 
6 > 0, 
p(I$ -pi < 5 )  > 1 - 6  
when N is sufficiently large, where E denotes the probability of E. This justifies 
the use of y/N as an estimate of p when we do not know r and s and hence cannot 
calculate p directly. Bernoulli derived an upper bound on how large the number of 
rounds N needs to be in order to estimate p with a given accuracy. He calculated, for 
example, that if p = 0.6, then 25,550 rounds is enough to make the odds at least a 
thousand to one that y/N will fall between 0.58 and 0.62 ([15], p. 239, [3], p. 14). 
In the 1730s, Abraham De Moivre (1667-1754) sharpened Bernoulli’s theorem 
by estimating (rather than merely bounding) how large N needs to be. As De Moivre 
showed, 
when N is large. By evaluating the integral in (2.2), we find that only 6,700 rounds 
(not 25,550) are needed in order to estimate p within 0.02 with thousand-to-one odds 
when p is actually equal to 0.6. 
Equal possibility, with all its internal tension between the subjective and the objec- 
tive, remained the starting point for the French mathematician Pierre Simon Laplace 
(1749-1 827). Laplace became the leading authority on mathematical probability by 
the 1770s, and his ThLorie analytique des probabilitLs remained authoritative for 
over half a century after his death [44, 189, 1911. Laplace shared Bernoulli’s sub- 
jectivism, not because he shared Bernoulli’s belief in God but because he shared his 
own era’s determinism: every event is objectively certain because it is determined by 

34 
CHAPTER 2: THE HISTORICAL CONTEXT 
the past and the laws of physics. Yet Laplace also shared Bernoulli’s interest in the 
empirical estimation of probabilities, and he created much of what we now recognize 
as mathematical statistics [295]. In particular, he generalized De Moivre’s theorem 
by showing that if zl, 
. . . , ZN are measurements resulting from N independent trials 
of an experiment, with expected value 1-1 and variance c2, then 
De Moivre’s theorem is the special case of (2.3) where 2, is equal to either one 
(success) or zero (failure), so that y = clL=l 
5,. Laplace’s proof is valid only for 
the case where 2, has only a finite number of possible values, but the result is an 
instance of what we now call the central limit theorem for independent identically 
distributed random variables (see !i7.4). 
Equally possible cases provide the simplest instance of measure theory. In this 
sense, measure theory was already the mathematical foundation for probability in the 
eighteenth and nineteenth centuries. But as the nineteenth century wore on, this foun- 
dation became increasingly untenable. It faced two philosophical problems. First, 
the traditional problem of God’s omniscience, now transformed into the problem of 
determinism. If God has foreseen what will happen, then how can a different outcome 
be possible? Or if the future can be predicted according to nature’s laws from the 
present, then how can a different future be possible? Second, the increasing demands 
of empiricism, which now required one to question the very ideas of possibility and 
probability. If equal possibility can be discerned only by observing equal frequency, 
then what is probability but mere frequency? 
Following Laplace’s death, his French successors began to speak of different 
kinds of probability. SimCon-Denis Poisson (178 1-1840) distinguished between 
subjective and objective probability. Antoine Augustin Cournot (1801-1 877) spoke 
ofprobability and chance. Whereas Laplace had explained determinism by imagining 
a superior intelligence who could observe the present fully and exactly and hence 
predict the future precisely according to nature’s laws, Cournot suggested that even 
an intelligence who observed everything and knew all the laws of nature would not be 
able to dispense with probability; chances are the probabilities that would be adopted 
by such an intelligence [58,59, 2221. 
Although Cournot’s understanding of objective probability is now attracting re- 
newed attention, it found little sympathy in the nineteenth century, which was in- 
creasingly concerned with the empirical grounding of our knowledge. This advanc- 
ing empiricism led to an equation between probability and frequency, especially in 
England, where it was articulated by John Venn (1834-1923) and John Stuart Mill 
(1 806- I 873). This equation could only discourage interest in mathematical probabil- 
ity, for it cast doubt on the basic theorems of probability, beginning with Bernoulli’s 
theorem. If probability is nothing but frequency, then there can be nothing but 
confusion in a complicated proof that the two are probably approximately equal. 
Serious mathematical work on probability slowed to a standstill with Laplace’s 
death, partly because he was too great and too difficult a giant to see past, but also 
N 

2.1: PROBABILITY BEFORE KOLMOGOROV 
35 
because his subjectivist defense of probability against determinism did not convince 
an empirical age. The reigning determinism of the nineteenth century, represented in 
France by Claude Bernard (1813-1 878) in the biological sciences and Auguste Comte 
(1798-1857) in the physical sciences, was resolutely uninterested in probability. 
This disinterest persisted even as the project of basing social science on statistical 
fact became increasingly popular [ 142, 2521. Social statisticians, like frequentist 
philosophers, agreed that probability is mere frequency and had little interest in any 
mathematical or philosophical theory of probability. 
A renewal of wide interest in probability came only near the end of the nineteenth 
century, as it began to appear that it could play a fundamental role in physics. 
Statistical physics began in the middle of the century, with the work of James Clerk 
Maxwell, Lord Kelvin, and Ludwig Boltzmann. At first, probability ideas played no 
greater role here than in social statistics; when physicists spoke of probabilities, they 
were thinking merely of frequencies over time. But as the subject developed, and 
especially as the philosophical conundrums of statistical thermodynamics emerged, 
the mathematics and philosophy of probability came to seem more and more relevant. 
People began to feel, as many still feel today, that statistical thermodynamics is 
confused about the relation between time averages and phase-state averages, and 
they began to hope that a clearer foundation for probability itself might bring clarity 
to this whole area of physics. When the German mathematician David Hilbert 
(1862-1943) listed the most important open problems in mathematics, at the second 
international congress of mathematicians at Paris in 1900, he named probability as one 
of the subdisciplines of physics whose axiomatic foundations needed investigation 
[139, 1521. Hilbert wanted a clearer and more rigorous treatment of what Jan von 
Plato [3 181 has called modern probability-probability 
for continuous quantities in 
continuous time. 
The strongest mathematical work in probability in the late nineteenth century 
was that of the Russian Pafnutii L. Chebyshev (1821-1894) and his student Andrei 
A. Markov (1856-1922). By the early twentieth century, interest in mathematical 
probability had revived in France, with the work of Henri PoincarC (1854-1912), 
a major figure in mathematical physics and the philosophy of science, Emile Bore1 
(1871-1956), a pioneer in measure theory, and Paul Ltvy (1886-1971), who pio- 
neered the study of dependent random variables. Other leaders included Francesco 
Cantelli (1887-1972) in Italy, Hugo Steinhaus (1875-1966) in Lviv, and Sergei 
Bernstein (1880-1968), who studied in Paris before starting his career in Kharkiv. 
The Advent of Measure Theory 
From the modern measure-theoretic point of view, the relevance of integration to 
probability theory is obvious. A variable is a function on a sample space, and 
the expected value of the variable is the integral of that function with respect to a 
probability measure on the sample space. But this is hindsight. In the nineteenth 
century, probability theory remained firmly anchored in the traditional framework 
of equally possible cases, and continuous probability was considered admissible 
only when it could be seen as a well-behaved extension of that framework. The 

36 
CHAPTER 2: THE HlSTORlCAL CONTEXT 
development of the theory of integration, iil contrast, was driven by the desire to 
integrate more and more badly behaved functions [ 15 1, 2461. Moreover, the theory 
of integration was concerned with functions of real or complex numbers, whereas 
probability was more abstract. It was only after the turn of the century, when the 
theory of measure and integration had been developed for abstract spaces, that it 
could be seen as a potential foundation for probability theory. 
Major milestones in the increasingly general and abstract understanding of mea- 
sure and integration were set by Bernhard Riemann, Camille Jordan, Emile Borel, 
Henri Lebesgue, Johann Radon, and Maurice FrCchet. In his Habilitutionsschrft of 
1854, Riemann developed the theory of integration for continuous functions in the 
modern sense-mappings 
from real numbers to real numbers not necessarily given by 
formulas. The Riemann integral is obtained as the limit of discrete approximations in 
which the domain of the function is divided into small intervals, rectangles, or other 
elementary sets, and the integral of the function over each elementary set is approx- 
imated from the volume of the elementary set and typical values of the function on 
the set. In 1892, Jordan reformulated Riemann’s theory of integration on the basis of 
a theory of measure in the domain of the function being integrated; the small sets in 
the domain used to approximate the integral, instead of being intervals or rectangles, 
might now be more complex sets, which could nevertheless be approximated by finite 
unions of intervals or rectangles. In 1898, Borel extended Jordan’s measure theory 
by using sets approximated by countably infinite rather than merely finite unions of 
elementary sets. Borel was concerned with the theory of complex analytic functions 
rather than the theory of integration. But his work inspired Lebesgue’s development, 
in 1901, of an entirely novel theory of integration. In Lebesgue’s theory, the sets 
going into an approximation of an integral are formed by grouping points together 
on the basis of the value of the function rather than their contiguity in the domain, 
thus liberating integration from any assumption about the continuity of the function. 
Lebesgue was still concerned with integration of functions on Euclidean spaces, but 
because his ideas required only a measure (not a topology) on the domain, others, 
including Radon in 1913 and FrCchet in 1915, soon extended his theory of measure 
and integration to more abstract spaces. 
In the 1890s, when the new measure theory was being developed, there was no felt 
need within probability for improved theories of integration. But the idea of measure 
zero was becoming more important for probability, and this made the new theories 
of measure and integration appear increasingly relevant. To understand the growing 
importance of measure zero in probability, we may begin with Henri PoincarC’s 
recurrence theorem of 1890. This theorem says that an isolated mechanical system 
consisting of three bodies will eventually return arbitrarily close to its initial state, 
provided only that this initial state is not exceptional. In order to make precise how 
few exceptional states there are, PoincarC proposed, as a convention, that we take the 
relative probability of two regions of phase space to be proportional to their volumes. 
He then showed that within any region of finite volume, the states for which the 
recurrence does not hold are contained in subregions whose volume is arbitrarily 
small, and hence these states have zero probability. This is the sense in which they 
are exceptional ([247], p. 71). The idea that an event could be possible but have 

2.1: PROBABILITY BEFORE KOLMOGOROV 
37 
zero probability was familiar to mathematicians from geometric probability: when 
we choose a point at random from a line segment or from a region of a higher- 
dimensional space, the probability of any particular point being chosen is zero, even 
though the choice is quite possible. But according to von Plato (1994, p. 90), 
PoincarC’s article on the three-body problem marks the first application of the idea 
of measure zero to a mechanical system. It was followed by many more. 
PoincarC’s assumption about the probabilities for the initial state of a mechani- 
cal system was, he said, a convention. He did not use the word carelessly. He is 
remembered for an influential philosophy of science that stressed the conventional 
nature of scientific laws. He considered even Newton’s law and Euclid’s axioms 
conventional inasmuch as they are deliberately chosen by scientists for their help- 
fulness in organizing our experience. Not all his contemporaries shared his broad 
conventionalism, but his fellow French mathematicians did tend to share his caution 
about the meaningfulness of continuous probability. 
Borel shared PoincarC’s cautious attitude 
towards continuous probability [ 164, 245, 
2701. For Borel, a concrete meaning could be 
given to the idea of choosing at random from 
a finite set and perhaps even from a denumer- 
able set, but because of the nonconstructive 
character of the totality of real numbers, no 
meaning could be given to choosing at ran- 
dom a real number from an interval or a point 
from a region of the plane. But in 1909, Borel 
published a celebrated article that brought con- 
tinuous measure theory into the very heart of 
probability. In this article, Borel investigated 
the behavior of the infinite sequence of suc- 
cesses and failures that would result were a 
game repeated indefinitely. Consider the sim- 
ple case where the probability of success on 
each round is 1/2 and the rounds are indepen- 
dent, and write yn for the number of successes 
in the first n rounds. Borel claimed that with 
probability one there will be a number N such 
that 
Emile Bore1 (1871-1956), minister of 
the French navy from 1925 to 1940. 
I? - 11 
ln(n/2) 
2 575T 
for all n larger than N .  Since limn+w ln(n/2)/d% = 0, this implies that 
. 
Yn 
1 
lim - = - 
n+m n 
2 
(2.4) 
(2.5) 
with probability one. The latter statement, generalized from the case where the 
probability on each round is 112 to the case of an arbitrary probability p ,  is now 

38 
CHAPTER 2: THE HISTORICAL CONTEXT 
called Borel’s strong law of large numbers. Bernoulli’s theorem has been demoted; 
it is now merely a weak law of large numbers. 
For the sake of historical accuracy, we hasten to add that Borel did not express his 
claim in the form (2.4). Instead, he asserted that there are sequences A, 
such that 
limn-+oo A,,/J71 = 0 and the number of successes in 2n trials is eventually bounded 
between 
n-Andn 
and 
n+A,Jn 
To fix ideas, he took A, 
to be Inn (Borel 1909, p. 259). When we replace A, 
by Inn 
and then 2n by n in (2.6), we obtain bounds equivalent to (2.4). There were gaps in 
Borel’s proof [104]; a complete proof was first given by Georg Faber (1877-1966) 
in 1910. Moreover, Borel did not investigate how slowly A, 
may grow and hence 
how tightly the frequency of successes can be bounded; this question was settled by 
Khinchin’s law of the iterated logarithm, which appeared in 1924 (see Chapter 5). 
Borel insisted on a constructive and ultimately finitary interpretation of his results. 
As he explained, they mean merely that as n increases, one may safely give indef- 
initely great odds that (2.4) will continue to hold no matter how much longer one 
continues to play. Yes, the relative frequency of successes converges to one-half with 
probability one. But this is only a manner of speaking. There is no infinite sequence 
that may converge or diverge, and “probability one” does not mean certainty. “Prob- 
ability one” means that we may give indefinitely great odds as the number of rounds 
increases; “converges to 1/2” means that these odds are for the relative frequency 
remaining in some ever tightening bounds around 1/2. 
But as Borel also understood and explained, his results can be expressed in terms 
of geometric probability. If we encode success as 1 and failure as 0, then the infinite 
sequence of 1s and 0s is the binary expansion of a real number from the closed interval 
[0,1], and the assumption that the rounds are independent with probability 1/2 for 1 
on each round corresponds to the uniform probability measure on this interval-the 
measure that gives each subinterval probability equal to its length. So if we imagine 
drawing a real number z at random from the interval [O, 11, and we write yn for 
the number of 1s in the first n digits of z’s binary expansion, then Borel’s strong 
law says that (2.5) holds with probability one. For Borel, this interpretation was 
mathematically instructive but conceptually inadmissible, simply because the idea of 
choosing a real number at random from [0,1] was inadmissible. 
An important example of the impact of Borel’s thinking is provided by Paul 
Ltvy’s Culcul des probabilitLs, published in 1925. In an appendix to the book, Ltvy 
explains how Borel’s example generalizes to a method for defining probabilities in an 
abstract space, such as a space of functions: partition the space into a denumerable 
collection of subsets, assign these subsets probabilities that add to one, then partition 
each of them in the same way, and so on indefinitely. In general, this does not 
produce probabilities for all interesting events. One cannot, for example, speak of 
the probability that a random function on [0,1] will never take the value 1/2 (LCvy 
1937, pp. 24-25). This limitation, for Borel and LCvy, was not an embarrassment; it 
was the result of the need for probabilities to have empirical meaning. 

2.2: KOLMOGOROVS MEASURE-THEORETIC FRAMEWORK 
39 
In the end, however, Borel’s scruples proved less influential than the elegance of his 
mathematics. His colleagues were surprised and fascinated by his results-surprised 
because it seemed paradoxical that the binary expansions of nearly all real numbers 
should have equal numbers of zeros and ones in the limit; fascinated because it now 
seemed that measure theory was fundamental to probability. Author after author 
declared that Bore1 had reduced the study of infinite sequences of events to measure 
theory ([318], pp. 57-60). The way was paved for the free-wheeling equation of 
probability and measure that found its full expression in the work of Kolmogorov. 
2.2 KOLMOGOROV’S MEASURE-THEORETIC FRAMEWORK 
Although measure and integration oc- 
cupied center stage in probability the- 
ory after 1909, and the idea that mea- 
sure could provide an axiomatic basis 
for probability was in the air in the 
1920s, Hilbert’s call for an axioma- 
tization of probability was answered 
in a fully satisfying way only by Kol- 
mogorov’s famous monograph Grund- 
begrifle der Wakrsckeinlickkeitsreck- 
nung, published in 1933. As Maurice 
FrCchet said in his opening address to 
the colloquium on probability theory 
at the University of Geneva in 1937 
([130], p. 54), it is not enough to have 
all the ideas in mind and recall them 
here and there; one must bring them 
Andrei Kolmogorov (1903-1987), in his dacha 
at Komarovka. 
together explicitly, make sure that the whole is sufficient, and take responsibility for 
saying that nothing further is needed in order to construct the theory. This is what 
Kolmogorov did. 
From a purely mathematical point of view, Kolmogorov’s framework was ex- 
tremely simple-six 
axioms and a few definitions. Among mathematicians, its 
simplicity, clarity, and power made it the easy victor in the spirited debate on the 
foundations of probability that took place in the 1930s. Its champions included Mau- 
rice FrCchet (1878-1973) in France, Harald CramCr (1893-1985) in Sweden, and 
William Feller (1906-1970) and Joseph L. Doob (born 1910) in the United States. 
After World War 11, it was the accepted wisdom. Exposited in countless textbooks, 
it is now familiar to all who study probability beyond the most elementary level. 
In addition to Kolmogorov’s axioms and definitions, we review his philosophical 
account of probability-his 
explanation of how these axioms and definitions can 
be used in practice. This explanation was as attuned to Kolmogorov’s time as his 
mathematics was, but it seemed less important to the mathematical probabilists who 
followed him. For us, it is very important. It is the key to understanding how our 

40 
CHAPTER2 THE HISTORICAL CONTEXT 
fundamental interpretative hypothesis relates both to Kolmogorov’s axioms and to 
the traditions that preceded him. 
Kolmogorov’s Axioms and Definitions 
Although Kolmogorov’s axioms and definitions are now very familiar, they are also 
very concise, and we will take the time to repeat them. We do so in the order and 
form in which he gave them, except that we deviate slightly from his notation and 
terminology, in favor of usages that will be more familiar to most readers and will 
recur later in this book. 
Because he wants to relate his ideas to the traditional framework of equally 
possible cases, Kolmogorov begins his exposition with the five of his six axioms that 
are relevant to finite spaces. These axioms concern a set 0, which we call the sample 
space, and a set 3 of subsets of 0, which we call events. With this notation, the five 
axioms run as follows: 
1. .F is ajeld of sets. (This means that whenever .F contains E and F it also 
contains the union E U F ,  the intersection E n F ,  and the difference E \ F.) 
2. 3 contains the set R. (Together with Axiom 1, this says that 3 is an ulgebra of 
sets. When 3 is also closed under countably infinite intersections and unions, 
it is called a a-algebra.) 
3. To each set E in 3 is assigned a nonnegative real number P E. This number 
is called the probability of the event E. 
4. 
equals 1. 
5. If E and F a r e  disjoint ( E n  F = 0, where 0 is the empty set), then P[EUF] = 
P E - t P F .  
With these axioms in place, Kolmogorov introduces the ideas of conditional proba- 
bility, experiment, and independence. 
If E and F are events and P E > 0, then the conditional probability of the 
event F under the condition E, P[F I El, is given by 
An experiment is a decomposition of 0-that 
is, a collection El,. . . , E, of 
disjoint events whose union is 0. 
A collection of n experiments, say Ei = {E;, . . . , E:,} for i = 1,. . . , n, are 
mutually independent if 
p[F1 n . . . n P] = P F ~ . .  
. p p Z  

2.2: KOL MOGOROVS MEASURE-THEORETIC FRAMEWORK 
4 1 
whenever F i  
is an element of EZ for i = 1, . . . , n. 
These axioms and definitions are satisfied in the traditional theory, in which the 
equally possible cases constitute, in effect, the sample space. The novelty of (2.7) 
is that only the unconditional probabilities P E are primitive. In earlier treatments, 
both conditional and unconditional probabilities were either defined in terms of 
equally possible cases or else taken as primitive, and (2.7) was a theorem rather 
than a definition. For historical accuracy, we should note that in 1933 Kolmogorov 
actually wrote PA(B) for the probability of B given A. This notation was widely 
used at the time; it goes back at least to an article by Felix Hausdorff in 1901. 
Kolmogorov switched to the now standard P(B I A) in the second Russian edition 
of his monograph, published in 1974. 
Finally, going beyond classical theory, Kolmogorov adds a sixth axiom, which is 
restrictive only when the sample space is infinite: 
6. For a decreasing sequence of events El 2 E2 2 . . . for which nrzl En = 0, 
A function P satisfying axioms 4, 5, and 6 is called a probability measure on the 
algebra F. 
Any probability measure on an algebra F can be extended to a probability 
measure on the smallest a-algebra containing F, 
and the extension will be countably 
limn+00 P En = 0. 
additive: 
n= 1 
n= 1 
for every sequence El, E2, . . . of disjoint events in the a-algebra (here we still write 
P for the extension). 
So Kolmogorov now assumes that F is a g-algebra. He then introduces the 
concepts of random variable, equivalence of random variables, expected value, and 
conditional expectation. 
A random variable is a function x on R that is measurable with respect to 
the a-algebra F. (This means that for each interval I of real numbers, the 
subset {< I x(<) E I }  of R is in F. When this is the case, we can define a 
probability measure on the real numbers by setting the probability for each 
interval I equal to P{< I x(<) E I }  and extending to the smallest a-algebra 
containing all intervals. This probability measure on the real numbers is called 
the probability distribution for the random variable.’ 
0 Two random variables z and y are equivalent if the probability of the event 
x # y is zero. 
‘When one speaks of a probability measure on the real numbers, it is always assumed that the a-algebra 
is either the Borel 0-algebra or the Lebesgue u-algebra. The Borel u-algebra, whose elements are called 
Borel sets, is the smallest 0-algebra containing the intervals. The Lebesgue u-algebra, whose elements 
are called Lebesgue sets, is the smallest 0-algebra containing both the Borel sets and any set contained in a 
Borel set that has measure zero with respect to the uniform measure. In practice, any probability measure 
on the real numbers is called a “probability distribution”; the requirement that it be constructed in the way 
specified is dropped. 

42 
CHAPTER 2: THE HISTORICAL CONTEXT 
0 The expected value of a random variable x, E 2, is its integral with respect to 
the measure p. If the integral does not exist, then we say that x does not have 
an expected value. If x does have an expected value, then we write v x  for 
@(x - E x)’], the variance of x. 
0 A version of the conditional expectation of a random variable y given another 
random variable 2 is any random variable z that (a) is a function of J: and (b) 
has the same integral with respect to P as y over every event defined in terms of 
x. (According to a theorem of measure theory now called the Radon-Nikodym 
theorem, at least one such random variable z exists, and any two are equivalent. 
We may write E[y 1 z] for any one of them,2 and we may write E[y I :c = c] for 
its value when x = c.) 
Conditional expectation generalizes conditional probability as defined by (2.7); if y 
takes the value 1 on an event B and 0 elsewhere, and the event x = c has positive 
probability, then all versions of E[y 1 x] agree that E[y I 5 = c] = P[B I x = c] (and 
this equality serves as the definition of conditional probability in general). 
As a first step towards demonstrating that these axioms and definitions are a 
sufficient mathematical foundation for continuous probability, Kolmogorov showed 
that in order to define a joint probability distribution for an indexed set of random 
variables, .ct, where the index t ranges over a set of arbitrary cardinality, it suffices 
to give mutually consistent joint probability distributions for all finite collections 
xt, , z t 2 ,  . . . , zt, . He also showed, in the Grundbegriffe and related articles, that 
the framework is adequate for fundamental results such as the strong law of large 
numbers. 
Of course, the reduction of probability to measure did not immediately persuade 
everyone. Borel, who lived until 1956, and LCvy, who lived until 1971, always 
felt that the mathematical theory should incorporate the passage from the finite to 
the continuous that makes abstract probabilities meaningful and makes conditional 
probability primitive [36,201,202]. De Finetti argued for decades against countable 
additivity (Axiom 6) and the demotion of conditional probability [92]. Along with 
de Finetti, Alfrtd RCnyi carried the battle for conditional probability into the 1960s 
[257, 2581. There were mathematical as well as philosophical reasons to hesitate 
about the new framework. In practice, the conditional expectations that characterize 
a stochastic process are given directly, not derived from unconditional expectations, 
and we want them to have properties that are not guaranteed by Kolmogorov’s axioms. 
These axioms do not even guarantee, for example, that the conditional probabilities 
P[B 
1 x = c], for fixed c, form a probability measure. It was some years after 
the GrundbegrzFe that topological conditions under which such regular conditional 
probabilities exist were formulated [262]. 
2Because our game-theoretic framework does not neglect what happens only on a set of measure zero, we 
avoid taking such liberties in this book. When we use a symbol for a variable in a protocol for a game, 
it always refers to a single particular variable, never to a class of variables every two members of which 
agree only almost surely. 

2.2: KOLMOGOROV’S MEASURE-THEORETIC FRAMEWORK 
43 
How Kolmogorov Related His Axioms to the World 
Kolmogorov was sympathetic with the frequentist interpretation of probability devel- 
oped and championed by Richard von Mises. As we will explain in the next section, 
probability was not primitive for von Mises; it was derived from the idea of a col- 
lective-a 
sequence of actual outcomes in which particular outcomes have limiting 
frequencies that remain invariant when we shift attention to subsequences defined 
without foreknowledge. Kolmogorov did not incorporate von Mises’s philosophical 
ideas into his mathematics; instead he axiomatized the mathematics of probability di- 
rectly. But he regarded his axioms as axioms for a frequentist concept of probability, 
and he tried to explain why. 
His explanation is brief enough to quote in full. We use the translation by Nathan 
Morrison ([178], 1950, pp. 3 4 )  except that we continue to deviate modestly from 
Kolmogorov’s notation. 
We apply the theory of probability to the actual world of experiments 
1. There is assumed a complex of conditions, C, which allows of any 
number of repetitions. 
2. We study a definite set of events which could take place as a result 
of the establishment of the conditions C. In individual cases where 
the conditions are realized, the events occur, generally, in different 
ways. Let 0 be the set of all possible variants w1, w2, . . . of the 
outcome of the given events. Some of these variants might in 
general not occur. We include in set R all the variants we regard a 
priori as possible. 
3. If the variant of the events which has actually occurred upon real- 
ization of conditions C belongs to the set E (defined in any way), 
then we say that the event E has taken place. 
4. Under certain conditions, which we shall not discuss here, we 
may assume that to an event E which may or may not occur under 
conditions C, is assigned a real number p E which has the following 
characteristics: 
(a) One can be practically certain that if the complex of conditions 
C is repeated a large number of times, n, then if y be the 
number of occurrences of event E, the ratio y/n will differ 
very slightly from P E. 
(b) If p E is very small, one can be practically certain that when 
conditions C are realized only once, the event E would not 
occur at all. 
in the following manner: 
For us, the most striking part of this passage is its final point, 4(b), which is closely 
related to our fundamental interpretative hypothesis. Point 4(b) is the only grounding 
Kolmogorov gives to the meaning of probabilities when an experiment is conducted 

44 
CHAPTERZ: THE HISTORICAL CONTEXT 
only once. So it would appear that for him, as for us (see §1.3), only probab 
very close to zero or one have any meaning in isolation. A probability close to zero 
means that the event almost certainly will not occur, and a probability close to one 
means that the event almost certainly will occur. But in the absence of repetition, a 
middling probability such as 1/3 or 1/2 has no particular meaning at all. 
In order to understand fully the significance 
of Kolmogorov’s points 4(a) and 4(b), we need 
to recall their antecedents. The basic idea goes 
back to Jacob Bernoulli, who first argued that 
an event with very high probability is prac- 
tically (or “morally”) certain and then con- 
cluded that frequency is practically certain to 
approximate probability ([ 151, pp. 217, 226). 
Cournot brought Bernoulli’s argument into the 
empiricist age by recasting practical certainty 
as physical certainty. It may be mathematically 
possible for a heavy cone to stand in equilib- 
rium on its point, but such an event is physi- 
cally impossible, Cournot argued, because of 
its very small or even zero probability. Sim- 
A A Cournot (1801-1877). The pnn- 
ilarly, it is physically impossible for the fre- 
ciple that events with zero probability 
probability theory 
the physical world, quence of trials to differ substantially from the 
event’s probability ([58], pp. 57, 106). This 
has been called Cournot’s bridge from probability theory to the physical world ([5], 
p. 106; [222], p. 175). 
Cournot’s bridge was alive and well in the early twentieth century. It was expressed 
most clearly by Paul LCvy. In his 1925 book, Levy explained that probability is 
founded on two principle?: the principle of equally likely cases and the principle of 
the very unlikely event. The first principle underlies the mathematics of probability, 
but it produces only a subjective theory. The second principle, which says that a very 
unlikely event will not happen, provides the bridge from this subjective theory to 
the world of experience. It is only this bridge that allows us to treat a mathematical 
probability as a physical quantity, which we can measure by repeated observations 
just as objectively as we measure length or weight ([ 1961, pp. 21-22,29-30,34). The 
importance of the principle of the very unlikely event to practice was also emphasized 
by the English statistician Ronald A. Fisher [125]. 
Kolmogorov’s formulation of 4(a) and 4(b) echoes this tradition, but he does 
not acknowledge that 4(b) renders 4(a) superfluous as an interpretive assumption. 
Once 4(b) is accepted, 4(a) is a theorem, and the frequency aspect of probability, as 
important as it is, seems derivative rather than fundamental. Passing over this point 
in silence was Kolmogorov’s way, perhaps, of expressing his own preference for an 
understanding of the relation between probability theory and the world that begins 
with the idea of frequency rather than the idea of practical impossibility. 
cannot happen is Cournot’s bridge from quency Of an event in a 
long se- 

2.2: KOL MOGOROVS MEASURE-THEORETIC FRAMEWORK 
45 
The Expulsion of Philosophy from Probability 
Although Kolmogorov himself did not see his framework as a substitute for what von 
Mises had tried to do, many mathematicians in the late 1930s did see Kolmogorov’s 
and von Mises’s approaches as rival mathematical foundations for the frequentist 
conception of probability. This is explicit in Maurice Frtchet’s contribution to the 
Geneva colloquium in 1937 and in Joseph L. Doob’s debate with von Mises in 
Hanover, New Hampshire, in 1940 [98, 313, 3151. In these discussions, FrCchet 
and Doob point to the law of large numbers as one aspect of the correspondence 
between Kolmogorov’s mathematics and what happens in the world, but neither of 
them mention any need for a principle such as Kolmogorov’s 4(b) or the similar 
principles that had seemed so important to Cournot and LCvy. 
For Doob, we need merely to “find a trans- 
lation of the results of the formal calculus 
which makes them relevant to empirical prac- 
tice” ([98], p. 208). Doob’s solution was to set 
up a correspondence between subsets of fl and 
events in the world, and to say that the mea- 
sure assigned to a subset of fl in the formal 
calculus corresponds to the probability of the 
event, which is found by the practitioner using 
“a judicious mixture of experiments with rea- 
son founded on theory and experience” ([98], 
p. 209). Whereas LCvy offered the princi- 
ple of practical impossibility as a way of giv- 
ing meaning to probability, Doob preferred to 
leave the meaning, numerical values, and va- 
lidity of probabilities entirely up to the practi- 
tioner. 
In the last analysis, Kolmogorov’s axioms Joseph L. Doob, president of the Amer- 
triumphed and endured because they made ican Mathematical Society, 1963-1964. 
probability legitimate as mathematics, freeing 
mathematical probabilists from the need to worry about interpretation. Before Kol- 
mogorov’s Grundbegriffe, most mathematicians were suspicious of probability, be- 
cause it seemed to be based on assumptions that could not be stated clearly within 
mathematics. After the Grundbegriffe, probability was mathematics, with fully re- 
spectable axioms and definitions, in the set-theoretic tradition championed by Hilbert. 
The intuitions remained, but now they provided only inspiration, not impediments to 
rigor. Other mathematicians could use Kolmogorov’s framework whether or not they 
shared his frequentism. And once it was accepted by mathematicians, the framework 
also was accepted by most other scholars interested in probability, regardless of their 
philosophical leanings. Thorough neosubjectivists still share de Fintetti’s [ 14, 1861 
reservations, but even many subjectivists now take Kolmogorov as their starting point 
[259]. 

46 
CHAPTER 2: THE HISTORICAL CONTEXT 
2.3 REALIZED RANDOMNESS 
Game theory is a mathematical account of po- 
tentiality; it analyzes what players can do, 
not what they have done or will do. Hence 
the probabilities in our framework are mea- 
sures of potentiality. But our thinking owes 
much to a twentieth-century line of work that 
treated probabilities as aspects of a concrete 
reality. 
This work was begun between the 
two world wars by Richard von Mises, who 
sought to explain what it means for a real- 
ized sequence to be random. Vigorously de- 
bated in the 1930s, von Mises’s ideas inspired 
Jean Ville’s work on martingales, an impor- 
tant ingredient in our framework. Once the 
adequacy of Kolmogorov’s axioms as a foun- 
dation for mathematical work in probability 
became clear, most mathematicians lost inter- 
est in trying to define randomness mathemati- 
Richard 
Berlin in 1930. 
Mises (1883-1957), in cally, but the project was revived in the 1960s 
by Kolmogorov and others, who developed it 
into a theory of algorithmic complexity. 
Von Mises’s Collectives 
Von Mises, who served in the Austro-Hungarian army in World War I, was educated 
in Vienna and taught in Strasbourg, Dresden, and Berlin before fleeing to Turkey 
when the Nazis came to power in 1933. In 1939, he emigrated to the United States, 
becoming a professor of mathematics at Harvard 11271. He explained his concept of 
a collective in an article in 1919 and then in a book, Wuhrscheinlichkeit, Statistik, und 
Wuhrlzeit, first published in 1928. His fundamental intuition was that a probability is 
an invariant limiting frequency-a 
frequency that (a) is obtained in the limit as one 
looks at longer and longer initial segments of an infinite sequence and (b) remains 
the same when one replaces the sequence with a subsequence. 
A collective (Kollektiv in German), according to von Mises, is an actual sequence 
for which such invariant limiting frequencies exist. Consider, for example, an infinite 
sequence of 0s and 1s that begins like this: 
0 0 1 0 0 1 1 0 0 1 0 1 0 0 1 1 1 1 1 0  .... 
As we move through the sequence, the cumulative relative frequency of 1 s changes: 
0 0 1 1 1 2 3 3 3 4  4 5 5 5 6 7 8 9 1 0 1 0  
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 2 0 ’ ” ’  

2.3: REALIZED RANDOMNESS 
47 
Von Mises’s definition requires that this cumulative relative frequency converge to a 
constant, say p. And it must converge to the same constant p in any subsequence, 
such as the subsequence consisting of every other entry: 
0 1 0 1 0 0 0 1 1 1  
or the subsequence consisting of entries preceded by a 1: 
0 1 0 0 1 1 1 1 0  . . . .  
Thus a gambler who bets on Is, say, cannot improve his performance by selecting 
only some trials on which to bet. In order to qualify as a collective, the sequence 
must be too irregular to permit any such strategy to succeed. 
In von Mises’s philosophy, the collective comes first, and then probability. The 
collective can consist of zeros and ones, as in our example, or its entries can be drawn 
from any other sample space. In any case, an event can have a probability only if 
it is situated in a collective, in which case its probability is that collective’s limiting 
frequency for the event. And the rules of probability derive from the properties of 
collectives. Probabilities add, for example, because frequencies add. 
Von Mises presented his ideas in an engaging, confident, but nonrigorous way. He 
did not explain how subsequences are to be selected, and so he was not in a position 
to consider the mathematical problem of proving that collectives-infinite 
sequences 
for which all permitted subsequences have the same frequencies-exist. But these 
challenges were taken up by others. 
The first authors to clarify how subsequences can be selected were Arthur H. 
Copeland, Sr., Karl Popper, and Hans Reichenbach [57, 249, 2541. Their ideas 
about how to select a subsequence from z1, 
z2, . . . all boil down to fixing a natural 
number T and a sequence a l ,  . . . , a, of elements of the sample space and then 
including z, 
in the subsequence if it is immediately preceded in z1, 
z2, 
. . . by 
al, . . . ,a,. They suggested that z1,x2,. 
. . be considered a collective if the same 
limiting frequencies are obtained in every infinite subsequence selected in this way, 
but this was unacceptable to von Mises, because it may allow some sequences defined 
by mathematical laws to qualify as collectives. For von Mises, a collective had to be 
unpredictable. 
In 1937, Abraham Wald (1902-1950) gave aformulation that von Mises did accept. 
Wald proposed that we permit any rule for selecting a subsequence that decides 
whether to include x, on the basis of the preceding outcomes z1, 
. . . , z,-1. 
But he 
demanded that such a rule be expressed in a formal logic, and he pointed out that only 
countably many rules can be expressed in a logic with a finite alphabet. If the sample 
space is finite, then it follows easily from standard probability theory that sequences 
with the same limiting frequencies for a given countable number of subsequences do 
exist, and similar results can also be obtained for infinite sample spaces if only well- 
behaved subsets are considered. In 1940, shortly after the publication of Wald’s ideas, 
the American logician Alonzo Church (1903-1995) used the concept of effective 
computability to support Wald’s argument that countably many rules would be enough 
to account for every implementable method of selection. Church had introduced 

48 
CHAPTER 2: THE HISTORICAL CONTEXT 
the mathematical notion of effective computability in 1936, and its adequacy for 
representing the empirical notion of effective calculation had been supported by Alan 
Turing’s demonstration that it is equivalent to computability by a universal computing 
machine. 
Church’s contribution marked the end of the intense discussion of collectives that 
flourished in the 1930s. The concept of a collective was consistent, but for most 
mathematicians, it was not very useful. In spite of von Mises’s efforts, especially 
in [3 111, the derivation of the rules of probability from the concept of a collective 
remained messy, and the idea of an infinite sequence seemed to contribute nothing 
to actual uses of probability. Kolmogorov’s axioms were a much clearer and more 
convenient starting point. (For a more detailed but still concise account of the work 
on collectives in the 1930s, see Martin-Lof 1969. See also [187,269].) 
Ville’s Strengthening of the Concept of a Collective 
A important contribution to the theory of collectives, which had relatively little impact 
at the time but has turned out to be of fundamental importance, was made by the young 
French mathematician Jean Ville (1 910-1988). As Ville showed, probability theory 
requires even more irregularity from a sequence than is required by the Mises-Wald 
definition of a collective [307, 308, 3061. 
Ville’s favorite example concerns the oscillation of a cumulative relative frequency 
as it converges. We expect the frequency to oscillate above and below its limiting 
value, and this expectation became part of probability theory when Khinchin proved 
the law of the iterated logarithm (see p. 99). But as Ville showed, the Mises- 
Wald definition does not imply this oscillation. No matter what countable set of 
subsequence selection rules are adopted, one can construct a Mises-Wald collective 
of 0s and Is in which the frequency of 1s approaches its limiting value from above. 
Ville dramatized the unacceptability of a collective of 0s and Is in which the limit- 
ing frequency of 1s is approached from above by demonstrating that it is susceptible 
to a gambling system that varies its bets. Suppose, to fix ideas, that the limiting 
frequency is 1/2. Then there is a system for placing even-money bets, possibly us- 
ing knowledge of the previous outcomes, that will avoid bankruptcy no matter what 
happens but will increase one’s capital without bound if y,/n 
always stays above 
Considered as tests of the randomness of sequences of 0s and Is, gambling 
systems are more powerful, as a class, than subsequence selection rules. Given 
any subsequence selection rule, there is a system for placing even-money bets that 
avoids bankruptcy no matter what happens and produces an infinite return if the 
frequency of 1s in the subsequence does not converge to 1/2 (see 53.1). In other 
words, there is a gambling system that detects any deviation from randomness that 
a given subsequence selection rule detects. And as Ville’s example shows, there are 
also gambling systems that detect deviations no subsequence selection rule detects. 
In fact, Ville’s method for testing for randomness is universal, in the sense that it 
can detect any deviation from randomness by a sequence of 0s and Is. A deviation 
from randomness, by definition, is the failure of a property E that has probability 
1/2. 

2.3: REALIZED RANDOMNESS 
49 
one under classical probability theory (or under measure-theoretic probability theory; 
there is no difference in the simple case of independent trials of an experiment with 
only two outcomes). For any such property E, as Ville showed, there is a system for 
betting at even odds that avoids bankruptcy no matter what happens and produces an 
infinite return if E does not happen (see $8.1). The oscillation required by the law 
of the iterated logarithm is merely one example of a property E that has probability 
one. 
Ville used von Mises’s own words to buttress his view that testing for randomness 
using a gambling system is just as valid as testing for randomness using a subsequence 
selection rule. In explaining the requirement that the limiting frequency in a collective 
be invariant across subsequences, von Mises had argued that the futility of even the 
most complicated systems for beating the odds in games of chance is part of “the 
experimental basis of our definition of probability” (p. 25 of von Mises 1957). This 
experience teaches that “one cannot improve one’s chances by a systematic choice 
of trials” (p. 11 of von Mises 193 1, our translation). As Ville noted, it also teaches 
that one cannot improve one’s chances by varying how and how much one bets. 
Gambling systems usually do vary their bets depending on preceding outcomes, and 
this feature is mentioned in discussions of their futility in nineteenth-century books on 
probability (Lacroix 1822, pp. 123-124; Cournot 1843, $62; Bertrand 1889,5113). 
So why not use Ville’s notion of a gambling system, rather than von Mises’s 
weaker notion of subsequence selection, to define the concept of a collective? As 
Ville noted, for any p between 0 and 1 (we need not take p equal to 1/2) and any 
countable set of systems for gambling at odds p : 1 - p without risking bankruptcy, a 
sequence of 0s and 1 s exists such that the capital from each of the gambling systems 
remains bounded. (The capital process for each gambling system remains bounded 
with probability one, the intersection of countably many events with probability one 
also has probability one, and a set that has probability one cannot be empty.) By 
including appropriate gambling systems in the countable set, we can make sure that p 
is the limiting frequency of 1s in the sequence and in any given countable number of 
subsequences, thus accomplishing all that von Mises and Wald accomplished. And 
we can also make sure that the sequence satisfies any given countable set of further 
properties that have probability one under the probability measure that makes the 
outcomes independent and assigns probability p to each coming out 1. 
Wald welcomed this strengthening of the idea of a collective. As he noted, the 
number of gambling systems expressible in a formal language, like the number of 
subsequence selection rules expressible in a formal language, is necessarily countable 
([91], pp. 15-16). Von Mises, however, never conceded Ville’s point ([312], p. 66). 
Apparently von Mises’s appeal to the impossibility of a gambling system had only 
been rhetorical. For him, frequency, not the impossibility of a gambling system, 
always remained the irreducible empirical core of the idea of probability. 
For his own part, Ville retained a critical stance towards collectives, refusing 
even to embrace his own strengthening of the concept. He agreed with his adviser, 
FrCchet, that probability should be founded on axioms (perhaps Kolmogorov’s axioms 
or perhaps a similar system that treats conditional probabilities as primitive), not on 
collectives. And he saw paradox lurking in Wald’s idea that one can enumerate all 

50 
CHAPTER 2: THE HlSTORlCAL CONTEXT 
definable subsequence selection rules or gambling systems. He knew how to construct 
a collective xs for a countable set S of selection rules, and he thought that the Is in 
xs would effectively define a new selection rule not in S, producing a contradiction 
([306], p. 134). In 1940, Church made it clear that this paradox is avoided: the 
effectively computable selection rules are enumerable but not effectively so. But this 
was not enough to revive interest in collectives. Twenty-five years passed before the 
topic was seriously revisited, by Per Martin-Lof 1969 and Claus Peter Schnorr 1971. 
Kolmogorov Complexity 
As a frequentist, Kolmogorov always felt that his axioms needed something like von 
Mises’s theory in order to connect with frequencies in the world. But he agreed 
with the critics that the infinitary character of von Mises’s collectives made them 
useless for connecting with our finite experience. For many decades, he thought it 
was impossible to express his finitary frequentism in mathematics. But in the early 
1960s, he realized that finite sequences and selection rules for them can be studied 
using Turing’s idea of a universal computing device, which permits an objective 
measurement of complexity and simplicity for finite mathematical objects: given a 
universal computing device, one mathematical object can be considered simpler than 
another if there is a shorter program for generating it. 
Kolmogorov first considered applying the notion of algorithmic simplicity to finite 
sequences in the same way Wald and Church had applied effective computability to 
von Mises’s infinite sequences. In an article entitled “On tables of random numbers”, 
published in 1963, Kolmogorov pointed out that only a few of the many subsequence 
selection rules that might be applied to a very long but finite sequence of 0s and 1s 
can be algorithmically simple. He suggested that we call the sequence p-random if 
the frequency of Is is close to p in all sufficiently long subsequences selected by 
these easily described rules. But he soon turned to a simpler idea, not so purely 
frequentist but too natural to resist. Why not consider directly the complexity of a 
finite sequence of zeros and ones? If the sequence’s algorithmic complexity is close 
to maximum {the length of the sequence), it can be regarded as random. Per Martin- 
Lof developed this idea when he visited Moscow in 1963-1964. In “The definition 
of random sequences”, a celebrated paper published in 1966, Martin-Lof showed that 
there exists a universal statistical test for detecting sequences that are nonrandom 
in Kolmogorov’s sense. He also extended the idea of a universal statistical test to 
infinite sequences. In 197 1 Schnorr showed that Martin-Lof’s notion of randomness 
for infinite sequences is also obtained if one imposes tests of Ville’s type; this result 
was also independently obtained by Leonid Levin. There are yet other variants on 
the idea; for reviews of the work in this area, see [183, 204, 2691. 
As for Kolmogorov himself, he continued to be concerned with finite sequences, 
and he eventually proposed an approach to statistical modeling that bypasses proba- 
bility, using algorithmic complexity directly to define statistical models (33 11. The 
field of study now called Kolmogorov or algorithmic complexity encompasses var- 
ious ideas for using complexity for statistical work, including ideas on inductive 
inference championed by Ray J. Solomonoff, who studied the universal measure- 

2.4: WHAT IS A MARTINGALE? 
51 
ment of complexity independently of Kolmogorov [294]. An excellent overview of 
the field is provided by Li and Vitinyi 1997. 
The success of Kolmogorov complexity has vindicated von Mises’s ambition to 
analyze the idea of randomness, and Kolmogorov complexity has contributed to the 
development of our framework. Saying that Skeptic cannot become infinitely rich 
is the same as saying that Reality’s moves will pass any computable test based on 
Forecaster’s prices-that 
is, they will be random in the sense of Schnorr. But we are 
concerned with potential unpredictability rather than concrete realized randomness. 
Moreover, we do not even attempt to measure unpredictability quantitatively in this 
book. We do believe, however, that the future development of our framework will 
involve more complicated games, in which different Forecasters compete and are 
compared quantitatively. This will require a greater use of ideas from Kolmogorov 
complexity. 
2.4 WHAT IS A MARTINGALE? 
In this section, we discuss the idea of a martingale: its origins in gambling, its intro- 
duction into probability theory by Jean Ville, its role in measure-theoretic probability, 
and its somewhat different role in the game-theoretic framework. 
Martingales before Jean Ville 
A martingale, in English and French, is a system by which a gambler tries to become 
rich. The word appears in the dictionary of the French Academy as early as 1762, 
where it is said to refer to the particular system where the gambler doubles his bet 
until he finally wins. If the gambler starts by betting a, and he finally wins on the 
n,th bet, then his profit on that bet, 2na, will exceed his total loss, 
a + 2a + . ’ ’ + 2--1a, 
by a. The difficulty is that a modest losing streak will exhaust the gambler’s capital 
or bring him up against the house’s limit on the size of a bet. As Sylvestre Franqois 
Lacroix (1765-1 843) wrote in his textbook on probability in 1822, 
Gamblers with little capital cannot follow a scheme like this, which is 
called making the martingale, without hurting or ruining themselves, and 
they are often forced to give up, losing everything they have laid out. As 
for the rich, they can make much better use of their capital . . . 
(p. 124, our translation). But such schemes are constantly reinvented by mathemat- 
ically inclined novice gamblers. We can find manuals for gamblers who want to 
follow martingales (e.g., [76]), and the theme of the martingale appears frequently in 
literature (see the works by Cocteau, Picard, and Thackeray in our list of references). 
In an apparently older sense, the word martingale refers to the strap of a horse’s 
harness that passes from the noseband through the forelegs and keeps the horse from 

52 
CHAPTER 2: THE HlSTORlCAL CONTEXT 
raising his head. In this meaning, at least, the word came into French and English from 
Arabic through Spanish, although many authorities believe it was also influenced by 
martegalo, the word in ProvenGal for a female inhabitant of the Mediterranean port of 
Martigues. Some French dictionaries quote Rabelais, in 149 1, ridiculing shoes that 
fastened in the back, & la martingale. Was he comparing them to a horse’s harness, 
referring to the style of dress in Martigues, or already evoking the wild abandon of 
the gambler going for all or nothing? 
Martingales in Jean Ville’s Etude critique de la notion de collectif 
Martingales are wild systems of play, but the distinction between wild and tame is not 
sharp. So in mathematics, we might call any strategy for placing bets a martingale. 
This is what Ville did, with no sense of originality. But he then gave the word a 
twist. In the case of coin tossing, which he emphasized, strategies are in a one-to-one 
correspondence with their capital processes once we have fixed the initial capital. So 
Ville called the capital processes martingales. 
Formally, Ville was considering a sequence of play with outcomes z1, 
x 2 )  . . . and 
a gambler who begins with initial capital equal to 1. A strategy for the gambler is 
a rule that chooses, for each initial subsequence x l , .  . . , z,-1, 
a gamble on x, (see 
5 1.2). The strategy’s capital process is the real-valued function C that assigns to each 
sequence 1c1, . . . , z, 
the capital C(z1,. . . , 2,) 
the gambler will have right after his 
gamble on z, 
is settled. If we assume (as Ville did but as we do not do in this book) 
that the permitted gambles define a probability distribution for 5 1 ,  x g ,  . . ., then we 
can speak of the expected value of C(z1,. . . , z,), 
and we have 
Conversely, any process C starting at 1 and satisfying (2.8) can be obtained from 
some strategy. So Ville took (2.8) and L(0) = 1 as his mathematical definition of a 
murzingale (Ville 1939, p. 99). 
As we have already noted, Ville demonstrated that for any set E of z1, 
~
2
,
 
. . . that 
has probability one, there exists a nonnegative martingale that diverges to infinity if E 
fails. He demonstrated, in fact, that this is an equivalence: an event E has probability 
one if and only if there exists a nonnegative martingale that diverges to infinity if the 
event fails. Moreover, he came very close to showing that nonzero probabilities can 
also be interpreted in terms of martingales: for any event E, 
where C ranges over all martingales, CO is the initial value of C, and C is its value 
at time n. We can put (2.9) in words by saying that the probability of an event is the 
smallest possible initial value for a nonnegative martingale that eventually reaches or 
exceeds 1 if the event happens. (We give proofs of Ville’s results in 58.5.) 
Ville also explored other uses of the concept of a martingale in probability theory. 
He used it to prove several limit theorems, and he even ventured to extend his results, 

2.4: WHAT IS A MARTINGALE? 
53 
along with his definition of martingale, to continuous time. He did not, however, 
pursue the study of martingales further after his book was published. (We provide a 
brief biography of Ville in 58.6.) 
Game-Theoretic Martingales 
It is scarcely an exaggeration to say that Ville showed how the classical theory of 
probability can be founded on the notion of a martingale. Martingales can serve as 
our starting point, because probability can be defined in terms of martingales, using 
Equation (2.9). 
Our game-theoretic framework simply develops this idea in a thorough-going 
way. Instead of beginning with classical probabilities, as Ville did, we begin with 
opportunities for betting, which define possible capital processes. Then we define 
probability in terms of these capital processes, in the way suggested by Ville’s results. 
We say that an event happens almost surely (that is, with probability one) if there is 
a nonnegative capital process that diverges to infinity if the event does not happen 
(p. 17), and we define upper probability in the spirit of Equation (2.9): the upper 
probability of an event is the smallest possible initial value for a nonnegative capital 
process that eventually reaches or exceeds 1 if the event happens (see Equation (1.4) 
on p. 15). Because Ville began with classical probabilities, it was possible to recover 
these probabilities by Equation (2.9). We begin instead with arbitrary betting op- 
portunities, which may or may not define probabilities; in general they define only 
upper probabilities. But this is the only essential difference between our viewpoint 
and Ville’s, which was already relatively game-theoretic. 
When the protocol for our probability game is symmetric (Skeptic can always buy 
tickets at the same price at which he is allowed to sell them), we even follow Ville 
by using the word “martingale”: we call a capital process for Skeptic in a symmetric 
probability protocol a (game-theoretic) martingale. This is more general than Ville’s 
notion of a martingale, because even in a symmetric probability protocol there is no 
requirement that Skeptic be offered enough gambles to define a probability measure 
(see p. 67 and p. 188). But it preserves Ville’s basic intuitions about martingales. 
The value of a game-theoretic martingale C in the initial situation 0 in a symmetric 
probability protocol is the price at which Skeptic can buy or sell C’s future payoffs. 
This is because there is a strategy P that produces these payoffs starting with C(0). 
If Skeptic follows P starting with zero instead of C(O), he gets L - C ( 0 ) ;  this is 
buying C for C ( 0 ) .  If he follows the opposite strategy, -P, starting with zero, he 
gets -C + C(0); this is selling C for C ( 0 ) .  
A nonnegative game-theoretic martingale in a symmetric probability protocol is 
the same thing as a capital process for a strategy that does not risk bankruptcy, 
and our fundamental interpretative hypothesis can be expressed by saying that any 
given nonnegative game-theoretic martingale will remain bounded. Equivalently, a 
game-theoretic martingale that is bounded below will not become infinitely large. 
Because -C is a game-theoretic martingale whenever C is, we can also say that a 
game-theoretic martingale that is bounded above will not become infinitely negative. 

54 
CHAPTER 2: THE HlSTORlCAL CONTEXT 
Measure-Theoretic Martingales 
In the 1940s and 1950s, Joseph L. Doob 
adapted Ville’s concept of a martingale 
to the measure-theoretic framework. 
Doob’s thinking was influenced by 
work on dependent random variables that 
goes back to Andrei A. Markov in the 
nineteenth century and Sergei Bernstein 
in the early twentieth century. Markov 
was interested in extending the central 
limit theorem from independent random 
variables to dependent random variables. 
Bernstein, a Russian mathematician who 
completed a doctorate in analysis in Paris 
in 1904, began working on this topic in 
about 1917, and in the 1920~, he pub- 
lished proofs of the central limit theo- 
rem for sequences of random variables 
x1,52, . . . obeying various conditions 
on the mean and variance of x, given 
XI ,..., ~
~
-
1
 
[17, 181. 
Paul Lcvy (1886-1?71). His beloved teacher 
Around 1930, following ~
~
~
Jacques Hadamard disapproved of his work 
lead, paul L
C
~
~
 
took up ~
~
~
k
prob- 
lem. In 1935, LCvy began to emphasize 
in probability, but Bourbaki ranked him as one 
of the leading French mathematicians between 
what he called condition C: the mean of 
the two world wars [202, 2701. 
2 ,  given 21,. . . , z,-1 
should be zero. 
If we write S(z1,. . . , xrL) for the sum of 51,. . . , z,, 
then we can express LCvy’s 
condition C in the form 
TE[S(zl,...,xn) 
lxl,~.~,x?z-11 
= S ( Z l , z : ! , . . . , ~ C n - l ) ,  
which looks like Ville’s definition of a martingale. 
Ville had not investigated the central limit theorem for dependent variables, but 
Doob, who reviewed Ville’s book right after its publication [96], immediately saw 
the connection. He also thought it more natural to write 
E[Sn I s1,. 
’ . , Sn-11 = S7L-1, 
(2.10) 
where S,, = S(z1,. 
. . , z,). 
This is a property of a sequence of random variables 
S1, S,, 
. . ., which can be studied in its own right. One can put matters more abstractly: 
writing Fn 
for the g-algebra generated by S 1 ,  . . . , S,, one can rewrite (2.10) as 
(2.1 1) 
It is also interesting to relax the condition that FTz be the g-algebra generated by 
S1, . . . , S,, 
to the condition that these random variables be measurable with respect 
to FTL 
and that the .Fn-l C F, for n = 1,2, . . . (see 58.1). 
E[Sn I Fn-11 = s n - 1 .  

2.5: THE lMPOSSlBlLlTY OFA GAMBLING SYSTEM 
55 
In an article he published in 1940, in which he called (2.11) condition &, Doob 
began to explore this condition in the measure-theoretic framework, in both discrete 
and continuous time. As he explained later, & did not stand for expected value; it was 
merely the second letter in the alphabet after C. It would have been too self-centered 
to use 2) [293]. Ten years later, when working on his immensely influential Stochastic 
Processes, which appeared in 1953, Doob returned to condition & and began calling 
sequences satisfying it martingales [99, 1001. This is now the accepted meaning of 
the word in measure-theoretic probability. 
We use “martingale” in both its game-theoretic and measure-theoretic senses in 
this book, appending the adjective “game-theoretic” or “measure-theoretic” when 
this is necessary in order to avoid confusion. 
2.5 THE IMPOSSIBILITY OF A GAMBLING SYSTEM 
Because the hypothesis of the impossibility of a gambling system is one of the two 
pillars of our framework, our historical review would not be complete without a search 
for its antecedents. Where, in the historical development of probability theory, did 
the hypothesis appear, and how did it develop? 
Different Ways of Understanding the Futility of Gambling Systems 
When was the impossibility of a gambling system first articulated? This is a tricky 
question because, as Maurice FrCchet pointed out, the impossibility can be understood 
in many different ways ([130], p. 40). 
Within classical or measure-theoretic probability theory, we might make the fol- 
lowing points in order to elaborate the assertion that a gambling system cannot 
succeed in a fair game: 
1. If X I ,  
z2, 
. . . are independent and identically distributed random variables, then 
the sequence of random variables obtained by applying a subsequence selection 
rule to ~ 1 ~ x 2 ,  
. . . has the same joint probability distribution. 
2. If at the beginning of each round of a game, the expected gain for each gamble 
available on that round is zero, then the initial expected value of one’s total 
gain is zero, no matter what strategy one adopts. 
3. A player’s gain in a fair game, being a random variable with expected value 
zero, cannot be positive with positive probability without also being negative 
with positive probability. 
4. If the player follows a system that does not risk bankruptcy, then the odds are 
at least K - 1 to one against his multiplying his stake by K .  
Points 2 and 3, which assume constraints on the size of bets, were made by Cournot 
1843 and Bertrand 1889 in their discussions of the futility of gambling systems. 
Doob 1936 advanced Point 1 as an expression of the impossibility of a gambling 

56 
CHAPTER 2: THE HISTORICAL CONTEXT 
system within measure-theoretic probability. Ville, as we have seen, put the spotlight 
on Point 4. In 1965, Lester E. Dubins and Leonard J. Savage christened Point 2 the 
conservution qffuirness ([105], 5 1.3). 
Jean Ville put the emphasis on Point 4, which he expressed by means of what we 
now call Doob’s inequality: if a nonnegative martingale L has the initial value 1, and 
A > 0, then 
(2.12) 
(Ville 1939, p. 100). This generalizes Murkov’s inequality, which says that a non- 
negative random variable z satisfies 
(Markov 1900, $13). As we have noted, Ville also proved an infinitary version of 
(2.12): if a strategy does not risk bankruptcy, then the probability that it makes 
you infinitely rich is zero. And for the classical fair coin (where 2 ,  is 0 or 1 with 
probability 1/2, no matter how xl, . . . , x7L-l come out), he proved a converse: if a 
certain property of the sequence xl, 2 2 ,  . . . has probability zero, then there is a strategy 
that makes you infinitely rich whenever that property holds (see 58.1). Thus there is 
a full equivalence, in the canonical classical case of the fair coin, between probability 
zero and Skeptic’s becoming infinitely rich. This equivalence was significant for 
Ville’s approach to collectives, because it gave intuitive grounds, conceptually prior 
to probability theory, for requiring a collective to avoid any property that is given 
probability zero by probability theory. It is equally significant for us, because it 
makes clear that “unless Skeptic becomes infinitely rich” derives as much legitimacy 
from classical probability theory as “except on a set of measure zero”. 
Points 1-4 are valid, with appropriate qualifications and changes in terminology, 
within our game-theoretic framework. But in whatever framework they are un- 
derstood (classical, measure-theoretic, or game-theoretic), they are only statements 
about probabilities. Our hypothesis of the impossibility of a gambling strategy, in 
contrast, is not a statement about probabilities. It is a hypothesis that relates a certain 
game to the world, which we can state before we compute probabilities for events 
from the prices in the game. When adopted for particular prices for a particular 
phenomenon, this hypothesis asserts directly our practical certainty that a gambler 
cannot get rich at the prices offered in the game without risking bankruptcy. This 
assertion stands outside the mathematics of probability, serving as a bridge between 
it and the world. It is our version of Cournot’s bridge. 
Our understanding of the impossibility of a gambling system, as something prior 
to the computation of probabilities, is relatively novel. It departs from the thinking of 
Cournot, L@vy, and Kolmogorov, for they formulated principles for interpreting zero 
or small probabilities, not hypotheses expressed without reference to probabilities. 
Von Mises anticipated our way of thinking, for he did say that the impossibility of a 
gambling system is something more primitive than probability. But his allegiance to 
this idea, as we have seen, was half-hearted; in the end he refused to acknowledge that 
the impossibility of a gambling system is more fundamental than invariant frequency. 

2.5: THE lMPOSSlBlLlTY OF A GAMBLING SYSTEM 
57 
And Ville was less radical, in some respects, than von Mises; in spite of his discovery 
of the fundamental properties of martingales, he insisted on classical or measure- 
theoretic probabilities as his starting point. So our understanding of the impossibility 
of a gambling system as a primitive hypothesis can be seen as the distinguishing 
novelty in our game-theoretic framework. 
The Prequential Principle 
In order to appreciate fully the independence of our fundamental hypothesis from 
classical or measure-theoretic probability theory, we should recognize that the prices 
whose testing is enabled by the hypothesis may fall short of defining a full probability 
distribution for a process, even $the prices for each step of the process define a full 
probability distribution for what happens on that step. This aspect of our framework 
finds an important antecedent in A. Philip Dawid’s work on probability forecasting. 
We can begin our discussion of probability forecasting by recalling an exchange 
between Emile Borel and Hans Reichenbach. Reichenbach argued that even the 
probability of an isolated event, such as Julius Caesar having visited Britain, can be 
given a frequency interpretation. When a historian asserts that Caesar visited Britain, 
he should set his probability equal to the frequency with which historians are correct 
in cases with similar evidence. Reichenbach acknowledged that there might be some 
question about how to choose the class of similar cases for which to calculate the 
frequency, but he counseled choosing the most restricted class, consisting of the 
most similar cases (Reichenbach 1937, p. 3 14). In his Vuleurprutique etphilosophie 
des probabilitis, Borel agreed with Reichenbach that it makes sense to talk about 
the probability of an isolated event but disputed the viability of a purely frequentist 
interpretation. In Borel’s view, the class of entirely similar cases-past 
and future- 
is usually too small to permit us to speak of frequencies. In order to assess the 
probability of an isolated event, we must take details into account by subjectively 
adjusting general frequencies (Borel 1939, p. 86). 
Ville took up the issue at the very end of his own book (Ville 1939, p. 139). In 
order to deal with isolated events, Ville contended, we must generalize von Mises’s 
notion of a homogeneous sequence of events by considering an observer 0 who 
makes probability judgments about a sequence El, E2, . . . of events: 
PE1 = Pl, PEa =pa, 
Each judgment P Ei = pi can be influenced by previous outcomes. The problem, 
Ville said, is to find “an objective method of verifying the value of 0’s judgments”. 
The problem was taken up in 1950 by Glenn W. Brier, who was engaged in 
training weather forecasters. For Brier, En might be the event that it rains on day 
n. Brier’s work led to a substantial literature [84, 2651. Most of this literature lies 
beyond the scope of this book, because it is concerned with nonlinear methods of 
scoring the forecaster (an extension of our methods to this case is given in [330]). It 
is instructive for us, however, to note the mismatch between the forecasting story and 
the measure-theoretic framework. 

58 
CHAPTER 2: THE HISTORICAL CONTEXT 
How can we put the forecaster’s pn into the measure-theoretic framework? The 
obvious way is to think of each one as the forecaster’s conditional probability given 
all his information at the time he announces it. If forecasts are given for four days, 
we have four such conditional probabilities: 
(2.13) 
where Z, represents all the forecaster’s relevant information (current weather maps, 
previous outcomes, success of previous forecasts, etc.) when he makes the forecast 
for day ri + 1. But the forecaster has not defined a probability measure for which these 
are conditional probabilities. He has not even specified a sample space, which needs 
to include, in addition to the 24 possible outcomes for the sequence El, E2 , E3 , E4, 
some number of alternative outcomes for the information sequence 10 
, 11 , &,Z3. 
We can certainly define a sample space and a probability measure on it that will 
have the conditional probabilities given in (2.13). In fact, there are many ways of 
doing this. But the fcrecaster need not do it, and whether he does it is irrelevant 
to the evaluation of his success. This is the point of the prequential principle, 
which Dawid first proposed in 1984. This principle says that the evaluation of a 
probability forecaster should depend only on his actual probability forecasts and 
the corresponding outcomes. The additional information contained in a Probability 
measure that has these probability forecasts as conditional probabilities should not 
enter into the evaluation, even if the probability measure was actually constructed 
and the probability forecasts were derived from it. 
The word prequential is Dawid’s invention; as he explained, it “combines 
probability forecasting with sequential prediction”. In 1985, Dawid applied the 
principle to infinite sequences of probability forecasts. In subsequent articles, in- 
cluding [85,272], he used it to propose new statistical methods. Unfortunately, these 
methods do not quite comply with the prequential principle; they still depend on 
some mild assumptions about the measure from which one’s probability forecasts are 
derived as conditional probabilities (see Dawid and Vovk 1997). 
Within the game-theoretic framework, we can evaluate probability forecasts in a 
way that complies strictly with the prequential principle. We do not begin with a 
probability measure. We begin only with a sequential game. Forecaster moves by 
giving a probability for rain, based on whatever information he has and wants to 
use, in whatever way he wants to use it. Skeptic bets at thc odds defined by this 
probability, and Reality decides whether it rains. Any strategy for Skeptic that does 
not risk bankruptcy casts doubt on Forecaster’s bona fides if it multiplies Skeptic’s 
initial capital by an unreasonably large factor. But in the end, we will have have only 
n probabilitiespl , 
We will return to the idea of probability forecasting in $7.3, where we consider 
one aspect of the evaluation of probability forecasters (calibration), and at greater 
length in Chapter 8, where we analyze a probability measure for a process as a 
strategy for our player Forecaster in a probability protocol, and where we discuss 
scicntifically important examples of open probability protocols, in which a scientific 
theory provides probability forecasts without defining such a strategy. 
, p,, not a full probability measure for the process El, 

2.6: NEOSUBJECTIVISM 
59 
2.6 NEOSUBJECTIVISM 
We have already mentioned the neosubjectivist 
interpretation of probability associated with 
Bruno de Finetti. De Finetti participated in 
the foundational debates of the 1930s, and in 
subsequent decades his reasoned but uncom- 
promising subjectivism emerged as the leading 
alternative to the vague stochasticism associ- 
ated with the measure-theoretic framework. 
Our most important point of agreement with 
de Finetti, perhaps, is our emphasis on price 
over probability. Like de Finetti and Pascal, we 
begin with prices and derive probabilities. We 
also agree with de Finetti that Kolmogorov’s 
sixth axiom should be regarded as optional. Be- 
cause our experience is finite, infinitary state- 
ments are less fundamental than finitary state- 
ments. 
We do allow Skeptic to combine a 
I h n o  de Finmi (1906-1985) at a re- 
countably infinite set of strategies (see, e.g., 
ception in Rome, around 1958. 
Lemma 3.2, p. 68), but this is much less problematic than Kolmogorov’s sixth axiom, 
because it does not appeal to infinite experience: it is merely a way of obtaining a 
new strategy which can then be used directly, not as a combination of infinitely many 
components. Of course, we do sometimes take advantage of the mathematical clarity 
permitted by the use of infinity, just as de Finetti did. Chapters 3-5, for example, are 
devoted to infinite-horizon games. 
De Finetti also insisted that probability is primarily a choice made by an individual. 
Our framework allows this role of probability to be made absolutely clear: in many 
cases, a probability is a move made by Forecaster. We also speak, however, of 
probabilities that are derived from the structure of the game, as in (1.4) and (1.5). 
The most important point where we differ with de Finetti is in our emphasis on 
upper and lower price. De Finetti was not persuaded that there is anything to be 
gained by generalizing price to possibly unequal upper and lower prices ([93], Vol. 2, 
Appendix 19.3). For him, use of probability required that one assign to each uncertain 
quantity z a price Ez such that one is indifferent between z and Ex. Even here, 
however, de Finetti has had his influence. Our analysis of upper and lower price finds 
antecedents in the work of other authors who were directly inspired by de Finetti: 
Peter M. Williams (1976) and Peter Walley (1991). 
We also differ with de Finetti with respect to the sequential nature of experience, 
which we emphasize more than he did, and Bayes’s theorem, which we emphasize 
less. Bayes’s theorem can be developed in our framework, but we do not develop 
it in this book. Advances in Bayesian statistics in recent decades have vindicated 
de Finetti’s insistence on its usefulness, but other probabilistic learning methods are 
also useful, and we are particularly interested in those that exploit directly the idea 
of a sequential game. 

60 
CHAPTERZ: THE HISTORICAL CONTEXT 
2.7 CONCLUSION 
Let us summarize briefly the most important sources and antecedents for the different 
aspects of our game-theoretic framework. 
1. Pricing by dynamic hedging goes back to Pascal, and our emphasis on the role 
of price in probability is also influenced by de Finetti. 
2. Our understanding of how probability theory can be bridged with the world 
has roots in the thinking of Bernoulli and Cournot, and especially in LCvy’s 
articulation of the principle of‘ practical impossibility. 
3. Our understanding of the hypothesis of the impossibility of a gambling strategy 
has roots in the work of von Mises and Ville. 
4. Our emphasis on testing only using what actually happens is inspired by 
Dawid’s prequential principle. 
As we will explain in Chapter 9, our understanding of dynamic hedging also owes 
a great deal to work in finance theory, from Bachelier to Merton. The reader may 
be able to identify other antecedents of our ideas. The depth, diversity, and number 
of these antecedents demonstrate the richness of the game-theoretic framework and 
helps explain its ability to capture so many of our intuitions about probability. 

3 
The Bounded Strong Law of 
Large Numbers 
In this chapter, we formulate and prove the simplest forms of the game-theoretic 
strong law of large numbers. 
In its very simplest form, the strong law of large numbers is concerned with a 
sequence of events, each with the same two possible outcomes, which we may call 
heads and tails. The law says that as one proceeds in the sequence, the proportion of 
heads converges to one-half almost surely. In symbols: 
(3.1) 
Yn 
1 
lim - = - 
n+cu n 
2 
almost surely, where gn is the number of heads among the first n events. A framework 
for mathematical probability must provide a precise mathematical context for this 
statement, including a mathematical definition of the term almost surely. 
In the measure-theoretic framework, the mathematical context is provided by 
adopting a certain probability measure for the infinite sequence of events: heads has 
probability one-half each time, and the events are independent. The term almost surely 
means except on a set of measure zero. This makes our claim about convergence 
into the precise statement known as Borel’s strong law: the sequences of outcomes 
for which the convergence to one-half fails have measure zero under the specified 
probability measure. 
The game between Skeptic and Reality that we study in this chapter makes the 
claim about convergence precise in a different way. No probability measure is given, 
but before each event, Skeptic is allowed to bet as much as he wants on heads or on 
tails, at even odds. The meaning of almost surely is this: an event happens almost 
surely if Skeptic has a strategy for betting that does not risk bankruptcy and allows 
him to become infinitely rich if the event does not happen. This is all we need: the 
61 
Probability and Finance: It’s Only a Game! Glenn Shafer, Vladimir Vovk 
Copyright 0 2001 John Wiley & Sons, Inc. 
ISBN: 0-471-40226-5 

62 
CHAPTER 3: THE BOUNDED STRONG LAW OF LARGE NUMBERS 
statement that the proportion of heads converges to one-half almost surely is now a 
precise statement in game theory, which we prove in this chapter. 
The preceding paragraph does not mention our fundamental interpretative hypoth- 
esis, which says that Skeptic cannot become infinitely rich without risking bankruptcy. 
As we explained in Chapter 1, this hypothesis stands outside the mathematical theory. 
It has nothing to do with the mathematical meaning of the strong law of large numbers 
or with its proof. It comes into play only when we use the theorem. If we adopt the 
hypothesis for a particular sequence of events, then the statement “the proportion of 
these events that happen will converge to one-half almost surely” acquires a useful 
meaning: we think the convergence will happen. If we do not adopt the hypothesis 
for the particular sequence, then the statement does not have this meaning. 
The game-theoretic formulation is more constructive than the measure-theoretic 
formulation. We construct a computable strategy for Skeptic that is sure to keep 
him from becoming bankrupt and allows him to become infinitely rich if the con- 
vergence of the proportion of heads to one-half fails. Moreover, our formulation is 
categorical-it 
is a statement about all sequences, not merely about sequences outside 
a set of measure zero. Every sequence either results in an infinite gain for Skeptic or 
else has a proportion of heads converging to one-half. 
The game-theoretic formulation has a further unfamiliar and very interesting facet. 
In the folk picture of stochastic reality, outcomes are determined independently of 
how any observer bets. In the game between Skeptic and Reality, in contrast, Reality 
is allowed to take Skeptic’s bets into account in deciding on outcomes. Yet this 
does not prevent Skeptic from constructing a winning strategy. No matter how 
diabolically Reality behaves, she cannot violate the required convergence without 
yielding an infinite gain to Skeptic. 
We do not propose to replace stochastic reality with a rational, diabolical reality. 
We propose, rather, to eliminate altogether from the general theory of probability any 
particular assumption about how outcomes are determined. It is consistent with our 
framework to suppose that Reality is nothing more than the actual outcomes of the 
events-that 
Reality has no strategy, that there is no sense in the question of how she 
would have made the second event come out had the first event come out differently 
or had Skeptic bet differently. By lingering over this supposition, we underline the 
concreteness of the strong law of large numbers; it concerns only our beliefs about a 
single sequence of actual outcomes. But it is equally consistent with our framework 
to imagine an active, strategic Reality. This diversity of possible suppositions hints 
at the breadth of possible applications of probability, a breadth not yet, perhaps, fully 
explored. 
We formalize our game of heads and tails in $3.1. Then, in $3.2, we generalize 
it to a game in which Reality decides on values for a bounded sequence of centered 
variables 5 1 ,  xp, . . . . The strong law for this game says that the average of the first 
N of the x, will converge to zero as N increases. In order to explain this in the 
measure-theoretic framework, we postulate a complete probability distribution for all 
the variables (this amounts to a specification of prices for all measurable functions of 
the variables), and then we conclude that the convergence will occur except on a set of 
measure zero, provided the conditional expectation (given the information available 

3.1: THE FAIR-COIN GAME 
63 
before time n) of each x, is zero. Our game-theoretic formulation dispenses not 
only with the use of measure zero but also with the complete probability distribution. 
We assume only that each xn is offered to Skeptic at the price of zero just before 
it is announced by Reality. Skeptic may buy the x, in any positive or negative 
amounts, but nonlinear functions of the x, need not be priced. This formulation 
is more widely-or 
at least more honestly-applicable 
than the measure-theoretic 
formulation. 
In 53.3, we generalize to the case where the successive variables have prices 
not necessarily equal to zero. In this case, the strong law says that the average 
difference between the variables and their prices converges to zero almost surely. The 
mathematical content of this generalization is slight (we continue to assume a uniform 
bound for the variables and their prices), but the generalization is philosophically 
interesting, because we must now discuss how the prices are set, a question that 
is very important for meaning and application. The diversity of interpretations of 
probability can be attributed to the variety of ways in which prices can be set. 
In 53.4, we briefly discuss the generalization from two-sided prices-prices 
at 
which Skeptic is allowed both to buy and sell-to 
one-sided prices, at which he is 
allowed only to buy or only to sell. If Skeptic is only allowed, for example, to buy 
at given prices, and not to sell, then our belief that he cannot become infinitely rich 
implies only that the long-term average difference between the variables and their 
prices will almost surely not exceed zero. 
In an appendix, 53.5, we comment on the computability of the strategies we 
construct and on the desirability of detailed investigation of their computational 
properties. 
The main results of this chapter are special cases of more general results we 
establish in Chapter 4, where we allow Reality’s moves, the variables x,, to be 
unbounded. For most readers, however, this chapter will be a better introduction to 
the basic ideas of the game-theoretic framework than Chapter 4, because it presents 
these ideas without the additional complications that arise in the unbounded case. 
3.1 
THE FAIR-COIN GAME 
Now we formalize our game of heads and tails. We call it the fair-coin game, but 
not too much meaning should be read into this name. The outcomes need not be 
determined by tossing a coin, and even if they are, there is no need for the coin to 
have any property that might be called fairness. All that is required is that Skeptic be 
allowed to bet at even odds on heads or on tails, as he pleases. 
Skeptic begins with some initial capital, say $1. He bets by buying some number, 
say M ,  of tickets in favor of heads; M may be any real number-positive, 
zero, or 
negative. Each ticket, which sells for $0, pays the bearer $1 if Reality chooses heads, 
and requires the bearer to forfeit $1 if Reality chooses tails. So buying M tickets 
means agreeing to pay $M if Reality chooses tails in order to gain $M if Reality 
chooses heads; if M is negative, then this is really a bet in favor of tails. If we code 
tails as - 1 and heads as 1, then the protocol for the game can be described as follows: 

64 
CHAPTER 3: THE BOUNDED STRONG LAW OF LARGE NUMBERS 
KO = 1. 
FOR n = 1 , 2 , .  . .: 
Skeptic announces hf, E R. 
Reality announces 2 ,  E { -1, l}. 
Ic, := Ic,-1+ 
Mnzn. 
The quantity Ic, is Skeptic's capital just after the bet on the nth toss is settled. 
Skeptic wins the game if (1) his capital Ic, is never negative, and (2) either 
1 "  
lim - C xi = o 
n+oo n 
i= 1 
or 
lim Ic, = co 
n+w 
(3.2) 
(3.3) 
holds. Otherwise Reality wins. 
Equation (3.2) says that the proportion of heads in the first n tosses converges to 
one-half. It is equivalent to (3.1), because cr=l 
2, = 2y, - n. We use (3.2) instead 
of (3.1) only because it is suitable for the more general bounded forecasting game 
that we consider in the next section. 
The rule for determining the winner, given by (3.2) and (3.2), completes our 
specification of thefuir-coin game. It is a two-person, zero-sum, perfect-information 
game. Zero-sum because Skeptic wins if and only if Reality loses. (Since a win 
is conventionally scored as a 1 and a loss as -1, the two players' scores sum to 
zero.) Perfect-information because each player knows all the previous moves when 
he makes his own next move. Here is the strong law of large numbers for this game: 
Proposition 3.1 Skeptic has a winning strategy in the fair-coin game. 
This means the convergence (3.2) occurs almost surely, in the game-theoretic sense 
of this term explained on p. 17 and p. 61. Skeptic has a strategy that forces Reality 
to arrange the convergence if she is to keep him from becoming infinitely rich. To 
the extent that we believe that Skeptic cannot become infinitely rich, we should also 
believe that the convergence will happen. If we adopt the fundamental interpretative 
hypothesis, then we may simply assert that the convergence will occur. 
Some readers might prefer to allow Skeptic to borrow money. Skeptic does not 
need any such concession, however; he has a winning strategy even if he is not 
allowed to borrow. Moreover, allowing Skeptic to borrow would not really change 
the picture so long as there were a limit to his borrowing; allowing him to borrow 
up to $p would have the same effect on our reasoning as changing his initial capital 
from $1 to $(1 + p), and so long as his initial capital is positive, its value makes no 
difference in our reasoning. 
We will prove a generalization of Proposition 3.1 in $3.2. Our proof is constructive; 
we spell out Skeptic's strategy explicitly. The strategy can be described roughly as 
follows: If Skeptic establishes an account for betting on heads, and if at each step 
he bets a fixed proportion 6 of the money then in the account on heads, then Reality 
can keep the account from getting indefinitely large only by eventually holding the 

3.2: FORECASTING A BOUNDED VARIABLE 
65 
average C:=, xi at or below E .  So Skeptic can force Reality to hold the average 
at zero or less by splitting a portion of his capital into an infinite number of accounts 
for betting on heads, including accounts with E that come arbitrarily close to zero. 
By also setting up similar accounts for betting on tails, Skeptic can force Reality to 
make the average converge exactly to zero. 
The rule for determining the winner in our game will seem simpler if we break out 
the two players’ collateral duties so as to emphasize the main question, whether (3.2) 
holds. The collateral duty of Skeptic is to make sure that his capital Ic, is never 
negative. The collateral duty of Reality is to make sure that K,, does not tend to 
infinity. If a player fails to perform his or her collateral duties, he or she loses the 
game. (More precisely, the first player to fail loses. If Skeptic and Reality both 
fail, then Skeptic loses and Reality wins, because Skeptic’s failure happens at some 
particular trial, while Reality’s failure happens later, at the end of the infinite sequence 
of trials.) If both players perform their collateral duties, Skeptic wins if and only 
if (3.2) is satisfied. 
Equation (3.2) is a particular event-a 
particular property of Reality’s moves. We 
can define a whole gamut of analogous games with the same protocol and the same 
collateral duties but with other events in the place of (3.2). In this more general 
context, we say that a strategy forces an event E if it is a winning strategy for Skeptic 
in the game in which E replaces (3.2) as Skeptic’s main goal. We say that Skeptic 
can force E if he has a strategy that forces E-that 
is, if E happens almost surely. 
As we will see in later chapters, Skeptic can force many events. 
3.2 FORECASTING A BOUNDED VARIABLE 
Suppose now that instead of being required to choose heads or tails (1 or - 1) on each 
trial, Reality is allowed to choose any real number x between -1 and 1. This number 
becomes the payoff (positive, negative, or zero) in dollars for a ticket Skeptic can 
buy for $0 before the trial. Skeptic is again allowed to buy any number M of such 
tickets; when he buys a positive number, he is betting Reality will choose x positive; 
when he buys a negative number, he is betting Reality will choose z negative. 
Our new game generalizes the fair-coin game only in that Reality chooses from 
the closed interval [-1,1] rather than from the two-element set {-1,l): 
BOUNDED 
FORECASTING 
GAME WITH FORECASTS 
S E T  TO ZERO 
Players: Skeptic, Reality 
Protocol: 
KO = 1. 
F O R n =  1,2, ... : 
Skeptic announces M ,  E R. 
Reality announces x, E [ - 1,1]. 
Ic, := I c , - 1 +  
Mnx,. 
Winner: Skeptic wins if Ic, is never negative and either (3.2) or (3.3) holds. Other- 
wise Reality wins. 

66 
CHAPTER 3: THE BOUNDED STRONG LAW OF LARGE NUMBERS 
Why do we call this a forecasting game? Who is forecasting what? The answer is 
that we have forecast Reality's move x,,, and the forecast is zero. This forecast has an 
economic meaning: Skeptic can buy x, for zero. In 53.3, we generalize by allowing 
forecasts different from zero, made in the course of the game. These forecasts will 
also serve as prices for Skeptic. 
Because the generalization from the fair-coin game to the bounded forecasting 
game with forecasts at zero involves only an enlargement of Reality's move space, 
the reformulation in terms of collateral duties and the concept of forcing developed 
in the preceding section apply here as well. We refrain from repeating the definitions. 
The game-theoretic strong law of large numbers says that Skeptic can always win 
this game; if Reality is committed to avoiding making him infinitely rich, then he can 
force her to make the average of the x1 2 2 ,  . . . converge to zero. 
Proposition 3.2 Skeptic has a winning strategy in the bounded forecasting game 
with forecasts set to zero. 
Because Proposition 3.2 generalizes Proposition 3.1, our proof of it will establish 
Proposition 3.1 as well. 
The proof of Proposition 3.2 will be facilitated by some additional terminology 
and notation. 
As we explained in 5 1.2, a complete sequence of moves by World is called a path, 
and the set of all paths is called the sample space and designated by R. In the game at 
hand, the bounded forecasting game with forecasts set to zero, World consists of the 
single player Reality, Reality's moves always come from the interval [-1, 11, and the 
game continues indefinitely. So R is the infinite Cartesian product [-ll 11". Each 
path is an infinite sequence xll 
2 2 ,  . . . of numbers in [-1,1]. 
As we said in 1.2, any function on the sample space is a variable. Here this means 
that any function of the xl, 2 2 ,  . . . is a variable. In particular, the 2, themselves are 
variables. 
A situation is a finite sequence of moves by Reality. For example, 21x2 is the 
situation after Reality has chosen 2 1  as her first move and 5 2  as her second move. 
We write Ro for the set of all situations. In the game at hand, Ro is the set of all 
finite sequences of numbers from [-1,1], including the sequence of length zero, the 
initial situation, which we designate by 0. 
We say that the situation s precedes the situation t if t, as a sequence, contains s as 
an initial segment-say 
s = 21x2 . . . x, and t = 21x2 . . . x, . . . 2,. 
We write s C: t 
when s precedes t. If s is a situation and 2 E [-l1 11, we write sx for the situation 
obtained by concatenating s with x; thus if s = x1 . . . x,, then sx = 21 . .. . x,x. If 
s and t are situations and neither precedes the other, then we say they are divergent. 
We write Is/ for the length of s; thus 1212~ z,I 
= n. If E is a path for Reality, 
, we write (" for the situati 
51x2 . . .x,. We say that s begins ( 
whenever s is a situation, ( is a path, and s = En for some n. 
We call a real-valued function on no aprocess. Any process P can be interpreted 
as a strategy for Skeptic; for each situation s, we interpret P(s) as the number of 
tickets Skeptic is to buy in situation s. This definition of strategy puts no constraints 
on Skeptic. In particular, his initial capital does not constrain him; he is allowed to 

3.2: FORECASTlNG A BOUNDED VARIABLE 
67 
borrow money indefinitely. In the games in this chapter, however, a strategy that may 
require borrowing money cannot be a winning strategy for Skeptic. In these games, 
Skeptic loses if his capital becomes negative. If he adopts a strategy that would result 
in a negative capital in any situation, Reality can defeat him by choosing a path that 
goes through that situation. 
In our game, Skeptic begins with the initial capital 1, but we can also consider 
the capital process that would result from his beginning with any given capital KO, 
positive, negative, or zero, and following a particular strategy P. 
As in 5 1.2, we write 
K p  for his capital process when he begins with zero: KP(0) = 0 and 
(3.4) 
When he uses the P with any other initial capital Q, his capital follows the process 
a + K p .  We call a process a martingale if it is of the form Q + K”-that 
is, if it is 
the capital process for some strategy and some initial capital.’ 
The capital processes that begin with zero form a linear space, for /3Kp = KOP 
and Kpl + KP2 = K p 1 f p 2 .  It follows that the set of all capital processes (the set of 
all martingales) is also a linear space. 
If a1 and a2 are nonnegative numbers that add to one, and PI 
and P2 are strategies, 
then the martingale that results from using the strategy alP1 + a2P2 starting with 
capital 1 is given by the same convex combination of the martingales that result from 
using the respective strategies starting with capital 1: 
(3.5) 
We can implement the convex combination in (3.5) by dividing the initial capital 1 
between two accounts, putting a1 in one and a2 in the other, and then applying the 
strategy akPk (which is simply Pk scaled down to the initial capital a k )  to the kth 
account. 
We will also find occasion to form infinite convex combinations of strategies. If 
PI, 
Pz, 
. . . are strategies, a1, a2,. . . are nonnegative real numbers adding to one, 
and the sum czl 
akPk converges, then the sum czl 
a k K p k  will also converge 
(by induction on (3.4)), and 1 + Cy=l a k K P k  will be the martingale the strategy 
Ck=l 
a k P k  produces when it starts with initial capital 1. The strategy xEl a k P k  
starting with 1 is implemented by dividing the initial capital of 1 among a countably 
infinite number of accounts, with Q k  in the kth account, and applying a k p k  to the 
kth account. 
Recall that an event is a subset of the sample space. We say that a strategy P for 
Skeptic forces an event E if 
for every t in Ro and 
Ic P ( ~ 1 ~ 2 . .  
.zn) := K P ( ~ 1 ~ 2 . .  
.zn-l) + P ( x ~ x ~ .  
. .IC,-~)Z,. 
1 + K ‘ I I P 1 + L y ~ P ~  = a1(l + P
I
)
 + a2(l + K P 2 ) .  
00 
P ( t )  > -1 
(3.6) 
‘As we explained in 52.4 (p. 53), we use the word “martingale” in this way only in symmetric probability 
protocols, The protocol we are studying now is symmetric: Skeptic can buy 2,-tickets in negative as well 
as in positive amounts. 

68 
CHAPTER 3: THE BOUNDED STRONG LAW OF LARGE NUMBERS 
for every path E not in E. This agrees with the definition given in 53.1; condition (3.6) 
says that Skeptic does not risk bankruptcy using the strategy starting with the capital 1, 
no matter what Reality does. We say that Skeptic can force E if he has a strategy 
that forces E; this is the same as saying that there exists a nonnegative martingale 
starting at 1 that becomes infinite on every path not in E. 
We say that P weakly forces E if (3.6) holds and every path < not in E satisfies 
supKP(E") = O3. 
n 
By these definitions, any strategy P for which (3.6) holds weakly forces 
supn. K P ( e n )  < 03. 
We say that Skeptic can weakly force E if he has a strat- 
egy that weakly forces E ;  this is the same as saying that there exists a nonnegative 
martingale starting at 1 that is unbounded on every path not in E. 
The following lemma shows that the concepts of forcing and weak forcing are 
nearly equivalent. 
Lemma 3.1 Ifskeptic can weakly force E, then he can force E. 
Proof Suppose P is a strategy that weakly forces E. For any C > 0, define a new strategy 
P(c) by 
P(s) ifKCP(t) < c for all t c 
s 
0 otherwise. 
P ( C ) ( S )  := 
This strategy mimics P except that it quits betting as soon as Skeptic's capital rcaches C. 
Define a strategy Q by 
Then limniM 
KQ(<") = 00 for every < for which sup, K P ( t n )  = 00. Since K p  2 -1, 
K Q  2 -1. Since sup,, K ~ ( < ~ )  
= 00 forevery < not in E ,  limn+M K'(<") = co for every 
6 not in E. So Q forces E. 
I 
Proving Proposition 3.2 means showing Skeptic can force (3.2), and according to 
Lemma 3.1, it suffices to show he can weakly force (3.2). The next two lemmas will 
make this easy. 
Lemma 3.2 If Skeptic can weakly force each of a sequence El, Ez, . . . of events, 
then he can weakly force nEl E k .  
Proof Let P, 
be a strategy that weakly forces E k  . The capital process 1 + K p k  is nonnegative, 
and in our game this implies that it can at most double on each step: 
1 + x C P k  
. . . 2 , )  5 
Since 
5 1 + K p k  (see (3.4)), we can also say that 
IPk(Z1.. 
.2,)1 5 2, 
for all k ,  which implies that a strategy Q can be defined by 
M 
Q := C2-"P,. 
k = l  

3.2: FORECASTING A BOUNDED VARIABLE 
69 
Since p k  weakly forces E k ,  Q also weakly forces Ek. so Q weakly forces nr=lEk. 
I 
Lemma 3.3 Suppose E > 0. Then Skeptic can weakly force 
and 
l n  
lim inf - C xi 2 -6. 
n+m n 
a= 1 
(3.10) 
Proof We may suppose that E < 1/2. The game specifies that the initial capital is 1. Let 
P be the strategy that always buys EQ tickets, where Q is the current capital. Since Reality's 
move z is never less than -1, this strategy loses at most the fraction E of the current capital, 
and hence the capital process 1 + K p  is nonnegative. It is given by 1 + K p ( 0 )  = 1 and 
n 
P 
1 + K P ( X l  . . . x n )  = (1 + K 
( 2 1  . . . xn-l ))(l + E X n )  = n 
(1 +€Xi) 
2=1 
Let E = Z ~ Z Z . .  . be a path such that supn K p(xl  . . . 2,) < 00. Then there exists a constant 
CE > 0 such that 
n 
i=l 
for all n. This implies that 
n 
for all n for some DE. Since ln(1 + t )  2 t - t2 whenever t > - i, E also satisfies 
n 
n 
n 
or 
for all n and hence satisfies (3.9). Thus P weakly forces (3.9). The same argument, with - E  
I 
in place of E, establishes that Skeptic can weakly force (3.10). 
In order to complete the proof that Skeptic can weakly force (3.2), we now simply 
consider the events (3.9) and (3.10) for E = 2Yk, where k ranges over all natural 
numbers; this defines a countable number of events Skeptic can weakly force, and 
their intersection, which he can also weakly force (by Lemma 3.2), is (3.2). 

70 
CHAPTER 3: THE BOUNDED STRONG LAW OF LARGE NUMBERS 
3.3 WHO SETS THE PRICES? 
We have formulated the bounded forecasting game in the simplest possible way. The 
variables xl, 2 2 ,  . . . are all between -1 and 1, and they all have the same price: zero. 
But our proof applies equally well when each variable has a different price, say 2 ,  
has the price m,,, provided only that both x, and m, are uniformly bounded. (In 
fact, it is enough that the net payoffs of the tickets, the differences z, - m,,, be 
uniformly bounded.) Of course, we must then replace (3.2) by 
(3.1 1) 
The price m, can be chosen in whatever manner we please; we require only that it 
be announced before Skeptic places his bet M,. 
As we explained in fj 1.1, the idea that prices can be set freely can be expressed 
within our framework by introducing a third player, Forecaster, who sets them. The 
game then takes the following form: 
BOUNDED 
FORECASTING 
GAME 
Parameter: C > 0 
Players: Forecaster, Skeptic, Reality 
Protocol: 
KO := 1. 
FOR n = 1,2,. . .: 
Forecaster announces m,, E [-C, C]. 
Skeptic announces M, E R. 
Reality announces 5 ,  E [-C, C]. 
K ,  := K,-1 + M,(z, - mn). 
Winner: Skeptic wins if Ic, is never negative and either (3.11) or (3.3) holds. 
Otherwise Reality wins. 
Since Forecaster can always choose the m,, to be zero, and since the bound C can 
be 1, this game generalizes the game of the preceding section. And Proposition 3.2 
generalizes as well: 
Proposition 3.3 Skeptic has a winning strategy in the bounded forecasting game. 
The proof of Proposition 3.2 generalizes immediately to a proof of Proposition 3.3. 
Alternatively, any winning strategy in the game with zero prices can be adapted in an 
obvious way to produce a winning strategy in the game with arbitrary prices. 
We can recover Proposition 3.2 from Proposition 3.3 by setting C equal to 1 
and requiring Forecaster to set each rri, equal to zero. Imposing this constraint 
on Forecaster changes the game (because his move is entirely determined, he is no 
longer really in the game!), but this change obviously does not impair the validity 
of the proposition. A strategy for Skeptic that wins when his opponents, Forecaster 

3.3: WHO SETS THE PRICES? 
71 
and Reality, have complete freedom of action will obviously still win when they are 
constrained, partially or completely. 
We introduce Forecaster, with his complete freedom of action, in order to empha- 
size that how the m, are selected is quite immaterial to the reasoning by which we 
establish the strong law of large numbers. No matter how prices are set, Skeptic has 
a winning strategy. This is not to say that how prices are set is unimportant to users 
of the law of large numbers. On the contrary, the practical significance of the law 
depends both on how the prices m, are determined and on how the outcomes x, are 
determined. And they can be determined in a variety of ways. In physics, the m, 
are furnished by theory, while the x, are furnished by reality. In finance, both m, 
and x, are determined by a market; in many cases, m, is the price of a stock at the 
beginning of day n, and x, is its price at the end of day n. 
It is possible for the price m, to be set by a market even though x, is determined 
outside the market. This happens, for example, in the Iowa Electronic Markets, 
which generate prices for events such as the outcomes of elections. Suppose the 
Iowa Electronic Markets continues to organize trading in contracts for the outcomes 
of U.S. presidential elections into the indefinite future: each November 1 before 
such an election, it determines a price for a contract that pays $1 if the Democratic 
candidate wins. Then the game-theoretic strong law of large numbers tells us that 
either we can become infinitely rich without risking more than $1 or else the market 
is calibrated, in the sense that the long-term average price of the contract approaches 
the long-term relative frequency with which the Democratic candidates win. Of 
course, this is a very idealized statement; we are assuming that the system that pits 
Democrats against Republicans will go on forever, that money is infinitely divisible, 
and that we can neglect transaction costs and bid-ask spreads. But in Chapter 6 we 
will prove a finitary game-theoretic law of large numbers, and the other idealizing 
assumptions can also be relaxed. 
When we say that m, is the price for x, when Skeptic makes his move M,, 
our manner of speaking is consistent with the general definition of price given in 
Chapter 1 (p. 14). Because it is determined by the path 5 1 ,  z2, . . ., we are entitled 
to call x, a variable, and because Skeptic can buy it exactly for m,, we have 
EL 
x, = IE, x, = m, in the situation t where Forecaster has just announced m,. 
In measure-theoretic probability, the strong law for a sequence x1 , z2, . . . of 
variables is formulated beginning with the assumption that the variables have a joint 
probability distribution, and the price m, is the conditional expected value of x, given 
21,. . . , xn-l; the conclusion is that (3.11) holds almost surely. We will leave for 
Chapter 8 the formal derivation of this measure-theoretic result from Proposition 3.3, 
but it is intuitively obvious that our game-theoretic formulation is more powerful, in 
the sense that it arrives at the same conclusion (Equation (3.11) holds almost surely) 
with fewer assumptions. Postulating a joint probability distribution for x1,x2, . . . 
amounts to assuming that for all n, every measurable function of z, 
(and even of 
x,, %,+I, . . .) is priced conditional on the outcomes 21, . . . , x,-1. But the game- 
theoretic formulation assumes only that a price for z, 
itself is given in light of 
xl, . . . , ~
~
-
1
.
 
In the simplest case, where each z, 
has only two possible values, 
heads or tails, there is no difference between pricing the x, and pricing all measurable 
- 

72 
CHAPTER3: THE BOUNDED STRONG LAW OF LARGE NUMBERS 
functions of it. But when each IC, 
can be chosen from a large range of values, the 
difference is immense, and consequently the game-theoretic result is much more 
powerful than the measure-theoretic result. 
As we pointed out earlier, Proposition 3.3 continues to be true when the bounded 
forecasting game is modified by a restriction, partial or complete, on the freedom 
of action of Skeptic’s opponents. When we constrain Forecaster by setting the 
m, equal to a common value m at the beginning of the game, we obtain a game- 
theoretic generalization of the measure-theoretic strong law for the case where the 
zl, z2, . . . are independent random variables with a common mean m. If we then 
constrain Reality to choose z, 
from the set (0, l}, we obtain the game-theoretic 
result corresponding to the measure-theoretic strong law for a possibly biased coin; 
if 1 represents heads and 0 represents tails, then m corresponds to the probability of 
heads on each toss, and (3.1 1) says that c:=l 
z,, the proportion of heads in the first 
R tosses, converges to m. If m = 1/2, then we are back to the fair-coin game with 
which we began the chapter, except that we are using 0 rather than -1 to represent 
heads. 
3.4 ASYMMETRIC BOUNDED FORECASTING GAMES 
Our bounded strong law of large numbers, Equation (3.1 I), can be decomposed into 
two parts: 
(3.12) 
.
n
 
and 
Moreover, the proof of Lemma 3.3 makes it clear that these two parts depend on 
different assumptions. If Skeptic can buy tickets at the prices m,, then either (3.12) 
will hold or else he can become infinitely rich. If Skeptic can sell tickets at the prices 
m,, then either (3.13) will hold or else he can become infinitely rich. 
We can express this point more formally by adapting the game of the preceding 
section as follows: 
BO~JNDED 
UPPER FORECASTING 
GAME 
Parameter: C > 0 
Players: Forecaster, Skeptic, Reality 
Protocol: 
lco := 1. 
FOR R = 1 , 2 , .  . .: 
Forecaster announces m, E [ - C, C]. 
Skeptic announces M, 2 0. 
Reality announces IC, E [-C, C]. 
K, := K,-1 + hfn(z, - mT2). 

3.5: APPENDIX: THE COMPUTATION OF STRATEGIES 
73 
Winner: Skeptic wins if and only if K, is never negative and either (3.12) or (3.3) 
holds. Otherwise Reality wins. 
This is an asymmetric protocol, in the sense explained on p. 11. Using only the first 
half of Lemma 3.3, we obtain our usual result: 
Proposition 3.4 Skeptic has a winning strategy in the bounded upper forecasting 
game. 
The hypothesis of the impossibility of a gambling system, as applied to this game, 
says that the prices m, are high enough that Skeptic cannot get infinitely rich by 
buying tickets. If we adopt this hypothesis, then we may conclude that (3.12) will 
hold for these prices and, a fortiori, for any higher prices. 
We can similarly define a bounded lower forecasting game, in which (1) Skeptic 
selects a nonpositive rather than a nonnegative real number, and (2) Skeptic wins if 
his capital remains nonnegative and either (3.13) or (3.3) holds. Again Skeptic will 
have a winning strategy. 
3.5 APPENDIX: THE COMPUTATION OF STRATEGIES 
The scope of this book is limited to showing how the game-theoretic framework can 
handle traditional questions in probability theory (Part I) and finance theory (Part 11). 
But our results raise many new questions, especially questions involving computation. 
All our theoretical results are based on the explicit construction of strategies, and it 
should be both interesting and useful to study the computational properties of these 
constructions. 
All the strategies we construct are in fact computable. For example, the construc- 
tion in 53.2 is obviously computable, and hence we can strengthen Proposition 3.3 to 
the following: 
Proposition 3.5 Skeptic has a computable winning strategy in the boundedforecast- 
ing game. 
This strengthening is relevant to points we have already made. For example, our 
argument on p. 71 concerning the Iowa Electronic Markets obviously requires that 
Skeptic’s strategy be computable. 
Proposition 3.5 is mathematically trivial, but it suggests many nontrivial questions. 
For example, fixing a computational model (such as the one-head and one-tapeTuring 
machine), we can ask questions such as this: 
Does there exist a winning strategy for Skeptic in the fair-coin game 
such that the move at step n can be computed in time O(nc), for some 
c? If yes, what is the infimum of such c? 
Similar questions, which may be of practical interest when one undertakes to imple- 
ment the game-theoretic approach, can be asked about other computational resources, 
such as the required memory. 

74 
CHAPTER 3: THE BOUNDED STRONG LAW OF LARGE NUMBERS 
In a different direction, we can ask about the rate at which Skeptic can increase his 
capital if the sequence of outcomes produced by Reality in the bounded forecasting 
game does not satisfy (3.1 1). For example, the construction in $3.2 shows that the 
following is true. 
Proposition 3.6 Skeptic has a computable winning strategy in the bounded forecast- 
ing game with the condition (3.3) that his capital tends to infinity replaced by the 
condition 
l o g L  > 
lim sup ___ 
72+03 
n 
that his capital increases exponentially fast. 
It might be interesting to study the trade-off (if any) between the computational 
efficiency of a strategy and the rate at which its capital tends to infinity. 
Questions similar to that answered in Proposition 3.6 have been asked in algo- 
rithmic probability theory: see Schnorr (1970, 1971) in connection with the strong 
law of large numbers and Vovk (1987) in connection with the law of the iterated 
logarithm and the recurrence property. 

Kolmogorov 's Strong Law 
of Large Numbers 
In 1930, Kolmogorov proved a measure- 
theoretic strong law for possibly unbounded 
variables. In this chapter, we reformulate this 
strong law and its proof in game-theoretic 
terms, just as we reformulated the bounded 
strong law in the preceding chapter. 
In our game for Kolmogorov's strong law, 
Reality announces a sequence X I ,  
2 2 ,  . . . of 
real numbers. There is no bound on how large 
Reality can make x,, but just before she an- 
nounces x,, Forecaster announces m, and IJ, 
and makes two offers to Skeptic: 
0 Skeptic can buy x, form,,, and 
0 Skeptic can buy ( 2 ,  - m7L)2 
for v,. 
At this point, the numbers m, and v, are 
the game-theoretic price and variance, respec- 
tively, for 2,. Our game-theoretic version of 
Kolmogorov's strong law says that Skeptic 
can force Reality to satisfy 
Andrei Ko,mogorov (1903-1987) 
4 
Probability and Finance: It’s Only a Game! Glenn Shafer, Vladimir Vovk 
Copyright 0 2001 John Wiley & Sons, Inc. 
ISBN: 0-471-40226-5 

76 
CHAPTER 4: KOLMOGOROV’S STRONG LAW OF LARGE NUMBERS 
if 
00 C3.m. 
n=l 
(4.2) 
Condition (4.2) is necessary as well as sufficient; as we will see, Skeptic can force (4.1) 
if and only if Forecaster makes his w, satisfy (4.2). 
We use “Skeptic can force E” in the same way here as in Chapter 3. It has the 
same meaning as “E happens almost surely”: Skeptic has a strategy that makes 
him infinitely rich without risk of bankruptcy if E does not happen. As always, the 
existence of such a strategy acquires practical meaning in a particular instance where 
the game is played only if we adopt the fundamental interpretative hypothesis for that 
instance, in which case the practical meaning is that we expect E to happen. But in 
this chapter we consider only the mathematical question of the existence of such a 
strategy, leaving aside issues of practical interpretation. 
We put no restrictions on how Forecaster chooses m, and Y, in the course of the 
game. Therefore (4.2), a condition on the w,, cannot be verified at the beginning of 
the game. But our claim that (4.2) is necessary and sufficient for Skeptic to be able 
to force (4.1) can be made precise as follows: 
0 Skeptic has a strategy that always keeps his capital nonnegative and guarantees 
that if Forecaster obeys (4.2), then either Reality obeys (4.1) or Skeptic becomes 
infinitely rich. 
0 The condition that Forecaster obey (4.2) cannot be relaxed. In fact, Reality has 
a strategy that guarantees that if Forecaster violates (4.2) and Skeptic’s capital 
is always nonnegative, then Skeptic does not become infinitely rich and (4.1) 
fails. 
We prove these assertions in $4.2 and 54.3, respectively. The two proofs differ 
somewhat in their logical status. We construct an explicit strategy for Skeptic, 
using ideas from the usual proof of Kolmogorov’s strong law. But we give only 
a very nonconstructive proof of the existence of the strategy for Reality, a proof 
that combines Kolmogorov’s counterexample to (4.1) when (4.2) fails with Martin’s 
theorem, which says that quasi-Bore1 games are determinate. Kolmogorov’s example 
yields a randomized strategy for Reality that wins with probability one. This implies 
that Reality can sometimes win and hence that Skeptic does not have a strategy that 
always wins. Martin’s theorem tells us that there is necessarily a winning strategy 
for one of the two players, and so we conclude that Reality has one. 
In 54.4, we relax the assumption that Skeptic can both buy and sell 5 ,  at the 
price m, to the assumption that he can only buy at that price or only sell at that 
price. The result is the same as we found in the bounded case: one-sided prices 
produce a one-sided bound on the oscillation of the average deviation rather than 
convergence. In $4.5, we show that the game-theoretic version of Kolmogorov’s 
strong law implies analogous strong laws for any symmetric probability protocol and 
for many asymmetric probability protocols. In an appendix, $4.6, we review the 
statement of Martin’s theorem. 

4.7: TWO STATEMENTS OF KOLMOGOROVS STRONG LAW 
77 
Our game-theoretic version of Kolmogorov’s strong law is more powerful than any 
measure-theoretic version, because it does not assume that the variables z1,z2, . . . 
are governed by a probability distribution. Kolmogorov assumed that the variables 
are independent with means ml , m2, . . . and variances w1, v2, . . ., respectively and 
concluded that (4.1) holds except on a set of measure zero if (4.2) holds. He also 
proved a converse: given a sequence of nonnegative numbers ‘u1, v2, . . . violating (4.2) 
and any sequence of numbers ml , m2, . . ., we can construct a probability distribution 
for a sequence 21, 5 2 ,  . . . of independent random variables with means ml , m2, . . . 
and variances 111,212,. . . such that (4.1) is violated except on a set of measure zero. 
The modern measure-theoretic version of his theorem relaxes the assumption of 
independence in the first statement to the assumption that m, and II, 
are the mean and 
variance of z, 
conditional on all the information available before time n, including 
knowledge of z1, 
z2, . . . , z,-1 (a precise statement is given on p. 171). The game- 
theoretic result established in this chapter (Statement 1 of Theorem 4.1) assumes 
still less. It assumes only the existence of prices ml, m2,. . . and v1, 
I I ~ ,  . . ., not the 
existence of an entire probability measure for ~ 1 ,  
z2, . . . . Because it assumes less, it 
implies the measure-theoretic result (see Corollary 8.1 on p. 171). 
4.1 TWO STATEMENTS OF KOLMOGOROV’S STRONG LAW 
We now state our game-theoretic version of Kolmogorov’s strong law precisely. We 
do this in two slightly different ways. First, we consider a game that Skeptic wins 
if (4.1) happens; here the game-theoretic strong law says that Skeptic can win if 
Forecaster obeys (4.2), while Reality can win if Forecaster violates (4.2). Then 
we formulate two different games, one that Skeptic can win playing against Reality 
and Forecaster together, and one that Reality can win playing against Skeptic and 
Forecaster together. 
The Unbounded Game 
Our game-theoretic version of Kolmogorov’s strong law says that Skeptic has a 
strategy that wins the following game if Forecaster makes his II, 
satisfy (4.2). 
UNBOUNDED FORECASTING 
GAME 
Players: Forecaster, Skeptic, Reality 
Protocol: 
KO := 1. 
FOR n = 1,2, . . .: 
Forecaster announces m, E R and v, 2 0. 
Skeptic announces M ,  E R and V, 2 0. 
Reality announces z, 
E R. 
(4.3) 
Winner: Skeptic wins if Ic, is never negative and either Ic, tends to infinity or 
else (4.1) holds. Otherwise Reality wins. 
2 
Kn := Kn-1 + Mn(zn - m,) + Vn((zn - mn) - U n ) .  

78 
CHAPTER 4: KOLMOGOROVS STRONG LAW OF LARGE NUMBERS 
This resembles the bounded forecasting game we studied in $3.3. Forecaster again 
has the task of forecasting Reality’s move 2,. 
But now he does so with two numbers 
instead of one: 
0 m,, is his forecast of x,, and 
0 II,, is his forecast of (2, - 7 r ~ , ) ~ ,  
the squared error in his forecast of x,,. 
Skeptic may use both forecasts as prices. He may buy any number (positive, negative, 
or zero) of x,,-tickets and any nonnegative number of (2, - rn,,)2-tickets. We write 
0 M ,  for the number of x,-tickets he buys, and 
0 
for the number of (x, - m,)’-tickets 
he buys. 
Skeptic’s total net gain is the sum of his net gains from the two kinds of tickets: 
0 J/lL(x, - mrL) from the 2,-tickets, and 
0 %,((z, - VL,)~ - v,) from the (z, - rn,)2-tickets. 
So (4.3) is his capital after Reality announces 5,. 
unbounded forecasting game. 
Proposition 4.1 
Here is one way of saying what Skeptic and Reality can each achieve in the 
1. Skeptic has a strategy that assures that he wins if(4.2) holds. 
2. Reality has a strategy that assures that she wins if(4.2) fails. 
Statement 1 of Proposition 4.1 generalizes Proposition 3.2, which asserts that 
Skeptic has a winning strategy in the bounded forecasting game. This becomes clear 
if we consider the following constraints on Reality and Forecaster: 
0 Reality must choose x, from [-C, C]. 
0 Forecaster must choose rn, from [-C, C] and must set each v, equal to 10C2. 
Constraining Reality and Forecaster in this way can only make it easier for Skeptic 
to win the game; so Statement 1 will remain true. But now Skeptic will never buy 
(xrL - nL,,)’-tickets, because he would necessarily lose money on them. So we can 
remove them from the description of the game, reducing it to the bounded forecasting 
game. And since Equation (4.2) is satisfied when the 21, are all equal to 10C2, we 
can drop it as a condition in Statement 1, which thereby becomes identical with 
Proposition 3.2. 
The rule for determining the winner of our unbounded forecasting game can 
be reformulated in terms of collateral duties, in the same way as in the bounded 
forecasting game. Keeping K ,  nonnegative is Skeptic’s collateral duty, and keeping 
K ,  from tending to infinity is Reality’s collateral duty. A player loses as soon as 
he or she fails to perform his or her collateral duties. If both players perform their 
collateral duties, then Skeptic wins if (4.1) holds, and Reality wins if it fails. 

4.1: TWO STATEMENTS OF KOLMOGOROV'S STRONG LAW 
79 
The Unbounded Protocol 
By dropping the particular goal (4.1) from our unbounded forecasting game, we 
obtain this protocol: 
UNBOUNDED 
FORECASTING 
Players: Forecaster, Skeptic, Reality 
Protocol: 
IcO := 1. 
FOR n = 1,2,. . .: 
Forecaster announces m, E R and v, 2 0. 
Skeptic announces M, E R and Vn 2 0. 
Reality announces z, 
E R. 
Ic, := Icn-1 + Mn(zn - mn) + Vn((zn - m,) - v,). 
Collateral Duties: Skeptic must keep Ic, nonnegative. Reality must keep Ic, from 
tending to infinity. 
We can make this protocol back into a game by providing Skeptic with some other 
goal-some 
other event E. The complement EC of E then becomes Reality's goal. 
Skeptic wins if he performs his collateral duty and either E happens or Reality fails 
to perform her collateral duty. Reality wins if either (1) Skeptic fails to perform his 
collateral duty or (2) Reality performs her collateral duty and her goal EC 
happens. 
What exactly is an event E for this protocol? In general, as we learned in 
5 1.2, an event is a subset of the sample space and so consists of paths formed by 
possible sequences of moves by World. Here World consists of Reality together with 
Forecaster, and a path of their moves is a sequence m~u1z1m2v2z2 . . ., with the u, 
all nonnegative. So an event E is any set of sequences of this form. If we take E to 
be the set of sequences mlv121m2v252 . . . that satisfy (4.1), then we are back to the 
unbounded forecasting game with which we began. 
We can speak of both Skeptic and Reality fmcing events. A strategy for Skeptic 
forces an event E if it is a winning strategy for Skeptic when E is Skeptic's goal. 
A strategy for Realityforces E if it is a winning strategy for Reality when E is her 
goal. We say that a player, Skeptic or Reality, canforce E whenever he or she has 
a strategy that forces E. Notice that if one of the two players can force E, then the 
other cannot force EC. 
With these definitions, Proposition 4.1 can be strengthened to the following: 
Theorem 4.1 
I .  Skeptic can force 
'Here we use =$ for material implication: if E and F are events, then E ==+ F is the event that F 
holds if E holds. Since these events are 5ets (of sequences of moves by Forecaster and Reality), we can 
write ( E  j 
F )  = EC 
U F .  

80 
CHAPTER 4: KOLMOGOROVS STRONG LAW OF LARGE NUMBERS 
2. Reality can force 
Statement 1 of Theorem 4.1 is completely equivalent to Statement 1 of Proposition 4.1. 
But Statement 2 of Theorem 4.1 is stronger than Statement 2 of Proposition 4.1. The 
strategy for Reality mentioned in Statement 2 of Proposition 4.1 need not accomplish 
anything when (4.2) holds, but a strategy for Reality that validates Statement 2 of 
Theorem 4.1 must satisfy Reality’s collateral duty whether (4.2) holds or not. 
We can imagine that Forecaster is doing the bidding of Reality when we interpret 
Statement 1 of Theorem 4.1; since Skeptic can force (4.4) no matter what the other 
players do, he can do so even if Reality is allowed to set the prices as well as determine 
the outcomes. Similarly, we can think of Forecaster as doing the bidding of Skeptic 
when we interpret Statement 2; Reality can force (4.5) even if Skeptic is allowed to 
set the prices. 
Statement 2 of Theorem 4.1 is equivalent, in light of Martin’s Theorem, to the 
statement that Skeptic does not have a winning strategy in the game in which Reality 
has (4.5) as her goal, even if he is allowed to set the prices. In other words, he cannot 
force 
(4.6) 
1 ”  
ca C?=cc 
V n  
lim -‘jJzI-mI)=o 
n+m n 
n=l 
t=l 
even if he is allowed to set the prices. We can restate Theorem 4.1 as a whole by 
saying that Skeptic can force (4.4) even if Reality sets the prices but cannot force 
(4.6) even if he sets the prices himself. 
The unbounded forecasting protocol, as we have formulated it, requires both v, 
and V, to be nonnegative. No generality is lost by requiring that v, be nonnegative; it 
is a forecast of the nonnegative quantity (z, - m,)2, and if it is negative Skeptic can 
make as much money as he wants. The requirement that V, be nonnegative requires 
more explanation; it means that Skeptic is allowed only to buy ( 2 ,  - m,)’-tickets, 
not to sell them. He can bet that u, is too low a price, but not that it is too high a price. 
This means that v, is only the upper price for (2, - m,)2-only 
the upper variance 
for 5,. In fact, Theorem 4.1 remains true if we change the protocol by allowing 
Skeptic to make V, negative, so that v, becomes the game-theoretic variance for z, 
rather than merely the game-theoretic upper variance. We have chosen to state the 
theorem in the form in which the 71, are merely upper variances because this broadens 
its applicability to include practical problems where it is much more reasonable to 
set upper bounds on squared errors than to set two-sided prices for them. 
We will prove both forms of the theorem. Our proof of Statement 1, in 54.2, 
assumes that Skeptic must make V, nonnegative, but it also applies when this restric- 
tion is lifted, because increasing Skeptic’s freedom cannot make it harder for him to 
have a winning strategy. Similarly, our proof of Statement 2, in $4.3, assumes that 
Skeptic’s choice of the V, is not restricted, and it then applies to the other case as 
well, because limiting Skeptic’s freedom cannot make it harder for Reality to have a 
winning strategy. 

4.2: SKEPTIC’S STRATEGY 
81 
4.2 SKEPTIC’S STRATEGY 
We now prove Statement 1 of Theorem 4.1 by constructing the required strategy for 
Skeptic. Our proof is similar to the usual proofs of Kolmogorov’s strong law; it uses 
a form of Doob’s martingale convergence theorem. 
For simplicity, we suppose that Forecaster is required to set all the m, to zero. 
This involves no loss of generality, because any strategy for Skeptic that forces 
when Forecaster is required to set the m, equal to zero can easily be adapted to yield 
a strategy that forces (4.4) when Forecaster is free to make the rn, nonzero. 
Apath is now a sequence of numbers ~ 1 x 1 ~ 2 ~ 2  
. . . with the v, nonnegative. As 
usual, an event is a set of paths, and a variable is a function on the paths. A situation is 
a finite sequence of numbers ~ 1 x 1  
. . . v,x, 
with all v, nonnegative, and aprocess is a 
function on the situations. If ( designates a path ~ 1 x 1 ~ 2 ~ 2  
. . . and n is a nonnegative 
integer, then En designates the situation v1 x1 . . . v,x,. 
We extend situations freely by 
appending additional numbers or sequences of numbers; whenever a and b designate 
numbers or finite sequences of numbers, ab designates the result of concatenating the 
two with b on the right. 
Following the usual practice in probability theory, we sometimes identify a process 
S with the sequence SO, 
S1, . . . of variables defined by 
S,(Q := s(c$7L). 
The first of these variables, SO, is always constant: 
for all (. 
A process A is predictable if for every integer n greater than or equal to one, 
An(v1zlv2x2 . . .) does not depend on x,. When we are dealing with a predictable 
process A, we will sometimes abbreviate A(vlx1 . . . v,x,) 
to A(wlx1 . . . v,). A 
strategy for Skeptic consists of two predictable processes, a process M that specifies 
the number M(vlxl . . . v,) of 2,-tickets Skeptic buys, and a process U that specifies 
the number V(vlxl . . . v,) of x2-tickets he buys. A pair ( M ,  V )  of predictable 
processes qualifies as a strategy for Skeptic provided only that V is nonnegative.2 
2Representing a strategy for Skeptic in this way, as a pair of predictable processes ( M ,  V ) ,  is awkward 
in one respect: the values M ( 0 )  and V ( 0 )  are superfluous; we can specify them arbitrarily since they 
do not specify moves for Skeptic. Notice also that this way of representing a strategy differs from the 
approach we used in the simpler setting of 53.2, where there was no Forecaster. There the value P(s) of 
a strategy P was the move by Skeptic that combined with Reality’s move to produce Skeptic’s capital in 
the situation following s. Now ( M ( s ) ,  
V ( s ) )  is the move by Skeptic that combines with Reality’s move 
(and Forecaster’s preceding move) to produce Skeptic’s capital in the situation s itself. 

82 
CHAPTER 4: KOLMOGOROV’S STRONG LAW OF LARGE NUMBERS 
Skeptic’s capital process is determined by his initial stake and strategy according 
to Equation (4.3). If the initial stake is 0 and the strategy is P = ( M ,  V ) ,  then the 
capital process is K P ,  where 
KP(0) := 0 
+M(viccl...v,)z,+V(vlzi...v,)(z~ - ~ n ) .  
If the initial stake is cy instead of 0, then the capital process is cy + K P .  
In the bounded forecasting game, we called capital processes martingales (see 
p. 67). Here we do not call them martingales, because they lack an important 
property that is often associated with the word “martingale”: the fact that S is a 
capital process does not imply that -S is also a capital process. This is because 
the protocol is asymmetric: Skeptic cannot make V, negative. In $4.5, where we 
derive Kolmogorov’s strong law for an abstract symmetric protocol, we will again 
call capital processes “martingales”. 
Lemma 4.1 The capital processes form a convex cone: ifS1 , . . . , SK are capital 
processes and c1 2 0, . . . , C K  2 0, then clS1 + . . . + C K S ~  
is a capital process. 
Proof If sk is the capital process resulting from the initial stake Lyk and the strategy 
( M k ,  
V‘), k = 1,. . . , K ,  then CIS’ + . . + cfi-SK is the capital process resulting from 
the initial stake cia1 + . . . + C K O K  and the strategy 
(QM’ + . . .  + c,yMK, civ’ + , .. + C K V ~ ) .  
I 
A supermartingale is a process of the form S - B, where S is a capital process 
and B is an increasing process. (A process B is increasing if a,(<) 5 
( E )  for 
all n and all E. A process that is identically equal to zero qualifies as increasing, 
and hence a capital process itself qualifies as a supermartingale.) We can think of 
S - B as the capital for Skeptic were he to follow the strategy that produces S but 
were also to throw money away on each round; B records the cumulative amount of 
money thrown away. If we write 7 for S - B, then the fact that B is increasing can 
be expressed by the inequality 
IJ;2fl(t) 
- ZL(E) 5 Snfl(0 - Sn(E), 
which holds for all 71 and all E; the increments for ‘7- are smaller than the increments 
for S because of the money thrown away. We call S a bounding capital process for 
the supermartingale 7, and we call a strategy ( M ,  V )  that generates S (wilh the help 
of some initial stake) a bounding strategy. 
If a nonnegative supermartingale 7 tends to infinity on a path, then any bounding 
capital process with initial stake 7( 
0) is also nonnegative and also tends to infinity 
on that path. So we can substitute nonnegative supermartingales for nonnegative 
capital processes in the definition of “almost surely”: An event E happens almost 
surely if and only if there exists a nonnegative supermartingale that tends to infinity 

4.2: SKEPTIC'S STRATEGY 
83 
on every path in EC. We also say that any such nonnegative supermartingale is a 
witness of the almost certain happening of E. 
Lemma 4.2 The supermartingales form a convex cone: if TI, . . . , TK are super- 
martingales and c1 > 0, . . . ] C K  > 0, then cl'T1 +. . . + C K r K  is a supermartingale. 
Proof If Tk = Sk - Bk, where the Sk are martingales and the Bk are increasing, then 
c17-1 + ' ' .  + C K 7 K  = ( C l S '  + ' ' .  + C K S K )  - ( C l B '  + . ' ' + C K B K ) .  
I 
Given a supermartingale 7- we define a predictable process 117-1 by 
(4.8) 
llTll(su) := inf{ 11(M, V)ll : V is nonnegative, and 
'T(svx) - r(s) 
5 M X  + ~ ( 2  
- u) for all x E R} 
for every situation s and every nonnegative number 'u. Here 11 . 11 is the usual norm 
for two-dimensional Euclidean space: ll(M, V)ll = d w . 3  
We say that a 
bounding strategy ( M , V )  for 'T is minimal if llM(s),V(s)ll = 11T(s) for all 
s # 0. 
Lemma 4.3 Every supermartingale has a minimal bounding strategy. 
Proof It suffices to show that the infimum over M and nonnegative V in (4.8) is attained 
for fixed s and v. Let p(z) denote the closed subset of R2 consisting of all ( M ,  V), with 
V nonnegative, that satisfy the inequality in (4.8) for x. Since 7- has at least one bounding 
strategy, the intersection of the p(z) over all z is nonempty. As the intersection of closed sets, 
I 
it is closed. So it has an element closest to the origin. 
Lemma 4.4 Suppose rl, P,. 
. . is a sequence ofnonnegative supermartingales and 
c1, cz,. . . is a sequence of nonnegative numbers such that 
k=l 
W 
and 
k=l 
for every situation s. Set 
W 
k=l 
Then 7 is a nonnegative supermartingale and 
W 
k=l 
(4.9) 
(4.10) 
(4.1 1) 
3The choice of this norm is arbitrary; many other norms would work just as well. We may also specify 
ll7li's value at 0 arbitrarily; say 11711(0) := 0. 

84 
CHAPTER 4: KOLMOGOROV'S STRONG LAW OF LARGE NUMBERS 
Proof Choose a minimal bounding strategy ( M k ,  V k )  for each T k  and set 
m 
m 
,"f := E C k M ' ;  v := E C k V k .  
k = l  
k = l  
(It is clear from (4.10) that the series defining M and V converge to finite numbers at every 
situation.) 
Let us prove that 7, < 03 for every n; since 5 < 03 by (4.9), it is sufficient to prove that 
Tn+l < 00 assuming 7n < 03, where n = 1 , 2 , .  . . . Summing the inequality 
T k ( s v z )  - 7"s) 5 M k ( s ) z  + V k ( s ) ( z 2  - u )  
7(svz) - T(s) 5 M ( s v ) z  + V(sv)(z2 - v), 
(cf. (4.8)) multiplied by Ck over k ,  we obtain 
(4.12) 
which shows that T(svz) is finite as soon as T ( s )  is finite. 
Equation (4.12) also shows that ( M ,  V )  bounds 7, and so equation (4.1 1) follows from 
Now our argument will follow Liptser's proof of Kolmogorov's strong law [287]. 
The next step is to establish a version of Doob's convergence theorem for our game- 
theoretic nonnegative supermartingales. Doob's theorem asserts that a nonnegative 
measure-theoretic supermartingale converges almost surely in the sense of measure 
theory-that 
is, except on a set of measure zero. Our version asserts that a nonnegative 
game-theoretic supermartingale converges almost surely in our sense-that 
is, there 
is another nonnegative game-theoretic supermartingale that tends to infinity on all 
paths where the convergence fails. 
Lemma 4.5 If7 is a nonnegative supermartingale, then 7, converges4 almost surely. 
Proof [Doob] We will prove the lemma by constructing a witnessing nonnegative 
supermartingale-a 
nonnegative supermartingale 7' that tends to infinity on every path 
where 7 does not converge. 
Choose a minimal bounding strategy P = ( M ,  V )  for 7. Let a, b be positive rational 
numbers such that a < b. Set TO := 0 and, fork = 1 , 2 , .  . ., set 
Uk := min{i > T k - 1  : Z > b}, 'rk := min{i > U k  : Z < a}. 
Let Palb be the strategy given by 
4We say a sequence converges when it has a finite limit. 

4.2: SKEPTIC'S STRATEGY 
85 
and let Tavb 
be the nonnegative martingale T( 0) + lCpa'*. It is easy to see that 
%a,b = 70, llra2bll 5 11711, 
and always 
liminf,,, 
7, < a 
limsup,,, 
7, > b 
Arrange all such pairs (a, b) in a sequence (al, b l ) ,  (az, bz), . . . and put 
k = l  
By Lemma 4.4, 7' is a nonnegative supermartingale with 
(4.13) 
(4.14) 
We need to show that if 7, does not have a finite limit, then 7," tends to infinity. But (4.14) 
implies that if 7, tends to infinity, then 7,' does as well. And 7, having no limit at all is 
eauivalent to 
3(a, 
b) E @: liminf 7, < a & limsup7, > b, 
n+m 
n + w  
and by (4.13) and (4.14), this implies that 7,' tends to infinity. 
I 
Almost certain convergence also holds for processes that can grow faster than 
nonnegative supermartingales but in a limited and predictable way. To explain this, 
we need another definition. A semimartingale is a process that can be written in the 
form U = 7 + A, where 7 is a supermartingale and A is an increasing predictable 
process; the process A is called a compensator for U. 
Lemma 4.6 IfU is a nonnegative semimartingale with A as a compensator; then 
(A, isjinite) ===+ (Un converges) 
(4.15) 
almost surely. (Here A, is the limit, jinite or injinite, of the increasing process An.) 
Proof Set 7 := U - A; 7 is a supermartingale. For C = 1,2, . . ., define the nonnegative 
supermartingales TC by the requirements Gc = C and 
(Aa, stands for a, -  an-^). Since ~ ~ ' T c ~ ~  
5 IlTIl, Lemma 4.4 implies that 
R := c 
2-"(7C)*, 
C=l 
where * is the transformation (4.14), witnesses that (4.15) holds almost surely. 
(4.16) 
(4.17) 
I 

86 
CHAPTER 4: KOLMOGOROV'S STRONG LAW OF LARGE NUMBERS 
Lemma 4.7 Suppose S is a supermartingale and S2 is a semimartingale with com- 
pensator A. Then 
(A, isjnite) -----r' (S, converges) 
almost surely. 
Proof If A is a compensator of S2, then A is a compensator of (S + 1)' as well. By 
Lemma 4.6, S: and (S, + 1)' converge when A, < 00, almost surely. It remains to note 
that 
I 
To conclude our proof that Skeptic has a winning strategy, consider the capital 
process 
and the increasing predictable process 
The difference 
is itself a capital process, and hence S2 is a semimartingale with A as its compensator. 
Applying Lemma 4.7, we deduce that 
co 2 < 03 ===+ (g 2 
exists and is finite 
n= 1 
almost surely. It remains only to apply Kronecker's lemma (see, e.g., [287]), which 
implies that 
(5 
2 exists and is finite 
n=1 
i=l 
This completes the proof. 
Implicit in this proof is the construction of a nonnegative supermartingale that 
tends to infinity on all paths outside the event (4.4). The following proposition 
specifies this supermartingale explicitly. 

4.3: REALITY‘S STRATEGY 
87 
Proposition 4.2 The following nonnegative supermartingale tends to infinity on all 
paths outside the event (4.4): 
5 
2YC ( s C ) *  + 5 
2TC (P)*, 
c= 
1 
C=l 
where S and 7 are the supermartingales de$ned b y  
n 
i=l 
i= 1 
the operation 7 + Tc is dejined b y  (4.16) with 
and * is the transformation (4.14). 
Proof If (4.4) is violated, then 
-
n
 
and 
1 
xi does not converge to 0. 
i=l 
(4.18) 
(4.19) 
By Kronecker’s lemma, Equation (4.19) implies 
2 7 
does not converge. 
(4.20) 
2 = 1  
As seen from the proof of Lemma 4.7, Equation (4.20) implies the disjunction of the events 
(2 ?) does not converge 
2 = 1  
and 
2 
does not converge. 
Now Equation (4.17) implies that the supermartingale (4.18) witnesses that (4.4) holds almost 
surely. 
I 
4.3 REALITY’S STRATEGY 
We turn now to Statement 2 of Theorem 4.1: Reality has a strategy that forces (4.5). 
We will prove this nonconstructively, by first showing that she has a randomized 

88 
CHAPTER 4: KOLMOGOROV’S STRONG LAW O f  LARGE NUMBERS 
strategy that wins with probability one. This implies that Skeptic and Forecaster do 
not have a winning strategy and hence, by Martin’s theorem, the other player, Reality, 
does have a winning strategy. Martin’s theorem applies because the event Skeptic 
and Forecaster are trying to make happen is quasi-Borel. 
As in the preceding section, we assume without loss of generality that Forecaster 
always sets m,, equal to zero. A strategy that always wins for Reality in this case 
can easily be adapted to a strategy that always win for Reality in the general case; we 
simply replace each move 5, the strategy recommends by 2 ,  + m,. 
The randomized strategy for Reality we use was devised by Kolmogorov (1930): 
ifv, < n2, 
vn/(2n2) 
2 ,  := ( ) with probability ( wn/(2n2) ) , 
1 - vn/n2 
respectively; if v, 2 n2, 
( )’ 
5 ,  := ( “ln ) with probability 
- Jvn 
Suppose Reality plays this strategy while Skeptic plays some (nonrandomized) strat- 
egy with a nonnegative capital process K,. 
Equation (4.3) implies that K, is a 
measure-theoretic martingale, and hence it tends to 00 with measure-theoretic prob- 
ability 0. In order to win against Reality, Skeptic and Forecaster must make 
( K ,  tends to infinity) or 
,--too n i=l 
happen always. Since they can make K ,  tend to infinity only with probability zero, 
they must make 
C$=m& 
n 3 m  
lirn - - C ~ , = O  
n. 1 ,  
00 
n= I 
z= 1 
happen with probability one. 
But the Borel-Cantelli-LCvy lemma (see, e.g., 
[287]) shows that with probability one Cnv,/n2 = co (or, equivalently, 
c, min(zr,/n2, l/2) = 00) implies that )x,) 2 n for infinitely many n and 
hence that limn+m 
So Skeptic and Forecaster lose with 
probability one. 
There is one hole in our argument. Doob’s inequality and the Borel-Cantelli-LCvy 
lemma require that the objects to which they are applied, Ic,, v?,, and 2 ,  in this case, 
be measurable. It is not quite obvious that they are, because these objects depend 
on Skeptic’s and Forecaster’s strategy, which is not assumed to be measurable. We 
can plug this hole simply by placing the argument in a probability space (0,3, 
P) so 
simple that the required measurability cannot be avoided. We set 0 := { -1, 0, l}“, 
0 
if w,, = 0 
c:=l 
2, = 0 fails. 
fn 
+Jv, 
if w, = dzl and v, < n2 
if w, 
= f l  and w, 2 n2, 

4.4: THE UNBOUNDED UPPER FORECASTING PROTOCOL 
89 
where w = wlw2 . . . E 0, 3 is the usual a-algebra on 0, and 
{ v,{?;') 
ifv, < n2 
otherwise, 
p(w, = 1 I 3,-1) 
:= p(w, = -1 I &-I) := 
where 3, is the a-algebra generated by w1, . . . , w,. 
Reality's moves 2 ,  are F,- 
measurable, and the other players' moves, v,, M,, and V,, are F,_l-measurable; 
therefore, Ic, is F,-measurable. 
4.4 THE UNBOUNDED UPPER FORECASTING PROTOCOL 
In the preceding chapter (§3.4), we showed that the bounded strong law can be 
generalized to a one-sided strong law when Skeptic is allowed only to buy, not to 
sell, %,-tickets. The unbounded strong law generalizes in the same way. 
For the generalization, we modify the unbounded forecasting protocol (p. 79) by 
adding the requirement that M, > 0. We call this the unbounded upper forecasting 
protocol; it allows Skeptic to buy only nonnegative amounts of 2,-tickets and also 
only nonnegative amounts of ( 2 ,  - rn,)2-tickets. 
Proposition 4.3 Skeptic can force 
00 
.
n
 
in the unbounded upper forecasting protocol. 
Proof As usual, we assume without loss of generality that Forecaster is required to set 
m, = 0 for all n. We then need to show that Skeptic has a strategy that forces 
(4.21) 
Suppose for the moment that Skeptic is allowed to buy negative as well as nonnegative numbers 
of 2,-tickets. We can then suppose with no loss of generality that Reality always chooses a 
nonnegative value for 2" whenever Skeptic buys a negative number of x, -tickets. By doing so, 
Reality both decreases Skeptic's capital and makes violating (4.21) easier, and so any strategy 
for Skeptic that defeats Reality when she plays under this constraint will defeat her regardless. 
We also know that Skeptic has a winning strategy-the 
one we constructed for him in 34.2. 
It forces (4.21) because it forces (4.7). This strategy may sometimes recommend buying a 
negative number of zn-tickets. But since Reality will make z, 
nonnegative in these cases, 
Skeptic will do better by changing any such negative values to zero, and the resulting strategy, 
which will consequently still force (4.21), does qualify as a strategy in the present game. 
I 

90 
CHAPTER 4: KOLMOGOROVS STRONG LAW OF LARGE NUMBERS 
4.5 A MARTINGALE STRONG LAW 
Theorem 4.1 is set in a very specific probability protocol: the unbounded forecasting 
protocol. But as we show in this section, it implies an abstract strong law of large 
numbers, which applies to martingales in any symmetric probability protocol and to 
supermartingales in a broad class of asymmetric probability protocols. 
Recall that a probability protocol involves two players, Skeptic and World. On 
each round, World moves after Skeptic, and their two moves together determine a 
gain for Skeptic (see 5 1.2 and 58.3). We sometimes divide World into two players: 
0 Reality, who announces (when World moves, after Skeptic’s nth move) the 
aspects of World’s nth move that are relevant to Skeptic’s nth payoff, and 
0 Forecaster, who announces (just before Skeptic’s nth move, because the Skeptic 
has no need for the information earlier) the aspects of World’s first n - 1 moves 
that are relevant to Skeptic’s nth payoff. 
(See 5 1.1 .) If we then make the simplifying assumption that Skeptic’s gain function 
and the three players’ move spaces do not change from round to round, we can 
describe the protocol as follows: 
C O N S T A N T  MOVE S P A C E S  A N D  GAIN FUNCTION 
Parameters: F, S, R, X 
Players: Forecaster, Skeptic, Reality 
Protocol: 
KO := 1. 
FOR TL = 1 , 2 , .  . .: 
Forecaster announces f, E F. 
Skeptic announces s, E S. 
Reality announces r, E R. 
Icn := Kn-1 + X(fn, s,, rn). 
Collateral Duties: Skeptic must keep Ic, nonnegative. Reality must keep Ic, from 
tending to infinity. 
We assume that the gain function and move spaces are constant only to make the 
notation manageable; our results (Propositions 4.4 and 4.5) and their proofs can be 
extended, merely by elaborating the notation, to the general case where the gain 
function and move spaces may depend on the situation (the previous moves of 
Forecaster and Reality). 
With the notation used here, a situation is a finite sequence fir1 . . . fnrn. Apath 
is an infinite sequence, flr1f2rz . . . . An event, as usual, is a set of paths. Fixing 
an event E as Skeptic’s goal makes the probability protocol into a probability game: 
Skeptic wins if the goal happens and he performs his collateral duty. As usual, we 
say that a strategy for Skeptic forces E in the protocol if it is a winning strategy in 
this game, and we say that E happens almost surely if Skeptic has a strategy that 
forces E. The concepts of supermartingale, predictable process, semimartingale, 
and compensator apply here as well. 

4.5: A MARTINGALE STRONG LAW 
91 
We begin with the symmetric case. Recall that a probability protocol is symmetric 
if Skeptic can take either side of any gamble (p. 11). Here this means that S is a 
linear space and X(f, s, r) is linear in s. In this case, the capital processes for Skeptic 
also form a linear space (any initial capital is allowed). In particular, if S is a capital 
process for Skeptic, then so is -S. We call the capital processes in a symmetric 
probability protocol martingales (cf. p. 67 and p. 82). 
In a symmetric probability protocol, the compensator of the square of a martingale, 
when it exists, has an interpretation that generalizes the idea of quadratic variation in 
measure-theoretic probability. We say that an increasing predictable process A is a 
quadratic supervariation for a martingale S if there exists a martingale K: such that 
(S(sfr) - S(s))’ - (A(sf) - A(s)) 5 IC(sfr) - K ( s )  
(4.22) 
for all situations s and all f E F and r E R. The idea behind the name “quadratic 
supervariation” is that the right-hand side of (4.22), as the increment of a martingale, 
is expected to be about zero on average, so that the increment of A is roughly an 
upper bound, on average, on the square of the increment of S. The relation between 
the idea of compensator and that of quadratic supervariation is made precise by the 
following lemma. 
Lemma 4.8 I f  S is a martingale in a symmetric probability protocol, then the fol- 
lowing conditions are equivalent. 
1. A is a quadratic supervariation jor S. 
2. S2 is a semimartingale with A as a compensator 
Proof For the moment, let us simplify the notation in (4.22) so that it reads 
(S+ - S ) 2  - (A+ - A) 5 K+ - IC. 
(4.23) 
Multiplying out the square, we find that this is equivalent to 
(Sl - S 2 )  - (A+ - A )  5 (K+ - K )  + 2S(S+ - S). 
(4.24) 
The right-hand side of (4.24) is itself the increment of a capital process, which we may designate 
by K’. Indeed, if PK is a strategy that produces K and Ps is a strategy that produces S, then 
IC’ is produced by the strategy P ,  where 
P(s) = P K ( S )  + 2S(s-)Ps(s) 
(4.25) 
for every noninitial situation s (s- being s’s parent-the 
situation preceding s). Since (4.23) 
implies (4.24) we may conclude that condition 1 implies condition 2. To derive condition 1 
from condition 2, we rewrite (4.24) and (4.23) as 
(S: - S 2 )  - (A+ - A) 5 K ;  - IC’ 
(4.26) 
and 
(S+ - S)2 - (A+ - A) 5 ( K ;  - K * )  - 2S(S+ - S ) ,  
(4.27) 
I 
respectively, and we similarly use the fact that (4.26) implies (4.27). 

92 
CHAPTER 4: KOLMOGOROV’S STRONG LAW OF LARGE NUMBERS 
Here is our strong law of large numbers for martingales, which is similar in form 
to the measure-theoretic strong law for martingales (Corollary 8.1 on p. 171): 
Proposition 4.4 IfS is a martingale in a symmetric probability protocol, and A is a 
quadratic supewariation for S, then Skeptic can force 
sn 
-<co===+ 
lim - = O ,  
AAn 
n2 
n+cc n 
n=l 
(4.28) 
where Ad, := An - &-I. 
Proof Let PI be a strategy with capital process S (i.e., S = Kpl), and let PZ be a strategy 
whose capital process satisfies (4.22), so that all increments obey 
AS = AK?, 
(4.29) 
and 
- AA 5 AP. 
(4.30) 
We will show how Skeptic can force (4.28) by combining PI and PZ with information obtained 
from a winning strategy ( M ,  V )  in the unbounded forecasting protocol with zero prices for 
z-tickets. 
In order to use the information in ( M ,  V ) ,  Skeptic simulates the unbounded forecasting 
protocol as he plays the symmetric probability protocol, pretending that Forecaster and Reality 
make moves in the unbounded forecasting protocol that he computes from their moves in the 
symmetric probability protocol and computing his own moves in the symmetric probability 
protocol from what happens in the unbounded forecasting protocol. His procedure is spelled 
out in Table 4.1, which shows one round in the two protocols. At the beginning of the 
round, the Skeptic is in situation sact in the symmetric probability protocol, the protocol he is 
actually playing, and in situation ssim in the unbounded forecasting protocol, the protocol he 
is simulating. He then observes Forecaster’s move f i n  the symmetric probability protocol. He 
calculates the resulting increment AA, and he interprets this as Forecaster’s move 71 (his upper 
Table 4.1 
forecasting protocol with zero prices for z-tickets. 
As he plays the symmetric probability protocol, Skeptic simulates the unbounded 
Symmetric 
Unbounded 
Probability Protocol 
Forecasting Protocol 
Situation 
sact (actual) 
s,im (simulated) 
Forecaster’s move 
Skeptic’s move 
Reality’s move 
r 

4.5: A MARTINGALE STRONG LAW 
93 
price for z2-tickets) in the simulated unbounded forecasting protocol. Using w, he calculates 
the number A4 of z-tickets and the number V of z2-tickets to buy in the unbounded forecasting 
protocol from his winning strategy ( M ,  V ) .  He then calculates A4P,(sactf) + VP,(sactf) 
and uses this as his own move in the symmetric probability protocol. After waiting for Reality 
to complete the round in symmetric probability protocol by making her move r, he completes 
the round in the unbounded forecasting protocol by pretending that Reality’s move there is the 
same as the increment of S in the symmetric probability protocol. 
In the unbounded forecasting protocol, Skeptic’s gain on this round is 
MZ + V(z2 - V) = MAS + V((AS), - AA). 
(4.31) 
But according to (4.29) and (4.30), 
M A S  + V((AS)2 - AA) 5 M A K P 1  + VAKP2, 
(4.32) 
and since the gain function is linear in Skeptic’s move, MAICP1 + VAKP2 is Skeptic’s 
gain in the symmetric probability protocol. So Skeptic makes at least as much money in the 
symmetric probability protocol as in the unbounded forecasting protocol. Since v = AA and 
z = AS, (4.4) happens in the unbounded forecasting protocol if and only if (4.28) happens 
in the symmetric probability protocol. So the fact that ( M ,  V )  is a winning strategy in the 
unbounded forecasting protocol implies that the strategy explained in Table 4.1 is a winning 
I 
strategy in the symmetric probability protocol. 
We are also interested in probability protocols that are not symmetric (after all, 
the unbounded forecasting protocol itself is not symmetric). When we do not assume 
symmetry, however, we must assume some other form of regularity on Skeptic’s 
move space and gain function. The following proposition is an example of the kind 
of result we can obtain. 
Proposition 4.5 Suppose Skeptic’s move space is a closed convex cone in a Banach 
space (i.e., a complete normed linear space), and suppose the gainfunction X is linear 
and continuous in Skeptic’s 
Suppose further that S is a supermartingale and 
A is a compensatorfor S2. Then Skeptic can force (4.28). 
Proof This proposition can be proven by mimicking the proof of the strong law for the 
unbounded forecasting protocol. It is clear that Lemmas 4.1 and 4.2 continue to hold under 
our new assumptions. We can replace (4.8) with 
and define minimal bounding strategies essentially as we did before, but, unfortunately, 
Lemma4.3 ceases to be true, since it makes use of the compactness of closed balls in Euclidean 
spaces. However, the following relaxation of Lemma 4.3 is obviously true: 
’Since we are not assuming that Skeptic’s move space is linear, the condition that X ( f ,  s, r) be linear in s 
must be understood carefully. For us it means that (a) if s is in S and c 2 0, then X(f, cs, r) = cX(f, s, r) 
(notice that cs is in S automatically), and (b) if s1 and s2 are both in S, then X(f, s1 + sz,r) = 
X ( f ,  s1, r) + X ( f ,  s2, r) (notice that s1 + s2 is in S automatically). 

94 
CHAPTER 4: KOLMOGOROVS STRONG LAW OF LARGE NUMBERS 
Lemma 4.9 Let E be a positive constant; we say that a bounding strategy B for 7 is 6-minimal 
ifllL?(s)ll 5 (1 +~)11711(s)foralZ s # 0. Every supermartingale hasan E-minimalbounding 
strategy. 
It is clear that Lemma 4.4 continues to be true: in its proof we can replace “minimal bounding 
strategy” with “e-minimal bounding strategy” and let E 
0; the convergence of series will 
follow from the completeness of the Banach space. The proof proceeds further as before; we 
leave the details to the reader. 
I 
The hypothesis of Proposition 4.5 is incomparable with the hypothesis of linearity 
used by Proposition 4.4. (A cone is not necessarily a linear space, and a linear space 
is not necessarily Banach.) But e,ither proposition can serve as the starting point for 
deriving the strong law of large numbers for securities markets that we study in 3 15.1. 
4.6 APPENDIX: MARTIN’S THEOREM 
Martin’s theorem, the only mathematically 
advanced result from game theory used in 
this book, says that quasi-Bore1 games are 
determinate. In this appendix, we explain the 
meaning of this statement. We also comment 
briefly on the significance of Martin’s theo- 
rem for topics that go far beyond the concerns 
of this book: the general theory of games and 
the foundations of mathematics. 
Consider a perfect-information game with 
two players, Player I and Player 11, who al- 
ternate moves. Such a game can be specified 
mathematically by specifying (1) the game 
tree and (2) the set of paths through the game 
tree that produce a win for Player I. In 19 13, 
Tony 
the UCLA mathematician Ernst Zermelo (1871-1953) proved an almost 
obvious fact: if the game has a finite horizon, 
who proved the determinacy of Bore1 and 
quasi-Bore1 games, in 1990 at his home 
then one of the players has a winning strat- 
in Santa Monica, California. 
egy. Figure 4.1 illustrates why this theorem 
is almost obvious: as soon as we see that the winner is determined in every penulti- 
mate situation in the game tree, it becomes obvious that the theorem can be proven 
by backward induction. 
In the general case, where the game tree may contain arbitrarily long or even 
infinite paths, it is not at all obvious that one of the players has a winning strategy. 
Martin’s theorem tells us, however, that this is the case unless the subset of paths on 
which Player I wins is extremely pathological. 

4.6: APPENDIX: MARTIN'S THEOREM 
95 
X 
I 
' . .  
I1 
/ 
I1 
\ 
'\ 
I1 
I 
I ', ' 
I1 
I 
,/ I1 
11 
/ 
1 
\ 
II 
1 
' 
/// 
II 
/ 
\ 
I 
I1 
Second Reduction 
\ 
The Game Tree 
I '\ I1 
Third Reduction 
Fourth Reduction 
Fig. 4.1 In the game tree on the left, Player I moves first, and the game ends after three or at 
most four moves. The winner is indicated at the end of each path; Player I wins on six paths, 
and Player I1 wins on the other five. But Player I1 has a winning strategy. To see this, we 
progressively prune away terminal moves. In the first reduction, we prune the moves following 
the four situations marked with an X, replacing each X with the winner, on the assumption that 
the player who has the move will choose a winning move if he has one. Three more reductions 
bring us back to the initial situation, marked with Player I1 as the winner. 

96 
CHAPTER 4: KOLMOGOROVS STRONG LAW OF LARGE NUMBERS 
Precise Statement 
In the games between Skeptic and World studied in this book, we use trees that 
describe only the moves made by World. We are now concerned, however, with a 
game tree in the classic sense-a 
tree that describes the moves of both players. In 
order to avoid any confusion on this point, we use a different notation; we write r 
instead of 62 for the set of possible paths, and we write t instead of Ro for the set of 
situations. We suppose, for simplicity, that the game tree has an infinite horizon: All 
the paths are infinite. This does not limit the generality of the discussion, because 
(as Fermat first noted) we can always imagine that play continues even though the 
winner has already been determined. 
The literature on perfect-information games in mathematical logic, on which this 
appendix draws, formalizes the infinite-horizon notion of a game tree starting with 
the set t of situations: a set of finite sequences t is a game tree if 
1 .  t E t and s 5 t (t extends s) imply that s E t, and 
2. s E t implies that there is a t E t such that s C t (t strictly extends s). 
A path in a game tree t is an infinite sequence a1a2 . . . such that a1 . . . a, E t for all 
n = 1,2, . . . . We write r for the set of all paths. Player I makes the odd-numbered 
moves, and Player 11 makes the even-numbered ones: 
I 
a1 
a3 
a5 
... 
I1 
a2 
a4 
... 
Each situation a1 . . .a,, n = 1,2,. . ., belongs to t. 
For E C r we denote by G(E) the game on t with the following winning 
conditions: I wins a play u1a2 . . . of G(E) if a1u2 . . . E E ;  otherwise, I1 wins. The 
game G(E) is determined if either I or I1 has a winning strategy. The notion of 
a strategy is based on the assumption that each player has perfect information: he 
always knows the other player's moves so far. 
If t E t, then r(t) C r is defined to be the set of all infinite extensions oft. We 
give r a topology by taking the r(t), t E t, as basic open sets. Each of the r(t) is 
both closed and open. 
that contains 
all open sets and is closed under (1) complementation, (2) finite or countable union, 
and (3) open-separated union. We will never use property (3), but for completeness 
we give the definition of open-separated union: E C r is the open-separated union 
of a family { F, : j E J }  of subsets of r if (1) E = U J E ~  
F3 and (2) there are disjoint 
open sets D,, j E J ,  such that F3 5 D, for each j E J .  This is a larger class than 
the Borel subsets: every Borel subset is a quasi-Bore1 subset. 
The following result was proven by Donald A. Martin in 1990 ([220], Corollary 1): 
The quasi-Bore1 subsets of r form the smallest class of subsets of 
Martin's Theorem IfE C r is quasi-Borel, then G(E) is determined. 

4.6: APPENDIX: MARTIN’S THEOREM 
97 
The winning sets for all games considered in this book are quasi-Borel. For 
example, let us check that the winning condition 
Ic, < 0 for some n 
(Ic, does not tend to 00) and 
1 ”  
i=l 
00 
< co or - c ( z i  - mi) does not tend to 0 
for Reality in the game of forcing (4.5) is quasi-Borel. Since the class of quasi-Bore1 
events is an algebra, it suffices to prove that the four events 
Ic, < 0 for some n, 
K, does not tend to co, 
1 ,  
n=l 
i=l 
00 $ < 00, 
and 
- c(zi 
- mi) does not tend to 0 
are quasi-Borel. All these events can be expressed by means of events depending only 
on a finite number of the players’ moves (such events are open and so quasi-Borel) 
using countable unions and intersections and therefore are quasi-Borel. 
Martin reviews the history of his theorem in [219]. As he explains, it was the 
culmination of a lengthy investigation by a number of mathematicians following 
Zermelo. Polish mathematicians proved the theorem for additional special cases, 
but a general result came in 1953, when David Gale and F. M. Stewart proved the 
determinacy of open games (games G(E) for which E is an open, or Ey, set) on 
trees with at most countably many situations. Philip Wolfe extended this result to 
E: games in 1955, Morton Davis extended it to E! games in 1964, and Jeff Paris 
extended it to E: games in 1972. Martin extended it to Borel games in 1975, then, 
in 1990, he established the general result that we cite: all quasi-Bore1 games are 
determined, even if the game tree is uncountable. The definition of the classes C Z ,  
as well as further information about the determinacy of Borel and projective sets, 
can be found in Kechris [ 1681. In our games, the goal E is usually very simple and 
hence very low in the E$ hierarchy, but Martin’s 1990 result relieves us of any need 
to examine E’s complexity closely; it is enough that E should be quasi-Borel. 
Perfect-information games occupy only a small corner of the general theory of 
games. In most of the two-person games studied in the social sciences and in 
operations research, the players do not alternate moves while observing each other. 
But in 1998, Martin showed that his 1990 theorem implies determinacy for a very wide 
class of Blackwell games. In a Blackwell game, Players I and I1 move simultaneously 
and play randomized strategies. Such a game can be defined by payoff functions 
rather than by winning sets, and then determinacy means the existence of a value for 
the game. Von Neumann’s minimax theorem asserts the determinacy of one-move 
Blackwell games. Martin’s result, which generalizes this to arbitrary Blackwell 
games with Borel measurable payoff functions, suggests that perfect-information 
games play a fundamental role in the general theory of games. 
In 1962 Mycielski and Steinhaus proposed a statement similar to Martin’s theorem 
as an axiom for mathematics in general. Their axiom of determinacy AD (see 12331) 

98 
CHAPTER 4: KOLMOGOROVS STRONG LAW OF LARGE NUMBERS 
asserts that every perfect-information game G(E) on the countable tree W (the set 
of all finite sequences of natural numbers) is determined. In his 1998 article, Martin 
showed that this implies the analogous statement for Blackwell games (see also 
[304]). The axiom AD contradicts the axiom of choice, which is assumed in Martin's 
proof, but in combination with the axiom of dependent choice DC it is a strong 
competitor with the axiom of choice. The mathematics based on AD + DC is more 
regular in some ways than standard mathematics, which uses the axiom of choice. 
For example, the following surprising results can be proven assuming AD + DC: 
Mycielski-Swierczkowski [234]: Any set of real numbers is Lebesgue measurable. 
Davis [Sl]: Any uncountable set of real numbers contains a perfect subset. 
The second result solves the continuum hypothesis, since every perfect (i.e., 
nonempty, closed, and without isolated points) subset of the real line has the cardi- 
nality of the continuum. 
Of course, we do not need a new foundation for mathematics in this book, and 
accepting AD instead of AC would actually be awkward for our Chapters 11-14. 
According to a folk theorem (whose proof can be found in [ 1651, p. 52), non-principal 
ultrafilters on N do not exist under AD, and this would eliminate the construction of 
nonstandard analysis described in '$1 1.5 and used throughout those chapters. 

5 
The Law of the Iterated 
Logarithm 
The strong law of large numbers says that under 
certain circumstances an average converges al- 
most surely. The law of the iterated logarithm 
concerns the rate and oscillation of this con- 
vergence. It was first formulated and proven 
by Aleksandr Yakovlevich Khinchin in work 
published in 1924. Khinchin considered only 
coin tossing, but general measure-theoretic ver- 
sions of the law were established by Andrei 
N. Kolmogorov (1929) and William F. Stout 
(1970). In this chapter, we state and prove 
a very general game-theoretic version of the 
law. As we will see in Chapter 8 (p. 172), this 
game-theoretic version implies Kolmogorov’s 
and Stout’s measure-theoretic results. 
Khinchin’s law is already very interesting in 
the simplest case, where the coin being tossed 
is fair. In this case, the strong law of large num- 
Aleksandr Khinchin (1894-1959) 
bers says that y,/n converges almost surely to 112, where yn is the number of heads 
in the first n tosses. Khinchin’s law adds that it almost surely oscillates as it con- 
verges, with maximal deviations on both sides asymptotically close to d m / f i .  
More precisely, 
99 
Probability and Finance: It’s Only a Game! Glenn Shafer, Vladimir Vovk 
Copyright 0 2001 John Wiley & Sons, Inc. 
ISBN: 0-471-40226-5 

100 
CHAPTER 5: THE LAW OF THE ITERATED LOGARITHM 
and 
both hold almost surely. We can interpret "almost surely" either measure-theoretically 
or game-theoretically. 
Our general game-theoretic result is set in a variant of the unbounded forecasting 
protocol, the protocol that we used in the preceding chapter for our game-theoretic 
version of Kolmogorov's strong law. In the unbounded forecasting protocol, Fore- 
caster gives a price rn, for Reality's move z, 
and an upper price v, for the squared 
deviation (z, - rn,)'. 
We show that 
= 1, 
c;="=,zi 
- 7%) 
lirn sup 
n+o3 
J2An In In A, 
(5.3) 
with A, := C;=l vi, holds almost surely in the game-theoretic sense provided that 
the rules of the protocol are adjusted so that A, must tend to infinity and the 2 ,  - m, 
must stay within bounds that do not grow too fast. Equation (5.3) generalizes (5.1). 
We can also generalize (5.2), obtaining 
= -1. 
c;=, 
(xi - mi) 
lim inf 
n+oo 
J2A, In ln A, 
(5.4) 
But because of symmetry between 2, and - 2 ,  in the unbounded forecasting protocol, 
(5.3) and (5.4) are equivalent. So we discuss only (5.3). 
Our game-theoretic study of the law of the iterated logarithm leads to insights not 
brought out in standard measure-theoretic expositions. These insights begin with our 
noticing that (5.3) combines two assertions: 
0 J2A, In 111 A, is almost surely valid as an asymptotic bound on the cumulative 
sum I cy=l 
(xi - mi) I. For any positive number E ,  
will eventually stay between - (1 + E )  and 1 + E almost surely. 
The bound is also almost surely sharp. For any positive number E ,  the ratio 
(5.5) will almost surely come within E of both -1 and 1 infinitely often. 
Sharpness is more delicate than validity, but measure-theoretic authors have made 
it a point of honor to prove both under the same conditions on the x, - m, and 
their variances. In the game-theoretic framework, a different attitude is natural, for 
Skeptic can force validity under weaker conditions than sharpness. He can force 
validity provided only that Reality keeps her values for 12,, - m,l bounded relative 
to Forecaster's values for il,. But in order also to force sharpness, the bounds A, 
must themselves be sharp (i.e., the zi,, 
which Forecaster announces to Skeptic in 

5.1: UNBOUNDED FORECASTING PROTOCOLS 
101 
advance of his move, must be prices rather than merely upper prices), and Forecaster 
must even give some extra advance warning of particularly large values of 15, - m, 1. 
The iterated-logarithm bound is valid but not sharp for many of the protocols in this 
book, including the bounded forecasting protocol of Chapter 3 and the unbounded 
forecasting protocol of Chapter 4. We obtain sharpness only after changing the 
unbounded forecasting rules in Skeptic’s favor, and these changes will not fit all 
applications. 
In our study of securities markets in Chapter 15, we will see an 
example where we might hope for the weak limits on Reality’s moves that make the 
bound valid but not for the advance warnings about her moves that make it sharp. 
In $5.1, we introduce our protocols and state our theorems concerning validity 
and sharpness. Then we turn to the proofs: $5.2 deals with validity and $5.3 
with sharpness. In 55.4, we consider the case of an abstract symmetric probability 
protocol. There are two appendixes: $5.5 discusses the history of the law of the 
iterated logarithm, and 55.6 explains its finitary interpretation. 
5.1 
UNBOUNDED FORECASTING PROTOCOLS 
Our main theorems are set in two general protocols: the unbounded forecasting pro- 
tocol (familiar from the preceding chapter) and a variant, the predictably unbounded 
forecasting protocol. We also consider some simpler protocols. 
The Unbounded and Predictably Unbounded Protocols 
Here again is the unbounded forecasting protocol, which we used in the preceding 
chapter for our game-theoretic version of Kolmogorov’s strong law. 
UNBOUNDED 
FORECASTING 
Players: Forecaster, Skeptic, Reality 
Protocol: 
KO := 1. 
F O R n =  1,2, ... : 
Forecaster announces mn E R and v, 2 0. 
Skeptic announces M ,  E R and V, 2 0. 
Reality announces IC, 
E R. 
Ic, := Kn-1 + M ~ ( z ,  - m,) + Vn((z, - mn) - w,). 
Forcing by Skeptic: A strategy for Skeptic (or for Skeptic and Forecaster) forces an 
event E if it assures that K ,  is never negative and either K ,  tends to infinity or else 
E happens, regardless of the moves of the other player(s). 
Forcing by Reality: A strategy for Reality (or for Reality and Forecaster) forces an 
event E if it assures that, provided K ,  is never negative, K, remains bounded and E 
happens, regardless of the moves of the other player(s). 
An unbounded forecasting game is obtained from this protocol by choosing a player 
or coalition (Skeptic, Reality, or a coalition of one of them with Forecaster) and a 

102 
CHAPTER 5: THE LAW OF THE ITERATED LOGARITHM 
goal E. The player or coalition wins by forcing the goal. In Chapter 4, we showed 
that Skeptic can force (4.4) and Reality can force (4.5). In this chapter, we consider 
goals related to the iterated-logarithm bound. 
As we shall prove, the iterated-logarithm bound is valid but not sharp in the 
unbounded forecasting protocol. In order to have sharpness as well as validity, we 
must slightly limit Reality's freedom of action and slightly enlarge Skeptic's freedom 
of action. as follows: 
PREDICTABLY UNBOIINDED FORECASTING 
Protocol: 
KO := 1. 
FOR n = 1,2,. . .: 
Forecaster announces rn, E R, c, 2 0, and v, 2 0. 
Skeptic announces M, E R and V, E R. 
Reality announces x, 6 R such that Ix, - m,l 5 Cn. 
K ,  := ~ n - 1  + M ~ ( x ,  
- mn) + v~((z, - mn)2 - vn). 
Here we have given Skeptic two advantages: (1) He is given, just before his choice 
of M, and V,, a bound c, on how far Reality's subsequent choice of x, will be from 
m,. (2) He is allowed to choose V, negative. 
We shall prove the following two theorems. The first says that the iterated- 
logarithm bound is both valid and sharp in the predictably unbounded protocol. 
The second says that it remains valid in our original unbounded protocol. In both 
theorems, A,, := C:=l w,. 
Theorem 5.1 In the predictably unbounded forecasting protocol, Skeptic can force 
( A ,  + co & c,, = 0 (/=)) 
lim sup c;="=,xi - mi) = 1. 
In In A,, 
,.--too J2A, In In A, 
Theorem 5.2 In the unbounded forecasting protocol, Skeptic can force 
L i  - l l b Z )  
~ 
5 1. 
In In A, 
The statement of Theorem 5.2 remains true, of course, if we increase Skeptic's 
freedom by allowing negative values of V,. 
In the next section, $5.2, we prove the validity of the iterated-logarithm bound: 
Skeptic can force (5.6) in the unbounded protocol and hence also force 
in the predictably unbounded protocol (where the rules are more favorable to him). 
This establishes Theorem 5.2 and half of Theorem 5.1-the 
half we obtain by replac- 
ing = 1 by 5 1. In the section following, 55.3, we prove sharpness in the predictably 

5.1: UNBOUNDED FORECASTING PROTOCOLS 
103 
unbounded protocol, thus establishing the other half of Theorem 5.1-the 
half we 
obtain by replacing = 1 by 2 1. 
The following proposition confirms that the iterated-logarithm bound is not sharp 
for the unbounded forecasting protocol. 
Proposition 5.1 In the unbounded forecasting protocol, Forecaster and Reality can 
force 
A, = n & x, = m, = 0 
for all n, even ifwe increase Skeptic’s freedom by allowing negative V,. 
Proof Forecaster always announces m, = 0 and w, = 1. If Skeptic chooses a negative 
number for V,, Reality busts him by choosing z, with sign opposite to that of M ,  (any sign, 
if M, = 0) and so large in absolute value that Skeptic’s capital, 
Kn-1 + Mnz, + V n ( d  - l), 
becomes negative. If Skeptic chooses V, nonnegative, Reality chooses x, = 0, producing a 
zero change or decrease in Skeptic’s capital. So A, = n and m, = 0 will always be satisfied, 
Skeptic’s capital will never increase, and either Skeptic will lose by going into debt or 5 ,  = 0 
will always be satisfied. 
I 
Simplifications 
If we are only interested in the validity of the iterated-logarithm bound, we can 
discard the requirement that Forecaster issue a variance vr2 at every step, as in the 
following simplified protocol: 
SIMPLIFIED 
PREDICTABLY 
UNBOUNDED 
FORECASTING 
Protocol: 
KO := 1. 
FOR n = 1,2,. . .: 
Forecaster announces m, E R and c, 2 0. 
Skeptic announces M ,  E R. 
Reality announces 2, E [ -c,, c,]. 
K ,  := K,-1+ 
Mn(x, - m,). 
Corollary 5.1 In the simplified predictably unbounded forecasting protocol, Skeptic 
can force 
where A, is dejined to be cy=l 
c:. 
Proof Without loss of generality we can assume that m, E [-c,, 
c,] (otherwise the protocol 
will not be coherent), but notice that we cannot just set m, = 0 (as we do in the proofs of 
Theorems 5.1 and 5.2 below). 

104 
CHAPTER 5: THE LAW OF THE ITERATED LOGARITHM 
In view of Theorem 5.2, it suffices to show that Skeptic can simulate buying the variance 
and price c: with the existing tickets. The lowest price for 
tickets with payoff (2, - 
which such a simulation is possible is 
supirif 
sup 
((xn - m,)’ + b,(z, - m,)) 
(5.7) 
m n  bn zn€[-cn,cnl 
(recall that z, - m, is the net payoff of the available tickets, which can be bought in any 
number to hedge against too large payoffs (s, - m,)2). It is easy to see that indeed (5.7) 
does not exceed c:; dropping the subindex n, we can transform (5.7) as follows: 
sup inf 
sup 
((z - 
+ b(z - m)) 
= sup inf max ((-c - m)’ + b(-c - m), (c - m)’ + b(c - m ) )  
m 
b 
2 t [ - c , c ]  
(the optimal value of b in this chain is 2m, the one that equalizes the two expressions after the 
max sign). 
I 
If we now require that Forecaster set each c, to some constant C, given in advance, 
then this protocol reduces, essentially, to the bounded forecasting protocol we studied 
in $3.3. The conclusion then reduces to 
Forecaster and Reality are still free, however, to make the differences z, - m, all 
equal to zero, and when they do so Skeptic certainly will not become infinitely rich. 
So Skeptic cannot force the bound to be sharp as well as valid even in the bounded 
forecasting protocol. 
5.2 THE VALIDITY OF THE ITERATED-LOGARITHM BOUND 
In this section we prove Theorem 5.2. This proof is an extension of the proof in 
Dawid and Vovk 1997 (which, in its turn, was adapted from Vovk 1988), but its idea 
goes back to Ville 1939. 
We are working in the unbounded forecasting protocol, where we assume, without 
loss of generality, that rn, = 0 for all n. 
The Main Idea of the Proof 
Our task is to construct a strategy for Skeptic that will make his capital unbounded 
if the sum Cy=l z, persists in having extremely large values so that the iterated- 
logarithm bound is violated. (Once we have a strategy with unbounded capital, we 
can construct one with capital that tends to infinity using the trick that we learned 
in Chapter 3.) This goal would certainly be achieved if we could always multiply 

5.2: THE VALIDITY OF THE ITERATED-LOGARITHM BOUND 
105 
Skeptic's capital on the nth step by, say, exp nx, for some positive K ,  for this would 
produce the capital 
(5.9) 
after n steps, which is unbounded if C:=l xi is unbounded, no matter how small the 
positive constant K is. Of course, (5.9) is too much to hope for, but we can come 
close to multiplying the capital on the nth step by exp (KZ, - K ~ w , / ~ ) ,  which is 
nearly the same when K is very small; this will produce the capital 
In order for this to work, we need to use a number of values of n, chosen to 
take maximal advantage of successively larger values of the deviation Cy=l xi. The 
large deviations we want to take advantage of are those just where c:=l 
xi slightly 
exceeds 
(2A, In In A,) 1'2 , 
since this is the maximal value allowed by the law of the iterated logarithm. The 
optimal value of K for taking advantage of such a deviation is 
(cf. (5.21); to see why K should be given by this expression notice that it provides the 
maximum of the exponent in (5.10)). The next step is to approximate A,, and this 
produces (5.14) with k defined by (5.19). The problem is that even k is unknown 
in advance; the solution is to take a mixture with different k with weights w(k) 
shrinking (as k --+ co) as slowly as possible. We use w ( k )  = k-lP6 (see (5.15)). 
In this argument the value 
2 In In A, 
IEM /T 
is obtained from the statement of the law of the iterated logarithm. A less ad hoc 
way to obtain it is to minimize the sum of the first two addends in the right-hand side 
of (5.24) with respect to K .  
The Proof 
Fix temporarily a number 6 E (0,l). (The intuition behind our reasoning will rely on S being 
very small.) For every K E (0, l), Skeptic has a strategy P(") 
in the unbounded forecasting 
protocol (with initial capital $1) such that, for all i, his capital KlK) satisfies 
(5.11) 

106 
CHAPTER 5: THE LAW OF THE ITERATED LOGARITHM 
when he is using that strategy (indeed, (5.11) is equivalent to 
so P(") 
recommends buying 
K!"'K 
1 + (1 + 6)rc2wz/2 
zt-tickets and 
K p ( 1  + 6)K2/2 
1 + (1 + b)n"vi/2 
zq-tickets at every step i). Notice that (5.1 1) is always nonnegative. Put 
r;(l~) := J2(1+ 
~ ) - k  In IC, 
00 
p := c 
k - 1 - 6 p b ( k ) )  > 
k = K  
(5.12) 
(5.13) 
(5.14) 
(5.15) 
where K = K(6) is chosen so that n(k) E (0,l) for k 2 K .  (Later we shall impose 
additional conditions on how large K should be.) Let Ic, > 0 be the capital prcicess for P 
with the initial capital 
Do 
KO := 
k-'-' 
Skeptic can weakly force sup, K ,  < 00 and hence also 
k = K  
(5.16) 
(5.17) 
n 
Consider a play where both (5.17) and 
hold. For such a play and n sufficiently large, we set 
and obtain 
where 4.1 
:= n(k(n)). By (5.1 l), we further obtain 
(5.18) 
(5.19) 
1 + n[?2]2z + (I + b ) n 2 [ n ] z 5 / 2  
1 + (1 + b)d".].i/2 
i=l 
<_ (I. + 6) lnln A, + 0(1), 

5.2: THE VALIDITY OF THE ITERATED-LOGARITHM BOUND 
107 
that is, 
n C In (I + ~ [ n l z ,  
+ (1 + ~)~’[n]zcf/2) 
~)ln(1+(1+S)rc2[n]v,/2) 
+ ( l + S)l n l n A,+O( l ) . 
n 
(5.20) 
2 = 1  
2 = 1  
For n large enough, 
(5.21) 
in conjunction with (5.18) this gives 
supK[n]lzil -+ 0 (n -+ 
00). 
(5.22) 
i<n 
Fort small enough in absolute value we have 
so (5.20) and (5.22) imply 
n 
n 
~ [ n ]  c 
z2 5 c 
In (1 + (1 + 6)n2[n]v2/2) 
+ (1 + S )  lnln An + O(1). 
2 = 1  
t=1 
Since always In( 1 + t) 5 t, we further obtain 
This and (5.21) give 
n C xi 5 (1 + S)’d2An In In A, + 0 
i = l  
(5.25) 
We have shown that for any 6 E (0,l) the strategy P = P(6) given by (5.11) and (5.15), 
with initial capital (5.16). weakly forces (5.25) or the failure of (5.18). Setting 
m 
P := c 
2-3 P(l/j), 
3 = 1  
we obtain a strategy that weakly forces (5.6) starting with initial capital 
03 c 
2-3no(l/j). 
j=1 
To get rid of “weakly” in “weakly forces”, use the device of Lemma 3.2 (p. 68). 
(5.26) 
(5.27) 

108 
CHAPTER 5: THE LAW OF THE ITERATED LOGARITHM 
It remains to consider the questions of convergence. First we prove that (5.27) is finite. It 
is easy: 
m 
m 
m 
provided that K ( l / j )  are so big that 
m 
k-l-l’J 
5 1, Vj. 
k = K ( 1 / 3 )  
So it remains to prove the convergence of series (5.15) and (5.26) (getting rid of “weakly” is 
trivial convergence-wise). Here we use the fact that all our strategies recommend nonnegative 
amounts of z,,-tickets and xi-tickets. This means that it suffices to prove that the strategy P 
recommends aJinite number of 2,-tickets and 2;-tickets in each situation. 
First we note that S E (0, l), K E (0, l), and (5.11) imply that K,(“(k”s)) 
(now weexplicitly 
indicate S in our notation for K = J2(1 + S)-k Ink) as function of k and S is bounded 
in every fixed situation. Since P(“(”’)) 
recommends buying (5.12) 2,-tickets and (5.13) 
&tickets, we are only required to prove that 
m 
m 
and 
(5.29) 
(5.30) 
Both (5.29) and (5.30) follow from (5.28). 
5.3 THE SHARPNESS OF THE ITERATED-LOGARITHM BOUND 
Again we assume without loss of generality that m, = 0 for all n. Our proof will be 
traditional, modeled on Kolmogorov (1929); see also Petrov [242, 2431. 
Reduction to a Large-Deviation Inequality 
Here is the general idea of the proof. Suppose the iterated-logarithm bound is not sharp on 
a particular sequence 2 1 ,  z2, . . . output by Reality; cr=l 
zz 
is too small, at least for large 
n. Divide the whole sequence 2 1 2 2 . .  . into pieces of rapidly increasing cumulative variance. 
For a typical piece znzn+1 . . . z,, 
the sum zTL + . . + z, 
will also be too small. We will 
prove a large-deviation inequality that enables Skeptic to increase his capital slightly for such 
a piece 2,zn+1 . . . zm. The cumulative effect of these slight increases will bring Skeptic’s 
capital from $1 to infinity. 
We define a stopping time to be a set of disjoint situations. A stopping time T is identified 
with the extended (this means that a value of co is allowed) nonnegative variable that maps 
every path ( into n, where n is the length of (’s prefix 6” which belongs to T if such a prefix 
exists and n = 00 if such a prefix does not exist. 
Here is the large-deviation inequality we need. 

5.3: THE SHARPNESS OF THE ITERATED-LOGARITHM BOUND 
109 
Lemma 5.1 For arbitrarily small E > 0, for suficiently small positive 6 < 6(e), and for 
suficiently large C > C(tl 6), the following holds: Consider the unbounded forecasting 
protocol in which Reality is additionally required to ensure that 
Define a stopping time r by 
r := min{n I A, 2 C }  
(so r = 00 if A, never reaches C). Then there exists a positive martingale C such that 
1 
In C 
C(D) = 1 
and 
C(Vlz1 . . . Wnxn) 2 1 + - 
for any situation v1x1 . . . vnx, E r such that 
n 
(5.31) 
(5.32) 
i=l 
We will write P(E, 6, C) for the strategy for Skeptic whose existence is asserted in this lemma. 
The lemma could, of course. be stated in terms of upper probability. 
Let us show that Lemma 5.1 does imply the sharpness of the iterated-logarithm bound in 
the predictably unbounded forecasting protocol, ignoring issues of convergence, which we 
will consider after we prove the lemma. In other words, let us prove that Skeptic can force 
for a fixed constant E > 0. Combining the strategies corresponding to em with em -+ 0 as 
m -+ 
00, we shall obtain the strategy forcing the sharpness of the iterated-logarithm bound. 
Take D sufficiently large (we will be precise later) and 6 sufficiently small in the sense of 
Lemma 5.1. Skeptic’s strategy for forcing (5.33) can be described as follows (the variable k is 
the ordinal number of the current piece of the path, or the cycle of the loop): 
Start with initial capital K := $1. 
FOR k = 1 , 2 , .  . .: 
C := Dk. 
Apply strategy KP(E, 6, C) until A, 2 C or cn > 6,/‘-. 
Clear memory, except for the current capital K .  
(5.34) 
(Command (5.34) means that Skeptic should forget all that he has seen so far and act as if 
the protocol has just started with the initial capital K. In the preceding command, “until” is 
understood inclusively for A, but exclusively for c,: the strategy K’P(e, 6, C) is still applied at 
the step n when An 2 C for the first time but is not applied when cn > 6
d
m
 
for the 
first time.) Suppose Skeptic plays this strategy, the iterated-logarithm bound is valid on the path 
chosen by Forecaster and Reality, and this path satisfies the antecedent but does not satisfy the 
consequent of (5.33). In this case, k will grow indefinitely, the condition c, 5 
will be always satisfied from some k on, and, from some k on, inequality (5.32) will be 
satisfied, with z1, . . . , z, 
Reality’s moves during the kth cycle of the loop in the description 
of Skeptic’s strategy. (Recall that we are assuming that the iterated-logarithm bound is valid 

110 
CHAPTER 5: THE LAW OF THE lTERATED LOGARITHM 
on the path chosen by Forecaster and Reality and that D is sufficiently large; these conditions 
allow us to make the influence of the previous pieces negligible.) Therefore, from some k on, 
Skeptic's capital will be multiplied by at least 
at cycle k. It remains to notice that 
Proof of the Large-Deviation Inequality (Lemma 5.1) 
It suffices to construct a martingale 7 that is always less than In C + 1 and satisfies 
when (5.32) holds. (We can then obtain the required C by putting C := 1 + G.) 
We shall 
do more: we shall find a martingale ,C that never exceeds 
and satisfies 
when (5.32) holds. 
as in the proof of the validity of the iterated-logarithm bound, is that the process 
Our construction is fairly complicated, so we first explain the basic idea. The crucial point, 
where 
n 
n 
s,, 
:= EXi, A, := x u z ,  
2 = 1  
a = l  
is nearly a martingale for small K (A, is the same as A, but is thought of as a process rather 
than as a number). The initial value of this approximate martingale is 1, and its value in a 
(5.35) 
and hence will depend, approximately, only on the value of S at this situation. In this proof we 
shall only be interested in martingales and approximate martingales whose value in a situation 
in T is at least approximately a function of the value of S at this situation; this function will be 
called the payqf of the martingale under consideration. 
Our goal is to find an approximate martingale whose payoff is bounded above by the 
function denoted by the thick line in Figure 5.1. As a very crude first approximation to this 
line, we use the payoff (5.35) of a suitable approximate martingale, which we call the basic 
payojf; the basic payoff is shown as the curved line in Figure 5.1. It is clear from Figure 5.1 
that it suffices to remove regions A, B, and C from the basic payoff. We shall do this by 
subtracting several payoffs of the form (5.35). 

5.3: THE SHARPNESS OF THE ITERATED-LOGARITHM BOUND 
11 1 
s 2  
s3 
Fig. 5.1 
(1 - E)J=, 
Sz = (1 + ~ * ) ' ( 1  - E
)
J
~
,
 
and S3 = 2
m
.
 
Proving the large-deviation inequality by reducing an initial payoff. Here St = 
To implement our plan, we shall need the following simple auxiliary result: Suppose we 
are given some value S of S. Then the value of K for which (5.35) attains its maximum is 
K = SIC, 
(5.36) 
and the corresponding value of the payoff (5.35) is 
(5.37) 
In this proof, we call this value of IC optimal. 
respect to the value 
and will therefore correspond to 
Let E* > 0 be a constant, small even compared to E. Our basic payoff will be optimal with 
s= ( l + E * ) ( l - € ) J 2 C l n I n c  
K = (1 + €*)(l 
- E )  
~ P F  
(5.38) 
Let us check that the bottom of the redundant region C lies below the thick line. For this K and 
for 
s = s2 = (1 + E * ) 2 ( 1  - E)J2CInInC, 

112 
CHAPTER 5: THE LAW OF THE ITERATED LOGARITHM 
we obtain the following value for the basic payoff: 
exp (nS2 - gc) =exp((l+E*)3(1 - E ) 2 2 1 n l n ~ - ( 1 + € * ) 2 ( 1  -E)21nlnc) 
=exp((1 +E*)2(1 - t ) ’ 1 n l n ~ + 2 € * ( 1 + ~ * ) ’ ( 1  
- t ) ’ ~ n l n c )  
5 exp ((1 - E )  In In C )  = (In c)’-‘, 
which is indeed smaller than In C/2. Later, in Lemma 5.2, we shall see that we can replace 
our approximate martingale with a genuine martingale without losing more than a factor 
(In C)O(’), and this will not spoil the picture. 
Now we remove the regions A, B, and C with martingales having small initial values. 
We remove region A using the payoff (5.35) optimal with respect to the rightmost S for 
this region, 
s = ~1 = (1 - E)v‘~C In In C, 
which corresponds to 
(5.39) 
We multiply this payoff by a suitable positive weight and subtract it from the basic payoff. Let 
KO be the basic value of K given by (5.38). Since the ratio 
exp n~ - $C 
exp (KOS - +c) 
( 
) o: e ( K - K o ) S  
(5.40) 
decreases as S increases, the weight with which we should take the payoff corresponding to 
(5.39) is 
exp ( K O ( 1 -  
E ) J ~ c  In In c - $c) 
- exp((l+E*)(l - E ) ’ ~ I ~ I ~ c -  
(1 + E * ) ~ ( I  
- E ) ’ I ~ I ~ c )  
- exp ((I 
+ € * ) ( I  - €*)(I - E
)
~
 
InInC) 
- 
exp (( 1 - ~ ) * 2  
In In C - (1 - E)’ In In C) 
- 
exp (( 1 - E)’ In In C) 
= exp (-(e*)’(~- 
1nInC) = (InC)-(c*)2(1-f)2 << 1. 
The region B UC is much more difficult than A; this is why we split it into B and C. Dealing 
with B is relatively easy, similar to dealing with A. We remove B using the payoff (5.35) 
optimal with respect to the leftmost S for this region, 
which corresponds to 
2lnlnC 
(5.41) 
Again, we multiply this optimal payoff by a suitable positive weight and subtract it from the 
basic payoff. Recall that KO is the basic value of K given by (5.38). Since the ratio (5.40) now 
increases as S increases, the weight with which we should take the payoff corresponding to 

5.3: THE SHARPNESS OF THE ITERATED-LOGARITHM BOUND 
113 
(5.41) is 
exp (3 In In C) 
exp (4 In In C) 
==:- 
= (lnC)-' << 1. 
Here = means approximate equality taking into account the smallness of E and E * .  
Removing region C is most difficult and will be accomplished by subtracting not just one 
but continuously many payoffs. To remove the narrow strip of C between the horizontal lines 
at heights 
5 2  
we use the payoff (5.35) optimal at S, corresponding to n = S/C and taking the value e x  at 
S; see (5.36) and (5.37). Since the width of this strip is 
exp (no(S + dS) - 2 
this payoff should be taken with the weight 
exp (nos - $C) nods 
n2 
= nodSexp nos- O C  - 
( 
2 
2c 
and so the total weight for the whole of C is 
(5.42) 
2J2C In In C 
s 
(I+E*)Z(I-~)JZC 
1nInE 
The expression under the integral sign attains its maximum in S when 
s = KOC = (1 + E*)(I - ~ ) J ~ c I ~ I ~ c ,  
which is to the left of the region of integration in (5.42). Since the integrand decreases over 
the region of integration, we can bound (5.42) from above by 
1 
((1 + E * ) 2 ( 1  - E ) d m ) 2  
- 
2c 

114 
CHAPTER 5: THE LAW OF THE ITERATED LOGARITHM 
= 4( 1 + E' )( 1 - E )  In In C exp 2( 1 + ~ * ) ~ ( l  
- E)' In In C 
i 
We have now removed all three redundant regions shown in Figure 5.1. 
martingales. 
The next lemma shows that our approximate martingales can be replaced by genuine 
Lemma 5.2 Consider the protocol of Lemma 5.1. Let 
(5.43) 
There exists a positive martingale L that starts with $1 and satisjies 
(5.44) 
L ( s )  
exp ( K s ( s )  - $c) 
( l n ~ ) - ~ '  
5 
for every situation s 6 r. There exists another positive martingale L that sturts,from $1 und 
satisfies 
5 ( 1 n ~ ) ~ '  
(5.45) 
L(s) 
for every situation s E r, 
Proqf First we prove (5.44). As in the proof of validity, we consider the martingale C 
satisfying C ( 0 )  = 1 and 
1 + K Z Z  + (I + s ) K ' Z : / 2  
1 + (1 + b)K%J,/2 
Cz+l = Ct 
for i = 1 , 2 , .  . . (cf. (5.1 1) on p. 105). We need to prove 
(5.46) 
(5.47) 

5.3: THE SHARPNESS OF THE ITERATED-LOGARITHM BOUND 
115 
Using the inequalities 
t' 
It15 2 J Z s  --r. l +  t +(1 + 6 ) -  > et 
2 -  
(this elaboration of (5.23) is true for 6 small enough) and 
(5.48) 
(5.49) 
(cf. (5.43) and (5.31)), we reduce the task of proving (5.47) to proving 
or 
fj 
(1 + (1 + 6)K2Ui/2) 5 (In Cy6 exp (+) , 
i=l 
which is equivalent to 
T 
K2 
In (1 + (1 + 6)n2w, / 2 )  5 86 In In C + -C. 
2 
i=l 
Using the inequality ln(1 + t )  5 t ,  we can see that it suffices to prove 
T 
K2 
c(1 
+ 6 ) ~ , ' v i / 2  5 86 In In C + -C. 
2 
z = 1  
(5.50) 
We can assume, without loss of generality, that 
wz 5 J2- 
vi 
(5.51) 
InInC' 
(see (5.31)). Using the definition of T ,  we can therefore reduce the inequality (5.50) to 
K' 
2 
) 5 86lnInC+ -C, 
or 
< 86lnlnC; 
K2 
2 
2 
2 
1nlnC - 
6-c + (1 + 6)-62- 
recalling (5.43), we further reduce it to 
41nInC+4(1+6)6 5 8lnlnC, 
which is indeed true for small 6 and large C. 
Now let us prove (5.45). Here we consider the martingale L satisfying L(0) = 1 and 
(5.52) 

116 
CHAPTER 5: THE LAW OF THE ITERATED LOGARITHM 
for i = 1,2,. . . . (Notice that it is positive for small 6.) We need to prove 
T 
l f n z , f ( l - 6 ) 2 2 / 2  
nz1 
l+(l-6)ti2uL/; 
5 ( l n ~ ) "  
exp ( K s ( ~ )  - $c) 
The inequalities (5.49) and 
t2 
It1 5 2JZs 
1 + t  + (1 - s)! 
5 et 
(this is analogous to (5.48)) reduce (5.53) to 
(5.53) 
or 
Taking logarithms of both sides, we obtain 
-C 
5 8SlnlnC + 
K 2  
2 
Since ln(1 + t )  2 t - t2/2 for all nonnegative t ,  it suffices to prove 
Since 
for large C and small S (see (5.51) and remember the definition of T ) ,  (5.54) reduces to 
by (5.43), this further reduces to 
8(ln In C/C)2 
1,; < 86 In In C - 66 In In C, 
i=l 
or 
According to (5.51) and (5.55), 
(5.55) 
(5.56) 

5.3: THE SHARPNESS OF THE ITERATED-LOGARITHM BOUND 
117 
which is stronger than (5.56) for small 6. 
I 
Our proof of the large-deviation lemma (Lemma 5.1) is now complete except for con- 
vergence issues (considered in the next paragraph) and the following small point: we were 
required to construct a martingale L that never exceeds In C/2 in the situations in and before 
the stopping time T ,  but so far we have only shown that our L: does not exceed In C/2 in the 
situations in T .  Let us show that L: does not exceed In C/2 in the situations before T as well. 
(This would be obvious were T a complete stopping time-one 
that intersects every path.) 
Suppose Skeptic plays the strategy we have constructed (the one whose capital process is the 
martingale L guaranteed not to exceed In C/2 inside T ) .  Suppose that in some situation s 
before T we have L(s) > In C/2. We shall arrive at a contradiction considering the following 
strategy for Forecaster and Reality. After s, Forecaster always sets 
C 
InInC' 
v, := a2- 
and Reality always sets 
This ensures that Skeptic's capital L:, will never decrease after s (the x;-tickets will produce 
zero loss since their price always equals their payoff, and the 2,-tickets will produce a profit 
unless M, = 0) and that d, will eventually exceed C (in other words, T will be reached). 
Convergence Check 
Let us fix a cycle k of Skeptic's strategy and a step n (counting from the beginning of the game) 
in this cycle; we now show that the sums of the amounts of xn- and z;-tickets required by the 
constituent strategies (defined by (5.46) and (5.52)) converges; our argument will also show 
that the sum of the initial capitals required by the constituent strategies converges. According 
to (5.49), (5.46), and (5.52), L, at most doubles at every step; therefore, L, 5 2,, 
and every 
constituent strategy involves amounts of 2,-tickets bounded (in absolute value) by ~ 2 ,  
and 
amounts of x i  tickets bounded by ~'2,. 
Since K satisfies (5.43), we can assume K < 1, and 
so these amounts are bounded by some constant (namely, 2") which depends only on n. 
Now we will list all constituent strategies and their weights: 
0 the one corresponding to the basic payoff is taken with the weight 1; 
0 the one removing region A is taken with weight << 1; 
0 the one removing region B is taken with weight << 1; 
0 the family removing region C has cumulative weight (5.42), which we have shown is 
<< 1. 
This shows that the combined strategy for Lemma 5.1 also requires amounts of tickets bounded 
by a constant depending only on n. 
The final step in the proof of the theorem is to combine the different E in (5.33). It suffices 
to take the strategy corresponding to tm > 0 with weight pm > 0, where tm is any sequence 
convergent to 0 and Cpm is any convergent series. 

118 
CHAPTER 5: THE LAW OF THE lTERATED LOGARITHM 
5.4 A MARTINGALE LAW OF THE ITERATED LOGARITHM 
Recall that in a symmetric probability protocol (a probability protocol in which 
Skeptic can take either side of any gamble), we call the capital processes for Skeptic 
martingales (p. 67 and p. 82). Recall also the game-theoretic definition of quadratic 
supervariation given on p. 91: a quadratic supervariation for a martingale s is 
an increasing predictable process A such that the inequality (4.22) holds for some 
martingale Ic. If the inequality holds with equality, we will call A a (game-theoretic) 
quadratic vuriation for S. 
The following propositions follow from Theorems 5.1 and 5.2, by the method we 
used to prove Proposition 4.4 (p. 92): 
Proposition 5.2 Suppose A is a quadratic supervariation of a martingale S in a 
symmetric probability protocol. Then Skeptic can force 
where AS, := S, - &-I. 
Proposition 5.3 Suppose A is a quadrutic variation of a martingale S in a symmetric 
probability protocol. And suppose c1, cz, . . . is a predictable process such that 
/AS, 
1 5 c, jor all n. Then Skeptic can force 
= 1. 
(A,, + oo & c, 
= o (/=)) 
lim sup 
In In A, 
,--fO3 
dad, In In A, 
Srl 
In Chapter 15, we will apply Proposition 5.2 to securities markets. 
in a Banach space, as in Proposition 4.5 on p. 93. 
Similar results hold when Skeptic’s move space is an arbitrary closed convex cone 
5.5 APPENDIX: HISTORICAL COMMENTS 
This appendix surveys the work leading up to Khinchin’s law of the iterated logarithm 
and the subsequent development of the law within the measure-theoretic framework. 
As we mentioned in Chapter 2, Emile Borel’s original proof of his strong law 
for coin tossing, published in 1909, already gave an upper bound on the rate of 
convergence. This bound was far from sharp; it was of order f i l n  n rather than 
d z .  
Borel made it clear, however, that he was not trying to give the tightest 
possible bound, and his method of proof-approximating 
the probability of his bound 
being violated for each n and then concluding that this would happen for only finitely 
many n because the sum of the probabilities converges-readily 
yields tighter bounds. 
In a two-page account of Borel’s strong law in the chapter on measure theory at 
the end of his first book on set theory (1914), Felix Hausdorff (1868-1942) gave a 
different (and more complete) proof than Borel but announced a bound on the rate 

5.5: APPENDIX: HISTORICAL COMMENTS 
119 
of convergence, n1/2+‘ for any E > 0, that is actually weaker than Borel’s bound. 
Perhaps because of the shortcomings of Borel’s proof, Hausdorff’s contribution has 
been seen as an important step on the way from Borel to Khinchin. Feller ([120], 
p. 196) states that Khinchin’s law gave an answer to a problem “treated in a series of 
papers initiated by” Hausdorff and Hardy and Littlewood. Chow and Teicher ([51], 
p. 368) state that Kolmogorov’s version of the law “was the culmination of a series 
of strides by mathematicians of the caliber of Hausdorff, Hardy, Littlewood, and 
Khintchine”. Other authors [ 134, 1881 make similar statements. 
The English mathematicians Godfrey H. Hardy and John E. Littlewood did touch 
on the rate of convergence in Borel’s law in a lengthy paper on number theory in 1914 
([145], p. 190). Their method was essentially the same as Borel’s, but they found the 
tightest asymptotic bound the method will yield: with probability one, the deviation 
of Cr=l xi from zero is, in their words, “not of order exceeding m’. 
They also 
made a start, as neither Borel nor Hausdorff had done, on investigating how large a 
deviation can be counted on; they showed that with probability one, “the deviation, 
in both directions, is sometimes of order exceeding Jn”. 
The big step after Borel was really Khinchin’s alone. Borel, Hausdorff, and Hardy 
and Littlewood had all followed the same strategy: they estimated the probability 
of a large deviation for Cr=l zi separately for each n and then summed these 
probabilities. This is crude, because the deviations are highly dependent for adjacent 
n. Khinchin estimated the probability of at least one deviation within increasingly 
wide ranges of n. This much more difficult calculation, which Khinchin made in 
1922 and published in 1924, yielded an asymptotic bound on the rate convergence in 
Borel’s strong law that was sharp as well as valid. Like his predecessors, Khinchin 
considered independent tosses of a coin with any probability p for heads; he showed 
that the number y, 
of heads will almost surely satisfy 
= 1. 
Yn - n P  
lim sup 
n+oo 
J2pqn In Inn 
In 1929, Kolmogorov generalized Khinchin’s law from coin tossing to independent 
random variables X I ,  
2 2 , .  . . with means ml, m2,. . . and variances v1, u2,. 
. .; he 
showed that (5.3), with A, := Cy=l ui, holds almost surely in the measure-theoretic 
sense if A, tends to infinity and the x, - m, stay within bounds that do not grow too 
fast. Stout 1970 generalized Kolmogorov’s result to the martingale setting, where 
the m, and u, are conditional means and variances relative to a filtration to which 
2 1 ,  x2, . . . is adapted. In Chapter 8 (p. 172), we deduce Stout’s theorem from our 
game-theoretic result. 
In 1941, Hartman and Wintner obtained a law of the iterated logarithm for inde- 
pendent identically distributed random variables. Although they used Kolmogorov’s 
theorem as the starting point of their proof, their result does not follow simply from 
Kolmogorov’s theorem or from Stout’s. Nor does it have a simple game-theoretic 
counterpart. A game could no doubt be constructed on the basis of their proof, but it 
would price so many functions of the x, that it would hold little interest. In general, 
we consider a game-theoretic generalization of a measure-theoretic result interesting 
only if it manages to reduce significantly the number of prices that are assumed. 

120 
CHAPTER 5: THE LAW OF THE lTERAJED LOGARITHM 
5.6 APPENDIX: KOLMOGOROV’S FINITARY INTERPRETATION 
Infinity is thoroughly embedded in the usual statement of the law of the iterated 
logarithm. It is possible, however, to formulate the law in finitary terms, thereby 
making clearer its relevance to practical problems. In this appendix, we review the 
finitary formulation given by Kolmogorov in 1929. 
We consider only the fair coin. Here the law can be written 
(5.57) 
(cf. (5.1)). According to Kolmogorov, this equation says two things: 
1. For arbitrary positive numbers 77 and 6 one can find a natural number n such 
that for any p the probability that at least one of the inequalities 
yk - $ > l f S ( k = n , n + l ,  ..., n + p )  
is satisfied is less than 7. 
2. For arbitrary positive numbers 7 and 6, and any natural number m, one can 
find a natural number q such that the probability of simultaneous satisfaction 
of all the inequalities 
k 
Y k  - 2 
,~ 
< 1 - 6 (k = m,m + 1,. . . ,m + q )  
is less than 7. 
For practical applications, we need to go further, explicitly telling how large n and 
q need to be in terms of the given parameters. In Point 1, for example, we need an 
explicit function n(q, 6) that outputs the required n from 7 and 6. 
The probabilities referred to in Points 1 and 2 can be interpreted game-theoretically. 
(In fact, as we explain in $8.2, the measure-theoretic and game-theoretic frameworks 
are essentially equivalent for coin tossing.) Further development of finitary versions 
of the game-theoretic strong limit theorems is outside the scope of this book, but 
some work in this direction is provided in [322]. 

The Weak Laws 
We now turn from the strong laws, which have occupied us for the last three chapters, 
to the weak laws-the 
weak law of large numbers and the central limit theorem. 
Though less elegant than the strong laws, the weak laws are a step closer to practice, 
because they do not use the concept of infinity. 
The most elementary weak laws are Bernoulli’s theorem (the weak law of large 
numbers for coin tossing) and De Moivre’s theorem (the central limit theorem for 
coin tossing). In this chapter, we formulate and prove game-theoretic versions of 
these theorems, for the simplest case, where the coin is fair. We use the same game 
as in 53.1, except that there are only N tosses: before each toss, Skeptic is allowed to 
bet at even odds on whether Reality will produce a head or a tail. Our game-theoretic 
version of Bernoulli’s theorem says that 
for fixed e > 0 and 6 > 0 when N is sufficiently large, where y is the number of 
heads. Our game-theoretic version of De Moivre’s theorem says that 
for fixed a and b when N is sufficiently large. The symbol E represents both upper 
and lower probability; (6.1) and (6.2) are each to be read as the conjunction of two 
statements, one with 
and the other with E. These two game-theoretic theorems 
are exactly the same as the classical theorems for the fair coin, except that we have 
replaced P with B; cf. (2.1) and (2.2). 
121 
Probability and Finance: It’s Only a Game! Glenn Shafer, Vladimir Vovk 
Copyright 0 2001 John Wiley & Sons, Inc. 
ISBN: 0-471-40226-5 

722 
CHAPTER 6: THE WEAK LAWS 
Our proof of the game-theoretic version of De Moivre's theorem is the part of this 
chapter that is most important for the rest of the book. It uses the method of proof 
first set out by Lindeberg in his 1920 and 1922 articles on the central limit theorem, 
and it makes two fundamental aspects of this method explicit: (1) the method's 
game-theoretic character, and (2) its relation to the heat equation. This is only the 
first of several times that we use Lindeberg's method. We use it in the next chapter to 
prove Lindeberg's more general central limit theorem, and we use it again in Part I1 to 
price European options in the Bachelier and Black-Scholes models. The applications 
of Lindeberg's method in these later chapters are self-contained, but the exposition 
in this chapter is much more transparent. 
In order to explain the game-theoretic character of De Moivre's theorem, it is 
convenient to write 2, for a variable that is equal to 1IJN when the nth toss is a 
head and -1IJN when it is a tail. We then have 
and we can rewrite (6.2) as 
We actually prove a more general approximation: 
where U is any well-behaved function. Equation (6.4) reduces to (6.3) when U is 
the indicator function for the interval [a, b]. The generalization from (6.3) to (6.4) 
is of little interest in typical applications of De Moivre's theorem, which rely on 
the fundamental interpretative hypothesis, because this hypothesis gives an intuitive 
meaning only to probabilities close to one, all of which can be calculated using (6.3). 
But it is mathematically more convenient to work with (6.4). 
Equation (6.4) gives an approximate price at the beginning of the game for the 
payoff U(Cf=,l 
2,) at the end of the game. We can also give an approximate price 
at intermediate points; the approximate price just after the nth toss is 
cu 
where 
- 
u(s, D) 
:= Lm 
u(s + 2) NO,D(dz). 
(Here we write Np,c2 for the Gaussian distribution with mean ,u and variance a'; 
see $6.4.) At the beginning of the game, when n = 0, the expression (6.5) reduces 

CHAPTER 6: THE WEAK LAWS 
123 
to u(0, l), which is equal to the right-hand side of (6.4), as required. At the end, 
when n = N, 
it correctly gives the payoff itself, U(c,,l 
x,), because the Gaussian 
distribution No,o approaches a probability distribution assigning probability one to 
0 as D approaches 0. Because (6.5) gives the correct price at the end of the game, 
we can show that it gives an approximately correct price earlier by showing that it is 
approximately a martingale (a capital process for Skeptic). We do this by expanding 
its increments in a Taylor’s series and eliminating some of the terms using the fact 
that u ( s ,  D )  satisfies 
N 
the heat equation. In fact, u ( s ,  D) 
is the solution of the Cauchy problem for the 
heat equation with the initial condition given by U .  This means that it satisfies the 
equation for all s and all D > 0, subject to the condition that it approach U ( s )  as D 
approaches 0. When we think of D as time, u ( s ,  D) 
describes the propagation of 
heat from an initial temperature distribution U ( s )  at time 0; see Figure 6.1 on p. 130. 
Bernoulli’s theorem generalizes readily from coin tossing to bounded forecasting, 
where Reality can choose each z, freely from a bounded interval of real numbers. The 
generalization of De Moivre’s theorem to bounded forecasting is more interesting. 
In general, we do not obtain an approximate price for the payoff U(c,,l 
2,) 
in 
the bounded forecasting game; instead we obtain upper and lower prices that may be 
quite different. Upper prices, as it turns out, are given by a function D(s, D )  that 
satisfies 
N 
- 
U(S,D) L U(s). 
This function describes heat propagation with a heat source at each point s that 
switches on when the temperature at s threatens to drop below U ( s ) ,  as in Figure 6.2 
on p. 135; only at times D when u(s, D )  > U ( s )  is the evolution of the temperature 
governed by the heat equation. As we will see, some understanding of u ( s ,  D )  can 
be obtained using elementary results from the parabolic potential theory developed by 
Joseph L. Doob in his Classical Potential Theory and Its Probabilistic Counterpart 
(1984). 
We call the version of De Moivre’s theorem that we obtain for bounded forecasting 
a one-sided central limit theorem. It gives us high lower probabilities for Reality’s 
average move 
z, 
ending up within certain distances of zero, but unlike De 
Moivre’s theorem, it does not give us any similar reassurance about this average 
move ending up even a small distance away from zero. This is a natural result of the 
difference between bounded forecasting and coin tossing. In the bounded forecasting 
protocol, Skeptic cannot force Reality away from zero, for Skeptic gains nothing 
when Reality sets all her z, 
exactly equal to zero. In coin tossing, in contrast, 
Reality must set each zn equal to 1/JN or - 1 / J N ,  and if she makes the average 
too close to zero, she gives Skeptic an opening to get rich by betting that the average 
will move towards zero whenever it is a slight distance away. 
We prove the game-theoretic version of Bernoulli’s theorem in $6.1, the game- 
theoretic version of De Moivre’s theorem in ‘$6.2, and the one-sided central limit 
theorem for bounded forecasting in 56.3. 
N 

124 
CHAPTER 6: THE WEAK LAWS 
6.1 BERNOULLI’S THEOREM 
In this section, we prove two game-theoretic 
versions of Bernoulli’s theorem. The first does 
not explicitly use upper and lower probability; 
it merely asserts that Skeptic can multiply his 
capital in the fair-coin game by a certain factor 
if the proportion of heads, y/N, does not ap- 
proximate one-half closely enough. The sec- 
ond does use upper and lower probability; it 
says that 
holds for given 6 and 6 when N is large enough. 
The second version follows from the first, be- 
cause the factor by which Skeptic can multiply 
his stake determines the lower probability for 
theevent 1 %  - < E .  
Jacob Bernoulli (1654-1705). His the- 
orem first appeared in his posthumously 
published book Ars conjecrandi. 
Bernoulli’s Theorem without Probability 
To facilitate the generalization from coin tossing to bounded forecasting, we code 
Reality’s move x, as 1 for heads and -1 for tails. We then define a process S by 
n 
So := 0 and S, := 
xi for n = 1,. . . , N. 
i=l 
With this coding, the condition that y/N be close to one-half becomes the condition 
that S N / N  be close to zero. 
We also find it convenient to start Skeptic’s capital at a small positive number 
cy and to challenge him to multiply it by the large factor a-’. This produces the 
following coherent symmetric probability game. 
THE FINITE-HORIZON 
FAIR-COIN 
GAME 
Parameters: N ,  E > 0, cy > 0 
Players: Reality, Skeptic 
Protocol: 
Ico := Q. 
F O R n = l ,  ..., N :  
Skeptic announces M, E R. 
Reality announces x, E {-I, l}. 
Ic, := K,-1+ 
Mnxn. 
Winning: Skeptic wins if K ,  is never negative and either KN 2 1 or \ S N / N ~  
< E .  

6.1: BERNOULLI’S THEOREM 
125 
This is a finitary version of the fair-coin game of Chapter 3. The number of rounds 
of play is finite, and instead of trying to make his capital infinite, Skeptic only tries 
to multiply it by a large factor a-l. And instead of trying to make the average of 
Reality’s moves converge exactly to zero, Skeptic only tries to keep it close to zero. 
Bernoulli’s theorem says that Skeptic has a winning strategy if N is large enough. 
Our proof uses the following lemma. 
Lemma 6.1 Set 
S : + N - n  
N 
forn = O , l , .  . . , N. 
(6.7) 
c, := 
Then C, 
is a nonnegative martingale, with Co = 1. 
Proof Because SK - 5:-1 = 2S,-lz, + xi, the increment of S: - n is 
(S? - n) - (SK-, - (n - 1)) = 2S,-1z, + (zg - 1). 
(6.8) 
Since z: = 1, S: - n is a martingale; it is obtained by starting with capital 0 and then buying 
2Sn-1 tickets on the nth round. The process C, is therefore also a martingale. Moreover, it 
is obvious from (6.7) that CO = 1 and C, 2 0 for n = 1, . . . , N .  
I 
Proposition 6.1 (Bernoulli’s Theorem) Skeptic has a winning strategy in thejnite- 
horizon fair-coin game i f N  > l/(aitz). 
Proof Suppose Skeptic starts with a and plays aP, where P is a strategy that produces the 
martingale ,Cn when he starts with 1. His capital at the end of the game is then cySi/N, and 
if this is 1 or more, then he wins. Otherwise crS$/N < 1. Multiplying this by 1 / ( a e 2 )  5 N ,  
I 
We can easily generalize this proof to a bounded forecasting game in which the 
two-element set { - 1, l} is replaced by the interval of real numbers [ - 1,1]. In this 
game, S, - n and C, are merely nonnegative supermartingales, not necessarily 
nonnegative martingales. As we learned in $4.2, a supermartingale is a process 
for Skeptic’s capital obtained when Skeptic is allowed to give away money on each 
round. To see that S, - n is a supermartingale in the bounded forecasting protocol, 
we use the fact that z i  5 1. By (629, Skeptic gets S: - n when he buys 2SnP1 
tickets and gives away 1 - xi on the nth round. 
We can generalize further, as we did for the strong law in Chapters 3 and 4. But let 
us instead turn to see how the weak law for bounded forecasting can be re-expressed 
in terms of upper and lower probability. 
we obtain ISN/NI < E; Skeptic again wins. 
Bernoulli’s Theorem with Upper or Lower Probability 
We now drop the condition for winning, and merely consider the upper and lower 
probabilities determined by the fair-coin protocol: 
Protocol: 
KO := 1. 
FORn = I,. . . , N :  

126 
CHAPTER 6: THE WEAK LAWS 
Skeptic announces Mn E R. 
Reality announces z, 
E { -1, l}. 
IC, := Kn-l + Mnx,. 
Recall that the upper probability of an event E measures the degree to which a 
strategy for betting on E can multiply one’s capital without risk of bankruptcy: 
- 
IP E = inf{a I there is a strategy that begins with cy and ends up 
with at least 1 if E happens and at least 0 otherwise}. 
(This formula follows from (1.1) and (1.4), on pp. 12 and 15, respectively.) Substi- 
tuting { IS/NI 2 c} for E, we obtain 
- 
P{ lS/NI 2 
E }  = inf{a I there is a strategy that begins with Q and ends up 
with at least 1 if IS/NI 2 
E and at least 0 if IS/NI < E } .  
According to Proposition 6.1, Skeptic has the desired strategy if N 2 1/(cyc2), or 
cy 2 1/(N2). so 
Because lower probability is never greater than upper probability in a coherent 
protocol, we can also write 
Equivalently, 
If we want SN/N to be within E of zero with lower probability 1 - 6, then it suffices, 
according to (6.9), to make the number of tosses at least 1/(e26). Actually, a much 
smaller number of tosses will suffice. Bernoulli himself gave a much better upper 
bound, but it was still very conservative. For a sharp bound, we need De Moivre’s 
theorem, which gives approximate probabilities for given deviations of S, /N from 
zero. 
6.2 DE MOIVRE’S THEOREM 
We outlined our game-theoretic version of De Moivre’s theorem for the fair coin 
in the introduction to this chapter. As we indicated there, it is convenient for this 
theorem to code Reality’s move x,, as l / d N  for heads and -1/dN for tails. We 
then define a process S by So := 0 and S, := cy=l 
xi for n = 1,. . . , N. Thus S, 
is the difference between the number of heads and the number of tails in the first n 
rounds, divided by J N .  De Moivre’s theorem says that when N is sufficiently large, 

6.2: DE MOIVRES THEOREM 
127 
SN is approximately standard Gaussian at the beginning of the game, inasmuch as 
s-”, U ( z )  Nb,l(dz) is an approximate price for U(SN) when U is a well-behaved 
function. 
Fixing the number N of tosses and a positive initial capital KO for Skeptic, we 
have the following protocol: 
THE DE MOIVRE FAIR-COIN 
PROTOCOL 
Parameters: N ,  KO > 0 
Players: Reality, Skeptic 
Protocol: 
F O R n =  1, ..., N :  
Skeptic announces Mn E R. 
Reality announces x, E { -N-lI2, N -  
Icn := I C n - I +  M ~ x , .  
We say that a function is smooth if it is infinitely differentiable. 
Proposition 6.2 (De Moivre’s Theorem) Let U be a smooth function constant out- 
side ajnite interval. Then for N suficiently large, the initial upper and lower prices 
of U ( S N )  are both arbitrarily close to f-”, V ( z )  No,l(dz). 
The upper and lower prices will not coincide exactly for any value of N ,  but they will 
both approach s-”, U ( z )  
(dz) as N grows, and so we may say that the game 
assigns U(SN) this price in the limit. 
Because many functions can be approxi- 
mated by smooth functions constant outside a 
finite interval, De Moivre’s theorem can eas- 
ily be extended to larger classes of functions. 
We leave these details for the next chapter, be- 
cause we want to avoid any complication that 
might obscure the simplicity of the proof. But 
we should note that the theorem does extend to 
the case where U is the indicator function for 
an event E that consists, say, of a finite union 
of intervals. Hence we can use De Moivre’s 
theorem to compute upper and lower proba- 
bilities for SN and thus for y, the number 
of heads in the N tosses, using the relation 
SN = (2y - N )  / J N .  Table 6.1 gives a couple 
of examples. As indicated there, De Moivre’s 
theorem not only says that y/N is likely to be 
close to 1/2; it also says that it is unlikely to 
be too close. 
Abraham De Moivre (1667-1754), from 
a portrait dated 1736, when he was about 
70. He Published his theorem for coin 
tossing in 1738. 

128 
CHAPTER 6: THE WEAK LAWS 
The Heat Equation 
Our proof of De Moivre’s theorem uses the idea of smoothing a function U by 
calculating the expected result of adding to its argument a Gaussian perturbation with 
mean zero and variance D. This transforms U into the function g(., 
D), where 
00 
00 
- 
u ( s , D )  := 
u(s + z)NO,D(dz) = 
U ( z ) N s , D ( d z ) .  
(6.10) 
The function u ( s ,  D )  plays an important role in many branches of science, because, 
as we mentioned in the introduction to the chapter, it satisfies the heat equation, 
L 
(6.1 1) 
for all s E R and all D > 0. This can be verified informally using Taylor’s 
approximation: for a small positive constant dD, 
6 
au 
- 
- ( s ,  
D)dD M U ( S ,  D + dD) - U(S, 
D )  
w
0
0
 
A rigorous proof requires some regularity conditions on U .  For example, if U is a 
Bore1 function such that 
for any E > 0 (this holds if U ( s )  grows at most polynomially fast), then a proof can 
be obtained by differentiating ‘IT(.s, D), in the form 
(6.13) 
Table 6.1 
heads in N trials. 
Some high probabilities, from De Moivre’s theorem, concerning the number y of 

6.2: DE MOIVRES THEOREM 
129 
under the integral sign; this is authorized by Leibniz’s differentiation rule for inte- 
grals [49, 381. Other proofs are given in standard references on partial differential 
equations, for example, [49]. It is easy to see that (6.10) converges to U ( s )  as D + 0 
and S -+ s for any real number s, provided that U is continuous and (6.12) holds. 
This means that u solves the heat equation for the initial conditions given by U .  
The heat equation was first successfully 
studied in the early nineteenth century by 
Joseph Fourier (1768-1830),who provided so- 
lutions in terms of trigonometric series for the 
case where initial conditions U ( s )  are given 
on a finite interval in [s1 sz], and boundary 
conditions u(s1, D) and u(s2, D) are also 
provided. Laplace, in 1809, was the first to 
provide the solution (6.10) for the case where 
U ( s )  is given for all s and hence no boundary 
conditions are needed [138]. 
Fourier and other earlier writers were con- 
cerned with the propagation of heat. In this 
context, D represents time, and the coefficient 
112 is replaced by an arbitrary constant. The 
value u ( s ,  D) is the temperature at point s at 
Joseph €3. Fourier (1768-1830), from an 
time D, and the equation says that the increase engraving made 
Jules BoillY in l873. 
in the temperature at a point is proportional to 
how much warmer adjacent points are. Figure 6.1 shows the resulting propagation 
of heat for one particular initial distribution u ( s ,  0). Because the equation is also 
used to describe the diffusion of a substance in a fluid, it is often called the difsu- 
sion equation. Our application is no exception to the rule that the variable whose 
first derivative appears in the equation represents time; superficially, D represents a 
variance, but this variance decreases proportionally with time. 
The Idea of the Proof 
The proposition we are undertaking to prove, De Moivre’s theorem, says that u(0, l), 
where u is given by (6.10), is an approximate price at the beginning of the fair-coin 
game for the payoff U ( S N )  at the end of the game. Our proof exhibits a strategy for 
Skeptic that begins with the capital u(0,l) 
and ends up approximately with U(SN). 
Indeed, the capital process for this strategy is approximately 
(6.14) 
In order to find the strategy, we use a Taylor’s series to study the increments in u. If 
we write A 5  for the increment on the nth round, 
N - n + l  
N 
A u : = U  &,- 
- U  
Sn-1, 
-( ,in> 
-( 

130 
CHAPTER 6: THE WEAK LAWS 
a Initial 
b D = l  
c D = l O  
d D = 100 
Fig. 6.1 Heat propagation according to the equation aU/aD = ;a2U/ds2. Part a shows 
an initial temperature distribution U ( s ) ,  or U(s, 0). Parts b, c, and d show u(s, D) as a 
function of s at times D = 1,10,100, respectively. 
Here As = x,, while AD = - l / N ;  the derivatives are evaluated at (or near) the 
point (Sn, ( N  - n ) / N ) .  Thus As is of order NP1I2, while   AS)^ and AD are of 
order N-l. We can neglect higher order terms, including the terms in (AD)2 and 
AsAD shown in (6.15), but we cannot neglect A AS)^ and AD. Although they are 
only of order N-l, each moves in a consistent direction (the one up and other down), 
so that in N steps they add to something of order 1. (The As, to the extent that 
Reality varies them, may be both positive and negative and hence may also add only 
to something of this order,) But according to the heat equation, AD and (As)2 have 
the same coefficient. So (6.15) reduces to 
AT7 M -AS 
aU 
+ - 
a77    AS)^ + A D ) ,  
as 
d D  
or 
A u  M clx, + c2 (x: - $) . 
(6.16) 
Since x, is always equal to N-1/2 or -NL112, this further reduces to 
AU x C l X , .  
(6.17) 
So Skeptic’s strategy is simple: on each round, he buys c1 tickets. 

6.2: DE MOIVRES THEOREM 
131 
The step from (6.16) to (6.17) relies on the fact that Reality is restricted to two 
moves in coin tossing; 2 ,  must be N-1/2 or -N-‘/2. In more general protocols, 
such as bounded forecasting or the Lindeberg protocol that we will study in the next 
chapter, the second term in (6.16) can be dealt with only if Skeptic is allowed to buy 
2;-tickets as well as %,-tickets. In this case, the price of these tickets will take the 
place of l/N, and Skeptic’s strategy will be to buy c1 2,-tickets and c2 2:-tickets. 
This method of proof can be used not only to verify the price given in Propo- 
sition 6.2 but also to discover it. If there is a game-theoretic price for the payoff 
U ( S N ) ,  then it must begin a martingale that ends with U ( S N ) .  A conjecture that 
the martingale’s value at the nth step depends only on the value of S, and n would 
lead to the Taylor’s series (6.15), from which it is clear that the desired increment 
can be obtained from tickets available to Skeptic only if the function expressing the 
current value of the martingale satisfies the heat equation; we would then solve the 
heat equation to obtain (6.10). 
The method also works in the measure-theoretic framework. In this case, we 
understand martingale in the measure-theoretic sense, as a sequence of random 
variables in which each step is a zero-mean perturbation. Since the mean of 2, will 
be zero and the mean of 2; will be 1/N in the measure-theoretic case, (6.16) makes 
it clear that (6.14) is an approximate martingale in this sense as well. 
This method of proof for the central limit theorem originated with Lindeberg, who 
used it in articles published in 1920 and 1922. Lindeberg’s argument was taken up by 
Paul LCvy, in his Calcul des Probabilitks in 1925 (§5l), and it has been subsequently 
repeated in a number of textbooks, including Breiman 1968 (pp. 167-170) and 
Billingsley 1968 (pp. 42-44). Neither Lindeberg nor these subsequent authors made 
explicit reference to the heat equation, which tends to disappear from view when one 
develops a rigorous treatment for the error terms in the approximation (6.15). The 
underlying gambling ideas are also usually left implicit. 
Details of the Proof 
Making our proof rigorous is mainly a matter of dealing carefully with the remainder terms in 
the Taylor expansion. 
As a first step, notice that it suffices to show that for any positive number E ,  
~ ( ~ i v )  
I /u(z) ni0,i ( d z )  + E 
(6.18) 
when N is sufficiently large. For when we substitute -U for U in (6.18). we obtain 
/u(z)Nn,i(dz) - 6 I 
IEU(SN), 
(6.19) 
and (6.18) and (6.19), together with the fact that the lower price cannot exceed the upper price, 
give the result we want. 
In order to establish (6.18), we need to construct a martingale V that starts at 
J” V ( z )  
(dz) and ends up with V N  satisfying U ( S N )  I VN + E .  In other words, we need 
a strategy P whose capital process Icp satisfies U ( S N )  I J” U ( z )  N0,l (dz) + K g  + E. The 

132 
CHAPTER 6: THE WEAK LAWS 
strategy is simple. On round 11 + 1, Skeptic knows X I , .  . . , xn. So he buys (du/ds)(S,, D,) 
tickets, where 
n 
Sn := S, = Ext, D, := 1 - - 
N '  
n 
2 = 1  
and u(s, D )  is defined, for s E W and D 2 0, by (6.10). 
We have' 
(6.20) 
forn = O , . .  . ,N-l,where(S:,,Dh)isapointstrictlybetween(Sn,Dn)and(S,+1,Dn+1). 
Applying Taylor's formula to d2u/ds2, we find 
where ( S z ,  0:) is apoint strictly between (Sn, D,) and (SL, DL), anddSk anddDi satisfy 
IdSLl 5 Idsn[, IdDhI 5 IdD,I. 
Plugging this equation and the heat equation, (6.11), 
into (6.20), we obtain 
The first term on the right-hand side is the increment of our martingale V :  the gain from 
buying g(Sn, 
D n) tickets on round n + 1. So we only need to show that the other terms are 
negligible when N is sufficiently large. 
The second term is identically zero in the current context (where (dSn)' =: z:+~ = 
1/N = -dDn), and so we are concerned only with the last four terms. All the partial 
derivatives involved in those terms are bounded: the heat equation implies 
- 
and a3u/as3 
and d4u/ds4, being averages of U(3) and U(4), are bounded. So the four terms 
will have at most the order of magnitude O ( N - 3 / 2 ) ,  
and their total cumulative contribution 
be at most O(N-'/2). 
'For any sequence A,, AA, := A, - An-l and dA, := An+l - A,. We use both in this book, 
switching from one to the other depending on which makes for the simpler expressions in the particular 
context. 

6.3: A ONE-SIDED CENTRAL LIMIT THEOREM 
133 
All the central limit theorems and the option pricing formulas studied in this book are based 
on variants of Equation (6.21). 
6.3 A ONE-SIDED CENTRAL LIMIT THEOREM 
We now turn to the case where Reality has more than two alternatives on each round 
of play. For simplicity, we assume that Reality may freely choose her move 2, from 
the entire closed interval [-N-’/2, N-’/’]. This degree of freedom is not essential, 
however. All the results of this section continue to hold if, for example, we assume 
instead that she chooses from the three-element set { --iV1/’, 
0, N-’/’}. 
FINITE-HORIZON 
BOUNDED 
FORECASTING 
PROTOCOL 
Parameters: N ,  Ico > 0 
Players: Reality, Skeptic 
Protocol: 
FOR n = 1,. . . , N :  
Skeptic announces M, E B. 
Reality announces 2, 
E [--N-’/’, N-1/2]. 
Ic, := Ic,-’ + M,X,. 
As we showed in 56.1, Bernoulli’s theorem generalizes readily to this protocol. De 
Moivre’s theorem does not. This is because De Moivre’s theorem is two-sided: as 
we noted in Table 6.1, it tells us not only that Skeptic can force Reality to bring her 
average move c;=’=, 
2, close to zero but also that he can force her not to bring it 
too close. In this protocol (and also in the protocol where Reality chooses from the 
three-element set { --N-’/’, 0, N-ll’}), Skeptic cannot force Reality to stay away 
from zero. She can set all her 2, exactly equal to zero with no penalty. 
The best we can do is generalize De Moivre’s theorem to a one-sided central limit 
theorem. We set SO := 0 and S, := Cy=l zi for n = 1, . . . , N ,  as in the preceding 
section. Using parabolic potential theory, we will define a function v(s, 
D), s E B 
and D > 0, that approaches U ( s )  as D -+ 0, satisfies 
for all s and D, and satisfies the heat equation, 
au - 1a2u 
- -- 
- 
dD 
2 as2’ 
for all s and D such that u ( s ,  D )  > U(s). And then we will prove the following 
one-sided theorem: 
One-sided Central Limit Theorem (Informal Statement) Zfthepayoffinction U 
satisfies appropriate regularity conditions, then limn+oo IE U ( S N )  = U(0,l). 
The regularity conditions we use are given in Theorem 6.1 in the next subsection. 
- 

134 
CHAPTEFl6: THE WEAK LAWS 
The value of u(0,l) 
can be found numerically (just as we find the value of the 
Gaussian integral numerically in the case of De Moivre’s theorem), and because 
E U ( S N )  = - E[-U(SN)], this allows us to find both upper and lower prices for 
~ ( S N ) .  
As Table 6.2 illustrates, the upper and lower prices may be quite different. 
We can gain insight into 
the behavior of the function 
from its interpretation in terms 
of heat propagation. In this in- 
terpretation, we start at time 
D = 0 with a distribution 
of heat over the real line de- 
scribed by the function U ( s ) ,  
and at every point s, there 
is a thermostat that switches 
on whenever this is necessary 
to keep the temperature from 
falling below U(s). When- 
ever the temperature at s rises 
above U(s), this local thermo- 
stat switches off and the evolu- 
Joseph L. Doob, receiving the National Medal of Science 
from President Carter in 1979. 
tion of the temperature is then governed by the heat equation. The function u ( s ,  D), 
which is defined for all s E R and all D 2 0, gives the resulting temperature at s 
at time D. Figure 6.2 depicts the temperature distribution s 6 u ( s ,  D )  for several 
values of D, starting with the same initial temperature distribution as in Figure 6.1 
(p. 130), which depicts heat propagation with no heat sources or sinks. 
For each D 2 0, set U D ( S )  := u(slD). It is clear that if UD, 2 UD,, then 
U D ~ + S  2 Uu2+6 for 6 > 0; given the physics of heat propagation, and given that 
the behavior of the local thermostats is fixed, more heat everywhere at the beginning 
of a time period of length 6 can only produce more heat everywhere at the end of 
the time period. We must certainly have 
2 DO, because the thermostats will not 
allow any decrease from the initial distribution uo. So by induction, the temperature 
is always increasing in D: 
(6.23) 
Table 6.2 Some upper and lower probabilities from the one-sided central limit for the sum 
SN in the finite-horizon bounded forecasting protocol. This table should be compared with 
Table 6.1. For any a > 0, IP{ISNI 2 a} = 0, and ~ { I S N I  
5 a} = 1. But p{ ISN~ 5 a }  
and { ISN I 2 a} must be found numerically. 
Upper probabilities 
Lower probabilities 

6.3: A ONE-SIDED CENTRAL LIMIT THEOREM 
135 
a Initial 
:.-L 
b D = l  
c D=lO 
d D = 100 
Fig. 6.2 Heat propagation with thermostats set to keep the temperature at s from falling 
below U(s). Part a shows the same initial temperature distribution as in Figure 6.1. Parts b, 
c, and d show u(s, D )  as a function of s at times D = 1,10,100, respectively. 
for all s E R and all D 2 0. For each D, UD divides the infinite rod -cc < s < 00 
into two parts: the part where the thermostats are active (the exercise region) and the 
part where they are not (the continuation region) (cf. the discussion of exercise and 
continuation regions for American options in [107], 8E and 8F). In the continuation 
region UD is convex (by (6.23) and the heat equation (6.1 1)); in the exercise region 
UD coincides with U .  The heat propagation, together with the influx of heat from 
the local thermostats, gradually increases the temperature everywhere, usually by 
making it increasingly convex. 
Another very valuable source of intuition for understanding the function g, de- 
scribed in detail by Doob (1984), is its interpretation in terms of Brownian motion. In 
order to avoid the confusion that might arise from working with too many metaphors 
at once, we leave this interpretation for an appendix, $6.5. 
Our one-sided central limit theorem says that limn+m IE U (SN) = U(0,l). 
- 
Before setting out the parabolic potential theory needed for a precise definition of 
U(0,l) and a proof of the theorem, we can give a heuristic proof of part of it, the 
inequality 
1imsupEU ( S N )  5 V(O, 
1). 
This inequality says that starting with U(0,l) at the beginning of the game, Skeptic 
can obtain at least ~ ( S N ) ,  
approximately, at the end. Reasoning as in our heuristic 
proof of De Moivre’s theorem (see (6.15)-(6.17)), but with our current definition of 
U ,  we obtain, instead of (6.16), that AT does not exceed, approximately, 
- 
N+CC 
- 
au 
au 
-5, 
+ !z 
- ;) 
5 -5,; 
8s 
dD 
8s 

136 
CHAPTER 6: THE WEAK LAWS 
the inequality follows from (6.23) and the restriction of 2, to [--N-’l2, N-’/2 I. 
By buying au/as tickets, Skeptic can ensure that his capital at the end of round n 
is close to or exceeds u(S,, 1 - n / N ) .  When n = N this will be close to or more 
than U ( S N ) ,  as required. 
Rigorous Treatment 
Potential theory dates from the eighteenth century [70]. It is mainly concerned with 
elliptic differential equations, but in recent decades it has been extended to parabolic 
differential equations as well [55]. The first systematic exposition of parabolic 
potential theory was provided by Doob 1984 [103], who demonstrated remarkable 
parallels between classical potential theory, parabolic potential theory, and parts of 
probability theory. We use only a small part of Doob’s theory. For a more elementary 
treatment of some of the key notions we use, see [49], Chapter 16. 
This section also requires some elementary notions from general topology that we 
do not use elsewhere. We write 2 for the closure of a set A and dA for its boundary. 
We begin with the notion of aparubolic measure. Doob ([103], $l.XV.lO) shows 
how parabolic measures can be defined for a wide class of domains, but we will be 
mainly concerned with rectangles of the form 
B(s, D ,  6) := ( S  - 6, s + 6) x ( D  - S2, D ) ,  
(6.24) 
where (s, D )  E R2 and 6 > 0 (see Figure 6.3). The height of the rectangle is the 
square of its width; intuitively, this is because space scales as the square root of time 
in heat propagation, as revealed by the exponent -(.z 
- s ) ~ / ( ~ D )  
in (6.13). We 
divide the boundary of B(s, D , 6) into four parts: 
0 the lower boundary (s - 6, s + 6 )  x { D  - S2}, 
0 the upper boundary (s - 6, s + 6) x { D}, 
0 the lateral boundary { s - 6, s + S} x ( D  - d2, D ) ,  
0 andthecorners(s-6,sfS) 
x { D - 6 2 , D } .  
There is a parabolic measure for every point in the interior of the rectangle, and all 
these measures are concentrated on the lower and lateral boundaries of the rectangle. 
The parabolic measure for (s‘, D‘) is denoted by p ~ ( , , ~ , d ) ( s ’ ,  
D’), and it is actually 
concentrated on the lower boundary and the parts of the lateral boundary below D‘. 
The purpose of this measure is to tell what temperature at s‘ will result at time D’ for 
any given initial conditions at time D - 6’ and boundary conditions at s +6 (assuming 
no heat sources or sinks). If the initial and boundary conditions are expressed by 
a function u on the lower and lateral boundaries of the rectangle (the temperature 
distribution at time D - d2 on the lower boundary, and the boundary conditions on 
the lateral boundaries), then the temperature at s‘ at time D’ is the expected value of 
u with respect to the parabolic measure: 

6.3: A ONE-SIDED CENTRAL LIMIT THEOREM 
137 
I 
i 
S - F  
S + F  
fig. 6.3 A rectangle in space and time. For each point (s’, D’) inside the rectangle (or on the 
upper boundary), there is a probability measure, the parabolic measure, which is concentrated 
on the lower and lateral boundaries and gives s”s temperature at time D’ as the expected value 
of a function u that is defined on the lower and lateral boundaries. The values of u on the 
lower boundary are initial conditions (the temperature distribution at time D - S2), and the 
values of u on the lateral boundary are boundary conditions (temperatures that are imposed at 
the points s - S and s + 6). 
The corners have too low a dimension to influence the temperature at (s’, D‘), and 
the upper boundary is situated later in time. 
It is easy to extend the definition of the parabolic measure ~ B ( ~ , D , J )  
(s’, D’) to the 
case where (s’, D’) lies on the upper boundary of B(s, D ,  6). For example, we can 
define it as p ~ ( s ’ ,  
D’), where A is a rectangle obtained from B(s, D ,  6) by raising 
its upper boundary. We are mainly interested in the case (s‘, D’) = (s, D ) ,  and we 
A function u(s, D), u : IR x (0, m) -+ (-m, 001, is called superparabolic if 
abbreviate PB(s,D,J) (s, 0) to PB(S,D,J). 
0 for any (s, D )  and S > 0 such that 6 < JD, 
(in particular, the integral is required to exist), 
it is lower semicontinuous (this means that the set {u > c} is open for any 
c E R), and 
0 it is finite on a dense subset of R x (0, m). 
This definition is analogous to the classical definition of a superharmonic function. 
The first condition says that only heat sources are allowed, no heat sinks: the 
temperature u(s, D )  should be 
u d p g ( , , ~ , ~ ) ,  
the temperature at s that would result 
at time D from unfettered propagation from nearby points, or else higher, because 
of heat sources. The second condition says that if a point (s, D )  is warm (perhaps 
because it was heated by some heat source), the points next to it should also be warm 

138 
CHAPTER 6: THE WEAK LAWS 
(for the same reason). The third condition is not really relevant for us: we consider 
only finite (in this chapter, bounded) superparabolic functions. 
A function u is subparabolic if -u is superparabolic (only heat sinks are allowed). 
A function defined on some open domain is parabolic if it (1) is continuously differ- 
entiable, (2) is twice continuously differentiable with respect to the space variable s, 
and (3) satisfies the standard heat equation. This is equivalent to the function being 
both superparabolic and subparabolic ([ 1031, 1 .XV. 12). 
The least superparabolic majorant of a function u : R x (0, m) -+ (-m, 031, if it 
exists, is denoted by LM u. 
Now we can state our one-sided central limit theorem: 
Theorem 6.1 Suppose the payoff function U is continuous und constant outside a 
finite interval. Then LMu, where u(s, D )  := U(s), exists and 
lim E U  (SN) = (LMu)(O, 1). 
N + m  
For the proof, we need a few more concepts from parabolic potential theory and 
general topology: 
0 If u is an integrable2 function on the lower and lateral boundary of B = 
B(s, D, 
6), the function PI(B, u) 
on B given by 
is well defined and is called the parabolic Poisson integral of u. The formula 
extends to the case where (s’, D’) 
is on the upper boundary of B. (See [ 1031, 
Sl.XV.12.) 
0 If u is a Bore1 function on R x (0, m), the closure of B = B(s, D, S) lies in 
R x (0, 
m), and the restriction of u to the lower and lateral boundaries of B is 
integrable, define TBU by (1) TBU := PI(B, u) on B and its upper boundary 
(this ensures the lower semicontinuity of TBU when u is superparabolic), and 
(2) TBU := u on the rest of R x (0,m). If a function u defined on R x (0, m) 
is superparabolic and the closure of B = B(s, D ,  6) lies in R x (0, m), then 
TBU 5 u, 
r ~ u  
is superparabolic, and TBU is parabolic in B. ((See [103], 
3 1 .XV. 14.) 
If u is a function defined on R x (0, m), we let U stand for the greatest lower 
semicontinuous minorant (also called the lower semicontinuous smoothing) 
, E E R x (O,m), 
of 21. 
*By “integrable” we always mean integrable with respect to the Lebesgue measure 

6.3: A ONE-SIDED CENTRAL LIMIT THEOREM 
139 
We also need the following results about superparabolic functions ([ 1031,s 1 .XV. 12 
and 5 1 .XV. 14): 
Smooth superparabolic functions. If u : R x (0, co) -+ (-co, co) is infinitely 
differentiable, then it is superparabolic if and only if 
(6.25) 
holds. 
Approximation theorem. Every superparabolic function u is the limit, on each 
compact subset of IR x (0, co), 
of an increasing sequence u, of infinitely dif- 
ferentiable superparabolic functions. The proof of this theorem is constructive: 
we take Allnu as u,, where the averaging operator Ab, 6 > 0, is defined by 
and $(r) is a weight function, s,'4(r)dr = 1. Here the averaging over 
B(s, D, 6) is combined with further averaging over 6. The function Abu 
will be infinitely differentiable for an appropriate choice of 4. Notice that 
A ~ u ( s ,  
D )  will only be defined for D > S 2 .  Because the smoothing operators 
Ad do not change parabolic functions at points not too close to the boundary, 
the construction shows that parabolic functions are infinitely differentiable. 
Convergence theorem. (This is part of what Doob [ 1031 calls the parabolic fun- 
damental convergence theorem.) Set u := infaEI u,, where {ua I a: € I }  is 
a family of superparabolic functions locally uniformly bounded below. Then 
the lower semicontinuous smoothing C is superparabolic. (This theorem will 
allow us to establish the existence of LM f in the case that interests us.) 
The last result we need to prove Theorem 6.1 is the continuity of LM u under the 
conditions of the theorem. 
Lemma 6.2 Under the conditions of Theorem 6.1 (01; more generally, if U is uni- 
formly continuous and bounded), (LM u) 
(s, D )  exists and is increasing in D and 
continuous. 
Proof Consider the infimum f of the set of all superparabolic majorant; of u (this set is 
nonempty since U is bounded). Since f >_ u and u is lower semicontinuous, f 2 u. According 
to the convergence theorem, f is superparabolic and, therefore, is the least superparabolic 
majorant LM u of u; in particular, f = f. 
The fact that LM u is nondecreasing in D is intuitively clear (cf. (6.23)) and easy to verify 
formally: indeed, to see that (LMu)(s,Dl) 5 (LMu)(s,Dz) when D1 < Dz, notice 
that (LM u)(s, 0 1 )  5 (LM ii)(s, 0 2 )  5 (LM u)(s, Dz), where i is defined as u in the 
region D > D2 - D1 and as inf u in D 5 D2 - D1. (A cleaner argument not requiring 
boundedness but involving parabolic potential theory for domains different from R x (0, m) 

140 
CHAPTER 6: THE WEAK LAWS 
is: (LM u ) ( s ,  Dl) = (LM U)(s, Dz) 5 (LM u)(s, 02). where ti is the restriction of u to 
Fix some modulus ofcontinuity for U, 
that is, a function f : (0,cm) 
--f (0, m) such that 
W X  (Dz-D1,00).) 
lirnalo f (6) = 0 and, for any 6, SI, and s2, 
Is1 - 321 < 6 ===+ IU(S1) - U(s2)l 5 f(6). 
It is easy to see that, for every D > 0, the function (LM u) (s, D )  is uniformly continuous in 
s with the same modulus of continuity f: indeed, if Is1 - sz1 < 6, 
( L M u ) ( s i , D )  = (LMfi)(sz,D) 5 (LMu)(sz,D) + f(J), 
where U ( s )  := u ( s  + s1 - sz). (A similar “shifting” argument, but along the time rather space 
axis, was used in the above proof that LM u increases in D.) 
It is now easy to see that the continuity of LM u will be implied by its continuity in the 
variable D .  Since (LM u)(s, D )  is continuous in D from below (being lower semicontinuous 
and increasing in D), we only need to prove 
lim(LM T L ) ( S ,  D + 6) = (LM u)(s, D )  
(6.26) 
8J.O 
for every point ( s ,  D )  in the domain of LM u. Assuming (6.26) is violated for a point (s, D), 
that is, 
G := lim(LM u ) ( s ,  D + 6) > (LM u)(s, D ) ,  
610 
let us choose positive numbers E and 6 such that 
G > (LM u)(s, D )  + 2 ~ ,  
f(6) < E .  
Setting A := (LM u ) ( s ,  D )  + E ,  we obtain 
(LMu)(s,D’) > A + €  > A > (LMu)(s’,D) 
foralls’ E (s-6, s+6) andD‘ > a. 
WecanseethatonthelowerboundaryofB(s, D+6’,6) 
the temperature is less than A, on the lateral boundary it is bounded by sup U, and strictly 
above (s, D )  it jumps to at least At- E. This contradicts the continuity of heat propagation. I 
Now we are ready to prove Theorem 6.1. We will deal separately with the positive 
part, 
limsupEU (SN) 5 (LMu)(O, l), 
N+m 
and the negative part, 
l i m i n f E U ( S N )  2 (LMu)(O,l). 
(6.27) 
N+CC 
Proof of the positive part of Theorem 6.1 Let f := LM u; it exists by Lemma 6.2. 
RememberthatD, := 1-n/N. FixalargeconstantC > Oandasmallconstantb E (0,l); 
how large and how small will become clear later. First we show that Skeptic, starting with 
f(0, l), can attain capital close to f(&, 6) (or more) when (&, D,), n = 0 , .  . . , N ,  hits the 
set 
{(s, D )  I Is1 L c or D 5 6) 
(6.28) 

6.3: A ONE-SIDED CENTRAL LIMIT THEOREM 
141 
(after that Skeptic will stop playing or will play just to prevent big changes in S,: see the next 
two paragraphs). According to the approximation theorem, there is a smooth superparabolic 
function v 5 f which is arbitrarily close to f on [-C, C] x [6,1]. The construction in the 
proof of the approximation theorem (see above) shows that u is, like f, nondecreasing in D. 
As in the proof of the central limit theorem, using (6.25), we will obtain (6.21) with = replaced 
by 5 (where S, = S, and D, = 1 - n/N). Since the second addend in (6.21) is nonpositive 
(it is the product of a nonnegative and a nonpositive factor) and all addends after the second 
add, over n = 0,. . . , N - 1, to O(N-'/'), Skeptic will be able to super-replicate, by buying 
au/as tickets, u(S,, D,) with arbitrary accuracy before the set (6.28) is hit. 
Let us first assume that only the border D = 6 of (6.28) is hit. We have proved that Skeptic 
can attain capital close to f(S,, 
6) starting with f(0,l). Since f(s, D )  2 U ( s )  for all s and 
D, it remains to prove that Skeptic can ensure that U(S,) will not move significantly after 
D, reaches 6 unless his capital is multiplied substantially; since U is bounded, this will allow 
Skeptic to hedge against moves of S, exceeding some small constant E with a small increase 
in the required initial capital. Since U is continuous and constant outside a finite interval 
(and, therefore, uniformly continuous), it is sufficient for Skeptic to prevent big changes in S,. 
Below we prove a version of the (one-sided) weak law of large numbers which is sufficient for 
this purpose3: setting a := N-'12 and N := r6N1, we can see that Skeptic has a winning 
strategy in the game of Lemma 6.3 when 6 is small enough (as compared to E'). 
Now let us see what happens if the border Is1 = C of (6.28) is (or both Is1 = C and D = 6 
are) hit. According to Lemma 6.3 (with a := N-'/', N := N ,  and E = C), the probability of 
this event is small when C is large, and Skeptic will be able to simulate a low-cost insurance 
policy with payoff exceeding sup U - inf U when Is\ = C is hit (after it is hit, Skeptic can 
stop any trading). 
I 
The following lemma is a variation on the result that Skeptic has a winning strategy 
in the finite-horizon bounded forecasting game with forecasts set at 0 (this is the game 
we obtain when we generalize the fair-coin game by replacing { - 1 , 1) with [ - 1 , 11; 
see p. 125). We recast the game as follows: 
Parameters: KO > 0, N ,  a > 0, K > o 
Players: Reality, Skeptic 
Protocol: 
F O R n = l ,  ..., fi: 
Skeptic announces Mn E R 
Reality announces 5 ,  E [-a, a]. 
K ,  := Kn-l + M,xn. 
Winning: Skeptic wins if K ,  is never negative and 
N 
either K f i  2 KKo or I 
5, I < E .  
3Lemma6.2, which asserts that LM u is continuous, provides adifferent means of coping with irregularities 
arising when D, approaches 0: we could use the trick (as we do in the proof of Theorem 13.1 on p. 331) 
of starting with (LM u)(O, 1 + 6) (for a small 6 > 0) rather than with (LMu)(O, l), instead of using 
a one-sided weak law of large numbers. However, we would still need a one-sided weak law of large 
numbers to hedge the possibility of hitting the lines /sI = C. 

142 
CHAPTER 6: THE WEAK LAWS 
Lemma 6.3 Skeptic has a winning strategy in this game f K u 2 N  < c2. 
This lemma can be obtained as a simple corollary from Proposition 6.1; alternatively, 
consider the nonnegative supermartingale L, := Ico(S2 + u2fi - a2n)/(u2fi). 
Proof of the negative part of Theorem 6.1 Here we prove (6.27). Since LM u is lower 
semicontinuous, the set D where it is different from the continuous u is open. We already 
know that (s, D )  is in D as soon as (s, D’) is in D for some D’ < D. A standard trick shows 
that LM u is parabolic inside D: indeed, replacing LM u inside a small interval B E D of the 
form (6.24) by the Poisson integral PI(B, LM u) 
(more accurately, applying the TB operation), 
we obtain a function which is simultaneously a superparabolic majorant of u and a minorant of 
LM u; 
since LM u is the least superparabolic majorant, it coincides with PI(B, LMu) inside 
B and so is parabolic inside B. Varying B we obtain that LM u is parabolic in 2). 
Suppose that, contrary to what we are proving, Skeptic can ensure, for a large enough N ,  
the final capital of at least U ( S N )  starting with (LM u)(O, 
1) - 2 ~ ,  
for some constant E > 0. 
Let 2)’ be the following open subset of D: 
2)‘ := { ( s ,  D )  I LM u - 2~ > E }  . 
Notice that LM u, 
as a parabolic function in V, 
is infinitely differentiable inside ‘D; 
therefore, 
all its partial derivatives are bounded in any compact subset of 5 C D (this inclusion follows 
from the continuity of LM u: 
see Lemma 6.2). Without loss of generality we assume that U is 
zero outside a finite interval. Let C be a large constant; in particular: U ( s )  = 0 when Is1 2 C; 
(LMu)(s,D) is uniformly negligible for D 6 ( 0 , l )  and Is1 2 C. (The latter property 
for large C can be seen from, e.g., the fact that (s, D )  ~--t e--s+D/2 and (s, D )  ~--t es+D/2 
are parabolic functions in R x (0, oo).) If Skeptic starts with (LM u)(O, 1) - 2 ~ ,  
it is clear 
from (6.21) (wherev is LM u) that, by choosing dS, = &.N-l/’ with a suitable sign, Reality 
will be able to keep Skeptic’s capital below (LM u) 
(S,, 
Dn) - 
E until (and including, since all 
partial derivatives are bounded) the first time (S, , D,) is outside { ( s ,  D )  E D‘ 1s E (-C, C)} 
(here and below we are assuming that N is large enough); after that time, by choosing dSi = 0, 
i 2 n, Reality will lock Skeptic’s capital below (LM u)(S,, 
Dn) - E ,  which is 
less than U(S,) = U ( S N )  if ISrL\ < C (by the definition of D*); 
negative if IS,I 2 C and, therefore, again less than U(S,) = U ( S N )  = 0. 
Therefore, Reality will always be able to prevent Skeptic from getting U ( S N )  or more in the 
end. 
I 
Indicator functions 
The case of indicator functions, although it is the most important case in applications 
where we adopt the fundamental interpretative hypothesis, is not covered directly by 
Theorem 6.1, because an indicator function is not continuous. But if the event E is 
reasonably simple (if it is a finite union of intervals, say), then the indicator function 
1~ can be approximated arbitrarily closely by continuous functions, both from above 
and below, and so there is no difficulty in proving an analogue of Theorem 6.1. 
Suppose u = 1~ is the indicator function of E, a finite union of closed intervals; 
let us see what LM u looks like in this case. It is clear that (LM u)(s, D )  = 1 if 
s E E ;  therefore we assume that s is outside E. Let a be the largest number in E 

6.4: APPENDIX: THE GAUSSIAN DISTRIBUTION 
143 
such that a < s and b be the smallest number in E such that b > s. The function 
U ( s ,  D), for all s E [a, b], is the solution of the heat equation (6.1 1) with the initial 
condition g(s, 0) = 0 and the boundary conditions a(u, D) = 1 and U(b, D )  = 1. 
It is clear that the solution is convex in s E [a, b]. The explicit form of the solution 
can be found in standard texts about partial differential equations (see, e.g., [4Y], 
Chapter 6), but we will never need it. 
- 
Convex functions 
Theorem 6.1 gives us no help when U is an unbounded convex function. Dealing 
with unbounded convex initial conditions will become important for us in Part 11, 
because put and call options have unboundedconvex payoffs; see Chapter 13. But this 
problem is actually relatively easy, because when the initial temperature distribution 
U is convex, the thermostats will never switch on. This suggests that under suitable 
regularity conditions, 
(6.29) 
The proof of De Moivre’s theorem shows that (6.29) holds provided that U ,  in 
addition to being convex, is smooth and has its third and fourth derivatives bounded 
in absolute value. (Indeed, d2U/ds2, being an average of U ( 2 ) ,  is nonnegative; 
the heat equation shows that dD/dD is also nonnegative, and so the second term 
on the right-hand side of (6.21) is nonpositive. This proves the positive part; the 
negative part follows directly from De Moivre’s theorem if the condition that U is 
constant outside a finite interval is relaxed to the one really used: IU(3)I and IU(4)1 
are bounded.) Such functions can approximate a wide class of functions, including 
the payoffs of standard put and call options. 
6.4 
APPENDIX: THE GAUSSIAN DISTRIBUTION 
A random variable x with probabilities 
(6.30) 
has the standard normal or standard Gaussian distribution. We use the latter name in 
this book. We write N0,l 
for the probability distribution 
and we may write (6.30) in the form 
(6.31) 

144 
CHAPTER 6: THE WEAK LAWS 
More generally, we write N,,,2 for the Gaussian distribution with mean p and 
variance 02. If x is standard Gaussian, then p + ox has this distribution. 
Further information about the Gaussian distribution is provided by any textbook 
on probability, and most give tables of (6.3 1); see, for example, [ 1201, $VII. 1. 
6.5 APPENDIX: STOCHASTIC PARABOLIC POTENTIAL THEORY 
In $6.3, we relied on intuitions about heat propagation to guide our thinking about 
the heat equation. The stochastic interpretation of the heat equation in terms of 
Brownian motion provides another important source of intuition. Leaving aside the 
needed regularity conditions on U ,  consider the least superparabolic majorant LM u 
of u(s, D) := U ( s ) .  The standard stochastic representation of 
= LMu is 
- 
U ( s ,  D )  = sup IEU ( s  + W(T)) , 
(6.32) 
where W is standard Brownian motion, and 7[0, D] is the set of all stopping times in 
[0, D]. The reader familiar with the standard approach to pricing American options 
(see also 5 13.4 below) will notice close similarity between the one-sided central limit 
theorem in the form E U ( S N )  + u(0, l), where U(0,l) is defined by (6.32), and 
the usual formulas for the value of an American option in terms of the Snell envelope 
([ 1071, 58E). The one-sided central limit theorem is actually of the same form (in 
both the stochastic and physical representations) as the pricing formula for American 
options in the Bachelier model of Chapter 11. 
The parabolic measure p ~ ( ~ , ~ , s )  
(s', D') gives the probabilities for where the 
space-time Brownian motion (s' + W(t), 
D' - t), starting from (s', D'), hits the 
boundaryofB(s, D, 6) ([103], 52.VII.12; asimilarassertionisalso trueforsetsmuch 
more general than B(s, D, 6): see [103], Theorem 3.11.2(b), parabolic context). This 
stochastic interpretation of p g ( , , ~ , ~ )  
makes (6.32) almost obvious. It also shows that 
superparabolicity of a function u is a variant of the supermartingale property (at least 
in a local sense) for the composition u(W(t), D - t). 
To help the reader appreciate the usefulness of the stochastic interpretation, we 
list several cases where stochastic arguments shed new light on what we did in 36.3: 
0 The representation (6.32) provides a heuristic argument in favor of the negative 
T t 7[O,D] 
half of the one-sided central limit theorem, 
liminfEU(SN) 2 sup E U ( W ( T ) )  
(6.33) 
(as before, even when Reality is restricted to choosing 2, from the three- 
element set { -NP1I2, 0, N-'12}). Fix some stopping time T (which can 
be arbitrarily close to attaining the supremum in (6.33)). Let Reality choose 
x, = N-'12 or x, = -NP1I2 with equal probabilities 112, independently 
for different n, before stopping time N T ;  after N T ,  Reality always chooses 
x, = 0. De Moivre's theorem in its functional form (see, e.g., [24]) asserts 
7 E T [ O ,  11 
N+03 

6.5: APPENDIX: STOCHASTC PARABOLIC POTENTIAL THEORY 
145 
that the normalized sequence S,, n = 1, . . . , N ,  is well approximated by the 
standard Wiener process ( N  is assumed sufficiently large). Since IC, is a 
martingale, its starting value cannot be much smaller than the right-hand side 
of (6.33) if its final value is at least ~ ( S N ) .  
0 In our proof of the negative half of Theorem 6.1 we used the fact that for a large 
constant C, (LM u)(s, D )  is negligible for D E (0,1] and Is1 2 C. Instead of 
the argument given on p. 142, one can use (6.32). 
0 In the subsection about convex functions (p. 143) we proved that for convex 
U the game-theoretic price of U ( S N )  is given by the usual Gaussian integral. 
For the stochastic interpretation of this observation, consider the representa- 
tion (6.32). According to Jensen’s inequality, the convexity of U implies 
- 
u(s,,D,) = 
SUP 
EU(s,+w(T)) =EU(S,fW(D,)). 
rE7[0,Dn1 
0 In the following subsection we considered the case where U was the indicator 
of some set E, which we assumed to be the union of a finite set of closed 
intervals. If U ( s )  = 1, then the stochastic definition (6.32) of g(s, D) 
reduces 
to 1; if U ( s )  = 0, it reduces to the probability that a standard one-dimensional 
Wiener process starting from s will hit E in time D or less. At (s, D )  the 
optimal stopping time T in (6.32) is ‘‘now” if U ( s )  = 1 and the hitting time for 
E if U ( s )  = 0. 
In general, the stochastic interpretation of differential equations has become a very 
powerful mathematical tool ([166], Chapter 4, or [107], Appendix E)-so 
much so 
that some probabilists now regard potential theory, both classical and parabolic, as a 
special topic in the theory of Markov processes. 

7 
Lindeberg ’s Theorem 
In a famous article published in 1922, Jar1 
Waldemar Lindeberg gave a condition under 
which the central limit theorem holds for in- 
dependent random variables with finite vari- 
ances. Lindeberg’s condition, as it turns out, 
is roughly necessary as well as sufficient, and 
so his theorem is now regarded as the defini- 
tive statement of the classical central limit the- 
orem. It is now usually proven in a general 
measure-theoretic context, where it applies to 
measure-theoretic martingales rather than to 
independent random variables. 
In this chapter, we generalize Lindeberg’s 
theorem to martingales in certain probability 
protocols. In this context, Lindeberg’s con- 
dition requires that extreme values for the in- 
crements of a martingale have small game- 
theoretic upper probability, and the theorem 
concludes that the price of any well-behaved 
function of the final value of the martingale is 
given by the integral of the function with respect to the standard Gaussian distribution. 
This game-theoretic version of Lindeberg’s theorem generalizes the game- 
theoretic version of De Moivre’s theorem that we proved in the preceding chapter, 
and its proof has the same basic structure. To establish the approximate validity 
Jarl Waldemar Lindeberg (1876-1932) 
147 
Probability and Finance: It’s Only a Game! Glenn Shafer, Vladimir Vovk 
Copyright 0 2001 John Wiley & Sons, Inc. 
ISBN: 0-471-40226-5 

148 
CHAPTER 7: LINDEBERG‘S THEOREM 
of a Gaussian price for a given function of the final value of a given martingale, 
we construct an approximate martingale that begins with the proposed price and 
ends with the value of the function. To show that the constructed process is indeed 
an approximate martingale, we relate its increments to the increments of the given 
martingale by expanding it in a Taylor’s series and then using the heat equation to 
combine some of the leading terms. As we will see in Part 11, this same strategy 
of proof also underlies the pricing of options in finance. As we remarked in the 
preceding chapter, it was also more or less the strategy of Lindeberg’s own proof. 
Our game-theoretic version of De Moivre’s theorem was concerned with a concrete 
protocol-a 
protocol for betting on N successive tosses of a fair coin. Our game- 
theoretic version of Lindeberg’s theorem, in contrast, is abstract; it is concerned 
with a martingale in any Lindeberg protocol-any 
coherent, terminating, symmetric 
probability protocol. We introduced such protocols in Chapter 1, but our discussion 
there was informal, and in subsequent chapters we have almost always worked with 
specific examples. So we begin this chapter with a brief but formal study of Lindeberg 
protocols ($7.1). We then state and prove the theorem (57.2). 
Although Lindeberg’s theorem is very powerful, its abstractness can disguise its 
relevance to specific examples. In $7.3, we try to remedy this by describing several 
specific protocols in which the theorem gives interesting results. 
In an appendix, 57.4, we review the history of the central limit theorem. The 
measure-theoretic version of Lindeberg’s theorem is stated precisely in Chapter 8, 
where we show that it follows from the game-theoretic version of this chapter (Corol- 
lary 8.4). 
7.1 LINDEBERG PROTOCOLS 
As we have just said, a Lindeberg protocol is a coherent terminating symmetric 
probability protocol. In this section, we repeat carefully the definitions of these 
terms that were given in Chapter 1, and we extend our notation and terminology 
slightly. Further abstract theory about probability protocols, which is not needed for 
Lindeberg’s theorem but may interest some readers, is presented in the next chapter. 
Terminating Protocols 
A probability protocol is defined by specifying (1) the moves each player is allowed to 
make, which may depend on the preceding moves made by World, and ( 2 )  Skeptic’s 
gain on each round as a function of the moves made so far by World and the move 
made on that round by Skeptic. 
In the terminating case, which we are now considering, World makes only a finite 
sequence of moves, no matter what happens. The possibilities for this finite sequence 
constitute the sample spuce R for the protocol. The sample space R can be any 
nonempty set of finite nonempty sequences that form the leaves of a tree. This means 

7.1: LlNDEBERG PROTOCOLS 
149 
that no proper initial subsequence of a sequence in R is also in a. We call an element 
of R apath. 
We call an initial segment of a path a situation. We include among the situations 
the empty sequence, which we call the initial situation and designate by 0. A path 
is itself a situation-ajnal 
situation. We write Ro for the set consisting of all 
situations. Thus R is a subset of Ro. 
In each situation t, we set 
wt := {w I tw E RO}, 
where tw is the sequence obtained by placing the single move w at the end of the 
sequence of moves t. This is the set of moves available to World in t; we call it 
World's moue space in t. An important assumption is being made here: the moves 
available to World may depend only on his own previous moves, not on the previous 
moves by Skeptic. 
To visualize the sample space, we picture it as a tree rooted at an initial node 0, as 
in Figure 1.2. The nodes in the tree represent the situations. The branches to the right 
of a situation t form the set Wt. A path starts with 
and ends at a final situation. 
We adopt the following terminology and notation, mostly familiar from earlier 
chapters. 
0 When the situation t is an initial segment of the situation u, 
we say that t 
precedes u and that u follows t, and we write t & u. (The initial situation 0 
precedes every situation.) 
0 When t & u and t # u, 
we say that t strictly precedes u and that u strictly 
follows t, and we write t C u. 
0 A situation u is a child of a situation t (and t is the parent of u) if t C u and 
there is no third situation between them-no 
situation w such that t c w c u. 
Every noninitial situation u has a unique parent. 
0 When < is a path and t C <, we say that t is on < and that [ goes through t. 
0 We call a function on Ro a process. We call a partial process (a function on a 
subset of 0') a t-process if its domain of definition includes all situations that 
follow t. (Thus a process is the same as a 0-process.) 
0 We call a function on R a variable. We call a partial variable (a function on a 
subset of R) a t-variable if its domain of definition includes all paths that go 
through t. 
We obtain a variable by considering the possible final values of a process-its 
values in R. We write Sa for the variable thus obtained from a process S: 
for each path < E 0. When all the sequences in R have the same length N ,  we write 
SN for So. We sometimes omit the subscript R or N if the context makes clear that 
we are treating S as a variable rather than as a process. 

150 
CHAPTER 7: LINDEBERG’S THEOREM 
We designate by St the set of moves available to Skeptic in a given nonfinal 
situation t, and we call St Skeptic’s move space in t. We assume (the assumption of 
symmetry is included here) that St is a linear space: if s1 and s2 are in St and a1 and 
a2 are real numbers, then alsl + a252 is in St. 
We also specify for each nonfinal situation t a real-valued function At on St x Wt, 
which we call Skeptic’s gain function. The quantity X t ( s , w )  is the increase in 
Skeptic’s capital in situation t if he moves s and then World moves w. We assume 
that At is linear in s. 
A strategy for Skeptic is a partial process defined on the nonfinal situations. In the 
nonfinal situation t, the strategy P directs Skeptic to make the move P(t). We write 
K? 
for Skeptic’s capital process when he starts with capital 0 and uses the strategy 
P; 
this process is defined inductively by Ic” (0) = 0 and 
P ( t W )  = P ( t )  + A,(P(t), w). 
Although P may be defined only for nonfinal situations, Icp is defined for all 
situations. 
When Skeptic begins with capital a in 0 and follows the strategy P, 
his capital 
process is a + Ic”. Under the assumptions we have made (including symmetry), we 
call a process a martingale if it is equal to N + Icp for some real number N and some 
strategy P-that 
is, if it is Skeptic’s capital process for some initial capital (which 
may be negative) and some strategy (see p. 53). Because the strategies form a linear 
space, the martingales also form a linear space. 
Beginning in a Situation 
In addition to strategies and capital processes that begin in the initial situation 0, 
we 
can talk about strategies and capital processes that begin in some later situation s. A 
partial process that is defined in the nonfinal situations following s can be interpreted 
as telling Skeptic how to move in s and afterwards; this is an s-strategy. When 
Skeptic begins in s with capital 0 and follows a particular s-strategy P, 
his capital 
process from s onward is the s-process K p  defined by Icp(s) = 0 and (7.1). When 
he begins with a instead of 0 in s, it is cu + Kp. We call any s-process of this form 
an s-martingale. 
Coherence 
We call a protocol coherent in 0 if World has a strategy that guarantees that Skeptic 
ends the game with no cumulative gain. This is equivalent (see Appendix 4.6) to the 
requirement that Skeptic have no strategy that guarantees a cumulative gain. In other 
words, for every strategy P for Skeptic, there is a path [ such that K P ( ( )  5 0. 
The notion of coherence can, of course, be applied beginning in any situation t. 
We call a protocol coherent in t if World has a strategy for play beginning in t that 
guarantees that Skeptic makes no cumulative gain from t onward. This implies that 
for every s E St, World has a move w E WL such that At(s,w) 5 0: otherwise 

7.1: LINDEBERG PROTOCOLS 
151 
Skeptic could achieve a cumulative gain by moving s in t and then preserve it by 
moving 0 thereafter. 
We call a protocol everywhere coherent if it is coherent in every situation t. This 
is equivalent to the requirement that for every situation t and every s E S t ,  World 
has a move w E Wt such that &(s, w) 5 0. 
Game-Theoretic Price and Probability 
Now we study upper and lower prices and probabilities. We define them just as in 
Chapter 1, but with slightly more formality. 
Given a nonfinal situation t and a t-variable x, we define Et x, the upperprice of 
x in t, and IE, x, the lower price of x in t, by 
- 
IEt x := inf { a  I there is some t-strategy P such that Icg 2 x - a }  
(7.2) 
and 
Et (z) := sup { a I there is some t-strategy P such that IcE 2 a - x} . 
(7.3) 
Here Icp is defined as in (7.1). The inequalities in (7.2) and (7.3) must be interpreted 
in light of the fact that x and Icg are only t-variables. 
In (7.2), for example, 
Icg 2 x - a means that Icg(E) 2 
x(<) - cr for every path < that goes through t. 
It follows from (7.2) and (7.3) that 
- 
E t x  = -IEt[-x]. 
(7.4) 
From (7.2) and (7.4), we obtain the following proposition. 
Proposition 7.1 IfS is a t-martingale, then & Sa 5 S(t) and iEt Sn 2 
S(t). 
When & x and iEt x are equal, we write IEt x for their common value and call Et x 
the (game-theoretic)price of x in t. When & x exists, we say that x is exactlypriced 
in t. 
So far we have not used coherence. When we do, we obtain the following 
proposition. 
Proposition 7.2 Suppose the protocol is coherent in t. 
I .  rfx is a t-variable, then IE, x 5 & x. 
2. IfS is a t-martingale, then Et Sc? = S(t). 
3. Ifr is a real number and r designates the variable that is equal to r on every 
path, then IE, r = T. 
Proof If LE, z 5 Et z did not hold, then there would exist constants a1 and a2 satisfying 
Et z < a1 < a2 < iE, z and t-strategies PI and P2 satisfying ICgl 2 z - a1 and ICp 2 
a2 - z. The t-strategy PI + P, would then satisfy ICE1+pz > 0, contradicting coherence in 
- 

152 
CHAPTER 7: LINDEBERG'S THEOREM 
t. Statement 2 follows from Statement 1 and Proposition 7.1. Statement 3 then follows from 
I 
The upper and lower probabilities of an event E in the situation t are the upper 
the fact that r is a martingale. 
and lower prices of the indicator function I[E in those situations: 
As we explained in Chapter 1, the fundamental hypothesis of probability makes 
E 
interesting when it is close to zero (this means E is very unlikely) and& E interesting 
when it is close to one (this means E is nearly certain). 
In measure-theoretic probability, we are accustomed to making the notion of a 
probability very close to zero vivid by imagining a sequence of events whose proba- 
bility converges to zero. We say, for example, that a sequence of variables z1,x2, 
. . ., 
in probability spaces (R1 3 1 ,  PI) (a,, 3 2 ,  P2), . . ., respectively, converges in prob- 
ability to a real number c if for any positive real numbers E and 6 there is an integer N 
such that p,{ Iz, - cI > S} < E for all n greater than N .  We can make an analogous 
definition for probability protocols: a sequence of variables z1,z2, . . . in a sequence 
of probability protocols converges in probability to a real number c if for any positive 
real numbers E and 6 there is an integer N such that pn,, { 12, - cI > 6} < E for all 
n greater than N ,  where 0, denotes the initial situation in the nth protocol. 
When z is exactly priced in t ,  we defineits upper variance vt z and its lower 
variance I, 
x by 
- 
- 
Vt z := Et(z - &(x)), and 
When vt z and Yt x are equal, we write Vt (x) for their common value, the (game- 
theoretic) variance of x in t. 
when Et z and E, z are not 
necessarily equal but we want to make the same assertion about both of them. For 
example, Et z < b means that both Et z and Et z are less than b. Similarly, we use 
- 
P to make simultaneous statements about an event's upper and lower price. 
Yt z := Et(x - &(x)), 
As in the preceding chapter, we use the symbol 
- 
The Gains of a Martingale 
Given a martingale S and a nonfinal situation t, we define a process dtS by 
d,S(u) := { S(tt)o-S(t) i f t  c u 
otherwise, 
(7.5) 
where t: is the next situation towards u after t-i.e., 
t t  := tw, where w is the next 
entry in the sequence u after the end of the initial subsequence t (see Figure 7.1). 
We call dtS the gain of S in t. The gain dtS is itself a martingale; it is the capital 
process for Skeptic when he moves in t following the strategy that produces S but 
moves 0 everywhere else. We can recover a martingale by adding up its gains: 
S = S ( O ) +  c 
d t S  
t nonfinal 

7.2: STATEMENTAND PROOF OF THE THEOREM 
153 
Fig. 7.1 
on the way to u from t. 
When the situation 'II strictly follows the situation t ,  we write t,f for the first situation 
(this sum may be even uncountable, but in every situation only finitely many addends 
are nonzero). Because the martingale dtS changes value only in t, all the information 
in it is also contained in the variable (dtS)n. When there is no danger of confusion, 
we use dtS, without the subscript, to designate the variable as well as the martingale. 
We say, for example, that E, dtS = dtS(u); in particular, Et dtS = 0. 
We may get some idea of what to expect from a martingale by looking at the 
upper and lower variances of its gains. In particular, we may want to look at the 
accumulated upper and lower variances, G s  
and ks, 
defined by 
and 
&(<) 
:= Ent dtS. 
tc< 
As we will see in Example 5 in 57.3, the sample space R is sometimes designed 
so that these variables are likely to reach a certain level. This may allow us to use 
Lindeberg's theorem to test whether the final size of S is consistent with the claim 
that it is a martingale. 
7.2 STATEMENT AND PROOF OF THE THEOREM 
Consider a martingale S in a Lindeberg protocol. For every positive number 6, we 
define a variable L s , ~ :  
These variables measure the degree to which exceptionally large increments are found 
along the path <, and Lindeberg's condition requires them to be small in probability. 
Our game-theoretic version of Lindeberg's theorem can be stated as follows: 
Theorem 7.1 Suppose U is a bounded continuous function. Then the initial upper 
andlowerprices of U(Sn) are botharbitrarilyclose to s-", 
U ( z )  NO,J 
(dz) forevery 

154 
CHAPTER 7: LINDEBERG’S THEOREM 
martingale S in every Lindeberg protocol~for which the initial lower probability of 
the conjunction 
is suflciently close to one for a positive number 6 suflciently close to 0. 
The condition that L S , ~  
5 6 have lower probability close to one is our version of 
Lindeberg’s condition. The condition that the lower probability of 1 - 6 < Vars 5 
Vars 5 1 + 6 be close to one makes precise the idea that successive gains have 
approximate game-theoretic variances that probably approximately sum to 1. The 
theorem remains valid if we replace 1 zt R in this condition by o2 f 6, where o2 is 
any positive real number; in this case NO,J 
becomes NO,,. . 
If we fix an interval [a, b] and choose the continuous function U so that it ap- 
proximates the (discontinuous) indicator function for [a, b], then the conclusion of 
the theorem, that & U(SQ) and IE, U ( S 0 )  are both close to s-”, U ( z )  Nb,l(dz), 
becomes 
__ 
b 
- 
En{cL < s0 < b )  = 
NO,l(dZ). 
More colloquially: So has approximately a standard Gaussian distribution at the 
beginning of the game. 
The meaning of the terms “sufficiently close” and “arbitrarily close” can be spelled 
out as follows: For every bounded continuous function U and every E > 0, there exist 
S > 0 and C > 0 such that if S is a martingale in a coherent terminating probability 
protocol and S satisfies 
03 
then 
jB U(SL2) - / U ( z )  NO,ddZ)l < 6 .  
--oo 
The same S and C work for every martingale in every Lindeberg protocol. 
Alternatively, we can restate the theorem in terms of convergence in probability. 
Suppose U is a bounded continuous function and S1, S2, . . . is a sequence of martin- 
gales in a sequence of coherent terminating prcbability protocols. Write El, for the 
initial situation and 0, for the sample space in the nth protocol. And suppose these 
two conditions are satisfied: 
1. E s -  
and as,, 
converge in probability to 1. 
2. For every 6 greater than zero, Ls- ,b converges in probability to zero. 
Then Eon L7(SEn) converges to s-”, U ( Z )  JVO,~ 
(dz). 
classical formulation can find the latter reviewed in 57.4. 
Proofof Lindeberg ’s theorem. Our proof will follow the same lines as the proof of De 
Moivre’s theorem in the preceding chapter, with one important difference: we move the center 
of Taylor’s expansion. 
Readers who wish to compare our formulation of Lindeberg’s theorem with the 

7.2: STATEMENT AND PROOF OF THE THEOREM 
155 
We begin by noticing that it suffices to show that for every t > 0 the hypotheses of the 
theorem imply 
m 
- 
Eo U ( S )  I 
JI, U ( z )  NO,l(dZ) + 6 .  
(7.6) 
First we assume that U is a smooth function that is constant outside a compact interval. We 
introduce the function 
g(h) := sup U ( z  + h) - U ( z )  - U’(z)h - 
X 
and note that 
and, for some constant K ,  
g(h) I K I ~ I ~ ,  
g(h) I 
~ h ’ ,  
vh. 
We shall suppose that K > 2. 
Fix arbitrarily small 6 E (0,l). Let c E (0,l) be so small that 
and, for all w E R and all A E (0,2<], 
(7.7) 
(7.8) 
Let us check that such C indeed exists. The existence of C satisfying (7.9) follows from U being 
uniformly continuous and bounded-see, 
for example, [121], Lemma VII. 1.1. Substituting 
the function w ++ s-”, U ( z )  ,ffv,l(dz) for U ,  C for A, and 0 for w in (7.9), we obtain (7.8). 
We assume that the lower probability of the conjunction of the inequalities 
(which is “sufficiently small’’ according to the statement of the theorem) is at least 1 - 6. 
(7.12) 
(7.13) 
We shall show that for some martingale V that is bounded below by a constant independent 
(7.14) 
of 6, we have 

156 
CHAPTER 7: LINDEBERG’S THEOREM 
where C is a constant (depending only on U ) ,  and, for all [ satisfying (7.10) and (7.11), 
V(F) L U (S(F)) 
’ 
(7.15) 
Since 4 satisfies (7.10) and (7.1 1) with lower probability at least 1-6, our goal will be achieved 
(remember (7.8), that S can be taken arbitrarily small, and that V is bounded below). 
Put, for each situation s, 
S(s) := S(s), D(s) := 1 + C - 
A(t) 
t c s  
(these are analogues of S, and D, in (6.21)), where 
- 
IEt(dtSI2 + E t ( d t S ) 2  
2 
i l ( t )  := 
Let ‘iT be defined as in Chapter 6 (see (6.10) on p. 128), except that we put u(s, 
U )  := U ( s )  
when D 5 0. We construct V so that it approximates, or at least is not too far below, 
- 
U ( S ( S ) ,  D(s)). 
Define variables S, and Dn by 
ST,(<) := S(E”) 
and 
D n ( 0  := D(Fn), 
for n = 0,1,. . , . Instead of using (6.21) directly, we will use a similar expansion, but around 
the point (S,, 
D,+1) rather than (S,, 
D,). It should be clear why this makes sense in our 
current context: we are interested in the connection between a(S,, Dn) and ~ ( S , + I ,  
&+I), 
the point (S,,, 
DYL+1) 
is the middle ground between (S,, 
Dn) and (&+I, 
& + I ) ,  and Skeptic 
knows S, and D,+l when he makes his own move in round n+l. Therefore, we replace (6.21) 
with 
(DL lies between D,, and D,+I), which can be obtained by subtracting 
au 
au 
d D  
I -(sn, D n + ~ ) ( d S n ) ~  
+ z ( S n ,  Dn+l)dSn + g(&Sn). 
The last inequality follows from (7.7): first we average (7.7) with respect to n: distributed as 
Ns, ,D,+, (we can do this by Leibniz’s differentiation rule for integrals), and then we replace 
(1 /2)a’u/dS2 by d u / d D .  
Let us first concentrate on the first two terms on the right-hand side of (7.16); the rest will be 
negligible. We established in Chapter 6 (see (6.22)) that all partial derivatives on the right-hand 
side of (7.16) are bounded by some constant c. It is clear that there exists a martingale V ( l )  
starting from 
s + cc 
(7.17) 

7.2: STATEMENT AND PROOF OF THE THEOREM 
157 
such that V ( l )  (c) exceeds the sum of the first two terms summed along (, for every [ satisfy- 
ing (7.10). Indeed, the second term on the right-hand side of (7.16) can be exactly replicated 
by Skeptic, and (dD, + (dS,)’) in the first term can be replicated with the accuracy equal to 
the half-difference between the upper and lower variance plus some allowance (which should 
be taken exponentially decreasing with n) for the potential nonattainability of the supremum 
or infimum in the definition of upper and lower variances. The 1 in (7.17) arises because of 
the discrepancies between the lower and upper variances, and we took 6 to be an upper bound 
on the error due to the allowances involved in super-replicating the first term. 
For the third term, we have 
(7.18) 
which shows that it is negligible (cf. (7.10) and (7.13)). For the last term, we split the 
corresponding sum as follows: 
The first sum on the right-hand side, according to Lindeberg’s condition (see (7.12)), can be 
super-replicated by a martingale V(’) starting from 26. The second sum can be bounded as 
and so can be, according to (7.10), super-replicated by a martingale V(3) starting from 26. 
Setting 
v := C(S(O), D ( 0 ) )  + v(l) + KV(’) + Kv(3) + 6 
(7.19) 
will ensure that (7.14) and (7.15) are satisfied (the 6 in (7.19) corresponds to the 6 in (7.9)). 
Let us now show that the sum V(’) + KV(’) + KV(3) can be chosen bounded below. We 
will assume that the martingales Y(’), V ( 2 ) ,  
V ( 3 )  are stopped as soon as it becomes clear that 
one of the relations (7.10) or (7.1 1) will be violated; more accurately, Skeptic starts playing 0 
from the first situation cN where 
(7.20) 
or 
c 
~s[(dsS)2~,d.s,>64 
> b4. 
sCCN 
According to (7.16), in no situation will the sum V(’) + KV(2) + KU(3) be smaller than the 
increment (from the root to that situation) in u plus a multiple of the following values: 
the accumulated error (bounded by 21; see (7.20)) due to using -dDn in place of the 
corresponding upper or lower variance plus the allowances (as discussed above); 
Cn,N(dDn)2, which is negligible by (7.18). 

158 
CHAPTER 7: LINDEBERG'S THEOREM 
Hence we established that V is bounded below, which completes the proof under the assumption 
that U is smooth and constant outside a finite interval. 
Lemma 7.1 For any t > 0 and bounded continuous U: W 
a$nite interval and smooth,function U such that U 5 U and 
R there exists a constant outside 
m 
(7.21) 
Proof There are an increasing finite sequence t l ,  . . . , t k  of real numbers and a function 
g: R -+ W which is constant on each of the intervals 
( - m , t 1 ] ,  (tl, t z ] ,  . . ., ( t k - 1 ,  t k ] ,  ( t k , r n )  
and satisfies g(-m) = g(m) and 
It is well known that there exists a smooth function 4: W -+ [0, 11 such that 4(t) = 1 fort 5 0 
and $(t) = 0 fort 2 1 (see, e.g., (7.1) of [24]). Choose 6 > 0 which does not exceed any of 
the values ( t 2  - t 1 ) / 2 , .  . . , ( t k  - t k - , ) / 2 .  Using the function 4, one can easily construct a 
smooth function U such that: 
!JIU, 
U ( t )  = g ( t )  for each t $ uf=l (t, - 6, t, + 6) ; 
U ( t )  E [g(tz-), g(tZ+)] when t E (tl - 6, t, + 6 )  . 
Choosing sufficiently small 6, we ensure 
I 
Now we can easily finish the proof. We are required to establish (7.6) for any bounded 
continuous U .  By Lemma 7.1, there exists a smooth and constantputside a finite interval 
function U such that U I 0 and (7.21) holds. Since (7.6) holds for U ,  we have: 
- 
E U ( S )  5 E U ( S )  
J - 0 0  
J - C C  
Since E can be arbitrarily small, this completes the proof. 
7.3 EXAMPLES OF THE THEOREM 
I 
We now we look at what Lindeberg's theorem says for some particular martingales 
in some particular Lindeberg protocols. 

7.3: EXAMPLES OF THE THEOREM 
159 
Example 1. Bounded Variables with Identical Variances 
This is a finite-horizon version of the bounded forecasting protocol we studied in 
Chapter 3. As always, the parameters are fixed and known to the players before the 
game begins. 
BOUNDED 
FORECASTING 
WITH CONSTANT 
VARIANCE 
Parameters: N ,  A 2 1, Kc0 > 0 
Players: Skeptic, Reality 
Protocol: 
FOR n = 1,. . . , N :  
Skeptic announces M, E R and V, E R. 
Reality announces x, E [-ANP1l2, AN-ll2]. 
K ,  := K,-1 + M,z, + V,(Z; - l/N). 
(7.22) 
Reality may always set x, equal to N-1/2 in absolute value, with sign opposite 
that of Ad,, thereby making Skeptic’s gain in (7.22) nonpositive. So the protocol is 
everywhere coherent. 
In every situation up to and including ~ 1 x 2  
. . . %,-I, the variable x, has exact 
price zero (by setting all his Mi and V, equal to zero except for M,, which he sets 
equal to 1, Skeptic gets x, with an investment of zero) and exact game-theoretic 
variance l/N (by setting them all equal to zero except for V,, which he sets equal to 
1, he gets xi with an investment of l/N). 
The martingale S that interests us is the sum of Reality’s moves; we set S( 0) 
:= 0 
and S(xlx2 . . . z,) 
:= cT=l xi. We verify as follows that S satisfies the hypotheses 
of Lindeberg ’s theorem. 
0 The x, are the gains of our martingale: dZ1z2.,.Zn-lS 
= 2,. So 
for n = 1, . . . , N ,  and so E s ( E )  = &(<) 
= 1 for all <, 
0 Reality is constrained to keep x; 5 A2 IN. So the inequality xi 2 6 is ruled 
out and L s , ~  
is identically zero when N > A2/S. 
We conclude that SN is approximately standard Gaussian when A is fixed and N is 
made large enough. 
For simplicity, we have arranged for the total game-theoretic variance to be one in 
this example, but we may rescale the protocol to make it any positive number cr2, and 
Lindeberg’s theorem will then easily give the conclusion that the sum of Reality’s 
moves will be approximately Gaussian with mean zero and variance 02. We can 
also allow Forecaster to enter the game and give x, a possibly nonzero price m, just 
before Skeptic moves; as in Chapter 3, this makes no difference. Reality still has the 
same freedom in choosing the difference x, - m,, which is all that matters. With 
these two modifications, the protocol reads as follows: 

760 
CHAPTER 7: LINDEBERG'S THEOREM 
Parameters: N ,  A >_ 1, cr2 >_ 0, KO > 0 
Players: Forecaster, Skeptic, Reality 
Protocol: 
FOR n = 1,. . . , N: 
Forecaster announces m, E R. 
Skeptic announces A4, E R and V,, E R. 
Reality announces x, such that (2, - m,,) E [ - A O N - ' / ~ ,  
A o N - ~ I ~ ] .  
K7% := Kn-l + MrL(xn - VL,) + V,(.C; - 0 2 / N ) .  
The conclusion is that S, the sum of the x, - 7n,, is approximately Gaussian with 
mean zero and variance cr2 when -4 
and cr2 are fixed and N is made large enough. 
It is natural to compare Lindeberg's theorem for this example with the classical 
central limit theorem for independent identically distributed random variables. We 
have no probability distribution, but our variables x, - m, are identically and 
independently priced in the sense that they all have the same price (zero) and their 
squares all have the same price ( a 2 / N )  independently of how the preceding ones 
have come out. On the other hand, we have the additional condition that the variables 
be uniformly bounded. 
The uniform bound and the constant variance are one way of making precise the 
condition, always needed in one form or another for a central limit theorem, that none 
of the individual variables contributes too substantially to the total variance. 
Example 2. Bounded Variables with Fixed Variances 
Instead of assuming that the x, all have the same game-theoretic variance, we may 
assume simply that their game-theoretic variances are fixed and known to all players 
at the beginning of the game. 
BOUNDED 
FORECASTING WITH FIXED 
VARIANCES 
Parameters: N, A 2 1, cr2 2 0, nonnegative ~ 1 , 2 1 2 , .  . . , VN adding to cr2, KO > 0 
Players: Skeptic, Reality 
Protocol: 
FOR n = I, . . . , N :  
Skeptic announces M, E Iw and V, E R. 
Reality announces x, E [-AJwn, AJw,]. 
Kn := Kn-i + M,s, + V,(X; - u,). 
If we set v, equal to u2/N, this reduces to the preceding example. 
Our reasoning for this example differs little from that for the preceding example. 
To see that the protocol is everywhere coherent, we notice that Reality may set xn 
equal to Ju, 
in absolute value, with sign opposite that of Adn, thereby making 
Skeptic's gain nonpositive. And by the same argument as in the preceding example, 
x, has exact price zero and exact game-theoretic variance 'u, 
in every situation up to 
and including 51x2 . . . x,-1. 
Again taking S to be the sum of Reality's moves, we have Es([) = V V ( E )  = 
cr2 for all [. 

7.3: EXAMPLES OF THE THEOREM 
161 
Now fix a positive constant B, and let us assume that 
v, 5 Ba2/N. 
(7.23) 
(Because the v, must add to r2, B cannot be less than 1.) Because Reality is 
constrained to keep x: 5 A2v,, this means that x: 5 Ba2A2/N. So the inequality 
x: 2 S is ruled out and Ls,a is identically zero when N > Bn2A2/6. We conclude 
by Lindeberg’s theorem that SN is approximately Gaussian with mean zero and 
variance u2 when the v, satisfy (7.23) and N is sufficiently large. 
Example 3. Bounded Variables with Bounded Variances 
In this example, we suppose that the game-theoretic variance v,, instead of being 
fixed in advance of the game, is determined by Forecaster on the nth round of play, 
just before Skeptic moves. 
BOUNDED 
FORECASTING 
WITH BOUNDED 
VARIANCES 
Parameters: A 2 1, B 2 1, u2 > 0, KO > 0 
Players: Forecaster, Skeptic, Reality 
Protocol: 
F O R n =  1, ..., N :  
N 
Respecting the constraint 
Skeptic announces M, E R and a number V, E R. 
Reality announces x, E [-AJv,, AJv,]. 
vi = r2, 
Forecaster announces v, E [0, Bo2/N]. 
K, := K,-1 + Mnxn + Vn(xi - v,). 
This protocol is obviously coherent: Forecaster and Reality can prevent Skeptic from 
increasing his capital by setting all the v, equal to r 2 / N  and setting x, equal in 
absolute value to a / J N ,  with sign opposite to M,. 
In order to fit the example into our formulation of Lindeberg’s theorem, we must 
treat Forecaster’s move v, as part of Reality’s move on the preceding round of 
play, the (n - 1)st round. This means that we have a 0th round of play in which 
Reality makes a move xo and Forecaster makes her first move, v1. The move 20, 
although irrelevant to Skeptic’s capital, becomes part of the record of play, along 
with the moves by Forecaster. So the situation just before Reality’s move x, is now 
~
0
~
1
~
1
~
2
~
2
~
3
 
. . . x,-1v, instead of xlx2 . . . z,-1. By our usual argument, we find 
that the prices of x, and 
As in the preceding examples, we study the martingale S, = Cy=l xi. So 
once again G s ( E )  = k s ( E )  = o2 for all <. Forecaster is constrained to keep 
v, 
_< Bu2/N, and Reality is then constrained to keep xi 5 A2v,, and so x$ 5 
Bu2A2/N. So again the inequality x: 2 6 is ruled out and L s , ~  
is identically zero 
when or N > Bu2A2/6. We again conclude by Lindeberg’s theorem that SN has 
approximately a normal distribution with mean zero and variance u2 when N is large 
enough-this 
time large enough relative to Bu2A2. 
in this situation are 0 and v,, respectively. 

162 
CHAPTER 7: LINDEBERG’S THEOREM 
Example 4. Lyapunov’s Condition 
Before Lindeberg’s 1922 article, the weakest conditions under which the central limit 
theorem was known to hold had been given by Lyapunov. Lyapunov’s condition 
was that the absolute third moments of the variables be bounded. As Lindeberg 
showed, Lyapunov’s theorem followed easily from his own. This is also clear in the 
game-theoretic context. 
In order to express Lyapunov’s theorem game-theoretically, we require Forecaster 
to give upper prices for the 1z,I3. 
At the beginning of the game, we fix and make 
known to both players a constant t > 0. 
LYAPUNOV’S 
PROTOCOL 
Parameter: N, 
t > 0, KO > 0 
Players: Forecaster, Skeptic, Reality 
Protocol: 
F O R n = l ,  ..., N :  
Forecaster announces v, 2 0 and w, 2 0. 
Skeptic announces M, E !E, V, 
E !E, and W, E R. 
Reality announces z, 
E R. 
K ,  := K , - ~  + M~~~ + v,(~: - v,) + ~ , ( / ~ , 1 3  - w,). 
N 
N 
Additional Constraints on Forecaster: 
v, = 1, 
w, 5 t. 
Corollary 7.1 (Lyapunov’s Theorem) Suppose U is a bounded continuous func- 
tion. I f r  is suficiently small and N is suficiently large, then the initial upper and 
lower prices of U ( 
To derive this as a corollary of Lindeberg’s Theorem, notice that 
z,) 
will both be arbitrarily close to 
U ( z )  ,VT],l (dz). 
N 
This, together with 
w, 5 t, makes it clear that we can satisfy Lindeberg’s 
condition with any 6 taking E small enough. This is the standard proof of Lyapunov’s 
theorem; see, for example, [287]. 
This game-theoretic version of Lyapunov’s theorem can be strengthened by re- 
quiring Skeptic to make W, nonnegative, but because this produces an asymmetric 
protocol, the result does not follow from our version of Lindeberg’s theorem. 
Example 5. Calibrating the Weather Forecaster 
Forecaster gives a probability p that it will rain, Skeptic bets for or against rain at the 
odds defined by p ,  and then Reality decides whether it rains or not. As we explained 
in 3 1.1, this is the prototypical probability game. 
Lindeberg’s theorem can be used to assess one particular aspect of the Forecaster’s 
ps: their calibration. Forecaster is said to be calibrated if it rains as often as he leads 

7.3: EXAMPLES OF THE THEOREM 
163 
us to expect. It should rain about 80% of the days for which p is 0.8, about 70% of 
the days for which p is 0.7, and so on. During a period when p varies, the frequency 
with which it rains should approximate the average of the ps. So in order to judge 
whether Forecaster is doing as well as he ought, we might monitor him for N days 
and calculate the difference between the his average probability and the frequency 
with which it rains. But how should we choose N? And how large should the 
difference be before we reproach Forecaster for his lack of calibration? 
We cannot choose N in advance, 
because we can learn something 
about Forecaster’s calibration only 
on days when forecasting is diffi- 
cult. When rain is clearly impossi- 
ble, Forecaster’s p will be 0; when 
rain is clearly inevitable, his p will 
be 1. If all the days we monitor 
are like this, we will learn noth- 
ing about how well Forecaster does 
when forecasting is difficult. We 
need to wait, however long it takes, 
until some hard cases come along. 
Reality’s move on day n, x,, is 
coded as 1 for rain and -1 for no 
rain, then (as we will verify shortly) 
the game-theoretic variance for 2n 
caster’s p for day n. This is zero 
when p ,  is 0 or 1. The most telling tests of Forecaster’s calibration will come 
when the game-theoretic variance is relatively large, say when p ,  is between 0.2 
and 0.8. We do not know in advance how often Forecaster will give forecasts with 
large p,(l - pn), so we may want to continue our monitoring until the sum of the 
p,(l - p,) reaches some fixed level that we consider adequate. This leads us to the 
following protocol. 
~ __ 
Phil Dawid, in the foreground, with Glenn Shafer 
on Lake Huron, during an excursion from the Fields 
is h ( l  - pn), where pn is Fore- Institute, October 1999. 
BINARY PROBABILITY 
FORECASTING 
Parameters: C > 0, KO > 0 
Players: Forecaster, Skeptic, Reality 
Protocol: 
FOR n = 1,2,. . .: 
Forecaster announcesp, E [0, 11. 
Skeptic announces Mn E R. 
Reality announces 2, E { 0, l}. 
K, := Icn-1 + Mn(xn -pn). 
STOP if cy=l 
pi(1 - pi) 2 C. 

764 
CHAPTER 7: LINDEBERG’S THEOREM 
We require that Forecaster eventually satisfy cy=l 
pi( 1 - pi) 2 C so the game will 
stop. We assume that C is very large, and since the increments of the sum are always 
between zero and .25, it will stop at a value relatively quite close to C. 
It is easy to check that this is a Lindeberg protocol. Forecaster and Reality can 
keep Skeptic from making money by setting p, = 1/2, x, := 0 when M ,  2 0, and 
x,, := 1 when AdTL < 0. 
In the situation just before Reality announces x,, it has price p ,  and game- 
theoretic variance p,( 1 - pn), just as we expected. It has price p ,  because Skeptic 
has a strategy for getting exactly x, beginning with capital pn: he sets M, equal to 
1 and his later Mi equal to zero. It has variance p,(l - p,) because Skeptic has a 
strategy for getting exactly (2, - p,)’ 
starting with capital p,(l - p,): he sets M, 
equal to 1 - 2p,, and his later Mi equal to zero. (This returns (1 - 2p,)(z, - p,), 
which is equal, because 
= xn, to (x, - P , ) ~  - p,(1 - p,).) 
Our test statistic will be SN, where S is the martingale defined by 
We have 
1 
so 
1 
C 
V x i x Z  ... xn-l dxlxz ... z n - l S  = - ~ n ( 1  -pn), 
and hence 
- 
1 ,  
\%(I) = &(I) = - CPd1 -Pi), 
C .  
2=1 
which will be quite close to 1 at the stopping time no matter what path 
Reality 
takes. The squared gain &(xi - pi)’ never exceeds 1/C. So, provided C is big 
enough, the inequality &(xi - pi)2 2 6 is ruled out and L s , ~  
is identically zero. So 
the conditions of Lindeberg’s theorem are met. 
We conclude that SN should have approximately a standard Gaussian distribution. 
So we will be entitled to question the calibration of Forecaster if ISN I exceeds 2 or 3. 
For further discussion, see Dawid [84, 851 and Dawid and Vovk [86]. 
7.4 APPENDIX: THE CLASSICAL CENTRAL LIMIT THEOREM 
As we noted in 52.1, the central limit theorem grew out of Jacob Bernoulli and 
Abraham De Moivre’s investigations of the speed with which the frequency of an 
event approaches its probability in repeated independent trials, such as the toss of 
a coin. When a coin is tossed N times, with probability p of heads each time, the 
probabilities for the number of heads, y, are 
N! 
P{y = k }  = 
PkQN-k, 
k!(N - k ) !  

7.4: APPENDIX: THE CLASSICAL CENTRAL LIMIT THEOREM 
165 
where q = 1 - p .  This is the binomial distribution. Bernoulli and De Moivre 
proved their respective theorems by studying the binomial distribution directly [3]. 
De Moivre’s theorem can be written in the form 
(7.24) 
where  NO,^ is the standard Gaussian distribution. De Moivre did not have the idea 
of a continuous probability distribution, but subsequent work by Laplace and Gauss 
led to the understanding that (7.24) is an approximation of the binomial, a discrete 
distribution, by the standard Gaussian, a continuous distribution. 
Laplace generalized De Moivre’s result 
to independent identically distributed ran- 
dom variables 21,. . . , XN: if N is large 
enough, then the normalized sum 
where p and o2 are the common mean and 
variance, will be approximately standard 
Gaussian (Stigler 1986). Laplace’s proof, 
based on a discrete version of what prob- 
abilists now call the characteristic func- 
tion and other mathematicians now call 
Pierre Simon Laplace (1749-1827), 
the 
the ~~~~i~~ 
transform, really applied only 
most illustrious scientist of the golden age 
to the very simple case where the zn are 
Of French science. 
bounded and take only values that are integer multiples of some small number. The 
task of perfecting the proof and relaxing its hypotheses was taken up by the Russian 
school of probability theorists-Pafnutii 
Chebyshev (1821-1 894) and his students 
Andrei Markov (1856-1922) and Aleksandr Lyapunov (1857-1918). Chebyshev 
and Markov proved the central limit theorem under conditions weaker than Laplace’s 
using moments, and Lyapunov later proved the same theorems using characteristic 
functions. 
The nineteenth-century authors did not use the name “central limit theorem”. 
Apparently it was George P6lya (1887-1985), writing in German in 1920, who first 
spoke of the zentralen Grenzwertsatz of probability theory. Since Grenzwertsatz, the 
German equivalent of limit theorem, is a single word, P6lya clearly meant that the 
theorem, not the limit, is central. But some authors in English and French have used 
the name to underline the fact that the theorem concerns the behavior in the limit of 
central rather than extreme values of a sum of random variables ([ 1921, p. 79). 
Jar1 Waldemar Lindeberg (1876-1932), a mathematician at the University of 
Helsinki, first advanced his method of proof of the central limit theorem in 1920, in 
an article published in a Finnish journal. He was unaware of Lyapunov’s work when 
he published this article, but he subsequently realized that he could use his method 
with weaker conditions and derive Lyapunov’s theorem as a corollary; he did this in 

166 
CHAPTER 7: LINDEBERG’S THEOREM 
his 1922 article. His method of proof was immediately taken up by Paul LCvy, who 
used it, together with the characteristic-function method, in his 1925 book. 
Lindeberg expressed his result as a limit theorem, applicable to an infinite sequence 
of independent random variables 1 c 1 , 2 2 , .  . . with means p1) p2,. . . and variances 
0;) 
04 . . . . He showed that 
for every positive number E .  The condition (7.26) says that none of the lzll - pnl are 
likely to be very large relative to L/ Cf=’=, 
pi, the standard deviation of their sum; 
each makes an individually negligible contribution to the sum. Lindeberg’s result 
is definitive for independent random variables because, as Paul LCvy and William 
Feller both showed in 1935 [122, 198, 1921, (7.26) is roughly necessary as well as 
sufficient for (7.25). The statement is only roughly true because some of the variables 
in the sum can be themselves exactly Gaussian, and such summands can have any 
variances whatsoever ([287], 111.5; [356], Theorem 5.2.5). We can make a precise 
statement by considering the condition 
(7.27) 
which is implied by (7.26). It turns out that (7.26) holds if and only if both (7.27) 
and (7.25) hold. So when (7.27) is assumed, we can say that Lindeberg’s condition, 
(7.26), is necessary and sufficient for the central limit theorem, (7.25), for independent 
random variables. 
Beginning with further work by Levy in the 1930s, work on the central limit 
theorem shifted to the martingale case, where Lindeberg’s condition is also applica- 
ble [144, 2061. Levy also initiated, in 1937, work on versions of the central limit 
theorem that do not even require the existence of the variances pf, 02” . . . . These 
versions justify a very general qualitative statement: a sum of independent variables, 
appropriately centered and normalized, will be nearly Gaussian if and only if each 
variable has a dispersion small relative to the dispersion of the sum or is itself nearly 
Gaussian ([192], Theorem 2; [356], Theorem 5.2.5). 

8 
The Generality of 
Probabilitv Games 
J 
In preceding chapters, we demonstrated the value of the game-theoretic framework 
by example. We looked at probability’s classical limit theorems one by one, showing 
in each case how well the game-theoretic framework captures the theorem’s classical 
intuition and generalizes its scope. In this chapter, we study the effectiveness of the 
game-theoretic framework in more abstract ways. 
We begin, in 58.1, by showing that the game-theoretic framework is strictly 
more powerful, in at least one important respect, than the measure-theoretic frame- 
work. The game-theoretic limit theorems that we proved in the preceding chapters 
actually imply the corresponding measure-theoretic versions of these theorems (Kol- 
mogorov’s strong law, the law of the iterated logarithm, and Lindeberg’s theorem). 
This is because the game-theoretic limit theorems all assert the existence of certain 
martingales, which are constructed from other martingales in a computable and hence 
Bore1 measurable way. These constructions can also be applied to martingales in the 
measure-theoretic framework, and this yields the corresponding measure-theoretic 
limit theorems. But there is no easy way to go in the opposite direction, from the 
measure-theoretic to the game-theoretic limit theorems. 
In $8.2, we look at how the game-theoretic framework deals with the historical 
and conceptual kernel of probability theory: coin tossing. Remarkably, the game- 
theoretic and measure-theoretic treatments of coin tossing have much in common: 
the same sample space, the same martingales, and the same probabilities. So we can 
say that the two frameworks represent two different ways of generalizing a common 
classical kernel. 
In $8.3, we return to the abstract study of game-theoretic price and probability 
that we began in $1.2 and $1.3 and continued in 57.1. One point of this section 
167 
Probability and Finance: It’s Only a Game! Glenn Shafer, Vladimir Vovk 
Copyright 0 2001 John Wiley & Sons, Inc. 
ISBN: 0-471-40226-5 

168 
CHAPTER 8: THE GENERALITY OF PROBABILITY GAMES 
is to reassure those readers who think of Kolmogorov’s axioms and definitions as 
the essence of probability theory that similar and equally abstract properties can be 
formulated and derived in the game-theoretic framework. These include the rule of 
iterated expectation and linearity (or sublinearity or superlinearity) of price. 
In $8.4, we underline the practical importance of the generality of the game- 
theoretic framework by looking at two scientifically important probability models 
that are easily understood in terms of probability protocols but do not fit into measure 
theory: quantum mechanics and the failure model in medical statistics. These 
models are probabilistic but open; they model processes that are open to external 
and unmodeled influences. Probabilities are determined as such a process proceeds, 
but not by the model alone; they are also influenced by factors outside the process. 
In the end, the model and these outside influences have determined a sequence 
of probabilities (or even probability distributions) for the successive steps, but no 
probability measure for the process as a whole is ever determined. 
In an appendix, $8.5, we state and prove Ville’s theorem, which relates probabilities 
in a filtered probability space to martingales. This theorem is used in $8.1 and 58.2. 
In a second appendix, 58.6, we provide some biographical information about Jean 
Ville. 
8.1 DERIVING THE MEASURE-THEORETIC LIMIT THEOREMS 
In this section we derive the three most important measure-theoretic limit theorems- 
Kolmogorov’s strong law of large numbers, the law of the iterated logarithm, and 
Lindeberg’s theorem-from 
the game-theoretic versions that we proved in Chapters 4, 
5, and 7, respectively. 
The game-theoretic strong laws assert that Skeptic can force certain events in 
the unbounded forecasting game. Kolmogorov’s strong law says that Skeptic can 
force the convergence of a certain average deviation to zero. The law of the iterated 
logarithm asserts that he can force the oscillation during the convergence to have 
certain properties. Here we restate these two game-theoretic results so that they also 
assert the Borel measurability of the strategies that enable Skeptic to force these 
events. The measure-theoretic versions of the two strong laws then follow easily. 
Our derivation of the measure-theoretic version of Lindeberg’s theorem from the 
game-theoretic version is similar; we begin by restating the game-theoretic version 
so that it asserts the measurability of what Skeptic does, and then we derive the 
measure-theoretic version from this restatement. The argument is more complicated 
than in the case of the strong laws, however, because the game-theoretic version 
of Lindeberg’s theorem begins with a game-theoretic martingale S that need not 
be measurable and constructs a strategy for Skeptic from S and from martingales 
witnessing certain conditions on S. Here it is the transformation, not the strategy 
itself, that is computable and therefore Borel measurable. 
In the rest of this section we emphasize measurability rather than computability, 
but this should not be misunderstood. In our view, measurability has no foundational 
role within the game-theoretic framework per se. We introduce it here only to make 

8.1: DERlVlNG THE MEASURE-THEORETIC LIMIT THEOREMS 
769 
the relation between the game-theoretic and measure-theoretic frameworks as clear 
as possible for readers already trained in measure theory. From the game-theoretic 
point of view, the important point about the strategies constructed in Chapters 4 
and 5 and the martingale transformation constructed in Chapter 7 is that they are 
computable. Computability is obviously important for applications, and it raises 
many interesting questions for further research, as we noted in $3.5. Computable 
functions and transformations are necessarily Bore1 measurable, but measurability 
by itself does not accomplish anything within the game-theoretic framework. 
Filtrations and Measure-Theoretic Martingales 
Before we look at the limit theorems, we must first extend the review of measure- 
theoretic terminology and notation that we began in $2.2. 
A measurable space is a nonempty set R together with a n-algebra 3 of subsets of 
R. A subset of R is measurable if it is in F. 
Elements of 3 are also called events. A 
real-valued function z on R is measurable if {c I z(E) 5 u }  is measurable for every 
real number a. 
A$ltration in a measurable space ( R , 3 )  is a sequence {3,}~=0 
of successively 
larger a-algebras all contained in 3: FO C 3 1  2 . . . . We write Fm for the smallest 
a-algebra containing all the 3,. 
A$ltered measurable space is a measurable space with a filtration. A sequence 
21, z2, 
. . . of functions on a filtered measurable space (R, 3, {3,}r=O) 
is adapted 
if z, 
is measurable with respect to 3, for n = 1,2,. . .; it is predictable if 2, 
is measurable with respect to F,-I 
for n = 1 , 2 , .  . . . A sequence VO, V1,. . . of 
functions is a process if V, is measurable with respect to F, for n = 0, 1, . . . . If 
V1, V2, . . . is a predictable sequence, we say the process is predictable. A function r 
is a stopping time if (1) T ( W )  is a natural number for all w E R and (2) {w I ~ ( w )  
= 
n} E 3,forn = 1,2, .... 
A probabilily space is a measurable space (a, F) 
together with a probability 
measure p on 3. A filtered probability space is a probability space with a fil- 
tration. It is customary to assume that the a-algebra 3 0  in a filtered probability 
space (a, 
3, {3,}r=0, 
P) contains all of p’s null events-that 
is, every E E fl 
such that P E = 0, but we will sometimes find it convenient to assume instead that 
A measurable function on a probability space is called a random variable. Given 
a random variable z whose expected value exists and a a-algebra 6 contained in 3, 
there exists at least one random variable y that is measurable with respect to G and 
satisfies E[z IE] = lE[y IE] for every E in G. Any such random variable y is called 
a version of the conditional expectation of 
with respect to 6. Any two versions of 
the same conditional expectation are equal except on a set of measure zero. 
It is customary to write E[z I G] = y to indicate that y is a version of the conditional 
expectation of z with respect to G. More generally, E[z I G] 
can represent an arbitrary 
version of the conditional expectation in an equation or inequality that is stated to 
hold almost surely. This does not entail any ambiguity, because the equation or 
inequality will hold almost surely for one version if and only if it holds almost surely 
3 0  = {0,R}. 

170 
CHAPTER 8: THE GENERALITY OF PROBABILITY GAMES 
for a different one.‘ Conditional variance is handled in the same way; one writes 
A process Lo, C1,. 
. . in a filtered probability space (0, F, 
{Fn}T=,,, 
IP) is a 
V[Z 1 G] for IE[(Z - E[Z I 
I GI. 
measure-theoretic martingale if 
IE[Ln I Fn-11 = Ln-1 
(8.1) 
for n = 1,2, . . . . If FO = (0, R}, then the initial variable Lo will necessarily be a 
constant. Equation (8.1) says that 
is a version of the conditional expectation 
of Cn given Fn-l. 
The Game-Theoretic Strong Laws with Measurability 
Our game-theoretic versions of Kolmogorov’s strong law and the law of the iterated 
logarithm involve no conditions of measurability. But as we noted at the beginning 
of this section, the strategies and capital processes that we constructed to prove 
these theorems are measurable in the sense required. In order to make the theorems 
comparable to measure-theoretic theorems, we now restate them in a way that makes 
this measurability explicit. 
Consider the unbounded forecasting protocol (p. 79), which we used for Kol- 
mogorov’s strong law of large numbers. In this protocol, Forecaster makes moves 
mn E Iw and v, 2 0, then Skeptic makes moves Mn E R and V .  2 0, and then 
Reality makes a move 2 ,  E R. A strategy for Skeptic is therefore a pair of processes 
M1, Ma,. . . and V1, Va, . . . such that for each n, M ,  and V,, are both functions 
of ml , w1,21, . . . , m,-l, ~
~
-
1
,
 
~ ~ - 1 ,  
m,, v,. Mathematically, M 
and V,, can be 
regarded as real-valued functions of 3n - 1 real variables. If these functions are all 
Borel measurable, then we say that the strategy is Borel measurable. 
If E is an event in the protocol, and Skeptic has a Borel measurable winning 
strategy in the game in which his goal is E, then we say that Skeptic can Borel 
force E. The strategy we constructed for Skeptic in 54.2, being the result of simple 
arithmetic and limiting processes, obviously is Borel measurable, and hence we may 
strengthen Statement 1 of Theorem 4.1 to the following: 
Proposition 8.1 Skeptic can Borel force 
1 ,  
00 
(8.2) 
11, 
C - < m ==+ lim - C(xi - m,) = o 
n+w n i=l 
n2 
n=l 
in the unbounded forecasting protocol. 
We can similarly restate Theorems 5.1 and 5.2, which together form our game- 
theoretic version of the law of the iterated logarithm: 
‘We hasten to remind the reader that this practice does not carry over to the game-theoretic framework. In 
the game-theoretic framework, a symbol for a variable always refers to a single particular variable, never 
to a class of variables every two members of which agree only almost surely. 

8.1: DERIVING THE MEASURE-THEORETIC LIMIT THEOREMS 
771 
Proposition 8.2 Skeptic can Borel force 
in the predictably unbounded forecasting protocol, where A, := cy=l ui 
Proposition 8.3 Skeptic can Borel force 
in the unboundedforecasting protocol, where, again, A, := cy=l ui. 
In general, the capital process for Skeptic resulting from an initial capital and a 
particular strategy in the unbounded or predictably unbounded forecasting protocol 
can be thought of as a sequence of variables LO, C1, . . . . Here LO is the initial capital 
and 
Ln(mlvlsl.. .m,v,z,) 
:= C,-l(mlvlzl.. .m,-1un-1s,-1) 
+ Mn(mlulz1 . . . mnUn)(zn - mn) 
+ vn(mlulz1.. . mnvn)((zn - mn)2 - V n )  
(8.3) 
is the capital at the end of the nth round of play. The function L, specified by (8.3) 
is a very simple--certainly measurable-function 
of the moves by Forecaster and 
Reality. So if Skeptic's strategy (MI, Vl), ( M 2 ,  V Z ) ,  . , . is Borel measurable, and 
if all the m,, u,, and z, 
are taken to be measurable functions on some measurable 
space (0, F),2 then LO, C1,. . . will also become measurable functions on (0, F). 
In fact, if {F,}?& is a filtration in (R,F), and the functions m,, u,, and 2, are 
measurable with respect to F, for each n, then C, will also be measurable with 
respect to F, for each n.3 
Deriving the Measure-Theoretic Strong Laws 
The following corollary of Proposition 8.1 is the measure-theoretic form of Kol- 
mogorov's strong law. 
*Here (R, F) 
is an arbitrary measurable space. We are not using the symbol R to designate the sample 
space for the probability protocol, as we usually do. 
We can make this mathematical observation more vivid by imagining that Forecaster and Reality choose 
a particular element w of R at the beginning of the game, behind Skeptic's back, and then simply make 
the moves specified by the measurable functions: ml (w), 
v1 (w), m 2 ( w ) ,  vz(w), 
. . . for Forecaster and 
21 (w), xz(w), 
. . . for Reality. 

172 
CHAPTER 8: THE GENERALITY OF PROBABILITY GAMES 
Corollary 8.1 Ifxl, x2, . . . is an adapted sequence of random variables in ajiltered 
probability space (0,3, {3n}~=)=o, 
P'), then 
almost .~ureLy.~ 
Proof According to Proposition 8. I, the player Skeptic in the unbounded forecasting game has 
a Bore1 measurable strategy ( M  1, V l ) ,  ( M z ,  V Z ) ,  . . . for which the capital process Lo, L1, . . ., 
given by (8.3), is nonnegative no matter how Forecaster and Reality move and diverges to 
infinity if (8.2) fails. Fix versions of the conditional expectations E(z, I F,-i) 
and then of the 
conditional variances v(z, I F,- 
1) (making sure the latter are nonnegative), and substitute 
them for m, and v, in (8.3). Similarly, substitute the random variable x ,  for the move zn 
in (8.3). As we explained in our comments following (8.3), the resulting function c, on 0 is 
measurable with respect to F,. Similarly, M ,  and V, become functions on 0 measurable 
with respect to Fn-l, 
and we can rewrite (8.3) in the form 
c, := en-1 + Mn(zn - E[xn I Fn-11) + V,((%I - E[zn 1 Fn-l])2 - v[xn I Fn-11). 
This implies (8.1). So LO, C1,. 
. . is a measure-theoretic martingale. It is nonnegative and 
diverges to infinity if (8.4) fails. But by Doob's martingale convergence theorem ([287], Theo- 
rem VII.4. I), a nonnegative measure-theoretic martingale diverges to infinity with probability 
zero. (This is one part of what we call Ville's theorem; see Proposition 8.14 on p. 196.) 
I 
Similarly, Propositions 8.2 and 8.3 have the following corollaries, which together 
form a slightly stronger-than-standard version of the measure-theoretic law of the 
iterated logarithm. 
Corollary 8.2 Ifx, is an adaptedsequence of random variables and c, apredictable 
sequence qf random variables in a3lteredprobability space (n, F, 
{.Fn}~=o, 
P'), and 
So (8.4) happens almost surely. 
for all n, then 
( A  ..--....=o(/")) 
In In A, 
= 1  
C?=l (Xi - E[Xi I .Ti-11) 
==+ limsup 
,--too 
d2A, In In A, 
almost surely, where A, := xy=l 
V [ X ~  
I Fi-11. 
4The conclusion is true even if some or all of the zn fail to have (finite) conditional expected values or 
variances on a set of w E R of a positive measure. At such w the conditional variance V[x, I Fn- 
11 does 
not exist or is infinite, and so the left-hand side of the implication (8.4) fails and thus the implication itself 
happens (remember that ( A  ==$ B )  = AC U B). 

8.1: DERIVING THE MEASURE-THEORETIC LIMIT THEOREMS 
173 
Corollary 8.3 Ifx, is an adapted sequence of random variables in a$lteredproba- 
bility space (n,F, {Fn}r=o, 
p), then 
almost surely, where, again, A, := Cy=l V[xi I 3i-11. 
The first of these, Corollary 8.2, is the sharpness part of the law of the iterated 
logarithm as proven by William F. Stout in 1970 (see also his 1973 book). The 
second, Corollary 8.3, strengthens the validity part of Stout’s theorem. 
The Game-Theoretic Form of Lindeberg’s Theorem with Measurability 
We now explain how to add measurability to the conclusion of Theorem 7.1, our 
game-theoretic version of Lindeberg ’s theorem. 
Recall that a probability protocol is a Lindeberg protoco2 if it is symmetric, 
coherent, and terminating. In a terminating protocol, a process C eventually has a 
final value, which we designate by La. We say that a game-theoretic martingale C 
in a Lindeberg protocol witnesses the relation & x < a, where x is a variable and a 
is a number, if C ( 0 )  < a and Co (w) 2 
x for all w E 0; and we say that C witnesses 
the relation F n  E < a, where E is an event, if it witnesses & IIE < a. 
Theorem 7.1 considers certain conditions on a game-theoretic martingale S in a 
Lindeberg protocol. Under these conditions, the Gaussian integral 
V ( z )   NO,^ (dz) 
is an approximate initial price for the payoff U(Sa), where U is a bounded continuous 
function. Our proof, in 57.2, constructed a witnessing game-theoretic martingale. 
Our restatement will point out that the witnessing martingale is obtained from S and 
other game-theoretic martingales in the problem (game-theoretic martingales that 
witness the conditions on S) by a measurable martingale transformation. 
In general, we can construct a new martingale C from martingales S1, . . . , SK 
by selecting an initial value for L and setting each increment of C equal to a linear 
combination of the corresponding increments of the Sk, say 
AC, = ck AS; + c i  AS: + . . . + c: 
AS:, 
(8.5) 
The c i  may depend on the previous values of the Sk and also on the current and 
previous values of other processes, provided the additional processes are predictable. 
Each such process has n previous values (say VO . . . , V,-l) in addition to its current 
value (say Vn). So we can formulate the following definitions: 
A ( K ,  K‘)-martingale transformation C consists of functions ck, for k = 
1, . . . , K and n = 1,2, . . ., where c i  is a real-valued function of nK + (n + 
1)K’ real variables. 

174 
CHAPTER 8: THE GENERALITY OF PROBABlLlTY GAMES 
0 A ( K ,  K‘)-martingale transformation C is measurable if all its ck are Bore1 
measurable. 
0 A process c is a martingale transform of martingales S1, . . . , SK given aux- 
iliary predictable processes R1 , .. . , RK‘ if there exists a ( K ,  K’)-martingale 
transformation C such that (8.5) is satisfied, with the coefficient ck given by 
applying ck to the previous values of S’ , . . . , SK and current and previous 
values of R ~ ,  
. . . , R ~ ’ .  
These definitions can be used both for game-theoretic martingales (in a given symmet- 
ric probability protocol, where the predictability of Rk 
means that 72: is a function 
of World’s first n - 1 moves) and for measure-theoretic martingales (in a given fil- 
tered probability space, where the predictability of Rk 
means that 72; is measurable 
with respect to F,-’). 
In a symmetric probability protocol, a martingale transform 
C is always a game-theoretic martingale, because if S1 , . . . , SK are game-theoretic 
martingales, then (8.5) is enough to ensure that C will be as well. In a filtered prob- 
ability space, on the other hand, we need a bit more. In order to be sure that C, is 
.En-measurable, we need to know that the martingale transformation C is measurable. 
In the preceding paragraph, a process V is represented as a sequence of variables, 
VO, 
V1 , . . . . This permits us to write AV, for the difference V, - V,-l and dV, for 
the difference Vn+l - V,. In the game-theoretic framework, especially in the case 
of a terminating protocol, we often use instead a notation that refers to a specific 
situation t; we write V(t) for V’s value in t, and we write AtV (or dtV) for the 
increment of V immediately before (or after) t (see p. 152). We may relate the two 
notations by writing t, for the nth situation (counting 0 as the 0th situation); then 
V, = V(t,,), AV, = AtnV, and 
dV, = dt,V. 
(8.6) 
The identity of the nth situation depends, of course, on the path w .  If we write tn(u) 
to make this explicit, then (8.6) becomes 
V,,(w) = V(t,(w)), AVn(w) = Atn(,,V, 
and 
dl.’,(w) = dt,(u)V. 
This makes it clear that V, and AV, only have a meaning for a path w on which there 
are at least n situations after 0, 
and dV, only has a meaning for a path w on which 
there are at least n + 1 situations after 0. 
Consider now a game-theoretic martingale S in a Lindeberg protocol. If 
IE,(dtS)2 = Et(dtS)2 
for every nonterminal situation t, then we call S scaled (or 0-scaled). If S is scaled, 
we define a process A, the game-theoretic quadratic variation of S, by setting 
A(t) := c 
Es(dsS)2 
SCt 
(8.7) 
for every situation t (so that A(0) = O), and we define a martingale B by setting 
B ( 0 )  := 0 and 
(8.8) 
dtB := ( d t s y  - IEt(dtS)2 

8.1: DERIVING THE MEASURE-THEORETIC LIMIT THEOREMS 
175 
for every nonterminal situation t. The current value of B is always determined by 
current and past values of S and A. 
If 6 > 0 and 
for every nonterminal situation t, then we call S &scaled. If S is &scaled, we define 
a process C by setting 
C ( t )  := c 
Es [(dsS)2qd.s12s] 
(8.9) 
forevery situation t (soC(0) = 0), and we define amartingalellby settingU(0) := 0 
and 
dtll := (dtS)2qdtsl>6 - Et [(dtS)2qdts1>6] 
(8.10) 
for every nonterminal situation t. The current value of 24 is always determined by 
current and past values of S and C. 
The proof of Theorem 7.1 in $7.2 involved the construction of a measurable 
martingale transformation. We now restate the theorem to make this explicit. For the 
sake of clarity, we simplify a bit as we do so; we consider only scaled and 6-scaled 
martingales. 
Proposition 8.4 Suppose U is a bounded continuous function, and suppose E > 0. 
Then there exists 6 > 0 and a measurable (4,2)-martingale transformation C such 
that ifS is a scaled and S-scaled game-theoretic martingale in a Lindeberg protocol 
and 
PO (Id0 - 11 > 6 or& > S} < 6, 
(8.11) 
S C t  
- 
then 
is witnessed by the game-theoretic martingale obtained by applying C to S, B, U ,  
and W given A and C, where W is any game-theoretic martingale witnessing (8.1 I ) ,  
and A, B, C andU are defined by (8.7), (8.8), (8.9), and(8.10), respectively. 
The restriction to game-theoretic martingales that are scaled and 6-scaled makes 
Proposition 8.4 less general than Theorem 7.1. This restriction is not necessary, 
but it simplifies the statement of the proposition considerably, and the result is still 
sufficient for the derivation of the theorem’s measure-theoretic counterpart. 
When the conditions of Proposition 8.4 are satisfied by S, they are also satisfied 
by -S, and when the proposition is applied to -S and to the bounded continuous 
function -U( -s), it yields a game-theoretic martingale witnessing 
00 
ED [U(SQ)I > lm 
~ ( 2 )  
Nn,i(dz) - c. 
So the final conclusion is the same as in Theorem 7.1: The initial upper and lower 
prices of U(S0) are both close to / U ( z )  No,l (dz). 

176 
CHAPTER 8: THE GENERALITY OF PROBABILITY GAMES 
Deriving the Measure-Theoretic Form of Lindeberg’s Theorem 
We can now derive the measure-theoretic form of Lindeberg’s theorem (see, e.g., 
[206], Theorem 5.5.9) as a corollary of Proposition 8.4. 
We begin by associating processes A and C with any measure-theoretic martingale 
S in a filtered probability space. For n = 0,1, . . ., we set 
n 
2= 1 
and 
i= 1 
The process C depends, of course, on the choice of the positive constant 6. The 
process A is the measure-theoretic quadratic variation of S. 
Corollary 8.4 Suppose U is a bounded continuous function, and suppose E > 0. 
Then there exists 6 > 0 such that ifS is a measure-theoretic martingale and r is a 
stopping time in a$ltered probability space, and 
p {IA, - 11 > S or C, > S} < 6, 
(8.13) 
then 
Proof Consider the number b > 0 and the measurable martingale transformation C given for 
E and U by Proposition 8.4. Fix a filtered probability space (0,3, 
{Fn}r=o, 
P), a stopping 
time 7, 
and a measure-theoretic martingale S satisfying (8.13). 
By Ville’s theorem (Proposition 8.13), there exists a measure-theoretic martingale W that 
witnesses (8.13)-that 
is, for which Wo < 6 and W ,  exceeds the indicator function for the 
event { 1.4, - 11 > 6 or C, > S}. Fix W .  Define measure-theoretic martingales B and U by 
setting BO and 240 equal to zero and setring 
A& := 
- E[(ASn)2 I Fn-l] 
and 
AUn := (ASn)21jas,l>s - E[(ASn)211as,/>s 
I F n - I ]  
for n = 1,2, . . . . Let ,C be the measure-theoretic martingale obtained by applying C to S, 
B, 
U, 
and W given A and C. 
Wenow defineaLindebergprotocolfrom the filteredprobability space (Q, F, 
{ F n } ~ . ~ ,  
P), 
the stopping time T ,  and the four processes S ,  W ,  A, and C. First we set 
w n  
(w) := (Sn (w), wn (w), An ( w ) ,  Cn (w), I,,,),,) 
(8.15) 
for each w E R. Then we set 
a’ 
:= {w1(w),w2(w), . . . , w,(u)(w) I w E Q}; 

8.2: COIN TOSSING 
177 
this is the sample space of the Lindeberg protocol. (The flag Ir(u)=, in (8.15) ensures that 
no proper initial subsequence of a sequence in a’ 
is also in 0’; see p. 149.) We can interpret 
the four processes S, W ,  A, and C as processes in this game-theoretic sample space, because 
their nth values are always identified by World’s nth move w,. The same is true for B and U, 
because their current values are always identified by the current and previous values of S, 
A, 
and C. Then we define Skeptic’s move space and gain function in each nonterminal situation 
t by allowing him to buy arbitrary multiples of the increments d t S ,  dtW, dtB, and dtU for 0. 
Because Skeptic can buy their increments for 0, the four processes S, 
W ,  23, and U are 
game-theoretic martingales in the Lindeberg protocol. So the martingale transform C is as 
well. By Proposition 8.4, C witnesses (8.12) in the Lindeberg protocol. This means that 
< U ( z )  n/o,l(dz) + E and C, 2 U(S,). Because C is a measure-theoretic martingale I 
in the filtered probability space, this implies (8.14) by Ville’s theorem. 
By applying Corollary 8.4 to -S and -U(-s), we can establish further that 
V ( z )  ,440~ (dz) -c. So altogether we have the usual conclusion: 
IE [U(S,)] exceeds 
IE [U(S,)] is close to J U ( z )  ~%~,~(dz). 
8.2 COIN TOSSING 
In this section, we compare the measure-theoretic and game-theoretic frameworks 
for coin tossing. Superficially, the game-theoretic picture looks very different from 
measure theory even in this simple case. The outcome of each toss is a move by 
Reality. Probabilities enter as moves by Forecaster. But once we fix a strategy for 
Forecaster, we obtain a probability measure for Reality’s moves, and then the picture 
looks more like measure theory. Indeed, as we will verify, we get the same martingales 
and probabilities whether we think game-theoretically or measure-theoretically. 
The two generalizations go in different directions, but in some cases the game- 
theoretic interpretation of a probability measure can be extended beyond coin tossing, 
and this can have some practical advantages. 
Binary Probability Forecasting 
Consider the following coherent probability protocol, in which Reality always makes 
a binary choice, and Forecaster always gives a probability for what she will do. 
BINARY 
PROBABILITY 
FORECASTING 
Parameter: KO E R 
Players: Forecaster, Skeptic, Reality 
Protocol: 
FOR n = 1,2,. . .: 
Forecaster announcesp, E (0,l). 
Skeptic announces Mn E W 
Reality announces 2, E (0, l}. 
IC, := Icn-1 + M,(Xn -pn). 

178 
CHAPTER 8: THE GENERALITY OF PROBABILITY GAMES 
This is identical with the binary forecasting protocol we studied in Chapter 7 (p. 162), 
except that it does not terminate. 
Forecaster has two opponents, Skeptic and Reality. We are interested in strate- 
gies for Forecaster that ignore previous moves by Skeptic, taking into account only 
previous moves by Reality. Such a strategy-we 
may call it a neutral .forecasting 
strutegy--can be specified by a family of numbers 
{Pt}t€(O,l}*, 
(8.16) 
where {0,1}* denotes the set of all finite sequences of 0s and Is, including the empty 
sequence 0, 
and 0 < pt < 1. The strategy directs Forecaster to set pl equal to PO 
and to set p ,  equal to pzl ...z,-l if Reality's first n - 1 moves are 21 . . . ~ ~ - 1 .  
If we require Forecaster to use a particular neutral forecasting strategy, then he 
has no decisions left to make, and we can remove him from the description of the 
protocol. We thereby obtain the following coherent probability protocol involving 
Skeptic and Reality only. 
COIN TOSSING 
Parameter: KO E R, neutral forecasting strategy {pt}tE(o,l)* 
Players: Skeptic, Reality 
Protocol: 
FOR n = 1 , 2 , .  . .: 
Skeptic announces Mn E R. 
Reality announces 2 ,  E (0, l}. 
K, := G - 1  + Mn(& - pzl...zn-l). 
If the pt are all equal to 1/2, this reduces, essentially, to the fair-coin protocol that 
we studied in Chapter 3 (p. 64). 
For Coin-Tossing, Forecaster's Strategy = Probability Distribution 
As the reader may have noticed, a neutral forecasting strategy for the binary fore- 
casting protocol amounts to the same thing as a positive probability distribution for 
an infinite sequence of 0s and 1s. 
Recall that a probability distribution for an infinite sequence of 0s and 1s is a 
probability measure on the filtered measurable space ((0, l}",C, 
{ C n } ~ z o ) ,  where 
C, consists of cylinder sets corresponding to subsets of (0, l}", and C = C,. 
Such 
a probability distribution p is completely determined once we give, for every finite 
sequence x1 . . . 2, of 0s and Is, the probability for the cylinder set corresponding to 
the element 51 . . . Z, 
of (0, l}". We may write [ X I  . . . z,] 
for this cylinder set and 
P[zl . . . z,] 
for its probability. If 
P[Zl . . .Z,] > 0 
for every finite sequence z1 . . . x, of 0s and Is, then we say that the probability 
distribution P is positive. 

8.2: COIN TOSSING 
179 
There is a one-to-one correspondence between neutral forecasting strategies and 
0 Given P, 
we can define {pt}tE{o,l). 
by setting the pt equal to P's conditional 
positive probability distributions for an infinite sequence of 0s and 1s: 
mobabilities: 
0 Given {pt}tE(o,l}*, 
we can define probability distributions {Pt}tE(o,l}* 
in 
{0,1) by 
(8.17) 
and then we can define p by setting 
For Coin Tossing, Game-Theoretic = Measure-Theoretic 
We now come to our main point. For coin tossing, we get the same martingales and 
probabilities whether we think game-theoretically or measure-theoretically. 
Proposition 8.5 Consider a coin-tossing protocol with parameter {pt}tE{o,l)* 
and 
the$lteredprobability space (P, 
(0, l}", C ,  {C,};=.=,) 
defined by (8.17) and (8.18). 
1. Every game-theoretic martingale in the coin-tossing protocol is a measure- 
theoretic martingale in the probability space. 
2. Every measure-theoretic martingale in the probability space is a game- 
theoretic martingale in the coin-tossing protocol. 
3. Every event in the probability space has a game-theoretic probability in the 
protocol, which is equal to the event's probability in the probability space. 
Proof We begin by observing that the protocol and the probability space have the same 
processes. In either case, a process is a real-valued function C on (0, l}*. It can also be 
described as a sequence LO, C1,. 
. ., where Cn is a function of TZ binary variables 21,. . . , zn. 
Because of the simplicity of the probability space, there are no measurability problems; all 
functions of z1 . . . z, 
are measurable. 
To prove Statement 1, we begin by observing that pzl...zn-l, 
considered as a function of 
z1, . . . , zn- 
1, is the unique version of the conditional expectation E[z, I 21, . . . , zn-l]. 
The 
condition for a process C to qualify as a game-theoretic martingale is that 
C ( Z ~ , .  . . , z n )  = C(z1,. . . , ~ n - 1 )  + M(z1,. . . , ~ n - l ) ( ~ n  
- p z l , . , z n - l )  
(8.19) 
Taking the conditional expectation of both sides with respect to 
for some process M .  
2 1 ,  . . . , zn-l and substituting E[z, I z1, . . . , zn-l] for pzl...z,-l, 
we obtain 
E[C(Zl,. . . ,zn) 
1 2 1 , .  . . , zn-11 = C(z1,. . . , zn-l), 
(8.20) 

180 
CHAPTER 8: THE GENERALITY OFPROBABILITY GAMES 
the condition for C to qualify as a measure-theoretic martingale. 
To prove Statement 2, we use the fact that z, 
can only take the values 0 and 1 to write 
C(z1,. . . ,z,) 
= C(z1,. . . ,%*-I, 1)z, + C(z1,. . . ,X,-I, 
0)(1- 2,) 
for any process C. This implies 
C(z1,. . . , z,) - E[L(z1,. . . ,z,) 
I E l , .  . , ,En-13 
(8.21) 
= M(zI,. . . , I ~ L - I ) ( Z ~  - E[z, I X I , .  . . , z n - l ] )  
almost surely, where M is the process defined by 
M(z1,. . . , zn-I) := Cn(z1,. . . , ~ ~ - 1 , l )  
- C n ( ~ 1 , .  
. . , z n - ~ ,  0). 
Because conditional expectations are unique, we can substitute pzl...z,-l for E[z, I 
X I , .  . . ,zn-l] in (8.21). If C is a measure-theoretic martingale, then we can also substi- 
tute C(z1, . . . , ~
~
-
1
)
 
for E[C(zl,. . . , 2,) I z1, . . . , zn-l], obtaining (8.19). 
Now suppose E is an event in the probability space-that 
is, E E C. Then by Ville's 
theorem for positive probabilities, Proposition 8.13, 
(8.22) 
where C ranges over measure-theoretic martingales. The initial game-theoretic upper proba- 
bility of E ,  
E, is given by exactly the same formula, with C ranging over game-theoretic 
martingales. Because the measure-theoretic and game-theoretic martingales are the same, we 
can immediately conclude that PO E = lip E. Similarly, PD E" = PEC, or p E = Lo E. 
I 
Generalizing from Coin Tossing 
It is instructive to think about the game-theoretic and measure-theoretic frameworks 
as two different generalizations of coin tossing. The game-theoretic generalization 
enlarges the freedom of both Reality and Forecaster. Reality may have more than 
a binary choice, and Forecaster may say much or little about what Reality will do. 
The measure-theoretic generalization, on the other hand, keeps Reality subject to a 
probability measure. This measure is analogous to our Forecaster, but in general it is 
more ambitious; it gives a price for every possible aspect of what Reality will do. 
To what extent can the measure-theoretic generalization of coin tossing be under- 
stood inside our game-theoretic generalization? 
Certainly we can generalize probability forecasting beyond the binary case. We 
might, for example, ask Forecaster to give a whole probability measure for an outcome 
(such as a real number) to be announced by Reality, thus obtaining this generalization: 
PROBABILITY 
FORECASTING 
Parameters: Measurable space (O., F), 
KO E R 
Players: Forecaster, Skeptic, Reality 
Protocol: 
FOR n = 1,2,. . .: 
Forecaster announces a probability measure pn on (O., F). 

8.2: COIN TOSSING 
181 
Skeptic announces a measurable function f n  on 0, such that so. fndpn, 
Reality announces x, E R.. 
the expected value of fn with respect to p,, exists. 
X n  := X n - 1 - t  fn(xn) - so, fndpn. 
This is a coherent probability protocol, with a very complex sample space. The paths 
are sequences pl, x1 ,p2, 
x2,. . ., where the x, are elements of 0. and the pn are 
probability measures on 0.. 
A neutral forecasting strategy for this protocol is a family of probability dis- 
tributions {Pt}tcfi:, where 0: denotes the set of all finite sequences of elements 
of 0.. Imposing such a strategy on Forecaster produces this generalization of the 
coin-tossing protocol: 
GENERALIZED 
COIN TOSSING 
Parameters: (O*, F), 
KO E R, neutral forecasting strategy {Pt}tcn: 
Players: Skeptic, Reality 
Protocol: 
FOR n = 1,2,. . .: 
Skeptic announces a measurable function f n  on 0. such that EZ1...,n-lfn, 
Reality announces x, E 0.. 
the expected value of f,(z,) with respect to P,, ...,n-l, 
exists. 
Gz := L - 1  + fn(xn) - E  z1 ... zn--lfn. 
Here the paths are merely sequences x1,x2, . . ., and the sample space is the Cartesian 
product R r .  A simple special case is where 0. is equal to (0, l}; in this case the 
generalized coin-tossing protocol is the same as the coin-tossing protocol except that 
some of the probabilities pt may be equal zero or one. 
Intuitively, the P,, ,,,,,-, in the generalized coin-tossing protocol are conditional 
probabilities, and so this protocol can be thought of as a game-theoretic representation 
of probability models, such as Markov chains, that are defined by means of successive 
conditional distributions. 
If the neutral forecasting strategy is measurable (i.e.,P,l...,n-l (A) is ameasurable 
function of xl, . . . , z,-1 for all n and all measurable A C_ O.), then it determines a 
probability measure on O r  by Ionescu-Tulcea’s theorem ([287], 511.9). We can then 
prove the following generalization of Statement 3 of Proposition 8.5. 
Proposition 8.6 If IID is the probability measure determined by Ionescu-Tulcea’s 
theorem for the neutral forecasting strategy {Pt}tEfi:, 
then every measurable subset 
E in 0: 
has a game-theoretic probability in the corresponding generalized coin- 
tossing protocol, and this game-theoretic probability is equal to p( E). 
Here we cannot assert that the game-theoretic and measure-theoretic martingales 
are exactly the same. However, a measure-theoretic martingale can be always made 
into a game-theoretic martingale by changes on a set of measure zero. Proposition 8.6 
can be proven using this fact together with the ideas in Proposition 8.5-Ville’s 

182 
CHAPTER 8: THE GENERALlTY OF PROBABlLlJY GAMES 
theorem and the definition of game-theoretic upper probability in terms of game- 
theoretic martingales. 
The measure-theoretic framework starts with a probability distribution P in a?, 
and then the question is whether there exists a neutral forecasting strategy that gives 
rise to p. Standard results on the existence of regular conditional probabilities 
([287], Theorem 11.7.5) imply that the answer is “yes” provided 0, is a Bore1 space 
(in particular, if Q, = R). 
What advantage is there in the game-theoretic representation of models already 
understood within the measure-theoretic framework? The main advantage may be in 
interpretation. The explicit interpretation of conditional probabilities as forecasts may 
be less mysterious and more helpful in applications than the notion that X I ,  5 2 ,  . . . 
are generated by the probability measure P. The protocol discourages us from saying 
that 
generates X I ,  5 2 ,  . . .; they are obviously chosen by Reality. On the other hand, 
we can give a clear meaning to the statement that P governs x1,x2, 
. . .; this can be 
interpreted as an assertion of the fundamental interpretative hypothesis. Reality will 
avoid letting Skeptic become too rich, it says, and so will avoid any path X I ,  5 2 , .  . . 
on which any particular nonnegative martingale for p becomes too large. Forecaster 
does not force Reality’s hand, but he has somehow found and adopted forecasts that 
Reality respects-forecasts 
that guide or govern her choices without determining 
them. 
8.3 GAME-THEORETIC PRICE AND PROBABILITY 
In this section, we return to the abstract study of game-theoretic price and probability 
that we began in 3 1.2 and $ 1.3 and continued in $7.1. We organize this study by 
distinguishing three types of protocols for our sequential perfect-information game 
between Skeptic and World. They involve increasingly strong assumptions about 
Skeptic’s move space: 
0 Gambling Protocols. We call the protocol a gambling protocol if (I) Skeptic’s 
moves do not affect the moves later available to World, and (2) the moves by 
Skeptic and World in each situation determine an immediate monetary payoff 
for Skeptic. This is enough to permit us to define upper and lower prices. 
0 Probability Protocols. Here we add some minimal assumptions on Skeptic’s 
move space and gain function, corresponding to the assumption that he can 
combine tickets and can buy any positive fraction or multiple of a ticket. These 
are the assumptions we made in 5 1.2. They are enough to permit us to define 
useful concepts of upper and lower probability. 
0 Symmetric Probability Protocols. Here we assume further that Skeptic can 
buy negative as well as positive amounts of tickets, so that his move space and 
gain function are linear in the usual sense. This is the one of the assumptions 
we made in Chapter 7. 

8.3: GAME-THEORETIC PRICE AND PROBABILITY 
183 
In this section, in contrast, with 57.1, we do not assume that play terminates. Protocols 
of all three types may allow play to continue indefinitely. 
It is not our intention in this section to formulate a framework so general that it 
accommodates all the ways game theory might be used as a foundation for probability. 
Game theory is an extraordinarily flexible tool, and we expect that others will find 
yet other ways to relate it to probability. Even in this book, in Chapter 13, we use 
games more general than the ones considered here. 
Gambling Protocols 
We begin, as always, with the sample space R, which consists of all sequences of 
moves World is allowed to make. The space R may be any set of sequences with the 
property that no proper initial subsequence of a sequence in 52 is also in R. Some or 
all of the sequences in 0 may be infinite. 
We adopt most of the terminology and notation for sample spaces that we have 
used in preceding chapters. An element of R is a path. A finite initial segment of a 
path is a situation. We write 1(1 
for the length of the path (; 151 may be infinite. If 
2 n, we write tn for E’s initial segment of length n. The initial (empty) situation 
is denoted by 0, 
and the set of all situations is denoted by O0. World’s move space 
in situation t is denoted by Wt: 
W f  
:= {w 1 t w  E no>, 
where t w  is the sequence obtained by placing the single move w after the sequence 
of moves t. We define precede, follow, strictly precede, strictly follow, child, parent, 
process, t-process, event, variable, and t-variable as in 57.1. 
If the situation t is an initial segment of the path [, then [ goes through t, and t is 
on (. Given a real-valued t-process U ,  we define a t-variable lim inf 24 by 
lirn infn+m U([“) if [ is infinite 
if u is the final situation on 
lim inf U ( ( )  := 
for all ( that go through t. In words: lirn inf is defined in the usual way if the path is 
infinite but is equal to the value in the final situation if the path is finite. We define 
lim sup and lirn similarly. 
A set U of situations is a cut of a situation t if (1) all the situations in U follow t 
and (2) there is exactly one situation from U on each path through t, as in Figure 8.1. 
For each nonfinal situation t, we specify Skeptic’s move space in t, a nonempty 
set St, and Skeptic’s gain,function in t, a real-valued function At on St x Wt. As 
usual, &(s, w) is the gain for Skeptic when he moves s and World then moves w; 
notice that because of the subindex t Skeptic’s gain may depend not only on World’s 
current move but also on his previous moves. For the moment, we make no further 
assumptions about St and At. 
As usual, a strategy is a strategy for Skeptic-a 
partial process P defined on all 
nonfinal situations and satisfying P ( t )  E St. When Skeptic starts with capital 0 and 

184 
CHAPTER 8: THE GENERALITY OF PROBABILITY GAMES 
'ollows P ,  his capital process is K p ,  where K p  (0) = 0 and 
KP(tw) = K P ( t )  + At(P(t), w). 
(8.23) 
When he starts with capital a and follows P, 
his capital process is a + K P .  A process 
7'- is a supermartingale if there is a strategy P such that 
7(tw) L T(t) + At(P(t),w) 
(8.24) 
for every nonterminal situation t and every w E Wt. Skeptic's capital will follow 
7 if he starts with 7(0), 
follows P, but gives away 7 ( t )  + &(P(t),w) - 7 ( t w )  
upon arrival in tw. Thus the supermartingales are the processes that Skeptic's capital 
can follow if he is allowed to give money away. As in 57.1, we also consider t- 
strategies, which begin in the situation t. They give rise to t-capital processes and 
t-supermartingales. 
Given a variable 5 and a situation t, we define the 
upper price of x in t by 
0 
0 
0 
t ,  
0 
Fig, 8.1 The situations 
marked with dots form a cut 
oft. 
- 
IEi x := inf{S(t) I S is a t-capital process, 
and lim inf S 2 x} 
(8.25) 
(relations such as A 2 B are understood as satisfied for all 
[in the domain of both A and B; therefore, lim inf S 2 x 
means that lim inf S([) 2 .(I) for all 
passing through 
2). This is equivalent to the definition we stated verbally 
at the end of 51.2: Ez is the infimum of all Q such 
that there is a capital process starting at a that eventually 
reaches 
and does not go back below it. Similarly, we 
define the lower price of x in t by 
lE, z := sup{ -S(t) 1 S is a t-capital process, and lim inf S 2 -x}. 
(8.26) 
When the protocol is terminating, Equations (8.25) and (8.26) reduce to the definitions 
for terminating protocols given in 1.2 and repeated in 57.1. They imply, of course, 
that 
lE, z = -IEt[-X] 
(8.27) 
for every situation t and every t-variable x. As usual, we write Et z for the common 
value of & x and IE, x when they are equal; this is the price of z in t. 
Suppose x is a t-variable and U is a cut of t. Then we can define a t-variable Eu z 
- 
by 
(ELI .)(I) := E, 2 ,  
where u is the unique situation on 
Proposition 8.7 Suppose z is a t-variable and U is a cut oft. Then 
in U .  
(8.28) 

8.3: GAME-THEORETIC PRICE AND PROBABILITY 
185 
(8.29) 
Proof Choose E > 0, and choose a t-strategy P that produces at least EU z when it starts in 
t with &[Eu z] + E .  And for each u E U ,  choose a u-strategy P, that produces at least z 
when it starts in u with E, z + E .  Combining these strategies In the obvious way (starting in t, 
play P and then after you go through a situation u in U ,  play P,), 
we obtain a t-strategy that 
produces at least x when started with 
z] + 2t. So Et z 5 Et[Eu z] + 2 ~ .  
This shows 
that Et x 5 Et [&I 
z]. 
Now choose a t-strategy P that produces at least z when it starts in t with Et z + E .  For 
each u in U ,  this strategy produces at least z when it starts in u with capital K p ( u ) .  So 
(8.30) 
for each u in U. Let us write K g  for the t-variable whose value for ( is K p ( u )  when E goes 
through u E U .  Then (8.30) says that &J z 5 KE, and it follows that Et[& z] 5 Et KE. 
On the other hand, we have a strategy (play P until U and then stop) that produces KE starting 
in t with Et z + E .  So Et KE 5 & z + E .  So Et[& z] 5 Et z + E .  This shows that 
I 
In probability theory, the equation 
z = &[Eu x] is sometimes called the law of 
iterated expectation. Its appearance at this stage of our study, where we have made 
only the minimal assumptions needed to define upper and lower price, shows how 
purely game-theoretic it is. 
Et[EU z] 5 Et 2 .  
Equation (8.29) follows from (8.28) by (8.27). 
Probability Protocols 
We call a gambling protocol a probability protocol when it satisfies the following 
assumptions: 
1. Each St is a convex cone in a linear space. In other words, if s1 and s2 are in 
St and a1 and a2 are nonnegative numbers, then alsl + a2s2 is in S t .  
2. Each Xt has the following linearity property: if s1 and s2 are in St and al 
and a2 are nonnegative numbers, then Xt(als1 + ~ 2 . 5 2 ,  w) = alXt(s1, w) + 
a2 At (s2, w) for every w E Wt . 
These two assumptions were stated informally in 51.2 and adopted in all the games 
we have studied so far: Skeptic can combine freely all the tickets offered to him, and 
he can buy any positive fraction or multiple of a ticket. He is also always free to 
choose the move 0, so that his capital does not change. 
In a probability protocol, the capital processes form a convex cone in the space of 
all processes. The supermartingales do as well. 
The following proposition lists some properties of upper price in a probability 
protocol. 
Proposition 8.8 Suppose t is a nonfinal situation. Then the upper prices have the 
following properties: 

186 
CHAPTER 8: THE GENERALITY OF PROBABILITY GAMES 
1. Ifx is a t-variable, then Et x 5 sup{x(() I 
2. If.1 
and x2 are t-variables, then Et[x~ + 521 5 Et 51 + Et ZZ. 
3. Zfx is a t-variable and cy > 0, then &[ax] = Q & x. 
4. Zfx is a t-variable and Q E B then &[x + a] = E, x + a. 
5. If.1 
and x2 are t-variables, and 51 5 x2, then Et x1 5 Et x2. 
E 0, ( goes through t}. 
These properties follow directly from the definition of upper price and our assump- 
tions about St and At. We leave it to the reader to verify these properties and to 
formulate the corresponding properties for lower price. 
The first three properties in Proposition 8.8 were taken as the defining properties 
of upper probability by Peter Walley (1991, p. 65); see also Peter M. Williams (1976). 
Walley and Williams were inspired by Bruno de Finetti, who had emphasized similar 
properties for probability (see p. 188). These authors also considered the relation 
between unconditional and conditional prices, but they were not working in a dynamic 
framework and so did not formulate Proposition 8.7. 
As in 57.1, we call a probability protocol coherent in t if World has a t-strategy 
that guarantees that Skeptic ends the game with no cumulative gain from t onward. 
We call it simply coherent if it is coherent in every situation t. Coherence in t implies 
that for every s E St, World has a move w E Wt such that &(s, w) 5 0. Coherence 
is equivalent to the requirement that for every situation t and every s E S t ,  World 
has a move w E Wt such that &(s, w) 5 0. 
Proposition 8.9 Suppose t is a nonfinal situation in a coherent probability protocol. 
1. Zfx is a t-variable, then IE, x 5 E, x. 
2. Ifa is a real number and a designates the variable that is equal to a on every 
path, then Et a = a. 
When the protocol is coherent, we can also strengthen Property 3 in Proposition 8.8 
by relaxing a > 0 to LY 2 0. 
We define upper and lower probabilities for an event E in a situation t as usual: 
Pt E := Et NE and & E := IEl 
IIE, where IIE is the indicator variable for E. 
Proposition 8.10 Suppose t is a non3fnal situation in a coherentprobabilityprotocol. 
Then 
- 
1. F, E = 1 -I& 
EC, 
2. Ft[E1 U Ez] 5 Ft El + Ft E2, 
alzd 
3. &[El n E2] 2 gt El + & E2 - 1. 
When the fundamental interpretative hypothesis is adopted, so that an upper proba- 
bility close to zero means that an event is very unlikely and a lower probability close 

8.3: GAME-THEORETIC PRICE AND PROBABILITY 
187 
to one means that it is very likely, Statements 2 and 3 of this proposition acquire 
substantive interpretations. Statement 2 says that the union of two very unlikely 
events is very unlikely, and Statement 3 says that the intersection of two very likely 
events is very likely. 
Proposition 8.11 Suppose t is a nonfnal situation in a coherentprobability protocol. 
Then 
- 
Pt E = inf {S(t) 
I S is a nonnegative t-capital process, 
and lim inf S 2 1 on E}. 
(8.31) 
Proof The condition that lim inf S([) 2 0 for all <, together with coherence, implies that 
S is nonnegative, for if S ( t )  < 0, then coherence implies that there is a path going through t 
I 
along which S remains negative. So (8.31) follows directly from (8.25). 
Another way of expressing (8.3 1) is to say that 
E is the infimum of all nonnegative 
numbers a such that Skeptic has a strategy that starts with capital 1 and reaches l / a  
on E without risking bankruptcy. 
Recall the definition of forcing in Chapter 3 (p. 65): a strategyforces E if it 
has a nonnegative capital process S satisfying limn+co S(c”) = co for all c in the 
complement EC. 
When Skeptic has a strategy that forces E, we say that Skeptic 
can force E, and that E happens almost surely. Comparing the definition of forcing 
with (8.3 l), we obtain the following proposition: 
Proposition 8.12 lfskeptic can force E, then 
Intuitively, the converse should also be true. If there are strategies that do not risk 
bankruptcy and multiply one’s capital by an arbitrarily large factor when E does 
not happen, we should be able to obtain a strategy that makes the multiplication 
infinite by forming an infinite convex combination, as in Lemma 3.1 (p. 68). In the 
present abstract context, however, some regularity conditions would be needed in 
order to assure the existence of the convex combination. We will not investigate such 
conditions here. (But see the discussion in connection with Proposition 4.5 on p. 93.) 
EC = 0. 
Symmetric Probability Protocols 
We call a probability protocol symmetric if whenever s E St, we also have -s E St 
and X~(-S, w) = -Xt(s, w) for all w E Wt. When we describe the moves available 
to Skeptic in terms of tickets that are offered to him, this means that Skeptic can buy 
negative as well as positive amounts of any ticket-he 
can sell at the same price at 
which he can buy. 
Given the assumptions already satisfied by St and At in a probability space (p. 1 89, 
symmetry means that St is a linear space and Xt(s, w) is linear in s. It follows that 
the strategies and capital processes available to Skeptic also form linear spaces. In 
particular, if P is a strategy for Skeptic, then -P is also a strategy for Skeptic, and 
K-” = -Kp. 
(8.32) 
by (8 2 3  1, 

788 
CHAPTER 8: THE GENERALlTY OF PROBABILITY GAMES 
In a symmetric probability protocol, we call a capital process (no matter whether it 
starts with 0 or some other initial capital-positive 
or negative) a martingale. 
In an asymmetric probability protocol, Skeptic may have moves that amount 
to throwing money away. There may, for example, be a move s E St such that 
&(s, w) = -1 for all w E Wt: if Skeptic moves s, he loses 1 no matter how World 
moves. This cannot happen in a coherent symmetric probability protocol. If there 
were a move by Skeptic that necessarily loses money, then there would be one that 
necessarily makes money, contrary to coherence. 
In a symmetric probability protocol, we can use (8.32) to rewrite (8.26) as 
IE, 2 = sup{S(t) I S is a t-capital process, and limsupS 5 x}. 
(8.33) 
This makes lower price analogous to upper price in a new way. Equation (8.25) says 
that the upper price of 2 is the smallest initial capital that will enable Skeptic to make 
at least as much as z; Equation (8.33) says that the lower price of 2 is the greatest 
initial capital with which Skeptic can manage to make no more than 2. 
As we have already seen in the preceding chapters, the probability protocols asso- 
ciated most closely with measure-theoretic probability are symmetric. For example, 
our formulation of Lindeberg’s theorem in Chapter 7 assumed symmetry. The prob- 
ability protocols considered in finance theory are also symmetric; investors can buy 
at the same prices at which they can sell. Only occasionally do finance theorists 
relax this condition in order to study the effect of a market’s bid-ask spread (see, 
e.g., [162]). But from our point of view, symmetry is not a crucial condition for a 
probability game. There are many interesting asymmetric probability games, and the 
most important general properties of upper and lower price hold for asymmetric as 
well as symmetric protocols. 
Adding Tickets 
If we abstract away from the details of Skeptic’s move spaces and gain functions in a 
probability protocol and consider only the set of capital processes, then it is natural 
to consider how the upper and lower prices and probabilities change as this set is 
changed. If the probability protocol is coherent, then enlarging the set of capital 
processes corresponds to making more tickets available to Skeptic, at least in some 
situations, and it is obvious that this can only increase the lower prices and decrease 
the upper prices. It is natural to ask whether a sufficient enlargement will bring the 
lower and upper prices together, producing exact prices for all variables and exact 
probabilities for all events. 
If the coherent probability protocol is symmetric and terminating, then the answer 
is yes. In the enlargement, the exact prices in each situation will satisfy de Finetti’s 
rules for probability ([93], English edition, Vol. 1, p. 74): 
1. If z is a t-variable, then 
inf{z([) I E goes through t} 5 & z _< sup{z([) I E goes through t}. 
2. If z1 and 2 2  are t-variables, then IEt(z1 + 2 2 )  = IEt z1 4- Et 2 2 .  

8.4: OPEN SCIENTIFIC PROTOCOLS 
189 
3. If z 
is a t-variable and a E R, then &(ax) = a IEt z. 
And the upper and lower prices in the protocol will be the suprema and infima of the 
exact prices obtained by different enlargements ([336], Chapter 3). Similar results 
may be possible for nonterminating symmetric probability protocols. Readers who 
see exact probabilities as fundamental may be interested in pursuing this line of 
thought further, because it provides a way of understanding upper and lower prices 
in terms of exact prices. 
8.4 OPEN SCIENTIFIC PROTOCOLS 
In this section, we further illustrate the generality of probability games by explaining 
how they accommodate two widely used scientific models that use probabilities 
but fall outside the measure-theoretic framework: quantum mechanics and Cox’s 
regression model. Both models go beyond the measure-theoretic framework because 
they are open in the sense we explained in 51.1: their forecasts are influenced by 
events in the world that lie outside the model. 
Quantum Mechanics 
Quantum mechanics is nearly as old as measure-theoretic probability, and probabilists 
and statisticians have extended the measure-theoretic framework to accommodate it 
in many different ways [213, 2311. Here we do not try to survey or evaluate this 
work; we merely sketch how one version of von Neumann’s axioms for quantum 
mechanics fits into the game-theoretic framework. 
This version of von Neumann’s axioms is adapted from Jammer 1974, Chapter 1 
(see also Chapter I11 of von Neumann 1955). 
Axiom 8.1 To every physical system corresponds a separable complex Hilbert space 
U whose unit vectors completely describe the state of the system. 
Axiom 8.2 To every observable (such as position, momentum, energy, or angular 
momentum) corresponds a unique self-adjoint operator A acting in X. 
Let us call an observable A simple if there exist a complete orthonormal system of 
states 
$ 2 ,  . . , (eigenfunctions) and a sequence a1 , a2, . . . of distinct real numbers 
(the corresponding eigenvalues) such that Aq5 = ci 
uiAi$i for each state 4, where 
the Xi are the coefficients in the expansion 4 = ci 
A&i. 
We consider only simple 
observables. 
Axiom 8.3 Let A be an observable with eigenfunctions $1, + 2 ,  . . . and correspond- 
ing eigenvalues a1, a;?, . . . . For a system in a state q5 = ci 
Xi+i, the probability 
that the result of a measurement of the observable A is ai equals \ X i  1’ (and so results 
other than a1, a2, . . . are impossible). 

190 
CHAPTER 8: THE GENERALlTY OF PROBABILITY GAMES 
Axiom 8.4 The time development of the state 4 is determined by the Schrodinger 
equation 
where H is an observable culled the Hamiltonian of the system. 
Axiom 8.5 Let A be an observable with eigenfunctions $ 1 ,  $2, . . . and correspond- 
ing eigenvalues a1 , C Y ~ ,  
. . . . If a measurement of A gives a,, then the state of the 
system immediately after the measurement is &. 
Axiom 8.5 is a condition on the observer’s measuring instruments. In Pauli’s ter- 
minology, the measuring instruments are required to be “ideal and of the first kind” 
([12], $8.1). For simplicity we only consider a single physical system (otherwise an 
extra axiom, such as Postulate IV in 1321, should be added). 
Writing P(N) for the set of all probability measures on the natural numbers N, 
we write the protocol for our game as follows: 
GAME OF Q U A N T U M  h/IECHANICS 
Parameters: KO > 0 (Skeptic’s initial capital), t o  (initial time) 
Players: Observer, Quantum Mechanics, Skeptic, Reality 
Protocol: 
FOR n = 1 , 2 , .  . .: 
Observer announces an observable A, and a time t, > t,-l. 
Quantum Mechanics announces a, : N + R andp, E P(N). 
Skeptic announces a function f, : N + R such that 
At time t,, Reality announces the measurement an(&). 
Kn := Kn-1 + f n ( i n )  - J fn&n. 
f,dp, 
exists. 
(8.34) 
In words, the protocol is: 
Observer decides what he is going to measure (Al) and when he is going to 
measure it (tl). 
Quantum Mechanics decides on the possible results a1 (z), i = 1,2,. . ., of the 
measurement, together with their probabilities p l  (i). 
Skeptic bets on what integer i Reality will choose, at odds given by the proba- 
bilities p1 (i). 
At time tl, Reality chooses the measurement result a1 ( i l )  (which is equivalent 
to choosing the index in, since our observables are simple). Her choice is 
governed by the probabilities pl ( i )  only in the sense that she is expected to 
avoid allowing Skeptic to become rich by betting at the corresponding odds. 
Skeptic’s capital is updated from KO to K 1  according to his bets f,; (8.34) 
means that Skeptic buys fn for 
Everything is repeated: Observer decides what (Aa) and when ( t z )  he is going 
to measure, etc. 
firdpn, Quantum Mechanics’s price for f .  

8.4: OPEN SCIENTIFIC PROTOCOLS 
191 
Quantum Mechanics follows a fixed strat- 
egy in this game. This strategy uses an auxil- 
iary variable 4, E 3-1, the state of the system; 
an initial state $0 E 3-1 (a vector in 3t of 
unit length) is given at the outset. Quantum 
Mechanics calculates her move (a,, p,) as 
follows: 
0 Let An’s eigenvalues and eigenfunc- 
tions be u,,i and $,,i 
(i = 1,2,. . .), 
respectively. 
0 Quantum Mechanics solves 
= 
& H 4  with the initial condition 
4(tn-1) = 
and sets 4; 
:= 
$(in) (this is the state of the system 
immediately before measuring An). 
John von Neumann (1903-1957). Born 
in Budapest under the Austro-Hungarian 
empire, he became the most trusted ad- 
viser of the United States military during 
the early years of the cold war. This pho- 
tograph appears to have been taken in the 
1930s. 
o Quantum Mechanics 
4; as a 
h e a r  combination Of An’s eigenfunc- 
tions: 4; = Ci 
X,,i$,,i. 
functionu, : i ++ un,i and the probability measurep, : i ++ IXn,iI2. 
0 Quantum Mechanics announces the 
0 Once Reality chooses in, the new state of the system, $,, 
becomes Gn,in. 
Skeptic’s goal is to falsify Quantum Mechanics or to make some point (such as 
(8.35)); he succeeds in falsifying Quantum Mechanics if K, is never negative and 
tends to infinity. As usual, we say that Skeptic can force an event E (such as (8.35)) 
if he has a strategy that falsifies Quantum Mechanics outside E. 
Our limit theorems can be applied to this game in many different ways. As an 
example, we give a corollary of the strong law of large numbers for the bounded 
forecasting game. 
Corollary 8.5 Suppose Observer repeatedly measures observables bounded by some 
constant C. Skeptic can force the event 
(8.35) 
Cox’s Regression Model 
To illustrate how open statistical models can fit into the game-theoretic framework, 
we look at failure models in general and Cox’s regression model in particular. This 
model was introduced by David R. Cox (1972); see also 1631 and [65], Chapter 7. 
We start with a general protocol for testing a failure model; Cox’s regression 
model will be a particular strategy for one of the players, Model. 

192 
CHAPTER 8: THE GENERALITY OFPROBABILITY GAMES 
TESTING A FAILURE 
MODEL 
Parameters: KO > 0 (Skeptic’s initial capital), K E N (number of covariates) 
Players: Reality, Skeptic, Model 
Protocol: 
FOR n = 1,2,. . .: 
Reality announces group B, and 2; E RK (covariates) for every i E B,. 
Model announces p ,  E P( 
B,). 
Skeptic announces a function f, : B, -i 
R. 
Reality announces b, E B,. 
K, := G-1 + f,(b,) 
- J,, 
fndpn. 
Reality stops when she pleases. 
The group B can be any finite non-empty set; we write P(B) 
for the set of all 
probability measures on B. This protocol describes the process of observation 
of a group of individuals, from which members may be deleted (say, by failure or 
censoring) or even added. Typically there is some continuity in the composition of the 
group, but this is not assumed. Every individual in the group is characterized by a set 
of K covariates, such as blood pressure, sex, etc., which may be useful in estimating 
the individual’s chances of failure. At the moment when the nth failure occurs, the 
experimenters record the composition of the group just prior to failure (B,) and 
the covariates for each individual i who was then in the group (zk), including the 
covariates for the individual who failed. With this information (but without knowing 
which individual failed), Model provides a probability distribution p ,  for b,, 
and 
Skeptic, who has the same information, is allowed to buy any payoff f, for the price 
s fndpn. Then the identity of the individual who failed, b,, is announced. We ignore 
the possibility that two individuals might fail simultaneously. 
Cox’s regression model is the following 
strategy for Model: for some constant vector 
8 E RK (unknown in advance), 
In [63] Cox defined the partial log-likelihood 
for a data sequence 
( B l , Z l ,  bl), . . . 1 (BN, Z N ,  b N ) ,  
where N is the duration of the game (we 
assume that Reality eventually stops), as the 
function L of 8 defined by 
Because we assume no stochastic mechanism, the adjective “partial” is not helpful. 
So we call L simply the log-likelihood. 

8.4: OPEN SCIENTIFIC PROTOCOLS 
193 
Let us assume, for simplicity, that K = 1. First we give a simple test of the 
null hypothesis 8 = 0 (the individuals fail at random) against the alternative 8 > 0, 
assuming that B1 (the initial group) and N (the duration of the game) are known 
in advance, that B,+1 = B, \ {b,} for all n (individuals are only removed when 
they fail, and none are added), and that the zf do not depend on n and are known in 
advance (2: = zi). In this case, N 5 IB1 I. This test is a game-theoretic formulation 
of the test given in Cox and Oakes [65], 57.4. 
For any sequence i l  , . . . ZN of different elements of B1, set 
where R, := B1 \ {ill.. . , & - I } .  
The intuition behind T(i1,. . . i
~
)
 
is that if 
i l ,  . . . , i~ were the individuals who failed in the order of failing ( ( b l ,  . . . b
~
)
 
= 
(il . . . i ~ ) ) ,  
then T(i1 . . . i
~
)
 
would measure how much the covariate for the 
failed individuals exceeded the average covariate for the individuals who were at 
risk at the moment of each failure. Under the null hypothesis 8 = 0, we expect T 
to be neither excessively large nor excessively small, whereas under the alternative 
8 > 0 we expect T to be large (individuals with large z will tend to fail). Under 
our simplifying assumptions, the failure model protocol is essentially a special case 
of the probability forecasting protocol on p. 181, and so, by Proposition 8.6, we 
obtain probabilities for T that are both game-theoretic and measure-theoretic: For 
any threshold u E R , 
where (ill.. . , i
~
)
 
ranges over all sequences of length N of distinct elements of 
B1. We can use this probability distribution for T to test the hypothesis 8 = 0. We 
might choose some conventional significance level LY (such as l%), define u, as the 
smallest u for which 
{T(bl . . . , b
~
)
 
> u} 5 a, and reject the hypothesis (at level 
a) if T(b1,. . . , b
~
)
 
> u, for the observed Reality's moves. Alternatively, p-values 
can be calculated, exactly as in the standard measure-theoretic statistics (see, e.g., 
We can also apply the law of the iterated logarithm for the bounded forecasting 
~ 4 1 ) .  
game (see (5.8) on p. 104): 
Corollary 8.6 Suppose K = 1, Reality always chooses nonempty groups B, and 
covariates zh bounded by some constant C in absolute value, she never stops, and 
Model follows Cox's strategy with 8 = 0. Then 
TN 
lim sup 
N+CC d 2 C 2 N l n l n N '  
where (cf (8.36)) 
11 
2) 

194 
CHAPTER 8: THE GENERALITY OF PROBABILITY GAMES 
Other limit theorems studied in this book can also be applied to COX’S model, but 
these do not answer the asymptotic questions about the model that are most interesting 
to statisticians. These questions have been widely explored within the measure- 
theoretic framework and also deserve exploration in the game-theoretic framework. 
For example (assuming K = 1): 
0 Let U ( 0 )  (the efficient score) be the derivative of the log-likelihood L(0) and 
-T(0) be the second derivative of L(0) (for very intuitive explicit expres- 
sions, see [62], p. 191). One can test the null hypothesis 0 = 00 if U ( & )  is 
asymptotically Gaussian with zero mean and variance T(Oo)-more 
precisely, 
if the random variable X := U(&)/JT(Oo) is close to standard Gaussian for 
large N .  (In particular, this provides another way of testing 0 = 0, cf. [62], 
52.) An open problem is to prove some variant of this in the game-theoretic 
framework. One might, for instance, prove that if Model plays Cox’s strategy 
with 0 = 00 and the path is required to satisfy some natural conditions, then 
the upper probability of the event X 2 C is close to SF n/~,l. 
0 It is often assumed that Y := (6 - O0)JT(6), where 6 := argmaxe L(0) is 
the maximum likelihood estimate, is approximately standard Gaussian under 
0 = 00 (cf. (1 1) in [63]); this assumption can be used for finding confidence 
limits for 0. Again an open problem is to prove some version of this in the 
game-theoretic framework. 
8.5 APPENDIX: VILLE’S THEOREM 
Ville’s theorem interprets probabilities in an arbitrary filtered probability space in 
terms of measure-theoretic martingales. Although quite elementary, the theorem is 
not usually discussed in expositions of the measure-theoretic framework, because 
it has no particular role to play there. The whole point of the measure-theoretic 
framework is to make probability measures, which give probabilities directly, one’s 
starting point, and so there is no reason to dwell on the point that martingales could 
be taken as the starting point instead. The theorem is clearly important, however, for 
understanding the relationship of the measure-theoretic framework with the game- 
theoretic framework, where capital processes (martingales in the symmetric case) are 
the starting point. 
Although we speak of it as one theorem, Ville’s theorem consists of two claims, 
one for positive probabilities and one for zero probabilities. We stated the two claims 
roughly and informally in Chapter 2 (p. 52): 
0 The probability of an event is the smallest possible initial value for a non- 
negative measure-theoretic martingale that reaches or exceeds one If the event 
happens. 
An event has probability zero if and only if there is a nonnegative martingale 
that diverges to infinity if the event happens. 

8.5: APPENDIX: VILLE'S THEOREM 
195 
They are made precise by Propositions 8.13 and 8.14, respectively. 
Lemma 8.1 Suppose (Q, F, 
{Fn}F!o, P) is ajlteredprobabilily space, andsuppose 
E E Fm. 
I f P  E < E for some E > 0, then there is a nonnegative measure-theoretic 
martingale LO, C1, . . . such that 
EL0 < E & liminf Cn 2 1 on E. 
n'+m 
Proof The union of all Ft, 
i = 0,1,. . ., is an algebra (i.e., is closed under the usual Boolean 
operations). The distribution p can be extended from this algebra to the a-algebra Fm 
uniquely by CarathCodory's construction (see, e.g., [25]). This construction shows that there 
is a sequence Eo E Fo, 
El E F1,. 
. . of disjoint events such that E 
U,E, and c, P E, < E. 
For i = 1 , 2 , .  . ., define a measure-theoretic martingale Ci, CI,, . . . by taking .Lk to be IE, 
if n 2 i and to be an arbitrary version of E[IE, IFn] otherwise. (Since IE, is a version of 
EIIE, IFn] 
when n 2 i, this means that .Lq is always a version of E[IIE, IFn].) Finally, set 
i=l 
This sequence of nonnegative extended (meaning that they can, a priori, take infinite values) 
random variables satisfies 
it is easy to see that, since all C i  are nonnegative measure-theoretic martingales, .Ln is an 
almost surely finite nonnegative measure-theoretic martingale. Every w E E belongs to some 
Ei and therefore satisfies 
I 
lim inf L, (w) 2 Iim inf Ck ( w )  = IE, (w) = 1. 
n 
n 
Proposition 8.13 Suppose (0, F, 
{Fn}r=o, p) is a Jiltered probability space, and 
suppose E E .Fa. 
Then 
P E  = inf EL0 liminf L, 2 IIE 
= inf EL0 supLn 2 IIE 
, 
(8.37) 
{ 
I n+m 
1 
{ 
I n  
I 
where C ranges over measure-theoretic martingales. 
Proof It is clear that 
so it suffices to prove 
and 
(8.38) 
(8.39) 

196 
CHAPTER 8: THE GENERALlTY OF PROBABILITY GAMES 
But (8.38) follows from Doob's inequality ([287], Theorem VII.3.1), and (8.39) follows from 
Lemma 8.1. 
I 
We are most interested in Proposition 8.13 in the case where FO = {a, 0). In this 
case, Co is a constant for every measure-theoretic martingale C, and so we can write 
Informally, this says that p E is the smallest possible initial value for a measure- 
theoretic martingale that eventually equals or exceeds 1 if E happens and zero 
otherwise. By (8. l), if a measure-theoretic martingale is eventually nonnegative 
no matter what happens it can be made always nonnegative by changes on a set of 
measure zero, and so this can also be put in the form we gave earlier: pE is the 
smallest possible initial value for a nonnegative measure-theoretic martingale that 
eventually equals or exceeds 1 if E happens. 
Proposition 8.13 applies in particular to the case where the probability is zero; it 
tells us that p E = 0 if and only if there is a nonnegative measure-theoretic martingale 
that multiplies its initial value by an arbitrarily large factor if E happens. Using a 
limiting argument, we could further conclude that 
E = 0 if and only if there is a 
nonnegative measure-theoretic martingale that becomes infinite if E happens. It is 
simpler, however, to prove this directly, as follows. 
Proposition 8.14 Suppose (Q, F, 
{Fn}r=o, 
p) is a filtered probabilitjl space, and 
suppose E E F. 
1. lfa nonnegative martingale diverges to in.nity when E happens, then P E = 0. 
2. If E E Fm and p E = 0, then then there is a nonnegative measure- theoretic 
martingale that diverges to infinity if E happens. 
Proof To prove Statement 1, consider a nonnegative measure-theoretic martingale L, , 
n = 0,1,. . . . For any positive integer j ,  en 
is also a nonnegative measure-theoretic 
martingale and satisfies, by Doob's inequality, 
Since the union of {LO 5 j }  over all positive integers j is the certain event, it follows that 
To prove Statement 2, notice that for each positive integer k there exists, by Lemma 8.1, 
a nonnegative measure-theoretic martingale L;, C:, . . . such that E(L$) < 2 - k  and 
lirrl inf, ,Ck 2 1 on E. The sequence LO, C1, . . . defined by 
p {sup, c, = m} = 0. 
03 
c, := c 
c,", 
k=1 

8.6: APPENDIX: A BRIEF BIOGRAPHY OF JEAN VlLLE 
197 
since it satisfies E Lo < 1, is finite almost surely and hence defines a nonnegative measure- 
I 
theoretic martingale that is divergent on E. 
We used Statement 1 in the derivation of the measure-theoretic strong laws in 
s8.1; as we noted there, it follows immediately from Doob’s convergence theorem. 
Statement 2 is trivially true if we assume that FO already includes all of P’S null 
sets, because then we can simply set C, := n l ~ ,  
where 1~ is the indicator of E 
[262]. This is one reason Ville’s theorem does not get much attention in standard 
measure-theoretic expositions. But our proof establishes that the statement holds no 
matter how we choose Fo-it 
is true, for example, when Fo = {R,0}. If .F = .Fm, 
then the two statements together reduce to our informal statement: an event E has 
probability zero if and only if there is a measure-theoretic martingale that tends to 
infinity whenever E happens. 
8.6 APPENDIX: A BRIEF BIOGRAPHY OF JEAN VILLE 
Because Jean Ville’s work is so important to 
our framework, we provide here some details 
about the sources of his ideas and his subse- 
quent career. Most of this information has been 
provided by Pierre CrCpel of the University of 
Lyons, who interviewed Ville in 1984 [69]. 
In France in the 1930s, as Ville told CrCpel 
in 1984, probability was an honorable pas- 
time for those who had already distinguished 
themselves in pure mathematics. It was not 
an appropriate subject for an aspiring mathe- 
matician’s dissertation. Ville was a promising 
young mathematician, and Maurice Frtchet, 
his adviser, had put him to work on a problem 
in Hilbert spaces. But Ville was intrigued by 
the foundations of probability, and after mak- 
ing no progress on his assigned topic, he went 
to Berlin for the academic year 1933-1934, in 
the hope of learning more about von Mises’s 
ideas, which FrCchet had found interesting but 
flawed. He found no one interested in the 
Jean Ville (1910-1988) 
topic in Berlin; Hitler was dictator, and von Mises had fled. The following year, Ville 
went to Vienna on an Asconti-Visconti fellowship, and there he found a much more 
stimulating environment, especially in Karl Menger’s seminar, where there was keen 
interest in the foundations of mathematics and economics. There, during 1934-1935, 
he met Constantin CarathCodory, Abraham Wald, and Kurt Godel, and he made his 
discoveries about collectives and martingales. In 1936, after he returned to Paris, he 
published two reports on the work in the Comptes rendus [307, 3081. 

198 
CHAPTER 8: THE GENERALITY OF PROBABILITY GAMES 
What led Ville to his insights about martingales? In 1984, he recalled knowing 
in his youth a relative of the woman who later became his wife, one M. Parcot, who 
apparently made a modest living gambling on lotteries and roulette after making 
laborious secret calculations. Ville had suspected that Parcot’s secret was related to 
Laplace’s idea for taking advantage of the bias in a coin without knowing whether 
heads or tails is favored [ 1901, and it was this old idea that led him to consider how 
to make money if one knew that the frequency of heads converged to one-half from 
above or below, without knowing which. 
After writing up his work on collectives as a dissertation, Ville turned, as Emile 
Borel’s research assistant, to other topics. His most striking success was a new proof 
of John von Neumann’s minimax theorem for games; he showed that von Neumann’s 
appeal to a fixed-point theorem could be replaced with a simpler argument relying on 
convexity [305, 1941. Together with Wolfgang Doeblin, a brilliant young colleague 
who had come with his family from Germany to Paris to escape the Nazis, he 
organized a seminar on probability theory, which was soon taken over by Borel. 
Frtchet had reluctantly agreed that the work on collectives could be Ville’s dis- 
sertation, and he presented Ville’s results in detail in his address in Geneva in 1937 
(or at least in the published version, [ 130]), as part of his argument for Kolmogorov’s 
framework and against von Mises’s collectives. But still hoping that Ville would do 
some real mathematics (game theory also did not count), he continually delayed the 
defense of the dissertation. In desperation, Ville took a job in a lycte in Nantes in 
1938. The defense was finally held, after Borel’s intervention, in March of 1939. 
Ville’s book, Etude critique de la notion de collectif, appeared in Borel’s series of 
monographs on probability soon after the defense. Except for an added introductory 
chapter, it is identical with the dissertation. The book received far less attention than 
it deserved, in part because of onslaught of the war. Aside from FrCchet, Borel, Ltvy, 
and Doeblin, there were few mathematicians in Paris interested in probability theory. 
Doeblin died as a soldier in 1940 (shooting himself when his unit was about to be 
captured by the Germans). LCvy paid no attention. According to Ville’s recollection 
in 1984, LCvy actually refused to read his dissertation because it was printed by an 
Italian press: “You had your thesis printed by the fascists.” “I didn’t have any money.” 
“I won’t read it.” Ltvy’s reluctance to read the work of other mathematicians was 
notorious, but like Doeblin, he had other things to worry about. He survived the 
German occupation of Paris only by hiding, with false papers, in the home of his 
non-Jewish son-in-law [270]. It was only ten years later, when Doob put the idea 
of a martingale in measure-theoretic form (see p. SS), that it attracted wide interest. 
Ville himself did not participate in this measure-theoretic development. He never 
met Doob or Feller. 
Ville’s subsequent work was distributed across information theory, operations 
research, statistics, computing, and economics. He worked at the University of 
Poitiers starting in 1941, then at the University of Lyons starting in 1943. Passed 
over for a professorship at Lyons in 1947, he held several academic and industrial 
jobs, finally becoming professor of econometrics at the University of Paris in 1958. 

Part 11 
Finance without Probability 
As the branch of economics concerned with time and uncertainty, finance theory has 
always been infused with probability. It was a probabilist, Louis Bachelier, who 
first developed a mathematical model for stock-market prices. Bachelier’s work, 
which began with his dissertation in 1900, was not noticed by economists until the 
late 1950s, but theoretical work on finance within economics, which might be dated 
from the work on portfolio selection by Markowitz and Tobin in the early 1950s, has 
always been equally probabilistic. 
In this part of the book, we demonstrate that finance theory can profit from the 
purely game-theoretic understanding of probability developed in Part I. We concen- 
trate on two central topics: the pricing of options and the efficient market hypothesis. 
In both cases, as we show, a purely game-theoretic understanding, without stochastic 
assumptions, is both possible and illuminating. 
Since the 1970s, the theory and practice of the pricing of options and other 
derivatives has been dominated by the Black-Scholes equation, which is based on 
a game-theoretic argument. The price of a derivative based on a particular stock is 
supposed to be the initial capital needed to reproduce the payoff of the derivative by 
continuously shifting capital between the stock and a risk-free bond as their relative 
prices change in the market. But a stochastic assumption is used in the proof that 
this works. One assumes that the price of the stock follows a geometric Brownian 
motion, and one uses the estimated variance of this geometric Brownian motion in 
the Black-Scholes formula for the price of the derivative. The assumption that prices 
follow a geometric Brownian motion is empirically shaky, and our deconstruction of 
the idea of stochasticity in Part I can only serve to make it less persuasive. How can 
we do without it? 
We offer a substantive proposal that may be practical for stocks for which there is 
a large market in derivatives. Instead of using the estimated variance of the price of 
Probability and Finance: It’s Only a Game! Glenn Shafer, Vladimir Vovk 
Copyright 0 2001 John Wiley & Sons, Inc. 
ISBN: 0-471-40226-5 

200 
PART /I: FlNANCE WITHOUT PROBABlLlTY 
a stock to price all derivatives in the stock, we propose that one particular derivative, 
which pays at maturity some strictly convex function of the current stock price, be 
itself priced by supply and demand. The market price of this derivative can be used 
to determine the theoretical price of an imagined derivative that pays a continuous 
dividend equal to the squared relative change in the stock price, and this theoretical 
price can replace the estimated or predicted variance of the stock price in the Black- 
Scholes formula. Implementation of this proposal would require that traders shift into 
the new derivative from derivatives they now prefer, usually call and put options. Our 
theory suggests, however, that the costs of this shift may be repaid by a substantial 
increase in the stability and reliability of pricing. 
Our game-theoretic approach to option pricing is explained in rigorous detail in 
Chapters 10-13. Chapters 10 and 11 lay out the basic argument, in discrete time 
and continuous time, respectively. In addition to the Black-Scholes model, these two 
chapters also treat the Bachelier model, which assumes that prices follow an ordinary 
Brownian motion. Because it permits negative stock prices, the Bachelier model is of 
little use in practice, but because it is slightly simpler, it provides a good starting point 
for our exposition. Later chapters demonstrate the flexibility of our approach; we can 
handle interest rates and jumps (Chapter 12) and American options (Chapter 13). 
In Chapter 14, we show how diffusion processes can be handled within our 
continuous-time game-theoretic framework. In addition to making absolutely clear 
the strength of the assumption that prices follow a diffusion process, this may provide 
a starting point for a better understanding of other uses of diffusion processes. 
The idea of efficient markets, which we study in Chapter 15, provides another ex- 
ample of the clarity that can be gained by eliminating stochasticity in favor of a game- 
theoretic understanding of probability. The existing literature on efficient markets 
begins with the simple proposition that opportunities for substantial profit-making in 
large capital markets are quickly eliminated by competition. This conceptual sim- 
plicity disappears when, in order to test efficiency empirically, stochastic assumptions 
are introduced. Our game-theoretic viewpoint allows us to recover the simplicity, 
for it shows us that the stochasticity is unnecessary. All that is needed for statistical 
testing is a variant of the fundamental interpretive assumption of probability-we 
assume that an investor is highly unlikely to do substantially better than the market. 
Since this is essentially identical with the intuitive hypothesis of market efficiency, 
it is fair to say that our approach to testing market efficiency requires no addition of 
probability ideas at all. 
The next chapter, Chapter 9, provides a more detailed introduction to Part 11. 
Because we hope that the audience for this book will include probabilists and others 
who have not previously studied finance theory, the tone of this chapter is relatively 
elementary. For details about established theory, however, we often refer the reader to 
the excellent introductions already available in book form. For practical information 
on option pricing, we most often cite Hull (2000). For mathematical details on 
stochastic option pricing, we usually cite Karatzas and Shreve (1991). In addition, 
readers may wish to consult standard textbooks and more popular accounts such as 
Bernstein (1992) and Malkiel (1996). 

Game-Theoretic 
Probability in Finance 
In this introductory chapter, we sketch our game-theoretic approach to some basic 
topics of finance theory. We concentrate on how the Black-Scholes method for 
pricing and hedging a European option can be made purely game-theoretic, but begin 
with an examination of the apparently random behavior of stock-market prices, and 
we conclude with a discussion of informational efficiency. 
The usual derivation of the Black-Scholes formula for the price of an option relies 
on the assumption that the market price S(t) of the underlying security S follows 
a diffusion process. As we explain in the first two sections of this chapter, this 
stochastic assumption is used in two crucial ways: 
Taming the Market The diffusion model limits the wildness of fluctuations in S(t). 
This is the celebrated Jdt effect: the change in S(t) over an increment of time 
of positive length dt has the order of magnitude (dt)’/’. This is wild enough, 
because (dt)1/2 is much larger than dt when dt is small, but one can imagine 
much wilder fluctuations-say 
fluctuations of order ( ~ l t ) ’ / ~ .  
Averaging Market Changes The diffusion model authorizes the use of the law of 
large numbers on a relatively fine time scale. The model says that relative 
changes in S(t) over nonoverlapping time intervals are independent, no matter 
how small the intervals, and so by breaking a small interval of time [tl , t z ]  into 
many even smaller intervals, we can use the law of large numbers to replace 
certain effects by their theoretical mean values. 
Our purely game-theoretic approach does not need the diffusion model for either of 
these purposes. 
201 
9 
Probability and Finance: It’s Only a Game! Glenn Shafer, Vladimir Vovk 
Copyright 0 2001 John Wiley & Sons, Inc. 
ISBN: 0-471-40226-5 

202 
CHAPTER 9: GAME-THEORETIC PROBABILITY IN FINANCE 
A limit on the wildness of price changes can be expressed straightforwardly in 
our game-theoretic framework: as a constraint on the market, it can be listed among 
the rules of the game between Investor and Market. Market simply is not allowed 
to move too wildly. In $9.1, we discuss how such a constraint can be expressed. 
In a realistic discrete-time framework, it can be expressed in terms of the variation 
spectrum of the price series S(t). In a theoretical continuous-time framework, where 
clearer and more elegant theorems can be proven, it can be expressed in terms of the 
variation exponent or the Holder exponent of S(t). 
The notion that the market is constrained in how it can change prices should, of 
course, be taken with a grain of salt. The market can do what it wants. But no theory 
is possible without some regularity assumptions, and the game-theoretic framework 
can be credited for making clear the nature of the assumptions that the Black-Scholes 
argument requires. 
As we explain in 59.2, the use of the law of large numbers on a fine time scale 
is more problematic. The problem is that the hedging of options must actually be 
implemented on a relatively coarse time scale. Transaction costs limit the frequency 
with which it is practical or desirable to trade in S ,  and the discreteness of actual 
trades limits the fineness of the scale at which the price process S(t) is even well 
defined. In practice, the interval dt between adjustments in one’s holdings of S is 
more likely to be a day than a millisecond, and this makes the appeal to the law of 
large numbers in the Black-Scholes argument appear pollyannaish, for this appeal 
requires the total change in S(t) to remain negligible during enough dts for the law 
of large numbers to do its work. 
In our judgment, the appeal to the law of large numbers is the weak point of the 
Black-Scholes method and may be partly responsible for the substantial departures 
from the Black-Scholes formula often observed when option prices are determined 
by supply and demand. In any case, the appeal is unpersuasive in the game-theoretic 
framework, and in order to eliminate it, we need a significant change in our under- 
standing of how options should be priced and hedged. 
When time is measured in days, acceptance of the Black-Scholes use of the law of 
large numbers amounts, roughly speaking, to the assumption that a derivative security 
that pays daily dividends equal to (dS(t)/S(t))2 
should decrease in price linearly: its 
price at time t should be u2 (T - t), where u2 is the variance rate of the process S(t) 
and T is the date the commitment to pay the dividends expires. We propose to drop 
this assumption and have the market actually price this dividend-paying derivative, 
the variance derivative, as we shall call it. As we show in 59.3, this produces a 
purely game-theoretic version of the Black-Scholes formula, in which the current 
market price of the variance derivative replaces the statistical estimate of o2 (T - t )  
that appears in the standard Black-Scholes formula. A derivative that pays dividends 
may not be very manageable, and in $12.2 we explain how to replace it with a 
more practical instrument. But the variance derivative is well suited to this chapter’s 
explanation of our fundamental idea: cure the shortcomings of the Black-Scholes 
method and make it purely game-theoretic by asking the market to price S’s volatility 
as well as S itself. 

9.1: THE BEHAVIOR OF STOCK-MARKET PRICES 
203 
70 
60 - 
50 - 
60 
50 '"p, 
, 
, 
I 
20 0 
100 
200 
300 
400 
500 
600 
'O0I 
900 
di 
600 
1 
100 
200 
300 
400 
500 
600 
500; 
Fig. 9.1 The graph on the left shows daily closing prices, in dollars, for shares of Microsoft 
for 600 working days starting January 1, 1996. The graph on the right shows daily closing 
values of the S&P 500 index for the same 600 days. 
After discussing stochastic and game-theoretical models for the behavior of stock- 
market prices and their application to option pricing, we move on, in 59.4, to a 
more theoretical topic: the efficient-market hypothesis. This section serves as an 
introduction to Chapter 15. 
In an appendix, $9.5, we discuss various ways that the prices given by the Black- 
Scholes formula are adjusted in practice to bring them into line with the forces of 
supply and demand. In some cases these adjustments can be thought of as responses 
to the market's pricing of the volatility of S(t). So our proposal is not radical with 
respect to practice. 
In a second appendix, $9.6, we provide additional information on stochastic option 
pricing, including a derivation of the stochastic differential equation for the logarithm 
of a diffusion process, a statement of It6's lemma, and a sketch of the general theory 
of risk-neutral valuation. 
9.1 THE BEHAVIOR OF STOCK-MARKET PRICES 
The erratic and apparently random character of changes in stock-market prices has 
been recognized ever since the publication of Louis Bachelier's doctoral dissertation, 
The'orie de la Speculation, in 1900 [9,60]. To appreciate just how erratic the behavior 
of these prices is, it suffices to glance at a few time-series plots, as in Figure 9.1. 
Bachelier proposed that the price of a stock moves like what is now called Brownian 
motion. This means that changes in the price over nonoverlapping intervals of time 
are independent and Gaussian, with the variance of each price change proportional to 
the length of time involved. Prominent among the several arguments Bachelie gave 
for each change being Gaussian was the claim that it is sum of many smaller changes, 
resulting from many independent influences; the idea that the Gaussian distribution 

204 
CHAPTER 9: GAME-THEORETIC PROBABILITY IN FINANCE 
appears whenever many small independent influences are at play was already widely 
accepted in 1900 ([3], Chapter 6). 
A important shortcoming of Bachelier’s model, which he himself recognized, is 
that it allows the price to become negative. The price of a share of a corporation 
cannot be negative, because the liability of the owner of the share is limited to what 
he pays to buy it. But this difficulty is easily eliminated: we may assume that the 
logarithm of the share price, rather than the price itself, follows a Brownian motion. 
In this case, we say that the price follows a geometric Brownian motion. 
In this section, we study how 
these stochastic models constrain the 
jaggedness of the path followed by 
the prices. 
In the next two chap- 
ters, we will use what we learn 
here to express these constraints di- 
rectly in game-theoretic terms-as 
constraints on Market’s moves in the 
game between Investor and Market. 
As we will see, this has many advan- 
tages. One advantage is that we can 
study the constraints in a realistically 
finite and discrete setting, instead of 
relying only on asymptotic theory ob- 
tained by making the length of time 
Norbert Wiener (1894-1964) at MIT in the 1920s. 
He was the first to put Brownian motion into the 
measure-theoretic framework. 
between successive price measure- 
ments or portfolio adjustments infinitely small. A second advantage is that we 
cannot avoid acknowledging the contingency of the constraints. At best, they are 
expectations based on the past behavior of Market, or perhaps on our understanding 
of the strategic interaction among the many players who comprise Market, and Mar- 
ket may well decide to violate them if Investor, perhaps together with some of these 
other players, puts enough money on the table. 
Our main tool for describing constraints on Market’s moves in a discrete-time 
game between Market and Investor is the variation spectrum. We define the variation 
spectrum in this section, and we explain how it behaves for the usual stochastic models 
and for typical price series such as those in Figure 9.1. We also discuss the variation 
and Holder exponents. These exponents can be defined only asymptotically, but once 
we understand how they are related to the variation spectrum, which is meaningful in 
the discrete context, we will be able to relate continuous-time theory based on them 
to discrete games between Investor and Market. 
Brownian Motion 
Five years after Bachelier published his dissertation, which was concerned with the 
motion of stock prices, the physicists Albert Einstein (1879-1955) and Marian von 
Smoluchowski (1872-1917) proposed the same model for the motion of particles 
suspended in a liquid (Einstein 1905, Smoluchowski 1906; see also [45, 110, 3181). 

9.1: THE BEHAVIOR OF STOCK-MARKET PRICES 
205 
-20,- 
I 
100 
200 
300 
400 
500 
600 
Fig. 9.2 
independent, with mean zero and variance one. 
A realization of the Wiener process. Each of the 600 steps in this graph are 
Because experimental study of the motion of such particles had been initiated by the 
naturalist Robert Brown in 1828, and because Einstein’s and Smoluchowski’s pre- 
dictions were promptly verified experimentally, the stochastic process that Bachelier, 
Einstein, and Smoluchowski studied became known as Brownian motion. 
Intuitively, Brownian motion is a continuous limit of a random walk. But as 
Norbert Wiener showed in the early 1920s, it can be described directly in terms of a 
probability measure over a space of continuous paths [ 102,3461. As Wiener showed, 
it is legitimate to talk about a random real-valued continuous function W on [0, co) 
such that 
W(0) = 0, 
0 for each t > 0, W ( t )  is Gaussian with mean zero and variance t, and 
0 if the intervals [tl , t 2 ]  and [ul, u2] do not overlap, then the random variables 
W(t2) - W(t1) and W(u2) - W(u1) are independent. 
We now call such a random function a Wiener process. It is nowhere differentiable, 
and its jaggedness makes it similar to observed price series like those in Figure 9.1. 
If dt is a small positive number, then the increment W(t + dt) - W ( t )  is Gaussian 
with mean zero and variance dt. This means in particular that its order of magnitude 
is 
One realization of the Wiener process (one continuous path chosen at random 
according to the probabilities given by the Wiener measure) is shown in Figure 9.2. 
Actually, this figure shows a random walk with 600 steps up or down, each Gaussian 
with mean zero and variance one. In theory, this is not the same thing as a realization 
of the Wiener process, which has the same jagged appearance no matter how fine the 
scale at which it is viewed. But this finer structure would not be visible at the scale 
of the figure. 
this is the Jdt effect. 

206 
CHAPTER 9: GAME-THEORETIC PROBABILITY IN FINANCE 
Diffusion Processes 
In practice, we may want to measure Brownian motion on an arbitrary scale and 
allow the mean to change. So given a Wiener process W ,  we call any process s of 
the form 
S(t) = pt + uW(t), 
(9.1) 
where p E R and u 2 0, a Brownian motion. The random variable S ( t )  then has 
mean pt and variance a‘t. We call p the drift of the process, we call u its volatiliq, 
and we call u‘ its variance. 
Equation (9.1) implies that any positive real number dt, we may write 
dS(t) = pdt + adW(t), 
(9.2) 
where, as usual, dS(t) := S(t + d t )  - S(t) and dW(t) := W(t + d t )  - W(t). When 
dt is interpreted as a infinitely small number rather than an ordinary real number, this 
is called a stochastic differential equation and is given a rigorous meaning in terms 
of a corresponding stochastic integral equation (see $9.6). 
We obtain a wider class of stochastic processes when we allow the drift and 
volatility in the stochastic differential equation to depend on S and t: 
dS(t) = p(S(t),t)dt + a(S(t), t)dW(t). 
(9.3) 
Stochastic processes that satisfy stochastic differential equations of this form are 
called diffusionprocesses, because of the connection with the diffusion equation (also 
known as the heat equation; see p. 128) and because the random walk represented by 
W diffuses the probabilities for the position of the path as time goes on. 
A diffusion process S that satisfies (9.3) has the Markov property: the probabilities 
for what S 
does next depend only on the current state, S( t). We can generalize further, 
allowing the drift and volatility to depend on the whole preceding path of S rather 
than merely the current value S(t). This produces a wider class of processes, which 
are often called It6 processes in honor of the Japanese mathematician Kiyosi It6. But 
in this book, we consider only the Markov case, (9.3). 
It8 developed a calculus for the study of stochastic differential equations, the 
stochastic calculus. The centerpiece of this calculus is It8’s lemma, which allows 
us write down, from knowledge of the stochastic differential equation governing an 
It8 process S, the stochastic differential equation governing the It6 process U ( S ) ,  
where U is a well-behaved function. We state It8’s lemma in $9.5, and we prove a 
game-theoretic variant in $14.2. But in the body of this chapter we avoid It6’s lemma 
in favor of more direct heuristic arguments, whose robustness is more easily analyzed 
when we relax the rather strong assumptions that define the Wiener process. 
The measure-theoretic account of continuous-time stochastic processes is essen- 
tially asymptotic: it shows us only what is left in the limit as the time steps of the 
underlying random walk (represented by W )  are made shorter and shorter. Although 
it makes for beauty and clarity, the asymptotic character of the theory can create dif- 
ficulties when we want to gauge the value and validity of applications to phenomena 
such as finance, which are discrete on a relatively macroscopic level. One of our 

9.1: THE BEHAVIOR OF STOCK-MARKET PRICES 
207 
goals in this book is to develop less asymptotic tools, whose relevance to discrete 
phenomena can be understood mQre directly and more clearly. 
Osborne’s Log-Gaussian Model (Geometric Brownian Motion) 
Although Bachelier continued publishing on probability and finance through the 
1930s, his fellow probabilists gave his work on probability little prominence and 
ignored his work on finance 1601. Consequently, the British and American statis- 
ticians and economists who began examining stock-market prices empirically and 
theoretically in the middle of the twentieth century had to rediscover for themselves 
the relevance of the Wiener process. The principal contribution was made in 1959 
by the American astrophysicist M. F. Maury Osborne, who was the first to publish a 
detailed study of the hypothesis that S(t) follows a geometric Brownian motion. This 
has been called Osborne’s log-Gaussian model, because it says that the logarithm of 
the price S(t), rather than S(t) itself, follows a Brownian motion [237, 3371. 
If In S(t) follows a Brownian motion, then we may write 
d l n  S(t) = podt + aodW(t) 
It follows (see p. 231) that the relative increments dS(t)/S(t) satisfy a stochastic 
differential equation of the same form: 
So S itself is also a diffusion process: 
dS(t) = pS(t)dt + OS(t)dW(t). 
(9.5) 
The stochastic differential equation (9.5) will be the starting point for our review in 
the next section of the Black-Scholes model for option pricing. 
Figure 9.3 shows two realized paths of the random motion defined by (9.3, with 
parameters chosen to match the apparent trend and volatility of the Microsoft prices 
shown in Figure 9.1. The parameters are the same for the two paths. Both start at 
22.4, the initial price of Microsoft in Figure 9.1, and for both the theoretical drift 
p is 0.0024 (the average daily change in the logarithm of Microsoft’s price), and 
the theoretical volatility o is 0.0197, (the square root of the average daily squared 
change in the logarithm of Microsoft’s price). The fact that o is multiplied by S(t) 
in (9.5) is visible in these graphs: the magnitude of the fluctuations tends to be larger 
when S(t) is larger. This same tendency towards larger fluctuations when the price 
is higher is also evident in Figure 9.1. On the other hand, the two paths show very 
different overall trends; the first ends up about 50% higher than Microsoft does at the 
end of 600 days, while the second ends up only about 1/3 as high. This illustrates 
one aspect of the relatively weak role played by the drift p in the diffusion model; it 
can easily be dominated by the random drift produced by the failure of the dW (t) to 
average exactly to zero. 

208 
CHAPTER 9: GAME-THEORETIC PROBABILITY IN FINANCE 
LcL- 
200 
100 
200 
300 
400 
500 
600 
L
2
0
0
k
 200 
300 
400 
500 
600 
Fig. 9.3 Two realizations of the same geometric Brownian motion, whose parameters are 
chosen to match the apparent trend and volatility in the Microsoft price series in Figure 9.1: 
S(0) = 22.4375, p = 0.0024, and 0 = 0.0197. 
In the four decades since Osborne’s for- 
mulation of the log-Gaussian model, abundant 
evidence has been found for deviations from it: 
dependencies, skewness, non-Gaussian kurto- 
sis, and heteroskedasticity [212, 216, 2081. 
Some authors, most notably Benoit Mandel- 
brot, have argued for alternative stochastic 
models. But most researchers in finance have 
not found these alternatives attractive or useful. 
They have continued to take the log-Gaussian 
model as their starting point,making ad hoc ad- 
justments and elaborations as necessary when 
empirical deviations become too troublesome. 
We agree with Mandelbrot that the log- 
Gaussian model is a doubtful starting point. 
But we do not propose replacing it with a 
different stochastic model. Instead, we pro- 
pose dropping the assumption that the market 
Benoit Mandelbrot (born 1924) in 1983. 
Since the 1960s, 
has cham- is governed by a stochastic model. We now 
pioned alternatives to the log-~aussian turn to a tool that can help us do this, the vari- 
model. 
ation spectrum. 

9.1: THE BEHAVIOR OF STOCK-MARKET PRICES 
209 
9 -  
8 -  
Fig. 9.4 Variation spectra for the two price series in Figure 9.1-Microsoft 
on the left and 
the S&P 500 on the right. In both cases, we have rescaled the data in Figure 9.1 by taking 
the median value as our unit. The median price for Microsoft over the 600 working days in 
Figure 9.1 is approximately $48.91; the median value of the S&P 500 index is approximately 
775. This unit determines the vertical scale in the picture of the variation spectrum. As an 
example, consider varsoo(l), which is the sum of the absolute values of the daily changes. In 
the case of Microsoft, vareoo(1) is approximately 9.5, meaning that the total of the absolute 
sizes of the daily changes over 600 days is 9.5 times the median price. In the case of the 
S&P 500, vareoo(1) is approximately 4.3, meaning that the total of the absolute sizes of the 
daily changes is 4.3 times the median value of the index. 
The Variation Spectrum 
Consider a continuous function S(t) on the finite interval [O, TI. Choose an integer 
N ,  set 
2, = s (n$) - s 
- 1);) 
for n = 1,. . . , N ,  and set 
N 
for all p > 0. We call vars,N(p) the p-variation of S, and we call the function 
varS,N the variation spectrum for S. We abbreviate varS,N to vars or varN or 
even to var in contexts that fix the missing parameters. If we set dt := T I N ,  then 
we can also write (9.6) in the form 
(9.7) 
where, as usual, dS(t) := dS(t + dt) - dS(t) 

210 
CHAPTER 9: GAME-THEORETIC PROBABILlTY IN NNANCE 
Figure 9.4 shows the variation spectra for the Microsoft and S&P 500 data shown 
in Figure 9. I. These spectra display some typical features: the p-variation has 
large values for p less than 1 and small values for p greater than 2. This is to 
be expected; if Iz,I 
< 1 for all n, then vars,N(p) decreases continuously in p ,  
with limp+O vars,N(O) = N and limp+m vars,N(p) = 0. The fall from large to 
small values is gradual, however, and the apparent position of the transition depends 
strongly on the unit of measurement for the original series. This dependence is 
illustrated by Table 9.1, which gives var600 (2) for the Microsoft and S&P 500 data 
measured with several different units. 
In many of the games between Investor and Market that we will study, the ability 
of Investor to hedge the sale of an option depends on Market choosing his moves 
2 1 , .  . . , XN so that v a r ~ ( 2 )  
is small-or 
at least so that v a r ~ ( 2  + E )  is small for 
some small positive E .  In Chapter 10, for example, we prove that under certain 
conditions, which include v a r ~ ( 2  + E )  5 S, the game-theoretic upper and lower 
prices of an option is approximated in discrete time by our Black-Scholes formula 
with an error no greater than KS for some constant K .  Here it makes sense that varN 
should depend on the unit of measurement for the price of the underlying security, 
for the error in pricing the option is also measured using some arbitrary unit, and the 
constant K depends on how these two units are related. But the devil is in the details. 
It is not enough to say that the Black-Scholes formula will be accurate if v a r ~ ( 2  + E )  
is small. Just how small a bound we can put on v a r ~ ( 2  + E )  will determine whether 
the formula will give a reasonable approximation or be an asymptotic irrelevance. 
The Variation and Holder Exponents 
In addition to a practical theory, in which we wade through messy calculations to 
obtain bounds on the accuracy of hedging in terms of bounds on 2-variation, we do 
also want an asymptotic theory, in which we clear away the clutter of practical detail 
in order to see the big picture more clearly. This book is far from practical, and 
asymptotic theory will occupy most of the remaining chapters. In this asymptotic 
theory, we will emphasize the value of p at which the p-variation drops from large 
(asymptotically infinite) to small (asymptotically zero). In practice, as we have just 
seen, this value is scarcely sharply defined. But an asymptotic theory will assume, 
Table 9.7 
Dependence of varaoo(2) and varcoo(2.5) on the choice of a unit for the Mi- 
crosoft price or the S&P 500 index. The p-variations are given to three significant figures or 
three decimal places, whichever is less. 
Microsoft 
S&P 500 

9.1: THE BEHAVIOR OF STOCK-MARKET PRlCES 
21 1 
Fig. 9.5 Mandelbrot’s concept of box dimension ([216], pp. 172-173). Intuitively, the box 
dimension of an object in the plane is the power to which we should raise l / d t  to get, to the 
right order of magnitude, the number of dt x dt boxes required to cover it. In the case of an 
object of area A, about 
boxes are required, so the box dimension is 2. In the case of 
a smooth curve of length T ,  T / d t  boxes are required, so the box dimension is 1. In the case of 
the graph of a function on [0, TI with Holder exponent H ,  we must cover a vertical distance 
( d t ) H  above the typical increment dt on the horizontal axis, which requires ( d t ) H / d t  boxes. 
So the order of magnitude of the number of boxes needed for all T / d t  increments is ( d t ) H - 2 ;  
the box dimension is 2 - H .  
one way or another, that it is defined. It is called the variation exponent, and its 
inverse is called the Holder exponent, in honor of Ludwig Otto Holder (1859-1937). 
We brush shoulders with the idea of a Holder exponent whenever we talk infor- 
mally about the order of magnitude of small numbers. What is the order of magnitude 
of 21, . . . , XN relative to l/N? If N is large and the lznl have the same order of 
magnitude as (l/N)H on average, where 0 < H 5 1, then the order of magnitude 
of the p-variation will be 
This will be close to zero for p > l/H + E and large for p < 1/H - E ,  where E is 
some small positive number. Intuitively, 1 / H  is the variation exponent, and H is the 
Holder exponent. In other words, the Holder exponent of S(t) is the number H such 
that dS(t) has the order of magnitude ( d t ) H .  
Following Mandelbrot ([215], Part 11, 52.3; [216], p. 160), we also introduce a 
name for 2 - H ;  this is the box dimension. Mandelbrot’s rationale for this name is 
sketched in Figure 9.5. Although this rationale is only heuristic, the concept gives 
visual meaning to the Holder exponent. In general, the box dimension of the graph 
of a time series falls between 1 and 2, because the jaggedness of the graph falls 
somewhere between that that of a line or a smooth curve and that of a graph so dense 
that it almost completely fills a two-dimensional area. 
As Figure 9.5 suggests, an ordinary continuous function should have box dimen- 
sion 1, which means that its Holder exponent and variation exponent should also be 1. 
For a wide class of stochastic processes with independent increments, including all 
diffusion processes, we expect the Holder exponent of a path to be 1/2; this expresses 
the idea that the increment dS has the order of magnitude (dt)l/’. Functions that 
fall between an ordinary function and a diffusion process in their jaggedness may be 
called substochastic. These benchmarks are summarized in Table 9.2. 

212 
CHAPTER 9: GAME-THEORETIC PROBABILITY 1N FINANCE 
For a greater variety of values for the Holder exponent, we may consider the 
fractional Brownian motions. The fractional Brownian motion with index h E (0,l) 
is a stochastic process Bh such that Bh(O) = 0, values Bh(t) for t > 0 are jointly 
Gaussian, and the variance of an increment Bh(t) - Bh(s), where 0 < s < t, is 
(t - s ) ~ ~ .  
If h = 0.5, then the fractional Brownian motion reduces to the usual 
Brownian motion, but for other values of h even nonoverlapping increments are 
correlated. 
We can assume that the sample paths are continuous. The Holder 
exponent should approximate the index h. Figure 9.6 shows some sample paths for 
different h. See [13,48,214,216]. 
We use such cautious turns of phrase (“the Holder exponent is supposed to be 
such and such”) because there is no canonical way to define the Holder exponent 
precisely. In practice, we cannot determine a Holder exponent for an arbitrary 
continuous function S(t) on [0, t ]  with any meaningful precision unless we chop the 
interval into an absolutely huge number of increments, and even then there will be 
an unattractive dependence on just how we do the chopping. In order to formulate a 
theoretical definition, we cannot merely look at the behavior in the limit of a division 
of [O, T ]  into N equal parts; in general, we must pass to infinity much faster than this, 
and exactly how we do it matters. In the nonstochastic and nonstandard framework 
that we use in Chapter 11, this arbitrariness is expressed as the choice of an arbitrary 
infinite positive integer N .  
The practical implication of the relative indeterminacy of the Holder exponent is 
clear. Unlike many other theoretical continuous-time concepts, the Holder exponent 
is not something that we should try to approximate in a discrete reality. It has a 
less direct meaning. When a statement in continuous-time theory mentions a Holder 
exponent H, we can use that statement in a discrete reality only after translating it 
into a statement about the p-variation for values of p at a decent distance from 1/H. 
For example, the statement that Market’s path will have Holder exponent l / 2  or less 
must be translated into a condition about the relative smallness of the p-variation for 
p = 2 + E ,  where E > 0 is not excessively small. 
Table 9.2 Typical values for our three related measures of the jaggedness of a continuous 
real-valued function S. The figures given for a substochastic function are typical of those 
reported for price series by Mandelbrot. 
Holder exponent 
variation exponent 
box dimension 
H 
vex 
dim 
definition 
vex := 1/H 
dim :=I 2 - H 
range 
O < H L 1  
1 5 vex 5 0;) 
1 5 dim 5 2 
ordinary function 
1 
diffusion process 
0.5 
substochastic 
0.57 
1 
1 
1.75 
1.43 
2 
1.5 

9.1: THE BEHAVIOR OF STOCK-MARKET PRICES 
213 
a h = 0.2 
b h = 0.4 
c h = 0.5 
d h = 0.6 
e h = 0.8 
f h = l  
Fig. 9.6 Sample paths for fractional Brownian motions with different values for the index 
h. The Holder exponent of a sample path is supposed to approximate the index h. When 
h = 0.5, the fractional Brownian motion reduces to ordinary Brownian motion. When h = 1, 
it reduces to a straight line. 
10 
9 
1 
1 5  
2 
2 5  
Fig. 9.7 Graphs of variation spectra for the straight line S(t) = t on 0 5 t 5 1. On the left 
is the variation spectrum based on a division of the interval [0, 11 into 600 steps. On the right 
is the variation spectrum based on a division into 10.000 steps. These graphs fall from values 
greater than one to values less than one when we cross p = 1 on the horizontal axis, but the 
fall is less than abrupt. 

214 
CHAPTER 9: GAME-THEORETIC PROBABILITY IN FINANCE 
In order to be fully persuasive on this point, we should perhaps look at some 
further examples of the indeterminacy of the Holder exponent even when N is 
huge. Consider the best behaved function there is: the linear function S(t) = t for 
0 5 t 5 1. We split the interval [0,1] into N parts, and (9.7) becomes 
Figure 9.7 graphs this function for N = 600 and N = 10,000. As N tends to 
infinity, N1-p tends to zero for p > 1 and to infinity for p < 1, confirming that the 
Holder exponent for S is 1. But how large does N have to be in order for the variation 
spectrum to identify this value to within, say, lo%? For example, how large does N 
have to be in order for 
vars,N(p) 2 10 forp 5 0.9 
and 
vars,N(p) 5 0.1 forp 2 1.1 
(9.9) 
to hold'? This is not hard to answer: the conditions N1-O 
5 0.1 
are both equivalent to N 2 10". And even when N is in the billions, there are still 
arbitrary choices to be made. If we had chosen our linear function on [0,1] to be 
S(t) = lOOf instead of S(t) = f ,  varN(1) would not be 1, as shown in Figure 9.7 
and taken for granted by our question about (9.9). Instead, it would be 100. 
The story is similar for other continuous functions, including sample paths for 
diffusion processes: we do not get even the appearance of a sharply defined value for 
the Holder exponent unless N is in the billions. Figure 9.8 illustrates the point with 
the variation spectra for two realizations of the Wiener process, one with N = 600 
and one with N = 10,000. In this case, the Holder exponent is 0.5: the p-variation 
tends to infinity with N for p less than 2 and to zero for p greater than 2. The scale in 
which the Wiener process is measured has the convenient feature that varN(p) = 2 
for all N ,  but the drop at this point is no more abrupt than for the linear function. We 
should note that Figure 9.8 is not affected by sampling error; different realizations 
give curves that cannot be distinguished visually. 
The vargoo for Microsoft and the va1-6~0 
for the S&P 500, both of which we 
displayed in Figure 9.4, are similar to the var6Oo for the Wiener process in Figure 9.8. 
But in the Microsoft and S&P 500 cases, we must use empirical scales for the data 
(in Figure 9.1, our unit was the observed median in each case), and so we cannot 
create the illusion that we can identify 2 as the crossover point from large to small 
p-variation. 
2 10 and N1 -' 
Why Do Stock-Market Prices Move Like Brownian Motion? 
As we have explained, we will use the variation spectrum and the variation exponent 
in game-theoretic versions of Black-Scholes pricing that do not rely on the assumption 
that stock-market prices are stochastic. In these versions, the assumption that the 
stock price S(t) follows a geometric Brownian motion with theoretical volatility 
a is replaced by the assumption that the market prices a derivative security that 

9.2: THE STOCHASTIC BLACK-SCHOLES FORMULA 
215 
-.L_. 
- 
1 
1.5 
2 
2 5  
lo---- 
~ 
- --_ 
0.5 
1 
1.5 
2 
2.5 
8 -  
7 -  i; 
2 
1 
0 0.5 
1 
1.5 
2 
2.5 
Fig. 9.8 The variation spectrum for a sample path of the Wiener process, for 600 and 10,000 
sample points. 
pays dividends that add up to the actual future (relative) variance of S(t). We 
then assume bounds on the p-variations of S(t) and the price D(t) of the traded 
derivative. In discrete time, we assume upper bounds on vars(2 + E) and varo(2 - 
E )  (Proposition 10.3, p. 249). In our continuous-time idealization, bounds on the 
wildness of S(t) are not even needed if we can assume that the payoff of the option 
we want to price is always nonnegative and that S does not become worthless; in this 
case it is enough that the variation exponent of the variance security 2) be greater 
than 2 (or, equivalently, that its Holder exponent be less than 1/2) (Theorem 11.2, 
p. 280). 
The movement of stock-market prices does look roughly like Brownian motion. 
But in our theory this is a consequence, not an assumption, of our market games 
for pricing options. This is made clear in our continuous-time theory, where we 
prove (Proposition 11.1, p. 28 1) that Market can avoid allowing Investor to become 
infinitely rich only by choosing his dS(t) so that S(t) has variation exponent exactly 
equal to 2. This is a way of expressing the truism that it is the operation of the market 
that makes price changes look like a random walk. The game-theoretic framework 
clears away the sediment of stochasticism that has obscured this truism, and in its 
discrete-time form it allows us to explore how far the effect must go in order for 
Black-Scholes pricing to work. 
9.2 THE STOCHASTIC BLACK-SCHOLES FORMULA 
The Black-Scholesjormula was published in 1973, in two celebrated articles, one by 
Fischer Black and Myron Scholes, the other by Robert C. Merton [30, 229,28, 161. 
This formula, which prices a wide class of derivatives, has facilitated an explosive 
growth in the markets for options and more complex derivatives. In addition to filling 
the need for objective pricing (a starting point for valuation by creditors and auditors), 

216 
CHAPTER 9: GAME-THEORETIC PROBABILITY IN FINANCE 
it gives those who write (originate) options guidance on how to hedge the risks they 
are taking, and it permits a great variety of adjustments that can bring the ultimate 
pricing into line with supply and demand. It was recognized by a Nobel Prize in 
1997. 
As we explained in the introduction to this chapter, the Black-Scholes formula 
relies on the assumption that the price of the underlying stock follows a geometric 
Brownian motion. In this section, we review the derivation, informally but with 
careful attention to how the stochastic assumption is used. This will set the stage 
for our presentation, in the next section, of our purely game-theoretic Black-Scholes 
formula. 
European Options 
Recall that a derivative (or, more properly, a 
derivative security) is a contract whose pay- 
off depends on the future movement of the 
prices of one or more commodities, securi- 
ties, or currencies. The derivative’s payoff 
may depend on these prices in a complicated 
way, but the easiest derivatives to study are 
the European options, whose payoffs depend 
only on the price of a single security at a fixed 
date of maturity. A European option U on an 
underlying security S is characterized by its 
maturity date, say T ,  and its payofffunction, 
say U .  Its payoff at time T is, by definition, 
U(T) 
:= U(S(T)). 
(9.10) 
The problem is to price IA at a time t before 
T .  What price should a bank charge at time 0, 
Fischer Black (1938-1995) in 1975. Be- 
say, for a contract that requires it to pay (9.10) 
cause of his early death, Black did not 
at time T? 
share in the 1997 Nobel prize for eco- 
The most familiar European option is the 
nomics, which was a ~ r d e d  
to Myron 
Europeaiz call, which allows the holder to buy 
Scholes and Robert C. Merton. 
a security at a price set in advance. The holder 
of a European call on S with strike price c and maturity T will exercise it only if 
S ( T )  exceeds c, and he can then immediately realize the profit S(T) - c by reselling 
the security. So the payoff function U of the call is 
S - c  
i f S > c  
i 0 
i f S 5 c .  
U ( S )  := 
In practice, the bank selling the option and the customer buying it usually do not 
bother with the underlying security; the bank simply agrees to pay the customer 
U ( S ( T )  
1. 

9.2: THE STOCHASTIC BLACK-SCHOLES FORMULA 
217 
At first glance, one might expect that buyers of call options would be motivated 
by the belief that the price of the stock S will go up. This is often true in practice, 
especially for buyers who cannot afford to buy the stock outright. But buying the 
stock is a more straightforward and efficient way to bet on a price increase. The 
buyer of a call option will generally be charged more for his potential payoff than the 
interest on the money needed to buy the stock, because he is not risking the loss a 
buyer of the stock would incur if its price goes down instead of up. If he can afford 
to buy the stock but buys the stock option instead, the fact that he is paying to avoid 
this risk reveals that he is not really so confident that the price will go up. He may be 
counting only on a big change in the price. If it goes up, he will make a lot of money. 
If it goes down, he will lose only the relatively small price he pays for the option. 
Another important European option is the European put, which entitles its holder 
to sell stock at a given price at a given time. It can be analyzed in the same way as 
we have analyzed the European call. European options are less popular, however, 
than American options, which can be exercised at a time of the holder’s choosing. 
We analyze American options in Chapter 13. 
The Market Game 
In the 1950s and early 1960s, when American economists first attacked the problem 
of pricing derivatives, they considered a number of factors that might influence the 
price an investor would be willing to pay, including the investor’s attitude toward risk 
and the prospects for the underlying security [56, 114,2641. But the formula derived 
by Black and Scholes involved, to their own surprise, only the time to maturity T ,  
the option’s payoff function U ,  the current price S(t) of the underlying security S, 
and the volatility of S’s price. Moreover, as they came to realize in discussions with 
Merton, the formula requires very little economic theory for its justification. If the 
price of S follows a geometric Brownian motion, then the price the formula gives for 
U is its game-theoretic price, in the sense of Part I, in a game between Investor and 
Market in which Investor is allowed to continuously adjust the amount of the stock 
S he holds. The protocol for this game looks like this: 
THE BLACK-SCHOLES 
PROTOCOL 
Parameters: T > 0 and N E N dt := TIN 
Players: Investor, Market 
Protocol: 
Z(0) := 0. 
Market announces S(0) > 0. 
FOR t = 0, dt, 2dt,. . . , T - dt: 
Investor announces d ( t )  c R 
Market announces dS(t) E R 
S(t + dt) := S(t) + dS(t). 
q t  + dt) := Z(t) + S(t)dS(t). 
(9.1 1) 

218 
CHAPTER 9: GAME-THEORETIC PROBABILITY IN FINANCE 
Investor’s move d ( t )  is the number of shares of the stock he holds during the period 
t to t + dt, Market’s move dS(t) is the change in the price per share over this period, 
and hence d(t)dS(t) is Investor’s gain (or loss). We write Z 
for Investor’s capital 
process. 
Investor starts with zero capital, but at each step he can borrow money to buy stock 
or borrow stock to sell, in amounts as large as he wants. So his move 6(t) may be 
any number, positive, zero, or negative. Market may also choose his move positive, 
zero, or negative, but he cannot allow S(t) to become negative. If S(t) ever becomes 
zero, the firm issuing the stock is bankrupt, and S(t) must remain zero. 
For simplicity, we assume that the interest rate is zero. Thus we do not need to 
adjust Investor’s gain, S(t)dS(t), to account for his payment or receipt of interest. 
We also assume that transaction costs are zero; Investor does not incur any fees when 
he buys or sells stock in order to change the number of shares he is holding from d(t) 
to 6(t + dt). 
The Stochastic Assumption 
To the protocol we have just described, Black and Scholes added the assumption that 
S(t) follows a geometric Brownian motion. In other words, Market’s moves must 
obey the stochastic differential equation for geometric Brownian motion, 
dS(t) = pS(t)dt + BS(t)dW(t). 
(9.12) 
But the derivation of the Black-Scholes formula does not actually use the full force of 
this assumption. What it does use can be boiled down to three subsidiary assumptions: 
1. The Jdt effect. The variation exponent of the S(t) is 2. In other words, the 
order of magnitude of the dS(t) is (dt)l/’. This is a constraint on the wildness 
of Market’s moves. They cannot take too jagged a path. 
2. Variance proportional to price. The expected value of (dS(t))2 
just before 
Market makes the move dS(t) is approximately a2S2(t)dt. 
3. Authorization to use of the law of large numbers. In a calculation where the 
squared increments (dS(t))’ are added, they can be replaced by their expccted 
values, 02S2(t)dt. This follows from the assumption that the dW(t) are 
independent, together with the law of large numbers, which is applicable if the 
time increment dt is sufficiently small. 
In our judgment, the most troublesome of these three assumptions is the third. The 
first assumption, as we explained in the preceding section, can be re-expressed 
in game-theoretic terms. Adjustments (more or less convincing and more or less 
cumbersome) can be made to correct for deviations from the second. But the third is 
risky, simply because the number of terms being averaged may fail to be large enough 
to justify the use of the law of large numbers. The new Black-Scholes method that 
we introduce in the next section is motivated mainly by our dissatisfaction with this 
risky use of the law of large numbers. 

9.2: THE STOCHASTIC BLACK-SCHOLES FORMULA 
219 
Assumption 1, that the dS(t) have order of magnitude (&)‘I2, follows, of course, 
from (9.12) and the fact that the dW(t), as increments in a Wiener process, have this 
order of magnitude. The first term on the right-hand side of (9.12), pS(t)dt, can be 
neglected, because dt is much smaller than (dt)ll2. 
Assumption 2 follows similarly when we square both sides of (9.12): 
(dS(t))’ = S”t) ($(dt)2 + 2pLadtdW(t) + La’((dW(t))’) . 
(9.13) 
Because dW(t) is of order (dt)’/’, (dW(t))’ is of order dt and dominates the other 
two terms, and hence the approximate expected value of (dS(t))’ is obtained by 
dropping them and replacing (dW(t))’ by its expected value, dt. 
In order to explain Assumption 3 carefully, we first note that as the square of 
a Gaussian variable with mean zero and variance dt, (dW(t))’ has mean dt and 
variance 2 ( ~ l t ) ~ .  
(The Gaussian assumption is not crucial here; the fact that the 
coefficient of (dt)’ in the variance is exactly 2 depends on it, but this coefficient is 
of no importance.) This can also be expressed by writing 
(dW(t))’ = dt + z ,  
(9.14) 
where the z has mean zero and variance 2(dt)2. In words: (dW(t))’ is equal to dt 
plus a fluctuation of order dt. Summing (9.14) over all N increments 
dW(O),dW(dt),dW(2dt), . . . ,dW(T - dt), 
we obtain 
N-1 
N-1 
C ( ~ W ( T & ) ) ~  
= T + C z,. 
n=O 
n=O 
Because 
z, has a total variance of only 2Tdt, we may neglect it and say that 
the (dW(t))2 
add to the total time T ;  the z, cancel each other out. More generally, 
if the squared increments (dW(t))2 
are added only after being multiplied by slowly 
varying coefficients, such as o2(S(t))’, we can still expect the z, to cancel each 
other out, and so we can simply replace each (dW(t))2 
in the sum with dt. Here it 
is crucial that the time step dt be sufficiently small; before there is any substantial 
change in the coefficient S2(t), 
there must be enough time increments to average the 
effects of the z, to zero. 
The Derivation 
Now to our problem. We want to find U ( t ) ,  the price at time t of the European option 
U that pays U(S(T)) at its maturity T .  We begin by optimistically supposing that 
there is such a price and that it depends only on t and on the current price of the 
stock, S(t). This means that there is a function of two variables, u ( s ,  t), such that 
U(t) = p(S(t), t). In order to find fl, we investigate the behavior of its increments 
by means of a Taylor’s series. 

220 
CHAPTER 9: GAME-THEORETIC PROBABILITY IN FINANCE 
Considering only terms of order (dt)1/2 
or dt (i.e., omitting terms of order (dt)3/2 
and higher, which are much smaller), we obtain 
(9.15) 
au 
aT7 
1a2u 
as 
at 
2 as 
dU(S(t), t) M -dS(t) + -dt + 
Here there is one term of order (dt)1/2-the 
term in dS(t). There are two terms of 
order dt-the 
term in dt and the term in (dS(t))2. The terms of order dt must be 
included because their coefficients are always positive and hence their cumulative 
effect (there are T/dt of them) will be nonnegligible. Individually, the dS(t) are 
much larger, but because they oscillate between positive and negative values while 
their coefficient varies slowly, their total effect may be comparable to that of the dt 
terms. (We made this same argument in our heuristic proof of De Moivre’s theorem 
in ‘$6.2.) 
Substituting the right-hand side of (9.13) for (dE~’(t))~ 
in (9.15) and again retaining 
only terms of order (dt)1/2 and dt, we obtain 
(9.16) 
au 
av 
1 
a2u 
a s  
at 
2 
asJ 
dU(S(t),t) 
M -dS(t) + -dt 
+ - ~ ~ S ~ ( t ) - ( d W ( t ) ) ~ .  
We still have one term of order (dt)1/2 
and two terms of order dt. 
obtaining 
Because its coefficient in (9.16) varies slowly, we replace (dW(t))2 
with dt, 
(9.17) 
d S 2  
This is the risky use of the law of large numbers. It is valid only if the coefficient 
S2(t)d2c/ds2 holds steady during enough d t  for the (~!T/li(t))~ 
to average out. 
Notice that we simplified in our preliminary discussion of this point. The variability 
in ( ~ ! W ( t ) ) ~ ’ s  
coefficient comes from d2U/ds2 in addition to S2(t). 
Now we look again at the Black-Scholes protocol. According to (9.1 I), 
d q t )  = &(t)dS(t), 
where d(t) is the amount of stock Investor holds from t to t + dt. Comparing this 
with (9.17), we see that we can achieve our goal by setting 
- 
dU 
d ( t )  := -(S(t), t )  
as 
if we are lucky enough to have 
au 
1 2 
2 a2u 
-(S(t),t) + 
s (t)-(S(t), t )  = 0 
at 
8.52 
(9.18) 
for all 2, no matter what value S(t) happens to take. 

9.3: A PURELY GAME-THEORETIC BLACK-SCHOLES FORMULA 
221 
Our problem is thus reduced to a purely mathematical one: we need to find a 
function u ( s ,  t), for 0 < t < T and 0 < s < co, that satisfies the partial differential 
equation 
au 
1 2 ,d2V 
-+--as 
- = 0  
dt 
2 
as2 
(9.19) 
(this is the Black-Scholes equation) and the final condition 
- 
U ( s , t )  + U ( s )  (t -+ T ) .  
As it turns out (see Chapter 1 l), there is a solution, 
03 
- 
U ( s ,  t) = 
U (4 
N-uZ(T-t)/2, u Z ( T - t ) ( W .  
(9.20) 
As the reader will have noted, (9.19) differs only slightly from the heat equation, 
which we used in our proof of De Moivre’s theorem, and (9.20) is similar to the 
solution of that equation. Both equations are parabolic equations, a class of par- 
tial differential equations that have been thoroughly studied and are easily solved 
numerically; see 56.3 and [68, 131, 3521. 
So an approximate price at time t for the European option U with maturity T and 
payoff U ( S ( T ) )  
is given by 
00 
U ( t )  = 
u (S(t)eZ) N-u2(T-t)/2, u2(T-t) (dz). 
(9.21) 
This is the Black-Scholes formula for an arbitrary European option. (The formula 
is more often stated in a form that applies only to calls and puts.) We can replicate 
the option U at the price (9.21) by holding a continuously adjusted amount of the 
underlying security S, the amount d ( t )  held at time t being given by (9.18). Financial 
institutions that write options often do just this; it is called delta-hedging. 
Only one of the parameters in (9.12), the volatility n, plays a role in the derivation 
we have just outlined. The other parameter, the drift p, does not appear in the 
Black-Scholes equation or in the Black-Scholes formula. 
Most expositions simplify the argument by using ItB’s lemma (p. 232). We have 
avoided this simplification, because ItB’s lemma itself is based on an asymptotic 
application of the law of large numbers, and so using it would obscure just where 
such asymptotic approximation comes into play. As we have explained, we are 
uncomfortable with the application of the law of large numbers that takes us from 
(9.16) to (9.17), because in practice the length of time dt may be equal to a day or 
longer, and it may be unreasonable to expect S2d2u/ds2 to hold steady for a large 
number of days. 
1, 
9.3 A PURELY GAME-THEORETIC BLACK-SCHOLES FORMULA 
We now turn to our game-theoretic version of the Black-Scholes formula. We have 
already explained the main ideas: (1) Market is asked to price both S and a derivative 

222 
CHAPTER 9: GAME-THEORETIC PROBABILlTY IN FlNANCE 
security 2) that pays dividends (dS(t)/S(t))2, 
and (2) constraints on the wildness of 
price changes are adopted directly as constraints on Market’s moves. We now explain 
informally how these ideas produce a Black-Scholes formula. The argument is made 
rigorous in the next two chapters, in discrete time in Chapter 10 and in continuous 
time in Chapter 1 I. 
Another Look at the Stochastic Derivation 
Consider again the derivation of the stochastic Black-Scholes formula. It begins with 
a Taylor’s series: 
(9.22) 
au 
aU 
ia2U 
as 
at 
2 as 
dU(S(t),t) 
M --dS(t) + -dt 
+ -?(dS(t))? 
The right-hand side of this approximation is the increment in the capital process of 
an investor who holds shares of two securities during the period from t to t + dt: 
0 d u / d s  shares of S ,  and 
0 -u-2du/at shares of a security D whose price per share at time t is 02(T - t )  
(the remaining variance of S), and which pays a continuous dividend per share 
amounting, over the period from t to t + dt, to 
(9.23) 
The second term on the right-hand side of (9.22) is the capital gain from holding 
the -o-2du/dt shares of D, 
and the third term is the total dividend. 
The Black-Scholes equation tells us to choose the function u so that the dividend per 
share, (9.23), reduces to 
(g)2, 
and the increment in the capital process, (9.22), becomes 
au 
au 
au (dS(t))2 
8 s  
at 
at o2S2(t) ‘ 
du(S(t), t )  M -dS(t) + -dt 
- - 
___ 
(9.24) 
Only at this point do we need the assumption that S(t) follows a geometric Brownian 
motion. It tells us that (dS(t))2 
M a2S2(t)dt, 
so that (9.24) reduces to 
av 
av 
av 
a s  
at 
at 
dU(S(t),t) 
M -dS(t) + -dt 
- -dt, 
which will be easier to interpret if we write it in the form 
av 
au 
au 
a s 
at 
at 
dU(S(t),t) 
M -dS(t) - 0-2-(-02dt) 
- 0-2-(02dt). 

9.3: A PURELY GAME-THEORETIC BLACK-SCHOLES FORMULA 
223 
The capital gain on each share of D, 
-a’dt, is cancelled by the dividend, a’dt. So 
there is no point in holding -a-’aU/dt 
shares, or any number of shares, of D. 
The 
increment in the capital process is simply 
au 
a 
9 
dU(S(t),t) x -dS(t), 
which we achieve just by holding avlas shares of S. 
This way of organizing the Black-Scholes argument points the way to the elimi- 
nation of the stochastic assumption. We can do without the assumption if the market 
really does price a security D whose dividend accounts for the (dS(t))’ term in the 
Taylor’s series. 
The Purely Game-Theoretic Derivation 
Assume now that between 0 and T ,  Investor trades in two securities: (1) a security 
S that pays no dividends and (2) a security D, 
each share of which periodically pays 
the dividend (dS(t)/S(t))2. 
This produces the following protocol: 
THE NEW BLACK-SCHOLES 
PROTOCOL 
Parameters: T > 0 and N E N; dt := TIN 
Players: Investor, Market 
Protocol: 
Market announces S(0) > 0 and D(0) > 0. 
Z(0) := 0. 
FOR t = 0, dt, 2dt,. . . , T - dt: 
Investor announces d(t) E R and X ( t )  E R. 
Market announces dS(t) E R and dD(t) E R 
S(t + dt) := S(t) + dS(t). 
D(t + dt) := D(t) + dD(t). 
Z(t + dt) := Z(t) + d(t)dS(t) + X ( t )  (dD(t) + (dS(t)/S(t))’). (9.25) 
Additional Constraints on Market: (1) D(t) > 0 for 0 < t < T and D(T) = 0, 
(2) S(t) 2 
0 for all t, and (3) the wildness of Market’s moves is constrained. 
Once D pays its last dividend, at time T ,  it is worthless: D ( T )  = 0. So Market 
is constrained to make his dD(t) add to -D(O). We also assume, as we did in the 
previous section, that the interest rate is zero. We do not spell out the constraints 
on the wildness of Market’s moves, which will take different forms in the different 
versions of game-theoretic Black-Scholes pricing that we will study in the next two 
chapters. Here we simply assume that these constraints are sufficient to justify our 
usual approximation by a Taylor’s series. 
Consider a European option U with maturity date T and payoff function U .  We 
begin by optimistically assuming that the price of U before T is given in terms of the 
current prices of ’D and S by 
U(t) = mw), 
D(t)), 

224 
CHAPTER 9: GAME-THEORETIC PROBABILITY IN FINANCE 
where the function u ( s ,  D )  satisfies the initial condition 
- 
U(s,O) = U ( s ) .  
(9.26) 
We approximate the increment in 24’s price from t to t + dt by a Taylor’s series: 
(9.27) 
au 
au 
1 d T 7  
d S  
dD 
2 as 
dU(S(t), D(t)) M -dS(t) + -dD(t) + - ~ ( d S ( t ) ) ~ .  
We assume that the rules of the game constrain Market’s moves dS(t) and dD(t) so 
that higher order terms in the Taylor expansion are negligible. 
Comparing Equations (9.25) and (9.27), we see that we need 
au 
ail7 
X ( t )  - 1 a2v 
d S  
dD 
S2(t) 
2 as2 
b(t) = -, 
X ( t )  = -, 
and - 
- -- 
The two equations involving X ( t )  require that the function v satisfy the partial 
differential ecluation 
for all s and all D > 0. This is the Black-Scholes equation, adapted to the market in 
which both S and D are traded. Its solution, with the initial condition (9.26), is 
00 
- 
u ( S , D )  = l m u ( S e z )  N - D / , , D ( ~ ~ ) .  
This is the Black-Scholes formula for this market. 
To summarize, the price for the European option U in a market where both the 
underlying security S and a volatility security D with dividend (dS(t)/S(t))2 
are 
traded is 
U ( t )  = 1, u (s(t)ez) 
N - D ( t ) / 2 , D ( t ) ( d z ) .  
(9.28) 
00 
To hedge this price, we hold a continuously changing portfolio, containing 
av 
-(S(t), D(t)) shares of S 
as 
and 
877 
-(S(t), D ( t ) )  shares of D 
dD 
at time t. 
By the argument of the preceding subsection, the derivative D is redundant if S( t )  
follows a geometric Brownian motion. In this case, D’s dividends are independent 
nonnegative random variables with expected value cr2dt. By the law of large numbers, 
the remaining dividends at time t will add to almost exactly 02(T - t), and hence 
this will be the market price, known in advance. 

9.3: A PURELY GAME-THEORETIC BLACK-SCHOLES FORMULA 
225 
In the following chapters, we refine and elaborate the derivation of (9.28) in various 
ways. In Chapter 10, we derive (9.28) as an approximate price in a discrete-time 
game in which Market is constrained to keep vars(2 + E )  and varD (2 - 
E )  small. In 
Chapter 11, we derive it as an exact price in a continuous-time game in which Market 
is constrained to make vex D < 2; it turns out that in this game Market is further 
obliged to make vex S = 2 in order to avoid allowing Investor to become infinitely 
rich. As we have already noted, this gives some insight into why stock-market prices 
resemble diffusion processes as much as they do: the game itself pushes them in this 
direction. In Chapter 12, we extend the argument to the case of a known interest rate 
and show that we can replace the dividend-paying security V with a derivative that 
pays at time T a strictly convex function of S(T). 
Other Choices for the Dividend-Paying Security 
The core idea of the preceding argument is to have the market price by supply and 
demand a derivative security D that pays a continuous dividend locally proportional to 
S’s incremental variance, (dS(t))2. 
We choseforV’s dividendto be (dS(t))2/S2(t), 
but this is not the only possible choice. If we take V’s dividend to be 
(9.29) 
then we obtain the partial differential equation 
au 
1 a2u 
aD 
2 
-- + -g(s)= 
= 0 
for the price u, and there are many different functions g(s) for which this equation 
has solutions. The choice g(s) := s2, which we have just studied and will study 
further in the next two chapters, leads to the Black-Scholes formula. The choice 
g(s) := 1, which we will also study in the next two chapters, leads to Bachelier’s 
formula. Bachelier’s formula makes sense only if S(t) can be negative, which is 
impossible for the price of stock in a limited-liability corporation. Powers of s 
intermediate between 0 and 2 (as in the Constant Elasticity of Variance model of Cox 
and Ross 1976) also have this defect, but there are many choices for g(s) that avoid 
it; it is sufficient that g(s) go to 0 fast enough as s goes to 0 ([107], p. 294). 
In general, the game in which Investor can buy a derivative that pays the divi- 
dend (9.29) has as its stochastic counterpart the diffusion model 
W t )  = P(S(t),t)dt + d m d w ( t ) .  
(9.30) 
As we explain in an appendix (p. 231), the stochastic theory of risk-neutral valu- 
ation, which generalizes the Black-Scholes theory, tells us that if S(t) follows the 
diffusion model (9.30), then all well-behaved derivatives are exactly priced, and the 
dividend (9.29), will total to exactly T - t over the period from t to T. So this diffu- 
sion model makes it redundant to trade in a derivative that pays the dividend (9.29), 

226 
CHAPTER 9: GAME-THEORETIC PROBABILITY IN FINANCE 
just as geometric Brownian motion makes it redundant to trade in a derivative that 
pays the dividend (dS(t))’/S’(t). 
Since the Taylor’s series on which our reasoning is based is only an approximation, 
the local proportionality of the dividend to (dS(t))2 
does not need to be exact, and this 
suggests another possibility: (dS( t))2 might be smoothed to limit the dependence 
on extreme values and the susceptibility of the market to manipulation by major 
investors. But as a practical matter, it seems more promising to take the more 
conventional approach we have already discussed: we ask the market to price a 
derivative that pays a strictly convex function of S(T) at T ,  and we calculate from 
its price an implied price for our theoretical derivative D ($12.2). 
9.4 INFORMATIONAL EFFICIENCY 
The hypothesis that capital markets are informationally efficient emerged from efforts 
in the 1960s to give an economic explanation for the apparent randomness of prices 
in markets for stocks and markets for commodity futures, and it is formulated in the 
context of a stochastic assumption. According to this stochastic assumption, each 
price p in such a market is based on a probability distribution for the ultimate value z 
of the contract being priced-the 
discounted value of the future stream of dividends 
in the case of a stock, the value at delivery of the commodity in the case of a futures 
contract. Neglecting interest, transactions costs, and so on, the assumption is that p is 
the expected value of z conditional on certain current information. What information? 
Different answers are possible. The hypothesis of informational efficiency says that 
p is the expected value of 2 conditional on all information available to investors, 
including all the information in past prices, so that an investor cannot expect, on 
average, to profit from buying at current prices and selling later. 
Our rejection of stochasticity obviously undercuts this whole discussion. If there 
is no probability distribution for 2, then there is no point to arguing about how 
the market uses such a probability distribution. But as we pointed out in $1.1, our 
game-theoretic framework permits a much simpler interpretation of the hypothesis 
of informational efficiency: it is simply the hypothesis of the impossibility of a 
gambling strategy in a game where the imaginary player Skeptic is allowed to buy 
and sell securities at current prices. It says that Skeptic does not, in this setting, have 
a strategy that will make him very rich without risk of bankruptcy. No assumptions 
of stochasticity are made, and yet there are many ways of testing the hypothesis: any 
strategy that does not risk bankruptcy can be the basis for such a test. As we will 
see in Chapter 15, under certain conditions there are strategies that allow Skeptic to 
become rich without risk of bankruptcy if returns do not average to zero in the long- 
run. So tests of the stochastic hypothesis of market efficiency that check whether 
returns do approximately average to zero can be made into tests of our hypothesis of 
market efficiency. 
In addition to allowing us to test market efficiency, this understanding of the 
market efficiency also opens the possibility of using game-theoretic probability in 
various contexts where established finance theory uses stochastic ideas. We explore 

9.4: INFORMATIONAL EFFICIENCY 
227 
a couple of examples in Chapter 15: the trade-off between risk and return, and the 
measurement of value at risk. 
Why Should Prices Be Stochastic? 
Why should prices in markets for stocks and commodity futures be stochastic? In 
1972, Paul Samuelson summarized the answer that comes to an economist’s mind as 
follows ([264], p. 17): 
Expected future price must be closely equal to present price, or else 
present price will be different from what it is. If there were a bargain, 
which all could recognize, that fact would be “discounted” in advance and 
acted upon, thereby raising or lowering present price until the expected 
discrepancy with the future price were sensibly zero. It is true that people 
in the marketplace differ in their guesses about the future: and that is a 
principal reason why there are transactions in which one man is buying 
and another is selling. But at all times there is said to be as many bulls as 
bears, and in some versions there is held to be a wisdom in the resultant of 
the mob that transcends any of its members and perhaps transcends that 
of any outside jury of scientific observers. The opinions of those who 
make up the whole market are not given equal weights: those who are 
richer, more confident, perhaps more volatile, command greater voting 
power; but since better-informed, more-perceptive speculators tend to be 
more successful, and since the unsuccessful tend both to lose their wealth 
and voting potential and also to lose their interest and participation, the 
verdict of the marketplace as recorded in the record of auction prices is 
alleged to be as accurate ex ante and ex post as one can hope for and 
may perhaps be regarded as more accurate and trustworthy than would 
be the opinions formed by governmental planning agencies. 
Samuelson did not represent this argument as his own opinion, and his tone suggests 
some misgivings. But he did represent it as “a faithful reproduction of similar ideas 
to be found repeatedly in the literature of economics and of practical finance”. He 
cited a collection of articles edited by Cootner [56], which included a translation of 
Louis Bachelier’s dissertation. 
As Samuelson had observed in 1965, the assumption that the current price of a 
stock (or a futures contract) is the expected value of its price at some future time has a 
simple consequence: the successive prices of the stock will form a martingale [263]. 
This means that if pt is the price of a stock at time t, then 
or 
IEt(Pt+l - Pt) = 0, 
(9.31) 
where IEt represents the expected value conditional on information available at time 
t. Before Samuelson’s observation, economists had been investigating the hypoth- 

228 
CHAPTER 9: GAME- THEORETIC PROBABILITY IN NNANCE 
esis that prices follow a random walk-that 
is, have statistically independent in- 
crements [ 1161. The increments of an arbitrary martingale have only the weaker 
property (9.31); each has expected value zero just before it is determined. Subse- 
quent to Samuelson’s calling attention to the martingale property, economists shifted 
from testing for a random walk to testing (9.3 l), and they began saying that they are 
testing market efficiency. 
Tests of the stochastic efficiency of markets 
have spawned an immense literature, chron- 
icled in successive reviews by Eugene Fama 
[117, 118, 1191. Many authors contend that 
the empirical results in this literature confirm 
that financial markets generally are efficient; 
as Fama put it in 1998, “the expected value of 
abnormal returns is zero, but chance generates 
deviations from zero (anomalies) in both direc- 
tions” ([119], p. 284). Other authors see de- 
viations from efficiency everywhere [288] and 
conclude that stock-market prices are the result 
of “indifferent thinking by millions of people” 
([286], p. 203) that can hardly identify correct 
probabilities for what will happen in the future. 
Yet other authors have suggested that the finan- 
cial markets can be considered efficient even 
Eugene Fama (born 1939) in 1999. His 
if they do not conform exactly to a stochastic 
work on efficient markets has helped 
model or eliminate entirely the possibility for 
make him the most frequently cited pro- 
abnormal returns [48, 140, 207,2081. 
fessor of finance. 
The diversity of interpretation of the empir- 
ical results can be explained in part by the fact, acknowledged by everyone in the 
debate, that the efficient-markets hypothesis cannot really be tested by itself. By 
itself, it says only that prices are expected values with respect to some stochastic 
model. An effective test requires that we specify the stochastic model, substantially 
if not completely, and then we will be testing not merely the efficient-markets hy- 
pothesis but also specific model. This is the joint hypothesis problem ([48], p. 24; 
[ 1181, pp. 1575-1576). 
Game-Theoretic Efficiency 
Our game-theoretic efficient-market hypothesis is in the spirit of Samuelson’s ar- 
gument but draws a weaker conclusion. We do not suppose that there is some 
mysteriously correct probability distribution for future prices, and therefore we reject 
the words with which Samuelson’s argument begins: “expected future price”. But 
we accept the notion that an efficient market is one in which bargains have already 
been discounted in advance and acted upon. We hypothesize that our Skeptic cannot 
become rich without risking bankruptcy because any bargains providing Skeptic se- 
curity against large loss would have already been snapped up, so much so that prices 

9.5: APPENDIX: TWEAKING THE BLACK-SCHOLES MODEL 
229 
would have adjusted to eliminate them. By the principles of 51.3 and 58.3, this is 
enough to determine game-theoretic upper and lower probabilities for other events in 
the market being considered. 
The purely game-theoretic approach obviously avoids the joint-hypothesis prob- 
lem. We do not assume a stochastic model, and so we do not need to specify one in 
order to test our efficient-market hypothesis. We must specify, however, just what 
market we are talking about. Are we asserting that Skeptic cannot get rich without 
risking bankruptcy by trading in stocks on the New York Stock Exchange? By trading 
in options on the Chicago Board Options Exchange? Or by trading just in stocks 
in the S&P 500 index? These are all well-defined markets, and the hypothesis that 
Skeptic cannot get rich is a different hypothesis for each of one of them, requiring 
different tests and perhaps leading to different practical conclusions. Ours is an 
efficient-market hypothesis, not an efficient-markets hypothesis. 
We must also specify a unit of measurement for Skeptic's gains-a 
nurne'raire. 
We may hypothesize that Skeptic cannot get rich relative to the total value of the 
market (if this is well-defined for the particular market we are considering). Or we 
may hypothesize that he cannot get rich in terms of some monetary unit, such as the 
dollar or the yen. Or we may hypothesize that he cannot get rich relative to the value 
of a risk-free bond. And so on. These are all different hypotheses, subject to different 
tests and possibly having different implications concerning what we should expect in 
the future. 
9.5 APPENDIX: TWEAKING THE BLACK-SCHOLES MODEL 
In practice, the Black-Scholes formula is only a starting point for pricing an option. 
There are a host of practical problems and many ways of adjusting the formula [27]. 
The first problem is that of estimating the volatility 0 of the price process S(t). 
We can use the historic volatility-the 
standard deviation of dS(t) in the historical 
record. Or, if an option on S is traded, we can find the implied volatility-the 
value 
of 0 that makes the Black-Scholes formula agree with the market price for the option. 
Unfortunately, these methods do not always give well-defined answers. The historic 
volatility may vary from one period to another, and the implied volatility may vary 
with the type of option, the strike price, and the maturity date. 
Writers of derivatives keep an eye on apparent changes in the volatility of S(t) 
and often combine different financial instruments to hedge against such changes. The 
derivation of the Black-Scholes formula tells us how to hedge against changes in the 
share price itself; we hold d(t) shares of S at time t, where b(t) is the derivative at 
time t of the Black-Scholes price with respect to the share price. To hedge against 
changes in n2, one combines different securities so that the the derivative of the total 
price with respect to o2 is zero. This is called vega-hedging. Though it is widely 
used, it does not have a theoretical justification like that for delta-hedging. 
Econometricians have developed elaborations of the Black-Scholes model that 
provide a theoretical basis for variations in historic and implied volatility. These 
models can allow changes in volatility to depend on time, on current and previous 

230 
CHAPTER 9: GAME-THEORETIC PROBABILITY IN FINANCE 
values of the security’s price, and even on current and previous values of the volatility 
itself, while still permitting hedging by strategies that trade only in the security. 
Among econometricians, the most popular of these models is probably the generalized 
autoregressive conditional heteroskedasticity (GARCH) model. It is sufficiently 
developed to use in practice ([48], Chapter 12), but it has not been widely perceived 
as useful by practitioners [l]. 
One reason for the lack of interest in GARCH models among practitioners is the 
very fact that they recommend hedging by trading only in the underlying security. 
When there is enough trading in a security’s derivatives to justify attention to variation 
in implied volatility, practitioners tend to have more confidence in the market prices 
of these traded derivatives than in any theory derived from them, and so they want 
to include the traded derivatives in their hedging strategy. This is done in practice. 
Typically, the practitioner inverts the Black-Scholes equation using prices for a single 
type of option, say a call option, obtaining the implied volatility as a function of the 
strike price and maturity. This volatility surface is usually unstable in time and has 
no more theoretical justification than vega-hedging. But it can be used to price more 
exotic and thinly traded options in a way that is consistent with the market pricing of 
the call. One then tries to replicate the exotic option by trading in the call, so as to 
reduce the risk taken in writing the exotic to the more familiar risk in the call ([154], 
$18.8; [351], Chapter 22). 
Theoretically, hedging using traded derivatives can be justified by models in 
which the volatility is influenced by an independent source of randomness. This is 
stochastic volatility in the full sense of the term. We might assume, for example, that 
the volatility CT in (9.4) follows a diffusion process independent of the Wiener process 
W(t) in that formula. Stochastic volatility models are often able to predict future 
option prices better than the Black-Scholes model, but their use by practitioners has 
been limited by their complexity ([ 11; [35 11, Chapter 23). 
A preference for relying on the market, carried to its logical conclusion, should 
result in market pricing for derivatives such as our variance derivative D or the more 
conventional R(S(T)), 
where R is a strictly convex function, that we propose in 
512.2. But this may be slow in coming; options are bought and sold in organized 
exchanges because there is a demand for them, not because they are interesting to pro- 
fessionals. In the early 1990s, the Chicago Board Options Exchange commissioned 
Robert E. Whaley of Duke University to design a market volatility index to serve 
as the underlying for volatility options that it was contemplating introducing. The 
resulting CBOE Market Volatility Index (ticker symbol “VIX’) is based on implied 
volatilities of S&P 100 index options [339,340] and has been disseminated an a real- 
time basis since 1993. Although the CBOE has yet to introduce exchange-traded 
volatility derivatives, there is now a substantial over-the-counter market in equity 
volatility and variance swaps, which pay out observed volatility or variance during 
the period up to maturity [52, 2251. 

9.6: APPENDIX: ON THE STOCHASTIC THEORY 
231 
9.6 APPENDIX: ON THE STOCHASTIC THEORY 
In this appendix, we pro- 
vide some additional informa- 
tion on stochastic option pric- 
ing and stochastic differential 
equations, aimed at readers new 
to these topics who would like 
a fuller picture at the heuris- 
tic level of this chapter. First, 
we fill some holes in our dis- 
cussion of stochastic differential 
equations: we explain why (9.4) 
represents a geometric Brown- 
ian motion, and we state Ite’s 
Kiyosi It6 (born 1915). at his desk in the national statis- 
lemma. Then we discuss what tics bureau of Japan at the age of 27. 
appears from the measure-theoretic point of view to be the general theory of option 
pricing: the theory of risk-neutral valuation. 
The Stochastic Differential Equation for Geometric Brownian Motion 
We used the stochastic differential equation 
(9.32) 
as the starting point for our study of geometric Brownian motion in 59.1, instead of 
the differential equation 
dlnS(t) = podt + aodW(t), 
(9.33) 
which also expresses the assumption that the logarithm of S(t) is a Brownian motion. 
To see that (9.32) implies (9.33), we may use Taylor’s expansion of the logarithm to 
obtain 
dInS(t) = In(S(t) + dS(t)) - InS(t) =In 
(9.34) 
If (9.32) holds, then by (9.13) and (9.14), (dS(t)/S(t))2 
differs from a2dt by at 
most a random term of order dt that makes no difference in the interpretation of the 
stochastic differential equation. So (9.34) becomes 
1 
dlnS(t) = pdt + adW(t) - -a2dt. 
(9.35) 
2 

232 
CHAPTER 9: GAME-THEORETIC PROBABlLlTY IN FINANCE 
This makes clear how p and u are related to the coefficients po and cro in (9.33): 
u = uo and p = /LO + u:/2. 
Some readers may be puzzled that approximations can produce the equals sign 
in (9.35). In general, however, equals signs in stochastic differential equations are 
meaningful only in the limit as dt is made smaller. For this reason, the equations are 
often translated into corresponding stochastic integral equations, in which equality 
has its usual measure-theoretic meaning: equal except on a set of measure zero. 
Higher-order terms are irrelevant to the integrals. 
In our game-theoretic framework, we do not necessarily have a probability mea- 
sure, and hence equations that relate increments such as dt and dS(t) must be given 
a pathwise meaning. In the discrete-time case (Chapter lo), this meaning i s  familiar: 
the dt and the other increments are real numbers. We handle the continuous-time 
case (Chapter 11) by supposing that they are infinitesimal. 
Statement of lt6's Lemma 
In terms of stochastic differential equations, ItB's lemma says that if 
dS(t) = pdt + U d W ( t )  
and f ( s ,  t )  is a well-behaved function, then 
at 
) 
1 
a2f 
df(S(t), t )  = p-(S(t),t) + -."(S(t),t) 
+ --(S(t)>t) dt 
+ .-(S(t), 
t)dW(t). 
2 
as2 
8.f 
( :: 
dS 
(The drift p and volatility u may depend on S(t) and t, and perhaps even on other 
information available at time t.) The equivalent statement in terms of stochastic 
integral equations is that if 
s(t) = S(0) + i ' p d t  + 6' 
gdW, 
then 
where the stochastic integral (the integral with respect to dW) is understood in the 
sense by It6 (see It8 1944 or, e.g., (261, $5.5). 
The equivalence of (9.32) and (9.33) follows directly from It8's lemma, and the 
derivation of the stochastic Black-Scholes formula is simplified by it. We prove a 
game-theoretic variant of the lemma in 3 14.2. 
Risk-Neutral Valuation 
Although it is central to option pricing in practice, the Black-Scholes model appears 
from the measure-theoretic point of view as merely one of many stochastic models 

9.6: APPENDIX: ON THE STOCHASTIC THEORY 
233 
that can be used to help price options, all of which fall under a general theory of 
continuous-time hedging, or risk-neutral valuation. (The name refers to the game- 
theoretic character of the price; although it does depend on a stochastic assumption, 
it does not depend on any assumption about anyone’s attitude towards risk.) 
Because the theory of risk-neutral valuation is part of the theory of continuous- 
time stochastic processes, a rigorous mathematical understanding of its main results 
would require a detour through several pages of definitions. (Most significantly, 
the definition of the capital process resulting from a strategy involves stochastic 
integration.) But the results are quite simple and can be stated clearly as soon as 
it is stipulated that the measure-theoretic concepts of process, strategy, martingale, 
etc., which we have studied in discrete time, can be extended to continuous time. 
We start with a process S(t), which represents as usual the price of a security S. 
Technically, this is a collection of random variables { S(t)},>o in a probability space 
with a probability measure p. For simplicity, we consider only t from 0 to T .  We say 
that the price process S(t) is arbitruge-free if there is no well-behaved strategy for 
trading in S, starting with capital zero, whose capital at time T is nonnegative with 
probability one and positive with positive probability (we say “well-behaved” to rule 
out wild strategies, such as those that make unbounded bets). Then we can state the 
main results of the theory as follows: 
Result 1 The price process S(t) is arbitrage-free if and only if there exists at least one 
probability measure equivalent to 
under which S is a martingale [75, 1131. 
(Recall that two probability measures on the same space are equivalent if they 
give positive probabilities to the same events.) 
Result 2 If there is only one such measure, say Q, 
then every well-behaved European 
option is priced, and its price is its expected value under Q [184, 1471. 
Although the generality of these results makes them mathematically attractive, 
their main use in practice seems to be in the well-known examples we discuss in 
this book-binomial 
trees (discussed in 5 1 S), diffusion processes (discussed in this 
chapter), and Poisson jump processes (discussed in 5 12.3). 
The content of the general risk-neutral results is most easily understood in a 
completely discrete and finite setting, where we are concerned only with a sequence 
of prices, say SO,. . . , S N ,  for S, and there are always only a finite number of 
possibilities for the change Sn+l - S,. 
This puts us into a finite tree, as in the 
examples we considered in 1 .S. We may assume that p gives the positive probability 
to all branches. In this case, the requirement that the price process be arbitrage-free 
is the same as the requirement that the game be coherent: in each situation t, the 
possible changes dS are never all positive or all negative. This is necessary and 
sufficient for the existence of positive probabilities for the branches from t that make 
the current price of S the expected value of its next price. This defines an equivalent 
martingale measure, which is unique only if the branching is always binary. This is 
also the condition, as we saw in 5 1.5, for options to be exactly priced, and their price 
is then their expected value under the equivalent martingale measure. Since a unique 
equivalent martingale measure exists in a finite tree only if it is binary, we would 

234 
CHAPTER 9: GAME-THEORETIC PROBABILITY IN FINANCE 
expect to obtain a unique equivalent martingale measure in continuous-time model 
only if it can be conveniently approximated by a binary tree. So it is not surprising 
that continuous-time risk-neutral pricing has been used mainly for the Gaussian and 
Poisson cases. 
In the case of the diffusion model, the change from the true probability measure 
to the equivalent martingale measure Q amounts to dropping the term in the stochastic 
differential equation that represents the drift, after which we can find option prices 
as expected values under Q. We can easily reorganize the derivation in a way 
that makes this clear-and 
also applies to any diffusion model, not just geometric 
Brownian motion. We begin with the general stochastic differential equation for the 
diffusion model 
dS(t) = p(S(t),t)dt + .(S(t),t)dW(t). 
As usual, we write u(s, 
t )  for the price of the derivative at time t when S(t) = s. 
Our problem is to find the function u starting with knowledge of its values when 
t = T .  The problem will be solved by backwards induction if we can find the function 
U ( s ,  t )  of s for fixed t from knowledge of the function u ( s ,  t + dt). Suppose we do 
know u ( s ,  t + dt) as a function of s, and designate it by U :  
- 
U ( s )  := U ( S ,  t + dt). 
Write S for the price of the security at time t and S + dS for the price at time t + dt. 
Investor can complete his hedging of the derivative if his capital at time t + dt is 
U ( S  + dS). But 
1 
U ( S  + dS) M U(S ) + U’(S)dS + ,U”(S)(dS)’. 
(9.36) 
(Here we use z to represent equality up to o(dt). As usual, we ignore terms of 
order o(dt), because their cumulative effect, when summed over the O(l/dt) time 
increments, is negligible.) He can approximately achieve the capital (9.36) at time 
t + dt if at time t he has 
1 
U ( S )  + Zu”(S)u2dt 
(9.37) 
(we omit the arguments t and S of . 
and p), because: 
he can replicate the term U‘(S)dS by buying U’(S) shares of S, and 
as we showed in $9.2 using the law of large numbers and the approximation 
(dS)2 M o’(dW(t))’, the difference between the third term of (9.36) and the 
second term of (9.37), 
1 
1 
2 
2 
- U”( S )  (dS)’ - - UI’( S).2dt, 
will eventually cancel out when we sum over all t. 
so 
1 
- 
U(S, t )  M U(S) Jr ,UJJ(S).2Crt. 

9.6: APPENDIX: ON THE STOCHASTIC THEORY 
235 
This is just a variant of the Black-Scholes equation, (9.19), generalized to the case 
where (T may depend on S and t, but it is written in a form that shows that u( S, t) is 
the expected value at time t of U(S + d S )  under the assumption that dS is distributed 
as adW(t). To find the price of an option, calculate the expected value ignoring the 
drift. 
The generalization to the general diffusion model carries over, in large measure, 
to our game-theoretic approach. We explained at the end of $9.3 how it generalizes 
to the case where p and g may depend on S(t). We cannot allow direct dependence 
on the time t, but we can allow dependence on the current value D(t) of the new 
security 2). Then instead of (9.37) we obtain 
1 
U ( S )  + 2U"(S)g(S, D)dD, 
S and D being the current prices of S and D; no law of large numbers is needed. 
To conclude this appendix, we will briefly describe an alternative approach to 
risk-neutral valuation based on Girsanov's theorem ([26], p. 159). We have seen that, 
when valuing options, we should ignore the drift of S. The idea of the approach 
based on Girsanov's theorem is to change the probability distribution governing the 
generation of dS(t) so that its expectation becomes zero; then the price of the option 
will be given by the expected value with respect to the modified distribution. 
Let us fix some t and suppose S = S(t) is known. For simplicity let us assume 
that d W ( t )  can only take a finite range of values, d w k ,  Ic = 1, . . . , K ;  the probability 
of value dWk will be denoted pk. The values of the increment d S ( t )  corresponding 
to different possible values dWk are 
(as before, we drop the arguments of p and a). The new probabilities will have the 
form 
$ik = Qpke-odwk 
for some constants a and /3. This is a natural form, analogous to (5.9) used in 
the proof of the law of the iterated logarithm. The constant of proportionality Q 
is determined by the requirement that the fik sum to 1, and /3 will be chosen later 
so that the average drift EkfikdSk is zero. If we again write U for the function 
s r-$ u(s, t + dt), the target function for time t + dt, we get 
which coincides with (9.37). (The final approximation relies on the fact that the 
average of the (dWk)2 with respect to$ik coincides, to our usual accuracy o(dt), with 
their average with respect to pk.) 

236 
CHAPTER9: GAME-THEORETIC PROBABILITY IN FlNANCE 
To have 
j j k  = 1, we need CY = e-(P2/2)dt: 
Let us see now that we can indeed choose ,Ll so that the mean drift becomes zero: 
therefore, it suffices to put p = p / u  (this ratio is sometimes called the market price 
of risk). 

10 
Games for Pricing Options 
in Discrete Time 
In the preceding chapter, we explained 
informally how an investor can hedge 
European options on a security S if the 
market prices both S and a dividend- 
paying derivative security D. The argu- 
ment was entirely game-theoretic. We 
required that the prices S(t) and D(t) 
of S and 2) not fluctuate too wildly, but 
we made no stochastic assumptions. 
This chapter makes the argument 
mathematically precise in a realistic 
discrete-time setting. We prove that 
European options can be approximately 
hedged in discrete time at a price given 
by the Black-Scholes formula, with 
the market price D(t) in the 
Of 
(5" - t)02, provided that S(t) is al- 
ways positive, D pays (dS(t)/S(t))2 
as a dividend, and both S(t) and D(t) obey certain constraints on their p-variations. 
For historical and mathematical reasons, we preface this Black-Scholes result 
with an analogous result for Bachelier's formula. In the Bachelier case, S(t) is not 
required to remain positive, and 2) pays the simpler dividend (d5'(t))2. Although a 
model that allows S(t) to be negative is of little substantive interest, the mathematical 
simplicity of the Bachelier model allows us to see clearly the close relation between 
Myron Scholes (born 19411, at a press confer- 
ence at Stanford in October 1997, after the an- 
nouncement that he and Robert C. Merton had 
been awarded the 1997 Nobel Prize for eco- 
nomics. 
237 
Probability and Finance: It’s Only a Game! Glenn Shafer, Vladimir Vovk 
Copyright 0 2001 John Wiley & Sons, Inc. 
ISBN: 0-471-40226-5 

238 
CHAPTER 10: GAMES FOR PRICING OPTIONS IN DISCRETE TIME 
option pricing and the central limit theorem. Bachelier’s formula is another central 
limit theorem. 
We derive Bachelier’s formula under two different sets of conditions. In the first 
derivation, in $10.1, we use conditions similar to those that we studied in Part I. These 
conditions are not realistic for finance, but they are similar to the martingale argument 
we used to prove De Moivre’s theorem in Chapter 6. In the second derivation, in 
$ 10.2, we use conditions on the p-variations of S and D. 
We also use two different sets of conditions to derive the Black-Scholes formula. 
In 5 10.3, we use nearly the same conditions as we use for Bachelier’s formula in $ 10.2. 
Then, in $ 10.5, we change the condition on S(t) slightly; instead of constraining the 
p-variation of its absolute fluctuations, we constrain the p-variation of its relative 
(percentage) fluctuations. This approach gives simpler bounds. 
Our discrete-time results are messy, involving many error terms and arbitrary 
decisions about how approximations will be made. In the next chapter, we will clear 
away the mess by passing to a limit in which the intervals between successive hedges 
are infinitesimal, thus obtaining elegant continuous-time counterparts for the main 
results of this chapter (see Table 10.1). But the details cleared away by continuous- 
time models must be brought back in practice. In finance, certainly, the possibility 
of making discrete-time calculations is fundamental. Traders usually balance their 
portfolios daily, and the gap between infinitely often and daily is so great that the 
meaningfulness of continuous-time results is in doubt unless we can demonstrate that 
they can be approximated in realistically coarse discrete time. 
In the latter part of this chapter, in 510.4 and $10.6, we look at some stock-price 
data to see whether the error bounds calculated by our discrete methods are tight 
enough to be useful. Here we encounter two important difficulties: 
Because our dividend-paying derivative ’D is not now traded for any S, we 
must speculate about the p-variations for 2) that will be observed if it is traded. 
In $ 10.4, we use an assumption that is surely overly optimistic: we suppose 
that the p-variations are the same as would be obtained if the market knew ’D’s 
future dividend stream (the fluctuations in S(t)) in advance. In $ 10.6, we use 
also prices for ’D implied by market prices for calls and puts. 
Table 70.7 
continuous-time results of the next chapter. 
The correspondence between the discrete-time results of this chapter and the 
Discrete Time 
Continuous Time 
Bachelier 
Proposition 10.2 
Theorem 1 1.1 
absolute fluctuations in S(t) 
p. 244 
p. 278 
Black-Scholes 
Proposition 10.3 
Theorem 11.2 
absolute fluctuations in S ( t )  
p. 249 
p. 280 
Black-Scholes 
Proposition 10.4 
Theorem 11.3 
relative fluctuations in S ( t )  
p. 260 
p. 282 

10.1: BACHELIER’S CENTRAL LlMlT THEOREM 
239 
0 In general, a discrete-time calculation is likely to give useful results only if it 
is tailored to one’s particular circumstances-more 
tailored than any general 
theorem, even a messy discrete-time theorem, can possibly be. In the case of 
option pricing, the calculation needs to be tailored not only to the particular 
stock (different conditions on the fluctuations may be reasonable for different 
stocks) but also to the particular option and even its practical purpose, which 
may affect how exactly it needs to be replicated. Because we are discussing 
option pricing in general, not just a particular option with a particular purpose, 
we must settle for conclusions that involve relatively arbitrary assumptions 
about the smoothness of the option’s payoff function. 
In spite of these difficulties, it is clear from our calculations that the hedging recom- 
mended by our theory can be practical. We obtain promising results in 5 10.4, where 
we apply 5 10.3’s method using our very optimistic assumption about D’s p-variation. 
We obtain even more promising results in $10.6, where we apply $10.5’~ 
method to 
the same data and also to data for which we have prices for 23 implied by market 
prices for calls and puts. 
These results compare very favorably with existing work on discrete-time Black- 
Scholes hedging, which has remained very asymptotic and therefore unconvincing. 
In fact, the results are so promising that we feel serious consideration should be given 
to implementing trading in our dividend-paying derivative or some more conventional 
derivative that would simulate it; see the discussion in $12.2. 
10.1 BACHELIER’S CENTRAL LIMIT THEOREM 
In this section, we derive a new central limit theorem, which we call Bachelier’s 
central limit theorem, because it gives Bachelier’s formula for option prices. 
Bachelier’s central limit theorem differs from the central limit theorems we studied 
in Part I in the way it handles the variances of Reality’s moves. In De Moivre’s and 
Lindeberg’s central limit theorems, a variance for Reality’s move X, is known before 
Skeptic decides how many tickets to buy. In Bachelier’s central limit theorem, Skeptic 
has less information before he decides how many tickets to buy: he has only a total 
variance for all of Reality’s remaining moves, x,, %,+I, . . . , XN. 
As a reminder of how a Lindeberg protocol handles variance, we reproduce here, 
in simplified form, one of the Lindeberg protocols we discussed in $7.3. 
A LINDEBERG PROTOCOL 
(Example 3 from Chapter 7, p. 161) 
Parameters: N ,  KO > 0, C 2 1, o2 > 0 
Players: World (Forecaster + Reality), Skeptic 
Protocol: 
FOR n = 1,. . . , N :  
Forecaster announces v, E R. 
Skeptic announces MrL E R and V, E R. 
Reality announces X, E Iw. 
K ,  := K,-1 + M,x, + V,(X; - vn). 

240 
CHAPTER 10: GAMES FOR PRlClNG OPTIONS IN DISCRETE TIME 
Constraints on World: Forecaster must make Cy=l vi < o2 for n = 1, . . . , N - 1, 
c;=, 
21, = 02, and Iv,J 5 CN-l for all n. Reality must make lxnl 5 CN-1/2 
for all n. 
In this Lindeberg protocol, Skeptic is told the total variance o2 at the beginning 
of the game. At the beginning of the nth round, he already knows v1, . . . , vn-l, and 
hence he knows the total variance of Reality's remaining moves, c:, vi. Before he 
makes his moves M, and V,, he is also told v,, and so he knows how the remaining 
total variance C:, 
vi is split between the current round and later rounds. 
The protocol we now consider differs from this Lindeberg protocol in only one 
particular: Forecaster does not announce the variance v, until after Skeptic and 
Reality move: 
PROTOCOL FOR BACHELIER'S 
CENTRAL LIMIT THEOREM 
Parameters: N ,  KO > 0, C 2 1,o' > 0 
Players: World (Forecaster + Reality), Skeptic 
Protocol: 
F O R n =  l , . . . , N :  
Skeptic announces M, E R and Vn E R. 
Reality announces x, E R. 
Forecaster announces v, E R 
Ic, := ICn-1 + M n ~ n  + Vn(Xi - Vn). 
Constraints on World: Forecaster must make C:='=, 
v n  = 02, cy=l 
vi < o2 for 
n < N ,  and Ivnl 5 CN-l for all n. Reality must make Ix,I 5 CN-l12 for all n. 
This is a symmetric probability protocol, and it is obviously coherent in the initial 
situation: Forecaster and Reality can ensure that Skeptic never makes money by 
choosing v, := 1/N and 
N-ll2 
if M, < 0 
{ -N-l12 
if M, 2 0. 
x, := 
As it turns out, we can still prove the central limit theorem for this protocol: for any 
well-behaved function U and large N ,  U ( z )  No,,. (dz) is an approximate price for 
it is convenient to write the protocol in the terms of the cumulative sums of World's 
moves: 
n 
SO := 0 
and 
S, := 
xi for n = 1,. . . , N 
i=l 
and 
N 
D, := 
vi forn = 0,. . . , N - 1 
and 
DN = 0. 
i=n+l 
The moves x, and v, can then be represented as increments: 
AS, := S, - S,-1 = x, 
and 
AD, := D, - D,-1 = -vn. 

10.7: BACHELIER’S CENTRAL LIMIT THEOREM 
241 
The quantity DO is the same as the total variance, c2, and instead of calling it a 
parameter, we may have Forecaster announce it at the beginning of the game. This 
puts the protocol in the following form: 
BACHELIER’S 
PROTOCOL IN TERMS 
OF D AND s 
Parameters: N ,  ICO > 0, C 2 1 
Players: World (Forecaster + Reality), Skeptic 
Protocol: 
Forecaster announces DO > 0. 
F O R n =  1, . . . ,  N :  
Skeptic announces M, E R and V,, E R 
Reality announces S, E R. 
Forecaster announces D, 2 0. 
IC, := Kn-l + MnASn + Vn((ASn)2 + AD,). 
Additional Constraints on World: Forecaster must make D, > 0 for n < N ,  
DN = 0, and lAD,I 1. CN-l for all n. Reality must make IAS,l 5 CN-ll2 for 
all n. 
This protocol is coherent both in the initial situation, before Forecaster announces 
DO, and in the situation just after Forecaster announces DO, where it reduces to the 
version in which u2 is a parameter. The central limit theorem for this protocol is a 
statement about prices in the situation just after Forecaster announces DO: it says that 
U ( z )  No,o0 
(dz) is then an approximate price for U(SN). Lindeberg’s theorem 
does not include this particular central limit theorem, and our proof of Lindeberg’s 
theorem cannot be adapted to cover it, because it was essential to that proof that 
Skeptic knew Dn+l when choosing his move on round n + 1. We used this when 
we moved the center of Taylor’s expansion of u forward from (S,, D,) (its position 
in Equation (6.21), p. 132, in our proof of De Moivre’s theorem) to (S,, D,+I) 
(Equation (7.16), p. 156). In our new protocol, where Skeptic does not know Dn+l 
when making his moves MTL+l and Vn+l, we must return to the expansion around 
(S,, 
D,) that we used for De Moivre’s theorem. 
Before proving the central limit theorem for Bachelier’s protocol, let us restate 
it to emphasize its financial interpretation, where S, and D, are the prices of the 
securities S and D, 
respectively, and Skeptic and World are renamed Investor and 
Market, respectively. Market determines the price of both securities. Instead of 
assuming that SO = 0, we now permit Market the same freedom in setting SO as he 
has in setting DO. 
BACHELIER’S 
PROTOCOL WITH MARKET TERMINOLOGY 
Parameters: N ,  ZO > 0, C 2 1 
Players: Market, Investor 
Protocol: 
Market announces SO E R and DO > 0. 
FORn = 1,. . . , N :  
Investor announces M, E R and V, E R. 

242 
CHAPTER 70: GAMES FOR PRICING OPTlONS IN DISCRETE TIME 
Market announces S, E R and D, 2 0. 
Z,, := Z,-l + M,AS, + V,((ASn)2 + AD,). 
(10.1) 
Additional Constraints on Market: Market must make lAD,I 
<_ CN-l and 
lAS,I 5 CN-‘I2 for n = 1,. . . N and must ensure that DN = 0 and D, > 0 for 
n < N .  
Now M,, 
and V, are the number of shares of S and D, respectively, that Investor 
holds during the nth period. According to (10. I), his net gain is 
AT,, = M,AS, + V,AD, + K,(AS,)2. 
(10.2) 
The first two terms of this expression are his capital gains from holding the Mn shares 
of S and the V, shares of V. The third term amounts to a dividend of (.AS,)’ for 
each share of V that he holds. After the end of the N periods, the security D will 
pay no more dividends and is worthless: DN = 0. The other constraints limit how 
wildly the prices of the two securities can fluctuate in a single period. 
The price D, is a signal from Market to Investor concerning how much the price 
of S will fluctuate during the remaining rounds of play. There is no requirement, 
however, that D, should decrease monotonically from its initial value of‘ Do to its 
final value of 0. Market may change his mind about the likely remaining fluctuation, 
either because of his own and Investor’s moves so far or because of information 
coming from outside the game. 
Now we state and prove Bachelier’s central limit theorem . 
Proposition 10.1 Suppose U is a bounded continuous function. Then in Bachelier’s 
protocol with market terminology, the upper and lower prices of U ( S N )  in the 
situation where So and Do have ,just been announced are both arbitrarily close to 
U ( z )  N S ~ , D ~ ( & )  
for N suficiently large. 
Proof By the symmetry of the protocol, it suffices to prove that the difference between the 
upper price of U ( S N )  and s U ( z )   NO,^, (dz) goes to zero as N increases without bound. 
First assume that U is a smooth function constant outside a finite interval, so that its third 
and fourth derivatives are bounded: for some constant c and all s E R, JU(3)(s)l 5 c and 
IU(4)(s)/ 5 c. AS usual, we set u ( s ,  D )  := s U ( z )  ,V,,D(dz) for s E R and D 2 0. 
As in our proof of De Moivre’s theorem in Chapter 6, we construct a strategy that makes 
Investor’s capital at the end of round n approximately equal to u(Snl 
Dn) when he starts at 
U(S0, DO). From (6.21) (p. 132) we see that Investor should set 
- 
(10.3) 
In this case, the first two terms of (6.21) give the increment of Investor’s capital (cf. (10.2)), 
and we can rewrite (6.21) as 

70.2: BACHELIER PRICING IN DISCRETE TIME 
243 
From (6.22), the fact that d 3 v / d s 3  and d4U/ds4 as averages of U(3) and U(4) cannot 
exceed c in absolute value, (10.4), and the constraints on Market’s moves, we obtain: 
IdU(Sn,Dn) - dZ,I 5 c (IdSn13 + IdD,(IdS,I2 + IdD,IldS,1+ 
IdD,I2) 
5 c (C1.5N-’.5 + C 3 N P 2  + C2N-1.5 + C2NP2) = 0 (N-’//’> 
. 
Summing over n = 0,. . . , N - 1, we obtain 
I(u(SN,DN)-u(sO,DO)) - ( Z N  -&)I = o  (N-”’>. 
This completes the proof under the assumption that U is a smooth function constant outside a 
I 
Proposition 10.1 is not really useful, because the constraints lAD,l 5 CN-’ 
and lASnl 5 CN-1/2 are unrealistically strong, and because the proposition does 
not provide an explicit bound on the accuracy of the approximation. While still 
remaining within the unrealistic Bachelier setting, we now take a step towards more 
useful bounds. 
finite interval. To drop that assumption it suffices to apply Lemma 7.1 (p. 158). 
10.2 BACHELIER PRICING IN DISCRETE TIME 
In this section we derive an explicit bound on the accuracy of Bachelier’s central limit 
theorem, using a version of Bachelier’s protocol that constrains the variation spectra 
of the prices of S and 2). This derivation will serve as a model for the more applicable 
but slightly more complicated derivation, in the next section, of a discrete-time error 
bound for Black-Scholes. 
The Taylor’s expansion that we studied in 59.3 should have a negligible remainder, 
as required by the argument there, if the variation exponents of the realized paths for 
S(t) and D(t) satisfy 
vexS 5 2 
and 
vexD < 2. 
(10.5) 
As we learned in $9.1, the practical (discrete-time) meaning of the variation exponent 
having a certain value cy is that var(p) will be small for p greater than a. So the 
meaning of (10.5) is that for small E > 0, vars(2 + E )  and v a r ~ ( 2  
- 
E )  will be small. 
So even for a small 6 > 0, there should exist an E E (0,l) such that 
vars(2 + E )  < 6 
and 
v a r ~ ( 2  - E )  < 6. 
(10.6) 
This is asymptotically weaker than the condition that we used in the preceding 
section-the 
condition that 
\ADn] 5 CN-l 
and 
IAS,I 5 CN-l/’. 
(10.7) 
Indeed, (10.7) implies that 
N 
< ~ c 2 . 5 ~ - 1 . 2 5  
- 
- ~ 2 . 5 ~ - 0 . 2 5  
vars(2.5) = C 
- 
n=l 

244 
CHAPTER 10: GAMES FOR PRlClNG OPTIONS IN DISCRETE TIME 
and 
N 
varo(1.5) = C l a ~ , ~ l . ~  
5 NC 1 . 5 ~ - 1 . 5  - 
- ~ 1 . 5 ~ - 0 . 5  
, 
n=l 
so that (10.6) holds with E = 0.5 when N is sufficiently large. 
The condition that an E satisfying (10.6) exists can be written compactly as 
inf max(vars(2 + E ) ,  v a r ~ ( 2  - E ) )  < 6. 
(10.8) 
f€(0,1) 
This is the constraint we impose on Market in our new version of Bachelier’s protocol: 
BACHELIER’S 
PROTOCOL WITH CONSTRAINED VARIATION 
Parameters: N ,  To, 6 E (0,l) 
Players: Market, Investor 
Protocol: 
Market announces SO E R and DO > 0. 
FOR TZ = 1,. . . , N :  
Investor announces M ,  E R and V, E R. 
Market announces S, E R and D, 2 0. 
1, := zrL-i + AdnaS, + V,l((ASn)2 + AD,). 
Additional Constraints on Market: Market must set DN = 0, D, > 0 for n < N ,  
and must make So,. 
. . , SN and DO, 
. . . , DN satisfy (10.8). 
We now state and prove our central limit theorem for this protocol. Because we 
are now concerned with pricing options rather than with statistical applications of the 
central limit theorem, we change our regularity conditions on the function U that we 
want to price. In the central limit theorems of Part I and also in Proposition 10.1, 
we assumed that U is bounded and continuous, a condition that is not even satisfied 
by European calls and puts. Now, and in subsequent theorems concerning option 
pricing, we assume instead that U is Lipschitzian. Recall that a function U :  IR 4 
R 
is Lipschitzian with coefficient c if IU(z) - U(y)i 5 CIZ - yI for all z and y in R. 
Proposition 10.2 Suppose U :  IW -+ R is Lipschitzian with coeflcient c. Then in 
Bachelier’s protocol with constrained variation, the variable U ( S N )  is priced by 
with accuracy 
6c61/4 
(10.9) 
(10.10) 
in the situation where SO and DO have just been determined. 
For standard call and put options, we have c = 1, and (10.10) becomes 6d1I4. 
Pioaf qfp’l-OpSitkJFZ 10.2 We will establish the proposition by showing that (10.9) prices 
U(S,v) with accuracy (10.10) provided (10.6) is satisfied, using a strategy for Investor that 
does not depend on E .  (Equation (10.13). which describes the strategy, does not depend on 6 

10.2: BACHELIER PRICING IN DISCRETE TIME 
245 
either, but later we will replace U with a smoothing, and the degree of smoothing will depend 
on 6; see (10.32).) 
First we state two well-known inequalities, involving nonnegative sequences X n  and Yn and 
nonnegative real numbers p and q, that we will use frequently. The first, Holder's inequality, 
says that if l/p + l/q = 1, then 
(10.11) 
The other, sometimes called Jensen's inequality, says that if p 5 q, then 
(&yP 
2 
(10.12) 
n=l 
n=l 
For proofs, see, for example, [Il, 1461. These two inequalities imply that if l/p + l/q 2 1, 
then (10.11) holds. In particular, 
N 
/
N
 
n=l 
First assume that the derivatives (lU(3)11 and llU(4)11 exist and their norms 
l l ~ ( ~ ) 1 1  
:= sup I U ( ~ ) ( ~ ) I ,  
J I U ( ~ ) ~ ~  
:= sup I U ( ~ ) ( ~ ) ~  
S 
s 
are bounded by positive constants c3 and c4, respectively. (We encountered a similar condition 
in 56.2: see the argument after (6.22), p. 132.) Taking as Investor's strategy 
(10.13) 
shares of S 
shares of 2) 
as in (10.3), and summing over n = 0, . . . , N - 1 in (6.21) (p. 132), we can see that 
I(U(SN,DN) 
-U(So,Do)) - ( I N  -&)I 
all suprema being over the convex hull of {(Sn, Dn) I n = 0, . . . , N } .  Remember that 
defined by (6.10), p. 128. 
Since, for n = 3,4, 
is 

246 
CHAPTER 10: GAMES FOR PRICING OPTIONS IN DISCRETE TIME 
(we may differentiate under the integral sign by Leibniz’s differentiation rule for integrals), 
we can bound from above all coefficients of (10.14) using (6.22) on p. 132: 
Therefore, (10.14) gives the following accuracy for (10.9) pricing the final payoff U ( S N ) :  
Using Holder’s inequality and the variant 
b / a  
a I b = = . ~ z k  ( F z : )  
n 
(a, 
b, and all zn are positive numbers) of (10.12), we obtain, with p := 2 + E and q := 2 - E, 
n 
\ n  
(here we used the inequality p / ( p  - 2) 2 q, which is easily checked), 
= (varo(q)) 
2/q < - s 2 / 4  5 6, 
n 
and so the accuracy (10.16) can be bounded from above by 
(10.18) 
(10.19) 
(10.20) 
(10.21) 
3 
8 
c3s + -c46. 
Now we drop the assumption that I(U(3)I( and llU(4)(I are bounded, assuming only, as 
stated in the proposition, that U is Lipschitzian with coefficient c. As usual, we introduce a 
new function V, a smoothed version of U ,  that does have bounded llV(3)II and IlV(4)II. But 
because we have replaced our usual condition on U ,  that it is bounded and continuous, by the 
condition that it is Lipschitzian, we cannot now rely on the method in Lemma 7.1 (p. 158) to 
construct V. 

70.2: BACHELIER PRICING IN DlSCRETE TlME 
247 
Let (T > 0 be some (small) parameter; put 
this is the smoothed version of U we are going to use. We know how to attain V ( S N )  
starting 
with s Vdh/,o,Do 
with accuracy (10.21), where c3 = I(v(3)ll 
and c4 = llv(4)II 
(We Will see 
momentarily that these derivatives exist and are bounded). So our plan is: 
0 Show that U ( S N )  is close to ~ ( S N ) .  
Show that s UdNs,,o, is close to s VdNs,,D, 
Bound c3 and c4 from above. 
From time to time we will make use of the formula 
First let us check that U ( s )  is close to V(s), using the fact that U is Lipschitzian with 
coefficient c: 
(1 0.24) 
(the last equality follows from (10.23)). We can also find 
(the last inequality follows from (10.24)). 
Now we find upper bounds for all derivatives V(n). We start by proving that, for n = 
0,1,. . ., 
(10.26) 
where Hn are Hermite's polynomials (see, e.g., [287], Example 11.1 1.1). Equality (10.26) can 
be proven by induction in n. Indeed, for n = 0 it is obvious (recall that Ho(z) = l), and 
assuming (10.26) we can obtain, by differentiating (10.26), the analogous equality with n + 1 
in place of n: 

248 
CHAPTER 10: GAMES FOR PRICING OPTlONS IN DISCRETE TIME 
(we used the easily checked recurrence for the Hermite polynomials, Hn+l(2) = xHn(z) - 
HA(2)). This completes the proof of (10.26). 
Assuming, without loss of generality, U ( s )  = 0, we obtain for n = 1 , 2 , .  . .: 
So we have the following upper bounds for llV(3)ll and llV(4)11: 
(the second and fourth moments of the Gaussian distribution are 1 and 3) and 
IIV (4) 115- kO3 
~ e - y 2 ~ 2 1 ~ 4  
- 6y2 + 3lIyldy 
- y 2 / 2  
5 
3 
2c 
2 3 a c  
e 
(y +6y + 3 y ) d y =  - 
(8 + 12 + 3) = --; 
5- 
&Gu3 
j1u3 
(10.29) 
in (10.29) we used formula (10.23). 
obtain the accuracv 
Plugging (10.28) and (10.29) into (10.21) and taking into account (10.24) and (10.25), we 
2&7&+,6+---- 6c 
323fic6 
u 
8 G u 3  
(10.30) 
of reproducing the payoff U ( S N )  when starting with (10.9). 
Finally, we need to choose some u in expression (10.30). This expression is of the form 
Au + BuP3 + C U - ~ ;  
(10.31) 
we will choose u so as to minimize the sum of the first two terms. This gives 
cr = (3B/A)1'4, 
(10.32) 
and so we can bound (10.3 1) from above by 
A(3B/A)'l4 + B(3B/A)-3/4 + C(3B/A)-'/' 
= (31/4 + 3-3/4)A3/4B'/4 + 3-1/2A1/2B-'/2C, 
Therefore, we obtain the following upper bound on (10.30): 
5 ((3'" + 3-1/2)21/2n-1/2231/4 + 8 x 23-'/') 
c S ' / ~  5 5 .7 1 ~6 ~/ * . 
which is slightly better than promised in (10.10). 
I 

10.3: BLACK-SCHOLES PRICING IN DISCRETE TIME 
249 
10.3 BLACK-SCHOLES PRICING IN DISCRETE TIME 
We now derive the Black-Scholes formula in a discrete-time protocol similar to the 
one we just used for Bachelier’s formula. This protocol differs from the discrete-time 
Bachelier protocol in two essential particulars: (1) Market is required to keep the 
price of the underlying security S positive, and (2) the derivative security D now 
pays the relative change in S(t), rather than the absolute change. We also bound the 
fluctuations in the prices of S and D. 
BLACK-SCHOLES 
PROTOCOL WITH CONSTRAINED VARIATION 
Parameters: N ,  10 > 0, S E (0, l), C > 0 
Players: Market, Investor 
Protocol: 
Market announces SO > 0 and DO > 0. 
FOR n = 1 , . . . , N :  
Investor announces M ,  E IR and V, E R. 
Market announces S, > 0 and D, 2 0. 
1, := In-1 + MnASn + Vn((ASn/Sn-1)2 + AD,), 
Additional Constraints on Market: Market’s moves must satisfy 0 < S, < C for 
n = 1,. . . , N ,  0 < D, < C f o r n  = I,.. . , N  - 1, DN = 0, and 
inf max(vars(2 + E ) ,  varo(2 - 6 ) )  < 6. 
(10.33) 
tE(O,1) 
This protocol is coherent: Market can prevent Investor from making any gains by 
announcing 
and 
N - n  
N 
D, = - 
DO 
with + or - chosen as needed. 
Proposition 10.3 Suppose U :  (0, m) + R is Lipschitzian with coeflcient c. Then 
in the Black-Scholesprotocol with constrained variation, the price of U ( S N )  is 
with accuracy 
8 c e 5 ~ 6 1 / 4  
(10.35) 
in the situation where So and DO have just been announced. 
For standard calls and puts, we have c = 1, and so (10.35) becomes 10e5C61/4. 
This is a relatively crude bound (see 5 10.4). We can eliminate the assumption S, < C 
from the protocol, but then we will obtain an even cruder bound. 

250 
CHAPTER 10: GAMES FOR PRICING OPJlONS IN DlSCRETE TlME 
Proof of Proposition 10.3 This proof is modeled on the proof of Proposition 10.2. We 
assume that 
(10.36) 
First we assume that the second through fourth derivatives exist and their norms llU(*)l\, 
Put, for D 2 0 and s > 0, 
vars(2 + E )  5 6, v a r ~ ( 2  - E )  5 6, 
and we prove that (10.34) prices U ( S N )  with accuracy (10.35). 
l(U(3)1(, 
and ((U(4)1( 
are bounded by positive constants cp, c3, and c4, respectively. 
It is clear that u is continuous and satisfies the initial condition u ( s ,  0) = U(s). It can be 
checked by direct differentiation that for D > 0, 
(10.38) 
In fact, (10.37) is the only solution of (10.38) with this initial condition that satisfies the 
polynomial growth condition (see [ 1071, Appendix E). 
Our trading strategy is exactly the same as in the proof of Proposition 10.2, (10.13) (only 
U is defined differently). Since the heat equation (6.6) is replaced by (10.38), we now have 
- 
instead of (6.21) (p. 132). Summing over n, we obtain 
1 (~(SN, 
D N )  - U(So, Do)) - (ZN - To)] 
(10.40) 
with all suprema over the convex hull of {(Sn, D,L) I 0 5 n 5 N } .  (This is the same 
as (10.14).) 
Now we prepare to bound the suprema in (10.40) from above. From (10.38), 
To bound the partial derivatives anG/dsT1, 
n = 1,2,. . ., from above in absolute value, we 
first note that E exc = ex''' 
forz E Rand a standard Gaussian variable < (this is arestatement 

10.3: BLACK-SCHOLES PRICING IN DISCRETE TIME 
251 
of the well-known fact that eCX2/' is the characteristic function of E). Therefore, applying 
Leibniz's differentiation rule, we obtain 
Now we are ready to bound the suprema in (10.40). From (10.41) and (10.42) we obtain 
(10.43) 
Combining Equations (10.43)-( 10.46) and (10.17)-( 10.20) with Equation (10.40), we obtain 
the following bound for the accuracy of pricing U: 
e 3C c3+ (:4 -+- :2) 
e 6C c4 ) . 
(10.47) 
Now we remove the restriction on llU(2)11-11U(4)II. As usual, we introduce a new function 
V by Equation (10.22) and apply the bound (10.47) to V. Equation (10.24) still holds, 
but (10.25) has to be modified (remember that cis the constant from the definition of U being 
Lipschitzian): 
(the last inequality follows from (10.24)); we can see that the inequality between the extreme 
terms in (10.25) still holds. 
Using inequality (10.27), we obtain (analogously to (10.28) and (10.29)): 
Combining (10.49), (10.28), (10.29), the inequalities (true for C > 0) 
C2 
1 
c3 c2 
1 
c4 c2 
- 
+ C + - < 0.5e[53]C, - + - + C + - < 0.5e[331C, 
4 
2 -  
2
2
 
2 -  
- + - 
5 3.14egc 
8
4
 

252 
CHAPTER 10: GAMES FOR PRICING OPTIONS IN DISCRETE TIME 
(we let [ k z ]  stand for the mixed fraction k + m/n), and the inequalities (10.24) and (10.48) 
relating V and ti, we obtain from (10.47), interpreted as the accuracy for pricing the deriva- 
tive V (  SN ), the accuracy 
2 m c o  + 6ce['#IC 
+ 0.5- 6 + 3.14- 23JI) 
(10.50) 
U2 
G o 3  
for pricing ~ ( S N ) .  
Similarly to our treatment of (10.3 l), we notice that (10.50) is an expression 
of the form 
Ao + B u - ~  + Co-' + DU-'; 
substituting the same value (10.32) for o as before, we obtain 
which for (10.50) becomes 
this proves the proposition. 
I 
10.4 HEDGING ERROR IN DISCRETE TIME 
In this section, we look at p-variations for the American stock price data that we stud- 
ied in the preceding chapter (prices for Microsoft stock and values for the S&P 500 
index), with a view to assessing whether the methods used in our proof of Proposi- 
tion 10.3 can be used in practice for hedging options. The results are encouraging. 
In 5 10.5, we will obtain even better results using the slightly different approach of 
Proposition 10.4. 
The Variation Spectrum for S 
We will use the first 5 12 days of the 600 days of data for Microsoft and the S&P 500 
that we displayed in Figure 9.1 (p. 203). We work with 512 days because this is a 
power of two close to a typical maturity for long-term options such as the Long-Term 
Equity Anticipation Securities (LEAPS) introduced by the Chicago Board Options 
Exchange in 1990 and now traded at all four United States options exchanges ([163], 
p. 56). 

10.4: HEDGlNG ERROR IN DlSCRETE TlME 
253 
-v 
-9 
-8.5 
-8 
-7.5 
-7 
-6.5 
-6 
-5.5 
-5 
Fig. 70.1 Plots of log var(p) against log dt for different values of p for the Microsoft stock 
price for the 512 working days starting January 1, 1996. We use 512 days as the unit for 
measuring time, and we use the final (day 512) price as the unit for measuring price. The 
logarithms are base 2. The time step dt runs from one day (1/512, or -9 on the logarithmic 
scale) to 16 days (16/512, or -5 on the logarithmic scale). 
We use daily closing prices, as we did in 59.1. Using one day as our time 
step corresponds to the usual banking practice of updating hedging portfolios daily. 
Fortunately, the exact choice of the time step does not make too much difference. 
The approximation 
log var(p) x ( H p  - 1) log dt 
(10.51) 
seems to hold within wide bounds, so multiplying dt by a moderate factor multiplies 
each p-variation by a similar factor, and this does not change whether a particular 
p-variation is close to zero. The approximation (10.5 1) follows directly from the 
heuristic relation (9.8), assuming that (1) the time horizon T is our unit for measuring 
time, and (2) the dSt have the order of magnitude (dt)H. Figures 10.1-10.4 confirm 
that the approximation is qualitatively accurate for our Microsoft and S&P 500 data 
when dt ranges from 1 to 16 days. Figures 10.1 and 10.2 show that logvar(p) is 
approximately linear in logdt, while Figures 10.3 and 10.4 show that it is approxi- 
mately linear in p. The important point is that whether we take dt to be 1, 2, 4, 8, 
or 16 days does not make much difference in the smallness of the p-variation for p 
greater than 1. This is indicated by the flatness of the lines in Figures 10.1 and 10.2 
and by their approximate agreement for p > 2 in Figures 10.3 and 10.4. 
Mandelbrot and his collaborators have reported similar results for a variety of price 
series. In [124], Fisher, Mandelbrot, and Calvet report that the variation spectrum 
for the USD/DM exchange rate is largely the same for dt from about two hours to 
about one hundred days. (They study the variation spectrum for the logarithm of the 
exchange rate, but theoretically, at least, this should make no difference.) A diagram 

254 
CHAPTER 70: GAMES FOR PRIClNG OPTIONS IN DISCRETE TIME 
2
7
 
’ 
I 
0 
-2 
-4 
-10 -8
-12L 
I 
-9 
-8.5 
-8 
-7.5 
-7 
-6.5 
-6 
-5.5 
-5 
Fig. 70.2 Plots of log var(p) against log dt for different values of p for the S&P 500 index 
for the 512 working days starting January 1, 1996. 
in [216], p. 176, shows that the dependence of logvar(p) on logdt is indeed close to 
being linear. This linear dependence breaks down for dt below 2 hours (at about 1.4 
hours according to [46]); this is attributed to market frictions such as bid-ask spreads 
and discontinuous trading [ 1241. The results depend on a filtering that expands time 
during typically active periods of the week, but there is no strong dependence on 
the choice of filter [124]. Calvet and Fisher report similar findings for five major 
US stocks and an equity index [46]. These results are reassuring, although they are 
not strictly applicable to our question, because they are based on analyses in which 
intercepts of straight lines (relevant for us but irrelevant to the multifractal model the 
authors are testing) have been discarded. 
In order for the bound in Proposition 10.3 to be useful, it is necessary that S’s 
3-variation, at least, should be small. So it is reassuring that the daily 3-variation (the 
value of the curve marked p = 3 at the point -9 on the horizontal axis in Figures 10.1 
and 10.2) is quite small, approximately 2-8 in the case of Microsoft and 2-1° in the 
case of the S&P 500. 
The Variation Spectrum for D 
Because the security 2) is not now traded, we can only speculate about its variation 
spectrum. We obtain an interesting benchmark, however, by looking at what 2, would 
be worth if all the future prices of S were known: 
511 
i=n 

10.4: HEDGING ERROR IN DISCRETE TIME 
255 
Fig. 10.3 Plots of log var(p) against p for different time steps for the Microsoft data. The 
lines are labeled by the logarithm of the time step, -9 to -5. 
-12 ' 
I 
1 
1.2 
1.4 
1.6 
1.8 
2 
2.2 2.4 2.6 
2.8 
3 
Fig. 10.4 Plots of log var(p) against p for different time steps for the S&P 500 data. 

256 
CHAPTER 10: GAMES FOR PRICING OPTIONS IN DISCRETE TIME 
0 0 1 5 ~  
001 
0005- 
- 
0 'pi- 
0 
100 
200 
300 
400 
500 
600 
0 
100 
200 
300 
400 
500 
600 
Fig. 10.5 The oracular prices D: for n = 0,. . . ,512, for the Microsoft stock price on the 
left and the S&P 500 index on the right. The straight line in each plot shows, for reference, 
the linear decrease in the value of 2) predicted by the diffusion model. 
-2 
-4 
-6 
-8 
-10 
-12 
-14 
-1 6 
-18 
-20 -9 
-8.5 
-8 
-7.5 
-7 
-65 
-6 
-5.5 
-5 
Fig- 10.6 The loglog plot of var(p) against the time step for the oracular prices D: for 
Microsoft. 
for n = 0,. . . 511, and DgI2 = 0. We call Dg, . . . Dg12 oracularprices; these are 
the prices that an oracle would set. Figure 10.5 shows the oracular prices for our two 
data sets, and Figures 10.6 and 10.7 show their variation spectra. 
In order for the bound in Proposition 10.3 to be useful, it is necessary that 2)'s 
2-variation be small. Figures 10.6 and 10.7 show daily 2-variations of approximately 
2-l' for Microsoft and 2-15 for the S&P 500. Market prices might show greater 
volatility than this (cf. §10.6), but the 2-variations could be several orders of magni- 
tude greater and still be very small. The diffusion model would produce computed 

10.4: HEDGING ERROR IN DISCRETE TIME 
257 
-3$ 
-*:5 
-0 
-7:5 
-7 
-6:5 
-6 
-5:5 
-4 
fig. 10.7 The loglog plot of var(p) against the time step for oracular prices for the S&P 500 
index. 
values of approximately 2-13 for Microsoft and 2-18 for the S&P 500 when the time 
step is one day, but this is surely too optimistic. 
Is the Hedging Error in Proposition 10.3 Acceptable? 
The estimates of the variation spectra for S and D that we have just developed show 
that Proposition 10.3 itself is too crude to give useful error bounds. But it comes 
close enough to doing so to give us reason to hope that its method can be useful when 
tailored to particular options. 
Recall that the error bound for Proposition 10.3 reduces to 8e5c61/4 for a call 
or put. In the case of Microsoft, we see from the values of logvar(p) given in 
Figures 10.1 and 10.6 for logdt = -9 (daily trading) that the smallest 6 satisfy- 
ing (10.33) is about 2-6, approximately the 2.6-variation for S and the 1.4-variation 
for D (t = 0.6). Optimistically setting C = 1, we find that a call or put can be 
hedged with accuracy 
8e5c6'/4 M 420. 
This is of no practical use, because the payoff of the call or put will be less than one. 
(Our unit of measurement is the final price of Microsoft, and the payoff of a call or 
a put will usually be less than the stock's price.) But it demonstrates that we are not 
hopelessly stuck at infinity. 
A re-examination of the proof of Proposition 10.3 shows several opportunities to 
tighten the estimate and obtain a meaningful bound. Most importantly, the right-hand 
side of the inequality (10.40) can be used directly, and it can give a very meaningful 
result. The first step where a significant loss of accuracy occurs in the proof is where 

258 
CHAPTER 10: GAMES FOR PRICING OPTIONS IN DISCRETE TIME 
cross-variations 
(the second and third terms on the right-hand side of (10.40) are of this form) are 
bounded in terms of the variations for S and D (cf. (10.19) on p. 246). This loss of 
accuracy is not too serious; in the case of Microsoft, for example, if we take E = 0.6 
(i.e., p = 2 + E = 2.6 and q = 2 - E = 1.4), then we obtain from (10.19) the accuracy 
c 
IdSnIld~nI 5 (vars(p)PP 
( V a r d Q P  
n 
(2-6)1/2.6(2-6)1/1.4 
0.01 
for the main cross-variation term. (We may alternatively take p = 3 and q = 1.5: the 
essential condition in the proof is l/p + l/q 2 1, not p = 2 + E and q = 2 - E. This 
gives 0.006 as the approximate upper bound.) The other cross-variation will be much 
smaller. The really big losses of accuracy occur when we estimate the coefficients in 
front of variations and cross-variations in (10.40) and when we smooth (10.22). By 
using suitable estimation procedures, these losses can be avoided if the coefficients 
(which are determined by partial derivatives of u) are all moderate in magnitude; for 
example, if the coefficients are all bounded in absolute value by 1, then we arrive at 
an overall bound on the hedging error less than 0.04. 
The prospects are therefore good for practical error bounds. A realistic assessment 
will require, however, both a better handle on the behavior of D (see $10.6) and 
consideration of transaction costs, which are steadily decreasing because of new 
technologies but never zero. 
The Accuracy of Stochastic Hedging 
There is an extensive literature on discrete hedging under the stochastic Black-Scholes 
model, going back to work by Black and Scholes themselves in the early 1970s [29]. 
This literature is concerned, however, with error that would be eliminated entirely 
by hedging in our variance derivative D. It does not deal with the O((dt)3/2) 
error 
studied in this section-an 
error that is smaller than the error we eliminate but still, 
as we have seen, nonnegligible. 
The seminal work on discrete stochastic hedging is by Boyle and Emanuel(1980), 
who studied expected error under geometric Brownian motion when Black-Scholes 
delta-hedging is implemented only discretely. Subsequent work moved in directions 
not central to our concerns. Schal (1994) derived the optimal (minimum expected 
squared error) strategy for hedging in discrete time under geometric Brownian motion 
(this differs slightly from the Black-Scholes delta, which is error-free and therefore 
optimal only for continuous hedging). Schweizer (1995) generalized this idea to 
other stochastic processes, and Mercurio and Vorst (1996) considered the effect of 
transaction costs (see also Wilmott 1998). 
Stochastic error analysis probably cannot approach the specificity and concreteness 
of our error analysis. The only nonasymptotic error bounds it can provide are 

10.5: BLACK-SCHOLES WITH RELATIVE VARIATIONS FOR s 
259 
probabilistic and are therefore questionable as soon as we acknowledge doubts about 
the diffusion model. The central problem in relying on the diffusion model is the 
implicit appeal to the law of large numbers to deal with the unhedged squared relative 
returns (dS(t)/S(t))2 
. If this is invalid, there is a potentially catastrophic error, which 
we avoid by variance hedging. Because we deal with (dS(t)/S(t))2 
by hedging rather 
than with stochastic theory, our discrete theory is completely model-free. Our error 
bounds involve no probabilities at all. 
10.5 BLACK-SCHOLES WITH RELATIVE VARIATIONS FOR S 
Given a sequence S1,Sa, 
. . . of positive numbers, we can define a function of p based 
on their relative increments: 
(10.52) 
where dS, := Sn+l - S,. We call this function of p the relative variation sprectrum. 
It is dimensionless and invariant with respect to the unit in which Sn is measured. 
The dimensionlessness of the relative variation spectrum contrasts, of course, with 
the behavior of the absolute variation spectrum, 
n 
As we saw in 59.1, to our repeated discomfort, vars(p) is measured in the pth power 
of whatever monetary unit we use for S. 
Proposition 10.3 (p. 249) can be adapted directly to the relative variation spectrum: 
replace the first inequality in (10.36) with 
and replace (10.35) with 
8 c e 5 ~ ( 6 ~ 3  
p 4 .  
(10.53) 
The extra factor C3 in (10.53) arises from the inequality vars(2 + E )  I 
IlSllZc var~'(2 + E )  5 C3 var~'(2 + 6). 
It is more natural, however, to extract a new Black-Scholes formula from the proof 
of Proposition 10.3 rather than from its statement. To this end, consider the protocol 
obtained from the Black-Scholes protocol with constrained variation (p. 249) by 
replacing (10.33) with 
inf max (var~'(2 + €1, varO(2 - E ) )  < 6. 
(10.54) 
(€(0,1) 
We may call this the relative Black-Scholes protocol with constrained variation. 

260 
CHAPTER 10: GAMES FOR PRICING OPTIONS IN DISCRETE TIME 
A function U : (0, m) -+ R is log-Lipschitzian (with coefficient c) if the function 
S E R 
I-+ U(eS) is Lipschitzian (with coefficient c). 
Proposition 10.4 Suppose U :  ( 0 , ~ )  
-+ JR is log-Lipschitzian with coeficient c and 
suppose 6 E (0,l). Then in the relative Black-Scholes protocol with constrained 
variation, the price of U(SN) 
is 
with accuracy 
4 0 ~ 6 ~ / ~  
(10.55) 
in the situation where SO and Do have just been announced. 
Put options are log-Lipschitzian, whereas call options are not. So the condition 
imposed on U in Proposition 10.4 is quite strong. A strong condition is needed 
because Investor must replicate the final payoff U ( S ( T ) )  with small absolute error, 
whereas we expect the oscillations dS(t) to grow as S(t) grows. 
Proof of Proposition 10.4 First we assume that the norms 
(10.56) 
are finite for m = 2,3,4. 
Analogously to (10.40) (but using relative rather than absolute increments of S), we obtain 
with all suprema again over the convex hull of { (S,, Dn) 1 0 5 n 5 N } .  These suprema can 
be bounded from above using (10.41) and the following analog of (10.42): 
In place of (10.43)-( 10.46), we obtain 
1 
a2G 
1 
1 
I
S
g
I
 I c2 + -c3, 
2 
I 
I I 5c2 + c3 + -c4. 
4 
(1 0.58) 
(10.59) 
Combining (10.58)-(10.59), the relative versions of (10.17)-(10.20), and (10.57), we obtain a 
simpler bound for the accuracy of pricing U: 
6 (1.75~2 4- 2 . k ~  
4- 0.375~4). 
(10.60) 

10.5: BLACK-SCHOLES WITH RELATIVE VARIATIONS FOR s 
261 
To remove the restriction on the existence and finiteness of c2 -c4, we define the g-smoothing 
V of U in three steps: 
represent U in the log-picture: f(S) := U ( e s ) ,  where S E W; 
smooth: for some u2 > 0, g(S) := 
leave the log picture: V ( s )  := g(ln s), s ranging over (0, co). 
f(S + z )  NO,o~(d~); 
Remember that f is c-Lipschitzian. Applying (10.28), (10.29), (10.49), and 
to g rather than V, we obtain for V’s norms (in the sense of (10.56)): 
ls3V(3)1 = (s3&g(lns)l = 1g(3)(lns) - 3g”(Ins) + 2g‘(Ins)l 
+ 2c, 
6c 
3 a c  
5 - + 3 -  
u 2  
J;;O 
s ~ V ‘ ~ )  
= s -g(lns) 
= 9(4)(lns) - 6~3(~)(1ns) 
+ llg”(1ns) - 6g’(lns)/ 
I 
I I4js: I 
I 
2 3 A c  
6c 
3 a c  +6c. 
+6?+11- fiff 
I- 
f i u 3  
ff 
Applying (10.60) to V and taking into account the accuracy (10.24), (10.48) of V approximat- 
ing U ,  we obtain the accuracy 
+ 4.75- 6c + 13.375- 3Jzc + Bc) 
U 2  
6.- 
for capital of Investor (who is playing the strategy computed from V) approximating the target 
payoff U. As in (10.50), we obtain the accuracy 
Au + B o - ~  + Cu-’ + Da-’ + E 
D + E  
= (31/4 + 3-3/4)A3/4B1/4 + 3-1/2A1/2B-1/2C + 3-1/4A1/4B-1/4 
-1/2 
+3-’/’ (2J27;;~)~” ( 0 . 3 7 5 y c S )  
4.75 x 6cS 
3 J z  
+3-lf4 ( z ~ c ) ” ~  
( o . 3 i ~ i y ~ 6 ) - ~ ~ ~  
13.375-05 J;; + 9 ~ 6  

262 
CHAPTER 10: GAMES FOR PRICING OPTIONS IN DlSCRETE TIME 
+23/231/2 0.375- 'I2 23- 'I'4.75 + 23/433/4 ~ - ' / ~ 0 . 3 7 5 - ' / ~  
23- 'I4 
13.375 + 9 
5 3 7 . 8 4 ~ 6 ' ~ ~ .  
This completes the proof. 
I 
Although we have singled out the relative variation spectrum for further study in 
this book, there are other reasonable ways of defining a variation spectrum when S(t) 
is required to be positive. For example, we can set 
for some uc E (0,l). Or we can use the logarithm to obtain an alternative dimension- 
less auantitv: 
These alternatives also merit serious study. 
10.6 HEDGING ERROR WITH RELATIVE VARIATIONS FOR s 
As we will see in this section, we can obtain much better error bounds on our 
Black-Scholes hedging error using relative variation rather than absolute variation 
for S (although comparison is impeded by the fact that these error bounds depend on 
different assumptions about the payoff function). We verify this very quickly for the 
American data that we used in s 10.4. Then we look at another data set, for which we 
have a more convincing way of estimating the prices for V. 
The American Data, using Absolute Variations for Oracular D and Rel- 
ative Variations for S 
Figures 10.8 and 10.9 show the relative variation spectra for the Microsoft and 
S&P 500 data we studied earlier. Because these relative variation spectra are roughly 
similar to the absolute variation spectra shown in Figures 10.1 and 10.2, this data 
should satisfy the relative Black-Scholes protocol with approximately the same 6 
as we used in 10.4 when we studied it under the absolute Black-Scholes protocol. 
Hence we can compare the error bound 4 0 ~ 6 l / ~  
given by Proposition 10.4 for the 
relative protocol with the bound 8 c e 5 w 4  given by Proposition 10.3 for the absolute 
protocol. Because 40 is much less than 8e5' for reasonable values of C, the bound 
based on relative variation should be much better. 
For Microsoft, for example, we can take 6 x 2T6 in (10.60), especially if (10.54) 
is replaced by what is actually used in the proof, 

10.6: HEDGlNG ERROR WlTH RELATIVE VARIATIONS FOR s 
263 
2 
0 
-2 
-4 
-6 
-8 -9 
-8.5 
-8 
-7.5 
-7 
-6.5 
-6 
-5.5 
-5 
Fig. 10.8 The loglog plot of varre'(p) against the time step for Microsoft. 
-2EzEsk 
-4 
-6 
-8 
-10 
-12' 
J 
-9 
-8.5 
-8 
-7.5 
-7 
-6.5 
-6 
-5.5 
-5 
Fig. 10.9 The loglog plot of varre'(p) against the time step for the S&P 500. 

264 
CHAPTER 10: GAMES FOR PRIClNG OPTIONS IN DlSCRETE TIME 
1 
~. 
7 4 0 0 ~ - -  --- 
7200 t 1 
I 
Fig, 70.70 The graph on the left shows values of the FTSE 100 index for 244 trading days 
ending in December 2000. The graph on the right shows the index’s implied D for this period, 
calculated from at-the-money implied volatility. 
This gives a reasonable accuracy if c2 through c4 are not too large. Even (10.55), the 
hedging accuracy declared in the statement of the proposition, gives approximately 
14 when S = 2-6 and c = 1; this is still impractical but much better than the 420 we 
had in the previous section. 
The British Data, using Absolute Variations for D Implied by the Market 
Prices of Calls and Puts and Relative Variations for S 
We now look at recent data for the FTSE 100 index and for the stock prices of two 
British companies, Vodafone and BP (British Petroleum) Amoco. In April 2001 these 
two companies (ticker symbols VOD and BP) were by far the two largest in Europe 
by market capitalization, each accounting for approximately 5% of the FTSE Eurotop 
100 index. Vodafone’s price was quickly dropping and was very volatile (and, also 
important for us, even “second order” volatile, with implied volatility undergoing 
rapid changes), whereas BP Arnoco shares were relatively stable. 
Our data, obtained from LIFFE, the London International Financial Futures and 
Options Exchange [205], also gives implied volatility from at-the-money call and put 
options on the index and the two stocks. In the case of the FTSE 100, we use data 
on European calls and puts (ticker symbol ESX) with maturity in December 2000 
and a life span of 244 days. (We removed 28 April 2000 from the data sets; on that 
day ESX migrated from pit trading to electronic trading, and all volatilities for that 
day are listed as 0.) In the case of Vodafone and BP, we use data on American calls 
and puts with maturity in October 2000 and a life span of 187 days. For all the three 
cases, the LIFFE data gives the at-the-money implied volatility for the underlying 
as a function of time-that 
is, the volatility a(t) implied by market prices for calls 
and puts with strike prices at the current value for the underlying. Because LIFFE 

10.6: HEDGING ERROR WITH RELATIVE VARIATIONS FOR s 
265 
0 0 6 -  
0 0 5 -  
400 
380 
360 
340 
320 
300 
280 
260 
240 
1 
50 
100 
150 
200 
fig. 70.77 The graph on the left shows stock prices for Vodafone for 187 trading days 
ending in October 2000. The graph on the right shows the stock’s implied D for this period, 
calculated from at-the-money implied volatility. 
400 
0 
50 
100 
150 
200 
Fig. 70.72 The graph on the left shows stock prices for BP Amoco for 187 trading days 
ending in October 2000. The graph on the right shows the stock’s implied D for this period, 
calculated from at-the-money implied volatility. 

266 
CHAPTER 10: GAMES FOR PRICING OPTIONS IN DISCRETE TIME 
0 
0 5  
1 
1 5  
2 
2 5  
3 
3 5  
4 
-
1
2
:
' 
' 
' 
-20' 
2 
' 
' 
' 
' 
0 
0 5  
1 
1 5  
2 
2 5  
3 
3 5  
4 
Fig, 70.73 The variation spectra for S (on the left) and D (on the right) for FTSE 100. The 
horizontal axis shows the time step, from 1 to 16 days, in logarithms to the base 2. This and 
the remaining figures in this section are all loglog plots with logarithms to base 2. 
assumes put/call parity, the option's class (call or put) is not important. The unit for 
t is one year, which we equate with 250 trading days. 
From the implied volatilities given by LIFFE, we can estimate an implied price 
path for 2): 
D(t) = (T - t)02(t), 
where the time t is measured from the time the option started trading, and T is the 
option's life span. (There would be difficulties, however, in replicating V using the 
at-the-money calls and puts; see 5 12.2.) We can then compute the variation spectrum 
of the path. The price processes for the underlyings and the implied D are shown in 
Figures 10.10-10.12. 
Figures 10.13-10.15 show the variation plots for S and implied D for the three 
underlyings. In our further discussion, we will use the information for a time step of 
1 day (the left side of the bounding rectangle). When the time step is 16 days (the 
right side), there are too few observations (just 11 in the case of Vodafone and BP 
Amoco shares) for the computations to be reliable. Because our time spans are no 
longer powers of 2 (as they were in our data for Microsoft and the S&P 500), we 
now label the horizontal axis with the log of the time period in days. We will be 
interested, in each of the three cases, in the 3-variation for the underlying (I? = 3 on 
the left) and the 2-variation for the implied D (p = 2 on the right). 
Figures 10.16-10.18 report all four quantities occurring in Equation (10.57) and 
contributing to the accuracy of hedging: varF'(3), varo(2) (these two quantities 
are shown in the previous figures as well), and the cross-variations 

10.6: HEDGING ERROR WITH RELATIVE VARIATIONS FOR s 
267 
2 
1 
0 
1 
-2 
-3 
-4 
-5 
-6 
-7b 
0'5 
i 
1'5 
2 
2'5 
3 
3'5 
a 
Fig. 10.14 The variation spectra for s (on the 
0 5  
1 
1 5  
2 
2.5 
3 
3 5  
4 
-6 
-10 
-12 
0 5  
1 
1 5  
2 
2.5 
3 
3 5  
4 
-14: 
" 
'
'
 '
'
 '
I
 
left) and D (on the right) for Vodafone. 
Fig. 10.15 The variation spectra for S (on the left) and D (on the right) for BP Amoco. 

268 
CHAPTER 10: GAMES FOR PRICING OPTIONS IN DISCRETE TIME 
-135' 
' 
' 
' 
' 
' 
' 
1 
1 
0 
0 5  
1 
1 5  
2 
2 5  
3 
3 5  
4 
0 
0.5 
1 
1.5 
2 
2.5 
3 
3.5 
-14 
Fig. 70.16 Variations and cross-variations for the FTSE 100. 
and 
2 
COV(2,l) := c - 
dSn 
ldDnJ. 
7L I sn 1 
The values given by varz'(3) and cov( 1,l) may be too pessimistic, inasmuch as the 
corresponding hedging errors can cancel each other out. So we also report the values 
and 
To assess the hedging accuracy corresponding to these pictures, assume (somewhat 
arbitrarily) that C Z - C ~  in (10.56) do not exceed 1. Then the hedging accuracy as given 
by the right-hand side of (10.57) is bounded by 
1 
7 
3 
7 
- varF'(3) + - cov(2,l) + - c o v ( l , ~ )  + - varo(2) 
2 
4 
2 
8 
(we have used (10.58)-( 10.59) here). Substituting the numbers obtained as described 
above from the LIFFE data, we obtain the following bounds (with accuracy 0.001): 
0.008 for FTSE 100, 0.052 for Vodafone, and 0.011 for BP Amoco. The largest 
contribution to these totals is invariably from cov(1,l) (0.036 in the case of Voda- 
fone); if we are lucky, the addends in the second sum in the right-hand side of (10.57) 
(corresponding to cov( 1 , l ) )  will cancel each other out; see the I cov* (1,l) 
I lines in 
the pictures. 

10.6: HEDGING ERROR WITH RELATIVE VARIATIONS FOR s 
269 
4 
/ 
__ 
- 
cov(1,l) 
-6 
-16' 
I 
' 
' 
' 
' 
' 
I 
0 
0.5 
1 
1.5 
2 
2.5 
3 
3.5 
4 
Fig. 70.77 Variations and 
-10.5L;,5 
' 
' 
0 
1.5 
2 
2.5 
3 
3.5 
4 
cross-variations for Vodafone. 
-6 !
"
"
"
'
1
 :
-12 
cov(2,l) 
-13 u 
0 
0 5  
1 
1.5 
2 
2.5 
3 
3.5 
4 
Fig. 70.78 Variations and cross-variations for BP Amoco. 

11 
Games for Pricing Options 
in Continuous Time 
In the preceding chapter, we demonstrated 
that a Black-Scholes game for option pricing 
is feasible in a realistic discrete-time setting. 
In our view, this justifies a theoretical explo- 
ration, which we will now undertake, of game- 
theoretic option pricing in continuous time. 
Our continuous-time theory will neglect de- 
tails of implementation but will give a clearer 
and broader perspective. 
One of the most important purposes of this 
chapter is to introduce our way of handling a 
continuous market game. In order to do so as 
clearly and simply as possible, we limit our 
scope: we consider only the simplest forms of 
Bachelier and Black-Scholes option pricing. 
We leave for later chapters issues that compli- 
cate the picture, such as interest rates, price 
processes with jumps, the pricing of American 
options, and so on. 
We use nonstandard analysis. Although it is still novel for many applied mathe- 
maticians, nonstandard analysis is well adapted to game theory, because, as we will 
show, it allows us to import into continuous time the fundamental picture in which 
two players alternate moves. Our time interval is a continuum-all 
real numbers 
between 0 and T are included, where T is a positive real number. But we divide the 
Abraham Robinson (1918-1974), the 
inventor of nonstandard analysis, pho- 
tographed in 1971 on his appointment 
as Sterling Professor, Yale University. 
271 
Probability and Finance: It’s Only a Game! Glenn Shafer, Vladimir Vovk 
Copyright 0 2001 John Wiley & Sons, Inc. 
ISBN: 0-471-40226-5 

272 
CHAPTER 11: GAMES FOR PRICING OPTIONS IN CONTINUOUS TIME 
interval [O, T ]  into an infinitely large number N of steps of equal infinitesimal length 
dt; dt := TIN. The time horizon T and the infinitely large positive integer N will be 
fixed throughout the rest of this book. We designate the resulting set of time points 
by T: 
The infinitely large number N is the number of rounds of play in our game between 
Investor and Market, and the infinitesimal number dt is the amount of time each round 
takes. After an initial move by Market at time 0, the first round takes place between 
time 0 and time dt, the second between time dt and time 2dt, and so on. The last 
round takes place between time (N - 1)dt and time Ndt = T .  If 1 < n < N - 1, 
then the nth round, which takes place between time (n - 1)dt and time ndt, has 
an immediately preceding round and an immediately following round, even if n is 
already infinitely large. 
We use only simplest notions of nonstandard analysis, such as infinitely large and 
injinitesimal (infinitely close to zero). The reader will be able to follow our reasoning 
at an intuitive level if he or she reads these terms simply as “very large” and “very 
small”. But they have an exact meaning in nonstandard analysis, and our reasoning 
is rigorous when these exact meanings are used. Explanations sufficient to allow the 
reader to understand the limited parts of nonstandard analysis we use are provided in 
an appendix, 5 11.5. 
Nonstandard analysis studies the hyperreal numbers, which consist of (1) the 
ordinary real numbers, which are called standard, together with (2) nonstandard 
numbers. A nonstandard number is either infinite (positive or negative) or else differs 
from a standard number by an infinitesimal amount. The set T defined above is a 
subset of the hyperreal numbers; it includes all the real numbers in the interval [0, TI, 
together with many (but not all) of the nonstandard numbers that lie infinitely close 
to a real number in [0, TI. 
Our claim that the continuous theory of this chapter is justified by the discrete-time 
theory of the preceding chapter is true quite literally. As we mentioned In 5 1.5, the 
transfer principle of nonstandard analysis allows some nonstandard theorems to be 
deduced directly from corresponding standard theorems ([ 1361, Chapter 4). Aside 
from a few details, such is the situation here; the principal continuous-time results 
in this chapter follow from the corresponding discrete-time results of the preceding 
chapter : 
T := {ndt 10 5 n 5 N } .  
0 Our continuous-time Bachelier formula, Theorem 11.1 (p. 278), follows by the 
transfer principle from Proposition 10.2 (p. 244). 
0 We did not state a discrete-time result corresponding exactly to our main 
statement of the Black-Scholes formula, Theorem 11.2 (p. 280), but application 
of the transfer principle to Proposition 10.3 (p. 249) under the assumption that 
U is smooth with bounded U(2)-U(4) produces a continuous-time result that 
makes Theorem 11.2 nearly obvious. 
Our continuous-time relative Black-Scholes formula, Theorem 11.3 (p. 282) 
follows by the transfer principle from Proposition 10.4 (p. 260). 

17.1: THE VARlATlON SPECTRUM 
273 
(In fact, these implications are very simple and will be explained in $11.5: see 
p. 286.) Thus our continuous-time theory is literally a simplification of our discrete- 
time theory, in which important but messy practical details are cleared away. The 
absence of these details makes the proofs of the continuous-time theorems much 
simpler than the proofs of the corresponding discrete-time results. In order to make 
this clear, we prove directly all the results in this chapter. 
We begin our exposition, here as in Chapter 9, by defining the variation spectrum 
and the variation and Holder exponents (5 1 1.1). Then we derive our game-theoretic 
versions of Bachelier’s formula ($1 1.2) and the Black-Scholes formula (5 11.3). In 
a final section, 5 I 1.4, we consider an important implication of our continuous-time 
game-theoretic treatment of option pricing: in a market where the variance of the 
price of a security S is traded, Investor can force Market to make her S(t) have 
Holder exponent 1/2 (i.e., Investor can become infinitely rich if Market does not do 
so). This is the Jdt effect, which is assumed at the outset by the diffusion model. 
In addition to the appendix in which we provide a brief introduction to nonstandard 
analysis ($1 lS), we also include a second appendix, $1 1.6. in which we show that 
our definition of the Holder exponent (which differs from the definitions usually 
used in stochastic theory) gives the expected result in the diffusion model: a random 
function that obeys the diffusion stochastic differential equation does indeed have 
Holder exponent 1/2. 
11.1 THE VARIATION SPECTRUM 
In this section, we define the variation spectrum, the variation exponent, and the 
Holder exponent for nonstandard continuous functions. In addition to the variation 
spectrum with absolute differences, which we introduced in 59.1 and emphasized 
in the preceding chapter, we also study the relative variation spectrum, which we 
introduced in $10.5. 
Continuity for Nonstandard Functions 
A real-valued function of real variables (such as x + x2 or x, y + x + y) automat- 
ically extends to a hyperreal-valued function of hyperreal variables (p. 284). This 
type of hyperreal function is called standard, although it may assign nonstandard 
values to nonstandard numbers (e.g., if z and y are nonstandard, then x + y may be 
as well). Other hyperreal-valued functions are called nonstandard; they may assign 
nonstandard values even to standard numbers. 
Given a function f on T, 
we write d f ( t )  for f ( t  +dt) - f ( t )  whenevert E T\ 
{T}, 
and we call f continuous if  up^^^\{^^ Idf (t)I is infinitesimal. In the case where f 
is standard, this condition is equivalent to f being continuous in the ordinary sense 
when it is considered as a real-valued function on the interval [0, TI (see p. 286). 

274 
CHAPTER 11: GAMES FOR PRICING OPTIONS IN CONTINUOUS TIME 
The Variation Spectrum 
Given a continuous, possibly nonstandard, function f on T, 
and a real number 
(11.1) 
t E F {  T }  
We call the number varf(p), which may be nonstandard, the p-variation of f. We 
call the function varf the variation spectrum. 
Lemma 11.1 Suppose f is a continuous, possibly nonstandard, function, on T. Then 
there exists a unique real number’ vex f E [l, m] such that 
0 varf (p) is infinitely large when 1 5 p < vex f, and 
varf ( p )  is infinitesimal when p > vex f. 
Proof If f is constant, then varr(p) = 0 for all p E [l, cm). This means that vexf exists 
and is equal to 1. 
Suppose now that f is not constant. Then it suffices to consider real numbers pl and pz 
satisfying 1 5 pl < pz and to show that the ratio 
(11.2) 
where t ranges over T \ {T}, is infinitesimal. (Because f is not constant, the denominator is 
positive.) To do this, we show that (1 1.2) is less than E for an arbitrary positive real number E .  
Let €1 > 0 be so small that E ~ ” ” ’  
< E .  Since f is continuous, Idf(t)l 5 €1 for all t. So we 
have: 
I 
t 
t 
t 
t 
We call vex f the variation exponent of f ,  and we call 1/vex f the Holder 
exponent. We write H( 
f) for the Holder exponent. We defined vex f and H( 
f) in 
this same way in 59.1, but there these definitions were merely heuristic. By dint of 
fixing a particular infinitely large integer N ,  we have ensured that vex f and H( 
f) 
are well defined in the present idealized continuous-time context. 
If vex f = 1, then we say that f has bounded variation. It is clear that vex f = 1 
when f is bounded and monotonic, for then varf(1) = Ct ldf (t)I = If (T) - 
f (O)l, which is finite and not infinitesimal. We obtain the same conclusion when 
f is bounded and [0, I] can be divided into a finite number of intervals where f is 
monotonic. This justifies the loose statement, which we made in 59.1, that ordinary 
well-behaved functions have variation exponent 1. 
We call f stochastic when vex f = 2, substochastic when vex f < 2, and super- 
stochastic when vex f > 2. As we will confirm in $1 1.6, we can expect the path of 
a diffusion process to be stochastic. A substochastic function is less jagged than the 
path of a diffusion process; a superstochastic one is more jagged. 
‘Sometimes we include 03 and -m in the real numbers 

11.2: BACHELIER PRICING IN CONTINUOUS TIME 
275 
The Relative Variation Spectrum 
We turn now to the relative variation spectrum, which we studied for the discrete case 
in $10.5 (p. 259). As we will see, it normally leads, in the present idealized setting, 
to the same variation and Holder exponents as the absolute variation spectrum. 
We call a possibly nonstandard function f on T positive if f (t) > 0 for all 
t E T. (This does not forbid infinitesimal values for f (t).) We call a positive, 
possibly nonstandard, function f relatively continuous if S
U
~
~
~
~
\
{
~
}
 
df(t)/ f (t) is 
infinitesimal. Iff is relatively continuous, we set 
As in the discrete case, we call varje'(p) the relative p-variation of f ,  and we call 
the function varrfel the relative variation spectrum. 
Lemma 11.2 I f f  is a relatively continuous positive, possibly nonstandard, function 
on T, 
then there exists a unique real number vexre' f E [I, m] such that 
varrfe'(p) is infinitely large when 1 5 p < vexre' f, 
varjel(p) is infinitesimal when p > vexre* f. 
The proof is analogous to that of Lemma 1 1.1. We call vexre1 f the relative variation 
exponent o f f .  
A possibly nonstandard function f on T is strictly positive if there exists a real 
number E > 0 such that f (t) > E for all t E T. It is bounded if there exists a real 
number C < 00 such that supt I f  (t)l < C. 
Lemma 11.3 Ifa strictly positive and bounded nonstandard function f is relatively 
continuous, then vexre' f coincides with its absolute counterpart: vexre' f = vex f. 
This lemma follows from the coincidence of varf(p) and varje'(p) to within a 
constant factor. 
11.2 BACHELIER PRICING IN CONTINUOUS TIME 
As in the preceding chapter, we begin, for simplicity, with the Bachelier game, even 
though it has less practical importance because it allows negative stock prices. 
In the Bachelier game, two securities are available to Investor: a security S, which 
pays no dividends, and a security D, 
which pays a regular dividend equal to the 
square of the most recent change in the price of S. Just as in the discrete case, Market 
sets prices for S and D at N + 1 successive points in time: 
prices So,. 
. . , SN for S, and prices Do,, . . , DN for D, 

276 
CHAPTER 11: GAMES FOR PRICING OPTIONS IN CONTINUOUS TIME 
and the dividend paid by 2) at point n is 
where A S ,  := S, - S,-1. 
But 
now N is infinitely large, and the sequences SO,. . . , SN and DO,. . . , DN define 
functions S and D, respectively, on our time interval T: 
S(ndt) := S, 
and 
D(ndt) := D, 
for n = 0, . . . , N .  
chapter (p. 244): 
The protocol for the Bachelier game can be written exactly as in the preceding 
Market announces SO E IR and DO > 0. 
FORn= 1,2, ..., N :  
Investor announces Ad, E IR and V, E 
Market announces S, E R and D, 2 0. 
1, := Zn-1 + MnASn + Vn((ASn)2 + AD,). 
(11.3) 
We can also write (1 1.3) as 
or 
d Z ,  := Mn+ldSn + Vn+l((dSn)2 + dDn) 
(11.4) 
for n = 0,. . . , N - 1. Here, as always, dfn := fn+l - fn. 
Investor decides on his moves M ,  and V, in the situation 
SoDo ... Sn-lDn-l. 
(11.5) 
So a strategy for Investor is a pair of functions, say M and V ,  each of which maps 
each situation of the form (1 1 3 ,  for TI = 1, . . . , N ,  to a real number. When Investor 
uses the strategy ( M ,  V ) ,  and Market’s moves are recorded by the functions S and 
D, (1 1.4) becomes 
dZ, := M(SoD0.. . S,D,)dS, + V(SoD0.. . S,LDn)((dSn)2 
+ dDn). (11.6) 
Let us write ZMlV(S, D )  for Investor’s total change in capital over the course of 
the game when he follows the strategy ( M  , V )  and Market plays (S, D). This is 
obtained by summing the increments (1 1.6): 
N-1 , 
(11.7) 
If Investor starts with initial capital Q at time 0, then his final capital at time T will 
be o + ZM>’(S, D). 

7 7.2: BACHELlER PRlClNG IN CONTlNUOUS TlME 
277 
If Investor’s decision on how many units of each security to hold during a time 
period depends only on the current prices of the two securities, then M and V are 
merely functions of two variables (the strategies we construct for Investor will in fact 
have this Markovian property), and (1 1.7) reduces to 
) 
N-1 
ZM9”(S,D) := 
(M(S,,D,)dS, +V(S,,D,)((dS,)’ + dD,) . 
n=O 
This can also be written as 
ZM9’(S, D )  := C M(S(t),D(t))dS(t) 
tET\{Tl 
+ c 
V(S(t), 
D(t)) ( ( d S ( W  + d W ) )  . 
t€T\{Tl 
In discrete time, we say that a is an approximate price for a European option U 
if Investor has a strategy that produces approximately the same capital starting with 
a. In the discrete-time Bachelier and Black-Scholes protocols, the approximation 
improves with the number of rounds played: for every positive real number E ,  there is 
a number of rounds N that allows the price to be approximated to within E ,  provided 
that Market’s moves obey the rules of the game. In our present setting, the number 
of rounds is infinite, and so we should be able to make the discrepancy between 24’s 
payoff and Investor’s final capital a + Z’)V(S, 
D )  smaller than every positive real 
number E. This is equivalent to saying that the difference should be infinitesimal. 
So here is how we define the price of a European option U in continuous time. 
First we complete the definition of the game by fixing constraints on Market’s paths 
S and D under which our protocol is coherent. Then we select the payoff function 
U for U. 
Finally, we consider a real number a. We say that a is the price of U at 
time 0 (just after Market has announced his initial moves So and Do) if for any E > 0 
Investor has a strategy ( M ,  V )  such that 
la + P y S ,  D )  - U(S(T)) I < E 
(11.8) 
for all paths S and D permitted by the rules of the game. If a price exists, it is unique. 
Indeed, if (1 1.8) holds and Investor also has a strategy (M’, V’) such that 
a‘ + ZM’VV’ 
then 
This means that Investor can obtain capital arbitrarily close to a - a’ by playing 
( M  - M’, V - V‘) starting with zero, and coherence then implies that a = a’. 
We should note the limited role played by nonstandard objects in this machinery. 
The payoff U is a real valued function of a real variable, and the price a is a real 
number. The moves M, and V, made by Investor are also always real numbers. 

278 
CHAPTER 11: GAMES FOR PRICING OPTIONS IN CONTINUOUS TIME 
Only the time interval T, 
the paths S and D taken by Market, and the resulting capital 
process ZM ,v (S, D )  are nonstandard. 
There are several different sets of constraints for Market’s moves that will produce 
the usual Gaussian prices for European options in the Bachelier game. Here we 
assume that S is not superstochastic and that D is substochastic: vexS 5 2 and 
vexD < 2. In terms of the Holder exponents: H ( S )  2 1/2 and H ( D )  > l/2. 
A weaker set of conditions that also works is H ( S )  > 1/3, H ( D )  > 1/2, and 
H ( S )  + H(D) > 1. 
BACIIELIER’S 
PROTOCOL 
IN CONTINUOUS 
TIME 
Players: Investor, Market 
Protocol: 
Z, := 0. 
Market announces SO E R and DO > 0. 
FOR n = 1,2,. . . , N :  
Investor announces M, E R and V, E Iw. 
Market announces S, E R and D, 2 0. 
1, := Z,-I + M,AS, + V,((AS,)2 + AD,). 
Additional Constraints on Market: Market must ensure that S and D are contin- 
uous and satisfy vex S 5 2 and vex D < 2 and that So, DO are neither infinitely 
large nor infinitesimal. Moreover, he must make D, > 0 for n = 1, . . . , N - 1 and 
DN = 0. 
The coherence of this protocol is verified as usual: Market can keep Investor from 
making money by setting, say, DO := T and then always setting AD, = -dt and 
AS, = *.Jdt, with the sign opposite that of M,. In this case vexS = 2 and 
vex D = 1. (The path D decreases linearly from Do to 0.) 
Theorem 11.1 Let U :  R -+ Iw be Lipschitzian. 
Then in Bachelier’s protocol in 
continuous time, the price at time 0 (right after S(0) and D(0) are announced) for 
the European option U(S(T)) is 
Proof This proof is modeled on the proof of Proposition 10.2 (p. 244). The ingredients 
are all familiar. First we assume that U is smooth with bounded U(3) and U(4), define 
U ( s ,  D )  by (6.10), and use the strategy ( M ,  V )  given by (10.13): M ( s ,  D )  := ag/as and 
V ( s ,  D )  := au/aD. We need to show that 
- 
- 
U(S(O), D(0)) + +V(S, 
D )  =: V(S(T), 
D(T)). 
(11.9) 

11.3: BLACK-SCHOLES PRICING IN CONTINUOUS TIME 
279 
all suprema being taken over the convex hull of {(S(t), 
D(t)) I 0 < t < T }  (or, in this proof, 
even the whole of R x (0, m)). 
We are required to show that the right-hand side of (1 1.10) is infinitesimal. Let p := 1 + E 
and q := 1 - 
E for some E E (0,l) such that vex D < q; we know that vex S < p .  Remember 
that we can use Holder’s inequality (lO.ll), since l/p + l / q  2 1. First we will show that 
are infinitesimal. This is easy: Holder’s inequality gives 
c 
IdD(t)IIdS(t)I I (F IdD(tW) l I q  (F IdS(t)lP) llP = 0; 
(1 1.1 1) 
t 
and the uniform continuity of S on [0, T ]  gives supt IdS(t)l 5 1 and, thus, 
t 
t 
In the preceding chapter (cf. (6.22) and (10.15)) we saw that all suprema in (11.10) are 
finite. Therefore, the right-hand side of (1 1.10) is infinitesimal, which completes the proof for 
the case of smooth U with bounded U(3) and U(4). 
The assumption that U is smooth with bounded U(3) and U(4) is dropped in the same way 
as in the proof of Proposition 10.2: for a small D > 0 define V by (10.22), apply (1 1.9) to V ,  
and notice that U ( S ( T ) )  is close to V ( S ( T ) )  
(by (10.24)) and s U ~ J V ’ S ( ~ ) , ~ ( ~ )  
is close to 
I 
s VdJV’s(o),o(o) 
(by (10.25)). This proves the theorem. 
11.3 
BLACK-SCHOLES PRICING IN CONTINUOUS TIME 
We turn now to the Black-Scholes protocol. This differs from the Bachelier protocol 
primarily in that we require S, to be positive and have ’D pay (AS,/S,-,)2 
instead 
of (AS,)2 as a dividend. We also relax the condition vex S 5 2. 
THE BLACK-SCHOLES 
PROTOCOL IN CONTINUOUS TIME 
Players: Investor, Market 
Protocol: 
1, := 0. 
Market announces SO > 0 and DO > 0. 
F O R n =  1,2, ..., N :  

280 
CHAPTER 11: GAMES FOR PRlClNG OPTIONS IN CONTINUOUS TIME 
Investor announces M, E R and V, 
E R. 
Market announces S, > 0 and D, >_ 0. 
Z, := & - I  + M,AS, + V,((AS,/S,-I)~ 
+ AD,). 
Additional Constraints on Market: Market must ensure that S is continuous, 
inf, S, is positive and not infinitesimal, and sup, S, is finite. He must also ensure 
that D is continuous, D, > 0 for n = 1,. . . , N - 1, DN = 0, supn D, is finite, and 
vexD < 2. 
Theorem 11.2 Let U: 
( 0 , ~ )  
-+ R be Lipschitzian and bounded below. Then in the 
Black-Scholes protocol in continuous time, the price at time 0 (right after S(0) and 
D(0) are announced) for the European option U(S ( T) )  is 
i 
u(s(o)ez) 
N - D ( 0 ) / 2 ,  D(0) (dz). 
(1 1.13) 
Proof This proof is modeled on the proofs of Theorem 11.1 and Proposition 10.3. First we 
assume that vex S 5 2 and that U is a smooth function such that the derivatives U(1)-U(4) 
are bounded. 
Our goal is to find a strategy ( M ,  V )  such that 
(11.14) 
Defining s ( S ,  D )  by (10.37), we can rewrite (11.14) as (1 1.9). The strategy ( M ,  V )  is the 
same as before, (10.13). 
In our present continuous-time notation we can rewrite (10.40) as 
We need to show that the right-hand side of this inequality is infinitesimal. In view of (1 1.1 I) 
and (11.12), it is sufficient to prove that all suprema in it are finite; this was done in the 
preceding chapter (see (10.41) and (10.42)). This completes the proof for the case of smooth 
U with bounded U(')-U(4). 
Now we drop the assumption that U is smooth with bounded U(')-U(4). Taking a small 
~7 > 0, define V by (10.22). Combining (10.24), (10.48), and the boundedness of (IV(2)(I- 
J1V(4)11 (Equations (10.49), (10.28), (10.29)) shows that (11.14) can be achieved for any 
Lipschitzian U .  
It remains to remove the assumption vex S 5 2. Since U is bounded below, we can assume 
that Investor's capital in the above construction never drops below some known constant (as 
soon as this constant is reached, Investor can start choosing zero moves, since it means that 
Market violated some of its obligations). But spending an arbitrarily small amount E > 0 on 
2) will make sure that Investor's dividends 

11.4: THE GAME-THEORETIC SOURCE OF THE Jdt EFFECT 
281 
from holding D will be infinitely large when vex S > 2 and so will more than compensate 
any losses incurred by his main hedging strategy. 
I 
Notice the difference between Theorems 11.1 and 11.2: in the former we require 
that vex S 5 2, whereas in the latter this requirement is replaced by the requirement 
that U should be bounded below and inft S(t) should not be infinitesimal. 
In 
principle, either of these requirements can be used in both theorems, but the condition 
that U should be bounded below, or even nonnegative, is more natural in the Black- 
Scholes model: share prices being nonnegative makes nonnegative options natural. 
In practice, options are usually nonnegative. 
The assumption vexD < 2 can be regarded as a limit on the amount of new 
information that arrives concerning the future rates of return dS(t)/S(t). 
There already exists some literature on option pricing without probabilities. For 
example, Bick and Willinger (1994, Proposition I) prove a path-wise variant of the 
Black-Scholes formula. However, Bick and Willinger do not go very far beyond the 
diffusion model: they essentially assume that 
(S(t + dt) - S(t))2 M 02S2(t)dt, 
where (T is a constant. In $14.5 we discuss some other work where stochastic 
processes are treated path by path. 
11.4 THE GAME-THEORETIC SOURCE OF THE d d t  EFFECT 
As we mentioned at the beginning of the chapter, Investor can multiply his capital 
substantially in our continuous Black-Scholes protocol unless Market makes vex S = 
2 (half of this result has just been used at the end of the proof of Theorem 11.2). 
If vex S > 2, it is possible to become infinitely rich buying our derivative security 
'D, and if vex S < 2, it is possible to become infinitely rich shorting 'D. 
Proposition 11.1 For any E > 0 (arbitrarily small) there exists a strategy which, 
starting from E at the moment when S(0) and D(0) are announced, never goes to 
debt and earns more than 1 if 
S is continuous, sup S(t) < co, st 
OStST 
(11.15) 
(where st(a) > 0 means that the hyperreal a is positive and non-injkitesimal) and 
vexS # 2 
Proof We assume that conditions (1 1.15) hold, and we show how to get rich when vex S < 2 
or vex S > 2. 
First we show how to get rich when vex S > 2 (we have actually done in the proof of 
Theorem 11.2). Since vexS > 2, vars(2) is infinitely large, whereas D(0) is finite. Buying 
$e worth of 'D, we will get an infinitely large amount, 

282 
CHAPTER 11: GAMES FOR PRICING OPTIONS IN CONTINUOUS TIME 
in dividends, however small E > 0 is. 
Now let us see how to hedge against vex S < 2. In this case, vars (2) is infinitesimal. 
Short selling $1 worth of D, 
we will get $1 outright, whereas we will owe the infinitesimal 
amount 
of dividends that can be covered with an arbitrarily small initial investment t. 
We can see that, sacrificing E ,  we can ensure that we get at least 1 when vex S is different I 
It is instructive to compare this result with the following measure-theoretic results: 
0 Fractional Brownian motion with h # 0.5 is not a semimartingale (Rogers 
1997; for h > 0.5, see also Example 4.9.2 of Liptser and Shiryaev 1986). 
Therefore (see, e.g., [206], Theorem 4.53, it cannot be turned into a martingale 
by an equivalent measure change. This shows that the traditional equivalent 
martingale measure approach to contingent claim valuation does not apply for 
the fractional Black-Scholes model. 
from 2. This proves the proposition. 
0 The geometric fractional Brownian motion with parameter h # 0.5 allows for 
arbitrage opportunities (this “almost follows” from the previous item), as shown 
by Rogers 1997 and, in a nonstandard framework for h > 0.5, Cutland, Kopp, 
and Willinger 1995. Remembering that the variation exponent of the fractional 
Brownian motion with parameter h is l/h, we see that this corresponds to the 
substochastic and superstochastic cases, vex S # 2. 
Black-Scholes with the Relative Variation Spectrum 
Therefore, Theorem 1 1.2 will remain true if we replace vex S with vexre’ S and im- 
pose the requirement that S should be strictly positive and bounded. Proposition 10.4 
on p. 260, however, implies the following simplified version: 
Theorem 11.3 Suppose U: 
W + W is log-Lipschitzian and bounded below. Then the 
price for the European option U(S(T)) at the time when S(0) and D(0) have just 
been determined is 
u(s(0)e”) 
~ - D ( o ) p ,  
o ( o ) ( d z ) ,  
provided that S is positive and relatively continuous, D is continuous, and vex D < 2. 
The proof immediately follows from Proposition 10.4 (p. 260) combined with the 
following analog of Proposition 1 1.1. 
Proposition 11.2 For any E > 0 (arbitrarily small) there exists a strategy which, 
startingfrom 6 at the moment when S(0) and D(0) are announced, never goes to 
debt and earns more than 1 provided that S is positive and relatively continuous and 
vexre’ s # 2. 
The proof is similar to (but simpler than) the proof of Proposition 1 1.1. 

7 1.5: APPENDIX: ELEMENTS OF NONSTANDARD ANALYSIS 
283 
11.5 APPENDIX: ELEMENTS OF NONSTANDARD ANALYSIS 
Nonstandard analysis was invented by Abraham Robinson (1 9 18-1 974) in 1960 [78]. 
The first edition of his book on the subject appeared in 1966 [260]. 
Robinson’s invention was based on insights into the logical foundations of math- 
ematics. As he realized, the usual axioms for arithmetic do not rule out the existence 
of infinite integers and therefore can be extended by assuming that infinite integers 
do exist. There are different ways of using nonstandard analysis. Some emphasize 
logical concepts [235, 2361. But most applications, including those in probability 
[209,6] and option pricing [72,73,74], rely on the representation of hyperreals within 
classical mathematics by means of the ultrapower construction ([ 1361, Chapter 3), 
and we follow this tradition. 
The nonstandard ideas that we use do not go beyond what is explained in this 
appendix, but readers who want a fuller account may consult Davis (1977), Hoskins 
(1990), and, especially, Goldblatt (1998). 
Most often, nonstandard analysis is used to prove theorems that can be formulated 
in standard analysis. Here, in contrast, nonstandard analysis is essential to the 
statement of the theorems we prove. We use it in drawing as well as in studying 
our idealized picture of a continuous-time game. The meaning of this picture is to 
be found directly in the corresponding discrete-time game, not in some intermediate 
picture, involving continuous time but formulated in standard analysis. We do not 
know how to represent a continuous-time game in standard analysis, and it might 
even be impossible. 
The Ultrapower Construction of the Hyperreals 
An ultrujilter in the set N of natural numbers (i.e., positive integers) is a family U of 
subsets of N such that 
1. N E U a n d 0 f U ,  
2. ifA E 24 andA C B C N, then B E U, 
3. if A E U and B E U, 
then A n B E U, 
and 
4. if A E N, then either A E U or N \ A E U. 
(The first three properties define ajilter.) An ultrafilter U is nontrivial if it does 
not contain a set consisting of a single integer; this implies that all the sets in U are 
infinite. It follows from the axiom of choice that a nontrivial ultrafilter exists. We fix 
a nontrivial ultrafilter U .  
We say that a property of natural numbers holds for most natural numbers (or for 
most k, as we will say for brevity) if the set of natural numbers for which it holds is 
in U; 
Condition 2 justifies this usage. It follows from Condition 4 in the definition of 
ultrafilter that for any property A, either A holds for most k or else the negation of A 
holds for most k. It follows from Conditions 1 and 3 that A and its negation cannot 
both hold for most k. 

284 
CHAPTER 11: GAMES FOR PRICING OPTIONS IN CONTINUOUS TIME 
A hyperreal number a is a sequence [ ~ ( l ) a ( ~ )  
. . .] of real numbers. Sometimes we 
abbreviate [u(')u(~) 
. . .] to [a")']. Operations (addition, multiplication, etc.) over 
hyperreals are defined term by term. For example, 
[ u ( ' ) u ( ~ )  
. . .] + [b(')b(") . . .] := [ (a(') + b(')) (a(2) + d2)) . . .]. 
Relations (equals, greater than, etc.) are extended to the hyperreals by voting. For 
example, [ a ( l ) ~ ( ~ )  
. . .] 5 [b(1)b(2) 
. . .] if 
5 b(k) for most k. For all a, b E *R 
one and only one of the following three possibilities holds: a < b, a = b, or a > b. 
Perhaps we should dwell for a moment on the fact that a hyperreal number 
a = [ ~ ( l ) a ( ~ )  
. . .] is always below, equal to, or above another hyperreal number 
b = [b(1)b(2) . . .] : a < b, a = b, or a > b. Obviously some of the 
can be above 
b(k), some equal to b(", and some below b(k). But the set of k satisfying one these 
three conditions is in U and outvotes the other two. 
We do not distinguish hyperreals a and b such that a = b. Technically, this 
means that a hyperreal is an equivalence class of sequences rather than an individual 
sequence: [ ~ ( l ) a ( ~ )  
. . .] is the equivalence class containing ~ ( l ) a ( ~ )  
. . . . 
For each A C R we denote by *A the set of all hyperreals [a(k)] 
with a(') E A for 
all k. We embed A into *A by identifying each a E A with [a, a, . . .] E *A. 
We say that a E *R is infinitesimal if la1 < t for each real t > 0. The only real 
number that qualifies as an infinitesimal by this definition is 0. We say that a E *R is 
infinitely large if a > C for each positive integer C, 
and we say that a E *R isfinite 
if a < C for some positive integer C. 
We write a M b when a - b is infinitesimal. For every hyperreal number a E *R 
there exists a unique standard number st(a) (its standardpart) such that a M b. 
The representation of the hyperreals as equivalence classes of sequences with 
respect to a nontrivial ultrafilter is constructive only in a relative sense, because 
the proof that a nontrivial ultrafilter exists is nonconstructive; no one knows how 
to exhibit one. However, the representation provides an intuition that helps us 
think about hyperreals. For example, an infinite positive integer is represented by a 
sequence of positive integers that increases without bound, such as [l, 2,4, . . .], and 
the faster it grows the larger it is. 
Whereas there are canonical ways to construct rational numbers from integers 
and real numbers from rational numbers, the construction of hyperreals from reals 
depends on the arbitrary choice of a nontrivial ultrafilter. This has been one source 
of dissatisfaction with nonstandard analysis. However, the continuum hypothesis 
implies that the choice of the ultrafilter is irrelevant: if the continuum hypothesis 
is adopted as an axiom, then all systems of hyperreal numbers are isomorphic as 
ordered fields ([ 1361, p. 33). 
Games and Strategies 
The simplest notions of nonstandard analysis introduced in the previous subsection 
suffice to formalize our informal exposition in the bulk of the chapter. In this 
subsection we will explain how this formalization is done. 

11.5: APPENDIX: ELEMENTS OF NONSTANDARD ANALYSIS 
285 
At the beginning of this chapter we fixed a positive real number T and an infinitely 
large positive integer N; 
let 
For each natural number k. set 
To each k corresponds a “finitary framework” (which we will call the k-finitary 
framework), where the time interval is the finite set T(k) rather than the infinite 
set T. The “limit” (formally, ultraproduct) of these finitary frameworks will be the 
infinitary framework based on T; 
as in the previous subsection, this “limit” is defined 
as follows: 
0 An object in the infinitary framework, such as strategy, should be defined as 
a family of finitary objects: for every k, an object in the k-finitary framework 
should be defined (cf. the definition of hyperreals in the previous subsection). 
0 Functionals defined on finitary objects are extended to infinitary objects term- 
wise, analogously to the previous subsection. (By “functionals” we mean 
functions of objects of complex nature, such as paths or strategies.) 
0 Relations (in particular, properties) are defined by voting (again as in the 
previous subsection). 
(In nonstandard analysis such limiting infinitary structures are called hyperfinite.) 
This defines the procedure of “translation” of the informal statements into the 
formal nonstandard framework. Let us first consider some random examples of 
infinitary objects. The Bachelier game is a family of finitary games indexed by 
k = 1,2, . . .; finitary game k is obtained from the protocol given in 11.2 by replacing 
N with N ( k ) .  A strategy in the infinitary game is actually a set of strategies indexed 
by k in the finitary games; it should specify, for any k and n = 0,. . . , N ( k )  - 1, 
two functions, M(’)(So, DO,. . . , S,, Dn) and V(k)(S~, 
DO,. . . , S,, Dn). A path 
(such as S and D in the theorems) in the infinitary game is a sequence, indexed by 
k ,  of finitary functions (i.e., functions defined on TI’(’))); for example, in the case of S 
every finitary function S(k) is just declared by Market as the values Sik) in the kth 
protocol. 
Now let us consider examples of infinitary functionals. Sum (1 1.1) is interpreted 
term by term: if N = “(‘))I, 
then (1 1.1) is the hyperreal 

286 
CHAPTER 1 I: GAMES FOR PRICING OPTIONS IN CONTINUOUS TIME 
Analogously, the sum in (1 1.7) is also interpreted term by term; namely, as the 
hyperreal 
where, as usual, S, = S ( T L T / N ( ~ ) )  
and D, = D(nT/N(’)). The functionals in the 
definition of continuous and relatively continuous functions are of course understood 
term-wise, as the positive hyperreals 
sup 
t€T(”\{T} 
p ) ( t  + dt) - f‘”(t)l, k = 1,2,. . . , 
and 
, k =  1 , 2  ,.”, 
f ( k )  (t + dt) - f (k) ( t )  
tE%(k)\{T} 
sup 
1 
f‘”(t) 
respectively (of course, in the finitary frameworks sup can be replaced by max). A 
function is continuous or relatively continuous, respectively, if this positive hyperreal 
is infinitesimal. 
And finally, examples of relations (actually, properties). The most important 
examples are, of course, Theorems 1 1.1 and 1 1.2 themselves. Theorem 1 1.1, for 
example, asserts that, for every E ,  there exists a strategy in the infinitary game 
replicating the European option’s payoff with accuracy E .  In the proof we actually 
constructed such a strategy: it is obvious how our construction works for every 
finitary game k ;  this family of finitary strategies indexed by k determines the desired 
infinitary strategy (it will replicate the European option with accuracy t for most k). 
At this point it is very easy to demonstrate that the finitary propositions 10.2 
and 10.3 of the previous chapter imply the theorems 11.1 and 11.2 of this chapter; 
this is a very special case of the general transfer principle briefly discussed above. 
Let us consider, for concreteness, the Bachelier formula. Suppose a play of the game 
satisfies vexS 5 2 and vex D < 2. For any real 6 > 0, (10.8) will be satisfied for 
S = S(k) and D = D(’) and most k (take any 0 < t < 2 - vexD). Proposition 10.2 
asserts the existence of a k-finitary strategy that reproduces the European option with 
accuracy 6cS1I4, which can be made arbitrarily small. 
The above construction of the “infinitary structure” on “from the finitary structures 
on 
is an informal version of the ultraproduct (see, e.g., [ 11 11). The use of 
ultraproducts goes back to work by Godel and Skolem in the 1930s. The first 
systematic study and the transfer principle for ultraproducts is due to the Polish (born 
in Lviv) mathematician Jerzy tog, in a paper published in 1955, before the invention 
of nonstandard analysis in 1960. Only this precursor of nonstandard analysis is really 
used in this book. 

11.6: APPENDIX: ON THE DIFFUSION MODEL 
287 
(W((n + l ) T / N )  - W(nT/N))’ - T 
11.6 APPENDIX: ON THE DIFFUSION MODEL 
2 E 
From an intuitive point of view, it is obvious that the variation exponent, as we have 
defined it in this chapter, is identical with the 2-variation as it is usually defined in the 
theory of stochastic processes, and so it follows that paths of diffusion processes will 
have a variation exponent of two almost surely. Rigorous verification of this intuition 
requires some work, however, because of differences between the measure-theoretic 
and game-theoretic frameworks and between standard and nonstandard definitions. 
In the first two subsections, we relate the definitions of p-variation and variation 
exponent that we used in this chapter to definitions used in the standard diffusion 
model-that 
is, the diffusion model as it is defined using standard rather than non- 
standard analysis. In the third subsection, we relate our definitions to definitions that 
have been used for the nonstandard diffusion model. 
The d d t  Effect in the Standard Diffusion Model 
The first three propositions of this subsection confirm that a path of the diffusion 
model will almost surely have a variation exponent equal to two. This is intuitively 
obvious because of the similarity between our definition of the 2-variation vars (2) 
and the usual definition of optional quadratic variation [S, S](T). But the proofs are 
not quite trivial, partly because of the mismatch between our nonstandard treatment of 
the game-theoretic approach and this subsection’s standard treatment of the measure- 
theoretic approach. The final subsection of the appendix covers the same ground 
in a cleaner but more demanding way, by making the comparison between our 
nonstandard game-theoretic approach and a nonstandard version of the measure- 
theoretic approach. 
Proposition 11.3 The path W :  [0, T ]  -+ IR of a standard Wiener process satisfies 
vex W = 2 almost surely. Moreover; varw(2) M T almost surely. 
Proof Let E > 0 be arbitrarily small. For each N = 1,2,. . ., we have 
(11.17) 

288 
CHAPTER 11: GAMES FOR PRICING OPTIONS IN CONTINUOUS TIME 
only for finitely many N; therefore, I varw (2) - TI < E almost surely. Since E can be taken 
I 
arbitrarily small, varw (2) z T almost surely. 
Proposition 11.3 is a nonstandard version of a result in Paul LCvy 1937. 
The following lemma is obvious now: 
Proposition 11.4 The path S :  [0, T ]  + R of the diffusion process governed by (9.2) 
satisfies vex S = 2 almost surely. 
Now we extend this result to the (standard) Black-Scholes model. 
Proposition 11.5 The path S: [0, TI + R of the diffusion process governed by (9.4) 
satisfies vex S = 2 almost surely. 
(1 1.18) 
for a standard Wiener process W ,  we have: 
dS(t) = S ( t ) e ( ~ - " 2 / 2 ) d t + " d w ( t )  - S(t) 
= S(t) 
, e ( t ) ( ( ~ - a Z ' 2 ) d t + " d W ( t ) ) ( ( p  - u2/2)dt + udW(t)) x ( p  - a2/2)dt + udW(t), 
where O(t) E (0,l) and a(t) =: b(t) means that la(t)l 5 Clb(t)l and Ib(t)l 5 Cla(t)l for 
some positive constant C (maybe, dependent on the path S(t)). Therefore, 
vars(2) x C ( ( p  - a2/2)dt + odW(t))2 
t 
= ( p  - 2 / 2 ) 2  C(dt)2 
+ 2(p - a2/2)a C d t d W ( t )  + u2 C(dW(t))2 
t 
t 
t 
z u2varw(2), 
t ranging over T \ {T}, and Lemma 11.3 on p. 287 shows that, with probability one, vars(2) 
is neither infinitesimal nor infinitely large. 
I 
Generalizing Propositions I 1.4 and 1 I .5, it is natural to expect that almost all paths 
of a regular continuous semimartingale S will satisfy vex S E { 1,2} (vex S = 1 
corresponding to a trivial martingale component) and 
vars(2) = [S, SI(77 = (S, S ) ( T )  
(cf. [158], Theorems 1.4.47 and 1.4.52, and Lepingle's result, discussed on p. 290). 
the Bachelier and Black-Scholes models, respectively. 
Proposition 11.6 (Bachelier derivative) Let the derivative security 2) pay a divi- 
dend of (dS(t))2 
at the end of each interval [t, t + dt], t E T \ { T } ,  where S(t) is 
governed by (9.2). With probability 1, the total amount of dividendspaid by D during 
every time interval [tl, ta], 0 5 tl < t2 5 T, is infinitely close to a2(t2 - tl). 
Proof First we consider fixed tl and t 2 .  We can assume that the dividend paid by 2, at the 
end of each [t, t + dt] is (crdW(t))2, where W ( t )  is a standard Wiener process. Analogously 
The next two propositions assert the uselessness of the derivative security D in 

11.6: APPENDIX: ON THE DIFFUSION MODEL 
289 
to(11.16)and(11.17),wehave,forany~ > OandfromsomeNon, 
Again applying the Borel-Cantelli lemma, we obtain that the total amount of dividends paid 
during [tl, t z ]  is a2(tz - t l )  to within E, almost surely; since E can be arbitrarily small, it is 
infinitely close to 0 2 ( t z  - tl), almost surely. 
Now it is clear that for almost all paths S(t) the total amount of dividends paid by V during 
[ t l , t z ]  is infinitely close to a 2 ( t 2  - t l )  for all rational t 1 , t Z  E [0, TI, tl < t 2 .  Consider 
a path S(t) satisfying this property; let t 1 , t z  E [O,T], tl < t z ,  be not necessarily rational. 
Since tl and t z  can be arbitrarily accurately approximated from below and from above by 
rational numbers, the total amount of dividends paid by V during [tl, tz] is infinitely close to 
a2(tz - tl). 
I 
Proposition 11.7 (Black-Scholes derivative) Let the derivative security D pay a 
dividend of(dS(t)/S(t))2 
at the end ofeach interval [t, t + dt], t E T \ {T}, where 
S(t) is governed by (9.4). With probability I ,  the total amount of dividendspaid by D 
during every time interval [tl, tz], 0 5 tl < t 2  5 T, is infinitely close to o2 
( t 2  - tl). 
Proof First we consider fixed tl and t z .  It is easy to see that we can assume that the dividend 
paid by V at the end of each [t, t + dt] is (adW(t))’ rather than (dS(t)/S(t))’, where W(t) 
is the standard Wiener process satisfying (1 1.18). This puts us in the same position as in the 
I 
proof of Proposition 11.6, and we can use the same argument. 
Propositions 1 1.6 and 1 1.7 immediately imply that in the case where the derivative 
security 2) is traded in an arbitrage-free market its price D(t) (as usual in probability 
theory, we assume that D(t) is continuous from the right) satisfies D(t) = oz (T - t )  
almost surely and, therefore, vex D = 1 almost surely. 
Strong p-variation 
We now turn to an alternative approach to the variation exponent that is popular in 
the measure-theoretic literature. Let f be a (standard) real-valued function defined 
on the interval [0, TI. Its strong p-variation, for p > 0, is 
n 
==f(P) := S U P C  If(ti) - f(ti-l)I” , 
i=l 
where n ranges over all positive integers and K over all subdivisions 0 = to < tl < 
. . . < t, = T of the interval [0, TI. For any function f there exists a unique number 
vex f such that iCEf (p) is finite when p > VET f and infinite when p < K
E
 f .  This 
is true for all functions f, although i%Zf can be finite only for functions that are 
~ 

290 
CHAPTER 11: GAMES FOR PRICING OPTIONS IN CONTINUOUS TIME 
regulated-that 
is. have left and right limits everywhere. We are mainly interested 
in the case where f is continuous and not constant. 
Lemma 11.4 r f  f : [0, T ]  -+ R is continuous and not constant, vex f 5 Ti5 f. 
Proof For any p >_ 1 and any continuous f : [0, T ]  + W, 
varf ( p )  = 00 implies Wf ( p )  = 
I 
Lepingle 1976 showed that VET f 5 2 for almost all paths f of a semimartingale; 
therefore, vex f 5 2. This shows that the processes with vex f > 2 are beyond the 
reach of the general theory of stochastic processes, which is based on the notion of a 
semimartingale. 
The analog for the result of the previous subsection that vex W = 2 for almost all 
paths of the Brownian motion is that 
W = 2 for almost all paths of the Brownian 
motion (Levy 1940). For the boundary valuep = 2, Levy proved that K%iFw (p) = 03 
almost surely; moreover, 
03; it is also obvious that Wf ( p )  = 03 when p < 1 since f is not a constant. 
n. 
is infinite almost surely, where Kd is the set of all finite partitions IC = (0 = to < 
. . . < tn6 = T }  whose mesh is less than 6: max Iti - ti-1 I < 6. This result found 
a beautiful continuation in Taylor (1972): 
for 
almost surely 
Recall that a fractional Brownian motion with index h E (0,l) is a continuous 
zero-mean Gaussian process Bh(t) whose increments Bh(t) - B ~ ( s ) ,  
where 0 5 
s 5 t, have variance (t - s ) ~ ~ .  
As shown by Kawada and K6no [167], 
Bh 5 l / h  
almost surely, with equality when h 5 0.5. This implies that vex Bh 5 l / h  almost 
surely. Comparing this result with our requirement (implicit in Theorem 11.2) 
vexS 5 2, we see that fractional Brownian motions with h < 0.5 may be too 
irregular even for our methods for the Bachelier and Black-Scholes formulas. See 
also [132, 1671. 
The d d t  Effect in the Nonstandard Diffusion Model 
The comparison of the game-theoretic and measure-theoretic approaches to the vari- 
ation exponent becomes transparent if we do it entirely in terms of nonstandard 
analysis. 
Before we can proceed, we need to discuss the key notion of internal objects 
in nonstandard analysis. Intuitively, internal sets, functions, measures, and so on, 

11.6: APPENDIX: ON THE DIFFUSION MODEL 
291 
can be defined in terms of sequences of standard objects of the same nature; this 
makes them tame, unlike the unmanageable external objects (i.e., objects that are not 
internal). For example, an internal subset Y of a standard set 2 can be defined to 
be a sequence [Y(')] of subsets Y(') C: 2; 
a nonstandard object [.(')I 
E '2 is in 
Y if and only if z(') 
E Y(') for most 5. Similarly, an internal function f on 2 is a 
sequence [f'')'] of standard functions f(') : 2 + Iw; internal functions are applied 
to elements of '2 term by term. We can also define internal objects for nonstandard 
domains such as T; 
for example, an internal function f on T is a sequence [f'')'] of 
functions f(') : T(') -+ R. 
The nonstandard treatment of Brownian motion (Anderson 1976) uses an impor- 
tant property of internal sets called countable saturation. This property is the key 
element in constructing the Loeb measure on the set of internal functions on T; 
the 
next theorem will be applied to internal subsets of T, but it is true in great generality 
and we denote by X the set whose internal subsets are considered. 
Saturation Theorem The following proper9 of countable saturation holds: the 
intersection of a decreasing sequence 
of nonempty internal sets in X is always nonempty. 
In this theorem, the relation [A('))] 2 [@'))I 
means, of course, that A(') 2 B(') for 
most of k .  For its proof (just a simple diagonalization argument) see, for example, 
Goldblatt [136], p. 138. 
In 1975 Peter Loeb introduced what is now known as the Loeb measure. Let Y be 
a finitely additive nonstandard (which just means "taking values in *EX+", where lR+ 
is the set of nonnegative reals) measure on an algebra of internal subsets of X .  Let 
st v be the composition of st and v (i.e., (st v)(A) is defined as st(v(A))); because 
of the saturation theorem, st v (as well as v) will automatically be a-additive (and, 
in general, taking values in [O,co] rather than [ O , c o ) ) .  This allows one to apply 
CarathCodory's extension theorem (see, e.g., [347] or [25]) to define a a-additive 
extension L, of st v to the smallest a-algebra containing the initial algebra on which 
v is defined (such an extension is unique if v only takes finite values; this will be the 
case in our applications). This extension L, is called the Loeb measure on X .  
The Loeb measure was used by Anderson (1976) to define a measure, analogous 
to the Wiener measure, on the set of internal functions on T. First we introduce some 
specific internal measure v = [v'')] 
on the internal functions on T: for any 5, v(') 
is the uniform distribution on the set 
{fjO,jI ,..., j N ( k )  I j O , j l , .  . . , j N ( " )  E {-I, I}} 
(11.19) 
of all functions defined by 

292 
CHAPTER 11: GAMES FOR PRICING OPTIONS IN CONTINUOUS TIME 
for any internal set A = [A(')], 
where each A(k) is a subset of (11.19), v(A) is 
defined to be the hyperreal [v(')(A(~))]. 
It is obvious that v is finitely additive. Let 
L, be CarathCodory's extension of st v (Loeb measure). The image P of L, under 
the mapping f ++ st f is a measure (actually a probability distribution) on the set of 
all functions of the type [0, T ]  + [-m, co]. 
This is Anderson's construction of the standard (i.e., variance T )  Brownian motion 
on [O,T]. He proves the following results about his construction ([6], Theorems 26 
and 27, Corollary 28): 
0 P-almost all functions f : [0, T ]  + [-co, m] are continuous and finite. 
0 The restriction of P to the continuous functions f : [0, TI + R (equipped with 
the usual g-algebra) is the standard Wiener measure. 
Propositions 11.3-1 1.7 are trivial under this construction. Under Cutland's vari- 
ant [71], where the jumps f l  are replaced by Gaussian jumps, they are less trivial 
but still can be proven very easily. 

12 
The Generality of 
Game-Theoretic Pricing 
In this chapter, we demonstrate the scope and 
flexibility of our purely game-theoretic ap- 
proach to option pricing by extending it in 
several directions. We show how to handle 
interest rates. We show that the dividend- 
paying derivative that we have used for Black- 
Scholes pricing can be replaced with a more 
conventional derivative. And we show how to 
deal with the case where there can be jumps in 
the price process for the underlying security. 
Interest rates are in the picture from the 
outset in most expositions of stochastic Black- 
Scholes pricing-including 
the original ex- 
position by Black and Scholes in 1973. And 
aside from a minor adjustment in the dividend 
paid by our security D, there is no concep- 
tual difference between the way they enter the 
stochastic picture and the way they enter our Robert c. Menon (born 1944). He was 
picture. We have chosen to leave them aside 
the first to understand and exploit fully 
until now only in order to make our exposition 
the game-theoretic nature of stochastic 
as simple and Clear as possible. In 3 12.1 W e  Black-Scholes pricing. 
correct the omission. 
In $12.2, we show that the dividend-paying security D we use in game-theoretic 
Black-Scholes pricing can be replaced with a European option R, 
which pays off 
293 
Probability and Finance: It’s Only a Game! Glenn Shafer, Vladimir Vovk 
Copyright 0 2001 John Wiley & Sons, Inc. 
ISBN: 0-471-40226-5 

294 
CHAPTER 72: THE GENERALlTY OF GAME- JHEORETlC PRlClNG 
only at its maturity T .  Many different European options might play the role of R: 
the main requirement is that R’s payoff at T be a strictly convex function of the price 
at T of the underlying security S. The simplest choice is to have R pay the square 
of S’s price at T .  In any case, we can infer from the current price of R an implied 
price for our dividend-paying security ’D, and this suffices for purely game-theoretic 
pricing of other derivatives with maturity T .  Unfortunately, calls and puts, which 
now constitute the bulk of options that are traded, are not strictly convex and can 
hardly serve our purpose. This suggests a market reform that might be both feasible 
and useful: the market might be more liquid and efficient if calls and puts were 
replaced by a strictly convex derivative. 
We deal with jumps in $ 12.3. The established stochastic theory uses the Poisson 
process to model jumps, just as it uses geometric Brownian motion to model contin- 
uous price processes. Our game-theoretic analog involves marketing an instrument 
that pays dividends when market crashes occur-an 
insurance policy similar to the 
weather derivatives used to insure against extreme storms. Our treatment of jumps, 
like the usual stochastic treatment, is in continuous time. This demonstrates the 
generality of our mathematical framework for continuous time, but it also means, 
from a practical point of view, that our results are only preliminary. Putting them into 
practice will require discrete-time analyses along the lines sketched in Chapter 10 for 
the game-theoretic Bachelier and Black-Scholes protocols. 
In an appendix, $12.4, we review the theory of stable and infinitely divisible 
probability distributions, which is related to the stochastic pricing of discontinuous 
processes and contains ideas that could lead to additional game-theoretic methods. 
12.1 THE BLACK-SCHOLES FORMULA WITH INTEREST 
In this section, we explain how interest rates can be taken into account in game- 
theoretic Black-Scholes pricing. We rely on an argument that has also been used in 
stochastic option-pricing theory: 
0 our reasoning ignoring interest rates is correct if all prices are measured relative 
to a risk-free bond, and 
0 formulas in which prices are expressed in dollars, say, can be derived from the 
formulas in which the prices are expressed relative to the risk-free bond. 
One point does arise, however, that does not arise in the stochastic theory: we need to 
adjust the dividend paid by 2, at the end of each period to take account of the bond’s 
change in value during the period. 
What Difference Does Interest Make? 
How are interest rates relevant to the game-theoretic hedging problem? Indeed, how 
have we used the assumption that the interest rate is zero? 

12.1: THE BLACK-SCHOLES FORMULA WITH INTEREST 
295 
When we look at our protocols for Black-Scholes pricing, we see that the need 
to consider interest enters only when we consider the rule for updating Investor’s 
capital. Consider our protocol for purely game-theoretic Black-Scholes pricing in 
discrete time, on p. 249 of § 10.3. The rule for updating Investor’s capital that appears 
there can be written in the form 
1, := 
- M,S,-l 
- V,D,-1) 
(12.1) 
The first term on the right-hand side, 1,-1 - M,S,-l 
- VnDn-l, is Investor’s net 
cash position during the nth round of trading. If interest is paid on money during the 
nth round at nonzero rate T,, then this term should be multiplied by 1 + T,, in order 
to account for the interest that Investor pays (if his net cash position is negative) or 
receives (if it is positive). The second term, M,S, + V,D,, is the net cash Investor 
receives or pays when he liquidates his position at the end of the round; this is not 
affected by the interest rate, except insofar as the Market might take it into account in 
setting the prices S, and D,. The final term, V,(AS,/S,-1)2, represents Investor’s 
dividends from holding V, shares of the security D. This is also unaffected by the 
interest rate, but as we will see shortly, we need to change the dividend (AS,/S,-1)2 
in order to replicate the option IA. 
+ (MnS, + V,&) + vn(As,/sn-l)2. 
Using a Risk-Free Bond as Numbraire 
Our first step is to recognize that all our reasoning concerning the game-theoretic 
Black-Scholes protocol, in both the discrete and continuous cases, is valid if all prices 
are measured relative to a risk-free bond B which is priced by the market and whose 
changes in value define the interest rate. 
Let us assume that a unit of B pays $1 at maturity (the end of round N )  and costs 
B, at the end of round n. Let us also assume that the interest rate for Investor is 
defined by the changes in B’s value: 
B, - B,-1 - AB, 
___ 
r, := 
- 
B,-1 
Bn-1. 
Investor begins with capital zero. We assume that he pays interest at the rate T ,  if 
he needs to borrow money during period n and that he draws interest at this rate 
on any spare cash that he does not use during period n. In theory (i.e., neglecting 
transaction costs), he can do this by investing all spare cash in B and borrowing any 
money that he needs by going short in B. We can then say that his strategy involves 
trading in three securities: the underlying security S, the derivative security D, and 
the risk-free bond B. 
When we make the role of B explicit in the protocol for discrete Black-Scholes 
pricing on p. 249, we obtain the following: 
A DISCRETE BLACK-SCHOLES 
PROTOCOL WITH A RISK-FREE 
BOND 
Parameters: N ,  1, > 0,s E (0, l), C > 0 

296 
CHAPTER 12: THE GENERALITY OF GAME-THEORETIC PRICING 
Players: Market, Investor 
Protocol: 
Market announces BO > 0, SO > 0, and DO > 0. 
FORn= 1, ..., N: 
Investor announces M ,  E R and V, E E%. 
Market announces B, > 0, S, E JR and Dn 2 0. 
(12.2) 
Additional Constraints on Market: Market must satisfy the constraints on S, and 
D,, stated in the protocol on p. 249 and must also satisfy BN = 1. 
The first line of the rule for updating Investor’s capital I, is different from the first line 
in (12.1) because of the interest paid; we now multiply Investor’s net cash position 
by Bn/Bnp1, 
or 1 + T,, to reflect the payment of interest. The third line is different 
because we are changing the dividend paid by the security V. 
We now have V pay 
the dividend 
(12.3) 
at the end of period n, instead of (ASn/Sn-1)’. Typically (12.3) will be approxi- 
mately equal to B,(AS,/S,-1 
- T,)’. 
Let us now re-express (12.2), the rule for updating Investor’s capital, with the 
capital and prices measured relative to B,, the current price of the bond. We use a 
dagger for quantities measured in this nume‘ruire: 
2 
which is exactly the same as (12.1) except for the presence of the daggers. In other 
words, our new protocol reduces to Chapter 10’s protocol for Black-Scholes when 
we measure prices and capital relative to the bond. The dividend (12.3) is chosen, of 
course, to make this happen. 
Because BN = 1, the shift from pricing in dollars to pricing relative to the risk- 
free bond makes no difference in how we describe a European option U with maturity 
at the end of period N ;  its payoff function U gives its price relative to B, which is the 
same as its price in dollars, and this price can be described as U ( S ( T ) )  
or U(St (T)); 
the two are the same. So Theorem 10.3, applied to the protocol in which prices are 
measured relative to B, tells us that the initial price of U relative to B is approximately 

12.1: THE BLACK-SCHOLES FORMULA WITH INTEREST 
297 
To obtain the initial price of U in dollars, UO, we multiply this expression by Bo: 
or 
(12.4) 
Dollar Pricing in Discrete Time 
We can simplify the expression (12.4) slightly by rescaling the derivative security D. 
Indeed, if we divide the dividend (12.3) by Bo, then Market will divide the price of 
2) at all times by Bo, thereby eliminating the need to introduce this divisor in the 
mean and variance of the Gaussian distribution in (12.4). So we have the following 
result, which we state informally: 
Black-Scholes Formula with Interest; Discrete Time Suppose Marketprices a se- 
curity S, a bond t? that pays $1 at maturity N ,  and a derivative security D that pays 
the dividend 
2 
(12.5) 
at the end of period n for n = 1, . . . , N .  And suppose U is a European option that 
pays $U(SN) at the end ofperiod N .  Then after Market has announced the prices 
$5'0, $Bo, and $DO, Investor can approximately replicate U starting with the initial 
capital 
$-(---) 
B:-I 
AS, 
ABn 
BoBn 
Sn-1 
Bn-1 
Dollar Pricing in Continuous Time 
When we pass to continuous time, t = (n - l ) d t ,  the expression (12.5) becomes 
where ~ ( t ) d t  
corresponds to the discrete-time T ,  (since dt is now infinitesimal, we 
prefer to deal with the "annualized" rate of return ~ ( t ) ) .  
So our informal result for 
continuous time reads as follows: 
Black-Scholes Formula with Interest; Continuous Time Suppose Market prices 
a security S, a bond B that pays $1 at maturity T, and a derivative security 2) that 
pays the continuous dividend 

298 
CHAPTER 72: THE GENERALITY OF GAME-THEORETIC PRICING 
And suppose U is a European option that pays $U(S(T)) at maturity T. Then 
after Market has announced the prices $S(O), $B(O), and $D(O), Investor can 
approximately replicate U starting with the initial capital 
When the interest rate is constant, say equal to r, B(t) = e-r(T-t). In this case 23’s 
continuous dividend is 
and the Black-Scholes price for U at time 0 is 
12.2 BETTER INSTRUMENTS FOR BLACK-SCHOLES 
Although the dividend-paying derivative D plays a fundamental theoretical role in 
game-theoretic Black-Scholes pricing, it has potentially fatal practical disadvantages. 
In this section, we show how it can be replaced in practice with a European option 
R. The replacement proceeds in a way that is familiar from stochastic option-pricing 
theory. Assuming that the market prices R, we find the price for 2) implied by R’s 
price. Then we price any other option U as if this price for 2) had been determined 
directly by the market, and we hedge the price of U by trading in S and R. 
By pricing R with a range of different maturities, the market would indirectly 
determine prices for ’D for a range of maturities, thereby allowing us to price all 
European options. In the current situation, where puts and calls are the options most 
often directly priced from the market, similar efforts are often made to price other 
options from these puts and calls, but these efforts lack the theoretical grounding of 
our proposal, and they are also less practical, because a doubly indexed array of puts 
and calls is required for effective pricing; we must have prices for puts and calls not 
only for a range of maturities but also for a range of strike prices. Our proposal, if 
implemented, would concentrate market activity on a single instrument with a range 
of maturities, thereby producing more reliable prices for this instrument and a more 
efficient and liquid market overall. 
Difficulties with the Dividend-Paying Derivative 
Before explaining our replacement for the dividend-paying derivative 23, let us pause 
to note the nature of the difficulties that would be involved in trading V. 
The derivative D is supposed to pay the dividend (dS(t)/S(t))2 
at the end of the 
period from t to t + dt. This raises several questions. Most importantly: 
1. What should dt be? One day? One hour? One week? 

12.2: BETTER lNSTRUMENTS FOR BLACK-SCHOLES 
299 
2. How is the price of S at the end of each period defined? By biddoffers or by 
actual trades? 
Possible answers to the second question raise further questions about possible biases 
and, most importantly, about the potential for manipulation by brokers and large 
traders. If S(t) is defined in terms of actual trades, the dividends paid by D might 
be excessively high, because sell orders are executed at a price lower (by the margin) 
than buy orders. And anyone with discretion over the timing of transactions might 
affect the dividend (dS(t)/S(t))’ by pushing a transaction to one side or the other 
of the time boundary d + dt. 
In addition to these issues, there are also practical problems in crediting dividends 
for units of D that change hands rapidly. It is conceivable that all these problems 
can be resolved, but the results of this section show that they do not really need to be 
addressed. 
Black-Scholes with the Square 
Consider a European option R with payoff function R : R -+ Iw; R pays R(S(T)) 
at maturity T .  If our variance derivative 2) were traded by the market, then the price 
R at time t would be given by our game-theoretic Black-Scholes formula: 
R(t) = 
R(s(t)ez) 
N--D(t)/2,D(t)(dz). 
(12.6) 
If D is not actually priced by the market, but R is, and if the function R is well-enough 
behaved that we can solve (12.6) for D(t), then we call the solution D(t) the implied 
remaining variance of S at time t. We will emphasize the example where R is the 
square of S: R(s) := s2. In this case, R’s price is 
i 
and this can be solved analytically; the implied remaining volatility at time t is 
(12.8) 
As we will show, D(t) can then be used to price another European option U with 
payoff function U using our usual game-theoretic Black-Scholes formula: 
(12.9) 
This works under the usual constraints on the paths S(t) and D(t). 
This price for U can be hedged by trading in S and R. 
From time t to t + dt, we 
hold 
( 1 2.1 0) 

300 
CHAPTER 12: THE GENERALITY OF GAME-THEORETIC PRICING 
units of S and 
(12.11) 
units of R, 
where, as usual, 
This recipe for pricing and hedging a security IA is similar to but distinct from recipes 
that have emerged from models for stochastic volatility; see p. 229. 
The following protocol formalizes the assumption that Investor can trade in both 
S and R: 
THE BLACK-SCHOLES 
PROTOCOL FOR THE SQUARE 
Players: Investor, Market 
Protocol: 
10 := 0. 
Market announces SO > 0 and Ro > 0. 
F O R n =  1,2, ..., N :  
Investor announces Ad, E JR and V, E EX. 
Market announces S, > 0 and R, 2 
0. 
Zn := Zn-1 + MnAS, + VnAR,. 
Additional Constraints on Market: Market must ensure that S is continuous, 
inf, S, is positive and not infinitesimal, and SUP, S, is finite. He must also ensure 
that the process D,, defined by D, = ln(R,/S:) 
is continuous and satisfies D, > 0 
for n = 0,1,. . . , N - I, DN = 0, SUP, D, is finite, and vex D < 2. 
Theorem 12.1 Suppose U :  E% -+ JR is a smooth European option with all derivatives 
(including U itseEfl bounded. Then the price for U(S(T)) in the Black-Scholes 
protocol for the square just after S(0) and R(0) 
are announced is 
(12.12) 
where D(0) := ln(R(0)/S2(0)). 
Proof (Sketch Only) It suffices to show that if Investor starts with initial capital (12.12) and 
follows the strategy given by (12.10) and (12.11), then his capital at time t will be infinitely 
close to (12.9). Using Taylor's formula and the fact that v satisfies the Black-Scholes equation, 
we obtain a simplified version of (6.20): 
a77 
au 
dQ(S(t), D(t)) = +S(t)> D(t))dS(t) + &S(t), D(t))dD(t) 
= -(S(t),D(t))dS(t) 
dS 
+ &W),W) 
1 a2Q 
+ Z ~ ( " ( " ) ' D ( " ) ( d " ( t ) ) 2  
(12.13) 
aT7 
aTI 

12.2: BETTER INSTRUMENTS FOR BLACK-SCHOLES 
301 
(where M stands for equality to within O((dt)3/2)). 
For R, 
we similarly obtain 
Substituting (12.14) into (12.13) and summing over t, we find that the strategy of holding 
units of S and 
(12.16) 
units of R works if the approximations implicit in (12.13) are not too crude. Here ?Z is defined 
as usual: 
- 
~ ( s ,  
D )  := S, R(se2) N - D ~ ,  D(dz). 
In the case R(s) = s2 the strategy (12.15)-(12.16) reduces to (12.10)-(12.11). 
It is clear that the accumulated hedging error has the order of magnitude 
vars(3) + C IdD(t)lldS(t)l+ varn(2) 
5 vars(3) + (varo(p))l” (vars(q))’lq + varo(2), 
where p ,  q E (1, KI) are chosen to satisfy vex D < p ,  vexS < q and l/p + l/q = 1. So the 
assumptions vex D < 2 and vex S = 2 (as we know, the latter can be added without loss of 
I 
tET\{T) 
generality) imply that the accumulated error will be infinitesimal. 
The theorem is easily generalized to typical payoff functions, such as those for 
calls and puts, which can be arbitrarily well approximated with smooth functions 
with bounded derivatives. 
Implementation of our proposal should be based, of course, on a careful analysis 
of the error in discrete time, along the lines of our analysis of the Bachelier and 
Black-Scholes protocols in Chapter 10. 
Alternatives to the Square 
As we have indicated, the square can be replaced by a different strictly convex 
function R, and in some cases this may be desirable. This subsection consists of two 
parts: first we discuss possible implementations of the square and then we discuss 
more substantive alternatives. 

302 
CHAPTER 12: THE GENERALlTY OF GAME-THEORETIC PRIClNG 
The simplest alternative is to set R(s) := (s - a)2 for some real number a. Having 
the market price ( S ( T )  
-a)2 is obviously equivalent to having it price S2 (T), because 
(S(T) - .)2 = S y T )  - 2aS(T) + 2, 
and the market is already pricing S(T): its price for S(T) at time t is S(t). But at a 
practical level, trading in (S(T) - a)2 for a value a close to S’s current price may be 
more sensible than trading in S2(T), if only because ( S ( T )  - 
is easier to think 
about. Further “normalization” of the square can be achieved by defining the final 
payoff to be, say, 
(12.17) 
Notice that Equation (12.17) has exactly the same form as the dividends for D; 
the 
difference is that for D the dividends are paid very often and for the square, as 
represented by (12.17), there is only one dividend, at the maturity. 
Other convex (but not linear) functions provide more substantive alternatives; their 
advantage over the square might be a slower growth (exponential in the case of the 
square; see (12.7)) of R(t) as D(t) increases. In what follows we will exclude the 
trivial case of a linear payoff function from consideration. Convexity is sufficient for 
to be a strictly increasing function of D for fixed s; since this function will typically 
be continuous, (12.6) can be solved to obtain D(t). In Chapter 10 we studied 
the volatility path D(t) implied by call and put options. Whereas we believe that 
encouraging results obtained there show the feasibility of our approach to option 
pricing, calls and puts, with their piecewise linear payoffs, might be too awkward 
analytically to be used effectively for hedging in place of the square (for concreteness 
we are discussing a call): 
0 Formally, R(s, D) 
(as defined in (12.18)) is a convex function of s, but in reality 
it will be almost flat unless the call is nearly at-the-money (especially for small 
D). Therefore, to simulate the dividend-paying security D (see (12.14)) we 
will need a large amount of the call, which may make the transaction costs 
involved too heavy. 
0 Our hedging strategies require that the function R(s, D )  should be smooth and 
that its derivatives should be sufficiently well-behaved; this becomes a problem 
in the case of a call when D becomes small: in the limit as D + 0, the payoff 
is not smooth at all. 
Ideally, the payoff function R should be smooth and strictly convex (recall that a 
smooth function R is strictly convex if R”(s) > 0 for all s > 0). 

12.3: GAMES FOR PRlCE PROCESSES WITH JUMPS 
303 
12.3 GAMES FOR PRICE PROCESSES WITH JUMPS 
In this section, we consider protocols in which the price of the underlying security S 
is allowed to jump. We show that our methods can handle jumps if the market itself 
prices securities that pay dividends when jumps of different sizes occur. 
A fundamental tool for dealing with jumps is the Poisson distribution, which 
plays a role analogous to the role played by the Gaussian distribution for continuous 
processes. This distribution depends on a nonnegativeparameter D, equal to its mean. 
We write TD for the Poisson distribution with parameter D; it assigns probability 
D" 
D 
P D { Z }  := -e- 
z! 
(12.19) 
to each z E Z+. 
Here Z+ designates the set of all nonnegative integers, and 0' and 
O! are understood to equal 1. 
We begin by studying a continuous-time process S that consists purely of jumps, 
always of the same size. Such counting processes occur in many domains, but for 
concreteness, we imagine that S counts the number of hurricanes. As we show, a 
payoff that depends on the number of hurricanes between time 0 and time T can be 
priced by its expected value under (12.19) if 2) is the market price for a dividend- 
paying derivative that pays a dollar every time a hurricane occurs. 
We then turn to the case of two simultaneous counting processes, for both of which 
the market prices a dividend-paying security. In this case, a payoff that depends on 
both counting processes can be priced using two Poisson distributions, with means 
equal to the market prices for the two dividend-paying derivatives. The distributions 
are used as if they were independent, but the source of the independence is not 
stochastic; rather it lies in the fact that an investor can choose how many units of 
the one derivatiw he holds independently of how many units of the other he holds 
(combined with the requirement that the processes do not jump simultaneously). 
Finally, we turn to the problem of pricing an option on a security whose price can 
change continuously and can also jump. Combining what we know about the Bache- 
lier process with what we have learned about simultaneous counting processes, we 
propose having the market price separate dividend-paying securities for continuous 
volatility and jumps. This approach can be applied to Black-Scholes pricing with 
jumps, but for simplicity we only briefly discuss Bachelier pricing with jumps. 
Weather Derivatives 
Suppose S(t) is the number of hurricanes in the time interval [0, t], and suppose that 
as time proceeds, S(t) increases in distinct jumps, always by 1; if two hurricanes 
occur simultaneously, we count them as one hurricane. And suppose we want to price 
a European option U(S(T)). Such an option is an example of a weather derivative. 
Such derivatives are actually traded; they are used to hedge insurance policies against 
weather damage. (See, e.g., the web site of the Met Office, the British weather 
service.) 

304 
CHAPTER 72: THE GENERALITY OF GAME-THEORETIC PRICING 
We can price U ( S ( T ) )  
if the market prices a security 2) that pays the dividend 
0 if dS(t) = 0 
{ 1 if dS(t) = 1 
during each infinitesimal interval [tl t + dt]. 
In our protocol, Investor plays against Reality, who determines the hurricanes, 
and Market, who sets the price for 2). Investor is Player I and Reality and Market 
together are Player I1 (see 5 1.1). As always, prices are defined by Player 1's strategies 
and their capital processes. 
THE POISSON 
PROTOCOL 
Players: Investor, Market, Reality 
Protocol: 
10 := 0. 
s o  := 0. 
Market announces DO > 0. 
FORn= 112, ... ] N :  
Investor announces V, E R 
Reality announces z, 
E (0,l). 
Market announces D, 2 0. 
s, := s,-1 + 2,. 
1, := Z,-I + V, (z, + AD,). 
(12.20) 
Additional Constraints on Reality and Market: Reality must make SN < 03. 
Market must make the path D is continuous, with D, > 0 for n = I,. . . , N - 1, 
DN = 0, supn D ,  < 03, and vex D < 2. 
This protocol codes a hurricane as 1 and its absence as 0. Equation (12.20), as usual, 
takes into account both the dividend z, 
and capital gain D, - D,-I 
for each of the 
V, shares of 2). 
Proposition 12.1 Suppose the function U :  Z+ -i 
R+ satis$es the growth condition 
(12.21) 
3c > o : u ( ~ )  
= o(c5). 
Then the price for a European option U(S(T)) 
at the time when D(0) has just been 
announced in the Poisson protocol is 
Proof We will find a strategy V such that 
(12.22) 

12.3: GAMES FOR PRlCE PROCESSES WITH JUMPS 
305 
for s = 0, 1, . . . and D 2 0. Equation (12.22) can be rewritten as 
- 
U(S(O),D(O)) 
+ Z V ( S , D )  = U(S(T),D(T)). 
(12.23) 
It can be checked by direct differentiation that T7 satisfies, for D > 0, 
( 1 2.24) 
(According to Leibniz’s differentiation rule for integrals, (12.21), which implies U ( s )  = 
o(E’s!), Ve > 0, is a sufficient condition for the differentiation to be valid.) 
aG 
-(sl 
D )  = U(s + 1, D )  - U(s, D). 
d D  
ou; strategy is simply 
(exactly as in the Black-Scholes case, except that no shares of S are bought). Using Taylor’s 
formula, we find fort E T \ (2’): if dS(t) = 0, 
(as usual, 0 stand for different numbers in (0, I)), and if dS(t) = 1, 
du(S(t), D(t)) = (u(s(t) 
+ 1, D(t)) - U(S(t), 
D(t))) 
+ (U(S(t) + 1, D(t) + dD(t)) - V(S(t) + 1, D ( t ) ) )  
d D  
(12.26) 
au 
au 
= -(S(t), D(t)) + a , ( S ( t )  + 1, D(t) + BdD(t))dD(t) 
(equation (12.24) was used here). Comparing (12.25) with 
av 
d L  = m(S(t), 
D(t))dD(t) 
(valid when dS(t) = 0) and (12.26) with 
an 
dZ, = =(S(t),D(t))(l + dD(t)) 
(valid when dS(t) = l), we see that the difference between the left-hand and right-hand sides 
of (12.23) does not exceed 
1 
- 
< ?cZ C(d~(t))’ 
+ P S ( T ) C ~  
mpx I d ~ ( t ) l  = 0, 
where c1 is an upper bound on I(au/aD)(s,D)l 
and cz is an upper bound on 
I(a2U/aDz)(s, 
D)l, s ranging over [O, S ( T )  + 11 n Z+ and D over [O, supt D(t)]. 
An apparent gap in this argument is that c1 and cz may not necessarily be finite because of 
the possibility of erratic behavior of (au/aD) and (d2u/dD2) as D --+ 0. However, it 
t 

306 
CHAPTER 12: THE GENERALITY OF GAME-THEORETIC PRlClNG 
can be seen that condition (12.21) (in conjunction with the Lebesgue dominated convergence 
theorem) implies u(s, D )  -+ U ( s )  as D --t 0; therefore, (12.24) implies that the limit 
au 
lim -(s, 
D )  = U(s + 1) - 
D+O d D  
exists for every s, and the easy corollary 
a2u 
a77 
au 
-(s,D) 
1 
- ( s +  
1,D) - -(s,D) 
dD2 
aD 
d D  
= (u(s + 2, D )  - g ( s  + 1, D )  ) - (a(, 
+ 1, D )  - u ( s , D )  
- 
= U ( s  + 2, D )  - 2n(s + 1, D )  + g ( s ,  D )  
of (12.24) implies that the limit 
a2u 
lim -(s, 
D )  = U ( s  + 2) - 
D - ~ O  dD2 
2U(s + 1) + U ( s )  
exists for every s. 
I 
As theproofshows, thegrowthcondition(l2.21)canberelaxedto U ( s )  = (o(s))’ 
or, more formally, lims+m(U(s))l/s/s = O. 
Proposition 12.1 is analogous to a result in Dambis (1965) and Dubins and Schwarz 
(1963, which says that a point process with continuous compensator can be trans- 
formed into a Poisson process by a change of time. (Similarly, our game-theoretic 
Bachelier formula is analogous to the measure-theoretic result in Meyer (197 1) and 
Papangelou (1972), that a continuous martingale can be transformed into a Wiener 
process by a change of time.) 
Multivalued Processes 
The preceding theory can be generalized to price options that depend on any number 
of counting processes. For simplicity, we consider the case of two counting processes; 
the extension to more than two is straightforward though notationally awkward. 
Let S(l) (t) and S(2) 
(t) be the number of hurricanes and hailstorms, respectively, 
in the time interval [0, t]. We assume that only one storm can occur at a time: dS(l) (t) 
and dS(’) (t) cannot exceed 1, and dS(l) (t) and dS(2) (t) cannot be 1 simultaneously. 
In order to price a European option U(S(l)(T) , 
S(’)((T)), where U : (iZ+)2 -+ 
R+ , we will need the Market to price two dividend-paying derivatives, D(l) and 
D(2). The derivative D(’)), 
for k = 1,2, pays the dividend 
o if 
(t) = o 
(t) = 1 
{ 1 if 
during the infinitesimal interval [t, t + dt]. 
POISSON 
PROTOCOL 
FOR Two PROCESSES 
Players: Investor, Market, Reality 

12.3: GAMES FOR PRlCE PROCESSES WITH JUMPS 
307 
Protocol: 
z, := 0. 
Market announces D t )  > 0 and DC) > 0. 
FOR n = 1,2,. . . , N :  
Investor announces Vil) E Iw and Vi2) E R. 
Reality announces 
Market announces D?) 2 
0 and D?) 2 0. 
,-I + z, 
. 
s, 
(1) := s(1) 
( 1 )  
( 2 )  
( 2 )  
( 2 )  
s, := Snp1 + z, 
. 
z, := T,-~ + v,") (zF) + AD!)) + vi2) ($1 
+ ADP)). 
sp := 0, 
$1 
:= 0. 
z?) E (0,l) with zF)zk2) = 0. 
Additional Constraints on Reality and Market: Reality must make S g )  < 00. 
Market must make the path D(k) is continuous, with Dkk) > 0 for n = 1, . . . , N - 1, 
Dg) 
= 0, supn Dkk) < co, and vex D(k) < 2. 
Theorem 12.2 Suppose the junction U: (Z+)2 -+ E%+ satisjies the growth condition 
The pricefor a European option U(S(l)(T), 
S(')((T)) at the time when D(l)(O) and 
D(2) (0) have just been announced in the Poisson protocol for two processes is 
(12.28) 
and rewrite the equality in (12.28) as 

308 
CHAPTER 12: THE GENERALITY OF GAME-THEORETIC PRlClNG 
Direct differentiation and application of Leibniz’s differentiation rule for integrals shows that 
our growth condition (12.27) on U implies 
Our strategy is to buy 

12.3: GAMES FOR PRICE PROCESSES WITH JUMPS 
309 
and that C k  and ck,l are finite (this can be proven as in Proposition 12.1). 
Consider the process S(t) defined by 
S(t) := S(l)(t) - S(2)(t) 
I 
We could think of this as a security price that can change only by jumps,a jump always 
being 1 or -1. A European option on such a security is priced by Theorem 12.2; its 
price is 

310 
CHAPTER 12: THE GENERALITY OF GAME-THEORETIC PRICING 
This simple model is in the spirit of the model of Cox, Ross, and Rubinstein 1979, 
except that here the timing of the jumps is not known in advance. Other differences 
between the two models, such as the positivity of prices in the Cox, Ross, and 
Rubinstein model, are easily eliminated. 
Putting Jumps in Price Processes 
The ideas of the preceding subsections can be combined to price options on share 
prices that can change continuously and can also jump. 
In its simplest form, at least, this combination requires that market participants 
be able to identify when a jump occurs, and it limits the different possible sizes for 
jumps. For each size that is permitted, there must be a dividend-paying security. It 
may be possible to extend the method so as to relax these assumptions. 
For simplicity, let us assume that there are only two kinds of external events: 
positive ones, which cause the price to jump by 1, and negative ones, which cause 
it to jump by -1. We write S("), S(-'), and S(') for the three components of S :  
the diffusion component S('), the cumulative effect S(') of jumps of 1, and the 
cumulative effect S(-l) 
of jumps of -1. For each component, we ask the market 
to price dividend-paying derivatives: D('), responsible for the diffusion component 
5"') of S ,  D(-'), 
responsible for negative jumps, and D(l), responsible for positive 
jumps. 
This gives the following protocol: 
BACHELIER'S 
PROTOCOL WITH JUMPS 
Players: Investor, Market 
Protocol: 
1, := 0. 
Market announces Sf) 
E JR, D r )  > 0, DA-l) > 0, and D g )  > 0. 
FORn= 1,21...1N: 
si-1) := 0, sp := 0. 
Investor announces M, E JR, V, E B Vi-') E JR, and V,'" E R. 
Market announces xi0) E R. 
Market announces xi-') E { -1,O} and x;) E (0, l} with xk-') Z1L (l) - 
- 0. 
Market announces DiO) 2 0, Dip') 2 0, and Dill 2 0. 
( 0 )  .- 
( 0 )  
( 0 )  
Sn .- S,-i + Z, 
. 
sL-1) .= s(-1) 
+ p) 
(1) ._ s(1) 
(1) 
sn .- 
n-l +x, . 
s, := s?) + sL-l) + $1. 
In := In-1 + MnAS, + V, 
. 
,-I 
in . 
+ v,'-~) 
(xi-1) +  AD^?) + v,") 
+ AD;)). 
Additional Constraints on Market: For k = - l , O ,  1, Market must ensure that 
Sg) < 03, the path S(O) is continuous, inf, St) 
is positive and not infinitesimal, 

12.4: APPENDIX: THE STABLE AND INFINITELY DIVISIBLE LAWS 
31 1 
sup, Si0) < m, the path D(k) is continuous, with DLk) > 0 for n = 1, . . . , N - 1, 
DE) = 0, SUP, DLk) < m, and vex D(k) < 2. 
This protocol does lead to a game-theoretic price for a well-behaved option on S, 
which can be found from the appropriate partial differential equation by numerical 
methods. Because there does not seem to be a simple formula for the price, we do 
not state this conclusion as a formal proposition. 
12.4 APPENDIX: THE STABLE AND INFINITELY DIVISIBLE LAWS 
In this appendix, we provide some standard definitions, results, and references con- 
cerning stable and infinitely divisible probability distributions (or laws, as one often 
says). 
Stable Distributions 
The study of the stable distributions goes back to the work of Augustin Louis Cauchy 
(1789-1857) in 1853. The topic was taken up by Paul Levy in 1925. (For an excellent 
historical account see Gnedenko [ 1341 .) Different authors define stability in slightly 
different ways, but we can use the definition due to Khinchin: a probability distribu- 
tion P is stable if, for any two independent random variables x and y distributed as P 
and any two real numbers a and b, the sum ax + by has the same distribution as cz + d 
for some real numbers c and d. The stable distributions arise in the theory of sums 
of independent random variables: a distribution can be the limit of the distributions 
of the random variables 
1 "  
y ,  := - xi - b,, 
an . 
z= 1 
where xi are independent and identically distributed, if and only if it is stable; see 
Gnedenko and Kolmogorov [ 1351, Theorem 35.2. 
Recall that the characteristic function for a random variable X is the function 
$(u), 
in general complex-valued, defined by G(u) := E(eiUX). Khinchin and LCvy 
(1936) showed that for a typical stable law, 
log$(u) = iyu - clula (1 + ip(signu) tan - , 
(12.31) 
where y is a location parameter, c 2 0 is a scale parameter, ,B E [-1,1] is an index 
of skewness, and a, usually of most interest, is the characteristic exponent; recall 
that sign u is defined to be 1 if u is positive, - 1 if u is negative, and 0 if u is 0. The 
characteristic exponent must lie in the range 0 < a 5 2. Equation (12.3 1) is actually 
valid only when a # 1; when a = 1, tan 
is not defined and has to be replaced 
by 3 log IuI. Except for the Gaussian distribution (a = 2 )  and a couple of other 
special cases, there is no simple expression for the density of a stable law ([121], 
Chapter XVII), but (12.31) shows how small the set of stable laws is: the stable 
2 1 

312 
CHAPTER 12: THE GENERALITY OF GAME-THEORETIC PRlClNG 
types (for any probability distribution P its type is defined to be the distributions of 
the random variables aX + b, a and b ranging over the reals) depend on just two 
parameters, cr and p. 
Cauchy discovered that the characteristic functions of symmetric stable laws are 
all of the simple form 
log$(u) = -cIula. 
(12.32) 
Important special cases, besides the Gaussian distribution (a = 2), are the Cauchy 
distribution (a = 1; actually discovered by Poisson) and the Holtzmark distributions 
(a = 0.5,1.5). The latter describe the gravitational field created by randomly placed 
stars; cr = 0.5 when the stars are distributed in a one-dimensional space, and a = 1.5 
in the three-dimensional case. In the one-dimensional case the Holtzmark distribution 
gives way to distribution (12.32) if the usual gravitational law of inverse squares is 
replaced by the law of inverse l/ath power, for any 0 < cr < 2 (the Gaussian case, 
cy = 2, is excluded). In all three cases, a = 0.5, cr = 1, and a = 1.5, closed-form 
expressions for densities are known. For details, see [ 121, 1881. 
The characteristic exponent characterizes the behavior of the tails of the 
distribution-that 
is, the probabilities for extreme values. For a nondegenerate 
random variable X following a stable law with a characteristic exponent cr less than 
2, the variance does not exist; in fact, the moment E(lXlk) exists when and only 
when k < cr (Gnedenko and Kolmogorov 1954). 
Infinitely Divisible Distributions 
The stable distributions are included in a larger class of distributions that are called 
infinitely divisible. A probability distribution is infinitely divisible if for any positive 
integer k it can be represented as the law of a sum c:=, 
5, of independent identically 
distributed random variables 2,. 
The study of infinitely divisible distributions began 
in 1929 with de Finetti [89, 88, 87, 901, and was continued by Kolmogorov (1932) 
and LCvy (1934). For a typical infinitely divisible law, 
where IT is a measure on R \ (0) with 
b is a real number (a location parameter), and o2 is a nonnegative number (the variance 
of the Gaussian component). Because II , which is called the LPvy measure, can be 
chosen freely, the class of infinitely divisible laws is infinite dimensional, in contrast 
with the class of stable laws, which, aside from the location and scale parameters, 
has only the two parameters Q and p. 
Formula (12.33) is Lpvy’s formula or the LPvy-Khinchin formula; it was proven by 
LCvy (1934) and Khinchin (1937). Different authors, including LCvy and Khinchin, 
write it in slightly different ways. 

12.4: APPENDIX: THE STABLE AND INFINITELY DIVISIBLE LAWS 
313 
The role of infinitely divisible distributions as limits of sums of independent 
random variables is clarified by the following fundamental result [ 17 1, 242, 2431: 
Khinchin’s Theorem Suppose the random variables 
X11, X12, . . . , Xlkl 
x21, ~ y 2 2 , .  
’ . , X 2 k z  
are independent within rows. Suppose k, -+ co as n + co and the condition of 
infinite smallness 
max p{X,k 2 
E }  -+ 0 (n + co) 
l<k<kn 
holds for every fuced E > 0. I f  the distributions of the sum tip, x n k  converge to 
some probability distribution, that probability distribution is infinitely divisible. 
Boris Gnedenko (19 12-1995) established necessary and sufficient conditions under 
which 
x n k  converges to a given infinitely divisible law [ 135,242,2431. There 
are a number of results here waiting to be extended to the game-theoretic framework. 
It remains to explain how (12.31) is a special case of (12.33). As we know, y 
and c in (12.31) are the location and scale parameters. In the case cy = 2, the LCvy 
measure rI is zero and c2 = c; in all other cases cr2 = 0. When 0 < cy < 2, the LCvy 
measure lI satisfies 
rI((-co, 4)) 
= c1t- 
& II((t,co)) = c2t-, 
vt > 0 ,  
for some constants c1 2 0 and c2 2 0. The index of skewness p can be defined as 
c1 - c2. 
p =  -, 
c1 + 0 2  
arbitrarily if c1 + c2 = 0 (see [135]). 
Levy Processes 
A c8dlAg stochastic process X with time parameter ranging from zero to infinity is a 
Le‘vy process if its increments X ( t  + h) - X ( t )  and independent and stationary (the 
distribution of X ( t  + h) - X ( t )  depends only on h but not on t). This implies that 
the increments have infinitely divisible distributions. In fact, there is a one-to-one 
correspondence between the LCvy processes and infinitely divisible distributions; for 
every infinitely divisible distribution P, there is a LCvy process X such that X(1) is 
distributed as P. An excellent book on LCvy processes is Bertoin [20]; for general 
processes with independent increments, see Skorohod [289]. For a brief and readable 
review of Gaussian and LCvy processes, see 51.4 of [262]. 
Suppose X is a LCvy process such that the characteristic function 11, of X (1) 
satisfies Equation (12.33). Then II describes the jumps of X .  Heuristically, if A 

314 
CHAPTER 12: THE GENERALITY OF GAME-THEORETIC PRICING 
is an open interval of the real line not containing 0, then II(A) < co, and for any 
infinitesimal interval [t, t + dt) the number 
q(t,A) = # { S  E [t,t + dt) I X ( S )  - X ( S - )  E A }  
of jumps in that interval belonging to A has expected value II(A)dt; for disjoint 
intervals [tl + d t )  and [ t 2  + dt), the random variables q(t1, A) and q ( t 2 ,  A) are 
independent [20]. 
Equation (12.33) has the following interpretation in the language of Ltvy pro- 
cesses. Every LCvy process can be represented as the sum of four independent 
components: 
1. The deterministic function X I  (t) = bt; the characteristic function $1 of Xl(1) 
satisfies 
log$1(u) = ibu 
(i.e., corresponds to the first addend in (12.33)). 
2. A scaled Brownian motion X,(t) = aW(t), where W is a standard Wiener 
process. The characteristic function $2 of X2 (1) satisfies 
(corresponds to the second addend in (12.33)). 
3. A pure jump process X3 with all jumps greater than 1 in absolute value. 
This is a compound Poisson process (the latter is defined similarly to the 
usual Poisson process, but with arbitrary independent identically distributed 
jumps). Its jumps are described by the restriction of the LCvy measure II(dt) 
to (-00, - 1) U (1,m). The characteristic function $3 of X 3  (1) satisfies 
4. A pure jump martingale X4 whose jumps never exceed one and are described 
by the restriction of the LCvy measure II(dt) to [-1,1]; the characteristic 
function $4 of X4 (1) satisfies 
(In principle, a LCvy process can have more than one representation in the 
form (12.33), but there will always be a representation under which X4 is a 
martingale.) 
For a proof, again see Bertoin [20]. Similar decompositions are known for general 
processes with independent increments (see Skorohod [289]). 

12.4: APPENDIX: THE STABLE AND INFINITELY DIVISIBLE LAWS 
315 
Similar decomposition results have recently been developed for semimartingales. 
For any semimartingale, it is possible to define a “triplet of predictable characteris- 
tics”, analogous to the deterministic term bt, the Wiener term aW(t), and the LCvy 
measure II; in the following informal discussion we will call b the drlft term and u2 
the diffusion term. This representation has a clear game-theoretic interpretation: at 
every step Forecaster announces b, u2, and II, Skeptic is allowed to buy correspond- 
ing tickets, and Reality chooses the increment in X ( t ) ,  which influences the amount 
received by Skeptic. 
It should be rewarding to review this literature from our game-theoretic point of 
view, seeking to simplify results by reducing Forecaster’s moves to what is actually 
needed. For some results, for example, it suffices for Forecaster to give only mean 
value and variance of a jump (defined to be 0 if there is no jump) instead of announcing 
a complete Levy measure II. We have already demonstrated this point with Theo- 
rems 4.1-5.2, where Forecaster was only required to price a few tickets associated 
with the next jump instead of giving the full distribution II. Those theorems were set 
in discrete time, but they fit into the general framework as a special case where X ( t )  
changes only when t is integer, b and cr2 are always zero, and the changes in X ( t )  
are governed by II. The continuous-time protocols in this part of the book can also 
be seen as part of this general approach. In 14.1, we will consider continuous-time 
protocols in which Forecaster announces only a diffusion term (denoted w,), omitting 
any drift terms. The continuous-time protocols we considered in Chapter 11 go even 
further, requiring only a remaining cumulative variance instead of an instantaneous 
variance w,. The Poisson protocol of 512.3 corresponds, of course, to the case where 
the LCvy measure II(t) at step t is concentrated at { 1}, but in this protocol we also ask 
for the remaining cumulative variance. The final protocol of 5 12.3, which combines 
Bachelier’s protocol with jumps, can be interpreted very roughly as an extension of 
Bachelier’s protocol from Brownian motion to Ltvy processes whose LCvy measure 
is concentrated on a finite set. 
We have not tried to create a general game-theoretic framework involving all three 
characteristics for semimartingales, because we do not yet have enough interesting 
special cases to justify such a general construction. Instead, we have been oppor- 
tunistic, developing only the mathematics needed for specific problems. When such 
a framework is developed, however, we expect it to be more flexible than the standard 
approach, with fewer technical conditions. The measure-theoretic general theory 
of stochastic processes is notorious for its highly technical nature; as Paul Meyer 
once said, “. . . il faut.. . un cours de six mois sur les dtfinitions. Que peut on y 
faire?” (quoted by Williams in the first edition of [262], 1979). The game-theoretic 
framework should support a more accessible theory. 
Stable Levy Processes 
Under any reasonable formalization, a stochastic process obtained by summing inde- 
pendent identically distributed stable infinitesimal increments will be a stable Ltvy 
process, that is, a Ltvy process with stable increments. In this case, if cy # 2, the 

316 
CHAPTER 12: THE GENERALITY OF GAME-THEORETIC PRICING 
a a = 0.01 
b a = 0.5 
c a = l  
d a = 1.2 
e 
cy = 1.4 
f 
cy == 1.6 
g a = 1.8 
h a = 1.9 
Fig. 72.7 
for the parameter a. 
Simulated price paths with increments dS(t) that are stable with different values 
diffusion component is absent and the LCvy measure Il is given by 
rI((-W, 4)) = C l P ,  rI((t, 03)) = c2tra 
(t > 0) for some nonnegative constants c1 and c2. The LCvy measure is absolutely 
continuous with the density ~ ; ( - t ) - ' - ~  
on ( - c o , O )  and ~ i t - l - ~  
on ( 0 , ~ ) .  
Its 
interpretation in terms of jumps makes computer modeling of stable processes quite 
easy. 
Figure 12.1 shows some paths of stable LCvy processes with different a. In 
contrast with the Wiener process (Figure 9.2), they do appear discontinuous. This 
is what we expect when a E (0,2). LCvy showed that the only continuous LCvy 
processes are diffusion processes ([262], Theorem 28.12), as we would expect from 
the interpretation we have given for the LCvy measure n. 

13 
Games for American 
Options 
In this chapter, we extend our purely game-theoretic approach to option pricing from 
European options to American options. 
An American option differs from a European option in that it can be exercised 
early. If a European option on a security S pays U(S(T)), 
where S(T) is the price 
of S at time T ,  then the corresponding American option pays U(S(t)), 
where t is the 
time when the holder of the option decides to exercise it. This flexibility is attractive 
to investors, because it allows them to use information coming from outside the 
market. Consider, for example, an American call option, which allows its holder to 
buy a share of S at the strike price a. If the current price of S is greater than a, then 
the immediate exercise of the option would produce a net gain. If the holder of the 
option learns something that convinces him that the price of S will soon fall and stay 
low at least until after T ,  then he will want to exercise the option immediately. 
Because of their flexibility, the pricing of American options raises some new 
issues. In order to establish that the option is worth no more than $c at time 0, it is 
not enough to show that we can reproduce a certain payoff at time T starting with 
$c. We must also show that we can reproduce the option’s flexibility starting with 
$c. This leads to a splitting of the concept of upper price. In general, we may have 
three prices for an American option H :  
(13.1) 
Roughly speaking, the lowerprice 
H is the largest amount of money the holder of 
the option can produce for certain (using the option and also trading directly in the 
market), the weak upperprice 
H is the least initial capital that will enable a trader 
without the option to produce any payoff variable that a trader with the option can 
317 
Probability and Finance: It’s Only a Game! Glenn Shafer, Vladimir Vovk 
Copyright 0 2001 John Wiley & Sons, Inc. 
ISBN: 0-471-40226-5 

318 
CHAPTER 13: GAMES FOR AMERICAN OPTIONS 
- 
produce with no additional capital, and the strong upperprice EH is the least initial 
capital that will enable a trader without the option to reproduce all the flexibility of 
the trader with the option. 
In this chapter, we show that an American option is priced-that 
is, the prices 
in (1 3.1) are all equal-under 
certain assumptions similar to those we used for pricing 
European options: the dividend-paying security 2) is traded, Market obeys certain 
conditions on the paths S and D, and the payoff function U is well-behaved. To 
show this, and to find the price, we use the ideas from parabolic potential theory that 
we introduced in 56.3. 
As an exercise in game theory, this chapter uses a more general framework than the 
rest of the book. Elsewhere, neither our particular games nor our abstract theory ever 
goes beyond protocols in which the capital of our protagonist, Skeptic or Investor, 
increases by increments that depend only on his current move. Here we consider 
more general protocols, in which Investor’s move on one round can influence what 
he can achieve by his move on another round. 
We introduce these more general protocols, which accommodate American options 
and many other types of options as well, in 3 13.1. In 13.2, we show how to construct 
a two-player game for comparing two of these protocols. In this game, each player 
follows his own protocol, except that he also observes the other player’s moves. This 
introduces an element of competition; we can see which protocol allows its player to 
do better. If one of the protocols merely gives its player cash to invest in the market, 
then we are comparing the other protocol to a given amount of cash. This leads to 
the weak and strong notions of price, which we formalize in 513.3. 
After all this careful groundwork, we finally show how to price American options 
in $13.4. That section concludes with a few examples. 
13.1 MARKET PROTOCOLS 
The protocols we studied in earlier chapters, in which the capital of Player I (Skeptic 
or Investor) increases by increments he influences only through his current move, 
are gambling protocols (see 58.3). We will call a protocol in which Player 1’s final 
capital is determined in a more complicated way a market protocol. 
We begin the chapter by introducing some general notation for market protocols. 
Then we discuss the two examples of market protocols that interest us the most: 
the investor who begins owning an American option, and the investor who begins 
holding a certain amount of cash, say $c. We assume that both investors are entitled 
to trade freely in the market, going short in securities if they want. Generalizing from 
these two examples while retaining the feature that the investor can trade freely in 
the market in addition to exploiting his initial endowment, we obtain the concept of a 
jinancial instrument. Both an American option and an endowment of $c are financial 
instruments. Other types of options are also financial instruments. The notation that 
we lay out for financial instruments in general in this section will help us define the 
concepts of weak and strong price in the next section. 

13.1: MARKET PROTOCOLS 
319 
The Abstract Market Protocol 
Here is our market protocol in its most general form. It is a discrete-time, perfect- 
information protocol. It generalizes the gambling protocol but retains the feature 
that the moves available to Player I1 (Market) can be affected only by his own earlier 
moves, not by the moves of Player I (Investor). 
MARKET PROTOCOL 
Parameters: N ,  set S, set W, R 
Players: Investor, Market 
Protocol: 
WNfl, A: R x S N  + IR 
Market announces wo E W. 
FORn= 1,2, ..., N :  
Investor announces s, E S. 
Market announces w, E W. 
I := A(wo,wl,. . . , W N , S ~ ,  
. . . , s N ) .  
Additional Constraint on Market: Market must make (WO, w1,. . . , WN) E R. 
The quantity I is Investor’s capital at the end of the game. 
As usual, we call R the sample space, we call an element of R a path, and we call 
a function on R a variable. We will call an initial subsequence of a path a market 
situation, and we write Ro for the set of all market situations. 
We assume that Investor has the same move space S on every round only to keep 
the notation simple. Because a move by Investor has no meaning aside from its effect 
on the final capital I (and this effect may depend on the round and on other moves by 
both players), the effective move space on each round is really defined by S together 
with the function A, and this may be quite different from round to round. 
The notion of a market protocol is obviously extremely general. Investor may 
begin the game with various kinds of property, including cash, shares of stock, and 
options. Investor’s moves may include all sorts of decisions he takes with respect to 
this endowment (including decisions about whether to exercise an American option), 
provided only that they have a well-defined effect on the final capital I .  
This generality changes the role played by coherence. We called a gambling pro- 
tocol coherent if World had a strategy guaranteeing that Skeptic ended the game with 
nonpositive capital. This would be inappropriate here; there is nothing incoherent 
about Investor starting with cash or with a promissory note guaranteeing some posi- 
tive capital in the future. But we will encounter an appropriate concept of coherence 
for the market protocols that interest us (p. 322). 
A strategy for Investor is a function P that assigns an element of S to every market 
situation. Given a strategy ‘P, we set 
P 
I 
(wO,w1, ..., WN) := 
qwo, w 1 ,  w2,. . . , WN, P(wo), P(W0, Wl), . . . , P ( W 0 ,  w 1 , .  . . , WN-1)). 
This defines a function I P  on the sample space, which we call the payoff variable 
for the strategy P. 

320 
CHAPTER 13: GAMES FORAMERICAN OPTIONS 
The American Option 
Let us assume that an investor who holds an American option on S also has the 
opportunity to trade in S and whatever auxiliary securities (such as our dividend- 
paying security D or our strictly convex derivative R) are in the market. This means 
that he makes two moves on each round: 
a market move-how 
much of each traded security to hold on that round, and 
0 a move intrinsic to the American option-whether 
to hold or exercise it. 
Leaving open exactly what auxiliary securities are traded, we use the following 
notation for the market move: 
0 The move space for the market move is a linear space S. (If Investor can trade 
in S and D, 
then S is R2, 
and an element (M,,V,) 
of S is interpreted as 
holding M ,  shares of S and V, shares of D.) 
0 The payoff from a market move on the nth round, say s, 
E S, is given by a 
function As: S x Ro -+ R that is linear in s E S. (In the case where Investor 
is trading in S and 2) and Market moves by announcing new prices for s and 
D, 
the payoff in the market situation s, just after announcing S, and D, is 
 AS(^^,, V,, s,) = M A S n  + vn((ns,/s,-i)2 + 4o,).) 
And we use the following notation for the intrinsic move: 
0 Given (hl,. . . , h ~ )  
E (Exercise,H~ld}~, 
we write lstE(h1,. . . , h
~
)
 
for 
the first n for which h, = Exercise; if h, = Hold for all n, then we set 
lstE(h1,. . . , h
~
)
 
= N .  
0 We write ~ ( w o ,  
w1, . . . , w,) for the payoff of the option when it is exercised 
on round 7. (Normally this is U(S,), where U is the payoff function for the 
option.) 
With this notation, the market protocol for the American option reads as follows: 
MARKET PROTOCOL FOR AN AMERICAN 
OPTION 
Market Parameters: N, W, R 
Instrument Parameter: U :  Wx + E% 
Players: Investor, Market 
Protocol: 
WN+l, 
S, As: S x W* -+ R 
1, := 0. 
Market announces wo E W. 
FOR n = 1,2, . . . , N: 
Investor announces h, E {Exercise, Hold} and s, 
E S. 
Market announces w, E W. 
1, = 1,-1 + As(sn, W O , .  . . , w n ) .  
I := IN + ~ ( W O , .  
. . , w,), where 7 = lstE(h1,. . . , h ~ ) .  
Additional Constraint on Market: Market must make (wo, . . . , WN) E 0. 

13.1: MARKET PROTOCOLS 
321 
Investor's total capital I at the end of the game is obtained by adding his capital from 
trading in the market, I N ,  
to his payoff from the option. 
Cash 
If a holder of $c is also allowed to trade in the same securities as the holder of the 
American option, then his market protocol can be formalized as follows: 
MARKET PROTOCOL FOR $C 
Parameters: N ,  W, R C WNfl, S, As: S x W* + E%, c 
Players: Cash, Market 
Protocol: 
I, = 0. 
Market announces wo E W. 
FORn= 1,2, ..., N :  
Cash announces s, E S. 
Market announces w, E W. 
1, = 1,-1 + As(s,,wo,. . . , wn). 
I := ZN + c. 
Additional Constraint on Market: Market must make (WO, . . . , WN) E Cl. 
As usual, we assume that S is a linear space and that A s  is linear in its first argument. 
The Concept of a Financial Instrument 
In order to have a general framework for comparing cash and the American option, 
we now introduce the concept of afinancial instrument. A financial instrument H ,  in 
the sense in which we shall use the term in this chapter, is defined by the parameters H 
and AH: R x HN -+ R in the following protocol. A holder of a financial instrument 
has the right to play the role of Investor in the protocol with these parameters. 
MARKET PROTOCOL FOR FINANCIAL 
INSTRUMENT H 
Market Parameters: N ,  W, R C WNfl, S, As: S x W* -+ R 
Instrument Parameters: H, AH: 0 x HN + R 
Players: Investor, Market 
Protocol: 
z, := 0. 
Market announces wo E W. 
FORn= 1,2, ..., N :  
Investor announces h, E H and s, E S. 
Market announces w, E W. 
1, = 1,-1 + As(s,, WO, . . . , w,). 
I :=I IN + AH(Wo,W1,. . . , W N ,  hi,. . . , h N ) .  
Additional Constraint on Market: Market must make (WO, . . . , WN) E R. 

322 
CHAPTER 13: GAMES FOR AMERICAN OPTIONS 
We again assume that S is a linear space and that A s  is linear in its first argument. We 
call h,, Investor’s intrinsic move; it is his action, if any, with respect to the instrument. 
We call s, 
his market move; it tells how many traded securities (such as shares of S 
and its traded derivatives) he holds on round n. 
The market for securities is defined by its sample space R and the function A s  
with which it rewards the positions taken by investors in traded securities, while the 
instrument is defined by its move space H and its payoff AH. 
A strategy for Investor can be decomposed into a market strategy P, which tells 
him how to choose his market moves, and an intrinsic strategy ‘R, which tells him 
how to choose his intrinsic moves. These strategies each determine a payoff variable; 
the payoff Z p  from the market strategy is given by 
N 
Zp(wo1.. . , WN) := C ils(P(~0,. 
. . , w,-I), W O , .  . . , w,) 
T X = 1  
and the payoff I R  from the intrinsic strategy is given by 
ZR(Wo,. 
. . , WN) := Af{(Wo,. . . , W N , X ( W o ) ,  . . . ,‘R(Wo,. . . , WN-1). 
The total payoff is In + Zp. 
nonpositive, then we say that the market is coherent. 
If Market can guarantee that Investor’s gain ZN from trading in the market is 
Passive Instruments 
We say that a financial instrument H is passive if Investor cannot do anything to 
affect its payoff. Cash and European options are passive; American options are not. 
We can formalize this by saying that the move space H has only one element, a move 
called “do nothing” that hzs no effect on the function AH. For a cleaner protocol, we 
can simply delete the intrinsic moves: 
MARKET PROTOCOL 
FOR A PASSIVE 
INSTRUMENTS 
H 
Market Parameters: N ,  W, R 5 WNfl, S, As: S x W* + IR 
Instrument Parameters: AH: R + IR 
Players: Investor, Market 
Protocol: 
2, := 0. 
Market announces wo E W. 
F O R n =  l l 2 , . . . , N :  
Investor announces s, 
E S. 
Market announces w, E W. 
Z, = Z,-l + As(s,, 
W O , .  . . , w,). 
+ Af$(Wo, W l , . .  . , WN). 
I := 
Additional Constraint on Market: Market must make (WO, . . . , WN) E R. 
Again, S is a linear space, and A s  is linear in its first argument. Here Investor only 
makes market moves, and so a strategy for him is merely a market strategy. 

13.2: COMPARING FINANCIAL INSTRUMENTS 
323 
Other Options 
Although we are mainly concerned with American options in this chapter, our concept 
of a market protocol is broad enough to accommodate almost all types of options, 
including the following types of non-European options. 
Asian option. An “average price call” on a security S with maturity N and strike 
price c pays at N the amount by which the average price of S over the period 
{ 1, . . . , N }  exceeds c. 
Make-your-mind-up option. This is a variant of the American option; the option 
can be exercised early, but the holder must give notice a certain number of days 
in advance that he will exercise it on a given day. 
Bermudan option. This is another variant on the American option, in which exercise 
is only allowed on days in a specified subset of the N trading days. 
Shout olption. This type of option combines the advantages of European and Amer- 
ican options by allowing the holder, on one occasion of his choosing, to lock 
in the gain he would obtain by the immediate exercise of an American option, 
without losing the possibility of doing even better by waiting until maturity. A 
simple shout call option on S with strike price c and maturity N ,  for example, 
Pays 
(S, - c) + max (SN - S,, 0) , 
where r is round where the holder shouts. Only one shout is allowed, on a 
round n where S, - c > 0. 
Chooser option. Here the holder of the option has the right to choose, at some 
specified time n, whether it will be a call or a put option, which can then be 
exercised only at maturity. 
Passport option. Also called a perjiect trader option, this option permits the holder 
to trade in the underlying security S, under some restrictions (for example, he 
may be allowed to hold only between -C and C shares of S on any round), 
without risking a net loss; the option pays the profit from the trading in S if it 
is positive, zero otherwise ([351], p. 243). 
Asian options are passive; the other types in this list are active. For reviews of 
different types of options and other financial instruments, see [154, 3511. 
13.2 COMPARING FINANCIAL INSTRUMENTS 
In this section, we define weak and strong ways of comparing two financial instru- 
ments. The weak comparison takes into account only the possible payoff variables 
that each instrument can produce, while the strong comparison also takes into ac- 
count the extent to which the instrument’s holder can change goals in the course of 
the game. 

324 
CHAPTER 13: GAMES FORAMERICAN OPTIONS 
Two different financial instruments in the same market, say Instrument A and 
Instrument B, can be represented by market protocols with the same moves for 
Market but different moves and payoffs for Investor: 
MARKET PROTOCOL FOR INSTRUMENT A 
Market Parameters: N, 
W, R 
Instrument Parameters: A, AA: R x AN -+ IR 
Players: Investor A, Market 
Protocol: 
WNfl 
Market announces wo E W. 
FORn= 1,2, ..., N :  
Investor A announces a, E A. 
Market announces w, E W. 
1 := A ~ ( w 0 , .  
. . , WN, al,. . . , aN). 
Additional Constraint on Market: Market must make (WO, . . . , w ~ )  
E 0. 
MARKET PROTOCOL FOR INSTRUMENT B 
Market Parameters: N, 
W, R C WNfl 
Instrument Parameters: B, 
AB: R x BN + B 
Players: Investor B, Market 
Protocol: 
Market announces wo E W. 
FORn= 1,2, ..., N: 
Investor B announces b, E B. 
Market announces w, E W. 
I := A g ( ~ g , .  
. . , W N , ~ I , .  . . , bN). 
Additional Constraint on Market: Market must make (WO, . . . , WN) E 0. 
These two protocols are simplified versions of the market protocol for financial 
instrument H in the previous section; the moves a, E A and b, E B now include 
both the intrinsic moves with respect to the instruments A and B, respectively, and 
the market moves. 
We can compare what the two instruments can achieve by comparing the payoff 
variables that the investors can produce. We say that Instrument A weakly super- 
replicates Instrument B if for every strategy Q for Investor B, there is a strategy '%' for 
Investor A such that I p  2 1". The relation of weak super-replication is obviously 
transitive. 
We call this kind of super-replication weak because it does not capture everything 
that investors consider when they compare financial instruments. If the investor 
intends to follow a strategy that he fixes at the beginning of the game, then it is 
appropriate for him to consider only the payoff variables that an instrument makes 
available. But a strategy determines each move based only on the preceding moves 
by the market, and investors often use other information-information 
from outside 
the market-when 
deciding on their moves. If an investor intends to use outside 
information that he acquires after the game begins, then he will be interested not only 

73.2: COMPARING FINANCIAL INSTRUMENTS 
325 
in what payoff variables are available at the beginning of the game but also in the 
flexibility he has to change from one payoff variable to another in the course of the 
game. 
One way to take this flexibility into account in the comparison of two instruments 
is to play them against each other in what we call a super-replication game: 
GAME FOR SUPER-REPLICATING 
INSTRUMENT 
B WITH INSTRUMENT 
A 
Market Parameters: N ,  W, R 5 WN" 
Parameters for Instrument A: A, AA: R x AN -+ R 
Parameters for Instrument B: B, AB: R x BN -+ R 
Players: Investor A, (Investor B + Market) 
Protocol: 
Market announces wo E W. 
FORn= 1,2, ..., N :  
Investor B announces b, E B. 
Investor A announces a, E A. 
Market announces w, E W. 
IA := A ~ ( w 0 , .  
. . , w ~ , a l , .  
. . , a ~ ) .  
IB := A B ( W ~ ,  . . . , WN, bl,. . . , b N ) .  
Additional Constraint on Market: Market must make (WO, . . . , WN) E 0. 
Winner: tnvestor A wins if IA >_ I,. 
Otherwise Investor B and Market win. 
We allow Investor A to move after Investor B, with knowledge of how Investor B has 
moved, because we are asking whether Instrument A gives at least as much flexibility 
as Instrument B. We are asking whether Investor A, using Instrument A, can always 
match or improve on what Investor B, using Instrument B, has achieved. If we were 
interested instead in which investor had the best outside information, then we might 
look at a game in which each must make his nth move without knowing the other's 
nth move. 
We say that Instrument A strongly super-replicates Instrument B if Investor A has 
a winning strategy in the game of super-replicating Instrument B with Instrument A. 
This relation is obviously transitive. 
It is also obvious that strong super-replication implies weak super-replication. The 
following example, in which two investors are trying to predict w2, shows that weak 
super-replication does not imply strong super-replication. 
EXAMPLE OF GAME FOR SUPER-REPLICATING B WITH A 
Players: Investor A, Investor B, Market 
Protocol: 
On ra'und 1: 
Investor A announces al: (0,l) -+ (0, l}. 
Market announces w1 E (0,l). 
Investor B announces b2 E (0, l}. 
Market announces w:, E {0,1}. 
On round 2: 

326 
CHAPTER 13: GAMES FOR AMERICAN OPTIONS 
I if al(w1) = w2 
0 otherwise. 
1 ifbz = w2 
0 otherwise. 
IA := 
Ig := { 
Winner: Investor A wins if IA 2 IB. 
In principle, both investors move on both rounds. But bl does not affect IB, and a2 
does not affect IA, and so we have simplified the protocol by omitting them. To see 
that Instrument A weakly super-replicates Instrument B, notice that a strategy P for 
Investor B produces the payoff variable 
1 ifP(w1) =w2 
0 otherwise, 
I;= { 
which Investor A can match merely by choosing his first move a1 to agree with P: 
al(0) = P(0) and al(1) = P(1). On the other hand, Investor A does not have a 
winning strategy in the super-replication game. After Investor A has made his first 
move al and Market has made his first move w1, Investor B can always make b2 
different from a1 (wl), and Market can then make w2 equal to bz, resulting in a final 
capital of 0 for Investor A and 1 for Investor B. So Instrument A clearly does not 
strongly super-replicate Instrument B. 
If B has just one element ("do nothing"), then there is no difference between 
strongly and weakly super-replicating Instrument B; because it is known in advance 
that the holder of B will not do anything, it makes no difference whether the holder 
of Instrument A gets to watch what he is doing. A similar conclusion can be drawn 
about passive instruments (whose owners are free to choose the market moves): there 
is no difference between strongly and weakly super-replicating a passive instrument 
with another instrument. But to see that this is true, we need to look a little closer at 
the relevant super-replication game. 
GAME FOR SUPER-REPLICATING PASSIVE H WITH G 
Market Parameters: N ,  W, 0 C WN+l, S, AS: S x W* + E% 
Parameters for instrument G: G ,  AG: R x GN -+ R 
Parameters for instrument H :  AH: 0 -+ R 
Players: Investor G, (Investor H + Market) 
Protocol: 
1: := 0. 
1,H := 0. 
Market announces wo E W. 
F O R n =  1,2, . . . ,  N :  
Investor H announces s: E S. 
Investor G announces gn E G and sg E S. 
Market announces w, E W. 
1," 
1 
1,"l + AS(S:,WO,. . . , wn). 
1," 
= 12-1 + AS(S:, 
wg,. . . , wn). 

13.2: COMPARING FINANCIAL INSTRUMENTS 
327 
IG :=zg 
+ h ~ ( ~ g , . . . , ~ N , g l , . . . , g N ) .  
IH := 
+ h ~ ( W 0 , .  . . , WN). 
Additional Constraint on Market: Market must make (WO, . . . , w ~ )  
E R. 
Winner: Investor G wins if IG 2 IH. Otherwise Investor H and Market win. 
As usual, we assume that S is a linear space and that A s  is linear in its first argument. 
Notice that Investor G can exactly match whatever Investor H accomplishes by 
trading in the market: he simply makes s: the same as s: on every round n. Because 
of the linearity of market trading, he can first do this and then make whatever other 
market moves he wants. So Investor H's ability to trade in the market makes no 
difference to whether Investor G has a winning strategy: Investor G has a winning 
strategy in this game if and only if he has a winning strategy in the following simpler 
game, where Investor H does not trade: 
SIMPLIFIED GAME FOR SUPER-REPLICATING PASSIVE H WITH G 
Market Parameters: N ,  W, R C WN+', 
S, AS: S x W" + R 
Paramletem for Instrument G: G, AG: R x GN -+ R 
Paramletem for Instrument H :  AH: R x BN -+ IR 
Players: Investor G, Market 
Protocol: 
z,G := 0. 
Market announces wo E W. 
FORn = 1,2, ..., N :  
Investor G announces g, E G and s z  E S. 
Market announces w, E W. 
Z," 
+As(s:,wo ,..., wn). 
IG := zg + AG(wo,. . . , WN,g1,. . . ,gN). 
IH := A H ( w ~ ,  . . . , WN). 
Additional Constraint on Market: Market must make (WO, . . . , WN) E R. 
Winner: Investor G wins if IG 2 IH. Otherwise Market wins. 
With this protocol in view, we easily obtain the following proposition. 
Proposition 13.1 Suppose G and H are instruments, H is passive, and G weakly 
super-replicates H. Then G strongly super-replicates H. 
Proof The hypothesis says that for every strategy P for Investor H, there is a market strategy 
Q and an intrinsic strategy G for Investor G such that ZG + ZQ 2 Zp + AH. Because market 
strategies form a linear space and their payoff variables combine linearly, this can be written 
as Zc i- ZQ-P 2 AH. In fact, we can omit mention of P: the condition is simply that 
Investor G have a market strategy Q and an intrinsic strategy 6 such that Zc + ZQ 2 AFI. 
This is obviously equivalent to having a winning strategy in the simplified game for super- 
replicating H .  
I 

328 
CHAPTER 13: GAMES FORAMERICAN OPTIONS 
13.3 WEAK AND STRONG NOTIONS OF PRICE 
In this section we formulate weak and strong notions of price, corresponding to the 
weak and strong notions of super-replication, for financial instruments. 
Intuitively, pricing a financial instrument H is a matter of comparing it with cash. 
If an investor can always achieve as much with the instrument as he can with $c, then 
the instrument is worth at least c; if he can always achieve as much with $c as he can 
with the instrument, then the instrument is worth no more than c. 
Because $c is a passive instrument, there is no difference between weakly and 
strongly super-replicating it with another instrument. So we may define H’s lower 
price by 
- 
IE H := sup{c E R I H weakly super-replicates $c} 
= sup{c E R I H strongly super-replicates $c}. 
On the other hand, there may be a difference between weakly and strongly super- 
replicating H ,  even with cash, and so we must consider strong and weak versions of 
upper price. The weak upper price is 
- 
IE H : = inf { c E R I $c weakly super-replicates H }  , 
and the strong upper price is 
- 
- 
IEH := inf{c E IR 1 $c strongly super-replicates H } .  
- 
Because strong super-replication implies weak super-replication, E H 5 EH. 
upper price: 
Proposition 13.2 
H 5 
H. 
Proof If 
H > H ,  then there exist real numbers c and d such that c < d, $c weakly super- 
replicates H ,  and H weakly super-replicates $d. This implies that $c weakly super-replicates 
$d. So given a strategy P for trading in the market, there is a strategy Q for trading in the 
market such that ZQ + c 2 Z p  + d. This implies Z Q P p  2 d - c, contradicting the coherence 
of the market. 
I 
Using the coherence of the market, we see that lower price cannot exceed weak 
So we have the relation (13.1) mentioned in the introduction to this chapter: 
- 
IE H 5 EH 5 EH. 
As usual, we speak simply of price when upper and lower prices coincide: 
When 
When 
H and E H  coincide, their common value is the weak price for H .  
H and EH coincide, their common value is the strong price for H .  
- 
When the strong price exists, the weak price also exists and has the same value. 

13.4: PRICING AN AMERICAN OPTION 
329 
- 
We will be mainly interested in IEo H ,  & H ,  and EoH, which are defined in 
exactly the same way as H ,  F H ,  and EH but starting in the situation 0 where wo 
has just been announced. 
If H is a European option or some other passive instrument, super-replicating 
it stronlgly is the same as super-replicating it weakly, and therefore there will be 
no difkrence between its weak or strong upper price. Moreover, as the following 
proposition makes clear, our new concepts of upper and lower price agree, in the 
case of European options, with the concepts of upper and lower price that we used in 
preceding chapters. 
Proposition 13.3 If24 is a European option with payoff function U ,  then & 24 = 
&((v(s~)) 
and& 24 = Eo(U(SN)), 
0 being the situation where wo has just been 
announced. 
- 
Proof Reasoning as in the proof of Proposition 13.2, we see that $c weakly replicates H if 
and only if there is a market strategy P such that c + Zp(wg,. . . , W N )  2 U ( S N )  for all 
w1, . . . , WN . This is same as saying that Investor in the protocol for trading in S alone can 
super-replicate U if he starts with capital c. So lEoU = l E O ( U ( S ~ ) ) .  
Similarly, H weakly replicates $c if and only if there is a market strategy P such that 
U ( S N )  + Zp(w0,. . . , WN) 2 c for all w1,. . . , W N .  This is same as saying that Investor 
in the protocol for trading in S alone can super-replicate -U if he starts with capital -c. So 
- 
EOU = EO(U(SN)). 
I 
13.4 PRICING AN AMERICAN OPTION 
We now consider the problem of pricing an American option on a security S with 
payoff function U ,  assuming that the dividend-paying security D is traded and that 
Market makes the paths S and D satisfy requirements similar to those that we used 
for pricing European options in Chapter 11. 
We begin by writing down the games for super-replicating the American option 
with $c and vice versa. We use the same discrete-time notation as in the preceding 
sections, but now N should be interpreted as an infinitely large number and the 
arithmetic should be understood in terms of nonstandard analysis. 
Because $c is passive, we can use the simplified protocol on p. 327 for super- 
replicating $c with the American option. Because Investor can never be sure to make 
money trading in the market, his strategy for being sure to have $c must accomplish 
this by the time r he exercises the option, and so we can simplify the notation by 
ending the game at that point. So here is our game: 
GAME FOR SUPER-REPLICATING 
$c WITH THE AMERICAN OPTION 
Market Parameters: N ,  C > 0 
ParamLeter for the American Option: U :  (0, co) +- R 
Paramieter for $c: c 
Players: Investor, Market 
Protocol: 

330 
CHAPTER 13: GAMES FOR AMERICAN OPTIONS 
Z, := 0. 
Market announces So > 0 and Do > 0. 
F O R n =  1,2, . . . ,  N :  
Investor announces h, E {Exercise, Hold}, M ,  E R, and 11, 
E R. 
Market announces S, > 0 and D, 2 0. 
1, := I,-l + M,AS,, + V, ( (AS,/S,-1)2 + AD,,). 
r := n. 
EXIT if h, = Exercise. 
Additional Constraints on Market: Market must ensure that S is continuous, 
l/C < S, < C for all n, and vex S 5 2. He must also ensure that D is continuous, 
O < D , < C f o r n = l ,  ..., N - l , D ~ = O , a n d v e x D < 2 .  
Winner: Investor if Z, + U(S,) 2 c. 
In the game for super-replicating the American option with $c, we cannot simplify 
as much, but we can, for the same reasons as in the first game, end the game after the 
round where the option is exercised and eliminate the market trading by the player 
who moves first, the holder of the option in this case. This gives the following 
somewhat simplified game. 
GAME FOR SUPER-REPLICATING THE AMERICAN 
OPTION WITH $C 
Market Parameters: N ,  C > 0 
Parameter for $c: c 
Parameter for the American Option: U :  (0, m) -+ R 
Players: Cash, (Investor + Market) 
Protocol: 
Z,c :=I 0. 
Market announces SO > 0 and DO > 0. 
F O R n =  1,2, ..., N: 
Investor announces h, E {Exercise, Hold}. 
Cash announces numbers M, E R and V, E R. 
Market announces S,, > 0 and D, 2 0. 
1," := 
r := n. 
EXIT if h, = Exercise. 
+ M,,AS, + V, ( (ASn/S,-l)' + AD,). 
Additional Constraints on Market: Market must ensure that s is continuous, 
l/C < S, < C for all n, and vex S 5 2. He must also ensure that D is continuous, 
O <  D , < C f o r n = l ,  ..., N - l , D ~ = O , a n d v e x D < 2 .  
Winner: Cash if 1," 
+ c 2 U(S,). 
In order to show that $c is the strong price of the American option, we must show 
that there is a winning strategy in both games-a 
winning strategy for Investor in the 
first game and for Cash in the second game. 
In order to identify the price $c for which such strategies exist, we need no- 
tions of parabolic potential theory similar to those used in Chapter 6 but for a non- 

13.4: PRICING AN AMERICAN OPTION 
331 
uniform medium. (The Black-Scholes equation is the heat equation corresponding 
to a medium with density proportional to s - ~ . )  
There are several possible approaches. We could develop parabolic potential 
theory for general parabolic differential equations, but this would be time-consuming: 
most standard references (such as Doob [ 1031 and Constantinescu and Cornea [55]) 
only discuss the simplest heat equation. Alternatively, we could exploit the stochastic 
interpretation, replacing Brownian motion with a stochastic process defined by the 
stochastic differential equation 
dS(t) = S(t)dW(t). 
(13.2) 
The simplest approach, however, is to reduce the Black-Scholes equation to the heat 
equation: a smooth function u(s, D )  satisfies the heat equation 
au - iazU 
- 
- -- 
dD 
2 as2 
if and only if the function 
G(s, D )  = u In s - -, D 
( 3 
satisfies the Black-Scholes equation 
dii 
1 ,826 
a~ 
2 
a s 2  
- --s - 
- 
- 
(see (13.4) below). We might remark that this change of variables has a stochastic 
interpretation. When W ( t )  is a Brownian motion, S(t) := eW(t)-t/2 satisfies, by 
16’s formula, the stochastic differential equation (13.2). Since D plays the role of 
remaining volatility, D = T - t, the transformation s r-) In s - D/2 will transform 
a solutilon to (13.2) into a Brownian motion. 
We say that a function u(s, D), (s, D )  E (0, C O ) ~ ,  is supermarket if the function 
(S, D )  E R x (0, m) 
u (es+D/2, D )  is superparabolic (as defined in Chapter 6). 
For any function u : (0, 
m)2 + IF$ we define LSM u to be the Least SuperMarket 
majorant of u, 
if it exists. 
Now we can state our theorem for pricing American options, which is analogous 
to Theorem 11.2 (p. 280) for pricing European options. 
Theorem 13.1 Suppose thepayoflfunction U :  (0, m) -+ R is continuousandgrows 
only at most polynomially fast as s -+ 0 and s -+ co: 
(13.3) 
Define u : (0, 
m), -+ R by u(s, D )  := U(s). 
situation where S(0) and D(0) have just been announced, 
Then LSMu exists, and in the 
(LSMu)(S(O), D(0)) 

332 
CHAPTER 13: GAMES FORAMERICAN OPT/ONS 
is the strong price for the American option with payoff U and maturity T ,  under the 
constraints on Market given in our super-replication protocols. 
Proof This proof is modeled on the proof of the one-sided central limit theorem in Chapter 6. 
Along with every function f(s, D), f : (0,co)’ -+ R, we will also consider the function 
f(S, 
D )  := f(s, D )  obtained from f by the change of variable s = es+D/2. As we have 
already mentioned, when smooth, f(s, D )  satisfies the Black-Scholes equation if and only if 
f(S, 
D )  satisfies the standard heat equation. To see why this is true and for future refer_ence, we 
give the connections between partial derivatives of f(s, D), (s, D) 
E (0, co)’, and f(S, 
D): 
(13.4) 
As before, we will also continue to use tilde for the opposite operation: if f ( S , D )  is a 
function of the type R x (0,co) -+ R, rather then (0, cm)2 + R, f : ( O , O O ) ~  + R is 
defined by the equation f(s, D )  = f(S, D), where S = Ins - D/2. To follow the proof 
of the theorem, it is helpful to split the change of variable ( s ,  D )  r--t (S, D )  into two steps: 
first the taking of the logarithm (s, D )  ++ (S’, D), where S’ := Ins, and then the shearing 
We say that a function u is submarket if -u is supermarket; u is market if it is both 
supermarket and submarket. We know from Chapter 6 that being both superparabolic and sub- 
parabolic is equivalent to satisfying the standard heat equation for locally bounded functions; 
therefore, locally bounded market functions satisfy the Black-Scholes equation. 
The function ii(S, D )  has the least superparabolic majorant LM ii; it is clear that LSM u 
will exist and coincide with L X .  
Let c be a large constant (in particular, c >> C; other requirements will be added later). We 
can (and will) assume that U = 0 outside the interval 1/c 5 s 5 c; indeed: 
(S’, 
D )  ++ (S‘ - D/2, D). 
S(t) will never reach that interval. 
Changing U outside that interval will not change (LSM u)(So, DO) much since: 
- for any constant y E W, 
the function 
is market (this class of functions is the image under the tilde-transformation of 
of functions parabolic in R x (0, co), and even in R’; see, e.g., [103], 1.XV.2, 
Example (a)); 
- we can take y = 3 4  where lc is a number whose existence is asserted in (13.3). 
Since G(S, D )  is constant along the lines S + D/2 = const, the function LA4 ii increases’ 
along those lines (the positive direction along such a line being the one in which D increases). 
The formal argument (the same “shifting” argument as in Lemma 6.2 on p. 139) is: 
LM G(S, D )  5 L M 6  ( S  - S / 2 ,  D + 6 )  
“‘Increases” is used in the wide sense in this proof. 

13.4: PRICING AN AMERICAN OPTION 
333 
when 6 > 0 because 
LM U(S, 
D )  5 f (S - 6/2, D + 6) 5 LM 5 (S - 6/2, D + 6 ) ,  
where f := LM u* and u* (S, D )  is defined as U(S, D )  if D > 6 and as inf U = inf u 
otherwise. Therefore, the function LSM u increases in D. 
First ‘we prove that (LSM u)(So, DO)+€, for any E > 0, strongly super-replicates the Amer- 
ican option U. 
We start with proving that, for an arbitrarily small 6 > 0, Cash can maintain his 
capitalat anyroundnabove(LSM u)(S,, D,+6) ifstartingwith(LSMu)(So, D0+6)+~/2. 
By the aipproximation theorem (stated on p. 139), there is a smooth supermarket function 
U 5 LSM u defined in the region 
- 
(s, D )  E (l/c, c) x (6/2, C + 26) 
and arbitrarily close to LSM u. The construction in the proof of the approximation theorem 
gives 
increasing in D; the property (6.25) (see p. 139) of smooth superparabolic functions 
and (13.4) imply that u, like any other smooth supermarket function, satisfies the “Black- 
Scholes iinequality” 
ai7 
1 za2U 
- > - s -  
d D  - 2 
a s 2 ’  
Therefore, we will have 
\ 
I 
+ --(SB, 
1 a3v 
D: + 6)dSk(dS,)2 + -- a3u (S:, D: + 6)dDk(dS,)2 
2 a s 3  
2 dDds2 
(Sk,Dh +b)dD,dS,+ 
--(Sk,Dk+S)(dD,)’ 
2 dD2 
+- dDds 
1 a2D 
(13.5) 
in place of (10.39) (p. 250). Since the sum of the addends after the second on the right-hand 
side of (I 3.5) is negligible, Cash will be able to maintain his capital above LSM u(S,, D, +6) 
until D, +6 reaches 6 at time n = N .  (Notice that, sincevis increasing in D, Cash only needs 
to hold long positions in security D when using this hedging strategy. Similarly, Investor’s 
strategy constructed below will require short positions in D.) Since (LSM u)(S,, D, + 6 )  2 
u(Snr D, + 6) = U(S,), we will prove that (LSM u)(So, DO) + E strongly super-replicates 
the Ameirican option if we show that the starting capital (LSM u)(So, DO + S) + ~ / 2  
does not 
exceed (LSM u)(So, DO) + E for sufficiently small 6 > 0. This immediately follows from the 
continuity of (LSM u)(s , D )  in D, which, in its turn, is an easy implication of the continuity 
of LM U (see Lemma 6.2 on p. 139). 
We have proved the “positive” part of the theorem; but before we can proceed, we will 
need several definitions. Let 5 be the set where LSM u is different from u; since LSM u 2 u, 
LSM u is lower semicontinuous and u is continuous, D is open. The argument of Theorem 6.1 
(p. 138) applied to LSMu = LMU shows that LSMu is market (i.e., satisfies the Black- 
Scholes equation) inside D. 
Now we can prove that c = (LSMU)(SO,DO) - E ,  where E is a positive constant, is 
strongly super-replicated by the American option. First we consider the log-picture, (s, D )  ++ 
(S, D )  ::= (In s - D/2, D). Let D be the set where LM U > U (i.e., 2, is 5 in the log-picture). 
Analogously to the proof of Theorem 6.1 on p. 138, define 
- 
D* := { ( s , D )  I LMU-U > ~ / 2 } .  

334 
CHAPTER 13: GAMES FORAMERICAN OPTIONS 
Our goal is to prove that in the game for super-replicating $c with the American option, Investor 
can, starting with 0, end up with at least LSM .(SO, DO) - E after exercising his American 
option. Investor’s market strategy before (Sn, Dn) hits ae* will be to replicate the first two 
addends on the right-hand side of (10.39) with the opposite sign, wherev is LSM u. Therefore, 
at the time of hitting E6* Investor’s capital will be close to -U(S,) + LSM v,(So1 DO); 
exercising the American option, he will procure a final capital close to LSM u(S0, DO). 
I 
Examples 
Suppose all the conditions of both Theorems 11.2 and 13.1, including the regularity 
conditions on the payoff function U ,  are satisfied. The solution to the Black-Scholes 
equation will be 
u(s, D) = 
U(set) N - D ~ ,  
D ( ~ z )  
I 
- 
(cf. (11.13) on p. 280). If U is convex, Jensen’s inequality tells us that E(S, D) 2 
U(sc), where c is the mean value of ez under the distribution N-ola,~(dz). 
A 
simple calculation shows that c = 1. This result, 
- 
u(s1D) 2 
U(S)l 
shows that Ti = LSM u (u is defined in Theorem 13.1) and that it is optimal to never 
exercise convex American options, such as plain put and call options. It should be 
remembered, however, that we are assuming zero interest rates and no dividends for 
S. If either of these assumptions is violated, early exercise may be optimal; see, e.g., 
[154]. 
The case of binary options (see [351]) is not formally covered by Theorem 13.1, 
because their payoff functions are discontinuous. But it is easy to see that in the case 
of an American binary call, 
l i f s > a  
0 otherwise 
U ( s )  = 
(where a is the strike price), the fair price is given (assuming D(0) < a) by the value 
at the point (S(0), D(0)) of the solution u(s, D) 
to the Black-Scholes equation in 
the region (s, D) E (0, a )  x (0, cm) with the initial condition u(s, 0) = 0 and the 
boundary condition u(a, D )  = 1. The analogous assertion for binary puts is also 
true. 

14 
Games for DiJffusion 
Processes 
So far in our study of game-theoretic option pricing, we have moved as far as 
possible away from the usual stochastic theory. Instead of assuming that the price of 
the underlying security S is governed by a stochastic differential equation, we have 
put much weaker constraints on the price process S(t), and we have required that the 
market should price a derivative V that anticipates the realized variance of S. 
In this chapter, we translate the stochastic Black-Scholes theory more directly 
into our game-theoretic framework. It should be no surprise that such a translation 
is possible, for as we learned in $8.2, any stochastic process can be embedded in a 
probability game. But it is instructive to work out the details. We obtain new insights 
not only into the Black-Scholes theory, but into diffusion processes in general. 
As we learned in Chapter 9, the stochastic Black-Scholes theory has both game- 
theoretic and stochastic elements. On the game-theoretic side, we have Investor 
playing a hedging strategy: hold (au/as)(S(t), 
t )  shares of S at time t. On the 
stochastic side, Market somehow generates the increments dS(t) according to the 
stochastic differential equation 
(14.1) 
The idea of this chapter is to interpret (14.1) game-theoretically, so that the entire setup 
becomes game-theoretic. As we learned in $8.2, we make a sequential stochastic 
model game-theoretic by interpreting the probabilities given by the model as a fixed 
strategy for Forecaster in a game involving Forecaster, Skeptic, and Reality; the 
probabilities are Forecaster’s forecasts for what Reality will do, which are binding 
on Reality in the sense that Reality can violate them on average only if she is willing 
to allow Skeptic to become rich. So the game-theoretic interpretation of (14.1) is 
335 
Probability and Finance: It’s Only a Game! Glenn Shafer, Vladimir Vovk 
Copyright 0 2001 John Wiley & Sons, Inc. 
ISBN: 0-471-40226-5 

336 
CHAPTER 14: GAMES FOR DlFfUSlON PROCESSES 
0 pdt is the price Forecaster sets for dS(t)/S(t), 
and 
0 odt is the price Forecaster sets for (dS(t)/S(t))2. 
With this interpretation, we call (14.1) a game-theoretic differential equation. 
The game-theoretic interpretation of what was a stochastic element adds additional 
players to the game. In our discussion in Chapter 9 (see the protocol on p. 217) we 
had only Investor, who was hedging, and Market, who was behaving stochastically. 
Now we have added Skeptic. We need not add Reality, because Market is already 
there to choose the dS(t). And we need not count Forecaster as a player, because 
he is required to follow the strategy defined by (14.1), which is known to the other 
players and therefore becomes part of the protocol of the game. So the game now has 
three players: Investor, Skeptic, and Market. Both Skeptic and Investor are playing 
against Market. Investor’s goal is to reproduce the derivative 24 starting with the 
Black-Scholes price by trading in S alone. Skeptic’s goal is to become rich. Skeptic 
and Investor win if one of them succeeds. We will show that as a team they do have 
a winning strategy. Thus Investor can succeed in his hedging almost surely-i.e., 
unless Skeptic becomes infinitely rich. 
To summarize, this chapter’s game-theoretic reinterpretation of the stochastic 
Black-Scholes theory contrasts with the game-theoretic Black-Scholes theory of 
Chapters 10 and 11 in two major respects: 
1. In the Black-Scholes game of Chapters 10 and 11, Investor trades in both S 
and D. 
In the game of this chapter, he trades only in S. 
2. In the Black-Scholes game of Chapters 10 and 11, Investor’s hedging always 
succeeds. In the game of this chapter, it succeeds only almost surely-that 
is, 
only if Skeptic does not become rich. 
One instructive sidelight of the Black-Scholes argument that we study in this 
chapter is the way the drift p drops out. In the stochastic argument, the drift is usually 
irrelevant to what we want to do, but we are accustomed to thinking that it needs to 
be present to complete the stochastic model. In the game-theoretic interpretation, it 
becomes clear that we can dispense with it altogether. We do not need Forecaster to 
price dS (this is what he would do with p); we only need for him to price 
(this 
is what he does with (T). We represent this possibility symbolically by writing 
= no price for drift + adW (t) . 
S(t) 
(14.2) 
Whereas (14.1) is a game-theoretic differential equation for drift and volatility, (14.2) 
is a game-theoretic differential equation for volatility only. It means that Skeptic can 
buy (dS(t)/S(t))2 
for adt but cannot buy the relative increment dS(t)/S(t) at any 
price. It should not be confused with (14.1) with p = 0, which says that Skeptic can 
buy (dS(t)/S(t))2 
for adt and dS(t)/S(t) 
for 0. 
The game-theoretic interpretation of diffusion processes may be useful not only in 
option pricing but also in other fields where diffusion processes are used. In general, 

14.1: GAME-THEORETIC DIFFUSION PROCESSES 
337 
it clarifies the meaning of the assumption that a phenomenon follows a diffusion 
process, and it expresses the assumption in a way that may often point to weaker or 
different assumptions. 
We begin this chapter with a general discussion of protocols for diffusion processes 
(514.1) and a game-theoretic version of ItB’s lemma (514.2). Then we use these 
ideas to obtain our game-theoretic reinterpretation of the stochastic Black-Scholes 
formula ($ 14.3). In appendixes (3 14.4 and $14.5), we comment on the nonstandard 
mathematics of this chapter and on some related stochastic literature. 
14.1 GAME-THEORETIC DIFFUSION PROCESSES 
In this section, we lay out some protocols in which a game-theoretic differential 
equation can serve as a strategy for Forecaster. The players in these protocols are 
Forecaster, Skeptic, and Reality. Our Black-Scholes game in 514.3 will add Investor 
and substitute Market for Reality. 
We begin with protocols in which Forecaster prices both drift and volatility, and 
then we consider a simpler protocol where he prices only volatility. 
As usual, our games are played over the time period [0, TI, during which a huge 
(nominally infinite) number N of rounds are played; each round occupies a tiny 
(nominally infinitesimal) time period of length dt := TIN. As in our protocol for 
the strong law of large numbers in $4.1, we define a process S, in terms of increments 
2,. 
Pricing Drift and Volatility 
We begin with two protocols in which Forecaster can use a game-theoretic differential 
equation for drift and volatility. 
The first protocol is very similar to the protocol that we used to prove the strong 
law of large numbers in $4.1. 
DIFFUSION 
PROTOCOL 
0 
Players: Forecaster, Skeptic, Reality 
Protocol: 
KO := 1. 
So := 0, To := 0, A0 := 0. 
F O R n =  1,2, ..., N: 
Forecaster announces m, E R and v, 2 0. 
Skeptic announces numbers M, E R and V, E R 
Reality announces number x, E R. 
s, := s,-1 + 2,. 
T, := T,-1 + m,. 
il, := A,-1 + v,. 
Ic, := Ic,-1 + Mn(x, - m,) + V,((x, - m,) - v,). 

338 
CHAPTER 14: GAMES FOR DlFFUSlON PROCESSES 
This protocol includes definitions of the trend T, and the quadratic variation A, of 
the process S,. 
In the second protocol, Forecaster provides forecasts for xn and x:. 
DIFFUSION 
PROTOCOL 
1 
Players: Forecaster, Skeptic, Reality 
Protocol: 
KO := 1. 
So := 0, To := 0, A0 := 0. 
F O R n =  1,2, ..., N :  
Forecaster announces m, E R and v, >_ 0. 
Skeptic announces M, E R and V, E R. 
Reality announces 5 ,  E R. 
T, := T,-I + m,. 
Ic, := K,-1 + M ~ ( z ,  - m,) + V,(Z; - v,). 
s, := s,-1 + 5,. 
A, := A,-1 + 21,. 
(14.3) 
These two protocols differ only in the role of v,. In Diffusion Protocol 0, v, is the 
price of (2, - m,)'-that 
is, the variance of IC,. In Diffusion Protocol I, it is simply 
the price of 2:. Because 
2 
IC:~ = ((x, - m,) + m,) = (2, - m,I2 + 2m,(z,, - m,) + m:: 
and because there is a ticket with payoff 2, - m,, the real difference between the 
two protocols is in the term mi. Because m, typically has the order of magnitude 
O(dt), summing mi with bounded coefficients will produce something also of order 
O(dt). So the two protocols are very close. 
In either of the two protocols, if Forecaster always sets 
m, := p(S,-l, ndt)dt and v, := o(,S,-l, ndt)dt, 
(14.4) 
where the functions p : R2 + R and CT : R2 -+ [0, co) are known in advance to 
all the players, then we say that Forecaster follows the game-theoretic differential 
equation 
dS(t) = p(S(t),t)dt + a(S(t),t)dW(t). 
(14.5) 
If we then adopt the fundamental interpretative hypothesis, then we may say that 
Reality is governed by this equation (see p. 182). 
Pricing Volatility Alone 
Consider now the following simplified protocol: 
DIFFUSION 
PROTOCOL 
2 
Players: Forecaster, Skeptic, Reality 

14.1: GAME-THEORETIC DIFFUSION PROCESSES 
339 
Protocol: 
KO := 1. 
So := 0, A0 := 0. 
F O R n =  1,2,.,.,N: 
Forecaster announces v, 2 0. 
Skeptic announces V, E R. 
Reality announces 2, E R 
s, := s,-1 + %,. 
A, := An-1 + w,. 
Ic, := K,-1 + Vn(%2, - u,). 
In this protocol, Skeptic is not offered 2,-tickets at any price, and Forecaster does 
not say anything that can be interpreted as an assumption about trend. 
If Forecaster always sets 
u, := (T(S,-1, ndt)dt, 
where D : R2 + [O, co) is known in advance to all the players, then we say that 
Forecaster follows the game-theoretic differential equation 
dS(t) = no price for drift + a(S(t), t)dW(t). 
This is a game-theoretic differential equation for volatility alone. 
Quadratic Variation and 2-Variation 
There are two distinct concepts of quadratic variation in our protocols: vars (2) and 
AN. The following proposition relates the two. We do not make any assumption 
here about the strategy followed by Forecaster. 
Proposition 14.1 Suppose Reality is required, in one of our diffusion protocols, to 
make S(t) continuous. Then almost surely, vars(2) < rn ifand only $AN < co. 
Proof Because S is continuous, all the zn are infinitesimal and hence less than 1. Suppose 
vars(2) < co. Fork = 1,2, . . ., define a martingale T(') inductively by 
n 
i=l 
for all values of n starting with n = 1 and switching, when and if the right-hand side gets 
down to the value 1, to ~
k
)
 
= T,(F), . Then the martingale 
(14.6) 
exists (because the strategies corresponding to Tik) 
take only two values, 0 or -1) and goes 
from 1 to an infinitely large amount when ci 
x: is finite but Xi 
zli is infinitely large. 

340 
CHAPTER 14: GAMES FOR DIFFUSION PROCESSES 
The construction is similar in the case where we start with the assumption that A(T) < 00. 
In this case, we define 
7$k’ 
= 2k + - y ( Z ?  - v,) 
9,=1 
before the right-hand side reaches 1 and ~
k
)
 
= et\ afterwards. The martingale (14.6) 
again exists and goes from 1 to an infinitely large amount when c, 
v2 is finite but c, 
z: is 
infinite. 
I 
In measure-theoretic probability [112, 158, 2061, the process A(t) corresponds 
to the predictable quadratic variation of the price process S(t), whereas vars(2) 
corresponds to the final value of the optional quadratic variation of s(t). For 
continuous semimartingales, the two coincide almost surely ([ 1581, Theorem 1.4.52). 
Here we draw only the weaker conclusion that that the finiteness of vars(2) and 
of A(T) imply each other almost surely, but they actually nearly coincide with high 
lower probability; this can be shown in the same way that we show that (14.11) is 
small in absolute value in the proof of Proposition 14.2 below. 
14.2 ITO’S LEMMA 
In this section, we formulate and prove 16’s lemma for our diffusion protocols. We 
do not assume that Forecaster follows any particular strategy, but we do impose 
constraints on Forecaster’s and Reality’s moves. 
Let f and g be real valued functions on ‘IT. We define the integral (or stochastic 
integrul) s,’ f dg as follows: 
,T 
N 
(we will not need other limits of integration). This definition uses f ( ( n  - 1)dt) 
rather than f ( n d t )  because f((n - 1)dt) is known before Skeptic’s move at trial 
n. This is analogous to the standard requirement of predictability for the integrand 
in measure-theoretic stochastic integration, where it is usually assumed that f is a 
path of a locally bounded predictable process and g is a path of a semimartingale 
[112, 1581. 
Let A and B be two variables (i.e., functions of Forecaster and Reality’s moves). 
We will say that A and B coincide almost surely, A “2. B, under some set of 
conditions y on Forecaster and Reality’s moves in a diffusion protocol if, for any 
(arbitrarily small) E > 0 and any (arbitrarily large) C > 0, Skeptic has a strategy in 
the protocol guaranteeing that mino<t<T 
_ -  K ( t )  2 0 and either 
or 

14.2: ITO’S LEMMA 
341 
when y is added to the protocol as a constraint on Forecaster’s and Reality’s moves. 
Proposition 14.2 (It6’s Lemma) In DifSusion Protocol 2, 
provided f (s, t )  is a smooth function and Forecaster and Reality are required to 
satisfy 
0 vars(2) < co or A(T) < co, 
SUPOjt<T 
< 
0 A(t) and S(t) are continuous. 
Proof By Proposition 14.1, the two conditions vars(2) < 03 and A(T) < co imply each 
other almost surely, and hence we assume that both vars(2) < 03 and A(T) < 03. 
Let A =‘ B (in words: A and B are t-close) stand for IA - BI 5 t. Expanding the 
definitions, we can rewrite (14.7) as: inf, K ,  2 0 and either 
f ( S N , T )  - f(S0,O) 
or K N  2 C. Here, as usual, dt = TIN. 
Using Taylor’s formula, we find (0, are numbers between 0 and 1): 
= 5 
( $(Sn, (n - 0,)dt)dt + af(Sn-1; (n - l ) d t ) s ,  
as 
,=l 
1 a 2 j  
+ --(Sn-l + ON+,(S, - Sn-1), (n - 1)dt)zi 
2 as2 

342 
CHAPTER 14: GAMES FOR DlFFUSlON PROCESSES 
Comparing this to (14.8), we can see that it is sufficient to prove that 
and 
are infinitesimal and that 
(14.9) 
(14.11) 
is less than e in absolute value unless some nonnegative martingale starts at 1 and ends at C. 
The assertion that (14.9) is infinitesimal follows from the fact that, uniformly in n, 
where c is  up^<^<^ max (a2 f/at2, a 2 f / ( d s a t ) )  (recall that the function f = f ( s ,  t )  is 
smooth and so b&Gded with all its derivatives in the region t E [0, T ]  and Is1 5 supt lS(t)l). 
To see that (14.10) is infinitesimal, notice that 
uniformly in n, and therefore, for an arbitrarily small S > 0, 
where c is an upper bound on vars(2). 
To complete the proof, we will prove that (14.1 1) squared, that is, 
is less than e2 unless some nonnegative martingale increases its initial value C-fold; our proof 
will again be similar to the proof of the weak law of large numbers in Chapter 6. Let us 
consider the nonnegative submartingale 

14.2: /TO’S LEMMA 
343 
Since 
its “compensator” is 
(This is not a usual compensator, because it is not predictable.) Writing c for an upper bound 
on a2 f /as2, we see that 
N 
N 
N 
n = l  
n=l 
n=l 
and this is infinitesimal because of the continuity of S(t) and A(t) and the finiteness of 
vars (2) and A(T). Therefore, the martingale 
7, := E 2 / C  + sn - An 
(14.12) 
I 
Proposition 14.2 extends easily to Diffusion Protocols 0 and 1. Skeptic can use the 
strategy constructed for Diffusion Protocol 2 and always take M ,  = 0; in Diffusion 
Protocol 1 m, will be completely irrelevant, and in Diffusion Protocol 0 the role of 
z, 
will be played by the difference X, - m,. In the case of Diffusion Protocol 0, 
however, continuity and boundedness (and finiteness of the 2-variation if A(T) < cc 
is omitted) should be imposed on the difference S - T rather than on S. 
The assumption that supt IS(t)I is finite is essential for Proposition 14.2. We 
cannot deduce it from the finiteness of A(T) since no assumptions about the drift of 
S(t) are made (the usual idea of bounding a compensator of S2(t), as used in the 
proof of the weak law of large numbers in 56.1, will not work since compensators will 
change), To verify that the proposition fails when the condition supt IS(t)l < cc is 
dropped, set f(s, t) := es. Arguing indirectly, suppose the proposition does remain 
true, suppose w, = dt for all n, and suppose Reality randomly chooses X, = 0 
or z, 
= @. Skeptic’s capital Ic, will be a martingale; therefore, by Doob’s 
inequality K N - ~  
will be at most 100 with probability at least 99%. Fix such a typical 
play through step N - 1. Consider the difference Do between the left-hand side and 
right-hand side of (14.7) when XN = 0 and the difference D+ between them when 
X N  = G. 
The difference D+ - Do will be at least 
is nonnegative. If its final value TN exceeds c2, it will have made t2 out of E2/C. 
( e s N - l + &  
- e s N - l  ~.lt) 
- ( ~ s N - ’ )  
= e S N - 1  
e
m
 
- 1 - a) 
2 e S N - l d t ,  

344 
CHAPTER 14: GAMES FOR DIFFUSION PROCESSES 
which, with probability close to 1, is infinitely large, comparable to eJN IN. Since 
in both cases (whether X N  is 0 or &) 
ICN will not exceed 200, we arrive at a 
contradiction. 
14.3 GAME-THEORETIC BLACK-SCHOLES DIFFUSION 
We now expand our diffusion protocols by adding another player, Investor, who 
tries to replicate a European option U(S(T)) at the cost given by the Black-Scholes 
formula. As we explained in the introduction, if Forecaster follows the appropriate 
game-theoretic differential equation, Investor and Skeptic can assure that Investor 
achieves his goal almost surely-that 
is, unless Skeptic becomes infinitely rich. 
Adding Investor and his capital process to Diffusion Protocol 1, changing the 
name of Reality to Market, and requiring S, > 0, we obtain this protocol: 
BLACK-SCHOLES 
DIFFUSION 
PROTOCOL 
1 
Parameters: p, (T > 0, c 
Players: Forecaster, Skeptic, Investor, Market 
Protocol: 
KO := 1. 
1, := c. 
Market chooses So > 0. 
F O R n =  1,2, ..., N :  
Forecaster announces m, E R and v, 2 0. 
Skeptic announces M, E R and V, E R. 
Investor announces X ,  E R. 
Market announces S, > 0. 
K ,  := K,-1 + M,(AS, - 711,) + V,((~ls,)~ 
- w,). 
1, := 2,-1 + X,AS,. 
Additional Constraints: Forecaster must follow (14. l), considered as a game- 
theoretic differential equation; this means that he must set 
m, := pS,-ldt 
and 
v, := u2S:-ldt. 
Market must assure that S is continuous and max IS1 < m. 
Here K ,  is Skeptic’s capital process, and Z, 
is Investor’s capital process. 
Suppose y is a property that may or may not be satisfied by the path S(t) chosen 
by Market. We say that c E R is the almost sure price given y for a European option 
U ( S ( T ) )  if, for any (arbitrarily small) E > 0 and for any (arbitrarily large) C > 0, 
there exist strategies for Investor and Skeptic in the preceding protocol that guarantee 
that inft K(t) 2 0 and either K N  2 C or 
4s) =+ 11, - U(S(T))I L E 
if Market is constrained to satisfy y. 

14.3: GA ME-THEORETIC BLACK-SCHOL ES DIFFUSION 
345 
The following is the analog of Theorem 11.2 (p. 280) closest to the usual measure- 
theoretic Black-Scholes formula: 
Proposition 14.3 Suppose U is a Lipschitzian function. Then when S(0) > 0 has 
just been announced in Black-Scholes DifSsion Protocol 1, the almost sure price for 
U ( S(T )) is 
J, U(S(0)eZ) 
N-Tu2/2,TuZ(dZ). 
This is almost a direct translation of the measure-theoretic Black-Scholes formula. 
We now simplify in the spirit of Diffusion Protocol 2, omitting the drift altogether. 
BLACK-SCHOLES 
DIFFUSION 
PROTOCOL 
2 
Parameters: p, CT > 0, c 
Players: Forecaster, Skeptic, Investor, Market 
Protocol: 
KO := 1. 
z, := c. 
Market chooses SO > 0. 
FORn = 1,2,. . . , N :  
Forecaster announces v, 2 0. 
Skeptic announces V, E R. 
Investor announces X, E R 
Market announces S, > 0. 
IC, := ICn-l + Vn((AS,)2 - v,). 
z, := z,-1 + x,as,. 
Additional Constraints: Forecaster must follow (14.2), considered as a game- 
theoretic differential equation; this means that he must set 
v, := 02Si-,dt. 
Market must assure that S is continuous and max IS1 < m. 
Theorem 14.1 Suppose U is a Lipschitzian function. Then when S(0) > 0 has just 
been announced in Black-Scholes Diffusion Protocol 2, the almost sure price for 
U(S(T)) 
is 
Proof The proof is similar to that of Theorem 11.2 in Chapter 11; the most essential difference 
is that now we take D = D(t) := a2(T - t ) .  Assuming that U is smooth (we reduce the case 
where U is merely Lipschitzian to the case where it is smooth as in Chapter 11) and putting 
f (s, t )  := v(s, 
a2(T - t ) ) ,  we find from the Black-Scholes equation (10.38): 

346 
CHAPTER 14: GAMES FOR DIFFUSION PROCESSES 
so from ItB’s lemma (Proposition 14.2 on p. 341) we obtain, setting zn := AS,, 
f(SN,T) - f(S0,O) 
since the last sum is exactly the gain of Investor’s strategy which recommends buying 
af 
-(Sn--l, (n - 1)dt) 
as 
shares on round n, this completes the proof. 
I 
Proposition 14.3 follows immediately from Theorem 14.1, because Skeptic can 
reduce Black-Scholes Diffusion Protocol 1 to Black-Scholes Diffusion Protocol 2 by 
setting M, to 0 for all n. 
14.4 APPENDIX: THE NONSTANDARD INTERPRETATION 
In this appendix we give a few guidelines concerning how our formulation and proof 
of It6’s lemma (p. 341) is to be understood in the nonstandard framework spelled out 
in $11.5. 
As usual, we consider a sequence of protocols indexed by k = 1,2,. . ., the kth 
protocol having Nk rounds of play. The condition vars(2) < 03 was explained 
in Chapter 11. The condition A(T) < co is interpreted analogously: the sequence 
A(’))(T) of quadratic variances corresponding to k = 1,2, . . . (with a fixed non- 
trivial ultrafilter on the set of ks) is a finite nonstandard number. In a similar way 
supt IS(t)l < co means that forevery k we consider M(kj := supt IS(’)(t)l, and the 
sequence M(kj is a finite nonstandard number; S(t) being continuous means that the 
sequence dk) := ~up,,~,,,,,~(k) 
xik) is an infinitesimal nonstandard number. The 
condition info<t<T K ( t )  2 0 means that the capital process is nonnegative for most 
k. The martingale (14.12) is also nonnegative for most k. The continuity of A(t) and 
S(t) implies that the martingale (14.6) is nonnegative for most k (namely, for the k 
I
I
 
such that sup, Iz, ( k )  I 5 1 and sup, u::’ 5 1). 

14.5: APPENDIX: RELATED STOCHASTIC THEORY 
347 
14.5 APPENDIX: RELATED STOCHASTIC THEORY 
In this appendix, we relate the ideas of this chapter to some of the existing stochastic 
literature. We comment on stochastic differential equations, risk-neutral valuation, 
and attempts to study the paths of stochastic processes outside of measure theory. 
Stochastic Differential Equations 
Measure-theoretic probability theory distinguishes between strong and weak solu- 
tions for stochastic differential equations. In the case of weak solutions, we do not 
really begin with a Wiener process W(t) in (14.5): we ask only for a process with 
infinitesimal increments with mean p(S(t), t)dt and variance 02(S(t), 
t)dt. This 
chapter's game-theoretic interpretation of stochastic differential equations is in this 
spirit. For strong solutions, on the other hand, we actually begin with a Wiener 
process W(t), and we use (14.5) as a recipe for constructing a process S(t) from 
W(t). The recipe does not always work; for example, when we try to follow (14.5) 
starting at t = 0, S(t) may explode to infinity in finite time. It is not trivial to iden- 
tify conditions under which the recipe does work, and these conditions are of course 
stronger than those required for weak solutions. But the main difference is that strong 
solutions require much stronger conditions on the drift term p(S, t), which does not 
even appear in our game-theoretic treatment of the Black-Scholes formula. We might 
construct strong game-theoretic solutions by means of an auxiliary protocol similar 
to Diffusion Protocol 0 but with Forecaster always choosing rn, = 0 and u, = dt; 
Reality's path W(t) in this protocol would have the properties of Brownian motion, 
and we could then call the process S(t) defined by (14.5) a strong solution. 
Stroock and Varadhan's representation of the problem of finding a weak solution 
to a stochastic differential equation as a martingale problem is especially close to our 
game-theoretic approach; see [299, 3001 and [ 1661, 55.4. Stroock and Varadhan's 
idea, loosely speaking, is to look for a probability measure on the set of all continuous 
functions y : [O, m) + R such that for every function f that is twice continuously 
differentiable, 
(14.13) 
is a martingale difference (at least in a local sense). It is sufficient to require this 
condition for f ( y )  = y and f(y) = y'; see, e.g., [166], Proposition 5.4.6. For 
f(y) = y, (14.13) reduces to requiring that 
dv(t) - P(Y(9,t)dt 
(14.14) 
should be a martingale difference; in game-theoretic terms, Skeptic should be able to 
buy or replicate the 2,-tickets responsible for the addend M,(X, - m,) in (14.3), 
where rn, is given by (14.4). For f(y) = y2, (14.13) reduces to requiring that 
d ( Y 2 W )  - 2P(Y(t)>t)Y(t)dt - 02(Y/(t)d)dt 
= 2Y(t)ldY(t) - P(Y(t),t)dtl + [(dY(t))2 - a2(?/(t),t)dtl 

348 
CHAPTER 14: GAMES FOR DIFFUSION PROCESSES 
be a martingale difference; since (14.14) is a martingale difference, this is equivalent 
to 
dY(t)I2 - g 2 ( y ( t ) , t ) d t  
being a martingale difference. In the game-theoretic terms, this says Skeptic should 
be able to buy or replicate the x:-tickets 
responsible for the addend V,(xi - v,) in 
(14.3), where ZI, 
is given by (14.4). 
A large part of the theory of stochastic differential equations is concerned with the 
existence and uniqueness of solutions. We have not attempted here even to define 
precisely what existence and uniqueness would mean in the game-theoretic approach, 
but the meanings are clear at an intuitive level. Existence of a solution to a game- 
theoretic differential equation means that the protocol is coherent when the equation 
is interpreted as a constraint on Forecaster, so that the lower price of a variable never 
exceeds its upper price. Uniqueness means that the lower and upper price coincide 
for variables that are well behaved. This corresponds to uniqueness in the sense of 
probability law in measure-theoretic probability ([ 1661, 55.3.A). 
Risk-Neutral Valuation 
The stochastic principle of risk-neutral valuation [ 1471, discussed in detail in 59.6, 
can be summarized as follows: 
1. Modify the probability measure governing the underlying security S so that 
under the modification (usually called the equivalent martingale measure in 
the probabilistic literature and the risk-neutral or risk-adjusted probability 
in the financial literature) the price process S(t) (properly discounted if our 
assumption of zero interest rates is dropped) is a martingale. 
2. Find the price of the given contingent claim by computing the payoff’s expec- 
tation under the risk-neutral probability. 
The modification mentioned in Step 1 can be effected by removing the drift term 
from the stochastic differential equation governing S(t) (more generally, equating 
the drift to the interest rate). 
The key difference between the stochastic and game-theoretic approaches is that 
whereas the stochastic approach essentially replaces a strategy for Forecaster that 
gives arbitrary values for the drift by one that always gives 0 for the drift, the game- 
theoretic approach does not start with any price for the drift but still obtains the same 
probabilities (now game-theoretic). 
Stochastic Processes without Measure 
Because it does not assume a measure as its starting point, our game-theoretic in- 
terpretation of stochastic processes deals directly with paths. A number of other 
authors, while not taking a game-theoretic approach, have also considered how paths 
of stochastic processes might be analyzed directly. Here we briefly review some 
examples. 

14.5: APPENDIX: RELATED STOCHASTIC THEORY 
349 
Follmer (1981) describes a pathwise approach to It6’s integral. For some functions 
f : [0, TI -+ R and sequences (m) of finite partitions of [0, TI whose mesh tends 
to 0, Follmer defines the notion of quadratic variation off relative to (m) and uses 
this definition to prove a pathwise version of ItB’s lemma, where stochastic integral 
is defined as the limit of Riemann-Stieltjes sums along (7;2). The dependence on 
(7,) is, of course, unattractive. Another approach to pathwise stochastic integration 
is described in Willinger and Taqqu (1989) and applied to finance in Willinger and 
Taqqu (1991). 
f dg has been studied for processes g that are not semimartingales. 
In the special case where f and g are continuous and 1/- 
f + 1 / W g  > 1, 
this integral can be defined pathwise as the Riemann-Stieltjes integral (Young 1936). 
Bertoin (1989) proves a variant of It6’s lemma for Young’s integral. Pathwise stochas- 
tic differential and integral equations involving a driving process with trajectories g 
satisfying 
g < 2 are considered in recent papers by Mikosch and NorvaiSa (2000) 
and Klingenhofer and Zahle (1999). 
Follmer’s work was the starting point for the work by Bick and Willinger (1994) on 
dynamic hedging without probabilities, which we mentioned in Chapter 11 (p. 281). 
They give conditions on a path under which an option can be priced by the Black- 
Scholes formula, without any assumption about other paths that are not realized. 
These conditions are much closer, however, to the standard stochastic conditions 
than our game-theoretic conditions are. For their Proposition 1, they assume that the 
quadratic variation of the log price path In S(t) is linear; in their notation, [Y, Y]t = 
Y o  + a’t, where S(t) = exp Y ( t )  and [Y, Y]t is the pathwise quadratic variation. 
They also consider (their Proposition 3) a more general case where d[S,S]t = 
p2 (S(t), t) for a continuous function p; but in this case p has to be known in advance 
for successful hedging to be possible. 
Bick and Willinger’s work was continued by Britten-Jones and Neuberger (1996). 
In their framework, a trading strategy is a function of the current price of the un- 
derlying security and its future variance. The future variance, in our notation, is 
(In S(t + dt) - In S(t))2 + (In S(t + 2dt) - In S(t + dt))2 + . . ‘ (they do not as- 
sume, however, a constant time step dt between the trades). Their main result is an 
upper bound on the cost of replicating a European call option provided the jumps 
Iln S(t + dt) - In S(t)l never exceed some constant. They do not clarify how the 
investor can know the future variances. 
The case where the existing literature manages to price options without probability 
most convincingly remains, of course, the elementary case we discussed in 3 1.5, 
where there are only two possible changes in the price of the underlying security at 
each step. 
The integral 

15 
The Game-Theoretic 
Eficient-Market Hypothesis 
In this final chapter, we explore tests and uses 
of our game-theoretic efficient-market hypoth- 
esis. As we explained in $9.4, this hypothesis 
must always be considered relative to a par- 
ticular financial market, defined by particular 
opportunities to buy and sell, and relative to 
a particular nume'raire with respect to which 
prices and capital are measured. The hypothe- 
sis says that our imaginary player Skeptic can- 
not become rich in the particular market rela- 
tive to the particular nume'raire without risking 
bankruptcy. This hypothesis can be tested in 
a multitude of ways, and each test specifies 
an event that we can count on if the hypothe- 
sis is true. In fact, the hypothesis determines 
game-theoretic upper and lower probabilities 
for everything that might happen in the mar- 
ket, and a test is defined by every event that 
has high lower probability. 
In the first three sections of this chapter, we 
corresponding to limit theorems that we stud- 
ied in Part I. In $15.1 and $15.2, we consider tests that lead to a strong law of large 
numbers and a law of the iterated logarithm for financial markets. The strong law of 
Paul Samuelson (born 1915) launched 
the literature on efficient markets with 
a stock should follow a martingale. 
study tests of the efficient-market hypothesis his suggestion, in 1965, that the price of 
351 
Probability and Finance: It’s Only a Game! Glenn Shafer, Vladimir Vovk 
Copyright 0 2001 John Wiley & Sons, Inc. 
ISBN: 0-471-40226-5 

352 
CHAPTER 15: THE GAME-THEORETIC EFFICIENT-MARKET HYPOTHESIS 
large numbers says that returns average to zero in the long run, while the law of the 
iterated logarithm describes how the average return oscillates as it converges to zero. 
In 5 15.3, we prove two weak laws for financial markets, a simple weak law of large 
numbers and a one-sided central limit theorem. 
In the last two sections, we illustrate how upper and lower probabilities determined 
by the efficient-market hypothesis can make substantive contributions to finance 
theory. First, in $15.4, we derive some interesting upper and lower probability 
judgments concerning the relation between risk and return in a market where the 
same securities are traded over many periods. Then, in 515.5, we discuss how a 
market that includes options on an index can provide nontrivial upper and lower 
probabilities for the growth in the index and for a trader's value at risk. 
This chapter, in contrast with the four preceding chapters, uses no nonstandard 
analysis. 
15.1 A STRONG LAW OF LARGE NUMBERS 
FOR A SECURITIES MARKET 
In this section, we study a strong law of large numbers for financial markets. This 
strong law says that if an imaginary investor (Skeptic) is unable to become infinitely 
rich, then the daily gains of an actual investor (Investor) must average to zero. 
In general, Skeptic represents a strategy for investing in a particular market. We 
call Skeptic imaginary in order to caution that there is always a degree of idealization 
involved in supposing that such a strategy can be implemented without transaction 
costs or other frictions, and of course the idea that one's capital might become 
infinitely large is already very much an idealization. Strategies vary a great deal 
in how closely they can actually be implemented, even within a single well-defined 
market. In some cases, it might be possible for an actual investor to play the role 
of Skeptic, to a reasonable approximation. In other cases, Skeptic must be seen as 
representing the limit of what might be achieved by actual investors. 
We assume, in this section, that the market we are considering is well defined; 
we have specified just what securities are traded each day. We also assume that 
the total number of all outstanding shares of all these securities is well defined, so 
that the total value of the market at current prices is well defined. We suppose that 
investments and capital are measured relative to this total market value. To make this 
concrete, let us say that a market unit is loa1' of the total value of the market at any 
particular time. This will be our nume'raire; when we say that an investor invests h in 
a particular security, we will mean that he invests h market units, not $h or h of any 
other monetary unit. If the dollar price of the security changes in proportion to the 
total value of the market, then we will say that the investor's gain from his investment 
in the security is 0, but if the price of the security increases by 5% relative to the 
total value of the market, we will say that he has gained 0.05h; his investment is now 
worth 1.05h market units. 

15.1: A STRONG LAW FOR A SECURITIES MARKET 
353 
We derive our strong law of large numbers for a securities markets from the game- 
theoretic martingale strong law of large numbers that we proved in 54.5. It itself, 
however, is still very general. As we will see, it still implies the measure-theoretic 
martingale strong law of large numbers. 
We begin the section by formulating a protocol in which a fixed number K of 
securities is traded each day. We prove our strong law of large numbers for this 
protocol, discuss its applications, and show how it implies a martingale strong law 
for discrete probability spaces. We then turn to a generalization in which the total 
value of the market is distributed across an abstract measurable space of securities; 
our strong law of large numbers in this more general protocol directly implies the 
measure-theoretic martingale strong law. 
The Securities Market Game 
Formally, our strong law for financial markets is a corollary of the strong law for 
martingales that we studied in 54.5. It involves a game between Skeptic and World, 
where World is divided into three players: 
0 Opening Market, who sets the opening prices for each of the market's securities 
each day, 
0 Investor, who decides, after hearing the opening prices, on a portfolio of 
securities to hold for the day, and 
0 Closing Market, who decides how the price of each security changes and hence 
how Skeptic's and Investor's investments turn out each day. 
Substantively, Investor represents an individual or institutional investor (perhaps 
a mutual fund) or an investment strategy that we want to test. In the game against 
Skeptic, however, Opening Market and Investor together play the role that was played 
by Forecaster in Part I. 
Here is our protocol: 
SECURITIES 
MARKET PROTOCOL 
Parameters: KO > 0, natural number K > 1 
Players: Opening Market, Investor, Skeptic, Closing Market 
Protocol: 
FOR TI = 1,2,. . .: 
Opening Market selects m, E [0, 1IK such that C;='=, 
mk = 1. 
Investor selects g, E 
Skeptic selects h, E IRK. 
Closing Market selects Z, E [-1, G O ) ~  
such that m, . Z, = 0. 
K, := Kn-l + h, . z,. 
Here . represents the dot product: if m and z are two vectors of the same length, say 
m = (m', , . . , mK) and z = (d,. 
. . , z K ) ,  then m . x = Ck=' mkxk. 
K 

354 
CHAPTER 75: THE GAME-THEORETIC EFFICIENTMARKET HYPOTHESIS 
The protocol assumes that K securities are traded each day in our market. The 
0 The vector m, = (mk, . . . , r n f )  specifies how the total value of the market is 
distributed among the K securities at the beginning of day n. In other words, 
mk is the total value of all the outstanding units of security k, as a fraction 
of the total value of all outstanding units of all K securities. Notice that rnk 
is less than one. If we measure the total value of all the outstanding units of 
security k in market units, we will get a much larger number, namely 101'mk. 
0 The vector z, = (z:, . . . , z t )  gives the rates of return relative to the market 
for the K securities on day n; zk = - 1 means security k becomes worthless, 
zk = 0 means its share of the market does not change, and z; 
= 0.07 means 
its price relative to the market goes up 7%. 
vectors m,, z,,, g,, and h, are interpreted as follows: 
0 The vector g, = (g:, . . . ,g,") is the portfolio Investor holds during day n. 
Its entries are measured in market units: holding g, means holding gk market 
units worth of security k ,  for k = 1,. . . , K .  We permit short positions: gk 
may be negative. For simplicity in writing the protocol, we have assumed that 
gk can be any real number, even exceeding the total value in market units of 
security k. In practice, we can assume some restrictions on the size of g;, but 
such restrictions will make no difference to our theory; our conclusion will be 
that Skeptic can achieve a certain goal playing against Investor and Market, and 
this conclusion will not be affected by any change in the protocol that restricts 
the moves of Investor. 
0 Similarly, h, is the portfolio Skeptic holds during day n. In the case of Skeptic, 
we do want to allow arbitrarily large values of hk; as his capital tends to infinity, 
he may make larger and larger investments. But this is part of the imaginary 
aspect of Skeptic; as his capital passes from large to astronomical, we must 
suppose that he is dealing in imaginary money. 
The market share of the kth security is rnk at the beginning of the day and mk( 1 +xi) 
at the end of the day, and both must add to one: 
K 
K 
Ern; = 1 
and 
Errrk(1 +xi) = 1. 
k = l  
k=l 
The second of these constraints is expressed in the protocol by the requirement that 
m, . 5 ,  = 0. 
Skeptic's capital Ic, is measured in market units; it changes on the nth day by the 
change of value, in market units, of the portfolio h, that Skeptic holds that day. We 
assume that all spare capital is invested in the market, and so the change in Skeptic's 
capital on day n has the following components: 
the capital invested in security k changes as 
(15.1) 

15.1: A STRONG LAW FOR A SECURITIES MARKET 
355 
0 the spare capital (which can be negative) is invested in the market, and so does 
not change, 
k 
k 
Summing (15.1) over k and adding (15.2) shows that on day n the capital changes 
from K,-1 
to K,-1 + h, . x,, which is the expression given in the protocol. 
The protocol is obviously a symmetric probability protocol. In fact, it satisfies 
the conditions of $4.5. The players Opening Market and Investor together constitute 
Forecaster, and Closing Market is Reality. Skeptic’s move space, RK, is a linear 
space, and his gain function, h, . x,, is linear in his move h,. 
The protocol is 
coherent, because Closing Market can keep Skeptic from making money by setting 
all his z, 
equal to zero. 
The vector m,, which gives the securities’ shares of the total value of the market, 
can also be used to distribute an investment of one market unit across the K securities: 
we invest the fraction mk of a market unit in security k. When m, is used in this 
way, we call it the market portfolio. 
There is a certain indeterminacy in our representation of portfolios by means of 
vectors. In general, two portfolios w and w + em,, where c is a constant and m, is 
the market portfolio for day n, produce the same net gain relative to the market on 
day n: 
(w + em,) .x, = w . 2, + c(m, . z,) 
= w ‘2,. 
We call two such portfolios equivalent for day n. One way to eliminate this in- 
determinacy is to represent portfolios only with vectors that indicate no net use of 
capital, all purchases of securities being offset by short selling in other securities. We 
call such vectors arbitrage portfolios. Formally, an arbitrage portfolio is a vector w 
with the property that Ck 
v k  = 0. For each portfolio w, there is a unique arbitrage 
portfolio that is equivalent to it for day n: w - cm,, where c = Ck 
vk. 
We may assume, without loss of generality, that Skeptic is always required to 
choose an arbitrage portfolio. This makes no difference in what Skeptic can achieve 
in the game, and because it leaves Skeptic with a linear move space, it does not affect 
the symmetry of the protocol. We will not, however, assume that Investor necessarily 
chooses an arbitrage portfolio. 
Interpretations 
The simplest and most concrete interpretation of the securities market protocol is 
obtained by supposing that the same K securities are included in the protocol on 
each of the N days and that the opening price of each security each morning is its 
closing price from the preceding evening: m:+l 
= mi( 1 + xi). In this case, Skeptic 
could be an actual investor, except for the consideration of transaction costs and until 
his capital becomes too large relative to the entire market. We can specify arbitrarily 
the K securities that we want to study for N days; they need not include all the 
securities traded in any existing exchange. 

356 
CHAPTER 15: THE GAME-THEORETIC EFFICIENT-MARKET HYPOTHESIS 
The formulation also permits us, however, to change the K securities in the 
protocol, perhaps in the same way as stock exchanges and market indexes update 
their listings: we throw out securities that have declined relative to the total market, 
and we bring in newly valuable securities. If such shifts change the total value of 
the market’ in dollars (or whatever monetary unit is relevant), Skeptic becomes more 
imaginary, however; the formula K, := Kn-l + h, .xn assumes that his capital in 
market units at the end of day n - 1, Kn-l, is also his capital in market units on the 
morning of day n, and if the total dollar value of the market has increased overnight 
because of new listings, then we must give Skeptic enough dollars for this to remain 
true. 
If we want to change the securities from day to day, then we can even change the 
total number K from day to day. This will become clear when we generalize our 
results to the case where the total value of the market is distributed across an arbitrary 
measurable space of securities. 
In fact, the protocol is very broad, with many possible interpretations. As we will 
see shortly, it even accommodates a general sequential gambling scenario (essentially 
what we called generalized coin tossing in Chapter 8), and so in a certain sense it 
contains the theory of probability. 
The Finance-Theoretic Strong Law of Large Numbers 
The following proposition, a corollary of Proposition 4.4 (p. 92), is our finance- 
theoretic strong law. 
Proposition 15.1 Skeptic can force the event 
To make this proposition stronger, we resolve the possible uncertainty 0/0 in the 
fraction on the left-hand side to 0. Notice that the proposition remains true if “can 
force” is replaced by “can Bore1 force”. 
Proof If the g, 
are arbitrage portfolios, then it suffices to apply Proposition 4.4 to the 
martingale 
n 
s, := c g i .  xi, 
,=1 
using the fact, established in the next lemma, that 
is a quadratic supervariation for S,. 
(15.4) 
(15.5) 
‘Such a change will usually be negligible in the idealized case of an index always containing K companies 
with the highest market capitalization. 

15.1: A STRONG LAW FORA SECURITIES MARKET 
357 
When the gn are arbitrage portfolios, the substitution of equivalent portfolios gn + cnmn 
yields 
So the sum on the left-hand side of the implication (15.3) can only be increased by substituting 
equivalent portfolios, while the sum on the right-hand side is not changed. So if the implication 
holds when the gn are arbitrage portfolios, it holds in general. 
I 
Lemma 15.1 Ifthe gn are arbitrageportjiolios, then (15.5) is a quadratic supervari- 
ation of (15.4). 
Proof We must show that Skeptic has a strategy that will ensure that 
A(S2)n - Ad, 5 hn. x,: 
or 
for n 2 1. This is equivalent to his having a strategy that ensures 
Thus our task is to find a move h for Skeptic, following moves m by Opening Market and g 
by Investor, such that 
(15.6) 
will hold no matter what move x is chosen by Closing Market. 
The case 3k : mk = 0 & g k  > 0 is trivial, so we assume Vk : mk = 0 + g k  = 0. 
Excluding the k for which mk = 0 from consideration (for such k Skeptic can set hk := 0), 
we further assume that mk > 0 for all k. 
The move x 6 RK must satisfy 
m .  x = 0 & ~k : x k  2 -1. 
(15.7) 
The left-hand side of (15.6) is a convex function of 2, so it suffices for Skeptic to ensure that 
(15.6) holds for the vertices of the polyhedron (15.7). These vertices are z j ,  j = 1,. . . , K ,  
with 
J
{
 -1 
otherwise. 
llmJ -1 
i f k = j  
2'" = 
The inequality (15.6) is satisfied for the vertex xj if 
(5)'- 
x+chk 
(skY 
m3 
k 
k 
m3 
(Here we have used the assumption that g is an arbitrage portfolio.) This is satisfied if we set 

358 
CHAPTER 15: THE GAMETHEOREJIC EFFICIENT-MARKET HYPOTHESIS 
thus defining an arbitrage portfolio h for Skeptic. 
I 
Proposition 15.1 says that Skeptic can force limn+oo c:=l 
gi . zi = 0 on paths 
where Investor's moves are not too unusual-not 
too greatly and too consistently 
deviant from the market portfolio. To illustrate this, consider the case where Investor 
chooses a particular security, say the kth one, and always invests one market unit in 
this security. In other words, he always chooses the portfolio g given by 
1 i f j = k  
0 
otherwise. 
Substituting this portfolio for all the gn in (15.3), we find that Skeptic can force the 
event 
For example, Skeptic can force lim,+,(l/n) c:=l 
zt = 0 on paths where mk is 
bounded below by E ln2 n/n for some E > 0. 
Is the Finance-Theoretic Strong Law Satisfied Empirically? 
Many studies of the stochastic efficient-markets hypothesis test the hypothesis using 
average returns for well-defined investment strategies or for actual investors, such as 
mutual funds. Provided that the larger market in which the strategies or investors 
operate is well defined, Proposition 15.1 tells us these tests can be regarded, at least 
to a first approximation, as tests of the game-theoretic efficient-market hypothesis 
for these particular markets with a nume'ruire proportional to the total value of the 
market. 
It is beyond the scope of this book to review these studies in detail in an attempt 
to judge which game-theoretic efficient-market hypotheses stand up to these tests. 
There is a widely held consensus, however, that funds that track market indexes such 
as the S&P 500 in the United States or the MSCI in Europe can do so successfully and 
usually outperform, often dramatically, other funds that follow different strategies 
[212]. The evidence on which this consensus is based may also serve as evidence that 
the markets defined by these indexes do satisfy our game-theoretic efficient-market 
hypothesis. 
Of course, Proposition 15.1 does not merely say that an investor should be unable 
to beat the market; it also says that the investor should do as well as the market. 
Thus the below-market returns often achieved by individual investors [ 101 and funds 
[ 160,211,50,2] must be taken as evidence against the game-theoretic efficient-market 
hypothesis except in cases where it can be attributed to violations of the securities 
market protocol (transactions costs or trading outside the index that is being tested, 
perhaps in emerging markets or small value stocks) or violations of the left-hand side 
of (15.3) (excessively wild trading). 

15.1: A STRONG LAW FORA SECURITIES MARKET 
359 
Horse Races 
Although it may seem rather specialized, our strong law for a securities market 
actually contains a martingale strong law for elementary (discrete) probability theory 
as a special case. This becomes clear if we think about how the securities market 
game can be used to model a sequence of horse races [61, 1691. 
Suppose we conduct a horse race every day, always with K horses. At the 
beginning of day n, Opening Market posts the current odds for the day's race: mi 
is the probability that the kth horse will win. The probabilities mi, . . . m: 
add to 
one. Investor can bet on horse k at odds m i  : (1 - mi). Putting $1 on horse k 
produces 
if horse k wins the race 
{ 
- 1 
if horse k loses the race. 
So if Investor puts g i  on horse k ,  for k = 1,2,. . . , K ,  his total gain will be gn . x,, 
where 2, is the vector given by 
l/mi - 1 
1/mi - 1 ifk = winner 
x:= { 
-1 
otherwise. 
(15.8) 
The vector x, satisfies the constraint m, .x, = 0. So the game played by Investor in 
the horse race is a special case of our securities market game, special only inasmuch 
as the moves by Closing Market, x,, must be of the special form (15.8). 
From the viewpoint of probability theory, the sequence of winners can be thought 
of as coming from a probability space { 1, . . . , K}W in which mk is the conditional 
probability that the nth element of the sequence will be k given the first n - 1 choices. 
Suppose tn = ((A, 
. . . t,") is a sequence of martingale differences in this space. 
This means simply that zf='=, 
CLrn; = 0 for all n-that 
is, the vectors tnmn are 
arbitrage portfolios. Proposition 15.1 with g i  = [:mk 
says that 
K 
holds almost surely (ti on the right-hand side is used, following the usual practice in 
probability theory, to mean 
where Ici is the ith race's winner). This is the strong 
law for martingales for elementary probability theory; the left-hand side of (15.9) is 
the usual condition on the variances. 
If K = 2, Opening Market always gives the two horses the same chance of winning 
(mi = m: = 1/2), and Investor always puts 112 on the second horse (gi = -112 
and g i  = l/2, so that [A = -1 and ti = l), then the convergence on the left-hand 
side of (15.9) is guaranteed, and the martingale strong law reduces to Borel's strong 
law. 
Markets with Infinitely Many Securities 
Real markets can only contain finitely many securities, but there is no obstacle to a 
generalization of our mathematical results in the direction of measure theory, so that 

360 
CHAPTER 15: THE GAME-THEORETIC EFFICIENTMARKET HYPOTHESIS 
the total value of the market is distributed, on each day, across an arbitrary measurable 
space of securities. 
For this measure-theoretic generalization, it is convenient to rewrite the protocol 
using the following quantities: 
0 Gk := gt/mk instead of gk (this means that we measure an investment in 
security k in units proportional to the total market value of this security), 
0 H," := h i / m k  instead of hk, and 
0 X k  := (1 + x;)rnk instead of xk (this is security k's share of the total value 
of the market at the end of day n). 
Skeptic's gain from his portfolio H, will be 
k 
k 
k 
k 
Passing from this discrete notation to the corresponding but more general measure- 
theoretic notation, we obtain the following protocol. 
ABSTRACT SECURITIES 
MARKET PROTOCOL 
Parameters: Measurable space (Re, 
F), 
Skeptic's initial capital KO > 0 
Players: Opening Market, Investor, Skeptic, Closing Market 
Protocol: 
FOR n = 1 , 2 , .  . .: 
Opening Market selects m, E P(R.). 
Investor selects measurable G ,  : R. + R 
Skeptic selects measurable H, : R. + R 
Closing Market selects X ,  E P(R.). 
K, := 
K-1+ J Hnd(Xn - mn) 
if j" H,dX, and s H,dm, are defined 
if s H,dm, is undefined 
-cc 
cc 
otherwise. 
Recall that P(B) stands for the set of all probability measures on the measurable 
space B. We have divided the job of ensuring that the integral s Hnd(Xn - m,) is 
defined between Skeptic and Closing Market in a natural way: Skeptic is required 
to ensure that s H,dm, is defined (i.e., s IH,ldm, < co); if he complies, Closing 
Market is required to ensure that J H,dX, is defined (i.e., s IH,ldX, < co). 
The analog of Lemma 15.1 (p. 357) is: 
Lemma 15.2 The process 
A, := c 
/ G:drni 
(15.10) 

15.1: A STRONG LAW FORA SECURlTES MARKET 
361 
is a quadratic supewariation of the martingale 
n , .  
S, := C J Gid(Xi - mi). 
i=l 
Proof We are required to prove that, for some H,, 
If s GEdm, = 00, this is trivially true, so we will assume that s Gtdm, is finite. We 
simplify the notation by dropping the subscript n; our goal is to find H for which 
( J G d ( X  - m))’ - J’ G’dm - J Hd(X - m) I 0. 
(15.11) 
The left-hand side is a convex function of X ;  therefore, by Jensen’s inequality (see the next 
paragraph), it is sufficient to establish this inequality for X that are concentrated at one point 
w E 0: 
( G ( w ) -  J G d m ) ’ -  
JG’dm- 
( H ( w ) - J H d m )  5 0 .  
(15.12) 
To show that such an H exists, it is enough to prove that the m-expected value of 
(G(w) - J Gdm) ’ - J G2dm 
(15.13) 
is nonpositive, which is obvious: the variance never exceeds the second moment. We will 
take (15.13) as H ;  notice that 
In conclusion, we will discuss the application of Jensen’s inequality above. If the function 
on the left-hand side of (15.11) is f ( X )  and [w] is the probability distribution concentrated at 
w, we have 
Hdm will be defined. 
f(X) = f (J[WldX) 5 Jf([Wl)dX I 0 
when f ( [ w ] )  I 0 for all w. The problem with this argument is that the domain off is the set 
P (0.) of all probability distributions in 0.. whereas the most usual form of Jensen’s inequality 
is only applicable to convex functions f : R -+ R. However, the result we need can easily be 
derived from the usual proof of Jensen’s inequality (as in, e.g., [287]): assuming (15.12), 
0 2 f ( [ w ] )  = ( J  Gd((X - m) + ([w] - x)))’ - JG’dm - J Hd([w] - m) 
2 
= ( / G d ( X  - m ) )  + 2J’Gd(X - m) /Gd([w] - X )  + ( / G ~ ( [ w ]  
- x))’ 
- J G2dm - J Hd([w] - m) 
2 (J Gd(X - m)) + 2 1 Gd(X - m) 1 Gd([w] - X )  
- 1 G2dm - 1 Hd([w] - m) 

362 
CHAPTER 15: THE GAME-THEORETIC EFFICIENT-MARKET HYPOTHESIS 
= ( / G d ( X - m ) ) 2 + 2 J ’ G d ( X - m )  ( G ( w ) - / G d X )  
- J’ G2dm - ( H ( w )  - J H d m )  ; 
integrating the last term of this chain over the probability distribution X ( d w )  gives (15.11). 
We have been assuming that s GdX and 
HdX are defined; the latter, which is Closing 
I 
Market’s responsibility, implies the former (and even 1 
G2dX < 00). 
This lemma immediately implies the following strong law for the abstract securities 
market protocol. 
Proposition 15.2 (Fuzzy Strong Law of Large Numbers) Skeptic can force the 
event 
co 
n-2 J’ GEdm, < co ==+ lim 1 5 
J’ Gid(Xi - mi) = 0. 
(15.14) 
n+oo n 
n= 1 
i=l 
We call it fuzzy because the outcome of each round of play is another probability 
distribution on 0. rather than a crisply defined point in 0.. As usual, the forcing 
strategy for Skeptic can be chosen measurable. 
Deducing the Martingale Strong Law of Large Numbers 
As we mentioned at the beginning of the section, our strong law for the abstract 
securities market game (the fuzzy strong law we have just proved, with Skeptic’s 
forcing strategy understood to be measurable) implies the usual measure-theoretic 
martingale strong law. 
Suppose, indeed, that 5 1 ,  z2, 
. . . is a measure-theoretic martingale difference with 
respect to a sequence of 0-algebras Fo, 
Fl, 
F2,. . .; let (0, F, 
P )  be the underlying 
probability space. To apply our fuzzy strong law, set 0. := R and assume that 
Opening Market, Investor, and Closing Market play the following strategies (deter- 
ministic for Investor and stochastic, i.e., dependent on w € 0, for the Markets): m, 
is always a regular conditional distribution of 2, with respect to F,-l evaluated at 
w (here we rely on the result in measure-theoretic probability that regular probability 
distributions do exist; see, for example, [287]), G, is the identity function (G,(t) = t 
for all t E 0.), and X ,  is concentrated at one point, X,(W). 
The implication (15.14) 
then reduces to 
Since Skeptic’s strategy that forces (15.15) is measurable, it gives a supermartingale 
(see Proposition 4.2 on p. 86); therefore, our fuzzy strong law implies that (15.15) 
holds almost surely. This is the usual measure-theoretic martingale strong law. 

15.2: THE ITERATED LOGARITHM FOR A SECURITIES MARKET 
363 
15.2 A LAW OF THE ITERATED LOGARITHM 
FOR A SECURITIES MARKET 
We now turn to the law of the iterated logarithm for our securities market. This law 
explains how Skeptic can control the oscillation of Investor’s average gain relative to 
the market as it converges to zero. We derive the law first for our discrete securities 
market ( K  securities) and then for our abstract securities market (a measurable space 
of securities). 
Here is the law for the discrete market. 
Proposition 15.3 In the securities market protocol, Skeptic can force 
(15.16) 
gi . xi 
The conditions on the left-hand side of the implication (15.16) can be interpreted 
Because A,, as given by (15.5), is a quadratic supervariation of 
(Lemma 15.1), this proposition is just a special case of Proposition 5.2 (p. 118). 
as follows: 
The condition A, --t 00 says that Investor does not play too timidly. It is 
implied, for example, by xzl (1gi1I2 = 03. 
The condition lgn . x,I = o(JA,/ 
lnln A,), which limits the growth of 
lgn . x,1, requires, in general, that g, and x, do not get too far from zero 
too fast-that 
is, neither Investor nor Market play too wildly. It is implied by 
(g, . x,1 = 0(1) (assuming A, --t 03). 
As an illustration of the law, consider the case where Investor always puts one 
market unit on security k. This means that his gain on the day n is always xk. The 
arbitrage portfolio representing his bet on day n, g,, 
is given by gk = 1 - mk and 
g i  = -m3, f o r j  # k .  We find 
=
p
m
t
 
mt . 
This will tend to infinity if the market share of the single security k never becomes 
too large-say 
if mi 5 1 - 6 for some 6 > 0 and all n. If we assume that lxkl < 1 
for all n, then Proposition 15.3 implies that Skeptic can force the event 
lim sup 
ICL1 xt I 
5 1. 
(15.17) 
,--too 
1-mk 
1-mk 
2CL mf lnlnC:=2=, * 

364 
CHAPTER 15: THE GAME-THEORETIC EFFICIENT-MARKET HYPOTHESIS 
If we assume further that rn; 2 E ,  so that the total value of the lcth security is never 
overwhelmingly dominated by that of the other securities, then the cumulative gain 
grows not faster than d
z
,
 
We are not aware of empirical studies that have tested the efficient-market hypoth- 
esis by looking for violations of the limits given by Equations (15.16) or (15.17). But 
this could be done, using some of the longer series of data now available, provided 
we restate Proposition 15.3 in finitary terms; see 55.6 and [322]. 
Lemma 15.2 implies the following abstract game-theoretic law of the iterated 
logarithm: 
Proposition 15.4 (Fuzzy Law of the Iterated Logarithm) Skeptic can force the 
event 
(d, -+ 02 & / / G , d ( X ,  -mnll = 0 (&)) 
Ic;=~ 
J G d X i  - mi) I 
limsup 
L 1, 
n+oo 
d2dn In In A, 
where A, is dejined by (1 5.10). 
15.3 WEAK LAWS FOR A SECURITIES MARKET 
We turn now to weak finance-theoretic laws, first a weak law of large numbers and 
then a one-sided central limit theorem. 
A Weak Law of Large Numbers for a Securities Market 
Here is a simple form of the weak law of large numbers for a securities market. 
Proposition 15.5 Let C > 0 be a (large) constant, E > 0 be a (small) constant, and 
S, and A, be dejined by (15.4) and (15.5). Suppose the players in the securities 
market protocol play a fied number N of trials. Then 
(15.18) 
Proof Adapting the proof of Proposition 6.1 on p. 125, we consider the nonnegative super- 
martingale 
with Lo = 1, where r is the last trial n with An 5 c: 
(15.19) 

15.3: WEAK LAWS FOR A SECURlTlES MARKET 
365 
On the event AN 5 C & ISNI/N 2 E ,  we have CN 2 N2c2/C. 
I 
The inequality (1 5.18) suggests that the efficient-market hypothesis should be 
rejected when S N / N ,  Investor’s average return relative to the market, is not small in 
absolute value and our other conditions are satisfied. But the presence of C makes 
the inequality difficult to interpret more specifically, because we are told nothing 
about the relation between C and N .  (In the coin-tossing case, in contrast, we can 
take C = N.) So it is convenient to replace (15.18) with 
(15.20) 
where S > 0 is some conventional threshold, such as 1 %; now N becomes irrelevant: 
the game can last infinitely long. It is possible that r in (15.18) will be infinite, 
and so S, may not be defined; (15.20) says that the upper probability that it is 
defined and satisfies IS, I 2 fl 
does not exceed 6. We will use this convention 
throughout. Equation (15.20) can be proven in the same way as (15.18): on the event 
IS,l 2 
The efficient-market hypothesis can be tested by looking at whether mutual funds 
or investment strategies do better than Investor is supposed to do in our game. It 
might be tempting to look at a large number of mutual funds and see what proportion 
of them achieve IS, I m, 
but this would not tell us anything, because different 
funds or strategies can be arbitrarily correlated. A more interesting approach is to 
consider a single fund or strategy over successive periods. The following strong law 
points to how this can be done: 
Proposition 15.6 Let C and 6 be two positive constants, and let S, and A, be 
dejined by (15.4) and (15.5). Let ro = 0 and ri, i = I, 2 , .  . ., be the last time that 
A,, - dTi-l 
5 C (this is an inductive dejinition). Then 
we have C, 2 1/S. 
Proof It suffices to combine (15.20) with the one-sided strong law of large numbers in 
I 
Chapter 3 (Proposition 3.4 on p. 73). 
This is a strong law, but a corresponding weak law holds for finitely many rounds. 
A One-sided Central Limit Theorem for a Securities Market 
We now establish a one-sided finance-theoretic central limit theorem, generalizing 
the one-sided central limit theorem of 56.3. 
For any constant C let TC be the moment when A, (see (15.5) on p. 356) reaches 
the value C, 
TC := min{n I A, 2 C} 
(we could define rc in the same way as r in (15.19), but now we follow what we did 
in Chapter 7, Example 5; both definitions are good for our purpose), and let XC be a 

366 
CHAPTER 15: THE GAME-THEORETIC EFFICIENT-MARKET HYPOTHESIS 
normalized version of (15.4), 
Proposition 15.7 Consider the securities market protocol with the additional re- 
striction that Investor and Closing Market are required to choose g: and xk bounded 
in absolute value by cJmk and c, respectively, where c is a given constant. Let U 
be the indicatorfunction of a closed set E C E% that does not contain 0. Let U ( s ,  D )  
be the solution to the heat equation a v ( s ,  D ) / a D  = (1/2)a20(s, 
D)/as2 with the 
initial condition U ( s ,  0) = 0, b's $ E, and the boundary condition a ( s ,  D )  = 1, 
Vs E E ,  D > 0. Then as C + 03, 
- 
P[XC E El -+ U(0,l). 
Proof Without loss of generality we can assume that E = (--03, a] U [b, m), E = (-00, a], 
or E = [b,-03), for some a < 0 < b. (We can define a := sup(E n (-co,O)) and 
b := inf(E n (0, co)).) There exist smooth functions V 5 IIE and W 2 1 1 ~  
that are constant 
outside afiniteinterval such that P(0,l) and W(0, 1) are arbitrarilyclose to U(0,l) (V and W 
are defined as LM IJ and LM w, respectively, where u ( s ,  D )  := V ( s )  and w(s, D )  := W(s)). 
It is sufficient to prove that, for any fixed E > 0 and large enough C, E[W(Xc)] 5 W(0,l) + E  
and E[V(Xc)] 2 c(0, 1) - E .  The proofs will be analogous to the proof of the one-sided 
central limit theorem in Chapter 6. Set 
(15.21) 
ProofofE[W(Xc)] 5 W(0, 1) + E .  As before, choose large C > 0 and small 6 E (0,l); 
our first goal is to show that Skeptic, starting with W(0,l) + E ,  can attain capital at least 
- 
<V(SnL6) 
+ ~ / 2  
when (S,, 
D,) hits the set (6.28) (p. 140). Find a smooth superparabolic 
U 5 W sufficiently close to W on [-C, C] x [6,1]. As usual, the proof is based on (6.21) 
(p. 132); the most important difference from the situation of Chapter 6 is that the second addend 
in (6.21), instead of being zero, is bounded from above by the return of some portfolio; this 
follows from d, being a quadratic supervariation and the fact that aD/aD is never negative 
(see Lemma 6.2 on p. 139). 
Let us prove that the cumulative effect of the last four addends in (6.21) is negligible. 
First notice that the conditions 1gh1 5 cJm: and IzkI 5 c imply that 
= O(C-') 
and IdSnI = O(C-'/')). The last addend is easiest: En 
Id&/ 
5 1 + O(C-'), and 
so C,(dD,)' 
= O(C-'). The third and fourth addends are negligible because Ids;[ 
and ldDLI are negligible and C,(dS,,)' is moderately large with lower probability close 
to 1 (this last point follows from the game-theoretic Markov inequality and the fact that, 
according to Lemma 15.1 on p. 357, the upper expectation of x,(dS,)2 is bounded above 
by C-'(C + O(1)) = O(1)). For the penultimate addend, we apply our usual argument for 
the weak law of large numbers. Lemma 15.1 implies that the upper expectation of 

15.4: RlSK VS. RETURN 
367 
is 0(CT2); 
therefore, by the game-theoretic Markov inequality, the sum over rt of the penulti- 
mate addend does not exceed AC-' in absolute value with lower probability arbitrarily close 
to 1 (provided A is sufficiently large). 
Similar arguments show that: (1) with high lower probability, S, will not change much 
after (S, , D,) hits the boundary D = b of (6.28); (2) with high lower probability the boundary 
I 
ProofofE[V(Xc)] 2 V(0,l) - E. This is simple, since in the current game Skeptic's oppo- 
nents have much more freedom than in the one-sided game of Chapter 6. The proof of the 
negative part of Theorem 6.1 (with 2~ defined by u ( s ,  D) 
:= V ( s ) ,  N replaced by C, and other 
obvious changes) works in the current setting if we assume the following horse-race scenario: 
Opening Market's move is always m, = (0.5,0.5,0,0,. . .) (only the first two stocks 
Investor's move is always g ,  = (-0.5,0.5,0,0,. . .); 
at the beginning of the game Closing Market (who plays the role of Chapter 6's Reality) 
chooses x, = (*l, ~ 1 , 0 , 0 , .  
. .) with a suitable sign; and at the end of the game he 
chooses 2, = (O,O, . . .). 
I 
Is\ = C will not be hit. 
will matter); 
As before, S, and D, should be defined by (15.21). 
This proposition can be combined with a one-sided law of large numbers, in the 
spirit of Proposition 15.6. 
15.4 RISK VS. RETURN 
An important aspect of stochastic asset pricing theories is the relation between risk 
and return: riskier securities tend to bring higher returns. In this section, we study to 
what extent this relation follows from our game-theoretic efficient-market hypothesis. 
For this study, we leave aside the very special protocol of the preceding sections, 
which assumes a well-defined total value for the market in which Skeptic is trading 
and takes the nurne'raire proportional to this total value. We now use a finite-horizon 
protocol, in which the nurne'raire can be chosen arbitrarily. This protocol tracks the 
capital of Investor as well as that of Skeptic and does not allow Investor to go short 
in securities. The requirement that Investor cannot go short might appear restrictive, 
but the protocol produces interesting results already in the case where K = 1 and 
g, = 1 for all n (Investor always holds one unit worth of the only security included 
in the protocol). 
We write Z, for Investor's capital, dispose of Opening Market, and rename Closing 
Market to Market. 
FINITE-HORIZON 
SECURITIES 
MARKET PROTOCOL 
Parameters: N ,  KO > O,& > 0 
Players: Investor, Skeptic, Market 
Protocol: 
FOR n = 1 , 2 , .  . . , N :  
Investor selects gn E [0, w ) ~ .  

368 
CHAPTER 15: THE GAME-THEORETIC EFFICIENT-MARKET HYPOTHESIS 
Skeptic selects h, E [O, w ) ~ .  
Market selects X, E [-1, w ) ~ .  
2, := In-l + 9,. 5,. 
K, := K,-1 + hn . 2,. 
We set 
Sn ’ X n  
In-1 
r, := -, 
and we call it Investor’s return on his capital on day n. We also set 
N 
1 
p := C r, 
n=l 
and 
p and a2 are the empirical mean and variance, respectively, of Investor’s returns, and 
a: is the uncentered empirical variance usually used in the finance literature. We 
will call 00 the empirical volatility and use it in Propositions 15.8 and 15.9 below; to 
state these propositions in terms of empirical variance, replace a; by a’ + p2 (but 
the difference p2 between 
and o2 is usually negligible: see, e.g., the figures for 
Microsoft and IBM below). 
Proposition 15.8 For any o > 0, 
(15.22) 
n:r,<O 
Proof The proof is based on an elementary idea: the daily logarithmic returns, ln(1 + r,), 
are more useful than the r, themselves because they are additive and because In( 1 + T,) % 
rn - rE/2 will be adversely influenced by high volatility. 
Suppose at every trial n Skeptic takes his portfolio h, = gnKo/Zo to be the same as 
Investor’s portfolio g, but scaled to his initial capital. Then K ,  = (1 + rn)Kn-i. So the 
lower probability of the event 
is at least 1 - a. It remains to take the log of both sides and apply the formulas (following 
from Taylor’s expansion) 
I 
In typical applications (where Ir,( <( 1) the quantity in the square brackets 
in (15.22) is small. The significance level a (typically something like 1%) is a 

15.4: RlSK VS. RETURN 
369 
number such that events of upper probability cy or less are considered unlikely. 
Assuming that lrnl << 1 and that (- In a ) / N  is of even lower order of magnitude, 
Equation (15.22) says that 
I S 2  
2 
p 5 0 
+ small amount 
(cf. (9.35) on p. 231). This is applicable to the case when there is just one security 
in Investor’s portfolio. So we can say that the efficient-market hypothesis implies a 
high lower probability that the average of the returns from a particular security will 
be less than half their squared volatility. 
This result is much more concrete than typical results from stochastic finance 
theory. It is about the mean and variance of the actual returns, not the mean and 
variance for some stochastic mechanism that is hypothesized to generate these returns. 
In order to verify that Proposition 15.8 is useful in practice, consider the returns 
from Microsoft stock for the period from March 13, 1986 (the first day on which data 
on Yahoo is available) until September 21, 2000, with S&P 500 as the nume‘raire. 
Here N = 3,671, and the empirical mean and volatility of the daily returns, to three 
significant digits, are 
p = 0.00141, or 0.141%; 
and 
00 = 0.0254, or 2.54%. 
Taking cy = 1%, the inequality 
ui 
h a :  
p < - - - +  
2 
N 
[;N - I*”] 
n:r, <O 
(15.23) 
within the lower probability assertion in (15.22) becomes, numerically, 
0.141% < 0.0322% + 0.125% + 0.000512% 
(we use % to mean multiplication by O.Ol), or 
0.141% < 0.158%. 
(15.24) 
Thus the bound that is asserted to hold with lower probability of at least 99% did hold 
for Microsoft in this period, even though the mean return p (0.141%) substantially 
exceeded 02/2 (0.0322%). Of course, we can scarcely expect the bound (15.23) to 
be as tight as (15.24) in general, because p will seldom be so large. The similar 
calculation for IBM, for the 9,748 days from the beginning of 1962 (the earliest data 
available on Yahoo) until 21 September 2000 yields 0.008 < 0.059 (to accuracy 
0.001), a bound that is much looser, although the two sides are still of the same order 
of magnitude. 
The bound (15.23) can be violated of course. We see this when we put cy equal 
to 10% for the Microsoft data. In this case, the term - In oc/N in (15.23) becomes 
0.063% instead of 0.125%, and (15.23) becomes 0.141% < 0.095%. The violation 
is hardly surprising, because Microsoft’s performance between 1986 and 2000 was 
in the top tenth of anyone’s range of expectations. 

370 
CHAPTER 15: THE GAME-THEORETIC EFFICIENT-MARKET HYPOTHESIS 
It should not be supposed that p can approach the limit (ri/2 asymptotically as 
the number of periods N increases. On the contrary, as N increases the limit on 
the size of p at any fixed significance level a tends to zero (assuming T, = 0(1)), 
and the increase in the limit associated with increasing 
becomes more and more 
negligible. This is clear from the following proposition, which appears asymptotically 
much stronger than Proposition 15.8. 
Proposition 15.9 Under conditions of Proposition 15.8, for any N 2 3 and sign$- 
cance level cy > 0, 
1 
1
1
 
J N  
2 
a 
J N  
{ p < - (3 + In - + -) } 2 1 - a. 
Proof From the proof of the previous proposition we know that the lower probability of the 
event 
1 
N 
rJ(1-t nr,) < - 
ff 
n=l 
is at least 1 - a, where 0 < fi < 1. (See our analogous use of n in the proof of the validity 
of the law of the iterated logarithm in Chapter 5.) Taking logarithms of both sides and again 
applying Taylor's expansion, we obtain 
Setting fi := NP1I2, we further obtain 
Because rn 2 -1 and N 2 3, we see that 
So we can transform (15.25) to 
I 
The asymptotic power of Proposition 15.9 is irrelevant, however, for values of N that 
we are likely to encounter in applications, because its error term involving the signif- 
icance level a (namely, - In a / J N ) ,  which is much larger than the corresponding 
term in Proposition 15.8 (- In c*/N), is usually too large to impose any interesting 
limit on p. Indeed, in our Microsoft example, where N = 3,671 and (Y = 1%, we 
obtain - In a / J N  = 7.60%, hardly interesting as part of an upper bound on average 
daily returns. 
Because of our insistence that Skeptic cannot risk bankruptcy, he cannot take short 
positions, and this means that we can prove Propositions 15.8 and 15.9 only under 

15.5: OTHER FORMS OF THE EFFICIENT-MARKET HYPOTHESIS 
371 
the assumption of no short selling. It also means that we cannot prove sharpness 
results for the law of the iterated logarithm and the central limit theorem. One way to 
remove this restriction on Skeptic is to assume that securities' returns do not exceed 
some specified positive constant C [333]. Another, more flexible, possibility is to 
allow Skeptic to buy a new kind of tickets which will allow him to hedge against 
large returns for securities he is short in; these tickets might be derivatives, such as 
out-of-the-money call options, which would insure against abnormal behavior by the 
market, or merely theoretical tickets expressing our beliefs about the market. 
15.5 OTHER FORMS OF THE EFFICIENT-MARKET HYPOTHESIS 
In this concluding section, we briefly discuss two more possibilities for choosing the 
nume'ruire for our efficient-market hypothesis: (1) a given market index might be 
used as the nume'ruire for a larger market game in which Skeptic is allowed to trade 
in options as well as in the securities that make up the index, and (2) a monetary 
unit such as the dollar might be used when evaluating a complex range of market 
opportunities. 
When Skeptic Can Trade in Options 
If the securities that are traded in a market include options, then we cannot take 
the total value of all outstanding units of all traded securities in the market as a 
nume'ruire, because a market order for an option may be filled by someone writing 
a new option, and hence the number of outstanding options contracts (this is called 
the open interest in the option and is included in daily market reports) can change 
from minute to minute. But we can consider the efficient-market hypothesis relative 
to some other nume'ruire. 
We have already encountered one very important example: our game-theoretic 
Black-Scholes protocol, where the nume'ruire is a risk-free bond. Skeptic is absent 
from this protocol; the only players are Market and Investor, who is allowed to trade in 
the bond, in a stock S, 
and in a derivative depending on S (the variance derivative 2) or 
the strictly convex option R). 
But we can formulate an efficient-market hypothesis for 
Investor: we can suppose that he cannot get infinitely rich without risking bankruptcy. 
As we showed in 5 1 1.4, this game-theoretic efficient-market hypothesis implies that 
Market will produce a price path for S with variation exponent equal to 2, the typical 
value for a diffusion process. This example is important because it demonstrates 
dramatically how specific stochastic properties can emerge from a market game, 
without any assumption or conclusion that market prices are fully stochastic. 
Another interesting implication of the efficient-market hypothesis in the Black- 
Scholes protocol with the risk-free bond as nume'ruire is discussed by Bodie (1993, 
who shows that as the time horizon grows it becomes more and more expensive to 
ensure, using the Black-Scholes formula, against a stock S earning less than the 
risk-free rate of interest. In our purely game-theoretic Black-Scholes protocol, with 

372 
CHAPTER 15: THE GAME-THEORETIC EFFICIENT-MARKET HYPOTHESIS 
our usual simplifying assumption that the interest rate is zero (and the bond price is 
constant), we may write 
for the price at time 0 of an option that pays 1 if the stock S does as well as the bond 
between 0 and T ,  where DT is the price at time 0 of our dividend-paying security 2) 
with maturity T and < is a standard Gaussian random variable. A simple arbitrage 
argument shows that DT increases with the time horizon T ,  and we can reasonably 
assume that DT -+ 00 as T -+ co. So the game-theoretic probability that S does 
as well as the bond tends to 0 as the time horizon T increases. For DT = 100, for 
example, the game-theoretic probability that S does as well as the bond is less than 
So the efficient-market hypothesis with the bond as nume'raire says that the S 
will not do as well as the bond. This does not contradict the fact that S's current price 
is the current game-theoretic price for what it will be worth at the time T for which 
DT = 100. Rather, it says that if we believe the efficient-market hypothesis for this 
market with the bond as nume'raire, then buying the stock to hold for the long-run 
is like buying a lottery ticket: we are paying for a very large payoff that will almost 
certainly not happen. 
Another interesting example is provided by the existence of options on market 
indexes I (such as the European option on FTSE 100 discussed in Chapter 10). 
Consider the efficient-market hypothesis that takes I as the nume'ruire but allows 
Skeptic to trade in the options on I as well as in the stocks in I (and hence, effectively, 
in I itself). This hypothesis may allow us to draw conclusions about the rate of growth 
of I .  For simplicity, suppose that a European call option on I ,  with maturity time T 
and strike price c, is traded. If the option is far out of the money (i.e., the strike price c 
is much greater than the current value I(0) of the index), its price p will be very low: 
p << I(0). Suppose we subscribe to the efficient-market hypothesis to the extent that 
we do not consider it possible to beat the market by a factor of 1/6 (6 might be 1%). 
Assume that the option is so far out of the money that p < 6I(O). Then holding one 
option to maturity will multiply Skeptic's capital by ( I ( T )  - c)+/p, where I ( T )  is 
the value of the index at time T. Because the nurne'ruire increases I(T)/I(O)-fold, 
the efficient-market hypothesis implies 
which is equivalent, under the assumption p < 6I(O), to 
This bound may be too loose to be useful, but it demonstrates the possibility of 
nontrivial implications for the performance of the market as a whole. 

15.5: OTHER FORMS OF THE EFFICIENT-MARKET HYPOTHESIS 
373 
Value at Risk 
It is currently popular in financial practice to summarize the uncertainties concerning 
the investment portfolio of an individual or institution in terms of the portfolio's value 
at risk (VaR) at a certain significance level a. This is defined in terms of a stipulated 
stochastic model P for the behavior of the prices of the securities in the portfolio. 
Writing S(0) and S(T) for the initial and final values of the portfolio, and assuming 
that its holder does not intend to make changes during the period [0, TI, 
VaR = inf {V 1 P{S(T) 2 S(0) - V }  2 1 - a )  
The significance level a is a small number, such as 5% or 1%, measuring the largest 
probability of disaster that we are willing to tolerate. The value at risk is the smallest 
bound on the portfolio's loss that we can endorse with confidence 1 - a. 
Suppose that we adopt the efficient-market hypothesis with the dollar as nume'raire 
for a market that includes all the investments of a particular individual or firm. This 
gives us upper and lower probabilities for all events concerning these investments, and 
hence it allows us to define the value at risk in an analogous way, using game-theoretic 
probability instead of stochastic probability: 
inf {V I E{S(T) 2 S(0) - V }  2 1 - a } ,  
where the lower probability is evaluated in the situation in which S(0) and other 
relevant financial data for time 0 (such as the prices P(0) and D(0) below) have just 
become known. 
Suppose there is only one security traded in the market for which we have adopted 
the efficient-market hypothesis, and assume for simplicity that the portfolio consists 
of one share of this security. The VaR of this portfolio equals its current price; 
everything can be lost. There exist lower probabilities that are nontrivial (different 
from 0), such as 
1 
- 
P {S (T ) 5 cS(O)} = 1 - 5 
C 
for c > 1, but all events of the form { S ( T )  2 a}, where a > 0 may depend on the 
information available at time 0, have lower probability zero. 
Now add another security to our market, a European put option with maturity T 
(or an American put option with maturity at least T )  and strike price C ;  suppose its 
initial price is P(0). In this case the value at risk is at most 
(15.26) 
(in some extreme cases this value can be negative). This is because the event that 
S(0) - S(T) exceeds (15.26) can be written as 
and the upper probability of the last event is at most a, as evidenced by the strategy 
of buying the put and holding it to maturity. 

374 
CHAPTER 15: THE GAME-THEORETIC EFFICIENTMARKET HYPOTHESIS 
An extreme case is where instead of the put the dividend-paying derivative 2) 
introduced in Chapter 1 1 is added to the market. It easily follows from Theorem 1 1.2 
(p. 280) that VaR in this case is 
S(0) ( 1 -exp ( -- 
- k.,rn))> 
where rC; is the upper a-quantile of the standard Gaussian distribution. This expres- 
sion is obtained by solving the equation 
(15.27) 
in V .  The left-hand side of (15.27) is a special case of (1 1.13) for U the indicator 
function of the set (-03, S(0) - V). According to Theorem 11.2, if (15.27) holds and 
the final value S(T) drops below S(0) -V, some trading strategy will have made 1 out 
of ct without any risk of debt. (Formally, U is required to be a Lipschitzian function, 
but it is clear that the indicator function can be approximated by a Lipschitzian 
function to any accuracy.) In this extreme case, our game-theoretic VaR is simply 
the usual stochastic VaR using the risk-neutral probability as the true probability. 
It is not feasible or reasonable to calculate value at risk from options markets at 
the present time. The range of maturities for marketed derivatives is too limited, 
and the efficient-market hypothesis for markets that include derivatives has not been 
sufficiently tested. But if some of this book’s ideas for improving option markets are 
implemented, game-theoretic value at risk may become feasible in the future. 

References 
The following list includes references cited in the text by number and also those cited by 
author. Whenever possible, we provide first names (or middle names in some cases) rather 
than merely initials. If the first name appeared in the publication cited, we reproduce it as it 
appeared, even if this results in more than one form of the same person’s name. (William Feller 
was Willy Feller in 1935.) In most cases where only initials were given in the publication but 
a first or middle name is known to us, we replace the initial with the name without comment. 
But if the name might be spelled or transliterated in more than one way, we put our addition 
in parentheses: A(1eksandr) Khinchine. 
1. Peter A. Abken and Saikat Nandi. Options and volatility. Economic Review, 81:21-35, 
December 1996. Federal Reserve Bank of Atlanta. A survey of competing proposals, 
deterministic and stochastic, for improving the performance of the Black-Scholes model 
by modeling changes in volatility. 
2. Carl Ackermann, Richard McEnally, and David Ravenscraft. The performance of hedge 
funds: Risk, return, and incentives. Journal of Finance, 545333-874, 1999. 
3. William J. Adams. The Life and Times ofthe Central Limit Theorem. Kaedmon, New 
York, 1974. A pleasantly written history of the central limit theorem from De Moivre to 
Lyapunov. 
4. Yutaka Aida and Yoshiro Sigeta. NHK Special: Monetary Revolution 2-The 
Standard- 
Bearers of Financial Engineering. NHK Publishing Company, Tokyo, 1999. NHK is an 
acronym for Nippon Housou Kyoukai, or the Japan Broadcasting Corporation. The book 
is based on a television program. 
5. Oskar Anderson. Probleme der statistischen Methodenlehre in den Sozialwissenschaften. 
Physica, Wiirzburg, 1954. 
375 
Probability and Finance: It’s Only a Game! Glenn Shafer, Vladimir Vovk 
Copyright 0 2001 John Wiley & Sons, Inc. 
ISBN: 0-471-40226-5 

376 
REFERENCES 
6. Robert M. Anderson. A non-standard representation for Brownian motion and It6 
integration. Israel Journal of Mathematics, 25: 15-46, 1976. 
7. John Arbuthnot. Of the Laws of Chance. B. Motte and C. Bathurst, London, fourth 
edition, 1738, A loose translation of Christiaan Huygens’s De ratiociniis in ludo aleae. 
The first edition appeared in 1692. 
8. Antoine Arnauld and Pierre Nicole. La Zogique, ou l’art de penser. Vrin, Paris, 1993. 
This critical edition, by Pierre Clair and Franqois Girbal, was first issued in 1981. It is 
based on the 1683 edition of 1 ’Art de penser, often called the Port Royal Logic. The first 
edition appeared in 1662, the year of Pascal’s death. 
9. Louis Bachelier. ThCorie de la spCculation. Annales scientifques de 1’Ecole Normale 
Supe‘rieure, 3“ se‘rie, 17:21-86, 1900. This was Bachelier’s doctoral dissertation. It was 
reprinted in facsimile in 1995 by Editions Jacques Gabay, Paris. An English translation, 
by A. James Boness, appears on pp. 17-78 of [56]. 
10. Brad M. Barber and Terrance Odean. Trading is hazardous to your wealth: The common 
stock investment performance of individual investors. Journal of Finance, 55:773-806, 
2000. 
11. Edwin F. Beckenbach and Richard Bellman. Inequalities. Springer, Berlin, 1965. 
12. Enrico G. Beltrametti and Gianni Cassinelli. The Logic ofQuantum Mechanics. Addison- 
Wesley, Reading, MA, 1981. 
13. Jan Beran. Statistics for Long-Mentory Processes. Chapman and Hall, New York, 1994. 
14. JosC M. Bernard0 and Adrian F. M. Smith. Bayesian Theory. Wiley, Chichester, England, 
1994. 
15. Jacob Bernoulli. Ars Conjectandi. Thurnisius, Basel, 1713. This pathbreaking work 
appeared eight years after Bernoulli’s death. Bound together with it were two other works 
by Bernoulli, a treatise in Latin on infinite series, and a study in French of odds in court 
tennis (Lettre ci un Amy, sur les Parties du Jeu de Paume). A facsimile reprinting of 
the original Latin text of Ars Conjectandi is marketed by Editions Jacques Gabay. A 
German translation (Wahrscheinlichkeitsrechnung von Jakob BernoulZi. Anmerkungen 
von R. Haussner. Ostwald’s Klassiker, Nr. 107-108, Engelmann, Leipzig) appeared in 
1899. No English edition is available. 
16. Peter L. Bernstein. Capital Ideas: The Improbable Origins of Modern Wall Street. Free 
Press, New York, 1992. A lively account of the development and intertwining of financial 
practice and theory, beginning with the stories of Louis Bachelier in Paris and Charles 
Dow and Eddie Jones on Wall Street a century ago and concluding with the adventures 
of the Wall Street professors of the 1970s and 1980s. Bernstein, a financial analyst and 
founding editor of the Journal of Portfolio Management is personally acquainted with 
many of the individuals who play starring roles in his story. 
Annalen, 85:237-241, 1922. 
17. Serge Bernstein. Sur le thCor2me limite du calcul des probabilitks. Mathematische 
18. Serge Bernstein. Sur I’extension du thCor2me limite du calcul des probabilitks aux 
sommes de quantitCs dkpendantes. Mathematische Annalen, 97: 1-59, 1927. 
19. Jean Bertoin. Sur une intCgrale pour les processus B a-variation bornCe. Annals of 
Probability, 17:1521-1535, 1989. 
20. Jean Bertoin. Le‘vy Processes. Cambridge University Press, Cambridge, 1996. 

REFERENCES 
377 
21. Joseph Bertrand. Calcul des Probabilitis. Gauthier-Villars, Paris, 1889. Some copies of 
the first edition are dated 1888. A second edition appeared in 1907 and was republished 
by Chelsea, New York, in 1972. 
22. Avi Bick and Walter Willinger. Dynamic spanning without probabilities. Stochastic 
23. Patrick Billingsley. Ergodic Theory and Information. Wiley, New York, 1965. 
24. Patrick Billingsley. Convergence of Probability Measures. Wiley, New York, 1968. 
25. Patrick Billingsley. Probability and Measure. Wiley, New York, third edition, 1995. 
Processes and their Applications, 50:349-374, 1994. 
Previous editions appeared in 1979 and 1986. 
26. Nicholas H. Bingham and Rudiger Kiesel. Risk-Neutral Valuation: Pricing and Hedging 
of Financial Derivatives. Springer-Verlag, London, 1998. A textbook on stochastic 
processes and option pricing. The authors present both topics first for discrete and then 
for continuous time. 
27. Fischer Black. How to use the holes in Black-Scholes. Journal ofApplied Corporate 
Finance, 1(4):67-73, Winter 1989. Reprinted in [174]. 
28. Fischer Black. How we came up with the option formula. Journal of Portfolio Manage- 
ment, 154-8, Winter 1989. 
29. Fischer Black and Myron Scholes. The valuation of option contracts and a test of market 
efficiency. Journal of Finance, 27:3994 17, 1972. 
30. Fischer Black and Myron Scholes. The pricing of options and corporate liabilities. 
Journal of Political Economy, 81:637-654, 1973. This is the article in which the Black- 
Scholes equation and the Black-Scholes formula were first derived. It is concerned as 
much with the pricing of warrants and other corporate liab 
es as with options and 
derivatives. 
31. Zvi Bodie. On the risk of stocks in the long run. Financial Analysts Journal, pp. 18-22, 
May-June 1995. 
32. Arno Bohm. Quantum Mechanics: Foundations and Applications. Springer, New York, 
33. Emile Borel. Legons sur la thiorie desfonctions. Gauthier-Villars, Paris, 1898. 
34. Emile Borel. Les probabilitis dinombrables et leurs applications arithmttiques. Rendi- 
conti del Circolo Matematico di Palermo, 271247-270, 1909. Reprinted in [37], Volume 
35. Emile Borel. Applications aux jewc de hasard. Gauthier-Villars. Paris, 1938. The title 
page lists Borel as the author but indicates that the entire book was actually written by 
Jean Ville. Ville is listed as the author, however, of an important note at the end of the 
book, [305]. 
36. Emile Borel. Valeur pratique et philosophie des probabilitis. Gauthier-Villars, Paris, 
37. Emile Borel. CEuvres de &mile Borel. Editions du Centre National de la Recherche 
Scientifique, Paris, 1972. Four volumes. 
second edition, 1986. 
2, pp. 1055-1079. 
1939. 
38. Nicolas Bourbaki. Eliments de mathimatique, Livre lv Fonctions d'une variable rkelle 
(thiorie ilhnentaire). Hermann, Paris, second edition, 1958. 

378 
REFERENCES 
39. Phelim P. Boyle and David Emanuel. Discretely adjusted option hedges. Journal of 
40. Leo Breiman. Probability. Addison-Wesley, Reading, MA, 1968. Second edition: 
41. Glenn W. Brier. Verification of forecasts expressed in terms of probability. Monthly 
Financial Economics, 8:259-282, 1980. 
SIAM, Philadelphia, 1992. 
Weather Review, 78:l-3, 1950. 
42. Mark Britten-Jones and Anthony Neuberger. Arbitrage pricing with incomplete markets. 
Applied Mathematical Finance, 31347-363, 1996. 
43. W. Browne. Christiani Hugenii Libellus de Ratiociniis in Ludo Aleae. Oc the Value of 
all Chances in Games of Fortune; Cards, Dice, Wagers, Lotteries, etc. Mathematically 
Demonstrated. Woodward, London, 1714. A translation of Christiaan Huygens’s De 
ratiociniis in ludo aleae. 
44. Bernard Bm. Postface to the 1986 edition of Laplace’s “Essai philosophique sur les 
probabilitCs”. In [I 901, pp. 245-303. Christian Bourgois, Paris, 1986. 
45. Stephen G. Brush. A history of random sequences. I: Brownian movement from Brown 
to Perrin. Archive for History of Exact Sciences, 5:l-36, 1968. 
46. Laurent Calvet and Adlai Fisher. A multifractal model of asset returns, November 1999. 
Available from http: //www. stern.nyu.edu/”afisher, 
this paper simplifies 
and elaborates results on the multifractal model of asset prices. Empirical calculations 
of the partition function are extended to equities, which were not covered by [124]. 
47. Laurent Calvet, Adlai Fisher, and Benoit B. Mandelbrot. Large deviations and the distri- 
bution of price changes. Cowles Foundation Discussion Paper No. 1166, September 1997. 
Yale University. Paper available from the SSRN database http : / /www. ssrn . corn. 
48. John Y. Campbell, Andrew W. Lo, and A. Craig MacKinlay. The Econometrics of 
Financial Markets. Princeton University Press, Princeton, NJ, 1997. 
49. John Rozier Cannon. The One-Dimensional Heat Equation. Addison-Wesley, Reading, 
MA, 1984. 
50. Mark M. Carhart. On persistence in mutual fund performance. Journal of Finance, 
5257-82, 1997. 
5 1. Yuan S. Chow and Henry Teicher. Probability Theory: Independence, Interchangeability, 
Martingales. Springer, New York, third edition, 1997. One of many excellent textbooks 
on measure-theoretic probability. Its first edition appeared in 1978. 
52. Neil Chriss and William Morokoff. Volatility and variance swaps. Risk, 12, October 
1999. 
53. Alonzo Church. On the concept of a random sequence. Bulletin of the American 
Mathematical Society, 46: 130-1 35, 1940. 
54. Jean Cocteau. (Euvres completes de Jean Cocteau. Marguerat, Lausanne, Switzerland, 
1946-195 1. The lovely poem entitled “Martingale”, originally published in Cocteau’s 
Op&a (1925-1927), is on p. 136 of Volume IV. 
55. Corneliu Constantinescu and Aurel Cornea. Potential Theory of Harmonic Spaces. 
Springer, Berlin, 1972. 
Cambridge, MA, 1964. 
56. Paul H. Cootner, editor. The Random Character of Stock Market Prices. MIT Press, 

REFERENCES 
379 
57. Arthur H. Copeland Sr. Admissible numbers in the theory of probability. American 
58. Antoine Augustin Cournot. Exposition de la thiorie des chances et des probabilitLs. 
59. Antoine Augustin Cournot. Euvres complktes. Vrin, Paris, 1973-1984. 10 volumes. 
60. Jean-Michel Courtault et al. Louis Bachelier: On the centenary of ThCorie de la Specu- 
61. Thomas M. Cover and Erik Ordentlich. Universal portfolios with side information. IEEE 
62. David R. Cox. Regression models and life tables (with discussion). Journal of the Royal 
Journal of Mathematics, 50535-552, 1928. 
Hachette, Paris, 1843. Reprinted in 1984 as Volume I (B. Bru, editor) of [59]. 
lation. Mathematical Finance, 10:339-353, 2000. 
Transactions on Information Theory, 42:348-363, 1996. 
Statistical Society. Series B, 34: 187-220, 1972. 
63. David R. Cox. Partial likelihood. Biometrika, 62:269-276, 1975. 
64. David R. Cox and David V. Hinkley. Theoretical Statistics. Chapman and Hall, London, 
65. David R. Cox and David Oakes. Analysis of Survival Data. Chapman and Hall, London, 
66. John C. Cox and Stephen A. Ross. The valuation of options for alternative stochastic 
processes. Journal of Financial Economics, 3: 145-166, 1976. 
67. John C. Cox, Stephen A. Ross, and Mark Rubinstein. Option pricing: A simplified 
approach. Journal of Financial Economics, 7:229-263, 1979. 
68. John Crank. The Mathematics of Diffusion. Oxford University Press, Oxford, second 
edition, 1975. 
69. Pierre CrCpel. Private communication, November 2000. Professor CrCpel has shared 
the following documents with us: (1) a letter from CrCpel to Jean Ville dated 22 August 
1984, (2) CrCpel’s notes from his interview of Ville on 27 August 1984, in Ville’s home at 
Langon, France, (3) a letter from CrCpel to Ville, dated 21 January 1985, (4) a letter from 
Ville to CrCpel, dated February 2, 1985, (5) two documents from the FrCchet Archives of 
the probability department at the University of Paris VI: a curriculum vitae for Ville from 
around 1956 and a 15-page summary by Ville of his scientific work, dated May 1955, 
and (6) CrCpel’s 65-page paper on the history of martingales, Quelques matiriaux pour 
l’histoire de la thiorie des martingales (1920-1940), which he presented on 5 November 
1984 to the Seminaires de Probabilitis of the University of Rennes. 
1974. 
1984. 
70. J. J. Cross. Potential theory. In Grattan-Guinness [137], pp. 475438 (Volume 1). 
71. Nigel J. Cutland. Infinitesimals in action. Journal of the London Mathematical Society, 
72. Nigel J. Cutland, P. Ekkehard Kopp, and Walter Willinger. A nonstandard approach to 
option pricing. Mathematical Finance, 1: 1-38, 1991. 
73. Nigel J. Cutland, P. Ekkehard Kopp, and Walter Willinger. From discrete to continuous 
financial models: New convergence results for option pricing. Mathematical Finance, 
74. Nigel J. Cutland, P. Ekkehard Kopp, and Walter Willinger. Stock price returns and 
the Joseph effect: A fractional version of the Black-Scholes model. In E. Bolthausen, 
M. Dozzi, and F. Russo, editors, Seminar on Stochastic Analysis, Random Fields and 
Applications, pp. 327-35 1. Birkhauser, Basel, 1995. 
35~202-216, 1987. 
3:101-123, 1993. 

380 
REFERENCES 
75. Robert C. Dalang, Andrew Morton, and Walter Willinger. Equivalent martingale mea- 
sures and no-arbitrage in stochastic securities market model. Stochastics and Stochastics 
Reports, 29:185-201, 1990. 
76. G. D’Albigny. Les martingales modernes. Nouveau recueil du joueur de Roulette et de 
Trente-et-Quarante, contenant les meilleurs systkmes. Librairie des Mathurins, Paris, 
1902. 
77. K. E. Dambis. On the decomposition of continuous submartingales. Theory of Probability 
78. Joseph Warren Dauben. Abraham Robinson: The Creation of Nonstandard Analysis. A 
79. Florence N. David. Games, Gods, and Gambling. Griffin, London, 1962. 
80. Martin Davis. Applied Nonstandard Analysis. Wiley, New York, 1977. 
81. Morton Davis. Infinite games with perfect information. In M. Dresher, L. S. Shapley, 
and A. W. Tucker, editors, Advances in Game Theory, pp. 85-101. Princeton University 
Press, Princeton, NJ, 1964. 
82. A. Philip Dawid. Statistical theory: The prequential approach (with discussion). Journal 
of the Royal Statistical Society. Series A, 147:278-292, 1984. 
83. A. Philip Dawid. Calibration-based empirical probability (with discussion). Annals of 
Statistics, 13:1251-1285, 1985. 
84. A. Philip Dawid. Probability forecasting. In S. Kotz, N. L. Johnson, and C. B. Read, 
editors, Encyclopedia of Statistical Sciences, volume 7, pp. 210-218. Wiley, New York, 
1986. 
85. A. Philip Dawid. Prequential data analysis. In Malay Ghosh and Pramod K. Pathak, 
editors, Current Issues in Statistical Inference: Essays in Honor of D. Basu, IMS 
Lecture Notes-Monographs Series 17, pp. 1 13-126. Institute of Mathematical Statistics, 
Hayward, California, 1992. 
86. A. Philip Dawid and Vladimir G. Vovk. Prequential probability: Principles and proper- 
ties. Bernoulli, 5: 125-1 62, 1999. This paper is the first to state formally a game-theoretic 
law of the iterated logarithm. 
87. Bruno de Finetti. Integrazione delle funzioni a incremento aleatorio. Atti della Reale 
Accademia Nazionale dei Lincei. Classe di scienze jisiche, matematiche, e naturali. 
Rendiconti Serie VI, 10:548-553, 1929. 
88. Bruno de Finetti. Sulla possibiliti di valori eccezionali per una legge di incrementi 
aleatori. Atti della Reale Accademia Nazionale dei Lincei. Classe di scienze jisiche, 
matematiche, e naturali. Rendiconti Serie VI, 10:325-329, 1929. 
89. Bruno de Finetti. Sulle funzione a incremento aleatorio. Atti della Reale Accademia 
Nazionale dei Lincei. Classe di scienze jisiche, matematiche, e naturali. Rendiconti 
Serie VI, 10:163-168, 1929. 
90. Bruno de Finetti. Le funzioni caratteristiche di legge istantanea. Atri della Reale 
Academia Nazionale dei Lincei. Classe di scienze jisiche, matematiche, e naturali. 
Rendiconti Serie VI, 12:278-282, 1930. 
91. Bruno de Finetti. Compte rendu critique du colloque de Genkve sur la thkorie des 
probubilitks. Number 766 in Actualitks Scientifques et Industrielles. Hermann, Paris, 
1939. This is the eighth fascicle of [338]. 
and Its Applications, 10:401-410, 1965. 
Personal and Mathematical Odyssey. Princeton University Press, Princeton, NJ, 1995. 

REFERENCES 
381 
92. Bruno de Finetti. Sull’impostazione assiomatica del calcolo delle probabiliti. Annuli 
Triestini dell’Universita di Trieste, 19:29-81, 1949. An English translation by Gian- 
domenico Majone appears as “On the axiomatization of probability theory”, Chapter 5 
of [94]. 
93. Bruno de Finetti. Teoria Delle Probabilitci. Einaudi, Turin, 1970. An English translation, 
by Antonio Machi and Adrian Smith, was published as Theory of Probability by Wiley 
(London, England) in two volumes in 1974 and 1975. 
94. Bruno de Finetti. Probability, Induction and Statistics: The Art of Guessing. Wiley, 
London, 1972. Ten articles in English, all previously published in English, French, or 
Italian in the period from 1949 to 1967. 
95. Joseph L. Doob. Note on probability. Annals of Mathematics, 37:363-367, 1936. This 
article demonstrates, within the measure-theoretic framework, that the probab 
the outcomes of an infinite sequence of independent, identically distributed random 
variables are not changed by a gambling system-in 
this case, a system for selecting a 
subsequence. 
96. Joseph L. Doob. Review of Etude critique de la notion de collectif. Bulletin of the 
97. Joseph L. Doob. Regularity properties of certain families of chance variables. Transac- 
98. Joseph L. Doob. Probability as measure. Annals of Mathematical Statistics, 12:20&214, 
1941. This article originated as a paper for a meeting of the Institute of Mathematical 
Statistics in Hanover, NH, in September 1940. It was published together with an article 
by von Mises [313] and comments by Doob and von Mises on each other’s articles [315]. 
99. Joseph L. Doob. Application of the theory of martingales. In Le Calcul des Probabilite‘s et 
ses Applications, Colloques Internationaux, pp. 23-27. Centre National de la Recherche 
Scientifique, Paris, 1949. 
American Mathematical Society, 45:824, 1939. 
tions of the American Mathematical Society, 47:455486, 1940. 
100. Joseph L. Doob. Continuous parameter martingales. In Jerzy Neyman, editor, Proceed- 
ings of the Second Berkeley Symposium on Mathematical Statistics and Probability, pp. 
269-277. University of California Press, Berkeley, 195 1. 
101. Joseph L. Doob. Stochastic Processes. Wiley, New York, 1953. Classical monograph 
102. Joseph L. Doob. Wiener’s work in probability theory. Bulletin of the American Mathe- 
matical Society, 72(1, Part II):69-72, 1966. This is a special obituary issue for Wiener, 
and its pages are numbered separately from the rest of Volume 72. 
New York, 1984. 
that popularized martingales. 
103. Joseph L. Doob. Classical Potential Theory and Its Probabilistic Counterpart. Springer, 
104. Joseph L. Doob. The development of rigor in mathematical probability, 190G1950. In 
Pier [245], pp. 157-170. 
105. Lester E. Dubins and Leonard J. Savage. How to Gamble $You Must: Inequalities for 
Stochastic Processes. McGraw-Hill, New York, 1965. A second edition, with the title 
and subtitle interchanged, was published in 1976 by Dover, New York. 
106. Lester E. Dubins and Cideon Schwarz. On continuous martingales. Proceedings of the 
National Academy of Sciences of the USA, 53:913-916, 1965. 

382 
REFERENCES 
107. Darrell Duffie. Dynamic Asset Pricing Theory. Princeton University Press, Princeton, 
NJ, second edition, 1996. In addition to a relatively rigorous treatment of continuous- 
time arbitrage pricing, this book includes discussions of equilibrium pricing and optimal 
portfolio selection. The first edition appeared in 1992. 
108. A. W. F. Edwards. Pascal’s Arithmetical Triangle. Charles Griffin & Company Limited 
and Oxford University Press, London and New York, 1987. 
109. Albert Einstein. Uber die von der molekularkinetischen Theorie der Warme geforderte 
Bewegung von in ruhenden Fliissigkeiten suspendierten Teilchen. Annalen der Physik, 
Dover, 
New York, 1956. First published by Dutton, New York, in 1926, this is a translation, 
by A. D. Cowper, of Untersuchungen iiber die Theorie der Brownschen Bewegung. It 
includes [lo91 together with Einstein’s other papers on Brownian motion. 
11 1. P. Eklof. Ultraproducts for algebraists. In J. Barwise, editor, Handbook ofMathematica1 
Logic, pp. 105-137. North Holland, Amsterdam, 1977. 
112. Robert J. Elliott. Stochastic Analysis and Applications. Springer, New York, 1982. 
113. Robert J. Elliott and P. Ekkehard Kopp. Mathematics of Financial Markets. Springer, 
114. Edwin J. Elton and Martin J. Gruber, editors. Security Evaluation and Portfolio Analysis. 
115. Georg Faber. iiber stetige Funktionen. Mathematische Annalen, 69:372443, 1910. 
116. Eugene F. Fama. The behavior of stock-market prices. Journal ofBusiness, 38:34-105, 
117. Eugene F. Fama. Efficient capital markets: A review of theory and empirical work. 
118. Eugene F. Fama. Efficient capital markets, 11. Journal of Finance, 46:1575-1617, 1991. 
119. Eugene F. Fama. Market efficiency, long-term returns, and behavioral finance. Journal 
of Financial Economics, 49:283-306, 1998. 
120. William Feller. An Introduction to Probability Theory and Its Applications, volume 1. 
Wiley, New York, third edition, 1968. Previous editions of this volume appeared in 1950 
and 1957. 
121. William Feller. An Introduction to Probability Theory and Its Applications, volume 2. 
Wiley, New York, second edition, 1971. The first edition of this volume appeared in 
1966. 
122. Willy Feller. Uber den zentralen Grenzwertsatz der Wahrscheinlichkeitsrechnung. Math- 
ematische Zeitschrvt, 40521-559, 1935. 
123. Pierre de Fermat. CEuvres. Gauthier-Villars, Paris, 1891-1912. Edited by Paul Tannery 
and Charles Henry in four volumes, together with a supplement that appeared in 1922. 
Fermat’s correspondence, including the surviving letters to Pascal on the problem of 
points and the problem of the gambler’s ruin, are in the second volume, which appeared 
in 1894. 
124. Adlai Fisher, Laurent Calvet, and Benoit B. Mandelbrot. Multifractality of Deutschmark I 
US Dollar exchange rates. Cowles Foundation Discussion Paper No. 1166, September 
17: 549-560, 1905. 
110. Albert Einstein. Investigations on the Theory of the Brownian Movement. 
New York, 1999. 
Prentice-Hall, Englewood Cliffs, NJ, 1972. 
1965. 
Journal of Finance, 25:383417, 1970. 

REFERENCES 
383 
1997. Yale University. Available from the SSRN database h t t p  : / /w. 
ssrn. corn. 
Among other things, the paper studies the variation spectrum for the DM/USD market. 
125. Ronald A. Fisher. Statistical Methods for Research Workers. Oliver and Boyd, Edinburgh, 
1925. The thirteenth edition appeared in 1958. 
126. Hans Follmer. Calcul d’It8 sans probabilitks. In J. AzCma and M. Yor, editors, Siminaire 
de Probabilitis XV, volume 850 of Lecture Notes in Mathematics, pp. 143-1.50. Springer, 
Berlin, 198 1. 
127. Hans Follmer and Uwe Kiichler. Richard von Mises. In Heinrich G. W. Begehr, Helmut 
Koch, Jiirg Kramer, Norbert Schappacher, and Ernst-Jochen Theile, editors, Mathematics 
in Berlin, pp. 11 1-1 16. Birkhauser Verlag, Berlin, 1998. 
128. Jack Clark Francis, William W. Toy, and J. Gregg Whittaker, editors. The Handbook of 
Equity Derivatives. Wiley, New York, revised edition, 2000. 
129. Maurice FrCchet. Sur 1’intCgrale d’une fonctionelle Ctendue B un ensemble abstrait. 
Bulletin de la Sociite‘ rnathimatique de France, 43:248-265, 1915. 
130. Maurice Frtchet. Expos6 et discussion de quelques recherches rCcentes sur les fonde- 
ments du calcul des probabilitts. In Rolin Wavre, editor, Les fondements du calcul des 
probabilite‘s, number 735 in Actualitis Scient$ques et Industrielles, pp. 22-55. Hermann, 
Paris, 1938. FrCchet reviews von Mises’s concept of a collective and the clarifications due 
to Reichenbach, Popper, Copeland, Wald, and Ville. He concludes that the theory of the 
collective is not successful as a foundation for probability and argues that Kolmogorov’s 
axioms provide a sufficient formal foundation. Les fondements du calcul desprobabilitis 
is the second fascicle of [338]. 
13 1. Avner Friedman. Partial DifSerential Equations of Parabolic Type. Prentice-Hall, En- 
glewood Cliffs, NJ, 1964. 
132. Bert Fristedt and S. James Taylor. Strong variation for the sample functions of a stable 
process. Duke Mathematical Journal, 40:2.59-278, 1973. 
133. David Gale and F. M. Stewart. Infinite games with perfect information. In H. W. Kuhn 
and A. W. Tucker, editors, Contributions to the Theory of Games, 11, pp. 245-266. 
Princeton University Press, Princeton, NJ, 1953. 
134. Boris V. Gnedenko. Theory of Probability. Gordon and Breach, St. Leonards, Australia, 
1997. This is an English translation, with revisions by the author, of the sixth Russian 
edition of Kypc Teopw B e p o m H o c T e F i ,  published in 1988 by Nauka, Moscow. The 
translator is Igor A. Ushakov. The first Russian edition of the book appeared in 1950. 
13.5. Boris V. Gnedenko and Andrei N. Kolmogorov. Limit distributions for sums of indepen- 
dent random variables. Addison-Wesley, Cambridge, MA, 1954. The original Russian 
edition: I l p e A e n b H b i e  p a c n p e A e n e H M R  Anfi CYMM H ~ ~ ~ B M C M M ~ I X  
C n y r a m H b l X  BenMYMH, 
1949. Translated and annotated by K. L. Chung. With an appendix by Joseph L. Doob. 
136. Robert Goldblatt. Lectures on the Hyperreals: An Introduction to Nonstandard Analysis. 
Springer, New York, 1998. An excellent exposition based on ultrafilters. Contains a 
chapter on the Loeb measure. 
137. Ivor Grattan-Guinness, editor. Companion Encyclopedia of the History and Philosophy 
ofthe Mathematical Sciences. Routledge, London, 1994. two volumes. 
138. Ivor Grattan-Guinness. Heat diffusion. In Companion Encyclopedia of the History and 
Philosophy of the Mathematical Sciences [137], pp. 1165-1 170 (Volume 2). 

384 
REFERENCES 
139. Jeremy J. Gray. The Hilbert Challenge. Oxford University Press, Oxford, 2000. 
140. Sanford Grossman and Joseph Stiglitz. On the impossibility of informationally efficient 
141. Ian Hacking. The Emergence of Probability. Cambridge University Press, New York, 
142. Ian Hacking. The Taming ofChance. Cambridge University Press, New York, 1990. 
143. Anders Hald. A History of Probability and Statistics and their Applications before 1750. 
markets. American Economic Review, 70:393-408, 1980. 
1975. 
Wiley, New York, 1990. 
144. Peter Hall and Christopher C. Heyde. Martingale Limit Theory and Its Application. 
Academic Press, New York, 1980. 
145. Godfrey H. Hardy and John E. Littlewood. Some problems of Diophantine approxima- 
146. Godfrey H. Hardy, John E. Littlewood, and George P6lya. Inequalities. Cambridge 
University Press, Cambridge, second edition, 1967. The first edition appeared in 1934. 
147. J. Michael Harrison and Stanley R. Pliska. Martingales and stochastic integrals in the 
theory of continuous trading. Stochastic Processes and their Applications, 1 1 :2 15-260, 
1981. This article is credited with the first rigorous and general proof that the absence 
of arbitrage and the ability to hedge depend only on the existence and uniqueness of an 
equivalent martingale measure. 
148. Philip Hartman and Avi Wintner. On the law of the iterated logarithm. American Journal 
of Mathematics, 63:169-176, 1941. 
149. Felix Hausdorff. Beitrage zur Wahrscheinlichkeitsrechnung. 
Sitzungsberichte der 
Koniglich Sachsischen Gesellschaf der Wissenschafen zu Leipzig, Mathematisch- 
Physische Klasse, 53:152-178, 1901. 
tion. Acta Mathemutica, 37: 155-239, 1914. 
150. Felix Hausdorff. Grundziige derMengenEehre. Verlag Von Veit & Comp., Leipzig, 1914. 
151. Thomas Hawkins. Lebesgue’s Theory of Integration: Its Origins and Development. 
Chelsea, New York, second edition, 1974. The first edition was published in 1970 by the 
University of Wisconsin Press, Madison. 
152. David Hilbert. Mathematical problems. Bulletin of the American Mathematical Society, 
8:437479, 1902. Hilbert’s famous address to the International Congress of Mathe- 
maticians in Paris in 1900, in which he listed twenty-three open problems central to 
mathematics. Translated from the German by Mary W. Newson. 
153. Roland F. Hoskins. Standard and Nonstandard Analysis: Fundamental Theory, Tech- 
niques, and Applications. Ellis Horwood, New York, 1990. Chapter 4 gives the construc- 
tion of *W 
via ultrafilters. Later chapters contain applications in mathematical analysis 
including convergence, continuity, differentiation, and integration. 
154. John C. Hull. Options, Futures, and Other Derivatives. Prentice-Hall, Upper Saddle 
River, NJ, fourth edition, 2000. A popular introduction to the study of derivatives at 
the MBA level. It discusses both the theory and practice of derivatives and includes 
numerical procedures for implementing the most common pricing algorithms. 
155. Christiaan Huygens. CEuvres compl2tes de Christiaan Huygens. Nijhoff, La Haye, 1888- 
1950. There are twenty-two volumes. Volume XIV, which contains Huygens’s work on 
probability, appeared in 1920. 

REFERENCES 
385 
156. Kiyosi ItB. Stochastic integral. Proceedings of the Imperial Academy of Tokyo, 20519- 
524, 1944. Reprinted in [157], pp. 85-90. 
157. Kiyosi It6 Selected Papers. Springer, New York, 1987. Edited by Daniel W. Stroock 
and S. R. Sriniva Varadhan. 
158. Jean Jacod and Albert N. Shiryaev. Limit Theorems for Stochastic Processes. Springer, 
159. Max Jammer. The Philosophy of Quantum Mechanics: The Interpretations of Quantum 
Berlin, 1987. 
Mechanics in Historical Perspective. Wiley, New York, 1974. 
160. Michael C. Jensen. Risk, the pricing of capital assets, and evaluation of investment 
161. Camille Jordan. Remarques sur les intkgrales dCfinies. Journal de mathkmatiques pures 
portfolios. Journal of Business, 42: 167-247, 1969. 
et appliqukes (4), 8:69-99, 1892. 
costs. Journal of Economic Theory, 66:178-197, 1995. 
162. E. Jouini and H. Kallal. Martingales and arbitrage in securities markets with transactions 
163. Joan Junkus. U. S. options exchanges. In Francis et al. [128], pp. 55-76. 
164. Jean-Pierre Kahane. Des sCries de Taylor au mouvement brownien, avec un aperp sur 
le retour. In Pier [245], pp. 415429. 
axiom of choice and the axiom of determinacy). Nauka, Moscow, 1984. 
Springer, New York, second edition, 1991. 
In 
G. Maruyama and Yurii V. Prokhorov, editors, Proceedings of the Second Japan-USSR 
Symposium on Probability Theory, volume 330 of Lecture Notes in Mathematics, pp. 
176-192. Springer, Berlin, 1973. 
165. Vladimir G. Kanovei. 
AKCMOMa B b l 6 O p a  M aKCMOMa AeTePMMHMpOBaHHOCTM (The 
166. Ioannis Karatzas and Steven E. Shreve. Brownian Motion and Stochastic Calculus. 
167. Takayuki Kawada and Norio KBno. On the variation of Gaussian processes. 
168. Alexander S. Kechris. Classical Descriptive Set Theory. Springer, New York, 1995. 
169. John L. Kelley, Jr. A new interpretation of information rate. Bell System Technical 
170. A(1eksandr) Khinchine. Uber einen Satz der Wahrscheinlichkeitsrechnung. Fundamenta 
Mathematicue, VI:9-20, 1924. The date “December 1922” is given at the end of the 
article. 
17 1. A(1eksandr) Khinchine. Zur Theorie der unbeschrankt teilbaren Vorteilungsgesetze. 
172. A(1eksandr) Khinchine and Paul LCvy. Sur les lois stables. Comptes rendus des Skances 
Journal, 35:917-926, 1956. 
Matematicheskii Sbornik, 2:79-119, 1937. 
de 1’Acadkmie des Sciences, 202:374-376, 1936. 
173. Frank Klingenhofer and Martina Zahle. Ordinary differential equations with fractal 
noise. Proceedings of the American Mathematical Society, 127: 1021-1028, 1999. 
174. Robert W. Kolb, editor. Practical Readings in Financial Derivatives. Blackwell, Malden, 
MA, 1998. 
175. Andrei N. Kolmogorov. Uber das Gesetz der iterierten Logarithmus. Mathematische 
Annalen, 101:126-135, 1929. Appears in English in [181], pp. 3242, as “On the law of 
the iterated logarithm”. 

386 
REFERENCES 
176. Andrei N. Kolmogorov. Sur la loi forte des grands nombres. Comptes rendus des Se‘ances 
de Z’Acade‘miedes Sciences, 191:910-912, 1930. Appears in English in [181], pp. 60-61, 
as “On the strong law of large numbers”. 
177. Andrei N. Kolmogorov. Sulla forma generale di un processo stocastico omogeneo (Un 
probleme di Bruno de Finetti). Atti della Reale Accademia Nazionale dei Lincei. Classe 
di scienze Jisiche, matematiche, e naturali. Rendiconti. Serie VI, 15:805-808 and 866- 
869, 1932. The second part of the article (pp. 866-869) is entitled “Ancora sulla forma 
generale di un processo omogeneo”. The article appears in English in [181], pp. 121-127, 
as “On the general form of a homogeneous stochastic process”. 
178. Andrei N. Kolmogorov. Grundbegrife der Wahrscheinlichkeitsrechnung. Springer, 
Berlin, 1933. An English translation by Nathan Morrison appeared under the title 
Foundations of the Theory of Probability (Chelsea, New York) in 1950, with a second 
edition in 1956. A Russian translation, by G. M. Bavli, appeared under the title OCHOB- 
slightly expanded by Kolmogorov with the assistance of Albert N. Shiryaev, in 1974. 
H b l e  nOHRTMR TeOpMl.1 BepORTHOCTefi (Nauka, MOSCOW) in 1936, with a second edition, 
179. Andrei N. Kolmogorov. On tables of random numbers. Sankhya, The Indian Journal 
of Statistics. Series A, 25:369-376, 1963. Republished in [182], pp. 176-183. The two 
English versions both contain potentially misleading errors, but in different places. 
180. Andrei N. Kolmogorov. Selected Works ofA. N. Kolmogorov. Volume I: Mathematics and 
Mechanics. Kluwer, Dordrecht, 1991. Translated by V. M. Volosov from the Russian orig- 
inal, L/l36paHHble Tpyflbl. M a T e M a T M K a  M MexaHbtKa, edited by Vladimir M. Tikhornirov 
and published in 1985 by Nauka, Moscow. The volume includes commentary on some 
of the articles. Some of the articles were originally published in languages other than 
Russian, but the translations of these articles in this volume appear to have been made 
from the Russian, without reference to the originals or other translations. Consequently, 
even the titles are sometimes different. 
18 1. Andrei N. Kolmogorov. Selected Works of A. N. Kolmogorov. Volume 11: Probability The- 
ory and Marhematical Statistics. Kluwer, Dordrecht, 1992. Translated by G. Lindquist 
from the Russian original, Teopm B e p o R w o c T e f i  M M a T e M a T w e c K a n  CTaTMcTMKa, 
edited by Albert N. Shiryaev and published in 1986 by Nauka, Moscow. Our comments 
about [180] also apply to this volume. 
182. Andrei N. Kolmogorov. Selected Works of A. N. Kolmogorov. Volume Ill: Informa- 
tion Theory and the Theory of Algorithms. Kluwer, Dordrecht, 1993. Translated by 
A. B. Sossinsky from the Russian original, Teopm nH+opMawfk! 
).I TeOpMfl anropm- 
MOB, edited by Albert N. Shiryaev and published in 1987 by Nauka, Moscow. Our 
comments about [I801 also apply to this volume. 
of Probability and Its Applications, 32:389-412, 1987. 
183. Andrei N. Kolmogorov and Vladirnir A. Uspenskii. Algorithms and randomness. Theory 
184. David M. Kreps. Multiperiod securities and the efficient allocation of risk: A comment 
on the Black-Scholes option pricing model. In John J. McCall, editor, The Economics of 
Information and Uncertainty, pp. 203-232. Chicago University Press, Chicago, 1982. 
Paris, 2nd edition, 1822. 
185. Sylvestre FranGois Lacroix. Trait6 e‘le‘rnentaire du calcul des probabi1it.h. Bachelier, 
186. Frank Lad. Operational Subjective Statistical Methods: A Mathematical, Philosophical, 
and Historical Introduction. Wiley, New York, 1996. 

REFERENCES 
387 
187. Michiel van Lambalgen. Random Sequences. PhD thesis, University of Amsterdam, 
188. John W. Lamperti. Probability. Wiley, New York, second edition, 1996. The first edition 
appeared in 1966. 
189. Pierre Simon de Laplace. Thiorie analytique des prohahilitis. Courcier, Paris, first 
edition, 1812. This monumental work had later editions in 1814 and 1820. The third 
edition was reprinted in Volume 7 of Laplace’s Euvres complltes. 
190. Pierre Simon de Laplace. Essai philosophique sur les probabilitis. Courcier, Paris, first 
edition, 1814. The fifth and definitive edition was published in 1825. A modern edition, 
edited by Bernard Bru, was published by Christian Bourgois, Paris, in 1986. 
191. Pierre Simon de Laplace. Philosophical Essay on Probabilities. Springer, New York, 
1994. English translation of [190]; translated by Andrew I. Dale. 
192. Lucien Le Cam. The central limit theorem around 1935 (with comments by Hale 
F. Trotter, Joseph L. Doob, and David Pollard). Statistical Science, 1:78-96, 1986. 
193. Henri Lebesgue. Sur une gCnCralisation de I’intCgrale dCfinie. Comptes rendus des 
Siances de I’Acadimie des Sciences, 132:1025-1028, 1901. 
194. Robert J. Leonard. Creating a context for game theory. In E. Roy Weintraub, editor, 
Toward a History of Game Theory, pp. 29-76. Duke University Press, Durham, NC, 
1992. 
195. Dominique Lepingle. La variation d’ordre p des semi-martingales. Zeitschrift fur 
Wahrscheinlichkeitstheorie und verwandte Gebiete, 36:295-316, 1976. 
196. Paul Levy. Calcul de probabilitis. Gauthier-Villars, Paris, 1925. This pathbreaking 
book includes the first theory of stable distributions. The first few chapters provide an 
eclectic understanding of the subjective and objective sides of probability. An appendix 
discusses the laws of probability in abstract spaces. 
197. Paul LCvy. 
Sur les intCgrales dont les ClCments sont des variables alCatoires 
indkpendantes. Annuli della R. Scuola Normale Superiore di Pisa. Series 2., 31337- 
366, 1934. See also the addendum in 4:217-218, 1935. The article and addendum are 
reprinted in [203], Volume IV, pp. 9-40. 
198. Paul LCvy. PropriCtCs asymptotiques des sommes de variables indkpendantes ou en- 
chaintes. Journal des rnathimatiques pures et appliqukes. Series 9., 14(4):347-402, 
1935. This article was omitted from [203], the six-volume collection of LCvy’s works. 
Second edition: 1954. 
1987. 
199. Paul LCvy. Thiorie de 1 ’addition des variables alkatoires. Gauthier-Villars, Paris, 1937. 
200. Paul LCvy. Le mouvement brownien plan. American Journal of Mathematics, 62:487- 
201. Paul LCvy. Les fondements du calcul des probabilitks. Revue de mitaphysique et de 
202. Paul LCvy. Quelques aspects de la pensie d’un rnathkmaticien. Blanchard, Paris, 1970. 
203. Paul LCvy. Euvres de Paul Livy. Gauthier-Villars, Paris, 1973-1980. In six volumes. 
204. Ming Li and Paul Vitinyi. An Introduction to Kolmogorov Complexity and Its Applica- 
550, 1940. Reprinted in [203], Volume V, pp. 10-74. 
morale, 59(2):164-179, 1954. Reprinted in [203], Volume VI, pp. 95-110. 
Edited by Daniel DuguC. 
tions. Springer, New York, second edition, 1997. The first edition appeared in 1993. 

388 
REFERENCES 
205. LIFFEdata historical CD-Rom: Equity products end of day data. LIFFE Data Services, 
Basingstoke, UK, March 2001. Website http: //www. liffedata. 
corn, e-mail 
sales@lif fedata. corn. 
206. Robert S. Liptser and Albert N. Shiryaev. Theory of Martingales. Kluwer, Dordrecht, 
1989. The Russian original, Teopm MapTwranoe, was published by Nauka, Moscow, 
in 1986. 
207. Andrew W. Lo, editor. Market Eficiency: Stock Market Behaviour in Theory and 
Practice. Elgar, Cheltenham, United Kingdom, 1997. Two volumes. A comprehensive 
and extremely expensive collection of articles on the efficient market hypothesis over 
three decades. 
208. Andrew W. Lo and A. Craig MacKinlay, editors. A Non-Random Walk Down Wall Street. 
Princeton, NJ, Princeton University Press, 1999. 
209. Peter A. Loeb. Conversion from nonstandard to standard measure spaces and applications 
in probability theory. Transactions of the American Mathematical Society, 21 1: 113-122, 
1975. 
210. Jerzy tog. Quelques remarques, thCoremes et problkmes sur les classes dkfinissables 
d'algkbres. In Mathematical Interpretation of Formal Systems, pp. 98-1 13. North Hol- 
land, Amsterdam, 1955. 
21 1. Burton G. Malkiel. Returns from investing in equity mutual funds 1971 to 1991. Journal 
of Finance, 50549-572, 1995. 
212. Burton G. Malkiel. A Random Walk Down Wall Street. Norton, New York, 1996. 
213. James D. Malley and John Hornstein. Quantum statistical inference. Statistical Science, 
8:433457, 1993. 
214. Benoit B. Mandelbrot. Une classe de processus stochastiques homothktiques 2 soi; 
application i la loi climatologique de H. E. Hurst. Comptes rendus des Skances de 
1 'Acade'mie des Sciences, 26013274-3277, 1965. 
215. Benoit B. Mandelbrot. Self-affine fractal sets. In L. Pietronero and E. Tosatti, editors, 
Fractals in Physics, pp. 3-28. North-Holland, Amsterdam, 1986. 
216. Benoit B. Mandelbrot. Fractals and Scaling in Finance: Discontinuity, Concentration, 
Risk. Springer, New York, 1997. This volume includes contributions Mandelbrot made 
to finance theory in the 1960s, with retrospective comments, together with reports on 
new developments, including work with Fisher and Calvet on the multifractal model of 
asset returns; see also [47], [124], and [217]. 
217. Benoit B. Mandelbrot, Adlai Fisher, and Laurent Calvet. A Multifractal Model of 
Asset Returns. Cowles Foundation Discussion Paper No. 1164, September 1997. Yale 
University. Available from the SSRN database http : / /www . ssrn . corn. 
218. Andrei A. Markov. L/lcwcneHue BepoflTHocTeR. Tmorpa+m b'lMnepaTopcKoFi h a -  
AeMMM HayK, Saint Petersburg, 1900. The second edition, which appeared in 1908, was 
translated into German by Heinrich Liebmann: Wahrscheinlichkeitsrechnung, Teubner, 
Leipzig, 1912. 
219. Donald A. Martin. Borel determinacy. Annals ofMathematics, 102:363-371, 1975. 
220. Donald A. Martin. An extension of Borel determinacy. Annals of Pure and Applied 
Logic, 49:279-293, 1990. 

REFERENCES 
389 
221. Donald A. Martin. The determinacy of blackwell games. The Journal of Symbolic Logic, 
6311565-1581, 1998. 
222. Thierry Martin. Probabilit6s et critique philosophique selon Coumot. Vrin, Paris, 1996. 
223. Per Martin-Lof. The definition of random sequences. Information and Control, 9:602- 
619, 1966. 
224. Per Martin-Lof. The literature on von Mises’ Kollectivs revisited. Theoria, 35: 12-37, 
1969. 
225. Nina Mehta. Equity vol swaps grow up. Derivatives Strategy, 4:ll-12, July 1999. 
226. D. H. Mellor. The Matter of Chance. Cambridge University Press, London, 1971. 
227. F. MentrC. Cournot et la renaissance du probabilisme au XIXe sikcle. Marcel Rivikre, 
228. Fabio Mercurio and Ton C. F. Vorst. Option pricing with hedging at fixed trading dates. 
Applied Mathematical Finance, 3: 135-158, 1996. 
229. Robert C. Merton. Theory of rational option pricing. Bell Journal of Economics and 
Management Science, 4: 141-183, 1973. 
230. Paul-Andre Meyer. Demonstration simplifiCe d’un thtorkme de Knight. In Paul-AndrC 
Meyer, editor, Skminaire de Probabilith V, volume 191 of Lecture Notes in Mathematics, 
pp. 191-195. Springer, Berlin, 1971. 
231. Paul-AndrC Meyer. Quantum probability as seen by a classical probabilist. In L. Accardi 
and Christopher C. Heyde, editors, Probability Towards 2000, volume 128 of Lecture 
Notes in Statistics, pp. 235-248. Springer, New York, 1998. 
Bernoulli, 6:401-434, 2000. 
Paris, 1908. 
232. Thomas Mikosch and Rimas NorvaiSa. Stochastic integral equations without probability. 
233. Jan Mycielski. On the axiom of determinateness. Fundamenta Mathematicue, 53:204- 
234. Jan Mycielski and S. Swierczkowski. On the Lebesgue measurability and the axiom of 
235. Edward Nelson. Internal set theory: A new approach to nonstandard analysis. Bulletin 
236. Edward Nelson. Radically Elementary Probability Theory. Princeton University Press, 
237. M. F. Maury Osbome. Brownian motion in the stock market. Operations Research, 
238. Fredos Papangelou. Integrability of expected increments of point processes and a related 
random change of scale. Transactions of the American Mathematical Society, 165:483- 
506, 1972. 
239. Jeff B. Paris. ZF k Xi determinateness. Journal of Symbolic Logic, 37:661-667, 1972. 
240. Blaise Pascal. Pascal: Euvres compl2tes. Desclte de Brouwer, Paris, 1970. Edited by 
J. Mesnard, four volumes. The third volume contains Pascal’s letters to Fermat on the 
problem of points and the problem of the gambler’s ruin. 
241. Blaise Pascal. Pascal: CEuvres complktes. Gallimard, Paris, 1998-2000. Edited by 
Michel Le Guern, two volumes. The first volume, which appeared in 1998, contains the 
224, 1964. 
determinateness. Fundamenta Mathematicue, 54:67-7 1, 1964. 
of the American Mathematical Society, 83: 1165-1 198, 1977. 
Princeton, NJ, 1987. 
71145-173, 1959. 

390 
REFERENCES 
letters to Fermat on the problem of points and the gambler’s ruin. The second volume 
appeared in 2000. 
242. Valentin V. Petrov. Sums of Independent Random Variables. Springer, Berlin, 1975. 
243. Valentin V. Petrov. Limit Theorems of Probability Theory: Sequences of Independent 
Random Variables. Oxford University Press, Oxford, 1995. 
244. Louis B. Picard. Euvres de L. B. Picard. Barba, Paris, 1821. The play entitled Les 
provinciaux &Paris is in Volume 3. On p. 401, JCrBme takes in a gambling house as he 
surveys the vices of Paris: “L’un vient de perdre son dernier e‘cu, et il va mettre sa boite 
d’or en gage pour suivre sa martingale”. 
245. Jean-Paul Pier, editor. Development of Mathematics 1900-1950. Birkhauser, Basel, 
1994. 
246. Jean-Paul Pier. Integration et mesure 1900-1950. In Development of Mathematics 
247. Henri Poincart. Sur le problbme des trois corps et les Cquations de la dynamique. Acta 
Mathematica, 13: 1-270, 1890. 
248. Georg PBlya. Uber den zentralen Grenzwertsatz der Wahrscheinlichkeitsrechnung und 
das Momentenproblem. Mafhematische Zeitschrift, 8: 170-1 8 1, 1920. Gorgy P6lya was 
born in Budapest in 1887 and died in Palo Alto in 1985. After he immigrated to the 
United States, PBlya used the English spelling of his first name, George. But this article 
used the German spelling. The article contributes only indirectly to the central limit 
theorem; it is concerned with conditions under which the convergence of a sequence of 
probability distributions is implied by the convergence of their moments. It appears to 
be responsible, however, for the name “central limit theorem”. 
249. Karl R. Popper. Logik der Forschung. Springer, Vienna, 1935. An English translation, 
The Logic of Scient$c Discovery, was published by Hutchinson, London, in 1959. 
250. Karl R. Popper. The Open Universe. Hutchinson, London, 1982. 
251. Karl R. Popper. Realism and the Aim of Science. Hutchinson, London, 1983. 
252. Theodore Porter. The Rise of Statistical Thinking, 1820-1900. Princeton University 
Theorie und Anwendungen der absolut additiven Mengenfunctio- 
nen. Sitzungsherichte der kaiserlichen Akadeinie der Wissenschafen, Mathematisch- 
Naturwissenschaftliche Klasse, 12211,: 1295-1438, 1913. 
Zeitschrift, 34:568-619, 1932. 
1900-1950 [245], pp. 517-564. 
Press, Princeton, NJ, 1986. 
253. Johann Radon. 
254. Hans Reichenbach. 
Axiomatik der Wahrscheinlichkeitsrechnung. Mathematische 
255. Hans Reichenbach. Les fondements logiques des probabilitCs. Annales de l’lnsfitut 
Henri Poincare‘, 7:267-348, 1937. 
256. Richard J. Rendleman and Brit J. Bartter. Two-state option pricing. Journal of Finance, 
257. AlfrCd RCnyi. Foundations of Probability. Holden-Day, San Francisco, 1970. 
258. AlfrCd RCnyi. Probability Theory. North-Holland, Amsterdam, 1970. 
259. Christian P. Robert. The Bayesian Choice. Springer, New York, 1994. 
260. Abraham Robinson. Non-Standard Analysis. North-Holland, Amsterdam, second edi- 
34: 1093-1 110, 1979. 
tion, 1974. First edition: 1966. 

REFERENCES 
391 
261. L. Chris G. Rogers. Arbitrage with fractional Brownian motion. Mathematical Finance, 
7:95-105, 1997. As the paper says, the fact that the fractional Brownian motion is a 
semimartingale only in the Brownian case has been known to its author since 1989. 
262. L. Chris G. Rogers and David Williams. Diffusions, Markov Processes, and Martingales, 
volume 1: Foundations. Wiley, Chichester, second edition, 1994. Reissued by Cambridge 
University Press in Cambridge Mathematical Library, 2000. 
263. Paul A. Samuelson. Proof that properly anticipated prices fluctuate randomly. Industrial 
264. Paul A. Samuelson. Mathematics of speculative price. SlAM Review, 15: 1 4 2 ,  1973 
265. Leonard J. Savage. Elicitation of personal probabilities and expectations. Journal ofthe 
Management Review, 6:41-50, Spring 1965. 
American Statistical Association, 66:783-801, 1971. 
266. Manfred Schal. On quadratic cost criterion for option hedging. Mathematics of Opera- 
tions Research, 19:121-131, 1994. 
267. Claus Peter Schnorr. Klassifikation der zufallsgesetze nach komplexitat und ordnung. 
Zeitschrifi fur Wahrsckeinlickkeitstheorie und venvandte Gebiete, 16: 1-21, 1970. 
268. Claw Peter Schnorr. A unified approach to the definition of random sequences. Math. 
Systems Theory, 5:246-258, 1971. 
269. Claus Peter Schnorr. 
Zufalligkeit und Wahrscheinlichkeit: Eine algorithmische 
Bergriindung der Wahrscheinlichkeitstheorie, volume 21 8 of Lecture Notes in Math- 
ematics. Springer, Berlin, 1971. 
270. Laurent Schwartz. Quelques rkflexions et souvenirs sur Paul LCvy. In M. Metivier, 
J. Neveu, and S. R. Sriniva Varadhan, editors, Colloque Paul Levy sur les Processus 
Stochastiques (22-26 juin 1987, Ecole Polytecknique, Palaiseau), number 157-158 in 
AstCrisque, pp. 13-28. SociCtC MathCmatique de France, Paris, 1988. 
271. Martin Schweizer. Variance-optimal hedging in discrete time. Mathematics of Operations 
Research, 2O:l-32, 1995. 
272. Franqoise Seillier-Moiseiwitsch and A. Philip Dawid. On testing the validity of sequential 
probability forecasts. Journal ofthe American Statistical Association, 88:355-359, 1993. 
273. Glenn Shafer. A Mathematical Theory of Evidence. Princeton University Press, Princeton, 
NJ, 1976. 
274. Glenn Shafer. Bayes’s two arguments for the rule of conditioning. Annals of Statistics, 
10:1075-1089, 1982. An examination of the role of time in Thomas Bayes’s theory of 
probability. 
275. Glenn Shafer. Conditional probability. International Statistical Review, 53:261-277, 
1985. This article argues that conditional probability is meaningful only in the context 
of a protocol (or event tree) that spells out the possibilities for future observations. 
276. Glenn Shafer. The unity and diversity of probability. Statistical Science, 5:435-462, 
1990. Argues that a broad conception of the foundation and applications of probability 
is needed in order for statistics to flourish as a profession. The article is accompanied by 
comments by a number of distinguished statisticians. 
277. Glenn Shafer. The unity of probability. In George von Furstenberg, editor, Acting 
Under Uncertainty: Multidisciplinary Conceptions, pp. 95-126. Kluwer, Boston, 1990. 
Argues that knowledge of the long run, value, and warranted belief are enrangled in the 

392 
REFERENCES 
picture underlying mathematical probability to the degree that no single one of these 
ideas suffices as a conceptual foundation. 
278. Glenn Shafer. What is probability? In David C. Hoaglin and David S. Moore, editors, 
Perspectives on Contemporary Statistics, MAA Notes 21, pp. 93-105. Mathematical As- 
sociation of America, 1992. A philosophical and historical introduction to the competing 
interpretations of probability. 
279. Glenn Shafer. Can the various meanings of probability be reconciled? In Gideon Keren 
and Charles Lewis, editors, A Handbook for Data Analysis in the Behavioral Sciences: 
Methodological Issues, pp. 165-196. Lawrence Erlbaum, Hillsdale, NJ, 1993. Develops 
the elementary theory of probability and price in trees and shows how it can be used to 
reconcile competing philosophies of probability. 
280. Glenn Shafer. The early development of mathematical probability. In Grattan-Guinness 
[ 1371, pp. 1293-1 302. Volume 2. This article surveys the development of the mathematics 
and philosophy of probability from Pascal to Laplace. 
281. Glenn Shafer. The subjective aspect of probability. In George Wright and Peter Ayton, 
editors, Subjective Probability, pp. 53-73. Wiley, New York, 1994. A philosophical 
examination of the use of probability models as benchmarks or standards to which to 
compare claims of predictive efficacy. The conclusion is that the probabilities in such 
models satisfy neither Bayesian nor frequentist claims about the general meaning of 
probability. 
282. Glenn Shafer. The Art of Causal Conjecture. MIT Press, Cambridge, MA, 1996. 
283. Glenn Shafer. The significance of Jacob Bernoulli’s Ars Conjectandi for the philosophy 
of probability today. Journal of Econometrics, 75: 15-32, 1996. 
284. Glenn Shafer. Mathematical foundations for probability and causality. In Frederick 
Hoffman, editor, Mathematical Aspects of Artificial Intelligence, volume 55 of Symposia 
in Applied Mathematics, pp. 207-270. American Mathematical Society, Providence, RI, 
1998. Develops axiomatically the concepts of an event space, which synthesizes the 
concepts of Boolean algebra and event tree. In an event space, one situation may follow 
another in time (as in an event tree) or merely be more detailed than another (as in a 
Boolean algebra). 
285. Glenn Shafer, Peter R. Gillett, and Richard B. Scherl. Probabilistic logic. Annals of 
Mathematics and Artificial Intelligence, 2000. Provides a more concise axiomatization 
for event trees, which were first axiomatized in [284]. 
286. Robert J. Shiller. Irrational Exuberance. Princeton University Press, Princeton, NJ, 
2000. 
287. Albert N. Shiryaev. Probability. Springer, New York, second edition, 1996. The first 
English edition appeared in 1984. Both editions where translated by R. P. Boas from the 
Russian originals, BepORTHOCTb, published by Nauka in Moscow in 1980 and 1989. 
288. Andrei Shleifer. Ineficient Markets. Oxford University Press, Oxford, 2000. 
289. Anatolii V. Skorohod. Random Processes with Independent Increments. Kluwer, Dor- 
drecht, 1991. Russian original: CnyYaiHbie npoueccbi c H ~ ~ ~ B V I C V I M ~ I M V I  
npMpauew- 
RMVI, Nauka, Moscow, 1986 (second edition). 
290. David E. Smith. A Source Book in Mathematics. McGraw-Hill, New York, 1929. 
291. Marian von Smoluchowski. Zarys kinetycznej teoriji ruchdw browna i roztwordw met- 
nych. Rozprawy i Sprawozdania z Posiedzen’ Wydzialu Matematyczno-Przyrodniczego 

REFERENCES 
393 
Akademii Umiejetnoici, 3:257-282, 1906. A German translation appeared in the Annalen 
der Physik, 21, pp. 756-780 in 1906. 
292. J. Laurie Snell. Gambling, probability, and martingales. Mathematical Intelligencer, 
293. J. Laurie Snell. A conversation with Joe Doob. Statistical Science, 12:301-311, 1997. 
294. Ray J. Solomonoff. A formal theory of inductive inference. parts I and 11. Information 
295. Stephen M. Stigler. The History of Statistics: The Measurement of Uncertainty before 
296. Stephen M. Stigler. Laplace’s 1774 memoir on inverse probability. Statistical Science, 
297. William F. Stout. A martingale analogue of Kolmogorov’s law of the iterated logarithm. 
298. William F. Stout. Almost Sure Convergence. Wiley, New York, 1973. 
299. Daniel W. Stroock and S. R. Sriniva Varadhan. Diffusion processes with continuous 
coefficients, I and 11. Communications in Pure and Applied Mathematics, 22:345-400 
and 479-530, 1969. 
300. Daniel W. Stroock and S. R. Sriniva Varadhan. Multidimensional Diffusion Processes. 
Springer, Berlin, 1979. 
301. S. James Taylor. Exact asymptotic estimates of Brownian path variation. Duke Mathe- 
matical Journal, 39:219-241, 1972. 
302. William M. Thackeray. The Newcomes: Memoirs of a Most Respectable Family. Brad- 
bury and Evans, London, 1853-1855. Monsieur de Florac admonishes Clive, “You have 
not played as yet? Do not do so; above all avoid a martingale, if you do. Play ought not 
to be an affair of calculation, but of inspiration.” (Volume I, Chapter 28, p. 259.) The 
novel appeared in monthly installments starting in 1853 and concluding in 1855. 
303. Isaac Todhunter. A History of the Mathematical Theory of Probability from the Time of 
Pascal to that of Laplace. Macmillan, London, 1865. Extraordinarily dry, Todhunter’s 
History was the authoritative history of early probability theory until Hald’s history 
appeared in 1990. It was reprinted by Chelsea, New York, in 1949 and 1965. 
304. Marco R. Vervoort. Blackwell games. In Thomas Ferguson, Lloyd Shapley, and James 
MacQueen, editors, Statistics, Probability, and Game Theory: Papers in Honor of David 
Blackwell, volume 30 of IMS Lecture Notes-Monograph Series, pp. 369-390. Institute 
of Mathematical Statistics, 1996. 
305. Jean Ville. Sur la thCorie des jeux ou intervient I’habiletC des joueurs. In Application 
aux jeux de hasard [35], pp. 105-113. 
306. Jean Ville. Etude critique de la notion de collectg. Gauthier-Villars, Paris, 1939. This 
differs from Ville’s dissertation, which was defended in March 1939, only in that a 
one-page introduction was replaced by a 17-page introductory chapter. 
307. Jean-AndrC Ville. Sur les suites indiffkrentes. Comptes rendus des Skances de 1 ’Acade‘mie 
des Sciences, 202:1393-1394, 1936. Session of April 27, 1936. 
308. Jean-Andre Ville. Sur la notion de collectif. Comptes rendus des Siances de 1’Acadkmie 
des Sciences, 203:2&27, 1936. Session of July 6, 1936. 
4(3):118-124, 1982. 
and Control, 7: 1-22 and 224-254, 1964. 
1900. Harvard University Press, Cambridge, MA, 1986. 
1:359-378, 1986. 
Zeitschrgt fur Wahrscheinlichkeitstheorie und venvandte Gebiete, 15:279-290, 1970. 

394 
REFERENCES 
309. Richard von Mises. Grundlagen der Wahrscheinlichkeitsrechnung. 
Mathemafische 
3 10. Richard von Mises. Wahrscheinlichkeitsrechnung, Statistik und Wahrheit. Verlag von 
Julius Springer, Wien, 1928. The second edition appeared in 1936 and the third in 1951. 
A posthumous fourth edition, edited by his wife Hilda Geiringer, appeared in 1972. 
English editions, under the title Probability, Statistics and Truth, appeared in 1939 and 
1957. 
3 11. Richard von Mises. Wahrscheinlichkeitsrechnung und ihre Anwendung in der Statistik 
3 12. Richard von Mises. Quelques remarques sur les fondements du calcul des probabilitks. In 
Rolin Wavre, editor, Les fondements du calcul des probabilite's, number 735 in Actualire's 
Scient$ques et Industrielles, pp. 57-66. Hermann, Paris, 1938. In this article, von Mises 
responds to the criticisms aired by Frkhet and others at the 1937 Geneva colloquium. 
Les fondements du calcul des probabilite's is the second fascicle of [338]. 
3 13. Richard von Mises. On the foundations of probability and statistics. Annals of Mathemat- 
ical Statistics, 12: 191-205, 1941. This article originated as an address to the Institute of 
Mathematical Statistics in Hanover, NH, in September 1940. It was published together 
with an article by Doob [98] and comments by von Mises and Doob on each other's 
articles [315]. 
314. Richard von Mises. Selected Papers of Richard von Mises. Volume One: Geometry, 
Mechanics, Analysis. American Mathematical Society, Providence, RI, 1963. Selected 
and edited by Ph. Frank, S. Goldstein, M. Kac, W. Prager, G. Szego, and G. Birkhoff, 
Chairman. 
315. Richard von Mises and Joseph L. Doob. Discussion of papers on probability theory. 
Annals of Mathematical Statistics, 12:215-217, 1941. Discussion of [313] and [98]. 
3 16. John von Neumann. Mathematical Foundations of Quantum Mechanics. Princeton 
University Press, Princeton, NJ, 1955. First German edition: Mathematische Grundlagen 
der Quantenmechanik, Springer, Berlin, 1932. 
317. John von Neumann and Oscar Morgenstern. Theory of Games and Economic Behavior. 
Princeton University Press, Princeton, NJ, third edition, 1953. Previous editions appeared 
in 1944 and 1947. 
3 18. Jan von Plato. Creating Modern Probability: Its Mathematics, Physics, and Philosophy 
in Historical Perspective. Cambridge University Press, Cambridge, 1994. A study of 
the emergence of measure-theoretic probability in the first third of the 20th century. It 
emphasizes statistical physics and includes a detailed look at the foundational work of 
Kolmogorov and de Finetti. 
319. Vladimir G. Vovk. On the concept of the Bernoulli property. Russian Mathematical 
Surveys, 41:247-248, 1986. Studies connections between Kolmogorov's finitary variant 
of von Mises's notion of collective and a more traditional measure-theoretic variant. 
320. Vladimir G. Vovk. The law of the iterated logarithm for random Kolmogorov, or chaotic, 
sequences. Theory of Probability and Its Applications, 32:413-425, 1987. This paper 
gives an algorithmic proof of the law of the iterated logarithm which was adapted to a 
game-theoretic framework in Dawid and Vovk [86]. 
321. Vladimir G. Vovk. Kolmogorov-Stout law of the iterated logarithm. Mathematical Notes, 
44502-507, 1988. A more general version of the proof given in [320]. 
Zeitschrif, 552-99, 1919. 
und theoretischen Physik. F. Deuticke, Leipzig und Wien, 1931. 

REFERENCES 
395 
322. Vladimir G. Vovk. Finitary prequential probability: Asymptotic results. Technical 
report, Institute of New Technologies, Moscow, 1991. Game-theoretic finitary versions 
of strong limit theorems (not in this book). The two examples of $8.4. 
323. Vladimir G. Vovk. Forecasting point and continuous processes: Prequential analysis. 
Test, 2:189-217, 1993. Versions of Theorem 11.1 (p. 278) and Proposition 12.1 (p. 304). 
324. Vladimir G. Vovk. A logic of probability, with applications to the foundations of statistics 
(with discussion). Journal of the Royal Statistical Society. Series B, 55:317-351, 1993. 
This paper argues for basing the theory and applications of probability on the principle of 
impossibility of a gambling system. It proves a variant of Ville’s finitary theorem (p. 195) 
and a prequential (essentially game-theoretic) central limit theorem. 
325. Vladimir G. Vovk. Central limit theorem without probability, June 1995. Bachelier’s 
central limit theorem (Proposition 10.1 on p. 242). 
326. Vladimir G. Vovk. Game-theoretic versions of Kolmogorov’s strong law of large num- 
bers, June 1995. Predictive and finance-theoretic strong law of large numbers (Proposi- 
tion 4.1 on p. 78 and Proposition 15.1 on p. 356). 
327. Vladimir G. Vovk. Pricing European options without probability, June 1995. A version 
of the game-theoretic Black-Scholes formula (Theorem 11.2 on p. 280). 
328. Vladimir G. Vovk. A purely martingale version of Lindeberg’s central limit theorem, 
June 1995. A variant of Theorem 7.1 on p. 153. 
329. Vladimir G. Vovk. A strictly martingale version of Kolmogorov’s strong law of large 
numbers. Theory of Probability and Its Applications, 41:605-608, 1996. A variant of 
Proposition 4.4 on p. 92. 
330. Vladimir G. Vovk. Probability theory for the Brier game. In Proceedings of the Eighth 
International Workshop on Algorithmic Learning Theory, 1997. Accepted for publication 
in Theoretical Computer Science. Limit theorems of probability theory for nonlinear 
protocols (not in this book). 
331. Vladimir G. Vovk. Kolmogorov’s complexity conception of probability. Technical Re- 
port CLRC-TR-00-01, Computer Learning Research Centre, Royal Holloway, University 
of London, January 2000. This report describes one of the sources of the game-theoretic 
approach, Kolmogorov’s algorithmic and finitary approach to the foundations of proba- 
bility. To appear in Proceedings of the 1999 Conference on Statistics: Philosophy, Recent 
History and Relations to Science, Roskilde, Denmark. Synthese Library Series, Kluwer 
Academic Publishers. Editors Vincent F. Hendricks, Stig Andur Pedersen, and Klaus 
Frovin Jargensen. 
332. Vladimir G. Vovk. Black-Scholes formula without stochastic assumptions. Technical 
Report CLRC-TR-00-02, Computer Learning Research Centre, Royal Holloway, Uni- 
versity of London, March 2000. Also in Models for Credit Risk, pp. 149-154. UNICOM 
Seminars, London, May 2000. Nonstochastic Black-Scholes using squares for hedging 
333. Vladimir G. Vovk and Chris J. H. C. Watkins. Universal portfolio selection. In Proceed- 
ings of the Eleventh Annual Conference on Computational Learning Theory, pp. 12-23, 
1998. 
334. Abraham Wald. Die Widerspruchfreiheit des Kollectivbegriffes der Wahrscheinlich- 
keitsrechnung. Ergebnisse eines Mathematischen Kolloquiums, 8:38-72, 1937. This 
journal, or series of publications, reported results from Karl Menger’s famous Vienna 
(5 12.2). 

396 
REFERENCES 
Colloquium. Participants included von Neumann, Morgenstern, and Wald. The eighth 
volume was the last in the series, because the colloquium ended with the Nazi invasion 
of Austria in 1938. In 1939, Menger started a second series in English (Reports of a 
mathematical colloquium), at the University of Notre Dame. 
335. Abraham Wald. Die Widerspruchfreiheit des Kollectivbegriffes. In Rolin Wavre, editor, 
Les fondements du calcul des probabilitis, number 735 in Actualitis Scientijiques et 
Industrielles, pp. 79-99. Hermann, Paris, 1938. This is an abridged version of [334]. Les 
fondements du calcul des probabilitis is the second fascicle of [338]. 
336. Peter Walley. Statistical Reasoning with Imprecise Probabilities. Chapman and Hall, 
London, 199 1. 
337. Christian Walter. Une histoire du concept d'efficience sur les marchis financiers. An- 
nales: Histoire, Sciences Sociales, number 4:873-905, July-August 1996. 
338. Rolin Wavre. Colloque consacri u la the'orie des probabilitks. Hermann, Paris, 1938- 
1939. This celebrated colloquium was held in October 1937 at the University of Geneva, 
as part of a series (Confe'rences internationales des sciences mathimatiques) that began 
in 1933. The colloquium was organized by Rolin Wavre and chaired by Maurice FrCchet. 
Other participants included Cram&, Deblin, Feller, de Finetti, Heisenberg, Hopf, LCvy, 
Neyman, Pdya, Steinhaus, and Wald, and communications were received from Bernstein, 
Cantelli, Glivenko, Jordan, Kolmogorov, von Mises, and Slutsky. The proceedings of the 
colloquium were published by Hermann in eight fascicles of 50 to 100 pages each, in 
their series Actualitis ScientiJques et fndustrielles. The first seven fascicles appeared in 
1938 as numbers 734 through 740 of this series; the eighth appeared in 1939 as number 
766. The second fascicle, entitled Les fondements du calcul des probabilitis, includes 
contributions by Feller, FrCchet, von Mises, and Wald. The eighth fascicle consists of de 
Finetti's summary of the colloquium. 
339. Robert E. Whaley. Derivatives on market volatility: Hedging tools long overdue. Journal 
qfDerivatives, 1:71-84, 1993. 
340. Robert E. Whaley. The investor fear gauge. Journal of Derivatives, 26:12-17, 2000. 
341. Norbert Wiener. The mean of a functional of arbitrary elements. Annals of Mathematics, 
22:66, 1920. 
342. Norbert Wiener. The average of an analytical functional. Proceedings of the National 
Academy of Science, 7:253, 1921. 
343. Norbert Wiener. The average of an analytical functional and the Brownian movement. 
Proceedings of the National Academy of Science, 7:294, 1921. 
344. Norbert Wiener. Differential space. Journal of Mathematics and Physics, 2: 13 1, 1923. 
345. Norbert Wiener. The average value of a functional. Proceedings of the London Mathe- 
matical Society, 22:454, 1924. 
346. Norbert Wiener. Collected Works. MIT Press, Cambridge, MA, 1976-1985. Four 
volumes. Edited by P. Pisani. Volume 1 includes Wiener's original papers on Brownian 
motion [341, 342,343, 344, 3451, with a commentary by Kiyosi It6. 
347. David Williams. Probability with Martingales. Cambridge University Press, Cambridge, 
1991. 
348. Peter M. Williams. Indeterminate probab 
es. In M. Przeleqki, K. Szaniawski, and 
R. Wojcicki, editors, Formal Methods in the Methodology of Empirical Sciences, pp. 
229-246. Ossolineum & Reidel, Wroclaw, 1976. 

REFERENCES 
397 
349. Walter Willinger and Murad S. Taqqu. Pathwise stochastic integration and application to 
the theory of continuous trading. Stochastic Processes and their Applications, 32:253- 
280, 1989. 
350. Walter Willinger and Murad S. Taqqu. Towards a convergence theory for continuous 
351. Paul Wilmott. Derivatives: The Theory and Practice of Financial Engineering. Wiley, 
Chichester, 1998. An engaging and leisurely (739 pages) introduction to the pricing of 
derivatives. 
352. Paul Wilmott, Jeff Dewynne, and Sam Howison. Option Pricing: Mathematical Models 
and Computation. Oxford Financial Press, Oxford, 1993. A readable book aimed at the 
applied mathematician. 
stochastic securities market models. Mathemarical Finance, 15-100, 1991. 
353. Philip Wolfe. The strict determinateness of certain infinite games. Pacijic Journal of 
354. L. C. Young. An inequality of the Holder type, connected with Stiltjes integration. Acta 
355. Ernst Zermelo. Uber eine Anwendung der Mengenlehre auf die Theorie des Schachspiels. 
In E. W. Hobson and A. E. H. Love, editors, Proceedings ofthe Fifth International 
Congress of Mathematicians, volume 11, pp. 501-504. Cambridge University Press, 
Cambridge, 1913. 
356. Vladimir M. Zolotarev. CoepeMeHtiaR Teopm CyMMMpoBaHm ~ e 3 a ~ ~ c ~ ~ t . i ~  
cnyqaR- 
Hbix BenMqMH (The modern theory of summation of independent random variables). 
Nauka, Moscow, 1986. 
Mathematics, 5:841-847, 1955. 
Math., 671251-282, 1936. 

Notation 
A := B: A equals B by definition, 12 
E 
F: material implication, 79 
x . y: dot product, 353 
log: logarithm to the base 2, 253 
8: empty set, 40 
W: the real numbers, 64 
Q: the rational numbers, 85 
N the positive integers, 190, 283 
Z+: 
the nonnegative integers, 303 
AA, := A, - A,-I: previous incre- 
dA, := A,+l -A,: next increment, 132 
ment, 129 
Q: game-theoretic sample space, 9, 148, 
183 
E :  path, 11 
En: initial segment of <, 66 
I<I: length of path <, 183 
E: event, 15 
E E :  indicator variable for E, 15 
EC: complement of E ,  16 
0’: set of all situations, 66, 149, 183 
0: initial situation, 10, 66, 149, 183 
t: situation, 11 
\ti: the length oft, 66 
s C t: s precedes t, 66, 149 
s C t: s strictly precedes t ,  149 
sx: concatenation of s with x, 66 
t i :  next situation towards u, 152 
m,: Forecaster’s move, 70 
wn : Forecaster’s variance move, 77 
f, : Forecaster’s abstract move, 90 
F: Forecaster’s move space, 90 
M,: Skeptic’s move, 64 
V,: Skeptic’s variance move, 77 
sn: Skeptic’s abstract move, 90 
S: Skeptic’s move space, 90 
S t :  Skeptic’s move space in t, 183 
z,: 
Reality’s move, 64 
r,: Reality’s abstract move, 90 
R: Reality’s move space, 90 
Wt: World’s move space in t ,  149, 183 
A: Skeptic’s gain function, 91 
At: Skeptic’s gain function in t, 150, 183 
K,: Skeptic’s capital, 64 
P: strategy for Skeptic, 11, 66, 183 
Kcp: Skeptic’scapital process, 11,67,150, 
184 
A: quadratic supervariation, 91 
403 
Probability and Finance: It’s Only a Game! Glenn Shafer, Vladimir Vovk 
Copyright 0 2001 John Wiley & Sons, Inc. 
ISBN: 0-471-40226-5 

404 
NOTATION 
0: variable identically equal to 0, 14 
Sn: variable from process S, 
149 
P(J): 
Skeptic’s final capital, 11 
Ex: upper price, 12 
- 
Ex: lower price, 13 
Et z: upper price in t, 13, 151, 184 
lfCt z: lower price in t ,  13, 151, 184 
Et z: game-theoretic price in t, 14, 151, 
- 
IE, 2: upper and lower prices in t, 152 
Vx: upper variance, 14, 152 
yx: lower variance, 14, 152 
- 
V x :  game-theoretic variance, 14 
PE: 
upper probability, 15 
- 
PE: lower probability, 15 
- 
PE: upper and lower probability, 121 
Vars: accumulated upper variance, 153 
Var,: accumulated lower variance, 153 
dtS: gain of S 
in t, 152 
- 
- 
184 
- 
- 
- - 
PE: classical probability, 33 
0: measure-theoretic sample space, 40 
7: a-algebra, 40 
P(B): set of all probability measures on 
B, 190, 192,360 
P E: measure-theoretic probability, 40 
P[F 1 El: measure-theoretic conditional 
x: random variable, 41 
E 
2: measure-theoretic expected value, 
42 
V 
2: measure-theoretic variance, 42 
E[z 1 61: measure-theoretic conditional 
expectation, 169 
IE[ylx]: measure-theoretic conditional ex- 
pectation, 42 
V[z I G]: measure-theoretic conditional 
variance, 170 
Et 2: measure-theoretic expected value 
conditional on information at 
time t, 227 
probability, 40 
$J: characteristic function, 31 1 
N&,+: Gaussian distribution, 122 
U: Gaussian smoothing of U, 123 
PD: Poisson distribution, 303 
W :  Wiener process, 205 
Bh: fractional Brownian motion, 2 12 
- 
II: LCvy measure, 312 
p: drift of diffusion process, 206 
a: volatility of diffusion process, 206 
7[0, D]: set of all stopping times, 144 
2: the closure of a set A, 136 
dA: the boundary of a set A ,  136 
B(s, D, 
6): spacehime rectangle, 136 
LM u: the least superparabolic majorant 
LSM u: the least supermarket majorant 
PI: parabolic Poisson integral, 138 
TBU, 138 
5: lower semicontinuous smoothing, 138 
of u, 138 
of u, 331 
varsp: variation spectrum for S, 209 
varN: same as varS,,v, 209 
varg: same as varS,N, 209 
var?’: relative variation spectrum, 259 
Ws: strong variation spectrum, 289 
H ( S ) :  Holder exponent of S, 212 
d i m s :  box dimension of S, 212 
vexS: variation exponent of S, 212 
S: strong variation exponent, 289 
S: underlying security, 201 
1: 
Investor’s capital process, 21 8,344 
I :  Investor’s final capital, 319 
U :  European option, 216 
D: dividend-paying derivative, 222 
0: 
risk-free bond, 295 
R: 
strictly convex option, 298 
- 
EH: strong upper price of option, 3 18 
IE H :  upper price of option, 3 17 
& H :  lower price of option, 3 17 
- 

Index 
p-variation, 209, 274 
n-algebra, 40 
Accumulated variance, 153 
Adapted, 169 
Algebra of sets, 40, 291 
Almost sure price, 344 
Almost surely 
game-theoretic meaning, 17, 61, 82, 90 
in probability protocol, 187 
measure-theoretic meaning, 61 
American option, 217, 317 
Anderson, Oskar (1887-1960) 
Cournot’s bridge, 44 
Anderson, Robert M. (born 1951) 
measure on internal functions, 291 
Approximation theorem, 139 
Arbitrage portfolio, 355 
Arbitrage-free, 233 
At-the-money, 264 
Axiom of dependent choice, 98 
Axiom of determinacy, 97 
Bachelier, Louis (1870-1946) 
behavior of stock-market prices, 203 
central limit theorem, 242 
continuous-time protocol, 278 
with jumps, 3 10 
discrete-time protocol, 240 
dynamic hedging, 60 
Banach space, 118 
Bankruptcy, 218 
Basic payoff, 110 
Bernard, Claude (1813-1878) 
Bernoulli, Jacob (1654-1705) 
determinism, 35 
Ars Conjectandi, 32 
Bernoulli’s theorem, 33-34, 38, 124 
coin tossing, 164 
photograph, 124 
practical certainty, 44, 60 
used Fermat’s and Pascal’s methods, 32 
used Fermat’s and Pascal’s methods, 32 
dependent variables, 54 
revival of probability, 35 
Bertoin, Jean (born 1961) 
ItB’s lemma, 349 
Bertrand, Joseph (1822-1900) 
gambling systems, 49,55 
Bick, Avi (born 1947) 
dynamic hedging without probabilities, 28 1, 349 
Bid-ask spread, 188 
Binary possibility, 24,63 
Binomial distribution, 165 
Binomial tree, 24 
Black-Scholes equation, 221,224 
Black-Scholes formula 
game-theoretic, 224 
publication, 215 
stochastic. 221 
Bernoulli, Nicholas (1687-1759) 
Bernstein, Sergei (1880-1968) 
405 
Probability and Finance: It’s Only a Game! Glenn Shafer, Vladimir Vovk 
Copyright 0 2001 John Wiley & Sons, Inc. 
ISBN: 0-471-40226-5 

with interest, 294 
Black-Scholes model, 25 
Black-Scholes protocol 
basic, 217 
continuous-time, 279 
diffusion, 344-345 
discrete-time, 249 
square, 300 
with constrained variation, 249 
with informal constraints, 223 
Blackwell game, 97 
Black, Fischer (1938-1995) 
Black-Scholes formula, 215 
photograph, 216 
Bodie, Zvi (born 1943) 
insuring long-run stock returns, 37 1 
Boltzmann, Ludwig (1844-1906) 
statistical physics, 35 
Borel, Emile (1871-1956) 
Bore1 u-algebra, 41 
Borel set, 41 
Borel-Cantelli-Ltvy lemma, 88 
continuous probability, 37 
discussion with Reichenbach, 57 
measure theory, 36 
photograph, 37 
quasi-Bore1 set, 96 
resistance to Kolmogorov’s framework, 42 
revival of probability, 35 
strong law, 38, I 1  8 
Boundary, 136 
Bounded forecasting, 70 
bounded-variance, 161 
constant-variance, 159 
finite-horizon, 125, 141 
fixed-variance, 160 
zero forecasts, 65 
Bounded variation, 274 
Bounding capital process, 82 
Bounding strategy, 82 
Box dimension, 21 1 
Boyle, Phelim P. (born 1941) 
discrete hedging, 258 
Brier, Glenn W. (1913-circa 1999) 
weather forecasting, 57 
Britten-Jones, Mark 
remaining variance, 349 
Brownian motion, 205 
definition, 206 
fractional, 2 12, 290 
geometric, 25, 207 
Calibration, 162 
Calvet, Laurent 
Can buy and can sell, 12 
Can force, 65, 187 
ohserved variation spectra, 253 
Cantelli, Francesco (1875-1972) 
Borel-Cantelli-Ltvy lemma, 88 
revival of probability, 35 
bounding, 82 
extension theorem, 195, 291 
Menger’s seminar, 197 
Cauchy, Augustin Louis (1789-1857) 
stable laws, 31 1 
Central limit theorem 
Bachelier’s, 242 
De Moivre’s, 33, 127 
dependent variables, 54 
history, 164 
Laplace’s, 34 
Lindeberg’s, 153 
Lyapunov’s, 162 
name coined by Pblya, 165 
one-sided, 133 
Capital process, 150 
Carathtodory, Constantin ( I  873-1950) 
for securities market, 365 
Certainty, 32 
Chance, 34 
Characteristic function, 3 I 1  
Chebyshev, Pafnutii L. (1821-1894) 
central limit theorem, 165 
revival of probability, 35 
LEAPS, 252 
VIX, 230 
Church, Alonzo (1903-1995) 
collectives, 47 
Closing Market, 353 
Closure, 136 
Coherence, 14, 150, 186 
for market, 322 
Coin tossing, 177 
Collateral duties, 65, 78 
Collective, 43, 46 
Compensator, 85 
Complement, 79 
Complete stopping time, 117 
Comte, Auguste (1798-1857) 
Conditional expectation, 42, 169 
Conditional expected value, 7 1 
Conditional probability, 40 
Chicago Board Options Exchange 
determinism, 35 
game-theoretic interpretation, 179 
notation, 41 
Continuation region, 135 
Continuous nonstandard function, 273,286 
Continuous probability, 35.42 
Continuum hypothesis, 284 
Conventionalism, 37 
Converge in probability, 152 
Copeland Sr., Arthur H. (1 898-1970) 

INDEX 
407 
collectives, 47 
Comers, 136 
cost, 12 
Countable additivity, 41 
Countable saturation, 291 
Cournot’s bridge, 44 
Cournot, Antoine Augustin (1801-1877) 
Cournot’s bridge, 44-45, 56, 60 
gambling systems, 49, 55 
photograph, 44 
probability and chance, 34 
Covariates, 192 
Cox, David R. (born 1924) 
photograph, 192 
regression model, 191 
Cramtr, Harald (1893-1985) 
advocated Kolmogorov’s framework, 39 
Crepel, Pierre (born 1947) 
interview of Ville, 197 
Cross-variation, 258 
Cut, 183 
Cutland, Nigel J. (born 1944) 
Dambis, K. E. 
Davis, Morton 
Dawid, A. Philip (born 1946) 
Anderson’s construction, 292 
change of time, 306 
determinate games, 97 
iterated logarithm, 104 
photograph, 163 
prequential principle, 8 
probability forecasting, 58, 164 
De Finetti, Bruno (19061985) 
conditional probability, 42 
emphasis on price, 60 
infinitely divisible laws, 312 
neosubjectivism, 5 
neosubjectivists, 59 
opposition to Kolmogorov, 45 
photograph, 59 
De Moivre, Abraham (1667-1754) 
coin tossing, 126, 164 
De Moivre’s theorem, 33, 127 
photograph, 127 
sharpened Bernoulli’s theorem, 33 
used Fermat’s and Pascal’s methods, 32 
Decision analysis, 21 
Delta, 221 
Derivative security, 2 16 
strictly convex, 302 
variance derivative, 202 
Determinism, 33-34 
Diffusion 
as continuous Levy process, 316 
equation, 129,221 
game-theoretic process, 338 
process, 206 
protocol, 337-338 
term (for semimartingale), 315 
Doeblin, Wolfgang (1915-1940) 
seminar with Ville, 198 
Doob, Joseph L. (born 1910) 
advocated Kolmogorov’s framework, 39 
debate with von Mises, 45 
defined martingale, 55 
gambling systems, 55 
inequality, 56, 196 
martingale convergence theorem, 81, 84, 172 
measure-theoretic martingales, 54 
photograph, 45, 134 
reviewed Ville’s book, 54 
Dot product, 353 
Drift 
diffusion process, 206 
term (for semimartingale), 3 15 
Dubins, Lester E. (born 1927) 
change of time, 306 
conservation of fairness, 56 
Dynamic hedging, 2,4 
Earlier notation for conditional probability 
Edwards, A. W. F. (born 1935) 
work on Pascal, 32 
Efficient markets, 228 
Efficient score, 194 
Efficient-market hypothesis, 6, 351 
( ~ A ( B ) ) .  
41 
game-theoretic nature, 228 
many tests, 351 
value at risk, 373 
with options, 371 
Efficient-markets hypothesis, 6,229 
Einstein, Albert (1879-1955) 
Brownian motion, 204 
Emanuel, David 
discrete hedging, 258 
Empirical volatility, 368 
Empiricism, 34 
Equivalent martingale measure, 348 
Equivalent portfolios, 355 
European call, 216 
European option, 216 
Event, 40,67,90, 169 
game-theoretic definition, 11 
unbounded forecasting, 8 1 
Exercise region, 135 
Expected value, 14,42 
Experiment, 40 
External object, 291 
Faber, Georg (1877-1966) 
Failure model, 192 
Fair-coin game, 64 
proof of Borel’s strong law, 38 

408 
INDEX 
Feller, William (1906-1970) 
advocated Kolmogorov’s framework, 39 
iterated logarithm, 119 
Lindeberg’s theorem, 166 
Fermat, Pierre de (1601-1665) 
correspondence with Pascal, 30 
Field of sets, 40 
Filter, 283 
Filtered measurable space, 169 
Filtered probability space, 169 
Filtration, 169 
Financial instrument, 321 
passive, 322 
Finite, 284 
Fisher, Adlai (born 1969) 
Folk stochasticism, 21 
Follows game-theoretic differential equation, 
Forcing, 65 
observed variation spectra, 253 
in probability protocol, 90, 187 
in unbounded forecasting, 79 
weak, 68 
as part of World, 7 
move space, 90 
Forecasting game 
bounded, 65 
unbounded, 77 
Forecasting protocol 
bounded and finite-horizon, 133 
predictably unbounded, 102 
simplified predictably unbounded, 103 
unbounded upper, 89 
unbounded, 79 
heat equation, 129 
photograph, 129 
Fiillmer, Hans (born 1941) 
pathwise integral, 349 
Fractional Brownian motion, 212, 290 
Frequency 
Forecaster 
Fourier, Joseph B. (1768-1830) 
Jacob Bernoulli, 33 
nineteenth century, 34 
relative, 18 
Richard von Mises, 46 
Kolmogorov’s, 43 
von Mises’s, 46 
advocated Kolmogorov’s framework, 39 
gambling systems, 55 
Geneva contribution, 39, 45 
measure theory, 36 
market, 332 
nonstandard, 273 
Frequentism 
Frtchet, Maurice (1878-1973) 
Function 
regulated, 290 
smooth, 127 
standard, 273 
strictly convex, 302 
submarket, 332 
supermarket, 331 
superparabolic, 137 
smooth, 139 
Fundamental interpretative hypothesis, 5 ,  14 
finitary, 15 
infinitary, 15 
in Kolmogorov, 43 
outside mathematics, 62 
function, 150, 183 
constant, 90 
process, 152 
determinate games, 97 
compared with market protocol, 319 
impossibility of, 2 
market, 20 
Blackwell, 97 
determined, 96 
of belief, 19 
of statistical regularity, 19 
probability, 9, 185 
securities market, 353 
terminating, 10 
tree, 96 
upper forecasting, 72 
for diffusion process, 338 
for drift and volatility, 336 
for volatility, 336 
GARCH model, 230 
Gauss, Carl Friedrich (1777-1 855) 
Gaussian distribution, 143, 165 
Geometric Brownian motion, 25, 207 
Girsanov, Igor V. (died 1967) 
Girsanov’s theorem, 235 
Gnedenko, Boris (1912-1995) 
history of stable laws, 31 1 
infinite divisibility, 313 
Governed by, game-theoretic meaning, 182, 338 
Godel, Kurt (1906-1978) 
Menger’s seminar, 197 
Greatest lower semicontinuous minorant, 138 
Hardy, Godfrey H. (1877-1947) 
Hausdorff, Felix (1868-1942) 
Gain 
338 
Gale, David 
Gambling protocol 
Gambling system 
Game 
Game-theoretic differential equation 
strong law, 119 
probability notation, 41 
strong law, I18 

lNDEX 
409 
Heat equation, 128, 130,221 
Hedging 
delta, 221 
dynamic, 4 
in the mean, 24 
upper and lower prices, 13 
vega, 229 
Hilbert, David (1862-1943) 
mathematical problems, 35 
philosophy of mathematics, 45 
Historic volatility, 229 
Holtzmark distribution, 312 
Horizon 
Horse races, 359 
Holder, Ludwig Otto (1859-1937) 
Holder exponent, 21 1 
in continuous time, 214 
Holder’s inequality, 245 
Huygens, Christiaan (1629-1695) 
simplified Pascal’s argument, 3 1 
Hyperreal number, 272,284 
Implied volatility, 229 
Impossibility 
finite or infinite, 10 
of a gambling system, 2 
practical, 17 
Independence, 40 
Indicator variable, 15 
Inequality 
Holder’s, 245 
Jensen’s, 245 
Infinitely divisible law, 312 
Infinitely large, 284 
Infinitesimal, 284 
Initial situation, 66 
Integral, 340 
Interest rate 
nonzero, 294 
zero, 5 
Internal measure, 291 
Internal object, 290 
Intrinsic move, 322 
Intrinsic strategy, 322 
Investor 
as Player I, 4, 217 
Ionescu-Tulcea, Cassius (born 1923) 
Ionescu-Tulcea’s theorem, 181 
Iowa Electronic Markets, 71 
It6, Kiyosi (born 1915) 
It6 processes, 206 
lemma, 232,340 
photograph, 23 1 
Jensen’s inequality, 245 
Joint hypothesis problem, 228 
Jordan, Camille (1838-1922) 
measure theory, 36 
Jumps in price processes, 303 
Kawada, Takayuki 
Kelvin (William Thomson 18261907) 
Khinchin, Aleksandr (1894-1959) 
strong variation exponent, 290 
statistical physics, 35 
definition of stable law, 3 11 
iterated logarithm, 99, 119 
LCvy-Khinchin formula, 312 
photograph, 99 
Klingenhofer, Frank 
pathwise stochastic integration, 349 
Kollektiv, 46 
Kolmogorov, Andrei N. (1903-1987) 
axioms, 40 
counterexample to strong law, 88 
Grundbegriffe, 39, 45 
infinitely divisible laws, 312 
iterated logarithm, 99, 119 
Kolmogorov complexity, 46, 50 
philosophy of probability, 43 
photograph, 39, 75 
probability before, 30 
sixth axiom, 41 
strong law, 75 
strong variation exponent, 290 
gambling systems, 49 
martingales, 51 
Gaussian distribution, 165 
heat equation, 129 
photograph, 165 
ThCorie analytique des prohabilit& 33 
Lateral boundary, 136 
Law of iterated expectation, 185 
Law of large numbers, 33 
K6no, Norio (born 1940) 
Lacroix, Sylvestre FranGois (1765-1843) 
Laplace, Pierre Simon (1749-1827) 
strong, 66 
weak, 38 
for a securities market, 356 
for a securities market, 364 
Law of the iterated logarithm, 38, 99 
for a securities market, 363 
fuzzy, 364 
sharpness, 100, 102 
validity, 100, 102 
LEAPS, 252 
Least supermarket majorant, 33 1 
Least superparabolic majorant, 138 
Lebesgue, Henri (I 875-1941) 
Lebesgue u-algebra, 41 
Lebesgue set, 41 
measure theory, 36 
Leibniz, Gottfried Wilhelm (1646-1716) 
differentiation rule for integrals, 129 

410 
INDEX 
Lepingle, Dominique (born 1943) 
strong variation, 290 
LCvy, Paul (1886-1971) 
abstract probability, 38 
Borel-Cantelli-Ltvy lemma, 88 
continuous Levy process, 3 16 
Cournot’s bridge, 44-45, 60 
dependent variables, 54 
formula, 3 12 
infinitely divisible laws, 312 
LCvy measure, 3 I2 
LCvy process, 313 
LCvy-Khinchin formula, 312 
Lindeberg’s theorem, 166 
photograph, 54 
resistance to Kolmogorov’s framework, 42 
revival of probability, 35 
stable laws, 3 11 
stable LCvy process, 3 15 
LIFFE, 264 
Likelihood, 192 
partial, 192 
Lindeberg, Jar1 Waldemar (1 876-1932) 
condition, 153 
method of proof, 131, 165 
photograph, 147 
protocol, 148 
theorem, 153 
Lipschitzian function 
definition, 244 
Liptser, Robert S. (born 1936) 
Kolmogorov’s strong law, 84 
Littlewood, John E. (1885-1977) 
strong law, 119 
Loeb, Peter A. (born 1937) 
Loeb measure, 291 
Log-Gaussian model, 207 
Log-likelihood, 192 
Log-Lipschitzian, 260 
Long-term options, 252 
Lower boundary, 136 
Lower price, 13, 151 
Lower probability, 15 
Lower semicontinuous smoothing, 138 
Lower variance, 14, 152 
Lyapunov, Alexander (1857-1918) 
central limit theorem, 162, 165 
condition, 162 
LoS, Jerzy (born 1920) 
ultraproduct, 286 
Mandelbrot, Benoit (born 1924) 
alternatives to the normal, 208 
observed variation spectra, 253 
photograph, 207 
Manipulation, 226 
partial, 192 
Market portfolio, 355 
Market unit, 352 
Market Volatility Index (VIX), 230 
Market 
Market 
as Player II,4, 217 
function, 332 
game, 20 
move, 322 
price of risk, 236 
protocol, 3 19 
central limit theorem, 165 
dependent variables, 54 
revival of probability, 35 
Markowitz, Harry (born 1927) 
portfolio selection, 199 
Martin’s theorem, 76,88,94, 96 
Martin-Lof, Per (born 1942) 
collectives, 48 
random sequences, 50 
approximate, 129 
bounded forecasting, 67 
convergence theorem, 81 
gambling system, 51 
game-theoretic definition, 53, 91, 188 
measure-theoretic definition, 55, 170 
scaled, 174 
strong law of large numbers, 90 
transformation, 173 
Ville’s definition, 52 
witnessing, 173 
Blackwell games, 97 
determinate games, 96 
photograph, 94 
Material implication, 79 
Maxwell, James Clerk (1831-1879) 
statistical physics, 35 
Measurable, I69 
Measure 
internal, 291 
Loeb, 291 
nonstandard, 291 
probability, 41 
zero, 36 
Measure theory 
advent of, 35 
equally likely cases, 34 
foundation for probability, 39 
Measuring instruments 
ideal and of the first kind, I90 
Menger, Karl (1902-1985) 
seminar, 197 
Mercurio, Fabio 
Markov, Andrei A. (1856-1922) 
Martingale, 51 
Martin, Donald A. (born 1940) 

INDEX 
41 I 
discrete hedging, 258 
Merton, Robert C. (born 1944) 
Black-Scholes formula, 215 
dynamic hedging, 60 
photograph, 293 
change of time, 306 
general theory of stochastic processes, 315 
Mikosch, Thomas (born 1955) 
pathwise stochastic integration, 349 
Mill, John Stuart (1806-1873) 
probability = frequency, 34 
Modulus of continuity, 140 
Montmort, Pierre de (1678-1719) 
Most, 283 
Mutual funds 
Meyer, Paul-Andre (born 1934) 
used Fermat’s and Pascal’s methods, 32 
success over time, 365 
tracking, 358 
Natural numbers, 283 
Neuberger, Anthony (born 1951) 
Neutral forecasting strategy, 178 
Nonstandard analysis, 26 
Nonstandard function, 273 
continuous, 273,286 
relatively continuous, 275, 286 
strictly positive, 275 
Nonstandard measure, 29 1 
Nonstandard number, 272 
NorvaiSa, Rimas (born 1956) 
Number 
remaining variance, 349 
pathwise stochastic integration, 349 
hyperreal, 272,284 
nonstandard, 272 
Numkraire. 6 
Open interest, 371 
Opening Market, 353 
Option, 23 
American, 3 17 
European, 216 
exotic, 323 
long-term, 252 
passive, 322 
Optional quadratic variation, 340 
Oracular prices, 256 
Osborne, M. F. Maury (born 1916) 
log-Gaussian model, 207 
Papangelou, Fredos (born 1939) 
change of time, 306 
Parabolic equation, 221 
Parabolic function, 138 
Parabolic fundamental convergence theorem, 139 
Parabolic measure, 136 
Parabolic Poisson integral, 138 
Paris, Jeff (born 1941) 
determinate games, 97 
Partial log-likelihood, 192 
Pascal, Blaise (1623-1662) 
dynamic hedging, 30, 60 
photograph, 30 
Passive financial instrument, 322 
Path, 9,66,90, 149, 183 
begin, 66 
for market protocol, 319 
go through situation, 149 
in game tree, 96 
unbounded forecasting, 81 
basic, 110 
market protocol, 319 
of martingale, 110 
Payoff 
Perfect set, 98 
Perfect trader option, 323 
Poincare, Henri (1854-1912) 
revival of probability, 35 
three body problem, 36 
Poisson distribution, 303 
Poisson integral, 142 
protocol, 304, 306 
subjective and objective probability, 34 
collectives, 47 
propensities, 22 
Port Royal Logic, 32 
Portfolio 
Poisson, Sirneon-Denis (1781-1840) 
Popper, Karl (1902-1994) 
arbitrage, 355 
equivalent, 355 
Possibility, 33 
Potentiality, 46 
Pblya, Georg (1887-1985) 
Practical certainty and impossibility 
Predictable process, 169 
Predictable quadratic variation, 340 
Predictable, 169 
Predictably unbounded forecasting protocol, 102 
Prequential principle, 8, 58 
Price, 14 
central limit theorem, 165 
game-theoretic meaning, 17 
almost sure, 344 
exact, 14, 151, 184 
in situation, 151 
lower, 13, 151, 184 
strong, 328 
upper, 12, 151, 184 
weak, 328 
classical, 33 
conditional, 42 
distribution, 41 
Probability 

412 
INDEX 
positive, 178 
stable, 31 1 
game, 9, 185 
finite or infinite horizon, 10 
game-theoretic, 16 
lower, 15, 152, 186 
measure, 41 
equivalent, 233 
measure-theoretic, 40 
modem, 35 
objective and subjective, 19, 34 
protocol, 9, 185 
constant move spaces, 90 
symmetric, 11, 187 
filtered, 169 
space, 169 
upper, 15, 152, 186 
bounded forecasting, 66 
increasing, 82 
measure-theoretic, 169 
partial, 149 
predictable, 81, 169 
unbounded forecasting, 81 
Process 
Propensity, 22 
Protocol 
binary probability forecasting, 177 
coin-tossing, 178 
Black-Scholes, 217 
diffusion. 337-338 
fair-coin, 127 
Lindeberg, 148 
Lyapunov’s, 162 
market, 319 
Poisson, 304, 306 
probability, 9, 90, 185 
securities market, 353 
Quadratic supervariation, 91 
Quadratic variation, 91, 338 
abstract, 360 
optional, 340 
predictable, 340 
game-theoretic, 118, 174 
measure-theoretic, 176 
Quantum mechanics 
as a game, 190 
challenge to determinism, 8 
fundamental interpretative hypothesis, 20 
open system, 7 
Quasi-Bore1 set, 96 
Radon, Johann (1887-1956) 
measure theory, 36 
Radon-Nikodym theorem, 42 
adapted sequence, 169 
definition, 10, 41, 169 
Random variable 
predictable sequence, 169 
as part of World, 7 
move space, 90 
strategy, 76, 87 
Reality 
Regulated function, 290 
Reichenbach, Hans (1891-1953) 
collectives, 47 
discussion with Borel, 57 
Relative frequency, 18 
Relative variation exponent, 275 
Relative variation sprectrum, 259 
Relatively continuous nonstandard function, 286 
Relatively continuous, 275 
Return on capital, 368 
RCnyi, AlfrCd (1921-1970) 
conditional probability, 42 
Riemann, Bernhard (1826-1866) 
integration, 36 
Risk vs. return, 367 
Risk-adjusted probability, 348 
Risk-free bond, 295 
Risk-neutral probability, 348 
Risk-neutral valuation, 233, 348 
Robinson, Abraham (1918-1974) 
life, 283 
nonstandard analysis, 26, 283 
photograph, 271 
bounded forecasting, 66 
for market protocol, 319 
measure-theoretic, 40 
probability game, 9 
efficient markets, 227 
photograph, 351 
Saturation theorem, 291 
Savage, Leonard J. (1917-1971) 
conservation of fairness, 56 
Schal, Manfred 
discrete hedging, 258 
Scholes, Myron (born 1941) 
Black-Scholes formula, 215 
photograph, 237 
Schwarz, Gideon 
change of time, 306 
Schweizer, Martin (born 1961) 
discrete hedging, 258 
Scrap value, 13 
Securities market protocol 
abstract, 360 
Security 
derivative, 23 
Semimartingale 
game-theoretic, 85 
stochastic, 315 
Sample space 
Samuelson, Paul A. (born 1915) 

INDEX 
413 
Simulating transactions, 12 
Situation, 10, 90, 183 
hounded forecasting, 66 
child, 149 
divergent, 66 
final, 149 
follow, 149 
in market protocol, 319 
initial, 10, 149, 183 
on path, 149 
parent, 91, 149 
precede, 66, 149 
strictly follow, 149 
strictly precede, 149 
terminal, 10 
unbounded forecasting, 8 1 
gain function, 150, 183 
goal, 90 
move space, 90, 150, 183 
name for Player I, 4 
real and imaginary, 352,355 
strategy, 66, 76, 81 
Skorohod, Anatolii V. (born 1930) 
independent increments, 314 
Smoluchowski, Marian von (1872-1917) 
Brownian motion, 204 
Smooth function, 127 
Solomonoff, Ray J. (born 1926) 
inductive inference, 50 
Square as derivative, 299 
Stable law 
Skeptic 
characteristic exponent, 31 1 
definition, 31 1 
tails, 312 
Standard function, 273 
Standard part, 284 
Standard, 272 
Statistical modeling, 21 
Statistical physics, 35 
Steinhaus, Hugo (1887-1966) 
revival of probability, 35 
Stewart, F. M. 
determinate games, 97 
Stochastic calculus, 206 
Stochastic differential equation, 206, 335 
Stochastic function, 274 
Stochastic integral, 340 
Stochastic process, 18 
Stochastic volatility, 230 
Stochasticism, 21 
Stopping time, 108, 169 
complete, 117 
Stout, William F. (born 1940) 
iterated logarithm, 99, 173 
Strategy, 66 
beginning in situation, 150 
Bore1 measurable, 170 
hounding, 82 
Forecaster’s, 178 
intrinsic, 322 
Investor’s in market protocol, 319 
market, 322 
Reality, 87 
Skeptic’s, 11, 81, 150, 183 
Strictly convex function, 302 
Strike price, 216 
Strong law of large numbers 
bounded, 61 
finance-theoretic, 356 
for martingales, 90 
fuzzy, 362 
Kolmogorov’s, 75 
Strong price, 328 
Strong upper price, 328 
Strong variation, 289 
Stroock, Daniel W. (born 1940) 
weak solution, 347 
Submarket function, 332 
Subparabolic, 138 
Substochastic function, 21 1, 274 
Super-replicate 
strongly, 325 
weakly, 324 
Super-replication game, 325-327 
Superior intelligence, 8,34 
Supermarket function, 331 
Supermartingale 
game-theoretic definition, 82, 184 
witnessing, 83 
smooth, 139 
Superparabolic function, 137 
Superstochastic function, 274 
Supervariation, quadratic, 91 
Symmetric probability protocol, 11 
Taqqu, Murad S. (born 1942) 
pathwise stochastic integration, 349 
Taylor, S. James (horn 1929) 
strong variation, 290 
Ternary possibility, 24 
Tobin, James (born 1918) 
portfolio selection, 199 
Topology, 96 
Transfer principle, 26, 286 
Tree 
binomial, 24 
game, 96 
of World’s moves, 10, 148, 183 
Trend, 338 
Turing, Alan M. (1912-1954) 
Ultrafilter, 283 
universal computing machine, 48 

414 
INDEX 
nontrivial, 283 
Upper boundary, 136 
Upper price, 12, 151 
strong, 328 
weak, 328 
Upper probability, 15 
Upper variance, 14, 80, 152 
Value at risk, 373 
Varadhan, S. R. Sriniva (born 1940) 
Variable, 66 
weak solution, 347 
for market protocol, 319 
game-theoretic definition, 10 
indicator, 15 
partial, 149 
unbounded forecasting, 81 
accumulated, 153 
derivative, 202 
game-theoretic, 14, 152 
lower, 14, 152 
measure-theoretic, 42 
of diffusion process, 206 
upper, 14, 152 
Variation spectrum 
relative, 259 
Variation 
exponent, 21 1 
Variance 
continuous-time, 274 
relative, 275 
quadratic, 91, 176 
game-theoretic, 118 
relative, 27.5 
spectrum, 209 
continuous-time, 274 
relative, 275 
strong, 289 
Venn, John (1834-1923) 
probability = frequency, 34 
Ville, Jean (1 9 10-1 988) 
collectives, 48 
counterexample, 18 
.!?‘rude critique de la notion de collectif, 
gambling systems, 60 
iterated logarithm, 104 
life and times, 197 
martingales, 52 
minimax theorem, 198 
photograph, 1, 197 
Ville’s theorem, 52, 194 
VIX, 230 
Volatility of diffusion process, 206 
Volatility surface, 230 
Volatility 
historic, 229 
implied, 229 
stochastic, 230 
collectives, 46 
debate with Doob, 45 
frequentism, 18 
gambling systems, 60 
in opposition to Kolmogorov, 45 
interpretation of probability, 43 
Kolmogorov’s agreement, 50 
life and times, 46 
photograph, 46 
resistance to Ville’s example, 49 
Von Neumann, John (1903-1957) 
minimax theorem, 97, 198 
photograph, 190 
quantum mechanics, 189 
Van Plato, Jan (born 1951) 
modern probability, 35 
Vorst, Ton C. F. (born 1952) 
discrete hedging, 258 
Wald, Abraham (1902-1950) 
collectives, 47 
Menger’s seminar, 197 
upper and lower price, 59 
Von Mises, Richard (1883-1957) 
Walley, Peter 
Weak price, 328 
Weak upper price, 328 
Weather derivative, 303, 306 
Weather forecasting, 21, 162 
Whaley, Robert E. (born 1953) 
Wiener, Norbert (1894-1964) 
implied volatility, 230 
Brownian motion, 205 
photograph, 204 
Wiener process, 205 
Williams, Peter M. (born 1944) 
upper and lower price, 59 
Willinger, Walter (born 1956) 
dynamic hedging without probabilities, 281, 349 
pathwise stochastic integration, 349 
Wilmott, Paul (born 1959) 
Witness, 83, 173 
Wolfe, Philip (born 1927) 
determinate games, 97 
World 
divided into Forecaster and Reality, 90 
divided into several players, 7 
move space, 183 
name for Player II,4 
ZShle, Martina (born 1950) 
pathwise stochastic integration, 349 
Zermelo, Ernst (1871-1853) 
determinate games, 94 
198 
discrete hedging, 258 

