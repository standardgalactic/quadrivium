Encyclopedia of  
Complexity and Systems Science Series
Editor-in-Chief: Robert A. Meyers
Statistical and 
Nonlinear Physics
Bulbul Chakraborty
Editor
A Volume in the Encyclopedia of
Complexity and Systems Science,
Second Edition

Encyclopedia of Complexity and
Systems Science Series
Editor-in-Chief
Robert A. Meyers

The Encyclopedia of Complexity and Systems Science series of topical vol-
umes provides an authoritative source for understanding and applying the
concepts of complexity theory, together with the tools and measures for
analyzing complex systems in all ﬁelds of science and engineering. Many
phenomena at all scales in science and engineering have the characteristics of
complex systems, and can be fully understood only through the transdisciplin-
ary perspectives, theories, and tools of self-organization, synergetics, dynam-
ical systems, turbulence, catastrophes, instabilities, nonlinearity, stochastic
processes, chaos, neural networks, cellular automata, adaptive systems,
genetic algorithms, and so on. Examples of near-term problems and major
unknowns that can be approached through complexity and systems science
include: The structure, history and future of the universe; the biological basis
of consciousness; the integration of genomics, proteomics and bioinformatics
as systems biology; human longevity limits; the limits of computing; sustain-
ability of human societies and life on earth; predictability, dynamics and extent
of earthquakes, hurricanes, tsunamis, and other natural disasters; the dynamics
of turbulent ﬂows; lasers or ﬂuids in physics, microprocessor design; macro-
molecular assembly in chemistry and biophysics; brain functions in cognitive
neuroscience; climate change; ecosystem management; trafﬁc management;
and business cycles. All these seemingly diverse kinds of phenomena and
structure formation have a number of important features and underlying
structures in common. These deep structural similarities can be exploited to
transfer analytical methods and understanding from one ﬁeld to another. This
unique work will extend the inﬂuence of complexity and system science to a
much wider audience than has been possible to date.
More information about this series at https://link.springer.com/bookseries/15581

Bulbul Chakraborty
Editor
Statistical and Nonlinear
Physics
A Volume in the Encyclopedia of Complexity
and Systems Science, Second Edition
With 300 Figures and 10 Tables

Editor
Bulbul Chakraborty
Department of Physics
Brandeis University
Waltham, MA, USA
ISBN 978-1-0716-1453-2
ISBN 978-1-0716-1454-9 (eBook)
https://doi.org/10.1007/978-1-0716-1454-9
© Springer Science+Business Media, LLC, part of Springer Nature 2022
This work is subject to copyright. All rights are reserved by the Publisher, whether the whole or
part of the material is concerned, speciﬁcally the rights of translation, reprinting, reuse of
illustrations, recitation, broadcasting, reproduction on microﬁlms or in any other physical way,
and transmission or information storage and retrieval, electronic adaptation, computer software, or
by similar or dissimilar methodology now known or hereafter developed.
The use of general descriptive names, registered names, trademarks, service marks, etc. in this
publication does not imply, even in the absence of a speciﬁc statement, that such names are exempt
from the relevant protective laws and regulations and therefore free for general use.
The publisher, the authors, and the editors are safe to assume that the advice and information in this
book are believed to be true and accurate at the date of publication. Neither the publisher nor the
authors or the editors give a warranty, expressed or implied, with respect to the material contained
herein or for any errors or omissions that may have been made. The publisher remains neutral with
regard to jurisdictional claims in published maps and institutional afﬁliations.
This Springer imprint is published by the registered company Springer Science+Business Media,
LLC part of Springer Nature.
The registered company address is: 1 New York Plaza, New York, NY 10004, U.S.A.

Series Preface
The Encyclopedia of Complexity and System Science Series is a multivolume
authoritative source for understanding and applying the basic tenets of com-
plexity and systems theory as well as the tools and measures for analyzing
complex systems in science, engineering, and many areas of social, ﬁnancial,
and business interactions. It is written for an audience of advanced university
undergraduate and graduate students, professors, and professionals in a wide
range of ﬁelds who must manage complexity on scales ranging from the
atomic and molecular to the societal and global.
Complex systems are systems that comprise many interacting parts with the
ability to generate a new quality of collective behavior through selforganization,
e.g., the spontaneous formation of temporal, spatial, or functional structures.
They are therefore adaptive as they evolve and may contain self-driving feed-
back loops. Thus, complex systems are much more than a sum of their parts.
Complex systems are often characterized as having extreme sensitivity to initial
conditions as well as emergent behavior that are not readily predictable or even
completely deterministic. The conclusion is that a reductionist (bottom-up)
approach is often an incomplete description of a phenomenon.
This recognition that the collective behavior of the whole system cannot be
simply inferred from the understanding of the behavior of the individual
components has led to many new concepts and sophisticated mathematical
and modeling tools for application to many scientiﬁc, engineering, and societal
issues that can be adequately described only in terms of complexity and
complex systems.
Examples of Grand Scientiﬁc Challenges which can be approached through
complexity and systems science include: the structure, history, and future of the
universe; the biological basis of consciousness; the true complexity of the
genetic makeup and molecular functioning of humans (genetics and epigenetics)
and other life forms; human longevity limits; uniﬁcation of the laws of physics;
the dynamics and extent of climate change and the effects of climate change;
extending the boundaries of and understanding the theoretical limits of comput-
ing; sustainability of life on the earth; workings of the interior of the earth;
predictability, dynamics, and extent of earthquakes, tsunamis, and other natural
disasters; dynamics of turbulent ﬂows and the motion of granular materials; the
structure of atoms as expressed in the Standard Model and the formulation of the
Standard Model and gravity into a Uniﬁed Theory; the structure of water; control
of global infectious diseases; and also evolution and quantiﬁcation of
v

(ultimately) human cooperative behavior in politics, economics, business sys-
tems, and social interactions. In fact, most of these issues have identiﬁed non-
linearities and are beginning to be addressed with nonlinear techniques, e.g.,
human longevity limits, the Standard Model, climate change, earthquake pre-
diction, workings of the earth’s interior, natural disaster prediction, etc.
The individual complex systems mathematical and modeling tools and
scientiﬁc and engineering applications that comprised the Encyclopedia of
Complexity and Systems Science are being completely updated and the major-
ity will be published as individual books edited by experts in each ﬁeld who are
eminent university faculty members.
The topics are as follows:
Agent Based Modeling and Simulation
Applications of Physics and Mathematics to Social Science
Cellular Automata, Mathematical Basis of
Chaos and Complexity in Astrophysics
Climate Modeling, Global Warming, and Weather Prediction
Complex Networks and Graph Theory
Complexity and Nonlinearity in Autonomous Robotics
Complexity in Computational Chemistry
Complexity in Earthquakes, Tsunamis, and Volcanoes, and Forecasting and
Early Warning of Their Hazards
Computational and Theoretical Nanoscience
Control and Dynamical Systems
Data Mining and Knowledge Discovery
Ecological Complexity
Ergodic Theory
Finance and Econometrics
Fractals and Multifractals
Game Theory
Granular Computing
Intelligent Systems
Nonlinear Ordinary Differential Equations and Dynamical Systems
Nonlinear Partial Differential Equations
Percolation
Perturbation Theory
Probability and Statistics in Complex Systems
Quantum Information Science
Social Network Analysis
Soft Computing
Solitons
Statistical and Nonlinear Physics
Synergetics
System Dynamics
Systems Biology
Each entry in each of the Series books was selected and peer reviews
organized by one of our university-based book Editors with advice and
consultation provided by our eminent Board Members and the Editor-in-Chief.
vi
Series Preface

This level of coordination assures that the reader can have a level of
conﬁdence in the relevance and accuracy of the information far exceeding
than that generally found on the World Wide Web. Accessibility is also a
priority and for this reason each entry includes a glossary of important terms
and a concise deﬁnition of the subject. In addition, we are pleased that the
mathematical portions of our Encyclopedia have been selected by Math
Reviews for indexing in MathSciNet. Also, ACM, the world’s largest educa-
tional and scientiﬁc computing society, recognized our Computational Com-
plexity: Theory, Techniques, and Applications book, which contains content
taken exclusively from the Encyclopedia of Complexity and Systems Science,
with an award as one of the notable Computer Science publications. Clearly,
we have achieved prominence at a level beyond our expectations, but consis-
tent with the high quality of the content!
Palm Desert, CA, USA
Robert A. Meyers
June 2022
Editor-in-Chief
Series Preface
vii

Volume Preface
The ﬁeld of statistical and nonlinear physics combines the exceedingly pow-
erful machinery of statistical mechanics with that of nonlinear dynamics to
create a highly interdisciplinary and exciting area of research. Rooted in
equilibrium statistical physics, the ﬁeld has evolved to encompass and empha-
size the emergence of collective behavior in systems that are near and very far
from equilibrium. It is a ﬁeld in rapid evolution, with a constantly changing
focus and a rapidly expanding realm of application.
This volume provides a modern perspective on statistical and nonlinear
physics. At the heart of this subject is the exploration of collective behavior
that emerges from the interactions of a large number of entities ranging from
the atomic scale to objects that are macroscopic in size such as ﬂocks of birds.
The phenomena that emerge at scales involving a multitude of interacting
objects are far richer than that of a few. A fundamental idea that anchors the
ﬁeld is that thermal motion allows the exploration of a free-energy landscape,
even in systems that are driven out of equilibrium, or whose dynamics become
arrested. Recent research has uncovered phenomena where this paradigm is
violated strongly, and new paradigms have begun to emerge. The chapters in
this volume cover both the classical and the newly emerging ideas that are
continually propelling the ﬁeld in new directions.
Rigidity and ﬂow in disordered solids such as glasses, gels, and frictional
granular materials is a signiﬁcant focus of this second edition. Primarily
because this area has experienced a paradigm shift in recent years. This volume
also highlights recent developments in systems with extremely complex ﬂows
such as those encountered in the atmosphere or ﬂows in geometries that
constrict the motion severely. The application of statistical and nonlinear
physics to complex networks has also been covered in this volume. These
newer subjects appear side by side with core areas of the ﬁeld in order to
provide the reader with a comprehensive picture of the current status of the
ﬁeld.
The editor wishes to thank all the authors for their generosity in providing
valuable and timely contributions as well as their thoughtful attention in their
presentations to the needs of the readers of this volume. The editor deeply
ix

appreciates the help and support of the entire publishing team through the long
process of assembling the material and shepherding the volume through the
production process.
Waltham, MA, USA
Bulbul Chakraborty
June 2022
Volume Editor
x
Volume Preface

Contents
Statistical and Nonlinear Physics: Introduction
. . . . . . . . . . . . . . .
1
Bulbul Chakraborty
Complex Systems and Emergent Phenomena
. . . . . . . . . . . . . . . . .
3
Henrik Jeldtoft Jensen
Polymer Physics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
23
T. C. B. McLeish
Chaotic Dynamics in Nonequilibrium Statistical Mechanics
. . . . .
55
J. Robert Dorfman
Monte Carlo Simulations in Statistical Physics . . . . . . . . . . . . . . . .
85
Kurt Binder
Nonlinear Fluid Flow, Pattern Formation, Mixing, and
Turbulence
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
99
T. H. Solomon
Fluid Dynamics in Clouds . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
121
S. Ravichandran, Jason R. Picardo, Samriddhi Sankar Ray and
Rama Govindarajan
Collective Transport and Depinning
. . . . . . . . . . . . . . . . . . . . . . . .
145
Lei-Han Tang
Disordered Elastic Media
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
165
Thierry Giamarchi
Physics of Jerky Motion in Slowly Driven Magnetic and
Earthquake Fault Systems
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
191
Karin A. Dahmen and Yehuda Ben-Zion
Flexible Mechanical Structures and Their Topologically
Protected Deformations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
213
D. Zeb Rocklin
Glasses and Aging, A Statistical Mechanics Perspective on
. . . . . .
229
Francesco Arceri, François P. Landes, Ludovic Berthier and
Giulio Biroli
xi

Stress Localization in Soft Particulate Gels . . . . . . . . . . . . . . . . . . .
297
Emanuela Del Gado
Nonlinear Mechanics of Colloidal Gels: Creep, Fatigue, and
Shear-Induced Yielding . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
313
Thomas Gibaud, Thibaut Divoux and Sébastien Manneville
Statistical Physics of the Yielding Transition . . . . . . . . . . . . . . . . . .
337
Kirsten Martens
Granular Flows
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
347
James W. Dufty
Statistical Mechanics of Clogging . . . . . . . . . . . . . . . . . . . . . . . . . . .
365
I. Zuriguel and A. Garcimartín
Jamming of Granular Matter . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
397
Bulbul Chakraborty and Bob Behringer
Rigidity Percolation and Frictional Jamming
. . . . . . . . . . . . . . . . .
427
Silke Henkes and J. M. Schwarz
Cell Biology: Networks, Regulation and Pathways . . . . . . . . . . . . .
449
Gašper Tkačik and William Bialek
Fluctuation Theorems, Brownian Motors and Thermodynamics
of Small Systems
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
477
Felix Ritort
Neuronal Dynamics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
495
Nicolas Brunel and Vincent Hakim
Dense Active Matter
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
517
Pinaki Chaudhuri and Chandan Dasgupta
Ultracold Atomic Gases: Novel States of Matter . . . . . . . . . . . . . . .
527
Ludwig Mathey, Shan-Wen Tsai and Antonio H. Castro Neto
Quantum Chaos . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
561
Giulio Casati and Tomaž Prosen
Networks: Structure and Dynamics . . . . . . . . . . . . . . . . . . . . . . . . .
575
Erzsébet Ravasz Regan
Centralities in Complex Networks
. . . . . . . . . . . . . . . . . . . . . . . . . .
599
Alexandre Bovet and Hernán A. Makse
Optimization Problems and Algorithms from Computer Science
. . .
611
Heiko Rieger
Statistical Mechanics Approach to Econophysics
. . . . . . . . . . . . . .
635
Victor M. Yakovenko
Index . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
669
xii
Contents

About the Editor-in-Chief
Robert A. Meyers President: RAMTECH Limited
Manger, Chemical Process Technology, TRW Inc.
Postdoctoral Fellow: California Institute of Technology
Ph.D. Chemistry, University of California at Los Angeles
B.A. Chemistry, California State University, San Diego
Biography
Dr. Meyers was manager of Energy and Environmental Projects at TRW (now
Northrop Grumman) in Redondo Beach, CA, and is now president of
RAMTECH Limited. He is coinventor of the Gravimelt process for desulfur-
ization and demineralization of coal for air pollution and water pollution
control and was manager of the Department of Energy project leading to the
construction and successful operation of a ﬁrst-of-a-kind Gravimelt Process
Integrated Test Plant. Dr. Meyers is the inventor of and was project manager
for the DOE-sponsored Magnetohydrodynamics Seed Regeneration Project
which has resulted in the construction and successful operation of a pilot plant
for production of potassium formate, a chemical utilized for plasma electricity
generation and air pollution control. He also managed TRWefforts in magne-
tohydrodynamics electricity generating combustor and plasma channel devel-
opment. Dr. Meyers managed the pilot-scale DoE project for determining the
hydrodynamics of synthetic fuels. He is a coinventor of several thermo-
oxidative stable polymers which have achieved commercial success as the
GE PEI, Upjohn Polyimides, and Rhone-Poulenc bismaleimide resins. He has
also managed projects for photochemistry, chemical lasers, ﬂue gas scrubbing,
oil shale analysis and reﬁning, petroleum analysis and reﬁning, global change
xiii

measurement from space satellites, analysis and mitigation (carbon dioxide
and ozone), hydrometallurgical reﬁning, soil and hazardous waste remedia-
tion, novel polymers synthesis, modeling of the economics of space transpor-
tation systems, space rigidizable structures, and chemiluminescence-based
devices.
He is a senior member of the American Institute of Chemical Engineers,
member of the American Physical Society, and member of the American
Chemical Society and has served on the UCLA Chemistry Department Advi-
sory Board. He was a member of the joint USA-Russia working group on air
pollution control and the EPA-sponsored Waste Reduction Institute for Scien-
tists and Engineers.
Dr. Meyers has more than 20 patents and 50 technical papers in the ﬁelds of
photochemistry, pollution control, inorganic reactions, organic reactions,
luminescence phenomena, and polymers. He has published in primary litera-
ture journals including Science and the Journal of the American Chemical
Society, and is listed in Who’s Who in America and Who’s Who in the World.
Dr. Meyers’ scientiﬁc achievements have been reviewed in feature articles
in the popular press in publications such as The New York Times Science
Supplement and The Wall Street Journal as well as more specialized publica-
tions such as Chemical Engineering and Coal Age. A public service ﬁlm was
produced by the Environmental Protection Agency on Dr. Meyers’ chemical
desulfurization invention for air pollution control.
Dr. Meyers is the author or editor-in-chief of a wide range of technical
books including the Handbook of Chemical Production Processes; the Hand-
book of Synfuels Technology; the Handbook of Petroleum Reﬁning Processes,
now in fourth edition; the Handbook of Petrochemical Production Processes
(McGraw-Hill), now in a second edition; the Handbook of Energy Technology
and Economics, published by John Wiley & Sons; Coal Structure, published
by Academic Press; and Coal Desulfurization as well as the Coal Handbook
published by Marcel Dekker. He served as chairman of the advisory board for
A Guide to Nuclear Power Technology, published by John Wiley & Sons,
which won the Association of American Publishers Award as the best book in
technology and engineering. He also served as editor-in-chief of three editions
of the Elsevier Encyclopedia of Physical Science and Technology. Most
recently, Dr. Meyers serves as editor-in-chief of the Encyclopedia of Analytical
Chemistry as well as Reviews in Cell Biology and Molecular Medicine and a
book series of the same name both published by John Wiley & Sons. In
addition, Dr. Meyers currently serves as editor-in-chief of two Springer Nature
book series, Encyclopedia of Complexity and Systems Science and Encyclo-
pedia of Sustainability Science and Technology.
xiv
About the Editor-in-Chief

About the Volume Editor
Bulbul Chakraborty is the Enid and Nate Ancell Professor of Physics at
Brandeis University. Her research focuses on theory of soft condensed matter.
She obtained her doctorate from Stony Brook University with a thesis on
superconductivity. Her early work focused on strongly correlated electronic
systems, including high Tc superconductors. Her recent research has focused
on developing a statistical mechanics framework for granular media and other
disordered systems that are non-thermal. She is a fellow of the American
Association for the Advancement of Science and the American Physical
Society.
xv

Contributors
Francesco Arceri Department of Physics, University of Oregon, Eugene,
OR, USA
Bob Behringer Department of Physics, Duke University, Durham, NC, USA
Yehuda Ben-Zion Department of Earth Sciences, University of Southern
California, Los Angeles, USA
Ludovic Berthier Laboratoire Charles Coulomb (L2C), Université de Mont-
pellier, CNRS, Montpellier, France
Department of Chemistry, University of Cambridge, Cambridge, UK
William Bialek Joseph Henry Laboratories of Physics, Lewis–Sigler Insti-
tute for Integrative Genomics, Princeton University, Princeton, NJ, USA
Princeton Center for Theoretical Physics, Princeton University, Princeton, NJ,
USA
Kurt Binder Institut für Physik, Johannes Gutenberg Universität, Mainz,
Germany
Giulio Biroli Laboratoire de Physique de l’École normale supérieure,
Université PSL, CNRS, Sorbonne Université, Université Paris-Diderot,
Paris, France
Alexandre Bovet Mathematical Institute, University of Oxford, Oxford, UK
Nicolas Brunel Department of Neurobiology, Duke University School of
Medicine, Durhum, North Carolina, USA
Giulio Casati Universita dell’Insubria, Como, Italy
Antonio H. Castro Neto Boston University, Boston, USA
Bulbul Chakraborty Department of Physics, Brandeis University, Waltham,
MA, USA
Pinaki Chaudhuri The Institute of Mathematical Sciences, Chennai, India
Karin A. Dahmen Department of Physics, University of Illinois at Urbana-
Champaign, Urbana, USA
Bob Behringer: deceased.
xvii

Chandan Dasgupta Department of Physics, Indian Institute of Science,
Bengaluru, India
International Centre for Theoretical Sciences, Tata Institute of Fundamental
Research, Bengaluru, India
Emanuela Del Gado Department of Physics and Institute for Soft Matter
Synthesis and Metrology, Georgetown University, Washington, DC, USA
Thibaut Divoux Laboratoire de Physique, Univ Lyon, Ens de Lyon, Univ
Claude Bernard, CNRS, Lyon, France
MultiScale Material Science for Energy and Environment, UMI 3466, CNRS-
MIT, Cambridge, MA, USA
J. Robert Dorfman Institute for Physical Science and Technology and
Department of Physics, University of Maryland, College Park, MD, USA
James W. Dufty Department of Physics, University of Florida, Gainesville,
FL, USA
A. Garcimartín Dpto. de Física y Mat. Apl. Facultad de Ciencias,
Universidad de Navarra, Pamplona, Spain
Thierry
Giamarchi DPMC-MaNEP,
University
of
Geneva,
Geneva,
Switzerland
Thomas Gibaud Laboratoire de Physique, Univ Lyon, Ens de Lyon, Univ
Claude Bernard, CNRS, Lyon, France
Rama Govindarajan International Centre for Theoretical Sciences, Tata
Institute of Fundamental Research, Bangalore, India
Vincent Hakim Département de Physique, Ecole Normale Supérieure, Paris,
France
Silke Henkes School of Mathematics, University of Bristol, Bristol, UK
Henrik Jeldtoft Jensen Institute for Mathematical Sciences and Department
of Mathematics, Imperial College London, London, UK
François P. Landes TAU, LRI, Université Paris Sud, CNRS, INRIA,
Université Paris Saclay, Orsay, France
Hernán A. Makse Levich Institute and Physics Department, City College of
New York, New York, NY, USA
Sébastien Manneville Laboratoire de Physique, Univ Lyon, Ens de Lyon,
Univ Claude Bernard, CNRS, Lyon, France
Kirsten Martens Université Grenoble Alpes, CNRS, LIPhy, Grenoble,
France
Ludwig Mathey Harvard University, Cambridge, USA
T. C. B. McLeish Department of Physics, University of York, York, UK
xviii
Contributors

Jason R. Picardo Department of Chemical Engineering, Indian Institute of
Technology Bombay, Mumbai, India
Tomaž Prosen Univerza v Ljubljani, Ljubljana, Slovenia
S. Ravichandran Nordita, KTH Royal Institute of Technology and Stock-
holm University, Stockholm, Sweden
Samriddhi Sankar Ray International Centre for Theoretical Sciences, Tata
Institute of Fundamental Research, Bangalore, India
Erzsébet Ravasz Regan The College of Wooster, Wooster, OH, USA
Heiko Rieger Theoretical Physics, Universität des Saarlandes, Saarbrücken,
Germany
Felix Ritort Department de Fisica Fonamental, Faculty of Physics,
Universitat de Barcelona, Barcelona, Spain
D. Zeb Rocklin Georgia Institute of Technology, Atlanta, GA, USA
J. M. Schwarz Physics Department, Syracuse University, Syracuse, NY,
USA
T. H. Solomon Department of Physics and Astronomy, Bucknell University,
Lewisburg, PA, USA
Lei-Han Tang Department of Physics, Hong Kong Baptist University, Kow-
loon Tong, Hong Kong SAR, China
Gašper Tkačik Joseph Henry Laboratories of Physics, Lewis–Sigler Insti-
tute for Integrative Genomics, Princeton University, Princeton, NJ, USA
Shan-Wen Tsai University of California, Riverside, USA
Victor M. Yakovenko Department of Physics, University of Maryland,
College Park, MD, USA
I. Zuriguel Dpto. de Física y Mat. Apl. Facultad de Ciencias, Universidad de
Navarra, Pamplona, Spain
Contributors
xix

Statistical and Nonlinear
Physics: Introduction
Bulbul Chakraborty
Department of Physics, Brandeis University,
Waltham, MA, USA
The “Statistical and Nonlinear Physics” section of
the second edition of Encyclopedia of Complexity
and Systems Science presents a combination of
entries that highlight new developments in the
ﬁeld and foundational ones that provide the
grounding needed to master the essence of this
ﬁeld that intersects physics, mathematics, com-
puter science, and biology. This encyclopedia
section is intended to be a resource for junior
scientists entering the ﬁeld and established scien-
tists branching out into new areas.
Rooted in equilibrium statistical physics and
nonlinear dynamics, the subject matter of this book
has evolved to encompass a vast array of emergent
phenomena in systems that can be near equilibrium
or very far from it, dominated by thermal ﬂuctua-
tions or completely athermal but driven externally.
A hallmark of the ﬁeld is that it is constantly in a
state of evolution and expansion of focus.
The singular objective of statistical and non-
linear physics is to describe collective behavior
that emerges from the interactions of a large num-
ber of degrees of freedom. The building blocks,
entities that form the “collective,” range from the
atomic scale to objects that are macroscopic in size.
The traditional approach is based on the prescrip-
tion of interactions between the building blocks,
which are then “coarse-grained” to lead to effective
theories that describe phenomena that occur on
length and time scales that are large compared to
the building blocks. The phenomena that emerge at
these scales are far richer than that of a few: The
collective is not just a sum of its parts. After all,
phase transitions and broken symmetry are deﬁned
only at these scales. Unlike fundamental ﬁeld the-
ories in physics that describe the behavior of the
universe at its smallest scales, the beauty of statis-
tical and nonlinear physics lies in the “effective”
ﬁeld theories that deﬁne it. Classical examples
range from the Navier-Stokes equations describing
ﬂuids to the theory of elasticity of solids.
Entries on subjects that have remained at the
core of the discipline have been updated as needed
from the ﬁrst edition. This volume provides an
excellent introduction to the subject and demys-
tiﬁes the emergence of collective, novel behavior
from
many
strongly
interacting
units
(see
▶“Complex Systems and Emergent Phenom-
ena”). The volume also explores the fascinating
ﬁeld of driven disordered media which uniﬁes
phenomena ranging from earthquakes to disor-
dered magnets where the physical features are
dominated by the driving of an internal elastic
membrane or interface through a medium that
“pins” it at random spatial positions (see ▶“Dis-
ordered Elastic Media” and ▶“Physics of Jerky
Motion in Slowly Driven Magnetic and Earth-
quake Fault Systems”). There is a host of other
entries in these core areas that provide the reader
with the essential tools of the trade.
The emergence of rigidity in disordered solids
such as glasses, gels, and frictional granular mate-
rials is a signiﬁcant focus of this second edition,
primarily because this area has experienced a par-
adigm shift in recent years. There are entries that
focus on the fundamental theoretical ideas that are
needed to understand the response of disordered
solid
to
external
stresses
(see
Topological
Mechanics). The quintessentially hard problem
of the glass transition is also tackled (see
▶“Glasses and Aging, A Statistical Mechanics
Perspective on”). The emergence of rigidity and
stress heterogeneities in granular solids and gels is
discussed (see ▶“Rigidity Percolation and Fric-
tional Jamming” and ▶“Stress Localization in
Soft Particulate Gels”), as well as the yielding
and failure of such solids (see ▶“Nonlinear
Mechanics of Colloidal Gels: Creep, Fatigue,
and Shear-Induced Yielding”).
Another area of research that this second edi-
tion focuses on are complex ﬂows (see ▶“Dense
© Springer Science+Business Media, LLC, part of Springer Nature 2022
B. Chakraborty (ed.), Statistical and Nonlinear Physics,
https://doi.org/10.1007/978-1-0716-1454-9_742
Originally published in
R. A. Meyers (ed.), Encyclopedia of Complexity and Systems Science, © Springer Science+Business Media LLC 2022
https://doi.org/10.1007/978-3-642-27737-5_742-1
1

Active Matter,” ▶“Statistical Mechanics of Clog-
ging,” and ▶“Fluid Dynamics in Clouds”). These
add to the techniques and extend the principles
presented in the entries on ▶“Nonlinear Fluid
Flow, Pattern Formation, Mixing, and Turbu-
lence” and ▶“Granular Flows,” which have
been updated from the ﬁrst edition.
The study of Networks has become integral to
statistical mechanics since the publication of the
ﬁrst edition. The discussion from the ﬁrst edition
(see ▶“Networks: Structure and Dynamics”) is
now augmented by a more focused discussion of
an aspect of Network theory that is being increas-
ingly employed to analyze the relation between the
structure and function of networks in complex sys-
tems (see ▶“Centralities in Complex Networks”).
We hope that this collection of entries will be a
useful resource to the existing community of sci-
entists engaged in statistical and nonlinear physics
research, and to anyone wishing to enter this ﬁeld.
2
Statistical and Nonlinear Physics: Introduction

Complex Systems and
Emergent Phenomena
Henrik Jeldtoft Jensen
Institute for Mathematical Sciences and
Department of Mathematics, Imperial College
London, London, UK
Article Outline
Glossary
Deﬁnition of the Subject
Introduction
Equilibrium Averages
The Two-Dimensional XY-Model
Lack of Ordering in Two Dimensions
Vortex Unbinding
The Vortex Unbinding Transition in Other
Systems
Non-Equilibrium Systems
1/f Fluctuations: A Langevin Approach
Self-Organized Structure Formation: Ant Trails
Summary and Future Directions
Bibliography
Glossary
Correlations is the degree, to which events at
different positions and at different times
depend on or inﬂuence each other, is measured
by correlation functions. If two events are sta-
tistically independent, the correlation between
them is zero. The opposite is not necessarily
the case, but one will often expect that if cor-
relations decay, the mutual dependence does
likewise.
Correlation
function describes
correlations
between two quantities and depends on their
separation in time and space.
Complex systems consist of a large number of
interacting components. The interactions give
rise to emergent hierarchical structures. The
components of the system and properties at
systems level typically change with time.
A complex system is inherently open and its
boundaries often a matter of convention.
Equilibrium In statistical mechanics the proto-
type equilibrium system consists of a “small”
system in thermal contact with another system,
the latter being big enough to act as a heat bath.
A heat bath is deﬁned as a system so big that
when it exchanges energy with the small sys-
tem the temperature of the heat bath remains
the same. The statistical properties of equilib-
rium systems are independent of time.
Generalized rigidity is a term introduced by
P.W. Anderson (1984) to describe the situation,
when a many component system acts as a
globally connected unit, in the sense that if
one apply a force at one point, the effect can
be transmitted across the system. Ice has rigid-
ity, if we push at one point, the entire piece of
ice will start moving. If the ice, on the other
hand melts to water, a force applied locally will
only have an effect locally.
Hamiltonian expresses the energy of a system as
a function of the degrees of freedom, in terms
of which the system is deﬁned at the consid-
ered level of description. Emergence in physi-
cal systems can sometimes be understood in
terms of lumping degrees of freedom, in the
Hamiltonian, together in sets of effective
degrees of freedom, e. g. the center of mass of
a solid body.
Non-equilibrium systems is a term used to
describe any system that is not in equilibrium.
Needless to say this is a characterization of
limited value, since there are many very differ-
ent types of systems included in this category.
Order parameter is a quantity that allows one to
discriminate between two phases of a physical
system. The order parameter changes from
zero to non-zero as one passes from one
phase to the other. To identify the relevant
order parameter is often non-trivial and, is in
itself, a ﬁrst important step.
© Springer-Verlag 2009
B. Chakraborty (ed.), Statistical and Nonlinear Physics,
https://doi.org/10.1007/978-1-0716-1454-9_85
Originally published in
R. A. Meyers (ed.), Encyclopedia of Complexity and Systems Science, © Springer-Verlag 2009
https://doi.org/10.1007/978-3-642-27737-5_85
3

Renormalization group analysis is a systematic
mathematical procedure that enables a deriva-
tion of the emergent behavior at the macro-
scopic systems level. The behavior at long
length and time scales is obtained from the
underlying microskopic short length scales
and fast dynamics.
Statistical mechanics seeks to understand how
properties at systems level emerge from the
level of the system components and their inter-
actions. This often involves the application of
probability theory, and a number of mathemat-
ical techniques. Throughout, we draw a dis-
tinction between statistical mechanics and
statistical
physics.
The
latter
is
mainly
concerned with the microscopic foundation of
thermodynamics and, e. g., phenomena such as
phase transitions and superconductivity.
Definition of the Subject
Matter in the universe is organized in a hierarchi-
cal structure. At the bottom (if there is one) we
have elementary particles, atoms and molecules
from which we get macro molecules like proteins
and DNA, these are the building blocks of organ-
elles, which together form the cells. From cells we
get organs, which put together form organisms:
animals and plants of a great variety of species.
One level of structure emerges from the level
below. Is it possible to scientiﬁcally describe,
let alone, predict emergence. Sometimes emer-
gence is described as a phenomena beyond anal-
ysis. The perplexity with which this concept is
sometimes met, is well illustrated by the following
quote from a recent call for participation in a
meeting, held by the British research council
EPSRC, to look at ways to explore emergence in
complex systems. Emergence is described in the
following words: “For the ﬁrst time since the
enlightenment in the western tradition we have
started to understand that there are non-causal
systems in which some things just “are”. The
concept of emergence by which patterns of possi-
bility arise through interactions of agents over
time, accepts that even with the same starting
conditions the same pattern would not necessarily
repeat.” Another attitude is represented by Lord
Roberts May’s statement in a recent lecture that
“when people say something is an emergent prop-
erty, it just means they don’t understand the
phenomena”.
In this brief article we will argue that emer-
gence is neither an empty concept nor a mysteri-
ous
non-causal
enigma.
On
the
contrary,
emergence is central to scientiﬁc enquiry. Emer-
gence occurs when many components interact and
combine to form an identiﬁable system. In philos-
ophy this is the observation that quantitative
changes accumulate and give rise to new qualita-
tive changes. A proposition that can be traced
from the ancient Greek philosophers through
Hegel to Dialectical Materialism. In physics Phil
Anderson famously summed the fact that new
levels of organization need new types of descrip-
tion, up in the phrase “More is Different”
(Anderson 1972). By following the tradition of
statistical mechanics it is sometimes possible to
reduce signiﬁcantly the confusion surrounding
what emergence is, and how it can be investigated
and described. Kenneth Wilson got the 1982
Nobel prize for his Renormalization Group the-
ory, which is a particular beautiful method for
extracting certain emergent properties with great
mathematical detail and precision (Wilson 1982).
Introduction
Statistical mechanics is concerned with the inter-
action of many components. From interactions
between the components at one given level the
aim is to understand the collective coherent
behavior, which emerges as many components
are put together. It is through the interactions of
the components at one level that the next level
emerges. We consider a collection of interacting
atoms and the outcome is, say, a transistor. In
some cases the microscopic details of the proper-
ties of the individual building blocks are not so
crucial. It happens that the collective behavior is
controlled by general properties of the interac-
tions between the components more than by the
intrinsic properties of the components. A number
of methods have been developed to bridge the gap
4
Complex Systems and Emergent Phenomena

between the individual components comprising a
system and the collective whole. This often
involves predictions of the asymptotic behavior
at long distances and at long times. In particular
the
philosophy
and
technique
of
the
Renormalization Group have been successful in
a number of cases in doing this. Many other
approaches exist, some in which a coarse grained
description is sought similar to the one used in
ﬂuid dynamics, other times the collective systems
level behavior is generated by use of Individual
Based Agent models typically simulated on com-
puters. The latter method goes beyond traditional
statistical mechanics, nevertheless it is reasonable
to consider simulations of agent based models as
part of statistical mechanics since they are very
similar in spirit to traditional statistical mechanics
simulations starting from the microscopic degrees
of freedom, as e. g. extensively done for the cel-
ebrated Ising model used in studies of magnetic
systems, melting and many other phenomena.
In this article we will discuss a number of
examples of how statistical mechanics is able to
deal with emergent phenomena. Our ﬁrst example
is from the theory of equilibrium properties of
magnetic materials. In the model the microscopic
magnetic moments – or spin – combine to form
macroscopic coherent vortices. The vortices are
bound in pairs at low temperature. When the tem-
perature is increased, the biggest pairs are able to
unbind, or fall apart. This is a subtle collective
effect caused by the smaller pairs weakening the
binding force between the vortices in the biggest
pairs. We use this case to describe in some detail
how the statistical mechanics formalism of
Boltzmann and Gibbs allows us to identify the
macroscopic excitations. These macroscopic exci-
tations are what constitute the macroscopic “com-
ponents” of the system, once they are identiﬁed
we can calculate the unbinding of the vortex pairs.
This discussion focuses on spatial aspects. The
mathematical description developed from this
model has applications to a range of very different
phenomena, such as melting, superconductivity,
super
ﬂuidity,
electrical
charges
in
two-
dimensional space and crystal growth. This is a
good typical example of how the mathematical
formalism of statistical mechanics is able to
deliver understanding, and a description, trans-
cending the particular and unify apparently dis-
connected phenomena.
Many-component systems also often exhibit
emergent temporal behavior that is caused by the
interactions and ensuing collective motion of the
components. For example, one typically see very
persistent correlations, or long time memory, in
the macro-dynamics of many-component sys-
tems. A particular version of this phenomena is
called 1/f ﬂuctuations, and we explain below what
this is, and how it is related to long time correla-
tions or long memory effects. To make the discus-
sion concrete we will present the details of a very
simple model of diffusing particles. The model
might be related to motorway trafﬁc.
To go beyond models taken from physics we
will ﬁnish by a discussion of models inspired by
the observed collective behavior of social insects.
Aspects of trail formation and mound building of
ants and termites have been reproduced in com-
puter simulations. Often the models consider
“agents” with a tendency to perform random
walks and picking up and laying down material.
The agents deviate from random walking when
they come across traces of smell – pheromones –
laid down by other ants. This indirect interaction
can lead to the formation of surprisingly intricate
structures of trails and mounds.
Since essentially any activity within statistical
mechanics is concerned with a description of
emerging phenomena a very large literature exists
and we list here only a few books of particular
relevance to the view point of the present article
(Anderson 1984; Reif 1965; Shang-Keng 1985;
Kadanoff 2000; Binney et al. 1992; Nelson 2002;
Chaikin and Lubensky 1995; Tinkham 2004;
Sornette 2004; Camazine et al. 2001; Solé and
Goodwin 2000) and some more specialized
papers as we go along.
Equilibrium Averages
To describe how statistical mechanics is able to
identify structures emerging at the macroscopic
level
we
brieﬂy
recall
how
macroscopic
(or systems level) quantities are obtained through
Complex Systems and Emergent Phenomena
5

averaging procedures. The reason equilibrium
systems can be analyzed in particular detail is
that the situation, where the systems of interest
can be considered as in thermal equilibrium with a
heat bath, allows for the determination of the
probability weights of the individual micro-states.
One starts out with the following fundamental
hypothesis concerning isolated or closed systems:
•
Micro Canonical Ensemble. For a closed sys-
tem it is assumed that all micro-states, consis-
tent with the macroscopic constraints, occur
with equal probability.
The macroscopic constraints can, for example,
be the total energy E (which is constant for a
closed system) and the volume V. Denote by
Ω(E, V) the total number of micro-states possible
under these constrains. Meaning the components
or particles of the system have to be located within
the given volume V, and that when we add all the
energies of the particles the sum must equal E.
The probability p(s) that the system is in a partic-
ular state s is then
p sð Þ ¼
1
O E, V
ð
Þ :
ð1Þ
Closed systems are not very interesting in the
sense that one is unable to interact with them.
A much more interesting situation is when the
system S under consideration is brought in contact
with a heat bath B or heat reservoir. The heat bath
is a system so big that even when it exchanges
energy with the small system of experimental
interest, the heat bath remains unchanged. Say a
cup of tea in contact with the Paciﬁc Ocean. The
heat bath is characterized by its temperature T. We
can now use the fundamental hypothesis above to
determine the probabilistic weights for the states
of S. Since the combined system B þ S is closed
the weights for the combined system is given by
the Micro Canonical Ensemble, i.e. all microstates
of the combined system are equally likely. The
number of micro-states for the combined system
of total energy ETot ¼ EB þ ES will be a product
OTot ETot
ð
Þ ¼ OB EB
ð
ÞOS ES
ð
Þ:
ð2Þ
Here one neglects the interactions between the
heat bath and the system. Now focus on one
particular micro-state s of S of energy Es. Since
we have a particular state, s, in mind we have
ΩS(s) ¼ 1. This state can be combined in many
ways with states of the bath B as long as those
fulﬁll the constraint ETot ¼ EB þ Es. So the prob-
ability, p(s), for ﬁnding the system S in s, when
S is in equilibrium with the bath, is proportional to
ΩB(ETot – Es). Namely
p sð Þ ¼
OB ETot  Es
ð
Þ
P
stateOB ETot  Estate
ð
Þ ,
ð3Þ
the denominator ensures normalization. In order
to introduce the temperature into the mathematical
formalism it turns out that we should consider the
logarithm of p(s). We have
ln p sð Þ
½
 ¼ constant þ ln OB ETot  Es
ð
Þ
½

¼ constant þ ln OB ETot
ð
Þ
½

ð4Þ
 @ ln OB ETot
ð
Þ
½

@ETot
Es
ð5Þ
¼ constant  1
kBT Es:
ð6Þ
Here we Taylor expanded to linear order to
obtain the ﬁrst equality. The second equality fol-
lows, because it can be shown by use of the ﬁrst
and second law of thermodynamics that the tem-
perature is given by
1
kB T ¼ @ ln OB ETot
ð
Þ
½

@ETot
:
ð7Þ
This is obtained in the following way. The ﬁrst
and second law of thermodynamics lead to the
following thermodynamic identity dE ¼ TdS –
pdV where the entropy S ¼ kB ln[Ω(E)]. Since
the thermodynamic identity takes the form of an
exact differential we conclude that @E/@S ¼ T
from which Eq. (7) follows. We now conclude
6
Complex Systems and Emergent Phenomena

p sð Þ ¼ e Es
kB T
Z
,
ð8Þ
where the constant Z is obtained from the normal-
ization condition
X
states
p sð Þ ¼ 1,
ð9Þ
to be given by
Z ¼
X
states
¼ e Es
kB T:
ð10Þ
We conclude that the probabilistic weights,
needed to calculate the average macroscopic
behavior of a system in contact with a heat bath at
temperature T, is given by the (Boltzmann) weights
in Eq. (8). And we mention that a large number of
average quantities can be calculated from the sum
in Eq. (10). This important sum is called the parti-
tion function or partition sum. Some states, or
conﬁgurations of the microscopic degrees of free-
dom, will contribute more to the partition sum than
others, such conﬁgurations can sometimes be iden-
tiﬁed as macroscopic collective excitations. These
may possess a degree of robustness and stability
and can in such cases be identiﬁed as macroscopic
emergent objects with speciﬁc properties that can
be considered essential building blocks. Perhaps it
is instructive to have the following picture in mind.
Think of a pool table. To describe the motion of the
balls we can either follow the trajectories of all the
individual molecules making up 15 colored balls or
we can notice that some of the molecules move
together in a coordinated way and thereby form
each of the 15 balls. We can therefore instead
simply follow the trajectories of the center of
mass (COM) of each of the balls. Obviously we
lose a lot of information since we can’t go from the
COM of the balls to the motion of all the mole-
cules; whereas we can drive the COM motion if we
know the motion of all the molecules. Hence we
note that emergence involves a loss of information.
We will discuss in detail an important and illustra-
tive example in the next section.
The Two-Dimensional XY-Model
Here we describe how the averaging procedure
described in the previous section can be structured
in a way that allows the introduction of new effective
collective degrees of freedom. These describe mac-
roscopic excitations created by the coherent motion
of a huge number of microscopic variables. When
the collective degrees have been identiﬁed informa-
tion concerning the detailed motion of the micro-
scopic variables can be neglected, and one is in this
way able to reduce the computational effort needed
and at the same time identify the essential emergent
structures. A particular clear example of this proce-
dure consists of the physics of systems modeled by
the so-called two-dimensional XY-model.
We start our discussion by considering the
formation
of
vortices
in
the
sea
of
two-
dimensional magnetic moments. The individual
microscopic magnetic moments sit on the sites
of a two-dimensional square lattice and the direc-
tion of the moments are conﬁned to two dimen-
sions, see Fig. 1 (A beautiful online interactive
simulation can be found on Hans Weber’s web
page at http://www.mt.luth.se/~weber/). Each
magnetic moment can be thought of as a magnetic
needle, or an arrow, conﬁned to two dimensions
and pointing in a speciﬁc direction described by
the angle θ. The magnetic moment number i is
given by the vector Si ¼ (cos(θi), sin(θi)).
We will use it as our reference model. We
think of the model as consisting of planar rotors
of unit length arranged on a two-dimensional
square lattice. The Hamiltonian of the system is
given by
H ¼ J
X
i, j
h
i
Si  S j
¼ J
X
i, j
h
i
cos yi  y j


:
ð11Þ
Here J is the coupling constant between the
magnetic moments, hi,
ji denotes summation
over all nearest neighbor sites in the lattice, and
θi denotes the angle of the rotor on site i with
respect to some (arbitrary) polar direction in the
Complex Systems and Emergent Phenomena
7

two-dimensional vector space containing the
rotors.
We shall see below how the components, the
rotors, work together to form certain collective
coherent structures: topological defects or topo-
logical charges. In Fig. 1 these excitations are
depicted. Each consists of a whirl or vortex in
the conﬁguration of the rotors. There are vorti-
ces of opposite sign. As one moves around in a
positive direction along a contour encircling the
center of a vortex (black circle) the rotors per-
form a full rotation in the positive direction as
well. When we move around one of the anti-
vortices (white circle) in a similar way, the
rotors undergo a full rotation in the negative
direction. Although these charges are here seen
as arising from rotors or magnetic moments, the
impressive fact is that these topological charges
also represent Coulomb charges in two dimen-
sions,
or
dislocations
in
two-dimensional
crystals, or vortices in two-dimensional super-
conductors or a large number of other collec-
tive excitations. The interaction between the
topological charges depends in all cases loga-
rithmically on the spatial separation and this
leads to some very general collective behavior,
most spectacular the logarithmic dependence
on separation causes a certain type of phase
transition: the Kosterlitz–Thouless transition
(Kosterlitz and Thouless 1973).
If we assume that the direction of the rotors
varies smoothly from site to site, we can approx-
imate cos(θi – θj) by the ﬁrst two terms 1 – 1/2(θi –
θj)2 in the Taylor expansion of cos. The sum over
the nearest neighbors corresponds to the discrete
Laplace operator, which we can express in terms
of partial derivatives through θi  θj ¼ @xθ for two
sites i and j which differs by one lattice spacing in
the x-direction. This leads to the continuum
Hamiltonian
Complex
Systems
and
Emergent
Phenomena,
Fig. 1 Rotor conﬁguration of the XY-model. Vortices
(black circle) and anti-vortices (white circle) are clearly
seen. The conﬁguration is neutral, i.e. there is an equal
number of vortices and anti-vortices; but only one white
circle is indicated. The reader may ﬁnd it amusing to try to
locate the missing anti-vortex
8
Complex Systems and Emergent Phenomena

H ¼ E0 þ J
2
Z
dr ∇y
ð
Þ2:
ð12Þ
Here E0 ¼ 2JN is the energy of the completely
aligned ground state of N rotors.
The thermodynamics of the system is obtained
from the partition function
Z ¼ eb E0
Z
D y½  exp
b J
2
Z
dr ∇y
ð
Þ2


,
ð13Þ
a functional integral over all possible conﬁgura-
tions of the director ﬁeld θ (r). Not all conﬁgu-
rations will be of the same importance. By
focusing on the terms in the sum that contribute
most, we can identify the conﬁgurations that
may be used as building blocks at the next
level of description. Since the energy appears
in the exponential with a negative sign in front,
the most signiﬁcant contributions will be those
with the smaller energy – thus we have to pick
out the local minima. We therefore divide the
integral over θ(r) into a sum over the local
minima θvor of H[θ] plus ﬂuctuations θsw around
the minima
Z ¼ eb E0X
yvor
Z
D ysw
½
 exp

b H yvor
½

ð
þ 1
2
Z
dr1
Z
dr2ysw r1
ð
Þ
d2H
dy r1
ð
Þdy r2
ð
Þ ysw r2
ð
ÞÞ

:
ð14Þ
The ﬁeld conﬁgurations corresponding to local
minima of H are solutions to the extremal
condition
dH
dy r
ð Þ ¼ 0 ) ∇2y r
ð Þ ¼ 0:
ð15Þ
There are two types of solutions to this
equation. The ﬁrst consists of the ground state
θ(r) ¼ constant. The second type of solutions
consist of vortices in the director ﬁeld (see
Fig. 1) and are obtained by imposing the fol-
lowing set of boundary conditions on the circu-
lation integral of θ(r):
1) For all closed curves encircling the position r0
of the center of the vortex
I
∇y r
ð Þ  dl ¼ 2pn,
n ¼ 1, 2, . . . :
ð16Þ
2) For all paths that don’t encircle the vortex
position r0
I
∇y r
ð Þ  dl ¼ 0:
ð17Þ
Condition 1) imposes a singularity in the direc-
tor ﬁeld. Note the circulation integral must be
equal to an integer times 2π since we circle a
closed path and therefore θ(r) has to point in the
same direction after traversing the path as it did
when we started.
We can estimate the energy of a vortex in the
following way. The problem is spherical symmet-
ric, hence the vortex ﬁeld θvor must be of the form
θ(r) ¼ θ(r). The dependence on r can be found
from Eq. (16). We calculate the circulation inte-
gral along a circle of radius r centered at the
position r0 of the vortex
2pn ¼
I
∇y r
ð Þ  dl ¼ 2prj∇yj:
ð18Þ
We solve and obtain |∇θ(r)| ¼ n/r. Substitute
this result into the Hamiltonian Eq. (12)
Evor  E0 ¼ J
2
Z
dr ∇y r
ð Þ
½
2
ð19Þ
¼ Jn2
2
Z 2p
0
df
Z L
a
rdr 1
r2
ð20Þ
¼ pn2J ln L
a :
ð21Þ
Here a denotes the lattice constant and L is the
linear size of the considered lattice. The circula-
tion condition Eq. (16) creates a distortion in the
phase ﬁeld θ (r) that persists inﬁnitely far from the
center of the vortex. |∇θ| decays only as 1/r lead-
ing to a logarithmic divergence of the energy.
Hence we need to take into account that the
Complex Systems and Emergent Phenomena
9

integral over r in Eq. (20) is cut-off for large
r-values by the ﬁnite system size L and for small
r-values by the lattice spacing a. We recall that our
continuum Hamiltonian is an approximation to
the lattice Hamiltonian in Eq. (11). A vortex with
the factor n in Eq. (16) larger than one is called
multiple charged. We notice that the energy of the
vortex is quadratic in the charge. In a macroscop-
ically large system even the energy of a single
charge vortex will be large, and therefore we do
not expect individual vortices to be thermally
induced.
Consider now a pair consisting of a single
charged vortex and a single charged anti-
vortex. When we encircle the vortex, we pick
up
H
dl  ∇θ ¼ 2π and when we encircle the
anti-vortex, we pick up
H
dl 
∇θ ¼
 2π.
Hence, if we choose a path large enough to
enclose both vortices, we pick up a circulation
of the phase equal to 2π þ (2π) ¼ 0. I.e. the
distortion of the phase ﬁeld θ(r) from the
vortex-anti-vortex pair is able to cancel out at
distances from the center of the two vortices
large compared to the separation R between the
vortex and the anti-vortex, see Fig. 1. This
explains why the energy of the vortex pair is
of the form (Cataudella and Minnhagen 1990;
Weber
and
Jensen
1991;
Minnhagen
and
Olsson 1991).
E2vor R
ð Þ ¼ 2Ec þ E1 ln R=a
ð
Þ:
ð22Þ
Where Ec is the energy of a vortex core and E1
is proportional to J. In detail, the phase ﬁeld
θ2vor(r) of a vortex located at r ¼ (a, 0) and an
anti-vortex located at r ¼ (a, 0) is given by
(Cataudella and Minnhagen 1990).
y2vor r
ð Þ ¼ arctg
2ay
a2  r2


:
ð23Þ
Signiﬁcant aspects of the macroscopic behav-
ior of the XY-model can be understood by treating
the vortices as particles characterized by their
position and their charge and ignoring the under-
lying sea of rotors. Indication of this follows from
the expression for the energy of a pair of vortices
in Eq. 22. This energy is given in terms of the
relative position of the two vortices, no reference
is needed to the microscopic rotor ﬁeld given in
Eq. 23. The pairs of vortices have dramatic effects
on the macroscopic behavior of the XY-model. At
low temperature the vortices are organized in
fairly small bound pairs, as the temperature is
increased and more thermal energy is available
the separation between paired up vortices grow
and at a certain temperature the pairs break apart
with the effect that the individual vortices now
can move freely around as they are no longer
kept in check by their partner of the opposite
charge. The result is the Kosterlitz–Thouless
transition which manifests itself in various
ways in different realizations of the XY-model.
Before we discuss this transition we will look at
the average ordering of the rotors. This quantity –
the magnetization – is usually able to monitor if a
dramatic change in the macroscopic behavior
occurs as a function of temperature. But not so
in the 2d XY-model. To understand this makes it
clearer how important it is to identify correctly
the emergent excitations of a many component
system.
Lack of Ordering in Two Dimensions
In order to highlight the peculiarity of two dimen-
sions we consider the d-dimensional XY-model.
We imagine a d-dimensional cubic lattice. Each
lattice site contains a planar rotor or a phase. In the
continuum limit the Hamiltonian is still given by
Eq. (12) except the integral over r is now a
d-dimensional integral and therefore the factor
J is replaced by Ja2–d. The average size of the
projection of the rotors along, say, the x-direction
in S space, i.e. the magnetization, is
Sx
h
i ¼
cos y r
ð Þ
h
i
ð24Þ
¼
cos y 0
ð Þ
h
i:
ð25Þ
Note that we might as well have chosen the
y-direction. The model is isotropic and the x and
the y directions are equivalent. When hSxi 6¼ 0 a
preferred direction is singled out in the sense that
on average S points in the direction given by hSxi.
10
Complex Systems and Emergent Phenomena

In this case we say that the rotor ﬁeld possesses
order. In contrast if hSxi ¼ 0 we also have hSyi ¼ 0,
since the model is isotropic. The zero projection
comes about because the rotors circulate around
and on average point equally much in all direc-
tions. So we say that the rotor ﬁeld is disordered or
does not possess any ordering.
First we neglect the singular vortex contribu-
tions (which is perfectly safe at low temperature)
and Fourier transform the phase ﬁeld
y r
ð Þ ¼
Z
dk
2p
ð
Þd ^y k
ð Þeikr
ð26Þ
y 0
ð Þ ¼
Z
dk
2p
ð
Þd ^y k
ð Þ
ð27Þ
Z
dr ∇y
ð
Þ2 ¼
Z
dk
2p
ð
Þd k2y ^k
 ^y k
ð
Þ:
ð28Þ
These
equations
are
substituted
into
the
expression
Sx
h
i ¼
Z
D y½  cos y 0
ð Þ
ð
Þeb H
Z
D y½ eb H
¼ Re
Z
D y½ eb Hþi y 0
ð Þ
Z
0
B
B
@
1
C
C
A:
ð29Þ
After some algebra one obtains the following
expression
Sx
h
i ¼ exp

T
2Ja2d Sd
Z p=a
p=L
dkkd3
 
!
: ð30Þ
The behavior of hSxi is controlled by the
integral
I L
ð Þ ¼
Z
p
a
p
L
dkkd3:
ð31Þ
The behavior of I(L) strongly depends on the
dimension d. For d < 2 we have I(L)  L2d
! 1 as L ! 1. Hence, hSxi ¼ 0 in the limit of
large systems for dimensions less than 2. For
d > 2 we have that
I L
ð Þ ! A ¼
1
d  2
p
a
 d2
ð32Þ
and therefore
Sx
h
i ¼ exp

Sd
2Ja2d AT

	
> 0:
ð33Þ
Finally for d ¼ 2 the integral I(L) is logarith-
mically divergent I(L) ¼ ln(L/a) which is sufﬁ-
cient to force hSxi to zero for any non-zero
temperature.
We conclude that there is no ordered phase
according to the behavior of hSxi at low tempera-
ture for d  2. For d < 2 this means that there is no
phase transition. The same was for a while
thought to be the case for d ¼ 2. Since the thermal
motion included in the calculation of hSxi is able
to prevent a preferred direction and hence ensure
hSxi ¼ 0 for T > 0 including other types of
excitations, such as vortices, can surely not make
hSxi different from zero. So it is safe to conclude
that the rotors are unable to order along a common
direction for any non-zero temperature and it was
accordingly expected that a phase transition in the
2d YX-model was excluded. This conclusion was
reached since in magnetic systems the average of
the local magnetic moment, i.e. hSxi is the order
parameter and the phase transition takes place at
the
temperature
where
the
order
parameter
changes from zero to a nonzero value. It turned
out that by identifying the vortices as emergent
collective excitations and by understanding their
physical effects, a phase transition of a new kind
was discovered in the 2d XY-model.
Vortex Unbinding
An indication of the importance of vortices as the
temperature is increased can be obtained from the
following simple and heuristic argument. We esti-
mate the free energy of a single vortex. The Helm-
holtz free energy is given by the difference between
the energy and the entropy multiplied by the
Complex Systems and Emergent Phenomena
11

temperature F ¼ E – TS. The energy is given by
Eq. (21). We estimate the entropy from the number
of places where we can position the vortex center,
namely on each of the (L/a)2 plaquette of the square
lattice, i.e., S ¼ kB ln(L2/a2). Accordingly, the free
energy is given by
F ¼ E0 þ pJ  2kBT
ð
Þ ln L=a
ð
Þ:
ð34Þ
For T < πJ/2kB the free energy will diverge to
plus inﬁnity as L ! 1. At temperatures T > πJ/
2kB the system can lower its free energy by pro-
ducing vortices: F !
 1 as L ! 1. This
simple heuristic argument points to the fact that
the logarithmic dependence on system size of the
energy of the vortex combines with the logarith-
mic dependence of the entropy to produce the
subtleties of the vortex unbinding transition.
Assume a different dependence of the energy on
system size and one will either have thermal acti-
vation of vortices at all temperatures (in case
Evor ! const. < 1) or vortices will not be acti-
vated at any temperature (in case Evor ~ (L/a)b
with b > 0). It is the logarithmic size dependence
of the 2d vortex energy that allows the outcome of
the competition between the entropy and the
energy to change qualitatively at a certain ﬁnite
temperature TKT.
In reality it is not single vortices of the same
sign that proliferate at a certain temperature. What
happens is that the larger vortex pairs which are
bound together for temperatures below TKT
unbind at TKT. This is a collective effect that can
be treated quantitatively by use of a special
Renormalization
Group
method
design
by
Kosterlitz (Kosterlitz 1974). The vortex pairs
induced as one approaches TKT disturb the phase
ﬁeld so much that the effective value of the vortex
binding term E1 in the vortex pair free energy, that
is Eq. (22) generalized to non-zero temperature, is
driven to zero for large vortex separations. In the
next section we shall see in detail how this
happens.
The Spin Wave Stiffness
As our concern in this article is with emergent
entities, we will now brieﬂy discuss how a focus
on, and an understanding of, the vortex degrees of
freedom makes it possible to identify and describe
the previously “hidden” phase transition in the 2d
XY-system.
The effect of the thermally activated vortex
pairs is describe by the temperature dependent
spin wave stiffness rR
s . This is an example of
what Philip W. Anderson calls a generalized rigid-
ity (Anderson 1984). The spin wave stiffness
describes how much free energy it costs to apply
a twist, or gradient, to the rotors (also called spins):
y r
ð Þ ¼ y0 r
ð Þ þ vex  r,
ð35Þ
here θ0(r) is allowed to vary according to the
canonical ensemble. The increase in the free
energy is given by
F vex
ð
Þ  F 0
ð Þ ¼ 1
2 VrR
s v2
ex:
ð36Þ
A number of comments concerning the nota-
tion are illuminating. The notation vex for the
gradient applied to the phase ﬁeld θ(r) has its
origin in the fact that the same physics, as we
describe here, applies to superﬂuid ﬁlms and
superconducting ﬁlms. In these cases the ﬁeld
θ(r) is the phase of the complex order parameter,
the wave function of the super-ﬂuid. Being the
phase of a quantum mechanical wave function the
gradient of θ(r) is related to a probability current
and thereby to the velocity ﬁeld of the superﬂuid.
The notation rR
s is meant to remind one that this
phase rigidity, is determined by the density of
superﬂuid in the case of a superﬂuid or a super-
conductor. The superscript R in rR
s indicates that
thermal excitations renormalize the quantity. It
follows immediately from the Hamiltonian in
Eq. (12) that at zero temperature rR
s ¼ J ¼ rs .
The spin wave stiffness is similar to the shear
constant of a material. The shear constant deter-
mines how the (free) energy increase when a shear
deformation
is
imposed.
As
temperature
is
increased the shear constant decreases and drops
abruptly to zero when the solid melts into a liquid.
To obtain rR
s one calculates the left hand side of
Eq. (36). Details can be found in the wonderful
book by Chaikin and Lubensky (1995). The phase
ﬁeld is split into two parts
12
Complex Systems and Emergent Phenomena

y0 r
ð Þ ¼ ys r
ð Þ þ yv r
ð Þ,
ð37Þ
where the ﬁrst term describes smooth spin waves
and the second term contains the singular vortex
contribution. The free energy is obtained from
F ¼ kBT ln Z and the partition function is given
by Eq. (13). To calculate Z introduce Fourier
transforms of the phase ﬁeld. After quite a bit of
algebra one arrives at the following simple
expression
rR
s ¼ rs  1
2
r2
s
T lim
k!0
^n k
ð Þ^n k
ð
Þ
h
i0
k2
,
ð38Þ
which expresses the renormalized stiffness in
terms of the correlation function of the Fourier
transform of the vortex density function
n r
ð Þ ¼
X
a
nad r  ra
ð
Þ,
ð39Þ
for a collection of vortices of charge nα (see
Eq. (16)) with centers located at positions rα.
The vortices are now described entirely by their
position exactly like if they were ordinary
particles. So what started out as a complex con-
ﬁguration in the ﬁeld of rotors is now possible to
treat as point particles. The effect of the extended
disturbance of the rotor ﬁeld is taken care of by the
interaction energy between two vortices. The ther-
modynamic average in Eq. (38) is over the canon-
ical ensemble with no twist imposed, hence the
subscript 0. Eq. (38) can be used to determine how
the spin wave stiffness behaves at large distances
as a function of temperature. We will discuss how
in the next section.
The KT Transition
Let us ﬁrst summarize the phenomenology of the
Kosterlitz–Thouless transition. As the tempera-
ture is increased more and more vortex pairs are
thermally activated. This makes rR
s decrease, see
Eq. (38). This corresponds to a decrease in the
increment of the free energy induced by a certain
twist vex. We can understand the effect from the
fact that the phase ﬁeld θ(r) becomes more and
more distorted as the temperature is increased,
hence the extra perturbation caused by vex
becomes relatively less important. Quantitatively
one ﬁnds
rR
s ¼
rR
s T
KT


1 þ const: TKT  T
ð
Þ1=2
h
i
for T < TKT
0
for T > TKT:
(
ð40Þ
Here, TKT is the Kosterlitz–Thouless tempera-
ture at which vortex pairs unbind. The value of
TKT differs from one system to another. In the 2d
XY-model TKT/J ’ 0.893  0.002 (Olsson and
Minnhagen 1991). The remarkable thing is, that
the ratio
rR
s T
KT


=TKT ¼ 2=p
ð41Þ
is universal for all systems that undergoes a
KT-transition. Since rR
s Tþ
KT
ð
Þ ¼ 0
Eq. (41) is
referred to as the universal jump. The correlation
length x(T) behaves in a very unusual way as one
approaches TKT from above. We are used to a
relatively
slow
algebraic
divergence
of
the
correlation length as the critical temperature is
approached. For the KT-transition the divergence
is, however, much faster
x T
ð Þ  exp
const:
T  TKT
ð
Þ1=2
 
!
for
T > TKT:
ð42Þ
Can we in a simple way understand this expo-
nential divergence? Yes, we can. The phase ﬁeld is
signiﬁcantly distorted by unbound vortices, since
these vortices are not screened by a nearby anti-
vortex. I.e. the phases θ(r) can remain correlated
over distances shorter than the typical distance
D ¼ 1=
ﬃﬃﬃﬃﬃﬃ
nub
p
between unbound vortices of density
Complex Systems and Emergent Phenomena
13

nub (Jensen and Weber 1992). Or in other words,
we expect the correlation length x ~ D. The vor-
tices are thermally induced and therefore their
density is expected to depend on the temperature
through a Boltzmann factor exp(Evor/T). The
situation described here is exactly what happens
in the one-dimensional so-called f4 model. This
model supports thermally activated solitons. The
correlation length is set by the inverse of the
soliton density and diverges exponentially as the
temperature goes to zero (Jensen and Fogedby
1985). The same thing, in a slightly simpler ver-
sion, also happens in the one-dimensional Ising
model. This argument can indicate the cause of the
exponential dependence of x. But it is no more
than an indication since the exponential depen-
dence in Eq. (42) is signiﬁcantly different from a
simple Boltzmann factor. This difference is due to
corrective renormalization effects.
Continuous phase transitions are accompa-
nied by divergences in thermodynamic quantities
caused by the divergence of the correlation
length as the critical temperature Tc is app-
roached. The singular part of the free energy
density f can be estimated as the amount of ther-
mal energy Tc within a correlated volume xd,
which gives f ~ Tc/xd. The speciﬁc heat cV is
given by the second derivative of the free
energy cV ¼  T@2f/@T2  @2xd@T2. For the
KT-transition the exponential divergence of x(T)
in Eq. (42) is so rapid and occur over such a
narrow temperature range that the divergence in
cV cannot be resolved in simulations or in exper-
iment. This is another reason why the vortex
unbinding transition remained unnoticed for so
long. It doesn’t leave any dramatic signature in
the thermodynamic quantities. However, as men-
tioned above, the macroscopic rigidity clearly
changes at the transition.
The Vortex Unbinding Transition in
Other Systems
We have above mentioned that not only the
XY-model exhibits the Kosterlitz–Thouless vortex
unbinding transition (Minnhagen 1987). Any
two-dimensional system that supports thermally
induced “charges” or topological defects that
interact logarithmically will undergo this transi-
tion. The U(1) symmetry of the phase ﬁeld θ(r) of
the XY-model is also present in the Ginzburg–
Landau free energy of superﬂuids and of super-
conductors. The topological excitations in the
case of a superﬂuid consist of vortices in the
ﬂow
of the
superﬂuid.
Vortices
like
those
observed when one empties a bath tub. In thin
superﬂuid helium ﬁlm such vortices destruct the
superﬂuid phase with increasing temperature
according to the scenario of the KT-transition
(Ambegaokar et al. 1978, 1980).
The situation is slightly more complicated in
superconductors. Because the superﬂuid in this
case is charged (the superconducting pairs of elec-
trons), screening effects play a role (Chaikin and
Lubensky
1995;
Tinkham
2004;
Minnhagen
1987). However, for thin superconducting ﬁlms
of thickness δ the effective screening length is
given by leff ¼ l2/δ, which can easily become a
macroscopic length. In this case the loss of super-
conductivity is caused by the unbinding of vortex
pairs according to the KT-transition. The broken
pairs can move freely when they respond to an
applied electric current. As they move they cause
phase slips in the superconducting order parameter.
These phase slips induce a voltage drop according
to the Josephson relation. The superconductor is
now unable to support an electric current without a
voltage drop, i.e. it is not a superconductor any
longer (Kadin et al. 1983; Huberman et al. 1978;
Doniach and Huberman 1979; Beasley et al. 1979).
Dislocations
in
two-dimensional
crystals
interact through the strain ﬁeld. Two edge dislo-
cations of opposite sign correspond to an extra
row of atoms inserted along the line connecting
the location of the two dislocation cores. The
extra line of atoms produces strain and leads to
an increase in the energy which is logarithmic in
the separation between the two dislocations.
Thus, the situation is very similar to the one
encountered in the XY-model. When the disloca-
tions unbind, free dislocations are produced.
A shear applied to the system can now be accom-
modated by the mobile dislocations without an
increase in the (free) energy. I.e., the shear con-
stant has dropped to zero and the system is
14
Complex Systems and Emergent Phenomena

melted. The 2d melting theory of Kosterlitz–
Thouless–Halperin–Nelson–Young predicts that
melting occurs in two stages. At the ﬁrst stage
dislocations unbind and make the shear constant
drop to zero. The dislocations are topological
defects, their effect on the order of the lattice
are, however, not very dramatic. Before the
unbinding of dislocations, the translational and
the orientational order of the lattice are both
described by correlation functions that depend
algebraically on distance. When the dislocations
unbind the translational correlation function
becomes
exponential
but
the
orientational
correlations remain algebraic. At a somewhat
higher temperature topological defects called
disclinations unbind with the effect that the ori-
entational order becomes exponential. Details
can be found in Chaikin and Lubensky (1995).
There are many other cases where the loga-
rithmic vortex interaction and the KT-transition
play a role. For instance, the shape of surfaces
in three dimensions may undergo a transition
from smooth to rough (Barabási and Stanley
1995). Assume that the surface energy of the
two-dimensional surface is proportional to the
area of the surface. And assume that the surface
is deﬁned in terms of its height h(x, y) above
the xy-plane, i.e. no over hangs. In other words
the points on the surface have the coordinates
(x, y, h(x, y)). The Hamiltonian for the surface
is then
H ¼ s
Z
dx
Z
dy
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
1 þ ∇h
ð
Þ2
q
:
ð43Þ
Here s is a measure of the surface tension. If
the height only varies slowly as a function of (x, y)
we can assume |∇h|  1 and then expand the
square root. In this approximation the Hamilto-
nian in Eq. (43) can be written as
H ¼ sL2 þ 1
2
Z
dx
Z
dy ∇h
ð
Þ2,
ð44Þ
(L is the linear size of the system in the
xy-plane) which is equivalent to Eq. (19), and we
expect the same physical phenomenology to
apply to the surface as we found for the XY-model.
Non-Equilibrium Systems
The Boltzmann probabilities cannot be used to
calculate the macroscopic properties when we
deal with situations that have no equivalence
among systems in contact with a heat bath. At
present there is no general procedure for the deter-
mination of the probability weights of the individ-
ual microstates. This doesn’t mean that statical
mechanics can’t describe how macroscopic prop-
erties emerge in systems out of equilibrium.
Indeed approaches of broad interest exist. Here
we will brieﬂy introduce the use of Langevin
equations and algorithmic models through two
concrete simplistic models. The ﬁrst is inspired
by the very long memory or correlation times
often observed in complex systems. We will dis-
cuss slow ﬂowing motorway trafﬁc. The other is
concerned with the emergence of self-organized
structures among interacting living organisms.
Speciﬁcally we will think of the formation of ant
trails.
1/f Fluctuations: A Langevin Approach
In this section we describe an example of emer-
gence in time. We will assume that interaction
between the components of our system forces
these to diffuse around, rather than to move
around in a ballistic manner. The result is a time
signal that contains very strong correlations and is
characterized by what is denoted a 1/f power spec-
trum (Milotti 2008).
We want to study correlations in a time signal
f (t). We measure the signal again and again at two
times separated by T time units. To make life
simple we will neglect the normalization factor in
the empirical averages, i.e. we don’t divide by the
number of terms in the sum in Eq. (45) below.
A justiﬁcation for this is that we are interested in
the functional dependence of the correlations on
the time interval Tand not so much interested in the
actual speciﬁc value of the correlation coefﬁcient.
Since the correlation coefﬁcient will depend on
Twe talk about the correlation function. Moreover,
since we are correlating the signal with itself we
talk about the autocorrelation function given by:
Complex Systems and Emergent Phenomena
15

C T
ð Þ ¼
X
t
f tð Þ 
f tð Þ
h
i
½
 f t þ T
ð
Þ 
f t þ T
ð
Þ
h
i
½

¼
Z
dt f tð Þ 
f tð Þ
h
i
½
 f t þ T
ð
Þ 
f t þ T
ð
Þ
h
i
½

¼
Z
dt f tð Þ 
f tð Þ
h
i
½
 f t þ T
ð
Þ 
f tð Þ
h
i
½
:
ð45Þ
In the last equality we made use of the fact that
the average of value f (t) and f (t þ T) are identical.
The autocorrelation function is an important
object for the study of memory effects or causality
effects in a signal. The correlation function is
equivalent to the power spectrum. The power
spectrum of the signal f(t) is deﬁned as
S f o
ð Þ ¼ ^f o
ð Þ

2:
ð46Þ
That is the absolute value squared of the Fou-
rier transform of the signal and the power spec-
trum is related to the Fourier transform of the
autocorrelation function:
S f o
ð Þ ¼ ^C o
ð Þ:
ð47Þ
This relation explains why power spectra that
approximately depend inversely proportional on
the frequency
S f o
ð Þ / 1=ob,
ð48Þ
with β ’ 1, are of special interest (Press 1978;
Weissman 1988; Grinstein et al. 1992). Namely, at
a somewhat heuristic level, we can substitute
Eq. (48) into Eq. (47) and then into
C T
ð Þ ¼
Z 1
1
do ^C o
ð Þeiot,
ð49Þ
to obtain
C T
ð Þ ¼
Z 1
1
doobeioT
ð50Þ
¼ T1b
Z 1
1
duubeu:
ð51Þ
We made the substitution u ¼ oT and note that
the integral in the above equation now is indepen-
dent of T. So when β ’ 1, the correlation function
C(T) depends very weakly on T meaning very
slow decay of correlations. This indicates the par-
ticular interest in power spectra that approxi-
mately decays as one over the frequency – called
1/f noise. The way we carried the argument
through is slightly dangerous due to possible
divergent integrals; the conclusion is, however,
sound.
Transport by Diffusion
For concreteness imagine a piece of motorway stre-
tching from x ¼ 1 to x ¼ 1. At x ¼ 0 vehicles
can enter or leave at an intersection. We will
develop a model for the time evolution of the
density of cars n(x, t) at position x at time t. Since
the cars – particles – only can leave or enter our
system at x ¼ 0, at all other positions, x 6¼ 0,
changes during a brief time interval δ in
the number of particles in a small interval
[x, x þ δx] about x
dn x, t
ð
Þ ¼ n x, t þ dt
ð
Þdx  n x, t
ð
Þdx
ð52Þ
will be caused by a difference during the time δt
between the number of particles leaving the sec-
tion [x, x þ δx] at x þ δx and the number of
particles entering the section at x. Let J(x, t)
denote the particle current (number of particles
crossing the position x at time t per time unit).
We can then write
dn x, t
ð
Þ ¼ J x þ dx, t
ð
Þdt  J x, t
ð
Þdt:
ð53Þ
Substituting Eq. (53) into Eq. (52) we obtain
n x, t þ dt
ð
Þdx  n x, t
ð
Þdx ¼ J x þ dx, t
ð
Þdt þ J x, t
ð
Þdt
+
ð54Þ
@n x, t
ð
Þ
@t
¼  @J x, t
ð
Þ
@x
:
ð55Þ
The last equation follows in the limit δx ! 0
and δt ! 0.
16
Complex Systems and Emergent Phenomena

This equation is exact and only assumes con-
servation of the particles. To obtain a closed equa-
tion for n(x, t) we need to relate J(x, t) to n(x, t).
And to do so we need to make assumptions
concerning the nature of how the particles, or
cars, move along the line. Let us imagine that
congestion makes it impossible for cars to move
freely. On the contrary assume that the drivers are
forced to effectively perform random walks;
i.e. diffuse along the motorway.
We emphasize that it is through this assump-
tion that the cars, or particles, are made to
interact. Here we assume that the diffusion is
a
result
of
over-crowding
and
interaction
amongst the cars. Obviously particles might
perform diffusive motion as a result of other
interactions. Pollen in water diffuses because it
is bombarded by large numbers of water mole-
cules. In any case some sort of complex inter-
action
is
always
responsible
for
diffusive
motion since the particles otherwise would
move around according to Newton’s laws. The
model might in fact be more relevant to small
particles (pollen, say) suspended in a long nar-
row strip of water – or something else.
To model the jamming and resulting diffusive
motion, we will assume that the net particle cur-
rent (at coarse grained level) is from high particle
density to low particle density, and linear in the
density difference. We express this as
J x, t
ð
Þ ¼ g @n x, t
ð
Þ
@x
:
ð56Þ
We combine Eq. (55) and Eq. (56) to obtain a
closed form of dynamical equation for n(x, t):
@n x, t
ð
Þ
@t
¼ g @2n x, t
ð
Þ
@x2
:
ð57Þ
This is the well-known diffusion equation.
It describes how inhomogeneities in the density
n(x, t) relaxes by diffusion. The equation describes
a closed system. Next we include the particles that
might be added or removed at a certain rate g(x, t) at
position x at time t. According to the description
above we have in particular in mind that g(x, t)
must describe cars leaving and entering at x ¼ 0.
We will later return to how this particular require-
ment can be imposed on g(x, t). We now have our
ﬁnal equation of motion for n(x, t)
@n x, t
ð
Þ
@t
¼ g @2n x, t
ð
Þ
@x2
þ g x, t
ð
Þ:
ð58Þ
This is an inhomogeneous partial differential
equation and we solve it easily by Fourier
transformation
n x, t
ð
Þ ¼
Z 1
1
dk
2p
Z 1
1
do
2p ^n k, o
ð
Þei kxþot
ð
Þ: ð59Þ
Substitute into Eq. (58) to obtain an expression
for ^n k, o
ð
Þ in terms of the Fourier transform of
the drive ^g k, o
ð
Þ
^n k, o
ð
Þ ¼ ^g k, o
ð
Þ
io þ gk2 :
ð60Þ
Now substitute Eq. (60) into Eq. (59):
n x, t
ð
Þ ¼
Z 1
1
dk
2p
Z 1
1
do
2p
^g k, o
ð
Þ
io þ gk2 ei kxþot
ð
Þ:
ð61Þ
Next we want to focus on the density ﬂuctua-
tions at a speciﬁc position x0 > 0. Therefore we
deﬁne
N tð Þ 	 n x0, t
ð
Þ  n x0, t
ð
Þ
h
it,
ð62Þ
where we have subtracted the temporal averaged
density. We will determine the power spectrum of
N(t) and for this purpose need the Fourier
transform
^N o
ð Þ ¼
Z 1
1
dtN tð Þeiot
ð63Þ
¼
Z 1
1
dt n x0, t
ð
Þeiot  n x0, t
ð
Þ
h
it
Z 1
1
dt eiot
ð64Þ
Complex Systems and Emergent Phenomena
17

¼
Z 1
1
dk
2p
^g k, o
ð
Þ
io þ gk2 ei k x0
 n x0, t
ð
Þ
h
itd o
ð Þ:
ð65Þ
That is how far we can go without further
assumptions concerning the nature of the drive
g(x, t). Since this source term is meant to represent
vehicles entering and leaving at position x ¼ 0 we
will now use
g x, t
ð
Þ ¼ d x
ð Þw tð Þ ) ^g o
ð Þ ¼ ^w o
ð Þ:
ð66Þ
We then have that for x 6¼ 0 the source g(x, t) ¼ 0
and at x ¼ 0 the temporal variation in the ﬂow onto
and away from the “motorway” is given by w(t).
From Eq. (65) we get
^N o
ð Þ ¼ ^w o
ð Þ
Z 1
1
dk
ei k x0
io þ gk2 :
ð67Þ
The power spectrum is ﬁnally calculated as the
absolute value square of ^N o
ð Þ
^N o
ð Þ

2 ¼ ^w o
ð Þ
j
j2
4go
e
ﬃﬃﬃ
2o
g
p
x0:
ð68Þ
The power spectrum of the density ﬂuctuations
is clearly inﬂuenced by the power spectrum of
w(t). Let us assume that vehicles enter and leave
at the intersection in a totally uncorrelated manner
(perhaps not a totally realistic assumption) which
translates into ^w o
ð Þ
j
j2 ¼ constant. In this case
^N o
ð Þ

2 / 1
o e
ﬃﬃﬃ
2o
g
p
x0:
ð69Þ
For frequencies so small that
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
2o
ð
Þ=g
p
x0 < 1
we have exp 
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
2o
ð
Þ=g
p
x0


’ 1 and therefore
^N o
ð Þ

2 / 1
o
for
o < g
2x2
o
	
1
2Tdiff :
ð70Þ
Where we introduced the time scale Tdiff ¼
x2
o=g. This is the characteristic time it takes for
particles, undergoing diffusion with a diffusion
constant γ, to move from x ¼ 0 to x ¼ x0.
Very long temporal correlations, as indicated
by the 1/f behavior of the power spectrum, is
observed in very many and diverse situations:
the light intensity from quasars, the ocean current,
the pitch or pressure ﬂuctuations in speech and
music, the ﬂow of trafﬁc, the ﬂuctuations in the
resistivity of a conductor, and many more (Press
1978; Weissman 1988). Is the model we have
sketched above able to explain the observed 1/f
correlations in all these many different systems?
No, probably not. Surface driven diffusion
doesn’t seem to be central to all these situations.
The question whether a general explanation for 1/f
exists is still an open one.
We have considered 1/f ﬂuctuations here for
mainly two reasons. It is a fascinating problem
which is often encountered in complex systems
and our discussion illustrates how one can use
stochastic differential equations to go beyond
equilibrium statistical mechanics to analyze tem-
poral emergent behavior.
Self-Organized Structure Formation: Ant
Trails
As our next example of non-equilibrium statistical
mechanics and emergence in complex systems we
will
brieﬂy
consider
an
algorithmic
model
inspired by ant trail formation. The model is sche-
matic, simplistic and its relevance to the actual
mechanism involved when real ants form trails is
Complex
Systems
and
Emergent
Phenomena,
Fig. 2 Cars/particles diffusing up and down a motorway
stretching from x ¼ 1 to x ¼ 1. At x ¼ 0 an intersection
allows the vehicles to enter or leave the motor way. At x ¼ x0
a trafﬁc warden is monitoring the number of vehicles, N(t),
in front of him
18
Complex Systems and Emergent Phenomena

not known in detail. Nevertheless, the model is an
interesting example of how emergent structures
can appear from a dynamical algorithm.
The model describes how the path selected by
ants gradually converge towards the shortest path
between the nest and a location of food, as a result
of ants’ tendency to walk around at random com-
bined with a preference for following the smell
(the pheromone trail) left behind by preceding
ants (Camazine et al. 2001; Solé and Goodwin
2000). The model discussed here is presented
by Danilo Benzatti at http://ai-depot.com/
CollectiveIntelligence/Ant.html; but a rich litera-
ture on individual based models of formation of
patterns by social insects exists (Camazine et al.
2001; Solé and Goodwin 2000; Schweitzer et al.
1997; Bonabeauc et al. 1998; Feltell et al. 2006).
We imagine a network of possible paths around
the ant nest (see Fig. 3).
The nest is located at one node. Around the
nest many edges connect a system of nodes. The
ants can only move along the edges and in this
way travel from node to node. At some of the
nodes food is present. Often more than one possi-
ble route will lead from the nest to the food. How
do ants, with no global overview and no sophisti-
cated means of measuring traveled distance, iden-
tify the shortest route from the nest to a food
position? The assumption is that all what an indi-
vidual ant is able to do is:
(1) Ant Motion: Perform random walks.
(2) Effect of ant on path: Lay down a unit of
pheromone when traversing an edge.
(3) Feedback: Feel attracted to pheromones
deposited on the edges. The more phero-
mones the more an ant is attracted to an
edge; and the more likely it is that the ant
chooses to walk along that edge.
(4) Return to nest: When food is found the ant
follows its own pheromone trail back to
the nest.
The
reason
this
algorithm
can
converge
towards the shortest path, is that the shortest path
between the nest and the location of the food will
have more ants traveling along its edges per time,
and therefore will have a higher pheromone con-
centration than the longer paths.
The details of the algorithm is as follows. Let
the nodes be enumerated by i ¼ 1, 2, . . ., N. Let
edges between node number i and node number
j be labeled Eij. Each edge carries a time-
dependent pheromone weight f(Eij, t).When an
ant traverses an edge it deposits one unit of pher-
omone leading to
f Ei j, t


7! f Ei j, t þ 1


¼ f Ei j, t


þ 1:
ð71Þ
At each node the ants chose probabilistically
between the edges sprouting from the node. The
probability p(Eij, t) that an ant chooses a certain
edge Eij among all the edges connected to a spe-
ciﬁc node number i is given by
p Ei j, t


¼
f Ei j, t


P
lf Eil, t
ð
Þ :
ð72Þ
At the start of the simulation all ants are in the
nest. Next they begin their random exploration of
the network. When an ant locates the food, it picks
up a unit of food and returns to the nest along the
path it followed on its way out. On the return
journey
pheromones
are
also
laid
down,
Complex
Systems
and
Emergent
Phenomena,
Fig. 3 A network of possible paths the ants can choose
between as they travel from the nest at N to the food at F.
The green short path will maintain a high level of phero-
mones, and will continue to attract ants, while the longer
red path will gradually sustain a high level of pheromones
and will therefore cease to attract ants
Complex Systems and Emergent Phenomena
19

reinforcing this speciﬁc path. Finally it is assumed
that the pheromones evaporate at a constant rate,
say,
f Ei j, t


7! f Ei j, t þ 1


¼ f Ei j, t


 nY Eij, t


:
ð73Þ
(Note the Θ-function [deﬁned as Θ(x) ¼ 1 for
x > 0 and Θ(x) ¼ 0 for x  0] ensures that the
evaporation stops when there are no more phero-
mones on an edge, i.e. when f(Eij ¼ 0.) Thus,
paths rarely used will lose their pheromone signa-
ture and will not be attractive to the ant, whereas
the pheromone level will be maintained along the
more often used paths. Thus, the shorter paths
with a more frequent ant-trafﬁc will prevail over
the longer paths, since the ants on the latter paths
visit the individual edges less frequently.
The collective effect of this algorithm is to ﬁnd
the shortest path between nest and food, although
the individual ant doesn’t need to know that this is
what is going on. For more detail see (Benzatti)
and for modeling of emergent collective intelli-
gence and pattern formation amongst social
insects (see Camazine et al. 2001; Solé and
Goodwin
2000;
Schweitzer
et
al.
1997;
Bonabeauc et al. 1998; Feltell et al. 2006). It is
still an open question how to represent algorith-
mic models, like the one described in this section,
in a precise way.
Summary and Future Directions
We have described a speciﬁc example where one
can follow in great detail the steps from one level
of structure to the next in the hierarchical order of
matter. Topological defects arise as coherent
structures of the “atoms” at one level and can be
considered as (composite) particles at the next
level. Their interaction can be derived from the
behavior of the constituent “atoms”. Many differ-
ent systems may support composite particles that
interact in the same way. We looked in particular
at vortex physics, where the Kosterlitz–Thouless
transition is caused by the logarithmic interaction
between the topological defects. The one most
important fact in determining the KT-transition is
that both energy and entropy depend logarithmi-
cally on length scale for the two-dimensional
topological charges. This example is hoped to
make clear that within equilibrium statistical
mechanics emergent phenomena can be described
and analyzed in great quantitative detail.
When we move to systems out of equilibrium,
which of course by far constitute the majority, no
universally applicable formalism exists so far. We
illustrated, however, by two very different exam-
ples that emergent collective behavior produced
by interactions between components can also in
non-equilibrium situations be modeled either by
use
of
various
mathematical
techniques
or
through the application of computer simulations.
I will ﬁnish by suggesting the following con-
clusion. There is nothing mysterious about emer-
gent phenomena. They are a wonderful thing – but
they are not of new character, something science
never has seen or dealt with before. On the con-
trary, I will claim that understanding emergent
phenomena is exactly what all science is aimed
at. Often this is not so explicitly clear as in the
examples discussed above where the emphasis is
explicitly on the macroscopic, or systems level,
effects of the interactions between the compo-
nents constituting the system. Nevertheless, even
when one studies, say, atomic physics (as in con-
trast to statistical physics), one is dealing with the
effect of interacting components. An atom con-
sists after all of interacting protons, neutrons and
electrons and the properties of the atom are the
emergent result of the interactions between these
particles.
Notwithstanding, the focus of the statistical
mechanics approach is towards generality. As
illustrated by our discussion of the XY-model and
the Kosterlitz–Thouless transition, the same phe-
nomenology can be observed in many very differ-
ent
systems
with
very
different
types
of
components (magnetic moments, atoms in a lat-
tice, superﬂuids etc.), if the interactions between
the components possess equivalence at a mathe-
matical level. It is this generality that leads people
20
Complex Systems and Emergent Phenomena

to suggest that even simple model studies may
sometimes be of relevance to seemingly much
more complicated situations. In the future we
are bound to see the statistical mechanics
approach to emergent phenomena being applied
to a much broader range of problems than was
traditionally the case. We see attempts in ﬁelds
like biology and economics, but also in linguis-
tics, to develop pertinent statistical mechanics
models. Examples include phenomena ranging
from gene regulation to the social behavior of
insect colonies and from stock market ﬂuctua-
tions to management of logistics. So far statisti-
cal mechanics has mainly been developed under
the inﬂuence of physics and methods like the
Renormalization Group arose. It will be very
interesting to follow how statistical mechanics
broadens its arsenal of tools as emergent phe-
nomena in other ﬁelds are approached from the
viewpoint of statistical mechanics.
Acknowledgments I am deeply grateful to many people
with whom I have collaborated and learnt from during
many years concerning matters relevant to the topic of
the present article. In particular it is a pleasure to mention
Hans Fogedby, Peter Minnhagen, and Hans Weber.
Bibliography
Ambegaokar V, Halperin BI, Nelson DR, Siggia ED
(1978) Dissipation in two-dimensional superﬂuids.
Phys Rev Lett 40:783–786
Ambegaokar V, Halperin BI, Nelson DR, Siggia ED
(1980) Dynamics of superﬂuid ﬁlms. Phys Rev B 21:
1806–1826
Anderson PW (1972) More is different. Science 177:
393–396
Anderson PW (1984) Basic notions of condensed matter
physics. Benjamin/Cummings, Menlo Park
Barabási A-L, Stanley HE (1995) Fractal concepts in sur-
face growth. Cambridge University Press, Cambridge
Beasley MR, Mooij JE, Orlandon TP (1979) Possibility of
vortex-antivortex pair dissociation in two-dimensional
superconductors. Phys Rev Lett 42:1165–1168
Benzatti D. http://ai-depot.com/CollectiveIntelligence/
Ant.html
Binney JJ, Dowrick NJ, Fisher AJ, Newman MEJ
(1992) The theory of critical pnenomena. An introduc-
tion to the renormalization group. Oxford University
Press, Oxford
Bonabeauc E, Theraulaz G, Deneubourg J-L, Franks NR,
Rafels-berger O, Joly J-L, Blanco S (1998) A model
for the emergence of pillars, walls and royal chambers
in termite nests. Philos Trans R Soc B 353:1561–1576
Camazine S, Deneubourg J-L, Franks NR, Sneyd J,
Theraulaz G, Bonabeau E (2001) Self-organization in
biological
systems.
Princeton
University
Press,
Princeton
Cataudella V, Minnhagen P (1990) Simple estimate for
vortex ﬂuctuations in connection with high-tc super-
conductors. Physica C 166:442–450
Chaikin PM, Lubensky TC (1995) Principles of condensed
matter
physics.
Cambridge
University
Press,
Cambridge
Doniach S, Huberman BA (1979) Topological excitations
in two-dimensional superconductors. Phys Rev Lett 42:
1169–1172
Feltell D, Bai L, Jensen HJ (2006) An individual approach
to modeling emergent structure in termite swarm sys-
tems. Int J Model Identif Control 1:43–54
Grinstein G, Hwa T, Jensen HJ (1992) 1/f α noise in
dissipative transport. Phys Rev A 45:R559–R562
Huberman BA, Myerson RJ, Doniach S (1978) Dissipation
near the critical point of a two-dimensional superﬂuid.
Phys Rev Lett 40:780–782
Jensen HJ, Fogedby HC (1985) Phonon-kink interference
in the ’4 model. Phys Scr 31:210–214
Jensen HJ, Weber H (1992) A phenomenological study of
vortices in a two dimensional xy-model in a magnetic
ﬁeld. Phys Rev B 45:10468–10472
Kadanoff LP (2000) Statistical physics. Statics, dynamics
and renormalization. World Scientiﬁc, Singapore
Kadin
AM,
Epstein
K,
Gildman
AM
(1983) Renormalization and the Kosterlitz–Thouless
transition in a two-dimensional superconductor. Phys
Rev B 27:6691–6702
Kosterlitz JM (1974) The critical properties of the two-
dimensional xy model. J Phys C Solid State Phys 7:
1046–1060
Kosterlitz JM, Thouless DJ (1973) Ordering, metastability
and phase transitions in two-dimensional systems.
J Phys C Solid State Phys 6:1181–1203
Milotti E 1/f noise: a pedagogical review. Available via
DIALOG http://arxiv.org/pdf/physics/0204033. Accessed
10 July 2008
Minnhagen P (1987) The two-dimensional coulomb gas,
vortex
unbinding,
and
superﬂuid-superconducting
ﬁlms. Rev Mod Phys 59:1001–1066
Minnhagen P, Olsson P (1991) Monte Carlo calculation of
the vortex interaction for high-tc superconductors. Phys
Rev B 44:4503–4511
Nelson DR (2002) Defects and geometry in condensed
matter
physics.
Cambridge
University
Press,
Cambridge
Olsson P, Minnhagen P (1991) On the helicity modulus, the
critical temperature and Monte Carlo simulations for
the two-dimensional xy-model. Phys Scr 43:203–209
Complex Systems and Emergent Phenomena
21

Press WH (1978) Flicker noises in astronomy and else-
where. Comments Mod Phys C 7:103–119
Reif F (1965) Fundamentals of statistical and thermal
physics. McGraw-Hill, New York
Schweitzer F, Lao K, Family F (1997) Active random
walkers
simulate
trunk
trail
formation
by
ants.
Biosystems 41:153–166
Shang-Keng M (1985) Statistical mechanics. World Scien-
tiﬁc, Singapore
Solé R, Goodwin B (2000) Signs of life, how complexity
pervades biology. Basic Books, New York
Sornette D (2004) Critical phenomena in natural sciences.
Chaos, fractals, selforganization and disorder: concepts
and tools. Springer, Berlin
Tinkham M (2004) Introduction to superconductivity,
2nd edn. Dover Publications, New York
Weber H, Jensen HJ (1991) Crossover from three- to two-
dimensional behavior of the vortex energies in layered
xy-models for high-tc superconductors. Phys Rev B 44:
454–457
Weissman MB (1988) 1/f noise and other slow, non-
exponential kinetics in condensed matter. Rev Mod
Phys 60:537–571
Wilson K (1982) The renormalization group and critical
phenomena. Available via DIALOG. http://nobelprize.
org/nobel_prizes/physics/laureats/1982/wilson-lecture.
html. Accessed 10 July 2008
22
Complex Systems and Emergent Phenomena

Polymer Physics
T. C. B. McLeish
Department of Physics, University of York,
York, UK
Article Outline
Glossary
Deﬁnition of the Subject
Introduction
Single Polymer Chain Physics
Equilibrium Properties of Many-Chain Fluids
Dynamics of Polymeric Fluids
Multiphase Polymeric Fluids
Future Directions
Bibliography
Glossary
R Radius of gyration of a polymer chain
N, M Degree of polymerization or number of
monomers in a polymer chain, molecular
weight
j The screening length or correlation length in
semi-dilute polymer solutions; the length over
which local density is dominated by a single
chain
Ne, Me Entanglement degree of polymerization
and molecular weight
lp Persistence length of polymer chain
n “Flory” exponent of a polymer chain relating
R and N so thatR~Nn
S(k) Scattering structure factor from a polymeric
ﬂuid
as
function
of
scattering
vector
k ¼ 4π sin θ/l where l is the wavelength and
θ the scattering angle of the experiment
P(c)
Osmotic pressure of a solution as a func-
tion of concentration c
sij Components of the stress tensor
d, D Dimensions of a macromolecular object and
its embedding space
R(n, t) Functional description of a macromolec-
ular contour as functions of monomer number
n and time t
G(t) Time-dependent relaxation modulus
h Viscosity
kB Boltzmann’s constant
x Flory interaction parameter between mono-
mers of different chemistry
Definition of the Subject
Physics is uniquely endowed among the sciences
with complete freedom from restriction to any
particular domain of the physical world. It is
able to turn its particular outlook on the scientiﬁc
program and its special set of experimental and
theoretical tools to most material phenomena. In
particular it is not limited to any particular length
scale, but is sensitive to the emergence of new
structures and processes of any size. So macro-
molecular science, born of the chemistry of the
early twentieth century, soon gave rise to a branch
of physics that seeks to understand the special
phenomena emerging from extremely large “poly-
mer” molecules and polymeric matter. Much of
the impetus behind a physics of polymers came
from the discipline’s developing theoretical tools,
such as ﬁeld-theory (born from quantum mechan-
ics), and the renormalization group (born from the
statistical mechanics of phase transitions), but in
new guise. Polymers are giant, usually linear mol-
ecules constructed as covalently bonded chains of
identical units, or monomers. Individual polymer
molecules may contain hundreds or even millions
of monomers. Initially disfavored by an organic
chemistry community that prized exactitude,
polymers were largely ignored since their molec-
ular weight was inexact within a single sample.
However, biology knew long before we did that
the properties of polymers met the essential
requirements
of
living
organisms.
Polymers
© Springer Science+Business Media, LLC, part of Springer Nature 2022
B. Chakraborty (ed.), Statistical and Nonlinear Physics,
https://doi.org/10.1007/978-1-0716-1454-9_409
Originally published in
R. A. Meyers (ed.), Encyclopedia of Complexity and Systems Science, © Springer Science+Business Media LLC 2021
https://doi.org/10.1007/978-3-642-27737-5_409-2
23

constitute nature’s scaffolds from the macroscopic
(bone, collagen) to the microscopic (ﬁlamentous
actin, polymerized tubulin), her force-generators
(myosin, dynein, and kinesin protein polymers),
her information-processing networks (peptide-
binding
proteins,
polysaccharides),
and
her
instruction sets (the nucleic acid family of poly-
mers including DNA). Much of the reason for this
lies in the unique set of physical properties of
polymeric matter. Some of these have now famil-
iar application in plastic materials from packaging
to high-performance ﬁber and even addressable
polymeric electronics. Yet polymer physics is
much more than the application of statistical
mechanics and spectroscopy to a class of molec-
ular matter; it has taught our discipline about some
of its own deep structural connections. Path-
integral techniques at the heart of theoretical poly-
mer physics were adopted from readily developed
tools in quantum ﬁeld theory and magnetism.
Flexible linear-like objects occur in many other
avenues of the subject, superconductivity, and
plasma turbulence to name two. Above all poly-
mer physics has provided us with a classic exam-
ple of emergent simplicity from bewildering
complexity, so beloved of our subject. It shows
every indication of providing in future an essential
Ariadne’s thread to guide us in our exploration of
complexity itself. It will certainly underpin the
urgent search for a sustainable plastics materials
economy. Like the human energy budget, fossil
fuel sources may serve to kick-start an advanced
materials technology, but cannot sustain it.
Introduction
The fascinating physics of ﬂexible polymers ﬂows
from both necessity and beauty. Born of the early
investigations into the phenomenon of the elastic-
ity of natural rubber (Kuhn 1936; Guth and Mark
1934), then out of the rapid growth in synthetic
polymer materials in the post-war years, the need
to understand and control the processing of such
highly viscoelastic liquids as polymer melts, and
to understand the properties of the resulting mate-
rials led rapidly to fundamental investigations led
by physicists who saw an opportunity to explore
the fundamental structures of a new class of mat-
ter. Flory (1953), Zimm and Stockmayer (1949),
and Edwards (1976) asked how large would mac-
romolecules, linear or branched, be, while Zimm
(1956) and Rouse (1953) asked how such giant
molecules would move. Paralleling developments
in solid-state many-body physics, the focus of
investigations moved from single-chain to many-
chain systems, which we review below in sections
“Single Polymer Chain Physics” and “Equilib-
rium Properties of Many-Chain Fluids.” These
pioneers were already using a beautiful notion
that was to take hold of condensed-matter physics
in the mid-twentieth century – that of universality,
or the independence of physical phenomena from
local, small-scale details. The emergence of uni-
versal properties is usually associated with “criti-
cal phenomena” (Zinn-Justin 1993), since near
phase transitions, the spatial scale of correlated
ﬂuctuations may hugely exceed molecular dimen-
sions. Any properties that depend on these ﬂuctu-
ations (an example would be compressibility of a
ﬂuid near its critical point, and especially the
exponent with which it vanishes as the tempera-
ture tends to its critical value) will then be insen-
sitive to molecular detail. In ﬁeld theories of both
condensed and high-energy matter, the ﬁeld-
ﬂuctuations “renormalize” microscopic constants
into new emergent numbers on which the physics
at coarser length scales (or lower energies) may be
built (a famous example is the charge of the elec-
tron). Although there is at ﬁrst glance no apparent
neighboring critical point in the case of polymeric
ﬂuids,
both
universality
in
exponents
and
renormalized quantities appear in abundance.
Moreover, there is a natural large number associ-
ated with mesoscopic, rather than microscopic
length scales. The deﬁning feature of a polymer
is, after all, its large “degree of polymerization,”
N, the number of monomers linked together cova-
lently to form the polymer chain. (The literature
discusses interchangeably N and the molecular
weight M of the chains, given in terms of the
monomer molecular weight m0 by M ¼ Nm0.) At
the most basic level of inquiry into polymer struc-
ture, experiments and simulations asking how the
average end-to-end distance R of a polymer mol-
ecule in solution depends on its degree of
24
Polymer Physics

polymerization N began to suggest a universal
scaling behavior:
R  Nn
ð1Þ
with an exponent n, dependent only on the embed-
ding dimension d and ﬁrst calculated by Edwards to
ben ¼
d
dþ2. It assumes a rather larger value in solu-
tion (’0.59) than the simple random walk value of
0.5 (de Gennes 1986), due to the self-exclusion of
the monomers. More phenomena reminiscent of
other areas of condensed matter appeared at the
level of many-body effects. In the dense limit of
polymer melts and concentrated solutions, where
chains are highly overlapped (and in embedding
dimensionsgreater than 4, the “upper critical dimen-
sion” of the self-exclusion problem), the exponent n
reassumes the value of 1/2 of the ideal Gaussian
random walk (“Gaussian” because the ensemble of
spatial end-to-end vectors of the polymer chains is
normally distributed). Closer inspection revealed
this to be true above a “screening length,” intro-
duced into polymer physics by Edwards (1966).
The screening length x itself may be directly mea-
sured by neutron scattering, and depends on con-
centration via another universal scaling exponent,
related to n (Adam and Delsanti 1984):
x  c
n
3n1 :
ð2Þ
The picture we have built up of a many-chain
polymer solution so far is summarized in Fig. 1,
where atomic detail at the monomer level is far
below the resolution of the diagram. As the poly-
mer concentration increases, so the screening
length or “mesh size” decreases. A typical strand
of chain, whose end-to-end distance is x, domi-
nates the monomer concentration within the vol-
ume it spans.
Both experimental and theoretical evidence of
universality continued to build up. Even in the
case of dynamics, the many-chain system of a
polymer melt followed the ideal, local-dissipation
theory of Rouse (1953) for sufﬁciently low molec-
ular weight chains (see below section “Dynamics
of Polymeric Fluids”) that assumed ideal Gauss-
ian chains. It became clear that Rouse’s result can
be seen as a ﬁxed “point” of all theories of poly-
mer dynamics in which linear connected objects
are ideal and are subject to local dissipation
(in
dilute
solution,
far-ﬁeld
hydrodynamics
destroys this locality (Zimm 1956)). For example,
lattice models of polymer dynamics with local
update rules renormalize to the continuum Rouse
theory at large enough length scales (Verdier and
Stockmayer 1962).
It seemed as though the huge connectivity of
macromolecules acts to freeze-in long-range
order, even though there is no true thermodynamic
transition nearby. Such suspicions were conﬁrmed
by the demonstration of direct isomorphisms of
the calculation of statistical mechanical partition
functions of polymers, both dilute and concen-
trated, onto idealized spin-lattice models of
Polymer Physics,
Fig. 1 Schematic picture
of universal structures of
screening (overlap) length x
and the number of
monomers g that just spans x
Polymer Physics
25

magnetism (de Gennes 1986). It is indeed the high
molecular connectivity, as the inverse of the
degree of polymerization, N1, that plays the
part of proximity to the distance from a critical
point in the spin model:
N1  e  T  Tc
Tc
:
ð3Þ
So by exhibiting physics in which an ensemble
of macromolecules of polystyrene (PS) exhibits
the same emergent behavior as polyisoprene
(PI) or polybutadiene (PB), following scaling
laws, and tractable by application of statistical
mechanical ﬁeld theories (Zinn-Justin 1993),
polymer physics drew together many of the stron-
gest conceptual strands of the century.
More, however, has proved to be true in the
realm of topological effects . The polymer melts
of industrial polymer processing are very highly
overlapped on the molecular level, where it
becomes immediately apparent that molecular
relaxation processes controlling elastic stress are
prolonged to very long times indeed. All the impor-
tant phenomenology is covered in Ferry’s seminal
survey of polymer viscoelasticity (Ferry 1986).
Mechanical experiments restricted to a range of
intermediate timescales of the plateau are hardly
able to distinguish between the polymer melt and a
rubber, in which the chains are permanently cross-
linked to each other at very rare points, sufﬁciently
for each chain to be permanently immobilized from
large-scale diffusion. Conceptually, the absent
“cross-links” were replaced in the minds of engi-
neers and physicists alike by “entanglements”
(Ferry 1986). These loosely deﬁned objects were
assumed to represent the topological constraint that
covalently bonded molecular chains may not pass
through each other. The effective distance between
these objects could be calculated, employing rubber
elasticity theory (see below), to deduce the degree
of polymerization between entanglements Ne, or the
equivalent “entanglement molecular weight,” Me.
The number Ne consistently turned out to be of
order 102, indicating a length scale for an “entan-
glement spacing” of 50–100 Å, depending on the
particular chemistry. This is highly signiﬁcant for
us, because it shows that small chains on the
threshold of feeling topological interactions are
real polymers, already long enough to show to a
good approximation all the universal properties of
statistical connected chains. It also suggests that the
role of topology in highly entangled (N  Ne)
polymer ﬂuids has the potential to be treated uni-
versally. Further evidence of universality in entan-
glements came from experiments in which the
polymers were diluted to a volume fraction fp by
a compatible solvent, indicating that Me ~
fa
p where
the scaling exponent α ’ 1 (Adam and Delsanti
1984). The dependence of melt viscosity Z (at ﬁxed
temperature) on molecular weight also exhibits
remarkable universality over very many different
polymer chemistries (Ferry 1986) closely matched
by ~M 3.4, providing that the molecular weight lay
well
above
the
entanglement
threshold
Me
suggested by their high-frequency elastic modulus.
We review this rapidly progressing area in section
“Dynamics of Polymeric Fluids.”
New phenomena arise when different chemis-
tries of monomer are introduced into the same
chain. Effective repulsive interactions between het-
erogeneous monomers create a tendency for strong
spatial correlations of chemical type. In blends of
more than one type of homogeneous polymer, the
result is often a demixing transition with near-
universal structure and dynamics (Koningsvelt
et al. 2001). When the chemical species are com-
bined into the same chain in regular “blocks” of
controlled molecular weight, demixing occurs on
the scale of the chains themselves, giving an
extremely rich variety of spatially periodic nano-
scopic structures, self-assembled micellar struc-
tures, and controlled collapsed forms. Both chain
composition and temperature act as control param-
eters of a structural space that becomes increas-
ingly biomimetic as the information content of the
macromolecular sequence increases. Experiment
and theory are reviewed in section “Multi-Phase
Polymeric Fluids.”
Single Polymer Chain Physics
It should not be surprising that the notion of com-
plexity should arise even in the context of the
26
Polymer Physics

“single particle” domain of polymer physics: that
of a single molecule. For already a macromolecule
contains many degrees of freedom that are coupled
in nonlinear ways. Not only this but also at the
single-chain level emergent co-operative properties
arise. We brieﬂy survey three important cases of
single-chain physics: the non-interacting chain, the
effect of excluded volume, and the role of charge.
Ideal Non-interacting Chains
The ﬁrst and most fundamental of these underlies
the physics of rubber elasticity: it is the emergence
of an entropic Hookean spring for macrostates of a
single polymer chain in thermal equilibrium
deﬁned in terms of its end-to-end vector R. We
recap brieﬂy here the statistical physics of a poly-
mer chain, modeled as a random walk in space
and subject to some local rule for spatial links. An
example is the freely jointed chain, in which the
orientations
of
a
set
of
linked
rods
are
uncorrelated. The step length of the chain corre-
sponds to the Kuhn length, b, of the polymer (the
shortest independently oriented segment length).
It is not as small as a monomer length, but usually
four or ﬁve monomers long.
For polymer statistics suppose a whole walk
has N links. Let the end-to-end displacement of an
individual chain be R(N). From the theory of
random walks: hR2(N)i ¼ Nb2 and the probability
density for the end-to-end vector G(R) must have
Gaussian form (from the law of large numbers,
since each vector step is an independent random
variable whose sum is R(N)). So,
G R, N
ð
Þ ¼
3
2pNb2

3=2
e3R2=2Nb2:
ð4Þ
The macrostate of an ensemble of such chains is
deﬁned by the chain end-to-end vector R. The
microstates are the different speciﬁc paths through
space that have R as their end-to-end displacement.
Each individual path, or microstate of the chain, will
be speciﬁed if the spatial position of each link is
known. We will use the notation R(n) for the posi-
tion of the nth link. The full time-dependence of the
chain would then be described by the function
R(n, t), extended to the two dependent variables of
contour position n and time t. The role of Brownian
motion can be cast in the form of Langevin equa-
tions for R(n, t) (see Rouse model, section
“Dynamics of Polymeric Fluids”), but here we
exploit it as a generator of ergodic exploration of
all chain conﬁgurations in the ensemble. The num-
ber of conﬁgurations with ﬁxed end to end vector
R is just the corresponding fraction of total micro-
states Ω(R) ¼ ΩTOTP(R). Since the entropy of the
walk S ¼ kB ln Ω(R) we have S R
ð Þ ¼ const: 3kBR2
2Nb2
t.
The conformational free energy of the chain
F(R) ¼ U  TS has U ¼ 0 since there are no sources
of internal energy. This yields for the free energy of
a chain of ﬁxed end-to-end vector F R
ð Þ ¼ 3kBTR2
2Nb2 .
Finally we may derive the thermodynamic force
(or “Brownian tension”) on the chain end-to-end
vector as
f ¼ ∇F R
ð Þ ¼  3kBT
Nb2 R
ð5Þ
and recognize a linear elastic spring law. That is, a
random walking polymer at ﬁnite T is a Hookean
spring with spring constant /T/N.
The analogies between the statistical mechanics
of random walks and the quantum mechanics of
spinless particles also emerge from this analysis.
Applying Eq. (4) to small subchains of path length
ΔN allows the (careful) taking of a limit so that
G R, DN
ð
Þ ¼
3
2pDNb2

3=2
e 3
2b2
@R
@N
ð Þ
2DN:
The notation G for the probability distribution is
suggestive: this descriptor of the chain has the
structure of a propagator. The complete end-to-
end propagation of (4) can be written as the sum
over all possible intermediate positions of the meet-
ing points of all smaller subchains, which in turn is
just an example of a Feynman path integral over all
possible paths of the polymer contour R(n):
G R, N
ð
Þ ¼
ðR N
ð Þ¼R
R 0
ð Þ¼0
e 3
2b2
Ð N
0
@R
@N
ð Þ
2dND R n
ð Þ
½
:
ð6Þ
The propagator structure arises because the
properties
of
the
chain
at
equilibrium
are
Polymer Physics
27

governed by its partition function, which in turn is
a sum over microstates that are in this case just the
possible paths of the chain. An analogous integral
arises in Feynman’s form of quantum mechanics
because the sum over all trajectories that gives the
(complex) amplitude for particle propagation is
just the same geometrical set of paths. The differ-
ence is that in polymer statistical mechanics the
phase angle attributed to the path is imaginary,
giving a real argument of the exponential in the
path integral. A rich set of techniques ﬂow natu-
rally from this analogy: since the propagator also
obeys Schrödinger’s equation, the equilibrium
conﬁguration of ideal chains in conﬁned geome-
tries and external potentials can be solved by any
technique developed for the quantum mechanical
case (de Gennes 1986).
Experiments on single chains have until recently
been indirect ensemble measurements. However,
neutron-scattering can give averaged single chain
properties because of the very different scattering
lengths of hydrogen and deuterium nuclei. It is
relatively straightforward to replace chemically
some or all of the hydrogen atoms in a fraction of
the chains in a polymeric ﬂuid. When the chains
themselves are monodisperse, the small-angle scat-
tering pattern is identical to that of the population of
labeled chains. Figure 2 shows an example of scat-
tering from a 7% labeled fraction of polystyrene
chains with a narrow distribution of molecular
weight. Early experiments of this type showed the
remarkable result illustrated here that the single
chains in a densely packed melt actually assume
an ideal (effectively non-self-interacting) set of
conﬁgurations described by the Gaussian propaga-
tor of Eq. (4) (see section “Equilibrium Properties
of Many-Chain Fluids” below). Much more
recently the advent of recombinant DNA, ﬂuores-
cent labeling, and video confocal microscopy has
begun to make direct inspection of individual poly-
mer molecules possible in restricted circumstances.
Even very high molecular weight DNA has a
random-walk molecular dimension bN1/2 below
the resolution limit of optics, but if the chain is
stretched out much larger dimensions are accessi-
ble approaching bN, so that some of the predictions
of single-chain elasticity can be explored.
Figure 3 shows one famous example that actu-
ally illustrates chain response as the maximum
elongation is approached. In this limit the Gaussian
approximation breaks down badly and a diver-
gence of force with extension is measured. The
form of the divergence is, unlike the linear
entropy-dominated range of elasticity, not univer-
sal among local polymer chemistries, but depends
on the form of the local structure and its response to
tension. Another analogy with high-energy physics
Polymer Physics, Fig. 2 Small angle neutron scattering
(SANS)
data averaged over angles for a monodisperse
polystyrene melt. The theoretical curve is that calculated
from a Gaussian propagator
Polymer Physics, Fig. 3 Images of a 64m long DNA
molecule held in place at one end by optical tweezers and
stretched out by hydrodynamic ﬂow of increasing velocity
from left to right. Reprinted with permission from (Perkins
et al. 1995)
28
Polymer Physics

arises here: strong applied forces measure structure
at smaller length scales. This is powerfully illus-
trated by the high-force asymptote of two models
of ﬂexible polymers, the freely jointed chain (FJC)
and the worm-like chain (WLC). The ﬁrst models
the local structure of a chain as N freely hinged but
inﬁnitely stiff rods each of length b. Such a chain
has a maximum extension of its own contour length
L0 ¼ Nb, but at low forces responds with the linear
behavior of the Gaussian chain so that the force
f with extension L follows f~kBT(L/Nb2). The force
diverges as L ! L0 with the asymptotic form f(L)~
(1  L/L0)1. The WLC introduces a ﬁnite bending
rigidity everywhere along the chain so that the
internal energy of a conﬁguration R(n) can be
written as
E ¼ kBTlp
ðN
n¼0
@2R n
ð Þ
@n2

2
dn
ð7Þ
with the constraint that
@R n
ð Þ
@n

 ¼ 1. The stiffness
is written as kB Tlp in terms of the “persistence
length” lp because at equilibrium the chain is
locally stiff at smaller length scales and ﬂexible
over longer lengths. This statement can be made
exact by considering the correlation function of
the orientation of the chain:
@R n1
ð
Þ
@n
@R n2
ð
Þ
@n


¼ e n1n2
j
j=lp:
Although this model also shares the Gaussian
linear response of the FJC, it possesses quite dif-
ferent asymptotics at high force (Marko and
Siggia 1995), following f(L )~ (1  L/L0)1/2.
The calculation takes the response under the
force of all harmonic normal modes of the Ham-
iltonian (7), the more gentle divergence arising
from the successive suppression of contortions
of the chain at smaller and smaller wavelength as
the force increases.
Self-Interacting Chains: Excluded Volume
As pointed out in the introduction, real polymer
chains in solution are not typically Gaussian. The
reason is that the path integral of (6) overcounts
the
allowable
conﬁgurations
of
the
chains,
including those that cross themselves. The modi-
ﬁcation to the Hamiltonian that achieves the
monomeric self-exclusion with maximum sim-
plicity and generality is the “Edwards Hamilto-
nian” (Edwards 1965):
G R, N
ð
Þ ¼
ð
R N
ð Þ¼R
R 0
ð Þ¼0
e
 3
2b2
ÐN
0
@R
@N
ð Þ
2dNwÐN
0
ÐN
0
d R n
ð ÞR n0
ð Þ
½
dndn0
D R n
ð Þ
½
:
Although formally the delta-function potential
removes only a volume of phase space of zero
measure from the path integral, its anticipated use
within ﬁeld-theoretic tools for the solution of the
model mean that it represents a renormalized local
repulsion between monomers of the chain at the
level of this universal coarse-grained theory. From
this starting point one can proceed by several
methods: self-consistent ﬁeld treatment of the
excluded volume term (Edwards 1965), mapping
onto problems in critical phenomena (de Gennes
1972), direct renormalization-group calculation
(des Cloiseaux 1981), and Monte Carlo numerical
enumeration (Mazur and McCrakin 1968). For a
comprehensive and technical review see des
Cloiseaux and Jannink (1990). The essential struc-
ture within the self-consistent ﬁeld methods is the
same as that of an early calculation by Flory (Flory
1953) who balanced the scaling forms of the free-
energy contributions from chain elasticity (R2/N)
and excluded volume (N2/Rd) in d-dimensional
space and minimized to give the dependence of
the scaling exponent for chain size n as
n ¼
d
d þ 2 :
ð8Þ
This is fortuitously accurate in all dimensions
from d ¼ 1 (where it is exact) to d ¼ 4, which it
correctly identiﬁes as the upper critical dimension
of the problem since the Gaussian exponent of
n ¼ 1/2 is recovered here. However, the method
is unreliable for the calculation of other quantities
because in dimensions less than four the excluded
volume term is not perturbative for any strength of
the parameter w in the large-N limit. This really
forces a renormalization approach to the problem,
already achieved in the case of spin interactions in
Polymer Physics
29

magnets at the ferromagnetic critical point.
A formal and beautiful exact mapping ﬁrst
pointed out by de Gennes exits between the
excluded volume chain and an analytic continua-
tion of the Heisenberg model in which the number
of spin components goes to zero (de Gennes
1972). The analogy arises because the calculation
of the correlation function between the magnetic
spins on any two sites of the lattice in the magnet
model can be written as a weighted sum over all
non-intersecting paths that connect the two sites
within the lattice. So formally,
SiS j


¼
X
N
O N
ð Þeϵ N,
ð9Þ
where Ω(N) counts the number of self-excluding
walks of length N connecting the sites and ε mea-
sures the dimensionless temperature difference
from the ferromagnetic critical point as in Eq. (3).
The analogy led directly to the ﬁrst calculated
values for the Flory Exponent n using diagram-
matic expansion methods developed originally
from Feynman’s perturbation tools for quantum
electrodynamics. In three dimensions the problem
is non-perturbative – the exponent departs from the
mean-ﬁeld value for all values of the excluded
volume parameter w no matter how small, provid-
ing that the chains are long enough. The calculation
of n requires ﬁrst taking the problem in four dimen-
sions, where it becomes perturbative, then taking a
double expansion in w and in the analytic continu-
ation of dimension below 4. For short enough
segments on the other hand, the chains do not
depart strongly from ideal behavior. There is a
characteristic length scale at which the energy of
self-exclusion equals the thermal energy kT below
which statistics are near-ideal and beyond which
the chains are swollen. Subchains of this interme-
diate length scale are known as “thermal blobs.” In
d ¼ 3 the value of n ’ 0.588, in close agreement
with the value predicted (fortuitously) by (8).
The behavior of chains under an attractive two-
body interaction constitutes an emergent phenom-
enon that mirrors that under repulsion discussed
above. The experimental case is that of a “poor
solvent” where monomers of the polymer now
enjoy a favorable interaction. Now the chains are
densely packed for high enough molecular
weights so that n ¼ 1/d above the thermal blob
size. In the limit of inﬁnite molecular weight the
transition from a swollen to collapsed chain
becomes thermodynamic. This is possible to real-
ize experimentally in some cases by simply con-
trolling the solvent quality though control of
temperature. There exists in these cases a critical
point known as the “theta temperature” at which
the effective two-body monomer-monomer inter-
actions from excluded volume and solvent-
induced attraction exactly cancel, leaving only
three-body and higher terms. The “coil-collapse”
transition is not sharp (only becoming so in the
thermodynamic limit of inﬁnitely long chains).
The collapsed and swollen chain conﬁgura-
tions of real chains leave their traces on the emer-
gent elastic properties of single chains that we
examined above in the ideal case. For example,
now the effective Hookean spring force-distance
relation f(R) is modiﬁed to f  R
n
1n in general.
The Role of Electrostatic Charge
A recently very active area in polymer physics
that has produced a number of surprises is the
form of emergent behavior arising from the com-
bination of electrostatic charge, polymeric con-
nectivity, and counter-charges in solution. This is
the
case
of
“polyelectrolytes”
–
polymers
containing charged monomers. Complex emer-
gent behavior is perhaps unsurprising since all
three have the propensity to generate long-ranged
interactions that are candidates for generators of
qualitatively different physics from the local inter-
actions examined in the last section.
The static conﬁgurations of a polyelectrolyte are
radically different from those of a neutral ﬂexible
chain in solution. Constructing a mean-ﬁeld
“Flory” type theory for a chain containing a fraction
f of monomers carrying charge e that, balancing
electrostatic energy with conﬁgurational entropy,
yields the result (Rubinstein and Colby 2003):
R ’ Nbf 2=3 lB
b

1=2
ð10Þ
showing that at this level the chains will be
completely stretched at the scaling level. This
result contains one of the several new length
30
Polymer Physics

scales that appear in complex ﬂuid electrostatics,
the Bjerrum length:
lB  e2= ekT
ð
Þ:
This is the distance between charges at which
the
electrostatic
and
thermal
energies
are
comparable.
Charged conﬁgurations of this extreme kind
are not realized globally, since counterions are
universally present to ensure overall neutrality.
Their presence in solution screens the “bare”
long-range electrostatic repulsion beyond the
“Debye screening length”:
lD 
ekT
n0e2

1=2
:
This is not the length scale on which the
charged chains adopt random-walk conﬁgura-
tions; however, since there is typically a strong
repulsion (many kT) between chain segments
adjacent by lD, providing the charge fraction is
great enough. The emergent persistence length is
another new scale:
lp ¼ lD lDlB
b2


f 2:
A different set of structures arises if the energy
competition is between electrostatic repulsion and
chain-collapse in a poor solvent. Without electro-
statics the chain will collapse into a compact glob-
ular form with n ¼ 1/d to minimize the total
contact
between
monomers
and
solvent,
restricting it to the surface of the globule. The
surface energy rises as γR2, but is eventually over-
come by the electrostatic self-repulsion from the
globule’s charge, which rises (in three dimen-
sions) as N2f2e2/R~R5. This instability was identi-
ﬁed as a cause of droplet breakup in simple ﬂuids
by Lord Rayleigh. The free-energy minimum is
achieved in the polymeric case by a conﬁguration
resembling a string of pearls, in which the poly-
electrolyte breaks up into small globules that
closely balance the surface and electrostatic ener-
gies, connected by stretched strands of chain. It is
a rare example of heterogeneous conﬁgurations
minimizing the free energy at the level of a single
chain (Dobrynin and Rubinstein 2005).
The combination of persistent, or rod-like, con-
ﬁgurations and counter-charges leads to other
remarkable properties of charged polymers. The
entropy of conﬁnement of counterions within a
cylindrical region around an extended polymer of
radius R decreases as k T log R per ion. In this
geometry this has the same functional form as the
electrostatic attraction (providing that R is less than
the screening length), which depends on the charge
per unit length of the polymer r as(re/ε) log R.
Providing (re/ε) > kT, most of the counterions in
solution balancing the charge on the polymer will
be closely bound to it, the phenomenon of “Man-
ning condensation” (Manning 1969). This criterion
is equivalent to evaluating the number of counter-
ions per Bjerrum length. If this is less than one,
then all counterions are effectively free; otherwise
there is signiﬁcant condensation onto the chain.
The charge clouds condensed in the vicinity of
neighboring polymers sustain thermal ﬂuctuations
that correlate via the long-range electrostatic inter-
action in an analogous way to the electronic origin
of the Van der Waals interaction. Providing the
ﬂuctuations are large enough (these are enhanced
by ions of high valency), then the ﬂuctuation-
induced attraction between the counterion clouds
may actually overcome the electrostatic repulsion
of the bare polyelectrolyte charge. For polymers
in solution like charges may indeed attract! This
effect is responsible for the attraction and bun-
dling of polymers of DNA, which carries a strong
negative charge (Ha and Liu Andrea 1998).
Equilibrium Properties of Many-Chain
Fluids
We have seen that the thermodynamic properties
of single polymer chains exhibit both richness and
a high degree of universality. Both aspects of the
emergent properties of polymer physics extend to
many-chain systems in which the molecular
chains become strongly overlapped. When this
happens the quality of the solvent (controlled
with temperature) that for single chains gave rise
to the coil-collapse transition, swollen statistics,
and the pseudo-ideal theta temperature, now
Polymer Physics
31

control co-operative phenomena such as the emer-
gence
of
an
osmotic
pressure,
and
phase
separation.
Semi-dilute Solutions
The existence of the coil-size itself R~Nn sets a
new concentration regime, termed “semi-dilute,”
that only exists in the case of polymeric ﬂuids. We
have already encountered it, and its key attributes,
in the introductory discussion of Fig. 1. The semi-
dilute concentration range covers those cases
where the chains themselves are strongly over-
lapped but where the volume fraction taken up
by monomer rather than solvent molecules is
still small. The structure of the solution when the
polymer-solvent
interaction
is
favorable
is
entirely dominated in this regime by the new
length scale of the screening length x. The physics
of this length scale is readily detected in two ways:
by direct structural probes such as neutron scat-
tering, and by the solution property of osmotic
pressure. If scattering contrast exists between
monomer and solvent, then the scattering intensity
and scattering wavevector k measures the ﬂuctua-
tions in monomer concentration within volumes
of ﬂuid of size k1. For large length scales
k  x1, there are no correlations between one
element bounded by a screening length and its
neighbors: the identity of a single chain is lost at
these scales where it is highly overlapped with
others. At the other limit, all scattering for
k  x1 is governed by correlations along single
chain segments within such correlation volumes,
and the scattering is identical to that from a single
chain. Since chains have a spatial scaling structure
whether in theta or good solvents, power-law
behavior is induced in the scattering as well. The
physics is captured by a generalization of the
Ornstein-Zernicke scattering function:
S k
ð Þ ’
S 0
ð Þ
1 þ kx
ð
Þ1=n
ð11Þ
illustrated in the ﬁgure (Daoud et al. 1975). The
exponent n is the same as that determining coil
size for single chains discussed in the previous
section.
The osmotic pressure as a function of mono-
mer concentration P(c) of a semi-dilute polymer
solution is also connected with the structure of
closely packed correlation volumes that emerges
from the screening-length picture. This is because
P measures the change of free energy with con-
centration, itself dominated by the balance of
chain entropy and chain contact-energy. Since all
sub-chain conﬁgurations within each correlation
volume x3 are sampled ergodically, but all corre-
lations at greater length scales lost, the conse-
quence is that the free-energy density carries the
structure of kT/x3, or one thermal degree of free-
dom per correlation volume. Since the concentra-
tion of the correlation length is calculable in
terms, once more, of the Flory exponent n, from
Eq. (2), the concentration dependence of the
osmotic pressure follows P(c)~c3n/(3n1) in the
semi-dilute regime. The same result can be arrived
at by anticipating a scaling structure that crosses
over to the correct ideal-gas form under truly
dilute conditions, writing
P c
ð Þ ¼ kT
b3
c
N f
c
c
	

:
ð12Þ
Here f(x) is a scaling function that tends to
unity for small argument, and to a power law f(x)
~xz for largest. The concentration c is the overlap
threshold
separating
dilute
and
semi-dilute
regimes, where individual coils just begin to over-
lap. Insisting that for c  c the osmotic pressure
should not depend on chain length N (this is
equivalent to the loss of correlations beyond x)
ﬁxes the power z ¼
1
3n1
and the result P(c)
~c3n/(3n1) is recovered. Experiments at different
molecular weights and chemistries in good sol-
vents collapse well onto the scaling form of (12)
(Noda et al. 1981). A formal route to the calcula-
tion of the solution properties of correlation, free
energy, and osmotic pressure was discovered by
Des Cloiseaux as a generalization of the magnetic
spin-analogy of de Gennes. A diagrammatic
expansion
of
n-body
chain
interactions
is
performed for the zero-spin limit of the model,
but this time in the presence of an external ﬁeld.
This acts as a fugacity for chains, and creates a
system where renormalization group methods
32
Polymer Physics

may be used, again in expansion around four
spatial dimensions, to calculate exponents such
as z (des Cloiseaux and Jannink 1990).
The semi-dilute structure for polyelectrolytes
(see above) is complex. In the absence of added
salt, small-angle scattering experiments display a
peak, rather than the “shoulder” of the Ornstein-
Zernike-like structure function of uncharged
chains, indicating a dominant correlation length
which is not entirely understood. The scaling of
the peak position km with concentration c, km ~ cδ
varies as the chains become overlapped, with the
exponent δ changing from 1/3 to ½ in the semi-
dilute regime, and ﬁnally to ¼ in concentrated
polyelectrolyte solutions. These regimes have
also appeared in approximate ﬁeld-theoretic cal-
culations (Muthukumar 2016).
Complex Topology Polymers and Gelation
The emergent properties of polymers in solution,
it should be clear by now, arise from the connec-
tivity of chains, either on its own or in the pres-
ence of other physical interactions such as
excluded volume or electrostatics. It is also the
essentially topological properties of connectivity
that endow polymer physics with its universality.
It is therefore of interest to explore the conse-
quences of altering the chain topology in more
complex ways. One very practical way of doing
this is to introduce cross-links chemically into a
polymer solution (industrially this is the route to
preparation of rubbers). In the limit of high cross-
link density the result is a system of chains that
have a signiﬁcant number of their degrees of free-
dom “quenched” (chemically connected mono-
mers on different chains are perpetually forced
into proximity). That the resulting physical object
is a solid when the original system was ﬂuid is by
no means an obvious result, and emerges only
delicately from the treatment of the statistical
mechanics of quenched disorder. Historically,
methods originally developed to treat the model
systems of “spin-glasses” were the ﬁrst to treat the
cross-linked polymeric ﬂuid from this point of
view, among them the “replica method” of
Edwards (Deam and Edwards 1976). Here the
formal free energy of the rubber as an average
over
the
logarithms
of
quenched
partition
functions with different conﬁgurations of cross-
links {Nx}:
F N, Nx, L
ð
Þ ¼ kT ln Z N, Nx
f
g, L
ð
Þ
h
i Nx
f
g
is
treated
using
the
formal
limit
log Z ¼
lim n!0 Zn1
n


. This amounts to the statistical
mechanics of an unquenched ensemble of replicas
of
the
original
network,
but
in
the
limit
(analytically continued) of the number of replicas
tending
to
zero.
The
liquid-solid
transition
emerges as the physical consequence of a mathe-
matical symmetry-breaking between the replicas
in the evaluation of the free energy, and a shear
modulus grows as the third power of the differ-
ence between the cross-link density and a critical
value for the onset of the solid (Castillo and
Goldbart 2000).
Although the formal treatment of rubber elas-
ticity is very subtle, there are good approxima-
tions that have generated a sequence of semi-
empirical models capable of capturing not only
stress generation in cross-linked rubbers but also
the temporary stress generated in entangled poly-
meric ﬂuids (see below). These begin with identi-
fying a length scale at which the deformation Λ is
imposed on chain segments afﬁnely, and below
which the chains are assumed to be able to explore
all microstates. Applying the result for the effec-
tive elasticity of the chain segments (5) above
yields an expression for the bulk stress tensor in
terms
of
the
average
conﬁguration
of
the
subchains:
sij ¼ 3kBT
b2
ℂ@Ri
@n
@R j
@n


:
ð13Þ
These results obtain for the case in which the
cross-links are suddenly imposed upon an equi-
librium semi-dilute or concentrated polymer
solution. If they are introduced gradually, a
richer structure arises in which chains of increas-
ingly branched nature are created well before the
critical liquid-solid transition. If this process is
imposed mathematically on an ensemble of ideal
chains, an ensemble of very compact branched
polymers results with a Flory exponent of n ¼ 1/4.
Polymer Physics
33

From the deﬁnition of n, (1), we see that its inverse
1/n  D plays the role of a dimension. Ideal linear
chains are in this sense two-dimensional objects,
but ideal branched polymers are four-dimensional!
This does not present a necessary difﬁculty at ﬁxed
spatial scales, since the individual molecules of
ﬁnite molecular weight are very sparse, but at high
enough molecular weight there will not be sufﬁcient
space in three embedding dimensions to contain
such objects without overlap. This must occur in
successive cross-linking, because calculations of
the distribution of molecular weights that result
from random insertion of cross-links (this may be
done elegantly by the use of generating functions
(de Gennes 1986)) give a result of the form:
P M
ð
Þ ¼ Mtf M=Mx
ð
Þ,
ð14Þ
where t is a “Fisher exponent” and f(x) a cut-off
function that limits the distribution function to a
highest molecular weight of Mx. This upper
molecular weight itself diverges as another scal-
ing function of the difference in cross-link den-
sity from the critical valueMx~|p  pc|1/s. This
class of critical phenomena generated by topo-
logical connectivity is called “percolation “and
generates beautiful physical effects in polymers.
Like other critical phenomena associated with
thermodynamic phase transitions it possesses
universality classes in which the values of the
exponents are independent of the geometry of
local interactions. We can see that the mean-
ﬁeld (ideal) value of D ¼ 4 (and t ¼ 5/2) is not
sustainable
in
three-dimensional
space:
the
branched polymers must swell by excluded vol-
ume so that they do not overlap strongly with
themselves (or with subclusters of larger mole-
cules) (Cates 1985). Applying this requirement
on the non-overlap of clusters of all molecular
weights generates a relationship between the
exponents t, D, and the embedding dimension
d called the hyperscaling relation:
d
D ¼ t  1:
ð15Þ
This holds for a wide range of “bare” fractal
dimensions D since the excluded volume drives
systems to marginal overlap at all length scales
stably: if the overlap reduces for larger chains,
then they suffer less excluded volume and swell
less,
consequently
increasing
overlap
once
more. The values for percolation in three-
dimensional space are D ﬃ2.53 and t ﬃ2.18.
Should the overlap increase, then the conse-
quent increased self-repulsion increases swell-
ing with the opposite effect. The structure
implied by (15) is self-similar on a grand
scale: not only are the individual molecules
self-similar but the ensemble also satisﬁes
self-similarity at all length scales in the mar-
ginal overlap of clusters of all sizes. There is no
correlation length and the scattering function is
a power law.
A major new class of complex polymeric
materials exploits a class of chemical exchange
reactions that endow a thermally controlled rate
of partner-exchange to the cross-links in a gel.
Termed “vitrimers” because of their ﬁne tem-
perature control of processing (akin to that of
silica glass), they constitute a new class of
temporary
cross-linked
materials
(Denissen
et al. 2015). The sudden loss of elasticity that
would arise from a simple switch from perma-
nent cross-links to those of ﬁnite lifetime (and
so a temperature-dependent density of active
cross-links), and an approach to the percolation
threshold discussed above, is replaced by a
dynamical evolution of network topology that
maintains the concentration of cross-links ﬁxed.
Such
materials
also
possess
“self-healing”
properties:
as
long
as
fractures
can
be
supported through breakage of the temporary
bonds only, mechanical ﬁssures and faults in
vitrimers will heal over the same timescale as
the cross-link reorganization.
Dynamics of Polymeric Fluids
Complex, emergent phenomena extend from
static structure of polymeric ﬂuids into their
rich dynamic properties. This is especially true
of the semi-dilute and concentrated cases when
interactions between distinct chains are very
strong and the conformational dynamics highly
34
Polymer Physics

coupled. But even in the case of dilute or effec-
tively uncoupled dynamics the scaling struc-
tures
we
saw
in
equilibrium
pattern
the
behavior out of equilibrium. The experimental
tools deployed also mirror those used for stat-
ics: direct structural probes of light or neutron
scattering possess dynamic counterparts in pho-
ton correlation spectroscopy (Jian et al. 1996)
and neutron spin-echo (Higgins and Benoit
1994). Speciﬁc averages over bond correlation
dynamics are available from dielectric spectros-
copy (Watanabe 1999) or NMR relaxation
(Klein et al. 1998). Emergent effects at the
level of the ﬂuid are most striking in their
rheology (McLeish 2002). At the level of linear
response, the rubber-elastic stress generated by
small deformations decays with a function G(t)
characteristic of the molecular structures pre-
sent: the phenomenon of viscoelasticity. In
strongly nonlinear ﬂows other effects appear,
such as the effective decrease in viscosity with
shear rate, complex transient behavior in stress
response, and the generation of rich stress ﬁelds
and non-inertial elastic instabilities in nontrivial
ﬂows. We ﬁrst review brieﬂy the dynamic prop-
erties of single polymer chains before treating
more extensively the complex dynamics of
entangled systems.
Single Chain Dynamics
In the simplest fundamental model of polymer
dynamics, due to Rouse, we make three key sim-
plifying assumptions (Rouse 1953). Their physi-
cal validity depends on the effectiveness of
screening (Edwards 1966) of both static and
hydrodynamic quantities in a melt. In the case of
concentrated solutions, screening will not be oper-
ative at length scales below the mesh size x, but
will hold at larger scales. But these contain the
length scales of entanglement effects, so in the
solution case also, coarse-grained local dynamics
are expected to follow the Rouse model locally.
Even in concentrated polymeric ﬂuids the dynam-
ics of chains (and subchains) below a characteris-
tic molecular weight are not strongly coupled to
the presence of other chains. The central assump-
tions are:
•
Gaussian Chains: in which the force on a sub-
chain segment n is the net entropic force from
its neighbors. In the continuum representation
we have adopted, this is equivalent to a ther-
modynamic force at each point of the chain of
 @
@n k @R
@n


¼ k @2R
@n2 with k ¼ 3kBT
b2 .
•
Local drag: the drag force on a subchain seg-
ment comes from frictional drag against back-
ground
without
long-range
hydrodynamic
effects of backﬂow (this works in melts where
all
long-range
mediated
backﬂows
are
screened). This force is z @R
@t
with ζ a drag
coefﬁcient per segment.
•
Brownian motion: a random force f(n, t) acts
on each subchain with correlation times much
faster than any polymer dynamics to be
modeled by the theory.
The monomeric drag constant ζ0 will parame-
trize all our theoretical models, setting the
timescale for both Rouse and, subsequently,
entangled, motion. The balance of entropic,
drag, and random forces on the chain of N sub-
chains is the Rouse equation:
z0 @R
@t ¼ 3kBT
b2
@2R
@n2 þ f n, t
ð
Þ:
ð16Þ
The noise on each subchain is related to its
frictional drag by the generalized Einstein relation
as above:
f n, t
ð
Þf ðm, t0Þ
h
i ¼ 2z0kB T Id n  m
ð
Þd t  t0
ð
Þ:
ð17Þ
The Rouse dynamical Eq. (16) is diagonalized
by the transformation:
R n, t
ð
Þ ¼ X0 tð Þ þ 2
X
1
p¼1
Xp tð Þ cos ppn
N
	

: ð18Þ
The Xp(t) are the time-dependent amplitudes of
the “Rouse modes” of the polymer chain. These
are just the (vector amplitude) Fourier modes of
the chain path R(n, t) with respect to the arclength
Polymer Physics
35

coordinate n. The key result for us is the time
correlation function of the mode amplitudes,
which is:
Xp tð ÞXq t0
ð Þ


¼ I kBT
kp dpqe tt0
j
j=tp
with kp ¼ 6kBTp2p2
Nb2
:
ð19Þ
Each mode has its own relaxation time tp ¼ ζ/kp
that decrease rapidly (as1/p2) with mode index p.
The longest of these relaxation times t1 ¼ zN2b2
3p2kBT
has special signiﬁcance. It is known as the Rouse
Time, and often given the notation tR. It is the time
for relaxation of the overall shape of the molecule
(it is the relaxation time of the amplitude of the
normal mode with fewest nodal points, cos pn
N ),
and is also the time for a Gaussian Rouse chain
to diffuse its own radius of gyration.
What does the local motion of this model chain
look like? We expect for short intervals that the
chain contour may have adjusted locally, but retain
a very similar global conﬁguration (see Fig. 4). In
order to answer this question, and to compare with
local diffusion probes of NSE and NMR on
unentangled dynamics, we need to calculate the
correlation function fn(t)  h(R(n, t)  R(n, 0))2i
that describes the mean displacement over time of
monomers on the chain. Summing over the inde-
pendent normal modes gives:
fn tð Þ ¼ 6DCMt þ Nb2
3p2
t
tR

1=2
a:
Here a ¼ 1
2
Ð 1
0 z3=2 1  ez
ð
Þdz ’ 1:77
is a
purely numerical constant. The result is remark-
able: each monomer executes an “anomalous” or
sub-Fickian diffusion, such that its mean square
displacement goes as t1/2 rather than t (as for ordi-
nary diffusion). This behavior persists until times
longer than the Rouse time, after which each
monomer is carried by the (faster) center of mass
motion of the whole molecule. This anomalous
diffusion is simply a consequence of chain con-
nectivity: the further a monomer travels under
Brownian motion, the greater is the length of
chain that must be correlated with it and the
greater the effective drag over that length scale.
The (deviatoric) stress formula
sij ¼ 3kBT
b2
ℂ@Ri
@n
@R j
@n


we derived above Eq. (13) leads, via representa-
tion in terms of the Rouse modes (Doi and
Edwards 1986), to an expression for the time-
dependent modulus function following a step
strain G(t) ¼ sxy(t)/γ. Each mode decays back to
equilibrium anisotropy with its own characteristic
time. The power-law distribution of modes then
gives:
G tð Þ ¼ ℂkBT
N
X
p
e2p2t=tR

 ℂkBT
t
t1

1=2
et=tR:
ð20Þ
So we ﬁnd that, until a ﬁnal crossover to an
exponential decay beyond the Rouse time, the
Rouse model has a relaxation modulus which is
a power-law of G(t)~t1/2. Note that the longest
relaxation time scales with molecular weight as
N 2, but the viscosity scales as ℂkB T N. This is
because at the longest relaxation time that sets the
value of the viscosity, the stress is carried only by
the lowest Rouse mode; the density of these
modes is just one per chain, or ℂ
N.
Polymer Physics, Fig. 4 A Rouse chain changes its
conﬁguration (from solid to dashed curve) locally but not
globally in times shorter than tR
36
Polymer Physics

Beautiful generalizations of such dynamical
scaling behavior arise in the case of marginally
overlapped fractal clusters, such as those arising
from gelation transitions. Long-range hydrody-
namic interactions are effectively screened, but
entanglement effects are negligible. So now the
Rouse Eq. (16) generalizes to solving the eigen-
values of the Laplacian (right-hand side of (16))
on a fractal cluster with high degree of branching.
Locally (for high-frequency modes) this is indis-
tinguishable from the case of linear chains, but at
longer wavelengths than the chain length between
branch points, the effective dimensionality of the
cluster rises. Just as in many cases it is possible to
represent the mass distribution with an effective
dimensional exponent D ¼ 1/n, so the Laplacian
eigenfunctions of a self-similar branched object
possess a “spectral dimension” ds and the density
of states in k-space can be written
g k
ð Þdk ﬃkds1dk:
ð21Þ
The combination of the scaling dimension of
individual clusters and the self-similarity of the
molecular weight distribution via the Fisher expo-
nent yields a generalized power-law for stress
relaxation (Cates 1985). For Rouse dynamics
(local
friction)
and
hyperscaling
the
result
depends only on the fractal dimension of the
clusters
G tð Þ ’ kT
b3
t
t0

 3
Dþ2
:
ð22Þ
The value of the dynamic exponent z in G(t)
~tz for three-dimensional percolation is therefore
predicted to be z ﬃ0.66. Experiments on critical
gels of unentangled chains conﬁrm this (Lusignan
et al. 1995).
Polymer Dynamics with Hydrodynamics
When macromolecular chains are not strongly
overlapped, the effects of hydrodynamic ﬂow
within the solvent makes a strong difference to
the absolute timescales of subchain motion, and to
the scaling form of diffusive, sub-diffusive, and
orientational relaxation (Doi and Edwards 1986).
The reason for this is the long-range nature of the
ﬂow-ﬁeld in a Newtonian ﬂuid in the appropriate
non-inertial (“Stokes”) limit applicable to poly-
mer solutions. The central hydrodynamic result
needed to develop a fully hydrodynamic theory
of polymeric ﬂuids can be captured as the velocity
perturbation v(r) resulting from a point force f
applied at the point r ¼ 0 within such a ﬂuid:
v rð Þ ¼
1
6pr I  r r
r2
	

:f
ð22aÞ
The distance-dependent tensor operating on
the force is the “Oseen tensor,” and scales like
an electrostatic potential with 1/r, but with addi-
tional structure that preserves the ﬁxed density of
the ﬂuid under the perturbed ﬂow (technically
ensuring that it is divergence-free). That this
“backﬂow” is all-important in the case of poly-
mers can be understood by a simple scaling esti-
mation of the total effect on the velocity at any
monomer on a chain from the rest of the chain. For
if the chain is a Gaussian random walk, the aver-
age density of monomers from the same chain at a
distance r from any one of them falls off as 1/r.
The contribution to the backﬂow from these
monomers also falls off as 1/r from the Oseen
result, but the number of such sources of ﬂow
perturbation increases with the area of the shell
at a distance r (r2). So each shell contributes
equivalently and the velocity “perturbation”
from all monomers diverges until cut-off by the
entire chain, or be a distance over which the sign
and size of the perturbing force fails to correlate. It
is instructive to note that for extended rods, rather
than polymer coils, this same argument leads to
the weak, logarithmic, divergence of hydrody-
namic corrections to local friction in that case.
The consequences of this hydrodynamic argu-
ment are remarkable: (1) a polymer coil will
essentially drag all its internal solvent with it as
it diffuses; (2) the “Rouse modes” of the internal
dynamics of chains are still approximately good
dynamical modes for the hydrodynamic case.
Entangled Polymer Dynamics
Richer behavior still emerges in the realm of
interchain topological effects that dominate in
Polymer Physics
37

ﬂuids where chain overlap is very strong. The
polymer melts of industrial polymer processing
are very highly overlapped on the molecular
level, where it becomes immediately apparent
that molecular relaxation processes controlling
elastic stress are prolonged to very long times
indeed. The classic “relaxation modulus” G(t)
measuring stress linear response to a step strain
records a “plateau” value before a terminal relax-
ation time that increases rapidly with molecular
weight, in strong contrast to the power-law decays
discussed above. Experiments restricted to the
timescales of the plateau are hardly able to distin-
guish between the polymer melt and a rubber, in
which the chains are permanently cross-linked to
each other at very rare points, sufﬁciently for each
chain to be permanently immobilized from large-
scale diffusion. Conceptually, the absent “cross-
links” were replaced in the minds of engineers and
physicists alike by “entanglements” (Ferry 1986).
These loosely deﬁned objects were assumed to
represent the topological constraint that cova-
lently bonded molecular chains may not pass
through
each
other.
The
effective
distance
between
these
objects
could
be
calculated,
employing rubber elasticity theory,
G 0
ð Þ
N ¼ kG RTr
Me
(with the constant kG ¼ 1 for “afﬁne” and 1/2 for
“junction ﬂuctuation” models of elasticity) to
deduce the degree of polymerization between
entanglements Ne, or the equivalent “entangle-
ment molecular weight,” Me. The number Ne con-
sistently turned out to be of order 102, indicating a
length scale for an “entanglement spacing” of
50–100 Å, depending on the particular chemistry.
This is highly signiﬁcant for us, because it shows
that small chains on the threshold of feeling topo-
logical interactions are real polymers, already
long enough to show to a good approximation
all the universal properties of statistical connected
chains. It also suggests that the role of topology in
highly entangled (N  Ne) polymer ﬂuids has the
potential to be treated universally. Further evi-
dence of universality in entanglements came
from experiments in which the polymers were
diluted to a volume fraction fp by a compatible
solvent. The apparent entanglement molecular
weight Me  fa
p
where the scaling exponent
α ’ 1 (Adam and Delsanti 1984).
Other experiments had pointed to the existence
of a topological feature at this coarse-grained
scale of structure. Careful measurements on rub-
bers of controlled synthesis had shown that the
shear modulus was higher for a network of long
chains than a model incorporating cross-links
alone
would
predict
(Treloar
1975).
Other
“trapped entanglements” on the same scale as
the melt value of Ne seemed to contribute to the
elasticity. Advanced theories of rubber elasticity
have been able to treat rubber networks in terms of
the two distinct constraints of physical cross-links
and trapped entanglements (Ball et al. 1981;
Rubinstein and Panyukov 2002). A remarkable
universality also emerged in measurements of
the scaling of melt viscosity Z on the molecular
weight M of very many different polymer chem-
istries (Ferry 1986):
  M1
M < Mc
  M3:4
M > Mc:
ð23Þ
For each material, a critical molecular weight,
Mc emerged, above which the viscosity rises very
steeply with molecular weight. Furthermore,
within experimental error, this explicitly dynami-
cal observation was linked phenomenologically to
the essentially static measurements of the plateau
modulus by the correlation
Mc ’ 2Me:
ð24Þ
This connection between essentially dynamic
(Mc) and static (Me) experiments, observed over a
wide range of chemistries, is strong evidence that
topological interactions dominate both the molec-
ular dynamics and the viscoelasticity at the 10 nm
scale in polymer melts (and at correspondingly
larger scales for concentrated solutions).
Without going beyond rheological measure-
ments on bulk samples, there has long been
other very strong evidence that molecular topol-
ogy is the dominant physics in melt dynamics.
This emerges from the phenomenology of “long
38
Polymer Physics

chain branched” (LCB) melts. These materials,
commonly used in industry, possess identical
molecular structure to their linear cousins on the
local scale, but contain rare molecular branches
(they
differ
from
the
“polymeric
fractals”
discussed above in that their linear sections are
long enough to be entangled). The density of
branching varies from one branched carbon in
every 10,000 to 1 in 1000. This level is chemically
all but undetectable, yet the melt rheology is
changed out of all recognition if the molecular
weight is high enough (Small 1975). Providing
that M  Me, the limiting low-shear viscosity
may be much higher for the same molecular
weight. Moreover in strong extensional ﬂows the
melt responds with a much higher apparent vis-
cosity than in linear response. This phenomenon,
vital for the stable processing properties of
branched melts, is called “extension hardening.”
The effect is all the more remarkable because in
shear ﬂows, branched, as well as linear, melts
exhibit a lower stress than would be predicted by
a continuation of their linear response (Meissner
1975) (they are “shear-thinning”). A fascinating
example of the difference between linear and
branched entangled melts is well-known from
ﬂow visualization experiments. The velocity
ﬁeld in a strong “contraction ﬂow” of a linear
polymer melt resembles that of a Newtonian
ﬂuid, while that of a branched polymer sets up
large vortices situated in the corners of the ﬂow
ﬁeld. Slight changes to the topology of the mole-
cules themselves give rise to qualitatively differ-
ent features in the macroscopic ﬂuid response.
The most successful accounts of these phe-
nomena have been given by the tube model. The
idea is to deploy the theoretical physicists’ favor-
ite strategy of replacing a difﬁcult many-body
problem with a tractable single-body problem in
an effective ﬁeld. In this case the “single body” is
the single polymer chain, and the effective ﬁeld
becomes a tubelike region of constraint along the
contour of the chain. The tube is invoked to rep-
resent the sum of all topological non-crossing
constraints active with neighboring chains, and
the tube radius, a, is of the order of the end-to-
end length of a chain of molecular weight Me. In
this way, only chains of higher molecular weight
than Me are strongly affected by the topological
constraints (see Fig. 5).
The tube was ﬁrst invoked by Edwards
(Edwards 1967) in an early model for the trapped
entanglements in a rubber network. The conse-
quences of the idea for dynamics were ﬁrst
explored by de Gennes (1971), again in the con-
text of networks. A free chain in a network would
Polymer Physics,
Fig. 5 A tubelike region of
constraint arises around any
selected polymer chain in a
melt due to the topological
constraints of other chains
(small circles) in its
neighborhood (diagram
courtesy of R. Blackwell)
Polymer Physics
39

be trapped by neighboring chains into tube of
radius a deﬁned by its own contour, suppressing
motion perpendicular to the tube’s local axis
beyond a distance of a, but permitting both local
curvilinear chain motions and center-of-mass dif-
fusion along the tube. de Gennes coined the term
“reptation” for this snake-like wriggling of the
chain under Brownian motion. The theory gives
immediately a characteristic timescale for disen-
gagement from the tube by curvilinear center-of-
mass diffusion. This disengagement time td is
naturally proportional to the cube of the molecular
weight of the trapped chain (this arises from com-
bining the Fickian law of diffusive displacement
of length L with time t, t~L2, recognizing that
path length L~M, with one extra power arising
from the proportionality of the total drag on
molecular weight). Very signiﬁcantly, de Gennes
also realized that a tubelike conﬁning ﬁeld would
endow a dangling arm, ﬁxed to the network at one
end, or belonging to a star-shaped polymer in a
network, with exponentially slow relaxations. In
this topology reptation would be suppressed by
the immobile branch point (de Gennes 1975), and
only exponentially rare retractions of the dangling
arm would disengage it from its original tube (see
Fig. 6 below). In the late 1970s, S.F. Edwards and
M. Doi developed the tube concept into a theory
of entangled melt dynamics and rheology for
monodisperse, linear chains (Doi and Edwards
1986), ﬁnding extensions to ﬂow instabilities
(McLeish and Ball 1986), blends (Watanabe and
Kotaka 1984), and polymers of controlled archi-
tecture that go beyond the star topology (Pearson
and Halfand 1984) to H-polymers (McLeish et al.
1999) and combs (Inkson et al. 2006).
Fully atomistic simulations of polymer melts
are now able to examine entanglement effects. It is
now possible to conduct molecular dynamics sim-
ulations of, for example, elastically connected
Lennard-Jones polymers that contain 50 chains
each of 10,000 monomers well into the regime
in which entanglements dominate the dynamics
(Pütz et al. 2000). This technology is now at the
point at which direct comparisons to experimental
results such as NSE is now possible. The other
advantage of large simulations is that they may
mimic the “ideal” experiment in which everything
may in principle be measured. This has been
exploited in tests of fundamental theories of
entanglements (see below) (Everaers 1998).
The growing quantity of data on branched
molecules of controlled molecular weight and
topology has provided severe tests of the tube
concept at a level beyond that probed by linear
chains (McLeish 2002). The hierarchical nature of
conﬁgurational relaxation at the molecular level in
particular has been turned from speculation into
orthodoxy. In the simplest case of entangled star
polymers, the theory suggests that chains escape
Polymer Physics, Fig. 6 The process of arm retraction
predicted by the tube model for the case of dangling
entangled arms, as from the branch point of a star polymer.
Unlike in reptation, reconﬁguration of the outer parts of the
arm occurs many times for one relaxation of deeper
segments
40
Polymer Physics

from their conﬁning tubes not by reptation, which
is suppressed by virtue of the immobile branch
point, but by a process of arm retraction, present
but largely eclipsed in the case of linear polymers
(see Fig. 6).
The effect on the viscosity of replacing linear
molecules with those of identical molecular
weight, but of star topology, is striking: now
  ea Ma=Me
ð
Þ
Ma > Mc
ð25Þ
is the dominant form of the molecular weight
dependence (where Ma is the molecular weight
of the dangling arm), rather than ~M3.4 (in the
case of linear polymers the entire effect of these
ﬂuctuations is to change the apparent exponent of
this relation from 3 to 3.4 up to a high molecular
weight of order 103 entanglements, where it satu-
rates at the “bare reptation” value of 3). In
entangled melts with repeated levels of branching,
the retraction dynamics of outer levels generate
the slower retraction of inner branches in a hier-
archical way. The most advanced application of
this process has been on materials that combine
the complexity of the gelation-point critical
ensemble (see section. “Single Chain Dynamics”
above) with the physics of entanglement. The
broad rheological spectrum of branching chemis-
try that builds molecules by grafting back repeat-
edly previously synthesized molecules (Das et al.
2006a) is captured by these calculations. When
the percolation transition is approached by cross-
linking entangled polymers, there exists a measur-
able region in which mean-ﬁeld statistics (D ¼ 4)
actually hold. Stress relaxation from such an
ensemble is logarithmic in this regime, but is
closely modeled by a dynamical scaling form in
which the dynamic exponent z is small (being
inversely proportional to the number of entangle-
ments between branch points) (Das et al. 2006b).
The wealth of experimental and simulation
data has sharpened the theoretical picture. With-
out exploding with new parameters, it has been
possible to capture, in a single model, modes of
entangled motion beyond pure reptation. In linear
response contour length ﬂuctuation (CLF), the
Brownian ﬂuctuation of the length of the entan-
glement path through the melt, modiﬁes early-
time relaxation. Similarly the process of con-
straint release (CR), by which the reptation of
surrounding chains endows the tube constraints
on a probe chain with ﬁnite lifetimes, contributes
to the conformational relaxation of chains at lon-
ger times. Both the processes of CLF and CR
contribute to the quantitative understanding of
linear rheology, such that the ~M3.4 law is no
longer a mystery (Milner and McLeish 1998;
Likhtman and McLeish 2002), but much of the
newer data still need to be examined quantita-
tively as sensitive tests of the detailed physics,
and many puzzles remain. These two additional
processes are visualized in Fig. 7.
Nonlinear Flow of Polymeric Fluids
In strong deformations the additional processes of
chain stretch, chain retraction, and branch-point
withdrawal emerge on the level of single chains
(the latter exclusively in the branched case), and
convective constraint release (CCR) at the level of
co-operative motion (Marrucci and Non-Newt
1996; Mead et al. 1998; Likhtman et al. 2000).
The most advanced formulation of the tube model
for linear polymers keeps the coarse grained
Polymer Physics, Fig. 7 A cartoon of the processes of
contour length ﬂuctuation (CLF) and constraint release
(CR) on a linear polymer in a constraining tube. In CLF
the chain end retracts via longitudinal ﬂuctuations of the
entangled chain, but without requiring center-of-mass
(reptation) motion. Re-extension of the chain end may
explore new topological constraints, reconﬁguring the
tube. In CR, an entanglement with a neighboring chain
(shown hatched) may disappear, allowing effective confor-
mational relaxation of that part of the tube, again without
reptation of the test chain itself. In both cases the former
tube conﬁguration is shown dark, the new, light.
Polymer Physics
41

coordinates of the chain, and allowing CCR
events to generate local Rouse jumps of the tube
(Likhtman et al. 2000). The idea is to retain full
information about average chain trajectories
instead of working indirectly with dynamic equa-
tions for the stress and orientation tensor. This
approach also allows quantitative predictions
about the single chain scattering function S(q),
and to develop a local description of CCR events.
The main assumptions of the ﬁrst version of the
theory (valid when there is no chain stretch) are:
(i) that CCR operates locally in reorienting chain
segments both into and away from the ﬂow direc-
tion, and (ii) that neither the number of entangle-
ments per chain Z ¼ M/Me nor the tube diameter
a changes. The ﬁrst assumption endows the tube
itself with a Rouse-like motion in which the local
hopping rate is coupled to the global deformation
rate via a single new parameter. The second
(constant length) assumption introduces a differ-
ence from ordinary Rouse-chain motion, and
limits the range of validity at ﬁrst (but see
below) to 0 < _g < 1= teZ2


.
No single set of variables will be able to diag-
onalize the essential entangled modes of motion,
namely (i) chain reptation, (ii) chain retraction,
(iii) tube-length ﬂuctuation and the new mode,
and (iv) Rouse-tube motion. However, the theory
is conventionally cast in a real-space notation for
the tube trajectory R(s, t) and its tangent curve
R0  @R
@s , functions of curvilinear distance s from
along the tube and time t. Our chains are mono-
disperse containing Z entanglements of tube
diameter a. The (stochastic) equation of motion
becomes (Graham et al. 2003):
R s, t þ Dt
ð
Þ ¼ kRDt þ R s þ Dx tð Þ, t
ð
Þ
þDt 3n
2
@2R
@s2 þ g s, t
ð
Þ


þDtl Z
2  s
	

 @R
@s þ 3DcZ R00 R0
ð
Þ
R0
j
j2 R0:
ð26Þ
The terms of this formulation describe, in
order, afﬁne convection of the tube, reptation,
CR Rouse motion of the tube, retraction of the
chain within the tube and chain stretch. This
model predicts in shear ﬂow a near plateau of
sxy _g
ð Þ between _gtd and _gtR, and an increase
proportional to _g1=2
beyond that (so that the
“shear-dependent
viscosity”
 _g
ð Þ ~
_g1=2 )
(see
Fig. 8). Both this feature and a prediction of strong
101
Non-stretching theory, n=10
Stretching theory, n=10
n=20
n=30
Slope 1/2
100
10–1
10–2
10–2
10–1
100
101
γ τd
σxy/G0
102
103
104
Polymer Physics, Fig. 8 Predictions of the local CCR model with chain stretch using cv ¼ 0.1 for values of Z ¼ 10,
20, 30. A comparison to the non-stretching version is given
42
Polymer Physics

extension hardening at rates faster than the inverse
chain stretch time have been quantitatively
matched to experiment.
The strongest tests of the predictions for chain
conformations have been performed in “neutron
ﬂow mapping “ experiments (Bent et al. 2003;
Graham 2006). Here a partially deuterated (for
neutron scattering contrast) polymer melt of
monodisperse or controlled architecture is passed
continuously through a complex ﬂow ﬁeld such as
a contraction, bounded by windows transparent to
both laser illumination and thermal neutrons. The
stress ﬁeld is measured in optical birefringence,
while single chain conformations are reported by
the neutron small angle scattering. Scanning the
apparatus across the neutron beam allows the
experiment to probe regions of the ﬂow with
varying strain histories. The experiments are com-
pared to calculations in which the model of (26) is
used both to calculate the ﬂow ﬁeld itself, then the
scattering function of chains subjected to the
stream lines that ﬂow through the neutron beams.
Figure 9 shows the results of one such experi-
ment. The key result is that relaxation to equilib-
rium structure takes place in the ﬂow at timescales
that depend on the chain length scale examined. It
also shows that no model containing just one
viscoelastic relaxation time is even qualitatively
able to account for the nonlinear physics of
entangled melts. The simplest must possess at
least two relaxation times, corresponding to
chain stretch (fast – by Rouse motion) and chain
orientation (slow – by reptation). At the purely
phenomenological level of the stress tensor the
emergent property is a rapidly relaxing trace, and
a slower traceless part to the stress.
One of the most remarkable predictions in non-
linear response of the tube model for entangled
polymers addresses the fruitful system of “bimodal
blends.”
These
controlled-composition
melts
Polymer
Physics,
Fig.
9 A
monodisperse
linear
entangled melt in a neutron ﬂow mapping experiment.
Flow is from bottom to top. Single chain scattering func-
tions from windows B, D, and F are compared with contour
predictions on the left. Chain conﬁgurations relax during
passage through the channel from an initial strain. On the
right, contours of principal stress (left) are compared with
calculations (right)
Polymer Physics
43

comprise two monodisperse fractions (short and
long chains) of different degrees of entanglement
ZS, ZL and a chosen volume fraction of the long
chain fraction fL. The parameters range, therefore,
over a three-dimensional space, even for this sim-
ple system. The linear response is already very rich
(Viovy et al. 1991). It is possible, for example, for
the reptation of the long fraction to be determined
by a tube of entanglements formed from all the
chains in the melt. However, if the difference in
degree of entanglement is great enough, the
constraint-release from the more rapid reptation of
the short chains reveals a “fat tube,” constituted
only from entanglements between long chains. In
this case the terminal relaxation time is determined
by a renormalized reptation of long chains within
these “fat tubes.”
An even more remarkable phenomenon was
predicted, then demonstrated, in strong exten-
sional ﬂows of such bimodal blends (Read et al.
2012). For when the constraint-release of short
chains is dominant, the nonlinear stretch-relaxation
(effective Rouse) time tRL for the long chains is
actually increased by the presence of the short-
chain diluent, so that tRL(fL) ¼ tRL(0)/fL. The
effect can be seen clearly in the comparison of the
two sets of curves in Fig. 10, where the onset of
extension-hardening
appears
at
proportionally
lower ﬂow rates for the blend with the lower con-
centration of long chains. The highly counterintu-
itive increase of stretch relaxation time when a
more rapidly relaxing fraction is added arises
from the subtle way that constraint-release from
short chains give rise to a slower tube-length ﬂuc-
tuation time (in the “fat tube”), and through this
renormalized process generating a corresponding
stretch relaxation time in nonlinear response. The
connection between extension hardening and
“melt-strength” in polymer processing means that,
long before this process was understood, it had
been employed to stabilize processing in industrial
blends. Although these are generically much more
complex than the idealized bimodal blend, the high
molecular weight tail of an industrially polydis-
perse blend may behave in the same way as the
long-chain fraction of the ideal blend.
At a more approximate level, it is possible to
combine the complexities of nonlinear response
and complex branched topologies in entangled
melts. All the linear and nonlinear molecular pro-
cesses of chains in tube-like entanglement ﬁelds
are present, together with one additional process,
that of “branch point withdrawal.” When a strand
connecting two branch points is very highly
stretched, the ﬁnite size of the clusters it connects
(in contrast to the network case) becomes appar-
ent, and one of the clusters may topologically
collapse into the deforming tube of the central
strand. In the simplest case of the H-polymer the
two outer arms are drawn into the tube of the
“cross-bar” segment (see Fig. 11).
There are consequences of the process for both
chain
conformation
(scattering)
and
stress
response (rheology). If the retracting arms are
labeled in a scattering experiment, very strong
signal enhancement is seen in the direction of
the deformation (McLeish et al. 1999; Heinrich
et al. 2004). At the same time, the growing exten-
sional stress, until that point resembling that of a
cross-linked network, reaches a near plateau. The
effect of this at the level of the process engineer-
ing is to endow strongly branched melts with both
extension hardening (leading to ﬂow stabilization)
and good processability. A useful modeling tool for
branched melts has been derived from the ideal
Polymer Physics, Fig. 10 (From ref. Read et al. 2012)
Transient extensional viscosity for a polyisoprene bimodal
blend of ZL ¼ 100, ZS ¼ 7, and fL ¼ 0.2 (upper curves) at
rates in s1 of 0.1, 1.24, 9.91, 101.6 and the same blend
with fL ¼ 0.04 (lower curves) at rates in s 1 of 0.1, 0.5, 2,
9.81, 46.7, 224. Also shown are the corresponding theo-
retical predictions. All data and rates are time–temperature
shifted to a reference temperature of 25 C. The Rouse time
of the long chains is indicated on the time axis
44
Polymer Physics

“pom-pom” architecture (McLeish and Larson
1998). This generalization of the H-polymer allows
the number of arms attached at either end of the
cross-bar, q, to vary. So q becomes a molecular
parameter controlling the degree of strain harden-
ing. Creating multiple modes from this model
allows accurate models to be built for commercial,
highly branched melts (Inkson et al. 1999;
Blackwell et al. 2000; Graham et al. 2001). Com-
puting in complex geometries with these models
has successfully predicted features of the ﬂows
particular to branched melts, such as recirculating
vortices upstream of a contraction and very persis-
tent sheets of high birefringence downstream from
re-entrant corners, sometimes known as “stress-
fangs” (Lee et al. 2001).
Multiphase Polymeric Fluids
In the foregoing, the spatial structure of polymeric
ﬂuids has remained essentially homogeneous, all
heterogeneities remaining at the level of entangle-
ments, or correlation volumes, in solution. The
hidden reason for this is that we have considered
systems containing just one chemistry of mono-
mer. Yet one of the great attractions of polymers is
their tendency to develop complex spatial struc-
tures when different chemistries are combined,
either in the case of entire chains, when we create
polymer blends, or within single chains, referred
to as copolymers. In the latter case, especially
interesting structures arise when the distinct
monomers are correlated in sequence along the
chain, forming block copolymers. The simplest
example would be a string of n monomers of
chemistry A followed by m of chemistry B. This
is an A-B diblock copolymer. The essential reason
for the sensitivity to local chemistry is that the
entropy of spatial translation per monomer in a
polymeric ﬂuid is extremely low. The usual Van’t-
Hoff term Strans ¼  k T log f is divided by the
degree of polymerization of the chain so that it
effectively competes with the mild Van der Waals
dominated enthalpic interaction between mono-
mer units, which tend to favor proximity of iden-
tical chemical units: polymers tend therefore
toward demixing. In blends the demixing com-
petes with the slow, viscoelastic dynamics we
discussed in the last section, creating spatially
complex morphologies that are determined kinet-
ically. In the case of block copolymers, the
demixing occurs locally, conﬁned to spatial scales
of the block subchain radii. The demixing now
competes with the chain elasticity we discussed in
section “Single Polymer Chain Physics.” The
connection of polymer sequence with emergent
structure illustrates the high potential information
Polymer Physics,
Fig. 11 The process of
branch point withdrawal: a
segment with greater than
equilibrium tension pulls
attached dangling arms
some distance into its own
tube, thus shortening their
effective entangled path
length
Polymer Physics
45

content of a macromolecule. It is an example of
the genotype-phenotype pattern developed to a
much higher degree in the case of the DNA-
embedded genetic code. This ﬁeld, like that of
controlled architecture dynamics, is an area of
polymer physics where the complex emergent
phenomena have required a parallel implementa-
tion of careful synthetic chemistry (Ruokolainen
et al. 2005), experimental physics (Adhikari and
Michler 2004), and advanced theoretical tech-
niques (Matsen 2005) to explore, and is growing
extremely rapidly.
Polymer Blends
The starting point for a conceptual understanding
of the physics of polymer blends is a mean-ﬁeld
model for the free energy of mixing of two species
such that one occupies a total volume fraction f.
Known
as
the
Flory-Huggins
free-energy
(Koningsvelt et al. 2001), it balances the entropy
of mixing of the two components against the
energy difference of mixed and demixed states:
DFmix ¼ kB T
f
NA ln f þ 1  f
NB
ln 1  f
ð
Þ þ wf 1  f
ð
Þ


:
ð27Þ
The control parameters for this theory are the
two molecular weights and the (temperature
dependent) interaction (“Flory”) parameter w.
The whole system is therefore three-dimensional:
the monomer interaction is best normalized with
the mean molecular weight so that wN
! is the
essential
parameter
that
controls
interaction
strength. Then NA/NB becomes the asymmetry
parameter while f controls the composition. The
possibility of phase separation means that ΔFmix
can be minimized by forming regions with differ-
ent values of f if the curvature @2ΔFmix/@f2 is
anywhere less than zero. This in turn occurs for all
w > wc. Phase separation then occurs for all systems
whose mean composition falls between the two
minima of ΔFmix(f), a region that broadens as w
moves further (as temperature is changed) from wc.
This behavior is mapped in Fig. 12. The region
between the two curves (binodal and spinodal) of
the plot corresponds to compositions and temper-
atures where the curvature of ΔFmix(f) is positive,
producing a ﬂuid that is locally stable to compo-
sition ﬂuctuations though globally unstable to
phase separation. In this case droplets of the sep-
arated phase have to nucleate, giving an initially
disconnected morphology. Within the spinodal
curve on the other hand, the ﬂuid is unstable to
local and inﬁnitesimal changes in composition, so
that natural thermal ﬂuctuations of composition
are ampliﬁed. The presence of a fastest growing
wavelength leads to a connected (or “spinodal”)
Polymer Physics,
Fig. 12 Regions of phase
separation in polymer
blends with the Flory-
Huggins model. Phase
separation occurs within the
binodal curve (solid curve),
but is unstable locally only
within the spinodal (dashed
curve)
46
Polymer Physics

morphology for most of this region. Since the ﬁnal
minimum in free-energy is total phase separation,
whatever intermediate structure evolves eventu-
ally coarsens with time with well-known growth
laws depending on whether hydrodynamics or
diffusion is dominating (Onuki 2002). This
beguilingly simple map hides a great deal of latent
complexity, however. More recently, the recogni-
tion that the spinodal process leads to a morphol-
ogy dependent on both the local free energy and
the distribution of initial ﬂuctuations has gener-
ated experimental and theoretical explorations of
the wider control space that includes trajectories
across the composition diagram (Henderson and
Clarke 2004), variations on boundary conditions
and viscoelastic effects (Tanaka et al. 2005).
A striking example is given by the “target” struc-
tures that result from kinetic trajectories that
spend some time in the nucleation region of the
composition space before (cooling) into the
spinodal region. During the ﬁrst period, small
nuclei are allowed to form but sustain limited
growth. Instead, the growth occurs in the locally
unstable region using the nuclei as sources of
unstable ﬂuctuations. Because the Fourier wavelet
decomposition of a spherical nucleus with a sharp
boundary consists of spherical waves centered on
the nucleus, it is these that are ampliﬁed by the
growth process, or reverse diffusion, and struc-
tures of nested spheres of varying composition
appear during it. Since phase separating polymers
typically also have a glass transition temperature,
it is possible to quench the composition structure
at any point in the phase separation.
Viscoelasticity may play a modifying role at
both early and late stages of the phase separation.
At early times, any dominant viscoelastic mode,
such as reptation, can undergo mode-mixing with
the dominant phase separation time to produce to
two timescale process of separation (Clarke et al.
1997). This may result in non-monotonic concen-
tration growth with time, since of the two resulting
modes one typically decays while the other grows.
At later stages, a strong viscoelasticity in at least one
phase causes the heterogeneous ﬂuid to retain the
mutual connectivity of both phases for much longer
than in Newtonian ﬂuids (Tanaka et al. 2005).
Figure 13 illustrates the high degree of univer-
sality of this effect, contrasting dilute, and con-
centrated
polymer
solutions
with
a
protein
Polymer Physics, Fig. 13 Confocal imaging of viscoelastic phase separation from (Tanaka et al. 2005) showing the
time development of structure from (a) dilute polymer solution, (b) protein solution, (c) concentrated polymer solution
Polymer Physics
47

solution in which the protein molecules behave
more as colloidal particles than polymer chains.
Although the structures coarsen, they retain con-
nectivity of the minority phase rather than suffer it
breaking into droplets. A similar effect is gener-
ated by the natural composition dependence of
mobility. It is unlikely that the mobilities of the
two demixing species will remain independent of
the local composition, since the natural drag con-
stants within the two ﬁnal demixed phases will
typically differ. The phase of lower mobility then
becomes kinetically quenched earlier than that of
higher mobility. This nonlinearity affects the con-
nectivity of the morphology at long times (Mao
et al. 2001).
Block Copolymers
The demixing tendencies of polymers of different
chemistries become very rich when it competes
with the feature at the heart of polymer physics
itself: that of connectivity. By connecting a chain
of A-monomers to one of B-monomers, they are
forced by the spatial correlations that chain con-
nectivity induces into proximity. Within a mean
ﬁeld picture, the repulsive interaction in the free
energy density kBTwfAfB (from the last term in
(27)) competes with the entropic chain elasticity
Felas ¼ kBT R2
A=NAb2 þ R2
B=NBb2


. In contrast
to previous sections, we consider ﬁrst the case of
dense chains (melts), then solutions, and ﬁnally
the effects within single chains of such controlled
chemical architecture.
Consider ﬁrst the case of the diblock copoly-
mer just outlined. In a melt, when the interaction
parameter w is large enough, the chains must
locally segregate into regions rich in one or other
of the polymers. The molecules themselves
clearly minimize their contribution by situating
their midpoints where the two chemistries join at
the interface between the two regions. Topology
dictates that at most two A-chains may span an
A-rich region, so consequently the length scale of
the morphology must be of the same order as the
radius of gyration of the chains. In the symmetric
case the system spontaneously forms lamellae of
alternating composition whose width increases as
the interaction parameter does though with a weak
power law of w1/6. The width of the interface
region in which both A and B monomers are
present decreases with w. In a fully quantitative
“strong segregation theory” of this physics
(Semenov 1985), the lamellum width L and inter-
face width w obey
L ¼ 2
8
3p4
	

1=6
N2=3 bw1=6 ;
w ¼
2b
6w
ð
Þ1=2 :
ð28Þ
But additional physics comes into play as soon
as the two blocks are of different length, for now
the entropy of conﬁnement of the chains in the
plane of the interface does not balance (we did not
consider that in the above), with the result that the
interface tends to curve away from the domains
containing the longer chains. Other more complex
morphologies become candidates for the mini-
mum in free energy: periodic cylinders (C) and
spheres (S) as well as the more exotic forms of the
gyroid (G), perforated lamellae (PL), and double
diamond lattices (D) of Fig. 14.
Experiments on carefully synthesized block
copolymers, especially the model polystyrene-
polyisoprene system, have mapped out the mor-
phology diagram in terms of interaction (via tem-
perature, as in blends) and composition of the
diblock. Calculations were ﬁrst performed near
the critical point, where segregation of the two
species is only weak, and the free energy can be
expanded in powers of the difference of the local
mean concentrations f ¼ (fA  fB) (Leibler
1980), but can be extended into strong segregation
by a fully continuous self-consistent mean ﬁeld
theory (Matsen 2002) that ignores only the ﬂuc-
tuations in composition. Results and comparison
with experiment are shown in Fig. 15.
Clearly the calculations are qualitatively and,
in some aspects, quantitatively in agreement,
especially far from the disordered (fully mixed)
state. However, ﬂuctuations clearly have an impor-
tant effect near the boundary. The topology of the
diagram at the critical point is actually changed by
them, stabilizing a ﬁnite region of the lamellar
phase. Quite recently, ﬁeld-theoretical methods
48
Polymer Physics

Polymer Physics,
Fig. 14 Potential
candidate morphologies for
block copolymer melts,
from (Matsen 2002)
Polymer Physics,
Fig. 15 The morphology
map for diblocks as a
function of interaction
parameter and composition
by (a) self-consistent ﬁeld
calculation and (b)
experiment on PS-PI
diblocks. From (Matsen
2002)
Polymer Physics
49

for computing the full effect of ﬂuctuations in the
partition function of block copolymers have been
introduced (Fredrickson 2007). Other natural
extensions include increasing the complexity of
the chemical structure of the block copolymer.
Taking only one step to the tri-block permits a
very wide class of morphologies that mix those of
the diblock, so that for example spheres of A may
decorate cylinders of B within a matrix of C. Such
materials are by no means only of academic inter-
est, as they constitute the fundamental technology
behind toughened plastics, in which the minority,
rubbery phase prevents crack propagation within a
majority glassy phase (Leibler 2005). We can begin
to see the sequence of the chain corresponding to
an information content (“genotype”) that implicitly
codes for the morphology (“phenotype”) of the
emergent morphology.
Block copolymers in solution, either of a low
molecular weight species or of a simple homopol-
ymer, may act as polymeric versions of the famil-
iar surfactants. Their self-assembly picks out the
same structures as we have already seen in the
context of bulk microphase separation (lamellae,
cylinders, and spheres) with now the difference that
these self-assembled structures exist in isolation
rather than in a regular array. The corresponding
structures are vesicles, wormlike micelles, and
spherical micelles (Discher and Eisenberg 2002).
Examples are given in Fig. 16. These phases
have a visibly complex form, since they are
largely determined kinetically: because of the
long timescales for diffusion and collision of the
individual micelles, and of the high activation
energy for mutual rearrangement, merger, and
breaking, true equilibrium is very hard to reach
in these systems. So vesicles of widely different
radius may coexist, together with nested struc-
tures and complexes. The transitions between lin-
ear and spherical structures, which may be driven
by changes in temperature or pH depending on the
chemistry of the polymers, may exhibit a rich
kinetics in which cylindrical structures emerge
from spherical and vice versa.
We ﬁnally consider the generalization of the
coil collapse transition we saw in the case of dilute
chains in poor solvents in section “Single Polymer
Chain Physics.” When all monomers are identical
in their interaction with the solvent the form of the
resultant globule will be on average spherical,
together with natural thermal ﬂuctuations of the
interface. When the polymer contains blocks of
heterogeneous interaction with solvent, as well as
self-interaction, the globule may become a much
more complex object. Experiments on diblocks
indicate that a range of nonspherical geometries
may be generated by controlling the architecture
of the primary chain (Govorun et al. 2001). Cal-
culations balancing chain stretch, mutual interac-
tion, and surface tension against the solvent
(Khokhlov et al. 2005) indicate that it is theoret-
ically possible, using only two monomers, to code
Polymer Physics, Fig. 16 Schematic of chain conﬁgu-
ration in the wall of a block copolymer vesicle and its
architectural control (a) and transmission electron micro-
graph of polymeric vesicles (b), from (Discher and
Eisenberg 2002)
50
Polymer Physics

for transitions between near-spherical to prolate
and ﬁnger-like forms of the collapsed globule.
More complex features such as budded and
pearled structures also emerge from the same
mean-ﬁeld level of theory that successfully treats
block copolymer melts. This single-molecule
form of the coding of emergent phenotype from
the information coded as a polymer sequence is
very suggestive of nature’s own method of
constructing the functional single molecules of
enzymes, motors, and cellular structures. For pro-
teins
are
“just”
copolymers
(of
a possible
20 amino acid monomer set) that code in their
sequence for absolutely speciﬁc forms of their
collapsed state. The protein-folding problem has
generated a huge literature (Dinner et al. 2000),
although rather little of it actually exploits poly-
mer physics, with its natural high order of dimen-
sionality and degrees of freedom (McLeish 2005)
to understand this ultimate reﬁnement of the art of
coded morphology.
The complex morphologies available to liquid-
liquid phase separation (LLPS) in polymeric
blends, or between internally structured polymers,
have likewise recently been compared to biologi-
cal systems that appear to demonstrate a sort of
LLPS within cells (Shin and Brangwynne 2017).
There are likely to be many processes at work,
recruited to deliver the internal droplets of con-
trolled size and composition that appear to be
essential to a number of biological functions,
from replication and photosynthesis to cell-stress.
There are indications that proteins in unfolded
(or “disordered” states) are frequently at play
here, suggesting that at least some of the molecu-
lar processes underlying such biological struc-
tures are shared with those of synthetic polymer
physics.
Future Directions
Several current themes suggest a rich future for
polymer physics, notwithstanding the experience
of history that the richest veins of research to
come will be those currently unforeseen. The gen-
eral area of biomimetic or, perhaps better, bio-
suggestive polymer physics is bound to be an
area of growth. Biology has already mastered the
art of synthesizing single polymers that act as self-
assembling machines, chemical reactors, and sep-
aration systems. Artiﬁcial polymers that act in
these ways are certainly possible, and may not
need to be as exactly structured as proteins are in
order to deliver function. We have already seen
that theoretical schemes exist for designing block
copolymers that will collapse into predetermined
shapes and forms (Khokhlov et al. 2005). Future
designs of active versions of protein-like poly-
mers may also go beyond the chemical “fuel” of
ATP dephosphorylation, perhaps using light as
both energy and signaling source. Optically acti-
vated mechanical transitions in polymers have
already been demonstrated (Hugel et al. 2002).
Effectively equally fast response can be elicited
from pressure changes. In the long term one might
hope for advanced therapeutics from this route,
especially in combination with polymer-based
encapsulation systems such as triggered micelles
of block copolymers. A surprising candidate for a
toolkit of nano-engineered machines and actively
self-assembled polymers is DNA itself (Dunn
et al. 2015). The molecule’s base-pair recognition
and bonding, essential for generic replication, can
be recruited for designed self-assembly, while the
bond energy released in forming double-stranded
DNA is able to act as a sort of “fuel.” This system
shows considerable promise.
Structural materials properties also have many
things to learn from evolution. As it becomes
possible to moderate and control microstructure,
both in terms of crystallinity and microseparation,
so polymeric nanocomposites will be able to real-
ize combinations of strength and stiffness cur-
rently existing as ideals (Leibler et al. 1994).
A related direction brings polymer physics into
biological research directly. Dynamic neutron
scattering by neutron spin echo (Bu et al. 2005),
as well as advanced NMR relaxation techniques,
will assist the current move toward exploring the
role of dynamics in molecular biological function
on a similar footing to the achievements in the
area of structure. Even thermal dynamics is begin-
ning to be recognized as a generator of functions
such as signaling, in an analogous way to the
emergence of rubber elasticity from the same
Polymer Physics
51

source (Hawkins and McLeish 2004). Technolog-
ically, the use of artiﬁcial polymers to create scaf-
folds for tissue engineering will require a balance
of local biochemical interaction and global
mechanical and topological structure formation.
The key underpinning science of biocompati-
ble and biomimetic polymers is the control of self-
assembly. Already there are a number of “supra-
chemical” options of noncovalent, reversible
polymerization (Lehn et al. 1990). Playing with
nature’s alphabet of peptide-forming amino acids,
which naturally self-assemble via main-chain
hydrogen bonds, gives a rich system in which
chirality becomes a new control parameter for
the equilibrium structure (Davies et al. 2006).
Combining main-chain self-assembly with side-
chain functionality may prove to open up new
classes of functional polymeric materials.
The
growth
of
conducting
and
semi-
conducting
polymeric
materials
within
a
burgeoning new sector of the electronics industry
is already well under way. But this area has been
driven largely by technology, and much of funda-
mental science remains to be understood, espe-
cially at the level of many chain, materials physics
(Barford 2005). The changing demands of the
world’s energy economy are bound to put pressure
on developments of organic, polymer-based pho-
tovoltaic materials, as well as lightweight polymer
gel energy storage. The combination of informa-
tion processing and advanced structural properties
within new polymeric materials is a tempting
prospect.
Bibliography
Primary Literature
Adam M, Delsanti M (1984). J Phys France 45:1513
Adhikari R, Michler GH (2004) Inﬂuence of molecular
architecture on Morphology and Micromechanical
behaviour of styrene/butadiene block copolymer sys-
tems. Prog Polym Sci 29:949–986
Ball RC, Doi M, Edwards SF, Warner M (1981). Polymer
1010:22
Barford W (2005) Electronic and optical properties of
conjugated polymers. Oxford University Press, Oxford
Bent J et al (2003). Science 301:1691–1695
Blackwell RJ, McLeish TCB, Harlen OG (2000). J Rheol
44:121
Bu Z, Biehl R, Monkenbusch M, Richter D, Callaway DJE
(2005) Coupled protein domain motion in Taq poly-
merase revealed by neutron spin-echo spectroscopy.
PNAS 102:17646–17651
Castillo HE, Goldbart P (2000). Phys Rev E 62:8159
Cates ME (1985) Excluded volume and hyperscaling in
polymeric systems. J Phys Lett 46:L837–L843
Clarke N, McLeish TCB, Pavawongsak S, Higgins JS
(1997) Viscoelastic effects on the phase-separation of
polymer blends. Macromolecules 30(15):4459–4463
Daoud M et al (1975). Macromolecules 8:804
Das C, Inkson NJ, Read DJ, Kelmanson Mark A, McLeish
TCB (2006a). J Rheol 50:207
Das C, Read DJ, Kelmanson MA, McLeish TCB (2006b).
Phys Rev E 74:011404
Davies RPW, Aggeli A, Beevers AJ, Boden N, Carrick
LM, Fishwick CWG, McLeish TCB, Nyrkova I,
Semonov AN (2006) Self-assembling β-sheet tape
forming peptides. Supramol Chem 18:435–443
de Gennes PG (1971). J Chem Phys 55:572
de Gennes PG (1972). Phys Lett 38A:339–341
de Gennes PG (1975). J Phys (Paris) 36:1199
de Gennes PG (1986) Scaling concepts in polymer physics.
Cornell University Press, Ithaca
Deam RT, Edwards SF (1976). Phil Trans R Soc A 280:
317–353
Denissen W, Rivero G, Nicolaÿ R, Leibler L, Winne JM,
Du Prez FE (2015). Adv Funct Mater 25:2451–2457
des Cloiseaux J (1975). J Phys 36:281
des Cloiseaux J (1981). J Phys 42:635
des Cloiseaux J, Jannink G (1990) Polymers in solution.
Oxford University Press, Oxford
Dinner AR, Šali A, Smith LJ, Dobson CM, Karplus
M (2000) Understanding protein folding via free-
energy surfaces from theory and experiment. Trends
Biochem Sci 25:331–339
Discher DE, Eisenberg A (2002). Science 297:967–973
Dobrynin AV, Rubinstein M (2005) Theory of polyelectro-
lytes in solutions and at surfaces. Prog Polym Sci
30(11):1049–1118
Dunn KE, Dannenberg F, Ouldridge TE, Kwiatkowska M,
Turberﬁeld AJ, Bath J (2015). Nature 525:82–86
Edwards SF (1965). Proc Phys Soc 85:613
Edwards SF (1966). Proc Phys Soc Lond 88:265
Edwards SF (1967). Proc Roy Soc London 92:9
Edwards SF (1976) The conﬁguration and dynamics of
polymer chains. In: Balian R, Weill G (eds) Molecular
ﬂuids. Gordon and Breach, London, pp 151–208
Everaers R (1998). Eur Phys J B 4:341
Ferry JD (1986) Viscoelastic properties of polymers.
Wiley, New York
Fetters LJ, Lohse DJ, Graessley WW (1999). J Polym Sci
Polym Phys Edn 37:1023
Feynman R (1965) Hibbs quantum mechanics and path
integrals. McGraw Hill, Kogakusha
Flory PJ (1953) Principles of polymer chemistry. Cornell
University Press, Ithaca
Fredrickson GH (2007) Computational ﬁeld theory of
polymers: opportunities and challenges. Soft Matter 3:
1329–1334
52
Polymer Physics

Govorun EN, Ivanov VA, Khokhlov AR, Khalatur PG,
Borovinsky AL, Grosberg AYU (2001). Phys Rev
E 64:R40903
Graham RS (2006) Macromolecules 39:2700–2709
Graham RS, McLeish TCB, Harlen OG (2001). J Rheol
45:275
Graham RS, Likhtman AE, Milner ST, McLeish TCB
(2003) J Rheol 47:1171
Guth E, Mark H (1934). Monatshefte Chemie 65:93
Ha BY, Liu Andrea J (1998) Effect of non-pairwise-
additive interactions on bundles of rodlike polyelectro-
lytes. Phys Rev Lett 81:1011
Hawkins RJ, McLeish TCB (2004) Coarse-grained model
of entropic allostery. Phys Rev Lett 93:098104
Heinrich M, Pyckhout-Hintzen W, Allgaier J, Richter D,
Straube E, McLeish TCB, Wiedenmann A, Blackwell
RJ, Read DJ (2004) Small-angle neutron scattering
study of the relaxation of a melt of polybutadiene
H-polymers following a large step strain. Macromole-
cules 37:5054–5064
Henderson IC, Clarke N (2004). Macromolecules 37:
1952–1959
Higgins JS, Benoit H (1994) Polymers and neutron scat-
tering. Clarendon Press, Oxford
Hugel T, Holland NB, Cattani A, Moroder L, Seitz M,
Gaub HE (2002) Single-molecule optomechanical
cycle. Science 296:1103–1106
Inkson NJ, McLeish TCB, Groves DJ, Harlen OG (1999).
J Rheol 43:873
Inkson NJ, Graham RS, McLeish TCB, Groves DJ,
Fernyhough
CM
(2006).
Macromolecules
39:
4217–4227
James H, Guth E (1947). J Chem Phys 15:669
Jian T, Vlassopoulos D, Fytas G, Pakula T, Brown
W (1996). Colloid Polym Sci 274:1033
Khokhlov AR, Semenov AN, Subbotin AV (2005) Shape
transformations of protein-like copolymer globules.
Eur Phys J E 17:283–306
Klein PG, Adams CH, Brereton MG, Ries ME, Nicholson
TM, Hutchings LR, Richards RW (1998). Macromole-
cules 31:8871
Koningsvelt R, Stockmayer WH, Nies E (2001) Polymer
phase diagrams. Oxford University Press, Oxford
Kuhn W (1936). Koll Z 76:258
Lee K, Mackley MR, McLeish TCB, Nicholson TM,
Harlen OG (2001) Experimental observation and
numerical simulation of transient stress fangs within
ﬂowing molten polyethyelene. J Rheol 45:1261–1277
Lehn JM, Mascal M, DeCian A, Fischer J (1990). J Chem
Soc Chem Commun 479. https://pubs.rsc.org/en/
content/articlelanding/1990/c3/c39900000479/
unauth#!divAbstract
Leibler L (1980). Macromolecules 13:1602
Leibler L (2005) Nanostructured plastics: joys of self-
assembling. Prog Polym Sci 30:898–914
Leibler L, Ajdari A, Mourran A, Coulon G, Chatenay
D
(1994)
Ordering
in
macromolecular
systems.
Springer, Berlin
Likhtman AE, McLeish TCB (2002). Macromolecules 35:
6332–6343
Likhtman AE, McLeish TCB, Milner ST (2000). Phys Rev
Lett 85:4550
Lusignan CP et al (1995). Phys Rev E 52:6271
Manning GS (1969) Limiting laws and counterion conden-
sation in polyelectrolyte solutions I. Colligative prop-
erties. J Chem Phys 51(3):924–933
Mao
Y,
McLeish
TCB,
Teixeira
PIC,
Read
DJ
(2001) Asymmetric landscapes of early spinodal
decomposition. Eur Phys J E 6:69–77
Marko JF, Siggia ED (1995) Stretching DNA. Macromol-
ecules 28:8759
Marrucci G, Non-Newt J (1996). Fluid Mech 62:279
Matsen MW (2002) The standard Gaussian model for
block copolymer melts. J Phys 14:R21–R47
Matsen MW (2005) In: Gompper G, Schick M (eds) Soft
condensed matter. Berlin, Wiley-VCH
Mazur J, McCrakin FL (1968). J Chem Phys 49:648
McLeish TCB (2002) Tube theory of entangled polymer
dynamics. Adv Phys 51:1379–1527
McLeish TCB (2005) Protein folding in high-dimensional
spaces: hypergutters and the role of nonnative interac-
tions. Biophys J 88:172–183
McLeish TCB, Ball RC (1986). J Polym Sci Polym Phys
Edn 24:1755; McLeish TCB (1987) J Polym Sci Polym
Edn Phys 25:2253
McLeish TCB, Larson RG (1998). J Rheol 42:81
McLeish TCB, Allgaier J, Bick DK, Bishko G, Biswas P,
Blackwell R, Blottière B, Clarke N, Gibbs B, Groves
DJ, Hakiki A, Heenan R, Johnson JM, Kant R, Read
DJ, Young RN (1999). Macromolecules 32:6734–6758
Mead DW, Doi M, Larson RG (1998). Macromolecules 31:
7895
Meissner J (1975). Pure Appl Chem 42:551
Milner ST, McLeish TCB (1998). Phys Rev Lett 81:725
Muthukumar M (2016). Polym Sci Ser A Chem Phys 58:
852–863
Noda I et al (1981) Macromolecules 14:668
Onuki A (2002) Phase transition dynamics. Cambridge
University Press, Cambridge
Pearson DS, Halfand E (1984). Macromolecules 17:888
Perkins TT, Smith DE, Larson RG, Chu S (1995)
Stretching of a single tethered polymer in a uniform
ﬂow. Science 268:83
Pütz M, Kremer K, Grest GS (2000). Europhys Lett 49:735
Read DJ, Jagannathan K, Sukumaran SK, Auhl D (2012)
J Rheol 56:823–873
Rouse PE (1953). J Chem Phys 21:1272
Rubinstein M, Colby RH (2003) Polymer physics. Oxford
University Press, Oxford
Rubinstein M, Panyukov S (2002). Macromoelcules 35:
6670
Ruokolainen J, Mezzenga R, Fredrickson GH, Kramer EJ,
Hustad PD, Coates GW (2005) Morphology and ther-
modynamic behaviour of syndiotactic polypropylene-
poly(ethylene-copropylene) block polymers prepared
by
living
oleﬁn
polymerization.
Macromolecules
38(3):851–860
Semenov AN (1985). Sov Phys-JETP 61:733
Shin Y, Brangwynne CP (2017). Science 357:1253–1264
Small PA (1975). Adv Polym Sci 18:1
Polymer Physics
53

Tanaka H, Araki T, Koyama T, Nishikawa Y (2005) Uni-
versality of viscoelastic phase separation in soft matter.
J Phys 17:S3195–S3204
Treloar LRG (1975) The physics of rubber elasticity.
Clarendon, Oxford
Verdier PH, Stockmayer WH (1962). J Chem Phys 36:227
Viovy JL, Rubinstein M, Colby RH (1991) Macromole-
cules 24:3587–3596
Watanabe H (1999). Prog Polym Sci 24:1253
Watanabe H, Kotaka T (1984). Macromolecules 17:2316
Zimm BH (1956). J Chem Phys 24:269
Zimm BH, Stockmayer WH (1949). J Chem Phys 17:1301
Zinn-Justin J (1993) Field theory and critical phenomena.
Clarendon Press, Oxford
Books and Reviews
Doi M, Edwards SF (1986) The theory of polymer dynam-
ics. Oxford University Press, Oxford
Fredrickson GH (2006) The equilibrium theory of inhomo-
geneous polymers. Oxford University Press, Oxford
Larson RG (1999) The structure and dynamics of complex
ﬂuids. Clarendon Press, Oxford
54
Polymer Physics

Chaotic Dynamics in
Nonequilibrium Statistical
Mechanics
J. Robert Dorfman
Institute for Physical Science and Technology and
Department of Physics, University of Maryland,
College Park, MD, USA
Article Outline
Glossary
Deﬁnition of the Subject
Introduction
The Roles of Ergodicity and Mixing for the
Approach to Thermodynamic Equilibrium
Integrable, Pseudo-Chaotic, and Chaotic Systems
Anosov and Anosov-Like Systems; the Chaotic
Hypothesis
Applications of Dynamical Systems Theory to
Non-equilibrium Statistical Mechanics
Discussion
Future Directions
Bibliography
Glossary
Chaotic systems The time evolution of a determin-
istic mechanical system deﬁnes a trajectory in the
phase space of all the generalized coordinates
and generalized momenta. Consider two inﬁni-
tesimally separated points that lie on two differ-
ent trajectories in this phase space. If these two
trajectories typically separate exponentially with
time, the systems is called chaotic provided the
set of all points with an exponentially separating
partner is of positive measure.
Chaotic hypothesis The hypothesis that systems
of large numbers of particles interacting with
short
ranged
forces
can
be
treated
mathematically as if the system were chaotic
with no pathologies in the mathematical descrip-
tion of the systems’ trajectories in phase space.
Dynamical systems theory The mathematical
theory of the time evolution in phase space,
or closely related spaces, of a deterministic
system, such as a mechanical system obeying
Hamiltonian equations of motion.
Ergodic systems A mechanical system is called
ergodic if a typical trajectory in a phase space
of ﬁnite total measure spends a fraction of its
time in a set which is equal to the ratio of the
measure of the set to the total measure of the
phase space.
Escape rate formula Consider a chaotic dynam-
ical system with a phase space constructed in
such a way that the phase space has some kind
of an absorbing boundary. The set of points, R,
in the phase space such that trajectories through
them never escape through the absorbing
boundary either in the forward or the backward
motion is called a repeller. One can deﬁne a
set of Lyapunov exponents, li(R) and a
Kolmogorov-Sinai entropy, hKS(R) for motion
on the repeller. Dynamical systems theory
shows that the rate of escape, γ, of points, not
on the repeller, through the boundary is given by
g ¼
X
i
lþ R
ð
Þ  hKS R
ð
Þ,
ð1Þ
where the sum is over all of the positive
Lyapunov exponents on the repeller.
Gaussian thermostats A dynamical friction act-
ing on the particles in a mechanical system which
keeps the total energy, or the total kinetic energy
of the system at a ﬁxed value. It was invented by
Gauss as the simplest solution to the problem of
ﬁnding the equations of motion for a mechanical
system with a constraint of ﬁxed energy.
Gelfand triplet An operator with right and left
hand eigenfunctions, possibly deﬁned in dif-
ferent function spaces, and an inner product of
one function from the right space and one from
© Springer Science+Business Media, LLC, part of Springer Nature 2022
B. Chakraborty (ed.), Statistical and Nonlinear Physics,
https://doi.org/10.1007/978-1-0716-1454-9_66
Originally published in
R. A. Meyers (ed.), Encyclopedia of Complexity and Systems Science, © Springer Science+Business Media LLC 2021
https://doi.org/10.1007/978-3-642-27737-5_66-2
55

the left space. Generally, one of these spaces
contains singular functions such as Schwartz
distributions and the other contains sufﬁciently
smooth functions so that the inner product is
well deﬁned. The term rigged Hilbert space is
also used to denote a Gelfand triplet.
Hyperbolic dynamical system A chaotic system
where the tangent space to almost all trajecto-
ries in its phase space can be separated into
well-deﬁned stable and unstable manifolds,
that intersect each other transversally.
Kolmogorov-Sinai entropy per unit time A mea-
sure of the rate at which information about the
initial point of a chaotic trajectory is pro-
duced in time. The exponential separation of
trajectories in phase space, characteristic of
chaotic
motion,
implies
that
trajectories
starting at very close-by, essentially indistin-
guishable, initial points will eventually be
distinguishable. Hence as time evolves we
can specify more precisely the initial point
of the trajectory. Pesin has proved that for
closed, hyperbolic systems, the Kolmogo-
rov-Sinai entropy is equal to the sum of the
positive Lyapunov exponents. The Kolmogo-
rov-Sinai entropy is often called the metric
entropy.
Lyapunov exponent Lyapunov exponents, li, are
the rates at which inﬁnitesimally close trajec-
tories separate or approach with time on the
unstable and stable manifolds of a chaotic
dynamical system. For closed phase spaces,
that is, no absorbing boundaries present,
Pesin theorem states that for hyperbolic
dynamical
system
the
Kolmogorov-Sinai
entropy, hKS is given by the sum of all the
positive Lyapunov exponents.
hKS ¼
X
i
lþ
i :
ð2Þ
Mixing systems Mixing systems are dynamical
systems with stronger dynamical properties
than ergodic systems in the sense that every
mixing system is ergodic, but the converse is
not true. A system is mixing if the following
statement about the time development of a set
A t is satisﬁed
lim
T!1
m AT \ B
ð
Þ
m B
ð Þ
¼ m A
ð Þ
m E
ð Þ ,
ð3Þ
where B is any set of ﬁnite measure, and m E
ð Þ
is the measure of the full phase space. This
statement is the mathematical expression of
the fact that for a mixing system, every set of
ﬁnite measure becomes uniformly distributed
throughout the full phase space, with respect to
the measure m.
Normal variables Microscopic variables whose
values are approximately constant on large
regions of the constant energy surface in phase
space.
Pseudo-chaotic systems A pseudo-chaotic sys-
tem is a dynamical system where the separation
of nearby trajectories is algebraic in time,
rather than exponential. Pseudo-chaotic sys-
tems are weakly mixing as deﬁned by the
relation
lim
T!1
1
T
Z T
0
dt m At \ B
ð
Þ  m A
ð Þm B
ð Þ
m E
ð Þ


¼ 0:
ð4Þ
Sinai-Ruelle-Bowen (SRB) measure SRB mea-
sures for a chaotic system are invariant mea-
sures that are smooth on unstable manifolds
and possibly singular on stable manifolds.
Stable manifold A stable manifold about a point
P in phase space is the set of points that will
approach P at time t approaches positive inﬁn-
ity, that is in the inﬁnite future of the motion.
Transport
coefﬁcients Transport
coefﬁcients
characterize the proportionality between the cur-
rents of particles, momentum, or energy in a
ﬂuid, and the gradients of density, ﬂuid velocity
or temperature in the ﬂuid. The coefﬁcients of
diffusion, shear and bulk viscosity, and thermal
conductivity are transport coefﬁcients, and
appear as coefﬁcients of the second order gradi-
ents in the Navier-Stokes and similar equations.
Unstable manifold An unstable manifold about
a point P in phase space is the set of points
that will approach P as time approaches neg-
ative inﬁnity, that is, as one follows the
motion backwards in time to the inﬁnitely
remote past.
56
Chaotic Dynamics in Nonequilibrium Statistical Mechanics

Definition of the Subject
For most of its history, non-equilibrium statistical
mechanics has produced mathematical descriptions
of irreversible processes by invoking one or
another stochastic assumption in order to obtain
useful equations. Central to our understanding of
transport in ﬂuids, for example, are random walk
processes, which typically are described by sto-
chastic equations. These in turn lead to the Einstein
relation for diffusion, and its generalizations to
other transport processes. This relation, as formu-
lated by Einstein, states that the mean square dis-
placement of a diffusing particle grows linearly in
time with a proportionality constant given by the
coefﬁcient of diffusion. If we assume that such a
description applies to mechanical systems of many
particles, we must explain the origins of irrevers-
ibility in deterministic – and time reversible –
mechanical systems, and we must locate the source
of stochasticity that is invoked to derive transport
equations. For systems of particles that are chaotic,
it is possible to make some progress on resolving
these issues, and to gain some insights into the
analogous properties of systems that are not chaotic
or that have both chaotic and non-chaotic behav-
iors. This article summarizes the current status of
the application of dynamical systems theory to
non-equilibrium statistical mechanics, focuses on
the behavior of chaotic systems, and presents some
of the important open issues needing resolution.
Introduction
Statistical mechanics is devoted to the study of the
collective properties of large numbers of particles,
typically atoms, molecules, electrons, etc., but can
also be stars, or even galaxies. The mechanical
properties of the individual particles and their
mutual interactions are presumed to be known,
and the emphasis is on the statistical properties
of
collections
of
large
numbers
of
them
(Uhlenbeck and Ford 1963; Toda et al. 1992;
Kubo et al. 1992). The study of statistical mechan-
ics has always involved both an examination of its
foundations and the devising of methods to com-
pute
thermodynamic,
transport,
and
related
quantities for systems of large numbers of parti-
cles. In recent years, there has been a great deal of
attention focused on the foundations of statistical
mechanics
prompted
by
developments
in:
(i) dynamical systems theory, particularly chaotic
dynamics, (ii) the mathematics of Anosov and
hard-ball systems, and in (iii) the computational
physics of systems of particles undergoing pro-
cesses of various kinds (Eckmann and Ruelle
1985; Evans and Morriss 1990; Gaspard 1998;
Hoover 1999; Dorfman 1999; Ruelle 1999;
Gallavotti 1999; Szasz 2000; Klages 2007; Klages
et al. 2004; Katok and Hasselblatt 1995). More-
over, modern developments in quantum physics,
particularly those of some relevance for the foun-
dations of quantum mechanics, for cosmology,
and for quantum computation have some bearing
on the foundations of quantum statistical mechan-
ics (Srednicki 1999).
Non-equilibrium statistical mechanics is faced
with the task of describing the wide range of non-
thermodynamic, generally time-dependent behav-
iors of large systems, such as the transport of
particles, momentum, and/or energy from one
region in space to another over some time interval.
Despite a large number of, as yet, unsolved prob-
lems, non-equilibrium statistical mechanics has
been able to explain and provide quantitative pre-
dictions for a wide range of transport phenomena.
Here we will discuss some of these applications
and describe the role played by the microscopic
dynamics of the constituent particles, particularly
when the microscopic dynamics is classical and
chaotic (Katok and Hasselblatt 1995). Most of this
article will be devoted to a study of the role of
chaotic dynamics in non-equilibrium transport for
classical, chaotic systems. We will also consider,
to some extent, classical, non-chaotic systems as
well as quantum systems, where the usual notions
of chaotic dynamics do not apply but one can
nevertheless understand some main features of
the behavior of a quantum system by examining
its classical counterpart, if there is one.
This article is devoted to the role played by
chaotic dynamics in our understanding non-
equilibrium statistical mechanics. It will focus on
two main topics: (1) Basic issues in statistical
mechanics, namely, the approach of systems of
Chaotic Dynamics in Nonequilibrium Statistical Mechanics
57

particles to thermodynamic equilibrium. Here we
give an updated view of the role of ergodic and
mixing properties, proposed by Boltzmann and
Gibbs, respectively, as the basis for understanding
the approach to equilibrium (Uhlenbeck and Ford
1963; Toda et al. 1992; Kubo et al. 1992;
Eckmann and Ruelle 1985). (2) Applications of
dynamical systems theory to non-equilibrium sta-
tistical mechanics and the theory of transport pro-
cesses. Here we show that for chaotic systems, at
least, one can ﬁnd some very deep relationships
between macroscopic transport and microscopic
dynamics (Evans and Morriss 1990; Gaspard
1998; Hoover 1999; Dorfman 1999; Ruelle
1999; Gallavotti 1999; Szasz 2000; Klages 2007;
Klages et al. 2004). We also discuss, brieﬂy, the
closely related topic of ﬂuctuation theorems for
non-equilibrium stationary states which apply
even in far-from equilibrium situations (Evans
et al. 1993; Evans and Searles 2002; Gallavotti
and Cohen 1995; Lebowitz and Spohn 1999;
Crooks 1999; Kurchan 1998).
By way of introduction we begin with some
observations about transport processes in ﬂuids in
order to set the stage for describing the role of
chaotic dynamics in transport theory. As we will
discuss in more detail below, normal transport
processes in ﬂuids are characterized by a linear
growth in time of the mean square ﬂuctuations of
an appropriate time dependent microscopic vari-
able of the system. Typical of such a ﬂuctuation
formula is the Einstein relation which states that
the mean square displacement of a particle under-
going Brownian motion in a ﬂuid grows linearly
in time with a coefﬁcient that is, apart from a
numerical factor, the diffusion coefﬁcient of the
Brownian particle (Mazo 2002). That is
r tð Þ  r 0
ð Þ
ð
Þ2
D
E
¼ 2dDt:
ð5Þ
Here r(t) is the spatial location of the Brownian
particle at some time t, and d is the number of
spatial dimensions of the system. D is the diffu-
sion coefﬁcient appearing in the linear relation,
known as Fick’s Law, that relates the probability
current, J(r, t) for the Brownian particle to its
probability density, P(r, t),
J r, t
ð
Þ ¼ D∇P r, t
ð
Þ:
ð6Þ
The angular brackets denote an average over
an ensemble of trajectories of time duration t, at
least. At the heart of the Einstein formula is the
fact that the Brownian particle undergoes a ran-
dom walk on sufﬁciently long-time scales. The
distinguishing feature of a random walk is the
linear growth in time of the mean square displace-
ment. Thus, normal transport in general is a form
of a random walk process. This was formalized by
Helfand in 1960 (Helfand 1960), who generalized
the Einstein formula to other transport processes
such as viscous ﬂow, and heat conduction. By
normal transport we mean transport that can be
described macroscopically by linear relations
between the currents of globally conserved quan-
tities such as mass, energy, and/or momentum,
and the gradients of the densities of these quanti-
ties. The coefﬁcients of proportionality are trans-
port coefﬁcients, such as the coefﬁcients of shear
and bulk viscosity, thermal conductivity, diffu-
sion, and so on. These coefﬁcients, for normal
transport, do not depend on time, but may depend
on the local densities of mass and the local tem-
perature of the ﬂuid.
Helfand was able to show that each transport
process may be regarded as a random walk process
characterized by a linear growth as a function of
time of the mean square ﬂuctuation of a micro-
scopic quantity, Ms(Γ, t), called a Helfand moment.
The Helfand moments depend on all of the phase
space variables of the system, now denoted collec-
tively by Γ, and time t. For normal transport, the
generalized Einstein relation becomes
Ms G, t
ð
Þ  Ms G
ð , t ¼ 0Þ
ð
Þ2
D
E
¼ sCst:
ð7Þ
Here s is a transport coefﬁcient appearing in
the Navier-Stokes or diffusion equations, Cs is a
constant, and the average is over an equilibrium
ensemble. For diffusion of a Brownian particle,
for example, the Helfand moment is simply the
spatial location of the particle. This result implies
that normal transport processes are essentially
random walk processes with a generalized “dis-
placement,” namely, the Helfand moment.
58
Chaotic Dynamics in Nonequilibrium Statistical Mechanics

If we think of a system of particles, undergoing
some kind of hydrodynamic ﬂow as a deterministic
dynamical system, with, typically but not exclu-
sively, Hamiltonian dynamics, a deep question
immediately presents itself: Where does the ran-
domness come from that is required for transport
processes to be generalized random-walk pro-
cesses? While there are a variety of answers to
this question, the main point of this article is to
argue that for chaotic systems the randomness is an
intrinsic property of the dynamics of the system
(Katok and Hasselblatt 1995), and then to illustrate
some of the results that have been obtained recently
which connect microscopic dynamics to macro-
scopic transport for such systems. We emphasize
that many chaotic systems display the kind of
randomness needed for good transport properties
even though such systems are deterministic, and
time reversible. However, chaos is neither neces-
sary nor sufﬁcient for normal transport. There are
examples of non-chaotic systems that exhibit nor-
mal diffusion. The wind-tree model to be discussed
below is an example (Ehrenfest and Ehrenfest
1959; Dettmann and Cohen 2000). There are also
chaotic systems that exhibit abnormal transport.
The two-dimensional periodic Lorentz gas with
circular scatterers is chaotic and exhibits both nor-
mal and abnormal diffusion, depending upon the
lattice
structure
and
the
separation
distance
between neighboring scatterers (Bunimovich and
Sinai 1981; Gaspard and Baras 1995).
Nevertheless, chaotic systems have sufﬁciently
many nice properties that for them it is possible to
obtain a number of rather, general connections
between microscopic dynamics and macroscopic
transport, and to understand the approach of sys-
tems to thermodynamic equilibrium from a
dynamical standpoint. Such connections, should
they exist, are not yet available for those non-
chaotic systems which exhibit normal transport.
The dynamical properties of most non-chaotic
systems are not yet sufﬁciently well understood
for the construction of a more or less general
theory for generic connections between micro-
scopic dynamics and macroscopic transport.
Most realistic dynamical systems have a mixed
phase space, where chaotic and non-chaotic
regions, to be deﬁned below, are intermingled
(Turaev and Rom-Kedar 1998; Donnay 1996). It
is generally supposed that for systems of large
numbers of particles in macroscopic volumes,
the non-chaotic regions occupy a very small part
of phase space and can be ignored for all practical
purposes. However, this remains to be proved,
and the effects of the non-chaotic regions require
much more elucidation.
The plan of this article is as follows: We begin
with a discussion of the foundations of statistical
mechanics in section “The Roles of Ergodicity
and Mixing for the Approach to Thermodynamic
Equilibrium.” There we discuss dynamical prop-
erties that are often considered to be important for
statistical mechanics, such as ergodicity and
mixing. There we argue that these properties, by
themselves, are not sufﬁcient to explain the
approach to equilibrium of systems of large num-
bers of particles and that further notions are
required. This will lead us in section “Integrable,
Pseudo-chaotic, and Chaotic Systems” to a dis-
cussion of some of the dynamical systems
encountered in classical statistical mechanics, par-
ticularly integrable, pseudo-chaotic, and chaotic
systems. In section “Anosov and Anosov-Like
Systems; the Chaotic Hypothesis,” we consider
chaotic systems in more detail and show for a
simple model of a chaotic system that the stochas-
tic behavior needed for diffusion can be seen as a
natural consequence of chaotic dynamics. Despite
its simplicity and low dimensionality, this model
will also allow us to provide a dynamical picture
of the approach of a system to equilibrium. These
models are simple examples of classes of dynam-
ical systems called Anosov and Anosov-like sys-
tems.
They
have
very
useful
mathematical
properties for the description of non-equilibrium
phenomena in simple systems, and it is conve-
nient to assume, whenever possible, that the sys-
tems of interest to physicists have these good
properties. These properties are then used for the
applications
of
chaotic
dynamics
to
non-
equilibrium
statistical
mechanics
in
section
“Applications of Dynamical Systems Theory to
Non-equilibrium Statistical Mechanics.” There
we discuss a number of results that connect micro-
scopic dynamical properties such as Lyapunov
exponents
and
Kolmogorov-Sinai
entropies
Chaotic Dynamics in Nonequilibrium Statistical Mechanics
59

(Eckmann and Ruelle 1985; Evans and Morriss
1990; Gaspard 1998; Hoover 1999; Dorfman
1999; Ruelle 1999; Gallavotti 1999; Szasz 2000;
Klages 2007; Klages et al. 2004; Katok and
Hasselblatt 1995) to macroscopic transport coef-
ﬁcients for chaotic systems. In section “Discus-
sion” we review the previous discussion and give
brief comments about quantum systems, where
the concepts of classical chaotic dynamics do not
apply, but certain features of these systems can be
understood in terms of the chaotic dynamics of
their classical counterparts. Finally, we mention
some future directions and open questions in sec-
tion “Future Directions.”
The Roles of Ergodicity and Mixing for
the Approach to Thermodynamic
Equilibrium
Ergodic Systems
Boltzmann invented the notion of ergodicity in an
attempt to reconcile the apparently irreversible
behavior of large systems of particles, especially
their approach to thermodynamic equilibrium,
with the microscopic reversibility of Newton’s
equations of motion (Uhlenbeck and Ford 1963;
Toda et al. 1992; Kubo et al. 1992). Brieﬂy put,
Boltzmann argued as follows: Consider an iso-
lated system of particles and follow the system’s
trajectory on the appropriate constant energy sur-
face in phase space. Suppose that the underlying
microscopic dynamics of the system is such that
the phase space trajectory of the system, over a
long time interval, spends an amount of time in
every region of phase space, A, that is proportional
to the measure of that region, m(A). Here the
measure is the standard equilibrium phase space
measure on a constant energy surface given by
m A
ð Þ ¼
Z
A
dS
j ∇H j ,
ð8Þ
where dS is the area of an inﬁnitesimal region of
the constant energy surface, and j∇Hj is the mag-
nitude of the gradient of the Hamiltonian function
for the system at the point of integration.
Boltzmann’s supposition above is called the
ergodic hypothesis, and in mathematical terms it
can be stated as (Eckmann and Ruelle 1985)
lim
T!1
t A
ð Þ
T
¼ m A
ð Þ
m E
ð Þ :
ð9Þ
Here t(A) is the amount of time the system
spends in region A during a time interval T, and
m E
ð Þ is the measure of the entire constant energy
surface, which we assume to be ﬁnite. If one
accepts the hypothesis, then one can easily show,
by approximating integrals by sums, for example,
that the time average of any well-behaved dynam-
ical quantity approaches its equilibrium, micro-
canonical ensemble average as the time interval
over which the average is taken approaches inﬁn-
ity. Boltzmann’s hypothesis holds equally well for
the time reversed motion of the system and is
consistent with the reversibility of the micro-
scopic dynamics.
The kinds of elementary physical systems one
studies in physics courses, such as coupled sys-
tems of harmonic oscillators, are generally not
ergodic, although some simple systems, such as
a single, one dimensional harmonic oscillator, can
be shown to be ergodic. Another simple example
is the discrete time motion of a point particle on
the circumference of a circle, where the particle
moves a ﬁxed irrational fraction of the length of
the circumference at successive time steps. In the
long-time limit, the circumference is uniformly
covered by points visited by the particle (Walters
1982). A great deal of mathematical research over
the past few decades, and longer, has been
devoted to a study of more complicated ergodic
systems. The ﬁrst dramatic example of a system
with
ergodic
properties,
and
one
that
has
inﬂuenced most of the more recent efforts in this
direction is the geodesic motion of a point on a
surface of constant negative curvature. This was
proved by E. Hopf (1937), and the techniques
employed
remain
useful
today.
Sinai
and
coworkers (Sinai 1991), as well as many other
workers, particularly Simányi (2004), have given
careful mathematical proofs of ergodic behavior
of various systems composed of hard disks or hard
spheres, generally referred to as hard-ball sys-
tems. Turaev and Rom-Kedar, Donnay and others
60
Chaotic Dynamics in Nonequilibrium Statistical Mechanics

(Turaev and Rom-Kedar 1998; Donnay 1996)
have shown that by softening the hard sphere
potential one may change an ergodic system into
a non-ergodic one. Thus, the problem of proving
that a system of interest to physicists is actually
ergodic, or ergodic for practical purposes, is still
far from a general solution.
Mixing Systems
Gibbs took a different approach to the problem of
irreversibility. He used the analogy of an ink drop
being stirred in a container of glycerin to intro-
duce the stronger notion of a mixing system in his
efforts to understand the approach of a non-
equilibrium ensemble distribution function to an
equilibrium distribution (Eckmann and Ruelle
1985; Dorfman 1999). In considering a non-
equilibrium phase space distribution one has to
follow the trajectories of a set of points in phase
space, not just a typical trajectory, as in the study
of ergodic behavior. Gibbs suggested that an ini-
tial set of points concentrated in a small region of
phase space might spread out over the entire avail-
able phase space in the course of time, and
become ﬁnely mixed throughout the phase space
in much the same way as the ink drop will become
mixed in the glycerin, in such a way that a coarse
grained observation of the ink would lead to the
conclusion that it is uniformly mixed, but a ﬁne
grained observation would reveal the individual
threads of ink. Returning to phase space, Gibbs
argued that although the measure of phase space
occupied by the set of points should remain con-
stant in time, in accordance with Liouville’s theo-
rem, the set eventually gets distributed over the
constant energy surface such that a coarse grained
observation of the phase space would lead to the
conclusion that the set uniformly covers the
energy surface, while a ﬁne grained observation
would reveal that the coverage consists of one
long, thin set of total measure much less than
that of the whole energy surface. Of course,
mechanical reversibility ensures that one can
recover the initial distribution of points by time
reversing the motion but eventually mixing takes
place for the time reversed motion, as well.
The mathematical deﬁnition of a mixing sys-
tem (Walters 1982) is given by looking at the time
development of the initial set of phase points. We
denote by A, the initial set of phase points on
which the initial ensemble is concentrated, and
the set to which this initial set evolves after a
time T, by AT. Then, to examine the mixing of
the set in phase space, we consider some arbitrary
set of positive measure B and consider the inter-
section B \ AT. If the dynamics of the system is
mixing, then eventually the fraction of the set
B occupied by AT should approach the fraction of
A in the entire phase space, no matter what sets of
positive measure A and B we consider. That is, a
system is mixing if for any sets A and B of positive
measure
lim
T!1
m AT \ B
ð
Þ
m B
ð Þ
¼ m A
ð Þ
m E
ð Þ :
ð10Þ
Here we used the conservation of phase space
measure, namely, that m(A) ¼ m(AT). One can
easily prove that a mixing system is also ergodic,
but the reverse need not be true (Walters 1982).
For a system of particles with the mixing prop-
erty one can prove that a non-equilibrium phase
space distribution will approach an equilibrium
phase space distribution in a weak, long time
limit (Dorfman 1999). That is, average quantities
taken with respect to the non-equilibrium distri-
bution approach equilibrium averages. The proof
can easily be constructed by approximating inte-
grals by sums in the usual way.
Mathematicians have considered proofs of the
mixing property for various systems of interest to
physicists. The most important of such systems
are hard ball systems mentioned previously,
where the proofs of ergodicity and mixing are
consequences of proving a stronger dynamical
property, the Bernoulli property of the system,
which implies that the system is mixing and there-
fore ergodic as well. We leave a proper deﬁnition
of a Bernoulli system to the literature (Cornfeld
et al. 1982) and we will not consider it any further
here. Needless to say, the class of systems which
can be proved to be mixing is not yet large enough
to encompass the typical systems studied in sta-
tistical mechanics or in kinetic theory, although
considerable progress has been made in this direc-
tion over the past several years.
Chaotic Dynamics in Nonequilibrium Statistical Mechanics
61

What Is the Relevance of These Notions for
Statistical Mechanics?
It would appear that with the proof that a system
of a large number of particles in a reasonable
container is mixing, the foundation for the appli-
cations of statistical mechanics to such a system
would be secure. That this is not a complete
explanation may be seen for the following rea-
sons, among others:
1. We have assumed that our systems have ﬁxed
energies and that all the forces acting between
the particles or on the system, due to the walls
of the container, say, are conservative and
known. Strictly speaking, this is not true of
any laboratory system.
2. We have not examined how long it might take
for the time average to be reasonably close to
the ensemble average for an ergodic system or
how long it would take a reasonable initial set
to get uniformly mixed over the appropriate
phase space, for a mixing system. One can
argue that the appropriate times are very long,
typically very much longer than the duration of
an experiment. A partial but useful answer to
this objection to the use of ergodicity and/or
mixing properties is to consider Reduced dis-
tribution functions, particularly the single par-
ticle and two-particle distribution functions.
These reduced distribution functions approach
equilibrium, or more generally, local equilib-
rium forms, on much more realistic time scales.
The notion of local equilibrium arises in the
context of the decay of a non-equilibrium state
in a many particle system to total equilibrium,
through hydrodynamic processes. In the usual
picture,
due
to
Chapman,
Enskog,
and
Bogoliubov (Chapman and Cowling 1970;
Bogoliubov 1962), the initial state becomes,
on the time scale of the duration of a collision,
one that can be described by reduced distribu-
tion functions. Then on the time scale of the
time between collisions, set by the microscopic
properties of the system such as the density and
the size of the particles, the system becomes
close to a state of local equilibrium with a local
temperature,
density
and
mean
velocity.
Finally, on a time scale set by the physical
size of the container, the system relaxes to
total equilibrium. The approach to local equi-
librium is set by the dynamical interactions
between the particles.
In addition, many non-equilibrium as well
as equilibrium properties of a many-particle
system can be formulated in terms of these
reduced functions. This being the case, the
questions are: What is the reason that reduced
distribution functions approach local equilib-
rium forms, and what are the time scales
involved in the approach to local equilibrium,
and eventually to total equilibrium? For cha-
otic systems, at least, there is reason to believe
that one can provide satisfactory answers to
these questions.
Another approach to resolving the issue of
time scales in applying these notions to labo-
ratory systems, and one closely related to the
use of reduced distribution functions is to focus
attention on a set of microscopic variables
called normal variables (Uhlenbeck and Ford
1963). These variables are deﬁned by the
requirement that they not vary much over the
constant energy surface. These variables then
have the property that their value is almost the
same no matter where the phase point happens
to be on the constant energy surface. In this
picture an initial non-equilibrium state would
be one where the values of the normal variables
are far from their equilibrium or average
values, but the time evolution of the system
leads to regions where these variables have
values closer to their equilibrium averages. In
this picture the relevant time scale is the aver-
age time needed for the system to evolve to
regions of phase space where the normal vari-
ables are close to their average values. Presum-
ably this time will be much shorter than the
time needed for the trajectory to cover the
phase space. However, we need a detailed
description of these variables and a description
of their behavior as a system approaches local,
then total equilibrium via kinetic and hydrody-
namic processes, respectively. In the absence
of such an understanding of normal variables,
in general, the reduced distribution functions
provide a clearer way to address the questions
62
Chaotic Dynamics in Nonequilibrium Statistical Mechanics

of time scales for the approach of distribution
functions to their equilibrium values.
One can imagine, that both the reduced
distribution resolution and the normal variable
resolution of the time scale issue become easier
to justify as the number of degrees of freedom,
or the number of particles become large. In
either case, although the phase space measure
will also grow, and the time needed to cover it
will increase, the relative ﬂuctuations in the
reduced distribution functions and normal vari-
ables will become smaller. It should be empha-
sized that the notions of ergodicity and mixing
have an important role to play in statistical
mechanics, despite the issues raised here
concerning the time needed for covering the
full phase space. Using ergodicity one can
motivate the use of the micro-canonical ensem-
ble and ultimately all of the Gibbs ensembles
that provide methods for computing equilib-
rium properties of systems. Similarly, the
mixing property can be used to show that
time correlation functions decay in time, an
important property needed for many applica-
tions of non-equilibrium statistical mechanics,
particularly for the Green-Kubo formalism
(Toda et al. 1992; Kubo et al. 1992).
3. We have used classical mechanics as our
description of dynamics, but nature is funda-
mentally quantum mechanical.
In the following sections we will address point
(2) in some detail, and point (3), brieﬂy. It is
important to note, however, that the answers we
shall provide, while encouraging, are very incom-
plete and much more work needs to be done to
make these answers believable and secure. Here
we consider point (1). As mentioned in the previ-
ous section, in order to produce a random walk of
the Helfand moments needed for normal trans-
port, some sort of stochastic or stochastic-like
mechanism is required. Possible sources of sto-
chastic behavior could be random external inﬂu-
ences or some built-in structural randomness,
however subtle and difﬁcult to identify. Evidence
for the effectiveness of built-in randomness is
provided by a useful model of a statistical system,
such as the Ehrenfest wind-tree model (Ehrenfest
and Ehrenfest 1959), where diamond shaped scat-
terers (trees) are placed at random in a plane, with
their diagonals aligned parallel to the x- and
y-axes. Then point particles (wind) move among
the trees with velocities only in the x and y
directions. The random placement of the trees
provides a clear stochastic mechanism leading to
normal diffusion and an approach to equilibrium
and thereby simulate a mixing system. Such sys-
tems are not chaotic and some source of random-
ness beyond the dynamics is necessary for normal
transport in such non-chaotic models. Moreover,
there are periodic versions of the wind-tree model
that also exhibit normal diffusion (Klages 2007;
Dettmann and Cohen 2000), with more subtle
sources of randomness, possibly connected with
the splitting of two nearby trajectories at the cor-
ners of the scatterers. Below we turn our attention
to the case of chaotic systems and argue that for
such systems, the dynamics can be enough to
allow normal transport and the approach of an
ensemble of such systems to equilibrium, even
when the system is spatially periodic.
Integrable, Pseudo-Chaotic, and Chaotic
Systems
The kind of systems one studies in courses on
classical mechanics are typically integrable sys-
tem. These are systems with N canonical coordi-
nates, N canonical momenta, and N independent
constants of the motion (Toda et al. 1992). The
canonical coordinates of such systems can be
transformed to a set of action-angle variables,
and when expressed in these variables, the sys-
tems become quasi-periodic in time, and the
motion is conﬁned to regions in phase space
called invariant tori. Systems of coupled har-
monic oscillators are good examples of integra-
ble systems. There is another class of mechanical
systems, of which the Ehrenfest wind-tree model
described above is an example, called pseudo-
chaotic systems (Zaslavsky 2007). These sys-
tems have the property that two inﬁnitesimally
close trajectories will separate algebraically with
time, for sufﬁciently long times. For example,
two distinct trajectories moving in initially
Chaotic Dynamics in Nonequilibrium Statistical Mechanics
63

parallel directions in a wind-tree system will
eventually separate algebraically with time, no
matter how close they are to each other initially,
due to the random placement of scatterers and the
fact that one of the two trajectories will eventu-
ally hit a scatterer that is “just missed” by the
other one. Pseudo-chaotic systems have a weak
mixing property (Walters 1982; Zaslavsky 2007),
namely, that
lim
T!1
1
T
Z T
0
dt m At \ B
ð
Þ  m At
ð
Þm B
ð Þ
m E
ð Þ


¼ 0: ð11Þ
Chaotic systems are usually deﬁned by the
condition that two inﬁnitesimally close trajecto-
ries will, in the appropriate long time limit, sepa-
rate exponentially (Eckmann and Ruelle 1985).
We will give a more careful discussion of chaotic
systems in the next section.
Anosov and Anosov-Like Systems; the
Chaotic Hypothesis
Earlier in this discussion we argued that the
notions of ergodicity and mixing are not, in them-
selves, fully sufﬁcient for understanding the
approach to thermodynamic equilibrium for sys-
tems of many particles due to problems of time
scales. In addition, we argued that in many cases
reduced distribution functions may very well be
better indicators of the approach to equilibrium
than the full phase space distribution function. We
also suggested that for chaotic systems at least,
these observations can be veriﬁed to the extent
that we can make some more detailed statements
concerning the approach to equilibrium and trans-
port properties. Here we will provide some justi-
ﬁcation for these comments.
It is helpful to consider simple model systems
that display the kind of irreversible behavior that
we would like to be able to describe for more
realistic, many particle systems. Two model sys-
tems that have this feature are the baker’s map
(Hopf 1937; Berry 1978) and the Arnold Cat Map,
which itself is an example of more general models
called hyperbolic toral automorphisms (Katok
and Hasselblatt 1995). We will explain this termi-
nology as we proceed.
The baker’s map is a map of a two dimensional
“unit square,” 0  x, y  1 onto itself, given by
(see Fig. 1)
x0
y0
 
!
¼
2x
y=2
 
!
for 0  x  1=2;
and ¼
2x  1
y þ 1
ð
Þ=2
 
!
for 1=2 < x < 1:
ð12Þ
This map consists of a stretching of the square
in the x-direction by a factor of 2 and squeezing
in the y-direction by a factor of 1/2. The elon-
gated image of the unit square is then cut in half
and the right side is put on top of the left side so
that a unit square is reconstructed, after each
application of the map. Of course, this is an
area preserving map, and it has a discontinuity
at x ¼ 1/2.
Suppose
the
x,
y-plane
is
our
(two-
dimensional) phase space and the motion of a
Chaotic
Dynamics in Nonequilibrium
Statistical
Mechanics, Fig. 1 The baker’s map: The unit square is
mapped onto itself by stretching by a factor 2 in the
x-direction and by a compression by a factor of 1/2 in the
y-direction. This is followed by cutting and re-arranging
the resulting rectangle
64
Chaotic Dynamics in Nonequilibrium Statistical Mechanics

phase point is conﬁned to the unit square. We now
apply some of the usual techniques of statistical
mechanics to baker-map distribution functions
deﬁned on the unit square. The phase space dis-
tribution function changes at each time step
according to
rnðx, yÞ ¼ rn1 x=2, 2y
ð
Þ for 0  y  1=2;
and ¼ rn1
x þ 1
ð
Þ=2, 2y  1
ð
Þ for 1=2 < y < 1:
ð13Þ
For statistical mechanics, we often are inter-
ested in the reduced distribution functions of
fewer variables. Here there are only two variables,
so we consider the reduced distribution function,
Wn(x) obtained by integrating rn(x, y) over the
y coordinate. Using Eq. (13), we obtain the equa-
tion (Berry 1978)
Wn x
ð Þ ¼ 1
2 Wn1 x
2
 
þ Wn1 x þ 1
2


h
i
: ð14Þ
If one assumes that the initial value, W0(x), of
the reduced distribution function is a reasonably
smooth function of x, for example, if it can be
represented by a convergent Fourier series, then
Wn (x) approaches a constant value as n ! 1!
The reason for this is that Eq. (14) says that the
reduced distribution at time n at a point x is the
average value of the distribution at two points, x/2
and (x þ 1)/2 at the previous time, n  1. This
averaging, if carried on long enough, produces a
function which is constant in x. One can readily
estimate the time it takes to reach this uniform
state in the following way. Suppose that l < 1 is
some length scale on which W0(x) varies with x.
Then since the baker’s map stretches sets of length
l into sets of length 2l we can estimate the time to
reach equilibrium as the time it takes a set of
length l to be stretched to a set of length 1,
which is ( ln l)/(ln2). This can be much shorter
than the time it takes for the ergodic or mixing
properties of the baker’s map to make themselves
manifest, which takes an additional time of order
lnN/ ln 2 to produce N horizontal strips of unit
length, stacked in the y-direction. If we were to
consider the reduced distribution function in the
y variable, we would not get a nice equation with a
distribution function that approaches equilibrium.
Why that is so will be clear in a moment.
We have not introduced any stochastic features
into our derivation of Eq. (14), but only integrated
the Liouville equation over one of the variables.
Thus, we have been able to start from the Liouville
equation, and by introducing nothing but an initial
condition and integrating over the appropriate
number of unmeasured variables, obtain an irre-
versible equation for a reduced distribution func-
tion which approaches equilibrium. Incidentally,
the quantity S ¼ 
R 1
0dxWn x
ð Þ ln Wn x
ð Þ exhibits
a monotonic increase with time n (Dorfman 1999).
Our analysis of the approach to equilibrium of
the function Wn(x) made strong use of the
stretching nature of the map in the x-direction.
To get some further insight into the importance
of the stretching of the phase space regions, we
consider another model, the Arnold Cat Map
(Katok and Hasselblatt 1995) (see Fig. 2). Here
the unit square, with opposite sides identiﬁed,
represents a torus. This transformation maps the
torus (that is, there is no cutting and moving of
any section as there is in the baker’s map) onto
itself and may be described by a 2  2 matrix with
unit determinant and integer elements. Such maps
are called toral automorphisms (Katok and
Hasselblatt 1995), of which the Cat Map is a
speciﬁc example. This map has an additional,
hyperbolic, property, namely, that one of its eigen-
values be greater than unity. It follows from the
fact that the determinant is unity, that the other
eigenvalue is less than unity, and the product of
the two is 1. The standard version of the map is
given by the symmetric matrix
x0
y0


¼ T 
x
y
 
¼
2
1
1
1



x
y
 
, modulo 1:
ð15Þ
The eigenvalues of T are
3 
ﬃﬃﬃ
5
p
	

=2. The
eigendirections are perpendicular to each other
and make non-zero angles with the x- and
y-axes. There is a stretching direction which cor-
responds to the direction of the larger eigenvalue,
Chaotic Dynamics in Nonequilibrium Statistical Mechanics
65

and a contracting direction which corresponds to
the smaller eigenvalue. While the equation for the
projection of the “phase space” distribution func-
tion onto the x- or y-directions is not as simple as
that for Wn(x) given above, it is not difﬁcult to
write a computer program which shows the values
of these projections after a few time steps, starting
with some initial distribution on the unit torus.
Figures 3 and 4 show the behavior of the projected
distribution functions, Wn(x) and Gn(y), onto the
x- and y-directions, respectively, for an initial set
of points that is uniform over the region 0  x,
y  0.1 and zero everywhere else. Both these
distribution functions become uniform after three
or four time steps. In Figs. 4 and 5, we show the
evolution of the phase space distribution function
at some of the same times. Here we clearly see the
difference on the rate of evolution of projected
vs. full phase space distribution functions, and
why, for simple models at least, the notions of
ergodicity and mixing demand more than is phys-
ically required for an approach to equilibrium for
the reduced distribution functions.
The important feature that both the baker’s
map and the cat map have in common is that
they are both area preserving maps with a
stretching direction, or unstable direction, and a
contracting direction, called a stable direction
(Katok and Hasselblatt 1995). These directions
are associated with stretching and contracting
factors that depend exponentially upon time. The
logarithms of these factors per unit time are the
Chaotic Dynamics in
Nonequilibrium
Statistical Mechanics,
Fig. 2 The Arnold Cat
Map of the unit torus onto
itself
66
Chaotic Dynamics in Nonequilibrium Statistical Mechanics

Lyapunov exponents (Eckmann and Ruelle 1985;
Gaspard 1998; Katok and Hasselblatt 1995; Tél
and Gruiz 2006). For the baker’s map the two
Lyapunov exponents are l ¼  ln 2, and for
the cat map above, the two Lyapunov exponents
are l ¼ ln
3 
ﬃﬃﬃ
5
p
	

=2


. In general, for higher
dimensional systems, the stable and unstable
directions span the so-called stable and unstable
manifolds, respectively. For the baker’s map the
y-axis and the x-axis are stable and unstable mani-
folds, respectively, for the baker’s map, as are the
axes in the eigen-directions of the cat map (Fig. 6).
The importance of the unstable manifolds resides
in the fact that on them non-uniform functions
become smoothed with time, if they are not too
singular, on a time scale that is determined by the
Chaotic Dynamics in
Nonequilibrium
Statistical Mechanics,
Fig. 3 The projection of
the Cat Map distribution
onto the x-axis, Wn(x), at
various times, n. By n ¼3, 4
the distribution is
essentially uniform
Chaotic Dynamics in
Nonequilibrium
Statistical Mechanics,
Fig. 4 The projection of
the Cat Map distribution
onto the y-axis, Gn( y) at
various times, n. By n ¼3, 4
the distribution is
essentially uniform
Chaotic Dynamics in Nonequilibrium Statistical Mechanics
67

positive Lyapunov exponents. In order to get a
reduced distribution function that approaches an
equilibrium distribution for long enough times,
one clearly must project the Liouville distribution
onto manifolds that are not orthogonal to all of the
unstable directions. This is one reason to examine
the Cat Map, namely, to show that projections
onto either direction, x or y equally lead to a
uniform distribution after a few time steps. This
would be the case for the baker’s map, if we were
to project on any direction that makes a non-zero
angle with the y-direction. Generally, the unstable
directions in phase space are so complex that
practically any projected distribution will not be
orthogonal to them. Under time reversal the unsta-
ble and stable manifolds are interchanged, and the
picture remains essentially the same. It is worth
mentioning that if we were to project the distribu-
tion function onto a stable manifold we would not
obtain an equilibrium distribution function, but
Chaotic Dynamics in
Nonequilibrium
Statistical Mechanics,
Fig. 5 The initial phase
space distribution used to
obtain Figs. 3 and 4
Chaotic Dynamics in
Nonequilibrium
Statistical Mechanics,
Fig. 6 The evolution of the
phase space distribution of
Fig. 5 after three iterations
of the Arnold Cat Map
68
Chaotic Dynamics in Nonequilibrium Statistical Mechanics

rather a very complicated function since any irreg-
ularities in the initial distribution function become
more irregular with time, along stable directions
(Gaspard 1997, 1998; Dorfman 1999; Tasaki et al.
1998). This is why a projection onto the y-axis
would not lead to an equilibrium distribution for
the baker’s map, without some sort of coarse
graining to “smooth out” an otherwise singular
function.
Dynamical systems that have properties simi-
lar to the cat map or the baker’s map are called
Anosov or Anosov-like systems, respectively
(Gaspard 1998; Katok and Hasselblatt 1995;
Gallavotti and Cohen 1995). Anosov systems are
continuous dynamical systems such that at every
point in phase space there are stable and unstable
directions, with positive and negative Lyapunov
exponents, respectively. There may also be some
neutral directions with zero Lyapunov exponents,
but there must be at least one positive Lyapunov
exponent. The presence of positive Lyapunov
exponents is characteristic of a hyperbolic system.
Furthermore, there must be at least one trajectory
in phase space that is dense, a requirement which
is called transitivity. Systems of particles with
some manageable singularities such as hard
spheres are not strictly Anosov systems but are
close enough to be considered Anosov-like. The
Arnold Cat Map is an example of an Anosov
system, while the baker’s map is Anosov-like.
Of course, in a multidimensional Anosov system,
there are a number of stable and unstable direc-
tions, and all stable manifolds intersect all unsta-
ble manifolds transversally. Systems with at least
one positive Lyapunov exponents are commonly
referred to as being chaotic. We have chosen
simple systems to illustrate the main ideas, but
the reader should be aware that it is possible to
deﬁne Lyapunov exponents for motion on invari-
ant sets in phase space, even for sets of measure
zero, such as periodic orbits, or as we discuss
below, fractal repellers.
Returning to statistical mechanics, we see that
the simple examples of the baker’s map and the
Cat Map give us some reason to believe that, for
chaotic systems at least, reduced distribution
functions will approach equilibrium values, or
more precisely, local equilibrium values, on
reasonable time scales. This conclusion depends,
of course, on the assumption that the underlying
microscopic dynamics is of the Anosov or
Anosov-like variety. It is therefore useful to
assume that systems of large numbers of particles
with short ranged interactions, of general interest
for statistical mechanics, are ergodic, Anosov-like
systems as far as their dynamical properties are
concerned. This assumption has been made a cen-
tral feature of the dynamical systems approach to
non-equilibrium
statistical
mechanics
by
Gallavotti and Cohen (1995), who have called it
the chaotic hypothesis. This hypothesis allows
one to apply the results of chaotic dynamics,
such as those discussed in the next section, to
realistic systems. In actuality we know little a
priori about the dynamics of such systems, such
as their Lyapunov exponents, or the structure and
properties of unstable and stable manifolds in
phase space. Furthermore, due to the work of
Turaev, Rom-Kedar, Donnay (Turaev and Rom-
Kedar 1998; Donnay 1996), and others, we know
that if the intermolecular potential is smooth, there
may exist regions in phase space where the
dynamics is not chaotic. For these systems, the
chaotic hypothesis implies the additional state-
ment that the total volume of the non-chaotic
regions in phase space is small enough so that
for determining the important averages, they can
be ignored.
Fractal Dimensions
An important concept used in applications of
dynamical systems theory to statistical mechan-
ics, among many other applications, is the notion
of fractal dimensions. As we will mention in the
next section, for chaotic systems many of the
connections between macroscopic transport coef-
ﬁcients and microscopic dynamical quantities
such as Lyapunov exponents can be related to
the dimensions of fractal structures that form in
the phase spaces of non-equilibrium systems.
Generally, but not exclusively, fractals are deﬁned
by the statement that their dimension is not an
integer. However, this deﬁnition is complicated
by the fact that there are many ways to deﬁne the
dimension of a set, and some fractals may have a
dimension that is an integer by some deﬁnition
Chaotic Dynamics in Nonequilibrium Statistical Mechanics
69

and non-integer by others. Fractals that have a
variety of different dimensions are referred to as
multifractals. There are also other deﬁnitions of
fractals based upon self-similarity at all scales, or
upon differentiability and continuity properties.
We refer to the literature for more details (Ott
2002).
In order to present one deﬁnition of the fractal
dimension of a set, imagine that the set is embed-
ded in a d-dimensional space. Cover the set with
cubes of length ϵ on a side, each labeled by an
index i and suppose that one needs at least N(ϵ) of
these cubes for a full coverage. Suppose further
that we have a way to assign a measure mi to each
cube. We can suppose that the total measure is
normalized to some constant, say unity,
X
N ϵð Þ
1
mi ¼ 1:
ð16Þ
The measure mi may be a normalized Lebesgue
measure of the cube, or it may be the fraction of
time that a typical trajectory on the fractal spends
in cube i, for example. In terms of this measure we
can deﬁne a dimension Dq that depends on a
continuous variable q, as
Dq ¼ 1
1  q lim
ϵ!0
I q, ϵ
ð
Þ
ln ϵ ,
ð17Þ
where I(q, ϵ) is given by
I q, ϵ
ð
Þ ¼
X
N ϵð Þ
i¼1
mq
i :
ð18Þ
In this construction the quantity, D0 is called
the box-counting dimension, D1 is called the infor-
mation dimension, and D2 is called the correlation
dimension. The dimension Dq is a monotonic non-
decreasing function of q. Other dimensions fre-
quently employed to characterize fractals include
the Hausdorff dimension, and we refer to the
literature for a careful deﬁnition and discussion
of this and other dimensions. As an example of a
fractal, consider the middle third Cantor Set. This
set is constructed by taking a unit interval,
discarding the middle third of it, then take each
of the two remaining pieces, discarding the middle
third of each of them, and so on. It is easy to show
that the dimensions, Dq, of the remaining set, are
all equal to ln2/ln3.
Applications of Dynamical Systems
Theory to Non-equilibrium Statistical
Mechanics
The connections between normal transport, ran-
dom walk processes, and the generalized Einstein
formulae have allowed results from dynamical
systems theory to be applied to non-equilibrium
statistical mechanics in a direct way, at least for
chaotic systems. However, one must study trans-
port processes in a way that takes advantage of the
fundamental properties of chaotic dynamics.
Among the useful properties of chaotic systems
are the formation of fractal structures in phase
space. If the phase space is of sufﬁciently low
dimensions then the fractal structures can be stud-
ied both by analytical methods and by computer
simulated molecular dynamics. In addition to pro-
viding some insights into the approach to equilib-
rium for large systems, the dynamical systems
approach gives us deep results of a more practical
sort. Among these results are: (i) relations
between transport coefﬁcients and dynamical
quantities, such as Lyapunov exponents and
Kolmogorov-Sinai entropies, to be deﬁned later
in this chapter (Evans and Morriss 1990; Gaspard
1992a, 1998; Hoover 1999; Dorfman 1999;
Ruelle 1999; Klages 2007; Ott 2002; Gaspard
and Nicolis 1990; Dorfman and Gaspard 1995;
Gaspard and Dorfman 1995); (ii) a theory of
entropy production in non-equilibrium steady
states and in the approach of a system to equilib-
rium (Evans and Morriss 1990; Gaspard 1997,
1998, 2004, 2006; Hoover 1999; Dorfman 1999;
Ruelle 1999; Gallavotti 1999; Evans et al. 1993;
Evans and Searles 2002; Gallavotti and Cohen
1995; Crooks 1999; Hoover and Posch 1994;
Dorfman et al. 2002; Tél and Vollmer 2000;
Vollmer 2002); and (iii) a number of ﬂuctuation
theorems – Evans-Searles-Gallavotti-Cohen theo-
rems – which describe ﬂuctuations in entropy
production
in
non-equilibrium
steady
states
70
Chaotic Dynamics in Nonequilibrium Statistical Mechanics

(Evans et al. 1993; Evans and Searles 2002;
Gallavotti and Cohen 1995; Lebowitz and Spohn
1999; Crooks 1999; Kurchan 1998; Gaspard
2006; van Zon and Cohen 2004). Here we will
summarize these results, and we refer the reader to
the literature for a more complete discussion of
these and related topics.
Microscopic Dynamical Quantities and
Macroscopic Transport Coefficients
Among the many reasons dynamical systems
theory attracted the attention of workers in
non-equilibrium statistical mechanics were the
connections
between
macroscopic
transport
coefﬁcients of a system of particles and quantities
that characterize the system’s chaotic behavior
discovered by Gaspard and Nicolis (Gaspard
1998, 1992a; Dorfman 1999; Gaspard and Nicolis
1990; Dorfman and Gaspard 1995; Gaspard and
Dorfman 1995; Viscardy and Gaspard 2003), for
Hamiltonian systems, and by Evans, Morriss,
Hoover, Posch, and coworkers, for dissipative
systems with Gaussian thermostats (Evans and
Morriss 1990; Hoover 1999; Ruelle 1999; Klages
2007; Evans et al. 1990; Hoover and Posch 1994).
We discuss each case separately.
The Escape-Rate Formulae for Transport
Coefficients
Previously we noted that the Helfand moments
related to transport undergo a random walk
motion in phase space. Gaspard and Nicolis
pointed out that if one considers a random walk
in a space with absorbing boundaries one can
combine results from random walk theory and
from dynamical systems theory to obtain very
interesting
previously
unknown
connections
between transport coefﬁcients and quantities that
characterize the microscopic chaotic dynamics.
The random walk theory that one needs for this
connection is based on a Fokker-Planck equation
for the probability distribution of the Helfand
moments, P(Ms, t), where Ms is a Helfand
moment. We assume that the transport process is
normal, that is, that the mean square ﬂuctuations
of the Helfand moment grows linearly with time.
In such a situation the Fokker-Planck equation
takes the simple form of a diffusion equation:
@P Ms, t
ð
Þ
@t
¼ a @2P Ms, t
ð
Þ
@M2
s
ð19Þ
Here α is a constant proportional to the trans-
port coefﬁcient s. Suppose now that we solve this
diffusion equation in M-space with boundary con-
ditions that when Ms reaches the values w/2,
P(Ms, t) ¼
0. That is, the Helfand moments
undergo a Brownian motion in a space with
absorbing boundaries such that the probability
distribution vanishes whenever jMsj reaches a
speciﬁc value for the ﬁrst time. Under these con-
ditions, the probability distribution will decay
exponentially, with a decay rate γ given by
g ¼ a p
w
 2
:
ð20Þ
A remarkable result from dynamical systems
theory is that for chaotic systems, another expres-
sion holds for the same escape rate in terms of
Lyapunov exponents and a quantity called the
Kolmogorov-Sinai
entropy
per
unit
time
(Gaspard 1993, 1998; Katok and Hasselblatt
1995; Gaspard and Rice 1989). This microscopic
escape-rate formula for the escape-rate, γmic is
gmic ¼
X
i
lþ
i R
ð
Þ  hKS R
ð
Þ:
ð21Þ
All of the terms on the right hand side of
Eq. (21) require some explanation. To get some
insight into this formula, we now consider the
microscopic dynamics of the system of particles
and imagine that there is a set of initial conditions
for all the particles for which the Helfand moment
is in the region w/2 < Ms < w/2, and such that as
the initial system evolves in time, either forward
or backward, the Helfand moment will never
reach the boundary. The set of all such initial
conditions is called a repeller and denoted by R.
It is typically a fractal set of points in phase space,
usually of measure zero in the set of all initial
phase points, and a highly unstable set since an
arbitrarily small displacement of the initial phase
of the system from a point in R will lead to
escape, unless the new initial point is also on the
Chaotic Dynamics in Nonequilibrium Statistical Mechanics
71

repeller. Now imagine that we consider an inﬁni-
tesimally small set of points in R, and observe
how these points separate in phase space in the
course of time. If the dynamics on R is Anosov-
like, there will be a set of positive Lyapunov
exponents which we have denoted by lþ
i R
ð
Þ in
Eq. (21). The positive Lyapunov exponents on the
repeller describe the rate with which trajectories
on the repeller move apart. apart. The other term
in the
escape-rate
formula,
hKS(R), is the
Kolmogorov-Sinai entropy per unit time of
the trajectories on R, and can be understood
in the following way. In general, dynamic entropies
characterize the rate at which information about the
exact trajectory of a system is gained or lost in the
course of time. For example, if we know that the
initial phase of a system is within some small
region of phase space, then the stretching of the
small region with time due to the dynamical insta-
bility allows us to locate the initial location of
the trajectory ever more precisely as we follow
the motion of the small initial set. If the system is
closed, that is, there is no possibility of escape, then
the amount of information about the initial location
of the trajectory grows exponentially as the sum of
the positive exponents. This result is known as
Pesin’s theorem. On the other hand, if the system
is open and there is a possibility of escape, then the
escaping trajectories lead to a loss of information
(Dorfman and van Beijeren 1997). Hence a better
way to write Eq. (21) is
hKS R
ð
Þ ¼
X
i
lþ
i R
ð
Þ  gmic:
ð22Þ
In any case we now have two expressions for
the same escape-rate for a hyperbolic system, and
by equating them, we obtain an expression for the
transport coefﬁcient in terms of microscopic
dynamical quantities, as
a ¼ lim
w!1
w2
p2
X
i
lþ
i R
ð
Þ  hKS R
ð
Þ
"
#
:
ð23Þ
We have taken the large system limit to remove
any possible dependence of the right hand side of
Eq. (23) on the shape of the boundaries or on the
size of the system. This result is due to Gaspard
and Nicolis (1990).
For
two
dimensional
systems,
one
can
reformulate the escape rate formula in terms of
the information dimension, d1, of the repeller
along the unstable direction (Gaspard 1998; Tél
et al. 1996), which is given by d1 ¼hKS/l+, so that
γ ¼ l+(1  d1).
The escape-rate formula has been used in
molecular dynamics studies to obtain values for
transport coefﬁcients in a number of cases such as
diffusion coefﬁcients in periodic Lorentz gases,
viscosities of simple systems and chemical reac-
tion rates (Gaspard and Baras 1995; Viscardy and
Gaspard 2003; Claus and Gaspard 2000; Claus
et al. 2004; Bunimovich and Demers 2005). The
results for the transport coefﬁcients obtained by
using the escape-rate methods agree with those
obtained by other methods, often based on the
Green-Kubo time correlation method, or, as
discussed
below,
on
Gaussian
thermostat
methods. There are as yet very few theoretical
methods
to
compute
the
Kolmogorov-Sinai
entropy for the repeller (Gaspard and Baras
1995; Gaspard 1998; Viscardy and Gaspard
2003), while both the transport coefﬁcients, and,
as it turns out, the sum of the positive Lyapunov
exponents on the repeller are sometimes amenable
to treatment by the usual methods of statistical
mechanics and kinetic theory (van Beijeren and
Dorfman 1995, 2001; van Zon et al. 2000).
Transport Coefficients and Phase-Space
Contraction in Gaussian Thermostatted Systems
An alternative method for relating macroscopic
transport coefﬁcients to Lyapunov exponents was
developed
by
Evans,
Hoover,
Posch,
and
co-workers in their work on developing computer
algorithms to simulate non-equilibrium ﬂows in
many-particle systems (Evans and Morriss 1990;
Hoover 1999; Ruelle 1999; Evans et al. 1983,
1990, 2000; Hoover and Posch 1994; Posch and
Hoover 1988, 1989; Chernov et al. 1993; Baranyi
et al. 1993; Dellago et al. 1995, 1996; Dettmann
2000; Posch and Hirshl 2000). A problem arose in
these simulations because the systems tended to
heat up considerably due to the presence of viscous
friction or, for charged particle systems, ohmic
72
Chaotic Dynamics in Nonequilibrium Statistical Mechanics

heating. To counteract this heating, these authors
introduced a ﬁctitious thermostat which maintains
a constant value for either the total energy or the
total kinetic energy of the system. The thermostat
was introduced by a modiﬁcation of the equations
of motion by the addition of a frictional force in
such a way that the Hamiltonian nature of the
system, in the usual coordinate, momentum, and
time variables, is lost. This kind of frictional force
was ﬁrst introduced by Gauss in his study of
mechanical systems with various constraints.
For
systems
with
Gaussian
thermostats,
Liouville’s theorem, which states that the phase
space density at a point moving under the equations
of motion does not change with time, is no longer
satisﬁed. It is replaced by a conservation equation
that relates the time derivative of the distribution
function to the parameters characterizing the fric-
tional forces. As a consequence, phase space vol-
umes for thermostatted systems do not remain
constant in time, but rather, on the average the
phase space volume of a set decreases with time,
the system approaches a non-equilibrium stationary
state,
and
the
system’s
distribution
function
approaches a distribution with fractal properties.
The average rate of decrease of the phase space
volume is given by a negative value of the sum of
all of the Lyapunov exponents of the system. The
non-equilibrium stationary state distribution is char-
acterized by a special type of measure, called a
Sinai-Ruelle-Bowen
(SRB)
measure,
which
describes the probability of ﬁnding a system in
different regions of phase space. The SRB measure
is characterized by the fact that it is smooth in the
unstable directions in phase space but typically is
fractal
in
the
stable
directions
(Katok
and
Hasselblatt 1995). Simple examples of this type of
measure can be found in the literature (Tasaki et al.
1998). The resulting fractal is called an attractor.
It is important to note that the decrease of the
phase space volume and the concomitant forma-
tion of an attractor with a non-trivial SRB mea-
sure, does not mean that the fractal has zero
dimension. Indeed, due to the decrease in phase
space volume the Lebesgue measure of the phase
space region where the trajectories are located
approaches zero. However, the dimension of the
resulting fractal is not zero. The box counting
dimension, D0, of the fractal may even coincide
with the dimension of phase space, and the infor-
mation dimension, D1, can often be expressed in
terms of the Lyapunov exponents. For example
for two-dimensional, thermostatted systems, with
one positive Lyapunov exponent, l+ and one neg-
ative exponent,  j lj, with l+  j l j < 0, the
information dimension of the attractor is given by
the Kaplan-Yorke-Young formula (Eckmann and
Ruelle 1985; Ott 2002; Chernov et al. 1993;
Evans et al. 2000) for two dimensional ergodic
systems, as D1 ¼ 1 þ l+/jlj.
The decrease of the phase space volume can
also be related to the entropy production in the
system+thermostat. This entropy production can
also be related to the transport coefﬁcients via the
usual macroscopic laws of irreversible thermody-
namics. Thus, one has a way to relate transport
coefﬁcients to the sum of the Lyapunov exponents
for these thermostatted systems.
To make this discussion more concrete, we con-
sider the example of a hard-ball Lorentz gas (Tél
and Vollmer 2000; Chernov et al. 1993; Baranyi
et al. 1993; Dettmann 2000; Posch and Hirshl
2000). We assume that the moving particles have
a bounded free path between collisions with the
ﬁxed scatterers, and that the scatterers do not form
traps without escape for the moving particles. We
suppose the moving particles have mass. m, and
carry a charge, q, (but still do not interact with each
other) and are placed in a constant, external electric
ﬁeld, E. Ordinarily, the ﬁeld will accelerate the
moving particles in such a way that their energy
increases over time. To avoid this we add a fric-
tional force to the equations of motion of the mov-
ing particle, and adjust the frictional force so as to
keep the kinetic energy of the moving particle
constant in time. The equations of motion for the
position, r and velocity, v, of the moving particle
between collisions with scatterers are
_r ¼ v
ð24Þ
_v ¼ qE
m  av,
ð25Þ
where α is a dynamical variable deﬁned by the
constant energy condition, _v  v ¼ 0. Thus we ﬁnd
that
Chaotic Dynamics in Nonequilibrium Statistical Mechanics
73

a ¼ qv  E
mv2 :
ð26Þ
The equations of motion given above for the
moving particle must be supplemented by the
equations describing the collisions of the moving
particles with the scatterers. To simplify matters,
we will suppose that the particles make instanta-
neous, elastic, and specular collisions with the
scatterers.
If we deﬁne the Gibbs entropy for this system
in terms of the phase space distribution function,
r(r, v, t), by
SG tð Þ ¼ kB
Z
dr
Z
dvr r, v, t
ð
Þ ln r r, v, t
ð
Þ  1
½
,
ð27Þ
where kB is Boltzmann’s constant, one ﬁnds that
dSG
dt ¼ kB
Z
dr
Z
dvar ¼ kB a
h i:
ð28Þ
The average value is taken with respect to the
phase space distribution function for the moving
particles, r. This entropy actually decreases with
time, since on the average α is positive. This
decrease in entropy must be matched, at least, by
an increase in entropy of the reservoir that is
responsible for the additional frictional force.
Thus
dSreservoir
dt
 kB a
h i  0:
ð29Þ
We now take the entropy production in the
reservoir to be given by the usual macroscopic
laws, in particular,
dSreservoir
dt
¼ J  E
T
¼ sE2
T ,
ð30Þ
where J ¼sE is the electrical current produced by
the moving particles and s is the coefﬁcient of
electrical
conductivity.
Then,
by
combining
Eqs. (29) and (30), and assuming that we take
the entropy production in the reservoir to be
exactly kBhαi, we obtain and expression for s as
s ¼ kBT a
h i
E2
:
ð31Þ
The ﬁnal step in this process is to relate the
average friction coefﬁcient, hαi, to the Lyapunov
exponents for the trajectories of the moving par-
ticles. We note, ﬁrst of all, that the volume, V of a
small region in phase space will change exponen-
tially in time with an exponent equal to the sum of
all the Lyapunov exponents, as
V tð Þ ¼ V 0
ð Þ exp
X
i
li,
ð32Þ
since the Lyapunov exponents describe the rates
of stretching or of contracting of small distances
in phase space. A simple argument shows that
d ln V
dt


¼  a
h i ¼
X
i
li
*
+
:
ð33Þ
In the non-equilibrium stationary state, all
averages remain constant with time, so that we
can now use Eq. (31) to obtain the desired con-
nection between a transport coefﬁcient, in this
case
the
conductivity
s,
and
the
average
Lyapunov exponents,
s ¼  kBT
E2
X
i
li
*
+
:
ð34Þ
This result has been used to determine the con-
ductivity and the diffusion coefﬁcient of the moving
particles in the Lorentz gas by means of efﬁcient
computer algorithms for determining the Lyapunov
exponents (Baranyi et al. 1993; Dettmann 2000;
Posch and Hirshl 2000). Similar methods have
been used to determine the shear viscosity (Evans
et al. 1990) and other transport properties of systems
with short range, repulsive potentials.
One important result of the analysis of these
thermostatted systems is the conjugate pairing
rule. This is a generalization of the result for
chaotic
Hamiltonian
systems
that
non-zero
Lyapunov exponents come in pairs, with the
same magnitude but with opposite signs so that
members of each conjugate pair sum to zero
74
Chaotic Dynamics in Nonequilibrium Statistical Mechanics

(Ott 2002). This is called the symplectic conjugate
pairing rule. For many chaotic systems with
Gaussian thermostats it is possible to prove
another
conjugate
pairing
rule
where
the
Lyapunov exponents form conjugate pairs which
sum to a non-zero value, independent of which
pair of exponents is chosen (Evans et al. 1990;
Dettmann and Morriss 1996; Wojtkowski and
Liverani 1998). The conjugate pairing rule is
very helpful for analyzing relations such as that
given by Eq. (34), since the right hand side is
completely determined by the sum of any one
conjugate pair of exponents. The easiest pair to
use is the pair formed by the positive and negative
exponents with the largest magnitude.
Ruelle-Pollicott Resonances and Irreversible
Processes
For a Hamiltonian N-particle system, the phase
space distribution function, r(Γ, t) evolves in time
according to the relation given by the Liouville
equation, in terms of a time evolution operator,
S t
ð
Þ, as
r G, t
ð
Þ ¼ S t
ð
Þr G, 0
ð
Þ
¼ exp  tLr G, 0
ð
Þ
¼ r G t
ð
Þ, 0
ð
Þ,
ð35Þ
where we indicate that the phase space variables Γ
evolve as
G tð Þ ¼ S tð ÞG ¼ exp tLG:
ð36Þ
Here L is the Liouville operator, when acting
on differentiable functions, is given, for an iso-
lated system of N particles, by
L ¼
X
N
i¼1
pi  @
@ri þ
X
N
i
Fi  @
@pi
,
ð37Þ
where Fi is the total force on particle i due to the
other particles, and external sources such as walls
of a container.
If one insists that the functions on which the
time displacement operator acts be ordinary func-
tions with well-behaved derivatives, the exponen-
tial operators, S appearing in Eqs. (35), (36) are
unitary with spectrum on the unit circle. In view of
this observation it is difﬁcult to see how a satis-
factory theory of irreversible behavior, including
decays in time, might be obtained from such an
operator. The answer is to be found by enlarging
the space of functions to include singular func-
tions such as Schwartz distributions (Gaspard
1998). The discussion in the previous subsection
has indicated that distributions may evolve to
fractals, which are typically non-differentiable
functions, so it is very natural to include singular
functions in the space of functions on which the
time evolution operator may act. In this enlarged
function space, the time evolution operator may
have properties that do not obtain in a more
restricted space of functions. Under these circum-
stances one studies the right and left eigen-
functions of the Liouville operator, L
in a
structure called a Gelfand triplet or rigged Hilbert
space (Bohm and Gadella 1990). There are two
sets of such triplets corresponding to forward and
time reversed motion.
A Gelfand triplet is an operator, together with
the two spaces spanned by its right and left eigen-
functions, and an inner product involving one
function from each of the two spaces. If the right
eigenfunctions are singular functions, the left
eigenfunctions must be sufﬁciently well behaved
so that the inner product of a function in the
“singular” space with a function in the “smooth”
space is well deﬁned. The eigenvalues for the time
displacement operator appear as two different sets
of poles of the resolvent operator, (z ℒ)1, in the
complex plane, one for forward and one for time-
reversed motion. The poles are called Ruelle-
Pollicott resonances (Pollicott 1985, 1986; Ruelle
1986a, b), and they give the relaxation rates for
various processes that can take place in the sys-
tem. The time reversal symmetry of the motion
provides the relation between the two sets of res-
onances in the complex plane. For simple models
it is possible to construct the functions, singular
and smooth, in a Gelfand triplet and to locate the
resonances in the complex plane (Dörﬂe 1985;
Gaspard 1992b, c). In addition to poles of the
resolvent one may, in general, expect to ﬁnd
branch cuts, etc. in the complex plane (Gaspard
1998). The existence of these resonances provides
Chaotic Dynamics in Nonequilibrium Statistical Mechanics
75

an argument that the rates of relaxation to equilib-
rium found by using traditional methods of statis-
tical mechanics, including kinetic theory, are not
artifacts of the approximations made in arriving at
these results, but are reﬂections of the existence of
Ruelle-Pollicott resonances for the system.
Fractal Forms in Diffusion and a Dimension
Formula
For chaotic systems, the relation between the mean
square displacement of a diffusing particle and the
diffusion coefﬁcient conceals a fractal function. This
can be understood on the basis of the following
observation: Since the actual displacement of the
diffusing particle depends on the initial phases of
the particles in the system, even the slightest change
in these phases will make a large change in the
displacement of the Brownian particle. One way to
try to capture some features of this variation of the
displacement is to consider simple models of diffu-
sion that are deterministic, chaotic, and diffusive
(Fox 1997; Gaspard 1996). The process of diffusion
in these models is often referred to as deterministic
diffusion, since no stochastic elements are intro-
duced in the dynamics of the models. Here we
illustrate this idea using the two dimensional peri-
odic Lorentz gas with ﬁnite free paths of the moving
particle between collisions, so that diffusion is well
deﬁned in this system (Fox 1997; Gaspard 1996;
Gilbert et al. 2001) (Fig. 7).
It is very convenient to use the van Hove inter-
mediate scattering function as a way of describing
the diffusive process. This function, denoted by
Fk(t), is deﬁned as
Fk tð Þ ¼
e ik r tð Þr 0
ð Þ
ð
Þ
½

D
E
,
ð38Þ
where the average is taken over an equilibrium
ensemble. The van Hove function is related to the
probability of ﬁnding the diffusing particle at
point r at time t, P(r, t) by
P r, t
ð
Þ ¼
Z
dk
2p
ð
Þd PkFk tð Þ,
ð39Þ
where d is the number of spatial dimensions of the
system and Pk is the Fourier transform of the
initial probability distribution for the diffusing
particle. One can use a cumulant expansion in
the exponent to show that Fk(t) is given by
Fk tð Þ ¼ es k
ð Þt,
ð40Þ
where s(k) is the wave-number dependent decay
rate for diffusive motion. Thus, for wave numbers,
Chaotic
Dynamics in Nonequilibrium
Statistical
Mechanics, Fig. 7 The incomplete van Hove function
for a periodic Lorentz gas where a point particle of unit
mass and velocity undergoes elastic collisions with hard
disks of unit radius forming a triangular lattice with
interdisk distance d ¼ 2.3: Curves of the cumulative
functions for wavenumber kx ¼ 0.0, 0.5, and 0.9 with
ky ¼
0. Note that the fractality increases with the
wavenumber
76
Chaotic Dynamics in Nonequilibrium Statistical Mechanics

k much smaller than the inverse of a lattice spac-
ing, in this case, unity, this function takes the form
s k
ð Þ ¼ Dk2 þ eDk4 þ O k6
	

,
ð41Þ
where D is the diffusion coefﬁcient, eDis called the
super-Burnett diffusion coefﬁcient, etc. In order to
see the physics that is obscured by taking the equi-
librium average, consider the microscopic quantity
that is averaged, namely, exp[ik  (r(t) r(0))]. If the
motion of the particle is chaotic, the displacement
over a time t is a very rapidly varying function of the
initial point r(0). As a result, the exponential
containing this displacement will be a rapidly oscil-
lating function of the initial point. To capture these
oscillations and to explore the fractal structure of the
exponential function, we consider a partially aver-
aged quantity, which we will call a normalized,
incomplete van Hove function, Fk(θ, t), deﬁned by
Fk y, t
ð
Þ ¼
R y
0dy0e ik r y0,t
ð
Þr y0,0
ð
Þ
ð
Þ
½

R 2p
0 dy0e ik r y0,t
ð
Þr y0,0
ð
Þ
ð
Þ
½
 :
ð42Þ
Here we take initial points to be uniformly
distributed just outside the surface of one of the
scatterers in the periodic Lorentz gas, with initial
velocity directed radially outward. The point on
the surface is indicated by the angle θ taken with
respect to some ﬁxed direction. If one waits for a
sufﬁcient number of collisions to take place so
that the motion is diffusive, and then plots Im
Fk(θ, t) vs Re Fk(θ, t) one ﬁnds a fractal curve
for small values of the wave number, jkj. Com-
puter results obtained by Claus et al. (Gaspard
et al. 2001) for the hard disk Lorentz gas are
plotted in Fig. 7 for various values of the wave
number.
It is possible to prove that there exists a striking
connection between the fractal Hausdorff dimen-
sion, DH, of the curve (Re Fk(x), Im Fk(x)), for the
incomplete van Hove function (Gaspard 1996;
Gilbert et al. 2001), for small k, the diffusion coef-
ﬁcient, D, and the positive Lyapunov exponent, l,
characterizing the chaotic process underlying the
diffusive motion of the particle. This connection is
illustrated in Fig. 8 and given by the equation
DH k
ð Þ ¼ 1 þ D
l k2 þ O k4
	

:
ð43Þ
Also illustrated in Fig. 8 is the analogous curve
obtained from the incomplete van Hove function
Chaotic
Dynamics in Nonequilibrium
Statistical
Mechanics, Fig. 8 Hausdorff dimension DH of the
incomplete van Hove function versus k2 ¼ k2
x (ky ¼ 0)
for both periodic Lorentz gases with hard-disk scatterers
(ﬁlled circles) and for the case where the hard disks are
replaced by repulsive Coulomb scatterers on a square
lattice, and the energy of the particle is sufﬁciently high
for the motion to be chaotic (open circles). Both solid lines
have slopes equal to D=l for the respective diffusion
coefﬁcient D and Lyapunov exponent l of the Lorentz
gases
Chaotic Dynamics in Nonequilibrium Statistical Mechanics
77

when the hard disk potential is replaced by a
repulsive Coulomb potential. For sufﬁciently
high energy of the moving particle, the motion
of the moving particle is chaotic and the van Hove
function also shows fractal properties. Thus the
fractal curves are not artifacts of the hard disk
potential. Equation (43) illustrates the fact that
for chaotic models such as the one discussed
here, the incomplete van Hove function encodes
in its structure both a macroscopic property of the
system, the diffusion coefﬁcient, and a micro-
scopic property, the Lyapunov exponent. Such
interesting connections are central to a deeper
understanding of the microscopic foundations of
transport processes.
Entropy Production in Non-equilibrium,
Hamiltonian Systems
One of the subjects of most active research in
recent years has been the theory of entropy pro-
duction in non-equilibrium systems. Dynamical
systems theory has provided some new insights
into this old problem. Brieﬂy formulated, the
problem is to explain the positive, irreversible
production of entropy using the fundamental
ideas in statistical mechanics, particularly the
Liouville equation. The obstacle in this direction
that must be overcome somehow is the fact that
the Gibbs entropy
SG tð Þ ¼ kB
Z
dGr G, t
ð
Þ ln r G, t
ð
Þ  1
½
,
ð44Þ
remains constant in time if r(Γ, t) satisﬁes the
Liouville equation for Hamiltonian systems
dr G, t
ð
Þ
dt
¼ 0:
ð45Þ
Here Γ represents all of the coordinate and
momentum variables of the system. The usual
way around this difﬁculty is to introduce a coarse
grained entropy, obtained by either deﬁning an
entropy in terms of reduced distribution functions,
as is done in Boltzmann’s famous H-theorem, or
by coarse graining the phase space itself, and
deﬁning an entropy in terms of the average
phase space distribution in each of the coarse
graining regions (Ruelle 1999). In either case, it
is possible to show that the rate of production of
the redeﬁned entropy is positive, and for the
Boltzmann case at least, is in agreement with the
predictions of irreversible thermodynamics when
the gas is close to a local equilibrium state.
Ideas from dynamical systems theory have not
changed
the
fundamental
need
for
coarse
graining. Instead they have provided strong rea-
sons for doing it, reasons that were lacking in the
previous approaches, where the motivation for
coarse graining seemed only to be that it was
necessary to coarse grain in some way to get a
positive entropy production. The central new idea
in this area is that the phase space description of a
non-equilibrium process requires, in the thermo-
dynamic limit at least, the use of distribution
functions
that
are
deﬁned
on
fractal
sets.
A simple example is provided by a system in
which diffusion can take place in a region between
two particle reservoirs, each reservoir being
maintained at a different density of particles
(Gaspard 1997, 1998). Then if the dynamics that
leads to transport of the particles between the
reservoirs is Anosov-like, one can argue, and in
simple enough cases show explicitly, that the
regions in phase space that correspond to regions
of different density in the system get so tangled up
and enmeshed that the distribution function is a
wildly varying fractal function. As such, it is no
longer differentiable and the steps that lead to the
proof of the constancy of the Gibbs entropy can no
longer be justiﬁed. The only way to treat this kind
of fractal behavior of the distribution function is to
smooth the function in one or another way, typi-
cally by deﬁning cumulative distribution func-
tions over small regions of phase space, leading
to the construction of SRB measures. In simple
cases, one can show that fractal forms appear in
the phase space distribution function for systems
in non-equilibrium stationary states produced by
particle reservoirs, or in the relaxation of a system
with particle diffusion to equilibrium, and that the
rate of entropy production agrees with the pre-
dictions
of
irreversible
thermodynamics
(Gaspard 1997, 1998; Dorfman et al. 2002; Fox
78
Chaotic Dynamics in Nonequilibrium Statistical Mechanics

1998; Goldstein et al. 1998). However, much
needs to be done to extend this work to other
hydrodynamic processes and to understand why
the results of macroscopic theory are obtained in
this way. Recently, Gaspard has presented an
expression for the rate of entropy production in
chaotic as well as in stochastic systems as the
difference in two dynamical entropies per unit
time, one a form of the Kolmogorov-Sinai entropy
per unit time, and the other, an entropy per unit
time for the time reversed motion but as measured
by the measure of the forward process. It is pos-
sible to prove that this rate of entropy production
is positive, and for the cases studied so far, agrees
with the results of irreversible thermodynamics
(Gaspard 2004, 2006).
Kinetic Theory Methods for Analytical
Calculations of Lyapunov Spectra
As we demonstrated in the examples given above
for the applications of chaos theory to non-
equilibrium processes, an important role is played
by Lyapunov exponents and Kolmogorov-Sinai
entropies per unit time. Apart from computer sim-
ulations, it is not always clear how one might
obtain expressions and values for these quantities.
In some simple cases such as the baker’s map and
toral automorphisms, the calculation of the
Lyapunov exponents is a simple matter. However
these cases are very special and rarely are realistic
models for physical systems. Thus the problem
remains of ﬁnding general methods for an analytic
determination
of
Lyapunov
exponents
and
Kolmogorov-Sinai entropies. One such method
is kinetic theory. Using the Boltzmann and
related equations (Dorfman 1999; Chapman and
Cowling 1970), van Beijeren and coworkers
have
been
able
to
obtain
expressions
for
Lyapunov
exponents,
and
in
some
cases,
Kolmogorov-Sinai entropies, for dilute gases
with short range potentials, such as hard ball
systems, and for dilute Lorentz gases (Dorfman
1999; van Beijeren and Dorfman 1995, 2001;
van Zon et al. 1998, 2000; de Wijn and van
Beijeren 2004). Results obtained this way are in
good agreement with the results of computer
simulations. We refer to the literature for details.
Entropy Production in Systems with Gaussian
Thermostats and the Cohen-Gallavotti
Fluctuation Theorem
As a ﬁnal example of the applications of dynam-
ical systems theory to non-equilibrium statistical
mechanics we brieﬂy discuss one example of a
number of closely related ﬂuctuation theorems,
ﬁrst
obtained
by
Evans,
Searles,
and
by
Gallavotti, and Cohen, and generalized by Spohn
and Lebowitz, among others (Evans et al. 1993;
Evans and Searles 2002; Gallavotti and Cohen
1995; Lebowitz and Spohn 1999; Crooks 1999;
Kurchan 1998). These ﬂuctuation theorems are
very closely related to a class of work-free energy
ﬂuctuation results due to Jarzynski (1997), and
Crooks (1999), as well as to the expression for
entropy production given by Gaspard (2004,
2006), as mentioned above. By now the literature
is quite extensive and the reader is directed there
for more details. Here we discuss, brieﬂy, the
Gallavotti-Cohen version of a ﬂuctuation theorem
appropriate for systems with Gaussian thermo-
stats (Gallavotti and Cohen 1995). In the discus-
sion
of
systems
with
energy
conserving
thermostats, we have introduced another idea for
entropy production, namely, entropy production
in a reservoir associated with phase space contrac-
tion of a thermostatted system. Here the central
idea is that the thermostatted dynamics produces
an attractor for the system’s trajectories in phase
space. The friction coefﬁcient, which we have
denoted by α, is a dynamical function taking on
positive or negative values depending on the tra-
jectory of the system in phase space. To produce
an overall phase space contraction, the friction
coefﬁcient should be positive on average, but
from time to time it may be negative. Loosely
speaking, we might say that the entropy produc-
tion in the system is positive when the value of α is
positive at the time, and negative when α is neg-
ative. For example, in the Lorentz gas that we
have been discussing, when the particle moves
in the direction of the ﬁeld, α is positive, and
when it moves opposite to the direction of the
ﬁeld, α is negative, provided the charge q is pos-
itive. One might imagine some time interval t,
say, and ask for the probability that the time-
Chaotic Dynamics in Nonequilibrium Statistical Mechanics
79

averaged entropy production per unit time, ϵt, as
measured by the phase space contraction, has a
value a over this time interval. This probability
can be expressed in terms of the SRB measure on
the attractor of the steady state system. The ﬂuc-
tuation theorem for this system is a result for the
ratio of the probability that the time-average
entropy production per unit time over an interval
t will be the value a, to the probability that this
value will be a. For a reversible, Anosov-like
system with a Gaussian thermostat, the theorem is
Prob ϵt ¼ a
ð
Þ
Prob ϵt ¼ a
ð
Þ ¼ eat
ð46Þ
Note that for long times this ratio approaches
zero or inﬁnity depending upon the sign of a.
This result was ﬁrst discovered by means of
computer simulations by Evans, Cohen, and
Morriss
(1993),
and
this
observation
was
explained on the basis of Anosov-like dynamics
by Gallavotti and Cohen (1995). A closely related
ﬂuctuation formula was derived by Evans and
Searles (2002). By now this class of ﬂuctuation
theorems has been generalized considerably to
include analogous results for stochastic and other
kinds of systems. We refer to the literature men-
tioned above for further details.
Discussion
Here we described some aspects of the theory of
irreversible processes, as seen from the point of
view of dynamical systems theory. We described
the notions of ergodic and mixing properties of a
dynamical system and argued that they alone are
insufﬁcient for a full explanation of the approach
to equilibrium as seen on laboratory time scales.
However, we tried to argue that if the microscopic
system
has
positive
Lyapunov
exponents
connected to unstable manifolds in the phase
space, then one can argue that an approach to
equilibrium of reduced distribution functions can
occur on much shorter times scales than those
needed to establish the mixing of phase space
regions throughout the entire phase space. More-
over the existence of a chaotic microscopic
dynamics allows us to derive some very striking
connections between macroscopic transport coef-
ﬁcients and quantities such as Lyapunov expo-
nents,
fractal
dimensions,
Kolmogorov-Sinai
entropies, that characterize the underlying cha-
otic, microscopic dynamics of the system. Much,
but not all, of our discussion was based on some
very simple examples of classical chaotic systems
with few degrees of freedom, the baker’s map and
the Arnold Cat Map. These are simple Anosov-
like and Anosov systems where one can analyze
many points in some detail. However, this analy-
sis is still very far from an analysis of systems of
real interest to statistical mechanics, where the
number of degrees of freedom is generally much,
much larger, even for systems of particles studied
on computers, and where the dynamics is not
always chaotic. Therefore, it is very much an
open question to show that this picture persists
when the systems studied are of macroscopic size,
and the dynamics is treated in a more realistic way.
Finally we should say something about the role
that quantum mechanics plays in our understand-
ing of the approach of a system to equilibrium.
“Quantum chaos” is a subject that has developed
an enormous literature (Srednicki 1999; Haake
2001; Stöckmann 1999; Wojcik 2006), primarily
associated with the quantum behavior of systems
with few degrees of freedom which are chaotic in
the classical limit of ℏ! 0. This work is clearly of
great importance for understanding the behavior
of mesoscopic quantum devices such as quantum
dots and related materials. However, there is no
analog of dynamical chaos in quantum mechanics
and no direct translation of the results described
here to quantum systems. This is a result of the
fact that the limit as ℏapproaches zero does not
commute with the limit of t approaching inﬁnity.
Therefore one cannot typically study the asymp-
totically long time behavior of a quantum system
whose classical counterpart is chaotic, and then by
taking the limit of ℏapproaching zero, obtain the
correct, chaotic behavior of the classical system.
Instead one may look for some sign in the quan-
tum
motion
that
the
classical
system
is
chaotic. Typically a quantum system will exhibit
some signs of the chaotic behavior of the classical
system in the semi-classical region of small, but
80
Chaotic Dynamics in Nonequilibrium Statistical Mechanics

not zero ℏ, for some period of time known as the
Ehrenfest time. The Ehrenfest time is essentially
the time that it takes an initially small wave packet
to expand to some characteristic length in the
system. While the packet is small, the semi-
classical behavior is essentially that of a classical
system. The rate of the expansion of the wave
packet is determined by the classical Lyapunov
exponents. When the wave packet reaches a cer-
tain size, then the motion of the system is
governed by interference and diffraction effects
that have no classical counterpart. For example,
while a classical particle moving among a random
array of ﬁxed scatterers exhibits normal diffusion,
its quantum counterpart can be localized, or move
diffusively, depending upon the spatial dimension
of the system and the particle’s energy.
The comments above suggest that chaotic
dynamics has a large role to play in quantum
systems when one looks at the semi-classical
regime, namely, the regime where ℏ, in proper
dimensionless units, can be considered very
small (Haake 2001; Stöckmann 1999). One
important result, known as Schnirelman’s Theo-
rem (Lazutkin 1993) states that in the semi-
classical limit, most of the wave functions for a
quantum system, whose classical counterpart is
chaotic and ergodic, become “equidistributed”
on the constant energy surface. This means that
the probability of ﬁnding of ﬁnding the system in
some region becomes equal to the ratio of the
measure of that region to the total measure of the
region available to the system. Nevertheless, there
are some wavefunctions for classically chaotic
systems that exhibit scars in the semi-classical
limit, where the wave function is concentrated
on periodic orbits of the classical motion. The
scarred wave functions then form a special class
which do not satisfy Schnirelman’s Theorem. In
this connection we also mention Berry’s conjec-
ture (Berry 1977) which states that the high
energy wavefunctions for a classically chaotic,
ergodic system can be represented as a Gaussian
random function, such as a superposition of plane
waves with random phases. For further details we
refer to the literature listed above.
The understanding of the approach to equilib-
rium in macroscopic systems typically requires a
treatment of quantum systems with a very large
number of degrees of freedom. Such systems are
not likely to be in one or in a superposition of a
few energy eigenstates. Instead, such systems are
likely to be in a state that is a superposition of a
huge number of such quantum states, and
destructive interference of the phase relations
among the states is an important ingredient of
the behavior of such systems (van Kampen
1988). In fact there is a large literature that
deals with the phenomenon of the loss of coher-
ence, or decoherence, of superpositions of large
numbers of quantum states for a macroscopic
system, and helps us understand a bit more
clearly why classical mechanics is a good
approximation for describing systems that we
know to be intrinsically quantum mechanical.
Future Directions
We conclude with a list of open questions that will
provide some indication of what directions might
be fruitful for further work in the future. This list is
far from exhaustive, but focuses upon the partic-
ular issues addressed here.
1. Most of the results described here that connect
microscopic dynamics and macroscopic trans-
port, such as the escape rate formulae, Eq. (23),
the dimension formula Eq. (43), and the
Lyapunov exponents-transport coefﬁcient rela-
tions for
Gaussian thermostatted
systems
Eq. (34), have been proven for purely chaotic,
Anosov or Anosov-like systems, only. The
phase spaces of most realistic systems are not
likely to be purely chaotic. Instead one expects
realistic systems to have mixed phase spaces
with both chaotic regions and non-chaotic
regions. So far a satisfactory treatment of trans-
port in mixed systems is in a very rudimentary
shape, except for some models which have
been studied extensively. It would be useful
to have estimates of the size and importance
of non-chaotic regions in many-particle sys-
tems and to determine what corrections, if
any, are needed to generalize the results men-
tioned above to mixed systems.
Chaotic Dynamics in Nonequilibrium Statistical Mechanics
81

2. Most of the results given here have been illus-
trated, and in some cases only derived, for low
dimensional systems. How much of this dis-
cussion is relevant for systems with many par-
ticles where the dimension of phase space is
very
large?
For
example,
the
formula
connecting diffusion and Lyapunov exponents,
given by Eq. (43), has only been derived for
diffusion in two dimensional chaotic systems
Lorentz gases. What is the generalization of
this formula to higher dimensions and to gen-
eral transport processes?
3. The fact that our detailed understanding of the
role of chaos in non-equilibrium processes is
for systems of low dimensionality suggests
that applications of chaos to nanoscale systems
might be very fruitful (Gaspard 2006).
4. Pseudo-chaotic systems present a great chal-
lenge both to physicists and to mathematicians
(Gutkin 1996; Tabachnikov 2005). Are there
general statements one can make about the
motion of a particle in a collection of scatterers,
such as hard squares or other scatterers where
the motion is not chaotic at all, and the rate of
separation of trajectories is at best algebraic?
How do these properties depend on the geo-
metrical structure and arrangements of the scat-
terers? Are there generalizations of the escape-
rate formula, and the others mentioned here, to
pseudo-chaotic systems?
5. There are at least a few logical gaps in the
applications of dynamical systems theory to
non-equilibrium statistical mechanics. On one
hand we have argued that as far as the
approach to equilibrium is concerned it
makes sense to look at projected distributions
since these distribution functions reach equi-
librium forms long before the full phase space
distribution function does. This statement
itself needs a careful proof for realistic sys-
tems. Moreover, the derivations of the formu-
lae that connect transport properties with
microscopic dynamical quantities rely upon
the use of the full phase space. This suggests
that there is a fundamental issue of relevant
time scales that needs to be resolved, in order
to determine the time scales on which these
results become valid.
Acknowledgments I would like to thank Henk van
Beijeren for reading a draft of this article and for his very
helpful remarks. I would also like to thank Rainer Klages
for his new book (Klages 2007), which was very helpful
when preparing this article.
Bibliography
Primary Literature
Baranyi A, Evans DJ, Cohen EGD (1993) Field-dependent
conductivity and diffusion in a two-dimensional
Lorentz gas. J Stat Phys 70:1085
Berry MV (1977) Regular and irregular wave functions.
J Phys 10:2083
Berry MV (1978) Regular and irregular motion. In: Jorna
S (ed) Topics in nonlinear dynamics: a tribute to Sir
Edward
Bullard.
American
Institute
of
Physics,
New York
Bogoliubov NN (1962) Problems of a dynamical theory in
statistical physics. In: Studies in statistical mechanics,
vol 1. North Holland, Amsterdam
Bohm A, Gadella M (1990) Dirac Kets, Gamow vectors
and Gelfand triplets: the rigged Hilbert space formula-
tion of quantum mechanics. Springer, Berlin
Bunimovich LA, Demers MF (2005) Deterministic models
of the simplest chemical reactions. J Stat Phys 120:239
Bunimovich L, Sinai YG (1981) Statistical properties of
the Lorentz gas with periodic conﬁguration of scat-
terers. Commun Math Phys 78:478
Chapman S, Cowling TG (1970) The mathematical theory
of non-uniform gases, 3rd edn. Cambridge University
Press, Cambridge
Chernov
NI,
Eyink
GL,
Lebowitz
JL,
Sinai
YG
(1993) Steady state electrical conduction in the periodic
Lorentz gas. Commun Math Phys 154:569
Claus I, Gaspard P (2000) Microscopic chaos and reaction-
diffusion processes in the periodic Lorentz gas. J Stat
Phys 101:161
Claus I, Gaspard P, van Beijeren H (2004) Fractals and
dynamical chaos in a random 2D Lorentz gas with
sinks. Physica D 187:146
Cornfeld IP, Fomin SV, Sinai YG (1982) Ergodic theory.
Springer, Berlin
Crooks GE (1999) Entropy ﬂuctuation theorem and the
nonequilibrium work relation for free energy differ-
ences. Phys Rev E 60:2721
de Wijn A, van Beijeren H (2004) Goldstone modes in
Lyapunov spectra of hard sphere systems. Phys Rev
E 70:016207
Dellago C, Glatz L, Posch H (1995) Lyapunov spectrum of
the driven Lorentz gas. Phys Rev E 52:4817
Dellago C, Posch HA, Hoover WG (1996) Lyapunov insta-
bility in a system of hard disks in equilibrium and
nonequilibrium steady states. Phys Rev E 53:1485
Dettmann CP (2000) The Lorentz gas: a paradigm for
nonequilibrium
steady
states.
In:
Szasz
D (ed) Hardball systems and the Lorentz gas. Springer,
Berlin
82
Chaotic Dynamics in Nonequilibrium Statistical Mechanics

Dettmann CP, Cohen EGD (2000) Microscopic chaos and
diffusion. J Stat Phys 101:775
Dettmann CP, Morriss GP (1996) Proof of Lyapunov expo-
nent pairing for systems at constant kinetic energy.
Phys Rev E 53:R5545
Donnay VJ (1996) Elliptic islands in generalized Sinai
billiards. Ergod Theory Dyn Syst 16:975
Dörﬂe M (1985) Spectrum and eigenfunctions of the
Frobenius-Perron operator for the tent map. J Stat
Phys 40:93
Dorfman JR (1999) An introduction to chaos in non-
equilibrium statistical mechanics. Cambridge Univer-
sity Press, Cambridge
Dorfman JR, Gaspard P (1995) Chaotic scattering theory of
transport and reaction-rate coefﬁcients. Phys Rev
E 51:28
Dorfman JR, van Beijeren H (1997) Dynamical systems
theory and transport coefﬁcients: A survey with appli-
cations to Lorentz gases. Physica A 240:12
Dorfman JR, Gaspard P, Gilbert T (2002) Entropy produc-
tion of diffusion in spatially periodic deterministic sys-
tems. Phys Rev E 66:026110
Eckmann JP, Ruelle D (1985) Ergodic theory of chaos and
strange attractors. Rev Mod Phys 57:617
Ehrenfest P, Ehrenfest T (1959) The conceptual founda-
tions of the statistical approach in mechanics. Cornell
University Press, Ithaca
Evans DJ, Morriss GM (1990) Statistical mechanics of
nonequilibrium liquids, 2nd edn. Cambridge Univ
Press, Cambridge
Evans DJ, Searles DJ (2002) The ﬂuctuation theorem. Adv
Physics 51:1529
Evans DJ, Hoover WG, Failor BH, Moran B, Ladd AJC
(1983)
Nonequilibrium
molecular
dynamics
via
Gauss’ principle
of least constraint. Phys Rev
A 28:1016
Evans DJ, Cohen EGD, Morriss GP (1990) Viscosity of a
simple liquid from its maximal Lyapunov exponents.
Phys Rev A 42:5990
Evans DJ, Cohen EGD, Morriss GP (1993) Probability of
second law violations in shearing steady ﬂows. Phys
Rev Lett 71:2401
Evans DJ, Cohen EGD, Searles DJ, Bonetto F (2000) Note
on the Kaplan-Yorke dimension and linear transport
coefﬁcients. J Stat Phys 101:17
Fox RF (1997) Construction of the Jordan basis for the
baker map. Chaos 7:254
Fox RF (1998) Entropy evolution for the baker map. Chaos
8:462
Gallavotti G (1999) Statistical mechanics – a short treatise.
Springer, Berlin
Gallavotti G, Cohen EGD (1995) Dynamical ensembles in
stationary states. J Stat Phys 80:931
Gaspard P (1992a) Diffusion, effusion and chaotic scatter-
ing. J Stat Phys 68:673
Gaspard P (1992b) R-adic one dimensional maps and the
Euler summation formula. J Phys A 25:L483
Gaspard P (1992c) Diffusion in uniformly hyperbolic one
dimensional maps and Appell polynomials. Phys Lett
A 168:13
Gaspard P (1993) What is the role of chaotic scatttering in
irreversible processes? Chaos 3:427
Gaspard P (1996) Hydrodynamic modes as singular eigen-
states of Liouvillian dynamics: deterministic diffusion.
Phys Rev E 53:4379
Gaspard
P
(1997)
Entropy
production
in
open
vol preserving systems. J Stat Phys 88:1215
Gaspard P (1998) Chaos, scattering, and statistical
mechanics. Cambridge University Press, Cambridge
Gaspard P (2004) Time reversed dynamical entropy and
irreversibility in Markovian random processes. J Stat
Phys 117:599
Gaspard P (2006) Hamiltonian dynamics, nanosystems,
and nonequilibrium statistical mechanics. Physica
A 369:201
Gaspard P, Baras F (1995) Chaotic scattering and diffusion
in the Lorentz gas. Phys Rev E 51:5332
Gaspard P, Dorfman JR (1995) Chaotic scattering theory,
thermodynamic formalism, and transport coefﬁcients.
Phys Rev E 52:3525
Gaspard
P,
Nicolis
G
(1990)
Transport
properties,
Lyapunov exponents and entropy per unit time. Phys
Rev Lett 65:1693
Gaspard P, Rice SA (1989) Scattering from a classically
chaotic repeller. J Chem Phys 90:2225
Gaspard P, Claus I, Gilbert T, Dorfman JR (2001) Fractality
of hydrodynamic modes of diffusion. Phys Rev Lett 86:
1506
Gilbert T, Dorfman JR, Gaspard P (2001) Fractal dimen-
sion of the hydrodynamic modes of diffusion. Non-
linearity 14:339
Goldstein S, Lebowitz JL, Sinai YG (1998) Remark on the
(non)convergence of ensemble densities in dynamical
systems. Chaos 8:393
Gutkin E (1996) Billiards in polygons: a survery of recent
results. J Stat Phys 83:7
Haake F (2001) Quantum signatures of chaos. Springer,
Berlin
Helfand E (1960) Transport coefﬁcients from dissipation in
a canonical ensemble. Phys Rev 119:1
Hoover WG (1999) Time reversibility, computer simula-
tion, and chaos. World Scientiﬁc Publishing, Singapore
Hoover WG, Posch HA (1994) Second-law irreversibility
and phase space dimensionality loss from time-
reversible nonequilibrium steady-state Lyapunov spec-
tra. Phys Rev E 49:1913
Hopf E (1937) Ergodentheorie. Springer, Berlin
Jarzynski C (1997) Nonequilibrium equality for free
energy differences. Phys Rev Lett 78:2960
Katok A, Hasselblatt B (1995) Introduction to the modern
theory of dynamical systems. Cambridge University
Press, Cambridge
Klages R (2007) Microscopic chaos, fractals and transport
in nonequilibrium statistical mechanics. World Scien-
tiﬁc Publishing, Singapore
Klages R, van Beijeren H, Dorfman JR, Gaspard P (eds)
(2004) Microscopic chaos and transport in many-
particle systems. Special Issue of Physica D 187:1–391
Kubo R, Toda M, Hashitsume (1992) Statistical physics,
vol II. Springer, Berlin
Chaotic Dynamics in Nonequilibrium Statistical Mechanics
83

Kurchan J (1998) Fluctuation theorem for stochastic
dynamics. J Phys A 31:3719
Lazutkin VF (1993) KAM theory and semiclassical
approximations to wave functions. Springer, Berlin
Lebowitz JL, Spohn H (1999) A Gallavotti-Cohen type
symmetry in the large deviation functional for stochas-
tic dynamics. J Stat Phys 95:333
Mazo RM (2002) Brownian motion: ﬂuctuations, dynam-
ics,
and
applications.
Oxford
University
Press,
Clarendon
Ott E (2002) Chaos in dynamical systems. Cambridge
University Press, Cambridge
Pollicott M (1985) On the rate of mixing of Axiom-A
ﬂows. Invent Math 81:413
Pollicott M (1986) Meromorphic extensions of generalized
zeta functions. Invent Math 85:147
Posch HA, Hirshl R (2000) Simulation of billiards and hard
body ﬂuids. In: Szasz D (ed) Hard ball systems and the
Lorentz gas. Springer, Berlin
Posch HA, Hoover WG (1988) Lyapunov instability of
dense Lennard-Jones ﬂuids. Phys Rev A 38:473
Posch HA, Hoover WG (1989) Equilibrium and non-
equilibrium Lyapunov spectra for dense ﬂuids and
solids. Phys Rev A 39:2175
Ruelle D (1986a) Resonances of chaotic dynamical sys-
tems. Phys Rev Lett 56:405
Ruelle D (1986b) Locating resonances for Axiom-A
dynamical systems. J Stat Phys 44:281
Ruelle D (1999) Smooth dynamics and new theoretical
ideas in nonequilibrium statistical mechanics. J Stat
Phys 95:393
Simányi N (2004) Proof of the ergodic hypothesis for
typical hard ball systems. Ann Henri Poincaré 5:203
Sinai YG (ed) (1991) Dynamical systems, A collection of
papers. World Scientiﬁc Publishing, Singapore
Srednicki M (1999) The approach to thermal equilibrium
in quantized chaotic systems. J Phys A 32:1163
Stöckmann H-J (1999) Quantum chaos: an introduction.
Cambridge University Press, Cambridge
Szasz D (ed) (2000) Hard-ball systems and the Lorentz gas.
Encyclopedia of mathematical sciences, vol 101.
Springer, Berlin
Tabachnikov S (2005) Billiards and geometry. American
Mathematical Society Press, Providence
Tasaki S, Gilbert T, Dorfman JR (1998) An analytical
construction of the SRB measures for baker-type
maps. Chaos 8:424
Tél T, Gruiz M (2006) Chaotic dynamics: an introduction
based on classical mechanics. Cambridge University
Press, Cambridge
Tél T, Vollmer J (2000) Entropy balance, multibaker maps,
and the dynamics of the Lorentz gas. In: Szasz D (ed)
Hard ball systems and the Lorentz gas. Springer, Berlin
Tél T, Vollmer J, Breymann W (1996) Transient chaos: the
origin of chaos in driven systems. Europhys Lett 35:659
Toda M, Kubo R, Saito N (1992) Statistical physics,
vol I. Springer, Berlin
Turaev D, Rom-Kedar V (1998) Elliptic islands appearing
in near-ergodic ﬂows. Nonlinearity 11:575
Uhlenbeck GE, Ford GW (1963) Lectures in statistical
mechanics, 2nd edn. Cambridge University Press,
Cambridge
van Beijeren H, Dorfman JR (1995) Lyapunov exponents
and Kolmogorov-Sinai entropy for the Lorentz gas at
low densities. Phys Rev Lett 74(4412):erratum 77:1974
van Beijeren H, Latz A, Dorfman JR (2001) Chaotic prop-
erties of dilute, two and three dimensional random
Lorentz gases II: open systems. Phys Rev E 63:016312
van Kampen N (1988) Ten theorems about quantum
mechanical measurements. Physica A 153:97
van Zon R, Cohen EGD (2004) Extended heat ﬂuctuation
theorems for a system with deterministic and stochastic
forces. Phys Rev E 69:056121
van Zon R, van Beijeren H, Dellago C (1998) Largest
Lyapunov exponent for many-particle systems at low
densities. Phys Rev Lett 80:2035
van Zon R, van Beijeren H, Dorfman JR (2000) Kinetic
theory estimates for the Kolmogorov-Sinai entropy and
the largest Lyapunov exponents for dilute, hard ball
gases and for dilute, random Lorentz gases. In: Szasz
D (ed) Hard ball systems and the Lorentz gas. Springer,
Berlin
Viscardy S, Gaspard P (2003) Viscosity in the escape-rate
formalism. Phys Rev E 68:041205
Vollmer J (2002) Chaos, spatial extension, transport, and
non-equilibrium thermodynamics. Phys Rep 372:131
Walters P (1982) An introduction to ergodic theory.
Springer, Berlin
Wojcik D (2006) Quantum maps with spatial extent: a
paradigm for lattice quantum walks. Int J Mod Phys
B 20:1969
Wojtkowski M, Liverani C (1998) Conformally symplectic
dynamics and the symmetry of the Lyapunov spectrum.
Commun Math Phys 194:7
Zaslavsky GM (2007) The physics of chaos in Hamiltonian
systems. Imperial College Press, London
Books and Reviews
Beck C, Schlögl F (1993) Thermodynamics of chaotic
systems. Cambridge University Press, Cambridge
Casati G, Chirikov B (eds) (1995) Quantum chaos:
between order and disorder. Cambridge University
Press, Cambridge
Dorfman JR (1998) Deterministic chaos and the founda-
tion of the kinetic theory of gases. Phys Rep 301:151
Garbaczewski P, Olkiewicz R (eds) (2002) Dynamics of
dissipation, Lecture notes in physics, vol 597. Springer,
Berlin
Moore CC (2015) Ergodic theorem, ergodic theory, and
statistical mechanics. PNAS 112:1907
Rom-Kedar V, Zaslavsky G (eds) (2000) Focus issue on
chaotic kinetics and transport. Chaos 10(1):1–288
Tél T, Gaspard P, Nicolis G (eds) (1998) Focus issue on
chaos and irreversibility. Chaos 8(2):309–529
84
Chaotic Dynamics in Nonequilibrium Statistical Mechanics

Monte Carlo Simulations in
Statistical Physics
Kurt Binder
Institut für Physik, Johannes Gutenberg
Universität, Mainz, Germany
Article Outline
Glossary
Deﬁnition of the Subject
Introduction
The Metropolis Importance Sampling Algorithm
as a Tool in Classical Equilibrium Statistical
Mechanics
The Dynamic Interpretation of Monte Carlo
Simulation and Application to Study Dynamic
Processes
Overcoming the Limitations of Finite Size
Extensions to Quantum Statistical Mechanics
Future Directions
Bibliography
Glossary
Classical
statistical
mechanics Statistical
mechanics relates the macroscopic properties
of matter to basic equations governing the
motion of the (many!) constituents from
which matter is built from. For classical statis-
tical mechanics these equations are Newton’s
laws of classical mechanics.
Critical slowing down Divergence of the relax-
ation time of the model describing the dynam-
ics of a many-particle system when one
approaches a second-order phase transition
(= “critical point” in the phase diagram).
Detailed balance principle Relation linking the
transition probability for a move and the tran-
sition probability for the inverse move to the
ratio of the probability for the occurrence of
these two states connected by these moves in
thermal equilibrium.
Equilibrium Statistical
mechanics
considers
“thermal equilibrium,” i.e., a many-body sys-
tem in contact with a (big) heat reservoir does
not take up heat from this reservoir, its macro-
scopic properties do not change with time, and
a few global properties (like temperature, pres-
sure, particle number) sufﬁce to characterize
the state of the system.
Ergodicity Property that ensures that ensemble
averages of statistical mechanics (taken with
the proper probability distribution) agree with
time averages taken along the trajectory along
which the system moves through its state space.
Finite-size scaling Theory that describes the
rounding and shifting of singularities that ther-
modynamic properties exhibit when the state
of a system changes from one phase to another
in the “thermodynamic limit” (i.e., particle
number N ! 1).
Importance sampling Monte Carlo method that
chooses the states that are generated according
to the probability distribution that one desires
to realize. For example, for statistical mechan-
ics applications, states are chosen with weights
proportional to the “Boltzmann factor” {exp
[–energy of the state/temperature]}.
Master equation Rate equation describing the
“time” – evolution of the probability that a
state occurs as a function of a “time” coordi-
nate labeling the sequence of states.
Molecular
dynamics
method Simulation
method for interacting many-body systems
based on the numerical solution of Newton’s
equations of motion of classical mechanics.
Monte Carlo step Unit of (pseudo) time in
(dynamically interpreted) importance sam-
pling where, on the average, each degree of
freedom in the system gets one chance to be
changed (or “updated”).
Quantum
statistical
mechanics Statistical
mechanics relates the macroscopic properties
# Springer Science+Business Media, LLC, part of Springer Nature 2022
B. Chakraborty (ed.), Statistical and Nonlinear Physics,
https://doi.org/10.1007/978-1-0716-1454-9_337
Originally published in
R. A. Meyers (ed.), Encyclopedia of Complexity and Systems Science, # Springer Science+Business Media LLC 2017
https://doi.org/10.1007/978-3-642-27737-5_337-2
85

of matter to basic equations governing the
motion of the (many!) constituents matter is
built from. For quantum statistical mechanics,
this basic equation is the Schrödinger equation
for the many body wavefunction. If the eigen-
value spectrum of this equation could be
obtained, the canonical formalism of statistical
mechanics could be straightforwardly applied;
since normally this is not possible, one has to
use a reformulation of the Schroedinger equa-
tion in terms of path integrals.
Random number generator (RNG) Computer
subroutine to produce pseudorandom numbers
that are approximately uniformly distributed in
the interval from zero to unity. Approximately
the subsequently generated random numbers
are uncorrelated. RNG’s typically are deter-
ministic algorithms and strictly periodic, but
the period is large enough that for many appli-
cations this periodicity does not matter.
Simple sampling Monte Carlo method that
chooses states uniformly and at random from
the available space.
Thermodynamic variables Macroscopic pieces
of matter (solids, liquids, gases) in thermal
equilibrium can be characterized by a few
state variables, “extensive” thermodynamic
variables (proportional to the particle number,
such as energy, volume) and “intensive” ones
(independent of the particle number, such as
tempera-ture, pressure).
Transition probability Probability that controls
the move from one state to the next one in a
Markovian Monte Carlo process.
Definition of the Subject
Monte Carlo simulation in statistical physics uses
powerful computers to obtain information on the
collective behavior of systems of many interacting
particles, based on the general framework of clas-
sical or quantum statistical mechanics. Typically
these systems are too complex to allow for a reli-
able treatment (i.e. with errors that can be con-
trolled)
by
analytical
theory.
Monte
Carlo
simulation uses (pseudo)-random numbers gener-
ated also on the computer, and hence is suitable to
derive estimates of probability distributions and
averages derived from them. Such probability dis-
tributions (such as the so-called “canonical” distri-
bution characterizing the equilibrium state of
matter at a given temperature and volume) are the
basic objects of statistical thermodynamics. While
the latter ﬁeld of physics provides a convenient
formal framework, it does in most cases not yield
a convenient tool for explicit calculation, and such
an approach is provided by Monte Carlo simula-
tion. In fact, already the ﬁrst application of the
Metropolis importance sampling algorithm in
1953 addressed a problem of this kind, namely
the equation of state of hard disks. Since then
Monte Carlo simulation has become an extremely
useful and versatile tool of statistical physics, with
applications varying from many subﬁelds of phys-
ics (from condensed matter (i.e. liquids and solids)
to elementary particles) to neighboring ﬁelds
(physical chemistry, theoretical biology, stochastic
modeling of complex phenomena in society such
as trafﬁc ﬂows, stock market ﬂuctuations, etc.),
where methodologies “borrowed” from physics
are increasingly applied.
Introduction
One important problem of statistical physics is the
explanation of the macroscopic properties of
solids, liquids and gases in terms of the atomistic
description: 1 cm3 of a solid contains about
N=1022 atoms, which in turn are composed of
electrons and nuclei. The basic interactions keep-
ing the atoms together are the Coulomb forces
between particles of opposite electrical charge,
and these Coulomb forces are also responsible
for effective forces acting between atoms as a
whole. In the present article, we are not concerned
with the quantum-mechanical problem of pre-
dicting these forces, but rather assume them to
be known, and deal only with the many-body
problem of interacting atoms in the framework
of classical statistical mechanics. Macroscopic
properties (e.g., the density r of a ﬂuid, the mag-
netization density m of a ferromagnet, etc.) will be
denoted as “observables” A(X) which depend on
the degrees of freedom of the N particles (these
86
Monte Carlo Simulations in Statistical Physics

degrees of freedom are formally denoted as a
vector x, which encompasses the conﬁgurational
“phase space” of the system). Statistical thermo-
dynamics then shows that in a thermal equilibrium
state that is characterized by parameters such as
temperature T, pressure p etc., averages 〈A〉are to
be computed as
A
h i ¼
ð
dXPeq X
ð ÞA X
ð Þ,
(1)
where Peq(X) the probability that in equilibrium the
“microstate” (=point in phase space) X occurs.
E.g., when the equilibrium of a system is charac-
terized by given volume Vand given T, then Peq(X)
is described by the socalled “canonic distribution”
Peq X
ð Þ ¼ 1=ZN
ð
Þexp H X
ð Þ=kBT
½
,
(2)
where
ZN ¼
Ð
dX exp H X
ð Þ=kBT
½

is called
“partition function,” kB is Boltzmann’s constant,
and the “Hamiltonian” H X
ð Þ describes the inter-
action energies among the particles (and possible
contributions to the energy due to external ﬁelds).
For N particles in d-dimensional space Eq. (1)
would involve a dN-dimensional integral, and in
general the task posed by Eqs. (1) and (2) cannot
be carried out analytically. Only when the parti-
cles do not interact (i.e., an ideal gas, or related
problems such as a harmonic solid where one can
reduce the problem to an ideal gas of “phonons”
describing the lattice vibrations, etc.), is the prob-
lem easily tractable, since the multidimensional
integration factorizes. In the case of interactions,
analytically soluble problems are extremely rare.
E.g., the famous Ising model of ferromagnetism
H ¼ 
X
i6¼j
Ji jSiSj  H
X
i
Si,
S1 ¼ 1,
(3)
where the ﬁrst term on the right hand side
describes the exchange interaction between spins
at lattice sites i j of a crystal lattice, while the
second term describes the energy due to an exter-
nal magnetic ﬁeld, can be solved (in the case of the
interaction Jij being nonzero only for nearest
neighbor pairs on the lattice) in d = 1, but there
the system stays paramagnetic at all temperatures.
In d = 2 dimensions and H = 0, one also can
solve the problem, though this requires very
tedious and subtle mathematics, but no solution
is known in either d = 2 or d = 3 for any more
complicated cases (H 6¼ 0 , Jij nonzero for next
nearest or even more distant neighbors; etc.). An
approximate solution, where the pairwise interac-
tion is reduced to a coupling to an effective mean
ﬁeld (one puts Si;Sj  Si;〈Sj〉+ 〈Si〉Sj  〈Si〉
〈Sj〉would reduce the problem to an effective
single-particle problem, similar to the problem of
the ideal paramagnet (for which ZN ¼ ZN
1 ). How-
ever, comparison with the exactly known cases in
d = 1 and d = 2 shows that this mean ﬁeld
approximation is unsatisfactory, the obtained
results may be even qualitatively wrong (such as
the prediction of ferromagnetism for d = 1), and
uncontrollable errors occur. In almost all cases of
the statistical mechanics of many interacting
degrees of freedom, no analytical tools exist to
solve the problem either exactly or approximately
with
errors
that
can
always
be
controlled
(in particular near the phase transitions).
Monte Carlo simulation amounts to replacing
the integration in Eq. (1) by a summation over a
representative statistical sample of M points {Xv}
that is suitably chosen (what this actually means,
will be discussed in the next section). The choice
of this sample requires random numbers, which
are produced on the computer via a pseudoran-
dom number generator (RNG). These random
numbers must be uniformly distributed between
zero and unity, and should be uncorrelated. Actu-
ally, all random numbers due to RNG’s exhibit
some residual correlations, which may cause erro-
neous results in Monte Carlo simulations, and
hence devising “good” RNG’s is a matter of
longstanding concern (e.g., (James 1990; Knuth
1969; Mascagni and Srinivasan 2000)). Of course,
due to the ﬁniteness of M there occurs the
so-called “statistical errors” (as a matter of fact,
for some algorithms statistical and systematic
errors are not easy to disentangle, see Landau
and Binder 2005); but by making M bigger and
bigger, these errors can be made smaller and
smaller, and hence controlled, and techniques
exist to estimate these errors reliably (Berg 2004).
Monte Carlo Simulations in Statistical Physics
87

Of course, the application outlined above
refers only to a subset of problems in statistical
physics, but many other problems can be reduced
to it. E.g., the problem of computing averages in
quantum statistical mechanics can be reduced to
Eqs. (1 and 2) by path-integral Monte Carlo
(PIMC) methods (Ceperley 1996; Landau and
Binder 2005; Suzuki 1982). In this method, the
quantum character of particles enters, on the one
hand, by replacing each quantum particle by a
chain of classical particles (the coordinate along
the chain is the “imaginary time” coordinate of the
path integral formalism).
While in this way the delocalization of quan-
tum particles at low temperatures (note that
Heisenberg’s uncertainty principle forbids to
specify both the spatial coordinates and the
momentum of a quantum particle precisely) is
elegantly taken into account, the statistics of the
particles (for fermions the wave functions need to
be strictly antisymmetric with respect to the inter-
change of coordinates for any pair of particles) is
still a challenge for such quantum Monte Carlo
methods (Ceperley 1996).
Also seemingly unrelated problems, such as
the theory of elementary particles which is a
ﬁeld theory of matter ﬁelds on the femtometer
scale and of gauge ﬁelds respecting the basic
symmetry principles of relativistic quantum ﬁeld
theory, can be cast into a form closely related to
Eqs. (1) and (2). The generating functional
Z ¼
ð
D AD cD cexp Sg A,c, c




(4)
formally corresponds to the partition function in
statistical mechanics. Equation (4) involves func-
tional integration over the gauge ﬁelds (here
A stands symbolically for the vector potential of
electrodynamics in the four-dimensional contin-
uum, 3 space + 1 time dimensions) and over the
fermionic matter ﬁeld (described symbolically by
c and c). The action Sg of the theory contains a
coupling constant g which is related to inverse
temperature, when one invokes the analogy to
statistical mechanics. In fact, to remove ultraviolet
divergences that would otherwise plague this
quantum
ﬁeld
theory
one
replaces
the
fourdimensional continuum by a lattice and
hence the theory is called “lattice gauge theory”
(Montvay and Münster 1994). Monte Carlo sim-
ulations based on this formalism promise to
become a powerful approach to unravel the prop-
erties of hadrons and other elementary particles,
beyond the regime of parameters where analytical
theories based on systematic expansions in terms
of small parameters (“perturbation theory”) work.
While both in the case of Eqs. (2) and (4) the
explicit probability distribution of the interacting
many-particle system needs to be constructed
itself in the course of the Monte Carlo sampling,
via Importance Sampling methods (as will be
described in the next section), there exist also
simpler cases where a generation of “microstates”
of the N-particle system is straightforward, but the
analysis of the properties of these microstates is
difﬁcult and hence requires large scale simulation.
As an example, we mention the “percolation prob-
lem” (Stauffer and Aharony 1994). Suppose a
ferromagnet, described by Eq. (3), is randomly
diluted with non-magnetic atoms, such that a lat-
tice site i carries a spin Si with probability p and
no spin with probability 1  p ,
Jij being non-
zero only between nearest neighbor pairs of spins.
Then a ferromagnetic ground state of the lattice is
only possible if p exceeds the “percolation thresh-
old” pc, where for the ﬁrst time an inﬁnite “perco-
lating cluster” of magnetic atoms connected by
“bonds” Jij and extending throughout the whole
lattice occurs. Choosing random numbers  uni-
formly distributed between zero and unity, a cho-
sen site is taken by a magnetic atom if  < p and
otherwise it is taken by a nonmagnetic atom. All
lattice sites are occupied independently of each
other and all conﬁgurations of the lattice gener-
ated in this way have equal a priori probability.
While the generation of a sample of states by such
a “simple random sampling” strategy hence is
straightforward, the analysis of the (fractal) per-
colation clusters near the percolation threshold is a
difﬁcult task. Note that many other problems
where simple sampling sufﬁces exist (e.g. gener-
ation of random walks on lattices, a problem aris-
ing
in
the
context
of
simulating
ﬂexible
macromolecules, or of diffusion processes). How-
ever, we shall not dwell on simple sampling
88
Monte Carlo Simulations in Statistical Physics

further but rather refer to the literature (Binder and
Heermann 2002; Landau and Binder 2005).
The Metropolis Importance Sampling
Algorithm as a Tool in Classical
Equilibrium Statistical Mechanics
If we would choose microstates X of a many-body
system according to a simple sampling strategy to
sample Eq. (2), we would fail to get useful results,
except for very small values of N. In fact, the
probability distribution Peq(X) has a very sharp
peak in phase space where all extensive variables
(extensive variables are proportional to N for
N ! 1) A(X) are close to their average values
〈A〉. This peak may be approximated by a Gauss-
ian centered at 〈A〉, with a relative half-width of
order
1=
ﬃﬃﬃﬃ
N
p
. Hence, for a practically useful
method, one should not sample the phase space
uniformly, but the points Xv over which the sam-
pling is extended must be chosen preferentially
from the important region of phase space, i.e., the
vicinity of the peak of this probability distribution.
This goal is achieved by the importance sampling
method (Metropolis et al. 1953): One generates a
Markov chain of M conﬁgurations Xv, in terms of
a Markovian transition probability W Xv ! X0
v


that rules the “Monte Carlo moves” from an old
state Xv to a new state Xv
0. Starting from some
(arbitrary) initial state X1 one creates a “random
walk through phase space,” choosing W such that
in the limit of M ! 1 a point Xv, is chosen with a
probability proportional to Peq(X), and hence the
average in Eq. (1) is approximated by a simple
arithmetic average,
A ¼ M  M0
ð
Þ1
X
M
v¼M0þ1
A Xv
ð
Þ
(5)
Here it is anticipated that in practice it is better
to eliminate the residual inﬂuence of the initial
state X1 by eliminating the ﬁrst M0  1 states
from the average. A condition sufﬁcient to ensure
that the points Xv are actually chosen proportional
to the desired probability Peq(Xv) is known as the
detailed balance principle,
Peq X
ð ÞW X ! X0
ð
Þ ¼ Peq X0
ð
ÞW X0 ! X
ð
Þ:
(6)
Detailed considerations of how the Monte
Carlo moves X ! X0 need to be chosen and why
the Monte Carlo method actually converges to
Eq. (2) can be found in the literature (Binder and
Heermann 2002; Frenkel and Smit 2002). Here
we only emphasize that one major disadvantage of
this method is that knowledge on the normaliza-
tion factor of Peq(X), the partition function
Z (Eq. (2)), is lost. This is unfortunate, since
from Z one could obtain the free energy F via
F = kBT ln Z, as well as the entropy. Finding
ways of obtaining F via alternative sampling algo-
rithms, that yield directly information on the
energy density of states, is an active area of
research (see “Bibliography” and Landau and
Binder (2005)).
It needs also to be pointed out that this Metrop-
olis method can be used for sampling any distri-
bution P(X): one simply has to choose a transition
probability W(X ! X0) that satisﬁes a detailed
balance condition with P(X) rather than Peq(X)
as given in Eq. (2).
We continue by giving some comments on the
practical implementation of Monte Carlo algo-
rithms. One obvious question is, what is meant
in practice by the transition X ! X0. However,
there is no general answer to this question:
the choice of the move may depend both on the
model under consideration and the simulation
purpose. Since Eqs. (2) and (6) imply that
W X ! X0
ð
Þ=W X0 ! X
ð
Þ ¼ exp dH=kBT
ð
Þ, dH
being the energy change caused by the move from
X to X0, typically it is necessary to carry out small
changes dX = X0  X only. This is achieved in
practice by moving only one (or a few) degrees of
freedom at a time. Only in rare cases (“cluster
algorithms” for Ising models, “pivot algorithm”
for self-avoiding walks, etc.) is it possible to ﬁnd
algorithms involving a large dX. It is also useful to
realize that often W(X ! X0) can be written as a
product of an “attempt frequency” times an
“acceptance rate.” By clever choice of the attempt
frequency it is sometimes possible to attempt
larger moves and still have a high acceptance
and thus make the computations more efﬁcient.
Monte Carlo Simulations in Statistical Physics
89

The types of Monte Carlo moves can also be
adjusted to the choice of statistical ensemble that
one wishes to realize. E.g., for a grandcanonical
ensemble the chemical potential m (in addition to
volume V and temperature T) is a given variable.
Suitable moves then include particle insertions
and deletions, i.e., the particle number N in the
simulation box ﬂuctuates, as well as the pressure
p (which can be sampled e.g. using the virial
theorem). Conversely, choosing the NpT ensem-
ble one must include moves where the volume
V of the system changes, V ! V0 = V  DV.
Also the chemical potential then ﬂuctuates (and
can be sampled using the Widom particle insertion
method). For details on all these aspects, we refer
to more detailed textbooks (Frenkel and Smit
2002; Landau and Binder 2005).
Another arbitrariness concerns the order in
which particles are selected for considering a
move. E.g., simulating a lattice model one may
go through the lattice in a typewriter fashion.
Sometimes it is advisable to use sublattices,
e.g. the “checker board algorithm” where white
and black sublattices are updated alternatively to
allow an efﬁcient “vectorization” of the code.
However, if the simulation purpose is to extract
dynamic information (invoking the interpretation
of the Markov chain in terms of a master equation
as will be discussed below), it is better to choose
lattice sites (or particle labels, respectively) at
random.
We brieﬂy mention the practical realization of
the algorithm, choosing the Ising model (Eq. (3))
as a simple example. Then the move X ! X0
simply may be a single spin ﬂip {Si ! Si},
for instance. The transition probability can be
chosen as
W X ! X0
ð
Þ ¼
exp

dH=kBT〉if dH > 0
1
otherwise:

(7)
One compares W for this trial move with a
random number , uniformly distributed in the
interval 0 <  < 1; if W < , the trial move is
rejected and the old state is counted once more in
the average. Then another trial is made. If W > ,
on the other hand, the trial move is accepted, and
the new conﬁguration thus generated is taken into
account in the average, and serves as a starting
point for the next step.
Since successive states Xv in this process differ
only very little, e.g. by a single spin ﬂip in the case
of the Ising model, they are highly correlated.
Therefore, it is not straightforward to estimate
the error of the average. Let us assume that only
every nth step is included in the average, and that
after n steps these correlations have completely
died out. Then the standard estimate for the statis-
tical error
dA
ð
Þ2 of A ¼
~M
1

	 P Ak with ~M
¼ M  M0
ð
Þ=n, Ak ¼ A Xv
ð
Þ
with
v = kn,
applies
dA
ð
Þ2 ¼
~M ~M 1



1 X
~M
k¼1
Ak A

2,
~M  1:
(8)
However, the judgment when correlations
have died out is subtle (see next section), and
great care is needed to derive reliable error esti-
mates (Berg 2004).
The Dynamic Interpretation of Monte
Carlo Simulation and Application to
Study Dynamic Processes
Often it is useful to associate a time variable t to
the index v of successively generated states and to
discuss the probability P(X, t) that a state X occurs
at time t. This probability evolves according to the
following master equation
d
dt P X, t
ð
Þ ¼ 
X
X0
W X ! X0
ð
ÞP X, t
ð
Þ
þ
X
X0
W X0 ! X
ð
ÞP X0, t
ð
Þ:
(9)
Obviously the probability P(X, t) decreases due
to all processes that lead away from the considered
state X (ﬁrst sum on the right hand side of Eq. (9)),
while it increases due to all processes that lead to
the considered state from other states X0 (second
sum on the right hand side of Eq. (9)). Thus, Monte
Carlo sampling (i.e., the sequence of generated
90
Monte Carlo Simulations in Statistical Physics

states X1 ! X2 !    ! Xv ! Xv + 1 !   )
can be interpreted as a numerical realization of a
stochastic time evolution described by the master
equation, Eq. (9).
Of course, the units of the “time” in Eq. (9) are
not in an obvious way related to the units of
physical time (as it appears in the Newtonian
equation of motion or in the Schrödinger equa-
tion, respectively). Thus, it is common practice to
normalize the “Monte Carlo time unit” such that
in a system with N particles one attempts N single
particle moves per unit time. This is called “one
Monte Carlo step (MCS).”
For the thermal equilibrium distribution
P(X, t) = Peq(X), Eq. (2) there is no change
of probability with time according to Eq. (9),
since the right hand side of Eq. (9) vanishes
because
of
the
detailed
balance
principle,
Eq. (6). Thus, thermal equilibrium arises as the
stationary solution of the master equation. Mar-
kov processes for which Eq. (9) holds involve a
relaxation toward thermal equilibrium.
The time evolution of a physical system
(whose trajectory through phase space, according
to classical statistical mechanics follows from
Newton’s equations of motion) in general will
differ from the time evolution that follows from
Eq. (9), a stochastic rather than deterministic tra-
jectory through phase space. For example, Eq. (9)
never describes any propagating modes such as
sound waves in a ﬂuid, phonons in a crystal, etc.
Nevertheless, often the trajectory described
by Eq. (9) does have physical signiﬁcance: this
is because often one does not wish to describe
the full set of dynamical variables of a system,
but rather a subset only: for instance, in a solid
where diffusion occurs via hopping of atoms
over energy barriers to the vacant lattice sites,
the mean time between successive hops is
orders of magnitude larger than the time scale
of atomic vibrations. The latter can be well
approximated as a heat bath, as far as diffusion
is concerned, and – at least in principle – the
transition probability in Eq. (9) describing such
a hopping process in a solid can be estimated
either by Molecular Dynamics methods or by
approximate analytic methods such as transition
state theory.
There are many examples where such a sepa-
ration of time scales for different degrees of free-
dom occurs. As a rule of thumb, any slow
relaxation
phenomena
may
be
modeled
by
Monte Carlo: kinetics of nucleation, spinodal
decomposition in alloys, growth of ordered
domains in superstructure solids or in adsorbed
mono-layers on surfaces, kinetic growth of rough
interfaces, etc. Of course, one must pay attention
to build in the relevant conservation laws into the
model properly (e.g., in a binary metallic alloy the
number of atoms of both species A,B is con-
served, while the number of vacancies and inter-
stitials may not be conserved). Often (such as in
surface diffusion processes) it is not a priori obvi-
ous what are the elementary steps that one needs
to include into such a “kinetic Monte Carlo”
study, and for a realistic description of their rates
extensive electronic structure calculations may be
needed, in order to be able to connect the Monte
Carlo time unit to physical time.
There are also some cases where a Monte Carlo
description is a borderline case, as far as the faith-
ful
modeling
of
relaxation
phenomena
is
concerned. E.g., macromolecules in polymer
melts
undergo
Brownian
motion
(described
approximately by analytic models such as Rouse
or reptation models, respectively). In such a case,
the heat bath for the slow conformational transitions
of the polymer is provided by the fast bond-length
and bond angle vibrations. However, a Monte Carlo
description is not useful for the modeling of poly-
mer melts under ﬂow (Binder 1995). Even if one is
not interested in any dynamic properties of the
model that is simulated by Monte Carlo, one should
be aware of important consequences of Eq. (9).
Since Eq. (9) implies that the arithmetic average
Eq. (5) has the meaning of a time average
tM ¼ M=N, tM0 ¼ M0=N, A Xv
ð
Þ  A tð Þ
ð
Þ
A ¼ tM  tM0
ð
Þ1
ðtM
tM0
A tð Þdt,
(10)
“ergodicity” is a problem here, as it is for
Molecular Dynamics simulations. By “ergodic-
ity” it is meant that time averages and ensemble
averages agree, in the limit of large enough
Monte Carlo Simulations in Statistical Physics
91

time intervals tM  tM0 . However, near a ﬁrst
order transition where (in the thermodynamic
limit N ! 1) several phases may coexist, each
of these phases plays the role of a separate
“ergodic component” from which a trajectory
never escapes to another ergodic component.
A consequence of this problem is the observa-
tion of hysteresis. Sometimes the considered
Monte Carlo moves do not even allow one in
principle to reach all the states Xv (a well-
known example includes algorithms with local
moves for self-avoiding walks on lattices, see
Binder (1995)). Also problems occur where the
system develops a “rugged free energy land-
scape,” e.g., spin glasses (Binder and Young
1986), where a spectrum of relaxation times
develops that spans many decades of time.
Similar
as
in
experiments,
one
then
may
observe phenomena such as “aging” in a
Monte Carlo simulation, and it is difﬁcult to
judge whether or not thermal equilibrium has
been reached.
Time-displaced correlation functions 〈A(t)
B(0)〉described by Eq. (9) are then estimated as
A tð ÞB 0
ð Þ ¼
tM ttM0
ð
Þ1
ð
tM1
tM0
A tþt0
ð
ÞB t0
ð Þ 	dt0:
(11)
Apart from its interest for the study of
dynamical properties of the considered models,
Eq. (11) is useful to interpret the error due to
the correlation between subsequently generated
conﬁgurations. When we do not assume that
subsequent A0
ks in Eq. (8) are uncorrelated, we
rather obtain
dA
ð
Þ2
D
E
¼
1
~M
X
b
M
k¼1
Ak  A
h i
ð
Þ
2
4
3
5
2
*
+
¼ 1
bM
A2


 A
h i2 þ2
X
b
M
k¼1
1 k
~M


A0Ak
h
i A
h i2
h
i
8
<
:
9
=
;:
(12)
Now we remember that a time t = kdt = k(n/N)
is associated with the kth state, and transform the
sum in Eq. (12) to a time integral
dA
ð
Þ2
D
E
¼
1
c
M
A2


 A
h i2
h
i
	
1 þ 2
dt
ðt ~M
0
1  t=t ~M

	
fAA tð Þdt
8
>
<
>
:
9
>
=
>
;
,
(13)
where a relaxation function fAA has been
introduced,
fAA tð Þ ¼
A 0
ð ÞA tð Þ
h
i  A
h i2
h
i
=
A2


 A
h i2
h
i
:
(14)
Deﬁning a relaxation time
tAA ¼
ð1
0
fAA tð Þdt
(15)
one ﬁnds for tAA 
 ~Mdt ¼ tobs, the “observation
time” of the system during the course of the sim-
ulation, that
dA
ð
Þ2
D
E
¼ 1
c
M
A2


 A
h i2
h
i
1 þ 2tAA=dt
ð
Þ
 2 tAA=tobs
ð
Þ
A2


 A
h i2
h
i
,
(16)
where in the last step we have assumed tAA  dt.
Comparing to Eq. (8), we see that the error is
enhanced by a “dynamic factor” 1 + 2tAA/dt (or,
equivalently, one has to choose dt so large that ~M
¼ tobs=tAA, to avoid correlations between subse-
quent states). Near critical points of second-order
phase transitions, tAA diverges (“critical slowing
down,” see Hohenberg and Halperin (1977) for a
detailed discussion).
For a discussion of nonlinear relaxation pro-
cesses, it is useful to consider the evolution of
averages 〈A(t)〉,
A tð Þ
h
i ¼
X
X
P X, t
ð
ÞA X
ð Þ
¼
X
X
P X, 0
ð
ÞA X tð Þ
ð
Þ:
(17)
Here we used the interpretation that the ensemble
average involved is an average over an ensemble of
92
Monte Carlo Simulations in Statistical Physics

initial states (weighted by P(X, 0)), which evolve
according to Eq. (9). In practice, Eq. (17) means an
averageover alargenumber nrun  1of statistically
independent runs,
A tð Þ


av ¼ nl
run
Pnrun
‘¼1 A t, ‘
ð
Þ,
where A(t, ‘) is the observable A recorded at time
t in the lth run. Then nonlinear relaxation functions
fn‘
A tð Þ and relaxation times t n‘
ð
Þ
A
are deﬁned as
f n‘
ð
Þ
A
tð Þ ¼
A tð Þ
h
i  A 1
ð
Þ
h
i
½

	= A 0
ð Þ
h
i  A 1
ð
Þ
h
i
½
,
(18)
t n‘
ð
Þ
A
¼
ð1
0
f n‘
ð
Þ
A
tð Þdt:
(19)
Note that the condition that enough states M0 at
the beginning of the Monte Carlo sampling were
omitted to eliminate the possible inﬂuence of the
starting state X1, reads tM0  tðn‘〉
A
Again, how-
ever, care is needed when one studies second-
order phase transitions: then nonlinear relaxation
functions may exhibit power law behavior rather
than exponential decay to equilibrium. E.g., for an
Ising model in thermal equilibrium we have
(Landau and Binder 2005) for the magnetization
m(t) and susceptibility w(t) [assuming one starts
from a perfectly aligned state at Tc, and N ! 1]
m tð Þ / tb=zv,
w tð Þ / tg=zv,
t ! 1,
(20)
where b,
g are the critical exponents of the order
parameter and susceptibility in thermal equilib-
rium (assuming a d-dimensional lattice of size
L for L ! 1)
j mj
h
i / 1  t=Tc
ð
Þb, w
 Ld
m2


 j mj
h
i2
h
i
/ 1  T=Tc
j
jg,
(21)
while v and z are the critical exponents of the
correlation length x and the relaxation time tmm,
x / 1  T=Tc
j
jv,
tmm / xz:
(22)
Also the nonlinear relaxation time diverges
tðn‘〉
m
/ xzb=v
n
o
. In fact, testing for Eq. (20) is a
possible approach to study critical phenomena by
Monte Carlo methods, avoiding the need to equil-
ibrate the system (“nonequilibrium relaxation
method”). However, this approach requires the
use of very large systems, since all critical diver-
gences considered in Eqs. (21) and (22) are
rounded off when the correlation length x(t)
(which grows as x(t) / t1/z, see Sadiq and Binder
1984) has grown to a value comparable to L. Such
ﬁnite size effects are also important to consider in
the context of equilibrium Monte Carlo studies, as
will be discussed in the next section. Note also
that power law growth of ﬂuctuations also occurs
for T < Tc, when we start an Ising model in a
disordered spin conﬁguration, domains grow
according to a relation ‘(t) / t1/2 for their linear
dimension and (Sadiq and Binder 1984)
w tð Þ / td=2:
(23)
Then
equilibrium
is
reached
only
when
‘(t)  L, implying that t n‘
ð
Þ
m
/ L2. This consider-
ation shows that the choice of the initial state in
Monte Carlo sampling also should be done with
care: for T < Tc equilibrium is reached much
faster if we start from a well-ordered initial state,
of course.
Overcoming the Limitations of Finite Size
While systematic analytic expansions or closed-
form approximations often are useful for systems
away from phase boundaries where ﬁrst- or second-
order phase transitions occur, such methods often
are of doubtful value near phase transitions. Thus,
the study of phase transitions is one of the most
important ﬁelds where Monte Carlo simulations are
useful and important. However, sharp phase transi-
tions occur in the thermodynamic limit only,
N ! 1. Of course, this is no problem for real
systems: even a small water droplet freezing into a
snowﬂake may still contain N=1018 water mole-
cules, and thus the relative shift and rounding of
the transition are of order N1/3=106 and
N1/2=109, respectively. But the situation is dif-
ferent for simulations, where an economical use of
computer resources requires to study rather small
systems (of order N=102 to N=106 are typical), and
hence ﬁnite size effects need careful consideration
(Binder and Heermann 2002).
Monte Carlo Simulations in Statistical Physics
93

It turns out, however, that these ﬁnite size
effects are not just only a limitation, but also a
valuable tool to infer properties of the inﬁnite sys-
tem from the ﬁnite size behavior. As an example,
we discuss the phase transition of the Ising ferro-
magnet (Fig. 1), which has a second-or- der transi-
tion at a critical temperature Tc, with critical
behavior as characterized by Eqs. (21) and (22).
In a ﬁnite system, of course, x cannot exceed L, and
hence these critical singularities are smeared out.
Now ﬁnite size scaling theory (Fisher 1971;
Privman 1990) implies that such ﬁnite size effects
can be understood from the principle that “L scales
with x.” Hence it is plausible that the magnetization
probability PL(m) can be written (Binder 1981)
PL m
ð Þ ¼ Lx ~P L=x, mLx
ð
Þ,
x ¼ b=v:
(24)
Here
PL(m)
satisﬁes
the
normalization
Ð
dmPL m
ð Þ ¼ 1, ~P is a scaling function, and the
result x = b/v follows from the fact that
j mj
h
i ¼ Lx ~m L=x
ð
Þ ¼ Lb=v ~m L=x
ð
Þ
(25)
for L ! 1 must reduce to 〈| m| 〉/ xb/v This is
only possible when ~mðz ! 1〉/ zx to cancel the
power of L and when x = b/v. Since similarly
m
j jk
D
E
¼ Lkb ~mkðL=x〉, one derives a similar
scaling relation for the susceptibility,
kBTw  Ld
m2


 j mj
h
i2

	
¼ Lg=vew L=x
ð
Þ,
(26)
where the hyperscaling relation g/v = d  2b/v
was invoked, and ew z
ð Þ  ~m2  ~m2 The fourth
order cumulant UL is a function of L/x only,
UL ¼ 1  m4


= 3 m2

2
h
i
¼ ~U L=x
ð
Þ:
(27)
For T > Tc and large L the distribution PL(m)
tends to a gaussian and hence UL ! 0; for the
double-gaussian distribution for T < Tc, however,
UL ! 2/3. For T = Tc ﬁnite size scaling implies
UL ¼ ~U 0
ð Þ, independent of L. As a consequence,
when one studies UL as a function of temperature
for different choices of L one should ﬁnd Tc from a
common intersection point. This “cumulant inter-
section method” has become a very widespread
and useful tool for the study of critical phenomena
(Binder and Heermann 2002).
Also the analysis of PL(m  0) for T < Tc is
very useful (Binder 1982). The state of the system
then is dominated by a twophase conﬁguration,
i.e. (because of periodic boundary conditions) a
slab-like domain with negative magnetization is
separated from a domain with positive magnetiza-
tion by two interfaces of area Ld1. As a conse-
quence, the deep minimum of PL(m  0) in Fig. 1
is described by
ln PL m  0
ð
Þ=PL m  Mspont




¼ 2Ld1f 1nt=kBT,
(28)
where Mspont characterizes the peak positions of
PL(m) for T < Tc, and fint is the interfacial free
energy (per unit area). As a consequence, one
can extract estimates for fint from an analysis of
PL(m  0) as well. This approach has also found
widespread applications for various systems
(including phase separation in simple ﬂuids and
ﬂuid mixtures and polymer solutions and blends,
colloid-polymer mixtures, etc.).
A simple discussion of ﬁnite size effects at
ﬁrst order transitions is similarly possible. The
phases coexisting at the ﬁrst-order transition are
again described by gaussians. In a ﬁnite system
these phases coexist not only right at the tran-
sition, but over a ﬁnite parameter region. The
relative weights of these states are given in
terms of the free energy differences of these
phases. From this phenomenological descrip-
tion, energy and order parameter distributions
and their moments can be derived. One ﬁnds
that the maximum of speciﬁc heat and suscep-
tibility
scale
proportional
to
the
volume,
i.e. kBTwmax / Ld (instead of Lg/v as at a
second-order transition, Eq. (26).
Extensions to Quantum Statistical
Mechanics
In quantum mechanics, an observable A(X) now is
represented by an quantum mechanical operator ^A,
and hence Eq. (1) is replaced by
94
Monte Carlo Simulations in Statistical Physics

^A

 
¼ Z1Trexp ^H=kBT

^A
¼ Z1 X
n
nj exp ^H=kBT


j n


,
(29)
where ^H is the Hamiltonian of the system, and the
states jn〉form a complete, orthonormal set. In
general, the eigenvalues Ea and eigenstates ja〉of
the Hamiltonian are not known Hj a〉¼ Eaj a〉
ð
Þ,
and we wish to evaluate the trace in Eq. (29)
without attempting to diagonalize the Hamilto-
nian. This can be achieved by path-integral
Monte Carlo (PIMC); other versions of quantum
Monte Carlo methods which focus on ﬁnding the
ground state and its energy are outside of
consideration here.
The basic idea of PIMC can already be
explained for the simple case of a single particle
in one dimension in a potential V(x). In position
representation, the Hamiltonian is
^H ¼  ℏ2
2m
d2
dx2 þ V x
ð Þ ¼ ^Ekin þ ^V,
(30)
where ℏis Planck’s constant. The problem is the
fact that the operators of kinetic energy ^Ekin and
potential energy ^V do not commute, ^Ekin,^V


6¼ 0.
If
^Ekin
and ^V
commuted, we could replace
exp  ^Ekin þ ^V


=kBT


by exp ^Ekin=kBT


exp
^V=kBT


, and by inserting the identity ^1 ¼
Ð
dx0
j x0〉〈x0 j we would have solved the problem, since
PL (M)
PL (M)
PL (M)
<IMI>
Mspont
 − Mspont
 + Mspont
L finite
=B(1-T/Tc)β
L
Ld (<m2>-<IMI>2)
0
M
TC
T
TC
TC
UL
T
T
2/3
0
l1-T/Tcl-?
0
0
M
T>Tc
T<Tc
T=Tc
KB Tχ/Ld
∞
L
L’>L
L
∞
L
∞
∞
L-β/ϒ
∞
Monte Carlo Simulations in Statistical Physics,
Fig. 1 Schematic evolution of the order parameter prob-
ability distribution PL(m) from T > Tc to T < Tc (from
above to below, left part), for an Ising ferromagnet
(where M is the magnetization per spin) in a cubic box of
volume V = Lds. The right part shows the corresponding
temperature dependence of the mean order parameter
〈| M| 〉, the susceptibility kBTw0 = Ld(〈M2〉 〈| M| 〉2),
and the reduced fourth-order cumulant UL = 1  〈M4〉/[3
〈M2〉2]. Dashdotted curves indicate the singular variation
that results in the thermodynamic limit, L ! 1
Monte Carlo Simulations in Statistical Physics
95

xj exp ^Ekin=kBT


j x0


amounts to dealing with
the (known) quantum mechanical propagator of a
free particle. However, by neglecting the non-
commutativity of ^Ekin and ^V we would have reduced
the problem back to the realm of classical mechan-
ics, all quantum effects would have been lost.
But, a related recipe is provided by the exact
Trotter product formula for two non-commuting
operators ^A and ^B, P being an integer,
exp ^A þ ^B


! exp ^A=P


exp ^B=P



P
for
P ! 1:
(31)
Using Eq. (31) the partition function can be
written as
Z ¼ lim
P!1
ð
dx1
ð
dx2
ð
dxp x1jexp ^Ekin=kBTP



exp ^V=kBTP


jx2

	〈x2 j  xpjexp ^Ekin=kBTP



exp ^V=kBTP


jx1
i:
(32)
Note the matrix elements can be worked out,
with the result (P ! 1)
Z ¼
mkBTP
2pℏ2

P=2 ð
dx1dxp
exp
 1
kBT
k
2
X
p
s¼1
xs xs1
ð
Þ2 þ 1
P
X
p
s¼1
V xs
ð Þ
"
#
(
)
,
(33)
with the boundary condition xp + 1 = x1 and the
effective
spring
constant
k = mP(kBT)2/ℏ2.
Equation (33) formally corresponds to a classical
partition function of a “ring polymer). will
P “monomers” Its gyration radius (which is of
order ℏ=
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
mkBT
p
, i.e. of the same order as the
thermal de Broglie wavelength lT ¼ h=
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
2pmkBT
p
of the quantum particle) represents the region over
which
the
quantum
particle
typically
is
delocalized at temperature T. If effects of quantum
statistics are ignored (which is admissible for
crystals at low T, apart from solid helium) the
generalization of this formalism (Eqs. (32) and
(33)) to N particles is straightforward. In fact,
useful applications to describe low temperature
properties of crystals beyond the harmonic
approximation have been given (Landau and
Binder 2005). Related approaches also based on
the Trotter formula can be developed for various
lattice problems, e.g. the Ising model on a
d-dimensional lattice in a transverse ﬁeld can be
reduced to an ordinary Ising problem (with no
transverse ﬁeld) on a (d + 1)-dimensional lattice,
but with anisotropic interactions (the extra lattice
direction corresponds to the “imaginary time”
coordinate s in Eq. (33) along the contour of the
ring polymer). But many problems of physical
interest, e.g. the Hubbard Hamiltonian describing
strongly correlated fermions on a lattice, cannot yet
be satisfactorily simulated by such Monte Carlo
methods at low enough temperatures because of
the “minus sign problem”: the distribution to be
sampled {r(x)} is not always positive, and hence
cannot be interpreted as a probability density suit-
able for importance sampling. The brute force rec-
ipe consists of splitting r(x) into its sign (S) and its
absolute value ( er ¼j r x
ð Þ j ), so that r ¼ Ser ,
and then the quantum average can be formally
rewritten as
A
h i ¼ AS
h
ier= S
h ier,
(34)
where   
h
ier means averaging with er as weight
function. However, this brute force approach
works only for rather small N, since the average
of the sign behaves as S
h ier / exp const: 	 N
ð
Þ.
Alleviating this problem is still an active area of
research.
Future Directions
There is still very active research going on to ﬁnd
more efﬁcient algorithms, by a clever design of
Monte Carlo moves adapted to speciﬁc problems,
by exploiting advanced computer architecture
(e.g. “parallel tempering” methods exploit parallel
architectures by running n real replicas of the sys-
tem at closely spaced neighboring temperatures or
other control parameters in parallel and exchanging
from time neighboring temperatures, to allow for a
faster relaxation of the system conﬁgurations), and
by techniques such as “multicanonical Monte
96
Monte Carlo Simulations in Statistical Physics

Carlo” (Berg 2004) or Wang-Landau sampling of
the energy density of states (Landau and Binder
2005) or related methods of so-called “umbrella
sampling.” The easy availability of powerful
desk-top computers has also facilitated the study
of rather complex model systems (unlike the early
days of Monte Carlo, where the research had to
focus on “toy problems” such as the Ising model,
the hard disk and hard sphere ﬂuids, the self-
avoiding walk problem, percolation, etc.). While
these classic problems still are useful as a testbed
for new methodologies of simulation the analysis
of simulation output, there is now much emphasis
on applications directed towards materials sci-
ences, soft and biological matter, and statistical
mechanics far from equilibrium. In this context,
also “multiscale simulation” methodology has
become a very active ﬁeld of research: e.g., elec-
tronic structure calculation on the subatomic scale
is required to yield realistic input for potentials that
can then be used for instance in kinetic Monte
Carlo simulations. Monte Carlo methods devel-
oped in the context of statistical physics are very
popular for applications clearly going beyond
physics, such as simulations of sociological and
economical processes (“econophysics”), biologi-
cally motivated models, etc. There also is a contin-
uous and fruitful exchange of know how with the
practitioners
of
other
simulation
techniques
(classical and “ab initio” Molecular Dynamics,
Lattice Boltzmann simulations of transport phe-
nomena), unlike in the past where the different
“communities” of simulators worked in a rather
disjunct manner.
Bibliography
Berg BA (2004) Markov chain Monte Carlo simulations and
their statistical analysis. World Scientiﬁc, Singapore
Binder K (1981) Critical properties from Monte Carlo
coarse graining and renormalization. Phys Rev Lett
47:693–696
Binder K (1982) The Monte Carlo calculation of the sur-
face tensions for two- and three-dimensional lattice
models. Phys Rev A 25:1699–1709
Binder K (ed) (1995) Monte Carlo and Molecular dynam-
ics simulations in polymer science. Oxford University
Press, New York
Binder K, Heermann DW (2002) Monte Carlo simulation
in statistical physics: an Introduction, 4th edn. Springer,
Berlin
Binder K, Young D (1986) Spin glasses: experimental
facts, theoretical concepts, and open questions. Rev
Mod Phys 58:801–976
Ceperley DM (1996) Path integral Monte Carlo methods
for fermions. In: Binder K, Ciccotti G (eds) Monte
Carlo and Molecular dynamics of condensed matter
systems.
Societa
Italiana
di
Fisica,
Bologna,
pp 445–482
Fisher ME (1971) The theory of critical point singularities
in critical phenomena. In: Green MS (ed) Proceedings
of the 1970 Enrico Fermi International School of Phys-
ics, vol 51. Academic, New York, pp 1–99
Frenkel D, Smit B (2002) Understanding molecular simu-
lation: from algorithms to applications, 2nd edn. Aca-
demic, San Diego
Hohenberg PC, Halperin BI (1977) Theory of dynamic
critical phenomena. Rev Mod Phys 49:435–479
James F (1990) A review of pseudorandom number gener-
ators. Comp Phys Commun 60:329–344
Knuth D (1969) The art of computer programming,
vol 2. Addison-Wesley, Reading
Landau DP, Binder K (2005) A guide to Monte Carlo
simulations in statistical physics, 2nd edn. Cambridge
University Press, Cambridge
Mascagni M, Srinivasan A (2000) Algorithm 806:
SPRNG:a scalable library for pseudorandom number
generation. ACM Trans Math Softw 26:436–461
Metropolis N, Rosenbluth AW, Rosenbluth MN, Teller
AM, Teller E (1953) Equation of state calculations by
fast computing machines. J Chem Phys 21:1087–1092
Montvay I, Münster G (1994) Quantum ﬁelds on the lat-
tice. Cambridge University Press, Cambridge
Privman V (ed) (1990) Finite size scaling and numerical
simulation of statistical systems. World Scientiﬁc,
Singapore
Sadiq A, Binder K (1984) Dynamics of the formation of
two dimensional ordered structures. J Stat Phys
35:517–585
Stauffer D, Aharony A (1994) Introduction to percolation
theory. Taylor and Francis, London
Suzuki M (ed) (1982) Quantum Monte Carlo methods
in
condensed
matter
physics.
World
Scientiﬁc,
Singapore
Monte Carlo Simulations in Statistical Physics
97

Nonlinear Fluid Flow, Pattern
Formation, Mixing, and
Turbulence
T. H. Solomon
Department of Physics and Astronomy, Bucknell
University, Lewisburg, PA, USA
Article Outline
Glossary
Deﬁnition
Introduction and Theoretical Background
Speciﬁc Examples of Patterns in Fluid Flows
Transport and Mixing
Manifolds, Lobes, and Transport Barriers
Pattern Formation in Reaction-Diffusion and
Advection-Reaction-Diffusion Systems
Burning Invariant Manifolds and Reaction Fronts
Other Examples of Pattern-Forming Systems
Future Directions
Bibliography
Glossary
Bifurcation A change from one kind of behavior
to another, e.g., a bifurcation from steady ﬂow
to time-periodic ﬂow
Defect A location where a pattern abruptly
changes, e.g., where a line ends or two lines
meet at a point
Deterministic chaos Erratic behavior arising
from a low-dimensional, deterministic system;
behavior that shows sensitive dependence on
initial conditions where a small error in initial
conditions grows roughly exponentially in time
Finite-time
Lyapunov
exponent
(FTLE)
ﬁeld A ﬁeld showing how much ﬂuid parcels
are stretched over a small interval of time
Free energy functional An effective energy that
depends on the function describing a pattern
Fully developed turbulence Turbulent ﬂow for
very large Reynolds number with no spatial or
temporal order
Grain boundary Line or curve in a pattern
where two different zones meet.
Kolmogorov-Arnold-Moser (KAM) invariant
surface Curve or surface that separates region
of ordered trajectories from region of chaotic
trajectories. Tracers cannot cross between these
two regions; consequently, a KAM invariant
surface acts as a transport barrier.
Lagrangian
coherent
structure
(LCS) A
region in a ﬂow where passive impurities
move mostly together, rather than being
stretched and mixed with the rest of the ﬂow
Laminar
ﬂow Smooth,
well-ordered
ﬂow,
achieved with small Reynolds number
Lévy ﬂights Trajectories characterized by jumps
between distant parts of the system. If it is a Lévy
ﬂight, the jumps in a trajectory have a probabil-
ity distribution P (L) ~ Lm, with 2 < m < 3.
Linear stability theory Approach used to deter-
mine critical parameters (e.g., Re or Ra) at
which a ﬂow becomes unstable. Linear stabil-
ity theory also determines the wavenumbers of
the disturbances that are unstable.
Lobe (or “turnstile”) Region bounded by the
intersection of stable and unstable manifolds.
Lobes provide the mechanism for transport of
impurities between different regions in a ﬂow.
Manifold (or “invariant manifold”) A collec-
tion of points in a ﬂow which, when evolved
forward in time, map on to the same collection
of points. Manifolds also act as barriers for
transport and front propagation.
Poincaré section A stroboscopic plot for a time-
periodic or ﬂow showing the positions of one
or more tracers once each period of the ﬂow
Rayleigh-Bénard
convection A
ﬂow
that
develops from an instability due to unstable
stratiﬁcation when a ﬂuid is heated from below
© Springer Science+Business Media, LLC, part of Springer Nature 2022
B. Chakraborty (ed.), Statistical and Nonlinear Physics,
https://doi.org/10.1007/978-1-0716-1454-9_362
Originally published in
R. A. Meyers (ed.), Encyclopedia of Complexity and Systems Science, © Springer Science+Business Media LLC 2020
https://doi.org/10.1007/978-3-642-27737-5_362-2
99

Rayleigh number Dimensionless parameter that
characterizes the magnitude of the temperature
difference in a Rayleigh-Bénard ﬂow. The Ray-
leigh number can also be thought of as a ratio of
thermal buoyancy to diffusive damping.
Reaction-diffusion system A spatially extended
system that produces patterns or fronts as a result
of the interaction between some sort of reaction
(e.g., chemical reaction, biological interaction,
phase transition) and molecular diffusion.
Reynolds number Dimensionless parameter that
characterizes the strength of a ﬂow. The Reyn-
olds number can also be thought of as the ratio
between ﬂuid inertia and viscous damping.
Stratiﬁcation Density variations in a ﬂuid system
Strong
turbulence High
Reynolds
number
turbulence
Subdiffusion Transport where the variance s2
grows more slowly than normal diffusion,
e.g., s2(t) ~ tg, with g < 1. Associated with
regions in the ﬂow where the tracers temporar-
ily stick.
Superdiffusion Transport where the variance s2
grows more rapidly than normal diffusion, e.g.,
s2(t) ~ tg, with g > 1. Associated with Lévy
ﬂight trajectories.
Taylor-Couette ﬂow Flow between two coaxial
cylinders, the inner of which (at least) is rotating
Weak
(defect-mediated)
turbulence Flows
with intermediate values of the Reynolds num-
ber that still produce short-range patterns but
evolve both spatially and temporally in a com-
plicated manner and can be characterized by
the presence of numerous defects in the pattern
(more defects for more turbulent ﬂows) that
move around the system.
Definition
“Nonlinear dynamics” is the study of systems
described by equations of motion that depend
nonlinearly on their variables. This is of signiﬁ-
cant scientiﬁc and mathematical interest because
nonlinear systems – unlike simpler linear ones –
typically
show
quite
complicated
behavior,
including deterministic chaos, spontaneous for-
mation of patterns, spatiotemporal complexity,
and turbulence. The equations describing ﬂuid
ﬂows are nonlinear; consequently, there is a
wide variety of types of ﬂows that can be
achieved, spanning a wide range of levels of com-
plexity from simple, well-ordered, laminar ﬂows
up through turbulent ﬂows with signiﬁcant com-
plexity both in space and time. The equations that
describe the mixing of impurities in a ﬂow are also
often nonlinear (depending on the ﬂuid ﬂow);
consequently, mixing can also be very compli-
cated and even chaotic.
Introduction and Theoretical
Background
The dynamics of a ﬂuid ﬂow are governed by the
Navier-Stokes equation:
@ u
!
@t þ u
!  ∇
!u
! ¼  1
r ∇
!p þ n∇2 u
! þ 1
r F
!:
This is the ﬂuid continuum version of Newton’s
second law. The ﬁrst term on the left represents the
change in a momentum of a small parcel of a ﬂuid.
Several factors can result in a change in momentum:
forces acting on the ﬂuid element – pressure differ-
ences, viscosity, and external forces (ﬁrst, second,
and third terms on the right) – and advection of
higher or lower velocity ﬂuid elements into the
region of interest (the second term on the left). The
Navier-Stokes equation can be nondimensionalized
by scaling the velocity by a characteristic velocity
scale U, lengths by a typical length scale L, and time
by an advective timescale L/U:
@ u
!
@t
0
þ u
!0  ∇
!0
u
!0 ¼ ∇
! Dp
ð
Þ0 þ 1
Re ∇02 u
!0
where we have neglected external forcing and
where u
!0  u=U is the nondimensional velocity.
The nondimensional parameter, Re ¼ UL/n, is the
Reynolds number. The Reynolds number charac-
terizes the ratio of inertia to viscosity in a ﬂuid ﬂow.
The advection term on the left is often referred
to as the inertial term and is the source of non-
linearity in the Navier-Stokes equation. Non-
linearity goes hand-in-hand with complexity;
100
Nonlinear Fluid Flow, Pattern Formation, Mixing, and Turbulence

consequently, the Reynolds number is the funda-
mental parameter used to describe the transition in
ﬂuid ﬂows from simple, laminar (smooth), well-
ordered ﬂows to more and more complicated
ﬂows. If Re << 1, the inertial term is negligible
and for steady ﬂows, viscosity at every location is
balanced by pressure gradients. In this limit, the
Navier-Stokes
equations
can
be
rewritten
(in dimensional form) as:
1
r ∇
!p ¼ n∇2 u
!
Flows in this limit are called viscous, creeping, or
Stokes ﬂows. If Re >> 1, viscosity is negligible,
and the NS Equation can be written as:
@ u
!
@t þ u
!  ∇
!u
! ¼  1
r ∇
!p
Flows in this limit are called inviscid or Euler
ﬂows and are dominated by inertial effects.
Flows with very large Re are typically turbulent.
There has been signiﬁcant research into the
transition between well-ordered, laminar, viscous
ﬂows for Re << 1 and fully developed turbulent
ﬂows for Re >> 1. Landau (1944) predicted that
an increase in Re would be accompanied by an
inﬁnite series of bifurcations as more and more
frequencies of ﬂuid oscillation (and corresponding
spatial
complexity)
are
added
to
the
ﬂow.
According to Landau, measurement of the ﬂow
velocity at a point will reveal a steady, time-
independent signal for weak ﬂows (low Re), then
for stronger ﬂows, the velocity will oscillate peri-
odically at that point, then at higher Re, the velocity
time series at that point will be a superposition of
two periodic oscillations with different frequencies.
As Re increases, the velocity time series will be a
superposition of more and more sinusoidal func-
tions
with
different
frequencies.
Ultimately,
according to Landau, a turbulent ﬂow is simply
one with so many superposed frequencies that it
seems complicated and unpredictable.
Landau’s prediction was tested in the early
1970s by Harry Swinney and Jerry Gollub in a
Taylor-Couette ﬂow (Gollub and Swinney 1975)
(see section “Taylor-Couette Flow” for more
detail about Taylor-Couette ﬂow). However, they
did not ﬁnd an inﬁnite sequence of transitions with
more and more frequencies (and more and more
complexity). Instead, they found a sudden transi-
tion from an ordered ﬂow with two superposed
frequencies directly to broad spectrum, aperiodic
time dependence, a state that we now know to be
chaotic. This direct transition in ﬂuid ﬂows to
chaotic time dependence was also predicted theo-
retically by Ruelle and Takens in 1971 (1971).
Deterministic chaos is denoted by two main
features: (1) complicated, aperiodic time depen-
dence from a simple, deterministic system with a
small number of degrees of freedom; and (2) sen-
sitive dependence on initial conditions, whereby
small uncertainties in measurements of the initial
conditions grow roughly exponentially in time,
destroying long-term predictability. Despite the
name, however, chaotic systems are usually
quite well-ordered spatially; it is the time depen-
dence that is complicated. Further increases in Re
are needed to break up the spatial patterns that
persist for chaotic ﬂows. A regime displaying
disorder in both space and time is referred to as
spatiotemporal chaos or weak turbulence. Weak
turbulent regimes are still characterized by well-
deﬁned structures (e.g., vortices), but the struc-
tures are arranged in a disordered pattern. These
structures break up if Re is increased beyond that
for the weak turbulent regime; ultimately, for large
enough Re, the ﬂow is described as fully devel-
oped turbulence with a broad spectrum of spatial
length scales. Long-lived vortex structures may
survive for surprisingly large Re, however, espe-
cially in planetary and atmospheric ﬂows in rotat-
ing systems (Marcus 1988) or in plasma ﬂows
with large uniform magnetic ﬁelds.
In this entry, we present several different exam-
ples of pattern formation, mixing, and chaos in
ﬂuid systems. Section “Speciﬁc Examples of Pat-
terns in Fluid Flows” presents speciﬁc examples
of the kinds of transitions discussed above in ﬂuid
ﬂows, showing the patterns that accompany these
transitions. We emphasize Taylor-Couette and
convective ﬂows, mainly due to their historical
importance in this ﬁeld. In section “Transport
and Mixing,” we discuss transport and mixing,
highlighting in particular the fact that ﬂuid mixing
in
laminar,
well-ordered
ﬂows
is
often
Nonlinear Fluid Flow, Pattern Formation, Mixing, and Turbulence
101

chaotic. Section “Manifolds, Lobes and Transport
Barriers” presents a discussion of manifold and
Lagrangian coherent structure theories that help
elucidate barriers that impede the mixing of pas-
sive impurities. In section “Pattern Formation in
Reaction-Diffusion
and
Advection-Reaction-
Diffusion Systems,” we discuss chemical pattern
formation and front propagation in both stagnant
and ﬂowing systems. Section “Burning Invariant
Manifolds and Reaction Fronts” presents an
extension of the manifold theory to advection-
reaction-diffusion systems, highlighting the one-
way barriers that impede the motion of reaction
fronts. Section “Other Examples of Pattern-
Forming Systems” contains a brief listing of
some other types of pattern-forming systems. We
ﬁnish in section “Future Directions” with a brief
overview of future directions in the ﬁeld.
Specific Examples of Patterns in Fluid
Flows
There are a number of different ﬂows whose spa-
tial patterns have been studied. Similar patterns
are found in a very wide range of ﬂows.
Taylor-Couette Flow
Taylor-Couette ﬂow is the ﬂow between two coax-
ial cylinders (Fig. 1a). In its simplest form, the
outer cylinder remains stationary while the inner
cylinder rotates. No-slip boundary conditions
require ﬂuid at the outer edge to remain stationary
while ﬂuid at the inner edge rotates with the inner
cylinder. The Reynolds number for this ﬂow is
deﬁned using the gap width L as the length scale
and the maximum ﬂow velocity U as the velocity
scale: Re ¼ UL/n. Taylor-Couette ﬂows are often
visualized with kalliroscope (Kalliroscope Corpo-
ration), a suspension of aluminum ﬂakes that align
with shear zones in the ﬂow. Reﬂection of light off
the ﬂakes depends on their orientation; conse-
quently, kalliroscope quite effectively visualizes
the ﬂow ﬁeld. This technique was originally devel-
oped by the artist Paul Matisse but has been
adopted by experimentalists who study ﬂuid
instabilities.
For small Re in the Taylor-Couette system,
ﬂow between the cylinders is laminar and purely
in the azimuthal direction, with the velocity mag-
nitude dropping smoothly from the inner cylinder
velocity to zero at the outer cylinder. Beyond a
critical Re, this smooth ﬂow becomes unstable
(a)
(b)
(c)
Nonlinear Fluid Flow, Pattern Formation, Mixing,
and Turbulence, Fig. 1 Taylor-Couette ﬂow. (a) Dia-
gram of conﬁguration. The ﬂuid is contained in the gap
between two coaxial cylinders, the inner of which (at least)
rotates, driving a ﬂow between the two cylinders. (b)
Cross-sectional sketch of Taylor-Couette vortices. (c)
Experimental image showing Taylor-Couette vortices;
ﬂow is visualized using kalliroscope. (From Fenstermacher
et al. 1979)
102
Nonlinear Fluid Flow, Pattern Formation, Mixing, and Turbulence

due to centrifugal effects – the faster moving ﬂuid
near the inner cylinder moves outward while the
slower moving ﬂuid near the outside moves
inward. The result is a pattern of stacked tori
(donut-shaped structures) called Taylor vortices
(Fenstermacher et al. 1979) (Fig. 1b and c).
A ﬂuid element within a Taylor vortex still
moves azimuthally around the cylinders but also
follows a closed (vortex) path in r-z coordinates.
A radial cross section of the ﬂow reveals a chain of
counter-rotating vortices.
Further increases in Re result in a bifurcation to
wavy vortex ﬂow (Andereck et al. 1986), where
the tori deﬁning the Taylor vortices develop a
snake-like undulation that propagates around the
annulus (Fig. 2a). This spatial pattern corresponds
to the time-periodic state discussed in transition to
chaos in section “Introduction and Theoretical
Background.” Further increases in Re result in
transitions to quasi-periodic and chaotic states.
Ultimately, for large enough Re, the ﬂow is turbu-
lent (Fig. 2e).
If the outer cylinder rotates as well, a wide
variety of spatial patterns are found (Andereck
et al. 1986, 1983). Some of these states are
shown in Fig. 2. Taylor-Couette ﬂows have been
studied extensively because of the wide variety of
different states, including states in which the ﬂow
experiences intermittent (momentary) bursts of
turbulence. Various investigators have mapped
Nonlinear Fluid Flow, Pattern Formation, Mixing,
and Turbulence, Fig. 2 Some examples of Taylor-
Couette patterns; all visualized with kalliroscope ﬂakes.
(a) Wavy vortex ﬂow (From Fenstermacher et al. 1979);
(b) Modulated wavy vortex ﬂow (From Andereck et al.
1986); (c) Braided vortex ﬂow (from Andereck et al.
1983); (d) Intermittent turbulent spots (From Andereck
et al. 1986); and (e) Turbulent ﬂow. (From Andereck
et al. 1986)
Nonlinear Fluid Flow, Pattern Formation, Mixing, and Turbulence
103

out parameter space diagrams that show the con-
ditions needed to obtain various different states in
Taylor-Couette ﬂow. An example of such a
parameter space diagram (Andereck et al. 1986)
is shown in Fig. 3.
Rayleigh-Bénard Convection
When a ﬂuid is heated from below or from the
side, the warmer ﬂuid near the bottom expands
and becomes less dense than the cooler ﬂuid
above. This results in unstable stratiﬁcation with
heavier, more dense ﬂuid above lighter, less dense
ﬂuid. If the stratiﬁcation is large enough, the
denser ﬂuid falls and the lighter ﬂuid rises, pro-
ducing a convective ﬂow. Thermal convection of
this nature is quite common: it occurs when
heating up water or soup on a stove; it is a dom-
inant mechanism by which a heating element
heats up the air in an oven or by which heat from
a radiator warms up a room; it is the dominant
mechanism by which atmospheric ﬂows are
driven; it is the mechanism by which ﬂows within
the Earth’s crust are formed; and it is a major
driving force for ﬂows in stars. In all cases, ther-
mal convection results in signiﬁcantly faster and
more efﬁcient transport of heat than would be
achieved solely with thermal diffusion.
In its simplest form, thermal convection
ensues if a large enough vertical temperature
gradient is applied with the bottom warmer than
the top (Fig. 4). The relevant dimensionless num-
ber characterizing the magnitude of the temper-
ature
difference
is
the
Rayleigh
Number.
Ra ¼ gaDT/nk, where DT ¼ Tbottom – Ttop is
the temperature gradient, a is the coefﬁcient
describing the volume expansion of the ﬂuid in
response to a change in temperature, g is the
gravitational acceleration, and k is the thermal
diffusivity. Conceptually, increases in the tem-
perature difference, gravitational acceleration, or
expansion coefﬁcient make the ﬂuid more unsta-
ble, whereas viscosity inhibits ﬂuid motion, and
thermal diffusivity tends to diminish temperature
differences.
2000
R1
1000
0
–4000
–3000
–2000
–1000
0
1000
Couette
flow
Taylor-
vortex
flow
Wavy
outflow
Twists
Wavy inflow
Wavy
inflow
+ twists
Wavy vortices
Ripple
Turbulent
Taylor
vortices
Unexplored
Featureless turbulence
Spiral turbulence
Corkscrew
Wavelets
Wavy
spirals
Spirals
Interpenetrating spirals
Intermittency
Modulated
waves
Modulated waves
Couette flow
Wavy
vortex
flow
R0
Nonlinear Fluid Flow, Pattern Formation, Mixing,
and Turbulence, Fig. 3 Parameter space diagram show-
ing the many different regimes of pattern formation for
Taylor-Couette ﬂow between two coaxial cylinders. (From
Andereck et al. 1986)
104
Nonlinear Fluid Flow, Pattern Formation, Mixing, and Turbulence

If Ra is small, the ﬂuid remains motionless –
viscosity and thermal diffusion are sufﬁcient to
keep the ﬂuid from becoming unstable. If Ra
exceed a critical value Rac, the motionless state
becomes unstable and the warmer, less dense ﬂuid
near the bottom rises while the cooler, more dense
ﬂuid near the top sinks. In a thin, rectangular box,
a pattern of convection rolls develops, with ﬂuid
circulating like rotating cigars in a box, as shown
schematically in Fig. 4.
Numerous studies have been made of patterns
made by Rayleigh-Bénard convection. In a man-
ner similar to that in Taylor-Couette ﬂow, there is
a series of bifurcations from well-ordered to cha-
otic and ultimately to turbulent ﬂow in Rayleigh-
Bénard convection. The nature of the transitions
depends not only on the Rayleigh number Ra but
also on a second dimensionless parameter called
the Prandtl number Pr ¼ n/k which denotes the
relative magnitudes of the viscous and thermal
diffusivities and is a property of the ﬂuid used in
the experiments. Large Prandtl numbers are
achieved in ﬂuids with large viscosities; even
water at room temperature has a Prandtl number
of around 6. Pressurized gases have Prandtl num-
bers of around 1. Small Prandtl numbers are
achieved in ﬂows of liquid metals (e.g., mercury
or sodium) that are very good thermal conductors
and ﬂows in gases which have a very small kine-
matic viscosity.
For ﬂuids with small Pr, the ﬁrst instability
from steady (time-independent) convection rolls
is an oscillatory instability, similar in many
respects to the wavy vortex state for Taylor-
Couette ﬂow. The convection rolls form a snake-
like instability along their axes, and this undula-
tion in the rolls propagates in a direction parallel
to the axes of the convection rolls. A cross section
of the ﬂow in this state would reveal a pattern of
counter-rotating vortices that oscillates periodi-
cally in the lateral direction.
There are also several other instabilities that
appear in Rayleigh-Bénard convection including:
cross-roll instabilities in which a second pattern of
convection rolls develops perpendicular to the
ﬁrst; a skew-varicose instability in which the
width of convection rolls is modulated; a zig-zag
instability which is exactly what its name implies,
one in which the convection rolls form a zig-zag
pattern; an instability referred to as the “Eckhaus
instability” where pairs of convection rolls disap-
pear, allowing other rolls present to grow and
increasing the wavelength of the pattern; and spi-
ral convection patterns. Defects can also appear in
convection patterns where either two or more
convection rolls meet at a point. The motion of a
defect parallel to convection rolls can result in the
addition or removal of a pair of convection rolls in
the ﬂow.
One way of understanding this behavior is to
consider the stability of convection rolls near
onset
as
a
function
of
their
wavelength.
A common way of analyzing stability is via a
“linear stability” argument. One starts with a
motionless state and then assumes a perturbation
of a periodic pattern of convection rolls on this
motionless state. A growth/decay term is associ-
ated with this perturbation, which might be writ-
ten in the form Aoestf(k), where f(k) is the
perturbation with wavenumber k, and s is the
Tbotton = Ttop + ΔT
Ttop
Nonlinear Fluid Flow, Pattern Formation, Mixing,
and Turbulence, Fig. 4 Schematic for Rayleigh-Bénard
convection. A thin layer of ﬂuid is sandwiched between
two thermally-conducting plates, with the bottom plate
hotter than the top plate. For sufﬁciently large DT, con-
vection ensues with hotter, light ﬂuid rising from the
bottom and colder, denser ﬂuid falling from the top. In
its simplest form, the convection pattern is a pattern of
counter-rotating “rolls” as shown in the sketch. The dot-
ted (dashed) lines denote “downwelling” (upwelling)
regions in the ﬂow
Nonlinear Fluid Flow, Pattern Formation, Mixing, and Turbulence
105

growth exponent. The growth exponent s is typ-
ically dependent on the value of k (Fig. 5). If s < 0
for all values of k, then all perturbations decay,
and the motionless state is stable and no convec-
tion rolls will develop; this is the case for Ra < Rac.
For Ra ¼ Rac, s ¼ 0 for one particular critical
wavenumber kc; for Ra just slightly above Rac,
perturbations with wavenumber kc should be
expected to grow, and, for an inﬁnite system
(i.e., no boundaries), a pattern of convection
rolls will appear with that precise wavenumber.
For Ra > Rac, there is a range of wavenumbers for
which s > 0.
The discussion above is idealistic; in realistic
systems, boundary conditions have a signiﬁcant
effect on convection patterns. If the ﬂuid layer is
conﬁned to a small-to-moderate rectangular box,
then the rolls line up parallel to the shortest side of
the box, as in Fig. 4. If the width of the box is an
integer multiple of the critical wavelength 2p/kc,
then linear stability correctly predicts convection
with this wavelength for Ra just barely above Rac.
If the ﬂuid layer is orders of magnitude wider than
the critical wavelength, multiple zones of parallel
convection rolls form at random orientation
(Fig. 6a); the zones are separated by grain bound-
aries. Over time, some zones grow while others
shrink. Ultimately, one zone may end up dominat-
ing, with a single pattern of parallel convection
rolls covering the entire system.
If contained in a circular container, a pattern of
parallel convection rolls cannot be achieved
(Heutmaker et al. 1985), because convection
rolls tend to line up perpendicular to the side
walls. A theory by Swift and Hohenberg (1977)
deﬁnes a free energy functional – an effective
energy that depends on the functional form of
the convection pattern; the pattern evolves to min-
imize this free energy. The free energy is increased
by convection rolls that are parallel to the side
walls, by bends in convection rolls and by defects
and grain boundaries in the patterns. Near onset
(i.e., for Ra just slightly over Rac), a complicated
convection pattern forms to minimize this free
σ
k
kc
Nonlinear Fluid Flow, Pattern Formation, Mixing,
and Turbulence, Fig. 5 Example of a plot of growth
exponent s as a function of wavenumber k, typical of
results of linear stability analysis. The bottom curve corre-
sponds to a Reynolds or Rayleigh number below the crit-
ical
value
for
instability;
s
is
negative
for
all
wavenumbers, so all disturbances decay. The middle
curve corresponds to the onset of instability. For Ra or Re
just above this value, s is positive for wavenumbers very
close to the critical value kc. For larger Re or Ra (top curve),
disturbances over a range wavenumbers are unstable
(a)
(b)
Nonlinear Fluid Flow,
Pattern Formation,
Mixing, and Turbulence,
Fig. 6 (a) Sketch of zones
of parallel convection rolls
separated by grain
boundaries. The lines
represent boundaries
between adjacent rolls, as
viewed from above (similar
to dashed and dotted lines in
Fig. 4). (b) Sketch of a
defect in a convection
pattern
106
Nonlinear Fluid Flow, Pattern Formation, Mixing, and Turbulence

energy functional (Fig. 7a). The patterns that form
have local wavenumbers that cannot all be at the
critical value kc; consequently, the pattern may
continually evolve in time, in contradiction to
the typical case in which convection with Ra just
above Rac is time independent.
For large enough Ra, convective ﬂows become
turbulent. Two types of turbulent ﬂows are often
discussed. At lower (but still large) Ra, compli-
cated convection patterns form with numerous
defects. The defects move around signiﬁcantly in
the pattern, resulting in continuous variation in the
pattern. This regime is referred to as weak turbu-
lence or defect-mediated turbulence. For very
high Ra, the convection pattern breaks up
completely and a regime of strong turbulence is
found. A side view of convection in the strongly
turbulent regime (Fig. 7b) shows that the ﬂow is
divided into three regions. Most of the tempera-
ture gradient is concentrated into thin boundary
layers at the top and bottom of the ﬂuid, while the
ﬂuid is well-mixed at roughly the average temper-
ature in the large central region of the ﬂow. The
boundary layers are not quiescent; rather, they
grow in thickness as heat ﬂows into (for the
lower boundary layer) and out of (for the upper
boundary
layer)
them,
eventually
becoming
unstable and forming plumes that erupt, carrying
blobs of warm or cold ﬂuid into the center region.
The eruption of these plumes both acts to drive the
turbulent ﬂow and also transport heat from the
bottom to the top of the system.
Bénard-Marangoni Convection
If a ﬂuid layer with a free surface is heated from
below, thermal convection can be driven by vari-
ations in surface tension at the surface. This form
of convection is referred to as Bénard-Marangoni
convection and is usually characterized by a pat-
tern of hexagons. Since the ﬂuid is heated from
below, it is unstably stratiﬁed. However, the main
force driving the ﬂow isn’t buoyancy; rather, the
ﬂow is driven by gradients in the surface tension
at the free surface. An instability occurs in which
small variations in the temperature arise on the
surface. The surface tension depends on the tem-
perature; consequently, temperature gradients
result in surface tension gradients that drive
ﬂows along the surface. Regions in which the
ﬂuid converges on the surface produce down-
ward-welling ﬂows; upwelling of ﬂuid occurs
(a)
(b)
(a) 8.83th 
(b) 9.81th 
(c) 9.89th 
(d) 11.1th 
Nonlinear Fluid Flow, Pattern Formation, Mixing,
and Turbulence, Fig. 7 (a) Images of Rayleigh-Bénard
convection in a circular container near onset, viewed from
above (From Heutmaker et al. 1985). (b) Sketch of
strongly turbulent convection from side, showing the for-
mation of thermal boundary layers at the bottom and top
that erupts, sending plumes of hot and cold ﬂuid into the
middle region
Nonlinear Fluid Flow, Pattern Formation, Mixing, and Turbulence
107

below regions in which the ﬂuid diverges on the
surface.
Transport and Mixing
The manner in which an impurity is mixed within
a ﬂuid is an issue with signiﬁcant practical impor-
tance for a wide range of scientiﬁc and engineer-
ing applications. Mixing of a passive impurity
(one that follows ﬂuid elements in the ﬂow and
whose distribution does not affect the ﬂow itself)
is governed by the advection-diffusion equation:
@c
@t ¼ u
!  ∇
!
c þ D∇2c,
where c is a scalar concentration ﬁeld,*u is the
velocity ﬁeld, and D is the molecular diffusion
coefﬁcient. This equation can be written in non-
dimensional form by scaling the velocity ﬁeld by a
characteristic ﬂow velocity U, distance by a char-
acteristic length L, and time by the advection
timescale L/U:
@c
@t0 ¼ u
!0  ∇
!0
c þ 1
Pe ∇02c
where the Peclet number Pe ¼ UL/D characterizes
the relative strength of advective to diffusive
mixing in the ﬂow. In the limit of no ﬂow
(Pe ! 0), mixing is entirely via molecular diffu-
sion caused by Brownian motion of individual
tracer particles in the impurity. Molecular diffusion
is a slow mixing process; the variance s2(t) of a
distribution grows linearly with time: s2(t) ¼ 2Dt.
The presence of a ﬂuid ﬂow dramatically
changes the mixing. An impurity is advected
along with ﬂuid elements in the ﬂow but can
diffuse away from these deterministic ﬂuid trajec-
tories. Advection of an individual tracer is deter-
mined from equations of motion derived from the
velocity ﬁeld u
! ¼ (ux,uy,uz):
dx=dt ¼ ux
dy=dt ¼ uy
dz=dt ¼ uz:
Trajectories are determined by integrating
these equations of motion. If the ﬂow is two-
dimensional and time-independent (u
! ¼ u
!(x, y)
and uz ¼ 0), then tracer trajectories are integrable
(well-ordered).
For
two-dimensional,
time-
periodic or three-dimensional, time-independent
ﬂows, however, the equations of motion in gen-
eral are not integrable, and trajectories are often
chaotic, with nearby tracers separating roughly
exponentially in time (sensitive dependence on
initial conditions).
The most well-known ﬂow exhibiting chaotic
advection is the blinking vortex ﬂow proposed by
Hassan Aref (1984). The ﬂow is shown in Fig. 8a;
the ﬂuid alternates periodically between circling
around the left vortex and around the right vortex.
Advection of a blob of a passive dye is shown in
Fig. 8b (Nugent et al. 2004). Mixing is associated
with a repeated process of stretching and folding
of tendrils of the impurity. Stretching and folding
behavior such as this is typical of chaotic mixing.
Transport on scales larger than typical length
scales of ﬂow can be illustrated with the alternat-
ing vortex chain (Solomon and Gollub 1988)
shown in Fig. 9. If the (two-dimensional) ﬂow is
time independent, tracers follow ordered and
closed trajectories within individual vortices.
The presence of molecular diffusion allows for
tracers to diffuse from one vortex to the next.
The combination of advection around and diffu-
sion between the vortices results in enhanced
transport whose variance grows linearly in time:
s2(t) ¼ 2Dt, where D is the enhanced diffusion
coefﬁcient.
The simplest time dependence for the alternat-
ing vortex chain is a simple lateral oscillation of
the entire chain, similar to time dependence found
in Taylor-Couette and Rayleigh-Bénard ﬂows for
intermediate values of Re and Ra. A passive tracer
moving in this ﬂow circles around an individual
vortex, but if it is near a separatrix (boundary)
between vortices, it can cross between vortices.
Over time, the tracer alternates between circling
within and crossing between vortices in an erratic
manner. The trajectories are rigorously chaotic in
the sense that nearby trajectories separate roughly
exponential as a function of time.
Not all tracers in the ﬂow follow chaotic tra-
jectories. Tracers near the center of a vortex
remain trapped within that vortex, following a
trajectory that is well-ordered and not sensitive
108
Nonlinear Fluid Flow, Pattern Formation, Mixing, and Turbulence

to initial conditions. The separation of the system
into both ordered and chaotic regions of transport
can be seen easily by plotting a Poincaré section
(Fig. 9b), a plot that shows the location of one
tracer (or more) once every period of the ﬂow.
A tracer that starts in the chaotic region will even-
tually explore the entire chaotic region, which
shows up on the Poincaré section as a pattern of
dots. A chaotic trajectory can never cross into a
region with ordered trajectories; consequently, the
ordered regions show up as white “islands” on a
Poincaré section.
The boundaries between ordered and chaotic
regions – referred to as Kolmogorov-Arnold-
Moser (KAM) invariant surfaces – act as barriers
against transport and mixing in the ﬂow. KAM
barriers are very common in laminar ﬂows and
also show up in many ﬂows found in nature, even
turbulent ones. Examples of transport barriers
include the ozone hole over Antarctica, Gulf
stream rings in the Atlantic Ocean, and coherent
vortices (called meddies) originating in the Med-
iterranean Sea that cross the Atlantic and maintain
the salinity and biological constituency found in
the Mediterranean for months and even years.
Another well-known example of a transport bar-
rier is the Great Red Spot of Jupiter, a large
coherent patch of vorticity in a very turbulent
atmosphere that clearly acts as a transport barrier,
evidenced by the fact that it has maintained its
distinct color for centuries.
Chaotic
advection
results
in
signiﬁcant
enhancements in long-range transport. In many
cases, enhanced transport is diffusive with a var-
iance that grows linearly in time. However, anom-
alous diffusion is also possible where the variance
grows as a power law in time with a growth
exponent different from 1: s2(t) ~ tg with g 6¼ 1.
Transport with g < 1 is called subdiffusion and
transport with g > 1 is called superdiffusion. The
presence of islands of ordered trajectories is often
associated with subdiffusive transport; tracers in
the chaotic region stick to the outside of these
islands and possibly diffuse inward due to
Brownian motion. Superdiffusion is associated
with Lévy  ight trajectories where tracers jump
large distances between regions in the ﬂow. An
example of a ﬂow with superdiffusion is the alter-
nating vortex chain with both oscillatory and
drifting time dependence (Paoletti et al. 2006)
(Fig. 9a). A Poincaré section for transport in this
ﬂow is shown in Fig. 9c. Two distinct chaotic
regions are apparent, and in addition to ordered
islands in the vortices, there is also a snake-like
Nonlinear Fluid Flow, Pattern Formation, Mixing,
and Turbulence, Fig. 8 (a) Sketch of blinking vortex
ﬂow. Fluid alternates between circling around left and right
vortex centers. (b) Mixing of dye in blinking vortex ﬂow.
Images are separated in time by one period of oscillation
each. (From Nugent et al. 2004)
Nonlinear Fluid Flow, Pattern Formation, Mixing, and Turbulence
109

region of ordered trajectories that wind around the
vortices. A tracer in the chaotic region in this ﬂow
alternately sticks to islands (remaining temporar-
ily conﬁned to a vortex) and to the snake region
(traveling rapidly along the vortex chain).
Chaotic advection is also possible in three-
dimensional ﬂows, even those that are time inde-
pendent. An example of such a ﬂow is shown in
Fig. 10 – a chain of alternating vortices super-
posed with a second chain which is shifted by
half of a vortex width and is oriented with its
vortex axes perpendicular to those of the ﬁrst
chain (Fogleman et al. 2001). Trajectories of
tracers in this ﬂow are shown in Fig. 10b. A
Poincaré section (Fig. 10c) again shows coexis-
tence of both ordered and chaotic regions of trans-
port in the ﬂow.
There are numerous applications of chaotic
mixing. Chemical engineers have already begun
to develop and market devices that take advantage
of chaos to enhance mixing in low-Reynolds
number ﬂows. Chaotic mixing is particularly use-
ful for mixing of high-viscosity ﬂuids for which
turbulent mixing would be difﬁcult and/or tre-
mendously
expensive
energetically.
Chaotic
mixing is also ﬁnding signiﬁcant applications in
the expanding ﬁeld of microﬂuidic devices,
so-called factories-on-a-chip, again which involve
very small Reynolds numbers due to the small
length scales of these systems.
Manifolds, Lobes, and Transport Barriers
In addition to KAM invariant surfaces, transport
barriers can also be found associated with invari-
ant manifolds in the system. Manifolds are found
connected to ﬁxed points in the ﬂow, as shown in
Fig. 11. In general, an invariant manifold is a set
of points in the ﬂow that map onto themselves
when integrated forward in time. For passive
transport, an unstable manifold of a particular
ﬁxed (stagnation) point in the ﬂow can be deter-
mined conceptually by starting with a large num-
ber of passive tracers, initially inﬁnitesimally
close to the ﬁxed point. The locations of these
tracers at a distant time in the future are the unsta-
ble manifold of that ﬁxed point. Similarly, the
stable manifold of a ﬁxed point is the locations
of tracers that will converge on the ﬁxed point in
the distant future.
For a time-independent, two-dimensional ﬂow,
the unstable manifold of one ﬁxed point often
coincides
with
the
stable
manifold
of
a
(a) 
(b)
(c)
0.5
0
–0.5
–0.5
0
0.5
1
1.5
Nonlinear Fluid Flow, Pattern Formation, Mixing,
and Turbulence, Fig. 9 (a) Sketch of alternating vortex
chain. (b) Poincaré section for oscillating vortex chain,
showing ordered regions of transport in vortex cores and
chaotic region around and between vortices. (c) Poincaré
section for oscillating and drifting vortex chain. (From
Paoletti et al. 2006)
110
Nonlinear Fluid Flow, Pattern Formation, Mixing, and Turbulence

neighboring ﬁxed point, as shown in red in
(Fig. 11a). This manifold acts as a transport bar-
rier, with passive impurities on one side staying on
that side. But the unstable and stable manifolds
often separate – and become very complicated – if
the ﬂow is time dependent, even for periodic time
dependence,
as
shown
in
(Fig.
11b).
The
manifolds in this case are still transport barriers,
but since the ﬂow is time dependent, the mani-
folds themselves undulate in time, and the tracers
can move through the ﬂow with the moving mani-
folds. The regions surrounded by pieces of over-
lapping stable and unstable manifolds are referred
to as “lobes”
(or “turnstiles”) (Solomon and
Gollub 1988; Camassa and Wiggins 1991; Rom-
Kedar and Wiggins 1991).
The lobes form a mechanism by which tracers
can be transported between different regions in the
ﬂow. This is best illustrated with the alternating
vortex ﬂow (Fig. 9a and Fig. 12). Impurities
trapped in a lobe can’t escape the lobe. But as
the manifolds undulate periodically, the lobes
move such that the ﬁrst lobe (to the right of the
middle
black
line)
maps
to
second
lobe
(immediately to the left of the middle black line)
after one oscillation period, then to third lobe after
two periods, etc. Consequently, impurities ini-
tially in the ﬁrst lobe move from one vortex to
another. This results in long-range transport in the
vortex
chain
(Solomon
and
Gollub
1988;
Camassa and Wiggins 1991)
Nonlinear Fluid Flow, Pattern Formation, Mixing,
and
Turbulence,
Fig.
10 (a)
Sketch
of
time-
independent, nested vortex chain ﬂow. (b) Example of a
chaotic trajectory for the nested vortex ﬂow. (c) Poincaré
section at the mid-height of the ﬂow, showing both ordered
and chaotic regions. (From Fogleman et al. 2001)
(a)
(b)
lobe
Nonlinear Fluid Flow, Pattern Formation, Mixing,
and Turbulence, Fig. 11 Stable and unstable manifolds
of two hyperbolic ﬁxed points in a ﬂow. (a) Time-
independent ﬂow; the unstable manifold (in red) of the
lower ﬁxed point is the same as the stable manifold of the
upper ﬁxed point. (b) Time-periodic ﬂow; the unstable
manifold (red) of the bottom ﬁxed point undulates, as
does the stable manifold (green) of the upper ﬁxed point
Nonlinear Fluid Flow, Pattern Formation, Mixing, and Turbulence
111

Recently, the manifold picture
has
been
extended to more complicated, time-aperiodic
ﬂows. Several groups have investigated what are
now called Lagrangian coherent structures (LCS)
(Haller 2015), which are generally deﬁned as
regions in a ﬂow where passive tracers are
advected together. For instance, tracers in the
Great Red Spot of Jupiter remain together – and
have so for hundreds of years, indicated by the
fact that it has remained red in color – even though
the vortex ﬂow of the Spot is embedded within a
very turbulent ﬂow.
But LCS approaches also identify manifold-
like structures in 2D ﬂuid ﬂows, even if the ﬂow
is aperiodic and even weakly turbulent. The most
common approach is to calculate ﬁnite-time
Lyapunov exponent (FTLE)
– or stretching –
ﬁelds for the ﬂow (Voth et al. 2002; Mathur et al.
2007). The ridges in the ﬁeld that follow local
maxima in the FTLE have sometimes been iden-
tiﬁed as repelling LCS and ridges in the backward-
time FTLE ﬁelds as attracting LCS. These struc-
tures have been identiﬁed as local barriers for the
mixing of passive impurities, similar to (and
equivalent in the time-independent limit) unstable
and stable manifolds, as seen in the experimental
images from Voth et al. (2002) in Fig. 13.
There have been numerous studies of Lagrang-
ian coherent structures since the ﬁrst papers in the
early 2000s. Follow-up studies have argued that
FTLE ridges may not be the best indicator of
repelling and attracting LCS and that instead a
variational approach (Haller 2011) would do a
better job. Several groups have proposed alternate
approaches for detecting coherent transport struc-
tures, including approaches involving ergodic
partition (Mezić and Wiggins 1999), maps of
mesohyperbolicity and mesoellipticity (Mezic
et al. 2010), almost-invariant sets (Froyland and
Padberg 2009), an M-function (Mendoza and
Mancho 2010) that identiﬁes distinguished trajec-
tories that separates the system into regions of
qualitatively different types of trajectories, and
shape coherence (Ma and Bollt 2014) based on
time evolution of curvature of boundary curves.
Concurrently with the development of these
Nonlinear Fluid Flow, Pattern Formation, Mixing,
and Turbulence, Fig. 12 Stable and unstable manifolds
of the hyperbolic ﬁxed points for the alternating vortex
chain. The straight vertical lines are the separatrices
between adjacent vortices and are also the manifolds for
the time-independent case with no lateral oscillations. The
complicated (stretched and folded) manifolds correspond
to time-periodic, lateral oscillations of the vortex chain.
Some of the lobes formed from the intersections of these
manifolds are shaded in
Nonlinear Fluid Flow, Pattern Formation, Mixing,
and Turbulence, Fig. 13 (a) Stretching ﬁelds calculated
from a 2D ﬂow. (b) Evolving dye concentration in the same
ﬂow. (c) Superposition of stretching ﬁelds from (a) and dye
concentration proﬁle from (b). (d) Superposition of dye
concentration ﬁeld and time-reversed stretching ﬁelds.
(From Voth et al. 2002)
112
Nonlinear Fluid Flow, Pattern Formation, Mixing, and Turbulence

approaches, other groups have focused on devel-
oping techniques for the identiﬁcation of coherent
transport structures from experimentally sparse
data such as that obtained by a ﬁnite number of
ocean ﬂoats. These sparse data approaches are
based on topological arguments and involve iden-
tiﬁcation of braiding patterns (Thiffeault and
Finn 2006) and the evolution of stretching “rubber
bands” advected by the ﬂow (Roberts et al. 2019).
Other research groups have extended LCS
approaches to a wider range of transport problems
involving impurities that aren’t necessarily pas-
sive (Balasuriya et al. 2018).
Pattern Formation in Reaction-Diffusion
and Advection-Reaction-Diffusion
Systems
Another class of nonlinear, pattern-forming sys-
tems
is
the
well-known
reaction-diffusion
(RD) problem. The reaction is a process in
which one or more species somehow changes
into something different. Examples include chem-
ical reactions, biological interactions of some sort
(such as the interaction of a disease with a popu-
lation of people or animals or a predator-prey
system), and a wide range of phase transitions.
In an extended, nonﬂowing system, the reaction
typically occurs at different times in different
locations in the system, resulting in the formation
of patterns. The key to the formation of these
patterns is the interaction between the reaction at
local regions in the system and molecular diffu-
sion which (for a nonﬂowing system) is the only
means
of
communication
between
different
regions.
A general form of the RD equation can be
written as follows:
@c
@t ¼ f c
ð Þ þ D∇2c
where c is a concentration ﬁeld of some chemical,
biological, or physical species, and the ﬁrst term
on the right denotes some sort of reaction. The
details of the reaction term itself vary from system
to system; however, some common behavior is
found in a wide range of RD systems, independent
of the details of this reaction term.
The ﬁeld of reaction-diffusion studies was
enhanced signiﬁcantly by the discovery of the
oscillatory Belousov-Zhabotinsky (BZ) chemical
reaction. Discovered in the 1950s, this reaction is
well-known to have a pH that oscillates for hours
when well-mixed in a beaker or a ﬂask. When
catalyzed with a pH-indicator such as ferroin, the
chemicals can be observed to alternate back and
forth between a red and blue color during this
period before the reaction ﬁnally runs down. The
oscillation is typically nearly periodic, but condi-
tions have been found in which chaotic oscilla-
tions can be found in the BZ reaction.
Reaction-diffusion systems can also produce
propagating fronts if the reaction is a one-shot
(or “burn”) reaction (i.e., A ! B) or if the reaction
is excitable, as shown in Fig. 14. An excitable
reaction is one in which some trigger turns species
A turns into B, but then the system slowly resets
back to state A after a refractory timescale.
A forest ﬁre is an example of a one-shot reaction,
unless the trees grow back really (unreasonably)
fast. The BZ reaction has an excitable regime in
which it forms pulse-like reaction fronts. A nerve
pulse is also excitable – a trigger causes the nerve
to ﬁre, and there is a refractory period after the
ﬁring during which the potential in the nerve
resets. After the refractory period, the nerve can
be triggered to ﬁre again.
A one-shot reaction in a spatially extended
system produces a burn-like front, as sketched in
Fig. 14a, whereas a spatially extended excitable
system produces pulse-like reactions (Fig. 14b).
Depending on the nature of the trigger, excitable
systems can also produce patterns called trigger
waves. For example, if the chemicals for the excit-
able BZ reaction are in a shallow petri dish with
no ﬂow (or in a gel or fritted disk that inhibits a
ﬂow), spiral and/or target patterns form, as seen in
Fig. 15. Patterns similar to these have been
observed in a wide range of physical, chemical
and
biological
systems.
Examples
include
(a) spiral waves of electrical activity in the heart
which act as pacemakers; breakdown of these
spiral waves are associated with cardiac ﬁbrilla-
tion; (b) spiral waves of “spreading depression” in
Nonlinear Fluid Flow, Pattern Formation, Mixing, and Turbulence
113

the brain that are associated with migraine head-
aches; (c) spiral patterns found in developing
embryos which may be partially responsible for
morphogenesis in which different cells in the
embryo develop different roles in the growing
organism; and (d) spiral and target patterns in
populations of slime molds in a stagnant system.
Because of the similarity of these patterns to those
found in the BZ system, there has been a signiﬁ-
cant amount of research into the properties of the
BZ system, which is considered to be a paradigm
of RD systems. Reaction-diffusion dynamics also
explain the propagation of fronts in stagnant sys-
tems, e.g., the spreading of a ﬁre in the absence of
any winds or the growth of a solid in the absence
of ﬂuid ﬂows.
In both natural and industrial systems, reacting
systems are rarely stagnant; ﬂows dramatically
affect the mixing and therefore the communica-
tion between different parts of the system. The
B
B
B
A
A
A
A
B
(a)
A
A
A
A
B
B
B
B
B
B
(b)
Nonlinear Fluid Flow, Pattern Formation, Mixing,
and Turbulence, Fig. 14 (a) Reaction front for a one-
shot (or “burn”) reaction where species A turns into species
B. (b) Reaction front for an excitable reaction where
species A turns into species B and then back into A after
a refractory period. Fronts in excitable systems are typi-
cally pulse-like fronts
Nonlinear Fluid Flow, Pattern Formation, Mixing, and Turbulence, Fig. 15 Examples of reaction-diffusion
patterns formed by the Belousov-Zhabotinsky chemical reaction in a thin layer in a petri dish
114
Nonlinear Fluid Flow, Pattern Formation, Mixing, and Turbulence

more general advection-reaction-diffusion (ARD)
problem is represented by the following equation:
@c
@t ¼ u
!  ∇
!c þ f c
ð Þ þ D∇2c
where the additional term on the right denotes
advection of the relevant species by the ﬂuid
ﬂow. Advection-reaction-diffusion dynamics are
relevant for pattern formation and front propaga-
tion in a wide range of systems, including marine
ecological systems (e.g., algae and phytoplankton
blooms), microﬂuidic chemical and biological
processing and diagnostics, forest ﬁres in the pres-
ence of winds, and the propagation of disease in a
moving population.
If the mixing is chaotic, it has been shown (Tel
et al. 2005) that ARD patterns reﬂect the struc-
tures that characterize chaotic mixing in the ﬂow.
An example (Nugent et al. 2004) is the BZ reac-
tion in a blinking vortex ﬂow (Fig. 8), in which
ﬂuid circulates alternately (and periodically)
between two separate vortex centers. As seen in
Fig. 16, except for very weak mixing, the patterns
associated with chaotic mixing end up dominating
the pattern formation process for the ARD system
as well (Nugent et al. 2004). Ideas such as this
have been used to explain patterns of populations
of marine organisms in both the Gulf of Mexico
and in the northern Atlantic Ocean.
Burning Invariant Manifolds and
Reaction Fronts
The manifold theory described in section “Mani-
folds, Lobes and Transport Barriers” can be
extended
to
describe
front
propagation
in
advection-reaction-diffusion systems. We can
use the alternating vortex chain ﬂow to explain
the behavior. Figure 17 shows two adjacent vorti-
ces in the time-independent, alternating chain vor-
tex ﬂow. For passive mixing, there are ﬁxed points
in the ﬂow (black dots in Fig. 17) – where the ﬂuid
velocity is zero – and manifolds (red curve) that
connect the ﬁxed points. If the ﬂuid is the medium
for a one-shot or excitable reaction, then if a
reaction is triggered at the bottom center ﬁxed
point, a reaction front will propagate outward
from that point. Of course, the front will propagate
upward along the direction of the unstable passive
manifold since the ﬂuid velocity is upward in that
region. But the reaction can also propagate left-
ward and rightward against the incoming ﬂow.
But since the incoming ﬂow increases with
Nonlinear Fluid Flow, Pattern Formation, Mixing,
and Turbulence, Fig. 16 (a) Simulation of mixing
ﬁeld for blinking vortex ﬂow. (b) Advection-reaction-
diffusion pattern for Belousov-Zhabotinsky chemical reac-
tion in the same ﬂow. (From Nugent et al. 2004)
Nonlinear Fluid Flow, Pattern Formation, Mixing, and Turbulence
115

distance from the ﬁxed point, the reaction front
eventually reaches a point where the incoming
ﬂow speed and the outgoing reacting speed are
the same; at that point – referred to as a burning
ﬁxed point (red circles in Fig. 17) – the reaction
stops. And as there are passive manifolds attached
to passive ﬁxed points in the ﬂow, there are burn-
ing invariant manifolds (BIMs) (Mahoney et al.
2012; Bargteil and Solomon 2012; Mitchell and
Mahoney 2012) attached to the burning ﬁxed
points.
Like the passive invariant manifolds, the BIMs
act as barriers, with these barriers blocking propa-
gating reaction fronts rather than passive impurities.
Unlike the passive manifolds, however, the BIMs
block reactions in one direction only. To understand
this one-way behavior, imagine triggering a reac-
tion on the bottom edge of the ﬂow in Fig. 17, to the
left of the left burning ﬁxed point. That reaction can
propagate to the right, and when it reaches the left
burning ﬁxed point and BIM, it passes right through
since the ﬂow and the reaction are both going to the
right. If a reaction front is triggered at the passive
ﬁxed point, however, it is blocked by both BIMs in
Fig. 17. The result is a reaction that propagates
upward between the two BIMs (as shown in
Fig. 18), penetrating into the vortex centers only
after it reaches cusps in the BIMs that signify a
reversal in the blocking direction.
The ability of BIMs to act as one-way barriers
has been demonstrated experimentally for a range of
two- and three-dimensional ﬂuid ﬂows. One of these
experiments is shown in Fig. 18b for the alternating
vortex ﬂow (Mahoney et al. 2012; Bargteil and
Solomon 2012). Other examples are shown in
Fig. 19, including reaction barriers that produce
stationary fronts in 2D vortex array ﬂows with
imposed winds (Megson et al. 2015) (Fig. 19a); a
Nonlinear Fluid Flow, Pattern Formation, Mixing,
and Turbulence, Fig. 17 (a) Fixed points (black dots)
and passive invariant manifold (red curve) for passive
mixing in two side-by-side alternating vortices. (b)
Burning ﬁxed points (red dots) and burning invariant mani-
folds for reaction front propagation in the same ﬂow. The
black carrots indicate the local blocking direction for the
BIMs. (From Mahoney et al. 2012)
Nonlinear Fluid Flow, Pattern Formation, Mixing,
and Turbulence, Fig. 18 (a) Simulation of burning var-
iant manifolds (red curves) and contours of a propagating
reaction front (blue to green curves) triggered initially at
the bottom/center stagnation point. (b) Experiments show-
ing front contours and inferred BIMs for the same ﬂow.
(From Mahoney et al. 2012)
116
Nonlinear Fluid Flow, Pattern Formation, Mixing, and Turbulence

Nonlinear Fluid Flow, Pattern Formation, Mixing,
and Turbulence, Fig. 19 Experimental evidence of
burning invariant manifolds in laminar ﬂows. (a) Experi-
ments (left) and predicted BIMs (right) for reaction in a 2D
vortex array ﬂow with imposed wind. (From Megson et al.
2015). (b) Measured barriers (red and green) and predicted
BIMs (purple) for spatially disordered, 2D ﬂow (From
Bargteil and Solomon 2012). (c) Stationary reaction
patterns for spatially disordered 2D ﬂow with imposed
wind (From Megson et al. 2015). (d) Time-independent,
3D ﬂow composed of superposed horizontal (red) and
vertical (blue) vortex chains (From Doan et al. 2018). (e)
and (f) experimental (top) reaction front barriers and pre-
dicted BIMs (bottom) for 3D ﬂow shown in (d). (From
Doan et al. 2018)
Nonlinear Fluid Flow, Pattern Formation, Mixing, and Turbulence
117

spatially random 2D ﬂow (Bargteil and Solomon
2012) characterized by multiple BIM segments
(Fig. 19b); a random ﬂow with an imposed wind
(Megson et al. 2015) that produces stationary fronts
with surprisingly complicated shapes, again, deter-
mined by BIMs in the system (Fig. 19c); and a 3D
ﬂow (Doan et al. 2018) (Fig. 19d) composed of the
superposition of a vertical and horizontal vortex
chain that produces tube-like (Fig. 19e) and sheet-
like barriers (Fig. 19f).
Other Examples of Pattern-Forming
Systems
Patterns similar to those discussed above are
found in a wide range of systems spanning all
ﬁelds of science and engineering. Some examples
are as follows:
•
Electrohydrodynamic convection in ﬂows of
nematic liquid crystals.
•
Wave patterns on the surface of a ﬂuid oscil-
lated periodically in the vertical direction.
•
Vibrating granular systems
•
Bubble froths
•
Ferroﬂuids – labyrinth patterns
This is just a small sample of the many non-
linear, pattern-forming systems that have been
studied during the past few decades.
Future Directions
The study of nonlinear systems is an ongoing and
continually evolving ﬁeld. Nonlinear dynamics
span a wide range of ﬁelds of study, including all
of the ﬁelds of sciences and engineering, as well
as mathematics, medicine, economics and even
some ﬁelds of social sciences. Not only are there
numerous ongoing studies of the basic mathemat-
ical and scientiﬁc behavior of nonlinear systems,
but there are also many applications that are being
developed, based on the principles of nonlinear
systems.
Bibliography
Primary Literature
Andereck CD, Dickman R, Swinney HL (1983) New ﬂows
in a circular Couette system with co‐rotating cylin-
ders. Phys Fluids 26:1395
Andereck CD, Liu SS, Swinney HL (1986) Flow regimes
in a circular Couette system with independently rotat-
ing cylinders. J Fluid Mech 164:155
Aref H (1984) Stirring by chaotic advection. J Fluid Mech
143:1
Balasuriya S, Ouellette NT, Rypina I (2018) Generalized
Lagrangian coherent structures. Phys D 372:31
Bargteil D, Solomon T (2012) Barriers to Front Propaga-
tion in Ordered and Disordered Vortex Flows. Chaos
22:037103
Camassa R, Wiggins S (1991) Chaotic advection in a
Rayleigh-Bénard ﬂow. Phys Rev A 43:774
Doan M, Simons JJ, Lilienthal K, Solomon T, Mitchell KA
(2018) Barriers to Front Propagation in Laminar,
Three-Dimensional
Fluid
Flows.
Phys
Rev
E 97:033111
Fenstermacher PR, Swinney HL, Gollub JP (1979) Dynam-
ical instabilities and the transition to chaotic Taylor
vortex ﬂow. J Fluid Mech 94:103
Fogleman MA, Fawcett MJ, Solomon TH (2001) Lagrang-
ian chaos and correlated Levy ﬂights in a non-Beltrami
ﬂow: transient versus long-term transport. Phys Rev
E 63:020101(R)
Froyland G, Padberg K (2009) Almost-invariant sets and
invariant manifolds – Connecting probabilistic and
geometric descriptions of coherent structures in ﬂows.
Phys D 238:1507
Gollub JP, Swinney HL (1975) Onset of Turbulence in a
Rotating Fluid. Phys Rev Lett 35:927
Haller G (2011) A variational theory of hyperbolic
Lagrangian coherent structures. Phys D 240:574
Haller G (2015) Lagrangian Coherent Structures. Annu
Rev Fluid Mech 47:137
Heutmaker MS, Fraenkel PN, Gollub JP (1985) Convection
patterns: time evolution of the wave-vector ﬁeld. Phys
Rev Lett 54:1369
Kalliroscope can be obtained from Kalliroscope Corpora-
tion, Groton. www.kalliroscope.com
Landau L (1944) On the problem of turbulence. C R (Dokl)
Acad Sci URSS 44:311
Ma T, Bollt E (2014) Differential Geometry Perspective of
Shape Coherence and Curvature Evolution by Finite-
Time Nonhyperbolic Splitting. SIAM J Appl Dyn Syst
13:1106
Mahoney J, Bargteil D, Kingsbury M, Mitchell K, Sol-
omon T (2012) Invariant Barriers to Reactive Front
Propagation
in
Fluid
Flows.
Europhys
Lett
98:44005
Marcus PS (1988) Numerical simulation of Jupiter’s Great
Red Spot. Nature 331:693; Sommeria J, Meyers SD,
Swinney HL (1988) Laboratory simulation of Jupiter’s
Great Red Spot. Nature 331:689
118
Nonlinear Fluid Flow, Pattern Formation, Mixing, and Turbulence

Mathur M, Haller G, Peacock T, Ruppert-Felsot JE,
Swinney HL (2007) Uncovering the Lagrangian skele-
ton of turbulence. Phys Rev Lett 98:144502
Megson PW, Najarian ML, Lilienthal KE, Solomon TH
(2015) Pinning of Reaction Fronts by Burning Invari-
ant
Manifolds in Extended
Flows. Phys
Fluids
27:023601
Mendoza C, Mancho AM (2010) Hidden Geometry of
Ocean Flows. Phys Rev Lett 105:03850
Mezić I, Wiggins S (1999) A method for visualization of
invariant sets of dynamical systems based on the ergo-
dic partition. Chaos 9:213; Budišić M, Mezić I (2012)
Geometry of the ergodic quotient reveals coherent
structures in ﬂows. Physica D 241:1255
Mezic I, Loire S, Fonoberov VA, Hogan P (2010) A New
Mixing Diagnostic and Gulf Oil Spill Movement. Sci-
ence 330:486
Mitchell KA, Mahoney J (2012) Finite-time barriers to
front propagation in two-dimensional ﬂuid ﬂows.
Chaos 22:037104
Nugent CR, Quarles WM, Solomon TH (2004) Experimen-
tal studies of pattern formation in a reaction-advection-
diffusion system. Phys Rev Lett 93:218301
Paoletti MS, Nugent CR, Solomon TH (2006) Synchroni-
zation of Oscillating Reactions in an Extended Fluid
System. Phys Rev Lett 96:124101
Roberts E, Sindi S, Smith S, Mitchell KA (2019) Ensem-
ble-based topological entropy calculation (E-tec).
Chaos 29:013124
Rom-Kedar V, Wiggins S (1991) Transport in two-dimen-
sional maps: Concepts, examples, and a comparison of
the theory of Rom-Kedar and Wiggins with the Markov
model of MacKay, Meiss, Ott, and Percival. Phys
(Amsterdam) 51D:248
Ruelle D, Takens F (1971) On the nature of turbulence.
Commun Math Phys 20:167
Solomon TH, Gollub JP (1988) Passive Transport in
Steady Rayleigh-Benard Convection. Phys Fluids
31:1372; Solomon TH, Gollub JP (1988) Chaotic
Particle Transport in Time-Dependent Rayleigh-B
nard Convection. Phys Rev A 38:6280; Solomon TH,
Tomas S, Warner JL (1996) The Role of Lobes in
Chaotic Mixing of Miscible and Immiscible Impurities.
Phys Rev Lett 77: 2682
Swift J, Hohenberg PC (1977) Hydrodynamic ﬂuctuations
at the convective instability. Phys Rev A 15:319
Tel T, de Moura A, Grebogi C, Karolyi G (2005) Chemical
and biological activity in open ﬂows: a dynamical
system approach. Phys Rep 413:91
Thiffeault JL, Finn MD (2006) Topology, braids and
mixing in ﬂuids. Phil Trans R Soc A 364:3251;
Allshouse MR, Thiffeault JL (2012) Detecting coherent
structures using braids. Physica D 241:95
Voth GA, Haller G, Gollub JP (2002) Experimental Mea-
surements of Stretching Fields in Fluid Mixing. Phys
Rev Lett 88:254501
Books and Reviews
Baker GL, Gollub JP (1990) Chaotic dynamics: an intro-
duction. Cambridge University Press, Cambridge
Ben-Avraham D, Havlin S (2000) Diffusion and reactions
in fractals and disordered systems. Cambridge Univer-
sity Press, Cambridge
Cross MC, Hohenberg PC (1993) Pattern-formation out-
side of equilibrium. Rev Mod Phys 65:851
Grindrod P (1996) The theory and applications of reaction-
diffusion equations: patterns and waves. Clarendon
Press, Oxford
Ott E (2002) Chaos in dynamical systems, 2nd edn. Cam-
bridge University Press, Cambridge
Tel T, de Moura A, Grebogi C, Karolyi G (2005) Chemical
and biological activity in open ﬂows: a dynamical
system approach. Phys Rep 413:91
Tritton DJ (1988) Physical ﬂuid synamics, 2nd edn.
Clarendon Press, Oxford
Winfree AT (1980) The geometry of biological time.
Springer, New York
Nonlinear Fluid Flow, Pattern Formation, Mixing, and Turbulence
119

Fluid Dynamics in Clouds
The Sum of Its Parts
S. Ravichandran
1, Jason R. Picardo
2,
Samriddhi Sankar Ray
3 and
Rama Govindarajan3
1Nordita, KTH Royal Institute of Technology and
Stockholm University, Stockholm, Sweden
2Department of Chemical Engineering, Indian
Institute of Technology Bombay, Mumbai, India
3International Centre for Theoretical Sciences,
Tata Institute of Fundamental Research,
Bangalore, India
Article Outline
Glossary
Why Study Clouds
Deﬁnition of the Subject
Microphysics Without Thermodynamics
Microphysics with Thermodynamics
Conclusion and Future Directions
Bibliography
This entry is aimed at describing cloud physics
with an emphasis on ﬂuid dynamics. As is inevi-
table for a review of an enormously complicated
problem, it is highly selective and reﬂects of the
authors’ focus. The range of scales involved and
the relevant physics at each scale are described.
Particular attention is given to droplet dynam-
ics and growth, and turbulence with and without
thermodynamics.
Glossary
Aerosol: Tiny
(0.1–1
m)
solid
particles
suspended in the air. There are about 100–1000
aerosol particles per cubic centimeter of air.
Clouds: Mixtures of air (99% by weight),
water
vapor
(1%),
liquid
water
droplets
(0.1%), aerosol particles, trace gases. Clouds
are usually in turbulent ﬂow.
Caustics: Regions of the ﬂow where particles
with different velocities arrive simultaneously
at the same location.
Supersaturation: A system that has more water
vapor than the saturation value prescribed by
the Clausius-Clapeyron equation 5.
Ventilation effects: The effects of oncoming
ﬂow on the growth of droplets. Used in the
context
of
water
droplets
growing
by
condensation.
Why Study Clouds
Clouds, since they involve many different phe-
nomena interacting with each other in complex
ways, are of interest purely from scientiﬁc curios-
ity. For instance, is it possible to predict what
cloud shapes will result for given atmospheric
conditions? More importantly, perhaps, clouds
are also immensely inﬂuential in the energy and
mass balances in the planet’s atmosphere. In fact,
clouds are the last great sources of uncertainty in
climate science.
For instance, clouds increase the planet’s
albedo, reﬂecting away sunlight before it can
make it to the surface; they also act to provide a
greenhouse effect, trapping energy radiated away
from the surface. These two opposing effects are
both of much larger magnitudes than any other
sources in the radiative balance of the planet
(Archer 2011, Chap. 6; Stevens 2013). The
response of clouds to a warming planet – whether
clouds will act to slow down or to accelerate the
planet’s warming – is not clear at present
(although very recent studies (Schneider et al.
2019) suggest that they do indeed act as positive
feedback). This uncertainty is due to the large
magnitudes of the aforementioned effects and
the fact that clouds are coupled with the global
circulation.
© Springer Science+Business Media, LLC, part of Springer Nature 2022
B. Chakraborty (ed.), Statistical and Nonlinear Physics,
https://doi.org/10.1007/978-1-0716-1454-9_741
Originally published in
R. A. Meyers (ed.), Encyclopedia of Complexity and Systems Science, © Springer Science+Business Media LLC 2020
https://doi.org/10.1007/978-3-642-27737-5_741-1
121

Similarly, the selective annual Northward
propagation of the cloud-band known as the
ITCZ (Inter-Tropical Convergence Zone) over
longitudes including those of the Indian landmass
brings the Indian monsoon, among the biggest
weather events, which provides fresh water for
close to two billion people. Understanding the
dynamics of the ITCZ requires understanding
the dynamics of clouds, which is as yet an open
problem (Bony et al. 2015). These are only a few
of the most compelling reasons to study clouds.
With the advent of machine learning and asso-
ciated statistical and data-driven techniques, and
the increasing availability of dedicated computing
power, it is tempting to rely solely on such statis-
tical
methods.
However,
understanding
the
dynamics is useful not just as a scientiﬁc exercise
but also pragmatically. Statistical techniques –
machine learning in particular – are best used in
scenarios for which they have been “trained.”
Most estimates suggest that the feedback from
clouds on the climate is likely to affect the circu-
lation
in
the
atmosphere
substantially.
The
resulting large changes in the dynamics may not
be possible to capture with machine learning tech-
niques. The planet needs us to study the dynamics
of clouds! (Schiermeier 2015).
Definition of the Subject
The ﬂuid dynamics in clouds covers length scales
from tenths of microns to hundreds of kilometers.
Being a nonlinear problem, the physics at each
scale has an effect on other scales. There are open
questions that require an understanding of the
basic physics at each scale, and also in the con-
nections between scales. The lower end of this
range concerns the chemistry and chemical phys-
ics of aerosols. Aerosols are crucial to cloud for-
mation, because they act as nuclei for droplet
formation, as will be discussed below. Aerosols
are introduced into the atmosphere in a variety of
ways, natural and anthropogenic. The production
of aerosols, especially sea-salt aerosol by the
mechanics of wave-breaking at the surface of the
ocean, is an outstanding problem of ﬂuid mechan-
ics. The upper end of the range of length scales
covers the dynamics of weather and the climate.
Signiﬁcant progress has been made in recent
years, aided by advances in supercomputing, in
the ability to make reasonable predictions of the
dynamics on these scales. The robustness of these
predictions depends, however, on understanding
the global dynamics at the “sub-grid scales.” The
intermediate range, incorporating the interactions
of buoyancy-driven ﬂuid turbulence of (dilute)
suspensions, is not only exceedingly complex,
but also controls the dynamics of processes at
the largest scales related to weather and climate.
We will describe recent progress in understanding
the dynamics in the intermediate length scales.
Studies of the cloud dynamics can be based on
observations of clouds either in the real world or
in the laboratory, or on analyses or numerical
solutions of the ﬂuid dynamical equations of
motion. Our work is in the latter, and we will for
the most part restrict ourselves to discussing the-
oretical/numerical studies of clouds, although we
do make note of some relevant experimental
studies.
An important ingredient in the intermediate
scales is that clouds are usually in turbulent ﬂow.
Turbulence consists of vortices and regions of
shear whose length scales span a large range,
starting from the biggest scale in a single cloud,
of the order of a few kilometers, to what is known
as the Kolmogorov scale , which is of the order
of a millimeter in a cloud. A turbulent ﬂow is
characterized, among other properties, by its
Reynolds number, which is a ratio of inertial and
viscous forces. Consider a cloud of length scale
L  1 km in height and width, where velocities
U are of the order of 10 m/s. The kinematic vis-
cosity n of air is about 105 m2/s. The Reynolds
number is LU/n  109.
The range of length scales involved even
within the intermediate range in clouds is vast.
Accurate direct numerical simulations (DNSs),
solving the Navier-Stokes equations or their var-
iants, have to resolve the Kolmogorov scales of
turbulence. If these scales have to be resolved in
simulations of a cloud of the length scale of
100 m, each dimension has to be resolved with
O(105) grid points. Such numerical simulations
are impossible with today’s computing resources.
122
Fluid Dynamics in Clouds

DNSs of cloud ﬂows are typically conducted only
within small boxes, of a few meters in length
(Kumar et al. 2012, 2013, 2014). In other words
a small volume within a cloud is all we can sim-
ulate. In effect experiments (on a computer or in
the laboratory) can be performed at Reynolds
numbers that are much smaller than those found
in clouds, in the hope that this will nevertheless
provide useful answers (Abma et al. 2013; de
Lozar and Mellado 2013, 2015, 2017; Pauluis
et al. 2010; Schumacher and Pauluis 2010;
Weidauer et al. 2010; Pauluis and Schumacher
2011; Narasimha et al. 2011; Ravichandran and
Narasimha 2020) at cloud Reynolds numbers (see
also section “Cumulus Clouds: Phase-Change+-
Buoyancy+Turbulence”). Workarounds for this
limitation take the form of large eddy simulations
(LESs) which resolve only the large scales of
motion
(i.e.,
they
are
“cloud-resolving”)
(Randall et al. 2003; Jarecka et al. 2009; Romps
2010; Grabowski 2014) and use models to
account for the smaller scales including the micro-
physics of phase-change.
Even simulations that resolve the Kolmogorov
scales of the ﬂow cannot resolve the scales asso-
ciated with the motion of the water droplets in
clouds, which range from about a micron to a
few millimeters. Even the simplest approach to
tracking droplets adds signiﬁcantly to the burden
of computations, given that there are O(1000)
small droplets per cubic centimeter of cloud. In
the simplest approach, the ﬁnite-sized water drop-
lets have to be treated as point particles and
tracked in a Lagrangian sense. Alternatively,
these particles can be coarse-grained into a ﬁeld.
The relative efﬁcacies of these two approaches to
particle-dynamics
are
studied
in
Mitra
and
Perlekar (2018). The effects of ﬁnite droplet size
and how this changes their dynamics is discussed
at length in section “Microphysics Without Ther-
modynamics.” These are known as “one-way
coupled” approaches, where the ﬂuid equations
are solved for without taking into account the
fact that ﬂuid is carrying particles and droplets,
whereas the dynamics of the particles and droplets
are dictated by the ﬂuid motion. For a dilute
suspension of small particles and droplets this is
a fair approach. However, larger raindrops can
affect the ﬂow and can affect the dynamics of
each other, and a perfect treatment would have
to account for the forces of these objects on the
ﬂuid and on each other (two-way or four-way
coupling). This can make computational costs
forbidding.
The thermodynamics taking place within a
cloud has an important effect on the dynamics.
Phase change results in heat release, which results
in buoyancy. The potential energy thus gained is
converted into the kinetic energy of turbulence.
Thus turbulence in a cloud is fundamentally dif-
ferent from mechanically forced turbulence, and
turbulence from heat supplied at the boundaries,
which are studied most often. We return to this
point in section “Thermodynamics of Phase-
Change.” The droplet-growth bottleneck is a
well-known open problem. Droplets can grow
quickly to about 10 m in size in a supersaturated
environment typical of clouds. Once they are
about 50 m in diameter, gravity can aid in the
process of droplet growth by enhancing collision
probability, with some fraction of all collisions
resulting in coalescence. How droplets grow
from about 10 to about 50 m is not completely
understood yet, and this is known as the droplet-
growth bottleneck. Turbulence is widely accepted
now to be a big part of the answer, and this is
discussed below.
Most present-day studies assume that water
droplets are spherical in shape whereas larger
drops are sensitive to gravity and can distort in
shape from the spherical, even to the point where
they adopt shapes which are locally sheet-like,
which then causes breakup into smaller droplets.
Ice crystals are most often not spherical. Thus, the
roles of shape, surface tension, gravity, and even
surface chemistry on the dynamics have to be
studied. These effects are also important in the
thermodynamics
of
water
droplet
growth
(discussed
in
section
“Thermodynamics
of
Phase-Change”) and in the collisions-coalescence
of water droplets (section “Microphysics Without
Thermodynamics”).
Another important attribute is that over the
length-scales that clouds occupy in the atmo-
sphere, air is a compressible ﬂuid. Note that the
Earth’s atmosphere at a height of 10 km is only a
Fluid Dynamics in Clouds
123

tenth as dense as it is on the ground. So a parcel of
air, as it rises, will undergo signiﬁcant expansion,
which
cannot
be
neglected
by
assuming
incompressibility. The equations of compressible
ﬂuid motion are signiﬁcantly more complicated
than those of an incompressible ﬂuid (which itself
is a “Millennium problem”). The fully compress-
ible equations of motion for air contain sound
waves which operate on very short timescales.
These sound waves are unimportant for the
dynamics of interest to us and computing them
would require short timesteps and greatly increase
the
computational
requirements.
Fortunately,
since the Mach numbers Ma associated with the
ﬂow are small, the thermodynamic pressure of the
ambient can be decoupled from the pressure ﬂuc-
tuations due to the motion (which are O(Ma2)
relative to the thermodynamic means). This
allows the use of the anelastic equations for
ﬂows over large heights or the incompressible
equations for shallow ﬂows, the latter of which
is the limit we are concerned with. A sketch of the
derivation of the anelastic and incompressible
equations from the compressible equations may
be found in Durran (1989) and Bannon (1996). As
the name suggests, the anelastic equations “ﬁlter
out” the sound waves from the dynamics, leaving
only the effects of compressibility on the large
scale dynamics. On relatively small scales, the
assumption of incompressibility is reasonable
and is typically made in studies of the ﬂows in
shallow clouds (Pauluis et al. 2010; Schumacher
and Pauluis 2010; Weidauer et al. 2010; Pauluis
and Schumacher 2011), and even in some
idealized
studies
of
deep
convection
(Hernandez-Duenas et al. 2013).
As we see in Fig. 1, the dynamics of clouds is
an interplay of particle inertia, thermodynamics,
the resulting buoyancy-driven ﬂow. At the largest
scales, the effect of Earth’s rotation, and solar
radiation and its modiﬁcation by clouds, need to
be understood better, and we do not deal with
these topics in the present entry.
In summary, studies at different scales have to
sometimes be carried out in isolation, using
approaches and assumptions appropriate for that
scale. New physics is revealed at each scale, and
their effects must then be included in our studies at
other scales.
Microphysics Without Thermodynamics
A simple framework, which ignores the effects of
thermodynamics, phase changes, and the associ-
ated changes in temperature, to understand the
physics of a single warm cloud is to model it as
a dilute suspension of small, spherical water drop-
lets of radius a which are advected by a statisti-
cally stationary, homogeneous, and isotropic, full-
developed turbulent ﬂow. Such an approach
ignores the effect of condensation, arising from a
super-saturated environment, by assuming that
the starting point of such studies are non-
precipitating droplets which are already con-
densed to sizes of about 10 mm; hence further
growth through condensation over a reasonably
short time window, corresponding to the life-time
Fluid Dynamics in
Clouds, Fig. 1 Cloud
dynamics as the sum of its
components
124
Fluid Dynamics in Clouds

of such a cloud, is unlikely (Shaw 2003;
Grabowski and Wang 2013; Lanotte et al. 2009;
Bodenschatz et al. 2010; Devenish et al. 2012).
Such a simpliﬁcation has at least two distinct
advantages. Firstly, it allows us to formulate and
address questions of collisions, coalescences, and
gravitational settling (precipitation) in the turbu-
lent setting of a cloud in a precise way. Secondly,
given this framework, it lends itself easily to the
use of tools and ideas developed in the ﬁeld of
turbulent transport over the last two decades or so.
In typical clouds, given a/  1, the Reynolds
number associated with a droplet Rep  1. This
allows us to deﬁne the dynamics of a droplet, in
the presence of a gravitational force g and an
(turbulent) advecting ﬂuid velocity u, in terms of
its position xp and velocity v, through the linear-
ized Stokes drag model with a Stokes time tp
(Ravichandran et al. 2017a):
dxp
dt ¼ v;
ð1aÞ
dv
dt ¼  v  u xp


tp
þ g:
ð1bÞ
The velocity ﬁeld of the carrier ﬂow, driven to a
statistically steady state through a force f, with
density rf, a kinematic viscosity n, and a pressure
ﬁeld
P,
satisﬁes
the
incompressible,
three-
dimensional Navier-Stokes equation
@u
@t þ u  ∇
ð
Þ ¼ n∇2u  ∇P
r f
þ f;
ð1cÞ
∇ u ¼ 0:
ð1dÞ
Given the assumptions of a small droplet and a
dilute suspension, the underlying ﬂow is assumed
to be unaffected by the presence of such water
droplets.
The effect of the ﬁnite size and the density
contrast of the particle with the carrier ﬂow,
which leads to a ﬁnite time of relaxation of the
particle velocities to that of the ﬂuid, are captured
by the Stokes time tp ¼
2a2rp
9nr f , where the particle
density is given by rp; for clouds (water droplets
in air), the ratio of these two densities is
rp/rf  1000. However, it is useful to measure
this inertia of the particles in terms of the non-
dimensional Stokes number St ¼ tp/t, where
t ¼
ﬃﬃﬃﬃﬃﬃﬃ
n=ϵ
p
is the characteristic, short-time, Kol-
mogorov time-scale of the ﬂuid (ϵ is mean energy
dissipation rate). Such nondimensional numbers
allow an easy comparison between observations,
experiments, theory and numerical simulations.
The linear Stokes drag model (Eqs. 1a and 1b)
is, of course, in the heavy-particle limit rp  rf, a
simpliﬁcation
of
the
Maxey-Riley
equation
(Maxey and Riley 1983) for the motion of a
spherical particle (with Rep  1) in a ﬂow:
rp
dv
dt ¼ r f
Du
Dt þ
rp  r f


g
 9nr f
2a2
v  u  a2
6 ∇2u


 r f
2
dv
dt  D
Dt u þ a2
10 ∇2u
	



 9r f
2a
ﬃﬃﬃ
n
p
r ðt
0
1
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
t  x
p
d
dx
v  u  a2
6 ∇2u


dx
ð2Þ
where D
Dt denotes the full convective derivative
and it factors in the effects of the force due to the
undisturbed ﬂow r f
Du
Dt, the buoyancy (rp – rf)g,
the Stokes drag
9nr f
2a2
v  u  a2
6 ∇2u


, the added mass
r f
2
dv
dt  D
Dt u þ a2
10 ∇2u
	



, and the Basset history
9r f
2a
ﬃﬃﬃ
n
p
r ðt
0
1
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
t  x
p
d
dx
v  u a2
6 ∇2u


dx effects. Without
going into a rigorous demonstration of how
Eq. 2 reduces to Eq. 1b, we can immediately see
that for heavy particles the force due to the
undisturbed ﬂow is negligible and the only effect
of gravity is a net acceleration downwards. Fur-
thermore, the Faxen corrections a2∇2u for small
particles are negligible as is the Basset term in
such dilute suspensions of passive particles.
(On the last aspect, we refer the reader to a recent
work by Prasath et al. (2019) for a detailed anal-
ysis of the Basset history term.) Indeed recent
work by Saw et al. (2014) has conﬁrmed by com-
paring experimental data with those obtained
from a numerical simulation of Eqs. 1, that the
approximations
discussed
here
are
indeed
Fluid Dynamics in Clouds
125

reasonably valid for the dilute suspensions of
small, but heavy, particles that we consider in
this entry.
Before we proceed further, it might be useful at
this stage to comment on how Eqs. 1 is solved on
the computer (Canuto et al. 2006). (See Pandit
et al. (2017) for a discussion on the nature of
such simulations in two-dimensional ﬂows.) The
incompressible Navier-Stokes equations (Eqs. 1c
and 1d) are typically solved, in three dimensions,
on triply periodic cube of side 2p with N3 collo-
cation points; in the results being reviewed in this
entry, N has ranged from 512 up to 2048 yielding
Taylor-scale
based
Reynolds
number
which
ranges from (approximately) 120 to 450. The
ﬂow is driven to a statistically steady, homoge-
neous, and isotropic, turbulent state with an exter-
nal forcing. There is of course considerable
freedom in the way we choose to force the ﬂuid;
two particularly popular choices are one with a
constant energy injection at low wavenumbers
(Sawford 1991) and another where (again at
low-wavenumbers)
a
second-order
Ornstein-
Uhlenbeck process (Lamorgese et al. 2005) is
adapted to provide a more random forcing. The
equations themselves are solved through a stan-
dard pseudo-spectral method where spatial deri-
vates are taken in Fourier space to allow an easy
integration in time of what essentially becomes an
algebraic equation.
Solving for the particle dynamics (Eqs. 1a and
1b) is less involved. The only nontrivial element
in this is to use suitable interpolation schemes to
obtain the ﬂuid velocity, which is calculated on a
regular Eulerian grid, at typically off-grid particle
positions. Several such schemes exist and the ones
commonly used are the cubic spline, the B-spline,
the trilinear, or the cubic interpolation schemes
(see e.g. van Hinsberg et al. 2013).
The consequences of the linear Stokes drag
model have been studied extensively (Bec et al.
2005; Chun et al. 2005; Bec et al. 2007; Monchaux
et al. 2012; Gustavsson and Mehlig 2016; Ireland
et al. 2016) since the pioneering work of Bec (Bec
2003; Bec 2005). A detailed discussion of this is
certainly beyond the scope of this entry. However,
in what follows, it is useful to recall two central
features of the dynamics deﬁned by Eqs. 1, namely
preferential concentration and caustics.
The dissipative dynamics of the particle
motion leads to a preferential sampling of the
ﬂow and hence a preferential concentration
of particles for ﬁnite Stokes numbers (seen in
Fig. 2), as opposed to a homogeneous distribution
in the ﬂow seen for tracer particles with St¼0.
Particles with ﬁnite sizes evolve to (dynamically
changing) attractors with fractal dimensions. Tra-
ditionally, this preferential concentration or inho-
mogeneities in the distribution of particles is
captured through the correlation dimension D2
obtained from calculating the probability P<(r)
of two particles being within a distance r, with
P< rð Þ  rD2. The correlation dimension D2 is of
course a function of the Stokes number St. In the
limit of vanishing St (tracers), particles must dis-
tribute homogeneously and hence, in a three-
dimensional ﬂow, D2 ¼ 3. For very large values
of St, the motion of particles is essentially
decorrelated from the ﬂow and thus has a more
ballistic behavior. This results, yet again, is space-
ﬁlling and consequently D2 ¼ 3. At intermediate
values of St, however, the particle distributions
are inhomogeneous D2 < 3 and maximal cluster-
ing (or inhomogeneities) is observed (with an
accompanying minimum in D2) for St
 O 1
ð Þ.
We refer the reader to Figs. 1 and 2 in Bec et al.
(2007) for an illustration of these effects.
From the perspective of ﬂow structures, the
clustering of heavy inertial particles can be tied
to their ejection from vortical or rotational regions
of the ﬂow. One way to quantify this behavior is
via the Q -criterion (Dubief and Delcayre 2000),
which uses the local velocity gradient matrix A to
deﬁne a quantity Q 
R2
ij  S2
ij


=2 (where R ¼
A þ AT
ð
Þ=2and S ¼ A  AT
ð
Þ=2). Regions dom-
inated by rotation (straining) have Q > 0 (< 0).
Figure 3a presents the Lagrangian probability dis-
tribution functions (PDFs) of Q measured along
the trajectories of tracers and inertial particles with
various values of St. The undersampling of vorti-
cal regions by inertial particles is clearly visible;
indeed the effect is signiﬁcant even for St as small
as 0.03 (relevant for 10–20 mm cloud droplets).
This effect gets stronger up to St  0.5, beyond
which the particles begin to decorrelate from the
underlying ﬂow structures, until eventually, for
large St, the PDF approaches that for tracers
(cf. St ¼ 8.3 in Fig. 3a).
126
Fluid Dynamics in Clouds

The fact that ejection from vortices leads to
concentration and clustering in straining regions
is apparent in Fig. 3b, which presents a coarse-
grained particle number density (using cubic bins
of side 20) conditioned on the local value of Q
for various St. As St increases from zero, the
Fluid Dynamics in Clouds, Fig. 2 Snapshots of tracers
(a) and inertial particles (b), with St ¼ 0.1, in a three-
dimensional turbulent ﬂow. Particles in regions dominated
by rotation (Q > 0) are colored red, while those in regions
dominated by straining (Q < 0 ) are colored blue. The
dissipative dynamics of inertial particles (St ¼ 0.1) causes
them to form dynamic clusters, which are seen in panel (b)
to mainly reside in straining regions, in accordance with
the ejection of inertial particles from rotational zones
Fluid Dynamics in Clouds, Fig. 3 Panel (a) presents
PDFs of Q sampled by tracers and inertial particles with
various values of St. Panel (b) shows the average coarse-
grained particle number density, conditioned on the local
value of Q , for various St
Fluid Dynamics in Clouds
127

density of particles in regions of moderate
straining increases, while the density in rotational
regions reduces. This is illustrated visually by
Fig. 2b, wherein most of the dense particle clus-
ters are blue (Q < 0). Figure 3b also shows that
particle density reduces with St in regions of very
high straining, indicating that inertial particles
cannot cluster in such intense regions of the
ﬂow, but rather prefer mildly straining zones.
A second important ingredient in this story is
caustics (Ravichandran and Govindarajan 2015).
Caustics are deﬁned here as regions in the ﬂow
where droplets of different velocities can arrive
simultaneously at the same location. In other
words, caustics are regions of the ﬂow where the
droplet velocity cannot be described as a ﬁeld.
These are signiﬁcant for the following reason.
Droplets of moderate Stokes number ( 0.1 to 1)
get ejected quickly out of vortices, and this
increases their propensity to collide and coalesce,
but smaller droplets are usually taken to behave
like passive scalars, just advecting passively with
the ﬂow. Under this assumption no preferential
concentration takes place for small droplets, and
collisions would be extremely rare. We thus do not
have a mechanism by which small droplets can
coalesce and begin to cross the bottleneck. In the
immediate vicinity of a single vortex of circulation
G, that is, within a distance 
ﬃﬃﬃﬃﬃﬃﬃﬃ
Gtp
p
from the
vortex centre, even the smallest droplets are
centrifuged out (Ravichandran and Govindarajan
2015), and caustics can form. It was shown
(Ravichandran and Govindarajan 2015; Deepu
et al. 2017) that collisions between small droplets
can be greatly enhanced in the caustics region,
giving rise to a small number of droplets which
can cross the bottleneck, and become the seeds for
further coalescence events.
Given this context, let us return once more to
questions within the framework of turbulent trans-
port which are pertinent to the problem of droplet
dynamics in a warm cloud. In particular, the ques-
tions that we discuss in this entry have to do with
collisions, coalescences, and precipitation. Spe-
ciﬁcally these are best discussed by answering
the following questions: How fast – and where –
do droplets collide? How fast do droplets grow
(by coalescence)? And, how fast do droplets settle
under gravity? (The issue of the structure of such
aggregates when they collide, but not coalesce,
will not be covered in this overview (Bec et al.
2013; Gupta et al. 2018).)
Turbulence is thought to play a dominant role
in enhancing the droplet-droplet collision rates,
and in turn the droplet-size distributions as well
as the initiation time of rain, in typical warm
clouds (Shaw 2003; Falkovich et al. 2002). The
underlying mechanism instrumental in this is not
only preferential concentration, discussed above,
but also, through slings (Falkovich et al. 2002;
Bewley et al. 2013) and caustics (Wilkinson et al.
2006; Falkovich and Pumir 2007), the extreme
velocities with which particles can approach
each other. Therefore in order to gain insights
which can help build mesoscopic models for col-
lision kernels, it is important to have reliable esti-
mates of the typical relative velocities between
droplets
which
are
about
to
collide
in
a
turbulent ﬂow.
This issue was addressed by Saw et al. (2014)
who, through experiments, numerical simula-
tions, and theory, studied the probability distribu-
tion functions of the velocity differences between
pairs of particles, measured along the line-of-
sight, when they are quite close to each other. In
the experiment, a turbulent ﬂow was generated
within a 1 m-diameter acrylic sphere (Bewley
et al. 2013) with Taylor microscale Reynolds
numbers Rl as high as 190 corresponding to
values of  as low as 180 mm. In such a ﬂow, a
bi-disperse population of droplets was introduced,
via a spinning disc (Walton and Prewett 1949),
with mean diameters 6.8 mm and 19 mm which are
much smaller than . Given that the experiment
was able to achieve three different Rl, and hence
, it was possible to obtain particle trajectories for
six different Stokes numbers through stereoscopic
Lagrangian Particle Tracking (Ouellette et al.
2006). Particle trajectories obtained from numer-
ical simulations, with similar Stokes numbers and
Rl as the experiments, make meaningful compar-
isons of theory and experiment possible.
A convenient measure of the statistics of how
droplets collide is through the probability distri-
bution function of the longitudinal component of
the velocity differences v|| between pairs of
128
Fluid Dynamics in Clouds

particles and conditioned on their separation r. In
Fig. 1 of Saw et al. (2014), these distribution
functions for four different values of the Stokes
number and, in each case, conditioned on three
different values of the separation r are shown. The
agreement between the experimental and numeri-
cal data, especially for the larger values of St, is a
conﬁrmation of the validity of the linearized
Stokes drag model of Eqs. 1. However, it is
worth pointing out that these distributions, which
seem to ﬁt the form of stretched exponentials
(Kailasnath et al. 1992) and at odds with the
compressed exponential
prediction for large
Stokes numbers (Gustavsson et al. 2008), show
consistently, for reasons still not clear, a greater
convergence between the numerical and experi-
mental data for the left tail (approaching pairs)
than for the right tail (separating pairs). Further-
more, a closer examination of these distributions
shows that droplet-pairs approach each other with
increasing relative velocities – and a possible
increase in collision rates – as their Stokes number
increases consistent with other evidences of the
sling effect (Bewley et al. 2013).
These distributions were of course conditioned
on small (O 
ð Þ) but still ﬁnite separations; in the
context of understanding collisions among drop-
lets in a cloud, we should examine the relative
velocities at contact or at least when they are even
closer to each other (r ! 0). It turns out that all
these distributions can be collapsed on top of one
another (Fig. 2 in Saw et al. (2014)) by a simple
rescaling with rb; experimental and numerical
data suggests that b has a mild Stokes-dependence
and for reasonably large values of St (not entirely
valid for droplets in a cloud at its infancy),
corresponding to extreme velocity differences,
its value is consistent to the saturation exponent
x1 of the higher-order moments of relative veloc-
ities (Bec et al. 2010). The positive exponent b,
which is small for small droplets, nevertheless
suggests the possibility of mild impact velocities
on contact.
The particle dynamics in a more realistic cloud
is of course nonstationary as droplets grow and
change their sizes and numbers. A step in this
direction is to account for the polydispersity in a
suspension. James and Ray (2017) investigated
this problem for suspensions in two- and three-
dimensional turbulent ﬂows. Interestingly, the
authors were able to derive the typical impact
velocities between particle pairs which, in princi-
ple, could have different Stokes numbers. This
was conveniently done by assuming a reference
particle with a Stokes number St1 and a second
one with St2; in the usual mono-disperse problem,
St2 ¼ St1. Assuming the smoothness of the under-
lying ﬂuid velocity at small interparticle separa-
tions, the impact velocity D was theoretically
calculated (under suitable approximations) for
pairs of droplets with different Stokes numbers
and validated against numerical simulations.
As we discussed before, because of the
collision-coalescence processes, it is safe to
assume that particle dynamics in a cloud may
well be nonstationary. As a result of this James
and Ray have also looked at the collision rates in a
nonstationary phase and found an enhancement of
this, when compared to the collision rates in the
statistically stationary phase for all nonzero
Stokes numbers. Interestingly, this ratio peaks to
2 (Fig. 4 in James and Ray (2017)) when the
Stokes number of the colliding pairs is around
0.2. Although the results obtained suggest a lack
of universality, this observation might be one pos-
sible explanation of possible run-away processes
which explains the rapid growth of droplets from
tiny nuclei, seed rain drops. We also refer the
reader to recent studies in Gustavsson and Mehlig
(2011, 2013), Meibohm et al. (2017), Bhatnagar
et al. (2018a, b) on the issue of such polydisperse
suspensions and the relative velocities of colliding
inertial particles in turbulent ﬂows.
All of this inevitably leads us to the question of
how the size distribution of droplets evolves when
we turn on actual coalescences in a suspension
advected by a turbulent ﬂow. A time-honored
theoretical framework for studying such problems
is the Smulochowski’s equation with a stationary
coalescence rate or kernel. Starting with an initial
inﬁnite bath of particles of the same size (and
mass), such an approach inevitably leads to a
growth in the population of droplets of larger
sizes as a simple power-law in time. Speciﬁcally,
assuming an initial inﬁnite bath of particles of
mass 1, the number of particles with mass i
Fluid Dynamics in Clouds
129

(also, in these units, an integer since coalescence
imposes mass conservation) grows as
ni tð Þ  e; ni
1 t=ti
ð
Þi1:
ð3Þ
(The time ti appearing in the exponent is taken as
an average time-scale set by the different station-
ary collision rates between all particle pairs which
add up to give the i-th particle.)
However, when such particles are in a dilute
suspension carried by a turbulent ﬂow, how
accurate are these estimates emerging from
Smulochowski’s equation? This question was
answered, through a combination of theory and
numerical simulations, by Bec et al. (2016). This
work carefully analyzed the contribution to the
coalescence rate coming not from the microphys-
ics of adhesion but the fact that particles are in a
turbulent ﬂow. This nontrivial contribution was
shown to factor in the anomalous part d3 in
the scaling of the third-order structure function
in a turbulence-advected passive-scalar ﬁeld
y x þ r
ð
Þ  y x
ð Þ
ð
Þ3
D
E
 rj j1d3
and leads to a
population growth of the form
ni tð Þ  e; ni
1 t=eti

 13
2d3
ð
Þ i2
ð
Þþ1:
ð4Þ
Given that the (universal) value of d3  0.18,
this form suggests a more rapid growth of droplets
with masses different from the bath of monomers
of mass 1.
The accuracy and correctness of the theoretical
calculations were benchmarked against the state-
of-the-art direct numerical simulations with an ini-
tial suspension of one billion monomers which
were then allowed to coalesce and form droplets
of other sizes in the same paper (Bec et al. 2016).
Figure 2 in this work shows the accuracy of the
prediction (4) at early times; a further conﬁrmation
of the importance of anomalous scaling was
obtained via the probability density function of
the inter-coalescence times between the initial
monomers (of mass 1) and other droplets of differ-
ent sizes which were subsequently formed (Fig. 3
in Bec et al. (2016)). Remarkably, these results are
perhaps the only ones that show how anomalous
scaling in turbulence shows up as a leading order
effect in a more applied problem such as the one of
coalescences in turbulent transport.
Fluid Dynamics in
Clouds, Fig. 4 Snapshot
of intense rotational (red)
and straining (blue) regions
in a turbulent ﬂow,
visualized using the Q -
criterion. Intense vortical/
rotational regions take the
form of tubes or worms that
are enveloped by strongly
straining sheet-like
structures, forming vortex-
strain wormrolls.
(Reproduced from Picardo
et al. 2019)
130
Fluid Dynamics in Clouds

This work thus established a plausible argu-
ment to suggest a rapid growth in droplets at
short times through a complex (Lagrangian) cor-
related sequence of events. However, the fate of
these droplets at long time still remains a large
unexplored issue.
All of these measurements are of course central
in building up models for collision and coales-
cences in a warm cloud. However, they do not
help us, in a direct way, to uncover the correlation,
if any, between collisions and the ﬂow structures
peculiar to turbulence. Indeed, even small-scale,
homogeneous and isotropic turbulence, which we
may expect to encounter in the core of a cumulus
cloud, is rich in structure: It is perforated by a
hierarchy of rotational and straining ﬂow struc-
tures (She et al. 1990; Douady et al. 1991;
Jiménez and Wray 1998; Zeff et al. 2003;
Schumacher et al. 2010; Davidson et al. 2012),
as shown in Fig. 4. These structures are a physical
manifestation of the intermittency of the velocity
gradient
ﬁeld,
which
distinguishes
fully-
developed turbulence from a simple random
Gaussian ﬁeld (Ishihara et al. 2007; Pandit et al.
2009; Tsinober 2009). One may ask, therefore,
whether the collisions between inertial particles
or droplets are sensitive to these ﬂow structures,
and thereby to the non-Gaussian nature of
turbulence. This question was addressed recently
by Picardo et al. (2019), who measured the rela-
tive values of rotation (R2) and straining (S2) at the
locations of collisions, and compared them to the
values sampled by particle trajectories. They
found that collisions among small St particles are
disproportionately frequent in straining regions,
much more than what may be anticipated from
preferential concentration alone. In fact, this effect
is not fundamentally tied to inertia, but persists
even in the limit of St ! 0, for which the particles
are homogeneously distributed. (In this limit, the
particles are effectively tracers, but with a small
ﬁctional radius that enables the detection of
collisions.)
Figure 5a presents contours of the joint proba-
bility distribution of the values of R2 and S2,
measured both where inertia-less particles reside
(dashed contours) and where they collide (solid
contours). Here, straining (rotational) regions
with Q
< 0.3 (> +0.3) are shaded in blue
(red).
Clearly,
there
is
an
oversampling
(undersampling) of straining (vortical) regions
by collisions, compared with the particle trajecto-
ries. This discrepancy is a result of the very dif-
ferent ﬂow geometry in these regions. Colliding
particles in straining regions tend to approach
each other in a head-on or rear-end fashion,
Fluid Dynamics in Clouds, Fig. 5 Panel (a) presents the
0.1 and 0.03 level contours of the joint probability distri-
bution function of the values of R2 and S2, measured at the
positions of inertia-less (St ¼ 0) particles (dashed) and at
their collision locations (solid). Panels (b) and (c) present
distributions of the collision angles and the collision veloc-
ities, respectively, conditioned on whether the collisions
occur in rotational (Q > +0.3, red) or straining (Q < 0.3,
blue) regions. The contribution of these regions to the joint
distribution in panel (a) is shown by the red/blue shading.
Taken together, these panels show that collisions in
straining regions tend to occur in a head-on or rear-end
fashion, which results in a higher collision approach veloc-
ity, and thereby a higher collision frequency. (Reproduced
from Picardo et al. 2019)
Fluid Dynamics in Clouds
131

whereas particles in rotational regions approach
each other in a side-on manner and undergo glanc-
ing collisions. This is shown by the conditioned-
PDFs of the collision angle y (the angle between
the relative velocity and position vectors of the
two colliding particles), presented in Fig. 5b. For a
given magnitude of the underlying ﬂuid velocity,
head-on collisions are faster than side-on colli-
sions, as shown in Fig. 5c, because a larger com-
ponent of the relative-velocity of the particles is
translated into the collision velocity. For the same
number density of particles, this results in a higher
collision frequency in straining regions.
Particle inertia acts to enhance this preference
of collisions for straining regions, up to St  0.3.
This is seen in Fig. 6a, which presents the average
value of Q ¼ (R2  S2)/2 measured at particle and
collision locations, as a function of St. At small St,
inertia selective enhances the collision velocity in
straining regions, as shown in Fig. 6b, and there-
fore increases the frequency of collisions in
straining regions relative to rotational regions. At
larger values of St, however, the particles begin to
decorrelate from the underlying ﬂow structures
and both particle and collision locations begin to
distribute uniformly (cf. the inset of Fig. 6a) and
also
collide
with
comparable
velocities
in
straining and vortical regions (Fig. 6c). This mis-
match between where inertial (for small St) parti-
cles reside and collide was earlier observed by
Perrin and Jonker (2014), who also analyzed the
inﬂuence of ﬂow structures on collisions using the
eigenvalues of the velocity gradient matrix (Perrin
and Jonker 2016), which enable a ﬁner classiﬁca-
tion of structures than the simple Q -criterion.
We have seen that collisions between small St
particles are sensitive to the local underlying
structure of the ﬂow. As St approaches unity,
however, collisions are affected not just by the
structure at the collision location, but by all the
ﬂow structures encountered by the particles, up to
a time of about tp prior to the collision, or up to a
distance of |v|tp around the collision. This raises
the possibility of intense vortical and straining
regions conspiring to generate violent, rapid col-
lisions, due to their peculiar vortex-strain worm-
roll geometry (cf. Figure 4): Particles in intense
vortex tubes will be ejected with large slip veloc-
ities into the enveloping straining sheets, where
they have a high chance of colliding with large
Fluid Dynamics in Clouds, Fig. 6 Panel (a) presents the
average value of Q measured where inertial particles or
droplets collide (black-solid) and reside (dashed-red), as a
function of St. The inset presents the same result for a wider
range of St using a semi-log scale. Panel (b) presents the
average collision velocity, conditioned on whether colli-
sions occur in regions dominated by rotation (red) or strain
(blue), as a function of St. (Adapted from Picardo et al.
2019)
132
Fluid Dynamics in Clouds

relative velocities. Picardo et al. (2019) found
evidence for this scenario, by Lagrangian back-
tracking of particles that collided in straining
regions: the particles that collided in the least
time after being ejected from a vortex were indeed
the ones that originated from the strongest vorti-
ces, collided in the strongest straining regions and
with the largest collision velocities.
This effect of vortex-strain worm rolls was
found to be prominent only for St beyond about
0.5. This value may seem too large for small cloud
droplets, and indeed it is when one considers the
particle relaxation time relative to the mean Kol-
mogorov time-scale of the turbulent ﬂow. However,
at the extremely large Re of in-cloud turbulence,
there are likely to be a few, very intense, intermit-
tent vortices, with a local ﬂow time scale that is
much smaller than the mean Kolmogorov time-
scale. This means that local, effective St of particles
in the vicinity of such intense vortices will be closer
to unity, making the vortex ejection and collision
scenario relevant. Even if such intense vortices
occupy a very small volume fraction of the ﬂow,
the rapid collisions generated will be able to act as a
seed that initiates the runaway growth of droplets
by
gravitational
driven
collision-coalescence
(Kostinski and Shaw 2005).
Unfortunately, the Re values that can be
directly simulated on a computer are still orders
of magnitude smaller than what is expected for a
cloud. Therefore, it is not possible to directly
investigate the effect of high-Re ﬂow structures.
However, one can gain a basic understanding of
how such structures may inﬂuence the motion and
collisions of droplets by using model vortex
ﬂows. Such an analysis was carried out in two
dimensions, using point and Gaussian vortices, by
Ravichandran
and Govindarajan
(2015) and
Deepu et al. (2017), and later extended to a
three-dimensional Burgers vortex (1948) by
Agasthya et al. (2019). These studies show that
particles near the core of a strong vortex are
ejected more rapidly than particles farther away.
This leads to a large increase in the local particle
density around the periphery of the vortex (Fig. 3
of Agasthya et al. (2019)), as well as large relative
velocities
between
neighboring
particles
(caustics). These factors combine to signiﬁcantly
enhance collisions in the vicinity of the vortex.
Figure 7 shows the coarse-grained collision den-
sity Y (obtained from a large ensemble of simu-
lations) as a function of the radial distance r from
the axis of a Burgers vortex, which serves as a
model for the intense vortex tubes (Gibbon et al.
1999;
Davidson
2004)
observed
in
three-
dimensional turbulence (cf. Fig. 4) (She et al.
1990; Douady et al. 1991). Three cases are pre-
sented, corresponding to a mild, wide vortex
(rcore
¼
0.4)
and
an
intense
thin
vortex
(rcore ¼ 0.2), with mild and strong axial straining
(s ¼ 0.08 and 0.3, respectively). The straining
ﬂow along the vortex axis is seen to enhance the
number of collision produced around an intense
vortex, by drawing particles in toward the core of
the vortex.
Taken together, these results show that colli-
sions are deﬁnitely sensitive to the structure of the
turbulent ﬂow, and suggest that the intense and
intermittent vortex-strain structures, characteristic
of turbulence, may play a key role in the coales-
cence driven growth of droplets in clouds.
Fluid Dynamics in Clouds, Fig. 7 Coarse-grained colli-
sion density Y, that is, the number of collision per unit
volume, as a function of the radial distance r from the axis
of a tubular Burgers vortex. rcore is a measure of the size of
the core of the vortex, that is, of how intensely the vorticity
in concentrated about the vortex-axis. s is a measure of the
straining ﬂow that is directed inward along the radial direc-
tion and outward along the vortex-axis. This straining is
essential for maintaining a concentrated vortex tube in a
viscous ﬂuid, where vorticity continuously diffuses out-
ward (Davidson 2004). Here, we see that this straining ﬂow
also acts to enhance the collisions around intense vortices.
(Reproduced from Agasthya et al. 2019)
Fluid Dynamics in Clouds
133

Before we conclude this section, let us touch
upon brieﬂy the question of how such droplets
settle under gravity. The mean settling velocity
Vs, that is, the component of the particle velocity
along the direction of gravity, of a particle with a
Stokes time tp is simply (1b) Vs ¼ tpg – huz(xp, t)i.
In the absence of a ﬂow or a uniform sampling of
the ﬂow by the particles, huz(xp, t)i ¼ 0 and leading
to a predictable settling velocity Vs ¼ tpg. How-
ever, in the presence of a background turbulent
ﬂow, it has been known that the settling velocity
can be enhanced through an oversampling of the
regions where the ﬂuid velocity is downwards.
A systematic and quantitative understanding of
this phenomenon was carried out by using exten-
sive numerical simulations and theory by Bec
et al. (2014).
A convenient way to estimate this enhancement
of the settling velocity is to measure the relative
increase DV ¼ (Vs  tpg)/(tpg) ¼  huz(xp, t)i/
(tpg) as a function of the Stokes number. In Fig. 2
of Bec et al. (2014), the authors showed the Dv is
indeed positive and a non-monotonic function of
St with a peak at St  1. This enhancement, in the
limit of small values of St, was understood
by showing that the correlation
uz∇⊥v
h
i ¼
t2
pg
@zuz
ð
Þ2
D
E
> 0: This shows that clustering of
particles on any horizontal plane (perpendicular to
the direction of gravity) – and hence ∇⊥ v < 0 –
occurs at points in the ﬂow where the ﬂuid veloc-
ity is downwards since for the overall correlation
function to be positive uz < 0. Such an asymp-
totics also suggests that for small Stokes numbers
Dv / St.
The large Stokes asymptotics, dominated by the
ballistic motion of particles resulting in a short-time
correlation with the ﬂuid velocity being sampled by
the particle, is more involved. However, the
remarkable thing about this asymptotics is it
makes a scaling prediction on Dv in terms of the
Reynolds, Froude, and Stokes numbers which are
shown, through numerical simulations (Fig. 2 in
Bec et al. (2014), to be exceptionally accurate.
From the perspective of warm clouds, the nature
of setting of droplets under gravity has one further
important consequence. Bec et al. (2014) showed
that gravitational settling, especially when the
effect of gravity is pronounced, is accompanied
by a quasi-two-dimensionalization of the particle
dynamics
(Fig.
3
in
Bec
et
al.
(2014)).
A consequence of this is the estimation of the
collision rate k  rg which is the average longitu-
dinal velocity differences between pairs of same-
sized particles at a separation r2a   as they
approach each other. It was shown that since
g ¼ x1 + D2–1, where x1 is exponent of the
order-1 structure function constructed from particle
velocities, the approach rates must be inﬂuenced by
the nature of clustering D2 brought about through
gravitational settling. Figure 4 in Bec et al. (2014)
summarizes these exponents with their dependence
on both the Stokes and Froude numbers and shows
how, under the inﬂuence of gravity, interparticle
approach velocities are diminished, through a
renormalized effective Stokes number, as the effect
of gravity begins to dominate. Indeed, these results
suggest that for 30 mm-sized water droplets, typical
in warm clouds, collision rates are almost doubled
when we factor in the interplay of both gravita-
tional and turbulent effects on their mixing. These
ideas of settling are now being extended to sphe-
roidal particles in turbulent ﬂows which serve as an
effective model for ice crystals in colder clouds
(Roy et al. 2018; Anand et al. 2019).
The ﬁndings above are obtained at moderate
Reynolds number, while the Reynolds numbers in
a cloud are several orders of magnitude higher. We
highlight the importance of understanding how
ﬂow structures and other features change with
increasing Reynolds numbers. Moreover buoy-
ancy effects can be important, as discussed below.
Microphysics with Thermodynamics
In the previous section we discussed how turbu-
lence affects the dynamics of droplets, clustering
droplets into high-strain regions, and enhancing
droplet collision-coalescence. We assumed that
droplets do not affect the turbulence. Mechanically
speaking, this is a fair assumption through most
stages of droplet growth. This is because water
droplets are very small, and form a very dilute
suspension, in that occupy only a millionth of the
volume in a cloud. However, droplets can distort
134
Fluid Dynamics in Clouds

the turbulence that drives them through the ther-
modynamics associated with phase change. Some
of the physics behind these effects was explained in
Ravichandran and Govindarajan (2017).
Thermodynamics of Phase-Change
The condensation of water vapor into water and
the evaporation of liquid water into vapor
(hereafter just phase-change) are governed by
the Clausius-Clapeyron law,
dps
dT ¼ Lvps
RvT2 ,
ð5Þ
where ps is the equilibrium water vapor pressure at
the temperature T, Lv is the enthalpy of vaporiza-
tion, and Rv is the gas constant for water vapor.
The Clausius-Clapeyron law can be derived from
the condition that the vapor-liquid system is at
equilibrium at the given temperature (see, e.g.,
Bohren and Albrecht 1998, Chap. 5). This equa-
tion can be integrated assuming Lv and Rv are
constants (this is a reasonable assumption) to give
ps ¼ p0
s exp
Lv
Rv
1
T0  1
T
	



:
ð6Þ
Further approximation is possible for small
temperature changes (T0  T) to give
ps ¼ p0
s exp
Lv T  T0
ð
Þ
RvT2
0


:
ð7Þ
Due to its exponential nature, the amount of
water vapor that can exist in equilibrium is a
rapidly changing function of the ambient temper-
ature; the equilibrium vapor pressure roughly
doubles for every 10 K increase in temperature.
While the Clausius-Clapeyron law governs the
equilibrium vapor pressure, it says nothing about
how this equilibrium is to be reached. Chemical
reactions or changes of phase that are thermody-
namically favored may nevertheless not occur
because the reactions have high energies of acti-
vation. As a result, pockets of air with higher
concentrations of water vapor than given by
Eq. 6 are very commonly found in the atmo-
sphere. The system of air and water vapor is then
said to be “supersaturated.” In fact a cloud is often
on average supersaturated. So excess water vapor
is available, which can then condense. However,
spontaneous condensation requires supersatura-
tions of about 400%, while supersaturation values
in the atmosphere are rarely greater than 5%. We
therefore need cloud condensation nuclei on
which condensation can occur, and droplets and
aerosol particles provide such surfaces. These
nuclei are typically small particles of salt or dust
and a background concentration of these nuclei of
about 100–1000 cc1 exists in the atmosphere.
This number concentration is a function of how
polluted the air is, typically being larger over the
continents than over the ocean. This number con-
centration, then, also decides how supersaturated
the air can be. Supersaturations for polluted air are
typically 1% or lower, while higher supersatura-
tions are seen in marine clouds (see, e.g.,
Pruppacher and Klett 2010, Chap. 2). Nuclei
smaller than a critical size (called the Kohler
radius) reach an equilibrium radius and do not
grow beyond this (due to the fact that the satura-
tion vapor pressure is a function of the radius).
Nuclei that are larger than the Kohler radius grow
to become water droplets in clouds. These water
droplets continue to grow by absorbing the water
vapor in the atmosphere. The resulting release of
the latent heat of vaporization drives the large-
scale dynamics of clouds, as we sketch below.
A relation describing the rate at which the
water droplets grow and consume water vapor
can be derived assuming the water droplets are
small enough for ventilation effects to be negligi-
ble (see Bohren and Albrecht 1998, Chap. 7;
Pruppacher and Klett 2010, Chap. 13). This gives
a da
dt ¼ s  1
Crw
,
where C ¼ O 107


ms=kg is a thermodynamic
constant which is a function of the ambient tem-
perature. The rate of growth of a droplet is
inversely proportional to its radius. As we have
seen in section “Microphysics Without Thermody-
namics,” this is one of the factors that makes
explaining rain-formation challenging. If this rela-
tion is applied to a system of n droplets per unit
Fluid Dynamics in Clouds
135

volume, ignoring interactions, the rate at which the
water vapor in the system is consumed is
1
r0
s
drv
dt ¼  rv=rs  1
ts
,
ð8Þ
where ts is a time-scale, rs ¼ ps/(RvT) is the
saturation vapor density, and r0
s is a base value
rsðp0, T0Þ. This condensation of vapor results in
the heating of the ﬂow at a rate
dT
dt ¼ Lvr0
s
Cp
rv=rs  1
ts


:
The latent heat of vaporization, Lv  2.5 	
106 J/kg/K, is a large value. As a result of this,
despite the small amounts by weight of water vapor
and liquid found in clouds (typical values are O
(1–10) g/kg), the amounts of heat released are
enormous and can be O(MW/m3 (see, e.g., the
discussion in Narasimha et al. (2011) on typical
heating rates in clouds). The heating thus provided
increases the temperature, and the resulting buoy-
ancy drives the upward ﬂow of the cloud. Differ-
ential heating of regions of the ﬂow and the
resulting buoyancy differences drive the turbulence
in the ﬂow. We look next at how particle inertia,
phase change, and buoyancy interact in clouds.
Interactions of Particle Inertia,
Thermodynamics, and Buoyancy-Driven Flow
We refer again to the box-diagram in Fig. 1 show-
ing the different interacting phenomena in clouds.
All clouds are composed of water vapor, water
droplets, and aerosol particles suspended in tur-
bulent ﬂow. Particle inertia, phase-change, and
buoyancy-driven turbulent ﬂow are all active in
clouds. However, depending on the type of cloud
and the range of parameters, simplifying approx-
imations may be made which ignore one or more
of these effects. We discuss some relevant exam-
ples below which illustrate this.
Cumulus Clouds: Phase-
Change+Buoyancy+Turbulence
Cumulus clouds are tall, heap-like clouds found in
the atmosphere, and are crucial to the maintenance
of heat and mass balance in the atmosphere. Their
importance in the dynamics of the atmosphere has
long been recognized, with competing attempts to
model them as various free-shear ﬂows like jets,
plumes, or thermals (Stommel 1947; Squires and
Turner 1962). These clouds, driven by the release
of latent heat in the ﬂow, differ signiﬁcantly in
their dynamics from jets and plumes without such
latent heating, and have been an object of study
for 60 years. A fuller review of these efforts may
be found in De Rooy et al. (2013). The parameter
of interest in the study of these clouds is the
entrainment rate – the rate at which the cloud
drags in ambient (dry) air from its environment.
Entrainment dilutes the cloud, leading to its ulti-
mate demise. Entrainment in free-shear ﬂows is
still a topic of active research, and the addition of
volumetric (i.e., not at the source on the ground)
heating complicates the picture.
Progress has been made through laboratory
experiments on cumulus clouds, showing the
role of the latent heat release (Narasimha et al.
2011), building on work in Bhat and Narasimha
(1996), Venkatakrishnan et al. (1998, 1999). The
addition of latent heat to the ﬂow seems to not only
accelerate the ﬂow but to shut down the entrainment
of ambient air into the bulk of the ﬂow. This shut-
down of entrainment (shown in Fig. 8) is argued to
be because the heating disrupts the coherent struc-
tures in the shear layer of the ﬂow (Narasimha et al.
2011; Bhat and Narasimha 1996). This then leads to
the cloud remaining undiluted for longer and
reaching higher altitudes than if the ﬂow were a
pure plume or jet.
As we have mentioned, the heating in the cloud
arises out of the condensation of water vapor onto
liquid water droplets in the cloud, and thus a full
description of the dynamics would include all the
phenomena listed in Fig. 1. However, especially
for growing cumulus clouds which have not
reached the precipitating state, the droplet size
may be assumed to be small enough that the
particle inertia is negligible. This is a reasonable
assumption since the size distribution in non-
precipitating cumulus clouds peaks at 10 mm.
This being the case, the droplet inertia is small
and the droplets follow the velocity of the ﬂuid.
This in turn allows the droplets to be coarse-
grained into a liquid-water ﬁeld, a step that saves
signiﬁcant computational
effort. Despite the
136
Fluid Dynamics in Clouds

challenges involved, progress has been made
because of the simplifying assumptions discussed.
Large eddy simulations of cumulus clouds show-
ing this behavior have been reported by Romps
and Kuang (2010). Laboratory experiments of
cumulus clouds have been reported by Narasimha
et al. (2011). Direct numerical simulations for
achievable Reynolds numbers are reported in
Ravichandran and Narasimha (2020).
Mammatus Clouds: Phase-Change + Particle
Settling + Buoyancy
A type of cloud that is perhaps not as consequen-
tial as the cumulus clouds, but no less fascinating,
is the mammatus cloud. Typically found under-
neath cumulonimbus anvil outﬂows, and there-
fore acting as harbingers of inclement weather.
The reasons for the formation of these clouds is
a matter of ongoing research, and a comprehen-
sive review of the various proposed mechanisms
may be found in Schultz et al. (2006), with follow-
up studies in Kanak and Straka (2006), Kanak
et al. (2008). A promising explanation involves
the combination of the settling of water droplets
out of the cumulonimbus anvils, their subsequent
evaporation forming a layer of air below the anvil
that is denser than the ambient air, and the even-
tual instability due to this density inversion.
Unlike in section “Cumulus Clouds: Phase-
Change+Buoyancy+Turbulence,” particle settling
cannot be neglected. Ravichandran et al. (2020)
ﬁnd that the size of the mammatus lobes is pro-
portional to the settling velocity (which increases
for small droplet sizes like the square of the drop-
let size) and to the time-scale for phase-change
(which is proportional to the inverse of the mean
droplet size and the number concentration).
Droplets in Clouds, Redux: Particle
Inertia+Turbulence+Phase-Change
The phenomenon of warm-rain initiation and the
droplet-growth bottleneck that has been a long-
standing unsolved problem in cloud physics, as
discussed in section “Microphysics Without Ther-
modynamics.” In studies focusing on the ﬂuid
mechanics of droplet collisions-coalescence, the
effects of phase-change and thermodynamics are
typically neglected. In the regime of interest –
when droplets have grown to large enough sizes
that their growth rates are small – this assumption
is justiﬁable. For most of the lifetime of a cloud
droplet, however, the thermodynamics of conden-
sation cannot be neglected. The interactions of
phase-change and particle inertia are thus relevant
in the dynamics of clouds: broad droplet size
distributions are important in the rapid growth of
falling droplets through coalescence with smaller
droplets.
A ﬁrst step in understanding the interactions of
particle inertia and thermodynamics was taken by
Shaw et al. (1998) who study how droplets interact
with vortices. Clouds, being turbulent ﬂows, are a
tangle of strong vortices. Vortices, then, are suitable
models for idealized studies. As we have seen in
section “Microphysics Without Thermodynamics,”
vortices expel inertial particles. When these inertial
Fluid Dynamics in
Clouds, Fig. 8 The
entrainment coefﬁcient in
heated plumes ﬁrst
increases and then
decreases to zero (i.e., the
plume stops entraining).
(Reproduced from
Narasimha et al. 2011)
Fluid Dynamics in Clouds
137

particles are also nuclei for condensation, the cores
of vortices are voided of nuclei for condensation
and therefore have higher vapor concentrations
than the outside. Shaw et al. (1998) argue that this
should have two consequences: ﬁrst, that any drop-
lets that remain trapped in the vortical region will
end up experiencing larger-than-average supersatu-
rations, and thus be able to grow to sizes not pre-
dicted by only considering cloud-average values of
supersaturation; second, that the supersaturations
produced in the cores of the vortices should lead
to the nucleation of condensation nuclei well above
cloud-base, which allows a broadening of the drop-
let size distributions (on the lower side). The use by
Shaw et al. (1998) of this mechanism in explaining
warm-rain initiation has been questioned in the
literature (see, e.g., Grabowski and Vaillancourt
(1999) and Vaillancourt et al. (2001, 2002)), but
the central message that particle inertia and thermo-
dynamics interact in complex ways remains rele-
vant, in our view.
Clouds are, as we have seen, turbulent ﬂows
where the turbulence is driven by the energy pro-
vided by condensing water vapor. While large
velocities can be generated by large values of buoy-
ancy, turbulence itself, as we have also argued, is
generated by spatial inhomogeneities in the heating.
Ravichandran and Govindarajan (2017) propose a
model of how this can be achieved starting from
initially homogeneous conditions, thereby provid-
ing a route by which turbulence can sustain itself by
“feeding” on the latent heat of vaporization. The
mechanism builds on the aforementioned effect of
inertial particles being centrifuged out of vortical
regions. This leaves the vortices more supersatu-
rated (as in Shaw et al. (1998), but keeping track of
temperature changes), but also colder than their
surroundings which have been heated by the con-
densation of water vapor. The resulting density
inhomogeneities lead to baroclinic torques which
generate vorticity and thus turbulence in the ﬂow
(Fig. 9). We mention in passing that the buoyant
10 0
10 1
10 2
k
10 -10
10 -7
10 -4
10 -1
10 0
E(k)
10 0
10 1
10 2
k
10 -10
10 -7
10 -4
10 -1
10 0
E(k)
No inertia
Inertia
k -3
10 0
10 1
10 2
k
10 -10
10 -7
10 -4
10 -1
10 0
E(k)
10 0
10 1
10 2
k
10 -10
10 -7
10 -4
10 -1
10 0
E(k)
t = 40
t = 50
t = 30
t = 10
Fluid Dynamics in Clouds, Fig. 9 The energy density
E(k) versus the wavenumber k in simulations with and
without accounting for the effects of particle inertia. The
addition of particle inertia effects provides a route for the
transfer of energy to smaller scales starting from homoge-
neous conditions. Similar to a ﬁgure in Ravichandran and
Govindarajan (2017)
138
Fluid Dynamics in Clouds

vortices that result have interesting dynamics of
their own (see Ravichandran et al. 2017b).
Growing clouds are also a class of free-shear
ﬂows. The edges of clouds, where the shear layers
separate
saturated
regions
from
unsaturated
regions, are thus regions of large inhomogeneities
in vapor and droplet concentration. This results in
the generation of strong sustained turbulent ﬂow.
Kumar et al. (2012, 2013, 2014) study this dynam-
ics in an idealized setup where the temperature is
held constant, but water droplets are allowed to
grow or shrink in response to local conditions.
The authors argue that, as a consequence of the
high ﬂow Reynolds numbers in a cloud, the mixing
of dry ambient air with the saturated cloudy air will
be highly inhomogeneous: that is, that parcels of
saturated air and parcels of subsaturated air will
often be found close to each other. As a result,
particles in the shear layer can have complicated
growth histories; the size distribution of such drop-
lets will also be very broad as a result. They quan-
tify this inhomogeneity in terms of a Damkoehler
number which is a ratio of the time-scale of phase-
change to a characteristic timescale of the ﬂow. In
the high Reynolds number ﬂows in the shear layers
of clouds, they show that using a large Damkoehler
number Da  1 results in highly skewed tails with
a large number of droplets that begin at the edge of
the shear layer experiencing extreme evaporation
and thus shrinking signiﬁcantly, while droplets in
the saturated core of the ﬂow grow slightly. In the
later stages of a cloud’s evolution, as large droplets
formed in the cloud settle out of the cloud, they are
likely to encounter these smaller droplets. The efﬁ-
ciency of collisions is signiﬁcantly greater if the
droplet sizes are different, and the presence of
much smaller droplets in the shear-layers could
play a crucial role in rain formation.
More recently, the entire process of rain forma-
tion from monodisperse cloud droplets has been
studied by Gotoh et al. (2016) and Saito and Gotoh
(2018). The authors develop a moving box model
where they account for the upward velocity of a
cloud by changing the mean background properties
seen by the box. This allows them to follow a
subvolume of the cloud as it ascends upwards.
The cloud droplets initially grow by condensation
of vapor. These cloud droplets eventually lead to a
small number of larger droplets by collisions with
each other. This is a weak effect, since collisions of
similarly sized particles are rare. The larger drop-
lets that eventually form start to settle at signiﬁcant
velocities, and grow rapidly because of collisions-
coalescence with the smaller droplets. The authors
report that the intensity of the turbulence which is
artiﬁcially chosen plays a key role in the collisions-
coalescence process, in line with expectations from
work on the problem over the last two decades.
Conclusion and Future Directions
The ﬂuid dynamics of clouds is only part – if the
most complex part – of climate science. We have
argued here that understanding the dynamics is
important in the face of the uncertainties of cli-
mate change. We hope to have convinced readers
of the immense challenges and opportunities the
ﬁeld presents, both as an exercise in scientiﬁc
curiosity and because of the far-reaching implica-
tions. Both these facets arise from the range of
length- and time-scales present in the dynamics.
The approach we favor – of understanding the
parts in service of understanding the whole – has
led to several semi-independent programs of
research which have to be eventually be uniﬁed.
Under present computational limitations the goal
of these studies is to be able to parameterize the
dynamics and improve global climate models.
Some areas of active research where the ques-
tions are reasonably well-deﬁned and can be
addressed computationally are (a) a fuller under-
standing of entrainment in free-shear ﬂows in
general, and cloud-ﬂows in particular. Open prob-
lems include the magnitude of the entrainment
and the details of the process by which volumetric
heating alters the entrainment; by extension,
entrainment in merging plumes/cumulus clouds
as a way of understanding the dynamics of con-
vective aggregation; and the incorporation of the
resultant better models for entrainment into global
climate simulations: perhaps by extending the
super-parameterization method (see Randall et al.
2003).
(b)
Droplet-resolved
simulations
for
collision-coalescence, in order to overcome limita-
tions of the geometric collisions approach; to
include effects of droplet splintering, droplet inter-
actions, and ﬂow-droplet coupling; and to include
Fluid Dynamics in Clouds
139

effects of differences in liquid/gas properties like
density, temperature, conductivity in the phase-
change process.
Acknowledgments SR was supported under Swedish
Research Council Grant No. 638-2013-9243.
JRP acknowledges funding from the IITB-IRCC seed
grant.
SSR acknowledges DST (India) project MTR/2019/
001553 for support.
RG and SSR acknowledge the support of the DAE,
Govt. of India, under project no. 12-R\&D-TFR-5.10-
1100.
Bibliography
Abma D, Heus T, Mellado JP (2013) Direct Numerical
Simulation of Evaporative Cooling at the Lateral
Boundary of Shallow Cumulus Clouds. J Atmos Sci
70:2088–2102
Agasthya L, Picardo JR, Ravichandran S, Govindarajan R,
Ray SS (2019) Understanding droplet collisions
through a model ﬂow: Insights from a Burgers vortex.
Phys Rev E 99:063107
Anand P, Ray SS, Subramanian G (2019) Orientation
dynamics of sedimenting anisotropic particles in turbu-
lence. Prepr arXiv:1907.02857 [physics.ao-ph]
Archer D (2011) Global warming: understanding the fore-
cast. John Wiley & Sons
Bannon PR (1996) On the Anelastic Approximation for a
Compressible Atmosphere. J Atmos Sci 53:3618–3628
Bec J (2003) Fractal clustering of inertial particles in ran-
dom ﬂows. Phys Fluids 15:L81–L84
Bec J (2005) Multifractal concentrations of inertial par-
ticles in smooth random ﬂows. J Fluid Mech
528:255–277
Bec J, Celani A, Cencini M, Musacchio S (2005) Cluster-
ing and collisions of heavy particles in random smooth
ﬂows. Phys Fluids 17:073301
Bec J, Biferale L, Cencini M, Lanotte A, Musacchio S,
Toschi F (2007) Heavy Particle Concentration in Tur-
bulence at Dissipative and Inertial Scales. Phys Rev
Lett 98:084502
Bec J, Biferale L, Cencini M, Lanotte AS, Toschi F (2010) .
Intermittency in the velocity distribution of heavy par-
ticles in turbulence. J Fluid Mech 646:527
Bec J, Musacchio S, Ray SS (2013) Sticky elastic colli-
sions. Phys Rev E 87:063013, 1–7
Bec J, Homann H, Ray SS (2014) Gravity-driven enhance-
ment
of
heavy
particle
clustering
in
turbulent
ﬂow. Phys Rev Lett 112:184501, 1–5
Bec J, Ray SS, Saw EW, Homann H (2016) Abrupt growth
of large aggregates by correlated coalescences in tur-
bulent ﬂow. Phys Rev E 93:031102
Bewley GP, Saw E-W, Bodenschatz E (2013) Observation
of the sling effect. New J Phys 15:083051
Bhat GS, Narasimha R (1996) A volumetrically heated jet:
large-eddy structure and entrainment characteristics.
J Fluid Mech 325:303–330
Bhatnagar A, Gustavsson K, Mehlig B, Mitra D (2018a)
Relative velocities in bidisperse turbulent aerosols:
Simulations and theory. Phys Rev E 98:063107
Bhatnagar A, Gustavsson K, Mitra D (2018b) Statistics of
the relative velocity of particles in turbulent ﬂows:
Monodisperse particles. Phys Rev E 97:023105
Bodenschatz E, Malinowski SP, Shaw RA, Stratmann
F (2010) Can We Understand Clouds Without Turbu-
lence? Science 327:970–971
Bohren CF, Albrecht BA (1998) Atmospheric thermody-
namics. Oxford University Press
Bony S, Stevens B, Frierson DM, Jakob C, Kageyama M,
Pincus R, Shepherd TG, Sherwood SC, Siebesma AP,
Sobel AH et al (2015) Clouds, circulation and climate
sensitivity. Nat Geosci 8:261–268
Burgers JM (1948) Advances in applied mechanics. Aca-
demic, New York
Canuto C, Hussaini MY, Quarteroni A, Zang TA
(2006)
Spectral
methods:
fundamental
in
single
domains. Springer, Berlin
Chun J, Koch DL, Rani SL, Ahluwalia A, Collins LR
(2005) Clustering of aerosol particles in isotropic tur-
bulence. J Fluid Mech 536:219–251
Davidson PA (2004) Turbulence: an introduction for sci-
entists and engineers. Oxford University Press, Oxford,
UK
Davidson PA, Kaneda Y, Sreenivasan KR (2012) Ten chap-
ters in turbulence. Cambridge University Press
de Lozar A, Mellado JP (2013) Direct numerical simula-
tions of a smoke cloud–top mixing layer as a model for
stratocumuli. J Atmos Sci 70:2356–2375
de Lozar A, Mellado JP (2015) Mixing Driven by Radia-
tive and Evaporative Cooling at the Stratocumulus Top.
J Atmos Sci 72:4681
de Lozar A, Mellado JP (2017) Reduction of the entrain-
ment velocity by cloud droplet sedimentation in strato-
cumulus. J Atmos Sci 74:751–765
de Rooy WC, Bechtold P, Fröhlich K, Hohenegger C,
Jonker H, Mironov D, Siebesma AP, Teixeira J, Yano
J-I (2013) Entrainment and detrainment in cumulus
convection: an overview. Q J R Meteorol Soc 139:1–19
Deepu P, Ravichandran S, Govindarajan R (2017) Caus-
tics-induced coalescence of small droplets near a vor-
tex. Phys Rev Fluids 2:024305
Devenish BJ, Bartello P, Brenguier J-L, Collins LR,
Grabowski WW, IJzermans RHA, Malinowski SP,
Reeks
MW,
Vassilicos
JC,
Wang
L-P,
Warhaft
Z (2012) Droplet growth in warm turbulent clouds.
Q J R Meteorol Soc 138:1401–1429
Douady S, Couder Y, Brachet ME (1991) Direct observa-
tion of the intermittency of intense vorticity ﬁlaments in
turbulence. Phys Rev Lett 67:983–986
140
Fluid Dynamics in Clouds

Dubief Y, Delcayre F (2000) On coherent-vortex identiﬁ-
cation in turbulence. J Turbul 1:N11
Durran DR (1989) Improving the Anelastic Approxima-
tion. J Atmos Sci 46:1453–1461
Falkovich G, Pumir A (2007) Sling Effect in Collisions of
Water Droplets in Turbulent Clouds. J Atmos Sci
64:4497–4505
Falkovich G, Fouxon A, Stepanov MG (2002) Acceleration
of rain initiation by cloud turbulence. Nature 419:151–
154
Gibbon JD, Fokas AS, Doering CR (1999) Dynamically
stretched vortices as solutions of the 3D Navier-Stokes
equations. Phys D 132:497–510
Gotoh T, Suehiro T, Saito I (2016) Continuous growth of
cloud droplets in cumulus cloud. New J Phys
18:043042
Grabowski WW (2014) Extracting microphysical impacts
in large-eddy simulations of shallow convection.
J Atmos Sci 71:4493–4499
Grabowski WW, Vaillancourt P (1999) Comments on pref-
erential concentration of cloud droplets by turbulence:
effects on the early evolution of cumulus cloud droplet
spectra. J Atmos Sci 56:1433–1436
Grabowski WW, Wang L-P (2013) Growth of Cloud Drop-
lets in a Turbulent Environment. Annu Rev Fluid Mech
45:293–324
Gupta M, Chaudhuri P, Bec J, Ray SS (2018) Turbulent
route
to
two-dimensional
soft
crystals.
arXiv:1812.06487 [physics.ﬂu-dyn]
Gustavsson K, Mehlig B (2011) Distribution of relative
velocities in turbulent aerosols. Phys Rev E 84:045304
Gustavsson K, Mehlig B (2013) Distribution of velocity
gradients and rate of caustic formation in turbulent
aerosols
at
ﬁnite
Kubo
numbers.
Phys
Rev
E 87:023016
Gustavsson K, Mehlig B (2016) Statistical models for
spatial patterns of heavy particles in turbulence. Adv
Phys 65:1, 1–57
Gustavsson K, Mehlig B, Wilkinson M, Uski V (2008)
Variable-range projection model for turbulence-driven
collisions. Phys Rev Lett 101:174503
Hernandez-Duenas G, Majda AJ, Smith LM, Stechmann
SN (2013) Minimal models for precipitating turbulent
convection. J Fluid Mech 717:576–611
Ireland PJ, Bragg AD, Collins LR (2016) The effect of
Reynolds number on inertial particle dynamics in iso-
tropic turbulence. Part I: Simulations without gravita-
tional effects. J Fluid Mech 796:617–658
Ishihara T, Kaneda Y, Yokokawa M, Itakura K, Uno
A (2007) Small-scale statistics in high-resolution direct
numerical simulation of turbulence: Reynolds number
dependence of one-point velocity gradient statistics.
J Fluid Mech 592:335–366
James M, Ray SS (2017) Enhanced droplet collision rates
and impact velocities in turbulent ﬂows: The effect of
poly-dispersity and transient phases. Sci Rep 7:12231,
1–9
Jarecka D, Grabowski WW, Pawlowska H (2009) Model-
ing of subgrid-scale mixing in large-eddy simulation of
shallow convection. J Atmos Sci 66:2125–2133
Jiménez J, Wray AA (1998) On the characteristics of
vortex ﬁlaments in isotropic turbulence. J Fluid Mech
373:255–285
Kailasnath P, Sreenivasan KR, Stolovitzky G (1992) Prob-
ability density of velocity increments in turbulent
ﬂows. Phys Rev Lett 68:2766–2769
Kanak KM, Straka JM (2006) An idealized numerical sim-
ulation of mammatus-like clouds. Atmos Sci Lett 7:2–8
Kanak KM, Straka JM, Schultz DM (2008) Numerical
simulation of mammatus. J Atmos Sci 65:1606–1621
Kostinski AB, Shaw RA (2005) Fluctuations and Luck in
Droplet Growth by Coalescence. Bull Am Meteorol
Soc 86:235–244
Kumar
B,
Janetzko
F,
Schumacher
J,
Shaw
RA
(2012) Extreme responses of a coupled scalar-particle
system during turbulent mixing. New J Phys 14:115020
Kumar B, Schumacher J, Shaw RA (2013) Cloud micro-
physical effects of turbulent mixing and entrainment.
Theor Comput Fluid Dyn 27:361–376
Kumar B, Schumacher J, Shaw RA (2014) Lagrangian
mixing dynamics at the cloudy–clear air interface.
J Atmos Sci 71:2564–2580
Lamorgese AG, Caughey DA, Pope SB (2005) Direct
numerical simulation of homogeneous turbulence
with hyperviscosity. Phys Fluids 17:015106
Lanotte AS, Seminara A, Toschi F (2009) Cloud Droplet
Growth by Condensation in Homogeneous Isotropic
Turbulence. J Atmos Sci 66:1685–1697
Maxey MR, Riley JJ (1983) Equation of motion for a small
rigid sphere in a nonuniform ﬂow. Phys Fluids 26:883
Meibohm J, Pistone L, Gustavsson K, Mehlig B (2017)
Relative velocities in bidisperse turbulent suspensions.
Phys Rev E 96:061102
Mitra D, Perlekar P (2018) Topology of two-dimensional
turbulent ﬂows of dust and gas. Phys Rev Fluids
3:044303
Monchaux R, Bourgoin M, Cartellier A (2012) Analyz-
ing preferential concentration and clustering of iner-
tial particles in turbulence. Int J Multiphase Flow
40:1–18
Narasimha R, Diwan SS, Duvvuri S, Sreenivas KR, Bhat
G (2011) Laboratory simulations show diabatic heating
drives cumulus-cloud evolution and entrainment. Proc
Natl Acad Sci 108:16164, 1–6
Ouellette NT, Xu H, Bourgoin M, Bodenschatz E (2006)
An experimental study of turbulent relative dispersion
models. New J Phys 8:109
Pandit R, Perlekar P, Ray SS (2009) Statistical Properties
of Turbulence: An Overview. Pramana J Phys 73:157
Pandit R, Banerjee D, Bhatnagar A, Brachet M, Gupta A,
Mitra D, Pal N, Perlekar P, Ray SS, Shukla V, Vincenzi
D (2017) An overview of the statistical properties of
two-dimensional turbulence in ﬂuids with particles,
conducting ﬂuids, ﬂuids with polymer additives,
Fluid Dynamics in Clouds
141

binary-ﬂuid mixtures, and superﬂuids. Phys Fluids
29:111112
Pauluis O, Schumacher J (2011) Self-aggregation of clouds
in conditionally unstable moist convection. Proc Natl
Acad Sci USA 108:12623–8
Pauluis O, Schumacher J et al (2010) Idealized moist
Rayleigh-Benard convection with piecewise linear
equation of state. Commun Math Sci 8:295–319
Perrin VE, Jonker HJJ (2014) Preferred location of droplet
collisions in turbulent ﬂows. Phys Rev E 89:033005
Perrin VE, Jonker HJJ (2016) Effect of the eigenvalues of
the velocity gradient tensor on particle collisions.
J Fluid Mech 792:36–49
Picardo JR, Agasthya L, Govindarajan R, Ray SS
(2019) Flow structures govern particle collisions in
turbulence. Phys Rev Fluids 4:032601
Prasath SG, Vasan V, Govindarajan R (2019) Accurate
solution method for the Maxey–Riley equation, and
the effects of Basset history. J Fluid Mech 868:428–460
Pruppacher HR, Klett JD (2010) Microphysics of clouds
and precipitation. Springer Netherlands, Dordrecht, pp
10–73
Randall D, Khairoutdinov M, Arakawa A, Grabowski
W (2003) Breaking the cloud parameterization dead-
lock. Bull Am Meteorol Soc 84:1547–1564
Ravichandran S, Govindarajan R (2015) Caustics and clus-
tering in the vicinity of a vortex. Phys Fluids 27
Ravichandran S, Govindarajan R (2017) Vortex-dipole
collapse induced by droplet inertia and phase change.
J Fluid Mech 832:745–776
Ravichandran S, Narasimha R (2020) Non-precipitating
shallow cumulus clouds: theory and direct numerical
simulation. Preprint (2020)
Ravichandran S, Deepu P, Govindarajan R (2017a) Clus-
tering of heavy particles in vortical ﬂows: a selective
review. Sādhanā 42:597–605
Ravichandran S, Dixit HN, Govindarajan R (2017b) Lift-
Induced Vortex-Dipole Collapse. Phys Rev Fluids
2:034702
Ravichandran S, Meiburg E, Govindarajan R (2020) Set-
tling driven instabilities in mammatus clouds. J Fluid
Mech (in Press)
Romps DM (2010) A direct measure of entrainment.
J Atmos Sci 67:1908–1927
Romps DM, Kuang Z (2010) Do Undiluted Convective
Plumes Exist in the Upper Tropical Troposphere?
J Atmos Sci 67:468–484
Roy A, Gupta A, Ray SS (2018) Inertial spheroids in
homogeneous,
isotropic
turbulence.
Phys
Rev
E98:21101
Saito I, Gotoh T (2018) Turbulence and cloud droplets in
cumulus clouds. New J Phys 20:023001
Saw E-W, Bewley GP, Bodenschatz E, Ray SS, Bec
J (2014) Extreme ﬂuctuations of the relative velocities
between droplets in turbulent airﬂow. Phys Fluids
26:111702
Sawford BL (1991) Reynolds number effects in Lagrang-
ian stochastic models of turbulent dispersion. Phys
Fluids A 3:1577–1586
Schiermeier Q (2015) Climatologists to physicists: your
planet needs you. Nature 520:140–141
Schneider T, Kaul CM, Pressel KG (2019) Possible climate
transitions from breakup of stratocumulus decks under
greenhouse warming. Nat Geosci 12:163
Schultz DM, Kanak KM, Straka JM, Trapp RJ, Gordon
BA, Zrnić DS, Bryan GH, Durant AJ, Garrett TJ, Klein
PM, Lilly D (2006) The Mysteries of Mammatus
Clouds : Observations and Formation Mechanisms.
J Atmos Sci 63:2409–2435
Schumacher J, Pauluis O (2010) Buoyancy statistics in
moist turbulent Rayleigh–Bénard convection. J Fluid
Mech 648:509–519
Schumacher J, Eckhardt B, Doering CR (2010) Extreme
vorticity growth in Navier–Stokes turbulence. Phys
Lett A 374:861–865
Shaw RA (2003) Particle-Turbulence Interactions in Atmo-
spheric Clouds. Annu Rev Fluid Mech 35:183–227
Shaw RA, Reade WC, Collins LR, Verlinde J (1998) Pref-
erential concentration of cloud droplets by turbulence:
Effects on the early evolution of cumulus cloud droplet
spectra. J Atmos Sci 55:1965–1976
She Z, Jackson E, Orszag SA (1990) Memory effects are
relevant for chaotic advection of inertial particles.
Nature 344:226–228
Squires P, Turner JS (1962) An entraining jet model for
cumulo-nimbus updraughts. Tellus 14:422–434
Stevens B, Bony S (2013) Water in the atmosphere. Phys
Today 66:29–34
Stommel H (1947) Entrainment of Air into a Cumulus
Cloud. J Meteorol 4:91–94
Tsinober A (2009) An informal conceptual introduction to
turbulence. Springer, New York
Vaillancourt PA, Yau MK, Bartello P, Grabowski WW
(2002)
Microscopic
approach
to
cloud
droplet
growth by condensation. Part II: Turbulence, clus-
tering, and condensational growth. J. Atmos. Sci.
59, 3421–3435
Vaillancourt PA, Yau MK, Grabowski WW (2001) Micro-
scopic approach to cloud droplet growth by condensa-
tion. Part I: Model description and results without
turbulence. J. Atmos. Sci. 58, 1945–1964
Van Hinsberg MAT, Boonkkamp JHMTT, Toschi F, Clercx
HJH (2013) Optimal interpolation schemes for particle
tracking in turbulence. Phys. Rev. E - Stat. Nonlinear,
Soft Matter Phys. 87, 1–8
Venkatakrishnan L, Bhat GS, Prabhu A, Narasimha
R (1998) Visualization studies of cloud-like ﬂows.
Curr Sci 74:597–606
Venkatakrishnan L, Bhat GS, Narasimha R (1999) Exper-
iments on a plume with off-source heating: Implica-
tions for cloud ﬂuid dynamics. J Geophys Res
104:14271
142
Fluid Dynamics in Clouds

Walton WH, Prewett WC (1949) The production of sprays
and mists of uniform drop size by means of spinning
disc type sprayers. Proc Phys Soc B 62:341–350
Weidauer T, Pauluis O, Schumacher J (2010) Cloud pat-
terns and mixing properties in shallow moist Rayleigh–
Bénard convection. New J Phys 12:105002
Wilkinson M, Mehlig B, Bezuglyy V (2006) Caustic Acti-
vation of Rain Showers. Phys Rev Lett 97:48501
Zeff
BW,
Lanterman
DD,
McAllister
R,
Roy R,
Kostelich EJ, Lathrop DP (2003) Measuring intense
rotation and dissipation in turbulent ﬂows. Nature
34:B479–B498
Fluid Dynamics in Clouds
143

Collective Transport and
Depinning
Lei-Han Tang
Department of Physics, Hong Kong Baptist
University, Kowloon Tong, Hong Kong SAR,
China
Article Outline
Glossary
Deﬁnition of the Subject
Introduction
Elastic Manifolds and Impurity Pinning
Driven Depinning, Critical Properties, and
Scaling
Analytical Treatments of the Depinning
Transition and Universality
Self-Organized Criticality
Interface Depinning in Anisotropic Medium
Future Directions
Bibliography
Glossary
Elastic manifold An elastic manifold is a spa-
tially extended object whose energy is given by
a quadratic function of the gradients of its
transverse displacements. In statistical physics,
it is used as a coarse-grained description of the
low-energy modes in an ordered structure.
Pinning Pinning is a common phenomenon in
condensed systems where the relevant degrees
of freedom are trapped to an energy minimum
and hence respond dynamically only when the
external driving exceeds a certain threshold.
Pinning is often caused by defects or impurities
in the system but it may also be due to intrinsic
properties such as the existence of a periodic
lattice that breaks the translational symmetry
of space.
Scaling Scaling describes power-law relation-
ships among two or more physical quantities.
Physical systems at continuous phase transi-
tions are often found to exhibit scale invariance,
i.e., structural and dynamic properties on differ-
ent length and time scales can be mapped onto
each other through suitable scale transforma-
tions. Such properties are characterized by a
set of scaling exponents. The renormalization
group theory, through its ﬂow equations under a
scale transformation, provides a systematic
method to compute these exponents.
Universality Universality is a key concept in the
classiﬁcation of systems which exhibit scale
invariance. Models in the same universality
class have identical scaling properties and are
described by the same set of scaling exponents.
Therefore the identiﬁcation of possible univer-
sality classes is one of the key issues in the
study of, e.g., critical phenomenon at continu-
ous phase transitions. The origin of universal-
ity is best illustrated by the ﬁxed-point
structure of the renormalization group ﬂow
equations. Studies have shown that dimension-
ality, symmetry, and conservation laws are the
key factors that determine a particular univer-
sality class. There is, however, a great deal of
theoretical interest to identify new principles
that determine universality classes, or excep-
tions to the above rule, particularly in driven
nonequilibrium systems.
Definition of the Subject
Collective transport takes place in systems which
exhibit highly correlated response to external
driving. This is in contrast to, e.g., electrical con-
duction in a normal metal, where free electrons
drift independently under an applied electric ﬁeld,
leading to Ohm’s law. Collective motion of micro-
scopic degrees of freedom, on the other hand,
often yields a nonlinear response or even thresh-
old behavior, where steady-state transport sets in
only when the driving exceeds a certain critical
© Springer-Verlag 2009
B. Chakraborty (ed.), Statistical and Nonlinear Physics,
https://doi.org/10.1007/978-1-0716-1454-9_75
Originally published in
R. A. Meyers (ed.), Encyclopedia of Complexity and Systems Science, © Springer-Verlag 2009
https://doi.org/10.1007/978-3-642-27737-5_75
145

strength. In the subcritical regime, the collective
modes are pinned by defects or impurities in the
system. An increasing degree of correlation and
corporation takes place as the threshold is
approached. The subject plays an important role
in the study of a broad class of solid state phe-
nomena, including charge and spin density wave
transport, hysteresis in dirty magnets, and non-
linear current-voltage characteristics in type-II
superconductors. It has also found interesting
applications outside physics, such as in crack
propagation and earthquake modeling. Important
theoretical developments that took place in the
early 1990s culminated in the formulation of a
functional renormalization group theory for the
no equilibrium deepening transition. The analyti-
cal framework enables systematic computation of
the critical properties and, perhaps more impor-
tantly, elucidation of universality through its ﬁxed
point structures. Subsequent work by many
research groups have established a close link
between driven deepening and the sand pile
models of self-organized criticality (SOC). This
connection has been fruitfully explored to gain a
better understanding of the long-range spatial cor-
relations and intermittent temporal activities in the
two classes of problems.
Introduction
The motion of a water drop down a glass window
under gravity illustrates many salient features of
collective transport and deepening, although the
phenomenon itself is surprisingly rich in physics
and chemistry when examined in microscopic
detail (de Gennes 1985; Leger and Joanny 1992;
Podgorski et al. 2001). The size of the drop is
governed by the so called capillary length
(typically of the order of a few millimeters) from
elementary physics: On this scale the surface ten-
sion that makes a water drop spherical competes
with the gravity which acts to deform the droplet.
The actual descent of the droplet, which usually
follows a zigzag path with an ever changing
speed, is a result of many factors, not least the
random force set by the local wettability of the
glass surface. With a microscope, one may
observe the hysteric advancement of the contact
line separating wet and dry regions on the sub-
strate. The interplay between the surface tension,
the pinning force on the contact line, and the
driving force provided by gravity gives rise to a
complex and intermittent dynamical behavior
encompassing a wide range of length and time
scales.
Similar types of collective and intermittent
transport
exist
in
solids.
In
certain
low-
dimensional materials such as NbSe3, periodic
modulation of the electronic density, known as
the charge-density-wave (CDW) (Grüner 1988),
develops spontaneously at sufﬁciently low tem-
peratures through the Peierls instability. An
applied electric ﬁeld in the direction of the charge
modulation exerts a body force on the CDW much
the same way as gravity does on the water droplet.
However, in the presence of impurity atoms or
crystal defects, the CDW does not move unless
the electric ﬁeld exceeds a certain threshold value,
as seen in experiments (Grüner 1988; Thorne
2005). The vortex lattice in type-II superconduc-
tors is another example of modulated electronic
structures within a solid (Larkin 1970). Pinning of
the vortex lattice by intrinsic or artiﬁcial defects is
essential for achieving a high critical supercurrent
in these materials.
Yet another class of collective pinning phe-
nomena in solids involves the dynamics of topo-
logical
defects
such
as
crystal
dislocations
(Granato and Lüke 1956) or magnetic domain
walls (Bruinsma and Aeppli 1984). These objects
have internal dimensions lower than that of the
embedding medium, and hence can explore inho-
mogeneities in the surrounding environment. The
driven motion of these objects has a great effect on
the physical properties of their host system,
e.g. plastic deformation of a solid due to glide
and climb motion of dislocations, and hysteresis
effect (Ryu et al. 2007; Sethna et al. 1993; Zapperi
et al. 1998) related to the pinning of domain walls
separating regions of opposite magnetization.
The development of quantitative theories for
impurity pinning and the driven depinning transi-
tion began in the 1970s after fundamental break-
throughs in many-body physics and equilibrium
critical phenomena (Fukuyama and Lee 1978;
146
Collective Transport and Depinning

Larkin 1970; Larkin and Ovchinnikov 1979; Lee
and Rice 1979). Research in this area has tradi-
tionally followed two separate approaches: The
microscopic approach that attempts to explain
the observed behavior starting from the funda-
mental laws of physics, and the phenomenologi-
cal approach that focuses on the large-scale
properties using the simplest models possible.
The second approach, which is popular in the
ﬁeld of statistical physics, has the advantage of
mathematical simplicity and clarity. It facilitates
identiﬁcation of the underlying symmetries of the
original problem, and the establishment of univer-
sality classes through which model systems can be
classiﬁed and compared. However, real physical
systems often contain complications that prevent
a direct comparison between model predictions
and experimental observations (see, e.g. Thorne
2005). This is where the microscopic approach,
popular among condensed matter theorists, comes
to aid. In the best studied cases, a microscopic
theory allows one to derive or estimate system-
speciﬁc parameters and properties, and to suggest
correct phenomenological models and possible
improvements when discrepancies are found.
The present article focuses on the recent theo-
retical developments in the statistical physics of
this class of problems. This is partly motivated by
the signiﬁcant progress that has been achieved in a
quantitative characterization of the depinning tran-
sition over the past two decades. Similar to the
critical phenomena in thermal equilibrium systems,
static and dynamic ﬂuctuations exhibit scaling
properties with exponents that fall into well-
deﬁned universality classes determined by the
symmetry and dimensionality of the problem.
These concepts allow one to establish precise rela-
tionships among models proposed under different
physical contexts. The successful application of the
renormalization group methods to the depinning
transition has led to a deeper analytical understand-
ing of the observed critical phenomena. Our choice
is also motivated by the close connection between
depinning and the subject of self-organized criti-
cality (Bak et al. 1987), which enjoys broad interest
in the complexity community.
We shall start with a brief review of systems,
mostly from solid state physics, where collective
modes and depinning play an important role in the
interpretation of the observed transport phenome-
non. A generic mathematical formulation of this
class of problems, known as the elastic manifold
in a disordered potential, is introduced, along with
a discussion of the complex energy landscape
underlying its equilibrium and dynamic proper-
ties. This is followed by a description of the crit-
ical properties at the driven depinning transition
and numerical results. The basic analytic structure
of the threshold solution can be seen in a mean-
ﬁeld theory. We then summarize the main results
of functional renormalization group calculations
which provide a systematic and quantitative char-
acterization of the depinning transition. The rela-
tionship between driven depinning and self-
organized criticality is explained. The inﬂuence
of medium anisotropy on the depinning transition
is brieﬂy discussed. Finally, we mention a few
open problems in the ﬁeld for future work.
Elastic Manifolds and Impurity Pinning
Elasticity, Order, and Symmetry Breaking
Although long-range spatial correlations that
underlie collective transport can be generated
dynamically under certain conditions, we shall
focus on systems for which such correlations are
already present before external driving is applied.
In particular, we shall assume that the system is in
a low temperature ordered state and responds
elastically to external perturbations. This assump-
tion allows us to concentrate on the large scale
properties of the system in the depinning process,
while leaving the microscopic, system-speciﬁc
behavior to a separate discussion.
Elasticity is a familiar concept in macroscopic
physics. An object is said to be elastic if it deforms
under an applied force in a continuous and revers-
ible manner. Microscopically, elasticity is inti-
mately related to the existence of an ordered
state
that
breaks
a
continuous
symmetry
(Anderson 1984). This point can be appreciated
with the example of a crystalline solid. Atoms in
the solid form a periodic structure in space with
energetically preferred unit cells and lattice con-
stants. This state is said to break the translational
Collective Transport and Depinning
147

symmetry of the particle system as the density of
atoms is no longer uniform in space. A uniform
translation of the structure does not lead to a
change in the system energy. On the other hand,
relative displacement of atoms distorts the unit
cells and leads to an increase in energy which
grows quadratically with the displacement. Thus,
the system has acquired a form of rigidity by
breaking a continuous symmetry to gain order.
Elasticity is a manifestation of this rigidity when
the ordered state is perturbed by external forces or
internal impurities and defects.
Both charge-density waves and vortex lattices
are periodic structures in space, and hence natu-
rally their behavior is similar to a crystalline solid.
There are, however, differences in the number of
components needed to describe a generic defor-
mation in each case. A CDW with a single mod-
ulation wave vector Q corresponds to an electron
density r(r) ¼ r0 þ r1 cos(Q  r þ ’), where r0 is
the average density and r1 the modulation ampli-
tude due to charge ordering. A uniform phase shift
’ ! ’ þ c moves the CDW uniformly against the
underlying lattice. Weak deformation of the CDW
is described by a spatially varying phase ’(r). The
elastic energy of a CDW depends quadratically on
the phase gradient ∇’, with different elastic con-
stants along and perpendicular to the modulation
vector Q (Fukuyama and Lee 1978). In the case of
the vortex lattice, a two-component vector ﬁeld
u(r) perpendicular to the vortex lines is needed to
describe a general distortion of the ideal structure.
The construction of the elastic energy parallels
that of a crystalline solid. In an isotropic medium,
three elastic constants are needed to describe the
energetics of a vortex line array (Larkin 1970;
Larkin and Ovchinnikov 1979).
Topological defects in an ordered structure also
behave elastically when deformed from their ideal
positions under a great variety of circumstances,
though this form of elasticity has a different
microscopic origin. A dislocation in a solid, for
example, has a core where the atomic arrangement
differs from elsewhere in the crystal. This gives
rise to an excess amount of energy proportional to
the length of the line. The interface between two
bulk phases has an excess free energy (commonly
known as the surface tension) proportional to the
surface area for the same reason. This applies also
to domain walls in a magnet.
Elastic Manifolds in a Disordered Potential
The energy of a topological defect is affected by
the presence of impurities or point defects in the
system. For example, an impurity atom sitting in
the core of a dislocation has a different atomic
environment and hence a different energy than
when it resides in a normal region. This effect
gives rise to a short-range and often attractive
force between the impurity and the dislocation
core. The tendency for the dislocation to distort
itself in order to adapt to the impurity conﬁgura-
tion is countered by the elastic energy cost. In
general, the two competing forces lead to a large
number of metastable conformations of the dislo-
cation core, separated by energy barriers. The
effect of impurities on interfaces and magnetic
domain walls can be considered in a similar way.
A uniﬁed statistical mechanical description of
impurity pinning can be formulated in terms of a
D-dimensional elastic manifold embedded in
d spatial dimensions (Fisher 1986; Halpin-Healy
and Zhang 1995; Le Doussal et al. 2004). Let
r  RD be the internal coordinates of the manifold
and u(r)  RdD be the transverse displacement
of the manifold at point r with respect to a ﬂat
conﬁguration. When the deformation is small, the
excess volume of the manifold is a quadratic func-
tion of the gradient of u(r). The following energy
function includes effects of both elasticity and
impurities,
E
u
f g
ð
Þ ¼
ð
dDr g
2 ∇u
j
j2 þ VR r, u
ð
Þ
h
i
:
ð1Þ
Here γ is the stiffness constant of the manifold,
and VR (r, u) is a random potential arising from the
interaction between the manifold and the impurities
in the medium. In most theoretical treatments, the
set of random variables {VR (r, u)}, which take
particular values in a given sample, is assumed to be
Gaussian distributed with the mean hVR(r, u)i ¼ 0
and the second moment hVR(r1, u1)VR(r2, u2)i ¼
R(u1  u2)δ(r1  r2). Here δ (r) is a short-ranged
function which vanishes beyond a coarse-graining
length ak.
148
Collective Transport and Depinning

The form of the disorder correlator R(u) in the
transverse directions is dictated by the symmetries
of the original physical problem (Fisher 1986).
For contact interactions and randomly distributed
impurities in the embedding space, R(u) is short-
ranged with a characteristic decay length a⊥.
A different situation is encountered when the
manifold represents an interface that separates
two bulk phases, each affected differently by the
impurities which serve as a “random ﬁeld”
(i.e., the impurity atom has different chemical
potential in the two bulk phases). The potential
VR(r, u) represents the cumulative effect of impu-
rities swept by the interface when it is displaced to
u(r) from a reference conﬁguration. Consequently
R(u) ~ |u| for large u.
A CDW in the presence of impurities can also
be described by Eq. (1), where u (r) ¼ ’ (r) is a
scalar ﬁeld and d ¼ D. Since the impurity interacts
with the local charge density which is a periodic
function of the local phase, the potential VR (r, ’)
is also periodic in ’. Consequently, R(’) is peri-
odic in ’ as well.
Application of Eq. (1) to the vortex lattice
requires special care. On scales smaller than the
spacing between vortex lines, each vortex line
behaves as an independent object. However, this
description fails on large scales, where the peri-
odicity of the lattice changes the nature of the
problem (Giamarchi and Le Doussal 1994;
Nattermann 1990).
Rugged Energy Landscape, Critical
Dimension, and the Pinning Length
The two terms in Eq. (1) represent competing
effects on the manifold: Elasticity favors a ﬂat
manifold with a constant u, while the attractive
force from impurities gives rise to a spatially
varying u(r). The conﬁguration u(r) which mini-
mizes Eq. (1) satisﬁes the following force-
equilibrium condition:
g∇2u  ∇uVR r, u
ð
Þ ¼ 0:
ð2Þ
Complications arise when Eq. (2) has many
solutions. Each solution corresponds to a local
minimum of the energy function (1), separated
by energy barriers from other local energy
minima. The resulting energy surface (or land-
scape) is known as rugged.
Proper characterization of the energy land-
scape deﬁned by Eq. (1) has been a long-standing
problem in the statistical mechanics of disordered
systems. For D < 4 and weak disorder, the rug-
gedness appears when the system size is greater
than a characteristic length Lc along the manifold,
known as the pinning length. This important
observation was due to Larkin (1970) for ﬂux
lines, Fukuyama, Lee and Rice (Fukuyama and
Lee 1978; Lee and Rice 1979) for CDWs, and
Imry and Ma (1975) for magnetic domain walls.
On scales L < Lc, elasticity limits the transverse
displacement u (known as roughness) to be within
the respective correlation length a⊥of the impu-
rity potential VR(r, u), so that the manifold lies
within a single minimum of the energy surface.
On the scale Lc, the typical strength of the random
force ∇u VR, averaged over a volume LD
c , is esti-
mated to be ∇u VR

 ’ R1=2 0
ð Þ
a⊥
LD=2
c
. Balancing it
with the elastic force ga⊥=L2
c, one obtains,
Lc ¼
g2a4
⊥
R 0
ð Þ

1= 4D
ð
Þ
:
ð3Þ
For L > Lc, Eq. (2) has an exponentially
increasing number of solutions.
For D > 4, the elastic term in (2) dominates
over the random force term on large length scales.
Consequently, the rugged energy landscape is a
small scale phenomenon which occurs when Lc is
larger than the correlation length ak of the disorder
potential VR (r, u) parallel to the manifold. From
Eq. (3) we see that this condition requires the
disorder strength to be sufﬁciently strong. Weak
disorder is not able to produce pinning for mani-
folds with internal dimension greater than 4.
The qualitative analysis above shows that
the energetics of the manifold problem are qualita-
tively different below and above four dimensions.
The existence of a critical dimension Dc ¼ 4 sug-
gests systematic renormalization group approach to
the problem. However, earlier attempts based on a
perturbative treatment of the disorder potential failed
to produce a renormalizable theory (Aharony et al.
1976; Efetov and Larkin 1977; Grinstein 1976).
This was ﬁrst achieved successfully by Daniel
Collective Transport and Depinning
149

Fisher (1986) in 1986 in the equilibrium case. Exten-
sion of the scheme to the driven depinning transition
is discussed in section “Analytical Treatments of the
Depinning Transition and Universality”.
Driven Depinning, Critical Properties,
and Scaling
The Driven Depinning Transition
An applied force F coupled linearly to the dis-
placement ﬁeld u(r) tilts the equilibrium energy
landscape as deﬁned by Eq. (1) towards a partic-
ular direction. For small F, the manifold makes
small adjustments locally to reach a new station-
ary state where force equilibrium is re-established,
and this happens for the majority of solutions to
Eq. (2). The number of such solutions, however,
continues to decrease as F increases. When the
magnitude of F exceeds a certain critical value, all
stationary states disappear, and the manifold
enters a running state. The transition from station-
ary to running states with increasing F is known as
the driven depinning transition.
Figure 1 illustrates the dependence of the steady-
state velocity v of the manifold against F ¼ |F|.
In the absence of thermal ﬂuctuations, there is a
well-deﬁned threshold Fc that separates the pinned
from moving regimes. At ﬁnite temperatures, the
transition from a pinned to a moving manifold is
smeared out by thermally activated creep motion.
At low temperatures, the rounding effect is weak
except in a very small region around Fc.
The discussion in subsection “Rugged Energy
Landscape, Critical Dimension, and the Pinning
Length” on the pinning length can be used to
estimate the critical force needed to depin the
manifold. For D < 4, the maximum pinning effect
is seen on the scale Lc, where the typical strength
of the ﬁrst two terms in (5) is given by (Bruinsma
and Aeppli 1984; Feigel’man 1983; Lee and Rice
1979).
Fc ’ ga⊥=L2
c ¼
R2= 4D
ð
Þ 0
ð Þ
gD= 4D
ð
Þ a 4þD
ð
Þ= 4D
ð
Þ
⊥
:
ð4Þ
This is also the force needed to depin the man-
ifold. For D > 4, pinning is possible only if Lc > ak
or R1=2 0
ð Þa1
⊥aD=4
k
> ga⊥=a2
k , i.e., the strength
of the pinning force is stronger than that of the
elastic force on the minimal scale ak.
Continuum Model of the Manifold Dynamics
A dynamical model for the manifold can be
constructed by assuming the motion to be
completely overdamped. This is quite reasonable
for the applications mentioned in section “Intro-
duction”, where the displacement u(r, t) repre-
sents a course-grained variable which changes
on a time scale much longer than the relaxation
time of underlying microscopic processes. With
this assumption, the equation of motion for the
manifold takes the form,
m1 @u
@t ¼ g∇2u þ  r, u
ð
Þ þ F:
Here m is known as the mobility of the mani-
fold, and (r, u) ¼  ∇u VR(r, u) is the random
pinning force.
An interface is described by a height function
u(r, t), so that the dynamical equation, which
Collective Transport and
Depinning,
Fig. 1 Schematic plot
showing the manifold
velocity v against the
driving force F at zero
(blue) and ﬁnite (red)
temperatures. Below the
threshold Fc, the manifold is
pinned by impurities in the
medium, but thermal
activation may generate a
small but ﬁnite velocity
150
Collective Transport and Depinning

deﬁnes the so-called linear interface model
(LIM), takes a scalar form (Bruinsma and Aeppli
1984; Feigel’man 1983),
m1 @u
@t ¼ g∇2u þ  r, u
ð
Þ þ F:
ð5Þ
The same equation applies to a CDW, but with
(r, u þ 2π) ¼ (r, u) periodic in the phase vari-
able (Fisher 1985). Using the example of a single
vortex line in three dimensions, Ertas and Kardar
(1994a) have shown that the extra transverse
dimensions do not change the main features of
the depinning process. Hence Eq. (5) can be con-
sidered as the generic description of the driven
manifold problem, where u(r, t) stands for the
component of the transverse displacement in the
driven direction.
In Layman’s terms, Eq. (5)may be viewed as
describing the advance of a military front where
the attacking side has more ammunition and man-
power F but the defending side is able to exploit
the hilly ground positions (r, u) to pose an effec-
tive resistance. In addition, stretching the front
line into a convoluted form results in a decrease
in attacking power and is hence discouraged!
For the analysis of Eq. (5), it is convenient to
describe pinning effects in terms of the random
force (r, u) instead of the random potential VR
(r, u). Without loss of generality, one may assume
the mean value of (r, u) to be zero. For Gaussian
distributed random forces, it is sufﬁce to specify the
statistics of (r, u) with the correlator,
 r1, u1
ð
Þ r2, u2
ð
Þ
h
i ¼ D u1  u2
ð
Þd r1  r2
ð
Þ:
ð6Þ
On the “bare” scale, Δ(u) ¼ – @2R/@u2 but as
shown in (Le Doussal et al. 2002; Narayan and
Fisher 1993), this relation breaks down in the
driven case upon coarse-graining of the original
degrees of freedom.
Critical Properties and Scaling Laws
Let us ﬁrst consider the interface depinning prob-
lem as described by Eq. (5). This model has been
studied extensively both analytically (Chauve et al.
2001; Narayan and Fisher 1993; Nattermann et al.
1992) and numerically (Leschhorn 1993; Rosso
et al. 2003) in recent years, and the main charac-
teristics of the solution have been well-understood.
These ﬁndings are summarized below.
The form of Eq. (5) suggests a “non-crossing
condition” as ﬁrst noted by Middleton (Middleton
1992a). Consider two interface conﬁgurations
u1(r, t0) and u2(r, t0) at some initial time t0. If
u1(r, t0) < u2(r, t0) for all r on the interface, one
can easily show that u1(r, t) < u2(r, t) at any later
time t > t0, i.e., the two solutions never touch if
initially one is completely behind the other. This
property in particular implies that the interface
velocity v ¼ du=dt (averaged over all sites r) in
the steady state is a unique and continuous func-
tion of F, ruling out ﬁrst order phase transition in
this class of models.
On the moving side but close to the depinning
threshold, advancement of the interface can be
described with the help of Fig. 2. The thick line
illustrates the interface position at a given time t0.
Pinning yields a roughness which grows as a
power-law of the distance between two points on
the interface, i.e.,
Collective Transport and Depinning, Fig. 2 An inter-
face above but close to the depinning threshold. Depinning
events within a correlation length xk and correlation time t
are highly correlated and obey scaling at the transition.
Shaded area represents the volume swept by the interface
over the time interval t
Collective Transport and Depinning
151

u r, t0
ð
Þ  u r0, t0
ð
Þ
½
2
D
E
 r  r0
j
j2z,
ð7Þ
where ζ is known as the roughness exponent. This
behavior holds on a range of length scales from
the pinning length Lc to a correlation length xk
along the interface. The transverse displacement
of the interface on scale xk is given by x⊥ xz
k.
Motion of the interface within a correlation
time t also obeys scaling. On time scales shorter
than t, the interface advances through a sequence
of rapid, localized movements (known as ava-
lanches) of varying size up to the scale xk. The
average time for a given site to move by a distance
Δu grows as a power law: Δt ~ Δu1/β. During this
time, activities within a distance l ~ Δt1/z along the
interface are correlated. The exponent z ¼ ζ/β is
known as the dynamical exponent. This scaling
terminates when l reaches the correlation length
xk, or Dt ¼ t  xz
k, where the interface as a whole
advances to a new disorder environment with a
different distribution of pinning sites and pinning
forces.
As F decreases towards Fc, the size of each
correlated domain grows to inﬁnity in a power-
law fashion as well, e.g., xk ~ |F – Fc|–n, where n is
known as the correlation length exponent. The
three exponents ζ, z and n together characterize
the critical properties of the interface at the
depinning transition. Through dimensional argu-
ments, one may determine the critical behavior of
quantities other than those discussed above. For
example, the interface velocity near the transition
can be estimated from v ’ x⊥=t  xz
k=xz
k 
F  Fc
j
jn zz
ð
Þ, hence the corresponding velocity
exponent is given by,
y ¼ n z  z
ð
Þ
ð8Þ
The region between two interface conﬁgura-
tions separated by time t, as shown in Fig. 2, can
be
described
as
a
set
of
“bubbles”,
each
representing a correlated volume of base area xD
k
and height x⊥. The average strength of the pinning
forces within each bubble has a variation of the
order xD=2
k
x1=2
⊥
from the system-wide average.
Variation of this quantity among bubbles should
be smaller than the excess driving force F – Fc so
that depinning can take place uniformly across the
system. This condition is fulﬁlled if the correla-
tion length exponent satisﬁes the following
inequality (Harris 1974; Narayan and Fisher
1993; Nattermann et al. 1992).
v 
2
D þ z
ð9Þ
The above description of interface depinning
applies also to the CDW with one important
caveat.
Due
to
the
non-crossing
condition,
steady-state motion of the CDW at F > Fc is
periodic in time, i.e., ’(r,
t þ t) ¼ ’(r,
t) þ
2π for all r, with t being the period of the attractor
(Middleton 1992a). The dynamic phase advance
at different sites has thus bounded variations
described by ζ ¼ 0. Above but close to Fc, the
activity at a given site, as measured by the phase
velocity _’ r, t
ð
Þ, is typically concentrated in time
windows much shorter than T, but acquires long-
ranged spatial correlations up to a correlation
length xk~(F  Fc)n. Both analytical (Narayan
and Fisher 1992) and numerical calculations
(Myers and Sethna 1993) indicate that n ¼ 1/2 in
all
dimensions,
therefore
violating
Eq.
(9).
Although the origin of this behavior has not
been settled completely (Narayan and Middleton
1994), a plausible explanation is that ﬂuctuations
of the pinning force in a given region of the
system are compensated by a static phase distor-
tion ’0(r) ¼ ’(r,
t ¼ 0), so that the system
behaves much more homogeneous than the naïve
estimate used to obtain Eq. (9). The sample-to-
sample ﬂuctuations of Fc, on the other hand, have
been shown recently (Bolech and Rosso 2004;
Fedorenko et al. 2006) to obey a Gaussian distri-
bution with a width proportional to L–D/2 as pre-
dicted, where L stands for the linear system size.
Numerical Results for the Critical Exponents
The depinning transition of the elastic manifolds
and the CDW has been studied extensively using
various lattice models. Middleton and Fisher
(1991, 1993), Myers and Sethna (1993), and
Narayan and Middleton (1994) simulated a
discretized version of Eq. (5) for CDW depinning
152
Collective Transport and Depinning

in one to three dimensions. The random force is
given by (r,
’) ¼ V sin (’  β(r)), where V is
the strength of the pinning force, and β(r) is the
preferred phase at site r, chosen randomly from
site to site. Values of critical exponents as deter-
mined in their numerical work are given in
Table 1, which show good agreement with the
analytic results in section “Analytical Treatments
of the Depinning Transition and Universality”.
The exponent nf (second row) is determined
from quantities related to the avalanche propaga-
tion below the depinning threshold.
Leschhorn (1993) carried out large-scale sim-
ulations of a discretized version of the LIM. Expo-
nents he obtained are also given in Table 1. These
values are in good agreement with more recent
studies (Rosso et al. 2003). Note that the rough
ness exponent ζ for a one-dimensional interface at
the depinning threshold is greater than one. This
gives rise to a subtlety in using Eq. (7) to measure
ζ as discussed in (Leschhorn and Tang 1993).
Analytical Treatments of the Depinning
Transition and Universality
The depinning transition differs from the usual
critical phenomena in thermal equilibrium sys-
tems in terms of the vast separation of fast and
slow time scales. Therefore the successful devel-
opment of a renormalization group theory in the
early 1990s to effectively capture this unique fea-
ture was an important milestone in the analytical
studies of nonequilibrium phase transitions. The
work acquired broader signiﬁcance due to the
later
discovered
correspondence
between
depinning and sand pile models of self-organized
criticality (SOC), which we discuss in section
“Self-Organized Criticality”.
Mean-Field Theory
Fisher (1985) and others (Koplik and Levine
1985; Leschhorn 1992; Leschhorn et al. 1997;
Narayan and Fisher 1992) considered a mean-
ﬁeld approximation to Eq. (5) which can be
treated analytically. It is instructive to examine
the calculation in some detail here as the solution
reveals
several
important
features
of
the
depinning transition which extend to lower
dimensions, while the mathematical manipula-
tions can be kept at an elementary level.
In sufﬁciently high dimensions, one may
approximate the Laplacian in Eq. (5) by a spring
force, whose equilibrium point is set by the mean
interface position u tð Þ. The resulting dynamical
equation for a given site on the interface takes the
form,
du=dt ¼ g u  u
ð
Þ þ  u
ð Þ þ F:
ð10Þ
For simplicity we have dropped m in (5)
through a redeﬁnition of t. In the steady-state,
u ¼ vt , where v is the interface velocity to be
determined self-consistently from the solution of
Eq. (10). Since the disorder (u) is uncorrelated
along the interface, the system-wide average ucan
be replaced by an average over the distribution of
(u).
Following the discussion in (Leschhorn et al.
1997), we adopt a moving frame and deﬁne x ¼
u  vt  (F  v)/γ to be the displacement away
from the equilibrium position when the random
force (u) is absent. In terms of x, Eq. (10) reads
(after a rigid translation of (u)),
Collective Transport and Depinning, Table 1 Scaling exponents at the depinning transition. Numbers in parentheses
indicate uncertainties in the last digit
Interfacea
CDW
MF
D  4
D ¼ 1
D ¼ 2
D ¼ 3
D ¼ 1
D ¼ 2
D ¼ 3
ζ (roughness)
1.25(1)
0.75(2)
0.35(1)
0
0
z (dynamic)
1.42(4)
1.56(6)
1.75(15)
1
1.32(4)b
1.65(6)b
2
n, nf (correlation
length)
1.33(2)
0.80(1)
0.606(4)
0.4(1)c
2.01(2)
0.5(1)c
0.98(3)b
0.5(1)c
0.68(4)b
1/2
θ (velocity)
0.25(3)
0.64(2)
0.84(2)
0.45(5)c
0.64(3)b,c
0.81(3)b,c
1
aLeschhorn (1993); bMiddleton and Fisher (1993); Narayan and Middleton (1994); cMayer and Sethna (1993)
Collective Transport and Depinning
153

dx=dt ¼ gx þ  vt þ x
ð
Þ:
ð11Þ
The self-consistency condition becomes,
g x
h i ¼ F þ v:
ð12Þ
The driving force F now disappears from the
equation of motion (11) and can be computed
from (12) as a function of v, once a solution
to (11) is found.
As illustrated in Fig. 3, Eq. (11) describes the
dynamics of an overdamped particle in a moving
potential,
W x, t
ð
Þ ¼ g
2 x2 þ U vt þ x
ð
Þ:
ð13Þ
The random part U vt þ x
ð
Þ ¼ 
Ð vtþx
x0
 u
ð Þdu
travels at a constant velocity v to the left or to
the right depending on the sign of v. In the
quasi-static limit v ! 0, the particle stays in a
local minimum of the potential W for the whole
time, and is interrupted occasionally by jumps
when the minimum it follows disappears. When
the potential travels to the left (v > 0), the
particle traces the leftmost minimum x+ of W.
The opposite occurs when the potential travels
to the right.
With the above picture in mind, we may use
Eq.
(12) to
calculate
the
thresholds
Fþ
c ¼
g lim v!0þ x
h i and F
c ¼  lim v!0 x
h i for for-
ward and backward depinning, respectively. For a
continuous, slow-varying function (u) with a
sufﬁciently small amplitude, the potential W has
a unique minimum all the time, and hence Fþ
c ¼
F
c ¼ 0, i.e., the system is never pinned. However,
for a discontinuous function (u) (or for sufﬁ-
ciently strong disorder), the potential W has,
from time to time, more than one minimum, and
hence Fþ
c ¼ F
c > 0 . Note that only upward
jumps in  (i.e. a sudden weakening of the pinning
force) give rise to upward cusps in the potential
which generate double minima in W.
When the potential W(x, t) travels at a small but
ﬁnite velocity v, the ball shown in Fig. 3b is
displaced to the leftmost minimum of W by an
amount proportional to v due to viscosity. From
Eq. (12) and the value of Fc determined above,
one ﬁnds v ¼ a(F – Fc), where a is a numerical
constant. This behavior is conﬁrmed by exact
solution of a “two-state” model for the pinning
force (Leschhorn 1992). The mean-ﬁeld velocity
exponent is thus given by θMF ¼ 1.
Collective Transport and Depinning, Fig. 3 The
mean-ﬁeld model of depinning. (a) Block (representing
the interface) dragged by a spring whose right end moves
at a slow but constant velocity v. The block is sitting on a
rough surface and immersed in a very viscous ﬂuid, so that
inertia effects can be neglected. (b) The effective potential
W on the block at a particular instant when viewed in a
co-moving frame. W is a sum of two parts: A quadratic
spring potential plus a random potential U which travels
slowly to the left. In the absence of thermal motion, the
block (represented by the red ball in the ﬁgure) traces the
left most minima x+ of W until it disappears, followed by an
“avalanche” into the next available minimum
154
Collective Transport and Depinning

Functional Renormalization Group
Equation (5) has been studied analytically since
the 1970s. Earlier attempts by Efetov and Larkin
(1977) and others (Feigel’man 1983; Koplik and
Levine 1985) based on a perturbative expansion
of the noise term around a ﬂat reference state ran
into divergences for D < Dc ¼ 4, which can not be
cured with the usual renormalization group (RG)
procedure. Breakthroughs were achieved in 1992
by Narayan and Fisher (1992) for the CDW
depinning and by Nattermann et al. (1992) for
the driven interface. In the ﬁeld theory jargon,
the model has an inﬁnite number of relevant oper-
ators that correspond to the coefﬁcients in a
power-law expansion of the random force corre-
lator Δ(u). Upon momentum shell integration on a
running scale L, the one-loop corrections to these
coefﬁcients can be summarized in terms of a func-
tional RG ﬂow for Δ(u),
dD u
ð Þ
d ln L ¼ cLe d2
du2
 1
2 D2 u
ð Þ  D u
ð ÞD 0
ð Þ
h
i
:
ð14Þ
Here ε ¼ 4 – D and c is a constant. Dependence
on L can be absorbed with the scaling transforma-
tion u ! Lζu, Δ ! L2ζ–εΔ. The resulting ﬂow
equation has an inﬁnite number of ﬁxed points,
which are distinguished by the number of nodes of
the function Δ. Figure 4 shows two such solutions,
the ﬁrst with no node at ζ ¼ ε/3, and the second with
inﬁnitely many nodes (periodic) at ζ ¼ 0.
The periodic ﬁxed point is associated with the
CDW depinning transition. The one with no node
describes the interface depinning transition. The
most prominent feature of the ﬁxed point function
Δ* is the cusp singularity at u ¼ 0, which is respon-
sible for the failure of previous RG treatments.
Equation (14) is supplemented with a RG
equation for the mobility m that determines the
dynamical response on scale L,
d ln m
d ln L ¼ cD00 0þ
ð
ÞLe:
ð15Þ
The elastic constant γ, on the other hand, is not
renormalized. The latter property yields the scal-
ing relation
v 2  z
ð
Þ ¼ 1:
ð16Þ
The functional RG analysis has been carried
out to two-loop order by Le Doussal and collabo-
rators (Chauve et al. 2001; Le Doussal et al.
2002). This study is particularly useful as it
helps to clear up several subtleties which can not
be easily resolved in the one-loop calculation. For
interface depinning, exponents up to the second
order in ε are given by,
z ¼ 1
3 e þ 0:047771e2
z ¼ 2  2
9 e  0:0432087e2
n ¼
1
2  z ¼ 1
2 þ 1
12 e þ 0:0258316e2
y ¼ n z  z
ð
Þ ¼ 1  1
9 e þ 0:040123e2:
ð17Þ
Good agreement is seen with the numerical
values given in Table 1.
Collective Transport and Depinning, Fig. 4 Fixed point solutions to Eq. (14) for (a) the linear interface models and
(b) the charge-density wave depinning
Collective Transport and Depinning
155

For CDW depinning, the two-loop analysis
yields the following exponents,
z ¼ 0
z ¼ 2  1
3 e  1
9 e2
n ¼
1
2  z ¼ 1
2
y ¼ n z  z
ð
Þ ¼ 1  1
6 e  1
18 e2:
ð18Þ
Interestingly, here the expression for the
dynamical exponent z truncated at ﬁrst order in ε
appears to be in better agreement with the simu-
lation results given in Table 1.
Very recently, Rosso et al. (2007) proposed and
implemented a scheme to measure numerically
the effective pinning force and the renormalized
correlator Δ on large distances. The idea is similar
to the mean-ﬁeld model discussed above, with the
particle replaced by the center of mass of the
manifold in a weak conﬁning potential that intro-
duces a running cut-off to spatial correlations.
Their numerical results provide direct conﬁrma-
tion of the cusp singularity in Δ, which has
become the hallmark of the RG theories for the
manifold problem.
Contact Line Depinning
The above analysis has been extended by Ertas
and Kardar (1994b) to the contact line depinning
problem. The increase in surface free energy
(or surface area) due to a deformation of the con-
tact line from an ideal straight conﬁguration has
been worked out previously by Joanny and de
Gennes (1984). Result of this analysis, general-
ized to a “contact manifold” with D internal
dimensions, is that the Laplace term in Eq. (5) is
replaced
by
a
nonlocal
term,
g∇2u !
Ð
dDr0 KD r  r0
ð
Þ u r0, t
ð
Þ  u tð Þ
½
:
Here
u tð Þ
denotes the mean displacement. The function
KD(r)~|r|D  1 describes the decay of the long-
ranged elastic coupling along the contact mani-
fold, assuming the modes in the “bulk” have
relaxed. This form of elastic coupling changes
the critical dimension to Dc ¼ 2. In terms of ε ¼
2 – D, the critical exponents of the depinning
transition from a two-loop renormalization group
calculation by Le Doussal et al. (2002) are given
by,
z ¼ 1
3 e þ 0:13245e2
z ¼ 1  2
9 e  0:1132997e2
n ¼
1
2  z ¼ 1 þ 1
3 e þ 0:24356e2
y ¼ n z  z
ð
Þ ¼ 1  2
9 e  0:1873737e2:
ð19Þ
Interestingly, the same long-range coupling is
found to describe tensile crack propagation
(Ramanathan and Fisher 1998). Numerical simu-
lations
(Duemmer
and
Krauth
2007)
of
a
discretized long-range model in D ¼ 1 (ε ¼ 1)
yield ζ ¼ 0.385(5), z ¼ 0.770(5), n ¼ 1.625(10),
θ ¼ 0.625(5), in good agreement with the theory.
Self-Organized Criticality
Close to the depinning threshold, motion of the
system is intermittent. The growth activities are
highly localized and exhibit strong correlations
over time. The natural separation of slow and fast
events at the onset of depinning invites comparison
to models of self-organized criticality (SOC) and of
earthquakes, which were made popular through the
seminal work of Bak, Tang and Wissenfeld (BTW)
(Bak et al. 1987; Bak et al. 1988) on the “sandpile”
model. This observation prompted a number of
detailed investigations of the microscopic pro-
cesses leading to the build-up of spatiotemporal
correlations
as
the
depinning
threshold
is
approached
from
below,
as
summarized
in
(Paczuski et al. 1996). Subsequent work by several
groups (Narayan and Middleton 1994; Paczuski
and Boettcher 1996) established a direct link
between these two classes of models. This devel-
opment has also contributed to a better understand-
ing of SOC in automaton models. It opens the door
to a systematic exploration of their scaling proper-
ties which were hitherto hindered by the lack of a
suitable continuum representation.
The mapping between depinning and SOC
automaton models is most easily understood by
156
Collective Transport and Depinning

considering u(r, t) in Eq. (5) as the accumulated
activity of a given lattice site r after time t
(Paczuski and Boettcher 1996). Take for exam-
ple the original sand-pile model introduced by
BTW on a square lattice. The system is speci-
ﬁed by an integer height z(x, y) on each lattice
site (x, y). Starting from a random set of values
z0(x, y), “sand” is gradually added through a
sequence of events z(x, y) ! z(x, y) þ 1, each
time only a single site is chosen randomly from
all available sites in the system for updating. If
the operation leads to an overﬂow, i.e., z(x,
y) > K, then toppling takes place according to
the rule,
z x, y
ð
Þ ! z x, y
ð
Þ  4
z x  1, y
ð
Þ ! z x  1, y
ð
Þ þ 1
z x, y  1
ð
Þ ! z x, y  1
ð
Þ þ 1:
ð20Þ
This process is continued until no site has a
height exceeding K. Let u(x, y; t) be the total
number of toppling events at site (x, y) from the
beginning of the process. Counting the number of
sand grains received and given away by the site
yields immediately
z x, y; t
ð
Þ ¼ z0 x, y
ð
Þ  4u x, y; t
ð
Þ þ u x þ 1, y; t
ð
Þ
þ u x  1, y; t
ð
Þ þ u x, y þ 1; t
ð
Þ
þ u x, y  1; t
ð
Þ
¼ z0 x, y
ð
Þ þ ∇2u,
ð21Þ
where ∇2 is the Laplace operator on the lattice.
The condition z(x, y; t) > K for toppling u ! u þ 1
is thus equivalent to
∇2u þ z0 x, y
ð
Þ  K > 0:
ð22Þ
The above growth rule is almost identical to a
lattice automaton model introduced by Narayan
and Middleton (1994) for CDW depinning. Com-
paring (22) to Eq. (5), we see that here (i) u is
restricted to take only integer values plus a ran-
dom, site dependent shift β(r), which can be con-
sidered as the preferred phase set by the local
disorder; (ii) The dynamical rules obey a global
symmetry u ! u þ 1, as in CDW depinning. The
usual wisdom in critical phenomena suggests that
the two models are in the same universality class
due to property (ii), while property (i) is a micro-
scopic detail which does not affect the scaling
properties at the depinning transition. Indeed, var-
ious scaling exponents determined through ana-
lytical and numerical studies of the two models
are shown to be consistent with each other
(Narayan and Middleton 1994; Tang and Bak
1988). Subtle differences exist, however, in the
way the system is driven to criticality (Narayan
and Middleton 1994; Paczuski et al. 1996). The
effect of boundary conditions also need to be
treated with care (Narayan and Middleton 1994).
To eliminate inertia effects in real sand pile
avalanches (Nagel 1992) which prevented direct
comparison with the BTW model, the Oslo group
(Christensen
et
al.
1996)
designed
a
two-
dimensional rice pile experiment that displays
power-law scaling and self-organized criticality.
The group also proposed an automaton model,
known as the Oslo model, which yields critical
exponents in good agreement with the experi-
ment. The Oslo model differs from the BTW
model only in the choice of the threshold value
K for toppling: Instead of taking a constant value,
K is site-dependent. Its value is updated after each
toppling event at the site. Consequently, condi-
tion (22) changes to,
∇2u þ z0 r
ð Þ  K r, u
ð
Þ > 0:
ð23Þ
The symmetry u ! u þ 1 is no longer present.
A similar discussion as above links the Oslo rice-
pile model to the LIM of depinning (Bonachela
et al. 2007; Paczuski and Boettcher 1996). Other
SOC models, such as the Manna model (Manna
1991) and the Zaitsev model (Zaitsev 1992), have
similar updating rules as the Oslo model and
hence belong to the LIM universality class as
well. The mechanism of self-organization and
the development of spatiotemporal correlations
in the SOC and depinning models have been
discussed in detail by Paczuski et al. (1996),
who have also identiﬁed a large number of scaling
relations that give all other exponents in terms of
two basic ones.
Collective Transport and Depinning
157

As an example, let us consider the power-law
distribution of the avalanche size which can be
measured, e.g., by the total number of toppling
events s when a new grain is added. For a system
of linear size L, the distribution satisﬁes the ﬁnite-
size scaling,
P s, L
ð
Þ ¼ stF s=Ld


:
ð24Þ
The mapping discussed above identiﬁes δ ¼
D þ ζ, i.e., the dimension of the total volume
swept by the interface in a system-wide ava-
lanche. On the other hand, a sum rule yields the
following expression,
t ¼ 2  z þ n1
z þ D
ð25Þ
For example, the exponents ζ ¼ 0 and n ¼ 1/2
for the CDW depinning predicts t ¼ 2 (D – 1)/D,
in excellent agreement with simulation results on
the sandpile model in two and three dimensions
(Tang and Bak 1988). Care must be taken, how-
ever, in applying Eq. (25) to the D ¼ 1 rice pile
model in the boundary driven case, as noted by
Paczuski and Boettcher (1996).
Interface Depinning in Anisotropic
Medium
Easy and Hard Directions of Depinning
The linear interface model deﬁned by Eq. (5)
together with Eq. (6) for the random force is
statistically invariant under the tilt transformation
u ! u þ s  r, where s is the slope of the interface.
Hence the depinning threshold Fc, as well as other
critical properties, are independent of the orienta-
tion of the interface. This property holds for an
interface moving in an isotropic medium.
When the medium is anisotropic, one or more
of the model parameters that enter the estimate
Eq. (4) for Fc may change with s. Consequently,
the
depinning
threshold
Fc(s)
becomes
orientation-dependent (Tang et al. 1995). An
interface oriented in the “easy” direction enters
the moving phase at the weakest driving. How-
ever, a moving interface in this direction is
generically unstable against faceting towards
directions of slower growth, particularly near the
depinning threshold. To illustrate this point, we
may consider a part of the interface that is slowed
down by an exceptionally strong pin. As the rest
of the interface moves forward at a higher veloc-
ity, a local tilt develops that moves the interface
away from the easy direction. This further
strengthens the pinning effect, producing a cone-
like structure. Indeed, the depinning transition in
the easy direction has been shown to be of ﬁrst
order with a velocity jump (Jeong et al. 1996).
The story is different for an interface oriented
in the “hard” direction. Both numerical (Amaral
et al. 1994, 1995; Buldyrev et al. 1992a; Tang and
Leschhorn 1992) and experimental (Amaral et al.
1995; Buldyrev et al. 1992a, b) studies have
shown that the depinning transition here is con-
tinuous, but the critical exponents take different
values from those of the LIM. Yet another set of
critical exponents are encountered when the inter-
face is forced to tilt away from the hard direction
by, say boundary conditions (Tang et al. 1995).
The resulting depinning problem is related to
directed percolation, which we consider in some
detail below.
A Lattice Automaton
Tang and Leschhorn (1992) introduced a lattice
automaton for imbibition in a two-dimensional
porous medium. Avery similar model was studied
by Buldyrev et al. (1992a) around the same time
and reported together with experimental results.
The automaton model is deﬁned as follows. On a
square lattice, each site (i, j) is assigned a random
pinning force (i, j), uniformly distributed in the
interval [0,1). At t ¼ 0, the interface hi is completely
ﬂat. In each time step, growth hi ! hi þ 1
is performed in parallel when either of the follow-
ing two conditions is satisﬁed: (i) the random force
(i, hi) on the interface at column i is less than a pre-
speciﬁed driving force f; or (ii) hi < hi–1 – 1 or
hi < hi þ 1 – 1. Thus to obtain a completely pinned
interface, we must have |hi – hi–1| 	 1 and (i, hi) > f
(called a blocking site) for all i. This condition
requires the existence of a directed percolating
path through blocking sites. Such paths exist if
the density p of blocking sites exceeds a critical
158
Collective Transport and Depinning

value pc ’ 0.539. Consequently, the depinning
threshold is given by fc ¼ 1 – pc ’ 0.461. It is
possible to show that, for f < fc, the interface stops
at the ﬁrst directed percolating path that lies fully
above its initial position.
The roughness of the incipient directed perco-
lating path at p ¼ pc is ζ ¼ n⊥/nk ’ 0.63, where
nk ¼ 1.733 and n⊥¼ 1.097 are exponents that
characterize the divergence of parallel and per-
pendicular correlation lengths, xk  p  pc
j
jnk ,
x⊥ p  pc
j
jn⊥, respectively [41]. This is also
the roughness exponent assumed by the interface
at the depinning threshold f ¼ fc. Simulations
(Tang and Leschhorn 1992) have shown that the
dynamic exponent z ¼ 1 at the depinning transi-
tion of the above model, while the crossover
length exponent n ¼ nk. From Eq. (8) one obtains
θ ¼ nk – n⊥’ 0.63.
The orientational dependence of the depinning
threshold in the automaton model has been stud-
ied by applying the helical boundary condition
hiþL ¼ hi þ sL which forces a global tilt (Tang
et al. 1995). The threshold force is indeed found to
be lower. This behavior matches well with the
well-known property of directed percolation: For
p > pc, percolating paths fall within a cone of
opening angle ’( p) around the symmetry direc-
tion (Kinzel 1982). If the average tilt s of the
interface exceeds this angle, no spanning perco-
lating path exists and the interface is free to move.
The roughness exponent of the cone boundary is
ζ ¼ 1/2, which belongs to yet another universality
class of interface depinning away from a symme-
try direction (Tang et al. 1995).
The above automaton model has been general-
ized by Buldyrev et al. (1992b) to higher dimen-
sions.
The
directed
percolating
strings
are
replaced by directed percolating surfaces which
have been considered in the context of resistor-
diode percolation (Dhar et al. 1981). The rough-
ness exponent of such a surface at the percolation
threshold in D ¼ 1 dimensions is given in Table 2.
Havlin et al. (1995) investigated in detail the
temporal sequence of growth activities at the
depinning transition, which exhibits an interesting
super-diffusive behavior. They argued that the
dynamic exponent z that describes the growth in
size of the affected region after an initial
depinning event is related to the scaling of mini-
mal path length with Euclidean distance on the
critical
(isotropic)
percolation
cluster
in
D dimensions. The values of z from their work
are also given in Table 2.
As in the 1 þ 1 dimensional case, a tilted
interface has a lower depinning threshold. Just
above the depinning threshold, the interface
decomposes into stripes of inactive regions per-
pendicular to the tilt, separated by active fronts
that propagate towards the “easy” direction at a
ﬁnite velocity. Based on this phenomenology,
Tang et al. (1995) determined exponents charac-
terizing the depinning transition of a tilted inter-
face. In particular, the velocity exponent θ ¼ 1 in
all dimensions.
Quenched KPZ Equation
The slope-dependent depinning threshold can be
modeled explicitly by adding the Kardar–Parisi–
Zhang (KPZ) term to Eq. (5). The resulting equa-
tion of motion takes the form,
m1 @u
@t ¼ g∇2u þ 1
2 l ∇u
ð
Þ2 þ  r, u
ð
Þ þ F: ð26Þ
In the original proposal (Kardar et al. 1986),
the l-term is due to a kinematic effect known as
lateral growth, and hence its strength is propor-
tional to the interface velocity v. At the depinning
Collective Transport and Depinning, Table 2 Summary of the exponents for directed percolation depinning along
the hard direction. After (Amaral et al. 1995)
D ¼ 1
D ¼ 2
D ¼ 3
D ¼ 4
D ¼ 5
D ¼ 6
MF
ζ (roughness)
0.63(1)
0.48(3)
0.35(1)
0.27(5)
0.25(5)
0.2(2)
0
z (dynamic)
1
1.15(5)
1.36 (5)
1.58(5)
1.7(1)
1.8(2)
2
n (correlation length)
1.73(2)
1.16(5)
0.95(10)
0.66(10)
0.6(1)
0.5(1)
1/2
θ (velocity)
0.58(7)
0.8(2)
1.0(2)
1.0(2)
1
Collective Transport and Depinning
159

threshold, however, this term is present only when
the medium is anisotropic. A positive l describes
depinning along a hard direction, while a negative
l corresponds to growth along an easy direction.
Directed numerical integrations (Csahók et al.
1993; Leschhorn 1996) of Eq. (26) in (1 þ 1)
dimensions yielded exponents consistent with
the directed percolation models. The relevance
of the KPZ nonlinearity in modifying the critical
behavior of the LIM has also been conﬁrmed by
renormalization group calculations (Le Doussal
and Wiese 2003; Stepanow 1995).
Future Directions
Through the intensive work by many groups in the
past 15 years, the depinning transition of elastic
manifolds in a disordered medium has emerged as
one of the best understood nonequilibrium critical
phenomena with nontrivial scaling properties.
The discovery of a renormalizable continuum the-
ory provided the much needed theoretical founda-
tion for the identiﬁcation of universality classes
and symmetry principles. Owing to this remark-
able development, models and experimental sys-
tems that differ in microscopic details can be
compared and classiﬁed with regard to their
threshold behavior. More recent reﬁnements of
the theory by the Paris group (e.g., Le Doussal
et al. 2008) have yielded deeper insights on the
role of the cusp singularity of the random force
correlator in capturing the multiple- minima
energy landscape of the disordered manifold
problem.
Within the class of models describe by Eq. (5),
there are still a few unresolved issues. For exam-
ple, the roughness exponent ζ of the (1 þ 1)-
dimensional LIM has been found numerically to
be indistinguishable to 5/4, suggesting the possi-
bility of an exact derivation. The effect of a ther-
mal noise term added to the deterministic model
has not been well-understood (Bustingorry et al.
2008; Middleton 1992b; Vandembroucq et al.
2004). There now exist very good numerical esti-
mates of the exponent c that describes the
vanishing of the interface velocity v ~ Tc with
temperature T at the depinning threshold, but its
value does not agree with any of the existing
theoretical proposals (Bustingorry et al. 2008).
Another puzzle is the closeness between the
numerical estimates for the dynamical exponent
z given in Table 1 and the one-loop RG prediction
for the CDW depinning.
The mapping between the CDW depinning and
the sandpile models offers a very powerful tool for
the development of RG theories for systems that
exhibit SOC. To our knowledge, this connection
has not been fully explored so far. It would be
interesting to see if SOC models other than the
sandpile and the rice-pile, such as the Olami–
Feder–Christensen model (Olami et al. 1992) for
earthquakes, can also be mapped to some type of
depinning model. Conversely, it would be nice to
ﬁnd out whether the lessons learned from the
detailed characterization of avalanche dynamics
(Dhar 2006) can contribute to a better understand-
ing of critical correlations in the LIM at the
depinning threshold from small to large scales.
On the experimental side, perhaps the best
studied system is the CDW depinning, yet the
CDW velocity generally grows faster than linear
above the depinning threshold (Thorne 2005),
while
the
elastic
depinning
theory
predicts
θ < 1. It has been suggested that the apparent
discrepancy could be due to a combination of
factors: Nonuniform driving, thermal activation
across energy barriers, and plasticity when dislo-
cations in the phase ﬁeld is present. Simultaneous
presence of strong pinning sites and weak collec-
tive pinning in a ﬁnite system may also give rise to
a complex I–V curve in experimental systems.
While some of these effects have been investi-
gated theoretically (Saunders et al. 2004) (see
also the review by Brazovskii and Nattermann),
a clear picture is yet to emerge.
Moulinet et al. (2002) designed an experimen-
tal system to study the roughness and dynamics of
the contact line of a viscous ﬂuid. The roughness
exponent ζ obtained from experimental measure-
ments is 0.5, much bigger than the value 0.385
obtained from numerical simulations (Duemmer
and Krauth 2007) of the model considered by
Ertas and Kardar (1994b). Similar discrepancies
have been reported in the experimental studies
(Bouchaud et al. 2002; Ponson et al. 2006) of
160
Collective Transport and Depinning

the roughness of crack fronts. Modiﬁcations of the
LIM to include nonlinear couplings and wavelike
dynamics (Bouchaud et al. 2002) for avalanche
propagation have been suggested. However,
many unresolved issues remain.
It is perhaps not surprising to see that real phys-
ical systems almost always contain complications
that invalidate direct comparison with the linear
elasticity theory of depinning. The pinned state
just below the transition is highly metastable and
hence is susceptible to various relaxational pro-
cesses that could possibly invalidate our simple
assumptions (see, however (Kolton et al. 2006)
for a discussion of correlation lengths below the
elastic depinning threshold). In-homogeneities
inside the sample, e.g., macroscopic variations in
the concentration of impurity atoms, may also have
a dramatic effect on the critical properties associ-
ated with the depinning transition. Incorporating
the relevant microscopic processes into the generic
description discussed here is expected to yield a
more complete theory of depinning. It is hoped that
future work in this direction will unleash the full
impact of the theoretical progress that have been
made in the past two decades, which in itself has
been intellectually extremely stimulating.
Bibliography
Primary Literature
Aharony A, Imry Y, Ma SK (1976) Lowering of dimen-
sionality in phase transitions with random ﬁelds. Phys
Rev Lett 37:1364–1367
Amaral LAN, Barabasi AL, Stanley HE (1994) Universal-
ity classes for interface growth with quenched disorder.
Phys Rev Lett 73:62–65
Amaral LAN, Barabasi AL, Buldyrev SV, Harrington ST,
Havlin S, Lahijany RS, Stanley HE (1995) Avalanches
and the directed percolation depinning model: experi-
ments, simulations, and theory. Phys Rev E 51:
4655–4673
Anderson PW (1984) Basic notions of condensed matter
physics. Benjamin/Cummings, Menlo Park
Bak P, Tang C, Wiesenfeld K (1987) Self-organized criti-
cality: an explanation for 1/f noise. Phys Rev Lett 59:
381–384
Bak P, Tang C, Wiesenfeld K (1988) Self-organized criti-
cality. Phys Rev A 38:364–374
Bolech CJ, Rosso A (2004) Universal statistics of the
critical depinning force of elastic systems in random
media. Phys Rev Lett 93:125701
Bonachela
JA,
Chaté
H,
Dornic
I,
Munoz
MA
(2007) Absorbing states and elastic interfaces in ran-
dom media: two equivalent descriptions of self-
organized criticality. Phys Rev Lett 98:155702
Bouchaud E, Bouchaud JP, Fisher DS, Ramanathan S, Rice
JR (2002) Can crack front waves explain the roughness
of cracks? J Mech Phys Solids 50:1703–1725
Bruinsma R, Aeppli G (1984) Interface motion and non-
equilibrium properties of the random-ﬁeld ising model.
Phys Rev Lett 52:1547–1550
Buldyrev SV, Barabasi AL, Caserta F, Havlin S, Stanley
HE, Vicsek T (1992a) Anomalous interface roughening
in porous media: experiment and model. Phys Rev
A 45:R8313–R8316
Buldyrev SV, Barabasi AL, Havlin S, Kertesz J, Stanley
HE, Xenias HS (1992b) Anomalous interface roughen-
ing in 3D porous media: experiment and model.
Physica A 191:220–226
Bustingorry S, Kolton AB, Giamarchi T (2008) Thermal
rounding of the depinning transition. Europhys Lett
81:26005
Chauve P, Le Doussal P, Wiese KJ (2001) Renormalization
of pinned elastic systems: how does it work beyond one
loop? Phys Rev Lett 86:1785–1788
Christensen K, Corral A, Frette V, Feder J, Jossang
T (1996) Tracer dispersion in a self-organized critical
system. Phys Rev Lett 77:107–110
Coppersmith SN, Millis AJ (1991) Diverging strains in the
phase-deformation model of sliding charge-density
waves. Phys Rev B 44:7799–7807
Csahók Z, Honda K, Vicsek T (1993) Dynamics of surface
roughening in disordered media. J Phys A 26:L171–
L178
de Gennes PG (1985) Wetting: statics and dynamics. Rev
Mod Phys 57:827–863
Dhar D (2006) Theoretical studies of self-organized criti-
cality. Physica A 369:29–70
Dhar D, Barma M, Phani MK (1981) Duality transforma-
tions for two-dimensional directed percolation and
resistance problems. Phys Rev Lett 47:1238–1241
Duemmer O, Krauth W (2007) Depinning exponents of the
driven long-range elastic string. J Stat Mech 2007:
P01019
Efetov KB, Larkin AI (1977) Charge-density wave in a
random potential. Sov Phys JETP 45:1236–1241
Ertas D, Kardar M (1994a) Anisotropic scaling in
depinning of a ﬂux line. Phys Rev Lett 73:1703–1706
Ertas D, Kardar M (1994b) Critical dynamics of contact
line depinning. Phys Rev E 49:R2532–R2535
Fedorenko AA, Doussal PL, Wiese KJ (2006) Universal
distribution of threshold forces at the depinning transi-
tion. Phys Rev B 74:041110
Feigel’man MV (1983) Propagation of a plane front in an
inhomogeneous medium. Sov Phys JETP 58:1076–1077
Fisher DS (1985) Sliding charge-density waves as a
dynamic critical phenomenon. Phys Rev B 31:
1396–1427
Fisher DS (1986) Interface ﬂuctuations in disordered sys-
tems: 5 – ε expansion and failure of dimensional reduc-
tion. Phys Rev Lett 56:1964–1967
Collective Transport and Depinning
161

Fukuyama H, Lee PA (1978) Dynamics of the charge-
density wave. I. Impurity pinning in a single chain.
Phys Rev B 17:535–541
Giamarchi T, Le Doussal P (1994) Elastic theory of pinned
ﬂux lattices. Phys Rev Lett 72:1530–1533
Granato A, Lüke K (1956) Theory of mechanical damping
due to dislocations. J Appl Phys 27:583–593
Grinstein G (1976) Ferromagnetic phase transitions in
random ﬁelds: the breakdown of scaling laws. Phys
Rev Lett 37:944–947
Grüner G (1988) The dynamics of charge-density waves.
Rev Mod Phys 60:1129–1181
Halpin-Healy T, Zhang YC (1995) Kinetic roughening
phenomena, stochastic growth, directed polymers and
all that. Aspects of multidisciplinary statistical mechan-
ics. Phys Rep 254:215–414
Harris AB (1974) Effect of random defects on the critical
behaviour of Ising models. J Phys C 7:1671–1692
Havlin S, Amaral LAN, Buldyrev SV, Harrington ST,
Stanley HE (1995) Dynamics of surface roughening
with quenched disorder. Phys Rev Lett 74:4205–4208
Imry Y, Ma SK (1975) Random-ﬁeld instability of the
ordered state of continuous symmetry. Phys Rev Lett
35:1399–1401
Jeong H, Kahng B, Kim D (1996) Anisotropic surface
growth model in disordered media. Phys Rev Lett 77:
5094–5097
Joanny JF, de Gennes PG (1984) A model for contact angle
hysteresis. J Chem Phys 81:552–562
Kardar M, Parisi G, Zhang YC (1986) Dynamic scaling of
growing interfaces. Phys Rev Lett 56:889–892
Kinzel W (1982) Directed percolation. In: Deutscher G,
Zallen R, Adler J (eds) Percolation structures and pro-
cesses.
Annals
of
the
Israel
Physical
Society,
vol 5. Hilger, Bristol, p 425
Kolton AB, Rosso A, Giamarchi T, Krauth W (2006)
Dynamics below the depinning threshold in disordered
elastic systems. Phys Rev Lett 97:057001
Koplik J, Levine H (1985) Interface moving through a
random background. Phys Rev B 32:280–292
Larkin AI (1970) Effect of inhomogeneities on the struc-
ture of the mixed state of superconductors. Sov Phys
JETP 31:784–786
Larkin AI, Ovchinnikov YN (1979) Pinning in type-II
superconductors. J Low Temp Phys 34:409–428
Le Doussal P, Wiese KJ (2003) Functional renormalization
group for anisotropic depinning and relation to
branching processes. Phys Rev E 67:016121
Le Doussal P, Wiese KJ, Chauve P (2002) Two-loop func-
tional renormalization group theory of the depinning
transition. Phys Rev B 66:174201
Le Doussal P, Wiese KJ, Chauve P (2004) Functional
renormalization group and the ﬁeld theory of disor-
dered elastic systems. Phys Rev E 69:026112
Le Doussal P, Muller M, Wiese KJ (2008) Cusps and
shocks in the renormalized potential of glassy random
manifolds: how functional renormalization group and
replica symmetry breaking ﬁt together. Phys Rev
B 77:064203
Lee PA, Rice TM (1979) Electric ﬁeld depinning of charge
density waves. Phys Rev B 19:3970–3980
Leger L, Joanny JF (1992) Liquid spreading. Rep Prog
Phys 55:431–486
Leschhorn H (1992) Interface motion in a random medium:
mean ﬁeld theory. J Phys A 25:L555–L560
Leschhorn H (1993) Interface depinning in a disordered
medium? Numerical results. Physica A 195:324–335
Leschhorn H (1996) Anisotropic interface depinning:
numerical results. Phys Rev E 54:1313–1320
Leschhorn H, Tang LH (1993) Comment on “Elastic string
in a random potential”. Phys Rev Lett 70:2973
Leschhorn H, Nattermann T, Stepanow S, Tang LH
(1997) Driven interface depinning in a disordered
medium. Ann Phys (Leipzig) 6:1–34
Manna S (1991) Two-state model of self-organized criti-
cality. J Phys A 24:L363–L369
Middleton AA (1992a) Asymptotic uniqueness of the slid-
ing state for charge-density waves. Phys Rev Lett 68:
670–673
Middleton AA (1992b) Thermal rounding of the charge-
density-wave depinning transition. Phys Rev B 45:
9465–9468
Middleton AA, Fisher DS (1991) Critical behavior of
pinned charge-density waves below the threshold for
sliding. Phys Rev Lett 66:92–95
Middleton AA, Fisher DS (1993) Critical behavior of
charge-density waves below threshold: numerical and
scaling analysis. Phys Rev B 47:3530–3552
Moulinet S, Guthmann C, Rolley E (2002) Roughness and
dynamics of a contact line of a viscous ﬂuid on a
disordered substrate. Eur Phys J E 8:437–443
Myers CR, Sethna JP (1993) Collective dynamics in a
model of sliding charge-density waves. I. Critical
behavior. Phys Rev B 47:11171–11192
Nagel SR (1992) Instabilities in a sandpile. Rev Mod Phys
64:321–325
Narayan O, Fisher DS (1992) Critical behavior of sliding
charge-density waves in 4 – ε dimensions. Phys Rev
B 46:11520–11549
Narayan O, Fisher DS (1993) Threshold critical dynamics
of driven interfaces in random media. Phys Rev B 48:
7030–7042
Narayan O, Middleton AA (1994) Avalanches and the
renormalization
group
for
pinned
charge-density
waves. Phys Rev B 49:244–256
Nattermann T (1990) Scaling approach to pinning: charge
density waves and giant ﬂux creep in superconductors.
Phys Rev Lett 64:2454–2457
Nattermann T, Stepanow S, Tang LH, Leschhorn H (1992)
Dynamics of interface depinning in a disordered
medium. J Phys II (Paris) 2:1483–1488
Olami Z, Feder HJS, Christensen K (1992) Self-organized
criticality in a continuous, nonconservative cellular
automaton modeling earthquakes. Phys Rev Lett 68:
1244–1247
Paczuski M, Boettcher S (1996) Universality in sandpiles,
interface depinning, and earthquake models. Phys Rev
Lett 77:111–114
162
Collective Transport and Depinning

Paczuski M, Maslov S, Bak P (1996) Avalanche dynamics
in evolution, growth, and depinning models. Phys Rev
E 53:414–443
Podgorski T, Flesselles JM, Limat L (2001) Corners, cusps,
and pearls in running drops. Phys Rev Lett 87:036102
Ponson L, Bonamy D, Bouchaud
E (2006)
Two-
dimensional scaling properties of experimental fracture
surfaces. Phys Rev Lett 96:035506
Ramanathan S, Fisher DS (1998) Onset of propagation of
planar cracks in heterogeneous media. Phys Rev B 58:
6026–6046
Rosso A, Hartmann AK, Krauth W (2003) Depinning of
elastic manifolds. Phys Rev E 67:021602
Rosso A, Le Doussal P, Wiese KJ (2007) Numerical cal-
culation of the functional renormalization group ﬁxed-
point functions at the depinning transition. Phys Rev
B 75:220201(R)
Ryu KS, Akinaga H, Shin SC (2007) Tunable scaling
behaviour observed in Barkhausen criticality of a fer-
romagnetic ﬁlm. Nat Phys 3:547–550
Saunders K, Schwarz JM, Marchetti MC, Middleton AA
(2004) Mean-ﬁeld theory of collective transport with
phase slips. Phys Rev B 70:024205
Sethna JP, Dahmen K, Kartha S, Krumhansl JA, Roberts
BW, Shore JD (1993) Hysteresis and hierarchies:
dynamics of disorder-driven ﬁrst-order phase transfor-
mations. Phys Rev Lett 70:3347–3350
Stepanow S (1995) Dynamics of growing interfaces in
disordered medium: the effect of lateral growth.
J Phys II (France) 5:11–18
Tang C, Bak P (1988) Critical exponents and scaling rela-
tions for self-organized criticality phenomena. Phys
Rev Lett 60:2347–2350
Tang LH, Leschhorn H (1992) Pinning by directed perco-
lation. Phys Rev A 45:R8309–R8312
Tang LH, Kardar M, Dhar D (1995) Driven depinning in
anisotropic media. Phys Rev Lett 74:920–923
Thorne RE (2005) A history of the I–V characteristic of
CDW conductors. J Phys IV France 131:89–94
Vandembroucq D, Skoe R, Roux S (2004) Universal
depinning force ﬂuctuations of an elastic line: applica-
tion
to
ﬁnite
temperature
behavior.
Phys
Rev
E 70:051101
Zaitsev SI (1992) Robin Hood as self-organized criticality.
Physica A 189:411–416
Zapperi S, Cizeau P, Durin G, Stanley HE (1998) Dynamics
of a ferromagnetic domain wall: Avalanches, depinning
transition, and the Barkhausen effect. Phys Rev B 58:
6353–6366
Books and Reviews
Alava M, Dubé M, Rost M (2004) Imbibition in disordered
media. Adv Phys 53:83–175
Blatter G, Feigelman MV, Geshkenbein VB, Larkin AI,
Vinokur VM (1994) Vortices in high-temperature
superconductors. Rev Mod Phys 66:1125–1388
Brazovskii S, Nattermann T (2004) Pinning and sliding of
driven elastic systems: from domain walls to charge
density waves. Adv Phys 53:177–252
de Gennes PG, Brochard-Wyart F, Quéré D (2003) Capil-
larity and wetting phenomena: drops, bubbles, pearls,
waves. Springer, New York
Fisher DS (1998) Collective transport in random media:
from super-conductors to earthquakes. Phys Rep 301:
113–150
Kardar M (1998) Nonequilibrium dynamics of interfaces
and lines. Phys Rep 301:85–112
Quéré D (2005) Non-sticking drops. Rep Prog Phys 68:
2495–2532
Sethna JP, Dahmen KA, Myers CR (2001) Crackling noise.
Nature 410:242–250
Turcotte DL (1999) Self-organized criticality. Rep Prog
Phys 62:1377–1429
Collective Transport and Depinning
163

Disordered Elastic Media
Thierry Giamarchi
DPMC-MaNEP, University of Geneva, Geneva,
Switzerland
Article Outline
Glossary
Deﬁnition of the Subject
Introduction
Static Properties of Disordered Elastic Media
Pinning and Dynamics
Future Directions
Bibliography
Glossary
Pinning An action exerted by impurities on an
object. The object has a preferential position in
space, and will move in response to an external
force only if this force is large enough.
Scaling The fact that each of two quantities
varies in a power-law relationship to the other.
Random manifold A single elastic structure (line,
sheet) embedded in a random environment.
Bragg glass A periodic elastic structure embed-
ded in a weakly disordered environment, nearly
as ordered as a solid but exhibiting some char-
acteristics normally associated with glasses.
Creep Very slow response at ﬁnite temperature
of a pinned structure in response to an external
force.
Definition of the Subject
Many seemingly different systems, with extremely
different microscopic physics, ranging from mag-
nets to superconductors, share the same essential
ingredients and can be described under the unifying
concept of disordered elastic media. In all these
systems, an internal elastic structure, such as an
interface between regions of opposite magnetiza-
tion in magnetic systems, is subject to the effects of
disorder existing in the material. A specially inter-
esting feature of all these systems is that these
disordered elastic structures can be set in motion
by applying an external force on them (e.g. a mag-
netic ﬁeld sets in motion a magnetic interface), and
that motion will be drastically affected by the pres-
ence of the disorder. What properties result from
this competition between elasticity and disorder is a
complicated problem which constitutes the essence
of the physics of disordered elastic media. The
resulting physics present characteristics similar to
those of glasses. This poses extremely challenging
fundamental questions in determining the static
and dynamic properties of these systems. Under-
standing both the static and dynamic properties of
these objects is not only an important question
from a fundamental point of view, but also has
strong practical applications. Indeed, being able to
write an interface between two regions of magne-
tization or polarization, and the speed of writing
and stability of such regions, is what conditions, in
particular, our ability to store information in such
systems, as (for example) recordings on a magnetic
hard drive. The physics pertaining to disordered
elastic media directly condition how we can use
these systems for practical applications.
Introduction
Understanding the statics and dynamics of elastic
systems in a random environment is a long-
standing problem with important applications for
a host of experimental systems. Such problems can
be split into two broad categories: (a) propagating
interfaces such as magnetic (Lemerle et al. 1998;
Krusin-Elbaum et al. 2001; Repain et al. 2004;
Metaxas et al. 2007), spintronic (Yamanouchi
et al. 2006, 2007), or ferroelectric (Tybell et al.
2002; Paruch et al. 2005) domain walls, ﬂuid
invasion
in
porous
media
(Wilkinsion
and
© Springer-Verlag 2009
B. Chakraborty (ed.), Statistical and Nonlinear Physics,
https://doi.org/10.1007/978-1-0716-1454-9_127
Originally published in
R. A. Meyers (ed.), Encyclopedia of Complexity and Systems Science, © Springer-Verlag 2009
https://doi.org/10.1007/978-3-642-27737-5_127
165

Willemsen
1983),
contact
lines
in
wetting
(Moulinet et al. 2002), epitaxial growth (Barabasi
and Stanley 1995) or crack propagation (Bouchaud
et al. 2002; Alava et al. 2006); (b) periodic systems
such as vortex lattices in type II superconductors
(Blatter et al. 1994; Nattermann and Scheidl 2000;
Giamarchi and Bhattacharya 2002), charge density
waves (Grüner 1988; Nattermann and Brazovskii
2004), magnetic bubbles (Seshadri and Westervelt
1992), colloids (Murray et al. 1990),Wigner crys-
tals of classical particles (Coupier et al. 2005) or of
electrons (Andrei et al. 1988; Giamarchi 2004).
Although all these systems have very different
microscopic descriptions, one aspect of their
physics is identical at a more macroscopic scale:
An object exists that obeys a macroscopic elastic
description. For case (a) this is an interface sepa-
rating two different regions of the system, for
example in a magnetic material a domain wall
separating regions of opposite magnetization. An
example of such an interface is shown in Fig. 1.
Since creating an interface costs energy, the inter-
face left to itself would tend to be ﬂat, and there is
an elastic cost to its deformations. Since this
object lives inside a microscopic crystal with dis-
order, it is also subjected to potentials that tend to
roughen it and pin it in speciﬁc regions of space.
This interface can be set in motion by applying an
external force on it, caused for example by a
magnetic ﬁeld for the magnetic domain wall or
an electric ﬁeld for a ferroelectric. For case (b),
that of periodic systems, a similar physics exists.
A “crystal” of objects (lines for vortices, points for
magnetic bubbles and colloids, or sheets for
charge-density waves) exists inside the system.
Since these objects repel each other, in the
absence of disorder they would tend to form a
perfect periodic crystal. In a way similar to the
interfaces, such crystals can be set in motion by
applying an external force (for example a current,
in the case of vortices). The disorder present at the
microscopic level tends to pin this crystal. It is
important to note that one is dealing here with the
physics of a crystal embedded in an external
medium containing impurities. The disorder can
thus vary at a length scale much smaller than the
lattice spacing of the moving crystal, which leads
to a physics radically novel compared to that of
chemical impurities in a regular solid. Under-
standing the physics, both static and dynamic, of
these objects has thus been a considerable chal-
lenge in the last 50 years or so. There are several
reasons for pursuing this interest, and for tackling
the challenges posed by this ﬁeld of disordered
elastic media.
First, at the fundamental level these systems
pose difﬁcult and important questions. It has been
known since the 1970s that the presence of disor-
der is crucial (Larkin 1970) and changes the phys-
ics completely. While the resulting models are
very difﬁcult to solve, they have contributed to
pushing the limits of our understanding of disor-
dered systems, and to developing new techniques
of statistical physics to deal with such issues. In
particular, it is clear that from the competition
between disorder and elasticity emerges a compli-
cated energy landscape with many metastable
states. This results in glassy properties (Mézard
et al. 1987) such as hysteresis and history depen-
dence of the static conﬁguration. Initially viewed
as toy models of glasses, these systems have
Disordered Elastic Media, Fig. 1 Left: an interface in a
magnetic system separating two different magnetic polar-
izations (dark and white). The image is 90  72 mm2. The
roughness of the domain wall due to the presence of disor-
der in the system is obvious on the image. Two positions of
the interface are shown. Dark and gray correspond to two
consecutive images after the interface has been pulled to
the right by applying a magnetic ﬁeld to the sample favor-
ing the magnetization direction on the left of the interface.
Such a magnetic ﬁeld acts as a force pulling the domain
wall. [From Lemerle et al. 1998 (Copyright 1998 by the
American Physical Society)]. Right: A vortex lattice
image, from Scanning Tunneling Microscope, in the super-
conductor MgB2. The tips of the vortices on the surface of
the sample are shown in the image, and correspond to the
red parts. The image is about 250nm2. In a perfectly pure
system, the vortex lattice is a periodic arrangement (here in
a triangular lattice) of objects of a given size (here the core
size of the vortex). Disorder affects this perfectly periodic
arrangement over a large distance. [From Eskildsen et al.
2002 (Copyright 2002 by the American Physical Society)]
166
Disordered Elastic Media

acquired their own importance and have posed
their own challenging questions. Understanding
the static properties of such systems has stimu-
lated
the
development
of
sophisticated
approaches such as replica theory (Mézard and
Parisi 1991), functional renormalization groups
(Fisher 1986) and numerical methods. Much pro-
gress has recently been accomplished due to both
analytical and numerical advances. If the static
view allows us to improve our techniques of sta-
tistical physics, the dynamic view is even more
complicated since most of our theoretical tools
fail. These systems thus provide wonderful moti-
vations to develop new techniques to tackle the
out-of-equilibrium dynamics of disordered sys-
tems and to understand and unify the concepts of
out-of-equilibrium physics of glasses.
Second, in addition to this theoretical motiva-
tion, the ability to apply these concepts in so many
different physical systems is a tremendous motiva-
tion and challenge. The various realizations allow
us to apply stringent tests to proposed theories and,
as we will see, have very often served to kill mis-
guided proposals or to put the theory on the right
track in these quite complicated systems. Experi-
ments in these systems can be remarkable by the
range they offer. In vortex systems, for example,
one can vary the vortex lattice spacing by several
orders of magnitude just by changing the magnetic
ﬁeld applied to the sample, something impossible
to do on a simple crystal. Similarly, for magnetic
domain walls, measurements of the velocity in
response to an external force can span about ten
orders of magnitude. This interplay and exchange
between theory and experiment has fueled the ﬁeld
and contributed greatly to its progress.
Last but not least, the phenomena studied for
disordered elastic media have a potential impact for
applications. Creating interfaces in magnetic or,
more recently, ferroelectric materials is a way to
store information (with “0” being one direction of
magnetization or polarization and “1” being the
reverse). This idea is at the root of information
storage in a magnetic hard drive or in ferroelectric
or magnetic bubble memory. How well one can
store the information is thus directly related to both
the static and dynamic properties of such inter-
faces. In particular,
stability
of the
written
information is ensured only if the interface is
pinned and will not meander due to outside forces,
such as thermal agitation. Similarly, there has been
much interest recently on spintronic materials
where the magnetic properties can be manipulated
by applying electrical currents (Yamanouchi et al.
2006; Yamanouchi et al. 2007). In the same vein,
multiferroic materials (Nature Group 2007) allow
manipulation of ferroelectric properties by the
application of magnetic ﬁelds. How the disordered
interfaces behave in such materials will certainly
determine their possible use for information tech-
nology. In a similar way, the vortex lattice in a
superconductor is set in motion by the application
of a current, while its motion generates a voltage.
The dynamic properties of the vortex lattice, and
how well it is pinned, thus directly affect the
absence of resistance of a superconductor (Blatter
et al. 1994; Nattermann and Scheidl 2000;
Giamarchi and Bhattacharya 2002), hence its
potential uses. Other examples, such propagation
of fractures, clearly show the potential importance
of such phenomena for applications.
This chapter presents basic concepts and results
in this very active ﬁeld. Section “Interfaces and
Basic Concepts” presents the basic concepts and
discusses the static properties of interfaces and
domain walls. Section “Periodic Systems and
Bragg Glass” deals with the periodic systems and
their differences compared to interfaces. Section
“Pinning and Dynamics” presents concepts and
important questions for the dynamics of disordered
elastic media, with focus on depinning in section
“Depinning”, on large velocity behavior in section
“High Velocity Phase” and responses to small
external forces in section “Small Applied Force
and Creep Motion”. Finally, section “Future Direc-
tions” discusses future directions of and perspec-
tives on the ﬁeld.
Static Properties of Disordered Elastic
Media
Interfaces and Basic Concepts
This section introduces the basic ingredients of the
systems under study and discusses the speciﬁc case
of interfaces. An interface is a sheet of dimension
Disordered Elastic Media
167

d living in a space of D dimensions. For realistic
interfaces D ¼ d þ 1, but generalizations are of
course possible. If we let r represent the internal
coordinate of the interface and z all its transverse
directions, the interface position is described by
displacement u(r) from a ﬂat conﬁguration. This
totally determines the shape of the interface pro-
vided that u is univalued, i.e., that there are no
overhangs or bubbles. The modelization of a one
dimensional interface (d ¼ 1) in a two dimensional
ﬁlm is shown in Fig. 2.
Since interface distortions cost elastic energy, a
system’s zero temperature equilibrium conﬁgura-
tion in the absence of disorder is ﬂat. Deviations
from this equilibrium position are described by a
Hamiltonian H[u] which is a function of the dis-
placement u. For small displacements one can
make the usual elastic approximation
H u½  ¼ 1
2
ð dd q
2p
ð
Þd c q
ð Þu
quq,
ð1Þ
where uq is the Fourier transform of u(r) and c(q)
are the so-called elastic coefﬁcients. If the elastic
forces acting on the interface are short ranged then
one has c(q) ¼ cq2 which corresponds to
H u½  ¼ c
2
ð
ddr ∇u rð Þ
ð
Þ2:
ð2Þ
For some interfaces where long range interac-
tions play a role, different forms of elasticity are
possible. This is particularly the case when dipolar
forces (Nattermann 1983) are taken into account
(Paruch et al. 2005) or for the contact line in
wetting (Joanny and de Gennes 1984) and crack
propagation (Gao and Rice 1989).
In addition to elastic energy, the interface gains
some energy by coupling to the disorder. Two
universality classes for the disorder exist (see
Fig. 3). The random bond disorder corresponds
to impurities that directly attract or repel the inter-
face. In contrast, for random ﬁeld disorder the
pinning energy is affected by all the randomness
that the interface has encountered in its previous
motion. On a more technical level, random bond
disorder couples in a symmetric way to the two
order parameters on each side of the domain wall,
while random ﬁeld disorder introduces an asym-
metry between these two in equivalent order
parameters. If V(r, z) denotes the random potential
generated by the impurities the pinning energy:
Hdis u½  ¼
ð
dd r
V r, u rð Þ
ð
Þ
random bond
ðu rð Þ
0
dzV r, z
ð
Þ
random field:
8
<
:
ð3Þ
As is obvious from Fig. 3, even if the micro-
scopic disorder is short-range correlated, as in the
case of the random ﬁeld disorder, the fact that the
energy of the system integrates between two posi-
tions of the interfaces means that long range cor-
relations exist if one considers the description
only in terms of the interface. The full Hamilto-
nian given by (1) and (3) describes the properties
of disordered elastic media, and despite its appar-
ent simplicity hides an extremely rich physics.
The competition between disorder and elastic-
ity manifests itself in several properties of the
Disordered Elastic Media, Fig. 2 A one dimensional
interface (such as a magnetic domain wall), shown in red,
living in a two dimensional space (ﬁlm). The position of
the interface is determined (provided there are no over-
hangs or bubbles) by the displacement u(r) from a ﬂat
conﬁguration, indicated by the dashed line. In the absence
of disorder, denoted by the blue dots, which pin the line in
preferred positions in space, the line would be ﬂat. The
competition between elasticity and disorder leads to the
physics of disordered elastic media and to glassy proper-
ties. The thickness of the line, denoted rf, or the correlation
length of the disorder deﬁne the Larkin length Lc for which
the relative displacements are of the order of rf, namely
u(Lc) – u(0) ~ rf
168
Disordered Elastic Media

interface. From an energetic point of view, this
competition leads to a complicated energy land-
scape for the conﬁgurations of the system, with
many metastable states leading to glassy proper-
ties. The competition also manifests itself in the
shape of the interface. In particular, it deviates
from the ﬂat conﬁguration and becomes rough.
From the scaling of the relative displacements
correlation function, a roughness exponent ζ can
be deﬁned from the correlation function of the
displacements
B rð Þ ¼
u rð Þ  u 0
ð Þ
½
2
D
E
/ r2z,
ð4Þ
where hi denotes thermodynamic average and   
denotes disorder average. There are relations
between the shape of the line and the energetic
properties. In particular, (4) suggests that dis-
placements
would
scale
with
distance
as
u(L) ~ Lζ. (2) suggests that the energy of a sample
of size L ﬂuctuates from sample to sample as
DF L
ð Þ  Ld2þ2z:
ð5Þ
Given the complexity of the problem, several
approximate methods have been put forward to
portray the role of disorder. A remarkable model
by which to probe the physics of such systems was
introduced by Larkin (1970), and goes by the
name of the Larkin model. The idea is to focus
on short length scale properties. In that case, the
displacements are small and one can expand the
disorder term in power of the displacements
Hdis ¼
ð
ddrV r, u rð Þ
ð
Þ
’
ð
ddr V r, 0
ð
Þ þ ∇r V r, 0
ð
Þ
½
jz¼0 u rð Þ:
ð6Þ
The ﬁrst term is a trivial constant and the sec-
ond one indicates that the interface is subject to a
random force
HL ¼
ð
dd r f rð Þu rð Þ:
ð7Þ
Although this model has several pathologies, it
has the advantage of being quadratic in the dis-
placement ﬁeld u and thus of being exactly solv-
able. It shows that below d ¼ 4, disorder plays a
major role. The displacements grow as a function
of distance and
B rð Þ ¼ r4d:
ð8Þ
This conﬁrms that there is algebraic roughen-
ing of the interface with the displacements grow-
ing as a power law of distance. One can deﬁne the
scaling u(L) ~ Lζ, with the Larkin model giving
ζ ¼ (4 – d)/2. Below d ¼ 4, disorder is relevant
and drastically modiﬁes the physical properties of
Disordered Elastic Media, Fig. 3 The two universality
classes of disorder (the names come from the magnetic
realization of such systems). In both ﬁgures the domain
wall in red separates two regions with different order
parameters, denoted by the two thick black arrows. Left:
random bond disorder. The impurities, denoted in blue,
couple symmetrically to the two sides of the domain wall,
thus only the impurities on the domain wall (denoted with
the orange circle) contribute to the energy. Right: random
ﬁeld disorder. The impurities, denoted by the blue arrows,
favor one of the two sides. Thus, all the impurities (denotes
in orange) between two conﬁgurations of the domain wall
contribute to the energy. This leads to a disorder seen by the
domain wall which has long range correlations, even if the
microscopic disorder is short-range correlated
Disordered Elastic Media
169

the interface compared to those of the non-
disordered one. In addition to the exponent itself,
since the displacements grow unboundedly, there
exists a length scale, Lc, called the Larkin length,
at which the displacements become of the order of
the only characteristic scale available, namely
either the correlation length of the random poten-
tial or the size of the interface rf, as shown in
Fig. 2. Clearly, this is also the length where the
applicability of the Larkin model breaks down,
since beyond that length the potential V(r, z) is
not smooth anymore and thus expansion in pow-
ers of u is not justiﬁed. Beyond this length, the
system will thus truly feel the effects of random
potential. One can thus expect metastability,
glassy effects and pinning to appear above that
length. One has to determine the physics of this
regime appearing above the Larkin length, which
we will call the random manifold regime. The
Larkin length is thus an important length scale
for the static properties since it separates two
different regimes for the interface. As I will dis-
cuss in section “Pinning and Dynamics”, the
Larkin length also has considerable consequences
for the dynamics.
To solve the problem in the random manifold
regime is not easy and requires greatly sophisti-
cated techniques of statistical physics. To get a
rough idea, one can simply use a scaling argument,
known as the Flory argument (Blatter et al. 1994).
At scale L, the elastic energy scales as cLd–2u(L)2.
To estimate the disorder term is more complicated
but one can assume that if L is large enough, one
sums random variables V(r, z). If one considers for
example random bond disorder, because the disor-
der is short-range correlated, one has
V r1, u1
ð
ÞV r2, u2
ð
Þ ¼ Ddm u1  u2
ð
Þdd r1  r2
ð
Þ:
ð9Þ
Since a δ(r) function has the dimension of 1/rd,
this leads to the scaling
V r, u
ð
Þ  D1=2u L
ð Þm=2Ld=2,
ð10Þ
where m is the number of components of u (for an
interface m ¼ 1). The disorder term thus scales as
Hdis ¼ D1=2u L
ð Þm=2Ld=2:
ð11Þ
Balancing the elastic and disorder terms leads
to a scaling u(L) ~ Lζ with z ¼ 4d
4þm for the random
bond case and z ¼ 4d
4m for the random ﬁeld case.
This argument suggests that even in the random
manifold, the interface remains rough, with
unbounded displacements growing with an alge-
braic roughness. The value of the exponent is
characteristic of the universality class of the dis-
order, and different from the one occurring below
L < Lc where the Larkin model applies.
Clearly this simple argument needs to be sub-
stantiated by more rigorous calculations. Because
the system is subjected to a random potential and
the metastability and glassy effects matter, one
can use the techniques traditionally used for dis-
ordered systems and spin glasses. For a one
dimensional interface, this problem can be solved
exactly and the roughness exponent ζ ¼ 2/3
obtained (Huse and Henley 1985; Kardar 1985).
Note that this exact value is, of course, slightly
different from the mean ﬁeld estimate. In higher
dimensions three main methods have been used to
tackle this problem. The ﬁrst one uses the
so-called replica trick (Mézard et al. 1987) to
average over the disorder and then a variational
approach to solve the corresponding ﬁeld theory
(Mézard and Parisi 1991). In this method the
initial symmetry between replicas is broken,
something familiar in spin-glasses and character-
istics of glasses with many metastable minima in
the energy. This approximate method gives back
the Flory exponent. The second method applies
the traditional renormalization technique (RG), so
successful for standard critical phenomena. This
consists in looking at the problem at larger and
larger length scales, eliminating degrees of free-
dom, while changing the Hamiltonian to ensure
that the large length scale physics remain invari-
ant. Usually one can expand the interaction poten-
tial, and only a few terms are relevant, which
means that the RG consists in the ﬂow of a small
number of coupling constants. In the case of dis-
ordered elastic systems, the task is considerably
more complex since all powers in the expansion of
the correlator of the disorder have the same scal-
ing dimension. During the ﬂow the whole
170
Disordered Elastic Media

correlator of the disorder is modiﬁed. One must
thus follow the renormalization of a whole func-
tion, hence the name functional renormalization
group (FRG) (Fisher 1986). This leads to a
remarkable property: Beyond a length scale that
coincides with the Larkin length, the disorder
correlator, initially a smooth analytic function,
becomes non-analytic and develops a cusp. The
appearance of this non-analyticity is, in this
method, the signal of glassy physics. FRG allows
us to obtain the roughening exponent in a system-
atic expansion in ϵ ¼ 4  d. This has been worked
out for the moment up to second order in ϵ ¼ 4 
d, leading to ζ ¼ 0.20829804ϵ þ 0.0068582ϵ2 and
ζ ¼ ϵ/3 for the random bond and random ﬁeld
disorder, respectively (Le Doussal et al. 2004).
Note that for the random ﬁeld the mean-ﬁeld
(Flory) exponent is exact due to the long range
nature of the disorder. In addition to these analyt-
ical approaches, a very useful approach is pro-
vided by numerical studies of such systems,
using either molecular dynamics simulations
(Giamarchi et al. 2006), Monte Carlo techniques
(Yoshino 1998; Rosso and Krauth 2002a), or spe-
cially designed algorithms (Rosso and Krauth
2002b; Petaja et al. 2006). Numerical approaches
are of course quite challenging due to the glassy
nature of the system with many metastable min-
ima close to the ground state. However they have
proven quite useful in obtaining not only the
asymptotic regime but also the full crossover
between
the
Larkin
and
random
manifold
regimes, as well as in incorporating the effects of
ﬁnite temperature.
These predictions can be veriﬁed experimen-
tally. I show in Fig. 4 the roughness exponent as
measured in a magnetic and a ferroelectric ﬁlm.
The algebraic growth of the correlation function
B(r) is clearly seen. These two experimental situ-
ations correspond to two different dimensional-
ities for the domain walls, due to the different
thicknesses of the material and different charac-
teristics of the domain wall.
Now we can say that we have a rather good
understanding of the static properties of the inter-
faces, at least for the simple case of local elasticity
shown here. Of course even for the statics this is
not the end of the story, since several microscopic
systems such as the contact line of a ﬂuid or
ferroelectric systems, have long range interactions
(dipolar interactions) making even the static prop-
erties quite challenging to determine. Other open
questions will be discussed in section “Future
Directions”.
Periodic Systems and Bragg Glass
Similar concepts apply directly to the case of peri-
odic systems. In all these systems the constituent
elements (lines for vortices, points for colloids and
magnetic bubbles, sheets for phase maxima in the
charge density wave systems) form a solid that is
embedded into the microscopic system but can
have widely different characteristics and, in partic-
ular, widely different lattice spacing. For example,
in the case of vortices, lattice spacing is controlled
by the magnetic ﬁeld and can easily be varied. An
important characteristic is that, in a similar fashion
to the interface, this crystal can be embedded in the
“external” disorder that corresponds to the imper-
fections of the real microscopic lattice in which this
artiﬁcial crystal lives. It is important to note that the
variation of the disorder potential can thus occur at
length scales much smaller than the lattice spacing.
Each point of the system can be described by an
equilibrium position R0
i forming a perfect lattice
(usually triangular for the vortex lattice), and a
displacement ui relative to this equilibrium posi-
tion, as shown on Fig. 5. As for the interfaces, the
interactions between the objects forming the crystal
favor a perfectly ordered crystal. The energy of the
system can be expanded for small deviations and
lead to a quadratic expansion in u characteristic of
an elastic energy. It is important to note that for
such an expansion to be valid, it is only necessary
for the relative displacements ui – uj between two
neighbors to be small. The displacements them-
selves can be arbitrary; for example translating
the whole crystal by a uniform displacement does
not change the energy.
H ¼ 1
2
X
i j
Ci j ui  u j

2,
ð12Þ
where the Cij are the elastic coefﬁcients of the
system. Since the interactions can be long range,
the elastic coefﬁcients are not necessarily limited
Disordered Elastic Media
171

to nearest neighbor only. Note that for such an
expansion to be meaningful, it is necessary for the
displacements to be uniquely deﬁned. This
assumes that there are no topological defects
(dislocations, disclinations) in the crystal. Indeed
in the presence of such defects, as shown in Fig. 5
the displacements have two different values when
circling around the defect. In order to use the
elastic approximation it is thus important to ascer-
tain that topological defects are not generated.
I will come back to this crucial point below.
As with the interfaces, the minimum energy
conﬁguration is the perfect crystal with all ui ¼
0. In the absence of disorder this perfect crystal
can be affected only by thermal ﬂuctuations. If
temperature becomes too large the crystal will
melt. A rule of thumb for melting is when the
relative displacements between two neighbors
become a sizeable fraction of the lattice spacing
ui  uiþ1
ð
Þ2
D
E
¼ C2
L a2,
ð13Þ
where h  i denotes the thermal average and CL is
a phenomenological constant which turns out to
be of the or der of CL ~ 0:1 to reproduce reason-
able values for the observed melting of solids.
This rule of thumb, called the Lindemann criterion
for melting, gives, in fact, quite decent results.
In the presence of disorder, one must add to the
elastic energy term (12) the energy coming from
Disordered Elastic Media, Fig. 4 Measurements of the
roughness exponent ζ in two experimental system. These
two examples show the algebraic roughness of the domain
walls. The top ﬁgures are the correlation function (4) of the
displacements B(r), and the bottom ones the measured
value of the roughness exponent ζ. Left: Magnetic domain
walls in thin magnetic ﬁlms. An exponent of ζ ~ 0:6 is
measured compatible with the value ζ ¼ 2/3 expected for a
one dimensional wall in a two dimensional space. [From
Lemerle et al. 1998 (Copyright 1998 by the American
Physical Society)]. Right: Ferroelectric domain wall in a
ferroelectric ﬁlm. An exponent of ζ ¼ 0:26 is measured.
This value is compatible with the value expected for a two
dimensional wall in a three dimensional space in the pres-
ence of long range dipolar interactions. [From Paruch et al.
2005 (Copyright 2005 by the American Physical Society)]
172
Disordered Elastic Media

the random potential created by the disorder. This
takes the form
Hdis ¼
ð
dd rV rð Þr rð Þ
¼
ð
dd rV rð Þ
X
i
d r  R0
i  ui


ð14Þ
and this term will clearly tend to disorder the
crystal.
The case of a periodic system constitutes a
specially important and interesting situation.
Indeed, the nature of order and the possible phases
are more complex than they are for interfaces. An
important question is thus whether these two sys-
tems are in the same universality class or not. In a
general way, the order in a periodic system is
characterized by a positional order, indicating
that, knowing the position of a reference particle,
one can ﬁnd a particular particle of the solid at a
given position. This positional order can be mea-
sured by the structure factor, which is the correla-
tion function of the Fourier transform of the
density S(q) ¼ h|rq|2i. In a perfect crystal, the
structure factor has divergent peaks at the position
of the reciprocal vectors K0 of the perfect lattice.
The presence of such divergent peaks indicates a
perfect positional order. The fact that one sees
peaks also indicates the existence of another type
of order, namely the orientational order in a solid.
This is illustrated in Fig. 6. The orientational order
indicates that if the bonds have a certain orienta-
tion in a region of space, this orientation is pre-
served in the other parts of the solid. Losing the
orientational order replaces the peaks in the struc-
ture factor by a ring since the orientation of a
given peak is not deﬁned any more. In standard
solids, both orders are usually lost at the same
time and the solid melts to a liquid, usually by a
ﬁrst order phase transition. But we also know that
in some cases for pure systems, such as two
dimensional solids, the melting may occur as a
two step process where the positional order is lost
ﬁrst and only then the orientational order, leading
to a so called hexatic phase (Nelson 1978).
A summary of the various cases is shown in
Fig. 7. In addition to these standard order param-
eters, a periodic system is also characterized by a
topological order corresponding to the fact that
the connectivity of the perfect crystal is preserved
by small displacements. Such order is determined
u
Disordered Elastic Media, Fig. 5 For a periodic system
the ability to deﬁne a displacement u(r) for the objects
(blue dots) compared to the perfect lattice (here a square
lattice corresponding to the intersections of the black
lines), necessitates the absence of topological defects.
Left: if there are no topological defects one can associate,
for each site R0
i of the perfect lattice, a displacement ui, as
indicated by the red arrow. Right: here there is a topological
defect, denoted by the red cross, corresponding to the
addition of one line of particles. In this case the displace-
ment ui is not univalued. From the point of view of the
particles on the left of the topological defect, the orange
particle has a displacement u of half a lattice spacing, while
one could surmise u ¼ 0 looking only at particles on the
right of the topological defect
Disordered Elastic Media, Fig. 6 A periodic system
possesses positional, orientational and topological order.
Left: positional order. A solid has perfect positional order
if, by knowing the position of a reference particle, one can
predict the position of a particle at distance L as indicated
by the dashed circle and the red arrow. Right: orientational
order. A solid has orientational order if, by knowing the
orientation of the bonds in a region of space, one can
predict the orientation at a distance L as indicated by the
red dashed lines. Note that the system need not possess
positional order for the orientational order to exist. Topo-
logical order: topological order exists if, after a triangula-
tion, the topology (i.e., the number of neighbors) of each
point of the solid is ﬁxed and the displacements can be
deﬁned in a univalued manner. The picture on the left
possesses perfect topological order
Disordered Elastic Media
173

by a triangulation of the solid and a determination
of the topology. If the topology is identical to that
of the perfect lattice, it means that the displace-
ments can be deﬁned in a univalued way across
the solid. In the liquid, topological defects such as
dislocations and disclinations destroy this perfect
topological order and the very concept of dis-
placements
around
an
equilibrium
position
becomes ill deﬁned, since in that case the dis-
placement ﬁeld is no longer univalued.
As for interfaces, disorder changes the proper-
ties of the pure elastic system. In order to take into
account the effect of disorder on periodic systems,
it is thus important to address two different aspects
of the problem: a) the effect of the disorder on an
approximation of the real system given by elastic
Disordered Elastic Media, Fig. 7 Decoration images of
vortex lattices, illustrating the difference between solid and
liquid phases. The top ﬁgures are the images in real space,
while the bottom ones are the structure factor S(q) ¼
h|r(q)|i. Left: the system is in a solid-like phase (in fact a
Bragg glass phase (see text)). The system possesses good
positional order and orientational order. This can be seen
both from the pictures in real space and from the structure
factor that shows Bragg peaks at the position of the recip-
rocal vectors K0 of the perfect underlying lattice. As shown
by the triangulation, most sites have six neighbors.
Topological defects where sites have ﬁve or seven neigh-
bors (as indicated by the triangles and square black marks
respectively) do exist, but are paired in 5–7 pairs, making
the system free of topological defects at large length scales.
Right: the system is in a liquid-like phase. Positional order
and orientational order are lost. The Bragg peaks are gone
and the structure factor has a ring-like structure (indicating
the loss of orientational order). Topological defects are
proliferating and are unpaired, contributing to the expo-
nential decay of order in the system. [Images from
M. Marchevsky, J. Aarts, P.H. Kes (unpublished)]
174
Disordered Elastic Media

theory; b) whether the disorder is able to generate
topological defects, in which case the very idea of
an elastic approximation breaks down and another
starting point should be found.
As was shown in the groundbreaking paper by
Larkin (1970), there always exists for d  4, a
characteristics length scale La for which the dis-
placements become of the order of the lattice
spacing a of the perfect crystal. The fact that
displacements can become as large as the lattice
spacing indicates that perfect positional order is
lost. The question of how this destruction takes
place and the nature of the resulting phase is a
long standing problem. Given the complexity of
the question, no solution existed until recently, but
it is interesting to see that the community con-
verged, by inference, on closely related models, to
a consensus that was accepted for a long time but
eventually proved wrong. The route followed was
to learn as much as possible from the interfaces.
At short distance, one can make an expansion in
powers of the displacements, and the system is
described by the Larkin model. This ceases to be
valid at the Larkin length Lc, for which the dis-
placements become of the order of the size rf of
the particle in the solid. Note that Lc and La are in
general two different length scales since the size
of the particle rf and the lattice spacing a are
usually different. Naturally, one has Lc < La. For
systems such as the vortex lattice or Wigner crys-
tals, the difference can be huge, while for charge-
density waves, one expects to have rf ~ a and thus
Lc ~ La. Below the Larkin length the system is
described by the Larkin model and thus by an
algebraic growth of the displacements with a
roughness exponent of ζ ¼ (4 – d)/2. Above the
Larkin length Lc, but for displacements smaller
than a (i.e., for lengths smaller than La), one can
consider that the various objects of the periodic
system don’t see each other except by their elastic
forces. In particular, they do not sample the same
random potential given the smallness of the dis-
placements. One thus has a regime very similar to
the random manifold regime of the interface. The
displacement continues to grow algebraically,
u ~ Lζ, albeit with a different exponent. Above
Lc, the connection between the growth of the
displacements and the structure factor (the density
density correlations) is non-trivial since the model
is non-Gaussian. Indeed the structure factor is
given by (Giamarchi and Le Doussal 1995a).
S K0 þ q
ð
Þ ¼
ð
ddqeiqrC rð Þ,
ð15Þ
where
C rð Þ ¼
eiK0u rð ÞeiK0u 0
ð Þ
D
E
:
ð16Þ
For Gaussian models such as the Larkin
model, one had C rð Þ ¼ exp K2
0=2B rð Þ



exp K2
0=2r2z


indicating a stretched exponen-
tial decay of positional order. Such an exponen-
tial decay of positional order would lead to non-
divergent peaks in the structure factor. The con-
stant ﬁnding of algebraic roughening, and the
existence of the length scale La seemed to sug-
gest that even beyond La the roughening is
also algebraic, with perhaps another exponent.
One
would
thus
naively
expect
C rð Þ ’
exp K2
0=2a2 r=La
ð
Þ2z
h
i
giving Lorentzian like
non-divergent Bragg peaks with a width con-
trolled by 1/La. In addition to this exponential
loss of positional order occurring even in the
elastic theory, one could question the very
starting point of the analysis, namely, the elastic
limit and the single-valuedness of the displace-
ments. One could indeed expect topological
defects (dislocations, disclinations etc.) to be
generated at the scale La where the displace-
ments are of the order of the lattice spacing a.
Indeed there are arguments (Fisher et al. 1990)
(incorrect, as we will see) “showing” that an
arbitrarily small disorder would always gener-
ate topological defects at length scale La, lead-
ing
deﬁnitely
to
an
exponential
loss
of
positional order beyond this length. All these
elements thus seemed to click together to sug-
gest the picture of a crystal broken into little
crystallites of size La as shown in Fig. 8.
A consensus was thus reached in the community
that disordered periodic systems would just lose
translational order, and some theories for the
vortex lattices were built on this incorrect pre-
mise. However this picture crumbled on two
Disordered Elastic Media
175

fronts. On the experimental side, it was in direct
contradiction with experiments showing, for
example, extremely large regions free of defects
(Grier et al. 1991; Kim et al. 1996) or a ﬁrst
order melting (Schilling et al. 1996), which was
hardly compatible with a very disordered solid
in which all positional order would have been
lost from the start. On the theory side, our under-
standing of glassy systems reached a point
where better solutions of this problem can be
found. The displacements were found to grow in
fact only logarithmically (Giamarchi and Le
Doussal 1995a; Nattermann 1990; Korshunov
1993; Giamarchi and Le Doussal 1994) with
distance B rð Þ ¼ A0
d log rð Þ (or u(L) ~ log(L)1/2).
The prefactor A0
d was computed using either a
variational approach (Giamarchi and Le Doussal
1995a; Korshunov 1993; Giamarchi and Le
Doussal 1994) or an FRG one (Giamarchi and
Le Doussal 1994, 1995a). Elastic disordered sys-
tems have, therefore, a completely different
roughness than interface systems. This a priori
surprising behavior can be explained in a quali-
tative way as shown in Fig. 9. Quite interestingly
the structure factor and positional order could
still be computed for the full model (Giamarchi
and Le Doussal 1994, 1995a), and it was shown
that in a quite nontrivial way, the relation
C rð Þ ¼ exp K2
0=2B rð Þ


remains essentially
applicable, leading to a power-law decay of posi-
tional order C(r) / (1/r), where the exponent ,
is for all practical purposes, a number determined
only by the dimension (Bogner et al. 2001). For
example  ¼ 1–1.2 for a three dimensional vor-
tex lattice. The algebraic decay of positional
order as well as the value of the exponent indi-
cated that the system still retained divergent
Bragg peaks in its structure factor and thus,
although indeed losing positional order, the loss
was very slow and the system was nearly as
ordered as a perfect solid. Furthermore, it has
been shown (Giamarchi and Le Doussal 1995a)
that the argument claiming that disorder would
always generate dislocations was incorrect and
that, on the contrary, due to the slow algebraic
decay of the positional order, a three dimensional
Disordered Elastic Media, Fig. 8 Left: the (incorrect)
image of an elastic medium in presence of disorder. The
system would be broken into “crystallites” of size La char-
acteristic size for which the displacements become of the
order of the lattice spacing a (u(La) ~ a). At the same length
scale to release part of the elastic energy due to disorder, the
system
would
prefer
to
create
topological
defects
(schematically indicated by the red crosses). Beyond the
size La indicated by the blue dashed line, positional order
would be lost exponentially quickly. Right: the Bragg
glass, describing the properties of a disordered periodic
system in the presence of weak disorder. Although posi-
tional order is destroyed at large length scale, and the
length scale La for which displacements are of order
a exists, the system preserves quasi-long range positional
order, and perfect topological order. No “crystallite” is thus
associated with the length scale La, and no topological
defects are generated by the disorder
Disordered Elastic Media, Fig. 9 Schematic explana-
tion of the difference of roughness between interfaces and
periodic systems. Left: In an interface, a high degree of
roughness is produced by the fact that there are always
regions where it is energetically favorable for the line to go,
and from there further to another region, endlessly increas-
ing the displacements. Right: For a periodic system (here a
periodic system of lines of period a), since what counts is
the total energy of the system, there is no interest for one
line to make displacements much larger than the interline
distance, since it would just steal disorder from the neigh-
bor. Thus, even with the same disorder, displacements
would “saturate” (in fact still grow but very slowly with
distance) when they reach the inter particle distance
176
Disordered Elastic Media

system is stable to the generation of dislocations,
at least when the disorder is below a certain
threshold. This has led to a physics for a periodic
disordered system radically different from the
generally accepted consensus. In particular, con-
sider the two following facts: (a) algebraic
(quasi-long range) decay of the positional order,
and divergent Bragg peaks; (b) absence of topo-
logical
defect
has
led
to
the
prediction
(Giamarchi and Le Doussal 1995a) that the dis-
ordered periodic system are in fact in a new state
of matter, the Bragg glass. Such a system is a
disordered system with glassy properties: an
energy landscape with many metastable states
and the dynamics of a glass, but which “looks”
nearly as ordered as a perfect solid. After the
Bragg glass was ﬁrst predicted, its existence has
been supported by further analytical (Carpentier
et al. 1996; Kierfeld et al. 1997; Fisher 1997) and
numerical (Gingras and Huse 1996; Otterlo et al.
1998) calculations.
The existence of the Bragg glass phase has
important consequences and makes it possible to
reconcile several apparently contradictory results
on the phase diagram of the vortices. It allows us
to explain that very large regions free of disloca-
tions can be observed (Grier et al. 1991; Kim et al.
1996) while the system is obviously pinned by the
disorder. It also explains (Giamarchi and Le
Doussal 1995b) the narrow peaks observed in
neutron scattering experiments (Yaron et al.
1994; Ling et al. 2001), with a width given by
the experimental resolution, which were indicat-
ing an excellent degree of positional order. The
power-law nature of the peaks has been directly
tested in neutron scattering experiments, proving
directly the existence of the Bragg glass phase
(Klein et al. 2001). In addition to its intrinsic
properties, the presence of the Bragg glass phase
puts strong constraints on the phase diagram.
Indeed, since it is a phase without free topological
defects, this phase has to “melt” either when the
temperature becomes too high or the disorder too
strong, since topological defects have to appear. In
vortex systems the latter can be done by changing
the magnetic ﬁeld. The Bragg glass thus provides
a very natural explanation (Giamarchi and Le
Doussal 1995a, 1997; Ertas and Nelson 1996)
for the existence of a “melting” phase transition
as a function of the magnetic ﬁeld (Khaykovich
et al. 1996; Deligiannis et al. 1997), such a tran-
sition being associated with the destruction of the
Bragg glass phase (Paltiel et al. 2000; Avraham
et al. 2001). An example is shown in Fig. 10.
This section can cover only a fraction of the
physics of periodic systems, and several other
questions have been explored. I refer the reader
to the above mentioned literature on the subject
for more details.
Pinning and Dynamics
Let us now turn to dynamic properties. One of the
main interests of such systems is the fact that their
dynamics can easily be probed. Indeed most of
these systems can be set in motion by an external
force acting directly on the interface or on the
crystal,
and
the
velocity
v
versus
force
F characteristics are directly measurable. As men-
tioned before, this is of special importance since
these characteristics are linked to paramount prop-
erties of the systems (voltage current for vortices,
current-voltage for CDW and Wigner crystals,
velocity-applied magnetic ﬁeld for magnetic
domain walls). In addition to this practical impor-
tance, the dynamics will reﬂect, even in a more
dramatic way than the statics, the competition
between disorder and elasticity. In particular, one
can expect the dynamics to be dramatically sensi-
tive to the glassy properties and the energy
landscape.
The main issues relating to the application of
an external force are shown in Fig. 11. In the
presence of disorder it is natural to expect that,
at zero temperature, the system remains pinned
and polarizes only under the action of a small
applied force, i.e., it moves until it locks on a
local minimum of the tilted energy landscape.
At a larger drive, the system follows the force
F and acquires a nonzero asymptotic velocity v.
So a ﬁrst set of questions is prompted by the
zero temperature properties: what is Fc and how
can it be computed? In addition, the v – F curve
at T ¼ 0 is reminiscent of the curve of an order
parameter in a second order phase transition.
Disordered Elastic Media
177

Here, the system being out of equilibrium, no
direct analogy is possible, but this suggests that
one could expect v ~ (F – Fc)β with a dynam-
ical critical exponent β. Whether such an
analogy to critical phenomena holds and what
the physical consequences and calculation of
such exponents might be are, of course, impor-
tant questions.
Disordered Elastic Media, Fig. 10 Left top: Schematic
theoretical phase diagram for vortices as a function of the
temperature T and the magnetic ﬁeld H, or the disorder D.
The Bragg glass (BrG) that has perfect topological order
can melt either due to thermal ﬂuctuations (red line) or
because the disorder becomes too large (green line). The
existence of the Bragg glass thus implies a single melting
curve having a crossover between these two regimes. The
melting of the Bragg glass thus explain the existence of a
transition as a function of the magnetic ﬁeld. The blue
dashed line would be the melting line of the solid in the
absence of disorder (After Giamarchi and Le Doussal
1997). Left bottom: Measured phase diagram for high
temperature superconductor BSCCO, showing that both
melting transitions with temperature and with magnetic
ﬁeld are indeed the same melting curve. [From Avraham
et al. 2001 (Copyright 2001 by the Nature group)]. Right:
Neutron diffraction on the superconductor BKBO. The
structure factor shows clear Bragg peaks, indicating the
good degree of both positional and orientational order
despite the disorder present in the sample. As shown in
the bottom diagram the width of the structure factor does
not change when the magnetic ﬁeld is changed, since it is
controlled by the experimental resolution, while the height
decreases. This is in agreement with the consequences of a
power law divergent Bragg peak, and is thus a test of the
existence of the Bragg glass. [From Klein et al. 2001
(Copyright 2001 by the Nature group)]
178
Disordered Elastic Media

Another important set of questions pertains to
the nature of the moving phase itself, and in par-
ticular to behavior at large velocity: to what extent
does this moving system resemble the static one?
This concerns both the positional order properties
and the ﬂuctuations in velocity such as the ones
measured in noise experiments. Can we expect
novel physics there, or is the system simply “surf-
ing” over the disorder?
Finally, how does the system respond to a very
small applied force? We are accustomed to the fact
that a normal system when perturbed usually
responds linearly to the perturbation. We could
thus naively expect v / F, with a coefﬁcient that
would deﬁne the “mobility” of the interface. Is
this true, or, due to the glassy nature of the system,
do we have nonlinear response and more compli-
cated physics?
General Description of the Dynamics
Computing the dynamics is not an easy task. Let
me illustrate the method using the case of the
interfaces. The displacement ﬁeld in each point
is now a function of the time u(r, t) and has to obey
the equation of motion. The starting point is the
equation of motion
m d2u r, t
ð
Þ
dt2
þ  du r, t
ð
Þ
dt
¼
X
F,
ð17Þ
where  is a friction coefﬁcient that phenomenolog-
ically describes the dissipation processes that take
place inside the object (interface, etc.) when there is
motion. Usually one is interested in the steady state
motion of the system, in which case in the long time
limit, the second order derivative becomes smaller
than the ﬁrst order one and a good approximation is
to take m ¼ 0 in the above equation.
The forces are of two types. There are the
forces deriving from a Hamiltonian
F u r, t
ð
Þ
½
 ¼  @H u½ 
@u r, t
ð
Þ :
ð18Þ
The two main contributions (elastic and disor-
der) lead in the equation of motion to the elastic
forces trying to keep the interface ﬂat, and to the
pinning forces. In addition to these forces that
would be present in equilibrium, one must add
two other forces: The ﬁrst one is the external
force. I consider here only the simple case of a
constant external force F. In the presence of this
force and in the absence of pinning it is natural to
expect the system to reach a steady state velocity
v ¼ F/. Note that such a state, although time-
independent, cannot be described by an equilib-
rium theory. In particular, the ﬂuctuation dissipa-
tion
theorem,
relating
in
equilibrium
the
ﬂuctuations in the absence of a perturbation and
the response of the system to an external perturba-
tion, is not in general obeyed any more. The second
force is needed if we want to describe the system at
a ﬁnite temperature. In that case, one must add
(Zinn-Justin 1989) a Langevin force ζ(z, t) which
is a noise with correlations
z r, t
ð
Þz r0
ð , t0Þ
h
i ¼ Td r  r0
ð
Þd t  t0
ð
Þ:
ð19Þ
The equation of motion thus becomes, in its
simplest incarnation,
 du r, t
ð
Þ
dt
¼  @H u½ 
@u r, t
ð
Þ þ F þ z r, t
ð
Þ:
ð20Þ
As is well known, the presence of Langevin
noise ensures that, in the absence of an external
Disordered
Elastic
Media,
Fig.
11 The
velocity
v induced by an external force F of a disordered elastic
system. In the absence of pinning and with a damping
coefﬁcient  the steady state velocity v ¼ F/ is reached.
At zero temperature T ¼ 0 the system stays pinned until a
critical force Fc is reached. At ﬁnite temperature a motion
can occur even for forces below the threshold F < Fc, since
the barriers to motion can always be passed by thermal
activation. One can distinguish three very different regimes
in this curve: large velocity, depinning and small force
response (creep)
Disordered Elastic Media
179

force F, the time evolution of the system repro-
duces the thermodynamic ensemble average. In
other words, the equal time correlations hu(z,
t)
u(z0,
t)i obtained by averaging over the thermal
noises, are identical to the equilibrium correlation
function
hu(z)u(z0)iH
that
one
would
have
obtained for a system with the Hamiltonian H at
the temperature T.
In the absence of disorder the equation
becomes quite simple and is known as the
Edwards–Wilkinson equation
 du r, t
ð
Þ
dt
¼ ∇2
r u r, t
ð
Þ þ F þ z r, t
ð
Þ:
ð21Þ
The system thus slides at a constant velocity
v ¼ F/ and one can see that in the moving frame
the interface is at equilibrium, since the change of
variable u r, t
ð
Þ ¼ F
 t þ du r, t
ð
Þ gives for the rela-
tive displacements δu(r, t) exactly the same equa-
tion as in equilibrium in the absence of any
external force. Even in this simple case, there are
several effects of the motion that need to be taken
into account, in particular the presence of a cutoff
in the system generates terms that would not nor-
mally have been incorporated in the original equa-
tion of motion and that can modify the behavior of
the system. The most well known is the so called
Kardar–Parisi–Zhang
(KPZ)
term
(Kardar
et al. 1986).
In the presence of disorder, the equation of
motion becomes extremely complicated to solve
since the pinning force is a random variable
depending on the particular realization of the
disorder, and a double averaging must be done,
both on the thermal noise and on the disorder. No
perfect method exists to treat such an equation.
Since we are usually better equipped to deal with
integrals than with differential equations, espe-
cially with stochastic terms, a convenient rewrit-
ing of this equation exists, which formally gives
back the equivalent of a path integral and an
action. This is the so-called Martin–Siggia–
Rose (MSR) formalism (Janssen 1976; Martin
et al. 1973). I refer the reader to the literature
on this relatively specialized method (Zinn-
Justin 1989). The advantage is that it allows
averaging over the disorder from the start. This
in particular paves the way for an FRG treatment
of the problem.
Depinning
The ﬁrst set of questions arises around depinning.
Indeed, in the presence of disorder the naive
expectation is that the interface is unable to
move, at zero temperature, below a certain thresh-
old of force Fc called the pinning force. Comput-
ing this pinning force is not easy. In a remarkable
feat of physical intuition, Larkin has shown that
the pinning force can be directly obtained from the
static
behavior
of
the
system
(Larkin
and
Ovchinnikov 1979). Indeed, the idea is that the
pinning force is related to the appearance of many
metastable states and the presence of random
potential. Because it is quadratic in the displace-
ments, the Larkin model does not exhibit a pin-
ning force. The idea would thus be to relate the
pinning force to the length scale at which the
Larkin model ceases to pertain. As we discussed
before, this is the length Lc for which the displace-
ments are of the order of the correlation length of
the random potential or the width of the elastic
object. At that scale, the elastic plus disorder
energy scales as cLd2
c
r2
f
while the additional
energy due to the force scales as
HF ¼
ð
ddrFu rð Þ  FLd
c r f :
ð22Þ
Balancing the two terms leads to the famous
Larkin collective pinning force
Fc ¼ cr f
L2
c
:
ð23Þ
This is a remarkable relation since it relates a
dynamic property to purely static quantities. This
intuitive result can be substantiated by consider-
ably more complicated calculations. In the next
section we will see another rough estimate based
on a large velocity expansion. Finally, starting
from the equation of motion (17), it is possible
to obtain Fc from an FRG calculation (Nattermann
et al. 1992; Chauve et al. 2000), conﬁrming, from
this microscopic calculation, Larkin’s result.
Numerical methods have allowed an extremely
180
Disordered Elastic Media

precise calculation of Fc (Rosso and Krauth
2002b).
Besides the existence of the pinning force itself,
the description of depinning is a considerable chal-
lenge. A very fruitful line of approach for this
problem was suggested by D.S. Fisher (1985).
Indeed, looking at the v – F characteristics is
strongly reminiscent of the curve of an order
parameter as a function of temperature in a second
order phase transition (zero for T > Tc and non-zero
for T < Tc). This strongly suggests using an anal-
ogy with a standard critical phenomenon to analyze
the depinning. In particular, one can infer from this
analogy that a divergent length scale exists at the
transition, and that one can deﬁne scaling behavior
and critical exponents as a function of this length
scale. One can deﬁne a critical exponent for the
velocity v ~ (F – Fc)β, for the correlation length
x ~ (F – Fc)–n and a dynamical exponent relating
space and time divergences t ~ xz. These exponents
are related by scaling relations, analogous to those
of standard critical phenomena and that can be
computed by looking at the scaling of the equation
of motion. The scaling relations are
n ¼
b
2  z ¼
1
z  z :
ð24Þ
Such scaling behavior is directly conﬁrmed
from solutions of the equation of motion, either
from FRG or from numerical simulations. The
length scale x can be identiﬁed as the length
scale of avalanches. Computing and measuring
these exponents is a considerable challenge and
sophisticated FRG (Le Doussal et al. 2004;
Nattermann et al. 1992; Chauve et al. 2000;
Narayan and Fisher 1993) or numerical (Rosso
and Krauth 2002b; Duemmer and Krauth 2005)
techniques have been developed for this goal.
In addition to these quantities characterizing the
motion of the line, other important physical observ-
ables are modiﬁed by the application of external
force. This is in particular the case of the roughness
of the line. Right at depinning F ¼ Fc, the line is
much more rough than when in equilibrium, since
it is on the verge of depinning. There is thus a new
roughness exponent ζdep which can be computed
and is ζdep ~ 1:2 for a one dimensional interface.
This result has two very important consequences.
The ﬁrst one comes from the value of the roughness
exponent itself. Since, at least for a line, this value
is larger than one, this immediately suggests that
close to depinning the elastic model will run into
trouble. Indeed when u scales more than linearly
with distance, the vary basis of the elastic approx-
imation ∇u 	 1 is violated at large length scales.
The line will thus have to generate defects
(overhangs) to heal this fact. The nature of the
resulting physics when this is taken into account
is a challenging and yet open question. The second
observation concerns the steady state aspect of the
line. At large length scales, because of ﬁnite veloc-
ity, the system will average over the disorder. We
will come back in more detail to this point in the
next section, but for the moment, stick with this
simple vision. In this case, beyond the length x one
can expect the disorder to be irrelevant and thus to
recover the pure thermal roughness exponent. The
system will thus have the depinning roughness
exponent ζdep for length scales below x and the
thermal one ζth for length scales above x. This is
summarized in Fig. 12. One important question
now is what happens at a small but ﬁnite tempera-
ture. The ﬁrst effect is, of course, to smooth the
v – F characteristics. This leads to the important
question of whether one can deﬁne a scaling with
the temperature of this thermal rounding of the
depinning (see e.g., Bustingorry et al. 2008 and
references therein). Even more interesting is the
question of the roughness of the line. The analogy
with a critical phenomenon would simply suggest
that a similar divergent length scale should exist for
F < Fc, leading to the standard pattern of “critical
regime”. However, as indicated in Fig. 12, such a
divergent length scale does not exist (Kolton et al.
2006). This leads to a very puzzling behavior and
shows that although the analogy with standard
critical phenomena can be extremely fruitful, it
must be taken with a grain of salt. The depinning,
which is by essence a dynamical transition, pos-
sesses its own physics.
High Velocity Phase
Another important set of questions and physics
occurs when the interface is moving at large
velocity, i.e., for F 
 Fc. This is apparently the
Disordered Elastic Media
181

simplest regime since one could expect that at
large velocity one has a control parameter on the
theory and that an expansion in 1/v is possible.
This is indeed the case for the v – F characteristics.
A large velocity expansion of the disorder term
can be made by going into the moving frame of
the elastic media. One can indeed write u(r, t) ¼
vt þ δu(r, t), where δu(r, t) describes the displace-
ments in the moving frame. Because the system
surfs over the disorder at very large velocity one
can expect the effects of the disorder, and hence
δu(r, t), to be small. This is conﬁrmed by a well
controlled large velocity expansion (Larkin and
Ovchinnikov 1974; Schmidt and Hauger 1973).
In particular, the correction due to the disorder to
the velocity can be computed and behaves as
F  v
v
/ D
1
v

4d
2
:
ð25Þ
This shows clearly that the effects of disorder
are kept small at large velocity or large force and
become increasingly important as the force/veloc-
ity gets smaller, in agreement with Fig. 11. The
relative correction to the velocity grows in dimen-
sions smaller than d ¼ 4, conﬁrming that disorder
is relevant below this dimension. Although one
cannot extrapolate the perturbative expressions, a
crude way to estimate the critical force Fc is when
the deviations (25) become of order one. This
method gives back the estimate (23) for Fc,
obtained from totally different considerations.
The large velocity expansion also allows us to
address the physics of the moving phase, namely
the shape and properties of the elastic system in
the moving frame. A calculation of these effects
was performed (Koshelev and Vinokur 1994) by
computing the displacements δu from the large
velocity expansion. This leads to the striking
result that at large velocity the effect of disorder
Disordered Elastic Media, Fig. 12 Close to depinning
the motion proceeds by avalanches between two conﬁgu-
rations α and γ. Above Fc, there exists a divergent length
scale (Lopt on the ﬁgure) below which the line is character-
ized by the roughness exponent ζdep and above which the
line shows the thermal roughness ζth. A normal critical
phenomenon would have had a similar divergent length
scale for F < Fc. This is not the case for the depinning.
A transient divergent length scale Lrelax does exist, but does
not show up in the steady state properties of the line.
Contrary to naive expectations from a “standard” critical
phenomenon, one observes the equilibrium roughness
exponent ζeq at short distances. This shows that the anal-
ogy between depinning and “standard” critical phenom-
ena, although very fruitful, must be taken with a grain of
salt. On the right, the schematic shape of the line and
energy proﬁles are shown. (After Kolton et al. 2006)
182
Disordered Elastic Media

disappears and can be absorbed in a simple mod-
iﬁcation of the temperature of the system, leading
to an effective temperature Teff. This has important
consequences on the properties of the system in
the moving frame. For an interface, this is consis-
tent with the idea, exposed in the previous section,
that at large distance one recovers the thermal
roughening exponent. For periodic systems,
since there is the possibility of melting, this has
the more drastic consequences that driving the
system could induce a velocity controlled melting.
Indeed, for large velocities, the effective temper-
ature is small, while for smaller velocities it would
be large. The system would thus be a disordered
system while static, then close to depinning,
where the effective temperature would be large,
it would be in a melted (liquid) state, and would
then
recrystallize
when
moving
at
larger
velocities.
Although the concept of effective temperature is
extremely fruitful, in particular for this dynamic
recrystallization, the properties of the moving peri-
odic system are richer (Giamarchi and Le Doussal
1996) than those of a simple solid subjected to
temperature. Indeed, periodic systems have a
structure in the direction transverse to the direction
of motion. This structure, and the corresponding
disorder structure, cannot be averaged by the
motion, however large the velocity remains. This
leads to the fact that disorder remains even when
the system is in motion. In other words, a moving
periodic system remains a glass. The way the
motion takes place is quite peculiar. The system
ﬁnds optimal paths (Giamarchi and Le Doussal
1996) which are a compromise between the elastic
energy, disorder and the motion. These paths are
rough, similar to the way in which a static system in
a disordered environment is rough. This is shown
in Fig. 13. For periodic systems, pinning effects
still manifest themselves in the moving system.
The glassy nature and the channel motion has
been conﬁrmed both numerically (Moon et al.
1997; Kolton and Grønbech-Jensen 1999; Fangohr
et al. 2001) and experimentally (Pardo et al. 1998).
The channel motion leads to an interesting conse-
quence. Since the effects of disorder are weakening
as velocity increases, the channels undergo a tran-
sition between a regime for which the particles in
different channels are coupled or decoupled
(Balents et al. 1998; Le Doussal and Giamarchi
Disordered Elastic Media, Fig. 13 Motion of a periodic
system. The system develops rough channels which com-
promise between elastic energy and the transverse compo-
nent of the disorder that are poorly averaged by the motion.
All the particles follow on these channels like cars on
highways. Depending on the velocity, the channels are
increasingly coupled: Bottom image: close to depinning,
motion can proceed through a plastic regime where
unpinned and pinned regions (denoted by the blue circle)
coexist; Middle image: topological defects can exist
between the channels, so although the channels themselves
are well formed, the particles in them are essentially
decoupled leading to a smectic like behavior; Top image:
the channels are coupled and the system is a moving Bragg
glass with effects of both disorder and elasticity and no
topological defects. On the right, the corresponding struc-
ture factors are indicated
Disordered Elastic Media
183

1998). In the ﬁrst case, the system is essentially
moving as a “solid” (in fact a moving Bragg glass)
since the topological order is perfect even if the
system is still distorted by disorder. In the second
case, the channels are decoupled, which means that
a smectic like structure of the particles inside the
channels
is
expected.
These
transitions
as
described in Fig. 13 have also been observed both
numerically and experimentally as shown in
Fig. 14. An additional consequence of the exis-
tence of such channels is the existence of a trans-
verse pinning force (Giamarchi and Le Doussal
1996; Le Doussal and Giamarchi 1998). Indeed,
even if the particles themselves are moving along
the channels, the channels themselves are pinned if
one applies an additional force transverse to the
direction of motion. This surprising phenomenon
has been numerically conﬁrmed (Moon et al. 1997;
Kolton and Grønbech-Jensen 1999; Fangohr et al.
2001), but observing it in classical periodic systems
is still an experimental challenge. Experiments
showing the absence of Hall effect in Wigner crys-
tal systems (Perruchot et al. 2000) could constitute
an experimental proof of such a transverse critical
force, but clearly further experimental data would
be needed to unambiguously decide on that point.
Small Applied Force and Creep Motion
Finally, let us look at the response of the system
to a small external force. At zero temperature,
Disordered Elastic Media, Fig. 14 Left: numerical sim-
ulations conﬁrming the presence of channels for moving
periodic structures and the sequence of transitions depicted
in Fig. 13. The left part of the image shows the real space
trajectories, while the right part is the structure factor. The
force is increasing from the top to the bottom of the image.
[From (Kolton and Grønbech-Jensen 1999) (Copyright
1999
by
the
American
Physical
Society)].
Right:
A decoration image of moving vortices also showing the
presence of channels. The direction of the applied force is
indicated by an arrow. The left column is the raw decora-
tion image, the center one is the Fourier transform giving
the structure factor, the right column is a ﬁltered version of
the image showing the channels more clearly. [From
(Pardo et al. 1998) (Copyright 1999 by the Nature group)]
184
Disordered Elastic Media

one is below the pinning force, and thus except
for a transient motion the system remains pinned.
Motion can thus only take place due to thermal
activation over the energy barriers. The response
to a small external force is thus a method of
choice to probe for the nature of the energy
landscape of such systems. For usual systems
one expects the response to be linear. Indeed,
earlier theories of such motion have found a
linear response. The idea is to consider that a
blob of pinned material has to move in an energy
landscape with characteristic barriers  as shown
in Fig. 15. The external force F tilts the energy
landscape, thus making forward motion possible.
The barriers are overcome by thermal activation
(Anderson and Kim 1964) (hence the name:
Thermally Assisted.
Flux Flow (TAFF)) with an Arrhenius law. If
the minima are separated by a distance a the
velocity is
v / eb DFa=2
ð
Þ  eb DþFa=2
ð
Þ ’ ebDF:
ð26Þ
The response is thus linear, but exponentially
small.
However this argument is grossly inadequate
for a glassy system. The reason is easy to under-
stand if one remembers that the static system is in
a glassy state. In such a state a characteristic
barrier Δ does not exist, since barriers are
expected to diverge as one gets closer to the
ground state of the system. The TAFF formula
is thus valid in systems where the glassy aspect is
somehow eliminated and the barriers saturate.
This could be the case, for example, for a ﬁnite
size interface. When the glassy nature of the
system persists up to arbitrarily large length
scales, the theory should be accommodated to
take into account divergent barriers. This can be
done qualitatively within the framework of the
elastic
description
using
scaling
arguments
(Nattermann 1990; Ioffe and Vinokur 1987;
Nattermann 1987; Feigelman et al. 1989). The
basic idea rests on two quite strong but reason-
able assumptions: (i) the motion is so slow that
one can consider, at each stage, that the interface
is motionless and use its static description;
(ii) the scaling for barriers, which is quite difﬁ-
cult to determine, is the same as the scaling of the
minimum of energy (metastable states) that can
be extracted, again, from the static calculation. If
the displacements scale as u ~ Lζ then the energy
of the metastable states (see (2)) scales as given
by (5): E(L)  Ld2þ2ζ. Since the motion is very
slow, the effect of the external force is simply to
tilt the energy landscape
E L
ð Þ  F
ð
ddru rð Þ  Ld2þ2z  FLdþz:
ð27Þ
Thus, in order to make the motion to the next
metastable state, one needs to move a piece of the
pinned system of size
Lopt 
1
F
 	 1
2z:
ð28Þ
The size of the optimal nucleus able to move
thus grows as the force decreases. Since the
barriers to overcome grow with the size of the
object,
the
minimum
barrier
to
overcome
(assuming that the scaling of the barriers is
also given by (5))
Disordered Elastic Media, Fig. 15 In thermally assisted
ﬂux ﬂow (Anderson and Kim 1964) a region of pinned
material is considered as a particle moving in an energy
landscape characterized by characteristic barriers Δ, sche-
matized by the blue dashed periodic potential, of period a.
Applying an external force tilts the energy landscape. The
motion over barriers can always proceed by thermal acti-
vation. Due to tilt, the barrier to forward motion (in red) is
smaller than the reverse barrier (in green). This results in an
exponentially small but linear response when a small exter-
nal force is applied to the system
Disordered Elastic Media
185

Ub F
ð Þ 
1
F
 	d2þ2z
2z
ð29Þ
leading to the creep formula for the velocity
v / exp bUc Fc
F

	m


,
ð30Þ
where Fc is the depinning force and Uc a charac-
teristic energy scale and the creep exponent m is
given by,
m ¼ d  2 þ 2z
2  z
:
ð31Þ
Equations (30) and (31) are quite remarkable.
They relate a dynamical property to static expo-
nents, and show clearly the glassy nature of the
system. The corresponding motion has been
called creep since it is a sub-linear response. It is
a direct consequence of the divergent barriers in
the pinned system.
Of course the derivation above is phenomeno-
logical, so it is important to ascertain by more
microscopic methods whether the results hold.
Although in principle one simply has to solve
the equation of motion (20), in practice this is
quite complicated. A natural framework for
computing perturbation theory in off-equilibrium
systems is the MSR formalism. Using this formal-
ism and an FRG analysis, one can conﬁrm the
creep formula for velocity (Chauve et al. 2000;
Chauve et al. 1998). Numerical simulations also
show the absence of linear response and the exis-
tence of a creep response (Kolton et al. 2005a).
Creep has also been checked experimentally in
various systems. Vortices show a creep behavior
with an exponent m ¼ 1/2 compatible with the
existence of the Bragg glass (d ¼ 3, ζ ¼ 0)
(Fuchs et al. 1998). However, the range of mea-
surable velocities makes it difﬁcult to unambigu-
ously
check
for
this
law.
One
spectacular
determination of the creep law was performed in
a magnetic ﬁlm (Lemerle et al. 1998). In such a
situation the roughness exponent is known
exactly (ζ ¼ 2/3) and thus the value of the creep
exponent m ¼ 1/4 is not an adjustable parameter,
making it a much more stringent test. As shown in
Fig. 16, the velocity was measured over ten orders
of magnitude, a spectacular feat, and a remarkable
conﬁrmation of the creep law. Measurements of
the creep law have also been performed for
domain walls in ferroelectrics where a simulta-
neous measurement of the creep exponent and of
the roughness exponent was performed (Tybell
et al. 2002; Paruch et al. 2005). As shown in
Disordered Elastic Media, Fig. 16 Experimental veri-
ﬁcation of the creep law for magnetic and ferroelectric
domain walls. Left: Magnetic domain walls. The ﬁlm is
extremely thin, thus the domain is a line in a two dimen-
sional plane, leading to a creep exponent of m ¼ 1/4. The
creep law is observed on about ten orders of magnitude for
the velocity. [From Lemerle et al. 1998 (Copyright 1998 by
the American Physical Society)]. Right: Ferroelectric
ﬁlms. A creep behavior is observed over several orders of
magnitude giving a creep exponent of m ~ 0:58. This value
together with the measured roughness exponent ζ ¼ 0:26
leads to an effective dimension of d ¼ 2:5, well in agree-
ment with a two dimensional domain wall in presence of
dipolar forces. [From Paruch et al. 2005 (Copyright 2005
by the American Physical Society)]
186
Disordered Elastic Media

Fig. 16 the stretched exponential behavior for the
velocity is well veriﬁed, and the formula (31)
consistent with what is expected for a two dimen-
sional domain wall in the presence of dipolar
forces,
corresponding
to
the
experimental
situation.
The FRG derivation allows us to more deeply
probe the physical understanding of the system. In
particular
it
unravels
a
new
phenomenon.
Although the velocity itself is dominated by
events occurring at the thermal length scale (28),
interesting physics takes place beyond this length
scale. Indeed, when a portion Lopt of the line has
been able to move forward by thermal activation
over the barriers, it serves as a nucleation center to
trigger an avalanche (Chauve et al. 2000) over a
much larger length scale Lav. The behavior
between these two length scales is thus very sim-
ilar to a depinning phenomenon where tempera-
ture plays no role. Although the velocity is
dominated by the ﬁrst process, which is the slow
one, the shape of the line reﬂects this much larger
avalanche scale in a way which is compatible with
experiments (Repain et al. 2004). The creep,
being controlled by the time to overcome diver-
gent barriers in the system, has several other con-
sequences, in particular on the issue of the out-of-
equilibrium physics of such systems (Kolton et al.
2005b) and its connection to the aging of glasses
(Cugliandolo et al. 1998).
Future Directions
Both because of experimental drive (no pun
intended) but also because of theoretical advances
and the development of the proper tools, this ﬁeld
has known several breakthroughs in the last
decade or so. There is now a good understanding
of static properties for both interfaces and for
periodic systems, and most of the misconceptions
and folklore have been replaced by solid results.
Novel phases have emerged such as the Bragg
glass phase. Steady state dynamics has also
made signiﬁcant progress, with the understanding
of processes such as creep motion. From the point
of view of methods, these systems have made it
possible to perfect methods to deal with glassy
systems such as replica methods, functional
renormalization group as well as special numeri-
cal methods. These results have found and con-
tinue to ﬁnd applications in a large variety of
experimental domains. Despite these advances, it
is clear that many questions remain pending, mak-
ing it still a very challenging ﬁeld which is yet in
constant progress. Experiments regularly provide
new systems and new challenges and stimulate
theoretical analysis. Several lines of research are
actually open and should carry the bulk of the
research in that domain in the future.
From the point of view of the static, although
the situation without defects is under control, we
know next to nothing when elasticity, disorder and
defects are included. For interfaces this means
treating the overhangs and bubbles, and for peri-
odic systems all the topological defects such as the
dislocations. Although we know now that the
situation without defects is robust below a certain
threshold of disorder, it is clear that the ability to
deal with the strong disorder situation is needed
for many experimental systems. This is the case
for the high ﬁeld phase of vortices and strong
disorder in the interfaces, both of which are dom-
inated by defects.
In the dynamics, one of the very challenging
questions that one has to face is the one of the out-
of-equilibrium dynamics, when the system has
not yet reached a steady state. A simple example
of such a situation would be an interface relaxing
slowly from a ﬂat conﬁguration or quenched at
low temperatures from a high temperature conﬁg-
uration. Given that these systems are glasses, the
time evolution of such cases is highly non-trivial,
and should show a generic phenomenon of glasses
known as aging. This is directly a situation rele-
vant to many experiments. From the conceptual
point of view this is an extremely challenging
question since most of the theoretical tools that
we have fail to tackle such situations, and thus
new tools or new concepts need to be invented.
Last but not least, we have dealt mainly with
classical systems here. But disordered elastic sys-
tems can also be realized in the quantum worlds as
brieﬂy mentioned in the introduction. The ques-
tion on how to extend the concepts of glasses to
quantum
systems
remains
largely
open.
In
Disordered Elastic Media
187

particular, one can expect the dynamics to be
affected. Indeed, classical systems can pass bar-
riers only by thermal activation, while quantum
systems are good at tunneling through barriers.
The extension of the above concepts to the quan-
tum world is thus a very challenging direction.
The gold mine of disordered elastic media is
thus far from being exhausted. It seems that each
nugget we ﬁnd is only the opening of a new vein
with even richer stones. The variety of experimen-
tal realization is ever growing, as is the depth of
the questions that are now within our grasp.
Bibliography
Primary Literature
Alava M, Nukalaz PKVV, Zapperi S (2006) Adv Phys
55:349
Anderson PW, Kim YB (1964) Rev Mod Phys 36:39
Andrei EY et al (1988) Phys Rev Lett 60:2765
Avraham N et al (2001) Nature 411:451
Balents L, Marchetti C, Radzihovsky L (1998) Phys Rev
B 57:7705
Barabasi A-L, Stanley HE (1995) Fractal concepts in sur-
face growth. Cambridge University Press, Cambridge
Blatter G et al (1994) Rev Mod Phys 66:1125
For a scalar displacement or isotropic elasticity the expo-
nent is universal. When the full anistropy of the elastic
constants is taken into account in the FRG equations
[Bogner S, Emig T, Nattermann T (2001) Phys Rev
B 63 174501] the possible variation of the exponent
with the magnetic ﬁeld is still less than a percent
Bouchaud E et al (2002) J Mech Phys Solids 50:1703
Bustingorry S, Kolton AB, Giamarchi T (2008) Europhys
Lett 81:26005
Carpentier D, Le Doussal P, Giamarchi T (1996) Europhys
Lett 35:379
Chauve P, Giamarchi T, Le Doussal P (1998) Europhys
Lett 44:110
Chauve P, Giamarchi T, Le Doussal P (2000) Phys Rev
B 62:6241
Coupier G, Guthmann C, Noat Y, Saint Jean M (2005)
Phys Rev E 71:046105
Cugliandolo LF, Kurchan J, Bouchaud JP, Mezard
M (1998) In: Young AP (ed) Spin glasses and random
ﬁelds. World Scientiﬁc, Singapore
Deligiannis K et al (1997) Phys Rev Lett 79:2121
Duemmer O, Krauth W (2005) arXiv:cond-mat/0501467
Ertas D, Nelson DR (1996) Physica C 272:79
Eskildsen MR et al (2002) Phys Rev Lett 89:187003
Fangohr H, Cox SJ, de Groot PAJ (2001) Phys Rev
B 64:64505
Feigelman M, Geshkenbein VB, Larkin AI, Vinokur
V (1989) Phys Rev Lett 63:2303
Fisher DS (1985) Phys Rev B 31:1396
Fisher DS (1986) Phys Rev Lett 56:1964
Fisher DS (1997) Phys Rev Lett 78:1964
Fisher DS, Fisher MPA, Huse DA (1990) Phys Rev
B 43:130
Fuchs DT et al (1998) Phys Rev Lett 80:4971
Gao H, Rice JR (1989) J Appl Mech 56:828
Giamarchi T (2004) Quantum phenomena in mesoscopic
systems.
IOS
Press,
Bologna.
arXiv:cond-mat/
0403531
Giamarchi T, Bhattacharya S (2002) In: Berthier C et al
(eds) High magnetic ﬁelds: applications in condensed
matter physics and spectroscopy. Springer, Berlin,
p 314. arXiv:cond-mat/0111052
Giamarchi T, Le Doussal P (1994) Phys Rev Lett 72:1530
Giamarchi T, Le Doussal P (1995a) Phys Rev B 52:1242
Giamarchi T, Le Doussal P (1995b) Phys Rev Lett 75:3372
Giamarchi T, Le Doussal P (1996) Phys Rev Lett 76:3408
Giamarchi T, Le Doussal P (1997) Phys Rev B 55:6577
Giamarchi T, Kolton AB, Rosso A (2006) In: Miguel MC,
Rubi JM (eds) Jamming, Yielding and Irreversible
deformation in condensed matter. Springer, Berlin,
p 91. arXiv:cond-mat/0503437
Gingras MJP, Huse DA (1996) Phys Rev B 53:15193
Grier DG et al (1991) Phys Rev Lett 66:2270
Grüner G (1988) Rev Mod Phys 60:1129
Huse DA, Henley CL (1985) Phys Rev Lett 54:2708
Ioffe LB, Vinokur VM (1987) J Phys C 20:6149
Janssen HK (1976) Z Phys B 23:377
Joanny JF, de Gennes PG (1984) J Chem Phys 81:552
Kardar M (1985) Phys Rev Lett 55:2923
Kardar M, Parisi G, Zhang Y (1986) Phys Rev Lett 56:889
Khaykovich B et al (1996) Phys Rev Lett 76:2555
Kierfeld J, Nattermann T, Hwa T (1997) Phys Rev
B 55:626
Kim P, Yao Z, Lieber CM (1996) Phys Rev Lett 77:5118
Klein T et al (2001) Nature 413:404
Kolton AB, Grønbech-Jensen DDN (1999) Phys Rev Lett
83:3061
Kolton AB, Rosso A, Giamarchi T (2005a) Phys Rev Lett
94:047002
Kolton AB, Rosso A, Giamarchi T (2005b) Phys Rev Lett
95:180604
Kolton AB, Rosso A, Giamarchi T, Krauth W (2006) Phys
Rev Lett 97:057001
Korshunov SE (1993) Phys Rev B 48:3969
Koshelev AE, Vinokur VM (1994) Phys Rev Lett 73:3580
Krusin-Elbaum L et al (2001) Nature 410:444
Larkin AI (1970) Sov Phys JETP 31:784
Larkin AI, Ovchinnikov YN (1974) Sov Phys JETP 38:854
Larkin AI, Ovchinnikov YN (1979) J Low Temp Phys
34:409
Le Doussal P, Giamarchi T (1998) Phys Rev B 57:11356
Le Doussal P, Wiese K, Chauve P (2004) Phys Rev
E 69:026112
Lemerle S et al (1998) Phys Rev Lett 80:849
Ling XS et al (2001) Phys Rev Lett 86:712
Martin PC, Siggia ED, Rose HA (1973) Phys Rev A 8:423
Metaxas PJ et al (2007) Phys Rev Lett 99:217208
188
Disordered Elastic Media

Mézard M, Parisi G (1991) J de Phys I(4):809
Mézard M, Parisi G, Virasoro MA (1987) Spin glass theory
and beyond. World Scientiﬁc, Singapore
Moon K et al (1997) Phys Rev Lett 77:2378
Moulinet S, Guthmann C, Rolley E (2002) Eur Phys J E
8:437
Murray CA, Sprenger WO, Wenk R (1990) Phys Rev
B 42:688
Narayan O, Fisher D (1993) Phys Rev B 48:7030
Nattermann T (1983) J Phys C 16:4125
Nattermann T (1987) Europhys Lett 4:1241
Nattermann T (1990) Phys Rev Lett 64:2454
Nattermann T, Brazovskii S (2004) Adv Phys 53:177
Nattermann T, Scheidl S (2000) Adv Phys 49:607
Nattermann T, Stepanow S, Tang LH, Leschhorn H (1992)
J Phys 2:1483
Nature Group (2007) Nature material, vol. 6. Focus issue
on Multiferroics
Nelson DR (1978) Phys Rev B 18:2318
Otterlo AV, Scalettar R, Zimányi G (1998) Phys Rev Lett
81:1497
Paltiel Y, Zeldov E, Myasoedov Y, Rappaport ML
(2000) Phys Rev Lett 85:3712
Pardo F et al (1998) Nature 396:348
Paruch P, Giamarchi T, Triscone JM (2005) Phys Rev Lett
94:197601
Perruchot F et al (2000) Physica B 284:1984
Petaja V et al (2006) Phys Rev E 73:94517
Repain V et al (2004) Europhys Lett 68:460
Rosso A, Krauth W (2002a) Phys Rev B 65:12202
Rosso A, Krauth W (2002b) Phys Rev E 65:025101R
Schilling A, Fisher RA, Crabtree GW (1996) Nature
382:791
Schmidt A, Hauger W (1973) J Low Temp Phys 11:667
Seshadri R, Westervelt RM (1992) Phys Rev B 46:5150
Tybell T, Paruch P, Giamarchi T, Triscone JM (2002) Phys
Rev Lett 89:97601
Wilkinsion D, Willemsen JF (1983) J Phys A 16:3365
Yamanouchi M et al (2006) Phys Rev Lett 96:096601
Yamanouchi M et al (2007) Science 317:1726
Yaron U et al (1994) Phys Rev Lett 73:2748
Yoshino H (1998) Phys Rev Lett 81:1493
Zinn-Justin J (1989) Quantum ﬁeld theory and critical
phenomena. Clarendon Press, Oxford
Books and Reviews
Barabasi A-L, Stanley HE (1995) Fractal concepts in
surface
growth.
Cambridge
University
Press,
Cambridge
Nelson DR (2002) Defects and geometry in condensed
matter
physics.
Cambridge
University
Press,
Cambridge
Young AP (ed) (1998) Spin glasses and random ﬁelds.
World Scientiﬁc, Singapore
Disordered Elastic Media
189

Physics of Jerky Motion in
Slowly Driven Magnetic and
Earthquake Fault Systems
Karin A. Dahmen1 and Yehuda Ben-Zion2
1Department of Physics, University of Illinois at
Urbana-Champaign, Urbana, USA
2Department of Earth Sciences, University of
Southern California, Los Angeles, USA
Article Outline
Glossary
Deﬁnition of the Subject
Introduction
Models
Theoretical Results
Summary
Future Directions
Bibliography
Glossary
Critical point A (phase transition) point in the
parameter space of a physical system where the
length-scale characteristic of its structure,
called the correlation length x, becomes inﬁ-
nite and the system displays power law scaling
behavior on all available scales. The associated
critical power law exponents are universal, i.e.,
they are independent of the microscopic details
of the system.
Earthquake quantities The most common form
of earthquake data consists of seismic catalogs
that list the time, location, and size of earth-
quakes in a given space-time domain. The size
of earthquakes is usually speciﬁed by magni-
tudes associated with spectral amplitudes of
seismograms at a given frequency and site-
instrument conditions. The seismic potency
and
moment
provide
better
physical
characterizations for the overall size of earth-
quakes. Additional important quantities are the
geometry of faulting (e.g., strike slip), stress
drop at the source region, and radiated seismic
energy.
Mean ﬁeld theory A theoretical approximation
with an interaction ﬁeld that has constant
strength and inﬁnite range. In mean ﬁeld
approximation, every domain interacts equally
strongly with every other domain, regardless of
their relative distance.
Renormalization group (RG) A set of mathe-
matical tools and concepts used to describe the
change of physics with the observation scale.
Renormalization group techniques can be used
to identify critical points of a system as ﬁxed
points under a coarse graining transformation
and to calculate the associated critical power
law exponents and the relevant tuning param-
eters. They can also be used to determine what
changes to the system will leave the scaling
exponents unchanged and thus to establish the
extent of the associated universality class of the
critical point.
Seismic moment A physical measure of earth-
quakes given by the rigidity at the source
region times the seismic potency.
Seismic potency A physical measure for the size
of earthquakes given by the integral of slip
over the rupture area during a seismic event.
Strike-slip fault A style of faulting involving
pure horizontal tangential motion, predicted
for situations where the maximum and mini-
mum principal stresses are both horizontal.
Prominent examples include the San Andreas
Fault in California, the Dead Sea Transform in
the Levant, and the North Anatolian Fault in
Turkey.
Tuning parameters Parameters such as disor-
der, temperature, pressure, driving force, etc.,
that span phase diagrams. Critical values of the
tuning parameters describe critical points of
the phase diagrams.
Universality Power law scaling exponents and
scaling functions near a critical point are the
© Springer Science+Business Media, LLC, part of Springer Nature 2022
B. Chakraborty (ed.), Statistical and Nonlinear Physics,
https://doi.org/10.1007/978-1-0716-1454-9_299
Originally published in
R. A. Meyers (ed.), Encyclopedia of Complexity and Systems Science, © Springer Science+Business Media New York 2022
https://doi.org/10.1007/978-3-642-27737-5_299-4
191

same for a class of systems, referred to as
universality class, independent of the micro-
scopic details. Universal aspects typically
depend only on a few basic physical attributes,
such as symmetries, range of interactions,
dimensions, and dynamics.
Definition of the Subject
Observations indicate that earthquakes and ava-
lanches in magnetic systems (Barkhausen noise)
exhibit broad regimes of power law size distribu-
tions and related scale-invariant quantities. We
review results of simple models for earthquakes
in heterogeneous fault zones and avalanches in
magnets that belong to the same universality
class and hence have many similarities. The stud-
ies highlight the roles of tuning parameters, asso-
ciated with dynamic effects and property disorder,
and the existence of several general dynamic
regimes. The models suggest that changes in the
values of the tuning parameters can modify the
frequency size event statistics from a broad power
law regime to a distribution of small events com-
bined
with
characteristic
system-size
events
(characteristic distribution). In a certain parameter
range, the earthquake model exhibits mode
switching between both distributions. The prop-
erties of individual events undergo corresponding
changes in different dynamic regimes. Universal
scaling functions for the temporal evolution of
individual events provide similar predictions for
the earthquake and magnet systems. The theoret-
ical results are generally in good agreement with
observations. Additional developments may lead
to improved understanding of the dynamics of
earthquakes, avalanches in magnets, and the
jerky response to slow driving in other systems.
Introduction
Global Statistics and Power Law Scaling
Earthquakes occur in a broad spectrum of sizes,
ranging from unnoticeable tremors to catastrophic
events. While short-term earthquake prediction is
still beyond reach, understanding the statistics of
earthquakes might facilitate longer-term predic-
tion of large earthquakes and statistical estimates
of seismic hazard. Gutenberg and Richter (1954)
found that the frequency of observed regional and
global earthquakes versus magnitude forms a reg-
ular function over a very large range of scales (see
Fig. 1). When the measure for the earthquake size
is the seismic potency or moment (see section
“Glossary”),
the
frequency-size
statistics
of
regional and global earthquakes follow a power
law distribution. Precise deﬁnitions and details on
the seismic potency and moment are given in Aki
and Richards (2002) and Ben-Zion (2003). (In this
entry, we assume a unit nominal rigidity and will
therefore use potency and moment interchange-
ably.) Omori (1894) found that the decay rate of
aftershocks with time follows a power law distri-
bution. One would expect that there might be a
simple explanation for why earthquakes occur in a
broad range of sizes and follow regular statistical
patterns!
In the last two decades, it has become increas-
ingly evident that there are many other systems
that respond to slowly changing external condi-
tions with events on extremely large ranges of
scales (“crackling noise”). An example of partic-
ular
interest
here
involves
magnets,
which
respond to a slowly varying external ﬁeld by
changing their magnetization in a series of bursts
or “avalanches” called Barkhausen noise. Just like
Magnitude
2
0
1
Log Number of Earthquakes
2
3
4
5
3
4
5
6
7
Physics of Jerky Motion in Slowly Driven Magnetic
and Earthquake Fault Systems, Fig. 1 Histogram of
earthquakes with magnitude 2.0 or larger recorded by the
Southern California network during 1984–2002. The earth-
quake catalog is available at http://www.data.scec.org/
research/SHLK.html
192
Physics of Jerky Motion in Slowly Driven Magnetic and Earthquake Fault Systems

earthquakes, these avalanches come in many
sizes, ranging from microscopic to macroscopic,
and are distributed according to a regular function
over the entire range. The spectra of the source
time function of earthquakes is approximately ﬂat
up to a corner frequency related to the rupture
size, followed by a power law decay at higher
frequencies (Aki and Richards 2002; Ben-Zion
2003). Similarly, the spectra of the number of
spins ﬂipping per time during an avalanche in
magnets have high frequency power law decay
with a low frequency roll-off (Travesset et al.
2002). For certain values of tuning parameters,
earthquake and magnet quantities are associated
with scale-invariant functions (power laws). In
such cases, each individual magnetic avalanche
or earthquake slip has a fractal spatial structure
(see Fig. 2 for magnets and Fig. 5a for earth-
quakes). Other systems with similar “collective
events” of all available sizes include, among
others, superconductors, charge density waves,
and group decision making (Sethna et al. 2001).
While there are several interesting recent
reviews, pointing out the similarities between sys-
tems with power law event size distributions, the
goal of this paper is to develop in detail some of
the connections and analysis methods in earth-
quake and magnetic systems. Expanding on
some of our earlier results, we focus especially
on the role of disorder and dynamic changes in the
strength threshold as potential tuning parameters
to drive the system toward power law scaling
behavior or away from it. Table 1 summarizes
some of the similarities between magnets and
earthquakes that are discussed in this review.
In “Models,” we describe several magnet and
earthquake models that are simple enough to
make the connections transparent and easy to
recognize. In “Theoretical Results,” we review
theoretical results obtained from these models
and their comparison to experimental or observa-
tional data. Finally in “Summary,” we summarize
the results and discuss future work, both observa-
tionally and theoretically, that can help to improve
our understanding of the dynamics of earthquakes
and magnets.
Models
Models for Barkhausen Noise in Magnets
Hysteresis and avalanches in disordered magnetic
materials have been modeled using several vari-
ants of the nonequilibrium, zero-temperature
random-ﬁeld Ising model (RFIM), which is one
of the simplest models of magnetism, with appli-
cations far beyond magnetic systems (for a
review, see Sethna et al. (2001) and also Dahmen
(1995), Nattermann (1997), and Perković et al.
(1995)). In contrast to some other hysteresis
models, like the Preisach model (Mayergoyz
1991) and the Stoner-Wohlfarth model (Jiles
1991), where interactions between the individual
hysteretic units (grains) are not included and col-
lective behavior in the form of avalanches is not
addressed, in the RFIM the inter-grain coupling is
an essential feature and cause for hysteresis and
avalanche effects.
Physics of Jerky Motion in Slowly Driven Magnetic
and Earthquake Fault Systems, Fig. 2 Fractal spatial
structure of a medium-sized avalanche of 282,785 domain
ﬂips in the three-dimensional random ﬁeld Ising model
(Sethna et al. 2001). Fractal structures and power laws are
characteristic of systems at their critical point. The shading
represents time of the domain ﬂips: the ﬁrst domains to ﬂip
are at the right end of the avalanche, the last toward the left.
The short range of the ferromagnetic interactions causes
the avalanche to be spatially connected (see Sethna et al.
(2001))
Physics of Jerky Motion in Slowly Driven Magnetic and Earthquake Fault Systems
193

The Random Field Ising Model (RFIM)
The equilibrium RFIM was originally introduced
to study disordered magnetic materials in thermal
equilibrium. We study the nonequilibrium ver-
sion, to model hysteresis and avalanches observed
far from thermal equilibrium. Even though the
model is a toy version of the microscopic details
in a magnet, near the critical point, it correctly
describes the large-scale behavior of systems with
the same general properties such as symmetries,
dimensions, interaction ranges, and dynamics
(Dahmen 1995), as follows from renormalization
group arguments.
In the RFIM, to each site i in a simple cubic
lattice is assigned a variable si, a so-called spin,
which can take two different values, si ¼ +1
(“up”) or si ¼ 1 (“down”). (This corresponds
to a real magnet where a crystal anisotropy prefers
the magnetic moments or elementary domains,
represented by the spins, to point along a certain
easy axis.) Each spin interacts with its nearest
neighbors on the lattice through a positive
exchange interaction, Jnn, which favors parallel
alignment. (For the behavior on large scales, the
exact range of the microscopic interaction is irrel-
evant, so long as it is ﬁnite.) Some variations of
the RFIM also include long-range interactions
due to the demagnetizing ﬁeld and the dipole-
dipole interactions. A general form of the Hamil-
tonian can be written as (Kuntz and Sethna 2000)
ℋ¼ 
X
nn
Jnnsisj 
X
i
Hsi 
X
i
hisi
þ
X
i
Jinf
N si 
X
i, j
f
g
Jdipole
3 cos yij


 1
r3
ij
sisj,
ð1Þ
where H is the homogeneous external magnetic
driving ﬁeld; hi is a local, uncorrelated random
ﬁeld, that models the disorder in the system; Jinf is
the strength of an inﬁnite range demagnetizing
ﬁeld; N is the total number of spins in the system;
and Jdipole is the strength of the dipole-dipole
interactions. The power laws of generated events
are independent of the particular choice for the
distribution r(hi) of random ﬁelds, for a large
variety of distributions. Usually, a Gaussian dis-
tribution of random ﬁelds is used, with a standard
deviation (“disorder”) R. As a simple approxima-
tion, the model is studied at zero temperature, far
from equilibrium, to describe materials with suf-
ﬁciently high barriers to equilibration, so that
temperature ﬂuctuations are negligible on experi-
mental time scales. As the magnetic ﬁeld is adia-
batically slowly changed between H ¼ 1 and
H ¼ +1, two different local dynamics have been
considered:
1. In the ﬁrst (“bulk”) dynamics, each spin si ﬂips
while decreasing its own energy. We have stud-
ied this dynamics for the original RFIM
Physics of Jerky Motion in Slowly Driven Magnetic
and Earthquake Fault Systems, Table 1 Some scaling
features that are similar for magnets and earthquakes. More
details on the various properties are given in the indicated
sections
Earthquake system
Magnetic system
Frequency-size
statistics
Power law near criticality, characteristic distribution
away from criticality (“Results on the Monotonic
Version of the Model”)
Same as earthquakes (“Results on
the Monotonic Version of the
Model”)
Scaling of source shape
functions
Parabola for moment rate shape of events with ﬁxed
duration T in simulations, scaling function skewed
to the left for observational data (“Moment Rate
Shapes for Monotonic Models”)
Same as earthquakes (“Moment
Rate Shapes for Monotonic
Models”)
Spatial properties of
individual events
Fractal near criticality, compact away from
criticality (“Non-monotonic Models” and Fig. 5)
Same as earthquakes (“Non-
monotonic Models” and “Phase
Diagram” and Fig. 2)
Spectral decay of
source function of
individual events
Flat up to a corner frequency followed by power law
decay (“Introduction”)
Same as earthquakes
(“Introduction”)
194
Physics of Jerky Motion in Slowly Driven Magnetic and Earthquake Fault Systems

without long-range interactions, i.e., for Jinf ¼
Jdipole ¼ 0 (Dahmen 1995; Perković et al.
1995). This dynamics allows for both domain
nucleation (when a spin si surrounded by equal
valued spins ﬂips in the opposite direction) and
for domain wall motion (when a spin ﬂips on
the surface of a preexisting cluster of uniform
spins in a background of opposite valued
spins). A spin ﬂip can trigger neighboring
(or more generally, coupled) spins to ﬂip as
well, leading to an avalanche of spin ﬂips,
analogous to a real Barkhausen pulse. During
an avalanche, the external ﬁeld is kept constant
until the avalanche is ﬁnished, in accordance
with the assumed adiabatic limit. The model is
completely deterministic – two successive
sweeps through the hysteresis loop produce
the exact same sequence of avalanches (since
the temperature is set to zero). This dynamics
may be appropriate to describe, for example,
hard magnetic materials with strong anisot-
ropies. The analog earthquake system may be
associated with fault regions or fault networks
that have strong geometrical and material
heterogeneities.
2. The second dynamics is a “front propagation
dynamics” in which only the spins on the edge
of an existing front (interface between up and
down spins) ﬂip if that decreases their energy.
This dynamics can be used to model soft mag-
netic materials with a single or several non-
interacting
advancing
domain
walls
and
negligible new domain nucleation, due to anti-
ferromagnetic demagnetizing ﬁelds. The front
propagation model without long-range interac-
tions (Jinf ¼ Jdipole ¼ 0) was originally intro-
duced by Robbins et al. to model ﬂuids
invading porous media (Martys et al. 1991).
The analog earthquake system for this case
may be associated with a single fault zone.
Simple Models for Inhomogeneous
Earthquake Faults
Much of the previous work on simple earthquake
models has involved variants of the Burridge-
Knopoff (or “slider-block”) model, in which com-
plex behavior is generated in a system with many
degrees of freedom and where inertia, friction laws,
and inherent discreteness play important roles
(Carlson et al. 1994; Langer et al. 1996; Rice and
Ben-Zion 1996). These systems appear to exhibit
power law statistics over some range with a cutoff
beyond some magnitude and with most of the slip
occurring in larger system-size events. However,
the understanding of the origin of the power law
behavior is limited. Our approach here is to obtain
an analytic understanding of a class of models and
then to add in various additional features by ana-
lytic scaling arguments using tools from the theory
of phase transition and the renormalization group,
aided by numerical studies. There are interesting
related studies using tools from statistical physics
(Chen et al. 1991; Schwarz and Fisher 2001). Some
studies suggest that the power law scaling is
connected to a spinodal (Klein et al. 1997). Various
cellular automata models have also been used for
modeling
earthquakes
(Lomnitz-Adler
1993).
Rather than reviewing a large number of models,
we will focus on a subgroup of models that we
found particularly well suited to clarify the connec-
tion between earthquake and magnetic systems
with a jerky response to slowly changing external
conditions.
The Ben-Zion and Rice Model
A representative of the class of models that we
consider is a model developed originally by Ben-
Zion and Rice (Ben-Zion 1996; Ben-Zion and Rice
1993, 1995), referred to below as the BZR model.
The model assumes that a narrow irregular strike-
slip fault zone of horizontal length L and vertical
depth W may be represented by an array of N 
LW cells in a two-dimensional planar region of
length L and width W, with long-range interaction,
abrupt transitions in the threshold dynamics during
failure, and constitutive parameters that vary from
cell to cell to model the disorder (offsets, etc.) of the
fault zone structure (Fig. 3).
The cells represent brittle patches on the inter-
face between two tectonic blocks that move with
slow transverse velocity v in the x direction at a
great distance from the fault. The interaction
between cells during slip events is governed by
3D elasticity and falls off with a distance r from
the failure zone as 1/r3. The cells remain stuck
while the stress ti on each cell is increased
Physics of Jerky Motion in Slowly Driven Magnetic and Earthquake Fault Systems
195

gradually as a result of the external loading which
grows adiabatically (i.e., we take the limit v ! 0).
When the stress on a cell i reaches its local failure
threshold ts,i, the cell slips until the stress is
reduced to its local arrest stress ta,i. Both failure
stress and arrest stress are distributed according to
some bounded probability distribution. The stress
drop resulting from a cell failure is redistributed to
the other cells according to the long-range elastic
stress transfer function. The resulting stress
increase on the other cells can cause some of
them to slip as well, leading to an avalanche of
cell slips, or a model earthquake. A review of
extensive numerical simulations with various ver-
sions of the BZR model, in relation to observed
features
of
seismicity,
criticality,
and
other
dynamic regimes, is given in Zöller et al. (2009).
Dynamic
Weakening The
model
includes
dynamic weakening effects during the failure
process (Ben-Zion 1996; Ben-Zion and Rice
1993, 1995): after an initial slip in an earthquake,
the strength of a failed cell is reduced to a dynamic
value:
td,i  ts,i  ϵ ts,i  ta,i
ð
Þ,
ð2Þ
with 0  ϵ  1 parametrizing the relative impor-
tance of the dynamic weakening in the system.
This weakening represents the transition from
static friction to dynamic friction during the rup-
ture. The strength of a failed cell remains at its
dynamic value throughout the remainder of the
earthquake. In the time intervals between earth-
quakes, all failure thresholds heal back to their
static value ts,i.
Dynamic Strengthening The model can be
expanded further to include dynamic strengthen-
ing
represented
by
ϵ < 0.
Multidisciplinary
observations indicate (Ben-Zion and Sammis
2003) that brittle failure of rock has an initial
transient phase associated with strengthening, dis-
tributed deformation, and creation of new struc-
tures. Detailed frictional studies also show an
initial strengthening phase associated with the
creation of a new population of asperity contacts
(Ben-Zion 2003; Dieterich 1979). In mean ﬁeld
studies of our model (Fig. 3) discussed in “Results
on Aftershocks,” we associate ϵ < 0 with regions
off the main fault segments that are in an early
deformation stage. The events that are triggered as
the failure stresses are lowered back in the follow-
ing weakening period are referred to as after-
shocks. The Omori law (Ben-Zion 2003; Utsu
2002; Utsu et al. 1995) is obtained if we assume
that the increased failure stress thresholds tf,i are
slowly lowered with time as log(t) toward their
earlier static values ts,i and that the stresses are
distributed over a wide range of values (Mehta
et al. 2006).
Related General Continuum Equations of Motion
The above model is a special case of a more
general class of models for inﬁnite systems
driven by a constant drive force F (Fisher et al.
1997). We consider general equations of motion
of the form
creep
z
z
y
y
x
x
Physics of Jerky Motion in Slowly Driven Magnetic
and Earthquake Fault Systems, Fig. 3 Illustration of
the Ben-Zion and Rice (BZR) model: projection of a 3D
fault zone (top) onto a 2D interface embedded in a 3D
elastic half space (bottom). The geometrical inhomogene-
ities of the physical fault zone are modeled by spatially
varying constitutive parameters of the brittle patches (see
Mehta et al. (2006))
196
Physics of Jerky Motion in Slowly Driven Magnetic and Earthquake Fault Systems

@u r, t
ð
Þ=@t ¼ F þ s r, t
ð
Þ  fR u r, t
ð
Þ, r, u r, t0 < 1
ð
Þ
f
g
½

ð3Þ
where
s r, t
ð
Þ ¼
ðt
1
dt0
ð
ddr0J r  r0, t  t0
ð
Þ u r0, t0
ð
Þ  u r, t
ð
Þ
½

ð4Þ
is the stress and fR is a quenched random “pin-
ning” force crudely representing inhomogeneities
in the friction, asperities, stepovers, etc., which in
general can depend on the local past history (e.g.,
as in velocity-dependent friction). The dynamic
variables u(r, t) are assumed to represent the dis-
continuity across the fault plane in the component
of the displacement in the direction of slip. The
dynamics depend on the local history dependence
of the pinning force, the stress transfer function
J(r, t), and the coefﬁcient Z that represents the
fault impedance. (In an elastic medium, the
impedance depends on mass density, the elastic
parameters, and directional parameters (Aki and
Richards 2002).) Equation 3 can be considered a
continuum description of the rules of the BZR
model. Integrating out the degrees of freedom
due to the bulk material on either side of the
d ¼ 2-dimensional fault plane leaves us with
effective long-range static stress transfer: Js(r)

Ð
dtJ(r,t)  1 / rd+Γ  1/r3. For a planar fault
in an elastic half space, d ¼ 2 and Γ ¼ 1
(Ben-Zion 1996; Ben-Zion and Rice 1995). The
correlations in fR are generally assumed to be short
range in u and r. (For results on the BZR model
with long-range correlations in the disorder, see
Ben-Zion (1996), Fisher et al. (1997), Zöller et al.
(2005), and section “Theoretical Results.”) In a
version of the BZR earthquake model with a con-
stant driving force F, the loading may be replaced
by driving through a weak spring with spring
constant K  1/L coupled to the slowly moving
continents far away (i.e., replacing F in Eq. 3 by
F(r, t) ¼ K[vt  u(r, t)], with v ! 0).
Monotonic Models Substantial simpliﬁcations
occur
if
fR
is
history
independent
and
J(r, t)  0 for all (r, t), leading to monotonic
models (Fisher et al. 1997). Related monotonic
models have been studied extensively in vari-
ous other contexts (Ertaş and Kardar 1994b;
Narayan and Fisher 1992b). Examples include
elastic depinning models for contact lines, vor-
tex lines, liquids invading porous materials, and
elastic charge density waves. Their crucial sim-
plifying feature is that the steady-state velocity
v  @u=@t
h
i is a history-independent function
of F (Middleton 1992). In the context of the
BZR model, this corresponds to the case with
zero weakening (ϵ ¼ 0) and nonnegative J.
A crucial feature of monotonic models is that
the slip proﬁle Δu(r) of a quake is independent
of the dynamics (Middleton 1992). However,
several interesting dynamic issues discussed
below are associated with the effects left out
of the monotonic models that can make this
feature break down.
Non-monotonic Models
(a) Weakening: We ﬁrst consider including some
weakening effects of sections which have
already slipped in a given quake. This is best
studied in the discrete model. In analogy to the
dynamic weakening in the BZR model
discussed above, we choose (Fisher et al.
1997)
fR ¼ ~fR u r
ð Þ, r
½
 1  ϵY u r, t
ð
Þ  u r, t  T
ð
Þ
½

f
g
ð5Þ
with T a cutoff time much longer than the
duration of the largest quakes but much
smaller than the interval between the quakes.
Here Θ(x) is the Heaviside step function. As
mentioned, the case ϵ > 0 represents the dif-
ference between static and dynamic friction.
The effects of small weakening (ϵ > 0) can be
analyzed perturbatively (see section “Theoret-
ical Results”).
(b) Stress Pulses: A similar but more subtle effect
can be caused by stress pulses that result from
nonpositive J(r, t); these arise naturally when
one
includes
elastodynamic
effects.
We
consider
Physics of Jerky Motion in Slowly Driven Magnetic and Earthquake Fault Systems
197

J r, t
ð
Þ  d t  r
c


rd þ G þ ad0 t  r
c


crdþg
ð6Þ
with c the sound speed, δ(t) the Dirac delta
distribution, and δ0(t) ¼ dδ(t)/dt. The scalar
approximation to elasticity in a half space
corresponds to d ¼ 2, Γ ¼ 1, γ ¼ 0, and
α ¼ 1 (Fisher et al. 1997). If a region slips
forward, the stress at another point ﬁrst has a
short pulse at the sound arrival time from the
second term in Eq. 6 and then settles down to
its smaller static value, i.e., it is non-
monotonic. The magnitude of these stress
pulses and their duration are set by various
aspects of the models; for example, larger Z in
Eq. 3 implies weaker stress pulses as the local
motion will be slower.
Theoretical Results
Both the magnet and earthquake models of the
previous section are capable of producing a large
range of power law scaling of event sizes and
related scale-invariant quantities in response to a
slowly varying driving force or ﬁeld. This section
highlights similarities between these different
physical systems and attempts to explain them.
The Universality Class of the BZR Model
We ﬁrst review results for the simpliﬁed mono-
tonic case, starting with scaling relations for driv-
ing with ﬁxed force and far ﬁeld plate motion and
continuing with moment rate shapes. We then
discuss additional results associated with non-
monotonic versions of the model, including
mode switching and aftershocks.
Results on the Monotonic Version of the Model
General Results: Depinning Transition As
mentioned
above,
substantial
simpliﬁcations
occur for the monotonic version of the model,
i.e., if fR is history-independent and J(r, t)  0
for all (r, t). In Ertaş and Kardar (1994b), Fisher
et al. (1997), and Narayan and Fisher (1992b), it is
shown that for F greater than a critical force Fc,
the displacement grows continuously in a “sliding
state”
for
which
the
mean
velocity
v  @u=@t
h
i  F  Fc
ð
Þb. Here, β is a universal
exponent that is independent of the microscopic
details of the system. It only depends on a few
fundamental properties, such as symmetries, spa-
tial
dimensions
d,
range
of
interactions,
etc. (Narayan and Fisher 1992b). Longtime
dynamic properties such as β depend in addition
on the small o dependence of J(q, o) (Narayan
and Fisher 1993).
For F less than the critical force Fc, the mean
velocity is v  0 . If F is adiabatically slowly
increased toward Fc, the system moves from one
metastable conﬁguration to another by a sequence
of “quakes” of various sizes. The “quakes” can be
characterized by their radius R, the d-dimensional
area A which slips (by more than some small cut-
off), their potency or moment M 
Ð
AddrΔu(r), a
typical displacement Δu  M/A, and a duration t.
The critical force Fc marks a second-order phase
transition point. Such phase transitions are typi-
cally associated with power law scaling behavior.
In the class of earthquake models with long-
range interactions along the fault involving the
static stress transfer Js(r) 
Ð
dtJ(r, t)  1/r3, the
equations are very similar to those of a model for
contact line depinning studied in Ertaş and
Kardar (1994b). Using renormalization group
methods, it was shown in Ertaş and Kardar
(1994b) that for a physical two-dimensional
interface (or “fault”) in a three-dimensional elas-
tic half space, these long-range interactions are
so long that the scaling behavior near Fc is cor-
rectly described by mean ﬁeld theory (up to log-
arithmic corrections, since d ¼ 2 is the “upper
critical dimension”). The main assumption in
mean ﬁeld theory is that the spatial and temporal
ﬂuctuations in the displacement ﬁeld u(r, t) are
so small that the local displacement u(r, t) can be
replaced by a time-dependent spatial average
u(t), which then needs to be determined self-
consistently from the behavior of the neighbor-
ing regions that contribute to the stress at a cho-
sen point r (Fisher 1998). The same mean ﬁeld
equations are obtained when the long-range
interaction is approximated to be constant in
space J(r, t) ¼ Jmft(t)/(LW). With this approxi-
mation, Eqs. 3 and 4 become
198
Physics of Jerky Motion in Slowly Driven Magnetic and Earthquake Fault Systems

@u r, t
ð
Þ=@t
¼ F þ smft r, t
ð
Þ  fR u r, t
ð
Þ, r, u r, t0 < t
ð
Þ
f
g
½

ð7Þ
where
smft r, t
ð
Þ ¼
ðt
1
dt0Jmft t  t0
ð
Þ u t0
ð Þ  u r, t
ð
Þ
½

ð8Þ
and the self-consistency requirement is
ð
u r, t
ð
Þd2r= LW
ð
Þ ¼ u tð Þ
ð9Þ
Many scaling exponents and scaling functions
can be calculated exactly in mean ﬁeld theory by
solving these simpliﬁed equations of the model.
In Dahmen (1995), Fisher (1998), and Marchetti
et al. (2000), several illustrative examples are
given for solving similar self-consistent mean
ﬁeld theories. There are various approaches that
one may use, ranging from numerical simula-
tions to analytic expansion and scaling analysis
near a phase transition point where universal
power law scaling occurs. The approach of
choice to solve the mean ﬁeld equations depends
on the quantity under consideration. To obtain
the exact results for the scaling behavior of the
frequency-size statistics of earthquake or ava-
lanche events, a fairly simple approach is to use
a discrete version of the model in which we treat
the fault as a discrete set of dislocation patches,
coupled to a mean displacement and an external
driving force that slowly increases with time.
(The stress ti at each patch is given by Eq. 16
of “Mode Switching” below.) As shown in
Dahmen
et
al.
(1998),
the
sequence
that
describes the distance from failure of the rescaled
stress variables resembles a biased random walk.
The scaling behavior of the resulting random
walk is known exactly from the literature.
Using this mapping, it then becomes straightfor-
ward to derive universal scaling predictions for
the mean ﬁeld earthquake frequency-size distri-
bution (Dahmen et al. 1998).
Furthermore, as shown in Cizeau et al. (1997)
and Ertaş and Kardar (1994b), their (and thus also
our) model have the same scaling behavior as a
front propagation model for a two-dimensional
domain wall in a soft magnet with long-range
dipolar magnetic interactions, driven by a slowly
changing external ﬁeld (see section “Models”).
A ﬂipping spin in the magnet model corresponds
to a slipping dislocation patch in the earthquake
model. The long-range elastic interactions in the
earthquake model are similar to the long-range
dipolar magnetic interactions in the magnet
model. The driven two-dimensional magnetic
domain wall in the (three-dimensional) magnet
model corresponds to the driven two-dimensional
earthquake fault in a three-dimensional elastic
half space. Since the scaling behavior of the earth-
quake model and that of Ertaş and Kardar (1994b)
and Zapperi et al. (1998) are identical, we may
simply copy their results and translate them into
quantities that can be extracted from seismic data.
Using tools from phase transitions, such as the
renormalization group (RG), near the critical
force, the following scaling results were derived
by Cizeau et al. (1997), Ertaş and Kardar (1994b),
Narayan and Fisher (1992b, 1993, Zapperi et al.
(1998) and others:
Du  Rz,
A  Rdf with df  2 a fractal dimention,
M  Rdf þz,
and t  Rz:
The differential distribution P(M) of moments
M is shown in Ertaş and Kardar (1994b), Narayan
and Fisher (1993), Fisher (1998), Fisher et al.
(1997) to scale as
P M
ð
ÞdM  dM=M 1þBr1 M= bM


ð10Þ
with r1 as a universal scaling function which
decays exponentially for large argument. The cut-
off bM
for large moments is characterized by
a correlation length – the largest likely radius
– x  1/(Fc  F)n with bM  xdf þB.
In the same references, it is shown that in mean
ﬁeld theory, B ¼ 1/2, 1/n ¼ 1, z ¼ 1, and the
Physics of Jerky Motion in Slowly Driven Magnetic and Earthquake Fault Systems
199

quakes are fractal with displacements of order the
range of correlations in fR (u), i. e. ζ ¼ 0.
These mean ﬁeld exponents are valid for a
d ¼ 2-dimensional
planar
fault
in
a
three-
dimensional elastic half space (Ben-Zion and
Sammis 2003), since the physical fault operates
at the upper critical dimension. As usual, at the
upper critical dimension, there are logarithmic
corrections
to
mean
ﬁeld
results.
Using
renormalization group methods, one can calculate
these corrections (Fisher et al. 1997) and ﬁnds
barely fractal quakes with A  R2/ln R so that
the fraction of the area slipped decreases only as
1/ln r away from the “hypocenter.” The typical
slip is Δu  (ln R)1/3 so that M  R2 / (ln R)2/3.
The scaling form of P(M) is the same as Eq. 10
with the mean ﬁeld r1, although for M  bM ,
P (M)  (ln M)1/3 / M3/2 so that B will be virtually
indistinguishable from 1/2 (Fisher et al. 1997).
A similar form of moment distribution and expo-
nent value B ¼ 1/2 were obtained also for a crit-
ical stochastic branching model
(Vere-Jones
1976).
More Realistic Driving of a Fault We now con-
sider more realistic drive and ﬁnite-fault-size
effects. As mentioned, driving the fault by very
slow motion far away from the fault is roughly
equivalent to driving it with a weak spring, i.e.,
replacing F in Eq. 3 by F(r, t) ¼ K[vt  u(r, t)].
With v ! 0, the system must then operate with
the spring stretched to make F r, t
ð
Þ<
~ Fc at least
on average, to ensure v ¼ 0; depending on the
stiffness of the spring, it will actually operate just
below Fc, as shown below. If in constant force
drive the force is increased by a small amount
ΔF,
the
average
resulting
slip
per
area,
Du
h
i 
X
i
Dui= LW
ð
Þ
is given by the total
potency/moment per total area M 
Ð
ddrΔu (r)/
(LW). The total moment per area observed in
response to a small force increase equals the
number nΔF of earthquakes per area that are
triggered by the increased ΔF, multiplied with
the average observed moment of a single earth-
quake ⟨M⟩¼
Ð
MP(M)dM. The result is
Du
h
i ¼ nDF
ð
MP M
ð
ÞdM
ð11Þ
where n is the number of quakes per unit area per
force increase ΔF. It has been shown that n(F) is
non-singular at Fc (Narayan and Fisher 1992b), so
it can be treated like a constant near Fc. Plugging
in Eq. 10 and the scaling laws written above and
below that equation, we obtain
Du
h
i  DFx 2eGþz


1B
ð
Þ  DFx
ð12Þ
for our case where mean ﬁeld results can be used
for the critical exponents. For consistency, we
must have in steady state with the spring drive
KvΔt ¼ ΔF ¼ KΔu so that the system will oper-
ate with a correlation length x  1=K1=eG, i.e., 1/K
for our case. For a fault section with linear dimen-
sions of order L, the drive either from uniformly
moving fault boundaries or from a distance  L
perpendicularly away from the fault plane will be
like K  1/L, so the power law quake distribution
will extend out to roughly the system size x  L.
For smaller quakes, i.e., R  L, the behavior will
be the same as in the inﬁnite system with constant
F drive, but the cutoff of the distribution of
moments will be like Eq. 10 with a different cutoff
function r that depends on the shape of the fault,
how it is driven, and the boundary conditions.
We have tested these conclusions numerically
by simulating the BZR model, which is a discrete
space, time, and displacement version of a mono-
tonic Eq. 3, with quasistatic stress transfer appro-
priate for an elastic half space (Ben-Zion 1996;
Ben-Zion and Rice 1993). The slip, u, is purely in
the horizontal direction along the fault, and
fR[u(r)] is a series of equal-height spikes with
spacings which are a random function of r.
When s(r, t) > fR[u(r, t], u(r) jumps to the next
spike. This provides a way of implementing the
random stress drops of the BZR model. The
boundary conditions on the bottom and sides are
uniform creep or slip – (u ¼ vt) with inﬁnitesimal
v – and stress-free on the top (Fig. 3). The statistics
of the moments of the quakes are shown by the
triangles in Fig. 4. Although the uncertainties are
200
Physics of Jerky Motion in Slowly Driven Magnetic and Earthquake Fault Systems

appreciable, relatively good agreement is found
with the prediction B ¼ 1/2. One typical large
quake is illustrated in Fig. 5 (top); it appears
almost fractal as predicted and tends to stay
away from the bottom and sides due to the speciﬁc
loading that we chose. The ratios of the moments
of quakes to their areas have been studied and
found to grow only very slowly with the area, as
predicted from the logarithmic corrections listed
below Eq. 3. This is in striking contrast to earth-
quakes in conventional crack models which are
compact (Fig. 5 (bottom)) and have Δu  R
(i.e., ζ ¼ 1), so that M=A 
ﬃﬃﬃ
A
p
. As discussed
by Ben-Zion and Zhu (2002), however, the scal-
ing M  A appears to be consistent with observa-
tional
results
for
small
earthquakes
which
presumably propagate and are arrested in rough
stress ﬁelds. More observational data on the scal-
ing of the moment M with the slipping area A for
smaller earthquakes would be highly desirable to
test this prediction more precisely.
Because the system is at its critical dimension,
the cutoff function r of the moment distribution
appropriate to the boundary conditions, as well as
various aspects of the shapes and dynamics of
quakes, can be computed using tools from the
theory of phase transitions (Fisher 1998; Fisher
et al. 1997). For quasistatic stress transfer,
J (r, t)  δ(t)/r3, in the inﬁnite system, the
quake durations are found to scale as t  Rz
with z ¼ 1 for a d ¼ 2-dimensional fault, with
logarithmic
corrections
(Ertaş
and
Kardar
Physics of Jerky Motion in Slowly Driven Magnetic
and Earthquake Fault Systems, Fig. 5 Distribution of
horizontal slip, u, along a fault with 32 	 128 cells for a
single large quake event. Lighter shading represents larger
slip during the quake. Top: almost fractal quake with a total
moment of 1,750 (and 1,691 cells failing) for the monotonic
model without any dynamic effects (ϵ ¼ 0). Bottom:
“crack-like” quake with a total moment of 16,922 (and
2,095 cells failing) for the model with dynamic weakening
(ϵ ¼ 0.95). In both cases, the system is driven by horizon-
tally creeping fault boundaries (sides and bottom) while the
top boundary is free (From Fisher et al. (1997))
moment (a.u.)
100
10–3
10–2
frequency (a.u.)
10–1
100
101
102
103
104
105
Physics of Jerky Motion in Slowly Driven Magnetic
and Earthquake Fault Systems, Fig. 4 Histograms of
moments for a simulation of a rectangular fault with
32 	 128 cells for the discrete monotonic quasistatic
model (with arbitrary units (a.u.)). Triangles: without
dynamic weakening (ϵ ¼ 0). Diamonds: with dynamic
weakening of ϵ ¼ 0.95. (ϵ is deﬁned in Eq. 5.) The straight
line indicates the predicted slope B ¼ 1/2 (From Fisher
et al. (1997))
Physics of Jerky Motion in Slowly Driven Magnetic and Earthquake Fault Systems
201

1994b). (A more physical dynamics with sound-
travel-time delay has slower growth of the quakes
with z ¼ 1 in all dimensions.) Due to the geomet-
rical disorder included in the model, in either case,
the growth will be very irregular – including
regions starting and stopping – in contrast to
crack models and what is often assumed in seis-
mological analysis of earthquakes on more regu-
lar
faults.
Similar
fractal-like
quakes
were
simulated by Zöller et al. (Zöller et al. 2009;
Zöller et al. 2004), for a quasi-dynamic version
of the BZR model that includes stress redistribu-
tion with a ﬁnite communication speed.
Moment Rate Shapes for Monotonic Models
In both magnet and earthquake models, it has been
shown that there are not just universal scaling
exponents but also some experimentally accessi-
ble universal scaling functions (Sethna et al.
2001). By comparing theoretical predictions for
these functions to experiments or observations,
one can often test models much more accurately
than by merely comparing a ﬁnite set of discrete
exponents. Two such functions were ﬁrst discov-
ered for Barkhausen noise in magnets (Mehta
et al. 2002; Sethna et al. 2001). The analogy
between magnets and earthquakes then leads to
the development of the corresponding functions
for earthquakes. For slowly driven magnets, con-
sider the time history V(t) of the number of
domains ﬂipping per unit time (Barkhausen
train). It is called V because it is usually measured
as a voltage in a pickup coil. An example of a
Barkhausen train for a single avalanche is shown
in Fig. 6.
The voltage function V(t) in magnets is the
analog of the moment rate dm/dt(t), or the slip
per unit time for earthquakes. Recent analysis
allowed researchers to obtain the moment rate
dm0(t)/dt, during the propagation of earthquake
rupture for hundreds of large seismic events
recorded
on
global
networks
(Bilek
2001;
Houston 2001). The moment rates shown below
are derived from inversions of teleseismically
recorded seismogram on a global seismic network
(Ruff and Miller 1994). (The frequency-moment
distribution D(M0)  M0
1β of the observed
data (Bilek 2001) has three decades of scaling
and an exponent of β ¼ 1/2 
 0.05, in close
agreement with the BZR model near ϵ ¼ 0 (Mehta
et al. 2006).)
For both magnets and earthquakes, there are
large ﬂuctuations in V(t) and dm/dt(t), respectively
(Fig. 6). However, averaging the signal over many
avalanches leads to typical shapes. Figure 7 shows
the average over all avalanches of ﬁxed duration
T, ⟨V⟩(T, t) obtained from simulations of two var-
iants of the RFIM (a) and from three different
Barkhausen noise experiments (b). Figure 8
shows ⟨dm/dt⟩(T,t) obtained for the BZR earth-
quake model and derived from earthquake obser-
vations, respectively. The renormalization group
and scaling theory (Sethna et al. 2001) predict that
for a self-similar system at a critical point with
power law size and duration distributions for ava-
lanches, there are self-similar average avalanche
proﬁles. As shown in Mehta et al. (2006) and
Sethna et al. (2001), one ﬁnds
dm=dt
h
i T, t
ð
Þ  Tb0g t=T
ð
Þ
ð13Þ
where the function g(x) is a universal scaling
prediction and b0  1/(snz)  1 ¼ 1 for the
BZR earthquake model (as obtained from mean
t
V(t)
Physics of Jerky Motion in Slowly Driven Magnetic
and Earthquake Fault Systems, Fig. 6 Voltage train of
a typical large avalanche. Note that the voltage ﬂuctuates
drastically and the avalanche nearly stopped several times
(From Kuntz and Sethna (2000)). The analogous moment
rate time trace for earthquakes (though measured with
lower resolution) is shown in the right inset marked
“RAW” of Fig. 8
202
Physics of Jerky Motion in Slowly Driven Magnetic and Earthquake Fault Systems

ﬁeld theory). The corresponding value for b0 for
magnets in three dimensions is smaller – the
values used for the corresponding collapses can
be read off for the different versions of the RFIM
from the caption of Fig. 7.
Based on universality, one would expect these
theoretical predictions to agree with experimental
results, apart from an overall shift in time and
voltage or moment rate scales. For the moment
rate of earthquakes, this means
Physics of Jerky Motion in Slowly Driven Magnetic
and Earthquake Fault Systems, Fig. 7 (a) Theoretical
average avalanche shape scaling functions for ﬁxed
avalanche durations T denoted with g(t/T) in the text,
for the nucleation and the front propagation RFIM (Mehta
et al. 2002). The overall height is nonuniversal; the curves
for the two models are otherwise extremely similar. The
front propagation model has 1/nz ¼ 1.72, and the nucle-
ation model has 1/snz ¼ 1.75 in this collapse. The inset
shows the two curves rescaled to the same (nonuniversal)
height: the two curves are quantitatively different but far
more similar from one to another than either is to the
experimental curve in (b). (b) Experimental average
pulse shapes from three different experiments for ﬁxed
pulse duration, as measured by three different groups
(Durin and Zapperi 2000, 2002; Mehta et al. 2002;
Spasojevic et al. 1996). Notice that both theory curves
are much more symmetrical than those of the experiments.
Notice also that the three experiments do not agree. At ﬁrst,
this result represented a serious challenge to the idea about
universality of the dynamics of crackling noise (Sethna
et al. 2001). (c) Pulse shape asymmetry experiment
(Zapperi et al. 2005). Careful experiments show a weak
but systematic duration dependence in the collapse of the
average Barkhausen pulse shape. The longer pulses (larger
avalanches)
are
systematically
more
symmetrical
(approaching the theoretical prediction). (d) Pulse shape
asymmetry theory (Zapperi et al. 2005). Incorporating the
delay effects of eddy currents into the theoretical model
produces a similar systematic effect. The nonuniversal
effects of eddy currents are in principle irrelevant for
extremely large avalanches (From Sethna (2006))
Physics of Jerky Motion in Slowly Driven Magnetic and Earthquake Fault Systems
203

dm=dt
h
iobservation T, t
ð
Þ ¼ A dm=dt
h
itheory T=B, t=B
ð
Þ
ð14Þ
for some rescaling factors A and B and similarly for
the average voltage ⟨V⟩(t,T) in magnets. In both
cases, the theory predicts a symmetrical-looking
proﬁle. The mean ﬁeld prediction for g(x) is in
fact a parabola (Mehta et al. 2006; Sethna et al.
2001) – the theoretical prediction thus is that events
grow as quickly as they decay. As seen in Figs. 7b
and 8, the experimental/observational proﬁle in
both cases, however, appear skewed – the real
events tend to grow more quickly than they
decay! A similar asymmetry has also been
observed in avalanches associated with plastic
deformation (Laurson and Alava 2006).
For magnets, this apparent disagreement has
been resolved by taking greater account of a micro-
scopic detail involving eddy currents that had been
neglected by previous models. Eddy currents are
transient current loops that arise in conducting
magnets in response to the reorientation of a mag-
netic domain. These currents temporarily prevent
neighboring domains from being triggered to
realign in the same direction in an avalanche of
domain reversals. The eddy currents decay after a
microscopic time t given by the resistance of the
material. Their delay effect thus also decays after a
time t. If the avalanche duration is large compared
to t, this effect is negligible and the mean proﬁle
approaches the predicted symmetrical shape (see
Fig. 7c and d).
The source of asymmetry in the mean moment
rate proﬁle may be similar for earthquakes
(Dahmen 2005). It has been suggested that trig-
gering delays – arising from a noticeable earth-
quake nucleation time or an increase in the failure
threshold during the formation of new cracks and
subsequent weakening as rock damage increases –
could be responsible for aftershocks that often
follow large earthquakes (Mehta et al. 2006). On
long time scales, a large mainshock with smaller
aftershocks can be seen as a similar asymmetry to
that seen in magnets, possibly with a similar
explanation.
There is a second scaling function that may be
extracted from the same data: Fig. 9 shows the
average over all earthquakes of ﬁxed total moment
60
50
40
COLLAPSE
0
0
20
40
5
t [s]
10
15
AVERAGE
T = 10 s
T = 12 s
T = 15 s
30
20
10
0
0
0.2
0.4
scaled time t/T
scaled moment rate <dm0(t\T)/dt > / T
<dm0/dt>/10 [Nm/s]
0
0
5
10
15
RAW
5
t [s]
10
15
(dm0/dt)/10 [Nm/s]
0.6
0.8
1
Physics of Jerky Motion in Slowly Driven Magnetic
and Earthquake Fault Systems, Fig. 8 A collapse of
averaged earthquake pulse shapes, ⟨dm0(t|M0)/dt⟩with a
duration of T (seconds) within 10 % (given in legend), is
shown. The collapse was obtained using the mean ﬁeld
scaling relation (Kuntz and Sethna 2000): ⟨dm0(t|T)/
dt⟩ g(t/T). In order to obtain each collapsed pulse
shape, two to ten earthquakes were averaged for each
value of T. In our mean ﬁeld theory, the universal scaling
function is gmf(x) ¼ Ax(1  x) with x ¼ t/T. We plot this
functional form (bold curve) with A ¼ 80. Note the appar-
ent asymmetry to the left in the observed data while the
theoretical curve is symmetrical around its maximum.
Inset: The raw data and the averaged data (before col-
lapsed) (From Mehta et al. (2006))
204
Physics of Jerky Motion in Slowly Driven Magnetic and Earthquake Fault Systems

M⟨dm/dt⟩(M,t), both for observations and the BZR
model prediction. As shown in Mehta et al. (2006)
and Sethna et al. (2001), the theory predicts
dm=dt
h
i M, t
ð
Þ  M 1=2q t=M1=2


ð15Þ
where the universal scaling function q(x) ¼ Ax
exp  Bx2/2 and the universal exponents are
obtained from the mean ﬁeld theory for the BZR
earthquake model. A comparison between predic-
tion and observational results for this scaling
function is shown in Fig. 9.
Clearly, more data, especially for small earth-
quakes, are needed to decrease the statistical error
bars of the observational data and determine the
degree of agreement between theory and observa-
tions. An alternative scaling approach to moment
rate data was given by Houston (2001) and a
comparison between both approaches is discussed
in Mehta et al. (2006).
Non-monotonic Models
We ﬁrst consider including weakening of the cell
failure threshold by an amount ϵ for sections
which have already slipped in a given quake.
This crudely models the difference in static versus
dynamic friction (see section “Models,” Eq. 5). In
between quakes, all thus weakened thresholds
heal back to their static strength. The effects of
small weakening can be analyzed perturbatively.
With ϵ ¼ 0, consider a quake of diameter R1
( L or x), with moment M1 and area A1: i.e., A1
sites have slipped. If a small ϵ is turned on at the
end of the quake, all slipped sites that are within ϵ
of slipping will now slip again – this will be
N2  ϵA1 sites. The simplest justiﬁable guess is
that each of these will cause an approximately
independent secondary quake. The total moment
of these secondary quakes will be dominated by
the largest one, so the extra moment will be
M2  (ϵ A1). (For a very large or inﬁnite fault,
this is obtained from 1 ¼ N ex
2
ð1
Mex
2
P M
ð
ÞdM and
inserting Eq. 10.) If M2
ex  M1, this process can
continue but will not increase the total moment
substantially. If M2
ex  M1, however, the process
can continue with a larger area A2 and hence a
larger Mex, leading to a catastrophic runaway
event. From the above exponent relations and scal-
ing laws, we obtain B ¼ 1/2 and A  M, so that
scaled time t/M0
1/2
scaled moment rate <dm0(t\M0)/dt>/M0
1/2
8
7
6
M0 = 110 Nm
M0 = 220 Nm
M0 = 330 Nm
M0 = 440 Nm
0
0
5
(dm0/dt)/10 [Nm/s]
<dm0/dt>/10 [Nm/s]
10
15
0
0
4
8
12
4
8
RAW
3
t [s]
AVERAGE
t [s]
6
COLLAPSE
5
4
3
2
1
0 0
0.2
0.4
0.6
0.8
Physics of Jerky Motion in Slowly Driven Magnetic
and Earthquake Fault Systems, Fig. 9 A collapse of
averaged earthquake pulse shapes, ⟨dm0(t|M0)/dt⟩, with the
size of the moment M0 in Newton meters within 10 % of
each size given in the legend, respectively. In order to
obtain each collapsed moment rate shape, ﬁve to ten earth-
quakes were averaged for each value of M0. The collapse
was obtained using the mean ﬁeld scaling relation (Fisher
et al. 1997): ⟨dm0(t|M0)/dt⟩/M0
1/2  f(t/M0
1/2). In our mean
ﬁeld theory, the universal scaling function is fmf (x) ¼
Axe  Bx2/2 where x ¼ t/M0
1/2. We plot this functional
form (bold curve) with A ¼ 4 and B ¼ 4.9. Inset: The
raw data and the averaged data (before collapsed) see
Mehta et al. (2006))
Physics of Jerky Motion in Slowly Driven Magnetic and Earthquake Fault Systems
205

for any ϵ, for large enough M1, M 1>
~ M D  ϵ2,
M2
ex will be comparable to M1 and the quake will
become much larger (runaway). In the force-driven
inﬁnite system for F<
~ Fc , quakes of size x will
runaway and become inﬁnite if x > ϵ1. Since
x  (F  Fc)n and 1/n ¼ 1, this will occur for
Fc  F < Cwϵ with some constant Cw. This result
is very intuitive and justiﬁes a posteriori the
assumptions leading to it: Since on slipping, the
random pinning forces, fR, in a region are reduced
by order ϵ, the effective critical force Fc for contin-
uous slip will have been reduced by order ϵ; thus, if
F > Fc(ϵ) ¼ Fc  Cwϵ, the mean velocity v will
be nonzero. A similar effect can be caused by stress
pulses associated with Eq. 6. By considering which
of the sites in a long quake with α ¼ 0 can be
caused to slip further by such stress pulses, one
ﬁnds that runaway will occur for M  MD  α4
for the physical case (Fisher et al. 1997). This has
been checked in d ¼ 1 with Γ ¼ 1 and γ ¼ 0,
ﬁnding the predicted reduced critical force Fc(α) 
Fc  Cpα2 as shown in Fig. 10 (Fisher et al. 1997).
These 1-d simulations also reveal a hysteretic v F
ð Þ
curve in ﬁnite systems. This is expected to also
occur with the model with weakening discussed
above. Related higher dimensional systems are
discussed in Ramanathan and Fisher (1998) and
in Hillers et al. (2007).
We can now understand what should happen
with either weakening or stress pulses in ﬁnite
systems driven with a weak spring or with slowly
moving boundaries. As the system is loaded,
quakes of increasing size are observed. If the
system is small enough that it cannot sustain
quakes with M > MD(ϵ, α), i.e., even events
within the power law scaling regime of the event
size distribution, with M  MD(ϵ, α), are system
spanning, then the behavior will not be much
different from the monotonic case with ϵ ¼ α
¼ 0. In both cases, there is a power law event
size distribution all the way to the largest events
that are determined by the system size. This will
occur if the dominant linear system size L is less
than the maximum possible linear extent of an
earthquake that does not become a runaway
event: L < RD(ϵ, α)  MD
1/2  max(Cα/α2, Cϵ/ϵ)
with appropriate coefﬁcients Cα, Cϵ, which will
depend on the amount of randomness in the fault.
On the other hand, if L > RD, quakes of size of
order RD will runaway and most of the system will
slip, stopping only when the load has decreased
enough to make the loading forces less than the
lower end of the hysteresis loop in v F
ð Þ (as in
Fig. 10).
Because of the tendency of regions that have
already slipped to slip further and the consequent
buildup of larger stresses near the boundaries of
the slipped regions, large events in systems with
dynamic weakening will be much more crack-like
than in monotonic models, probably with Δu  L.
Statistics of quakes with weakening, ϵ, reasonably
large, but no stress, pulses (α ¼ 0) are shown in
Fig. 4 and in Ben-Zion (1996), and Ben-Zion and
Rice (1993, 1995); note the absence of quakes
with intermediate moments. A typical large
event in this case is shown in Fig. 5b; it appears
to be crack-like.
In this section, we have shown that simple
models of heterogeneous faults – with the dimen-
sionality and long-range elastic interactions prop-
erly included – can give rise to either power law
statistics of earthquake moments or a distribution
of small events combined with characteristic
system-size
events.
Which
behavior
–
or
0.0
0.00
0.10
0.20
Velocity
0.30
0.40
1.0
Force
2.0
0.0
α
1.0
0.0
Δ(α)
α = 0.8
α = 0.5
α = 0
0.6
3.0
Physics of Jerky Motion in Slowly Driven Magnetic
and Earthquake Fault Systems, Fig. 10 Mean velocity
versus force for one-dimensional system with a non-
monotonic kernel J(x,t) ¼ δ(t  x)/x2 + αδ0(t  x)/x for
α ¼ 0.8,0.5,0. A spring or boundary-loaded system will
traverse the hysteresis loops in the direction indicated.
Inset: the threshold force, Fc
"(α), on increasing the load;
Δα ¼ [1  Fc
"(α)/Fc
"(α ¼ 0)]1/2 is plotted versus α (From
Fisher et al. (1997))
206
Physics of Jerky Motion in Slowly Driven Magnetic and Earthquake Fault Systems

intermediate behavior – obtains is found to
depend on a number of physical properties such
as frictional weakening and dynamic stress trans-
fer, analogs of which should deﬁnitely exist in real
systems. In the power law regime, the convention-
ally deﬁned Gutenberg-Richter exponent b  3B/
2 (Ben-Zion 2003) is found to be b ¼ 3/4. This is
close to the observed b-value of global strike-slip
earthquakes at depth less than 50 km (Frohlich
and Davis 1993).
Mode Switching
In Dahmen et al. (1998), the mean ﬁeld approxi-
mation of inﬁnite range elastic interaction in the
BZR model with N ¼ LW (with W  L) geomet-
rically equal cells on the fault is used to write the
local stress ti on cell i as
ti ¼
J=N
X
j
uj  ui


þ KL vt  ui
ð
Þ
¼
Ju þ KLvt  KL þ J
ð
Þui,
ð16Þ
where ui is the total fault offset of cell i in the
horizontal (x) direction, u ¼
X
j
uj
 
!
=N , J/N is
the elastic coupling between cells in the mean
ﬁeld approximation, and KL is the effective load-
ing stiffness of the bulk material surrounding the
fault patch. Instead of the loading spring stiffness
KL, a conservation parameter c  J/(KL + J) is
introduced, which equals the fraction of the stress
drop of the failing cell, that is retained in the
system after the slip. There, it is shown that for
the physical loading spring stiffness KL  1/L,
one has 1  c  O 1=
ﬃﬃﬃﬃ
N
p


. A value c < 1 for a
large system would be physically realized if the
external drive is closer to the fault than its linear
extent. To be precise, mean ﬁeld theory only gives
the correct physical scaling behavior near the crit-
ical point at zero weakening ϵ ! 0 and for
c ! 1. In Dahmen et al. (1998), it is shown,
however, that in a certain parameter regime for
ϵ > 0 and 0.5 < c < 1 indicated in the phase
diagram of Fig. 11, one ﬁnds a mode-switching
behavior between Gutenberg-Richter statistics
and characteristic earthquake statistics. Similar
mode-switching behavior has also been seen in a
more
realistic
three-dimensional
model
for
coupled evolution of earthquakes and faults
(Ben-Zion et al. 1999; Lyakhovsky et al. 2001)
and in numerical simulations with the BZR model
that includes elastic stress transfer (Zöller et al.
2004). In the mean ﬁeld BZR model, the activity
switching results from episodic global reorgani-
zation of the mode of strain energy release of the
fault system, reﬂected in a “conﬁgurational
entropy” of stress states on the fault (Dahmen
et al. 1998). This is associated with a statistical
competition between a tendency of a synchro-
nized behavior leading to clusters of large earth-
quakes
and
the
characteristic
earthquake
distribution
and
a
tendency
for
disordered
response leading to Gutenberg-Richter-type sta-
tistics without a preferred event size. Mode
switching happens when these two opposite ten-
dencies are roughly equal in strength. Some pos-
sible observational evidence for mode switching
in earthquake data is discussed in Ben-Zion
et al. (1999).
Results on Aftershocks
As mentioned in “Simple Models for Inhomoge-
neous Earthquake Faults,” we associate regions
off the main fault segments that are in an early
mode
ε > 0
weakening
ε < 0
strengthening
ε
ε–2
switching
Char. EQ.
GR
0
1-c
0.5
1
(w. aftershocks)
M0
ε–2
M0
n(M0)
n(M0)
truncated
power law
truncated power law
critical point
Physics of Jerky Motion in Slowly Driven Magnetic
and Earthquake Fault Systems, Fig. 11 Phase diagram
of the BZR model, described in the text. The range ϵ > 0
represents dynamic weakening, while ϵ < 0 represents
strengthening. The parameter 1  c quantiﬁes the devia-
tion from stress conservation in the mean ﬁeld approxima-
tion of the model
Physics of Jerky Motion in Slowly Driven Magnetic and Earthquake Fault Systems
207

deformation stage with dynamic strengthening
ϵ < 0. To capture basic aspects of brittle defor-
mation on such regions in the three-dimensional
volume around the main fault (Fig. 3), we change
the model as follows: when any cell i slips during
an earthquake and thereby reduces its stress by
Δti  tf,i  ta,i, the failure stress tf,j of every cell
j ¼ 1,. . ., N is strengthened by an amount
|ϵ|Δti/N. Once the earthquake is complete, the
failure stress of each cell is slowly lowered back
to its original value. This represents in a simple
way the brittle deformation that occurs during an
earthquake in the off-fault regions, which are ﬁrst
in a strengthening regime, compared to the main
fault, and then have a weakening process. The
events that are triggered as the failure stresses
are lowered in the weakening period are referred
to as aftershocks. The occurrence of aftershocks in
this version of the model for off-fault regions is in
agreement with the observation that a large frac-
tion of observed aftershocks typically occur in off-
fault regions (Utsu et al. 1995). For this version of
the model with ϵ < 0, both the primary earth-
quakes (i.e., mainshocks) and the triggered after-
shocks
are
distributed
according
to
the
Gutenberg-Richter distribution, up to a cutoff
moment scaling as 1/ϵ2. Assuming that the
increased failure stress thresholds tf,i are slowly
lowered with time as log(t) toward their earlier
static values ts,i and that the stresses are distrib-
uted over a wide range of values, we show ana-
lytically in Mehta et al. (2006) that the temporal
decay of aftershock rates at long times is propor-
tional to 1/t, as in the modiﬁed Omori law ΔN/
ΔtK/(t + c)p with p ¼ 1 (Ben-Zion 2003; Utsu
2002; Utsu et al. 1995), where N is the cumulative
number of aftershocks, t is the time after the
mainshock, and K, c, and p are empirical
constants.
Remarkably, the long length-scale behavior of
this model can be shown (Mehta 2005) to be the
same as the behavior of the mean ﬁeld BZR model
given in Eq. 16 with an added “antiferroelastic”
term ( ϵj jJu):
ti ¼ Ju þ KLvt  KL þ J
ð
Þui  ϵj jJu:
ð17Þ
In Eq. 17, every time a cell fails, it slips by an
amount Δui that leads to stress loading of the other
cells, lessened by |ϵ|JΔui/N compared to our orig-
inal model (Eq. 16). On the other hand, in the
global strengthening model (described above),
when a cell slips, the failure stresses of all cells
are strengthened by |ϵ|JΔui/N. On long length
scales, the global strengthening of the failure
stress has equivalent effects on the earthquake
statistics as the dissipation of the redistributed
stress, up to corrections of order O(1/N), so the
scaling behavior for large events of both models
are the same. Moreover, Eq. 17 can be rewritten as
ti ¼ J 1  ϵj j
½
 u  ui
½
 þ KLvt  KL þ J ϵj j
½
ui:
ð18Þ
We can now absorb |ϵ| by deﬁning J0 ¼ J(1-
 |ϵ|) and KL0 ¼ KL + J|ϵ|. Rewriting Eq. 18 with
the new deﬁnitions and dropping the |ϵ| contribu-
tion in [KL0  J|ϵ|]nvt since v ! 0, we ﬁnd
ti ¼ J 0u þ K0
Lvt  K0
L þ J 0


ui:
ð19Þ
Therefore, we recover Eq. 16 with J ! J and
KL ! KL0. This amounts to changing the stress
conservation
parameter
c
(from
reference
(Dahmen et al. 1998)). For Eq. 19
c ¼ J 0= K0
L þ J 0


¼ 1  ϵj j
ð20Þ
where KL ! 0 since we are concerned with the
adiabatic limit. We also know (from reference
(Dahmen et al. 1998)) that the cutoff Scf for the
Gutenberg-Richter distribution scales as Scf ~
1/(1  c)2. Thus, from Eq. 20, we ﬁnd that the
cutoff for Eq. 17 will scale as ~ 1/|ϵ|2.
Mapping to Single-Interface Magnet Model
The mean ﬁeld version of the single-interface
magnet model with inﬁnite range antiferromag-
netic interactions is given by (Durin and Zapperi
2001; Zapperi et al. 1998)
_hi tð Þ ¼ J h  hi tð Þ


þ H tð Þ  kh þ i h
ð Þ ð21Þ
208
Physics of Jerky Motion in Slowly Driven Magnetic and Earthquake Fault Systems

where hi(t) is the position of the domain wall, H(t)
is the external driving ﬁeld, k is the coefﬁcient of
the antiferromagnetic term, and Zi(h) is the pin-
ning ﬁeld. In the paper by Fisher et al. (1997), it
has been shown that the scaling behavior on long
length scales resulting from Eq. 5, without the
 ϵj jJu term, is the same as that of Eq. 21 without
the antiferromagnetic term kh . Furthermore,
upon inspection, we see the following correspon-
dence between the single-interface magnet model
(Eq. 21) and the mean ﬁeld earthquake model
(Eq. 17):
kh ,  ϵj jJu
ð22Þ
In other words, the coefﬁcient of the antiferro-
magnetic term k plays the same role in the magnet
model (Eq. 21), as the coefﬁcient of strengthening
|ϵ|J does in the earthquake model (Eq. 17).
Summary
Phase Diagram
The regimes with various statistics produced by
the model are summarized by the phase diagram
given in Fig. 11. The range ϵ > 0 corresponds to
“mature” localized faults with a weakening rheol-
ogy and characteristic earthquake statistics. The
value ϵ ¼ 0 corresponds to “immature” strongly
inhomogeneous fault zones and fault networks
with power law statistics and scale-invariant rup-
ture properties. The range ϵ < 0 corresponds to
the fracture and fault networks around large rup-
ture zones, characterized by strengthening due to
the creation of new structures and associated
emerging aftershocks. The right side of the dia-
gram summarizes the mean ﬁeld theory results on
mode switching described in “Mode Switching.”
The left side of the phase diagram resembles the
phase diagram for avalanches in the nucleation
RFIM for magnets (Sethna et al. 1993). There,
too, increasing the disorder from small to large
(compared to the ferromagnetic coupling between
the individual domains) drives the system from a
characteristic avalanche size distribution to a
truncated power law, with a disorder-induced crit-
ical point separating the two regimes.
It may be surprising that the discussed simple
BZR model can capture many of the essential
general features of earthquake statistics (or other
systems with avalanches, such as driven magnetic
domain walls). This can be understood through
the renormalization group (Binney et al. 1993;
Sethna et al. 2001), a powerful mathematical
tool to coarse grain a system and extract its effec-
tive behavior on long space-time scales. Many
microscopic details of a system are averaged out
under coarse graining, and universal aspects of the
behavior on long scales depend only on a few
basic properties such as symmetries, dimensions,
range of interactions, weakening/strengthening,
etc. When a model correctly captures those basic
features, the results provide proper predictions for
statistics, critical exponents, and universal scaling
functions near the critical point. Consequently,
many models that are in the same universality
class lead to the same statistics and exponents
(Binney et al. 1993; Dahmen et al. 1998; Fisher
et al. 1997; Sethna et al. 2001).
Conclusions
The phenomenology of earthquakes and ava-
lanches in magnets exhibits a number of power
law distributions and scale-invariant functions
(Table 1). In search of basic model ingredients
that can explain these results, we have focused
on models that are rich enough to produce a diver-
sity of observed features, while being simple
enough to allow analytic predictions on long spa-
tiotemporal scales. For the earthquake system, we
use the BZR model for a heterogeneous fault with
threshold dynamics and long-range stress-transfer
interactions (Ben-Zion 1996; Ben-Zion and Rice
1993, 1995). For the magnet system, we use var-
iants of the RFIM model with threshold dynamics
and both short-range and long-range interactions
(Kuntz and Sethna 2000; Sethna et al. 1993, 2001;
Zapperi et al. 1998). In both classes of models,
changes in the property disorder and dynamic
effects
lead
to
different
dynamic
regimes
(Fig. 11). For different ranges of parameters, the
Physics of Jerky Motion in Slowly Driven Magnetic and Earthquake Fault Systems
209

earthquake model produces fractal and crack-like
slip functions, power law frequency-size statis-
tics, characteristic earthquake distribution, mode
switching, and aftershocks. Similar features are
found with the magnet models. We discussed
two universal scaling functions of moment rates
near criticality as a stronger test of the theory
against observations than mere scaling exponents
that have large error bars. As in magnetic systems,
we ﬁnd that our analysis for earthquakes provides
a good overall agreement between theory and
observations but with a potential discrepancy in
one particular universal scaling function for mean
moment-rate shapes at ﬁxed duration. The dis-
crepancy has an interesting precedent in the con-
text of avalanches in magnetic systems and has
been explained there in terms of nonuniversal
time retardation effects due to eddy currents. Sim-
ilar retardation effects may be due to triggering
delays or strengthening effects that are responsi-
ble for aftershocks in earthquake faults. More
observational data, in particular on small earth-
quakes, would be needed to test some of the pre-
dictions in detail.
Future Directions
We have highlighted some interesting connec-
tions between earthquake and magnet systems
with a jerky response to a slowly varying driving
force. Future useful studies include analysis of
factors controlling nucleation processes, transi-
tions to instabilities, and ﬁnal event sizes, along
with a more detailed analysis of the effects of
geometrical heterogeneities in the fault structure
on the statistics of earthquakes. Additional obser-
vational data, particularly for small earthquakes,
are needed to test predictions for the scaling of the
earthquake
duration
and
rupture
area
with
moment and for accurately testing our mean ﬁeld
predictions for moment rate shapes. Developing
analytic corrections to the mean ﬁeld earthquake
models can provide additional important insights.
Testing similar ideas in other systems with crack-
ling noise would improve and deepen our under-
standing of universal behavior in disordered
nonequilibrium systems.
Acknowledgments We thank Daniel S. Fisher, James
R. Rice, James P. Sethna, Michael B. Weissman, Deniz
Ertas, Matthias Holschneider, Amit Mehta, Gert Zöller,
and many others for the very helpful discussions.
K.D. acknowledges support from the National Science
Foundation, the NSF-funded Materials Computation Cen-
ter, and IBM. YBZ acknowledges support from the
National Science Foundation, the United States Geological
Survey, and the Southern California Earthquake Center.
Bibliography
Primary Literature
Aki K, Richards PG (2002) Quantitative seismology,
2nd edn. University Science, Sausalito
Ben-Zion Y (1996) Stress slip and earthquakes in models
of complex single-fault systems incorporating brittle
and
creep
deformations.
J
Geophys
Res
101:
5677–5706
Ben-Zion Y (2003) Appendix 2, key formulas in earth-
quake seismology. In: Lee WHK, Kanamori H,
Jennings PC, Kisslinger C (eds) International hand-
book of earthquake and engineering seismology, Part
B. Academic, San Diego, pp 1857–1875
Ben-Zion Y, Rice JR (1993) Earthquake failure sequences
along a cellular fault zone in a three-dimensional elastic
solid containing asperity and nonasperity regions.
J Geophys Res 98:14109–14131
Ben-Zion Y, Rice JR (1995) Slip patterns and earthquake
populations along different classes of faults in elastic
solids. J Geophys Res 100:12959–12983
Ben-Zion Y, Sammis CG (2003) Characterization of fault
zones. Pure Appl Geophys 160:677–715
Ben-Zion Y, Zhu L (2002) Potency-magnitude scaling
relations for southern California earthquakes with
1.0 < ML < 7.0. Geophys J Int 148:F1–F5
Ben-Zion Y, Dahmen K, Lyakhovsky V, Ertaş D, Agnon
A (1999) Self driven mode switching of earthquake
activity on a fault system. Earth Planet Sci Lett
172(1–2):11–21
Bilek SL (2001) Earthquake rupture processes in circum-
Paciﬁc subduction zones. Ph.D. thesis, University of
California
Binney JJ, Dowrick NJ, Fisher AJ, Newman MEJ
(1993) The theory of critical phenomena. Oxford Uni-
versity Press, Oxford
Carlson JM, Langer JS, Shaw BE (1994) Dynamics of
earthquake faults. Rev Mod Phys 66:658–670, and
references therein
Chen K, Bak P, Obukhov SP (1991) Phys Rev A 43:625
Cizeau P, Zapperi S, Durin G, Stanley HE (1997) Phys Rev
Lett 79:4669–4672
Cowie PA, Vanette C, Sornette D (1993) J Geophys Res
98:21809
Dahmen K (1995) Hysteresis, avalanches, and disorder
induced critical scaling: a renormalization group
approach. Ph.D. Thesis, Cornell University
210
Physics of Jerky Motion in Slowly Driven Magnetic and Earthquake Fault Systems

Dahmen K (2005) Nat Phys 1:13–14
Dahmen KA, Sethna JP (1996) Hysteresis, avalanches, and
disorder induced critical scaling: a renormalization
group approach. Phys Rev B 53:14872
Dahmen K, Ertaş D, Ben-Zion Y (1998) Gutenberg-
Richter and characteristic earthquake behavior in a
simple mean-ﬁeld model of heterogeneous faults.
Phys Rev E 58:1494–1501
Dieterich JH (1979) J Geophys Res 84:2161–2168
Dieterich JH (1981) Am Geophys Union Monogr 24:
103–120
Durin G, Zapperi S (2000) Scaling exponents for
Barkhausen avalanches in polycrystalline and amor-
phous ferromagnets. Phys Rev Lett 84:4705–4708
Durin G, Zapperi S (2001) J Magn Mat 1085:242–245
Durin G, Zapperi S (2002) Low ﬁeld hysteresis in disor-
dered ferromagnets. Phys Rev B 65:144441
Ertaş D, Kardar M (1994a) Critical dynamics of contact
line depinning. Phys Rev E 49:R2532–R2535
Ertaş D, Kardar M (1994b) Phys Rev E 49:R2532,
(1994) Phys Rev Lett 73:1703
Fisher DS (1998) Phys Rep 301:113
Fisher DS, Dahmen K, Ramanathan S, Ben-Zion Y (1997)
Phys Rev Lett 78:4885–4888
Frohlich C, Davis SD (1993) J Geophys Res 98:631
Gutenberg B, Richter CF (1954) Seismicity of earth and
associated phenomena. Princeton University Press,
Princeton
Hillers G, Mai PM, Ben-Zion Y, Ampuero J-P (2007) Sta-
tistical properties of seismicity along fault zones at
different evolutionary stages. Geophys J Int 169(515):
V533. doi:10.1111/j.1365-246X.2006.03275.x
Houston H (2001) Inﬂuence of depth, focal mechanism,
and tectonic setting on the shape and duration of earth-
quake
source
time
functions.
J
Geophys
Res
106(B6):11137–11150
Ji H, Robbins MO (1992) Percolative, self-afﬁne, and
faceted domain growth in random three-dimensional
magnets. Phys Rev B 46:14519–14527
Jiles D (1991) Introduction to magnetism and magnetic
materials. Chapman and Hall, London
Klein W, Rundle JB, Ferguson CD (1997) Scaling and
nucleation in models of earthquake faults. Phys Rev
Lett 78:3793–3796
Koiller B, Ji H, Robbins MO (1992a) Fluid wetting prop-
erties and the invasion of square networks. ibid 45:
7762–7767
Koiller B, Ji H, Robbins MO (1992b) Effect of disorder and
lattice type on domain-wall motion in two dimensions.
Phys Rev B 46:5258–5265
Kuntz MC, Sethna JP (2000) Phys Rev B 62:11699–11708
Langer JS, Carlson JM, Myers CR, Shaw BE (1996) Slip
complexity in dynamic models of earthquake faults.
Proc Natl Acad Sci 93:3825–3829
Laurson L, Alava MJ (2006) 1/f noise and avalanche scal-
ing in plastic deformation. Phys Rev E 74:066106
Lomnitz-Adler J (1993) Automaton models of seismic
fracture:
constraints imposed
by
the
magnitude-
frequency relation. J Geophys Res 98:17745–17756
Lyakhovsky V, Ben-Zion Y, Agnon A (2001) Earthquake
cycle, fault zones, and seismicity patterns in a rheologi-
cally layered lithosphere. J Geophys Res 106:4103–4120
Marchetti MC, Middleton AA, Prellberg T (2000) Visco-
elastic depinning of driven systems: mean-ﬁeld plastic
scallops. Phys Rev Lett 85:1104–1107
Martys N, Robbins MO, Cieplak M (1991) Scaling rela-
tions for interface motion through disordered media:
application to two-dimensional ﬂuid invasion. Phys
Rev B 44:12294–12306
Mayergoyz ID (1991) Mathematical models of hysteresis.
Springer, New York
Mehta AP (2005) Ph.D. Thesis, University of Illinois at
Urbana Champaign
Mehta AP, Mills AC, Dahmen KA, Sethna JP (2002) Phy
Rev E 65:46139, 1–6
Mehta AP, Dahmen KA, Ben-Zion Y (2006) Universal
mean moment rate proﬁles of earthquake ruptures.
Phys Rev E 73:056104
Middleton AA (1992) Phys Rev Lett 68:670
Miltenberger P, Sornette D, Vanette C (1993) Phys Rev
Lett 71:3604
Myers CR, Sethna JP (1993a) Collective dynamics in a
model of sliding charge-density waves. I. Critical
behavior. Phys Rev B 47:11171–11193
Myers CR, Sethna JP (1993b) Collective dynamics in a
model of sliding charge-density waves. II. Finite-size
effects. Phys Rev B 47:11194–11203
Narayan O, Fisher DS (1992a) Critical behavior of sliding
charge-density waves in 4  dimensions. Phys Rev
B 46:11520–11549
Narayan O, Fisher DS (1992b) Dynamics of sliding
charge-density waves in 4  dimensions. Phys Rev
Lett 68:3615–3618
Narayan O, Fisher DS (1993) Threshold critical dynamics
of driven interfaces in random media. Phys Rev B 48:
7030–7042
Narayan O, Middleton AA (1994) Avalanches and the
renormalization
group
for
pinned
charge-density
waves. Phys Rev B 49:244
Nattermann T (1997) Theory of the random ﬁeld Ising
model. In: Young AP (ed) Spin glasses and random
ﬁelds. World Scientiﬁc, Singapore
Omori F (1894) On the aftershocks of earthquakes. J Coll
Sci Imp Univ Tokyo 7:111–200
Perković O, Dahmen K, Sethna JP (1995) Avalanches,
Barkhausen noise, and plain old criticality. Phys Rev
Lett 75:4528–4531
Perković O, Dahmen K, Sethna JP (1999) Disorder-
induced critical phenomena in hysteresis: numerical
scaling in three and higher dimensions. Phys Rev
B 59:6106–6119
Ramanathan S, Fisher DS (1998) Phys Rev B 58:6026
Rice JR, Ben-Zion Y (1996) Slip complexity in earthquake
fault models. Proc Natl Acad Sci 93:3811–3818
Ruff LJ, Miller AD (1994) Pure Appl Geophys 142:101
Schwarz JM, Fisher DS (2001) Depinning with dynamic
stress overshoots: mean ﬁeld theory. Phys Rev Lett 87:
096107, 1–4
Physics of Jerky Motion in Slowly Driven Magnetic and Earthquake Fault Systems
211

Sethna JP (2006) Les Houches Summer School notes.
Crackling noise and avalanches: scaling, critical phe-
nomena, and the renormalization group. E-print at
http://xxx.lanl.gov/pdf/cond-mat/0612418
Sethna JP, Dahmen K, Kartha S, Krumhansl JA, Roberts
BW, Shore JD (1993) Hysteresis and hierarchies:
dynamics of disorder driven ﬁrst order phase transfor-
mations. Phys Rev Lett 70:3347
Sethna JP, Dahmen KA, Myers CR (2001) Nature 410:
242–250
Spasojevic D, Bukvic S, Milosevic S, Stanley HE
(1996) Barkhausen noise: elementary signals. Power
laws, and scaling relations. Phys Rev E 54:2531–2546
Travesset A, White RA, Dahmen KA (2002) Phys Rev
B 66:024430
Utsu T (2002) Statistical features of seismology. In: Lee
WHK, Kanamori H, Jennings PC, Kisslinger C (eds)
International handbook of earthquake and engineering
seismology, Part A. Academic, New York, pp 719–732
Utsu Y, Ogata Y, Matsu’uara RS (1995) The centenary of
the Omori Formula for a decay law of aftershock activ-
ity. J Phys Earth 43:1–33
Vere-Jones
D
(1976)
A
branching
model
for
crack propagation. Pure Appl Geophys 114(4):
711–726
Zapperi S, Cizeau P, Durin G, Stanley HE (1998) Dynamics
of a ferromagnetic domain wall: avalanches, depinning
transition, and the Barkhausen effect. Phys Rev
B 58(10):6353–6366
Zapperi S, Castellano C, Calaiori F, Durin G (2005) Sig-
nature of effective mass in crackling-noise asymmetry.
Nat Phys 1:46–49
Zöller G, Holschneider M, Ben-Zion Y (2004) Quasi-static
and Quasi-dynamic modeling of earthquake failure at
intermediate
scales.
Pure
Appl
Geophys
161:
2103–2118
Zöller G, Holschneider M, Ben-Zion Y (2005) The role of
heterogeneities as a tuning parameter of earthquake
dynamics.
Pure
Appl
Geophys
162:1027–1049.
doi:10.1007/s00024-004-2660-9
Zöller G, Hainzl S, Ben-Zion Y, Holschneider M (2009)
Critical states of seismicity: from models to practical
seismic hazard estimates. In: Encyclopedia of complex-
ity and system science
212
Physics of Jerky Motion in Slowly Driven Magnetic and Earthquake Fault Systems

Flexible Mechanical Structures
and Their Topologically
Protected Deformations
D. Zeb Rocklin
Georgia Institute of Technology, Atlanta, GA,
USA
Article Outline
Glossary
Introduction
Rigidity
Topological Boundary Modes of Maxwell
Lattices
Continuum Systems
Conclusion
Bibliography
Glossary
Bloch mode A mode of a periodic structure that
differs between unit cells only by a phase fac-
tor, with the physical part understood to be the
real part of the complex ﬁeld.
Constraint Some algebraic, usually linear, equa-
tion relating a condition between degrees of
freedom that must be satisﬁed. Violations of a
linear constraint cost an energy proportional to
the constraint’s stiffness, and in the limit of
inﬁnite stiffness the constraint is called strict
and is always satisﬁed. The most common type
of constraint that one considers is that the dis-
tance between two particles not change.
Degree of Freedom A scalar number partially
describing the conﬁguration of a system.
Most often, a component of a displacement of
a particle from its initial position.
Dynamical Matrix A self-adjoint linear opera-
tor, typically denoted D, that maps from the
vector of the system’s degrees of freedom to
the vector of the forces.
Equilibrium Matrix A linear operator, typically
denoted Q, whose i, j element describes the
linear scaling between the tension associated
with the violation of the jth constraint and the
force on the ith degree of freedom. Its trans-
pose is the rigidity matrix.
Floppy mode A deformation mode of a structure
that satisﬁes all constraints to linear order and
thus costs zero energy. That is, a zero mode that
changes the shape rather than just the position
or orientation of the structure.
Rigid A structure is rigid if the only way in
which it can be continuously deformed is via
the Euclidean motions of uniform translations
and rotations of the whole structure.
Rigidity Matrix A linear operator, typically
denoted C whose i, j element describes the
linear scaling between the jth degree of free-
dom and the ith constraint. Its transpose is the
equilibrium matrix.
Self stress A set of tensions within bonds that
generates no net force on any particle or
pseudo-force on any degree of freedom.
Stiffness Matrix A self-adjoint linear operator,
typically denoted K, that maps from the vector
of the violations of the system’s constraints to
the vector of the associated tensions. In the case
that all of the constraints consist of springs, the
stiffness matrix is a diagonal matrix whose ele-
ments are the spring stiffnesses.
Topological Invariant Also called a topological
number, this is a number, usually an integer or
a binary number, that corresponds to a topo-
logical state and thus changes only via abrupt
transitions.
Winding Number An integer topological invari-
ant associated with a map from the one-sphere
(a circle) to itself. This is the net number of
times the mapped function covers the one-
sphere each time one winds around the original
space. It assumes different physical signiﬁ-
cance in different systems.
© Springer Science+Business Media, LLC, part of Springer Nature 2022
B. Chakraborty (ed.), Statistical and Nonlinear Physics,
https://doi.org/10.1007/978-1-0716-1454-9_733
Originally published in
R. A. Meyers (ed.), Encyclopedia of Complexity and Systems Science, © Springer Science+Business Media LLC 2022
https://doi.org/10.1007/978-3-642-27737-5_733-1
213

Zero
Mode An inﬁnitesimal deformation
or
Euclidean motion of a structure that satisﬁes all
constraints to linear order and thus costs zero
energy.
Introduction
The particles composing a ﬂuid continuously
rearrange themselves. In contrast, a solid object
possesses bonds of sufﬁcient strength such that
the relative positions of its composite particles are
ﬁxed, up to overall rigid-body rotations and trans-
lations. In conventional equilibrium physics,
phase transitions shift systems abruptly from
solid to ﬂuid, with no intermediate regime.
However, as permanent bonds (or the tempo-
rary contact forces present in, e.g., granular sys-
tems) are added to a structure one by one it
acquires the ability to support external loads
before it is reduced to a single rigid conﬁguration.
Such ﬂexible structures are able to undergo pre-
scribed motions and have tremendous utility in
locomotion, manipulation, and shape-changing.
Consequently, they are ubiquitous in both biology
and in technological applications.
As will be explored here, such ﬂexible objects
realize complex algebraic structures. A rigid, solid
object possesses only a single minimum-energy
shape and the particles of a ﬂuid explore an
ensemble of nearly any possible set of positions,
but the subset of spatial embeddings of a set of
particles that satisfy a critical number of bond
constraints
can
describe
a
complex,
high-
dimensional manifold. Remarkably, when the
structure
has
long-range
(typically
periodic)
order in its bulk, this can actually determine the
existence of modes on the boundary, the topolog-
ical bulk-boundary correspondence of ﬂexible
mechanical
structures
(Kane
and
Lubensky
2014). This same principle extends not only to
purely geometrical embeddings but also to struc-
tural dynamics (Süsstrunk and Huber 2016).
Rigidity
Consider a set of point particles, each with no
internal structure or orientational degrees of
freedom, with positions in D-dimensional space
given by {ri} and with some sets of bonds of rest
lengths ‘α and some bond topology of the form
pα ¼ (i, j) specifying that bond α connects parti-
cles i, j. One can then deﬁne the extension
function,
ea  rpa,2  rpa,1

  ‘a,
ð1Þ
where a positive value indicates extension of the
bond and a negative amount indicates compression.
A rigid embedding is then a set of particle
positions that satisﬁes the constraint equations
eα ¼ 0. As will be explored below, different
mechanical constraints may arise as well.
The space of embeddings of Np particles in
D-dimensional Cartesian space is simply the ten-
sor product of N copies of ℝD. In the absence of
any bonds, the space of rigid embeddings is this
entire NpD-dimensional space. Including a single
bond of ﬁnite length reduces the dimension of this
space by one. For example, in three dimensions,
once the position of one particle connected to the
bond is ﬁxed, the second must lie on a two-
dimensional sphere centered on that particle rather
than at an arbitrary point in three-dimensional
space. In contrast, including a bond of vanishing
length reduces the dimension of the space of rigid
embeddings by D, since it requires each of the
D components of the position of the second parti-
cle to coincide with the ﬁrst. Unless otherwise
stated, bonds will be taken to have ﬁnite rest
length. This simple counting argument, in which
a single constraint can reduce the space of allowed
embeddings, goes back to JC Maxwell’s founda-
tional 1864 formulation of mechanical constraints
(Maxwell 1864).
Continuing in this way, adding an additional
bond reduces the manifold of rigid embeddings to
a submanifold one dimension lower. However,
two special cases present themselves. Consider
as the ﬁrst a rigid bond structure such that the
distance between two particles is ﬁxed. Placing a
bond between these two particles with rest length
equal to this distance will have no affect on the
rigid states of the system. As a slightly more
complicated example, consider the structure in
Fig. 1d, in which four particles in two dimensions
214
Flexible Mechanical Structures and Their Topologically Protected Deformations

are arranged in a square with bonds between each
pair of particles. Either one of the two bonds that
crosses the interior of the square sufﬁces to render
the structure rigid, meaning that the second such
bond is redundant. Such redundant bonds allowed
Maxwell to identify a necessary but not sufﬁcient
number of bonds to render a mechanical system
with a certain number of degrees of freedom rigid.
The simplest example of such a redundant bond
would be one placed between two particles that
are already bonded.
Alternately, one could take a pair of particles of
ﬁxed rigid separation and place a bond between
them with some other rest length. Because this
new, incompatible constraint cannot be satisﬁed
simultaneously with the existing ones, this elimi-
nates entirely the rigid embeddings. The result
must be a stressed structure in which at least one
constraint is violated. A trivial example would be
the joining of three particles via three bonds
whose lengths do not satisfy the triangle inequal-
ity. Another example, returning again to Fig. 1d,
would occur if one of the rest lengths of any of the
bonds were changed, so that no embedding of the
structure could achieve all of the rest lengths.
Linearization
Flexible structures possess fascinating and rich
sets of nonlinear modes, from the shearing of the
simple square truss of Fig. 1c to the folding of the
most intricate origami. However, in order to make
contact most directly with topological band the-
ory, it is necessary for us to narrow our focus, at
least temporarily, to inﬁnitesimal deformations of
structures about rigid embeddings. Consider a
embedding subject to inﬁnitesimal displacements
such that ri ! ri þ ui. Via Eq. (1), the extension of
a bond between particles i, j is
Flexible Mechanical Structures and Their Topologi-
cally Protected Deformations, Fig. 1 (a) A system of
particles (gray dots) located at positions ri joined by bonds
of lengths ‘j, with the blackness of the bonds indicating that
they are at their rest lengths. (b) Particles undergo displace-
ments indicated by blue arrows that extend (red) or
compress (green) the bonds. Alternately, the same diagram
could represent tensions within bonds and the external
forces needed to balance them. (c) A set of displacements
that does not stretch any bonds: a zero mode. (d) A set of
tensions that does not generate a force on any particle: a
state of self stress
Flexible Mechanical Structures and Their Topologically Protected Deformations
215

ea ¼ r j  ri þ u j  ui

  ‘a
ð2Þ
¼ rij

  ‘a þ brij  uij
þ
1
2 rij

 u2
ij  brij  uij

2
h
i
þO u3


,
ð3Þ
where vij  vj – vi, bu  v= j v j . For a rigid
embedding, |rij|  ‘α ¼ 0 and consequently the
linear extension takes the simple form:
ea ¼ brij  uij:
ð4Þ
We may then describe the linear relationship
between the vector of extensions e and the vector
describing the displacements of all the particles,
u  u1, u2, . . . uNp


(here denoting a concatena-
tion of vectors into a vector, not composition into
a matrix) via the linear map
e ¼ Cu,
ð5Þ
where C is known as the compatibility matrix, or
sometimes the rigidity matrix, since its nullspace
is the set of deformations that are rigidly compat-
ible with one another. Such modes, costing zero
energy and resulting in zero extension (to linear
order) are referred to as zero modes.
We now introduce minimal dynamics by sup-
posing that our bonds generate a Hookean return
force. In this case, the system’s potential energy
takes the form
E ¼ 1
2 eTKe,
ð6Þ
where K is a diagonal matrix with each element
kα the spring constant associated with bond α.
From this, one may obtain the vector of forces
f that the structure exerts on all the degrees of
freedom:
f ¼ ∇uE ¼ CTKCu:
ð7Þ
In terms of the vector of tensions t ¼ Ke and
deﬁning the equilibrium matrix Q  CT this
becomes
f ¼ Qt:
ð8Þ
Note that the minus sign is not always present in the
literature as f can be deﬁned as the external force
that must be applied in equilibrium to overcome
internal forces. Just as the nullspace of the compat-
ibility matrix gives the compatible displacements,
the nullspace of the equilibrium matrix gives the
sets of tensions that result in no net force. Collec-
tively, the conﬁgurations without any tensions and
those in which tension forces are balanced are
known as equilibrium con gurations. A set of ten-
sions in the latter is known as a state of self stress.
The linear representation above gives for a
single vertex i:
fi ¼ 
X
a
tabra,
ð9Þ
where α is summed over all edges connected to
vertex i and bra is the unit vector along edge α
pointing away from this vertex.
Although Maxwell was not able to identify
redundant bonds systematically, this formulation
allowed
Calladine,
over
a
century
later
(Calladine
1978),
to
derive
a
relationship
between zero modes and states of self stress.
Let Ndof, Ncon, NZM, NSS refer, respectively, to
the numbers of degrees of freedom, constraints,
zero modes, and states of self stress. In linear
algebra, the rank of a matrix is deﬁned as dimen-
sion the space spanned by its columns. Deforma-
tion modes spanned by C’s columns are the
complement of modes in its nullspace and ten-
sions spanned by the columns of Q are the com-
plement of its nullspace. Hence,
rank C
ð Þ þ NZM ¼ Ndof,
ð10Þ
rank Q
ð Þ þ NSS ¼ Ncon:
ð11Þ
However, using the well-known linear-algebraic
result that column and row ranks are equal, Q ¼
CT implies rank(C) ¼ rank(Q), leading to the
Maxwell-Calladine index theorem:
NZM  NSS ¼ Ndof  Ncon:
ð12Þ
Thus, one may see that each additional constraint
either eliminates a zero mode or generates a state
216
Flexible Mechanical Structures and Their Topologically Protected Deformations

of self stress. Similarly, each additional degree of
freedom either generates a zero mode or elimi-
nates a state of self stress. Zero modes and self
stresses are subtly related to one another, compos-
ing the right and left nullspaces of a linear opera-
tor that connects two distinct vector spaces.
Although it is not in general possible to derive
one from the other, this result demonstrates that
the two are related. This is particularly evident in
Maxwell or mechanically critical systems, deﬁned
as those for which NZM ¼ NSS. In this case, zero
modes and states of self stress are equal to one
another in number (Fig. 2).
Periodic Structures
As is well-known in condensed matter physics,
systems with discrete periodic structure crystals
have signiﬁcantly different properties than either
isolated atoms or amorphous structures. This is
because, per Bloch’s theorem as discussed below,
the normal modes of the system become grouped
into smooth, analytically tractable bands. How-
ever, the consequences of periodicity are even
more profound in rigidity theory as periodic struc-
ture can not only group zero modes but, due to
redundancy, generate them.
Consequently, one may consider a system with
periodic structure, with a cell indexed by n ¼
n1, n2, . . . , nDc
ð
Þ. Note that the number of lattice
directions Dc may be less than the dimension of
the space, as in the case of chains and sheets (e.g.,
origami) that have only one or two discrete trans-
lational symmetries despite being embedded in
three dimensions. Thus, the spatial embedding of
one of the np particles per cell indexed by i is bi þ
njlj, where bi are the basis vectors, lj are the lattice
primitive vectors and the repeated indices imply
a sum.
The topology of the ncon bonds per unit cell
must then be generalized to pα ¼ (i, j, ni, nj),
where ni, nj describe the cell indices of the
particles relative to the bond. For example,
bond one could connect particle one to particle
2 within the same cell, but bond two might
connect particle two to particle one in the cell
to its right. In that case, one could either choose
to deﬁne this second bond to lie on the right-
hand side of the ﬁrst cell, p2 ¼ (2, 1, 0, 1) or the
left-hand side of the second cell, p2 ¼ (2, 1,
1, 0). So long as these choices are made
consistently they will remain valid and conse-
quently they can be thought of as a sort of gauge
choice. However, due to the discrete nature of
this gauge, it does not have a conventional con-
nection to a conserved current.
With this formulation one has an opportunity
to represent two types of mode more efﬁciently
in the periodic structure than in a general one.
The ﬁrst is Guest Hutchinson (GH) modes (Guest
and Hutchinson 2003). One wishes to explore
whether there is an inﬁnitesimal rigid mode that
consists of a uniform strain between cells
Flexible Mechanical Structures and Their Topologi-
cally Protected Deformations, Fig. 2 Here, one sees
two representations of a periodic structure consisting of red
particles at points b1 þ nl1 and blue particles at points b2 þ
nl1. One sees two separate choices of unit cells, as indicated
by the dashed boxes and darker colors. In both cases, the
same pair of particles is chosen for the main unit cell but in
the ﬁrst case the bond that has a blue particle to its left and the
red particle to its right is chosen to lie on the right of the unit
cell, whereas in the second case it is chosen to lie on the left
of the unit cell. Using the notation in the main text, in which
pα is a list of the basis indices and lattice indices of the two
particles connected via the bond, one has in either case p1 ¼
(1, 2, 0, 0) for the bond with the red particle on its left. For the
second bond, the two cases correspond, respectively, to p2 ¼
(2, 1, 0, 1), p2 ¼ (2, 1, 1, 0)
Flexible Mechanical Structures and Their Topologically Protected Deformations
217

coupled to identical rearrangements within those
cells. Such rearrangements can be described as
inﬁnitesimal shifts db
i , dl
k in the basis and lattice
vectors. The resulting extension of bond α as
indexed above is
ea ¼ brij 
db
j  db
i þ nkdl
k


:
ð13Þ
Note the resemblance between Eq. (13) and
Eq. (4). Consequently one may term the map
between changes to the crystal structure and
bond extensions the augmented compatibility
matrix. Repeating the Maxwell-Calladine logic
above, one ﬁnds then that there are a number of
linear deformations of the crystal at least equal to
the number of ways to deform it less the number
of constraints: D(np þ Dc) – ncon. However, these
include D uniform translations and D(D – 1)/2
rotations, the latter of which require simultaneous
rotation of both basis and lattice vectors. Thus,
one has Guest-Hutchinson type deformation
modes of number
nGM  D np þ Dc


 ncon
 D D þ 1
ð
Þ=2:
ð14Þ
Of particular importance is the case of periodic
Maxwell lattices, which one deﬁnes as those with
equal numbers of bulk constraints and degrees of
freedom, Dnp ¼ Ncon. In particular, for D ¼ Dc ¼
2 there are four quantities that determine the lat-
tice vectors (two components of two vectors) but
only two translations and one rotation. Hence, one
has a single Guest mode in 2D. In 3D, D ¼ Dc ¼ 3,
there are instead three such modes. Consequently,
Maxwell lattices do not have unique ground states
but instead have a continuum of rigid periodic
embeddings.
The simplest case is the two-dimensional sim-
ple square lattice, of Fig. 3a. This has one particle
with coordination number four, and hence two
bonds per cell. The lattice is thus deﬁned by six
numbers: the two components each of the basis
vector of the single particle and the two lattice
vectors. Even after satisfying the two constraints,
this leaves us with a four-dimensional space of
rigid periodic embeddings, only three dimensions
of which are satisﬁed by the rigid-body rotations
(two translations and a rotation) in three dimen-
sions. The remaining one-dimensional set of
states is given by the GH mode, a shearing of the
two bonds against one another.
The other commonly considered Maxwell lat-
tice, one with a nontrivial basis, is the kagome of
Fig. 3b. This consists of two rigid triangular
pieces joined by edges. Thinking of the basis as
three triangular vertices and the six constraints as
the requirements that the distances between verti-
ces on the same triangle must remain ﬁxed, one
sees that the Maxwell condition that ndof ¼ ncon is
met. Alternately, if one thinks of the basis as
consisting of the positions and orientations of the
two triangular pieces per cell, one again has six
degrees of freedom. In this picture, the six con-
straints are the three places where the triangles
touch remain in contact. Either way, the lattice
possesses threefold rotational symmetry which
would be broken by a shearing motion: hence,
the GH mode is purely dilational. For the
deformed kagome of Fig. 3c the counting argu-
ment holds but the symmetry is broken, so the GH
mode mixes shear and dilation in a way that varies
along the action of the mode. This is in contrast with
a system of corner-sharing quadrilaterals that neces-
sarily exists above the Maxwell point: there, the
fourfold symmetry of Fig. 3d does permit a
dilational mode, but when this symmetry is broken
the system is generically rigid, as in Fig. 3e.
These GH modes are the sole rigid modes of
Maxwell lattices that preserve their symmetry.
However, the Maxwell counting argument indi-
cates that in a ﬁnite system with open boundary
conditions (i.e., missing constraints at the edges)
there should emerge a number of zero modes
proportional to the boundary of the system. As
will be examined in the next section, this leads to a
broader class of modes that do not preserve
periodicity.
Spatially Varying Modes
The striking behavior of crystalline systems fol-
lows largely from Bloch’s theorem, which states
that in a periodic system governed by the
218
Flexible Mechanical Structures and Their Topologically Protected Deformations

Flexible Mechanical Structures and Their Topologi-
cally Protected Deformations, Fig. 3 (a) The simple
square lattice is a two-dimensional Maxwell lattice that
therefore
possesses
a
nonlinear
Guest-Hutchinson
(GH) mode that preserves the periodicity of its structure
without stretching either of the two bonds per cell. The
structure is deﬁned by a basis vector and two lattice vec-
tors, a six-dimensional space that can satisfy the two
constraints and undergo three transformations: two trans-
lations, a rotation and the Guest mode. (b) The regular
kagome lattice similarly exists at the Maxwell point and
possesses a GH mode; in this case the lattice’s threefold
rotational symmetry forbids shear and yields a purely
dilational mode. (c) However, an irregular kagome lattice
still possesses a GH mode, and the lack of symmetry
merely means that the mode mixes shear and dilation. In
contrast, corner-sharing quadrilaterals exist above the
Maxwell point and consequently while the symmetric
structure in (d) possesses a similar dilational mode, the
irregular structure in (e) is rigid
Flexible Mechanical Structures and Their Topologically Protected Deformations
219

Schrödinger equation the eigenstates of the fully
periodic system differ between cells only by a
phase factor. To develop this in the context of
rigid frames, a broader class of deformations will
be considered. Let u(n) describe the combined
vector of np D-dimensional displacement vectors
within cell n. Then, consider a mode of the gen-
eralized Bloch form
u n
ð Þ ¼
zn1
1 zn2
2 . . . znDc
Dc


u  znu:
ð15Þ
That is, if z1 ¼ r1eiy1 then the mode is scaled
by r1 in magnitude and its phase is shifted by θ1 as
one shifts by one cell in the ﬁrst lattice direction.
Here one adopts the common convention that only
the real part of the mode is physical, and u itself
can contain both a real and imaginary component.
Such a mode is then an eigenmode of the crystal
translation operator in the ith direction with eigen-
value zi.
In the standard Bloch argument, one would
choose zi to be phase factors and diagonalize the
matrix (in this case, the compatibility matrix) to
show that its eigenmodes, including zero modes,
would take this form. However, this argument is
complicated by the over-completeness of our basis.
For now, let us calculate the extension of bond α in
cell n with bond topology pα ¼ (i, j, ni, nj):
ea n
ð Þ ¼ brij  u jznþn j  uiznþni


ð16Þ
¼ znbrij  u jzn j  uizni


:
ð17Þ
rij ¼ n jl j þ b j  nili þ bi
ð
Þ
ð18Þ
We then ﬁnd that e(n) takes the form ezn with
e ¼ C z
ð Þu:
ð19Þ
This means that the compatibility matrix, and
hence the equilibrium matrix, are Laurent poly-
nomials in the complex variables zi. From the
form of Eq. (18) it is clear that generalized Bloch
modes then possess a great advantage over other
modes in satisfying the compatibility conditions.
Since the extensions in different cells are simply
rescaled, then a generalized Bloch mode that
obeys the constraints in one cell obeys them in
all cells. In contrast, a mode that could not be
represented as a linear combination of such
modes would face non-redundant constraints
across the whole periodic system and would not
be expected to satisfy them all. The one exception
is modes whose displacements grow linearly, as in
the Guest-Hutchinson modes above, since the rel-
ative displacements then are constant, which is the
special case z ¼ 1.
The nature of this quantity z determines the
spatial extent of a mode. Consider for simplicity
a one-dimensional system. If z ¼ eiθ, then the
mode varies periodically without growing or
shrinking on average-it is a bulk mode. If |z| < 1,
then the mode grows exponentially smaller
(in addition perhaps to oscillatory behavior) as
one moves rightward and consequently one
would label it a left edge mode, since it is expo-
nentially suppressed away from the left edge.
Similarly, |z| > 1 implies a right edge mode.
Since z could potentially lie anywhere within the
complex plane, one has then a two-dimensional
space of modes with the unit circle representing
bulk modes, the unit disk representing left-edge
modes and the rest of the plane the right edge
modes (this picture becomes more symmetrical
under stereographic projection, for which the
two edges become the two hemispheres of the
unit sphere). Thus, although bulk modes occupy
the majority of the one-dimensional system, they
are only a vanishing portion of the entire two-
dimensional space of possible modes. More pre-
cisely, one might refer to such modes as possible
edge modes, since it has not yet been speciﬁed
which of them satisfy which boundary condi-
tions – for example a zero mode would not gen-
erally
be
possible
under
ﬁxed
boundary
conditions, nor a state of self stress under free
boundary conditions. However, a rigid mode
must satisfy this bulk condition, so a particular
system’s actual rigid modes will be a subset of
those discussed here.
For reasons analogous to the above analysis,
one would expect states of self stress to take on
this same spatial variation pattern, with tensions
rescaling and varying by phase factors across the
cells. Repeating the above analysis then yields
220
Flexible Mechanical Structures and Their Topologically Protected Deformations

forces and tensions related via a linear relationship
of the form
f ¼ Q z
ð Þt:
ð20Þ
Here, however, a subtlety emerges. If a bond is
connected to a site in the positive ﬁrst lattice
direction, the displacement is rescaled relative to
the extension by z1. However, this means the site
is connected to a bond in the negative ﬁrst lattice
direction and consequently the tension is rescaled
by 1/z1 relative to the force. Thus, one now has:
Q z
ð Þ ¼ CT 1=z
ð
Þ:
ð21Þ
That is, where a factor of zi appears in the com-
patibility matrix, a factor of 1/zi appears in the
equilibrium matrix. Note that zi ¼ 0 is no more
permitted than zi ¼ 1, since either case would
imply that a lattice translation would yield a
diverging amplitude.
In a system that is not just periodic in the bulk
but
has
periodic
boundary
conditions,
the
reciprocal-space rigidity and equilibrium matrices
may be obtained by a discrete Fourier transform.
For example, if the system repeats after Ni cells in
the ith lattice direction, then the compatibility
matrix can be expressed entirely as connections
between displacement vectors at wavevectors of
the form zi ¼ exp.(ini/(2πNi) and extension vec-
tors at the corresponding wavevector.
However, as the above real-space analysis
shows, the result is much more general. Repeating
the linear-algebraic analysis now yields
nZM z
ð Þ  nSS 1=z
ð
Þ ¼ ndof  ncon:
ð22Þ
In particular, for a Maxwell lattice with ndof –
ncon ¼ 0 (the number of degrees of freedom per
unit cell is related to the number of particles via
ndof ¼ np D) one may say that for each zero mode
on the left edge (with |z1| < 1) there is exactly one
state of self stress on the right edge (with |z1| > 1).
Referring to these two families collectively as
force-balancing modes, it may be said that there
are equal numbers of force-balancing modes on
opposing sides of the lattice. This raises a question
as to whether either type of mode by itself must be
divided evenly between the two edges in this way.
This question is of fundamental importance to the
topic of topological rigid modes.
Topological Boundary Modes of Maxwell
Lattices
Consider a Maxwell lattice whose rigid modes are
then governed by a square matrix, C(z), where for
simplicity a single direction of crystal periodicity
is considered. If a rigid mode u exists at some
z such that C(z)u ¼ 0, it follows that d(z)  det
[C(z)] ¼ 0. Hence, the spatial extent of zero
modes may be found simply by ﬁnding the zeros
of the determinant function d(z). From Eq. (18) it
follows that this is a ﬁnite Laurent polynomial.
One may rescale this polynomial by some integer
power of z through the appropriate choice of
gauge (i.e., choosing whether one labels bonds
as appearing on the right- or left-hand side of the
crystal cell), as shown in Fig. 2. The minimal
gauge, in which the lowest power of z in the
polynomial is a constant, is chosen. In this
gauge, each bond that connects two adjacent
cells contributes a power of z (and a bond that
connects cells shifted relative to one another by n
contributes a power of zn). Recall that the Funda-
mental Theorem of Algebra states that the total
number of zeros of a polynomial in the complex
plane, counting multiplicity, is the degree of the
polynomial. Hence, the total number of zeros is
the number of intercell constraints weighted by
the difference in cell index between the particles at
the two ends of the bond. In the common case in
which intercell bonds connect only adjacent cells,
this is simply the number of intercell bonds per
cell, making sure not to count a bond twice
because it connects two cells.
While ample numerical methods exist to solve
for each of these modes, deep analytical insight
may be obtained by instead attempting to count
the total number of modes that lie on one edge.
The left edge is chosen, since |z| < 1 is compact.
The number on the right edge may be obtained
either by using the Fundamental Theorem of
Algebra or by using the transformation z $ 1/z
to exchange the two regions.
Flexible Mechanical Structures and Their Topologically Protected Deformations
221

First, note that d(z), as an analytic function, has
a phase that is well-deﬁned everywhere in the
plane up to multiples of 2π. Indeed, as one winds
around a single zero the phase winds by the degree
(multiplicity) of the zero, and the phase does not
wind at all in a region that contains no zeros (the
polynomials do not contain branch cuts and the
choice of gauge prevents poles). Consequently,
the number of times the phase increases by 2π
around a loop in the complex plane is simply the
number of zero modes contained by the loop
(counting multiplicity). In particular, if one
chooses a contour running counterclockwise
around the unit circle, one ﬁnds that the number
of zero modes on the left edge is
NL ¼ 1
2pi
ðp
p
dq@q log detC eiq


¼ 1
2pi
þ
dz@z log d zð Þ:
ð23Þ
Here the fact that the imaginary part of the loga-
rithm a complex number is its argument is used.
The ﬁnal integral is performed in the positive
(counterclockwise) direction around the unit cir-
cle in the complex plane.
The quantity NL is a topological number. Topo-
logical quantities are those that remain unchanged
under classes of deformations of the underlying
system. Perhaps most famously, the Gauss-
Bonnet theorem shows that the genus (number
of holes) of a closed two-dimensional surface
embedded in three dimensions can be obtained
from the integral of its Gaussian curvature over
that surface and hence this integral remains
unchanged under deformations that do not pierce
the surface. Other real-space topological quanti-
ties include knot invariants, the charges of liquid-
crystalline topological defects and the Burgers
vectors describing crystal topological defects.
However, as will be seen, Eq. (23) most closely
resembles the invariants of topological insulators
(Hasan and Kane 2010), electronic systems with
periodic structure whose bulk invariants protect
surface conducting states.
In the same way, Eq. (23) describes a mechan-
ical topological insulator. The zero modes can
“conduct” displacements by generating them at
zero energy. The invariant cannot be changed
without a zero passing from inside the unit disk
of mode space in the complex plane to outside it,
which necessarily implies that the zero modes
enter the bulk bands, breaking the bulk mechani-
cal insulator. Thus, the number of zero modes on a
surface is protected by the insulating character of
the bulk. This type of relationship between the
number of modes on a boundary and a bulk topo-
logical invariant is referred to as bulk-boundary
correspondence.
The winding number is in fact a special case of
a type of topological invariant known as a homo-
topy group. Topologically, the Brillouin Zone of
the bulk bands is equivalent to a circle, or the one-
sphere, S1, since the dimensionless wavevector
q is invariant under increases of 2π and points on
the one-sphere are similarly invariant under an
increase in phase of 2π. Similarly, the phase of
d(z) lies on S1. Consequently, the winding number
is the ﬁrst homotopy group of S1, π1(S1) ¼ ℤand
indeed the winding number can take on any inte-
ger value.
Topological Invariants in Higher Dimensions
Although the topological invariant is, as derived
in the previous section, a one-dimensional invari-
ant, it nevertheless has implications for structures
that are periodic in two or three spatial dimen-
sions. One may deﬁne the winding number in the
ith direction as
Ni
qi
f
g
ð
Þ ¼  i
2p
ðp
p
dqi@qi log detC eiq


:
ð24Þ
As before, this must comprise an integer
invariant. However, the rigidity matrix is a func-
tion of the entire wavevector, and consequently
the number of zero modes on the surface of the
system from which qi counts up from is in general
a function of the other components of the
wavevector, {q–i}.
In the deformed kagome lattices ﬁrst consid-
ered by Kane and Lubensky (2014), the winding
numbers are independent of these transverse
momenta. However, in other lattices, including
the deformed square lattice, these invariants do
222
Flexible Mechanical Structures and Their Topologically Protected Deformations

indeed vary at different wavevectors. As is
required of an integer topological invariant, they
shift abruptly by integer amounts. This implies the
existence of a zero mode at some real wavevector
within the Brillouin Zone, a Weyl point (Rocklin
et al. 2016). This Weyl point is itself topologically
protected, in that the winding of det C) is nonzero
around it. For a simple Weyl point, the bulk wind-
ing number shifts by one across it, and hence the
winding number around the Weyl point is 1.
Because the rigidity matrix is a polynomial of
eiq with real coefﬁcients, it follows that within the
Brillouin zone (though not for edge modes) det
C(q) ¼ [det C(q)]*. Thus, if there is a Weyl
point at q, such that the determinant vanishes
there, there is another Weyl point at –q with the
opposite winding number. Such winding numbers
are preserved under deformations of the lattice, so
individual Weyl points cannot spontaneously be
created or destroyed. However, they can be
removed when two with opposite charge come
into contact, as is the case at high symmetry points
where qi ¼ qi mod 2π. That is, at qi ¼ 0, π.
The topological invariant of Eq. (23) is a fun-
damentally one-dimensional quantity. It is per-
haps surprising, then, that it leads to directly
observable behavior in higher-dimensional sys-
tems. Nevertheless, the dependence on the trans-
verse
wavevector
highlights
that
in
higher
dimensions this is not a simple, global topological
invariant. This motivates us to ask whether such
invariants do exist. To address this, one must think
more carefully about the structure of degrees of
freedom and constraints, as they exist for linear
modes of periodic cells. A mode is deﬁned by the
complex zi which describe how it oscillates and
grows between cells, and by the complex ui that
describe its structure within the cell. More pre-
cisely, u can be treated as living in a complex
projective space (in which two complex vectors
are considered the same if they are the same up to
an overall scale and phase, u1 ¼ leifu2). Hence,
the space of all possible z-periodic modes is
2 ndof  1 þ Dc
ð
Þ,
ð25Þ
where the factor of two reﬂects the real and imag-
inary components of complex numbers. The term
ndof is for the mode’s internal cellular degrees of
freedom, Dc is for the complex wavevectors that
describe how the mode varies between cells and
the 1 is because modes are equivalent under
complex projection. Each additional complex
constraint imposes two algebraic equations that a
zero mode must satisfy. Suppose also that rather
than varying exactly one zi and holding the others
ﬁxed as done previously, let us allow n  Dc of the
zi to vary. Therefore, isolated zero modes such as
the ones thus far considered would require a bal-
ance between the allowed space of the modes and
the number of constraints we impose:
ndof þ n  1 ¼ ncon:
ð26Þ
This is a generalization of the Maxwell condition,
ndof ¼ ncon, that permits topological modes a sys-
tem’s surface. Consider in particular the case n ¼ 2,
with one additional constraint per unit cell above
the Maxwell point. In this case, we would expect
zero modes to appear only at particular values of z1,
z2 which will, in general, not have unit magnitude.
Thus, such modes will grow as one moves toward a
particular corner, and are corner modes. In a new
scheme of higher-order topological polarization,
nth-order modes are those that occur on surface
elements n dimensions smaller than the bulk. Con-
ventional edge modes are ﬁrst-order, appearing on
the 0D end of a 1D chain, the 1D edge of a 2D
system, or the 2D surface of a 3D system. Second-
order modes appear at the corners of 2D systems
and the 1D hinges of 3D systems. Since n  Dc,
third-order polarization can appear only in the cor-
ners of 3D systems.
Considering the possibility of such modes, we
must consider whether the bulk-boundary corre-
spondence of Eq. (23) extends to such non-
Maxwell systems. As demonstrated in Saremi and
Rocklin (2018), this principle does extend concep-
tually, but the lack of a square matrix, which can be
reduced essentially to a scalar by taking its deter-
minant, complicates the mathematics considerably.
As before, one can consider the space of all
possible modes corresponding to a particular cor-
ner, for example those with |z1| < 1, |z2| < 1 and in
particular the boundary of this space, where either
|z1| ¼ 1, |z2| < 1 or |z2| < 1, |z2| – 1. That is, the
Flexible Mechanical Structures and Their Topologically Protected Deformations
223

boundary of the space of corner modes is the space
of modes on the adjacent edges. One can map from
modes in this space to the space of constraints,
which is guaranteed via Eq. (26) to be of the
same dimension. In this case, with complex-
analytic expressions, the number of times this
map covers the space [the generalization of the
winding number of the winding number of
Eq. (23)] is the number of corner modes.
This notion of higher-order topological invari-
ants associated with rigidity matrices has been
enumerated by Roychowdhury and Lawler, who
classify topological invariants based on three
symmetry classes, the dimension of the homotopy
group and the amount by which the number of
constraints differs from the degrees of freedom
(Roychowdhury and Lawler 2018). In addition
to the integer topological invariants discussed
above, these include things such as Z2 (binary)
invariants. Additional topologically protected
modes consistent with this scheme were recently
identiﬁed at the interface between systems of
over-constrained periodic chains with a certain
symmetry (Kedia et al. 2021).
Alternate Formulations
The condition for linear zero modes Eq. (4) suf-
ﬁces to describe both ﬁnite-energy and rigid
deformations. However, it is not the only way of
characterizing a rigid deformation. Consider, in
particular, the rigid deformations of a two-
dimensional planar graph such as the kagome
lattice. Such deformations translate and rotate
bonds without stretching them. Consequently,
we may characterize such a mode by the inﬁnites-
imal angle it rotates each bond. Such rotations
automatically ensure bonds do not stretch, but
they introduce an additional closure requirement,
that any closed loop around bonds remains closed.
This is a discrete version of mechanical compat-
ibility, the requirement that a deformation or strain
tensor correspond to a valid spatial embedding.
The condition here is
X
i
riyi ¼ 0,
ð27Þ
where the sum is over all edges in a closed loop.
Here, ri denotes the vector pointing from one end
to the other of a bond and θi the inﬁnitesimal
rotation of the bond. For a planar graph, if this
condition is met on every irreducible loop around
an open pore, it is also met on every loop com-
posed therefrom. More properly, this sum should
involve vectors perpendicular to the original bond
vectors, but a common 90 degree rotation can be
applied to place the expression in terms of the
original vectors. Notably, Eq. (27) bears a close
resemblance to the condition on a state of self
stress, Eq. (9).
Such formulations are not necessarily superior
to the conventional language of displacements,
but they do offer certain advantages. Consider,
for example, the deformed kagome lattice, which
would normally require a 6  6 rigidity matrix to
represent the displacements in two dimensions of
the three particles and the constraints of the six
bonds. In contrast, this formulation needs only
describe the two orientational degrees of freedom
of the two triangular pieces and the two-
dimensional closure condition around the hexag-
onal pore, with the four additional degrees of
freedom becoming trivial because the two trian-
gular pieces are rigid. This formulation can be
used to demonstrate that the deformed kagome
cannot possess Weyl points, unlike another Max-
well lattice, the deformed square. Moreover, this
notion of an alternate formulation for rigid defor-
mations has greater bearing on the origami that we
next consider.
Origami
A case of particular interest is triangulated ori-
gami, which consists of rigid triangular faces allo-
wed to rotate freely along creases. A rigid
embedding can then be described via a set of
vertex positions that do not stretch any faces.
However, a triangular face remains unstretched
if and only if its edges remain unstretched
(in contrast, a quadrilateral face could bend
along a diagonal without stretching any of its
edges). Thus, the rigid modes of origami corre-
spond precisely to those of a system of particles at
each of its vertices and bonds along each of its
edges. Naively, one would then expect that topo-
logical polarization may occur. Indeed, triangu-
lated periodic origami is particularly well-suited
224
Flexible Mechanical Structures and Their Topologically Protected Deformations

to this as it is automatically mechanically critical.
This can be seen via Euler’s formula for the poly-
hedron, in which the numbers of vertices, faces,
and edges are related via
V þ F  E ¼ w:
ð28Þ
In the periodic triangulated case, each face has
three edges but each edge appears along two
faces, so to avoid double-counting we have E ¼
(3/2)F. Since the Euler characteristic w vanishes
on a torus, including the ﬂat torus to which peri-
odic boundary conditions correspond, this implies
that
E ¼ 3V
ð29Þ
for any triangulated surface. Thus, since each
vertex can displace in three dimensions, we see
that mechanical criticality is assured.
However, when such surfaces were generated,
it was found exhaustively that their topological
polarization vanished (Chen et al. 2016). This can
be explained by considering a feature that makes
such
triangulations
special
and
non-generic
among all such frames. For such a surface, one
may describe the change in shape of the system as
a series of changes to the angles along edges
between adjacent faces (the dihedral angles).
One may not choose these arbitrarily, but only so
that the total change in orientation around each
vertex vanishes. In general, this change in orien-
tation would be described via an element of SO
(3), as described by belcastro and Hull (Hull et al.
2002). For inﬁnitesimal linear changes, however,
the condition simpliﬁes to
0 ¼
X
a
fabra,
ð30Þ
where the α index labels edges emanating from a
single vertex along directions bra and fα describes
the change in the dihedral angle along each edge.
This condition, which must be satisﬁed at every
vertex, has the precise form of a state of self stress
in Eq. (9). Consequently, the (normalized) ten-
sions in a state of self stress are exactly the angle
changes of a zero mode (Mclnerney et al. 2020).
Unlike in the general case, in origami the states of
self stress and zero modes really do map onto one
another. Note that previously we had mechanical
criticality because E ¼ 3 Vand each edge had one
constraint and each vertex had three degrees of
freedom. Now we still have criticality in this pic-
ture because each edge has one degree of freedom
and each vertex has three constraints.
This duality between zero modes and states of
self stress has important consequences for the
topological character of origami zero modes. In
general, in a Maxwell lattice a zero mode at a
given complex wavevector implies a state of self
stress at the opposite wavevector and vice versa,
via Eq. (21). Now, however, this vertex duality
means that a state of self stress at a wavevector
implies a zero mode at the same wavevector.
Thus, where for a general frame it was possible
to have, for example, two zero modes on the left
edge and two states of self stress on the right, in
origami it is only possible to have equal numbers
of zero modes on the left and right edges.
This feature has additional impact on the ori-
gami system. In particular, Weyl points emerged
generically as zero-dimensional points in 2D
Brillouin Zones of Maxwell lattices. This is
because these correspond to places in which the
determinant of the rigidity matrix vanishes. The
real part of this matrix should vanish on a 1D
subset of the 2D Brillouin Zone and the imaginary
part should vanish on another 1D subset, such that
the intersections are generically 0D Weyl points.
In the origami case, however, the fact that a zero
mode existing at some complex z comes paired
with another at 1z implies that the determinant
function d(z) is proportional to a “palindromic”
polynomial in z such that the real coefﬁcients of
opposite powers of z are equal. This means that,
up to a trivial gauge-dependent phase factor, the
determinant function is real. This means that the
requirement that its imaginary part vanishes
becomes trivial and generically zero modes
appear on 1D lines in the 2D Brillouin Zone.
Further, there is a new Z2 topological invariant,
the sign of the determinant of the rigidity matrix,
which ﬂips value on either side of this line of zero
modes. This behavior, which falls within the clas-
siﬁcation scheme of (Roychowdhury and Lawler
Flexible Mechanical Structures and Their Topologically Protected Deformations
225

2018), has been predicted in both real origami
(Mclnerney et al. 2020) and in the low-energy
excitations of 2D frustrated magnetic systems
that can be mapped onto origami (Roychowdhury
et al. 2018).
Continuum Systems
Rigidity theory is naturally granular, or atomic, in
the sense of having discrete vertices and edges.
However, despite the atomic nature of elemental
and molecular matter, over longer length scales
this gives rise to continuum behavior as systems
undergo deformations described not by sets of
displacements but by displacement ﬁelds u(r).
Linear elasticity is a well-developed theory
which maps strain tensors, symmetrized gradients
of displacements, onto stress tensors, whose
divergences yield body forces. In this, then, con-
ventional elasticity resembles a map between dis-
placements and forces, a dynamical matrix, which
due to mechanical reciprocity cannot display
topological polarization. This raises the question
of how such polarization can manifest itself in the
continuum limit, in which the Brillouin zone and
hence the notion of a compact region of state
space seems to recede.
This challenge was addressed in two works in
2020 (Saremi and Rocklin 2020; Sun and Mao
2020). Here, the approach taken by Saremi and
Rocklin is sketched. There, one begins with the
linear rigidity map between extensions and dis-
placements in a periodic cell Eq. (19). Treating
the cell index as a continuous position vector
allows one to express the extensions at a point in
terms of continuous displacement ﬁelds. Due to
intercellular bonds, these extensions are affected
by gradients of the ﬁelds. In this way, one obtains a
differential operator between the displacements of
the microscopic degrees of freedom and the micro-
scopic constraints.
In order to make connection with elasticity, one
considers smooth displacement ﬁelds applied
equally to each microscopic particle. This gener-
ally leads to extensions of bonds and unbalanced
forces acting on each particle. However, follow-
ing microscopic rearrangements in order to
alleviate these forces, the only extensions that
remain are those that lie in the space of states of
self stress. In a Maxwell system, the number of
such self stresses is equal to the dimension of the
embedding space. Consequently, the resulting
reduced, continuum rigidity map is square, so
that microscopic criticality maps onto macro-
scopic criticality.
This map shares a number of features with its
discrete
analog.
Most
notably,
there
is
a
corresponding equilibrium map that maps from
continuous states of self stress onto force ﬁelds.
These two maps are in a certain sense transposes
of one another evaluated at opposite wavevectors,
just as in the microscopic case.
However, while the principle of topological
polarization does indeed carry over to the contin-
uum, it is also transformed. Modes on the left and
right edges can no longer be expressed as the
interior and exterior of the unit circle in the 2D
plane.
Now,
these
modes
are
most
easily
expressed as the upper and lower half-planes,
neither of which is compact, limiting the applica-
tion of the argument principle. However, by tak-
ing the continuum limit carefully, one can
demonstrate that a similar topological invariant
emerges that yields not the number of modes on
the left or right edges but rather the difference
between the two. That is,
NL  NR ¼ 1
p
ð
dqi @qi argdet C
ð Þ,
ð31Þ
where the regularization scheme required to per-
form the integral in the continuum is described in
Saremi and Rocklin (2020). This result, based in
the continuum rather than in periodic microstruc-
tures, closely resembles, yet conceptually mod-
iﬁes that of Kane and Lubensky (2014). This
raises the question of how generally the principle
that asymmetrical structures may serve to direct
ﬂexibility may be extended.
Conclusion
In recent years, tight connections have been
drawn between the static modes (zero modes and
226
Flexible Mechanical Structures and Their Topologically Protected Deformations

states of self stress) of mechanical frames and
topological states. This connection has been used
to create, direct, and protect novel modes.
A fundamental advance came in Kane and
Lubensky’s 2014 result for periodic Maxwell
(critically coordinated) lattices. Many subsequent
results have come for systems with additional
geometric
complexity,
including
topological
defects (Paulose et al. 2015), nonlinearities
(Chen et al. 2014), imbalances between con-
straints and degrees of freedom (Saremi and
Rocklin 2018; Roychowdhury and Lawler 2018;
Kedia et al. 2021), continuous degrees of freedom
(Saremi and Rocklin 2020; Sun and Mao 2020;
Bartolo and Carpentier 2019), and surfaces and
non-mechanical constraints (Roychowdhury et al.
2018;
Murugan
and
Vaikuntanathan
2017).
Developments have also come from protected
bulk modes (Rocklin et al. 2016; Stenull et al.
2016) and mechanical response (Rocklin 2017).
Future advances may come by exploring addi-
tional geometries of mechanical systems. Dynam-
ical topologically protected modes have already
been
demonstrated
in
amorphous
systems
(Mitchell et al. 2018) via real-space techniques –
might the static modes of such structures also
display topological classes?
Despite the extensive work on topological
mechanics of dynamical modes (Süsstrunk and
Huber 2016), the connection to static modes
remains to be developed. Dynamic topological
mechanics is further enriched by the possibility
of thermal (Rocklin et al. 2018) and quantum
ﬂuctuations (Mizoguchi et al. 2021) and perhaps
by the incorporation of active matter (Shankar
et al. 2020).
In summary, recent years have revealed that
beyond the topological dynamical modes lie topo-
logical zero modes and state of self stress that
determine a system’s low-frequency mechanical
response. New topological invariants lead to
novel and robust forms of ﬂexibility, centered
around proximity to a mechanical critical point.
This behavior has been demonstrated in increas-
ingly complex structures, with the promise of
further discoveries lying in systems with aperio-
dicity, nonlinearity, ﬂuctuations, and other com-
plex, challenging features that lie beyond the
Brillouin Zone.
Bibliography
Bartolo D, Carpentier D (2019) Phys Rev 9:041058
Calladine CR (1978) Int J Solids Struct 14:161
Chen BG-G, Upadhyaya N, Vitelli V (2014) Proc Natl
Acad Sci 111:13004
Chen BG-G, Liu B, Evans AA, Paulose J, Cohen I,
Vitelli V, Santangelo C (2016) Phys Rev Lett
116:135501
Guest S, Hutchinson J (2003) J Mech Phys Solids 51:383
Hasan MZ, Kane CL (2010) Rev Mod Phys 82:3045
Hull TC et al (2002) Linear Algebra Appl 348:273
Kane C, Lubensky T (2014) Nat Phys 10:39
Kedia H, Souslov A, Rocklin DZ (2021) Phys Rev B 103:
L060104
Maxwell JC (1864) Lond Edinb Dublin Philos Mag J Sci
27:294
Mclnerney J, Chen BG-G, Theran L, Santangelo CD,
Rocklin DZ (2020) Proc Natl Acad Sci 117:30252
Mitchell NP, Nash LM, Hexner D, Turner AM, Irvine WT
(2018) Nat Phys 14:380
Mizoguchi T, Yoshida T, Hatsugai Y (2021) Phys Rev
B 103:045136
Murugan A, Vaikuntanathan S (2017) Nat Commun 8:1
Paulose J, Chen BG-G, Vitelli V (2015) Nat Phys 11:153
Rocklin DZ (2017) New J Phys 19:065004
Rocklin DZ, Chen BG-G, Falk M, Vitelli V, Lubensky
T (2016) Phys Rev Lett 116:135503
Rocklin D, Vitelli V, Mao X (2018) arXiv preprint
arXiv:1802.02704
Roychowdhury
K,
Lawler
MJ
(2018)
Phys
Rev
B 98:094432
Roychowdhury K, Rocklin DZ, Lawler MJ (2018) Phys
Rev Lett 121:177201
Saremi A, Rocklin Z (2018) Phys Rev B 98:180102
Saremi A, Rocklin Z (2020) Phys Rev 10:011052
Shankar S, Souslov A, Bowick MJ, Marchetti MC, Vitelli
V (2020) arXiv preprint arXiv:2010.00364
Stenull O, Kane C, Lubensky T (2016) Phys Rev Lett
117:068001
Sun K, Mao X (2020) Phys Rev Lett 124:207601
Süsstrunk R, Huber SD (2016) Proc Natl Acad Sci 113:
E4767
Flexible Mechanical Structures and Their Topologically Protected Deformations
227

Glasses and Aging, A
Statistical Mechanics
Perspective on
Francesco Arceri1, François P. Landes2,
Ludovic Berthier3,4 and Giulio Biroli5
1Department of Physics, University of Oregon,
Eugene, OR, USA
2TAU, LRI, Université Paris Sud, CNRS, INRIA,
Université Paris Saclay, Orsay, France
3Laboratoire Charles Coulomb (L2C), Université
de Montpellier, CNRS, Montpellier, France
4Department of Chemistry, University of
Cambridge, Cambridge, UK
5Laboratoire de Physique de l’École normale
supérieure, Université PSL, CNRS, Sorbonne
Université, Université Paris-Diderot, Paris,
France
Article Outline
Glossary
Deﬁnition of the Subject
Phenomenology
Taxonomy of “Glasses” in Science
Numerical Simulations
Dynamic Heterogeneity
Theory of the Glass Transition
Mean-Field Theory of the Amorphous Phase
New Computational Methods
Aging and Off-Equilibrium Dynamics
Future Directions
Bibliography
Glossary
We start with a few concise deﬁnitions of the most
important concepts discussed in this entry.
Glass transition For molecular liquids, the glass
transition denotes a crossover from a viscous
liquid to an amorphous solid. Experimentally,
the crossover takes place at the glass tempera-
ture, Tg, conventionally deﬁned as the temper-
ature where the liquid’s viscosity reaches the
arbitrary value of 1012 Pa.s. The glass transi-
tion more generally applies to many different
condensed matter systems where a crossover
or, less frequently, a true phase transition takes
place between an ergodic phase and a frozen,
amorphous glassy phase.
Aging In the glass phase, disordered materials
are characterized by relaxation times that
exceed common observation timescales, so
that a material quenched in its glass phase
never reaches equilibrium (neither a metastable
equilibrium). It exhibits instead an aging
behavior during which its physical properties
keep evolving with time.
Dynamic heterogeneity Relaxation spectra of
dynamical
observables,
for
example,
the
dynamical structure factor, are very broad in
supercooled liquids. This is associated to a
spatial distribution of timescales: at any given
time, different regions in the liquid relax at
different rates. Since the supercooled liquid is
ergodic, slow regions eventually become fast,
and vice versa. Dynamic heterogeneity refers
to the existence of these nontrivial spatiotem-
poral ﬂuctuations in the local dynamical
behavior, a phenomenon observed in virtually
all disordered systems with slow dynamics.
Effective temperature An aging material relaxes
very slowly, trying (in vain) to reach its equilib-
rium state. During this process, the system
probes states that do not correspond to thermo-
dynamic equilibrium, so that its thermodynamic
properties cannot be rigorously deﬁned. Any
practical
measurement
of
its
temperature
becomes
a
frequency-dependent
operation.
A “slow” thermometer tuned to the relaxation
timescale of the aging system measures an effec-
tive temperature corresponding to the ratio
between spontaneous ﬂuctuations (correlation)
and
linear
response
(susceptibility).
This
© Springer Science+Business Media, LLC, part of Springer Nature 2022
B. Chakraborty (ed.), Statistical and Nonlinear Physics,
https://doi.org/10.1007/978-1-0716-1454-9_248
Originally published in
R. A. Meyers (ed.), Encyclopedia of Complexity and Systems Science, © Springer Science+Business Media LLC 2021
https://doi.org/10.1007/978-3-642-27737-5_248-2
229

corresponds to a generalized form of the
ﬂuctuation-dissipation
theorem
for
off-
equilibrium materials.
Frustration Impossibility
of
simultaneously
minimizing all the interaction terms in the
energy function of the system. Frustration
might arise from quenched disorder (as in the
spin glass models), from competing interac-
tions (as in geometrically frustrated magnets),
or from competition between a “locally pre-
ferred order,” and global, for example, geomet-
ric, constraints (as in hard spheres packing
problems).
Marginal Stability Systems are marginally sta-
ble when the number of external inputs con-
trolling their stability is just enough to
constrain all their degrees of freedom (think
of a table with three legs). Marginally stable
systems display an excess of zero-energy
modes which makes them highly susceptible
to external perturbations, and prone to exten-
sive rearrangements.
Definition of the Subject
Glasses belong to a seemingly well-known state
of matter: we easily design glasses with desired
mechanical or optical properties on an industrial
scale, and they are widely present in our daily life.
Yet, a deep microscopic understanding of the
glassy state of matter remains a challenge for
condensed
matter
physicists
(Angell
1995;
Debenedetti and Stillinger 2001; Berthier and
Biroli 2011). Glasses share similarities with crys-
talline solids (they are both mechanically rigid),
but also with liquids (they both have similar dis-
ordered structures at the molecular level). It is
mainly this mixed character that makes them fas-
cinating objects, even to nonscientists.
A glass can be obtained by cooling the temper-
ature of a liquid below its glass temperature, Tg.
The quench must be fast enough, such that the
more standard ﬁrst-order phase transition toward
the crystalline phase is avoided. The glass “tran-
sition” is not a thermodynamic transition at all,
since Tg is only empirically deﬁned as the temper-
ature below which the material has become too
viscous to ﬂow on a “reasonable” timescale (and it
is hard to deﬁne the word “reasonable” in any
reasonable manner). Therefore, Tg cannot play a
very fundamental role, as a phase transition tem-
perature would. It is simply the temperature below
which the material looks solid on the timescale of
the observer. When quenched in the glass phase
below Tg, liquids slowly evolve toward an equi-
librium state they will never reach on experimen-
tal timescales. Physical properties are then found
to evolve slowly with time in far from equilibrium
states, a process known as “aging” (Struik 1977).
Describing
theoretically
and
quantifying
experimentally the physical mechanisms respon-
sible
for
the
viscosity
increase
of
liquids
approaching the glass transition and for aging
phenomena below the glass transition certainly
stand as central open challenges in condensed
matter physics. Since statistical mechanics aims
at understanding the collective behavior of large
assemblies of interacting objects, it comes as no
surprise that it is a central tool in the glass ﬁeld.
We shall therefore summarize the understanding
gained from statistical mechanics perspectives
into the problem of glasses and aging.
The subject has quite broad implications.
A material is said to be “glassy” when its typical
relaxation timescale becomes of the order of, and
often much larger than, the typical duration of an
experiment or a numerical simulation. Under this
generic deﬁnition, a large number of systems can
be considered as glassy (Young 1998). One can be
interested in the physics of liquids (window glasses
are then the archetype), in “hard” condensed matter
(for instance type II superconductors in the pres-
ence of disorder such as high-Tc superconductors),
charge density waves or spin glasses, “soft” con-
densed matter with numerous complex ﬂuids such
as colloidal assemblies, emulsions, foams, but also
granular materials, proteins, etc. All these materials
exhibit, in a part of their phase diagrams, some sort
of glassy dynamics characterized by a very rich
phenomenology with effects such as aging, hyster-
esis, creep, memory, effective temperatures, reju-
venation, dynamic heterogeneity, and nonlinear
response.
This long list explains why this research ﬁeld
has received increasing attention from physicists
230
Glasses and Aging, A Statistical Mechanics Perspective on

in the last four decades. “Glassy” topics now go
much beyond the physics of simple liquids (glass
transition physics), and models and concepts
developed for one system often ﬁnd applications
elsewhere in physics, from algorithmics to bio-
physics (Bouchaud et al. 2011). Motivations to
study glassy materials are numerous. Glassy
materials are everywhere around us and therefore
obviously
attract
interest
beyond
academic
research. At the same time, the glass conundrum
provides theoretical physicists with deep funda-
mental questions since classical tools are some-
times not sufﬁcient to properly account for the
glass state. Moreover, numerically simulating the
dynamics of microscopically realistic material on
timescales
that
are
experimentally
relevant
remains a difﬁcult challenge, even with modern
computers.
Studies on glassy materials constitute an excit-
ing research area where experiments, simulations,
and theoretical calculations can meet, and where
both applied and fundamental problems are con-
sidered. How can one observe, understand, and
theoretically describe the rich phenomenology of
glassy materials? What are the fundamental quan-
tities and concepts that emerge from these
descriptions?
The outline of the entry is as follows. In section
“Phenomenology” the phenomenology of glass-
forming liquids is discussed. In section “Taxon-
omy of “Glasses” in Science” different types of
glasses are described. We then describe how com-
puter simulations can provide deep insights into
the glass problem in section “Numerical Simula-
tions.” The issue of dynamic heterogeneity is
tackled in section “Dynamic Heterogeneity.” The
main theoretical perspectives currently available
in the ﬁeld are then summarized in section “The-
ory of the Glass Transition.” The mean-ﬁeld anal-
ysis of the amorphous solid phase is reviewed in
section “Mean-Field Theory of the Amorphous
Phase.”
In
section
“New
Computational
Methods,” we discuss novel developments in
computational studies. Aging and off-equilibrium
phenomena occupy section “Aging and Off-
Equilibrium
Dynamics.”
Finally,
issues
that
seem important for future research are discussed
in section “Future Directions.”
Phenomenology
Basic Facts
A vast majority of liquids (molecular liquids,
polymeric liquids, etc.) form a glass if cooled
fast enough in order to avoid the crystallization
transition (Angell
1995). Typical
values of
cooling
rate
in
laboratory
experiments
are
0.1–100 K/min. The metastable phase reached in
this way is called “supercooled liquid.” In this
regime the typical timescales increase in a dra-
matic way and they end up to be many orders of
magnitudes larger than microscopic timescales at
Tg, the glass transition temperature.
For example, around the melting temperature
Tm, the typical timescale Tα on which density ﬂuc-
tuations relax is of the order of
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
ma2=KBT
p
, which
corresponds to few picoseconds (m is the molecular
mass, T the temperature, Kb the Boltzmann con-
stant, and a is a typical distance between mole-
cules). At Tg, which as a rule of thumb is about
2
3 Tm, this timescale tα has become of the order of
100 s, that is, 14 orders of magnitude larger! This
phenomenon is accompanied by a concomitant
increase of the shear viscosity . This can be under-
stood by a simple Maxwell model in which  and t
are related by  ¼ G1tα, where G1 is the instan-
taneous (elastic) shear modulus which does not
vary considerably in the supercooled regime. In
fact, viscosities at the glass transition temperature
are of the order of 1012 Pa.s. In order to grasp how
viscous this is, recall that the typical viscosity of
water (or wine) at ambient temperature is of the
order of 102 Pa.s. How long would one have to
wait to drink a glass of wine with a viscosity 1014
times larger?
As a matter of fact, the temperature at which
the liquid does not ﬂow anymore and becomes an
amorphous solid, called a “glass,” is protocol
dependent. It depends on the cooling rate and on
the patience of the person carrying out the exper-
iment: solidity is a timescale-dependent notion.
Pragmatically, Tg is deﬁned as the temperature at
which the shear viscosity is equal to 1013 Poise
(also 1012 Pa.s).
The increase of the relaxation timescale of
supercooled liquids is
remarkable not only
because of the large number of decades involved
Glasses and Aging, A Statistical Mechanics Perspective on
231

but also because of its temperature dependence.
This is vividly demonstrated by plotting the loga-
rithm of the viscosity (or of the relaxation time) as
a function of Tg/T, as in Fig. 1. This is called the
“Angell” plot (Angell 1995), which is very help-
ful in classifying supercooled liquids. A liquid is
called strong or fragile depending on its position
in the Angell plot. Straight lines correspond to
“strong” glass-formers and to an Arrhenius
behavior. In this case, one can extract from the
plot an effective activation energy, suggesting
quite a simple mechanism for relaxation, for
instance by “breaking” locally a chemical bond.
The typical relaxation time is then dominated by
the energy barrier to activate this process and,
hence, has an Arrhenius behavior. Window
glasses fall in this category. (The terminology
“strong” and “fragile” is not related to the
mechanical properties of the glass but to the evo-
lution of the short-range order close to Tg. Strong
liquids, such as SiO2, have a locally tetrahedric
structure which persists both below and above the
glass transition contrary to fragile liquids whose
short-range amorphous structure disappears rap-
idly upon heating above Tg.) If one tries to deﬁne
an effective activation energy for fragile glass-
formers using the slope of the curve in Fig. 1,
then one ﬁnds that this energy scale increases
when
the
temperature
decreases,
a
“super-
Arrhenius” behavior. This increase of energy bar-
riers immediately suggests that glass formation is
a collective phenomenon for fragile supercooled
liquids. Support for this interpretation is provided
by the fact that a good ﬁt of the relaxation time or
the viscosity is given by the Vogel-Fulcher-
Tamman law (VFT):
ta ¼ t0 exp
DT 0
T  T0
ð
Þ


,
ð1Þ
which suggests a divergence of the relaxation
time, and therefore a phase transition of some
kind, at a ﬁnite temperature T0. A smaller D in
the VFT law corresponds to a more fragile glass.
Note that there are other comparably good ﬁts of
these curves, such as the Bässler law (Bässler
1987),
ta ¼ t0 exp
K T
T

2


,
ð2Þ
that only lead to a divergence at zero temperature.
Actually, although the relaxation time increases
by 14 orders of magnitude, the increase of its
logarithm, and therefore of the effective activation
energy is very modest, and experimental data do
not allow one to unambiguously determine the
true underlying functional law without any rea-
sonable doubt. For this and other reasons, physi-
cal interpretations in terms of a ﬁnite temperature
phase transition must always be taken with a grain
of salt.
However, there are other experimental facts
that shed some light and reinforce this interpreta-
tion. Among them is an empirical connection
found between kinetic and thermodynamic behav-
iors. Consider the part of the entropy of liquids,
Sexc, which is in excess compared to the entropy of
the corresponding crystal. Once this quantity, nor-
malized by its value at the melting temperature, is
Glasses and Aging, A Statistical Mechanics Perspec-
tive on, Fig. 1 Arrhenius plot of the viscosity of several
glass-forming liquids approaching the glass temperature Tg
(Debenedetti and Stillinger 2001). For “strong” glasses, the
viscosity increases in an Arrhenius manner as temperature
is decreased, log  ~ E/(KBT), where E is an activation
energy and the plot is a straight line, as for silica. For
“fragile” liquids, the plot is bent and the effective activation
energy increases when T is decreased toward Tg, as for
ortho-terphenyl
232
Glasses and Aging, A Statistical Mechanics Perspective on

plotted as a function of T, a remarkable connection
with the dynamics emerges. As for the relaxation
time one cannot follow this curve below Tg in
thermal equilibrium. However, extrapolating the
curve below Tg apparently indicates that the
excess entropy vanishes at some ﬁnite tempera-
ture, called TK, which is very close to zero for
strong glasses and, generically, very close to T0,
the temperature at which a VFT ﬁt diverges. This
coincidence is quite remarkable: for materials
with glass transition temperatures that vary from
50 K to 1000 K the ratio TK/T0 remains close to 1,
up to a few percent. Examples reported in Richert
and Angell (1998) are provided in Table 1.
The chosen subscript for TK stands for
Kauzmann (1948), who recognized TK as an
important
temperature
scale
for
glasses.
Kauzmann further claimed that some change of
behavior (phase transition, crystal nucleation,
etc.) must take place above TK, because below
TK the entropy of the liquid, a disordered state of
matter, becomes less than the entropy of the crys-
tal, an ordered state of matter. The situation that
seemed paradoxical at that time is actually not a
serious conceptual problem (Berthier and Biroli
2011; Berthier et al. 2019a). There is no general
principle that constrains the entropy of the liquid
to be larger than that of the crystal. As a matter of
fact, the crystallization transition for hard spheres
takes place precisely because the crystal becomes
the state with the largest entropy at sufﬁciently
high density (Hołyst 2001).
On the other hand, the importance of TK stands,
partially because it is experimentally very close to
T0. Additionally, the quantity Sexc which vanishes
at TK is thought to be a proxy for the so-called
conﬁgurational entropy, Sc, which quantiﬁes the
number of metastable states. A popular physical
picture due to Goldstein (1969) is that close to Tg
the system explores a part of the energy landscape
(or conﬁguration space) which is full of minima
separated by barriers that increase when tempera-
ture decreases. The dynamic evolution in the
energy landscape would then consist in a rather
short equilibration inside a minimum followed by
infrequent “jumps” between different minima. At
Tg the barriers between states become so large that
the system remains trapped in one minimum,
identiﬁed as one of the possible microscopic
amorphous conﬁgurations of a glass. Following
this interpretation, one can split the entropy into
two parts. A ﬁrst contribution is due to the fast
relaxation inside one minimum and a second one,
called the “conﬁgurational” entropy, counts the
number of metastable states: Sc ¼ log Nmetastable.
Assuming that the contribution to the entropy due
to the “vibrations” around an amorphous glass
conﬁguration is not very different from the
entropy of the crystal, one ﬁnds that Sexc ≈Sc. In
that case, TK would correspond to a temperature at
which the conﬁgurational entropy vanishes. This
in turn would lead to a discontinuity (a downward
jump) of the speciﬁc heat and would truly corre-
spond to a thermodynamic phase transition.
Static and Dynamic Correlation Functions
At this point the reader might have reached the
conclusion that the glass transition may not be
such a difﬁcult problem: there are experimental
indications of a diverging timescale and a con-
comitant singularity in the thermodynamics. It
simply remains to ﬁnd static correlation functions
displaying a diverging correlation length related
to the emergence of “amorphous order,” which
would indeed classify the glass transition as a
standard second-order phase transition. Remark-
ably, this conclusion remains an open and debated
question despite several decades of research.
Glasses and Aging, A
Statistical Mechanics
Perspective on,
Table 1 Values of glass
transition temperature, VFT
singularity and Kauzmann
temperatures for four
supercooled liquids
(Richert and Angell 1998)
Substance
o-
terphenyl
2-methyltetra-
hydrofuran
n-
propanol
3-
bromopentane
Tg
246
91
97
108
T0
202.4
69.6
70.2
82.9
TK
204.2
69.3
72.2
82.5
TK/T0
1.009
0.996
1.028
0.995
Glasses and Aging, A Statistical Mechanics Perspective on
233

Simple static correlation functions are quite fea-
tureless in the supercooled regime, notwithstand-
ing the dramatic changes in the dynamics.
A simple static quantity is the structure factor
deﬁned by
S q
ð Þ ¼
1
N drqdrq
D
E
,
ð3Þ
where the Fourier component of the density reads
drq ¼
X
N
i¼1
eiq:ri  N
V dq,0,
ð4Þ
with N the number of particles, V the volume, and
ri the position of particle i. The structure factor
measures the spatial correlations of particle posi-
tions, but it does not show any diverging peak in
contrast to what happens, for example, at the
liquid-gas critical point where there is a diver-
gence at small q. More complicated static corre-
lation functions have been studied (Debenedetti
1996), especially in numerical work, but until now
there are no strong indications of a diverging, or at
least substantially growing, static lengthscale
(Menon and Nagel 1995; Fernández et al. 2006;
Cavagna et al. 2007). A snapshot of a supercooled
liquid conﬁguration in fact just looks like a glass
conﬁguration,
despite
their
widely
different
dynamic properties (Berthier et al. 2019a). What
happens then at the glass transition? Is it a transi-
tion or simply a dynamic crossover? A more
reﬁned understanding can be gained by studying
dynamic correlations or response functions.
A dynamic observable studied in light and
neutron scattering experiments is the intermediate
scattering function,
F q, t
ð
Þ ¼
1
N drq tð Þdrq 0
ð Þ
D
E
:
ð5Þ
Different F(q, t) measured by neutron scatter-
ing in supercooled glycerol (Wuttke et al. 1996)
are shown for different temperatures in Fig. 2.
These curves show a ﬁrst, rather fast, relaxation
to a plateau followed by a second, much slower,
relaxation. The plateau is due to the fraction of
density
ﬂuctuations
that
are
frozen
on
intermediate timescales, but eventually relax dur-
ing the second relaxation. The latter is called
“alpha-relaxation,” and corresponds to the struc-
tural relaxation of the liquid. This plateau is akin
to the Edwards-Anderson order parameter qEA
deﬁned for spin glasses, which measures the frac-
tion of frozen spin ﬂuctuations (Binder and Kob
2011). Note that qEA continuously increases from
zero at the spin glass transition. Instead, for struc-
tural glasses, a ﬁnite plateau value already appears
above any transition.
The intermediate scattering function can be pro-
bed only on a relatively small regime of tempera-
tures. In order to track the dynamic slowing down
from microscopic to macroscopic timescales, other
correlators have been studied. A popular one is
obtained from the dielectric susceptibility, which
is related by the ﬂuctuation-dissipation theorem to
the time correlation of polarization ﬂuctuations. It
is generally admitted that different dynamic probes
reveal similar temperature dependencies of the
relaxation time. The temperature evolution of the
imaginary part of the dielectric susceptibility,
ϵ00(o), is shown in Fig. 3, which covers a very
wide temperature window (Pardo et al. 2007). At
high temperature, a good representation of the data
is given by a Debye law, ϵ(o) ¼ ϵ(1) þ  ϵ/(1 þ
iotα), which corresponds to an exponential
0.01
0
0.25
0.5
Φq(t)
0.75
1
0.1
t (nsec)
1
Glasses and Aging, A Statistical Mechanics Perspec-
tive on, Fig. 2 Temperature evolution of the intermediate
scattering function normalized by its value at time equal to
zero for supercooled glycerol (Wuttke et al. 1996). Tem-
peratures decrease from 413 K to 270 K from right to left.
The solid lines are ﬁt with a stretched exponential with
exponent β ¼ 0.7. The dotted line represents another ﬁt
with β ¼ 0.82
234
Glasses and Aging, A Statistical Mechanics Perspective on

relaxation in the time domain. When temperature is
decreased, however, the relaxation spectra become
very broad and strongly non-Debye. One particu-
larly well-known feature of the spectra is that they
are well ﬁtted, in the time domain, for times
corresponding to the alpha relaxation with a
stretched exponential, exp((t/tα)β). In the Fourier
domain, forms such as the Havriliak-Negami law
are used, ϵ(o) ¼ ϵ(1) þ  ϵ/(1 þ (iotα)α)γ, which
generalize the Debye law. The exponents β, α, and
γ depend in general on temperature and on the
particular dynamic probe chosen, but they capture
the fact that relaxation is increasingly non-
exponential
when
T
decreases
toward
Tg.
A connection was empirically established between
fragility and degree of non-exponentiality, more
fragile liquids being characterized by broader relax-
ation spectra (Debenedetti and Stillinger 2001).
To sum up, there are many remarkable phe-
nomena that take place when a supercooled liquid
approaches the glass transition. Striking ones have
been presented, but many others have been left out
for lack of space (Angell 1995; Debenedetti and
Stillinger 2001; Debenedetti 1996; Binder and
Kob 2011; Berthier and Ediger 2016). We have
discussed physical behaviors, relationships, or
empirical correlations observed in a broad class
of materials. This is quite remarkable and suggests
that there is some physics (and not only chemis-
try) to the problem of the glass transition, which
we see as a collective (critical?) phenomenon
which should be relatively independent of micro-
scopic
details.
This
justiﬁes
our
statistical
mechanics perspective on this problem.
Taxonomy of “Glasses” in Science
We now introduce a wider range of systems whose
phenomenological behavior is close or related to the
one of glass-forming liquids, showing that glassi-
ness is truly ubiquitous. It does not only appear in
many different physical situations but also in more
abstract contexts, such as computer science.
Colloidal Glass Transition
Colloidal suspensions consist of large particles
suspended in a solvent (Larson 1999). The typical
Glasses and Aging, A Statistical Mechanics Perspec-
tive on, Fig. 3 Temperature evolution of the dielectric
susceptibility of the glass-former benzophenone measured
over more than 10 decades of relaxation times (Pardo et al.
2007). Dynamics slows down dramatically as temperature
is decreased and relaxation spectra become very broad at
low temperature
Glasses and Aging, A Statistical Mechanics Perspective on
235

radii of the particles are in the range of R ¼
1–500 nm. The solvent, which is at equilibrium
at temperature T, renders the short-time dynamics
of the particles Brownian. The microscopic time-
scale for this diffusion is given by t ¼R2/D, where
D is the short-time self-diffusion coefﬁcient.
A typical value is of the order of t ~ 1 ms, which
is thus much larger than microscopic timescales
for molecular liquids (in the picosecond regime).
The
interaction
potential
between
particles
depends on the systems, and this large tunability
makes colloids very attractive objects for techni-
cal applications. A particularly relevant case, on
which we will focus in the following, is a purely
hard sphere potential, which is zero when particles
do not overlap and inﬁnite otherwise. In this case
the temperature scale becomes an irrelevant num-
ber, apart from a trivial rescaling of the micro-
scopic timescale. Colloidal hard sphere systems
have been intensively studied (Larson 1999) in
experiments, simulations, and theory, varying
their
density
r,
or
their
volume
fraction
’ ¼ 4
3 pR3r. Hard spheres display a ﬂuid phase
from ’ ¼ 0 to intermediate volume fractions, a
freezing-crystallization transition at ’ ’ 0.494,
and a melting transition at ’ ’ 0.545. Above
this latter value the system can be compressed
until the close packing point ’ ’ 0.74, which
corresponds to the FCC crystal. Interestingly for
our purposes, a small amount of size polydisper-
sity can suppress crystallization. In this case, the
system can be “supercompressed” above the
freezing transition without nucleating the crystal,
at least on experimental timescales. In this regime
the relaxation timescale increases very fast (Pusey
and VanMegen 1986). At a packing fraction
’g ’ 0.58  0.60 it becomes so large compared
to typical experimental timescales that the system
does not relax anymore: it is frozen. This “colloi-
dal glass transition” is obviously reminiscent of
the glass transition of molecular systems. In par-
ticular, the location ’g of the colloidal glass tran-
sition is as ill-deﬁned as the glass temperature Tg.
Actually, the phenomena that take place when
increasing the volume fraction are analogous to
the ones seen in molecular supercooled liquid
when decreasing temperature: the relaxation
timescales increases very fast and can be ﬁtted
(Cheng et al. 2002; Berthier and Witten 2009) by
a VFT law in density similar to Eq. (1), dynamical
correlation functions display a broad spectrum of
timescales and develop a plateau, no static grow-
ing correlation length has been found, etc. Also
the phenomenon of dynamic heterogeneity that
will be addressed in section “Dynamic Heteroge-
neity” is also observed in colloids (Kegel and van
Blaaderen 2000; Weeks et al. 2000). However, it
is important to underline a major difference:
because the microscopic timescale for colloids is
so large, experiments can only track the ﬁrst ﬁve
decades of slowing down. A major consequence is
that the comparison between the glass and colloi-
dal transitions must be performed by focusing in
both cases on the ﬁrst ﬁve decades of the slowing
down, which corresponds to relatively high tem-
peratures in molecular liquids (Brambilla et al.
2009). Understanding how much and to what
extent the glassiness of colloidal suspensions is
related to the one of molecular liquids remains an
active domain of research. Recently, by using
colloids of smaller size and hence decreasing the
microscopic timescale t, it has been possible to
explore a larger range of relaxation times (Hallett
et al. 2018). This is a very promising research
direction to explore the colloidal glassy regime.
Jamming Transition
Every day life offers many examples of jammed
solids: grains and beans poured into a container,
foams and emulsions produced by a large shear
stress, sand and colloidal particles under very high
pressure. Depending on how compressed they are,
these materials behave as ﬂuids or solids: a hand-
ful of sand will ﬂow from our open hand, while we
experience rigidity when closing the ﬁst. For-
mally, the jamming transition is reached at inﬁnite
pressure when all the droplets, bubbles, or col-
loids are forced to come into enduring kissing
contact with one another (Donev et al. 2004,
2005). All these systems share a fundamental
feature: they can be considered athermal in the
sense that thermal ﬂuctuations at room tempera-
ture are, by far, not able to allow the system to
explore its phase space.
236
Glasses and Aging, A Statistical Mechanics Perspective on

As an immediate consequence, the glass and
jamming transitions are of a very different nature.
The former describes a ﬂuid-to-solid transition in
a system controlled by thermal ﬂuctuations, and
its location depends on the cooling or compres-
sion rate. The latter is a purely geometrical tran-
sition happening at T ¼ 0 in the absence of any
dynamics, but it also corresponds to the change
between a viscous liquid to a solid mechanical
response (Liu and Nagel 1998). In recent years,
the connection between the two phenomena has
been elucidated (Charbonneau et al. 2017), and
both transitions can be observed under different
physical conditions in the hard spheres model.
Granular Glass Transition
Driven granular media represent another family of
systems that have recently been studied from the
point of view of their glassiness. Grains are mac-
roscopic objects and, as a consequence, are not
affected by thermal ﬂuctuations. A granular mate-
rial is therefore frozen in a given conﬁguration if
no energy is injected into the system (Jaeger et al.
1996). However, it can be forced in a steady state
by an external drive, such as shearing or tapping.
The dynamics in this steady state shows remark-
able similarities (and differences) with simple
ﬂuids. The physics of granular materials is a
very wide subject (Jaeger et al. 1996). In the
following we only address brieﬂy what happens
to a polydisperse granular ﬂuid at very high pack-
ing fractions. As for colloids, the timescales for
relaxation or diffusion increase very fast when
density is increased, without any noticeable
change
in
structural
properties.
It
is
now
established (D’Anna and Grémaud 2001; Marty
and Dauchot 2005; Keys et al. 2007) that many
phenomenological properties of the glass and
jamming transitions also occur in granular assem-
blies. Going beyond the mere analogy and under-
standing
how
much
colloids
and
granular
materials are related is a very active domain of
research.
Active Glasses
Active matter has recently emerged as a new ﬁeld
in physics (Marchetti et al. 2013; Bechinger et al.
2016), fueled by the observation that systems such
as a school ﬁsh, bacterial colonies, and biological
tissues display physical properties and phase tran-
sitions which can be described by statistical phys-
ics tools, and captured by simpliﬁed theoretical
models. Physical systems mimicking the behavior
of natural systems have also been developed to
perform controlled experiments on model systems
of active materials. In particular, colloidal parti-
cles and macroscopic objects similar to the sys-
tems displaying a granular glass transition have
also been developed so that these particles can
become
“active”
(Deseigne
et
al.
2010;
Theurkauff et al. 2012; Buttinoni et al. 2013),
that is, self-motile objects that can move in the
absence of thermal ﬂuctuations, similar to ani-
mals, cells, or bacteria.
It is natural to expect that dense assemblies of
active particles will undergo some form of
dynamic arrest (Henkes et al. 2011; Angelini
et al. 2011). As human beings, we are well
aware that it becomes difﬁcult to walk very fast
in a dense crowd, as observed in the streets of
large cities or in subway corridors at peak times.
Indeed, there are several indications from experi-
mental observations that a transition from a ﬂuid-
like state to an arrested glassy state can be
observed in active materials (Angelini et al.
2011; Garcia et al. 2015; Mongera et al. 2018;
Klongvessa et al. 2019).
From a conceptual viewpoint, the main differ-
ence between these observations and the glass
transition observed in molecular and colloidal
systems is that the driving force for single particle
motion is not of thermal origin, but is instead
chemical, mechanical, or biological. This means
that any theoretical model for dense active mate-
rials must include some sort of nonequilibrium
sources of microscopic motion and consequently
the glassy phenomena that will be described must
necessarily occur far from equilibrium (Berthier
and Kurchan 2013). In that sense, the situation is
conceptually not very different from the phenom-
enon of the granular glass transition discussed in
the previous paragraph. The difference between
the two essentially lies in the details of the driving
motion, which very much resembles a quasi-
Glasses and Aging, A Statistical Mechanics Perspective on
237

equilibrium thermal bath in granular glasses
(Keys et al. 2007).
Several numerical and theoretical studies of the
glass transition in active materials have been
recently published, see Berthier et al. (2019b) for
a speciﬁc review on this topic. In particular, the
glassy dynamics of so-called self-propelled parti-
cles have received considerable attention (Ni et al.
2013; Berthier 2014; Mandal et al. 2016; Bi et al.
2016; Berthier et al. 2017a; Matoz-Fernandez
et al. 2017). In these models, particles interacting
with simple pair interactions (similar to the ones
studied to model the equilibrium glass transition)
are driven by active forces that tend to displace the
particles in straight lines over a ﬁnite persistence
length.
It is now understood that for dense active
ﬂuids, due to these nonequilibrium driving forces
both the structure and the dynamics are very dif-
ferent
from
their
equilibrium
counterparts
(Berthier et al. 2019b). It is observed that a large
persistence length has a profound inﬂuence on the
static correlations of the ﬂuid since both density-
density (as in Eq. (3)) and velocity-velocity cor-
relation
functions
develop
non
trivial
non-
equilibrium features (Berthier et al. 2017a). As
particle crowding is increased, slow dynamics
develop and is accompanied by a phenomenology
similar to that of equilibrium glassy materials,
with motion becoming gradually arrested at large
enough density or small enough activity. Dynamic
arrest in dense active materials is therefore called
a nonequilibrium glass transition (Berthier and
Kurchan 2013). Understanding this new class of
glassy dynamics is an exciting new direction for
research.
Random Pinning Glass Transition
The standard control parameters used to induce a
glass transition are temperature and pressure.
A new way introduced in the 2000s is “random
pinning” (Scheidler et al. 2002; Kim 2003), which
consists in freezing the positions of a fraction c of
particles from an equilibrium conﬁguration of a
supercooled
liquid.
Theoretical
arguments
(Cammarota and Biroli 2012) and numerical sim-
ulations (Berthier and Kob 2012; Karmakar and
Procaccia 2011) suggested that the dynamics of
the remaining free particles slow down and
undergo a glass transition by increasing c. The
study of the random pinning glass transition has
been the focus of several theoretical analyses
(Cammarota and Biroli 2013; Krakoviack 2011,
2014; Szamel and Flenner 2013; Franz and Parisi
2013; Cammarota 2013; Franz et al. 2013; Phan
and Schweizer 2018; Cammarota and Seoane
2016; Ikeda et al. 2017a) and numerical simula-
tions (Berthier and Kob 2012; Kob and Berthier
2013; Charbonneau and Tarjus 2013; Karmakar
and Parisi 2013; Chakrabarty et al. 2015, 2016;
Kob and Coslovich 2014; Jack and Fullerton
2013; Fullerton and Jack 2014; Li et al. 2015;
Angelani et al. 2018; Ozawa et al. 2018a; Niblett
et al. 2018) in the decade 2005–2015. It has also
been studied in experiments, in particular in col-
loidal glasses by optical microscopy (Gokhale
et al. 2014, 2016; Ganapathi et al. 2018; Williams
et al. 2018).
The interest in the “random-pinning glass tran-
sition” has been twofold. First, it represents a new
way to test theories of the glass transition. In fact,
RFOT theory and MCT (see section “Theory of
the Glass Transition”) predict that it should have
the same properties as the usual glass transition
(Cammarota and Biroli 2012; Szamel and Flenner
2013), that is, increasing the pinned fraction c
plays the same role as lowering the temperature.
This phenomenon was studied and conﬁrmed in
Kob and Berthier (2013), where the equilibrium
phase diagram of a randomly pinned glass-former
was fully characterized. The dynamical behavior
is not as well understood. Although it is clear that
dynamics dramatically slows down when increas-
ing c, hence the name “random-pinning glass
transition,” it has proven difﬁcult to disentangle
trivial effects due to steric constraints from collec-
tive ones. In consequence, numerical simulations
could not validate or disprove the competing pre-
dictions from dynamical facilitation theories (Jack
and Berthier 2012) and RFOT theory (Cammarota
and Biroli 2012). The other reason for the random
pinning procedure was to produce conﬁgurations
equilibrated very close to the glass transition (just
after pinning, the remaining unpinned particles
are in an equilibrium conﬁguration for the
constrained systems (Krakoviack 2010)). This
238
Glasses and Aging, A Statistical Mechanics Perspective on

allowed to perform the ﬁrst computational study
of ultrastable glasses (Hocky et al. 2014), see
below.
The random pinning procedure has interesting
connections, similarities, and differences with
other ways to constrain the dynamics of glassy
liquids introduced in recent years. Those can be
grouped in three main categories: modiﬁcations of
the Hamiltonian (ϵ-coupling, see section “Franz-
Parisi
Potential”),
in
the
dynamical
rules
(s-ensemble dynamics, see section “s-Ensemble
and Large Deviations”), and in the space available
to the system (liquids in quenched environments
(Thalmann et al. 2000)).
Ultrastable Glasses
Glassy materials are typically prepared by slowly
cooling or compressing a dense ﬂuid across the
glass transition described above. The glass transi-
tion temperature or density is set by the competi-
tion between an extrinsic time scale imposed by
the experimentalist (for instance the duration of
the experiment, or the cooling rate), and an intrin-
sic timescale of the material, such as the structural
relaxation time. The degree of supercooling
observed in most glassy materials is then set by
the typical duration of an experiment, which cor-
responds to an intrinsic timescale of about 100 s in
molecular liquids.
It has recently become possible to prepare
“ultrastable” glasses (Swallen et al. 2007; Ediger
2017), namely glassy materials which reach a
degree of supercooling which is equivalent to
cooling glasses at rates that are 105–1010 times
slower than usual. Ultrastable glasses are not pre-
pared by cooling bulk liquids across the glass
transition, but using a completely different route
called physical vapor deposition. In this proce-
dure, the glassy material is prepared directly at
the desired temperature (there is no cooling
involved) by the slow deposition of individual
molecules suspended in a gas phase onto a glassy
ﬁlm whose height increases slowly as more mol-
ecules are deposited.
The degree of supercooling that can be
achieved by physical vapor deposition is again
set by the competition between two timescales
(Swallen et al. 2007; Berthier et al. 2017b). The
extrinsic timescale is now related to the deposition
rate of the molecules, whereas the intrinsic time-
scale is set by the relaxation time of molecules
diffusing at the free surface of the glassy ﬁlm. It is
known that bulk and surface dynamics may differ
by many orders of magnitude in glasses (Zhu et al.
2011), because the molecular mobility at a free
surface is much less constrained than in the bulk.
Therefore,
for
a
similar
extrinsic
timescale
imposed by the experimental setup, a much
deeper degree of supercooling is achieved by the
vapor deposition process.
Ultrastable glasses prepared using physical
vapor deposition are thus expected to behave as
extraordinarily slowly cooled supercooled liq-
uids, with a cooling rate or a preparation time
that is impractically large. As such, theses glasses
have physical properties that can differ rather
drastically from ordinary glassy materials. In par-
ticular, it was shown that their mechanical, ther-
modynamic,
and
kinetic
properties
differ
quantitatively from ordinary glasses, and display
speciﬁc dynamic phenomena (Kearns et al. 2010;
Chen et al. 2013; Pérez-Castañeda et al. 2014;
Sepúlveda et al. 2014; Ràfols-Ribé et al. 2018;
Vila-Costa et al. 2020). As such, they are currently
the subject of intense theoretical investigations as
well (Wolynes 2009; Léonard and Harrowell
2010; Lyubimov et al. 2013; Jack and Berthier
2016; Gutiérrez and Garrahan 2016; Fullerton
and Berthier 2017; Flenner et al. 2019; Khomenko
et al. 2020). The goal is to better understand the
deposition process itself, but also to better char-
acterize the physical properties of ultrastable
glasses in view of their many potential practical
applications. Also, since ultrastable glasses offer a
way to access much deeper supercooled states, it
can be hoped that they can be used to shed new
light on the glass transition phenomenon itself.
Other Glasses in Physics, and Beyond
There are many other physical contexts in which
glassiness plays an important role (Young 1998).
One of the most famous examples is the ﬁeld of
spin glasses. Real spin glasses are magnetic impu-
rities interacting by quenched random couplings.
At low temperatures, their dynamics become
extremely slow and they freeze in amorphous
Glasses and Aging, A Statistical Mechanics Perspective on
239

spin conﬁguration dubbed a “spin glass” by
Anderson. There are many other physical sys-
tems, often characterized by quenched disorder,
that show glassy behavior, like Coulomb glasses,
Bose glasses, etc. In many cases, however, one
does expect quite a different physics from struc-
tural glasses: the similarity between these systems
is therefore only qualitative.
Quite remarkably, glassiness also emerges in
other branches of science (Bouchaud et al. 2011).
In particular, it has been discovered recently that
concepts and techniques developed for glassy sys-
tems turn out to apply and be very useful tools in
the ﬁeld of computer science. Problems like com-
binatorial
optimization
display
phenomena
completely analogous to phase transitions, and
actually, to glassy phase transitions. A posteriori,
this is quite natural, because a typical optimization
problem consists in ﬁnding a solution in a presence
of a large number of constraints. This can be
deﬁned, for instance, as a set of N Boolean vari-
ables that satisﬁes M constraints. For N and M very
large at ﬁxed α ¼ M/N, this problem very much
resembles ﬁnding a ground state in a statistical
mechanics
problem
with
quenched
disorder.
Indeed
one
can
deﬁne
an
energy
function
(a Hamiltonian) as the number of unsatisﬁed con-
straints, that has to be minimized, as in a T ¼
0 statistical mechanics problem. The connection
with glassy systems originates from the fact that
in both cases the energy landscape is extremely
complicated, full of minima and saddles. The frac-
tion of constraints per degree of freedom, α, plays a
role similar to the density in a hard sphere system.
For instance, a central problem in optimization,
random k-satisﬁability, has been shown to undergo
a glass transition when α increases, analogous to
the one of structural glasses (Krzakala et al. 2007;
Antenucci et al. 2019).
Glassiness also plays an important role in
machine learning and signal processing. In those
cases, one wants to learn a speciﬁc task from
many examples or retrieve a speciﬁc signal from
a huge amount of data. This is done in practice by
minimizing a cost function. For example, imagine
that one is given a tensor Ti1,i2,i3 ¼ ui1ui2ui3,
constructed from a vector ui(i ¼ 1, . . ., N) of
norm
ﬃﬃﬃﬃ
N
p
, and that this tensor is corrupted by
noise Ji1,i2,i3 , which for simplicity we take inde-
pendent and Gaussian for each triple (i1, i2, i3).
The problem called tensor PCA, which appears in
image and video analysis (Anandkumar et al.
2014), consists in retrieving the signal ui from
the noisy tensor Ti1,i2,i3 þ Ji1,i2,i3 . The simplest
procedure to solve this problem is to ﬁnd the
vector xi minimizing the following cost function:
H
xi
f g
ð
Þ ¼
X
i1, i2, i3
ui1ui2ui3 þ Ji1,i2,i3  xi1xi2xi3
ð
Þ2:
By developing the square, one ﬁnds that the
cost function H is identical to the one of a 3-spin
spherical glass mean-ﬁeld model with quenched
random couplings Ji1,i2,i3
and a term favoring
conﬁgurations in the direction of ui (Richard and
Montanari 2014). These two contributions are
competing for determining the ground-state prop-
erties, the strength of the latter with respect to the
former is proportional to the signal-to-noise ratio.
This example illustrates one way in which glass-
iness plays an important role in machine learning:
one has to ﬁnd a signal (the ui’s) buried in a rough
landscape (induced by the Ji1,i2,i3 ’s). Practical
algorithms, such as gradient descent and its sto-
chastic version, lead to dynamics which are very
similar to the ones of physical systems after a
quench to low temperature. One of the main ques-
tions in this area is characterizing the algorithmic
threshold, that is, the critical value of the signal-
to-noise ratio such that the original signal can be
recovered with some given accuracy. Glassy
dynamics plays a central role: it is the main obsta-
cle for recovering the signal, as the dynamics can
be lost and trapped in bad minima instead of
converging toward the good one correlated with
the signal (Mannelli et al. 2020).
Finally, hunting for a signal in a rough land-
scape (Zdeborová and Krzakala 2016) is not the
only context in which glassiness emerged in
machine learning in recent years. In fact, more
generally, there has been a lot of work aimed at
characterizing the landscapes over which optimi-
zation dynamics take places in general machine
learning problems (from high-dimensional statis-
tics to deep neural networks), and at assessing to
which
extent
glassy
dynamics
and
rough
240
Glasses and Aging, A Statistical Mechanics Perspective on

landscapes play a relevant role (Sagun et al. 2014;
Baity-Jesi et al. 2019).
Numerical Simulations
Studying the glass transition of molecular liquids
at a microscopic level is in principle straightfor-
ward since one must answer a very simple ques-
tion: how do particles move in a liquid close to Tg?
It is of course a daunting task to attempt answering
this question experimentally because one should
then resolve the dynamics of single molecules to
be able to follow the trajectories of objects that are
a few Angstroms large on timescales of tens or
hundreds of seconds, which sounds like eternity
when compared to typical molecular dynamics
usually lying in the picosecond regime. In recent
years, such direct experimental investigations
have been developed using time and space
resolved techniques such as atomic force micros-
copy (Russell and Israeloff 2000) or single mole-
cule spectroscopy (Adhikari et al. 2007; Paeng
et al. 2015), but this remains a very difﬁcult task.
In numerical simulations, by contrast, the tra-
jectory of each particle in the system can, by
construction, be followed at all times. This allows
one to quantify easily single particle dynamics, as
proved in Fig. 4 where the averaged mean-
squared displacement  (t) measured in a simple
Lennard-Jones glass-former is shown and is
deﬁned as.
D tð Þ ¼
1
N
X
N
i¼1
ri tð Þ  ri 0
ð Þ
j
j2
*
+
,
ð6Þ
where ri(t) represents the position of particle i at
time t in a system composed of N particles and the
brackets indicate an ensemble average. The parti-
cle displacements considerably slow down when
T is decreased and the self-diffusion constant
decreases by orders of magnitude, mirroring the
behavior of the viscosity shown in Fig. 1 for real
systems. Moreover, a rich dynamics is observed,
with a plateau regime at intermediate timescales,
corresponding to an extended time window dur-
ing which particles vibrate around their initial
positions, exactly as in a crystalline solid. The
difference with a crystal is of course that this
localization is only transient, and all particles
eventually escape and diffuse at long times with
a diffusion constant Ds, so that  (t)~6Dst when
t ! 1.
In recent years, computer experiments have
played an increasingly important role in glass
transition studies. It could almost be said that
particle trajectories in numerical work have been
studied under so many different angles that prob-
ably very little remains to be learned from such
studies in the regime that is presently accessible
using present day computers. Unfortunately, this
does not imply complete knowledge of the phys-
ics of supercooled liquids. As shown in Fig. 4, it is
presently possible to follow the dynamics of a
simple glass-forming liquid over more than eight
decades of time, and over a temperature window
in which average relaxation timescales increase
by more than ﬁve decades. This might sound
impressive, but a quick look at Fig. 1 shows,
however, that at the lowest temperatures studied
in the computer, the relaxation timescales are still
orders of magnitude faster than in experiments
performed close to the glass transition tempera-
ture. They can be directly compared to experi-
ments
performed
in
this
high
temperature
regime, but this also implies that simulations
∼t
∼t2
t
Δ(t)
107
105
103
101
10−1
101
10−1
10−3
Glasses and Aging, A Statistical Mechanics Perspec-
tive on, Fig. 4 Mean-squared displacements of individ-
ual particles in a simple model of a glass-forming liquid
composed of Lennard-Jones particles observed on a wide
time window. When temperature decreases (from left to
right), the particle displacements become increasingly slow
with several distinct time regimes corresponding to (in this
order) ballistic, localized, and diffusive regimes
Glasses and Aging, A Statistical Mechanics Perspective on
241

focus on a relaxation regime that is about eight to
ten decades of times faster than in experiments
performed close to Tg. Whether numerical works
are useful to understand the kinetics of the glass
transition itself at all is therefore an open, widely
debated, question. We believe that it is now pos-
sible to numerically access temperatures which
are low enough that many features associated to
the glass transition physics can be observed:
strong decoupling phenomena, clear deviations
from ﬁts to the mode-coupling theory (which are
experimentally known to hold only at high tem-
peratures), and crossovers toward truly activated
dynamics.
In
section
“New
Computational
Methods,” we discuss recent developments in
the ﬁeld of computational studies that are able to
address novel challenges regarding the static
properties of supercooled liquids over a broad
temperature range.
Classical computer simulations of supercooled
liquids usually proceed by solving a cleverly
discretized version of Newton’s equations for a
given potential interaction between particles
(Allen and Tildesley 1989). If quantitative agree-
ment with experimental data on an existing spe-
ciﬁc material is sought, the interaction must be
carefully chosen in order to reproduce reality, for
instance by combining classical to ab initio sim-
ulations. From a more fundamental perspective
one rather seeks the simplest model that is still
able to reproduce qualitatively the phenomenol-
ogy of real glass-formers, while being consider-
ably simpler to study. The implicit, but quite
strong, hypothesis is that molecular details are
not needed to explain the behavior of supercooled
liquids, so that the glass transition is indeed a topic
for statistical mechanics, not for chemistry.
A considerable amount of work has therefore
been dedicated to studying models such as hard
spheres, soft spheres, or Lennard-Jones particles.
More realistic materials are also studied focusing
for instance on the physics of network forming
materials, multicomponent ones, anisotropic par-
ticles, or molecules with internal degrees of free-
dom. Connections to experimental work can be
made by computing quantities that are experimen-
tally accessible such as the intermediate scattering
function,
static
structure
factors,
S(q),
or
thermodynamic quantities such as speciﬁc heat
or conﬁgurational entropy, which are directly
obtained from particle trajectories and can be
measured in experiments as well. As an example
we show in Fig. 5 the intermediate scattering
function F(q, t) obtained from a molecular
dynamics simulation of a classical model for
SiO2 as a function of time for different tempera-
tures (Horbach and Kob 2001).
An important role is played by simulations also
because a large variety of dynamic and static
quantities can be simultaneously measured in a
single model system. As we shall discuss below,
there are scores of different theoretical approaches
to describe the physics of glass-formers, and
sometimes they have their own set of predictions
that can be readily tested by numerical work.
Indeed, quite a large amount of numerical papers
have been dedicated to testing in detail the pre-
dictions formulated by the mode-coupling theory
of the glass transition, as reviewed in Götze
(1999). Here, computer simulations are particu-
larly
well-suited
as
the
theory
speciﬁcally
addresses the relatively high temperature window
that is studied in computer simulations.
While Newtonian dynamics is mainly used in
numerical work on supercooled liquids, a most
appropriate choice for these materials, it can be
interesting to consider alternative dynamics that
are not deterministic, or which do not conserve the
energy. In colloidal glasses and physical gels, for
instance, particles undergo Brownian motion aris-
ing from collisions with molecules in the solvent,
and a stochastic dynamics is more appropriate.
Theoretical considerations might also suggest
1.0
0.8
T=6100K
F (q,t)
(a)
T=2750K
Si−Si
0.6
0.4
0.2
0.0
Glasses and Aging, A Statistical Mechanics Perspec-
tive on, Fig. 5 Intermediate scattering function at
wavevector 1.7 Å1 for the Si particles at T ¼ 2750 K
obtained from molecular dynamics simulations of a model
for silica (Horbach and Kob 2001)
242
Glasses and Aging, A Statistical Mechanics Perspective on

the study of different sorts of dynamics for a given
interaction between particles, for instance, to
assess the role of conservation laws and structural
information. Of course, if a given dynamics sat-
isﬁes
detailed
balance
with
respect
to
the
Boltzmann distribution, all structural quantities
remain unchanged, but the resulting dynamical
behavior might be very different. Several papers
(Gleim et al. 1998; Szamel and Flenner 2004;
Berthier and Kob 2007) have studied in detail
the inﬂuence of the chosen microscopic dynamics
on the dynamical behavior in glass-formers using
either stochastic dynamics (where a friction term
and a random noise are added to Newton’s equa-
tions, the amplitude of both terms being related by
a
ﬂuctuation-dissipation
theorem),
Brownian
dynamics (in which there are no momenta, and
positions evolve with Langevin dynamics), or
Monte-Carlo
dynamics
(where
the
potential
energy between two conﬁgurations is used to
accept or reject a trial move). Quite surprisingly,
the equivalence between these three types of sto-
chastic dynamics and the originally studied New-
tonian dynamics was established at the level of the
averaged dynamical behavior (Gleim et al. 1998;
Szamel and Flenner 2004; Berthier and Kob
2007), except at very short times where obvious
differences are indeed expected. This strongly
suggests that an explanation for the appearance
of slow dynamics in these materials originates
from their amorphous structure. However, impor-
tant differences were found when dynamic ﬂuctu-
ations were considered (Berthier and Kob 2007;
Berthier et al. 2007a, b), even in the long-time
regime comprising the structural relaxation.
Another crucial advantage of molecular simu-
lations is illustrated in Fig. 6. This ﬁgure shows a
spatial map of single particle displacements
recorded during the simulation of a binary soft
sphere system in two dimensions (Hurley and
Harrowell 1995). This type of measurement, out
of reach of most experimental techniques that
study the liquid state, reveals that dynamics
might be very different from one particle to
another. More importantly, Fig. 6 also unambigu-
ously reveals the existence of spatial correlations
between these dynamic ﬂuctuations. The presence
of
nontrivial
spatiotemporal
ﬂuctuations
in
supercooled liquids is now called “dynamic het-
erogeneity” (Ediger 2000), as we now discuss.
Dynamic Heterogeneity
Existence of Spatiotemporal Dynamic
Fluctuations
A new facet of the relaxational behavior of super-
cooled liquids has emerged in the last two decades
thanks to a considerable experimental and theo-
retical effort. It is called “dynamic heterogeneity”
(DH), and now plays a central role in modern
descriptions of glassy liquids (Ediger 2000;
Berthier et al. 2011a). As anticipated in the previ-
ous section, the phenomenon of dynamic hetero-
geneity
is
related
to
the
spatiotemporal
ﬂuctuations of the dynamics. Initial motivations
stemmed from the search of an explanation for the
non-exponential nature of relaxation processes in
supercooled liquids, related to the existence of a
broad relaxation spectrum. Two natural but fun-
damentally different explanations can be put for-
ward. (1) The relaxation is locally exponential,
but the typical relaxation timescale varies spa-
tially. Hence, global correlation or response func-
tions
become
non-exponential
upon
spatial
averaging over this spatial distribution of relaxa-
tion times. (2) The relaxation is complicated and
inherently non-exponential, even locally. Experi-
mental and theoretical works (Ediger 2000) sug-
gest that both mechanisms are likely at play, but
deﬁnitely conclude that relaxation is spatially het-
erogeneous, with regions that are faster and
slower than the average. Since supercooled liq-
uids are ergodic materials, a slow region will
eventually
become
fast,
and
vice
versa.
A physical characterization of DH entails the
determination of the typical lifetime of the hetero-
geneities, as well as their typical lengthscale.
A clear and more direct conﬁrmation of the
heterogeneous character of the dynamics also
stems from simulation studies. For example,
whereas the simulated average mean-squared dis-
placements are smooth functions of time, time
signals for individual particles clearly exhibit spe-
ciﬁc features that are not observed unless dynamics
is resolved both in space and time. These features
Glasses and Aging, A Statistical Mechanics Perspective on
243

are displayed in Fig. 7. What do we see? We mainly
observe that particle trajectories are not smooth but
rather composed of a succession of long periods of
time where particles simply vibrate around well-
deﬁned locations, separated by rapid “jumps.”
Vibrations were previously inferred from the pla-
teau observed at intermediate times in the mean-
squared displacements of Fig. 4, but the existence
of jumps that are clearly statistically widely distrib-
uted in time cannot be guessed from averaged
quantities only. The ﬂuctuations in Fig. 7 suggest,
and direct measurements conﬁrm, the importance
played by ﬂuctuations around the averaged dynam-
ical behavior.
A simple type of such ﬂuctuations has been
studied in much detail. When looking at Fig. 7,
it is indeed natural to ask, for any given time, what
is the distribution of particle displacements. This
is quantiﬁed by the self-part of the van-Hove
function deﬁned as
Gs r, t
ð
Þ ¼
1
N
X
N
i¼1
d r  ri tð Þ  ri 0
ð Þ
½

ð
Þ
*
+
: ð7Þ
For an isotropic Gaussian diffusive process,
one gets Gs(r, t) ¼ exp (|r|2/(4Dst))/(4πDst)3/2.
Simulations reveal instead strong deviations
from Gaussian behavior on the timescales rele-
vant for structural relaxation (Kob et al. 1997). In
particular they reveal “fat” tails in the distribu-
tions that are much wider than expected from the
Gaussian approximation. These tails are in fact
better described by an exponential decay rather
than a Gaussian one, in a wide time window
comprising the structural relaxation, such that
Glasses and Aging, A Statistical Mechanics Perspec-
tive on, Fig. 6 Spatial map of single particle displace-
ments in the simulation of a binary mixture of soft spheres
in two dimensions (Hurley and Harrowell 1995). Arrows
show the displacement of each particle in a trajectory of
length about 10 times the structural relaxation time. The
map reveals the existence of particles with different mobil-
ities during relaxation, but also the existence of spatial
correlations between these dynamic ﬂuctuations
244
Glasses and Aging, A Statistical Mechanics Perspective on

Gs(r, t)~ exp (| r| /l(t)) (Chaudhuri et al.
2007). Thus, they reﬂect the existence of a pop-
ulation of particles that moves distinctively fur-
ther than the rest and appears therefore to be
much more mobile. This observation implies
that relaxation in a viscous liquid qualitatively
differs from that of a normal liquid where diffu-
sion is close to Gaussian, and that a nontrivial
single particle displacements statistics exists.
A long series of questions immediately follows
this seemingly simple observation. Answering
them has been the main occupation of many
workers in this ﬁeld over the last decade. What
are the particles in the tails effectively doing?
Why are they faster than the rest? Are they located
randomly in space or do they cluster? What is the
geometry, time, and temperature evolution of the
clusters? Are these spatial ﬂuctuations correlated
to geometric or thermodynamic properties of the
liquids? Do similar correlations occur in all glassy
materials? Can one predict these ﬂuctuations the-
oretically? Can one understand glassy phenome-
nology using ﬂuctuation-based arguments? Can
these ﬂuctuations be detected experimentally?
Another inﬂuential phenomenon that was
related early on to the existence of DH is the
decoupling of self-diffusion (Ds) and viscosity
(). In the high temperature liquid self-diffusion
and viscosity are related by the Stokes-Einstein
relation (Hansen and McDonald 1990), Ds/T ¼
const. For a large particle moving in a ﬂuid the
constant is equal to 1/(6πR) where R is the particle
radius. Physically, the Stokes-Einstein relation
means that two different measures of the relaxa-
tion time R2/Ds and R3/T lead to the same time-
scale up to a constant factor. In supercooled
liquids this phenomenological law breaks down,
as shown in Fig. 8 for ortho-terphenyl (Mapes
et al. 2006). It is commonly found that D1
s
does
not increase as fast as  so that, at Tg, the product
Ds has increased by 2–3 orders of magnitude as
compared to its Stokes-Einstein value. This phe-
nomenon, although less spectacular than the over-
all change of viscosity, is a signiﬁcative indication
that different ways to measure relaxation times
lead to different answers and thus is a strong hint
of the existence of a distribution of relaxation
timescales.
Indeed, a natural explanation of this effect is
that different observables probe the underlying
distribution of relaxation times in different ways
(Ediger 2000). For example, the self-diffusion
coefﬁcient of tracer particles is dominated by the
more mobile particles whereas the viscosity or
other measures of structural relaxation probe the
timescale needed for every particle to move. An
unrealistic but instructive example is a model
where there is a small, non-percolative subset of
particles that are blocked forever, coexisting with
a majority of mobile particles. In this case, the
structure never relaxes but the self-diffusion coef-
ﬁcient is nonzero because of the mobile particles.
Of course, in reality all particles move, eventually,
but this shows how different observables are
likely to probe different moments of the distribu-
tion of timescales, as explicitly shown within sev-
eral theoretical frameworks (Tarjus and Kivelson
1995; Jung et al. 2004).
The phenomena described above, although
certainly an indication of spatiotemporal ﬂuctua-
tions, do not allow one to study how these ﬂuctu-
ations are correlated in space. This is however a
fundamental issue both from the experimental and
theoretical points of view. How large are the
regions that are faster or slower than the average?
How does their size depend on temperature? Are
103 × t/τα
|ri(t) −ri(0)|2
2500
2000
1500
1000
500
0
4
3
2
1
0
Glasses and Aging, A Statistical Mechanics Perspec-
tive on, Fig. 7 Time resolved squared displacements of
individual particles in a simple model of a glass-forming
liquid composed of Lennard-Jones particles. The average
is shown as a smooth full line. Trajectories are composed of
long periods of time during which particles vibrate around
well-deﬁned positions, separated by rapid jumps that are
widely distributed in time, underlying the importance of
dynamic ﬂuctuations
Glasses and Aging, A Statistical Mechanics Perspective on
245

these regions compact or fractal? These important
questions were ﬁrst addressed in pioneering
works using four-dimensional NMR (Reinsberg
et al. 2001), or by directly probing ﬂuctuations at
the nanoscopic scale using microscopy tech-
niques. In particular, Vidal Russel and Israeloff
using
Atomic
Force
Microscopy
techniques
(Russell and Israeloff 2000) measured the polari-
zation ﬂuctuations in a volume of size of few tens
of nanometers in a supercooled polymeric liquid
(PVAc) close to Tg. In this spatially resolved mea-
surement, the hope is to probe a small enough
number of dynamically correlated regions, and
detect their dynamics. Indeed, the signal shown
in Fig. 9 shows a dynamics which is very inter-
mittent in time, switching between periods with
intense activity and other periods with no dynam-
ics at all, suggesting that extended regions of
space indeed transiently behave as fast or slow
regions. A much smoother signal would be mea-
sured if such dynamically correlated “domains”
were not present. Spatially resolved and NMR
experiments
are
quite
difﬁcult.
They
give
undisputed information about the typical lifetime
of the DH, but their determination of a dynamic
correlation lengthscale is rather indirect and/or
performed on a small number of liquids in a
small temperature window. Nevertheless, the out-
come is that a nontrivial dynamic correlation
length emerges at the glass transition, where it
reaches a value of the order of 5–10 molecule
diameters (Ediger 2000).
Multipoint Correlation Functions
More recently, substantial progress in characteriz-
ing spatiotemporal dynamical ﬂuctuations was
obtained from theoretical (Berthier et al. 2007a, b;
Franz and Parisi 2000; Toninelli et al. 2005) and
numerical results (Hurley and Harrowell 1995;
Yamamoto and Onuki 1998; Franz et al. 1999;
Bennemann et al. 1999; Lačević et al. 2003;
Berthier 2004). In particular, it is now understood
that dynamical ﬂuctuations can be measured and
characterized through the use of four-point corre-
lation functions. These multipoint functions can be
seen as a generalization of the spin glass suscepti-
bility measuring the extent of amorphous long-
range order in spin glasses. In this subsection, we
introduce these correlation functions and summa-
rize the main results obtained using them.
Glasses and Aging, A Statistical Mechanics Perspec-
tive on, Fig. 8 Decoupling between viscosity (full line)
and self-diffusion coefﬁcient (symbols) in supercooled
ortho-terphenyl (Mapes et al. 2006). The dashed line
shows a ﬁt with a “fractional” Stokes-Einstein relation,
Ds~(T/)ζ with ζ ~ 0.82
246
Glasses and Aging, A Statistical Mechanics Perspective on

Standard experimental probes of the averaged
dynamics of liquids give access to the time-
dependent autocorrelation function of the sponta-
neous ﬂuctuations of some observable O(t),
F(t) ¼ hδO(0)δO(t)i, where δO(t) ¼ O(t)  hOi
represents the instantaneous value of the deviation
of O(t) from its ensemble average hOi at time t.
One can think of F(t) as being the average of a
two-point quantity, C(0, t) ¼ δO(0)δO(t), charac-
terizing the dynamics. A standard example corre-
sponds to O being equal to the Fourier transform
of the density ﬁeld. In this case F(t) is the dynam-
ical structure factor as in Eq. (5). More generally, a
correlation function F(t) measures the global
relaxation in the system. Intuitively, in a system
with important dynamic correlations, the ﬂuctua-
tions of C(0, t) are stronger. Quantitative informa-
tion on the amplitude of those ﬂuctuations is
provided by the variance
w4 tð Þ ¼ N dC 0, t
ð
Þ2
D
E
,
ð8Þ
where δC(0, t) ¼ C(0, t)  F(t), and N is the total
number of particles in the system. The associated
spatial correlations show up more clearly when
considering a “local” probe of the dynamics, like
for instance an orientational correlation function
measured by dielectric or light scattering experi-
ments, which can be expressed as
C 0, t
ð
Þ ¼ 1
V
ð
d3rc r; 0, t
ð
Þ,
ð9Þ
where V is the volume of the sample and c(r; 0, t)
characterizes the dynamics between times 0 and t
around point r. For example, in the above mentioned
case of
orientational correlations, c r; 0, t
ð
Þ /
V
N
PN
i,j¼1d r  ri
ð
ÞY Oi 0
ð Þ
ð
ÞY O j tð Þ
	

,
where Ωi
denotes the angles describing the orientation of mol-
ecule i, ri(0) is the position of that molecule at time
0, and Y(Ω) is some appropriate rotation matrix
element. Here, the “locality” of the probe comes
from the fact that it is dominated by the self-term
involving the same molecule at times 0 and t, or by
the contribution coming from neighboring mole-
cules. The dynamic susceptibility w4(t) can thus be
rewritten as
w4 tð Þ ¼ r
ð
d3rG4 r; 0, t
ð
Þ,
ð10Þ
where
G4 r; 0, t
ð
Þ ¼ dc 0; 0, t
ð
Þdc r; 0, t
ð
Þ
h
i,
ð11Þ
and translational invariance has been taken into
account (r ¼ N/V denotes the mean density). The
above equations show that w4(t) measures the
extent of spatial correlation between dynamical
b
Time (s)
8
10
12
16
14
6
4
2
0
Glasses and Aging, A Statistical Mechanics Perspec-
tive on, Fig. 9 Time series of polarization in the AFM
experiment performed by Vidal Russell and Israeloff
(2000) on PVAc at T ¼ 300 K. The signal intermittently
switches between periods with fast or slow dynamics,
suggesting that extended regions of space indeed tran-
siently behave as fast and slow regions
Glasses and Aging, A Statistical Mechanics Perspective on
247

events at times 0 and t at different points, that is,
the spatial extent of dynamically heterogeneous
regions over a time span t.
The function w4(t) has been measured by molec-
ular dynamics, Brownian and Monte Carlo simu-
lations in different liquids (Franz et al. 1999;
Bennemann et al. 1999; Lačević et al. 2003;
Berthier 2004, 2007a; Gebremichael et al. 2004).
An example is shown in Fig. 10 for a Lennard-
Jones liquid. The qualitative behavior is similar in
all cases (Berthier et al. 2007a; Franz and Parisi
2000; Toninelli et al. 2005): as a function of time
w4(t) ﬁrst increases, it has a peak on a timescale that
tracks the structural relaxation timescale and then it
decreases. (The decrease at long times constitutes a
major difference with spin glasses. In a spin glass,
w4 would be a monotonically increasing function of
time whose longtime limit coincides with the static
spin glass susceptibility. Physically, the difference
is that spin glasses develop long-range static amor-
phous order while structural glasses do not or, at
least, in a different and more subtle way.) Thus the
peak value measures the volume on which the
structural relaxation processes are correlated. It is
found to increase when the temperature decreases
and the dynamics slows down. By measuring
directly G4(r; 0, t) it has also been checked that
the increase of the peak of w4(t) corresponds, as
expected, to a growing dynamic lengthscale x
(Berthier et al. 2007a; Bennemann et al. 1999;
Lačević et al. 2003; Berthier 2004), although
these measurements are much harder in com-
puter simulations, because very large systems
need to be simulated to determine x unambigu-
ously. Note that if the dynamically correlated
regions were compact, the peak of w4 would be
proportional to x3 in three dimensions, directly
relating w4 measurements to that of the relevant
lengthscale of DH.
These results are also relevant because many
theories of the glass transition assume or predict,
in a way or another, that the dynamics slows down
because there are increasingly large regions on
which particles have to relax in a correlated or
cooperative
way.
However,
this
lengthscale
remained elusive for a long time. Measures of
the spatial extent of dynamic heterogeneity, in
particular w4(t) and G4(r; 0, t), seem to provide
the long-sought evidence of this phenomenon.
This in turn suggests that the glass transition is
indeed a critical phenomenon characterized by
growing timescales and lengthscales. A clear and
conclusive understanding of the relationship
between the lengthscale obtained from G4(r; 0, t)
and the relaxation timescale is still the focus of an
intense research activity.
Glasses and Aging, A Statistical Mechanics Perspec-
tive on, Fig. 10 Time dependence of w4(t), quantifying
the spontaneous ﬂuctuations of the intermediate scattering
function in a Lennard-Jones supercooled liquid. For each
temperature, w4(t) has a maximum, which shifts to larger
times and has a larger value when T is decreased, revealing
the increasing lengthscale of dynamic heterogeneity in
supercooled liquids approaching the glass transition
248
Glasses and Aging, A Statistical Mechanics Perspective on

One major issue is that obtaining information
on the behavior of w4(t) and G4 (r; 0, t) from
experiments is difﬁcult. Such measurements are
necessary because numerical simulations can only
be performed rather far from Tg, see section
“Numerical Simulations.” Up to now, direct
experimental measurements of w4(t) have been
restricted to colloidal (Weeks et al. 2007) and
granular materials (Keys et al. 2007; Dauchot
et al. 2005) close to the jamming transition,
because
dynamics
is
more
easily
spatially
resolved in those cases. Unfortunately, similar
measurements are currently not available in
molecular liquids.
Recently, an approach based on ﬂuctuation-
dissipation relations and rigorous inequalities has
been developed in order to overcome this difﬁculty
(Berthier et al. 2005, 2007a; b; Dalle-Ferrier et al.
2007). The main idea is to obtain a rigorous lower
bound on w4(t) using the Cauchy-Schwarz inequal-
ity hδH(0)δC(0, t)i2 O hδH(0)2i hδC(0, t)2i, where
H(t) denotes the enthalpy at time t. By using
ﬂuctuation-dissipation
relations
the
previous
inequality can be rewritten as (Berthier et al. 2005)
w4 tð Þ  kBT2
cP
wT tð Þ
½
2,
ð12Þ
where the multipoint response function wT (t) is
deﬁned by
wT tð Þ ¼ @F tð Þ
@T

N,P
¼
N
kBT2 dH 0
ð ÞdC 0, t
ð
Þ
h
i:
ð13Þ
In this way, the experimentally accessible
response wT(t) which quantiﬁes the sensitivity of
average correlation functions F(t) to an inﬁnites-
imal temperature change, can be used in Eq. (12)
to yield a lower bound on w4(t). Moreover,
detailed numerical simulations and theoretical
arguments (Berthier et al. 2007a, b) strongly sug-
gest that the right hand side of (12) actually pro-
vides a good estimation of w4(t), not just a lower
bound.
Using this method, Dalle-Ferrier et al. (2007)
have been able to obtain the evolution of the peak
value of w4 for many different glass-formers in the
entire supercooled regime. In Fig. 11 we show
some of these results as a function of the relaxa-
tion timescale. The value on the y-axis, the peak of
w4, is a proxy for the number of molecules, Ncorr,4
that have to evolve in a correlated way in order to
relax the structure of the liquid. Note that w4 is
expected to be equal to Ncorr,4 only up to a pro-
portionality constant that is not known from
experiments, which probably explains why the
high temperature values of Ncorr,4 are smaller
than one. Figure 11 also indicates that Ncorr,4
grows faster when Tα is not very large, close to
the onset of slow dynamics, and a power law
relationship between Ncorr,4 and Tα ﬁts this regime
well (tα/t0 < 104). The growth of Ncorr,4 becomes
much slower closer to Tg. A change of six decades
in time corresponds to a mere increase of a factor
about 4 of Ncorr,4, suggesting logarithmic rather
than power law growth of dynamic correlations.
This is in agreement with several theories of the
glass transition which are based on activated
dynamic
scaling
(Xia
and
Wolynes
2000;
Garrahan and Chandler 2003; Tarjus et al. 2005).
Understanding
quantitatively
this
relation
between timescales and lengthscales is one of
the main recent topics addressed in theories of
the glass transition, see section “Theory of the
Glass Transition.” Furthermore, numerical works
are also devoted to characterizing better the geom-
etry of the dynamically heterogeneous regions
(Donati et al. 1998; Appignanesi et al. 2006;
Kob et al. 2012).
Nonlinear Response Function
Diverging responses are characteristic signatures
of phase transitions. Linear static responses mea-
suring the change in the order parameter due to
external ﬁelds diverge at second-order phase tran-
sitions (Chaikin et al. 1995). By using ﬂuctuation-
dissipation relations one can show that such diver-
gence is intimately related to the divergence of the
correlation
length
emerging
in
two
point-
functions. Spin-glasses, the archetypal example
of disordered systems, display a diverging static
magnetic nonlinear cubic response (Binder and
Young 1986; Baity-Jesi et al. 2013). In Bouchaud
and
Biroli
(2005)
it
was
argued
that
the
Glasses and Aging, A Statistical Mechanics Perspective on
249

counterpart of these phenomena for supercooled
liquids can be found in nonlinear dynamical sus-
ceptibilities, which should grow approaching the
glass transition, thus providing a complementary
way (compared to w4) to reveal its collective
nature. In experiments on molecular liquids, non-
linear dielectric susceptibility is a natural probe to
unveil this phenomenon.
The simplest explanation (Albert et al. 2016)
for this scenario is based on the assumption that
Ncorr ¼ ‘=a
ð
Þd f
molecules
are
amorphously
ordered over the lengthscale ‘, where a is the
molecular size and df is the fractal dimension of
the
ordered
clusters.
In
consequence,
their
dipoles, which are oriented in apparently random
positions, are essentially locked together during a
time tα. In the presence of an external electric ﬁeld
E oscillating at frequency o  t1
a , the dipolar
degrees of freedom of these molecules contribute
to the polarization per unit volume as
p ¼ mdip
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
‘=a
ð
Þd f
q
‘=a
ð
Þd
F
mdipE
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
‘=a
ð
Þd f
q
kT
0
@
1
A
ð14Þ
where mdip is an elementary dipole moment, F is
an odd scaling function, and d ¼ 3 the dimension
of space. This states that randomly locked dipoles
have an overall moment
~ﬃﬃﬃﬃﬃﬃﬃﬃﬃ
Ncorr
p
, and that we
should compare the thermal energy with the
energy of this “super-dipole” in a ﬁeld.
Expanding Eq. 14 in powers of E, one ﬁnds the
“glassy” contribution to p:
p
mdip
¼ F0 0
ð Þ ‘
a
 d f d mdipE
kT


þ
þ 1
3! F 3
ð Þ 0
ð Þ ‘
a
 2d f d mdipE
kT

3
þ
þ 1
5! F 5
ð Þ 0
ð Þ ‘
a
 3d f d mdipE
kT

5
þ   
ð15Þ
Because df  d, the ﬁrst term, contributing to
the usual linear dielectric susceptibility, w1(o),
cannot grow as ‘ increases. This simple theoretical
argument explains why spatial glassy correlations
does not show up in w1(o), in experiments. The
second term, contributing to the third-order
dielectric susceptibility w3(o), does grow with ‘
provided df > d/2. Several theories indeed suggest
that ordered domains are compact, df ¼ d (Tarjus
et al. 2005; Wolynes and Lubchenko 2012). The
third term leads to the ﬁfth-order susceptibility
w5(o), which should diverge as ‘3d f d (higher
Glasses and Aging, A Statistical Mechanics Perspec-
tive on, Fig. 11 Universal dynamic scaling relation
between number of dynamically correlated particles,
Ncorr,4, and relaxation timescale, tα, for a number of
glass-formers (Dalle-Ferrier et al. 2007), determined
using Eq. (12)
250
Glasses and Aging, A Statistical Mechanics Perspective on

n-order susceptibilities diverge as ‘ nþ1
ð
Þd f =2d .
This line of arguments shows that measuring non-
linear susceptibilities is a way to probe and char-
acterize
the
collective
dynamical
behavior
associated to glassy dynamics.
This challenge was taken up in the series of
works (Albert et al. 2016; Crauste-Thibierge
et al. 2010; Bauer et al. 2013; Brun et al.
2012). The main outcomes of these experiments
have been: (i) to show that indeed a growth of
the nonlinear responses goes along with the
glass transition, (ii) to measure in a new way
the number of correlated molecules close to Tg,
(iii) to estimate that df ’ d (for d ¼ 3). As an
example, we reproduce the results of (Albert
et al. 2016) in Fig. 12, which shows the increase
of the ﬁfth-order susceptibility with temperature
(panel A), its humped shape in frequency
(panel B), and the stronger singularity of the
ﬁfth-order susceptibility compared to the third-
order one (panel C), as expected for a collective
phenomenon.
Another set of experiments on nonlinear
responses was performed in colloids: non-
linear mechanical susceptibilities were probed
approaching
the
colloidal
glass
transition
(Seyboldt et al. 2016) and shown to grow
approaching it. Differently from the dielectric
case, third-harmonic shear responses have a
peak
at
a
frequency
associated
to
the
β-relaxation, and not to the α-relaxation. The
reason is related to the fact that a very slow
shear-strain does not affect the relaxation
time-scale, whereas an external electric ﬁeld
(even
a
static
one)
does,
see
Seyboldt
et al. (2016).
10
-2
10
-1
10
0
10
1
10
2
10
-34
10
-33
10
-32
10
-31
f (Hz)
195K
|χ
(5)
 5 | (m
4/V
4)
204K
B
glycerol
10
-2
10
-1
10
0
10
1
10
2
0
1
2
3
4
5
6
|χ
(k)
 k (f)| / |χ
(k)
 k (0)|
f / fα
 k = 5
 k = 3
 k = 1
 k = 5, trivial
 k = 3, trivial
glycerol  204K
C
A
Glasses and Aging, A Statistical Mechanics Perspec-
tive on, Fig. 12 Modulus of the ﬁfth-order susceptibility
in supercooled glycerol as a function of frequency (from
Albert et al. (2016)). (a) The susceptibilities w 5
ð Þ
5
reported
are obtained directly by monitoring the response of the
sample at 5o, when applying an electric ﬁeld E at angular
frequency o. Two independent setups were used. Lines are
guides for the eyes. (b) Projection onto the susceptibility-
frequency plane of the data of panel A at 204 K and at
195 K. (c) Comparison of the ﬁfth-order, cubic, and linear
susceptibilities. Symbols, with line to guide the eyes. The
higher the order k, the stronger the hump of j w k
ð Þ
k
j
Glasses and Aging, A Statistical Mechanics Perspective on
251

Finally, a word about theories. Given that the
growth of nonlinear dynamical susceptibility is a
relatively newly established fact in the glass-
physics arena, one can wonder how the different
theoretical framework developed to explain the
glass transitions cope with it. Thermodynamic
theories based on the increases of some kind of
medium range order naturally do, as explained
above. Mode-Coupling-Theory also predicts
diverging dynamical nonlinear susceptibility at
the MCT transition (Seyboldt et al. 2016; Tarzia
et al. 2010). Purely local theory are instead at
odds. Dynamical facilitation theory was argued
to be compatible with such ﬁndings in Speck
(2019), even though the general arguments put
forward in Albert et al. (2016) indicate the oppo-
site conclusion.
Theory of the Glass Transition
We now present some theoretical approaches to
the glass transition. It is impossible to cover all of
them in a brief review, simply because there are
way too many of them, perhaps the clearest indi-
cation that the glass transition remains an open
problem. We choose to present approaches that
are keystones and have a solid statistical mechan-
ics basis. Loosely speaking, they have a Hamil-
tonian, can be simulated numerically, or studied
analytically with statistical mechanics tools. Of
course, the choice of Hamiltonians is crucial and
contains very important assumptions about the
nature
of
the
glass
transition.
All
these
approaches have given rise to unexpected results.
One ﬁnds more in them than what was supposed
at the beginning, which leads to new, testable
predictions. Furthermore, with models that are
precise enough, one can test (and hopefully fal-
sify!) these approaches by working out all their
predictions in great detail, and comparing the
outcome to actual data. This is not possible
with “physical pictures,” or simpler approaches
of the problem which we therefore do not
discuss.
Before going into the models, we would like to
state the few important questions that theoreti-
cians face.
•
Why do the relaxation time and the viscosity
increase when Tg is approached? Why is this
growth super-Arrhenius?
•
Can one understand and describe quantita-
tively the average dynamical behavior of
supercooled liquids, in particular broad relax-
ation spectra, non-exponential behavior, and
their evolution with fragility?
•
Is there a relation between kinetics and ther-
modynamics (like T0 ’ TK), and why?
•
Can one understand and describe quantita-
tively the spatiotemporal ﬂuctuations of the
dynamics? How and why are these ﬂuctuations
related to the dynamic slowing down?
•
Is the glass transition a collective phenome-
non? If yes, of which kind? Is there a ﬁnite
temperature or zero temperature ideal glass
transition?
•
Is the slowing down of the dynamics driven by
the growth of amorphous order and a static
length? Or is its origin purely dynamic?
•
Is there a geometric, real space explanation for
the dynamic slowing down that takes into
account molecular degrees of freedom?
The glass transition appears as a kind of “inter-
mediate coupling” problem, since for instance
typical growing lengthscales are found to be at
most a few tens of particles large close to Tg. It
would therefore be difﬁcult to recognize the cor-
rect theory even if one bumped into it. To obtain
quantitative, testable predictions, one must there-
fore be able to work out also preasymptotic
effects. This is particularly difﬁcult, especially in
cases where the asymptotic theory itself has not
satisfactorily been worked out. As a consequence,
at this time, theories can only be judged by their
overall predictive power and their theoretical
consistency.
Random First-Order Transition Theory
Mean-Field Models and a Zest of Replica Theory
In the last three decades, three independent lines
of research, Adam-Gibbs theory (Adam and
Gibbs
1965),
mode-coupling
theory
(Götze
1999), and spin glass theory (Mézard et al.
1987), have merged to produce a theoretical
252
Glasses and Aging, A Statistical Mechanics Perspective on

ensemble that now goes under the name of Ran-
dom First-Order Transition theory (RFOT), a ter-
minology introduced by Kirkpatrick, Thirumalai,
and Wolynes (Kirkpatrick and Thirumalai 1987;
Kirkpatrick and Wolynes 1987a) who played a
major role in this uniﬁcation. Instead of following
the rambling development of history, we summa-
rize it in a more modern and uniﬁed way.
A key ingredient of RFOT theory is the exis-
tence of a chaotic or complex free energy land-
scape with a speciﬁc evolution with temperature
and/or density. Analyzing it in a controlled way
for three-dimensional interacting particles is an
impossible task. This can be achieved, however,
in simpliﬁed models or using mean-ﬁeld approx-
imations that have therefore played a crucial role
in the development of RFOT theory.
A ﬁrst concrete example is given by “lattice
glass models” (Biroli and Mézard 2001). These
are models of hard particles sitting on a lattice.
The Hamiltonian is inﬁnite either if there is more
than one particle on a site or if the number of
occupied neighbors of an occupied site is larger
than a parameter m, but is zero otherwise. Tuning
the parameter m, or changing the type of lattice, in
particular its connectivity, yields different models.
Lattice glasses are constructed as simple statmech
models to study the glassiness of hard sphere
systems. The constraint on the number of occu-
pied neighbors mimics the geometric frustration
(Nelson 2002) encountered when trying to pack
hard spheres in three dimensions. Numerical sim-
ulations show that their phenomenological glassy
behavior is indeed analogous to the one of super-
cooled liquids (Darst et al. 2010; Seif and Grigera
2016; Nishikawa and Hukushima 2020). Other
models with a ﬁnite energy are closer to molecular
glass-formers,
and
can
also
be
constructed
(McCullagh et al. 2005). These models can be
solved exactly on a Bethe lattice, which reveals a
rich physical behavior (Rivoire et al. 2004).
(In order to have a well-deﬁned thermodynamics,
Bethe lattices are generated as random graphs
with ﬁxed connectivity, also called random regu-
lar graphs.) In particular their free energy land-
scape can be analyzed in full details and turns out
to have the properties that are also found in several
“generalized spin glasses.” Probably the most
studied example of such spin glasses is the
p-spin model, deﬁned by the Hamiltonian (Gross
and Mézard 1984)
H ¼ 
X
i1, ..., ip
Ji1,...,ipSi1...Sip,
ð16Þ
where the Si’s are N Ising or spherical spins, p > 2
is the number of interacting spins in a single term
of the sum, and Ji1,...,ip quenched random cou-
plings extracted from a distribution which, with
no loss of generality, can be taken as the Gaussian
distribution
with
zero
mean
and
variance
p!/(2Np–1). In this model, the couplings Ji1,...,ip
play the role of self-induced disorder in glasses,
and promote a glass phase at low temperature.
All these models can be analyzed using the
so-called replica theory (Mézard et al. 1987).
Given its importance in setting the foundations
of the theory of glasses at the mean-ﬁeld level,
we now present its main technical steps. To
keep the discussion as simple as possible, we
focus on p-spin models. Note that the theory
holds for more complex models but it is tech-
nically more involved. The starting point is the
computation
of
the
free-energy
which
is
obtained as an average over the distribution of
couplings:
F ¼ lim
N!1  1
bN log ZJ,
ð17Þ
where   represents the average over the disorder.
Performing this average is possible thanks to the
replica trick
log ZJ ¼ lim
n!0
1
n log Zn,
ð18Þ
where n is the index of replicas, that is, clones of
the same system with different couplings Ji1,...,ip
extracted from the same distribution. The use of
the replica trick may seem purely mathematical,
yet it has a profound physical sense. If the system
is ergodic, averages of thermodynamical observ-
ables for two replicas of the same system (with
identical disorder) coincide, whereas they differ if
ergodicity is broken. We can deﬁne the overlaps
Glasses and Aging, A Statistical Mechanics Perspective on
253

between two replicas a, b as Qab, which deﬁnes
the n  n overlap matrix:
Qab ¼ 1
N
X
N
i¼1
Sa
i Sb
i ,
ð19Þ
where the product between spins represents a dot
product
for
spherical
spins
(Castellani
and
Cavagna 2005). After some computations, the
free energy can be expressed as a function of
Qab, which therefore plays the role of the order
parameter. In the ergodic phase one expects sym-
metry between replicas (if additional symmetries
are broken, then one can have ergodicity breaking
also in the RS phase), and the so-called replica-
symmetric
(RS) parameterization
of
Qab is
adopted: all the off-diagonal elements of Qab are
equal to q0 < 1 and the diagonal elements are
Qaa ¼ 1. The parameterization that corresponds
to the glass phase, when ergodicity is broken, is
the so-called one-step replica symmetry breaking
(1RSB) solution. Here, the overlap matrix is
divided into blocks of dimension m m; elements
belonging to blocks far from the diagonal are
equal to q0, while off-diagonal elements of blocks
along
the
diagonal
are
equal
to
q1
with
1 > q1 > q0. On the diagonal Qaa ¼ 1. This
parameterization encodes the existence of many
thermodynamically equivalent basins, hence two
replicas can either fall in the same basin and have
overlap q1, or fall in two different basins and have
overlap q0. The crucial simpliﬁcation introduced
by the mean-ﬁeld approximation is that barriers
between basins have a free energy cost which
grows exponentially with N, so that truly metasta-
ble states can be deﬁned in the thermodynamic
limit (Cavagna 2009). At high temperature (or low
density) the RS solution has a lower free energy.
Below the ideal glass transition temperature the
1RSB solution instead becomes dominant.
Liquids and Glasses in Infinite Dimensions
A major theoretical breakthrough of the last years
is the analysis of the glass transition for interacting
particle systems in the limit of inﬁnite dimensions
(Kurchan et al. 2012, 2013; Charbonneau et al.
2014a, b; Parisi et al. 2020). The starting point
approach is the deﬁnition of a pair interaction
potential with a proper scaling with dimension
d to ensure a nontrivial thermodynamic limit:
u rð Þ ¼ eu d r=‘  1
ð
Þ
½

ð20Þ
where ‘ deﬁnes the range of the interaction. Many
different potentials used to model glasses can be
written in this way by using a suitable function
eu x
ð Þ , such as hard spheres, Lennard-Jones,
Yukawa, square-well, harmonic, and Weeks-
Chandler-Andersen
potentials
(Parisi
et
al.
2020). In the limit of inﬁnite space dimension,
d ! 1, and using the scaling above, the thermo-
dynamics and the dynamics of liquids and glasses
can be analyzed exactly. (For large d the crystal-
line phase does not intervene. In fact, the amor-
phous and crystalline solid phases are well
separated in conﬁguration space and issues related
to ﬁnite dimensions, such as the crystallization of
monodisperse particles, are suppressed (Skoge
et al. 2006; van Meel et al. 2009).) The resulting
theory is qualitatively very similar to the one
obtained from the simple models discussed in
the previous section (both for the statics, in
terms of replica formalism, and for the dynamics,
in terms of self-consistent Langevin equations).
In fact, all these models belong to the univer-
sality class of 1RSB systems (Charbonneau et al.
2014b), with a free-energy landscape evolving as
in the sketch in Fig. 13. At low densities or high
enough temperatures, they all describe an ergodic
liquid phase, analogous to the paramagnetic phase
of a spin glass. Under cooling or application of an
external pressure, the free energy breaks up into
many different minima which eventually trap the
dynamics, and the system enters the glass phase,
as described further below.
The merit of the inﬁnite dimensional theory is
that it offers quantitative results and applies
directly to microscopic models of liquids and
glasses. Moreover, it directly reveals the nature
of “mean-ﬁeld” theories and approximations,
such as the diagrammatic liquid theory and
Mode-Coupling Theory. Last but not least, it
establishes once and for all that the 1RSB phase
and associated physics and phase transition is the
correct and universal mean-ﬁeld theory of glass-
forming models.
254
Glasses and Aging, A Statistical Mechanics Perspective on

Random First-Order Transitions
We now discuss the physics associated to the
1RSB phase transition, and more generally to
RFOT. The free energy landscape of glassy sys-
tems is “rugged,” as shown in Fig. 13. It is char-
acterized by many minima and saddle points of
various orders. Actually, the number of stationary
points is so large that in order to count them one
has to introduce an entropy, called conﬁgurational
entropy or complexity, sc ¼ 1
N log N
f
ð Þ, where
N
f
ð Þ is the number of stationary points with a
given free energy density f. The (real space) den-
sity proﬁle corresponding to one given minimum
is amorphous and lacks any type of periodic long-
range order, and different minima are very differ-
ent from one another. Deﬁning a similarity mea-
sure between them, an “overlap” Q (see Eq. (39)
below for a precise deﬁnition), one typically ﬁnds
that two minima with the same free energy f have
zero overlap. The typical shape of the conﬁgura-
tional entropy as a function of f is shown in
Fig. 14.
At high temperature, there is typically a single
minimum, the high temperature liquid state. There
is a temperature below which an exponentially
large (in the system size) number of minima
appear. Within mean-ﬁeld models, corresponding
to Bethe lattices, completely connected lattices,
and interacting particles for d ! 1 these minima
correspond to macroscopic physical states analo-
gous to the periodic minimum corresponding to
the crystal. (There is of course no crystal state in
disordered systems such as in Eq. (16). In the case
of lattice glass models, there is a crystal phase but
it can disappear depending whether the Bethe
lattice is a Cayley tree or a random regular
graph.) Once the system is in one of these states
it remains trapped there forever, since the barriers
separating states diverge with the system size.
However, when transposed to ﬁnite dimensional
systems, these states become metastable and have
a ﬁnite lifetime. As a consequence, in order to
compute thermodynamic properties, one has to
sum over all of them using the Boltzmann weight
exp(βNfα) for each state α (Monasson 1995):
Z ¼
X
a
ebNf a
¼
ð
df exp Nsc f; T
ð
Þ
½
ebNf ,
ð21Þ
where β ¼ 1/(KBT). Evaluating this sum by saddle
point method yields three regimes. At high tem-
perature, T > TMCT, the liquid corresponding to a
ﬂat density proﬁle dominates the sum. The land-
scape is simple and has a single minimum. This is
followed by an intermediate temperature regime,
TK < T < TMCT, where the sum is dominated by all
terms with free energy density satisfying
@sc f, T
ð
Þ
@f

f¼ f  ¼ b:
ð22Þ
There are many of them, the logarithm of their
number being given by Nsc(f*, T), see Fig. 14 for a
graphical solution of Eq. (22). Upon decreasing
a
b
jjg
jjg
Glasses and Aging, A Statistical Mechanics Perspec-
tive on, Fig. 13 Sketch of the evolution of free-energy
landscape of hard spheres across the glass transition. In the
liquid phase (a) at low packing fractions ’ < ’g, every
portion of the phase space is accessible. For ’ < ’g the
system is in the glass phase (b) and remains trapped in one
of the many equivalent basins
Glasses and Aging, A Statistical Mechanics Perspective on
255

the temperature, sc( f*, T) decreases until a tem-
perature, TK, below which the sum in Eq. (21)
becomes
dominated
by
only
few
terms
corresponding to states with free energy density
fK given by sc( fK, T) ¼ 0, see Fig. 14. The entropy
in the intermediate temperature range above TK
has two contributions: the one counting the num-
ber of minima, given by sc, and the intra-state
entropy, sin, counting the number of conﬁgura-
tions inside each state. At TK, the conﬁgurational
entropy vanishes, sc(TK) ¼ 0. As a consequence
the speciﬁc heat undergoes a jump toward a
smaller value across TK, an exact realization of
the “entropy vanishing” mechanism conjectured
by Kauzmann (1948).
Let us discuss the dynamical behavior which
results from the above analysis. We have already
mentioned that relaxation processes do not occur
below TMCT because states have an inﬁnite life-
time. The stability of these states can be analyzed
by computing the free energy Hessian in the min-
ima (Castellani and Cavagna 2005). One ﬁnds that
states become more fragile when T ! T
MCT are
marginally stable at T ¼
TMCT, unstable for
T > TMCT. The relaxation dynamics of these
models can be analyzed exactly (Barrat et al.
2004; Maimbourg et al. 2016). Coming from
high temperature, the dynamics slows down and
the relaxation time diverges at TMCT in a power law
manner,
ta 	
1
T  TMCT
ð
Þg ,
ð23Þ
where γ is a critical exponent. The physical reason
is the incipient stable states that appear close to
TMCT. The closer the temperature is to TMCT, the
longer it takes to ﬁnd an unstable direction to
relax.
Amazingly,
the
dynamical
transition
that
appears upon approaching TMCT in random ﬁrst-
order landscapes is completely analogous to the
one predicted for supercooled liquids by the
Mode-Coupling Theory (MCT) of the glass tran-
sition,
and
developed
independently
by
Leuthesser, Bengtzelius, Götze, Sjolander, and
coworkers (Götze 1999). Actually, MCT can be
considered as an approximation which becomes
controlled and exact for these mean-ﬁeld models.
Originally, MCT was developed using projector
operator
formalism
(Leutheusser
1984;
Bengtzelius et al. 1984) and ﬁeld-theory methods
(Das and Mazenko 1986) to yield closed integro-
differential equations for the dynamical structure
factor in supercooled liquids. These approaches
were recently generalized (Biroli and Bouchaud
2004; Biroli et al. 2006) to deal with dynamic
heterogeneity and make predictions for the multi-
point susceptibilities and correlation functions
discussed in section “Dynamic Heterogeneity.”
Within MCT, the relaxation timescale diverges
in a power law fashion at TMCT, as in Eq. (23).
This divergence is accompanied by critical behav-
ior that appears both in space (long range spatial
dynamic
correlations),
and
in
time
(time-
dependent power laws).
Comparing Eqs. (1) and (23) makes it clear that
MCT cannot be used to describe viscosity data
close to Tg since it does not predict activated
behavior. It is recognized that an MCT transition
at TMCT does not occur in real materials, so that
TMCT is, at best, a dynamical crossover. A central
advantage of MCT compared to many other theo-
ries is that it can yield quantitative predictions
from microscopic input obtained for a particular
1/TMCT
1/T
1/TK
fMCT
f
fK
f
sc
Glasses and Aging, A Statistical Mechanics Perspec-
tive on, Fig. 14 Typical shape of the conﬁgurational
entropy, sc, as a function of free energy density, f in the
range Tk < T < TMCT for random ﬁrst-order landscapes.
A graphical solution of Eq. (22) is obtained by ﬁnding the
value of f at which the slope of the curve is 1/T. Note that
sc is also a function of temperature, so this curve changes
with T
256
Glasses and Aging, A Statistical Mechanics Perspective on

material. As such it has been applied to scores of
different systems, with predictions that can be
directly confronted to experimental or numerical
measurements. A major drawback is the freedom
offered by the “crossover” nature of the MCT
transition, so that “negative” results can often be
attributed to corrections to asymptotic predictions
rather than deﬁciencies of the theory itself. Nev-
ertheless, MCT has proven to be useful and con-
tinues to be developed, applied, and generalized to
study many different physical situations (Götze
1999), including aging systems and nonlinear
rheology of glassy materials (Berthier et al.
2000; Miyazaki and Reichman 2002; Fuchs and
Cates 2002), see also section “Aging and Off-
Equilibrium Dynamics.”
What happens below TMCT in a ﬁnite dimen-
sional system if the relaxation time does not
diverge as predicted in Eq. (23)? Why is the
transition avoided? In fact, the plethora of states
that one ﬁnds in mean-ﬁeld are expected to
become (at best) metastable in ﬁnite dimension,
with a ﬁnite lifetime, even below TMCT. What is
their typical life time and how these metastable
states are related to the structural relaxation are
issues that still await for a complete microscopic
analysis.
There exist, however, phenomenological argu-
ments (Xia and Wolynes 2000; Kirkpatrick et al.
1989; Bouchaud and Biroli 2004), backed by
microscopic computations (Dzero et al. 2005;
Franz 2006) that yield a possible solution dubbed
“mosaic state” by Kirkpatrick, Thirumalai, and
Wolynes (1989). Schematically, the mosaic pic-
ture states that, in the regime TK < T < TMCT, the
liquid is composed of domains of linear size x.
Inside each domain, the system is in one of the
mean-ﬁeld states. The length of the domains is
ﬁxed by a competition between energy and con-
ﬁgurational entropy. A state in a ﬁnite but large
region of linear size l can be selected by appropri-
ate boundary conditions that decrease its free
energy by an amount which scales as Ulθ with
θ  2. On the other hand, the system can gain
entropy, which scales as scl3, if it visits the other
numerous states. Entropy obviously gains on
large lengthscales, the crossover length x being
obtained by balancing the two terms,
x ¼
U
Tsc T
ð Þ

1= 3y
ð
Þ
:
ð24Þ
In this scenario, the conﬁgurational entropy on
scales smaller than x is too small to stir the con-
ﬁgurations efﬁciently and win over the dynami-
cally
generated
pinning
ﬁeld
due
to
the
environment, while ergodicity is restored at larger
scale. Hence, the relaxation time of the system is
the relaxation time, t(x), of ﬁnite size regions.
Barriers are ﬁnite, unlike in the mean-ﬁeld treat-
ment. Smaller length scales are faster but unable
to decorrelate, whereas larger scales are orders of
magnitude slower. Assuming thermal activation
over energy barriers which are supposed to grow
with size as xc, one ﬁnally predicts, using
Eq. (24), that (Bouchaud and Biroli 2004)
log
ta
t0


¼ c U
kBT
U
Tsc T
ð Þ

c= 3y
ð
Þ
,
ð25Þ
where c is a constant.
The above argument is rather generic and
therefore not very predictive. There exist micro-
scopic computations (Dzero et al. 2005; Franz
2006; Biroli and Cammarota 2017) aimed at put-
ting these phenomenological arguments on a
ﬁrmer basis and computing the exponents θ and
c. The results are not yet fully conclusive because
they involve replica calculations with some
assumptions, but they do conﬁrm the phenome-
nological scenario presented above and suggest
that θ ¼ 2. Some other phenomenological argu-
ments suggest the value of θ ¼ 3/2 (Kirkpatrick
et al. 1989). There are no computation available
for c, only the suggestion that c ¼ 0 (Kirkpatrick
et al. 1989).
Note that using the value θ ¼ 3/2 with θ ¼ c
simpliﬁes Eq. (25) into a form that is well-known
experimentally and relates log tα directly to 1/Sc,
which is the celebrated Adam-Gibbs relation
(Adam and Gibbs 1965) between relaxation time
and conﬁgurational entropy that is in rather good
quantitative agreement with many experimental
results (Angell 1997; Hodge 1997; Johari 2000;
Ozawa et al. 2019). The Random First-Order
Transition theory can be considered, therefore,
Glasses and Aging, A Statistical Mechanics Perspective on
257

as a microscopic theory that reformulates and
generalizes the Adam-Gibbs mechanism. Further-
more, using the fact that the conﬁgurational
entropy vanishes linearly at TK, a VFT divergence
of the relaxation time as in Eq. (1) is predicted,
with the identiﬁcation that
T0 ¼ TK:
ð26Þ
The equality (26) between two temperatures
that are commonly used in the description of exper-
imental data certainly constitutes a central achieve-
ment of RFOT theory since it accounts for the
empirical relation found between the kinetics and
the thermodynamics of supercooled liquids. Fur-
thermore RFOT theory naturally contains MCT,
which can be used to describe the ﬁrst decades of
the dynamical slowing down, while the spin glass
side of RFOT theory qualitatively explains the
dynamics in terms of the peculiar features of the
free energy landscape that have been detailed
above. Dynamics ﬁrst slows down because there
appear incipient metastable states, and once these
metastable
states
are
formed,
the
dynamics
becomes dominated by the thermally activated bar-
rier crossing from one metastable state to another,
which is consistent with the relation between
dynamical
correlation
length
and
timescale
discussed in section “Dynamic Heterogeneity.”
Quite importantly, microscopic computations of
TMCT and T0 for realistic models of liquids are pos-
sible (Parisi et al. 2020; Mézard and Parisi 1999).
Probably the most serious weakness of the
RFOT theory construction is that the theory,
although worked out in full details within mean-
ﬁeld models or the large dimensionality limit, is
based for ﬁnite dimensions on asymptotic results
valid, for example, for T ! TK. The application of
RFOT theory to temperatures accessible in exper-
iments (hence not very close to TK) requires addi-
tional phenomenological assumptions. Moreover,
the dynamical processes leading to the VFT law
are not understood completely. Although the ulti-
mate consequences of the theory are sometimes in
very
good
agreement
with
experiments,
as
Eq. (26), direct tests of the mosaic state picture
are rare and difﬁcult (Cavagna et al. 2007; Ozawa
and Berthier 2017).
Heterogeneous Disorder and Mapping to the
Random, Field Ising Model
The study of second-order phase transitions
shows that ﬁeld theory provides a natural frame-
work to go beyond mean-ﬁeld theory (Chaikin
et al. 1995). With this in mind, researchers in
glass physics have also gone down this route in
recent years. One of their main achievements has
been to identify ﬂuctuations that are neglected by
mean-ﬁeld theory and play a very important role
in shaping the physical behavior of supercooled
liquids. These ﬂuctuations have been related to
the notion of “self-induced disorder” in Franz
et al. (2011). In the following, we may prefer the
name “self-induced heterogeneity” to make the
distinction
with
the
“self-induced
disorder”
discussed in section “Franz-Parisi Potential.”
(This terminology was suggested to us by Jean-
Philippe Bouchaud.) The main idea is that when
observing equilibrium relaxation from time t to
time t þ tα, the state of the system at time t is
spatially heterogeneous: for instance it can have
higher density in one region and lower density in
another. Actually, theoretical analysis shows
(Stevenson et al. 2008; Biroli et al. 2018a, b)
that even key mean-ﬁeld quantities, such as the
conﬁgurational entropy, are heterogeneously dis-
tributed in space. Since the amount of slowing
down is directly linked to those quantities
(at least within RFOT theory), these static ﬂuctu-
ations induce strong dynamical ﬂuctuations, lead-
ing in particular to dynamical heterogeneities
(Franz et al. 2011). From the theoretical point of
view, they play a key role in changing properties
of the MCT transition and the ideal glass transi-
tion. In fact, even though the MCT transition is
like a spinodal instability within mean-ﬁeld the-
ory (Kirkpatrick and Wolynes 1987b), one ﬁnds
that once these ﬂuctuations are included, MCT
enters the universality class of a disordered
spinodal, like, for example, the spinodal of the
Random Field-Ising Model (Franz et al. 2011).
Using results obtained on this problem, this con-
nection implies that even in the absence of acti-
vated hopping, the MCT transition changes nature
in any ﬁnite dimension: it is either wiped out by
non-perturbative ﬂuctuations (Rizzo 2016) or it
becomes dominated by rare and non-perturbative
258
Glasses and Aging, A Statistical Mechanics Perspective on

events, as happens for the spinodal of the RFIM
(Nandi et al. 2016). One nevertheless expects that
the higher the spatial dimension, the more obvious
an echo of the MCT mean-ﬁeld transition should
persist (Maimbourg et al. 2016; Biroli and
Bouchaud 2012; Berthier et al. 2020).
Finally, the role of heterogeneous disorder
on the ideal glass transition has been investi-
gated in Stevenson et al. (2008) and Biroli et al.
(2018a, b). The main outcome of these studies
is an effective model for the glass transition
that takes the form of an RFIM with extra
long-range anti-ferromagnetic and multi-body
interactions. These new couplings depress the
ideal glass transition temperature but do not
lead to qualitative changes. The strength of
the disorder is, however, crucial: a strong
enough disorder (a system-dependent feature)
can destroy the ideal glass transition, as may
happen for the RFIM. Another relation with the
RFIM was also found in Biroli and Bouchaud
(2012), where it was shown that amorphous
interfaces between rearranging regions behave
statistically as the ones of domain walls in
the RFIM.
Let us conclude with a word of caution: not
everything is understood about self-induced
heterogeneity. Since the disorder is strongly
linked to the state of the system, it is also to a
large extent renewed after a time tα, thus it
evolves and at the same time it affects the
dynamics, that is, it is not truly quenched.
This is a ﬁrst difﬁculty in assessing precisely
its role for glassy relaxation (Berthier et al.
2019c). A second one is that although for static
properties, such as conﬁgurational entropy or
the Franz-Parisi potential, one can establish a
mapping to the RFIM, for the dynamics the
situation is more intricate and no mapping has
been found up to now. (The difﬁculty is that the
mapping to the RFIM proceeds by relating the
overlap (for glasses) to the magnetization (for
the RFIM). There are no natural dynamical
equations for the overlap, and in the only
cases where those have been established – the
β-regime of MCT – these proved to be quite
complex and different from the corresponding
equations for the magnetization of the RFIM.)
Renormalization Group for the Glass Transition
In parallel with the efforts described in the previ-
ous section, developing a renormalization group
(RG) analysis of the glass transition has been a
new important theoretical activity in the last
decade. Different methods have been used, and
were applied on lattice disordered models and
replica lattice ﬁeld theories which display a glass
transition. Given that the ideal glass transition has
a mixed character, intermediate between ﬁrst- and
second-order phase transition, usual perturbative
RG techniques developed for continuous phase
transitions do not work. Therefore researchers
had to focus on non-perturbative methods. In
Castellana et al. (2010) the hierarchical Dyson
RG method was employed to analyze the Random
Energy Model in ﬁnite dimension. The authors
found an ideal glass phase transition similar to
the one taking place within mean-ﬁeld but with a
nonanalytical behavior of the free-energy at TK,
leading in particular to a speciﬁc heat exponent
different from one, as assumed within RFOT the-
ory. The real-space properties, correlation length
and energy barrier, and the nature of the ﬁxed-
point were ﬁrst studied in Yeo and Moore (2012)
and Cammarota et al. (2011) by Migdal-Kadanoff
RG. A complete and more advanced analysis was
performed in Angelini and Biroli (2017), in which
it was shown that the ideal glass transition is
associated to a so-called zero temperature ﬁxed
point (Fisher 1986). The main implication is that
the correlation length and the typical energy bar-
rier have power law divergences with nontrivial
exponents, hence implying a super-Arrhenius
behavior. However, such a ﬁxed point was found
only in dimensions higher than three. In conse-
quence, this RG treatment predicts that in three
dimensions the glass transition is actually an
avoided phase transition (Kivelson et al. 1995):
glassy behavior is still driven by the RG ﬁxed
point present in higher dimension, but the corre-
lation length and the timescale do not truly
diverge (arguably an irrelevant fact since one can-
not approach the transition close enough, but an
important conceptual one).
The RG approaches we reviewed above offer a
new perspective on the nature of the glass transi-
tion. They provide important guidelines for more
Glasses and Aging, A Statistical Mechanics Perspective on
259

controlled non-perturbative RG treatments. Ide-
ally, one would like to tackle directly interacting
particle systems in the continuum and use
methods that have been proved to be precise and
reliable in previous studies, such as the one devel-
oped by Wetterich (Berges et al. 2002). This is a
formidable challenge as those techniques do not
seem to be able to handle the kind of rare and
localized non-perturbative events that are relevant
for glassy dynamics (Rulquin et al. 2016).
Free Volume, Defects, and Facilitated Models
Lattice Gases
In this subsection we motivate and brieﬂy summa-
rize studies of a different family of statistical
mechanics models that turns out to yield a rich
variety of physical behaviors. Their starting points
are physical assumptions that might seem similar to
the models described in section “Random First-
Order Transition Theory,” but the outcome yields
a different physical explanation of the glass transi-
tion. Although the two theoretical approaches can-
not be simultaneously correct, they both have been
inﬂuential and very instructive in order to develop a
theoretical understanding of glassy phenomena.
As in section “Random First-Order Transition
Theory,” we ﬁrst consider hard sphere systems.
We follow the lattice gas description introduced
by Kob and Andersen (1993), and work on a
three-dimensional cubic lattice. As in a hard
sphere system, we assume no interaction between
particles beyond the hard-core constraint that the
occupation number ni at site i is at most equal to 1,
H
ni
f g
½
 ¼ 0, ni ¼ 0, 1:
ð27Þ
In contrast to the lattice glass model, all con-
ﬁgurations respecting the hard-core constraint are
allowed and are equally probable. Geometric frus-
tration is instead introduced at the level of the
kinetic rules, which are deﬁned as constrained
local moves. Namely, a particle can jump to a
nearest neighbor site only if that site is empty
(to satisfy the hard-core constraint), but, addition-
ally, only if the sites occupied before and after the
move have less than m neighbors, m being an
adjustable parameter, which Kob and Andersen
choose as m ¼ 4 for d ¼ 3 (m ¼ 6 corresponds to
the unconstrained lattice gas). The model captures
the idea that if the liquid if locally very dense, no
movement is possible while regions with low
density move more easily.
Of course, such kinetically constrained lattice
gases have been studied in various spatial dimen-
sions, for different values of m, for different con-
straints, or even different lattice geometries (Ritort
and Sollich 2003). These models capture the idea
of a “cage” effect in a strict sense, meaning that a
particle with a dense neighbor shell cannot diffuse.
Although the cage seems a purely local concept, it
turns out that diffusion in constrained lattice gases
arises from cooperative rearrangements, so that
slow dynamics can be directly shown to be driven
by the growth of dynamic lengthscales for these
cooperative moves (Franz et al. 2002; Toninelli
et al. 2004; Pan et al. 2005). This strongly suggests
that such cooperative moves most probably have a
role in the dynamics of real liquids.
Free Volume, Dynamic Criticality
In the lattice gas picture, the connection with the
liquid is not obvious because it is the density
(“free volume”) rather than the temperature that
controls the dynamics. Thermal models with sim-
ilar features can in fact be deﬁned along the fol-
lowing lines. In a liquid, low temperature implies
a very small probability to ﬁnd a location with
enough free volume to move. The idea of a small
concentration of “hot spots” is in fact reminiscent
of another picture of the glass transition based on
the idea of “defects” which is captured by the
defect model proposed by Glarum (1960) in the
1960s, where relaxation proceeds via the diffusion
of a low concentration of independent defects. In
the mid-1980s, using both ideas of kinetic con-
straints and rare defects, Fredrickson and Ander-
sen deﬁned a family of kinetic Ising models for the
glass transition (Fredrickson and Andersen 1984).
They studied an assembly of noninteracting spins,
H
ni
f g
½
 ¼
X
N
i¼1
ni, ni ¼ 0, 1,
ð28Þ
where ni ¼ 1 represents the defects, whose con-
centration becomes exponentially small at low
260
Glasses and Aging, A Statistical Mechanics Perspective on

temperature, hnii ≈exp (1/T). As for the Kob-
Andersen lattice gas, the nontrivial ingredient lies
in the chosen rates for the kinetic transitions
between states. The kinetic rules stipulate that a
transition at site i can happen with a usual Glauber
rate, but only if site i is surrounded by at least
k defects (k ¼ 0 corresponds to the unconstrained
limit). Again, one can easily imagine studying
such models in different spatial dimensions, on
different lattices, and with slightly different
kinetic rules, yielding a large number of possible
behaviors (Ritort and Sollich 2003; Léonard et al.
2007). The similarity between those spin facili-
tated models and the kinetically constrained lat-
tice gases is striking. Altogether, they form a large
family of models generically called kinetically
constrained models (KCMs) (Ritort and Sollich
2003).
The connection between KCMs and the much
older concept of free volume is obvious from our
presentation. Free volume models are among the
most widely used models to analyze experimental
data, especially in polymeric systems. They have
been thoroughly reviewed before (Debenedetti
1996; Cohen and Grest 1982), and the main predic-
tion is that dynamic slowing down occurs because
the free volume available to each particle, uf, van-
ishes at some temperature T0 as uf ≈α(T  T0).
Statistical arguments then relate relaxation time-
scales to free volume assuming that a movement is
possible if locally there is “enough” available free
volume, more than a typical value u0. This is clearly
reminiscent of the above idea of a kinetic constraint
for local moves in lattice gases. An appealing VFT
divergence is then predicted:
ta
t0 	 exp
g u0
u f


~
exp
gu0=a
T  T0
j
jm


,
ð29Þ
where γ is a numerical factor and m ¼ 1. Pre-
dictions such as Eq. (29) justify the wide use of
free
volume
approaches,
despite
the
many
(justiﬁed) criticisms that have been raised.
Initially it was suggested that KCMs would
similarly display ﬁnite temperature or ﬁnite den-
sity dynamic transitions similar to the one pre-
dicted
by
the
mode-coupling
theory
of
supercooled liquids (Fredrickson and Andersen
1984), but it was soon realized (Fredrickson and
Brawer 1986; Butler and Harrowell 1991) that
most KCMs do not display such singularity, and
timescales in fact only diverge in the limit of zero
temperature (T ¼ 0) or maximal density (r ¼ 1).
Models displaying a Tc > 0 or rc < 1 transition
have also been introduced and analyzed (Toninelli
et al. 2006). They provide a microscopic realiza-
tion, based on well-deﬁned statistical mechanics
models, of the glass transition predicted by free
volume arguments. Their relaxation timescale
diverges with a VFT-like form but with an expo-
nent m ’ 0.64. Understanding their universality
classes or the degree of generality of the mecha-
nism leading to the transition is still an open
problem (Elmatad et al. 2009, 2010; Elmatad
and Keys 2012); the most recent results on this
front come from mathematical physicists who
have been able to classify many of the different
possible behaviors on the basis of the microscopic
dynamical rules (Hartarsky et al. 2019a, b;
Martinelli et al. 2019a, b).
Extensive studies have shown that KCMs have
a macroscopic behavior which resembles the phe-
nomenology of supercooled liquids, displaying in
particular
an
Arrhenius
or
super-Arrhenius
increase of relaxation timescales upon decreasing
temperature, and non-exponential relaxation func-
tions at equilibrium (Ritort and Sollich 2003).
Early studies also demonstrated that, when sud-
denly quenched to very low temperatures, the
subsequent nonequilibrium aging dynamics of
these models compares well with experimental
observations on the aging of liquids (Fredrickson
and Brawer 1986). The diverse deﬁnitions of such
models suggest a broad variety of different behav-
iors. This feature is both positive and negative: on
the one hand one can explore various scenarios to
describe glass transition phenomena, but on the
other hand, one would like to be able to decide
what particular model should be used to get a
quantitative description for a particular liquid. It
is not straightforward to perform microscopic pre-
dictions using the framework of KCMs, since
there is no direct observable parameter to use as
input of the theory (unlike g(r), for MCT). An
operative deﬁnition of KCMs’ defects was pro-
vided (see next section and Keys et al. (2011,
Glasses and Aging, A Statistical Mechanics Perspective on
261

2013)); however, this does not allow to directly
choose which KCM (which rules) are appropriate
for a given liquid.
Despite this caveat, it is quite useful to use
KCMs as theoretical tools to deﬁne concepts and
obtain new ideas. It is precisely in this perspective
that interest in KCMs has increased, in large part
since it was realized that their dynamics is spa-
tially heterogeneous (Franz et al. 2002; Butler and
Harrowell 1991; Garrahan and Chandler 2002), a
central feature of supercooled liquids dynamics.
In particular, virtually all the aspects related to
dynamic heterogeneity mentioned in section
“Dynamic Heterogeneity” can be investigated
and rationalized, at least qualitatively, in terms of
KCMs. The dynamics of these systems can be
understood by considering where “relaxation”
happens and then propagate, which is dictated by
the underlying defect motion (Ritort and Sollich
2003). Depending on the particular model, defects
can diffuse or have a more complicated motion.
Furthermore, they can be point-like or “coopera-
tive” (formed by point-like defects moving in a
cooperative way). A site can relax only when it is
visited by a defect. As a consequence, the hetero-
geneous character of the dynamics is entirely
encoded in the defect conﬁguration and defect
motion (Garrahan and Chandler 2002). For
instance, a snapshot similar to Fig. 6 in a KCM
shows clusters which have relaxed within the time
interval t (Whitelam et al. 2005; Berthier and
Garrahan 2005). These are formed by all sites
visited by a defect between 0 and t. The other
sites are instead frozen in their initial state. In
these models the dynamics slows down because
the defect concentration decreases. As a conse-
quence, in the regime of slow dynamics there are
few defects and strong dynamic heterogeneity.
Detailed numerical and analytical studies have
indeed
shown
that
in
these
systems,
non-
exponential relaxation patterns do stem from a
spatial, heterogeneous distribution of timescales,
directly connected to a distribution of dynamic
lengthscales (Toninelli et al. 2004, 2006; Pan
et al. 2005; Garrahan and Chandler 2002;
Whitelam et al. 2005; Jack et al. 2006a).
Decoupling phenomena also appear naturally in
KCMs and can be shown to be very direct,
quantiﬁable, consequences of the dynamic hetero-
geneity (Jung et al. 2004), which also deeply
affects the process of self-diffusion in a system
close to its glass transition (Berthier et al. 2004).
More fundamentally, multipoint susceptibilities
and multipoint spatial correlation functions such
as the ones deﬁned in Eqs. (8) and (11) can be
studied in much greater detail than in molecular
systems, relating their evolution to time and
length scales (Berthier et al. 2007b; Toninelli
et al. 2005; Pan et al. 2005; Chandler et al. 2006;
Whitelam et al. 2004). This type of scaling behav-
ior has been observed close to T ¼ 0 and r ¼ 1 in
spin models and lattice gases without a transition.
(Acritical (diérent) behavior is expected and pre-
dicted for models having a transition (Toninelli
et al. 2006).) Different theoretical approaches
have shown that these particular points of the
phase diagram correspond to genuine critical
points where timescales and dynamic lengthscales
diverge with well-deﬁned critical laws (Jack et al.
2006a; Whitelam et al. 2004). Such “dynamic
criticality” implies the existence of universal scal-
ing behavior in the physics of supercooled liquids,
of the type reported for instance in Fig. 11.
Defects: Connection with Hamiltonian Dynamics
Models
A
central
criticism
about
the
free
volume
approach, that is equally relevant for KCMs, con-
cerns the identiﬁcation, at the molecular level, of
the vacancies (in lattice gases), mobility defects
(in spin facilitated models), or of the free volume
itself. The attempts to provide reasonable coarse-
graining from molecular models with continuous
degrees of freedom to lattice models with kinetic
rules have been, for a very long time, quite limited
and not fully convincing (Gebremichael et al.
2004; Downton and Kennett 2007).
For molecular models, this issue was ﬁrst
attacked in 2010, with a deﬁnition of the cumu-
lated dynamical activity K, an extensive quantity
characterizing the frequency of state changes
(from excited to non-excited and vice versa)
(Elmatad et al. 2010; Hedges et al. 2009). This
deﬁnition was made more concrete and studied in
models of supercooled liquids in Keys et al.
(2011),
where
an
appropriate
functional
is
262
Glasses and Aging, A Statistical Mechanics Perspective on

explicitly designed as a recorder of excitations
(or defects). Defects or excitations are not to be
mistaken with displacements. Indeed, some loca-
tions providing opportunities for structural reor-
ganization do coincide with defects, and their
presence can be inferred by observing nontrivial
particle displacements associated with transitions
between relatively long-lived conﬁgurations. Dis-
placements instead refer to dynamical moves in
short segments of a trajectory, while defects refer
to underlying conﬁgurations. The explicit deﬁni-
tion of defects has since been used to estimate the
role of facilitation in glassy dynamics, to provide a
microscopic validation of KCMs (Keys et al.
2015; Isobe et al. 2016), to explain dynamical
heterogeneities in glassy materials, or to compute
the dynamical facilitation volume (Elmatad and
Keys 2012).
The conceptual proof that kinetic rules emerge
effectively and induce a slow dynamics has been
obtained for simple lattice spin models (Garrahan
2002), with a dynamics that directly maps onto
constrained models. A deeper study of this kind of
model was performed more recently (Turner et al.
2015). Several examples are available but here we
only mention the simple case of the bidimensional
plaquette model deﬁned by a Hamiltonian of a
p-spin type on a square lattice of linear size L,
H ¼ J
X
L1
i¼1
X
L1
j¼1
Si,jSiþ1,jSi,jþ1Siþ1,jþ1,
ð30Þ
where Si,j ¼ 
1 is an Ising variable lying at node
(i, j) of the lattice. Contrary to KCMs, the Hamil-
tonian in Eq. (30) contains genuine interactions,
which are no less (or no more) physical than
p-spin models discussed in section “Random
First-Order Transition Theory.” Interestingly the
dynamics of this system is (trivially) mapped onto
that of a KCM by analyzing its behavior in terms
of plaquette variables, pi, j ¼Si, jSi þ1, jSi, j þ 1Si þ1,
j þ 1, such that the Hamiltonian becomes a non-
interacting one, H ¼  J i, jpi, j, as in Eq. (28).
More interestingly, the analogy also applies to the
dynamics (Garrahan 2002). The fundamental
moves are spin-ﬂips, but when a single spin is
ﬂipped
the
states
of
the
four
plaquettes
surrounding that spin change. Considering the
different types of moves, one quickly realizes
that excited plaquettes, pi,j ¼ +1, act as sources
of mobility, since the energetic barriers to spin
ﬂips are smaller in those regions. This observation
allows to identify the excited plaquettes as
defects, by analogy with KCMs. Spatially hetero-
geneous dynamics, diverging lengthscales accom-
panying
diverging
timescales
and
scaling
behavior sufﬁciently close to T ¼
0 can be
established by further analysis (Jack et al. 2005),
providing a simple but concrete example of how
an interacting many body system might effec-
tively behave as a model with kinetic constraints.
(This type of plaquette models and other spin
models were introduced originally (Lipowski
et al. 2000; Sethna et al. 1991) to show how
ultraslow glassy dynamics can emerge because
of growing free energy barriers.)
Connection with Other Perspectives
An essential drawback of facilitated models is that
among the microscopic “details” thrown away to
arrive at simple statmech models such as the ones
in Eqs. (27) and (28), information on the thermo-
dynamical behavior of the liquids has totally
disappeared. In particular, a possible coincidence
between VFT and Kauzmann temperatures, To
and TK is not expected, nor can the dynamics be
deeply connected to thermodynamics, as in
Adam-Gibbs relations. The thermodynamical
behavior of KCMs appears different from the
one of real glass-formers close to Tg (Biroli et al.
2005). This is probably the point where KCMs
and RFOT approaches differ most obviously.
Even though the dynamics of KCMs shares sim-
ilarities with systems characterized with a com-
plex energy landscape (Berthier and Garrahan
2003; Whitelam and Garrahan 2004), thermody-
namical behaviors are widely different in both
cases, as has been recently highlighted in Jack
and Garrahan (2005) by focusing on the concrete
examples of plaquette models such as in Eq. (30).
Finally, when KCMs were ﬁrst deﬁned, they
were argued to display a dynamical transition of a
very similar nature to the one predicted by MCT
(Fredrickson and Andersen 1984). Although the
claim has been proven wrong, it bears some truth:
Glasses and Aging, A Statistical Mechanics Perspective on
263

both approaches basically focus on the kinetic
aspects of the glass transition and they both pre-
dict the existence of some dynamic criticality with
diverging lengthscales and timescales. (Most
KCMs do not have a ﬁnite temperature dynamical
transition and the ones displaying a transition
have critical properties diérent from MCT.) This
similarity is even deeper, since a modecoupling
singularity is present when (some) KCMs are
studied on the Bethe lattice (Toninelli et al.
2004), but is “avoided” when more realistic lattice
geometries are considered (Berthier et al. 2012).
Geometric Frustration, Avoided Criticality,
and Locally Preferred Structures
In all of the above models, “real space” was pre-
sent in the sense that special attention was paid to
different lengthscales characterizing the physics
of the models that were discussed. However, apart
from the “packing models” with hard-core inter-
actions, no or very little attention was paid to the
geometric structure of local arrangements in
molecular liquids close to a glass transition. This
slight oversight is generally justiﬁed using con-
cepts such as “universality” or “simplicity,”
meaning that one studies complex phenomena
using
simple
models,
a
typically
statistical
mechanics perspective. However, important ques-
tions remain: what is the liquid structure within
mosaic states? How do different states differ?
What is the geometric origin of the defects
invoked in KCMs? Are they similar to defects
found in crystalline materials (disclinations, dis-
locations, vacancies, etc.)? Some lines of research
attempt to provide answers to these questions,
making heavy use of the concept of geometric
frustration.
Geometric Frustration
Broadly speaking, frustration refers to the impos-
sibility of simultaneously minimizing all the inter-
action terms in the energy function of a system.
Frustration might arise from quenched disorder
(as in the spin glass models described above),
but liquids have no quenched randomness. In
liquids, instead, frustration has a purely geometri-
cal origin. It is attributed to a competition between
a short-range tendency for the extension of a
“locally preferred order,” and global constraints
that prevent the periodic tiling of space with this
local structure.
This can be illustrated by considering once
more the packing problem of spheres in three
dimensions. In that case, locally the preferred
cluster of spheres is an icosahedron. However,
the ﬁvefold rotational symmetry characteristic of
icosahedral order is not compatible with transla-
tional symmetry, and formation of a periodic
icosahedral crystal is impossible (Frank 1952).
The geometric frustration that affects spheres in
three
dimensional
Euclidean
space
can
be
relieved in curved space (Nelson 2002). In
Euclidian space, the system possesses topologi-
cal defects (disclination lines), as the result of
forcing the ideal icosahedral ordering into a
“ﬂat” space. Nelson and coworkers developed a
solid theoretical framework based on this picture
to suggest that the slowing down of supercooled
liquids is due to the slow wandering of these
topological defects (Nelson 2002), but their
treatment remains too abstract to obtain quanti-
tative, explicit results. Further theoretical work
extended the integral-equation approach to cal-
culate the pair correlation function in hyperbolic
geometry, making it easier to compare predic-
tions and simulation data (Sausset et al. 2009).
MCT was also re-derived in curved space (on a
sphere), showing that it still cannot capture quan-
titatively the transition (Vest et al. 2014, 2015).
Explicit numerical results were also obtained
recently (Turci et al. 2017a), showing a clear
ﬁrst-order like transition from liquid to ordered
solid in an appropriately curved space, becoming
avoided as Euclidean space is retrieved.
Coulomb Frustrated Theories
The picture of sphere packing disrupted by frus-
tration has been further developed in simple sta-
tistical
models
characterized
by
geometric
frustration,
in
a
pure
statistical
mechanics
approach (Tarjus et al. 2005). To build such a
model, one must be able to identify, then capture,
the physics of geometric frustration. Considering
a locally ordered domain of linear size L, Kivelson
et al. (1995) suggest that the corresponding free
energy scales as
264
Glasses and Aging, A Statistical Mechanics Perspective on

F L, T
ð
Þ ¼ s T
ð ÞL2 ¼ f T
ð ÞL3 þ s T
ð ÞL5:
ð31Þ
The ﬁrst two terms express the tendency of
growing locally preferred order and represent
respectively the energy cost of having an interface
between two phases and a bulk free energy gain
inside the domain. Geometric frustration is
encoded in the third term which represents the
strain free energy resulting from frustration. The
remarkable feature of Eq. (31) is the super-
extensive scaling of the energy cost due to frus-
tration which opposes the growth of local order.
The elements in Eq. (31) can then be directly
incorporated into ferromagnetic models where
“magnetization” represents the local order, ferro-
magnetic interactions represent the tendency to
local ordering, and Coulombic antiferromagnetic
interactions represent the opposite effect, coming
from the frustration. The following Hamiltonian
possesses these minimal ingredients:
H ¼ J
X
i, j
h
i
Si  S j þ K
X
i6¼j
Si  S j
j xi  x j j ,
ð32Þ
where the spin Si occupies the site i at position xi.
Such Coulomb frustrated models have been stud-
ied in great detail, using various approximations
to study models for various space and spin dimen-
sions (Tarjus et al. 2005).
The general picture is that the ferromagnetic
transition occurring at T ¼ T0
c in the pure model
with no frustration (K ¼ 0) is either severely
displaced to lower temperatures for K > 0, some-
times with a genuine discontinuity at K ! 0,
yielding the concept of “avoided criticality.” For
the simple case of Ising spins in d ¼ 3, the
situation is different since the second-order tran-
sition becomes ﬁrst-order between a paramagnetic
phase and a spatially modulated phase (stripes).
For K > 0 and T < T0
c the system is described as a
“mosaic” of domains corresponding to some local
order, the size of which increases (but does not
diverge!) when T decreases. Tarjus, Kivelson, and
coworkers clearly demonstrated that such a struc-
turation into mesoscopic domains allows one to
understand most of the fundamental phenomena
occurring in supercooled liquids (Tarjus et al.
2005). Their picture as a whole is very appealing
because it directly addresses the physics in terms
of the “real space,” and the presence of domains of
course connects to ideas such as cooperativity,
dynamic heterogeneity, and spatial ﬂuctuations,
which directly explains, at least qualitatively,
non-exponential relaxation, decoupling phenom-
ena, or super-Arrhenius increase of the viscosity.
However, as for the RFOT mosaic picture, direct
conﬁrmations of this scenario are rare (Coslovich
and Pastore 2007), or difﬁcult to obtain.
Locally Preferred Structures
Going back to the geometric structure of local
arrangements in real space, a line of research has
emerged that is based upon some kind of local order
(Coslovich 2011; Royall and Williams 2015;
Malins et al. 2013a, b). Icosahedral order was ini-
tially shown to be linked to the dynamics of some
binary mixtures. But more generally, for simple
enough glass-formers, a broader variety of locally
ordered structures can be deﬁned (Royall and
Williams 2015), such as, for example, defective
icosahedron (Royall and Kob 2017). A vast body
of literature has shown that these locally preferred
structures (LPS) seem to correlate with structural
relaxation. Using trajectory path sampling (see sec-
tion “s-Ensemble and Large Deviations”), it was
found that LPS and dynamic activity play equiva-
lent roles, and are therefore strongly correlated
(Turci et al. 2017b, 2018). The increased number
of LPS has also been linked to hindered crystalliza-
tion (Turci et al. 2019). These multiple effects sug-
gest the LPS impacts the dynamics in various ways.
For several systems in d ¼ 2, 3, simple local
order parameters measuring the distance from ste-
rically favored structures (sixfold symmetry,
angles, and closeness to local tetrahedron) have
been spatially coarse-grained (Tong and Tanaka
2018), thus revealing a clear structure-dynamics
relationship. The interpretation in Tong and
Tanaka (2018) is that these LPS represent an indi-
rect measurement of the true amorphous order.
The very simple and widespread tetrahedral
order has been observed in a variety of materials
(Shi and Tanaka 2019). The LPS-dynamics corre-
lation has also been conﬁrmed recently in exper-
iments on colloids (Hallett et al. 2018; Pinchaipat
Glasses and Aging, A Statistical Mechanics Perspective on
265

et al. 2017), providing further evidence of the
important role of LPS in glassy behavior.
Despite these important advances, the concrete
application of LPS-based techniques on any par-
ticular realistic glass-forming material is hindered
by the lack of a universal operative deﬁnition of
the LPS. For relatively simple systems, an opera-
tive scheme was designed to automatically ﬁnd
these LPS (Royall and Williams 2015; Mossa and
Tarjus 2006).
A natural alternative to this tedious exercise is
the use of modern machine learning techniques. In
particular, one may consider the unsupervised
learning task of grouping together similar local
structures (this is called clustering). Once clusters
(corresponding to automatically found LPS) are
found, any local environment may be assigned to
its most similar group (LPS), but without the
burden of deﬁning the LPS’s one by one
(Ronhovde et al. 2011, 2012; Paret et al. 2020;
Boattini et al. 2020).
Mean-Field Theory of the Amorphous
Phase
The phase transition between liquid and glass is
not the only interesting phenomenon characteriz-
ing the phase diagram of glassy materials. Since
the transition occurs at ﬁnite pressure and temper-
ature, glasses can be further compressed or cooled
within the glass phase itself (Kurchan et al. 2012,
2013; Biroli and Urbani 2018; Rainone and
Urbani 2016; Rainone et al. 2015; Scalliet et al.
2019a). How do physical properties of glasses
change in this context? In mean-ﬁeld theory, this
question has been widely investigated by using
the hard spheres glass model (Parisi and Slanina
2000; Parisi and Zamponi 2010), a favorite canon-
ical example of a glass-former system because of
its
analytical
simplicity.
Eventually,
by
compressing a hard sphere glass, the system
undergoes the jamming transition in the limit of
inﬁnite pressure (Donev et al. 2004). In this sec-
tion, we brieﬂy survey recent progress in the
development of an analytic theory of the glass
phase in the large d limit, with a particular empha-
sis on hard spheres (Parisi et al. 2020).
Mean-Field Glassy Phase Diagrams
When a glass-forming liquid undergoes the glass
transition, it becomes conﬁned into a single free
energy minimum and the timescale to explore
different minima becomes inﬁnite. It is formally
possible to deﬁne thermodynamic properties by
restricting the available statistical conﬁgurations
to a single free energy minimum. This can be
enforced in the replica formalism by considering
two copies of the system and constraining the
distance between them (Charbonneau et al.
2017). First, an equilibrium reference conﬁgura-
tion Y at
Tg, b’g


is introduced, where b’ is the
scaled packing fraction b’ ¼ 2d’=d . Second, a
copy of the equilibrium conﬁguration X(t) is cre-
ated and evolved in time. Let us deﬁne now the
mean-squared displacement (MSD) between the
two copies as D X, Y
ð
Þ
h
i ¼ Dr. The properties of
X(t) are sampled in a restricted region of phase
space close to the equilibrium conﬁguration.
Within this state following construction, the sys-
tem at Tg, b’g


with initial conﬁguration Y can be
adiabatically followed anywhere in the glass
phase diagram.
Concretely, for the glass state selected by Yand
followed until T, b’
ð
Þ, we can write the restricted
partition function as:
Z T, b’jY, Dr
½
 ¼
ð
dXebV X
ð Þd Dr  D X, Y
ð
Þ
ð
Þ,
ð33Þ
where V(X) is the potential energy of the conﬁgu-
ration X, and the delta function enforces the
restricted average. In order to obtain the glass
free energy, we need to compute its average over
the chosen reference conﬁguration Y, which acts
as a source of quenched disorder:
f g T, b’jTg, b’g, Dt


¼  T
N
ð
dY
Z Tg, b’g
h
i e  bgV Y
ð Þ
 ln Z T, b’jY, Dr
½

ð34Þ
where Z Tg, b’g
h
i
¼
Ð
dY exp bgV Yð Þ is the parti-
tion function at
Tg, b’g


. Mathematically, the
266
Glasses and Aging, A Statistical Mechanics Perspective on

quenched disorder is handled using the replica
method. We then introduce (n þ 1) replicas of
the original system, with the initial glass at
Tg, b’g


being the master replica, while the
n other slave replicas describe the glass at T, b’
ð
Þ.
The glass free energy is ﬁnally expressed in terms
of the average MSD between the slave replicas
and the master replica  r, and the average distance
between the slave replicas  . At this step, we
assume that the symmetry between slave replicas
is not broken, which corresponds to the 1RSB
ansatz described in section “Random First-Order
Transition Theory.”
By choosing the state point at
T, b’
ð
Þ ¼
Tg, b’g


, the recursive equations for  and  r
have to satisfy 1=b’ ¼ F b D
ð Þ, where F β( ) is a
positive function which vanishes for both  ! 1
and  ! 0, with an absolute maximum in
between. This equation can then be satisﬁed
only if
1
b’d
 max
D F b D
ð Þ:
ð35Þ
This condition occurs for volume fractions
larger than a critical value b’d bg


, which corre-
sponds to the dynamical glass transition.
We can explore the glass phase following the
glass prepared at the glass transition
Tg, b’g


at
different temperatures and packing fractions. At
low T and high b’ one eventually meets another
phase transition (Kurchan et al. 2013), where the
1RSB assumption fails (Mézard et al. 1987) and
the more complex full-replica symmetry breaking
(fullRSB) solution is necessary to compute the
glass free energy, the so-called Gardner phase tran-
sition (Gardner 1985; Berthier et al. 2019d). Here,
the fullRSB solution corresponds to a hierarchical
organization of the distances between the slave
replicas and the glass becomes marginally stable
(Rainone and Urbani 2016; Franz et al. 2017). The
emergence of a complex free energy landscape
gives rise to nontrivial dynamical processes
(Scalliet and Berthier 2019; Liao and Berthier
2019; Scalliet et al. 2019b). A pictorial representa-
tion of the Gardner transition is shown in Fig. 15.
It is worth noting that the derivation sketched
above is completely general and can be used for
any glassy pair potential mentioned in section
“Random First-Order Transition Theory.” In the
following we will apply this formalism to the hard
spheres model, for which several implications
from the mean ﬁeld picture have been success-
fully tested numerically (Charbonneau et al.
2014b; Berthier et al. 2016a). Here, the relevant
state parameter is the scaled reduced pressure
bp ¼ bP=rd . We refer to Biroli and Urbani
(2016, 2018), Berthier et al. (2019d), and Scalliet
et al. (2017, 2019a, b) for more results regarding
systems made of soft potentials.
Starting from an equilibrated hard sphere liq-
uid conﬁguration at b’g , we can apply the state
following formalism to explore the hard sphere
phase diagram in Fig. 16. The reduced pressure
can lie computed from the equation of state of an
inﬁnite dimensional hard sphere liquid bp~b’=2 ,
a
b
jG  jjg
j jG
Glasses and Aging, A Statistical Mechanics Perspec-
tive on, Fig. 15 (a) Sketch of the free energy structure
deep in the hard sphere glass phase, where each basin
breaks down in sub-basins corresponding to secondary
relaxations. At the Gardner transition in (b), the sub-basins
become fractal and ergodicity is broken
Glasses and Aging, A Statistical Mechanics Perspective on
267

derived from a Virial expansion of the free energy
(Maimbourg et al. 2016). Starting from b’g and
decompressing the system, the glass eventually
undergoes a melting transition: the 1RSB solution
becomes unstable and the glass melts into the
liquid via a spinodal instability (Kurchan et al.
2013). Upon compression instead, the glass enters
deeper into the glass phase and remains dynami-
cally arrested. Numerically, this has been proven
by measuring  as the long-time limit of the MSD
 (t) between the system at time t and the initial
conﬁguration at t ¼ 0. The order parameter of the
transition  r is instead computed as the long-time
limit of the distance  ab(t) between two copies
A and B of the same initial system evolved with
different initial velocities:
DAB ¼
1
N
X
N
i¼1
rA
i  rB
i

2
*
+
:
ð36Þ
Upon further compression, the glass eventually
undergoes the Gardner transition at a ﬁnite pres-
sure bpG . Here, the relation between  r and  
breaks down and  (t) is characterized by a loga-
rithmic growth in time, suggesting the emergence
of a complex free energy landscape (Berthier et al.
2016a). The copies A and B cannot occupy the
same sub-basin and are no longer able to explore
the entire metabasin. Due to the fractal nature of
the free energy landscape, the excitations required
to move around the fractal states correspond to
soft modes (Scalliet et al. 2019b). The correlation
length of these modes can be estimated by mea-
suring the dynamical susceptibility, computed as
the variance of  AB, which indeed shows a diver-
gence at the Gardner transition (Berthier et al.
2016a).
Compressing further within the Gardner phase,
the pressure eventually diverges as the system
reaches its jamming density b’J, which depends
ϕg = 8, 7, 6, 5.5, 5
equilibrium liquid
RS glass
fullRSB glass
jamming line
1/p
ϕ
ϕd
Glasses and Aging, A Statistical Mechanics Perspec-
tive on, Fig. 16 Phase diagram of hard spheres in the
inverse reduced pressure – reduced peaking fraction
1=bp, b’
ð
Þ plane. The glass transition is marked by a full
circle. The glass equations of state are reported as full lines
in the region where the replica symmetric solution is stable.
The Gardner transition is marked by triangles, beyond
which the fullRSB solution is stable (dashed lines). Tice
glass equations of state end at the jamming transition.
Upon decompression, glasses are stabile until a spinodal
instability arises (open squares)
268
Glasses and Aging, A Statistical Mechanics Perspective on

explicitly
on
the
selected
initial
condition
Tg, b’g


: In particular, there exists a range of
jamming points, or a “jamming line” (Chaudhuri
et al. 2010), whose extension increases with
d (Kurchan et al. 2012).
Jamming
During the last two decades, a large research effort
has shed light on the critical behavior characteriz-
ing the jamming transition (Liu and Nagel 2010).
Jamming can be seen from two different perspec-
tives. An assembly of Brownian hard spheres
under compression becomes rigid at a ﬁnite den-
sity, at which point the pressure diverges. On the
other hand, athermal packings of soft repulsive
spheres reach the jamming point under decompres-
sion when the pressure vanishes. In both situations,
each particle is constrained by enduring contacts
with the neighbor particles and the system is rigid.
In particular, at jamming the average number of
contacts per particle Z reaches the critical value
Zc ¼ 2d, which represents the lower limit for
mechanical
stability
(O’Hern
et
al.
2002)
(Maxwell’s criterion for rigidity). From the hard
spheres side, Z jumps from zero to Zc at the transi-
tion, while from the soft spheres side, as the pres-
sure decreases toward zero the excess number of
contacts scales as (Ohern et al. 2003; Durian 1995):
DZ ¼ Z  Zc~D’1=2,
ð37Þ
where  ’ ¼ ’  ’J is the amount of compression
above the jamming threshold. A connection
between hard and soft spheres at jamming is
observed in the pair correlation function (Donev
et al. 2005; Ohern et al. 2003), conﬁrming that
allowed conﬁgurations of hard and soft spheres
are identical at jamming.
When  Z ¼ 0 the system is isostatic, that is,
there are just enough contacts to ensure mechan-
ical stability and the system is marginally stable:
breaking a bond between contacts can lead to an
excitation that causes a collective motion through-
out the whole system (Wyart 2012). Not surpris-
ingly, this critical behavior ﬁts well into the free
energy picture of marginal glasses reported above.
Marginality in athermal jammed solids can be
explained in real space by the so-called cutting
argument (Wyart et al. 2005). Imagine removing
the contacts between a subsystem of linear size
l and the rest of the system. If we slightly compress
the system, this cutting will lead to a competition
between the overall excess contacts  Z created by
the compression, and the missing contacts at the
boundary of the subsystem. If the total number of
contacts is below the isostatic value Niso ¼ NZ/2,
then there are modes with no energetic cost, that is,
soft modes. The number of soft modes Nsoft then
corresponds to the difference between the number
of contacts at the boundary, proportional to ld–1,
and the number of extra contacts created by the
compression, which scales as ΔZld. There is then a
critical length l~ ’1/2 for which the system
looks isostatic and for l ¼ l*, soft modes correlate
over the whole subsystem. These extended anom-
alous modes correspond to random excitations
over all the system, profoundly different from
acoustic modes proper of crystalline solids.
Other
anomalies
of
jammed
solids
are
observed in the scaling of the elastic moduli near
the transition. These critical behaviors have been
successfully described within a force network pic-
ture, for which en effective medium theory has
been developed (Wyart 2010; Degiuli et al. 2015).
In particular, a jammed soft sphere conﬁguration
can be mapped onto a network of springs with
elastic contacts keff, computed as second deriva-
tives of the pairwise interaction between particles.
The resulting scaling behaviors for the bulk mod-
ulus B ~ keff and the shear modulus G~keff ’1/2
suggest that the Poisson ratio G/B~ ’1/2 vanishes
at the jamming transition (Ohern et al. 2003). This
criticality reﬂects on the frequency of normal
modes which is directly related to the elastic mod-
uli (B(o), G(o)) by the dispersion relation o ¼
ck, where k* ~ 1/l* and c is the speed of sound.
Since sound propagates either longitudinally
(B) or transversely (G), two different length scales
can be deﬁned: the longitudinal length scale
l~ ’1/2, which matches the cutting length scal-
ing behavior and is indeed attributed to extended
soft modes, and the transverse length scale which
follows the scaling lt~ ’1/4.
Glasses and Aging, A Statistical Mechanics Perspective on
269

Other critical scaling laws have been predicted
both by replica mean ﬁeld calculations and effec-
tive medium theory for a spring network, with
good consistency with numerical results in ﬁnite
dimensions. In particular, the distributions of
interparticle voids and interparticle forces follow
universal power laws (Charbonneau et al. 2012,
2015; DeGiuli et al. 2014; Lerner et al. 2013).
Contact forces can be either extended or localized,
with distributions deﬁned by power law expo-
nents θe and θl, respectively. Extended forces are
predicted from the inﬁnite dimensional exact solu-
tion, whereas the localized forces likely result
from the presence of localized defects, such as
rattling particles, which only exist in ﬁnite dimen-
sions. Remarkably, the numerical value of the
critical exponents associated to scaling laws near
jamming can be predicted analytically in the
mean-ﬁeld approach (Charbonneau et al. 2014a,
b; Parisi et al. 2020), and their value is conﬁrmed
by numerical simulations in dimensions d  2.
The inﬂuence of temperature on the jamming
criticality has also been studied (Degiuli et al.
2015; Ikeda et al. 2013). These works show that
above jamming there exists a region in the plane
T – ’ where the harmonic approximation of the
soft sphere potential holds, and the vibrational
spectrum converges to its zero temperature limit,
provided that T < T*(’). The value of T*(’)
decreases with  ’ ! 0 with a trivial scaling
exponent. A similar result holds below jamming
for hard sphere glasses (Brito and Wyart 2009).
For T > T*(’), the harmonic approximation
breaks down, deﬁning an anharmonic critical
regime, controlled by nonanalyticities in the
interparticle
potential.
Physically,
strong
anharmonicites stem from the constant breaking
and reformation of particle contacts in the pres-
ence of thermal ﬂuctuations (Schreck et al. 2011).
Vibrational Properties
The anomalous thermal properties of low temper-
ature glasses can be related to the structure of the
free energy landscape of glassy states. Amor-
phous solids behave very differently from crystal-
line solids. In terms of heat capacity and thermal
conductivity, crystals are dominated by phononic
excitations with a low-frequency density of states
(DOS) D(o) given by the Debye scaling law
D(o)~od1. Instead, the thermal properties of
glasses are dominated by an excess of vibrational
modes referred to as the boson peak and by an
anomalous low-frequency scaling of D(o). This
excess of anomalous vibrations reﬂects, within
mean-ﬁeld theory, the existence of multiple free
energy barriers in glassy states. In fact, when the
glass enters the Gardner phase, the system
becomes marginal and even inﬁnitesimal pertur-
bations lead to excitations that can bring the sys-
tem to a different glassy state.
The mean-ﬁeld theory of glasses has been
explored using soft spheres in the jamming limit
(Franz et al. 2015). The theory predicts the low-
frequency scaling of the vibrational density of
states (vDOS) to be D(o) ~ o2 in any dimension
(Parisi and Zamponi 2010; Wyart 2010; Berthier
et al. 2011b), quite differently from the Debye
scaling. The same result was previously obtained
within the effective medium theory (DeGiuli
et al. 2014).
Numerically, the nature of the low-frequency
vibrational spectrum has been widely studied
using soft spheres packings close to jamming.
Early studies suggested the existence of the
D(o) ~ o2 scaling (Charbonneau et al. 2014b;
Franz et al. 2015) for a wide range of dimensions
d, reinforcing the relevance of the mean-ﬁeld
description
for
ﬁnite
dimensional
systems
(Charbonneau et al. 2016a). The modes giving
rise to this scaling form have been found to be
extended anomalous modes. A more recent study
established that the o2 scaling is only observed
over a ﬁnite frequency range, which seems to
increase systematically with the space dimension
d, which is consistent with a pure quadratic scal-
ing when d ¼ 1. However, for any ﬁnite d, the
density of states eventually obeys Debye scaling
for sufﬁciently low frequencies.
Finally, recent numerical works show that for
frequencies lower than the boson peak, an addi-
tional family of soft modes due to marginal insta-
bilities can be observed (Mizuno et al. 2017; Lerner
et al. 2016). As Fig. 17 shows, the vibrational
density of these additional modes scales as o4.
270
Glasses and Aging, A Statistical Mechanics Perspective on

A spatial analysis of such modes shows that they
correspond to quasi-localized modes, which are
again absent from the large d analytic description.
Rheology
Once the glass is created, it can be adiabatically
cooled or compressed, but it can also be deformed
by applying an external mechanical constraint.
The rheology of amorphous solids is a very
broad research ﬁeld. Here, we present recent
results in this ﬁeld obtained using the mean ﬁeld
glass theory, including implications regarding
elasticity, yielding, and shear jamming (Rainone
and Urbani 2016; Rainone et al. 2015; Biroli and
Urbani 2016; Yoshino and Zamponi 2014).
We report results obtained from the same state
following formalism applied to study the amor-
phous phase along a compression in the d ! 1
limit. If the master replica Y is in the dynamically
arrested region, the system reacts elastically to a
small applied strain γ. We can then obtain the
stress-strain curve as a function of the state point
T, b’
ð
Þ of the slave replica X. The stress for an
elastic medium increases linearly with strain,
which deﬁnes the shear modulus bm ¼ dbs
dg computed
at zero strain, where stress and shear modulus are
scaled such that the d ! 1 limit remains ﬁnite. In
the small strain limit one ﬁnds
bm ¼ 1
D
ð38Þ
where  is the long time limit of the MSD. The
MSD  (X, Y) is the superposition of an afﬁne
component due to the strain, and of a non-afﬁne
contribution deﬁned by the particular shear proto-
col. At the glass transition, the shear modulus
jumps from a zero value (liquid state) to a ﬁnite
value at b’d (glass state). In ﬁnite dimensions, this
sharp discontinuity becomes a crossover (Parisi
et al. 2020).
When the system is conﬁned within a glass state,
it is able to sustain a shear strain on a time scale
which corresponds to the diverging time scale for
which the dynamics becomes diffusive. One can
then follow adiabatically the slave replica until a
state point T, b’
ð
Þ and study the linear response to
shear for the different phases of the glass. This
corresponds to exploring the strain vs volume frac-
tion phase diagram of the system. Upon decom-
pression, the shear modulus decreases and displays
a square root singularity at the melting spinodal
point (Parisi et al. 2020; Rainone et al. 2015).
Increasing the strain and/or the volume frac-
tion, the glass phase may undergo a Gardner tran-
sition and transform into a marginal glass, for
which all nonlinear elastic moduli diverge and
 0
 1
 2
 3
 4
 5
10-1
100
All modes
P k > 10-2
P k < 10-2
ω
D(ω)/ω2
AD
ωex0
ωBP
ω∗
10-4
10-3
D(ω)
ω
ωex0
∝ω4
ADω2
Glasses and Aging, A Statistical Mechanics Perspec-
tive on, Fig. 17 Adapted from (Mizuno et al. 2017).
Vibrational density of states of jammed harmonic soft
spheres scaled by the Debye law od–1 in d ¼ 3. Modes
with index k are classiﬁed as extended (blue) or localized
(yellow) by their participation ratio Pk. Below the boson
peak frequency oBP, the density of states is the superposi-
tion of anomalous extended modes eventually obeying
Debye scaling, and a population of quasi-localized modes
scaling as o4, as conﬁrmed in the inset
Glasses and Aging, A Statistical Mechanics Perspective on
271

standard elasticity theory does not hold anymore
(Biroli and Urbani 2016). As for a simple com-
pression without shear, the boundary of the Gard-
ner phase transition explicitly depends on the
selected glass state.
Once the Gardner phase is entered, upon fur-
ther compression or strain, two kinds of transition
may occur in hard sphere glasses. First, the shear
modulus may increase and eventually diverge
when a jamming point is reached. At zero strain,
this is the ordinary jamming transition. In that
case, the power law scaling of the MSD directly
implies a similar behavior for the shear modulus.
In the presence of a ﬁnite strain, this corresponds
to the phenomenon of shear jamming, observed in
the context of granular materials (Urbani and
Zamponi 2017; Peters et al. 2016).
A second type of instability can occur when
increasing the strain of a hard sphere glass. Here,
the shear stress reaches a maximum followed by a
spinodal instability where the fullRSB solution
for  and  r is no longer stable. The spinodal
point gY b’g


corresponds to the glass yielding
transition (Urbani and Zamponi 2017; Parisi et al.
2017). The yielding transition in glasses has been
studied for a variety of models and under different
physical conditions (Lin et al. 2014; Ozawa et al.
2018b). In particular, it has been suggested that
the yielding transition belongs to the same univer-
sality class as the RFIM, that is, a spinodal transi-
tion with disorder.
New Computational Methods
In the last decade, a number of new numerical
techniques have allowed to attack the challenges
presented in the above theoretical sections. These
techniques typically make use of tools that go
beyond the realm of standard computer simula-
tions to either sample phase space more efﬁciently
or access information and observables that are not
directly stored in particle trajectories.
The Swap Monte-Carlo Method
To sample deeply supercooled states in equilib-
rium, one needs to run computer simulations over
a duration that scales with the equilibrium struc-
tural relaxation time tα. Because tα grows rapidly
as the system approaches the glass transition,
ordinary computer simulations are limited to a
rather high temperature regime much above the
experimental glass transition Tg.
The swap Monte Carlo algorithm is an efﬁcient
way to produce equilibrium conﬁgurations of a
supercooled liquid on the computer (Berthier et al.
2016b; Ninarello et al. 2017). Here, “efﬁcient”
means that the equilibration time of the swap
Monte Carlo algorithm increases much less than
tα as temperature decreases. Actually, it was
shown that for several three-dimensional model
systems, the equilibration speedup can be larger
than a factor 1011, as illustrated in Fig. 18. For this
particular model of soft spheres, the swap algo-
rithm continues to reach thermal equilibrium
below the experimental glass transition Tg.
The swap algorithm was introduced long ago
(Gazzillo and Pastore 1989), and it was ﬁrst used
in the context of the glass transition by Grigera
and Parisi (2001). Its ability to reach equilibrium
at extremely low temperatures was established
more recently (Berthier et al. 2016b; Ninarello
et al. 2017; Ninarello 2017). By comparison
with ordinary computer simulations, the swap
Monte Carlo algorithm introduces unphysical par-
ticle moves, where the identity of a pair of ran-
domly chosen particles is exchanged. Provided
the swap moves are constructed to satisfy detailed
balance, the algorithm is guaranteed to reach ther-
mal equilibrium. The swap Monte Carlo algo-
rithm
can
be
implemented
in
a
molecular
dynamics setting, replacing the swap moves by
an exchange between the system and a reservoir of
particles (Brito et al. 2018; Kapteijns et al. 2019;
Berthier et al. 2019e). Typically, increasing the
frequency of swap moves speeds up the dynamics
but there are practical limits to the maximal allo-
wed frequency (Berthier et al. 2019e). The swap
algorithm was shown to work well from d ¼ 2 up
to at least d ¼8 dimensions (Berthier et al. 2019f).
A decisive step to increase the efﬁciency of the
swap Monte Carlo algorithm was the develop-
ment of models for supercooled liquids that were
tailored to increase the swap efﬁciency. However,
and perhaps more importantly, many models that
272
Glasses and Aging, A Statistical Mechanics Perspective on

were previously thought to be good glass-formers
were in fact crystallizing very easily when swap
was employed. Thus, a key step was also the
development
of
more
robust
glass-forming
models, using size polydispersity and nonadditive
interaction parameters to prevent structural order-
ing (Ninarello et al. 2017; Parmar et al. 2020).
In summary, the swap Monte Carlo algorithm
easily and rapidly produces a large number of
independent
equilibrium
conﬁgurations
of a
glass-former over a very broad range of tempera-
tures, from the high temperature liquid, down to
the mode-coupling crossover, and even below the
experimental glass transition temperature. The
latter regime can be explored experimentally
only using physical vapor deposition, see section
“Ultrastable Glasses.” Therefore, many physical
properties of glassy materials can now be mea-
sured over a temperature regime that is extremely
broad, and may be compared directly to experi-
ments with no extrapolation. This has led to an
important activity to address several problems
related to glassy materials: the Gardner transition
in ﬁnite dimensional glass-formers (Liao and
Berthier 2019; Scalliet et al. 2019b; Berthier
et al. 2016a), the link between glass and jamming
transitions (Berthier et al. 2016b; Coslovich et al.
2018), the measurement of the conﬁgurational
entropy in deeply supercooled liquids (Ozawa
et al. 2018c; Berthier et al. 2019g), the analysis
of point-to-set lengthscales (Berthier et al. 2017c;
Yaida et al. 2016) and of the Franz-Parisi potential
(Berthier et al. 2017c; Guiselin et al. 2020), the
evolution of several important properties of
glasses with the glass preparation (Khomenko
et al. 2020; Wang et al. 2019a; Wang et al.
2019b), and the physics of ultrastable glasses
(Berthier et al. 2017b; Flenner et al. 2019).
In addition, the demonstration that a very
simple algorithm can speed up the equilibration
dynamics of supercooled liquids can be seen as
an interesting physical result in itself. If such a
result appears quite natural in the context of
kinetic facilitation (Wyart and Cates 2017;
Gutiérrez et al. 2019), it is more challenging
(but possible) to interpret in the context of the
random ﬁrst-order transition theory (Berthier
et al. 2019c; Ikeda et al. 2017b; Szamel 2018),
2
4
6
8
10
12
14
16
18
1/T
10
2
10
3
10
4
10
5
10
6
10
7
τα
VFT
Parabolic
Arrhenius
(a)
Standard
Swap
Glasses and Aging, A Statistical Mechanics Perspec-
tive on, Fig. 18 From (Ninarello et al. 2017). Relaxation
times for standard (open symbols) and swap (closed sym-
bols) Monte Carlo dynamics. The standard dynamics is
ﬁtted with the VFT, parabolic, and Arrhenius laws, which
are then used to estimate the location of the experimental
glass temperature Tg (vertical dashed lines). The swap
dynamics efﬁciently equilibrates the system at tempera-
tures below Tg
Glasses and Aging, A Statistical Mechanics Perspective on
273

where dynamics becomes highly collective at
very low temperatures.
Franz-Parisi Potential
In seminal work (Franz and Parisi 1997; Franz and
Parisi 1998), Franz and Parisi introduced a quan-
tity now called the Franz-Parisi potential, V(Q).
This quantity plays the role of a Landau free
energy for mean-ﬁeld phase transitions, in the
sense that it expresses the free energy cost of the
order parameter ﬂuctuations at the mean-ﬁeld
level.
For spin glass models, where the approach was
ﬁrst introduced, the overlap Q represents indeed
the spin glass order parameter. It quantiﬁes the
degree of similarity between two conﬁgurations
C0 and C1. For liquids with continuous degrees of
freedom, a practical deﬁnition of the overlap
reads:
Q ¼ 1
N
X
N
i¼1
X
N
j¼1
Y ajrC 0
i
 rC 1
j j


,
ð39Þ
where rC0
i
represents the position of particle i in
conﬁguration C 0. The overlap is close to unity
when the two conﬁgurations C 0 and C 1 have
similar density proﬁles, up to thermal vibrations
of spatial extension a (typically, one takes a as
a
small
fraction
of
the
particle
diameter,
a ~ 0.2s).
The Franz-Parisi potential V(Q) efﬁciently cap-
tures all the features associated to a random ﬁrst-
order transition. It can be deﬁned from the prob-
ability distribution function P(Q) of the overlap as
V(Q) ¼  (T/N) log P(Q). In particular, V(Q) is
characterized by a single minimum near Q ¼ 0 at
high temperature, but develops within mean-ﬁeld
theory a secondary minimum at a ﬁnite Q > 0
when T decreases toward the Kauzmann transi-
tion, indicating that the glass phase is metastable
with respect to the liquid. The free energy differ-
ence between the glass and the liquid phases in
this regime is given by TSc(T), where Sc(T) is the
conﬁgurational entropy. Physically, this means
that localizing the system in a single free energy
minimum in the liquid phase comes with a free
energy cost of entropic nature.
In addition, Franz and Parisi introduced a ﬁeld
ε conjugate to the overlap Q:
HFP C 1
½
 ¼ H C 1
½
  eQ C 0, C 1
½
:
ð40Þ
This allowed them to explore an extended
phase diagram by changing both T and ε
(Cardenas et al. 1999; Donati et al. 2002). In this
plane, the Kauzmann transition at (T ¼ TK, ε ¼ 0)
extends as a ﬁrst-order transition line, which ends
at a second-order critical point at a position
(Tc > TK, εc). More recent work taking into
account ﬁnite dimensional ﬂuctuations suggest
that this critical point should exist also in ﬁnite
dimensions, and should be in the same universal-
ity class of the random ﬁeld Ising model (Biroli
et al. 2014).
The Franz-Parisi potential and the extended
phase diagram have been studied numerically in
ﬁnite dimensional models in recent years (Turner
et al. 2015; Berthier et al. 2017c; Guiselin et al.
2020; Cardenas et al. 1999; Berthier 2013; Biroli
et al. 2016; Berthier and Jack 2015; Jack and
Garrahan 2016; Parisi and Seoane 2014). Taken
together, these studies conﬁrm the existence of
both a ﬁrst-order transition line and a second-
order RFIM critical point in ﬁnite dimensional
glass-formers.
A second important outcome of the Franz-
Parisi potential is the possibility to directly esti-
mate a conﬁgurational entropy for equilibrium
glass-formers using the free energy difference
between the liquid and metastable glass phase
(Berthier et al. 2017c; Berthier and Coslovich
2014). This deﬁnition of the conﬁgurational
entropy is conceptually closer to its mean-ﬁeld
deﬁnition, and does not rely on an explicit deﬁni-
tion of metastable states for a ﬁnite dimensional
system (Berthier et al. 2019a).
Point-to-Set Lengthscale
As mentioned in section “Static and Dynamic
Correlation Functions,” assessing and measuring
a growing static length scale is crucial to the glass
problem. Standard probes used for second-order
phase transitions, such as 2-point and 4-point
correlation functions, do not seem to provide any
useful evidence. A possible explanation is that
274
Glasses and Aging, A Statistical Mechanics Perspective on

these correlation functions do not carry enough
information to capture the relevant structural
order, also termed amorphous order, and that one
has to use higher-order correlation functions (see
also section “Jamming Transition”). The point-to-
set correlation function C(R) is effectively an
n-point correlation function, where n is the num-
ber of particles comprised in a sphere of radius
R (the “set”), which can indeed be a large number.
The justiﬁcation is that in order to probe amor-
phous order one has to proceed as in standard
phase transitions: ﬁx a suitable boundary condi-
tion and study whether it enforces a given arrange-
ment of particles in the bulk of the system. For
simple cases, such as the ferromagnetic Ising
model, it is clear what type of boundary condi-
tions are needed (all spins up or all spins down).
However, for supercooled liquids this is a much
harder task. The problem can be circumvented by
using equilibrated conﬁgurations and freezing all
particles outside a cavity of radius R. This pro-
vides the boundary conditions sought for: if the
system is indeed ordering, then using cavities
drawn from different equilibrium conﬁgurations
will give access to different sets of appropriate
boundary conditions. This method was ﬁrst pro-
posed theoretically in the context of RFOT theory
(Bouchaud and Biroli 2004; Montanari and
Semerjian 2006) and signal processing (Mézard
and Montanari 2006), and was transformed into a
concrete numerical procedure in Cavagna et al.
(2007) and Biroli et al. (2008). In the last decades,
measurements of the point-to-set length were pro-
gressively reﬁned (Berthier and Kob 2012;
Berthier et al. 2016c, 2017c; Yaida et al. 2016;
Cavagna et al. 2012; Charbonneau et al. 2016b).
Let us describe the main steps and mention
some important obstacles that had to be over-
come. Firstly, one needs a collection of well-
equilibrated conﬁgurations C 0 to start with. This
is not supposed to be the hardest part, but for very
low temperatures, methods such as the swap
Monte Carlo algorithm are necessary.
Secondly, for each sample C 0 one freezes all
particles outside a cavity of radius R, then let the
particles inside ergodically visit the remaining
phase space, and record the conﬁgurations C 1
that are sampled. For small cavities, large
activation barriers make conventional molecular
dynamics simulations ineffective, but this prob-
lem can be solved using parallel tempering tech-
niques (Berthier et al. 2016c), in addition to swap
Monte Carlo (Cavagna et al. 2012). It is crucial to
check that a complete sampling of the restricted
conﬁgurational space has been reached inside the
cavity, and careful tests have been devised to this
end (Cavagna et al. 2012).
Thirdly, one needs to measure the overlap dis-
tribution P(Q) between the quenched reference
conﬁguration C 0 and the equilibrium samples C 1.
This is very similar to the Franz-Parisi construc-
tion, except for the local nature of the constraint.
There are two possibilities. One is that the cavity is
so small that only one state (one conﬁguration, up
to vibrations) can be visited, so that the peak of
P(Q) is in the high-overlap range. The other is that
the cavity is sufﬁciently large for many different
states to be accessible. In that case, P(Q) has a peak
at low Q. In between the two cases, there is a
critical value of the radius, R ~ xPTS, which corre-
sponds to the crossover, with a bimodal P(Q).
Since ﬁnite size cavities cannot be self-averaging,
one needs to repeat the overlap measurements for
many independent quenched conﬁgurations C 0 ,
and then perform an average over these realizations
of the disorder. Indeed, for R ~ xPTS, large sample-
to-sample variations of P(Q) are observed.
There are a number of subtleties and exten-
sions related to the overlap function that we now
describe. A ﬁrst subtlety is that an appropriate
measure of the overlap needs to focus on the
center of the spherical cavity, since boundaries
always have a high overlap, and this makes the
results difﬁcult to interpret (Biroli et al. 2008).
Moreover, the overlap needs to be a smooth func-
tion of the distance between conﬁgurations, and
step functions are too singular to average over.
A second subtlety is that for some liquids, the
simple positional information does not adequately
cover all the structural information. In that case,
the conventional overlap needs to be completed
with additional coordinates overlap, for example,
bond angles. This was used in Yaida et al. (2016)
to show that hexatic order could be captured by
the point-to-set correlations (see also Russo and
Tanaka 2015).
Glasses and Aging, A Statistical Mechanics Perspective on
275

Let us also mention a few extensions of the
method that have been proposed. In Cavagna et al.
(2012), the authors proposed to relax the frozen
conﬁguration constraint by letting the outside
atoms vibrate, so long as they maintain a large
overlap with the initial conﬁguration: they called
this reference state “frozen state” (as opposed to
frozen conﬁguration). A second type of extension
is to study various conﬁnement geometries, as in
Berthier and Kob (2012), Kob et al. (2012),
Cavagna et al. (2012), and Li et al. (2014),
where it was shown that the geometry of conﬁne-
ment needs to be carefully considered.
Thanks to the computational progress outlined
above, several important results were established
in the last decade. Among them: (i) clear evidence
that the slowing down of the dynamics is accom-
panied by the growth of the point-to-set length
(even though a mild one), (ii) established relation
between point-to-set and conﬁgurational entropy:
the former appears to be inversely proportional to
the other (Berthier et al. 2019a), thus directly linking
the growth of amorphous order to the decrease in
number of metastable states – a tenet of RFOT
theory,
(iii)
clear
difference
between
two-
dimensional and three-dimensional behavior: two-
dimensional glass-formers display a point-to-set that
appears to diverges at zero temperature, as shown in
Fig. 19, thus indicating a TK ¼ 0 Kauzman transition
temperature (Berthier et al. 2019g). This is in sharp
contrast with the results in three dimensions, where
the extrapolated TK is larger than zero.
s-Ensemble and Large Deviations
The Franz-Parisi potential is an example of a large
deviation analysis. The idea behind it is that ﬂuc-
tuations in the overlap ﬁeld play an important role
for the glass transition, analog to the magnetiza-
tion ﬁeld in a ferromagnet. In order to investigate
such ﬂuctuations, one can then study the large
deviation function (the free-energy) associated to
the spatial average of the ﬁeld (the order parame-
ter). This is the usual route followed in thermody-
namic analyses of second-order phase transitions.
The s-ensemble is the dynamical counterpart of
such a procedure. One modiﬁes the dynamical
rules, in order to be in a particular subset of the
“dynamical states,” to probe the tendency of the
original system to explore these states. This idea
originates both from theoretical considerations on
the large deviations of activity (rare events) pre-
dicted in KCMs (Garrahan et al. 2007, 2009) and
from
considerations
on
efﬁcient
simulation
schemes (for rare events as well) that apply more
generally (Noe et al. 2009). In practice, the
s-ensemble dynamics is a particular instance of
transition path sampling, where the quantity of
interest is a measure of the activity of a multi-
particles trajectory {xi(t)}i ¼ 1, . . ., N, cumulated
over time
K x tð Þ
½
 ¼
1
Ntobs
X
t  t0, t0þtobs
½

X
i  1, N
½

xi t þ Dt
ð
Þ  xi tð Þ
ð
Þ2
ð41Þ
where  t (resp. tobs) is chosen to be of the order of a
few ballistic times (resp. a few relaxation times). In
the s-ensemble, the actual relaxation time then
becomes larger than tobs. Here we follow the nota-
tions used in (Hedges et al. 2009), where this biasing
method was ﬁrst applied to structural glasses (for its
initial introduction in KCMs, see Elmatad et al.
(2010), and Garrahan et al. (2007, 2009)). The
method is called s-ensemble because the probability
0.0
0.2
0.4
0.00
0.05
0.10
0.15
A
Glasses and Aging, A Statistical Mechanics Perspec-
tive on, Fig. 19 From Berthier et al. (2019g). Evolution
of the inverse point to set length, denoted here as 1/R with
the temperature T. A clear growth of the point to set length
up to xPTS ≈6.5 is observed. Cavities smaller (larger) than
xPTS have a large (small) overlap with the reference con-
ﬁguration, as illustrated in the snapshots, where the particle
shade encodes the overlap value
276
Glasses and Aging, A Statistical Mechanics Perspective on

of a trajectory x(t) is P0[x(t)]esK[x(t)], where P0[x(t)]
is the probability for the unperturbed system. This
amounts to deﬁning a “thermodynamics of trajecto-
ries” which are biased (and classiﬁed) depending on
their activity; s is the biasing ﬁeld. In order to
numerically simulate and probe such a measure,
one can perform Monte-Carlo sampling in trajectory
space. This method is actually so efﬁcient at ﬁnding
low-energy states that special attention must be paid
to crystallization (Hedges et al. 2009).
One of the most important results obtained by
the s-ensemble method is a direct evidence of a
ﬁrst-order phase transition between an active phase
(for low s) and an inactive phase (for large s) in
supercooled liquids: see Fig. 20. In the s – T plane
this corresponds to a ﬁrst-order transition line s*(T)
which ends in a critical point at high temperature
(Elmatad et al. 2010; Hedges et al. 2009). Although
the method focuses on the dynamical properties,
inactive states do exhibit interesting structural fea-
tures. They are more stable than equilibrium sam-
ples (Jack et al. 2011): mechanically, in terms of
their
lower
number
of
low-energy
modes
(depletion of D(o)), and thermodynamically, in
terms of a longer lived “melting” transient from
the glass to the liquid state. This suggests that
inactive states correspond to very stable glassy
state, that is, nonequilibrium glassy states with
low ﬁctive temperatures.
The foundation of the s-ensemble relies on the
dynamical behavior of KCMs. For the East model
scenario it was shown (Keys et al. 2015) that
conﬁgurations obtained by (i) the s-ensemble,
(ii) ﬁnite-rate cooling, and (iii) quenching and
longtime aging are all equivalent. This provides
a concrete example where glassiness is directly
related to the phase transition unveiled by the
s-ensemble. Let us conclude by noticing that
even systems having an RFOT display such a
phase transition, the difference being that the
line s*(T) reaches s* ¼ 0 for T ¼ TK and not for
T ¼ 0 as for KCMs (Jack and Garrahan 2010).
This shows that the s-ensemble is actually a gen-
eral construction, which transforms the physics of
metastability observed in supercooled liquids in
well-deﬁned phase transitions in the extended
ensemble comprising space and time.
Machine Learning Developments
We
have
mentioned
the
possible
use
of
(unsupervised) Machine Learning (ML) in section
“Geometric Frustration, Avoided Criticality, and
Locally Preferred Structures” for automatic identiﬁ-
cation of LPS in supercooled liquids (see also
Ronhovde et al. 2011, 2012; Paret et al. 2020; and
Boattini et al. 2020). Another set of ML techniques
to be used is supervised learning: automatically
deﬁning ﬂuid- or solid-like structures (features in
Glasses and Aging, A Statistical Mechanics Perspec-
tive on, Fig. 20 From Hedges et al. (2009). Coexistence
of the active (large K) and inactive (small K) phases, as
evidenced
from
s-ensemble
biased
simulations.
As
temperature is reduced, the distribution becomes increas-
ingly bimodal, as expected when approaching a ﬁrst-order
phase transition
Glasses and Aging, A Statistical Mechanics Perspective on
277

ML language) by labeling them for a training set of
local environments which are observed to be locally
ﬂuid-or solid-like. The general idea developed in
Schoenholz (2018) is to train a neural network
(or other ﬁtting model) to “predict” the current
degree of mobility or “instantaneous activity” from
the knowledge of structure only. This may be cast as
ﬁnding the function f such that f
r!
n o



i, t
ð
Þ ¼ yprecl  ytrue i, t
ð
Þ, where
r!
n o
i, t
ð
Þ is the
structure of the neighborhood of particle i at time t,
and ytrue(i, t) (the label) is a measure of the dynam-
ical activity for particle i at time t. Concretely, the
target label ytrue has to encode some notion of local,
instantaneous mobility (Candelier et al. 2009,
2010a, b), while the local structure may be deﬁned,
for example, by the (local, instantaneous) density
pair correlation function g(r), with the possible addi-
tion of angular variables (Cubuk et al. 2016;
Schoenholz et al. 2016). This technique has been
applied with success, showing how much structure
correlates with dynamics in supercooled liquids
(Schoenholz et al. 2016; Landes et al. 2020), disor-
dered solids (Cubuk et al. 2016; Schoenholz et al.
2015, 2016; Landes et al. 2020; Cubuk et al. 2015),
for the plasticity of amorphous materials (Ivancic
et al. 2017; Cubuk et al. 2017), and in polycrystal-
line materials (Sharp et al. 2018).
The problem of the interpretation, which is one
of the major issues with statistical learning in
general, remains open: how to make use of pre-
dictions
emerging
from
hundred-parameters
models? This issue is transverse to most ML
applications and is currently under active scrutiny.
In terms of basic science, the conclusion of Liu
and collaborators is that the predicted ypred pro-
vides a new observable, called the softness ﬁeld
(Schoenholz et al. 2015), which plays a key role
for the dynamics.
We conclude mentioning a very recent work
which introduced a new ML technique in the glass
physics arena. The authors of (Bapst et al. 2020)
focused on the problem of predicting long-time
dynamics (more precisely, the propensity ﬁeld
(Widmer-Cooper and Harrowell 2006)) from
knowledge of structure alone, by leveraging on
recent progress in graph neural networks. The
results are impressive: the ability to predict the
propensity
map
is
substantially
better
than
existing numerical physics-based methods and
the
ML
techniques
described
above,
thus
establishing a promising new way to study glassy
dynamics.
Aging and Off-Equilibrium Dynamics
Why Aging?
We have dedicated most of the above discussion
to properties of materials approaching the glass
transition at thermal equilibrium. We discussed a
rich phenomenology and serious challenges for
both our numerical and analytical capabilities to
account for these phenomena. For most people,
however, glasses are interesting below the glass
transition, so deep in the glass phase that the
material seems to be frozen forever in a seemingly
arrested amorphous state, endowed with enough
mechanical stability for a glass to retain, say, the
liquid it contains (preferably a nice red wine).
Does this mean that there is no interesting physics
in the glass state?
The answer is clearly “no.” There is still life
(and physics) below the glass transition. We recall
that for molecular glasses, Tg is deﬁned as the
temperature below which relaxation is too slow
to occur within an experimental timescale. Much
below Tg, therefore, the equilibrium relaxation
timescale is so astronomically large that thermal
equilibrium is out of reach. One enters therefore
the realm of off-equilibrium dynamics. A full
physical understanding of the nonequilibrium
glassy state remains a central challenge (Young
1998; Barrat et al. 2004).
A ﬁrst consequence of studying materials in a
time window smaller than equilibrium relaxation
timescales is that the system can, in principle,
remember its complete history, a most unwanted
experimental situation since all details of the
experimental protocol may then matter. The sim-
plest protocol to study aging phenomena in the
glass phase is quite brutal (Struik 1977): take a
system equilibrated above the glass transition and
suddenly quench it at a low temperature at a
“waiting time” tw ¼ 0 which corresponds to the
beginning of the experiment. For tw > 0 the
278
Glasses and Aging, A Statistical Mechanics Perspective on

system is left unperturbed at constant temperature
where it tries to slowly reach thermal equilibrium,
even though it has no hope to ever get there.
Aging means that the system never forgets the
time tw spent in the glass phase, its “age.” The
evolution of one time quantities, for example, the
energy, as a function of time is not a good evi-
dence of aging. In order to show that the system
never equilibrates, two time quantities such as
density-density or spin-spin correlation functions
are much more useful. A typical example is pre-
sented in Fig. 21 where the self-part of the inter-
mediate function in Eq. (5) is shown for a
Lennard-Jones molecular liquid at low tempera-
ture. Immediately after the quench, the system
exhibits a relatively fast relaxation: particles still
move substantially. However, when the age
increases, dynamics slow down and relaxation
becomes much slower. When tw becomes very
large, relaxation becomes too slow to be followed
in the considered time window and the system
seems frozen on that particular timescale: it has
become a glass. A striking feature conveyed by
these data is that an aging system not only remains
out-of-equilibrium for all practical purposes, but
its typical relaxation time is in fact set by its age tw.
In simple cases, the effective relaxation time after
waiting a time tw scales at tw itself, which means
that since equilibration timescales have diverged,
tw is the only remaining relevant timescale in the
problem.
A popular interpretation of this phenomenon is
given by considering trap models (Bouchaud
1992). In this picture, reminiscent of the Goldstein
view of the glass transition mentioned above
(Goldstein 1969), the system is described as a
single particle evolving in a complex energy land-
scape with a broad distribution of trap depths – a
paradigmatic mean-ﬁeld approach. Aging in this
perspective arises because the system visits traps
that
become
deeper
when
tw
increases,
corresponding to more and more stable states. It
therefore takes more and more time for the system
to escape, and the dynamics slow down with time,
as observed in Fig. 21. This implies that any
physical property of the glass becomes an age-
dependent quantity in aging protocols, and more
generally becomes dependent on how the glass
was prepared. One can easily imagine using this
property to tune mechanical or optical character-
istics of a material by simply changing the way it
is prepared, like how fast it is cooled to the glassy
state (recall our discussion of ultrastable glasses in
section “Ultrastable Glasses”).
A real space alternative picture was promoted
in particular in the context of spin glass studies,
based on the ideas of scaling and renormalization
(Bray and Moore 1984; van Hemmen and
t −tw
Fs(q, t, tw)
100000
10000
1000
100
10
1
1
0.8
0.6
0.4
0.2
0
Glasses and Aging, A Statistical Mechanics Perspec-
tive on, Fig. 21 Aging dynamics in a Lennard-Jones
glass-forming liquid at low temperature. The system is
quenched at time tw ¼ 0 at low T, where the temperature
is kept constant. Two-time self-intermediate scattering
functions are then measured for 20 logarithmically spaced
waiting times tw from tw ¼1 to tw ¼105 (from left to right).
The relaxation becomes slower when tw increases: the
system ages
Glasses and Aging, A Statistical Mechanics Perspective on
279

Morgenstern 1987; Fisher and Huse 1986). The
physical picture is that of a coarsening process,
where the system develops long-range order by
growing extended domains of lengthscale ‘(tw).
On lengthscales less than ‘(tw), the system has had
the time to order since the quench at tw ¼ 0. The
walls between domains evolve in a random envi-
ronment. In order to move they have to overcome
free energy barriers. It is then assumed an acti-
vated dynamic scaling which states that the typi-
cal barrier to extend the domain from linear size
‘(tw) to, say, 2‘(tw) scales as ‘c, where c is some
“barrier” exponent. Using the Arrhenius law to
relate dynamics to barriers, one gets that aging
corresponds to the logarithmic growth with time
of spatially correlated domains, ‘~(T log tw)1/c.
A domain growth picture of aging in spin glasses
can be directly conﬁrmed by numerical simula-
tions (Kisker et al. 1996), only indirectly by
experiments.
Memory and Rejuvenation Effects
Since the complete history of a sample in the glass
phase matters, there is no reason to restrain exper-
imental protocols to the simple aging experiment
mentioned above. Indeed, experimentalists have
investigated scores of more elaborated protocols
that have revealed an incredibly rich, and some-
times quite unexpected, physics (Young 1998).
We restrain ourselves here to a short discussion
of memory and rejuvenation effects observed dur-
ing temperature cycling experiments (Refregier
et al. 1987) (one can imagine applying a magnetic
ﬁeld or a mechanical constraint, be they constant
in time or sinusoidal, etc.). These two effects were
ﬁrst observed in spin glasses, but the protocol was
then repeated in many different materials, from
polymers and organic liquids to disordered ferro-
electrics. After several unsuccessful attempts,
similar effects are now observed in numerical
work as well (Berthier and Young 2005; Berthier
and Bouchaud 2002). Recent results obtained
from simulations of a three-dimensional glass-
former exploring the spin-glass-like Gardner
phase (Scalliet and Berthier 2019) are presented
in Fig. 22.
There are three steps in temperature cycling
experiments (Refregier et al. 1987). The ﬁrst one
is a standard aging experiment, namely a sudden
quench from high to low temperature at time
tw ¼ 0. The system then ages for a duration t1 at
constant temperature T1. The system slowly
2.106
0.100
4
2
0
t1 + t2
t1
Memory
Rejuvenation
Aging
T1 = 0.0353
T2 = 0.0005
T1 = 0.0353
tw
χ(tw, ω)
4.106
2.106
0.100
4
3
2
1
0
Glasses and Aging, A Statistical Mechanics Perspec-
tive on, Fig. 22 Memory and rejuvenation effects
obtained
in
the
numerical
simulation
of
a
three-
dimensional glass-former (Scalliet and Berthier 2019).
There is a ﬁrst aging step, 0 < tw < 11, during which the
system slowly tries to reach thermal equilibrium at
temperature T1. The system “rejuvenates” in the second
step at T2, t1 < t < t1 þ
t2, and it restart aging
(rejuvenation). Finally in the third step, temperature is
back to T1, and memory of the ﬁrst step is kept intact, as
shown in the inset where relaxation during the second step
of the experiment is taken away
280
Glasses and Aging, A Statistical Mechanics Perspective on

relaxes toward equilibrium and its dynamics
slows down: for our spin glass example (see
Fig. 22) this is observed through the measurement
of some dynamic susceptibility w(tw, o). Temper-
ature is then suddenly shifted to T2 < T1 at time t1.
There, the material restarts aging (almost) as if the
ﬁrst step had not taken place. This is called “reju-
venation effect,” because the system seems to
forget it is already “old.” At total time t1 þ t2,
temperature is then shifted back to its initial value
T1. Then, aging is found to proceed as a quasi-
perfect continuation of the ﬁrst step, as if the
second step had not taken place. The system has
kept the “memory” of the ﬁrst part of the experi-
ment, despite the rejuvenation observed in the
intermediate part. The memory effect becomes
more spectacular when relaxation during the sec-
ond step is removed, as in the inset of Fig. 22. The
third relaxation appears indeed as a perfect con-
tinuation of the ﬁrst one.
On top of being elegant and quite intriguing,
such protocols are relevant because they probe
more deeply the dynamics of aging materials, allo-
wing one to ask more precise questions beyond the
simplistic observation that “this material displays
aging.” Moreover, the observation of similar
effects in many different glassy materials implies
that these effects are intrinsic to systems with slow
dynamics. Interesting also are the subtle differ-
ences observed from one material to the other.
Several experimental, numerical and theoreti-
cal papers have been devoted to this type of
experiments, and these effects are not “mysteri-
ous” anymore (see Barrat et al. (2004)). A clear
link
between
memory
effects
and
typical
lengthscales over which the slow dynamics takes
place has been established. Because lengthscales
depend so sensitively on timescales and on the
working temperature, experiments performed at
two different temperatures typically probe very
different lengthscales, allowing the system to
store memory of its state at different temperatures
over
different
lengthscales
(Berthier
and
Bouchaud 2002; Bouchaud et al. 2001). In return,
this link has been elegantly exploited to obtain a
rather precise experimental estimate of dynamic
lengthscales involved in the aging dynamics of
spin glass materials (Bert et al. 2004), which
seems to conﬁrm the slow logarithmic growth
law mentioned before.
Discussion of the rejuvenation effect is slightly
more subtle. It is indeed not yet obvious that the
effect as it is observed in computer simulations
and reported, for example, in Fig. 22, is exactly
similar to the one observed in experiments. The
difﬁculty comes from the fact that some seem-
ingly innocuous details of the experimental pro-
tocol, such as the necessary use in experiments of
ﬁnite cooling rates, in fact play a crucial role and
inﬂuence the physics so that direct comparison
between experiments and simulations is difﬁcult.
In numerical work, rejuvenation can be attributed
to a gradual change with temperature of the nature
of spatial correlations between spins that develop
with time (Berthier and Young 2005; Berthier and
Bouchaud 2002). More drastic changes are pre-
dicted to occur in disordered systems as a result of
the chaotic evolution with temperature of the
metastable states in a spin glass (so-called chaos
effect (Bray and Moore 1987)), which could also
be responsible for the observed rejuvenation
effect (Jönsson et al. 2004).
Mean-Field Aging and Effective Temperatures
Theoretical studies of mean-ﬁeld glassy models
have provided important insights into the aging
dynamics of both structural and spin glasses
(Cugliandolo and Kurchan 1993, 1994). Although
such models are deﬁned in terms of spin degrees of
freedom interacting via inﬁnite-ranged interac-
tions, the deep connections between them and the
mode-coupling theory of the glass transition make
them serious candidates to investigate glassy states
in general, not only thermodynamic properties at
thermal equilibrium but also nonequilibrium aging
dynamics. Despite their often reported “simplic-
ity,” it took several years to derive a proper asymp-
totic solution of the long-time dynamics for a series
of mean-ﬁeld spin glasses (see Cugliandolo in
Barrat et al. (2004)). These results have then trig-
gered an enormous activity (Crisanti and Ritort
2003) encompassing theoretical, numerical, and
also experimental work trying to understand further
these results, and to check in more realistic systems
whether they have some reasonable range of appli-
cability beyond mean-ﬁeld.
Glasses and Aging, A Statistical Mechanics Perspective on
281

This large activity, by itself, easily demonstrates
the broad interest of these results. More recently,
the derivation of the static properties of liquids and
glasses in large dimensions has renewed the inter-
est in mean-ﬁeld dynamic phenomena (Parisi et al.
2020).
In
particular,
the
dynamic
equations
governing the equilibrium properties of super-
cooled
liquids
have
now
been
derived
(Maimbourg et al. 2016; Kurchan et al. 2016) and
their consequences are being explored (Manacorda
et al. 2020). The study of the nonequilibrium
(aging and sheared) dynamics is now under way
(Agoritsas et al. 2018, 2019; Altieri et al. 2020).
In these mean-ﬁeld models, thermal equilibrium
is never reached, and aging proceeds by downhill
motion in an increasingly ﬂat free energy landscape
(Kurchan and Laloux 1996), with subtle differ-
ences between spin glass and structural glass
models. In both cases, however, time translational
invariance is broken, and two-time correlation and
response functions depend on both their temporal
arguments. In fact, the exact dynamic solution of
the equations of motion for time correlators dis-
plays behaviors in strikingly good agreement with
the numerical results reported in Fig. 21.
In these systems, the equations of motion in the
aging regime involve not only temporal correla-
tions, but also time-dependent response functions.
At thermal equilibrium, response and correlation
are
not
independent,
since
the
ﬂuctuation-
dissipation theorem (FDT) relates both quantities.
In aging systems, there is no reason to expect the
FDT to hold and both quantities carry, at least in
principle, distinct physical information. Again,
the asymptotic solution obtained for mean-ﬁeld
models quantitatively establishes that the FDT
does not apply in the aging regime. Unexpectedly,
the solution also shows that a generalized form of
the FDT holds at large waiting times (Cugliandolo
and Kurchan 1993). This is deﬁned in terms of the
two-time connected correlation function for some
generic observable A(t),
C t, tw
ð
Þ ¼ A tð ÞA tw
ð
Þ
h
i  A tð Þ
h
i A tw
ð
Þ
h
i,
ð42Þ
with t  tw, and the corresponding two-time
(impulse) response function
R t, tw
ð
Þ ¼ T d A tð Þ
h
i
dh tw
ð
Þ

h¼0
:
ð43Þ
Here h denotes the thermodynamically conju-
gate ﬁeld to the observable A so that the perturba-
tion to the Hamiltonian (or energy function) is
δE ¼ hA, and angled brackets indicate an aver-
age over initial conditions and any stochasticity in
the dynamics. Note that we have absorbed the
temperature T in the deﬁnition of the response,
for convenience. The associated generalized FDT
reads then
R t, tw
ð
Þ ¼ X t, tw
ð
Þ @
@tw C t, tw
ð
Þ,
ð44Þ
with X(t, tw) the so-called ﬂuctuation-dissipation
ratio (FDR). At equilibrium, correlation and
response functions are time translation invariant,
depending only on t ¼t – tw, and equilibrium FDT
imposes that X(t, tw) ¼ 1 at all times. A parametric
ﬂuctuation-dissipation (FD) plot of the step
response or susceptibility
w t, tw
ð
Þ ¼
ðt
tw
dt0R t, t0
ð
Þ,
ð45Þ
against
DC t, tw
ð
Þ ¼ C t, t
ð
Þ ¼ C t, tw
ð
Þ,
ð46Þ
is then a straight line with unit slope. These sim-
pliﬁcations do not occur in nonequilibrium sys-
tems. But the deﬁnition of an FDR through
Eq. (44) becomes signiﬁcant for aging systems
(Cugliandolo and Kurchan 1993, 1994). In
mean-ﬁeld spin glass models the dependence of
the FDR on both temporal arguments is only
through the correlation function,
X t, tw
ð
Þ 	 X C t, tw
ð
Þ
ð
Þ,
ð47Þ
valid at large waiting times, tw ! 1. For mean-
ﬁeld structural glass models, the simplication (47)
is even more spectacular since the FDR is shown
to be characterized by only two numbers instead
of a function, namely X ~ 1 at short times (large
282
Glasses and Aging, A Statistical Mechanics Perspective on

value of the correlator) corresponding to a quasi-
equilibrium regime, with a crossover to a non-
trivial number, X ~ X 1 for large times (small
value of the correlator). This implies that paramet-
ric FD plots are simply made of two straight lines
with slope 1 and X 1, instead of the single straight
line of slope 1 obtained at equilibrium.
Since any kind of behavior is in principle allo-
wed in nonequilibrium situations, getting such a
simple, equilibrium-like structure for the FD rela-
tions is a remarkable result. This immediately led
to the idea that aging systems might be character-
ized by an effective thermodynamic behavior and
the idea of quasi-equilibration at different time-
scales (Cugliandolo et al. 1997). In particular,
generalized FD relations suggest to deﬁne an
effective temperature, as
Teff ¼
T
X t, tw
ð
Þ ,
ð48Þ
such that mean-ﬁeld glasses are characterized by a
unique effective temperature, Teff ¼ T/X1 It is
thought of as the temperature at which slow
modes are quasi-equilibrated. One ﬁnds in general
that 0 < X1 < 1, such that Teff > T, as if the
system had kept some memory of its high temper-
ature initial state.
The name “temperature” for the quantity
deﬁned in Eq. (48) is not simply the result of a
dimensional analysis but has a deeper, physically
appealing meaning that is revealed by asking the
following questions. How does one measure tem-
peratures in a many-body system whose relaxa-
tion involves well-separated timescales? What is a
thermometer (and a temperature) in a far from
equilibrium aging material? Answers are provided
in Cugliandolo et al. (1997), and Kurchan (2005)
both for mean-ﬁeld models and for additional toy
models with multiple relaxation timescales. The
idea is to couple an additional degree of freedom,
such as a harmonic oscillator, x(t), which plays the
role of the thermometer operating at frequency w,
to an observable of interest A(t) via a linear cou-
pling, lx(t)A(t). Simple calculations show then
that the thermometer “reads” the following
temperature,
1
2 KBT2
meas ¼ 1
2 o2 x2


¼ oC0 o, tw
ð
Þ
2w00 o, tw
ð
Þ ,
ð49Þ
where C0(o, tw) is the real part of the Fourier
transform of Eq. (42), and w(o, tw) the imaginary
part of the Fourier transform of Eq. (43), with
h ¼ lx. The relation (49) indicates that the bath
temperature is measured, Tmeas ¼ T, if the fre-
quency is high and FDT is satisﬁed, while Tmeas ¼
Teff > T if the frequency is slow enough to be
tuned to that of the slow relaxation in the aging
material. The link between the FDR in Eq. (44)
and
the
effective
temperature
measured
in
Eq. (49) was numerically conﬁrmed in the com-
puter simulation of a glassy molecular liquid in
Berthier and Barrat (2002a).
More generally, relaxation in glassy systems
occurs
in
well-separated
time
sectors
(Cugliandolo and Kurchan 1994); it is then easy
to imagine that each sector could be associated
with an effective temperature (Kurchan 2005).
A thermodynamic interpretation of effective tem-
peratures has also been put forward, relating them
to the concept of replica symmetry breaking
(Franz et al. 1998). Interestingly, the full-step or
one-step replica symmetry breaking schemes
needed to solve the static problem in these models
have a counterpart as the FDR being a function or
a number, respectively, in the aging regime. More-
over, we note that these modern concepts are
related to, but make much more precise, older
ideas of quasi-equilibrium and ﬁctive tempera-
tures in aging glasses (Struik 1977).
Taken together, these results make the mean-
ﬁeld description of aging very appealing, and they
nicely complement the mode-coupling/RFOT
description of the equilibrium glass transition
described above. Moreover, they have set the
agenda for a large body of numerical and experi-
mental work, as reviewed in Crisanti and Ritort
(2003). In Fig. 23 we present recent numerical
data obtained in an aging silica glass (Berthier
2007b), presented in the form of a parametric
response-correlation plot. The measured correla-
tion functions are the self-part of the intermediate
scattering functions deﬁned in Eq. (5), while the
conjugated
response
functions
quantify
the
Glasses and Aging, A Statistical Mechanics Perspective on
283

response of particle displacements to a spatially
modulated ﬁeld conjugated to the density. Plots
for silicon and oxygen atoms at different ages are
presented. They seem to smoothly converge
toward a two-straight line plot, as obtained in
mean-ﬁeld models (note, however, that this
could be just a pre-asymptotic, ﬁnite “tw,” effect).
Moreover, the second, nontrivial part of the plot is
characterized by a slope that appears to be inde-
pendent of the species, and of the wavevector
chosen to quantify the dynamics, in agreement
with the idea of a unique asymptotic value of the
FDR, possibly related to a well-deﬁned effective
temperature.
Beyond Mean-Field: Real Space
Despite successful results, such as those shown in
Fig. 23, the broader applicability of the mean-ﬁeld
scenario of aging dynamics remains still unclear.
While some experiments and simulations indeed
seem to support the existence of well-behaved
effective
temperatures
(Grigera
and
Israeloff
1999; Abou and Gallet 2004; Wang et al. 2006),
other studies also reveal the limits of the mean-ﬁeld
scenario. Experiments have for instance reported
anomalously large FDT violations associated with
intermittent dynamics (Bellon et al. 2001; Bellon
and Ciliberto 2002; Buisson et al. 2003a, b), while
theoretical studies of model systems have also
found non-monotonic or even negative response
functions (Talbot et al. 2003; Nicodemi 1999;
Krzkala 2005; Depken and Stinchcombe 2005),
and ill-deﬁned or observable-dependent FDRs
(Fielding and Sollich 2002). In principle, these
discrepancies with mean-ﬁeld predictions are to
be expected, since there are many systems of phys-
ical interest in which the dynamics are not of mean-
ﬁeld type, displaying both activated processes and
spatial heterogeneity.
It is thus an important task to understand from
the theoretical point of view when the mean-ﬁeld
concept of an FDR-related effective temperature
remains viable. However, theoretically studying
the
interplay
between
relevant
dynamic
lengthscales and thermally activated dynamics in
the nonequilibrium regime of disordered materials
is clearly a challenging task. Nevertheless, this
problem has been approached in different ways,
as we brieﬂy summarize in this subsection.
A ﬁrst class of system that displays aging and
spatial heterogeneity is given by coarsening sys-
tems. The paradigmatic situation is that of an Ising
ferromagnetic model (with a transition at Tc) sud-
denly quenched in the ferromagnetic phase at time
tw ¼ 0. For tw > 0, domains of positive and
negative
magnetizations
appear
and
slowly
coarsen with time. The appearance of domains
that grow with time proves the presence of both
aging and heterogeneity.
The case where the quench is performed down
to T < Tc is well understood. The system becomes
scale invariant (Bray 1994), since the only rele-
vant lengthscale is the growing domain size, ‘(tw).
Correlation functions display aging, and scale
invariance
implies
that
C(t, tw)~f(‘(t)/‘(tw)).
Response functions can be decomposed into two
contributions (Barrat 1998; Berthier et al. 1999):
one part stems from the bulk of the domains and
behaves as the equilibrium response, and a second
one from the domain walls and becomes vanish-
ingly small in the long time limit, where ‘(tw) ! 1
and the density of domain walls vanishes. This
implies that for coarsening systems in d ≥2, one
has X1 ¼ 0, or equivalently an inﬁnite effective
temperature, Teff ¼ 1. The case d ¼ 1 is special
because Tc ¼ 0 and the response function remains
dominated by the domain walls, which yields the
4 × 104
1 × 104
2 × 103
t = 5 × 102
FDT
O
Si
T = 2500 K
C(t, t )
Tχ(t, t )
1.2
1
0.8
0.6
0.4
0.6
0.4
0.2
0
Glasses and Aging, A Statistical Mechanics Perspec-
tive on, Fig. 23 Parametric correlation-response plots
measured in the aging regime of a numerical model for a
silica glass, SiO2 (Berthier 2007b). The plots for both spe-
cies smoothly converges toward a two-straight line plot of
slope 1 at short times (large C values), and of slope
X 1 ≈0.51 at large times (small values of C), yielding an
effective temperature of about Teff ¼ T/X 1 ≈4900 K. Note
that the glass transition temperature of SiO2 is 1446 K
284
Glasses and Aging, A Statistical Mechanics Perspective on

nontrivial value X1 ¼ 1/2 (Godréche and Luck
2000; Lippiello and Zannetti 2000).
Another special case has retained attention.
When the quench is performed at T ¼ Tc, there is
no more distinction between walls and domains
and the above argument yielding X 1 ¼0 does not
hold. Instead one studies the growth of critical
ﬂuctuations with time, with x tw
ð
Þ ~
t1=z
w
the correla-
tion length at time tw, where z is the dynamic
exponent. Both correlation and response func-
tions become nontrivial at the critical point
(Godreche and Luck 2000). It proves useful in
that case to consider the dynamics of the Fourier
components of the magnetization ﬂuctuations,
Cq(t, tw) ¼ hmq(t)mq(tw)i, and the conjugated
response Rq t, tw
ð
Þ ¼
d mq tð Þ
h
i
dhq tw
ð
Þ: From Eq. (44) a wave-
vector-dependent FDR follows, Xq(t, tw), which
has interesting properties (Mayer et al. 2003)
(see Calabrese and Gambassi (2005) for a review).
In dimension d ¼ 1, it is possible to compute
Xq(t, tw) exactly in the aging regime at T ¼ Tc ¼ 0.
An interesting scaling form is found, and numer-
ical simulations performed for d > 1 conﬁrm its
validity:
Xq t, tw
ð
Þ ¼ w q2tw
	

,
ð50Þ
where the scaling function w(x) is w(x ! 1) ! 1 at
small lengthscale, qx  1, and w(x ! 0) ! 1/2
(in d ¼ 1) at large distance, qx  1; recall that z ¼
2 in that case.
Contrary to mean-ﬁeld systems where geome-
try played no role, here the presence of a growing
correlation lengthscale plays a crucial role in the
off-equilibrium regime since x(tw) allows one to
discriminate between ﬂuctuations that satisfy the
FDT at small lengthscale, Xq ~ 1, and those at
large lengthscale which are still far from equilib-
rium, 0 < Xq ~ X 1 < 1. These studies suggest
therefore that generalized ﬂuctuation-dissipation
relations in fact have a strong lengthscale depen-
dence – a result which is not predicted by mean-
ﬁeld approaches.
Another interesting result is that the FDT vio-
lation for global observables (i.e., those at q ¼ 0)
takes a particularly simple form, since the intro-
duction of a single number is sufﬁcient, the FDR
at zero wavevector, Xq ¼ 0(t, tw) ¼ X 1 ¼ 1/2
(in d ¼ 1). This universal quantity takes nontrivial
values
in
higher
dimension,
for
example,
X 1 ≈0.34 is measured in d ¼ 2 (Mayer et al.
2003). This shows that the study of global rather
than local quantities makes the measurement of
X 1 much easier. Finally, having a nontrivial
value of X 1 for global observables suggests that
the possibility to deﬁne an effective temperature
remains valid, but it has become a more compli-
cated object, related to global ﬂuctuations on large
lengthscale.
Kinetically constrained spin models represent
a second class of non-mean-ﬁeld systems whose
off-equilibrium has been thoroughly studied
recently (Léonard et al. 2007). This is quite a
natural thing to do since these systems have
local, ﬁnite ranged interactions, and they com-
bine the interesting features of being deﬁned in
terms of (effective) microscopic degrees of free-
dom,
having
local
dynamical
rules,
and
displaying thermally activated and heteroge-
neous dynamics.
The case of the Fredrickson-Andersen model,
described in section “Theory of the Glass Transi-
tion,” has been studied in great detail (Léonard
et al. 2007), and we summarize the main results.
Here, the relevant dynamic variables are the Fou-
rier components of the mobility ﬁeld, which also
correspond in that case to the ﬂuctuations of the
energy density. Surprisingly, the structure of the
generalized
ﬂuctuation-dissipation
relation
remains once more very simple. In particular, in
dimension d > 2, one ﬁnds a scaling form similar
to (50), Xq(t, tw) ¼ w(q2tw), with a well-deﬁned
limit at large distance Xq ¼0(t, tw) ¼X 1. The deep
analogy with critical Ising models stems from the
fact that mobility defects in KCMs diffuse in a
way similar to domain walls in coarsening Ising
models. It is in fact by exploiting this analogy that
analytic results are obtained in the aging regime of
the Fredrickson-Andersen model (Mayer and
Sollich 2007).
There is however a major qualitative differ-
ence between the two families of model.
The (big!) surprise lies in the sign of the
asymptotic FDR, since calculations show that
(Mayer et al. 2006)
Glasses and Aging, A Statistical Mechanics Perspective on
285

X1 ¼ 3, d > 2:
ð51Þ
In dimension d ¼ 1, one ﬁnds Xq ¼ 0(t, tw) ¼
f(t/tw) with Xq¼0 t ! 1, tw
ð
Þ ¼
3p
166p  3:307.
Numerical simulations conﬁrm these calculations.
In Fig. 24, we show such a comparison between
simulations (symbols) and theory (lines) in the
case of the d ¼ 3 Fredrickson-Andersen model
(Mayer et al. 2006). Fourier components of the
mobility ﬁeld yield parametric FD plots that fol-
low scaling with the variable q2tw, as a direct
result of the presence of a growing lengthscale
for dynamic heterogeneity, x tw
ð
Þ ~ﬃﬃﬃﬃﬃ
tw
p . Again, gen-
eralized ﬂuctuation-dissipation relations explic-
itly depend on the spatial lengthscale considered,
unlike in mean-ﬁeld studies. In Fig. 24, the limit
q ¼ 0 corresponding to global observables is also
very interesting since the plot is a pure straight
line, as in equilibrium. Unlike equilibrium, how-
ever, the slope is not 1 but 3. A negative slope in
this plot means a negative FDR, and therefore
suggests a negative effective temperature, a very
nonintuitive result at ﬁrst sight.
Negative response functions in fact directly
follows from the thermally activated nature of
the dynamics of these models (Mayer et al.
2006). First, one should note that the global
observable shown in Fig. 24 corresponds to ﬂuc-
tuations of the energy, e(tw), whose conjugated
ﬁeld is temperature. In the aging regime the sys-
tem slowly drifts toward equilibrium. Micro-
scopic moves result from thermally activated
processes, corresponding to the local crossing of
energy barriers. An inﬁnitesimal change in tem-
perature, T ! T þ δT with δT > 0, accelerates
these barrier crossings and makes the relaxation
dynamics faster. The energy response to a positive
temperature pulse is therefore negative, δe < 0,
which directly yields δe/δT < 0, which explains
the negative sign of the FDR. This result does not
hold in mean-ﬁeld glasses, where thermal activa-
tion plays no role.
Finally, another scenario holds for local
observables in some KCMs when kinetic con-
straints are stronger, such as the East model
(Léonard et al. 2007) or a bidimensional triangular
plaquette model (Jack et al. 2006b). Here, relaxa-
tion is governed by a hierarchy of energy barriers
that endow the systems with speciﬁc dynamic
properties. In the aging regime following a
quench, in particular, the hierarchy yields an
energy relaxation that arises in discrete steps
which take place on very different timescales,
reminiscent of the “time sectors” encountered in
mean-ﬁeld spin glasses. Surprisingly, it is found
that to each of these discrete relaxations one can
associate a well-deﬁned (positive) value of the
ﬂuctuation-dissipation ratio, again reminiscent of
Glasses and Aging, A Statistical Mechanics Perspec-
tive on, Fig. 24 Parametric response-correlation plots for
the Fourier components of the mobility ﬁeld in the d ¼ 3
Fredrickson-Andersen model. Symbols are from simula-
tions, lines from analytic calculations, and wavevectors
decrease from top to bottom. The FDT is close to being
satisﬁed at large q corresponding to local equilibrium. At
larger distance deviations from the FDT are seen, with an
asymptotic FDR which becomes negative. Finally, for
energy ﬂuctuations at q ¼ 0 (bottom curve), the plot
becomes a pure straight line of (negative!) slope  3, as a
result of thermally activated dynamics
286
Glasses and Aging, A Statistical Mechanics Perspective on

the dynamics of mean-ﬁeld spin glass models.
Therefore, a physical picture seems to have some
validity, even in models that are very far from the
mean-ﬁeld limit: in that picture, slow relaxation
takes place on multiple timescales, with each
timescale characterized by a different effective
temperature.
Beyond Mean-Field: Energy Landscape
What the mean-ﬁeld approach crucially lacks is
the description of activated processes that allow
the system to jump over larger and larger barriers
at large times. One way to introduce this key effect
is to study mean-ﬁeld models at ﬁnite system size
N. In fact, the mean ﬁeld theory of aging is derived
by ﬁrst taking the limit N ! 1 to study the
dynamics on large but ﬁnite timescales. Instead,
if one focuses on timescales that diverge exponen-
tially with N, activated processes will occur. One
can then analyze in a controlled way how jumping
over barriers alters the mean-ﬁeld dynamics.
This approach was pioneered numerically by
Crisanti and Ritort (2000a; b, 2003), and more
recently pursued further in (Baity-Jesi et al.
2018a, b; Billoire et al. 2005; Stariolo and
Cugliandolo 2019). One of the most important
outcomes of their study is to show the existence
of an effective temperature and its relation with
the energy landscape, more precisely the com-
plexity, even when barriers are crossed. The
understanding of the dynamical evolution in this
regime was reached recently by theoretical and
rigorous analysis of the Random Energy Model
(REM) in (Baity-Jesi et al. 2018a; Baity-Jesi et al.
2018b; Arous et al. 2002; Gayrard 2019). It was
shown that when observing the dynamics on
exponentially large (in N) timescales, activated
processes lead to a dynamical evolution that can
be mapped on the one of the trap model
(Bouchaud 1992; Dyre 1987). Again, an interest-
ing relation with the energy landscape emerges:
the exponent of the trapping time power law
describing aging dynamics at a given energy is
directly linked to the slope of the conﬁgurational
entropy at that energy. It is not yet clear whether
this scenario goes beyond the REM and applies,
for instance, to the Monte Carlo dynamics of the
p-spin model. In this case the energy landscape is
more complex and one needs to understand the
interplay between energy and entropic barriers
(Barrat
and
Mézard
1995;
Cammarota
and
Marinari 2015, 2018).
To this end, a series of recent works focused on
the organization in conﬁguration space of the
barriers that can be used to escape from a given
minimum for the p-spin spherical model. By using
the Kac-Rice formalism, these works computed
the entropy of the barriers at a given energy and at
a certain distance from a given minimum (Ros
et al. 2019) and obtained the dynamical instanton
representing the escape from a given minimum.
Finally, another set of works performed a com-
plementary study on ﬁnite size models of three
dimensional supercooled liquids. The key idea
was to focus on a size that is large enough to be
representative of the bulk behavior and small
enough to be able to study the dynamics in terms
of energy landscape (Büchner and Heuer 1999;
Doliwa and Heuer 2003; Heuer 2008). This led to
the introduction of the notion of metabasins, a set
of basins that corresponds to the same metastable
state. A study of the dynamics in terms of energy
barriers between metabasins was then performed.
It showed in a very compelling way that the
dynamics start to be activated even above the
MCT cross-over in 3D systems (Doliwa and
Heuer 2003; Denny et al. 2003). Interestingly, a
strong relationship with the dynamics of the trap
model was also found in this case (Heuer 2008).
All the results cited above provide valuable
information and insights on activated dynamics.
Interestingly, they show that relations between
aging dynamics and energy landscape found
within mean-ﬁeld theory seem to hold more
broadly. Many questions remain open and will
hopefully be addressed in future work, such as
understanding and characterizing the dynamical
paths and the barrier crossings leading to relaxa-
tion during the aging regime.
Driven Glassy Materials
We have introduced aging phenomena with the
argument that in a glass phase, the timescale to
equilibrate becomes so long that the system
always remembers its complete history. This is
true in general, but one can wonder whether it is
Glasses and Aging, A Statistical Mechanics Perspective on
287

possible to invent a protocol where the material
history could be erased, and the system “rejuve-
nated” (McKenna and Kovacs 1984). This con-
cept has been known for decades in the ﬁeld of
polymer
glasses,
where
complex
thermo-
mechanical histories are often used.
Let us consider an aging protocol where the
system is quenched to low temperature at time
tw ¼ 0, but the system is simultaneously forced
by an external mechanical constraint. Experimen-
tally one ﬁnds that a stationary state can be
reached, which explicitly depends on the strength
of the forcing: a system which is forced more
strongly relaxes faster than a material that is less
solicited, a phenomenon called “shear-thinning.”
The material has therefore entered a driven steady
state, where memory of its age is no longer present
and the dynamics have become stationary: aging
is stopped.
Many studies of these driven glassy states have
been performed in recent years. These studies are
relevant for the rheology of supercooled liquids and
glasses, and the T  Tg limit corresponds to studies
of the plasticity of amorphous solids, a broad ﬁeld
in itself, see section “Rheology.” In the colloidal
world, such studies are also relevant for the newly-
deﬁned ﬁeld of the rheology of “soft glassy mate-
rials.” These materials are (somewhat tautologi-
cally) deﬁned as those for which the nonlinear
rheological behavior is believed to result precisely
from the competition between intrinsically slow
relaxation processes and an external forcing
(Sollich et al. 1997; Ikeda et al. 2012). It is believed
that the rheology of dense colloidal suspensions,
foams, emulsions, binary mixtures, or even bio-
physical systems is ruled by such a competition,
which represents a broad scope for applications.
From the point of view of statmech modeling,
soft glassy rheology can be naturally studied from
the very same angles as the glass transition itself.
As such trap models (Sollich et al. 1997; Sollich
1998), mean-ﬁeld spin glasses (Berthier et al.
2000), and the related mode-coupling theory
approach (Miyazaki and Reichman 2002; Fuchs
and Cates 2002) have been explicitly extended to
include an external mechanical forcing. In all
these cases, one ﬁnds that a driven steady state
can be reached and aging is indeed expected to
stop at a level that depends on the strength of the
forcing. Many of the results obtained in aging
systems about the properties of an effective tem-
perature are also shown to apply in the driven
case, as shown both theoretically (Berthier et al.
2000) and numerically (Berthier and Barrat
2002b). A most interesting aspect is that the
broad relaxation spectra predicted to occur in
glassy materials close to a glass transition directly
translate into “anomalous” laws both for the linear
rheological behavior (seen experimentally in the
broad spectrum of elastic, G0(v) and loss, G00(v),
moduli), and the nonlinear rheological behavior
(a strong dependence of the viscosity  upon the
shear rate _g).
Future Directions
The problem of the glass transition, already very
exciting in itself, has ramiﬁcations well beyond
the physics of supercooled liquids. Glassy sys-
tems ﬁgure among the even larger class of “com-
plex systems.” These are formed by a set of
interacting degrees of freedom showing nontrivial
emergent behavior: as a whole they exhibit prop-
erties that are not already encoded in the deﬁnition
of the individual parts. As a consequence the
study of glass-formers as statistical mechanics
models characterized by frustrated interactions is
a fertile ground to develop new concepts and
techniques that will likely be applied to other
physical, and more generally, scientiﬁc situations.
An example, already cited in this review, is the
progress obtained in computer science and infor-
mation theory (Bouchaud et al. 2011) using tech-
niques originally developed for spin glasses and
structural glasses. There is no doubt that progress
will steadily continue in the future along these
interdisciplinary
routes.
Concerning
physics,
glassiness is such a ubiquitous and, yet as we
showed, rather poorly understood problem that
many developments are very likely to take place
in the next decade.
Instead of guessing future developments of the
ﬁeld (and then very likely be proven wrong), we
prefer to list a few problems we would like to see
solved in the next years.
288
Glasses and Aging, A Statistical Mechanics Perspective on

•
Is the glass transition related to a true phase
transition? If yes, a static or a dynamic one?
A ﬁnite or zero temperature one?
•
Do
RFOT
theory,
defects
models,
or
frustration-based
theory
form
the
correct
starting points of “the” theory of the glass
transition?
•
Is MCT really a useful theory for the ﬁrst
decades of slowing down of the dynamics?
Can one ﬁnd direct evidence that an avoided
MCT
transition
exists
and
controls
the
dynamics?
•
What is the correct physical picture for the low
temperature phase of glass-forming liquids and
spin glasses?
•
Are there general principles governing off-
equilibrium dynamics, and in particular aging
and sheared materials?
•
Do non-disordered, ﬁnite-dimensional, and
ﬁnite-range statmech model exist that display
a thermodynamically stable amorphous phase
at low temperature?
Finally, notice that we did not discuss possible
interplays between glassiness, disorder, and quan-
tum ﬂuctuations. This is a very fascinating topic
that has boomed in recent years; new phenomena
such as Many-Body Localization (Nandkishore
and Huse 2015) and Quantum Scars (Turner
et al. 2018) have been discovered, revealing new
facets of slow dynamics. Models of classical
glasses, such as the KCMs and the p-spin models,
found new applications in this arena (Pancotti
et al. 2020; Facoetti et al. 2019).
Acknowledgments This work was supported by a grant
from the Simons Foundation (Grant No. 454933, L. B.,
Grant No. 454935, G. B.)
Bibliography
Abou B, Gallet F (2004) Phys Rev Lett 93:160603
Adam G, Gibbs JH (1965) J Chem Phys 43:139
Adhikari AN, Capurso NA, Bingemann D (2007) J Chem
Phys 127:114508
Agoritsas E, Biroli G, Urbani P, Zamponi F (2018) J Phys
A Math Theor 51:085002
Agoritsas E, Maimbourg T, Zamponi F (2019) J Phys
A Math Theor 52:144002
Albert S, Bauer T, Michl M, Biroli G, Bouchaud J-P,
Loidl A, Lunkenheimer P, Tourbot R, Wiertel-Gasquet-
C, Ladieu F (2016) Science 352:1308
Allen M, Tildesley D (1989) New York/Oxford, p 385
Altieri A, Biroli G, Cammarota C (2020) arXiv preprint
arXiv:2005.05118
Anandkumar A, Ge R, Hsu D, Kakade SM, Telgarsky
M (2014) J Mach Learn Res 15:2773
Angelani L, Paoluzzi M, Parisi G, Ruocco G (2018) Proc
Natl Acad Sci 115:8700
Angelini MC, Biroli G (2017) Proc Natl Acad Sci 114:
3328
Angelini TE, Hannezo E, Trepat X, Marquez M, Fredberg
JJ, Weitz DA (2011) Proc Natl Acad Sci 108:4714
Angell CA (1995) Science 267:1924
Angell CA (1997) J Res Natl Inst Stand Technol 102:171
Antenucci F, Franz S, Urbani P, Zdeborová L (2019) Phys
Rev X 9:011020
Appignanesi GA, Rodríguez Fris JA, Montani RA, Kob
W (2006) Phys Rev Lett 96:057801
Arous GB, Bovier A, Gayrard V (2002) Phys Rev Lett 88:
087201
Baity-Jesi M, Baños R, Cruz A, Fernandez LA, Gil-
Narvion
JM,
Gordillo-Guerrero
A,
Iniguez
D,
Maiorano
A,
Mantovani
F,
Marinari
E
et
al
(2013) Phys Rev B 88:224416
Baity-Jesi M, Achard-de Lustrac A, Biroli G (2018a) Phys
Rev E 98:012133
Baity-Jesi M, Biroli G, Cammarota C (2018b) J Stat Mech:
Theory Exp 2018:013301
Baity-Jesi M, Sagun L, Geiger M, Spigler S, Arous GB,
Cammarota C, LeCun Y, Wyart M, Biroli G (2019)
J Stat Mech: Theory Exp 2019:124013
Bapst V, Keck T, Grabska-Barwińska A, Donner C, Cubuk
ED, Schoenholz S, Obika A, Nelson A, Back T,
Hassabis D et al (2020) Nat Phys 16:448
Barrat A (1998) Phys Rev E 57:3629
Barrat A, Mézard M (1995) J Phys I 5:941
Barrat J-L, Feigelman M, Kurchan J et al (2004) Slow
relaxations and nonequilibrium dynamics in condensed
matter 77. Springer, Berlin, Heidelberg, https://doi.org/
10.1007/978-3-540-44835-8_5
Bässler H (1987) Phys Rev Lett 58:767
Bauer T, Lunkenheimer P, Loidl A (2013) Phys Rev Lett
111:225702
Bechinger C, Di Leonardo R, Löwen H, Reichhardt C,
Volpe G, Volpe G (2016) Rev Mod Phys 88:045006
Bellon L, Ciliberto S (2002) Physica D 168:325
Bellon L, Ciliberto S, Laroche C (2001) EPL (Europhys
Lett) 53:511
Bengtzelius U, Gotze W, Sjolander A (1984) J Phys
C Solid State Phys 17:5915
Bennemann C, Donati C, Baschnagel J, Glotzer SC
(1999) Nature 399:246
Berges J, Tetradis N, Wetterich C (2002) Phys Rep 363:223
Bert F, Dupuis V, Vincent E, Hammann J, Bouchaud J-P
(2004) Phys Rev Lett 92:167203
Berthier L (2004) Phys Rev E 69:020201
Berthier L (2007a) Phys Rev E 76:011507
Berthier L (2007b) Phys Rev Lett 98:220601
Glasses and Aging, A Statistical Mechanics Perspective on
289

Berthier L (2013) Phys Rev E 88. https://doi.org/10.1103/
PhysRevE.88.022313
Berthier L (2014) Phys Rev Lett 112:220602
Berthier L, Barrat J-L (2002a) Phys Rev Lett 89:095702
Berthier L, Barrat J-L (2002b) J Chem Phys 116:6228
Berthier L, Biroli G (2011) Rev Mod Phys 83:587
Berthier L, Bouchaud J-P (2002) Phys Rev B 66:054404
Berthier L, Coslovich D (2014) Proc Natl Acad Sci 111:
11668
Berthier L, Ediger MD (2016) Phys Today 69:40
Berthier L, Garrahan JP (2003) J Chem Phys 119:4367
Berthier L, Garrahan JP (2005) J Phys Chem B 109:3578
Berthier L, Jack RL (2015) Phys Rev Lett 114. https://doi.
org/10.1103/PhysRevLett.114.205701
Berthier L, Kob W (2007) J Phys Condens Matter 19:
205130
Berthier L, Kob W (2012) Phys Rev E:85. https://doi.org/
10.1103/PhysRevE.85.011102
Berthier L, Kurchan J (2013) Nat Phys 9:310
Berthier L, Witten TA (2009) Phys Rev E 80:021502
Berthier L, Young A (2005) Phys Rev B 71:214429
Berthier L, Barrat J-L, Kurchan J (1999) Eur Phys
J B-Condens Matter Complex Syst 11:635
Berthier L, Barrat J-L, Kurchan J (2000) Phys Rev E 61:
5464
Berthier L, Chandler D, Garrahan JP (2004) EPL
(Europhys Lett) 69:320
Berthier L, Biroli G, Bouchaud J-P, Cipelletti L, El
Masri D, L’Hôte D, Ladieu F, Pierno M (2005) Science
310:1797
Berthier L, Biroli G, Bouchaud J-P, Kob W, Miyazaki K,
Reichman D (2007a) J Chem Phys 126:184503
Berthier L, Biroli G, Bouchaud J-P, Kob W, Miyazaki K,
Reichman DR (2007b) J Chem Phys 126:184504
Berthier L, Biroli G, Bouchaud J-P, Cipelletti L, van
Saarloos W (2011a) Dynamical heterogeneities in
glasses, colloids, and granular media, vol 150. OUP,
Oxford
Berthier L, Jacquin H, Zamponi F (2011b) Phys Rev E 84:
051103
Berthier L, Biroli G, Coslovich D, Kob W, Toninelli
C (2012) Phys Rev E 86:031502
Berthier L, Charbonneau P, Jin Y, Parisi G, Seoane B,
Zamponi F (2016a) Proc Natl Acad Sci 113:8397
Berthier L, Coslovich D, Ninarello A, Ozawa M (2016b)
Phys Rev Lett 116. https://doi.org/10.1103/Phys-
RevLett.116.238002
Berthier L, Charbonneau P, Yaida S (2016c) J Chem Phys
144:024501
Berthier L, Flenner E, Szamel G (2017a) New J Phys 19:
125006
Berthier L, Charbonneau P, Flenner E, Zamponi F (2017b)
Phys Rev Lett 119:188002
Berthier L, Charbonneau P, Coslovich D, Ninarello A,
Ozawa M, Yaida S (2017c) Proc Natl Acad Sci 114:
11356
Berthier L, Ozawa M, Scalliet C (2019a) J Chem Phys 150:
160902
Berthier L, Flenner E, Szamel G (2019b) J Chem Phys 150:
200901
Berthier L, Biroli G, Bouchaud J-P, Tarjus G (2019c)
J Chem Phys 150:094501
Berthier L, Biroli G, Charbonneau P, Corwin EI, Franz S,
Zamponi F (2019d) J Chem Phys 151:010901
Berthier L, Flenner E, Fullerton CJ, Scalliet C, Singh
M (2019e) J Stat Mech: Theory Exp 2019:064004
Berthier L, Charbonneau P, Kundu J (2019f) Phys Rev
E 99. https://doi.org/10.1103/PhysRevE.99.031301
Berthier L, Charbonneau P, Ninarello A, Ozawa M, Yaida
S (2019g) Nat Commun 10. https://doi.org/10.1038/
s41467-019-09512-3
Berthier L, Charbonneau P, Kundu J (2020) Phys Rev Lett
125:108001
Bi D, Yang X, Marchetti MC, Manning ML (2016) Phys
Rev X:6. https://doi.org/10.1103/Phys-RevX.6.021011
Billoire A, Giomi L, Marinari E (2005) EPL (Europhys
Lett) 71:824
Binder K, Kob W (2011) Glassy materials and disordered
solids: an introduction to their statistical mechanics.
World Scientiﬁc
Binder K, Young AP (1986) Rev Mod Phys 58:801
Biroli G, Bouchaud J-P (2004) EPL (Europhys Lett) 67:21
Biroli G, Bouchaud J-P (2012) Structural glasses and
supercooled liquids: theory, experiment, and applica-
tions. p 31
Biroli G, Cammarota C (2017) Phys Rev X 7:011011
Biroli G, Mézard M (2001) Phys Rev Lett 88:025501
Biroli G, Urbani P (2016) Nat Phys 12:1130
Biroli G, Urbani P (2018) SciPost Phys 4:020
Biroli G, Bouchaud J-P, Tarjus G (2005) J Chem Phys 123:
044510
Biroli G, Bouchaud J-P, Miyazaki K, Reichman DR
(2006) Phys Rev Lett 97:195701
Biroli G, Bouchaud J-P, Cavagna A, Grigera TS, Verroc-
chio P (2008) Nat Phys 4:771
Biroli G, Cammarota C, Tarjus G, Tarzia M (2014) Phys
Rev Lett 112:175701
Biroli G, Rulquin C, Tarjus G, Tarzia M (2016) SciPost
Phys 1. https://doi.org/10.21468/SciPostPhys.1.1.007
Biroli G, Cammarota C, Tarjus G, Tarzia M (2018a) Phys
Rev B 98:174205
Biroli G, Cammarota C, Tarjus G, Tarzia M (2018b) Phys
Rev B 98:174206
Boattini E, Marín-Aguilar S, Mitra S, FofﬁG, Smallenburg F,
Filion L (2020) arXiv preprint arXiv:2003.00586
Bouchaud J-P (1992) J Phys I 2:1705
Bouchaud J-P, Biroli G (2004) J Chem Phys 121:7347
Bouchaud J-P, Biroli G (2005) Phys Rev B 72:064204
Bouchaud J-P, Dupuis V, Hammann J, Vincent E (2001)
Phys Rev B 65:024439
Bouchaud J-P, Mézard M, Dalibard J (2011) Complex
systems: lecture notes of the les Houches Summer
School 2006. Elsevier
Brambilla G, El Masri D, Pierno M, Berthier L,
Cipelletti L, Petekidis G, Schoﬁeld AB (2009) Phys
Rev Lett 102:085703
290
Glasses and Aging, A Statistical Mechanics Perspective on

Bray A (1994) Adv Phys 43:357
Bray A, Moore M (1984) J Phys C Solid State Phys 17:
L463
Bray A, Moore M (1987) Phys Rev Lett 58:57
Brito C, Wyart M (2009) J Chem Phys 131:149
Brito C, Lerner E, Wyart M (2018) Phys Rev X 8. https://
doi.org/10.1103/PhysRevX.8.031050
Brun C, Ladieu F, LHôte D, Biroli G, Bouchaud J (2012)
Phys Rev Lett 109:175702
Büchner S, Heuer A (1999) Phys Rev E 60:6507
Buisson L, Bellon L, Ciliberto S (2003a) J Phys Condens
Matter 15:S1163
Buisson L, Ciliberto S, Garcimartin A (2003b) EPL
(Europhys Lett) 63:603
Butler S, Harrowell P (1991) J Chem Phys 95:4454
Buttinoni I, Bialké J, Kümmel F, Löwen H, Bechinger C,
Speck T (2013) Phys Rev Lett 110:238301
Calabrese P, Gambassi A (2005) J Phys A Math Gen 38:
R133
Cammarota C (2013) EPL (Europhys Lett) 101:56001
Cammarota C, Biroli G (2012) Proc Natl Acad Sci 109:
8850
Cammarota C, Biroli G (2013) J Chem Phys 138:12A547
Cammarota C, Marinari E (2015) Phys Rev E 92:010301
Cammarota C, Marinari E (2018) J Stat Mech: Theory Exp
2018:043303
Cammarota C, Seoane B (2016) Phys Rev B 94:180201
Cammarota C, Biroli G, Tarzia M, Tarjus G (2011) Phys
Rev Lett 106:115705
Candelier R, Dauchot O, Biroli G (2009) Phys Rev Lett
102:1
Candelier
R,
Widmer-Cooper
A,
Kummerfeld
JK,
Dauchot O, Biroli G, Harrowell P, Reichman DR
(2010a) Phys Rev Lett 105:135702. https://doi.org/10.
1103/PhysRevLett.105.135702
Candelier R, Dauchot O, Biroli G (2010b) EPL (Europhys
Lett) 92:24003
Cardenas M, Franz S, Parisi G (1999) J Chem Phys 110:
1726
Castellana M, Decelle A, Franz S, Mézard M, Parisi
G (2010) Phys Rev Lett 104:127206
Castellani T, Cavagna A (2005) J Stat Mech: Theory Exp
2005:P05012
Cavagna A (2009) Phys Rep 476:51
Cavagna A, Grigera TS, Verrocchio P (2007) Phys Rev
Lett 98:187801
Cavagna A, Grigera TS, Verrocchio P (2012) J Chem Phys
136:204502
Chaikin PM, Lubensky TC, Witten TA (1995) Principles of
condensed matter physics, vol 10. Cambridge Univer-
sity Press, Cambridge
Chakrabarty S, Karmakar S, Dasgupta C (2015) Sci Rep 5:
12577
Chakrabarty S, Das R, Karmakar S, Dasgupta C (2016)
J Chem Phys 145:034507
Chandler D, Garrahan JP, Jack RL, Maibaum L, Pan AC
(2006) Phys Rev E 74:051501
Charbonneau P, Tarjus G (2013) Phys Rev E 87:042305
Charbonneau P, Corwin EI, Parisi G, Zamponi F (2012)
Phys Rev Lett 109:205501
Charbonneau P, Kurchan J, Parisi G, Urbani P, Zamponi
F (2014a) Nat Commun 5:1
Charbonneau P, Kurchan J, Parisi G, Urbani P, Zamponi
F (2014b) J Stat Mech: Theory Exp 2014:P10009
Charbonneau P, Corwin EI, Parisi G, Zamponi F (2015)
Phys Rev Lett 114:125504
Charbonneau P, Corwin EI, Parisi G, Poncet A, Zamponi
F (2016a) Phys Rev Lett 117:045503
Charbonneau P, Dyer E, Lee J, Yaida S (2016b) J Stat
Mech: Theory Exp 2016:074004
Charbonneau P, Kurchan J, Parisi G, Urbani P, Zamponi
F (2017) Annu Rev Condens Matter Phys 8:265
Chaudhuri P, Berthier L, Kob W (2007) Phys Rev Lett 99:
060604
Chaudhuri P, Berthier L, Sastry S (2010) Phys Rev Lett
104:165701
Chen Z, Sepúlveda A, Ediger M, Richert R (2013) J Chem
Phys 138:12A519
Cheng Z, Zhu J, Chaikin PM, Phan S-E, Russel WB
(2002) Phys Rev E 65:041405
Cohen MH, Grest G (1982) Phys Rev B 26:6313
Coslovich D (2011) Phys Rev E Stat Nonlinear Soft Matter
Phys 83:1
Coslovich D, Pastore G (2007) J Chem Phys 127:124504
Coslovich D, Ozawa M, Berthier L (2018) J Phys Condens
Matter 30:144004
Crauste-Thibierge C, Brun C, Ladieu F, Lhôte D, Biroli G,
Bouchaud J-P (2010) Phys Rev Lett 104:165703
Crisanti A, Ritort F (2000a) EPL (Europhys Lett) 51:147
Crisanti A, Ritort F (2000b) EPL (Europhys Lett)
52:640
Crisanti A, Ritort F (2003) J Phys A Math Gen 36:R181
Cubuk ED, Schoenholz SS, Rieser JM, Malone BD,
Rottler J, Durian DJ, Kaxiras E, Liu AJ (2015) Phys
Rev Lett 114:1
Cubuk
ED,
Schoenholz
SS,
Kaxiras
E,
Liu
AJ
(2016) J Phys Chem B 120:6139. iSBN: 1520-5207
(Electronic) 1520-5207 (Linking)
Cubuk ED, Ivancic RJS, Schoenholz SS, Strickland DJ,
Basu A, Davidson ZS, Fontaine J, Hor JL, Huang Y-R,
Jiang Y, Keim NC, Koshigan KD, Lefever JA, Liu T,
Ma X-G, Magagnosc DJ, Morrow E, Ortiz CP, Rieser
JM, Shavit A, Still T, Xu Y, Zhang Y, Nordstrom KN,
Arratia PE, Carpick RW, Durian DJ, Fakhraai Z,
Jerolmack DJ, Lee D, Li J, Riggleman R, Turner KT,
Yodh AG, Gianola DS, Liu AJ (2017) Science 358:
1033. iSBN: 3487716170192
Cugliandolo LF, Kurchan J (1993) Phys Rev Lett 71:173
Cugliandolo LF, Kurchan J (1994) J Phys A Math Gen 27:
5749
Cugliandolo LF, Kurchan J, Peliti L (1997) Phys Rev E 55:
3898
D’Anna G, Grémaud G (2001) Nature 413:407
Dalle-Ferrier
C,
Thibierge
C,
Alba-Simionesco
C,
Berthier L, Biroli G, Bouchaud J-P, Ladieu F,
L’Hôte D, Tarjus G (2007) Phys Rev E 76:041510
Glasses and Aging, A Statistical Mechanics Perspective on
291

Darst RK, Reichman DR, Biroli G (2010) J Chem Phys
132:044510
Das SP, Mazenko GF (1986) Phys Rev A 34:2265
Dauchot O, Marty G, Biroli G (2005) Phys Rev Lett 95:
265701
Debenedetti PG (1996) Metastable liquids: concepts and
principles. Princeton University Press
Debenedetti PG, Stillinger FH (2001) Nature 410:259
DeGiuli E, Lerner E, Brito C, Wyart M (2014) Proc Natl
Acad Sci 111:17054
Degiuli E, Lerner E, Wyart M (2015) J Chem Phys 142:
164503
Denny RA, Reichman DR, Bouchaud J-P (2003) Phys Rev
Lett 90:025503
Depken M, Stinchcombe R (2005) Phys Rev E 71:065102
Deseigne J, Dauchot O, Chaté H (2010) Phys Rev Lett 105:
098001
Doliwa B, Heuer A (2003) Phys Rev E 67:030501
Donati C, Douglas JF, Kob W, Plimpton SJ, Poole PH,
Glotzer SC (1998) Phys Rev Lett 80:2338
Donati C, Franz S, Glotzer SC, Parisi G (2002) J Non-Cryst
Solids 307–310:215
Donev A, Torquato S, Stillinger FH, Connelly R (2004)
J Appl Phys 95:989
Donev A, Torquato S, Stillinger FH (2005) Phys Rev E 71:
011105
Downton MT, Kennett MP (2007) Phys Rev E 76:031502
Durian DJ (1995) Phys Rev Lett 75:4780
Dyre JC (1987) Phys Rev Lett 58:792
Dzero M, Schmalian J, Wolynes PG (2005) Phys Rev B 72:
100201
Ediger MD (2000) Annu Rev Phys Chem 51:99
Ediger MD (2017) J Chem Phys 147:210901
Elmatad YS, Keys AS (2012) Phys Rev E Stat Nonlinear
Soft Matter Phys 85:061502
Elmatad Y, Chandler D, Garrahan J (2009) J Phys Chem
B 113:5563
Elmatad
YS,
Jack
RL,
Chandler
D,
Garrahan
JP
(2010) Proc Natl Acad Sci 107:12793
Facoetti D, Biroli G, Kurchan J, Reichman DR (2019) Phys
Rev B 100:205108
Fernández L, Martín-Mayor V, Verrocchio P (2006) Phys
Rev E 73:020501
Fielding S, Sollich P (2002) Phys Rev Lett 88:050603
Fisher DS (1986) Phys Rev Lett 56:416
Fisher DS, Huse DA (1986) Phys Rev Lett 56:1601
Flenner E, Berthier L, Charbonneau P, Fullerton CJ
(2019) Phys Rev Lett 123:175501
Frank FC (1952) Proc R Soc Lond A Math Phys Sci 215:43
Franz S (2006) EPL (Europhys Lett) 73:492
Franz S, Parisi G (1997) Phys Rev Lett 79:2486
Franz S, Parisi G (1998) Physica A 23:317–339
Franz S, Parisi G (2000) J Phys Condens Matter 12:6335
Franz S, Parisi G (2013) J Stat Mech: Theory Exp 2013:
P11012
Franz S, Mézard M, Parisi G, Peliti L (1998) Phys Rev Lett
81:1758
Franz S, Donati C, Parisi G, Glotzer SC (1999) Philos Mag
B 79:1827. https://doi.org/10.1080/136428199
08223066
Franz S, Mulet R, Parisi G (2002) Phys Rev E 65:021506
Franz S, Parisi G, Ricci-Tersenghi F, Rizzo T (2011) Eur
Phys J E 34:1
Franz S, Parisi G, Ricci-Tersenghi F (2013) J Stat Mech:
Theory Exp 2013:L02001
Franz S, Parisi G, Urbani P, Zamponi F (2015) Proc Natl
Acad Sci 112:14539
Franz S, Parisi G, Sevelev M, Urbani P, Zamponi F (2017)
SciPost Phys 2:019
Fredrickson GH, Andersen HC (1984) Phys Rev Lett 53:
1244
Fredrickson GH, Brawer SA (1986) J Chem Phys 84:3351
Fuchs M, Cates ME (2002) Phys Rev Lett 89:248304
Fullerton CJ, Berthier L (2017) EPL (Europhys Lett) 119:
36003
Fullerton CJ, Jack RL (2014) Phys Rev Lett 112:255701
Ganapathi D, Nagamanasa KH, Sood A, Ganapathy
R (2018) Nat Commun 9:1
Garcia S, Hannezo E, Elgeti J, Joanny J-F, Silberzan P, Gov
NS (2015) Proc Natl Acad Sci 112:15314
Gardner E (1985) Nucl Phys B 257:747
Garrahan JP (2002) J Phys Condens Matter 14:1571
Garrahan JP, Chandler D (2002) Phys Rev Lett 89:035704
Garrahan JP, Chandler D (2003) Proc Natl Acad Sci 100:
9710. tex.eprint: https://www.pnas.org/content/100/17/
9710.full.pdf.
tex.publisher:
National
Academy
of
Sciences
Garrahan JP, Jack RL, Lecomte V, Pitard E, van
Duijvendijk K, van Wijland F (2007) Phys Rev Lett
98. https://doi.org/10.1103/Phys-RevLett.98.195702
Garrahan JP, Jack RL, Lecomte V, Pitard E, van
Duijvendijk K, van Wijland F (2009) J Phys A Math
Theor 42:075007
Gayrard V (2019) Probab Theory Relat Fields 174:501
Gazzillo D, Pastore G (1989) Chem Phys Lett 159:388
Gebremichael Y, Vogel M, Glotzer SC (2004) J Chem Phys
120:4415. https://doi.org/10.1063/1.1644539
Glarum SH (1960) J Chem Phys 33:639
Gleim T, Kob W, Binder K (1998) Phys Rev Lett 81:4404
Godréche C, Luck J (2000) J Phys A Math Gen 33:1151
Godreche C, Luck J (2000) J Phys A Math Gen 33:9141
Gokhale S, Nagamanasa KH, Ganapathy R, Sood A (2014)
Nat Commun 5:4685
Gokhale S, Sood A, Ganapathy R (2016) Adv Phys 65:363
Goldstein M (1969) J Chem Phys 51:3728
Götze W (1999) J Phys Condens Matter 11:A1
Grigera TS, Israeloff N (1999) Phys Rev Lett 83:5038
Grigera TS, Parisi G (2001) Phys Rev E 63. https://doi.org/
10.1103/PhysRevE.63.045102
Gross DJ, Mézard M (1984) Nucl Phys B 240:431
Guiselin B, Berthier L, Tarjus G (2020) arXiv preprint
arXiv:2004.10555
Gutiérrez R, Garrahan JP (2016) J Stat Mech: Theory Exp
2016:074005
292
Glasses and Aging, A Statistical Mechanics Perspective on

Gutiérrez R, Garrahan JP, Jack RL (2019) J Stat Mech:
Theory Exp 2019:094006
Hallett JE, Turci F, Royall CP (2018) Nat Commun 9:1
Hansen J-P, McDonald IR (1990) Theory of simple liquids.
Elsevier
Hartarsky I, Marêché L, Toninelli C (2019a) arXiv preprint
arXiv:1904.09145
Hartarsky I, Martinelli F, Toninelli C (2019b) arXiv pre-
print arXiv:1910.06782
Hedges LO, Jack RL, Garrahan JP, Chandler D (2009)
Science 323:1309
Henkes S, Fily Y, Marchetti MC (2011) Phys Rev E 84:
040301
Heuer A (2008) J Phys Condens Matter 20:373101
Hocky GM, Berthier L, Reichman DR (2014) J Chem Phys
141:224503
Hodge IM (1997) J Res Natl Inst Stand Technol 102:195
Hołyst R (2001) Physica A 292:255
Horbach J, Kob W (2001) Phys Rev E 64:041503
Hurley M, Harrowell P (1995) Phys Rev E 52:1694
Ikeda A, Berthier L, Sollich P (2012) Phys Rev Lett 109:
018301
Ikeda A, Berthier L, Biroli G (2013) J Chem Phys 138:
12A507
Ikeda H, Miyazaki K, Biroli G (2017a) EPL (Europhys
Lett) 116:56004
Ikeda H, Zamponi F, Ikeda A (2017b) J Chem Phys 147:
234506
Isobe M, Keys AS, Chandler D, Garrahan JP (2016) Phys
Rev Lett 117:1
Ivancic R, Cubuk E, Schoenholz S, Strickland D, Gianola D,
Liu A (2017) Bull Am Phys Soc 62:B16–013
Jack RL, Berthier L (2012) Phys Rev E 85:021120
Jack RL, Berthier L (2016) J Chem Phys 144:244506
Jack RL, Fullerton CJ (2013) Phys Rev E 88:042304
Jack RL, Garrahan JP (2005) J Chem Phys 123:164508
Jack RL, Garrahan JP (2010) Phys Rev E 81:011111
Jack RL, Garrahan JP (2016) Phys Rev Lett 116. https://
doi.org/10.1103/PhysRevLett.116.055702
Jack RL, Berthier L, Garrahan JP (2005) Phys Rev E 72:
016103
Jack RL, Mayer P, Sollich P (2006a) J Stat Mech: Theory
Exp 2006:P03006
Jack RL, Berthier L, Garrahan JP (2006b) J Stat Mech:
Theory Exp 2006:P12005
Jack RL, Hedges LO, Garrahan JP, Chandler D (2011)
Phys Rev Lett 107. https://doi.org/10.1103/
PhysRevLett.107.275702
Jaeger HM, Nagel SR, Behringer RP (1996) Rev Mod Phys
68:1259
Johari G (2000) J Chem Phys 112:7518
Jönsson P, Mathieu R, Nordblad P, Yoshino H, Katori HA,
Ito A (2004) Phys Rev B 70:174402
Jung Y, Garrahan JP, Chandler D (2004) Phys Rev E 69:
061205
Kapteijns G, Ji W, Brito C, Wyart M, Lerner E (2019) Phys
Rev E 99. https://doi.org/10.1103/Phys-RevE.99.012106
Karmakar S, Parisi G (2013) Proc Natl Acad Sci 110:2752
Karmakar
S,
Procaccia
I
(2011)
arXiv
preprint
arXiv:1105.4053
Kauzmann W (1948) Chem Rev 43:219
Kearns KL, Ediger M, Huth H, Schick C (2010) J Phys
Chem Lett 1:388
Kegel WK, van Blaaderen A (2000) Science 287:290
Keys AS, Abate AR, Glotzer SC, Durian DJ (2007) Nat
Phys 3:260
Keys AS, Hedges LO, Garrahan JP, Glotzer SC, Chandler
D (2011) Phys Rev X 1:1
Keys AS, Garrahan JP, Chandler D (2013) Proc Natl Acad
Sci 110:4482
Keys AS, Chandler D, Garrahan JP (2015) Phys Rev E Stat
Nonlinear Soft Matter Phys 92(1)
Khomenko D, Scalliet C, Berthier L, Reichman DR,
Zamponi F (2020) Phys Rev Lett 124:225901
Kim K (2003) EPL (Europhys Lett) 61:790
Kirkpatrick TR, Thirumalai D (1987) Phys Rev Lett 58:
2091
Kirkpatrick T, Wolynes P (1987a) Phys Rev A 35:3072
Kirkpatrick T, Wolynes P (1987b) Phys Rev B 36:8552
Kirkpatrick TR, Thirumalai D, Wolynes PG (1989) Phys
Rev A 40:1045
Kisker J, Santen L, Schreckenberg M, Rieger H (1996)
Phys Rev B 53:6418
Kivelson D, Kivelson SA, Zhao X, Nussinov Z, Tarjus
G (1995) Physica A 219:27
Klongvessa N, Ginot F, Ybert C, Cottin-Bizonne C,
Leocmach M (2019) Phys Rev Lett 123:248004
Kob W, Andersen HC (1993) Phys Rev E 48:4364
Kob W, Berthier L (2013) Phys Rev Lett 110:245702
Kob W, Coslovich D (2014) Phys Rev E 90:052305
Kob W, Donati C, Plimpton SJ, Poole PH, Glotzer SC
(1997) Phys Rev Lett 79:2827
Kob W, Roldán-Vargas S, Berthier L (2012) Nat Phys
8:164
Krakoviack V (2010) Phys Rev E 82:061501
Krakoviack V (2011) Phys Rev E 84:050501
Krakoviack V (2014) J Chem Phys 141:104504
Krzakala F, Montanari A, Ricci-Tersenghi F, Semerjian G,
Zdeborová L (2007) Proc Natl Acad Sci 104:10318
Krzkala F (2005) Phys Rev Lett 94:077204
Kurchan J (2005) Nature 433:222
Kurchan J, Laloux L (1996) J Phys A Math Gen 29:1929
Kurchan J, Parisi G, Zamponi F (2012) J Stat Mech:
Theory Exp 2012:P10012
Kurchan J, Parisi G, Urbani P, Zamponi F (2013) J Phys
Chem B 117:12979
Kurchan J, Maimbourg T, Zamponi F (2016) J Stat Mech:
Theory Exp 2016:033210
Lačević N, Starr FW, Schrøder T, Glotzer S (2003) J Chem
Phys 119:7372
Landes FP, Biroli G, Dauchot O, Liu AJ, Reichman DR
(2020) Phys Rev E 101:010602
Larson RG (1999) The structure and rheology of complex
ﬂuids, vol 150. Oxford University Press, New York
Glasses and Aging, A Statistical Mechanics Perspective on
293

Léonard S, Harrowell P (2010) J Chem Phys 133:244502
Léonard S, Mayer P, Sollich P, Berthier L, Garrahan JP
(2007) J Stat Mech: Theory Exp 2007:P07017
Lerner E, Düring G, Wyart M (2013) Soft Matter 9:8252
Lerner E, Düring G, Bouchbinder E (2016) Phys Rev Lett
117:035501
Leutheusser E (1984) Phys Rev A 29:2765
Li Y-W, Xu W-S, Sun Z-Y (2014) J Chem Phys 140:
124502
Li Y-W, Zhu Y-L, Sun Z-Y (2015) J Chem Phys 142:
124507
Liao Q, Berthier L (2019) Phys Rev X 9:011049
Lin J, Lerner E, Rosso A, Wyart M (2014) Proc Natl Acad
Sci 111:14382
Lipowski A, Johnston D, Espriu D (2000) Phys Rev E 62:
3404
Lippiello E, Zannetti M (2000) Phys Rev E 61:3369
Liu AJ, Nagel SR (1998) Nature 396:21
Liu AJ, Nagel SR (2010) Annu Rev Condens Matter Phys
1:347
Lyubimov I, Ediger MD, de Pablo JJ (2013) J Chem Phys
139:144505
Maimbourg T, Kurchan J, Zamponi F (2016) Phys Rev Lett
116:015902
Malins A, Eggers J, Royall CP, Williams SR, Tanaka
H (2013a) J Chem Phys 138:12A535
Malins A, Williams SR, Eggers J, Royall CP (2013b)
J Chem Phys 139:234506
Manacorda A, Schehr G, Zamponi F (2020) J Chem Phys
152:164506
Mandal R, Bhuyan PJ, Rao M, Dasgupta C (2016) Soft
Matter 12:6268
Mannelli SS, Biroli G, Cammarota C, Krzakala F, Urbani P,
Zdeborová L (2020) Phys Rev X 10:011057
Mapes MK, Swallen SF, Ediger MD (2006) J Phys Chem
B 110:507. https://doi.org/10.1021/jp0555955. PMID:
16471562
Marchetti MC, Joanny J-F, Ramaswamy S, Liverpool TB,
Prost J, Rao M, Simha RA (2013) Rev Mod Phys 85:
1143
Martinelli F, Morris R, Toninelli C (2019a) Commun Math
Phys 369:761
Martinelli F, Toninelli C et al (2019b) Ann Probab
47:324
Marty G, Dauchot O (2005) Phys Rev Lett 94:015701
Matoz-Fernandez D, Martens K, Sknepnek R, Barrat J,
Henkes S (2017) Soft Matter 13:3205
Mayer P, Sollich P (2007) J Phys A Math Theor 40:5823
Mayer P, Berthier L, Garrahan JP, Sollich P (2003) Phys
Rev E 68:016116
Mayer P, Léonard S, Berthier L, Garrahan JP, Sollich
P (2006) Phys Rev Lett 96:030602
McCullagh GD, Cellai D, Lawlor A, Dawson KA
(2005) Phys Rev E 71:030102
McKenna G, Kovacs A (1984) Polym Eng Sci 24:1138
Menon N, Nagel SR (1995) Phys Rev Lett 74:1230
Mézard M, Montanari A (2006) J Stat Phys 124:1317
Mézard M, Parisi G (1999) Phys Rev Lett 82:747
Mézard M, Parisi G, Virasoro M (1987) Spin glass theory
and beyond: an introduction to the replica method and
its applications, vol 9. World Scientiﬁc
Miyazaki K, Reichman DR (2002) Phys Rev E 66:050501
Mizuno H, Shiba H, Ikeda A (2017) Proc Natl Acad Sci
114:E9767
Monasson R (1995) Phys Rev Lett 75:2847
Mongera A, Rowghanian P, Gustafson HJ, Shelton E,
Kealhofer DA, Carn EK, Serwane F, Lucio AA,
Giammona J, Campàs O (2018) Nature 561:401
Montanari A, Semerjian G (2006) J Stat Phys 125:23
Mossa S, Tarjus G (2006) J Non-Cryst Solids 352:4847
Nandi SK, Biroli G, Tarjus G (2016) Phys Rev Lett 116:
145701
Nandkishore R, Huse DA (2015) Annu Rev Condens Mat-
ter Phys 6:15
Nelson DR (2002) Defects and geometry in condensed
matter physics. Cambridge University Press
Ni R, Stuart MAC, Dijkstra M (2013) Nat Commun 4:1
Niblett S, de Souza VK, Jack R, Wales D (2018) J Chem
Phys 149:114503
Nicodemi M (1999) Phys Rev Lett 82:3734
Ninarello AS (2017) Computer simulations of supercooled
liquids near the experimental glass transition, PhD the-
sis, Montpellier
Ninarello A, Berthier L, Coslovich D (2017) Phys Rev
X 7. https://doi.org/10.1103/PhysRevX.7.021039
Nishikawa Y, Hukushima K (2020) Phys Rev Lett 125:
065501
Noe F, Schutte C, Vanden-Eijnden E, Reich L, Weikl TR
(2009) Proc Natl Acad Sci 106:19011. iSBN: 0027-
8424
O’Hern CS, Langer SA, Liu AJ, Nagel SR (2002) Phys
Rev Lett 88:075507
Ohern CS, Silbert LE, Liu AJ, Nagel SR (2003) Phys Rev
E 68:011306
Ozawa M, Berthier L (2017) J Chem Phys 146:014502
Ozawa M, Ikeda A, Miyazaki K, Kob W (2018a) Phys Rev
Lett 121:205501
Ozawa M, Berthier L, Biroli G, Rosso A, Tarjus G (2018b)
Proc Natl Acad Sci 115:6656
Ozawa M, Parisi G, Berthier L (2018c) J Chem Phys 149:
154501
Ozawa M, Scalliet C, Ninarello A, Berthier L (2019)
J Chem Phys 151:084504
Paeng K, Park H, Hoang DT, Kaufman LJ (2015) Proc Natl
Acad Sci 112:4952
Pan AC, Garrahan JP, Chandler D (2005) Phys Rev E 72:
041106
Pancotti N, Giudice G, Cirac JI, Garrahan JP, Bañuls MC
(2020) Phys Rev X 10:021051
Pardo L, Lunkenheimer P, Loidl A (2007) Phys Rev E 76:
030502
Paret J, Jack RL, Coslovich D (2020) J Chem Phys 152:
144502
Parisi G, Seoane B (2014) Phys Rev E 89:022309
Parisi G, Slanina F (2000) Phys Rev E 62:6554
Parisi G, Zamponi F (2010) Rev Mod Phys 82:789
294
Glasses and Aging, A Statistical Mechanics Perspective on

Parisi G, Procaccia I, Rainone C, Singh M (2017) Proc Natl
Acad Sci 114:5577
Parisi G, Urbani P, Zamponi F (2020) Theory of simple
glasses: exact solutions in inﬁnite dimensions. Cam-
bridge University Press
Parmar ADS, Ozawa M, Berthier L (2020) Phys Rev Lett
125:085505
Pérez-Castañeda T, Rodríguez-Tinoco C,Rodríguez-Viejo J,
Ramos MA (2014) Proc Natl Acad Sci 111:11275
Peters IR, Majumdar S, Jaeger HM (2016) Nature 532:214
Phan AD, Schweizer KS (2018) J Chem Phys 148:054502
Pinchaipat R, Campo M, Turci F, Hallett JE, Speck T,
Royall CP (2017) Phys Rev Lett 119. https://doi.org/
10.1103/PhysRevLett.119.028004
Pusey PN, VanMegen W (1986) Nature 320:340
Ràfols-Ribé J, Will P-A, Hänisch C, Gonzalez-Silveira M,
Lenk S, Rodríguez-Viejo J, Reineke S (2018) Sci Adv
4:eaar8332
Rainone C, Urbani P (2016) J Stat Mech: Theory Exp
2016:053302
Rainone C, Urbani P, Yoshino H, Zamponi F (2015) Phys
Rev Lett 114:015701
Refregier P, Vincent E, Hammann J, Ocio M (1987) J Phys
48:1533
Reinsberg SA, Qiu XH, Wilhelm M, Spiess HW, Ediger
MD (2001) J Chem Phys 114:7299. https://doi.org/10.
1063/1.1369160
Richard E, Montanari A (2014) Advances in neural infor-
mation processing systems. pp 2897–2905
Richert R, Angell C (1998) J Chem Phys 108:9016
Ritort F, Sollich P (2003) Adv Phys 52:219
Rivoire O, Biroli G, Martin OC, Mézard M (2004) Eur
Phys J B-Condens Matter Complex Syst 37:55
Rizzo T (2016) Phys Rev B 94:014202
Ronhovde P, Chakrabarty S, Hu D, Sahu M, Sahu K,
Kelton K, Mauro N, Nussinov Z (2011) Eur Phys J E
34:105
Ronhovde P, Chakrabarty S, Hu D, Sahu M, Sahu KK,
Kelton KF, Mauro NA, Nussinov Z (2012) Sci Rep 2:1
Ros V, Biroli G, Cammarota C (2019) EPL (Europhys Lett)
126:20003
Royall CP, Kob W (2017) J Stat Mech: Theory Exp 2017.
https://doi.org/10.1088/1742-5468/aa4e92
Royall CP, Williams SR (2015) Phys Rep 560:1
Rulquin C, Urbani P, Biroli G, Tarjus G, Tarzia M (2016)
J Stat Mech: Theory Exp 2016:023209
Russell EV, Israeloff N (2000) Nature 408:695
Russo J, Tanaka H (2015) Proc Natl Acad Sci 112:6920
Sagun L, Guney VU, Arous GB, LeCun YA (2014) arXiv
preprint arXiv:1412.6615
Sausset F, Tarjus G, Viot P (2009) J Stat Mech: Theory Exp
2009:P04022
Scalliet C, Berthier L (2019) Phys Rev Lett 122:255502
Scalliet C, Berthier L, Zamponi F (2017) Phys Rev Lett
119:205501
Scalliet C, Berthier L, Zamponi F (2019a) Phys Rev E 99:
012107
Scalliet C, Berthier L, Zamponi F (2019b) Nat Commun 10:1
Scheidler P, Kob W, Binder K, Parisi G (2002) Philos Mag
B 82:283
Schoenholz SS (2018) In: Journal of Physics: conference
series, vol 1036. IOP Publishing, p 012021
Schoenholz SS, Cubuk ED, Sussman DM, Kaxiras E, Liu
AJ (2015) Nat Phys 12:469
Schoenholz SS, Cubuk ED, Kaxiras E, Liu AJ (2016) Proc
Natl Acad Sci 114:263
Schreck CF, Bertrand T, OHern CS, Shattuck M (2011)
Phys Rev Lett 107:078301
Seif A, Grigera TS (2016) arXiv preprint arXiv:1611.06754
Sepúlveda A, Tylinski M, Guiseppi-Elie A, Richert R,
Ediger M (2014) Phys Rev Lett 113:045901
Sethna JP, Shore JD, Huang M (1991) Phys Rev B 44:4943
Seyboldt R, Merger D, Coupette F, Siebenbürger M,
Ballauff M, Wilhelm M, Fuchs M (2016) Soft Matter
12:8825
Sharp TA, Thomas SL, Cubuk ED, Schoenholz SS,
Srolovitz DJ, Liu AJ (2018) Proc Natl Acad Sci 115:
10943
Shi R, Tanaka H (2019) Sci Adv 5:eaav3194
Skoge M, Donev A, Stillinger FH, Torquato S (2006) Phys
Rev E 74:041127
Sollich P (1998) Phys Rev E 58:738
Sollich P, Lequeux F, Hébraud P, Cates ME (1997) Phys
Rev Lett 78:2020
Speck T (2019) J Stat Mech: Theory Exp 2019:084015
Stariolo DA, Cugliandolo LF (2019) EPL (Europhys Lett)
127:16002
Stevenson JD, Walczak AM, Hall RW, Wolynes PG
(2008) J Chem Phys 129:194505
Struik L (1977) Polym Eng Sci 17:165
Swallen SF, Kearns KL, Mapes MK, Kim YS, McMahon
RJ, Ediger MD, Wu T, Yu L, Satija S (2007) Science
315:353
Szamel G (2018) Phys Rev E 98. https://doi.org/10.1103/
Phys-RevE.98.050601
Szamel G, Flenner E (2004) EPL (Europhys Lett) 67:779
Szamel G, Flenner E (2013) EPL (Europhys Lett) 101:
66005
Talbot J, Tarjus G, Viot P (2003) J Phys A Math Gen 36:
9009
Tarjus G, Kivelson D (1995) J Chem Phys 103:3071.
https://doi.org/10.1063/1.470495
Tarjus G, Kivelson SA, Nussinov Z, Viot P (2005) J Phys
Condens Matter 17:R1143
Tarzia
M,
Biroli
G,
Lefèvre
A,
Bouchaud
J-P
(2010) J Chem Phys 132:054501
Thalmann F, Dasgupta C, Feinberg D (2000) EPL
(Europhys Lett) 50:54
Theurkauff I, Cottin-Bizonne C, Palacci J, Ybert C,
Bocquet L (2012) Phys Rev Lett 108:268303
Tong H, Tanaka H (2018) Phys Rev X 8. https://doi.org/10.
1103/PhysRevX.8.011041
Toninelli C, Biroli G, Fisher DS (2004) Phys Rev Lett 92:
185504
Toninelli C, Wyart M, Berthier L, Biroli G, Bouchaud J-P
(2005) Phys Rev E 71:041505
Glasses and Aging, A Statistical Mechanics Perspective on
295

Toninelli C, Biroli G, Fisher DS (2006) Phys Rev Lett 96:
035702
Turci F, Tarjus G, Royall CP (2017a) Phys Rev Lett 118:1
Turci F, Royall CP, Speck T (2017b) Phys Rev X 7. https://
doi.org/10.1103/PhysRevX.7.031028
Turci F, Speck T, Royall CP (2018) Eur Phys J E 41. https://
doi.org/10.1140/epje/i2018-11662-3
Turci F, Patrick Royall C, Speck T (2019) J Phys Conf Ser
1252:012012
Turner RM, Jack RL, Garrahan JP (2015) Phys Rev E 92.
https://doi.org/10.1103/PhysRevE.92.022115
Turner CJ, Michailidis AA, Abanin DA, Serbyn M, Papić
Z (2018) Nat Phys 14:745
Urbani P, Zamponi F (2017) Phys Rev Lett 118:038001
van Hemmen J, Morgenstern I (1987) In: Lecture notes in
physics, vol 275. Springer, Berlin
van Meel JA, Charbonneau B, Fortini A, Charbonneau
P (2009) Phys Rev E 80:061110
Vest J-P, Tarjus G, Viot P (2014) Mol Phys 112:1330
Vest J-P, Tarjus G, Viot P (2015) J Chem Phys 143:084505
Vila-Costa
A,
Ràfols-Ribé
J,
González-Silveira
M,
Lopeandia
A,
Abad-Muñoz
L,
Rodríguez-Viejo
J (2020) Phys Rev Lett 124:076002
Wang P, Song C, Makse HA (2006) Nat Phys 2:526
Wang L, Ninarello A, Guan P, Berthier L, Szamel G,
Flenner E (2019a) Nat Commun 10:1
Wang L, Berthier L, Flenner E, Guan P, Szamel G (2019b)
Soft Matter 15:7018
Weeks ER, Crocker JC, Levitt AC, Schoﬁeld A, Weitz DA
(2000) Science 287:627
Weeks ER, Crocker JC, Weitz DA (2007) J Phys Condens
Matter 19:205131
Whitelam S, Garrahan JP (2004) J Phys Chem B 108:6611
Whitelam S, Berthier L, Garrahan JP (2004) Phys Rev Lett
92:185705
Whitelam S, Berthier L, Garrahan JP (2005) Phys Rev
E 71:026128
Widmer-Cooper A, Harrowell P (2006) Phys Rev Lett 96:
185701
Williams I, Turci F, Hallett JE, Crowther P, Cammarota C,
Biroli G, Royall CP (2018) J Phys Condens Matter 30:
094003
Wolynes PG (2009) Proc Natl Acad Sci
Wolynes PG, Lubchenko V (2012) Structural glasses and
supercooled liquids: theory, experiment, and applica-
tions. Wiley
Wuttke J, Petry W, Pouget S (1996) J Chem Phys 105:5177
Wyart M (2010) EPL (Europhys Lett) 89:64001
Wyart M (2012) Phys Rev Lett 109:125502
Wyart M, Cates ME (2017) Phys Rev Lett 119. https://doi.
org/10.1103/PhysRevLett.119.195501
Wyart M, Nagel SR, Witten TA (2005) EPL (Europhys
Lett) 72:486
Xia X, Wolynes PG (2000) Proc Natl Acad Sci 97:2990.
tex.eprint: https://www.pnas.org/content/97/7/2990.
full.pdf. tex.publisher: National Academy of Sciences
Yaida S, Berthier L, Charbonneau P, Tarjus G (2016) Phys
Rev E 94. https://doi.org/10.1103/Phys-RevE.94.032605
Yamamoto R, Onuki A (1998) Phys Rev E 58:3515
Yeo J, Moore M (2012) Phys Rev E 86:052501
Yoshino H, Zamponi F (2014) Phys Rev E 90:022302
Young AP (1998) Spin glasses and random ﬁelds, vol 12.
World Scientiﬁc
Zdeborová L, Krzakala F (2016) Adv Phys 65:453
Zhu L, Brian C, Swallen S, Straus P, Ediger M, Yu L (2011)
Phys Rev Lett 106:256103
296
Glasses and Aging, A Statistical Mechanics Perspective on

Stress Localization in Soft
Particulate Gels
Emanuela Del Gado
Department of Physics and Institute for Soft
Matter Synthesis and Metrology, Georgetown
University, Washington, DC, USA
Article Outline
Glossary
Deﬁnition of the Subject
Introduction
Source of Mechanical Heterogeneities and
Frozen-in Stresses: Microscopic Forces and
Gelation Processes
Origin of Elastic Modulus and Emergence of
Rigidity
Stress Localization at Rest and Under Shear
Future Directions
References
Glossary
Gels Refers to solid-like materials composed by
an interconnected matrix embedded in a sol-
vent. The matrix can be made by cross-linked
polymers that constitute a network in polymer
gels or particulate matter that further self-
assembles into a solid, porous matrix in other
cases. Particulate gels are also referred to as
colloidal gels when made of colloidal units,
that is, particles or aggregates that have sizes
from ~ 10nm to ~ 1mm.
Stress Refers to the force per unit area across a
plane that goes through a material. Internal
stresses result from the forces between the
microscopic components of the material, in
response to an external deformation or chang-
ing
environmental
conditions.
In
elastic
solids, external stresses produce a deforma-
tion associated to energy stored by adjusting
the
forces
between
the
microscopic
components.
Elasticity Refers to the capacity of a solid mate-
rial to store energy when subjected to a defor-
mation
or
a
load.
The
elastic
modulus
quantiﬁes the deformation that the solid mate-
rial can accommodate, by storing energy, when
subjected to an external load; or the amount of
energy per unit volume that can be stored when
subjected to a deformation and that translates
into an increase of stress.
Rigidity Refers to a solid structure that is
mechanically stable, has a ﬁnite elastic modu-
lus, and hence can support an external load
without ﬂowing or yielding.
Definition of the Subject
Many materials we eat, spread, squeeze, or 3D
print are gels, soft amorphous solids whose solid
component is constituted by a network of self-
assembled particles or agglomerated smaller
units (proteins, polymers, or other particulates).
The properties and mechanical performance of
these gels are determined by a complex interplay
between the molecular cohesion or surface inter-
actions in the solid component, the aggregation
kinetics that drive formation of various types of
structures, and the effect of external forces that
can promote breaking or reforming of the solid
network. Solidiﬁcation processes are typically
sources of frozen-in stresses in the load bearing
network and help build a memory of the pro-
cessing history in these amorphous solids. More-
over, the disorder in the stress-bearing structure
promotes and enhances stress localization under
load. The feedback between stress heterogene-
ities, structural disorder, and nonequilibrium
conditions is therefore key to the mechanical
response of these fascinating and ubiquitous
materials.
© Springer Science+Business Media, LLC, part of Springer Nature 2022
B. Chakraborty (ed.), Statistical and Nonlinear Physics,
https://doi.org/10.1007/978-1-0716-1454-9_734
Originally published in
R. A. Meyers (ed.), Encyclopedia of Complexity and Systems Science, © Springer Science+Business Media LLC 2021
https://doi.org/10.1007/978-3-642-27737-5_734-1
297

Introduction
Materials made from polymers, colloidal suspen-
sions and surfactants, are at the core of novel
technologies that require tunable mechanics. In
many cases, these soft and adaptive solids are
gels, that is, they are prevalently composed of a
ﬂuid
in
which
a
relatively
small
amount
(sometimes tiny!) of solid material is embedded.
The key is that the solid component, typically
made of small particles or aggregates, is spatially
organized into an open, porous network and
hence, in spite of being the minority constituent,
is able to provide rigidity and control the mechan-
ical response of the whole material. Gels are ubiq-
uitous in nature, probably because they provide
the means to optimize mechanical functionalities
without necessarily blocking transport or diffu-
sion of various substances, while they require in
principle arbitrarily small amounts of solid matter.
In the biological context, it is clear that their
highly adaptive and tunable rheological response
is central to biological functions. For technologi-
cal applications, because of the sparse and in
many case reconﬁgurable solid matrix embedded
in the ﬂuid, they can ﬂow, be stretched, squeezed,
or fractured. The small amount of actual solid
material needed makes them also extremely con-
venient to include new high-value functional
components while limiting costs and risks.
For gels obtained through polymerization reac-
tions or crosslinking of polymer solutions, poly-
mer physics provides the basis to understand their
rheology (de Gennes 1979; Rubinstein and Colby
2003). The elasticity is largely entropic in nature
in these materials, like in rubber, and can be tuned
mainly by varying the density of crosslinks or of
the reacting units, which is the main control
parameter in the gelation process. Connectivity
is the key because thermal ﬂuctuations guarantee
an elastic response as long as there is a connected
path through the sample. The formation of such
connected path is, in most cases, described by a
random percolation process, because the func-
tional units that react to create the gel network
are typically uniformly distributed in space and
their chemical reactions or physical associations
are the limiting process (Stauffer et al. 1982).
Particulate gels can form, instead, through a
number of complex (and sometimes hierarchical)
physical processes initiated by the net interactions
in solution of colloidal (supramolecular) units,
which lead to a self-assembled spanning solid-
like matrix (Del Gado et al. 2016). The colloidal
units relevant to the gel build-up can be the result
of
speciﬁcally
designed
chemical
synthesis
(i.e., nanoparticles, microgel particles), of aggre-
gation or hierarchical self-assembly of smaller
units (i.e., ﬂocs, micelles, ﬁbrils), or of conforma-
tional changes of polymers and biopolymers
(Fig. 1). Hence, these (colloidal) particulate gels
are relevant to quite a wide range of systems in
soft matter, from proteins to other biopolymers,
clay materials, and cement, to ceramics and to
polymer-based or microgel materials.
The wide range of physical chemistry at play
and the lack of a coherent theoretical framework
analogue to polymer physics make it much more
challenging to identify common traits and unify-
ing physical concepts that help understand and
predict the mechanics. While these materials can
be extremely soft because of the overall low solid
content, the strength of the interactions that drive
the aggregation of the colloidal units into the gel
network must be large enough with respect to kBT
to overcome thermal ﬂuctuations and stabilize the
gel structural elements and their connections. The
implication is that the elasticity here is largely
enthalpic in nature and that the interaction
strength, together with the total volume fraction
of the solid content, controls elastic moduli, vis-
coelastic
spectra,
and
nonlinear
response.
Remarkably, the interaction strength alone does
not allow to predict the gel properties: the mor-
phology of the gel networks, its structural ele-
ments and their connectivity, may change a lot
due to different kinetics at play during the gel
self-assembly, leading to huge variations of the
mechanical response, sometimes even for similar
compositions of the initial solution.
Considering the nature of the aggregation pro-
cesses is therefore crucial in these materials, and
not only because these processes change the gel
morphology and appearance, but also, and proba-
bly more importantly, because they provide insight
into
how
local
stresses
and
mechanical
298
Stress Localization in Soft Particulate Gels

heterogeneities get embedded and remain frozen-
in, in the gel structure, during gelation. As in a wide
range of soft amorphous solids, there is growing
evidence that the mechanical response of these soft
gels emerges from localized stress patterns with
nontrivial geometry (Nampoothiri et al. 2020). Fur-
thermore, due to the predominantly enthalpic
nature of the gel networks, thermal ﬂuctuations
play a much reduced role in the elasticity, and
connectivity through the sample is not sufﬁcient
to guarantee a solid-like, elastic response (Fig. 2).
Large colloidal aggregates can be still non-
rigid, just like a ﬂoppy but fully connected ﬁshing
net, and a rigid percolating backbone, satisfying
the constraints of mechanical equilibrium, must
be present for a solid-like response to emerge.
Therefore, while microscopy and spectroscopy
imaging techniques often provide quantitative
and multiscale insight into the morphology of
the aggregates that compose the gel, one still
needs to combine it with information on the topol-
ogy of the larger scale particle assemblies and on
the forces that act as mechanical constraints on the
gel units, to gain access to the part of the structure
that is rigid and load-bearing.
Different aggregation paths, that can become
available by varying the gelation conditions, can
favor or not the development of various types of
mechanical heterogeneities, where rigid structures
coexist with, or are interspersed in, ﬂoppy or
softer regions. The presence of such mechanical
heterogeneities, often not recognizable from
structural
and
morphological
heterogeneities,
translates into stress and strain localization when
the material is deformed or under load, or into
prestressed states that will evolve due to thermal
ﬂuctuations, under deformation or changing
boundary conditions. The understanding of the
emergence of rigidity and of the role of stress
localization in the mechanics of particulate gels
has just started, but it is clearly key to designing
and expanding their performances and functions.
The remainder of the chapter tries to provide an
overview of the fundamental physics understand-
ing of these soft particulate gels, and in particular of
how stress localization emerges as the central
ingredient controlling their mechanics, in spite of
the softness and deformability of these materials.
I start by discussing brieﬂy how microstructural
heterogeneities can emerge during gelation, pro-
moting frozen-in stresses in section “Source of
Mechanical
Heterogeneities
and
Frozen-in
Stresses: Microscopic Forces and Gelation Pro-
cesses.” Microscopic processes and heterogeneities
Stress
Localization
in
Soft
Particulate
Gels,
Fig. 1 Solid networks in soft particulate gels. Left: col-
loidal particles in a colloidal gel from (Whitaker et al.
2019. Reprinted with permission. Creative Commons
license available at https://creativecommons.org/licenses/
by/4.0/.). Center: SEM image of casein gels which are the
basis of yogurt products ((Kalab et al. 1983). Reprinted
with permission. Creative Commons license available at
https://creativecommons.org/licenses/by/4.0/.). Right (top
and bottom): Confocal reﬂectance images of gels of colla-
gen ﬁbrils obtained at different temperatures from (Burla
et al. 2020).
Stress Localization in Soft Particulate Gels
299

enter rigidity and elasticity, as brieﬂy outlined in
section “Origin of Elastic Modulus and Emergence
of Rigidity.” Section “Stress Localization at Rest
and Under Shear” gives a concise account of ideas
for microscopic processes at rest and under an
external load. Finally, section “Future Directions”
contains an outlook of the outstanding questions
and new research paths.
Source of Mechanical Heterogeneities
and Frozen-in Stresses: Microscopic
Forces and Gelation Processes
In soft particulate gels, gelation is typically initi-
ated by the net physical interactions between the
colloidal units in solution, which can be described
through equilibrium statistical mechanics and
thermodynamics. However, the ﬁnal result, in
terms of solid matrix, is a nonequilibrium, non-
ergodic state that depends on the path along which
the system evolves given the procedure used (e.g.,
mixing,
temperature
control,
etc. . .).
The
lengthscales over which nonergodic processes
dominate depend on the physical chemistry at
play, but also on procedures and conditions, and
determine the type of frozen-in stresses and
mechanical heterogeneities that are crucial to the
gel mechanics.
In terms of microscopic forces, well-studied
and relatively simple cases of solvent-mediated
interactions in colloidal suspensions are those
described by DLVO (Derjaguin and Landau
1941; Verwey and Overbeek 1948; Israelachvili
2011) or depletion interactions theories (Asakura
and Oosawa 1954), providing simple analytical
forms for short-ranged attractive forces that
depend only on the particle surface separation,
and where the attractive strength is determined
by the composition and physical chemistry of
the solution. These theoretical approaches give
excellent estimates of phase and even gelation
boundaries in many cases (Poon et al. 1997;
Anderson and Lekkerkerker 2002). Figure 3
(left) shows typical phase diagrams for colloidal
suspensions (reproduced from (Anderson and
Lekkerkerker 2002) with permission) indicating
gas, liquid, and crystalline phases in which the
colloidal component can be found. Gelation can
then be initiated by equilibrium (or close-to-
equilibrium) phenomena predicted on the basis
of these short range attractive interactions, such
as phase separation or spinodal decomposition
(Gibaud et al. 2008; Lu et al. 2008). Microphase
separation phenomena, typical of colloidal sus-
pensions with competing short range attraction
and longer range repulsion, can also initiate gel
formation (Campbell et al. 2005; Sciortino et al.
2005; De Candia et al. 2006; Ciach et al. 2013;
Zhuang et al. 2016; Ioannidou et al. 2016). In all
these cases, the initial driving of the aggregation is
the underlying thermodynamics, with equilibrium
(or close to equilibrium) sampling of microstates
underpinning
the
initial
evolution
of
the
Stress
Localization
in
Soft
Particulate
Gels,
Fig. 2 Connectivity and rigidity in soft gels. Left:
A connected mesh can be ﬂoppy in absence of thermal
ﬂuctuations. Center and right: self-assembled structures in
a simple 2D model for colloidal gels (Reprinted with
permission from (Zhang et al. 2019)): rigid structures
(red) can constitute a minor portion of the percolating
connected nonrigid (gray) cluster, depending on the
aggregation path.
300
Stress Localization in Soft Particulate Gels

microscopic degrees of freedom. Theoretical pre-
dictions of the effective interactions therefore pro-
vide useful information on the initial steps of the
aggregation and structural build-up.
Frustration in the growth of large scale struc-
tures, also combined with the slowing down of the
microscopic dynamics due to the vicinity of
glassy states, can eventually result in gel struc-
tures with solid-like properties. A possible gel-
line, deﬁned by measuring the onset of a ﬁnite
elastic modulus, is sketched in Fig. 3 (right) for
colloidal suspensions with short range attractive
interactions, in the low volume fraction region,
where phase separation and spinodal decomposi-
tion can occur. Structural arrest of the microscopic
dynamics associated to the emergence of gels or
glassy states in presence of short range attraction
has been extensively studied (Manley et al. 2004;
Mayer et al. 2008; Lu et al. 2008; Gibaud and
Schurtenberger 2009; Conrad et al. 2010). The
ﬁnal gel microstructure, from the thickness of the
gel branches to pore sizes and connectivity, will
depend not only on the volume fraction of the
particle component and the interaction strength
but also on the way nonergodicity is attained. For
example, gels initiated in the vicinity of the
spinodal line associated to short range attractive
interactions are characterized by thick dense
branches with large pores, and the speciﬁc pore
size distribution can vary depending on the speciﬁc
path chosen to quench the solution in the spinodal
region (Fofﬁet al. 2005; Testard et al. 2011; Zia
et al. 2014), on hydrodynamic interactions, and on
the viscoelasticity of the interfaces (Tanaka 2000;
Padmanabhan and Zia 2018). These factors will
inﬂuence both the possible structural arrest of the
microscopic dynamics of the colloidal units and the
way in which the internal stresses, that develop
from the frustration at larger lengthscales as the
gel forms, can be relaxed. As a consequence, they
will determine the stress state of the gel, that is, the
presence and nature of frozen-in stresses, and the
spatial organization of local stresses in the gel
structure. While different scenarios of kinetic arrest
competing with phase separation and spinodal
decomposition have been extensively discussed in
the literature, the way they may control the ﬁnal
stress state of the gels has been highlighted in
recent studies (Testard et al. 2011; Padmanabhan
and Zia 2018; Filiberti et al. 2019; Tsurusawa et al.
2020) but is far from being fully understood.
Another aspect whose implications have been
less investigated is that form and nature of surface
forces in colloidal gels may be not necessarily
captured by DLVO theories, for example, due to
discreteness effects of ions and ion-water interac-
tions that become important at small separations
and in presence of high surface charges or multi-
valent ions (Shen and Bourg 2021; Goyal et al.
2021). Surface heterogeneity and roughness are
also known to modify interaction strengths and
sign (Monti et al. 2019). Moreover, once colloidal
units are at close contact, different chemical or
physical processes occurring on much smaller
lengthscales, not included in existing theories, can
drive the development of solid-on-solid contacts
Stress
Localization
in
Soft
Particulate
Gels,
Fig. 3 Phase behavior and gelation in colloidal solutions.
Left: Phase diagrams for colloidal suspensions for colloi-
dal hard spheres (a) and short range attractions (b,c) indi-
cating gas (G), Fluid (F) and liquid (L), and crystalline
phases (C). Reproduced with permission from (Anderson
and Lekkerkerker 2002). Right: A possible rigidity line for
colloidal suspensions with short range attractive interac-
tions (with kT/V the ratio between attraction strength Vand
thermal energy at temperature T), at low volume fractions
and across the binodal/spinodal regions (respectively con-
tinuum and dashed lines). G0 is the low frequency elastic
modulus of the gel (see also Zaccone et al. 2009)
Stress Localization in Soft Particulate Gels
301

and sintering of the particle surfaces (Bonacci
et al. 2020).
As a consequence, the forces that are relevant
to the formation of mechanical contacts during
gelation may not simply depend on just the sepa-
ration between surfaces of the colloidal units, but
also on relative orientation of interparticle bonds
or mechanical constraints, in the sense that the
relative motion of particles in aggregates may be
signiﬁcantly more constrained than what spheri-
cally symmetric interactions would imply. It has
been indeed shown experimentally that contacts
between colloidal particles can resist torques
(Pantina and Furst 2005; Wu et al. 2020) and
that colloidal gels microstructures can be charac-
terized by very low local coordination (Dinsmore
et al. 2006; Dibble et al. 2008; Ohtsuka et al.
2008), supporting the idea that interparticle
bonds may have bending resistance, that is, short
range interactions may be directional and not only
depend on interparticle separation (Del Gado and
Kob 2005, 2010; Colombo and Del Gado 2014a;
Bouzid and Del Gado 2020).
The implications are that the arrested structures
and the micromechanics of the gels, may be qual-
itatively different from those obtained without
considering these effects, even when the theoret-
ical predictions for the phase boundaries can still
provide useful indications of the regions of the
phase diagram where gels will tend to form.
Interesting insights come from the studies of
gelation in cases where one can access strong
attractive forces between the colloidal units far
enough from the spinodal or phase-separation
boundaries. Gelation in colloidal suspensions
has been investigated extensively for very low
volume fractions of the solid components, for
example, when the colloidal units are so dilute
that can only interact if diffusing far enough, and
only strong enough interactions can result in
aggregation, which is therefore largely irrevers-
ible and results into fractal structures, typical of
diffusion limited aggregation models (Lin et al.
1989; Trappe et al. 2001; Aime et al. 2018a; Cho
et al. 2020). In these cases, gelation is obviously
much less affected by the thermodynamics of the
solution. If the aggregation is treated as irrevers-
ible, the kinetics is mostly limited to single
particle diffusion governed by the thermal ﬂuctu-
ations in the solvent, and a truly equilibrium sam-
pling of the microstates of the particle assembly is
not attained since it would require several aggre-
gation- disaggregation steps. The implication is
that the path through which the gel forms is nearly
uniquely determined once particle volume frac-
tion and diffusivity are ﬁxed. Changing the initial
conditions, as long as these properties are kept the
same, may have very little impact on the gelation
path. Hence the fact that gelation proceeds
through exactly the same intermediate steps to
the ﬁnal gel state, with negligible effect of the
initial conditions, is a direct manifestation of the
non-equilibrium processes that drive it. In con-
trast, when equilibrium collective processes are
entering the initial gel growth, changing the gela-
tion path will signiﬁcantly modify the gel
obtained because it will correspond to different
amounts of microstate sampling. In spite of these
differences, the fact that irreversible aggregation
requires interactions strengths dramatically larger
than kBTcould make the development of solid-on-
solid contacts and surface interactions leading to
noncentral forces also relevant here. In the case
of irreversible aggregation, the fractal dimension
of the aggregates can be modiﬁed by details of the
surface interactions, such as the directionality and
bending stiffness of interparticle bonds (Witten
et al. 2004).
As particle density increases, the limiting dif-
fusion process may be due to fractal ﬂocs or
clusters, rather than single particles. The gel
may therefore appear as a space ﬁlling assembly
of those ﬂocs, suggesting that ﬂoc-ﬂoc interac-
tions or mechanical connections may be crucial
to determine not only the dynamics of the gel
formation (Kroy et al. 2004; Del Gado et al.
2004) but also frozen-in stresses or gels mechan-
ics. Existing studies of colloidal elasticity and
rheology have mainly assumed completely rigid
fractal ﬂocs connected by weaker mechanical
connections (Shih et al. 1990; Ramakrishnan
et al. 2004), although this scenario may not be
valid for a number of gels where the ﬂoc
deformability, strong ﬂoc-ﬂoc interactions, and
in general more complex mechanics may be
at play.
302
Stress Localization in Soft Particulate Gels

This brief overview of different gelation sce-
narios, albeit limited to a simple suspension of
colloidal particles, naturally highlights the diver-
sity of structure, morphology, and mechanical
characteristics of soft particulate gels. Gelation
scenarios for biopolymers and other supramolec-
ular polymer-based colloidal units are much more
complex, with the build-up of the interconnected
network being usually the last step of multiple
hierarchical aggregation processes, leading to
ﬁbrils, micelles, or bundles (Tabatabai et al.
2015; Mao et al. 2016; Burla et al. 2020;
Vereroudakis et al. 2020). In other cases, such as
gels that are at the origin of cement cohesion and
strength (Ioannidou et al. 2016), or that form
during biomineralization (Shoaib et al. 2017),
the development of the porous solid matrix takes
place in presence of additional nonequilibrium
processes and chemical reactions, more intricated
sources
of
internal
stresses,
structural
and
mechanical heterogeneities, including the fact
that the microscopic forces driving the aggrega-
tion may change over time. Understanding these
more complex gels obviously requires a much
more detailed insight into the hierarchical aggre-
gation of the microstructure and lacks a theoretical
framework for the microscopic forces and ther-
modynamic stability. However, we can still iden-
tify common traits with the simpler scenarios
discussed above: gelation corresponds to the
emergence of nonerogodic states and it is associ-
ated to development of internal stresses, due to the
geometric frustration in the aggregation of meso-
scale gel constituents. These gel states and the
microscopic stresses imprinted in the gel matrix
depend on the gelation path, and there is a direct,
albeit
poorly
understood,
correspondence
between the organization of the gel in space,
the frozen-in stresses, and the gel mechanics.
To summarize, because soft particulate gels
require a rigid matrix and the total solid volume
fractions are typically quite low, structural hetero-
geneities tend to be large. Microscopic processes,
more or less affected by the underlying thermo-
dynamics, will favor different types of structural
and morphological heterogeneities. In general,
gelation will be associated to the build-up of frus-
tration and local stress inhomogeneities over
different lengthscales. The outstanding questions
are: is there an organizing principle in the gel
microstructures that can encompass so many
structures, processes and materials? Is it possible
to develop a consistent fundamental understand-
ing of their mechanics or identify common under-
lying mechanisms?
Origin of Elastic Modulus and
Emergence of Rigidity
While the understanding of these phenomena is
only nascent, there is growing evidence that 1) the
mechanics of soft particulate gels are determined
by mechanical heterogeneities and frozen-in
stresses built-up during gelation, and 2) that the
role of structural heterogeneities in the mechani-
cal response and rheology is a hint to that. Figure 3
(right) revisits the equilibrium phase diagram for
colloidal suspensions with short range attractive
interactions (left, (b)) by complementing it with
the hypothetical line along which the suspension
could solidify into a gel, characterized by a ﬁnite
low frequency elastic modulus G0 that dominates
its mechanical response (Zaccone et al. 2009). It is
important to consider that the elastic response in
the solid-like region (darkened) may be controlled
by different lengthscales, as gelation conditions or
solid volume fraction changes. In particular, the
key lengthscale would grow from right to left, that
is, going from the denser (and more structurally
homogeneous) to the more dilute (and more struc-
turally heterogeneous) gels. At sufﬁciently high
volume fractions, these gels have solid matrices
that are relatively homogeneous at the scale of the
colloidal units, very similar to colloidal glasses.
Even when considering the role of disorder, the
elasticity of the material is largely set by the
interactions between the colloidal units and the
typical coordination number. As the colloidal gel
assembly becomes more heterogeneous with
decreasing the solid volume fraction, as discussed
in the previous section, the elastic modulus of the
gels can change by orders of magnitude even if the
colloidal interactions are not signiﬁcantly differ-
ent. It is clear that the way the gel structure is
spatially organized, rather than just the colloidal
Stress Localization in Soft Particulate Gels
303

interaction strength, plays a predominant role and
in fact determines the elastic response.
Let’s consider the case where initial steps of
phase
separation
or
irreversible
aggregation
among colloidal units lead to formation of clus-
ters, but further growth or merging is kinetically
arrested or geometrically frustrated. Hence, the
gel appears as a dense assembly of such clusters
(Ramakrishnan et al. 2004; Kroy et al. 2004; Del
Gado et al. 2004; Laurati et al. 2009). Zaccone
et al. (2009) proposed that in such microstructures
the cluster-cluster interactions may dominate the
elastic modulus. Using information from experi-
ments on the attractive interactions between the
colloidal units and on the cluster sizes, their sim-
ple theoretical framework allowed them to show
that the elastic response is indeed dominated by
the cluster-cluster connections and that the elastic
modulus can be justiﬁed in those terms, once one
makes the approximation of roughly spherical
clusters, completely rigid, and joint by single par-
ticle connections. A recent study (Whitaker et al.
2019), combining microscopy, rheology, and
numerical simulations with graph analysis, has
shown that gels prepared by deep quenches in
the spinodal region have such morphology, with
clusters that are not necessarily spherical but are
rather compact, relatively isotropic and likely
rigid. Whitaker et al. (2019) have also demon-
strated that, by systematically varying the colloi-
dal interaction strength, the related change in the
mechanical properties of the interparticle bonds
does not account for the change in the modulus of
the gel that can instead be explained only in terms
of cluster-cluster connections. Further studies
have identiﬁed the gelation in similar colloidal
systems with a percolation of such clusters, poten-
tially rigid, therefore also supporting the idea that
cluster-cluster interactions dominate the elasticity
of the gels (Tsurusawa et al. 2019).
Zaccone et al. (2009) also suggested that, with
decreasing the solid content, as the structure of
soft particulate gels becomes sparser and more
open, the rigid units may be quite different from
compact clusters, have to span larger lengthscales,
and may be hard to separate out from the rest of
the structure. If one could still identify the
lengthscale that contributes most to the elastic
response, this would be larger in the sparser net-
works, and its relationship to the mesoscopic gel
structure would be hard to disentangle.
Because
of lower
connectivity,
nonafﬁne
rearrangements are likely to be more pronounced
and sensibly decrease the shear modulus of more
dilute colloidal gels. Moreover, because removing
even few colloidal units can signiﬁcantly compro-
mise the mechanical stability of these sparser net-
works, varying the solid content in this regime
would have a stronger effect on the elastic modu-
lus, as indeed suggested by the relatively strong
dependences reported in very diluted colloidal
gels (Shih et al. 1990; Gisler et al. 1999; Trappe
et al. 2001; Del Gado et al. 2016). The role of
larger scale connections across the gel structure
also appears in the viscoelastic spectra, with the
moduli varying over a wider range of frequencies
and featuring
extended
power
law
regimes
(Bremer et al. 1989; Curtis et al. 2013; Hung
et al. 2015; Aime et al. 2018a; Keshavarz et al.
2021) These effects are often rationalized in terms
of fractal microstructures, whose self-similarity is
responsible to connect the particle-particle inter-
action strength to the overall modulus at very low
solid content (Shih et al. 1990; Muthukumar
1989). However, such mechanical characteristics
seem common to a wide range of soft particulate
gels, in spite of the fact that the structural self-
similarity does not always cover a range of length-
scales sufﬁcient to provide a robust justiﬁcation.
In fact, it seems that the low frequency elastic
modulus and the shape of the viscoelastic spec-
trum are determined by both the connectivity and
the topology of the gel microstructure (Bouzid
et al. 2018), with the latter being much more
difﬁcult to characterize in these complex three-
dimensional
disordered
and
heterogeneous
networks.
Some of these considerations point to the pos-
sibility that only a subpart of the gel microstruc-
ture is in fact responsible for the gel rigidity and
hence for its elasticity, an idea reminiscent of the
concept of the elastically active chain in polymer
gels close to connectivity percolation (de Gennes
1979; Rubinstein and Colby 2003; Daoud and
Coniglio 1981; Daoud 2000; Xing et al. 2004).
For gels and soft amorphous solids in general, the
304
Stress Localization in Soft Particulate Gels

main theoretical framework to understand rigidity
considers locally rigid structures, due to mechan-
ical constraints such as chemical bonds or steric
repulsion, that percolate through the material. The
problem is hence translated into analyzing the
onset of rigidity in a disordered network of
springs, an abstraction of the actual solid, and its
rigidity percolation (RP) transition (He and
Thorpe 1985; Jacobs and Thorpe 1995). With
respect to percolation phenomena controlled by
the geometric connectivity (Sahimi 1998), the
onset of rigidity requires a spanning cluster that
is not just connected but also mechanically stable
and able to transmit stresses. The condition for
rigidity percolation is therefore typically achieved
at higher solid volume fractions, with respect to
connectivity percolation, whereas soft particulate
gels can be mechanically rigid at volume fractions
as low as a few percent (Trappe et al. 2001; Del
Gado et al. 2016).
Starting from the fact that pronounced struc-
tural heterogeneities in colloidal gels are the man-
ifestation of spatial correlations induced by
colloidal interactions and speciﬁc gelation condi-
tions (and can in fact be affected in different ways
through the gelation process as discussed in sec-
tion “Source of Mechanical Heterogeneities and
Frozen-in Stresses: Microscopic Forces and Gela-
tion Processes”), Zhang et al. (2019) have dem-
onstrated that such spatial correlations can shift
the RP to much lower volume fractions. Combin-
ing a lattice model and rigidity analysis, together
with molecular dynamics simulations, Zhang
et al. (2019) have shown that physical interactions
and correlations naturally organize the colloidal
units into thin structures that efﬁciently transmit
stress, such as the Warren truss in 2d, shown in
Fig. 2 (center), which is a mechanical element
well known in structural engineering and archi-
tecture for its ability to carry substantial load.
Different gelation conditions can favor the growth
of structures like the Warren truss in different
amounts (see Fig. 2 center and right). However,
the volume fraction of this one-dimensional struc-
ture in a two-dimensional plane vanishes in the
thermodynamic limit, giving rise to rigidity at
arbitrary low volume fractions. Recent experi-
mental observations and simulations (Hsiao et al.
2012; Valadez-Pérez et al. 2013; Rocklin et al.
2021; Tsurusawa et al. 2019; Whitaker et al.
2019) support these ﬁndings, having highlighted
the presence of locally rigid structures and their
percolation in various colloidal gels.
The idea that in soft particulate gels the gela-
tion processes and the microscopic forces at play
help select the smart structures needed for rigidity
brings in a new perspective: the subpart of the
gel microstructure actually determining its elastic
response, may be related to localized stress pat-
terns that naturally emerge during gelation and
affect the linear and nonlinear mechanics of
these materials. In particular, the development of
locally rigid structures may naturally create
(or contribute to) the mechanical heterogeneities
previously discussed. It is worth considering that
locally rigid structures may be formed at different
times and through various processes, but the
emergence of the gel rigidity through RP requires
their spatial organization into a spanning rigid
network, a nonlocal phenomenon. Hence, not all
locally rigid structures identiﬁed at different steps
may end up contributing in the same way to the
gel rigidity and some of them may disappear in
favor of others as the material solidiﬁes. What are
the implications of the development of smart rigid
structures and of the role of rigidity percolation in
the build-up of frozen-in stresses are among the
outstanding questions.
Stress Localization at Rest and Under
Shear
Frozen-in stresses in soft particle gels may be
thought as elusive and negligible however they
manifest even when the material is at rest.
Depending on the size of the colloidal units and
interaction strength, these solids can be more or
less sensitive to thermal ﬂuctuations, with sponta-
neous and thermally activated processes produc-
ing rich microscopic dynamics. Even at rest,
thermal ﬂuctuations can trigger ruptures of parts
of the microscopic structure that are under tension
or can promote coarsening and compaction of
initially loosely packed domains, depending on
the conditions under which the material initially
Stress Localization in Soft Particulate Gels
305

solidiﬁed: these processes underpin the aging of
the
microstructure
and
of
the
mechanical
response of the gels. There is now extensive
experimental evidence that the microscopic
dynamics associated to these processes are
intermittent
and
faster
than
exponential
(Cipelletti et al. 2000; Ramos and Cipelletti
2001; Bellour et al. 2003; Bandyopadhyay
et al. 2004; Maccarrone et al. 2010; Mansel
and Williams 2015; Bandyopadhyay et al.
2004; Lieleg et al. 2011; Angelini et al. 2013;
Ruta et al. 2014; Gao et al. 2015), suggesting an
elastic rebound of the gel matrix as a response to
microscopic
restructuring
(Bouchaud
2008;
Ferrero et al. 2014). Bouzid et al. (2017) have
proposed that the large stress heterogeneities
frozen-in during solidiﬁcation trigger micro-
scopic rearrangements which are dominated by
the elasticity stored in the material structure
(Fig. 4). They have demonstrated that this elas-
tically driven dynamics is intermittent and spa-
tially correlated, markedly different from the
spontaneous dynamics induced by thermal ﬂuc-
tuations close to equilibrium. Hence, the anom-
alous aging dynamics detected in experiments is
the direct consequence of the internal stresses
frozen-in during the gelation process and by the
gel history.
Numerical simulations have access to local
stresses in model gel networks and can provide
direct insight into how locally competing stresses
emerge during the gelation process and in differ-
ent processing conditions (Fig. 5, left) (Colombo
and Del Gado 2014b; Bouzid et al. 2017; Johnson
and Zia 2021), an information that cannot be
easily accessed by experiments. Building on this
capability, and in feedback with experiments,
computational studies can help develop the link
between the stresses localized in the gel structure
and its mechanical response (Bouzid and Del
Gado
2020).
Under
deformation,
localized
stresses naturally become sources of nonafﬁne
motion and, together with the disorder of the gel
structure,
favor
further
stress
localization
(Colombo and Del Gado 2014b): the sparsely
connected structure of soft particulate gels helps
concentrate stresses and the stress localization can
initiate, at large deformation, large scale damage
of the structure itself. Recent studies have demon-
strated that just the network topology can control
the nonlinear behavior of gel networks, beyond
the properties of the single components (ﬁber,
particles, or agglomerates), and can determine,
alone, the softening or stiffening nature of the
gel response (Bouzid and Del Gado 2018). Recent
explorations
of
the
link
between
disorder/
Stress
Localization
in
Soft
Particulate
Gels,
Fig. 4 Elastically driven intermittent dynamics. Left:
sketch of break-up of gel connections during aging, due
to frozen-in stresses. Right: stress ﬂuctuations become
intermittent
and
strongly
correlated
when
elasticity
dominates the microscopic rearrangements. (Reproduced
from Bouzid et al. (2017) with permission. Creative Com-
mons license available at https://creativecommons.org/
licenses/by/4.0/.)
306
Stress Localization in Soft Particulate Gels

connectivity/failure in collagen gels (Burla et al.
2020), central to biological tissues, and of micro-
scopic precursors in the failure of colloidal mate-
rials (de Oliveira Reis et al 2019; van Doorn et al.
2018; Aime et al. 2018b) point in the same direc-
tion. The spatial organization of the gel matrix and
the microscopic forces that helped make it
mechanically stable hold crucial information on
the gel nonlinear response and failure, because
they determine the initial stress localization pat-
tern and its evolution under external load. Deeper
understanding of how localized stress patterns
emerge in soft particulate gels and how they
evolve as the material is processed or used is
therefore the key to new theories and constitutive
models and the various questions outlined in this
chapter.
Future Directions
Circling back to the initial discussion, the variety
and
complexity
of
microstructures
and
the
nonequilibrium nature of soft particulate gels
make it difﬁcult to identify organizing principles
and fundamental mechanisms, but the common
trait of localized stress patterns emerging from
mechanical constraints and the fact that they con-
trol the evolution and the response of these mate-
rials indicate a path for future research directions.
A systematic characterization of the conse-
quences of speciﬁc stress states and patterns
built through various gelation processes or across
different gels would provide deeper insight into
the role of frozen-in stresses and their conse-
quences for the mechanical response. Under-
standing the emergence of rigidity can provide
a different perspective, complementary to the
thermodynamics of the colloidal solutions or
the models for colloidal aggregation, needed
to capture structure formation and development
of frozen-in stresses in soft particulate gels. It
will connect the physics of these very soft
materials to the one of granular matter and of
other amorphous solids, where mechanical con-
straints and localized stress pattern are key.
Stress
Localization
in
Soft
Particulate
Gels,
Fig. 5 Stress localization in soft particulate gels. Left:
Gelation results in frozen-in stresses in a model gel net-
work, with parts of the structure preferentially contribute to
tension (blue) or compression (red). (Reproduced from
(Bouzid et al. 2017) with permission). Right: Tensions
localize in a small portion of the overall network under
shear, in a model gel network. The visualization from
numerical simulations depicts as thicker the regions
where tension is higher. (Reproduced from (Colombo and
Del Gado 2014b) with permission. Creative Commons
license available at https://creativecommons.org/licenses/
by/4.0/.)
Stress Localization in Soft Particulate Gels
307

Complementing experiments with numerical
simulations
and
connecting
to
theoretical
approaches for rigidity percolation and topo-
logical mechanics will be essential to go from
microscopic processes and material speciﬁcity
to critical lengthscales, geometry and implica-
tions
of
localized
stress
patterns
for
the
mechanical response.
The question of how mechanical constraints and
localized stresses evolve in time, under load, and
with varying deformation, is at the core of under-
standing how frozen-in, localized stresses can help
promote or prevent instabilities when driving a soft
gel toward yielding, jamming, or hardening. In
particular, identifying microscopic precursors to
failure and yielding, understanding their possible
connections to speciﬁc frozen-in stresses, and
their time evolution, is central to gain insight
into the complex nature of failure or yielding in
these very soft materials and into toughening,
embrittlement, or self-healing of gel structures.
Investigating along these lines will certainly
require combining different approaches, analyt-
ical theories with numerical simulations and
multiple
experimental
techniques,
crossing
boundaries across traditionally distinct areas in
material physics, bridging fundamental and
applied research.
Acknowledgments The author would like to thank the
Impact Program of the Georgetown Environmental Initia-
tive and Georgetown University for funding and the Kavli
Institute for Theoretical Physics at the University of Cali-
fornia Santa Barbara for hospitality. This work was
supported in part by the National Science Foundation
under Grant No. NSF PHY17-48958 and NSF DMR-
2026842.
References
Aime S, Cipelletti L, Ramos L (2018a) Power law visco-
elasticity of a fractal colloidal gel. Journal of Rheology
62(6):1429–1441
Aime S, Ramos L, Cipelletti L (2018b) Microscopic
dynamics and failure precursors of a gel under mechan-
ical load. Proceedings of the National Academy of
Sciences 115(14):3587–3592
Anderson VJ, Lekkerkerker HN (2002) Insights into phase
transition
kinetics
from
colloid
science.
Nature
416(6883):811
Angelini R, Zulian L, Fluerasu A, Madsen A, Ruocco G,
Ruzicka B (2013) Dichotomic aging behaviour in a
colloidal glass. Soft Matter 9(46):10955–10959
Asakura S, Oosawa F (1954) On interaction between two
bodies immersed in a solution of macromolecules. The
Journal of Chemical Physics 22(7):1255–1256
Bandyopadhyay R, Liang D, Yardimci H, Sessoms D,
Borthwick M, Mochrie S, Harden J, Leheny R (2004)
Evolution of particle-scale dynamics in an aging clay
suspension. Phys Rev Lett 93(22):228302
Bellour M, Knaebel A, Harden J, Lequeux F, Munch JP
(2003) Aging processes and scale dependence in soft
glassy colloidal suspensions. Phys Rev E 67(3):031405
Bonacci F, Chateau X, Furst E, Fusier J, Goyon J, Lemaitre
A (2020) Contact and macroscopic ageing in colloidal
suspensions. Nature Materials 19:775
Bouchaud JP (2008) Anomalous relaxation in complex
systems: from stretched to compressed exponentials.
Anomalous Transport: Foundations and Applications.
pp 327–345
Bouzid M, Del Gado E (2018) Network topology in soft
gels: hardening and softening materials. Langmuir 34:
773–781
Bouzid M, Del Gado E (2020) Handbook of Materials
Modeling. volume 2 Applications: Current and Emerg-
ing Materials, Springer Nature, chap Mechanics of Soft
Gels: Linear and Nonlinear Response
Bouzid M, Colombo J, Barbosa LV, Del Gado E (2017)
Elastically driven intermittent microscopic dynamics in
soft solids. Nature Communications 8:15846
Bouzid M, Keshavarz B, Geri M, Divoux T, Del Gado E,
McKinley GH (2018) Computing the linear viscoelas-
tic properties of soft gels using an optimally windowed
chirp protocol. Journal of Rheology (1978-present) 62:
1037
Bremer LGB, van Vliet T, Walstra P (1989) Theoretical
and experimental study of the fractal nature of the
structure of casein gels. J Chem Soc, Faraday Trans 1
85:3359–3372
Burla F, Dussi S, Martinez-Torres C, Tauber J, van der
Gucht JGH (2020) Connectivity and plasticity deter-
mine collagen network fracture. Proceedings of the
National Academy of Sciences 117(15):8326–8334
Campbell AI, Anderson VJ, van Duijneveldt JS, Bartlett
P (2005) Dynamical arrest in attractive colloids: The
effect of long-range repulsion. Phys Rev Lett 94:
208301
Cho JH, Cerbino R, Bischofberger I (2020) Emergence of
multiscale dynamics in colloidal gels. Phys Rev Lett
124:088005
Ciach A, Pekalski J, Góźdź WT (2013) Origin of similarity
of phase diagrams in amphiphilic and colloidal systems
with competing interactions. Soft Matter 9(27):6301
Cipelletti L, Manley S, Ball R, Weitz D (2000) Universal
aging features in the restructuring of fractal colloidal
gels. Phys Rev Lett 84(10):2275
Colombo J, Del Gado E (2014a) Self-assembly and coop-
erative dynamics of a model colloidal gel network. Soft
matter 10(22):4003–4015
308
Stress Localization in Soft Particulate Gels

Colombo J, Del Gado E (2014b) Stress localization, stiff-
ening, and yielding in a model colloidal gel. Journal of
rheology 58(5):1089–1116
Conrad JC, Wyss HM, Trappe V, Manley S, Miyazaki K,
Kaufman LJ, Schoﬁeld AB, Reichman DR, Weitz DA
(2010) Journal of Rheology (1978-present) 54(2):
421–438
Curtis
DJ, Williams PR,
Badiei
N, Campbell
AI,
Hawkins K, Evans PA, Brown MR (2013) A study of
microstructural templating in ﬁbrinthrombin gel net-
works by spectral and viscoelastic analysis. Soft Matter
9:4883–4889
Daoud M (2000) Viscoelasticity near the solgel transition.
Macromolecules 33(8):3019–3022
Daoud M, Coniglio A (1981) Singular behaviour of the
free energy in the sol-gel transition. Journal of Physics
A: Mathematical and General 14(8):L301–L306
De Candia A, Del Gado E, Fierro A, Sator N, Tarzia M,
Coniglio A (2006) Columnar and lamellar phases in
attractive colloidal systems. Phys Rev E 74(1):010403
de Oliveira RG, Gibaud T, Saint-Michel B, Manneville S,
Leocmach M, Vaysse L, Bonﬁls F, Sanchez C, Menut
P (2019) Irreversible hardening of a colloidal gel under
shear: The smart response of natural rubber latex gels.
Journal of Colloid and Interface Science 539:287–296
Del Gado E, Kob W (2005) Structure and relaxation
dynamics of a colloidal gel. EPL (Europhysics Letters)
72(6):1032
Del Gado E, Kob W (2010) A microscopic model for
colloidal gels with directional effective interactions:
network induced glassy dynamics. Soft Matter 6(7):
1547–1558
Del Gado E, Fierro A, Arcangelis LD, Coniglio A (2004)
Slow dynamics in gelation phenomena: From chemical
gels to colloidal glasses. Phys Rev E 69:051103
Del Gado E, Fiocco D, FofﬁG, Manley S, Trappe V,
Zaccone A (2016) Colloidal gelation. Fluids, Colloids
and Soft Materials: An Introduction to Soft Matter
Physics pp 279–291
Derjaguin B, Landau L (1941) Theory of the stability of
strongly charged lyophobic sols and of the adhesion of
strongly charged particles in solutions of electrolytes.
Acta Physicochim USSR 14:633–662
Dibble CJ, Kogan M, Solomon MJ (2008) Structural ori-
gins of dynamical heterogeneity in colloidal gels. Phys
Rev E 77:050401
Dinsmore A, Prasad V, Wong I, Weitz D (2006) Micro-
scopic structure and elasticity of weakly aggregated
colloidal gels. Phys Rev Lett 96(18):185502
van Doorn JM, Verweij JE, Sprakel J, van der Gucht
J (2018) Strand plasticity governs fatigue in colloidal
gels. Phys Rev Lett 120(20)
Ferrero EE, Martens K, Barrat JL (2014) Relaxation in
yield stress systems through elastically interacting acti-
vated events. Phys Rev Lett 113(24):248301
Filiberti Z, Piazza R, Buzzaccaro S (2019) Multiscale
relaxation in aging colloidal gels: From localized plas-
tic events to system-spanning quakes. Phys Rev E 100:
042607
FofﬁG, De Michele C, Sciortino F, Tartaglia P (2005)
Arrested phase separation in a shortranged attractive
colloidal system: A numerical study. The Journal of
Chemical Physics 122(22):224903
Gao Y, Kim J, Helgeson ME (2015) Microdynamics and
arrest of coarsening during spinodal decomposition in
thermoreversible colloidal gels. Soft Matter 11(32):
6360–6370
de Gennes PG (1979) Scaling concepts in polymer physics.
Cornell University Press, Ithaca
Gibaud T, Schurtenberger P (2009) A closer look at
arrested spinodal decomposition in protein solutions.
Journal of Physics: Condensed Matter 21(32):322201
Gisler T, Ball RC, Weitz DA (1999) Strain hardening of
fractal colloidal gels. Phys Rev Lett 82:1064–1067
Goyal A, Palaia I, Ioannidou K, Ulm H F-J amd Van
Damme, Pellenq RM, Trizac E, Del Gado E (2021)
The physics of cement cohesion. Science Advances
7(32):eabg5882
He H, Thorpe MF (1985) Elastic properties of glasses.
Phys Rev Lett 54(19):2107
Hsiao L, Newman RS, Glotzer SC, Solomon MJ (2012) Role
of isostaticity and load-bearing microstructure in the
elasticity of yielded colloidal gels. Proceedings of the
National Academy of Sciences 109(40):16029–16034
Hung KC, Jeng US, Hsu S (2015) Fractal structure of
hydrogels modulates stem cell behavior. ACS Macro
Letters 4(9):1056–1061
Ioannidou K, Kanduˇc M, Li L, Frenkel D, Dobnikar J, Del
Gado E (2016) The crucial effect of early-stage gelation
on the mechanical properties of cement hydrates.
Nature Communications 7(1):1–9
Israelachvili J (2011) Intermolecular and Surface Forces,
3rd edn. Academic Press
Jacobs DJ, Thorpe MF (1995) Generic rigidity percolation:
the pebble game. Phys Rev Lett 75(22):4051
Johnson LC, Zia RN (2021) Phase mechanics of colloidal
gels: osmotic pressure drives nonequilibrium phase
separation. Soft Matter 17, 3784–3797
Kalab M, Allan-Wojtas P, Phipps-Todd BE (1983) Devel-
opment of microstructure in set- style nonfat yogurt - a
review. Food Microstructure 2:51
Keshavarz B, Gomes Rodrigues D, Champenois J-B, Frith
J, Ilavsky J, Geri M, Divoux T, McKinley GH,
Poulesquen A (2021) Time-connectivity superposition
and the gel/glass duality of weak colloidal gels. PNAS
118, e2022339118
Kroy K, Cates ME, Poon WCK (2004) Cluster mode-
coupling approach to weak gelation in attractive col-
loids. Phys Rev Lett 92:148302
Laurati M, Petekidis G, Koumakis N, Cardinaux F, Scho-
ﬁeld
AB,
Brader
JM,
Fuchs
M,
Egelhaaf
SU
(2009) Structure, dynamics, and rheology of colloid-
polymer mixtures: From liquids to gels. The Journal of
Chemical Physics 130(13):134907
Lieleg O, Kayser J, Brambilla G, Cipelletti L, Bausch
A (2011) Slow dynamics and internal stress relaxation
in bundled cytoskeletal networks. Nature Materials
10(3):236
Stress Localization in Soft Particulate Gels
309

Lin M, Lindsay H, Weitz D, Ball R, Klein R, Meakin
P (1989) Universality in colloid aggregation. Nature
339(6223):360
Lu PJ, Zaccarelli E, Ciulla F, Schoﬁeld AB, Sciortino F,
Weitz DA (2008) Gelation of particles with short-range
attraction. Nature 453:499
Maccarrone S, Brambilla G, Pravaz O, Duri A, Ciccotti M,
Fromental JM, Pashkovski E, Lips A, Sessoms D,
Trappe V, Cipelletti L (2010) Ultra-long range correla-
tions of the dynamics of jammed soft matter. Soft
Matter 6(21):5514–5522
Manley S, Cipelletti L, Trappe V, Bailey A, Christianson R,
Gasser U, Prasad V, Segre P, Doherty M, Sankaran
S et al (2004) Limits to gelation in colloidal aggrega-
tion. Phys Rev Lett 93(10):108302
Mansel BW, Williams MA (2015) Internal stress drives
slow glassy dynamics and quake-like behaviour in
ionotropic pectin gels. Soft matter 11(35):7016–7023
Mao B, Divoux T, Snabre P (2016) Normal force con-
trolled rheology applied to agar gelation. Journal of
Rheology 60(3):473–489
Mayer C, Zaccarelli E, Stiakakis E, Likos CN, Sciortino F,
Munam A, Gauthier M, Hadjichristidis H, Tartaglia P,
Vlassopoulos D (2008) Asymmetric caging in soft col-
loidal mixtures. Nature Materials 7:784
Monti JM, McGuiggan PM, Robbins MO (2019) Effect of
roughness and elasticity on interactions between
charged colloidal spheres. Langmuir 35(48):15948–
15959
Muthukumar M (1989) Screening effect on viscoelasticity
near the gel point. Macromolecules 22(12):4656–4658
Nampoothiri
JN,
Wang
Y,
Ramola
K,
Zhang
J,
Bhattacharjee S, Chakraborty B (2020) Emergent
elasticity in amorphous solids. Phys Rev Lett 125:
118002
Ohtsuka T, Royall CP, Tanaka H (2008) Local structure and
dynamics
in
colloidal
ﬂuids
and
gels.
EPL
(Europhysics Letters) 84(4):46002
Padmanabhan P, Zia R (2018) Gravitational collapse of
colloidal gels: non-equilibrium phase separation driven
by osmotic pressure. Soft Matter 14(17):3265–3287
Pantina JP, Furst EM (2005) Elasticity and critical bending
moment of model colloidal aggregates. Phys Rev Lett
94(13):138301
Poon W, Pirie A, Haw M, Pusey P (1997) Non-equilibrium
behaviour of colloid-polymer mixtures. Physica A:
Statistical Mechanics and its Applications 235(1):
110–119
Ramakrishnan S, Chen YL, Schweizer KS, Zukoski CF
(2004) Elasticity and clustering in concentrated deple-
tion gels. Phys Rev E 70:040401
Ramos L, Cipelletti L (2001) Ultraslow dynamics and
stress relaxation in the aging of a soft glassy system.
Phys Rev Lett 87(24):245503
Rocklin DZ, Hsiao LC, Szakasits ME, Solomon MJ, Mao
X (2021) Elasticity of colloidal gels: structural hetero-
geneity, ﬂoppy modes, and rigidity. Soft Matter
17:6929
Rubinstein M, Colby R (2003) Polymer Physics. Oxford
University Press, Oxford, UK
Ruta B, Czakkel O, Chushkin Y, Pignon F, Nervo R,
Zontone F, Rinaudo M (2014) Silica nanoparticles as
tracers of the gelation dynamics of a natural biopolymer
physical gel. Soft Matter 10(25):4547–4554
Sahimi M (1998) Non-linear and non-local transport pro-
cesses in heterogeneous media: from long-range corre-
lated percolation to fracture and materials breakdown.
Physics Reports 306(4-6):213–395
Sciortino F, Tartaglia P, Zaccarelli E (2005) One-
dimensional cluster growth and branching gels in col-
loidal systems with short-range depletion attraction and
screened electrostatic repulsion. The Journal of Physi-
cal Chemistry B 109(46):21942–21953
Shen X, Bourg I (2021) Molecular dynamics simulations
of the colloidal interactions between smectite clay
nanoparticles in liquid water. J Colloid Interf Sci
584:610
Shih WH, Shih WY, Kim SI, Liu J, Aksay IA (1990) Scal-
ing behavior of the elastic properties of colloidal gels.
Phys Rev A 42:4772–4779
Shoaib T, Carmichael A, Corman RE, Shen Y, Nguyen TH,
Ewoldt RH, Espinosa-Marzal RM (2017) Self-adaptive
hydrogels to biomineralization. Soft Matter 13:5469
Stauffer D, Coniglio A, Adam M (1982) Gelation and
critical phenomena. In: Duˇsek K (ed) Polymer Net-
works. Springer, Berlin/Heidelberg, pp 103–158
Tabatabai AP, Kaplan DL, Blair DL (2015) Rheology of
reconstituted silk ﬁbroin protein gels: the epitome of
extreme mechanics. Soft matter 11(4):756–761
Tanaka H (2000) Viscoelastic phase separation. Journal of
Physics: Condensed Matter 12(15):R207–R264
Testard V, Berthier L, Kob W (2011) Inﬂuence of the glass
transition on the liquid-gas spinodal decomposition.
Phys Rev Lett 106:125702
Trappe V, Prasad V, Cipelletti L, Segre P, Weitz D (2001)
Jamming phase diagram for attractive particles. Nature
411(6839):772
Tsurusawa H, Leocmach M, Russo J, Tanaka H (2019)
Direct link between mechanical stability in gels and
percolation of isostatic particles. Science Advances 5:
eaav6090
Tsurusawa H, Arai S, Tanaka H (2020) A unique route of
colloidal phase separation yields stress-free gels. Sci-
ence Advances 6:eabb8107
Valadez-Pérez NE, Liu Y, Eberle AP, Wagner NJ, Priego
R (2013) Dynamical arrest in adhesive hard-sphere
dispersions driven by rigidity percolation. Phys Rev
E 88(6):060302
Vereroudakis E, Bantawa M, Laﬂeur RPM, Parisi D,
Matsumoto NM, Peeters JW, Del Gado E, Meijer EW,
Vlassopoulos D (2020) Competitive supramolecular
associations mediate the viscoelasticity of binary
hydrogels. ACS Central Science 6(8):1401–1411
Verwey E, Overbeek J (1948) Theory of the Stability of
Lyophobic Colloids: The Interaction of Sol Particles
Having an Electric Double Layer. Courier Corporation
310
Stress Localization in Soft Particulate Gels

Whitaker KA, Varga Z, Hsiao LC, Solomon MJ, Swan JW,
Furst EM (2019) Colloidal gel elasticity arises from the
packing of locally glassy clusters. Nature Communica-
tions 10:2237
Witten T, Pincus PA (2004) Structured Fluids: Polymers,
Colloids and Surfactants, Oxford University Press
(Oxford, UK) 2004
Wu Q, van der Gucht J, Kodger TE (2020) Syneresis of
colloidal gels: Endogenous stress and interfacial
mobility drive compaction. Phys Rev Lett 125:
208004
Xing X, Mukhopadhyay S, Goldbart PM (2004) Scaling of
entropic shear rigidity. Phys Rev Lett 93:225701
Zaccone A, Wu H, Del Gado E (2009) Elasticity of arrested
short-ranged attractive colloids: Homogeneous and
heterogeneous glasses. Phys Rev Lett 103:208301
Zhang S, Zhang L, Bouzid M, Rocklin DZ, Del Gado E,
Mao X (2019) Correlated rigidity percolation and col-
loidal gels. Phys Rev Lett 123:058001
Zhuang Y, Zhang K, Charbonneau P (2016) Equilibrium
phase behavior of a continuous-space microphase for-
mer. Phys Rev Lett 116:098301
Zia RN, Landrum BJ, Russel WB (2014) A micro-
mechanical study of coarsening and rheology of colloidal
gels: Cage building, cage hopping, and smoluchowski’s
ratchet. Journal of Rheology 58(5):1121–1157
Stress Localization in Soft Particulate Gels
311

Nonlinear Mechanics of
Colloidal Gels: Creep, Fatigue,
and Shear-Induced Yielding
Thomas Gibaud1, Thibaut Divoux1,2 and
Sébastien Manneville1
1Laboratoire de Physique, Univ Lyon, Ens de
Lyon, Univ Claude Bernard, CNRS, Lyon, France
2MultiScale Material Science for Energy and
Environment, UMI 3466, CNRS-MIT,
Cambridge, MA, USA
Article Outline
Glossary
Deﬁnition of the Subject
Introduction: From Gelation to Rupture in
Colloidal Dispersions
Reversible Yielding Versus Irreversible Rupture
Fundamental Questions and Perspectives
Summary and Conclusion
Bibliography
Glossary
Colloids Refers to entities, such as particles or
polymers, smaller than a few microns in size
and sensitive to thermal agitation. Colloids
therefore display Brownian motion when
dispersed at low volume fraction in a solvent.
They encompass a broad range of entities
from proteins and clay particles to synthetic
polymeric particles and come in all sorts of
geometrical shapes, such as spheres, plate-
lets, and rods. Colloids are also subject to a
wide variety of interactions, which gives rise
to rich state diagrams including ﬂuid and
crystalline equilibrium phases as well as
out-of-equilibrium states such as gels and
glasses.
Colloidal gels Refers to soft solids, whose struc-
ture is composed of attractive colloids that form a
space-spanning network. Colloidal gels are in an
out-of-equilibrium state and display mainly
solid-like properties at rest and under mild defor-
mations, i.e., their elastic modulus is much larger
than their viscous modulus in the linear regime.
Upon increasing external mechanical constraints,
their viscoelastic response becomes nonlinear
and generally involves a yield point above
which colloidal gels show liquid-like properties
(see “Yielding” below).
Creep Refers to the motion induced by imposing
a constant load to a material, whose response is
quantiﬁed by the resulting deformation or strain.
Fatigue Refers to the phenomena induced by
imposing an oscillatory load of constant ampli-
tude to a material, whose response is quantiﬁed
via the temporal evolution of its viscoelastic
properties.
Yielding Refers to a solid-to-liquid transition
induced by imposing some deformation or
stress to a material. The yield stress and yield
strain are respectively the critical stress and
strain above which a complex material starts
to ﬂow or loses its integrity. The yielding tran-
sition
often
involves
a
complex
spatio-
temporal scenario, which is still the topic of
intense research effort.
Definition of the Subject
Colloidal gels are formed through the aggregation
of attractive particles, whose size ranges from
10 nm to a few micrometers, suspended in a
liquid. Such gels are ubiquitous in everyday life
applications, from food products to paints or con-
struction materials, in particular thanks to their
ability to easily “yield,” i.e., to turn from a solid
to a liquid under the application of a weak external
load. Understanding and controlling the mechan-
ical response of colloidal gels is, therefore, of
prime importance. Depending on the details of
© Springer Science+Business Media, LLC, part of Springer Nature 2022
B. Chakraborty (ed.), Statistical and Nonlinear Physics,
https://doi.org/10.1007/978-1-0716-1454-9_743
Originally published in
R. A. Meyers (ed.), Encyclopedia of Complexity and Systems Science, © Springer Science+Business Media LLC 2020
https://doi.org/10.1007/978-3-642-27737-5_743-1
313

the system, however, the resulting gel networks
present different microstructural organizations
that may lead to widely different mechanical
responses. This raises important challenges in
fully characterizing yielding and in uncovering
the mechanisms of nonlinear response in colloidal
gels. In this entry, we distinguish between two
classes of colloidal gels showing respectively
reversible
yielding,
where
the
gel
network
reforms upon load release, and irreversible yield-
ing, where the network is fully destroyed through
fractures and phase separation. This broad, empir-
ical distinction is achieved through rheology and
local experiments at a mesoscopic scale, interme-
diate between the network characteristic size and
the sample size. We further discuss how the
observables derived from creep and fatigue exper-
iments may be modeled to predict yielding and
highlight open questions and future research
directions in the domain.
Introduction: From Gelation to Rupture
in Colloidal Dispersions
General Context: The Mechanics of
Colloidal Gels
In mechanics, material rupture refers to a cata-
strophic series of microscopic events that lead to
the macroscopic, irreversible failure of a material
under an applied load. Studying the onset of rup-
ture and rupture itself is crucial in ﬁelds like
earthquake studies and construction materials
where understanding and being able to predict
the rupture of hard materials is at the core of
people’s safety (Sornette 2002; Alava et al.
2006; Dixon et al. 2014). In soft solids such as
gels, rupture is less dramatic but just as important.
A colloidal gel forms whenever attractive col-
loidal particles dispersed in a ﬂuid aggregate into
a loose, fragile network that percolates across the
sample volume (Larson 1999; Mewis and Wagner
2012). Colloidal gels are found in a huge number
of practical situations, from pharmaceutical and
food products (Gibaud et al. 2012; Mezzenga and
Fischer 2013) to construction materials like
cement (Lootens et al. 2004; Ioannidou et al.
2016), as well as ink-jet printing (Lewis 2002;
Smay et al. 2002; Tan et al. 2018) or ﬂow-cell
batteries (Youssry et al. 2013; Fan et al. 2014;
Helal et al. 2016; Narayanan et al. 2017). Such
ubiquity results from the peculiar mechanical
response of colloidal gels: while they behave
like soft elastic solids at rest, with an elastic mod-
ulus in the range of 1 Pa–10 kPa, colloidal gels are
easily made to ﬂow upon application of mild
external stresses including shear, compression,
gravity or vibration. This solid-to-liquid out-of-
equilibrium transition is referred to as the “yield-
ing transition,” and a fundamental understanding
of the various steps involved in such a transition is
of prime importance for applications to material
design and industrial processes (Balmforth et al.
2014; Bonn et al. 2017). For instance, in food
science, the texture and yielding properties of
edible gels control mouth feel (Jetlema et al.
2016; Wagner et al. 2017) but is also at the heart
of food design for people with swallowing prob-
lems such as toddlers or elderly people (Aguilera
and Park 2016).
Depending on the nature of the particles and due
to the wide variety of ways to induce gelation, e.g.,
through
electrostatic
interactions,
dipole-dipole
interactions, pH, or temperature variations, gel net-
works present a broad variety of structural organi-
zations at the microscopic scale (Nicolai and Durand
2013; Mezzenga and Fischer 2013). The mechanical
properties of colloidal gels are then encoded in the
colloidal interactions and the gel structure.
In particular, the gel structure is expected to
have a signiﬁcant impact on the way the gel fails
under stress. Yet, uncovering the exact link
between the interparticle potential, the gel struc-
ture, and the gel mechanical properties is tricky
and currently constitutes an active research
domain. Such a difﬁculty can be mainly attributed
to
the
fact
that
colloidal
gels
are
out-of-
equilibrium phases with a complex microstructure
that is itself pushed into a nonlinear regime due to
the applied stress. Rationalizing the link between
the gel structure and the failure scenario, there-
fore, remains a complex exercise that we shall
approach here by considering two limiting cases,
both in the gel structure and in the rupture mech-
anisms. Indeed, the main goal of this paper is to
apprehend the various yielding processes in
314
Nonlinear Mechanics of Colloidal Gels: Creep, Fatigue, and Shear-Induced Yielding

colloidal gels through two systems with similar
elasticity at rest and yet very distinct rupture
mechanisms: a carbon black gel that shows
reversible ﬂuidization upon yielding (also com-
monly referred to as shear-rejuvenation) and a
sodium caseinate gel that displays irreversible
brittle failure akin to hard solids (also referred to
as brittle-like failure).
In the rest of this section, we ﬁrst brieﬂy
remind the reader about the most common gela-
tion pathways in attractive colloids and describe
the two gel systems that we will use to illustrate
our discussion on yielding processes. We then
introduce the rheological measurements that are
usually
performed
to
assess
the
nonlinear
mechanical response of colloidal gels. In section
“Reversible Yielding Versus Irreversible Rup-
ture,” we distinguish experimentally between
two types of yielding behaviors in colloidal gels,
namely reversible vs. irreversible yielding, both
from a macroscopic point of view and from local
approaches. Finally, section “Fundamental Ques-
tions and Perspectives” further generalizes the
previous observations based on the current litera-
ture and highlights open questions in the domain.
A Brief Reminder on Colloidal Gelation
As sketched in Fig. 1, two limit scenarios can be
distinguished in the case of colloids with short-
range attraction (Trappe and Sandkühler 2004;
Zaccarelli 2007). In the extreme case of very
strong interparticle attraction and very low vol-
ume fractions, the regime of so-called “irrevers-
ible aggregation” is reached, and one observes the
formation of soft fractal gels (Shih et al. 1990;
Krall and Weitz 1998). In this regime, the inter-
mediate entities between the particle size and the
gel network are fractal clusters, i.e., fractal aggre-
gates of individual colloids. The particles within
the clusters are trapped in the potential well of
their neighbors so that their motion is constrained,
thereby leading to arrested dynamics and provid-
ing elasticity to the network. At intermediate
attraction strength and concentrations, the regime
of so-called “arrested phase separation” is reached
(Fofﬁet al. 2005; Cardinaux et al. 2007;
Buzzaccaro et al. 2007; Lu et al. 2008). In this
regime, a gel results from the interplay between
phase separation and the glass transition line: the
dispersion is unstable and phase separates into a
bi-continuous network (spinodal structure) com-
posed of a “gas” phase, i.e., a dilute phase of
colloids, and a “liquid” phase, i.e., a dense phase
of colloids. During the phase separation process,
the concentration of the liquid phase increases and
eventually meets the glass line where the liquid
network becomes glassy, thus “freezing” the pro-
cess of phase separation. Such arrested dynamics
leads to a long-lived network of particles with a
spinodal structure (Gibaud and Schurtenberger
2009; Gibaud et al. 2012; Gao et al. 2015; Da
Vela et al. 2016). Here, the intermediate entities
between the particle size and the gel network are
the network strands. Strands are composed of
densely packed attractive particles and provide
rigidity to the network.
Although very simpliﬁed, Fig. 1 illustrates
how the gelation kinetic pathway may affect the
microstructure of the resulting colloidal gel. Since
the microstructure directly impacts the mechani-
cal properties of these out-of-equilibrium systems,
controlling the route to gelation offers a way to
tune gel properties. A common way to control
gelation consists in using particles with an inter-
action potential that is sensitive to an external
stimulus such as pH or temperature (Gosal and
Ross-Murphy 2000). By increasing the attraction
strength, one can continuously go from a ﬂuid
state to a gel state. Another common way to con-
trol the gel state consists in playing with the shear
history experienced by the system during or after
gelation (Ovarlez et al. 2013; Koumakis et al.
2015; Helal et al. 2016; Narayanan et al. 2017;
Hipp et al. 2019; Jamali et al. 2020). By tuning the
way a colloidal gel is sheared or mixed, one may
vary
its
terminal
structure
and
mechanical
strength without changing the interparticle poten-
tial. Two experimental knobs may be controlled:
the preshear intensity and the rate of ﬂow cessa-
tion. On the one hand, gels reformed after strong
shearing and “instantaneous” ﬂow cessation gen-
erally evolve into stronger solids with a relatively
homogeneous and ﬁne microstructure, whereas
the application of weak shear rates leads to weaker
gels with a coarser microstructure (Koumakis
et al. 2015). On the other hand, a preshear of
Nonlinear Mechanics of Colloidal Gels: Creep, Fatigue, and Shear-Induced Yielding
315

large intensity followed by ﬂow-cessation exper-
iments performed at different rates allows one to
tune continuously the gel microstructure. For
instance, it was shown for some fractal gels that
the slower the ﬂow cessation, the less connected
and the weaker the resulting gel (Helal et al.
2016). A major difference in the ﬁnal gel states
accessed via continuous quenching of pH or tem-
perature and mechanical shearing lies in the
anisotropy and residual stresses associated with
the latter (Grenard et al. 2014; Colombo et al.
2017; Sung et al. 2018).
Two Illustrations of Colloidal Gel
Microstructures
To apprehend the mechanical properties of colloi-
dal gels, we focus on two systems with distinct
gelation pathways and microstructures: (i) a dis-
persion of carbon black particles in oil (Trappe
and Weitz 2000) and (ii) an acid-induced sodium
caseinate
gel
(Bremer
et
al.
1990;
Braga
et al. 2006).
Carbon black gels are composed of carbon
black particles dispersed in oil and are a reason-
able realization of fractal gels that result from
cluster aggregation (Donnet et al. 1993; Trappe
and Weitz 2000). Carbon black particles are
obtained from partial combustion of fuel and are
made of unbreakable aggregates of permanently
fused nanometric primary particles. These aggre-
gates have a typical diameter of 500 nm. When
dispersed in a light mineral oil at a weight con-
centration of a few percent, carbon black particles
form a space-spanning gel network of fractal
dimension df ’ 2.2 due to attractive Van der
Waals interactions of typical strength U ~ 30 kBT
(Hartley and Parﬁtt 1985; Trappe et al. 2007;
Richards et al. 2017). Representative pictures of
the carbon black gel microstructure and an indi-
vidual carbon black particle are shown in Fig. 2a.
The initial gel state is obtained by preshearing the
suspension at +1000 s1 then at 1000 s1 for
20 s each, in order to break up any large aggre-
gates. Abrupt ﬂow cessation quickly leads to the
gel formation (in less than a second), which is then
left at rest for 100 s before performing any subse-
quent test. All results concerning carbon black
gels presented in this article are based on such a
preshear protocol. Note that preshear not only
rejuvenates the sample by erasing its previous
shear history, it also selects a speciﬁc reproducible
microstructure with some degree of anisotropy
and stored internal stresses that may play a signif-
icant role in the subsequent mechanical response
Aracon
Colloid volume fracon
Fluid
Phase 
separaon
Fractal gels
Cluster
Arrested 
phase 
separaon
Strand
Nonlinear Mechanics of Colloidal Gels: Creep, Fatigue,
and Shear-Induced Yielding, Fig. 1 Schematic state
diagram for colloidal particles with short-range attrac-
tion. In the extreme case of very strong interparticle attrac-
tion and very low volume fractions, colloids aggregate into
fractal gels, whereas at intermediate strength of attraction
and volume fractions, gels result from the interplay
between phase separation (the green line indicates the
binodal line) and the glass transition (red line). Those two
types of gels have very different structures, characterized
by clusters for fractal gels and network strands for arrested
phase separation gels
316
Nonlinear Mechanics of Colloidal Gels: Creep, Fatigue, and Shear-Induced Yielding

(Osuji et al. 2008; Negi and Osuji 2009; Grenard
et al. 2014; Helal et al. 2016).
Sodium caseinate gels are made of sodium
caseinate proteins dispersed in water and can be
seen as a close realization of arrested phase sepa-
ration. Sodium caseinate is a by-product of casein,
which is the main protein component of milk (Fox
2003). Casein is present in the form of polydis-
perse spherical complexes containing casein pro-
teins and colloidal calcium phosphate. Four main
casein proteins may be distinguished, namely a1-,
a2-, b-, and k-casein, with typical weight ratios
0.4:0.08:0.4:0.1 and approximately the same
molar mass M ’ 2  104g. mol1 (HadjSadok
et al. 2008). The native casein complex dissoci-
ates after removal of the colloidal calcium phos-
phate, yielding a mixture of individual casein
proteins referred to as sodium caseinate with an
average diameter of 400 nm (Coskun et al. 2015).
Sodium caseinate particles display a mixed
interparticle potential: a short-range attraction
and a long-range electrostatic repulsion due to
the protein surface charges. Gelation can be
obtained by turning down the electrostatic repul-
sion. This can be achieved using the pH as a
control parameter thanks to the presence of car-
boxylate and primary amine groups at the surface
of the sodium caseinate, which charge depends on
the pH. At pH ¼ 7, sodium caseinates are on
average positively charged, and an aqueous dis-
persion of caseinate is stable and translucent. All
sodium caseinate gels discussed here are obtained
by using glucono-d-lactone (GDL), a molecule
that slowly hydrolyzes into gluconic acid and
thus continuously, and homogeneously lowers
the pH of the sodium caseinate dispersion from
7 to 3. This GDL-controlled acidiﬁcation enables
the formation of a bulk gel phase around the
isoelectric point – the point where surface charges
vanish on average – at pHcas ¼ 4.6. At pH ¼ pHcas,
the gelation is kinetically driven by diffusion-lim-
ited cluster aggregation (DLCA) (Bremer et al.
1990). Right below pHcas, at pH ¼ 3, sodium
caseinates have slightly negative surface charges
and over-acidiﬁcation results in the coexistence of
a “gas” phase of dilute sodium caseinates and a
glassy network (Leocmach et al. 2015), a scenario
that is consistent with arrested phase separation
(Cardinaux et al. 2007). Figure 2b displays an
example of scanning electron microscopy (SEM)
image of an acid-induced sodium caseinate gel
together with an SEM image (as an inset) of an
individual sodium caseinate particle at pH = 3.5.
The gel structure is made of strands with a typical
width of 1 mm. All mechanical characterizations
presented below are performed on sodium casein-
ate gels prepared in situ, i.e., for which acidiﬁca-
tion is performed directly in the measurement cell.
A First Approach of Yielding Based on
Oscillatory Shear Rheometry
The two colloidal gels presented above result
from very different gelation pathways and thus
present very different microstructures. The main
100 µm 
100 µm 
(a) 
(b) 
200 nm
200 nm 
Nonlinear Mechanics of Colloidal Gels: Creep, Fatigue,
and Shear-Induced Yielding, Fig. 2 Microstructures
of two colloidal gels. (a) Optical microscopy image of a
carbon black dispersion at 0.064 vol % in light mineral oil.
(Adapted from Trappe and Weitz (2000) with permission
from the American Physical Society.) Inset: transmission
electron microscopy image of an individual carbon black
particle. (Adapted from Ehrburger-Dolle et al. (1990) with
permission from Elsevier.) (b) SEM microscopy image of a
sodium caseinate gel at 4 wt % in water acidiﬁed with
1 wt % GDL (unpublished data). Inset: SEM image of an
individual sodium caseinate particle at pH ¼ 3.5. (Adapted
from Coskun et al. (2015) with permission from Elsevier)
Nonlinear Mechanics of Colloidal Gels: Creep, Fatigue, and Shear-Induced Yielding
317

question that we wish to address in the following
is: how do their nonlinear mechanical responses
differ? As a ﬁrst approach of this question, we
now introduce the widespread toolbox of rheol-
ogy to induce and assess gel yielding.
The mechanical response of soft materials is
most commonly probed through shear rheometry,
where the sample is conﬁned between a ﬁxed
boundary and a rotating tool and the shear stress
s and strain g are measured at a macroscopic level,
respectively through the torque applied on the
rotating tool and its displacement (Macosko
1994). One usually explores the gel mechanical
behavior from the linear elastic regime up to fail-
ure thanks to oscillatory shear. More speciﬁcally,
in a strain-sweep experiment, the rheometer
imposes an oscillatory strain g(t) ¼ g0 cos(2pft)
of increasing amplitude g0 at a frequency f, and
records the corresponding stress response s(t).
Linear response theory allows one to deﬁne the
response function G⋆that relates the stress to the
strain as s ¼ G⋆g in complex notation. G⋆is
referred to as the complex modulus of the gel
and can be decomposed into its real part, the
elastic (or storage) modulus G0 that indicates
how much elastic energy the gel can store, and
its imaginary part, the viscous (or loss) modulus
G00 that indicates how much energy is lost due to
dissipation.
Figure 3 compares the mechanical properties
G0 and G00 of a carbon black gel (Fig. 3a) and those
of a sodium caseinate gel (Fig. 3b) as a function of
the strain amplitude g0. For both systems, the gel
response to oscillatory shear can be decomposed
into three different regimes depending on g0. At
small g0, in the linear viscoelastic regime, the
stress amplitude s0 is simply proportional to the
strain amplitude g0: the sample mechanical prop-
erties are entirely characterized by the elastic
modulus G0 and loss modulus G00. For the gels
under study, G0 is of the order of 100–1000 Pa and
much greater than G00, a characteristic of soft
solids. Upon increasing g0, the strain response
becomes non-linear. Therefore, linear response
theory no longer strictly applies, and G0 and G00
only provide information on the material response
at the fundamental frequency f. In other words,
higher harmonics of the stress s(t) must be taken
into account to fully characterize nonlinear visco-
elasticity (Hyun et al. 2011). Eventually, above a
critical strain gy deﬁned as the strain where
G0 ¼ G00, the gel yields and subsequently ﬂows
Linear
regime
Yielding
Fluid
Non
linear
regime
Linear
regime
Yielding
Fluid
Non
linear
regime
(a)
(b)
Nonlinear Mechanics of Colloidal Gels: Creep, Fatigue,
and Shear-Induced Yielding, Fig. 3 Assessing yielding
from oscillatory shear. Elastic modulus G0 (■), viscous
modulus G00 (o) and stress amplitude s0 (◊) as a function
of the amplitude g0 of oscillatory strain at frequency
f ¼ 1 Hz in (a) a carbon black dispersion at 6 wt % in
light mineral oil (adapted from Perge et al. (2014) with
permission from the Society of Rheology) and (b) a
sodium caseinate gel at 4 wt % in water acidiﬁed with
4 wt % GDL (unpublished data)
318
Nonlinear Mechanics of Colloidal Gels: Creep, Fatigue, and Shear-Induced Yielding

like a liquid: this critical strain gy corresponds to
the yield strain that can be inferred from large-
amplitude oscillatory shear (LAOS) and the
corresponding stress is associated with the yield
stress sy. Note that such deﬁnitions of the yield
strain and stress are obviously protocol-dependent
(Bonn et al. 2017) and that in the case of the
carbon black gel, G0 displays two local maxima
beyond
the
yield
point,
which
have
been
interpreted respectively in terms of inter-cluster
and intra-cluster bond-breaking (Koumakis and
Petekidis 2011).
While being qualitatively similar, the behav-
iors of G0 and G00 as a function of the strain
amplitude hint at different mechanical scenarios
for the two gels under study even long before
yielding. One may ﬁrst note that although its
elastic modulus at rest is about 10 times larger
than that of the sodium caseinate gel, the carbon
black gel enters the nonlinear regime and then
yields
at
strain
amplitudes
that
are
about
10 times smaller than in the sodium caseinate
gel. Thus, the more elastic, fractal gel constituted
of particle clusters is more sensitive to external
strain than the softer yet more “resistant” gel,
whose structure is made of strands. Second, in
the
“medium-amplitude
oscillatory
shear”
(MAOS) regime, the carbon black gel shows
strain softening, i.e., the elastic modulus drops
for g0 ≳1% and the stress amplitude s0 plateaus
as a function of g0, while the sodium caseinate gel
displays strain stiffening, i.e., G0 increases for
g0 ≳20% and s0 increases faster than linearly
with g0. Third, contrary to the carbon black gel
that shows a smooth, continuous variation of the
various observables at the yielding transition, the
sodium caseinate gel displays a strong disconti-
nuity. In particular, the stress abruptly drops at
yielding, which is indicative of the sample frac-
ture. Indeed, visual inspection on the sample in a
concentric-cylinder geometry reveals that the
sodium caseinate gel fractures irreversibly at
yielding, as also described in more details in sec-
tion “Characterizing Yielding Through Spatially-
Resolved Dynamical Measurements.”
To summarize, the above description of strain
sweeps remains only qualitative and does not
provide full details on the yielding scenario.
Although the rheological response allows estimat-
ing the yield stress sy and the yield strain gy of the
gel, it is insufﬁcient to characterize the gel yield-
ing as it does not provide any time-resolved infor-
mation. This calls for more reﬁned, time-resolved
measurements, both macroscopic and micro-
scopic, to uncover the reasons for the speciﬁc
variations of G0 and G00 exempliﬁed in Fig. 3.
Reversible Yielding Versus Irreversible
Rupture
In this section, we offer a time-resolved analysis
of the yielding transition of colloidal gels at the
macroscopic level. Indeed, the amplitude sweep
protocol used so far to characterize yielding and
sketched in Fig. 4a does not allow one to disen-
tangle the effects of increasing the stress or strain
from the temporal evolution of the sample, e.g.,
due to slow damage accumulation. In fact, there is
a major difference between the yielding behaviors
of the two systems presented above. Whilst the
carbon black gel swiftly reforms and regains elas-
ticity once the external load is released, i.e., yield-
ing and shear-induced ﬂuidization are to some
extent
reversible,
the
sodium
caseinate
gel
remains liquid-like beyond the yield point, and
composed of macroscopic pieces of the original
gel network that coexist with the “gas” phase of
dilute sodium caseinates. The protein gel is per-
manently broken and the yielding process thus
appears as irreversible. In amplitude sweep exper-
iments, such a striking difference only shows
through the discontinuity reported in Fig. 2b and
through the fact that one may perform several
successive identical sweep tests on the carbon
black
gels,
leading
to
reproducible
results
(provided that two consecutive tests are separated
by the same preshear step), whereas one needs to
prepare
a
fresh
protein
gel
prior
to
each
experiment.
To better characterize the two types of yielding
scenarios and quantify their dynamics, we con-
sider other mechanical tests, namely fatigue and
creep tests that are schematized respectively in
Fig. 4b and c. Contrary to stress sweep experi-
ments, the input signal is stationary, which
Nonlinear Mechanics of Colloidal Gels: Creep, Fatigue, and Shear-Induced Yielding
319

facilitates the analysis of the material response
and its time dependence. The primary objective
of those tests is to determine the ﬂuidization
(or fracture) time tf deﬁned as the time needed
for the gel to become ﬂuid as a function of the
input parameter. Stress-controlled experiments
such as fatigue or creep tests provide a relation-
ship tf vs. s, which characterizes the yielding
dynamics at the macroscopic scale. We will
show that the functional form of tf (s) is repre-
sentative of the rupture mechanism and allows
one to differentiate between reversible and irre-
versible yielding. We will then brieﬂy turn to local
measurements that provide additional insight into
the yielding process at the “mesoscale,” i.e., at
spatial scales intermediate between the macro-
scopic scale probed by rheometry and the micro-
scopic scale of the colloidal gel network.
Carbon Black Gels as Model Materials for
“Reversible” Yielding
The yielding dynamics of carbon black gels asso-
ciated with creep tests and fatigue tests is pre-
sented in Fig. 5a–c. In both cases, the yielding
transition is strongly time- and load-dependent.
Figure 5a shows the evolution of the shear rate _g
as function of time t under constant stress ampli-
tudes s (increasing from right to left). All mea-
surements show similar features: _g ﬁrst slowly
decreases at short times, then shows an abrupt
increase and presents one or several kinks and
ﬂuctuations before a ﬁnal increase up to a steady
state. The whole process takes from a few seconds
for large stresses to several hours at low stresses.
The ﬂuidization time tf is deﬁned as the inﬂection
point during the ﬁnal increase of _g. Measurements
of the velocity ﬁeld within the gel revealed that the
inﬂection point indeed corresponds to the point
where the sample ﬂows homogeneously like a
liquid (Gibaud et al. 2010; Grenard et al. 2014).
Similarly, Fig. 5b displays the temporal evolution
of the strain amplitude g0 in response to three
different fatigue tests (i.e., oscillatory shear stress
at constant stress amplitude) conducted at various
amplitudes s0. Here again, all measurements
show the same trend: a slow initial increase of
g0 followed by a ﬁnal increase up to a steady
state. As shown in the inset of Fig. 5b, the ﬁnal
increase of g0 corresponds to the transition from a
solid-like state where G0 > G00 to a ﬂuid-like state
where G00 > G0. The ﬂuidization time tf is here
deﬁned as the inﬂection point of the ﬁnal increase
of g0, which corresponds to the time where the
two moduli roughly coincide, G0 ’ G00, at least for
low enough stress amplitudes (see inset in
Fig. 5b). The time-dependence observed here is
usually referred to as “delayed ﬂow” or “delayed
yielding” in the literature (Gopalakrishnan and
Zukoski 2007; Sprakel et al. 2011; Lindström
et al. 2012). Finally, note that in both creep and
fatigue tests, a steady state is reached where the
carbon black dispersion ﬂows like a liquid. When
the test is stopped and the stress is released, the
dispersion aggregates again into a gel. As a result,
successive yielding experiments can be performed
on a single sample provided that the same pre-
shear protocol is repeated between each test to
prepare the sample into the same initial state.
Nonlinear Mechanics of Colloidal Gels: Creep, Fatigue,
and Shear-Induced Yielding, Fig. 4 Rheological tests
used to probe yielding in colloidal gels. (a) Stress ampli-
tude sweep at ﬁxed frequency. (b) Fatigue test under an
oscillatory shear stress of constant amplitude and fre-
quency. (c) Creep test under a constant shear stress. (d)
Shear start up test under constant imposed shear rate. The
imposed variable in (a)–(c) is the stress s. The measured
observables are the strain g, the elastic modulus G0 and the
viscous modulus G00 in (a, b) and the strain g in (c) or
equivalently its time-derivative, the shear rate _g. In (d), the
imposed variable is the shear rate _g and the measured
variable is the stress s
320
Nonlinear Mechanics of Colloidal Gels: Creep, Fatigue, and Shear-Induced Yielding

Based on series of creep and fatigue tests, one
may then access the dependence of tf with the
applied stress. As shown in Fig. 5c, such a depen-
dence is well captured by an exponential decrease,
tf ¼ t0 exp(s/s*), for both types of tests,
although with different characteristic stresses s*
and prefactors t0. Such an empiric law was ﬁrst
reported for carbon black gels in (Gibaud et al.
2010; Sprakel et al. 2011). It is well captured by a
mean-ﬁeld model based on Kramers’ theory for
activated
processes
(Sprakel
et
al.
2011;
Lindström et al. 2012; Gibaud et al. 2016). In
this framework, yielding results from the compe-
tition between individual interparticle bond for-
mation and rupture events induced by the external
stress. Moreover, the characteristic stress s*
(b) 
(c) 
(a) 
(e) 
(f) 
(d) 
Nonlinear Mechanics of Colloidal Gels: Creep, Fatigue,
and Shear-Induced Yielding, Fig. 5 Comparison
between creep and fatigue experiments in carbon
black gels and sodium caseinate gels. (a)–(c) Delayed
yielding in carbon black gels. (a) Creep experiments in a
carbon black gel at 8 wt % in light mineral oil: shear rate
responses _g tð Þ for different shear stresses s applied at time
t ¼ 0 (s ¼ 45, 50, 52, 53, 55, 60, 65, 70, and 75 Pa from
right to left, adapted from Grenard et al. (2014) with
permission from the Royal Society of Chemistry). (b)
Fatigue experiments in a carbon black gel at 6 wt % in
light mineral oil: strain amplitude response g0 (t) to oscil-
latory stresses of frequency f ¼ 1 Hz and amplitude
s0 ¼ 11, 15 and 27 Pa from right to left. Inset: G0 (solid
line) and G00 (dashed line) as a function of time t for
s ¼ 11 Pa. (Adapted from Perge et al. (2014) with permis-
sion from the Society of Rheology and Gibaud et al. (2016)
with permission from the Royal Society of Chemistry.) (c)
Fluidization time tf as a function of stress s in creep
experiments (•) and as a function of stress amplitude
s0 in fatigue experiments (■) for a carbon black gel at
6 wt % in light mineral oil. Lines corresponds to the best
exponential ﬁts of the data: tf ~ exp(s/s*) with s* ¼ 7 Pa
for fatigue and s* ¼ 3.5 Pa for creep experiments.
(Adapted from Grenard et al. (2014) and Gibaud et al.
(2016) with permission from the Royal Society of Chem-
istry.) (d–f) Brittle fracture in sodium caseinate gels.
(d) Creep experiments in an aqueous gel of sodium casein-
ate at 4 wt % acidiﬁed with 1 wt % GDL: shear rate
responses _g tð Þ for different shear stresses s applied at
time t ¼ 0 (s ¼ 200, 300, 400, 550, and 1000 Pa from
right to left, adapted from Leocmach et al. (2014) with
permission
from
the
American
Physical
Society).
(e) Fatigue experiments in an aqueous gel of sodium
caseinate at 6 wt % acidiﬁed with 6 wt % GDL: strain
amplitude response g0 (t) to oscillatory stresses of fre-
quency f ¼ 1 Hz and amplitude s0 ¼ 90, 150 and 200 Pa
from right to left. (Adapted from Saint-Michel et al. (2017)
with permission from the Royal Society of Chemistry.)
(f) Fluidization time tf as a function of stress s in creep
experiments (•) and as a function of stress amplitude s0 in
fatigue experiments (■) for a sodium caseinate gel at
4 wt % in water acidiﬁed with 1 wt % GDL. Lines corre-
spond to the best power-law ﬁts of the data: tf  sb with
b ¼ 4.2 for fatigue and b ¼ 5.5 for creep experiments
(unpublished data)
Nonlinear Mechanics of Colloidal Gels: Creep, Fatigue, and Shear-Induced Yielding
321

reﬂects the mean elastic barrier that should be
overcome for a single bond to break. Typical
values of s* in carbon black gels range from
1 to 10 Pa. We note from Fig. 5c that this stress
barrier is smaller in creep experiments than in
fatigue experiments (s* ’ 3.5 Pa vs. s* ’ 7 Pa
resp.). Such an Arrhenius-like behavior of tf
is observed in many other types of colloidal
gels that also show reversible yielding, including
depletion
gels
(Ramakrishnan
et
al.
2005;
Dibble et al. 2006; Koumakis et al. 2015;
Sprakel et al. 2011), presheared proteins gels
(Brenner et al. 2013), and thermo-reversible gels
(Gopalakrishnan and Zukoski 2007). As for car-
bon black gels, they appear as a model system to
investigate delayed yielding. For the sake of sim-
plicity, we only focus here on tf. Yet, we empha-
size that the ﬂuidization process also generically
involves several other time scales, e.g., due to the
early detachment from the shearing walls at large
stresses, and that tf also depends on boundary
conditions as well as on the preshear protocol or
on external mechanical vibrations. For full details,
the reader is referred to (Gibaud et al. 2010, 2016,
2020; Grenard et al. 2014; Perge et al. 2014; Helal
et al. 2016).
Caseinate Gels as Model Materials for
Irreversible Yielding
The counterpart of Fig. 5a–c for sodium caseinate
gels is displayed in Fig. 5d–f. Here again, the
strong time- and load-dependence of the yielding
process is evident. In the creep experiments of
Fig. 5d, the shear rate ﬁrst decreases as a power
law of time _g  ta, with a ’ 0.85. This initial
regime is strongly reminiscent of the primary
creep regime observed in hard solids (Miguel
et al. 2002; Nechad et al. 2005; Rosti et al. 2010)
and referred to as “Andrade creep” (da C Andrade
1910). Here, the value of a observed in sodium
caseinate gel can be inferred from linear visco-
elasticity (Leocmach et al. 2014), and quantita-
tively differs from the value 2/3 classically
reported in hard solids, where such a primary
creep response is interpreted in terms of collective
plastic events (Miguel et al. 2008). Then _g reaches
a minimum and ﬁnally diverges at the ﬂuidization
time tf. In the fatigue experiments shown in
Fig. 5e, the strain increases slowly before diverg-
ing upon yielding, which deﬁnes the ﬂuidization
time tf. The striking divergence of _g tð Þ and g0(t) is
the hallmark of irreversible rupture in the investi-
gated sodium caseinate gels. Contrary to the case
of reversible yielding where a saturation is
observed, the velocity of the moving tool keeps
increasing for all applied stresses until the rheom-
eter reaches its speed limit. In the process, the gel
structure is fully destroyed. Moreover, the gel
does not recover once the load is released, which
is why tf corresponds to the “fracture time” (van
Vliet and Walstra 1995). As a consequence, one
has to perform the various yielding tests on dif-
ferent samples, each being freshly prepared for a
given set of parameters.
Furthermore, as displayed in Fig. 5f, the rup-
ture time does not follow an exponential scaling
but its dependence with stress is rather given by a
power law, tf~sb, with b ¼ 5.5 under creep and
b ¼ 4.2 under fatigue. This power-law scaling was
ﬁrst reported for sodium caseinate gels by
Leocmach et al. (2014) and is strikingly reminis-
cent of the Basquin law of fatigue (Basquin 1910)
found for a variety of heterogeneous or cellular
materials under cyclic deformation (Kohout 2000;
Kun et al. 2008). This behavior can be recovered
from a ﬁber bundle model where the system under
stress is represented by a set of linear elastic ﬁbers
following simple failure rules (Jagla 2011). When
the ﬁber bundle is subjected to an increasing
external load, the ﬁbers behave like linear elastic
springs until they break for a given failure load. To
recover the Basquin law, (Kun et al. 2008) mod-
iﬁed the original ﬁber bundle model and consid-
ered a mean-ﬁeld approach in which the network
strands form a random network and fail either due
to immediate breaking or to aging through dam-
age accumulation. In this framework, b is directly
related to the growth of local damage as a function
of the local stress. High values of b mean that the
material is prompt to accumulate damage. In soft
gels, typical values of b range from 1 to 10, much
larger that in hard solids such as metals (b ’ 0.1)
(Eshbach and Tapley 1990) and asphalt (b ’ 0.5)
(Kun et al. 2008). Here, the larger exponent found
in creep tests than in fatigue experiments suggests
that sodium caseinate gels accumulate damage
322
Nonlinear Mechanics of Colloidal Gels: Creep, Fatigue, and Shear-Induced Yielding

more “efﬁciently” under a constant stress than
under an oscillatory stress. In any case, both the
strain divergence during the approach of yielding
and the Basquin power-law scaling for the rupture
time are indicative of a brittle-like behavior of the
strand network, which strongly differs from the
delayed yielding observed in gels constituted of
colloidal clusters. This difference is further
explored through more local approaches in the
next paragraph.
Characterizing Yielding Through Spatially-
Resolved Dynamical Measurements
Measuring the functional form tf (s) constitutes a
big step forward when compared to the simple
amplitude-sweep measurements or to the mere
estimation of a yield stress or strain. In particular,
the stress-dependence of the ﬂuidization time
allows one to classify the yielding behavior, to
infer a rupture mechanism and to quantitatively
test models, e.g., based on reversible bond-
breaking or on damage accumulation. This
approach remains however macroscopic and
more local measurements are required to better
pinpoint the rupture mechanism. Such measure-
ments can be performed at different length scales:
at the mesoscopic scale, typically 10–100 mm, in
order to map the displacement ﬁeld within the gel
or at the microscopic scale, typically 0.1–10 mm,
to directly retrieve the structure of the strands or
clusters during fatigue or creep experiments.
At the mesoscopic scale, displacement maps
and velocity proﬁles can be obtained from
scattering-based techniques (Adam et al. 1988;
Kroon et al. 1996; Romer et al. 2000; Duri et al.
2005), magnetic resonance imaging (Assink and
Kay 1991; Bonn et al. 2008), image correlation
microscopy (Derks et al. 2004; Larsen and Furst
2008; Edera et al. 2017) or ultrasonic imaging
(Manneville et al. 2004; Gallot et al. 2013;
Saint-Michel et al. 2016).
When coupled to rheology, the latter high-
frequency ultrasonic imaging technique, sketched
in Fig. 6a, allows one to measure the displacement
map within the gel with a spatial resolution of
about 50 mm simultaneously to standard rheolog-
ical observables. Compared to light-based tech-
niques, ultrasound has the great advantage of
being able to probe optically opaque gels, in
spite of lower spatial resolution. In the case of
the carbon black and sodium caseinate gels inves-
tigated so far, which are transparent to ultrasound,
this imaging technique necessitates to seed the gel
with acoustic contrast agents, respectively hollow
glass spheres of mean diameter 6 mm and poly-
amide spheres of mean diameter 30 mm.
Figure 6b shows displacement maps recorded
during a fatigue experiment carried out on a car-
bon black gel. One can identify four successive
regimes. (i) At short time scales, the gel displace-
ment from one oscillation cycle to the other is
zero, i.e., the gel behaves like an elastic solid.
(ii) For t ¼ tw, the gel yields at the inner cylinder
of the geometry (located at r ¼ 0) inducing a plug-
like ﬂow of the bulk gel. (iii) The gel gets pro-
gressively fragmented into large solid domains
(that show as uniform patches on the displacement
map) evolving in a ﬂuid background (that shows
as apparently noisy regions where the displace-
ments are very large and uncorrelated from one
pixel to the other). (iv) Finally, at t ¼ tf, those
large domains get fully eroded, and the whole gel
is turned into a homogeneous ﬂuid. As described
in detail in (Perge et al. 2014; Gibaud et al. 2016),
this last step corresponds to the ﬁnal increase in
the strain amplitude g0 reported in Fig. 5b.
Thus, despite a complex yielding process char-
acterized by solid-liquid coexistence and hetero-
geneous ﬂows, the carbon black gel ends up being
homogeneously ﬂuidized. The case of a sodium
caseinate gel is strikingly different. Figure 6c
shows pictures of the gel subjected to a creep
experiment in a concentric-cylinder cell together
with time-resolved velocity maps. Three regimes
are observed under a constant stress. (i) During
primary creep, the gel is linearly deformed and
behaves like an elastic solid. (ii) At intermediate
times, around the time at which _g tð Þ reaches a
minimum value in Fig. 5d, regularly-spaced
cracks start to nucleate from the top and bottom
edges of the cell. (iii) Finally, cracks grow along
the vorticity direction, i.e., perpendicular to the
applied stress, and the gel eventually fails when
fractures meet in the middle of the cell at tf, which
translates into the divergence of the shear rate.
The macroscopic fractures within the sodium
Nonlinear Mechanics of Colloidal Gels: Creep, Fatigue, and Shear-Induced Yielding
323

Nonlinear Mechanics of Colloidal Gels: Creep, Fatigue, and Shear-Induced Yield-
ing, Fig. 6 Heterogeneous dynamics during yielding of carbon black and sodium
caseinate gels. (a) Sketch of the rheology experiment coupled to high-frequency
ultrasonic imaging. The rheology is carried out using a Taylor-Couette geometry, a
concentric-cylinder geometry of height H and of gap e with an inner rotating cylinder of
radius Ri. (b) Time-resolved displacement maps D(r,z,t) recorded in a carbon black gel at
6 wt % in light mineral oil between two cycles of oscillation during a fatigue experiment
with s0 ¼ 11 Pa and f ¼ 1 Hz. (Adapted from Perge et al. (2014) with permission from
the Society of Rheology.) The experiment is performed in the experimental setup
sketched in (a) with H ¼ 50 mm, e ¼ 2 mm and Ri ¼ 48 mm. r denotes the radial
distance from the inner cylinder and z the position along the height of the cylinder.
tw indicates the time at which the gel detaches from the inner cylinder and tf indicates
full bulk ﬂuidization, which corresponds to the last inﬂection point of g0 (t) in Fig. 5b.
(c) Typical fracture growth in a sodium caseinate gel at 4 wt % acidiﬁed with 1 wt %
GDL and subjected to a constant shear stress s ¼ 300 Pa in the experimental setup
sketched in (a) with H ¼ 60 mm, e ¼ 2 mm and Ri ¼ 23 mm. The picture taken at t/
tf ¼ 0.57 corresponds to the time at which the shear rate passes through a minimum.
Velocity maps u(r, z,t) recorded simultaneously to both the rheological data and to the
images are shown next to the corresponding picture. (Adapted from Leocmach et al.
(2014) with permission from the American Physical Society.) tf is the “fracture time”
deﬁned from rheology as the point where _g tð Þ diverges in Fig. 5d and which also
corresponds to when fractures meet in the middle of the cell
324
Nonlinear Mechanics of Colloidal Gels: Creep, Fatigue, and Shear-Induced Yielding

caseinate gel network are invaded with water
expelled from the gel matrix. Therefore, the yield-
ing behavior of the present acid-induced protein
gel can be described as a stress-induced macro-
scopic fracture of the gel network leading to an
irreversible separation of the sample between a
dilute protein suspension and broken pieces of
the original gel.
To summarize, we have illustrated how revers-
ible and irreversible yielding processes differ at
both macroscopic and mesoscopic scales based on
optical and ultrasound imaging. Note that the gel
microstructure under stress can also be probed at
scales below 10 mm by coupling the shearing
device to scattering techniques such as small-
angle neutron, x-ray or light scattering (Verduin
et al. 1996; Pignon et al. 1997; Varadan and
Solomon 2001; Mohraz and Solomon 2005;
Vermant and Solomon 2005; Eberle and Porcar
2012; Kim et al. 2014; Hipp et al. 2019). When
time-resolved measurements are available, such
techniques provide valuable insight into the yield-
ing dynamics in the reciprocal space, i.e., as a
function of the scattering wave number. For
instance, they allow one to identify the relevant
length and time scales of plastic activity (Aime
et al. 2018). However, they fail to provide a direct
picture of the microscopic mechanisms underpin-
ning the physics of shear-induced yielding in col-
loidal gels. As discussed below in section “Can
We Get a Microscopic Picture of Yielding?,” fast
confocal microscopy appears as an even more
promising alternative to tackle such a challenge.
Fundamental Questions and
Perspectives
In the previous sections, we have illustrated how
one may investigate the yielding transition on two
speciﬁc cases representative of two distinctive
behaviors, namely reversible ﬂuidization and irre-
versible fracture. Such a distinction opens a num-
ber of fundamental questions, e.g., on the
predictability of yielding or on the microscopic
rupture events pre-existing macroscopic failure.
In the following section, we list such questions
and draw a few perspectives for future work.
What Is the Physical Meaning of the
Functional Form tf (s)?
We have identiﬁed two types of functional forms
for the empirical failure law tf(s), namely an
exponential in the case of carbon black gels, and
a power law in the case of sodium caseinate gels.
The reason for such a striking difference and the
physical origins of these laws remain unclear and
raise several outstanding questions.
First, does such a difference at the macroscale
directly stem from the fact that bonds can sponta-
neously reform in carbon black gels, whereas they
cannot in sodium caseinate gels, or does it origi-
nate only from stress-induced plastic events at the
microscale? In that framework, one may ask
whether precursors to failure are of different
nature for these two functional forms, and thus if
they could help anticipate the nature of the failure
scenario thanks to a single creep or fatigue exper-
iment. Second, one may be tempted to rationalize
these two functional forms as two cases of a single
master function tf (s) that could involve a Weibull
distribution for instance (van der Zwaag 1989).
This raises the question of whether it is possible to
go continuously from one type of functional form
to the other within the same type of colloidal gel
and how to devise such an experimental system.
How Does Strain-Induced Yielding Compare
to Stress-Induced Yielding?
So far, we have focused on stress-induced yield-
ing through both creep and fatigue experiments.
Another way to induce yielding is by imposing a
constant shear rate, _g, in a shear start-up experi-
ment as sketched in Fig. 4d. Such a ﬂow test
amounts to submitting the material to a shear
strain g tð Þ ¼ _gt that increases linearly with time.
As long as the deformation lies in the linear
domain, imposing the strain is equivalent to
imposing the stress. However, such an equiva-
lence a priori breaks down when the material
enters the nonlinear regime so that a natural ques-
tion is how yielding under a given shear rate may
be compared to that induced by stress and whether
it is possible to relate the two.
Figure 7a shows the stress responses of a
sodium caseinate gel during shear start-up exper-
iments performed under various shear rates. The
Nonlinear Mechanics of Colloidal Gels: Creep, Fatigue, and Shear-Induced Yielding
325

general shape of s vs. t resembles that of s0 vs. g0
reported in Fig. 3b. In particular, it presents a
marked stress increase characteristic of strain
stiffening prior to the sudden drop that marks the
sample macroscopic failure. As explained at
length in (Keshavarz et al. 2017), such stress
responses can be quantitatively modeled by a
K-BKZ (Kaye–Bernstein–Kearsley–Zapas) con-
stitutive formulation (Bird et al. 1987; Larson
1999) based on the linear viscoelastic spectrum
and a “damping function” inferred empirically
from step-strain experiments. The predictions of
this K-BKZ approach are displayed as solid lines
in Fig. 7a and closely match the experimental data
up to the rupture point. Interestingly, one may
relate the fracture time T f _g
ð Þ , which is now a
function of _g since measured under a constant
shear, to the Basquin law tf (s) obtained from
creep tests thanks to the Bailey “durability” crite-
rion ﬁrst introduced for glasses and metals (Bailey
1939; Freed and Leonov 2002) and later applied
to the rupture of polymeric liquids and elastomers
(Eirich and Smith 1972; Malkin and Petrie 1997).
This criterion states that
Ð T f
0 dt=t f s tð Þ
½
 ¼ 1,
where the creep rupture time tf is evaluated all
along the loading process s(t). The Bailey crite-
rion assumes that the failure of the material results
from the accumulation of independent local fail-
ure events. Combining the K-BKZ approach with
the Bailey criterion allows one to quantitatively
predict the scaling of the yield stress and yield
strain as a function of the applied shear rate _g. This
result nicely extends the range of application of
Bailey’s criterion to soft viscoelastic gels, further
reinforcing the emerging analogies between soft
and hard materials (Schmoller and Bausch 2013).
Still, the above approach to reconcile stress-
induced and strain-induced failure requires a care-
ful modeling of the linear and nonlinear viscoelas-
tic response. In the speciﬁc case of sodium
caseinate gels, it is successful thanks to a robust,
well-deﬁned kernel for the K-BKZ equation.
Besides, in these gels, the deformation remains
homogeneous well into the nonlinear viscoelastic
regime without signiﬁcant structural damage. In
practice, however, the gel may detach from the
Nonlinear Mechanics of Colloidal Gels: Creep, Fatigue,
and Shear-Induced Yielding, Fig. 7 (a) Strain-induced
rupture. Shear stress response s vs. time t of a sodium
caseinate gel at 4 wt % acidiﬁed with 1 wt % GDL and
subjected to a constant shear rate _g ¼ 103, 0.02, 0.2 and
0.6 s1 (from right to left) applied at t ¼ 0. The fracture
time Tf corresponds to the locus of the stress maximum.
Dashed lines correspond to linear viscoelastic response and
solid lines show the K-BKZ prediction. (Adapted from
(Keshavarz et al. 2017) with permission of the American
Chemical Society.) (b) Rupture prediction from Fourier
transform rheology. Amplitude of the Fourier modes gk of
the strain response of sodium caseinate gels subjected to an
oscillatory stress of amplitude s1 for various casein
concentrations. Colors code for k ¼ 1 to 9. The stress
amplitude is normalized by the elastic modulus G0 of the
gel measured in the linear viscoelastic regime. Solid lines
show the best power-law ﬁts of gk for s1/G0 < 0.5. The
build-up of Fourier modes within the nonlinear viscoelastic
regime yields an empirical criterion for rupture as the
intersection point of the power-law extrapolations into
the damaged regime. Inset: elastic modulus G0 as a func-
tion of the sodium caseinate weight concentration [Cas].
Symbols code for casein concentrations in the main graph.
The solid line is G0 ~ [Cas]4. (Adapted from Saint-Michel
et al. (2017) with permission from the Royal Society of
Chemistry)
326
Nonlinear Mechanics of Colloidal Gels: Creep, Fatigue, and Shear-Induced Yielding

wall and/or present heterogeneous deformation
ﬁelds, as already shown above in Fig. 6b in the
case of carbon black gels. Therefore, it is not clear
whether a similar approach, possibly based on a
different durability criterion, is achievable in the
case of reversible, delayed yielding due to acti-
vated processes, or even in other colloidal gels
showing irreversible, brittle-like rupture. Finally,
the Bailey criterion necessitates previous knowl-
edge of the full tf (s) law and, as such, does not
allow one to become genuinely predictive of rup-
ture. This observation leads us to ask whether it is
at all possible to predict yielding in colloidal gels
based on the sole measurement of macroscopic
rheological observables.
Can One Predict the Yielding Scenario from
Macroscopic Observables?
Rupture prediction consists in using indicators of
the material properties way before it fails to pre-
dict the time, strain, or stress at which the sample
will fail. Establishing a yielding prediction from
the sole rheological measurements appears as a
major challenge for colloidal gels. Leocmach et al.
(2014) have shown that the time tmin at which the
shear rate reaches its minimum in the creep exper-
iments of Fig. 5d is the same fraction of the
rupture time tf whatever the applied stress,
namely tmin ’ 0.57tf. Such a proportionality is
known
as
the
Monkman-Grant
relation
(Monkman and Grant 1956; Voight 1989) and
has been reported in a broad variety of solids
(Sundararajan 1989; Nechad et al. 2005; Laurson
et al. 2011). It allows for a rough estimate of the
rupture time by recording _g tð Þ up to the point
where it reaches a minimum. Still, sample to sam-
ple variations usually dominate, which limits the
predictions of the failure time to within at least
10% (Koivisto et al. 2016). Moreover, as seen in
Fig. 6c, at this point, macroscopic fractures have
appeared, and the network structure is already
deeply affected by stress.
For the same sodium caseinate gels, Fig. 7b
shows that, based on Fourier transform rheology
(Wilhelm et al. 2002), a prediction of rupture
under an oscillatory stress can be empirically
achieved before any signiﬁcant damage occurs.
There, we take advantage of the increasingly rich
harmonic content of the strain response to an oscil-
latory stress of increasing amplitude (Saint-Michel
et al. 2017). The strain response is decomposed
into a Fourier series, g(t) ¼ kgk cos (2pkft + fk),
where gk is the amplitude of the kth harmonics and
fk its phase with respect to the sinusoidal stress
input s(t) ¼ s1 cos (2pft), which is applied for only
10 cycles of oscillations and for increasing ampli-
tude s1. Between two sets of oscillation cycles, the
gel is left to recover for 10 min. The amplitudes of
the harmonics gk > 1 follow power laws of the
applied stress amplitude with exponents that
increase with k and that are larger than 1 in the
non-linear viscoelastic regime and eventually
get close to 1 in the damaged regime. The extrap-
olations of the power laws from the non-linear
viscoelastic regime all intersect at a single
point. Interestingly, this single point matches
remarkably well the experimental rupture point
(sc/G0 ¼ 1.06  0.25, gc ¼ 1.32  0.20). This
empirical analysis seems to point out that rupture
is encoded in the non-linear strain modes and that,
for sodium caseinate gels, a simple extrapolation of
Fourier modes allows one to predict the rupture
point way before the gels actually fail. Such an idea
echoes ﬁndings from Fourier transform rheology
on
other
systems
such
as
polymer
melts
(Hirschberg et al. 2017).
Here again, the fact that the deformation ﬁeld
remains homogeneous and that the gel sticks to
the walls deep into the nonlinear regime might
help to get a simple rupture prediction in the
present protein gel. Furthermore, in the absence
of any theoretical basis, such a prediction appears
as an ad-hoc criterion, and more work is needed to
understand its origin. Whether or not a similar
predictive approach, either based on Fourier
modes or on more advanced indicators from
LAOS
measurements
(Ewoldt
et
al.
2008;
Dimitriou et al. 2013), can be proposed for revers-
ible yielding of colloidal gels stands out as an
open question.
What Does Strain-Stiffening Tell Us About
Yielding?
Related to the previous question of the yielding
predictability is the observation that colloidal gels
do not
all
become weaker
before
rupture.
Nonlinear Mechanics of Colloidal Gels: Creep, Fatigue, and Shear-Induced Yielding
327

Although strain softening corresponds to the most
general case, as exempliﬁed in Fig. 3a for carbon
black gels, some gels show the reverse trend.
Indeed, their elastic modulus G0 increases as the
strain or stress increases, i.e., these gels stiffen
until abrupt rupture takes place. Such a strain-
stiffening behavior has also been reported in a
wide range of materials including rubbers, swol-
len polymer gels and semi-ﬂexible biopolymer
networks such as actin (Gardel et al. 2004;
Schmoller et al. 2010), heat-set b-lactoglobulin
(Pouzot et al. 2006), collagen (Arevalo et al.
2015), ﬁbrin, and vimentin or neuroﬁlaments
(Storm et al. 2005). In colloidal gels, strain stiff-
ening is rather rare and, when present, the ampli-
tude of the phenomenon is usually small with G0
increasing at most by a factor of 5. This is the case
for polystyrene latex particles that gel under the
addition of MgCl2 (Gisler and Weitz 1999) or for
the sodium caseinate gels that we have been
discussing throughout in this article, as displayed
in Fig. 3b. Recently, however, it was reported that
natural rubber latex gels (de Oliveira Reis et al.
2015) and thermosensitive polystyrene colloidal
gels (van Doorn et al. 2018) display a strain-
stiffening behavior with an amplitude comparable
to that of biopolymer gels for which G0 may
increase by a factor of 100. As shown in Fig. 8a
and b, the elasticity of these gels adapts to the
imposed stress or strain and grows up to rupture.
The interpretation of such an impressive strain
stiffening and its relationship with subsequent
yielding are not yet settled. Using numerical sim-
ulations, van Doorn et al. (2018) suggest that
plasticity at the strand level is responsible for the
strain-stiffening behavior. Mechanical loading
leads to strand stretching, which displays a strong
hysteresis: it builds slack into the network that
softens the solid at small strains but causes strain
stiffening at larger deformations. Bouzid and Del
Gado (2017) have recently tackled this issue
through computer simulations and found that
strain stiffening could be understood in terms of
backbone network topology: the stiffening is
observed in stiffer gels where there is a lack of
soft bending relaxation modes. Those gels exhibit
Nonlinear Mechanics of Colloidal Gels: Creep, Fatigue,
and Shear-Induced Yielding, Fig. 8 Strain stiffening
prior to rupture. (a) Response of a natural rubber latex
colloidal gel at a volume fraction of 0.11 to successive
amplitude sweeps under oscillatory shear. Each cycle con-
sists of a continuous increase in strain amplitude g0 (full
symbols) up to a predetermined maximum strain gmax,
followed by a continuous decrease in strain amplitude
(empty symbols). Each new cycle is performed on the
same sample. The elastic modulus increases irreversibly
until rupture at gc ’ 1.3. The red line highlights the strain
stiffening behavior the gel, G0  g1:0
0 . (Adapted from de
Oliveira Reis et al. (2019) with permission from the Royal
Society of Chemistry.) (b) Stress-strain curves s(t) vs. g(t)
of an attractive polystyrene gel at a volume fraction of 0.18
for a triangular strain input with _g ¼ 0:1 s1 and increasing
values of the maximum strain gmax ¼ 0.005, 0.02, 0.035,
0.05, 0.065, 0.08, 0.095 (from blue to yellow, see also
inset). The right panel shows visual representations of the
plastic deformation in a computer-simulated gel strand
after the ﬁrst cycle (F1), before fracture (F11), and after
fracture (F12). Colors code for low (purple) to high
(yellow) noncumulative plastic deformation mi per parti-
cle. (Adapted from van Doorn et al. (2018) with permission
from the American Physical Society)
328
Nonlinear Mechanics of Colloidal Gels: Creep, Fatigue, and Shear-Induced Yielding

purely stiffening behavior due to their still rela-
tively sparse backbone connectivity that allows
for stretching and orienting the gel branches
along the direction of maximum elongation in
shear.
Still, natural rubber latex gels must fall in
another category as the strain-stiffening process
is irreversible (de Oliveira Reis et al. 2019): once
stiffened the material never regains its initial elas-
ticity. Here, it can be hypothesized that the net-
work is not just stretched and oriented but that it
restructures, most probably through strand coales-
cence along the shear direction. Another interpre-
tation could rely on the details and speciﬁcity of
the particles themselves. In any case, it is clear
that the strain-stiffening phenomenon that pre-
cedes rupture deserves renewed attention as it
may help discriminate between various plastic
responses or restructuring processes in some
colloidal gels.
Can We Get a Microscopic Picture of Yielding?
As already pointed out above in section “Charac-
terizing Yielding Through Spatially-Resolved
Dynamical Measurements,” macroscopic observ-
ables such as rheological data, although very
informative, do not tell us anything about the
microscopic events that govern yielding in colloi-
dal gels. Therefore, additional experimental tools
are needed to explore yielding at the cluster or
strand scales. To be able to anticipate failure, one
needs to identify precursors of yielding both for
reversible and irreversible yielding. Such precur-
sors are broadly deﬁned by Cipelletti et al. (2020)
as “any sharp variation of a parameter quantifying
the system structure or dynamics on length scales
of the order of, or slightly larger than, the relevant
length scale of the sample structure, [and that]
should be detectable well in advance of macro-
scopic failure.” A major step forward has been
achieved recently by Aime et al. (2018) in the
case of a gel of silica colloids that shows irrevers-
ible rupture. By coupling rheometry to small-
angle light scattering, it was shown that the min-
imum in the shear rate corresponds to a sudden
burst of plastic activity that is interpreted as the
proliferation of irreversible rearrangements most
probably consecutive to bond-breaking events.
This dynamic precursor irreversibly weakens the
network until it fully breaks.
Although
very
promising,
the
previous
dynamic light-scattering technique still fails to
provide detailed, spatially-resolved information
on the individual events that are responsible for
plastic activity. To access such information, direct
microscopic visualization must be performed. To
date, only a handful of studies have addressed this
question in colloidal gels. In particular, mono-
layers of attractive colloidal particles trapped at
an liquid–gas interface or at a liquid–liquid inter-
face have allowed one to image model two-
dimensional gels with video microscopy under
strain or stress and to study ﬂow-induced anisot-
ropy in the aggregated layer (Hoekstra et al. 2003;
Vermant and Solomon 2005). It was shown by
Masschaele et al. (2009, 2011) that yielding is
preceded by a cascade of bond-breaking events,
which number steadily increases up to a strain
g ~ 1. Dangling chains that are formed upon
breaking may either fold back to the backbone or
reconnect with other dangling ends. In the former
case, the backbone densiﬁes while connectivity is
restored in the latter case. For g > 1, global con-
nectivity is lost, and one is left with a more het-
erogeneous structure than that of the gel at rest,
with larger voids that coexist with more compact
clusters as illustrated in Fig. 9a.
In three-dimensional gels, confocal laser scan-
ning microscopy (CSLM) as emerged as a pow-
erful tool to study colloidal gels under ﬂow
(Prasad et al. 2007). Pioneering experiments by
Varadan and Solomon (2003) on thermoreversible
gels of silica colloids showed that squeeze ﬂow
induces voids
at moderate
volume
fraction
(f ¼ 0.26) and cracks at large volume fraction
(f ¼ 0.40). In both cases, the characteristic size,
i.e., void diameter or crack width, measured after
ﬂow cessation corresponded to about 10 particle
diameters. Subsequent studies by (Tolpekin et al.
2004; Conrad and Lewis 2008) used faster CSLM
to investigate the dynamic balance between
aggregation and breakup events in depletion-
induced gels of silica colloids under shear. More
recently, the microstructure of colloidal gels made
of poly(methyl-methacrylate) (PMMA) particles
was imaged after imposing high-rate step strains,
Nonlinear Mechanics of Colloidal Gels: Creep, Fatigue, and Shear-Induced Yielding
329

showing that bond-breaking events result from the
erosion of rigid clusters that persist far beyond
yielding and provide some degree of elasticity to
the ruptured gel (Hsiao et al. 2012).
In all these previous works, however, no time-
resolved information on yielding could be extra-
cted. To the best of our knowledge, the only time-
resolved studies of yielding in colloidal gels under
shear were performed by Rajaram and Mohraz
(2010, 2011). There, fast CSLM allowed the
authors to access the various stages of the shear-
induced microstructure in depletion-induced gels
of PMMA colloids. Although limited to a tempo-
ral resolution of a few seconds per confocal
image, these experiments revealed that after a
ﬁrst regime where the structure turns from isotro-
pic to oriented along the extensional component
of the ﬂow, yielding results from sporadic, local
rupture events that sometimes lead to the forma-
tion of chain-like segments that eventually merge
with the gel backbone as displayed in Fig. 9b. The
fully ruptured gel is constituted of dense, discon-
nected solid-like clusters that coexist with large
voids, which is qualitatively consistent with the
mesoscopic picture shown above in Fig. 6b for
carbon black gels (Gibaud et al. 2010, 2016; Perge
et al. 2014).
Finally, it appears that confocal microscopy
has only been applied so far to colloidal gels
that show reversible yielding. Exploring irre-
versible rupture in a time-resolved fashion at
the particle or strand scale constitutes one of
the major challenges for future research. Exper-
imental setups designed to apply a given shear
stress while imaging the structure, such as those
developed by Chan and Mohraz (2013), Dutta
et al. (2013), Aime et al. (2016), and Colombo
et al. (2019), seem very promising to address
this challenge, especially if coupled to a rhe-
ometer and if a spinning-disk confocal micro-
scope is used in order to achieve even higher
frame rates.
Nonlinear Mechanics of Colloidal Gels: Creep, Fatigue,
and
Shear-Induced
Yielding,
Fig.
9 Shear-rate-
induced rupture at the microscopic level. (a) Micros-
copy images of a two-dimensional colloidal gel composed
of 3.1 mm polystyrene particles adsorbed at an oil-water
interface with a surface fraction of 0.3. From left to right:
gel structure observed just after aggregation and during
steady-state ﬂows at _g ¼ 0:015 and 0.026 s1. Note that
particles have been reduced by about 20% in size for better
visualization. (Adapted from Masschaele et al. (2011) with
permission from the Royal Society of Chemistry.) (b)
Three-dimensional images reconstructed from a confocal
microscopy experiment of a gel composed of 1 mm
sterically-stabilized PMMA colloids at a volume fraction
of 0.035 in an index-matched solvent. Polymers where
added to the dispersion to mediate an attraction between
the colloids (depletion interactions) and form a gel. From
left to right: time sequence of a local rupture event indi-
cated by the arrow, which leads to the formation of two
distinct clusters highlighted by circles. The imposed shear
rate is _g ¼ 0:07 s1. The total duration of the sequence is
about 100 s. (Adapted from Rajaram and Mohraz (2010)
with permission from the Royal Society of Chemistry)
330
Nonlinear Mechanics of Colloidal Gels: Creep, Fatigue, and Shear-Induced Yielding

Summary and Conclusion
Long-term goals in the study of yielding in col-
loidal gels are multiple. One of them consists in
classifying the rupture processes in relation with
the properties of the gels. This “zoologist”
approach is all the more complex that the features
of colloidal gels depend on a myriad of parameters
such as the interaction potential, the particle con-
centration, or the pathway taken to form the gel.
Thus one issue is to determine the minimal level
of description of the colloidal gels necessary to
capture the yielding scenario. Here, we have
described the current state of understanding of
the nonlinear mechanical response of colloidal
gels starting from experimental observations on
two different systems that highlight the typical
features of reversible ﬂuidization and irreversible
rupture. While carbon black gels display revers-
ible ﬂuidization preceded by strain softening and
characterized by an exponential stress dependence
of the yielding times, sodium caseinate gels show
brittle rupture preceded by strain stiffening and
failure times that depend on the load as power
laws. Such a clear-cut distinction in the yielding
behaviors prompts us to rationalize the nonlinear
mechanics of colloidal gels based on their struc-
ture, in particular on their intermediate structures.
Such an idea is supported by the fact that carbon
black gels and sodium caseinate gels respectively
display cluster- versus strand-based structures.
This coarse-grained approach at the network
level has the advantage to drastically diminish
the number of parameters necessary to classify
rupture, restricting it to cluster or strand proper-
ties, such as their size and their fractal dimension.
In particular, it disregards the inﬂuence of param-
eters such as the colloid interactions, the colloid
concentration and the gelation pathway. This
could greatly simplify our understanding of rup-
ture and set a simple basis for future theoretical
and simulation work.
A more reﬁned coarse-grained approach would
consist in focusing on the particles. Such a “col-
loid physicist” approach has been followed in the
early and current literature on colloid and protein
dispersions and has allowed one to make fairly
precise predictions about the phase behavior and
the static properties of such particles under well-
deﬁned solution compositions (Cardinaux et al.
2007; Gibaud and Schurtenberger 2009). Coarse-
grained approaches at the particle level are, how-
ever, far from providing a complete description of
the complexity of colloidal gels. Colloidal particles
are indeed rarely perfect spheres; their interaction
potentials are, in general, not isotropic and do not
necessarily remain invariant as a function of pH,
temperature, or concentration. For instance, carbon
black particles are fractal aggregates that may pen-
etrate one another at high concentrations. Sodium
caseinate colloids have complex shape- and
pH-dependent interactions that provide an original
way to form gels starting from a ﬂuid dispersion at
equilibrium. Natural rubber latex gels, although
very similar to standard latex particle gels, show
unprecedented strain stiffening, which link with the
reorganization of the microscopic network struc-
ture remains to be uncovered. Such spectacular
properties, which make colloidal gels all the more
versatile, are difﬁcult to model and call for more
reﬁned approaches than simple coarse-graining,
including complementary modeling based on poly-
mer or macromolecular approaches. The limits of
simple colloidal descriptions have been recently
discussed
in
the
case
of
globular
proteins
(Sarangapani
et
al.
2015;
Stradner
and
Schurtenberger 2020). Similarly, disentangling
the inﬂuence of colloid physics from the polymer
or macromolecular aspects of the particle on the
rupture properties of colloidal gels remains an open
challenge and could be of great help to ﬁne-tune the
gel rupture behavior.
Therefore, beyond classifying yielding pro-
cesses in colloidal gels, controlling and/or pre-
dicting
their
rupture
appears
as
a
major
challenge for future work. There again, the ade-
quate level of description is crucial. While meso-
scopic
measurements
may
help
interpret
macroscopic
mechanical
observations,
direct
visualization at the scale of individual strands or
particles is essential to assess rupture precursors
and localized events during yielding. We also
emphasize that the discussions in this chapter
may apply to a larger range of materials than just
colloidal gels. Indeed, some features of shear-
induced yielding reported here for colloidal gels
Nonlinear Mechanics of Colloidal Gels: Creep, Fatigue, and Shear-Induced Yielding
331

share a number of similarities with the rupture of
polymer gels (Skrzeszewska et al. 2010; Tabuteau
et al. 2009; Mora 2011; Erk et al. 2012; Thornell
et al. 2014), elastomers (Ducrot et al. 2014), or
hydrogels (Karobi et al. 2016; Bai et al. 2019),
i.e., three-dimensional networks composed of
macromolecules that are chemically or physically
cross-linked. This suggests that either some spe-
ciﬁc details of the particle are irrelevant or that the
ambivalent properties of the particles, half-way
between colloids and polymer or macromole-
cules, are at the origin of this analogy. In any
case, much work is still required before gel micro-
structures, nonlinear viscoelastic responses, and
yielding
scenarios
are
fully
connected
and
explained. Such a research effort will help to
design and optimize soft materials where yielding
is fully part of the application, e.g., in food prod-
ucts or 3D printing, or where it should rather be
avoided.
Bibliography
Adam M, Delsanti M, Munch JP, Durand D (1988)
Dynamical studies of polymeric cluster solutions
obtained near the gelation threshold: glasslike behavior.
Phys Rev Lett 61:706–709
Aguilera JM, Park DJ (2016) Texture-modiﬁed foods for
the elderly: status, technology and opportunities.
Trends Food Sci Technol 57:156–164
Aime S, Ramos L, Fromental J-M, Prevot G, Jelinek R,
Cipelletti L (2016) A stress-controlled shear cell for
small-angle light scattering and microscopy. Rev Sci
Instrum 87(12):123907
Aime S, Ramos L, Cipelletti L (2018) Microscopic dynam-
ics and failure precursors of a gel under mechanical
load. Proc Natl Acad Sci U S A 115:3587–3592
Alava MJ, Nukala PKVV, Zapperi S (2006) Statistical
models of fracture. Adv Phys 55(3–4):349–476
Andrade ENdaC (1910) The viscous ﬂow in metals, and
allied phenomena. Proc R Soc London A 84(1):1–12
Arevalo RC, Kumar P, Urbach JS, Blair DL (2015) Stress
heterogeneities in sheared type-i collagen networks
revealed by boundary stress microscopy. PLoS One
10:1–12
Assink RA, Kay BD (1991) Study of sol-gel chemical
reaction kinetics by NMR. Annu Rev Mater Sci
21:491–513
Bai R, Yang J, Suo Z (2019) Fatigue of hydrogels. Eur
J Mech A Solids 74:337–370
Bailey J (1939) An attempt to correlate some tensile
strength
measurements
on
glass:
III.
Glass
Ind
20:95–99
Balmforth N, Frigaard I, Ovarlez G (2014) Yielding to
stress:
recent
developments
in
viscoplastic
ﬂuid
mechanics. Annu Rev Fluid Mech 46:121–146
Basquin OH (1910) The exponential law of endurance
tests. Proc Am Soc Test Mater ASTEA 10:625–630
Bird RB, Armstrong RC, Hassager O (1987) Dynamics of
polymeric
liquids.
Cambridge
University
Press,
New York
Bonn D, Rodts S, Groenink S, Rafaï NS-B, Coussot
P (2008) Some applications of magnetic resonance
imaging in ﬂuid mechanics: complex ﬂows and com-
plex ﬂuids. Annu Rev Fluid Mech 40:209–233
Bonn D, Denn MM, Berthier L, Divoux T, Manneville
S (2017) Yield stress materials in soft condensed mat-
ter. Rev Mod Phys 89:035005
Bouzid M, Del Gado E (2017) Network topology in soft
gels: hardening and softening materials. Langmuir
34(3):773–781
Braga ALM, Menossi M, Cunha RL (2006) The effect of
the
glucono-d-lactone/caseinate
ratio
on
sodium
caseinate gelation. Int Dairy J 16:389–398
Bremer LGB, Bijsterbosch BH, Schrijvers R, van Vliet T,
Walstra P (1990) On the fractal nature of the structure
of acid casein gels. Colloids Surf 51:159–170
Brenner T, Matsukawa S, Nishinari K, Johannsson
R (2013) Failure in a soft gel: delayed failure and the
dynamic yield stress. J Non-Newtonian Fluid Mech
196:1–7
Buzzaccaro S, Rusconi R, Piazza R (2007) “Sticky” hard
spheres: equation of state, phase diagram, and metasta-
ble gels. Phys Rev Lett 99(9):098301
Cardinaux F, Gibaud T, Stradner A, Schurtenberger
P (2007) Interplay between spinodal decomposition
and glass formation in proteins exhibiting short-range
attractions. Phys Rev Lett 99:118301
Chan H, Mohraz A (2013) A simple shear cell for the direct
visualization of step-stress deformation in soft mate-
rials. Rheol Acta 52:383–394
Cipelletti L, Martens K, Ramos L (2020) Microscopic
precursors of failure in soft matter. Soft Matter
16(1):82–93
Colombo G, Kim S, Schweizer T, Schroyen B, Clasen C,
Mewis J, Vermant J (2017) Superposition rheology and
anisotropy in rheological properties of sheared colloi-
dal gels. J Rheol 61(5):1035–1048
Colombo G, Massaro R, Coleman S, Läuger J, Van
Puyvelde P, Vermant J (2019) Ultrafast imaging of
soft materials during shear ﬂow. Korea-Aust Rheol
J 31(4):229–240
Conrad JC, Lewis JA (2008) Structure of colloidal gels
during microchannel ﬂow. Langmuir 24:7628–7634
Coskun AEI, Sağlam D, Venema P, van der Linden E,
Scholten E (2015) Preparation, structure and stability
of sodium caseinate and gelatin micro-particles. Food
Hydrocoll 45:291–300
Da Vela S, Braun MK, Dörr A, Greco A, Möller J, Fu Z,
Zhang F, Schreiber F (2016) Kinetics of liquid–liquid
phase separation in protein solutions exhibiting lcst
phase behavior studied by time-resolved usaxs and
vsans. Soft Matter 12(46):9334–9341
332
Nonlinear Mechanics of Colloidal Gels: Creep, Fatigue, and Shear-Induced Yielding

de Oliveira Reis G, Menut P, Bonﬁls F, Vaysse L, Hemar Y,
Sanchez C (2015) Acid-induced aggregation and gela-
tion of natural rubber latex particles. Colloids Surf
A Physicochem Eng Asp 482:9–17
de
Oliveira
Reis
G,
Gibaud
T,
Saint-Michel
B,
Manneville S, Leocmach M, Vaysse L, Bonﬁls F,
Sanchez C, Menut P (2019) Irreversible hardening of a
colloidal gel under shear: the smart response of natural
rubber latex gels. J Colloid Interface Sci 539:287–296
Derks D, Wisman H, van Blaaderen A, Imhof A (2004)
Confocal microscopy of colloidal dispersions in shear
ﬂow using a counter-rotating cone-plate shear cell.
J Phys Condens Matter 16(38):S3917–S3927
Dibble CJ, Kogan M, Solomon MJ (2006) Structure and
dynamics of colloidal depletion gels: coincidence of
transitions and heterogeneity. Phys Rev E 74:041403
Dimitriou C, Ewoldt R, McKinley G (2013) Describing
and prescribing the constitutive response of yield stress
ﬂuids using large amplitude oscillatory shear stress
(LAOStress). J Rheol 57:27–70
Dixon TH, Jiang Y, Malservisi R, McCaffrey R, Voss N,
Protti M, Gonzalez V (2014) Earthquake and tsunami
forecasts: relation of slow slip events to subsequent
earthquake
rupture.
Proc
Natl
Acad
Sci
111(48):17039–17044
Donnet J-B, Bansal RC, Wang M-J (1993) Carbon black:
science and technology. Marcel Dekker, New York
Ducrot E, Chen Y, Bulters M, Sijbesma RP, Creton
C (2014) Toughening elastomers with sacriﬁcial
bonds
and
watching
them
break.
Science
344(6180):186–189
Duri A, Bissig H, Trappe V, Cipelletti L (2005) Time-
resolved-correlation measurements of temporally het-
erogeneous dynamics. Phys Rev E 72:051401
Dutta S, Mbi A, Arevalo RC, Blair DL (2013) Develop-
ment of a confocal rheometer for soft and biological
materials. Rev Sci Instrum 84(6):063702
Eberle AP, Porcar L (2012) Flow-sans and rheo-sans
applied to soft matter. Curr Opin Colloid Interface Sci
17(1):33–43
Edera P, Bergamini D, Trappe V, Giavazzi F, Cerbino
R (2017) Differential dynamic microscopy micro-
rheology of soft materials: a tracking-free determina-
tion of the frequency-dependent loss and storage
moduli. Phys Rev Mater 1:073804
Ehrburger-Dolle F, Misono S, Lahaye J (1990) Character-
ization of the aggregate void structure of carbon blacks
by
thermoporometry.
J
Colloid
Interface
Sci
135(2):468–485
Eirich F, Smith TL (1972) Molecular mechanical aspects of
the isothermal rupture of elastomers. In: Liebowitz
H (ed) Fracture of nonmetals and composites. Aca-
demic, New York, pp 351–609
Erk KA, Martin JD, Hu YT, Shull KR (2012) Extreme
strain localization and sliding friction in physically
associating polymer gels. Langmuir 28(9):4472–4478
Eshbach OW, Tapley BD (1990) Eshbach’s handbook of
engineering fundamentals. Wiley, New York
Ewoldt RH, Hosoi AE, McKinley GH (2008) New mea-
sures for characterizing nonlinear viscoelasticity in
large
amplitude
oscillatory
shear.
J
Rheol
52:1427–1458
Fan FY, Woodford WH, Li Z, Baram N, Smith KC, Helal A,
McKinley GH, Carter WC, Chiang Y-M (2014) Polysul-
ﬁde ﬂow batteries enabled by percolating nanoscale
conductor networks. Nano Lett 14(4):2210–2218
FofﬁG, De Michele C, Sciortino F, Tartaglia P (2005)
Arrested phase separation in a short-ranged attractive
colloidal system: a numerical study. J Chem Phys
122(22):224903
Fox P (2003) Milk proteins: general and historical aspects.
In: Advanced dairy chemistry – 1 proteins. Springer,
New York, pp 1–48
Freed AD, Leonov AI (2002) The Bailey criterion: statis-
tical derivation and applications to interpretations of
durability tests and chemical kinetics. Z Angew Math
Phys 53:160–166
Gallot T, Perge C, Grenard V, Fardin M-A, Taberlet N,
Manneville S (2013) Ultrafast ultrasonic imaging
coupled to rheometry: principle and illustration. Rev
Sci Instrum 84:045107
Gao Y, Kim J, Helgeson ME (2015) Microdynamics and
arrest of coarsening during spinodal decomposition in
thermoreversible
colloidal
gels.
Soft
Matter
11(32):6360–6370
Gardel M, Shin JH, MacKintosh F, Mahadevan L,
Matsudaira P, Weitz D (2004) Elastic behavior of
cross-linked and bundled actin networks. Science
304(5675):1301–1305
Gibaud T, Schurtenberger P (2009) A closer look at
arrested spinodal decomposition in protein solutions.
J Phys Condens Matter 21(32):322201
Gibaud T, Frelat D, Manneville S (2010) Heterogeneous
yielding dynamics in a colloidal gel. Soft Matter
6:3482–3488
Gibaud T, Mahmoudi N, Oberdisse J, Lindner P, Pedersen
JS, Oliveira CL, Stradner A, Schurtenberger P (2012)
New routes to food gels and glasses. Faraday Discuss
158(1):267–284
Gibaud T, Perge C, Lindströfm SB, Taberlet N, Manneville
S (2016) Multiple yielding processes in a colloidal gel
under large amplitude oscillatory stress. Soft Matter
12:1701–1712
Gibaud T, Dagès N, Lidon P, Jung G, Ahouré LC,
Sztucki M, Poulesquen A, Hengl N, Pignon F,
Manneville
S
(2020)
Rheoacoustic
gels:
tuning
mechanical and ﬂow properties of colloidal gels with
ultrasonic vibrations. Phys Rev X 10:011028
Gisler T, Weitz DA (1999) Scaling of the microrheology of
semidilute
f-actin
solutions.
Phys
Rev
Lett
82:1606–1609
Gopalakrishnan V, Zukoski C (2007) Delayed ﬂow in
thermoreversible colloidal gels. J Rheol 51:623–644
Gosal WS, Ross-Murphy SB (2000) Globular protein gela-
tion. Curr Opin Colloid Interface Sci 5(3–4):188–194
Grenard V, Divoux T, Taberlet N, Manneville S (2014)
Timescales in creep and yielding of attractive gels.
Soft Matter 10:1555–1571
HadjSadok A, Pitkowski A, Nicolai T, Benyahia L,
Moulai-Mostefa N (2008) Characterisation of sodium
Nonlinear Mechanics of Colloidal Gels: Creep, Fatigue, and Shear-Induced Yielding
333

caseinate as a function of ionic strength, ph and tem-
perature using static and dynamic light scattering. Food
Hydrocoll 22(8):1460–1466
Hartley PA, Parﬁtt GD (1985) Dispersion of powders in
liquids. 1. The contribution of the van der Waals force
to the cohesiveness of carbon black powders. Langmuir
1:651–657
Helal A, Divoux T, McKinley GH (2016) Simultaneous
rheo-electric measurements of strongly conductive
complex ﬂuids. Phys Rev Appl 6:064004
Hipp JB, Richards JJ, Wagner NJW (2019) Structure-
property relationships of sheared carbon black suspen-
sions determined by simultaneous rheological and neu-
tron scattering measurements. J Rheol 63:423–436
Hirschberg V, Wilhelm M, Rodrigue D (2017) Fatigue
behavior of polystyrene (ps) analyzed from the fourier
transform (ft) of stress response: ﬁrst evidence of i2/1
(n) and i3/1 (n) as new ﬁngerprints. Polym Test
60:343–350
Hoekstra H, Vermant J, Mewis J, Fuller G (2003) Flow-
induced anisotropy and reversible aggregation in two-
dimensional
suspensions.
Langmuir
19(22):9134–9141
Hsiao LC, Newman RS, Glotzer SC, Solomon MJ
(2012) Role of isostaticity and load-bearing microstruc-
ture in the elasticity of yielded colloidal gels. Proc Natl
Acad Sci 109(40):16029–16034
Hyun K, Wilhelm M, Klein C, Cho K, Nam J, Ahn K,
Lee S, Ewoldt R, McKinley G (2011) A review of
nonlinear oscillatory shear tests: analysis and applica-
tion of large amplitude oscillatory shear (LAOS). Prog
Polym Sci 36:1697–1753
Ioannidou K, Kanduc M, Li L, Frenkel D, Dobnikar J,
Gado ED (2016) The crucial effect of early-stage gela-
tion on the mechanical properties of cement hydrates.
Nat Commun 7:12106
Jagla EA (2011) Creep rupture of materials: insights from a
ﬁber
bundle
model
with
relaxation.
Phys
Rev
E 83:046119
Jamali S, Armstrong RC, McKinley GH (2020) Time-rate-
transformation framework for targeted assembly of
short-range attractive colloidal suspensions. Mater
Today Adv 5:100026
Jetlema M, Beckley J, Vahalik J (2016) Food texture
assessment and preference based on mouth behavior.
Food Qual Prefer 52:160–171
Karobi SN, Sun TL, Kurokawa T, Luo F, Nakajima T,
Nonoyama T, Gong JP (2016) Creep behavior and
delayed fracture of tough polyampholyte hydrogels by
tensile test. Macromolecules 49(15):5630–5636
Keshavarz B, Divoux T, Manneville S, McKinley GH
(2017) Nonlinear viscoelasticity and generalized fail-
ure criterion for biopolymer gels. ACS Macro Lett
6:663–667
Kim J, Merger D, Wilhelm M, Helgeson ME (2014) Micro-
structure and nonlinear signatures of yielding in a het-
erogeneous
colloidal
gel
under
large
amplitude
oscillatory shear. J Rheol 58(5):1359–1390
Kohout J (2000) Temperature dependence of stress–life-
time fatigue curves. Fatigue Fract Eng Mater Struct
23:969–977
Koivisto J, Ovaska M, Miksic A, Laurson L, Alava MJ
(2016) Predicting sample lifetimes in creep fracture of
heterogeneous materials. Phys Rev E 94:023002
Koumakis N, Petekidis G (2011) Two step yielding in
attractive colloids: transition from gels to attractive
glasses. Soft Matter 7:2456–2470
Koumakis N, Moghimi E, Besseling R, Poon W, Brady JF,
Petekidis G (2015) Tuning colloidal gels by shear. Soft
Matter 11:4640–4648
Krall A, Weitz D (1998) Internal dynamics and elasticity of
fractal colloidal gels. Phys Rev Lett 80(4):778
Kroon M, Wegdam GH, Sprik R (1996) Dynamic light
scattering studies on the sol-gel transition of a suspen-
sion of anisotropic colloidal particles. Phys Rev
E 54:6541–6550
Kun F, Carmona HA, Andrade JS Jr, Herrmann HJ
(2008) Universality behind Basquin’s law of fatigue.
Phys Rev Lett 100:094301
Larsen TH, Furst EM (2008) Microrheology of the liquid-
solid
transition
during
gelation.
Phys
Rev
Lett
100:146001
Larson RG (1999) The structure and rheology of complex
ﬂuids. Oxford University Press, New York
Laurson L, Rosti J, Koivisto J, Miksic A, Alava MJ
(2011) Spatial ﬂuctuations in transient creep deforma-
tion. J Stat Mech: Theory Exp 2011(07):P07002
Leocmach M, Perge C, Divoux T, Manneville S (2014)
Creep and fracture of a protein gel under stress. Phys
Rev Lett 113:038303
Leocmach M, Nespoulous M, Manneville S, Gibaud
T (2015) Hierarchical wrinkling in a conﬁned perme-
able biogel. Sci Adv 1:e1500608
Lewis JA (2002) Direct-write assembly of ceramics from
colloidal inks. Curr Opinion Solid State Mater Sci
6(3):245–250
Lindström
SB,
Kodger
TE,
Sprakel
J,
Weitz
DA
(2012) Structures, stresses, and ﬂuctuations in the
delayed
failure
of
colloidal
gels.
Soft
Matter
8:3657–3664
Lootens D, Hébraud P, Lécolier E, Van Damme H (2004)
Gelation, shearthinning and shear-thickening in cement
slurries. Oil Gas Sci Technol 59(1):31–40
Lu PJ, Zaccarelli E, Ciulla F, Schoﬁeld AB, Sciortino F,
Weitz DA (2008) Gelation of particles with short-range
attraction. Nature 453(7194):499–503
Macosko C (1994) Rheology. Principles, measurements,
and applications. Wiley-VCH, New York
Malkin AY, Petrie CJS (1997) Some conditions for rupture
of polymer liquids in extension. J Rheol 41:1–25
Manneville S, Bécu L, Colin A (2004) High-frequency
ultrasonic speckle velocimetry in sheared complex
ﬂuids. Eur Phys J AP 28:361–373
Masschaele K, Fransaer J, Vermant J (2009) Direct visual-
ization of yielding in model two-dimensional colloidal
gels subjected to shear ﬂow. J Rheol 53(6):1437–1460
334
Nonlinear Mechanics of Colloidal Gels: Creep, Fatigue, and Shear-Induced Yielding

Masschaele K, Fransaer J, Vermant J (2011) Flow-induced
structure in colloidal gels: direct visualization of model
2d suspensions. Soft Matter 7(17):7717–7726
Mewis J, Wagner NJ (2012) Colloidal suspension rheol-
ogy. Cambridge University Press, Cambridge, UK
Mezzenga R, Fischer P (2013) The self-assembly, aggre-
gation and phase transitions of food protein systems in
one, two and three dimensions. Rep Prog Phys
76(4):046601
Miguel M-C, Vespignani A, Zaiser M, Zapperi S (2002)
Dislocation jamming and Andrade creep. Phys Rev
Lett 89:165501
Miguel M-C, Laurson L, Alava MJ (2008) Material yield-
ing and irreversible deformation mediated by disloca-
tion motion. Eur Phys J B 64:443–450
Mohraz A, Solomon M (2005) Orientation and rupture of
fractal colloidal gels during start-up of steady shear
ﬂow. J Rheol 49:657–681
Monkman FC, Grant NJ (1956) An empirical relationship
between rupture life and minimum creep rate in creep-
rupture tests. Proc Am Soc Test Mater 56:593–605
Mora S (2011) The kinetic approach to fracture in transient
networks. Soft Matter 7:4908–4917
Narayanan A, Mugele F, Duits MHG (2017) Mechanical
history dependence in carbon black suspensions for
ﬂow batteries: a rheo-impedance study. Langmuir
33(7):1629–1638
Nechad H, Helmstetter A, El Guerjouma R, Sornette
D (2005) Creep ruptures in heterogeneous materials.
Phys Rev Lett 94:045501
Negi A, Osuji C (2009) New insights on fumed colloidal
rheology-shear thickening and vorticity-aligned struc-
tures in ﬂocculating dispersions. Rheol Acta 48:871–881
Nicolai T, Durand D (2013) Controlled food protein aggre-
gation for new functionality. Curr Opin Colloid Inter-
face Sci 18(4):249–256
Osuji CO, Kim C, Weitz DA (2008) Shear thickening and
scaling of the elastic modulus in a fractal colloidal system
with attractive interactions. Phys Rev E 77:060402(R)
Ovarlez G, Tocquer L, Bertrand F, Coussot P (2013)
Rheopexy and tunable yield stress of carbon black
suspensions. Soft Matter 9:5540–5549
Perge C, Taberlet N, Gibaud T, Manneville S (2014) Time
dependence in large amplitude oscillatory shear: a rheo-
ultrasonic study of fatigue dynamics in a colloidal gel.
J Rheol 58:1331–1357
Pignon F, Magnin A, Piau J-M (1997) Butterﬂy light scat-
tering pattern and rheology of a sheared thixotropic
clay gel. Phys Rev Lett 79:4689–4692
Pouzot M, Nicolai T, Benyahia L, Durand D (2006) Strain
hardening and fracture of heat-set fractal globular pro-
tein gels. J Colloid Interface Sci 293:376–383
Prasad V, Semwogerere D, Weeks ER (2007) Confocal
microscopy of colloids. J Phys Condens Matter
19:113102
Rajaram B, Mohraz A (2010) Microstructural response of
dilute colloidal gels to nonlinear shear deformation.
Soft Matter 6:2246–2259
Rajaram B, Mohraz A (2011) Dynamics of shear-induced
yielding and ﬂow in dilute colloidal gels. Phys Rev
E 84(1):011405
Ramakrishnan
S,
Gopalakrishnan
V,
Zukoski
CF
(2005) Clustering and mechanics in dense depletion
and thermal gels. Lang Des 21:9917–9925
Richards JJ, Hipp JB, Riley JK, Wagner NJ, Butler PD
(2017) Clustering and percolation in suspensions of
carbon black. Langmuir 33:12260–12266
Romer S, Scheffold F, Schurtenberger P (2000) Sol-gel
transition of concentrated colloidal suspensions. Phys
Rev Lett 85:4980–4983
Rosti J, Koivisto J, Laurson L, Alava MJ (2010) Fluctua-
tions and scaling in creep deformation. Phys Rev Lett
105:100601
Saint-Michel B, Gibaud T, Leocmach M, Manneville
S (2016) Local oscillatory rheology from echography.
Phys Rev Appl 5:034014
Saint-Michel B, Gibaud T, Manneville S (2017) Predicting
and assessing rupture in protein gels under oscillatory
shear. Soft Matter 13:2643–2653
Sarangapani PS, Hudson SD, Jones RL, Douglas JF,
Pathak JA (2015) Critical examination of the colloidal
particle
model
of
globular
proteins.
Biophys
J 108(3):724–737
Schmoller KM, Bausch AR (2013) Similar nonlinear
mechanical responses in hard and soft materials. Nat
Mater 12:278–281
Schmoller KM, Fernández P, Arevalo RC, Blair DL,
Bausch AR (2010) Cyclic hardening in bundled actin
networks. Nat Commun 1(134):1–7
Shih W-H, Shih WY, Kim S-I, Liu J, Aksay IA (1990) Scal-
ing behavior of the elastic properties of colloidal gels.
Phys Rev A 42(8):4772
Skrzeszewska P, Sprakel J, de Wolf F, Fokkink R, Stuart
MC, van der Gucht J (2010) Fracture and self-healing
in a well-deﬁned self-assembled polymer network.
Macromolecules 43:3542–3548
Smay JE, Cesarano J, Lewis JA (2002) Colloidal inks for
directed assembly of 3-d periodic structures. Langmuir
18(14):5429–5437
Sornette D (2002) Predictability of catastrophic events:
material rupture, earthquakes, turbulence, ﬁnancial
crashes, and human birth. Proc Natl Acad Sci
99(Suppl 1):2522–2529
Sprakel J, Lindström S, Kodger T, Weitz D (2011) Stress
enhancement in the delayed yielding of colloidal gels.
Phys Rev Lett 106:248303
Storm C, Pastore JJ, MacKintosh FC, Lubensky TC,
Janmey PA (2005) Nonlinear elasticity in biological
gels. Nature 435(7039):191–194
Stradner A, Schurtenberger P (2020) Potential and limits of
a colloid approach to protein solutions. Soft Matter
16(2):307–323
Sundararajan G (1989) The Monkman-Grant relationship.
Mater Sci Eng A 112:205–214
Sung SH, Kim S, Hendricks J, Clasen C, Ahn KH
(2018)
Orthogonal
superposition
rheometry
of
Nonlinear Mechanics of Colloidal Gels: Creep, Fatigue, and Shear-Induced Yielding
335

colloidal gels: time-shear rate superposition. Soft Mat-
ter 14:8651–8659
Tabuteau H, Mora S, Porte G, Abkarian M, Ligoure
C (2009) Microscopic mechanisms of the brittleness
of viscoelastic ﬂuids. Phys Rev Lett 102:155501
Tan ATL, Beroz J, Kolle M, Hart AJ (2018) Direct-write
freeform
colloidal
assembly.
Adv
Mater
30(44):1803620
Thornell TL, Helfrecht BA, Mullen SA, Bawiskar A, Erk
KA (2014) Fracture-healing kinetics of thermoreversible
physical gels quantiﬁed by shear rheophysical experi-
ments. ACS Macro Lett 3(10):1069–1073
Tolpekin V, Duits MH, Van den Ende D, Mellema J (2004)
Aggregation and breakup of colloidal particle aggre-
gates in shear ﬂow, studied with video microscopy.
Langmuir 20(7):2614–2627
Trappe V, Sandkühler P (2004) Colloidal gels – low-
density disordered solid-like states. Curr Opin Colloid
Interface Sci 8(6):494–500
Trappe V, Weitz DA (2000) Scaling of the viscoelasticity of
weakly attractive particles. Phys Rev Lett 85:449–452
Trappe V, Pitard E, Ramos L, Robert A, Bissig H, Cipelletti
L (2007) Investigation of q-dependent dynamical het-
erogeneity in a colloidal gel by X-ray photon correla-
tion spectroscopy. Phys Rev E 76:051404
van der Zwaag S (1989) The concept of ﬁlament strength
and the weibull modulus. J Test Eval 17(5):292–298
van Doorn JM, Verweij JE, Sprakel J, van der Gucht
J (2018) Strand plasticity governs fatigue in colloidal
gels. Phys Rev Lett 120:208005
van Vliet T, Walstra P (1995) Large deformation and frac-
ture behaviour of gels. Faraday Discuss 101:359–370
Varadan P, Solomon M (2001) Shear-induced microstruc-
tural evolution of a thermoreversible colloidal gel.
Langmuir 17:2918–2929
Varadan P, Solomon MJ (2003) Direct visualization of
ﬂow-induced microstructure in dense colloidal gels by
confocal
laser
scanning
microscopy.
J
Rheol
47(4):943–968
Verduin H, De Gans B, Dhont J (1996) Shear induced
structural changes in a gel-forming suspension studied
by
light
scattering
and
rheology.
Langmuir
12(12):2947–2955
Vermant J, Solomon MJ (2005) Flow-induced structure in
colloidal suspensions. J Phys: Condens Matter 17:
R187–R216
Voight B (1989) A relation to describe rate-dependent
material failure. Science 243(4888):200–203
Wagner CE, Barbati AC, Engmann J, Burbidge AS,
McKinley G (2017) Quantifying the consistency and
rheology of liquid foods using fractional calculus. Food
Hydrocoll 69:242–254
Wilhelm C, Elias F, Browaeys J, Ponton A, Bacri J-C
(2002) Local rheological probes for complex ﬂuids:
application
to
laponite
suspensions.
Phys
Rev
E 66:021502
Youssry
M,
Madec
L,
Soudan
P,
Cerbelaud
M,
Guyomard D, Lestriez B (2013) Non-aqueous carbon
black suspensions for lithium-based redox ﬂow batte-
ries: rheology and simultaneous rheo-electrical behav-
ior. Phys Chem Chem Phys 15(34):14476–14486
Zaccarelli E (2007) Colloidal gels: equilibrium and non-
equilibrium
routes.
J
Phys
Condens
Matter
19(32):323101
336
Nonlinear Mechanics of Colloidal Gels: Creep, Fatigue, and Shear-Induced Yielding

Statistical Physics of the
Yielding Transition
Kirsten Martens
Université Grenoble Alpes, CNRS, LIPhy,
Grenoble, France
Article Outline
Glossary
Introduction
Conclusion and Outlook
Bibliography
Glossary
Yielding transition Dense disordered materials
undergo, just like crystalline materials, a yield-
ing transition under large deformation protocols.
After the ﬁrst elastic response, these systems
accumulate
irreversible
plastic
deformation
until they either fracture (hard glassy materials)
or ﬂow (yield stress ﬂuids), depending on the
material properties and preparation.
Local shear transformations Local structural
changes that dissipate energy play a similar
role for the deformation process in amorphous
materials as defects in crystals. The globally
accumulated plasticity can be divided in the
occurrence
of
many
such
local
shear
transformations.
Elastic interactions The on average elastic sur-
rounding medium reacts to local shear transfor-
mations with an elastic response to the locally
deformed part. This elastic response is long
range and can trigger other events to occur.
Mesoscopic
scale
for
elastoplastic
descriptions Beyond the microscopic scale
corresponding to the scale of the constituents
of the material (atoms, molecules, bubbles, and
grains) and the macroscopic scale for which
continuum models can be developed, a meso-
scopic scale can be deﬁned as the scale
corresponding to the typical inclusion size of
the shear transformations. Beyond this scale,
the elastic response of the surrounding material
becomes scale free.
Avalanche dynamics In the slow driving limit,
the local shear transformations organize into
strongly correlated domains and the dynam-
ics becomes strongly intermittent. Energy
release and duration of these correlated
events follow a power law behavior, similar
to what is observed in earthquakes (Guten-
berg Richter law). The scaling properties
point
toward
the
existence
of
out-of-
equilibrium critical transitions in the frame-
work of yielding.
Out-of-equilibrium phase transitions This is
an analogue to the well-studied equilibrium
phase transitions. One observes scale-free
behavior for the relevant dynamically deﬁned
observables, and in analogy to equilibrium
critical phenomena one can try to ﬁnd generic
behaviors close to criticality for classes of sys-
tems and scaling relations between the various
exponents. However, one has to note that some
analogies do not apply, because these systems
are typically far from equilibrium and exhibit
apart from the obvious ﬂuxes of mass also
ﬂuxes in energy. In the case of deformed amor-
phous
materials,
energy
is
continuously
injected in the system to perform the deforma-
tion protocol and the energy is dissipated on
small scales. Even the limit of small deforma-
tion rates will still yield dynamics far from
equilibrium, and novel out-of-equilibrium sta-
tistical theories and methods apply.
Transient dynamics In the early deformation
stages, one can trace the stress response to an
imposed deformation (stress-strain curve) or
the deformation response in time to an imposed
sudden step stress (creep curve).
Steady state dynamics In the long time limit, the
probability distribution for the relevant observ-
ables, such as local mesoscopic stresses,
© Springer Science+Business Media, LLC, part of Springer Nature 2022
B. Chakraborty (ed.), Statistical and Nonlinear Physics,
https://doi.org/10.1007/978-1-0716-1454-9_740
Originally published in
R. A. Meyers (ed.), Encyclopedia of Complexity and Systems Science, © Springer Science+Business Media LLC 2022
https://doi.org/10.1007/978-3-642-27737-5_740-1
337

becomes stationary and the dynamics becomes
time-translational invariant.
Flow curve For yield stress ﬂuids, one can estab-
lish a ﬂow curve given by the steady state
average stress value for a given deformation
rate, or the average deformation rate in the long
time limit for a given imposed stress.
Shear localization When local shear transfor-
mations
organize
spatially
into
strongly
deformed regions, this can be identiﬁed as
shear localization. This can take the form of
slip lines that can be characterized by dynam-
ical heterogeneities and live on relatively short
timescales. During the transient dynamics,
shear localization can occur in form of tran-
sient shear bands. Shear localization can also
be observed as a steady state feature for intrin-
sically unstable ﬂows; this typically occurs
when the local shear transformations lead to a
local weakening of the material.
Introduction
Amorphous materials under deformation, such as
hard glassy materials soft and granular matter like
emulsions, foams, colloidal suspensions, or large-
scale granular materials, exhibit a wide spectrum
of nontrivial phenomena that not only elicit fun-
damental questions, but also bring about various
practical challenges (Rodney et al. 2011; Bonn
et al. 2017; Nicolas et al. 2018; Cipelletti et al.
2020). One of the major goals, in this context, is to
develop a unique theoretical framework for tran-
sient phenomena like stress overshoots prior to
yielding, e.g., in metallic glasses (Kawamura
et al. 1999; Lu et al. 2003; Maaß et al. 2012) and
soft materials (Amann et al. 2013; Divoux et al.
2011; Dzuy and Boger 1983; Rogers et al. 2010;
Zausch et al. 2008; Sentjabrskaja et al. 2014;
Koumakis et al. 2012a, b), delayed failure in
creep
experiments
(Cipelletti
et
al.
2020;
Chaudhuri and Horbach 2013; Sentjabrskaja
et al. 2015), together with steady state properties
for soft glassy materials, such as strongly non-
linear ﬂow curves (Agoritsas and Martens 2017).
Some of these questions can be approached by
traditional
continuum-modeling
techniques.
However, it is known that several yielding phe-
nomena of amorphous materials are dominated by
ﬂuctuations, strongly correlated dynamics, disor-
der, and memory effects resulting from the micro-
scopic reality. In these cases, bridging the
dynamics on the microscopic scale with its coun-
terpart, the complex macroscopic consequences,
is a challenging task that requires the use of sta-
tistical physics-modeling approaches and tools.
In this context, there exist several interesting
out-of-equilibrium transitions, which are accompa-
nied by intermittent dynamics (Bonn et al. 2017;
Nicolas et al. 2018). In the quasi-static yielding,
relevant for hard amorphous materials, the systems
undergo a transition upon increase of an externally
applied deformation. They evolve from an elastic
regime at small deformations, to a plastic ﬂow-
regime after reaching the so-called static yield
stress (Varnik et al. 2004). The nature of this tran-
sition in the transient regime, potentially leading to
strongly intermittent dynamics in form of ava-
lanches (Combe and Roux 2000; Karmakar et al.
2010), has been investigated in the context of non-
equilibrium phase transitions (Jaiswal et al. 2016;
Leishangthem et al. 2017; Ozawa et al. 2018;
Popović et al. 2018). A second well-studied transi-
tion in this context is the dynamic yielding transi-
tion, which is concerned with the steady ﬂow
regime at a vanishing but ﬁnite imposed shear
rate. In this quasi-static driving regime, the mate-
rials exhibit a ﬁnite dynamic yield stress that can
differ from the above deﬁned static one (Varnik
et al. 2004). The emerging critical dynamics in
the steady ﬂow of soft glassy materials in the
vicinity of the dynamic yield transition has been
extensively studied (Bailey et al. 2007; Talamali
et al. 2011; Lin et al. 2014; Liu et al. 2016; Aguirre
and Jagla 2018).
Soft disordered materials in form of yield stress
ﬂuids have in common that once deformed beyond
their solid elastic regime they yield plastically
toward a complex ﬂow regime with a shear rate-
dependent viscosity (Bonn et al. 2017; Nicolas
et al. 2018). The steady state ﬂow behavior of
these yield stress ﬂuids can be described at the
continuum level using empirical laws like the
Herschel-Bulkley
relationship
(Herschel
and
Bulkley 1926), or continuum descriptions, such as
338
Statistical Physics of the Yielding Transition

viscoelastoplastic (Marmottant and Graner 2007;
Saramito 2007) and ﬂuidity models (Bocquet
et al. 2009; Fielding 2014). While these types of
descriptions account well for the average ﬂow
behavior at a coarse-grained scale, it has appeared
that some ﬂow features of yield stress materials are
dominated by giant ﬂuctuations of the macroscopic
stress or shear rate (Coussot et al. 2002; Lootens
et al. 2003; Cantat and Pitois 2006; Barés et al.
2017; Pastore et al. 2011; Srivastava et al. 2019).
This can, for example, lead to nonlocal, strongly
system-size-dependent, transport coefﬁcients for
the material dynamics (Lemaître and Caroli 2009;
Martens et al. 2011; Tyukodi et al. 2018). Accord-
ingly, understanding the role of mechanical noise
and its spatiotemporal features has not only
attracted a strong fundamental interest (Nicolas
et al. 2018) but is also of direct importance in
rheological applications (Bonn et al. 2017).
Part of the mechanical ﬂuctuations in driven
disordered materials are usually generated by the
ﬂow itself, for example, resulting from the elastic
response of the material to localized plastic events
(Argon and Kuo 1979; Schall et al. 2007). They
are therefore very different in nature from ther-
mally generated ﬂuctuations (Nicolas et al. 2014)
and
must
be
incorporated
into
modeling
approaches in a self-consistent manner (Hébraud
and Lequeux 1998).
In some cases, ﬂow-induced ﬂuctuations can
be associated with a self-ﬂuidization of the mate-
rial, i.e., a decrease in shear stress with increasing
shear rate. This leads to nonmonotonic rheologi-
cal constitutive curves (Fielding 2014; Schall and
van Hecke 2010; Mansard et al. 2011) that can be
associated with ﬂow instabilities, potentially lead-
ing to shear localization, metastability, and hys-
teresis (Wortel et al. 2014). In the case of granular
materials, this self-ﬂuidization process ﬁnds its
origin in sliding frictional contacts (Wortel et al.
2014, 2016; DeGiuli and Wyart 2017). In non-
frictional yield stress materials, nonmonotonic
ﬂow curves can be explained by mechanisms
such as inertia (Nicolas et al. 2016) or local soft-
ening
following
structural
rearrangements
(Coussot and Ovarlez 2010; Martens et al. 2012).
Besides this self-generated mechanical noise,
there can be additional external sources of noise,
which can be regarded in a ﬁrst-order approxima-
tion independent of the shear-induced one. This is,
for example, the case of irreversible deformations
induced by thermal activation (Chattoraj et al.
2010; Ikeda et al. 2012) or mechanical vibrations
(D’anna et al. 2003; Caballero-Robledo and
Clément 2009; Jia et al. 2011; Hanotin et al.
2012; Gnoli et al. 2016). Other mostly rate-
independent ﬂuctuations can also result from
local processes such as coarsening in foams
(Cohen-Addad et al. 2004), or internal activity
(Mandal et al. 2016; Tjhung and Berthier 2017;
Matoz-Fernandez et al. 2017). One important
aspect of such external noise sources is that they
can induce a ﬂuidization of the system at small
imposed external stresses. Interestingly, in the
case of materials with a nonmonotonic constitu-
tive curve, this additional ﬂuidization can give rise
to a critical point at ﬁnite deformation rates, which
leads in the case of an imposed shear stress to
giant ﬂuctuations in the shear rate statistics
(Wortel et al. 2016; Le Goff et al. 2019, 2020).
Elastoplastic Models
It is well established that deformation of disor-
dered materials is realized through successive dis-
sipative events in the form of localized shear
transformations (Argon and Kuo 1979). These
result in long-range elastic stress variations in
the surroundings (Eshelby 1957a), potentially
leading to cascading plastic events correlated on
time and length scales far beyond the scale of the
initial local rearrangement (Martens et al. 2011;
Baret et al. 2002). Following this very generic
picture, it has been proposed that brittle amor-
phous materials, such as metallic glasses, and
dense soft particle ﬂow, such as emulsions or
colloidal suspensions, can be described by similar
mesoscopic modeling approaches (Nicolas et al.
2018). To reveal the underlying physics and unify
the understanding of the various phenomena in
yielding and ﬂow of amorphous systems, it is
thus tempting to derive models on the mesoscopic
scale, using coarse-grained quantities like a local
tensorial stress, strain, and corresponding elastic
moduli (Tsamados et al. 2009). A large number of
elastoplastic descriptions are based on this under-
standing (Rodney et al. 2011; Nicolas et al. 2018;
Statistical Physics of the Yielding Transition
339

Hébraud and Lequeux 1998; Baret et al. 2002;
Merabia and Detcheverry 2016).
To overcome fundamental difﬁculties related to
the complexity of the dynamics on the microscopic
scale, the elastoplastic modeling approach has been
proposed to bridge the gap between the different
scales (for an extensive review, see Nicolas et al.
2017). Built upon ideas developed by Argon and
Kuo (1979), who pioneered the understanding that
macroscopic plastic deformation in dense disor-
dered materials is induced by localized plastic
events of a size of few particle diameters, models
where proposed starting from the scale of the typ-
ical plastic inclusion size (Baret et al. 2002; Bulatov
and Argon 1994a, b), which implies an important
coarse graining in space and in time. The dense
particle system is divided into blocks of a size that
is relevant to deﬁne a meaningful coarse-grained
elastic modulus (Tsamados et al. 2009) together
with ﬁelds of stress, elastic, and plastic deforma-
tion. The elastoplastic modeling approach depends
crucially on the existence of these localized plastic
events, and the approach can thus only be valid in
deeply jammed systems since close to unjamming
dissipation mechanisms are known to become
strongly nonlocal (Lerner et al. 2012) (Fig. 1).
An elastically deforming region in the material
acquires a new reference conﬁguration not only as
a response to the external deformation, but also
responding
to
the
surrounding
plastically
deforming regions. This new conﬁguration will
differ from the original reference state by some
eigenstrain. To simplify the problem further, we
consider that the plastically deforming zones can
be considered point-like at this coarse-grained
scale. In this limit, only the far ﬁeld response of
the surrounding material to the locally deformed
plastic inclusions can be considered. In the sim-
plest formulation, this response can be derived for
linear isotropic elastic medium, which is a good
ﬁrst-order approximation of the complex prob-
lem. The mesoscopic model then involves the
calculation of the elastic response of the surround-
ing medium to the forces that are exerted by the
zones that have undergone a yield event. This
calculation goes along the lines of a standard
linear elasticity calculation, but we omit the
details of this technical point and we give directly
the ﬁnal result that describes the response of the
medium at point r! to a yield event taking place at
the origin using the propagator G given in Eq. 1.
Approximating
the
rearrangements
corres-
ponding to the local plastic events by a force quad-
rupole (Eshelby problem), one expects a fourfold
quadrupolar symmetry for the inhomogeneous part
of the stress propagator (Eshelby 1957b). The form
of this propagator for an inﬁnite two-dimensional
medium reads in nondimensional form
G 1
ð
Þ r, y
ð
Þ ¼ 1
pr2 cos 4y
ð
Þ:
ð1Þ
The
medium
is
described
by
a
set
of
elastoplastic elements that occupy the nodes of a
regular square lattice. To model a yield stress
material under steady shear with a ﬁxed strain
rate _g , we start from a simple Maxwell-like
description of the stress dynamics associated
with a given element (Fig. 2):
@ts tð Þ ¼ m_g  2m_epl tð Þ
ð2Þ
where @t denotes the partial time derivative, s(t) is
the shear component of the stress tensor, m is the
shear modulus, and _epl tð Þ accounts for the change
in the strain due to local yielding. To take into
Statistical
Physics
of
the
Yielding
Transition,
Fig. 1 Scheme of different scales: the microscopic scale
(in yellow) on the scale of the constituents, here illustrated
by the bubbles of a sheared polydisperse 2d bubble raft; the
mesoscopic scale (in red) on the scale of the shear trans-
formation inclusions; and the macroscopic scale (in green)
is the scale of the average ﬂow properties
340
Statistical Physics of the Yielding Transition

account the long range effects of the plastic events,
ﬁrst predicted by Argon (Argon and Kuo 1979) and
later evidenced in molecular dynamics simulations
(Tanguy et al. 2006) and experiments on colloids
(Schall et al. 2007), we change the above homoge-
neous equation to a ﬁeld description with a stress
propagator G r!  r!0


accounting for the stress
redistribution due to a plastic event,
@tsðr
!, tÞ ¼ m_g
þ 2m
ð
d r!0G r!  r!0


_epl r!0, t


ð3Þ
To describe the deformation due to the plastic
events, we model a Maxwellian viscoelastic-like
relaxation of the material in the plastic state, i.e.,
_eplðr!, tÞ ¼ 1
2mt nðr!, tÞsðr!, tÞ,
ð4Þ
where t is the typical time for the stress release in
the plastic phase and nðr!, tÞ a local state variable.
In the following, we refer to nðr!, tÞ as local
activity. We deﬁne nðr!, tÞ ¼ 0
indicating the
absence of a plastic event and nðr!, tÞ ¼ 1 if the
local region is in the plastic phase.
To incorporate the idea of a yield stress, we
deﬁne the following stochastic dynamics for the
state variable nðr!, tÞ. If the local stress exceeds a
threshold value sðr!, tÞ > sy, there is a ﬁnite prob-
ability to yield locally. The yielding rate is given
by 1/tpl. Once yielded, ðnðr!, tÞ ¼ 1Þ stress is
redistributed using an appropriate stress propaga-
tor, and locally the stress is relaxing during a
typical
restructuring
time
tel.
The
rate
to
reestablish the elastic state ðnðr!, tÞ ¼ 0Þ is given
by 1/tel.
It has been shown that this very simpliﬁed
cellular automata model, for the mesoscopic
elastoplastic dynamics, results in many qualitative
and semiquantitative results, ﬁtting the ﬂuctua-
tions and rheological measurements from experi-
ments and microscopic simulations. They have
been intensively studied in the framework of
dynamical heterogeneities (Martens et al. 2011),
avalanche dynamics (Talamali et al. 2011), shear-
banding (Martens et al. 2012), critical phenomena
(Lin et al. 2014), and transient creep dynamics
(Merabia and Detcheverry 2016), to name only
few ﬁelds where these types of models have been
successfully used to understand the link between
microscopic
plasticity
and
the
macroscopic
mechanical response.
Statistical
Physics
of
the
Yielding
Transition,
Fig. 2 From microscopic events to macroscopic ﬂow.
Left: change in the stress ﬁeld due to a single plastic
event (color code) and the corresponding displacement
ﬁeld (blue vectors). Right: average local stress in the steady
state as a function of strain rate for different system sizes.
Inset: evolution of the spatially averaged stress as a func-
tion of strain, the arrow indicates a decrease of the
strain rate
Statistical Physics of the Yielding Transition
341

Mean-Field Descriptions
Several mean-ﬁeld descriptions that neglect the
details of the spatial dynamics have been developed.
Examples are the soft glassy rheology model
(Sollich et al. 1997; Moorcroft et al. 2011), ﬂuidity
models (Bocquet et al. 2009; Picard et al. 2002), the
shear transformation zone theory (Falk and Langer
1998), and the mode-coupling theory (Fuchs and
Cates 2002). Although some of these models could
be successfully ﬁtted to simulations and experi-
ments (Zausch et al. 2008; Manning et al. 2007;
Goyon et al. 2008; Mansard et al. 2013), the ingre-
dients of these mesoscopic models remain in most
cases phenomenological and the direct link to under-
lying microscopic dynamics remains unresolved.
Due to the challenging character of the problem of
deformation of disordered systems, no consensus
has been established even on the basic ingredients
that should underlie coarse-grained descriptions of
the nonlinear rheological response of yield stress
materials (Hébraud and Lequeux 1998; Sollich
et al. 1997; Falk and Langer 1998; Agoritsas et al.
2015; Lin and Wyart 2016; Richard et al. 2020).
Here, we present in detail one of the ways to
derive a phenomenogical mean-ﬁeld description
that is based on the above lattice model. The idea
is to introduce the probability density P of local
shear stresses s ¼ sxy in regions of mesoscopic
size W while the material is sheared at rate _g. The
time evolution of P is given by
@tP s, t
ð
Þ ¼ G0_g tð Þ@sP  1
t y jsjsc
ð
ÞP
þG tð Þd s
ð Þ þ D tð Þ@2
sP
ð5Þ
where θ(x) and δ(x) denote, respectively, the
usual Heaviside and delta-distributions. The
ﬁrst term on the right-hand side proportional
to the stress gradient of the probability density
@sP
accounts for the linear elastic response.
The following term describes the loss in the
probability density due to local yielding of
overstressed regions above a critical stress sc
at a rate given by 1/t. It has been argued that
the
phenomenological
parameter
t
can
be
interpreted as the duration of a plastic event in
the low shear rate limit (Agoritsas et al. 2015).
The corresponding gain term is given in the
third expression on the right-hand side, where
the stress is set to zero after a yielding event
with a rate given by the plastic activity rate
G tð Þ ¼ 1
t
ð
jsj>sc
P s, t
ð
Þds:
ð6Þ
The last term encompasses the stress changes
created through other yielding events in a mean-
ﬁeld manner, assuming that this mechanical noise
can be approximated through a normal diffusion
of the mesoscopic stresses. To describe this noise
in a self-consistent manner, the HL approach pro-
poses that its amplitude should be related to the
rate of plastic activity through a dimensionless
coupling constant ea
D tð Þ ¼ eas2
cG tð Þ:
ð7Þ
This last relation introduces a nonlinearity into
Eq. (5), since the rate of plastic activity itself
depends on the density probability of the meso-
scopic stresses. It is this coupling that renders the
problem nontrivial and yields interesting results
regarding the behavior of macroscopic quantities.
This model is known to exhibit a unique sta-
tionary state for a ﬁnite shear rate in the large time
limit, where the probability density for the meso-
scopic stresses becomes time independent. To
determine the time-averaged macroscopic stress
in the steady state, one averages over the meso-
scopic stresses weighted by the corresponding
steady state probability density
s
h i ¼
ð
sP s
ð Þds:
ð8Þ
Using appropriate units, we can write the equa-
tions in dimensionless quantities, expressing
stress-related values in units of the local yield
stress sc, time quantities in units of t, the shear
rate in units of sc/(G0t), and the stress diffusion
coefﬁcient in units of s2
c=t , leaving only two
independent dimensionless model parameters
that determine the ﬂow behavior, namely the
dimensionless shear rate and coupling constant ea.
The rheological results in the small shear rate
limit for this model are well studied (Agoritsas
342
Statistical Physics of the Yielding Transition

and Martens 2017; Hébraud and Lequeux 1998;
Olivier and Renardy 2011). For small enough
coupling strength ea < 1=2, the HL model predicts
a Herschel-Bulkley ﬂow behavior of exponent 1/2
s
h i  sY þ A_g1=2
for the time-averaged macroscopic stress in the
steady state s
h i ¼
Ð
sP s
ð Þds, with the two con-
stants sY (the dynamical yield stress) and A (the
prefactor). Thus, this very simpliﬁed model can
already capture well the nonlinear behavior of the
ﬂow of yield stress materials. Moreover, it has
also been shown that the typical transient dynam-
ics during creep experiments can be qualitatively
well reproduced using these modeling techniques
(Liu et al. 2018) (Fig. 3).
Conclusion and Outlook
Although much progress has been made in the
statistical modeling of yield stress materials and
their yielding phenomena, there remain still a lot
of challenging questions. One important route is
to connect better the different scales by under-
standing how the mesoscopic parameters for the
local yielding and initial conditions emerge from
the microscopic interactions and preparation pro-
tocols (Liu et al. 2021).
In the recent past, there have been ﬁrst steps
toward a better understanding of the details in
the elastic response to local shear transforma-
tions, the evolution of local yield thresholds
(Puosi et al. 2015; Patinet et al. 2016), and
the detection of precursors to local yielding
events (Richard et al. 2020). This ﬁeld became
very active and is expected to develop rapidly
in the future.
In a broader context, it will be important to
understand the different links between the theory
developed for the deformation of glasses with
various interconnected ﬁelds. In the framework
of aging and glassy dynamics, it will be important
to connect the understanding of the deformation
of glasses with the different theories about treating
the dynamics close to the glass transition. For
athermal systems, it will be important to connect
the different insights with the knowledge in the
ﬁeld of jamming phenomena.
Statistical Physics of the Yielding Transition, Fig. 3 The different approaches for the different scales are illustrated
in the above table
Statistical Physics of the Yielding Transition
343

And last but not least, the yielding transition
can serve as a model of an out-of-equilibrium
system that remains close to applications. As
such, it shows a variety of interesting out-of-
equilibrium features, including critical dynamics,
that can be studied within the general framework
of out-of-equilibrium statistical physics.
Bibliography
Agoritsas E, Martens K (2017) Soft Matter 13:4653
Agoritsas E, Bertin E, Martens K, Barrat J-L (2015) Eur
Phys J E 38:71
Aguirre IF, Jagla E (2018) Phys Rev E 98:013002
Amann CP, Siebenbuürger M, Kruüger M, Weysser F,
Ballauff M, Fuchs M (2013) J Rheol 57:149
Argon A, Kuo H (1979) Mater Sci Eng 39:101
Bailey
NP,
Schiøtz
J,
Lemaître
A,
Jacobsen
KW
(2007) Phys Rev Lett 98:095501
Barés J, Wang D, Wang D, Bertrand T, O’Hern CS,
Behringer RP (2017) Phys Rev E 96:052902
Baret J-C, Vandembroucq D, Roux S (2002) Phys Rev Lett
89:195506
Bocquet L, Colin A, Ajdari A (2009) Phys Rev Lett
103:036001
Bonn D, Denn MM, Berthier L, Divoux T, Manneville
S (2017) Rev Mod Phys 89:035005
Bulatov V, Argon A (1994a) Model Simul Mater Sci Eng
2:167
Bulatov V, Argon A (1994b) Model Simul Mater Sci Eng
2:203
Caballero-Robledo GA, Clément E (2009) Eur Phys J E
30:395
Cantat I, Pitois O (2006) Phys Fluids 18:083302
Chattoraj J, Caroli C, Lemaître A (2010) Phys Rev Lett
105:266001
Chaudhuri P, Horbach J (2013) Phys Rev E 88:040301
Cipelletti L, Martens K, Ramos L (2020) Soft Matter 16:82
Cohen-Addad S, Höhler R, Khidas Y (2004) Phys Rev Lett
93:028302
Combe G, Roux J-N (2000) Phys Rev Lett 85:3628
Coussot P, Ovarlez G (2010) Eur Phys J E Soft Matter Biol
Phys 33:183
Coussot P, Nguyen QD, Huynh H, Bonn D (2002) Phys
Rev Lett 88:175501
D’anna G, Mayor P, Barrat A, Loreto V, Nori F (2003)
Nature 424:909
DeGiuli E, Wyart M (2017) Proc Natl Acad Sci 114:9284
Divoux T, Barentin C, Manneville S (2011) Soft Matter
7:8409
Dzuy NQ, Boger DV (1983) J Rheol 27:321
Eshelby J (1957a)
Eshelby JD (1957b) Proc R Soc Lond A 241:376
Falk ML, Langer JS (1998) Phys Rev E 57:7192
Fielding SM (2014) Rep Prog Phys 77:102601
Fuchs M, Cates ME (2002) Phys Rev Lett 89:248304
Gnoli A, Lasanta A, Sarracino A, Puglisi A (2016) Sci Rep
6:38604
Goyon J, Colin A, Ovarlez G, Ajdari A, Bocquet L (2008)
Nature 454:84
Hanotin C, De Richter SK, Marchal P, Michot LJ, Baravian
C (2012) Phys Rev Lett 108:198301
Hébraud P, Lequeux F (1998) Phys Rev Lett 81:2934
Herschel WH, Bulkley R (1926) Coll Polym Sci 39:291
Ikeda A, Berthier L, Sollich P (2012) Phys Rev Lett
109:018301
Jaiswal PK, Procaccia I, Rainone C, Singh M (2016) Phys
Rev Lett 116:085501
Jia X, Brunet T, Laurent J (2011) Phys Rev E 84:020301
Karmakar S, Lerner E, Procaccia I (2010) Phys Rev
E 82:055103
Kawamura Y, Shibata T, Inoue A, Masumoto T (1999)
Mater Trans JIM 40:335
Koumakis N, Laurati M, Egelhaaf S, Brady J, Petekidis
G (2012a) Phys Rev Lett 108:098303
Koumakis N, Pamvouxoglou A, Poulos A, Petekidis
G (2012b) Soft Matter 8:4271
Le Goff M, Bertin E, Martens K (2019) Phys Rev Lett
123:108003
Le Goff M, Bertin E, Martens K (2020) J Phys Mater
3:025010
Leishangthem P, Parmar AD, Sastry S (2017) Nat Commun
8:14653
Lemaître A, Caroli C (2009) Phys Rev Lett 103:065501
Lerner E, Düring G, Wyart M (2012) Proc Natl Acad Sci
109:4798
Lin J, Wyart M (2016) Phys Rev X 6:011005
Lin J, Lerner E, Rosso A, Wyart M (2014) Proc Natl Acad
Sci 111:14382
Liu C, Ferrero EE, Puosi F, Barrat J-L, Martens K (2016)
Phys Rev Lett 116:065501
Liu C, Martens K, Barrat J-L (2018) Phys Rev Lett
120:028004
Liu C, Dutta S, Chaudhuri P, Martens K (2021) Phys Rev
Lett 126:138005
Lootens D, Van Damme H, Hébraud P (2003) Phys Rev
Lett 90:178301
Lu J, Ravichandran G, Johnson WL (2003) Acta Mater
51:3429
Maaß R, Klaumünzer D, Villard G, Derlet P, Löfﬂer JF
(2012) Appl Phys Lett 100:071904
Mandal R, Bhuyan PJ, Rao M, Dasgupta C (2016) Soft
Matter 12:6268
Manning M, Langer J, Carlson J (2007) Phys Rev
E 76:056106
Mansard V, Colin A, Chauduri P, Bocquet L (2011) Soft
Matter 7:5524
Mansard V, Colin A, Chaudhuri P, Bocquet L (2013) Soft
Matter 9:7489
Marmottant P, Graner F (2007) Eur Phys J E 23:337
Martens K, Bocquet L, Barrat J-L (2011) Phys Rev Lett
106:156001
Martens K, Bocquet L, Barrat J-L (2012) Soft Matter
8:4197
344
Statistical Physics of the Yielding Transition

Matoz-Fernandez D, Agoritsas E, Barrat J-L, Bertin E,
Martens K (2017) Phys Rev Lett 118:158105
Merabia S, Detcheverry F (2016) EPL 116:46003
Moorcroft RL, Cates ME, Fielding SM (2011) Phys Rev
Lett 106:055502
Nicolas A, Martens K, Barrat J-L (2014) EPL 107:44003
Nicolas A, Barrat J-L, Rottler J (2016) Phys Rev Lett
116:058303
Nicolas A, Ferrero EE, Martens K, Barrat J-L (2017) arXiv
preprint arXiv:1708.09194
Nicolas A, Ferrero EE, Martens K, Barrat J-L (2018) Rev
Mod Phys 90:045006
Olivier J, Renardy M (2011) SIAM J Appl Math 71:1144
Ozawa M, Berthier L, Biroli G, Rosso A, Tarjus G (2018)
Proc Natl Acad Sci 115:6656
Pastore R, Ciamarra MP, Coniglio A (2011) Philos Mag
91:2006
Patinet S, Vandembroucq D, Falk ML (2016) Phys Rev
Lett 117:045501
Picard G, Ajdari A, Bocquet L, Lequeux F (2002) Phys
Rev E 66:051501
Popović M, de Geus TW, Wyart M (2018) Phys Rev
E 98:040901
Puosi F, Olivier J, Martens K (2015) Soft Matter 11:7639
Richard D, Ozawa M, Patinet S, Stanifer E, Shang B,
Ridout S, Xu B, Zhang G, Morse P, Barrat J-L et al
(2020) Phys Rev Mater 4:113609
Rodney D, Tanguy A, Vandembroucq D (2011) Model
Simul Mater Sci Eng 19:083001
Rogers S, Callaghan P, Petekidis G, Vlassopoulos D (2010)
J Rheol 54:133
Saramito P (2007) J Non-Newtonian Fluid Mech 145:1
Schall P, van Hecke M (2010) Annu Rev Fluid Mech 42:67
Schall P, Weitz DA, Spaepen F (2007) Science 318:1895
Sentjabrskaja
T,
Hermes
M,
Poon
W,
Estrada
C,
Castaneda-Priego R, Egelhaaf S, Laurati M (2014)
Soft Matter 10:6546
Sentjabrskaja T, Chaudhuri P, Hermes M, Poon W,
Horbach J, Egelhaaf S, Laurati M (2015) Sci Rep
5:11884
Sollich P, Lequeux F, Hébraud P, Cates ME (1997) Phys
Rev Lett 78:2020
Srivastava
I,
Silbert
LE,
Grest
GS,
Lechman
JB
(2019) Phys Rev Lett 122:048003
Talamali M, Petäjä V, Vandembroucq D, Roux S (2011)
Phys Rev E 84:016115
Tanguy A, Leonforte F, Barrat J-L (2006) Eur Phys J E
20:355
Tjhung E, Berthier L (2017) Phys Rev E 96:050601
Tsamados M, Tanguy A, Goldenberg C, Barrat J-L
(2009) Phys Rev E 80:026112
Tyukodi B, Vandembroucq D, Maloney CE (2018) Phys
Rev Lett 121:145501
Varnik F, Bocquet L, Barrat J-L (2004) J Chem Phys
120:2788
Wortel GH, Dijksman JA, van Hecke M (2014) Phys Rev
E 89:012202
Wortel G, Dauchot O, van Hecke M (2016) Phys Rev Lett
117:198002
Zausch J, Horbach J, Laurati M, Egelhaaf SU, Brader JM,
Voigtmann T, Fuchs M (2008) J Phys Condens Matter
20:404210
Statistical Physics of the Yielding Transition
345

Granular Flows
James W. Dufty
Department of Physics, University of Florida,
Gainesville, FL, USA
Article Outline
Glossary
Deﬁnition of the Subject
Introduction
Granular Fluid and Its Statistical Mechanics
Macroscopic Balance Equations
“Normal” States and Hydrodynamics
Navier–Stokes Approximation
Future Directions
Appendix
Bibliography
Glossary
Granular matter a system comprised of a large
number of grains, or particles, of macroscopic
size. Examples include powders, sand, seeds,
and the surface of Mars.
Granular ﬂuid an activated (driven) state of
granular matter such that the grains move
(ﬂow) and collide frequently.
Statistical mechanics a ﬁeld of physics that
addresses systems with many degrees of free-
dom based on the fundamental microscopic
laws to describe derived macroscopic properties.
Macrostate a statistical description of a system
with many degrees of freedom in terms of
limited information about that system.
Hydrodynamic ﬁelds the local densities of
mass, energy, and momentum deﬁned at each
point in the system of interest.
Normal state a macrostate whose time evolution
is described entirely through that of the average
hydrodynamic ﬁelds.
Balance equations exact equations for the time
derivatives of the hydrodynamic ﬁelds in terms
of associated ﬂuxes and sources.
Constitutive
equations expressions
for
the
ﬂuxes and sources of the balance equations as
functionals of the hydrodynamic ﬁelds.
Hydrodynamics a macroscopic description of
the system in terms of a closed, deterministic
set of equations for the average hydrodynamic
ﬁelds, resulting from the exact balance equa-
tions with approximate constitutive equations.
Navier–Stokes hydrodynamics local, ﬁrst order
in time, partial differential equations for states
with small spatial gradients in the hydrody-
namic ﬁelds (constitutive equations calculated
to ﬁrst order in the spatial gradients).
Definition of the Subject
The terminology granular matter refers to systems
with a large number of hard objects (grains) of
mesoscopic size ranging from millimeters to
meters. Geological examples include desert sand
and the rocks of a landslide. But the scope of such
systems is much broader, including powders and
snow, edible products such a seeds and salt, med-
ical products like pills, and extraterrestrial sys-
tems such as the surface regolith of Mars and the
rings of Saturn. The importance of a fundamental
understanding for granular matter properties can
hardly be overestimated. Practical issues of cur-
rent concern range from disaster mitigation of
avalanches and explosions of grain silos to
immense economic consequences within the
pharmaceutical industry. In addition, they are of
academic and conceptual importance as well as
examples of systems far from equilibrium.
Under many conditions of interest, granular
matter ﬂows like a normal ﬂuid (Kadanoff
1999). In the latter case such ﬂows are accurately
described by the equations of hydrodynamics.
Attention is focused here on the possibility for a
corresponding hydrodynamic description of gran-
ular ﬂows. The tools of nonequilibrium statistical
© Springer-Verlag 2009
B. Chakraborty (ed.), Statistical and Nonlinear Physics,
https://doi.org/10.1007/978-1-0716-1454-9_259
Originally published in
R. A. Meyers (ed.), Encyclopedia of Complexity and Systems Science, © Springer-Verlag 2009
https://doi.org/10.1007/978-3-642-27737-5_259
347

mechanics (McLennan 1989), developed over the
past 50 years for ﬂuids composed of atoms and
molecules (Hansen and McDonald 1986; Resibois
and De Leener 1977), are applied here to a system
of grains for a fundamental approach to both
qualitative questions and practical quantitative
predictions. Applications of basic atomic physics
principles to granular ﬂuids have accelerated dur-
ing the past decade, starting with an emphasis on
molecular
dynamics
(MD)
simulations
(Goldhirsch et al. 1993) and kinetic theory
(Brilliantov and Pöschel 2004; Dufty 2001), and
more recently with the theoretical methods of the
type described here (Brey et al. 1997; Van Noije
and Ernst 2001; Dufty 2000; Dufty et al. 2002,
2006, 2007).
Introduction
To start with the familiar, consider a jar of vitamin
pills, mustard seeds, or peanuts. Remove the lid
and pour them into a bowl, observing that the
“ﬂow”, or their collective motion, has some sim-
ilarity to that of a normal ﬂuid such as water. The
collective motion in both cases is the consequence
of collisions among their constituents, grains or
atoms, and their large number. It is tempting to
make the correspondence of grains to atoms in
considering the similarities of ﬂows in these two
types of ﬂuids. The objective here is to explore in
formal detail the extent to which that correspon-
dence is conceptually and quantitatively justiﬁed.
An important prerequisite is the integrity of the
grains during their motion. Each grain is com-
prised of a large number of atoms or molecules.
Integrity refers to their retention of mass and
shape following interactions with other grains or
with their environment. As such, the grains
behave as “particles” whose detailed internal
structure is not essential to their description,
which is captured instead by a few parameters
describing their shape, mass, and collisional prop-
erties with other grains. However, an important
consequence of this underlying molecular struc-
ture is a redistribution of translational kinetic
energy of the grains and internal energy of the
constituent molecules. At the mesoscopic level
this appears as an energy loss on collisions
between pairs of grains. This is a central feature
of granular ﬂuids differentiating them from
atomic ﬂuids: the inelasticity of granular pair
collisions.
Granular matter occurs in two classes of states,
compact and activated (see for example articles
2002). In the ﬁrst case, the grains form a static
packed conﬁguration within the container due to
the effects of gravity on their relatively large mass
and their inelastic collisions. Any initial motion is
quickly
dissipated
and
their
kinetic
energy
becomes negligible relative to the gravitational
potential energy. Important questions arise about
the possible and probable packing conﬁgurations
that determine the stresses within the system and
the distribution of forces on the container. For
example, chains of particles in contact can occur
as arches to support matter above them while
reducing their force on the matter below. There
is an intense interest in the study of such states,
generically referred to as contact mechanics.
Activated states refer to continuously driven
systems, or gravity free conditions. For example,
a container of grains in a compact conﬁguration
can be shaken to impose kinetic energy and
motion among the grains. Similarly, unrestrained
systems in a gravitational ﬁeld will ﬂow towards
lower potential energy (e.g., hopper ﬂow or ﬂow
down an incline). Initial activation in space labo-
ratory experiments provides another example
(self-sustained ﬂuidization). For the ﬂows consid-
ered here as candidates for a hydrodynamic
description continual collisions are essential.
This means that within each small cell, still
containing many particles, the particles are mov-
ing randomly relative to the collective motion of
that cell. Thus, ballistic motion or beams with all
particles moving independently in the same direc-
tion are excluded.
Both compact and activated grains may occur
immersed in a continuum such as water or air that
may have a strong or weak effect on their collec-
tive properties. For compact systems water may
provide a lubrication effect that affects the domi-
nant class of conﬁgurations. For activated systems
it can provide an additional dissipative drag
between collisions among the grains. When the
348
Granular Flows

medium plays an important role the systems is
said to be wet. In the opposite limit it is said to
be dry. Finally, it is possible for compact and
activated components of a system to coexist as
heterogeneous states. Here, only the simplest case
of dry systems in fully activated ﬂows are consid-
ered. These are referred to in the following as
granular ﬂuids.
Advances in the study of granular ﬂuids have
arisen from many communities, including chemi-
cal engineering, materials sciences, and physics.
The additional academic and conceptual impor-
tance of granular matter as practical systems for
exploring the relevance of many-body ﬂuid
methods is primarily for the physics community.
Granular matter, viewed as a system of particles
with inelastic interactions, provides new opportu-
nities to test the qualitative and quantitative limits
of many-body methods developed over the past
century for atomic and molecular systems. This is
the ﬁeld of non-equilibrium statistical mechanics
(McLennan 1989; Hansen and McDonald 1986;
Resibois and De Leener 1977). Granular matter
provides a new testing ground for a reconsidera-
tion of the most fundamental concepts and tools
(Kadanoff 1999), with the potential for enhanced
understanding of their place in atomic and molec-
ular systems as well.
Statistical mechanics addresses the difﬁcult
many-body problem of extracting macroscopic
properties of experimental interest from the very
large number of constituent particles. The results
express these properties in terms of the fundamen-
tal “microscopic” features of these particles, such
as mass, shape, degree of inelasticity, and colli-
sional properties. In this way the properties of the
vitamin pills, mustard seeds, and peanuts are dis-
tinguished at a fundamental level. Also, concep-
tual
issues
such
as
the
limitations
of
a
macroscopic description are exposed through the
insistence on their logical evolution from the fun-
damental microdynamics. In the next section, the
granular ﬂuid is described as a system of particles
interacting via pairwise additive, nonconservative
forces. The microscopic dynamics of these parti-
cles leads to balance equations for the mass den-
sity, energy density, and momentum density. Their
averages deﬁne the “hydrodynamic ﬁelds” which
are candidates for a macroscopic, continuum
mechanics description. These exact equations are
described in section “Macroscopic Balance Equa-
tions” and the need for “constitutive equations” to
provide a closure is described. The origin of con-
stitutive equations, and consequently the origin of
hydrodynamics, is associated with the concept of
“normal states” (Dufty and Brey 2005a) in section
“Normal” States and Hydrodynamics”. The nor-
mal state for the case of small spatial deviations
from homogeneity is constructed formally in sec-
tion “Navier–Stokes Approximation”, resulting in
the constitutive equations for Navier–Stokes
hydrodynamics (Here the Navier–Stokes n.d.).
This derivation also provides insight into the con-
text in which such a description should hold, and
differences from the corresponding results for a
normal ﬂuid are noted. Empirical evidence (Huan
et al. 2004; Bizon et al. 1999), simulations (Brey
et al. 1999, 2002, 2005), and corresponding
results from kinetic theory (Brey et al. 1998;
Dufty 2005; Dufty and Brey 2002, 2005b) support
the applicability of this hydrodynamic description
under appropriate conditions. Finally, the results
are summarized in section “Future Directions”
and some comments on the outlook for future
developments are offered.
The presentation here is focused on recent
work of the author and his collaborators for appli-
cation of statistical mechanics to explore hydro-
dynamics for a granular gas. Consequently, the
references quoted are heavily weighted toward
those
developmental
studies.
Apologies
are
offered for the exclusion of the vast and important
complementary literature on simulations, kinetic
theory, and experiments also bearing on this
topic. Many of these can be found in the list of
Books and Reviews given here.
Granular Fluid and Its Statistical
Mechanics
Nonequilibrium Statistical Mechanics
Consider a system of N  1 identical grains
(hereafter referred to as particles) in a volume V,
whose initial positions {qi} and velocities {vi}, 1

I  N, are speciﬁed. The positions and
Granular Flows
349

velocities deﬁne a point in a 6 N dimensional
space denoted by Γ  {qi, vi}, deﬁning the micro-
state of the system. A macrostate is deﬁned by a
probability
density
r
(Γ)
in
this
space,
representing statistical rather than precise knowl-
edge of the system. The ﬁeld of statistical mechan-
ics addresses properties of macrostates, based on
the recognition that for very large N the details of
microstates are neither experimentally accessible
nor practically calculable. Properties of interest
are represented by functions A(Γ), and their
values for a macrostate r(Γ) are determined from
the expectations
A; r
h
i 
ð
dGr G
ð ÞA G
ð Þ:
ð1Þ
In this section, a brief overview of the essential
ingredients of nonequilibrium statistical mechan-
ics is given, broadened from its usual form
(McLennan 1989) to include granular matter.
The dynamics of macrostates is determined
from the underlying dynamics of the microstates.
The initial point Γ changes in time since the par-
ticles have velocities and move to new positions.
They move in straight lines until one or more
come within the force ﬁeld of other particles, at
which point their velocities change as well as their
positions. The forces are taken to be pairwise
additive, such that the total force on particle I is
Fi ¼ jFij, where Fij is the force on particle I due
to particle J. This does not mean that the interac-
tions are pairwise sequential; three or more parti-
cles can interact simultaneously. The pair forces
are restricted by Newton’s third law, Fij ¼ Fji,
with conservation of momentum. Otherwise quite
general forces can be considered to represent the
shape of the particles and their degree of inelas-
ticity. It is assumed here that the force range
vanishes outside a distance s/2 from the center
of each particle so that s characterizes the size of
the particles. Furthermore, the particles are taken
to be strongly repulsive so that their mean maxi-
mum overlap D on collision is small compared to
their size, D/s < 1. However, their size can be
large or small compared to the mean distance
between particles (V/N)1/3, depending on whether
the density of the system is small or large,
respectively. Most importantly for the purposes
here, these forces do not conserve energy. This
property captures the feature of real grains that
center of mass kinetic energy is lost as they distort
during pair collisions. Further details of the force
law are not required at this point.
The dynamics consists of straight line motion
along the direction of the velocity at time T (free
streaming), until the force range of any pair of
particles, say i, j, overlaps. The relative velocity
GIJ ¼ VI – VJ of that pair changes according to
Newton’s second law for the chosen force law
Fij. Subsequently, all particles continue to stream
freely until another pair has a force range of over-
lap, and the collisional change is repeated for that
pair. In this way a trajectory Γt ¼ {q1(t), . . ., qN(t),
v1(t), . . ., vN(t)} is generated for T > 0. This tra-
jectory is unique and invertible. The statistical
mechanics for a ﬂuid of inelastic particles (Brey
et al. 1997; Van Noije and Ernst 2001; Dufty et al.
2002; Dufty 2000) is comprised of the dynamics
just described, a macrostate speciﬁed in terms of a
probability density r(Γ), and a set of observables
generically denoted by A(Γ). The expectation
value for an observable at time T > 0 for a state
r(Γ) given at T ¼ 0 is deﬁned by
A tð Þ; 0
h
i 
ð
dGr G
ð ÞA Gt
ð
Þ

ð
dGr G
ð ÞetLA G
ð Þ
ð2Þ
where A(t) ¼ A(Γt), and Γt  {q1(t), . . .,
qN(t), v1(t), . . ., vN(t)}
is
the
phase
point
evolved to time T from Γ ¼ Γt ¼ 0. The dynamics
can be represented in terms of a generator
L deﬁned by the second equality of (2). There
are
two
components
to
the
generator,
corresponding to the two steps of free streaming
and velocity changes due to interactions
L ¼
X
N
i¼1
vi  ∇i þ 1
2m
X
N
i¼1
X
N
j6¼i
Fij
 ∇vi  ∇v j


:
ð3Þ
An alternative equivalent representation of the
dynamics is obtained by transferring the dynamics
350
Granular Flows

from the observable A(Γ) to the state r(Γ) by the
deﬁnition
ð
dGr G
ð ÞetLA G
ð Þ 
ð
dG etL r G
ð Þ


A G
ð Þ

ð
dGr G, t
ð
ÞA G
ð Þ:
ð4Þ
The representation in terms of a dynamical
state r(Γ, t) is referred to as Liouville dynamics.
Its generator L is the formal adjoint of L which is
found to be
L ¼ L þ 1
2m
X
N
i¼1
X
N
j6¼i
∇vi  ∇v j


 Fij:
ð5Þ
The difference between L and L arises because
the forces are non-conservative and therefore
depend on the relative velocities of each pair as
well as their positions. Time correlation functions
for two observables A and B are deﬁned in a
similar way
A tð ÞB; 0
h
i 
ð
dG etLA G
ð Þ


r G
ð ÞB G
ð Þ

ð
dGΑ G
ð Þ etLr G
ð Þ


etLB G
ð Þ


:
ð6Þ
or
A tð ÞB; 0
h
i  AB t
ð
Þ; t
h
i:
ð7Þ
In summary, averages like hA(t); 0i and corre-
lation functions hA(t)B; 0i are the central proper-
ties of interest for a macroscopic description of
physical systems. The microscopic dynamics can
be represented in terms of the observables A(Γ, T)
or the states r(Γ, t) which are determined from
speciﬁed initial values and the equations
@t  L
ð
ÞA G, t
ð
Þ ¼ 0,
@t þ L


r G, t
ð
Þ ¼ 0:
ð8Þ
In the following most of the analysis is done in
terms of the states, and the associated equation of
motion is known as the Liouville equation.
Liouville Equation and Cooling
For an isolated system, the total energy decreases
monotonically due to the loss of energy on each pair
collision. This is reﬂected in a decrease of the
average kinetic energy of the particles between
collisions and hence is referred to as collisional
“cooling”. The energy per particle at time T and its
loss are
ϵ tð Þ  N1 E; t
h
i,
o tð Þ  @tϵ tð Þ ¼ N1 LE; t
h
i:
ð9Þ
This cooling effect is common to all solutions
to the Liouville equation and it is useful to sepa-
rate the dynamics into that due to this cooling and
the residual time dependence
r G, t
ð
Þ  r G, ϵ tð Þ, t
ð
Þ:
ð10Þ
The Liouville equation then can be written
@tr G, ϵ, t
ð
Þjϵ þ o ϵ, t
ð
Þ@ϵ þ L


r G, ϵ, t
ð
Þ ¼ 0: ð11Þ
The time derivative is now taken at constant ϵ.
The notation o (ϵ, t) reﬂects the fact that it is a
linear functional of r(Γ, ϵ, t), from its deﬁnition (9).
This is a useful form that isolates a primary effect of
the nonconservative forces (cooling) from the
residual dynamics that will be associated with
relaxation of the spatial inhomogeneities of interest
below. For notational simplicity (11) is written
@t þ L
ð
Þ r G, ϵ, t
ð
Þ ¼ 0,
L  o ϵ, t
ð
Þ@ϵ þ L:
ð12Þ
The corresponding equation for observables is
@t  L
ð
Þ A G, ϵ, t
ð
Þ ¼ 0,
L  @ϵo ϵ, t
ð
Þ þ L:
ð13Þ
where it is understood that @ϵ operates on every-
thing to its right.
Stationary Homogeneous State
An isolated normal ﬂuid supports an equilibrium
state. This is a stationary solution to the Liouville
equation with translational invariance, the Gibbs
Granular Flows
351

states. From the discussion above it is clear that
isolated granular ﬂuids have no truly stationary
state due to cooling. However, there is a “univer-
sal” homogeneous state similar to the Gibbs state
in the sense that a wide class of homogeneous
initial states rapidly approach this state, on the
time scale of a few collisions per particle. It is
simple in the sense that all of its time dependence
is that associated with cooling
r0 G, t
ð
Þ ¼ r0
qij, vi
n
o
, ϵ tð Þ


:
ð14Þ
Here, qij ¼ qi  qj so the solution also has
translational invariance. In the representation (12)
it is seen to be a stationary solution to the
Liouville equation
Lr0 ¼ 0:
ð15Þ
There is no longer any explicit time dependence
since o (ϵ, t) ¼ o (ϵ) and L ¼ o ϵð Þ @ϵ þ L for
this state. This solution is referred to as the homo-
geneous cooling state (HCS). Clearly, it is the close
analogue of the Gibbs state for a normal ﬂuid. It is
an example of a “normal” state in the sense that all
of its time dependence occurs through one of the
hydrodynamic ﬁelds (the energy). This concept is
sharpened below.
Macroscopic Balance Equations
The origins of a macroscopic description for a
ﬂuid are the balance equations for the average
mass density hm (r); ti, energy density he (r); ti,
and
momentum
density
hg
(r); ti,
where
r denotes an arbitrary ﬁeld point within the sys-
tem (Dufty and Brey 2005a). These will be
referred to as the hydrodynamic ﬁelds since
they are the ones that are expected to obey the
hydrodynamic equations under appropriate con-
ditions. The phase functions M (Γ, r), E (Γ, r), and
g (Γ, r) are well known and their explicit forms
will not be needed here. They will be denoted
collectively by AΑ (r)
aa r, t
ð
Þ $ m r
ð Þ, e r
ð Þ, g r
ð Þ
f
g:
ð16Þ
It follows from (8) that they obey the micro-
scopic balance equations (Dufty et al. 2007)
@t aa r, t
ð
Þ ¼ Laa r, t
ð
Þ ¼ ∇ ba r, t
ð
Þ  da2w r, t
ð
Þ:
ð17Þ
To obtain this result, it has been recognized that
the quantity –LAΑ(r, t) can be written as the sum of
a divergence ∇ bα(r, t) plus a remainder w(r, t)
that cannot be so represented. For a normal ﬂuid
w(r, t) vanishes and (17) become the local conser-
vation laws for mass, energy, and momentum. The
BΑ (r, t) are the corresponding ﬂuxes. This clariﬁes
why
AΑ (r, t) are selected for a macroscopic
description. Their time dependence is determined
by the scale of the spatial gradients of the ﬂuxes,
and averages of the latter become small as the
system approaches homogeneity. Consequently,
on long time scales the haα(r); ti are the only
surviving dynamical variables, and it is under
these conditions that these ﬁelds obey hydrody-
namic equations. The mass and momentum are
conserved for a granular ﬂuid as well, but there is
a loss of energy w(r, t) due to the non-conservative
forces. It is no longer obvious that the energy is
still one of the slow variables since its time scale is
coupled to w(r, t) which does not become small
for nearly homogeneous states. Thus, an addi-
tional requirement for the existence of a macro-
scopic description in terms of haα(r); ti is that the
time scale of he (r); ti/hw (r); ti must be larger
than that for nonhydrodynamic properties. This
issue is discussed further below.
The macroscopic balance equations follow
from the averages of (17)
@t aa r
ð Þ; t
h
i þ ∇ ba r
ð Þ; t
h
i
¼ da2 w r
ð Þ; t
h
i:
ð18Þ
These equations are formally exact, but of little
practical use as they do not form a closed (self-
deterministic) set of equations for haα(r); ti. Clo-
sure requires expressing the average ﬂux hbα(r); ti
and energy loss hw (r); ti as functionals of the
ﬁelds haα(r); ti. Such relationships are called
“constitutive equations”. The combination of the
exact balance equations with some form of con-
stitutive equations provides the most general def-
inition of hydrodynamics.
Construction of the constitutive equations is
simpliﬁed by extracting the effects of convection.
352
Granular Flows

The velocity U(r, t) of a cell at point r is deﬁned in
terms of the average momentum
g r
ð Þ; t
h
i  m r
ð Þ; t
h
i U r, t
ð
Þ:
ð19Þ
The ﬂuxes are functions of the positions and
velocities bα(r) ¼ bα (r; {qi, vi}) ¼ bα(r; {qi, Vi þ
U(r)}), where the velocity in the local rest frame
has been introduced, Vi ¼ vi  U(r, t). Then deﬁn-
ing the microscopic ﬂux in the rest frame by
b0
a r
ð Þ ¼ ba r; qi, Vi
f
g
ð
Þ it follows that the average
ﬂux has the form (McLennan 1989).
ba r
ð Þ; t
h
i ¼ b0
a r
ð Þ; t


þ caU r, t
ð
Þ 
b0
 r
ð Þ; t
D
E
þU r, t
ð
Þda
av r
ð Þ; t
h
i
f
g
ð
Þ:
ð20Þ
The ﬁrst term is the ﬂux of mass, energy, and
momentum in a ﬂuid element at rest, and repre-
sents the dissipative processes. The second and
third terms are proportional to the ﬂow velocity
U(r, T) and are associated with convection. The
coefﬁcients of these terms are explicit functions of
the ﬁelds haα(r); ti (as is U(r, t)). For a normal
ﬂuid, neglect of the rest frame ﬂuxes leads to the
perfect ﬂuid Euler hydrodynamic equations.
Hence, determination of the constitutive equa-
tions is reduced to expressing the rest frame ﬂuxes
and energy loss as functionals of the ﬁelds.
“Normal” States and Hydrodynamics
A hydrodynamic description is a closed set of
equations for the hydrodynamic ﬁelds, haα(r); ti.
This follows from the exact macroscopic balance
equations if the energy loss and ﬂuxes can be
represented as functionals of these ﬁelds
w r
ð Þ; t
h
i ! o rj aa; t
h
i
ð
Þ,
ba r
ð Þ; t
h
i ! ba rj aa; t
h
i
ð
Þ:
ð21Þ
The arrow is used to indicate that such a func-
tional representation need not be valid on all
length and time scales, and any such restrictions
constitute the domain of validity for hydrodynam-
ics. The notation here and below is such that
f (r, t, {haα(r); ti}) denotes a function of r, T and
of the ﬁelds haα(r); ti at the point r, while
f (r, t, | haα; ti) denotes a function of r, T and a
functional of the haα; ti at all space points. With
such constitutive relations the macroscopic bal-
ance Eqs. (18) become hydrodynamic equations
@t aa r
ð Þ; t
h
i þ ∇ b rj aa; t
h
i
ð
Þ ¼ da2o rj aa; t
h
i
ð
Þ:
ð22Þ
The average energy loss and ﬂuxes are aver-
ages of speciﬁc functions of the particle positions
and velocities, and hence are linear functionals of
the solution to the Liouville equation. The exis-
tence of constitutive equations is therefore related
to a special property of the solution which will be
called “normal” (this terminology originates in a
related context for derivation of hydrodynamics
from the Boltzmann kinetic equation (McLennan
1989)). The class of “normal” distributions is
deﬁned by the functional forms
rn G, t
ð
Þ ¼ rn
qij, vi
n
o
j aa; t
h
i


:
ð23Þ
All time dependence and all the breaking of
translational invariance for normal states occurs
only through the hydrodynamic ﬁelds. A familiar
example of a normal distribution for real ﬂuids is
the LOCAL Gibbs distribution
re‘ Gj aa; t
h
i
ð
Þ ¼ exp
q 
ð
drya r, t
ð
Þaa r
ð Þ

	
:
ð24Þ
Here Q is a normalization constant, and YΑ (r, T)
are conjugate ﬁelds determined by the requirement
that the averages of AΑ (r) give the speciﬁed values
haα(r); ti. In this way YΑ (r, t) are functionals of the
hydrodynamic ﬁelds and re‘ (Γ| haα; ti) is normal.
The importance of normal solutions is that they
yield directly the desired functionals of (21)
o rj aa; t
h
i
ð
Þ ¼
ð
dGrn Gj aa; t
h
i
ð
Þ w r
ð Þ
ð25Þ
ba rj aa; t
h
i
ð
Þ ¼
ð
dGrn Gj aa; t
h
i
ð
Þ ba r
ð Þ: ð26Þ
The normal state in (25) and (26) must be a
solution to the Liouville equation. In general, the
Granular Flows
353

time derivative in the Liouville equation can
be separated into that which occurs through
haα; ti
plus
the
residual
time
dependence,
generalizing (10)
r G, t
ð
Þ ¼ r G, tj aa; t
h
i
ð
Þ:
ð27Þ
The Liouville equation then becomes
@trj aa; t
h
i 
ð
dr
dr
d aa r
ð Þ; t
h
i
 ∇ ba r
ð Þ; t
h
i þ da2 w r
ð Þ; t
h
i
f
g þ Lr ¼ 0:
ð28Þ
A normal solution results when @trnj aa; t
h
i ! 0:
For speciﬁed ﬁelds, (28) becomes an equation for
the Γ dependence of the normal phase space den-
sity as a functional of the ﬁelds. This dependence
then allows determination of the normal forms
in (25) and (26). Finally, with the form of the
hydrodynamic equation determined at that point,
their solution with suitable initial and boundary
conditions provides the explicit forms for the
ﬁelds, and completes the normal solution. The
existence and determination of this solution is
the central problem for establishing a hydrody-
namic description for both normal and granular
ﬂuids.
The concept of a normal solution and its use in
the macroscopic balance equations makes no spe-
cial reference to whether the ﬂuid is atomic or
granular, and is not restricted to states near homo-
geneity. In this general context, hydrodynamics is
not a simple set of local partial differential equa-
tions such as the familiar Navier–Stokes equa-
tions. The latter are a special case of this more
general idea, and their inadequacy for some con-
ditions should not be interpreted as the absence of
a more complex hydrodynamic description.
In closing this Section a qualitative explana-
tion of why a normal solution can be expected
is given, by analogy with the similar expecta-
tion for atomic ﬂuids. For a wide class of initial
states there is a ﬁrst stage of rapid velocity
relaxation in each small region toward the uni-
versal homogeneous state (HCS or Gibbs,
respectively).
However,
the
hydrodynamic
parameters of that universal state are speciﬁc
to each region so it is only locally homogenous,
as in (24) for the atomic ﬂuid. Subsequently,
these differences in the parameters of neighbor-
ing cells are decreased by the ﬂuxes of mass,
energy, and momentum across their boundaries.
It is this second stage where a normal descrip-
tion in terms of the hydrodynamic ﬁelds can be
expected, indicating also that the space and
time scales for a hydrodynamic description
should be large compared to those of the ﬁrst
stage. This basic conceptual picture is essen-
tially the same for both atomic and granular
ﬂuids, and the rapid approach of the ﬁrst stage
is indeed observed in molecular dynamics sim-
ulation studies of both equilibrium and the
HCS.
Navier–Stokes Approximation
Equation (28) presents a formidable problem and
further progress requires specialization to speciﬁc
cases of interest. Perhaps the simplest of these are
weakly inhomogeneous states. These are states for
which all spatial gradients of ﬁrst order are small
and all higher order derivatives are negligible.
Small gradients means that the relative change in
the hydrodynamic ﬁelds over the largest micro-
scopic length scale ‘0 is small: ‘0@r ln haα; ti  1.
There are two characteristic length scales, the
mean free path and the grain diameter. For a dilute
gas the mean free path is largest, while for a dense
ﬂuid the grain size is largest. Under these condi-
tions a solution to the Liouville equation can be
sought as an expansion to leading order in these
small gradients. This will be referred to as the
Navier–Stokes approximation.
According to the discussion at the end of the
last section, a normal solution is expected after the
system has relaxed to its local HCS form, denoted
by r0‘(Γ| haα; ti), representing the ﬂuid as having
each cell in its own HCS. Deﬁne the deviations of
the hydrodynamic ﬁelds from some common ref-
erence value by
d aa; t
h
i ¼ aa; t
h
i  a0a,
ð29Þ
where A0Α is the same for all cells. Then, the local
HCS must satisfy the conditions
354
Granular Flows

r0‘ G a0a þ d aa; t
h
iÞ
j
jd aa; t
h
i¼0¼ r0 G; a0a
ð
Þ,

ð30Þ
@r0
@a0a
¼
ð
dr dr0‘ Gja0a þ d aa; t
h
i
ð
Þ
d aa r
ð Þ; t
h
i




d aa; t
h
i¼0
,   
ð31Þ
i.e., the local HCS and all of its functional deriva-
tives must agree with those of the HCS in the
homogenous limit. Also, as a normal distribution
its time dependence is through the exact hydrody-
namic ﬁelds for the ﬂuid state considered. This
means the averages of the corresponding micro-
scopic ﬁelds AΑ (r) for the local HCS and for the
solution to the Liouville equation must be the same
ð
dG r  r0‘
ð
Þaa r
ð Þ ¼ 0:
ð32Þ
A more complete discussion of the construc-
tion of r0‘ from knowledge of r0 is given else-
where (Dufty et al. 2007). For the purposes here
properties (30), (31), and (32) are sufﬁcient.
The local HCS distribution, r0‘, is not a solution
to the Liouville equation except in limit that all
hydrodynamic ﬁelds become the same for each
cell. Instead, it is a reference state approximating
the actual solution after its ﬁrst stage of velocity
relaxation. To construct a solution p deﬁne its devi-
ation from r0‘ by
r G, tj aa; t
h
i
ð
Þ ¼ r0‘ G, tj aa; t
h
i
ð
Þ
þ D G, tj aa; t
h
i
ð
Þ:
ð33Þ
The Liouville Equation (28) gives
@tD 
ð
dr0
dD
d aa r0
ð Þ; t
h
i
 ∇ ba r
ð Þ; t
h
i þ da2 w r
ð Þ; t
h
i
f
g þ LD
¼
ð
dr0
dr0‘
d aa r0
ð Þ; t
h
i
 ∇ ba r
ð Þ; t
h
i þ da2 w r
ð Þ; t
h
i
f
g  Lr0‘:
ð34Þ
This equation is still exact, but if only small
gradient states are considered it simpliﬁes by
retaining terms only of ﬁrst order in the gradients.
To be precise, the ultimate use of this solution is to
calculate local properties of the form
A r, tj ya tð Þ
f
g
ð
Þ
¼
ð
dGa G, r
ð
Þr G, tj aa r
ð Þ; t
h
i þ d aa; t
h
i
ð
Þ:
ð35Þ
Therefore, in the following analysis the gradi-
ent expansions are referred to the ﬁeld point r of
interest, haα; ti ¼ haα(r); ti þ δhaα; ti, i.e. the
common reference values in (29) are the exact
ﬁeld values at the chosen point, a0α ¼ haα(r); ti.
The gradient expansion is carried out relative to
these values. Of course the results will be general
and applicable to any choice for r.
The details of the gradient expansion are given
in the Appendix. The solution to the Liouville
equation to ﬁrst order in the gradients is
r G, tj aa; t
h
i
ð
Þ ¼ r0 G, aa r
ð Þ; t
h
i
ð
Þ þ 1  P
ð
Þ
 Mb G
ð , haa r
ð Þ; tiÞ þ
ðt
0
dt0 e ILþKT
ð
Þt0


bv

 1  P
ð
Þ Yv G
ð , haa r
ð Þ; tiÞ

 ∇ab r
ð Þ; t


:
ð36Þ
with the deﬁnitions
Mb ¼
ð
dr0
dr0‘
d aa r0
ð Þ; t
h
i


d aa; t
h
i¼0
r0,
ð37Þ
Ya ¼  IL þ KT


ab Mb:
ð38Þ
The generator for the dynamics IL þ KT has a
contribution from L which is the same as in (12),
with o evaluated for the HCS as a function of the
exact hydrodynamic ﬁelds at the point r and time
T.
L ¼ o0
aa r
ð Þ; t
h
i
ð
Þ@ e r
ð Þ; t
h
i þ L:
ð39Þ
The second contribution to the generator of the
dynamics is the transpose of the matrix KΑΒ
Kab ¼ da2 @o0
aa r
ð Þ; t
h
i
ð
Þ
@ ab r
ð Þ; t


:
ð40Þ
Finally, P is a projection operator
Granular Flows
355

PX ¼ Cb
ð
dGAbX,
Ab ¼ V1
ð
draa r
ð Þ,
Cb 
@r0
@ ab r
ð Þ; t


:
ð41Þ
The phase functions AΒ and Cβ form a
biorthogonal set in the sense
ð
dGAaCb ¼ dab:
ð42Þ
The AΑ are the usual global invariants of the
Liouville operator L for a normal ﬂuid; it is shown
in the Appendix that the Cβ are the invariants of
the new generator for dynamics in a granular ﬂuid
ILT þ KT


vb Cb ¼ 0:
ð43Þ
Equation (36) is not quite the normal solution
desired. All terms depend on time through haβ(-
r); ti as required, except for the last term which
has
an additional explicit time
dependence
through the upper limit of the time integral. This
time dependence becomes negligible if the inte-
grand is effectively non-zero after some short time
scale t. Then for t  t the time integral becomes
independent of T and can be taken formally to
inﬁnity. Thus, a normal solution is attained for
this time scale
rn G, aa r
ð Þ; t
h
i
ð
Þ ¼ r0 G, aa r
ð Þ; t
h
i
ð
Þ
þ 1  P
ð
Þ Mb G
ð , haa r
ð Þ; tiÞ

þ lim
t0!1
ðt0
0
dt0 e ILþKT
ð
Þt0


bv
 1  P
ð
ÞYv G
ð , haa r
ð Þ; tiÞÞ
∇ab r
ð Þ; t


:
ð44Þ
It is expected that the integrand should have
this property of a short time scale since the domain
of operation for the generator of time dependence
is functions with translational invariance (as a
consequence of the gradient expansion). Hence
there are no explicit slow hydrodynamic modes
of ﬁnite wavelength. Also, there is no contribution
from the homogeneous hydrodynamics (that for
the invariants) due to the orthogonal projection
1  P
ð
Þ. The appearance of this projection is an
essential self-consistency of the analysis, and
occurs as well for normal ﬂuids. The expres-
sion (44) is only formal and the actual limit should
be taken in the weak sense only after (36) has been
used to deﬁne average properties. A technical
complication is the occurrence of periodic time
dependence, the Poincare recurrence time. This
can be removed by considering the thermody-
namic limit of V ! 1, N ! 1 at constant
N/V. Therefore, averages using the normal solu-
tion to the Liouville equation are understood as
having the thermodynamic limit followed by the
long time limit at constant haα(r); ti.
An alternative equivalent form results from
performing the integral in (44) using the explicit
form (38) and the property (99) of the Appendix
rn G, aa r
ð Þ; t
h
i
ð
Þ ¼ r0 G, aa r
ð Þ; t
h
i
ð
Þ
þ lim
t0!1 1  P
ð
Þ e ILþKT
ð
Þt0


bv
Mv G, aa r
ð Þ; t
h
i
ð
Þ  ∇ab r
ð Þ; t


:
ð45Þ
The decay time for the integrand of (44) now
becomes the time after which (45) reaches its
normal form.
Constitutive Equations
The exact macroscopic balance equations are
given by (22), and the necessary constitutive
equations are given by (26) and (27) as averages
over the normal solution. These can be made more
explicit now using the small gradient result (44).
Since the latter is a local function of the ﬁelds, the
constitutive equations also will be local. Further-
more, since all components of the gradients
in (45) depend on the common value hg (r); ti,
this can be eliminated through a Galilean transfor-
mation so that all properties refer to a ﬂuid ele-
ment at rest. Of course, the gradients of hg (r); ti
in that ﬂuid element are nonzero.
356
Granular Flows

Consider ﬁrst the energy loss function o
o aa r
ð Þ; t
h
i
ð
Þ ¼
ð
dGrn G, aa r
ð Þ; t
h
i
ð
Þ w r
ð Þ
¼
ð
dGrn G, aa r
ð Þ; t
h
i
ð
Þ w:
ð46Þ
The coefﬁcients of the gradient in the normal
solution have translational invariance and the
average is independent of r, except through its
parametrization by haα(r); ti. The second equality
takes this into account by replacing w(r) by its
average w
w ¼ V1
ð
drw r
ð Þ:
ð47Þ
Since o (haα(r); ti) is a scalar, ﬂuid symmetry
restricts the contributions to ﬁrst order in the gra-
dients to
o
aa r
ð Þ; t
h
i
ð
Þ
¼ o0
aa r
ð Þ; t
h
i
ð
Þ þ o1
aa r
ð Þ; t
h
i
ð
Þ∇ U r, t
ð
Þ:
ð48Þ
Here, the ﬂow velocity U (r, t) of (19) has been
used in place of the momentum density. The ﬁrst
term is the contribution from the HCS distribution
o0
aa r
ð Þ; t
h
i
ð
Þ ¼
ð
dGr0 G, aa r
ð Þ; t
h
i
ð
Þ w: ð49Þ
The coefﬁcient of ∇ U(r, t) is
o1
aa r
ð Þ; t
h
i
ð
Þ ¼ lim
t0!1 Co t0, aa r
ð Þ; t
h
i
ð
Þ
¼ Co 0, aa r
ð Þ; t
h
i
ð
Þ
þ lim
t0!1
ðt0
0
@t0Co t0, aa r
ð Þ; t
h
i
ð
Þdt0
ð50Þ
with the correlation function deﬁned by
Co tð Þ ¼
ð
dGw 1  P
ð
Þ eLtMU,
ð51Þ
MU  1
3
ð
dr0r0 
dr0‘
dU r0, t
ð
Þ


d aa; t
h
i¼0
:
ð52Þ
The coefﬁcient o0 deﬁnes an “equation of state”
for the granular hydrodynamics, and gives the ﬁrst
non-trivial result of this analysis. It is similar to the
pressure (given below) and is an inherent property
of the local state of each cell, independent of the
gradients between cells. In contrast, o1 is a true
transport coefﬁcient characterizing communication
between cells. The ﬁrst equality of (50) provides
the Helfand form for this coefﬁcient, while the
second equality gives the equivalent Green–Kubo
form. Each has its practical utility, depending on the
method used for its approximate evaluation. Both
forms have proven useful for normal ﬂuids, and
further discussion is provided below. Both o0 and
the transport coefﬁcient o1 vanish for normal ﬂuids
since they characterize collisional energy loss.
The ﬂuxes βα of (26) can be determined in a
similar way. As indicated in (20), only the rest
frame ﬂux b0
a is required. Furthermore, since all
components of the gradients in (45) depend on the
common value hg (r); ti, this can be eliminated
through a Galilean transformation so that all prop-
erties refer to a ﬂuid element at rest. Of course, the
gradients of hg (r); ti in that ﬂuid element are
nonzero. The component b0
1 is the rest frame mass
ﬂux which is expected to vanish in order to give the
continuity equation. This follows from the fact that
b0
1 r
ð Þ is the microscopic momentum density
b0
1 ¼
ð
dGg r
ð Þr0 G, aa r
ð Þ; t
h
i
ð
Þ
þ lim
t0!1
ð
dGg r
ð Þ 1  P
ð
Þ   
ð
Þ ¼ 0
ð53Þ
The ﬁrst term vanishes since hg (r); ti ¼ 0 in
the rest frame, and the second term vanishes since
1  P
ð
Þ projects orthogonal to the mass, energy,
and momentum. Thus, the expected continuity
equation is veriﬁed.
The ﬂuxes b0
2 and b0
a for Α ¼ 3, 4, 5 are the rest
frame energy and momentum ﬂuxes. The energy
ﬂux transforms like a vector and therefore ﬂuid
symmetry (translational and rotational invariance)
Granular Flows
357

requires that it can depend only on gradients of
scalars
b0
2 ¼ l aa r
ð Þ; t
h
i
ð
Þ∇T r, t
ð
Þ
m
aa r
ð Þ; t
h
i
ð
Þ∇m r
ð Þ; t
h
i:
ð54Þ
To make the connection with Fourier’s law for
an atomic ﬂuid, a temperature T(r, t) has been
introduced through the deﬁnition
e r
ð Þ; t
h
i  e0
m r
ð Þ; t
h
i, T r, t
ð
Þ
ð
Þ:
ð55Þ
For an atomic ﬂuid the function e0(hm (r); ti,
T(r, t)) is chosen to be the thermodynamic internal
energy density. As there is no thermodynamics for
a granular ﬂuid this function is arbitrary and simply
constitutes a change of variables from he(r); ti,
hm(r); ti to T(r, t)), hm(r); ti. In this form (54) is
a generalization of Fourier’s law where l is the
thermal conductivity (Dufty 2007). The contribu-
tion from the gradient of the mass density is new to
granular ﬂuids (m ¼ 0 for atomic ﬂuids). These
coefﬁcients are given by
l
aa r
ð Þ; t
h
i
ð
Þ ¼ lim
t0!1 Cl t0, aa r
ð Þ; t
h
i
ð
Þ
¼ Cl 0, aa r
ð Þ; t
h
i
ð
Þ
þ lim
t0!1
ðt0
0
@t0Cl t0, aa r
ð Þ; t
h
i
ð
Þdt0
ð56Þ
m
aa r
ð Þ; t
h
i
ð
Þ ¼ lim
t0!1 Cm t0, aa r
ð Þ; t
h
i
ð
Þ
¼ Cm 0, aa r
ð Þ; t
h
i
ð
Þ
þ lim
t0!1
ðt0
0
@t0Cm t0, aa r
ð Þ; t
h
i
ð
Þdt0
ð57Þ
with the correlation functions
Cl tð Þ ¼ 1
3
ð
dGb0
2  1  P
ð
Þ e LþK22
ð
ÞtMT, ð58Þ
Cm tð Þ ¼ 1
3
ð
dGb0
2  1  P
ð
Þ
eLt
Mm þ K21
K22 MT


0
@
þ e LþK22
ð
Þt
@e0
@ m r
ð Þ; t
h
i  K21
K22


@T
@e0 j
m r
ð Þ; t
h
i
MT
1
A,
ð59Þ
MT 
ð
dr0r0
dr0‘
dT r0, t
ð
Þ


d aa; t
h
i¼0
:
ð60Þ
Mm 
ð
dr0r0
dr0‘
d m r0
ð Þ; t
h
i


d aa; t
h
i¼0
:
ð61Þ
Finally, the set of vectors b0
a for α ¼ 3, 4, 5
deﬁne the pressure tensor b0
a , Pij. Fluid sym-
metry then determines that it can couple only to
the momentum gradients, or equivalently the
ﬂow velocity gradients, in the form
Pij ¼ p aa r
ð Þ; t
h
i
ð
Þdij   aa r
ð Þ; t
h
i
ð
Þ

@iU j r, t
ð
Þ þ @ jUi r
ð , tÞ  2
3 dij∇ U r, t
ð
Þ


 k aa r
ð Þ; t
h
i
ð
Þdij∇ U r, t
ð
Þ:
ð62Þ
The scalar function p (haα(r); ti) is the pres-
sure, now identiﬁed as
p
aa r
ð Þ; t
h
i
ð
Þ ¼
ð
dGr0 G, aa r
ð Þ; t
h
i
ð
Þb0
3x: ð63Þ
The transport coefﬁcients in (62) are the shear
viscosity  (haα(r); ti) and the bulk viscosity
k (haα(r); ti) given by

aa r
ð Þ; t
h
i
ð
Þ ¼ lim
t0!1 C t0, aa r
ð Þ; t
h
i
ð
Þ
¼ C 0, aa r
ð Þ; t
h
i
ð
Þ
þ lim
t0!1
ðt0
0
@t0C t0, aa r
ð Þ; t
h
i
ð
Þdt0
ð64Þ
k
aa r
ð Þ; t
h
i
ð
Þ ¼ lim
t0!1 Ck t0, aa r
ð Þ; t
h
i
ð
Þ
¼ Ck 0, aa r
ð Þ; t
h
i
ð
Þ
þ lim
t0!1
ðt0
0
@t0Ck t0, aa r
ð Þ; t
h
i
ð
Þdt0
ð65Þ
with the correlation functions
358
Granular Flows

C tð Þ ¼
ð
dGb0
3y  1  P
ð
Þ eLtM,
ð66Þ
Ck tð Þ ¼
ð
dGb0
3x  1  P
ð
Þ eLtMk,
ð67Þ
M 
ð
dr0x0
dr0‘
dUy r0, t
ð
Þ


d aa; t
h
i¼0
:
ð68Þ
Mk 
ð
dr0y0
dr0‘
dUy r0, t
ð
Þ


d aa; t
h
i¼0
:
ð69Þ
This completes the formal derivation of the
constitutive equations leading to the nonlinear
Navier–Stokes equations, including expressions
for the cooling rate, energy ﬂux, and pressure
tensor including contributions up through ﬁrst
order in the gradients of the hydrodynamic
ﬁelds. These expressions are functions of the
hydrodynamic ﬁelds to be determined by their
detailed many-body analysis of the correlation
functions.
Green–Kubo Expressions
To contrast the results here with those for an
atomic ﬂuid, it is instructive to focus on the
Green–Kubo forms for the transport coefﬁcients
(McLennan 1989). These are given by the second
equalities of (50), (56), (57), (64), and (65); the
ﬁrst equalities are the corresponding Helfand
forms (Helfand 1960). For atomic ﬂuids there is
no counter part to o1 and m. However, there are
Green–Kubo expressions for the thermal conduc-
tivity and the two viscosities. For the discussion
here only the thermal conductivity is considered,
whose Green–Kubo expression is
l
aa r
ð Þ; t
h
i
ð
Þ ¼ Cl 0, aa r
ð Þ; t
h
i
ð
Þ
þ lim
t0!1
ðt0
0
@t0Cl t0, aa r
ð Þ; t
h
i
ð
Þdt0
ð70Þ
@tCl tð Þ ¼ 1
3
ð
dGb0
2
 1  P
ð
Þ e LþK22
ð
Þt Yl,
ð71Þ
Ye ¼  L þ K22
ð
ÞMe:
ð72Þ
In contrast the thermal conductivity for an
atomic ﬂuid is
l
aa r
ð Þ; t
h
i
ð
Þ ! lim
t0!1
ðt0
0
@t0Cl t0, aa r
ð Þ; t
h
i
ð
Þdt0
ð73Þ
@tCl tð Þ ! 1
3T2
ð
dGb0
2
 1  P
ð
Þ eLtb0
2re,
ð74Þ
In this last expression rE is the equilibrium Gibbs
ensemble, and it is understood that b0
2 is the micro-
scopic expression for the energy ﬂux for a dynamics
with conservative forces, and L is the Liouville
generator for the corresponding dynamics.
There are several similarities and differences
between the granular and atomic ﬂuid expressions
(Dufty et al. 2007). The latter is the time integral
of a energy ﬂux – energy ﬂux equilibrium time
correlation function. The granular ﬂuid is similar,
with one of the ﬂuxes the same but the other ﬂux is
generated from the local HCS state. Also, the
generator for the dynamics in the granular case
has two additional effects, L replaced by L þ K22,
to represents homogeneous cooling of the refer-
ence state and its homogeneous response to per-
turbations. The projection orthogonal to the
invariants of each dynamics
1  P
ð
Þ occurs in
both cases as a necessary condition for the long
time
limit
of
the
time
integral,
and
the
corresponding existence of the normal state.
Finally, the contribution from Cl(0, haα(r); ti)
vanishes for a normal ﬂuid (except for singular
forces) but is non-zero for the granular ﬂuid due to
the non-conservative forces.
Navier–Stokes Hydrodynamic Equations
In closing this section it is appropriate to record
the results of substituting the Navier–Stokes con-
stitutive equations, valid to ﬁrst order in the gra-
dients,
into
the
exact
macroscopic
balance
equations. This deﬁnes the Navier–Stokes hydro-
dynamic equations for a granular ﬂuid
Granular Flows
359

Dtm þ m∇r  U ¼ 0
ð75Þ
Dte0 þ o0 þ
p þ o1 þ
2
3   k


∇ U


∇ U
 @aUb þ @bUa


@aUb  ∇ l∇T þ m∇m
ð
Þ ¼ 0,
ð76Þ
DtUa þ m1@a p 
2
3  þ k


∇ U


m1@b @aUb þ @bUa


¼ 0:
ð77Þ
For simplicity of notation, m  hm (r); ti in
these equations. They are a set of ﬁve nonlinear
partial differential equations for the variables M,
E0, and U. They are a closed set of equations
since o0, P, and the transport coefﬁcients o1, l,
m, , and k are deﬁned as functions of these
variables. These deﬁnitions for the constitutive
equations are the primary accomplishment of the
statistical mechanical basis for the hydrody-
namic equations. The form of (64)–(65) could
have been guessed from the outset based on the
macroscopic balance equations and ﬂuid symme-
try. The underlying basis in the microdynamics
of the particles provides the necessary details for
how the parameters of these equations must
depend on the ﬁelds. Here only the formal deﬁ-
nitions have been identiﬁed. It is only the ﬁrst
half of the problem of completing these equa-
tions, as the evaluation of these deﬁnitions poses
a difﬁcult many body problem. Still, without this
ﬁrst half, the starting point for that detailed anal-
ysis would not be possible. This the case for
atomic ﬂuids as well.
Future Directions
The objective here has been to formulate the basis
for a macroscopic description of granular ﬂuids
using
the
fundamental
principles
of
non-
equilibrium statistical mechanics. The analysis
presented follows that for an atomic ﬂuid. First,
the exact macroscopic balance equations are iden-
tiﬁed. Next, their closure is linked to the concept
of a normal state and corresponding normal
solution to the Liouville equation. This deﬁnes
the domain of hydrodynamics in its most general
sense, both for atomic and granular ﬂuids. The
construction of a normal solution is quite difﬁcult
in general, but can be accomplished for states with
small gradients relative to locally homogeneous
conditions. This gives the Navier–Stokes approx-
imation described here.
Navier–Stokes hydrodynamics is applicable
for most common states of atomic ﬂuids, while
deviations occur primarily for more complex
polymeric molecular ﬂuids. The latter have rheo-
logical properties corresponding to larger gradi-
ents relative to additional microscopic length and
time scales. The construction of normal states in
these cases is more difﬁcult and is still at the semi-
phenomenological stage (Bird et al. 1977). Gran-
ular ﬂuids provide a new motivation for renewed
efforts to describe these more complex normal
states. The reason is that even structurally simple
granular ﬂuids composed of spherically symmet-
ric particles can exhibit rheology and other phe-
nomena beyond the Navier–Stokes domain of
validity (Santos et al. 2004; Hrenya 2007). This
is due to the cooling rate in the energy balance
equation which provides a new internal time scale,
that can set the size of hydrodynamic gradients
beyond any control through boundary conditions.
For example, new steady states are possible for
granular ﬂuids due to the balance of this internal
cooling with external forcing. In many cases this
implies
that
the
hydrodynamic
description
required is beyond the Navier–Stokes domain.
The understanding of constitutive equations in
these cases is poor at this point. It is hoped that
the formal structure described here will provide
the
appropriate
basis
for
studies
of
these
problems.
The context of hydrodynamics depends on the
formation of a normal state from more complex
conditions. Above this has been described quali-
tatively as a two stage process of rapid velocity
relaxation in each cell to a state near the local
HCS,
followed
by hydrodynamic
relaxation
through exchange of mass, energy, and momen-
tum between the cells on a longer time scale. This
360
Granular Flows

separation of microscopic and hydrodynamic time
scales is essential to the dominance of the hydro-
dynamic excitations over all others at large space
and time scales. It is justiﬁed for atomic ﬂuids
since the hydrodynamic times are determined by
the wavelength of the phenomena studied. As the
system
approaches
homogeneity,
these
time
scales become much larger than the microscopic
excitations and hydrodynamics prevails at large
times. However, there is an additional hydrody-
namic time scale for granular ﬂuids, the cooling
rate, which is not set by the wavelength alone. It
would seem that this additional time scale must be
large as well, implying a weak cooling rate. This
condition is too strong. What matters is the rate of
the approach to the homogeneous state, not any
dynamics of that ﬁnal state. In the above deriva-
tion of hydrodynamics the ﬁnal form for the solu-
tion to the Liouville equation, Eq. (44) or (45), has
a dynamics generated by IL þ KT rather than
simply that for the trajectories L. This is signiﬁ-
cant since the former has the additional compen-
sation for the cooling and for the homogeneous
perturbations of that cooling. Hence the approach
to the time dependent normal state is determined
only by the remaining non-hydrodynamic relaxa-
tion. The time scale for relaxation to the normal
state is independent of the hydrodynamic time
scales of that normal state. Quantitative veriﬁca-
tion of these concepts is another important future
direction for research on a hydrodynamic descrip-
tion for granular ﬂuids.
Acknowledgments The author is indebted to Professor
J. Javier Brey and Dr. Aparna Baskaran of Syracuse Uni-
versity for their collaboration on closely related linear
response methods for granular ﬂuids.
Appendix
Gradient expansion In this Appendix the Liouville
equation in the form (34) is written to ﬁrst order in
the gradients and solved. Also the invariants of the
associated dynamics are identiﬁed.
Consider ﬁrst the right side of (34) which can
be written equivalently as
ð
dr0
dr0‘
d aa r0
ð Þ; t
h
i
∇ ba r
ð Þ; t
h
i
n
þ da2 w r
ð Þ; t
h
i
o
 Lr0‘
¼ 
ð
dr0
dr0‘
d aa r0
ð Þ; t
h
i Laa r0
ð Þ; t
h
i  Lr0‘
¼
ð
dr0
dr0‘
d aa r0
ð Þ; t
h
i
ð
dGaa r
ð ÞL r0‘ þ Δ
ð
Þ
Lr0‘:
ð78Þ
The ﬁrst equality follows from (17) and (21).
The ﬁrst two terms are determined by the local
HCS which can be expanded to ﬁrst order in the
gradients
r0‘ ¼ r0
aa r
ð Þ; t
h
i
ð
Þ
þ
ð
dr0
dr0‘
d aa r0
ð Þ; t
h
i


d aa; t
h
i¼0
 aa r0
ð Þ; t
h
i  aa r
ð Þ; t
h
i
ð
Þ þ . . .
¼ r0
aa r
ð Þ; t
h
i
ð
Þ
þmb r, aa r
ð Þ; t
h
i
ð
Þ  ∇aa r
ð Þ; t
h
i þ . . .
ð79Þ
The functional derivatives are
dr0‘
d aa r0
ð Þ; t
h
i


d aa; t
h
i¼0
¼ d r0  r
ð
Þ @r0
aa r
ð Þ; t
h
i
ð
Þ
@ aa r
ð Þ; t
h
i

þ @mb r, aa r
ð Þ; t
h
i
ð
Þ
@ aa r
ð Þ; t
h
i
 ∇hab r
ð Þ; ti

þma r, aa r
ð Þ; t
h
i
ð
Þ  ∇d r0  r
ð
Þ þ . . .
ð80Þ
Here,
mb r, aa r
ð Þ; t
h
i
ð
Þ

ð
dr0
dr0‘
d ab r0
ð Þ; t


 
!
d aa; t
h
i¼0
r0  r
ð
Þ,
ð81Þ
and r0(haα(r); ti) is the actual HCS with its global
density, energy, and momentum evaluated at the
common values haα(r); ti. It follows from (32)
that the averages of AΑ (r) for r, r0‘, and r0 are all
the same. This in turn gives
Granular Flows
361

ð
dGaa r
ð Þmb ¼ 0 ¼
ð
dGaa r
ð ÞD:
ð82Þ
With these results and the fact that Δ is of ﬁrst
order in the gradients, (78) to ﬁrst order in the
gradients becomes
ð
dr0
dr0‘
d aa r0
ð Þ; t
h
i
∇ ba r
ð Þ; t
h
i
n
þ da2 w r
ð Þ; t
h
i
o
 Lr0‘
! Lr0  1  P
ð
Þ 1L þ KT


abmb  ∇aa; t
h
i
þ PLΔ:
ð83Þ
The matrix KT is the transpose of K.
Kab ¼ da2 @o aa r
ð Þ; t
h
i
ð
Þ
@ ab r
ð Þ; t


,
ð84Þ
and I is the unit matrix. The generator L is the same
as that of (12) with o ! o0(haα(r); ti) for the HCS
evaluated at the common values haα(r); ti
L ¼ o0
aa r
ð Þ; t
h
i
ð
Þ@ e r
ð Þ; t
h
i þ L:
ð85Þ
Finally, P is the projection operator
PX ¼
@r0
@ aa r
ð Þ; t
h
i
ð
dGaa r
ð ÞX:
ð86Þ
The ﬁrst term of (83) vanishes by deﬁnition of
the HCS, r0, conﬁrming that the right side of the
Liouville Eq. (34) is of ﬁrst order in the
gradients.
At this point, the Liouville Eq. (34) becomes
@tD 
ð
dr0
dD
d a2 r0
ð Þ; t
h
i o0
aa r0
ð Þ; t
h
i
ð
Þ þ PLD
¼ 1  P
ð
ÞY0
a  ∇aa; t
h
i,
ð87Þ
Y0
a   IL þ KT


abmb:
ð88Þ
This equation is still exact up through contri-
butions of ﬁrst order in the gradients. It has solu-
tions of the form
D G, tj aa r
ð Þ; t
h
i
ð
Þ ¼ Gv G, t, aa r
ð Þ; t
h
i
ð
Þ
 ∇av r
ð Þ; t
h
i,
ð89Þ
Substitution into (87) gives the corresponding
equation for Gv
@tGv þ 1  P
ð
Þ 1L þ KT


vbGb ¼ 1  P
ð
ÞY0
v, ð90Þ
with the solution
Gv G, t, aa r
ð Þ; t
h
i
ð
Þ
¼
ðt
0
dt0 e 1P
ð
Þ 1LþKT
ð
Þt0


vb 1  P
ð
ÞY0
b:
ð91Þ
It is possible to add to (87) an arbitrary solution
to
the
homogeneous
equation
corresponding
to (90). As described in the text, this represents the
dynamics of the ﬁrst stage of rapid velocity relaxa-
tion to the local HCS. The interest here is in the
second stage where possible formation of a normal
solution occurs. Hence, it is simpler to choose that
stage for initial conditions (initial local HCS).
Deﬁne the derivatives of the HCS by
Cb G, aa r
ð Þ; t
h
i
ð
Þ 
@r0
@ ab r
ð Þ; t

 :
ð92Þ
Then differentiate the equation for r0
@
@ ab r
ð Þ; t

 Lr0 ¼ 0,
ð93Þ
to get
ILT þ KT


vbCb ¼ 0:
ð94Þ
Since
ILT þ KT


is the generator for the
dynamics in (91) this shows that Cβ are the invari-
ants of that dynamics.
The projection operator P in (95) acts only on
phase functions with translational invariance. In
that case (86) simpliﬁes to
PX ¼ Cb
ð
dGAbX,
Ab ¼ V1
ð
draa rð Þ:
ð95Þ
The ﬁrst equality of (82) becomes Pmb ¼ 0.
This in turn gives
362
Granular Flows

mb ¼ 1  P
ð
Þ mb ¼ 1  P
ð
Þ Mb,
Mb 
ð
dr0
dr0‘
d aa r0
ð Þ; t
h
i


d aa; t
h
i¼0
r0:
ð96Þ
Then 1  P
ð
ÞY0
a simpliﬁes to
1  P
ð
ÞY0
a ¼  1  P
ð
Þ IL þ KT


ab 1  P
ð
ÞMb
 1  P
ð
ÞYa
ð97Þ
with
Ya ¼  IL þ KT


abMb:
ð98Þ
Use has been made of the identity
1  P
ð
Þ 1L þ KT


P ¼ 0:
ð99Þ
This same identity leads to a simpliﬁcation of
the dynamics in (91)
e 1P
ð
Þ 1LþKT
ð
Þt0 1  P
ð
Þ
¼ 1  P
ð
Þe 1LþKT
ð
Þt0 1  P
ð
Þ:
ð100Þ
In summary, the solution to the Liouville equa-
tion to ﬁrst order in the gradients is
r G, tj aa; t
h
i
ð
Þ ¼ r0 G, aa r
ð Þ; t
h
i
ð
Þ
þ 1  P
ð
Þ Mb G
ð , haa r
ð Þ; tiÞ

þ
ðt
0
dt0 e ILþKT
ð
Þt0


vb
 1  P
ð
ÞYb G
ð , haa rð Þ; tiÞ

∇av rð Þ; t
h
i:
ð101Þ
Bibliography
Primary Literature
Bird R, Armstrong R, Hassager O (1977) Dynamics of
polymeric liquids. Wiley, New York
Bizon
C,
Shattuck
MD,
Swift
JB,
Swinney
HL
(1999) Transport coefﬁcients for granular media from
molecular dynamics simulations. Phys Rev E 60:
4340–4351; Rericha EC, Bizon C, Shattuck MD,
Swinney HL (2001) Shocks in supersonic sand. Phys
Rev Lett 88:014302
Brey JJ, Dufty JW, Santos A (1997) Dissipative dynamics
for hard spheres. J Stat Phys 87:1051–1066
Brey JJ, Dufty JW, Kim CS, Santos A (1998) Hydrody-
namics for granular ﬂow at low density. Phys Rev E 58:
4638–4653; Sela N, Goldhirsch I (1998) Hydrody-
namic equations for rapid ﬂows of smooth inelastic
spheres, to Burnett order. J Fluid Mech 361:41–74
Brey JJ, Ruiz-Montero MJ, Moreno F, Garcia-Rojo
R
(2002)
Transversal
inhomogeneities
in
dilute
vibroﬂuidized granular ﬂuids. Phys Rev E 65:061302;
Brey JJ, Ruiz-Montero MJ, Moreno F (2001) Hydro-
dynamics of an open vibrated granular system. Phys
Rev E 63:061305
Brey JJ, Ruiz-Montero MJ, Maynar P, Garzia de Soria MI
(2005) Hydrodynamic modes, Green–Kubo relations,
and velocity correlations in dilute granular gases.
J Phys Cond Mat 17:S2489–S2502
Brilliantov N, Pöschel T (2004) Kinetictheory of granular
gases. Oxford/New York
Dufty JW (2000) Statistical mechanics, kinetic theory, and
hydrodynamics for rapid granular ﬂow. J Phys Condens
Matter 12:A47–A56
Dufty JW (2001) Kinetic theory and hydrodynamics for a
low density gas. Adv Complex Syst 4:397–407. cond-
mat/0109215.201
Dufty JW (2005) Some aspects of the Boltzmann equation
for granular gase. In: Capitelli M (ed) Rareﬁed gas
dynamics
(AIP
conference
proceedings
762,
New York). pp 789–796
Dufty JW (2007) Fourier’s law for a granular ﬂuid. J Phys
Chem B 111:15605–15612
Dufty JW, Brey JJ (2002) Green–Kubo expressions for a
low density granular gas. J Stat Phys 109:433–448.
cond-mat 0201361
Dufty J, Brey JJ (2005a) Origins of hydrodynamics for a
granular gas. In: Pareschi L, Russo G, Toscani G (eds)
Modelling and numerics of kinetic dissipative systems.
Nova Science, New York, pp 17–30. cond-mat/
0410133
Dufty JW, Brey JJ (2005b) Hydrodynamic modes for gran-
ular gases. Phys Rev E 68:030302; Brey JJ, Dufty JW
(2005) Hydrodynamic modes for a granular gas from
kinetic theory. Phys Rev E 72:011303
Dufty JW, Brey JJ, Lutsko J (2002) Diffusion in a granular
ﬂuid. I. Theory Phys Rev E 65:051303; Lutsko J, Dufty
JW, Brey JJ (2002) Diffusion in a granular ﬂuid.
II. Simulation. Phys Rev E 65:051305; Dufty JW,
Garzó V (2001) Mobility and diffusion in granular
ﬂuids. J Stat Phys 105:723–744
Dufty JW, Baskaran A, Brey JJ (2006) Linear response for
a granular ﬂuid. JSTAT L08002:1–8
Dufty JW, Baskaran A, Brey JJ (2007) Linear response and
hydrodynamics for granular ﬂuids. Phys Rev E77,
031310; Baskaran A, Dufty JW, Brey JJ (2007) Trans-
port coefﬁcients for the hard sphere granular ﬂuid. Phys
Rev E77, 031311
Haff PK (1983) Grain ﬂow as a ﬂuid mechanical phenom-
enon. J Fluid Mech 134:401–430
Granular Flows
363

Hansen J-P, McDonald I (1986) Theory of simple liquids.
Elsevier Press, London
Helfand E (1960) Transport coefﬁcients from dissipation in
a canonical ensemble. Phys Rev 119:1–9
Here the Navier–Stokes approximation is deﬁned by cal-
culating the cooling rate, energy ﬂux, and momentum
ﬂux to ﬁrst order in the gradients. However, the ﬂuxes
occur under a gradient in the macroscopic balance
equations while the cooling rate does not. Hence the
equations themselves do not have all terms to second
order in the gradients (i.e., the additional terms of
second order contributing to the cooling rate)
Hrenya C (2007) Private communication, and to be
published
Huan C, Yang X, Candela D, Mair RW, Walsworth RL
(2004) NMR experiments on a three-dimensional
vibroﬂuidized granular medium. Phys Rev E 69:041302
Kadanoff LP (1999) Built upon sand: theoretical ideas
inspired by granular ﬂows. Rev Mod Phys 71:435–444
McLennan JA (1989) Introduction to nonequilibrium sta-
tistical mechanics. Prentice-Hall, Englewood Cliffs
Resibois P, De Leener M (1977) Classical kinetic theory of
ﬂuids. Wiley, New York
Santos A, Garzo V, Dufty JW (2004) Inherent rheology of a
granular ﬂuid in uniform shear ﬂow. Phys Rev E 69:
061303. condmat 0309320
See for example articles (2002) In: Halsey T, Metha A (eds)
Challenges in granular physics. World Scientiﬁc,
Singapore
See, for instance, Brey JJ, Ruiz-Montero MJ, Cubero
D (1999) On the validity of linear hydrodynamics for
low-density
granular
ﬂows
described
by
the
Boltzmann equation. Europhys Lett 48:359–364;
Brey JJ, Ruiz-Montero MJ, Cubero D, García-Rojo
R (2000) Self-diffusion in freely evolving granular
gases. Phys Fluids 12:876–883; Garzó V, Montanero
JM (2002) Transport coefﬁcients of a heated granular
gas.
Physica
A
313:336–356;
Montanero
JM,
Santos A, Garzò V (2005) DSMC evaluation of the
Navier–Stokes shear viscosity of a granular ﬂuid. In:
Capitelli M (ed) Rareﬁed Gas Dynamics 24 (AIP Conf
Proc, vol 72), pp 797–802
See, for instance, Goldhirsch I, Tan ML, Zanetti G (1993)
A molecular dynamical study of granular ﬂuids: the
unforced
granular
gas.
J
Sci
Comput
8:1–40;
McNamara S, Young WR (1996) Dynamics of a freely
evolving, two-dimensional granular medium. Phys Rev
E 53:5089–5100; Deltour P, Barrat JL (1997) Quantita-
tive study of a freely cooling granular medium. J Phys
I 7:137–151
Van Noije TPC, Ernst MH (2001) Kinetic theory of gran-
ular gases. In: Pöschel T, Luding S (eds) Granular
gases. Springer, New York
Books and Reviews
Brilliantov N, Pöschel T (2004) Kinetic theory of granular
gases. Oxford, New York
Campbell CS (1990) Rapid granular ﬂows. Ann Rev. Fluid
Mech 22:57–92
Campbell CS (2002) Granular shear ﬂows in the elastic
limit. J Fluid Mech 465:261–291
Coniglio A, Fierro A, Herrmann H, Nicodemi M (eds)
(2004) Unifying concepts in granular media and
glasses. Elsevier, Amsterdam
Dufty JW (2007) Nonequilibrium statistical mechanics and
hydrodynamics for a granular ﬂuid. Six lectures at the
Second
Warsaw
School
on
Statistical
Physics.
Kazimierz, Poland. arXiv:0707.3714
Duran J (2000) Sands, powders, and grains: an introduc-
tion to the physics of granular materials. Springer,
New York
Goldhirsch I (2003) Rapid granular ﬂows. Annu Rev Fluid
Mech 35:267–293
Halsey T, Metha A (eds) (2002) Challenges in granular
physics. World Scientiﬁc, Singapore
Hinrichsen H, Wolf D (eds) (2004) The physics of granular
media. Wiley-VCH, Berlin
Jaeger HM, Nagel SR, Behringer RP (1996) Granular
solids,
liquids,
and
gases.
Rev
Mod
Phys
68:
1259–1273
Mehta A (ed) (1993) Granular matter, an interdisciplinary
approach. Springer, New York
Pöschel T, Brilliantov N (eds) (2003) Granular gases
dynamics. Springer, New York
Pöschel T, Luding S (eds) (2001) Granular gases. Springer,
New York
Pöschel T, Schwager T (2005) Computational granular
dynamics:
models
and
algorithms.
Springer,
New York
364
Granular Flows

Statistical Mechanics of
Clogging
I. Zuriguel and A. Garcimartín
Dpto. de Física y Mat. Apl. Facultad de Ciencias,
Universidad de Navarra, Pamplona, Spain
Article Outline
Glossary
Deﬁnition of the Subject
Introduction
Clogging
Unclogging
Summary and Discussion
Future Directions
Bibliography
Glossary
Arch Set of mutually stabilizing particles, mean-
ing that if any one of them is removed the
whole set will collapse.
Clogging Halt of the ﬂow of macroscopic parti-
cles caused by the development of a local
structure (an arch in two dimensions or a
dome in three) which brings the whole system
to a rest state.
Granular matter Material composed of inde-
pendent, macroscopic particles that interact
solely by contacts or collisions. As the latter
are intrinsically dissipative, energy is not con-
served, and therefore, the system typically
adopts metastable conﬁgurations.
Granular Silo Container in which granular mat-
ter is stored. The emptying of silos is generally
performed through an oriﬁce at the bottom,
although other alternatives (such as the dis-
charge through lateral oriﬁces or by means of
extraction belts) are also possible.
Unclogging Destabilization of a clogging arch
by means of an energy input which must be
external for the case of inert granular media,
but can be also internal for other systems such
as active matter.
Definition of the Subject
Clogging is deﬁned as an arrest of the ﬂow of
macroscopic particles caused by the formation
of a local arrangement that is generally meta-
stable. Usually, clogging occurs at bottlenecks
when the neck-to-particle size ratio is slightly
above the unity. Although clogs may appear in
a wide variety of systems – such as cells, col-
loids, or live beings – we will focus here on
clogging in granular matter as a prototypical
and simple case. Understanding clogging in
granular systems is important from the indus-
trial
and
environmental
viewpoint.
Indeed,
clogging in silos or hoppers may completely
halt a production line in food or pharmaceutical
industries. Also, a safe and efﬁcient handling of
raw materials in mining is important to prevent
environmental harm and to reduce production
costs. But even in granular matter, understand-
ing clogging poses a tough challenge as the
arch formation is essentially a local phenome-
non that drives the whole system to a sudden
arrest. Contrary to other physical processes like
jamming, the deﬁnition of average magnitudes –
such as volume fraction, for instance – is not
straightforward.
Clogging is intimately related to the formation
of arches and their stability. Therefore, introduc-
ing an excitation at the outlet or nearby can be a
suitable strategy to destroy the clog and resume
the ﬂow. Thus, when a vibration is applied at the
bottom of a silo, the ﬂow may become intermittent
resembling the dynamics observed in other active
systems ﬂowing through constrictions. The phys-
ics underlying clogging,
on one side, and
unclogging, on the other side, is not the same, as
© Springer Science+Business Media, LLC, part of Springer Nature 2022
B. Chakraborty (ed.), Statistical and Nonlinear Physics,
https://doi.org/10.1007/978-1-0716-1454-9_746
Originally published in
R. A. Meyers (ed.), Encyclopedia of Complexity and Systems Science, © Springer Science+Business Media LLC 2020
https://doi.org/10.1007/978-3-642-27737-5_746-1
365

revealed by the different nature of their statistical
properties. In the following sections we will deep
into this question and others, such as the argu-
ments on the existence or not of a critical outlet
size above which clogging is not possible, a sub-
ject discussed since mid last century.
Introduction
The dense ﬂow of granular materials through a
narrowing is a complex situation. At the bottle-
neck, the system undergoes a transition from ﬂuid
like behavior (above the opening) to gas like
behavior (after the neck, where the contacts
among particles are sparse). This ﬂow becomes
even more complicated when the aperture is only
a few times larger than the typical particle size; in
this scenario there exists the possibility that a
metastable structure forms spanning the whole
outlet, causing a complete arrest of the grains.
Although by the end of the last century an
abundant number of devices were created – and
even patented – to prevent clogging, the problem
fundamentals were only scarcely studied at that
time. As a matter of fact, most of the works were
aimed at determining the size of the outlet that
guaranteed a continuous ﬂow through the silo
outlet (Arnold and McLean 1976; Drescher et al.
1995; Jenike 1964; Walker 1966). Conversely,
there was a remarkable interest on investigating
the ﬂow properties in the silo discharge; the focus
was mostly put on the ﬂow rate dependence on the
outlet size (Beverloo et al. 1961). In most cases,
the oriﬁces were large enough to prevent clog-
ging, which was considered as an aside problem
to be avoided. Indeed, from an applied point of
view, clogging avoidance was the main concern at
that time and this is reﬂected on the focus of the
investigations that were performed.
In the last two decades, the study of clogging in
granular silos has regained the attention of the
scientiﬁc community. Among others, two reasons
may be pointed out for this appealing. First, clog-
ging is an apparently simple everyday problem
(we all have to shake the saltcellar to pour salt in
our food) with a fundamental interest, where deep
questions arise, and it is accessible to researchers
with limited resources. Second, given the inert
nature of the grains, clogging in silos has been
taken as a standard against which to compare
clogging in other, more complex systems. As
examples, we pinpoint the ﬂow through bottle-
necks of colloids, microbial populations, mechan-
ically self-driven robots, suspensions, pedestrians,
animals, and other kinds of active matter. Given the
different nature of the particles composing these
systems, it becomes obvious that the analogies are
only qualitative; despite this, some of the models
and analytical approaches introduced for the gran-
ular case can be used as a starting point for more
sophisticated elaborations pertinent to those other
systems.
Remarkably, the number of applications in
which clogging is a paramount concern is much
larger if all these related many-body systems are
included. For example, clogging of a dense micro-
particle suspension can occlude microchannel
constrictions, a behavior that is exploited in med-
icine to provoke embolization of blood vessels in
order to shrink a tumor. Besides, the formation of
clogs in suspensions of larger particles is crucial in
determining the lifetime of subsurface ﬂow treat-
ments, a widely used alternative to remove pollut-
ants from wastewater. Similarly, clogging of
suspended hydrated particles is a major issue
concerning oil and gas transport through pipe-
lines. A reasonable understanding of clogging is
also necessary to guarantee a good performance of
slit-structures, which are rigid barriers with one or
more slits built in craggy mountains to reduce
avalanche hazard. Last but not least, clogging
has also occasionally happened in crowds trying
to evacuate enclosed areas in highly competitive
and dire situations.
In all the examples given above, a geometrical
constriction (i.e., a bottleneck) is at play. How-
ever, it has been recently shown that this speciﬁc
geometry is not imperative to observe clogging.
Indeed, if the particles are sufﬁciently conﬁned, a
blockage may also show up in a straight channel.
This happens for instance in underground min-
ing, where raw materials driven by gravity are
conveyed through vertical pipes from one level
of the mine to another. In this case, the blocking
arches do not rest on the silo bottom or hopper
366
Statistical Mechanics of Clogging

walls, but lean against the vertical walls of the
pipe. This is possible due to frictional forces, and
the effect is magniﬁed because of the geometrical
frustration introduced by the ﬂat faceted stones
that are typically transported in these channels.
Although here we will focus on the bottleneck
geometry, several works about clogging in
straight channels and obstacle arrays – an inter-
esting conﬁguration that may turn out to be use-
ful for linking clogging and jamming behavior –
will also be described.
Clogging
Clogging as a Stochastic Process
Let us consider a container full of grains
discharged through an oriﬁce at the bottom
which is only a few times larger than the typical
particle size. In this scenario, the probability that a
clogging arch develops is constant over time, that
is, it is a Poisson process. This fact implies that:
1. There is no way to predict exactly when the
system will get clogged.
2. Clogging is a history independent process:
even if the system has been ﬂowing for a lot
of time, the probability of getting clogged
remains the same.
3. If we deﬁne the avalanche size as the number
of grains ﬂowing out the silo before an arch
clogs it, the distribution of these sizes will
follow an exponential tail.
4. There is no correlation among the size of con-
secutive avalanches.
5. The average avalanche size is well deﬁned.
The ﬁrst evidence of the exponential nature of
the avalanche size distribution was reported by
Clément et al. (2000) as shown in Fig. 1. Subse-
quently, Zuriguel et al. corroborated this feature
and provided an interpretation in terms of a prob-
abilistic model (Zuriguel et al. 2003). The idea
was to assign the same probability of clogging pc
to all particles inside the silo. Therefore, the prob-
ability that a particle passes through the outlet
without forming a clog can be written as pp ¼ 1 –
pc, and the probability of getting an avalanche of
s particles can be described by Eq. 1 (note that the
original equation proposed was n sð Þ ¼ ps
p p2
c as it
was considered also the precedent clogging event
but it was posteriorly (Zuriguel et al. 2005)
corrected to Eq. 1).
n sð Þ ¼ ps
p pc
ð1Þ
That is, the probability of getting an avalanche
of size s is obtained by multiplying s times the
probability that a particle passes through the exit
and one time the probability that the particle clogs
it. This deﬁnition allows a straightforward con-
nection
between
the
ﬁrst
moment
of
the
Statistical Mechanics of
Clogging, Fig. 1 Rescaled
mass distributions of
avalanches for different
outlet sizes a, as indicated in
the legend. Pa(M) is the
probability density for an
avalanche with mass M for
an outlet size a. The average
avalanche mass is hMai.
The solid line displays an
exponential decay.
(Reprinted from Clément
et al. (2000))
Statistical Mechanics of Clogging
367

distribution (the mean avalanche size) and pc
(Janda et al. 2008):
sh i ¼ pp
pc
ð2Þ
In most of the scenarios investigated the ava-
lanches are larger than about 100 particles. In this
case pp ’ 1, and therefore sh i ’ p1
c .
Another salient feature reported in Zuriguel
et al. (2003) was the apparent lack of correlation
among the size of consecutive avalanches (see
Fig. 2). If we accept the hypothesis of lack of
memory in the passage of particles within a single
avalanche, it is not surprising that the statistics of
consecutive avalanches are independent.
Although the probabilistic model leading to
Eq. 1 was obtained by assigning to each particle
a given probability of forming a clog, the same
reasoning is valid if groups of particles are con-
sidered instead, as stated in Zuriguel et al. (2003).
Indeed, it is obvious that the development of a
clogging arch is a process involving several par-
ticles. In order to account for this issue, Masuda
et al. (2014) devised a model in which the arch
formation region was split into discrete sites that
can contain at most one particle. By deﬁning a
particle inﬂow rate a and different outﬂow rates
depending on the occupancy of neighboring sites
(see Fig. 3), different dynamics were observed
including ﬂow intermittency and clog formation.
The later occurred when all sites were ﬁlled.
Remarkably, this model recovers the exponential
distribution of avalanche sizes.
A similar approach of dividing the space in cells
was in fact implemented a decade before by
Helbing and coworkers in a work (Helbing et al.
2006) where they presented an analytical model
which served for both granular bottleneck ﬂows
and
pedestrian
escape
dynamics
through
a
narrowing. Based on a continuity equation in
polar coordinates, they observed shockwaves
nt
100
101
102
103
nt+1
100
101
102
103
Statistical Mechanics of Clogging, Fig. 2 First return
map of avalanche sizes, that is, the avalanche size nt + 1
vs. the previous avalanche size nt, where t is a correlative
index ordering the sequence of avalanches. (Reprinted
from Zuriguel et al. (2003))
368
Statistical Mechanics of Clogging

when the inﬂow exceeds the maximum outﬂow.
More importantly for the case we are analyzing
here, their model gave rise to three different
regimes depending on the exit size: no ﬂow for
small exits, intermittent ﬂow for medium size
doors, and continuous ﬂow for large enough open-
ings. In the intermittent ﬂow scenario, exponen-
tially distributed avalanche sizes were reported in
good agreement with experimental data.
Up to now, we have described several works
where the exponential distribution of avalanche
sizes is observed and explained in different, but
similar, ways. All share the idea that clogging is a
stochastic process where the probability of a clog
depends on the outlet size, as will be explained
below. The exponential distribution of avalanches
is considered as a hallmark of the ﬂow of discrete
particles through bottlenecks and has been also
reproduced by many authors in different geome-
tries and scenarios (Kondic 2014; Pérez 2008;
Sheldon and Durian 2010). Nevertheless, there is
an exception to this accepted rule: when the oriﬁce
is strongly asymmetric the avalanche statistics
resemble more a power law than an exponential
distribution. This was discovered by Saraf and
Franklin when working with wedge hoppers hav-
ing an oriﬁce that was around 20 times longer than
wider (Saraf and Franklin 2011). The explanation
given for this feature assumed that the clogging
probability of strings of particles depends on their
orientation. By considering a uniform distribution
of probabilities and integrating over all the allow-
able string orientations, an expression is obtained
for the avalanche size distribution that depends on
the exit geometry. In particular, the well-known
exponential distribution is generated for isometric
(round) oriﬁces, whereas for anisometric exits the
expression tends to an asymptotic value that
scales as n(s) ~ s2.
Does a Critical Outlet Size Exist?
The supply of a continuous ﬂow of grains through
the oriﬁce (i.e., preventing clog formation) was
the ambition of the pioneering engineers who
studied silo clogging. For this reason, the research
since the 1960s has been primarily focused in
ﬁnding the outlet size that guaranteed a complete
Statistical Mechanics of
Clogging, Fig. 3 Arch
formation model in which
the arch region is divided in
several cells of about the
size of a particle (top). In the
bottom, one-dimensional
projection of the arch where
arrows into a site represent a
particle “inﬂow” at a rate a.
The arrows pointing out of
sites indicate the “outﬂow”
which is deﬁned by three-
site interactions. When a
ﬁlled site is besides an
empty site, the outﬂow rate
is deﬁned by b. When a
ﬁlled cell is surrounded by
two ﬁlled cells, the outﬂow
rate is g; and when a ﬁlled
cell is between a ﬁlled cell
and a boundary, the outﬂow
rate is d. (Reprinted from
Masuda et al. (2014))
Statistical Mechanics of Clogging
369

absence of clogging (Arnold and McLean 1976;
Drescher et al. 1995; Jenike 1964; Walker 1966).
The approach followed in these works was to set
up the stress-strain rate relations and analyze the
critical factors which ensured continuous gravity
ﬂow. From this, a typical oriﬁce value of around
5 to 10 times the particle size was found for non-
cohesive grains.
Instead, modern approaches involve statistical
analysis of the avalanche sizes or clogging prob-
ability, and their dependence on the outlet size. In
the following subsection we summarize some
recent advances in this area.
Statistics of Avalanches
In their trailblazing work K. To et al. (2001)
measured a quantity they called J – the probability
that a two-dimensional silo ﬁlled with a ﬁxed
number of grains gets jammed before emptied –
for different outlet sizes (Fig. 4). The most salient
feature they observed was a strong dependence of
J on the outlet size, which suggested a transition to
a state where J ¼ 0 (i.e., complete absence of
clogging) for an opening size of around 5 to 7 par-
ticle diameters. In order to describe this transition,
the authors developed a model in which the clog-
ging arch was envisaged as a restricted random
Statistical Mechanics of
Clogging, Fig. 4 Left:
probability that a silo gets
jammed J versus the outlet
size. Data correspond to
hoppers of different angles
f: circles (f ¼ 34),
triangles (f ¼ 60), and
squares (f ¼ 75). Right:
Sketch of an arch clogging a
hopper of angle f with an
exit size R. The angles
among consecutive
particles are deﬁned, from
left to right, as y1, y2,. . .
yn–1. (Reprinted from To
et al. (2001))
370
Statistical Mechanics of Clogging

walker. In this model, the particles conforming the
arch took random positions with some restrictions:
1. The random walker goes from left to right.
2. The arch has to be convex at all sites to guar-
antee its stability.
3. The particles cannot interpenetrate each other.
4. The total span of the arch has to be larger than
the outlet size.
This model successfully described the jam-
ming probability dependence on the outlet size
for the experimental conditions implemented in
that work, showing values of J tending to zero for
large enough outlet sizes. However, the question
about the existence of a transition (in the thermody-
namic sense) from a jammed state to an unjammed
one remained open.
This problem was approached by Zuriguel
et al. (2005), who used a three-dimensional silo
to experimentally investigate the clogging proba-
bility in a wide range of outlet sizes, including
some cases with a very low probability of clog-
ging. Remarkably, they explored outlet sizes in
which the mean avalanche size was above 106
particles and proposed Eq. 3 as the best ﬁtting
expression for their data. As it is evidenced in
Fig. 5, the ﬁtting was quite good with the following
parameter values: g ¼ 6.9  0.2, A ¼ 9900  100,
and Rc ¼ 4.94  0.03. Notably, the ﬁgure obtained
for the critical outlet size was similar to previous
predictions based on the stress-strain rate relations
reported at the end of the twentieth century. The
unusually high value of the exponent, apart from
manifesting the strong dependence of the ava-
lanche size on the outlet size, also hinted to the
need of looking for another order parameter
(instead of the avalanche size) that better describes
the clogging transition. In addition, it was shown
that R – the outlet size rescaled by the particle
diameter – is the most important parameter on
determining the clogging probability. In fact,
experiments with different outlet sizes and particle
diameters, but the same R, displayed very similar
results (Fig. 5, right). Also, the effect on clogging
of the material properties of the particles was
revealed to be rather small.
sh i ¼
A
Rc  R
ð
Þg
ð3Þ
Shortly after the introduction of this power law
ﬁt, K. To suggested that two other expressions
were able to ﬁt the data equally well (at least for
experiments in two-dimensional silos) (To 2005).
One of such expressions (Eq. 4) was a stretched
exponential which did not involve a critical outlet
size. Later on, this result was given additional
a
b
Statistical Mechanics of Clogging, Fig. 5 Left: mean
avalanche size versus the exit size R. In the inset, mean
avalanche size versus (Rc – R)1 in logarithmic scale. In
both cases the ﬁt corresponds to Eq. 3 with the parameters
indicated in the text. Right: mean avalanche size vs R in a
semilogarithmic scale; data correspond to spherical grains
of different materials (delrin, glass, lead, and steel) and
different particle diameters (from 1 to 3 mm). (Reprinted
from Zuriguel et al. (2005))
Statistical Mechanics of Clogging
371

support by Janda et al. (2008) for the two-
dimensional case, a scenario for which the origin
of the equation was related with the statistics of
the arch lengths obtained in static deposits of
grains. Nevertheless, the goodness of Eq. 4 to ﬁt
the outcomes of a three-dimensional silo was
challenged, suggesting that the ﬁtting was neither
satisfactory when raising R to a power of 3 (the
dimension of the system).
sh i ¼ A eB R2
ð4Þ
Following another line of reasoning, Thomas
and Durian (2015) build upon experimental data
of avalanche sizes in a wide variety of situations
(hoppers with several tilt angles, oriﬁces with
different geometries, particles of diverse nature,
and so on) to show that the three ﬁtting expres-
sions proposed by K. To worked nicely in three
dimensions (Fig. 6). Moreover, the origin of the
sh i ¼ AeB R3 relationship was justiﬁed by consid-
ering all possible arch conﬁgurations and evaluat-
ing the amount of them that would be effectively
able to block the oriﬁce. The same approach was
afterwards further elaborated by researchers of the
same group (Koivisto and Durian 2017) to suc-
cessfully evaluate the effect of interstitial ﬂuid on
the clogging probability.
Dynamical Signatures of Clogging
An alternative way of approaching the question of
whether there is a critical outlet size above which
clogging would never happen is to look for dynam-
ical ﬂow features that could reveal any difference at
both sides of the hypothetical transition point. The
ﬁrst proof of the existence of such differences was
reported by Longhi et al. (2002) in a work where
they characterize the impulses delivered to the wall
Statistical Mechanics of
Clogging, Fig. 6 Left:
mean avalanche size
(in grams) versus the exit
size. Data for hopers with
different tilt angles as
indicated in the legend. The
three line types represent
different ﬁtting alternatives.
Right: the same data and ﬁts
using the outlet size raised
to the third power in the
abscissa axis. (Reprinted
from Thomas and Durian
(2015))
372
Statistical Mechanics of Clogging

of a 2D hopper. They found that the distribution of
impulses decayed exponentially for impulses
above the average, in the same way that the forces
in a static granular packing do (Mueth et al. 1998).
This happens independently on the hopper size,
which only affects the impulse distribution for
values below the average. However, these small
impulses display a smooth evolution when going
from continuous to intermittently jamming ﬂows;
so there was not any signature of a proper clogging
transition. Nevertheless, as reported in the same
work, the distributions of time intervals among
consecutive collisions did hint an approach to jam-
ming as they tend to a power law distribution with
an exponent 3/2 when the outlet size was pro-
gressively reduced (see Fig. 7).
An additional signature of clogging has been
identiﬁed by analyzing the ﬂuctuations of the ﬂow
rate.
In
this
regard,
Janda
et
al.
(2009a)
implemented high-speed video recordings to
detect the passage of every individual grain
through the outlet. With this information the
ﬂow rate was calculated in very short temporal
windows (of the order of 0.1 s) for different outlet
sizes. Interestingly, the distributions of the instan-
taneous ﬂow rate q were Gaussian for large outlet
sizes (where clogging never happens), whereas
they became strongly asymmetric for small outlet
sizes (where clogging eventually occurs). In the
latter case, a strong increase of the number of
events toward small values of q was found,
displaying a peak at q ¼ 0 that was related with
the formation of unstable clogs (see Fig. 8).
Therefore, a relationship between the appearance
of unstable clogs and stable ones was established,
and it was suggested that the total absence of
unstable clogs for large outlet sizes was reﬂecting
the existence of a “clogging free” region.
A similar increasing of the ﬂuctuations when
reducing the outlet size was reported by Thomas
and Durian (2016). In particular, they measured the
relative velocity ﬂuctuations and the skewness of
the velocity distribution. They also quantiﬁed the
intermittency by means of a descriptor based on the
two-sample Kolmogorov-Smirnov statistic. All
these estimators were shown to grow for ﬂows
more prone to clogging, that is, when the outlet
size was reduced. However, the evolution of these
magnitudes with R was smooth and no discontinu-
ity or kink was observed for a hypothetical critical
outlet size. Therefore, this analysis undermined the
hypothesis of a critical outlet size, supporting
instead the notion that clogging is always possible,
irrespective of the outlet size.
Incipient Clogging Let us ﬁnally mention here a
couple of works where different dynamical signa-
tures of incipient clog formation were reported. In
1993, Sakaguchi et al. (1993) suggested that the
ﬂow in a 2D silo with a small oriﬁce consisted on
an alternation of ﬂows coming from both sides of
the outlet. At the instant when the transition (ﬂow
from one side to ﬂow from the other side) occurred,
the grains collided, thus facilitating the formation
of the arches that would lead to clogging. Alterna-
tively, Tewari et al. (2013) performed numerical
Statistical Mechanics of
Clogging,
Fig. 7 Logarithmic plot of
the probability distributions
P(t) of the time intervals t
between collisions, for
opening sizes ranging from
R ¼ 3 (top series) to R ¼ 16
(bottom). (Reprinted from
Longhi et al. (2002))
Statistical Mechanics of Clogging
373

simulations of silo discharge and gridded the space
into a number of boxes in which the vertical veloc-
ity was calculated. Then, the boxes with an instan-
taneous velocity below half the average were
assigned to clusters. From these data, it was
observed that just before the appearance of a clog,
there was a notable increase of the area covered by
these clusters comprising regions with a markedly
low velocity. In the same way, after the ﬂow was
resumed, the area of these clusters decreased, as
displayed in Fig. 9. Moreover, clog formation was
associated to the development of vortices at the
corners of the hopper that extended inwards, even-
tually arresting the ﬂow.
Effect of Other Variables
Clearly, the parameter that mainly determines the
clogging probability (and hence, the avalanche
size) is the ratio R among the outlet and the
particle size. As displayed above (Fig. 5b), its
effect is so important that an increase from
R ¼ 3 to R ¼ 4 leads to a growth of the avalanche
size by more than 100 times. Due to this dramatic
dependence, the main way to analyze the inﬂu-
ence of other variables has been to keep a strictly
constant outlet size (sometimes a variation of a
tenth of millimeter may conceal the effect of other
quantities). A time-consuming alternative consists
of repeating a series of experiments for all the
range of outlet sizes changing an additional
parameter.
The latter was, indeed, the strategy followed
by K. To and collaborators to analyze the role of
the hopper angle (To et al. 2001). Oddly enough,
they observed that for small and medium hopper
angles (close to a ﬂat bottomed silo) this param-
eter had a negligible effect on the probability of
clogging (f ¼ 34 and f ¼ 60 displayed almost
the same values). Nevertheless, clogging was
dramatically reduced when using a hopper of
f ¼ 75. This strongly nonlinear dependence
has been recently conﬁrmed and explained by
considering the angles among the particles
conforming the arch (López-Rodríguez et al.
2019) in a two-dimensional silo. This approach
revealed
that
increasing
the
hopper
angle
extended the number of forbidden arch conﬁgu-
rations,
that
is,
those
that
would
imply
interparticle angles that could not be stabilized
with typical friction forces. Although this inter-
pretation has not been yet extrapolated to three-
dimensional silos, recent results reported in
Parretta and Grillo (2019) are perfectly compat-
ible with it. In Arches (devoted to the geometry
of clogging arches) we will come back to the role
of particle angles in the arch stability.
0
20
40
60
0
1000
2000
3000
time (s)
q (beads / s)
Statistical Mechanics of Clogging, Fig. 8 Instantaneous
ﬂow rate (in number of particles per unit time) measured at
short time windows (of 150 ms). The line at the top corre-
sponds to an oriﬁce size of R ¼ 9.5, and the one at the
bottom to an oriﬁce of R ¼ 4.3. The arrows mark two
events where the ﬂow has ceased for a time longer than
the window. (Reprinted from Janda et al. (2009a))
374
Statistical Mechanics of Clogging

A similar line of reasoning could be valid to
deal with clogging in lateral and inclined oriﬁces.
In two manuscripts from Durian’s group (Sheldon
and Durian 2010; Thomas and Durian 2013), a
clogging phase diagram was suggested when con-
sidering its dependence on two parameters: the
outlet size and the tilt angle of the silo (Fig. 10).
Remark that it is tempting to consider silo tilt as a
situation similar to using different hopper angles,
but
there
are
conspicuous
differences.
For
instance, it was reported that for a given outlet
size the clogging probability grows when increas-
ing the tilt angle (opposite to the hopper case).
Moreover, by implementing experiments in both,
symmetric oriﬁces (circular) and asymmetric ones
(slits), these authors showed that the behavior in
all these systems could be encompassed by using
the projected area of the aperture over the average
ﬂow direction (instead of the gravity direction) as
depicted in Fig. 10. In principle, this collapse of
the transition points should be also valid for
completely vertical oriﬁces, a scenario where the
wall width is capital (Davies and Desai 2008;
Serrano et al. 2014; Zhou et al. 2017).
Certainly, one of the most surprising features
concerning clogging appears when an obstacle is
placed above the oriﬁce (Lozano et al. 2012a;
Zuriguel et al. 2011). This geometrical constraint,
which a priori would restrict the ﬂow of grains,
turns to be beneﬁcial if the obstacle position is
carefully selected. Indeed, the effect can be utterly
remarkable, as in some cases the avalanche size is
increased by more than one hundred times. The
physical origin of this behavior was speculated to
be related with the arch stabilization process.
According to this argument, in a usual silo without
an obstacle, a stable arch can develop when a
group of particles collides above the oriﬁce due
to the conﬁnement imposed by the particles com-
ing from above. On the contrary, for some obsta-
cle positions, there is an effective reduction of
pressure above the oriﬁce that allows the colliding
particles to be ejected upwards, thus preventing
the formation of a stable arch. A demonstration of
this behavior was numerically given in Zuriguel
et al. (2011) by simulating clogging in silos ﬁlled
with thin layers of grains. In fact, reducing the
height of the granular column inside the silo
caused an increase of the mean avalanche size
comparable to the one obtained when placing the
obstacle. In addition, in Lozano et al. (2012a) it
was shown that the clogging reduction effect
increased when enlarging the outlet size (see
Fig. 11). This can be understood if we consider
that the system becomes more sensitive to pertur-
bations when approaching the hypothetical criti-
cal outlet size. Although these features were
originally reported using a circular obstacle,
other authors have implemented different shapes,
such as triangular, inverted-triangular, and a hor-
izontal bar (Endo et al. 2017). Among these
forms, the triangular obstacle and the horizontal
bar were shown to be the most effective to prevent
clogging.
These
authors
also
attribute
the
Statistical Mechanics of
Clogging, Fig. 9 Tempo-
ral evolution of the area
covered by connected clus-
ters of low velocity regions
(where the vertical velocity
is less than half the average)
near the oriﬁce. As it can be
seen, the area starts growing
before the formation of a
clog and decreases when the
ﬂow is resumed. (Reprinted
from Tewari et al. (2013))
Statistical Mechanics of Clogging
375

clogging reduction to a decrease in the packing
fraction at the exit region. Even though this justi-
ﬁcation seems different from the pressure reduc-
tion explained above, it should be noted that both
variables
are
strongly
coupled
in
granular
materials.
Implementing
multiple
oriﬁces
in
a
silo
appears as a natural extension of previous inves-
tigations with a single oriﬁce (Kunte et al. 2014;
Mondal and Sharma 2014). In this system, if two
oriﬁces are sufﬁciently close to each other, it is
possible to obtain an intermittent ﬂow. The reason
is that if an arch blocks only one of the oriﬁces, the
ﬂow through the other one can cause the destabi-
lization of the former and restart the ﬂow through
it. This behavior has been observed in three-
(Mondal and Sharma 2014) and two-dimensional
silos (Kunte et al. 2014) and can be used to reduce
the overall clogging probability. As could be
expected, the distance between both oriﬁces
emerges as a key variable. If the oriﬁces are far
enough, the effect is negligible and the system
behaves as if there were two independent silos;
otherwise, when the oriﬁces are close to each
other, the interaction becomes increasingly impor-
tant. Besides, it is interesting to note that the
Statistical Mechanics of Clogging, Fig. 10 Top: sketch
of the oriﬁce indicating the unit vectors bn (normal to the
plane of the aperture) and bv (average ﬂow direction, as
deﬁned by bisecting the region where the grains ﬂow)
when the tilt angle y is (a) less than, and (b) greater than,
the angle of repose yr. Bottom: Clogging transition
diagram for holes and slits and different types of particles.
The y-axis is the component bv  bnof the unit vectors deﬁned
above and the x-axis is the area of the hole normalized by
the critical hole area at zero tilt angle. (Reprinted from
Thomas and Durian (2013))
376
Statistical Mechanics of Clogging

intermittent blocking and unblocking of both ori-
ﬁces can provoke the mixing of the granular mat-
ter, as reported in (Kamath et al. 2014).
Another variable that is known to strongly affect
the clogging probability and is intimately related
with the effect of the obstacle described above is
the density of particles in the outlet neighborhood.
In fact, if the number of particles above the oriﬁce
is controlled by modifying the inﬂow rate of grains
into the silo, it can be observed that there is a
threshold value above which the grains start to
accumulate. Only in this scenario, and if the oriﬁce
is small enough, clogging may appear (Hou et al.
2003; Kohring et al. 1995). In this sense, a connec-
tion can be made with an experimental work of
Roussel et al. where a suspension of grains was
made to pass through a mesh with a typical hole
size slightly larger than the particle size (Roussel
et al. 2007). In particular, it was shown that the
proportion of material that was trapped in the mesh
(called residual R) strongly depended on the hole
size but also on the number of particles per volume
unit (solid fraction). Indeed, for outlet sizes as
small as two times the particle size (where clogging
in a standard silo happens very quickly) it was
found that R is negligible for 4% solid fraction
samples (Fig. 12). This behavior was reproduced
with a model in which the likelihood of clogging
was linked to the probability that a given number of
particles coincide above an oriﬁce; therefore,
Statistical Mechanics of
Clogging, Fig. 11 Left:
photograph of an arch
formed above the outlet.
R is the length (or size) of
the outlet and h is the
distance from the bottom of
the obstacle to the outlet.
Right: mean avalanche size
versus the obstacle position
for silos with three different
outlet sizes (from bottom to
top: R ¼ 3.13, R ¼ 4.20 and
R ¼ 4.55). The horizontal
lines correspond to the
mean avalanche size
without obstacle for each
outlet size. (Reprinted from
Lozano et al. (2012a))
Statistical Mechanics of Clogging
377

higher packing fractions lead to higher probabili-
ties of clogging. The dependence on the outlet size
was reproduced by determining that the number of
particles necessary to form a clog, n, depended on
the hole size as n ¼ gR2. Interestingly, the trend
displayed by the residual as a function of R shown
in Fig. 12 closely resembles the one reported by To
for the probability that a silo with a single oriﬁce
jams before emptied (J), as shown in Fig. 4, left.
Finally, let us mention that the dependence of the
clogging probability on the concentration of parti-
cles above the oriﬁce has been also observed in a
recent work of Koivisto and Durian, as well as in
complementary experiments of ﬂuid driven ﬂow of
suspensions through single oriﬁces performed by
Wu and coworkers (Guariguata et al. 2012; Lafond
et al. 2013).
Regarding the dependence of the clogging
probability on the packing fraction above the ori-
ﬁce, Uñac et al. went a step further and revealed
the importance of the grain arrangements in the
development of clogging inside the silo prior the
discharge (Uñac et al. 2012). Their protocol
consisted in applying a series of taps of an inten-
sity G to a column of grains previous to their
discharge through an oriﬁce at the bottom of the
column. Remarkably, very low values of G –
which are known to induce very high values of
volume fraction – lead to very small avalanche
sizes, that is, high probability of clogging
(Fig. 13). Nevertheless, the authors also reported
that samples with the same volume fraction but
generated with a different intensity of tapping
gave rise to a different clogging probability. This
fact revealed that, in very dense granular matter,
the volume fraction is not a good macroscopic
parameter for predicting the size of the avalanches
that would ﬂow through a given aperture.
Influence of Particles Properties
Apart from the morphology of the exit or the
concentration of particles above the oriﬁce, clog-
ging is also affected by the properties of the
grains. After a revision of the articles dealing
with this issue, it can be concluded that the
shape of the grains and the grain to grain friction
are the two most inﬂuential ones concerning the
development of clogging.
It was K. To in his pioneer work (To et al. 2001)
who ﬁrst analyzed the role of friction in the devel-
opment of clogging from a statistical point of view.
He observed that the probability of clogging
increased when using toothed disks instead smooth
ones (Fig. 14). This phenomenon was linked to the
appearance of local convexities in the arches; that
is, particles hanging below the line joining the
center of their two neighbors. Of course, these
conﬁgurations are only possible because of fric-
tion. Independent conﬁrmation came a few years
later when Pournin et al. studied the effect of fric-
tion in a systematic way combining experimental
and numerical approaches (Pournin et al. 2007).
Statistical Mechanics of
Clogging, Fig. 12 Pro-
portion of material trapped
in the mesh (R) as a function
of the mesh hole, in a sus-
pension of particles of dif-
ferent solid fractions as
indicated in the legend.
(Reprinted from Roussel
et al. (2007))
378
Statistical Mechanics of Clogging

They observed that clogging decreased when
reducing the friction coefﬁcient m; indeed, for the
limit case of m ¼ 0 (analyzed numerically) clogging
was dramatically reduced. Clearly, in this unrealis-
tic situation, arches can only adopt regular shapes,
and local convexities are forbidden as it was previ-
ously illustrated when inspecting the arches devel-
oped in a granular column (Pugnaloni et al. 2006).
Experimentally, this issue was conﬁrmed by
using frictionless (or almost frictionless) hydrogel
particles (Ashour et al. 2017a; Hong et al. 2017).
In these works it was reported that even for very
narrow bottlenecks (of around 2 or 2.5 times the
particle size) the probability of clogging was very
small. Interestingly, Hong et al. (2017) demon-
strated that using droplets (which are frictionless
and deformable at the same time) ﬂow can be
attained even for an outlet size equal to the parti-
cles. In addition, it was shown (Ashour et al.
2017a) that reducing the friction coefﬁcient pre-
vented the pressure saturation at the bottom of the
silo, a phenomenon known as the Janssen effect
(Janssen 1895).
As mentioned above, the other outstanding
property of grains regarding clogging is the parti-
cle shape (Ashour et al. 2017b; Goldberg et al.
Statistical Mechanics of
Clogging, Fig. 13 Mean
avalanche size versus the
intensity of taps used to
prepare the sample before
opening the oriﬁce at the
bottom. (Reprinted from
Uñac et al. (2012))
Statistical Mechanics of
Clogging, Fig. 14 Proba-
bility that a silo gets
clogged before all the grains
are discharged for smooth
disks (a) and toothed disks
(b). (Reprinted from To
et al. (2001))
Statistical Mechanics of Clogging
379

2018; Tang and Behringer 2016; Vamsi Krishna
Reddy et al. 2018). Tang and Behringer observed
that clogging in a 2D silo was enhanced when
using elliptical cylinders because they align with
each other, thus increasing the probability of
forming stable arches. Also, they suggested that
the relevant particle length scale to compare the
behavior of ellipses and isotropic grains is the
major diameter of the former, and they demon-
strated that the number of particles conforming the
arch was considerably higher when using aniso-
tropic grains. In a subsequent work, Ashour et al.
(Ashour et al. 2017b) conﬁrmed this observation
in a 3D silo, and correlated it with the preference
of the elongated particles to orient with the longer
axis perpendicular to the clogging dome. This
orientation was quantiﬁed by using X-ray tomog-
raphy. Again, in this work it was found that an
increasing aspect ratio of the grains leads to higher
clogging probabilities compared to spherical
grains. Notably, for aspect ratios smaller than 6,
the mean avalanche size dependence on the outlet
size nicely agreed with the divergent ﬁtting
expression (Eq. 3) proposed for discs, which was
already found to be valid for rice grains (Zuriguel
et al. 2005). Nevertheless, a new feature was
discovered for particles with aspect ratios larger
than 6: whereas for small outlet sizes the mean
avalanche size dependence on the outlet size
resembles all the other cases, above a given outlet
size the experimental data fall below the expected
values given by the ﬁtting curves. For even higher
aspect rations (above 8) the development of rat-
holes (completely emptied regions in the central
part of the silo surrounded by material close to the
lateral wall) strongly alter the clogging dynamics.
Apart from the aspect ratio, another feature of
the particle shape that strongly affects clogging is
the
presence
of
ﬂat
faces
(Ahmadi
and
Hosseininia 2018; Goldberg et al. 2018). By
means of discrete element modeling, Goldberg
et al. evidenced that polygonal particles clogged
more easily than discs. Indeed, the polygons that
were more prone to clog a two dimensional silo
were shown to be the squares, and then hexagons,
pentagons, triangles, and heptagons – which
displayed a much smaller probability of clogging
(close to that of discs). The reason for this
behavior was found to be in the number of side
to side contacts among the particles due to shear-
ing forces: squares where the most likely to be
aligned and develop this kind of highly stable
contact, whereas these conﬁgurations were most
rare in heptagons. Also, in a recent work in which
both gravel and spherical beads were used, more
clogging and taller arches were found with gravel
(Ahmadi and Hosseininia 2018). Interestingly
enough, all the results obtained with these differ-
ent materials have been accounted for using the
peak friction angle, which was found to be the
main parameter controlling the stability and
dimension of the clogging arches.
Finally, let us mention that other variables such
as the particle size dispersion (Chevoir et al. 2007;
Pournin et al. 2007; Zhao et al. 2019) or the
particle size (Gella et al. 2018) have been also
shown to affect the clogging probability. Regard-
ing
polydispersity,
Pournin
et
al.
(2007)
performed experiments in a 3D silo with both
monodisperse and bidisperse samples, evidencing
that jamming mainly depends on the volume aver-
aged diameter of the sample. However, care must
be taken when the size difference among the par-
ticles is large enough to induce segregation; in this
case clogging propensity was enhanced. Opposite
to these results, in a recent work based on DEM
simulations, Zhao et al. (2019) revealed that
increasing the polydispersity of the particle sizes
in the silo enhances the probability of clogging.
To reach this conclusion, they worked with differ-
ent samples where the particles distributions were
lognormal with the same mean particle size but
different standard deviation. Then, although the
polydispersity role was shown to be less important
than the mean particle size, it was discovered to be
relevant for some conﬁgurations. Interestingly,
the same conclusions were attained a decade
before when studying clogging of grains through
a sieve (Chevoir et al. 2007).
Role of Dynamics on Clogging
Up to now, all the variables that have been related
to clogging concern geometrical features, charac-
terizing either the oriﬁce (where the outlet size is
the most inﬂuential) or the particles (shape, poly-
dispersity, and so on). Also, the effect of other
380
Statistical Mechanics of Clogging

parameters such as the volume fraction above the
oriﬁce has been identiﬁed as potentially relevant.
Nevertheless, the role of kinematics in the devel-
opment of clogging has not been addressed yet,
even though the inﬂuence of some geometrical
aspects of the silo on clogging has been explained
through a connection with this parameter. This is
the case of a recent work where the inﬂuence of
the silo width on the clogging probability was
linked to an alteration of the particles movement
above the outlet (Gella et al. 2017).
Concerning the role of particle dynamics on
clogging, Dorbolo et al. performed pioneer silo
discharge experiments in high and low gravity
conditions, studying gravity values above and
below the Earth’s gravity (Dorbolo et al. 2013).
Although this work was mainly focused on the
ﬂow regime (i.e., when clogging does not hap-
pen), it was tentatively reported that gravity did
not strongly affect clogging behavior. This result
was conﬁrmed afterwards by Arévalo et al.
(2014), who performed systematic numerical sim-
ulations of clogging in a silo with a ﬁxed outlet
size (3.5 times the particle size) varying the grav-
ity values over four orders of magnitude. Despite
this huge variation, the avalanche size only
changed slightly, increasing 1.6 times when
going from 0.001 g to 10 g. In a subsequent
work, this result was qualiﬁed and it was shown
that the effect became more important when
increasing the outlet size, as it happened with the
obstacle effect. For the largest outlet investigated,
the avalanche size increased 10 times for the same
variation of 4 orders of magnitude in the gravity
value.
This
discovery
was
explained
by
portraying the clog formation as a double step
process: ﬁrst, an arch spanning the outlet size
must be formed; and second, the arch must resist
until the complete dissipation of the kinetic
energy in the system. Indeed, this approach allo-
wed estimating the probability that an arch is
destabilized, which was shown to primarily
depend on the square root of the system kinetic
energy.
Following this idea and aiming to design an
experiment that better isolates the contribution of
the kinematic effects on the clogging process,
Gella et al. built a setup consisting of an extracting
belt below the silo oriﬁce. This device allows to
control the grain mean velocity without changing
the outlet size, effectively decoupling these two
variables. Using this strategy, it was revealed that
clogging dramatically increases when the grains
are discharged at very low velocities (in a quasi-
static manner). Moreover, the geometrical and
kinetic contributions to the clogging process in a
2D silo were nicely decoupled and described by
an expression (Eq. 5) which was inspired in the
stretched exponential proposed by K. To (2005)
and D. Durian (Thomas and Durian 2015).
Pc ¼ a þ bv
ð
Þ R=dp
ð
Þ
2
ð5Þ
Remarkably, this new expression included only
two ﬁtting parameters to describe all the results
obtained when varying both the outlet size and
the velocity of the grains. The ﬁrst parameter (a)
accounts for the geometrical effects of clogging
and was the only one affecting the value of the
probability of clogging in the quasi-static regime,
that is, when the velocity of the grains tends to zero.
The second (b) accounted for the kinematic effects
and enters Eq. 5 as a factor the velocity of the grains
v. As the experiment was performed in 2D, the
exponent was the rescaled outlet size raised to the
power of 2. The authors demonstrated that this
expression (with the same ﬁtting values) was also
valid to reproduce the data obtained in a standard
silo (discharged purely by gravity without a con-
veyor belt) if the velocity of the grains is replaced
by the well-known relationship v ¼
ﬃﬃﬃﬃﬃﬃ
gR
p
proposed
in Beverloo et al. (1961).
Arches
As clogs are caused by the formation of arches, it
is natural to study the properties of these meso-
scopic structures and try to establish a relationship
between them and the macroscopic behavior. For
example, it is interesting to establish a connection
between the microscopic properties of the parti-
cles conforming the arch, and its shape or stability.
We will now approach the topic of the arch shape
and its relationship to clogging.
A natural way to describe the arch shape is
through the angles subtended between the centers
of consecutive beads (Fig. 15): the center of every
Statistical Mechanics of Clogging
381

three beads in contact subtends an angle f, and
therefore the set {fi} is a straightforward way to
deﬁne the shape of an arch blocking the exit
oriﬁce. In the model of To (see Fig. 4, right)
these angles must be smaller than 180 (To et al.
2001). This is a good approximation because most
of the beads indeed fulﬁll this condition, and if
friction is very small this should hold. Neverthe-
less, in experiments it is found that angles can be
higher than 180, meaning that the beads associ-
ated to that angle are hanging from the neighbors
due to friction. In one particular realization using a
ﬂat bottomed hopper it was found that the propor-
tion
of such
beads
was as high
as 17%
(Garcimartín et al. 2010). They were called
defects, and it can be surmised that they will be
rather unstable against perturbations. Although in
principle this result would contradict To’s ideas, it
turns out that the model is quite representative of
the real behavior. The reason is that successive
angles are anticorrelated (Garcimartín et al. 2010),
meaning that a big angle is likely to be found
before a small one, and vice versa. Therefore if
angles are taken in pairs the average is very likely
below 180, as assumed by the model of
To. Finally, let us note that particle shape and
friction are paramount in determining how large
the angles can be. As reported in To’s article of
2001 enhanced friction, as achieved with dented
disks, largely increased clogging probability. In
particles with ﬂat faces, this effect is exacerbated
(Ahmadi and Hosseininia 2018; Goldberg et al.
2018).
If a hopper is considered instead of a ﬂat-
bottomed silo, then the hopper angle introduces
a boundary constraint that determines the maxi-
mum values of the angles y between the segment
joining the centers of two consecutive particles
and the horizontal (see Fig. 16e). López and
coworkers (2019) proposed that for hypotheti-
cally frictionless particles in a hopper having an
angle b with respect to the horizontal, the angle y1
formed by the ﬁrst two particles (starting from the
left) would necessarily be smaller or equal to
(90 – b). Otherwise, the ﬁrst particle would be
unstable. Then, following To’s idea (To et al.
2001), the second angle y2 should be equal or
smaller than y1, and so forth, until the last one
yn–1, which must fulﬁll the condition of being
larger than –(90 – b). Therefore, all the angles
9 should fall within a range determined by the
hopper angle as denoted by the following
equation:
90
  b


 y1  y2  . . .  yn1
 90
  b


ð6Þ
Experimental results are in good agreement
with this interpretation (see Fig. 16), although
some values of y are also observed beyond these
limits, a behavior that was attributed to friction.
As a consequence of the restriction of possible
angles provoked by the hopper walls, it happens
that the number of allowed arches is drastically
reduced as the hopper angle increases. Conse-
quently, the clogging probability diminishes.
Besides, for large hopper angles, the narrow
range of angles allowed (see Fig. 16d) imposes
that arches are almost ﬂat; as a consequence, the
number of beads in the arch becomes discretized
Statistical Mechanics of
Clogging, Fig. 15 Photo-
graph of a clogging arch in a
ﬂat bottomed 2D silo. The
angle formed by the centers
of three beads is deﬁned as
f. (Reprinted from Lozano
et al. (2012b))
382
Statistical Mechanics of Clogging

and the clogging probability changes stepwise
with the size of the exit oriﬁce. This contrasts
with the case of a ﬂat bottomed silo, where the
distributions are rather wide (see Fig. 16a). In this
case, it was shown that the arches display a wide
variety of shapes, although they tend to be semi-
circular when the outlet size was enlarged
(Garcimartín et al. 2010).
An interesting question in relation with the
arch shape concerns their connection with the
forces that they withstand. This relationship can
only be statistical: it is impossible to establish a
univocal correspondence between shape and
force, as one arch shape can tally with many
different force distributions. In two dimensions,
Valdes and Santamarina (2008) pointed out that
10–1
10–2
10–3
2.18
Did=
β=0°
β=45°
β=60°
β=80°
Did=
Did=
Did=
2.69
3.03
3.12
3.61
4.70
4.21
1.74
3.21
2.12
1.62
2.10
2.63
2.82
3.13
3.57
3.79
4.35
1.76
1.96
2.10
2.45
2.74
3.12
3.43
3.63
3.47
3.53
2.73
4.30
3.70
10–4
a
b
c
d
e
pdf
10–1
10–2
10–3
10–4
pdf
10–1
10–2
10–3
10–4
pdf
10–1
10–2
10–3
10–4
–80
80
–60
60
–40
40
–20
20
0
θ (deg)
pdf
Statistical Mechanics of Clogging, Fig. 16 (a–d) Prob-
ability distribution function of the angle y between the
centers of two consecutive particles in an arch and the
horizontal, as indicated in (e). b is the angle that the hopper
makes with the horizontal. In a–d the curves represent
values
of
y
obtained
for
different
outlet
sizes
(as indicated in the legend), and the vertical dashed lines,
the limit values that would be imposed by the hopper walls
for
a
frictionless
sample.
(Reprinted
from
López-
Rodríguez et al. (2019))
Statistical Mechanics of Clogging
383

the mean force orientation in the packing would
determine the optimal arch shape: for vertical and
horizontal average forces, the optimal shape is
parabolic or a catenary; and for a uniform force
orientation distribution, the optimal shape is semi-
circular. In fact, the semicircular shape observed
for large arches in Garcimartín et al. (2010) was
attributed to a uniform orientation of the forces
within the silo. Although arches are not necessar-
ily an optimal response to the orientation distribu-
tion of forces, this result can be taken as a hint,
showing how shape can provide valuable infor-
mation about the forces.
Unfortunately, the measurement of the forces
at the grain level is not easy (Daniels et al. 2017)
and, as far as we know, it has been never system-
atically performed for clogging arches. Therefore,
all the knowledge we have about this topic comes
from numerical simulations, as in the work of
Pugnaloni and collaborators (2006) where the
forces in the arches developed within a column
of grains were analyzed. Forces in clogging arches
have been investigated in Hidalgo et al. (2013)
and Longjas et al. (2009). Indeed, in Longjas et al.
(2009) the forces were used to infer the proportion
of possible arches that would be stable and, there-
fore, able to cause clogging. However, this analy-
sis was limited to arches of three particles. In a
subsequent work (Hidalgo et al. 2013), molecular
dynamics simulations were used to unveil that the
normal forces within the particles conforming the
arch are, in average, much larger than the ones
among particles in the bulk. In addition, an impor-
tant relation among the angle subtended among
every three particles f and the average force was
observed: the larger the angle, the higher the tan-
gential, and the lower the normal force. Therefore,
the higher the angle, the higher the friction mobi-
lized to sustain the particle. This result is consis-
tent with experimental data reported in the
following chapter concerning the resistance of
arches against perturbations.
Unclogging
Once an arch that blocks the oriﬁce is formed, in
principle it will last forever. The formation of an
arch involves a mechanically stable conﬁguration,
and therefore a perturbation is needed to break
it. This may come in different forms. Thermal
cycles, for instance, may make the grains dilate
and contract, hereby disturbing the contact forces.
Although this method has not been used speciﬁ-
cally to unclog a silo, it was shown that this
procedure can compact a granular medium,
which is closely related to breaking arches inside
it (Divoux et al. 2008). Local perturbations on the
grains at the oriﬁce, for instance with a ﬂuid jet
(Zuriguel et al. 2005), or a movable oriﬁce (either
oscillating (To and Tai 2017) or rotating (To et al.
2019)) have also been used. However, an external
vibration is probably the most extended method to
restore ﬂow when an oriﬁce clogs; this is espe-
cially true in industry and applications, where
silos and hoppers with the addition of a vibrating
mechanism are often used. Indeed, vibrations can
be also coupled to air injection to ﬂuidize granular
materials stored in industrial silos, especially of
cohesive grains (Wes et al. 1990). Finally, the
vibration of lateral walls as a means of enhancing
the ﬂow has been also proved to be a good alter-
native (Pacheco-Martinez et al. 2008).
Among all these ways to disturb the clogging
arches and resume the ﬂow, we will focus here on
vertical vibrations applied to the silo bottom or to
the whole silo. The reason is that this situation
allows for a relatively easy way to quantify the
strength of the external perturbation introduced.
As a matter of fact, a silo submitted to a sinusoidal
vibration of frequency f and amplitude A is rela-
tively easy to implement in the laboratory. Impor-
tantly, it has been shown (Wassgren et al. 2002)
that the ﬂow rate of a vibrated silo does not change
drastically with respect to a static one, provided
that the amplitude is small and the frequency is
higher than the characteristic time of the dynamics
(Chen et al. 2006; Evesque and Meftah 1993;
Mankoc et al. 2009; Suzuki et al. 1968). This
allows a straightforward comparison of vibrated
and static silos. Indeed, in a vibrated silo with a
small oriﬁce it was shown an intermittent ﬂow in
which the distribution of ﬂow intervals follows an
exponential distribution (Mankoc et al. 2009). As
explained in section “Clogging as a Stochastic
Process” for the avalanche size distribution, this
384
Statistical Mechanics of Clogging

means that the probability of clogging is constant
along
time,
and
that
clogging
events
are
uncorrelated. Therefore a single characteristic
time can describe this process, which can be
related to the mean ﬂowing time, the clogging
probability of a single bead as it passes through
the oriﬁce, and the avalanche size. On the con-
trary,
the
distribution
of
clogging
intervals
revealed wider tails. Notably, the same scenario
was found for horizontal vibrations of the oriﬁce
(To and Tai 2017).
The nature and speciﬁc properties of these tails
were studied more closely by Janda et al. (2009b).
Although the research was aimed to obtain a
delivery device that could release a small quantity
of grains in a controlled fashion (and thus some of
the experiment details, such as the oriﬁce shape
and the vibration mechanism, were highly spe-
ciﬁc), similar features to the results reported in
Mankoc et al. (2009) were observed concerning
the dynamics of clogging and unclogging. Again,
the ﬂowing intervals were shown to be distributed
exponentially, while the duration of clogs was
suggested to follow a power law: pdf TJ
ð
Þ / Ta
J
(Fig. 17). This implies the absence of a character-
istic time scale for the clog duration, and then, it
follows that the probability that a clogging arch is
shattered is not constant along time. Remarkably,
it was found that for some speciﬁc values of the
variables, the exponent a of the power law was
lower than 2, implying that the average clog
duration (calculated with an integral including the
probability density function) does not converge.
All these facts hint that the process of breaking
arches with vibrations involves complex dynamics.
In order to explore how the clogging arches are
broken, two broad kind of procedures can be used
concerning the kind of vibration applied: either a
vibration of growing amplitude (a ramp), or a
constant amplitude vibration. In the ﬁrst case,
the intensity of the perturbation grows along
time, which is a natural way to probe the force,
or acceleration, that arches can withstand. On the
second case, the time that arches last under an
imposed perturbation is studied. The next two
sections are devoted to explain the investigations
related to these different approaches.
The Weakest Link
In order to test the endurance of arches, the idea is
to place a silo on top of a shaker and, when an arch
is formed, to start a vibration ramp at a constant
frequency and a linearly growing amplitude
(Lozano et al. 2012b, 2015). Then, the instant
when the arch is broken can be measured, and
hence the acceleration needed to break it. In addi-
tion, if the silo is two-dimensional, the shape of
the arch above the oriﬁce can be monitored. As the
variable considered here is the force needed to
break the arch, the adimensional parameter
G ¼ Ao2
g
is used to quantify the vibration, which
10–1
10–2
10–3
10–4
0,1
PDF (TJ)
1
Γ = 0.056
Γ = 0.084
Γ = 0.112
TJ (s)
Statistical Mechanics of
Clogging, Fig. 17 Log-
log plot of the pdf of the
time lapses during which
the ﬂow is arrested using an
inclined hopper with an
aperture of around R ¼ 1.78
times the particle size. The
dashed line has a slope of
two so the slope of the
distribution for lowest
acceleration G (see legend)
is smaller than this value.
(Reprinted from Janda et al.
(2009b))
Statistical Mechanics of Clogging
385

is the maximum acceleration in gravity units (o is
the angular frequency).
The ﬁrst remarkable result obtained with this
protocol is that the shape of the arch is closely
related to the acceleration needed to break it
(Lozano et al. 2012b). In particular, if we focus
on the angles subtended between the centers of
adjacent beads (f), then arches having beads with
an associated angle larger than 180 (or, defects)
are the weakest. Indeed, it was found that the larger
the maximum angle in an arch (fmax), the lower the
acceleration needed to break it (Fig. 18). Although
this is only true in a statistical sense, a linear ﬁt
betweenGandfmaxwasproposedforfmax> 180:
G ¼ –C1(f – 80) + C2, where C1 and C2 are
positive constants that depend on the friction coef-
ﬁcient. This relationship holds for materials with
different friction coefﬁcients. By extrapolating the
curve, a limit value of fmax close to 200 was
found for steel beads (the exact value depends on
the material). Interestingly, the distribution of f
revealed an abrupt decrease at an angle around
200. Therefore, this ﬁgure was interpreted as a
cut-off value above which particles cannot be
sustained by frictional forces anymore. A simple
model was proposed to account for the relationship
between G and fmax explained above.
As a general result, it was concluded that the
bead with fmax was the weakest link in the arch,
especially if that angle was bigger than 180. Apart
from the dependence of the arch robustness on
fmax explained above, it was also evidenced that
the likelihood of the arch breaking precisely at that
defect was bigger than in other positions. Then, in a
subsequent work (Lozano et al. 2015) these ﬁnd-
ings were generalized to other acceleration ramps,
and several outlet sizes. In particular, it was found
that even comparing sets of arches with the same
maximum angle, the ones corresponding to larger
outlet sizes displayed lower values of G, indicating
that fmax is not the only variable determining the
stability of the clogging arch.
Arch Breaking Is a History Dependent Process
An alternative approach to study the arch breaking
process is to apply a constant vibration and mea-
sure the breaking time (or, the time it takes for the
vibration to shatter the arch and restore the ﬂow).
This is analogous to the procedure explained at the
beginning of this chapter as implemented in
(Janda et al. 2009b; Mankoc et al. 2009). How-
ever, in the cases that will be described below, the
external excitation was not acting all the time but
was started after the formation of a clogging arch
that was formed without vibration. With this pro-
cedure, it is guaranteed that the arches formed are
not broken by the impacts of particles coming
from above, or in other words, by the intrinsic
noise within the silo before all the kinetic energy
is dissipated.
Results of such an experiment were reported in
(Zuriguel et al. 2014) where risk analysis was
used to describe the time that arches can resist a
constant vibration. Let us call tb the time it takes to
160
170
180
190
200
0
0.5
1
1.5
2
2.5
3
3.5
φmax
Γ
Statistical Mechanics of
Clogging, Fig. 18 The
average maximum
acceleration G at the instant
of arch breaking, as a
function of fmax, the
maximum angle in the arch.
Triangles and circles
correspond to steel and
brass beads respectively.
Error bars are 95%
conﬁdence intervals.
(Reprinted from Lozano
et al. (2012b))
386
Statistical Mechanics of Clogging

break an arch. Then, the survival function S at
time t is deﬁned as the probability that an arch
lasts more than t. Mathematically,
S tð Þ  P tb > t
ð
Þ ¼
ð1
t
P t0
ð Þdt0
ð7Þ
where P(t) is the probability distribution function,
or pdf, of tb. Note that if P(t) ~ t-a
, then S(t) ~ t–a + 1.
Observations are robust in ﬁnding heavy tails
(see Fig. 19), meaning that for times larger than a
given value (tthreshold) S decays as a power law. As
stated before, this indicates that the probability of
breaking an arch is not constant along time. More-
over, it was conﬁrmed that in some cases the expo-
nent a is such that the integral does not converge. In
particular, the role of three parameters on the dis-
tribution of breaking times was explored in
Zuriguel et al. (2014). It was shown that increasing
the outlet size or the intensity of vibration leads to a
bigger a, whereas an increase of the number of
grains above the clogging arch implied a reduction
of the exponent. It was also demonstrated that
distributions for which the average diverges
(a  2) took place for low vibration intensities,
small oriﬁces, and large heights of the column of
grains above the clogging arch (Fig. 19).
In addition, the distributions of Fig. 19 reveal
that in some cases the curves ﬂatten for very large
times (typically above 100 s). Overall, the trends
displayed by the survival functions hint to the
following interpretation. When a constant vibra-
tion is imposed, some arches break down in a
relatively short time (say, a few tenths of seconds).
After this time (tthreshold), surviving arches are
harder and harder to break, so the breaking time
for these arches lacks any characteristic scale. In
this temporal range S(t) is compatible with a
power law decay. Finally, it seems that there are
a few arches that are even more enduring, so the
10–1
100
10–2
10–1
100
10–2
10–3
10–1
10–1
101
102
103
100
100
10–2
10–2
P(T ≥ τ)
τ (s)
P(T ≥ τ)
P(T ≥ τ)
10–3
Γ = 2.6
L = 4.50
h>6cm
α=1.9
α=1.9
α=1.9
α=2
α=2
h<6cm
Γ = 1.0
Γ = 1.5
Γ = 2.0
Γ = 2.6
L = 4.76 mm
L = 4.00 mm
L = 4.50 mm
L = 4.65 mm
L = 4.76 mm
L = 4.84 mm
Γ = 2.6
α=4.7
α=2.2
α=2.2
α=1.6
α=1.7
α=2.3
Statistical Mechanics of
Clogging, Fig. 19 Clog-
ging time distributions in a
two-dimensional silo. (Top)
Time lapse complementary
CDFs obtained using
L ¼ 4.50 and G ¼ 0.26 for
two different heads of
grains above the silo bottom
(h < 6 cm and h > 6 cm).
(Middle) Time lapse com-
plementary CDFs obtained
for h > 6 cm, L ¼ 4.76 and
several G as indicated in the
legend. (Bottom) Time
lapse complementary CDFs
obtained for h > 6 cm,
G ¼ 0.26, and several outlet
sizes as indicated in the
legend. (Reprinted from
Zuriguel et al. (2014))
Statistical Mechanics of Clogging
387

vibration seems unable to break them, and cause a
ﬁnal ﬂattening of the distribution. This latter result
was conﬁrmed in Lozano et al. (2015) where for
some of experimental conditions the distribution
almost completely ﬂattened after a time of about
50 to 100 s, suggesting that there are some arches
that the vibration cannot break for the parameter
range explored.
In order to unveil the origin of the broad tails of
the breaking times distributions and the ﬁnal ﬂat-
tening, Guerrero et al. analyzed the movements of
individual beads in an arch along time prior to
their collapse (Guerrero et al. 2018). They
observed that under a gentle, constant vibration,
the
beads
hardly
move
except
for
fast
rearrangements (fast meaning that they take
place in a short time compared to the life of the
arch). This can be observed by plotting the tem-
poral evolution of the values of {fi} for all the
beads in the arch. Alternatively, one can use a
single number: s (the standard deviation of all
the values fi found in a given arch) which cap-
tures the rearrangements of the arch as illustrated
in Fig. 20.
A key feature that can be deduced from these
time series is that the angle rate of change is not
proportional to the angle itself. From experiments
with a vibration ramp one could have naively
Statistical Mechanics of Clogging, Fig. 20 Evolution
of two different long-lasting broken arches, (a) plus (c),
and (b) plus (d). Upper panels show f(t) for each grain.
The lower panels show s (the standard deviation of all the
values fi found in a given arch). The color and the number
on the right side of each f(t) curve indicate the bead of the
arch (see the insets in lower ﬁgures). The inset shows the
position of each bead of the arch at two instants: just after
starting the vibration (solid line) and just before the col-
lapse (dashed line). Reprinted from Guerrero et al. (2018)
388
Statistical Mechanics of Clogging

expected that at least the bead associated to the
biggest angle (the most dangerous one) would
evolve in such a way that its angle would monot-
onously grow until it reached the point of col-
lapse. This is not the case if the arch is submitted
to a gentle, constant vibration. The evolution of
individual
angles
is
much
more
complex
than that.
In order to analyze the slow relaxation dynam-
ics, one can calculate the two time autocorrelation
function of s, for a lag time t and a waiting time tw:
C tw, t
ð
Þ ¼ s tw þ t
ð
Þs tw
ð Þ
h
i  s tw þ t
ð
Þ
h
i s tw
ð
Þ
h
i
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
VAR s tw
ð Þ
ð
ÞVAR s tw þ t
ð
Þ
ð
Þ
p
ð8Þ
where h. . .i denotes the ensemble average. It was
found that the correlation decreases with t; but
notably, it also depends on tw, denoting that the
process is not stationary along time. For long
waiting times, C tends to a limit value. It had
been pointed out (Nicodemi and Coniglio 1999)
that aging effects often show a logarithmic depen-
dence on this time, and this was precisely the
behavior observed for the dependence of C on tw
for a ﬁxed t.
Aging is a nonergodic process in which the
ensemble average and the time average are not
equivalent. Some models have been proposed to
explain the behavior of these arches. Nicolas and
coworkers (2018) considered that the arch being
vibrated is able to explore an energy landscape in
which traps represent more stable conﬁgurations.
Using a simple shape for the energy wells and the
escape rate proposed by H. Kramers (1940), a
survival function that reproduces the basic features
of the experimental observations was obtained.
Also, in an effort to understand nonergodicity,
C. Merrigan and coworkers (2018) rationalized
the intermittent motion of the beads as a continuous
time random walk of a vector whose components
are the angles {fi} of the arch. They simulated
vibrated arches and noted how this model is con-
sistent with ergodicity breaking. They went on to
compare some of the numerical results with exper-
iments, ﬁnding an overall good agreement, not-
withstanding
several
discrepancies
(Guerrero
et al. 2019). The notion of the arch performing a
random walk in the space of locally stable arch
shapes, where each shape is characterized by a
dwelling time that depends on the depth of the
trap, is therefore quite reasonable.
Summary and Discussion
Along this work we have summarized the existing
knowledge about clogging of macroscopic inert
particles when passing through a constriction. The
typical instance of this scenario is the discharge of
a silo through a small oriﬁce, a system in which it
is well accepted that the development of clogging
can be described as a Poisson process. The reason
behind this is that the emergence of a clog is
equally likely at any time during the discharge.
In practice, this feature is typically inferred from
the statistics of the avalanche sizes which, in all
cases but in narrow slits, reveal an exponential
tail. This implies that the mean avalanche size
(as well as the mean avalanche duration or the
probability of clogging) is always well deﬁned.
As a matter of fact, for its simplicity and easi-
ness to obtain, the avalanche size is often used to
characterize the effect of different variables on
clogging development. Among these variables,
the most inﬂuential is clearly the outlet size
(or more precisely, the ratio between the outlet
and particles size). Indeed, it is known that the
mean avalanche size abruptly grows when this
parameter is increased. The question about the
existence of a critical outlet size above which
clogging is not possible is still open, although
mounting evidences suggest that the clogging
transition is similar to the glass and jamming
ones. In these cases, relaxation times grow dra-
matically but do not necessarily imply the exis-
tence of a critical point.
Concerning other parameters that affect clog-
ging, we have underlined the role of two: the
volume fraction and the velocity of the grains at
(or near) the oriﬁce. The former is a contributing
factor, as it determines the probability that a given
number of grains coincide above the outlet and
form an arch. The latter, however, has been argued
to affect the number of these arches that are able to
Statistical Mechanics of Clogging
389

become stabilized and survive after all the kinetic
energy within the system is dissipated. Then, the
higher the velocity of the grains, the smaller the
number of arches that are stable, and therefore the
lower the probability of clogging. Interestingly,
the reason for which a suitably placed obstacle
above the oriﬁce is able to dramatically reduce the
clogging probability can be associated to an alter-
ation of these two parameters: the obstacle
reduces the pressure, conﬁnement and packing
fraction near the oriﬁce (so it prevents arch for-
mation), and besides, it alters the velocity ﬁeld
increasing the kinetic energy of the grains at the
outlet (so it prevents arch stabilization).
Once a clog is formed, an external input of
energy is necessary to resume the ﬂow. The most
widely employed method to perform this task is to
apply a vibration (either locally at the exit, or to
the whole silo). For low intensity vibrations, it has
been reported that the distributions of breaking
times (i.e., the time that takes since the vibration
is applied until the collapse of the arch) display fat
tails. These tails can be ﬁtted to power laws,
whose exponents depend on different parameters
such as the intensity of vibration, the outlet size,
and the height of the layer of grains within the silo.
It has been remarked that in some cases, the expo-
nent of the power law is smaller than two, a
feature implying that the ﬁrst moment of the dis-
tribution cannot be calculated as the integration
does not converge.
It is noteworthy that the different nature of the
ﬂowing and the clogging times – the former being
an
exponential
distribution,
and
the
latter
displaying a power law tail – has also been
observed in the passage through bottlenecks of
other discrete systems. In particular, it was exper-
imentally shown (Zuriguel et al. 2014) that the
ﬂow of sheep through narrow doors displayed an
intermittency that could be described within this
framework. Moreover, in this scenario, the distri-
bution of clogging times when placing an obstacle
in front of the door revealed an exponent higher
than obtained in a standard entrance (without
obstacle); this implies a beneﬁcial effect of the
obstacle as it reduces the number of long lasting
clogs. In the same work, simplistic simulations of
pedestrian evacuations through a bottleneck also
showed how reducing the desired speed of the
agents (which in a congested scenario amounts
to diminishing the driving force) lead to an aug-
ment of the power law exponent, improving the
ﬂow. The same effect was reached when increas-
ing the outlet size or the intrinsic noise included in
the movement of these bodies. Finally, in a simu-
lated colloidal suspension, it was also observed an
augment of the exponent when increasing the bath
temperature.
Considering all these outcomes, a phase dia-
gram of sorts was proposed to account for the
clogging behavior in different systems of solid
particles ﬂowing through bottle-necks (Zuriguel
et al. 2014). The order parameter introduced was
F ¼
t f
h i
tc
h iþ t f
h i where htfi is the average duration of
the ﬂow intervals and htci is the average clog
duration. As htci only converges when the expo-
nent a of the power law is larger than two, a  2
implies F ¼ 0; a feature that was proposed to
qualify the “clogged state.” On the contrary, when
F > 0 it can be said the system is in an “unclogged
state.” In the latter scenario, the ﬂow can be either
continuous if F ¼ 1, or intermittent if 0 < F < 1.
From this, the effect of the different variables in the
values of F was tested, checking that the system
could reach the clogged state (i.e., F ¼ 0) by
decreasing the exit size and reducing the particle’s
excitation (intrinsic or external). Also, augmenting
the pressure at the narrowing seemed to drive the
system to a clogged state. According to these ﬁnd-
ings, and inspired along the concepts of compatible
and incompatible load introduced by Cates et al. at
the end of the last century (Cates et al. 1998), all the
variables affecting clogging were encompassed in
three general magnitudes: the characteristic size of
the neck (l), the incompatible load (IL) and the
compatible load (CL) as depicted in Fig. 21 (left).
For the case of a vibrated silo, a more detailed
phase diagram for the plane G – D (which in the
framework of the generic variables corresponds to
the plane IL – l) was reported in Zuriguel et al.
(2017) (see Fig. 21, right).
In recent years, several lines of investigation
have reported a number of results which are
390
Statistical Mechanics of Clogging

congruent with the proposed global framework.
For example, real pedestrian drills evidenced that
the stronger the force applied by the crowd in their
way out of a room, the slower the evacuation
(which can be considered as a slightly modiﬁed
version of the traditional Faster is Slower phe-
nomenon in pedestrian dynamics) (Pastor et al.
2015). The reason behind this behavior was on
the increment of the clogging times with a higher
force (compatible load). Also, it seems that the
increment of the compatible load was behind the
transition from unclogged to clogged states reported
for the ﬂow of small robots (Vibration-Driven Vehi-
cles) when passing through a narrowing (Patterson
et al. 2017). In that case, instead of altering the force
of each individual, the increment of the compatible
load was achieved by increasing the number of
agents inside the room.
Apart from the interest of the phase diagram
from the point of view of clogging, its resem-
blance to the scheme introduced for the jamming
transition by Liu and Nagel (1998) has stimulated
recent investigations on the relation among these
two states. In principle, clogging and jamming are
two well-differentiated phenomena: clogging is a
local occurrence triggered by the formation of a
mesoscopic structure (an arch) that is able to arrest
the grains (or bodies) behind it; on the contrary,
jamming is a global state of the matter where
different kind of spatially averaged quantities
can be measured and used to characterize the
system response.
Recently, Reichhardt and collaborators have
started to investigate the connection between
these two phenomena (Nguyen et al. 2017; Péter
et al. 2018). To this end, they have developed
numerical simulations of the ﬂow of particles
through arrays of obstacles, implemented as pinned
particles (see Fig. 22, left). Then, depending on the
number of pinned and mobile particles, the system
was found to reach different stationary states: ﬂuid,
clogged, or jammed, as illustrated in Fig. 22 (right).
Remarkably, the clogging transition was reported
to have characteristics of an absorbing phase tran-
sition in which, after a transient time, the system
evolves into a heterogeneous state as the one
represented in Fig. 22 (left). This transient time
was shown to diverge at the transition as illustrated
by the yellow region in Fig. 22 (right). In contrast,
jamming was proved to be a rapid process in which
the sample does not reveal any sign of heterogene-
ity. In this case, the magnitude that diverges as the
jamming density is approached turns out to be the
rigidity.
Statistical Mechanics of Clogging, Fig. 21 Left,
generic phase diagram proposed for the ﬂow of many-
particle systems through bottlenecks. Right, phase diagram
for the plane G – D obtained for the locally vibrated
eccentrically discharged hopper used in (Janda et al.
2009b). Stars indicate points where F ¼ 0 (clogged
phase) and circles
show
positions where F
> 0
(unclogged phase). The dashed line is a guide to the eye
suggesting a possible boundary between the two phases.
(Reprinted from (Zuriguel et al. 2014) (left) and (Zuriguel
et al. 2017) (right))
Statistical Mechanics of Clogging
391

All these results – which are similar to the ones
reported in a previous work of Tejada et al.
(2016) – have been partially conﬁrmed by Stoop
and Tierno in experiments where they drove col-
loidal monolayers across different arrays of obsta-
cles (Stoop and Tierno 2018). Remarkably, in the
experimental conditions implemented in this
research, the Faster is Slower effect –characteris-
tic of the ﬂow through bottlenecks of pedestrians –
was also identiﬁed. Again, this is another evi-
dence that supports the existing connections on
the behavior of different many-body systems
when ﬂowing through constrictions.
Future Directions
Although the amount of knowledge gained in the
last two decades on the silo clogging problem is
rather considerable, it is also true that the number
of questions that are still unanswered is also
numerous. Here, we are going to indicate some
of the problems we consider more stimulating,
either from a fundamental or by an applied point
of view.
First, it will be interesting to deepen in the
relationship among clogging and jamming. As
mentioned above, this topic has been approached
within the framework of a simulation where a
dense sample of mobile particles ﬂows through a
series of obstacles. Although the ﬁndings of these
simulations have been somehow validated by
experiments with colloidal suspensions, it would
be nice to see if the same behavior can be exper-
imentally tested using dry macroscopic grains.
Also, there are some other systems which may
help to shed light on this jamming-clogging con-
nection. One of these is the ﬂow of inert grains
through very narrow pipes. In this geometrical
conﬁguration, it has been recently shown that
clogging is also possible due to the development
of hanging arches supported by frictional forces
against the wall (Janda et al. 2015; Verbücheln
et al. 2015). As in this pipe ﬂow there is not a
bottleneck that introduces a local inhomogeneity,
it is possible that the conditions leading to clog-
ging are comparable to the ones leading to jam-
ming. In addition, the study of clogging in narrow
vertical pipes is of great applied interest as the
formation of hang-ups is one of the major
Statistical Mechanics of Clogging, Fig. 22 Left: Final
clogged state of mobile disks (blue open circles) driven in
the positive x direction through obstacles (red ﬁlled circles)
in a sample with obstacle density fobs ¼ 0.175 and disk
density fm ¼ 0.436. Right: Map of the transient times t
obtained depending on fobs vs fm. Yellow corresponds to
large t and blue to small t as indicated in the legend. The
dark dashed line is a guide to the eye marking the crossover
from a ﬂowing state to a clogged state, while the white
dashed line indicates the transition from a ﬂowing state to a
jammed state. In the white region, there are not data as it is
above the maximum density that could be reached in the
implemented model. (Reprinted from Péter et al. (2018))
392
Statistical Mechanics of Clogging

problems in ore transportation in underground
mining (Hadjigeorgiou and Stacey 2013).
Another issue that should be carefully investi-
gated in the forthcoming years is the parallels
among clogging in 2D and 3D scenarios. Although
most of the features observed in relation with clog-
ging are similar in two and three dimensions, some
differences exist. The most salient one concerns the
divergence of the mean avalanche size with the
outlet size, which seems to take place in 3D silos
but has been practically discarded in 2D ones. In
addition, the statistical analysis of the properties of
arches and the effect of different variables (such as
the hopper angle) has been mostly approached
using 2D silos, so an extension to 3D scenarios is
needed. This could be tackled by studying the role
played
by
the
silo
thickness
in
quasi-two-
dimensional geometries, gradually changing from
a 2D silo formed by a monolayer of grains to a fully
3D case.
Considering the role of all the different vari-
ables summarized in this work, it seems that
investigating the effect of combining more than
one of these parameters can be fruitful to better
understand the physical mechanism behind clog-
ging. For example, knowing the dramatic aug-
ment of the probability of clogging occurring
when the grains ﬂow through the outlet in a
quasi-static manner, it would be interesting to
see if in this regime the effect of geometrical
aspects (such as the hopper angle or the placement
of an obstacle) is similar to the one observed in
conditions of free discharge. In this way we will
be able to ascertain if the role of these variables is
due to its effect on the geometrical or dynamical
aspects. Also, further investigation in the conﬁg-
uration where the grains are extracted by an exter-
nal device (a belt or an endless screw) is important
because this is a common procedure in industry.
Doubtless, more investigations are needed in
other systems that could also display clogging,
such as active matter or pedestrian dynamics. Of
course, this research is not straightforward given
the complex nature of the agents involved in these
ﬁelds and the intrinsic difﬁculty associated to
performing experiments at the micro scale or
with pedestrians. Nevertheless, other systems
such as macroscopic active materials (or small
robots) can be reasonable models in which to
incorporate some intrinsic activity to the particles
and compare with the behavior of inert granular
media. Similar reasoning holds for very promising
studies of submerged grains (Koivisto and Durian
2017) and suspended particles (Guariguata et al.
2012; Lafond et al. 2013; Marin et al. 2018),
which can be seen as examples with a behavior
that is halfway between granular materials and
colloidal suspensions.
Bibliography
Ahmadi A, Hosseininia ES (2018) An experimental inves-
tigation on stable arch formation in cohesionless gran-
ular materials using developed trapdoor test. Powder
Technol 330:137–146
Arévalo R, Zuriguel I, Maza D, Garcimartín A (2014) Role
of driving force on the clogging of inert particles in a
bottleneck. Phys Rev E 89:042205
Arnold P, McLean A (1976) An analytical solution for the
stress function at the wall of a converging channel.
Powder Technol 13(2):255–260
Ashour A, Trittel T, Börzsönyi T, Stannarius R (2017a)
Silo outﬂow of soft frictionless spheres. Phys Rev
Fluids 2(12):123302
Ashour A, Wegner S, Trittel T, Börzsönyi T, Stannarius
R (2017b) Outﬂow and clogging of shape-anisotropic
grains in hoppers with small apertures. Soft Matter
13(2):402–414
Beverloo W, Leniger H, van de Velde J (1961) The ﬂow of
granular solids through oriﬁces. Chem Eng Sci
15(3):260–269
Cates ME, Wittmer JP, Bouchaud J-P, Claudin P (1998)
Jamming, force chains, and fragile matter. Phys Rev
Lett 81:1841–1844
Chen K, Stone MB, Barry R, Lohr M, McConville W,
Klein K, Sheu B, Morss A, Scheidemantel T, Schiffer
P (2006) Flux through a hole from a shaken granular
medium. Phys Rev E 74(1):011306
Chevoir F, Gaulard F, Roussel N (2007) Flow and jamming
of granular mixtures through obstacles. Europhys Lett
(EPL) 79(1):14001
Clément E, Reydellet G, Rioual F, Parise B, Fanguet V,
Lanuza J, Kolb E (2000) Jamming patterns and block-
ade statistics in model granular ﬂows. In: Helbing D,
Herrmann HJ, Schreckenberg M, Wolf DE (eds) Trafﬁc
and granular ﬂow ’99. Springer Berlin Heidelberg,
Berlin/Heidelberg, pp 457–468
Daniels KE, Kollmer JE, Puckett JG (2017) Photoelastic
force measurements in granular materials. Rev Sci
Instrum 88(5):051808
Davies C, Desai M (2008) Blockage in vertical slots:
experimental measurement of minimum slot width for
a variety of granular materials. Powder Technol
Statistical Mechanics of Clogging
393

183(3):436–440. Festschrift issue in honor of Professor
Robert Pfeffer – articles presented at the honoring
session of the AIChE annual meeting in 2006
Divoux T, Gayvallet H, Géminard J-C (2008) Creep
motion of a granular pile induced by thermal cycling.
Phys Rev Lett 101:148303
Dorbolo S, Maquet L, Brandenbourger M, Ludewig F,
Lumay
G,
Caps
H,
Vandewalle
N,
Rondia
S,
Mélard M, van Loon J, Dowson A, Vincent-Bonnieu
S (2013) Inﬂuence of the gravity on the discharge of a
silo. Granul Matter 15(3):263–273
Drescher A, Waters A, Rhoades C (1995) Arching in
hoppers: II. Arching theories and critical outlet size.
Powder Technol 84(2):177–183
Endo K, Reddy KA, Katsuragi H (2017) Obstacle-shape
effect in a two-dimensional granular silo ﬂow ﬁeld.
Phys Rev Fluids 2:094302
Evesque P, Meftah W (1993) Mean ﬂow of a vertically
vibrated hourglass. Int J Mod Phys B 7(09n10):
1799–1805
Garcimartín A, Zuriguel I, Pugnaloni LA, Janda A (2010)
Shape of jamming arches in two-dimensional deposits
of granular materials. Phys Rev E 82:031306
Gella D, Maza D, Zuriguel I, Ashour A, Arévalo R,
Stannarius R (2017) Linking bottleneck clogging with
ﬂow kinematics in granular materials: the role of silo
width. Phys Rev Fluids 2:084304
Gella D, Zuriguel I, Maza D (2018) Decoupling geometri-
cal and kinematic contributions to the silo clogging
process. Phys Rev Lett 121:138001
GoldbergE, Carlevaro CM, Pugnaloni LA (2018) Clogging
in two-dimensions: effect of particle shape. J Stat
Mech: Theory Exp 2018(11):113201
Guariguata A, Pascall MA, Gilmer MW, Sum AK, Sloan
ED, Koh CA, Wu DT (2012) Jamming of particles in a
two-dimensional
ﬂuid-driven
ﬂow.
Phys
Rev
E 86:061311
Guerrero BV, Pugnaloni LA, Lozano C, Zuriguel I,
Garcimartín A (2018) Slow relaxation dynamics of
clogs in a vibrated granular silo. Phys Rev E 97:042904
Guerrero BV, Chakraborty B, Zuriguel I, Garcimartín
A (2019) Nonergodicity in silo unclogging: broken
and unbroken arches. Phys Rev E 100:032901
Hadjigeorgiou J, Stacey T (2013) The absence of strategy
in orepass planning, design, and management. J South
Afr Inst Min Metall 113:795–801
Helbing D, Johansson A, Mathiesen J, Jensen MH,
Hansen A (2006) Analytical approach to continuous
and intermittent bottleneck ﬂows. Phys Rev Lett
97(16):168001
Hidalgo RC, Lozano C, Zuriguel I, Garcimartín A (2013)
Force analysis of clogging arches in a silo. Granul
Matter 15(6):841–848
Hong X, Kohne M, Morrell M, Wang H, Weeks ER
(2017) Clogging of soft particles in two-dimensional
hoppers. Phys Rev E 96:062605
Hou M, Chen W, Zhang T, Lu K, Chan C (2003) Global
nature of dilute-to-dense transition of granular ﬂows in
a 2d channel. Phys Rev Lett 91(20):204301
Janda A, Zuriguel I, Garcimartín A, Pugnaloni LA, Maza
D (2008) Jamming and critical outlet size in the dis-
charge of a two-dimensional silo. EPL (Europhys Lett)
84(4):44002
Janda A, Harich R, Zuriguel I, Maza D, Cixous P,
Garcimartín A (2009a) Flow-rate ﬂuctuations in the
outpouring of grains from a twodimensional silo.
Phys Rev E 79:031302
Janda A, Maza D, Garcimartín A, Kolb E, Lanuza J, Clém-
ent E (2009b) Unjamming a granular hopper by vibra-
tion. EPL (Europhys Lett) 87(2):24002
Janda A, Zuriguel I, Garcimartín A, Maza D (2015) Clog-
ging of granular materials in narrow vertical pipes
discharged
at
constant
velocity.
Granul
Matter
17(5):545–551
Janssen HA (1895) Versuche uber getreidedruck in
silozellen. Z Ver Dtsch Ing 39(35):1045–1049
Jenike AW (1964) Steady gravity ﬂow of frictional-
cohesive solids in converging channels. J Appl Mech
31(1):5–11
Kamath S, Kunte A, Doshi P, Orpe AV (2014) Flow of
granular matter in a silo with multiple exit oriﬁces:
jamming to mixing. Phys Rev E 90(6):062206
Kohring G, Melin S, Puhl H, Tillemans H, Vermöhlen
W (1995) Computer simulations of critical, non-
stationary granular ﬂow through a hopper. Comput
Methods Appl Mech Eng 124(3):273–281
Koivisto J, Durian DJ (2017) Effect of interstitial ﬂuid on
the fraction of ﬂow microstates that precede clogging in
granular hoppers. Phys Rev E 95:032904
Kondic L (2014) Simulations of two dimensional hopper
ﬂow. Granul Matter 16(2):235–242
Kramers HA (1940) Brownian motion in a ﬁeld of force
and the diffusion model of chemical reactions. Physica
7(4):284–304
Kunte A, Doshi P, Orpe AV (2014) Spontaneous jamming
and unjamming in a hopper with multiple exit oriﬁces.
Phys Rev E 90:020201
Lafond PG, Gilmer MW, Koh CA, Sloan ED, Wu DT, Sum
AK (2013) Oriﬁce jamming of ﬂuid-driven granular
ﬂow. Phys Rev E 87:042204
Liu AJ, Nagel SR (1998) Nonlinear dynamics: jamming is
not just cool any more. Nature 396(6706):21
Longhi E, Easwar N, Menon N (2002) Large force ﬂuctu-
ations in a ﬂowing granular medium. Phys Rev Lett
89:045501
Longjas A, Monterola C, Saloma C (2009) Force analysis
of jamming with disks of different sizes in a two-
dimensional
hopper.
J
Stat
Mech:
Theory
Exp
2009(05):P05006
López-Rodríguez
D,
Gella
D,
To,
K,
Maza
D,
Garcimartín A, Zuriguel I (2019) Effect of hopper
angle on granular clogging. Phys Rev E 99:032901
Lozano C, Janda A, Garcimartín A, Maza D, Zuriguel
I (2012a) Flow and clogging in a silo with an obstacle
above the oriﬁce. Phys Rev E 86:031306
Lozano C, Lumay G, Zuriguel I, Hidalgo RC, Garcimartín
A (2012b) Breaking arches with vibrations: the role of
defects. Phys Rev Lett 109:068001
394
Statistical Mechanics of Clogging

Lozano C, Zuriguel I, Garcimartín A (2015) Stability of
clogging arches in a silo submitted to vertical vibra-
tions. Phys Rev E 91:062203
Mankoc C, Garcimartín A, Zuriguel I, Maza D, Pugnaloni
LA (2009) Role of vibrations in the jamming and
unjamming of grains discharging from a silo. Phys
Rev E 80:011309
Marin A, Lhuissier H, Rossi M, Kähler CJ (2018) Clogging
in constricted suspension ﬂows. Phys Rev E 97:021102
Masuda T, Nishinari K, Schadschneider A (2014) Critical
bottleneck size for jamless particle ﬂows in two dimen-
sions. Phys Rev Lett 112:138701
Merrigan C, Birwa SK, Tewari S, Chakraborty B (2018)
Ergodicity breaking dynamics of arch collapse. Phys
Rev E 97:040901
Mondal S, Sharma MM (2014) Role of ﬂying buttresses in
the jamming of granular matter through multiple rect-
angular outlets. Granul Matter 16(1):125–132
Mueth DM, Jaeger HM, Nagel SR (1998) Force distribu-
tion in a granular medium. Phys Rev E 57:3164–3169
Nguyen HT, Reichhardt C, Reichhardt CJO (2017) Clog-
ging and jamming transitions in periodic obstacle
arrays. Phys Rev E 95:030902
Nicodemi M, Coniglio A (1999) Aging in out-of-
equilibrium dynamics of models for granular media.
Phys Rev Lett 82(5):916
Nicolas A, Garcimartín Á, Zuriguel I (2018) Trap model
for clogging and unclogging in granular hopper ﬂows.
Phys Rev Lett 120(19):198002
Pacheco-Martinez H, Van Gerner HJ, Ruiz-Suárez J (2008)
Storage and discharge of a granular ﬂuid. Phys Rev
E 77(2):021303
Parretta A, Grillo P (2019) Flow dynamics of spherical
grains through conical cardboard hoppers. Granul Mat-
ter 21(2):31
Pastor
JM,
Garcimartín
A,
Gago
PA,
Peralta
JP,
MartínGómez C, Ferrer LM, Maza D, Parisi DR,
Pugnaloni LA, Zuriguel I (2015) Experimental proof
of faster-is-slower in systems of frictional particles
ﬂowing
through
constrictions.
Phys
Rev
E 92(6):062817
Patterson GA, Fierens PI, Sangiuliano Jimka F, König PG,
Garcimartín A, Zuriguel I, Pugnaloni LA, Parisi DR
(2017) Clogging transition of vibration-driven vehicles
passing through constrictions. Phys Rev Lett 119:248301
Pérez G (2008) Numerical simulations in granular matter:
the discharge of a 2d silo. Pramana 70(6):989–1007
Péter H, Libál A, Reichhardt C, Reichhardt CJ (2018) Cross-
over from jamming to clogging behaviours in heteroge-
neous environments. Sci Rep 8(1):10252
Pournin
L,
Ramaioli
M,
Folly
P,
Liebling
TM
(2007) About the inﬂuence of friction and poly-
dispersityon the jamming behavior of bead assemblies.
Eur Phys J E 23(2):229
Pugnaloni LA, Valluzzi MG, Valluzzi LG (2006) Arching
in tapped deposits of hard disks. Phys Rev E 73:051302
Roussel N, Nguyen TLH, Coussot P (2007) General prob-
abilistic approach to the ﬁltration process. Phys Rev
Lett 98(11):114502
Sakaguohi H, Ozaki E, Igarashi T (1993) Plugging of the
ﬂow of granular materials during the discharge from a
silo. Int J Mod Phys B 07(09n10):1949–1963
Saraf S, Franklin SV (2011) Power-law ﬂow statistics in
anisometric (wedge) hoppers. Phys Rev E 83:030301
Serrano DA, Cabrera D, Gutiérrez GJ, Medina A (2014)
Experimental study of mass ﬂow rate in a Silo under the
wall width inﬂuence. Springer International Publish-
ing, Cham, pp 207–217
Sheldon HG, Durian DJ (Dec 2010) Granular discharge
and
clogging
for
tilted
hoppers.
Granul
Matter
12(6):579–585
Stoop RL, Tierno P (2018) Clogging and jamming of
colloidal monolayers driven across disordered land-
scapes. Commun Phys 1(1):68
Suzuki A, Takahashi H, Tanaka T (1968) Behaviour of a
particle bed in the ﬁeld of vibration ii ﬂow of particles
through slits in the bottom of a vibrating vessel. Powder
Technol 2(2):72–77
Tang J, Behringer RP (2016) Orientation, ﬂow, and clog-
ging in a two-dimensional hopper: Ellipses vs. disks.
EPL (Europhys Lett) 114(3):34002
Tejada I, Sibille L, Chareyre B (2016) Role of blockages in
particle
transport
through
homogeneous
granular
assemblies. EPL (Europhys Lett) 115(5):54005
Tewari S, Dichter M, Chakraborty B (2013) Signatures of
incipient jamming in collisional hopper ﬂows. Soft
Matter 9:5016–5024
Thomas CC, Durian DJ (2013) Geometry dependence of
the clogging transition in tilted hoppers. Phys Rev
E 87:052201
Thomas CC, Durian DJ (Apr 2015) Fraction of clogging
conﬁgurations sampled by granular hopper ﬂow. Phys
Rev Lett 114:178001
Thomas CC, Durian DJ (2016) Intermittency and velocity
ﬂuctuations in hopper ﬂows prone to clogging. Phys
Rev E 94:022901
To K (2005) Jamming transition in two-dimensional hop-
pers and silos. Phys Rev E 71:060301
To K, Tai H-T (2017) Flow and clog in a silo with oscil-
lating exit. Phys Rev E 96(3):032906
To K, Lai P-Y, Pak HK (2001) Jamming of granular ﬂow in
a two dimensional hopper. Phys Rev Lett 86:71–74
To K, Yen Y, Mo Y-K, Huang J-R (2019) Granular ﬂow
from
silos
with
rotating
oriﬁce.
Phys
Rev
E 100(1):012906
Uñac RO, Vidales AM, Pugnaloni LA (2012) The effect of
the packing fraction on the jamming of granular ﬂow
through small apertures. J Stat Mech: Theory Exp
2012(04):P04008
Valdes JR, Santamarina JC (2008) Clogging: bridge for-
mation
and
vibration-based
destabilization.
Can
Geotech J 45(2):177–184
Vamsi Krishna Reddy A, Kumar S, Anki Reddy K, Talbot
J (2018) Granular silo ﬂow of inelastic dumbbells:
clogging and its reduction. Phys Rev E 98:022904
Verbücheln F, Parteli EJR, Pösohel T (2015) Helical inner-
wall texture prevents jamming in granular pipe ﬂows.
Soft Matter 11:4295–4305
Statistical Mechanics of Clogging
395

Walker D (1966) An approximate theory for pressures and
arching in hoppers. Chem Eng Sci 21(11):975–997
Wassgren CR, Hunt ML, Freese P, Palamara J, Brennen
C (2002) Effects of vertical vibration on hopper ﬂows
of granular material. Phys Fluids 14(10):3439–3448
Wes G, Stemerding S, van Zuiliohem D (1990) Control of
ﬂow of cohesive powders by means of simultaneous
aeration, and vibration. Powder Technol 61(1):39–49
Zhao Y, Cocco RA, Yang S, Chew JW (2019) Dem study
on the effect of particle-size distribution on jamming in
a 3d conical hopper. AICHE J 65(2):512–519
Zhou Y, Lagrée P-Y, Popinet S, Ruyer P, Aussillous
P (2017) Experiments on, and discrete and continuum
simulations of, the discharge of granular media from
silos with a lateral oriﬁce. J Fluid Mech 829:459–485
Zuriguel I, Pugnaloni LA, Garcimartín A, Maza D (2003)
Jamming during the discharge of grains from a silo
described
as
a
percolating
transition.
Phys
Rev
E 68:030301
Zuriguel I, Garcimartín A, Maza D, Pugnaloni LA, Pastor
JM (2005) Jamming during the discharge of granular
matter from a silo. Phys Rev E 71:051303
Zuriguel I, Janda A, Garcimartín A, Lozano C, Arévalo R,
Maza D (2011) Silo clogging reduction by the presence
of an obstacle. Phys Rev Lett 107:278001
Zuriguel I, Parisi DR, Hidalgo RC, Lozano C, Janda A,
Gago PA, Peralta JP, Ferrer LM, Pugnaloni LA,
Clément E, Maza D, Pagonabarraga I, Garcimartín
A (2014) Clogging transition of many-particle systems
ﬂowing through bottlenecks. Sci Rep 4:7324
Zuriguel I, Janda A, Arévalo R, Maza D, Garcimartín
A (2017) Clogging and unclogging of many-particle
systems passing through a bottleneck. EPJ Web Conf
140:01002
396
Statistical Mechanics of Clogging

Jamming of Granular Matter
Bulbul Chakraborty1 and Bob Behringer2
1Department of Physics, Brandeis University,
Waltham, MA, USA
2Department of Physics, Duke University,
Durham, NC, USA
Article Outline
Glossary
Deﬁnition of the Subject
Introduction
Statistical Framework of Jamming
Jamming Phase Diagram
Force Fluctuations, Dynamical Heterogeneities,
Length and Time Scales in Granular Flows
Approaching Jamming
Force Distributions, Length and Time Scales in
Jammed States Near the Jamming Transition
Isostaticity and Point J
Future Directions
Bibliography
Glossary
Granular matter Material such as sand or sugar,
which is composed of independent, macro-
scopic particles characterized by short range
interactions that do not conserve energy.
Energy is lost to excitations of internal degrees
of freedom, and is then unavailable for
macroscopic ﬂow.
Supercooled liquid A liquid cooled below its
freezing point by avoiding crystallization.
Shear deformation Deformation of a material in
which internal clusters or layers slide past each
other.
Couette ﬂow Flow between two surfaces one of
which is moving with respect to the other.
Definition of the Subject
A jammed material is deﬁned as one that is struc-
turally disordered but, unlike a ﬂuid, possesses an
yield stress. In the ﬁeld of traditional condensed
matter physics, such a material would be called an
amorphous solid. The broader use of “jammed”
extends this concept to non-traditional materials
such as granular systems, foams and colloids. Jam-
ming is, similarly, the extension of the concept of
freezing to the transition from a ﬂuid state to a
jammed state. Understanding jamming in granular
systems is important from technological, environ-
mental, and basic science perspectives. Jamming of
grains in silos causes catastrophic failures. Ava-
lanches are examples of unjamming, which we
need to understand prevent and control. The phe-
nomenon of jamming in granular matter poses fun-
damental challenges in basic science because there
is no known framework leading from the micro-
scopic, grain level interactions to the macroscopic
properties that reﬂect collective behavior.
Jamming in granular matter is intimately
related to stress propagation, and the nature of
jamming will depend on whether the material is
under shear or isotropic compression. It will also
depend on whether there is sustained motion with
the grains having a ﬁnite kinetic energy or if the
system is at rest and being slowly deformed. In the
following sections, we explore different types of
jamming in granular matter.
Introduction
Experiments point to many similarities between the
jamming transition in granular materials (Jaeger
et al. 1996a, b; Kadanoff 1999) and other similar
non-equilibrium transitions such as that in driven
foams, emulsions and gels. The common unifying
features are: (a) these are purely non-equilibrium
transitions
since
the
ﬂowing
state
can
be
Bob Behringer: deceased.
© Springer-Verlag 2009
B. Chakraborty (ed.), Statistical and Nonlinear Physics,
https://doi.org/10.1007/978-1-0716-1454-9_298
Originally published in
R. A. Meyers (ed.), Encyclopedia of Complexity and Systems Science, © Springer-Verlag 2009
https://doi.org/10.1007/978-3-642-27737-5_298
397

maintained only by external driving, (b) the sys-
tems exhibit anomalously slow dynamics as the
transition is approached and (c) there are no obvi-
ous structural signatures of the transition. By struc-
tural, we refer to the geometric arrangement of
particles. In addition, we will see that there is
increasing evidence for a divergence in correlation
functions for forces in the granular case. Features
(b) and (c) are, in fact, similar to a transition in a
thermal system; that of a supercooled liquid under-
going the glass transition. The origin of the slow
dynamics and the relationship between time and
length scales has been studied extensively in the
context of the glass transition in supercooled liq-
uids, and it has been shown that the dynamics
becomes spatially heterogeneous as the glass tran-
sition is approached (Weeks et al. 2000; Donati
et al. 1998; Donati et al. 1999; Berthier et al.
2005). There is a time scale and a length scale
associated with dynamical heterogeneities and
these
have
been
measured
in
experiments
(Berthier et al. 2005) and simulations (Lacevic
et al. 2003). Inspired by this framework, dynamical
heterogeneities have been explored in experiments
on granular systems approaching jamming and a
length and time scale associated with the jamming
transition has been identiﬁed (Keys et al. 2007;
Dauchot et al. 2005; Pouliquen 2004).
In granular systems, there is a type of heteroge-
neity arising from stress transmission which is dis-
tinct
from
the
heterogeneity
of
particle
displacements and density ﬂuctuations that are com-
mon to both supercooled liquids and granular mat-
ter. Stress heterogeneities in ﬂowing granular matter
has been studied in experiments on Couette shear
ﬂow (Miller et al. 1996; Howell and Behringer
1999; Veje et al. 1999; Geng et al. 2003; Daniels
and Behringer 2005a, b, 2006) and in hopper ﬂow
(Longhi et al. 2002). Simulations have a played a
seminal role in the developments leading up to the
dynamical heterogeneities framework in super-
cooled liquids. Likewise, simulations of granular
ﬂows can play a role in clarifying the relationship
between heterogeneity in different dynamical vari-
ables. For instance, a simulation of grains ﬂowing
through a hopper (a long, vertical tube with a narrow
opening at the bottom), has identiﬁed/characterized
both
stress
and
displacement
heterogeneities.
However, a clear relationship between the two has
not been identiﬁed (Ferguson and Chakraborty
2007). Indeed, there may be some reason to think
that there is anti-correlation between the strong
force structures of force chains, and the freedom
needed for density ﬂuctuations. Dynamical hetero-
geneities have been explored in simulations of other
types of dense granular ﬂows (Silbert et al. 2002,
2007; Silbert 2005).
The similarities in dynamics between super-
cooled liquids and granular systems have raised
the intriguing possibility of “universality” in the
jamming transition. Universality is a concept
associated with continuous phase transitions in
thermal systems such as the liquid-gas transition
or the Curie point in ferromagnets (Chandler
1987). In these systems, universality, owes its
origin to the presence of a diverging length-scale
at the transition. Microscopic properties of the
system can be coarse-grained because of the pres-
ence of this diverging length scale and universal-
ity classes can be speciﬁed by properties such as
the symmetry of the system and the spatial dimen-
sionality. These concepts are still evolving in the
context of granular systems. However, there are
an increasing number of studies that have identi-
ﬁed a growing, possibly diverging, length scale.
Statistical Framework of Jamming
The ubiquitous presence of force ﬂuctuations,
well-deﬁned statistical distributions and similari-
ties to thermal systems observed in granular sys-
tems close to jamming, have led researchers to
look for a statistical framework that can describe
the spatial and temporal ﬂuctuations in static and
quasi-static (weakly driven) granular ﬂows.
Experiments and simulations suggest that the
phenomenon of jamming has the ﬂavor of a phase
transition. Phase transitions can be broadly
divided into two classes: (a) Equilibrium and
(b) Non-equilibrium. The former encompasses
transitions such as the liquid-solid transition, the
superﬂuid and superconducting transitions, and
describes transitions between states which are in
thermal equilibrium. Non-equilibrium phase tran-
sitions are commonly observed in pattern-forming
398
Jamming of Granular Matter

systems such as chemical reactions, a well known
example being the Belousov–Zhabotinsky reac-
tion (Dolnik et al. 1996), or in ﬂuid ﬂows, such as
Raleigh–Bénard convection. The framework of
equilibrium
statistical
mechanics
is
well
established and can be used to analyze and under-
stand equilibrium phase transitions. In contrast,
there
is
no
universal
framework
for
non-
equilibrium phase transitions even though there
are many speciﬁc transitions which are well
understood (Dhar 2006; Schmittmann and Zia
1995). In many cases where non-equilibrium tran-
sitions occur, the systems are locally close to
thermal equilibrium, but not globally so. It is
then possible to use hydrodynamic-like descrip-
tions involving gradients in relevant quantities, as
well as transport models. Transitions in such sys-
tems often involve spatially extended modes
which become unstable or stable for different
control parameters. In the usual case, it is the
most unstable mode which dominates, and ther-
mal ﬂuctuations play a very limited role.
An interesting question is whether a statistical
approach can be used to understand jamming and
other phenomena in granular matter. In such an
approach, one would like to know the ensemble of
states that are consistent with the external con-
straints. In the granular case, there is some evi-
dence to suggest that ﬂuctuations are important,
particularly near jamming unlike the typical non-
equilibrium transition discussed above.
Granular Packings
A static granular packing is in mechanical equi-
librium if every grain satisﬁes the conditions of
force and torque balance. At the microscopic
level, the grains interact via contact forces,
which are frictional. For rigid grains, friction
leads to a microscopic indeterminacy of the forces
since the tangential force magnitude at a contact
has to be less than the normal force: |ft|  m fn,
where m is the friction coefﬁcient.
There is a broader class of indeterminacy
which has to do with the fact that there are many
packing conﬁgurations that are consistent with a
set of macroscopic constraints. For example, if
one shakes a box of marbles and examines the
positions of the marbles after the shaking has
stopped, the positions and the contact network
will be different each time one stops shaking.
This is analogous to the situation of systems in
thermal equilibrium: many microscopic conﬁgu-
rations of the oxygen molecules in a closed room
occur while the temperature and total volume
remain ﬁxed. Of course, in the granular case,
there is no internal ‘shaking’ mechanism.
The different conﬁgurations of systems in ther-
mal equilibrium (such as the oxygen molecules in
a room) have a given probability of occurring at a
given temperature. This probability is well known
from equilibrium statistical mechanics and is the
Boltzmann distribution: e–βE. Here β ¼ 1/kBT is
the inverse of the temperature T multiplied by the
Boltzman constant kB, and E is the energy of the
conﬁguration. The probability of ﬁnding a conﬁg-
uration is, therefore, completely determined by its
energy and does not depend on the particular
dynamics or the history. This is the essence of
systems in thermal equilibrium and leads to their
simplicity.
Edward’s Ensemble
The conﬁgurations of a box of marbles at the end
of a shaking experiment are certainly not in ther-
mal equilibrium. Marbles are large objects, and
they dissipate energy as heat when they interact.
Ordinary thermal ﬂuctuations are not relevant to a
box of marbles; one has to shake them to move
them and generate new states. These end states
are, however, static. A natural question to ask is
whether one can make a priori prediction of the
probability of occurrence of a particular conﬁgu-
ration, as we can for systems in thermal equilib-
rium. The ﬁrst theoretical approach to address this
question was that of the Edwards ensemble which
asserts that the total volume (V) of a mechanically
stable grain packing plays the role of energy, and
that there is a temperature-like quantity called the
compactivity (Edwards and Blumenfeld 2007;
Edwards and Grinev 1999, 2001; Edwards and
Oakeshott 1989). The mechanically stable grain
packings of inﬁnitely rigid objects have been
termed blocked states (Edwards and Grinev
2001), and are related to strictly jammed states
(Donev et al. 2004). The basic hypothesis under-
lying the Edwards ensemble is the microcanonical
Jamming of Granular Matter
399

(Chandler 1987) hypothesis that all blocked states
with the same total volume V are equally likely.
This hypothesis has been tested in numerical sim-
ulations, in experiments, and in some exactly
solvable models (Barrat et al. 2001; Barrat et al.
2000; Coniglio et al. 2001, 2002; Kurchan 2001;
Makse and Kurchan 2002). The consensus seems
to be that the hypothesis is not universally valid
but holds under some conditions. The Edwards
hypothesis involves the deﬁnition of the Edwards
entropy: S(V) ¼ ln Ω(V), where Ω(V) is the den-
sity of blocked states, that is, the number of
blocked states between V and V þ δV. Evaluating
this function has been a challenging problem,
although
progress
has
been
made
recently
(Blumenfeld and Edwards 2003).
Force Ensembles
The Edwards picture was originally based on the
assumption of completely rigid particles. How-
ever, all physical particles have ﬁnite stiffness,
and in the usual case, interact via frictional con-
tact forces. The conditions of ﬁnite vs. inﬁnite
stiffness and frictionless vs. frictional interac-
tions has some important consequences for gran-
ular packings. Relaxing the inﬁnite stiffness
constraint introduces couplings between the
positions of grains and the contact forces.
Below we discuss an ensemble for frictionless,
spherical particles.
A mechanically stable packing of frictionless,
deformable, spherical particles have to satisfy the
equations of force balance. In addition, there is
force law relating the positions of the particles to
the forces (Snoeijer et al. 2003a; Tkachenko and
Witten 1999). For grains interacting through
purely repulsive, short-range, forces, there are
dN equations of force balance for N grains in a
space of dimensionality d:
force  balance
dN eqs :
X
j
Fij
rij
j rij j ¼ 0
ð1Þ
force  law
zh iN=2 eqs : Fij ¼ f rij


ð2Þ
Here hzi is the average number of contacts per
grain, Fij is the magnitude of the contact force
between grains i and j, the angles of the contacts
being ﬁxed by the geometry, and f(rij) is a function
specifying the inter-grain force law. For a given
geometry, (i.e. ﬁxed
rij
jrijj), the equations of force
balance involve hziN/2 unknowns. The number of
force-balance equations cannot be greater than the
number of unknowns, otherwise the forces are
overdetermined, and, therefore, hziN/2  dN.
For rigid, non-deformable grains, the force law
becomes a constraint on the positions of the grains
(Tkachenko and Witten 1999). There is one con-
straint for each contact, which leads to hziN/2
equations for the dN positions, the unknowns.
Since the number of constraint equations have to
be larger than the number of unknowns, hziN/2
 dN. The force law and the force balance
constraints can, therefore be satisﬁed only if hzi ¼
ziso ¼ 2d. This enumeration argument applies only
to disordered packings, since for ordered, crystal-
line packings, angles of the lines connecting the
grains are not independent, and therefore, not all
the constraint equations are linearly independent.
Considering such disordered packings, the enu-
meration argument leads to the conclusion that
packings of rigid, isotropic, frictionless particles
have to be isostatic; they have to have hzi ¼ ziso.
For deformable particles, mechanically stable
packings can exist for hzi  ziso. If the particles are
very stiff, the magnitude of the forces change a lot
for small changes in the separation between
grains. There is, therefore, an effective separation
of scales (Snoeijer et al. 2003a, 2004a) in Eqs. (1)
and (2), and one can consider the ensemble of
forces which satisfy force-balance for a ﬁxed
geometry of the packing, i.e., a packing with
ﬁxed grain positions. The properties of such
force-ensembles have been studied (Snoeijer
et al. 2003a, b, 2004a, b, c, 2006; van Eerd et al.
2007), and it has been shown that P(F), the prob-
ability distribution function (PDF) of contact
forces, evolves to a exponential form as the parti-
cles are made increasingly rigid (Snoeijer et al.
2003a; 2004a). In addition, work on sheared and
isotropically compressed packings have shown
that there are more extended spatial correlations
of the forces in the force ensembles for sheared
packings (Tighe et al. 2005a).
400
Jamming of Granular Matter

The force ensemble approach captures many
features of packings near Point J. However, the
approach to this point involves coupling between
the geometry and forces, as observed in simula-
tions (O’Hern et al. 2003). Below, we discuss a
generalized ensemble that allows for the coupling
of these two, and applies to spherical and non-
spherical grains with and without friction.
Generalized Ensembles
In a more recent development, it has been shown
that the “equally likely” hypothesis of Edwards
and the Microcanonical ensemble of thermal sys-
tems (Chandler 1987) is not essential for the def-
inition of a temperature-like quantity, and a much
weaker condition of factorizability of distribu-
tions is sufﬁcient (Bertin et al. 2004, 2005,
2006). The necessary conditions for being able
to deﬁne a temperature-like variable and a statis-
tical ensemble based on this variable are (a) the
existence of a physical quantity that is conserved
by the natural dynamics of the system (in thermal
systems energy is conserved but in dissipative
granular media, it is not) and (b) that the fre-
quency of ﬁnding different states with the same
value of the conserved quantity is factorizable:
ov1þv2 ¼ ov1 ov2 . The latter condition implies
that if one creates a conﬁguration by bringing
together two conﬁgurations 1 and 2, then the fre-
quency of occurrence of this joint conﬁguration is
a product of the frequency ov of the individual
conﬁgurations.
In the context of mechanically stable packings
of grains (soft, deformable or rigid), a conserved
quantity that has been identiﬁed is the force-
moment tensor (Henkes et al. 2007; Blumenfeld
2007; Ball and Blumenfeld 2002) which is related
to the Cauchy stress tensor:
bs ¼ 1=V
ð
Þ
X
ij
r!
ijF
!
ij
ð3Þ
The summation in Eq. (3) is over all contacts
{ij} in an assembly of grains, occupying a volume
V, with contact vectors r!
ij and contact forces F
!
ij
(for grains with friction F
!
ij does not lie along the
direction of r!
ij).
The microscopic force moment tensor for a
grain is given by:
bki ¼
X
j
r
!
ijF
!
ij,
ð4Þ
where the sum is over all grains j that contact grain i.
For grains in mechanical equilibrium, it can be
shown, using a generalized Stoke’s theorem
(Edwards and Blumenfeld 2007; Henkes and
Chakraborty 2005, 2008), that the total force
moment tensor
bS ¼
X
i
ki
becomes a boundary integral for systems with
open boundaries and is a topologically conserved
quantity for systems with periodic boundary con-
ditions (Henkes et al. 2007). In two dimensions,
this property can be explicitly demonstrated by
introducing a set of auxiliary variables (Ball and
Blumenfeld 2002) which are the analog of the
vector potential in electromagnetism. The connec-
tion to electromagnetism is natural if one remem-
bers that for mechanically stable packings, the
divergence of the stress tensor is zero, just as the
divergence of the magnetic ﬁeld is zero in
electromagnetism.
Given the topologically conserved nature
and/or the strict boundary sensitivity of bS , the
phase space of all mechanically stable packings
can be grouped into sectors characterized by the
value of bS . Thinking of systems with periodic
boundary conditions, the topologically conserved
nature implies that packings in different sectors
are completely disconnected by any natural
dynamics, and therefore, bS is the type of con-
served quantity that meets criterion (a) of the
previous paragraph. If we now assume criterion
(b), then a statistical ensemble can be constructed
to describe the end states of processes such as
shaking grains. The role of energy is played by
bS which is an extensive quantity (scales with
system size) and the analog of temperature is a
tensorial quantity, ba (In the context of inﬁnitely,
rigid grains, this intensive variable has been called
Jamming of Granular Matter
401

Angoricity by Edwards (Edwards and Blumenfeld
2007)). This tensor is deﬁned by:
ba bS
 
¼
@Z0 bS
 
@bS
ð5Þ
where
Z0 bS
 
¼
X
v
ovd bSv  bS


and the sum is over all mechanically stable
packings v.
Tests of the Stress-Based Ensemble
The ability to deﬁne an ensemble does not neces-
sarily mean that real granular packings conform to
this ensemble. The assumption of factorizabilty
could break down or the frequency of occurrence
of a packing, ov could be history-dependent mak-
ing the temperature or the ensemble concept not
very useful. It is, therefore, essential to check the
predictions of this ensemble against experiments
and simulations.
This has been done for simulations of friction-
less grain packings in two dimensions (Henkes
et al. 2007) and it has been shown to work remark-
ably well. As a result of this comparison, an equa-
tion of state analogous to thermal equations of
state, has been derived for frictionless grain pack-
ing approaching Point J (Henkes et al. 2007), that
is consistent with the ﬁeld theory constructed for
Point J (Henkes and Chakraborty 2008).
Two applications of the stress-based ensemble
to experiments probing the jamming transition
will be discussed below.
Jamming Phase Diagram
About a decade ago, Liu and Nagel proposed that
the jamming transitions in all systems, including
the glass transition in supercooled liquids can be
described by one uniﬁed framework through the
jamming phase diagram and a special point in this
phase diagram referred to as Point J (Liu and
Nagel 1998). The proposed phase diagram,
shown in Fig. 1, delineates the boundaries of the
jammed region in a phase space spanned by a
temperature, density, and a load axis. The load
axis captures the non-equilibrium aspects of these
materials. For ideal spherical particles, the transi-
tion at Point J is a purely density-driven change,
occurring at a critical packing fraction, fc
between an amorphous solid state of dry granular
packings and a state where the packings fall apart
under any external stress (O’Hern et al. 2003).
Recent experiments in granular packings have
veriﬁed
the
existence
of
this,
transition
(Majmudar et al. 2007), as discussed in the section
on experiments, and a theoretical description of
this speciﬁc point is also emerging (Henkes and
Chakraborty 2005; Wyart 2005; Wyart et al.
2005a).
In recent years, a theoretical framework has
been developed (Kirkpatrick et al. 1989; Xia and
Wolynes 2001; Bouchaud and Biroli 2004) that
describes the complete phenomenology of the
glass transition in supercooled liquids. There are
similarities between this framework and the prop-
erties of Point J, but whether or not these diverse
phenomena can be uniﬁed under the umbrella of
universality is a subject of intense current
research. The stress-based ensemble approach
described earlier has been used to construct a
coarse-grained ﬁeld theory of Point J and the
jamming transition (Henkes and Chakraborty
Jamming of Granular Matter, Fig. 1 Jamming Phase
Diagram proposed by Liu and Nagel. Adapted from
(O’Hern et al. 2003)
402
Jamming of Granular Matter

2005, 2008). Since ﬁeld theories and scaling ideas
based on them underlies universality in thermal
phase transitions, the extension of this approach to
granular materials hold out the promise of identi-
fying different universality classes in the context
of jamming.
The special properties of Point J are related to
isostaticity (O’Hern et al. 2003). The discussion in
section “Statistical Framework of Jamming” ana-
lyzes isostaticity for frictionless, spherical grains.
In general, isostatic packings are those special
ones where the number of contacts is just enough
to provide mechanical stability (Tkachenko and
Witten 1999). It has become increasingly evident
(Donev et al. 2007) that isostaticity plays very
different roles in spherical vs. non-spherical par-
ticles, which raises the question of whether Point
J is special to frictionless spheres and disks. Also,
it is not clear how generic the properties of this
special point are, and whether or not it controls the
behavior as one moves away from it in parameter
space.
The jamming phase diagram of Liu and Nagel
provides a framework for exploring the phenom-
enon of jamming in granular matter. Since tem-
perature is not a relevant variable in the granular
case, the phase space of interest would generically
be the loading-density plane. The mechanical fail-
ure (or unjamming) of granular packings can
occur because of (i) a vanishing bulk modulus
(instability with respect to volume ﬂuctuations)
or (ii) a vanishing shear modulus (instability
with respect to ﬂuctuations of the shear stress).
The state at Point J is an especially fragile one
since both conditions (i) and (ii) are met. The
stress state of the packing at this point is
isotropic. In many instances, however, a granular
material can be irreversibly deformed through the
application of shear, and this process is also fre-
quently referred to as unjamming. Speciﬁcally, for
large enough shear stresses, a solid-like granular
material will dilate, and fail in a process that
typically leads to a locally weak and dilated region
known as a shear band. This type of process has
interesting analogues in the plastic failure of dis-
ordered glassy materials, in foams, in colloids and
perhaps elsewhere. The tendency of densely
packed granular materials to dilate under shear
was discovered by Reynolds (1885), and the
adjustment of the density under shear is incorpo-
rated into critical state models of soil mechanics
(Nedderman 1992). Although under shear, granu-
lar materials yield, and in some sense are
‘unjammed’, this process typically occurs under
non-zero pressure as well as nonzero shear stress.
Hence, ‘unjamming’ due to shear differs from the
isotropic-stress state that occurs at Point J. In fact,
the vast majority of experiments associated with
jamming/unjamming are of this latter shear-
induced process. There is compelling reason,
discussed below, to think that plastic failure by
shearing has a qualitatively different behavior
than what occurs at Point J. For instance, jammed
states also depend on whether they are isotropic or
not, as shown by Majmudar and Behringer
(2005a).
Given the dilatancy effects, and the differences
between isotropically and anisotropically stressed
states, we organize our discussion of jamming
around a phase space spanned by the components
of the Cauchy stress tensor (Eq. 3). This is a
symmetric tensor, and in two dimensions we can,
therefore, work with the isotropic pressure, P, and
the shear stress t. P ¼ s1 þ s2, and t ¼ s1 – s2,
where the si are the principal stresses, i.e.
eigenvalues of the stress tensor. Since the prin-
cipal stresses are positive for granular materials,
the physical space is enclosed by the |t| ¼ P
and P ¼ 0 lines. In fact, shear failure typically
occurs for |t| < P. Point J lies at P ¼ 0; t ¼ 0.
Along the t ¼ 0 axis, simulations provide strong
evidence of Point J having critical properties with,
in particular, at least one diverging length scale
(O’Hern et al. 2003).
If t 6¼ 0 then the jamming behavior could be
quite different from that characteristic of Point J.
Here, a useful analogy to equilibrium phase
transitions may be the difference between a criti-
cal point, where a line of ﬁrst-order phase transi-
tions terminates, such as the ferromagnetic Curie
Point which occurs at zero magnetic ﬁeld and at a
characteristic temperature Tc, or a tricritical point,
which separates a region of second-order transi-
tions from a region of ﬁrst-order transitions. This
type of a critical point arises in multicomponent,
thermodynamic
systems
and
a
well-known
Jamming of Granular Matter
403

example is superﬂuidity in a mixture of He3 and
He4. For a high enough concentration of He3, the
mixture undergoes a ﬁrst order transition into two
phases, and only one, the He4-rich phase is super-
ﬂuid (Blume et al. 1971). A characteristic of a
tricritical point is the existence of two diverging
length scales, and in particular, there is a higher
dimensional phase space that describes the vari-
ous transitions. We present this discussion here
purely as an illustrative example of a phase-
transition scenario in which the signatures depend
on what parameters are varied. We use the phase
diagram of Fig. 2 to provide a framework for
differentiating between the avenues available for
approaching the jamming transition. In much of
the literature, no distinction has been made, and
we believe that has led to confusion. For each
possible
path,
the
transition
can
also
be
approached
from
the
jammed
side
or
the
unjammed side. If t ¼ 0, then the unjammed
state is ﬂuid-like in the sense that the system
cannot respond elastically to any applied stress.
Below, we ﬁrst provide an overview of the
signatures of jamming observed as the transition
is approached from the ﬂuid-like side (section
“Force Fluctuations, Dynamical Heterogeneities,
Length and Time Scales in Granular Flows
Approaching Jamming”), we then discuss the
properties of jammed states under both shear and
isotropic compression, as the jamming transition
is approached from the jammed side (section
“Force Distributions, Length and Time Scales in
Jammed States Near the Jamming Transition”). In
section “Isostaticity and Point J”, we summarize
the experimental and theoretical description of
Point J and the associated length and time scales.
Related areas of research that we do not include in
this article at all, are the phenomenon of aging,
non-equilibrium dynamics, and generalized elas-
ticity for granular matter. We refer the interested
reader to articles listed in the bibliography.
Force Fluctuations, Dynamical
Heterogeneities, Length and Time Scales
in Granular Flows Approaching Jamming
In this section, we review a number of physical
and numerical experiments which give insight
into the nature of the jamming process. Each
approach has advantages and disadvantages.
Numerics, typically consisting of direct simula-
tions of the equations of motions for a set of
particles, has the advantage that it is possible to
easily explore parameter space. This approach is
referred to as Molecular Dynamics (MD) or as
Discrete Element Simulations (DEM), depending
on the community. The disadvantage of simula-
tion is that it is difﬁcult to achieve an accurate
representation
of
friction
(often
friction
is
neglected), and in addition, simulations are typi-
cally done only for spheres in 3D or disks in 2D
(which we will refer to as isotropic particles).
Experiments do not suffer from issues of accuracy
of the interaction law, but it is very difﬁcult to
obtain quantitative data except at the boundary of
3D systems. Alternatively, it is possible to obtain
information using quasi-2D systems, such as col-
lections of disks, something that is also done
frequently for simulations. Two-dimensional sys-
tems for both experiments and simulations can
yield excellent quantitative information, but may
leave open the question of generalizability to
higher dimension. With these caveats, we turn to
a review of both numerical and physical experi-
ments that probe the jamming transition from the
ﬂuid-like side. Granular ﬂows can be broadly
divided into two categories, (a) inertial ﬂows
Jamming of Granular Matter, Fig. 2 Jamming Phase
Diagram in the space of components of the Cauchy stress
tensor. The diagram shows a schematic in the P – |t| plane,
with arrows marking possible avenues of unjamming
404
Jamming of Granular Matter

dominated by collisions between grains, and
(b) quasistatic ﬂows that involve extended con-
tacts and slow evolution from one static, mechan-
ically stable state to another.
Recent results from numerical simulations by
Lois et al. (2007a, b) are of particular interest here.
These authors studied shear ﬂow of rigid particles
which they modeled using contact dynamics, a
version
of
MD/DEM
for
rigid
particles.
A particularly interesting discovery coming from
these studies was the existence of a divergent
correlation length for forces, associated with the
formation of clusters, as the packing fraction
approached fc from below. The presence of a
divergent length scale reinforces the idea that
jamming is actually a critical transition.
Evidence for critical properties also come from
experiments on hopper ﬂow by Longhi et al.
(2002). These experiments involved a quasi-2D
ﬂow of monodisperse spheres out of a hopper-
shaped container. Necessarily, the presence of
ﬂow implies that the states studied here were
unjammed. As the particles moved by, a small
high speed force gauge mounted near the outlet
of the hopper yielded the impulse of individual
collisions. The collisions could be clearly identi-
ﬁed because of a large separation of scales
between the duration of contact, and time between
contacts. The distributions of these impulses, at
large impulses were roughly exponentially dis-
tributed, and independent of the ﬂow rate. At
small impulses, the distributions evolve with
ﬂow rate with a relative increase of small impulse
events as the ﬂow rate decreases. A more interest-
ing statistic is the distribution of t’s, the time
between successive collisions. As the jamming
transition was approached, these distributions
approached a powerlaw, P(t) / t3/2.
An MD simulation of hard disks, in a geometry
designed to mimic the experiments of Longhi
et al. (2002), provided an explanation for the
evolution of the impulse distribution in terms of
increasing velocity correlations (Ferguson and
Chakraborty 2006; Ferguson et al. 2004). These
correlations also led to a qualitative explanation of
the changes in P(t) (Ferguson and Chakraborty
2006), which occur because the average time
between collisions decreases as the ﬂow velocity
decreases while at the same time the time taken for
a particle to fall through its own diameter
increases. This leads to a large separation of time
scales and a range of times over which the dynam-
ics is scale invariant. The simulations provided
strong indications that these physical effects owe
their
origin
to
the
existence
of
chains
of
frequently-colliding particles. In addition, it was
shown that these collision chains could be
interpreted as stress chains with the stress mea-
sured through momentum transfer [20, the coun-
terpart of force chains in this system of ﬂowing
hard particles. Figure 3 is a snapshot of a simula-
tion illustrating the stress chains for two different
ﬂow rates, as controlled by the width of the open-
ing at the bottom of the hopper. More recent work
on this system of hard disks has provided evi-
dence for the existence of dynamical heterogene-
ities identiﬁed through the displacements of
grains (Ferguson and Chakraborty 2006).
Jamming of Granular Matter, Fig. 3 Stress chains. The
grayscale plot is constructed by scaling the collisional
stress by the average collisional stress (hli) obtained by
coarse graining over many collisions. Close to jamming,
the coarse-graining time is much shorter than the time
taken by a particle to fall through its own diameter
(Ferguson and Chakraborty 2006)
Jamming of Granular Matter
405

A length scale can be extracted from measure-
ments of spatio-temporal correlations of these
heterogeneities. As in supercooled liquids, there
is a length scale that has a peak at a characteristic
time. Both length and time scales depend on the
average ﬂow velocity, growing as the system
approaches jamming. The increase in length,
however, is not as dramatic as in supercooled
liquids or in experiments on air-driven granular
beads (Keys et al. 2007). As an example of the
characteristic shapes of the length versus time
curves observed in all of these systems, super-
cooled liquids, inertial and quasistatic granular
ﬂows, we show a set of data from the MD simu-
lations of hopper ﬂow in Fig. 4 (Ferguson and
Chakraborty 2007).
Pouliquen et al. have carried out a series of
experiments on ﬂow down chutes/inclined planes
(Pouliquen 2004; Pouliquen 1999). These studies
have shown that there is a range of inclination
angles, θ, for the chute for which it is possible to
obtain steady state ﬂow, and that the depth of the
ﬂowing layer, h, depends on θ. The ﬂow stops if
h is smaller then an inclination-angle-dependent
function, hstop(θ). Data for the depth-averaged
velocity, u can then be expressed in terms of a
ﬂow rule, u/(gh)1/2 ¼ βh/hstop(θ), where β is a
material-dependent O(1) constant. Following a
suggestion by Ertas and Halsey (2002), Pouliquen
(2004) explored the possibility that there might be
observable spatial correlations for the surface
velocity which would signal the onset of jamming.
Indeed, such correlations exist, and they grow as
the inclination angle of the chute is lowered, i.e. as
the system approaches the jammed state.
Kolb et al. (2004) have studied the response of
a jammed 2D layer to a localized cyclic displace-
ment. This process was carried out quasi-
statically, and in such a way as to locally unjam
the system. More speciﬁcally, the experiment
consisted of a bidisperse layer of disks, inclined
from the vertical, so that the system was normally
jammed. An intruder particle having a diameter
corresponding to the larger of the two grain sizes,
was displaced periodically in time by small
amounts. These local displacements led to a
much longer range set of displacements, part of
which was reversible, but part of which was irre-
versible. This long-range response is suggestive
of a critical-like response for states near jamming.
Jamming of Granular Matter, Fig. 4 Lengths scale, x,
associated with the heterogeneity of dynamics as a function
of the mean square displacement, r, of particles in MD
simulations of a two-dimensional hopper ﬂow (Ferguson
and Chakraborty 2007). This length scale, extracted by
analyzing the spatial correlation between displacements
of particles (Hurley and Harrowell 1995; Perera and
Harrowell 1996), peaks at a characteristic displacement
which can be related to a characteristic time at which the
dynamics is most heterogeneous. This plot is qualitatively
similar to x vs. time plots observed in the experiments of
Durian et al. on air-driven beads, in the experiments of
Dauchot et al. on particles driven by oscillating shear (see
text), and in supercooled liquids
406
Jamming of Granular Matter

Drocco et al. (2005) have used MD to to simu-
late the behavior of a 2D particle that is pushed
through originally static bidisperse packings of
similar particles. The packings reside in a square
geometry with periodic boundary conditions, and
are prepared at packing fractions below the jam-
ming value for this system. The authors ﬁrst focus
on the intruder velocity, which becomes increas-
ingly intermittent as f ! fc from below. To char-
acterize the intermittency, Drocco et al. use
multifractal analysis to compute moments, M(q) ¼
Ð
dnP(n)nq / (fc  f)t(q), and present evidence
for multiscaling. Of particular relevance here is a
demonstration that as f ! fc, the number of disks,
n, that move in response to a ﬁxed pushing distance
for the intruder grows rapidly. These authors use
data for the number of moving disks vs. f to
estimate a correlation length, which diverges as
x / (fcf)v, with v ¼ 0.71  0.12. These numer-
ical studies have an interesting parallel with exper-
imental studies by Geng and Behringer (2005)
which yielded the force needed to push a disk
through a channel of other disks in the jammed
state. These data yielded a pushing force that also
became increasingly intermittent on approach to
fc, in this case from above, and a mean force that
vanished as (f – fc)α with α ¼ 1.5.
Dauchot et al. (2005) have studied correla-
tions in systems of particles in 2D that are subject
to small-amplitude oscillating shear. In this case,
simple shear was applied, meaning that a rectan-
gular sample was alternately tilted into a paral-
lelogram to the right, then left. Dauchot et al.
were particularly interested in characterizing the
spatio-temporal ﬂuctuations of systems near
jamming. An image was obtained each time that
the system was returned to the rectangular state,
and the location of each particle was then deter-
mined. From these data, the authors ﬁrst calcu-
lated a measure of individual particle motion,
the self-intermediate scattering function, Fs ¼
bFs k, t
ð
Þ
D
E
¼ N1S j exp ik r j tð Þ  r j 0
ð Þ





	
.
The results for Fs(k, t) /
exp [  (t/t(k))β(k)
indicate Brownian diffusion at small k, but a
different behavior at large k, i.e. smaller spatial
scales, where β is smaller than unity: a stretched
exponential. They attribute this behavior to
dynamical heterogeneities, and they further
quantify the nature of these dynamical heteroge-
neities by analyzing length and time scales asso-
ciated with ﬂuctuations of bFs k, t
ð
Þ, as has been
done for supercooled liquids. The analysis iden-
tiﬁes a moderate length scale associated with the
ﬂuctuations, in agreement with the type of length
scales that have been observed in supercooled
liquids.
Durian et al. (Keys et al. 2007) have studied
dynamical heterogeneities in a system of air-
driven granular beads as a function of the packing
density. Using multiple measures of lengths asso-
ciated with dynamical heterogeneities, these
authors demonstrate that there are length and
time scales, which grow with the approach to
Point J. They also show that the increase in these
scales follows the Vogel–Fulcher–Tamann form: a
form that is associated with supercooled liquids
approaching the glass transition (Ediger et al.
1996). Figure 5 shows length and time scales
extracted from different measures of dynamical
heterogeneities as a function of the packing frac-
tion. The ﬁts are to the predictions of Mode-
Coupling-Theory of the glass transitions and to
the Vogel–Fulcher–Tamann form, which implies
an exponential divergence at a packing fraction
f0. Interestingly, the value of f0 is very close to
the fc associated with Point J (Keys et al. 2007).
Force Distributions, Length and Time
Scales in Jammed States Near the
Jamming Transition
An interesting premise is that the distribution of
interparticle contact forces, P(F), can provide
insight into the nature of the global granular
state of a system. In particular, it may be useful
as a tool to distinguish jammed from unjammed or
nearly unjammed states. It is also an important
indicator of the overall stress state of the system,
as demonstrated in experiments (Majmudar and
Behringer 2005a, b) and theory (Snoeijer et al.
2004d, e). Since the transition to a deforming
state in a dense granular material has often been
obtained by shearing, there have been a number of
studies that have addressed this case (Miller et al.
Jamming of Granular Matter
407

1996; Howell and Behringer 1999; Veje et al.
1999; Daniels and Behringer 2005a, b, 2006;
Hartley and Behringer 2003; Corwin et al.
2005a). In particular, Howell et al. (Howell and
Behringer 1999; Veje et al. 1999) have directly
probed the transition that occurs when the density
of a sheared granular sample is reduced to the
point where stresses vanish. Other studies have
probed the nature of steady granular shear (Miller
et al. 1996; Daniels and Behringer 2005a, 2006;
Hartley and Behringer 2003; Corwin et al. 2005a).
We discuss below several recent experimental
studies which help elucidate this point. Here, we
focus ﬁrst on sheared, and then on isotropicically
conﬁned systems.
Sheared States
Fluctuations, their distributions and their correla-
tions, are interesting for a number of reasons.
First, they can reveal the nature of short and long
range behavior. In addition, they provide a useful
test of model behavior, and they help to identify
key parameters. One of the earliest experimental
characterization of force ﬂuctuations in dense
granular materials was by Miller et al. (1996).
These experiments involved the shearing of an
annular layer of glass spheres. A rough plate
sheared the top of the annular layer and the pres-
sure was measured at the bottom of the layer using
a force gauge of ﬁxed area. These studies are
typical of many quasi-static shearing experiments.
Jamming of Granular Matter, Fig. 5 Data for length (x) and time (t*) showing an increase in these scales associated
with dynamical heterogeneities in a system of air-driven beads. Reprinted from (Keys et al. 2007)
408
Jamming of Granular Matter

The system remains close to a static state, so that if
the shear stress is reduced, the system typically
reverts to a static state with only small changes in
the particle conﬁgurations. However, enough
shear is applied during steady-state motion that
the system unjams intermittently, presumably
associated with a short-term weakening of the
shear modulus. In some sense, this type of motion
straddles the jammed-unjammed boundary, ﬁrst
on one side, and then on the other. In addition, it
is typical that a region of the material weakens and
forms what is called a shear band. Because a shear
band has lower shear strength than other regions,
it tends to persist as a localized region where most
of the shear deformation occurs. This process is
typiﬁed by local structural rearrangements and
frequently with large force ﬂuctuations. The ﬂuc-
tuations in the experiments of Miller et al. showed
a kind of rate-independence. They also yielded
information
on
the
force
and
pressure
distributions, Fig. 6. The force detector was of
ﬁxed diameter, so by varying the particle diame-
ter, it was possible to tune the number of particles
contacting the detector from a small number, to
~100 particles. For the largest particles, this pro-
vided, at least roughly, information on P(F). For
the smallest particles, one might expect that the
force ﬂuctuations would be substantially averaged
out, yielding something more like the mean pres-
sure. We show data for the PDF’s of the measured
forces/stresses, in Fig. 6. If the forces acting on the
detector
from
individual
particles
were
uncorrelated, then one would expect that this
would narrow as N1/2, i.e. as the square root of
the number of contacting particles, and evolve
towards a gaussian. In fact, there is much less
narrowing than would occur for uncorrelated
forces from individual particles.
Two recent studies of 3D continuously sheared
systems provide additional insight (Daniels and
Jamming of Granular Matter, Fig. 6 Distributions of
forces measured at the base of a continuously sheared layer
of glass spheres, for different sphere diameters of 1 mm,
2 mm, 3 mm and 4 mm, as indicated, and a ﬁxed detector
diameter of 1.0 cm. The other numbers give the depth of
the granular layer as a fraction of the full height, 4.1 cm,
and the shearing rate (Miller et al. 1996)
Jamming of Granular Matter
409

Behringer 2005a, b, 2006; Corwin et al. 2005a).
Both systems yield PDF’s of forces at the bound-
aries, and it is interesting to contrast the two sets
of results.
Corwin et al. (2005b) have recently presented
extensive experiments using a photoelastic tech-
nique to measure forces at the bottom boundary of
a cylindrical container ﬁlled with spherical parti-
cles and sheared from above. In the steady state,
particles in the bottom layer located beyond a
characteristic
radius,
Rb,
exhibited
dynamic
shear ﬂow, speciﬁcally, a shear band. Particles
located closer to the center than this radius
remained in a permanently jammed state and
moved as a solid body. Corwin et al. obtained
P(F)’s, with a particular focus on the region above
Rb. These distributions, Fig. 7, show an enhance-
ment for small F, and qualitatively resemble those
obtained by Howell et al. for 2D shear ﬂow, as
discussed below. Corwin et al. proposed that these
distributions can be related to an effective temper-
ature, Teff, by noting that the distribution of forces
and the radial correlation function, assuming
forces described by a potential, V(r), should sat-
isfy P(F)dF ¼ G(r)dr, where G(r)dr is the radial
distribution function. They then drew on the
small-r thermal result G(r) / r2 exp [V(r)β]
where β ¼ 1/(kBT) (in this case, T should be
replaced by Teff). This argument leads to the pre-
diction that at low forces, one should expect
P(F) / F1/3, a prediction that describes their
data well. The resulting effective temperatures
obtained from this analysis are insensitive to
shear rate and also to the height of the granular
layer.
Other recent studies of sheared 3D particles,
this time in an annular channel, were carried out
by Daniels and Behringer (2005a, b, 2006). In
these experiments, the overall geometry was sim-
ilar to Miller et al. (1996) but in addition, the
bottom boundary of the experiment was shaken
with peak accelerations that typically exceeded
the acceleration of gravity. The shaking motion
allowed the system to ﬁnd not only a jammed
state, but actually a crystalline state. At high
enough shear, the crystal melted, producing a
shear-banded, disordered, and ﬂowing state. This
transition was clearly evident in P(F). Here, F is
the force exerted by particles on a transducer that
is roughly three particle diameters across. In the
crystalline state, P(F), Fig. 8, had an overall enve-
lope that was roughly gaussian, but that had two
peaks which were induced by the vibrational
motion. In the melted, disordered state, P(F)
resembled the distributions of Miller et al. As the
transition to the ordered state was approached
from the disordered state, the tail of P(F) became
increasingly extended. Associated with this long
tail were increasingly large volume ﬂuctuations.
In fact, the variance of volume ﬂuctuations and
the various moments, including the kurtosis of the
P(F), showed a cusp at the transition. This is
particularly interesting in the present discussion,
since the volume variance should be proportional
to
the
derivative
of
the
Edwards
entropy
(discussed in section “Statistical Framework of
Jamming of Granular Matter, Fig. 7 P(F) in sheared
and non-sheared zones. Reprinted from (Corwin et al.
2005b)
410
Jamming of Granular Matter

Jamming”) with respect to compactivity, i.e. the
Edwards ensemble analogue of a speciﬁc heat.
A relatively early demonstration of jamming
properties was the work of Howell et al. (Howell
and Behringer 1999; Veje et al. 1999) These
experiments
consisted
of
photoelastic
disks
which were sheared in an annular Couette geom-
etry, as in the sketch of Fig. 9. The boundaries of
the apparatus consisted of a ﬁxed outer ring, and
in inner wheel whose rotations provided the shear.
The particles were conﬁned in the horizontal
directions by the ring and wheel, and they rested
on a smooth powder-lubricated horizontal Plexi-
glas sheet. Data were obtained in a steady state
after the system had been sheared for roughly
30 min. The low shearing rate meant that that the
process was quasi-static and hence always close to
equilibrium. In particular, if the shearing was
stopped, the majority of the force chains remained
unchanged following an initial relaxation. Over
long times, more of the force chains decayed, but
that process was logarithmically slow (Hartley
and Behringer 2003). In these experiments, the
average force per particle (roughly a measure of
the particle-scale pressure) was obtained by cali-
brating an applied compression to the photoelastic
response of the particles. These experiments, as
well as those of Daniels and Behringer (2005c,
2006), showed an increase of the mean stress with
Jamming of Granular Matter, Fig. 8 Distributions for
the pressure/force at the bottom of an annular layer of
spheres that is sheared at a rate Ω, from above, and that is
vibrated from below with a peak acceleration of Γ ¼ 2.0, in
units of g. R is the mean radius of the annulus, and d is the
particle diameter. The two-peaked distributions are in the
crystalline phase, and the single-peaked distributions are in
the disordered phase. The inset shows the Kurtosis of the
distributions as a function of a scaled shear rate. The cusp
in the kurtosis is caused by the stretching out of the distri-
butions as Ω is decreased from a large value where the state
is disordered
Jamming of Granular Matter, Fig. 9 Sketch of the
basic two-dimensional Couette shear apparatus, with an
overlaid image showing the heterogeneous force structure
that occurs. Photoelastic particles are conﬁned within an
annular region whose boundaries are a rotating inner
wheel, and a ﬁxed outer ring. Also shown is a blow-up
sketch indicating the rough nature of the shearing wheel,
and the fact that the photoelastic disks are marked with
small bars for tracking purposes. In the false-color image
from
this
experiment,
red
corresponds
to
particles
experiencing a large force, and blue 0 to particles
experiencing a small force (Howell and Behringer 1999;
Veje et al. 1999)
Jamming of Granular Matter
411

the shear rate that varied linearly as the logarithm
of the shear rate. The logarithmic strengthening
has been shown to be consistent with predictions
of the stress-based ensemble, described in section
“Statistical Framework of Jamming” (Behringer
et al. 2008).
Several observations concerning these experi-
ments are noteworthy. First, these experiments
yielded the force distributions for the mean force
on a particle, and also for averages over multiple
particles. Second, they showed a kind of critical
slowing
down
as
the
packing
fraction,
f,
approached the jamming transition from above,
and third, they showed that a characteristic length
scale associated with the mean length of force
chains grew as f ! fc from above. We reproduce
these results in Figs. 10 and 11 (Howell and
Behringer 1999).
The distributions for the single particle forces
depend on the distance to fc. For f close to fc,
the distributions fall off roughly exponentially
with large force, although there is an extra density
of low force states. These distributions are nomi-
nally rather similar to single particle force
distributions which were observed for particles
at the boundaries of the 3D sheared system by
Corwin et al. (2005a). For larger f, the distribu-
tions from the 2D shear experiments developed a
peak which gradually migrated to larger force as
the density grew. The distributions for the force on
collections of particles also depend on the density.
Close to jamming, they are similar to the single-
particle distributions; at larger density, they
evolve to a more gaussian shape. The multi-
particle-force distributions are then interesting
on several accounts. First, they provide a way to
compare to earlier 3D pressure measurements
(i.e. force measurements involving multiple parti-
cles) and they also give some sense of force cor-
relations. That is, if the force on a given particle
were uncorrelated with the force on other nearby
particles, then the distribution for the forces expe-
rienced by a collection of particles would typi-
cally evolve to a guassian as the number of
particles in the collection increases. This is con-
sistent with what is observed for larger f, but not
with what is observed for f near fc. Hence, by
inference, there exist correlations for the particle-
Jamming of Granular
Matter, Fig. 10 PDF’s
from the 2D Couette
experiment for single
particles (bottom) and for
collections of particles lying
within an extended region.
Numbers indicate the
packing fraction. This
system has a critical value
of f ¼ 0.776 where stresses
vanish. Note that the
distributions of forces for
single particles develops a
maximum for large packing
fractions. The distributions
for forces for collections of
roughly 260 particles in a
contiguous region show a
much stronger peak as f
increases, and no peak
when f is just above fc.
This suggests that
correlations in force grow as
f ! fc (Howell and
Behringer 1999)
412
Jamming of Granular Matter

scale forces for near-critical f’s. To make this idea
somewhat more precise, we show in Fig. 13 what
happens to the PDF for the collective force for
groups of particles acting on a detector if a) the
forces exerted by each particle are chosen from
q-model like distribution (Coppersmith et al.
1996), and b) the forces exerted by any one parti-
cle are uncorrelated with any of the others. Spe-
ciﬁcally, the distribution narrows as N–1/2.
The results from the 2D Couette shear for the
velocity proﬁles vs. f and also data for the char-
acteristic force chain length both suggest that the
system becomes increasingly inhomogeneous, in
terms of force transmission as f ! fc from
above. In particular, the typical force chain length
clearly grows, although it does not necessarily
diverge, in these experiments on approach to fc.
In fact, given our discussion above concerning a
P – t phase diagram, we might well expect that in
shear experiments one approaches point J along a
path which lies above the P axis. Figure 11 con-
trasts a photoelastic image from Howell et al.
(Howell and Behringer 1999) taken well above
fc with an image for f just slightly above fc. In
the higher f case, the force network is more
nearly homogeneous, in contrast to the case just
above fc. For the latter case, only a handful of
particles are visibly in a force chain. (Here, some
caution must be taken, since there is a force below
which the photoelastic image is too weak to be
resolved.) Nevertheless, only intermittently is
there a strong enough contact at the shearing
wheel so that a particle is entrained by the shear-
ing wheel. This leads to critical slowing down
which is evident in the mean velocity proﬁles,
Fig. 12.
Isotropic vs. Anistropic Stress States
As discussed above, the nature of jamming
depends, in what appears to be a signiﬁcant way,
on the presense or absence of shear stresses. The
experiments and simulation discussed above have
all involved sheared states. Here, we consider
simulations and experiments which are for isotro-
pic systems, and which focus on an approach to
jamming that involves the dense/jammed side
(Fig. 13).
Numerical Simulations
The phenomenon
of jamming in isotropically stressed states has
been extensively investigated through numerical
simulations of frictionless, spherical grains in
both two and three dimensions (O’Hern et al.
Jamming of Granular Matter, Fig. 11 Photoelastic
images from the Couette shear experiment at a low (left,
f – fc ¼ 0.001) and high (right, f – phic ¼ 0.031) distance
from the unjamming point of this system. Note the long
ﬁlimentary chains near fc and the tangled network far from
fc (Howell and Behringer 1999; Veje et al. 1999)
Jamming of Granular Matter
413

2003; Makse et al. 2000). This work includes in
particular, a series of MD simulations by O’Hern
et al. (2001, 2002, 2003). This series of simula-
tions led to the introduction of the existence of a
critical point at zero shear and a critical density,
fc: Point J. The simulations probed the nature of
the packings of spherical grains (disks in two
dimensions), which interact via a short-range,
soft-repulsive potential, meaning that there are
no long-range interactions, and that there are
purely repulsive normal forces which come into
play when the grains are compressed. The pack-
ings were obtained by quenching from initial ran-
dom states with a packing fraction f ¼ NVp/V,
where N grains each with volume Vp were packed
in a box of volume V. For polydispersed assem-
blies of grains, the deﬁnition of the packing frac-
tion can be easily generalized. An interesting
protocol that was developed in trying to identify
Point J was that of inﬂation or deﬂation, in which
the pressure of a quenched state was measured,
and the radius of the grains were scaled up or
down by small factors until the pressure was
zero (within a numerical tolerance). For each ini-
tial conﬁguration (v) the zero pressure state
corresponded to a particular packing fraction, fc
v
. At this packing fraction, the grains just touched
and if the packing fraction was reduced below
this, no mechanically stable states could be
obtained. The crucial ﬁndings of these simulations
are summarized below:
1. If properties such as pressure, shear modulus,
and average number of contacts of the pack-
ings are measured as a function of fv  fc
v ,
then the properties are found to be independent
of v.
2. The pressure, bulk modulus and shear modulus
all go to zero as some power of fv  fc
v. The
exponent of the power law for the pressure and
the bulk modulus follows from the force law
but the shear modulus has a non-trivial expo-
nent that indicates non-afﬁne displacements
(O’Hern et al. 2003; Ellenbroek 2007).
3. The distribution of fc
v becomes narrower with
increasing
system
size
and
the
mean
Jamming of Granular Matter, Fig. 13 Computed PDF
of the force per particle exerted by collections of n particles
whose forces are uncorrleated and are drawn from expo-
nential distributions. The absence of correlations leads to
the expected narrowing by n–1/2
Jamming of Granular
Matter, Fig. 12 Data for
the mean azimuthal velocity
proﬁles vs. radial distance
from the shearing wheel for
the 2D Couette experiment.
These data are normalized
by the angular speed, Ω, of
the shearing wheel. Inset
shows that these data
collapse onto a single curve
when scaled a function
/(f  fc)1 (Howell and
Behringer 1999)
414
Jamming of Granular Matter

approaches the Random Close Packing value
(Donev et al. 2004).
4. Above fc, the average number of contact fol-
lows a power law: hzi  ziso / (f  fc)1/2.
5. The vibrational density of states exhibits
increasing weight at low frequencies as Point
J is approached, and the lowest frequency
below which the packing behaves as a normal
elastic material approaches zero (Wyart et al.
2005b).
6. Two different diverging lengths scales can be
identiﬁed from analysis of the vibrational spec-
trum. These two length scales diverge with
different exponents (Silbert et al. 2005), and
therefore indicate the existenc of multiple
diverging correlation lengths at Point J.
7. The force distribution, P(F) is sensitive to the
distance from fc, and approaches an exponen-
tial as the packing fraction approaches fc
Experiments
Regarding physical experi-
ments for the isotropic case, we are aware of
only one set of results, namely data by Majmudar
and Behringer (2005a). These results depend
crucially on using photoelastic techniques in a
much more precise way to obtain contact forces
(Majmudar and Behringer 2005a, b). Hence, we
discuss brieﬂy how this approach works. The
basic idea is the following. For given contact
forces acting on a disk, the stress ﬁeld within
the disk is determined. The stress ﬁeld in turn
determines the photoelastic response. Speciﬁ-
cally, for a ray that traverses a slab of photo-
elastic
material
of
thickness
L
that
is
sandwiched between crossed circular polarizers,
the transmitted intensity is I ¼ Iosin2[(s2  s1)
CL/l]. Here, s2 and s1 are the principal stresses
in the plane of the slab (or disk), C, the stress
optic coefﬁcient is a property of the material, and
l is the wavelength of the light with intensity Io.
Thus, contact forces determine stresses which in
turn determine the photoelastic pattern. The idea
is to carry out the inverse of this process. Specif-
ically, from the photoelastic pattern, determine
the applied forces. This can be done efﬁciently in
the case of a disk because there is a closed form
relation for the stress ﬁeld generated by any
number of contact forces.
MB have developed such an inverse process
and applied it to systems of photoelastic disks that
have been prepared in well deﬁned stress/defor-
mation states. The particularly important aspect of
these experiments is that they have yielded the
only experimental data, to our knowledge, for
contact forces inside a granular sample, although
a number of other experiments have yielded
forces at boundaries. This point is important; the-
oretical studies by Snoeijer et al. (2004d, 2004e)
indicate that force distributions for contacts at
boundaries and in the interior of a sample differ
substantially.
Figure 14 shows a rough schematic of a biaxial
tester (or biax) and resulting photoelastic response
images for different types of applied stresses
(Majmudar and Behringer 2005a). The purpose
of the biax is to prepare states of well controlled
strain or stress. The biax is constructed so that the
space between opposing pairs of walls can be set
to any convenient value. The particles in this
sample are bidisperse disks, with about 80% hav-
ing a smaller diameter (0.8 cm) and 20% having a
larger diameter (0.9 cm). Bidisperse packings of
this sort typically have no long-range crystalline
order, although they tend to show hexagonal bond
order.
Manifestly, the force chain structures that
result from pure shear vs. isotropic compression,
Fig. 14b, are substantially different. Pure shear
induces force chains that extend nearly straight
and uninterrupted over the compressional direc-
tion of the biax. This is intuitively reasonable,
since the pure shear state is achieved by
compressing, hence strengthening contacts in
one direction, while dilating the sample, thus
weakening contacts, in the perpendicular direc-
tion. By contrast, for an isotropically compressed
sample, the force network consists of a dense
tangle of short force chain segments.
Various statistical measures reﬂect the fact that
shear and isotropic compression yield qualita-
tively different states. We consider ﬁrst, the distri-
butions of contact forces, P(F), which are given in
Fig. 15. For convenience, forces are normalized
by hFni, the mean normal force. The ﬁgures show
separate distributions for the normal and tangen-
tial contact forces. Although the distributions for
Jamming of Granular Matter
415

the tangential forces are always exponentially dis-
tributed, regardless of the stress state, the same is
not true for the normal force distribution. These
clearly reﬂect the stress state, with a state of pure
shear showing a roughly exponential fall-off at
large F, and with a state of isotropic compression
showing a much more rapid fall-off with F. In fact,
these distributions are consistent with recent
entropy-based arguments by Snoeijer et al.
(2004d) and by Tighe et al. (2005b). In both
cases, the distributions for the normal forces
show a peak at a force comparable to the mean.
Perhaps a better measure of the difference
between the shear and isotropic deformations is
given by the force correlation function, which is
signiﬁcantly longer range along the force chain
direction of the sheared case, than any direction
for the isotropic case (Majmudar and Behringer
2005a). We show these results in Fig. 16.
Isostaticity and Point J
Isostaticity and Random Close Packing
This section is devoted to a geometrical picture
which offers a perspective that is complementary
to the statistical ensemble picture. The geometri-
cal approach is focused on mathematically precise
descriptions of packing of inﬁnitely rigid particles
(Donev et al. 2004, 2007). In this statistical geo-
metric picture, packings are characterized by the
type of jamming: local, collective or strict. In the
Jamming of Granular Matter, Fig. 14 Biaxial experi-
ment. (a) Sketch illustrating the fact that two walls of the
experiment are moveable, allowing the creation of arbi-
trary (rectangular) deformations and stress states. (b) Two
different
stress
states
produced
by
top:
isotropic
compression, and bottom: pure shear, i.e. compression in
one direction and equal dilation in the opposite. (c)
A closeup image of a single photoelastic particle showing
the detailed photoelastic pattern that is used to deduce
contact forces (Majmudar and Behringer 2005a)
416
Jamming of Granular Matter

hierarchy of jammed states, locally jammed states
are ones where each particle in the system is
locally trapped by its neighbors. Collectively
jammed states are ones where all ﬁnite subsets of
particles are trapped by their neighbors, and
strictly jammed states are collectively jammed
conﬁgurations for which no global, volume-
nonincreasing deformations are possible (Donev
et al. 2004). In addition, the degree of order in the
packings is characterized by an order parameter or
an order metric (Torquato et al. 2000). The
emphasis in this approach is to understand the
existence of packings, not their statistical weight
in any dynamical protocol. The geometrical
approach applies to inﬁnitely rigid bodies which
is an idealization of real particles, but the classiﬁ-
cation into jamming categories and a precise
understanding of the nature of packings which
can exist as the packing fraction is varied provides
a framework onto which the statistical decsription
can be superposed. There are a few special points
on a phase diagram in the order-packing fraction
space: (a) the maximally random jammed state
(MRJ) is an extremal point corresponding to the
least ordered, strictly jammed state, (b) the
random-loose-packed (RLP) state is another
extremal point corresponding to the lowest den-
sity at which a strictly jammed state can exist. This
RLP state is more ordered than the MRJ state and
is extremely fragile (Torquato et al. 2000). In
contrast
to
the
concept
of
random
close
packing (RCP) (Donev et al. 2004; Torquato
et al. 2000), the MRJ state is protocol-independent
leading to a mathematical framework for studying
Jamming of Granular Matter, Fig. 15 Distributions of
forces for pure shear (top) and isotropic compression
(bottom). Parts (a and c) give distributions of normal (Fn)
and tangential (Ft, frictional) forces, all normalised by the
appropriate mean normal force, hFni. Parts (b and d) indi-
cate the mobilization of friction, where the variable
S indicates fully mobilized (at the point of slipping) friction
when S ¼ 1 (Majmudar and Behringer 2005a)
Jamming of Granular Matter
417

randomeness in hard particle packings. The deﬁ-
nition of MRJ does, however, depend on the
choice of the order parameter, and further work
needs to be done to explore appropriate order
parameters.
Isostatic Packings are Marginal
It has become increasingly clear through theoret-
ical analysis and simulations that isostatic packing
of frictionless, isotropic particles are marginally
stable. Simulations show that the vibrational spec-
trum of these packings have many soft modes and
that the density of states of zero-frequency modes
become non-zero as Point J (which is isostatic) is
approached (O’Hern et al. 2003). There is a
diverging length scale associated with these vibra-
tional modes, and this length scales as 1/(z – ziso)
(Wyart et al. 2005a, b). The theoretical explana-
tion for this divergence is rooted in the vanishing
degrees of freedom as the isostatic point is
approached from the jammed, hyperstatic side
(Wyart 2005; Wyart et al. 2005a; Ellenbroek
2007). Stability analysis of the packing of deform-
able, isotropic grains, also shows that there is a
Jamming of Granular Matter, Fig. 16 Force-force cor-
relation functions obtained from 2D experiments. To com-
pute these correlation functions, we compute the average
force magnitude, hF(r þ r0)F(r)i, acting on a particle. Since
the system may be anisotropic, the average over r0 must
retain the angular information. We contrast data for a
system that has been subjected to pure shear, top, with
one that has been subject to isotropic compression, bottom
(see part b of Fig. 14). The right side of the ﬁgure shows a
grayscale representation of the data. For the shear case, the
correlation function has a roughly power-law decay (to the
limits of the system size) for correlations along the strong
force chain direction, and a rapid drop off for the transverse
direction. For the isotropically compressed case, the corre-
lations are identical in all directions, and decay rapidly
(Majmudar and Behringer 2005a)
418
Jamming of Granular Matter

marginal stability line along which, the pressure
of the packing obeys p/B ¼ (z – ziso),(Jaeger et al.
1996b) where p is the pressure and B is the bulk
modulus of the packing (Wyart 2005; Ellenbroek
2007). Packings with fewer than the number of
contacts speciﬁed by this relation are unstable.
The question of whether isostacity and marginal-
ity always go hand in hand is an interesting ques-
tion that is beginning to be explored (Donev et al.
2007; Krzakala and Kurchan 2007).
Simulations and Theory
As discussed in section “Isotropic vs. Anistropic
Stress States”, simulations of deformable, spherical
grains (O’Hern et al. 2003; O’Hern et al. 2001)
exhibit a special packing fraction, fc, below which
it is impossible to construct a jammed packing, and
interestingly, for large systems, fc approaches the
RCP value. Recent theoretical work based on the
isostatic nature of Point J (Wyart 2005; Ellenbroek
2007), have provided an explanation for the diverg-
ing correlation length and the scaling relation
between pressure and the number of contacts.
A theory based on a minimum number of contacts
needed for local stability is the K-core percolation
model of Schwartz et al. (2006). This theory
focusses on the mixed ﬁrst-second order nature of
the transition at Point J in terms of the order param-
eter, hzi, which approaches ziso with an exponent
close to 1/2 as f ! fþ
c , but which is predicted to
be zero for f inﬁnitesimally below fc. The
meanﬁeld exponents of this model agree with the
exponents associated with Point J in the numerical
simulations.
A ﬁeld theory of jammed grain packings in two
dimensions, and close to Point J has been
constructed using the generalized stress-based
ensemble (section “Statistical Framework of Jam-
ming”), and a ﬂuctuating ﬁeld related to the Airy
Stress function (Ball and Blumenfeld 2002). This
ﬁeld theory (Henkes and Chakraborty 2005),
identiﬁes two order parameters associated with
the transition at Point J; the Airy stress function
and the deviation of the number of contacts from
the isostatic value. The ﬁeld theory predicts a
transition with a diverging length scale. Recent
work
(Henkes
and
Chakraborty
2008)
has
focussed
on
reﬁning
this
ﬁeld
theory
by
comparing its predictions to simulations of fric-
tionless disks (O’Hern et al. 2003).
The stress-based ensemble described in section
“Statistical Framework of Jamming” can be used
to understand the exponential form of P(F), if one
uses the fact that the packings at fc are
isostatic. The starting point of this calculation is
the canonical partition function of the stress-based
ensemble: Z(α) ¼ veαΓv, where α is the coun-
terpart of the inverse temperature and Γ ¼ ij|rij|
Fij (Henkes et al. 2007). At fc, the spheres or
disks are just touching, and therefore, the separa-
tions |rij| can be replaced by the diameter of the
grains. The sum over grain conﬁgurations, v,
therefore, involves a sum over the Fij’s and the
angles of the contact vectors. The isostatic point is
special in that there is a one-to-one correspon-
dence between geometry and forces. This means
that for a chosen set of {Fij}, there is only one
geometry characterized by a set of contact angles
that can be mechanically stable. The partition
function then becomes:
Z a
ð Þ ¼
X
Fij
f g
e
P
ijaFij ¼
ð1
0
dFeaF

zisoN=2
ð6Þ
The integral is easily performed, and the result
can be used to relate ˛ to the average contact force,
hFi: α ¼ (ziso/2)hFi. Since the forces on different
contacts are completely independent of each other
at this isostatic point, as seen from Eq. (6), it
follows that P F
ð Þ / eaF ¼ ezisoF= 2 F
h i
ð
Þ, a pure
exponential. This is a consequence of isostaticity.
Away from the isostatic point, the correspondence
between geometry and a set of contact forces is no
longer one-to-one and distributions will acquire a
non-exponential character, in agreement with
observations that P(F) of crystalline packings
are more Gaussian than disordered packings, as
discussed in section “Force Distributions, Length
and Time Scales in Jammed States near the Jam-
ming Transition”.
Analysis of simulations of frictionless disks,
using this generalized ensemble led to a deﬁnitive
functional form for the distribution of Gm ¼
Pm
i¼1
P
jrijFij, the pressure of m particles inside
an assembly of N grains, integrated over the
Jamming of Granular Matter
419

volume occupied by the grains (Γ is known as the
internal virial). The distribution Pm(Γm) depends
only on x ¼ NΓm/ΓN, where ΓN is the internal virial
of the whole assembly of N grains, and the func-
tional form is (Henkes et al. 2007):
Pm x
ð Þ / xmaeax,
ð7Þ
where a ¼ 2 þ (hzi  ziso)2 This form indicates
that the distribution would approach a Gaussian
with a width which narrows as
ﬃﬃﬃﬃm
p , in x space. In
the space of the unscaled variable Γm, however,
the distribution could acquire a non-trivial shape
and scaling with m if ΓN ! 0, or equivalently,
α ! 1. Since this is what happens as f ! fc, one
can expect non-trivial scaling of the pressure dis-
tribution. Equation (7) also shows that the expo-
nential tail is maximally stretched at hzi ¼ ziso.
Evidence for this may appear in the distributions
of Fig. 8, where just at the transition, the expo-
nential tail has become extremely extended.
There are many existing models for the expo-
nential distribution of forces. In one view (Corwin
et al. 2005b; O’Hern et al. 2001), the exponential
distribution is related to the form of the pair cor-
relation function G(r), a function that measures
the number of particles separated by a distance r,
at small r. Using generic properties of G(r) and the
limit where grains are barely compressed, leads to
a P F
ð Þ / eFk, where the exponent k depends on
the force law. In this approach, the exponential
distribution is not related to isostaticity. This point
of view was developed through the discussion of
the experimental results of Corwin et al. (2005b).
A different set of approaches have considered the
origin of the unidirectional transmission of forces
(force chains) (Cates et al. 1998a, b, 1999) by
proposing a new class of constitutive relations
arising from constraints on the stress tensor due
to geometry of the packings. This approach has a
natural connection to the generalized ensemble
(Edwards and Blumenfeld 2007; Blumenfeld
2007) and isostaticity (Edwards and Blumenfeld
2007; Tkachenko and Witten 1999; Ball and
Blumenfeld 2002). An earlier, heuristic model,
the q-model led to unidirectional propagation of
forces, and an exponential distribution of contact
forces (Coppersmith et al. 1996). More recently,
Snoeijer et al. (2004d) and Tighe et al. (2005b)
have predicted force distributions using the force
ensemble approach (section “Statistical Frame-
work of Jamming”). The connection between the
stress-based ensemble and force chains, away
from isostaticity is still being explored.
Experimental Observations
Direct experimental investigation of Point J,
approached from the jammed side, and the behav-
ior in its vicinity have been more limited than
computational and theoretical studies. We are
aware of only one experiment by Majmudar et al.
(2007) that has directly probed Point-J from the
jammed side. This work (Majmudar et al. 2007)
has provided detailed experimental data for the
mean contact number, Z, and the pressure, P vs.
the packing fraction, fc. Hence, it is possible now
to make direct comparison between a physical
experiment and theory/model results. In these
experiments, photoelastic disks were conﬁned in
the biaxial tester discussed above. The photoelastic
approach allows the experimental determination of
contact forces between pairs of particles or between
particles and a boundary.
Figure 17 shows results for Z(f) and P(f). The
data for Z show a fairly rapid increase in Z with
increasing f, but not a truly sharp discontinuity.
However, assuming a reasonable choice of fc, the
data indicate an increase of Z above the critical
value which varies as Z  Zc / (f  fc)α with an
exponent α ¼ 0.55  0.05. This result is in agree-
ment with the simulation of frictionless grains
(O’Hern et al. 2003). The pressure also follows a
power-law in f – fc with an exponent of
1.1  0.05, which is in agreement with Silbert
et al. (O’Hern et al. 2003). Finally, it is possible to
compare to the stress-ensemble predictions of
Henkes and Chakraborty by eliminating α in
their predictions for P(α) and Z(α) to obtain an
expression for P(Z). The data, Fig. 18, are also in
reasonable agreement with this prediction.
Future Directions
From the combined experimental, theoretical, and
simulation studies of the last decade, a picture of
420
Jamming of Granular Matter

the nature of jamming in granular matter is begin-
ning to emerge, although many questions remain.
In our discussion, we distinguish jamming/
unjamming under isotropic and anisotropic stress
conditions. Many recent simulations have consid-
ered the isotropic approach to Point J. A number
of
experiments
have
explored
jamming/
unjamming, although most of these involved the
succession of failures that occur under shear and
away from Point J, which corresponds to pro-
cesses with a heuristically ‘ﬁrst-order’ character.
We believe that it is important to distinguish these
various cases. To our knowledge, no one has
considered the approach to Point J along an aniso-
tropic stress path.
There are clear indications of heterogeneities
in granular matter. These have both a spatial and a
temporal aspect, and they become increasingly
important with the approach to jamming. They
have been identiﬁed on both the ﬂuid-like and
jammed side of the transition.
One
aspect
of
these
heterogeneities
is
concerned with forces and their transmission.
A clear manifestation is in force chains, which
can show strong correlations in the sheared state,
but very short range correlations in the isotropic
stress state. In dynamic processes, force chains
continually rearrange, leading to strong force ﬂuc-
tuations. Although force chains are clearly visible
in a variety of 2D experiments that are carried out
above jamming, incipient stress chains have been
observed in simulations of hopper ﬂow on the
ﬂuid-like side (Ferguson and Chakraborty 2007),
and there is evidence of arch formation and stress
chains in experiments studying jamming in hopper
ﬂow (To 2005; Zuriguel et al. 2005; Easwar n.d.).
An open question concerns the role that such
structures may play if Point J is approached
along a path of anisotropic stress.
A different type of heterogeneity in granular
ﬂows is related to the mobilities of grains (Keys
et al. 2007; Dauchot et al. 2005). This situation is
similar to heterogeneities in supercooled liquids.
The analogies between jamming and thermal
phase transitions prompts questions about the
extent of the similarities between the two. For
instance, is there an order parameter associated
with the transition? Studies of the special type of
Jamming of Granular Matter, Fig. 17 Data for the
pressure and for the mean contact number per particle,
Z vs. f. The inset shows that Z vs. f over a larger range
than the top part of the ﬁgure. Data including rattlers as
shown by asterisks, and data without rattlers by diamonds.
Note that Z rises rapidly but not discontinuously at jam-
ming. Power-law ﬁts of P and Z – Zc vs. f – fc above
jamming and for reasonable fc show expected exponents
of 0.55  0.05 for Z – Zc and 1.1 for P (Majmudar et al.
2007)
Jamming
of
Granular
Matter,
Fig.
18 Data
of
Majmudar et al. for P vs. Z showing the generally good
agreement with the predictions of Henkes and Chakraborty
(Majmudar et al. 2007)
Jamming of Granular Matter
421

jamming at Point J suggest that pressure and the
deviation of the number of contacts from the iso-
static value are the two, possibly coupled, candi-
dates for the order parameter.
The generic jamming/unjamming transition
that takes place in the presence of non-zero shear
stress is characterized by intermittent dynamics
and is reminiscent of trap-like dynamics, where
the shearing causes the system to “hop” from one
jammed state to another and jamming occurs
when the average time scale for exploring all the
traps diverges (Behringer et al. 2008; Monthus
and Bouchaud 1996). The framework of soft-
glassy-rheology
(Sollich
1998)
provides
an
approach to calculating the stress response of
granular packings approaching jamming. In this
picture, the jammed state is an intrinsically non-
equilibrium state, which exhibits aging, meaning
a slow evolution of its properties with time. The
issues raised here are much the same as those
arising in the context of the glass transition, and
involve understanding the relation between ﬂuc-
tuations and response (Bouchaud et al. 1996),
through the deﬁnition of an effective temperature.
This is an area of active research (Song et al.
2005a, b; Potiguar and Makse 2006; Ono et al.
2002; O’Hern et al. 2004).
Understanding the jamming of non-spherical
grains is much less advanced than that of spherical
grains. In this regard, the geometrical approach of
Torquato and Stillinger (Donev et al. 2007) is
being applied to non-spherical grains. Experi-
ments have probed the issue of isostaticity in
non-spherical grains (Desmond and Franklin
2006; Man et al. 2005; Blouwolff and Fraden
2006). The stress-based ensemble described in
this article is a promising approach for analyzing
these issues.
In the context of frictional and frictionless
packings, a question that needs to be addressed
is what aspects of the jamming transition are sen-
sitive to the presence of friction. Simulations and
theories of jamming have mainly focussed on
frictionless
grains.
The
statistical
ensemble
approaches, however, are general and provide an
avenue for a uniﬁed framework.
These observations raise many questions:
1. How are stress chains related to the the mobil-
ity of grains? Since force chains tend to lock
grains in place, it may well be that there is anti-
correlation between force chains and mobility.
2. Is there a basic dynamical principle leading to
the occurrence of stress chains, or are they
more strongly inﬂuenced by geometry?
3. What if any, is the relationship between the
length and time scales on the jammed side to
those observed on the ﬂowing side?
4. Are incipient chains on the ﬂuid-like side
responsible for jamming as the transition is
approached? Is jamming caused by a diver-
gence of the lifetime of these chains?
5. Is there an extension to jamming in the pres-
ence of shear? That is, how does the path in P-t
space affect jamming?
6. What is the nature of jamming for nonspherical
particles, for systems with a broad range of
particle sizes, or for particles that interact
with cohesive forces?
The advances in experimental techniques
which have led to the measurement of grain-
level forces, has been a tremendous boon for
theorists. Simulations have led to detailed descrip-
tions of ﬂuctuations which provide means for
testing
theoretical
frameworks.
The
recent
advance in the statistical ensemble approach to
jamming, the geometrical characterizations of
packings of rigid grains, combined with the
detailed experimental and simulation studies, is
expected to answer many of the remaining ques-
tions and lead to a fuller understanding of the
phenomenon of jamming.
Bibliography
Ball RC, Blumenfeld R (2002) Stress ﬁeld in granular
systems: loop forces and potential formulation. Phys
Rev Lett 88:115505
Barrat A, Kurchan J, Loreto V, Sellitto M (2000) Edwards’
measures for powders and glasses. Phys Rev Lett
85:5034
Barrat A, Kurchan J, Loreto V, Sellitto M (2001) Edwards’
measures: a thermodynamic construction for dense
granular media and glasses. Phys Rev E 6305:
0513011–05130114
422
Jamming of Granular Matter

Behringer RP, Chakraborty B, Henkes S, Hartley RR
(2008) Why do granular materials stiffen with shear
rate? A test of novel stress-based statistics. Phys Rev
Lett (to appear)
Berthier L et al (2005) Direct experimental evidence of a
growing length scale accompanying the glass transi-
tion. Science 310:1797–1800
Bertin E, Dauchot O, Droz M (2004) Temperature in non-
equilibrium systems with conserved energy. Phys Rev
Lett 93:2306011–2306014
Bertin E, Dauchot O, Droz M (2005) Nonequilibrium
temperatures in steady-state systems with conserved
energy. Phys Rev E 71:0461401–04614014
Bertin E, Dauchot O, Droz M (2006) Deﬁnition and rele-
vance of nonequilibrium intensive thermodynamic
parameters. Phys Rev Lett 96:1206011–1206014
Blouwolff J, Fraden S (2006) The coordination number of
granular cylinders. Europhys Lett 76:1095
Blume M, Emery V, Grifﬁths RB (1971) Ising model for
the lambda transition. . .. Phys Rev A 4:1071
Blumenfeld R (2007) On entropic characterization of gran-
ular materials. To appear. In: Aste T, Tordesiillas A,
Matteo T (eds) Lecture notes. World Scientiﬁc,
Singapore
Blumenfeld R, Edwards SF (2003) Granular entropy:
explicit calculations for planar assemblies. Phys Rev
Lett 90:1143031–1143034
Bouchaud J, Biroli G (2004) On the Adam-Gibbs-
Kirkpatrick-Thirumalai-Wolynes scenario for the vis-
cosity increase in glasses. J Chem Phys 121:7347–7354
Bouchaud J, Cugliandolo L, Kurchan J, Mezard M (1996)
Mode-coupling approximations, glass theory and dis-
ordered systems. Phys A 226:243–273
Cates M, Wittmer J, Bouchaud J, Claudin P (1998a) Jam-
ming, force chains, and fragile matter. Phys Rev Lett
81:1841–1844
Cates M, Wittmer J, Bouchaud J, Claudin P (1998b) Devel-
opment of stresses in cohesionless poured sand. Philos
Trans R Soc Lond Ser A-Math Phys Eng Sci 356:
2535–2560
Cates ME, Wittmer JP, Bouchaud JP, Claudin P (1999)
Jamming and static stress transmission in granular
materials. Chaos 9:511–522
Chandler D (1987) Introduction to modern statistical
mechanics. Oxford University Press, New York
Coniglio A, Fierro A, Nicodemi M (2001) Applications of
the statistical mechanics of inherent states to granular
media. Phys A-Stat Mech Appl 302:193
Coniglio A, Fierro A, Nicodemi M (2002) Probability
distribution of inherent states in models of granular
media and glasses. Eur Phys J E 9:219
Coppersmith S, Liu C, Majumdar S, Narayan O, Witten
T (1996) Model for force ﬂuctuations in bead packs.
Phys Rev E 53:4673–4685
Corwin EI, Jaeger HM, Nagel SR (2005a) Structural sig-
nature of Jamming in granular media. Nature 435:
1075–1078
Corwin E, Jaeger H, Nagel S (2005b) Structural signature
of Jamming in granular media. Nature 435:1075–1078
Daniels KE, Behringer RP (2005a) Hysteresis and compe-
tition between disorder and crystallization in sheared
and vibrated granular ﬂow. Phys Rev Lett 94:168001
Daniels KE, Behringer RP (2005b) Characterization of a
freezing/melting transition in a vibrated and sheared
granular medium. In: Garcia-Rojo R, Herrmann HJ,
McNamara S (eds) Powders, grains 05. Balkema, Rot-
terdam, pp 357–360
Daniels KE, Behringer RP (2005c) Hysteresis and compe-
tition between disorder and crystallization in sheared
and vibrated granular ﬂow: hysteresis and competition
between disorder and crystallization in sheared and
vibrated granular ﬂow. Phys Rev Lett 94:168001
Daniels KE, Behringer RP (2006) Characterization of a
freezing/melting transition in a vibrated and sheared
granular medium. J Stat Mech 7:P07018
Dauchot O, Marty G, Biroli G (2005) Dynamical hetero-
geneity close to the jamming transition in a sheared
granular material. Phys Rev Lett 95:265701
Desmond K, Franklin SV (2006) Jamming of three-
dimensional prolate granular materials. Phys Rev
E Stat Nonlinear Soft Matter Phys 73:031306
Dhar D (2006) Theoretical studies of self-organized criti-
cality. Phys A-Stat Mech Appl 369:29–70
Dolnik M, Zhabotinsky A, Epstein I (1996) Modulated
standing waves in a short reaction-diffusion system.
J Phys Chem 100:6604–6607
Donati C et al (1998) Stringlike cooperative motion in a
supercooled liquid. Phys Rev Lett 80:2338
Donati C, Glotzer S, Poole P, Kob W, Plimpton S (1999)
Spatial correlations of mobility and immobility in a
glass-forming
Lennard-Jones
liquid.
Phys
Rev
E 60:3107
Donev A, Torquato S, Stillinger F, Connelly R (2004)
Jamming in hard sphere and disk packings. J Appl
Phys 95:989–999
Donev A, Connelly R, Stillinger FH, Torquato S (2007)
Underconstrained jammed packings of nonspherical
hard particles: ellipses and ellipsoids. Phys Rev E 75:
0513041–05130432
Drocco JA, Hastings MB, Reichardt CJO, Reichardt
C (2005) Multiscaling at point j: Jamming is a critical
phenomenon. Phys Rev Lett 95:088001
Easwar N Private communication
Ediger MD, Angell CA, Nagel SR (1996) Supercooled
liquids and glasses. J Phys Chem 100:13200
Edwards SF, Blumenfeld R (2007) The thermodynamics of
granular materials. In: Mehta A (ed) Physics of granular
materials. Cambridge University Press, Cambridge
Edwards SF, Grinev DV (1999) Statistical mechanics of
stress transmission in disordered granular arrays. Phys
Rev Lett 82:5397
Edwards SF, Grinev DV (2001) Jamming and Rheology:
constrained dynamics on microscopic and macroscopic
scales. Taylor, New York
Edwards SF, Oakeshott RBS (1989) Theory of powders.
Phys A 157:1080
Ellenbroek WG (2007) Response of granular media near
the Jamming transition. PhD thesis, Leiden University
Jamming of Granular Matter
423

Ertas D, Halsey T (2002) Granular gravitational collapse
and chute ﬂow. Europhys Lett 60:931–937
Ferguson A, Chakraborty B (2006) Stress and large-scale
spatial structures in dense, driven granular ﬂows. Phys
Rev E 73:0113031–0113037
Ferguson A, Chakraborty B (2007) Spatially heterogenous
dynamics in dense, driven granular ﬂows. Europhys
Lett 78
Ferguson A, Fisher B, Chakraborty B (2004) Impulse
distributions in dense granular ﬂows: signatures of
large-scale
spatial
structures.
Europhys
Lett
66:
277–283
Geng J, Behringer RP (2005) Slow drag in two-
dimensional granular media. Phys Rev E 71:011302
Geng J, Behringer RP, Reydellet G, Clément E (2003)
Green’s function measurements of force transmission
in 2d granular materials. Physica D 182:274
Hartley RR, Behringer RP (2003) Logarithmic rate depen-
dence of force networks in sheared granular materials.
Nature 421:928
Henkes S, Chakraborty B (2005) Jamming as a critical
phenomenon: a ﬁeld theory of zero-temperature grain
packings. Phys Rev Lett 95:1980021–1980024
Henkes S, Chakraborty B (2008) Field theory, soft modes
and the nature of jamming the critical point. Phys Rev
E (to appear)
Henkes S, O’Hern CS, Chakraborty B (2007) Entropy and
temperature of a static granular assembly: an ab initio
approach. Phys Rev Lett 99:0380021–0380024
Howell D, Behringer RP (1999) Fluctuations in a 2d gran-
ular Couette experiment: a critical transition. Phys Rev
Lett 82:5241
Hurley M, Harrowell P (1995) Kinetic structure of a two-
dimensional liquid. Phys Rev E 52:1694–1698
Jaeger H, Nagel S, Behringer R (1996a) Granular solids,
liquids, and gases. Rev Mod Phys 68:1259–1273
Jaeger H, Nagel S, Behringer R (1996b) The physics of
granular materials. Phys Today 49:32–38
Kadanoff LP (1999) Built upon sand: theoretical ideas
inspired by granular ﬂows. Rev Mod Phys 71:435
Keys AS, Abate AR, Glotzer SC, Durian DJ (2007) Direct
observation of growing dynamical length scales and
prediction of the jamming transition from dynamical
heterogeneity in a granular system. Nat Phys 3:260
Kirkpatrick TR, Thirumalai D, Wolynes PG (1989) Scaling
concepts for the dynamics of viscous liquids near an
ideal glassy state. Phys Rev A 40:1045
Kolb E, Cviklinski J, Lanuza J, Clauding P, Clement
E (2004) Reorganization of a dense granular assembly:
the
unjamming
response
function.
Phys
Rev
E 69:031306
Krzakala F, Kurchan J (2007) Landscape analysis of con-
straint
satisfaction
problems.
Phys
Rev
E
76:
0210021–02100213
Kurchan J (2001) Recent theories of glasses as out of
equilibrium systems. Comptes Rendus Acad Sci Ser
Iv Phys Astrophys 2:239–247
Lacevic N, Starr F, Schroder T, Glotzer S (2003) Growing
correlation length on cooling below the onset of caging
in a simulated glass-forming liquid. J Chem Phys
119:7372
Liu AJ, Nagel SR (1998) Jamming is not just cool any-
more. Nature 396:21
Lois G, Lemaitre A, Carlson JM (2007a) Spatial force
correlations in granular shear ﬂow. I. Numerical evi-
dence. Phys Rev E 76:0213021–02130212
Lois G, Lemaitre A, Carlson JM (2007b) Spatial force
correlations in granular shear ﬂow. II. Theoretical
implications. Phys Rev E 76:0213031–02130314
Longhi E, Easwar N, Menon N (2002) Large force ﬂuctu-
ations in a ﬂowing granular medium. Phys Rev Lett 89:
0455011–0455014
Majmudar TS, Behringer RP (2005a) Contact force mea-
surements and stress-induced anisotropy in granular
materials. Nature 435:1079–1082
Majmudar TS, Behringer RP (2005b) Contact forces and
stress induced anisotropy. In: Garcia-Rojo R, Herr-
mann HJ, McNamara S (eds) Powders and grains. 65.
AA Balkema, Leiden
Majmudar TS, Sperl M, Luding S, Behringer RP
(2007) Jamming transition in granular systems. Phys
Rev Lett 98:058001
Makse H, Kurchan J (2002) Testing the thermodynamic
approach to granular matter with a numerical model of
a decisive experiment. Nature 415:614–617
Makse H, Johnson D, Schwartz L (2000) Packing of com-
pressible granular materials. Phys Rev Lett 84:
4160–4163
Man W et al (2005) Experiments on random packings of
ellipsoids. Phys Rev Lett 94:198001
Miller B, O’Hern C, Behringer RP (1996) Stress ﬂuctua-
tions for continuously sheared granular materials. Phys
Rev Lett 77:3110
Monthus C, Bouchaud J-P (1996) Models of traps and
glass phenomenology. J Phys A 29:3847
Nedderman RM (1992) Statics and kinematics of granular
materials. Cambridge University Press, Cambridge
O’Hern C, Langer S, Liu A, Nagel S (2001) Force distri-
butions near Jamming and glass transitions. Phys Rev
Lett 86:111
O’Hern C, Langer S, Liu A, Nagel S (2002) Random pack-
ings of frictionless particles. Phys Rev Lett 88:075507
O’Hern CS, Silbert LE, Liu AJ, Nagel SR (2003) Jamming
at zero temperature and zero applied stress: the epitome
of disorder. Phys Rev E 68:011306
O’Hern C, Liu A, Nagel S (2004) Effective temperatures in
driven systems: static versus time-dependent relations.
Phys Rev Lett 93:1657021–1657024
Ono I et al (2002) Effective temperatures of a driven
system
near
jamming.
Phys
Rev
Lett
89:
0957031–0957034
Perera D, Harrowell P (1996) Kinetic structure of a two-
dimensional liquid. Phys Rev E 54:1652
Potiguar F, Makse H (2006) Effective temperature and
jamming transition in dense, gently sheared granular
assemblies. Euro Phys J E 19:171–183
Pouliquen O (1999) Scaling laws in granular ﬂows down
rough inclined planes. Phys Fluids 11:542–548
424
Jamming of Granular Matter

Pouliquen O (2004) Velocity correlations in dense granular
ﬂows. Phys Rev Lett 93:248001
Reynolds O (1885) On the dilatancy of media composed
of
rigid
particles
in
contact.
Philos
Mag
Ser
5(50–20):469
Schmittmann B, Zia RKP (1995) Statistical mechanics of
driven diffusive systems. In: Domb C, Lebowitz J (eds)
Phase transitions and critical phenomena, vol 17. Aca-
demic Press, New York
Schwartz J, Liu A, Chayes L (2006) The onset of jamming
as the sudden emergence of an inﬁnite k-core cluster.
Europhys Lett 73:560–566
Silbert L (2005) Temporally heterogeneous dynamics in
granular ﬂows. cond-mat/0501617
Silbert LE, Ertas D, Grest GS, Halsey TC, Levine D (2002)
Analogies between granular jamming and the liquid-
glass transition. Phys Rev E 65:051307
Silbert LE, Liu AJ, Nagel SR (2005) Vibrations and diverg-
ing length scales near the unjamming transition. Phys
Rev Lett 95:098301
Silbert LE, Grest GS, Brewster R, Levine AJ (2007) Rhe-
ology and contact lifetimes in dense granular ﬂows.
Phys Rev Lett 99:068002
Snoeijer JH, Vlugt TJH, van Hecke M, van Saarloos
W (2003a) Force network ensemble: a new approach
to static granular matter. Phys Rev Lett 91:072303
Snoeijer J, van Hecke M, Somfai E, van Saarloos
W (2003b) Force and weight distributions in granular
media: effects of contact geometry. Phys Rev E 67:
0303021–0303024
Snoeijer J, Vlugt T, van Hecke M, van Saarloos W (2004a)
Force network ensemble: a new approach to static
granular matter. Phys Rev Lett 92:0543021–0543024
Snoeijer J, van Hecke M, Somfai E, van Saarloos
W (2004b) Packing geometry and statistics of force
networks
in
granular
media.
Phys
Rev
E
70:
0113011–01130115
Snoeijer J, Vlugt T, Ellenbroek W, van Hecke M, van
Leeuwen J (2004c) Ensemble theory for force networks
in hyperstatic granular matter. Phys Rev E 70:
0613061–06130616
Snoeijer JH, van Hecke M, Somfai E, van Saarloos
W (2004d) Force and weight distributions in granulr
media:
effects
of
contact
geometry.
Phys
Rev
E 67:030302
Snoeijer JH, Vlugt TJH, van Hecke M, van Saarloos
W (2004e) Force network ensemble: a new approach
to static granular matter. Phys Rev Lett 92:054302
Snoeijer J, Ellenbroek W, Vlugt T, van Hecke M (2006)
Sheared force networks: anisotropies, yielding, and
geometry. Phys Rev Lett 96:09800191–00980014
Sollich P (1998) Rheological constitutive equation for a
model of soft glassy materials. Phys Rev E 58:738
Song C, Wang P, Potiguar F, Makse H (2005a) Experimen-
tal and computational studies of jamming. J Phys-
Condens Matter 17:S2755–S2770
Song C, Wang P, Makse H (2005b) Experimental measure-
ment of an effective temperature for jammed granular
materials. Proc Natl Acad Sci USA 102:2299–2304
Tighe B, Socolar J, Schaeffer D, Mitchener W, Huber
M (2005a) Force distributions in a triangular lattice of
rigid bars. Phys Rev E 72:0313061–03130610
Tighe BP, Socolar JES, Schaeffeer DG, Mitchener WG,
Huber ML (2005b) Force distributions in a triangular
lattice of rigid bars. Phys Rev E 72:031306
Tkachenko A, Witten T (1999) Stress propagation through
frictionless granular material. Phys Rev E 60:687
To K (2005) Jamming transition in two-dimensional hop-
pers and silos. Phys Rev E Stat Nonlinear Soft Matter
Phys 71:060301
Torquato S, Truskett T, Debenedetti P (2000) Is random
close packing of spheres well deﬁned? Phys Rev Lett
84:2064–2067
van Eerd ART, Ellenbroek WG, van Hecke M, Snoeijer JH,
Vlugt TJH (2007) Tail of the contact force distribution
in
static
granular
materials.
Phys
Rev
E
75:
0603021–0603024
Veje C, Howell D, Behringer RP (1999) Kinematics of a
two-dimensional granular Couette experiment at the
transition to shearing. Phys Rev E 59:739–745
Weeks ER, Crocker JC, Levitt AC, Schoﬁeld A, Weitz DA
(2000) Three-dimensional direct imaging of structural
relaxation near the colloidal glass transition. Science
287:627
Wyart M (2005) On the rigidity of amorphous solids. Ann
Phys 30:1–96
Wyart M, Nagel S, Witten T (2005a) Geometric origin of
excess low-frequency vibrational modes in weakly
connected amorphous solids. Europhys Lett 72:486–492
Wyart M, Silbert LE, Nagel SR, Witten TA (2005b) Effects
of compression on the vibrational modes of marginally
jammed solids. Phys Rev E 72:051306
Xia X, Wolynes PG (2001) Fragilities of liquids predicted
from the random ﬁrst order transition theory of glasses.
Phys Rev Lett 86:5526
Zuriguel I, Garcimartin A, Maza D, Pugnaloni LA, Astor
JM (2005) Jamming during the discharge of granular
matter from a silo. Phys Rev E Stat Nonlinear Soft
Matter Phys 71:051303
Books and Reviews
Blumenfeld R (2004) Stresses in isostatic granular systems
and emergence of force chains. Phys Rev. Lett
93:108301
Bouchaud JP (2003) Granular media: some ideas from sta-
tistical physics. In: Barrat JL, Dalibard J, Feigelman M,
Kurchan J (eds) Slow relaxations and nonequilibrium
dynamics in condensed matter. Springer, Berlin
Bouchaud JP, Claudin P, Levine D, Otto M (2001) Force
chain splitting in granular materials: a mechanism for
large-scale pseudo-elastic behaviour. Eur Phys J E 4:
451–457
Coniglio A, Fierro A, Herrmann H, Nicodemi M (eds)
(2004) Unifying concepts in granular media and
glasses, 1st edn. Elsevier, Amsterdam
Mehta A (1994) Granular matter: an interdisciplinary
approach. Springer, New York
Jamming of Granular Matter
425

Halsey TC, Mehta A (2002) Challenges in granular phys-
ics. World Scientiﬁc, Singapore
Herrmann HJ, Hovi JP, Luding S (1998) Physics of dry
granular media. In: NATOASI series. Series E, Applied
sciences, vol 350. Kluwer Academic, Dordrecht
Jiang Y, Liu M (2007) A brief review of “granular elastic-
ity”: why and how far is sand elastic? Eur Phys J E Soft
Matter 22:255–260
Krimer DO, Pﬁtzner M, Brauer K, Jiang Y, Liu M (2006)
Granular elasticity: general considerations and the
stress dip in sand piles. Phys Rev. E Stat Nonlinear
Soft Matter Phys 74:061310
Otto
M,
Bouchaud
JP,
Claudin
P,
Socolar
JES
(2003) Anisotropy in granular media: classical elastic-
ity and directed-force chain network. Phys Rev. E Stat
Nonlinear Soft Matter Phys 67:031302
Ovarlez G, Fond C, Clement E (2003) Overshoot effect in
the Janssen granular column: a crucial test for granular
mechanics. Phys Rev. E Stat Nonlinear Soft Matter
Phys 67:060302
Torquato S, Donev A, Stillinger F (2003) Breakdown of
elasticity theory for jammed hard-particle packings:
conical nonlinear constitutive theory. Int J Solid Struct
40:7143–7153
426
Jamming of Granular Matter

Rigidity Percolation and
Frictional Jamming
Silke Henkes1 and J. M. Schwarz2
1School of Mathematics, University of Bristol,
Bristol, UK
2Physics Department, Syracuse University,
Syracuse, NY, USA
Article Outline
Glossary
Deﬁnition of the Subject
Introduction
Friction in Granular Materials
Rigidity Percolation
The Frictional Rigidity Transition
Future Directions
Bibliography
Glossary
Force chain Heterogeneous stress in granular
packings with localized force transmission
along one-dimensional structures.
Friction Property of mechanical contacts that
support tangential loading due to microscopic
asperities.
Isostatic The state of a packing where the num-
ber of degrees of freedom exactly balances the
independent constraints.
Jamming Transition to rigidity in granular mate-
rials from a liquid-like state to a state that
supports shear stresses.
Percolation The study of the connectivity of a
structure, such a particle packing, via connec-
tivity clusters, including the onset of a span-
ning connectivity cluster deﬁning the location
of a percolation transition.
Rigid cluster Part of a packing where the num-
ber of independent constraints is greater or
equal to the number of degrees of freedom;
region that supports mechanical load.
Spanning rigid cluster Rigid cluster that spans
the size of the system, equivalent to attaining
macroscopic rigidity, i.e., being jammed.
Definition of the Subject
Frictional jamming in granular materials is the
transition between a state cannot support an
applied stress and so yields or ﬂows, and one
that can. For example, in sand on a well-travelled
beach, an old footprint remains frozen in the sand
until the stress applied by a new step causes it ﬂow
into new shapes.
Introduction
Granular materials are ubiquitous both in nature and
in manufacturing. They span a range of composi-
tion, from sand to pebbles (see Fig. 1a) to grains to
coal to pharmaceuticals, and a range of sizes from
the ﬁnest powder in pharmaceutical processing to
the loose icy gravel that makes up small asteroids
(Kleinhans et al. 2011; Bogdan et al. 2020). Despite
differences in composition and size, what these
materials have in common is that they are made of
discrete, solid units that are interacting with each
other primarily through (mostly) repulsive contact
forces, and that they are sufﬁciently large for thermal
ﬂuctuations to be irrelevant. Related, but different,
materials include colloids and dry foams and cells in
tissues. Colloids are typically smaller in size such
that thermal ﬂuctuations may be signiﬁcant and
interact via longer-ranged attractive polar forces
and depletion forces (Fernandez-Nieves and Puertas
2016). Dry foams and cells in tissues are sufﬁciently
deformable
to
create
conﬂuent
arrangements
© Springer Science+Business Media, LLC, part of Springer Nature 2022
B. Chakraborty (ed.), Statistical and Nonlinear Physics,
https://doi.org/10.1007/978-1-0716-1454-9_739
Originally published in
R. A. Meyers (ed.), Encyclopedia of Complexity and Systems Science, © Springer Science+Business Media LLC 2021
https://doi.org/10.1007/978-3-642-27737-5_739-1
427

without the interstitial free volume characteristic of a
packing
of
nondeformable
granular
particles
(Alberts et al. 2018).
Despite the interactions driving granular mate-
rials being primarily contact forces, they still
exhibit a range of different phases from gaseous
to ﬂuid-like, or unjammed, to solid-like, or
jammed, as they are driven by nonequilibrium
stresses at different packing fractions, for exam-
ple, with the latter two phases characterized by the
jamming phase diagram (Liu and Nagel 1998;
Ciamarra et al. 2010). Moreover, granular pack-
ings exhibit a wealth of interesting, more detailed
phenomena from hysteretic ﬂows (Daniels and
Behringer 2005; Silbert et al. 2001; DeGiuli and
Wyart 2017) to force-chains (Cates et al. 1998;
Majmudar and Behringer 2005) to avalanches
(Daerr and Douady 1999; Staron and Radjai
2005; Pudasaini and Hutter 2007). As for hyster-
etic ﬂows, once a packing begins to ﬂow above
some critical value of applied shear stress, to stop
the ﬂow, one must impose a shear stress less than
the critical value to generate the ﬂow. Force
chains, or chain-like structures with branchings
in the force map for those forces greater than the
average force, emerge in jammed packings.
Avalanches are large-scale rearrangements of a
packing initiated by the motion of just several
particles and can be difﬁcult to predict.
While friction is typically part-and-parcel to
granular packings, given the complications of
hysteretic phenomenon, some theoretical efforts,
at least in the physics community, focused on
frictionless granular packings. Such packings
also exhibit a jamming transition, or a transition
from ﬂuid-like behavior to solid-like behavior as
its packing fraction is increased as evidenced by
the elastic moduli going from zero to non-zero
(Ohern et al. 2003). Frictionless granular packings
also exhibit
force-chains and avalanche-like
behavior, at least near the jamming transition
(Tighe et al. 2010; Xu et al. 2010; Bassett et al.
2015; Olson Reichhardt and Reichhardt 2010). At
the onset of jamming occurs when the packing
becomes mechanically stable to perturbations,
much progress has been made in understanding
the nature of the frictionless jamming transition by
analyzing the mechanical constraints of the sys-
tem (Tighe et al. 2010; Wyart et al. 2005). When
the degrees of freedom outweigh the constraints,
the packing is unjammed. In the opposite case, the
packing is jammed and when there is a balance
a
b
Rigidity
Percolation
and
Frictional
Jamming,
Fig. 1 Examples of frictional granular materials. (a) The
gravel in your front yard hides a secret: Mechanics and
stress transmission in such a jammed frictional granular
packing are highly complex. Image is from the author’s
front yard. (b) Frictional granular material made from
photoelastic disks imaged between cross-polarizers, show-
ing stress transmission along force chains. Image courtesy
of Farnaz Fazelpour and Karen Daniels
428
Rigidity Percolation and Frictional Jamming

between the two, the system is isostatic, or at the
boundary between the two phases. As a conse-
quence of such an approach, consensus has been
reached that the frictionless jamming transition is
mean-ﬁeld-like and has a mixed nature in terms of
a discontinuous onset of average coordination
number from zero, accompanied with several
diverging correlation lengths, typically suggestive
of a continuous phase transition in systems in
thermal equilibrium (van Hecke 2009). The
focus of this review is to determine if such ﬁnd-
ings carry over to frictional granular packings,
which are more generic in nature. After doing
so, we will conclude with a discussion of how
our theoretical approach relates to other theoreti-
cal approaches to frictional jamming, most nota-
bly, theoretical approaches to understand the
phenomenon of shear jamming as well as give
the reader a glimpse into related problems and
open questions.
Friction in Granular Materials
Frictional Contacts
Friction is an emergent property of solid materials
in which microscopic interactions give rise to an
effective resistance to transverse load. At the
microscopic scale of a single contact between two
particles, microscopic creeping and slipping events
at the rough interface allow for the system to sup-
port tangential loading, up to a threshold that
depends sensitively on the interface properties
and compression. At the simplest level, in Cou-
lomb friction, this threshold is approximated as
proportional to the normal compression force, i.e.,
thesystemsupportstangentialloadingforjftj mfn,
where m is the static friction coefﬁcient. Further
tangential motion also induces resistance and is
then modelled by a dynamical friction coefﬁcient.
While frictional contacts are complex and the
subject of active research effort (Müser et al.
2017),
basic
Hertz-Mindlin
contact
theory
(Mindlin 1949), captures the qualitative features
of a frictional contact law: For two spherical par-
ticles of radius R1 and R2, respectively, as shown
in Fig. 2, in contact with a deformation depth δ,
with normal fn and tangential force ft are given by:
f n ¼ knd3=2,
df t ¼ f ndt if j f t j m f n,
f t ¼ mf n otherwise,
ð1Þ
with dt denoting the tangential sliding increment
dt ¼ dr btij  Ridyi þ R jdy j


. The normal stiff-
ness kn is given by Hertzian elastic deformation
theory (Hertz 1881; Johnson 1982; Johnson
1987) with kn ¼ 4
3
ﬃﬃﬃﬃﬃﬃﬃﬃ
RE
p
, where 1/R ¼ 1/R1 þ
1/R2 and E ¼ 2E/(1  n2) with E, the Young’s
modulus, and n, the Poisson ratio. The tangential
force has a differential form since for every tangen-
tial sliding increment dt, the force increases
(or decreases) up to the Coulomb threshold, and
then it remains constant during the sliding phase.
More elaborate theories which include either a
different dynamic friction coefﬁcient or contact
laws that incorporate liquid bridges have been
developed as well (Barber and Ciavarella 2000;
Ciavarella et al. 2019).
Experiments
Experiments on frictional granular materials span
a range from industrial research, where the focus
is on precise modelling of, e.g., a production
environment (see Coussot 2005), to more abstract
setups, which are more useful to understand jam-
ming (Jaeger et al. 1996; Duran 2012). It is these
latter ones we will focus on here. They include
silica beads (Mueth et al. 1998), dense suspen-
sions (Brujić et al. 2003), and most importantly
Rigidity
Percolation
and
Frictional
Jamming,
Fig. 2 Geometry and local coordinates around a frictional
contact. Particles i and j share a contact point with local
normal and tangential vectors bnij and btij. The inﬁnitesimal
motion at the contact can be decomposed into a transla-
tional component δr and rotational components δθi and δθj
Rigidity Percolation and Frictional Jamming
429

for studies of frictional jamming, photoelastic
disks (Amon et al. 2017).
Silica (i.e., SiO2, or quartz) beads consist of
grains that are spherical and monodisperse to the
best experimental precision, with known material
properties. Other controlled experimental condi-
tions, such as humidity control are also frequently
used to make experiments reproducible. Silica
beads have been used extensively to understand
the ﬂow properties of granular materials, e.g., in a
hopper or tilted plane/avalanche setup, or in var-
ious types of explicit rheological setups, such as a
Couette geometry with differentially rotating cyl-
inders (Forterre and Pouliquen 2008). Such three-
dimensional setups are an excellent approxima-
tion of industrially relevant ﬂows, but it is very
difﬁcult to know their internal structure and
forces. In addition to explicit rheometers and sen-
sors at speciﬁc points in the ﬂow (Gardel et al.
2009), X-ray tomography has been used to deter-
mine the packing of such beads (Weis and
Schröter 2017). This method can, however, only
give limited dynamical information and no force
information. To understand the properties of static
packings, on other hand, earlier experiments mea-
sured the forces exerted on boundary particles
(Mueth et al. 1998; Liu et al. 1995).
Better imaging of three-dimensional granular
materials can be achieved by immersing transpar-
ent particles in an index-matched ﬂuid. Then con-
focal
imaging
together
with
laser-sheet
illumination can reveal the internal structure of
the system (Amon et al. 2017). This method has
been applied to both macroscopic (Dijksman et al.
2012) and microscopic granular packings. For
microscale setups of deformable droplets, forces
can be determined from inverting the deformation
at the contact. Fluorescent markers can help dis-
tinguish membranes in contact with each other
from a free interface, and so allow for an accurate
measure of the contact area and, hence, the inter-
action forces (Brujić et al. 2003; Clusel et al.
2009). Dynamically, these setups are more accu-
rately described as dense suspensions: While their
static properties, e.g., the packing structure and
force distributions, are equivalent to either fric-
tional or frictionless packings, viscous dissipation
in the surrounding liquid is crucial to their
rheological properties. In particular, the issue of
shear-thickening in such dense suspensions has
attracted a lot of attention in recent years (Brown
and Jaeger 2009; Clavaud et al. 2017; Royer et al.
2016; Wyart and Cates 2014). We will address the
interaction between shear thickening and fric-
tional rigidity in the concluding section.
An accurate mechanical and dynamical picture
of two-dimensional granular packings with no sur-
rounding ﬂuid can be uncovered by using photo-
elastic disks. Cylinder-shaped particles made from
a photoelastic material are arranged in a ﬂat pack-
ing and are then imaged between cross-polarizers.
Contact deformations induce stresses in the mate-
rial, leading to photoelastic fringes that can be
imaged (see Fig. 1b). One can then use Hertzian
contact theory to invert the fringe pattern to obtain
the contact forces (Majmudar and Behringer 2005;
Majmudar et al. 2007). In practice, it took the best
part of a decade to optimize this experimental
setup: Difﬁculties include, but are not limited to,
nonlinear elastic interactions necessitating solving
the inverse problem iteratively for a full packing,
and minimizing friction with the bottom plate of
the setup (e.g., using an air table) (Daniels et al.
2017) (see Fig. 1b). Rheological measurements on
such photoelastic setups are done in the quasistatic
limit, by applying step-strains at the boundary in
different geometries, with a focus on a pure shear
setup where one direction is compressed while the
perpendicular direction expands (Bi et al. 2011).
Photoelastic disk experiments have given us the
only data sets to date on the full set of forces in
macroscopic frictional packings with dry solid fric-
tion at the contact. These forces can then be tracked
over time to obtain information about the dynamics
of the packing.
Numerical Models
Simulating frictional granular materials is not an
easy task. Unlike for frictionless materials, con-
tact interactions are not conservative, i.e., they do
not derive from a potential. This precludes using
energy minimization protocols to generate fric-
tional packings, and instead full dynamical simu-
lations are nonnegotiable.
The ﬁrst simulations of frictional granular mat-
ter by Cundall and Strack (1979) were a direct
430
Rigidity Percolation and Frictional Jamming

implementation of the Hertz-Mindlin theory of
frictional contacts for two-dimensional cylinders.
The interactions between such cylinders are to
ﬁrst order harmonic, i.e., fn ¼ knδ, instead of
fn ¼ knδ3/2 since there is a contact line instead of
a contact point. More sophisticated models of the
frictional contact abound in the engineering liter-
ature (Wriggers and Nackenhorst 2006). This type
of direct simulation is referred to as molecular
dynamics (MD) in the physics literature, while it
is known as the discrete element method (DEM) in
engineering. In addition to the contact forces, such
simulations are both driven through externally
applied shear, and necessarily also include dissi-
pation, either at the contacts or with a surrounding
bath. Closely related models include a surround-
ing liquid for modelling dense suspensions,
though usually only through effective viscous
pair forces and not a full ﬂuid model. While
there are a number of very detailed DEM simula-
tion tools in the engineering and soil mechanics
literature (see Wriggers and Nackenhorst (2006)
for a review), we focus on the minimal model
ingredients here.
Schematically, the equations of motion for a
granular MD simulation of two-dimensional,
disk-like particles (i.e., real-world cylinders) are
given by the force and torque equations:
mi€ri ¼
X
ij
h i
Fc
ij þ Fdiss
ij
h
i
 z_ri
ð2Þ
Ii€yi ¼
X
ij
h i
rc
ij  Fc
ij þ Fdiss
ij
h
i
 zrot _yi:
ð3Þ
Here, Fc
ij ¼ Fn
ijbnij þ Ft
ijbtij and for round parti-
cles, only the tangential force contributes to the
torque. The pair dissipation forces usually take the
simple form Fdiss
ij
¼ zpair _r j  _ri


. For a simple
harmonic contact model, this corresponds to a
spring and a dashpot in parallel, i.e., a Kelvin
model, in both normal and tangential directions.
To explore frictional jamming, such MD sim-
ulations have been paired with Lees-Edwards
boundary conditions (Allen and Tildesley 2017),
where a simple shear is imposed by shifting the
top and bottom of periodic boundary conditions
with strain rate _g. Alternatively, simulations can
be run with a constant applied (shear) stress s by
applying
a
force
proﬁle
to
the
simulation
(Heussinger 2013; Grob et al. 2014). Another
protocol, inspired by experiment, is to incorporate
gravitation and generate a heap of sand simula-
tion, and study its instability to tilting or rotating
the support (Staron and Radjai 2005). A ﬁnal sim-
ulated protocol is to generate states by controlling
the system pressure in a viscous environment
(Shundyak et al. 2007; Somfai et al. 2007),
thereby explicitly sampling states at very low
pressure and, hence, near frictional jamming.
MD simulations of frictional particles are com-
putationally expensive and, in particular, for very
hard grains (as is appropriate for, e.g., silica beads
or sand), time steps need to be very small to
resolve individual collisions. At the same time,
in the plastic deformation regime, time scales for
signiﬁcant ﬂow are very large. This separation of
time scales has given rise to collision-based algo-
rithms for frictional granular packings: The con-
tact dynamics algorithm (Jean 1999; Radjai and
Richefeu 2009) combines a well-deﬁned collision
protocol with an iterative algorithm to respect the
Coulomb criterion and instantaneous force bal-
ance, and it has been used to simulate avalanches
(Staron and Radjai 2005). Related models are
used
for
lower
density
granular
ﬂow
(Bannerman et al. 2011) and in computer anima-
tion (Bell et al. 2005). Computational speedup
comes at the expense of a realistic contact
model, however.
Frictional Jamming
Given the difﬁculties in obtaining both forces and
dynamics in frictional granular packings, earlier
experimental work centered on questions regard-
ing the lowest attainable density of packing, i.e.,
random loose packing (Onoda and Liniger 1990)
and tests of the Edwards volume ensemble
(Edwards and Oakeshott 1989; Blumenfeld and
Edwards 2009; Puckett and Daniels 2013). Addi-
tionally,
dense,
frictional
granular
packings
revealed two distinct phases: a ﬂuid-like phase
with the packing ﬂowing in response to an applied
perturbation at lower densities and a solid-like
phase with no ﬂows at higher densities. Later, an
Rigidity Percolation and Frictional Jamming
431

additional shear-jamming transition where the
system solidiﬁes in response to a ﬁnite perturba-
tion was discovered (Bi et al. 2011). The boundary
between these two phases is otherwise known as
the frictional jamming transition. Characterization
of this transition started in earnest around the turn
of the millennium with simulations using both
variants of the molecular dynamics approach
introduced above (Silbert et al. 2002; Silbert
2010; Ciamarra et al. 2011; Hatano 2007) and
contact dynamics (Radjai et al. 1996). In parallel,
simulations on granular ﬂows that are not jammed
continued (Forterre and Pouliquen 2008).
Simulations of slowly sheared packings in
two dimensions established a hysteresis loop
(Ciamarra et al. 2011; Hatano 2007) between
unjammed packings at low packing fractions
(typically f < 0.74) and jammed packings at
higher density. These simulations also established
that the jamming packing fraction (as variously
deﬁned by the protocol) strongly depends on the
friction coefﬁcient m, with higher m corresponding
to lower packing fractions (Silbert 2010). Other
simulations (Shundyak et al. 2007; Somfai et al.
2007) sought to formalize this result and focused
on creating frictional packings through an over-
damped equilibration mode in a stress-controlled
ensemble.
Interestingly,
experimental
two-
dimensional packings of photoelastic frictional
disks fall within the range of simulated results
(Majmudar and Behringer 2005). These ﬁndings
are in stark contrast with frictionless packings not
exhibiting such hysteresis and having well-
deﬁned transition point as a function of density,
or packing fraction.
The absence of a well-deﬁned transition pack-
ing fraction, or contact number, then led to explor-
ing the local structure of packings. First, the
analysis of the anisotropy of the local force and
contact network (Peters et al. 2005; Tordesillas
et al. 2010; Walker et al. 2011) led to the devel-
opment
of
shear
jamming.
Shear
jamming
(Bi et al. 2011; Vinutha and Sastry 2016; Peters
et al. 2016; Wang et al. 2018; Zhao et al. 2019)
starts from the empirical result that an initially
unjammed frictional packing will frequently jam
when a shear stress is applied at constant volume
fraction. When under shear stress, the internal
stress state of the system becomes necessarily
anisotropic with a growing correlation length in
the principal stress direction (Baity-Jesi et al.
2017). At a microscopic level, this corresponds
to force chains orienting themselves along the
principal stress direction. This divides the force
network into “strong forces” and “weak forces.”
The strong forces forming chains was ﬁrst
highlighted by Radjai et al. (1998) more than
two decades ago. The shear jamming measure
thresholds the contact network to retain only the
above-average forces f > h f i, where the average
is a spatial average over the given conﬁguration.
The resulting network can either fully percolate,
percolate in one direction only, or not percolate at
all. Shear jamming classiﬁes the states that can be
obtained in this manner as unjammed, shear-
jammed, and fully jammed. In the phase diagram
proposed in (Bi et al. 2011) (Fig. 3), the reentrant
nature of the jamming line in axes of packing
fraction and applied shear stress becomes appar-
ent. Again, this result should be contrasted with
the frictionless case where there is no reentrant
effect.
As for the second local structure approach in
terms of analysis of the number of sliding contacts
(Shundyak et al. 2007; Henkes et al. 2010), we
will turn to constraint counting, which is at the
packing fraction
packing fraction 
Frictionless Jamming
Frictional Jamming
unjammed
jammed
jammed
unjammed
fragile
shear-jammed
Rigidity Percolation and
Frictional Jamming,
Fig. 3 Jamming phase
diagram as a function of
packing fraction and shear
stress for frictionless and
frictional packings. (The
image is a redrawing of the
phase diagram proposed in
(Bi et al. 2011))
432
Rigidity Percolation and Frictional Jamming

heart of rigidity percolation, initially constructed
for frictionless systems. In the last section, we will
comment on the complementarity of the two
approaches.
Rigidity Percolation
Maxwell Constraint Counting
Let us begin brieﬂy with percolation before
addressing rigidity percolation. Percolation con-
siders a spatially embedded graph of vertices
(particles) and edges (bonds), and asks the simple
question: Does the graph contain a spanning clus-
ter, i.e., a subgraph of vertices connected via
bonds that span the entire length of the embed-
ding? Connectivity or bond percolation, the orig-
inal and best-known form of percolation, simply
requires that the graph of the bonds deﬁned by
particle-particle contacts leads to a spanning clus-
ter (Stauffer and Aharony 2018). This is necessary
for a jammed packing, but it is by no means
sufﬁcient! For example, a one-dimensional chain
of connected particles is mechanically unstable
due to buckling under compression; however, it
forms a bond-percolated system.
To gauge the mechanical stability of a system,
rigidity percolation then asks the following ques-
tion: Is there a spanning, mechanically rigid clus-
ter in the system? As we will detail below, within
the constraints of a quasistatic system with inﬁn-
itesimal displacements, this question is equivalent
to (or at least strongly correlated with) the ques-
tion of whether or not a system is jammed.
To mentally unpack rigidity percolation, we
need to step back to the time of James Clerk Max-
well (1831–1879). In the middle of the Victorian
industrial age, it became important to understand
the mechanical stability (or lack thereof) of iron
frames to construct, for example, railway bridges
and stations. Inspired by these applications, in a
pair of seminal papers (Maxwell 1864, 1870),
Maxwell
developed
the
idea
of
constraint
counting, where rigidity is acquired by introducing
a sufﬁcient number of constraints for the degrees of
freedom in the system.
Let us illustrate Maxwell constraint counting
for
a
packing
of
frictional
particles
in
d
dimensions. Each particle has d translational
degrees of freedom and
1
2 d d  1
ð
Þ
rotational
degrees
of freedom, leading to a total of
N 1
2 d d þ 1
ð
Þ degrees of freedom for a packing
composed of N particles. To constrain the motion
along these degrees of freedom, we use the forces
between particles: In the idealized situation of a
packing with inﬁnite friction coefﬁcient m ¼ 1,
regardless of the orientation of the contact surface,
the force can point in any direction. We have also
neglected the restrictions imposed of a purely
compressive force. Under these circumstances,
the interparticle force has d independent compo-
nents which impose d constraints on the motion of
the packing. Due to every contact being shared
between two particles, the total number of con-
tacts is given by Nc ¼ N z
2, where z is the mean
number of contacts between particles. When we
have constrained the packing sufﬁciently, the full
system acts as a rigid body, but it will still retain
d translational and 1
2 d d  1
ð
Þ global rotational
degrees of freedom. Therefore, we need to ﬁx
only exactly N  1
ð
Þ 1
2 d d þ 1
ð
Þ degrees of free-
dom through our constraints. Then by constraint
counting, the packing is rigid if there are enough
constraints, i.e., if N d z
2  N  1
ð
Þ 1
2 d d þ 1
ð
Þ or
after some rearrangements,
z  d þ 1
ð
Þ  1
N d þ 1
ð
Þ:
ð4Þ
The packing is isostatic at ziso ¼(d þ1)(1 1/N)
when we have exactly equal number of constraints
and degrees of freedom. It is hyperstatic or over-
constrained when there are more constraints at
larger
z
>
ziso,
and
it
is
hypostatic
or
underconstrained when there are not enough con-
straints at z < ziso. We will mainly focus on the
case d ¼ 2 below, where every particle has two
rotational and one translational degree of free-
dom, i.e., three in total. Every contact provides
two constraints, one in the normal direction and
one in the tangential direction, and we also have
three global degrees of freedom. The isostatic
point is then given by ziso ¼ 3(1  1/N).
Frictionless isostaticity for spherical particles
is the simplest case exhibiting a jamming transi-
tion (Ohern et al. 2003; Wyart et al. 2005; van
Rigidity Percolation and Frictional Jamming
433

Hecke 2009). Since for a frictionless spherical
particle, orientation is irrelevant, only its d trans-
lational degrees of freedom are pertinent. At the
same time, interparticle forces are necessarily
along the surface normal at the contact point.
Since then only their magnitude is variable, not
their direction, every contact only contributes one
constraint. However, the packing still retains
1
2 d d þ 1
ð
Þ
global translational and rotational
degrees of freedom. The frictionless packing is
rigid if there are more constraints than degrees of
freedom, i.e., if N z
2  N d  1
2 d d þ 1
ð
Þ or after
some rearrangements,
z  2d  1
N d d þ 1
ð
Þ:
ð5Þ
In particular, in two dimensions, we have ziso ¼
4 – 6/N. This ziso is observed in simulations
(Ohern et al. 2003), even the 1/N correction
(Dagois-Bohy et al. 2012; Goodrich et al. 2014).
We will return to address particles with both trans-
lational and rotational degrees of freedom in the
next section.
Laman’s Theorem
Maxwell constraint counting has obvious weak-
ness:
In
addition
to
the
assumption
of
uncorrelated, or independent, constraints, which
breaks down, e.g., for crystalline packings, it only
takes into account z, the mean number of contacts
in the packing. In other words, Maxwell constraint
counting is a mean ﬁeld type approximation. For
instance, any small disconnected part of the pack-
ing cannot be rigid with respect to the rest of it, no
matter how many extra contacts exist between
particles of the main packing. This issue is well
known in granular packings where “rattlers,” that
is particles that have either no or few contacts, are
routinely
excluded from constraint counting
(Ohern et al. 2003). However, there is no guaran-
tee that removing rattlers (even recursively) vali-
dates the mean ﬁeld approximation.
These weaknesses can be overcome by using
graph theory. To go from a packing to a graph, we
map every particle of the packing to a vertex, and
every contact to one or more edges between the
vertices. While we lose information of the positions
of the particles, we gain information of the
interdependency of constraints, or which con-
straints are redundant or not. In the absence of
friction with only normal forces between particles,
the combinatorial Laman’s theorem (Laman 1970)
gives the necessary and sufﬁcient conditions for the
rigidity of such a graph extracted from a two-
dimensional, generic packing, where generic trans-
lates to the absence of any underlying spatial sym-
metries in the packing. We state here the more user-
friendly formulation due to Tay (1993).
Theorem: The graph G containing u vertices
and e edges is inﬁnitesimally rigid if and only if
every subgraph G0, with its own u0 vertices and e0
edges, satisﬁes e0  2u0  3.
The graph is isostatic when G ¼ G0. This
theorem is very powerful in that it relies purely
on a combinatorial approach. Yet, in practical
terms, counting the number of edges in every
subgraph, which scale exponentially in the num-
ber of components (vertices and edges), is com-
putationally
cumbersome.
This
is
where
a
reformulation of Laman’s theorem implemented
via the pebble game will come in handy.
Unfortunately, the obvious, three-dimensional
extension of Laman’s theorem guaranteeing sufﬁ-
ciency is not possible, given several counterexam-
ples. However, Tay’s theorem (Tay 1984) is a
three-dimensional extension of Laman’s theorem
applied to body-bar graphs representing rigid bod-
ies, each with six degrees of freedom, connected by
bars. With such graphs, the counterexamples to the
three-dimensional version of Laman’s theorem do
not exist. In addition to Tay’s theorem, there exist
linear algebraic approaches to determining whether
or not a system is rigid, such as computing the rank
of the rigidity matrix (Pellegrino and Calladine
1986). These linear algebra approaches can be
implemented in any dimension, though computing
the rank of a matrix can also be computationally
intensive. We describe an application of the latter
and its relation to the pebble game below.
The Pebble Game
The basic notion behind the pebble game is to
apply Laman’s Theorem recursively by adding
434
Rigidity Percolation and Frictional Jamming

contact edges to the graph one at a time until we
achieve the maximal subset of independent edges
(Jacobs and Hendrickson 1997; Lee and Streinu
2008), i.e., all the contacts that can be added
without introducing redundancy. Keeping track
of which edges are independent or not is, there-
fore, the important part of the game. Once this
maximal subset has been identiﬁed, we can deter-
mine whether the graph is rigid or not. The pebble
game can also be used to decompose the graph
into rigid clusters.
We begin with an outline of the (2, 3) pebble
game, as shown for a sample frictionless packing
in Fig. 4. Here 2 denotes the degrees of freedom at
a vertex and 3 denotes the number of trivial global
zero modes. As shown in panel 2, we assign two
pebbles representing degrees of freedom to each
vertex and convert each contact into a constraint
edge.
We proceed by sequentially adding bonds to
the graph by moving pebbles from the vertices
onto the edges, thereby identifying these edges
as independent constraints. For a given edge, the
search for unassigned pebbles begins at the inci-
dent vertices, and once a pebble is found, we
assign a direction to the edge, away from the
vertex that is the origin of the pebble. Due to the
three global degrees of freedom, we need to exe-
cute a successful pebble search an additional three
times (for a total of four) before implementing the
ﬁrst pebble assignment to the edge. Expressed at a
set of rules, we have:
Rule 1. No more than two pebbles can be present
on any vertex.
Rule 2. A directed bond is accepted into the directed
network when at least a total of four pebbles are
present at the two vertices deﬁning the bond.
Eventually, the search for pebbles at the inci-
dent vertices will fall short. Then we execute a
depth-ﬁrst directed graph search for unassigned
pebbles at other vertices backwards along the
directed bonds that are already part of the
graph. Once enough pebbles are found at the
two ends of an edge, one of them is reassigned
to the edge, as before. Algorithmically, we pro-
ceed as follows:
Move A. A pebble found via depth-ﬁrst search
starting at vertex u is moved along the directed
path
while
reversing
the
arrows
until
reaching u.
Move B. If a directed bond is accepted into the
directed network via Rule 2, then the found
pebble is reassigned to an edge and is no longer
at play.
The (2, 3) pebble game is played until all
edges in the graph have been considered, as
shown in panel 3 of Fig. 4. This algorithm
ensures that the edges accepted into the directed
graph map to independent constraints. If there
are more than three pebbles that have not been
reassigned to an edge, then the graph is ﬂoppy.
contact
2 pebbles / particle
1 bond per contact
Cover bonds with pebbles
Leave 3 pebbles for 
global dof
leftover
pebbles
Decompose into rigid 
clusters and floppy bonds
2
3
4
1
redundant 
bond
Rigidity
Percolation
and
Frictional
Jamming,
Fig. 4 The (2, 3) pebble game. Step 1: A frictionless
packing is mapped to a graph with two pebbles on each
vertex. In step 3, the two pebbles per particle are placed on
bonds where possible using the pebble game, leaving left-
over pebbles and redundant bonds (purple). In step 4, the
graph is decomposed into rigid clusters (green) and ﬂoppy
bonds (gray)
Rigidity Percolation and Frictional Jamming
435

Conversely, if there are three pebbles left over
and bonds that have not been accepted into the
directed graph, then these correspond to redun-
dant edges (purple). Note that such edges are not
necessarily unique since they may change
depending on the order in which the edges are
considered. A graph can both be ﬂoppy and con-
tain redundant edges, as some pebbles, e.g., at
poorly connected vertices are inaccessible via the
directed search. The algorithm time for the peb-
ble game typically scales linearly with the num-
ber of edges in the graph.
We can also use the (2, 3) pebble game to
identify the rigid clusters, i.e., the subgraphs
that have 2u – 3 independent edges. Two vertices
u1 and u2 in G that are linked by bond b are
mutually rigid if a search for a free pebble at
both ends comes up short. Intuitively this is
because both are part of the same rigid cluster
with its exactly three global degrees of freedom,
so that no extra pebbles are available. However,
if an extra pebble can be found, they are either
part of two distinct rigid clusters, or one or both
are in ﬂoppy regions. Making use of the fact that
the directed graph pebble search necessarily tra-
verses the rigid cluster before coming up short,
we can quickly (at order of number of rigid
clusters) mark particles and bonds as mutually
rigid or ﬂoppy. If there is a redundant edge, the
search for a free pebble has failed, and it there-
fore necessarily belongs to a rigid cluster, and
more speciﬁcally the same cluster as the two
vertices at either end. One can also identify over-
constrained clusters in which redundant edges
are added, and which each correspond to a state
of self-stress. Interestingly, while the number of
redundant edges is independent of the way in
which the graph is “grown,” the labeling of the
redundant edges is not independent of this pro-
cess, i.e., a different ordering of edges tested
leads to different redundant edges.
The (2, 3) pebble game can be generalized to a
(k, l) pebble game. For instance, implementation
of Tay’s theorem translates to a total sum of seven
(k þ1) free pebbles at either end of the edge, and if
there are more than six (l) pebbles that have not
been reassigned to an edge, then the graph is
ﬂoppy.
Rigid Clusters and Nature of the Rigidity
Transition
Now that we can map out the rigid clusters in a
packing, we can circle back to the nuts and bolts
of rigidity percolation from a phase transition
perspective, which is the search for a spanning
rigid cluster and determining its properties. The
emergence of a spanning rigid cluster pinpoints
the location of the transition. Therefore, its size, or
number of bonds, serves as a reasonable order
parameter. The dimensionality of the spanning
rigid cluster at the transition location gives us
information about the nature of the transition. To
determine the dimensionality of the cluster, one
typically measures the number of bonds in the
spanning rigid cluster as a function of the system
length. In two-dimensions, if the size of the span-
ning rigid cluster scales as Ld f , where L is the
system length, and df ¼ 2, then the dimension of
the rigid cluster is simply the dimension of the
system and the rigid cluster is, therefore, bulky. In
contrast, if 1 < df < 2, then the rigid cluster is a
fractal. Should the dimension of the rigid cluster
be a fractal, this property points to a continuous
phase transition since its size is zero in the inﬁnite
system limit at the transition but nonzero as, for
example, the number of bonds are increased in the
system. On the other hand, if the spanning rigid
cluster is bulky at its onset, the transition is
discontinuous.
Interestingly, the nature of the rigidity transition
in network models of rigidity percolation can vary.
For instance, the rigidity transition in the central
force, randomly bond-diluted triangular lattice was
numerically found to be a continuous one with
df ¼
1.86  0.02 (Jacobs and Thorpe 1995,
1996). Meanwhile, Bethe lattices with no loops
are amenable to analytical treatment and demon-
strate that the spanning rigid cluster at the transition
is not fractal, or bulky (Moukarzel et al. 1997;
Moukarzel
and
Duxbury
1999;
Thorpe and
Stinchcombe 2014). To add to the complexity,
numerical simulations of three-dimensional lattices
with central-force interactions indicate a discontin-
uous rigidity transition as well, in contrast to the
two-dimensional case (Chubynsky and Thorpe
2007). Finally, central-force models with next-
neighbor springs can exhibit hybrid rigidity
436
Rigidity Percolation and Frictional Jamming

transitions with both continuous and discontinuous
features (Zhang et al. 2015) in terms of bulky
spanning rigid cluster but having at least one
diverging correlation length. This kind of hybrid
transition is not unique to rigidity percolation. It
has also been found in correlated percolation
models inspired by jamming in which the mechan-
ical constraints are encoded in the geometry (Harris
and Schwarz 2005; Schwarz et al. 2006; Jeng and
Schwarz 2007, 2010; Morone et al. 2019).
Turning now to packing problems, the contact
network is a graph from which the rigid clusters
can be constructed and, therefore, the spanning
rigid cluster can be identiﬁed. This has been done
for
frictionless
two-dimensional
packings
(derived from numerical simulations). In such
packings, there is no contact graph in the ﬂuid-
like phase of the packing (zero bulk modulus),
while at the transition from ﬂuid-like to solid-
like, a contact graph emerges. It turns out that
every bond in the contact graph (excluding rat-
tlers) is part of one system-spanning rigid cluster.
This means that the spanning rigid cluster is
bulky, or df ¼ 2 (see Fig. 5). And while the onset
of the rigid cluster is discontinuous, there is at
least one diverging correlation lengths in friction-
less jamming associated the divergence of the
isostaticity of the packing as one begins to add
contacts further into the solid-like phase of the
packing (Wyart et al. 2005). This divergence was
more recently explored explicitly using rigid clus-
ter analysis in which a smaller and smaller sub-
system is carved out until there is no spanning
rigid cluster (Goodrich et al. 2013).
Given that nature of the frictionless jamming
transition is that of a hybrid transition, we now
turn to the case with friction and ask how different
is the nature of the frictional jamming transition.
The Frictional Rigidity Transition
Frictional Constraint Counting
Now that we have discussed in detail constraint
counting in frictionless, or central-force, systems,
let us return to frictional systems with contacts
below and at the Coulomb threshold. Maxwell
constraint counting for frictional packings can be
generalized from Eq. 4 describing particles with
both translational and rotational degrees of free-
dom as follows. First, at ﬁnite friction coefﬁcient
m < 1, a number of contacts have reached the
Coulomb threshold and are now sliding. Therefore,
they will be unable to provide any tangential con-
straints on the motion, only a simple normal con-
straint. Let nm be the mean number of such sliding
Rigidity
Percolation
and
Frictional
Jamming,
Fig. 5 The frictionless rigidity transition on networks
derived
from
numerically
derived
frictionless,
two-
dimensional packings just below (left) at (middle) and
above (right) the frictionless jamming transition, as
detailed in (Ellenbroek et al. 2006). The data for this
image derives from a f ¼ 0.84 run of the frictionless
simulations in (Henkes et al. 2016). Gray bonds are ﬂoppy,
and colored bonds correspond to rigid clusters. The middle
network has exactly one overconstrained bond, i.e., it is
isostatic; the right network has 43 (nonunique) over-
constrained bonds. Leftover pebbles are either red (one)
or green (two); the isolated green dots correspond to rat-
tlers, i.e., isolated particles not participating in the packing.
There is no partial rigidity except for strictly microscopic
clusters, consistent with a mean-ﬁeld nature of the friction-
less rigidity transition in jamming
Rigidity Percolation and Frictional Jamming
437

contacts per particle. Then the total number of con-
straints is now only given by N dz/2  N(d  1)nm.
Requiring that the number of constraints be
sufﬁcient to constrain all degrees of freedom then
leads
to
the
generalized
isostaticity
criterion
(Shundyak et al. 2007; Henkes et al. 2010)
zm  d þ 1
ð
Þ þ 2 d  1
ð
Þ
d
nm  1
N d þ 1
ð
Þ:
ð6Þ
In particular, in two dimensions, we recover
zm  3 þ nm  3
N :
ð7Þ
We observe that as a function of nm, there is
now a line of generalized isostatic points that
increases from a lower limit of z1
iso ¼ 3 when
nm ¼ 0, i.e., the m ¼ 1 limit. For decreasing
friction coefﬁcient, we expect nm to increase: gen-
eralized isostatic counting provides for a mecha-
nism to explain the shifting value of z at the
jamming point with m – though empirically, the
curve z(m) obtained in simulations is monotonic,
but not unique (Shundyak et al. 2007; Silbert
2010; Henkes et al. 2010) (see Fig. 6). The very
carefully equilibrated simulations of (Somfai et al.
2007) are compatible with generalized isostaticity,
with simulations in the zero-pressure limit falling
along this line. Later analysis of the same data set
using normal modes (Henkes et al. 2010) con-
ﬁrmed that the density of states replicates a cross-
over scaling where the plateau emerges at
o 	 z  zm
iso


, consistent with the critical scal-
ings found in frictionless packings.
The Frictional Pebble Game
We now extend the generalization of frictionless
isostaticity to Laman’s theorem and the pebble
game to two-dimensional frictional packings. Con-
sider the sample frictional packing shown in Fig. 7
(panel 1). It consists of particles that are joined by
bonds which are either fully frictional (blue) or
sliding (orange). We can map this packing to a
graph constraint counting problem (panel 2):
Every particle has three degrees of freedom (two
rotations and one translation), and every frictional
contact provides two constraints, while a sliding
contact provides one constraint, represented by
double edges and single edges, respectively. As in
the frictionless case, we need to allow for three
global degrees of freedom as well. While there is
not currently a proof of Laman’s theorem for the
frictional case, the equivalent hypothesis is:
Hypothesis: The graph G containing u vertices
and e edges is inﬁnitesimally rigid if and only if
every subgraph G0, with its own u0 vertices and e0
edges, satisﬁes” e0  3u0  3.
We consequently play a (3, 3) pebble game to
investigate the rigidity of the graph. As shown in
panel 2, we associate three pebbles to each parti-
cles. We then add the bonds representing frictional
and sliding contacts to the graph one by one, using
a directed search of the graph for free pebbles. As
in the (2, 3) game, for every bond, we need to
locate four pebbles sequentially to make sure that
three
global
degrees
of
freedom
remain
unconstrained. In panel 3, we show the results of
Rigidity Percolation and
Frictional Jamming,
Fig. 6 Constraint counting
for frictional and
frictionless packings,
together with representative
examples of simulated
packings. “Rattler” particles
with less than two contacts
are colored gray and are
clearly visible in the m ¼ 10
simulation. The mean
contact number shown here
excludes rattlers
438
Rigidity Percolation and Frictional Jamming

the pebble game: For most bonds, a pebble (blue)
has been located and placed on the bond (black),
making it part of G. For redundant bonds (purple),
the addition process failed, signaling a local over-
constraint or equivalently the existence of a
(single) state of self-stress. At the same time,
more than global three pebbles can remain on
the graph. These leftover pebbles (red) are the
unconstrained degrees of freedom. In the last
stage of the process, we decompose G into rigid
and ﬂoppy regions using the algorithm introduced
in section “The Pebble Game.” Panel 4 shows an
example of such a decomposition, with one rigid
cluster (green) surrounded by ﬂoppy bonds.
Results for Lattices, Simulated, and
Experimental Packings
Now that we can identify frictional rigid clusters,
we summarize how frictional jamming emerges in
three situations through the lens of the frictional
rigidity transition: First in a simulation of soft
frictional particles in simple shear Lees-Edwards
boundary conditions, along the lines of section
“Numerical Models” (Henkes et al. 2016); second
in experimental packings of frictional disks driven
by pure shear (Liu et al. 2020); and third, in a
simpliﬁed frictional rigidity percolation lattice
model in which the transition is tuned by control-
ling the number of contacts (Liu et al. 2019).
In all three cases, we apply the (3, 3) pebble
game to graphs obtained from packings under
different conditions. Figure 8 shows the different
stages of the rigid cluster decomposition process
for a simulated packing near jamming: In panel a
is the contact network, with the normal force
magnitude shown as color and width; force
chains oriented in the principal stress direction
are clearly visible (diagonal for Lees-Edwards
boundary conditions, corresponding to simple
shear). Panel b shows which contacts are below
the Coulomb threshold (frictional contacts, in
black) and which contacts are sliding (red).
This simulation was run for small friction coef-
ﬁcient m ¼0.1, leading to a signiﬁcant fraction of
sliding contacts (nm ≈0.55 near jamming
(Henkes et al. 2016)). In panel c, the result
from the pebble game shows bonds that have
been successfully added to the graph (dark red)
as well as bonds that are overconstrained
(green);
thick
lines are
the
double bonds
corresponding to frictional contacts. Colored cir-
cles correspond to leftover pebbles on particles,
with three leftover pebbles in blue (prominent on
particles without contacts), but also particles
with two (green) and one (red) leftover pebble.
The existence of both overconstrained bonds and
leftover pebbles on the same graph already
shows that mean-ﬁeld constraint counting is
insufﬁcient. Finally, panel 4 shows the decom-
position of the packing into rigid subgraphs: in
this particular packing, there is one large span-
ning rigid cluster (black), together with two
other small rigid clusters (pink and green),
among a sea of ﬂoppy bonds (gray). This pack-
ing is partially rigid, showing that partial rigidity
is possible for frictional packings.
frictional contact
sliding contact
pebbles / particle
bonds / frictional contact
bond / sliding contact
Cover bonds with pebbles
Leave 3 pebbles for 
global dof
leftover
pebbles
Decompose into rigid 
clusters and floppy bonds
1
2
3
4
redundant 
bond
Rigidity
Percolation
and
Frictional
Jamming,
Fig. 7 The (3,3) pebble game. Step 1: A packing with
frictional and sliding contacts is mapped to a graph with
double and single bonds in step 2. In step 3, the three
pebbles per particle are placed on bonds where possible
using the pebble game, leaving leftover pebbles and redun-
dant bonds. In step 4, the graph is decomposed into rigid
clusters (green) and ﬂoppy bonds (gray)
Rigidity Percolation and Frictional Jamming
439

Figure 9 shows the rigid cluster decomposition
for an experimental packing. The observation of a
partially rigid system also emerges for the exper-
imental system of (Liu et al. 2020). Figure 9a
shows the photoelastic experimental setup. The
air ﬂow from the bottom minimizes friction with
the
substrate,
allowing
for
a
truly
two-
dimensional system. Panel b shows the photo-
elastic response of the packing captured through
cross-polarizers; the force chains are clearly visi-
ble. Panel d show the decomposition of this same
packing into rigid clusters: as in the simulation, it
is apparent that the packing is partially rigid, with
two substantial rigid clusters and a smattering of
small ones separated by ﬂoppy bonds.
Panel c represents the results of a complemen-
tary approach to frictional rigidity. Following the
Hertz-Mindlin or Cundall-Strack contact models,
the incremental increase of tangential force in
response to tangential sliding can be mapped to a
harmonic potential for very small displacements,
i.e., within the range of linear response. This
effective frictional potential for contact ij in the
same geometry as Fig. 2 can be written as (Somfai
et al. 2007; Henkes et al. 2010; Liu et al. 2020):
Vij ¼ 1
2 Kn dr  bn
ð
Þ2 ¼
f n
j rij j dr bt

2 þ dV f
eff


,
ð8Þ
where the last term is the effective frictional
potential
for
an
inﬁnitesimal
displacement,
V f
eff ¼ Ktdt2 for a frictional contact, and V f
eff ¼
mf ndt for a sliding contact. As in Fig. 2 and
Eq.
1,
we
have
deﬁned
dt ¼ dr btij 
Ridyi þ R jdy j


. Using this potential, one can
deﬁne a dynamical matrix for inﬁnitesimal trans-
lations and rotations and obtain the normal modes
(eigenvectors) and their eigenvalues. A  oppy
mode corresponds to an eigenvector with zero
eigenvalue, while a displacement involving con-
straint motions will cost energy. One can deﬁne a
particle as rigid within this context if it does not
participate signiﬁcantly in any of the ﬂoppy
modes in this system. Rigid regions then consist
of these particles and the contacts that link them.
Figure 9c shows the bonds that make up the rigid
regions of the packing. It is apparent that they are
strongly correlated with the rigid clusters of the
pebble game, which can be quantitatively con-
ﬁrmed using the adjusted rand index (Liu
et al. 2020).
To provide context for frictional rigidity per-
colation, Liu et al. (2019) created a lattice model
to study the transition in detail. It consists of a
honeycomb lattice with second neighbor bonds
that have been randomly deleted, giving a mean
contact number of z ¼ 3.5, where bonds are either
frictional or sliding with probability q, see
Fig. 10a. As in standard percolation measures,
adding bonds to the graph with probability
p then either produces a percolated system or
not. Figure 10 shows a schematic of the lattice
model with frictional and sliding contacts together
a
b
c
d
Rigidity
Percolation
and
Frictional
Jamming,
Fig. 8 Decomposition of a simulated frictional packing
into rigid clusters (Henkes et al. 2016). (a) Contact forces,
(b) frictional (black) and sliding (red) bonds, (c) after the
pebble game, including covered bonds (red), redundant
bonds (green), and leftover pebbles (three in blue, two in
green, and one in red). (d) Decomposition into rigid clus-
ters (black and colored) as well as ﬂoppy bonds (gray)
440
Rigidity Percolation and Frictional Jamming

with the rigid cluster decomposition with increas-
ing p. Here, as in the two earlier cases, one
observes partial rigidity, i.e., regions of particles
in contact but not part of a spanning rigid cluster,
regions of particles in contact and part of a span-
ning rigid cluster, and a boundary between the
two.
The next step for frictional rigidity percolation
is to accurately determine the order of the transi-
tion and its critical exponents. Figure 11a shows
the probability of a spanning rigid cluster for the
numerically derived packings. The probability of
spanning approaches a step function as a function
of the distance to the generalized isostaticity
line dz ¼ z  (3 þ nm) with growing particle
number N. The transition itself is at approximately
dz ¼ 0.2  0.05, clearly below the mean ﬁeld
counting prediction z ¼ 3 þ nm. Figure 11d shows
the corresponding cluster size distribution, using
the pressure as a proxy for distance to jamming.
This distribution in the transition region 4 
105 < p < 2  101 is broad on a log-log
scale, consistent with a second-order phase tran-
sition. Contrasting this result with the frictionless
case, consistent with the results of Ellenbroek
et al. (2006) (see Fig. 5), repeating the simulation
and analysis for frictionless particles leads to a
mean-ﬁeld like transition (Henkes et al. 2016):
there is a gap in the cluster size distribution, with
packings having either a handful of very small
rigid clusters or a single spanning rigid cluster.
With the exception of isolated rattler particles, the
spanning rigid cluster encompasses the full
packing.
Figure 11b show the probability of ﬁnding a
spanning rigid cluster in the experiment. The tran-
sition is again signiﬁcantly below the mean-ﬁeld
point z ¼ 3 (the fraction of sliding contacts is
below 1% in the experiment), with zrigid ¼
2.4  0.1. Part of the discrepancy with other
experimental measures of the transition point
(Majmudar and Behringer 2005; Majmudar et al.
2007) is explained by this analysis not removing
rattlers, as the ﬂoppy regions are an integral part
a
b
c
d
Rigidity
Percolation
and
Frictional
Jamming,
Fig. 9 Decomposition of experimental frictional packings
into rigid clusters and rigid regions (Liu et al. 2020). (a)
Experimental setup, (b) photoelastic response showing
forces in the packing, (c) rigid region decomposition
using the dynamical matrix, and (d) decomposition into
rigid clusters (colors) as well as ﬂoppy bonds (gray)
Rigidity Percolation and Frictional Jamming, Fig. 10 Rigid clusters of the (3, 3) pebble game for the lattice models
of (Liu et al. 2019) as shown on the left, below, at, and above the transition
Rigidity Percolation and Frictional Jamming
441

of the packing. The cluster size distribution
(panel e), obtained on limited statistics, is consis-
tent with a continuous distribution, strengthening
the evidence of a second order rigidity transition.
Figure 11c shows the probability of ﬁnding a
spanning rigid cluster for the lattice model as a
function of p and increasing system size, showing
clear evidence of a phase transition for ﬁnite p.
This is qualitatively consistent with the simulation
(panel a) and experimental (panel b) transition
curves. Panel f shows cluster size distributions
below (blue) at (red) and above (yellow) the tran-
sition. There is a power law distribution in cluster
size at the transition, cut off only by the system
size, indicating a second order rigidity transition.
Figure 10 shows examples of rigid clusters below,
at and above the rigidity transition. They strongly
resemble their simulated and experimental coun-
terparts, with a sea of very small rigid clusters
giving way to a rapidly appearing spanning rigid
cluster that ﬁlls a substantial fraction of the
system.
For the lattice model, careful computation of
the critical exponents of the system revealed that
frictional rigidity percolation (the (3, 3) game) is
in a separate universality class from standard
rigidity percolation (the (2, 3) game) on the same
lattice (Liu et al. 2019). The authors also extended
the careful renormalization ﬂow calculations for
standard rigidity percolation on hierarchical lat-
tices of (Thorpe and Stinchcombe 2014) to fric-
tional rigidity percolation, again ﬁnding a separate
universality class.
Consistent with the rapid appearance of the
spanning rigid cluster, the fractal dimension of
the spanning cluster is just below 2. Differences
are apparent especially in the cluster size distribu-
tion exponent t which falls systematically below
2. This is unusual, since standard arguments in
percolation predict t > 2, which is also observed
in standard rigidity percolation. The difference
here is the nonadditive nature of rigid clusters
(see Fig. 12): Adding only one bond can merge
several disconnected rigid clusters into one giant
cluster, with sets of ﬂoppy bonds suddenly
becoming rigid due to the nonlocal nature of con-
straint counting. The narrow points of the span-
ning rigid cluster are dominated by several types
of hinge or arch structure (panels a–c), allowing
one or a pair of contacts between two particles to
s
P(s)
z-(3+nm)
0.0
0.2
0.0
0.2
0.4
-0.4 -0.2
-0.6
0.6
0.8
1.0
a
b
c
d
e
f
Rigidity
Percolation
and
Frictional
Jamming,
Fig. 11 Rigid cluster spanning probabilities (top row)
and cluster size distributions (bottom row) for simulations
(Henkes et al. 2016) (left), experiment (Liu et al. 2020)
(middle) and lattice model (Liu et al. 2019) (right)
442
Rigidity Percolation and Frictional Jamming

transmit rigidity. This mechanism is not possible
for the (2, 3) pebble game, i.e., in frictionless
rigidity percolation. It provides more options for
rigid arches, and ﬂoppy holes, giving a potential
explanation for why frictionless rigid clusters on
graphs derived from granular packings are always
space-ﬁlling (see Fig. 5).
At this point it should be said that the corre-
spondence between rigidity and the (3, 3) pebble
game is likely not exact: Lester et al. (Lester and
Li 2018) tested the (3, 3) pebble game against the
rank of the rigidity matrix on random planar
graphs and found a subset of graphs where the
two measures differ. The most prominent exam-
ples are gearing motions in loops of an even
number of particles, where the leftover rotational
degree of freedom is unrecognized by the pebble
game. Since realistic packings almost always frus-
trate such gearing motion, the effect of such
exceptions is likely limited in practice.
One is then led to ask whether or not these rigid
clusters correlate with other physical properties of
the packing. A measure of stress does produce a
correlation between rigid clusters and high-stress
regions: Fig. 13a (from the simulations of (Henkes
et al. 2016) shows the mean normal force magni-
tude divided by the virial pressure of a given, both
inside rigid clusters (red) as well as outside rigid
clusters (green). Below the transition (indicated by
the black line of the fraction of the system that
belongs to a rigid cluster), both regions equally
support what little stress there is in the packing,
indicating that rigid clusters do not play a special
mechanical role; separately the pressure in these
unjammed packings strongly increases with the
dissipation coefﬁcient ζ, indicating that the pres-
sure is largely due to dissipative forces. However,
as the transition is crossed, rigid clusters progres-
sively take more of the overall load, while the
forces within ﬂoppy regions sharply decreases.
Well above the transition, the ﬂoppy regions
morph into individual contact-less rattler particles.
In experiments (Liu et al. 2020), a very similar
effect is apparent. Figure 13b shows the virial
pressure inside and outside rigid clusters normal-
ized by the packing virial pressure. Here, the
pressure inside rigid clusters always exceeds the
pressure in ﬂoppy regions. As in the simulation,
that pressure in ﬂoppy regions is rapidly dropping
as the rigidity transition is crossed. In contrast, the
Rigidity Percolation and
Frictional Jamming,
Fig. 12 Mechanisms of
rigid cluster mergers using
hinges, from (Liu et al.
2019)
Rigidity Percolation and Frictional Jamming
443

pressure in rigid clusters far exceeds the mean
pressure at low contact number, potentially due
to a different mechanism of dissipation in the
packings under quasistatic shear steps or due to
boundary effects.
Future Directions
We now have new understanding of the nature of
the frictional jamming transition via rigid clusters,
which correlate both with high stress regions and
with rigid regions obtained from a dynamical
matrix approach with an effective potential for
friction. The rigid clusters have a broad range of
sizes near the frictional jamming transition and are
ﬁlled with regions of ﬂoppy particles despite
being part of the packing. Such structures resem-
ble those found in a continuous phase transition as
is found in connectivity percolation and some
models of rigidity percolation and is different
from frictionless jamming and other models of
correlated and rigidity percolation. How does
this rigid cluster approach compare with more
traditional approaches to frictional jamming?
What remains unclear so far is the precise relation
between frictional rigidity percolation and other
aspects of frictional jamming, in particular, shear
jamming. Both transitions, as measured by rigid
clusters and by strong force network percolation,
respectively, occur in the same set of packings
(Liu et al. 2020). There is, however, no substantial
correlation between the shear jamming measure of
contacts with above average force and the rigid
clusters, or rigid regions, in the experiment (Liu
et al. 2020). In contrast, in simulations that start
from frictionless packings and then introduce nor-
mal and tangential forces compatible with fric-
tion, Vinutha et al. (Vinutha and Sastry 2016,
2019) found strong correlations between force
chains and rigid clusters. This discrepancy may
ultimately be resolved by exploring the differ-
ences between how the packings are generated.
If indeed, there is ultimately not a strong corre-
spondence between rigid clusters and force chains
for some generically generated class of frictional
packings, then one would have to tease apart the
role of each characteristic and presumably their
interplay. Determining the interplay between
rigidity, forces, and geometry in frictional pack-
ings is a necessary ongoing task in the granular
community.
There are clearly other rigidity transitions that
have similarities to the onset of frictional rigidity.
In addition to frictionless jamming which we have
already discussed in the main text, these include
shear thickening in dense suspensions and the
rigidity of gels. In shear thickening, lubrication
between contacts initially leads to rheology
appropriate to frictionless particles in a ﬂuid, but
0.0
0.2
-0.2
1.0
-
3.0
1.0
-0.3
0.0
0.2
0.4
0.6
0.8
1.0
1.2
fnormal/pressure
z-(3+nm)
fraction
inside
outside
a
b
Rigidity
Percolation
and
Frictional
Jamming,
Fig. 13 Correlation between rigidity and pressure in sim-
ulations (left) and experiments (right). (a) Rigid cluster
fraction (black) together with the normal force scaled by
the pressure of a packing inside (red) and outside (green)
rigid clusters (Henkes et al. 2016). (b) Pressure scaled by
the packing pressure inside (blue) and outside (red) of rigid
clusters, together with the rigid fraction for experimental
packings (Liu et al. 2020)
444
Rigidity Percolation and Frictional Jamming

as the strain rate increases, frictional contacts
begin to form. Since the frictional jamming tran-
sition is at lower packing fraction, the system
moves at least partially into a jammed state, lead-
ing to a sudden, enormous increase in the viscos-
ity,
the
eponymous
shear
thickening.
This
transition has been investigated theoretically
(Wyart and Cates 2014), numerically, and exper-
imentally, but there is an incomplete picture of the
local structure in such suspensions, and rigidity
percolation techniques have so far not been
applied to these systems. We expect that the dif-
ferent nature of the rigidity transition in frictional
and frictionless systems will bear on the details of
the shear thickening transition.
In gels, the jamming transition has long known
to be history dependent, with strikingly different
internal structures appearing depending on the
strain history of the sample (Trappe et al. 2001).
Recent work (Koeze and Tighe 2018; Zhang et al.
2019) has mapped out the rigid structures in these
gels using the (2, 3) pebble game, ﬁnding a second
order transition. This ﬁnding adds to the emerging
notion that the mean ﬁeld frictionless rigidity
transition is the unusual case, not the second
order frictional rigidity transition.
We have so far focused on particle packings.
However, related questions arise within the
domain of biological tissues: Epithelial cell sheets
are made of living, actively driven particles that
interact to produce conﬂuent tissues with novel
soft active mechanics (Nagai and Honda 2001;
Farhadifar et al. 2007; Fletcher et al. 2014). Such
tissues closely resemble a cobblestone pavement,
with a single layer of tightly packed cells that
approximate a polygonal tiling. One set of theo-
retical approaches describing such a tissue is
known as vertex models (Nagai and Honda
2001; Farhadifar et al. 2007; Fletcher et al.
2014), where the tissue is mapped to an energy
functional on the polygonal tiling. In such models,
there exists a density-independent rigidity transi-
tion as a preferred shape parameter is tuned
(Bi et al. 2015). One way to understand this tran-
sition is in the context of energy barriers to T1
transitions, or local cellular rearrangements. In
addition, constraint counting methods have also
been applied to understand how the ﬂuidization
happens as the coordination number of the graph
changes (Yan and Bi 2019). A further generaliza-
tion of rigidity percolation and the pebble game to
these systems will be helpful. In these same sys-
tems and more generally in spring networks, the
question of rigidity at nonlinear level is also being
raised: Tensegrity or rigidity through states of
self-stress is important for these systems (Merkel
et al. 2019), while the purely repulsive forces in
the granular systems that we have considered
above make those states rare at best.
Finally, this approach calls for more mathemat-
ical endeavors, such as the task of making fric-
tional constraint counting more rigorous. While
comparison with rigid regions gives us conﬁdence
in the frictional pebble game, particularly near the
transition, it does not yet take into account the
gear phenomenon that odd cycles/loops are frus-
trated, i.e., there is no gear motion. With such
mathematical endeavors, we hope that the bond
between the mathematicians studying rigidity the-
ory and the physicists studying rigidity percola-
tion will become stronger such that the origins of
rigidity in systems ranging from particle packings
to spring networks to vertex models will become
more transparent.
Bibliography
Alberts B, Johnson A, Lewis J, Morgan D, Raff M, Keith
Roberts PW et al (2018) Molecular biology of the cell.
Garland Science, Taylor and Francis Group
Allen MP, Tildesley DJ (2017) Computer simulation of
liquids. Oxford University Press
Amon A, Born P, Daniels KE, Dijksman JA, Huang K,
Parker D, Schröter M, Stannarius R, Wierschem
A (2017) Preface: focus on imaging methods in granu-
lar physics. Rev Sci Instrum 88:051701
Baity-Jesi M, Goodrich CP, Liu AJ, Nagel SR, Sethna JP
(2017) Emergent so(3) symmetry of the frictionless
shear jamming transition. J Stat Phys 167:735
Bannerman MN, Sargant R, Lue L (2011) Dynamo: a free
o(n) general event-driven molecular dynamics simu-
lator. J Comput Chem 32(15):3329–3338
Barber J, Ciavarella M (2000) Contact mechanics. Int
J Solids Struct 37(1–2):29–43
Bassett DS, Owens ET, Porter MA, Manning ML, Daniels
KE (2015) Extraction of force-chain network architec-
ture in granular materials using community detection.
Soft Matter 11:2731–2744
Bell N, Yu Y, Mucha PJ (2005) Particle-based simulation
of granular materials. In: Proceedings of the 2005 ACM
Rigidity Percolation and Frictional Jamming
445

SIGGRAPH/Eurographics symposium on Computer
animation, pp 77–86
Bi D, Zhang J, Chakraborty B, Behringer RP (2011) Jam-
ming by shear. Nature 480(7377):355–358
Bi D, Lopez JH, Schwarz JM, Manning ML (2015) A
density-independent rigidity transition in biological tis-
sues. Nat Phys 11(12):1074–1079
Blumenfeld R, Edwards SF (2009) On granular stress
statistics: compactivity, angoricity, and some open
issues. J Phys Chem B 113(12):3981–3987
Bogdan T, Kollmer JE, Teiser J, Kruss M, Wurm G (2020)
Laboratory impact splash experiments to simulate
asteroid surfaces. Icarus 341:113646
Brown E, Jaeger HM (2009) Dynamic jamming point for
shear thickening suspensions. Phys Rev Lett 103(8):
086001
Brujić J, Edwards SF, Grinev DV, Hopkinson I, Brujić D,
Makse HA (2003) 3d bulk measurements of the force
distribution in a compressed emulsion system. Faraday
Discuss 123:207–220
Cates M, Wittmer J, Bouchaud JP, Claudin P (1998) Jam-
ming, force chains, and fragile matter. Phys Rev Lett
81(9):1841
Chubynsky MV, Thorpe MF (2007) Algorithms for three-
dimensional rigidity analysis and a ﬁrst-order percola-
tion transition. Phys Rev E 76:041135
Ciamarra MP, Nicodemi M, Coniglio A (2010) Recent
results on the jamming phase diagram. Soft Matter
6(13):2871–2874
Ciamarra MP, Pastore R, Nicodemi M, Coniglio A (2011)
Jamming phase diagram for frictional particles. Phys
Rev E 84(4):041308
Ciavarella M, Joe J, Papangelo A, Barber J (2019) The role
of adhesion in contact mechanics. J R Soc Interface
16(151):20180738
Clavaud C, Bérut A, Metzger B, Forterre Y (2017) Reveal-
ing the frictional transition in shear-thickening suspen-
sions. Proc Natl Acad Sci 114(20):5147–5152
Clusel M, Corwin EI, Siemens AO, Brujić J (2009) A
‘granocentric’ model for random packing of jammed
emulsions. Nature 460(7255):611–615
Coussot P (2005) Rheometry of pastes, suspensions, and
granular materials: applications in industry and envi-
ronment. John Wiley & Sons
Cundall P, Strack ODL (1979) No accessa discrete numer-
ical model for granular assemblies. Geotechnique
29:47–65
Daerr A, Douady S (1999) Two types of avalanche behav-
iour in granular media. Nature 399(6733):241–243
Dagois-Bohy S, Tighe BP, Simon J, Henkes S, van Hecke
M (2012) Soft-sphere packings at ﬁnite pressure but
unstable to shear. Phys Rev Lett 109:095703
Daniels KE, Behringer RP (2005) Hysteresis and competi-
tion between disorder and crystallization in sheared and
vibrated granular ﬂow. Phys Rev Lett 94(16):168001
Daniels KE, Kollmer JE, Puckett JG (2017) Photoelastic
force measurements in granular materials. Rev Sci
Instrum 88(5):051808
DeGiuli E, Wyart M (2017) Friction law and hysteresis
in granular materials. Proc Natl Acad Sci 114(35):
9284–9289
Dijksman JA, Rietz F, Lőrincz KA, van Hecke M, Losert
W (2012) Invited article: Refractive index matched
scanning of dense granular materials. Rev Sci Instrum
83(1):011301
Duran J (2012) Sands, powders, and grains: an introduc-
tion to the physics of granular materials. Springer Sci-
ence & Business Media
Edwards SF, Oakeshott R (1989) Theory of powders. Phys
A Stat Mech Appl 157(3):1080–1090
Ellenbroek WG, Somfai E, van Hecke M, van Saarloos
W (2006) Critical scaling in linear response of friction-
less granular packings near jamming. Phys Rev Lett 97:
258001
Farhadifar R, Röper JC, Aigouy B, Eaton S, Jülicher
F (2007) The inﬂuence of cell mechanics, cell-cell
interactions, and proliferation on epithelial packing.
Curr Biol 17(24):2095–2104
Fernandez-Nieves A, Puertas AM (2016) Fluids, colloids,
and soft materials: an introduction to soft matter phys-
ics, vol 7. Wiley Online Library
Fletcher AG, Osterﬁeld M, Baker RE, Shvartsman SY
(2014) Vertex models of epithelial morphogenesis.
Biophys J 106(11):2291–2304
Forterre Y, Pouliquen O (2008) Flows of dense granular
media. Annu Rev Fluid Mech 40:1–24
Gardel E, Sitaridou E, Facto K, Keene E, Hattam K,
Easwar N, Menon N (2009) Dynamical ﬂuctuations in
dense granular ﬂows. Philos Trans R Soc A Math Phys
Eng Sci 367(1909):5109–5121
Goodrich CP, Ellenbroek W, Liu AJ (2013) Stability of
jammed packings i: the rigidity length scale. Soft Mat-
ter 9:10993–10999
Goodrich CP, Dagois-Bohy S, Tighe BP, van Hecke M, Liu
AJ, Nagel SR (2014) Jamming in ﬁnite systems: Sta-
bility, anisotropy, ﬂuctuations, and scaling. Phys Rev
E 90:022138
Grob M, Heussinger C, Zippelius A (2014) Jamming of
frictional particles: A nonequilibrium ﬁrst-order phase
transition. Phys Rev E 89(5):050201
Harris AB, Schwarz JM (2005) 1d expansion for k-core
percolation. Phys Rev E 72:046123
Hatano T (2007) Power-law friction in closely packed
granular materials. Phys Rev E 75(6):060301
Henkes S, van Hecke M, van Saarloos W (2010) Crit-
ical jamming of frictional grains in the generalized
isostaticity picture. EPL (Europhys Lett) 90(1):
14003
Henkes S, Quint DA, Fily Y, Schwarz JM (2016) Rigid
Cluster Decomposition Reveals Criticality in Frictional
Jamming. Phys Rev Lett 116(2):028301
Hertz H (1881) On the contact of elastic solids. Z Reine
Angew Mathematik 92:156–171
Heussinger C (2013) Shear thickening in granular suspen-
sions: Interparticle friction and dynamically correlated
clusters. Phys Rev E 88(5):050201
446
Rigidity Percolation and Frictional Jamming

Jacobs DJ, Hendrickson B (1997) An Algorithm for Two-
Dimensional Rigidity Percolation: The Pebble Game.
J Comput Phys 137(2):346–365
Jacobs DJ, Thorpe MF (1995) Generic rigidity percolation:
The pebble game. Phys Rev Lett 75:4051
Jacobs DJ, Thorpe MF (1996) Generic rigidity percolation
in two dimensions. Phys Rev E 53:3682
Jaeger HM, Nagel SR, Behringer RP (1996) Granular
solids, liquids, and gases. Rev Mod Phys 68(4):
1259
Jean M (1999) The non-smooth contact dynamics method.
Comput Methods Appl Mech Eng 177(3–4):235–257
Jeng M, Schwarz JM (2007) Comment on “jamming per-
colation and glass transitions in lattice models”. Phys
Rev Lett 98:129601
Jeng M, Schwarz JM (2010) Force-balance percolation.
Phys Rev E 81:011134
Johnson KL (1982) One hundred years of hertz contact.
Proc Inst Mech Eng 196(1):363–378
Johnson KL (1987) Contact mechanics. Cambridge Uni-
versity Press
Kleinhans M, Markies H, De Vet S, Postema F et al
(2011) Static and dynamic angles of repose in loose
granular materials under reduced gravity. J Geophys
Res Planets 116(E11):188002
Koeze DJ, Tighe BP (2018) Sticky matters: Jamming and
rigid cluster statistics with attractive particle interac-
tions. Phys Rev Lett 121:188002
Laman G (1970) On graphs and rigidity of plane skeletal
structures. Journal of Engineering Mathematics. J Eng
Math 4(4):331–340
Lee A, Streinu I (2008) Pebble game algorithms and sparse
graphs. Discret Math 308:1425–1437
Lester DR, Li R (2018) The frictional pebble game: An
algorithm for rigidity percolation in saturated frictional
assemblies. J Comput Phys 369:225–236
Liu AJ, Nagel SR (1998) Jamming is not just cool any
more. Nature 396(6706):21–22
Liu CH, Nagel SR, Schecter DA, Coppersmith SN,
Majumdar S, Narayan O, Witten TA (1995) Force
ﬂuctuations in bead packs. Science 269(5223):
513–515
Liu K, Henkes S, Schwarz JM (2019) Frictional Rigidity
Percolation: A New Universality Class and Its Super-
universal Connections through Minimal Rigidity Pro-
liferation. Phys Rev X 9(2):021006
Liu K, Kollmer JE, Daniels KE, Schwarz J, Henkes
S (2020) Sponge-like rigid structures in frictional gran-
ular packings. arXiv preprint arXiv:2006.00557
Majmudar TS, Behringer RP (2005) Contact force mea-
surements and stress-induced anisotropy in granular
materials. Nature 435(7045):1079–1082
Majmudar T, Sperl M, Luding S, Behringer RP (2007)
Jamming transition in granular systems. Phys Rev
Lett 98(5):058001
Maxwell JC (1864) L. on the calculation of the equilibrium
and stiffness of frames. The London, Edinburgh, and
Dublin Philos Mag J Sci 27(182):294–299
Maxwell JC (1870) I.—on reciprocal ﬁgures, frames, and
diagrams of forces. Earth Environ Sci Trans R Soc
Edinb 26(1):1–40
Merkel M, Baumgarten K, Tighe BP, Manning ML
(2019) A minimal-length approach uniﬁes rigidity in
underconstrained
materials.
Proc
Natl
Acad
Sci
116(14):6560–6568
Mindlin RD (1949) Compliance of elastic bodies in con-
tact. J Appl Mech ASME 16:259–268
Morone F, Burleson-Lesser K, Vinutha H, Sastry S,
Makse HA (2019) The jamming transition is a k-core
percolation transition. Phys A Stat Mech Appl
516:172–177
Moukarzel C, Duxbury PM (1999) Comparison of rigidity
and connectivity percolation in two dimensions. Phys
Rev E 59:2614–2622
Moukarzel C, Duxbury PM, Leath PL (1997) First-order
rigidity on cayley trees. Phys Rev E 55:5800–5811
Mueth DM, Jaeger HM, Nagel SR (1998) Force distribu-
tion in a granular medium. Phys Rev E 57(3):3164
Müser
MH,
Dapp
WB,
Bugnicourt
R,
Sainsot
P,
Lesaffre N, Lubrecht TA, Persson BN, Harris K,
Bennett A, Schulze K et al (2017) Meeting the
contactmechanics challenge. Tribol Lett 65(4):1–18
Nagai T, Honda H (2001) A dynamic cell model for the
formation of epithelial tissues. Philos Mag B 81(7):
699–719
Ohern CS, Silbert LE, Liu AJ, Nagel SR (2003) Jamming
at zero temperature and zero applied stress: The epit-
ome of disorder. Phys Rev E 68(1):011306
Olson Reichhardt CJ, Reichhardt C (2010) Fluctua-
tions, jamming, and yielding for a driven probe
particle in disordered disk assemblies. Phys Rev
E 82:051306
Onoda GY, Liniger EG (1990) Random loose packings of
uniform spheres and the dilatancy onset. Phys Rev Lett
64(22):2727
Pellegrino S, Calladine CR (1986) Matrix analysis of stat-
ically and kinematically indeterminate frameworks. Int
J Solids Struct 22:409
Peters J, Muthuswamy M, Wibowo J, Tordesillas A (2005)
Characterization of force chains in granular material.
Phys Rev E 72(4):041307
Peters IR, Majumdar S, Jaeger HM (2016) Direct observa-
tion of dynamic shear jamming in dense suspensions.
Nature 532(7598):214–217
Puckett
JG,
Daniels
KE
(2013)
Equilibrating
Temperaturelike Variables in Jammed Granular Sub-
systems. Phys Rev Lett 110(5):058001
Pudasaini SP, Hutter K (2007) Avalanche dynamics:
dynamics of rapid ﬂows of dense granular avalanches.
Springer Science & Business Media
Radjai F, Richefeu V (2009) Contact dynamics as a non-
smooth discrete element method. Mech Mater 41(6):
715–728
Radjai F, Jean M, Moreau JJ, Roux S (1996) Force distri-
butions in dense twodimensional granular systems.
Phys Rev Lett 77(2):274
Rigidity Percolation and Frictional Jamming
447

Radjai F, Wolf DE, Jean M, Moreau JJ (1998) Bimodal
character of stress transmission in granular packings.
Phys Rev Lett 80(1):61
Royer JR, Blair DL, Hudson SD (2016) Rheological sig-
nature of frictional interactions in shear thickening
suspensions. Phys Rev Lett 116(18):188301
Schwarz JM, Liu AJ, Chayes LQ (2006) The onset of
jamming as the sudden emergence of an inﬁnitek-core
cluster. Europhys Lett (EPL) 73(4):560–566
Shundyak K, van Hecke M, van Saarloos W (2007) Force
mobilization and generalized isostaticity in jammed
packings of frictional grains. Phys Rev E 75(1):010301
Silbert LE (2010) Jamming of frictional spheres and ran-
dom loose packing. Soft Matter 6(13):2918–2924
Silbert LE, Ertaş D, Grest GS, Halsey TC, Levine D,
Plimpton SJ (2001) Granular ﬂow down an inclined
plane: Bagnold scaling and rheology. Phys Rev
E 64(5):051302
Silbert LE, Ertaş D, Grest GS, Halsey TC, Levine D (2002)
Geometry of frictionless and frictional sphere packings.
Phys Rev E 65(3):031304
Somfai E, van Hecke M, Ellenbroek WG, Shundyak K, van
Saarloos W (2007) Critical and noncritical jamming of
frictional grains. Phys Rev E 75(2):020301
Staron L, Radjai F (2005) Friction versus texture at the
approach of a granular avalanche. Phys Rev E 72(4):
041308
Stauffer D, Aharony A (2018) Introduction to percolation
theory. CRC Press
Tay TS (1984) Rigidity of multi-graphs i. linking rigid
bodies in n-space. J Comb Theory Ser B 36:95–112
Tay TS (1993) A new proof of laman’s theorem. Graphs
and Combinatorics 9(2–4):365–370
Thorpe M, Stinchcombe R (2014) Two exactly soluble
models of rigidity percolation. Philos Trans R Soc
A Math Phys Eng Sci 372(2008):20120038
Tighe BP, Snoeijer JH, Vlugt TJ, van Hecke M (2010) The
force network ensemble for granular packings. Soft
Matter 6(13):2908–2917
Tordesillas A, Walker DM, Lin Q (2010) Force cycles and
force chains. Phys Rev E 81:011302
Trappe V, Prasad L, Cipellett V, Segra PN, Weitz DA
(2001) Jamming phase diagram for attractive particles.
Nature 411:772
van Hecke M (2009) Jamming of soft particles: geometry,
mechanics, scaling and isostaticity. J Phys Condens
Matter 22(3):033101
Vinutha H, Sastry S (2016) Disentangling the role of struc-
ture and friction in shear jamming. Nat Phys 12(6):
578–583
Vinutha HA, Sastry S (2019) Force networks and jamming
in shear-deformed sphere packings. Phys Rev E 99:
012123
Walker DM, Tordesillas A, Thornton C, Behringer RP,
Zhang J, Peters JF (2011) Percolating contact subnet-
works on the edge of isostaticity. Granul Matter 13(3):
233–240
Wang D, Ren J, Dijksman JA, Zheng H, Behringer RP
(2018) Microscopic origins of shear jamming for
2d frictional grains. Phys Rev Lett 120(20):208004
Weis S, Schröter M (2017) Analyzing x-ray tomogra-
phies of granular packings. Rev Sci Instrum 88(5):
051809
Wriggers P, Nackenhorst U (2006) Analysis and simulation
of contact problems, vol. 1. Springer
Wyart M, Cates M (2014) Discontinuous shear thickening
without inertia in dense nonbrownian suspensions.
Phys Rev Lett 112(9):098302
Wyart M, Nagel SR, Witten TA (2005) Geometric origin of
excess low-frequency vibrational modes in weakly
connected amorphous solids. EPL (Europhys Lett)
72(3):486
Xu SY, Illa X, Schwarz JM (2010) Force network analysis
of a jammed solid. arXiv preprint arXiv:1008.4568
Yan L, Bi D (2019) Multicellular rosettes drive ﬂuid-
solid
transition
in
epithelial
tissues.
Phys
Rev
X 9(1):011029
Zhang L, Rocklin DZ, Chen BG, Mao X (2015) Rigid-
ity percolation by next-nearestneighbor bonds on
generic and regular isostatic lattices. Phys Rev
E 91:032124
Zhang S, Zhang L, Bouzid M, Rocklin DZ, Del Gado E,
Mao X (2019) Correlated rigidity percolation and col-
loidal gels. Phys Rev Lett 123(5):058001
Zhao Y, Barés J, Zheng H, Socolar JE, Behringer RP et al
(2019) Shear-jammed, fragile, and steady states in
homogeneously strained granular materials. Phys Rev
Lett 123(15):158001
448
Rigidity Percolation and Frictional Jamming

Cell Biology: Networks,
Regulation and Pathways
Gašper Tkačik1 and William Bialek1,2
1Joseph Henry Laboratories of Physics, Lewis–
Sigler Institute for Integrative Genomics,
Princeton University, Princeton, NJ, USA
2Princeton Center for Theoretical Physics,
Princeton University, Princeton, NJ, USA
Article Outline
Glossary
Deﬁnition of the Subject
Introduction
Biological Networks and Their Building Blocks
Models of Biological Networks
Network Properties and Operating Principles
Dynamics, Attractors, Stability and Large
Fluctuations
Future Directions
Bibliography
Glossary
Dynamical system is a set of components the
properties of which (e. g. their quantity, activ-
ity level etc.) change in time because the com-
ponents interact among themselves and are
also inﬂuenced by external forces.
Network node is a constituent component of the
network, in biological networks most often
identiﬁed with a molecular species.
Interaction is a connection between network
nodes; in biological networks an interaction
means that two nodes chemically react, regulate
each other, or effectively inﬂuence each other’s
activities. Interactions are mostly pairwise, but
can be higher-order as well; they can be directed
or undirected, and are usually characterized by
an interaction strength.
Network is a system of interacting nodes.
A network can be represented mathematically
as a graph, where vertices denote the nodes and
edges denote the interactions. Biological net-
works often are understood to be dynamical
systems as well, because the activities of net-
work nodes evolve in time due to the graph of
interactions.
Network state is the vector of activities of all
nodes that fully characterizes the network at
any point in time; since a biological network is
a dynamical system, this state generally
changes through time according to a set of
dynamical equations.
Biological function refers to the role that a spe-
ciﬁc network plays in the life of the organism;
the network can be viewed as existing to per-
form a task that enables the cell to survive and
reproduce, such as the detection or transduc-
tion of a speciﬁc chemical signal.
Pathway is a subset of nodes and interactions in a
network along which information or energy and
matter ﬂow in a directed fashion; pathways can
be coupled through interactions or unwanted
cross-talk.
Curse of dimensionality is the rapid increase of
complexity encountered when analyzing or
experimentally observing network states, as
more and more network nodes are added. If
there are N network nodes each of which only
has two states (for example on and off ), the
number of states that the network can be in
grows as 2N.
Design principle is an (assumed) constraint on
the network architecture, stating that a biolog-
ical network, in addition to performing a cer-
tain function, implements that function in a
particular way, usually to maximize or mini-
mize some further objective measure, for
instance robustness, information transmis-
sion, or designability.
© Springer-Verlag 2009
B. Chakraborty (ed.), Statistical and Nonlinear Physics,
https://doi.org/10.1007/978-1-0716-1454-9_48
Originally published in
R. A. Meyers (ed.), Encyclopedia of Complexity and Systems Science, © Springer-Verlag 2009
https://doi.org/10.1007/978-3-642-27737-5_48
449

Definition of the Subject
In
cell
biology,
networks
are
systems
of
interacting molecules that implement cellular
functions, such as the regulation of gene expres-
sion, metabolism or intracellular signaling. While
on a molecular level a biological network is a
mesh of chemical reactions between, for example,
enzymes and their substrates, or DNA-binding
proteins and the genes that they regulate, the col-
lective effect of these reactions can often be
thought of as the enabling and regulating the
ﬂow of matter and energy (in metabolic net-
works), or of information (in signaling and tran-
scriptional regulatory networks). The ﬁeld is
concerned primarily with the description and
properties of such ﬂows and with their emergence
from network constituent parts – the molecules
and their physical interactions. An important
focus is also the question of how network function
and operating principles can be inferred despite
the limited experimental access to network states
and building blocks.
Introduction
Biological network has come to mean a system of
interacting molecules that jointly perform cellular
tasks such as the regulation of gene expression,
information transmission, or metabolism (Bray
1995). Speciﬁc instances of biological networks
include, for example, the DNA and DNA binding
proteins comprising the transcriptional regulatory
network; signaling proteins and small molecules
comprising
various
signaling
networks;
or
enzymes and metabolites comprising the meta-
bolic network. Two important assumptions shape
our current understanding of such systems: ﬁrst,
that the biological networks have been under
selective evolutionary pressure to perform spe-
ciﬁc cellular functions in a way that furthers the
overall reproductive success of the individual; and
second,
that
these
functions
often
are
not
implemented on a microscopic level by single
molecules, but are rather a collective property of
the whole interaction network. The question of
how complex behavior emerges in a network of
(simple) nodes under a functional constraint is
thus central (Strogatz 2001).
To start off with a concrete example, consider
chemo-taxis in the bacterium Escherichia coli
(Berg 1975; Falke et al. 1997), one of the para-
digmatic examples of signal transduction. This
system is dedicated to steering the bacteria
towards areas high in nutrient substances and
away from repellents. Chemo-effector molecules
in the solution outside the bacterium bind to
receptor molecules on the cell surface, and the
resulting structural changes in the receptors are
relayed in turn by the activities of the intracellular
signaling proteins to generate a control signal for
molecular motors that drive the bacterial ﬂagella.
The chemotactic network consists of about ten
nodes (here, signaling proteins), and the interac-
tions between the nodes are the chemical reactions
of methylation or phosphorylation. Notable fea-
tures of this system include its extreme sensitivity,
down to the limits set by counting individual
molecules as they arrive at the cell surface (Berg
and Purcell 1977), and the maintenance of this
sensitivity across a huge dynamic range, through
an adaptation mechanism that provides nearly
perfect compensation of background concentra-
tions (Block et al. 1983). More recently it has
been appreciated that aspects of this functionality,
such as perfect adaptation, are also robust against
large variations in the concentrations of the net-
work components (Alon et al. 1999).
Abstractly, different kinds of signaling pro-
teins, such those in chemotaxis, can be thought
of as the building blocks of a network, with their
biochemical interactions forming the wiring dia-
gram of the system, much like the components
and wiring diagram of, for instance, a radio
receiver. In principle, these wiring diagrams are
hugely complex; for a network composed of
N species, there are  CN
k possible connections
among any set of k components, and typically we
don’t have direct experimental guidance about the
numbers
associated
with
each
‘wire.’
One
approach is to view this as giant ﬁtting problem:
once we draw a network, there is a direct transla-
tion of this graph into dynamical equations, with
many parameters, and we should test the predic-
tions of these dynamics against whatever data are
450
Cell Biology: Networks, Regulation and Pathways

available to best determine the underlying param-
eters. Another approach is to ask whether this
large collection of parameters is special in any
way other than that it happens to ﬁt the data –
are there principles that allow us to predict how
these systems should work? In the context of
chemotaxis, we might imagine that network
parameters have been selected to optimize the
average progress of bacteria up the chemical gra-
dients of nutrients, or to maximize the robustness
of certain functions against extreme parameter
variations. These ideas of design principles
clearly are not limited to bacterial chemotaxis.
An important aspect of biological networks is
that the same components (or components that
have an easily identiﬁable evolutionary relation-
ship) can be (re)used in different modules or used
for the same function in a different way across
species, as discussed for example by Rao et al.
(2004) for the case of bacterial chemotaxis. Fur-
thermore, because evolutionary selection depends
on function and not directly on microscopic
details, different wiring diagrams or even changes
in components themselves can result in the same
performance; evolutionary process can gradually
change the structure of the network as long as its
function is preserved; as an example see the dis-
cussion of transcriptional regulation in yeast by
Tanay et al. (2005). On the other hand, one can
also expect that signal processing problems like
gain control, noise reduction, ensuring (bi)stabil-
ity etc., have appeared and were solved repeat-
edly, perhaps even in similar ways across various
cellular functions, and we might be able to detect
the traces of their commonality in the network
structure, as for example in the discussion of
local connectivity in bacterial transcriptional reg-
ulation by Shen–Orr et al. (2002). Thus there are
reasons to believe that in addition to design prin-
ciples at the network level, there might also be
local organizing principles, similar to common
wiring motifs in electronic circuitry, yet still inde-
pendent of the identity of the molecules that
implement these principles.
Biological networks have been approached at
many different levels, often by investigators from
different disciplines. The basic wiring diagram of
a network – the fact that a kinase phosphorylates
these particular proteins, and not all others, or that
a transcription factor binds to the promoter
regions of particular genes – is determined by
classical biochemical and structural concepts
such as binding speciﬁcity. At the opposite
extreme, trying to understand the collective
behavior of the network as a whole suggests
approaches from statistical physics, often looking
at simpliﬁed models that leave out many molecu-
lar details. Analyses that start with design princi-
ples are yet a different approach, more in the ‘top–
down’ spirit of statistical physics but leaving per-
haps more room for details to emerge as the anal-
ysis is reﬁned. Eventually, all of these different
views need to converge: networks really are built
out of molecules, their functions emerge as col-
lective behaviors, and these functions must really
be functions of use to the organism. At the
moment, however, we seldom know enough to
bridge the different levels of description, so the
different approaches are pursued more or less
independently, and we follow this convention
here. We will start with the molecular building
blocks, then look at models for networks as a
whole, and ﬁnally consider design principles.
We hope that this sequence doesn’t leave the
impression that we actually know how to build
up from molecules to function!
Before exploring our subject in more detail, we
take a moment to consider its boundaries. Our
assignment from the editors was to focus on phe-
nomena at the level of molecular and cellular
biology. A very different approach attempts to
create a ‘science of networks’ that searches for
common properties in biological, social, eco-
nomic and computer networks (Newman et al.
2006). Even within the biological world, there is
a signiﬁcant divide between work on networks in
cell biology and networks in the brain. As far as
we can see this division is an artifact of history,
since there are many issues which cut across these
different ﬁelds. Thus, some of the most beautiful
work on signaling comes from photoreceptors,
where the combination of optical inputs and elec-
trical outputs allowed, already in the 1970s, for
experiments with a degree of quantitative analysis
that even today is hard to match in systems which
take chemical inputs and give outputs that
Cell Biology: Networks, Regulation and Pathways
451

modulate the expression levels of genes (Baylor
et al. 1979; Rieke and Baylor 1998). Similarly,
problems of noise in the control of gene expres-
sion have parallels in the long history of work on
noise in ion channels, as we have discussed else-
where (Tkačik et al. 2008c), and the problems of
robustness have also been extensively explored in
the network of interactions among the multiple
species
of
ion
channels
in
the
membrane
(Goldman et al. 2001; LeMasson et al. 1993).
Finally, the ideas of collective behavior are much
better developed in the context of neural networks
than in cellular networks, and it is an open ques-
tion how much can be learned by studying these
different systems in the same language (Tkačik
2007).
Biological Networks and Their Building
Blocks
Genetic Regulatory Networks
Cells constantly adjust their levels of gene expres-
sion. One central mechanism in this regulatory
process involves the control of transcription by
proteins known as transcription factors (TFs),
which locate and bind short DNA sequences in
the
regulated
genes’
promoter
or
enhancer
regions. A given transcription factor can regulate
either a few or a sizable proportion of the genes in
a genome, and a single gene may be regulated by
more than one transcription factor; different tran-
scription factors can also regulate each other
(Watson et al. 2003).
In the simplest case of a gene regulated by a
single TF, the gene might be expressed whenever
the factor – in this case called an activator – is
bound to the cognate sequence in the promoter
(which corresponds to the situation when the TF
concentration in the nucleus is high), whereas the
binding of a repressor would shut a normally
active gene down. The outlines of these basic
control principles were established long ago,
well before the individual transcription factors
could be isolated, in elegant experiments on the
lactose operon of Escherichia coli (Jacob and
Monod 1961) and even simpler model systems
such as phage l (Ptashne 2004). To a great extent
the lessons learned from these experiments have
provided the framework for understanding tran-
scriptional control more generally, in prokaryotes
(Ptashne 2001), eukaryotes (Kadonaga 2004), and
even during the development of complex multi-
cellular organisms (Arnosti and Kulkarni 2005).
The advent of high throughput techniques for
probing gene regulation has extended our reach
beyond single genes. In particular, microarrays
(Brown and Botstein 1999) and the related data
analysis tools, such as clustering (Eisen et al.
1998), have enabled researchers to ﬁnd sets of
genes, or modules, that are coexpressed, i.e. up-
or down-regulated in a correlated fashion when
the organism is exposed to different external con-
ditions, and are thus probably regulated by the
same set of transcription factors. Chromatin
immunoprecipitation (ChIP) assays have made it
possible to directly screen for short segments of
DNA that known TFs bind; using microarray
technology it is then possible to locate the
intergenic regions which these segments belong
to, and hence ﬁnd the regulated genes, as has
recently
been
done
for
the
Saccharomyces
cerevisiae
DNA-TF
interaction
map
(Lee
et al. 2002).
These
high
throughput
experimental
approaches, combined with traditional molecular
biology and complemented by sequence analysis
and related mathematical tools (Siggia 2005), pro-
vide a large scale, topological view of the tran-
scriptional regulatory network of a particular
organism, where each link between two nodes
(genes) in the regulatory graph implies either acti-
vation or repression (Alm and Arkin 2003). While
useful for describing causal interactions and try-
ing to predict responses to mutations and external
perturbations (Levine and Davidson 2005), this
picture does not explain how the network operates
on a physical level: it lacks dynamics and speciﬁes
neither the strengths of the interactions nor how
all the links converging onto a given node jointly
exercise control over it. To address these issues,
representative wild-type or simple synthetic regu-
latory elements and networks consisting of a few
nodes have been studied extensively to construct
quantitative models of the network building
blocks.
452
Cell Biology: Networks, Regulation and Pathways

For instance, combinatorial regulation of a
gene by several transcription factors that bind
and interact on the promoter has been considered
by Buchler et al. (Buchler et al. 2003) as an
example of (binary) biological computation and
synthetic networks implementing such computa-
tions have been created (Guet et al. 2002;
Yokobayashi et al. 2002). Building on classical
work describing allosteric proteins such as hemo-
globin, thermodynamic models have been used
with success to account for combinatorial interac-
tions on the operator of the l phage (Ackers et al.
1982).More recently Bintu et al. (2005a, b) have
reviewed the equilibrium statistical mechanics of
such interactions, Setty et al. (2003) have experi-
mentally and systematically mapped out the
response surface of the lac promoter to combina-
tions of its two regulatory inputs, cAMP and
IPTG, and Kuhlman et al. (2007) have ﬁnally
provided a consistent picture of the known exper-
imental results and the thermodynamic model for
the combinatorial regulation of the lactose operon.
There have also been some successes in eukary-
otic regulation, where Schroeder et al. (2004) used
thermodynamically motivated models to detect
clusters of binding sites that regulate the gap
genes in morphogenesis of the fruit ﬂy.
Gene regulation is a dynamical process com-
posed of a number of steps, for example the bind-
ing of TF to DNA, recruitment of transcription
machinery and the production of the messenger
RNA, post-transcriptional regulation, splicing and
transport of mRNA, translation, maturation and
possible localization of proteins. While the exten-
sive palette of such microscopic interactions rep-
resents a formidable theoretical and experimental
challenge for each detailed study, on a network
level it primarily induces three effects. First, each
node – usually understood as the amount of gene
product – in a graph of regulatory interactions is
really not a single dynamical variable, but has a
nontrivial internal state representing the conﬁgu-
ration on the associated promoter, concentration
of the corresponding messenger RNA etc.; the
relation of these quantities to the concentration
of the output protein is not necessarily straightfor-
ward, as emphasized in recent work comparing
mRNA
and
protein
levels
in
yeast
(Ghaemmaghami et al. 2003). Second, collapsing
multiple chemical species onto a single node
makes it difﬁcult to include non-transcriptional
regulation of gene expression in the same frame-
work. Third, the response of the target gene to
changes in the concentrations of its regulators will
be delayed and extended in time, as in the example
explored by Rosenfeld and Alon (2003).
Perhaps the clearest testimonies to the impor-
tance of dynamics in addition to network topology
are provided by systems that involve regulatory
loops, in which the output of a network feeds back
on one of the inputs as an activator or repressor.
McAdams and Shapiro (1995) have argued that
the time delays in genetic regulatory elements are
essential for the proper functioning of the phage l
switch, while Elowitz and Leibler (2000) have
created a synthetic circuit made up of three mutu-
ally repressing genes (the “repressilator”), that
exhibits
spontaneous
oscillations.
Circadian
clocks are examples of naturally occurring genetic
oscillators (Young and Kay 2001).
In short, much is known about the skeleton of
genetic regulatory interactions for model organ-
isms, and physical models exist for several well
studied (mostly prokaryotic) regulatory elements.
While homology allows us to bridge the gap
between model organisms and their relatives, it
is less clear how and at which level of detail the
knowledge about regulatory elements must be
combined into a network to explain and predict
its function.
Protein–Protein Interaction Networks
After having been produced, proteins often
assemble into complexes through direct contact
interactions, and these complexes are functionally
active units participating in signal propagation
and other pathways. Proteins also interact through
less persistent encounters, as when a protein
kinase meets its substrate. It is tempting to deﬁne
a link in the network of protein–protein interac-
tions by such physical associations, and this is the
basis of several experimental methods which aim
at a genome-wide survey of these interactions.
Although starting out being relatively unreliable
(with false positive rates of up to 50%), high
throughput techniques like the yeast two hybrid
Cell Biology: Networks, Regulation and Pathways
453

assay (Ito et al. 2001; Uetz et al. 2000) or mass
spectrometry (Gavin et al. 2002; Ho et al. 2002)
are providing data of increasing quality about
protein–protein interactions, or the “interactome”
(Krogan et al. 2006). While more reliable methods
are being developed (Alm and Arkin 2003) and
new organisms are being analyzed in this way
(Giot et al. 2003; Li et al. 2004; Rual et al.
2005), the existing interaction data from high
throughput experiments and curated databases
has already been extensively studied.
Interpretation of the interactions in the protein
network is tricky, however, due to the fact that
different experimental approaches have various
biases – for example, mass spectrometry is biased
towards detecting interactions between proteins of
high abundance, while two hybrid methods seem
to be unbiased in this regard; on the other hand, all
methods show some degree of bias towards dif-
ferent cellular localizations and evolutionary nov-
elty of the proteins. Assessing such biases,
however, currently depends not on direct calibra-
tion of the methods themselves but on comparison
of the results with manually curated databases,
although the databases surely have their own
biases (Jansen and Gerstein 2004). It is reassuring
that the intersection of various experimental
results shows signiﬁcantly improved agreement
with the databases, but this comes at the cost of
a substantial drop in coverage of the proteome
(von Mering et al. 2002).
In contrast to the case of transcriptional regu-
lation, the relationship between two interacting
proteins is symmetric: if protein A binds to
protein B, B also binds to A, so that the network
is described by an undirected graph. Most of the
studies have been focused on binary interactions
that yeast two hybrid and derived approaches can
probe, although spectrometry can detect multi-
protein complexes as well. Estimates of number
of links in these networks vary widely, even in the
yeast Saccharomyces cerevisiae: Krogan et al.
(2006) directly measure around 7100 interactions
(between 2700 proteins), while Tucker et al.
(2001)
estimate
the
total
to
be
around
13,000–17,000, and von Mering et al. (2002)
would put the lower estimate at about 30,000.
Apart from the experimental biases that can
inﬂuence such estimates and have been discussed
already, it is important to realize that each exper-
iment can only detect interactions between pro-
teins that are expressed under the chosen external
conditions (e. g. the nutrient medium); moreover,
interactions can vary from being transient to per-
manent, to which various measurement methods
respond differently. It will thus become increas-
ingly important to qualify each interaction in a
graph by specifying how it depends on context
in which the interaction takes place.
Proteins ultimately carry out most of the cellu-
lar processes such as transcriptional regulation,
signal propagation and metabolism, and these
processes can be modeled by their respective net-
work and dynamical system abstractions. In con-
trast, the interactome is not a dynamical system
itself, but instead captures speciﬁc reactions (like
protein complex assembly) and structural and/or
functional relations that are present in all of the
above processes. In this respect it has an important
practical role of annotating currently unknown
proteins through ‘guilt by association,’ by tying
them into complexes and processes with a previ-
ously known function.
Metabolic Networks
Metabolic networks organize our knowledge
about anabolic and catabolic reactions between
the enzymes, their substrates and co-factors
(such as ATP), by reducing the set of reactions to
a graph representation where two substrates are
joined by a link if they participate in the same
reaction. For model organisms like the bacterium
Escherichia coli the metabolic networks have
been studied in depth and are publicly available
(Kanehisa et al. 2002; Karp et al. 2002), and an
increasing number of analyzed genomes offers
sufﬁcient sampling power to make statistical
statements about the network properties across
different domains of life (Jeong et al. 2000).
Several important features distinguish meta-
bolic from protein–protein interaction and tran-
scriptional regulation networks. First, for well
studied systems the coverage of metabolic reac-
tions is high, at least for the central routes of
energy metabolism and small molecule synthesis;
notice that this is a property of our knowledge, not
454
Cell Biology: Networks, Regulation and Pathways

a property of the networks (!). Second, cellular
concentrations of metabolites usually are much
higher than those of transcription factors, making
the stochasticity in reactions due to small molec-
ular counts irrelevant. Third, knowledge of the
stoichiometry of reactions allows one to directly
write down a system of ﬁrst order differential
equations for the metabolite ﬂuxes (Heinrich and
Schuster 1996), which in steady state reduces to a
set of linear constraints on the space of solutions.
These chemical constraints go beyond topology
and can yield strong and testable predictions; for
example, Ibarra et al. (2002) have shown how
computationally maximizing the growth rate of
Escherichia coli within the space of allowed solu-
tions given by ﬂux balance constraints can cor-
rectly predict measurable relationships between
oxygen and substrate uptake, and that bacteria
can be evolved towards the predicted optimality
for growth conditions in which the response was
initially suboptimal.
Signaling Networks
Signaling networks consist of receptor and signal-
ing proteins that integrate, transmit and route
information by means of chemical transforma-
tions of the network constituents. One class of
such transformations, for example, are post–trans-
lational modiﬁcations, where targets are phos-
phorylated,
methylated,
acetylated,
. . .
on
speciﬁc residues, with a resulting change in their
enzymatic (and thus signaling) activity. Alterna-
tively, proteins might form stable complexes or
dissociate from them, again introducing states of
differential activity. The ability of cells to modify
or tag proteins (possibly on several residues) can
increase considerably the cell’s capacity to encode
its state and transmit information, assuming that
the signaling proteins are highly speciﬁc not only
for the identity but also the modiﬁcation state of
their targets; for a review see Papin et al. (2005).
Despite the seeming overlap between the
domains of protein–protein network and signaling
networks, the focus of the analysis is substantially
different. The inter-actome is simply a set of pos-
sible protein–protein interactions and thus a topo-
logical
(or
connectivity)
map;
in
contrast,
signaling
networks
aim
to
capture
signal
transduction and therefore need to establish a
causal map, in which the nature of the protein–
protein interaction, its direction and timescale,
and its quantitative effect on the activity of the
target protein matter. As an example, see the dis-
cussion by Kolch (2000) on the role of protein–
protein interactions in MAPK signaling cascade.
Experiments on some signaling systems, such
as the Escherichia coli chemotactic module, have
generated enough experimental data to require
detailed models in the form of dynamical equa-
tions. Molecular processes in a signaling cascade
extend over different time scales, from millisec-
onds required for kinase and phosphatase reac-
tions and protein conformational changes, to
minutes or more required for gene expression
control, cell movement and receptor trafﬁcking;
this fact, along with the (often essential) spatial
effects such as the localization of signaling
machinery and diffusion of chemical messengers,
can
considerably
complicate
analyses
and
simulations.
Signaling networks are often factored into
pathways that have speciﬁc inputs, such as the
ligands of the G protein coupled receptors on the
cell surface, and speciﬁc outputs, as with path-
ways that couple to the transcriptional regulation
apparatus or to changes in the intracellular con-
centration of messengers such as calcium or cyclic
nucleotides. Nodes in signaling networks can par-
ticipate in several pathways simultaneously, thus
enabling signal integration or potentially inducing
damaging “crosstalk” between pathways; how
junctions and nodes process signals is an area of
active research (Jordan et al. 2000).
The components of signaling networks have
long been the focus of biochemical research, and
genetic methods allow experiments to assess the
impact of knocking out or over-expressing partic-
ular components. In addition, several experimen-
tal approaches are being designed speciﬁcally for
elucidating signaling networks. Ab-chips localize
various signaling proteins on chips reminiscent of
DNA microarrays, and stain them with appropri-
ate ﬂuorescent antibodies (Nielsen et al. 2003).
Multicolor ﬂow cytometry is performed on cells
immuno-stained for signaling protein modiﬁca-
tions and hundreds of single cell simultaneous
Cell Biology: Networks, Regulation and Pathways
455

measurements of the modiﬁcation state of path-
way nodes are collected (Perez and Nolan 2002).
Indirect inference of signaling pathways is also
possible from genomic or proteomic data.
One well studied signal transduction system is
the mitogen activated protein kinase (MAPK)
cascade that controls, among other functions,
cell proliferation and differentiation (Chang and
Karin 2001). Because this system is present in all
eukaryotes and its structural components are used
in multiple pathways, it has been chosen as a
paradigm for the study of speciﬁcity and crosstalk.
Similarly, the TOR system, identiﬁed initially in
yeast, is responsible for integrating the informa-
tion on nutrient availability, growth factors and
energy status of the cell and correspondingly reg-
ulating the cell growth (Martin and Hall 2005).
Another interesting example of signal integration
and both intra- and inter-cellular communication
is observed in the quorum sensing circuit of the
bacterium Vibrio harveyi, where different kinds of
species- and genus-speciﬁc signaling molecules
are detected by their cognate receptors on the
cell surface, and the information is fed into a
common Lux phosphorelay pathway which ulti-
mately regulates the quorum sensing genes
(Waters and Bassler 2005).
Models of Biological Networks
Topological Models
The structural features of a network are captured
by its connectivity graph, where interactions
(reactions, structural relations) are depicted as
the links between the interacting nodes (genes,
proteins, metabolites). Information about connec-
tivity clearly cannot and does not describe the
network behavior, but it might inﬂuence and con-
strain it in revealing ways, similar to effect that the
topology of the lattice has on the statistical
mechanics of systems living on it.
Theorists have studied extensively the proper-
ties of regular networks and random graphs
starting with Erdös and Rényi in 1960s. The ﬁrst
ones are characterized by high symmetry inherent
in a square, triangular, or all-to-all (mean ﬁeld)
lattice; the random graphs were without such
regularity, constructed simply by distributing
K links at random between N nodes. The simple
one–point statistical characterization that distin-
guishes random from regular networks looks at
the node degree, that is the probability P(k) that
any node has k incoming and/or outgoing links.
For random graphs this distribution is Poisson,
meaning that most of the nodes have degrees
very close to the mean, hki ¼ k k P(k), although
there are ﬂuctuations; for regular lattices every
node has the same connectivity to its neighbors.
The ﬁrst analyses of the early reconstructions
of large metabolic networks revealed a surpris-
ing “scale free” node degree distribution, that is
P(k)  kγ, with γ between two and three for
most networks. For the physics community,
which had seen the impact of such scale invari-
ance on our understanding of phase transitions,
these observations were extremely suggestive. It
should be emphasized that for many problems in
areas as diverse as quantum ﬁeld theory, statis-
tical mechanics and dynamical systems, such
scaling relations are much more than curiosities.
Power laws relating various experimentally
observable quantities are exact (at least in some
limit), and the exponents (here, γ) really contain
everything one might want to know about the
nature of order in the system. Further, some of
the ﬁrst thoughts on scaling emerged from phe-
nomenological analyses of real data. Thus, the
large body of work on scaling ideas in theoreti-
cal physics set the stage for people to be excited
by the experimental observation of power laws
in much more complex systems, although it is
not clear to us whether the implied promise of
connection to a deeper theoretical structure has
been fulﬁlled. For divergent views on these mat-
ters see Barabási (2002) and Keller (2005).
The most immediate practical consequence of
a scale free degree distribution is that – relative to
expectations based on random graphs – there will
be an over-representation of nodes with very large
numbers of links, as with pyruvate or co-enzyme
A in metabolic networks (Jeong et al. 2000; Wag-
ner and Fell 2001). These are sometimes called
hubs, although another consequence of a scale
free distribution is that there is no ‘critical degree
of connection’ that distinguishes hubs from non-
456
Cell Biology: Networks, Regulation and Pathways

hubs. In the protein–protein interaction network
of Saccharomyces cerevisiae, nodes with higher
degree are more likely to represent essential pro-
teins (Jeong et al. 2001), suggesting that node
degree does have some biological meaning. On
the theoretical side, removal of a sizable fraction
of nodes from a scale free network will neither
increase the network diameter much, nor partition
the network into equally sized parts (Albert et al.
2000), and it is tempting to think that this robust-
ness is also biologically signiﬁcant. The scale free
property has been observed in many non-
biological contexts, such as the topology of social
interactions, World Wide Web links, electrical
power grid connectivity . . . (Strogatz 2001).
A number of models have been proposed for
how such scaling might arise, and some of these
ideas, such as growth by preferential attachment,
have a vaguely biological ﬂavor (Barabasi and
Albert 1999; Barabasi and Oltvai 2004). Finding
the properties of networks that actually discrimi-
nate among different mechanisms of evolution or
growth turns out to be surprisingly subtle (Ziv
et al. 2005a).
Two other revealing measures are regularly
computed for biological networks. The mean
path length, hli, is the shortest path between a
pair of nodes, averaged over all pairs in the
graph, and measures the network’s overall ‘navi-
gability.’ Intuitively, short path lengths corre-
spond to, for example, efﬁcient or fast ﬂow of
information and energy in signaling or metabolic
networks, quick spread of diseases in a social
network and so on. The clustering coefﬁcient of
a node i is deﬁned as Ci ¼ 2ni/ki(ki – 1), where ni is
the number of links connecting the ki neighbors of
node i to each other; equivalently, Ci is the ratio
between the number of triangles passing through
two neighbors of i and node i itself, divided by the
maximum possible number of such triangles.
Random networks have low path lengths and
low clustering coefﬁcients, whereas regular lat-
tices have long path lengths and are locally clus-
tered. Watts and Strogatz (1998) have constructed
an intermediate regime of “small world” net-
works,
where
the
regular
lattice
has
been
perturbed by a small number of random links
connecting distant parts of the network together.
These networks, although not necessarily scale
free, have short path lengths and high clustering
coefﬁcients, a property that was subsequently
observed in metabolic and other biological net-
works as well (Wagner and Fell 2001).
A high clustering coefﬁcient suggests the exis-
tence of densely connected groups of nodes
within a network, which seems contradictory to
the idea of scale invariance, in which there is no
inherent group or cluster size; Ravasz et al. (2002)
addressed this problem by introducing hierarchi-
cal networks and providing a simple construction
for synthetic hierarchical networks exhibiting
both scale free and clustering behaviors. Although
there is no unique scale for the clusters, clusters
will appear at any scale one chooses to look at,
and this is revealed by the scaling of clustering
coefﬁcient C(k)withthenode degreek,C(k)k1,
on both synthetic as well as natural metabolic
networks of organisms from different domains of
life (Ravasz et al. 2002). Another interesting prop-
erty of some biological networks is an anti-
correlation of node degree of connected nodes
(Maslov and Sneppen 2002), which we can think
of as a ‘dissociative’ structure; in contrast, for
example, with the associative character of social
networks, where well connected people usually
know one another.
As we look more ﬁnely at the structure of the
graph representing a network, there is of course a
much greater variety of things to look at. For
example, Spirin and Mirny (2003) have focused
on high clustering coefﬁcients as a starting point
and devised algorithms to search for modules, or
densely connected subgraphs within the yeast
protein–protein interaction network. Although
the problem has combinatorial complexity in gen-
eral, the authors found about 50 modules (of 5–10
proteins in size, some of which were unknown at
the time) that come in two types: the ﬁrst repre-
sents dynamic functional units (e. g. signaling cas-
cades),
and
the
second
protein
complexes.
A similar conclusion was reached by Han et al.
(2004), after having analyzed the interactome in
combination with the temporal gene expression
proﬁles and protein localization data; the authors
argue that nodes of high degree can sit either at the
centers of modules, which are simultaneously
Cell Biology: Networks, Regulation and Pathways
457

expressed (“party hubs”), or they can be involved
in various pathways and modules at different
times (“date hubs”). The former kind is at a
lower level of organization, whereas the latter tie
the network into one large connected component.
Focusing on even a smaller scale, Shen-Orr
et al. (2002) have explored motifs, or patterns of
connectivity of small sets of nodes that are over-
represented in a given network compared to the
randomized networks of the same degree distribu-
tion P(k). In the transcriptional network of the
bacterium E. coli, three such motifs were found:
feed forward loops (in which gene X regulates
Y that regulates Z, but X directly regulates Z as
well),
single
input
modules
(where
gene
X regulates a large number of other genes in the
same way and usually auto-regulates itself), and
dense overlapping regulons (layers of overlapping
interactions between genes and a group of tran-
scription factors, much denser than in randomized
networks). The motif approach has been extended
to combined network of transcriptional regulation
and protein–protein interactions (Yeger-Lotem
et al. 2004) in yeast, as well as to other systems
(Milo et al. 2004).
At the risk of being overly pessimistic, we
should conclude this section with a note of cau-
tion. It would be attractive to think that a decade of
work on network topology has resulted in a coher-
ent picture, perhaps of the following form: on the
smallest scale, the nodes of biological networks
are assembled into motifs, these in turn are linked
into modules, and this continues in a hierarchical
fashion until the entire network is scale free. As
we will discuss again in the context of design
principles, the notion of such discrete substruc-
ture – motifs and modules – is intuitively appeal-
ing, and some discussions suggest that it is
essential either for the function or the evolution
of networks. On the other hand, the evidence for
such structure usually is gathered with reference
to some null model (e. g., a random network with
the same P(k)), so we don’t even have an absolute
deﬁnition of these structures, much less a measure
of their sufﬁciency as a characterization of the
whole system; for attempts at an absolute deﬁni-
tion of modularity see Ziv et al. (2005b) and
Hofman and Wiggins (2007). Similarly, while it
is appealing to think about scale free networks, the
evidence for scaling almost always is conﬁned to
less than two decades, and in practice scaling
often is not exact. It is then not clear whether the
idealization of scale invariance captures the essen-
tial structure in these systems.
Boolean Networks
A straightforward extension of the topological
picture that also permits the study of network
dynamics assumes that the entities at the nodes –
for example, genes or signaling proteins – are
either ‘on’ or ‘off’ at each moment of time, so
that for node i the state at time t is si(t)  {0, 1}.
Time is usually discretized, and an additional pre-
scription is needed to implement the evolution of
the system: si(t þ 1) ¼ fi({sm(t)}), where fi is a
function that speciﬁes how the states of the nodes m
that are the inputs to node i in the interaction graph
combine to determine the next state at node i.
For instance, fA might be a Boolean function for
gene A, which needs to have its activator gene B
present and repressor gene C absent, so that
sA t þ 1
ð
Þ ¼ sB tð Þ ^ esC tð Þ. Alternatively, f might
be a function that sums the inputs at state t with
some weights, and then sets si ¼ 1(0) if the result
is above (below) a threshold, as in classical
models of neural networks.
Boolean networks are amenable both to analyt-
ical treatment and to efﬁcient simulation. Early on,
Kauffman (1969) considered the family of random
boolean networks. In these models, each node is
connected at random to K other nodes on average,
and it computes a random Boolean function of its
inputs in which a fraction r of the 2K possible input
combinations leads to si (t þ 1) ¼ 1. In the limit
that the network is large, the dynamics are either
regular (settling into a stable ﬁxed cycle) or chaotic,
and these two phases are separated by a separatrix
2r(1 – r)K ¼ 1 in the phase space (r, K).
Aldana and Cluzel (2003) have shown that for
connectivities of K ~ 20 that could reasonably be
expected in e.g. transcriptional regulatory net-
works, the chaotic regime dominates the phase
space. They point out, however, that if the net-
work is scale free, there is no ‘typical’ K as the
distribution P(k)  k–γ does not have a well-
deﬁned mean for γ  3 and the phase transition
458
Cell Biology: Networks, Regulation and Pathways

criterion must be restated. It turns out, surpris-
ingly, that regular behavior is possible for values
of γ between 2 and 2.5, observed in most biolog-
ical networks, and this is exactly the region where
the separatrix lies. Scale free architecture, at least
for Boolean networks, seems to prevent chaos.
Several groups have used Boolean models to
look at speciﬁc biological systems. Thomas
(Thomas 1973) has established a theoretical frame-
work in which current states of the genes (as well as
the states in the immediate past) and the environ-
mental inputs are represented by Boolean variables
that evolve through the application of Boolean
functions. This work has been continued by, for
example, Sanchez and Thieffry (2001) who ana-
lyzed the gap-gene system of the fruit ﬂy Drosoph-
ila by building a Boolean network that generates
the correct levels of gene expression for 4 gap
genes in response to input levels of 3 maternal
morphogens
with
spatially
varying
proﬁles
stretched along the anterior-posterior axis of the
ﬂy embryo. Interestingly, to reproduce the observed
results and correctly predict the known Drosophila
segmentation mutants, the authors had to introduce
generalized Boolean variables that can take more
than two states, and have identiﬁed the smallest
necessary number of such states for each gene.
In a similar spirit, Li et al. (2004) studied the
skeleton of the budding yeast cell cycle, com-
posed of 11 nodes, and a thresholding update
rule. They found that the topology of this small
network generates a robust sequence of transitions
corresponding to known progression through
yeast cell-cycle phases G1 (growth), S (DNA
duplication), G2 (pause) and M (division), trig-
gered by a known ‘cell-size checkpoint.’ This
progression is robust, in the sense that the correct
trajectory is the biggest dynamical attractor of the
system, with respect to various choices of update
rules and parameters, small changes in network
topology, and choice of triggering checkpoints.
The usefulness of Boolean networks stems
from the relative ease of implementation and sim-
ple parametrization of network topology and
dynamics, making them suitable for studying
medium or large networks. In addition to simpli-
fying the states at the nodes to two (or more)
discrete levels, which is an assumption that has
not been clearly explored, one should be cautious
that the discrete and usually synchronous dynam-
ics in time can induce unwanted artifacts.
Probabilistic Models
Suppose one is able to observe simultaneously the
activity levels of several proteins comprising a
signaling network, or the expression levels of a
set of genes belonging to the same regulatory mod-
ule. Because they are part of a functional whole, the
activity levels of the components will be correlated.
Naively, one could build a network model by sim-
ply computing pairwise correlation coefﬁcients
between pairs of nodes, and postulating an interac-
tion, and therefore a link, between the two nodes
whenever their correlation is above some thresh-
old. However, in a test case where A ! B ! C
(gene A induces B which induces C), one expects
to see high positive correlation among all three
elements, even though there is no (physical) inter-
action between A and C. Correlation therefore is
not equal to interaction or causation. Constructing a
network from the correlations in this naive way
also does not lead to a generative model that
would predict the probabilities for observing dif-
ferent states of the network as a whole. Another
approach is clearly needed; see Markowetz and
Spang (2007) for a review.
In the simple case where the activity of a pro-
tein/gene i can either be ‘on’ (si ¼ 1) or ‘off’
(si ¼ 0), the state of a network with N nodes will
be characterized by a binary word of N bits, and
because of interaction between nodes, not all these
words will be equally likely. For example, if node
A represses node B, then combinations such as
1A0B . . . or 0A1B . . . will be more likely than 1A1B
. . . In the case of deterministic Boolean networks,
having node A be ‘on’ would imply that node B is
‘off’ with certainty, but in probabilistic models it
only means that there is a positive bias for node
B to be ‘off,’ quantiﬁed by the probability that
node B is ‘off’ given that the state of node A is
known.
Having
this
additional
probabilistic
degree of freedom is advantageous, both because
the network itself might be noisy, and because the
experiment can induce errors in the signal readout,
making the inference of deterministic rules from
observed binary patterns an ill-posed problem.
Cell Biology: Networks, Regulation and Pathways
459

Once we agree to make a probabilistic model,
the goal is to ﬁnd the distribution over all network
states, which we can also think of as the joint
distribution of all the N variable that live on the
nodes of the network, P(s1,. . ., sN|C), perhaps
conditioned on some ﬁxed set of environmental
or experimental factors C. The activities of the
nodes, si, can be binary, can take on a discrete
set of states, or be continuous, depending on our
prior knowledge about the system and experimen-
tal and numerical constraints. Even for a modest
N, experiments of realistic scale will not be
enough to directly estimate the probability distri-
bution, since even with binary variable the num-
ber of possible states, and hence the number of
parameters required to specify the general proba-
bility distribution, grows as ~2 N. Progress thus
depends in an essential way on simplifying
assumptions.
Returning
to
the
three
gene
example
A ! B ! C, we realize that C depends on
A only through B, or in other words, C is condi-
tionally independent of A and hence no interac-
tion should be assigned between nodes A and
C. Thus, the joint distribution of three variables
can be factorized,
P sA, sB, sC
ð
Þ ¼ P sCjsB
ð
ÞP sBjsA
ð
ÞP sA
ð
Þ:
One might hope that, even in a large network,
these sorts of conditional independence relations
could be used to simplify our model of the prob-
ability distribution. In general this doesn’t work,
because of feedback loops which, in our simple
example, would include the possibility that
C affects the state of A, either directly or through
some more circuitous path. Nonetheless one can
try to make an approximation in which loops
either are neglected or (more sensibly) taken into
account in some sort of average way; in statistical
mechanics, this approximation goes back at least
to the work of Bethe (1935).
In the computer science and bioinformatics
literature, the exploitation of Bethe-like approxi-
mations has come to be known as ‘Bayesian net-
work modeling’ (Gardner et al. 2000). In practice
what this approach does is to search among pos-
sible network topologies, excluding loops, and
then for ﬁxed topology one uses the conditional
probability relationships to factorize the probabil-
ity distribution and ﬁt the tables of conditional
probabilities at each node that will best reproduce
some set of data. Networks with more links have
more parameters, so one must introduce a trade-
off between the quality of the ﬁt to the data and
this increasing complexity. In this framework
there is thus an explicit simpliﬁcation based on
conditional independence, and an implicit simpli-
ﬁcation based on a preference for models with
fewer links or sparse connectivity.
The best known application of this approach to a
biological network is the analysis of the MAPK
signaling pathway in T cells from the human
immune system (Sachs et al. 2005). The data for
this analysis comes from experiments in which the
phosophorylated states of 11 proteins in the pathway
are sampled simultaneously by immunostaining
(Perez and Nolan 2002), with hundreds of cells
sampled for each set of external conditions. By
combining experiments from multiple conditions,
the Bayesian network analysis was able to ﬁnd a
network of interactions among the 11 proteins that
has high overlap with those known to occur
experimentally.
A very different approach to simpliﬁcation of
probabilistic models is based on the maximum
entropy principle (Jaynes 1957). In this approach
one views a set of experiments as providing an
estimate of some set of correlations, for example
the ~N2 correlations among all pairs of elements in
the network. One then tries to construct a proba-
bility distribution which matches these correla-
tions but otherwise has as little structure – as
much entropy – as possible. We recall that the
Boltzmann distribution for systems in thermal
equilibrium can be derived as the distribution
which has maximum entropy consistent with a
given average energy, and maximum entropy
modeling generalizes this to take account of
other average properties. In fact one can construct
a hierarchy of maximum entropy distributions
which are consistent with higher and higher orders
of correlation (Schneidman et al. 2003).Maxi-
mum entropy models for binary variables that
are consistent with pairwise correlations are
exactly the Ising models of statistical physics,
460
Cell Biology: Networks, Regulation and Pathways

which opens a wealth of analytic tools and intui-
tion about collective behavior in these systems.
In the context of biological networks (broadly
construed), recent work has shown that maximum
entropy models consistent with pairwise correla-
tions are surprisingly successful at describing the
patterns of activity among populations of neurons
in the vertebrate retina as it responds to natural
movies (Schneidman et al. 2006; Tkačik et al.
2006). Similar results are obtained for very differ-
ent retinas under different conditions (Shlens et al.
2006), and these successes have touched a ﬂurry
of interest in the analysis of neural populations
more generally. The connection to the Ising model
has a special resonance in the context of neural
networks, where the collective behavior of the
Ising model has been used for some time as a
prototype for thinking about the dynamics of com-
putation and memory storage (Hopﬁeld 1982); in
the maximum entropy approach the Ising model
emerges directly as the least structured model
consistent with the experimentally measured pat-
terns
of
correlation
among
pairs
of
cells.
A particularly striking result of this analysis is
that the Ising models which emerge seem to be
poised near a critical point (Tkačik et al. 2006).
Returning to cell biology, the maximum entropy
approach has also been used to analyze patterns of
gene expression in yeast (Lezon et al. 2006) as
well as to revisit the MAPK cascade (Tkačik
2007).
Dynamical Systems
If the information about a biological system is
detailed
enough
to
encompass
all
relevant
interacting molecules along with the associated
reactions and estimated reaction rates, and the
molecular noise is expected to play a negligible
role, it is possible to describe the system with rate
equations of chemical kinetics. An obvious bene-
ﬁt is the immediate availability of mathematical
tools, such as steady state and stability analyses,
insight provided by nonlinear dynamics and chaos
theory, well developed numerical algorithms for
integration in time and convenient visualization
with phase portraits or bifurcation diagrams.
Moreover, analytical approximations
can be
often exploited productively when warranted by
some prior knowledge, for example, in separately
treating ‘fast’ and ‘slow’ reactions. In practice,
however, reaction rates and other important
parameters are often unknown or known only up
to order-of-magnitude estimations; in this case the
problem usually reduces to the identiﬁcation of
phase space regions where the behavior of the
system is qualitatively the same, for example,
regions where the system exhibits limit-cycle
oscillations, bistability, convergence into a single
steady state etc.; see Tyson et al. (2001) for a
review. Despite the difﬁculties, deterministic
chemical kinetic models have been very powerful
tools in analyzing speciﬁc network motifs or reg-
ulatory elements, as in the protein signaling cir-
cuits that achieve perfect adaptation, homeostasis,
switching and so on, described by Tyson et al.
(2003), and more generally in the analysis of
transcriptional regulatory networks as reviewed
by Hasty et al. (2001).
In the world of bacteria, some of the ﬁrst
detailed computer simulations of the chemotaxis
module of Escherichia coli were undertaken by
Bray et al. (1993). The signaling cascade from the
Tar receptor at the cell surface to the modiﬁcations
in the phosphorylation state of the molecular
motor
were
captured
by
Michaelis–Menten
kinetic reactions (and equilibrium binding condi-
tions for the receptor), and the system of equations
was numerically integrated in time. While slow
adaptation kinetics was not studied in this ﬁrst
effort, the model nevertheless qualitatively repro-
duces about 80 percent of examined chemotactic
protein deletion and overexpression mutants,
although the extreme sensitivity of the system
remained unexplained.
In eukaryotes, Novak and Tyson (1997) have,
for instance, constructed an extensive model of
cell cycle control in ﬁssion yeast. Despite its com-
plexity (~10 proteins and ~30 rate constants),
Novak and colleagues have provided an interpre-
tation of the system in terms of three interlocking
modules that regulate the transitions from G1
(growth) into S (DNA synthesis) phase, from G2
into M (division) phase, and the exit from mitosis,
respectively. The modules are coupled through
cdc2/cdc13 protein complex and the system is
driven by the interaction with the cell size signal
Cell Biology: Networks, Regulation and Pathways
461

(proportional to the number of ribosomes per
nucleus). At small size, the control circuit can
only support one stable attractor, which is the
state with low cdc2 activity corresponding to G1
phase. As the cell grows, new stable state appears
and the system makes an irreversible transition
into S/G2 at a bifurcation point, and, at an even
larger size, the mitotic module becomes unstable
and executes limit cycles in cdc2-cdc13 activity
until the M phase is completed and the cell returns
to its initial size. The basic idea is that the cell,
driven by the the size readout, progresses through
robust cell states created by bistability in the three
modules comprising the cell cycle control – in this
way, once it commits to a transition from G2 state
into M, small ﬂuctuations will not ﬂip it back into
G2. The mathematical model has in this case
successfully predicted the behaviors of a number
of cell cycle mutants and recapitulated experimen-
tal observations collected during 1970s and 1980s
by Nurse and collaborators (Nurse 2001).
The circadian clock is a naturally occurring
transcriptional module that is particularly ame-
nable to dynamical systems modeling. Leloup
and Goldbeter (2003) have created a mathemat-
ical model of a mammalian clock (with ~20 rate
equations) that exhibits autonomous sustained
oscillations over a sizable range of parameter
values, and reproduces the entrainment of the
oscillations to the light– dark cycles through
light-induced gene expression. The basic mech-
anism that enables the cyclic behavior is negative
feedback transcriptional control, although the
actual circuit contains at least two coupled oscil-
lators. Studying circadian clock in mammals, the
fruit ﬂy Drosophila or Neurospora is attractive
because of the possibility of connecting a sizable
cataloge of physiological disorders in circadian
rhythms to malfunctions in the clock circuit and
direct experimentation with light-dark stimuli
(Young and Kay 2001). Recent experiments indi-
cate that at least in cyanobacteria the circadian
clock can be reconstituted from a surprisingly
small set of biochemical reactions, without tran-
scription or translation (Nakajima et al. 2005;
Tomita et al. 2005), and this opens possibilities
for even simpler and highly predictive dynamical
models (Rust et al. 2007).
Dynamical modeling has in addition been
applied to many smaller systems. For example,
the construction of a synthetic toggle switch
(Gardner et al. 2000), and the ‘repressilator’ –
oscillating network of three mutually repressing
genes (Elowitz and Leibler 2000) – are examples
where mathematical analysis has stimulated the
design of synthetic circuits. A successful reaction-
diffusion model of how localization and complex
formation of Min proteins can lead to spatial limit
cycle oscillations (used by Escherichia coli to ﬁnd
its division site) was constructed by Huang et al.
(2003). It remains a challenge, nevertheless, to
navigate in the space of parameters as it becomes
ever larger for bigger networks, to correctly
account for localization and count various forms
of protein modiﬁcations, especially when the sig-
naling networks also couple to transcriptional reg-
ulation, and to ﬁnd a proper balance between
models that capture all known reactions and inter-
actions
and
phenomenological
models
that
include coarse-grained variables.
Stochastic Dynamics
Stochastic dynamics is in principle the most
detailed level of system description. Here, the
(integer) count of every molecular species is tracked
and reactions are drawn at random with appropriate
probabilities per unit time (proportional to their
respective reaction rates) and executed to update
the current tally of molecular counts. An algorithm
implementing this prescription, called the stochastic
simulation algorithm or SSA, was devised by Gil-
lespie (1977); see Gillespie (2007) for a review of
SSA and a discussion of related methods. Although
slow, this approach for simulating chemical reac-
tions can be made exact. In general, when all mol-
ecules are present in large numbers and continuous,
well-mixed concentrations are good approxima-
tions, the (deterministic) rate dynamics equations
and stochastic simulation give the same results;
however, when molecular counts are low and, con-
sequently, the stochasticity in reaction timing and
ordering becomes important, the rate dynamics
breaks down and SSA needs to be used. In biolog-
ical networks and speciﬁcally in transcriptional reg-
ulation, a gene and its promoter region are only
present in one (or perhaps a few) copies, while
462
Cell Biology: Networks, Regulation and Pathways

transcription factors that regulate it can also be at
nanomolar concentrations (i. e. from a few to a few
hundred molecules per nucleus), making stochastic
effects possibly very important (McAdams and
Arkin 1997, 1999).
One of the pioneering studies of the role of
noise in a biological system was a simulation of
the phage l lysis-lysogeny switch by Arkin et al.
(1998). The life cycle of the phage is determined
by the concentrations of two transcription factors,
cI (lambda repressor) and cro, that compete for
binding to the same operator on the DNA. If cI is
prevalent, the phage DNA is integrated into the
host’s genome and no phage genes except for cI
are expressed (the lysogenic state); if cro is dom-
inant, the phage is in lytic state, using cell’s DNA
replication machinery to produce more phages
and ultimately lyse the host cell (Ptashne 2004).
The switch is bistable and the fate of the phage
depends on the temporal and random pattern of
gene expression of two mutually antagonistic
transcription factors, although the balance can be
shifted by subjecting the host cell to stress and
thus ﬂipping the toggle into lytic phase. The sto-
chastic simulation correctly reproduces the exper-
imentally observed fraction of lysogenic phages
as a function of multiplicity-of-infection. An
extension of SSA to spatially extended models is
possible.
Although the simulations are exact, they are
computationally intensive and do not offer any
analytical insight into the behavior of the solu-
tions. As a result, various theoretical techniques
have been developed for studying the effects of
stochasticity in biological networks. These are
often operating in a regime where the determin-
istic chemical kinetics is a good approximation,
and noise (i. e. ﬂuctuation of concentrations
around the mean) is added into the system of
differential equations as a perturbation; these
Langevin methods have been useful for the
study of noise propagation in regulatory net-
works (van Kampen 2007; Paulsson 2004;
Thattai and van Oudenaarden 2001). The analy-
sis of stochastic dynamics is especially interest-
ing in the context of design principles which
consider the reliability of network function, to
which we return below.
Network Properties and Operating
Principles
Modularity
Biological networks are said to be modular,
although the term has several related but never-
theless distinct meanings. Their common denom-
inator is the idea that there exist a partitioning of
the network nodes into groups, or modules, that
are largely independent of each other and perform
separate or autonomous functions. Independence
can be achieved through spatial isolation of the
module’s processes or by chemical speciﬁcity of
its components. The ability to extract the module
from the cell and reconstitute it in vitro, or trans-
plant it to another type of cell is a powerful argu-
ment for the existence of modularity (Hartwell
et al. 1999). In the absence of such strong and
laborious experimental veriﬁcations, however,
measures of modularity that depend on a particu-
lar network model are frequently used.
In topological networks, the focus is on the
module’s independence: nodes within a module
are densely connected to each other, while inter-
modular links are sparse (Han et al. 2004; Ravasz
et al. 2002; Spirin and Mirny 2003) and the ten-
dency to cluster is measured by high clustering
coefﬁcients. As a caveat to this view note that
despite their sparseness the inter-module links
could represent strong dynamical couplings.
Modular architecture has been studied in Boolean
networks by Kashtan and Alon (2005), who have
shown that modularity can evolve by mutation
and selection in a time-varying ﬁtness landscape
where changeable goals decompose into a set of
ﬁxed subproblems. In the example studied they
computationally evolve networks implementing
several Boolean formulae and observe the appear-
ance of a module – a circuit of logical gates
implementing a particular Boolean operator (like
XOR) in a reusable way. This work makes clear
that
modularity
in
networks
is
plausibly
connected to modularity in the kinds of problems
that these networks were selected to solve, but we
really know relatively little about the formal struc-
ture of these problems.
There are also ways of inferring a form of
modularity
directly
without
assuming
any
Cell Biology: Networks, Regulation and Pathways
463

particular network model. Clustering tools parti-
tion genes into co-expressed groups, or clusters,
that are often identiﬁed with particular modules
(Eisen et al. 1998; Segal et al. 2003; Slonim et al.
2005). Ihmels et al. (Ihmels et al. 2002) have
noted that each node can belong to more than
one module depending on the biological state of
the cell, or the context, and have correspondingly
reexamined the clustering problem. Elemento
et al. (2007) have recently presented a general
information theoretic approach to inferring regu-
latory modules and the associated transcription
factor binding sites from various kinds of high-
throughput data. While clustering methods have
been widely applied in the exploration of gene
expression, it should be emphasized that merely
ﬁnding clusters does not by itself provide evi-
dence for modularity. As noted above, the whole
discussion would be much more satisfying if we
had independent deﬁnitions of modularity and, we
might add, clearly stated alternative hypotheses
about the structure and dynamics of these
networks.
Focusing on the functional aspect of the mod-
ule, we often observe that the majority of the
components of a system (for instance, a set of
promoter sites or a set of genes regulating motility
in bacteria) are conserved together across species.
These observations support the hypothesis that the
conserved components are part of a very tightly
coupled sub-network which we might identify as a
module. Bioinformatic tools can then use the
combined sequence and expression data to give
predictions about modules, as reviewed by Siggia
(2005). Purely phylogenetic approaches that infer
module components based on inter-species com-
parisons have also been productive and can
extract candidate modules based only on phylo-
genetic footprinting, that is, studying the presence
or absence of homologous genes across organisms
and correlating their presence with hand anno-
tated phenotypic traits (Slonim et al. 2006).
Robustness
Robustness refers to a property of the biological
network such that some aspect of its function is
not sensitive to perturbations of network parame-
ters, environmental variables (e. g. temperature),
or initial state; see de Visser et al. (2003) for a
review of robustness from an evolutionary per-
spective and Goulian (2004) for mechanisms of
robustness
in
bacterial
circuits.
Robustness
encompasses two very different ideas. One idea
has to do with a general principle about the nature
of explanation in the quantitative sciences: quali-
tatively striking facts should not depend on the
ﬁne tuning of parameters, because such a scenario
just shifts the problem to understanding why the
parameters are tuned as they are. The second idea
is more intrinsic to the function of the system, and
entails the hypothesis that cells cannot rely on
precisely reproducible parameters or conditions
and must nonetheless function reliably and
reproducibly.
Robustness has been studied extensively in the
chemotactic system of the bacterium Escherichia
coli. The systematic bias to swim towards
chemoattractants and away from repellents can
only be sustained if the bacterium is sensitive to
the spatial gradients of the concentration and not
to its absolute levels. This discriminative ability is
ensured by the mechanism of perfect adaptation,
with which the proportion of bacterial straight
runs and tumbles (random changes in direction)
always returns to the same value in the absence of
gradients (Block et al. 1983). Naively, however,
the ability to adapt perfectly seems to be sensitive
to the amounts of intracellular signaling proteins,
which can be tuned only approximately by means
of transcriptional regulation. Barkai and Leibler
(1997) argued that there is integral feedback con-
trol in the chemotactic circuit which makes it
robust against changes in these parameters, and
Alon et al. (1999) showed experimentally that
precision of adaptation truly stays robust, while
other properties of the systems (such as the time to
adapt and the steady state) show marked varia-
tions
with
intracellular
signaling
protein
concentrations.
One seemingly clear example of robust biolog-
ical function is embryonic development. We know
that the spatial structure of the fully developed
organism follows a ‘blueprint’ laid out early in
development as a spatial pattern of gene expres-
sion levels. von Dassow et al. (2000) studied one
part of this process in the fruit ﬂy Drosophila, the
464
Cell Biology: Networks, Regulation and Pathways

‘segment polarity network’ that generates striped
patterns of expression. They considered a dynam-
ical system based on the wiring diagram of inter-
actions among a small group of genes and
signaling molecules, with ~50 associated con-
stants parametrizing production and degradation
rates, saturation response and diffusion, and
searched the parameter space for solutions that
reproduce the known striped patterns. They
found that, with their initial guess at network
topology, such solutions do not exist, but adding
a particular link – biologically motivated though
unconﬁrmed at the time – allowed them to ﬁnd
solutions by random sampling of parameter space.
Although they presented no rigorous measure for
the volume of parameter space in which correct
solutions exist, it seems that a wide variety of
parameter choices and initial conditions indeed
produce striped expression patterns, and this was
taken to be a signature of robustness.
Robustness in dynamical models is the ability
of the biological network to sustain its trajectory
through state space despite parameter or state
perturbations. In circadian clocks the oscillations
have to be robust against both molecular noise
inherent in transcriptional regulation, examined
in stochastic simulations by Gonze et al. (2002),
as well as variation in rate parameters (Stelling
et al. 2004); in the latter work the authors intro-
duce integral robustness measures along the tra-
jectory in state space and argue that the clock
network architecture tends to concentrate the fra-
gility to perturbations into parameters that are
global to the cell (maximum overall translation
and protein degradation rates) while increasing
the robustness to processes speciﬁc to the circa-
dian oscillator. As was mentioned earlier, robust-
ness to state perturbations was demonstrated by Li
et al. (2004) in the threshold binary network
model of the yeast cell cycle, and examined in
scale-free random Boolean networks by Aldana
and Cluzel (2003).
As with modularity, robustness has been some-
what resistant to rigorous deﬁnitions. Importantly,
robustness has always been used as a relational
concept: function X is robust to variations in Y. An
alternative to robustness is for the organism to
exert precise control over Y, perhaps even using
X as a feedback signal. This seems to be how
neurons stabilize a functional mix of different
ion channels (Marder and Bucher 2006), follow-
ing
the
original
theoretical
suggestion
of
LeMasson et al. (1993). Pattern formation during
embryonic development in Drosophila begins
with spatial gradients of transcription factors,
such as Bicoid, which are established by maternal
gene expression, and it has been assumed that
variations in these expression levels are inevita-
ble, requiring some robust readout mechanism.
Recent measurements of Bicoid in live embryos,
however, demonstrate that the absolute concentra-
tions are actually reproducible from embryo to
embryo with ~10% precision (Gregor et al.
2007a).While there remain many open questions,
these results suggest that organisms may be able
to exert surprisingly exact control over critical
parameters, rather than having compensation
schemes for initially sloppy mechanisms. The
example of ion channels alerts us to the possibility
that cells may even ‘know’ which combinations of
parameters are critical, so that variations in a
multidimensional parameter space are large, but
conﬁned to a low dimensional manifold.
Noise
A dynamical system with constant reaction rates,
starting repeatedly from the same initial condition
in a stable environment, always follows a deter-
ministic time evolution. When the concentrations
of the reacting species are low enough, however,
the description in terms of time (and possibly
space) dependent concentration breaks down,
and the stochasticity in reactions, driven by ran-
dom encounters between individual molecules,
becomes important: on repeated trials from the
same initial conditions, the system will trace out
different trajectories in the state space. As has
been pointed out in the section on stochastic
dynamics, biological networks in this regime
need to be simulated with the Gillespie algorithm
(Gillespie 1977), or analyzed within approximate
schemes that treat noise as perturbation of deter-
ministic dynamics. Recent experimental develop-
ments have made it possible to observe this noise
directly, spurring new research in the ﬁeld. Noise
in biological networks fundamentally limits the
Cell Biology: Networks, Regulation and Pathways
465

organism’s ability to sense, process and respond
to environmental and internal signals, suggesting
that analysis of noise is a crucial component in
any attempt to understand the design of these
networks. This line of reasoning is well developed
in the context of neural function (Bialek 1987),
and we draw attention in particular to work on the
ability of the visual system to count single pho-
tons, which depends upon the precision of the
G-protein mediated signaling cascade in photo
receptors;
see,
for
example,
(Ramanathan
et al. 2005).
Because transcriptional regulation inherently
deals with molecules, such as DNA and transcrip-
tion factors, that are present at low copy numbers,
most noise studies were carried out on transcrip-
tional regulatory elements. The availability of
ﬂuorescent proteins and their fusions to wild
type proteins have been the crucial tools, enabling
researchers to image the cells expressing these
probes in a controllable manner, and track their
number in time and across the population of cells.
Elowitz et al. (2002) pioneered the idea of observ-
ing the output of two identical regulatory elements
driving the expression of two ﬂuorescent proteins
of different colors, regulated by a common input
in a single Escherichia coli cell. In this ‘two-color
experiment,’ the correlated ﬂuctuations in both
colors must be due to the extrinsic ﬂuctuations in
the common factors that inﬂuence the production
of both proteins, such as overall RNA polymerase
or transcription factor levels; on the other hand,
the remaining, uncorrelated ﬂuctuation is due to
the intrinsic stochasticity in the transcription of
the gene and translation of the messenger RNA
into the ﬂuorescent protein from each of the two
promoters (Swain et al. 2002). Ozbudak et al.
(2002)
have
studied
the
contributions
of
stochasticity in transcription and translation to
the total noise in gene expression in prokaryotes,
while Pedraza and van Oudenaarden (2005) and
Hooshangi et al. (2005) have looked at the prop-
agation of noise from transcription factors to their
targets
in
synthetic
multi-gene
cascades.
Rosenfeld et al. (2005) have used the statistics of
binomial partitioning of proteins during the divi-
sion of Escherichia coli to convert their ﬂuores-
cence
measurements
into
the
corresponding
absolute protein concentrations, and also were
able to observe the dynamics of these ﬂuctuations,
characterizing the correlation times of both intrin-
sic and extrinsic noise.
Theoretical work has primarily been concerned
with disentangling and quantifying the contribu-
tions of different steps in transcriptional regula-
tion and gene expression to the total noise in the
regulated gene (Paulsson 2004; Swain 2004;
Thattai and van Oudenaarden 2001), often by
looking for signatures of various noise sources in
the behavior of the measured noise as a function
of the mean expression level of a gene. For many
of the examples studied in prokaryotes, noise
seemed to be primarily attributable to the produc-
tion of proteins in bursts from single messenger
RNA molecules, and to pulsatile and random acti-
vation of genes and therefore bursty translation
into mRNA (Golding et al. 2005). In yeast (Blake
et al. 2003; Raser and O’Shea 2005) and in mam-
malian cells (Raj et al. 2006) such stochastic syn-
thesis of mRNA was modeled and observed as
well. Simple scaling of noise with the mean was
observed in ~40 yeast proteins under different
conditions
by
Bar-Even
et
al.
(2006)
and
interpreted as originating in variability in mRNA
copy numbers or gene activation.
Bialek and Setayeshgar (2005) have demon-
strated theoretically that at low concentrations of
transcriptional regulator, there should be a lower
bound on the noise set by the basic physics of
diffusion of transcription factor molecules to the
DNA binding sites. This limit is independent of
(possibly complex, and usually unknown) molec-
ular details of the binding process; as an example,
cooperativity enhances the ‘sensitivity’ to small
changes in concentration, but doesn’t lower the
physical limit to noise performance (Bialek and
Setayeshgar 2006). This randomness in diffusive
ﬂux of factors to their ‘detectors’ on the DNA
must ultimately limit the precision and reliability
of transcriptional regulation, much like the ran-
domness in diffusion of chemoattractants to the
detectors on the surface of Escherichia coli limits
its chemotactic performance (Berg and Purcell
1977). Interestingly, one dimensional diffusion
of transcription factors along the DNA can have
a big impact on the speed with which TFs ﬁnd
466
Cell Biology: Networks, Regulation and Pathways

their targets, but the change in noise performance
that one might expect to accompany these kinetic
changes is largely compensated by the extended
correlation structure of one dimensional diffusion
(Tkačik and Bialek 2007). Recent measurements
of the regulation of the hunchback gene by Bicoid
during early fruit ﬂy development by Gregor et al.
(2007a) have provided evidence for the dominant
role of such input noise, which coexists with pre-
viously studied output noise in production of
mRNA and protein (Tkačik et al. 2008c). These
results raise the possibility that initial decisions in
embryonic development are made with a preci-
sion limited by fundamental physical principles.
Dynamics, Attractors, Stability and
Large Fluctuations
The behavior of a dynamical system as the time
tends to inﬁnity, in response to a particular input,
is interesting regardless of the nature of the net-
work model. Both discrete and continuous, or
deterministic and noisy, systems can settle into a
number of ﬁxed points, exhibit limit-cycle oscil-
lations, or execute chaotic dynamics. In biological
networks it is important to ask whether these
qualitatively different outcomes correspond to
distinct phenotypes or behaviors. If so, then a
speciﬁc stable gene expression proﬁle in a net-
work of developmental genes, for example,
encodes that cell’s developmental fate, as the
amount of lambda repressor encodes the state of
lysis vs lysogeny switch in the phage. The history
of the system that led to the establishment of a
speciﬁc steady state would not matter as long as
the system persisted in the same attractor: the
dynamics could be regarded as a ‘computation’
leading to the ﬁnal result, the identity of the
attractor, with the activities of genes in this steady
state in turn driving the downstream pathways and
other modules; see Kauffman (1969) for genetic
networks and Hopﬁeld (1982) for similar ideas in
neural networks for associative memory. Alterna-
tively, such partitioning into transient dynamics
and ‘meaningful’ steady states might not be pos-
sible: the system must be analyzed as a whole
while it moves in state space, and parts of it do
not separately and sequentially settle into their
attactors.
It seems, for example, that qualitative behavior
of the cell cycle can be understood by progression
through well-deﬁned states or checkpoints: after
transients die away, the cell cycle proteins are in a
‘consistent’ state that regulates division or growth
related activities, so long as the conditions do not
warrant a new transition into the next state (Chen
et al. 2000; Nasmyth 1996). In the fruit ﬂy Dro-
sophila development it has been suggested that
combined processes of diffusion and degradation
ﬁrst establish steady-state spatial proﬁles of
maternal morphogens along the major axis of the
embryo, after which this stable ‘coordinate sys-
tem’ is read out by gap and other downstream
genes to generate the body segments. Recent mea-
surements by Gregor et al. (2007b) have shown
that there is a rich dynamics in the Bicoid mor-
phogens concentration, prompting Bergmann
et al. (2007) to hypothesize that perhaps down-
stream genes read out and respond to morphogens
even before the steady state has been reached. On
another note, an interesting excitable motif, called
the “feedback resistor,” has been found in HIV Tat
system – instead of having a bistable switch like
the l phage, HIV (which lacks negative feedback
capability) implements a circuit with a single sta-
ble ‘off’ lysogenic state, that is perturbed in a
pulse of trans activation when the virus attacks.
The pulse probably triggers a threshold-crossing
process that drives downstream events, and sub-
sequently decays away; the feedback resistor is
thus again an example of a dynamic, as opposed to
the steady-state, readout (Weinberger and Shenk
2007). Excitable dynamics are of course at the
heart of the action potential in neurons, which
results from the coupled dynamics of ion channel
proteins, and related dynamical ideas are now
emerging
other
cellular
networks
(Süel
et al. 2006).
If attractors of the dynamical system corre-
spond to distinct biological states of the organism,
it is important to examine their stability against
noise-induced spontaneous ﬂipping. Bistable ele-
ments are akin to the ‘ﬂip-ﬂop’ switches in com-
puter chips – they form the basis of cellular
(epigenetic) memory. While this mechanism for
Cell Biology: Networks, Regulation and Pathways
467

remembering the past is not unique – for example,
a very slow, but not bistable, dynamics will also
retain ‘memory’ of the initial condition through
protein levels that persist on a generation time
scale (Sigal et al. 2006), it has the potential to be
the most stable mechanism. The naturally occur-
ring bistable switch of the l phage was studied
using stochastic simulation by Arkin et al. (1998),
and a synthetic toggle switch was constructed in
Escherichia coli by Gardner et al. (2000). Theo-
retical studies of systems where large ﬂuctuations
are important are generally difﬁcult and restricted
to simple regulatory elements, but Bialek (2001)
has shown that a bistable switch can be created
with as few as tens of molecules yet remain stable
for years. A full understanding of such stochastic
switching brings in powerful methods from statis-
tical physics and ﬁeld theory (Roma et al. 2005;
Sasai and Wolynes 2003; Walczak et al. 2005),
ultimately with the hope of connecting to quanti-
tative experiments (Acar et al. 2005).
Optimization Principles
If the function of a pathway or a network module
can be quantiﬁed by a scalar measure, it is possi-
ble to explore the space of networks that perform
the given function optimally. An example already
given was that of maximizing the growth rate of
the bacterium Escherichia coli, subject to the con-
straints imposed by the known metabolic reac-
tions of the cell; the resulting optimal joint usage
of oxygen and food could be compared to the
experiments (Ibarra et al. 2002). If enough con-
straints exist for the problem to be well posed, and
there is sufﬁcient reason to believe that evolution
drove the organism towards optimal behavior,
optimization principles allow us to both tune the
otherwise unknown parameters to achieve the
maximum, and also to compare the wild type
and optimal performances.
Dekel and Alon (2005) have performed the
cost/beneﬁt analysis of expressing lac operon in
bacteria.
On
one
hand
lac
genes
allow
Escherichia coli to digest lactose, but on the
other there is the incurred metabolic cost to the
cell for expressing them. That the cost is not
negligible to the bacterium is demonstrated best
by the fact that it shuts off the operon if no lactose
is present in the environment. The cost terms are
measured by inducing the lac operon with
changeable amount of IPTG that provides no
energy in return; the beneﬁt is measured by fully
inducing lac with IPTG and supplying variable
amounts of lactose; both cost and beneﬁt are in
turn expressed as the change in the growth rate
compared to the wild-type grown at ﬁxed condi-
tions. Optimal levels of lac expression were then
predicted as a function of lactose concentration
and bacteria were evolved for several hundred
generations to verify that evolved organisms lie
close to the predicted optimum.
Zaslaver et al. (2004) have considered a cascade
of amino-acid biosynthesis reactions in Escherichia
coli, catalyzed by their corresponding enzymes.
They have then optimized the parameters of the
model that describes the regulation of enzyme
gene expression, such that the total metabolic cost
for enzyme production was balanced against the
beneﬁt of achieving a desired metabolic ﬂux
through the biosynthesis pathway. The resulting
optimal on-times and promoter activities for the
enzymes were compared to the measured activities
of amino-acid biosynthesis promoters exposed to
different amino-acids in the medium. The authors
conclude that the bacterium implements a ‘just-in-
time’ transcription program, with enzymes catalyz-
ing initial steps in the pathway being produced
from strong and low-latency promoters.
In signal transduction networks the deﬁnition
of an objective function to be maximized is some-
what more tricky. The ability of the cell to sense
its environment and make decisions, for instance
about which genes to up- or down-regulate, is
limited by several factors: scarcity of signals com-
ing from the environment, perhaps because of the
limited time that can be dedicated to data collec-
tion; noise inherent in the signaling network that
degrades the quality of the detected signal; (sub-)
optimality of the decision strategy; and noise in
the effector systems at the output. A ﬁrst idea
would be to postulate that networks are designed
to lower the noise, and intuitively the ubiquity of
mechanisms such as negative feedback (Becskei
and Serrano 2000; Goulian 2004) is consistent
with such an objective. There are various deﬁni-
tions for noise, however, which in addition are
468
Cell Biology: Networks, Regulation and Pathways

generally a function of the input, raising serious
issues about how to formulate a principled opti-
mization criterion.
When we think about energy ﬂow in biological
systems, there is no doubt that our thinking must at
least be consistent with thermodynamics. More
strongly, thermodynamics provides us with notions
of efﬁciency that place the performance of biolog-
ical systems on an absolute scale, and in many
cases this performance really is quite impressive.
In contrast, most discussions of information in
biological systems leave “information” as a collo-
quial term, making no reference to the formal
apparatus of information theory as developed by
Shannon and others more than ﬁfty years ago
(Shannon 1948). Although many aspects of infor-
mation theory that are especially important for
modern technology (e. g., sophisticated error-
correcting codes) have no obvious connection to
biology, there is something at the core of informa-
tion theory that is vital: Shannon proved that if we
want to quantify the intuitive concept that “x pro-
vides information about y,” then there is only one
way to do this that is guaranteed to work under all
conditions and to obey simple intuitive criteria
such as the additivity of independent information.
This unique measure of “information” is Shannon’s
mutual information. Further, there are theorems in
information theory which, in parallel to results in
thermodynamics, provide us with limits to what is
possible and with notions of efﬁciency.
There is a long history of using information
theoretic ideas to analyze the ﬂow of information
in the nervous system, including the idea that
aspects of the brain’s coding strategies might be
chosen to optimize the efﬁciency of coding, and
these theoretical ideas have led directly to interest-
ing experiments. The use of information to think
about cellular signaling and its possible optimiza-
tion is more recent (Tkačik et al. 2008a; Ziv et al.
2006). An important aspect of optimizing informa-
tion ﬂow is that the input/output relations of signal-
ing devices must be matched to the distribution of
inputs, and recent measurements on the control of
hunchback by Bicoid in the early fruit ﬂy embryo
(Gregor et al. 2007a) seem remarkably consistent
with the (parameter free) predictions from these
matching relations (Tkačik et al. 2008b).
In the context of neuroscience there is a long
tradition of forcing the complex dynamics of sig-
nal processing into a setting where the subject
needs to decide between a small set of alterna-
tives; in this limit there is a well developed theory
of optimal Bayesian decision making, which uses
prior knowledge of the possible signals to help
overcome noise intrinsic to the signaling system;
Libby et al. (2007) have recently applied this
approach to the lac operon in Escherichia coli.
The regulatory element is viewed as an inference
module that has to ‘decide,’ by choosing its induc-
tion level, if the environmental lactose concentra-
tion is high or low. If the bacterium detects a
momentarily high sugar concentration, it has to
discriminate between two situations: either the
environment really is at low overall concentration
but there has been a large ﬂuctuation; or the envi-
ronment has switched to a high concentration
mode. The authors examine how plausible regu-
latory element architectures (e. g. activator vs
repressor, cooperative binding etc.) yield different
discrimination performance. Intrinsic noise in the
lac system can additionally complicate such deci-
sion making, but can be included into the theoret-
ical Bayesian framework.
The question of whether biological systems are
optimal in any precise mathematical sense is
likely to remain controversial for some time. Cur-
rently opinions are stronger than the data, with
some
investigators
using
‘optimized’
rather
loosely and others convinced that what we see
today is only a historical accident, not organizable
around such lofty principles. We emphasize, how-
ever, that attempts to formulate optimization prin-
ciples require us to articulate clearly what we
mean by “function” in each context, and this is
an important exercise. Exploration of optimiza-
tion principles also exposes new questions, such
as the nature of the distribution of inputs to sig-
naling systems, that one might not have thought to
ask otherwise. Many of these questions remain as
challenges for a new generation of experiments.
Evolvability and Designability
Kirschner and Gerhart (1998) deﬁne evolvability
as an organism’s capacity to generate heritable
phenotypic variation. This capacity may have
Cell Biology: Networks, Regulation and Pathways
469

two components: ﬁrst, to reduce the lethality of
mutations, and second, to reduce the number of
mutations needed to produce phenotypically
novel traits. The systematic study of evolvability
is hard because the genotype-to-phenotype map is
highly nontrivial, but there have been some qual-
itative observations relevant to biological net-
works. Emergence of weak linkage of processes,
such as the co-dependence of transcription factors
and their DNA binding sites in metazoan tran-
scriptional regulation, is one example. Metazoan
regulation seems to depend on combinatorial con-
trol by many transcription factors with weak
DNA-binding speciﬁcities and the corresponding
binding sites (called cis-regulatory modules) can
be dispersed and extended on the DNA. This is in
stark contrast to the strong linkage between the
factors and the DNA in prokaryotic regulation or
in metabolism, energy transfer or macromolecular
assembly, where steric and complementarity
requirements for interacting molecules are high.
In protein signaling networks, strongly conserved
but ﬂexible proteins, like calmodulin, can bind
weakly to many other proteins, with small muta-
tions in their sequence probably affecting such
binding and making the establishment of new
regulatory links possible and perhaps easy.
Some of the most detailed attempts to follow
the evolution of network function have been by
Francois and coworkers (Francois and Hakim
2004; Francois et al. 2007). In their initial work
they showed how simple functional circuits,
performing logical operations or implementing
bistable or oscillatory behavior, can be reliably
created by a mutational process with selection by
an appropriate ﬁtness function. More recently
they have considered ﬁtness functions which
favor spatial structure in patterns of gene expres-
sion, and shown how the networks that emerge
from dynamics in this ﬁtness landscape recapitu-
late the outlines of the segmentation networks
known
to
be
operating
during
embryonic
development.
Instead of asking if there exists a network of
nodes such that they perform a given computation,
and if it can be found by mutation and selection as
in the examples above, one can ask how many
network topologies perform a given computation.
In other words, one is asking whether there is only
one (ﬁne tuned?) or many topologies or solutions to
a given problem. The question of how many net-
work topologies, proxies for different genotypes,
produce the same dynamics, a proxy for pheno-
type, is a question of designability, a concept orig-
inally proposed to study the properties of amino-
acid sequences comprising functional proteins, but
applicable also to biological regulatory networks
(Nochomovitz and Li 2006). The authors examine
three- and four-node binary networks with thresh-
old updating rule and show that all networks with
the shared phenotype have a common ‘core’ set of
connections, but can differ in the variable part,
similar to protein folding where the essential set
of residues is necessary for the fold, with numerous
variations in the nonessential part.
Future Directions
The study of biological networks is at an early
stage, both on the theoretical as well as on
the experimental side. Although high-throughput
experiments are generating large data sets, these
can suffer from serious biases, lack of temporal or
spatial detail, and limited access to the component
parts of the interacting system. On a theoretical
front, general analytical insights that would link
dynamics with network topology are few, although
for speciﬁc systems with known topology com-
puter simulation can be of great assistance. There
can be confusion about which aspects of the
dynamical model have biological signiﬁcance and
interpretation, and which aspects are just ‘tempo-
rary variables’ and the ‘envelope’ of the proverbial
back-of-the-envelope calculations that cells use to
perform their biological computations on; which
parts of the trajectory are functionally constrained
and which ones could ﬂuctuate considerably with
no ill-effects; how much noise is tolerable in the
nodes of the network and what is its correlation
structure; or how the unobserved, or ‘hidden,’
nodes (or their modiﬁcation/activity states) inﬂu-
ence the network dynamics.
Despite these caveats, cellular networks have
some advantages over biological systems of com-
parable complexity, such as neural networks. Due
470
Cell Biology: Networks, Regulation and Pathways

to technological developments, we are consider-
ably closer to the complete census of the
interacting molecules in a cell than we are gener-
ally to the picture of connectivity of the neural
tissue. Components of the regulatory networks are
simpler than neurons, which are capable of a
range of complicated behaviors on different time-
scales. Modules and pathways often comprise
smaller number of interacting elements than in
neural networks, making it possible to design
small but interesting synthetic circuits. Last but
not least, sequence and homology can provide
strong insights or be powerful tools for network
inference in their own right.
Those of us who come from the traditionally
quantitative sciences, such as physics, were raised
with experiments in which crucial elements are
isolated and controlled. In biological systems,
attempts at such isolation may break the regula-
tory mechanisms that are essential for normal
operation of the system, leaving us with a system
which is in fact more variable and less controlled
than we would have if we faced the full complex-
ity of the organism. It is only recently that we have
seen the development of experimental techniques
that allow fully quantitative, real time measure-
ments of the molecular events inside individual
cells, and the theoretical framework into which
such measurements will be ﬁt still is being
constructed. The range of theoretical approaches
being explored is diverse, and it behooves us to
search for those approaches which have the
chance to organize our understanding of many
different systems rather than being satisﬁed with
models of particular systems. Again, there is a
balance between the search for generality and
the need to connect with experiments on speciﬁc
networks. We have tried to give some examples of
all these developments, hopefully conveying the
correct
combination
of
enthusiasm
and
skepticism.
Acknowledgments We thank our colleagues and collab-
orators who have helped us learn about these issues: MJ
Berry, CG Callan, T Gregor, JB Kinney, P Mehta, SE
Palmer,
E
Schneidman,
JJ
Hopﬁeld,
T
Mora,
S Setayeshgar, N Slonim, GJ Stephens, DW Tank,
N Tishby, A Walczak, EF Wieschaus, CH Wiggins and
NS Wingreen. Our work was supported in part by NIH
grants P50 GM071508 and R01 GM077599, by NSF
Grants IIS–0613435 and PHY–0650617, by the Swartz
Foundation, and by the Burroughs Wellcome Fund.
Bibliography
Acar M, Becksei A, van Oudenaarden A (2005) Enhance-
ment of cellular memory by reducing stochastic transi-
tions. Nature 435:228–232
Ackers GK, Johnson AD, Shea MA (1982) Quantitative
model for gene regulation by lambda phage repressor.
Proc Natl Acad Sci U S A 79(4):1129–1133
Albert R, Jeong H, Barabasi AL (2000) Error and attack
tolerance of complex networks. Nature 406(6794):
378–382
Aldana M, Cluzel P (2003) A natural class of robust net-
works. Proc Natl Acad Sci U S A 100:8710–8714
Alm E, Arkin AP (2003) Biological networks. Curr Opin
Struct Biol 13(2):193–202
Alon U, Surette MG, Barkai N, Leibler S (1999) Robust-
ness in bacterial chemotaxis. Nature 397(6715):
168–171
Arkin A, Ross J, McAdams HH (1998) Stochastic kinetic
analysis of developmental pathway bifurcation in
phage lambda-infected escherichia coli cells. Genetics
149(4):1633–1648
Arnosti
DN,
Kulkarni
MM
(2005)
Transcriptional
enhancers: intelligent enhanceosomes or ﬂexible bill-
boards? J Cell Biochem 94(5):890–898
Barabási AL (2002) Linked: the new science of networks.
Perseus Publishing, Cambridge
Barabasi AL, Albert R (1999) Emergence of scaling in
random networks. Science 286(5439):509–512
Barabasi AL, Oltvai ZN (2004) Network biology: under-
standing the cell’s functional organization. Nat Rev
Genet 5(2):101–113
Bar-Even A, Paulsson J, Maheshri N, Carmi M, O’Shea E,
Pilpel Y, Barkai N (2006) Noise in protein expression
scales with natural protein abundance. Nat Genet 38(6):
636–643
Barkai N, Leibler S (1997) Robustness in simple biochem-
ical networks. Nature 387(6636):913–917
Baylor DA, Lamb TD, Yau KW (1979) Responses of
retinal rods to single photons. J Physiol Lond 288:
613–634
Becskei A, Serrano L (2000) Engineering stability in gene
networks by autoregulation. Nature 405(6786):590–593
Berg HC (1975) Chemotaxis in bacteria. Annu Rev
Biophys Bioeng 4(00):119–136
Berg HC, Purcell EM (1977) Physics of chemoreception.
Biophys J 20(2):193–219
Bergmann S, Sandler O, Sberro H, Shnider S, Schejter E,
Shilo BZ, Barkai N (2007) Pre-steady-state decoding of
the bicoid morphogen gradient. PLoS Biol 5(2):e46
Bethe HA (1935) Statistical theory of superlattices. Proc
R Soc London Ser A 150:552–575
Bialek W (1987) Physical limits to sensation and percep-
tion. Annu Rev Biophys Biophys Chem 16:455–478
Cell Biology: Networks, Regulation and Pathways
471

Bialek W (2001) Stability and noise in biochemical
switches. Adv Neurol Inform Process Syst 13:103
Bialek W, Setayeshgar S (2005) Physical limits to bio-
chemical
signaling.
Proc
Natl
Acad
Sci
U
S
A 102(29):10040–10045
Bialek W, Setayeshgar S (2006) Cooperativity, sensitivity
and noise in biochemical signaling. arXiv.org:q-bio.
MN/0601001
Bintu L, Buchler NE, Garcia HG, Gerland U, Hwa T,
Kondev J, Kuhlman T, Phillips R (2005a) Transcrip-
tional regulation by the numbers: applications. Curr
Opin Genet Dev 15(2):125–135
Bintu L, Buchler NE, Garcia HG, Gerland U, Hwa T,
Kondev J, Phillips R (2005b) Transcriptional regula-
tion by the numbers: models. Curr Opin Genet Dev
15(2):116–124
Blake WJ, Kaern M, Cantor CR, Collins JJ (2003) Noise in
eukaryotic
gene
expression.
Nature
422(6932):
633–637
Block SM, Segall JE, Berg HC (1983) Adaptation kinetics
in bacterial chemotaxis. J Bacteriol 154(1):312–323
Bray D (1995) Protein molecules as computational ele-
ments in living cells. Nature 376(6538):307–312
Bray D, Bourret RB, Simon MI (1993) Computer simula-
tion of the phosphorylation cascade controlling bacte-
rial chemotaxis. Mol Biol Cell 4(5):469–482
Brown PO, Botstein D (1999) Exploring the new world of
the genome with DNA microarrays. Nat Genet
21(1 Suppl):33–37
Buchler NE, Gerland U, Hwa T (2003) On schemes of
combinatorial transcription logic. Proc Natl Acad Sci
U S A 100(9):5136–5141
Chang L, Karin M (2001) Mammalian map kinase signal-
ling cascades. Nature 410(6824):37–40
Chen KC, Csikasz-Nagy A, Gyorffy B, Val J, Novak B,
Tyson JJ (2000) Kinetic analysis of a molecular model
of the budding yeast cell cycle. Mol Biol Cell 11(1):
369–391
de Visser JA, Hermisson J, Wagner GP, Ancel Meyers L,
Bagheri-Chaichian H, Blanchard JL, Chao L, Cheverud
JM, Elena SF, Fontana W, Gibson G, Hansen TF,
Krakauer D, Lewontin RC, Ofria C, Rice SH, von
Dassow G, Wagner A, Whitlock MC (2003) Perspec-
tive: evolution and detection of genetic robustness.
Evol Int J Org Evol 57(9):1959–1972
Dekel E, Alon U (2005) Optimality and evolutionary
tuning of the expression level of a protein. Nature
436(7050):588–592
Eisen MB, Spellman PT, Brown PO, Botstein D (1998)
Cluster analysis and display of genome-wide expres-
sion patterns. Proc Natl Acad Sci U S A 95(25):
14863–14868
Elemento O, Slonim N, Tavazoie S (2007) A universal
framework for regulatory element discovery across all
genomes and data types. Mol Cell 28(2):337–350
Elowitz MB, Leibler S (2000) A synthetic oscillatory net-
work of transcriptional regulators. Nature 403(6767):
335–338
Elowitz MB, Levine AJ, Siggia ED, Swain PS (2002) Sto-
chastic gene expression in a single cell. Science
297(5584):1183–1186
Falke JJ, Bass RB, Butler SL, Chervitz SA, Danielson MA
(1997) The two-component signaling pathway of bac-
terial chemotaxis: a molecular view of signal transduc-
tion by receptors, kinases, and adaptation enzymes.
Annu Rev Cell Dev Biol 13:457–512
Francois P, Hakim V (2004) Design of genetic networks
with speciﬁed functions by evolution in silico. Proc
Natl Acad Sci U S A 101(2):580–585
Francois P, Hakim V, Siggia ED (2007) Deriving structure
from evolution: metazoan segmentation. Mol Syst Biol
3: Article 154
Friedman N (2004) Inferring cellular networks using
probabilistic graphical models. Science 303(5659):
799–805
Gardner TS, Cantor CR, Collins JJ (2000) Construction of
a genetic toggle switch in Escherichia coli. Nature
403(6767):339–342
Gavin AC, Bosche M, Krause R, Grandi P, Marzioch M,
Bauer A, Schultz J, Rick JM, Michon AM, Cruciat CM,
Remor M, Hofert C, Schelder M, Brajenovic M,
Ruffner H, Merino A, Klein K, Hudak M, Dickson D,
Rudi T, Gnau V, Bauch A, Bastuck S, Huhse B,
Leutwein C, Heurtier MA, Copley RR, Edelmann A,
Querfurth
E,
Rybin
V,
Drewes
G,
Raida
M,
Bouwmeester T, Bork P, Seraphin B, Kuster B,
Neubauer G, Superti-Furga G (2002) Functional orga-
nization of the yeast proteome by systematic analysis of
protein complexes. Nature 415(6868):141–147
Ghaemmaghami S, Huh WK, Bower K, Howson RW,
Belle A, Dephoure N, O’Shea EK, Weissman JS
(2003) Global analysis of protein expression in yeast.
Nature 425(6959):737–741
Gillespie DT (1977) Exact stochastic simulation of coupled
chemical reactions. J Phys Chem 81:2340–2361
Gillespie DT (2007) Stochastic simulation of chemical
kinetics. Annu Rev Phys Chem 58:35–55
Giot L, Bader JS, Brouwer C, Chaudhuri A, Kuang B, Li Y,
Hao
YL,
Ooi
CE,
Godwin
B,
Vitols
E,
Vijayadamodar G, Pochart P, Machineni H, Welsh M,
Kong Y, Zerhusen B, Malcolm R, Varrone Z, Collis A,
Minto M, Burgess S, McDaniel L, Stimpson E,
Spriggs F, Williams J, Neurath K, Ioime N, Agee M,
Voss E, Furtak K, Renzulli R, Aanensen N, Carrolla S,
Bickelhaupt E, Lazovatsky Y, DaSilva A, Zhong J,
Stanyon CA, Finley JRL, White KP, Braverman M,
Jarvie T, Gold S, Leach M, Knight J, Shimkets RA,
McKenna MP, Chant J, Rothberg JM (2003) A protein
interaction map of Drosophila melanogaster. Science
5651:1727–1736
Golding I, Paulsson J, Zawilski SM, Cox EC (2005) Real-
time kinetics of gene activity in individual bacteria.
Cell 123(6):1025–1036
Goldman MS, Golowasch J, Marder E, Abbott LF
(2001) Global structure robustness and modulation of
neural models. J Neurosci 21:5229–5238
472
Cell Biology: Networks, Regulation and Pathways

Gonze D, Halloy J, Goldbeter A (2002) Robustness of
circadian rhythms with respect to molecular noise.
Proc Natl Acad Sci U S A 99(2):673–678
Goulian M (2004) Robust control in bacterial regulatory
circuits. Curr Opin Microbiol 7(2):198–202
Gregor T, Tank DW, Wieschaus EF, Bialek W (2007a)
Probing the limits to positional information. Cell
130(1):153–164
Gregor T, Wieschaus EF, McGregor AP, Bialek W, Tank
DW (2007b) Stability and nuclear dynamics of the
bicoid morphogen gradient. Cell 130(1):141–152
Guet CC, Elowitz MB, Hsing W, Leibler S (2002) Combi-
natorial
synthesis
of
genetic
networks.
Science
296(5572):1466–1470
Han JD, Bertin N, Hao T, Goldberg DS, Berriz GF, Zhang
LV, Dupuy D, Walhout AJ, Cusick ME, Roth FP, Vidal
M (2004) Evidence for dynamically organized modu-
larity in the yeast protein-protein interaction network.
Nature 430(6995):88–93
Hartwell LH, Hopﬁeld JJ, Leibler S, Murray AW
(1999) From molecular to modular cell biology. Nature
402(6761 Suppl):C47–C52
Hasty J, McMillen D, Isaacs F, Collins JJ (2001) Compu-
tational studies of gene regulatory networks: in numero
molecular biology. Nat Rev Genet 2(4):268–279
Heinrich R, Schuster S (1996) The regulation of cellular
systems. Chapman and Hall, New York
Ho Y, Gruhler A, Heilbut A, Bader GD, Moore L, Adams
SL, Millar A, Taylor P, Bennett K, Boutilier K, Yang L,
Wolting C, Donaldson I, Schandorff S, Shewnarane J,
Vo M, Taggart J, Goudreault M, Muskat B, Alfarano C,
Dewar D, Lin Z, Michalickova K, Willems AR,
Sassi H, Nielsen PA, Rasmussen KJ, Andersen JR,
Johansen
LE,
Hansen
LH,
Jespersen
H,
Podtelejnikov A, Nielsen E, Crawford J, Poulsen V,
Sorensen
BD,
Matthiesen
J,
Hendrickson
RC,
Gleeson F, Pawson T, Moran MF, Durocher D,
Mann M, Hogue CW, Figeys D, Tyers M (2002) Sys-
tematic identiﬁcation of protein complexes in Saccha-
romyces cerevisiae by mass spectrometry. Nature
415(6868):180–183
Hofman J, Wiggins C (2007) A bayesian approach to
network modularity. arXiv.org:07093512
Hooshangi S, Thiberge S, Weiss R (2005) Ultrasensitivity
and noise propagation in a synthetic transcriptional
cascade. Proc Natl Acad Sci U S A 102(10):3581–3586
Hopﬁeld JJ (1982) Neural networks and physical systems
with emergent collective computational abilities. Proc
Natl Acad Sci U S A 79(8):2554–2558
Huang KC, Meir Y, Wingreen NS (2003) Dynamic struc-
tures in Escherichia coli: spontaneous formation of
mine rings and mind polar zones. Proc Natl Acad Sci
U S A 100(22):12724–12728
Ibarra RU, Edwards JS, Palsson BO (2002) Escherichia coli
K-12 undergoes adaptive evolution to achieve in silico
predicted optimal growth. Nature 420(6912):186–189
Ihmels J, Friedlander G, Bergmann S, Sarig O, Ziv Y,
Barkai N (2002) Revealing modular organization in
the yeast transcriptional network. Nat Genet 31(4):
370–377
Ito T, Chiba T, Ozawa R, Yoshida M, Hattori M, Sakaki
Y (2001) A comprehensive two-hybrid analysis to
explore the yeast protein interactome. Proc Natl Acad
Sci U S A 98(8):4569–4574
Jacob F, Monod J (1961) Genetic regulatory mechanisms
in the synthesis of proteins. J Mol Biol 3:318–356
Jansen R, Gerstein M (2004) Analyzing protein function
on a genomic scale: the importance of gold-standard
positives and negatives for network prediction. Curr
Opin Microbiol 7(5):535–545
Jaynes ET (1957) Information theory and statistical
mechanics. Phys Rev 106:62–79
Jeong H, Tombor B, Albert R, Oltvai ZN, Barabasi AL
(2000) The large-scale organization of metabolic net-
works. Nature 407(6804):651–654
Jeong H, Mason SP, Barabasi AL, Oltvai ZN (2001) Lethal-
ity
and
centrality
in
protein
networks.
Nature
411(6833):41–42
Jordan JD, Landau EM, Iyengar R (2000) Signaling net-
works: the origins of cellular multitasking. Cell 103(2):
193–200
Kadonaga JT (2004) Regulation of RNA polymerase II
transcription by sequence-speciﬁc DNA binding fac-
tors. Cell 116(2):247–257
Kanehisa M, Goto S, Kawashima S, Nakaya A (2002) The
KEGG databases at genomenet. Nucleic Acids Res
30(1):42–46
Karp PD, Riley M, Saier M, Paulsen IT, Collado-Vides J,
Paley SM, Pellegrini-Toole A, Bonavides C, Gama-
Castro S (2002) The ecocyc database. Nucleic Acids
Res 30(1):56–58
Kashtan N, Alon U (2005) Spontaneous evolution of mod-
ularity and network motifs. Proc Natl Acad Sci U S
A 102(39):13773–13778
Kauffman SA (1969) Metabolic stability and epigenesis in
randomly constructed genetic nets. J Theor Biol 22(3):
437–467
Keller
EF
(2005)
Revisiting
“scale-free”
networks.
BioEssays 27(10):1060–1068
Kirschner M, Gerhart J (1998) Evolvability. Proc Natl
Acad Sci (USA) 95(15):8420–8427
Kolch W (2000) Meaningful relationships: the regulation
of the ras/raf/mek/erk pathway by protein interactions.
Biochem J 351(Pt 2):289–305
Krogan NJ, Cagney G, Yu H, Zhong G, Guo X,
Ignatchenko A, Li J, Pu S, Datta N, Tikuisis AP,
Punna T, Peregrin-Alvarez JM, Shales M, Zhang X,
Davey M, Robinson MD, Paccanaro A, Bray JE,
Sheung A, Beattie B, Richards DP, Canadien V,
Lalev A, Mena F, Wong P, Starostine A, Canete MM,
Vlasblom J, Wu S, Orsi C, Collins SR, Chandran S,
Haw R, Rilstone JJ, Gandi K, Thompson NJ, Musso G,
St Onge P, Ghanny S, Lam MH, Butland G, Altaf-Ul
AM, Kanaya S, Shilatifard A, O’Shea E, Weissman JS,
Ingles CJ, Hughes TR, Parkinson J, Gerstein M, Wodak
SJ, Emili A, Greenblatt JF (2006) Global landscape of
Cell Biology: Networks, Regulation and Pathways
473

protein
complexes
in
the
yeast
Saccharomyces
cerevisiae. Nature 440(7084):637–643
Kuhlman T, Zhang Z, Saier JMH, Hwa T (2007) Combi-
natorial transcriptional control of the lactose operon of
Escherichia coli. Proc Natl Acad Sci U S A 104(14):
6043–6048
Lee TI, Rinaldi NJ, Robert F, Odom DT, Bar-Joseph Z,
Gerber GK, Hannett NM, Harbison CT, Thompson
CM, Simon I, Zeitlinger J, Jennings EG, Murray HL,
Gordon DB, Ren B, Wyrick JJ, Tagne JB, Volkert TL,
Fraenkel E, Gifford DK, Young RA (2002) Transcrip-
tional
regulatory
networks
in
Saccharomyces
cerevisiae. Science 298(5594):799–804
Leloup JC, Goldbeter A (2003) Toward a detailed compu-
tational model for the mammalian circadian clock. Proc
Natl Acad Sci U S A 100(12):7051–7056
LeMasson G, Marder E, Abbott LF (1993) Activity-
dependent regulation of conductances in model neu-
rons. Science 259:1915–1917
Levine M, Davidson EH (2005) Gene regulatory networks
for development. Proc Natl Acad Sci U S A 102(14):
4936–4942
Lezon TR, Banavar JR, Cieplak M, Maritan A, Federoff
NV (2006) Using the principle of entropy maximiza-
tion to infer genetic interaction networks from gene
expression patterns. Proc Natl Acad Sci U S A 103:
19033–19038
Li F, Long T, Lu Y, Ouyang Q, Tang C (2004) The yeast
cellcycle network is robustly designed. Proc Natl Acad
Sci U S A 101(14):4781–4786
Libby E, Perkins TJ, Swain PS (2007) Noisy information
processing through transcriptional regulation. Proc
Natl Acad Sci U S A 104(17):7151–7156
Marder E, Bucher D (2006) Variability, compensation and
homeostasis in neuron and network function. Nat Rev
Neurosci 7:563–574
Markowetz F, Spang R (2007) Inferring cellular networks –
a review. BMC Bioinform 8:6–S5
Martin DE, Hall MN (2005) The expanding tor signaling
network. Curr Opin Cell Biol 17(2):158–166
Maslov S, Sneppen K (2002) Speciﬁcity and stability in
topology of protein networks. Science 296(5569):
910–913
McAdams HH, Arkin A (1997) Stochastic mechanisms in
gene expression. Proc Natl Acad Sci U S A 94(3):
814–819
McAdams HH, Arkin A (1999) It’s a noisy business!
Genetic regulation at the nanomolar scale. Trends
Genet 15(2):65–69
McAdams HH, Shapiro L (1995) Circuit simulation of
genetic networks. Science 269(5224):650–656
Milo R, Itzkovitz S, Kashtan N, Levitt R, Shen-Orr S,
Ayzenshtat I, Sheffer M, Alon U (2004) Superfamilies
of evolved and designed networks. Science 303(5663):
1538–1542
Nakajima M, Imai K, Ito H, Nishiwaki T, Murayama Y,
Iwasaki H, Oyama T, Kondo T (2005) Reconstitution
of
circadian
oscillation
of
cyanobacterial
KaiC
phophorylation in vitro. Science 308:414–415
Nasmyth K (1996) At the heart of the budding yeast cell
cycle. Trends Genet 12(10):405–412
Newman M, Watts D, Barabási AL (2006) The structure
and dynamics of networks. Princeton University Press,
Princeton
Nielsen UB, Cardone MH, Sinskey AJ, MacBeath G,
Sorger PK (2003) Proﬁling receptor tyrosine kinase
activation by using ab microarrays. Proc Natl Acad
Sci U S A 100(16):9330–9335
Nochomovitz YD, Li H (2006) Highly designable phe-
notypes and mutational buffers emerge from a sys-
tematic mapping between network topology and
dynamic output. Proc Natl Acad Sci U S A 103(11):
4180–4185
Novak B, Tyson JJ (1997) Modeling the control of DNA
replication in ﬁssion yeast. Proc Natl Acad Sci U S
A 94(17):9147–9152
Nurse P (2001) Cyclin dependent kinases and cell cycle
control. Les Prix Nobel
Ozbudak EM, Thattai M, Kurtser I, Grossman AD, van
Oudenaarden A (2002) Regulation of noise in the
expression of a single gene. Nat Genet 31(1):69–73
Papin JA, Hunter T, Palsson BO, Subramaniam S (2005)
Reconstruction of cellular signalling networks and
analysis of their properties. Nat Rev Mol Cell Biol
6(2):99–111
Paulsson J (2004) Summing up the noise in gene networks.
Nature 427(6973):415–418
Pedraza JM, van Oudenaarden A (2005) Noise propagation
in gene networks. Science 307(5717):1965–1969
Perez OD, Nolan GP (2002) Simultaneous measurement of
multiple active kinase states using polychromatic ﬂow
cytometry. Nat Biotechnol 20(2):155–162
Ptashne M (2001) Genes and signals. CSHL Press, Cold
Spring Harbor
Ptashne M (2004) A genetic switch: phage lambda
revisited. CSHL Press
Raj A, Peskin CS, Tranchina D, Vargas DY, Tyagi S (2006)
Stochastic mRNA synthesis in mammalian cells. PLoS
Biol 4(10):e309
Ramanathan S, Detwiler PB, Sengupta AM, Shraiman BI
(2005)
G-protein-coupled
enzyme
cascades
have
intrinsic properties that improve signal localization
and ﬁdelity. Biophys J 88(5):3063–3071
Rao CV, Kirby JR, Arkin AP (2004) Design and diversity
in bacterial chemotaxis: a comparative study in
Escherichia coli and Bacillus subtilis. PLoS Biol 2(2):
E49
Raser JM, O’Shea EK (2005) Noise in gene expression:
origins, consequences, and control. Science 309(5743):
2010–2013
Ravasz E, Somera AL, Mongru DA, Oltvai ZN, Barabasi
AL (2002) Hierarchical organization of modularity in
metabolic networks. Science 297(5586):1551–1555
Rieke F, Baylor DA (1998) Single photon detection by rod
cells of the retina. Rev Mod Phys 70:1027–1036
Roma DM, O’Flanagan R, Ruckenstein AE, Sengupta AM
(2005) Optimal path to epigenetic switching. Phys Rev
E 71:011902
474
Cell Biology: Networks, Regulation and Pathways

Rosenfeld N, Alon U (2003) Response delays and the
structure of transcription networks. J Mol Biol 329(4):
645–654
Rosenfeld N, Young JW, Alon U, Swain PS, Elowitz MB
(2005) Gene regulation at the single-cell level. Science
307(5717):1962–1965
Rual JF, Venkatesan K, Hao T, Hirozane-Kishikawa T,
Dricot A, Li N, Berriz GF, Gibbons FD, Dreze M,
Ayivi-Guedehoussou
N,
Klitgord
N,
Simon
C,
Boxem M, Milstein S, Rosenberg J, Goldberg DS,
Zhang LV, Wong SL, Franklin G, Li S, Albala JS,
Lim J, Fraughton C, Llamosas E, Cevik S, Bex C,
Lamesch P, Sikorski RS, Vandenhaute J, Zoghbi HY,
Smolyar A, Bosak S, Sequerra R, Doucette-Stamm L,
Cusick ME, Hill DE, Roth FP, Vidal M (2005) Towards
a proteome-scale map of the human protein–protein
interaction network. Nature 437(7062):1173–1178
Rust MJ, Markson JS, Lane WS, Fisher DS, O’Shea EK
(2007) Ordered phosphorylation governs oscillation
of a three-protein circadian clock. Science 318:
809–812
Sachs K, Perez O, Pe’er D, Lauffenburger DA, Nolan GP
(2005) Causal protein-signaling networks derived from
multiparameter single-cell data. Science 308(5721):
523–529
Sanchez L, Thieffry D (2001) A logical analysis of the
Drosophila gap-gene system. J Theor Biol 211(2):
115–141
Sasai M, Wolynes PG (2003) Stochastic gene expression as
a many-body problem. Proc Natl Acad Sci U S
A 100(5):2374–2379
Schneidman E, Still S, Berry MJ II, Bialek W (2003)
Network information
and connected
correlations.
Phys Rev Lett 91(23):238701
Schneidman E, Berry MJ II, Segev R, Bialek W (2006)
Weak pairwise correlations imply strongly correlated
network
states
in
a
neural
population.
Nature
440(7087):1007–1012
Schroeder MD, Pearce M, Fak J, Fan H, Unnerstall U,
Emberly E, Rajewsky N, Siggia ED, Gaul U (2004)
Transcriptional control in the segmentation gene net-
work of Drosophila. PLoS Biol 2(9):E271
Segal E, Shapira M, Regev A, Pe’er D, Botstein D,
Koller D, Friedman N (2003) Module networks: iden-
tifying regulatory modules and their condition-speciﬁc
regulators from gene expression data. Nat Genet 34(2):
166–176
Setty Y, Mayo AE, Surette MG, Alon U (2003) Detailed
map of a cis-regulatory input function. Proc Natl Acad
Sci U S A 100(13):7702–7707
Shannon CE (1948) A mathematical theory of communi-
cation. Bell Syst Tech J 27:379–423. & 623–656
Shen-Orr SS, Milo R, Mangan S, Alon U (2002) Network
motifs in the transcriptional regulation network of
Escherichia coli. Nat Genet 31(1):64–68
Shlens J, Field GD, Gauthier JL, Grivich MI, Petrusca D,
Sher A, Litke AM, Chichilnisky EJ (2006) The struc-
ture of multi-neuron ﬁring patterns in primate retina.
J Neurosci 26(32):8254–8266
Sigal A, Milo R, Cohen A, Geva-Zatorsky N, Klein Y,
Liron Y, Rosenfeld N, Danon T, Perzov N, Alon
U (2006) Variability and memory of protein levels in
human cells. Nature 444(7119):643–646
Siggia ED (2005) Computational methods for transcrip-
tional regulation. Curr Opin Genet Dev 15(2):214–221
Slonim N, Atwal GS, Tkačik G, Bialek W (2005)
Information-based clustering. Proc Natl Acad Sci
(USA) 102(51):18297–18302
Slonim N, Elemento O, Tavazoie S (2006) Ab initio
genotype-phenotype association reveals intrinsic mod-
ularity in genetic networks. Mol Syst Biol 2:0005
Spirin V, Mirny LA (2003) Protein complexes and func-
tional modules in molecular networks. Proc Natl Acad
Sci U S A 100(21):12123–12128
Stelling J, Gilles ED, Doyle FJ 3rd (2004) Robustness
properties of circadian clock architectures. Proc Natl
Acad Sci U S A 101(36):13210–13215
Strogatz SH (2001) Exploring complex networks. Nature
410(6825):268–276
Süel GM, Garcia-Ojalvo J, Liberman L, Elowitz MB
(2006) An excitable gene regulatory circuit induces
transient cellular differentiation. Nature 440:545–550
Swain PS (2004) Efﬁcient attenuation of stochasticity in
gene expression through post-transcriptional control.
J Mol Biol 344(4):965–976
Swain PS, Elowitz MB, Siggia ED (2002) Intrinsic and
extrinsic contributions to stochasticity in gene expres-
sion. Proc Natl Acad Sci U S A 99(20):12795–12800
Tanay A, Regev A, Shamir R (2005) Conservation and
evolvability in regulatory networks: the evolution of
ribosomal regulation in yeast. Proc Natl Acad Sci U S
A 102(20):7203–7208
Thattai M, van Oudenaarden A (2001) Intrinsic noise in
gene regulatory networks. Proc Natl Acad Sci U S
A 98(15):8614–8619
Thomas R (1973) Boolean formalization of genetic control
circuits. J Theor Biol 42(3):563–585
Tkačik G (2007) Information ﬂow in biological networks.
Dissertation, Princeton University, Princeton
Tkačik G, Bialek W (2007) Diffusion, dimensionality and
noise in transcriptional regulation. arXiv.org:07121852
[q-bio.MN]
Tkačik G, Schneidman E, Berry II MJ, Bialek W (2006)
Ising models for networks of real neurons. arXiv.org:
q-bio.NC/0611072
Tkačik G, Callan Jr CG, Bialek W (2008a) Information
capacity of genetic regulatory elements. Phys Rev E 78:
011910. arXiv.org:0709.4209. [q-bioMN]
Tkačik G, Callan CG Jr, Bialek W (2008b) Information
ﬂow and optimization in transcriptional regulation.
Proc Natl Acad Sci 105(34):12265–12270. arXiv.
org:0705.0313. [q-bio.MN]
Tkačik G, Gregor T, Bialek W (2008c) The role of input
noise in transcriptional regulation. PLoS One 3:e2774.
arXiv.org:qbioMN/0701002
Tomita J, Nakajima M, Kondo T, Iwasaki H (2005) No
transcription- translation feedback in circadian rhythm
of KaiC phosphorylation. Science 307:251–254
Cell Biology: Networks, Regulation and Pathways
475

Tucker CL, Gera JF, Uetz P (2001) Towards an understand-
ing of complex protein networks. Trends Cell Biol
11(3):102–106
Tyson JJ, Chen K, Novak B (2001) Network dynamics and
cell physiology. Nat Rev Mol Cell Biol 2(12):908–916
Tyson JJ, Chen KC, Novak B (2003) Sniffers, buzzers,
toggles and blinkers: dynamics of regulatory and signal-
ing pathways in the cell. Curr Opin Cell Biol 15(2):
221–231
Uetz P, Giot L, Cagney G, Mansﬁeld TA, Judson RS, Knight
JR, Lockshon D, Narayan V, Srinivasan M, Pochart P,
Qureshi-Emili A, Li Y, Godwin B, Conover D,
Kalbﬂeisch T, Vijayadamodar G, Yang M, Johnston M,
Fields S, Rothberg JM (2000) A comprehensive analysis
of
protein-protein
interactions
in
Saccharomyces
cerevisiae. Nature 403(6770):623–627
van Kampen NG (2007) Stochastic processes in physics
and chemistry. Elsevier, Amsterdam
von Dassow G, Meir E, Munro EM, Odell GM (2000) The
segment polarity network is a robust developmental
module. Nature 406(6792):188–192
von Mering C, Krause R, Snel B, Cornell M, Oliver SG,
Fields S, Bork P (2002) Comparative assessment of
large-scale data sets of protein-protein interactions.
Nature 417(6887):399–403
Wagner A, Fell DA (2001) The small world inside large
metabolic networks. Proc Biol Sci 268(1478):1803–1810
Walczak AM, Sasai M, Wolynes PG (2005) Self-consistent
proteomic ﬁeld theory of stochastic gene switches.
Biophys J 88(2):828–850
Waters CM, Bassler BL (2005) Quorum sensing: cell-to-
cell communication in bacteria. Annu Rev Cell Dev
Biol 21:319–346
Watson JD, Baker TA, Beli SP, Gann A, Levine M, Losick
R (2003) Molecular biology of the gene, 5th edn. Ben-
jamin Cummings, Menlo Park
Watts DJ, Strogatz SH (1998) Collective dynamics
of
‘small-world’
networks.
Nature
393(6684):
440–442
Weinberger LS, Shenk T (2007) An HIV feedback resistor:
auto-regulatory circuit deactivator and noise buffer.
PLoS Biol 5(1):e9
Yeger-Lotem E, Sattath S, Kashtan N, Itzkovitz S, Milo R,
Pinter RY, Alon U, Margalit H (2004) Network motifs
in
integrated
cellular
networks
of
transcription-
regulation and protein protein interaction. Proc Natl
Acad Sci U S A 101(16):5934–5939
Yokobayashi Y, Weiss R, Arnold FH (2002) Directed evo-
lution of a genetic circuit. Proc Natl Acad Sci U S
A 99(26):16587–16591
Young MW, Kay SA (2001) Time zones: a comparative
genetics of circadian clocks. Nat Rev Genet 2(9):
702–715
Zaslaver A, Mayo AE, Rosenberg R, Bashkin P, Sberro H,
Tsalyuk M, Surette MG, Alon U (2004) Just-in-time
transcription program in metabolic pathways. Nat
Genet 36(5):486–491
Ziv E, Koytcheff R, Middendorf M, Wiggins C (2005a)
Systematic identiﬁcation of statistically signiﬁcant net-
work measures. Phys Rev E 71:016110
Ziv E, Middendorf M, Wiggins C (2005b) Information
theoretic approach to network modularity. Phys Rev
E 71:046117
Ziv E, Nemenman I, Wiggins CH (2006) Optimal signal
processing in small stochastic biochemical networks.
arXiv.org:qbio/0612041
476
Cell Biology: Networks, Regulation and Pathways

Fluctuation Theorems,
Brownian Motors and
Thermodynamics of Small
Systems
Felix Ritort
Department de Fisica Fonamental, Faculty of
Physics, Universitat de Barcelona, Barcelona,
Spain
Article Outline
Glossary
Deﬁnition of the Subject
Introduction
Molecular Motors
Non-equilibrium Thermodynamics of Small
Systems
Fluctuation Theorems
Future Directions
Bibliography
Glossary
Trajectory or path A crucial concept in the sta-
tistical description of small system is that of a
trajectory or path. A path is the time sequence
of conﬁgurations followed by the system as it
is driven to a non-equilibrium state by the
action of an external perturbation.
Control parameter External perturbations are
usually described in terms of the control
parameter l. These are a set of external param-
eters (e.g. an electric ﬁeld, magnetic ﬁeld, opti-
cal force, . . .) that can be experimentally
controlled and do not ﬂuctuate. Experimen-
tally, control parameters are produced by mac-
roscopic systems that are used to manipulate
the small system under study and which are
insensitive to thermal ﬂuctuations (but that
produce other sorts of uncontrolled instrumen-
tal noises and drift effects).
Single molecule experiments (SME) Recent
technological developments have provided the
tools to design and build scientiﬁc instruments
of high enough sensitivity and precision to
manipulate and visualize individual molecules
and measure microscopic forces. Using SME it
is possible to manipulate molecules one at a time
and measure distributions describing molecular
properties, characterize the kinetics of bio-
molecular reactions, and detect molecular inter-
mediates. SME provide the additional informa-
tion about thermodynamics and kinetics of bio-
molecular processes. This complements informa-
tion obtained in traditional bulk assays. In SME it
is also possible to measure small energies and
detect
large
Brownian
deviations
in
bio-
molecular
reactions,
thereby
offering
new
methods and systems to scrutinize the basic foun-
dations of statistical mechanics. Common single
molecule experimental techniques are: atomic-
force microscopy, laser optical tweezers, mag-
netic tweezers and single-molecule ﬂuorescence.
Free energy The natural or spontaneous evolution
of any thermodynamic process is determined by
the free energy. The free energy in thermody-
namics is the equivalent of the mechanical
energy in classical mechanics. Spontaneous
transformations take place by a decrease of the
free energy in the system. In addition, mechan-
ical work must be exerted by an external agent
upon the system to increase its free energy. For
reversible processes the amount of work is equal
to the free energy change. However, in general,
processes are irreversible and the work must be
always larger than the free energy difference
(a statement of the second law of thermodynam-
ics). Free energies in small systems are typically
expressed in either work (pNnm) or energy
units (kJ/mol, kcal/mol or kB T where kB is the
Boltzmann constant and T is a reference temper-
ature – usually 298 K or 25 degrees Celsius).
The conversion factors are (T ¼ 298 K): 1 kB T
© Springer-Verlag 2009
B. Chakraborty (ed.), Statistical and Nonlinear Physics,
https://doi.org/10.1007/978-1-0716-1454-9_213
Originally published in
R. A. Meyers (ed.), Encyclopedia of Complexity and Systems Science, © Springer-Verlag 2009
https://doi.org/10.1007/978-3-642-27737-5_213
477

¼ 4.11 pN  nm ¼ 4.111021 J, 1 kB T
¼ 0.6 kcal/mol ¼ 2.4 kJ/mol.
ATP Acronym for adenosine triphosphate, the
molecule that carries the energy necessary to
sustain life processes. ATP is made of one aden-
osine base weakly bonded to three phosphate
groups. Upon conversion (by hydrolysis) to
ADP (adenosine diphosphate) and inorganic
phosphate or AMP (adenosine monophosphate)
and pirophosphate (P-P), ATP delivers a con-
siderable amount of free energy (in the range
8–12 kcal/mol, depending on buffer condi-
tions). By coupling to other reactions, ATP
hydrolysis supplies the energy necessary to
carry out unfavorable transformations.
RNA RNA (ribonucleic acid) is a very important
player in molecular biology that shows biolog-
ical functions in between those attributed to
DNA and proteins. For the biophysicist and
the statistical physicist RNA is also a fascinat-
ing molecule. Primarily found in nature in sin-
gle stranded form, RNA folds into a three
dimensional structure mainly stabilized by
stacking interactions and hydrogen bonds
between complementary bases (A-U,G-C).
Full complementarity between different RNA
segments is often impossible so, at difference
with DNA, RNA structure includes also mis-
matches between bases as well other structural
defects (bulges, loops, junctions, . . .). In addi-
tion to Watson-Crick base pairing, RNA forms
a compact structure through speciﬁc interac-
tions mediated by magnesium ions that bring
together distal RNA segments.
Definition of the Subject
The thermodynamics of small systems describes
energy exchange processes between a system
and its environment in the low energy range of
a few kB T where Brownian ﬂuctuations are dom-
inant (Bustamante et al. 2005). The main goal of
this discipline is to identify the building blocks of
a general theory describing energy ﬂuctuations in
non-equilibrium processes occurring in systems
ranging from condensed matter physics to
biophysics.
Thermodynamics,
a
scientiﬁc
discipline
inherited from the eighteenth century, is facing
new challenges
in the description of non-
equilibrium small (sometimes also called meso-
scopic) systems. Thermodynamics is a discipline
built in order to explain and interpret energetic
processes occurring in macroscopic systems
made out of a large number of molecules on the
order of the Avogadro number. The subsequent
development of statistical mechanics has provided
a solid probabilistic basis to thermodynamics and
increased its predictive power at the same time.
The development of statistical mechanics goes
together with the establishment of the molecular
hypothesis. Matter is made out of interacting mol-
ecules in motion. Heat, energy and work are mea-
surable quantities that depend on the motion of
molecules. The laws of thermodynamics operate
at all scales.
However, thermodynamics, a science inherited
in the eighteenth century from the times of the
industrial revolution, has been inspired by motors
and steam engines that proved to be indispensable
during that time. It is fair then to question the
relevance and applicability of all this knowledge
when scientists immerse into the realm of the very
small, far from the initial context that inspired
Carnot and others.
What are the novel features of thermodynamics
when applied to small (also called mesoscopic)
systems? Is it necessary to revisit some of the
main concepts that we learned from standard ther-
modynamics? How are energy dissipation and
efﬁciency related for non-equilibrium small sys-
tems where energy ﬂuctuations are dominant?
Finally, what are the implications in quantum
systems already governed by quantum ﬂuctua-
tions? Answering such questions is one of the
main goals of this new discipline.
Introduction
The non-equilibrium thermodynamics of small sys-
tems is becoming quite popular among statistical
physicists who recognize there new aspects of ther-
modynamics where large Brownian ﬂuctuations
are
of
pivotal
importance
as
compared
to
478
Fluctuation Theorems, Brownian Motors and Thermodynamics of Small Systems

ﬂuctuations in macroscopic (or large) systems. In
macroscopic systems, ﬂuctuations represent just
small deviations respect to the average behavior.
For example, an ideal gas of N molecules in ther-
mal contact with a bath at temperature T has an
average total kinetic energy of (3/2)NkB T. How-
ever, the total energy is not a conserved quantity
but ﬂuctuates, its spectrum being a Gaussian distri-
bution of variance (3/2)N(kB T)2 according to the
law of equipartition. Therefore, relative deviations
of the energy are on the order 1=
ﬃﬃﬃﬃ
N
p
respect to the
average value. For macroscopic systems such devi-
ations are very small: for N ¼ 1012 (this is the
typical number of molecules in a 1 ml test tube at
nanomolar concentration) relative deviations are
on the order of 106, hence experimentally
unobservable by calorimetry methods. For a few
molecules, N  O 1
ð Þ , relative deviations are on
the same order. Fluctuations are then measurable
by direct observation of individual molecules.
Small systems share the property that energy
ﬂuctuations are much larger than 
ﬃﬃﬃ
E
p
(the pre-
diction by the law of large numbers) where E is the
average total energy. Large deviations from aver-
age values are normally observed in mesoscopic
systems where non-equilibrium ﬂuctuations are
governed by a few degrees of freedom. Examples
abound in physics and biology: the Brownian
motion of a micron-size silica bead captured in
an optical trap; the unfolding of a bio-molecule
(e.g. a nucleic acid hairpin or a protein); the
movement of molecular motors inside the cell;
the cooperative rearrangement of a nanosized
region containing a few molecules inside an amor-
phous material such as a glass.
As a rule of thumb we can say that small
systems are those where the typical energy con-
tent of the system is a few times kB T, maybe from
1 to 1000 but not much more. As often happens,
there is no well deﬁned frontier separating the
small-size regime from the large-size regime.
The name thermodynamics of small systems was
ﬁrst coined by T. L. Hill (1994) who showed the
importance of the statistical ensemble in thermo-
dynamic relations. A main result of statistical
mechanics is the independence of the equation of
state on the statistical ensemble in the thermody-
namic limit. Such independence breaks down in
small systems due to the contribution of ﬂuctua-
tions which depend on the type of statistical
ensemble considered. In biology, the most impor-
tant aspect of these tiny machines is that they
operate far from equilibrium; its consequences
and importance in their biological function are
still unknown. The combination of small size
and non-equilibrium behavior is the playground
for the striking behavior observed in condensed
matter physics and biophysics.
Prominent in the ﬁeld is the study of the so
called work and heat ﬂuctuations in systems
driven to a non-equilibrium state. Fluctuation the-
orems are mathematical relations that quantify the
relative probability of trajectories that release and
absorb a given amount of work/heat to and from
the environment. Taken individually, the work
and heat along these trajectories can violate
some of the inequalities of thermodynamics, lead-
ing to what is commonly referred as transient
violations of the second law. This name has raised
strong objections among some groups of physi-
cists. Of course the second law remains inviolate.
The name just stresses the fact that Brownian
ﬂuctuations are big enough for such deviations
from the average value to be observed. For mac-
roscopic systems these trajectories are known to
be irrelevant and unobservable, however at the
level of small system sizes, when the energies
involved are of order of several times kB T, these
trajectories become important. Although thermo-
dynamic inequalities are known to describe the
behavior of average values, it is important to
explore the implications and relevance of these
deviations in our understanding of energy trans-
formation processes at the molecular level.
The quantitative experimental observation and
measurement of large energy ﬂuctuations has
become possible only recently with the develop-
ment of new micro-manipulation tools. Particu-
larly important are the application of single-
molecule techniques to explore physical theories
in systems out of equilibrium. The use of new
micro-manipulation tools in the exploration of
the behavior of tiny objects (such as bio-
molecules and motors) embedded in a thermal
environment opens the possibility to investigate
how these systems exchange energy with their
Fluctuation Theorems, Brownian Motors and Thermodynamics of Small Systems
479

environment. This question is of great interest
both at a fundamental and practical level. From a
fundamental point of view, the comprehension of
how bio-molecules operating very far from equi-
librium are so efﬁcient raises the question whether
such tiny systems exploit rare and large deviations
from their average behavior by rectifying thermal
ﬂuctuations from the bath. From a practical point
of view, this might help in the design of efﬁcient
nanomotors in the future.
In the next sections we overview a selection of
topics in this fascinating area of research. We will
start by discussing molecular motors in section
“Molecular Motors”. In section “Non-equilibrium
Thermodynamics of Small Systems” we explain
what are the main types of non-equilibrium states
and introduce the microscopic deﬁnitions of heat
and work. In subsection “The Jarzynski Equality”
we derive the Jarzynski equality by using the
master equation approach. This part is a bit tech-
nical and the reader who is not interested in the
details can jump to Eq. (17) and continue reading
from there. Finally, in section “Fluctuation Theo-
rems” we discuss ﬂuctuation theorems and review
some of their applications to condensed matter
physics and biophysics. The article ﬁnishes with
a discussion of future directions in research.
Molecular Motors
Molecular motors are proteins that use the energy
extracted from the hydrolysis of ATP to exert
mechanical work (Fig. 1) (Spudich 2002). The
Fluctuation Theorems, Brownian Motors and Ther-
modynamics of Small Systems, Fig. 1 Examples of
molecular machines: (a) Kinesin walking a long micro-
tubule and transporting a cargo. (b) F1-ATP synthase is the
proton pump responsible of producing ATP in the mito-
chondria of eukaryotic cells. (c) Helicases are forerunners
of the DNA polymerase that unwind DNA by transforming
dsDNA into two strands of ssDNA. (d) The ribosome is
one among the largest molecular machines inside the cyto-
plasm of the cell in charge of manufacturing proteins
480
Fluctuation Theorems, Brownian Motors and Thermodynamics of Small Systems

mechanism by which motors utilize the energy
stored in the high energy bonds of the ATP mol-
ecules to perform mechanical work is based on
two hypothesized mechanisms: 1) Power stroke
generation or 2) Brownian ratchet mechanism. In
the ﬁrst mechanism the release of the pyrophos-
phate during the ATP hydrolysis cycle is tightly
coupled to the generation of force which drives
the motor. In the second mechanism, the motor
diffuses reversibly along the substrate. Movement
is then produced by the hydrolysis of ATP that
induces a conformational change in the protein.
This change is then rectiﬁed by thermal ﬂuctua-
tions that induce the release of ADP. By steady
repetition of this mechanochemical cycle (one
ATP molecule is hydrolyzed per cycle) the motor
carries out important cellular functions. Motors
are characterized by the so called processivity or
number of turnover cycles the motor does until
detaching from the substrate. Processivities of
molecular motors can vary by several orders of
magnitude depending on the type of motor and the
presence of other regulating factors. For example,
the muscle myosin II motors work in large assem-
blies, each myosin having a processivity around 1,
meaning that each myosin performs one mecha-
nochemical cycle on average before detaching
from the substrate. In the other extreme of the
scale there are DNA polymerases in eukaryotes
which
show
processivities
that
range
from
1 (adding approximately one nucleotide before
detaching) up to several thousands or even mil-
lions. However, in the presence of sliding clamps
(proteins with the shape of a doughnut that encir-
cle the DNA and tightly bind DNA polymerases)
processivities go up to 109. Molecular motors are
magniﬁcent objects from the point of view of their
efﬁciency. If we deﬁne the efﬁciency rate as the
ratio between the useful work performed by the
motor and the energy released in the hydrolysis of
one ATP molecule in one mechanochemical
cycle, then typical values for the efﬁciencies are
around several tens per cent, reaching the value of
90% in some cases (like in the rotary motor F1-
ATPase). For example, out of the 20 kB Tobtained
from the hydrolysis of one molecule of ATP,
kinesin exerts a mechanical work of 12 kB T at
every step, having an efﬁciency of around 60%.
Such large efﬁciencies are rarely found in macro-
scopic systems (motors of cars have efﬁciencies
below 20%) meaning that molecular motors have
been designed by evolution to efﬁciently operate
in a highly noisy environment. Molecular motors
are expected to be essential constituents of future
nanodevices.
What is the relation between molecular motors
and the non-equilibrium thermodynamics of small
systems? It is a well established fact that the
typical amounts of energy obtained from chemical
sources (e.g. ATP or GTP hydrolysis) used by
most molecular machines are a few kcal per mol
(at T ~ 300 K this corresponds to a few units of
kB T, 1 kBT ’ 0.6 kcal/mol). Let us consider the
example of RNA transcription. The process by
which RNA nucleotides (A,U,G,C) are added to
the newly synthesized RNA strand during the
transcription process involves the hydrolysis of
the different nucleoside-phosphate complexes as
they are added to the 30 end of the growing chain.
The overall process by which one base is added to
the newly synthesized strand is a highly favorable
reaction (mainly driven by the hydrolysis of the
pyrophosphate) with a free energy release, ΔG, in
the range between 7 and 12 kcal/mol mainly
depending on the magnesium concentration in
the environment. Effectively this is an irreversible
process that generates an amount of available
energy between 10 and 20 kB T at room tempera-
ture (~ 300 K, 1kBT ’ 0.6 kcal/mol) per base pair
added. This energy would be lost to the environ-
ment in the form of heat were it not for the fact that
a big part of the energy is used by the RNA
polymerase to locally unwind the double DNA
helix and pull apart the two DNA strands to pro-
duce a bubble a few bases long of denatured
DNA.
This
bubble
is
then
used
by
the
DNA/RNA/polymerase ternary complex as a sub-
strate to polymerize the RNA. As transcription
proceeds the bubble moves downstream together
with the RNA polymerase and the RNA transcript
is synthesized.
For this process to occur, the RNA polymerase
must move against the Stokes friction produced
by water as well as other roadblocks that hamper
its motion. In particular, the RNA polymerase
must exert force and torque on the DNA. Typical
Fluctuation Theorems, Brownian Motors and Thermodynamics of Small Systems
481

forces to unzip DNA are on the order of 15 pN
meaning that the minimum mechanical work nec-
essary to unzip one base pair is around 15 pN
times 12 Angstroms (the typical extension gained
after pulling apart two bases at the fork of a DNA
hairpin), which is equal to 18 pN  nm or equiva-
lently 4.4 kB T (1 kBT ’ 4.11pN  nm at room
temperature). We can deﬁne the efﬁciency of the
RNA motor as the ratio between the mechanical
work needed to unzip one base pair and the
amount of energy obtained from hydrolysis upon
the addition of a nucleotide (however this is not
the only way to deﬁne mechanical efﬁciencies,
e.g. see Wang and Oster 2002; Bustamante et al.
2004). The efﬁciency of the transcription process
is then about 40%, a quite remarkable feat if we
compare this number with the ones obtained in
man made machines (cars have efﬁciencies below
20%). The motion of a single RNA polymerase
has been studied in several prokaryotic systems
using optical and magnetic tweezers (Yin et al.
1995; Wang et al. 1998). In these experiments a
DNA/polymerase complex is tethered between a
trapped
bead
and
an
streptavidin
coated
immobilized bead or surface. To initiate transcrip-
tion nucleotides are allowed to ﬂow inside the
chamber and the elongation of the transcript can
be followed in real time while force is applied on
the tether. The extension of the RNA transcript as
a function of time reveals a complex intermittent
motion of the polymerase with pauses (temporary
stops), arrests (permanent stops) and even back-
tracking events (Davenport et al. 2000; Forde
et al. 2002).
Non-equilibrium Thermodynamics of
Small Systems
Non-equilibrium States
An important concept in thermodynamics is the
state variable. State variables are those that, once
determined, uniquely specify the thermodynamic
state of the system. Examples are the temperature,
the pressure, the volume and the mass of the
different components in a given system. To spec-
ify the state variables of a system it is common to
put the system in contact with a bath. The bath is
any set of sources (of energy, volume, mass, etc.)
large enough to remain unaffected by the interac-
tion with the system under study. The bath ensures
that a system can reach a given temperature, pres-
sure, volume and mass concentrations of the dif-
ferent components when put in thermal contact
with the bath (i.e. with all the relevant sources).
Equilibrium states are then generated by putting
the system in contact with a bath and waiting until
the system properties relax to the equilibrium
values. Under such conditions the system proper-
ties do not change with time and the average heat/
work/mass exchanged between the system and the
bath is zero.
Non-equilibrium states can be produced in
many ways, either by continuously changing the
parameters of the bath or by preparing the system
in an initial nonequilibrium state that slowly
relaxes toward equilibrium. In general a non-
equilibrium state is produced whenever the sys-
tem properties change with time and/or the net
heat/work/mass exchanged by the system and
the bath is non zero. We can distinguish at least
three different classes of non-equilibrium states:
•
Non-equilibrium transient state (NETS) The
system is initially prepared in an equilibrium
state and later driven out of equilibrium by
switching on an external perturbation. The sys-
tem quickly returns to a new equilibrium state
once the external perturbation stops changing.
A classic example of NETS is the case of a
protein in its initial native state that is mechani-
cally pulled (e.g. using AFM) by exerting force on
the ends of the molecule. The protein is initially
folded and in thermal equilibrium with the sur-
rounding aqueous solvent. Upon pulling the pro-
tein is driven away from equilibrium into a
transient state until it ﬁnally settles into the
unfolded and extended equilibrium state. Another
example of a NETS is a bead immersed in water
and trapped in an optical well generated by a
focused laser beam. When the trap is moved to a
nearby new position (e.g. by moving the laser
beams) the bead is driven to a NETS. After some
time the bead reaches equilibrium again at the new
position of the trap. In another experiment the trap
482
Fluctuation Theorems, Brownian Motors and Thermodynamics of Small Systems

is suddenly put in motion at a speed v so the bead
is transiently driven away from its equilibrium
average position until it settles into a non-
equilibrium steady-state (NESS, see below) char-
acterized by the speed of the trap. The average
position of the bead lags behind the position of the
center of the trap.
•
Non-equilibrium steady-state (NESS) The
system is driven by external forces (either
time dependent or non-conservative) in a sta-
tionary non-equilibrium state where its proper-
ties do not change with time. The steady state
cannot be described by the Boltzmann- Gibbs
distribution and the average net heat that is
dissipated by the system (equal to the entropy
production of the bath) is positive.
A classic example of a NESS is an electrical
circuit made out of a battery and a resistance. The
current ﬂows through the resistance and the chem-
ical energy stored in the battery is dissipated to the
environment in the form of heat; the average dis-
sipated power, P dis ¼ VI , is equal to the power
supplied by the battery. Another example is a
sheared ﬂuid between two plates or coverslips
and one of them is moved relative to the other at
a constant velocity v. To sustain such state a
mechanical power equal to P / v2 has to be
exerted upon the moving plate where  is the
viscosity of water. The mechanical work produced
is then dissipated in the form of heat through the
viscous friction between contiguous ﬂuid layers.
Further examples of NESS are chemical reactions
in metabolic pathways that are sustained by acti-
vated carrier molecules such as ATP. In such
cases, hydrolysis of ATP is strongly coupled to
speciﬁc oxidative reactions. For example, ionic
channels use ATP hydrolysis to transport protons
against the electromotive force.
•
Non-equilibrium aging state (NEAS) The
system
is
initially
prepared
in
a
non-
equilibrium state and put in contact with the
sources. However, at difference with NETS,
the system fails to reach thermal equilibrium
in observable or laboratory time scales. In this
case the system is in a non-stationary slowly
relaxing non-equilibrium state called aging
state and characterized by a very small entropy
production of the sources. In the aging state
two-time correlations decay slower as the sys-
tem becomes older. Two-time correlation func-
tions depend on both times and not just on their
difference. The classic example of a NEAS is a
super-cooled liquid cooled below its glass tran-
sition temperature (Ediger et al. 1996). The
liquid solidiﬁes into an amorphous slowly
relaxing
state
characterized
by
huge
relaxational times and anomalous low fre-
quency response. Other systems are colloids
that can be prepared in a NEAS by the sudden
reduction/increase of the volume fraction of
the colloidal particles or by putting the system
under a strain/stress (Cipelletti and Ramos
2005).
The classes of non-equilibrium states previ-
ously described do not make distinctions whether
the system is macroscopic or small. In small sys-
tems, however, it is common to speak about the
control parameter to emphasize the importance of
the constraints imposed by the bath that are exter-
nally controlled and do not ﬂuctuate. The control
parameter (l) represents a value (in general, a set
of values) that deﬁnes the state of the bath. Its
value determines the equilibrium properties of the
system, e.g. the equation of state. In macroscopic
systems it is unnecessary to discern which value is
externally controlled because ﬂuctuations are
small and all equilibrium ensembles give the
same
equivalent
thermodynamic
description,
i.e. the same equation of state. Differences arise
when taking into account ﬂuctuations. The non-
equilibrium behavior of small systems is then
strongly
dependent
on
the
speciﬁc
non-
equilibrium protocol. Figure 2 shows a represen-
tation of a few examples of NESS and control
parameters.
Microscopic Definitions of Work and Heat
Microscopic deﬁnitions of work and heat can be
given using Markov processes. Let us consider a
general system described by an energy function
E(C) where C is a generic conﬁguration in contact
with a bath at temperature T. For instance, in a gas
Fluctuation Theorems, Brownian Motors and Thermodynamics of Small Systems
483

of N molecules, C would stand for their positions
and momenta. The dynamics are assumed to be
discrete in time with elementary time-step Δt. A
trajectory or path of the system is characterized by
the sequence of conﬁgurations
G  Ck; 0  k  M
f
g
 C0, C1, C2, . . . , CM
f
g
ð1Þ
where k is the index for the discrete time step and
M is the total number of time steps. The time
corresponding to step k is then given by t ¼ kΔt
with t ¼ 0 (k ¼ 0) and tf (k ¼ M/Δt) denoting the
initial
and
ﬁnal
times
respectively.
The
continuous-time limit is recovered by taking
Δt ! 0, M ! 1 with tf ﬁnite.
Now we will treat the case where the system is
perturbed in a prescribed way. Because the
dynamics is stochastic, it will generate an ensem-
ble of trajectories when the same experiment is
repeated many times. In addition to the conﬁgu-
ration C, and in order to characterize the pertur-
bation protocol, we need to specify the temporal
sequence of values {lk; 0  k  M}. The control
parameter l shifts the energy levels of the system
according to the relation,
El C
ð Þ ¼ E C
ð Þ  lA C
ð Þ
ð2Þ
where A(C) is the observable coupled to the exter-
nal perturbation l (e.g., if l is a magnetic or
gravitational ﬁeld then A stands for the magneti-
zation or the height of the center of mass
respectively).
We now consider the variation of energy along
a given path DE G
ð Þ ¼ El f C f


 El0 C0
ð
Þ where
C0, Cf are the initial and ﬁnal conﬁgurations for
that path and l0, lf are the initial and ﬁnal values
of the control parameter as deﬁned by the protocol
(path independent). From Eq. (2) the energy var-
iation is given by,
Fluctuation Theorems, Brownian Motors and Ther-
modynamics of Small Systems, Fig. 2 Examples of
NESS: (a) An electric current / ﬂowing through a resis-
tance R and maintained by a voltage source or control
parameter V. (b) A ﬂuid sheared between two plates that
move at speed v (the control parameter) relative to each
other. (c) A chemical reaction A ! B coupled to ATP
hydrolysis. The control parameters are the concentrations
of ATP and ADP
484
Fluctuation Theorems, Brownian Motors and Thermodynamics of Small Systems

DE G
ð Þ ¼ ElM CM
ð
Þ  El0 C0
ð
Þ
¼
X
M1
k¼0
Elkþ1 Ckþ1
ð
Þ  Elk Ckþ1
ð
Þ



X
M1
k¼0
Elk Ck
ð
Þ  Elk Ckþ1
ð
Þ
ð
Þ
ð3Þ
with Δlk ¼ lk þ 1  lk. This decomposition
identiﬁes work and heat by using the ﬁrst law of
thermodynamics, ΔE ¼ W – Q. The ﬁrst term in
Eq. (3) is identiﬁed as the work W exerted upon
the system whereas the second corresponds to the
heat Q transferred from the system to the bath,
W G
ð Þ ¼
X
M1
k¼0
Elkþ1 Ckþ1
ð
Þ  Elk Ckþ1
ð
Þ


ð4Þ
Q G
ð Þ ¼
X
M1
k¼0
Elk Ck
ð
Þ  Elk Ckþ1
ð
Þ
ð
Þ:
ð5Þ
We concentrate our attention on the work
exerted upon the system along a given path Γ.
Inserting (2) in (4) we get
W G
ð Þ ¼
X
M1
k¼0
@El Ck
ð
Þ
@l


l¼lk
Dlk
¼ 
X
M1
k¼0
A Ck
ð
ÞDlk  
ðt
0
ds_l sð ÞA C sð Þ
ð
Þds
ð6Þ
where we have applied the continuous-time limit
in the last term in the r.h.s. of (6).
As the path is stochastic the work is a ﬂuctuat-
ing quantity that can be characterized by its prob-
ability distribution P W
ð
Þ deﬁned as,
P W
ð
Þ ¼
X
G
P G
ð Þd W  W G
ð Þ
ð
Þ
ð7Þ
where Γ stands for the path and P(Γ) indicates the
probability of that path. The importance of P W
ð
Þ
relies upon the fact that it is a quantity that is
experimentally measurable and therefore is suitable
to quantitatively characterize work ﬂuctuations
with
the
aid
of
recently
developed
micro-
manipulation tools.
The Jarzynski Equality
In 1997 Chris Jarzynski derived a remarkable
equality describing work ﬂuctuations in non-
equilibrium isothermal systems (Jarzynski 1997).
This relation was somewhat unexpected because
it related the free energy change in a reversible
process with exponential averages of the work
measured in irreversible processes. The equality
applies to all non-equilibrium systems under gen-
eral assumptions of local detailed balance and
ergodicity. In what follows we show a derivation
of the equality based on a master equation
approach. The following calculation intends to
show the simplicity of the algebraic math used in
the derivation of this general result. The reader not
interested in math details can jump directly to
Eq. (17) and continue reading from there.
Let us consider a system in contact with a
thermal bath at temperature T that is initially in
thermal equilibrium. The system is then driven to
a NETS under the action of an external perturba-
tion described by the temporal sequence of values
{lk; 0  k  M}.
We consider the ensemble of all possible tra-
jectories that start from an initial state character-
ized by the distribution Pl0 C
ð Þ. Dynamics of the
system are then given by the set of probabilities
Plk C
ð Þ for the system to be found at conﬁguration
C at time-step k. These probabilities satisfy a
master equation. For a Markov process the time
evolution of the Pl(C) depends on the quantities,
W lk C ! C0
ð
Þ, deﬁned as the transition probabil-
ity per unit time to go from conﬁguration C to C0
at time-step k. The W ‘s are assumed to lead to an
ergodic dynamics (where any pair of conﬁgura-
tions are always connected by at least one trajec-
tory, i.e. dynamics is irreducible) and satisfy the
detailed balance condition,
W lk C ! C0
ð
Þ
W lk C0 ! C
ð
Þ ¼
Peq
lk C0
ð
Þ
Peq
lk C
ð Þ
¼ exp b Elk C0
ð
Þ  Elk C
ð Þ
ð
Þ
ð
Þ
ð8Þ
where β ¼ 1/kBT, kB is the Boltzmann constant
and T is the temperature. The Peq
lk C
ð Þ
is the
Boltzmann–Gibbs distribution,
Fluctuation Theorems, Brownian Motors and Thermodynamics of Small Systems
485

Peq
l C
ð Þ ¼ exp bEl C0
ð
Þ
ð
Þ=Zl;
Zl ¼
X
C
exp bEl C
ð Þ
ð
ð9Þ
where Zl ¼ exp.(–βFl) is the partition function
and Fl is the free energy.
The energy function Elk C
ð Þ is given in (2).
Under very general conditions these dynamics
guarantee that the system reaches a stationary state
where conﬁgurations are populated according to the
Boltzmann–Gibbs weight. The solution to the mas-
ter equation gives the time evolution for the system.
For a generic path-dependent observable A G
ð Þ
, the ensemble average value is given by,
A
h i ¼
X
G
P G
ð ÞA G
ð Þ:
ð10Þ
Using the fact that the dynamics are Markovian
together with the deﬁnition (1) we can write,
P G
ð Þ ¼ Peq
l0 C0
ð
Þ
Y
M1
k¼0
W lk Ck  Ckþ1
ð
Þ
ð11Þ
where the system initially starts in equilibrium at
l0. By inserting (11) into (10) we obtain,
A
h i ¼
X
G
A G
ð ÞPeq
l0 C0
ð
Þ
Y
M1
k¼0
W lk Ck  Ckþ1
ð
Þ: ð12Þ
Using the detailed balance condition (8) this
expression reduces to,
A
h i ¼
X
G
Peq
l0 C0
ð
ÞA G
ð Þ
Y
M1
k¼0

W lk Ckþ1  Ck
ð
Þ
exp b Elk Ckþ1
ð
Þ  Elk Ck
ð
Þ
ð
Þ
½


ð13Þ
¼
X
G
A G
ð ÞPeq
l0 C0
ð
Þ
exp b
X
M1
k¼0
Elk Ckþ1  Elk Ck
ð
Þ
ð
Þ
ð
"
#
Y
M1
k¼0
W lk Ckþ1 ! Ck
ð
Þ:
ð14Þ
This equation can not be worked out further for
a general observable A. However, let us consider
the observable, A G
ð Þ ¼ exp W G
ð Þ
ð
Þ , where
W(Γ) stands for the work deﬁned in (4). By
inserting this expression in (14) we obtain the
Jarzynski equality:
exp W
ð
Þ
h
i
¼ 1
Zl0
X
G
Y
M1
k¼0
W lk Ckþ1 ! Ck
ð
Þ exp bElM C0
ð
Þ
ð
Þ
¼ ZlM
Zl0
¼ exp bFlM  Fl0
ð
Þ ¼ exp bDF
ð
Þ
ð15Þ
where we have applied a telescopic sum and
used (9). To carry out the telescopic sums we ﬁrst
summed over C0, C1 . . . by applying the normali-
zation condition on the transition probabilities,
X
C0
W k C ! C0
ð
Þ ¼ 1:
ð16Þ
The second law of thermodynamics, hWi  ΔF,
also follows naturally as a particular case of (15) by
using the convexity inequality, hexp(x)i  exp hxi.
The Jarzynski equality is often written in the form,
exp Wdiss
ð
Þ
h
i ¼ 1
ð17Þ
where Wdiss ¼ W  ΔF is called the dissipated
work. The second law of thermodynamics puts
bounds on the minimum amount of average
work performed on the system: although W may
strongly ﬂuctuate from path to path its mean value
(averaged over an inﬁnite number of repeated
experiments, i.e. the ﬁrst moment of P(W)) is
always greater than the reversible or quasi-static
work, Wrev, which is also equal to the free energy
difference ΔF between the initial and ﬁnal equi-
librium states. The reversible work is the value of
the work that is obtained for protocols that are
adiabatic or quasi-static, i.e. the control parame-
ters are changed inﬁnitely slowly. The difference
between the actual work and the reversible work
then corresponds to the dissipated work, Wdiss ¼
W – ΔF. The second law establishes that in
486
Fluctuation Theorems, Brownian Motors and Thermodynamics of Small Systems

average a positive amount of heat is irreversibly
lost to the environment, hWdissi  0 (Fig. 3). The
amount of dissipation in irreversible processes is
then related to the asymmetry between the phase
space densities obtained when the process is run
forward and backward in time (Kawai et al. 2007).
Gaussian work distributions exactly satisfy (17)
provided the average dissipated work hWdissi
and the variance of the work, s2
W , are related by
s2
W ¼ 2kBT Wdiss
h
i: A ﬂuctuation-dissipation para-
meter R can be introduced to quantify deviations
from the Gaussian behavior (Ritort et al. 2002),
R ¼
s2
W
2kBT Wdiss
h
i :
ð18Þ
For Gaussian work distributions R ¼ 1,
corresponding to non-equilibrium processes in
the linear regime where the ﬂuctuation-dissipation
theorem holds.
The validity of the Jarzynski equality extends
to deterministic dynamics (e.g. Hamiltonian or
thermostated). In Hamiltonian dynamics the set
of phase space points then behaves as an incom-
pressible ﬂuid, a consequence of the Liouville
theorem. The case of Hamiltonian dynamics was
originally addressed by Jarzynski in his original
derivation of the non-equilibrium work relation
(Jarzynski 1997). The stochastic case has been
analyzed also for general Markov processes by
Crooks (1999, 2000) and for Langevin dynamics
by Kurchan (1998) and Seifert (2005a). Equa-
tion (15) has appeared in the past in the literature
in
the
form
of
a
generalized
ﬂuctuation-
dissipation relation proposed by Bochkov and
Kuzovlev (1981) which is mathematically identi-
cal to the Jarzynski equality (Jarzynski 1997).
Related results to the Jarzynski’s equality can be
also traced back also in the free-energy perturba-
tion identity derived by Zwanzig (1954) and the
Kirkwood formula (Kirkwood 1935).
Fluctuation Theorems
Since the beginning of the 90’s some exact
results in statistical mechanics have provided a
mathematical description of energy ﬂuctuations
(in the form of heat and work) for non-equilibrium
systems. This new class of results go under the
name of ﬂuctuation theorems (FTs) and provide a
solid theoretical basis to quantify energy ﬂuctua-
tions in non-equilibrium systems. FTs describe
energy ﬂuctuations in systems while they execute
transitions between different types of states. For
these ﬂuctuations to be observable the system has
to be small enough and/or operate over short
periods of time, otherwise the measured proper-
ties approach the macroscopic limit where ﬂuctu-
ations get masked by the dominant average
behavior. Most ﬂuctuation theorems are of the
form,
P þS
ð
Þ
P S
ð
Þ ¼ exp
S
kB


,
ð19Þ
where S has the dimensions of an entropy that may
represent heat and/or work produced during a
given time interval. The precise mathematical
form of relations such as (19) (for instance, the
precise deﬁnition of S or whether they are valid at
ﬁnite time intervals or just in the limit where the
time interval goes to inﬁnity) depends on the par-
ticular non-equilibrium conditions (e.g. whether
Fluctuation Theorems, Brownian Motors and Ther-
modynamics of Small Systems, Fig. 3 Probability dis-
tribution of the dissipated work: According to the second
law of thermodynamics the average dissipated work is
always positive. However, because of ﬂuctuations, the
dissipated work of some paths can be negative (shaded
area). These paths are sometimes referred to as “transient
violations of the second law”
Fluctuation Theorems, Brownian Motors and Thermodynamics of Small Systems
487

the systems starts in an equilibrium Gibbs state, or
whether the system is in a non-equilibrium steady
state, or whether the system executes transitions
between steady states, etc.).
Generally speaking, FTs relate the amounts of
work or heat exchanged between the system and its
environment for a given non-equilibrium process
and its corresponding time-reversed process. The
time-reversed process is deﬁned as follows. Let us
consider a given non-equilibrium process (we call
it forward, denoted by F) characterized by the
protocol lF(t) of duration tf. In the reverse process
(denoted by R) the system starts at t ¼ 0 in a
stationary state at the value lF(tf) and the control
parameter is varied for the same duration tf as in the
forward process according to the protocol lR(t) ¼
lF(tf – t). FTs depend on the type of initial state and
the particular type of dynamics (deterministic ver-
sus stochastic) or thermostated conditions.
Despite of the fact that most of these theorems
are treated as distinct they are in fact closely
related. The main hypothesis for all theorems is
the validity of some form of microscopic revers-
ibility or local detailed balance (see however
Cohen and Mauzerall 2004, Jarzynski 2004,
Astumian 2006 for some controversy). Major
classes of FTs include the transient FT (TFT)
and the steady state FT (SSFT):
•
The transient FT (TFT) In the TFT the system
initially starts in an equilibrium (Boltzmann-
Gibbs) state and is driven away from equilib-
rium by the action of time-dependent forces
that derive from a time-dependent potential
Vl(t). The potential depends on time through
the value of the control parameter l(t). At any
time during the process the system in an
unknown transient non-equilibrium state. If
the value of l is kept ﬁxed then the system
relaxes into a new equilibrium state. The TFT
was introduced by Evans and Searles (1994) in
thermos-tatted systems and later extended by
Crooks to Markov processes (Crooks 1999).
•
The steady state FT (SSFT) In the SSFT the
system is in a non-equilibrium steady state
where it exchanges net heat and work with the
environment. The existence of the SSFT was
numerically anticipated by Evans and collabora-
tors for thermostated systems (Cohen et al. 1993)
and demonstrated for deterministic Anosov sys-
tems by Gallavotti and Cohen (1995). The
entropy production S by the system (equal to
the heat exchanged by the system divided by
the temperature of the environment) satisﬁes the
relation (19) in the asymptotic limit of large times
t ! 1 and for bounded energy ﬂuctuations,
s ¼ jSj
t < s	 where s* is a model dependent
quantity. Other classes of SSFTs include stochas-
tic Langevin dynamics (Kurchan 1998), Markov
chains (Lebowitz and Spohn 1999; Maes 1999)
or the case where the system initially starts in a
steady state (Oono and Paniconi 1998) and exe-
cutes transitions between different steady states
(Hatano and Sasa 2005; Speck and Seifert
2005a).
Particularly relevant to the single molecule
context is the FT by Crooks (1999, 2000) which
relates the work distributions measured along the
forward (F) and reverse (R) paths,
PF W
ð
Þ
PR W
ð
Þ ¼ exp
W  DF
kBT


:
ð20Þ
where PF(W), PR( W) are the work distributions
along the F and R processes respectively, and ΔF is
the free energy difference between the equilibrium
states corresponding to the ﬁnal value of the control
parameter lf ¼ l(tf) and the initial one li ¼ l(0).
A particular result of (20) is the Jarzynski equality
(Jarzynski 1997) described in subsection “The
Jarzynski Equality” that is obtained from (20) by
rewriting it as PR W
ð
Þ ¼ exp
WþDG
kBT
	

PF W
ð
Þ
and integrating both sides of the equation between
W ¼ 1 and W ¼ 1. Because of the normaliza-
tion property of probability distributions, the left
hand side is equal to 1 and the Jarzynski equality
reads,
exp
 W
kBT




F
¼ exp
 DF
kBT


or
DF ¼ kBT log
exp
 W
kBT




F


:
ð21Þ
where < . . . >F denotes an average over an inﬁ-
nite number of paths, all generated by a given
forward protocol lF(T).
488
Fluctuation Theorems, Brownian Motors and Thermodynamics of Small Systems

Experimental Tests and Free Energy Recovery
Various categories of FTs have been introduced
and experimentally validated. The ﬁrst experimen-
tal tests of FTs were carried out by Ciliberto and
coworkers for the Gallavoti-Cohen FTin Rayleigh-
Bernard convection (Ciliberto and Laroche 1998)
and turbulent ﬂows (Ciliberto et al. 2004). Later on
FTs were tested for beads trapped in an optical
potential and moved through water at low Reyn-
olds numbers. The motion of the bead is then well
described by a Langevin equation that includes a
friction (non-conservative) force, a conﬁning
(conservative) potential and a source of stochastic
noise. Experiments have been carried out by Evans
and collaborators who have tested the validity of
the TFT (Wang et al. 2002; Carberry et al. 2004),
and by Liphardt and collaborators for a bead exe-
cuting transitions between different steady states
(Trepagnier et al. 2004). The validity of the TFT
has been also recently tested for non-Gaussian
optical trap potentials (Blickle et al. 2005).
The Jarzynski equality and the FT by Crooks
can be used to recover equilibrium free-energy
differences between different molecular states by
using non-equilibrium measurements in single
molecule
experiments
(Hummer
and
Szabo
2001; Jarzynski 2001; Hummer and Szabo
2005). In particular, by using the Jarzynski equal-
ity (21) it is possible to extract the value of ΔF
from repeated measurements of the mechanical
work along many trajectories. The idea is to repeat
non-equilibrium experiments many times and
evaluate the exponential average in the r.h.s
of (21) to extract the work corresponding to the
reversible process. Would it then not be easier to
directly measure the work for a reversible pro-
cess? Unfortunately many processes cannot be
carried in quasistatic conditions (either simula-
tions or experiments) and therefore, alternative
methods are required to determine free-energy
differences. There are practical difﬁculties in the
applicability of (21) as the number of trajectories
included in the exponential average must be actu-
ally inﬁnite. This is unrealizable in practice as
non-equilibrium experiments can be performed
only a ﬁnite number of times and the ﬁniteness
of the number of trajectories introduces a bias. It is
known that the number of trajectories required to
evaluate
the
Jarzynski
equality
grows
exponentially with the average value of the dissi-
pated work. The dependence of the bias and error
with the number of pulls has been estimated in
some cases (Zuckermann and Woolf 2002; Gore
et al. 2003). In general this dependence can be
quite complicated as it depends on the behavior of
the low-work tails of the distribution P(W) which
are difﬁcult to analyze in general.
In 2002, the Jarzynski equality was experimen-
tally tested by pulling the P5ab RNA hairpin, a
derivative of the Tetrahymena Termophila L21
ribozyme (Liphardt et al. 2002) using optical
tweezers. However, in that case the molecule
was pulled not too far from equilibrium. The
Jarzynski equality and related identities for
athermal systems have been recently put under
scrutiny in other systems (Schuler et al. 2005;
Douarche et al. 2005a, b). The Jarzynski equality
and the FT by Crooks have inspired several theo-
retical papers discussing other related exact
results (Van Zon and Cohen 2003a, b; Seifert
2004; Jarzynski and Wojcik 2004; Seifert 2005b;
Reid et al. 2005), free-energy recovery from
numerical simulations (Hummer 2001; Isralewitz
et al. 2001; Jensen et al. 2002; Park et al. 2003;
Andriocioaei et al. 2003; Park and Schulten
2004), bias and error estimates for free-energy
differences (Zuckermann and Woolf 2002; Gore
et al. 2003; Bennett 1976; Wood et al. 1991;
Hendrix and Jarzynski 2001; Shirts et al. 2003),
enzyme kinetics (Qian 2005; Min et al. 2005) or
solvable models (Mazonka and Jarzynski 1999;
Lhua and Grossberg 2005; Bena et al. 2005;
Speck and Seifert 2005b; Cleuren et al. 2007). In
addition, analytical studies on small systems ther-
modynamics show that work/heat distributions
display non-Gaussian tails describing large and
rare deviations from the average and/or most
probable behavior (Van Zon and Cohen 2004;
Ritort 2004; Imparato and Peliti 2005a; Imparato
and Peliti 2005b). These theoretical studies open
the way to investigate the possible relevance of
these large deviations in other non-equilibrium
systems in condensed matter physics.
The FT by Crooks can be applied and tested
by measuring the unfolding and refolding work
distributions in single molecule pulling experi-
ments (Fig. 4a). For example, let us consider the
case of a molecule (e.g. a DNA or RNA hairpin
Fluctuation Theorems, Brownian Motors and Thermodynamics of Small Systems
489

or a protein) initially in thermal equilibrium in
the folded (F) or native state. By applying
mechanical
force
(e.g.
using
atomic
force
microscopy or optical tweezers) the molecule
can be mechanically unfolded and the conforma-
tion of the molecule changed from the native to
the unfolded (U) state. The unfolding event is
observed by the presence of a rip in the force-
extension curve of the molecule (Fig. 4b). Dur-
ing the unfolding process the tip of the cantilever
or the bead in the trap exerts a mechanical work
on the molecule that is given by,
Fluctuation Theorems, Brownian Motors and Ther-
modynamics of Small Systems, Fig. 4 Experimental
measurement of work ﬂuctuations in small systems using
single molecules. (a) Experimental setup in RNA force
pulling experiments using optical tweezers. An RNA hair-
pin of a few tens of base pairs is inserted between two
molecular handles (A and B) that are attached to two beads.
One bead is trapped in the optical well, the other bead is
immobilized on the tip of a micropipette. As the optical
trap is moved relative to the micropipette the RNA mole-
cule is stretched. (b) Measured force-extension cycle
showing a force rip around 15pN characteristic of the
unfolding/refolding of the RNA molecule. The work
along a given unfolding/refolding force-extension curve
corresponds to the area below the curve integrated along
a given range of the molecular extension (indicated by the
two vertical dashed lines). (c) Work distributions for the
unfolding and refolding process measured at three different
pulling speeds. According to the FT by Crooks all curves
should cross at a given value of the work, W ¼ ΔF, inde-
pendently of the pulling speed. In this case ΔF ’ 110kBT, a
number that includes also the stretching contributions from
the hybrid handles and the ssRNA. (d) Experimental ver-
iﬁcation of the FT by Crooks for four different tethered
molecules (all with identical sequence). The black dashed
line is the best ﬁt for all curves and has slope equal to
0.9 
 0.1. Results taken from Collin et al. (2005)
490
Fluctuation Theorems, Brownian Motors and Thermodynamics of Small Systems

W ¼
ðx f
x0
Fdx
ð22Þ
where x0, xf are the initial and ﬁnal extension of
the molecule. In (22) we are assuming that the
molecular extension x is the externally controlled
parameter (i.e. l  x) which is not necessarily the
case. However the corrections introduced by
using (22) are shown to be often small. The
work (22) done upon the molecule along a given
path corresponds to the area below the force-
extension curve that is limited by the initial and
ﬁnal extensions, x0 and xf (Fig. 4b). Because the
unfolding
of
the
molecule
is
a
stochastic
(i.e. random) process, the value of the force at
which the molecule unfolds changes from exper-
iment to experiment and so does the value of the
mechanical work required to unfold the molecule.
Upon repetition of the experiment many times a
distribution of unfolding work values for the mol-
ecule to go from the folded (F) to the unfolded
(U) state is obtained, PF ! U(W). A related work
distribution can be obtained if we reverse the
pulling process by releasing the molecular exten-
sion at the same speed at which the molecule was
previously pulled, to allow the molecule to go
from the unfolded (U) to the folded (F) state. In
that case the molecule refolds by performing
mechanical work on the cantilever or the optical
trap. Upon repetition of the folding process many
times the work distribution, PU ! F(W) can be
also measured. The unfolding and refolding work
distributions can then be measured in stretching/
releasing cycles (Fig. 4c). From (20) we observe
that PF(ΔF) ¼ PR(–ΔF) so the forward and reverse
work probability distributions cross each other at
W ¼ ΔF. In Fig. 4c we observe that both distribu-
tions cross each other at a value (ΔF) that is
independent of the pulling speed as expected.
Figure 4d shows the experimental veriﬁcation
of (20).
The FT by Crooks has been tested in different
types of RNA molecules and the method has been
shown capable of recovering free-energies under
strong non-equilibrium conditions (Collin et al.
2005). The work probability distributions were
measured along the unfolding and refolding
pathways for a three-way junction RNA molecule
and found to strongly deviate from a Gaussian
distribution (Collin et al. 2005). These experimen-
tal results pave the way for other related studies,
for example in molecular dynamics simulations
(Kosztin et al. 2006).
These kind of studies will expand in the future
to cover more complex cases and other non-
equilibrium situations such as the free-energy
recovery of folding free energies in native states
in proteins or free energies in misfolded structures
and intermediate states in RNA molecules and
proteins. Ultimately FTs, when combined with
SME, will offer an excellent opportunity to char-
acterize and understand the possible biological
relevance of large deviations and extremal ﬂuctu-
ations in molecular systems.
Future Directions
The experimental and theoretical study of non-
equilibrium small systems offers exciting possi-
bilities for the statistical physicist and the bio-
physicist. This discipline aims to describe the
novel properties observed in bio-molecules and
molecular machines operating far from equilib-
rium, such as the folding of a nucleic acid or a
protein or the trans-location motion of a molecular
motor.
We are just starting to have a glance about how
these small objects exchange energy with their
environment. It is a well known fact in molecular
biology and biochemistry that biological function
at the molecular level is tightly related to struc-
ture. It might not be surprising that the link
between molecular structure and biological func-
tion is encoded in the low frequency region of the
spectrum of non-equilibrium energy ﬂuctuations
(the spectrum of energy ﬂuctuations extending far
at the most extreme tails of the distribution). It is
difﬁcult to imagine how bio-molecular processes,
often carrying a lot of information, can operate
solely from high frequency events describing the
motion of a few number of atoms. Rather, these
should somehow rely on the low frequency coop-
erative motion between different and distant parts
Fluctuation Theorems, Brownian Motors and Thermodynamics of Small Systems
491

of the molecule. Investigating ﬂuctuations in non-
equilibrium systems calls for a deeper theoretical
understanding of large deviation functions in non-
equilibrium systems as well as more systematic
and accurate experiments identifying sources of
large energy ﬂuctuations in biological systems.
We are at the dawn of an interdisciplinary
scientiﬁc discipline that will bring together scien-
tists with expertises coming from very different
branches of knowledge. This merging process
might culminate with the future engineering of
artiﬁcial
mesoscopic
structures
capable
of
reproducing and even improving the behavior of
the biological ones.
Bibliography
Primary Literature
Andriocioaei I, Dinner AR, Karplus M (2003) Self-guided
enhanced sampling methods for thermodynamic aver-
ages. J Chem Phys 118:1074–1084
Astumian RD (2006) The unreasonable effectiveness of
equilibrium-like
theory
for
interpreting
non-
equilibrium experiments. Am J Phys 74:683
Bena I, Van den Broeck C, Kawai R (2005) Jarzynski
equality for the Jepsen gas. Europhys Lett 71:879–885
Bennett CH (1976) Efﬁcient estimation of free-energy
differences from Monte Carlo data. J Comput Phys
22:245–268
Blickle V, Speck T, Helden L, Seifert U, Bechinger
C (2005) Thermodynamics of a colloidal particle in a
time-dependent non-harmonic potential. Phys Rev Lett
93:158105
Bochkov GN, Kuzovlev JE (1981) Non-linear ﬂuctuation
relations and stochastic models in non-equilibrium
thermodynamics. I. Generalized ﬂuctuation-dissipation
theorem. Physica A 106:443–479
Bustamante C, Chemla YR, Forde NR, Izhaky D (2004)
Mechanical processes in biochemistry. Annu Rev
Biochem 73:705–748
Bustamante C, Liphardt J, Ritort F (2005) The non-
equilibrium thermodynamics of small systems. Phys
Today 58:43–48
Carberry DM, Reid JC, Wang GM, Sevick EM, Searles DJ,
Evans DJ (2004) Fluctuations and irreversibility: an
experimental demonstration of a second-law-like theo-
rem using a colloidal particle held in an optical trap.
Phys Rev Lett 92:140601
Ciliberto S, Laroche C (1998) An experimental test of the
Gallavotti–Cohen ﬂuctuation theorem. J Phys IV
France 8:215–220
Ciliberto S, Garnier N, Hernandez S, Lacpatia C, Pinton JF,
Ruiz-Chavarria G (2004) Experimental test of the
Gallavotti–Cohen ﬂuctuation theorem in turbulent
ﬂows. Physica A 340:240–250
Cipelletti L, Ramos L (2005) Slow dynamics in glassy soft
matter. J Phys 17:R253–R285
Cleuren B, Van den Broeck C, Kawai R (2007) Fluctuation
and dissipation of work in a Joule experiment. Phys
Rev Lett 98:080602
Cohen EGD, Mauzerall D (2004) A note on the Jarzynski
equality. J Stat Mech, P07006
Cohen EGD, Evans DJ, Morriss GP (1993) Probability of
second law violations in shearing steady states. Phys
Rev Lett 71:2401–2404
Collin D, Ritort F, Jarzynski C, Smith SB, Tinoco I,
Bustamante C (2005) Veriﬁcation of the Crooks ﬂuctu-
ation theorem and recovery of RNA folding free ener-
gies. Nature 437:231–234
Crooks GE (1999) Entropy production ﬂuctuation theorem
and the non-equilibrium work relation for free-energy
differences. Phys Rev E 60:2721–2726
Crooks GE (2000) Path-ensemble averages in systems
driven far from equilibrium. Phys Rev E 61:2361–2366
Davenport RJ, Wuite GJ, Landick R, Bustamante C (2000)
Single-molecule study of transcriptional pausing and
arrest by E. coli RNA polymerase. Science 287:
2497–2500
Douarche F, Ciliberto S, Petrosyan A (2005a) An experi-
mental test of the Jarzynski equality in a mechanical
experiment. Europhys Lett 70:593–598
Douarche F, Ciliberto S, Petrosyan A (2005b) Estimate of
the free energy difference in mechanical systems from
work ﬂuctuations: experiments and models. J Stat
Mech (Theor Exp), P09011
Ediger MD, Angell CA, Nagel SR (1996) Supercooled
liquids and glasses. J Phys Chem 100:13200–13212
Evans DJ, Searles DJ (1994) Equilibrium micro-states
which generate second law violating steady-states.
Phys Rev E 50:1645–1648
Forde NR, Izhaky D, Woodcock GR, Wuite GJL,
Bustamante C (2002) Using mechanical force to
probe the mechanism of pausing and arrest during
continuous elongation by Escherichia coli RNA poly-
merase. Proc Natl Acad Sci 99:11682–11687
Gallavotti G, Cohen EGD (1995) Dynamical ensembles in
non-equilibrium statistical mechanics. Phys Rev Lett
74:2694–2697
Gore J, Ritort F, Bustamante C (2003) Bias and error in
estimates of equilibrium free-energy differences from
non-equilibrium measurements. Proc Natl Acad Sci
100:12564–12569
Hatano T, Sasa S (2005) Steady-state thermodynamics of
Langevin systems. Phys Rev Lett 86:3463–3466
Hendrix DA, Jarzynski C (2001) A “fast growth” method
of computing free-energy differences. J Chem Phys
114:5974–5981
Hill TL (1994) Thermodynamics of small systems. Dover
Publications, New York
Hummer G (2001) Fast-growth thermodynamic integra-
tion: error and efﬁciency analysis. J Chem Phys 114:
7330–7337
492
Fluctuation Theorems, Brownian Motors and Thermodynamics of Small Systems

Hummer G, Szabo A (2001) Free-energy reconstruction
from non-equilibrium single-molecule experiments.
Proc Natl Acad Sci 98:3658–3661
Hummer G, Szabo A (2005) Free-energy surfaces from
single-molecule force spectroscopy. Acc Chem Res
38:504–513
Imparato A, Peliti L (2005a) Work distribution and path
integrals in mean-ﬁeld systems. Europhys Lett 70:
740–746
Imparato A, Peliti L (2005b) Work probability distribution
in systems driven out of equilibrium. Phys Rev
E 72:046114
Isralewitz B, Gao M, Schulten K (2001) Steered molecular
dynamics and mechanical functions of proteins. Curr
Opin Struct Biol 11:224–230
Jarzynski C (1997) Non-equilibrium equality for free-
energy differences. Phys Rev Lett 78:2690–2693
Jarzynski C (2001) How does a system respond when
driven away from thermal equilibrium? Proc Natl
Acad Sci 98:3636–3638
Jarzynski C (2004) Non-equilibrium work theorem for a
system strongly coupled to a thermal environment.
J Stat Mech, P09005
Jarzynski C, Wojcik DK (2004) Classical and quantum
ﬂuctuation theorems for heat exchange. Phys Rev Lett
92:230602
Jensen MO, Park S, Tajkhorshid E, Schulten K (2002)
Energetics
of
glycerol
conduction
through
aquaglyceroporin Glpf. Proc Natl Acad Sci 99:
6731–6736
Kawai R, Parrondo JMR, den Broeck CV (2007) Dissipa-
tion: the phase-space perspective. Phys Rev Lett
98:080602
Kirkwood JG (1935) Statistical mechanics of ﬂuid mix-
tures. J Chem Phys 3:300–313
Kosztin I, Barz B, Janosi L (2006) Calculating potentials of
mean force and diffusion coefﬁcients from non-
equilibrium processes without Jarzynski equality.
J Chem Phys 124:064106
Kurchan J (1998) Fluctuation theorem for stochastic
dynamics. J Phys A 31:3719–3729
Lebowitz JL, Spohn H (1999) A Gallavotti-Cohen type
symmetry in the large deviation functional for stochas-
tic dynamics. J Stat Phys 95:333–365
Lhua RC, Grossberg AY (2005) Practical applicability of
the Jarzynski relation in statistical mechanics: a peda-
gogical example. J Phys Chem B 109:6805–6811
Liphardt J, Dumont S, Smith SB, Tinoco I, Bustamante
C
(2002)
Equilibrium
information
from
non-
equilibrium measurements in an experimental test of
the Jarzynski equality. Science 296:1833–1835
Maes C (1999) The ﬂuctuation theorem as a Gibbs prop-
erty. J Stat Phys 95:367–392
Mazonka O, Jarzynski C (1999) Exactly solvable model
illustrating far-from-equilibrium predictions. Preprint
arXiv:condmat/9912121
Min W, Jiang L, Yu J, Kou SC, Qian H, Xie XS
(2005) Non-equilibrium steady state of a nanometric
biochemical system: determining the thermodynamic
driving force from single enzyme turnover time traces.
Nano 5:2373–2378
Oono Y, Paniconi M (1998) Steady state thermodynamics.
Prog Theor Phys Suppl 130:29–44
Park S, Schulten K (2004) Calculating potentials of mean
force from steered molecular dynamics simulation.
J Chem Phys 13:5946–5961
Park S, Khalili-Araghi F, Tajkhorshid E, Schulten K (2003)
Free-energy
calculation
from
steered
molecular
dynamics
simulations
using
Jarzynski’s
equality.
J Phys Chem B 119:3559–3566
Qian H (2005) Cycle kinetics, steady state thermodynam-
ics and motors – a paradigm for living matter physics.
J Phys (Condensed Matter) 17:S3783–S3794
Reid JC, Sevick EM, Evans DJ (2005) A uniﬁed descrip-
tion of two theorems in non-equilibrium statistical
mechanics: the ﬂuctuation theorem and the work rela-
tion. Europhys Lett 72:726–730
Ritort F (2004) Work and heat ﬂuctuations in two-state
systems: a trajectory thermodynamics formalism.
J Stat Mech (Theor Exp), P10016
Ritort F, Bustamante C, Tinoco I (2002) A two-state
kinetic model for the unfolding of single molecules
by mechanical force. Proc Natl Acad Sci 99:
13544–13548
Schuler S, Speck T, Tierz C, Wrachtrup J, Seifert U (2005)
Experimental test of the ﬂuctuation theorem for a
driven two-level system with time-dependent rates.
Phys Rev Lett 94:180602
Seifert U (2004) Fluctuation theorem for birth-death or
chemical master equations with time-dependent rates.
J Phys A 37:L517–L521
Seifert U (2005a) Entropy production along a stochastic
trajectory and an integral ﬂuctuation theorem. Phys
Rev Lett 95:040602
Seifert U (2005b) Entropy production along a stochastic
trajectory and an integral ﬂuctuation theorem. Phys
Rev Lett 95:040602
Shirts MR, Bair E, Hooker G, Pande VS (2003) Equilib-
rium free energies from non-equilibrium measurements
using maximum-likelihood methods. Phys Rev Lett
91:140601
Speck T, Seifert U (2005a) Integral ﬂuctuation theorem for
the housekeeping heat. J Phys A 38:L581–L588
Speck T, Seifert U (2005b) Dissipated work in driven
harmonic diffusive systems: general solution and appli-
cation to stretching rouse polymers. Eur Phys J B 43:
521–527
Spudich A (2002) How molecular motors work. Nature
372:515–518
Trepagnier EH, Jarzynski C, Ritort F, Crooks GE,
Bustamante C, Liphardt J (2004) Experimental test of
Hatano and Sasa’s nonequilibrium steady state equality.
Proc Natl Acad Sci 101:15038–15041
Van Zon R, Cohen EGD (2003a) Extension of the ﬂuctu-
ation theorem. Phys Rev Lett 91:110601
Van Zon R, Cohen EGD (2003b) Stationary and transient
work-ﬂuctuation theorems for a dragged Brownian par-
ticle. Phys Rev E 67:046102
Fluctuation Theorems, Brownian Motors and Thermodynamics of Small Systems
493

Van Zon R, Cohen EGD (2004) Extended heat-ﬂuctuation
theorems for a system with deterministic and stochastic
forces. Phys Rev E 69:056121
Wang H, Oster G (2002) The Stokes efﬁciency for molecular
motors and its applications. Europhys Lett 57:134–140
Wang MD, Schnitzer MJ, Yin H, Landick R, Gelles J, Block
SM (1998) Force and velocity measured for single mol-
ecules of RNA polymerase. Science 282:902–907
Wang GM, Sevick EM, Mittag E, Searles DJ, Evans DJ
(2002) Experimental demonstration of violations of the
second law of thermodynamics for small systems and
short timescales. Phys Rev Lett 89:050601
Wood RH, Mühlbauer WCF, Thompson PT (1991) System-
atic errors in free energy perturbation calculations due
to a ﬁnite sample of conﬁguration space: sample-size
hysteresis. J Phys Chem 95:6670–6675
Yin H, Wang MD, Svoboda K, Landick R, Block SM,
Gelles J (1995) Transcription against an applied force.
Science 270:1653–1657
Zuckermann DM, Woolf TB (2002) Theory of systematic
computational error in free energy differences. Phys
Rev Lett 89:180602
Zwanzig RW (1954) High-temperature equation of state by
a perturbation method. I. Non-polar gases. J Chem Phys
22:1420–1426
Books and Reviews
Comptes Rendus Physique (2007) Work, dissipation and
ﬂuctuations in non-equilibrium physics, vol 8(5–6).
Elsevier
Duplantier B, Dalibard J, Rivasseau V (eds) (2004) Bose-
Einstein condensation and entropy 2. Birkhäuser,
Basel. Contributions by Maes C, On the origin and
use of ﬂuctuation relations on the entropy, p 145–191
and Ritort F, Work ﬂuctuations, transient violations of
the second law and free-energy recovery methods,
pp. 193–226. Available also at: http://www.ffn.ub.es/
ritort/publications.html
Evans DJ, Searles D (2002) The ﬂuctuation theorem. Adv
Phys 51:1529–1585
Garbaczewski P, Olkiewicz R (eds) (2002) Dynamics
of
dissipation.
Springer,
Berlin.
Contribution
by
Jarzynski
C,
What
is
the
microscopic
response of a system driven far from equilibrium,
pp. 63–82
Mathews CK, van Holde KE, Ahern KG (2000) Biochem-
istry. Addison-Wesley, Longman, SF
Ritort F (2008) Nonequilibrium ﬂuctuations in small sys-
tems:
from
physics
to
biology.
In:
Rice
SA
(ed) Advances in Chemical Physics, vol 137. Wiley,
Hoboken, pp 31–123
494
Fluctuation Theorems, Brownian Motors and Thermodynamics of Small Systems

Neuronal Dynamics
Nicolas Brunel1 and Vincent Hakim2
1Department of Neurobiology, Duke University
School of Medicine, Durhum, North Carolina,
USA
2Département de Physique, Ecole Normale
Supérieure, Paris, France
Article Outline
Glossary
Deﬁnition of the Subject
Introduction
Types of Modeling and Theoretical Tools
Intrinsic Network Dynamics
Stimulus Driven Dynamics
Future Directions
Bibliography
Glossary
Action potential or Spikes electrical pulses of
an amplitude of about 100 mV that travel along
nerve ﬁbers.
Field potential an electrical signal recorded
extracellularly which arises from the synchro-
nized activity of many cells.
Hippocampus one of the most studied area of
the mammalian nervous system which is part
of the limbic system and is involved in learning
and memory.
Neuron the main excitable cells of nerve tissue.
Network an ensemble of synaptically connected
cells.
Synapse the specialized junction between two
neurons where the action potential voltage
transient in the presynaptic cell is transmitted
to the post-synaptic cell via neurotransmitter
release (chemical synapse) or direct electrical
connection (electrical synapse).
Definition of the Subject
How information is processed by nervous systems
is a question of major interest, with far-reaching
implications for domains as diverse as medicine
and philosophy. It is however still far from under-
stood despite much work and progress during the
last 60 years. Neurons are cells which exhibit
diverse dynamical behaviors. Our present partial
view makes it clear that, besides physiology of
single neurons and anatomy of neural systems,
understanding the dynamics of coupled neuron
assemblies and their collective dynamics is of
utmost importance. This requires supplementing
the tools of experimental biology, that themselves
are making impressive progress, by modeling and
theoretical analysis.
Introduction
Since the ﬁrst electrical recordings, it has been
noted that the mammalian brain exhibits diverse
patterns of activity [14]. Oscillations at various
frequencies are prominent features of human
electroencephalograms that is, voltage signals
recorded from the scalp [19]. Their dominant
frequencies are state and task dependent shifting
from slow “delta” frequencies (1–4 Hz) in cer-
tain stages of sleep, to “alpha” frequencies
(8–13 Hz) in quiet wakefulness or “beta” fre-
quencies (13–30 Hz) in attentive immobility.
Intracranial recordings of ﬁeld potential or neu-
ron activity in animals have revealed higher fre-
quency components from 40 Hz to more than
200 Hz and have also shown that neural rhythms
depend on the neural structures from which they
originate [3]. For instance, in the rat hippocam-
pus, rhythms at theta (4–8 Hz) and gamma
(30–100 Hz) frequencies are observed during
exploratory behaviors whereas intermittent fast
oscillations (100–200 Hz) are recorded during
awake immobility and consummatory behaviors
[34]. In the rat olfactory bulb, odorants induce
strong gamma oscillations [4].
© Springer-Verlag 2009
B. Chakraborty (ed.), Statistical and Nonlinear Physics,
https://doi.org/10.1007/978-1-0716-1454-9_359
Originally published in
R. A. Meyers (ed.), Encyclopedia of Complexity and Systems Science, © Springer-Verlag 2009
https://doi.org/10.1007/978-3-642-27737-5_359
495

Electrophysiological recordings, visualiza-
tion, pharmacological and genetic manipula-
tions
are
important
experimental
tools
for
observing and assessing the mechanisms under-
lying this complex neural activity. However,
analyzing the dynamics of a large ensemble of
coupled dynamical elements is a difﬁcult task.
Modeling, theoretical analysis and computer
simulations are proving increasingly helpful to
interpret experimental data, as it becomes more
precise and extensive, and to direct further
experiments.
In the following, we ﬁrst review the different
types of models that are currently most useful in
analyzing network dynamics. We then consider
various topics to which theoretical modeling has
signiﬁcantly contributed. We start in Sect.
“Intrinsic Network Dynamics” by discussing
spontaneous neural activity, that is, activity not
directly induced by stimulus-processing. Exper-
imentally, “background” spontaneous activity
appears to consist of neurons ﬁring irregularly
and at low rates and poses a ﬁrst modeling
challenge.
The
coexistence
of
different
attractors, a question of central interest in dif-
ferent contexts, is considered next. We then
review
the
different
mechanisms
that
are
thought to give rise to the various time scales
of neural dynamics. In Sect. “Stimulus Driven
Dynamics”, we examine how stimulus presen-
tation can modify neural dynamics and discuss
various ways in which dynamics can lead to
information processing. We begin by discussing
two contrasting views: classically, sensory pro-
cessing has been thought to proceed by a
feedforward
and
stimulus-driven
dynamic,
whereas some more recent modeling and exper-
iments suggest that stimuli provide only a weak
bias on endogenous dynamics. We then examine
various other ways in which dynamics can con-
tribute to information processing and memory.
The precise role of oscillations at diverse fre-
quencies in information processing is still ill-
understood. We brieﬂy discuss two of the better
understood structures and several proposals. We
ﬁnally conclude, in Sect. “Future Directions”,
by pointing out some approaches that appear to
bear promises of future progress.
Types of Modeling and Theoretical Tools
The ﬁrst task of a modeler in computational or
theoretical neuroscience is to specify a particu-
lar model to be investigated. Choosing which
model depends, of course, on the nature of the
problem one is interested in, as well as on the
availability of relevant experimental data. For
example, if one is interested in understanding
the origin of the irregularity of spike trains in
cortex as observed in extracellular recordings
in vivo, it is clear that one needs a spiking
neuron model. For people working at the net-
work level, this means specifying at least three
things:
the
‘architecture’
of
the
network
(number of ‘units’, a speciﬁcation of who com-
municates with who, and ﬁnally speciﬁcation of
the inputs); a model for the ‘units’ themselves
(these ‘units’ can be groups or populations of
functionally equivalent neurons, or single neu-
rons); and a model for the connections between
the units (synapses in the case units are single
neurons).
In
this
section,
we
ﬁrst
brieﬂy
describe popular models of units and connec-
tions, and then commonly studied network
architectures. Finally, we explain brieﬂy the
theoretical methods that are used to investigate
such networks.
Different Classes of Neurons Models
Broadly speaking, there are three classes of
models: rate models; networks of binary neurons;
and networks of spiking neurons. Though net-
works of binary neurons are a very useful tool to
investigate associative memory properties of
recurrent networks, they are not well-suited to
study questions involving dynamics. We therefore
restrict ourselves here to discussing rate models
and networks of spiking neurons.
Rate Models In so-called ‘rate models’ (also
called neural mass models, or neural ﬁeld
models), one describes the activity of a population
of functionally equivalent neurons by a continu-
ous variable r that typically obeys an ordinary
differential equation. In its simplest form, the
activity of a single population of neurons can be
described by the equation
496
Neuronal Dynamics

t dr
dt ¼ r þ F Iext þ Jr
ð
Þ,
ð1Þ
where: r is the mean activity (ﬁring rate) of the
population, t is the characteristic time constant
of rate dynamics, F is the steady state input-
output transfer function (f–I curve), that is typi-
cally taken to be sigmoidal, Iext are the external
inputs to the population, and J is the strength of
the intra-population connections. For excitatory
populations, J > 0, while for inhibitory popu-
lations, J < 0.
The function F that describes the ‘static’ trans-
fer function of neurons in the population can take
different forms. Popular transfer functions are
threshold-linear,
F Ið Þ ¼
I  T
I > T
0
I < T

,
ð2Þ
where T is a threshold, or sigmoidal, F(I) ¼
rmax/(1 þ exp (β(I  T))), where T is again a
threshold and β measures the steepness of the f–I
curve at half-maximal ﬁring rate. Note that while
the
threshold-linear
transfer
function
is
unbounded, the sigmoidal one saturates at a max-
imal rate rmax. In the limit β ! 1, the sigmoidal
transfer function becomes binary, F ¼ rmax for
I > T, F ¼ 0 otherwise.
Another choice is to take F as the analytically
computed transfer function of a speciﬁc spiking
neuron model, like the integrate-and-ﬁre model.
As described below, one can compute the average
ﬁring frequency as a function of both mean and
variance of inputs in some simple cases, and the
resulting function can be used as a transfer func-
tion in a rate model formulation [7]. Examples of
f–I curves are shown schematically in Fig. la.
Spiking Neurons As for most cells, ionic con-
centration differences and selective membrane
permeability make neurons intracellularly hyper-
polarized
with
respect
to
the
extracellular
medium. The difference between the intracellu-
lar and extracellular potentials, the cell mem-
brane potential, is thus negative, with a typical
value of about –70 mV. Most neurons in the
nervous
systems
of
vertebrates
use
action
potentials,1 or spikes, which are large depolariza-
tions of short duration (1 ms), as communication
units. It is therefore natural to use spiking neuron
models in network studies. The action potential is
primarily a membrane phenomenon that can be
described with different degrees of realism and
reﬁnement. There is a correspondingly large diver-
sity of single neuron spiking models in the literature,
from
simple,
one-variable
integrate-
and-ﬁre
models, to complex multi-compartmental models
with many voltage-gated ionic channels. The com-
plexity of a single neuron model can be character-
ized along two dimensions: (i) the number of
variables describing the membrane dynamics at a
given location; and (ii) the number of compartments
describing the spatial geometry of the neuron.
Along the ﬁrst dimension, the simplest model
is the integrate-and-ﬁre model. It retains as its
only variable the membrane potential [27, 28,
68, 74, 112] and simply describes the action
potential by a threshold VT in membrane potential.
In the subthreshold range V < VT, the membrane
dynamic is simply described as that of a capaci-
tance C (of about 1 mF/cm2, coming from the
insulating property of the lipid bilayer) in parallel
with a passive leak conductance g,
tm dV
dt ¼  V  VL
ð
Þ þ Isyn tð Þ,
ð3Þ
where tm ¼ C/g is the membrane time constant
(typical values are 10–20 ms), VL is the resting
potential, and Isyn(t) are the synaptic inputs, in
which we have absorbed the input resistance of
the neuron (typical values are 10–100 MΩ). Thus,
in Eq. (3), the inputs are in mV. In this model, a
spike is emitted when the voltage hits the thresh-
old VT. At such times, the voltage is immediately
reset to a sub-threshold voltage VR. It is also
possible to add to the model an absolute refractory
period, during which the voltage is clamped to the
reset, to get saturation of the ﬁring frequency. To
choose the values of the voltage parameters, there
are basically two options: take the ‘realistic’
1Note however that there are well-documented exceptions,
for instance in the retina.
Neuronal Dynamics
497

values (similar to observed values in real neu-
rons), VL  70 mV, VT  50 mV, and VR
somewhere in between; or deﬁne the origin of
the voltage to be VL ¼ 0, and redeﬁne VT and VR
accordingly. The dynamic of the integrate-and-
ﬁre model to various types of inputs is shown in
Fig. 1b.
At the opposite extreme, ‘biophysically realis-
tic’ models aim to accurately represent the dynam-
ics of the ionic channels that modify membrane
permeability. They often employ the celebrated
Hodgkin–Huxley formalism [55] which describes
the ionic channel contribution as changes in mem-
brane conductance via the dynamics of the activa-
tion and inactivation of various voltage-gated
ionic
currents.
While
the
integrate-and-ﬁre
model, due to its very simplicity, is a model of
choice for analytical studies and large-scale sim-
ulations, it lacks many features exhibited by real
neurons. These features can often be accurately
Neuronal Dynamics, Fig. 1 Single unit/neuron models.
(a) Rate model: commonly used f–I curves F (mean ﬁring
rate as a function of inputs). Solid: threshold linear func-
tion. Dashed: sigmoidal function. Dot-dashed: f–I curve of
a leaky integrate-and-ﬁre neuron subjected to noisy inputs.
(b)
Dynamics
of
a
leaky
integrate-and-ﬁre
neuron
(membrane potential) driven by constant suprathreshold
input (upper panel) or noisy input (lower panel). Spikes
are added by hand to better visualize the timing. (c)
Dynamics of two versions of an exponential integrate-
and-ﬁre model (red: with hard reset, green: with adaptive
threshold), together with recording of a cortical pyramidal
cell. Both the artiﬁcial and the real cell receive the same
injected time-dependent current (a realization of an
Ornstein–Uhlenbeck process). (From Ref. [8])
498
Neuronal Dynamics

captured in the Hodgkin–Huxley formalism but at
the price of difﬁculties in mathematical analysis
(due to a large number of variables and pro-
nounced non-linearities) and heavy computational
cost. An intermediate class of models try to cap-
ture the best of both worlds: they contain the
minimal number of variables (typically 1 or 2)
and the minimal non-linearity required to capture
particular phenomena of interest [21]. For exam-
ple, generalized integrate-and-ﬁre neurons con-
tain
an
additional
variable
coupled
to
the
voltage, which can give rise to sub-threshold res-
onance, as seen in many cell types [61, 104]; non-
linear integrate-and-ﬁre models can accurately
capture
spike
generation
with
a
minimal
(exponential) non-linearity in the voltage equation
[8, 42], see Fig. 1c; ﬁring rate adaptation can be
captured by a single adaptation variable coupled
to the voltage; and so on.
Along the second (spatial) dimension, a similar
diversity exists. The simplest models are composed
of a single compartment. At the opposite, detailed
models of cells with highly branched dendritic
trees, such as the cerebellar Purkinje cell, can con-
tain more than a thousand compartments [36].
Again,
intermediate
models,
such
as
two-
compartmental models, try to capture the best of
both worlds: capturing non-trivial phenomena
exhibited by real cells with the minimal description.
While multi-compartment models have been a
valuable tool at the single neuron level, most
studies of network behaviors use neurons with a
single compartment. Apart from the obvious
issues of mathematical tractability and computa-
tional cost, another concern limiting the use of
such models is the limited present experimental
knowledge on relative geometry and repartition of
ionic channels. Ongoing initiatives, such as the
“blue brain” project [86], may lead this to change,
but we expect progress in this direction to be slow,
given the huge number of parameters (especially
if there are correlations in the properties of
connected neurons).
Synapses
While in rate models synapses are speciﬁed by a
single number, in spiking neuron models synapses
are speciﬁed by dynamical variables. In the
simplest case, synapses have static amplitude:
their response to a particular pre-synaptic spike
is the same regardless of the history of their acti-
vation. However, many, if not all, synapses in the
CNS are history-dependent. This is described by
models capturing short- and/or long-term plastic-
ity properties.
Total Synaptic Inputs A typical neuron in the
CNS receives inputs from something on the order
of 10,000 presynaptic neurons.2 The total synaptic
inputs Isyn(t) of Eq. (3) are typically taken as a
linear sum of both individual synaptic inputs and
individual spikes. This leads to a synaptic current
to neuron i of the type
Ii tð Þ ¼
X
j
Jij
X
k
s t  tk
j


,
where the sum over j runs over pre-synaptic neu-
rons, Jij deﬁnes the amplitude of a unitary post-
synaptic potential (PSP) elicited by a spike of neu-
ron j in neuron i (Jij > 0 if neuron j is excitatory,
while Jij < 0 if neuron j is inhibitory), the sum over
k is a sum over spikes of pre-synaptic neuron j,
S describes the temporal dynamics of a unitary
post-synaptic current (PSC see below), and tk
j is
the timing of the kth spike emitted by neuron j.
The
simplest
models
use
the
so-called
“current-based” description of synaptic inputs, in
which the current is independent of the voltage.
A more realistic description is to take a voltage
dependent J / g(V  Vrev) where g is the time-
dependent synaptic conductance, and Vrev is the
corresponding
reversal
potential
–
the
“conductance-based” description. Typical values
for PSP amplitudes are in the range 0.1–1 mV;
Vrev  0 mV for excitatory synapses, while
Vrev  80 mV for inhibitory synapses. Typical
values for synaptic conductances are in the nS
range.
2This is an estimate for pyramidal cells in neocortex and
hippocampus. Different cell types can have widely differ-
ent average number of inputs, from the 4 average inputs of
a granule cell in cerebellum, to the more than 100,000
inputs of a Purkinje cell.
Neuronal Dynamics
499

A Simplified Semi-realistic Description for
Single PSCs
The time course of post-synaptic currents elicited
by a single spike can be described quite accu-
rately by a delayed difference of exponentials.
When a spike is emitted at time t ¼ 0, the current
is zero until t ¼ D, where D is the delay, or
latency, of the synaptic connection. Then the
current is described by
s tð Þ / exp
 t  D
ð
Þ
td


 exp
 t  D
ð
Þ
tr


,
ð4Þ
where tr < td describe the rise and decay times of
the current, respectively. This can be equivalently
described by the system of differential equations
td ds
dt ¼ s þ x
tr dx
dt ¼ x þ d t  D
ð
Þ:
Typical values for the time constants are:
D  1 ms; tr and td vary widely depending on
receptor type, but are tr < 1 ms, td  2–10 ms for
the fast (AMPA and GABAA) receptor-mediated
synaptic responses. See Fig. 2 for synaptic
currents described by Eq. (4), as well as a few
experimentally recorded synaptic currents.
Dynamic Synapses Virtually all synapses in the
CNS undergo plasticity at various time scales.
Short-term plasticity (on timescales of 100 s of
ms) is ubiquitous; Short-term depression and
facilitation has been characterized experimentally
and models exist that reproduce fairly accurately
the characteristics of this plasticity (see [2, 117]).
On longer timescales (>1 h) various types of
synapses (for example, pyramidal-to-pyramidal
synapses in the neocortex; CA3 to CA1 synapses
in the hippocampus; granule cell to Purkinje cell
synapses in the cerebellum) exhibit various types of
long-term plastic changes. There is a vast amount of
material documenting such plasticity in the literature
(for reviews see [16, 82, 83, 119]), and a large
number of investigators have proposed models that
account for rate-based and/or spike-timing based
plasticity.
In this review, we will mostly consider net-
works with ﬁxed synapses; the effects of both
short-term and longterm plasticity will be men-
tioned only brieﬂy.
Network Architecture
The network architecture speciﬁes how the units,
or neurons, are coupled together.
Neuronal Dynamics, Fig. 2 Synaptic models. (a) Syn-
aptic current elicited by a single spike of Eq. (4). Timing of
the presynaptic spike is indicated schematically by a dotted
line. (b) Synaptic currents mediated by various receptors,
recorded in various slice preparations. From [38]
500
Neuronal Dynamics

Architectures in Rate Models Rate models are
often used to investigate the dynamics of spatially
extended networks, or systems which encode con-
tinuous stimuli. A prototypical example is given
by models of the primary visual cortex, in which
the activity r(x) at a given location x evolves
according to
t dr x
ð Þ
dt
¼ r x
ð Þ þ F Iext x, t
ð
Þ þ
ð
dyJ x
ð , yÞr y
ð Þ


:
ð5Þ
The network ‘architecture’ is characterized by
the ‘synaptic footprint’ J(x, y) that speciﬁes the
strength of connections from y to x (the recurrent
part); and the inputs Iext(x, t), describing inputs
coming from outside the modeled network (LGN
and other cortical areas in the case of primary
visual cortex). See Fig. 3a.
Networks of Spiking Neurons The architecture
of a network of spiking neurons can be speciﬁed
by answering the following list of questions:
How many classes of neurons? Early studies of
networks of spiking neurons focused on one
population networks
(either
excitatory or
inhibitory
networks).
Networks
in
which
there are two populations of neurons—one
excitatory, and one inhibitory—have also
been analyzed in detail.
How many neurons in each class? Analytical
studies often use the limit in which the number
of neurons goes to inﬁnity (see theoretical tools
section below). This is justiﬁed by the fact that
local networks in the brain are typically
composed of a very large number of neurons
( 105). It is also becoming possible to simulate
networks of such large numbers of neurons.
What is the wiring diagram? Early studies
focused on fully connected networks, which
are easier to handle analytically. Another popu-
lar architecture has been a randomly connected
network, with a given connection probability
(see Fig. 3b). Such an architecture takes into
account the relatively low connection probabil-
ity of nearby neurons. Relatively few studies of
networks of spiking neurons take into account
spatial structure, such as a monotonically
decaying connection probability.
What is the nature of the individual couplings
between neurons? Theorists have investi-
gated networks connected by chemical synap-
ses, electrical synapses, or both. More recently,
the effect of various types of synaptic plasticity
phenomena (both short-term and long-term)
has begun to be studied.
What are the inputs to the neurons in the
network?
Popular choices to study the intrinsic dynamics of
networks are constant uniform inputs, or noisy
inputs, which are uncorrelated from neuron to
neuron.
To
understand
the
information
Neuronal Dynamics, Fig. 3 Network architectures. (a)
Sketch of a rate model. Each circle represents a population
of cells at a given location. Lines connecting circles repre-
sent
synaptic
connections
between
populations.
(b)
A randomly connected network of individual neurons.
The
drawing
schematically
represents
cell
bodies
(circles), dendrites (vertical line), and axons contacting
dendrites of post-synaptic neurons (curved lines)
Neuronal Dynamics
501

processing capabilities of networks, one has to
choose a model for the type of inputs that are
processed by such network. This choice typi-
cally depends on the area that is modeled. For
example, inputs to a model of a hypercolumn
in visual cortex are often taken to represent
(ﬁxed or dynamic) oriented bars, and are
modeled appropriately.
Theoretical Tools
Different types of analytical tools are available
depending on the nature of the model. Rate
models are typically speciﬁed by systems of
coupled ordinary differential equations. Hence,
standard tools can be borrowed from dynamical
system theory. One typically starts by investigat-
ing the case of constant inputs, for which it is
sometimes possible to ﬁnd ﬁxed points, and the
linear stability of these ﬁxed points. Sometimes, it
is possible to analyze more complex behaviors,
oscillatory states, spatially localized states, waves,
etc., and their stability.
Networks of spiking neurons are substantially
harder to analyze. Several types of approximations
can be used, depending on the strength of coupling
and the level of noise: fully connected networks in
the weak coupling/weak noise scenario can be
studied in the framework of the theory of coupled
oscillators. When coupling and noise are strong, it
is sometimes possible to approximate synaptic
inputs to a neuron as a random Gaussian process,
the moments of which depends on both connectiv-
ity and activity in the network. For instance, for
leaky integrate-and-ﬁre neurons, this leads to the
study of the Langevin-like equation
tm dV
dt ¼  V  VL
ð
Þ þ Isyn tð Þ
þ s
ﬃﬃﬃﬃﬃ
tm
p
x tð Þ,
ð6Þ
where Isyn represents the mean synaptic input and
x(t) a white noise term representing its ﬂuctuations.
In conditions in which correlations between these
inputs can be neglected (as when the connection
probability between cells is weak), a network of
integrate-and-ﬁre neurons can then be character-
ized by a Fokker–Planck equation that describes
the time evolution of the instantaneous distribution
of membrane potentials [1, 22, 105].
tm @P
@t ¼ @
@V
V  Isyn tð Þ

	
P


þ s2
2
@2P
@V2 ,
ð7Þ
where the mean Isyn tð Þ
is determined self-
consistently from the neuron discharges.
In addition to the above mentioned analytical
tools, numerical simulations are almost always
indispensable, if only to check the validity of the
approximations. While simulating rate models is
relatively straightforward, simulations of net-
works of spiking neurons are, again, more
demanding.
In
addition
to
standard
ﬁnite-
difference integration schemes [53, 57, 101], it is
sometimes possible to use event-driven schemes,
in which one jumps from one spike to the next,
using an exact integration of network dynamics
during inter-spike intervals (see [88]).
Intrinsic Network Dynamics
We start by a description of intrinsic network
dynamics, that is, dynamics in absence of spatially
or temporally structured inputs. In rate models,
this means taking a constant and uniform input
Iext(x, t) ¼ Iext; in networks of spiking neurons,
this means taking either a constant deterministic
input, or a noisy stationary input. Noise is typi-
cally chosen to be a Gaussian random noise,
uncorrelated
from
neuron
to
neuron,
or
uncorrelated Poisson processes independently
activating all the neurons of the network.
The goal is then to understand the types of
dynamics that can be generated by the network,
independently
of
its
inputs.
Experimentally,
intrinsic dynamics of a network can be observed
in vitro, or in vivo, either in anesthetized animals
or in awake animals in absence of speciﬁc inputs
that activate the particular area under observation.
Such experiments reveal many different types of
activity that modelers have been trying to under-
stand. A prominent and ubiquitous ﬁnding in
in vivo recordings is irregular background activity
at low rates. The issue of the origin and mecha-
nisms of this activity can be addressed using net-
works of spiking neurons, and will be the topic of
Subsect. “Irregular Firing at Low Rates”. We will
then move to the issue of multistability in net-
works, which can be considered in the simple
502
Neuronal Dynamics

setting of rate models. Finally, we will discuss the
issue of synchronization and oscillations, which
can be addressed both with rate models and spik-
ing neuron models.
Irregular Firing at Low Rates
Recordings of cortical neurons in vivo show very
irregular activity. The distributions of intervals
between successive action potential emissions,
commonly called inter spike intervals (ISI), are
approximately Poissonian in a variety of cases.
Understanding this irregularity, is a ﬁrst theoretical
challenge [15, 111]. Cortical cells receive on the
order of 104 synapses. This large number should
tend to promote regular ﬁring since ﬂuctuations of
the total input should be small compared to its
mean,
unless
inputs
are
strongly
correlated.
Another related difﬁculty is that measurements of
synaptic weights [40, 56, 87, 110] (see [10] for a
short survey) indicate that the detectable connec-
tions between pyramidal cells are relatively strong
with a mean value of 0.5–1 mV, as measured from
the peak somatic depolarization that they provoke.
As a consequence, thousands of presynaptic pyra-
midal cells spiking at a low rate of a few Hertz
should provide a strong depolarization of the post
synaptic cells. It is thus not clear how a low rate of
spike emission can be maintained in a recurrently
coupled network. One loophole in the argument is
that it does not take inhibition into account. Inhibi-
tion can potentially solve both puzzles at once when
inhibitory inputs balance on average excitatory
ones [6, 108, 120, 121]. This drastically reduces
the input current so that low ﬁring rates are possible.
Moreover, current ﬂuctuations can be comparable
to the mean current, allowing for irregular ﬁring.
These studies have shown that irregular ﬁring
is obtained in randomly connected networks of
spiking neurons, as soon as recurrent inhibition
is strong enough. Remarkably, such an irregular
ﬁring can be obtained even when the inputs to the
network are deterministic, that is, in the absence
of noise [120]. The nature of this irregular ﬁring
remains the subject of intense study. Irregular
ﬁring can be associated with complex but stable
trajectories in phase space [63, 127], or with cha-
otic dynamics [127].
Recent data provide some evidence for a balance
between inhibition and excitation in cortical
networks [109]. Somewhat unexpectedly, a balance
of excitation and inhibition has also been found in
the rhythmic input onto motor neurons during
scratching behavior in turtles [13]. It is proposed
that the associated enhanced irregularity can be
used to produce a smoother muscle excitation.
Attractors with Inhomogeneously Distributed
Activity
A recurring idea in theoretical studies is that struc-
tured connectivity can lead the dynamics of a given
neural network to settle in one of several coexisting
attractors with mean activity differently distributed
among the different neurons of the networks. It is,
for instance, central to Hop-ﬁeld’s view of memory
storage in neural networks [58], as well as to pro-
posed explanations for persistent activity underly-
ing short-term memory.
Many designs of this type are based on short-
range recurrent excitation together with long-
range inhibition. The simplest embodies the
so-called “winner-take-all” mechanism. It con-
sists of two-recurrently coupled excitatory sub-
networks inhibiting each other. This can described
in a rate model framework as
t dr1
dt ¼ r1 þ F I0  Jr2
ð
Þ
ð8Þ
t dr2
dt ¼ r2 þ F I0  Jr1
ð
Þ,
ð9Þ
where r1 and r2 describe the activity of each sub-
network and J > 0 the magnitude of recurrent
inhibition. The homogeneous steady state has
r1 ¼ r2 ¼ rs with
rs ¼ F I0  Jrs
ð
Þ:
ð10Þ
However, linearization of Eqs. (8), (9) shows that
homogeneously distributed activity is unstable
when inhibition is sufﬁciently strong (the bifurca-
tion itself can be supercritical or subcriticalm
depending on the sign of the third derivative of
F). In this case, the symmetry between the two
neuronal populations is broken and there are two
possible coexisting attractors with the activity
enhanced in either sub-network enhanced and
suppressed in the other one.
Neuronal Dynamics
503

This scheme can be simply extended to several
sub-networks (with global rather than reciprocal
inhibition) to enlarge the possible number of
coexisting attractors. Some neuronal networks,
such as, for instance, the head-direction cell net-
work, are thought to possess a line of attractors
instead of a discrete set of attractors. This can
again be obtained by generalizing Eqs. (8), (9) to
cells labeled by a continuous parameter, which we
denote by θ, with excitatory connections between
cells with close values of θ and inhibition between
cells with more distant values [5, 39, 48]. For illus-
trative purposes, we describe one such simple
scheme proposed in [12], where for deﬁniteness
the continuous parameter is taken to correspond to
an angle. This so-called ring model is a speciﬁc case
of Eq. (5)
t d
dt r y, t
ð
Þ
¼ r y, t
ð
Þ þ F Iext þ
ðp
p
dy0
2p J y  y0
ð
Þr y0
ð , tÞ


,
p  y  p:
ð11Þ
It considerably simpliﬁes the analysis [12] to
restrict the synaptic coupling function to its ﬁrst
harmonic, J ¼ J0 þ J1 cos (θ  θ0) and to take F to
be a threshold linear f–I curve, F[I] ¼ β[I]+ that is
F[I] ¼ β[I] for I  T and 0 otherwise. Integration
over θ reduces the dynamics to coupled differen-
tial equations for the ﬁrst three moments r0, r11
and r12 of r with
r0 ¼
ðp
p
dy
2p r y
ð Þ,
r11 ¼
ðp
p
dy
2p r y
ð Þ cos y
ð Þ,
r12 ¼
ðp
p
dy
2p r y
ð Þ sin y
ð Þ:
ð12Þ
The homogeneous activity (r(θ) ¼ r0) is non-zero
for Iext > 0, r0 ¼ Iext/(1  βJ0); βJ0 < 1 is needed
for the dynamics to be well-behaved that is, all-to
all interactions should be inhibitory, or at least not
too excitatory, to prevent activity growth without
bounds (or saturated activity when saturation is
included in F). However, homogeneous activity is
unstable when interaction between cells with
close values of θ is large enough that is, here for
βJ1 > 2. Then, the network attractor is formed by a
line of solutions in the form
r y
ð Þ ¼ A cos y  y0
ð
Þ  cos yc
ð
Þ
½
þ,  p  y0  p:
ð13Þ
Thus, the network activity is conﬁned to cells with
parameter θ in a interval of values of width 2θc
around an arbitrary angle θ0. The constant θc, the
solution selectivity, depends only on the magni-
tude of βJ1. Localized states of activity and their
domain of existence in parameter space are shown
in Fig. 4.
The ring model is a nice example of a model
with a continuous line of attractors but it also
exempliﬁes difﬁculties inherent to this type of
models. The main problem is that a line of
attractors is a fragile structure. It is not resistant
to perturbations coming, for instance, from het-
erogeneity in the connection strengths or neurons’
properties. If this design is used in real neural
systems, there should exist additional mecha-
nisms that maintain the line of attractors and
avoid its breaking to a discrete set. Some pro-
posals exist [70, 102], but the existence of a line
attractor in an actual neural network remains to be
demonstrated.
Dynamics at Various Time Scales
As has already been stressed, spontaneous activity
in a variety of neural systems exhibits rhythmicity
at time scales that range from a few millisecond to
many seconds. We restrict ourselves to rhythms
which are intrinsically of electrophysiological ori-
gins (unlike for instance, circadian rhythms which
are accompanied by changes of neuronal excit-
ability but which are thought to be primarily
driven by changes in gene expression).
Bursts of Activity At the lower end of the spec-
trum, networks which produce repeated bursts of
activities at a time scale of a few tenths of seconds
to a few seconds are observed in different cases.
They seem to be an essential component of
504
Neuronal Dynamics

pacemakers generating locomotion [29] or respi-
ration [69]. Repeated bursts of activity are also
observed in neuron cultures [81, 93, 96]. An
important additional example is given by the
observation of up-down states in cortical slices
[107], which are proposed to be analogous to
slow oscillations during slow-wave sleep.
Speciﬁc models have been proposed for differ-
ent systems but they appear to be based on the
same general ideas. First, recurrent excitation
allows for the self-sustaining bursting state. Sec-
ond, this active state terminates when a slower
building process has reached sufﬁcient magnitude
to prevent self-sustainment of the active state. The
main contenders for the slow process are synaptic
depression (see Subsect. “Dynamic Synapses”) or
some intracellular mechanism such as a slow
increase of an ionic concentration that opens an
ion-gated channel once it has reached a threshold
level. The generation of bursts of activity by syn-
aptic depression has been modeled at a general
theoretical level in [118]. In the context of respi-
ratory rhythm generation, burst termination has
been modeled as due to the slow inactivation of
a
Na+
current
(that
is,
termination
of
a
depolarizing current) or by the activation of a
calciumgated potassium (that is, hyperpolarizing)
current. For up-down states, a sodium-dependent
potassium conductance has been hypothesized to
mediate their termination and has been taken into
account in a proposed model [32]. The mecha-
nism is illustrated in Fig. 5. Both calcium and
sodium-gated potassium conductances have been
identiﬁed in spinal neurons [123]. It is worth
noting however that in most cases the actual
mechanism at work has not been experimentally
pinpointed.
Besides burst termination, the cause of a burst
should be determined to see how a repetition at
about 1 Hz can come about. The general mecha-
nisms appear again to be of two different types.
Slow recovery from the termination process (for
instance, return of concentration to a low level by
the action of an ionic pump) can deterministically
bring the networks above a threshold for excita-
tion. Alternately, recovery can lead the network in
a low activity state from which it can stochasti-
cally transit to the active state [126].
It is worth noting here that both the size distri-
bution and duration distribution of bursts of activ-
ity in cortical slices have been examined using
multi-electrode arrays [11]. Power law distribu-
tions corresponding to critical branching pro-
cesses, reminiscent of a self-organized critical
phenomenon [9], have been found. This was
shown to emerge naturally from synaptic depres-
sion in a simpliﬁed IF neuron model without leak
[77]. The applicability of this result to more phys-
iologically realistic networks remains to be
examined.
Wandering
Between
Different
Attractors
Bursts of activity can be seen as a succession of
jumps between two attractors with homoge-
neously distributed activity—a high activity state
and a low activity state—mediated by a slow
Neuronal Dynamics, Fig. 4 Ring model. (a) Phase dia-
gram showing the position of the uniform and localized
activity for the model of Eq. (11). (b) Proﬁles of localized
activity for Iext ¼ 0.1, J2 ¼ 3. and J0 ¼ 2, 1,. –5 (from
bottom to top). (Adapted from Ref. [12])
Neuronal Dynamics
505

process. With structured connectivity, similar
mechanisms can mediate transitions between a
larger number of more complex coexisting
attractors,
as
those
described
in
Subsect.
“Attractors with Inhomogeneously Distributed
Activity”. A given active state then consists of
one particular subnetwork of active neurons
among several possible ones. Some evidence for
such stochastic visits of coexisting attractors has
been provided both in vitro and in vivo. Using
calcium imaging, mouse neocortical slices have
been found to display sparse spontaneous activity
and sets of coactive neurons that repeatedly
appear above chance level [33]. In vivo, neurons
of cat visual cortex responding to the same pre-
ferred orientation (the so-called orientation maps)
have also been reported to be spontaneously
coactive, with sets belonging to different orienta-
tions appearing in time in a stochastic manner
[67, 115]. A model with biologically plausible
connectivity and attractors consisting of orienta-
tion maps is able to reproduce these remarkable
data [17]. It should be noted, however, that the
experimental results seem also to be interpretable
as ﬂuctuations about a single background state
driven by correlated thalamic inputs [49].
Interestingly, a similar set of ideas has been
used
to
model
slow
oscillations
in
higher
cognitive tasks. One interesting example is binoc-
ular rivalry: when the right and left eyes are pre-
sented with two different images, the perceived
pattern alternates between the two images every
few seconds. Moreover, several functional mag-
netic resonance imaging studies have shown that
ﬂuctuation in neural activity in several brain areas
correlates with perception changes [80, 100, 114].
The dominance of the perception of one image
over the other one has been modeled as a compe-
tition between two recurrently coupled excitatory
networks reciprocally inhibiting each other, the
“winner-take-all” design described in Subsect.
“Attractors with Inhomogeneously Distributed
Activity”. Without further elaboration this gives
rise to two attractors: either one of the two net-
works can be active with the other silenced. Sim-
ilarly to burst or upstate termination, alternation
between attractors (and percepts) can arise by
supplementing this basic design with a slow pro-
cess. It has been modeled either as coming in a
deterministic way from synaptic depression [124]
or from a stochastic jump from one of the two
attractors to the other [92].
Synchronization
of
Periodically
Firing
Neurons Neural recordings shows oscillations
in diverse frequency bands. They depend both
on the neural structure and, when recorded
in vivo, on the type of activity that the animal is
performing. These rhythms, which are seen in
EEG or local ﬁeld potential, emerge from the
coordinated activity of many neurons. Synchroni-
zation of nonlinear oscillators [99] has of course
been thoroughly studied since its discovery by
Huyghens. Some of the tools developed [73]
have been directly applied to neurons in a regime
where they emit action potentials in a periodic
manner [52, 122]. Many experimental and theo-
retical studies have focused on single neurons and
coupled pairs of neurons to infer synchronization
properties of large networks of weakly coupled
neurons. This has acquired renewed importance
with the discovery that inhibitory interneurons in
the same subtype category appear to be preferen-
tially coupled [45, 47] For weak coupling, the
dynamics of an oscillator can be described by
the behavior of its phase, that is, its position
Neuronal Dynamics, Fig. 5 Mechanism of slow oscilla-
tions in cortical slices. Recurrent excitation provokes a
burst of activity which is terminated by a slow adaptation
current. Activity resumes when the adaptation current has
decayed. (From Ref. [32])
506
Neuronal Dynamics

along its limit cycle. How the spike advance/delay
produced by a short current injection depends on
the time of injection during the interspike interval
is a crucial quantity for synchronization. This
so-called phase-response-curve (PRC) has been
studied in different models [52, 122] with the
result that generally a small and short depolariza-
tion advances the next spike, and does so to a
greater extent the more closely it occurs before
spike emission. This is referred to as a type I PRC.
In some cases, though, (as in the original
Hodgkin- Huxley model) a less intuitive type II
PRC is found: a small depolarization just after the
spike has a greater effect on hyperpolarizing cur-
rents than on depolarizing ones and results in a
delay of the next spike. The PRC has also been
experimentally measured for neocortical neurons.
The results of the early experiment of [103] are
shown in Fig. 6 and give a type I PRC. For
instantaneous synaptic transmission, this would
lead one to expect that excitatory interactions
tend to make two identical neurons spike in
phase while inhibitory ones would push them to
antiphase spiking. It was therefore an important
theoretical ﬁnding that, for more realistic synaptic
currents with ﬁnite rise and decay, this is not
generally the case and that inhibition can be
more efﬁcient than excitation for synchronization.
For excitatory synapses, complete in-phase spik-
ing is generally unstable for type I PRC and a
ﬁnite dephasing exists even for identical neurons.
On the contrary for inhibitory synapses, in-phase
and anti-phase spiking are both possible at low
frequency, a bistable situation. However the
attraction basin of the in-phase state grows with
frequency, and above a threshold frequency the
anti-phase state disappears. This leads one to
expect a transition from antiphase to in-phase
spiking for a coupled pair of identical interneu-
rons as their ﬁring frequency increases. This has
been veriﬁed experimentally [46] as well as other
similar predictions for gap junctions or on the
combined effect of inhibitory synapses and gap
junctions [31, 78, 84].
Neuronal Dynamics, Fig. 6 Measurement of phase-
response curve (PRC) for neocortical neurons [103]. The
authors injected a short depolarizing current pulse at dif-
ferent times during the interspike interval. As shown on the
left panel, this results in a timing change for the spike
following the current injection. The right panel show
results for different injection times as well as the PRC
which summarizes the data by giving the spike time
changes
as
function
of
the
current
injection
time
(expressed here as a percentage of the ISI). (Adapted
from Ref. [103])
Neuronal Dynamics
507

Sparsely Synchronized Oscillations Although
a substantial amount of work has been devoted
to analyzing periodically ﬁring neurons with a
minimal amount of noise and heterogeneity,
this seems to be a rather infrequent situation
in the brain. Strong heterogeneity appears to be
the norm rather than the exception. Moreover,
as explained in Subsect. “Irregular Firing at
Low Rates,” the activity of most neurons
appears quite irregular and their discharge rate
is often low compared to the frequency of
gamma oscillations and faster rhythms. This is
also the case in vitro when pharmacologically-
induced activity in hippocampal slices results in
spontaneous gamma oscillations [41]. Modeling
studies have shown that a mechanism distinct
from the Huyghens-type synchronization of
oscillators can produce a fast and robust rhythm
at the network level with neurons discharging
irregularly and at a lower frequency [23]. An
example from a simulation of a network of IF
neurons is shown in Fig. 7. Recurrent inhibition
again plays an important role in these sparsely
synchronized oscillations. The basic idea can
be understood from a rate model description
similar to Eq. (1)
t dr
dt ¼ r þ F Iext þ Jr t  D
ð
Þ
½
,
ð14Þ
where the activity r(t) of the network at time t is
inﬂuenced by its activity at a previous time t – D.
The delay D models in a crude but effective way
the latency and ﬁnite kinetics of synaptic currents
(see Eq. (4)). It is not difﬁcult to show that for
J < Jc < 0, that is, for a sufﬁciently strong recur-
rent inhibition, the activity r(t) is attracted to a
limit cycle and oscillates periodically. The oscil-
lation frequency is of order 1/D and increases
from f ¼ 1/(4D) for delays short compared to t
to f ¼ 1/(2D) for delays long compared to t. It is
simple to see the origin of the oscillations: an
increase of activity in the network at time
t provokes an increase of recurrent inhibition.
This results in a decrease in network activity at
about t þ D, since transmission from one neuron
to the next takes a time D. This decrease of activ-
ity at t þ D itself again generates an increase of
activity at about t þ 2D from which the cycle can
continue. One sees that the frequency of the net-
work oscillation, of order 1/D, is directly linked to
the kinetics of synaptic transmission but not
related to the neuron discharge rate r. While the
rate description of Eq. (14) simply captures some
characteristics of network oscillations in the
sparsely synchronized regimes, it is far from pro-
viding accurate estimates, in particular for the
oscillation threshold. A more complex mathemat-
ical description based on the Fokker–Planck equa-
tion has been developed to this end [22, 25]. It
allows, moreover, the inclusion of various fea-
tures of single neuron dynamics such as the ﬁnite
rise time of the action potential [42] or of an
eventual resonance in subthreshold dynamics
[26, 104] (see [23] for a short review).
Although many experimental recordings are
suggestive of this kind of oscillations in the
brain, it is not easy to eliminate the possibility
that the observed rhythm is created by a popula-
tion of fast-spiking unidentiﬁed cells. At present,
two of the best studied examples are provided by
fast oscillations in the hippocampus and the
Neuronal Dynamics, Fig. 7 Oscillations with sparsely
ﬁring neurons in a fully connected network of 1000 leaky
integrate-and-ﬁre neurons receiving independent white
noise sources. The top panel shows a raster of 10 neurons,
while the bottom panel shows the network instantaneous
ﬁring rate (computed in 1 ms bins). The network oscillates
at about 90 Hz, while single cells ﬁre at about 30 Hz, as
predicted by theory [22, 25] (synaptic time constants: 1 ms
latency, 1 ms rise time, 6 ms decay time). (Reproduced
from Ref. [21])
508
Neuronal Dynamics

cerebellum. The “ultrafast” ripple oscillations
(140–200 Hz) are the fastest among the numerous
hippocampal rhythms. They occur together with
“sharp waves” during awake immobility and slow
wave sleep in rats. Recordings show that both the
discharge rates of pyramidal cells and interneu-
rons (average rates 8 Hz and 30 Hz respectively
[34]) are much lower than the frequency of the
population oscillation. In the cerebellum, fast
oscillations were discovered by Adrian in one of
the ﬁrst intracranial recordings [3]. More recently,
de Solages et al. [37] have provided strong evi-
dence that these fast (150–250 Hz) oscillations are
emerging
from
recurrent
inhibition
among
Purkinje cells that themselves ﬁre at an average
of about 40 Hz.
Wave Propagation The propagation of waves of
neural activity is certainly an important topic but
one that has traditionally be difﬁcult to study
experimentally. It has therefore been the subject
of relatively few speciﬁc theoretical works. Wave
propagation in neural networks has been classi-
cally analyzed in the framework of rate models
[5, 39] with results for wave existence similar to
those for general excitable media (for which many
studies exist motivated, for instance, by applica-
tions to chemical waves in the Belousov–
Zhabotinsky reaction or, in a biological context,
to electrical waves in cardiac tissue). Advances in
imaging techniques are now providing more
data on neural activity propagation, in slices
[18, 72, 107], in cell cultures [62] and even
in vivo [98]. In parallel, theoretical interest in
spiking models is developing and results have
been obtained either by the analysis of simpliﬁed
cases [50] or by simulations [32]. The results
highlight in particular the role played by inhibi-
tion and the potential importance of long- range
connections in wave propagation.
Stimulus Driven Dynamics
What happens when external stimuli are presented
to a network of neurons? An external stimulus is
usually modeled as an increase (or decrease) of
external inputs to speciﬁc groups of neurons. For
example, in the ring model, presentation of
an external stimulus representing an oriented
bar during an interval [0, T] is described by
Iext(θ, t) ¼ I0 þ I1 cos (θ  θs)Θ(t)Θ(T  t),
where θs is the angle of the presented bar. In a
spiking neuron model, an external stimulus can be
represented by a transient change of the mean
currents impinging on a subset of neurons, or by
a transient change in the frequency of incoming
spike trains. Conceptually, these transient inputs
can lead to three types of phenomena: (i) During
the transient input, the nature of the dynamics of
the network can change qualitatively. For exam-
ple, the network might switch from an asynchro-
nous to a synchronous state or it might switch
from a uniform to a spatially localized state.
(ii) In multistable networks, the stimulus can
switch the network from one state to another,
and the network will then stay in this particular
state, thereby maintaining a short-term memory of
the stimulus that was presented. (iii) Presentation
of a stimulus can induce synaptic plasticity
between neurons that are activated/inactivated by
the stimulus, leading to a remodeling of the net-
work, and therefore potentially to a change in the
repertoire of states that the network dynamics can
sustain. We now brieﬂy examine these three phe-
nomena before focusing on speciﬁc systems.
Dynamics During Stimulus Presentation
Selective Ampliﬁcation The simplest change
induced by external stimuli is a change in ﬁring
rates of the neurons. This change in rate is
governed by external inputs, but also by recurrent
connectivity. This can be best studied in the con-
text of rate models (see [35]). In general, excit-
atory networks tend to amplify external inputs,
while inhibitory networks tend to attenuate them.
With spatially structured connectivity, the net-
work will tend to amplify certain inputs, at the
same time attenuating another. A typical example
is represented by the ring model of Subsect.
“Attractors with Inhomogeneously Distributed
Activity” with a ‘Mexican-hat’ connectivity –
with this type of connectivity (excitatory at
short-range, inhibitory at long-range), the network
tends to amplify spatially localized inputs, while it
will attenuate inputs with no spatial selectivity.
Neuronal Dynamics
509

Thus, the network has the property of selective
ampliﬁcation. When the excitatory connectivity is
strong enough and one enters the marginal phase,
the network generates spatially localized states
even in absence of external inputs. In this case,
the external stimulus selects one of the possible
network states (a state in which the activity is
peaked around the most strongly activated neu-
ron) out of the repertoire of possible states
(a continuum in the case of the ring model). This
property is consistent with several experimental
ﬁndings in various areas [67, 79].
Switching from Asynchronous to
Synchronous State
Another effect of external stimuli can be to change
the degree of synchrony in the network. For exam-
ple, a stimulus can switch a network from an
asynchronous
state
to
a
synchronous
state
(or vice versa). This is typically what happens in
randomly connected networks of excitatory and
inhibitory neurons (or purely inhibitory networks)
when
inhibition
is
stronger
than
excitation
[20, 22]. This is due to the fact that external inputs
tend to increase the average ﬁring rate of the
network, leading to an effective increase in the
strength of inhibitory feedback. This increase can
potentially make the network switch from the
asynchronous to the synchronous region.
This
emergence
of
synchronous
activity
induced by external inputs is reminiscent of
many experimental ﬁndings, from oscillations
induced by odors in the olfactory system (to be
discussed in more detail below), to oscillations
correlated with selective visual attention in the
visual system of the primate [44]. The emergence
of oscillations in the presence of visual inputs has
also been hypothesized to allow the system to
solve the so-called ‘binding problem,’ though
this issue remains hotly debated [59, 71, 106].
Multistability and Working Memory
In multistable networks, stimuli can potentially
switch the network from one state to another. For
example, in winner-take-all rate models, a stimu-
lus will switch the network to an attractor state in
which the population that received the largest
input is active, while all others are inactive. The
fact that this network conﬁguration is an attractor
means that the network maintains, in short-term
memory, some information about which stimulus
it was shown. This property is the hallmark of
associative memory models, where many ‘mem-
ory states’ in which subpopulations of neurons are
selectively active at higher rates, are attractors of
the network dynamics, thanks to strong excitatory
feedback inside such sub-populations. It is widely
believed to form the basic mechanism underlying
working memory, that is, the active maintenance
of information in short-term memory. Such net-
works have been investigated extensively in the
last three decades, from networks of simpliﬁed
binary neurons [58] to networks of spiking neu-
rons of increasing realism see [6, 24]). The work-
ing of such a network is illustrated in Fig. 8.
Effect of Long-Term Synaptic Plasticity on
Network Dynamics
Another potential effect of external stimuli is to
modify the synaptic structure of the network. For
example, in associative memory models, external
stimuli are assumed to lead to synaptic modiﬁca-
tions induced by increases or decreases of ﬁring
rates of single neurons. Hebbian learning rules
posit that synapses connecting two neurons
which are strongly activated by the same stimulus
will potentiate, while synapses connecting one
strongly activated neuron to an inactivated neuron
will depress. This learning dynamic tends to cre-
ate a synaptic structure that leads to attractors
strongly correlated with the state of the network
during stimulus presentation.
Most network studies have separated neuronal
and synaptic dynamics, assuming much slower
synaptic dynamics. Typically, one studies the net-
work with a ﬁxed synaptic structure that incorpo-
rates, in a Hebbian way, learning of patterns of
activity presented to the network in the past. More
recently, there have been studies of networks with
double
dynamics
of
neurons
and
synapses
[60, 91].
Dynamics and Information Processing: Two
Specific Examples
In some neural structures, the role of dynamics in
information processing has been particularly
510
Neuronal Dynamics

scrutinized. We brieﬂy describe here two promi-
nent cases and some views and hypotheses that
they have suggested.
Dynamics
and
Odor
Discrimination As
recalled previously, it has been known since the
recordings of Adrian [4] that odors promote
gamma oscillations in the olfactory bulb. The
role of oscillations in odor processing has, how-
ever, remained unclear in spite of interesting pro-
posals [43]. Olfaction is an evolutionarily ancient
function and the associated neural structure are
analogous in very different species. Recent
recordings in insects are shedding new light on
the role of dynamics in odor discrimination. The
antennal lobe in insects corresponds to the olfac-
tory bulb in mammals. It receives input from
neurons in the olfactory epithelium and its princi-
pal neurons project to the next structure, the
“mushroom body”. In the locust, puffs of two
close odors induce antennal lobe activities that
are similar at start (as measured from the activity
of a sample of the eight hundred projection neu-
rons) but that diverge in a few hundred millisec-
onds [113]. The antennal lobe oscillations shape
its output as successive volleys of projection neu-
ron spikes emitted at a rate of about 20–30 Hz.
The numerous Kenyon cells in the mushroom
body then appear to function as coincidence
detectors that process each projection neuron
spike
volley
independently
of
the
others
[89, 113] (reset between each volley being pro-
vided by non-speciﬁc feedforward inhibition
coming from lateral horn interneurons [97]). The
precise timing of the whole process appears to
allow STDP plasticity at the Kenyon cells output
synapses [30] and presumably memory formation
in a way that remains to be related to behavioral
experiments and genetic data [54, 66].
Place
Maps
and
Oscillations
in
the
Hippocampus The
hippocampus
is
another
brain region in which oscillations are prominent
and one in which their role in information pro-
cessing is among the best studied. The hippocam-
pus is an important structure for navigation.
“Place” cells that ﬁre at particular locations have
been discovered 30 years ago in the rat hippocam-
pus [94]. Different place cells discharge in differ-
ent “place ﬁelds”, of about 25 cm in size, and
recording several cells allows the determination
of the animal position in its environment. How-
ever, place cell ﬁring is also strongly modulated at
theta frequency. The phase of a place cell dis-
charge advances as the animal enters the place
Neuronal Dynamics, Fig. 8 Dynamics of a randomly
connected network of excitatory and inhibitory neurons
with working memory properties (top: raster; bottom: aver-
age ﬁring rate of different populations of neurons). Inhibi-
tion is strong enough to stabilize the network in a
background state (before ‘sample’ presentation). External
stimuli have been ‘stored’ in the synaptic matrix, through
enhanced synaptic connectivity between neurons that
belong to a subpopulation that is activated by a stimulus
(sub-populations 1–5 in the ﬁgure). Presentation of an
external stimulus (sample 1 in the ﬁgure) increases the
ﬁring rate of the relevant neurons (see red curve in bottom
panel, average ﬁring rate of neurons in population 1). This
enhanced ﬁring rate survives removal of the stimulus
because of the strong excitatory connectivity between
1 neurons. Hence, the stimulus has switched the network
from
the
background
state
to
the
memory
state
corresponding to stimulus 1. Finally, a sufﬁciently strong
non-speciﬁc stimulus switches the network back to the
background state. (From Ref. [24])
Neuronal Dynamics
511

cell ﬁeld [95]. So, monitoring precise spike timing
with respect to the theta oscillations provides sup-
plementary information and a more accurate posi-
tion determination [64, 125]. Several models have
been proposed for place cell formation during
exploration of a new environment, some based
on network dynamics [116] related to that
exposed
in
Subsect.
“Attractors
with
Inhomogeneously Distributed Activity”, other
based on temporal modulation of single cell spik-
ing created by addition of oscillations at different
frequencies [65, 76, 95]. Supplementary complex-
ity and theoretical puzzle has been added by the
startling discovery of “grid” cells [51, 90] in the
entorhinal cortex, a neural area in the hippocam-
pal formation by which transits much of the sen-
sory information that reaches the hippocampus.
Future Directions
We are still far from having a precise understand-
ing of how neural systems operate, but there are
daily advances at all levels from the description of
detailed molecular mechanisms to that of high-
level cognitive processes. We limit ourselves
here to underlining some areas where further
investigations of dynamics are clearly needed.
We have focused on networks with very little
spatial structure but propagation and spatio-
temporal dynamics most surely play important
roles in neural information processing. This
appears to be a very rich domain that imaging
and theoretical investigations will help to explore.
A related question is that of the coordination
between different neural areas. How do dynamics
in one structure, for instance oscillations, serve to
transmit and process information in a connected
structure? As mentioned above, recent investiga-
tions of olfaction in insects provide a fascinating
glimpse on this question. It will clearly be neces-
sary to address it more generally in spite of the
experimental difﬁculties.
Our emphasis in this article has been on elec-
trical activity and its transmission. Another all-
important
aspect
is
neuromodulation
which
affects neuron properties on a slower time scale
and probably a less local spatial scale. At present,
the relation between these two facets of neural
activity has been considered in few theoretical
studies, but this needs to be thoroughly addressed
in future work.
Homeostasis, or how dynamical properties of
neuronal networks are maintained, is another
question that needs analysis. Interesting experi-
mental and theoretical work has been performed
using the stomatogastric of the lobster as an exam-
ple [75, 85], but certainly this important topic
requires further scrutiny.
These few questions among many others
should make it clear that investigation of neuronal
dynamics requires the development of powerful
experimental techniques and theoretical analyses
and that the subject will remain a topic of intense
research in the forthcoming years.
Bibliography
Primary Literature
1. Abbott LF, van Vreeswijk C (1993) Asynchronous
states in a network of pulse-coupled oscillators. Phys
Rev E 48:1483–1490
2. Abbott LF, Varela JA, Sen K, Nelson SB (1997) Syn-
aptic depression and cortical gain control. Science
275:220–224
3. Adrian ED (1934) Discharge frequencies in the cere-
bral and cerebellar cortex. Proc Physiol Soc 83:
32–33
4. Adrian ED (1942) Olfactory reactions in the brain of
the hedgehog. J Physiol 100:459–473
5. Amari S (1977) Dynamics of pattern formation in
lateral-inhibition type neural ﬁelds. Biol Cybern 27:
77–87
6. Amit DJ, Brunel N (1997) Model of global sponta-
neous activity and local structured activity during
delay periods in the cerebral cortex. Cereb Cortex 7:
237–252
7. Amit DJ, Tsodyks MV (1991) Quantitative study of
attractor neural network retrieving at low spike rates
I: Substrate – spikes, rates and neuronal gain. Net-
work 2:259–274
8. Badel L, Lefort S, Brette R, Petersen CCH,
Gerstner W, Richardson MJE (2008) Dynamic I–V
curves
are
reliable
predictors
of
naturalistic
pyramidal-neuron voltage traces. J Neurophysiol
99:656–666
9. Bak P, Tang C, Wiesenfeld K (1988) Self-organized
criticality. Phys Rev A 38:364–374
10. Barbour B, Brunel N, Hakim V, Nadal J (2007) What
can we learn from synaptic weight distributions?
Trends Neurosci 30:622–629
512
Neuronal Dynamics

11. Beggs JM, Plenz D (2003) Neuronal avalanches in
neocortical circuits. J Neurosci 23:11167–11177
12. Ben-Yishai R, Bar-Or RL, Sompolinsky H (1995)
Theory of orientation tuning in visual cortex. Proc
Natl Acad Sci U S A 92:3844–3848
13. Berg RW, Alaburda A, Hounsgaard J (2007) Bal-
anced inhibition and excitation drive spike activity
in spinal half center. Science 315:390–393
14. Berger H (1929) Über das Elektroenkephalogramm
des Menschen. Arch Psychiatr Nervenkrankh 87:
527–570
15. Bernander O, Douglas RJ, Martin KA, Koch
C (1991) Synaptic background activity determines
spatio-temporal
integration
in
single
pyramidal
cells. Proc Natl Acad Sci U S A 88:11569–11573
16. Bliss TVP, Collingridge GL (1993) A synaptic model
of memory: long-term potentiation in the hippocam-
pus. Nature 361:31–39
17. Blumenfeld
B,
Bibitchkov
D,
Tsodyks
MV
(2006) Neural network model of the primary
visual cortex: from functional architecture to lat-
eral connectivity and back. J Comput Neurosci 20:
219–241
18. Bolea S, Sanchez-Andres J, Huang X, Wu J (2006)
Initiation and propagation of neuronal coactivation in
the developing hippocampus. J Neurophysiol 95:
552–561
19. Bromﬁeld EB, Cavazos JE, Sirven JI (2006) An
introduction to epilepsy. American Epilepsy Society,
Bethesda
20. Brunel N (2000) Dynamics of sparsely connected
networks of excitatory and inhibitory spiking neu-
rons. J Comput Neurosci 8:183–208
21. Brunel N (2008) Modeling point neurons: from
Hodgkin–Huxley to integrate-and-ﬁre. In: Schutter
D (ed) Computational modeling methods for neuro-
scientists. MIT Press, Cambridge, MA
22. Brunei N, Hakim V (1999) Fast global oscillations in
networks of integrate-and-ﬁre neurons with low ﬁr-
ing rates. Neural Comp 11:1621–1671
23. Brunel N, Hakim V (2008) Sparsely synchronized
neuronal oscillations. Chaos 18:015113
24. Brunel
N,
Wang
X-J
(2001)
Effects
of
neuromodulation in a cortical network model of
object working memory dominated by recurrent inhi-
bition. J Comput Neurosci 11:63–85
25. Brunel N, Wang X-J (2003) What determines the
frequency of fast network oscillations with irreg-
ular
neural
discharges?
J
Neurophysiol
90:
415–430
26. Brunel N, Hakim V, Richardson MJE (2003) Firing
rate resonance in a generalized integrate-and-ﬁre
neuron with subthreshold resonance. Phys Rev
E 67:051916
27. Burkitt AN (2006) A review of the integrate-and-ﬁre
neuron model: I. Homogeneous synaptic input. Biol
Cybern 95:1–19
28. Burkitt AN (2006) A review of the integrate-and-ﬁre
neuron model: II. Inhomogeneous synaptic input and
network properties. Biol Cybern 95:97–112
29. Cangiano L, Grillner S (2005) Mechanisms of
rhythm generation in a spinal network deprived of
crossed
connections:
the
lamprey
hemichord.
J Neurosci 25:923–935
30. Cassenauer J, Laurent G (2007) Hebbian stdp in
mushroom bodies facilitates the synchronous ﬂow
of olfactory information in locusts. Nature 448:
709–713
31. Chow CC, Kopell N (2000) Dynamics of spiking
neurons with electrical coupling. Neural Comput
12:1643–1678
32. Compte A, Sanchez-Vives MV, McCormick DA,
Wang X-J (2003) Cellular and network mechanisms
of slow oscillatory activity (<1Hz) and wave propa-
gations in a cortical network model. J Neurophysiol
90:2707–2725
33. Cossart R, Aronov D, Yuste R (2003) Attractor
dynamics of network up states in the neocortex.
Nature 423:283–288
34. Csicsvari J, Hirase H, Czurko A, Buzsaki G (1998)
Reliability and state dependence of pyramidal cell-
interneuron synapses in the hippocampus: an ensem-
ble approach in the behaving rat. Neuron 21:179–189
35. Dayan P, Abbott L (2001) Theoretical neuroscience.
MIT Press, Cambridge, MA
36. De Schutter E (1999) Using realistic models to study
synaptic integration in cerebellar Purkinje cells. Rev
Neurosci 10:233–245
37. de Solages C, Szapiro G, Brunel N, Hakim V, Isope P,
Buisseret P, Rousseau C, Barbour B, Léna C (2008)
High-frequency organization and synchrony of activ-
ity in the Purkinje cell layer of the cerebellum. Neu-
ron 58:775–788
38. Destexhe A, Mainen ZF, Sejnowski TJ (1998) Kinetic
models of synaptic transmission. In: Koch C, Segev
I (eds) Methods in neuronal modeling, 2nd edn. MIT
Press, Cambridge, MA, pp 1–26
39. Ermentrout GB (1998) Neural networks as spatio-
temporal pattern-forming systems. Rep Prog Phys
61:353–430
40. Feldmeyer D, Lubke J, Sakmann B (2006) Efﬁcacy
and connectivity of intracolumnar pairs of layer 2/3
pyramidal cells in the barrel cortex of juvenile rats.
J Physiol 575:583–602
41. Fisahn A, Pike FG, Buhl EH, Paulsen O (1998) Cho-
linergic induction of network oscillations at 40 Hz in
the in vitro. Nature 394:186–189
42. Fourcaud-Trocmé N, Hansel D, van Vreeswijk C,
Brunei N (2003) How spike generation mechanisms
determine the neuronal response to ﬂuctuating
inputs. J Neurosci 23:11628–11640
43. Freeman W (1991) The physiology of perception. Sci
Am 264:78–85
44. Fries P, Reynolds J, Rorie A, Desimone R (2001)
Modulation of oscillatory neuronal synchroniza-
tion by selective visual attention. Science 291:
1560–1563
45. Galarreta M, Hestrin S (1999) A network of fast-
spiking cells in the neocortex connected by electrical
synapses. Nature 402(6757):72–75
Neuronal Dynamics
513

46. Gibson JR, Beierlein M, Connors BW (1999) Func-
tional properties of electrical synapses between
inhibitory interneurons of neocortical layer 4. J
Neurophysiol 93:467–480
47. Gibson JR, Beierlein M, Connors BW (1999) Two
networks of electrically coupled inhibitory neurons
in neocortex. Nature 402(6757):75–79
48. Gierer A, Meinhardt H (1972) A theory of biological
pattern formation. Kybernetik 12:30–39
49. Goldberg JA, Rokni U, Sompolinsky H (2004) Pat-
terns of ongoing activity and the functional archi-
tecture of the primary visual cortex. Neuron 42:
489–500
50. Golomb D, Ermentrout GB (2002) Slow excitation
supports propagation of slow pulses in networks of
excitatory and inhibitory populations. Phys Rev
E 65:061911
51. Hafting T, Fyhn M, Molden S, Moser M, Moser
E (2005) Microstructure of a spatial map in the ento-
rhinal cortex. Nature 436:801–806
52. Hansel D, Mato G, Meunier C (1995) Synchrony in
excitatory neural networks. Neural Comput 7:
307–337
53. Hansel D, Mato G, Meunier C, Neltner L (1998) On
numerical simulations of integrate-and-ﬁre neural
networks. Neural Comput 10:467–483
54. Heisenberg M (2003) Mushroom body memoir: from
maps to models. Nat Rev Neurosci 4:266–275
55. Hodgkin AL, Huxley AF (1952) A quantitative
description of membrane current and its application
to conductance and excitation in nerve. J Physiol 117:
500–544
56. Holmgren C, Harkany T, Svennenfors B, Zilberter
Y (2003) Pyramidal cell communication within local
networks in layer 2/3 of rat neocortex. J Physiol 551:
139–153
57. Honeycutt RL (1992) Stochastic Runge–Kutta algo-
rithms. I. White noise. Phys Rev A 45:600–603
58. Hopﬁeld JJ (1982) Neural networks and physical
systems with emergent collective computational abil-
ities. Proc Natl Acad Sci U S A 79:2554–2558
59. Issue S (1999) Special issue: the binding problem.
Neuron 24:7–125
60. Izhikevich E, Gally J, Edelman G (2004) Spike-
timing dynamics of neuronal groups. Cereb Cortex
14:933–944
61. Izhikevich EM (2001) Resonate-and-ﬁre neurons.
Neural Netw 14:883–894
62. Jacobi
S,
Moses
E
(2007)
Variability
and
corresponding amplitude-velocity relation of activity
propagating in one-dimensional neural cultures.
J Neurophysiol 97:35973606
63. Jahnke S, Memmesheimer R-M, Timme M (2008)
Stable irregular dynamics in spiking neural networks.
Phys Rev Lett 100:048102
64. Jensen O, Lisman J (2000) Position reconstruction
from an ensemble of hippocampal place cells: con-
tribution of theta phase coding. J Neurophysiol 83:
2602–2609
65. Kamondi A, Acsády L, Wang X-J, Buzsáki G (1998)
Theta oscillations in somata and dendrites of hippo-
campal pyramidal cells in vivo: activity-dependent
phase-precession of action potentials. Hippocampus
8:244–261
66. Keene A, Waddell S (2007) Drosophila olfactory
memory: single genes to complex neural circuits.
Nat Rev Neurosci 8:341–354
67. Kenet T, Bibitchkov D, Tsodyks MV, Grinvald A,
Arieli A (2003) Spontaneously emerging cortical rep-
resentations of visual attributes. Nature 425:954–956
68. Knight BW (1972) Dynamics of encoding in a pop-
ulation of neurons. J Gen Physiol 59:734–766
69. Koshiya N, Smith JC (1999) Neuronal pacemaker for
breathing visualized in vitro. Nature400:360–363
70. Koulakov AA, Raghavachari S, Kepecs A, Lisman
JE (2002) Model for a robust neural integrator. Nat
Neurosci 5:775–782
71. Kreiter AK, Singer W (1996) Stimulus dependent
synchronization of neuronal responses in the visual
cortex of the awake macaque monkey. J Neurosci 16:
2381–2396
72. Kubota D, Colgin L, Casale M, Brucher F, Lynch
G (2003) Endogenous waves in hippocampal slices.
J Neurophysiol 89:81–89
73. Kuramoto Y (1984) Chemical oscillations, waves
and turbulence. Springer, New York
74. Lapicque L (1907) Recherches quantitatives sur
l’excitabilité électrique des nerfs traitée comme une
polarisation. J Physiol Pathol Gen 9:620–635
75. LeMasson G, Marder E, Abbott L (1993) Activity-
dependent regulation of conductances in model neu-
rons. Science 259:1915–1917
76. Lengyel M, Szatmáry Z, Erdi P (2003) Dynamically
detuned oscillations account for the coupled rate and
temporal code of place cell ﬁring. Hippocampus 13:
700–714
77. Levina A, Hermann JM, Geisel T (2007) Dynamical
synapses causing self-organized criticality in neural
networks. Nat Phys 3:857–860
78. Lewis T, Rinzel J (2003) Dynamics of spiking neu-
rons connected by both inhibitory and electrical cou-
pling. J Comput Neurosci 14:283–309
79. Luczak A, Barthó P, Marguet S, Buzsáki G, Harris
K (2007) Sequential structure of neocortical sponta-
neous activity in vivo. Proc Natl Acad Sci U S A 104:
347–352
80. Lumer ED, Friston KJ, Rees G (1998) Neural corre-
lates of perceptual rivalry in the human brain. Sci-
ence 280:1930–1934
81. Maeda E, Robinson HPC, Kawana A (1995) The
mechanisms of generation and propagation of syn-
chronized bursting in developing networks of cortical
neurons. J Neurosci 15:6834–6845
82. Malenka RC, Bear MF (2004) LTP and LTD: an
embarrassment of riches. Neuron 44:5–21
83. Malinow R, Mainen ZF, Hayashi Y (2000) LTP
mechanisms: from silence to four-lane trafﬁc. Curr
Opin Neurobiol 10:352–357
514
Neuronal Dynamics

84. Mancilla JG, Lewis TJ, Pinto DJ, Rinzel J, Connors
BW (2007) Synchronization of electrically coupled
pairs
of
inhibitory
interneurons
in
neocortex.
J Neurosci 27:2058–2073
85. Marder E, Goaillard J (2006) Variability, compensa-
tion and homeostasis in neuron and network func-
tion. Nat Rev Neurosci 7:563–574
86. Markram H (2006) The blue brain project. Nat Rev
Neurosci 7:153–160
87. Mason A, Nicoll A, Stratford K (1991) Synaptic
transmission between individual pyramidal neurons
of the rat visual cortex in vitro. J Neurosci 11:72–84
88. Mattia M, Del Giudice P (2000) Efﬁcient event-
driven simulation of large networks of spiking neu-
rons and dynamical synapses. Neural Comput 12:
2305–2329
89. Mazor O, Laurent G (2005) Transient dynamics ver-
sus ﬁxed points in odor representations by locust
antennal
lobe
projection
neurons.
Neuron
48:
661–673
90. McNaughton B, Battaglia F, Jensen O, Moser E, Moser
M (2006) Path integration and the neural basis of the
‘cognitive map’. Nat Rev Neurosci 7:663–678
91. Mongillo
G,
Curti
E,
Romani
S,
Amit
DJ
(2005) Learning in realistic networks of spiking neu-
rons
and
spike-driven
plastic
synapses.
Eur
J Neurosci 21:3143–3160
92. Moreno-Bote R, Rinzel J, Rubin N (2007) Noise-
induced alternations in an attractor network model of
perceptual bistability. J Neurophysiol 98:1125–1139
93. Murphy TH, Blatter LA, Wier WG, Baraban JM
(1992) Spontaneous synchronous synaptic calcium
transients in cultured cortical neurons. J Neurosci
12:4834–4845
94. O’Keefe J, Dostrovsky J (1971) The hippocampus as
a spatial map. Preliminary evidence from unit activity
in the freely moving rat. Exp Brain Res 34:171–175
95. O’Keefe J, Recce M (1993) Phase relationship
between hippocampal place units and the EEG theta
rhythm. Hippocampus 3:317–330
96. Opitz T, Lima ADD, Voigt T (2002) Spontaneous
development of synchronous oscillatory activity dur-
ing
maturation
of
cortical
neurons
in
vitro.
J Neurophysiol 88:2196–2206
97. Perez-Orive J, Mazor O, Turner G, Cassenaer S,
Wilson R, Laurent G (2002) Oscillations and
sparsening of odor representations in the mushroom
body. Science 297:359–365
98. Petersen C, Grinvald A, Sakmann B (2003) Spatio-
temporal dynamics of sensory responses in layer 2/3
of rat barrel cortex measured in vivo by voltage-
sensitive dye imaging combined with whole-cell
voltage
recordings
and
neuron
reconstructions.
J Neurosci 23:1298–1309
99. Pikovsky A, Rosenblum M, Kurth J (2001) Synchro-
nization, a universal concept in nonlinear science.
Cambridge University Press, Cambridge
100. Polonsky
A,
Blake
R,
Braun
J,
Heeger
DJ
(2000) Neuronal activity in human primary visual
cortex correlates with perception during binocular
rivalry. Nat Neurosci 3:1153–1159
101. Press WH, Teukolsky SA, Vetterling WT, Flannery
BP (1992) Numerical recipes in C. Cambridge Uni-
versity Press, Cambridge
102. Renart A, Moreno R, Wang X-J (2003) Robust spatial
working memory through homeostatic synaptic scaling
in heterogenous cortical networks. Neuron 38:473–485
103. Reyes A, Fetz E (1993) Effects of transient
depolarizing potentials on the ﬁring rate of cat neo-
cortical neurons. J Neurophysiol 69:1673–1683
104. Richardson MJE, Brunel N, Hakim V (2003) From
subthreshold to ﬁring-rate resonance. J Neurophysiol
89:2538–2554
105. Risken H (1984) The Fokker-Planck equation:
methods of solution and applications. Springer,
Berlin
106. Roelfsema P, Lamme V, Spekreijse H (2004) Syn-
chrony and covariation of ﬁring rates in the primary
visual cortex during contour grouping. Nat Neurosci
7:982–991
107. Sanchez-Vives MV, McCormick DA (2000) Cellular
and network mechanisms of rhythmic recurrent
activity in neocortex. Nat Neurosci 3:1027–1034
108. Shadlen MN, Newsome WT (1998) The variable
discharge of cortical neurons: implications for con-
nectivity, computation, and information coding.
J Neurosci 18:3870–3896
109. Shu Y, Hasenstaub A, McCormick DA (2003) Turn-
ing on and off recurrent balanced cortical activity.
Nature 423:288–293
110. Sjöström PJ, Turrigiano GG, Nelson S (2001) Rate,
timing, and cooperativity jointly determine cortical
synaptic plasticity. Neuron 32:1149–1164
111. Softky WR, Koch C (1993) The highly irregular
ﬁring of cortical cells is inconsistent with temporal
integration of random EPSPs. J Neurosci 13:334–350
112. Stein R (1965) A theoretical analysis of neuronal
variability. Biophys J 5:173–194
113. Stopfer M, Jayaraman V, Laurent G (2003) Intensity
versus identity coding in an olfactory system. Neuron
39:991–1004
114. Tong F, Nakayama K, Vaughan JT, Kanwisher
N (1998) Binocular rivalry and visual awareness in
human extrastriate visual cortex. Neuron 21:761–773
115. Tsodyks MV, Kenet T, Grinvald A, Arieli A (1999)
Linking spontaneous activity of single cortical neu-
rons and the underlying functional architecture. Sci-
ence 286:1943–1946
116. Tsodyks MV, Skaggs W, Sejnowski T, McNaughton
B (1996) Population dynamics and theta rhythm
phase precession of hippocampal place cell ﬁring: a
spiking neuron model. Hippocampus 6:271–280
117. Tsodyks MV, Pawelzik K, Markran H (1998) Neural
networks with dynamic synapses. Neural Comp 10:
821–835
118. Tsodyks MV, Uziel A, Markram H (2000) Synchrony
generation in recurrent networks with frequency-
dependent synapses. J Neurosci 20:RC50
Neuronal Dynamics
515

119. Turrigiano GG, Nelson SB (2000) Hebb and homeo-
stasis in neuronal plasticity. Curr Opin Neurobiol 10:
358–364
120. van Vreeswijk C, Sompalinsky H (1996) Chaos in
neuronal networks with balanced excitatory and
inhibitory activity. Science 274:1724–1726
121. van Vreeswijk C, Sompolinsky H (1998) Chaotic
balanced state in a model of cortical circuits. Neural
Comput 10:1321–1371
122. van
Vreeswijk
C,
Abbott
L,
Ermentrout
GB
(1994) When inhibition not excitation synchronizes
neural ﬁring. J Comput Neurosci 1:313–321
123. Wallén P et al (2007) Sodium-dependent potassium
channels of a slack-like subtype contribute to slow
after hyperpolarization in lamprey spinal neurons.
J Physiol 585:75–90
124. Wilson HR (2003) Computational evidence for a
rivalry hierarchy in vision. Proc Natl Acad Sci U S
A 100:14499–14503
125. Wilson M, McNaughton B (1993) Dynamics of the
hippocampal ensemble code for space. Science 261:
1055–1058
126. Wyart C, Cocco S, Bourdieu L, Léger JF, Herr C,
Chatenay D (2005) Dynamics of excitatory synaptic
components
in
sustained
ﬁring
at
low
rates.
J Neurophysiol 96:3370–3380
127. Zillmer R, Brunei N, Hansel D (2008) Irregular states
in randomly diluted networks of leaky integrate-and-
ﬁre neurons (in preparation)
Books and Reviews
Buzsaki G (2006) Rhythms of the brain. Oxford University
Press
Chow C, Gutkin B, Hansel D, Meunier C, Dalibard J (eds)
(2004) Methods and models in neurophysics, Les
Houches 2003. North-Holland
Dayan P, Abbott L (2001) Theoretical neuroscience. MIT
Press, Cambridge, MA
Gerstner W, Kistler WM (2002) Spiking neuron models:
single neurons, populations, plasticity. Cambridge Uni-
versity Press, Cambridge
Wang
X-J
(2003)
Neural
oscillations.
In:
Nadel
L (ed) Encyclopedia of Cognitive Science. MacMillan,
London, pp 272–280
516
Neuronal Dynamics

Dense Active Matter
Pinaki Chaudhuri1 and Chandan Dasgupta2,3
1The Institute of Mathematical Sciences, Chennai,
India
2Department of Physics, Indian Institute of
Science, Bengaluru, India
3International Centre for Theoretical Sciences,
Tata Institute of Fundamental Research,
Bengaluru, India
Article Outline
Glossary
Why Study Active Matter?
Deﬁnition of the Subject
Experimental Studies
Models
Numerical Studies
Theoretical Studies
Comparison with Experiments
Conclusion and Future Directions
Bibliography
Properties of dense systems of active objects with
self-propulsionarereviewedwithemphasisonglassy
behavior and jamming. Experimental realizations of
such systems are pointed out, and the effects of the
presenceofself-propulsionforcesonthepropertiesof
passive glass-forming liquids are discussed, with
special attention to the dependence of the observed
behavior on the strength and persistence time of the
self-propulsion force. Results obtained from theoret-
ical and numerical studies of simple models of dense
active systems are summarized and compared with
the results of experimental studies.
Glossary
Active matter Collection of objects with self-
propulsion forces.
Cytoplasm Viscous ﬂuid that ﬁlls the inside of a
cell.
Epithelial sheet Single layer of cells with every
cell in direct contact with the membrane that
separates it from the underlying connective
tissue.
Fragility A parameter that quantiﬁes the rate of
growth of the viscosity of a liquid with
decreasing temperature or increasing density.
Glass Disordered solid obtained by rapidly
cooling or compressing a liquid.
Persistence time Timescale of decorrelation of
the direction of the self-propulsion force.
Strength of activity Magnitude of typical self-
propulsion force.
Why Study Active Matter?
Active matter consists of objects that can convert
internal or ambient sources of energy into system-
atic motion (Schweitzer 2003). It includes any
nonequilibrium condensed matter system, whether
it is composed of living or nonliving matter, in
which “self-propulsion” forces are present. Exper-
imentally studied active matter includes living sys-
tems such as ﬂocks of birds (Cavagna and Giardina
2014), schools of ﬁsh (Katz et al. 2011), swimming
bacteria (Wolgemuth 2008; Peruani et al. 2012),
migrating cells, (Angelini et al. 2011) and molecu-
lar motors (Kodera et al. 2010), as well as synthetic
nonliving examples such as vibrated granular mat-
ter (Kumar et al. 2014), self-propelled colloids
(Jiang et al. 2010; Buttinoni et al. 2013), magnetic
nano-propellers
(Ghosh
and
Fischer
2009),
Quincke rollers (Bricard et al. 2013, 2015), and
swimming microrobots (Peyer et al. 2013). Since
active systems are characterized by self-propulsion
forces that do not arise from interparticle interac-
tions, they are outside thermodynamic equilibrium
(Ramaswamy 2010; Marchetti et al. 2013). These
systems have received a lot of attention in recent
years because they exhibit novel collective behav-
ior (Ramaswamy 2010; Marchetti et al. 2013;
Bechinger
et
al.
2016),
such
as
ﬂocking
© Springer Science+Business Media, LLC, part of Springer Nature 2022
B. Chakraborty (ed.), Statistical and Nonlinear Physics,
https://doi.org/10.1007/978-1-0716-1454-9_713
Originally published in
R. A. Meyers (ed.), Encyclopedia of Complexity and Systems Science, © Springer Science+Business Media LLC 2021
https://doi.org/10.1007/978-3-642-27737-5_713-1
517

(Toner and Tu 1998), giant number ﬂuctuation
(Ramaswamy 2010), motility induced phase sepa-
ration (Cates and Tailleur 2015), and active turbu-
lence (Thampi and Yeomans 2016).
Definition of the Subject
In this entry, we consider dense active systems
that exhibit glassy behavior or jamming (Janssen
2019; Berthier et al. 2017). When a liquid is
cooled sufﬁciently fast so that crystallization is
avoided, it enters a supercooled liquid state
which, upon further cooling, undergoes a transi-
tion to an amorphous solid state that is called a
glass (Binder and Kob 2011). A similar phenom-
enology is found when a system of hard particles
is compressed sufﬁciently fast. The supercooled
liquid state near the glass transition exhibits many
interesting properties (Berthier and Biroli 2011),
the most remarkable among these being a rapid
growth of the viscosity and the structural relaxa-
tion time with decreasing temperature or increas-
ing density. This growth is faster than Arrhenius
in “fragile” liquids and follows the Arrhenius
form in “strong” liquids (Angell 1995). Jamming,
on the other hand, refers to a purely geometrical
process in which the freedom of movement of the
constituting particles is lost. When a system of
particles without thermal ﬂuctuations is com-
pressed from a low density, it undergoes a jam-
ming transition (Liu and Nagel 2010) at which
macroscopic rigidity sets in. We focus on how
the behavior of dense systems near the glass or
jamming transition is modiﬁed by the presence of
activity. Aligning interactions that may induce
ﬂocking behavior (Cavagna and Giardina 2014)
are not considered and hydrodynamic interactions
between active particles are neglected.
Experimental Studies
Glassy dynamics has been observed in a variety of
active biological systems. Several experimental
studies (Zhou et al. 2009; Nishizawa et al. 2017;
Parry et al. 2014) have revealed the occurrence of
glassy dynamics in the cytoplasm of cells. These
studies show a transition from a ﬂuid state to a glass
as the strength of activity is reduced. Activity is
also found to decrease the fragility (Angell 1995) of
the liquid state. Similar results have been obtained
in a study of the dynamics of micron-size particles
embedded in cell nuclei (Hameed et al. 2012).
Another class of dense active systems that has
received a lot of experimental attention consists of
two-dimensional epithelial sheets and three-
dimensional assemblies of cells. Angelini et al.
(2011) have presented evidence for fragile glass-
like behavior in conﬂuent epithelial monolayers
of Madin-Darby Canine Kidney (MDCK) cells.
Garcia et al. (Garcia et al. 2015) have found evi-
dence for a jamming transition in a monolayer of
human
bronchial
epithelial
cells.
Recently,
Henkes et al. (2020) have shown that displace-
ment and velocity correlations in epithelial mono-
layers are reminiscent of those in supercooled
liquids. A connection between a liquid-to-glass
transition in layers of human bronchial epithelial
cells and the occurrence of asthma has been dem-
onstrated in the work of Park et al. (2015). Signa-
tures of glassy dynamics have also been observed
in
three-dimensional
collections
of
cells
in
embryogenesis (Schötz et al. 2013), wound
healing (Vishwakarma et al. 2020), and metastasis
of cancer (Palamidessi et al. 2019).
A recent study (Klongvessa et al. 2019a, b) of
glass transition in synthetic active matter has con-
sidered two-dimensional layers of Janus colloids
(gold particles half-coated with platinum) in which
self-propulsion forces are controlled by the con-
centration of hydrogen peroxide. The main result
of this study is the observation that the relaxation
time decreases with increasing activity if the pack-
ing fraction is not very large. On the other hand, if
the packing fraction is very large, such that the
dynamics is nonergodic in the absence of activity,
then the introduction of activity is found to slow
down the dynamics. This slowing down is
followed by ﬂuidization at higher activity.
Models
Theoretical and numerical studies of dense active
systems have been carried out mostly for particle-
518
Dense Active Matter

based models. The simplest particle-based model,
known in the literature as Active Brownian Parti-
cles (ABPs) (Romanczuk et al. 2012), consists of
particles with spherically symmetric interactions.
Activity in the system is modeled by a random
self-propulsion force with magnitude f and persis-
tence time tp that describes the timescale of
decorrelation of its direction. The overdamped
equations of motion of the constituent particles
in the ABP model in two dimensions are given by
g_xi ¼
X
j6¼i
fij þ fni þ yi,
_yi ¼ xi,
ð1Þ
where γ is a friction coefﬁcient, fij is the force
exerted on particle i by particle j, fni is the self-
propulsion force, and yi is a thermal noise with
zero mean and variance 2kBTγδ(t–t0) that obeys
the ﬂuctuation-dissipation relation (T is the tem-
perature and kB is the Boltzmann constant). The
direction ni  (cos θi, sin θi) of the stochastic self-
propulsion force undergoes rotational diffusion
described by the noise xi with zero mean and
correlation
xi tð Þx j t0
ð Þ


¼ 2t1
p dijd t  t0
ð
Þ . Its
effect on the xi-dynamics is that of an exponen-
tially correlated vectorial noise with correlation
time tp. In Brownian dynamics simulations,
these equations of motion are numerically inte-
grated forward in time. In simulations of glassy
behavior, one typically considers binary mixtures
or poly-disperse systems in order to avoid crystal-
lization. Models of active rod-like particles, such
as dumbbells, have also been considered in simu-
lations (Mandal et al. 2017). The self-propulsion
force in such models is usually assumed to have a
ﬁxed magnitude f, and to act along the long axis of
each rod-like particle. The persistence time of the
active force is not an independent variable in these
models – it is determined by system parameters
such as the density, the temperature, and the
strength f of the active force.
Studies of the collective dynamics of living
cells in tissues involve a different class of models.
These models are different from the particle-based
models described above in that the cells in these
models cover the entire space without any gap
between neighboring cells. In vertex models
(Bi et al. 2015; Barton et al. 2017) of conﬂuent
layers of epithelial cells, the cells are represented
as polygons that share edges. The energy of a
collection of cells is deﬁned in terms of the areas
and perimeters of these polygons. Activity is
incorporated in the model by the addition of a
velocity of ﬁxed magnitude and random direction
in the equation of motion of the cells. Variants of
the vortex model include the Voronoi model
(Bi et al. 2016) and the cellular Potts model
(Chiang and Marenduzzo 2016).
Numerical Studies
Similar to other domains in soft matter, computer
simulations have been very useful to study struc-
tural and dynamical behavior of active matter
systems. The standard procedure has been to con-
sider conventional models of passive liquids
whose phase behavior has been extensively char-
acterized and introduce activity in these model
systems to study how the known properties get
modiﬁed. One of the ﬁrst numerical studies
(Ni et al. 2013) involved probing the effects of
activity on the slow dynamics of a three-
dimensional hard sphere system. A similar study
(Berthier 2014) was carried out at about the same
time for a two-dimensional system of hard disks.
In both cases, it was observed that with increasing
activity, the relaxation timescale decreases, at any
packing fraction, which consequently pushes the
glass transition density to higher values.
The effects of including activity in a well-
studied model glass former, viz. the Kob-
Andersen binary Lennard-Jones mixture (Kob
and Andersen 1994), were studied in Ref.
(Mandal et al. 2016) wherein active forces were
assumed to be present for one of the constituent
species. The active particles were randomly
assigned self-propulsion forces of ﬁxed magni-
tude f0, chosen such that there is conservation of
the net momentum of the system. After a persis-
tence time tp the directions of the active forces
were randomized, while maintaining momentum
conservation. The dynamical properties of this
system at different temperatures were probed via
Dense Active Matter
519

the mean-square-displacement (MSD) of tagged
particles, h|Δr(t)|2i, and the self-overlap function,
Q(t). Relatively small values of tp were consid-
ered in this study.
In the absence of activity, the glass-forming
mixture is a liquid at high temperatures. With the
lowering of temperature, the diffusion coefﬁcient,
D, extracted from the MSD decreases, along with
the increase in the relaxation timescale, tα, extra-
cted from the decay of Q(t). A glass transition
temperature for the system can be estimated by
ﬁtting tα to the well-known Vogel-Fulcher-
Tammann
(VFT)
form,
tα
¼
t1
exp
{1/(k(T/TVFT–1))}, where k is the kinetic fragility,
t1 is the relaxation time at high temperatures, and
TVFT is identiﬁed as the putative glass transition
temperature.
In the presence of active forcing, the dynamics
gets accelerated and the temperature dependence
of the diffusion coefﬁcient becomes weaker. This
is illustrated in the top panel of Fig. 1 where the
temperature dependence of the long-time diffu-
sion coefﬁcient D has been shown for different
values of f0. Similarly, the temperature depen-
dence of the relaxation timescales, tα, shows a
weaker increase with decreasing temperature as
f0 is increased. The phase diagram in the middle
panel of Fig. 1 shows the values of TVFT for
different values of f0, as extracted via VFT ﬁts of
the data for the relaxation time tα. It shows that
even in the presence of ﬁnite activity, there is a
thermal threshold below which the glassy regime
is obtained. However, this threshold vanishes at
high enough active forcing. This is qualitatively
different from the behavior found in Refs
(Berthier 2014). and (Ni et al. 2013) in which a
(putative) glass transition was found to be present
for all ﬁnite values of the strength of the activity.
This important observation tells us that some of
the effects of activity on the glass transition are
sensitive to the nature of the system (whether
controlled by temperature or density) and the
details of the self-propulsion mechanism.
Another interesting observation regarding the
effect of activity on glassy dynamics is the
decrease of kinetic fragility of the liquid with
increasing activity. This is illustrated via the
so-called “Angell plots,” shown in the bottom
panel of Fig. 1, where one plots tα vs Tg/T, Tg
being the analog of the experimentally determined
glass transition temperature at which the viscosity
is 1013 poise, obtained from the deﬁnition tα
Dense Active Matter, Fig. 1 Effect of activity on a
three-dimensional glass-forming liquid (Kob-Andersen
binary
Lennard-Jones
mixture)
(Adapted
from
Ref.
Mandal et al. 2016). (Top) Diffusion coefﬁcient (D) vs
temperature (T) for tp ¼ 4.0 and different active forcing
( f0), as marked. The inset shows the corresponding relax-
ation timescales, tα. (Middle) Phase diagram in the T–f0
plane. The color indicates the value of tα according to the
colorbar. (Bottom) Angell plot, showing variation of tα
with Tg/T for different f0
520
Dense Active Matter

(Tg) ¼ 106. The curvature of the plots gives us a
measure of the fragility, k, which is seen to
decrease with increased forcing as shown in the
inset of the bottom panel of Fig. 1.
The question of whether the dynamics in pas-
sive and active supercooled liquids are different
was investigated in Ref. (Mandal et al. 2017)
using a two-dimensional dense assembly of self-
propelled dumbbells. Speciﬁcally, maps of the
displacement ﬁeld of the center of mass of
the dumbbells were computed for state points in
the (T–f0) plane having similar relaxation time-
scales. In the passive limit, these maps do not
reveal any spatial structures or correlations. As
one increases the strength of the activity along
the iso-relaxation time line, vortex-like structures
become visible (see Fig. 2) and the size of these
vortices increases with increasing activity. Fur-
ther, the displacement maps, constructed over
the structural relaxation timescales, show that the
active system exhibits more dynamical heteroge-
neity than the passive one. The correlation lengths
associated with these spatial structures increase as
one moves along the path of iso-relaxation time-
scales in the direction of increasing activity
(Mandal et al. 2017). The observed swirling pat-
terns are similar to structures observed in active
turbulence exhibited by a ﬂuid of active rods
(Wensink et al. 2012; Giomi 2015), and it is pos-
sible that the dynamical heterogeneity exhibited
by the active glass is a remnant signature of the
turbulent ﬂuid.
More recently, an interesting emerging direc-
tion of investigation in active glassy matter has
Dense Active Matter, Fig. 2 Active vs passive super-
cooled liquid (Adapted from Ref. Mandal et al. 2017).
(left) Streamlines of displacement ﬁeld computed over
the relaxation timescale tα with the underlying colormap
reﬂecting the corresponding values of the spatially varying
vorticity.
(right)
Map
showing
the
magnitude
of
displacement during the same time window, with blue
particles being the fastest and black particles being the
slowest. The top panel corresponds to the active system
displaying large-scale vortical structures and extensive
spatial heterogeneity, in contrast to the passive system
shown in the bottom panel
Dense Active Matter
521

been the so-called extreme limit wherein the mag-
nitude of the propulsion force f is higher than that
of interparticle or thermal forces and the direction
of the propulsion force persists over times tp
longer than characteristic relaxation times of the
system in the absence of activity. This aspect has
been numerically explored (Mandal et al. 2020)
using a two-dimensional athermal assembly of
soft-interacting active Brownian particles, each
of mass m and driven by a stochastic self-
propulsion
force
f
¼
fn
whose
direction
n undergoes rotational diffusion. Extreme activity
is attained when (a) the magnitude of the active
force is larger than both thermal forces and the
typical force exerted on a particle by the other
particles, and (b) the persistence time tp is larger
than the characteristic relaxation time of the sys-
tem in the absence of activity. In the athermal
limit, condition (b) above is replaced by Pe 
1 where Pe is an active Péclet number deﬁned as
Pe  ftp/(γs) (γ is a friction coefﬁcient and s is the
particle size).
For small values of tp, as was discussed earlier,
the system transforms from a ﬂuid at high f to a
glassy state at low f. The phase boundary is well
described by an active generalization of RFOT
theory (see section “Theoretical Studies”). This is
illustrated in the phase diagram shown in the left
panel of Fig. 3. For intermediate values of the
persistence time tp >
 103, the variation of the
time series of the system’s kinetic energy with
changing active force marks the evolution of the
system through different dynamical regimes; see
the middle panel of Fig. 3. At large forcing, it
shows random ﬂuctuations. However, as the forc-
ing is decreased, the time series starts becoming
intermittent, with periods of bursts followed by
quiescence. The gap between these periods of
bursts increases with decreasing forcing, and even-
tually the system gets dynamically arrested as f is
decreased even further. The single particle dynam-
ics become more heterogeneous as the phase
boundary is crossed (Mandal et al. 2020). Deep
inside the intermittent phase, the spikes in the
time series of the kinetic energy correspond to the
occurrence of local plastic events resulting from the
local shear induced via the internal stirring at the
scale of the active particles (Mandal et al. 2020).
An interesting limit is the case of inﬁnite per-
sistent time of the active particles, that is, where
the direction of the active force on each particle
does not change with time. In this limit, above a
Dense Active Matter, Fig. 3 Extreme active matter
(Adapted from Ref. Mandal et al. 2020). (top) Phase dia-
gram showing different dynamical regimes in the persis-
tence time tp vs active forcing f plane. (middle) Time series
of kinetic energy, E(t), showing increasing intermittency
with decreasing f, for tp ¼ 104. (bottom) In the limit of
inﬁnite persistence time, variation of the mean kinetic
energy, hEi, with forcing f. The system transits to a jammed
state as f is decreased below f *(1) ¼ 1.6, with hEi~|f 
f (1)|3/2 near f ¼ f *(1)
522
Dense Active Matter

threshold forcing, f *(1), the system of particles
behaves like a ﬂuid, and below this threshold, it
reaches an arrested state, consistent with similar
observations in the vicinity of the jamming tran-
sition for soft harmonic disks (Liao and Xu 2018).
On
the
approach
to
this
arrested
state,
corresponding to the formation of a force-
balanced conﬁguration (Mandal et al. 2020), the
kinetic energy vanishes as ~|f – f (1)|3/2; see the
right panel of Fig. 3. A similar yielding transition
was also observed (Morse et al. 2020) for the case
of athermal quasi-static persistent random dis-
placement, whereby a link to the response under
macroscopic shear has also been outlined.
Further studies have tried to explore the aging
dynamics in the presence of activity (Janssen et al.
2017), and different aging behavior has been
observed for small and large persistence times
(Mandal and Sollich 2020), with the former
more similar to aging observed during thermal
quenches and the latter exhibiting a two-step pro-
cess with active athermal aging at short times and
activity-driven aging at late times.
Theoretical Studies
Most theoretical studies of dense active matter are
based on modiﬁcations of theoretical descriptions
of passive glass-forming liquids (Berthier and
Biroli 2011; Lubchenko and Wolynes 2007) to
include the effects of activity. The nonequilibrium
nature of active systems is not explicitly taken into
account in these descriptions. The simplest among
these is the “effective temperature” description
(Fily et al. 2014) in which the effects of active
forces are represented in terms of an “active tem-
perature” that adds to the bath temperature. The
active force fni in Eq.(1) differs from the thermal
noise yi in that it has a nonzero correlation time tp.
If tp is small compared to the characteristic time-
scales of the system, then the active force can be
treated (Mandal et al. 2016) as additional thermal
noise corresponding to an active temperature Ta
that is proportional to f 2tp. The behavior of the
active system at temperature T is then assumed to
be the same as that of the corresponding passive
system at effective temperature Teff ¼ T þ Ta.
A similar expression for the effective temperature
may be obtained from an exact analytic treatment
(Mandal et al. 2016; Szamel 2014) of the over-
damped dynamics of a particle in a harmonic
potential in the presence of an active force with
correlation time tp. This simple description pro-
vides a qualitative understanding of several sim-
ulation results (Mandal et al. 2016) obtained for
relatively small values of f and tp. The line drawn
through the data points for the transition temper-
ature in the middle panel of Fig. 1 was obtained
from this description.
A more detailed description of the dynamics of
dense active systems involves an extension (Nandi
et al. 2018) of the Random First Order Transition
(RFOT)
theory
(Berthier
and
Biroli
2011;
Lubchenko and Wolynes 2007) of passive glassy
dynamics. In the RFOT theory, the structural relax-
ation time is predicted to diverge at a putative
thermodynamic glass transition temperature TK
(also known as the Kauzmann temperature) at
which the conﬁgurational entropy density sc asso-
ciated with the multiplicity of local minima of the
potential energy of the system goes to zero. Strictly
speaking, sc is not a well-deﬁned quantity for active
systems because they are not in equilibrium. Nev-
ertheless, using a physically reasonable deﬁnition
of sc and a mean-ﬁeld treatment in which the many-
particle dynamics is approximated by that of an
active particle in a harmonic cage potential pro-
duced by its neighbors, an expression for sc for an
active system, characterized by the activity param-
eters f and tp, can be obtained. The dependence of
the relaxation time on the activity parameters f and
tp, obtained by using the expression for sc in the
passive RFOT relation between sc and the relaxa-
tion time, was found to provide a good description
of the results of several simulations. The dashed
line separating liquid and dynamically arrested
phases in the phase diagram shown in the left
panel of Fig. 3 was obtained from this theory. The
active RFOT theory also resolved apparently con-
tradictory results for the effects of activity on the
fragility obtained from different simulations. How-
ever, substantial deviations of the predicted results
from those obtained from simulations were found
for relatively large values of f and tp. A recent
modiﬁcation (Mandal et al. 2021) of the active
Dense Active Matter
523

RFOT theory to include nonperturbative effects
arising from a large f has reduced this discrepancy
between analytic and simulation results.
Mode coupling theories (Das 2004) of the
dynamics of passive glass-forming liquids have
also been extended to include the effects of activ-
ity (Szamel et al. 2015; Szamel 2016; Nandi and
Gov 2017; Liluashvili et al. 2017; Szamel 2019).
These theories start from the microscopic equa-
tions of motion or the equations of ﬂuctuating
hydrodynamics and make certain uncontrolled
approximations to obtain analytic results for var-
ious time-dependent correlation functions. For
passive glass-forming liquids, mode coupling the-
ories provide an accurate description of the
dynamics in the weakly super-cooled regime but
fail to describe the behavior at lower tempera-
tures. Several studies have used this formalism
to look into the effects of activity on the dynamics.
The predictions of these studies on the depen-
dence of the dynamics on the activity parameters
seem to depend on the nature of the approxima-
tions made in deriving the results, the details of
the self-propagation mechanism, and the presence
or absence of thermal noise. More work is needed
to sort out these issues.
Comparison with Experiments
The simple model systems considered in theoreti-
cal studies do not provide a realistic description of
biological active matter studied in experiments.
Nevertheless, some of the results obtained from
analytic and numerical studies of these simple
models are found to be qualitatively similar to
those of experiments on biological systems. For
example, the dependence of the fragility parameter
on the strength f of the active force found in simu-
lations (Mandal et al. 2016) (see the bottom panel
of Fig. 1) and the active RFOT theory (Nandi et al.
2018) is quite similar to that observed in experi-
ments on in vitro and living cytoplasm (Nishizawa
et al. 2017) – in both cases, the fragility decreases
as the activity is increased (see Fig. 4). It has been
shown in Ref. (Henkes et al. 2020) that several
features of experimentally observed displacement
and
velocity
correlations
in
epithelial
cell
monolayers can be reproduced in theoretical and
numerical studies of simple models. Another
example is the observation (Park et al. 2015) of a
jamming transition in conﬂuent monolayers of
human bronchial epithelial cells at a value of a
geometrical parameter associated with cell shapes
that is close to the value at which a similar transi-
tion occurs in simulations (Bi et al. 2015) of the
vertex model mentioned above.
There is a closer connection between theoreti-
cal models and experimentally studied systems of
synthetic active matter. As shown in Fig. 5, the
phase diagram obtained in an experimental study
of a system of Janus colloids (Klongvessa et al.
2019a) for which the packing fraction is the con-
trol parameter is qualitatively similar to that found
in simulations (Mandal et al. 2016) of a model of
thermally driven active particles (see the middle
panel of Fig. 1). In both cases, the activity is found
to promote ﬂuidization in a similar way.
Conclusion and Future Directions
This short review attempts to provide a summary of
the current state of affairs in the developing ﬁeld of
dense active matter. The primary interest in studies
Dense Active Matter, Fig. 4 Viscosity (scaled by the
viscosity of water) as a function of scaled concentration for
BSA – a globular protein – (red circles and the dash-dot-dot
curve), for cell extracts from E. coli (green triangles and the
dotted curve), and for cytoplasm in a living cell (pink
diamonds and the solid line). Higher curvature of the plot
indicates larger fragility (from Ref. Nishizawa et al. 2017).
The dependence of the fragility on activity is similar to that
shown in the bottom panel of Fig. 1
524
Dense Active Matter

of dense active matter derives from the biological
importance of understanding the behavior of two-
and three-dimensional collections of cells. As
discussed above, analytic and computational stud-
ies of simple models of active matter are beginning
to make contact with experiments on cell assem-
blies. However, there is a need for incorporating
biologically important features in these models.
Experiments on synthetic active systems that are
closer to the theoretical models are also being
performed. More effort in this direction would
make it easier to connect theoretical predictions
with experimental results. On the theoretical side,
the behavior of dense active matter with relatively
small values of f and tp is fairly well-understood.
However, there is little theoretical understanding of
several interesting features observed in simulations
(Mandal et al. 2020) of extreme active matter with
large f and/or tp. More theoretical work and exper-
iments on extreme active matter would be most
welcome.
Bibliography
Angelini TE, Hannezo E, Trepat X, Marquez M, Fredberg
JJ, Weitz DA (2011) Proc Natl Acad Sci U S A 108:
4714
Angell CA (1995) Science 267:1924
Barton DL, Henkes S, Weijer CJ, Sknepnek R (2017) PLoS
Comput Biol 13:e1005569
Bechinger C, Di Leonardo R, Löwen H, Reichhardt C,
Volpe G, Volpe G (2016) Rev Mod Phys 88:045006
Berthier L (2014) Phys Rev Lett 112:220602
Berthier L, Biroli G (2011) Rev Mod Phys 83:587
Berthier L, Flenner E, Szamel G (2017) New J Phys 19:
125006
Bi D, Lopez JH, Schwarz JM, Manning LM (2015) Nat
Phys 11:1074
Bi D, Yang X, Marchetti MC, Manning LM (2016) Phys
Rev X 6:021011
Binder K, Kob W (2011) Glassy materials and disordered
solids. World Scientiﬁc
Bricard A, Caussin J-B, Desreumaux N, Dauchot O,
Bartolo D (2013) Nature 503:95
Bricard A, Caussin J-B, Das D, Savoie C, Chikkadi V,
Shitara K, Chepizhko O, Peruani F, Saintillan D,
Bartolo D (2015) Nat Commun 6:1
Buttinoni I, Bialké J, Kümmel F, Löwen H, Bechinger C,
Speck T (2013) Phys Rev Lett 110:238301
Cates M, Tailleur J (2015) Annu Rev Condens Matt Phys
6:219
Cavagna A, Giardina I (2014) Annu Rev Condens Matt
Phys 5:183
Chiang M, Marenduzzo D (2016) Europhys Lett 116:
28009
Das SP (2004) Rev Mod Phys 76:785
Fily S, Henkes S, Marchetti MC (2014) Soft Matter 10:10
Garcia S, Hannezo E, Elgeti J, Joanny J-F, Silberzan P, Gov
NS (2015) Proc Natl Acad Sci U S A 112:15314
Ghosh A, Fischer P (2009) Nano Lett 9:2243
Giomi L (2015) Phys Rev X 5:031003
Hameed FM, Rao M, Shivashankar GV (2012) PLoS One
7:1
Henkes S, Kostanjevec K, Collinson JM, Sknepnek R, Eric
Bertin E (2020) Nat Commun 11:1405
Janssen LM (2019) J Phys Condens Matter 31:503002
Janssen LM, Kaiser A, Löwen H (2017) Sci Rep 7:1
Dense Active Matter, Fig. 5 Phase diagram of a two-
dimensional system of Janus colloids in the activity
(Teff/T0) vs. packing fraction (f) plane (from Ref.
Klongvessa et al. 2019a). The colorbar indicates the
value of the relaxation time. Increasing the packing
fraction in this system is similar to decreasing the temper-
ature in a thermally driven system. This phase diagram is
similar to that in the middle panel of Fig. 1 – activity
promotes ﬂuidization in both cases
Dense Active Matter
525

Jiang H-R, Yoshinaga N, Sano M (2010) Phys Rev Lett
105:268302
Katz Y, Ioannou C, Tunstro K, Huepe C, Couzin I (2011)
Proc Natl Acad Sci U S A 108:18720
Klongvessa N, Ginot F, Ybert C, Cottin-Bizonne C,
Leocmach M (2019a) Phys Rev Lett 123:248004
Klongvessa N, Ginot F, Ybert C, Cottin-Bizonne C,
Leocmach M (2019b) Phys Rev E 100:062603
Kob W, Andersen HC (1994) Phys Rev Lett 73:1376
Kodera N, Yamamoto D, Ishikawa R, Ando T (2010)
Nature 468:72
Kumar N, Soni H, Ramaswamy S, Sood AK (2014) Nat
Commun 5:4688
Liao Q, Xu N (2018) Soft Matter 14:853
Liluashvili J, Onody J, Voigtmann T (2017) Phys Rev E 96:
062608
Liu AJ, Nagel SR (2010) Annu Rev Condens Matt Phys
1:347
Lubchenko V, Wolynes P (2007) Ann Rev Phys Chem
58:235
Mandal R, Sollich P (2020) Phys Rev Lett 125:218001
Mandal R, Bhuyan PJ, Rao M, Dasgupta C (2016) Soft
Matter 12:6268
Mandal R, Bhuyan PJ, Chaudhuri P, Rao M, Dasgupta
C (2017) Phys Rev E 96:042605
Mandal R, Bhuyan PJ, Chaudhuri P, Dasgupta C, Rao
M (2020) Nat Commun 11:1
Mandal R, Nandi SK, Dasgupta C, Sollich P, Gov NS
(2021) arXiv:2102.07519v1
Marchetti MC, Joanny J-F, Ramaswamy S, Liverpool TB,
Prost J, Rao M, Simha RA (2013) Rev Mod Phys 85:
1143
Morse PK, Roy S, Agoritsas E, Stanifer E, Corwin EI,
Manning ML (2020) arXiv preprint arXiv:2009.07706
Nandi SK, Gov NS (2017) Soft Matter 13:7609
Nandi SK, Mandal R, Bhuyan PJ, Dasgupta C, Rao M,
Gov NS (2018) Proc Natl Acad Sci U S A 115:7688
Ni R, Stuart MAC, Dijkstra M (2013) Nat Commun 4:2704
Nishizawa K, Fujiwara K, Ikenaga M, Nakajo N,
Yanagisawa M, Mizuno D (2017) Sci Rep 7:15143
Palamidessi A et al (2019) Nat Mater 11:1252
Park J-A et al (2015) Nat Mater 14:1040
Parry B, Surovtsev I, Cabeen M, O’Hern C, Dufresne E,
Jacobs-Wagner C (2014) Cell 156:183
Peruani F, Staruss J, Jakovljevic V, Sogaard-Andersen-
L, Deutsch A, Bar M (2012) Phys Rev Lett 108:
098102
Peyer KE, Zhang L, Nelson BJ (2013) Nanoscale 5:1259
Ramaswamy S (2010) Annu Rev Condens Matt Phys
1:323
Romanczuk P, Bär M, Ebeling W, Lindner B, Schimansky-
Geier L (2012) Eur Phys J Spec Top 202:1
Schötz E-M, Lanio M, Talbot JA, Manning ML (2013) J R
Soc Interface 10:20130726
Schweitzer F (2003) Brownian agents and active particles:
collective dynamics in the natural and social sciences.
Springer
Szamel G (2014) Phys Rev E 90:012111
Szamel G (2016) Phys Rev E 93:012603
Szamel G (2019) J Chem Phys 150:124901
Szamel G, Flenner E, Berthier L (2015) Phys Rev E 91:
062304
Thampi S, Yeomans J (2016) Eur Phys J Spec Top 225:651
Toner J, Tu Y (1998) Phys Rev E 58:4828
Vishwakarma M, Thurakkal B, Spatz JP, Das T (2020)
Philos Trans R Soc Lond Ser B Biol Sci 375:20190391
Wensink HH, Dunkel J, Heidenreich S, Drescher K, Gold-
stein RE, Löwen H, Yeomans JM (2012) Proc Natl
Acad Sci 109:14308
Wolgemuth C (2008) Biophys J 95:1564–1574
Zhou EH, Trepat X, Park CY, Lenormand G, Oliver MN,
Mijailovich SM, Hardin C, Weitz DA, Butler JP,
Fredberg JJ (2009) Proc Natl Acad Sci U S A 106:
10632.
526
Dense Active Matter

Ultracold Atomic Gases: Novel
States of Matter
Ludwig Mathey1, Shan-Wen Tsai2 and
Antonio H. Castro Neto3
1Harvard University, Cambridge, USA
2University of California, Riverside, USA
3Boston University, Boston, USA
Article Outline
Glossary
Deﬁnition of the Subject
Introduction
One-Dimensional Lattices
Phase-Locking Transition of Coupled Low-
Dimensional Superﬂuids
Bose-Fermi Mixtures in Two-Dimensional
Optical Lattices
Conclusions
Bibliography
Glossary
Bose-Einstein
condensation
(BEC) Low-
temperature phase of systems of identical
bosons, characterized by superﬂuidity.
Boson Particles with integer spin S ¼ 0, 1, 2, . . . .
Mediators of interactions, such as photons and
gluons, are bosons. Objects made of an even
number of fermions are bosons: positronium
(electron + positron), meson (two quarks),
87Rb(37protons,48neutrons,and37electrons),
and 7Li (3 protons, 4 neutrons, 3 electrons).
Cooper pairs At low temperatures and for
attractive interactions, fermions form a super-
conducting state, in which fermions form pairs
which condense.
Evaporative cooling To slow the atoms down
further, to the mK regime, one applies radio fre-
quency radiation that ﬂips the internal state to a
high-ﬁeld seeking, i.e., non-trapped, state in such
a way that only atoms of high kinetic energy can
escape. Due to thermalization, this leads to
cooling of the remaining atomic ensemble.
Fermi
surface Since
fermions obey Pauli’s
exclusion
principle,
the
ground
state
of
N noninteracting fermions in d-dimensions is
the state with the N lowest energy states occu-
pied. In momentum space the last occupied state
and the ﬁrst unoccupied state deﬁne a surface of
dimensions d  1, called the Fermi surface.
Fermion Particles with half-odd integer spin S ¼
1/ 2,3/ 2,5/ 2, . . . . Examples include elementary
particles such as electrons and quarks. Objects
made of an odd number of fermions are also
fermionic, such as protons, 40K (19 protons,
21 neutrons, and 19 electrons), and 6Li (3 pro-
tons, 3 neutrons, and 3 electrons).
Laser cooling In a typical experimental setup,
the atoms are cooled to the regime of 102mK,
by using pairs of counterpropagating laser
beams that are slightly red-detuned below an
atomic transition. Due to the Doppler effect,
the atoms can only absorb a photon if they
travel toward the beam with a high velocity.
From that process the atoms experience a
recoil, which slows them down.
Magnetic trap The atoms are trapped by apply-
ing a spatially inhomogeneous magnetic ﬁeld.
This ﬁeld leads to an energy shift due to the
Zeeman effect, which the atoms experience as
an external potential, for large energy splittings
of the magnetic levels. Different geometric
designs are in use, such as the TOP trap or the
Ioffe-Pritchard trap.
Nesting Fermi surface with portions that are
parallel. The vector that connects different
parallel portions is called the nesting vector Q
!.
Optical lattice Counterpropagating laser beams
create a standing wave ﬁeld, which the atoms
experience as a periodic potential, due to the ac
Stark shift. If the temperature and all energy
scales are small compared to the energy split-
ting due the spatial conﬁnement in each well,
© Springer Science+Business Media, LLC, part of Springer Nature 2022
B. Chakraborty (ed.), Statistical and Nonlinear Physics,
https://doi.org/10.1007/978-1-0716-1454-9_573
Originally published in
R. A. Meyers (ed.), Encyclopedia of Complexity and Systems Science, © Springer Science+Business Media New York 2013
https://doi.org/10.1007/978-3-642-27737-5_573-3
527

this system is well approximated by a Hubbard
model, i.e., by taking into account nearest-
neighbor hopping and on-site interaction.
Definition of the Subject
The work presented in this entry belongs to the
recently emerging interface of atomic physics and
condensed matter theory. One of the crucial con-
nections between these ﬁelds is the fact that ultra-
cold atom ensembles in optical lattices, i.e.,
periodic potentials provided by standing waves
of laser light, are well described by Hubbard
models, the quintessential model of many-body
theory. Therefore, these experiments allow for the
study of many-body effects in a well-deﬁned and
tunable environment.
The subject of this entry is the study of quantum
phases of ultracold atoms in optical lattices. The
objective is to propose experimental conﬁgura-
tions, such as what lattice geometry or which
types of atoms to use, for which unusual many-
body effects can be found. Besides the applicability
to ultracold atom systems and given the generic
nature of the underlying models, the resulting
phases are also of interest in solid-state systems.
Using techniques such as a numerical imple-
mentation of functional renormalization group
equations and Luttinger liquid theory, we ﬁnd
the phase diagrams of various low-dimensional
systems of different geometry and discuss how
the various phases could be detected.
Introduction
The technology of cooling and trapping atomic
ensembles has been one of the most important
developments in physics over the last decades. It
has been a critical ingredient in creating Bose-
Einstein condensates (Anderson et al. 1995;
Davis et al. 1995), improving atomic clocks
(Phillips et al. 1996), and studying atomic proper-
ties (Jones et al. 1996; Lett et al. 1995). A new
direction in this development was the realization of
the Mott insulator transition (Greiner et al. 2002)
with ultracold atoms, which demonstrated that
these systems can be used to create various types
of quantum phases in a tunable and well-deﬁned
environment. The subsequent progress that has
been made in controlling and manipulating ensem-
bles of ultracold atoms (Köhl et al. 2005; Mandel
et al. 2003a, b; Stöferle et al. 2004) was followed
by a number of experiments to create and study
more and more sophisticated many-body effects,
such as fermionic superﬂuids (Greiner et al. 2003;
Jochim et al. 2003; Zwierlein et al. 2003), one-
dimensional strongly correlated Fermi and Bose
systems (Kinoshita et al. 2004; Moritz et al. 2005;
Paredes et al. 2004), or noise correlations in
interacting atomic systems (Altman et al. 2004;
Fölling et al. 2005; Greiner et al. 2005; Mathey
et al. 2008a). These developments established the
notion of “engineering” many-body states in a
tunable environment, i.e., manipulating ensembles
of ultracold atoms in optical lattices.
This entry further explores this development.
The ﬁrst step of creating novel states of matter is
to determine the phase diagram of the system under
consideration. For this purpose we use Luttinger
liquid theory for studying one-dimensional quan-
tum systems and two-dimensional thermal systems
and functional renormalization group equations to
study two-dimensional quantum systems, which
are both sophisticated methods that generate a lot
of insight into the physics of these systems.
This entry contains three main sections, which
can be read independently of each other, orga-
nized as follows: In section “One-Dimensional
Lattices,” we ﬁrst study the phase diagram of an
incommensurate Bose-Fermi mixture in one
dimension,
which
can be
understood
as
a
Luttinger liquid of polarons (see Mathey et al.
2004; Mathey and Wang 2007). We then broaden
the scope of this study to include the effects of
commensurate densities (see Mathey 2007). In
section “Phase-Locking Transition of Coupled
Low-Dimensional Superﬂuids,” we study the
phases of two coupled two-dimensional super-
ﬂuids, and we propose how the phase-locking
transition of such systems can be used to realize
the Kibble-Zurek mechanism, i.e., to create topo-
logical defects by ramping across a phase transi-
tion (see Mathey et al. 2008b). In section “Bose-
Fermi Mixtures in Two-Dimensional Optical Lat-
tices,” we use a numerical implementation of
functional renormalization group equations to
528
Ultracold Atomic Gases: Novel States of Matter

study the phase diagrams of Bose-Fermi mixtures
in optical lattices in two dimensions. For both, a
square and a triangular lattice, we ﬁnd a rich
structure of competing phases (see Klironomos
and Tsai 2007; Mathey et al. 2006, 2007).
One-Dimensional Lattices
The theory of one-dimensional many-body sys-
tems has been a highly active and fascinating
ﬁeld of physics for many decades, the center-
piece of which is the notion of the Luttinger
liquid (Giamarchi 2004; Gogolin et al. 1998;
Solyom 1979). In this section, we propose sev-
eral systems that display various features of
Luttinger
liquids,
such
as
quasi-long-range
order,
competing
orders,
and
Kosterlitz-
Thouless transitions due to commensurate densi-
ties, as will be explained.
Recent advances in controlling ultracold atoms
lead to the realization of truly one-dimensional
systems and the study of many-body effects
therein. Important benchmarks, such as the
Tonks-Girardeau gas (Kinoshita et al. 2004;
Paredes et al. 2004) and the Mott transition in
one dimension (Stöferle et al. 2004), have been
achieved by trapping bosonic atoms in tight tubes
formed by an optical lattice potential. Novel trans-
port properties of one-dimensional lattice bosons
have been studied using these techniques (Fertig
et al. 2004). More recently, a strongly interacting
one-dimensional Fermi gas was realized using
similar trapping methods (Moritz et al. 2005).
Interactions between the fermion atoms were con-
trolled by tuning a Feshbach resonance in these
experiments. On the theory side, numerous pro-
posals were given for realizing a variety of differ-
ent phases in ultracold Fermi systems (Cazalilla
et al. 2005; Fuchs et al. 2004; Recati et al. 2003),
Bose-Fermi mixtures (Cazalilla and Ho 2003;
Mathey et al. 2004; Mathey and Wang 2007;
Sengupta and Pryadko 2005), and Bose-Bose
mixtures (Isacsson and Girvin 2005; Isacsson
et al. 2005).
In the ﬁrst part of this section, we describe the
phase diagram of an incommensurate Bose-Fermi
mixture; in the second part we consider the effect
of commensurate ﬁllings.
Luttinger Liquid of Polarons in One-
Dimensional Bose-Fermi Mixtures
In this section we investigate one-dimensional
(1D)
Bose-Fermi
mixtures
(BFM)
using
bosonization (Cazalilla 2004; Haldane 1981).
The resulting quantum phases can be understood
by introducing polarons, i.e., atoms of one species
surrounded by screening clouds of the other spe-
cies. In our analysis the polarons emerge as the
most
well-deﬁned
quasi-particles
in
the
interacting system, while quantum phases of the
system arise from a competition of various order-
ing instabilities of such polarons. The phase dia-
grams we obtain show a remarkable similarity to
the Luttinger liquid phase diagrams of 1D
interacting electron systems (Solyom 1979; Voit
1995), suggesting that 1D BFM may be under-
stood as Luttinger liquids of polarons.
To illustrate the results of this section, we show
a typical phase diagram for a BFM in an optical
lattice in Fig. 1, as a function of experimentally
controlled parameters. We consider two types of
atoms, one fermionic and one bosonic, moving in a
lattice potential with the amplitude Vb,|| (see
4
CDW
f-PP
PS
4
0
3
Vb,||/ER
2
1
0.01
0.02
πabf /λL
0.03
0.04
Ultracold Atomic Gases: Novel States of Matter,
Fig. 1 Phase diagram for a mixture of bosonic and spin-
less fermionic atoms in a 1D optical lattice. Shading in the
f-PP phase describes the strength of the bosonic screening
cloud (2l, see Eq. 4) around a pair of fermions. lL and ER
are, respectively, the lattice period and recoil energy. Other
parameters used for this ﬁgure are (see text for notations,
Mathey and Wang (2007) for details) as follows: nb ¼
4, nf ¼ 0.5, Vb,⊥¼ Vf,⊥¼ 20ER, Vf,|| ¼ 2ER, and boson-
boson scattering length abb ¼ 0.01lL
Ultracold Atomic Gases: Novel States of Matter
529

Mathey and Wang 2007), and interacting via a
short-ranged interaction characterized by the scat-
tering length abf between bosons and fermions. We
use these parameters, the scattering length abf and
the strength of the longitudinal optical lattice for
bosonic atoms (Vb,||) as tuning parameters in Fig. 1.
(In this paper, we use Vf/ b,||(⊥) to denote the optical
lattice potential experienced by fermionic/bosonic
atoms in the longitudinal (perpendicular) direc-
tions. Independent tuning of the optical lattices
for two species of atoms can be achieved even
with a single pair of lasers by controlling the laser
detuning and intensity separately.) For relatively
weak interactions and slow bosons (i.e., large
Vb,||), the system is in the charge-density-wave
(CDW) phase, in which the densities of fermions
and bosons have a periodic modulation. (We note
that in a homogeneous 1D system, only quasi-long-
range order for CDW phase is possible. However,
the inhomogeneous trap boundary in a realistic
experiment can pin the CDW phase to generate a
true density modulation.) For very strong interac-
tions the system is unstable to phase separation
(PS) (Albus et al. 2003; Bijlsma et al. 2000;
Cazalilla and Ho 2003). The two regimes are sep-
arated by a p-wave pairing phase of fermionic
polarons ( f-PP). Our analysis is carried out for
the most promising system of atoms in an optical
lattice. However, qualitative results should also
apply to atoms in a tight 1D cigar-shaped magnetic
trap (Görlitz et al. 2001). A sketch of the two
phases is shown in Fig. 2.
The essence of the bosonization procedure is to
diagonalize the effective low-energy Hamilto-
nian, which allows for the exact calculation of
all relevant correlation functions. The phase dia-
grams are determined by ﬁnding the order param-
eter which has the most divergent susceptibility
(Solyom
1979;
Voit
1995).
Bosonization
approach has been applied to BFM in Cazalilla
and Ho (2003). However, that work did not con-
sider the formation of polarons and, as a result, did
not
describe
most
of
the
quantum
phases
discussed here. The present system also has a
close analogy to 1D electron-phonon systems
discussed previously (see, e.g., Voit and Schulz
1987). A qualitative difference of the electron-
phonon system is that the sound velocity is usu-
ally much smaller than the Fermi velocity,
whereas for a BFM the velocity of the phonon
modes (of the bosonic condensate) can be larger
than the Fermi velocity. We also note that the 1D
Ultracold Atomic Gases: Novel States of Matter,
Fig. 2 Illustration of the two phases that occur in a BFM
with spinless fermions, CDW, and f-PP. In the CDW phase
the system develops a 2kf density modulation in both the
fermionic and the bosonic liquids. In the f-PP phase, the
fermions form polarons, indicated by the reduced bosonic
density in their vicinity, that is, their polarization cloud.
This polarization leads to an effective attractive interaction,
which causes these fermionic polarons to pair up and form
a superﬂuid state
530
Ultracold Atomic Gases: Novel States of Matter

p-wave superﬂuid we obtain here may be of rele-
vance to a recent proposal for quantum computa-
tion (Kitaev 2000).
We now give an overview over the, somewhat
technical, derivation of this phase diagram, before
we discuss issues concerning the experimental
realization and detection of these phases and con-
clude. We consider a mixture of spinless fermi-
onic ( f ) and bosonic (b) atoms. For a sufﬁciently
strong optical potential, the microscopic Hamilto-
nian is given by a single-band Hubbard model:
H ¼ 
X
ij
h i
tbb†
i bj þ tff †
i fj



X
i
mfnf,i þ mbnb,i
ð
Þ
þ Ub
2
X
i
nb,i nb,i  1
ð
Þ þ U bf
X
i
nb,inf,i,
ð1Þ
where nb/f,i are the boson-fermion density opera-
tors with mb/f being their chemical potentials. The
tunneling amplitudes tf/b and the particle interac-
tions Ub and Ubf can be expressed explicitly in
terms of the s-wave scattering lengths, the laser
beam intensities, and the atomic masses (Jaksch
et al. 1998). For simplicity we assume that the
ﬁlling fraction of fermions nf  hnf,ii is not com-
mensurate with the lattice or with the ﬁlling frac-
tion of bosons nb. Therefore, we can neglect
lattice-assisted
backward/Umklapp
scattering.
The Fermi momentum and velocity are given by
kf ¼ πnf and vf ¼ 2tf sin(kf), respectively.
In Haldane’s bosonization approach (Cazalilla
2004;
Haldane
1981),
1D
fermion
and
boson
operators
can
be
represented
by
f x
ð Þ ¼ nf þ Pf
½
1=2 X
1
m¼1
e 2mþ1
ð
ÞiYf eiFf
and
b x
ð Þ ¼ nb þ Pb
½
1=2 X
1
m¼1
e2miYbeiFb, where x is a
continuous coordinate that replaces the site
index i. The operators Pf/b(x) and Ff/b(x) are the
bosonized density and phase ﬂuctuation opera-
tors. The  f/b(x) ﬁelds are given by  f/b  πnf/bx
+ π
Ð xdyPf/b(y). The low-energy effective Ham-
iltonian thus can be written as
Heff ¼
X
a¼b, f
ua
2
ð
dx Ka
p
@xFa
ð
Þ2 þ p
Ka P2
a


þ Ubf
ð
dxPbPf
þ 2G
2p
ð
dx p2P2
f  @xFf
ð
Þ2
h
i
:
ð2Þ
where vb and Kb are the phonon velocity and
Luttinger exponent of the bosons and Kf ¼ 1 for
noninteracting fermion atoms.
To obtain the last term of Heff, we have inte-
grated out the high-energy (2kf) phonons within
the instantaneous approximation (i.e., assuming
ub  uf). G  g2kf
2/ o2kf, where o k is the
(Bogoliubov)
phonon
energy
dispersion
(Tsuchiya
and
Grifﬁn
2003)
and
gk ¼ Ubf
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
nbeb,k=2pok
p
is the fermion-phonon
(FP) coupling vertex with εb,k being the non-
interacting boson band energy. In the long wave-
length limit, we have a conventional FP coupling
gk ¼ g|k|1/2 with g  U bf
ﬃﬃﬃﬃﬃﬃ
Kb
p
=2p. The effective
Hamiltonian, Eq. 2, is quadratic and can be diag-
onalized (Engelsberg and Varga 1964). The
resulting two eigenmode velocities are given by
Cazalilla and Ho (2003)
u2
a,A ¼ 1
2 u2
b þ eu2
f


 1
2
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
u2
b þ eu2
f


þ 16eg2ubeuf
q
,
ð3Þ
where euf  u2
f  4G2

1=2 and eg  gey with eθ ¼
((vf  2G)/(vf + 2G))1/4. When the FP coupling
g becomes sufﬁciently strong, the eigenmode
velocity vA becomes imaginary, indicating an insta-
bility of the system. This instability corresponds to
phase separation (global collapse) for positive
(negative) Ubf (Cazalilla and Ho 2003).
To understand the nature of the many-body
state of BFM outside of the instability region, we
analyze the long-distance behavior of the correla-
tion functions. For the bare bosonic and fermionic
particles, we ﬁnd
b x
ð Þb† 0
ð Þ
	

 xj j1
2K1
c
and
f x
ð Þf † 0
ð Þ
	

 cos kfx
ð
Þ xj j1
2 KbþK1
g
ð
Þ: (Here we
deﬁned Kb  e2yevf cos 2c=vA þ sin 2c=va


, Kδ
 Kbvb(sin2c/vA + cos2c/va), K1
g
 e2y=evf
Ultracold Atomic Gases: Novel States of Matter
531

vA cos 2c þ va sin 2c


.Kϵ
1  Kb
1/vb(vA sin2c +
va sin2c), Kbd ¼ ey
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
Kbevfvb
p
sin 2c
ð
Þ=2 1=va  1=vA
ð
Þ,
and K1
gϵ ¼ ey=
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
Kbevfvb
p
sin 2c
ð
Þ=2 va  vA
ð
Þ. c
is
given
by
tan 2c ¼ 4eg vbevf
ð
Þ1=2= v2
b  ev2
f


:
These expressions are obtained from diagonalizing
Heff. For details see Mathey and Wang (2007).) To
describe particles dressed by the other species, we
introduce the composite operators
ef x
ð Þ  eilFb x
ð Þf x
ð Þ,
eb x
ð Þ  eiFf x
ð Þb x
ð Þ,
ð4Þ
with l and Z being some real numbers. The corre-
lation functions of these operators are given by
ef x
ð Þef
† 0
ð Þ
D
E
 cos kfx
ð
Þ xj j1
2 Kbþl2K1
c þK1
g 2lK1
gc
ð
Þ
and
eb x
ð Þeb
† 0
ð Þ
D
E
 xj j1
2 K1
c þ2K1
g 2K1
gc
ð
Þ (Here
we deﬁned Kb  e2yevf cos 2c=vA þ sin 2c=va


,
Kδ  Kbvb(sin2c/vA + cos2c/va), K1
g
 e2y=evf
vA cos 2c þ va sin 2c


, Kϵ
1  Kb
 1/vb(vA sin2c
+ va sin2c), Kbd ¼ ey
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
Kbevfvb
p
sin 2c
ð
Þ=2 1=va  1=vA
ð
Þ,
and K1
gϵ ¼ ey=
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
Kbevfvb
p
sin 2c
ð
Þ=2 va  vA
ð
Þ. c
is
given
by
tan 2c ¼ 4eg vbevf
ð
Þ1=2= v2
b  ev2
f


:
These expressions are obtained from diagonalizing
Heff. For details see Mathey and Wang (2007).) We
observe that the exponents of the correlation func-
tions are maximized for lc ¼ Kϵ/Kγϵ and c ¼
Kγ/Kγϵ. From now on we will use Eq. 4 with lc
and Zc to construct polaronic particles. In the limit
of weak interactions, we have lc ! Ubf/Ub and Zc
! 2Ubf/πvb. This result can be understood by a
simple density counting argument that a fermionic
polaron ( f-polaron) locally suppresses (enhances) a
bosonic cloud by lc particles, whereas a bosonic
polaron (b-polaron) depletes (enhances) the fermi-
onic system by Zc atoms for positive (negative) g.
The polaronic operators deﬁned in Eq. 4 can also
be introduced via the canonical polaron transforma-
tion (CPT), which is often used in polaron theory
(Alexandrov andMott 1995; Mahan1990). The CPT
operator is given by U ¼ e
il
X
k6¼0
Fkbkr†
k þ h:c:


,
where βk is the phonon annihilation operator, rk is the
fermion density operator, Fk is some function of
wavevector k, and l speciﬁes the strength of the
phonon dressing. When applied to a fermion
operator, the CPT transforms it to a polaron operator,
U 1f x
ð ÞU ¼ f x
ð Þ exp il
X
k6¼0
Fkbkeikx þ h:c:


"
#
(Alexandrov and Mott 1995; Mahan 1990), which is
the same as Eq. 4, provided that one takes
Fk ¼
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
2p= Kb kj jL
ð
Þ
p
sgn k
ð Þ . (Note that in 1D
fermionic systems, density operators correspond to
Luttinger bosons.) We note, however, unlike in ordi-
nary polaron theory, where further approximations
after the CPT have to be made (Alexandrov and Mott
1995; Mahan 1990), in the 1D BFM system we
consider here, the full low energy quantum ﬂuctua-
tions have been included via bosonization method
and exact diagonalization of the resulting Hamilto-
nian Eq. 2. This allows for an essentially exact deter-
mination of the polarization parameter l.
Now we study the many-body ground state
phase diagram of a 1D BFM, which is character-
ized by specifying the order parameters that have
the slowest long-distance decay of the correlation
functions (Solyom 1979; Voit 1995). Two types of
ordering were found to occur: 2kf ordering due to
a Peierls-type instability and f-polaron pairing due
to their effective attractive interactions induced by
the screening clouds; see Fig. 2. For the 2kf CDW
order parameter, OCDW ¼ fL
†fR, we ﬁnd αCDW ¼
2  2Kβ, and for the f-polaron pairing ﬁeld,
Of PP ¼ ef Lef R, we obtain αf  PP ¼ 2  2[lc
2Kϵ
1
+ Kγ
1  2lcKγϵ
1]. We did not include polaron
dressing in OCDW, since this operator has no net
fermionic charge and the exponent of OCDW does
not change if we replace f by ef. Scaling exponents
shown in Fig. 3a demonstrate that divergencies of
the CDW and f-PP susceptibilities (corresponding
to positive α) are mutually exclusive and cover the
entire phase diagram outside the PS regime. In the
same ﬁgure, we also show the scaling exponents
calculated for bare fermion pairing (OBFP ¼ fL fR),
bare boson condensate (OBB ¼ b), and b-polaron
condensate (ObP ¼ eb). It is easy to see that the
polaronic order parameters always have larger
exponents than their counterparts constructed
with
bare
atoms,
showing
the
stability
of
polaronic quasi-particle in a 1D BFM system.
Moreover, the necessity to consider f-polaron
pairing instead of bare fermion pairing is further
532
Ultracold Atomic Gases: Novel States of Matter

supported by considering the stability of superﬂu-
idity: We introduce a single weak impurity poten-
tial in the 1D BFM and determine its relevance by
a renormalization group (RG) calculation (Kane
and Fisher 1992). We ﬁnd that the impurity poten-
tial is relevant within the CDW phase and irrele-
vant outside of it. This indicates that there should
be a superﬂuid phase outside of the insulating
CDW phase, which supports the existence of
f-polaron pairing instead of bare fermion pairing
according to Fig. 3a.
In Fig. 3b we show a global phase diagram of a
BFM considering the FP coupling (g) and effec-
tive fermion-fermion interaction (G) as indepen-
dent variables. One can see that the polaronic
effects and the associated pairing phase are impor-
tant when FP coupling (g) is large, while the CDW
phase dominates when the effective fermion inter-
action (G) is increased. This phase diagram is very
similar to what one ﬁnds for spinless electrons in
Luttinger liquid theory (Solyom 1979; Voit 1995),
where CDWand pairing phase compete with each
other in the whole phase diagram. Therefore, one
can introduce a Luttinger liquid of polarons to
describe BFM in 1D systems. The phase diagram
in terms of experimentally controlled parameters
was shown in Fig. 1. When considering ﬁnite
temperature effects in a realistic experiment, we
note that the correlation function is cut off by
thermal correlation lengths, which are approxi-
mately given by x  vf/ kBT. Therefore, the zero
temperature ground states should appear when
x > L with L being the system size. This corre-
sponds to a temperature regime of 1 % of the
Fermi temperature for systems of approximately
100 sites in the longitudinal direction.
Several approaches can be used to detect the
quantum phases discussed above. First, in the
CDW phase the fermion density modulation will
induce a 2kf density wave in the boson ﬁeld in
addition to the zero momentum condensation so
that the CDW phase can be observed as interfer-
ence peaks at momentum k ¼ 2kf in a standard
time-of-ﬂight (TOF) measurement for bosons.
(We note that in a homogeneous 1D system only
quasi-long-range order for CDW phase is possi-
ble. However, the inhomogeneous trap boundary
in a realistic experiment can pin the CDW phase to
generate a true density modulation.) Secondly, the
polaron pairing phase can be observed by measur-
ing the noise correlation of fermions in a TOF
experiment as proposed in Altman et al. (2004).
Thirdly, a laser stirring experiment (Onofrio et al.
1999; Raman et al. 1999) can be used to probe the
phase transition between the insulating (pinned by
trap potential) CDW and the superﬂuid f-PP
phase: One can use a laser beam focused at the
center of the cloud and stir such local potential to
measure the response of the BFM. If the system is
in the pairing phase, the laser beam can be moved
through the system without dissipation if only its
velocity is slower than some critical value
2
a
b
1
0
CDW
CDW
f−PP
0.4
0.8
0.5
1.0
PS
0
3
f−PP
0.05
0.1
G / νf
g / νf
g / νf
b−P
BB
BFP
α
Ultracold Atomic Gases: Novel States of Matter,
Fig. 3 Ground state of a BFM with spinless fermions.
(a) Scaling exponents of different order parameters (see
the text). Parameters are chosen to be vb/vf ¼ 3, Kb ¼ 5, and
G/ vf ¼ 0.1. (b) Global phase diagram for vb/vf ¼ 5 and
Kb ¼ 10. Shading density indicates the strength of the
screening clouds of a polaron pair, 2lc
Ultracold Atomic Gases: Novel States of Matter
533

(Onofrio et al. 1999; Raman et al. 1999). At the
f-PP/CDW phase boundary, this critical velocity
goes to zero, reﬂecting a transition to the insulat-
ing (CDW) state. This scenario follows from the
above described RG analysis of a single impurity
potential (Kane and Fisher 1992). Finally, a way
to probe the PS boundary could be to measure the
dipolar collective oscillations of the system, gen-
erated by a sudden displacement of the harmonic
trap potential with respect to the lattice potential
(Gensemer and Jin 2001; Maddaloni et al. 2000;
Vichi et al. 1999). When the system is near the PS
boundary, fermion-boson interaction will strongly
reduce the frequency of the dipolar mode.
In summary, we used bosonization to investi-
gate the quantum phases of 1D mixtures of
bosonic and fermionic atoms involving spinless
fermions. The phase diagram that we found can be
understood in terms of a Luttinger liquid of
polarons. We also described several experimental
techniques for probing these quantum phases.
Commensurate Mixtures of Ultracold Atoms
in One Dimension
In this section we explore the behavior of ultra-
cold
atomic
mixtures,
conﬁned
to
one-
dimensional (1D) motion in an optical lattice,
that exhibit different types of commensurability,
by which we mean that the atomic densities and/or
the inverse lattice spacing has an integer ratio.
Commensurable ﬁllings arise naturally in many
ultracold atom systems, because the external trap
potential approximately corresponds to a sweep of
the chemical potential through the phase diagram
and therefore passes through points of commen-
surability. At these points the system can develop
an energy gap, which ﬁxes the density commen-
surability over a spatially extended volume. This
was demonstrated in the celebrated Mott insulator
experiment by Greiner et al. (2002), where Mott
phases with integer ﬁlling occurred in shell-
shaped regions in the atom trap. These gaped
phases gave rise to the well-known signature in
the
time-of-ﬂight
images
and
triggered
the
endeavor of “engineering” many-body states in
optical lattices. (Due to the conﬁning trap, the
transition is, while visible, “blurred” into a grad-
ual crossover, due to ﬁnite size effects and, more
importantly, due to the coexistence of several
phases in the trap. This can also be expected for
the phase transitions predicted in this entry.) Fur-
ther
examples
include
the
recently
created
density-imbalanced fermion mixtures (Partridge
et al. 2005; Zwierlein et al. 2005) in which the
development of a balanced, i.e., commensurate,
mixture at the center of the trap is observed.
In 1D, this phenomenon is of particular impor-
tance, because it is the only effect that can lead to
the opening of a gap, for a system with short-range
interactions. In contrast to higher-dimensional sys-
tems, where, for instance, pairing can lead to a state
with an energy gap, in 1D only discrete symmetries
can be broken, due to the importance of ﬂuctua-
tions. Orders that correspond to a continuous sym-
metry can, at most, develop quasi-long-range order
(QLRO), which refers to a state in which an order
parameter O(x) has a correlation function with
algebraic scaling, hO(x)O(0)i  |x| (2  α), with a
positive scaling exponent α.
Due to its importance in solid-state physics, the
most thoroughly studied commensurate 1D sys-
tem is the SU(2) symmetric system of spin-1/2
fermions. This system develops a spin gap for
attractive interaction and remains gapless for
repulsive interaction, as can be seen from a
second-order
RG
calculation.
However,
the
assumed symmetry between the two internal
spin states, which is natural in solid-state systems,
does not generically occur in Fermi-Fermi mix-
tures (FFMs) of ultracold atoms, where the “spin”
states are in fact different hyperﬁne states of the
atoms. An analysis of the generic system is there-
fore highly called for. Furthermore, we will
extend this analysis to both Bose-Fermi (BFMs)
and Bose-Bose mixtures (BBMs), as well as to the
dual commensurability, in which the charge ﬁeld,
and not the spin ﬁeld, exhibits commensurate
ﬁlling, as will be explained below.
The main results of this section are the phase
diagrams shown in Figs. 4 and 5. We ﬁnd that
both attractive and repulsive interactions can
open an energy gap. For FFMs the entire phase
diagram is gaped, except for the repulsive SU
(2) symmetric regime (cf. Cazalilla et al. 2005);
for BFMs or BBMs the bosonic liquid(s) need
(s) to be close to the hardcore limit, otherwise the
534
Ultracold Atomic Gases: Novel States of Matter

system remains gapless. Furthermore, we ﬁnd a
rich structure of quasi-phases, including charge
and spin density wave order (CDW, SDW), sin-
glet and triplet pairing (SS, TS), polaron pairing
(Mathey et al. 2004; Mathey and Wang 2007),
and a supersolid phase, which is the ﬁrst
example of a supersolid phase in 1D. These
results are derived within a Luttinger liquid
(LL) description, which treats bosonic and fer-
mionic liquids on equal footing.
We will now classify the types of commensu-
rability that can occur in a system with short-
SDWZ(TSZ)
CDW(SS) 
SDWZ
CDW
PS
PS
PP
CL
CDW
SDWZ
CL
SS(CDW)
SS
0
0.5
Z
Z
1
0
−2
−1
0
1
2
−2
−1
0
1
2
0.5
1
U12/ν0
U12/ν0
a
b
Ultracold Atomic Gases: Novel States of Matter,
Fig. 4 (a) Phase diagram of a commensurate FFM or a
BBM of hardcore bosons (with the replacement TSz ! SS),
(b) phase diagram of a BFM with hardcore bosons, in
terms of the interaction U 12 and the parameter z ¼ |v1 
v2|/(v1 + v2). For both attractive and repulsive interactions,
a spin gap opens, except for z ¼ 0 and positive interaction.
In the attractive regime, a FFM or a BBM shows either
singlet pairing or CDW order or a coexistence of these
phases and a BFM shows either CDW order or polaron
pairing. For repulsive interaction all mixtures show SDW
ordering, with FFMs and BBMs showing subdominant
triplet or singlet pairing, respectively, for a large range of
z. In the gapless regime, a FFM shows degenerate SDW
and CDWorder, a BFM shows CDWorder for the fermions
and SF for the bosons, and a BBM shows SF with sub-
dominant CDW, i.e., supersolid behavior. For very large
positive values of U12, the system undergoes phase sepa-
ration (PS); for very large negative values, it collapses (CL)
CDW
f−PP
PP
2
2
SS
SF
PS
1
−2
−1
0
1
2
−2
−1
1
0
U12/ν0
U12/ν0
1
2
SDWZ
SDWZ
2
K
K
CL
PS
2
SS
(CDW)
CDW(SS)
SF(CDW)
CDW
CL
a
b
Ultracold Atomic Gases: Novel States of Matter,
Fig. 5 (a) Phase diagram of a BFM; (b) phase diagram
of a BBM with the ﬁrst species being in the hardcore limit,
in terms of U12, and the Luttinger parameter of the second
species (K2), at the ﬁxed velocity ratio |v1  v2|/(v1 + v2) ¼
0.5. For large repulsive interaction the system undergoes
phase separation (PS); for large attractive interaction the
system collapses (CL). In the regime below the thick line,
the system opens a gap, i.e., if species 2 is close to the
hardcore limit. However, for larger values of K2, the
gapless phase is restored. Close to the transition, the prop-
erties of the fermions, respectively, hardcore bosons, are
still affected by the RG ﬂow, leading to CDW order for the
fermions and to supersolid behavior for the bosons
Ultracold Atomic Gases: Novel States of Matter
535

ranged density-density interaction. We consider
Haldane’s
representation
(Cazalilla
2004;
Haldane 1981) of the densities for the two species:
n1=2 ¼ n1=2 þ P1=2

X
m
e2miY1=2:
ð5Þ
n1 and n2 are the densities of the two liquids
and P1/ 2(x) are the low-k parts (i.e., k 	 1/v) of
the density ﬂuctuations; the ﬁelds  1/2(x) are
given by  1/2(x) ¼ πn1/2x + θ1/2(x), with θ1/2(x)
¼ π
Ð x dyP1/2(y). These expressions hold for
both bosons and fermions. If we use this repre-
sentation in a density-density interaction term
U12
Ð
dxn1(x)n2(x), we generate to lowest order
a term of the shape U12
Ð
dxP1(x)P2(x), but in
addition an inﬁnite number of nonlinear terms,
corresponding to all harmonics in the represen-
tation. However, only the terms for which the
linear terms (2πm1/2n1/2x) cancel can drive a
phase transition. For a continuous system this
happens for m1n1  m2n2 ¼ 0, whereas for a
system on a lattice, we have the condition
m1n1  m2n2 ¼ m3, where m1, m2, and m3 are
integer numbers. In general, higher integer num-
bers correspond to terms that are less relevant,
because the scaling dimension of the nonlinear
term scales quadratically with these integers. We
are therefore led to consider small integer ratios
between the ﬁllings and the lattice if present. In
Mathey and Wang (2007), we considered two
cases of commensurabilities: a Mott insulator tran-
sition coupled to an incommensurate liquid and a
fermionic liquid at half-ﬁlling coupled to an incom-
mensurate bosonic liquid. In both cases the com-
mensurability occurs between one species and the
lattice, but does not involve the second species.
Here, we consider the two most relevant, i.e., low-
est order, cases which exhibit a commensurability
that involves both species. The ﬁrst case is the case
of equal ﬁlling n1 ¼ n2; the second is the case of the
total density being unity, i.e., n1 + n2 ¼ 1, where the
densities n1 and n2 themselves are incommensu-
rate. The ﬁrst case can drive the system to a spin-
gaped state, the second to a charge gaped state. We
will determine in which parameter regime these
transitions occur and what type of QRLO the
system exhibits in the vicinity of the transition.
These two cases can be mapped onto each other
via a dual mapping, which enables us to study only
one case and then infer the results for the second by
using this mapping. We will write out our discus-
sion for the case of equal ﬁlling and merely state
the corresponding results for complementary
ﬁlling.
The action of a two-species mixture with equal
ﬁlling in bosonized form is given by
S ¼ S0,1 þ S0,2 þ S12 þ Sint:
ð6Þ
The terms S0,j, with j ¼ 1,2, are given by
S0,j ¼
1
2pKj
ð
d2r
1
uj @tyj

2 þ uj @xyj

2


: ð7Þ
Each of the two types of atoms, regardless of
being bosonic or fermionic, is characterized by a
Luttinger parameter K1/2 and a velocity v1/2. Here
we integrate over r ¼ (n0t, x), where we deﬁned
the energy scale v0 ¼ (v1 + v2)/2. The term S12
describes the acoustic coupling between the two
species, and is bilinear:
S12 ¼ U12
p2
ð
d2r@xy1@xy2 þ V 12
p2
ð
d2r@ty1@ty2:
ð8Þ
The second term is created during the RG ﬂow;
its prefactor therefore has the initial value
V12(0) ¼ 0. We deﬁne S0 ¼ S0,1 + S0,2 + S12,
which is the diagonalizable part of the action.
Sint
corresponds
to
the
non-linear
coupling
between the two liquids, which we study within
an RG approach:
Sint ¼ 2g12
2pa
ð
Þ2
ð
d2r cos 2y1 þ 2y2
ð
Þ:
ð9Þ
This bosonized description applies to a BBM, a
BFM, and a FFM. Depending on which of these
mixtures we want to describe, we construct either
bosonic or fermionic operators according to
Haldane’s construction (Cazalilla 2004; Haldane
1981):
536
Ultracold Atomic Gases: Novel States of Matter

f =b ¼ n0 þ P
½
1=2
X
m odd=even
emiYeiF:
ð10Þ
n0 is the zero mode of the density and F(x) is the
phase ﬁeld, which is the conjugate ﬁeld of the
density ﬂuctuations P(x). The action for a mixture
with complementary ﬁlling, n1 + n2 ¼ 1, is of the
form S0 + Sint
0, where the interaction Sint
0 is given by
S0
int ¼ 2g12
2pa
ð
Þ2
ð
d2r cos 2y1 þ 2y2
ð
Þ:
ð11Þ
To map the action in Eq. 6 onto this system, we
use the mapping θ2 !  θ2, f2 !  f2, and g12
!  g12, which evidently maps a mixture with
complementary ﬁlling and attractive (repulsive)
interaction and onto a mixture with equal ﬁlling
with repulsive (attractive) interaction.
To study the action given in Eq. 6, we perform
an RG calculation along the lines of the treatment
of the sine-Gordon model in Gogolin et al. (1998)
and Kogut (1979). In our model, a crucial modi-
ﬁcation arises: The linear combination θ1  θ2 that
appears in the nonlinear term is not proportional to
an eigenmode of S0, and therefore, the RG ﬂow
does not affect only one separate sector of the
system, as in an SU(2)-symmetric system. The
RG scheme that we use here proceeds as follows:
First, we diagonalize S0 through the transforma-
tion (see Mathey 2007) y2 ¼ B1ey1 þ B2ey2 and
y2 ¼ D1ey1 þ D2ey2 , where B1/2 and D1/2 are
some coefﬁcients, and ey1=2 are the eigenmode
ﬁelds with velocities eu1=2. Now we introduce an
energy
cutoff
Λ
on
ey1=2
according
to
o2=eu1=2 þ eu1=2k2 < L2 . We shift this cutoff by
an amount dΛ and correct for this shift up to
second order in g12. At ﬁrst order, only g12 is
affected; its ﬂow equation is given by
dg12
dl ¼
2  K1  K2  2
p
U12 þ V 12u1u2
u1 þ u2


g12,
ð12Þ
with dl ¼ dΛ/Λ. At second order several terms are
created that are quadratic in the original ﬁelds θ1
and θ2. We undo the diagonalization and absorb
these terms into the parameters of the action,
which concludes the RG step. By iterating this
procedure we obtain these ﬂow equations at sec-
ond order in g12:
dK1=2
dl
¼  g2
12
16p2
2 þ
u2
u1 þ u1
u2




,
ð13Þ
du1
dl ¼ u1
g2
12
16p2
u2
u1  u1
u2


,
ð14Þ
du2
dl ¼ u2
g2
12
16p2
u1
u2  u2
u1


,
ð15Þ
dU 12
dl
¼  g2
12
8p u1 þ u2
ð
Þ,
ð16Þ
dV 12
dl
¼  g2
12
8p 1=u1 þ 1=u2
ð
Þ:
ð17Þ
The system of differential equations, Eqs. 12–17,
can show two types of qualitative behavior: The
coefﬁcient g 12 of the nonlinear term (9) can either
ﬂow to zero, i.e., Sint is irrelevant, or it diverges,
leading to the formation of an energy gap. In the ﬁrst
case, the system ﬂows to a ﬁxed point that is
described by a renormalized diagonalizable action
of the type S 0, from which the quasi-phases can be
determined.
When Sint is relevant, we introduce the ﬁelds
(Voit 1995) yr=s ¼
1ﬃﬃ
2
p
y1  y2
ð
Þ, which deﬁne the
charge and the spin sector of the system. In this
regime, these sectors decouple. Each of the two
sectors is characterized by a Luttinger parameter
and a velocity, Kr/s and vr/s, which are related to
the original parameters in S0 in a straightforward
way. Using the numerical solution of the ﬂow
equations, we ﬁnd that Ks ! 0, as can be
expected for an ordering of the nature of a spin
gap, leaving Kr the only parameter characterizing
the QLRO in this phase.
In order to determine the QLRO in the system,
we will determine the scaling exponents of vari-
ous order parameters. The order parameter with
the largest positive scaling exponent shows the
dominant order, whereas other orders with posi-
tive exponent are subdominant.
Ultracold Atomic Gases: Novel States of Matter
537

We will now apply this procedure to the differ-
ent types of mixtures. For a FFM we ﬁnd that the
system always develops a gap, with the exception
of
the
repulsive
SU(2)
symmetric
regime
(cf. Cazalilla et al. 2005). To determine the
QLRO we introduce the following operators
(Giamarchi 2004; Voit 1995):
OSS
¼
X
s, s0
esf R,sds,s0f L,3s0,
Oa
TS
¼
X
s, s0
esf R,ssa
s,s0f L,3s0,
OCDW
¼
X
s, s0
f †
R,sds,s0f L,s0,
and
Oa
SDW
¼
X
s, s0
esf †
R,ssa
s,s0f L,s0,
with s,s0 ¼ 1,2, es ¼ 3  2s, and a ¼ x,y,z. In the
gapless SU(2) symmetric regime, both CDW and
SDW show QLRO, with both scaling exponents
of the form αSDW/CDW ¼ 1  Kr (Voit 1995),
which shows that these orders are algebraically
degenerate. Within the gaped regime the scaling
exponents of these operators are given by αSS,
TSz ¼ 2  Kr
1 and αCDW,SDWz ¼ 2  Kr. As
discussed in Giamarchi (2004), the sign of g12
determines whether CDW or SDWz and SS or
TSz appear. In Fig. 4a, we show the phase diagram
based on these results. In addition to these phases,
we indicate the appearance of the Wentzel-
Bardeen instability, shown as phase separation
for repulsive interaction and collapse for attractive
interaction.
We will now use the dual mapping to obtain the
phase diagram of a FFM with complementary
ﬁlling from Fig. 4a. Under this mapping, the
attractive and repulsive regimes are exchanged
with
the following
replacements: CDW
!
SDWz, SDWz ! CDW, SS,TSz ! SDW, and
SDW ! SS. Note that the gapless regime is now
on the attractive side, with degenerate CDW and
SS pairing.
For BBMs we proceed in the same way as for
FFMs. We introduce the following set of order
parameters: OCDW ¼ b1
†b1 + b2
†b2s, OSS ¼ b1b2,
OSDWz ¼ b†
1b1 þ b†
2b2 , OSDWx ¼ b†
1b2 þ b†
2b1 ,
OSDWy ¼ i(b1
†b2  b2
†b1), and in addition the
superﬂuid (SF) order parameters b1 and b2. In
Fig. 4a we show the phase diagram of a mixture
of a BBM of hardcore bosons, which is almost
identical to the one of a FFM. The phase diagram
of the mixture with complementary ﬁlling, as
obtained from the dual mapping, is also of the
same form as its fermionic equivalent, with the
exception of the gapless regime, in which BBMs
show supersolid behavior (coexistence of SF and
CDWorder), and with the replacement TSz ! SS.
In Fig. 5b, we show the phase diagram of a
mixture of hardcore bosons (species 1) and bosons
in the intermediate to hardcore regime (species 2).
If species 2 is sufﬁciently far away from the hard-
core limit, the system remains gapless. However,
in the vicinity of the transition, the scaling expo-
nents of the liquids are affected by the RG ﬂow.
As indicated, the effective scaling exponent of the
hardcore bosons is renormalized to a value that is
smaller than 1, and therefore, we ﬁnd both SF and
CDW order, i.e., supersolid behavior. The phase
diagram of the dual mixture is of the following
form: The attractive and the repulsive regimes are
exchanged, and in the gaped phase, we again have
the following mapping: CDW ! SDWz, SDWz
! CDW, SS ! SDW, and SDW ! SS. The
gapless regime is unaffected.
For a BFM we ﬁnd that the order parameters
OCDW, OSDWz, Of PP ¼ fR fLe 2ilF
b (Mathey
et al. 2004; Mathey and Wang 2007), and b can
develop QLRO in the gapless regime. In the gaped
regime, the order parameters OPP  fRbfLb and
OPP0  fRb†fLb†, in addition to OCDW, show
QLRO. (OPP/PP
0 are special cases of the polaron
pairing operators discussed in Mathey et al.
(2004), and Mathey and Wang (2007).) In
Fig. 4b we show the phase diagram of a BFM
with hardcore bosons, and in Fig. 5a, we vary
the Luttinger parameter of the bosons. In both
the gapless phase and the gaped phase, we ﬁnd
that CDW and f-PP or PP, respectively, are mutu-
ally exclusive and cover the entire phase diagram,
cf. (Mathey et al. 2004; Mathey and Wang 2007).
The dual mapping again maps attractive and
repulsive regimes onto each other. Within the
gaped phase we ﬁnd the mapping CDW !
SDWz, SDWz ! CDW, and PP ! PP0; the
gapless regime is unaffected.
538
Ultracold Atomic Gases: Novel States of Matter

Before we conclude, we discuss how these
predictions could be measured experimentally.
CDW order will create additional peaks in TOF
images, corresponding to a wavevector Q ¼ 2kf.
As demonstrated and pointed out in Altman et al.
(2004), Fölling et al. (2005), Greiner et al. (2005),
and Mathey et al. (2008a), the noise in TOF
images allows to identify the different regimes of
both gaped and gapless phases. As discussed in
Mathey et al. (2004) and Mathey and Wang
(2007), a laser stirring experiment could deter-
mine the onset of CDW order for fermions or the
supersolid regime for bosons. RF spectroscopy
(Chin et al. 2004) can be used to determine the
presence and the size of an energy gap.
In conclusion, we have studied mixtures of
ultracold atoms in 1D with commensurate ﬁlling.
We used a Luttinger liquid description which
enables us to study FFMs, BFMs, and BBMs in
a single approach. We ﬁnd that FFMs are generi-
cally gaped for both attractive and repulsive inter-
actions, whereas for BFMs and BBMs the bosons
need to be close to the hardcore limit. We ﬁnd a
rich structure of quasi-phases in the vicinity of
these transitions, in particular a supersolid phase
for BBMs that occurs close to the hardcore limit.
Experimental methods to detect the predictions
were also discussed.
Phase-Locking Transition of Coupled
Low-Dimensional Superfluids
Most phase transitions that have been realized in
ultracold atom systems are generic ﬁrst- or
second-order transitions. However, the paradigm
of phase transitions in two dimensions at ﬁnite
temperature is of a more intricate type, a
Kosterlitz-Thouless transition, which is character-
ized by a change of the functional form of the
correlation function of the order parameter, from
algebraic decay to exponential decay. In an
intriguing new development in studying low-
dimensional strongly correlated systems, such a
Kosterlitz-Thouless (KT) transition (Chaikin and
Lubensky
1995)
was
indeed
realized
and
observed (Hadzibabic et al. 2006). In this experi-
ment the interference amplitude between two
independent two-dimensional (2D) Bose systems
was studied as a function of temperature. This
analysis revealed the jump in the superﬂuid stiff-
ness (see also Polkovnikov et al. 2006) and the
emergence of unpaired isolated vortices as they
crossed the phase transition.
The other focus of this section, the physics of
ramping across a phase transition, is also triggered
by a recent experiment: Sadler et al. observed
spontaneous generation of topological defects in
the spinor condensate after a sudden quench
(i.e., a rapid, non-adiabatic ramp) through a quan-
tum phase transition (Sadler et al. 2006). A similar
experiment in a double-layer system was reported
in Scherer et al. (2006). The topological defects
are generated (Kibble 1976) at a density which is
related to the rate at which the transition is crossed
(Zurek 1985). Later it was argued that the depen-
dence of the number of such defects on the swipe
rate across a quantum critical point can be used as
a probe of the critical exponents characterizing the
phase transition (Polkovnikov 2005; Zurek et al.
2005;
Dziarmaga
2005).
This
Kibble-Zurek
(KZ) mechanism was originally considered as an
early universe scenario creating cosmic strings,
which would serve as an ingredient for the forma-
tion of galaxies. (Since then, it has been
established that cosmic strings can only contribute
a small fraction of the initial density perturbations.
We thank T. Kibble for this comment.) Cold atom
systems appear to be a very suitable laboratory for
performing such “cosmological experiments,”
since these systems are highly tunable and well
isolated from the environment. So far the experi-
ments and the theoretical proposals addressed the
KZ scenario across a quantum phase transition.
The main reason is that it is generally hard to cool
such systems sufﬁciently fast to observe non-
equilibrium effects. In this work we provide an
example of a particular system where this difﬁ-
culty can be easily overcome by quenching the
transition temperature Tc instead of T. Thus, the
relevant ratio T/ Tc can be tuned with an arbitrary
rate and the KZ mechanism can be observed.
Speciﬁcally, we examine a system of two super-
ﬂuids (SF): As we show below, by turning on
tunneling between the two systems, the transition
temperature increases rapidly, and the system
Ultracold Atomic Gases: Novel States of Matter
539

attempts to create long-range order (LRO). How-
ever, in this process, defects in the SF phase are
created, which develop into long-lived vortex-
antivortex pairs or in ﬁnite system unbalanced
population between vortices and antivortices. We
note that because the systems are isolated and
there is no external heat bath, the temperature
itself also changes due to the quench. However,
the long-wavelength ﬂuctuations relevant for the
KT transition are only a small subset of all degrees
of freedom, majority of which are only weakly
affected by small interlayer tunneling. So we
believe that the change of the Tc is the main effect
of the quench.
In this section we consider two SFs coupled via
tunneling and/or interactions. In the experiments
the hopping or tunneling rate between two sys-
tems can be tuned to a high precision (Hadzibabic
et al. 2006, 2004; Paredes et al. 2004; Schumm
et al. 2005). Interactions between the atoms in
different systems can either be realized in ensem-
bles of polar molecules or by using mixtures of
two hyperﬁne states, where the tunneling rate is
controlled by an infrared light source (Jo et al.
2007), which induces spin-ﬂipping between the
hyperﬁne states. In this case the atoms in different
states naturally interact with each other since they
are not physically separated in space. The main
results of our analysis are the phase diagrams of
coupled SFs in Figs. 6 and 7, the behavior of Tc,
and the energy gap shown in Fig. 8, as well as the
proposal of realizing the KZ mechanism by
switching on the tunneling between two SFs.
2D Superfluids
In this section we consider two 2D SFs, each
characterized by a KT temperature TKT. We write
the bosonic operators b1/2 in the two layers in a
phase-density
representation
(Chaikin
and
Lubensky
1995;
Gogolin
et
al.
1998),
b1=2 
ﬃﬃﬃﬃﬃﬃﬃﬃ
r1=2
p
exp if1=2


, where r1/2 are the den-
sity operators of the two systems and f1/2 the
phases. The low-momentum ﬂuctuations of the
phase ﬁelds are described by Gaussian contribu-
tions to the Hamiltonian ℋ0. Because of the for-
mal analogy between the quantum 1D and thermal
2D systems (Giamarchi 2004), we adopt the quan-
tum terminology throughout the paper and refer to
the ratio of the Hamiltonian and the temperature
as the action. Then
TBG
AQ
SQ
−1
1
2
−0.5
0
0.5
1
AQ/SQ
T/T KT
Jint/J
Ultracold Atomic Gases: Novel States of Matter,
Fig. 6 Phase diagrams of two 2D SFs, coupled through
a term of the form S12 S12, Eq. 22, in terms of Jint/J and
T/TKT. For low temperatures we ﬁnd antisymmetric quasi-
order (AQ) and/or symmetric quasi-order (SQ), which
undergo a KT transition either simultaneously due to single
vortices (AQ/SQ to thermal Bose gas (TBG) phase) or
individually due to correlated vortex pairs: Symmetric
(antisymmetric) vortex pairs drive the AQ/SQ to AQ
(SQ) transition
3
2
1
−1
−0.5
0
DLSF
TBG
ASF
I
I
T/TKT
II
SQ
0.5
Jint /J
1
Ultracold Atomic Gases: Novel States of Matter,
Fig. 7 Phase diagram, temperature (in units of TKT) versus
interaction (in units of J). We assume J⊥/J  103 and A1/J
 103. DLSF double-layer superﬂuid, TBG thermal Bose
gas, ASF antisymmetric superﬂuid, SQ symmetric quasi-
order. The order of the transition lines are either ﬁrst order
(I), second order (II), or KT (thin lines)
540
Ultracold Atomic Gases: Novel States of Matter

S0  ℋ0
T
¼ J
2T
ð
d2r
∇f1
ð
Þ2 þ ∇f2
ð
Þ2
h
i
: ð18Þ
The energy scale J here is related to TKT by J ¼
2TKT/ π. Besides these long-wavelength ﬂuctua-
tions, the system also contains additional degrees
of freedom, vortex-antivortex pairs (Chaikin and
Lubensky 1995). The corresponding term in the
action is expressed through the dual ﬁelds θ1,2
(Gogolin et al. 1998):
S1 ¼ 2A1
T
ð
d2r
2pa
ð
Þ2 cos 2y1
ð
Þ þ cos 2y2
ð
Þ
½
,
ð19Þ
where α is a short-distance cutoff of the size of the
vortex core and A1 is proportional to the single-
vortex fugacity, A1  J exp(J/T), where we
assume both SFs to have the same effective param-
eters J and A1. Operators of the type exp(2iθ) create
kinks in the ﬁeld f: exp(2iθ(x))f(x 0)exp(2iθ(x))
 f(x0) + 2π (x  x0),  (x) being the step function,
which corresponds to the effect of vortices in the
original 2D problem (Giamarchi 2004, p. 92).
In addition, the two systems are coupled by a
hopping term t⊥b1
†b2 + h.c., which results in the
following contribution to the action:
S⊥¼ 2J ⊥
T
ð
d2r
2pa
ð
Þ2 cos f1  f2
ð
Þ,
ð20Þ
where the bare value of J⊥corresponds approxi-
mately to t⊥r0. In principle, the hopping term is
modiﬁed by the vortex contributions; however,
these corrections are always irrelevant under
renormalization group (RG).
For most of the discussion in this entry, we use
the symmetric and antisymmetric combinations of
f1/2 and θ1/2:
fs=a ¼ f1  f2
ð
Þ=
ﬃﬃﬃ
2
p
,
ys=a ¼ y1  y2
ð
Þ=
ﬃﬃﬃﬃ
2
p
ð21Þ
Written in these ﬁelds, the term S0 in Eq. 18 is
again a sum of Gaussian models, now in the ﬁelds
fs and fa, with the same energy scale J. However,
we will consider a broader class of actions, in
which the energy scales of the symmetric and
antisymmetric sectors differ. We include the fol-
lowing term in the action:
S12 ¼ J int
T
ð
d2r∇f1∇f2:
ð22Þ
With this, the quadratic part of the action is
given by
S0 þ S12 ¼ J s
2T
ð
d2r ∇fs
ð
Þ2 þ J a
2T
ð
d2r ∇fa
ð
Þ2,
ð23Þ
where Js and Ja are given by Js/a ¼ J  Jint.
We now motivate the existence of such a term
S12 in ultracold atom systems, by considering two
BECs coupled by a short-range density-density
interaction. Starting from a Hamiltonian of the
0.2
0.1
0.02
0.01
2
TBG
I
II
III
DLSF
1
0.03
0.02
0.01
0
1
2
3
TC/TKT
T / TKT
J⊥/J
J⊥/J
Δ / J⊥
a
b
Ultracold Atomic Gases:
Novel States of Matter,
Fig. 8 (a) Critical
temperature Tc of the DLSF-
TBG transition (in units of
TKT) for different values of
A1/ J: 103, 0.1, 0.4 (I–III)
and for Jint ¼ 0. (b) Energy
gap in the anti-symmetric
sector (in units of J⊥) as a
function of J⊥/J and
temperature (in units of
TKT). We have set A1/J ¼
0.1 and Jint ¼ 0
Ultracold Atomic Gases: Novel States of Matter
541

form H ¼
X
k
ϵkb†
kbk þ g=2V
ð
Þr†
krk
h
i
, where bk
is the boson operator, ϵk is the free dispersion ϵk ¼
k2/2m, g is the interaction strength of the contact
interaction, V is the volume, and rk is the
density operator of momentum k, given by
rk ¼
X
P
b†
PbP þ k,
we assume that the zero
momentum mode is macroscopically occupied
and formally replace the operator b 0 by a number,
b0 !
ﬃﬃﬃﬃﬃﬃ
N0
p
, where N0 is the number of condensed
atoms which is comparable to the total atom num-
ber N, i.e., N0  N. Next we keep all terms that are
quadratic in bk (with k 6¼ 0) and perform a
Bogoliubov transformation, given by bk ¼ ukβk
+ ukβ k
†
, to diagonalize the Hamiltonian. The
eigenmodes
βk
have
a
dispersion
relation
ok ¼
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
ϵk ϵk þ 2gn
ð
Þ
p
, with n being the density
N/ V. The low-k limit is given by ok
2  u2|k|2, with
u ¼
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
gn=m
p
, which corresponds to the contribu-
tion in Eq. 18 of the action. Next, we consider the
sum of two copies of the previous Hamiltonian
with boson operators b1/2. In addition we consider
an interaction H12 ¼ g12=V
X
k
r†
1,kr2,k,
where
the
density
operators
r1/2,k
are
given
by
r1=2,k ¼
X
p
b†
1=2,pb1=2,pþk: Following the same
procedure as before, we ﬁnd two eigenmode
branches, corresponding to inphase and out-of-
phase superpositions of the modes of each con-
densate, with the dispersions os/a,k
2
 us/a
2 |k|2, with
the velocities us=a ¼
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
g  g12
ð
Þn=m
p
. Therefore,
for this example, the energy scale Jint is related to
g12n/ m, which would be of similar order as J for a
system interacting via contact interaction, for
small temperatures. This discussion only applies
to the weakly interacting limit of a true conden-
sate. However, it demonstrates that a density-
density contact interaction term can lead to a
substantial energy splitting of the inphase and
out-of-phase modes.
Finally, in addition to single vortices in each
SF, we have to consider the possibility of corre-
lated vortex pairs, i.e., one vortex in each layer at
the same location of either the same or of opposite
vorticity. We will refer to these vortex conﬁgura-
tions as symmetric or antisymmetric vortex pairs,
respectively. These excitations appear as the fol-
lowing terms in the action:
Ss,a ¼ 2As,a
T
ð
d2r
2pa
ð
Þ2 cos 2
ﬃﬃﬃ
2
p
ys,a



ð24Þ
These
correlated
vortex
terms,
which
describe new degrees of freedom, can be the
most relevant nonlinear terms in the action,
which derives from the possibility that the vor-
tices in different layers interact with each other,
through the terms (20) and (22). The effect of
these terms is the following: At low tempera-
tures the energy between two single vortices of
opposite vorticity due to tunneling grows as the
square of the distance D between them, i.e., as
J⊥(D/ α)2. As a result, the tunneling term
attempts to conﬁne vortices of opposite vortic-
ity,
leading
to
phase-locking
between
the
layers, which we describe further later on. The
interaction S12 changes the energy of correlated
vortex pairs as follows: The energy of a single
vortex is given by 2πJlog L/α, where L is the
system size, whereas a symmetric/antisymmet-
ric vortex pair has an energy of 4π(J  Jint)log
L/α. Therefore, symmetric vortex pairs are
the
lowest
energy
vortex
excitations
for
Jint < J/2, whereas for Jint > J/2, antisym-
metric vortex pairs are the lowest energy exci-
tations. As we will see below, in these regimes
correlated vortex pairs drive transitions to
phases, in which one sector is (quasi-)SF,
whereas the other is disordered. We will also
see that these terms are generated under the RG
ﬂow, even if not present at the onset.
We note that a similar system has been studied
in Cazalilla (2004). Here, we consider a larger
class of systems by including the interaction
term (22), which in turn requires us to include
the correlated vortex excitations (Eq. 24). These
terms give rise to additional phases as we will see
in the following.
Next we analyze our system within the RG
approach. This RG ﬂow is perturbative in the
vortex fugacities A1, As, and Aa and the tunneling
energy J⊥and therefore applies to the weak-
coupling limit (in particular J⊥! + 0). At second
order the ﬂow equations are given by Benfatto
et al. (2007):
542
Ultracold Atomic Gases: Novel States of Matter

dJ ⊥
dl ¼
2 
T
2pJ a


J ⊥,
ð25Þ
dAs
dl ¼
2  2p J s
T


As þ a3
A2
1 J a  J s
ð
Þ
2T 2
,
ð26Þ
dAa
dl ¼
2  2p J a
T


Aa þ a3
A2
1 J s  J a
ð
Þ
2T2
,
ð27Þ
dA1
dl ¼
2  p J s þ J a
ð
Þ
2T
þ a3 AsJ s þ AaJ a
T2


A1,
ð28Þ
dJ a
dl ¼ a2
J 2
⊥
4p4J a  4 A2
a
T4 J 3
a  A2
1
2T4 J s þ J a
ð
ÞJ 2
a


,
ð29Þ
dJ s
dl ¼ a2 2 A2
s
T4 J 2
s þ A2
1
4T 4 J s þ J a
ð
ÞJ s


2J s:
ð30Þ
The coefﬁcients α2/3 are non-universal parame-
ters that appear in the RG procedure (Kogut 1979),
and which do not affect the results qualitatively.
For consistency, we have to expand the right-hand
site of the above equations up to second order,
around the resulting Gaussian ﬁxed point : Js/a ¼
J  Jint + js/a. We emphasize again that Jint near the
ﬁxed point can be generated by RG and be nonzero
even if it is not present at the onset.
Before we consider the full RG ﬂow, we con-
sider the simpler case of no tunneling, i.e., we
solve the RG equations while setting J⊥¼ 0. In
Fig. 6 we show the phase diagram of two 2D SFs
coupled by S12, Eq. 22. Such a system would be
realized by a 2D mixture of bosonic atoms in two
different hyperﬁne states, interacting via some
short-range potential. The order parameters we
consider are Os(x) ¼ b1(x)b2(x) and Oa(x) ¼
b1
†(x)b2(x). To obtain the phase diagram, we con-
sider the correlation functions of each of these
order parameters, which can either scale algebra-
ically or exponentially. In Fig. 6 we refer to alge-
braic scaling of Os(x) as symmetric quasi-order
(SQ) and of Oa(x) as anti-symmetric quasi-order
(AQ). In each of the sectors, a KT transition marks
the transition from the algebraic to the exponential
regime, which occur either simultaneously and are
driven by single-vortex excitations or at different
temperatures and are driven by correlated vortex
pairs. As a result we ﬁnd four regimes: At temper-
atures above TKT, both sectors are disordered,
giving rise to a thermal Bose gas (TBG) phase.
For temperatures below TKT, and for a wide range
of Jint, we ﬁnd that both sectors are quasi-SF
(AQ/SQ), which is the only phase in which the
correlation function of the single boson operators
shows algebraic scaling. We also ﬁnd regimes in
which only one sector shows algebraic scaling,
whereas the other is disordered (AQ and SQ).
From the perspective of vortices, the TBG phase
is a gas of free single vortices in each layer,
whereas the AQ (SQ) phase is a gas of symmetric
(antisymmetric) vortex pairs.
We now consider the full RG system, including
J⊥. We numerically integrate the RG equations,
and ﬁnd the phase diagram shown in Fig. 7 in
terms of the temperature T and the interaction Jint.
We again ﬁnd four different phases that are differ-
ent combinations of LRO, QLRO, and disorder in
the symmetric and anti-symmetric sector. At high
temperatures we ﬁnd that both sectors are disor-
dered in a TBG phase, as before. For lower tem-
peratures and for a wide range of Jint, the system is
in a double-layer SF phase (DLSF): The symmet-
ric sector shows algebraic scaling, whereas the
exponent
of
the
anti-symmetric
sector
is
renormalized to zero, i.e., we ﬁnd two SFs that
are phase-locked due to J⊥. Note that the transi-
tion temperature Tc between DLSF and TBG has
been
noticeably
increased
relative
to
the
decoupled value TKT, as we will discuss further
later on. We also ﬁnd two additional phases,
which are partially (quasi-)SF and partially disor-
dered. One of them is the SQ phase, as before,
whereas the other one (ASF) now shows true LRO
in the antisymmetric sector due to J⊥, whereas the
symmetric sector remains disordered. We note
that the generic double-layer action that we dis-
cuss in this entry does not show a sliding phase
(Mukhopadhyay et al. 2001), for any nonzero J⊥.
Ultracold Atomic Gases: Novel States of Matter
543

Either S1 or Sa, which is generated by RG, drives
the anti-symmetric sector to a disordered state, or
S⊥creates true LRO in the ﬁeld fa.
We also use the RG ﬂow to ﬁnd the order of the
phase transitions in the weak-coupling limit that
the anti-symmetric sector undergoes, by determin-
ing the energy gap using a “poor man’s scaling”
argument: When the coupling amplitude J⊥(l*) is
of order unity, the corresponding gap is given by
the expression Δ  J⊥exp(l*). From the behavior
of Δ at the phase transition, we can read off whether
it is of ﬁrst or second order, as indicated in Fig. 7.
Given the nature of an effective theory, only
approximate statements can be made about how
the different regimes of the phase diagram relate
to the microscopic interactions. To create the ASF
or AQ phase, an attraction between the two atom
species is needed that is of order J, whereas to
create the SQ phase, a repulsion of that order
would be needed. To detect the different phases,
one could use the interference method used in
Hadzibabic et al. (2006) to distinguish the phase-
locked phases (DLSF and ASF), which would
show a well-deﬁned interference pattern, from
the
uncorrelated
phases.
Another
approach
would be time-of-ﬂight images: The DLSF
phase would display a quasi-condensate signa-
ture, whereas the other phases would appear dis-
ordered. However, at the transition from ASF or
SQ to TBG, the width of the distribution would
abruptly increase.
Kibble-Zurek Mechanism
In this section we discuss how the phase-locking
transition found in the previous section could be
used to realize the KZ mechanism. The deﬁning
property of this mechanism is the generation of
topological defects by ramping across a phase tran-
sition, coming from the disordered phase. The dis-
ordered phase that we propose to use is the TBG
phase of the decoupled 2D systems, that is, we
consider
the
experimental
setup
reported
in
Hadzibabic et al. (2006) for a temperature T above
the KT temperature TKT. The ordered phase we
consider is the DLSF phase, i.e., the phase-locked
phase of two coupled SFs. The ramping is achieved
by turning on the tunneling between the two layers,
which can be done by lowering the potential barrier
between them. For this procedure the critical tem-
perature Tc of the DLSF-TBG transition needs to be
above the KT temperature of the uncoupled sys-
tems. We now show that the RG ﬂow indeed pre-
dicts such a scenario. In the experiments in
Hadzibabic et al. (2006), the atoms in different
layers do not interact with each other. Therefore,
it can be expected that Jint is small, of order J⊥,
which motivates us to discuss the case Jint ¼ 0 here.
We note, however, that the desired scenario of an
increased critical temperature is found for a wide
range of Jint, as can be seen in Fig. 7. In Fig. 8a we
show how the critical temperature of the DLSF-
TBG transition behaves, predicted by the RG ﬂow,
for different values of A1. The critical temperature
shows a sizable increase, due to the phase-locking
transition. Due to the perturbative nature of the RG
scheme, the RG ﬂow underestimates the effects of
the term S 1 and predicts a ﬁnite jump of the critical
temperature when J⊥is turned on. However, to
lock the SFs together in the regime slightly above
TKT, J⊥needs to be at least of the order of the vortex
core energy, giving rise to a ﬁnite slope of Tc instead
of a jump. The energy gap of this transition is
shown in Fig. 8 from which we can see that the
transition is of ﬁrst order, in contrast to the second-
order transition described in Kibble (1976) and
Zurek (1985), which is advantageous because the
onset of order is instantaneous rather than continu-
ous. We note that the phase diagram was obtained
using the assumption that the bare parameters of the
model, in particular J, do not depend on tempera-
ture. This is true only if temperature is close to TKT.
Here we ﬁnd that the ratio Tc/TKT can be relatively
large. In fact Tc/TKTwill be always smaller than that
shown in Fig. 8a; however, qualitatively the behav-
ior of Tc/TKT as a function of J⊥should remain
intact. We point out that our results can be general-
ized to a system of N > 2 coupled SFs. One ﬁnds
that the SFs still show a strong tendency to phase
lock together. As a result the critical temperature
should approximately satisfy the equality πJ(Tc)
N ¼ 2Tc. Thus, as N increases Tc approaches the
mean-ﬁeld critical temperature at which the stiff-
ness J vanishes, and we recover the usual 3D result.
In ﬁnite size systems there is another constraint
on the minimum value of J⊥: We consider the free
energy of a single vortex in the antisymmetric
544
Ultracold Atomic Gases: Novel States of Matter

ﬁeld, fa  arctan(x/y). For the decoupled system
we get for the free energy (Kogut 1979): F 
2(πJ  2T)log L/α, where L is the system size.
The coupling term gives a free energy contribu-
tion F⊥ J⊥(L/α)2. In the thermodynamic limit,
L ! 1, this term diverges faster than the others,
which is consistent with our ﬁnding of LRO in the
antisymmetric sector. For a ﬁnite system, compar-
ing these terms gives the estimate J⊥ J log(L/α)/
(L/α)2, that is required for this order to develop.
With a system size L/α  102, that would require
J⊥ 103J, which, for the setup in Hadzibabic
et al. (2006), would be around 102s1.
As an estimate of the number of domains that
would be created, we follow the argument in Kib-
ble (1976): The coherence scale of the DLSF phase
is given by (J/Δ)1/2α, which is the scale of a Klein-
Gordon model with a kinetic energy scale J and a
“mass term” with a prefactor Δ/α2. The domain size
is then given by (J/Δ)α2 and the number of domains
by  (Δ/J)L2/α2. As we show in Fig. 8b for J⊥/J ≈
102, we ﬁnd Δ/J⊥ 101, and therefore, J/Δ 
103. With L/ α  102, we would get Ndom  101 
102, which would generate a similar number of
vortices. We estimate the vortex-antivortex imbal-
ance by considering the number of domains around
the periphery of the system, which scales as L/x. If
we imagine that the phase behaves like a random
walk, the total phase mismatch, corresponding to
the vortex-antivortex imbalance, will scale as
ﬃﬃﬃﬃﬃﬃﬃﬃ
L=x
p
 N1=4
dom , which, for L/α  102, is of the
order 100–101.
In summary, we propose the following proce-
dure: (i) Prepare two uncoupled SFs at a temper-
ature T slightly above TKT. (ii) Switch on the
tunneling between the two layers, which creates
a DLSF phase with a critical temperature Tc higher
than T. As a result, one should ﬁnd a number of
long-lived vortex-antivortex pairs in the antisym-
metric phase ﬁeld fa, which would be visible in an
interference measurement, at a temperature where
there would be none in thermal equilibrium.
In conclusion of the section, we studied the
phase-locking transition of 2D superﬂuids, within
an renormalization group approach. We ﬁnd that
this transition is accompanied by an increase of
the transition temperature. We suggest that this
effect can be used to probe the Kibble-Zurek
mechanism in cold atom systems by rapidly
changing the ratio T/Tc. When we include interac-
tions between the layers, we ﬁnd additional
phases, in which either the symmetric or the
anti-symmetric sector is disordered, and the
other sector stays superﬂuid or quasi-superﬂuid.
Bose-Fermi Mixtures in Two-
Dimensional Optical Lattices
In the spirit of engineering many-body systems
that are relevant in other ﬁelds, we now turn to
atomic mixtures that resemble qualitatively, i.e.,
in terms of degrees of freedom of the system,
electron-phonon systems. In two dimensions,
these systems are actively studied and prove to
be of considerable complexity. In order to study
their atomic counterparts, Bose-Fermi mixtures in
optical lattices, we use the powerful method of
functional renormalization group equations, with
which we can determine their phase diagrams in
the weak-coupling limit in a systematic fashion.
We ﬁnd a rich competition of phases for both the
square lattice and triangular lattice geometry that
we consider.
In this section we consider mixtures of one
bosonic type of atom and either two fermionic
types that are SU(2) symmetric or spinless fer-
mions. The Hamiltonian for a mixture on a square
lattice is given by
H ¼ tf
X
ij
h i, s
f †
i,sf j,s  tb
X
ij
h i
b†
i bj

X
i
mfnf,i þ mbnb,i
ð
Þ
þ
X
i
Uffnf,i,"nf,i,# þ U bb
2 nb,inb,i þ U bfnb,inf,i
h
i
,
ð31Þ
where fi,s
† ( fi,s) creates (annihilates) a fermion at
site i with pseudo-spin s (s ¼ ",#), bi
† (bi) creating
(annihilates) a boson at site i, nf,i ¼
X
s
f †
i,sf i,s (nb,i
¼ bi
†bi) is the fermion (boson) number operator, tf
and tb are the fermionic and bosonic tunneling
Ultracold Atomic Gases: Novel States of Matter
545

energies between neighboring sites, mf (mb) is the
chemical potential for fermions (bosons), Ubb is
the repulsion energy between bosons on the same
site, Uff is the repulsion energy between the two
species of fermions, and Ubf is the repulsion
energy between bosons and fermions. The two
fermion species have been treated as a pseudo-
spin-1/2 index (" and #). The case of spinless
fermions can be immediately obtained from
Eq. 31 by ignoring one of the spin states. In
momentum space, the Hamiltonian Eq. 31 is writ-
ten as
H ¼
X
k
ϵf,k  mf
ð
Þ
X
s
f †
k,sf k,s þ ϵb,k  mb
ð
Þb†
kbk þ U ff
V rf,k,"rf,k,# þ U bb
2V rb,krb,k þ Ubf
V rb,krf,k
(
)
,
ð32Þ
where rf,k ¼
X
q, s
f †
kþq,sf k,s (rb,k ¼
X
q
b†
kþqbk) is
the fermion (boson) density operator and ϵb/f,k ¼
2tb/f (cos kx + cos ky) is the bosonic/fermionic
dispersion relation.
We consider the limit of weakly interacting
bosons that form a BEC (Mathey et al. 2006;
Wang et al. 2005), where we assume that the
zero momentum bosonic mode is macroscopically
occupied, and the corresponding operator b0 can
be formally replaced by a real number b0 !
ﬃﬃﬃﬃﬃﬃ
N0
p
,
where N0 is the number of condensed atoms. After
this replacement we keep all terms that are qua-
dratic in bk (with k 6¼ 0) and perform a
Bogoliubov transformation, given by bk ¼ ukβk
+ ukβk
† , to diagonalize the bosonic Hamiltonian.
The resulting eigenmodes βk have a dispersion
relation given by ok ¼
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
ϵb,k ϵb,k þ 2U bbnb
ð
Þ
p
,
with
the
low-k
limit
ok

ub|k|,
with
ub ¼
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
2tbU bbnb
p
. The parameters uk and vk are
given by uk
2 ¼ (ok + ϵb,k + Ubbnb)/(2ok) and nk
2
¼(ok + ϵb,k + Ubbnb)/(2ok).
The density ﬂuctuations of the bosons are
approximated by rb,k 
ﬃﬃﬃﬃﬃﬃ
N0
p
uk þ uk
ð
Þ bk þ b†
k


,
with k 6¼ 0. The interaction between bosons and
fermions is then given by U bf
ﬃﬃﬃﬃﬃﬃ
N 0
p
=V
X
k
uk þ uk
ð
Þ
bk þ b†
k


rf,k . As a next step we integrate
out the bosonic modes and use an instantaneous
approximation, leading to the following effective
Hamiltonian:
Heff: ¼
X
k

ϵk  mf
ð
Þ
X
s
f †
k,sf k,s
þ U ff
V rf,k,"rf,k,#
þ 1
2V V ind:,krf,k,rf,k

,
ð33Þ
where the induced potential Vind.,k is given by
V ind:,k ¼ eV= 1 þ x2 4  2 cos kx  2 cos ky




,
ð34Þ
with eV
given by eV ¼ U 2
bf=U bb , and x is the
healing length of the BEC and is given by
x ¼
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
tb=2nbU bb
p
. This approach is only valid
when ub  uf, so that the fermion-fermion inter-
action mediated by the bosons can be considered
as instantaneous. Away from this limit, retardation
effects are present. In this case, one has to con-
sider the frequency dependence of the interaction
explicitly (Klironomos and Tsai 2007; Tsai et al.
2005a, b). The full effective interaction, including
retardation, is given by
V ind: o,k
ð
Þ ¼ 
eV
1þx2 42coskx 2cosky


"
#
o2
k
o2 þo2
k
,
ð35Þ
and the static limit (34) is recovered when ok 
o. Equation 33 describes the scattering of two
fermions from momenta k1 and k2 that are
546
Ultracold Atomic Gases: Novel States of Matter

scattered into momenta k3 and k4. Momentum
conservation at the interaction vertex requires
that k4 ¼ k1 + k2  k3, and hence, the interaction
vertex, U(k1, k2, k3), depends on three momenta.
Its bare value from Eq. 33 can be written as
U k1, k2, k3
ð
Þ ¼ U ff þ V ind:,k1k3:
ð36Þ
For the case with retardation, there is depen-
dence on both the momenta and frequencies of the
electrons, so we have U(k1, k2, k3), with k4 ¼ k1 +
k2  k3, where ki ¼ (o, k).
Starting from non-interacting fermions, we ask
the general question of what new many-body
phases can emerge when the system is subjected
to a given interaction U(k1, k2, k3). Our approach
to address this question is the renormalization-
group method, described in the next section.
Renormalization Group Method
Starting with a microscopic model of interacting
electrons on a lattice, the renormalization-group
(RG) method provides the effective model at a
given temperature or energy scale (Shankar
1994). The RG is implemented by systematically
tracing out high-energy degrees of freedom in a
region between Λ and Λ + dΛ, where Λ is the
energy cutoff of the problem. In this process, the
vertex U is renormalized. At the initial value of the
cutoff Λ ¼ Λ0, the value of U is given by its bare
value. For the BFM system we describe here, it is
given by Eq. 36. At one loop, the RG ﬂow is
obtained from a series of coupled integral-
differential equations (Zanchi and Schulz 2000)
for all the different interaction vertices U(k1, k2,
k3). The RG equations read as follows:
@‘U‘ k1, k2, k3
ð
Þ ¼ 
ð
p,o
@‘ Gp‘Gk‘


U ‘ k1, k2, k
ð
ÞU‘ p, k, k3
ð
Þ

ð
p,o
@‘ Gp‘Gq1‘


U ‘ p, k2, q1
ð
ÞU ‘ k1, q1, k3
ð
Þ 
ð
p,o
@‘ Gp‘Gq2‘


 f2U‘ k1, p, q2
ð
ÞU ‘ q2, k2, k3
ð
Þ þ U‘ p, k1, q2
ð
ÞU ‘ q2, k2, k3
ð
Þ
þ U‘ k1, p, q2
ð
ÞU ‘ k2, q2, k3
ð
Þg
ð37Þ
where ‘ ¼ ln(Λ0/Λ), k ¼ k1 + k2  p, q1 ¼ p +
k2  k3, q2 ¼ p + k1  k3, and Gk‘ ¼  (|xk| 
Λ)/(io  xk) with xk ¼ ϵf,k  mf and k ¼ (o, k).
From the general interaction vertices U(k1, k2,
k3), the speciﬁc interaction channels, such as
charge-density wave (CDW), antiferromagnetic
(AF), and superconducting (BCS), can be obtained:
V CDW ¼ 4U c k1, k2, k1 þ Q
ð
Þ,
ð38Þ
V AF ¼ 4Us k1, k2, k1 þ Q
ð
Þ,
ð39Þ
V BCS ¼ U k1,  k1, k2
ð
Þ,
ð40Þ
where
we
have
used
the
notation
U c ¼
2  bX


U=4,
U s ¼ bXU=4 with bXU k1, k2, k3
ð
Þ
¼ U k2, k1, k3
ð
Þ , and Q is the nesting vector,
Q ¼ (π, π).
In
a
numerical
implementation,
one
discretizes the Fermi surface into M patches,
and hence, each of the interaction channels
(Eqs. 38, 39, and 40) is represented by an M 
M matrix. At each RG step, we diagonalize each
of these matrices. The channel with the largest
eigenvalue (with the caveat that a BCS channel
needs to be attractive to drive a transition) corre-
sponds to the dominant order. The elements of
the eigenvector are labeled by the discrete patch
indices around the Fermi surface, and the sym-
metry of the order parameter is given by this
angular dependence.
The RG method for interacting fermions has
been extended to also include retardation effects,
as for the case of interacting electrons which are
also coupled to phonons in a crystal (Tsai et al.
2005a, b). In this case (i) the interaction vertices
Ultracold Atomic Gases: Novel States of Matter
547

also depend on frequencies of the incoming and
outgoing fermions, so the RG equations are writ-
ten for given external frequencies and the integral
over intermediate frequencies cannot be done ana-
lytically, and (ii) there are important self-energy
corrections (in particular the imaginary part of the
self-energy is nonzero). Eliashberg equations for
strong-coupling
superconductivity
has
been
derived with this method (Tsai et al. 2005a, b)
for the case of electrons, with a circular Fermi
surface, coupled to phonons. This method has
also been applied to other electron-phonon prob-
lems (Klironomos and Tsai 2006; Tam et al. 2007)
and to mixtures of cold atoms in an optical lattice
(Klironomos and Tsai 2007).
Phase Diagram and Subdominant Orders
The microscopic parameters in the Hamiltonian
Eq. 31 determine the initial conditions for the RG
ﬂow and the shape of the Fermi surface. With
these, we write the RG ﬂow equations and solve
them numerically. We ﬁrst discuss the case with-
out retardation. For some parameters, we encoun-
ter a divergence in the RG ﬂow, indicating the
onset of ordering with a gap that is in the detect-
able regime, i.e., larger than 103tf. In other
regimes, where such a divergence is not reached,
one can read off the dominant tendency of the RG
ﬂow. In Fig. 9 we show examples of RG ﬂows as a
function of ‘. In Fig. 9a, we show the competition
between d-wave and s-wave pairing, with d-wave
being dominant and s-wave being subdominant.
In Fig. 9b we show an example with dominant
d-wave channel and subdominant AF channel. In
both cases we ﬁnd that for short distances (or high
energies) CDW ﬂuctuations are dominant, giving
rise to a state that resembles the ﬁndings for high-
Tc
superconductors
(Hanaguri
et
al.
2004;
Hoffman et al. 2002; Vershinin et al. 2004). In
some situations the many-body states are almost
degenerate, and small changes in the initial con-
ditions (i.e., changes in the form of the interac-
tions) can be used to select one particular ground
state.
With this procedure we determine the phase
diagram of the system, which is shown in
Fig. 10. We now discuss the general features of
the phase diagram. In the absence of any coupling
to the bosons, i.e., for eV ¼ 0, the system shows
s-wave
pairing
for
attractive
interaction,
Uff < 0, and no ordering for Uff > 0, i.e., Fermi
liquid behavior, except for the special case of half-
ﬁlling where Fermi surface nesting drives the
system to AF order for repulsive interactions and
to s-wave pairing (degenerate with CDW) for
attractive interaction. If we now turn on the inter-
action to the bosons, this picture is modiﬁed in the
following way: The boundary of the s-wave
regime is moved into the regime of positive Uff,
approximately to a value of Uff where the effective
interaction at the nesting vector Q between the
fermions, Uff + Vind.,Q, is positive, i.e., for
Ultracold Atomic Gases: Novel States of Matter,
Fig. 9 RG ﬂow for the different effective interactions
(in units of tf) as a function of the RG parameter
l (eV=tf ¼ 3 and x ¼ 1). (a) Uff/tF ¼ 0.5; (b) Uff/tf ¼ 1.2
Ultracold Atomic Gases: Novel States of Matter,
Fig. 10 Phase diagram, interaction strength, Uff/tf, versus
number of fermions per site, n, for a Fermi-Bose mixture in
a square lattice in 2D (eV=tf ¼ 2, x ¼ 1)
548
Ultracold Atomic Gases: Novel States of Matter

U ff 
 eV= 1 þ 8x2


. On the repulsive side, and
away from half-ﬁlling, we ﬁnd the tendency to
form a paired state, either d-wave or p-wave. This
tendency becomes weaker the further the system
is away from half-ﬁlling. We typically ﬁnd a gap
in the vicinity of half-ﬁlling, and further away
from m ¼ 0, we ﬁnd only an increasing strength
of the corresponding interaction channel. For the
half-ﬁlled system, we ﬁnd that for attractive inter-
actions the degeneracy between s-wave pairing
and CDW ordering is lifted, with s-wave pairing
being the remaining type of order. For repulsive
interactions, we ﬁnd an intermediate regime of
d-wave pairing, and for larger values of Uff, we
obtain AF order.
The RG approach also allows the extraction of
the many-body gaps in the system through a “poor
man’s scaling” analysis of the divergent ﬂow: At
the point where the coupling becomes of order of
tf, the scaling parameter ‘ reaches the maximum
value ‘c ¼ ln(tf/Δ), where Δ is the value of the gap.
Hence, Δ/tf ≈exp{‘c} can be obtained from the
RG ﬂows such as the ones in Fig. 9. In Fig. 11 we
show the gaps of the problem as a function of
Uff/tf in the half-ﬁlled case. One can see that as
Uff increases, from negative to positive values, the
s-wave gap is replaced by a d-wave gap and
ﬁnally for an antiferromagnetic gap. As is appar-
ent from this ﬁgure, the gap in the d-wave phase is
much smaller than the gaps of the AF order and
the s-wave pairing and, furthermore, almost inde-
pendent of the value of Uff. The latter is the case
because the Uff term is a pure s-wave contribution
to the interaction and therefore does not contribute
to the d-wave channel. The d-wave channel has an
initial contribution which is entirely due to the
anisotropy of the induced interaction, which
gives only a small value and as a consequence
only a small value for the gap. The value of the
gap (in units of tf) can be numerically ﬁtted with a
BCS expression of the form a exp b=eV


, with
the parameters a and b given by a ¼ 0.31 and b ¼
14.2.
For a system of spinless fermions, one can
simply suppress one of the spin indices in
Eqs. 31 and 32. In this case there is a major
simpliﬁcation in the problem since Uff is absent:
In a spinless problem there can be only one fer-
mion per site, as per Pauli’s principle. Hence, in
the absence of bosons, the spinless gas is non-
interacting. The bosons, however, mediate the
interaction between the fermions. Since the fer-
mions are in different lattice sites, the pair
wavefunction has necessarily a node, and hence,
no s-wave pairing is allowed. In other words, in
the
spinless
case
the
antisymmetry
of
the
wavefunction requires pairing in an odd angular
momentum channel. In fact, we ﬁnd that through-
out the entire phase diagram, the fermions develop
p-wave pairing. At half-ﬁlling we ﬁnd a similar
behavior of CDW ﬂuctuations on short scales,
analogous to the ﬂow shown in Fig. 9. One should
point out that in real solids the conditions of
“spinlessness” behavior is hard to achieve since
it usually requires complete polarization of the
electron gas, that is, magnetic energies of the
order of the Fermi energy (a situation experimen-
tally difﬁcult to achieve in good metals). How-
ever, in cold atom lattices this situation can be
easily accomplished with the correct choice of
atoms.
Finally, when retardation is important, the
numerical task of solving the RG ﬂow equations
becomes much more demanding. In addition to
the discretization of the Fermi surface, one has to
also discretize the frequency (for T ¼ 0) or
Ultracold Atomic Gases: Novel States of Matter,
Fig. 11 Many-body energy gaps at half-ﬁlling (m ¼ 0),
as a function of Uff/tf, for eV=tf ¼ 3 and at a ﬁxed value of
the coherence length x ¼ 1. Dashed line, s-wave gap;
continuous line, d-wave gap; dotted-dashed line, antiferro-
magnetic gap. The inset shows a magniﬁed plot of the
d-wave regime
Ultracold Atomic Gases: Novel States of Matter
549

consider a certain number of Matsubara frequen-
cies (T 6¼ 0). This has been done for this Bose-
Fermi system only for a ﬁxed density of fermions
corresponding to one half (Klironomos and Tsai
2007). In this case the Fermi surface has a dia-
mond shape, and scattering processes are domi-
nated by the van Hove points (corners of the
diamond) where the density of states is singular.
The Fermi surface can therefore be approximated
by the van Hove points only (Schulz 1987) so that
the types of relevant processes are reduced, as
shown in Fig. 12. Each of the processes still
depend on frequencies: gi(o1,o2,o3), for i ¼
1,2,3,4. The phase diagram is shown in Fig. 13.
Retardation leads to additional phases at half-
ﬁlling and by tuning the lattice parameters, the
system undergoes AF (or spin-density-wave
SDW), d-wave SC pairing, s-wave-pairing, and
CDW. In the limit of ub  uf discussed previously,
when retardation is not important, CDW does not
become dominant (Fig. 10). It is at most degener-
ate with s-wave pairing for Uff < 0. As the bosons
become slower, there is stronger tendency for
CDW formation (Fig. 13).
Quantum Frustration in Triangular Lattices
It is known that the geometric shape of the lattice
is a crucial factor in determining the properties of
interacting many-body systems. For instance,
localized spins interacting antiferromagnetically
on a triangular lattice suffer from the phenomenon
of frustration, when antiferromagnetic order can-
not be achieved because of the particular lattice
Ultracold Atomic Gases: Novel States of Matter,
Fig.
12 Relevant
processes
in
the
two-patch
approximation
Ultracold Atomic Gases:
Novel States of Matter,
Fig. 13 Phase diagram for
Uff ¼ 0.4tf, Ubb ¼ 0.8tf, and
nb ¼ 2.5. Blue circles
indicate s-wave SC, red
rhombuses d-wave SC,
magenta squares AF (also
called spin-density-wave
SDW), and green stars
CDW type of ordering.
Dashed lines are guides to
the eye
550
Ultracold Atomic Gases: Novel States of Matter

structure. For itinerant fermionic systems, the lat-
tice structure, together with the dispersion relation
and the ﬁlling fraction, determines the shape of the
Fermi surface. The Fermi surface, by its turn, is a
crucial factor in determining what type of orders
the system can develop. Indeed, for the triangular
lattice we consider in this section, which shows a
rich and subtle competition between super-
conducting phases with different symmetries,
small changes in the shape of the FS determine
which pairing symmetry is dominant. This is a
reﬂection of the “lattice frustration” on the super-
conducting phases. In solids, this intriguing lattice
geometry
is
realized
in
materials
such
as
cobaltates (Takada et al. 2003), transition metal
dichalcogenides (Withers and Wilson 1986), and
k-(ET)2X layered organic crystals (Jérome 1991)
(if each lattice site is represented by one ET dimer
(Kino and Fukuyama 1995)) and has been the
subject of several theoretical studies (Baskaran
2003; Choy et al. 2007; Gan et al. 2006;
Honerkamp 2003; Lee and Lee 2005; Tsai and
Marston 2001; Vojta and Dagotto 1999; Zhou
and Wang 2006).
In this section we consider a BFM on a trian-
gular lattice. The geometry of the lattice under
consideration here is shown in Fig. 15a. This
system is described by a similar Hubbard
model as for the square lattice. But now, besides
the triangular geometry, we allow for two differ-
ent values for the hopping amplitudes, for two
types of lattice bonds, as indicated in Fig. 15a by
dashed and continuous lines. tf,a and tb,a with a ¼
1,2 are the fermionic and bosonic tunneling
amplitudes between neighboring sites, where
the index a ¼ 1 (a ¼ 2) refers to the continuous
(dashed) bonds. For the description of the
isotropic case, we equate tb/f,1 and tb/f,2 and
deﬁne tf  tf,1 ¼ tf,2 and tb  tb,1 ¼ tb,2. mf(mb)
is the chemical potential for fermions (bosons);
Ubb, Uff, and Ubf are the on-site boson-boson,
fermion-fermion, and boson-fermion repulsion
energy, respectively.
Just as for the case of a square lattice, we
consider the limit of weakly interacting bosons,
in which the bosons form a BEC, for which
we use the same description. The resulting
dispersion
relation
is
now
given
by
ok ¼
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
ϵb,k  ϵb,0
ð
Þ ϵb,k  ϵb,0 þ 2U bbnb
ð
Þ
p
, where
the bare lattice dispersion is given by
ϵb,k ¼  tb,12 cos kx
 tb,2

2 cos

kx=2 þ
ﬃﬃﬃ
3
p
ky=2

þ 2 cos

kx=2 
ﬃﬃﬃ
3
p
ky=2

:
(41)
For small values of kx and ky, ok can be expanded
as ok
~
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
2tb,1 þ tb,2
ð
Þk2
x þ 3tb,2k2
y


U bbnb
r
, which
gives us the two velocities vb,x ¼
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
2tb,1 þ tb,2
ð
ÞUbbnb
p
and vb,y ¼
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
3tb,2Ubbnb
p
s.
We again assume that these velocities of the
condensate ﬂuctuations are much larger than the
Fermi velocity, which corresponds to the conditions
vb,x/y > tf,1/2. Therefore, large bosonic hopping
amplitudes, a bosonic density of ≈1  3, and some
intermediate value for tf,1/ 2 will satisfy this require-
ment. As before, the bosonic modes can be inte-
grated out, and we obtain an approximately
non-retarded
fermion-fermion
interaction.
The
induced
potential
Vind.,k
is
given
by
V ind:,k ¼ eV= 1 þ x2
1 2
ð

2 cos kxÞ þ x2
2 4
ð
4 cos kx=2
ð
Þ cos
ﬃﬃﬃ
3
p
ky=2


ÞÞ with eV ¼ U 2
bf=U bb,
and xa are the healing lengths of the Bose-Einstein
condensate
(BEC)
and
are
given
by
xa ¼
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
tb=2nbU bb
p
with a ¼ 1,2. We again arrive
at a purely fermionic, non-retarded description of the
same form as before. This is the effective model that
we study with a numerical implementation of the
functional renormalization group. For the isotropic
case, perfect nesting occurs at three fourth ﬁlling,
with three possible nesting vectors, Q1 ¼ (0, 2π),
Q2 ¼ p,
ﬃﬃﬃ
3
p
p


, and Q3 ¼ p,
ﬃﬃﬃ
3
p
p


, leading to
three different possible types of instabilities per den-
sity wave channel. For the anisotropic case, only Q1
can be a nesting vector, for the condition mf ¼ 2tf,1.
To determine the scale of the gaps, Δ, associated
with each of these order parameters, we again use a
“poor
man’s”
scaling
estimate,
speciﬁcally
D 
 L0e‘c, where ‘c is the point at which the RG
ﬂow diverges and the instability occurs.
The RG is implemented numerically by
discretizing the FS into M patches. For the results
shown in this section, M ¼ 24 or 36 was used. The
CDW, AF, and BCS channels are diagonalized at
Ultracold Atomic Gases: Novel States of Matter
551

each RG step. The dominant instability is the
channel that has an eigenvalue (divided by the
dimension of the matrix) with the largest magni-
tude (for BCS one has to ensure that such eigen-
value is negative so that the channel is attractive).
Each element of the corresponding eigenvector
represents a given FS patch, and hence, the sym-
metry of the dominant order parameter is reﬂected
on the patch (i.e., angular) dependence of each
element around the FS. Using this method, we
determine the phase diagram of the system in
various limits.
We ﬁrst consider spin-1/2 fermions on an iso-
tropic triangular lattice, i.e., with tf,1 ¼ tf,2  tf.
The FS for such a lattice behaves as follows: For
small ﬁlling the FS consists of one near-circular
piece, which then approaches the shape of a hexa-
gon as mf approaches the special value mf ¼ 2tf. At
this special chemical potential, which corresponds
to three fourth ﬁlling, the FS is nested with the
three distinct nesting vectors Qi. For ﬁlling frac-
tions larger than three fourth, the FS breaks into
six disjoined arcs. Examples for these different
regimes are shown in Fig. 14a. Without coupling
to the BEC, the fermions form an s-wave pairing
phase for attractive interactions, and a Fermi liq-
uid phase for repulsive interactions (ignoring high
angular momentum pairing phases predicted by
the Kohn-Luttinger theorem (Kohn and Luttinger
1965) which would occur at energy scales much
lower than the experimentally accessible regime),
except for the speciﬁc case mf ¼ 2tf, where the
system shows AF order for repulsive interactions.
A schematic picture of this order is shown in
Fig. 15b for the nesting vector Q1. This behavior
is similar to the one found for isotropic square
lattice in the previous section (Mathey et al.
2006): s-wave pairing for attractive interaction
Ultracold Atomic Gases: Novel States of Matter,
Fig. 14 (a) Fermi surfaces for an isotropic lattice, for
mf < 2tf,1=2 ,
mf ¼ 2tf,1=2
(hexagonal
shape),
and
mf > 2tf,1/2 (six disjoint arcs). (b) Diagram of the different
types of Fermi surfaces that can be created on an aniso-
tropic lattice, by varying the ratio tf,2/tf,1 and mf. (c) Fermi
surfaces for tf,2 < tf,1, for mf < 4tf,2  2tf,1, 4tf,2 
2tf,1 < mf < 2tf,1, and mf > 2tf,1, corresponding to the
regimes
I–III,
respectively.
(d)
Fermi
surfaces
for
tf,2 > tf,1, for mf < 2tf,1, 2tf,1 < mf < 4tf,2  2tf,1, and
mf > 4tf,2  2tf,1, corresponding to the regimes IV–VI,
respectively
552
Ultracold Atomic Gases: Novel States of Matter

Ultracold Atomic Gases: Novel States of Matter,
Fig. 15 (a) Lattice geometry of the system. The
continuous (dashed) bonds correspond to the hopping
amplitudes tb/f,1(2). For tb=f,1 ¼ tb=f,2 , the lattice is an
Ultracold Atomic Gases: Novel States of Matter
553

and Fermi liquid behavior for repulsive interac-
tion, except at a special ﬁlling, for which we ﬁnd
AF order due to nesting. An interesting difference
for the triangular lattice is the threefold degener-
acy of the AF phase, an indication of frustration.
When the coupling to the BEC is turned on, the
isotropic triangular lattice shows a phase diagram
of the type shown in Fig. 8. The s-wave pairing
phase slightly extends into the regime of positive
Uff, because of the induced attractive interaction
mediated by the bosonic ﬂuctuations. The regime
that showed Fermi liquid behavior in the absence
of the induced interaction now shows a rich com-
petition of various types of pairing. In the regime
where the density is below half-ﬁlling, when the
FS is approximately circular, the system shows
p-wave pairing. For ﬁllings larger than three
fourth, when the FS consists of six disjoined
parts, the fermions Cooper pair in a super-
conducting state with f symmetry. As shown in
Fig. 15e, the FS in this regime can also be
interpreted as two distinct near-circular Fermi sur-
faces of holes. In this interpretation each of these
two fermionic systems is in an s-wave pairing
phase, but the relative phase between the two
order parameters is π. At three fourth ﬁlling and
large values of Uff, the system still shows AF
order. However, for smaller values of Uff and
also for smaller ﬁllings, two phases with degener-
ate extended d symmetry develop. These super-
conducting
orders
have
a
sizable
g-wave
component and are approximately given by
cD1 ¼ sin 2y þ 0:5 sin 4y,
ð42Þ
cD2 ¼ cos 2y  0:5 cos 4y:
ð43Þ
These order parameters are shown in Fig. 15c, d.
The shapes of the order parameters are energeti-
cally advantageous because, on the one hand, the
order parameter maxima are located at points at
which the system has a high density of states (the
“corners” of the FS). Hence, when the super-
conducting gap opens, there is a large gain of
condensation energy coming from these regions
on the FS. On the other hand, the d-wave state
has lower kinetic energy than the f-wave and
hence is selected.
The phase diagram Fig. 8 has a number of
similarities to the phase diagram for a BFM on a
square lattice, such as the s- and the p-wave
pairing phases and the existence of AF order for
a nested Fermi surface for large Uff.
However, the competition of pairing orders for
positive Uff and intermediate and large ﬁlling is
much richer, due to the more complex shape of the
Fermi surface.
The energy gaps associated with these order
parameters can be determined as we did in the
previous section (Mathey et al. 2006), by using a
“poor man’s” scaling argument. We ﬁnd for the
s-wave pairing and the AF order that they are
around 0.1TF, where TF is the Fermi temperature
of the system. For most of the exotic phases, we
energy gaps of the order of 0.01  0.001TF.
We now consider a BFM with spin-1/2 fermions
on an anisotropic triangular lattice, i.e., with
unequal hopping amplitudes, tf(b),1 6¼ tf(b),2. The
shape of the FS behaves as follows: For tf,2 > tf,1,
as one increases the chemical potential, the FS ﬁrst
breaks into four arcs at mf ¼ 2tf,1 and then breaks
into six arcs at mf ¼ 4tf,2  2tf,1, corresponding to
the regimes IV–VI, in Fig. 14b, d. For tf,2 < tf,1 the
FS ﬁrst breaks into two arcs at mf ¼ 4tf,2  2tf,1 and
then breaks into six arcs at mf ¼ 2tf,1 corresponding
to the regimes I–III, in Fig. 14b, c. At the special
chemical potential mf ¼ 2tf,1, the FS is still nested,
but there is only one nesting vector along the
direction of the bonds with hopping amplitude
tf,1. In the absence of the coupling to the BEC, the
phase diagram has a similar structure as for the
isotropic
case:
s-wave
pairing
for
attractive

Ultracold Atomic Gases: Novel States of Matter,
Fig. 15 (continued) isotropic triangular lattice. (b) Sche-
matic representation of the AF order corresponding to
nesting vector Q1. (c, d) Order parameters of the extended
d-wave orders D1 and D2. (e) Order parameter of the
f-wave phase. This order can also be interpreted as two
s-wave paired hole states whose order parameters are out of
phase by π. (f) Order parameter of the extended p-wave
phase that appears in anisotropic lattices
554
Ultracold Atomic Gases: Novel States of Matter

interaction and Fermi liquid behavior for repulsive
interaction, with the exception of the nested FS at
mf ¼ 2tf,1 where one ﬁnds AF order (notice that in
this case the ﬁlling is not three fourth).
When the coupling to the bosons is turned on,
one generates an even more complicated compe-
tition of pairing phases for repulsive Uff in the
vicinity of the point mf ¼ 2tf,1, as is shown in
Fig. 17. Generally, for unequal hopping the
degeneracy between D1 and D2 in Eq. 43 as well
as px and py is lifted: In the regime with tf,2 >
tf,1(tf,2 < tf,1), D1(D2) and px ( py) dominate. For
tf,2 > tf,1, in the intermediate regime, in which the
FS consists of four disjoined arcs, corresponding
to the regime V in Fig. 14, the type of ordering
changes from D1 to f. For tf,2 < tf,1, the type of
pairing also eventually becomes f-wave but ﬁrst
develops two other types of pairing, in regime II in
Fig. 14. Firstly, one ﬁnds an unusual extended
p-wave symmetry, which is schematically shown
in Fig. 15f. Its wavefunction is of the form
cPext ¼
sin 2y
p=2 < y < p=2
 sin 2y
p=2 < y < 3p=2:
(
ð44Þ
The second type of pairing that appears before
the system develops f-wave pairing is D1. These
unusual pairing states are energetically favorable
because of the anisotropic shape of the FS. For the
regime in which the FS has just barely broken up
into two arcs, the order parameter assumes p-wave
symmetry and the maxima are located along the
y-axis, where the density of states is highest. As
the region of open FS widens (see Fig. 15f), this
pairing becomes energetically unfavorable, and
the system develops D1-pairing, so that the max-
ima of the order parameter can again be located
near the point of highest density of states. The
energy gaps associated with these order parame-
ters are of the same order of magnitude as for the
isotropic lattice.
Finally, we consider a BFM with spinless fer-
mions on an isotropic lattice. Due to the absence
of s-wave scattering between fermions of the same
spin state, there is no direct interaction, that is,
Uff ¼ 0. Hence, in the absence of bosons, the
spinless gas is non-interacting. The boson ﬂuctu-
ations, however, mediate an induced interaction
between the fermions. Due to the antisymmetry of
the Cooper pair wavefunction, pairing occurs in
an odd angular momentum channel. We ﬁnd a
competition between p- and f-wave pairing sym-
metries. For small to intermediate ﬁlling (n <
0.65), p-wave pairing dominates. For larger ﬁll-
ings, for which the FS ﬁrst approaches the shape
of a hexagon and then breaks up into six arcs, the
system shows f-wave pairing. Since these larger
p−BCS
d−BCS
s−AF
f−BCS
s−BCS
1/2
3/4
Uff/tf
n
−1
1
Ultracold Atomic Gases: Novel States of Matter,
Fig. 16 Phase diagram of a Bose-Fermi mixture on a 2D
isotropic triangular lattice. The vertical axis corresponds to
the interaction strength, Uff/tf, whereas the horizontal axis
corresponds to the ﬁlling fraction of the fermions per site,
n. The other parameters are given by eV=tf ¼ 3 and xa ¼
1 with a ¼ 1, 2
Px−BCS
Py−BCS
Pext−BCS
1.2
2
tf,2/tf,1
μf,2/tf,1
0.8
D2−BCS
D1−BCS
D1−BCS
f−BCS
f−BCS
Ultracold Atomic Gases: Novel States of Matter,
Fig. 17 Phase diagram of a Bose-Fermi mixture on an
anisotropic triangular lattice. The vertical axis corresponds
to the ratio tf,2/tf,1; the horizontal axis corresponds to the
chemical potential mf. The other parameters are given by
eV=tf ¼ 3, U ff=tf,1 ¼ 2, and xa ¼ 1 with a ¼ 1,2)
Ultracold Atomic Gases: Novel States of Matter
555

ﬁllings of fermions are typically realized in the
center of an atomic trap, this result would suggest
a comparatively easy way to create an exotic
pairing state experimentally. In contrast to this, a
spinless BFM on a square lattice only shows
p-wave pairing, since for the quadrangular shape
of its FS, channels of higher angular momentum
are of no advantage energetically.
The many-body states discussed in this section
can be observed through various methods: AF
order could be revealed in time-of-ﬂight images
and Bragg scattering (Stenger et al. 1999), noise
correlations (Altman et al. 2004; Fölling et al.
2005; Greiner et al. 2005; Mathey et al. 2008a)
can be used to detect the various pairing phases,
and laser stirring experiments (Onofrio et al.
1999; Raman et al. 1999) can be used to detect
the phase boundary between AF order and
pairing. The short-scale CDW ﬂuctuations should
give a signature in a photo-association measure-
ment. RF spectroscopy (Chin et al. 2004) can be
used to quantify the gaps of the various phases.
Conclusions
In this entry we studied the phase diagrams of
various low-dimensional ultracold atom systems.
In section “One-Dimensional Lattices,” we stud-
ied atomic mixtures in one dimension, using
Luttinger liquid theory. We argued that a Bose-
Fermi mixture can be naturally looked at as a
Luttinger liquid of polarons, and we discussed
the rich phase diagrams of commensurate mix-
tures. In section “Phase-Locking Transition of
Coupled
Low-Dimensional
Superﬂuids,”
we
studied
the
phases
of
two
coupled
two-
dimensional superﬂuids at ﬁnite temperature. We
found that the critical temperature of the phase-
locked phase is signiﬁcantly increased over its
bare value, which we propose to use for realizing
the Kibble-Zurek mechanism. When interactions
between the two superﬂuids are present, we ﬁnd
additional phases which are partially superﬂuid
and partially disordered. In section “Bose-Fermi
Mixtures in Two-Dimensional Optical Lattices,”
we used the powerful method of functional
renormalization group equations to determine
the phases of Bose-Fermi mixtures in two-
dimensional optical lattices. We found an intricate
competition of orders, including new types of
exotic pairing for triangular lattices. In all these
sections, ideas how to probe our predictions were
also given.
Bibliography
Primary Literature
Albus AP et al (2003) Phys Rev A67:063606
Alexandrov AS, Mott SN (1995) Polarons and bipolarons.
World Scientiﬁc, Singapore
Altman E, Demler E, Lukin M (2004) Probing many-body
states of ultracold atoms via noise correlations. Phys
Rev A 70:013603
Anderson MH, Ensher JR, Matthews MR, Wieman CE,
Cornell EA (1995) Observation of Bose-Einstein con-
densation in a dilute atomic vapor below 200 nano-
kelvin. Science 269:198
Baskaran G (2003) Electronic model for CoO2 layer based
systems: chiral resonating valence bond metal and
superconductivity. Phys Rev Lett 91:097003
Benfatto L et al (2007) Kosterlitz-Thouless behavior in
layered superconductors: the role of the vortex-core
energy. arXiv:cond-mat/0609287
Bijlsma MJ et al (2000) Phys Rev A 61:053601
Cazalilla MA (2004) Phys J B 37:1–47
Cazalilla MA, Ho AF (2003) Phys Rev Lett 91:150403
Cazalilla MA, Ho AF, Giamarchi T (2005) Phys Rev Lett
95:226402
Chaikin PM, Lubensky TC (1995) Principles of con-
densed matter physics. Cambridge University Press,
Cambridge
Chin C, Bartenstein M, Altmeyer A, Riendl S, Jochim S,
Hecker Denschlag J, Grimm R (2004) Observation of
the pairing gap in a strongly interacting Fermi gas.
Science 305:1128
Choy TP, Galanakis D, Phillips P (2007) Proposed insulat-
ing ground state of Na0.5CoO2: squaring the triangle.
Phys Rev B 75:073103
Davis KB, Mewes M-O, Andrews MR, van Druten NJ,
Durfee DS, Kurn DM, Ketterle W (1995) Bose-
Einstein condensation in a gas of sodium atoms. Phys
Rev Lett 75:3969
de Pue MT, McCormick C, Winoto SL, Oliver S, Weiss DS
(1999) Unity occupation of sites in a 3D optical lattice.
Phys Rev Lett 82:2262
Dziarmaga J (2005) Phys Rev Lett 95:245701
Engelsberg S, Varga BB (1964) Phys Rev 136:A1582
Fertig CD et al (2004) Strongly inhibited transport of a 1D
Bose gas in a lattice. arXiv:cond-mat/0410491
Fölling S, Gerbier F, Widera A, Mandel O, Gericke T,
Bloch I (2005) Spatial quantum noise interferometry
in expanding ultracold atom clouds. Nature 434:481
556
Ultracold Atomic Gases: Novel States of Matter

Fuchs JN, Recati A, Zwerger W (2004) Phys Rev Lett
93:090408
Gan JY, Chen Y, Zhang FC (2006) Superconducting
pairing symmetries in anisotropic triangular quantum
antiferromagnets. Phys Rev B 74:094515
Gensemer SD, Jin DS (2001) Phys Rev Lett 87:173201
Giamarchi T (2004) Quantum physics in one dimension.
Clarendon Press, Oxford
Gogolin
AO,
Nerseyan
AA,
Tsvelik
AM
(1998) Bosonization and strongly correlated systems.
Cambridge University Press, Cambridge
Goldwin J, Inouye S, Olsen ML, Newman B, DePaola BD,
Jin DS (2004) Measurement of the interaction strength
in a Bose-Fermi mixture with 87Rb and 40K. Phys Rev
A 70:021601
Görlitz A et al (2001) Phys Rev Lett 87:130402
Greiner M, Bloch I, Mandel O, Hänsch TW, Esslinger
T (2001) Exploring phase coherence in a 2D lattice of
Bose-Einstein condensates. Phys Rev Lett 87:160405
Greiner M, Mandel O, Esslinger T, Hänsch TW, Bloch
I (2002) Quantum phase transition from a superﬂuid
to a Mott insulator in a gas of ultracold atoms. Nature
415:39
Greiner M, Regal CA, Jin DS (2003) Emergence of a
molecular Bose-Einstein condensate from a Fermi
gas. Nature 426:537
Greiner M, Regal CA, Stewart JT, Jin DS (2005) Probing
pair-correlated fermionic atoms through correlations in
atom shot noise. Phys Rev Lett 94:110401
Hadzibabic Z, Stock S, Battelier B, Bretin V, Dalibard
J (2004) Phys Rev Lett 93:180403
Hadzibabic Z, Krüger P, Cheneau M, Battelier B, Dalibard
JB (2006) Nature 441:1118
Haldane FDM (1981) Phys Rev Lett 47:1840
Hanaguri T, Lupien C, Kohsaka Y, Lee D-H, Azuma M,
Takano M, Takagi H, Davis JC (2004) A ‘checkerboard’
electronic crystal state in lightly hole-doped Ca2 
xNaxCuO2Cl2. Nature 430:1001
Hoffman JE, Hudson EW, Lang KM, Madhavan V,
Eisaki H, Uchida S, Davis SC (2002) A four unit cell
periodic pattern of quasi-particle states surrounding
vortex cores in Bi2Sr2CaCu2O8+δ. Science 295:466
Honerkamp C (2003) Instabilities of interacting electrons
on the triangular lattice. Phys Rev B 68:104510
Hubbard J (1963) Electron correlations in narrow energy
band. Proc Soc R Lond A276:238
Isacsson A, Girvin SM (2005) Phys Rev A 72:053604
Isacsson A, Cha M-C, Sengupta K, Girvin SM (2005) Phys
Rev B 72:184507
Jaksch D, Bruder C, Cirac JI, Gardiner CW, Zoller P (1998)
Cold bosonic atoms in optical lattices. Phys Rev Lett
81:3108
Jérome D (1991) The physics of organic superconductors.
Science 252:1509
Jo G-B, Shin Y, Will S, Pasquini TA, Saba M, Ketterle W,
Pritchard DE, Vengalattore M, Prentiss M (2007) Long
phase coherence time and number squeezing of two
Bose-Einstein condensates on an atom chip. arXiv:
cond-mat/0608585
Jochim S, Bartenstein M, Altmeyer A, Hendl G, Riedl S,
Chin C, Denschlag JH, Grimm R (2003) Science
302:2101
Jones K, Julienne P, Lett P, Phillips WD, Tiesinga E, Wil-
liams C (1996) Measurement of the atomic Na
(3P) lifetime and of retardation in the interaction
between two atoms bound in a molecule. Europhys
Lett 35:85
Kane C, Fisher MPA (1992) Phys Rev Lett 68:1220
Kibble TWB (1976) Phys J A 9:1387
Kino H, Fukuyama H (1995) Electronic states of conducting
organic k-(BEDT-TTF)2. Phys XJ Soc Jpn 64:2726
Kinoshita T, Wenger T, Weiss DS (2004) Science 305:1125
Kitaev AY (2000) Unpaired Majorana fermions in quan-
tum wires. arXiv:cond-mat/0010440
Klironomos FD, Tsai S-W (2006) Phonon-mediated tuning
of instabilities in the Hubbard model at half-ﬁlling.
Phys Rev B 74:205109
Klironomos FD, Tsai S-W (2007) Pairing and density-
wave phases in Boson-Fermion mixtures at ﬁxed ﬁll-
ing. arXiv:cond-mat/0702660
Kogut JB (1979) Rev Mod Phys 51:659
Köhl M, Moritz H, Stöferle T, Günter ET (2005) Fermionic
atoms in a three dimensional optical lattice: observing
Fermi surfaces, dynamics, and interactions. Phys Rev
Lett 94:080403
Kohn W, Luttinger JM (1965) New mechanism for super-
conductivity. Phys Rev Lett 15:524
Lee S-S, Lee PA (2005) U(1) Gauge theory of the Hubbard
model: spin liquid states and possible application to
k-(BEDT-TTF)2Cu2(CN)3. Phys Rev Lett 95:036403
Lett PD, Julienne PS, Phillips WD (1995) Photoassociative
spectroscopy of laser-cooled atoms. Annu Rev Phys
Chem 46:423
Maddaloni P et al (2000) Phys Rev Lett 85:2413
Mahan GD (1990) Many-particle physics. Plenum Press,
New York
Mandel O, Greiner M, Widera A, Rom T, Hänsch TW,
Bloch I (2003a) Phys Rev Lett 91:010407
Mandel O, Greiner M, Widera A, Rom T, Hänsch TW,
Bloch I (2003b) Nature 425:937
Mathey L (2007) Commensurate mixtures of ultra-cold
atoms in one dimension. Phys Rev B 75:144510
Mathey L, Wang D-W (2007) Phase diagrams of one-
dimensional Bose-Fermi mixtures of ultra-cold atoms.
Phys Rev A 75:013612
Mathey L, Wang D-W, Hofstetter W, Lukin MD, Demler
E
(2004)
Luttinger
liquid
of
polarons
in
one-
dimensional boson-fermion mixtures. Phys Rev Lett
93:120404
Mathey L, Tsai S-W, Castro Neto AH (2006) Competing
types of order in two-dimensional Bose-Fermi mix-
tures. Phys Rev Lett 97:030601
Mathey L, Tsai S-W, Castro Neto AH (2007) Exotic super-
conducting phases of ultracold atom mixtures on trian-
gular lattices. Phys Rev B 75:144510
Mathey L, Altman E, Vishwanath A (2008a) Noise corre-
lations in one-dimensional systems of ultra-cold fer-
mions. Phys Rev Lett 100:240401
Ultracold Atomic Gases: Novel States of Matter
557

Mathey L, Polkovnikov A, Castro Neto AH (2008b)
Phase-locking transition of coupled low-dimensional
superﬂuids. EuroPhys Lett 81:10008
Mckenzie RH (1997) Similarities between organic and
cuprate superconductors. Science 278:820
Modugno G, Roati G, Riboli F, Ferlaino F, Brech RJ,
Inguscio M (2002) Collapse of a degenerate Fermi
gas. Science 297:2240
Modugno G, Ferlaino F, Heidemann R, Roati G, Inguscio
M (2003) Production of a Fermi gas of atoms in an
optical lattice. Phys Rev A 68:011601
Moritz H, Stöferle T, Günter K, Köhl M, Esslinger
T (2005) Phys Rev Lett 94:210401
Mukhopadhyay R, Kane CL, Lubensky TC (2001) Phys
Rev B 64:045120
O’Hern CS, Lubensky TC, Toner J (1999) Phys Rev Lett
83:2745
Onofrio R, Raman C, Vogels JM, Abo-Shaeer JR,
Chikkatur AP, Ketterle W (1999) Observation of super-
ﬂuid ﬂow in a Bose-Einstein condensed gas. Phys Rev
Lett 85:2228
Ospelkaus C, Ospelkaus S, Sengstock K, Bongs K (2006a)
Interaction-driven dynamics of
40K-87Rb fermion-
boson gas mixtures in the large-particle-number limit.
Phys Rev Lett 96:020401
Ospelkaus
C,
Ospelkaus
S,
Humbert
L,
Ernst
P,
Sengstock K, Bongs K (2006b) Ultracold heteronuclear
molecules in a 3optical D lattice. Phys Rev Lett
97:120402
Ospelkaus S, Ospelkaus C, Wille O, Succo M, Ernst P,
Sengstock K, Bongs K (2006c) Localization of
bosonic atoms by fermionic impurities in a three-
dimensional
optical
lattice.
Phys
Rev
Lett
96:180403
Ospelkaus S, Ospelkaus C, Humbert L, Sengstock K,
Bongs K (2006d) Tuning of heteronuclear interactions
in a degenerate Fermi-Bose mixture. Phys Rev Lett
97:120403
Paredes B, Widera A, Murg V, Mandel O, Foelling S,
Cirac I, Shlyapnikov GV, Hänsch TW, Bloch I (2004)
Nature 429:277
Partridge GB, et al (2005) Pairing and phase separation in a
polarized fermi gas. arXiv:cond-mat/0511752
Phillips
WD,
Ekstrom
C,
Goldin
W,
Rolston
SL
(1996) Laser cooling of neutral atoms for frequency
standards. In: Bergquist J (ed) Symposium on fre-
quency standards and metrology. World Scientiﬁc, Sin-
gapore, pp 5–10
Polkovnikov A (2005) Phys Rev B 72:161201(R)
Polkovnikov A, Altman E, Demler E (2006) Proc Natl
Acad Sci USA 103:6125
Raman C, Köhl M, Onofrio R, Durfee DS, Kuklewicz CE,
Hadzibabic Z, Ketterle W (1999) Evidence for a critical
velocity in a Bose-Einstein condensed gas. Phys Rev
Lett 83:2502
Recati A, Fedichev PO, Zwerger W, Zoller P (2003) Phys
Rev Lett 90:020401
Sadler LE et al (2006) Nature 443:312
Scherer DR et al (2006) Vortex formation by interference
of multiple trapped Bose-Einstein condensates. arXiv:
cond-mat/0610187
Schulz HJ (1987) Superconductivity and antiferromagnet-
ism in the two-dimensional Hubbard model – scaling
theory. Europhys Lett 4:609
Schumm T, Hofferberth S, Andersson LM, Wildermuth S,
Groth S, Bar-Joseph I, Schmiedmayer J, Krüger
P (2005) Nature Phys 1:57
Sengupta P, Pryadko LP (2005) Quantum degenerate Bose-
Fermi mixtures on 1D optical lattices. arXiv:cond-mat/
0512241
Shankar R (1994) Renormalization group approach to
interacting fermions. Rev Mod Phys 68:129
Solyom J (1979) Adv Phys 28:201
Stenger J, Inouye S, Chikkatur AP, Stamper-Kurn DM,
Pritchard DE, Ketterle W (1999) Bragg spectroscopy
of a Bose-Einstein condensate. Phys Rev Lett 82:4569
Stöferle T, Moritz H, Schori C, Köhl M, Esslinger T (2004)
Transition from a strongly interacting 1D superﬂuid to
a Mott insulator. Phys Rev Lett 92:130403
Takada K, Sakurai H, Takayama-Muromachi E, Izumi F,
Dilanian RA, Sasaki T (2003) Nature 422:53
Tam K-M, Tsai S-W, Campbell DK, Castro Neto AH
(2007) Retardation effects in the Holstein-Hubbard
chain at half ﬁlling. Phys Rev B 75:161103
Tsai S-W, Marston JB (2001) k-(BEDTTTF)2X organic
crystals: superconducting versus anti-ferromagnetic
instabilities in the Hubbard model on an anisotropic
triangular lattice. Can Phys J 79:1463
Tsai S-W, Castro Neto AH, Shankar R, Campbell DK
(2005a) Renormalization group approach to strong-
coupled superconductors. Phys Rev B 72:054531
Tsai S-W, Castro Neto AH, Shankar R, Campbell DK
(2005b) Renormalization group approach to supercon-
ductivity: from weak to strong electron-phonon cou-
pling. Philos Mag 86:2631
Tsuchiya S, Grifﬁn A (2003) Damping of bogoliubov
excitations in optical lattices. arXiv:cond-mat/0311321
Vershinin M, Misra S, Ono S, Abe Y, Ando Y, Yazdani
A (2004) Local ordering in the pseudogap state of the
high-T
c superconductor Bi2Sr2CaCu2O8+δ. Science
303:1995
Vichi L et al (1999) Phys Rev A 60:4734
Voit J (1995) Rep Prog Phys 58:977
Voit J, Schulz HJ (1987) Phys Rev B 36:968. ibid 37:
10068 (1988)
Vojta M, Dagotto E (1999) Indications of unconventional
superconductivity in doped and undoped triangular
antiferromagnets. Phys Rev B 59:713
Wang D-W, Lukin MD, Demler E (2005) Engineering
superﬂuidity in Bose-Fermi mixtures of ultracold
atoms. Phys Rev A 72:(R)051604
Withers RL, Wilson JA (1986) An examination of the
formation and characteristics of charge-density waves
in inorganic materials with special reference to the two-
and one-dimensional transition-metal chalcogenides.
Phys J C 19:4809
558
Ultracold Atomic Gases: Novel States of Matter

Zanchi D, Schulz HJ (2000) Weakly correlated electrons
on a square lattice: renormalization-group theory. Phys
Rev B 61:13609
Zhou A, Wang Z (2006) Charge and spin order on the
triangular lattice - NaxCoO2 at x ¼ 0.5. arXiv:cond-
mat/0608068
Zurek WH (1985) Nature 317:505109
Zurek WH, Dorner U, Zoller P (2005) Phys Rev Lett
95:105701
Zwierlein MW, Stan CA, Schunck CH, Raupach SMF,
Gupta S, Hadzibabic Z, Ketterle W (2003) Phys Rev
Lett 91:250401
Zwierlein M et al (2005) Fermionic superﬂuidity with
imbalanced spin populations and the quantum phase
transition
to
the
normal
state.
arXiv:cond-mat/
0511197
Books and Reviews
Bloch I, Dalibard J, Zwerger W (2007) Many-body physics
with ultracold gases. arXiv:0704.3011v1
Leggett AJ (2001) Bose-Einstein condensation in the alkali
gases: some fundamental concepts. Rev Mod Phys
73:307
Ultracold Atomic Gases: Novel States of Matter
559

Quantum Chaos
Giulio Casati1 and Tomaž Prosen2
1Universita dell’Insubria, Como, Italy
2Univerza v Ljubljani, Ljubljana, Slovenia
Article Outline
Glossary
Deﬁnition of the Subject
Introduction
Quantum Chaos: Stationary Aspects
Quantum Chaos: Dynamical Aspects
Applications of Quantum Chaos
Future Directions
Bibliography
Glossary
Ergodicity The property of a dynamical system,
according to which a single trajectory, starting
from almost any initial condition, explores
(densely covers) the entire available phase
space of physical states.
Integrability A classical Hamiltonian dynamical
system of N degrees of freedom is said to be
integrable (according to Liouville) if there
exist N independent conserved quantities. Inte-
grability implies explicit quasiperiodic solu-
tion of the equations of motion.
Periodic orbit theory or trace formula A rela-
tionship between certain properties of energy
spectrum of a quantized chaotic system and the
set
of
unstable
periodic
orbits
of
the
corresponding classical chaotic system.
Quantum Loschmidt echo or ﬁdelity A mea-
sure of stability of quantum time evolution. It is
computed as a Hilbert space inner product of
two slightly different quantum time evolutions
starting from the same initial state.
Random matrix theory The statistical theory
which allows to describe the ﬂuctuation prop-
erties of quantum systems in terms of the sets
(ensembles) of random Hermitian matrices
with appropriate invariant measures.
Wigner surmise Nearest neighbor energy level
spacing distribution based on the simplest 2  2
Gaussian Hermitian random matrix models,
accurately approximating spacing distributions
in complex quantum systems.
Definition of the Subject
As it is now widely recognized, classical dynam-
ical chaos has been one of the major scientiﬁc
breakthroughs of the past century. Quantum
chaos, sometimes called Quantum chaology, stud-
ies the manifestations of chaotic motion and
related
dynamical
phenomena
in
quantum
mechanics (Haake 2001; Stöckmann 1999).
More abstractly, one may deﬁne as quantum
chaos those phenomena of simple quantum sys-
tems which can be described statistically and
exhibit some universal (i.e., system independent)
features. By the term simple we mean here that the
system can be speciﬁed by a ﬁnite set of parameters
or, generally, can be described by a ﬁnite amount of
information. So we can fundamentally distinguish
the phenomena of quantum chaos from similar
dynamical phenomena in disordered systems –
speciﬁed in terms of random parameters and
which therefore contain inﬁnite amount of infor-
mation in an appropriate (say thermodynamic)
limit.
The universal statistical properties of quantum
chaotic systems which have been widely studied
include statistics of energy level spectra, statistical
and semiclassical structures of the wave func-
tions, and statistical distributions of transition
matrix elements (matrix elements of certain phys-
ical observables in the energy eigenbasis). These
properties are of key importance for understand-
ing
quantum
state
transitions,
dissipation,
© Springer Science+Business Media, LLC, part of Springer Nature 2022
B. Chakraborty (ed.), Statistical and Nonlinear Physics,
https://doi.org/10.1007/978-1-0716-1454-9_427
Originally published in
R. A. Meyers (ed.), Encyclopedia of Complexity and Systems Science, © Springer Science+Business Media New York 2013
https://doi.org/10.1007/978-3-642-27737-5_427-3
561

ionization, and related phenomena. Traditionally
quantum chaos has been intimately connected to
problems in atomic physics, nuclear physics,
mesoscopic solid-state physics, and more recently
also to the emerging ﬁeld of quantum information.
The subject of quantum chaos is at the core of
the fundamental and general understanding of the
correspondence principle according to which clas-
sical mechanics emerges as a limit of quantum
mechanics when an “effective” value of the
Planck’s constant goes to zero. However, chang-
ing perspective and treating quantum mechanics
as a fundamental theory and classical mechanics
as its convenient approximation, one can ask what
happens to the phenomena of quantum chaos in
systems which lack the classical limit, such as
systems of spin one half or quantum bits
(qubits). Still, many of the successful statistical
tools developed or widely used in the ﬁeld of
quantum chaos can be applied to understand the
dynamical and statistical properties of interacting
qubits.
Introduction
Classical Hamiltonian dynamical systems display
a rich variety of behaviors (Cornfeld et al. 1982).
At one end, we have strongly chaotic dynamical
systems, which are distinguished by such proper-
ties as algorithmic complexity, exponential sensi-
tivity to initial conditions, continuous spectrum
and consequent decay of temporal correlations
(“loss of memory”), relaxation to equilibrium,
and ergodicity. Without entering a discussion of
the above properties, we notice that rigorous
examples of such strongly chaotic systems are
billiard balls bouncing inside a table with inward
curved boundaries or point mass particles moving
freely on any surfaces of constant negative
curvature.
At the opposite end, there are completely inte-
grable or regular dynamical systems, which,
according to Liouville, are characterized by the
existence of as many independent smooth con-
stants of motion as there are degrees of freedom
and which are distinguished by analytic predict-
ability
of
time
evolutions
and
absence
of
algorithmic complexity. Consequently, integrable
systems have a discrete spectrum of time evolu-
tion, do not display relaxation to equilibrium, and
due to existence of nontrivial constants of motion,
are not ergodic.
Nowadays
we
know
few
examples
of
completely integrable systems, such as an arbi-
trary system of coupled linear (harmonic) oscilla-
tors, the general problem of two moving bodies
interacting with a centrally symmetric force, and
even many-body models such as the famous Toda
lattice which is a system of equal point masses in
one dimension interacting with exponentially
distance-dependent force. On the other hand we
also know that a generic or typical Hamiltonian
system is not integrable, neither it is strongly
chaotic in a rigorous sense. Instead, we ﬁnd a
variety
of
intermediate
behaviors
between
completely integrable and strongly chaotic.
A famous Kolmogorov-Arnold-Moser (KAM)
theorem states that a small generic (smooth) per-
turbation of a completely integrable Hamiltonian
systems preserves most of the features of regular
motion, such as quasiperiodicity or discrete spec-
trum, for most of initial conditions. However, in
the vicinity of the so-called resonant tori (i.e., for
initial conditions for which the motion of the
unperturbed system has commensurate frequen-
cies), the motion becomes locally (weakly) cha-
otic even for arbitrary weak perturbations. Still,
the relative overall phase space volume occupied
by chaotic trajectories decreases to zero faster
than any power of the perturbation strength.
However, KAM theory does not describe the
only scenario of integrability breaking in Hamil-
tonian systems. Other types of perturbations,
which do not obey the conditions of KAM theo-
rem, are possible which yield physically interest-
ing behavior. One class of such behaviors is the
motion in generic polygonal billiards (Casati and
Prosen 1999) (namely, billiard tables with the
shape of a generic polygon, say a triangle) or the
motion of any number of elastically colliding
point masses in one dimension. Such systems are
neither integrable nor chaotic in the sense of expo-
nential sensitivity or algorithmic complexity.
The fundamental problem of quantum chaos
concerns the manifestations in the quantum world
562
Quantum Chaos

of the various degrees of complexity of classical
dynamics, as described by the above hierarchy.
Primarily we are interested in simple, closed
(isolated), and bounded systems for which, as it
is known, the spectrum of the Hamilton operator
(the generator of the Schrödinger equation) is
always discrete. Notice that in classical ergodic
theory, discrete spectrum is associated to integra-
bility which is just the opposite of chaos which
requires continuous spectrum. In such a situation,
quantum mechanics, at most, can follow chaotic
classical dynamics only up to the so-called break-
ing time scale t* after which the quantum motion
becomes fundamentally different from the classi-
cal one. Precise understanding of this transition
phenomena, scaling of the time scale t* with var-
ious physical properties, is at the heart of quantum
chaos and shall be brieﬂy discussed in the subse-
quent sections.
Quantum Chaos: Stationary Aspects
The problems of quantum chaos can be viewed
from two different but closely connected view-
points, namely, the stationary aspects in the
energy domain and the dynamical aspects in the
time domain. Let us start by discussing the sta-
tionary aspects.
It has been recognized as early as in the 1950s
by Wigner, and later by Dyson, that many statis-
tical features of energy levels of complex nuclei,
or long-lived resonance states, can be adequately
described by a simple statistical model of random
Hermitian matrices. Wigner’s idea was that for a
sufﬁciently complicated quantum system with
many degrees of freedom like a heavy nucleus,
one assumes that the matrix elements of the Ham-
iltonian in a typical basis can be treated as inde-
pendent Gaussian random numbers. Such random
matrix model has essentially no free parameters
and is invariant under almost arbitrary basis
changes, and therefore, one can obtain many
explicit analytical results.
The simplest and perhaps the main result of
random matrix theory (Mehta 1991) predicts that
the statistical distribution of spacings between adja-
cent energy levels, denoted by Sn ¼ En+1  En,
properly scaled or normalized such that the average
spacing S equals one, obeys universal distributions
which only depend on certain symmetry properties.
Roughly speaking, they depend on the existence of
time-reversal invariance of the Hamiltonian and are,
to a high level of accuracy, given by the so-called
Wigner surmise:
Pb S
ð Þ ¼ ASb exp BS2


where the constants A and B are determined
from normalization conditions,
Ð 1
0 Pb S
ð ÞdS ¼ 1,
Ð 1
0 SP S
ð ÞdS ¼ 1. The integer β is known as uni-
versality index and equals β ¼ 1 for real Gaussian
random matrices applying in the time-reversal
invariant case and β ¼ 2 for complex Gaussian
random matrices applying in the case where time-
reversal invariance is broken. Note that β has also
an interesting interpretation as a level repulsion
parameter since β > 0 implies repulsive correla-
tions between adjacent energy levels.
Of course, random matrix theory would only
remain an interesting mathematical model if it
would not have been so immensely successful
in describing spectral correlations of complex
quantum systems. As already mentioned it
started with nuclear spectra for which one is
ready to believe that due to immense complexity
of interactions, random matrix description is
intuitively adequate. However, in the beginning
of the 1980s, numerical evidence started to accu-
mulate (Casati et al. 1980; Bohigas et al. 1984)
that even the spectra of very simple, but yet
nonintegrable and classically chaotic systems
exhibit universal level ﬂuctuations described by
random matrix theory.
This observation, namely, that short-range
spectral correlations of quantum systems which
are strongly chaotic in the classical limit obey
universal ﬂuctuation laws which are given by
ensembles of random matrices without free
parameters, has been known as quantum chaos
conjecture and, despite of still not being rigor-
ously proven, remains one of the deﬁning and
most important results in the ﬁeld.
One of the standard paradigmatic models
where quantum chaos conjecture has been most
often and convincingly demonstrated is quantum
Quantum Chaos
563

billiards. The stationary Schrödinger problem for
a billiard of a point particle of mass m moving
freely inside a planar domain (billiard table) D and
colliding elastically off its boundary is simply the
well-known Helmholtz (amplitude) equation for
the particle wave function:
∇2C x, y
ð
Þ þ k2C x, y
ð
Þ ¼ 0
with Dirichlet boundary condition Cj@D ¼ 0, hav-
ing a discrete set of solutions {kn, Cn; n ¼ 1, 2,
. . .} with a dispersion relation to the eigenenergies
En ¼ ℏ2kn
2/(2m). In Fig. 1 we show two examples
of a typical integrable billiard (circular billiard)
and a typical fully chaotic and ergodic billiard
(cardioid billiard proposed by Robnik (Robnik
1983)) – plotting typical trajectories for each and
a sequence of few typical chaotic and regular
eigenstates.
Solving the Dirichlet-Helmholtz problem for a
ﬁnite domain is one of the most standard problems
in linear wave physics and emerges in equivalent
forms
in
gas
acoustics,
ﬂat
electromagnetic
(microwave) resonators, transverse waves in opti-
cal ﬁbers, etc., the only difference from the station-
ary quantum problem being the dispersion relation
which connects the frequency of stationary waves
to the eigenvalues of the wavenumber kn.
In Fig. 2 one can observe that spectra of chaotic
quantum billiard, hydrogen atom in strong mag-
netic ﬁeld, excitation spectrum of NO2 molecule,
microwave electromagnetic spectrum of a three-
dimensional chaotic cavity, and even spectra of
vibrating elastic solids all exhibit spectral correla-
tions which are given by a Gaussian ensemble of
real random matrices.
The universality of quantum statistics of clas-
sically chaotic systems applies also to other prop-
erties, such as the distribution of a chaotic wave-
function amplitudes, which is Gaussian and very
well modeled by the so-called random plane wave
superposition (Berry 1977); the distribution of
matrix elements of typical observables in the
eigenbasis of chaotic Hamiltonians (Feingold
and Peres 1986), which is again Gaussian; or
even distribution of chaotic Wigner functions
(quantum analogues of phase space densities)
which is found again to be Gaussian (Horvat and
Prosen 2003).
An interesting related mathematical question is
the problem of quantum ergodicity. For a generic
physical observable A, the question is whether its
Quantum Chaos, Fig. 1 Typical examples of a regular
billiard (circular billiard, above) and a fully chaotic billiard
(cardioid billiard, below). In the left side of the ﬁgure, we
show two typical trajectories in the billiard table, whereas
to the right, we depict few examples of wave functions of
eigenstates
at
different
sequential
level
numbers
n (Courtesy of Bäcker 2007)
564
Quantum Chaos

expectation
value
in
a
given
eigenstate
approaches, with increasing quantum level num-
ber,
the
microcanonical
average
of
the
corresponding classical observable evaluated at
the corresponding energy, namely, whether the
sequence
Cn
h
jA Cn
j
i  Aclassical En
ð
Þ; n ¼ 1, 2, 3, . . .
f
g
converges to zero? Mathematicians often relax the
above condition to hold for a subsequence of
density 1 meaning that the above property holds
for a typical eigenstate, whereas the sequence of
exceptions (with semiclassically vanishing statis-
tical weight) corresponds to the famous scar
states discovered by Heller (1984). For quantum
billiards, the statement of quantum ergodicity is
equivalent
to
the
statement
of
uniform
equidistribution of probability density for eigen-
states (see e.g., lower panels of Fig. 1). It has been
proven (the proof has been announced by
Shnirelman (1974) and later worked out by
Zelditch (1987) and Colin de Verrdiere (1985))
that strongly chaotic billiards, and some other
rigorous examples of strongly chaotic systems,
are quantum ergodic. However, the minimal clas-
sical ergodic properties (like ergodicity, weak
mixing, etc.) sufﬁcient for quantum ergodicity
are still under debate.
One can now ask similar questions for the other
extreme of ergodic hierarchy, namely, for classi-
cally regular systems: Are there some universal
Quantum Chaos,
Fig. 2 Level spacing
distributions for (a) the fully
chaotic Sinai billiard
(Bohigas et al. 1984), (b) a
hydrogen atom in a strong
magnetic ﬁeld, (c) an NO2
molecule, (d) a vibrating
quartz block shaped like a
three-dimensional Sinai
billiard, (e) the microwave
spectrum of a three-
dimensional chaotic cavity,
(f) a vibrating elastic disc-
shaped like a quarter
stadium (Courtesy of
Stöckmann 1999)
Quantum Chaos
565

features of spectral ﬂuctuations of quantum sys-
tems whose classical limit is completely regular?
The answer is only partly afﬁrmative, in the sense
of an argument which has been originally given
by Berry and Tabor (1977a). The starting point of
this argument is that the eigenenergies of a
completely integrable system with d degrees of
freedom can be labeled by a d-duple of quantum
numbers – integers nj – namely, En1n2. . .nd. Berry
and Tabor argued that level subsequences, where
d  1 quantum numbers are ﬁxed and only one of
them is being varied, are mutually independent.
As the overall spectrum of an integrable system is
a superposition of many such almost uncorrelated
level sequences, one concludes that any short-
range level correlations should be absent. For
example, the level spacing distribution for an inte-
grable system should be the same as for a
Poissonian distribution of uncorrelated events,
namely,
Pint S
ð Þ ¼ exp S
ð
Þ:
One has to note that for integrable systems, one
should not really expect a universality in the same
sense as for chaotic systems. Berry and Tabor’s
argument cannot in general be turned into a rigor-
ous proof, and for any particular integrable sys-
tem, one can in principle always ﬁnd statistical
measures which deviate from Poissonian predic-
tions (Casati and Chirikov 1985). For example, a
one-dimensional harmonic oscillator has an equi-
distant (the so-called picket fence) spectrum so its
level spacing distribution can be written in terms
of
a
Dirac’s
delta
distribution
Pharm.osc. ¼
δ(S  1). In other words, as quantum statistical
properties are concerned, there is no such thing as
a typical integrable system. This can be viewed as
another manifestation of quantum non-ergodicity
of integrable systems.
Even if spectral ﬂuctuations of integrable sys-
tems are relatively universal – in the sense as
explained above – this is not at all true for other
statistical properties of quantized integrable sys-
tems, such as wave-function amplitudes, sizes,
and numbers of nodal domains of wave functions,
matrix elements of typical physical observables,
etc. There we ﬁnd system-speciﬁc features which
can hardly be described by some general statisti-
cal rules.
The general case of typical quantum systems,
say those which can be understood as quantiza-
tions of systems with classically mixed phase
space with coexisting regular and chaotic orbits,
is the most difﬁcult to describe. It is fair to say that
quantum chaos of generic systems is still in its
infancy. Among the few results which can be
mentioned is the semiclassical theory of Berry
and Robnik (1984) describing level ﬂuctuations
of mixed systems as statistical superposition of
independent level subsequences corresponding
to each invariant classical phase space compo-
nent: level subsequences corresponding to areas
of chaotic motion are modeled by an appropriate
ensemble of random matrices with the relative
level density which is given by the classical vol-
ume of the chaotic component, and a (single)
subsequence corresponding to all regular trajecto-
ries is modeled by a Poissonian level sequence of
the corresponding overall level density. However,
in realistic quantum systems, tunneling between
chaotic and regular states has to be taken into
account, and in spite of few attempts, we are still
lacking a general statistical theory of tunneling
amplitudes in mixed phase space systems.
It should be noted that statistical properties of
energy level ﬂuctuations can be related to clas-
sical recurrent phase space structures such as
periodic orbits. In particular, for chaotic dynam-
ical systems, one ﬁnds a beautiful relationship
between semiclassical approximation to the
energy spectrum and isolated unstable classical
periodic orbits, which is known as Gutzwiller’s
trace formula (Gutzwiller 1991), and is based on
stationary phase approximation to Feynman
path integral representation of Green’s function
of the Schrödinger equation. A similar trace
formula has been proposed by Berry and Tabor
also for classically regular systems (Berry and
Tabor 1977b). Related periodic or closed orbit
theories have been later developed for describ-
ing semiclassical properties of other quantities,
for example, scars in chaotic wave functions
(Bogomolny 1988; Berry 1989). The trace for-
mula has been believed to be the theoretical tool
to attack the proof of quantum chaos conjecture.
566
Quantum Chaos

Considerable recent progress has been achieved
by Müller et al. (2004), building upon an idea of
Sieber (2002), who have shown that the correct
resummation of a trace formula indeed yields
short time expansion of the universal spectral
form factor (Fourier transformation of the two-
point spectral correlation function) which is
identical to the one obtained from random
matrix theory.
Quantum Chaos: Dynamical Aspects
Classical chaos is a property of time evolution
and, as we have seen, requires continuous spec-
trum of the motion. However, the spectrum of
bounded closed quantum systems is always dis-
crete; therefore, genuine quantum chaos which
would be a property of asymptotic time evolution
is not possible, namely, there is an ultimate break-
ing time scale t* which is determined by the den-
sity of states r ¼ dEn/dn. Indeed, writing a
completely general solution of the time-dependent
Schrödinger equation as
C tð Þ ¼
X
n
cn exp iEnt=ℏ
ð
ÞCn
one sees that the quasiperiodic nature of time
evolution shows up, on average, when the differ-
ence of two adjacent phases grows to 2π, namely,
t ¼ 2pℏr
This breaking time scale is also sometimes
referred to as Heisenberg time, and after t* the
time evolution in quantum mechanics is domi-
nated by quantum ﬂuctuations.
Thus, genuine quantum chaos is possible only
within a time scale t < t*, where quantum phe-
nomena with semiclassical description are possi-
ble, such as relaxation, exponential sensitivity,
etc. However, not all chaotic phenomena can be
observed in quantum dynamics up to t*; some are
much more short lived. For example, exponential
sensitivity to initial conditions can be mimicked
by quantum motion only up to the so-called
Ehrenfest time
tE ¼ ln A0=ℏ
ð
Þ
l
where A0 is the phase space volume explored by a
classical chaotic trajectory, and l is the classical
Lyapunov exponent measuring the exponential
rate of divergence δx(t)exp(lt)δx(0) of nearby
trajectories in classical dynamics. Up to time tE,
Gaussian wave packets centered on classical tra-
jectories can be used for semiclassical description
of quantum motion (Heller 1991). Ehrenfest time
tE and Heisenberg time t* are two essential time
scales of quantum chaos.
A simple but fundamental manifestation of
quantum chaos is the destruction of quantum
interferences by quantum dephasing as a result
of chaotic classical dynamics. To illustrate this,
let us consider a time-dependent double-slit
experiment, where the source is closed inside a
two-dimensional wave resonator in the shape of a
chaotic billiard (Casati and Prosen 2005). The
setting is depicted in Fig. 3. We take an initial
Gaussian wave packet with average energy
corresponding to about the 1600th excited state
of the closed billiard and direct it towards two
narrow openings – slits – which are a few (about
three) De Broglie wavelengths apart. The wave
packet is taken to be as sharply as possible local-
ized
in
momentum
space,
so
that
due
to
screen
l
a
s
l
absorber
Quantum Chaos, Fig. 3 The geometry of the numerical
double-slit experiment. All scales are in proper propor-
tions. The two slits are placed at a distance s on the lower
side of the billiard
Quantum Chaos
567

Heisenberg uncertainty principle, its spreading in
position space is of the order of the diameter of the
billiard. Then we solve the time-dependent
Schrödinger equation and observe the radiation
which is transmitted through the two slits to an
inﬁnite plane below. We then record the time-
integrated probability current density I(x) as a
function of the horizontal position x on the screen.
The results of such numerical experiment are
shown in Fig. 4. We observe almost no sign of
quantum interference if the shape of the resonator
is chaotic. This is a manifestation of chaotic
dynamics of classical rays and consequently
phase randomization of multiply reﬂected waves
impacting onto the slits. For comparison we show
an analogous result for a regular geometry of the
resonator which is represented by an integrable
billiard. Here we ﬁnd the well-known interference
fringes whose location and visibility is a well-
controlled function of the initial conditions of
the wave packet. In Fig. 5 we show instant snap-
shots of the probability density at around half the
Heisenberg time for chaotic and regular geometry.
The crucial difference is that the jets of probability
coming out from the two slits have time-
dependent direction in the chaotic case, whereas
these directions are frozen in time for the regular
geometry.
We note that such a simple numerical experi-
ment has a well-deﬁned analogue (and explana-
tion) in the stationary quantum chaos. Namely, the
Quantum Chaos, Fig. 4 The total intensity after the
double-slit experiment as a function of the position on the
screen. I(x) is obtained as the perpendicular component of
the probability current, integrated in time. The red full
curve indicates the case of regular billiard, while the blue
dotted curve indicates the case of chaotic one. The green
dashed curve indicates the averaged intensity over two
1-slit experiments (where one of the slits is closed), with
either the regular or chaotic billiard (with results being
practically the same)
Quantum Chaos, Fig. 5 Typical snapshots of the wave
function (plotted is the probability density) for the two
cases: (a) for the regular billiard at t ¼ 0.325 and (b) for
the chaotic billiard at t ¼ 0.275 (both cases correspond to
about half the Heisenberg time). The probability density is
normalized separately in both parts of each plot, namely,
the probability density, in absolute units, in the radiating
region is typically less than 1 % of the probability density
in the billiard domain. The screen, its center, and the
positions of the slits are indicated with thin black lines.
Please note that the color code on the top of the ﬁgure is
proportional to the square root of probability density
568
Quantum Chaos

intensity I(x), in the far ﬁeld and narrow slit
approximations, can be expressed in terms of spa-
tial autocorrelation of the eigenfunctions of the
billiard at the two positions of the slit. It is
known (Berry 1977) that chaotic eigenfunctions
are characterized by decaying spatial correla-
tions – hence the destruction of interference pat-
tern – whereas eigenfunctions of regular systems
have long-range spatial correlations.
Another important aspect of time-dependent
quantum chaos is the study of the so-called
Loschmidt echoes or ﬁdelity decay (Gorin et al.
2006). This quantity has been proposed by Peres
(1984) as a natural analogy in quantum mechanics
of Lyapunov exponents and sensitive dependence
to initial conditions. Let U0(t) represent some
unitary quantum mechanical evolution operator,
e.g., U0(t) ¼ exp(iHt/ℏ) where H is the Hamil-
tonian, and let Uε(t) represent a perturbed evolu-
tion, where ε is some small perturbation strength
parameter. Quantum Loschmidt echo is deﬁned in
terms of ﬁdelity (square modulus of Hilbert space
inner product) of a state of perturbed time evolu-
tion |Cε(t)⟩¼ Uε(t)|C(0)⟩with respect to time-
evolved state of the unperturbed evolution |C0-
(t)⟩¼ U0(t)|C(0)⟩, namely,
F tð Þ ¼ j⟨Ψ0 tð Þ Ψ tð Þ
j
⟩j2
¼ ⟨Ψ 0
ð ÞjU 0 tð ÞU tð Þ Ψ 0
ð Þ
j
⟩
j
j2
The
ﬁrst
expression
(ﬁdelity)
can
be
interpreted as the probability that two nearby
quantum evolutions end up in the same state,
whereas the second expression (Loschmidt echo)
is the probability that the state after forward
perturbed time evolution composed with time-
reversal operation and (backward) unperturbed
evolution for the same amount of time end up in
the same (initial) state. The equivalence of the two
expressions is a simple consequence of the
unitarity of quantum dynamics. The ﬁdelity is a
measure of stability of quantum motion. Note that
the formalism of Loschmidt echoes can be closely
connected to the theory of decoherence in open
quantum systems (Gorin et al. 2006). For exam-
ple, in many interesting speciﬁc situations, the
Loschmidt echo can be used to bound or estimate
certain standard measures of decoherence.
For
a
semiclassical
understanding
of
Loschmidt echoes, it is very useful to write the
expression of quantum ﬁdelity in terms of the
Wigner phase space function
W e q, p, t
ð
Þ ¼ 2pℏ
ð
Þd:
ð
ddr q  r=2 Ce tð Þ
j
h
i Ce tð Þ q þ r=2
j
j
h
i exp ip  r=ℏ
ð
Þ
corresponding to state |Cε(t)⟩, namely,
F tð Þ ¼ 2pℏ
ð
Þd
ð
ddqddqW 0 q, p, t
ð
ÞW e q, p, t
ð
Þ
It is known that the Wigner function of an
initial Gaussian wave packet follows the classical
Liouville equation for times below the Ehrenfest
time. It can also be easily shown that for short
times, the corresponding classical  delity com-
puted in terms of classical phase space densities
decays with the same rate with which nearby
orbits diverge, namely, with the Lyapunov expo-
nent (Gorin et al. 2006). Therefore, for t < tE,
quantum ﬁdelity decays with the perturbation-
independent rate given by the classical Lyapunov
exponent l, Flyap(t)  exp(lt).
For times between Ehrenfest and Heisenberg
time, tE < t < t*, and correspondingly small per-
turbation strength so that the ﬁdelity is apprecia-
ble, the decay of Loschmidt echo can be computed
using time-dependent perturbation theory, or
Fermi golden rule, and one obtains Ffgr(t)  exp
(ε2st) where the coefﬁcient s is equal to aver-
age square of near-diagonal matrix elements of the
generator of the perturbation. The quantity s can
be semiclassically computed in terms of inte-
grated time-correlation function of the classical
perturbation (Gorin et al. 2006).
For even larger times, t > t*, the quantum
dynamics is dominated by ﬂuctuations, and ﬁdel-
ity decay, provided ε is small enough, can be
computed by static quantum perturbation theory
which leads to the Gaussian decay Fp(t)  exp
(2ε2st2/t*).
On the other hand, ﬁdelity decay for classically
integrable (regular) systems is somewhat simpler
but less universal – namely, it depends on the
structure of invariant tori of the integrable system
Quantum Chaos
569

and on the initial state. For initial Gaussian wave
packets, the decay of ﬁdelity is typically faster
than for chaotic systems, which is a manifestation
of ballistic nature of regular dynamics as opposed
to diffusive nature of chaotic dynamics. In Fig. 6,
we demonstrate the decay of ﬁdelity for Haake’s
kicked top model (Haake 2001) and compare the
regimes of regular and chaotic dynamics for the
same initial coherent (Gaussian) state and the
same value of perturbation parameter. Both cases
can be theoretically described and understood
(Gorin et al. 2006). For illustration we plot the
Wigner functions of the time evolution as well as
the Wigner function of the echo dynamics –
perturbed forward evolution composed with
unperturbed backward evolution. Note that the
t=0
forward
echo
forward
echo
1
0.1
0.01
0.001
F(t)
0.0001
0
0
100
10−1
10−2
10−3
10−4
500
1000
1500
20
40
t
60
80
100
120
t=60
t=120
Quantum Chaos,
Fig. 6 Fidelity decay for
chaotic (top curve and
pictures) and regular
(bottom curve and pictures)
kicked top. Initial
conditions and the
perturbation are the same in
both cases, and theoretical
formulae, with the only
input given in terms of
classical dynamics, are
shown with full curves (see
Heller 1991 for details).
Wigner functions after
forward and echo evolution
are shown for illustration of
the ballistic versus diffusive
mechanisms
570
Quantum Chaos

Wigner function of a quantum top (spin) is deﬁned
over a surface of the sphere.
Quantum chaos has been studied also in
unbounded systems with inﬁnite classical phase
space, such as the kicked rotator (Casati and
Chirikov 1995), where classical chaos – through
decaying temporal correlations – gives rise to
deterministic
diffusion.
It
has
been
shown
(Casati and Chirikov 1995; Casati et al. 1979;
Fishman et al. 1982) that the role of classical
deterministic chaos in kicked one-dimensional
systems with inﬁnite momentum space is analo-
gous and sometimes even formally equivalent to
the role of disorder in one-dimensional tight-
binding model of a solid. In fact the phenomenon
of dynamical localization has been discovered
(Casati et al. 1979) in full analogy with Anderson
localization in disordered one-dimensional solids.
Applications of Quantum Chaos
Theoretical phenomena of quantum chaos have
been applied or experimentally observed in a vari-
ety of ﬁelds. Far from being complete we just
mention a few.
Atomic Physics
One of the ﬁrst successful applications of the ideas
of quantum chaos has been a theoretical explana-
tion of multiphoton ionization experiments with
hydrogen
in
microwave
ﬁeld
which
were
performed by Bayﬁeld and Koch (1974). Single
hydrogen atoms prepared in very elongated states
with
high
principal
quantum
number
were
injected into the microwave cavity and the ioni-
zation rate was measured. Even though the micro-
wave frequency was well below the ionization
energy, in fact even lower than the transition
energy to the next excited energy level, it was
found very surprisingly that very efﬁcient ioniza-
tion occurred when the electric ﬁeld intensity
exceeded a certain threshold value. The theoreti-
cal analysis (described, e.g., in Casati and
Chirikov 1995) explained the threshold intensities
as critical values for the onset of chaotic diffusion
in phase space. Quite interestingly, it has been
shown that classical mechanics alone accurately
describes the results of experiment, namely, in the
situation above the delocalization border (which
has been predicted theoretically (Casati et al.
1984)) and in the semiclassical regime of high
principal quantum number, where an effective
value of the Planck constant is sufﬁciently small.
However, in Casati et al. (1984) it has been shown
that dynamical localization can take place in
hydrogen atom, and this has been experimentally
observed in Bayﬁeld et al. (1989), Galvez
et al. (1988).
A second notable experimental achievement
has been the observation of dynamical localiza-
tion, in fact a realization of quantum mechanical
kicked rotor in terms of cold Cesium atoms in a
standing wave of kicked electric ﬁeld by the
Raizen’s group (Klappauf et al. 1999).
Mesoscopic Solid-State Physics
The ideas of quantum chaos have been exten-
sively investigated in mesoscopic solid-state sys-
tems, in particular in the studies of quantum
transport in the ballistic regime, where the mean
free path of the electrons is much larger than the
device.
Perhaps it is worth mentioning the discovery of
universal conductance ﬂuctuations (Marcus et al.
1992) which correspond to Ericson ﬂuctuations in
nuclear physics. It has been shown – by measuring
the so-called magnetoresistance in quantum dots
(2d conducting structure of a size of the order of a
micrometer) – that the conductance ﬂuctuations
have some universal statistical features if the
shape of the quantum dot represents a chaotic
billiard. Universal conductance ﬂuctuations have
been later extensively discussed theoretically and
explained in terms of random matrix theory (see,
e.g., review Beenakker 1997).
Quantum Information
Chaotic quantum dynamics is effective in produc-
ing entanglement, which is a key resource for
quantum information processing (Nielsen and
Chuang 2000; Benenti et al. 2004). This has
been demonstrated theoretically with many cha-
otic toy models; see, e.g., Žnidarič and Prosen
(2003). Perhaps it deserves to be mentioned that
two of these models, namely, the quantized Baker
Quantum Chaos
571

map and the quantized sawtooth map, have been
realized in a real-world quantum computer
(Weinstein et al. 2002). Dynamical chaos can
also be explored to engineer robust and accurate
decoupling schemes for processing quantum
information in the presence of static noise (Gorin
et al. 2006).
Wave Chaos
There are many applications of the ideas and
mechanisms of quantum chaos outside of quan-
tum mechanics. For example, essentially all the
stationary aspects of quantum chaos, and some-
times even some dynamical aspects provided the
change in dispersion relations is taken into
account, are being beautifully demonstrated in
the planar electromagnetic microwave resonators
since the early 1990s by the groups of Stöckmann
(see, e.g., Stein and Stöckmann 1992), Richter
(see, e.g., Richter 2001) and Sridhar (see, e.g.,
Sridhar 1991). Very impressive “quantum chaos”
experimental studies were conducted in acoustics,
namely, with blocks of vibrating solids; see, e.g.,
Ellegaard et al. (2001), Kuhl et al. (2005). It turns
out
that
experimentally
feasible
quality
(Q) factors in elastodynamics resonators can be
much larger than in microwave billiards, however,
the complication here being that the underlying
amplitude wave equation is of fourth order and
cannot be interpreted as a Schrödinger equation.
Still, using the universality of quantum chaos, one
can argue (and ﬁnd) that statistical properties of
resonance frequencies are described by the same
statistical random matrix theory (Fyodorov et al.
2005). We may also mention a recent application
of quantum chaos to optical ﬁbers (Doya et al.
2001). Another impressive extension of quantum
chaos is the nonlinear wave-optics, namely, to
engineering of directed stimulated emission of
micron-size and chaotic billiard-shaped semicon-
ductor lasers (Harayama et al. 2003).
Future Directions
By now quantum chaos of single – or few parti-
cles – systems is relatively well understood.
Among open future problems, we should perhaps
mention the case of systems with mixed phase
space being neither completely integrable nor
fully chaotic. In such systems, one of the most
important problems is to derive a quantitative
theory of tunneling rates between classically dis-
joint phase space components.
Most of the results so far obtained in the ﬁeld of
quantum chaos are based on numerical evidence,
and we are still lacking of rigorous proofs. For
example, we are missing the proof of quantum
chaos conjecture, the precise conditions (ergodic
properties of the underlying classical system) under
which it holds, precise statements about quantum
ergodicity in general Hamiltonian systems, etc.
However, one of the key challenges for the
future is to understand and apply dynamical chaos
mechanisms
to
quantum
systems
of
many
interacting particles. In particular it seems that com-
plete integrability of many-body systems implies
anomalous nonequilibrium statistical behaviors,
such as ballistic transport, and it seems necessary
to operate in the regime of quantum chaos in order
to validate diffusive statistical laws in many-body
transport. Furthermore, it seems that quantum chaos
in many-body systems is intimately connected to
the impossibility of efﬁcient simulation of such
systems on classical computers. See, e.g., Prosen
(2007) for a recent review of these topics.
At the general level, we recall that while in
classical mechanics there is a very well-developed
ergodic theory which is important for understand-
ing equilibrium and nonequilibrium properties of
classical physical systems, in quantum mechan-
ics, there is not, so far, a well-established theory.
A theory would be required which could explain
the asymptotic relaxation process (in the correct
order of limits, namely, letting the time to inﬁnity
at last) in the presence of a purely discrete spec-
trum and in the absence of exponential instability.
We close on a more speculative note. In quan-
tum mechanics, we are always facing with the
problem of the measurement device which should
be treated as a macroscopic classical system. As
for such, classical chaos and exponential instabil-
ity are present. This is indeed even necessary since
by its purpose, a measurement device must be
unstable because a microscopic intervention
must
produce
a
macroscopic
effect.
The
572
Quantum Chaos

importance of chaos in the quantum measurement
is that it destroys the coherence of the initial pure
state to be measured converting it to an incoherent
mixture. In the existing theories of quantum mea-
surement, this is described as the effect of external
noise. Chaos theory allows to get rid of this unsat-
isfactory assumption and to develop a purely
dynamical theory of loss of quantum coherence.
Still, a fundamental problem remains open,
namely,
the
redistribution
of
probability
according to the result of the measurement: the
so-called collapse of the wave function which
remains to be understood.
Bibliography
Bäcker A (2007) Comput Sci Eng 9:60
Bayﬁeld JE, Koch PM (1974) Phys Rev Lett 33:258
Bayﬁeld JE, Casati G, Guarneri I, Sokol DW (1989) Phys
Rev Lett 63:364
Beenakker CWJ (1997) Rev Mod Phys 69:731
Benenti G, Casati G, Strini G (2004) Principles of quantum
computation and information, vol I, Basic concepts.
World Scientiﬁc, Singapore
Benenti G, Casati G, Strini G (2007) Principles of quantum
computation and information, vol II, Basic tools and
special topics. World Scientiﬁc, Singapore
Berry MV (1977) J Phys A 10:2083
Berry MV (1989) Proc R Soc A 423:219
Berry MV, Robnik M (1984) J Phys A 17:2413
Berry MV, Tabor M (1977a) Proc R Soc A 356:375
Berry MV, Tabor M (1977b) J Phys A 10:371
Bogomolny EB (1988) Phys D 31:169
Bohigas O, Giannoni MJ, Schmit C (1984) Phys Rev Lett
52:1
Casati G, Chirikov BV (1985) Phys Rev Lett 54:1350
Casati G, Chirikov BV (1995) In: Quantum chaos: between
order and disorder. Cambridge University Press, Cam-
bridge, p 3
Casati G, Prosen T (1999) Phys Rev Lett 83:4279
Casati G, Prosen T (2000) Phys Rev Lett 85:4261
Casati G, Prosen T (2005) Phys Rev A 72:032111
Casati G, Chirikov BV, Izrailev FM, Ford J (1979) Sto-
chastic behavior in classical and quantum Hamiltonian
systems. In: Casati FG, Ford J (eds) Lecture notes in
physics, vol 93. Springer, Berlin
Casati G, Guarneri I, Valz-Gris (1980) Lett Nuovo
Cimento 28:279
Casati G, Chirikov BV, Shepelyanski D (1984) Phys Rev
Lett 53:2525
ColindeVerdiere Y (1985) Commun Math Phys 102:111
Cornfeld IP, Fomin SV, Sinai YG (1982) Ergodic theory.
Springer, New York
Doya V, Legrand O, Mortessagne F, Miniatura C (2001)
Phys Rev Lett 88:014 102
Ellegaard C, Schaadt K, Bertelsen P (2001) Phys Scr
T90:223
Feingold M, Peres A (1986) Phys Rev A 34:591
Fishman S, Grempel DR, Prange RE (1982) Phys Rev Lett
49:509
Fyodorov YV, Savin DV, Sommers HJ (2005) J Phys A 38:
10 731
Galvez EJ, Sauer BE, Moorman L, Koch PM, Richards
D (1988) Phys Rev Lett 61:2011
Gorin T, Prosen T, Seligman TH, Žnidarič M (2006) Phys
Rep 435:33
Gutzwiller MC (1991) Chaos in classical and quantum
mechanics. Springer, New York
Haake F (2001) Quantum signatures of chaos, 2nd edn.
Springer, Heidelberg
Harayama
T,
Fukushima
T,
Sunada
S,
Ikeda
KS
(2003) Phys Rev Lett 91:073 903
Heller EJ (1984) Phys Rev Lett 53:1515
Heller EJ (1991) Chaos and quantum physics. In: Giannoni
MJ, Voros A, Zinn-Justin J (eds) Les Houches, session
LII, 1989. North Holland, Amsterdam, p 547
Henry MK, Emerson J, Martinez R, Cory DG (2006) Phys
Rev A 74:032 617
Horvat M, Prosen T (2003) J Phys A 36:4015
Klappauf BG, Oskay WH, Steck DA, Raizen MG
(1999) Phys D 131:78
Kuhl U, Stöckmann HJ, Weaver R (2005) J Phys A 38:10 
433
Marcus CM, Rimberg AJ, Westervelt RM, Hopkins PF,
Gossard AC (1992) Phys Rev Lett 69:506
Mehta ML (1991) Random matrices. Academic, New York
Müller S, Heusler S, Braun P, Haake F, Altland A (2004)
Phys Rev Lett 93:014 103
Müller S, Heusler S, Braun P, Haake F, Altland A (2005)
Phys Rev E 72:046 207
Nielsen MA, Chuang IL (2000) Quantum computation and
quantum information. Cambridge University Press,
Cambridge
Peres A (1984) Phys Rev A 30:1610
Prosen T (2007) J Phys A Math Theor 40:7881
Richter A (2001) Phys Scr T90:212
Robnik M (1983) J Phys A 16:3971
Shnirelman AI (1974) Usp Math Nauk 29:181
Sieber M (2002) J Phys A 35:L613
Sridhar S (1991) Phys Rev Lett 67:785
Stein J, Stöckmann HJ (1992) Phys Rev Lett 68:2867
Stöckmann HJ (1999) Quantum chaos: an introduction.
Cambridge University Press, Cambridge
Weinstein YA, Lloyd S, Emerson J, Cory DG (2002) Phys
Rev Lett 89:157 902
Zelditch S (1987) Duke Math J 55:919
Žnidarič M, Prosen T (2003) J Phys A Math Gen 36:2463
Quantum Chaos
573

Networks: Structure and
Dynamics
Erzsébet Ravasz Regan
The College of Wooster, Wooster, OH, USA
Article Outline
Glossary
Deﬁnition and Relevance
Introduction
Structural Properties of Complex Networks
Dynamics on Complex Networks
Future Directions
Bibliography
Glossary
Simple graph or network A group of N nodes
(vertices) among which there exist L undi-
rected connections (links, edges), identical in
strength.
Directed graph A group of nodes among which
connections are directed.
Weighted network A group of nodes among
which connections are not identical in strength,
but carry a weight.
Bipartite network A network with more than
one type of node, in which connections only
exist between different node types (the deﬁni-
tion can be relaxed to a network were most, but
not all links run between vertices of different
types).
Adjacency
matrix
A An
N

N
matrix
representing the network, whose elements aij
are equal to 1 when there is a link from node
i to j, zero otherwise.
Degree distribution P(k) The probability that a
node of a network, chosen uniformly at ran-
dom, has degree k.
Scale-free network A network in which the tail
of the degree distribution follows a power law
(strictly speaking, the term scale-free implies
P(k) ~ k–γ, however, it is often used for networks
where the tail of the distribution follows a
power-law).
Degree exponent γ The power law exponent of
the (tail of the) degree distribution.
Scale-free model A growing network model pro-
posed by Barabási and Albert (1999). The model
builds a simple graph starting from a small
connected group of nodes, to which new nodes
are added one by one. These new nodes connect
to m old nodes with probabilities that increase
linearly with the degree of the old nodes.
Shortest path (geodesic path) The smallest col-
lection of links that form a path through the
network from one vertex to another.
Diameter D The length of the largest geodesic
path in a network.
Small-world network A network in which the
average shortest path length grows logarithmi-
cally (or slower) with N.
Node betweenness (betweenness centrality or
load) The number of shortest paths between
nodes of the network that run through a given
node (Freeman 1977).
Edge betweennes The number of shortest paths
between nodes of the network that run through
a given edge.
Clustering coefﬁcient C The fraction of connec-
tions that are realized between the neighbors of
a node:
Ci ¼
2 ni
ki ki  1
ð
Þ ,
where ni denotes the number of links connecting
the ki neighbors of node i. (The average cluster-
ing coefﬁcient is given by C
h i ¼ 1
N
P
iCi. An
alternative global measure of clustering, also
called transitivity, is the fraction of node triples
that are linked into triangles.)
Assortativity coefﬁcient A measure of the ten-
dency of links to run among nodes that are
© Springer-Verlag 2009
B. Chakraborty (ed.), Statistical and Nonlinear Physics,
https://doi.org/10.1007/978-1-0716-1454-9_356
Originally published in
R. A. Meyers (ed.), Encyclopedia of Complexity and Systems Science, © Springer-Verlag 2009
https://doi.org/10.1007/978-3-642-27737-5_356
575

similar in some respect. If the similarity is
described by a scalar quantity (most often the
node’ s degree), then the assortativity coefﬁ-
cient is given by
r ¼
P
x,y xy ex,y  axby


sa sb
,
where x (y) is the scalar at the origin (end) of a
link, ex,y denotes the fraction of all edges in the
network that go from nodes with value x to ones
with value y, ax (by) is the fraction of edges that
start (end) at a link with values x (y), and sa (sb)
is the standard deviations of the distributions of
ax (by) values (Newman 2003).
Modularity Q The number of links between
nodes within the same community minus the
number expected by chance:
Q ¼ 1
2L
X
N
i¼1
X
N
j¼1
Aij  Pij


dgi,g j,
where node i ( j) belongs to the community
gi (gj). Pij gives the expected number of links
between two nodes if the network is random
with respect to communities (Newman and
Girvan 2004). In the simplest case, in which
the null model is a random network, Pij ¼
2 L/N2. A more suitable assumption is Pij ¼
ki kj/2 L, which preserves the degree distribu-
tion of the network in question (the expected
degree of node i is jPij ¼ ki) (Newman 2006).
Definition and Relevance
Scientiﬁc research has had a long history of
bottom-up approaches, which break the system
into small or elementary constituents and map
out interactions between these components. The
Standard Model describing elementary particles
and the four types of interactions governing our
world is perhaps the most successful example.
Biology has developed a very detailed description
of cellular components such as the DNA molecule
or the various proteins and metabolites. Further-
more, many of the interactions that govern a cells
life have been investigated in great detail, but
mainly in isolation: transcription of DNA, protein
assembly, enzyme function, etc. Perhaps not sur-
prisingly, the ﬁrst attempts to understand com-
plexity in physics were focused on small, simple
system with complex dynamics: chaos theory.
Nonetheless, large natural or social systems, like
a cell, an ecosystem or the Internet are much more
intuitive
examples
of
complex
systems.
A
meaningful
description of these
systems
requires more than a mere account of the constit-
uent parts: one does not understand the way the
Internet works by detailing the physical charac-
teristics of computers. Nor is the sequence of a
cell’s genome the ﬁnal tool for understanding its
behavior.
Complex systems display characteristics that
are fundamentally determined by their organiza-
tion, emergent phenomena created by all the
interacting constituents. In many cases, if one
takes a step back, avoiding the details of the inter-
actions, a complex system as a whole is made up of
an assemblage of generic elements and connec-
tions; in other words, it looks like a network. For
example, a cells metabolism is maintained by a
biochemical network, whose nodes are substrates
and links chemical reactions (Jeong et al. 2000).
Equally complex webs describe human societies,
whose nodes are individuals and links represent
social interactions (Wasserman and Faust 1994),
the World Wide Web (WWW) (Albert et al. 1999;
Broder et al. 2000), where nodes are Web docu-
ments connected by URL links, the scientiﬁc liter-
ature, whose nodes are publications and links
citations (de Solla Price 1965; Redner 1998;
Redner 2004), or language, made of words linked
by various syntactic or grammatical relationships
(Dorogovtsev and Mendes 2001b; Ferrer i Cancho
and Solé 2001; Sigman and Cecchi 2002). Due to
the diversity and large number of the nodes and
interactions, the system-level characteristics of
these networks remained largely unknown and
unexplored prior to the last decade. At the same
time, the inability of contemporary science to
address the properties of complex networks limited
advances in many disciplines, including molecular
biology, computer science, ecology and the social
sciences. The recent availability of system-level
576
Networks: Structure and Dynamics

data on the network of interactions in large num-
bers of systems has opened the door for interdisci-
plinary research in ﬁelds where the behavior of the
system as a whole is a central question. Recogniz-
ing generic organizational principles and order
behind diversity and apparent randomness in
these different systems has certainly been a surprise
along the way.
Introduction
The explosion of available data describing inter-
action of hundreds to millions of components in
systems like the Internet or the protein interaction
network is a recent development for the study of
complex systems. Nonetheless, networks are not
new to mathematics or the social sciences. Graph
theory was born from the famous Königsberg
bridge problem and its even more famous solution
by Euler in 1736 (Euler 1741). The problem was
simple: ﬁnd a closed walk that visits each of
Königsberg’s seven bridges once, but only once.
The trouble was, nobody could ﬁnd such a walk.
Euler drew a four-node graph of the pieces of land
connected by the bridges and showed that graphs
that have nodes with odd degrees cannot have
closed self-avoiding paths. (All four pieces of
land in Königsberg are connected via an odd
number of bridges). Euler’s emphasis on the
topology of the bridge problem as key to the
solution marks the starting point of two proliﬁc
subﬁelds of mathematics: topology and graph
theory.
The early 1920’s witnessed the birth of social
network analysis, a subﬁeld of sociology trying to
understand how social interactions organize. Data
gathering methods limited the size of the networks
studied, nonetheless many network measures
important today were deﬁned: degree distribution,
betweenness, clustering and the small world
effect.
In the 1950’s two proliﬁc hungarian mathema-
ticians, Erdős and Rény, took the challenge of
describing the structure of large social networks
from social science to mathematics and formu-
lated their famous random graph model (Erdős
and Rényi 1959, 1960). Their key innovation
was a statistical approach to graph theory: their
theorems were proved on the set of all networks
generated by the rules of their model. Their ran-
dom network rules were simple: take N nodes and
connect each pair with probability p. They found
that above a certain threshold probability the
ensemble
of
random
graphs
undergoes
a
percolation-type phase transition from a graph
made of small disjoint subgraphs to one with a
giant component comparable with the system size.
Random graphs have a Poissonian degree distri-
bution: they are homogeneous networks with a
well-deﬁned average degree. Erdős and Rényi
pointed out that random networks are “small
worlds”: their diameter scales with the logarithm
of system size (node number), quite different from
the power-law relationship that holds for regular
lattices.
The Erdős–Rényi model guided our thinking
about complex networks until the end of the
1990’s, when two seminal papers triggered a
very rapid growth of the ﬁeld which today is
called complex networks research. The ﬁrst
paper, published by Watts and Strogatz (1998),
showed that natural systems such as the neural
network of the C. Elegans worm, the power grid
and the network of movie actors connected by
feature ﬁlms have a topology somewhere between
regular lattices and random graphs. These net-
works have large clustering coefﬁcients, but also
the small world property. The small-world model
presented in the paper is the ﬁrst important step
away from the random world of the Erdős–Rényi
graph. The second paper, published one year later
by Barabási and Albert, showed that the degree
distributions of the movie actor network, the
WWW and the power grid are not Poissonian:
they have a power-law tail, inspiring the term
scale-free networks (Barabási and Albert 1999).
The list of power-law tailed degree distributions
measured on natural and man-made systems is
still growing, with degree exponents that rarely
fall outside the (2,3) interval. Power law degree
distributions tell us that most real networks are
highly heterogeneous: the majority of nodes have
very small degree, but a few hubs with degrees
orders of magnitude larger than the average also
exist, along with nodes with degrees of all scales
Networks: Structure and Dynamics
577

in between. A good example is the US airport
network connected by direct ﬂights: Chicago and
Atlanta at the high end of the degree scale, the
numerous regional airports at the low end.
Naturally, the sudden explosion of data and
tools to explore them brought us closer to the
heart of questions fundamental to understanding
complex systems: what drives their organization,
what deﬁnes their emergent properties. What do
these networks do, what is their function? This
question is natural to biology. A metabolic net-
work has a well-deﬁned job in the living cell: it
fuels the cell with energy, nutrients and building
blocks, and it does so adaptively and robustly.
Man-made complex networks, such as the Internet
or WWW, the power grid or the network of syn-
onyms in a language also perform well-deﬁned
functions. In contrast with the delicate and well-
thought-out internal structure of a computer, these
systems were not designed from scratch with their
function in mind: they evolved and emerged nat-
urally. Also in contrast with the fragility of a
computer (pull out a random element and it stops
working), complex systems in biology and tech-
nology have a remarkable resilience to random
node failure: the internet does not die when a
few routers go down, in fact this probably is its
normal mode of operation.
Questions about the characteristics mandated
by function, common to all these systems, along
with questions about the selection principles that
shape these structures, are at the heart of our quest
to understand complex function. These questions
are typically formulated in terms of the dynamics
natural to the network in question: metabolic ﬂux
driven by enzymes, packet trafﬁc on the internet,
web browsing, electric current ﬂow on the power
grid, the spread of HIV on the sexual contact
network, etc. Understanding how structure affects
dynamics and vice versa is in the spotlight of
complex networks research today.
Structural Properties of Complex
Networks
Let us look at the metabolism of a cell as an
example that highlights the increasingly detailed
ways one can pose the question: what is the large-
scale structure of cellular metabolism? At ﬁrst
glance, the metabolic network is a simple graph
in which metabolites (the nodes) are connected by
chemical reactions. This representation tells us
whether the network is homogeneous in degree
or has hubs, whether it is a “small world”, whether
it has a community structure. A more detailed
description of the system takes into account the
direction of chemical reactions, since a large num-
ber of them are not reversible in a living cell. This
leads to a directed network in which the in- and
-out-degree distributions can be different and
paths are directed. The next step is a weighted
network: metabolites are characterized by their
concentrations in the cell, edges are weighted by
ﬂuxes carried by reactions. A different way of
adding complexity to the representation is by
constructing a bipartite graph, where metabolites
on one side connect to reactions on the other.
The above example suggests a natural organi-
zation for this section: presentation of simple
graphs and their characteristics followed by
more detailed networks, in parallel with speciﬁc
real-world examples and models.
Simple Graphs
Degree Distribution
The Königsberg bridge
network had only four nodes; the network exam-
ples we cite nowadays have from hundreds to
millions. Most of them show a degree heteroge-
neity best captured by the degree distribution,
which carries more information than the average
degree, as pointed out by Barabási and Albert
(1999). Examples of scale-free networks include
networks of metabolic reactions (Jeong et al.
2000), genetic regulatory interactions (Milo et al.
2002; Shen-Orr et al. 2002; Thieffry et al. 1998),
earthquake
event
correlations
(Baiesi
and
Paczuski 2004), word co-occurrence and syno-
nyms (Dorogovtsev and Mendes 2001b; Ferrer i
Cancho and Solé 2001; Motter et al. 2002;
Sigman and Cecchi 2002), power lines (Albert
et al. 2004; Watts and Strogatz 1998), air routes
(Amaral et al. 2000; Barrat et al. 2004), the Inter-
net (Broida and Claffy 2001; Faloutsos et al.
1999; Govindan and Tangmunarunkit 2000), the
World Wide Web (Adamic 1999; Adamic and
578
Networks: Structure and Dynamics

Huberman 2000; Albert et al. 1999; Kleinberg
et al. 1999; Kumar et al. 1999), software systems
(Myers 2003), Wikipedia links (Capocci et al.
2006), phone calls (Aiello et al. 2000), e-mails
(Ebel et al. 2002), coauthorship (Barabási et al.
2002;
Newman
2001b),
scientiﬁc
citations
(Redner 1998), World trade (Serrano and Boguñá
2003), innovation ﬂow (Di Matteo et al. 2005),
sexual partnership (Liljeros et al. 2001) and the
list goes on.
Barabási and Albert had a much shorter list of
examples to work with in 1999. Nonetheless, they
saw that three very different networks, the actor
network, power grid and World Wide Web had
similar degree distributions, different from that of
a random network model. They argued that the
Erdős–Rényi random network model lacks two
important features present in real-world systems.
First, it is a static model, while most real-world
networks constantly evolve and grow. Second, the
random network model is too democratic: the
probability of linking any two nodes is constant.
Barabási and Albert proposed that in real net-
works the nodes that already have a large degree
are more likely to receive new links as the network
grows (think of Google in the WWW network).
Preferential attachment accompanied by network
growth was the ﬁrst mechanism ever reported to
reproduce the scale-free (power-law) degree dis-
tribution seen in real networks. Interestingly,
though, Barabási and Albert were not the ﬁrst to
report it. A sociologist named Price reported the
ﬁrst example of a scale-free network back in 1965,
that of citations linking scientiﬁc papers (de Solla
Price 1965). Building on the “the rich get richer”
idea proposed to explain wealth distributions,
Price constructed a network model for citations
in which the more citations a paper has, the more
likely it is to acquire further citations (de Solla
Price 1976).
The scale-free model, simple and analytically
solvable, propelled scale-free networks and pref-
erential
attachment
to
the
forefront
of
the
expanding ﬁeld of complex networks research.
Barabási and Albert showed that both growth
and preferential attachment are essential for
obtaining a scale-free network. Growth along
with uniform attachment leads to an exponential
degree distribution, while no growth with prefer-
ential attachment leads to a Gaussian distribution
(although the system does start out with a transient
power law) (Barabási et al. 1999). They also con-
sidered the effects of random rewiring and internal
link formation, showing that internal link dynam-
ics cause deviation from the power-law at low
degrees, observed in real-world networks (Albert
and Barabási 2000). A variety of models and
analytical methods were developed in the wake
of these papers, addressing the effects of further
changes in rules of growth or attachment on the
degree distribution. The exact solution for the
degree distribution of the Barabási–Albert model
was worked out by graph theorists Bollobás and
Riordan (Bollobás et al. 2001).
One of the most important generalizations of
the original scale-free model was the study of
nonlinear preferential attachment by Krapivsky
and
Redner
(Krapivsky
and
Redner
2001;
Krapivsky et al. 2000). They found that power-
law scaling is destroyed by nonlinearity: sublinear
attachment leads to a power law multiplied by a
stretched exponential, while faster than linear
attachment causes the network to “condense”:
the fraction of nodes connected to a single super-
hub is ﬁnite in the thermodynamic limit. Indeed,
the simple linear attachment rule of the scale-free
model was later veriﬁed in real systems: citation
networks, the Internet, the actor and scientiﬁc
collaboration
networks
(Jeong
et
al.
2003;
Newman 2001a).
Variations on the scale-free model include lin-
ear preferential attachment offset by a constant
(Dorogovtsev et al. 2000), internal edge creation
and removal (Dorogovtsev and Mendes 2000;
Krapivsky and Redner 2002), growing average
degree (Dorogovtsev and Mendes 2001a) (seen
in
the
WWW
and
co-authorship
networks
Barabási et al. 2002), and edge rewiring (Albert
and Barabási 2000; Tadić 2001). One of the chal-
lenges of modeling the WWW with the original
scale-free model was spotted by Adamic and
Huberman: while the oldest nodes are the ones
with the highest degree in the model, the WWW
does not show this correlation (Adamic and
Huberman 2000). Bianconi and Barabási pro-
posed a multiplicative ﬁtness model (Bianconi
Networks: Structure and Dynamics
579

and Barabási 2001a) in which the attachment rule
is inﬂuenced by the degree as well as the “worth”
of a node. This model generates both scale-free
networks and “winner takes all” scenarios; the
transition between the two outcomes maps beau-
tifully
onto
a
Bose-Einstein
condensation
(Bianconi and Barabási 2001b).
The presence of preferential attachment can be
justiﬁed in many real systems such as the WWW,
citation, collaboration or airport networks through
the larger visibility of high-degree nodes and the
advantage nodes gain by linking to them. There
are, however, scale-free networks where a differ-
ent mechanism leading to preferential attachment
is necessary. Biological networks offer intriguing
examples: the metabolic and the protein-protein
interaction networks are scale-free, even though
their connections are governed by biochemistry
and not choice. Protein interaction networks have
inspired a class of models based on gene duplica-
tion (duplication of a node and all it’s links) and
subsequent mutation (addition and/or deletion of
some of the copy’s links) (Solé et al. 2002;
Vázquez et al. 2003). Preferential attachment in
these models is a consequence of the evolutionary
dynamics: nodes with a higher degree have more
duplicating neighbors, thus receiving more links.
Vertex (node) copying has been proposed as a
possible mechanism for the growth of the WWW
(Kleinberg et al. 1999) and auto-catalytic net-
works (Jain and Krishna 1998).
In the spirit of the Erdős–Rényi model, Bender
and Canﬁeld proposed an ensemble model for
scale-free networks. The conﬁguration model
describes the group of all networks with a pre-
scribed degree sequence (Bender et al. 1997). If
the sequence is chosen from a power-law distri-
bution, the resulting networks are naturally scale-
free. However, the average properties of the
ensemble carry no other characteristics intrinsic
to evolving models (such as degree correlations or
clustering). Moreover, the simple deﬁnition of the
model makes it ideal for analytical approaches.
Newman et al. used probability generating func-
tions to calculate exact expressions for average
path length and clustering in conﬁguration net-
works. (They used a generalized deﬁnition: the
ensemble of all networks with an ensemble of
degree sequences drawn from the same distribu-
tion.) (Newman et al. 2001). Many analytical
results for scale-free networks were proven using
the conﬁguration model: they have asymptotically
vanishing clustering coefﬁcients (Davidsen et al.
2002) and they are ultra-small for the degree
exponents measured on most real-world networks
(γ  (2, 3)): their average path length scales as
O log log N
ð
Þ (Cohen and Havlin 2003).
Some real networks are embedded in physical
space and have physical connections: brain net-
works, the power grid, the Internet, airport net-
works, streets, public transportation systems,
highways and rivers. Some of the above examples
(brain networks, streets, rivers) are missing from
the list of scale-free networks: spatial constraints
can be forbidding to the formation of hubs. Sev-
eral studies with both preferential attachment and
bias towards shorter links show that large length
costs can destroy the scale-free nature of spatial
networks (Barthélémy 2003; Manna and Sen
2002; Xulvi-Brunet and Sokolov 2002). Systems
with ﬁxed maximum link length, such as wireless
networks in which the range of a particular device
is much smaller than the physical size of the
system are not scale-free. Conformation networks
made of all physically allowed conformations of a
system (a polymer or bead chain) are also homo-
geneous structures naturally embedded in an
n-dimensional conﬁguration space deﬁned by the
system’s degrees of freedom (Ravasz et al. 2007;
Scala et al. 2001).
The distribution of nodes in space can also
have great inﬂuence on network topology, as
shown in a detailed study of the Internet by
Yook et al. (2003). They found that the router
density distribution is a fractal with the same
dimension D ¼ 1.5 as the population density
distribution. They were able to mimic the topol-
ogy of the Internet using a simple evolving model
in which nodes are distributed according to a
fractal distribution and incoming nodes connect
to old ones using preferential attachment divided
by some power of their distance. Interestingly, the
only model parameters able to reproduce the inter-
net’s topology were the ones actually measured
for the real system: fractal dimension D ¼ 1.5,
linear preferential attachment and a probability of
580
Networks: Structure and Dynamics

connecting two nodes that is inversely propor-
tional to the distance between them. A similar
model was also successful in describing the topol-
ogy of the world-wide airport network (Guimerà
and Amaral 2004).
Paths on Networks, Small Worlds and
Betweenness
A networks’ most basic function
always requires some type of communication
along its edges. Thus it is natural that average
shortest
paths,
network
diameter
and
local
betweenness measures are of great interest to net-
works research. Erdős and Rényi proved that the
diameter of their random network model scales as
the logarithm of node number. Watts and Strogatz
called such networks small worlds (Watts and
Strogatz 1998), in tribute to the “small world
phenomenon” in sociology: the idea that one can
connect any two people on Earth by about six
handshakes between mutual acquaintances. In
1967, an ingenious experiment by Milgram pro-
ved the existence of short paths of an average six
hops between random people in the US, known as
“six degrees of separation” (Milgram 1967). The
small word nature and searchability of small-
world networks allow movie lovers to ﬁnd short
chains of movies connecting their favorite actor to
Kevin Bacon. Mathematicians (and networks
researchers)
play
the
same
game
on
the
co-authorship network: one’s shortest path to Pál
Erdős is called the Erdős number.
The small world model introduced by Watts
and Strogatz is based on the idea that real net-
works are in between random graphs and regular
lattices: they are highly clustered (as a regular
lattice), but they also have shortcuts. The model
is built starting with a regular low-dimentional
lattice to which one adds (or rewires) a certain
number of edges, shortcuts between distant parts
of the lattice (Watts and Strogatz 1998). Watts and
Strogatz showed that increasing the number of
shortcuts turns regular lattices into random net-
works, moreover, a small number of shortcuts is
sufﬁcient for the small-world effect without
destroying the high clustering coefﬁcient of the
original lattice (Newman and Watts 1999; Watts
and Strogatz 1998). Most real networks display
both characteristics of the small world model:
short average path lengths and high clustering.
However, the small world model has a peaked
degree distribution, thus the topology of real net-
works with scale-free degree distribution is fun-
damentally different from the ones generated by
the model. The Barabási–Albert scale-free model,
on the other hand, fails to account for the high
clustering of most real networks.
Logarithmic or slower increase of the average
path length was proved for a variety of network
models (Bollobás and Riordan 2004; Bollobás
and de la Vega 1982; Chung and Lu 2002).
Bollobás and Riordan showed that the average
shortest path length in scale-free networks grows
no faster than log N/ log(log N) (Bollobás and
Riordan 2004). Cohen and Havlin used the con-
ﬁguration model to show that random scale-free
networks with γ  (2, 3) are ultra-small: their
average shortest path length grows as log(log N)
(Cohen and Havlin 2003).
The structure of shortest paths is crucial to any
communication or ﬂow between nodes of a net-
work. Naturally, betweenness was found to be the
relevant quantity when one deals with congestion
or disruption of ﬂow in networks. Goh et al. mea-
sured the distribution of node betweenness values
for a variety of real networks as well as models,
and showed that it follows a power-law with only
two distinct exponents (Goh et al. 2002).
Clustering and Network Motifs
Clustering
is a rediscovery of “network density”, a quantity
widely used in sociological network analysis: it
provides a measure of how well one’s acquain-
tances know each other. High values have been
observed in social networks, but also in most other
real-world networks, motivating the development
of clustered scale-free models. The Holme–Kim
model, aimed at creating scale-free networks that
also have high clustering coefﬁcients, is a straight-
forward generalization of the scale-free model,
with triangle-forming steps complementing pref-
erential attachment (Holme and Kim 2002a).
Klemm and Eguíluz introduced a citation network
model based on the idea that papers are only cited
for a limited stretch of time before they are for-
gotten (Klemm and Eguíluz 2002). The model is
built by the constant addition of nodes that con-
nect to all “active” nodes and join their ranks.
Then, one of the active nodes is deactivated with
Networks: Structure and Dynamics
581

a
probability
inversely
proportional
to
its
in-degree (offset by a constant). This model
leads to scale-free networks with high clustering
coefﬁcient, but fails to capture their small-world
nature: visualized, the networks look like tubes.
Gene duplication models, while motivated by
evolutionary arguments, also lead to clustered
scale-free networks (Solé et al. 2002; Vázquez
et al. 2003).
An interesting generalization of the clustering
coefﬁcient was introduced by Uri Alon’s group:
network motifs are signiﬁcantly over- or under-
represented
patters
of
connections
between
n vertices (compared to the randomly rewired
network). Distinct characteristic motifs were
found in regulatory networks, food webs, neural
networks and WWW, corresponding to local func-
tions performed by the network (Milo et al. 2002;
Shen-Orr et al. 2002). For example, different
types of feed-forward loops (FFLs, directed
motifs of 3 nodes: A ! B, B ! C and A ! C)
in genetic regulatory networks perform distinct
signal processing roles as shown by both simula-
tion and experiments with living cells (Alon
2007). FFLs made of activating iterations only
(abundant in the regulatory network) can ﬁlter
out transient changes in the concentration of the
input node, while also delaying the turn-on or
turn-off of the output node. On the other hand,
FFLs where the B ! C link is a repressing one
(also abundant) act as pulse generators.
Degree Correlations and Mixing Patterns
In social networks, links between people who are
alike are more common; popular people are
connected
with
popular
people.
Assortative
mixing means that degrees at two ends of an
edge are correlated, as measured by the condi-
tional probability, P(k0|k), that a node with
k links is connected to another one with k0 links.
Measurements on the Internet and protein interac-
tion networks show that in these system, as
opposed to their social counterparts, small degrees
are more likely to connect to high degree nodes
(Maslov and Sneppen 2002). The conditional
probability is difﬁcult to measure in most real
networks due to poor statistics, although it is
convenient in analytical work. A more compact
representation of degree correlations was deﬁned
by Pastor-Satorras et al. (2001): the average
degree of neighbors as a function of degree,
knn(k), which decreases with k for disassortative
systems. One can further simplify the measure of
assortativity by calculating the Pearson correla-
tion coefﬁcient of degrees at the ends of a net-
work’s
edges:
the
assortativity
coefﬁcient
(Newman 2002a; Newman 2003). Intriguingly,
most social systems are assortative (actor net-
work, company directors, coauthorship networks,
phone calls, email address books), while most
technological
and
biological
systems
prefer
disassortative mixing (WWW, Internet, train
routes, software packages, software classes, elec-
tronic circuits, peer-to-peer networks, metabolic
networks, food webs, neural networks).
Degree is not the only property of a network
that can show assortative or disassortative mixing.
In networks where nodes can be classiﬁed in types
of some kind, mixing between types can also be
characterized by the assortativity coefﬁcient (see
“Deﬁnition”). Maslov et al. showed that there are
three main types of nodes in the Internet: high
level providers who manage the backbone and
trunk lines, Internet Service Providers who bring
the network out to end-users and the end-users
themselves. These three types show strong
disassortativity: few end-user to end-user or ISP
to ISP links in the network. In social networks,
mixing by race, age or income has been observed
(Newman 2003).
Communities,
Hierarchy and Fractality
Community structure is an intuitive feature of com-
plex networks: one expects them in social systems
(circles of friends), biological networks (functional
units), the WWW (websites related to a topic or
organizations), co-authorship networks (scientiﬁc
ﬁelds and sub-ﬁelds), etc. Communities within net-
works are structural features related to the function
of the network as a whole, and are thus expected to
have a strong inﬂuence on their dynamics. Deﬁn-
ing and ﬁnding network communities has its his-
tory in both sociology and computer science, and
has been revisited many times. The methods devel-
oped along the way paint a rich picture of the
structural diversity of complex networks.
Non-Overlapping
Community
Structure
Hierarchical clustering or cluster analysis is
582
Networks: Structure and Dynamics

widely used in the study of social networks. The
ﬁrst step in hierarchical clustering is the construc-
tion of a similarity measure between network
nodes. Next, each node is assigned to a separate
cluster (the leaves of the dentogram). The two
most similar clusters are joined to form junctions
of the dentogram, until all clusters have been
united, forming the root. Many similarity mea-
sures have been deﬁned and used successfully.
Structural equivalence, used in social network
analysis, gives two nodes the highest similarity
score if they have the same pattern of relation-
ships. It can be measured using Euclidean dis-
tance or Pearson correlation coefﬁcient between
rows of the adjacency matrix, as well as topolog-
ical overlap, deﬁned as the number of overlapping
neighbors divided by the smaller of the two
degrees (Ravasz et al. 2002).
Girvan and Newman introduced a famous com-
munity detection algorithm that is similar to hier-
archical clustering, but works divisively (Girvan
and Newman 2002). It is based on the idea that
the edges most likely to run between communities
are the ones that have the highest edge betweenness
centrality. They ﬁrst remove the edge with the
highest
betweenness,
then
recompute
edge
betweenness and keep removing edges until the
network falls apart into non-connected nodes. As
the network falls appart, they draw a dentogram
where each joint is a splitting event.
Hierarchical clustering works with varying suc-
cess for different systems, but it cannot determine
how many communities there are in the network.
Newman et al. introduced an elegant measure for
the “quality” of any given partitioning into com-
munities, called modularity, which compares a
community partitioning to a null model that can
be appropriately chosen for the system at hand
(Newman 2006). The Girvan–Newman algorithm,
together with the dentogram cut that maximizes
modularity, has been successfully used for many
different social and biological networks (Arenas
et al. 2004; Boguñá et al. 2004; Guimerà et al.
2003; Newman and Girvan 2004; Tyler et al.
2003; Wilkinson and Huberman 2004). The main
drawback of the method is computation time
(O N3


on a sparse graph): it is not feasible for
networks with more than a few thousand nodes.
In a quest to develop a faster community detec-
tion method closely tied to the deﬁnition of com-
munities, Newman used direct optimization of the
modularity measure (Newman 2004). Since ﬁnd-
ing the best partitioning is an NP-hard problem, his
ﬁrst approach was a greedy optimization. All nodes
start out as separate communities, which are then
repeatedly joined such that the increase in modu-
larity is maximal (or decrease is minimal). New-
man showed that the method works well both in
tests and real networks, and it works quite fast:
O N2


time for sparse graphs. Still not fast enough?
A collaboration with Clauset and Moore resulted in
an algorithm that performed the same optimization
in O N log 2N


for sparse graphs with many levels
of communities (Clauset et al. 2004), solving the
problem of partitioning networks with billions of
nodes.
(The
general
result
for
runtime
is
O KD log N
ð
Þ,
where K is the total number of
links and D is the depth of the generated
dentogram).
Interested in the theoretical foundations of
community structure detection and its relationship
to matrix spectra, Newman argued that commu-
nity detection requires the use of the modularity
matrix (Newman 2006) in place of the Laplacian
matrix, as done by traditional spectral methods of
graph partitioning. (The Laplacian matrix of a
graph, L, is a real symmetric matrix with elements
Lij ¼ ki δij – Aij) The modularity matrix is deﬁned
as Bij ¼ Aij – Pij (see “Modularity Deﬁnition”). He
showed that the eigenvalues and eigenvectors of
the modularity matrix encode the networks’s com-
munity structure. Methods based on this relation-
ship perform as well, if not better, than previous
ones, but more importantly, they are also able to
detect
“anti-modular”,
or
bipartite
structure
(Newman 2006).
Hierarchical Community Structure and Frac-
tal Networks
Ravasz et al. argued that in many
real networks with interesting modular structure
there is no ideal partitioning into distinct modules:
the network is built of small, very cohesive com-
munities, hierarchically embedded in larger, less
cohesive ones (Ravasz and Barabási 2002; Ravasz
et al. 2002). Their hierarchical model is a deter-
ministic construction of a scale-free network with
hierarchically embedded modules. They showed
Networks: Structure and Dynamics
583

that hubs on all scales unite communities on all
scales: small nodes are part of small, very cohe-
sive clusters (thus have large clustering coefﬁ-
cients), larger nodes serve as connectors of these
clusters, while the largest hubs span modules at
the highest level or organization (and have low
clustering coefﬁcients). Indeed, they found that
the clustering coefﬁcient C(k) decreases with
increasing k in a variety of real networks, such
as the metabolic network, synonyms, movie
actors, the WWW and the Internet represented at
Autonomous System level (each node is a
domain, not just a computer), and it often scales
as 1/k (Ravasz and Barabási 2002). This scaling
was found in a variety other networks: software
systems (Myers 2003), the World Trade network
(Serrano and Boguñá 2003), the worldwide air-
port network, the co-authorship network of http://
arxiv.org/archive/cond-mat (Barrat et al. 2004;
Newman 2001b) and protein folding networks
(Rao and Caﬂisch 2004). Not all networks are
hierarchical: the power grid and the Internet at
router level show no scaling of the clustering
coefﬁcient (Ravasz and Barabási 2002). Ravasz
et al. suggested that spatial embedding of both
systems, where length costs are signiﬁcant,
works against hierarchical modularity. Both net-
works distribute something to a physical area.
Thus, the formation of tight communities is not
required for these networks to function.
Hierarchical organization in metabolic net-
works was found to reﬂect biological function
on different scales of organization: the branches
of the dentogram obtained by hierarchical cluster-
ing (using topological overlap as similarity mea-
sure) correspond to known functional classes of
the metabolism on two different levels of organi-
zation (Ravasz et al. 2002).
The question of self-similarity or fractal nature
has been on the mind of network researchers since
the scale-free degree distribution was observed.
Are networks like fractals, self-similar on all
scales? Hierarchical organization strengthens this
image: most networks not only have degrees in a
broad range of scales, they are also made of mod-
ules of different scales embedded into each-other.
The problem with complex networks as fractals
was, of course, that most networks of interest to us
are also small-world (Watts and Strogatz 1998). In
a small-world network the number nodes at a
distance l from any given node increases expo-
nentially. One expects this number to grow as a
power law in the case of a fractal object: measur-
ing the “mass” within distance l from a point on
the object, called the cluster growing method, is
one way of measuring fractal dimension.
While some deterministic models have been
constructed with the idea of fractality in mind
(Dorogovtsev et al. 2002; Jung et al. 2002), the
breakthrough in understanding topological self-
similarity in complex networks was brought
forth by Song, Havlin and Makse (Song et al.
2005; Song et al. 2006). They generalized the
standard box counting method for measuring frac-
tal dimension of a physical object to complex
networks. How does one cover a network with
boxes of different size? Divide all nodes in groups
such that the shortest path between any two nodes
in a group is at most lB long: these are the boxes.
Use the smallest number of groups necessary to do
this (or a decent approximation) and repeat it for
lB  [2, D]. The results of this procedure were
quite surprising: many scale-free real-world net-
works, such as the WWW, actor network and
various metabolic networks show a neat fractal
scaling between the number of boxes and their
size. Thus these networks are self-similar, fractal
structures. To prove their point further, the authors
used a renormalization procedure where they col-
lapsed each box into a node and linked these new
nodes to each other if any member of the original
boxes
had
a
connection.
The
networks
renormalized this way were also a scale-free,
with the same degree distribution exponent, inde-
pendent of the box size used for renormalization
(Song et al. 2005).
The question of how these networks are small
world and self similar at the same time has also
been resolved: the two methods of determining
the fractal dimension of an object, box counting
and cluster growing are not equivalent on com-
plex networks with broad degree distribution.
While box counting covers all the hubs only
once (they are assigned to one box only), cluster
growing ﬁnds the hubs for almost any choice of
seed node, thus bringing a large part of the
584
Networks: Structure and Dynamics

network into the cluster with them. This explains
the exponential increase in the number of nodes
within a distance l, and shows the small-world
property of the system. Box counting, on the
other hand, can reveal the fractal nature of the
network, if present (Song et al. 2005).
Song et al. uncover some of the requirements of
fractality via proposing a network growth model
based on reverse renormalization. Starting from
one point, the network grows by nodes trans-
forming into small clusters in each iteration. The
conversion from a node to a small cluster mimics
the renormalization process in reverse: the degree
of a node grows by multiplication with a scaling
factor (thus nodes of previous iterations become
the hubs). The newly formed clusters have a diam-
eter of bB (the box size). They showed that the key
feature that inﬂuences fractality in the emerging
networks is how the clusters connect: if the link
always runs between the hubs (leading to assorta-
tive mixing), the result is small-world network that
is not a fractal. The internet at router level, found to
be non-hierarchical, is a good example of such an
assortative, non-fractal network. On the other hand,
if the clusters only connect to each other via the
non-hub (newly created) nodes, the resulting net-
work is a fractal, but it loses it’s small-world char-
acter. Many real-world networks, however, seem to
be both fractal and small-world (WWW, actor net-
work, protein interaction networks, metabolic net-
works). Indeed a very small number of hub-to-hub
connections in this model can restore the small-
world property of the network while preserving its
fractal nature.
Overlapping Community Structure
The com-
munity detection methods presented thus far
assign each node to only one community. Palla
et al. argued that many nodes in real networks
belong to more than one community (Palla et al.
2005): proteins can simultaneously be part of
several complexes, people have disjoint groups
of acquaintances from friends to work to extended
family. They proposed a community deﬁnition
that allows them to capture overlap between com-
munities. Their method is based on “k-clique
rolling”: a k-clique community is the union of all
k-cliques (complete subgraphs of size k) that can
be connected through a series of k-cliques that
share k – 1 nodes. Increasing values of k lead to
smaller, denser, but more disjoint communities.
They ﬁnd that k-clique communities in real net-
works (co-authorship, word association and pro-
tein interaction networks) have a power-law size
distribution, and there are signiﬁcant overlaps: the
size distributions of overlap as well as node mem-
bership have fat tails.
Directed Networks
Directionality of a link is often important in real
networks: scientiﬁc citations, url links, genetic reg-
ulatory interactions are only a few examples of
inherently asymmetric connections. Directed links
require the separate measurement of in- and out-
degree distributions. In case of the WWW both are
power-laws, but the degree exponents differ:
PWWW
in
k
ð Þ  k2:1 and PWWW
out
k
ð Þ  k2:45 (Albert
et al. 1999). Genetic regulatory networks show an
even stronger difference. Their out-degree distribu-
tions are power laws, however, the in-degree ones
are scaled: genes cannot receive input from hun-
dreds of transcription factors.
Another interesting consequence of directed
links is the rich structure of directed paths. They
were found to partition the WWW as well as met-
abolic networks into parts resembling a bow-tie
(Broder et al. 2000; Ma and Zeng 2003): a strongly
connected component, in which there is a directed
path in both directions between any pair of nodes,
an IN-component, the nodes of which can reach the
strongly connected component bot cannot them-
selves be reached, and an OUT-component that
can be reached from, but has no directed paths
leading into the strongly connected component.
Not all directed networks have bow-tie structure:
some of them are entirely acyclic, with no directed
loops. Citation networks are a natural example: one
can only cite papers already published. However,
genetic regulatory networks are also acyclic (not
considering auto-regulatory loops), even though
the cause of this is now yet understood (Balázsi
et al. 2005; Thieffry et al. 1998).
Gradient networks are directed graphs that gen-
eralize the concept of gradients from continuous
scalar ﬁelds to networks. They capture the back-
bone of a gradient-induced ﬂow on complex net-
works: given a substrate graph with a scalar value
Networks: Structure and Dynamics
585

associated to every node, its gradient network is
formed by the collection of all directed links that
lead from every node to its neighbor with the
highest
scalar value (Toroczkai and
Bassler
2004). These directed links form collections of
trees. For an independent, identically distributed
association of random variables to the nodes of an
Erdős–Rényi graph, the generated gradient net-
work has been shown to be scale-free, with a con-
nectivity exponent of γ ¼ 1. This ﬁnding can be
proved for any substrate graph with no loops
shorter than 5 (Toroczkai et al. 2004). Moreover,
the gradient networks’scale-free nature seems to be
universal: it was numerically observed for a wide
variety of substrate networks (including ones with
short loops): regular and random trees, Erdős–
Rényi and small-world networks, high dimensional
regular lattices and n-tori, random geometric net-
works (Dall and Christensen 2002), the scale-free
and the conﬁguration model (Ravasz et al. 2007;
Toroczkai et al. 2004).
Weighted Networks
Real world networks display signiﬁcant heteroge-
neity in the strength of their connections. The dis-
tribution of link weights has been found to have a
heavy tail in metabolic networks: the steady-state
ﬂux distribution follows Θ(w) ~ (w0 þ w)–1.5(w0 ¼
3  104) (Almaas et al. 2004). Moreover, the
average link strength scales with the connectivity
of the nodes at the two ends as hwiji ~ (ki kj)0.5 in
both metabolic networks and the Worldwide Air-
port Network, indicating correlations between
node degree and links weights (Almaas et al.
2004; Barrat et al. 2004). Scientiﬁc collaboration
networks, on the other hand, have a weight distri-
bution that is not correlated with degree.
The existence of weighted links requires a gen-
eralization of most network measures:
•
Node strength and strength distribution.
Node strength, si is a natural generalization of
the node degree, ki:
si ¼
X
N
j¼1
wij Aij,
the sum of weights over the links of node i. The
strength distribution, P(s), is typically also heavy
tailed (Barrat et al. 2004). Weights are often
dependent upon topology (see “Metabolic and
Airport Networks”), expressed by a nonlinear
relationship between node strength and degree:
s ~ kβ (in the airport network β ¼ 1.5). Heteroge-
neity in the weights around a node can be mea-
sured using
Yi ¼
X
N
j¼1
wij
si

2
Aij:
If all edges have the same weight, Y(k) scales as
1/k, while if one weigth is signiﬁcantly larger than
the others, Y(k) ’ 1. In metabolic networks Y(k)
was found to scale as k–0.27, indicating that metab-
olites used in a large number of reactions are more
likely to have one high-ﬂux reaction dominating
their production (consumption) (Almaas et al.
2004).
•
Weighted clustering coefﬁcient. Deﬁned by
Barrat et al. as
CW
i ¼
1
si ki  1
ð
Þ
X
N
j¼1
X
N
m¼1
wij þ wim
2
Ajm Aij Aim,
the weighted clustering coefﬁcient is often com-
pared to the standard one: CW > C means that the
triangles of the network are preferentially formed
by high-weight links. This is indeed the case in the
coauthorship network, for nodes with k > 10: more
established investigators form stable, high-weight
cliques (research groups) from which the main
volume of their publications originate. A similar
phenomenon can be seen in the world-wide air-
port network: larger airports form high passenger-
ﬂux triangles, so called “rich-clubs” (Barrat et al.
2004).
•
Degree Correlations. The weighted average
degree of neighbors is deﬁned as:
kW
nn,i ¼ 1
si
X
N
j¼1
wij k j Aij,
a sensitive probe into the structure of weighted
networks. The behavior of knn(k) in the airport
586
Networks: Structure and Dynamics

network shows a plateau for airports with more
than 10 direct ﬁghts, indicating no degree prefer-
ence. However, kW
nn k
ð Þ increases in a wider range
and is in general larger knn(k), showing that while
large airports do not preferentially connect to
large airports, the high trafﬁc links run among
members of the “rich-clubs” (Barrat et al. 2004).
Dynamics on Complex Networks
The main theme of this section is: how does the
structure of a network inﬂuence its dynamics?
Most lessons of statistical mechanics are worth
revisiting when the underlying space is a network:
does an inhomogeneous topology change the
dynamics? The answer, as we will see, is yes, in
interesting ways.
Robustness and Vulnerability of Complex
Networks
Perhaps the most intriguing feature of complex
systems is their robustness. Close to 75% of the
genes in E. coli are non-essential: the organism
can survive without them (under one set of growth
conditions) (Gerdes et al. 2003). If the webpage of
a company or university goes down, the WWWas
a whole is still perfectly functional, the effect of
the failure is local. On the other hand, an inten-
tional “attack”, similar to the denial-of-service
attacks that crippled Yahoo, Amazon, eBay,
CNN and a few other very popular websites in
February of 2000, can substantially cripple the
function of a complex system.
Vulnerability and robustness go hand in hand
in most complex systems: bad weather in Atlanta
(although usually not labeled an “attack”) has
very different consequences for air trafﬁc than
problems at a regional airport. Opinions expressed
in the New York Times are much more likely to
spread and inﬂuence events than opinions in a
small town local newspaper. These trivial exam-
ples
hint
at
interesting
consequences
of
in-homogeneous network topology, brought to
light in a 2000 Nature paper by Albert et al.
(2000): while scale-free networks are largely
unaffected by random failure, they are very sensi-
tive to change in their highly connected, central
nodes, rendering them vulnerable (and/or respon-
sive) to planned, targeted interventions.
Resilience
One of the simplest indicators of
robustness under the damage done by node or link
removal is a structural one: the size of the largest
connected
component.
Numerical
studies
performed by Albert et al. show that the giant
connected component of Erdős–Rényi random
networks falls apart at a much lower fraction of
randomly removed nodes that of a scale-free net-
work (Albert et al. 2000). A fraction of nodes the
removal of which causes a random network to
falls into pieces, only slightly shrinks the giant
component of a scale-free network, while small
fragments of the system become isolated. An
attack, on the other hand, where the most
connected nodes are the ﬁrst to be removed,
shows a different picture. While the Erdős–
Rényi random network falls appart somewhat
faster but in essentially the same way, a scale-
free network is blasted appart by the removal of
a much lower fraction of nodes. The results hold
for simulations using the actual network topolo-
gies of the Internet and WWW (Albert et al. 2000;
Broder et al. 2000).
The topological aspects of random node or
edge removal can be calculated by mapping ran-
dom failures to percolation problems. Cohen et al.
have shown that uncorrelated random networks
with a diverging second moment of their degree
distribution (scale-free networks with degree
exponents between 2 and 3) have zero percolation
thresholds (Cohen et al. 2000). Vázques and
Moreno used an approach that allowed them to
investigate the percolation properties of correlated
networks, showing that assortative mixing is ben-
eﬁcial for resilience: it can push the percolation
threshold down to zero, even for networks with a
ﬁnite second moment (Vázquez and Weigt 2003).
The opposite effect is also true: scale-free net-
works with diverging second moments but
dissasortative degree correlations are less resilient
to node failure (Leone et al. 2002). A general
analytical approach based on generating function
formalism not only reproduced the previous
results, but also allowed Callaway and Newmann
to investigate degree-dependent node removal
scenarios, such as attacks (Callaway et al. 2000).
Interestingly, assortative mixing does not help in
case of an attack: Song et al. have found that non-
fractal networks created via a mechanism that
Networks: Structure and Dynamics
587

favors hub to hub connections on all scales are
more vulnerable to intentional attack than their
fractal (and also disassortative) counterparts
(Song et al. 2006).
Cascading Failures
The function of a vari-
ety of complex networks involves the transmis-
sion or ﬂow of some conserved quantity. Removal
or failure of a node in such a network has conse-
quences that ripple through the rest of the system
far beyond the effects on connectivity: the node
suddenly sheds the load or ﬂux that it carried
before, thus its neighbors suddenly experience
higher loads: some of these overload and fail.
A cascading failure can follow, as often seen on
the power grid, perhaps the most quoted example
of the phenomenon. Unlike the fragmentation of a
network, a cascading failure can be triggered by a
relatively small number of node failures, often a
single one (Holme and Kim 2002b; Motter and
Lai 2002).
Using a model of overload in which the load-
bearing capacity of a node is proportional to its
load (betweenness) in the full network, Motter and
Lai showed that scale-free networks are more
vulnerable to randomly seeded cascading failures
than random networks (Motter and Lai 2002). The
vulnerability
becomes
especially
pronounced
under targeted attack: overload of the largest
node can cause cascades that propagate through
the whole system. They ﬁnd that the most danger-
ous targets are not the most highly connected, but
the most load-baring (highest betweenness cen-
trality) nodes. Betweenness is usually correlated
with degree. The US powergrid, however, is vul-
nerable under attack targeting its most central
nodes, but not its highest degree ones.
In a followup paper Motter introduced a fast
defense
strategy
against
cascading
failures
(Motter 2004). He argued that the only defense
strategy which is fast enough is further removal of
nodes: counterintuitive, but effective, if the nodes
are carefully chosen. The reason this is possible,
he argued, is because nodes that carry small
amounts of load (thus are less central to the net-
work) actually generate much more load than they
carry. Their shortest paths to the rest of the system
are larger, thus all the communication (trafﬁc,
power) they receive or generate affects a larger
number of intermediary nodes, increasing the total
network load. Generated and handled load are
anticorrelated, thus removal of nodes in ascending
order of loads signiﬁcantly reduces the size of
cascading failures in the rest of the network, as
veriﬁed by numerical simulations.
Congestion
Cascading failures and conges-
tion of trafﬁc carried by networks are similar
problems. As opposed to the node-removing
effect of a failure, congestion does not disconnect
a node, nonetheless, it can bring the trafﬁc-
bearing capability of a system to a halt. Most
congestion models show a transition from free
ﬂow to congestion as the load is increased, regard-
less of the network type.
Ohira and Sawatari showed the occurrence of a
jamming transition on a simple trafﬁc model in
which packets travel along the shortest paths of a
two dimensional lattice between randomly chosen
boundary nodes (Ohira and Sawatari 1998). On a
regular lattice shortest paths are highly degener-
ate, thus the authors considered two strategies:
one is deterministic in picking it’s route, the
other is random, preferring shortest paths but
occasionally picking longer than optimal ones.
They found that the jamming transition occurred
at larger packet creation rates if the routing was
probabilistic, with an optimal randomness that
does not considerably lengthen the travel paths,
but relieves the network from always choosing
congested paths. Guimerá et al. considered a dif-
ferent formulation of the congestion problem on
lattices and Cayley trees where all nodes generate
packets to random destinations and send them
along shortest paths, but the probability for a
packet to hop between two nodes along the path
depends on the queues accumulated by these two
nodes (Guimerà et al. 2002). Thus, there is some
congestion-awareness built into the model. If the
processing speed of nodes decreases with an
increased number of packets, the system shows a
discontinuous
transition
from
free
ﬂow
to
congested state: the ratio of undelivered packets
(the order parameter) jumps from 0 to 1. The
positive feedback between congestion and slower
processing leads to the formation of congestion
nuclei that spread through the network. On the
other hand, no transition is observed in networks
588
Networks: Structure and Dynamics

in which the processing speed of nodes increases
with queue lengths, only a crossover from low-
density ﬂow to high density ﬂow accompanied by
a change in ﬂuctuation statistics. The critical case
in between is queue-independent processing,
which shows a continuous transition between
free ﬂow and congestion.
Solé and Valverde proposed a generalization of
the Ohira–Sawatari model (Solé and Valverde
2001) and showed that the system at transition
point exhibits self-similar time-series dynamics
with an 1/f power spectrum, as observed in mea-
surements of packet transmission times on the
Internet. Latency times and queue lengths also
showed heavy tails with similar queue length dis-
tributions to jam size distribution in highway traf-
ﬁc models. Interestingly, the systems reaches its
highest efﬁciency and information transfer regime
right at the critical point, before entering the
congested state (Solé and Valverde 2001).
Building on the observation that the time series
dynamics of the model close to the critical point
matches the real data, the authors introduced a
self-organizing version of the model (Valverde
and Solé 2002). They argued that packet genera-
tion (thus user behavior) is linked to dynamics:
each user tries to increase its rate until congestion
of neighboring nodes is detected, at which point it
starts to decrease it, dropping its rate to 0 if all it’s
neighbors are congested. This model generates
highly heterogeneous dynamics in space and
time, with a power-law congestion length distri-
bution. Moreover, this model points to internal
network dynamics being responsible for ﬂuctua-
tions, supported by an analysis of real ﬂuctuations
by de Menezes and Barabási. They observed a
power-law scaling of ﬂux ﬂuctuations as a func-
tion of total ﬂux values, with two distinct scaling
exponents. α ¼ 1/2 scaling is generated by ﬂuctu-
ations internal to the system (as seen in the Inter-
net and on a microchip), while α ¼ 1 corresponds
to external noise (seen in the WWW, river net-
works and the highway system) (de Menezes and
Barabási 2004). Solé and Valverde have further
extended their model to study complex topologies
similar to the Internet (using the model by Yook
et al. 2003), with a routing strategy that can be
tuned from random routing to global shortest path
routing. Each node is assumed to know its neigh-
borhood to m hops. If the destination of a packet is
within a node’s search horizon it uses shortest path
routing, otherwise it passes the packet to a random
neighbor (Valverde and Solé 2004) (local routing
strategies with a ﬁxed search horizon were also
investigated by Tadić et al. (Tadić and Rodgers
2002; Tadić and Thurner 2004)). They found that
the routing was optimal when the search horizon
equaled the average path length of the network.
Further push toward global shortest paths actually
decreased the efﬁciency by over-specifying paths
and thus exacerbating congestion. The dynamics
observed with optimal search depth reproduced
the 1/2 scaling between ﬂuctuations and mean
ﬂow observed in (de Menezes and Barabási
2004), as well as the power-law exponent of the
average latency time distribution measured on the
Internet.
Zhao et al. investigated the effect of network
topology on congestion in a model in which the
packet processing speed of nodes is determined by
their degree or their betweenness. They found that
if the capacity of nodes was proportional to their
degree, random networks as well as scale-free
ones were less prone to congestion than regular
lattices or Cayley trees. However, systems in
which the node capacities were proportional to
their betweenness had the same critical packet
generation rate regardless of topology, suggesting
that selectively increasing the capacity of high-
betweenness nodes is a good way of increasing
the carrying capacity of the system as a whole
(Zhao et al. 2005).
A different approach for investigating the
effect of network topology on congestion was
proposed by Toroczkai and Bassler (2004). They
measured the congestion factor of the Erdős–
Rényi and Barabási–Albert models, deﬁned as
the average fraction of nodes that do not receive
and thus process incoming trafﬁc. Instead of an
explicit choice of routing or packet generation
behavior, they assumed that packets on average
follow the steepest gradients towards the neighbor
with the highest “potential”, thus the gradient
links determine the congestion factor (they
assume a random distribution of node potentials).
They found that the congestion factor of Erdős–
Networks: Structure and Dynamics
589

Rényi random graphs increases with the size of
the network, asymptotically growing to 1, while
for scale-free networks it quickly reaches a value
of ~0.7 and does not increase with system size.
A followup study by Danila et al. proposed a
trafﬁc model based on the idea of congestion-
gradient driven ﬂows (Danila et al. 2007).
The recognition that congestion occurs when
the average number of packets processed by the
busiest node reaches 1 (time-step) highlighted the
importance of betweenness in the study of con-
gestion. Routing protocols can inﬂuence the expe-
rienced betweenness of a node: the number of
packets that actually go through it on average.
Several methods of reducing the largest between-
ness value have been investigated: optimization of
link weights such that the shortest weighted paths
give rise to a small maximum betweennes (Danila
et al. 2006), hub avoiding global routing Schemes
(Sreenivasan et al. 2007) or trafﬁc-aware routing
(Echenique et al. 2004). Sreenivasan et al. proved
that for any network topology there always exist
an absolute upper bound for the communication
threshold,
determined
by
network
topology,
above which no routing algorithm can increase
the critical congestion threshold (Sreenivasan
et al. 2007).
Spreading Processes and Social Dynamics
Epidemic Models
Epidemiological modeling
jumped to the forefront of networks research
with a landmark paper by Pastor-Satorras and
Vespignani which revealed the striking difference
between virus spreading on scale-free networks
and homogeneous systems (Pastor-Satorras and
Vespignani 2001a, b). They studied the “suscep-
tible–infected–susceptible”
(SIS)
epidemic
model, suited to describe diseases that confer no
immunity, such as tuberculosis, gonorrhea as well
as computer viruses on systems that do not update
their virus protection software. Each susceptible
node can be infected with rate v if it is connected
to one or more infected nodes, while infected
nodes are cured with rate δ and become suscepti-
ble again. The SIS model was known to show a
non-equilibrium phase transition at a critical
spreading rate lc (l ¼ v/δ): if the spreading rate
is higher than this threshold, the disease is
endemic; a ﬁnite faction of nodes is persistently
infected. Below the threshold the disease dies out
completely after an initial breakout. As Pastor-
Satorras and Vespignani pointed out, these results
were obtained on lattices and failed to explain the
very low but sustained prevalence of computer
viruses. The authors report the absence of a criti-
cal
point
on
scale-free
networks
with
2 < γ  3: there is no non-zero spreading rate
for which the disease dies out. As l approaches 0,
the prevalence of the disease decreases exponen-
tially, but only reaches 0 when l ¼ 0.
In a followup study together with Moreno they
showed that the lack of an epidemic threshold
holds for the “susceptible–infected–recovered”
(SIR) model as well (Moreno et al. 2002). This
model, applicable for diseases that result in immu-
nity or death, has a radically different overall
behavior from the SIS model. Recovered individ-
uals cannot get infected again, thus the disease
always dies out. Nonetheless, for homogeneous
networks it shows a phase transition at a critical
spreading rate lc, reﬂected in the total fraction of
the population to ever get the disease. Below lc
this fraction is vanishing as the system size goes to
inﬁnity, above lc there is a ﬁnite infected fraction.
Moreno et al. have found that the critical spread-
ing rate for uncorrelated complex networks is
lc ¼ hki/hk2i.
Thus, networks with diverging connectivity
ﬂuctuations (such as scale-free graphs with
2 < γ  3) have no non-zero epidemic threshold.
Although real and thus ﬁnite-size networks cannot
have inﬁnite hk2i, the epidemic threshold is very
small for large systems, much smaller than that of
a similar homogeneous network, and it decreases
with systems size (Pastor-Satorras and Vespignani
2002a). The SIR model has been mapped onto a
bond percolation problem by Grassberger (1983).
This mapping was exploited by Newman, who
used
the
generating
function
formalism
(Callaway et al. 2000; Newman et al. 2001) to
obtain the exact solution of the model in the inﬁ-
nite time limit for simple graphs with arbitrary
degree distribution. He then extended the map-
ping to bipartite graphs to model sexually trans-
mitted diseases spreading between men and
women (Newman 2002b).
590
Networks: Structure and Dynamics

The absence of an epidemic threshold has pro-
found implications on immunization policies
effective in scale-free networks. Dezsö and
Barabási (2002) as well as Pastor-Satorras and
Vespignani (2002b) have shown that scale-free
networks do not respond to random immuniza-
tion: such a strategy cannot restore the epidemic
threshold, or bring the effective spreading rate
below it, even for an unrealistically high number
of administered vaccines. On the other hand,
immunization preferentially targeting the hubs of
the network successfully reintroduces an epi-
demic threshold at very low vaccination rates,
even if the strategy is imperfect in identifying
the hubs. These results have important and con-
troversial consequences for public policy of vac-
cination in the context of sexually transmitted
diseases. This is partly because a policy that
gives priority vaccination to prostitutes is contro-
versial even if the public beneﬁts are substantial,
but also because it is generally difﬁcult to identify
the hubs of sexual networks. Cohen et al. pro-
posed an immunization policy that overcomes
this problem without relying on any global knowl-
edge of the system: immunize a randomly chosen
friend of a random person (Cohen et al. 2003).
They showed that this strategy preferentially tar-
gets the hubs, thus restoring the epidemic
threshold.
Epidemic spreading on networks with degree
correlations show that degree correlations do not
affect the lack of epidemic threshold in scale-free
networks (Boguñá et al. 2003; Moreno et al.
2003). However, the epidemic incidence is
smaller in these networks, while diseases are lon-
ger lived (Moreno et al. 2003).
The inﬂuence of link weights on epidemic
spreading has been investigated in the context of
diseases such as Severe Acute Respiratory Syn-
drome (SARS), spreading on the world-wide air-
line network (Colizza et al. 2006). Colizza et al.
developed a detailed multi-scale model of global
epidemic spreading and found that the degree
heterogeneity of the airport network accounts for
most of the observed behavior of the epidemics,
the heterogeneity of its weights has a much
smalled inﬂuence on the spread of the disease
(Colizza et al. 2006). They found that epidemics
are fairly predictable, except at the very beginning
of an outbreak originating from a hub, as well as
the end of epidemics (Colizza et al. 2006).
Information
Spreading
The
similarity
between rumor spreading and epidemic spreading
was recognized as early as 1964, when Goffman
and Newill used the SIR model to describe the
spread of ideas instead of diseases (Goffman and
Newill 1964). The authors pointed out an impor-
tant difference between the two processes: while
one studies epidemic models with an effective
immunization
strategy
in
mind,
information
spread is in general favored; moreover, the pro-
cess can be engineered in a way that facilitates
high reliability of the spread. Later in the same
year, Daley and Kendall published a spreading
model that is speciﬁc to rumor (or information)
spreading: instead of the random recovery rate of
the SIR model (which assumes spontaneous for-
getting of the news), they assumed that nodes
loose their interest in spreading the news upon
encounter with another node that knows it
(Daley and Kendall 1965). Thus the “recovery”
process of the Daley–Kendall model is very dif-
ferent that that of SIR, leading to a signiﬁcant
difference in the outcome of spreading. Assuming
homogeneous mixing (each infected individual,
or spreader can randomly contact any node in
the system), the ﬁnal fraction of nodes who have
heard the news is ~80%.
A
decentralized,
spontaneous
and
robust
method of spreading information was welcome
by the computer science community; it allowed
them to overcome the scalability problems of data
disseminating protocols in large-scale distributed
computing (Vogels et al. 2003) and peer-to-peer
networks (Kermarrec et al. 2003). It was also used
in update management of databases duplicated at
many sites (Demers et al. 1987).
In the context of complex networks, the
Daley–Kendall model was ﬁrst investigated on
the small-world model by Zanette, who found
that below a density of shortcuts the rumor dies
out without reaching a ﬁnite fraction of nodes
(Zanette 2001). Moreover, this threshold is ﬁnite
for inﬁnite systems ( pc ¼ 0.2 for K ¼ 2), even
though the network is turned into a small-world
by a vanishingly small number of shortcuts.
Networks: Structure and Dynamics
591

Moreno et al. studied the same model on homo-
geneous versus scale-free networks and found that
as opposed to epidemic spreading, rumors spread
to a higher fraction of nodes in homogeneous
networks (Moreno et al. 2004). Hubs in scale-
free networks have a conﬂicting effect on rumor
spreading: while they are highly likely and quick
to hear the information, they also facilitate the
formation of stiﬂer nodes who do not spread the
rumor.
Searching on Complex Networks
Milgram’s
famous
experiment
showing
six
degrees of separation between two random people
not only showed the existence of short paths on
social networks, it also highlighted the fact that
ﬁnding a destination node with local information
is not very difﬁcult (Milgram 1967). Motivated by
these ﬁndings, Kleinberg showed that the perfor-
mance of a simple greedy search critically
depends on the topology of the underlying net-
work. He used a small-world type model in which
nodes sit on a two-dimensional lattice (connected
to their four neighbors) to which a few long-range
connections are added. Unlike in the small-world
model, these connections are not added entirely
randomly: the probability of a shortcut is propor-
tional to r–α, where r is the Manhattan distance
between two nodes. In this model the best-case
performance of a decentralized algorithm (the
expected delivery time) scales as (log N)2 for
α ¼ 2. However, both larger and smaller values of
α result in expected times that scale as polynomials
in N, highlighting that not all networks with short
average path lengths allow the use of efﬁcient
decentralized searches (Kleinberg 2000).
Adamic et al. proposed to exploit the hetero-
geneous nature of scale-free networks to signiﬁ-
cantly speed up breath-ﬁrst type searches (also
called burning algorithms) which typically run in
O N
ð Þ time (Adamic et al. 2001; Kim et al. 2002).
Instead of broadcasting a query to all neighbors
who in turn broadcast it further, their algorithm
checks whether the target is among its ﬁrst neigh-
bor, and if not, it passes the query along to the
neighbor with the highest degree. This neighbor
continues the search in a similar way, and if a dead
end is reached, the message is recursively back-
tracked until there are no neighbors left to explore.
This strategy can improve the performance to
O N1=2


for γ ¼ 3, and O log N
ð
Þ for γ ¼ 2 scale-
free networks. The method was tested by the
authors on the GNUTELLA peer-to-peer net-
work, as well as by Kim et al. on scale-free net-
works generated by the conﬁguration model and
the Barabási–Albert model (Kim et al. 2002).
(Kim, Yoon, Han and Jeong proposed the strategy
independently a few months after Adamic et al.
submitted their paper.)
Searchability of social networks has been
revisited several times since Milgram’s experi-
ment. Killworth and Bernard found that the choice
of neighbor to pass the letter on was most often
based on common characteristics with the target,
such as geographical location and profession
(Killworth and Bernard 1978). An electronic ver-
sion of the experiment carried out by Dodds et al.
concluded that the search on the e-mail network is
also guided by reliance on common “social iden-
tities”, and the chosen routes do not favor social
hubs (Dodds et al. 2003). Motivated by these
results, Watts et al. and Kleingerg independently
proposed a searchable social network model in
which nodes are grouped in a nested hierarchy of
social categories. A link between two nodes is
exponentially less likely if their social distance
(length of the path along the hierarchical tree of
social groups) is large (Kleinberg 2002; Watts
et al. 2002). In a simulated Milgram–type exper-
iment, the letter would be passed from a node to a
neighbor with the smallest social distance to the
target. Such a search performs well for a range of
the model parameters, with it’s best performance
scaling as O log N
ð
Þ (Kleinberg 2002).
Future Directions
The short account of research advances into
dynamics on complex networks presented here
is by no means exhaustive. Several fairly large
and lively research areas, synchronization, bool-
ean networks, random walks on complex net-
works, brain networks, models of adaptive or
dynamical wiring among them, have all been
omitted here.
592
Networks: Structure and Dynamics

Future directions in networks research are hard
to account for in a few paragraphs. It is believed
that further understanding of dynamics on com-
plex networks is the general direction of the ﬁeld.
Along with a shift from pure structural studies to
dynamics, there has also been a shift from studies
of networks in general and features that are com-
mon to most of them to more application-driven
studies of increasingly narrow classes of net-
works. This is not to say that important lessons
learned this way do not often carry over from one
system to the other, but it shows that enough is
known about network characteristics now to tell
them apart, to look for distinguishing features as
well as universal ones.
A fairly standard toolkit for the assessment of
the structural properties of a network has already
emerged, making the notion of networks and
knowledge about them a useful toolkit in studying
the architecture of complex systems. Our hope is
that dynamical studies will further extend the
toolkit to cover general aspects of the type of
events occurring on complex networks, and per-
haps lead the way in understanding how function
emerges in complex systems.
Bibliography
Primary Literature
Adamic LA (1999) The small world web. In: Lecture notes
in computer science, vol 1696. Springer, New York,
pp 443–454
Adamic LA, Huberman BA (2000) Power-law distribution
of the World Wide Web. Science 287:2115
Adamic LA, Lukose RM, Puniyani AR, Huberman BA
(2001) Search in power-law networks. Phys Rev
E 64(4):046135
Aiello W, Chung F, Lu L (2000) A random graph model for
massive graphs. In: Proceedings of the 32nd annual
ACM symposium on theory of computing. ACM,
New York, pp 171–180
Albert R, Barabási A-L (2000) Topology of evolving net-
works: local events and universality. Phys Rev Lett
85:5234
Albert R, Jeong H, Barabási A-L (1999) Diameter of the
World-Wide Web. Nature 401:130–131
Albert R, Jeong H, Barabási A-L (2000) Attack and error
tolerance of complex networks. Nature 406:378
Albert R, Albert I, Nakarado GL (2004) Structural vulner-
ability of the North American power grid. Phys Rev
Lett 69:025103
Almaas E, Kovacs B, Vicsek T, Oltvai ZN, Barabási A-L
(2004) Global organization of metabolic ﬂuxes in the
bacterium Escherichia coli. Nature 427(6977):839–843
Alon U (2007) Network motifs: theory and experimental
approaches. Nat Rev Genet 8:450–461
Amaral LAN, Scala A, Barthélémy M, Stanley HE
(2000) Classes of small-world networks. Proc Natl
Acad Sci U S A 97(11):149
Arenas A, Danon L, Díaz-Guilera A, Gleiser PM, Guimerà
R (2004) Community analysis in social networks. Eur
Phys J B 38(2):373–380
Baiesi M, Paczuski M (2004) Scale-free networks of earth-
quakes and aftershocks. Phys Rev E 69(6):066106
Balázsi G, Barabási A-L, Oltvai ZN (2005) Topological
units of environmental signal processing in the tran-
scriptional regulatory network of Escherichia coli. Proc
Natl Acad Sci U S A 102(22):7841–7846
Barabási A-L, Albert R (1999) Emergence of scaling in
random networks. Science 286:509–512
Barabási A-L, Albert R, Jeong H (1999) Mean-ﬁeld theory
for scale-free random networks. Physica A 272:
173–187
Barabási A-L, Jeong H, Néda Z, Ravasz E, Schubert A,
Vicsek T (2002) Evolution of the social network of
scientiﬁc collaborations. Physica A 311:590
Barrat A, Barthélemy M, Pastor-Satorras R, Vespignani
A (2004) The architecture of complex weighted net-
works. Proc Natl Acad Sci U S A 101:3747–3752
Barthélémy M (2003) Crossover from scale-free to spatial
networks. Europhys Lett 63(6):915–921
Bender EA, Canﬁeld ER, McKay BD (1997) The asymp-
totic number of labeled graphs with n vertices, q edges,
and no isolated vertices. J Comb Theor: Ser A 80(1):
124–150
Bianconi G, Barabási A-L (2001a) Competition and multi-
scaling in evolving networks. Europhys Lett 54:436
Bianconi G, Barabási A-L (2001b) Bose-Einstein conden-
sation in complex networks. Phys Rev Lett 86:5632
Boguñá M, Pastor-Satorras R, Vespignani A (2003)
Absence of epidemic threshold in scale-free networks
with degree correlations. Phys Rev Lett 90(2):028701
Boguñá M, Pastor-Satorras R, Diaz-Guilera A, Arenas
A (2004) Models of social networks based on social
distance attachment. Phys Rev E 70(5):056122
Bollobás B, de la Vega WF (1982) The diameter of random
regular graphs. Combinatorica 2(2):125–134
Bollobás B, Riordan O (2004) The diameter of a scale-free
random graph. Combinatorica 24(1):5–34
Bollobás B, Riordan O, Spencer J, Tusnády G (2001) The
degree sequence of a scale-free random process. Ran-
dom Struct Algorithms 18:279–290
Broder
A,
Kumar
R,
Maghoul
F,
Raghavan
P,
Rajalopagan
S,
Stata
R,
Tomkins
A,
Wiener
J (2000) Graph structure in the web. Comput Netw
33:309–320
Broida A, Claffy KC (2001) Internet topology: connectiv-
ity of IP graphs. In: Fahmy S, Park K (eds) Scalability
and trafﬁc control in IP networks in proceedings SPIE,
vol 4526. International Society for Optical Engineer-
ing, Bellingham, pp 172–187
Networks: Structure and Dynamics
593

Callaway DS, Newman MEJ, Strogatz SH, Watts DJ
(2000) Network robustness and fragility: percolation
on random graphs. Phys Rev Lett 85:5468
Capocci A, Servedio VDP, Colaiori F, Buriol LS,
Donato D, Leonardi S, Caldarelli G (2006) Preferential
attachment in the growth of social networks: the inter-
net encyclopedia wikipedia. Phys Rev E 74:036116
Chung F, Lu L (2002) The average distances in random
graphs with given expected degrees. Proc Natl Acad
Sci U S A 99:15879–15882
Clauset A, Newman MEJ, Moore C (2004) Finding com-
munity structure in very large networks. Phys Rev
E 70(6 Pt 2):066111
Cohen R, Havlin S (2003) Scale-free networks are ultra
small. Phys Rev Lett 90:058701
Cohen R, Erez K, ben Avraham D, Havlin S (2000) Resil-
ience of the Internet to random breakdowns. Phys Rev
Lett 85:4626–4628
Cohen R, Havlin S, ben Avraham D (2003) Efﬁcient immu-
nization
strategies
for
computer
networks
and
populations. Phys Rev Lett 91(24):247901
Colizza V, Barrat A, Barthelemy M, Vespignani A (2006)
The role of the airline transportation network in the
prediction and predictability of global epidemics. Proc
Natl Acad Sci U S A 103(7):2015–2020
Daley DJ, Kendall DG (1965) Stochastic rumours. IMA
J Appl Math 1(1):42–55
Dall J, Christensen M (2002) Random geometric graphs.
Phys Rev E 66:016121
Danila B, Yu Y, Marsh JA, Bassler KE (2006) Optimal
transport
on
complex
networks.
Phys
Rev
E 74(4):046106
Danila B, Yu Y, Marsh JA, Bassler KE (2007) Transport
optimization
on
complex
networks.
Chaos
17(2):026102
Davidsen J, Ebel H, Bornholdt S (2002) Emergence of a
small world from local interactions: modeling acquain-
tance networks. Phys Rev Lett 88(12):128701
de Menezes MA, Barabási A-L (2004) Fluctuations in
network dynamics. Phys Rev Lett 92:028701
de Solla Price DJ (1965) Networks of scientiﬁc papers.
Science 149:510–515
de Solla Price DJ (1976) A general theory of bibliometric
and other cumulative advantage processes. J Am Soc
Inform Sci 27:292–306
Demers A, Greene D, Hauser C, Irish W, Larson J,
Shenker S, Sturgis H, Swinehart D, Terry D (1987)
Epidemic algorithms for replicated database mainte-
nance. In: PODC 87: Proceedings of the 6th Annual
ACM symposium on principles of distributed comput-
ing. ACM, New York, pp 1–12
Dezső Z, Barabási A-L (2002) Halting viruses in scale-free
networks. Phys Rev E 65:055103
Di Matteo T, Aste T, Gallegati M (2005) Innovation ﬂow
through social networks: productivity distribution in
france and italy. Eur Phys J B 47(3):459–466
Dodds PS, Muhamad R, Watts DJ (2003) An experimental
study of search in global social networks. Science
301(5634):827–829
Dorogovtsev SN, Mendes JFF (2000) Scaling behaviour of
developing and decaying networks. Europhys Lett
52:33
Dorogovtsev SN, Mendes JFF (2001a) Effect of the accel-
erating growth of communications networks on their
structure. Phys Rev E 63:025101
Dorogovtsev SN, Mendes JFF (2001b) Language as an
evolving word web. Proc R Soc Lond B 268:
2603–2606
Dorogovtsev SN, Mendes JFF, Samukhin AN (2000) Struc-
ture of growing networks with preferential linking.
Phys Rev Lett 85:4633–4636
Dorogovtsev SN, Goltsev AV, Mendes JFF (2002) Pseudo-
fractal scale-free web. Phys Rev E 65:66122
Ebel H, Mielsch LI, Bormholdt S (2002) Scale-free topol-
ogy of e-mail networks. Phys Rev E 66:035103
Echenique P, Gómez-Gardeñes J, Moreno Y (2004)
Improved routing strategies for internet trafﬁc delivery.
Phys Rev E 70(5):056105
Erdős P, Rényi A (1959) On random graphs I. Publ Math
(Debrecen) 6:290–297
Erdős P, Rényi A (1960) On the evolution of random
graphs. Publ Math Inst Hung Acad Sci 5:17–61
Euler L (1741) Solutio problematis ad geometriam situs
pertinentis.
Commentarii
academiae
scientiarum
Petropolitanae 8:128–140
Faloutsos M, Faloutsos P, Faloutsos C (1999) On power-
law relationships of the Internet topology. Comput
Commun Rev 29:251–262
Ferrer i Cancho R, Solé RV (2001) The small-world of
human language. Proc R Soc Lond B 268:2261–2266
Freeman LC (1977) A set of measures of centrality based
on betweenness. Sociometry 40(1):35–41
Gerdes SY, Scholle MD, Campbell JW, Balázsi G,
Ravasz E, Daugherty MD, Somera AL, Kyrpides NC,
Anderson I, Gelfand MS, Bhattacharya A, Kapatral V,
DíSouza M, Baev MV, Grechkin Y, Mseeh F, Fonstein
MY, Overbeek R, Barabási A-L, Oltvai ZN, Osterman
AL (2003) Experimental determination and system
level analysis of essential genes in Escherichia coli
MG1655. J Bacteriol 185:5673–5684
Girvan M, Newman MEJ (2002) Community structure in
social and biological networks. Proc Natl Acad Sci U S
A 99:7821–7826
Goffman W, Newill VA (1964) Generalization of epidemic
theory: an application to the transmission of ideas.
Nature 204(4955):225–228
Goh K-I, Oh E, Jeong H, Kahng B, Kim D (2002) Classi-
ﬁcation of scale-free networks. Proc Natl Acad Sci U S
A 99(20):12583–12588
Govindan R, Tangmunarunkit H (2000) Heuristics for
Internet map discovery. In: Proceedings of IEEE
INFOCOM 2000 Nineteenth annual joint conference
of the IEEE computer and communications societies,
Tel
Aviv,
Israel,
vol
3.
IEEE,
Piscataway,
pp 1371–1380
Grassberger P (1983) Critical behavior of the general epi-
demic process and dynamical percolation. Math Biosci
63(2):157–172
594
Networks: Structure and Dynamics

Guimerà R, Amaral LAN (2004) Modeling the world-wide
airport network. Eur Phys J B 38(2):381–385
Guimerà R, Arenas A, Díaz-Guilera A, Giralt F (2002)
Dynamical properties of model communication net-
works. Phys Rev E 66(2):026704
Guimerà R, Danon L, Díaz-Guilera A, Giralt F, Arenas
A (2003) Self-similar community structure in a net-
work of human interactions. Phys Rev E 68(6):065103
Holme P, Kim BJ (2002a) Growing scale-free networks
with tunable clustering. Phys Rev E 65(2):026107
Holme P, Kim BJ (2002b) Vertex overload breakdown in
evolving networks. Phys Rev E 65(6):066109
Jain S, Krishna S (1998) Autocatalytic sets and the growth
of complexity in an evolutionary model. Phys Rev Lett
81(25):5684–5687
Jeong H, Tombor B, Albert R, Oltvai ZN, Barabási A-L
(2000) The large-scale organization of metabolic net-
works. Nature 407:651–654
Jeong H, Néda Z, Barabási A-L (2003) Measuring prefer-
ential attachment for evolving networks. Europhys Lett
61:567
Jung S, Kim S, Kahng B (2002) A geometric fractal growth
model for scale free networks. Phys Rev E 65:056101
Kermarrec AM, Massoulie L, Ganesh AJ (2003) Probabi-
listic reliable dissemination in large-scale systems.
IEEE Trans Parallel Distrib Syst 14(3):248–258
Killworth PD, Bernard HR (1978) The reverse small world
experiment. Social Netw 1:159–192
Kim BJ, Yoon CN, Han SK, Jeong H (2002) Path ﬁnding
strategies
in
scale-free
networks.
Phys
Rev
E 65(2):027103
Kleinberg JM (2000) Navigation in a small world. Nature
406(6798):845
Kleinberg JM (2002) Small-world phenomena and the
dynamics of information. In: Dietterich TG, Becker S,
Ghahramani Z (eds) Proceedings of the 2001 neural
information processing systems conference. MIT Press,
Cambridge
Kleinberg JM, Kumar SR, Raghavan P, Rajagopalan S,
Tomkins A (1999) The web as a graph: measurements,
models and methods. In: Proceedings of the interna-
tional conference on combinatorics and computing,
COCOON’99, Berlin. Springer, Tokyo, p 1
Klemm K, Eguíluz VM (2002) Growing scale-free net-
works
with
small-world
behavior.
Phys
Rev
E 65:057102
Krapivsky PL, Redner S (2001) Organization of growing
random networks. Phys Rev E 63:66–123
Krapivsky PL, Redner S (2002) A statistical physics per-
spective on web growth. Comput Netw 39:261–276
Krapivsky PL, Redner S, Leyvraz F (2000) Connectivity of
growing
random
networks.
Phys
Rev
Lett
85:
4629–4632
Kumar R, Raghavan P, Rajagopalan S, Tomkins A (1999)
Trawling the web for emerging cyber-communities.
Comput Netw 31:1481–1493
Leone M, Vázquez A, Vespignani A, Zecchina R (2002)
Ferromagnetic ordering in graphs with arbitrary degree
distribution. Eur Phys J B 28:191–197
Liljeros F, Edling C, Amaral L, Aberg Y (2001) The web of
human sexual contacts. Nature 411:907–908
Ma HW, Zeng AP (2003) The connectivity structure, giant
strong component and centrality of metabolic net-
works. Bioinformatics 19(11):1423–1430
Manna SS, Sen P (2002) Modulated scale-free network in
Euclidean space. Phys Rev E 66(6):066114
Maslov S, Sneppen K (2002) Speciﬁcity and stability in
topology of protein networks. Science 296:910–913
Milgram S (1967) The small-world problem. Psychol
Today 2:60–67
Milo R, Shen-Orr S, Itzkovitz S, Kashtan N, Chklovskii D,
Alon U (2002) Network motifs: simple building blocks
of complex networks. Science 298:824–827
Moreno Y, Pastor-Satorras R, Vespignani A (2002) Epi-
demic outbreaks in complex heterogeneous networks.
Eur Phys J B 26(4):521–529
Moreno Y, Gómez JB, Pacheco AF (2003) Epidemic inci-
dence in correlated complex networks. Phys Rev
E 68(3):035103
Moreno Y, Nekovee M, Vespignani A (2004) Efﬁciency
and reliability of epidemic data dissemination in com-
plex networks. Phys Rev E 69(5):055101
Motter AE (2004) Cascade control and defense in complex
networks. Phys Rev Lett 93(9):098701
Motter AE, Lai YC (2002) Cascade-based attacks on com-
plex networks. Phys Rev E 66(6):065102
Motter AE, de Moura APS, Lai YC, Dasgupta P (2002)
Topology of the conceptual network of language. Phys
Rev E 65:065102
Myers CR (2003) Software systems as complex networks:
structure, function, and evolvability of software collab-
oration graphs. Phys Rev E 68:046116
Newman
MEJ
(2001a)
Clustering
and
preferential
attachment in growing networks. Phys Rev E 64:
025102(R)
Newman MEJ (2001b) The structure of scientiﬁc collabo-
ration networks. Proc Natl Acad Sci U S A 98:404–409
Newman MEJ (2002a) Assortative mixing in networks.
Phys Rev Lett 89:208701
Newman MEJ (2002b) Spread of epidemic disease on
networks. Phys Rev E 66(1):016128
Newman MEJ (2003) Mixing patterns in networks. Phys
Rev E 67:026126
Newman MEJ (2004) Fast algorithm for detecting commu-
nity structure in networks. Phys Rev E 69(6 Pt
2):066133
Newman MEJ (2006) Finding community structure in
networks using the eigenvectors of matrices. Phys
Rev E 74(3):036104
Newman MEJ, Girvan M (2004) Finding and evaluating
community
structure
in
networks.
Phys
Rev
E 69(2):026113
Newman MEJ, Watts DJ (1999) Renormalization group
analysis of the small-world network model. Phys Lett
A 263:341–346
Newman MEJ, Strogatz SH, Watts DJ (2001) Random
graphs with arbitrary degree distributions and their
applications. Phys Rev E 64(2):026118
Networks: Structure and Dynamics
595

Ohira T, Sawatari R (1998) Phase transition in a computer
network trafﬁc model. Phys Rev E 58(1):193–195
Palla G, Derenyi I, Farkas I, Vicsek T (2005) Uncovering
the overlapping community structure of complex net-
works in nature and society. Nature 435(7043):
814–818
Pastor-Satorras R, Vespignani A (2001a) Epidemic dynam-
ics and endemic states in complex networks. Phys Rev
E 63(6):066117
Pastor-Satorras R, Vespignani A (2001b) Epidemic spread-
ing in scale-free networks. Phys Rev Lett 86:
3200–3203
Pastor-Satorras R, Vespignani A (2002a) Epidemic dynam-
ics in ﬁnite size scale-free networks. Phys Rev
E 65(3):035108
Pastor-Satorras R, Vespignani A (2002b) Immunization of
complex networks. Phys Rev Lett 65:036104
Pastor-Satorras R, Vázquez A, Vespignani A (2001)
Dynamical and correlation properties of the Internet.
Phys Rev Lett 87:258701
Rao F, Caﬂisch A (2004) The protein folding network.
J Mol Biol 342:299–306
Ravasz E, Barabási A-L (2002) Hierarchical organization
in complex networks. Phys Rev E 67:026122
Ravasz E, Somera AL, Mongru DA, Oltvai ZN, Barabási
A-L (2002) Hierarchical organization of modularity in
metabolic networks. Science 297:1551–1555
Ravasz E, Gnanakaran S, Toroczkai Z (2007) Network struc-
ture of protein folding pathways. arXiv:0705.0912v1
Redner S (1998) How popular is your paper? An empirical
study of the citation distribution. Eur Phys J B 4:
131–135
Redner S (2004) Citation statistics from more than a cen-
tury of physical review. arXiv:physics/0407137v2
Scala A, Amaral LAN, Barthélémy M (2001) Small-world
networks and the conformation space of a short lattice
polymer chain. Europhys Lett 55(4):594–600
Serrano MA, Boguñá M (2003) Topology of the world
trade web. Phys Rev E 68:015101
Shen-Orr S, Milo R, Mangan S, Alon U (2002) Network
motifs in the transcriptional regulation network of
E. coli. Nat Genet 31:64–68
Sigman M, Cecchi GA (2002) Global organization of the
Wordnet lexicon. Proc Natl Acad Sci U S A 99(3):
1742–1747
Solé RV, Valverde S (2001) Information transfer and phase
transitions in a model of internet trafﬁc. Physica
A 289(3–4):595–605
Solé R, Pastor-Satorras R, Smith E, Kepler T (2002)
A model of large-scale proteome evolution. Adv Com-
plex Syst 5:43–54
Song C, Havlin S, Makse HA (2005) Self-similarity of
complex networks. Nature 433(7024):392–395
Song C, Havlin S, Makse HA (2006) Origins of fractality in
the growth of complex networks. Nat Phys 2(4):
275–281
Sreenivasan S, Cohen R, Lopez E, Toroczkai Z, Stanley
HE (2007) Structural bottlenecks for communication in
networks. Phys Rev E 75(3):036105
Tadić B (2001) Dynamics of directed graphs: the world-
wide web. Physica A 293:273–284
Tadić B, Rodgers GJ (2002) Packet transport on scale free
networks. Adv Complex Syst 5:445–456
Tadić B, Thurner S (2004) Information super-diffusion on
structured networks. Physica A 332:566–584
Thieffry D, Huerta AM, Perez-Rueda E, Collado-
Vides J (1998) From speciﬁc gene regulation to
genomic networks: a global analysis of transcrip-
tional regulation in Escherichia coli. BioEssays
20(5):433–440
Toroczkai Z, Bassler KE (2004) Network dynamics:
Jamming is limited in scale-free systems. Nature
428:716
Toroczkai Z, Kozma B, Bassler KE, Hengartner NW,
Korniss G (2004) Gradient networks. arXiv:cond-mat/
0408262v1
Tyler JR, Wilkinson DM, Huberman BA (2003) Email as
spectroscopy: automated discovery of community
structure
within
organizations.
In:
Huysman
M,
Wenger E, Wulf V (eds) Communities and technolo-
gies. Proceedings of the ﬁrst international conference
on communities and technologies. Kluwer, Norwell,
pp 81–96
Valverde S, Solé RV (2002) Self-organized critical trafﬁc
in
parallel
computer
networks.
Physica
A 312(3–4):636–648
Valverde S, Solé RV (2004) Internet’s critical path horizon.
Eur Phys J B 38(2):245–252
Vázquez A, Weigt M (2003) Computational complexity
arising from degree correlations in networks. Phys Rev
E 67(2):027101
Vázquez A, Flammini A, Maritan A, Vespignani A (2003)
Modelling of protein interaction networks. Complexus
1:38–44
Vogels W, van Renesse R, Birman K (2003) The power of
epidemics: robust communication for large-scale dis-
tributed systems. SIGCOMM Comput Commun Rev
33(1):131–135
Wasserman S, Faust K (1994) Social network analysis.
Cambridge University Press, Cambridge
Watts DJ, Strogatz SH (1998) Collective dynamics of
small-world networks. Nature 393:440–442
Watts DJ, Dodds PS, Newman MEJ (2002) Identity and
search in social networks. Science 296:130
Wilkinson DM, Huberman BA (2004) A method for ﬁnd-
ing communities of related genes. Proc Natl Acad Sci
USA Suppl 101(1):5241–5248
Xulvi-Brunet R, Sokolov IM (2002) Evolving networks
with disadvantaged long-range connections. Phys Rev
E 66(2):026118
Yook SH, Jeong H, Barabási A-L (2003) Modelling the
Internet’s large-scale topology. Proc Natl Acad Sci U S
A 99:13382–13386
Zanette DH (2001) Critical behavior of propagation on
small-world networks. Phys Rev E 64(5):050901
Zhao L, Lai YC, Park K, Ye N (2005) Onset of trafﬁc
congestion
in
complex
networks.
Phys
Rev
E 71(2):026125
596
Networks: Structure and Dynamics

Books and Reviews
Albert R, Barabási AL (2002) Statistical mechanics of
complex networks. Rev Mod Phys 74(1):47–97
Barabási A-L (2002) Linked: the new science of networks.
Perseus Publishing, Cambridge
Ben-Naim
E,
Frauenfelder
H,
Toroczkai
Z
(eds)
(2005) Complex networks, 650, Lecture notes in phys-
ics. Springer, Secaucus
Boccaletti S, Latora V, Moreno Y, Chavez M, Hwang DU
(2006) Complex networks: Structure and dynamics.
Phys Rep 424(4–5):175–308
Bollobás B (1985) Random graphs. Academic Press, London
Bornholdt S, Schuster HG (eds) (2002) Handbook of
graphs and networks: from the genome to the internet.
Wiley-VCH, Berlin
Dorogovtsev SN, Mendes JFF (2002) Evolution of net-
works. Adv Phys 51:1079
Mendes
J,
Oliveira
JG,
Abreu
FV,
Povolotsky
A,
Dorogovtsev SN (eds) (2005) Science of complex net-
works: from biology to the internet and WWW. AIP
conference proceedings, CNET 2004, Aveiro, Portugal,
vol 776
Newman MEJ, Barabási A-L, Watts DJ (eds) (2003) The
structure
and
dynamics
of
complex
networks.
Princeton University Press, Princeton
Newman MEJ (2003) The structure and function of com-
plex networks. SIAM Rev 45(2):167–256
Pastor-Satorras
R,
Rubi
M,
Diaz-Guilera
A
(eds)
(2003) Statistical mechanics of complex networks,
625, Lecture notes in physics. Springer, Berlin
Watts DJ (1999) Small worlds: the dynamics of networks
between order and randomness. Princeton University
Press, Princeton
Networks: Structure and Dynamics
597

Centralities in Complex
Networks
Alexandre Bovet1 and Hernán A. Makse2
1Mathematical Institute, University of Oxford,
Oxford, UK
2Levich Institute and Physics Department, City
College of New York, New York, NY, USA
Article Outline
Glossary
Why Study Networks?
Deﬁnition of the Subject
Conclusion and Future Directions
Bibliography
Glossary
Adjacency matrix The adjacency matrix, A, of a
network is a N  N matrix (N ¼ |V|) with element
Aij ¼ 1 if there is an edge from node i to node
j and Aij ¼ 0 otherwise. If the network is
weighted, Aij ¼ wij where wij  ℝis the weight
associated with the edge between nodes i and j if
it exists and Aij ¼ 0 otherwise. For undirected
network, Aij ¼ Aji, i.e., A is symmetric.
Connected components A connected compo-
nent of an undirected graph G(V, E) is a sub-
graph of G, made of a subset of V and all the
edges connecting nodes of the subset together,
where there exists a path between each pair of
nodes. In directed graphs, we differentiate
strongly connected components, where there
exists a path in both directions between all
pairs of nodes, and weakly connected compo-
nents, where there exists a path in at least one
direction between all pairs of nodes.
Degree of a node The degree, ki, of node i in an
undirected network is equal to its number of
connections, i.e., ki ¼  j Aij. For directed
network, we differentiate the in-degree, kin
i ¼
P
j Aji and the out-degree, kout
i
¼ P
j Aij, i.e.,
the number of edges incoming to node i and
outcoming
from
node
i,
respectively. In
weighted undirected networks, the degree of a
node is replaced by its strength, si ¼  j wij or
in-strength and out-strength for weighted
directed networks.
Network A network is a collection of nodes (also
called vertices) and edges (also called links)
linking pair of nodes. Mathematically, it is
represented by a graph G ¼ (V, E) where V is
the set of nodes and E  V  V is the set of
edges. Additional information can be attached
to each node or edge, for example, edges can
have different weights. Edges can be undi-
rected or directed.
Path A path on a graph is a walk in which all
vertices and edges are distinct.
Walk A walk is an alternating sequence of verti-
ces and edges in which every vertex is incident
to both the edges that come before and after it
in the sequence.
Why Study Networks?
In
network
science
complex
systems
are
represented as a mathematical graph consisting
of a set of nodes representing the components
and a set of edges representing their interactions.
The framework of networks has led to signiﬁcant
advances in the understanding of the structure,
formation, and function of complex systems
(Albert and Barabasi 2002; Newman 2003;
Boccaletti et al. 2006; Barrat et al. 2008). Social
and biological processes such as the dynamics of
epidemics (Pastor-Satorras et al. 2015), the diffu-
sion of information in social media (Zhang et al.
2016), the interactions between species in ecosys-
tems (Montoya et al. 2006), or the communication
between neurons in our brains (Bullmore and
Sporns 2009) are all actively studied using
dynamical models on complex networks. In all
of these systems, the patterns of connections at
© Springer Science+Business Media, LLC, part of Springer Nature 2022
B. Chakraborty (ed.), Statistical and Nonlinear Physics,
https://doi.org/10.1007/978-1-0716-1454-9_765
Originally published in
R. A. Meyers (ed.), Encyclopedia of Complexity and Systems Science, © Springer Science+Business Media LLC 2021
https://doi.org/10.1007/978-3-642-27737-5_765-1
599

the individual level play a fundamental role on the
global dynamics and ﬁnding the most important
nodes allows one to better understand and predict
their behaviors.
Definition of the Subject
Real-world complex networks are characterized by
a number of structural features differentiating them
from regular networks, such as lattices, but also
making them different than completely random
graphs, such as Erdős-Rényi graphs (Newman
2003). The properties that can be found in complex
networks include, for example, a modular organi-
zation, also called community structure (Fortunato
2010), or the so-called small-world effect, i.e., the
fact that most pairs of nodes are connected by a
very short path compared to the sizes of the net-
works (Watts and Strogatz 1998). A characteristic
of real-world complex networks that interests us
here and that has been intensively studied is the fact
that their degree distributions are usually very het-
erogeneous (Albert and Barabasi 2002; Newman
2003), indicating that there are usually large differ-
ences in the number of connections that nodes
have. Many real-world networks have been found
to have degree distributions resembling power laws
and are sometimes referred to as scale free
(Barabási 2009). Whether these real-world systems
are really scale free and whether their degree dis-
tributions are really power laws is still disputed
(Holme 2019). However, what is undeniable is
the fact that many real-world networks have degree
distributions that are heavy tailed with a minority
of the nodes concentrating the majority of the
connections.
In these systems, a small set of essential nodes
can shape the collective dynamics of the entire
systems. For example, during epidemic outbreaks
of infectious diseases, some individuals, known as
super-spreaders, infect disproportionately more
secondary contacts, as compared to most others
(Kitsak et al. 2010; Stein 2011), keystone species
in ecology are responsible for the integrity and
stability of ecosystems (May 1972; Mills et al.
1993; Scheffer et al. 2012; Morone et al. 2019)
and speciﬁc regions in brain networks are more
important than others in the formation of memory
(Bullmore and Sporns 2009; Zamora-Lóapez et al.
2010; Reis et al. 2014; Del Ferraro et al. 2018). In
social networks, a small set of inﬂuencers can
drive the global dynamics of the system (Bovet
and Makse 2019) and opinion leaders are capable
of inﬂuencing the public viewpoint on certain
trending topics (Watts and Dodds 2007). An
important research effort in network science has
therefore been dedicated to the development of
methods allowing to ﬁnd the most important
nodes in networks. Intuitively, nodes with a large
degree are likely to be more successful to trigger
large-scale propagations or to control a large num-
ber of nodes. The degree centrality ranks nodes in
terms of their degree and allows to identify highly
connected hubs present in most real-world com-
plex networks that play an essential role in con-
trolling their dynamics and maintaining their
integrity (Barabasi and Albert 1999; Albert et al.
2000; Cohen et al. 2001). While the degree cen-
trality is arguably the simplest centrality measure,
it only uses local information about each node to
rank its centrality and more complex centrality
measures have been developed in order to capture
the collective network effects impacting the inﬂu-
ence of a node. Most centrality measures are based
on a notion of distance between nodes or on a way
to traverse the network that allows to compute
how “central” a node is compared to other nodes
while capturing the heterogeneous structural pat-
terns of complex networks. In the following, we
describe centrality measures based on the notions
of network traversal they rely on. This short entry
aims at being an introduction to this extremely
vast topic, with many contributions from several
ﬁelds, and is by no means an exhaustive review of
all the literature about network centralities (see,
for example, (Freeman 1978; Borgatti 2005; Perra
and Fortunato 2008; Landherr et al. 2010;
Rodrigues 2019) for more exhaustive reviews).
Centrality Measures Based on Shortest Paths
Closeness centrality (Bavelas 1950; Beauchamp
1965; Sabidussi 1966; Dangalchev 2006) and
betweenness centrality (Freeman 1978; Friedkin
1991) are two dual measures of centrality initially
developed in social sciences to assess the
600
Centralities in Complex Networks

importance in terms of ease of access to others
nodes
(closeness)
and
brokering
power
(betweenness) of individuals in social networks.
These centralities have since then been used in
many other contexts. They are based on the
assumption that information, or inﬂuence, propa-
gates between two nodes in the most efﬁcient way,
i.e., by following the shortest path between them.
Considering an unweighted and undirected
graph G ¼ (V, E), a walk on the graph G is an
alternating sequence of vertices and edges in
which every vertex is incident to both the edges
that come before and after it in the sequence.
A path on a graph is a walk in which all vertices
and edges are distinct. A graph is said to be
connected if there exists a path from any node to
any other node in the graph. Considering the
distance dist(s, r) between two nodes s and r in a
connected undirected and unweighted graph G ¼
(V, E) as the number of edges in the shortest path
between them, the total distance of vertex u is
deﬁned as the sum of its distance to all other
vertices
dist sð Þ ¼
X
r  V
dist s, r
ð
Þ,
which is larger for vertices that are the farther
away from other vertices. Therefore, the closeness
centrality of a node s on a connected and undi-
rected network is usually deﬁned as (Bavelas
1950; Beauchamp 1965)
cC sð Þ ¼
1
P
r  Vdist s, r
ð
Þ ¼
1
dist sð Þ
ð1Þ
The
betweenness
centrality
captures
the
brokering power of a node as the opportunity it
has to intercept or inﬂuence the communications
happening between pairs of other nodes. Let s(s, r)
be the number of shortest paths between s and
r and let s(s, r|b) be the number of shortest paths
between s and r passing by a brokering node
b  V \{s, r}. We consider s(s, s) ¼ 1 and s(s,
r|b) ¼ 0 if b  {s, r}. We call the quantity
d s, b, r
ð
Þ ¼ s s, rjb
ð
Þ
s s, r
ð
Þ
the dependency of a sender
s and a receiver r on a broker b (Brandes et al.
2016). The betweenness centrality in a connected
and undirected graph G ¼ (V, E) is deﬁned as the
sum of dependencies of all communicating pairs
on a broker b (Freeman 1980)
cB b
ð Þ ¼
X
s, r  V
s s, rjb
ð
Þ
s s, r
ð
Þ ¼
X
s, r  V
d s, b, r
ð
Þ,
ð2Þ
and can be seen as the overall potential control of
b on the communications in G. Betweenness and
closeness centrality can be seen as being dual to
each other conceptually expressing either the
independence
from
the
control
of
others
(closeness) or the potential control over others
(betweenness) (Freeman 1980; Brandes et al.
2016). Indeed, by noting that when considering
shortest paths between s and r with different brokers
b at a ﬁxed distance d from s (1  d < dist(s, r))
each shortest path pass through exactly one
broker and therefore P
b  V:dist s,b
ð
Þ¼d
s s, rjb
ð
Þ
s s, r
ð
Þ ¼ 1:
This implies that the sum of dependencies
between a sender s and a receiver r taken
over of possible brokers b is proportional to
the distance between s and r: P
bd s, b, r
ð
Þ ¼
Pdist s,r
ð
Þ1
d¼1
P
b  V:dist s,b
ð
Þ¼d
s s, rjb
ð
Þ
s s, r
ð
Þ ¼ dist s, r
ð
Þ  1:
This
observation allows
one to
deﬁne the
closeness centrality as cC(s)1 ¼ (N  1) þ
 b, r
 
Vδ (s, b, r) revealing its mathematical
duality with betweenness centrality as a different
partial sum, over b and r instead of s and r, of the
dependencies δ(s, b, r) showing its interpretation
as a measure of lack of independence on others
(Brandes et al. 2016). Figure 1 shows the kite
graph introduced by Krackhardt in 1990 as an
illustration of the different ranking obtained by
these centrality measures (Krackhardt 1990).
In
directed
networks,
closeness
and
betweenness centrality can be generalized by
considering the notion of reachability instead
of distance. In weighted networks where edge
weights typically represent a distance or a lag
in the connection between adjacent nodes, the
length of a path is usually taken as being the
sum of the weights of its edges. We refer the
reader to (Brandes et al. 2016) for a discussion
about the generalizations of the closeness and
betweenness centrality to directed and weighted
networks, and to their interpretations in these
cases.
Centralities in Complex Networks
601

Many variants of closeness and betweenness
have been developed (Brandes 2008). The con-
cept of betweenness centrality has also been
extended to edges by considering the number of
shortest paths containing an edge instead of a
node in Eq. (2) (Brandes 2008) or, for example,
by considering the fraction of minimum spanning
trees of a graph that contain a given edge (Teixeira
et al. 2015). Versions of the closeness and
betweenness centralities based on random walks
instead of shortest paths have also been developed
(White and Smyth 2003; Newman 2005).
Centrality Measures Based on Walks
Several widely used centrality measures can be
seen as being based on the concept of graph
walks. Walks, alternating sequences of vertices
and edges in which every vertex is incident to
both the edges that come before and after it in
the sequence, are useful to count the number of
possible ways there is to reach a given node
starting from another node. Centrality measures
based on walks usually try to ﬁnd the nodes from
which there are the largest number of walks
reaching other nodes. For unweighted networks,
the number of walks of length ‘ existing between
two nodes i and j is given by the element (i, j) of
the ‘th power of the adjacency matrix: (A‘)ij. The
number of walks of length ‘ starting from node i is
then given by w(‘)i ¼  j(A‘)ij or in matrix nota-
tion w(‘) ¼ A‘1, where 1 is the unit vector. The
degree centrality of a node i can be expressed as
the number of walks of length 1 starting from it:
cdeg ið Þ ¼ w 1
ð Þi ¼
X
j
Aij:
ð3Þ
In order to take into account information about
the surrounding of a node in its centrality score,
several researchers have developed centrality
measures that consider longer walks. The idea
being that if a node is close to a node with a high
centrality, its centrality should also be high (Katz
1953; Bonacich 1972). Starting from an initial
guess for the centrality of each node given by
the vector x(0) (e.g. x(0) ¼ 1), we can propagate
this initial centrality through walks of a given
length. The centrality vector for walks of length
‘ is given by
x ‘ð Þ ¼ A‘x 0
ð Þ:
ð4Þ
Writing the initial centrality as a linear combi-
nation of the eigenvector of the adjacency matrix,
one can see that as l ! 1 the centrality will
converge to a vector proportional to the leading
eigenvector of A, the one corresponding to its
largest eigenvalue, and that takes into account
global information about the network structure
(Newman 2010). As A is nonnegative and if G is
connected, the Perron-Frobenius theorem ensures
that the leading eigenvector is positive and that the
associated eigenvalue is positive and simple. The
resulting vector is called the eigenvector centrality
whose element i is deﬁned as
ceig ið Þ /
X
j
Aijceig j
ð Þ:
ð5Þ
In weighted networks, the eigenvector central-
ity is propagated along walks on the graph that are
weighted by the edge weights. The eigenvector
centrality can be computed similarly on directed
and undirected networks with the difference that
for directed networks, the adjacency matrix is in
Centralities in Complex Networks, Fig. 1 Krackhardt
kite graph showing the different ranking obtained using
degree, closeness, and betweenness centralities (Krackhardt
1990). The closeness of a node is represented by its size and
the betweenness of a node is indicated by its color with nodes
with larger betweenness being of a lighter shade. The node
with largest degree centrality is 3. Nodes 5 and 6 have the
largest closeness centrality and node 7 has the largest
betweenness centrality
602
Centralities in Complex Networks

general asymmetric and has therefore two differ-
ent sets of left and right eigenvectors. Depending
on the application, one may prefer to use the
largest left eigenvector or the largest right eigen-
vector if one is more interested in nodes having a
large number of incoming walks or outgoing
walks, respectively. However, other types of cen-
tralities are usually preferred for directed net-
works as the eigenvector centrality of nodes
outside of a strongly connected component
(a subgraph where there exists a path in both
directions between all pairs of nodes) may be
equal to zero. In particular, in directed graphs
without cycles (closed directed paths), the eigen-
vector
centrality
is
zero
for
all
nodes.
A comparison of the degree centrality with the
eigenvector centrality is shown in Fig. 2 for an
undirected network of American football teams
(Girvan and Newman 2002; Evans 2010).
The subgraph centrality is based on the idea of
counting the number of times that a node takes
part in the different connected subgraphs of a
network, with smaller subgraphs having higher
importance (Estrada and Rodríguez-Velázquez
2005). The subgraphs are identiﬁed by counting
closed walks of different lengths that start and end
on a given node. The subgraph centrality of node
i is deﬁned as
cSub ið Þ ¼
X
1
‘¼0
A‘


ii
‘!
:
ð6Þ
By noticing that cSub(i) ¼ (eA)ii, where eA
denotes the matrix exponential of A, the subgraph
centrality can be obtained from the spectrum of
the adjacency matrix as (Estrada and Rodríguez-
Velázquez 2005)
cSub ið Þ ¼
X
N
i¼1
ui
j

2
el j,
ð7Þ
where u1, u2,..., uN form an orthonormal basis of
ℝN and are eigenvectors of A associated with the
eigenvalues l1, l2,..., lN. This centrality is more
discriminative than the degree, betweenness,
closeness, or eigenvector centralities and gives a
distinctly different ranking of nodes in real-world
complex
networks
(Estrada
and
Rodríguez-
Velázquez 2005).
Another centrality measure based on walks that
tries to solve the issue of the eigenvector centrality
Centralities in Complex Networks, Fig. 2 Network of
American football games between Division IA colleges
during regular season Fall 2000 (Girvan and Newman
2002; Evans 2010). Degree centrality for this undirected
graph is shown on the left and eigenvector centrality is
shown on the right. Lighter shades indicate a higher
centrality. Several nodes have the same degree in this
network making the degree centrality unable to disentangle
the importance of nodes with the same degree. Eigenvector
centrality has a tendency of being localized in regions
where many high degree nodes are close to each other
Centralities in Complex Networks
603

in directed networks is the Katz centrality (Katz
1953). The Katz centrality of node i is the
weighted sum of all walks emanating from i,
with the count for walks of length ‘ weighted by
a factor α‘ where 0 < α < 1. In this way the
importance of longer walks is diminished com-
pared to shorter walks. The Katz centrality of
node i can be written as (Katz 1953)
cKatz ið Þ ¼ 1 þ
X
1
‘¼1
X
j
a‘ A‘


ij,
ð8Þ
where the unit shift does not alter the ranking of
the nodes and may be seen as arising from a single
walk of length zero. In order for the centrality to
converge, the factor α must be smaller than the
reciprocal of the absolute value of the largest
eigenvalue of A (Katz 1953; Bonacich 1972;
Bonacich 1987). In this case, we can also note
that I þ αA þ α2 A2 þ α3 A3 þ . . . ¼ (I – αA)1.
Thus, the vector x giving the Katz centrality of
each node is also solution of the matrix equation
x ¼ (I – αA)1 1 which can be rewritten as x ¼
αAx þ 1. The Katz centrality can therefore be
computed iteratively in a similar manner than the
eigenvector centrality (with Eq. (4)) using
x t þ 1
ð
Þ ¼ aAx tð Þ þ 1:
ð9Þ
A unit value is added at each iteration
guaranteeing that the Katz centrality will never be
equal to zero, even in directed networks. The factor
α can also be seen as balancing the importance of
the eigenvector term compared to the constant term
added at each iteration. In the limit as α approaches
the reciprocal of the absolute value of the largest
eigenvalue of A, the Katz centrality approaches the
eigenvector
centrality
on
strongly
connected
graphs (Bonacich 1972; Bonacich 1987).
Walk-based centralities have been generalized
to hypergraphs (e.g., (Bonacich et al. 2004;
Benson 2019), multiplex networks (e.g., Solá
et al. 2013; De Domenico et al. 2015), and tem-
poral
networks
(e.g.,
Nicosia
et
al.
2013;
Praprotnik and Batagelj 2015; Taylor et al. 2017).
Centrality Measures Based on Random Walks
Random walks on graphs have been extensively
studied and have many applications in the study of
diffusive processes on networks and for the char-
acterization of the structure of complex networks
(Rosvall and Bergstrom 2008; Delvenne et al.
2010;
Durrett
2010;
Masuda
et
al.
2017).
A random walk on a graph is deﬁned by the
trajectory of a walker that, at each time step,
jumps to a neighbor of a node i with equal prob-
ability. On an unweighted and undirected net-
work, the transition probability for a walker on
node i to jump to node j is equal to
Tij ¼ Aij
ki ,
ð10Þ
or in matrix notation T ¼ D–1A, where D ¼ diag (k)
is the diagonal degree matrix. In directed net-
works, the degree is replaced by the out-degree
and in weighted networks with positive weights,
the probability transition is proportional to the
weight of edge (i, j). Centrality measures based
on random walks exploit the fact that, if a central-
ity value propagates as a random walk, at each
iteration, its value is divided across all outgoing
edges of a node. This is different than for eigen-
vector and Katz centralities, based on walks,
where the centrality tends to concentrate on a
few hubs in the network, leaving other nodes
almost indistinguishable with very low scores
due to the repeated reﬂection of inﬂuence along
the mutual connections between hubs during iter-
ations of Eqs. (4) and (9) (see Figs. 2 and 3).
The distribution probability of ﬁnding a walker
at time step n on any node of the network can be
written as a row-vector p(n) with  i pi ¼ 1. The
evolution
of
the
distribution
probability
is
given by
p n þ 1
ð
Þ ¼ p n
ð ÞT:
ð11Þ
On connected undirected network, the random
walk reaches a stationary distribution satisfying
p* ¼ p*T where the probability at each node is
proportional to its degree:
p
i ¼
ki
P
jk j :
ð12Þ
On undirected networks, the degree centrality
can therefore also be seen as the stationary state of
604
Centralities in Complex Networks

the random walk process. On directed networks,
random walks are not guaranteed to converge to a
unique stationary state. A stationary distribution
only exists on strongly connected components of
a directed network (Aldous and Fill 2014; Masuda
et al. 2017).
To overcome this issue the PageRank central-
ity modiﬁes the classical random walk by intro-
ducing a “teleportation” probability, i.e., at each
step the walkers have a given probability to tele-
port uniformly at random to any other nodes of the
network. The updated equation for the PageRank
probability density is given by (Brin and Page
1998; Page et al. 1999; Masuda et al. 2017)
p n þ 1
ð
Þ ¼ ap n
ð ÞS þ 1  a
N
1T,
ð13Þ
where S is a transition matrix constructed from
A such that Sij ¼ Aij/kout(i) when kout( i) > 0. For
“dangling nodes,” which have no outgoing edges
(i.e., kout(i) ¼ 0), Sij ¼ 1/N, meaning that a walker
on such a node has a uniform probability to jump
to any other nodes in the network. On non-
dangling nodes, at each step, walkers have a prob-
ability α < 1 to follow an outgoing edge and a
probability 1 – α to teleport to any node in the
network. This modiﬁed random walks is now
ergodic also on networks that are not strongly
connected and converges to the probability
density vector giving the PageRank centrality of
node i as
cPR ið Þ ¼ a
X
j
cPR j
ð ÞSji þ 1  a
N
ð14Þ
which is equal to the normalized eigenvector
corresponding to the largest positive eigenvalue
of the so-called Google matrix G ¼ aS þ 1a
N 11T
(Ermann et al. 2015). PageRank was famously
developed for ranking websites for the search
engine Google considering a “random surfer
model” navigating through webpages by ran-
domly clicking on hyperlinks (Page et al. 1999).
PageRank also found many applications in other
aspects, such as ranking scientists and academic
papers (Ding et al. 2009), images (Jing and Baluja
2008), and proteins (Ivaan and Grolmusz 2010).
Figure 3 shows a comparison of the PageRank and
Katz centralities on a directed network of hyper-
links between weblogs (Adamic and Glance
2005). The similarities between Eqs. (4) and (11)
as well as Eqs. (9) and (13) reveal that the degree
and the PageRank centralities can be seen as sim-
ilar to the eigenvector and Katz centralities, but
for random walks instead of regular graph walks.
In the case of random walk–based centralities, one
looks for eigenvectors of transition matrices
instead of adjacency matrices.
Centralities in Complex Networks, Fig. 3 A directed
network of hyperlinks between weblogs on US politics,
recorded in 2005 by Adamic and Glance (Adamic and
Glance 2005). PageRank centrality is shown on the left
and Katz centrality is shown on the right. Lighter shades
indicate a higher centrality. The Katz centrality has a ten-
dency of being “localized” in regions with many close by
hubs
Centralities in Complex Networks
605

Centrality Measures Based on Non-
Backtracking Walks
In order to address the issue of “localization” of the
eigenvector centrality mentioned above, i.e., when
most of the weight of centrality vector concentrates
around one or a few nodes in the network, several
authors have focused on using non-backtracking
walks instead of regular or random walks (Martin
et al., 2014; Arrigo et al., 2018, 2020). Non-
backtracking walks are graph walks where back-
tracking steps, i.e., steps where the walk comes
back to an immediately preceding node, are not
permitted. Using this type of walks can sometimes
solve the problem of localization as they decrease
reﬂections between hubs during iterations of the
centrality (Martin et al., 2014). Non-backtracking
walks
on
unweighted
networks
are
usually
described using the 2 M  2 M matrix B where
rows and columns correspond to the directed edges
of the network (M ¼ |E|). If the network is undi-
rected, an equivalent directed network is consid-
ered by replacing each edge by a pair of directed
edges in both directions. Element (i ! j, ‘ ! h) of
B is equal to one only if j ¼ ‘ and i 6¼ h, i.e., there is
a non-backtracking path of length 2 i ! j ! h in
the network. More succinctly,
Bi!j,‘!h ¼ dj‘ 1  dih
ð
Þ,
ð15Þ
where δij is the Kronecker delta. The matrix B is
referred to as the non-backtracking matrix or the
Hashimoto matrix (Hashimoto 1989). Powers of
B enumerate non-backtracking walks similarly to
powers of the adjacency enumerate walks (Arrigo
et al. 2020). The non-backtracking matrix is in
general asymmetric with eigenvalues that are in
general complex, however, since its entries are non-
negatives, by the Perron-Frobenius theorem, its
leading eigenvalue, l, is real and nonnegative, and
there exists a corresponding leading eigenvector, v,
whose elements are also nonnegative real numbers.
If G is connected and not a tree, i.e., it has at least
one cycle, l is positive (Lin and Zhang 2019). The
eigenvalues satisfy the eigenvector equation
lv ¼ Bv
ð16Þ
and the non-backtracking eigenvector centrality
of node j is deﬁned by (Martin et al., 2014)
cNBeig jð Þ ¼
X
i
Aijui!j:
ð17Þ
Finding the leading eigenvector of B can how-
ever be computationally demanding for large
graphs as the size of B is usually much larger
than the size of A. However, the computation
can be made much faster by computing directly
cNBeig as the ﬁrst N elements of a 2 N  2 N matrix
called
the
Ihara-Bass
matrix
(Krzakala
et al. 2013).
Non-backtracking walks have also been used
to modify other centrality measures, such as the
Katz (Arrigo et al., 2018), random walk (Lin and
Zhang 2019), or PageRank (Aleja et al. 2019)
centralities. Research on centrality measures
based on non-backtracking walks is very active
with recent results showing that they can also
suffer from localization issues on some networks
(Barucca
et
al.
2016;
Pastor-Satorras
and
Castellano 2020).
Non-backtracking walks are also used in the
problem of inﬂuence maximization: ﬁnding the
minimal set of nodes, the inﬂuencers, which, if
activated, would cause the spread of information
to the whole network, or, if immunized, would
prevent the diffusion of a large-scale epidemic
(Kempe et al. 2003). Inﬂuence maximization can
be mapped to the problem of optimal percolation
of random networks (Morone and Makse 2015)
which consist in identifying the minimal set of
nodes whose removal would dismember the net-
work in many disconnected and nonextensive
components. The fragmentation of the network
is measured by the size of the largest connected
component, called the giant component of the
network.
The intuition behind the usage of non-
backtracking walks in the optimal percolation
problem comes from the fact that the giant com-
ponent is held together by long paths and that
powers of the non-backtracking matrix allows to
quickly ﬁnd them. The removal of nodes is
represented with the vector n ¼ (n1,..., nN) where
ni ¼ 0 if i is removed (inﬂuencer) or ni ¼ 1
otherwise. Considering undirected locally tree-
like random graphs, a modiﬁed 2 M  2 M non-
606
Centralities in Complex Networks

backtracking
matrix
M
is
then
deﬁned
as
Mi!j,‘!h ¼ n‘Bi!j,‘!h. Given an initial arbit-
rary positive vector w(0), repeated iterations
with M,
w n
ð Þi!j ¼
X
kl
Mi!j,k!lw n  1
ð
Þk!l,
ð18Þ
increase the norm of the vector as the inﬂuence of
nodes on non-backtracking walks of increasingly
lager lengths is included. The growth rate of the
vector’s norm is determined by the value of the
largest eigenvalue, l(n), of the modiﬁed non-
backtracking matrix. As the inﬂuencer nodes are
removed, the value of l(n) decreases until the
giant component is reduced to a tree (a graph
without cycles) plus only one cycle when l(n) ¼
1. The removal of supplementary nodes quickly
destroys the giant component and l(n) falls to
zero (Morone and Makse 2015). The optimal
inﬂuence problem can therefore be rephrased as
ﬁnding the optimal conﬁguration n that minimizes
the largest eigenvalue of M (Morone and Makse
2015), which consists in removing the nodes that
are on the most non-backtracking walks in the
network and that are keeping the giant component
connected. The collective inﬂuence (Morone and
Makse 2015) of a node, deﬁned as
CI‘ ið Þ ¼ ki  1
ð
Þ
X
j  @Ball i, ‘
ð
Þ
k j  1


,
ð19Þ
where @Ball(i, ‘) is the set of the nodes at a distance
i from ‘, is a measure of which node to remove in
order to produce the largest diminution of the larg-
est eigenvalue of non-backtracking matrix. The
ranking of the nodes in term of collective inﬂuence
is produced by removing the node with the largest
CI value, recomputing the CI values of its neigh-
bors and repeating the operation until the giant
component of the network disappears. An advan-
tage of CI is that it gives a high rank to seemingly
“weak nodes” with a small number of connections
that are in fact surrounded by highly connected
nodes and therefore on the path of many non-
backtracking walks. The problem of inﬂuence
maximization in networks is actively researched
using many different approaches (see, for example,
Braunstein et al. 2016; Mugisha and Zhou 2016;
Zdeborová et al. 2016; Radicchi and Castellano
2016; Pan et al. 2016, Pei et al. 2020).
Conclusion and Future Directions
We have seen that there is not a single measure of
centrality in networks and that one should carefully
choose an appropriate measure depending on the
subject of investigation. In practice, centrality mea-
sures should be chosen depending on whether the
network is directed or not and whether, for exam-
ple, one is looking for highly connected nodes,
nodes with the most brokering power, nodes that
share the most inﬂuence with each others, or the
minimal set of nodes that can spread information to
the whole network. The differences in ranking
obtained from different centrality measures should
also be examined in order to better understand the
signiﬁcation of each ranking in a given context.
The research landscape on centrality measures
for complex networks is much vaster than what
has been presented in this short entry. Research is
very active with recent and future directions
including, for example, the properties of centrality
measures
based
on
non-backtracking
walks
(Pastor-Satorras and Castellano 2020), centralities
in signed networks (networks where weights can
be positive or negative) (Liu et al. 2020), and
multilayer networks (Solá et al. 2013; De
Domenico et al. 2015; Wang and Zou 2018; Wu
et al. 2019). Research is also active on the devel-
opment of centralities for speciﬁc applications
based on network dynamics not necessarily cap-
tured by network traversals. Examples include
centralities for social networks based on game
theoretical concepts (Shapley 1953; Gómez et al.
2003; Michalak et al. 2013), centralities for
detecting vulnerabilities in power grids based on
networks of oscillators (Gutierrez et al. 2013;
Tyloo et al. 2018; Tyloo et al. 2019), or centralities
for identifying key genes in gene regulatory net-
works based on the propagation of biological sig-
nals (Zotenko et al. 2008; Missiuro et al. 2009;
Kim et al. 2011; Cowen et al. 2017).
Research is also ongoing about the develop-
ment of centralities in network models that extend
the concept of network as an ensemble of static
Centralities in Complex Networks
607

pairwise relations, namely centralities in temporal
networks, i.e., time-evolving networks (Nicosia
et al. 2013; Praprotnik and Batagelj 2015; Taylor
et al. 2017; Flores and Romance 2018; Lv et al.
2019), and in hypergraphs or simplicial com-
plexes, i.e., generalizations of graphs where an
edge can join more than two nodes (Bonacich
et al. 2004; Estrada and Ross 2018; Benson
2019; Aksoy et al. 2020; Serrano and Gaomez
2020).
Acknowledgments Funding
was
provided
by
NIH
NIBIB EB028157 and NSF DMR 1945909.
Bibliography
Adamic LA, Glance N (2005) Proceedings of the 3rd
international workshop on Link discovery. Association
for Computing Machinery, New York, pp 36–43
Aksoy SG, Joslyn C, Marrero CO, Praggastis B, Purvine
E (2020) EPJ Data Science 9:16
Albert R, Barabasi A-L (2002) Rev Mod Phys 74:47
Albert R, Jeong H, Barabasi A-L (2000) Nature 406:378
Aldous D, Fill J (2014) Reversible Markov chains and
random walks on graphs. Unﬁnished monograph
Aleja D, Criado R, del Amo AJG, Paerez A, Romance
M (2019) Chaos, Solitons Fractals 126:283
Arrigo F, Grindrod P, Higham DJ, Noferini V (2018)
J Comp Netw 6:54
Arrigo F, Higham DJ, Noferini V (2020) Proceedings of
the Royal Society A: Mathematical, Physical and Engi-
neering. Sciences 476:20190653
Barabási A-L (2009) Science 325:412
Barabasi A-L, Albert R (1999) Science 286:509
Barrat A, Barthelemy M, Vespignani A (2008) Dynamical
processes on complex networks. Cambridge University
Press, New York
Barucca P, Tantari D, Lillo F (2016) Journal of Statistical
Mechanics: Theory and Experiment 2016:023401
Bavelas A (1950) J Acoust Soc Am 22:725
Beauchamp MA (1965) Behav Sci 10:161
Benson AR (2019) SIAM J Math Data Sci 1:293
Boccaletti S, Latora V, Moreno Y, Chavez M, Hwang D-U
(2006) Phys Rep 424:175
Bonacich P (1972) J Math Sociol 2:113
Bonacich P (1987) Am J Sociol 92:1170
Bonacich P, Holdren AC, Johnston M (2004) Soc Net-
works 26:189
Borgatti SP (2005) Soc Networks 27:55
Bovet A, Makse HA (2019) Nat Commun 10:7
Brandes U (2008) Soc Networks 30:136
Brandes U, Borgatti SP, Freeman LC (2016) Soc Networks
44:153
Braunstein A, Dall’Asta L, Semerjian G, Zdeborová
L (2016) Proc Natl Acad Sci U S A 113:12368
Brin S, Page L (1998) Comp Netw ISDN Syst 30:107
Bullmore E, Sporns O (2009) Nat Rev Neurosci 10:186
Cohen R, Erez K, Ben-Avraham D, Havlin S (2001) Phys
Rev Lett 86:3682
Cowen L, Ideker T, Raphael BJ, Sharan R (2017) Nat Rev
Genet 18:551
Dangalchev C (2006) Physica A 365:556
De Domenico M, Solae-Ribalta A, Omodei E, Gaómez S,
Arenas A (2015) Nat Commun 6:1
Del Ferraro G, Moreno A, Min B, Morone F, Pérez-
Ramirez Ú, Pérez-Cervera L, Parra LC, Holodny A,
Canals S, Makse HA (2018) Nat Commun 9:2274
Delvenne JC, Yaliraki SN, Barahona M (2010) Proc Natl
Acad Sci 107:12755. arXiv:0812.1811
Ding Y, Yan E, Frazho A, Caverlee J (2009) J Assoc Inf Sci
Technol 60:2229
Durrett R (2010) Proc Natl Acad Sci 107:4491
Ermann L, Frahm KM, Shepelyansky DL (2015) Rev Mod
Phys 87:1261
Estrada E, Rodríguez-Velázquez JA (2005) Phys Rev
E 71:056103
Estrada E, Ross GJ (2018) J Theor Biol 438:46
Evans TS (2010) J Stat Mech Theory Exp 2010:P12037
Flores J, Romance M (2018) J Comput Appl Math
330:1041
Fortunato S (2010) Phys Rep 486:75. arXiv:0906.0612
Freeman LC (1978) Soc Networks 1:215
Freeman LC (1980) Qual Quant 14:585
Friedkin NE (1991) Am J Sociol 96:1478
Girvan M, Newman ME (2002) Proc Natl Acad Sci
99:7821
Gómez D, González-Arangüena E, Manuel C, Owen G, del
Pozo M, Tejada J (2003) Math Soc Sci 46:27
Gutierrez F, Barocio E, Uribe F, Zuniga P (2013) Discret
Dyn Nat Soc 2013:135731
Hashimoto K-i (1989) Adv Stud Pure Math 15:211
Holme P (2019) Nat Commun 10(1):1016
Ivaan G, Grolmusz V (2010) Bioinformatics 27:405
Jing Y, Baluja S (2008) IEEE Trans Pattern Anal Mach
Intell 30:1877
Katz L (1953) Psychometrika 18:39
Kempe D, Kleinberg J, Tardos É (2003) Proceedings
of the 9th ACM SIGKDD international conference
on knowledge discovery and data mining. Associ-
ation
for
Computing
Machinery,
New
York,
pp 137–146
Kim Y-A, Wuchty S, Przytycka TM (2011) PLoS Comput
Biol 7:e1001095
Kitsak M, Gallos LK, Havlin S, Liljeros F, Muchnik L,
Stanley HE, Makse HA (2010) Nat Phys 6:888
Krackhardt D (1990) Adm Sci Q 35(2):342–369
Krzakala F, Moore C, Mossel E, Neeman J, Sly A,
Zdeborovaa L, Zhang P (2013) Proc Natl Acad Sci
110:20935
Landherr A, Friedl B, Heidemann J (2010) Bus Inf Syst
Eng 2:371
Lin Y, Zhang Z (2019) Comput J 62:63
Liu W-C, Huang L-C, Liu CW-J, Jordan F (2020) Appl
Netw Sci 5:1
608
Centralities in Complex Networks

Lv L, Zhang K, Zhang T, Bardou D, Zhang J, Cai Y (2019)
Phys Lett A 383:1215
Martin T, Zhang X, Newman MEJ (2014) Phys Rev E 90:
052808. arXiv:1401.5093
Masuda N, Porter MA, Lambiotte R (2017) Phys Rep
716-717:1. arXiv:1612.03281
May RM (1972) Nature 238:413
Michalak TP, Aadithya KV, Szczepanski PL, Ravindran B,
Jennings NR (2013) J Artif Intell Res 46:607
Mills LS, Soulaé ME, Doak DF (1993) Bioscience 43:219
Missiuro PV, Liu K, Zou L, Ross BC, Zhao G, Liu JS, Ge
H (2009) PLoS Comput Biol 5:e1000350
Montoya JM, Pimm SL, Solé RV (2006) Nature 442:259
Morone F, Del Ferraro G, Makse HA (2019) Nat Phys
15:95
Morone F, Makse HA (2015) Nature 524:65
Mugisha S, Zhou H-J (2016) Phys Rev E 94:012305
Newman MEJ (2003) SIAM Rev 45:167
Newman MJ (2005) Soc Networks 27:39. arXiv:0309045
[cond-mat]
Newman M (2010) Networks: an introduction. OUP,
Oxford
Nicosia V, Tang J, Mascolo C, Musolesi M, Russo G,
Latora V (2013) Graph metrics for temporal networks.
In: Holme P, Saramäki J (eds) Temporal networks.
Understanding Complex Systems. Springer, Berlin,
Heidelberg, pp 15–40. https://doi.org/10.1007/978-3-
642-36461-7_2
Page L, Brin S, Motwani R, Winograd T (1999) The
PageRank citation ranking: Bringing order to the web,
Tech. Rep. (Stanford InfoLab), Stanford, California
Pan J, Jiang F, Xu J (2016) 2016 IEEE  rst international
conference on data science in cyberspace (DSC). IEEE,
pp 260–267
Pastor-Satorras R, Castellano C (2020) Sci Rep 10:1
Pastor-Satorras
R,
Castellano
C,
Van
Mieghem
P,
Vespignani A (2015) Rev Mod Phys 87:925
Pei S, Wang J, Morone F, Makse HA (2020) J Comp Netw
8:cnz029
Perra N, Fortunato S (2008) Phys Rev E 78:036107.
arXiv:0805.3322
Praprotnik S, Batagelj V (2015) Ars Math Contem 11:11
Radicchi F, Castellano C (2016) Phys Rev E 93:030302
Reis SD, Hu Y, Babino A, Andrade JS Jr, Canals S,
Sigman M, Makse HA (2014) Nat Phys 10:762
Rodrigues FA (2019) Network centrality: An introduction.
In: Macau E (eds) A mathematical modeling approach
from nonlinear dynamics to complex systems. Non-
linear systems and complexity, vol 22. Springer,
Cham, pp 177–196. https://doi.org/10.1007/978-3-
319-78512-7_10
Rosvall M, Bergstrom CT (2008) Proc Natl Acad Sci
105(1118). arXiv:0707.0609
Sabidussi G (1966) Psychometrika 31:581
Scheffer M, Carpenter SR, Lenton TM, Bascompte J,
Brock W, Dakos V, Van de Koppel J, Van de Leemput
IA, Levin SA, Van Nes EH et al (2012) Science
338:344
Serrano DH, Gaomez DS (2020) Appl Math Comput
382:125331
Shapley L (1953) In: Kuhn H, Tucker A et al (eds) Contri-
butions to game theory. Princeton University Press,
pp 307–317
Solá L, Romance M, Criado R, Flores J, García del Amo A,
Boccaletti S (2013) Chaos: An Interdiscip J Non-
linear Sci 23:033131
Stein RA (2011) Int J Infect Dis 15:e510
Taylor D, Myers SA, Clauset A, Porter MA, Mucha PJ
(2017) Multiscale Model Simul 15:537
Teixeira AS, Monteiro PT, Carrico JA, Ramirez M,
Francisco AP (2015) PLoS One 10:e0119315
Tyloo M, Coletta T, Jacquod P (2018) Phys Rev Lett
120:084101
Tyloo M, Pagnier L, Jacquod P (2019) Sci Adv 5,
eaaw8359
Wang D, Zou X (2018) Appl Math Model 54:46
Watts DJ, Dodds PS (2007) J Consum Res 34:441
Watts DJ, Strogatz SH (1998) Nature 393:440
White S, Smyth P (2003) Proceedings of the ninth ACM
SIGKDD international conference on knowledge dis-
covery and data mining, pp 266–275
Wu M, He S, Zhang Y, Chen J, Sun Y, Liu Y-Y, Zhang J,
Poor HV (2019) Proc Natl Acad Sci 116:15407
Zamora-Lóapez G, Zhou C, Kurths J (2010) Front
Neuroinform 4:1
Zdeborová L, Zhang P, Zhou H-J (2016) Sci Rep 6:37954
Zhang Z-K, Liu C, Zhan X-X, Lu X, Zhang C-X, Zhang
Y-C (2016) Phys Rep 651:1
Zotenko E, Mestre J, O’Leary DP, Przytycka TM
(2008) PLoS Comput Biol 4:e1000140
Centralities in Complex Networks
609

Optimization Problems and
Algorithms from Computer
Science
Heiko Rieger
Theoretical Physics, Universität des Saarlandes,
Saarbrücken, Germany
Article Outline
Glossary
Deﬁnition of the Subject
Introduction
Polymers in a Disordered Environment
Many Repulsive Elastic Lines in Random Media
Vortex Glasses and Loop Percolation
Interfaces and Elastic Manifolds
Random Field Ising Model
The Spin Glass Problem
Potts Free Energy and Submodular Functions
Future Directions
Bibliography
Glossary
Combinatorial optimization The search for an
optimal conﬁguration in terms of a cost func-
tion on a discrete set of allowed conﬁgurations.
Ground state The conﬁguration of a model for a
physical system of many interacting degrees of
freedom described by a Hamiltonian or energy
function that has the lowest energy. Also dented
as the global minimum of the energy of the
system.
Disordered system A physical system with fro-
zen in or quenched in homogeneities, usually
modeled by an energy function containing
parameters that are random numbers obeying
in prescribed probability distribution.
Universal properties Properties that do not
depend on microscopic details of a physical
system, like the critical exponents at a contin-
uous phase transition or fractal dimensions.
Network ﬂows A function deﬁned on the edges
of a graph that obeys mass balance constraints at
each node. A number of polynomial optimiza-
tion problems relevant for disordered systems
can be formulated as network ﬂow models.
Definition of the Subject
Optimization problems in statistical physics occur
whenever the ground state of a classical model for a
complex condensed matter system has to be deter-
mined, which is necessary for understanding its low
temperature properties. In some cases calculating
the ground state is an easy task as for instance for
the paradigmatic model for a ferromagnet: The
conﬁguration of all magnetic moments or spins
with the lowest energy is the one, where all spins
point in the same direction. But usually the situation
is much more complex and the problem of calcu-
lating the state with the lowest energy is highly non-
trivial. This occurs typically in systems with
quenched disorder and/or frustration, which means
that their Hamiltonian or energy function consists
of competing terms that cannot be satisﬁed simul-
taneously. Powerful algorithms from computer sci-
ence have been devised to ﬁnd the optimum of
complex cost-functions and in some cases this can
even be achieved in polynomial time. In recent
years many of these algorithms could be success-
fully applied to physically relevant model systems:
to polymers in random media, interface problems in
random ferromagnets, magnetic ﬂux-lines in disor-
dered environments, spin glasses, and many more.
Introduction
Solid materials which contain a substantial degree
of quenched disorder, so called disordered systems,
have been an experimental and a theoretical chal-
lenge for physicists for many decades. The differ-
ent thermodynamic phases emerging in random
© Springer-Verlag 2009
B. Chakraborty (ed.), Statistical and Nonlinear Physics,
https://doi.org/10.1007/978-1-0716-1454-9_378
Originally published in
R. A. Meyers (ed.), Encyclopedia of Complexity and Systems Science, © Springer-Verlag 2009
https://doi.org/10.1007/978-3-642-27737-5_378
611

magnets, the aging properties and memory effects
of spin glasses, the disorder induced conductor-
to-insulator transition in electronic or bosonic sys-
tems, the collective behavior of magnetic ﬂux lines
in amorphous high temperature superconductors,
and the roughening transition of a disordered
charge density wave systems are only a few exam-
ples for these fascinating phenomena that occur
due to the presence of quenched disorder.
Analytic studies of models for these systems are
usually based on perturbation theories valid for
weak disorder, on phenomenological scaling pic-
tures or on mean-ﬁeld approximations. Therefore
the demand for efﬁcient numerical techniques that
allow the investigation of the model Hamiltonians
of disordered systems has always been high. Three
facts make life difﬁcult here: (1) The regime, where
disorder effects are most clearly seen, are at low
temperatures – and are even best visible at zero
temperature; (2) the presence of disorder slows the
dynamics of these systems down, they become
glassy, such that for instance conventional Monte-
Carlo or molecular dynamics simulations encoun-
ter enormous equilibration problems; (3) any
numerical computation of disordered systems has
to incorporate an extensive disorder average.
In recent years more and more model systems
with quenched disorder were found that can be
investigated numerically (1) at zero temperature,
(2) without equilibration problems, (3) extremely
fast, in polynomial time (for reviews see [1–3]).
This is indeed progress, which became possible
by the application of exact combinatorial optimi-
zation algorithms developed by mathematicians
and computer scientists over the last few decades.
This gift is not for free: ﬁrst a mapping of the
problem of ﬁnding the exact ground state of the
model Hamiltonian under consideration onto a
standard combinatorial optimization problem has
to be found. If one is lucky, this problem falls into
the class of P-problems, for which polynomial
algorithms exist. If not, the intellectual challenge
for
the
theoretical
physicist
remains
to
reformulate the model Hamiltonian in such a
way that its universality class is not changed but
a mapping on a P-problem becomes feasible.
An optimization problem can be described
mathematically
in
the
following
way:
let
s ¼ s1, . . . , sn
ð
Þ be a vector with n elements
which can take values from a domain X n : si  X.
The domain X can be either discrete, for instance
X ¼ {0, 1} or X ¼ Z the set of all integers (in which
case it is an integer optimization problem) or X can
be continuous, for instance X ¼ R the real numbers.
Moreover, let H be a real valued function, the cost
function or objective, or in physics usually the
Hamiltonian or the energy of the system. The min-
imization problem is then:
Find s  Xn, whichminimizes H !
A maximization problem is deﬁned in an analo-
gous way. It is sufﬁcient to consider only minimi-
zation problems, since maximizing a function H is
equivalent to minimizing –H. Minimization prob-
lems in which the set X is countable are called
combinatorial [4–6]. Optimization methods for
real valued variables are treated mainly in mathe-
matical literature and in books on numerical
methods, see e.g. [8].
Constraints, must hold for the solution, may be
expressed by additional equations or inequalities.
An arbitrary value of s , which fulﬁlls all con-
straints, is called feasible. Usually constraints
can be expressed more conveniently without giv-
ing equations or inequalities. A famous example
is the Traveling Salesman Problem (TSP) [7].
The TSP has attracted the interest of physi-
cist several times. For an introduction, see [9].
The model is brieﬂy presented here. Consider
n cities distributed randomly in a plane. With-
out loss of generality the plane is considered to
be the unit square. The minimization task is to
ﬁnd the shortest round-tour through all cities
which visits each city only once. The tour stops
at the city where it started. The problem is
described by
X ¼ 1, 2, . . . , n
f
g
ð1Þ
H s
ð Þ ¼
X
n
i¼1
d si, siþ1
ð
Þ
ð2Þ
where d(sα, sβ) is the distance between cities sα
and sβ and sn þ 1  s1. The constraint that every
city is visited only once can be realized by
constraining the vector s to be a permutation of
the sequence [1, 2,. . ., n].
612
Optimization Problems and Algorithms from Computer Science

The optimum order of the cities for a TSP
depends on their exact positions, i.e. on the ran-
dom values of the distance matrix d. It is a feature
of all problems we will encounter here that they
are characterized by various random parameters.
Each random realization of the parameters is
called an instance of the problem. In general, if
we have a collection of optimization problems of
the same (general) type, we will call each single
problem an instance of the general problem.
Because the values of the random parameters
are ﬁxed for each instance of the TSP, one speaks of
frozen or quenched disorder. To obtain information
about the general structure of a problem one has to
average measurable quantities, like the length of
the shortest tour for the TSP, over the disorder.
In this article we give an overview of methods
how to solve these problems, i.e. how to ﬁnd the
optimum. Interestingly, there is no single way to
achieve this. For some problems it is very easy
while for others it is rather hard, this refers to the
time you or a computer will need at least to solve the
problem, it does not say anything about the elabo-
rateness of the algorithms which are applied. Addi-
tionally, within the class of hard or within the class of
easy problems, there is no universal method. Usu-
ally, even for each kind of problem there are many
different ways to obtain an optimum. Once a prob-
lem becomes large, i.e. when the number of vari-
ables n is large, it is impossible to ﬁnd a minimum by
hand. Then computers are used to obtain a solution.
Only the rapid development in the ﬁeld of computer
science during the last two decades has pushed
forward the application of optimization methods to
many problems from science and real life.
We will review some of the most fruitful appli-
cations of polynomial algorithms from the realm
of combinatorial optimization to various problems
in the statistical physics of disordered systems.
The next section presents the application of
Dijkstra’s algorithm for ﬁnding shortest paths in
weighted networks to the model of a non-directed
polymer in a disordered environment with iso-
tropical correlations. Then, in the fourth and ﬁfth
section, we discuss minimum cost ﬂow problems
on weighted graphs and its solution via the suc-
cessive shortest path algorithm and apply it to the
entanglement transition of elastic lines in a disor-
dered environment and to the loop percolation
transition in a vortex glass model. In the sixth
section we focus on the minimum cut-maximum
ﬂow problem and discuss among its many appli-
cations the roughening transition of elastic media
in a disordered environment. The seventh section
is devoted to the random ﬁeld Ising model and
how its ground states can be computed with
maximum-ﬂow-minimum-cut
techniques.
The
spin glass problem is presented in the eighth sec-
tion with a mapping onto minimum weighted
matching in two dimensions and a brief outline
of branch and cut methods for the higher dimen-
sional case. The ninth section is devoted to ﬁnite
temperature properties of the random bond Potts
model and how its free energy can be computed in
the limit of inﬁnite Potts states. An outlook in the
tenth section closes this chapter.
Polymers in a Disordered Environment
A well studied model of a single elastic line [10],
like an individual polymer or a single magnetic ﬂux
line in a type-II superconductor, in a disordered
environment is the following: If one excludes over-
hangs (and by this also self-overlaps) of the elastic
lines one can parametrize its conﬁguration by the
longitudinal coordinate z. The line conﬁguration
can then be described by the transverse coordinate
r(z) as a function of z. The presence of disorder is
usually modeled by a random potential energy
V(r, z) and the ground state conﬁguration of the
line is highly nontrivial due to the competition
between the elastic energy, that tends to straighten
the line, and the random energy, that tries to bend
the line into positions of favorable energy:
H singleline ¼ H elastic þ H random
¼
ðH
0
dz
g
2
dr
dz

2
þ V r zð Þ, z
½

(
)
,
ð3Þ
where H is the longitudinal length (not the proper
length) of the line. The random potential energy is
a Gaussian variable with prescribed mean and
correlations hhV[r,
z] V[r0,
z0]ii ¼ g(R  R0),
where R ¼ (r, z) and hh  ii denotes the average
over the disorder.
Optimization Problems and Algorithms from Computer Science
613

A lattice version of this continuum model is the
directed polymer model: The lines correspond to
directed paths on a hyper-cubic lattice that start at
a speciﬁc lattice site, say (0, 0,. . ., 0) and proceed
only in the (1, 1,. . ., 1) direction along the bonds.
The energy contribution for a path passing bond
i of the lattice is a positive random variable ei and
the total energy of a path P is simply
H lattice
singleline ¼
X
i  P
ei ¼
X
i
ei ni,
ð4Þ
where ni ¼ 1 if the path passes bond i (i.e. i  P)
and ni ¼ 0 otherwise.
One is interested in isotropically correlated
disorder and consider the problem on a non-
directed (square) lattice (i.e. paths can pass any
bond in both directions) in order not too exclude
overhangs right from the beginning. In case of
uncorrelated disorder overhangs were shown to
be irrelevant [12], but for isotropically correlated
disorder this is not clear. The latter is deﬁned to
decay algebraically with the spatial distance of the
bonds
ei  ej




¼ Ri  Rj

2a1,
ð5Þ
where Ri spatial position of bond i and α is the
correlation exponent: Note that one expects short-
range correlations like hhei  ejii / exp (|Ri 
Rj|/l) with a ﬁnite correlation length l, to be
irrelevant
and
only
long-range
correlations
like (5) to change the universality class of the
system. Increasing ˛ imply stronger correlations,
uncorrelated disorder corresponds to α ! –1.
The kind of correlated disorder described by (5)
can be realized by generating correlated random
numbers are generated using a well-established
numerical procedure [11].
Exact ground states of the Hamiltonian (4) or
optimal paths are calculated using Dijkstra’s algo-
rithm (note that all energies ei are positive). This
simple polynomial algorithm works as follows:
Let V ¼ {1,. . ., Ld} be the set of lattice sites and
A ¼ {(i, j)|i, j  V nearest neighbors} the set of
bonds. The algorithm increases successively a
subset S of sites for which the optimal path
starting at the ﬁxed site s are known. Obviously
initially S: ¼ {s}. We denote the energy of the
optimal path starting at s and terminating at i with
E(i) and since all optimal paths can be constructed
via a predecessor list, we keep track of this list,
too, via an array pred(i), denoting the predecessor
site of site i in a shortest path from s to i:
In Fig. 1 we show examples of the set ﬁg of
lattice sites that are end-points of optimal paths
starting from a ﬁxed initial site and having a total
energy E(i) less than a given value Emax. For
uncorrelated disorder the surface of this set is
roughly a semi-circle, whereas for strongly corre-
lated disorder the surface becomes topologically
more complicated.
The universal properties of the optimal paths
are typically described the scaling of two charac-
teristic quantities: The average transverse ﬂuctua-
tions hhr2ii and the average energy ﬂuctuations
Optimization Problems and Algorithms from Com-
puter Science, Fig. 1 Example for the growth front of
the non-directed polymer for uncorrelated disorder (a and
b) and correlated disorder (c and d; α ¼ 0.4). The black
pixels indicate the lattice sites of the (square) lattice are
connected via optimal paths to the offspring (center of the
top line) with energy less than a given value. (From
Ref. [13])
614
Optimization Problems and Algorithms from Computer Science

hhE2ii. Both are expected to grow algebraically
with the longitudinal distance H between starting
point and end point of the paths:
r2




/ Hn
and
E2




/ Ho,
ð6Þ
where n is called the roughness exponent and o
the energy ﬂuctuation exponent. For uncorrelated
disorder (α ! 1) one knows n ¼ 2/3 and o ¼ 1/3.
By computing the optimal paths for several thou-
sands of samples for a given disorder correlation
exponent α and for a given longitudinal distances
H and ﬁtting the resulting data for transverse and
energy ﬂuctuations to the expected power laws we
can extract the exponents n and o (for details see
[13]). The resulting estimates in 2d show that the
correlations are relevant for α > 0 and the rough-
ness exponent increases linearly for α > 0 from its
value for uncorrelated disorder n ¼ 2/3. Although
the number of overhangs in the optimal paths we
computed in the non-directed case increased with
α (i.e. increasing correlations) the fraction of
bonds contributing to overhangs scaled to zero
for all values of α we considered. Hence over-
hangs appear to be irrelevant also in the presence
of correlated disorder.
Many Repulsive Elastic Lines in Random
Media
When one puts interacting elastic lines together
into a ﬁnite system with a given density of lines
they will show interesting collective behavior.
Examples are the entanglement of magnetic ﬂux
lines in high-Tc superconductors in the mixed
phase [14] or the entanglement of polymers in
materials like rubber [15]. The degree of entan-
glement of the lines usually manifests itself in
various measurable properties like stiffness or
shear modulus in the case of polymers and in
transport or dynamical properties for magnetic
ﬂux lines in superconductors. A theoretical
description of these line systems can be based on
the single line Hamiltonian (3) plus an appropriate
line interaction term:
H manylines ¼
X
N
i¼1
H ið Þ
singleline
þ
X
i<j
ðL
0
dz
ðL
0
dz0 Vint Ri zð Þ  R j z0
ð Þ


,
ð7Þ
where Ri (z) ¼ (ri (z), z) is the spatial position of
the inﬁnitesimal line segment dz of the ith line. If
the interactions Vint[Ri(z) – Rj(z0)] are short ranged
(i.e. in case of ﬂux lines the screening length small
compared to the average line distance) or just hard
core repulsive, and the random, δ-correlated dis-
order potential Vr [ri (z), z] in (3) is strong com-
pared to the elastic energy (1 γ) this continuum
model reduces to a lattice model reminiscent of
the single-line lattice model (4):
H lattice
manylines ¼
X
i
eini,
ð8Þ
where ni ¼ 1 if a line passes bond i and ni ¼ 0
otherwise and the positive random variable ei
is the energy cost for a line segment to occupy
bond i. The hard core constraint is thus enforced
on the bonds but for the sake of an easier formal
description we allow the lines to touch in isolated
points, the lattice sites. The lines live on the bonds
of a simple cubic lattice with a lateral width L and
a longitudinal height H(L  L  H sites) with free
boundary conditions in all directions. Each line
starts and ends at an arbitrary position on the
bottom respective top planes. The number N of
lines threading the sample is ﬁxed by a prescribed
density r ¼ N/L2. For a single line N ¼ 1, one
recovers the non-directed polymer model (4). The
random bond energies are uniformly distributed
over the interval [0, 1].
Note that the allowed conﬁgurations of the
bond variables ni are only those that can be iden-
tiﬁed with lines threading the samples (or loops
inside the sample, which, however, cost energy
and therefore do not occur in the ground state),
which means that the number of occupied bonds
connected to a lattice site that lies neither on the
top nor on the bottom plane has always to be even.
If we connect all sites on the top to an extra site,
called the source, an all sites on the bottom to
Optimization Problems and Algorithms from Computer Science
615

another extra site, called the target, than the latter
statement remains true also for the top an bottom
plane. We can now say that N lines start at the
source node and terminate at the target node, or, in
network ﬂow jargon: The feasible conﬁgurations
of the variables ni constitute a ﬂow with zero
excess on all lattice sites and an excess +N and –
N for the source and target node, respectively.
Thus the determination of the ground state con-
ﬁguration of the N-line problem with the Hamilto-
nian (8) is a minimum-cost-ﬂow-problem, which
can be solved with a successive shortest path algo-
rithm [1–3]. In essence one starts with the zero ﬂow
ni ¼ 0, corresponding to zero lines in the system,
and sends successively one unit of ﬂow from the
source to the target, corresponding to adding one
line after the other to the system. This has to happen
with the minimal energy, i.e. along optimal paths,
which are calculated using Dijkstra’s algorithm that
we encountered already in the single line problem
discussed in the last section. However, when trying
to add a line to a system with a number, say M, of
lines already present, the existing line conﬁguration
sometimes must be changed to minimize the total
energy for M þ 1 line solution. That becomes
feasible by allowing ﬂow to be sent backwards on
already occupied bonds. By this operation one
gains energy (whereas occupying an empty bond
i always costs energy ei  0), which means one has
to operate on a network that has to be adapted to the
existing ﬂow conﬁguration and has negative ener-
gies on all occupied bonds. Unfortunately Dijkstra’s
algorithm works only for positive bond energies,
and one has either to use a slower (label-correcting)
algorithm to ﬁnd the optimal paths in a graph with
negative edge costs [3] or one has to use the concept
of node potentials, by which one can make all
energies in the adapted network non-negative with-
out changing the actual shortest paths. This proce-
dure is described in full detail in [3].
The resulting line conﬁguration is then ana-
lyzed. One computes the winding angle of all line
pairs as indicated in Fig. 2 (c.f. [16]). For each
z-coordinate the vector connecting the two lines is
projected onto that basal plane (left part of Fig. 2).
z ¼ 0 gives the reference line with respect to which
the consecutive vectors for increasing z-coordinate
have an angle f(z). If the two lines intersect one
neglects the intersection point and interpolate
between the last and the next point in such a way
that the global winding angle is minimized. One
deﬁnes two lines to be entangled when f(z) > 2π.
This choice is one that measures entanglement
from the topological perspective [17], and comes
Optimization Problems and Algorithms from Com-
puter Science, Fig. 2 Left: Ground state conﬁguration of
a N-line system with N ¼ 9 deﬁned by (8). The entry/exit
points are ﬁxed in a regular 3  3 array for better visibility.
Right: Deﬁnition of the winding angle of two ﬂux lines.
Right part, top: A conﬁguration of three lines that are
entangled. Right part, bottom: The projection of the line
conﬁguration on the basal plane, deﬁning a connected
cluster
616
Optimization Problems and Algorithms from Computer Science

from the requirement that an entangled pair of lines
can not be separated by a suitable linear transfor-
mation in the basal plane (i.e. the lines almost
always would cut each other, if one were shifted).
The precise deﬁnition of entanglement is not of
major relevance, and the one used is useful since
it is the computationally easiest.
Sets or bundles of pairwise entangled lines are
formed so that a line belongs to a bundle if it is
entangled at least with one other line in the set.
The topological multi-line-entanglement could
be characterized by other measures as well; the
universal properties of the transition will not
depend
on
these.
These
line
bundles
are
spaghetti-like – i.e. topologically complicated
and knotted sets of one-dimensional objects. To
study the size distribution of these objects one
projects these bundles on the basal plane, as
indicated in Fig. 2, where a bundle projects
onto a connected cluster. The probability for
two lines to be entangled increases with increas-
ing system height. Consequently one would
expect that the bundle size increases with H,
and therefore also their projections, the clusters.
This scenario is exempliﬁed in Fig. 3, for the
largest height the largest cluster spans from one
side of the system to the other, i.e. it percolates.
Hence, for a given line density r one expect
that for system heights larger than a critical value
Hc an system spanning large entangled bundle
occurs, containing an inﬁnite number of lines in
the limit L ! 1. One calls this an entanglement
transition occurring at a ﬁnite system height Hc.
In the projection plane this appears like a perco-
lation transition and in [18] it was shown that this
transition is in the same universality class as con-
ventional bond percolation.
Vortex Glasses and Loop Percolation
Another application of the successive shortest
path algorithm for minimum-cost-ﬂow-problems
is ﬁnding the ground state of the Hamiltonian
H ¼
X
i
ni  bi
ð
Þ2
withtheconstraint
8k :
X
l n:n:of k
n kl
ð Þ ¼ 0,
ð9Þ
where the integer variables ni live on the bonds i of
a
d-dimensional
hyper-cubic
lattice
and
bi  [–2s, 2s] are real valued quenched random
variables with s  0 setting the strength of the
disorder. The constraint  l n. n. of kn(kl) ¼ 0 means
that at all lattice sites k the incoming ﬂow has to
balance the outgoing ﬂow, i.e. the ﬂow {ni} is
divergenceless. The physical motivation of study-
ing models these kind of models is the following:
Optimization Problems and Algorithms from Com-
puter Science, Fig. 3 Line conﬁgurations for different
heights H ( from left to right: H ¼ 64, 96, 128), the lateral
size L ¼ 20, the line density is r ¼ 0.3. Only the largest line
bundles are shown, indicated by a varying gray scale.
Black denotes the largest cluster, which eventually
percolates
Optimization Problems and Algorithms from Computer Science
617

In 2d the Hamiltonian (9) occurs for instance
in the context of the solid-on-solid (SOS) model
on a disordered substrate [19]. The SOS repre-
sentation of a 2d surface is deﬁned by integer
height variables uk for each lattice site k of a
square
lattice.
The
disordered
substrate
is
modeled via random offsets dk  [0,
1] for
each lattice site, such that the total height at
lattice site k is hk ¼ uk þ dk. The total energy of
the surface is
H SOS ¼
X
kl
ð Þ
hk  hl
ð
Þ2
¼
X
~kl
ð Þ
n ~kl
ð Þ  b ~kl
ð Þ
	

2
ð10Þ
where the ﬁrst sum runs over all nearest neighbor
pairs (kl) of the square lattice and the second sum
runs over all bonds ~kl
 
of the dual lattice (being a
square lattice, too), which connect the centers of
the elementary plaquettes of the original lattice.
A dual bond
~kl
 
therefore crosses perpendicu-
larly a bond (kl) connecting neighbors k and l on
the original lattice. We deﬁne n ~kl
ð Þ ¼ nk  nl and
d ~kl
ð Þ ¼ dl  dk if l is either the right or the upper
neighbor of k (i.e. for k ¼ (x, y) either l ¼ (x þ 1, y)
or l ¼ (x, y þ 1) and n ~kl
ð Þ ¼ nl  nk and d ~kl
ð Þ ¼
dk  dl if l is either the left or the lower neighbor
of k (i.e. for k ¼ (x, y) either l ¼ (x – 1, y) or l ¼ (x,
y – 1)). In this way the sum over all four dual bond
variables attached to one site of the dual lattice
corresponds
to
the
sum
of
original
height
variables around an elementary plaquettes in the
original lattice: (n(x, y) – n(x, y þ 1)) þ (n(x, y þ 1) –
n(x þ 1, y þ 1)) þ (n(x þ 1, y þ 1) – n(x þ 1, y)) þ (n(x þ 1, y)
– n(x, y)) ¼ 0, which implies that the ﬂow fn ~kl
ð Þg
is divergence free as inferred in (9).
In 3d the Hamiltonian (9) is the strong screen-
ing limit of the vortex glass model for disordered
superconductors [20, 21].
H VG ¼
X
i, j
ni  bi
ð
ÞGl ri  r j


n j  b j


, ð11Þ
where the integer vortex variables ni live on the
bonds of a simple cubic lattice and have to
fulﬁll the constraint in (9) since they represent
magnetic vortex lines that are divergence free.
The real valued quenched random variables
bi  [–2s, 2s] are derived from the lattice
curl of a random vector potential (s  0 being
the strength of the disorder). The 3d vector ri
denotes the spatial positions of bond i in the
lattice and the sum runs over all bond pairs of
the lattice (not only nearest neighbors). The
lattice propagator Gl (r) has the asymptotic
form Gl(r) /
exp (–|r|/l)/|r|, where l is the
screening length. In the strong screening limit
l ! 0 only the on-site repulsion survives [20]
and gets.
H l!0
VG ¼
X
i
ni  bi
ð
Þ2
ð12Þ
which is the Hamiltonian (9) in 3d that we intend
to discuss here.
The ground state of (9) can again be com-
puted within polynomial time by a successive
shortest path algorithm [3]. As for the N-line
problem one starts with a conﬁguration {ni}
that optimizes the Hamiltonian in (9) but does
not, in general, fulﬁll the mass balance con-
straint given in (9). In the N-line problem that
was simply the zero-ﬂow ni ¼ 0, which does
not fulﬁll the requirement that the source and
the target have excess +N and –N, respec-
tively. Here we start with ni the closest integer
to the real number bi for each bond i. Since
this solution violates the mass-balance con-
straint
one
successively
sends
ﬂow
from
nodes that have an excess ﬂow to nodes that
have a deﬁcit along optimal paths that are
again found using node potentials (to make
all costs non-negative) and Dijkstra’s algo-
rithm. The details of this algorithm can be
found in [1–3].
Figure 4 shows three typical ground state
conﬁgurations for different strength of the dis-
order s in 2d and in 3d. For small s only small
isolated loops occur, whereas for larger s one
ﬁnds loops that extend through the whole sys-
tem, they percolate. A ﬁnite size scaling study
of the underlying percolation transition [22]
yields a novel universality class with numeri-
cally estimated critical exponents that differ
signiﬁcantly
from
those
for
conventional
bond-or site-percolation [22].
618
Optimization Problems and Algorithms from Computer Science

Interfaces and Elastic Manifolds
A system of strongly interacting (classical) parti-
cles or other objects, like magnetic ﬂux lines in a
type-II superconductor (as we discussed in Sect.
“Many Repulsive Elastic Lines in Random
Media” and for which the starting Hamiltonian
would given by (7)), or a charge density wave
system in a solid, will order at low temperatures
into a regular arrangement a lattice (crystal lattice
or ﬂux line lattice). Fluctuations either induced by
thermal
noise
(temperature)
or
by
disorder
(impurities, pinning centers) induce deviations of
the individual particles from their equilibrium
positions. As long as these ﬂuctuations are not
too strong an expansion of the potential energy
around these equilibrium conﬁguration might be
appropriate. An expansion up to second order is
called the elastic description or elastic approxima-
tion, which in a coarse grained form (where the
individual particles that undergo displacements
from their equilibrium positions do not occur
any more and are replaced by a continuum ﬁeld
f(r) reads then.
H manifold ¼ H elastic þ H random
¼
ð
ddr g
2 ∇f r
ð Þ
j
j2 þ V f r
ð Þ, r
ð
Þ
n
o
:
ð13Þ
The random potential energy is a delta-correlated
Gaussian variable with mean zero, hhV(f, r)
V(f0, r0)ii ¼ D2δ(f  f0)δ(r  r0). The integra-
tion extends over the whole space that parameter-
izes the manifold, for instance d ¼ 1 for an elastic
line in a random potential, d ¼ 2 for an interface or
a surface in a disordered environment etc. Note
that for d ¼ 1 one recovers the single line Hamil-
tonian (3). The many-line Hamiltonian (7) also
allows such an elastic description in the limit, in
which the interactions are strong and the random
potential is weak compared to the elastic energy.
In this limit the lines will only deviate moderately
from
a
regular,
translationally
invariant
Optimization Problems and Algorithms from Com-
puter Science, Fig. 4 Examples of ground state conﬁg-
urations of the Hamiltonian (9) for varying disorder
strengths s (for particular disorder realizations). Top: 2d,
L ¼ 50, the critical disorder strength is sc ≈0.46; Bottom:
3d, L ¼ 16, the critical disorder strength is sc ≈0.31. The
occupied bonds (ni 6¼ 0) are marked black, the percolating
loop is marked by light gray (red)
Optimization Problems and Algorithms from Computer Science
619

conﬁguration (the Abrikosov ﬂux line lattice).
This case is called an elastic periodic medium
and one has to modify the ’-part of the disorder
correlator such that the Hamiltonian has the cor-
rect translational symmetry [26].
Elastic Manifold
The typical example for an elastic manifold in a
disordered environment are domain walls in the
d þ 1 dimensional random bond ferromagnet H ¼
–  hi jiJi jsi sj (Ji j  0, random) in which we ﬁx
all spins in the lower (upper) plane, i.e. all si with
i ¼ (x1 1,. . ., xd, y) and y ¼ 1 (y ¼ H), to be si ¼
+1(1), c.f. Fig. 5. First one maps it onto a ﬂow
problem in a capacitated network. One introduces
two extra sites, a source node s, which is
connected to all spins of the hyperplane y ¼ 1
with bonds Js, (x1,. . ., xd, y ¼ 1) ¼ J1, and a sink
node t, which is connected to all spins of the
hyperplane y ¼ H with bonds Js, (x1,. . ., xd, y ¼
H) ¼ J1. One chooses J1 ¼ 2  (i j)Ji j, i.e. strong
enough that the interface cannot pass through a
bond involving one of the two extra sites. Now we
enforce the aforementioned boundary conditions
for the spins in the upper and the lower plane by
simply ﬁxing ss ¼ +1 and st ¼ 1. The graph
underlying the capacitated network one has to
consider is now deﬁned by the set of vertices
(or nodes) N ¼ {1, . . ., H  Ld} [ {s,
t} and the
set of edges (or arcs) connecting them A ¼ {(i, j)|
i, j  N, Ji j > 0}.
The capacities ui j of the arcs (i, j) is given by
the bond strength Ji j. For any spin conﬁguration
ff ¼ (s1,. . ., sN) one deﬁnes S ¼ {i  N|si ¼ þ
1} and S ¼ i  Njsi ¼ 1
f
g ¼ N∖S. Obviously
ss  S and st  S. The knowledge of S is sufﬁ-
cient to determine the energy of any spin conﬁg-
uration via H S
ð Þ ¼ C þ 2P
i,j
ð
Þ  S,S
ð
ÞJi j where
S, S


¼
i, j
ð
Þji  S, j  S


. The constant C ¼
 (i, j)  AJi j is irrelevant, i.e. independent of S.
Note that
S, S


is the set of edges (or arcs)
connecting S with S, this means it cuts N in two
disjoint sets. Since s  S and t  S, this is a so
called s-t-cut-set, abbreviated
S, S


. Thus the
problem of ﬁnding the ground state conﬁguration
of an interface in the random bond ferromagnet
can be reformulated as a minimum cut problem
min SN H0 S
ð Þ
f
g ¼ min S,S
½

X
i, j
ð
Þ  S, S
ð
Þ
Ji j: ð14Þ
in the above deﬁned capacitated network (with
H0 ¼ (H þ C)/2). It does not come as a surprise
that this minimum cut is identical with the
Optimization Problems and Algorithms from Com-
puter Science, Fig. 5 Left: Sketch of a 2d (RBIM) with
antiperiodic boundary conditions. Broken lines represent
weak bonds, full lines strong bonds, the spin conﬁguration
with the lowest energy deﬁnes an interface, as indicated,
and corresponds to the minimum cut in the corresponding
network ﬂow problem. Right: An optimal interface in the
111-direction of a 3d RBIM corresponding to the ground
state conﬁguration of a 2d elastic medium with scalar
displacement ﬁeld. (From Ref. [23])
620
Optimization Problems and Algorithms from Computer Science

interface between the (si ¼ +1)-domain and the
(si ¼ 1)-domain that has the lowest energy.
Actually any s-t-cut-set deﬁnes such an inter-
face, some of them might consist of many com-
ponents,
which
is
of
course
energetically
unfavorable.
A ﬂow in the network G is a set of nonnegative
numbers xi j subject to a capacity constraint and
amass balance constraint for each arc
0 	 xij 	 ui j
and
X
jj i, j
ð
Þ  Aj
f
g
xi j 
X
jj
j, i
ð
Þ  Aj
f
g
x j i
¼
v
fori ¼ s
þv
fori ¼ t
0
else
8
>
>
<
>
>
:
ð15Þ
This means that at each node everything that goes
in has to go out, too, with the only exception being
the source and the sink. What actually ﬂows from
s to t is v, the value of the ﬂow. The maximum
ﬂow problem for the capacitated network G is
simply to ﬁnd the ﬂow x that has the maximum
value v under the constraint (15).
Let x be a ﬂow, v its value and [S, S] an s-t-cut.
Then, by adding the mass balances for all nodes in
S one has v ¼ P
i,j
ð
Þ  S,S
ð
Þxij  P
i,j
ð
Þ  S,S
ð
Þx ji
and since xi j 	 ui j and xji  0 the following
inequality holds: v 	 P
i,j
ð
Þ  S,S
ð
Þuij ¼ u S, S


:
Thus the value of any ﬂow x is less or equal to
the capacity of any cut in the network. If one
discovers a ﬂow x whose value equals to the capac-
ity of some cut S, S


, then x is a maximum ﬂow
and the cut is a minimum cut. The following imple-
mentation of the augmenting path algorithm con-
structs a ﬂow whose value is equal to the capacity
of a s-t-cut it deﬁnes simultaneously. Thus it will
solve the maximum ﬂow problem (and, of course,
the minimum cut problem).
Given a ﬂow x, the residual capacity ri j of any
arc (i, j)  A is the maximum additional ﬂow that
can be sent from node i to node j using the arcs
(i, j) and ( j, i). The residual capacity has two com-
ponents: (1) ui j – xi j, the unused capacity of arc (i, j),
(2) xj i the current ﬂow on arc ( j, i), which one
can cancel to increase the ﬂow from node i to j ri j ¼
ui j – xi j þ xji. The residual network G(x) with
respect to the ﬂow x consists of the arcs with
positive residual capacities. An augmenting path is
a directed path from the node s to the node t in the
residual network. The capacity of an augmenting
path is the minimum residual capacity of any arc in
this path.
Obviously, whenever there is an augmenting
path in the residual network G(x) the ﬂow x is not
optimal. This motivates the following generic
augmenting path algorithm:
algorithm Ford–Fulkerson
begin
Initially set xi
j: ¼ 0, xji: ¼ 0 for
all (i, j)  A;
do
construct residual network R with
capacities ri
j;
if there is an augmenting path from
s to t in G0 then
begin
Let rmin the minimum capacity of
r along this path;
Increase the ﬂow in N along the
path
by a value of rmin;
end
until no such path from s to t in G0 is
found;
end
This algorithm is polynomial in the number of
lattice sites if the distribution of capacities is dis-
crete (binary for in stance). In the general case it
has to be improved and there are indeed more
efﬁcient algorithms to solve this problem in poly-
nomial time. One of them is the push/relabel algo-
rithm introduced by Goldberg and Tarjan [24]. It
determines the maximal ﬂow by successively
improving a “preﬂow”. A preﬂow is an edge
function f (e) that obeys the range constraint
0 	 f (e) 	 w(e), but the conservation constraint
at each node is relaxed: the sum of the f (e) into or
out of a node can be nonzero at internal (physical)
nodes. The amount of violation of conservation at
each node v give “excesses” e(v). The basic oper-
ations of the algorithm, push and relabel, are used
to rearrange these excesses. When the preﬂow can
no longer be improved, it can, if desired, be
converted to a maximal ﬂow, proving the correct-
ness of the algorithm. For details see [24, 25]. It
Optimization Problems and Algorithms from Computer Science
621

can be applied in the way sketched above to
compute universal geometrical properties of elas-
tic manifolds in 2 and 3 dimensions [23].
Periodic Medium
The presence of a periodic background potential,
like a crystal potential, has a smoothening effect
on the elastic manifold and tends to lock it into
one of its minima. The competition between the
random potential, that roughens the manifold, and
such a periodic potential might lead to a roughen-
ing transition [27, 28]. In 2d this is actually not the
case [29], but in 3d there is as we will see. We
consider a lattice version of the Hamiltonian
H ¼ H manifold þ Hperiodic
withHperiodic ¼
ð
ddr Vperiodic f r
ð Þ
ð
Þ,
ð16Þ
where Vperiodic(f) ¼ cos f represents the peri-
odic potential.
We introduce a discrete solid-on-solid (SOS)
type interface model for the elastic manifold
whose
continuum
Hamiltonian
is
given
in
Eq. (16). Locally the EM remains ﬂat in one of
periodic potential minima at f ¼ 2π h with integer
h. Due to ﬂuctuations, some regions might shift to
a different minimum with another value of h to
create a step (or domain wall) separating domains.
To minimize the cost of the elastic and periodic
potential energy in Eq. (16), the domain-wall
width must be ﬁnite, say xo. Therefore, if one
neglects ﬂuctuations in length scales less than
xo, the continuous displacement ﬁeld f(r) can be
replaced by the integer height variable {hx}
representing a (3 þ 1)d SOS interface on a simple
cubic lattice with sites x  {1, . . ., L}3. The
lattice constant is of order xo and set to unity.
The energy of the interface is given by the
Hamiltonian
H ¼
X
x, y
h
i
J hx,x
ð
Þ;
hy,y
ð
Þ hx  hy



X
x
VR hx, x
ð
Þ,
ð17Þ
where the ﬁrst sum is over nearest neighbor site
pairs. After the coarse graining, the step energy
J > 0 as well as the random pinning potential
energy VR becomes a quenched random variable
distributed independently and randomly. Note a
periodic elastic medium has the same Hamiltonian
as in Eq. (17) with random but periodic J and VR in
h with periodicity p [30]. In this sense, the elastic
manifold emerges as in the limit p ! 1 of the
periodic elastic medium.
To ﬁnd the ground state, one maps the 3D SOS
model onto a ferromagnetic random bond Ising
model in (3 þ 1)d hyper-cubic lattice with anti-
periodic boundary conditions in the extra dimen-
sion [23] (for the 3 space direction one uses peri-
odic boundary conditions instead). The anti-
periodic boundary conditions force a domain wall
into the ground state conﬁguration of the (3 þ 1)d
ferromagnet. Note that bubbles are not present in
the ground state. A domain wall may contain an
overhang which is unphysical in the interface inter-
pretation. Fortunately, one can forbid overhangs in
the Ising model representation using a technique
described in [23]. If the longitudinal and transver-
sal bond strengths are assigned with J/2 and VR/2
occurring in Eq. (17), respectively, this domain
wall of the ferromagnet becomes equivalent to the
ground state conﬁguration of (17) for the interface
with the same energy. The domain wall with the
lowest energy is then determined exactly by using
again the maxﬂow/min-cost algorithm.
In elastic media described by (17) the tendency
of the periodic potential to lock the displacements
competes with the roughening effect of the disor-
der. Analytically a roughening transition was pre-
dicted in [28] and the critical exponents could be
numerically estimated in three dimensions [30]
with the mapping and algorithm described above.
Random Field Ising Model
The random ﬁeld Ising model (RFIM, for a review
see [31, 32]) is deﬁned
H ¼ 
X
i j
ð Þ
Ji jsi s j 
X
i
hisi
ð18Þ
with si ¼ 
 1 Ising spins, ferromagnetic bonds
Ji j  0 (random or uniform), (ij) nearest neighbor
622
Optimization Problems and Algorithms from Computer Science

pairs on a d-dimensional lattice and at each site i a
random ﬁeld hi  R that can be positive and
negative. The ﬁrst term prefers a ferromagnetic
order, which means it tries to align all spins. The
random ﬁeld, however, tends to align the spins
with the ﬁeld which points in random directions
depending on whether it is positive or negative.
This is the source of competition in this model.
Let us suppose for the moment uniform inter-
actions Ji j ¼ J and a symmetric distribution of the
random ﬁelds with mean zero and variance hr. It is
established by now that in 3d (and higher dimen-
sions) the RFIM shows ferromagnetic long range
order at low temperatures, provided hr is small
enough. In 1d and 2d there is no ordered phase at
any ﬁnite temperature. Thus in 3d one has a para-
magnetic/ferromagnetic phase transition along a
line hc (T) in the hr-T-diagram.
The renormalization group picture says that the
nature of the transition is the same all along the line
hc (T), with the exception being the pure ﬁxed point
at hr ¼ 0 and Tc ~ 4.51 J. The RG ﬂow is dominated
by a zero temperature ﬁxed point at hc (T ¼ 0). As a
consequence, the critical exponents determining the
critical behavior of the RFIM should be all identical
along the phase transition line, in particular identi-
cal to those one obtains at zero temperature by
varying hr alone. Thus to study the universal prop-
erties of the phase transition in the RFIM one needs
to calculate its ground state.
This optimization task is again equivalent to a
maximum ﬂow problem [33, 34], as in the inter-
face model discussed in the last section. Histori-
cally the RFIM was the ﬁrst physical model that
has been investigated with a maximum ﬂow algo-
rithm [36]. However, here the minimum-cut is not
a geometric object within the original system.
To map the ground state problem for the RFIM
onto a max-ﬂow-min-cut problem one proceeds in
the same way as in the interface problem: One
adds to extra nodes s and t and attaches spins with
ﬁxed values there (see Fig. 6):
ss ¼ þ1
andst ¼ 1
ð19Þ
One connects all sites with positive random ﬁeld
to the node s and all sites with negative random
ﬁeld to t:
Js i ¼
hi
if hi  0
0
if hi < 0
(
Ji t ¼
hi
j j
if hi < 0
0
if hi  0
(
ð20Þ
The a network is constructed with the set of nodes
N ¼ {1, . . ., Ld} [ {s,
t} and the set of (forward
and backward) arcs A ¼ {(i, j)|i, j  N, Jij > 0}.
Each of them has a capacity ui j ¼ Ji j. The energy
or cost function can the be written as.
E ¼ 
X
i, j
ð
Þ  A
Ji jsis j
ð21Þ
or, by denoting the set S ¼ {i  N|Si ¼ þ 1} and
S ¼ N∖S
E S
ð Þ ¼ C þ 2
X
i, j
ð
Þ  S, S
ð
Þ
Ji j
ð22Þ
with C ¼  (i, j)  AJi j. The problem is reduced to
the problem of ﬁnding a minimum s-t-cut as
in (14). The difference to the interface problem is
that now the extra bonds connecting the two special
Optimization Problems and Algorithms from Com-
puter Science, Fig. 6 Representation of the ground state
problem for the RFIM as an RBIM domain wall or
minimum-cut problem. The physical spins are the ﬁve
nodes in the single row in the ﬁgure, while the ﬁxed
external spins are s+ and s. The physical RFIM coupling
J ¼ 1.0. A spin with hi > 0 (hi < 0) is connected by an
auxiliary coupling of strength hi(hi) to s+ (s). The
weights of each bond are indicated: the random ﬁelds are,
from left to right, h ¼ 1.5, +4.0, 2.3, +1.2, and 0.15. In
the ground state, the interfacial energy between up-spin
and down-spin domains is minimized, i.e., the spins are
partitioned into two sets with minimal total cost for the
bonds connecting the two sets. The dashed curve indicates
the minimal weight cut. The white (dark) nodes indicate up
(down) spins in the ground state conﬁguration
Optimization Problems and Algorithms from Computer Science
623

nodes s and t with the original lattice do not have
inﬁnite capacity: they can lie in the cut, namely
whenever it is more favorable not to break a ferro-
magnetic bond but to disalign a spin with its local
random ﬁeld. In the extended graph the s-t-cut
again forms connected interface, however, in the
original lattice (without the bonds leading to and
from the extra nodes) the resulting structure is
generally disconnected, a multicomponent inter-
face.
Each
single
component
surrounds
a
connected region in the original lattice containing
spins, which all point in the same direction. In other
words,
they
form
ferromagnetically
ordered
domains separated by domain walls given by the
subset of the s-t-cut that lies in the original lattice.
In passing we note that diluted Ising antiferro-
magnets in a homogeneous external ﬁeld (DAFF)
map straightforwardly onto a RFIM if the under-
lying lattice is bipartite. The 3d DAFF on a simple
cubic lattice is deﬁned by
H ¼ þ
X
i j
ð Þ
Ji jeie jsis j 
X
i
hieisi
ð23Þ
where si ¼ 
 1, Ji j  0, (ij) are nearest neighbor
pairs on a simple cubic lattice, and εi  {0,
1}
with εi ¼ 1 with probability c, representing the
concentration of spins. Because of the plus sign in
front of the ﬁrst term in (23) all interactions are
antiferromagnetic, the model represents a diluted
antiferromagnet, for which many experimental
realizations exist (e.g. Fec Zn1–cF2).Now that
neighboring spins tend to point in opposite direc-
tions due to their antiferromagnetic interaction a
uniform ﬁeld competes with this ordering tendency
by trying to align them all. On a bipartite lattice in
zero external ﬁeld the ground state would be anti-
ferromagnetic, which means that one can deﬁne
two bipartite sublattices A and B. One deﬁnes
new spin and ﬁeld variables via
s0
i ¼
þsi
fori  A
si
fori  B
(
h0
i ¼
þeihi
fori  A
eihi
fori  B:
(
Since s0
is0
j ¼ sis j for all nearest neighbor pairs
(ij) one can write (23) as
H ¼ 
X
i j
ð Þ
J0
i js0
is0
j 
X
i
h0
is0
i
ð24Þ
with J0
i j ¼ Ji jeie j . This is again a RFIM and
ground states can be computed with the max-
ﬂow technique.
The main focus of the application of the
max-ﬂow-min- cut algorithm to the RFIM is
the phase transition in the three-dimensional
model occurring at a critical disorder strength
hc at zero temperature, which separates a para-
magnetic phase for large disorder strength from
a ferromagnetic phase. The maximum ﬂow
algorithm has ﬁrst been used by Ogielski [36]
to calculate the critical exponents of the RFIM
via the ﬁnite size scaling. More accurate esti-
mates were obtained more recently by Middle-
ton and Fisher [35], where also an detailed
discussion of the problems and conﬂicting
results about the RFIM universality class is
provided. For Gaussian random ﬁelds (with
variance h2) they ﬁnd for the ﬁnite size scaling
of magnetization m ¼ [Si]av. and speciﬁc heat
c ¼ N1 dE/dT and
m  Lb=n,
c  La=n,
ð25Þ
with the magnetization exponent x ¼ β/n ¼
0.012 
 0.004 the correlation length exponent n ¼
1.37 
 0.09, and the speciﬁc heat exponent α ¼
 0.07 
 0.17. Note that the magnetization expo-
nent is very close to zero, which means that the
transition is hard to discriminate from a ﬁrst order
transition. Also the speciﬁc heat exponents is close
to zero and slightly negative, implying a lack of
divergence of the speciﬁc heat at the transition.
The Spin Glass Problem
Spin glasses are the prototypes of (disordered)
frustrated systems (see [37]). In the models
discussed up to now, the frustration was caused
by two separate terms of different physical origin
(interactions and external ﬁelds or boundary con-
ditions). Spin glasses are magnetic systems in
which the magnetic moments interact ferro- or
anti-ferromagnetically in a random way, as in the
624
Optimization Problems and Algorithms from Computer Science

following Edwards–Anderson Hamiltonian for a
short ranged Ising spin glass (SG)
H ¼ 
X
i j
ð Þ
Ji jsis j,
ð26Þ
where si ¼ 
 1, (ij) are nearest neighbor interac-
tions on a d-dimensional lattice and the interaction
strengths Ji j  R are unrestricted in sign. In
analogy to Eq. (14) one shows that the problem
of ﬁnding the ground state is again equivalent to
ﬁnding a minimal cut S, S


in a network
min ff H0 ff
ð Þ
f
g ¼ min S,S
½

X
i, j
ð
Þ  S, S
ð
Þ
Ji j,
ð27Þ
again H0 ¼ (H þ C)/2 with C ¼  (i j)Ji j. How-
ever, now the capacities ui j ¼ Ji j of the underlying
network are not non-negative any more, therefore
it is not a minimum-cut problem and thus it is also
not equivalent to a maximum ﬂow problem,
which we know how to handle efﬁciently.
It turns out that the spin glass problem is much
harder than the questions we have discussed so
far. In general (i.e. in any dimension larger than
two and also for 2d in the presence of an external
ﬁeld) the problem of ﬁnding the SG ground state
is N P -complete [42], which means in essence
that no polynomial algorithm for it is known
(and also that chances to ﬁnd one in the future
are marginal). Nevertheless, some extremely efﬁ-
cient algorithms for it have been developed
[38, 39], which have a non-polynomial bound
for their worst case running-time but which termi-
nate (i.e. ﬁnd the optimal solution) after a reason-
able computing time for pretty respectable system
sizes.
Two Dimensions, Planar Graph
First we discuss the only non-trivial case that can
be solved with a polynomial algorithm: the two-
dimensional Ising SG on a planar graph. This
problem can be shown to be equivalent to ﬁnding
a minimum weight perfect matching, which can
be solved in polynomial time. We do not treat
matching problems and the algorithms to solve
them in this lecture (see [4, 40, 41]), however,
we would like to present the idea [42]. To be
concrete let us consider a square lattice with free
boundary conditions. Given a spin conﬁguration
ff (which is equivalent to ff) we say that an edge
(or arc) (i, j) is satisﬁed if Ji j si sj > 0 and it is
unsatisﬁed if Ji jsisj < 0. Furthermore we say a
plaquette (i.e. a unit cell of the square lattice) is
frustrated if it is surrounded by an odd number of
negative bonds (i.e. Ji j  Jjk  Jk l  Jl i < 0 with i, j,
k and l the four corners of the plaquette). There is a
one-to-one correspondence between equivalent
spin conﬁgurations (ff
and ff ) and sets of
unsatisﬁed edges with the property that on each
frustrated (unfrustrated) plaquette there is an odd
(even) number of unsatisﬁed edges. See Fig. 7 for
illustration.
Note that
H ff
ð Þ ¼ C þ 2
X
unsatisfied edges
Jij

:
ð28Þ
which means that one has to minimize the sum
over the weights of unsatisﬁed edges. A set of
unsatisﬁed edges will be constituted by a set of
paths (in the dual lattice) from one frustrated
plaquette to another and a set of closed circles
(see Fig. 7). Obviously the latter always increase
the energy so that we can neglect them. The prob-
lem of ﬁnding the ground state is therefore
Optimization Problems and Algorithms from Com-
puter Science, Fig. 7 Two-dimensional Ising spin glass
with 6 - J couplings: Thin lines, are positive interactions,
thick lines are negative interactions, ↗means si ¼ +1, ↙
means si ¼ 1, shaded faces are frustrated plaquettes,
broken lines cross unsatisﬁed edges
Optimization Problems and Algorithms from Computer Science
625

equivalent to ﬁnding the minimum possible sum
of the weights of these paths between the frus-
trated plaquettes. This means that we have to
match the black dots in the Fig. 7 with one another
in an optimal way. One can map this problem on a
minimum weight perfect matching problem
(a perfect matching of a graph G ¼ (N, A) is a
set M  A such that each node has only has only
one edge of M adjacent to it). This can be solved in
polynomial time (see [42] for further details).
Note that for binary couplings, i.e. Ji j ¼ 
 J,
where Ji j ¼ þ J with probability p the weight of a
matching is simply proportional to the sum of the
lengths of the various paths connecting the centers
of the frustrated plaquettes, which simpliﬁes the
actual implementation of the algorithm. In [43]
the 2d 
 J spin glass and the site disordered SG
has been studied extensively with this algorithm.
The site disordered spin glass is deﬁned as fol-
lows: occupy the sites of a square lattice randomly
with A (with concentration c) and B (with concen-
tration 1 – c) atoms. Now deﬁne the interactions
Ji j between neighboring atoms: Ji j ¼ J if on
both sites are A-atoms and Ji j otherwise.
The main application of this algorithm is
directed towards studying domain walls in spin
glasses since they provide informations on the low
temperature behavior and the stability of the
ground state with respect to thermal ﬂuctuations.
Domain walls can be induced by applying two
different boundary conditions to the system
(usually periodic and anti-periodic), their energy
is simply the difference between the energies of
the ground states with the two different boundary
conditions. The domain wall energy of the two-
dimensional spin glass model with Gaussian cou-
plings scales like
DE  Ly,
ð29Þ
where the stiffness exponent is θ ¼ 0.282 (see
[44] for a survey). The negativity of this exponent
indicates the absence of stable spin glass phase at
any non-vanishing temperature in the 2d spin
glass model. Recently also the fractal properties
of the domain walls in 2d spin glasses with Gauss-
ian couplings became important: They have a
fractal dimension of df ¼ 1.27(1) and it was
argued [45] that they might be a realization of a
stochastic Loewner evolution (see [46] for a
review) realized in disordered systems.
Three Dimensions, Non-planar Graphs
As we mentioned, in any other case except the
planar lattice situation discussed above the spin
glass problem is N P -hard. In what follows we
would like to sketch the idea of an efﬁcient but
non-polynomial algorithm [39]. To avoid confu-
sion with the minimum cut problem we discussed
in connection with maximum ﬂows one calls the
problem (27) a max-cut problem (since ﬁnding the
minimum of H is equivalent to ﬁnding the maxi-
mum of –H).
Let us consider the vector space RA. For each cut
S, S


deﬁne w S,S
ð
Þ  RA, the incidence vector of
the cut, by w
S,S
ð
Þ
e
¼ 1
for each edge e ¼
i, j
ð
Þ  S, S


and w
S,S
ð
Þ
e
¼ 0
otherwise. Thus
there is a one-to-one correspondence between
cuts in G and their {0, 1}-incidence vectors in RA.
The cut-polytope PC(G) of G is the convex hull of
all incidence vectors of cuts in G: PC G
ð Þ ¼
conv w S,S
ð
Þ  RAS  A
n
o
:
Then the max-cut
problem can be written as a linear program
max uTx
x  PC G
ð Þ


ð30Þ
since the vertices of PC (G) are cuts of G and vice
versa. Linear programs usually consist of a linear
cost function uTx that has to be maximized under
the constraint of various inequalities deﬁning a
polytope in Rn (i.e. the convex hull of ﬁnite sub-
sets of Rn) and can be solved for example by the
simplex method, which proceeds from corner to
corner of that polytope to ﬁnd the maximum (see
e.g. [40, 41, 48].). The crucial problem in the
present case is that it is N P -hard to write down
all inequalities that represent the cut polytope
PC(G).
It turns out that also partial systems are useful,
and this is the essential idea for an efﬁcient algo-
rithm to solve the general spin glass problem as
well as the traveling salesman problem or other so
called mixed integer problems (i.e. linear pro-
grams where some of the variables x are only
allowed to take on some integer values, like
0 and 1 in our case) [7, 47]. One chooses a system
of linear inequalities L whose solution set P(L)
626
Optimization Problems and Algorithms from Computer Science

contains PC(G) and for which PC(G) ¼ convex
hull{x  P(L)|x integer}. In the present case
these are 0 	 x 	 1, which is trivial, and the so
called cycle inequalities, which are based on the
observation that all cycles in G have to intersect a
cut an even number of times. The most remarkable
feature of this set L of inequalities is the following:
The separation problem for a set of inequalities
L consists in either proving that a vector x satisﬁes
all inequalities of this class or to ﬁnd an inequality
that is violated by x. A linear program can be
solved in polynomial time if and only if the sep-
aration problem is solvable in polynomial time
[49]. The separation problem for the cycle
inequalities can be solved in polynomial time by
the cutting plane algorithm which, starting from
some small initial set of inequalities, generates
iteratively new inequalities until the optimal solu-
tion for the actual subset of inequalities is feasible.
Note that one does not solve this linear program
by the simplex method since the cycle inequalities
are still too numerous for this to work efﬁciently.
Due to the insufﬁcient knowledge of the
inequalities that are necessary to describe PC(G)
completely, one may end up with a non-integral
solution x*. In this case one branches on some
fractional
variable
xe
(i.e.
a
variable
with
x
e  0, 1
f
g), creating two subproblems in one of
which xe is set to 0 and in the other xe is set to
1. Then one applies the cutting plane algorithm
recursively for both subproblems, which is the
origin of the name branch-and-cut. Note that in
principle this algorithm is not restricted to any
dimension, boundary conditions, or to the ﬁeldless
case. However, there are realizations of it that run
fast (e.g. in 2d) and others that run slow (e.g. in 3d)
and it is ongoing research to improve on the latter,
for an overview over the current status see [47].
Potts Free Energy and Submodular
Functions
The problem addressed in this chapter is not a low
temperature problem but concerns the computation
of the free energy of a Potts model (see [50] for a
review) at any temperature, including some phase
transition temperatures. To transform the problem
of computing the free energy into an optimization
problem (i.e. ﬁnd a minimum in a ﬁnite set), one
needs to take some limit. Usually this is a zero
temperature limit as it was for all applications
discussed so far in this article. Here this will be
the limit of an inﬁnite number of states.
Consider
the
q-state
Potts
model
on
a
d-dimensional hyper-cubic lattice with periodic
boundary conditions deﬁned by the Hamiltonian:
H ¼ 
X
i j
h i
Ji jd si, s j


,
ð31Þ
where
si
are
q-state
Potts
variables
(si  {1, . . ., q} located at lattice sites i, the sum
goes over all nearest neighbor pairs hi ji of the
lattice, and Ji j > 0 are ferromagnetic couplings
(not that δ(s, s0) is the Kronecker-delta, which
means δ(s, s0) ¼ 1 for s ¼ s0 and δ(s, s0) ¼ 0
for s 6¼ s0). The case q ¼ 2 corresponds to the
Ising model. In the random bond Potts model,
which is of interest here, the couplings Ji j are
random variables. In d 	 2 dimensions the Potts
model has phase transition at some critical temper-
ature T from a paramagnetic to a ferromagnetic
phase. Thermodynamic properties of the q-state
Potts model are computed via its partition function
Z ¼ s
f g
X
exp
X
i j
 bJi jd si, s j


 
!
:
ð32Þ
The ﬁrst sum runs over all possible spin conﬁgu-
ration, i.e. it involves qN terms, where N is the
number of spins in the system and β ¼ 1/T is the
inverse temperature.
In the so-called random cluster representation
[51] the partition sum can be written as a sum over
all subsets U  E of the set of edges (or bonds)
Z ¼
P
s
f g
Q
i j
exp bJi jd si, s j




¼
P
s
f g
Q
i j
1 þ vi jd si, s j




where vi j ¼ exp.(β Ki j) – 1. Note that the
Kronecker-delta can only take on the values zero
and one by which it is possible to identify exp.
(Jδ) ¼ 1 þ δ(exp(J) – 1) ¼ 1 þ vδ. Again one can
Optimization Problems and Algorithms from Computer Science
627

regard the lattice as a graph G ¼ (V, E), where the
sites and the bonds of the lattice are the vertices
V and the edges E of the graph. Then a careful
bookkeeping of the terms in the development of
the above expression leads to:
Z ¼
X
G0G
qc G0
ð
Þ Y
e  G
ve,
ð33Þ
where G0 denotes any subgraph of G, i.e. a graph,
possibly not connected (but all vertices are kept),
where some edges of G have been deleted (there
are 2m subgraphs where m is the number of edges
of G). c(G0) is the number of connected compo-
nents of the subgraph G0. For example for the
empty subgraph G0 ¼

0 the number of connected
components is the number of sites, while for G0 ¼
G it is one. The product in (33) is over all the
edges in G0 with the convention that the product
over an empty set is one. If the parameter β is
small (i.e. high temperature) then the parameters
vi j are small and, summing in (33), only the sub-
graphs with few edges provides an approximation
to the partition function: this is a high temperature
development. Note also the way the parameter
q appears in (33): it can be extended to non integer
values, relating the Potts model to other problems
(percolation, etc. . . .) [57].
Following [52] one can map the computation
of the partition function Z of any ferromagnetic
Potts model in the limit q ! 1 onto an optimi-
zation problem by introducing another parametri-
zation of the couplings with new variables we
deﬁned by
ve ¼ qwe:
Inserting this expression in (33) one gets Z ¼
P
G0Gqc G0
ð
Þ þ P
e  G0we,
and deﬁning f(G) ¼
c(G) þ  e  Gwe.
Z ¼
X
G0G
q f G0
ð
Þ:
In the limit q ! 1 only the subgraphs G* maxi-
mizing f (G) will contribute, and computing the
partition function of the Potts model in the inﬁnite
number of states limit amounts to ﬁnding the sub-
graphs G0 of the graph G maximizing the function f,
i.e. minimizing the function [52]:
f P G0
ð
Þ ¼  c G0
ð
Þ þ
X
e  G0
we
 
!
:
ð34Þ
It turns out that this function has a property which
allows to minimize it very efﬁciently: it is a sub-
modular function.
Submodular Functions
The concept of a submodular function in discrete
optimization appears to be in several respects
analogous to that of a convex function in contin-
uous optimization. In many combinatorial theo-
rems and problems, submodularity is involved, in
one form or another, and submodularity often
plays an essential role in a proof or an algorithm.
Moreover, analogous to the fast methods for con-
vex function minimization, it turns out that sub-
modular functions can also be minimized fast,
i.e. in polynomial time.
Submodularity is a special property of set func-
tions, which are deﬁned as follows: Let V be a ﬁnite
set and 2V ¼ {X|X  V} be the set of all the subsets
of V. A function f: 2V ! ℝis called a set function.
Now a set function f is submodular if for all
subsets A  V and B  V:
f A
ð Þ þ f B
ð Þ  f A \ B
ð
Þ þ f A [ B
ð
Þ:
ð35Þ
It is simple to show that a function f is sub-
modular if and only if for any subsets S  R  V
and for any x  V:
f S [ x
f g
ð
Þ  f S
ð Þ  f R [ x
f g
ð
Þ  f R
ð Þ:
ð36Þ
This means intuitively that adding an element to a
“small” ensemble S (since S  R) has more effect
than adding to a “large” ensemble R.
The function (34) fP(A) ¼ (c(A) þ w(A)) is
sub-modular, because the function –c(A) is sub-
modular (and the function w(A) is modular: Take
two sets of edges A  B and an edge e. Inspecting
the three possible cases: e  A, e  A and e  B,
628
Optimization Problems and Algorithms from Computer Science

c(B), which is the reverse of (36), so that the
function –c is a submodular function. Note that
c(E0) with E0  E counts the number of connected
components of the graph G0 that contains all ver-
tices Vof the complete graph but only the edges in
E0. Thus adding an edge will never increase the
number of components.
On the other hand it is straightforward to see that
the function w(G) ¼  e  Gwe veriﬁes w(A [ C) þ
w(A \ C) þ w(A) þ w(C). It is a so-called modular
function. Consequently the function (34) fP is a
submodular function. In summary we are looking
for the sets of edges minimizing the submodular
function fP for which a strongly polynomial algo-
rithm has been recently discovered.
In passing we note that we encountered other
examples of submodular functions already in the
preceding sections, namely the function that
deﬁnes the costs of cuts in a graph with positive
edge weights, which occurs the interface problem
and the random ﬁeld Ising model in the last sec-
tions: Take a graph G ¼ (V, E) and deﬁne C to be a
function of the subsets of the V and C(U  V) is
the number of edges having exactly one end in U.
This function can be generalized to the case where
the edges are directed and weighted, i.e. each edge
carries an arrow and a positive number. The func-
tion C(U  V) is then the sum of the weight of the
edges having the beginning vertex in U and the
ending vertex not in U. This kind of function is
generally called a “cut” and is submodular.
Minimization of Submodular Function
The minimization of any submodular function can
be done in polynomial time. This was ﬁrst
published in reference [53] in 1981. In this paper
the authors utilize the so-called ellipsoid method.
However this method is not a combinatorial one
and is far from being efﬁcient. In that respect this
result was not quite satisfactory at least for the
practical applications. Eighteen years later, Iwata–
Fleischer–Fujishige
[54],
and
independently
Schrijver [55] discovered a combinatorial method
which is fully satisfactory from the theoretical, as
well as from the practical, point of view.
The general method uses a mathematical
programming
formulation.
The
problem
is
algebraically expressed as a linear program, i.e. a
set of variables yS associated to each subset S  V
is introduced, these variables are subjected to
constraints and a linear function F of these vari-
ables is to be minimized. The constraints include a
set of linear equations and the condition that each
of the yS is zero or one. This last condition is in
general extremely difﬁcult to realize. However, it
turns out that a theorem due to Edmonds [56]
indicates this condition can be simply dropped,
and that automatically the set of values yS which
minimize F will all be zero or one! Actually only
one variable yS ¼ 1 will be non zero and it is
precisely associated to the optimal set. Combined
with the dual version of this linear program, it
provides a characterization of the optimal set.
The general algorithm mentioned above can
be applied to minimize (34), however, due to the
speciﬁc form of the function to minimize, a
more suitable method does exist. For this a
property that is true for any submodular function
is useful. To emphasize that the function f to
minimize is deﬁned on all the subsets of a set
E we will label f with the index E as fE. Let us
now consider a subset F  E; one can deﬁne a
set function on F by fF(A) ¼ fE(A) for any
A  F. If the function fE is submodular then its
restriction fF is also submodular. We have the
following property:
Let F  E and e  E, if AF is an optimal set of
the set function fF deﬁned on F, then there will be
an optimal set AF [{e} of the function fF [{e}
deﬁned on F [{e} such that AF AF [{e}.
To make the notation simpler we denote the
function fF [{e} on F [{e} by f1. Let A be an
optimal set of fF on F and B an optimal set of f1
on F[{e}. One has
f 1 A [ B
ð
Þ 	 f 1 A
ð Þ þ f 1 B
ð Þ  f 1 A \ B
ð
Þ ð37Þ
since f1 is submodular. But f1(A) ¼ fF (A) and
f1(A \ B) ¼ fF(A \ B) since both A and A \ B
are in A. Since A is an optimal set one has fF(A) 	
fF(A\ B) and consequently f1(A) – f1(A \ B) 	 0.
Inserting this last inequality into (37) one ﬁnds that
f1(A [ B) 	 f1(B) which proves that A [ B is one of
the optimal sets (Q.E.D.).
Optimization Problems and Algorithms from Computer Science
629

This property has an important consequence.
Indeed let us suppose that the optimal set has been
found for a subset F of E. Then all the elements of
E which have been selected as belonging to the
optimal set of F will still belong to one optimal set
of all the sets G  F. In other words, let us ﬁnd the
optimal set for {e0, e1} where e0 and e1 are arbi-
trary elements of E; then if we ﬁnd that any of
these two elements belongs to the optimal set, it
will belong to one optimal set for F  E! Such an
algorithm which makes a deﬁnitive choice at each
step is called a greedy algorithm.
Based on this observation an efﬁcient algo-
rithm for the minimization of (34) was developed
in [58], see also [59].
Results
The algorithm based on the ideas mentioned
before and presented in detail in [58, 59], was
applied to various two dimensional and three
dimensional lattices. A realization of the disorder
is chosen accordingly to a probability distribution.
In practice all the weights w(e) on the edge e are
rational numbers with a common integer denom-
inator q. In other words, we choose an integer p(e)
for each edge and set w(e) ¼ p(e)/q. To work only
with integers one maximizes the product qf:
qf A
ð Þ ¼ qC A
ð Þ þ
X
e  A
p e
ð Þ:
It is clear that if q is small compare to all the p(e),
then all the weights w(e) will be large and the
optimal set will be the set of all edges. On the
contrary if q is large all the weights will be small
and the optimal set will be empty. These two situ-
ations are easy to handle. Between this two limits
the optimal set grows, and for a precise value qc of
q, which depends on the lattice, the optimal set
percolates. This value corresponds to a phase tran-
sition. Depending on the lattice under consideration
and on the distribution of the random variables p(e)
this transition can be ﬁrst or second order.
In Fig. 8, one optimal set is shown for a lattice
where each edge carries a weight 1/6 or 5/6 with
probability one half (i.e. it is a critical point). The
edges from the optimal set belonging to the per-
colation cluster are shown in black, while the
others are shown in gray. The percolation cluster,
which is the largest connected component in the
optimal subgraph G0  G is fractal with a fractal
dimension df ¼ 1.809 that is related to the critical
exponent x ¼ β/n for the magnetization of the
random bond q ! 1 Potts model (31) in two
dimensions via x ¼ 2 – df ¼ 0.191. Surprisingly
this agrees within the error bars with the magne-
tization exponent x ¼ 3 
ﬃﬃﬃ
5
p


=4 of the random
transverse Ising chain [61], which is a one-
dimensional quantum spin model. A discussion
of this observation and details of the computations
can be found in [60].
Future Directions
We have reviewed several applications of polyno-
mial optimization algorithms from computer sci-
ence to disordered systems in statistical physics.
They were used extensively in the recent years to
compute numerically universal properties like crit-
ical exponents, domain wall exponents and geomet-
rical features like roughness and stiffness with
much higher precision than with Monte-Carlo
methods,
which
suffer
notoriously
from
Optimization Problems and Algorithms from Com-
puter Science, Fig. 8 A 512  512 lattice. The edges of
the optimal set belonging to the percolating cluster are
shown in black, and the edges of the optimal set not
belonging to the optimal set are in gray. (From Ref. [59])
630
Optimization Problems and Algorithms from Computer Science

equilibration problems. A number of important
issues, which were controversially debated within
different analytical could be clariﬁed, numerically,
in this way – as for instance the nature of the low
temperature phase of the superrough phase in the
two-dimensional Bragg glass [19, 62], the absence
of a stable glass phase in the strongly screened
vortex glass model [21] and the issue of many states
in various two-dimensional glassy models [63].
Other questions still remain to be answered, as for
example the phenomenon of an apparent non-
universality in the three-dimensional random ﬁeld
Ising model [64].
NP-hard problems occurring in the statistical
physics of disordered systems, still remain a chal-
lenge: Examples are the computation of ground
states of spin glass models on non-planar graphs,
like the three-dimensional spin glass or the ran-
dom ﬁeld Potts model for three or more Potts
states [65]. Stochastic optimization techniques
like hysteretic optimization [66] or extremal opti-
mization [67] have reached a high level of sophis-
tication but naturally suffer from the lack of a
proof of optimality of the resulting solution. Pro-
gress in the development of exact and efﬁcient
algorithm that can handle sufﬁciently large system
sizes to perform a reliable ﬁnite size scaling anal-
ysis is being made [47] and highly rewarding.
The cross-fertilization between computer sci-
ence and statistical physics is also fruitful in the
other direction: Phase transitions that occur in
some combinatorial optimization problems like
the satisﬁability problem (SAT) were studied
intensively in recent years by physicists and
remarkable progress has been achieved in under-
standing it and inventing efﬁcient algorithms.
These developments were not covered in this arti-
cle, excellent introductions can be found in [68].
Bibliography
Primary Literature
1. Rieger H (1998) Frustrated systems: ground state
properties
via
combinatorial
optimization.
In:
Kertesz
J,
Kondor
I
(eds)
Lect
Note
Phys,
vol 501, pp 122–158
2. Alava M, Duxbury P, Moukarzel C, Rieger H (2000)
Exact combinatorial algorithms: ground states of
disordered systems. In: Domb C, Lebowitz JL (eds)
Phase Transit Crit Phenom, vol 18, pp 141–317
3. Hartmann A, Rieger H (2002) Optimization in phys-
ics. Wiley, Darmstadt
4. Papadimitriou CH, Steiglitz K (1998) Combinatorial
Optimization. Dover Publications, Mineola
5. Cook WJ, Cunningham WH, Pulleyblank WR,
Schrijver
A (1998) Combinatorial
Optimization.
Wiley, New York
6. Korte B, Vygen J (2000) Combinatorial Optimization.
Springer, Berlin
7. Lawler EL, Lenstra JK, Rinnooy Kan AHG, Shmoys
DB (1990) The travelling salesman problem. Wiley,
Chichester
8. Press WH, Teukolsky SA, Vetterling WT, Flannery BP
(1995) Numerical recipes in C. Cambridge University
Press, Cambridge
9. Kirkpatrick S, Gelatt CD Jr, Vecchi MP (1983) Opti-
mization by simulated annealing. Science 220:671
10. Halpin-Healy T, Zhang Y-C (1995) Kinetic roughen-
ing phenomena, stochastic growth directed polymers
and all that – aspects of multidisciplinary statistical-
mechanics. Phys Rep 254:215
11. Peng C-K, Havlin S, Schwartz M, Stanley HE
(1991)
Directed-polymer
and
ballistic-deposition
growth with correlated noise. Phys Rev A 44:2239.
Pang N-N, Yu Y-K, Halpin-Healy T (1995) Interfacial
kinetic roughening with correlated noise. Phys Rev
E 52:3224
12. Marsili M, Zhang Y-C (1998) Overhangs in interface
growth and ground-state paths. Phys Rev E 57:4814.
Schwartz N, Nazaryev AL, Havlin S (1998) Optimal
path in two and three dimensions. Phys Rev E 58:7642
13. Schorr R, Rieger H (2003) Universal properties of
shortest paths in isotropically correlated random
potentials. Eur Phys J 33:347
14. For a review see Blatter G et al (1994) Vortices in high-
temperature superconductors. Rev Mod Phys 66:1125
15. Doi M, Edwards SF (1986) The theory of polymer
dynamics. Oxford University Press, Oxford
16. Drossel B, Kardar M (1996) Winding angle distribu-
tions for random walks and ﬂux lines. Phys Rev
E 53:5861
17. Bikbov R, Nechaev S (2001) Topological relaxation of
entangled ﬂux lattices: single versus collective line
dynamics. Phys Rev Lett 87:150602
18. Petäjä V, Alava M, Rieger H (2004) Entanglement
transition of elastic lines in a strongly disordered envi-
ronment. Europhys Lett 66:778
19. Rieger H, Blasum U (1997) Ground state properties
of solid-on-solid models with disordered substrates.
Phys Rev B 55:7394R. Pfeiffer F, Rieger H (2000)
Dislocations in the ground state of the solid-on-
solid model on a disordered substrate. J Phys
A 33:2489
20. Bokil HS, Young AP (1995) Absence of a phase
transition in a three-dimensional vortex glass model
with screening. Phys Rev Lett 74:3021
21. Kisker J, Rieger H (1998) Application of a minimum
cost ﬂow algorithm to the three-dimensional gauge
Optimization Problems and Algorithms from Computer Science
631

glass model with screening. Phys Rev B 58:R8873.
Pfeiffer F, Rieger H (1999) Numerical study of the
strongly screened vortex glass model in an external
ﬁeld. Phys Rev B 60:6304
22. Pfeiffer FO, Rieger H (2002) Superconductor-to-
normal phase transition in a vortex glass model: a
new percolation universality glass. J Phys C 14:2361.
Pfeiffer FO, Rieger H (2003) Critical properties of
loop percolation models with optimization constraints.
Phys Rev E 67:056113
23. Middleton AA (1995) Numerical results for the
ground-state interface in a random medium. Phys
Rev E 52:R3337. McNamara D, Middleton AA,
Zeng C (1999) Simulation of the zero-temperature
behavior of a three-dimensional elastic medium.
Phys Rev B 60:10062
24. Goldberg AV, Tarjan RE (1988) A new approach to the
maximum-ﬂow problem. J Assoc Comput Mach
35:921
25. Ahuja RK, Magnati TL, Orlin JB (1993) Network
ﬂows. Prentice Hall, London
26. Nattermann T (1990) Scaling approach to pinning:
charge density waves and giant ﬂux creep in supercon-
ductors. Phys Rev Lett 64:2454. Giarmachi T, Le
Doussal P (1994) Elastic theory of pinned ﬂux lattices.
Phys Rev Lett 72:1530; (1995) Phys Rev B 52:1242
27. Bouchaud
J-P,
Georges
A
(1992)
Competition
between lattice pinning and impurity pinning: varia-
tional theory and physical realizations. Phys Rev Lett
68:3908
28. Emig T, Nattermann T (1997) A new disorder-driven
roughening transition of charge-density waves and
ﬂux-line lattices. Phys Rev Lett 79:5090. (1999) Dis-
order driven roughening transitions of elastic mani-
folds and periodic elastic media. Eur J Phys B 8:525
29. Seppälä ET, Alava MJ, Duxbury PM (2001) Intermit-
tence and roughening of periodic elastic media. Phys
Rev E 63:036126
30. Noh JD, Rieger H (2001) Disorder driven critical
behavior of periodic elastic media in a crystal poten-
tial. Phys Rev Lett 87:176102. (2002) Numerical
study of the disorder-driven roughening transition in
an elastic manifold in a periodic potential. Phys Rev
E 66:036117
31. Rieger H (1995) Monte Carlo simulations of Ising spin
glasses and random ﬁeld systems. In: Annual reviews
of computational physics II. World Scientiﬁc, Singa-
pore, pp 295–341
32. Nattermann T (1998) In: Young AP (ed) Spin glasses
and random ﬁelds. World Scientiﬁc, Singapore
33. Anglés d’Auriac JC, Preissman M, Rammal R (1985)
The random ﬁeld Ising-model - algorithmic complex-
ity and phase-transition. J Phys (France) Lett 46:L173
34. Barahona F (1985) Finding ground-states in random-
ﬁeld Ising-ferromagnets. J Phys A 18:L673
35. Middleton AA, Fisher DS (2002) Three-dimensional
random-ﬁeld Ising magnet: interfaces, scaling, and the
nature of states. Phys Rev B 65:13411
36. Ogielski AT (1986) Integer optimization and zero-
temperature ﬁxed point in Ising random-ﬁeld systems.
Phys Rev Lett 57:1251
37. Kawashima N, Rieger H (2004) In: Diep HT
(ed)
Frustrated
spin
systems.
World
Scientiﬁc,
Singapore
38. Grötschel M, Jünger M, Reinelt G (1985) In: van
Hemmen
L,
Morgenstern
I
(eds)
Heidelberg
Colloqium on glassy dynamics and optimization.
Springer, Heidelberg
39. de Simone C, Diehl M, Jünger M, Mutzel P, Reinelt G,
Rinaldi G (1995) Exact ground-states of Ising spin-
glasses - new experimental results with a branch-and-
cut algorithm. J Stat Phys 80:487
40. Lawler EL (1976) Combinatorial optimization: net-
works and matroids. Holt, Rinehart and Winston,
New York
41. Derigs U (1988) Programming in networks and
graphs. In: Springer series: lecture notes in economics
and mathematical systems, vol 300. Springer, Berlin
42. Barahona F (1982) On the computational-complexity
of Ising spin-glass models. J Phys A 15:3241.
Barahona F, Maynard R, Rammal R, Uhry JP (1982)
Morphology of ground-states of two-dimensional
frustration model. J Phys A 15:673
43. Kawashima N, Rieger H (1997) Finite size scaling
analysis of exact ground states for 
J spin glass
models. Europhys Lett 39:85
44. Hartmann
AK,
Young
AP
(2002)
Large-scale
low-energy excitations in the two-dimensional Ising
spin glass. Phys Rev B 66:094419. Hartmann AK,
Bray AJ, Carter
AC, Moore MA, Young AP
(2002) Stiffness exponent of two-dimensional Ising
spin glasses for nonperiodic boundary conditions
using aspect-ratio scaling. Phys Rev B 66:224401
45. Amoruso C, Hartmann AK, Hastings MB, Moore MA
(2006) Conformal invariance and stochastic Loewner
evolution processes in two-dimensional Ising spin
glasses. Phys Rev Lett 97:267202. Bernard D,
LeDoussal P, Middleton AA (2007) Possible descrip-
tion of domain walls in two-dimensional spin glasses
by stochastic Loewner evolutions. Phys Rev B 76:
020403(R)
46. Cardy J (2005) SLE for theoretical physicists. Ann Phys
318:81. Bauer M, Bernard D (2006) 2D growth pro-
cesses: SLE and Loewner chains. Phys Rep 432:115
47. Liers F, Jünger M, Reinelt G, Rinaldi G (2004) Com-
puting exact ground states of hard Ising spin glass
problems by branch-and- cut. In: Hartmann A, Rieger
H (eds) New optimization algorithms in physics.
Wiley, Berlin
48. Chvátal V (1983) Linear programming. Freeman, San
Francisco
49. Grötschel M, Lovász L, Schrijver A (1988) Geometric
algorithms and combinatorial optimization. Springer,
Berlin
50. Wu FY (1982) The Potts model. Rev Mod Phys
54:235
632
Optimization Problems and Algorithms from Computer Science

51. Kasteleyn PW, Fortuin CM (1969) Phase transitions in
lattice systems with random local properties. J Phys
Soc Jpn 46:11
52. Juhász R, Rieger H, Iglói F (2001) The random-bond
Potts
model
in
the
large-q
limit.
Phys
Rev
E 64:056122
53. Grötschel M, Lovász L, Schrijver A (1981) The ellip-
soid method and its consequences in combinatorial
optimization. Combinatorica 1:169
54. Iwata
S,
Fleischer
L,
Fujishige
S
(2001)
A combinatorial strongly polynomial algorithm for
minimizing submodular functions. J ACM 48(4):761
55. Schrijver A (2000) A combinatorial algorithm mini-
mizing submodular functions in strongly polynomial
time. J Comb Theory Ser B 80:346
56. Edmonds J (1977) In: Guy R, Hannani H, Sauer N,
Schóonheim J (eds) Combinatorial structures and their
applications. Gordon and Breach, New York
57. Kasteleyn PW, Fortuin CM (1969) Phase transitions in
lattice systems with random local properties. J Phys
Soc Jpn 26:11
58. Anglés d’Auriac JC, Iglói F, Preissmann M, Sebö
A (2002) Optimal cooperation and submodularity for
computing Potts’ partition functions with a large num-
ber of states. J Phys A 85:6973
59. Anglés d’Auriac JC (2004) Computing the Potts free
energy and submodular functions. In: Hartmann A,
Rieger H (eds) New optimization algorithms in phys-
ics. Wiley, Berlin
60. Anglés d’Auriac JC, Iglói F (2003) Phase transition in
the 2D random Potts model in the large-q limit. Phys
Rev Lett 90:190601. Mercaldo MT, Anglés d’Auriac
J-C, Iglói F (2004) Disorder-induced rounding of the
phase transition in the large-q-state Potts model. Phys
Rev E 69:056112; Mercaldo MT, Anglés d’Auriac
J-C, Iglói F (2005) Disorder-driven phase transitions
of the large q-state Potts model in three dimensions.
Europhys Lett 70:733
61. Fisher DS (1992) Random transverse ﬁeld Ising spin
chains. Phys Rev Lett 69:534. (1995) Critical behavior
of random transverse-ﬁeld Ising spin chains. Phys Rev
B 51:6411
62. Zeng C, Middleton AA, Shapir Y (1996) Ground-state
roughness of the disordered substrate and ﬂux lines in
d ¼ 2. Phys Rev Lett 77:3204
63. Middleton AA (1999) Numerical investigation of the
thermodynamic limit for ground states in models with
quenched disorder. Phys Rev Lett 83:1672
64. Anglés d’Auriac J-C, Sourlas N (1997) The 3d random
ﬁeld Ising model at zero temperature. Europhys Lett
39:473
65. Anglés d’Auriac J-C, Preissmann M, Sebö A (1997)
Optimal cuts in graphs and statistical mechanics. Math
Comput Model 26:1
66. Pal
KF
(2004)
Hysteretic
opimization.
In:
Hartmann A, Rieger H (eds) New optimization algo-
rithms in physics. Wiley, Berlin
67. Boettcher
S
(2004)
Extremal
optimization.
In:
Hartmann A, Rieger H (eds) New optimization algo-
rithms in physics. Wiley, Berlin
68. Weigt M (2004) The random 3-satisﬁability prob-
lem: from the phase transition to the efﬁcient gen-
eration
of
hard,
but
satisﬁable
instances.
In:
Hartmann A, Rieger H (eds) New optimization
algorithms in physics. Wiley, Berlin; Cocco S,
Ein-Dor L, Monasson R (ibid) Analysis of back-
tracking procedures for random decision problems;
Zecchina R (ibid) New iterative algorithms for hard
combinatorial problems
Books and Reviews
Alava M, Duxbury P, Moukarzel C, Rieger H (2000) Com-
binatorial optimization and disordered systems. In:
Domb C, Lebowitz JL (eds) Phase transition and criti-
cal phenomena, vol 18. Academic, Cambridge
Hartmann A, Rieger H (2002) Optimization algorithms in
physics. Wiley, Berlin
Hartmann A, Rieger H (2004) New optimization algo-
rithms in physics. Wiley, Berlin
Hartmann AK, Weigt M (2005) Phase transitions in com-
binatorial optimization problems. Wiley, Berlin
Optimization Problems and Algorithms from Computer Science
633

Statistical Mechanics
Approach to Econophysics
Victor M. Yakovenko
Department of Physics, University of Maryland,
College Park, MD, USA
Article Outline
Glossary
Deﬁnition of the Subject
Historical Introduction
Statistical Mechanics of Money Distribution
Statistical Mechanics of Wealth Distribution
Data and Models for Income Distribution
Other Applications of Statistical Physics
Future Directions, Criticism, and Conclusions
Future Directions
Criticism from Economists
Conclusions
Bibliography
Glossary
Probability density P(x) is deﬁned so that the
probability of ﬁnding a random variable x in
the interval from x to x þ dx is equal to P(x) dx.
Cumulative probability C(x) is deﬁned as the
integral C x
ð Þ ¼
Ð 1
x P x
ð Þdx. It gives the proba-
bility that the random variable exceeds a given
value x.
The Boltzmann-Gibbs distribution gives the
probability of ﬁnding a physical system in a
state with the energy ε. Its probability density
is given by the exponential function (1).
The Gamma distribution has the probability
density given by a product of an exponential
function and a power-law function, as in (9).
The Pareto distribution has the probability
density P(x) / 1/x1þα and the cumulative
probability C(x) / 1/xα given by a power law.
These expressions apply only for high enough
values of x and do not apply for x ! 0.
The Lorenz curve was introduced by American
economist Max Lorenz to describe income and
wealth inequality. It is deﬁned in terms of two
coordinates x(r) and y(r) given by (19). The
horizontal coordinate x(r) is the fraction of the
population with income below r, and the verti-
cal coordinate y(r) is the fraction of income this
population accounts for. As r changes from 0 to
1, x and y change from 0 to 1, parametrically
deﬁning a curve in the (x, y)-plane.
The Gini coefﬁcient G was introduced by the
Italian statistician Corrado Gini as a measure
of inequality in a society. It is deﬁned as the
area between the Lorenz curve and the straight
diagonal line, divided by the area of the trian-
gle beneath the diagonal line. For perfect
equality (everybody has the same income or
wealth) G ¼ 0, and for total inequality (one
person has all income or wealth, and the rest
have nothing) G ¼ 1.
The Fokker-Planck equation is the partial dif-
ferential Eq. (22) that describes evolution in
time t of the probability density P(r, t) of a
random variable r experiencing small random
changes Δr during short time intervals Δt. It is
also known in mathematical literature as the
Kolmogorov forward equation. The diffusion
equation is an example of the Fokker-Planck
equation.
Definition of the Subject
Econophysics is an interdisciplinary research
ﬁeld applying methods of statistical physics to
problems in economics and ﬁnance. The term
“econophysics” was ﬁrst introduced by the prom-
inent theoretical physicist Eugene Stanley in
1995 at the conference Dynamics of Complex
Systems, which was held in Calcutta (now
known as Kolkata) as a satellite meeting to the
© Springer Science+Business Media, LLC, part of Springer Nature 2022
B. Chakraborty (ed.), Statistical and Nonlinear Physics,
https://doi.org/10.1007/978-1-0716-1454-9_169
Originally published in
R. A. Meyers (ed.), Encyclopedia of Complexity and Systems Science, © Springer Science+Business Media LLC 2022
https://doi.org/10.1007/978-3-642-27737-5_169-2
635

STATPHYS-19 conference in China (Chakrabarti
2005; Carbone et al. 2007). The term appeared in
print for the ﬁrst time in the paper by Stanley et al.
(1996) in the proceedings of the Calcutta confer-
ence. The paper presented a manifesto of the new
ﬁeld, arguing that “behavior of large numbers of
humans (as measured, e. g., by economic indices)
might conform to analogs of the scaling laws that
have proved useful in describing systems composed
of large numbers of inanimate objects” (Stanley
et al. 1996). Soon the ﬁrst econophysics confer-
ences were organized: International Workshop on
Econophysics, Budapest, 1997, and International
WorkshoponEconophysics andStatistical Finance,
Palermo, 1998 (Carbone et al. 2007), and the book
An Introduction to Econophysics (Mantegna and
Stanley 1999) was published.
The term “econophysics” was introduced by
analogy with similar terms, such as “astrophys-
ics,” “geophysics,” and “biophysics,” which
describe applications of physics to different ﬁelds.
Particularly important is the parallel with biophys-
ics, which studies living creatures, which still
obey the laws of physics. It should be emphasized
that econophysics does not literally apply the laws
of physics, such as Newton’s laws or quantum
mechanics, to humans, but rather uses mathemat-
ical methods developed in statistical physics to
study statistical properties of complex economic
systems consisting of a large number of humans.
So, it may be considered as a branch of applied
theory of probabilities. However, statistical phys-
ics is distinctly different from mathematical sta-
tistics in its focus, methods, and results.
Originating from physics as a quantitative sci-
ence, econophysics emphasizes quantitative anal-
ysis of large amounts of economic and ﬁnancial
data, which became increasingly available with
the massive introduction of computers and the
Internet. Econophysics distances itself from the
verbose, narrative, and ideological style of politi-
cal economy and is closer to econometrics in its
focus. Studying mathematical models of a large
number
of
interacting
economic
agents,
econophysics has much common ground with
the agent-based modeling and simulation. Cor-
respondingly,
it
distances
itself
from
the
representative-agent
approach
of
traditional
economics, which, by deﬁnition, ignores statisti-
cal and heterogeneous aspects of the economy.
Two major directions in econophysics are appli-
cations to ﬁnance and economics. Observational
aspects are covered in the entry “Econophysics,
Observational.” This entry, “Econophysics, Statis-
tical Mechanics Approach to,” concentrates primar-
ily on statistical distributions of money, wealth, and
income among interacting economic agents.
Another direction related to econophysics has
been advocated by the theoretical physicist Serge
Galam since the early 1980s under the name
“sociophysics” (Galam 2004), with the ﬁrst
appearance of the term in print in Galan et al.
(1982). It echoes the term physique sociale pro-
posed in the nineteenth century by Auguste
Comte,
the
founder
of
sociology.
Unlike
econophysics, the term “sociophysics” did not
catch on when ﬁrst introduced, but it is coming
back with the popularity of econophysics and
active promotion by some physicists (Stauffer
2004; Schweitzer 2003; Weidlich 2000). While
the principles of both ﬁelds have a lot in common,
econophysics focuses on the narrower subject of
economic behavior of humans, where more quan-
titative data are available, whereas sociophysics
studies a broader range of social issues. The
boundary
between
econophysics
and
socio-
physics is not sharp, and the two ﬁelds enjoy a
good rapport (Chakrabarti et al. 2006). A more
detailed description of the historical development
is presented in section “Historical Introduction.”
Historical Introduction
Statistical mechanics was developed in the second
half of the nineteenth century by James Clerk
Maxwell, Ludwig Boltzmann, and Josiah Willard
Gibbs. These physicists believed in the existence
of atoms and developed mathematical methods
for describing their statistical properties, such as
the probability distribution of velocities of mole-
cules in a gas (the Maxwell-Boltzmann distribu-
tion) and the general probability distribution of
states with different energies (the Boltzmann-
Gibbs distribution). There are interesting connec-
tions between the development of statistical
636
Statistical Mechanics Approach to Econophysics

physics and statistics of social phenomena, which
were recently brought up by the science journalist
Philip Ball (Ball 2002, 2004).
Collection and study of “social numbers,” such
as the rates of death, birth, and marriage, has been
growing progressively since the seventeenth cen-
tury (see Chap. 3 in Ball 2004). The term “statis-
tics” was introduced in the eighteenth century to
denote these studies dealing with the civil
“states,” and its practitioners were called “stat-
ists.” Popularization of social statistics in the nine-
teenth century is particularly accredited to the
Belgian astronomer Adolphe Quetelet. Before
the 1850s, statistics was considered an empirical
arm of political economy, but then it started to
transform into a general method of quantitative
analysis suitable for all disciplines. It stimulated
physicists to develop statistical mechanics in the
second half of the nineteenth century.
Rudolf Clausius started development of the
kinetic theory of gases, but it was James Clerk
Maxwell who made a decisive step of deriving the
probability distribution of velocities of molecules
in a gas. Historical studies show (see Chap. 3 in
Ball 2004) that, in developing statistical mechan-
ics, Maxwell was strongly inﬂuenced and encour-
aged by the widespread popularity of social
statistics at the time. This approach was further
developed by Ludwig Boltzmann, who was very
explicit about its origins (see p. 69 in Ball 2004):
The molecules are like individuals, and the proper-
ties of gases only remain unaltered, because the
number of these molecules, which on the average
have a given state, is constant.
In his book Populäre Schriften from 1905
(Boltzmann 1905), Boltzmann praises Josiah Wil-
lard Gibbs for systematic development of statisti-
cal mechanics. Then, Boltzmann says (cited from
Austrian Central Library for Physics (2006)):
This opens a broad perspective if we do not only
think of mechanical objects. Let’s consider to apply
this method to the statistics of living beings, society,
sociology and so forth.
(The author is grateful to Michael E. Fisher for
bringing this quote to his attention.)
It is worth noting that many now-famous econ-
omists were originally educated in physics and
engineering. Vilfredo Pareto earned a degree in
mathematical sciences and a doctorate in engi-
neering. Working as a civil engineer, he collected
statistics
demonstrating
that
distributions
of
income and wealth in a society follow a power
law (Pareto 1897). He later became a professor of
economics at Lausanne, where he replaced Léon
Walras, also an engineer by education. The inﬂu-
ential American economist Irving Fisher was a
student of Gibbs. However, most of the mathe-
matical apparatus transferred to economics from
physics was that of Newtonian mechanics and
classical thermodynamics (Mirowski 1989). It
culminated in the neoclassical concept of mecha-
nistic equilibrium where the “forces” of supply
and demand balance each other. The more general
concept of statistical equilibrium largely eluded
mainstream economics.
With
time,
both
physics
and
economics
became more formal and rigid in their specializa-
tions, and the social origin of statistical physics
was forgotten. The situation is well summarized
by Philip Ball (see p. 69 in Ball (2004)):
Today physicists regard the application of statistical
mechanics to social phenomena as a new and risky
venture. Few, it seems, recall how the process orig-
inated the other way around, in the days when phys-
ical science and social science were the twin siblings
of a mechanistic philosophy and when it was not in
the least disreputable to invoke the habits of people
to explain the habits of inanimate particles.
Some physicists and economists attempted to
connect the two disciplines during the twentieth
century. The theoretical physicist Ettore Majorana
argued in favor of applying the laws of statistical
physics to social phenomena in a paper published
after his mysterious disappearance (Majorana
1942). The statistical physicist Elliott Montroll
co-authored the book Introduction to Quantitative
Aspects of Social Phenomena (Montroll and
Badger 1974). Several economists applied statis-
tical physics to economic problems (Föllmer
1974; Blume 1993; Foley 1994; Durlauf 1997).
An early attempt to bring together the leading
theoretical physicists and economists at the
Santa Fe Institute was not entirely successful
(Anderson et al. 1988). However, by the late
1990s, the attempts to apply statistical physics to
Statistical Mechanics Approach to Econophysics
637

social phenomena ﬁnally coalesced into the robust
movements of econophysics and sociophysics, as
described in section “Deﬁnition of the Subject.”
The current standing of econophysics within
the physics and economics communities is mixed.
Although an entry on econophysics has appeared
in the New Palgrave Dictionary of Economics
(Rosser 2008), it is fair to say that econophysics
is not accepted yet by mainstream economics.
Nevertheless, a number of open-minded, non-
traditional economists have joined this move-
ment, and the number is growing. Under these
circumstances, econophysicists have most of
their papers published in physics journals. The
journal Physica A: Statistical Mechanics and Its
Applications
emerged
as
the
leader
in
econophysics publications and has even attracted
submissions from some bona ﬁde economists. The
mainstream physics community is generally sym-
pathetic to econophysics, although it is not uncom-
mon for econophysics papers to be rejected by
Physical Review Letters on the grounds that “it is
not physics.” There are regular conferences on
econophysics, such as Applications of Physics in
Financial Analysis (sponsored by the European
Physical Society), Nikkei Econophysics Sympo-
sium, and Econophysics Colloquium. Econophysics
sessions are included in the annual meetings of
physical societies and statistical physics confer-
ences. The overlap with economics is the strongest
in the ﬁeld of agent-based simulation. Not surpris-
ingly, the conference series WEHIA/ESHIA, which
deals with heterogeneous interacting agents, regu-
larly includes sessions on econophysics.
Statistical Mechanics of Money
Distribution
When modern econophysics started in the middle
of the 1990s, its attention was primarily focused
on analysis of ﬁnancial markets. However, three
inﬂuential papers (Drăgulescu and Yakovenko
2000;
Chakraborti
and
Chakrabarti
2000;
Bouchaud and Mézard 2000), dealing with the
subject of money and wealth distributions, were
published in 2000. They started a new direction
that is closer to economics than ﬁnance and
created an expanding wave of follow-up publica-
tions. We start reviewing this subject with
Drăgulescu and Yakovenko (2000), whose results
are the most closely related to the traditional sta-
tistical mechanics in physics.
The Boltzmann-Gibbs Distribution of Energy
The fundamental law of equilibrium statistical
mechanics is the Boltzmann-Gibbs distribution.
It states that the probability P(ε) of ﬁnding a
physical system or subsystem in a state with the
energy ε is given by the exponential function
P eð Þ ¼ ce
e
T ,
ð1Þ
where T is the temperature, and c is a normalizing
constant (Wannier 1987). Here we set the
Boltzmann constant kB to unity by choosing the
energy units for measuring the physical tempera-
ture T. Then, the expectation value of any physical
variable x can be obtained as
x
h i ¼
P
k
xke
ek
T
P
k
e
ek
T
,
ð2Þ
where the sum is taken over all states of the
system. Temperature is equal to the average
energy per particle: T ~ hεi, up to a numerical
coefﬁcient of the order of 1.
Equation (1) can be derived in different ways
(Wannier 1987). All derivations involve the two
main ingredients: statistical character of the sys-
tem and conservation of energy ε. One of the
shortest derivations can be summarized as fol-
lows.
Let
us
divide
the
system
into
two
(generally unequal) parts. Then, the total energy
is the sum of the parts, ε ¼ ε1 þ ε2, whereas the
probability is the product of probabilities, P(ε) ¼
P(ε1)P(ε2). The only solution of these two equa-
tions is the exponential function (1).
A more sophisticated derivation, proposed by
Boltzmann himself, uses the concept of entropy.
Let us consider N particles with total energy E. Let
us divide the energy axis into small intervals
(bins) of width Δε and count the number of parti-
cles Nk having energies from εk to εk þ Δε. The
638
Statistical Mechanics Approach to Econophysics

ratio Nk/N ¼ Pk gives the probability for a particle
having the energy εk. Let us now calculate the
multiplicity W, which is the number of permuta-
tions of the particles between different energy bins
such that the occupation numbers of the bins do
not change. This quantity is given by the combi-
natorial formula in terms of the factorials
W ¼
N!
N1!N2!N3! . . . :
ð3Þ
The logarithm of multiplicity of called the
entropy S ¼ ln W. In the limit of large numbers,
the entropy per particle can be written in the
following form using the Stirling approximation
for the factorials:
S
N ¼ 
X
k
Nk
N ln Nk
N


¼ 
X
k
Pk ln Pk:
ð4Þ
Now we would like to ﬁnd what distribution of
particles between different energy states has the
highest entropy, that is, the highest multiplicity,
provided that the total energy of the system,
E ¼ P
k
Nkek, has a ﬁxed value. Solution of this
problem can be easily obtained using the method
of Lagrange multipliers (Wannier 1987), and the
answer gives the exponential distribution (1).
The same result can be derived from the ergo-
dic theory, which says that the many-body system
occupies all possible states of a given total energy
with equal probabilities. Then it is straightforward
to show (Lopez-Ruiz et al. 2007a, b) that the
probability distribution of the energy of an indi-
vidual particle is given by (1).
Conservation of Money
The
derivations
outlined
in
section
“The
Boltzmann-Gibbs Distribution of Energy” are
very general and use only the statistical character
of the system and the conservation of energy. So,
one may expect that the exponential Boltzmann-
Gibbs distribution (1) may apply to other statisti-
cal systems with a conserved quantity.
The economy is a big statistical system with
millions of participating agents, so it is a promis-
ing target for applications of statistical mechanics.
Is there a conserved quantity in economy?
Drăgulescu and Yakovenko (2000) argue that
such a conserved quantity is money m. Indeed,
the ordinary economic agents can only receive
money from and give money to other agents.
They are not permitted to “manufacture” money,
for example, to print dollar bills. When one agent
i pays money Δm to another agent j for some
goods or services, the money balances of the
agents change as follows:
mi
! m0
i ¼ mi  Dm,
m j
! m0
j ¼ m j þ Dm:
ð5Þ
The total amount of money of the two agents
before and after the transaction remains the same,
mi þ m j ¼ m0
i þ m0
j,
ð6Þ
that is, there is a local conservation law for money.
The rule (5) for the transfer of money is analogous
to the transfer of energy from one molecule to
another in molecular collisions in a gas, and (6)
is analogous to conservation of energy in such
collisions.
Addressing some misunderstandings devel-
oped in economic literature (Anglin 2005; Lux
2005; Gallegati et al. 2006; Lux 2008), we
should
emphasize
that,
in
the
model
of
Drăgulescu and Yakovenko (2000), the transfer
of money from one agent to another happens
voluntarily, as a payment for goods and services
in a market economy. However, the model only
keeps track of money ﬂow, and does not keep
track of what kinds of goods and service are
delivered. One reason for this is that many
goods, for example, food and other supplies,
and most services, for example, getting a haircut
or going to a movie, are not tangible and disap-
pear after consumption. Because they are not
conserved and also because they are measured
in different physical units, it is not very practical
to keep track of them. In contrast, money is
measured in the same unit (within a given coun-
try with a single currency) and is conserved in
transactions, so it is straightforward to keep
track of money ﬂow.
Statistical Mechanics Approach to Econophysics
639

Unlike ordinary economic agents, a central
bank or a central government can inject money
into the economy. This process is analogous to an
inﬂux of energy into a system from external
sources, for example, the Earth receives energy
from the Sun. Dealing with these situations, phys-
icists start with an idealization of a closed system in
thermal equilibrium and then generalize to an open
system subject to an energy ﬂux. As long as the rate
of money inﬂux from central sources is slow com-
pared with relaxation processes in the economy
and does not cause hyperinﬂation, the system is in
quasi-stationary statistical equilibrium with slowly
changing parameters. This situation is analogous to
heating a kettle on a gas stove slowly, where the
kettle has a well-deﬁned, but slowly increasing
temperature at any moment of time.
Another potential problem with conservation
of money is debt. This issue is discussed in more
detail in section “Models with Debt.” As a starting
point, Drăgulescu and Yakovenko (2000) ﬁrst
considered simple models, where debt is not per-
mitted. This means that money balances of agents
cannot go below zero: mi  0 for all i. Transac-
tion (5) takes place only when an agent has
enough money to pay the price, mi  Δm, other-
wise the transaction does not take place. If an
agent spends all the money, the balance drops to
zero mi ¼ 0, so the agent cannot buy any goods
from other agents. However, this agent can still
produce goods or services, sell them to other
agents, and receive money for them. In real life,
cash balance dropping to zero is not at all unusual
for people who live from paycheck to paycheck.
The conservation law is the key feature for the
successful functioning of money. If the agents
were permitted to “manufacture” money, they
would be printing money and buying all goods
for nothing, which would be a disaster. The phys-
ical medium of money is not essential, as long as
the conservation law is enforced. Money may be
in the form of paper cash, but today it is more
often represented by digits in computerized bank
accounts. The conservation law is the fundamen-
tal principle of accounting, whether in the single-
entry or in the double-entry form. More discus-
sion of banks and debt is given in section “Models
with Debt.”
The Boltzmann-Gibbs Distribution of Money
Having recognized the principle of money conser-
vation, Drăgulescu and Yakovenko (2000) argued
that the stationary distribution of money should be
given by the exponential Boltzmann-Gibbs func-
tion analogous to (1):
P m
ð Þ ¼ ce
m
Tm:
ð7Þ
Here c is a normalizing constant, and Tm is the
“money temperature,” which is equal to the average
amount of money per agent: T ¼ hmi ¼ M/N, where
M is the total money, and N is the number of agents.
To verify this conjecture, Drăgulescu and
Yakovenko (2000) performed agent-based com-
puter simulations of money transfers between
agents. Initially all agents were given the same
amount of money, say, $1000. Then, a pair of
agents (i, j) were randomly selected, the amount
Δm was transferred from one agent to another, and
the process was repeated many times. Time evo-
lution of the probability distribution of money
P(m) can be seen in computer animation videos
at the Web pages (Computer animation videos of
money-transfer models 2008; Wright 2007). After
a transitory period, money distribution converges
to the stationary form shown in Fig. 1. As
expected, the distribution is very well ﬁtted by
the exponential function (7).
Several different rules for Δm were considered
in Drăgulescu and Yakovenko (2000). In one
model, the amount transferred was ﬁxed to a con-
stant Δm ¼ 1$. Economically, it means that all
agents were selling their products for the same
price Δm ¼ 1$. Computer animation (Computer
animation videos of money-transfer models 2008)
shows that the initial distribution of money ﬁrst
broadens to a symmetric, Gaussian curve, charac-
teristic for a diffusion process. Then, the distribu-
tion starts to pile up around the m ¼ 0 state, which
acts as the impenetrable boundary, because of
the imposed condition m  0. As a result, P(m)
becomes skewed (asymmetric) and eventually
reaches
the
stationary
exponential
shape,
as shown in Fig. 1. The boundary at m ¼ 0 is
analogous to the ground-state energy in statistical
physics. Without this boundary condition, the prob-
ability
distribution
of
money
would
not
640
Statistical Mechanics Approach to Econophysics

reach a stationary state. Computer animation
(Computer animation videos of money-transfer
models
2008;
Wright
2007)
also
shows
how the entropy of money distribution, deﬁned as
S=N ¼ P
k
P mk
ð
Þ ln P mk
ð
Þ, grows from the initial
value S ¼ 0, when all agents have the same
money, to the maximal value at the statistical
equilibrium.
While the model with Δm ¼ 1 is very simple
and instructive, it is not very realistic, because all
prices are taken to be the same. In another model
considered in Drăgulescu and Yakovenko (2000),
Δm in each transaction is taken to be a random
fraction of the average amount of money per
agent, that is, Δm ¼ n(M/N), where n is a uniformly
distributed random number between 0 and 1. The
random distribution of Δm is supposed to represent
the wide variety of prices for different products in
the real economy. It reﬂects the fact that agents buy
and consume many different types of products,
some of them simple and cheap, some sophisticated
and expensive. Moreover, different agents like to
consume these products in different quantities, so
there is variation in the amounts Δm paid, even
though the unit price of the same product is con-
stant. Computer simulation of this model produces
exactly the same stationary distribution (7) as in the
ﬁrst model. Computer animation for this model is
also available on the Web page (Computer anima-
tion videos of money-transfer models 2008).
The ﬁnal distribution is universal despite dif-
ferent rules for Δm. To amplify this point further,
Drăgulescu and Yakovenko (2000) also consid-
ered a toy model, where Δm was taken to be a
random fraction of the average amount of money
of the two agents: Δm ¼ n(mi þ mj)/2. This model
produced the same stationary distribution (7) as
the other two models.
The pairwise models of money transfer are
attractive in their simplicity, but they represent a
rather primitive market. The modern economy is
dominated by big ﬁrms, which consist of many
agents, so Drăgulescu and Yakovenko (2000) also
studied a model with ﬁrms. One agent at a time is
appointed to become a “ﬁrm.” The ﬁrm borrows
capital K from another agent and returns it with
interest hK, hires L agents and pays them wages
W, manufactures Q items of a product, sells them
to Q agents at price R, and receives proﬁt F ¼
RQ  LW  hK. All of these agents are randomly
selected. The parameters of the model are opti-
mized following a procedure from economics
textbooks (McConnell and Brue 1996). The
aggregate demand-supply curve for the product
is used in the form R(Q) ¼ v/Q, where Q is the
quantity consumers would buy at price R, and Z
and v are some parameters. The production func-
tion of the ﬁrm has the traditional Cobb-Douglas
form: Q(L, K) ¼ LwK1w, where w is a parameter.
Then the proﬁt of the ﬁrm F is maximized with
respect to K and L. The net result of the ﬁrm
Statistical Mechanics
Approach
to Econophysics,
Fig. 1 Stationary
probability distribution of
money P(m) obtained in
agent-based computer
simulations. Solid curves:
ﬁts to the Boltzmann-Gibbs
law (7). Vertical lines: the
initial distribution of
money. (Reproduced from
Drăgulescu and Yakovenko
(2000))
Statistical Mechanics Approach to Econophysics
641

activity is a many-body transfer of money, which
still satisﬁes the conservation law. Computer sim-
ulation of this model generates the same exponen-
tial distribution (7), independently of the model
parameters. The reasons for the universality of the
Boltzmann-Gibbs distribution and its limitations
are discussed from a different perspective in sec-
tion “Additive Versus Multiplicative Models.”
Well after paper (Drăgulescu and Yakovenko
2000) appeared, Italian econophysicists (Patriarca
et al. 2005) found that similar ideas had been
published earlier in obscure journals in Italian by
Eleonora Bennati (Bennati 1988, 1993). They
proposed
calling
these
models
the
Bennati-
Drăgulescu-Yakovenko game (Scalas et al. 2006).
The Boltzmann distribution was independently
applied to social sciences by Jürgen Mimkes using
the Lagrange principle of maximization with con-
straints (Mimkes 2000, 2005). The exponential dis-
tribution of money was also found in Shubik (1999)
using a Markov chain approach to strategic market
games. A long time ago, Benoit Mandelbrot
observed (see p. 83 in Mandelbrot (1960)):
There is a great temptation to consider the exchanges
of money which occur in economic interaction as
analogous to the exchanges of energy which occur in
physical shocks between gas molecules.
He realized that this process should result in the
exponential distribution, by analogy with the baro-
metric distribution of density in the atmosphere.
However, he discarded this idea, because it does
not produce the Pareto power law, and proceeded
to study the stable Lévy distributions. Ironically,
the actual economic data, discussed in section
“Empirical Data on Money and Wealth Distribu-
tions” and “Empirical Data on Income Distribu-
tion,” do show the exponential distribution for the
majority of the population. Moreover, the data have
ﬁnite variance, so the stable Lévy distributions are
not applicable because of their inﬁnite variance.
Models with Debt
Now let us discuss how the results change when
debt is permitted. Debt may be considered as
negative money. When an agent borrows money
from a bank (considered here as a big reservoir of
money), the cash balance of the agent (positive
money) increases, but the agent also acquires a
debt obligation (negative money), so the total
balance (net worth) of the agent remains the
same, and the conservation law of total money
(positive and negative) is satisﬁed. After spending
some cash, the agent still has the debt obligation,
so the money balance of the agent becomes neg-
ative. Any stable economic system must have a
mechanism preventing unlimited borrowing and
unlimited debt. Otherwise, agents can buy any
products without producing anything in exchange
by simply going into unlimited debt. The exact
mechanisms of limiting debt in the real economy
are complicated and obscured. Drăgulescu and
Yakovenko (2000) considered a simple model
where the maximal debt of any agent is limited
by a certain amount md. This means that the
boundary condition mi  0 is now replaced by
the condition mi   md for all agents i. Setting
interest rates on borrowed money to be zero for
simplicity, Drăgulescu and Yakovenko (2000)
performed computer simulations of the models
described in section “The Boltzmann-Gibbs Dis-
tribution of Money” with the new boundary con-
dition. The results are shown in Fig. 2. Not
surprisingly, the stationary money distribution
again has an exponential shape, but now with the
new boundary condition at m ¼  md and the
higher money temperature Td ¼ md þ M/N. By
allowing agents to go into debt up to md, we
effectively increase the amount of money avail-
able to each agent by md. So, the money temper-
ature, which is equal to the average amount of
effectively available money per agent, increases.
A model with nonzero interest rates was also
studied in Drăgulescu and Yakovenko (2000).
We see that debt does not violate the conserva-
tion law of money, but rather modiﬁes boundary
conditions for P(m). When economics textbooks
describe how “banks create money” or “debt cre-
ates money” (McConnell and Brue 1996), they
count only positive money (cash) as money, but
do not count liabilities (debt obligations) as neg-
ative money. With such a deﬁnition, money is not
conserved. However, if we include debt obliga-
tions in the deﬁnition of money, then the conser-
vation law is restored. This approach is in
agreement with the principles of double-entry
accounting, which records both assets and debts.
642
Statistical Mechanics Approach to Econophysics

Debt obligations are as real as positive cash, as
many borrowers painfully realized in their expe-
rience. A more detailed study of positive and
negative money and bookkeeping from the point
of view of econophysics is presented in a series of
papers by the physicist Dieter Braun (2001;
Fischer and Braun 2003a, b).
One way of limiting the total debt in the econ-
omy is the so-called required reserve ratio
r (McConnell and Brue 1996). Every bank is
required by law to set aside a fraction r of the
money deposited with the bank, and this reserved
money cannot be loaned further. If the initial
amount of money in the system (the money base)
is M0, then with loans and borrowing the total
amount of positive money available to the agents
increases to M ¼ M0/r, where the factor 1/r is called
the money multiplier (McConnell and Brue 1996).
This is how “banks create money.” Where does this
extra money come from? It comes from the
increase of the total debt in the system. The max-
imal total debt is equal to D ¼ M0/r  M0 and is
limited by the factor r. When the debt is maximal,
the total amounts of positive, M0/r, and negative,
M0(1  r)/r, money circulate between the agents in
the system, so there are effectively two conserva-
tion laws for each of them (Xi et al. 2005). Thus,
we expect to see the exponential distributions of
positive and negative money characterized by two
different temperatures: T+ ¼ M0/rN and T ¼
M0(1  r)/rN. This is exactly what was found in
computer simulations in Xi et al. (2005), shown in
Fig. 3. Similar two-sided distributions were also
found in Fischer and Braun (2003a).
Proportional Money Transfers and Saving
Propensity
In the models of money transfer considered thus
far, the transferred amount Δm is typically inde-
pendent of the money balances of agents.
A different model was introduced in the physics
literature earlier (Ispolatov et al. 1998) under the
name multiplicative asset exchange model. This
model also satisﬁes the conservation law, but the
amount of money transferred is a ﬁxed fraction γ
of the payer’s money in (5):
Dm ¼ gmi:
ð8Þ
The stationary distribution of money in this
model, shown in Fig. 4 with an exponential func-
tion, is close, but not exactly equal, to the Gamma
distribution:
P m
ð Þ ¼ cmbe
m
T :
ð9Þ
Equation (9) differs from (7) by the power-law
prefactor
mβ.
From
the
Boltzmann
kinetic
equation (discussed in more detail in section
Statistical Mechanics
Approach
to Econophysics,
Fig. 2 Stationary
distributions of money with
and without debt. The debt
is limited to md ¼ 800. Solid
curves: ﬁts to the
Boltzmann-Gibbs laws
with the “temperatures”
T ¼ 1800 and T ¼ 1000.
(Reproduced from
Drăgulescu and Yakovenko
(2000))
Statistical Mechanics Approach to Econophysics
643

“Additive
Versus
Multiplicative
Models”),
Ispolatov et al. (1998) derived a formula relating
the parameters γ and β in (8) and (9):
b ¼ 1  ln 2
ln 1  g
ð
Þ :
ð10Þ
When payers spend a relatively small fraction of
their money γ < 1/2, (10) gives β > 0, so the low-
money population is reduced and P(m ! 0) ¼ 0, as
shown in Fig. 4.
Later, Thomas Lux brought to the attention of
physicists (Lux 2005) that essentially the same
model, called the inequality process, had been
introduced and studied much earlier by the
sociologist John Angle (1986, 1992a, b, 1996,
2002), see also the review Angle (2006) for addi-
tional references. While Ispolatov et al. (Ispolatov
et al. 1998) did not give much justiﬁcation for the
proportionality law (8), Angle (1986) connected
this rule with the surplus theory of social stratiﬁ-
cation (Engels 1972), which argues that inequality
in human society develops when people can pro-
duce more than necessary for minimal subsis-
tence. This additional wealth (surplus) can be
transferred from original producers to other peo-
ple, thus generating inequality. In the ﬁrst paper
by Angle (1986), the parameter γ was randomly
distributed, and another parameter, δ, gave a
higher probability of winning to the agent with a
Statistical Mechanics
Approach
to Econophysics,
Fig. 4 Stationary
probability distribution of
money in the multiplicative
random exchange model (8)
for γ ¼ 1/3. Solid curve: the
exponential Boltzmann-
Gibbs law. (Reproduced
from Drăgulescu and
Yakovenko (2000))
40
30
20
10
0
-50
0
Monetary Wealth, m
TProbability, P(m) (1x10 
-3)
50
-50
0
Monetary Wealth m
log(PT(m)) (1x10
-3)
10
1
0.1
50
100
150
100
150
Statistical Mechanics
Approach
to Econophysics,
Fig. 3 The stationary
distribution of money for
the required reserve ratio
r ¼ 0.8. The distribution is
exponential for positive and
negative money with
different “temperatures” T+
and T, as illustrated by the
inset on log-linear scale.
(Reproduced from Xi et al.
(2005))
644
Statistical Mechanics Approach to Econophysics

higher money balance in (5). However, in the
following papers, he simpliﬁed the model to a
ﬁxed γ (denoted as o by Angle) and equal prob-
abilities of winning for higher- and lower-balance
agents, which makes it completely equivalent to
the model of Ispolatov et al. (1998). Angle also
considered a model (Angle 2002, 2006) where
groups of agents have different values of γ, simu-
lating the effect of education and other “human
capital.” All of these models generate a Gamma-
like distribution, well approximated by (9).
Another model with an element of proportion-
ality was proposed in Chakraborti and Chakrabarti
(2000). (This paper originally appeared as a follow-
up preprint cond-mat/0004256 to the preprint
cond-mat/0001432 of Drăgulescu and Yakovenko
(2000).) In this model, the agents set aside (save)
some fraction of their money lmi, whereas the rest
of their money balance (1  l)mi becomes avail-
able for random exchanges. Thus, the rule of
exchange (5) becomes
m0
i ¼ lmi þ x 1  l
ð
Þ mi þ m j


,
m0
j ¼ lm j þ 1  x
ð
Þ 1  l
ð
Þ mi þ m j


:
ð11Þ
Here the coefﬁcient l is called the saving pro-
pensity, and the random variable x is uniformly
distributed between 0 and 1. It was pointed out in
Angle (2006) that, by the change of notation
l ! (1  γ), (11) can be transformed to the
same form as (8), if the random variable x takes
only discrete values 0 and 1. Computer simula-
tions (Chakraborti and Chakrabarti 2000) of the
model (11) found a stationary distribution close to
the Gamma distribution (9). It was shown that the
parameter β is related to the saving propensity l
by the formula β ¼ 3l/(1  l) (Patriarca et al.
2004a, b, 2005, Repetowicz et al. 2005). For
l 6¼ 0, agents always keep some money, so their
balances never go to zero and P(m ! 0) ¼ 0,
whereas for l ¼ 0 the distribution becomes
exponential.
In the subsequent papers by the Kolkata school
(Chakrabarti 2005) and related papers, the case of
random saving propensity was studied. In these
models, the agents are assigned random parame-
ters l drawn from a uniform distribution between
0 and 1 (Chatterjee et al. 2004). It was found that
this model produces a power-law tail P(m) / 1/m2
at high m. The reasons for stability of this law
were understood using the Boltzmann kinetic
equation (Repetowicz et al. 2005; Das and
Yarlagadda 2005; Chatterjee et al. 2005), but
most
elegantly
in
the
mean-ﬁeld
theory
(Mohanty 2006). The fat tail originates from the
agents whose saving propensity is close to 1, who
hoard money and do not give it back (Patriarca
et al. 2005, 2006). An interesting matrix formula-
tion of the problem was presented in Gupta
(2006). Patriarca et al. (2007) studied the relaxa-
tion rate in the money transfer models. Drăgulescu
and Yakovenko (2000) studied a model with tax-
ation, which also has an element of proportional-
ity. The Gamma distribution was also studied for
conservative models within a simple Boltzmann
approach in Ferrero (2004) and using much more
complicated rules of exchange in Scafetta et al.
(2004a, b).
Additive Versus Multiplicative Models
The stationary distribution of money (9) for the
models of section “Proportional Money Transfers
and Saving Propensity” is different from the sim-
ple exponential formula (7) found for the models
of section “The Boltzmann-Gibbs Distribution of
Money.” The origin of this difference can be
understood from the Boltzmann kinetic equation
(Wannier 1987; Lifshitz and Pitaevskii 1981). This
equation describes time evolution of the distribu-
tion function P(m) due to pairwise interactions:
dP m
ð Þ
dt
¼
ð ð
f mm0
½
! mm0þ
½
P m
ð ÞP m0
ð
Þ
n
þ f mm0þ
½
! mm0
½
P m
ð Þ
P m0 þ
ð
Þ
o
dm0d:
ð12Þ
Here f m,m0
½
! mD,m0þD
½
 is the probability of
transferring money Δ from an agent with money
m to an agent with money m0 per unit time. This
probability, multiplied by the occupation numbers
P(m) and P(m0), gives the rate of transitions from
the state [m, m0] to the state[m  Δ, m0 þ Δ]. The
ﬁrst term in (12) gives the depopulation rate of the
state m. The second term in (12) describes the
reverse process, where the occupation number
Statistical Mechanics Approach to Econophysics
645

P(m) increases. When the two terms are equal, the
direct and reverse transitions cancel each other
statistically, and the probability distribution is sta-
tionary: dP(m)/dt ¼ 0. This is the principle of
detailed balance.
In physics, the fundamental microscopic equa-
tions of motion of particles obey time-reversal
symmetry. This means that the probabilities of
the direct and reverse processes are exactly equal:
f m,m0
½
! mD,m0þD
½
 ¼ f mD,m0þD
½
! m,m0
½
:
ð13Þ
When (13) is satisﬁed, the detailed balance con-
dition for (12) reduces to the equation P(m)
P(m0) ¼ P(m  Δ)P(m0 þ Δ), because the factors
f cancel out. The only solution of this equation is
the exponential function P(m) ¼ c exp (m/Tm), so
the Boltzmann-Gibbs distribution is the stationary
solution of the Boltzmann kinetic Eq. (12). Notice
that the transition probabilities (13) are determined
by the dynamical rules of the model, but the equi-
librium Boltzmann-Gibbs distribution does not
depend on the dynamical rules at all. This is the
origin of the universality of the Boltzmann-Gibbs
distribution. It shows that it may be possible to ﬁnd
out the stationary distribution without knowing
details of the dynamical rules (which are rarely
known very well), as long as the symmetry condi-
tion (13) is satisﬁed.
The
models
considered
in
section
“The
Boltzmann-Gibbs Distribution of Money” have
the time-reversal symmetry. The model with the
ﬁxed money transfer Δ has equal probabilities (13)
of transferring money from an agent with balance
m to an agent with balance m0 and vice versa. This
is also true when Δ is random, as long as the
probability distribution of Δ is independent of
m and m0. Thus, the stationary distribution P(m)
is always exponential in these models.
However, there is no fundamental reason to
expect time-reversal symmetry in economics,
so (13) may be not valid. In this case, the system
may have a nonexponential stationary distribution
or no stationary distribution at all. In model (8), the
time-reversal symmetry is broken. Indeed, when an
agent i gives a ﬁxed fraction γ of his money mi to
an agent with balance mj, their balances become
(1  γ)mi and mj þ γmi. If we try to reverse this
process and appoint an agent j to be the payer and
to give the fraction γ of her money, γ(mj þ γmi), to
agent i, the system does not return to the original
conﬁguration [mi, mj]. As emphasized by Angle
(2006), the payer pays a deterministic fraction of
his money, but the receiver receives a random
amount from a random agent, so their roles are
not interchangeable. Because the proportional rule
typically violates the time-reversal symmetry, the
stationary
distribution
P(m)
in
multiplicative
models is typically not exactly exponential.
(However, when Δm is a fraction of the total
money mi þ mj of the two agents, the model is
time-reversible and has an exponential distribution,
as discussed in section “The Boltzmann-Gibbs Dis-
tribution of Money.”) Making the transfer depen-
dent on the money balance of the payer effectively
introduces a Maxwell’s demon into the model. That
is why the stationary distribution is not exponen-
tial, and, thus, does not maximize entropy (4).
Another view on the time-reversal symmetry in
economic dynamics is presented in Ao (2007).
These examples show that the Boltzmann-
Gibbs distribution does not hold for any conser-
vative model. However, it is universal in a limited
sense. For a broad class of models that have time-
reversal symmetry, the stationary distribution is
exponential and does not depend on the details of
the model. Conversely, when the time-reversal
symmetry is broken, the distribution may depend
on the details of the model. The difference
between these two classes of models may be
rather subtle. Deviations from the Boltzmann-
Gibbs law may occur only if the transition rates
f in (13) explicitly depend on the agent’s money
m or m0 in an asymmetric manner. Drăgulescu and
Yakovenko (2000) performed a computer simula-
tion where the direction of payment was randomly
selected in advance for every pair of agents (i, j). In
this case, money ﬂows along directed links
between the agents: i ! j ! k, and the time-
reversal symmetry is strongly violated. This
model is closer to the real economy, where one
typically receives money from an employer and
pays it to a grocery store. Nevertheless, the
Boltzmann-Gibbs distribution was found in this
model, because the transition rates f do not explic-
itly depend on m and m0 and do not violate (13).
646
Statistical Mechanics Approach to Econophysics

In the absence of detailed knowledge of real
microscopic dynamics of economic exchanges,
the
semiuniversal
Boltzmann-Gibbs
distribu-
tion (7) is a natural starting point. Moreover, the
assumption of Drăgulescu and Yakovenko (2000)
that agents pay the same prices Δm for the same
products, independent of their money balances m,
seems very appropriate for the modern anony-
mous economy, especially for purchases over the
Internet. There is no particular empirical evidence
for the proportional rules (8) or (11). However, the
difference between the additive (7) and multipli-
cative (9) distributions may be not so crucial after
all. From the mathematical point of view, the
difference is in the implementation of the bound-
ary condition at m ¼ 0. In the additive models of
section “The Boltzmann-Gibbs Distribution of
Money,” there is a sharp cutoff of P(m) at m ¼ 0.
In the multiplicative models of section “Propor-
tional Money Transfers and Saving Propensity,”
the balance of an agent never reaches m ¼ 0, so
P(m) vanishes at m ! 0 in a power-law manner.
At the same time, P(m) decreases exponentially
for large m for both models.
By further modifying the rules of money trans-
fer and introducing more parameters in the
models, one can obtain even more complicated
distributions (Scafetta and West 2007). However,
one can argue that parsimony is the virtue of a
good mathematical model, not the abundance of
additional assumptions and parameters, whose
correspondence to reality is hard to verify.
Statistical Mechanics of Wealth
Distribution
In the econophysics literature on exchange models,
the terms “money” and “wealth” are often used
interchangeably; however, economists emphasize
the difference between these two concepts. In this
section, we review the models of wealth distribu-
tion, as opposed to money distribution.
Models with a Conserved Commodity
What is the difference between money and wealth?
One can argue (Drăgulescu and Yakovenko 2000)
that wealth wi is equal to money mi plus the other
property that an agent i has. The latter may include
durable material property, such as houses and cars,
and ﬁnancial instruments, such as stocks, bonds,
and options. Money (paper cash, bank accounts) is
generally liquid and countable. However, the other
property is not immediately liquid and has to be
sold ﬁrst (converted into money) to be used for
other purchases. In order to estimate the monetary
value of property, one needs to know the price p. In
the simplest model, let us consider just one type of
property, say, stocks s. Then the wealth of an agent
i is given by the formula
wi ¼ mi þ psi:
ð14Þ
It is assumed that the price p is common for all
agents and is established by some kind of market
process, such as an auction, and may change
in time.
It is reasonable to start with a model where
both the total money M ¼ P
i
mi and the total
stock S ¼ P
i
si are conserved (Chakraborti et al.
2001; Chatterjee and Chakrabarti 2006; Ausloos
and Pekalski 2007). The agents pay money to buy
stock and sell stock to get money, and so
on. Although M and S are conserved, the total
wealth W ¼ P
i
wi
is generally not conserved,
because of the price ﬂuctuation (Chatterjee and
Chakrabarti 2006) in (14). This is an important
difference from the money transfer models of
section “Statistical Mechanics of Money Distribu-
tion.” Here the wealth wi of an agent i, not partic-
ipating in any transactions, may change when
transactions between other agents establish a
new price p. Moreover, the wealth wi of an agent
i does not change after a transaction with an agent
j. Indeed, in exchange for paying money Δm,
agent i receives the stock Δs ¼ Δm/p, so her
total wealth (14) remains the same. In principle,
the agent can instantaneously sell the stock back at
the same price and recover the money paid. If the
price p never changes, then the wealth wi of each
agent remains constant, despite transfers of
money and stock between agents.
We see that redistribution of wealth in this
model is directly related to price ﬂuctuations.
Statistical Mechanics Approach to Econophysics
647

One mathematical model of this process was stud-
ied in Silver et al. (2002). In this model, the agents
randomly change preferences for the fraction of
their wealth invested in stocks. As a result, some
agents offer stock for sale and some want to buy
it. The price p is determined from the market-
clearing auction matching supply and demand. Sil-
ver et al. (Silver et al. 2002) demonstrated in com-
puter simulations and proved analytically using the
theory of Markov processes that the stationary dis-
tribution P(w) of wealth w in this model is given by
the Gamma distribution, as in (9). Various modiﬁ-
cations of this model (Lux 2005), such as introduc-
ing monopolistic coalitions, do not change this
result signiﬁcantly, which shows the robustness of
the Gamma distribution. For models with a con-
served commodity, Chatterjee and Chakrabarti
(2006) found the Gamma distribution for a ﬁxed
saving propensity and a power law tail for a dis-
tributed saving propensity.
Another model with conserved money and
stock was studied in Raberto et al. (2003) for an
artiﬁcial stock market where traders follow differ-
ent investment strategies: random, momentum,
contrarian, and fundamentalist. Wealth distribu-
tion in the model with random traders was found
have a power-law tail P(w) ~ 1/w2 for large w.
However, unlike in most other simulation, where
all agents initially have equal balances, here the
initial money and stock balances of the agents
were randomly populated according to a power
law with the same exponent. This raises the ques-
tion whether the observed power-law distribution
of wealth is an artifact of the initial conditions,
because equilibrization of the upper tail may take
a very long simulation time.
Models with Stochastic Growth of Wealth
Although the total wealth W is not exactly con-
served in the models considered in section
“Models
with
a
Conserved
Commodity,”
W nevertheless remains constant on average,
because the total money M and stock S are con-
served. A different model for wealth distribution
was proposed in Bouchaud and Mézard (2000). In
this model, time evolution of the wealth wi of an
agent i is given by the stochastic differential
equation
dwi
dt ¼ i tð Þwi þ
X
j 6¼i
ð
Þ
Jijw j 
X
j 6¼i
ð
Þ
Jjiwi,
ð15Þ
where i(t) is a Gaussian random variable with
mean hi and variance 2s2. This variable repre-
sents growth or loss of wealth of an agent due to
investment in stock market. The last two terms
describe transfer of wealth between different
agents, which is taken to be proportional to the
wealth of the payers with the coefﬁcients Jij. So,
the model (15) is multiplicative and invariant
under the scale transformation wi ! Zwi. For
simplicity, the exchange fractions are taken to be
the same for all agents: Jij ¼ J/N for all i 6¼ j,
where N is the total number of agents. In this case,
the last two terms in (15) can be written as J(hwi 
wi), where w
h i ¼ P
i
wi=N is the average wealth
per agent. This case represents a “mean-ﬁeld”
model, where all agents feel the same environ-
ment. It can be easily shown that the average
wealth increases in time as w
h it ¼ w
h i0e

h iþs2
ð
Þt.
Then, it makes more sense to consider the relative
wealth ewi ¼ wi= w
h it. Equation (15) for this vari-
able becomes
dewi
dt ¼ i tð Þ  
h i  s2

ewi þ J 1  ewi
ð
Þ: ð16Þ
The probability distribution P ew, t
ð
Þ for the
stochastic differential Eq. (16) is governed by
the Fokker-Planck equation:
@P
@t ¼ @ J ew1
ð
Þþs2 ew
½
P
@ ew
þs2 @
@ ew
ew@ ewP
ð
Þ
@ ew


:
ð17Þ
The stationary solution (@P/@t ¼ 0) of this
equation is given by the following formula:
P ew
ð Þ ¼ c e
J
s2 ~w
ew
2þJ
s2 :
ð18Þ
The distribution (18) is quite different from the
Boltzmann-Gibbs (7) and Gamma (9) distribu-
tions. Equation (18) has a power-law tail at large
ew and a sharp cutoff at small ew. Equation (15) is a
version of the generalized Lotka-Volterra model,
648
Statistical Mechanics Approach to Econophysics

and the stationary distribution (18) was also
obtained in Solomon and Richmond (2001,
2002). The model was generalized to include neg-
ative wealth in Huang (2004).
Bouchaud and Mézard (2000) used the mean-
ﬁeld approach. A similar result was found for a
model with pairwise interaction between agents in
Slanina (2004). In this model, wealth is trans-
ferred between the agents using the proportional
rule (8). In addition, the wealth of the agents
increases by the factor 1 þ ζ in each transaction.
This factor is supposed to reﬂect creation of
wealth in economic interactions. Because the
total wealth in the system increases, it makes
sense to consider the distribution of relative
wealth P ew
ð Þ. In the limit of continuous trading,
Slanina (2004) found the same stationary distri-
bution (18). This result was reproduced using a
mathematically more involved treatment of this
model in Cordier et al. (2005). Numerical simula-
tions of the models with stochastic noise Z in
Scafetta et al. (2004a, b) also found a power-law
tail for large w.
Let us contrast the models discussed in section
“Models with a Conserved Commodity” and
“Models with Stochastic Growth of Wealth.” In
the former case, where money and commodity are
conserved and wealth does not grow, the distribu-
tion of wealth is given by the Gamma distribution
with an exponential tail for large w. In the latter
models, wealth grows in time exponentially, and
the distribution of relative wealth has a power-law
tail for large ew . These results suggest that the
presence of a power-law tail is a nonequilibrium
effect that requires constant growth or inﬂation of
the economy, but disappears for a closed system
with conservation laws.
Reviews of the models discussed were also
given in Richmond et al. (2006a, b). Because of
lack of space, we omit discussion of models with
wealth condensation (Bouchaud and Mézard
2000; Ispolatov et al. 1998; Burda et al. 2002;
Pianegonda et al. 2003; Braun 2006), where a
few agents accumulate a ﬁnite fraction of the
total wealth, and studies of wealth distribution
on networks (Coelho et al. 2005; Iglesias et al.
2003; Di Matteo et al. 2004; Hu et al. 2007). Here
we
discuss
the
models
with
long-range
interaction,
where
any
agent
can
exchange
money and wealth with any other agent. A local
model, where agents trade only with the nearest
neighbors, was studied in Bak et al. (1999).
Empirical Data on Money and Wealth
Distributions
It would be very interesting to compare theoretical
results for money and wealth distributions in var-
ious models with empirical data. Unfortunately,
such empirical data are difﬁcult to ﬁnd. Unlike
income, which is discussed in section “Data and
Models for Income Distribution,” wealth is not
routinely reported by the majority of individuals
to the government. However, in many countries,
when a person dies, all assets must be reported for
the purpose of inheritance tax. So, in principle,
there exist good statistics of wealth distribution
among dead people, which, of course, is different
from the wealth distribution among living people.
Using an adjustment procedure based on the age,
gender, and other characteristics of the deceased,
the
UK
tax
agency,
the
Inland
Revenue,
reconstructed the wealth distribution of the
whole population of the UK (Revenue and
Customs 2003). Figure 5 shows the UK data for
1996
reproduced
from
Drăgulescu
and
Yakovenko (2001a). The ﬁgure shows the cumu-
lative probability C w
ð Þ ¼
Ð 1
w P w0
ð
Þdw0 as a func-
tion of the personal net wealth w, which is
composed of assets (cash, stocks, property, house-
hold goods, etc.) and liabilities (mortgages and
other debts). Because statistical data are usually
reported at nonuniform intervals of w, it is more
practical to plot the cumulative probability distri-
bution C(w) rather than its derivative, the proba-
bility density P(w). Fortunately, when P(w) is an
exponential or a power-law function, then C(w) is
also an exponential or a power-law function.
The cumulative probability distribution in
Fig. 5 is plotted on a log-log scale, where a
straight line represents a power-law dependence.
The ﬁgure shows that the distribution follows a
power law C(w) / 1/wα with exponent α ¼ 1.9 for
wealth greater than about £100,000. The inset in
Fig. 5 shows the data on log-linear scale, where
the straight line represents an exponential depen-
dence. We observe that below £100,000 the data
Statistical Mechanics Approach to Econophysics
649

are well ﬁtted by the exponential distribution
C(w) / exp (w/Tw) with the effective “wealth
temperature” Tw ¼ £60, 000 (which corresponds
to the median wealth of £41,000). So, the distri-
bution of wealth is characterized by the Pareto
power law in the upper tail of the distribution
and the exponential Boltzmann-Gibbs law in the
lower part of the distribution for the great majority
(about 90%) of the population. Similar results are
found for the distribution of income, as discussed
in section “Data and Models for Income Distribu-
tion.” One may speculate that the wealth distribu-
tion in the lower part is dominated by distribution
of money, because the corresponding people do
not have other signiﬁcant assets, so the results of
section “Statistical Mechanics of Money Distribu-
tion” give the Boltzmann-Gibbs law. On the other
hand, the upper tail of the wealth distribution is
dominated by investment assess, where the results
of section “Models with Stochastic Growth of
Wealth” give the Pareto law. The power law was
studied by many researchers for the upper-tail
data, such as the Forbes list of the 400 richest
people (Klass et al. 2007; Sinha 2006), but much
less attention was paid to the lower part of the
wealth
distribution.
Curiously,
Abdul-Magd
(2002) found that the wealth distribution in
ancient Egyptian society was consistent with (18).
For direct comparison with the results of
section “Statistical Mechanics of Money Distribu-
tion,” it would be very interesting to ﬁnd data on
the distribution of money, as opposed to the
distribution of wealth. Making a reasonable
assumption that most people keep most of their
money in banks, one can approximate the distri-
bution of money by the distribution of balances
on bank accounts. (Balances on all types of bank
accounts, such as checking, saving, and money
manager, associated with the same person should
be added up.) Despite imperfections (people
may have accounts with different banks or not
keep all their money in banks), the distribution of
balances on bank accounts would give valuable
information about the distribution of money. The
data for a big enough bank would be representative
of the distribution in the whole economy. Unfortu-
nately, it has not been possible to obtain such data
thus far, even though it would be completely anon-
ymous and not compromise the privacy of bank
clients.
Measuring
the
probability
distribution
of
money would be very useful, because it deter-
mines how much people can, in principle, spend
on purchases without going into debt. This is
different from the distribution of wealth, where
the property component, such as house, car, or
retirement investment, is effectively locked up
and, in most cases, is not easily available for
consumer spending. So, although wealth distribu-
tion may reﬂect the distribution of economic
power, the distribution of money is more relevant
for consumption. Money distribution can be
Statistical Mechanics
Approach
to Econophysics,
Fig. 5 Cumulative
probability distribution of
net wealth in the UK shown
on log-log and log-linear
(inset) scales. Points
represent the data from the
Inland Revenue, and solid
lines are ﬁts to the
exponential (Boltzmann-
Gibbs) and power (Pareto)
laws. (Reproduced from
(Drăgulescu and
Yakovenko 2001a))
650
Statistical Mechanics Approach to Econophysics

useful for determining prices that maximize reve-
nue
of
a
manufacturer
(Drăgulescu
and
Yakovenko 2000). If a price p is set too high,
few people can afford it, and, if a price is too
low, the sales revenue is small, so the optimal
price must be in-between. The fraction of the
population who can afford to pay the price p is
given by the cumulative probability C( p), so the
total sales revenue is proportional to pC( p). For
the exponential distribution C( p) ¼ exp (p/Tm),
the maximal revenue is achieved at p ¼ Tm, that is,
at the optimal price equal to the average amount of
money per person (Drăgulescu and Yakovenko
2000). Indeed, the prices of mass-market con-
sumer products, such as computers, electronics
goods, and appliances, remain stable for many
years at a level determined by their affordability
to the population, whereas the technical parame-
ters of these products at the same price level
improve dramatically owing to technological
progress.
Data and Models for Income Distribution
In contrast to money and wealth distributions, a
lot more empirical data are available for the dis-
tribution of income r from tax agencies and pop-
ulation surveys. In this section, we ﬁrst present
empirical data on income distribution and then
discuss theoretical models.
Empirical Data on Income Distribution
Empirical studies of income distribution have a
long history in the economics literature (Kakwani
1980;
Champernowne
and
Cowell
1998;
Atkinson and Bourguignon 2000). Following the
work by Pareto (1897), much attention was
focused on the power-law upper tail of the income
distribution and less on the lower part. In contrast
to more complicated functions discussed in the
literature, Drăgulescu and Yakovenko (2001b)
introduced a new idea by demonstrating that the
lower part of income distribution can be well ﬁtted
with a simple exponential function P(r) ¼
c exp (r/Tr) characterized by just one parameter,
the “income temperature” Tr. Then it was recog-
nized that the whole income distribution can be
ﬁtted by an exponential function in the lower part
and a power-law function in the upper part
(Drăgulescu and Yakovenko 2001a, 2003), as
shown in Fig. 6. The straight line on the log-linear
scale in the inset of Fig. 6 demonstrates the expo-
nential Boltzmann-Gibbs law, and the straight line
on the log-log scale in the main panel illustrates
the Pareto power law. The fact that income distri-
bution consists of two distinct parts reveals the
two-class
structure
of
American
society
(Yakovenko
and
Silva
2005;
Silva
and
Yakovenko 2005). Coexistence of the exponential
and power-law distributions is known in plasma
physics and astrophysics, where they are called
the
“thermal”
and
“superthermal”
parts
(Hasegawa et al. 1985; Desai et al. 2003; Collier
2004). The boundary between the lower and upper
classes can be deﬁned as the intersection point of
the exponential and power-law ﬁts in Fig. 6. For
1997, the annual income separating the two clas-
ses was about $120,000. About 3% of the popu-
lation belonged to the upper class, and 97%
belonged to the lower class.
Silva and Yakovenko (2005) studied time evo-
lution of income distribution in the USA during
1983–2001 on the basis of data from the Internal
Revenue Service (IRS), the government tax
agency. The structure of the income distribution
was found to be qualitatively the same for all
years, as shown in Fig. 7. The average income in
nominal dollars approximately doubled during this
time interval. So, the horizontal axis in Fig. 7
shows the normalized income r/Tr, where the
“income temperature” Tr was obtained by ﬁtting
of the exponential part of the distribution for each
year. The values of Tr are shown in Fig. 7. The plots
for the 1980s and 1990s are shifted vertically for
clarity. We observe that the data points in the lower-
income part of the distribution collapse on the same
exponential curve for all years. This demonstrates
that the shape of the income distribution for the
lower class is extremely stable and does not change
in time, despite the gradual increase of the average
income in nominal dollars. This observation sug-
gests that the lower-class distribution is in statisti-
cal, “thermal” equilibrium.
On the other hand, Fig. 7 shows that the
income distribution in the upper class does not
Statistical Mechanics Approach to Econophysics
651

rescale and signiﬁcantly changes in time. Silva
and Yakovenko (2005) found that the exponent α
of the power law C(r) / 1/rα decreased from 1.8 in
1983 to 1.4 in 2000. This means that the upper tail
became “fatter.” Another useful parameter is the
total income of the upper class as the fraction f of
the total income in the system. The fraction
f increased from 4% in 1983 to 20% in 2000
Statistical Mechanics
Approach
to Econophysics,
Fig. 6 Cumulative
probability distribution of
tax returns for the USA in
1997 shown on log-log and
log-linear (inset) scales.
Points represent the Internal
Revenue Service (IRS)
data, and solid lines are ﬁts
to the exponential and
power-law functions.
(Reproduced from
(Drăgulescu and
Yakovenko 2003))
Statistical Mechanics Approach to Econophysics,
Fig. 7 Cumulative probability distribution of tax returns
plotted on log-log scale versus r/Tr (the annual income
r normalized by the average income Tr in the exponential
part of the distribution). The IRS data points are for
1983–2001, and the columns of numbers give the values
of Tr for the corresponding years. (Reproduced from Silva
and Yakovenko (2005))
652
Statistical Mechanics Approach to Econophysics

(Silva and Yakovenko 2005). However, in 2001, α
increased and f decreased, indicating that the
upper tail was reduced after the stock market
crash at that time. These results indicate that the
upper tail is highly dynamical and not stationary.
It tends to swell during the stock market boom and
shrink during the bust. Similar results were found
for Japan (Souma 2001, 2002; Fujiwara et al.
2003; Aoyama et al. 2003).
Although relative income inequality within the
lower class remains stable, the overall income
inequality in the USA has increased signiﬁcantly
as a result of the tremendous growth of the income
of the upper class. This is illustrated by the Lorenz
curve and the Gini coefﬁcient shown in Fig. 8.
The Lorenz curve (Kakwani 1980) is a standard
way of representing income distribution in the
economics literature. It is deﬁned in terms of two
coordinates x(r) and y(r) depending on a parame-
ter r:
x rð Þ ¼
ðr
0
P r0
ð Þdr0,
y rð Þ ¼
Ð r
0r0P r0
ð Þdr0
Ð 1
0 r0P r0
ð Þdr0 :
ð19Þ
The horizontal coordinate x(r) is the fraction of
the population with income below r, and the ver-
tical coordinate y(r) is the fraction of the income
this population accounts for. As r changes from
0 to 1, x and y change from 0 to 1 and paramet-
rically deﬁne a curve in the (x, y)-plane.
Figure 8 shows the data points for the Lorenz
curves in 1983 and 2000, as computed by the IRS
(Strudler et al. 2003). Drăgulescu and Yakovenko
(2001b) analytically derived the Lorenz curve
formula y ¼ x þ (1  x) ln(1  x) for a purely
exponential distribution P(r) ¼ c exp(r/Tr). This
formula is shown by the red line in Fig. 8 and
describes the 1983 data reasonably well. How-
ever, for 2000, it is essential to take into account
the fraction f of income in the upper tail, which
modiﬁes
the
Lorenz
formula
as
follows
(Drăgulescu and Yakovenko 2003; Yakovenko
and Silva 2005; Silva and Yakovenko 2005):
y ¼ 1  f
ð
Þ x þ 1  x
ð
Þ ln 1  x
ð
Þ
½

þ fY x  1
ð
Þ:
ð20Þ
The last term in (20) represent the vertical jump
of the Lorenz curve at x ¼ 1, where a very small
percentage of the population in the upper class
100%
90
80
70
40
1980
4985
1990
US, IRS data for 1983 and 2000 
Gini from IRS datat
Gini=(1+f)/2
1995
2000
Year
20
10
00
10
20
30
Cumulative percent of tax returns
Cumulative percent of income
40
50
60
70
80
2000
1983
19%
4%
90
100%
30
60
50
Statistical Mechanics
Approach
to Econophysics,
Fig. 8 Lorenz plots for
income distribution in 1983
and 2000. The data points
are from the IRS (Strudler
et al. 2003), and the
theoretical curves
represent (20) with f from
Fig. 7. Inset: The closed
circles are the IRS data
113 for the Gini coefﬁcient
G, and the open circles
show the theoretical
formula G ¼ (1 þ f )/2.
(Reproduced from Silva
and Yakovenko (2005))
Statistical Mechanics Approach to Econophysics
653

accounts for a substantial fraction f of the total
income. The blue curve representing (20) ﬁts the
2000 data in Fig. 8 very well.
The deviation of the Lorenz curve from the
straight diagonal line in Fig. 8 is a certain measure
of income inequality. Indeed, if everybody had the
same income, the Lorenz curve would be a diag-
onal line, because the fraction of income would be
proportional to the fraction of the population. The
standard measure of income inequality is the
so-called Gini coefﬁcient 0  G  1, which is
deﬁned as the area between the Lorenz curve and
the diagonal line, divided by the area of the trian-
gle beneath the diagonal line (Kakwani 1980).
Time evolution of the Gini coefﬁcient, as com-
puted by the IRS (Strudler et al. 2003), is shown in
the inset of Fig. 8. Drăgulescu and Yakovenko
(2001b) derived analytically the result that G ¼
1/2 for a purely exponential distribution. In the
ﬁrst approximation, the values of G shown in the
inset of Fig. 8 are indeed close to the theoretical
value 1/2. If we take into account the upper tail
using (20), the formula for the Gini coefﬁcient
becomes G ¼ (1 þ f )/2 (Silva and Yakovenko
2005). The inset in Fig. 8 shows that this formula
is a very good ﬁt to the IRS data for the 1990s
using the values of f deduced from Fig. 7. The
values G < 1/2 for the 1980s cannot be captured
by this formula, because the Lorenz data points
are slightly above the theoretical curve for 1983 in
Fig. 8. Overall, we observe that income inequality
has been increasing for the last 20 years, because
of swelling of the Pareto tail, but decreased in
2001 after the stock market crash.
Thus far we have discussed the distribution of
individual income. An interesting related question
is the distribution P2(r) of family income r ¼ r1 þ
r2, where r1 and r2 are the incomes of spouses. If
individual incomes are distributed exponentially
P(r) / exp(r/Tr), then
P2 rð Þ ¼
ðr
0
dr0P r0
ð ÞP r  r0
ð
Þ
¼ cr exp r=Tr
ð
Þ,
ð21Þ
where c is a normalization constant. Figure 9
shows that (21) is in good agreement with the
family income distribution data from the US Cen-
sus Bureau (Drăgulescu and Yakovenko 2001b).
In (21), we assumed that incomes of spouses are
uncorrelated. This simple approximation is indeed
supported by the scatter plot of incomes of
spouses shown in Fig. 10. Each family is
represented in this plot by two points (r1, r2) and
(r2, r1) for symmetry. We observe that the density
of points is approximately constant along the lines
of constant family income r1 þ r2 ¼ const, which
indicates that incomes of spouses are approxi-
mately uncorrelated. There is no signiﬁcant
Statistical Mechanics
Approach
to Econophysics,
Fig. 9 Probability
distribution of family
income for families with
two adults (US Census
Bureau data). Solid line: ﬁt
to (21). (Reproduced from
Drăgulescu and Yakovenko
(2001b))
654
Statistical Mechanics Approach to Econophysics

clustering of points along the diagonal r1 ¼ r2,
that is, no strong positive correlation of spouses’
incomes.
The Gini coefﬁcient for the family income dis-
tribution (21) was calculated in Drăgulescu and
Yakovenko (2001b) as G ¼ 3/8 ¼ 37.5%. Figure 11
shows the Lorenz quintiles and the Gini coefﬁcient
for 1947–1994 plotted from the US Census Bureau
data. The solid line, representing the Lorenz curve
calculated from (21), is in good agreement with the
data. The systematic deviation for the top 5% of
earners results from the upper tail, which has a less
pronounced effect on family income than on indi-
vidual income, because of income averaging in the
family. The Gini coefﬁcient, shown in the inset of
Fig. 11, is close to the calculated value of 37.5%.
Moreover, the average G for the developed capital-
ist countries of North America and western Europe,
as determined by the World Bank (Drăgulescu and
Yakovenko 2003), is also close to the calculated
value of 37.5%.
Income distribution has been examined in
econophysics
papers
for
different
countries:
Japan
(Ferrero
2004;
Souma
2001,
2002;
Fujiwara et al. 2003; Aoyama et al. 2003; Souma
and Nirei 2005, Nirei and Souma 2007; Ferrero
2005), Germany (Clementi and Gallegati 2005a;
Clementi et al. 2007), the UK (Ferrero 2004,
2005; Richmond et al. 2006b; Clementi and
Gallegati 2005a; Clementi et al. 2007), Italy
(Clementi et al. 2007; Clementi and Gallegati
2005b;
Clementi
et
al.
2006),
the
USA
(Clementi and Gallegati 2005a; Rawlings et al.
2004), India (Sinha 2006), Australia (Di Matteo
et al. 2004; Clementi et al. 2006; Banerjee et al.
2006), and New Zealand (Ferrero 2004, 2005).
The distributions are qualitatively similar to the
results presented in this section. The upper tail
follows a power law and comprises a small frac-
tion of the population. To ﬁt the lower part of the
distribution, the use of exponential, Gamma, and
log-normal distributions was reported in different
papers. Unfortunately, income distribution is
often reported by statistical agencies for house-
holds, so it is difﬁcult to differentiate between
one-earner and two-earner income distributions.
Some papers reported the use of interpolating
functions with different asymptotic behavior for
low and high incomes, such as the Tsallis function
(Ferrero 2005) and the Kaniadakis function
(Clementi et al. 2007). However, the transition
between the lower and upper classes is not smooth
for the US data shown in Figs. 6 and 7, so such
functions would not be useful in this case. The
Statistical Mechanics
Approach
to Econophysics,
Fig. 10 Scatter plot of the
spouses’ incomes (r1, r2)
and (r2, r1) based on the
data from the Panel Study of
Income Dynamics (PSID).
(Reproduced from
Drăgulescu and Yakovenko
(2003))
Statistical Mechanics Approach to Econophysics
655

special case is income distribution in Argentina
during the economic crisis, which shows a time-
dependent bimodal shape with two peaks (Ferrero
2005).
Theoretical Models of Income Distribution
Having examined the empirical data on income
distribution,
let
us
now
discuss
theoretical
models. Income ri is the inﬂux of money per unit
time to an agent i. If the money balance mi is
analogous to energy, then the income ri would
be analogous to power, which is the energy ﬂux
per unit time. So, one should conceptually distin-
guish between the distributions of money and
income. While money is regularly transferred
from one agent to another in pairwise transactions,
it is not typical for agents to trade portions of their
income. Nevertheless, indirect transfer of income
may occur when one employee is promoted and
another demoted, while the total annual budget is
ﬁxed, or when one company gets a contract,
whereas another one loses it, etc. A reasonable
approach, which has a long tradition in the eco-
nomics literature (Gibrat 1931; Kalecki 1945;
Champernowne 1953), is to treat individual
income r as a stochastic process and study its
probability distribution. In general, one can
study a Markov process generated by a matrix of
transitions from one income to another. In the case
where income r changes by a small amount Δr
over a time period Δt, the Markov process can be
treated as income diffusion . Then one can apply
the general Fokker-Planck equation (Lifshitz and
Pitaevskii 1981) to describe evolution in time t of
the income distribution function P(r, t) (Silva and
Yakovenko 2005):
@P
@t ¼ @
@r AP þ @ BP
ð
Þ
@r

	
,
A ¼  Dr
h
i
Dt , B ¼
Dr
ð
Þ2
D
E
2Dt
:
ð22Þ
The coefﬁcients A and B in (22) are determined
by the ﬁrst and second moments of income
changes per unit time. The stationary solution
@tP ¼ 0 of (22) obeys the following equation
with the general solution:
@ BP
ð
Þ
@r
¼ AP,
P rð Þ ¼
c
B rð Þ exp

ðr A r0
ð Þ
B r0
ð Þ dr0


:
ð23Þ
For the lower part of the distribution, it is
reasonable to assume that Δr is independent of r,
Statistical Mechanics
Approach
to Econophysics,
Fig. 11 Lorenz plot for
family income calculated
from (21), compared with
the US Census data points.
Inset: The US Census data
points for the Gini
coefﬁcient for families,
compared with the
theoretically calculated
value 3/8¼37.5%.
(Reproduced from
Drăgulescu and Yakovenko
(2001b))
656
Statistical Mechanics Approach to Econophysics

that is, the changes of income are independent of
income itself. This process is called additive dif-
fusion (Silva and Yakovenko 2005). In this case,
the coefﬁcients in (22) are constants A0 and B0.
Then (23) gives the exponential distribution
P(r) /
exp (r/Tr), with the effective income
temperatureTr ¼ B0/A0. Notice that a meaningful
stationary solution (23) requires that A > 0, that is,
hΔri < 0. The coincidence of this result with the
Boltzmann-Gibbs exponential law (1) and (7) is
not accidental. Indeed, instead of considering
pairwise interaction between particles, one can
derive
(1)
by
considering
energy
transfers
between a particle and a big reservoir, as long as
the transfer process is “additive” and does not
involve a Maxwell-demon-like discrimination.
Stochastic income ﬂuctuations are described by
a similar process. So, although money and
income are different concepts, they may have
similar distributions, because they are governed
by similar mathematical principles. It was shown
explicitly in Drăgulescu and Yakovenko (2000),
Slanina (2004), and Cordier et al. (2005) that the
models of pairwise money transfer can be
described in a certain limit by the Fokker-Planck
equation.
On the other hand, for the upper tail of the
income distribution, it is reasonable to expect
that Δr / r, that is, income changes are propor-
tional to income itself. This is known as the pro-
portionality principle of Gibrat (1931), and the
process is called multiplicative diffusion (Silva
and Yakovenko 2005). In this case, A ¼ ar and
B ¼ br2, and (23) gives the power-law distribution
P(r) / 1/rα+1, with α ¼ 1 þ a/b.
Generally, lower-class income comes from
wages and salaries, where the additive process is
appropriate, whereas upper-class income comes
from bonuses, investments, and capital gains, cal-
culated in percentages, where the multiplicative
process applies (Milaković 2005). However, the
additive and multiplicative processes may coexist.
An employee may receive a cost-of-living rise cal-
culated in percentages (the multiplicative process)
and a merit rise calculated in dollars (the additive
process). In this case, we have A ¼ A0 þ ar and
B ¼ B0 þ br2 ¼ b r2
0 þ r2


,
where r2
0 ¼ B0=b .
Substituting these expressions into (23), we ﬁnd
P rð Þ ¼ c e

r0
Tr
ð Þ arctan
r
r0
 
1 þ
r
r0
 2

	1þa
2b :
ð24Þ
The distribution (24) interpolates between the
exponential law for low r and the power law for
high r, because either the additive or the multipli-
cative process dominates in the corresponding
limit. The crossover between the two regimes
takes place at r ~ r0, where the additive and
multiplicative contributions to B are equal. The
distribution
(24)
has
three
parameters:
the
“income temperature” Tr ¼ A0/B0, the Pareto
exponent α ¼ 1 þ a/b, and the crossover income
r0. It is a minimal model that captures the salient
features of the empirical income distribution
shown in Fig. 6. A mathematically similar, but
more economically oriented model was proposed
in Souma and Nirei (2005) and Nirei and Souma
(2007), where labor income and asset accumula-
tion are described by the additive and multiplica-
tive
processes
correspondingly.
A
general
stochastic process with additive and multiplica-
tive noise was studied numerically in Takayasu
et al. (1997), but the stationary distribution was
not derived analytically. A similar process with
discrete time increments was studied by Kesten
(1973). Recently, a formula similar to (24) was
obtained in Fiaschi and Marsili (2007).
To verify the multiplicative and additive
hypotheses empirically, it is necessary to have
data on income mobility, that is, the income
changes Δr of the same people from one year to
another. The distribution of income changes
P(Δr| r) conditional on income r is generally
not
available
publicly,
although
it
can
be
reconstructed by researchers at the tax agencies.
Nevertheless, the multiplicative hypothesis for the
upper class was quantitatively veriﬁed in Fujiwara
et al. (2003) and Aoyama et al. (2003) for Japan,
where tax identiﬁcation data is published for the
top taxpayers.
The power-law distribution is meaningful
only when it is limited to high enough incomes
r > r0. If all incomes r from 0 to 1 follow a
purely multiplicative process, then one can
change to a logarithmic variable x ¼ ln (r/r)
Statistical Mechanics Approach to Econophysics
657

in (22) and show that it gives a Gaussian time-
dependent distribution Pt(x) / exp (x2/2s2t)
for x, that is, the log-normal distribution for r,
also known as the Gibrat distribution (Gibrat
1931). However, the width of this distribution
increases linearly in time, so the distribution is
not stationary. This was pointed out by Kalecki
(1945) a long time ago, but the log-normal dis-
tribution is still widely used for ﬁtting income
distribution, despite this fundamental logical
ﬂaw in its justiﬁcation. In a classic paper,
Champernowne (1953) showed that a multipli-
cative process gives a stationary power-law dis-
tribution when a boundary condition is imposed
at r0 6¼ 0. Later, this result was rediscovered by
econophysicists
(Levy
and
Solomon
1996;
Sornette and Cont 1997). In our (24), the expo-
nential distribution of the lower class effectively
provides such a boundary condition for the
power law of the upper class. Notice also
that (24) reduces to (18) in the limit r0 ! 0,
which
corresponds
to
purely
multiplicative
noise B ¼ br2.
There are alternative approaches to income
distribution in the economics literature. One of
them, proposed by Lydall (1959), involves social
hierarchy. Groups of people have leaders, who
have leaders of a higher order, and so on. The
number
of
people
decreases
geometrically
(exponentially) with the increase of the hierar-
chical level. If individual income increases by a
certain factor (i.e., multiplicatively) when mov-
ing to the next hierarchical level, then income
distribution follows a power law (Lydall 1959).
However, the original argument of Lydall can be
easily modiﬁed to produce an exponential distri-
bution. If individual income increases by a cer-
tain amount, that is, income increases linearly
with the hierarchical level, then income distribu-
tion is exponential. The latter process seems to be
more realistic for moderate incomes below
$ 100,000. A similar scenario is the Bernoulli
trials (Feller 1966), where individuals have a
constant probability of increasing their income
by a ﬁxed amount. We see that the deterministic
hierarchical models and the stochastic models of
additive and multiplicative income mobility rep-
resent essentially the same ideas.
Other Applications of Statistical Physics
Statistical physics was applied to a number of
other subjects in economics. Because of lack of
space, only two such topics are brieﬂy discussed
in this section.
Economic Temperatures in Different
Countries
As discussed in section “Empirical Data on
Money and Wealth Distributions” and “Empirical
Data on Income Distribution,” the distributions of
money, wealth, and income are often described by
exponential functions for the majority of the pop-
ulation. These exponential distributions are char-
acterized by the parameters Tm, Tw, and Tr, which
are mathematically analogous to temperature in
the Boltzmann-Gibbs distribution (1). The values
of these parameters, extracted from the ﬁts of the
empirical data, are generally different for different
countries, i.e., different countries have different
economic
“temperatures.”
For
example,
Drăgulescu and Yakovenko (2001a) found that
the US income temperature was 1.9 times higher
than the UK income temperature in 1998 (using
the exchange rate of dollars to pounds at that
time). Also, there was 25% variation between
income temperatures of different states within the
USA (Drăgulescu and Yakovenko 2001a).
In physics, a difference of temperatures allows
one to set up a thermal machine. In was argued in
Drăgulescu and Yakovenko (2000) that the differ-
ence of money or income temperatures between
different countries allows one to extract proﬁt in
international trade. Indeed, as discussed at the end
of section “Empirical Data on Money and Wealth
Distributions,” the prices of goods should be com-
mensurate with money or income temperature ,
because otherwise people cannot afford to buy
those goods. So, an international trading company
can buy goods at a low price T1 in a “low-
temperature” country and sell them at a high
price T2 in a “high-temperature” country. The
difference of prices T2  T1 would be the proﬁt
of the trading company. In this process, money
(the analog of energy) ﬂows from the “high-
temperature” to the “low-temperature” country,
in
agreement
with
the
second
law
of
658
Statistical Mechanics Approach to Econophysics

thermodynamics, whereas products ﬂow in the
opposite direction. This process very much resem-
bles what is going on in the global economy now.
In this framework, the perpetual trade deﬁcit of
the USA is the consequence of the second law of
thermodynamics and the difference of tempera-
tures between the USA and “low-temperature”
countries, such as China. Similar ideas were
developed in more detail in Mimkes and Aruka
(2005) and Mimkes (2006a), including a formal
Carnot cycle for international trade.
The statistical physics approach demonstrates
that
proﬁt
originates
from
statistical
non-
equilibrium (the difference of temperatures),
which exists in the global economy. However, it
does not answer the question what is the origin of
this difference. By analogy with physics, one
would expect that the money ﬂow should reduce
the temperature difference and, eventually, lead to
equilibrization of temperatures. In physics, this
situation is known as the “thermal death of the
universe.” In a completely equilibrated global
economy, it would be impossible to make proﬁt
by exploiting differences of economic tempera-
tures between different countries. Although glob-
alization of the modern economy does show a
tendency toward equilibrization of living stan-
dards in different countries, this process is far
from straightforward, and there are many exam-
ples contrary to equilibrization. This interesting
and timely subject certainly requires further study.
Society as a Binary Alloy
In 1971, Thomas Schelling (Schelling 1971) pro-
posed the now-famous mathematical model of
segregation. He considered a lattice, where the
sites can be occupied by agents of two types, for
example, blacks and whites in the problem of
racial segregation. He showed that if the agents
have some probabilistic preference for the neigh-
bors of the same type, the system spontaneously
segregates into black and white neighborhoods.
This mathematical model is similar to the
so-called Ising model, which is a popular model
for studying phase transitions in physics. In this
model, each lattice site is occupied by a magnetic
atom, whose magnetic moment has only two pos-
sible orientations, up or down. The interaction
energy between two neighboring atoms depends
on whether their magnetic moments point in the
same or in the opposite directions. In physics
language, the segregation found by Schelling rep-
resents a phase transition in this system.
Another similar model is the binary alloy, a
mixture of two elements which attract or repel
each other. It was noticed in Mimkes (1995) that
the behavior of actual binary alloys is strikingly
similar to social segregation. In the following
papers (Mimkes 2000, 2006b), this mathematical
analogy was developed further and compared
with social data. Interesting concepts, such as the
coexistence curve between two phases and the
solubility limit, were discussed in this work. The
latter concept means that a small amount of one
substance dissolves in another up to some limit,
but phase separation (segregation) develops for
higher concentrations. Recently, similar ideas
were rediscovered in Jego and Roehner (2007),
Stauffer and Schulze (2007), and Dall’Asta et al.
(2007). The vast experience of physicists in deal-
ing with phase transitions and alloys may be help-
ful for practical applications of such models (Lim
et al. 2007).
Future Directions, Criticism, and
Conclusions
The statistical models described in this review are
quite simple. It is commonly accepted in physics
that theoretical models are not intended to be
photographic copies of reality, but rather to be
caricatures, capturing the most essential features
of a phenomenon with a minimal number of
details. With only few rules and parameters, the
models discussed in section “Statistical Mechan-
ics of Money Distribution,” “Statistical Mechan-
ics of Wealth Distribution,” and “Data and Models
for Income Distribution” reproduce spontaneous
development of stable inequality, which is present
in virtually all societies. It is amazing that the
calculated Gini coefﬁcients, G ¼ 1/2 for individ-
uals and G ¼ 3/8 for families, are actually very
close to the US income data, as shown in Figs. 8
and 11. These simple models establish a baseline
and a reference point for development of more
Statistical Mechanics Approach to Econophysics
659

sophisticated and more realistic models. Some of
these future directions are outlined below.
Future Directions
Agents with a Finite Lifespan
The models discussed in this review consider
immortal agents who live forever, like atoms.
However, humans have a ﬁnite lifespan. They
enter the economy as young people and exit at
an old age. Evolution of income and wealth as
functions of age is studied in economics using the
so-called overlapping-generations model. The
absence of the age variable was one of the criti-
cisms of econophysics by the economist Paul
Anglin (Anglin 2005). However, the drawback
of the standard overlapping-generations model is
that there is no variation of income and wealth
between agents of the same age, because it is a
representative-agent model. It would be best to
combine stochastic models with the age variable.
Also, to take into account inﬂation of average
income, (22) should be rewritten for relative
income, in the spirit of (17). These modiﬁcations
would allow one to study the effects of demo-
graphic waves, such as baby boomers, on the
distributions of income and wealth.
Agent-Based Simulations of the Two-Class
Society
The empirical data presented in section “Empiri-
cal Data on Income Distribution” show quite con-
vincingly that the US population consists of two
very distinct classes characterized by different
distribution functions. However, the theoretical
models discussed in section “Statistical Mechan-
ics of Money Distribution” and “Statistical
Mechanics of Wealth Distribution” do not pro-
duce two classes, although they do produce
broad distributions. Generally, not much attention
has been paid in the agent-based literature to sim-
ulation of two classes. One exception is Wright
(2005), in which spontaneous development of
employers and employees classes from initially
equal agents was simulated (Wright 2007). More
work
in
this
direction
would
be
certainly
desirable.
Access to Detailed Empirical Data
A great amount of statistical information is pub-
licly available on the Internet, but not for all types
of data. As discussed in section “Empirical Data
on Money and Wealth Distributions,” it would be
very interesting to obtain data on the distribution
of balances on bank accounts, which would give
information about the distribution of money
(as opposed to wealth). As discussed in section
“Theoretical Models of Income Distribution,” it
would be useful to obtain detailed data on income
mobility, to verify the additive and multiplicative
hypotheses for income dynamics. Income distri-
bution is often reported as a mix of data on indi-
vidual income and family income, when the
counting unit is a tax return (joint or single) or a
household. To have a meaningful comparison
with theoretical models, it is desirable to obtain
clean data where the counting unit is an individ-
ual. Direct collaboration with statistical agencies
would be very useful.
Economies in Transition
Inequality in developed capitalist countries is gen-
erally quite stable. The situation is very different
for former socialist countries making a transition
to a market economy. According to the World
Bank data (Drăgulescu and Yakovenko 2003),
the average Gini coefﬁcient for family income in
eastern Europe and the former Soviet Union
jumped from 25% in 1988 to 47% in 1993. The
Gini coefﬁcient in the socialist countries before
the transition was well below the equilibrium
value of 37.5% for market economies. However,
the fast collapse of socialism left these countries
out of market equilibrium and generated a much
higher inequality. One may expect that, with time,
their inequality will decrease to the equilibrium
value of 37.5%. It would be very interesting to
trace how fast this relaxation takes place. Such a
study would also verify whether the equilibrium
level of inequality is universal for all market
economies.
Relation to Physical Energy
The
analogy
between
energy
and
money
discussed in section “Conservation of Money” is
a formal mathematical analogy. However, actual
660
Statistical Mechanics Approach to Econophysics

physical energy with low entropy (typically in the
form of fossil fuel) also plays a very important
role in the modern economy, as the basis of cur-
rent human technology. In view of the looming
energy and climate crisis, it is imperative to ﬁnd
realistic ways for making a transition from the
current “disposable” economy based on “cheap”
and “unlimited” energy and natural resources to a
sustainable one. Heterogeneity of human society
is one of the important factors affecting such a
transition. Econophysics, at the intersection of
energy, entropy, economy, and statistical physics,
may play a useful role in this quest (Deﬁlla 2007).
Criticism from Economists
As econophysics is gaining popularity, some crit-
icism has appeared from economists (Anglin
2005), including those who are closely involved
with the econophysics movement (Lux 2005;
2008; Gallegati et al. 2006). This reﬂects a long-
standing tradition in economic and social sciences
of writing critiques on different schools of
thought. Much of the criticism is useful and con-
structive and is already being accommodated in
econophysics work. However, some criticism
results from misunderstanding or miscommunica-
tion between the two ﬁelds and some from signif-
icant differences in scientiﬁc philosophy. Several
insightful responses to the criticism have been
published (McCauley 2006; Richmond et al.
2006c; Rosser 2006a); see also (Stauffer 2004;
Rosser 2006b). In this section, we brieﬂy address
the issues that are directly related to the material
discussed in this review.
Awareness of Previous Economics Literature
One complaint of Anglin (2005), Lux (2005),
(2008), and Gallegati et al. (2006) is that physi-
cists are not well aware of the previous economics
literature and either rediscover known results or
ignore well-established approaches. To address
this issue, it is useful to keep in mind that science
itself is a complex system, and scientiﬁc progress
is an evolutionary process with natural selection.
The sea of scientiﬁc literature is enormous, and
nobody knows it all. Recurrent rediscovery of
regularities in the natural and social world only
conﬁrms their validity. Independent rediscovery
usually brings a different perspective, broader
applicability range, higher accuracy, and better
mathematical treatment, so there is progress even
when some overlap with previous results exists.
Physicists are grateful to economists for bringing
relevant and speciﬁc references to their attention.
Since the beginning of modern econophysics,
many old references have been uncovered and
are now routinely cited.
However, not all old references are relevant to
the new development. For example, Gallegati
et al. (2006) complained that the econophysics
literature on income distribution ignores the
so-called Kuznets hypothesis (Kuznets 1955).
The Kuznets hypothesis postulates that income
inequality ﬁrst rises during an industrial revolu-
tion and then decreases, producing an inverted-U-
shaped curve. Gallegati et al. (2006) admitted that,
to date, the large amount of literature on the
Kuznets hypothesis is inconclusive. Kuznets
(1955) mentioned that this hypothesis applies to
the period from colonial times to the 1970s; how-
ever, the empirical data for this period are sparse
and not very reliable. The econophysics literature
deals with reliable volumes of data for the second
half of the twentieth century, collected with the
introduction of computers. It is not clear what is
the deﬁnition of industrial revolution and when
exactly it starts and ends. The chain of technolog-
ical progress seems to be continuous (steam
engine, internal combustion engine, cars, plastics,
computers, Internet), so it is not clear where the
purported U-curve is supposed to be placed in
time. Thus, the Kuznets hypothesis appears to
be, in principle, unveriﬁable and unfalsiﬁable.
The original paper by Kuznets (1955) actually
does not contain any curves, but it has one table
ﬁlled with made-up, imaginary data! Kuznets
admits that he has “neither the necessary data
nor a reasonably complete theoretical model”
(p. 12 in Kuznets (1955)). So, this paper is under-
standably ignored by the econophysics commu-
nity. In fact, the data analysis for 1947–1984
shows amazing stability of income distribution
(Levy 1987), consistent with Fig. 11. The increase
of inequality in the 1990s resulted from growth of
Statistical Mechanics Approach to Econophysics
661

the upper class relative to the lower class, but the
relative inequality within the lower class remains
very stable, as shown in Fig. 7.
Reliance on Visual Data Analysis
Another complaint of Gallegati et al. (2006) is that
econophysicists favor graphic analysis of data
over the formal and “rigorous” testing prescribed
by mathematical statistics, as favored by econo-
mists. This complaint goes against the trend of all
sciences to use increasingly sophisticated data
visualization for uncovering regularities in com-
plex systems. The thick IRS publication 1304
(Internal Revenue Service 1999) is ﬁlled with
data tables, but has virtually no graphs. Despite
the abundance of data, it gives a reader no idea
about income distribution, whereas plotting the
data immediately gives insight. However, intelli-
gent plotting is the art with many tools, which not
many researchers have mastered. The author
completely agrees with Gallegati et al. (2006)
that too many papers mindlessly plot any kind of
data on a log-log scale, pick a ﬁnite interval,
where any smooth curved line can be approxi-
mated by a straight line, and claim that there is a
power law. In many cases, replotting the same
data on a log-linear scale converts a curved line
into a straight line, which means that the law is
actually exponential.
Good visualization is extremely helpful in
identifying trends in complex data, which can
then be ﬁtted to a mathematical function; how-
ever, for a complex system, such a ﬁt should not
be expected with inﬁnite precision. The funda-
mental laws of physics, such as Newton’s law of
gravity or Maxwell’s equations, are valid with
enormous precision. However, the laws in con-
densed matter physics, uncovered by experimen-
talists with a combination of visual analysis and
ﬁtting, usually have much lower precision, at best
10% or so. Most of these laws would fail the
formal criteria of mathematical statistics. Never-
theless these approximate laws are enormously
useful
in
practice,
and
everyday
devices
engineered on the basis of these laws work very
well for all of us.
Because
of the ﬁnite accuracy, different
functions
may
produce
equally
good
ﬁts.
Discrimination
between
the
exponential,
Gamma, and log-normal functions may not be
always possible (Banerjee et al. 2006). However,
the exponential function has fewer ﬁtting param-
eters, so it is preferable on the basis of simplicity.
The other two functions can simply mimic the
exponential function with a particular choice of
the additional parameters (Banerjee et al. 2006).
Unfortunately, many papers in mathematical sta-
tistics introduce too many ﬁtting parameters into
complicated functions, such as the generalized
beta distribution mentioned in Gallegati et al.
(2006). Such overparameterization is more mis-
leading than insightful for data ﬁtting.
Quest for Universality
Gallegati et al. (2006) criticized physicists for
trying to ﬁnd universality in economics data.
They also seemed to equate the concepts of
power law, scaling, and universality. These are
three different, albeit overlapping, concepts.
Power laws usually apply only to a small fraction
of data at the high ends of various distributions.
Moreover, the exponents of these power laws are
usually nonuniversal and vary from case to case.
Scaling means that the shape of a function remains
the same when its scale changes. However, the
scaling function does not have to be a power-law
function. A good example of scaling is shown in
Fig. 7, where income distributions for the lower
class collapse on the same exponential line for
about 20 years of data. We observe amazing uni-
versality of income distribution, unrelated to a
power law. In a general sense, the diffusion equa-
tion is universal, because it describes a wide range
of systems, from dissolution of sugar in water to a
random walk in the stock market.
Universalities are not easy to uncover, but they
form the backbone of regularities in the world
around us. This is why physicists are so interested
in them. Universalities establish the ﬁrst-order
effect, and deviations represent the second-order
effect. Different countries may have somewhat
different distributions, and economists often tend
to focus on these differences. However, this focus
on details misses the big picture that, in the ﬁrst
approximation, the distributions are quite similar
and universal.
662
Statistical Mechanics Approach to Econophysics

Theoretical Modeling of Money, Wealth, and
Income
It was pointed out in Anglin (2005), Gallegati et al.
(2006), and Lux (2008) that many econophysics
papers confuse or misuse the terms for money,
wealth, and income. It is true that terminology is
sloppy in many papers and should be reﬁned.
However, the terms in Drăgulescu and Yakovenko
(2000) and Chakraborti and Chakrabarti (2000) are
quite precise, and this review clearly distinguishes
between these concepts in section “Statistical
Mechanics of Money Distribution,” “Statistical
Mechanics of Wealth Distribution,” and “Data
and Models for Income Distribution.”
One contentious issue is about conservation of
money. Gallegati et al. (2006) agree that “trans-
actions are a key economic process, and they are
necessarily conservative,” that is, money is indeed
conserved in transactions between agents. How-
ever, Anglin (2005), Gallegati et al. (2006), and
Lux (2008) complain that the models of conser-
vative exchange do not consider production of
goods, which is the core economic process and
the source of economic growth. Material produc-
tion is indeed the ultimate goal of an economy, but
it does not violate conservation of money by itself.
One can grow coffee beans, but nobody can grow
money on a money tree. Money is an artiﬁcial
economic device that is designed to be conserved.
As explained in section “Statistical Mechanics of
Money Distribution,” the money transfer models
implicitly assume that money in transactions is
voluntarily paid for goods and services generated
by production for the mutual beneﬁt of the parties.
In principle, one can introduce a billion variables
to keep track of every coffee bean and other prod-
uct of the economy. What difference would it
make for the distribution of money? Despite the
claims in Anglin (2005) and Gallegati et al.
(2006), there is no contradiction between models
of conservative exchange and the classic work of
Adam Smith and David Ricardo. The difference is
only in the focus: We keep track of money,
whereas they keep track of coffee beans, from
production to consumption. These approaches
address different questions, but do not contradict
each other. Because money constantly circulates
in the system as payment for production and
consumption, the resulting statistical distribution
of money may very well not depend on what
exactly is produced and in what quantities.
In principle, the models with random transfers
of money should be considered as a reference
point for developing more sophisticated models.
Despite the totally random rules and “zero intelli-
gence” of the agents, these models develop well-
characterized, stable, and stationary distributions
of money. One can modify the rules to make the
agents more intelligent and realistic and see how
much the resulting distribution changes relative to
the reference one. Such an attempt was made in
Lux (2005) by modifying the model of Silver et al.
(2002) with various more realistic economic
ingredients. However, despite the modiﬁcations,
the resulting distributions were essentially the
same as in the original model. This example illus-
trates the typical robustness and universality of
statistical models: Modifying details of micro-
scopic rules does not necessarily change the sta-
tistical outcome.
Another misconception, elaborated in Lux
(2005), (2008), is that the money transfer models
discussed in section “Statistical Mechanics of
Money Distribution” imply that money is trans-
ferred by fraud, theft, and violence, rather than
voluntarily. One should keep in mind that the
catchy labels “theft-and-fraud,” “marriage-and-
divorce,” and “yard-sale” were given to the
money transfer models by the journalist Brian
Hayes (2002) in a popular article. Econophysicists
who originally introduced and studied these
models do not subscribe to this terminology,
although the early work of Angle (1986) did men-
tion violence as one source of redistribution. In the
opinion of the author, it is indeed difﬁcult to justify
the proportionality rule (8), which implies that
agents with high balances pay proportionally
greater amounts in transactions than agents with
low balances. However, the additive model of
Drăgulescu and Yakovenko (2000), where money
transfers Δm are independent of money balances mi
of the agents, does not have this problem. As
explained in section “The Boltzmann-Gibbs Dis-
tribution of Money,” this model simply means that
all agents pay the same prices for the same product,
although prices may be different for different
Statistical Mechanics Approach to Econophysics
663

products. So, this model is consistent with volun-
tary transactions in a free market.
McCauley (2006) argued that conservation of
money is violated by credit. As explained in sec-
tion “Models with Debt,” credit does not violate
conservation law, but creates positive and nega-
tive money without changing net worth. Negative
money (debt) is as real as positive money.
McCauley (2006) claimed that money can be eas-
ily created with the tap of a computer key via
credit. Then why would an employer not tap the
key and double salaries, or a funding agency
double research grants? Because budget con-
straints are real. Credit may provide a temporary
relief, but sooner or later it has to be paid back.
Allowing debt may produce a double-exponential
distribution as shown in Fig. 3, but it does not
change the distribution fundamentally.
As discussed in section “Conservation of
Money,” a central bank or a central government
can inject new money into the economy. As
discussed in section “Statistical Mechanics of
Wealth Distribution,” wealth is generally not con-
served. As discussed in section “Data and Models
for Income Distribution,” income is different from
money and is described by a different model (22).
However, the empirical distribution of income
shown in Fig. 6 is qualitatively similar to the
distribution of wealth shown in Fig. 5, and we
do not have data on money distribution.
Conclusions
The “invasion” of physicists into economics and
ﬁnance at the turn of the millennium is a fasci-
nating
phenomenon.
The
physicist
Joseph
McCauley proclaims that “Econophysics will
displace economics in both the universities and
boardrooms, simply because what is taught in
economics classes doesn’t work” (Ball 2006;
McCauley 2004; Farmer et al. 2005; Samanidou
et
al.
2007;
Econophysics
forum
2008).
Although there is some truth in his arguments
(McCauley 2006), one may consider a less radi-
cal scenario. Econophysics may become a
branch of economics, in the same way as games
theory,
psychological
economics,
and
now
agent-based modeling became branches of eco-
nomics. These branches have their own interests,
methods, philosophy, and journals. The main
contribution from the infusion of new ideas
from a different ﬁeld is not in answering old
questions, but in raising new questions. Much
of the misunderstanding between economists
and physicists happens not because they are get-
ting different answers, but because they are
answering different questions.
The subject of income and wealth distribu-
tions and social inequality was very popular at
the turn of another century and is associated with
the names of Pareto, Lorenz, Gini, Gibrat, and
Champernowne, among others. Following the
work by Pareto, attention of researchers was
primarily focused on the power laws. However,
when physicists took a fresh, unbiased look at the
empirical data, they found a different, exponen-
tial law for the lower part of the distribution. The
motivation for looking at the exponential law, of
course, came from the Boltzmann-Gibbs distri-
bution in physics. Further studies provided a
more detailed picture of the two-class distribu-
tion in a society. Although social classes have
been known in political economy since Karl
Marx, the realization that they are described by
simple mathematical distributions is quite new.
Demonstration of the ubiquitous nature of the
exponential distribution for money, wealth, and
income is one of the new contributions produced
by econophysics.
Bibliography
Primary Literature
Abul-Magd AY (2002) Wealth distribution in an ancient
Egyptian society. Phys Rev E 66:057104
Anderson PW, Arrow KJ, Pines D (eds) (1988) The econ-
omy as an evolving complex system. Addison-Wesley,
Reading
Angle J (1986) The surplus theory of social stratiﬁcation
and the size distribution of personal wealth. Soc Forces
65:293–326
Angle J (1992a) The inequality process and the distribution
of income to blacks and whites. J Math Sociol 17:
77–98
Angle J (1992b) Deriving the size distribution of personal
wealth from ‘the rich get richer, the poor get poorer’.
J Math Sociol 18:27–46
664
Statistical Mechanics Approach to Econophysics

Angle J (1996) How the Gamma Law of income distribu-
tion appears invariant under aggregation. J Math Sociol
21:325–358
Angle J (2002) The statistical signature of pervasive com-
petition on wage and salary incomes. J Math Sociol 26:
217–270
Angle J (2006) The inequality process as a wealth maxi-
mizing process. Phys A 367:388–414
Anglin P (2005) Econophysics of wealth distributions: a
comment. In: Chatterjee A, Yarlagadda S, Chakrabarti
BK
(eds)
Econophysics
of
wealth
distributions.
Springer, New York, pp 229–238
Ao P (2007) Boltzmann-Gibbs distribution of fortune and
broken time reversible symmetry in econodynamics.
Commun
Nonlinear
Sci
Numer
Simul
12:
619–626
Aoyama H, Souma W, Fujiwara Y (2003) Growth and
ﬂuctuations of personal and company’s income. Phys
A 324:352–358
Atkinson AB, Bourguignon F (eds) (2000) Handbook of
income distribution. Elsevier, Amsterdam
Ausloos M, Pekalski A (2007) Model of wealth and goods
dynamics in a closed market. Phys A 373:560–568
Austrian Central Library for Physics (2006) Ludwig
Boltzmann 1844-1906. ISBN 3-900490-11-2. Vienna
Bak P, Nørrelykke SF, Shubik M (1999) Dynamics of
money. Phys Rev E 60:2528–2532
Ball P (2002) The physical modelling of society: a histor-
ical perspective. Phys A 314:1–14
Ball P (2004) Critical mass: how one thing leads to another.
Farrar, Straus and Giroux, New York
Ball P (2006) Econophysics: culture crash. Nature 441:
686–688
Banerjee A, Yakovenko VM, Di Matteo T (2006) A study
of the personal income distribution in Australia. Phys
A 370:54–59
Bennati E (1988) Un metodo di simulazione statistica per
l’analisi
della
distribuzione
del
reddito.
Rivista
Internazionale di Scienze Economiche e Commerciali
35:735–756
Bennati E (1993) Il metodo di Montecarlo nell’analisi
economica. Rassegna di Lavori dell’ISCO (Istituto
Nazionale per lo Studio della Congiuntura). Anno
X 4:31–79
Blume LE (1993) The statistical mechanics of strategic
interaction. Games Econ Behav 5:387–424
Boltzmann L (1905) Populäre Schriften. Barth, Leipzig,
p 360
Bouchaud JP, Mézard M (2000) Wealth condensation in a
simple model of economy. Phys A 282:536–545
Braun D (2001) Assets and liabilities are the momentum of
particles and antiparticles displayed in Feynman-
graphs. Phys A 290:491–500
Braun D (2006) Nonequilibrium thermodynamics of
wealth condensation. Phys A 369:714–722
Burda Z, Johnston D, Jurkiewicz J, Kaminski M, Nowak
MA, Papp G, Zahed I (2002) Wealth condensation in
Pareto macroeconomies. Phys Rev E 65:026102
Carbone A, Kaniadakis G, Scarfone AM (2007) Where do
we stand on econophysics? Phys A 382:xi–xiv
Chakrabarti BK (2005) Econophys-Kolkata: a short story.
In: Chatterjee A, Yarlagadda S, Chakrabarti BK (eds)
Econophysics of wealth distributions. Springer, Milan,
pp 225–228
Chakrabarti BK, Chakraborti A, Chatterjee A (eds)
(2006) Econophysics and sociophysics: trends and per-
spectives. Wiley-VCH, Berlin
Chakraborti A, Chakrabarti BK (2000) Statistical mechan-
ics of money: how saving propensity affects its distri-
bution. Europ Phys J B 17:167–170
Chakraborti A, Pradhan S, Chakrabarti BK (2001) A self-
organising model of market with single commodity.
Phys A 297:253–259
Champernowne DG (1953) A model of income distribu-
tion. Econ J 63:318–351
Champernowne DG, Cowell FA (1998) Economic inequal-
ity and income distribution. Cambridge University
Press, Cambridge
Chatterjee A, Chakrabarti BK (2006) Kinetic market
models with single commodity having price ﬂuctua-
tions. Europ Phys J B 54:399–404
Chatterjee A, Chakrabarti BK, Manna SS (2004) Pareto
law in a kinetic model of market with random saving
propensity. Phys A 335:155–163
Chatterjee
S,
Chakrabarti
BK,
Stinchcombe
RB
(2005) Master equation for a kinetic model of a trad-
ing market and its analytic solution. Phys Rev
E 72:026126
Clementi F, Gallegati M (2005a) Pareto’s law of income
distribution: evidence for Germany, the United King-
dom, the United States. In: Chatterjee A, Yarlagadda S,
Chakrabarti BK (eds) Econophysics of wealth distribu-
tions. Springer, Milan, pp 3–14
Clementi F, Gallegati M (2005b) Power law tails in the
Italian personal income distribution. Phys A 350:
427–438
Clementi F, Di Matteo T, Gallegati M (2006) The power-
law tail exponent of income distributions. Phys A 370:
49–53
Clementi
F,
Gallegati
M,
Kaniadakis
G
(2007)
k-generalized statistics in personal income distribution.
Europ Phys J B 57:187–193
Coelho
R,
Néda
Z,
Ramasco
JJ,
Santos
MA
(2005) A family-network model for wealth distribution
in societies. Phys A 353:515–528
Collier MR (2004) Are magnetospheric suprathermal particle
distributions (k functions) inconsistent with maximum
entropy considerations? Adv Space Res 33:2108–2112
Computer animation videos of money-transfer models.
http://www2.physics.umd.edu/~yakovenk/econophysics/
animation.html. Accessed 1 Jul 2008
Cordier S, Pareschi L, Toscani G (2005) On a kinetic model
for a simple market economy. J Stat Phys 120:253–277
Dall’Asta L, Castellano C, Marsili M (2007) Statistical
physics of the Schelling model of segregation. Avail-
able
via
DIALOG.
http://arxiv.org/abs/0707.1681.
Accessed 1 Jul 2008
Das A, Yarlagadda S (2005) An analytic treatment of the
Gibbs-Pareto behavior in wealth distribution. Phys
A 353:529–538
Statistical Mechanics Approach to Econophysics
665

Deﬁlla S (2007) A natural value unit - Econophysics as
arbiter between ﬁnance and economics. Phys A 382:
42–51
Desai MI, Mason GM, Dwyer JR, Mazur JE, Gold RE,
Krimigis SM, Smith CW, Skoug RM (2003) Evidence
for a suprathermal seed population of heavy ions accel-
erated by interplanetary shocks near 1 AU. Astrophys
J 588:1149–1162
Di Matteo T, Aste T, Hyde ST (2004) Exchanges in com-
plex networks: income and wealth distributions. In:
Mallamace F, Stanley HE (eds) The physics of complex
systems (New advances and perspectives). IOS Press,
Amsterdam, p 435
Drăgulescu
AA,
Yakovenko
VM
(2000)
Statistical
mechanics of money. Europ Phys J B 17:723–729
Drăgulescu AA, Yakovenko VM (2001a) Exponential and
power-law probability distributions of wealth and
income in the United Kingdom and the United States.
Phys A 299:213–221
Drăgulescu AA, Yakovenko VM (2001b) Evidence for the
exponential distribution of income in the USA. Europ
Phys J B 20:585–589
Drăgulescu
AA,
Yakovenko
VM
(2003)
Statistical
mechanics of money, income, and wealth: a short sur-
vey. In: Garrido PL, Marro J (eds) Modeling of com-
plex systems: seventh granada lectures, conference
proceedings 661. American Institute of Physics,
New York, pp 180–183
Durlauf SN (1997) Statistical mechanics approaches to
socioeconomic behavior. In: Arthur WB, Durlauf SN,
Lane DA (eds) The economy as a complex evolving
system
II.
Addison-Wesley,
Redwood
City,
pp 81–104
Engels F (1972) The origin of the family, private property
and the state, in the light of the researches of Lewis
H. Morgan. New York, International Publishers
Feller W (1966) An introduction to probability theory and
its applications, vol 2. Wiley, New York, p 10
Ferrero JC (2004) The statistical distribution of money and
the rate of money transference. Phys A 341:575–585
Ferrero JC (2005) The monomodal, polymodal, equilib-
rium and nonequilibrium distribution of money. In:
Chatterjee A, Yarlagadda S, Chakrabarti BK (eds)
Econophysics
of
wealth
distributions.
Springer,
Milan, pp 159–167
Fiaschi D, Marsili M (2007) Distribution of wealth:
theoretical microfoundations and empirical evidence.
Working paper. Avialable via DIALOG. http://www.
dse.ec.unipi.it/persone/docenti/ﬁaschi/Lavori/
distributionWealthMicrofoundations.pdf.
Accessed
1 Jul 2008
Fischer R, Braun D (2003a) Transfer potentials shape and
equilibrate monetary systems. Phys A 321:605–618
Fischer R, Braun D (2003b) Nontrivial bookkeeping: a
mechanical perspective. Phys A 324:266–271
Foley DK (1994) A statistical equilibrium theory of mar-
kets. J Econ Theory 62:321–345
Föllmer
H
(1974)
Random
economies
with
many
interacting agents. J Math Econ 1:51–62
Fujiwara Y, Souma W, Aoyama H, Kaizoji T, Aoki
M (2003) Growth and ﬂuctuations of personal income.
Phys A 321:598–604
Galam S (2004) Sociophysics: a personal testimony. Phys
A 336:49–55
Galan S, Gefen Y, Shapir Y (1982) Sociophysics: a new
approach of sociological collective behaviour. I. Mean-
behaviour description of a strike. J Math Sociol 9:1–13
Gallegati M, Keen S, Lux T, Ormerod P (2006) Worrying
trends in econophysics. Phys A 370:1–6
Gibrat R (1931) Les Inégalités Economiques. Sirely, Paris
Gupta AK (2006) Money exchange model and a general
outlook. Phys A 359:634–640
Hasegawa A, Mima K, Duong-van M (1985) Plasma dis-
tribution function in a superthermal radiation ﬁeld.
Phys Rev Lett 54:2608–2610
Hayes B (2002) Follow the money. Am Sci 90:400–405
Hu MB, Jiang R, Wu QS, Wu YH (2007) Simulating the
wealth distribution with a richest-following strategy on
scale-free network. Phys A 381:467–472
Huang DW (2004) Wealth accumulation with random
redistribution. Phys Rev E 69:057103
Iglesias JR, Gonçalves S, Pianegonda S, Vega JL,
Abramson G (2003) Wealth redistribution in our small
world. Phys A 327:12–17
Internal Revenue Service (1999) Statistics of income-1997,
individual income tax returns. Publication 1304, Revi-
sion 12–99, Washington DC
Ispolatov S, Krapivsky PL, Redner S (1998) Wealth distri-
butions in asset exchange models. Europ Phys J B 2:
267–276
Jego C, Roehner BM (2007) A physicist’s view of the
notion of “racism”. Available via DIALOG. http://
arxiv.org/abs/0704.2883. Accessed 1 Jul 2008
Kakwani N (1980) Income Inequality and Poverty. Oxford
University Press, Oxford
Kalecki
M
(1945)
On
the
Gibrat
distribution.
Econometrica 13:161–170
Kesten H (1973) Random difference equations and
renewal theory for products of random matrices. Acta
Math 131:207–248
Klass OS, Biham O, Levy M, Malcai O, Solomon S (2007)
The Forbes 400, the Pareto power-law and efﬁcient
markets. Europ Phys J B 55:143–147
Kuznets S (1955) Economic growth and income inequality.
Am Econ Rev 45:1–28
Levy F (1987) Changes in the distribution of American
family incomes, 1947 to 1984. Science 236:923–927
Levy M, Solomon S (1996) Power laws are logarithmic
Boltzmann laws. Int J Mod Phys C 7:595–751
Lifshitz EM, Pitaevskii LP (1981) Physical kinetics.
Pergamon Press, Oxford
Lim M, Metzler R, Bar-Yam Y (2007) Global pattern
formation and ethnic/cultural violence. Science 317:
1540–1544
Lopez-Ruiz R, Sanudo J, Calbet X (2007a) Geometrical
derivation of the Boltzmann factor. Available via
DIALOG.
http://arxiv.org/abs/0707.4081.
Accessed
1 Jul 2008
666
Statistical Mechanics Approach to Econophysics

Lopez-Ruiz R, Sanudo J, Calbet X (2007b) On the equiv-
alence of the microcanonical and the canonical ensem-
bles: a geometrical approach. Available via DIALOG.
http://arxiv.org/abs/0708.1866. Accessed 1 Jul 2008
Lux T (2005) Emergent statistical wealth distributions in
simple monetary exchange models: a critical review. In:
Chatterjee A, Yarlagadda S, Chakrabarti BK (eds)
Econophysics
of
wealth
distributions.
Springer,
Milan, pp 51–60
Lux T (2008) Applications of statistical physics in ﬁnance
and economics. In: Rosser JB (ed) Handbook of com-
plexity research. Edward Elgar, Cheltenham, UK and
Northampton, MA. (in press)
Lydall
HF (1959) The distribution of employment
incomes. Econometrica 27:110–115
Majorana E (1942) Il valore delle leggi statistiche nella
ﬁsica e nelle scienze sociali. Scientia 36:58–66.
(English translation by Mantegna RN in: Bassani GF
(ed) (2006) Ettore Majorana scientiﬁc papers. Springer,
Berlin, pp 250–260)
Mandelbrot B (1960) The Pareto-Lévy law and the distri-
bution of income. Int Econ Rev 1:79–106
Mantegna RN, Stanley HE (1999) An introduction to
econophysics: correlations and complexity in ﬁnance.
Cambridge University Press, Cambridge
McCauley JL (2006) Response to “worrying trends in
econophysics”. Phys A 371:601–609
McConnell CR, Brue SL (1996) Economics: princi-
ples,
problems,
and
policies.
McGraw-Hill,
New York
Milaković M (2005) Do we all face the same constraints?
In: Chatterjee A, Yarlagadda S, Chakrabarti BK (eds)
Econophysics of wealth distributions. Springer, Milan,
pp 184–191
Mimkes J (1995) Binary alloys as a model for the multi-
cultural society. J Therm Anal 43:521–537
Mimkes J (2000) Society as a many-particle system.
J Therm Anal Calorim 60:1055–1069
Mimkes J (2005) Lagrange principle of wealth distribution.
In: Chatterjee A, Yarlagadda S, Chakrabarti BK (eds)
Econophysics of wealth distributions. Springer, Milan,
pp 61–69
Mimkes J (2006a) A thermodynamic formulation of eco-
nomics. In: Chakrabarti BK, Chakraborti A, Chatterjee
A (eds) Econophysics and sociophysics: trends and
perspectives. Wiley-VCH, Berlin, pp 1–33
Mimkes J (2006b) A thermodynamic formulation of social
science. In: Chakrabarti BK, Chakraborti A, Chatterjee
A (eds) Econophysics and sociophysics: trends and
perspectives. Wiley-VCH, Berlin
Mimkes J, Aruka Y (2005) Carnot process of wealth dis-
tribution. In: Chatterjee A, Yarlagadda S, Chakrabarti
BK
(eds)
Econophysics
of
wealth
distributions.
Springer, Milan, pp 70–78
Mirowski P (1989) More heat than light: economics as
social physics, physics as nature’s economics. Cam-
bridge University Press, Cambridge
Mohanty PK (2006) Generic features of the wealth distri-
bution in ideal-gas-like markets. Phys Rev E 74:011117
Montroll EW, Badger WW (1974) Introduction to quanti-
tative aspects of social phenomena. Gordon and
Breach, New York
Nirei M, Souma W (2007) A two factor model of income
distribution dynamics. Rev Income Wealth 53:440–459
Pareto V (1897) Cours d’Économie Politique. L’Université
de Lausanne
Patriarca M, Chakraborti A, Kaski K (2004a) Gibbs versus
non-Gibbs distributions in money dynamics. Phys
A 340:334–339
Patriarca M, Chakraborti A, Kaski K (2004b) Statistical
model with a standard Gamma distribution. Phys Rev
E 70:016104
Patriarca M, Chakraborti A, Kaski K, Germano G (2005)
Kinetic theory models for the distribution of wealth:
Power
law
from
overlap
of
exponentials.
In:
Chatterjee A, Yarlagadda S, Chakrabarti BK (eds)
Econophysics
of
wealth
distributions.
Springer,
Milan, pp 93–110
Patriarca M, Chakraborti A, Germano G (2006) Inﬂuence
of saving propensity on the power-law tail of the wealth
distribution. Phys A 369:723–736
Patriarca M, Chakraborti A, Heinsalu E, Germano
G (2007) Relaxation in statistical many-agent economy
models. Europ Phys J B 57:219–224
Pianegonda S, Iglesias JR, Abramson G, Vega JL
(2003)
Wealth
redistribution
with
conservative
exchanges. Phys A 322:667–675
Raberto M, Cincotti S, Focardi SM, Marchesi M (2003)
Traders’ long-run wealth in an artiﬁcial ﬁnancial mar-
ket. Comput Econ 22:255–272
Rawlings PK, Reguera D, Reiss H (2004) Entropic basis of
the Pareto law. Phys A 343:643–652
Repetowicz P, Hutzler S, Richmond P (2005) Dynamics of
money and income distributions. Phys A 356:641–654
Her Majesty Revenue and Customs (2003) Distribution of
personal wealth. Available via DIALOG. http://www.
hmrc.gov.uk/stats/personal_wealth/wealth_oct03.pdf.
Accessed 1 Jul 2008
Richmond P, Repetowicz P, Hutzler S, Coelho R (2006a)
Comments on recent studies of the dynamics and dis-
tribution of money. Phys A 370:43–48
Richmond P, Hutzler S, Coelho R, Repetowicz P (2006b)
A review of empirical studies and models of income
distributions in society. In: Chakrabarti BK, Chakraborti
A Chatterjee A (eds) Econophysics and sociophysics:
trends and perspectives. Wiley-VCH, Berlin
Richmond P, Chakrabarti BK, Chatterjee A, Angle
J
(2006c)
Comments
on
“worrying
trends
in
econophysics”:
income
distribution
models.
In:
Chatterjee A, Chakrabarti BK (eds) Econophysics of
stock and other markets. Springer, Milan, pp 244–253
Rosser JB (2006a) Debating the Role of Econophysics.
Working paper. Available via DIALOG. http://cob.
jmu.edu/rosserjb/. Accessed 1 Jul 2008
Rosser JB (2006b) The nature and future of econophysics.
In: Chatterjee A, Chakrabarti BK (eds) Econophysics
of
stock
and
other
markets.
Springer,
Milan,
pp 225–234
Statistical Mechanics Approach to Econophysics
667

Rosser JB (2008) Econophysics. In: Blume LE, Durlauf
SN (eds) New Palgrave dictionary of economics,
2nd edn. Macmillan, London. (in press)
Scafetta N, West BJ (2007) Probability distributions in
conservative energy exchange models of multiple
interacting agents. J Phys Condens Matter 19:065138
Scafetta N, Picozzi S, West BJ (2004a) An out-of-
equilibrium model of the distributions of wealth.
Quant Financ 4:353–364
Scafetta N, Picozzi S, West BJ (2004b) A trade-investment
model for distribution of wealth. Physica D 193:
338–352
Scalas E, Garibaldi U, Donadio S (2006) Statistical equi-
librium in simple exchange games I: methods of solu-
tion
and
application
to
the
Bennati-Drăgulescu-
Yakovenko (BDY) game. Europ Phys J B 53:267–272
Schelling TC (1971) Dynamic models of segregation.
J Math Sociol 1:143–186
Schweitzer F (2003) Brownian agents and active particles:
collective dynamics in the natural and social sciences.
Springer, Berlin
Shubik M (1999) The theory of money and ﬁnancial insti-
tutions, vol 2. MIT Press, Cambridge, p 192
Silva AC, Yakovenko VM (2005) Temporal evolution of
the ‘thermal’ and ‘superthermal’ income classes in the
USA during 1983-2001. Europhys Lett 69:304–310
Silver J, Slud E, Takamoto K (2002) Statistical equilibrium
wealth distributions in an exchange economy with sto-
chastic preferences. J Econ Theory 106:417–435
Sinha S (2006) Evidence for power-law tail of the wealth
distribution in India. Phys A 359:555–562
Slanina F (2004) Inelastically scattering particles and
wealth distribution in an open economy. Phys Rev
E 69:046102
Solomon S, Richmond P (2001) Power laws of wealth,
market order volumes and market returns. Phys
A 299:188–197
Solomon S, Richmond P (2002) Stable power laws in
variable economies; Lotka-Volterra implies Pareto-
Zipf. Europ Phys J B 27:257–261
Sornette D, Cont R (1997) Convergent multiplicative pro-
cesses repelled from zero: power laws and truncated
power laws. J Phys I (France) 7:431–444
Souma W (2001) Universal structure of the personal
income distribution. Fractals 9:463–470
Souma W (2002) Physics of personal income. In: Takayasu
H (ed) Empirical science of ﬁnancial ﬂuctuations: the
advent of econophysics. Springer, Tokyo, pp 343–352
Souma W, Nirei M (2005) Empirical study and model of
personal income. In: Chatterjee A, Yarlagadda S,
Chakrabarti BK (eds) Econophysics of wealth distribu-
tions. Springer, Milan, pp 34–42
Stanley HE et al (1996) Anomalous ﬂuctuations in the
dynamics of complex systems: from DNA and physi-
ology to econophysics. Phys A 224:302–321
Stauffer D (2004) Introduction to statistical physics outside
physics. Phys A 336:1–5
Stauffer D, Schulze C (2007) Urban and scientiﬁc segre-
gation: the Schelling-Ising model. Avialable via DIA-
LOG.
http://arxiv.org/abs/0710.5237.
Accessed
1 Jul 2008
Strudler M, Petska T, Petska R (2003) An analysis of the
distribution of individual income and taxes, 1979-
2001. The Internal Revenue Service, Washington
DC. Available via DIALOG. http://www.irs.gov/pub/
irs-soi/03strudl.pdf. Accessed 1 Jul 2008
Takayasu H, Sato AH, Takayasu M (1997) Stable inﬁnite
variance ﬂuctuations in randomly ampliﬁed Langevin
systems. Phys Rev Lett 79:966–969
Wannier GH (1987) Statistical physics. Dover, New York
Weidlich W (2000) Sociodynamics: a systematic approach
to mathematical modeling in the social sciences.
Harwood Academic Publishers, Amsterdam
Wright I (2005) The social architecture of capitalism. Phys
A 346:589–620
Wright I (2007) Computer simulations of statistical
mechanics of money in mathematica. Available via
DIALOG. http://demonstrations.wolfram.com/Statisti
calMechanicsOfMoney. Accessed 1 Jul 2008
Xi N, Ding N, Wang Y (2005) How required reserve ratio
affects distribution and velocity of money. Phys A 357:
543–555
Yakovenko VM, Silva AC (2005) Two-class structure of
income distribution in the USA: exponential bulk and
power-law tail. In: Chatterjee A, Yarlagadda S,
Chakrabarti BK (eds) Econophysics of wealth distribu-
tions. Springer, Milan, pp 15–23
Books and Reviews
Econophysics forum. Avialable via DIALOG. http://www.
unifr.ch/econophysics/. Accessed 1 Jul 2008
Farmer JD, Shubik M, Smith E (2005) Is economics the
next physical science? Phys Today 58(9):37–42
McCauley J (2004) Dynamics of markets: econo-
physics and ﬁnance. Cambridge University Press,
Cambridge
Samanidou E, Zschischang E, Stauffer D, Lux T (2007)
Agent-based models of ﬁnancial markets. Rep Prog
Phys 70:409–450
668
Statistical Mechanics Approach to Econophysics

Index
A
Abrikosov ﬂux line lattice, 620
Action potential, 497
Activated states, 348
Active Brownian particles (ABPs), 519
Active glasses, 237–238
Adam-Gibbs mechanism, 258
Aftershocks,196, 207–208
Adjacency matrix, 602, 603
Advection-reaction-diffusion, 115
Aerosol, 122, 135, 136
Agent-based simulations, 660
Aging, 278–280, 389
driven glassy states, 287–288
energy landscape, 287
mean-ﬁeld aging and effective
temperatures, 281–284
memory and rejuvenation effects, 280–281
state, 483
Alpha-relaxation, 234
Angell Plot, 232, 520
Angoricity, 402
Anisotropic grains, 380
Anosov/Anosov-like systems, 69
Arch breaking process, 386–387
Arches, 365, 381–384
Arch formation model, 369
Arch stabilization process, 375
Arnold Cat Map, 64–66, 68, 69, 80
Arrhenius behavior, 232
Arrhenius law, 185
Associative memory models, 510
Assortative mixing, 582
Atomic force microscopy techniques, 246
Atomic physics, 571
Augmented compatibility matrix, 218
Autocorrelation function, 15, 16
Avalanche, 192, 193
dynamics, 337
size distribution, 367–369
Average macroscopic behavior, 7
B
Bailey criterion, 326
Baker’s map, 64–69, 79, 80
Ball, Philip, 637
Barabási–Albert scale-free model, 581
Barkhausen noise, 192
in magnets, 193–195
Basquin law, 326
Bässler law, 232
Belousov–Zhabotinsky reaction, 509
Bénard-Marangoni convection, 107
Bennati, Eleonora, 642
Ben-Zion and Rice (BZR) model, 195–196
aftershocks, 207–208
depinning transition, 198–200
mode switching, 207
moment rate shapes, 202–205
monotonic models, 198–205
non-monotonic models, 205–208
realistic driving of fault, 200–202
single-interface magnet model, 208–209
Berry’s conjecture, 81
Bethe lattice, 253, 255, 264
Betweenness, 581
centrality, 600–602
Bidimensional plaquette model, 263
Bifurcation, 99, 103, 105
Binocular rivalry, 506
Bioinformatic tools, 464
Biological active matter, 524
Biological function, 464
Biological network, 450, 451, 580
Boolean networks, 458–459
dynamical systems, 461–462
genetic regulatory networks, 452–453
metabolic networks, 454–455
probabilistic models, 459–461
protein–protein interaction networks, 453–454
signaling networks, 455–456
stochastic dynamics, 462–463
topological models, 456–458
© Springer Science+Business Media, LLC, part of Springer Nature 2022
B. Chakraborty (ed.), Statistical and Nonlinear Physics,
https://doi.org/10.1007/978-1-0716-1454-9
669

Biophysically realistic models, 498
Biopolymers, 303
Bipartite graph, 578
Black dashed line, 490
Bloch mode, 213, 220
Block co-polymers, 45, 48–51
Boltzmann, Ludwig, 637
Boltzmann constant, 519
Boltzmann distribution, 399
Boltzmann-Gibbs distribution of energy, 638–639
Boltzmann-Gibbs distribution of money, 640–642
Boltzmann probabilities, 15
Boltzmann’s constant, 74
Boolean function, 458
Boolean networks, 458–459
Bose-Fermi mixtures (BFM)
one-dimensional lattices, 529–534
two-dimensional optical lattices, 545–547
Bosonization procedure, 530
Box-counting dimension, 70
Box counting method, 584
Bragg glass, 174, 176–178, 183, 184, 186, 187
Bragg peaks, 174–178
Brownian dynamics, 243, 519
Brownian ﬂuctuations, 478, 479
Brownian motion, 27, 35, 36, 58
Brownian particle, 58, 76
Bulk-boundary correspondence, 222
Buoyancy, 123–125, 134, 136, 138
Burgers vortex, 133
Burning invariant manifolds, 115–118
Burridge-Knopoff model, 195
C
Cage effect, 260
Canonical polaron transformation (CPT) operator, 532
Carbon black gels, 316, 320–321
Caseinate gels, 322, 324, 327
Cauchy-Schwarz inequality, 249
Caustics, 126, 128, 133
Cell biology
Boolean networks, 458–459
dynamical systems, 461–462
dynamics, attractors, stability and large ﬂuctuations,
467–468
evolvability and designability, 469–470
genetic regulatory networks, 452–453
metabolic networks, 454–455
modularity, 463–464
noise, 465–467
optimization principles, 468–469
probabilistic models, 459–461
protein–protein interaction networks, 453–454
robustness, 464–465
signaling networks, 455–456
stochastic dynamics, 462–463
topological models, 456–458
Cellular automata model, 341
Cellular networks, 470
Center of mass (COM), 7
Centrality, 600, 607
betweenness, 600–602
closeness, 600, 601
degree, 602
eigenvector, 602
non-backtracking walks, 606–607
random walks, 604–605
subgraph, 603
walks, 602–604
Chaos effect, 281
Chaos theory, 461
Chaotic advection, 108
Chaotic hypothesis, 69
Chaotic quantum billiard, 564–565
Chaotic systems, 57–60, 62–64, 69–71, 75, 76, 80–82
Charge-density-wave (CDW), 146, 148, 149, 151, 152,
155–158, 160
phase, 530, 533–534
Chemotaxis, 450
Chromatin immunoprecipitation (ChIP) assays, 452
Classical chaos, 567
Classical computer simulations, 242
Clausius, Rudolf, 637
Clausius-Clapeyron law, 135
Clogging, 365
arches, 365, 381–384
dense microparticle suspension, 366
dynamical signatures, 372–374
dynamics, 380–381
geometrical frustration, 367
granular silos, 366
granular systems, 365
and jamming, 392
metastable structure, 366
oriﬁces, 366
particles properties, 378–380
phase diagram, 375, 391
physical mechanism, 393
statistics of avalanches, 370–372
stochastic process, 367–369
suspended hydrated particles, 366
time distributions, 387
transition, 391
variables, 374–380
Closeness centrality, 600, 601
Clouds, 121–122
cumulus, 136–137
droplets in, 137–139
length-scales, 123
mammatus, 137
particle inertia, thermodynamics and buoyancy-driven
ﬂow, 136–139
phase-change, thermodynamics of, 135–136
Cluster analysis, 582
Clustered scale-free networks, 582
Cluster growing method, 584
Clustering, 266, 464, 581
670
Index

Coarse-grained collision density, 133
Cohen-Gallavotti ﬂuctuation theorem, 79
Collectively jammed states, 417
Collective transport and deepening, 146
Collective transport and depinning
contact line depinning, 156
continuum model of manifold dynamics, 150–151
critical exponents, numerical results for, 152–153
critical properties and scaling laws, 151–152
depinning transition and universality, analytical
treatments of, 153
driven depinning transition, 150
easy and hard directions of depinning, 158
elasticity, order and symmetry breaking, 147–148
elastic manifolds, in disordered potential, 148–149
elastic manifolds and impurity pinning, 147–149
functional renormalization group, 155–156
lattice automaton, 158–159
mean-ﬁeld theory, 153–154
quenched KPZ equation, 159–160
rugged energy landscape, critical dimension and
pinning length, 149
self-organized criticality, 156–158
Collisional cooling, 351
Collision-coalescence processes, 129
Colloidal gels
mechanics of, 314–315
microstructures, 316–317
oscillatory shear rheometry, 317–319
reversible yielding vs. irreversible rupture, 319–324
strain-induced yielding, stress-induced yielding,
325–327
Colloidal glass transition, 235–236
Combinatorial optimization algorithms, 612
Compatibility matrix, 216
Complex networks
cascading failures, 588
community structure, 582
dynamics on, 587
resilience, 587
robustness, 587
searchability of, 592
structural properties of, 578
vulnerability, 587
Complex systems and emergent phenomena
equilibrium averages, 5–7
1/f ﬂuctuations, 15–16
KT transition, 13–14
lack of ordering in two dimensions, 10–11
non-equilibrium systems, 15
self-organized structure formation, 18–20
spin wave stiffness, 12–13
two-dimensional XY-model, 7–10
vortex unbinding, 11–12
vortex unbinding transition, 14–15
Conﬁgurational entropy, 233, 257
Confocal scanning microscopy, 329, 330
Conservation law, 640
Constitutive equations, 352, 356–359
Constraint release (CR), 41
Contact forces, 270
Contact line depinning, 156
Contact mechanics, 348
Continuity equation, 368
Continuum model of manifold dynamics, 150–151
Continuum systems, 226
Contour length ﬂuctuation (CLF), 41
Convective constraint-release (CCR), 41, 42
Convective ﬂow, 104
Correlation dimension, 70
Correlation function, 13, 15, 16, 285
Correlation length exponent, 152
Cost function, 240
Couette shear experiment, 411, 413
Coulomb forces, 86, 87
Coulomb frustrated models, 264–265
Coupled low-dimensional superﬂuids, 539–540
Crackling noise, 192
Creep law, 186
Creep motion, 187
and small applied force, 184–187
Creep test, 319–322, 326
Critical dimension, 149
Crystallization transition, 233
Cumulative probability distribution, 649, 650, 652
Cumulus clouds, 136–137
Cutting plane algorithm, 627
Cytoplasm, 518, 524
D
Daley–Kendall model, 591
Damkoehler number, 139
2D Brillouin Zones of Maxwell lattices, 225
Decoupling, 381
Decoupling phenomena, 262
Defect-mediated turbulence, 107
Defects, 99, 105, 106
Degree centrality, 602, 604
Degree correlations, 586
Delayed yielding, 321–323
Dense active matter, 518, 524
experimental studies, 518
numerical studies, 519–523
theoretical studies, 523–524
Depinning, 180–182
transition, 198–200
Design principle, 451, 458, 463
Deterministic chaos, 99–101
Deterministic diffusion, 76
Diffusion coefﬁcient, 520
Diffusion equation, 17
Diffusion-limited cluster aggregation (DLCA), 317
Dijkstra’s algorithm, 614, 616
Directed networks, 578, 585–586
Directed percolating path, 158, 159
Directed percolation, 158–160
Directed polymer model, 614
Index
671

Direct numerical simulations (DNSs), 122, 123
Dirichlet-Helmholtz problem, 564
Disassortative mixing, 582
Discrete element method (DEM), 431
Discrete element modelling, 380
Discrete Element Simulations (DEM), 404
Discrete Fourier transform, 221
Disordered elastic media
depinning, 180–182
general description of dynamics, 179–180
high velocity phase, 181–183
interfaces and basic concepts, 167–171
periodic systems and Bragg glass, 171–177
pinning and dynamics, 177–179
small applied force and creep motion, 184–187
Dissipated work, 486
Distribution probability, 604
DNA microarrays, 455
Driven depinning transition, 150
Driven glassy states, 287–288
2D superﬂuids, 540–544
Dynamical exponent, 152
Dynamical facilitation theory, 252
Dynamical system, 454, 456, 461–462, 465, 467
theory, 78
Dynamic weakening model, 196
Dynamic strengthening model, 196
E
Earthquake(s)
aftershocks, 196, 207–208
depinning transition, 198–200
global statistics, 192–193
power law scaling, 192–193
realistic driving of fault, 200–202
Earthquake fault models
aftershocks, 196
Burridge-Knopoff model, 195
BZR model (see Ben-Zion and Rice (BZR) model)
dynamic weakening model, 196
dynamic strengthening model, 196
equations of motion, 196–197
monotonic models, 197
non-monotonic models, 197–198
slider block model, 195
stress pulses, 197–198
weakening, 197
Earthquake system vs. magnet system, 194
Earth’s gravity, 381
Eckhaus instability, 105
Econometrics, 636
Econophysics, 636, 638, 643, 647, 655, 660, 661, 663, 664
Edwards–Anderson Hamiltonian, 625
Edwards ensemble, 399
Edwards–Wilkinson equation, 180
Ehrenfest time, 81, 567
Eigenvector centrality, 602
Eigenvector equation, 606
Elastic approximation, 168, 619
Elastic coefﬁcients, 168, 171
Elastic energy, 148, 170
Elastic interactions, 337
Elasticity, 147, 149, 297
Elastic manifold, 620–622
Elastic modulus, 318
Elastic plus disorder energy scales, 180
Elasto-plastic models, 339–341
Electrostatic charge, 30–31
Energy density, 138
Energy function, 240
Entanglement transition, 617
Entropy, 639
production, 78–80
vanishing mechanism, 256
Epithelial sheets, 518
Equations of motion, 17, 179, 196–197
Equilibrium averages, 5–7
Equilibrium energy, 150
Equilibrium statistical mechanics, 399
Equilibrium theory, 179
Erdős number, 581
Erdős-Rényi graphs, 600
Erdős–Rényi model, 577, 579
Ergodic dynamics, 485
Ergodic hypothesis, 60
Ergodicity, 91–92
Ergodic systems, 60–61
Ergodic theory, 639
Escape-rate formulae, 71–72
Escherichia coli, 455, 464, 466, 468
Eshelby problem, 340
Euclidian space, 264
Euler ﬂows, 101
External stresses, 297
F
Fatigue test, 319–321
Faxen corrections, 125
Feed-forward loops (FFLs), 582
Ferroelectric domain wall, 172
Ferroelectric ﬁlm, 172
Ferromagnetic Ising model, 275
Ferromagnetic transition, 265
Fidelity decay, 569
Field theory of jammed grain packings, 419
Finite-time Lyapunov exponent (FTLE) ﬁeld, 99, 112
Fisher, Irving, 637
Flexible structures, 214
Flory argument, 170
Flory-Huggins free-energy, 46
Flow-induced ﬂuctuations, 339
Fluctuation-dissipation relations, 249
Fluctuation-dissipation theorem (FDT), 282
Fluctuation theorems (FTs), 479, 487–488
Fluid dynamics, in clouds, see Clouds
Fluidization time, 320, 321, 323
672
Index

Fokker–Planck equation, 502, 508
Fokker-Planck equation, 71, 648, 656, 657
Force ensembles, 400–401
Force-equilibrium condition, 149
Fourier transform, 13, 16, 17, 168
Fractal dimensions, 69–70
Fractality, 584
Fractals, 584
Fragile liquids, 232
Fragility, 518, 520, 523, 524
Franz-Parisi potential, 274
Fredrickson-Andersen model, 285
Free energy functional, 99, 107
Free energy recovery, 489–491
Freely jointed chain (FJC), 29
Frictional jamming
dry foams, 427
geometry/local coordinates, 429
granular materials, 427, 429
packings, 428
Frictional rigidity transition
cluster spanning probabilities, 442
constraint counting, 437, 438
Coulomb threshold, 439
ﬂoppy modes, 440
packings, 439, 441
pebble game, 445
shear thickening, 444
spanning rigid cluster, 442–444
Friction coefﬁcient, 179
Friction development, 378
Frictionless hydrogel particles, 379
Frozen disorder, 613
Full-replica symmetry breaking, 267
Fully-developed turbulence, 99, 101
Functional renormalization group (FRG), 155–156, 171
G
Galilean transformation, 356, 357
Gamma distribution, 643, 645, 648, 649
Gardner transition, 267, 268
Gaussian chains, 35
Gaussian decay, 569
Gaussian thermostats, 71, 73, 75, 79, 80
Gelation, 37
Gelfand triplet, 75
Gels, 297, 298
connectivity and rigidity, 300
elastic modulus and emergence of rigidity, 303–305
microscopic forces and gelation processes, 300–303
morphology and appearance, 298
particulate gels, 298
polymerization reactions, 298
solid networks, 299
stress localization, 305
Generalized Bloch form, 220
Generalized ensembles, 401–402
Generalized rigidity, 12
Gene regulation, 453
Genetic regulatory networks, 452–453
Geometric frustration, 260, 264
Gini coefﬁcient, 653–656, 659, 660
Girvan–Newman algorithm, 583
Glasses, 230
active, 237–238
aging and equilibrium dynamics, 278–288
colloidal glass transition, 235–236
dynamic heterogeneity, 243–252
granular glass transition, 237
jamming transitions, 237, 269–271
mean-ﬁeld glassy phase diagrams, 266–269
multi-point correlation functions, 246–249
phenomenology of glass-forming liquids, 231–235
random pinning, 238–239
rheology, 271–272
spatio-temporal dynamic ﬂuctuations, 243–247
spin, 239
ultrastable, 239
vibrational properties, 270–271
Glass transition, 230
computer experiments, 241
Coulomb frustrated models, 264–265
defects, 262–263
deﬁnition, 229, 231
s-ensemble and large deviations, 276–277
Franz-Parisi potential, 274
future research, 288–289
geometric frustration, 264
lattice gas, 260
locally preferred structures, 265–266
machine learning developments, 277–278
non-linear response function, 249–252
numerical simulation, 241–243
point-to-set correlation function, 274–276
random ﬁrst order transition theory (RFOT), 252–260
static and dynamic correlation function, 234
swap Monte Carlo algorithm, 272–274
temperature values, 233
theory of, 252–266
Glassy dynamics, 518
Globular protein, 524
Glucono-δ-lactone (GDL), 317, 318, 321, 324, 326
Google matrix, 605
Gradient expansion, Liouville equation, 361–363
Gradient networks, 585
Grain boundaries, 99, 106
Granular ﬂows
categories, 404
force ﬂuctuations and dynamical heterogeneities in,
404–407
length and time scales in, 404–407
simulations of, 398
Granular ﬂuids, 349
and non-equilibrium statistical mechanics, 349–351
Granular glass transition, 237
Granular materials, friction
contacts, 429
experiments, 429
Index
673

Granular materials, friction (cont.)
frictional jamming, 431
jamming phase, 432
numerical models, 430, 431
sheared packing, 432
well-deﬁned transition packing, 432
Granular matter, 348, 349, 365
Granular packings, 399
Granular silo, 365, 366
Graph theory, 577
Green–Kubo expressions, 359
H
Hamiltonian, 7–10, 12, 15
dynamical systems, 562
dynamics model, 59, 262–263
N‑particle system, 75
systems, 78
Hashimoto matrix, 606
Hausdorff dimension, 70, 77
Havriliak-Negami law, 235
Heat, 483–485
Heisenberg time, 567
Helfand moment, 58, 71
Helmholtz free energy, 11
Herschel-Bulkley ﬂow behaviour, 343
Hertz-Mindlin contact theory, 429
Hertz-Mindlin/Cundall-Strack contact models, 440
Heterogeneous disorder, 258–259
H‑theorem, 78
Hexatic phase, 173
Hierarchical clustering, 582, 583
Hierarchical community structure, 583, 584
Hierarchical Dyson RG method, 259
High velocity phase, 181–183
Hodgkin–Huxley formalism, 499
Holme–Kim model, 581
Homeostasis, 512
Homogeneous cooling state (HCS), 352
Homogeneous turbulence, 131
Homotopy group, 222
Hookean return force, 216
Hopper angles, 374
Huyghens-type synchronization, 508
Hydrodynamic ﬁelds, 352
and normal states, 353–354
Hydrodynamics, 37
I
Ice crystals, 123, 134
Icosahedral order, 265
Ihara-Bass matrix, 606
Importance sampling algorithm, 89–90
Incipient clogging, 373
Income distribution
empirical data on, 651–656
theoretical models, 656–658
Inequality, 660
Inﬁnite dimensional theory, 254
Information dimension, 70
Inhomogeneous partial differential equation, 17
Instantaneous ﬂow rate, 374
Integrable system, 63
Integral-equation approach, 264
Integrate-and-ﬁre model, 497
Integrity, 348
Intermediate scattering function, 76, 234, 242
Internal stresses, 297
Inter-Tropical Convergence Zone (ITCZ), 122
Intrinsic network dynamics, 502–503
Invariant manifolds, 110
Irregular ﬁring, 503
Irreversible behavior, 75
Ising ferromagnetic model, 284
Ising model, 622
Ising spins, 265
Isotropic turbulence, 131
J
Jamming-clogging connection, 392
Jamming, in granular matter
experimental observations, 420
force distributions, 407
future directions, 420–422
isostacity and marginality, 419
isostaticity and random close packing, 416–418
isotropic vs. anistropic stress states, 413
numerical simulations, 413–415
physical experiments for isotropic case, 415–416
sheared states, 408–413
simulations and theory, 419–420
statistical frameworks, 398–399
Jamming phase diagram, 402–404
Jamming transition, 237, 518, 524
in granular materials, 397
Janssen effect, 379
Janus colloids, 518, 525
Jarzynski equality, 485–487
K
Katz centrality, 604
Kauzmann transition, 274
K-core percolation model, 419
Kenyon cells, 511
Kibble-Zurek mechanism, 544–545
Kinematics, 381
Kinematic viscosity, 122, 125
Kinetically constrained models (KCMs), 261, 263
Kinetic energy, 381, 390
Kinetic Ising models, 260
Kinetic theory methods, 79
Kinetic theory of gases, 637
Kob-Andersen binary Lennard-Jones mixture, 519, 520
Kob-Andersen lattice gas, 261
674
Index

Kohler radius, 135
Kolmogorov-Arnold-Moser (KAM)
invariant surface, 99, 109
theorem, 562
Kolmogorov scale, 122, 123
Kolmogorov-Sinai entropy per unit time, 71, 72, 79
Kosterlitz–Thouless transition (KT transition), 8, 10,
13–14
Krackhardt kite graph, 602
Kronecker-delta, 606, 627
Kuhn length, 27
L
Lagrangian coherent structure (LCS), 99
Laman’s theorem, 434, 438
Laminar ﬂow, 99, 100, 109
Langevin approach, 15–16
Langevin equations, 27
Langevin force, 179
Langevin-like equation, 502
Langevin noise, 179
Laplacian eigenfunctions, 37
Large-amplitude oscillatory shear (LAOS), 319
Large eddy simulations (LESs), 123
Larkin collective pinning force, 180
Larkin length, 170, 171, 175
Lattice automaton, 158–159
Lattice disordered models, 259
Lattice gas model, 260
Lattice gauge theory, 88
Lattice glass models, 253
Laurent polynomials, 220
Lebesgue measure, 73
Lennard-Jones glass-former, 241
Lennard-Jones liquid, 248
Lévy ﬂights, 99, 109
Lindemann criterion, 172
Linear elasticity, 226
Linear interface model (LIM), 151, 153, 157, 158,
160, 161
Linear response theory, 318
Linear stability theory, 99
Linear Stokes drag model, 125, 126
Liouville dynamics, 351
Liouville equation, 65, 78, 351
gradient expansion, 361–363
Liouville’s theorem, 73
Liquid-liquid phase separation (LLPS), 51
Lobes, 99, 111
Local drag, 35
Local inhomogeneity, 392
Locally preferred structures, 265–266
Local shear transformations, 337
Long chain branched (LCB) melts, 39
Lorenz curve, 653–655
Loschmidt echoes, 569
Luttinger liquid of polarons, 529–534
Lyapunov exponents, 59, 67–75, 77–82
M
Machine learning, 122, 277–278
Macroscopic balance equations, 352–353
Macrostate, 350
Madin-Darby Canine Kidney (MDCK) cells, 518
Magnetic domain wall, 172
Magnetic ﬁlms, 172
Magnetic moments, 7
Magnetization, 166
Magnets
Barkhausen noise models in, 192–193
random ﬁeld Ising model (RFIM), 194–195
Magnet system vs. earthquake system, 194
Mammatus clouds, 137
Manifolds, 99
burning invariant, 115–118
lobes and transport barriers, 110–112
Man-made complex networks, 578
Many-chain ﬂuids
complex topology polymers and gelation, 33–34
semi-dilute solutions, 32–33
Martin–Siggia–Rose (MSR) formalism, 180
Mathematical programming formulation, 629
Maxey-Riley equation, 125
Maximally random jammed state (MRJ), 417
Maximization problem, 612
Maximum ﬂow problem, 621
Maxwell, James Clerk, 637
Maxwell-Calladine index theorem, 216
Maxwell lattice, 218, 221–222
formulations, 224
origami, 224–226
topological invariants in higher dimension, 222–224
Maxwell/mechanically critical systems, 217
Maxwell model, 231
Maxwell’s criterion for rigidity, 269
Mean avalanche size vs. exit size, 371, 372
Mean avalanche size vs. intensity of taps, 379
Mean-ﬁeld, 342–343
models, 252–254
theory, 153–154
Mean-square-displacement (MSD), 520
Mechanical compatibility, 224
Medium-amplitude oscillatory shear (MAOS), 319
Memory and rejuvenation effects, 280–281
Mesoscopic scale, 323
Mesoscopic solid-state physics, 571
Metabolic networks, 454–455, 578
Michaelis–Menten kinetic reactions, 461
Micro canonical ensemble, 6
Micro-phase separation phenomena, 300
Microphysics
without thermodynamics, 124–134
with thermodynamics, 134–139
Microscopic approach, 147
Microscopic realization, 261
Microstate, 350
Middle third Cantor set, 70
Minimal gauge, 221
Index
675

Minimization problem, 612
Minimum cut problem, 620
Mitogen activated protein kinase (MAPK), 456
Mixing systems, 61
Mode-coupling theory (MCT), 256, 261
Model Hamiltonian, 612
Mode switching, 207
Modiﬁed random walks, 605
Modular function, 629
Modularity, 463–464
Molecular dynamics (MD), 404, 431
Molecular glasses, 278
Molecular motors, 480–481
Molecular weight, 24
Moment rate shapes of monotonic models, 202–205
Money distribution, statistical mechanics
additive vs. multiplicative models, 645–647
Boltzmann-Gibbs distribution of energy, 638–639
Boltzmann-Gibbs distribution of money, 640–642
conservation of money, 639–640
debt, models with, 642–644
proportional money transfers and saving propensity,
643–645
Monomeric drag constant, 35
Monomer length, 27
Monotonic models, 197
depinning transition, 198–200
moment rate shapes, 202–205
realistic driving of fault, 200–202
Monte-Carlo dynamics, 243
Monte Carlo simulation, 86–87
dynamic process application, 90–93
ergodicity, 91–92
ﬁnite size effects, 93–94
importance sampling algorithm, 89–90
lattice gauge theory, 88
pseudorandom number generator (RNG), 87
quantum statistical mechanics, 94–96
statistical errors, 87
statistical physics, 95
Monte Carlo step (MCS), 91
Multi-compartment models, 499
Multifractals, 70
Multi-phase polymeric ﬂuids, 45–46
block co-polymers, 48–51
polymer blends, 46–48
Multi-point correlation functions, 246–249
Multistable networks, 510
N
Natural metabolic networks, 457
Natural rubber latex gels, 329
Navier–Stokes approximation, 354–356
constitutive equations, 356–359
Green–Kubo expressions, 359
Navier–Stokes hydrodynamic equations, 359
Navier-Stokes equation, 122, 125, 126
Navier–Stokes hydrodynamic equations, 359
Navier–Stokes hydrodynamics, 360
Network(s), 2, 577
congestion, 588–590
degree correlations and mixing patterns, 582
degree distribution, 578–581
directed, 585–586
epidemiological modeling, 590–591
function, 581
future research directions, 592–593
and information spreading, 591–592
nodes, 463
states, 460
weighted, 586–587
Neural mass models, 496
Neuronal dynamics
asynchronous to synchronous state, 510
attractors with inhomogeneously distributed activity,
503–505
bursts of activity, 504–505
classes of neural models, 496–499
dynamics at time scales, 504
future research, 512
and information processing, 510–512
intrinsic network dynamics, 502–503
irregular ﬁring, 503
long-term synaptic plasticity on, 510–511
multistablity and working memory, 510
network architecture, 500–502
and odor discrimination, 511
place maps and oscillations in hippocampus, 511
rate models, 496–497
selective ampliﬁcation, 509
sparsely synchronized oscillations, 508–509
spiking neuron model, 497–499
stimulus driven dynamics, 509
synapses, 499–500
synchronization of periodically ﬁring neurons,
506–507
theoretical tools, 502
wave propagation, 509
Newtonian dynamics, 242, 243
Node strength, 586
Non-backtracking eigenvector centrality, 606
Non-backtracking walks, 606–607
Non-chaotic systems, 59
Non-equilibrium aging state (NEAS), 483
Non-equilibrium glass transition, 238
Non-equilibrium phase transitions, 398, 399
Non-equilibrium states, 482
non-equilibrium aging state (NEAS), 483
non-equilibrium steady state (NESS), 483
non-equilibrium transient state (NETS), 482
Non-equilibrium statistical mechanics, 57
Non-equilibrium steady state (NESS), 483
Non-equilibrium systems, 15, 78
Non-equilibrium thermodynamics of small systems, 478,
482–483
Non-equilibrium transient state (NETS), 482
Non-interacting chains, 27–29
676
Index

Non-linear dynamical susceptibility, 252
Nonlinear dynamics, 1, 100, 461
Nonlinear Guest-Hutchinson (GH) mode, 219
Non-linear mechanical susceptibilities, 251
Non-linear response function, 249–252
Non-monotonic models, 197–198, 205–207
aftershocks, 207–208
mode switching, 207
Non-overlapping community structure, 582
Normalized Lebesgue measure, 70
Normal states, and hydrodynamic ﬁelds, 353–354
Normal variables, 62
Numerical simulations, 391
O
Ohira–Sawatari model, 589
Olfaction, 511
One-dimensional Bose-Fermi mixtures (BFM), 529–534
One-step replica symmetry breaking (1RSB) solution, 254
Optimal paths, 614
Optimization problem and algorithms
deﬁnition, 611
elastic lines in random media, 615–617
elastic manifold, 620–622
future research, 630
interfaces and elastic manifolds, 619–620
periodic medium, 622
Potts free energy and submodular function, 627–628
random ﬁeld Ising model, 622–624
spin glass problem, 624–625
three dimensions, non-planar graphs, 626–627
two-dimensional Ising SG on a planar graph, 625–626
vortex glasses and loop percolation, 617–618
Order parameter, 11, 12, 14
Oriﬁces, 375–378
Ornstein-Zernicke scattering function, 32
Orthonormal basis, 603
Oscillatory shear rheometry, 317–319
Oseen tensor, 37
Osmotic pressure, 32
Out-of-equilibrium phase transitions, 337
Overlapping community structure, 585
P
PageRank, 605, 606
Parametric correlation-response plots, 284
Pareto, Vilfredo, 637
Particle-based models, 519
Particle dynamics, 129
Particle inertia, 132, 136–138
Particulate gels, 298
Partition function, 7, 87
Path integral Monte Carlo, 95
Peierls instability, 146
Percolation cluster, 630
Perfect matching problem, 626
Periodic Lorentz gas, 77
Periodic structures, 217–218
Perron-Frobenius theorem, 602
Persistence time, 519, 522, 523
Phase change, 123, 124, 135–137, 139, 140
Phase diagram, 209, 548–550
Phase-locking transition, 539–540
Phase-response-curve (PRC), 507
Phase transitions, 1
classes of, 398
Phenomenogical mean-ﬁeld, 342
Photoelastic technique, 410
Physical vapor deposition, 239
Physics of jerky motion, 192–194, 196, 201, 203–207
Pinning length, 149
Plastic activity rate, 342
Poincaré section, 99, 109, 110
Poisson process, 389
Polydispersity, 380
Polyelectrolyte, 30
Polymer(s), 613
blends, 46–48
statistics, 27
Polymeric ﬂuids
entangled polymer dynamics, 37–41
multi-phase, 45–51
non-linear ﬂow, 41–45
polymer dynamics with hydrodynamics, 37
single chain dynamics, 35–37
Polynomial algorithms, 613
Post-synaptic potential (PSP), 499
Potts free energy, 627–628
Power law, 390
degree distributions, 577
Power spectrum, 16
Prandtl number, 105
Precursor (to failure or yielding), 325, 329
Preﬂow, 621
Probabilistic model, 367, 368, 459–461
Probability density, 605, 649
Probability distribution function (pdf), 387
Processivities, molecular motors, 481
Protein–protein interaction networks, 453–454
Pseudo-chaotic systems, 63, 64, 82
Pseudorandom number generator (RNG), 87
p-spin model, 253
Q
Qualitative analysis, 149
Quantitative analysis, 451
Quantum chaos
atomic physics, 571
chaotic billard, 564–565
deﬁnition, 561
dynamical aspects, 567–571
Ehrenfest time, 567
ﬁdelity decay, 569
Gaussian decay, 569
Heisenberg time, 567
Index
677

Quantum chaos (cont.)
Loschmidt echoes, 569
mesoscopic solid-state physics, 571
quantum ergodicity, 564–565
quantum information, 571–572
regular billard, 564
stationary aspects, 563–567
statistical properties, 561
wave chaos, 572
Quantum statistical mechanics, 94–96
Quenched disorder, 613
Quantum dynamics, 567–571
Quantum ergodicity, 564–565
Quantum frustration, 550–556
Quantum information, 571–572
Quantum numbers, 565
Quenched KPZ Equation, 159–160
Quincke rollers, 517
R
Random close packing (RCP), 417
Random cluster representation, 627
Random energy model (REM), 287
Random ﬁeld Ising model (RFIM), 194–195, 258,
622–624
Random ﬁrst order transition (RFOT) theory, 522–524
Adam-Gibbs relation, 257
dynamical behavior, 256
energy and conﬁgurational entropy, 257
heterogeneous disorder, 258–259
liquids and glasses in inﬁnite dimensions, 254
mean-ﬁeld models, 252–254
renormalization group, 259–260
Random-loose-packed (RLP) state, 417
Random manifold, 170, 171, 175
Random matrix theory, 563
Random pinning glass transition, 238–239
Random surfer model, 605
Random walk(s), 27, 604–605
theory, 71
Rate models, 496–497
architecture, 501–502
tools, 502
wave propagation, 509
Rayleigh-Bénard convection, 99, 104–107
Rayleigh number, 100, 104
Reaction-diffusion system, 100, 113
Real networks, 581
Reference model, 7
Regular billard, 564
Rejuvenation effect, 281
Relaxation modulus, 38
Renormalization group (RG), 5, 12, 21, 155, 170,
259–260, 547–548
Replica-symmetic (RS) parametrization, 254
Replica theory, 253
Replica trick, 170
Resonant tori, 562
Response functions, 284
Restricted partition function, 266
Reynolds number, 100–102, 122, 123, 125, 126, 128, 134,
137, 139
Rheology, 271–272
Rigged Hilbert space, 75
Rigid embedding, 214
Rigidity, 297
matrix, 216, 222, 224–226
theory, 226
Rigidity percolation
Laman’s theorem, 434–437
Maxwell constraint counting, 433
Ring model, 504
Robustness, 7, 464–465
exponent, 152, 172
Rouse equation, 35
Rubber elasticity theory, 38
Ruelle-Pollicott resonances, 75
S
Saccharomyces cerevisiae, 457
Saddle point method, 255
Scale-free model, 579
Schelling, Thomas, 659
Schnirelman’s theorem, 81
Schrödinger problem, 564
Searchable social network model, 592
Second law of thermodynamics, 6
Selective ampliﬁcation, 509
Self-diffusion coefﬁcient, 245
Self-ﬂuidization process, 339
Self-induced heterogeneity, 258
Self-interacting chains, 29–30
Self-organized criticality (SOC), 153, 156–158, 160
Self-propelled particles, 238
Semi-dilute solutions, 32–33
s-ensemble method, 276–277
Settling velocity, 134
Shear localization, 338
Shear-thinning, 288
Signaling networks, 455–456
Simple graph, 578
Sinai-Ruelle-Bowen (SRB) measure, 73, 78, 80
Single chain dynamics, 35–37
Single-interface magnet model, 208–209
Single-line lattice model, 615
Single particle displacements, 244
Single polymer chain physics
electrostatic charge, role of, 30–31
non-interacting chains, 27–29
self-interacting chains, 29–30
Slow dynamics, 238
Small angle neutron scattering (SANS), 28
Small world phenomenon, 581
Smulochowski’s equation, 129, 130
Social networks, 582
Sodium caseinate gels, 315–319, 321–328, 331
678
Index

Soft disordered materials, 338
Softness ﬁeld, 278
Soft particulate gels
elastic modulus and emergence of rigidity, 303–305
microscopic forces and gelation processes, 300–303
stress localization, 305
Solidiﬁcation processes, 297
Solid-on-solid (SOS) model, 618, 622
Space ﬁlling assembly, 302
Spatio-temporal chaos, 101
Spatio-temporal dynamic ﬂuctuations, 243–247
Spiking neuron model, 497–499
architecture of, 501
external stimulus, 509
irregular ﬁring, 503
Spin facilitated models, 262
Spin ﬂip, 195
Spin glasses, 234, 239, 249, 253, 624–625
3-Spin spherical glass mean-ﬁeld model, 240
Spin wave stiffness, 12–13
Stable manifold, 67–69, 110
State of self stress, 215–217, 225
Static yield stress, 338
Stationary probability distribution of money, 644
Stationary quantum chaos, 563–567
Statistical and Nonlinear Physics, 1, 2
Statistical ensemble approach, 422
Statistical errors, 87
Statistical mechanics, 4, 5, 57, 62–63, 349, 479
and granular ﬂuids, 349–351
history, 636–638
importance sampling algorithm, 89–90
money distribution, 638–647
wealth distribution, 647–651
Statistical physics, 1, 658–659
Monte Carlo simulation, 95
Steady state dynamics, 337
Steady state FT (SSFT), 488
Stiffness matrix, 213
Stirling approximation, 639
Stochastic dynamics, 243, 462–463
Stokes-Einstein relation, 245
Stokes ﬂows, 101
Strain softening, 319, 328, 331
Strain stiffening, 319, 326, 328, 331
Stratiﬁcation, 100, 104
Strength distribution, 586
Strength of activity, 518
Stress, 297
localization, 305
Stress-based ensemble, 402
jamming phase diagram, 402–404
Stress pulses, 197–198
Strong turbulence, 107
Structure factor, 234
Subdiffusion, 100, 109
Subgraph centrality, 603
Submodular function, 628–629
minimization of, 629–630
Super-Arrhenius behaviour, 232
Super-Burnett diffusion coefﬁcient, 77
Supercooled liquid conﬁguration, 234
Supercooled liquid state, 518
Superdiffusion, 100, 109
Supersaturation, 135, 138
Super-spreaders, 600
“Susceptible–infected–recovered” (SIR) model, 590
Susceptible–infected–susceptible (SIS) epidemic
model, 590
Swap Monte Carlo algorithm, 272–274
Swimming microrobots, 517
Synthetic active matter, 518
T
Taylor-Couette ﬂow, 100, 102–104
Taylor vortices, 103
Temperature cycling, 280
Thermal activation, 179, 185
Thermal length scale, 187
Thermal noise, 519, 523
Thermodynamic(s), 123, 124, 134–139
average, 169
equilibrium, 517
of small systems, 479
Threshold-linear transfer function, 497
Time-reversed process, 488
Topological band theory, 215
Topological defects, 148
Topological effects, 26, 37
Topological insulator, 222
Topological models, 456–458
Topological multi-line-entanglement, 617
Topological networks, 463
Toral automorphisms, 65
Trace formula, 566
Transcriptional regulation, 454, 466
Transcription factors (TFs), 452
Transient dynamics, 337
Transient FT (TFT), 488
Transient violations of the second law, 479, 487
Transition matrix, 605
Transition probability, 485, 604
Transitivity, 69
Transport coefﬁcients, 58, 60, 69, 70
escape-rate formulae, 71–72
and phase-space contraction, in Gaussian thermostatted
systems, 72–75
Traveling salesman problem (TSP), 612
Triangular lattices, 550–556
Trigger waves, 113
Tube model, 39
Turbulence, 122, 123, 128, 130, 131, 133, 134, 136,
138, 139
homogeneous and isotropic, 131
Two-dimensional optical lattice Bose-Fermi mixtures,
545–547
Two-dimensional XY-model, 7–10
Two-sample Kolmogorov-Smirnov statistics, 373
Index
679

U
Ultracold atomic gases, 528–529
commensurate mixtures, 534–539
coupled low-dimensional superﬂuids, 539–540
2D superﬂuids, 540–544
Kibble-Zurek Mechanism, 544–545
Luttinger liquid of polarons, 529–534
one-dimensional lattices, 529–539
one-dimensional Bose-Fermi mixtures (BFM),
529–534
phase diagram, 548–550
phase-locking transition, 539–540
quantum frustration, 550–556
renormalization group method, 547–548
triangular lattices, 550–556
two-dimensional optical lattice Bose-Fermi mixtures
(BFM), 545–548
Ultrafast ripple oscillations, 509
Ultrastable glasses, 239
Unclogging, 365
arch breaking process, 386–387
cohesive grains, 384
log-log plot, 385
power law, 385
sinusoidal vibration, 384
thermal cycles, 384
weakest link, 385, 386
Uncorrelated random networks, 587
Uniform force orientation distribution, 384
Universality, 147, 157, 159, 160, 398
Unstable manifold, 67, 69, 80, 110
V
van-Hove function, 244
Van Hove intermediate scattering function, 76
Velocity exponent, 152
Ventilation effects, 135
Vibrational density of states, 270
Viscoelasticity, 47
Viscosity, 245, 524
Viscous modulus, 318
Visual data analysis, 662
Vogel-Fulcher-Tammann (VFT) form, 407, 520
Vogel-Fulcher-Tamman (VFT) law, 232
Vortex density function, 13
Vortex systems, 167
Vortex unbinding, 11–12
Vortex unbinding transition, 14–15
W
Wave chaos, 572
Weakening, 197
Weak turbulence, 100, 101, 107
Wealth distribution, statistical mechanics
conserved commodity, models with, 647–648
empirical data, on money and wealth distributions,
649–651
stochastic growth of wealth, models with, 648–649
Weibull distribution, 325
Weighted clustering coefﬁcient, 586
Weighted networks, 578, 586–587
Winding number, 222
Window glasses, 232
Winner-take-all mechanism, 503
Work, 483–485
World Bank, 660
Worm-like chain (WLC), 29
X
X-ray tomography, 380
Y
Yielding transition, 337
680
Index

