Course Guidebook
Science & Mathematics
Topic
Psychology
Subtopic
How You Decide 
The Science of Human 
Decision Making
Professor Ryan Hamilton
Emory University

PUBLISHED BY:
THE GREAT COURSES
Corporate Headquarters
4840 Westfields Boulevard, Suite 500
Chantilly, Virginia 20151-2299
Phone: 1-800-832-2412
Fax: 703-378-3819
www.thegreatcourses.com
Copyright © The Teaching Company, 2016
Printed in the United States of America
This book is in copyright. All rights reserved. 
Without limiting the rights under copyright reserved above,
no part of this publication may be reproduced, stored in 
or introduced into a retrieval system, or transmitted, 
in any form, or by any means 
(electronic, mechanical, photocopying, recording, or otherwise), 
without the prior written permission of
The Teaching Company.

i
Ryan Hamilton, Ph.D.
Associate Professor of Marketing 
Emory University
R
yan 
Hamilton 
is 
an 
Associate 
Professor of Marketing at Emory 
University’s 
Goizueta 
Business 
School, where he has taught since 2008. 
He received his Ph.D. in Marketing from 
Northwestern University’s Kellogg School 
of Management. He also has a B.S. in 
Applied Physics from Brigham Young 
University. 
Dr. Hamilton is a consumer psychologist whose research investigates shopper 
decision making: how brands, prices, and choice architecture influence 
decision making at the point of purchase. His research generally fits within 
the school of behavioral decision theory, examining how contextual factors 
produce decision biases and irregularities. In 2013, he was recognized by 
the Marketing Science Institute as being among the most productive young 
scholars in his field.
Dr. Hamilton has received multiple teaching excellence awards from his 
M.B.A. students at Emory and, in 2011, was named one of “The World’s 
Best 40 B-School Profs under the Age of 40” by Poets & Quants, an online 
magazine that covers the world of M.B.A. education. 
Dr. Hamilton’s research findings have been published in some of the most 
prestigious peer-reviewed journals in marketing and management, including 
the Journal of Consumer Research, the Journal of Marketing Research, the 
Journal of Marketing, Management Science, and Organizational Behavior 
and Human Decision Processes. His findings have also been covered in the 
popular press, including The New York Times, The Wall Street Journal, TIME, 
USA TODAY, The Financial Times, New York magazine, and CNN Headline 
News. He also taught Critical Business Skills for Success (Marketing) for The 
Great Courses.

How You Decide: The Science of Human Decision Making
ii
Dr. Hamilton is the proud father of five young children, which means that he 
spends much of his time exhausted and slightly rumpled. He is also a former 
amateur sketch and stand-up comedian and performed in that capacity in 
clubs and on college campuses across the country. ■

iii
Table of Contents
INTRODUCTION 
Professor Biography . .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  i
Course Scope. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1
LECTURE GUIDES
LECTURE 1
Thinking Scientifically about Decisions. .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . 2
LECTURE 2
The Two-System Model of Decision Making. .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . 10
LECTURE 3
The Role of Heuristics in Decisions. .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . 18
LECTURE 4
How Habits Make Decisions Easier. .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . 26
LECTURE 5
Self-Regulation and Choice . .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . 33
LECTURE 6
The Value Curve and Human Decisions . .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . 41
LECTURE 7
Emotional Influences on Decision Making . .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . 49
LECTURE 8
How Goals Guide Our Decisions . .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . 57
LECTURE 9
Reason-Based Choice. .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . 65

How You Decide: The Science of Human Decision Making
iv
LECTURE 10
Mental Accounting as a Factor in Decisions . .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . 73
LECTURE 11
The Role of Mindsets in Decision Making. .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . 81
LECTURE 12
How Consistency Drives Decisions . .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . 89
LECTURE 13 
Social Influences on Decision Making . .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . 97
LECTURE 14
Nonconscious Influences on Decision Making. .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . 105
LECTURE 15
An Evolutionary View of Decision Making. .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  113
LECTURE 16
Regulatory Focus and Human Motivation . .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . 121
LECTURE 17 
Decision Rules . .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . 129
LECTURE 18
How Context Influences Choice . .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . 138
LECTURE 19
How Framing Effects Guide Decisions. .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . 147
LECTURE 20 
The Role of Memory in Decisions . .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . 154
LECTURE 21
Assortments, Variety, and Choice . .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . 162
LECTURE 22
How Evaluability Affects Decisions. .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . 170
LECTURE 23
Halo Effects and Choice. .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . 178

Table of Contents 
v
LECTURE 24
The Four Rs of Decision Making. .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . 186
SUPPLEMENTAL MATERIAL
Bibliography. .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . 195
Image Credits . .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . 201

How You Decide: The Science of Human Decision Making
vi

1
How You Decide: The Science of 
Human Decision Making
Scope:
Interest in how we make decisions dates back to some of our earliest cultural 
stories. Nearly every branch of science and philosophy has weighed in on 
how decisions are made and how they might be evaluated. In this course, 
we will investigate the most prominent theories that describe how people 
make decisions, the various factors that can influence those decisions, and 
the common shortcuts that can bias the results.
The course is organized around a metaphor of decision making as a 
manufacturing process. In the first part of the course, we’ll discuss the 
cognitive machinery that ultimately produces decisions. These lectures are 
about the cognitive processes that underlie decision making, the features of 
the mind that tend to be general across people. 
Although we have only imperfect control over some of our cognitive 
machinery, we do have some say over how it is used and to what end. In 
the second part of the course, we will discuss the motivational control panel 
that directs our decision-making machinery. These lectures are about the 
motivations people have when making decisions.
The last factor that determines the output of our decision-making apparatus 
is the input: the information we use when making decisions. This information 
is the raw material of our decision-manufacturing process. The lectures in this 
section are about the properties of the options from which we make choices.
The focus of this course is on the fascinating ways this most common of 
human activities can still surprise us. Decision making—that of others 
and even our own—can be mysterious, but with the right tools, it can be 
understood, anticipated, and influenced.

2
Lecture 1
Thinking Scientifically about 
Decisions
P
rotoplast myths, such as the story of Adam and Eve, are stories 
of the progenitors of a people, a race, or all mankind. They are 
important because they tell us something about the fundamental 
values, concerns, and decisions of the people involved in them. As it turns 
out, in many places and cultures, our ancestors were interested in decision 
making—particularly bad decision making—and its consequences. We’ll take 
a scientific approach to this topic in these lectures, but all the experiments 
and theories can’t obscure the intriguing and subtle answers to the question: 
How do we decide? Studying decision making allows us the consistent 
opportunity to be amazed at the results of our own minds.
Limiting Your Spending


If your goal is to save money on consumer purchases, experts agree that 
you should place some limits on yourself before you go shopping. For 
example, if you want to buy a new TV, you should decide on your level 
of spending first. That will keep you from getting carried away when you 
get to the store.


Although this may make sense from a pragmatic perspective, it’s rather 
unusual advice from a decision-theory perspective. 


It’s not news that people make decisions relative to constraints; we 
don’t often buy as if we had infinite amounts of money to spend.


But most theories don’t allow for any change from making spending 
restraints salient. In other words, you only have so much money 
available to you, and your choices are constrained by that limit. 
That will be true whether you articulate an amount beforehand or 

Lecture 1—Thinking Scientifically about Decisions 
3
not. Reminding yourself to not overspend before you go shopping 
shouldn’t matter. Research on this question, however, yields some 
interesting results.


In one study, students were paid $6.00 to complete a battery of surveys. 
Then, they were asked if they would be interested in using some of that 
$6.00 to buy a pen at a steep discount; 85 students said yes.


The participants were randomly assigned to one of two purchase-
decision scenarios. One group was shown a group of four pens, ranging 
in price from $0.99 to $3.99. Participants simply chose the pens they 
liked; then, a research assistant gave them their pens and the $6.00 
participation fee, minus the price of the pen they had chosen. People 
in the other condition were asked to set a spending limit for themselves 
before they saw the options. Then, they chose from the same set of 
discounted pens.


Surprisingly, people who first set a price restraint ended up choosing 
more expensive pens than people who didn’t. On average, people 
spent about $1.64 when they simply chose a pen. When they stated 
how much they were willing to spend first, they spent $2.10 on average.


Looking at the data another way, when people chose without first 
thinking about price restraints, about 60% chose the cheapest pen, 
and only about 2% chose the most expensive pen. 


In contrast, when people thought about how much they might 
spend first, the share of the cheapest pen dropped to about 40% 
and the share of the most expensive pen jumped to more than 12%.


Why does thinking about a price limit before choosing change what 
people chose? And why would it make people choose more expensive 
options?


Close to a dozen similar experiments were run, and the result was 
the same: Deciding how much you planned on spending beforehand 

How You Decide: The Science of Human Decision Making
4
caused people to spend more than those who did not initially set a 
spending restraint.
Decision Making as Manufacturing


A simple metaphor for breaking down complex decisions is to treat 
decision making as a manufacturing process. This process requires 
three things: raw materials to serve as input; machinery that prepares 
and assembles the raw materials into their final form; and a control 
mechanism to govern the machinery in the manufacturing process.


We can treat the “manufacturing” of a decision in a similar way. Each 
decision is the result of some combination of processes in our cognitive 
machinery combined with some (imperfect) governance of that 
machinery via a motivational control panel. These are used together to 
process the various types of informational inputs that constitute the raw 
materials in our metaphor.


Let’s begin with the cognitive machinery of decision making. Although 
there is wide variance in the quality of mental operations from person to 
person—and even within the same person at times—there are still some 
similarities in how we process information and make decisions. 


The two-system model of cognition has recently become popular 
as a way of explaining the often-divergent decisions people make. 


There are also some inherent limitations on decision making; think 
of this as the tolerances, or bounded rationality, of our cognitive 
machines. 


In our manufacturing metaphor, the motivational forces that regulate 
cognitive machinery come next. Think of them as a brightly lit, extremely 
complicated control panel. Sometimes, switches flip and dials spin 
without our being aware of it. Further, some switches and buttons are 
buried deep within the control panel and are activated by something 
else going on in the factory that we may not know about.

Lecture 1—Thinking Scientifically about Decisions 
5


Each decision is made on the basis of some informational inputs that 
we feed into the decision-making machinery. In manufacturing, the raw 
materials tend to be basic and uniform. In contrast, the raw materials that 
people use to inform decisions tend to be quite complex. Sometimes, 
objectively equivalent information can lead to different choices, 
depending on the way that information is communicated. Sometimes, 
objectively irrelevant information can be incorporated into our decisions 
and bias our choices.
The Manufacturing Metaphor and Price Restraints


How might this manufacturing metaphor help us understand the finding 
that setting a price restraint can lead to more expensive choices? This 
finding seems mostly to be a raw material effect. In particular, one of 
the early choices that people make when manufacturing a decision is 
how much weight or importance to give each piece of informational 
raw material.
We can use our cognitive machinery 
to do an astonishing array of things, 
but the human mind is not infinitely 
flexible and runs up against some 
predictable restraints.

How You Decide: The Science of Human Decision Making
6


If you’re making a table with the raw materials walnut and maple, you 
can use mostly walnut and end up with a dark-wood table with light-
wood accents. Or you can use mostly maple and end up with a light-
colored table with dark accents. The emphasis you put on the different 
raw materials leads to the manufacture of two outputs.


The same is true of price restraints. When you set a price restraint, 
you partition the decision into two stages. Instead of answering the 
single question “Which option should I choose?” which generally 
involves making some tradeoffs between price and quality, you ask two 
questions: “How much do I want to spend?” and “Which option should 
I choose?” By asking the price question first, you start to break down 
some of those tradeoffs. 


Suppose you decided that you didn’t want to spend any more than 
$400.00 on a TV. You then go into a store and find two TVs: one 
medium-quality brand for $350.00 and one higher-quality brand for 
$390.00. Without a price restraint, you would have to make a tradeoff: Is 
the better brand worth the extra $40.00?


But if you’ve already decided that you won’t spend any more than 
$400.00, you’ve essentially already decided that anything up to 
$400.00 is acceptable, at least in terms of price. Now, you are faced 
with a choice between a moderate-quality brand at an acceptable 
price or a higher-quality brand—also at an acceptable price. 


When framed that way, of course, you would pick the higher-
quality, higher-priced option. The result is a tendency to pick more 
expensive options after setting a restraint for ourselves on spending.
Breaking down the Process 


Decision making is often too nebulous and general to grasp, but if we 
break it down into three simple components, it becomes much more 
approachable.

Lecture 1—Thinking Scientifically about Decisions 
7


What is the decision we are trying to understand or anticipate? First, 
we can ask: What is the informational input? What options does the 
person have to choose among? How are those options described? In 
what context will they be evaluated? What decision rules will be used to 
process and weight that information?


Next, we can inquire: What are the characteristics of the cognitive 
machinery that will process that information? What biases are likely to 
be introduced as a natural result of the way our minds work? How might 
a person try to make that decision easier?


Finally, what motivations are likely to underlie a person’s decision 
making? What are the goals or deep-rooted drives that can influence 
this person?
Scientific Skepticism


As we saw, the experiments from the beginning of the lecture showed 
the surprising effects of price restraints on decision making, prompting 
a number of questions. For example, some people might question 
whether the effect would still occur if the price restraint were set 
aggressively low; others might be skeptical based on the fact that some 
of the studies used hypothetical choices. 


Such criticisms are not out-of-bounds. All these objections concern what 
scientists call boundary conditions—limits on how far a theory can be 
applied. Boundary conditions let us know that a theory is likely to hold 
under certain conditions but may not under others.


Does the identification of a boundary condition undermine the theory? 
Scientists—particularly social scientists—have identified two ways for a 
theory to be valid: internal and external validity. 


With regard to internal validity: Most scientific research is conducted 
to test causal relationships: Does A cause B? Does smoking cause 
lung cancer? Internal validity means that a theory has successfully 
established a relationship between a cause and an effect.

How You Decide: The Science of Human Decision Making
8


External validity is the degree to which findings can be extended 
(or generalized) beyond the initial settings in which they were 
discovered.


Scientists are, of course, concerned with both internal and external 
validity. But when a tradeoff between the two is necessary—and it 
usually is, at least to some extent—they tend to side more with internal 
than external validity. Obviously, if you are in the business of developing 
theories, it is more important for the theories to be correct than for them 
to be generalizable, although ideally, they would be both. 


As a consumer of research on human decision making, it’s important 
for you to critique research in a responsible and useful way. You should 
be skeptical of all research findings, but not all skepticism is equally 
useful. A threat to internal validity is significant, but when it comes to 
No theory related to 
human decision making 
will hold all the time and 
in every situation.

Lecture 1—Thinking Scientifically about Decisions 
9
skepticism, incredulity about external validity tends to not be as serious 
as disbelief related to internal validity. In general, it’s important to 
remember that no theory related to human decision making will hold all 
the time and in every situation.
Suggested Reading
Larson and Hamilton, “When Budgeting Backfires.”
Plous, The Psychology of Judgment and Decision Making.
Shadish, Cook, and Campbell, Experimental and Quasi-Experimental 
Designs for Generalized Causal Inference.
Questions to Consider
1.	 What is the difference between a normative and a descriptive 
approach to understanding decision making? What are the 
advantages and disadvantages of each?
2.	 What is the difference between internal and external validity? Which 
should scientists care more about? Which type of validity should 
policymakers, government officials, and business leaders care more 
about?

10
Lecture 2
The Two-System Model of Decision 
Making
T
hinkers going back to antiquity have noted that people sometimes 
seem to be directed by two entirely different centers of control. 
More recently, empirical psychology has taken a renewed interest in 
a two-minds approach to understanding the cognitive machinery of human 
decision making. Today, the systems under study are generally known as 
System 1 and System 2. In fact, it turns out that as we receive informational 
input—the raw materials of our decision making—there is more than one 
type of “machine” through which we can feed that information. And the 
characteristics of these two types of cognitive machinery can lead to very 
different decisions.
System 1 and System 2


From an evolutionary perspective, System 1 is the earlier of the two 
cognitive systems. This system is automatic and effortless. It is a parallel-
processing system, meaning that it is capable of performing multiple 
tasks at the same time. System 1 is good at making rough estimates, 
noting correlations, and logging incidences. It also handles the initial 
screening and processing of perceptual information.


In an evolutionary sense, System 2 is a relative newcomer, and compared 
to System 1, it is slow and ponderous. It is a serial processor, meaning 
that it doesn’t multitask well. And it requires us to devote cognitive 
resources for it to operate properly. However, this system is able to 
handle diverse tasks. It is also a deliberate system, meaning that we can 
control and direct it. System 2 is good at making precise calculations, 
forming and following rules, and making tradeoffs.

Lecture 2—The Two-System Model of Decision Making 
11


Amazingly, System 2 can train System 1. In fact, some psychologists 
have suggested that this may be the ultimate purpose of System 2: to 
teach our automatic system to do new tricks. For example, when you 
first learned to drive a car, that complex tangle of decisions and actions 
required your full attention; System 2 was fully engaged. But within a few 
months, your approach changed completely. You now go through all the 
same motions and process the same amount of complex information 
without focusing all your attention on the task.
We can see the process 
of System 2 training 
System 1 by observing 
a toddler who is just 
learning to walk.

How You Decide: The Science of Human Decision Making
12
Approval and Override


Six modes of interaction are possible between System 1 and System 2: 
approval, override, neglect, influenced, informed, and solo operation. 
Each of these labels describes the role of System 2 in the process of 
making a decision.


Let’s begin with approval. Imagine that you are walking down the street 
and you pass an ice cream parlor. System 1, the repository of all our base 
desires and instinctual behavior, immediately craves ice cream. System 
2, feeling the urge to get some ice cream bubble up from System 1, 
decides that some ice cream is indeed in order. This is approval.


Note that the System 1 response doesn’t have to be appropriate, 
wise, or even factually correct for it to be endorsed by System 2. The 
response may not even have been closely scrutinized by System 2. 


Approval means only that System 2 had the opportunity and 
ability to acknowledge the System 1 response and allowed it to go 
through.


In contrast to approval, override takes place when System 2 prevents 
us from acting on the System 1 response and, instead, overrides it with 
something it deems more appropriate. 


People differ in terms of how likely they are to override System 1 
responses and engage in System 2 processing. Shane Frederick, from 
Yale University, developed a three-question test of this natural difference. 


Question 1: A bat and a ball cost $1.10 in total. The bat costs $1.00 
more than the ball. How much does the ball cost?


Question 2: If it takes 5 machines 5 minutes to make 5 widgets, 
how long would it take 100 machines to make 100 widgets?


Question 3: In a lake, there is a patch of lily pads. Every day, the 
patch doubles in size. If it takes 48 days for the patch to cover the 
entire lake, how long would it take for the patch to cover half the 
lake?

Lecture 2—The Two-System Model of Decision Making 
13


If you answered $0.10, 100 minutes, and 24 days, you are a typical 
human being, and you are wrong on all three counts. The real answers 
are: $0.05, 5 minutes, and 47 days. All three of these questions share 
a common formulation. They are all questions for which there is an 
obvious, intuitive answer that is also obviously wrong. 


Frederick argued that this cognitive reflection test measures the 
natural tendency of someone to engage in System 2 processing. 
For all these questions, an intuitive answer was available and 
seemed reasonable at first glance. It is only those who truly want 
to engage in additional processing who will find the correct, 
nonintuitive answers. 
Neglect


The third way that these two systems can interact is neglect. Neglect 
takes place when System 2 is distracted, exhausted, or otherwise unable 
to fulfill its oversight responsibilities.


A set of experiments published under the title “Heart and Mind in 
Conflict” investigated decision making under both an override mode 
and a neglect mode. 


In one of the experiments, participants were given a choice 
between eating a piece of chocolate cake or eating a fruit salad. 
Before making their choice, they were given what psychologists call 
a cognitive-load manipulation. This is a task designed to occupy 
the participants’ short-term memory and keep them mentally 
distracted. In terms of our discussion, a cognitive-load task is 
something that requires System 2 processing. 


In this case, people in the low-cognitive-load condition were asked 
to remember a two-digit number, and those in the high-cognitive-
load condition were asked to remember a seven-digit number. 


Researchers found that given the choice between the chocolate 
cake and the fruit salad, 41% of the people who were cognitively 

How You Decide: The Science of Human Decision Making
14
unburdened chose the cake. But among the group who had System 
2 occupied with the harder memorization task, 63% chose the cake.


This is a powerful demonstration of neglect in action. We can 
assume that, for most people, System 1 always wants the cake. 
But because System 2 is in charge of managing higher-order goals 
(such as losing weight), it often overrides System 1. 
When System 2 is otherwise 
occupied, it is less able to 
restrain System 1 and more 
likely to allow us to choose 
the chocolate cake or ice 
cream through neglect.

Lecture 2—The Two-System Model of Decision Making 
15


When System 2 is otherwise occupied, such as in trying to 
remember a long number, it is also less able to restrain System 
1. In this experiment, the result was about a 50% increase in the 
percentage of people choosing the chocolate cake.
Influenced


The fourth way that these two systems can interact occurs when System 
2 is influenced by System 1. This looks similar to override in that System 
2 rejects the System 1 response, but in this case, System 1 insidiously 
biases or influences the System 2 response. 


For example, you walk past the ice cream parlor; System 1 wants you 
to go inside, but System 2 tamps down that base response. However, 
even though you passed up one temptation, System 1 keeps thinking 
about ice cream, below the surface. Later, you find that you have an 
unexpected urge to dish up some ice cream after dinner. System 2 was 
initially successful at blocking the System 1 response, but System 1 still 
influenced the System 2 response.


The baseline (control) group answered only one survey. This group 
got the question “Have you purchased a car in the previous six 
months?” and about 2.4% answered yes. 


Another group answered two surveys, delivered six months apart. 
In the first survey, group members were asked when they planned 
on purchasing their next new car, with the options ranging from six 
months or less to never. Then, about six months later, this group 
was asked whether they had purchased a new car in the last six 
months.


The researchers were interested in the following question: Does 
answering a neutral survey question about when you might buy a 
new car increase the likelihood that you will actually buy one? 


The baseline condition—the nearly 5,000 people who responded 
to the survey just once—included about 2.4% who had recently 

How You Decide: The Science of Human Decision Making
16
purchased a new car. In contrast, in the treatment condition—
the 3,500 who were first asked when they planned to buy a car, 
then asked if they had recently bought a car—the purchase rate 
increased to 3.3%. That may not seem like much in absolute terms, 
but remember that the subject here is buying a car and that the 
only manipulation was a single question on a mail-in survey. The 
overall purchase rate increased by about 50%.


This is known as the mere measurement effect—the idea that simply 
asking people about a possible behavior can increase the likelihood 
that they will engage in that behavior. It may be one manifestation of a 
System 2 response being influenced by System 1. When asked when they 
are likely to buy their next new car, people engage in a kind of mental 
simulation, considering what life would be like with and without a new car, 
and at least some of this consideration process engages System 1. That 
seed, once planted in System 1, can eventually flower into something that 
influences System 2 choices, even the decision to buy a car.
Informed


The fifth type of interaction between the two systems occurs when 
System 2 is informed by System 1. System 1 can provide information 
about how easy or hard it is to recall something or to generate examples 
of something, and that information can be used by System 2 when 
making judgments and decisions. 


For example, you might try to assess how reliable Hondas are by trying 
to think about times you have seen a Honda broken down on the side of 
the road. As you do so, System 1 can helpfully provide the information 
that generating examples is difficult. System 2 could then use that 
information to determine that if it is hard to come up with examples of 
broken Hondas, then Honda must be a reliable brand.

Lecture 2—The Two-System Model of Decision Making 
17
Solo Operation


The last way to characterize the interactions between these two systems 
is solo operation. System 1 is a wonderfully complex and capable set 
of cognitive machinery, but it can’t do everything, and for the things it 
can’t help with, System 2 is on its own. 


For example, for most people, System 1 can’t help with doing long 
division or balancing a checkbook. Unless you have specifically trained 
your System 1 to do these types of tasks, then System 2 must engage in 
solo operation.
Suggested Reading
Kahneman, “Maps of Bounded Rationality.” 
———, Thinking, Fast and Slow.
Questions to Consider
1.	 Define the two systems in the two-system model of decision 
making. What does System 1 do? What does System 2 do?
2.	 What are the various ways that System 1 and System 2 interact 
when making a decision? Think of examples from your own life or 
observations from others that might be characterized as each type 
of interaction.

18
Lecture 3
The Role of Heuristics in Decisions
S
o far, we’ve been laying the groundwork for understanding our 
cognitive machinery—those common mental processes and functions 
we all share. And we’ve used the two-system model of decision 
making. The popularity of this model is due, in part, to the efficiency with 
which it explains many different kinds of decision phenomena. We’ll spend 
the next several lectures exploring some of the implications of this two-
system model as they relate to decision making. In this lecture, we’ll look at 
the role of heuristics in decision making and how some common heuristics 
can be explained by the two-system model of cognition.
Defining Heuristic


A heuristic is a way of simplifying a complex process. In psychology, it 
almost always refers to simplifying the process of making a judgment 
or a decision. Common heuristics include educated guesses, rules of 
thumb, trial and error, and stereotyping and profiling. None of these 
heuristics guarantees a correct decision, but they will serve you well 
most of the time. 


Heuristics simplify things in ways that increase the likelihood of arriving 
at an acceptable outcome. Many heuristics operate by substituting an 
easy-to-solve problem for the hard-to-solve problem to which you really 
need an answer. Common heuristics also tend to leverage the strengths 
of our cognitive machinery and minimize the weaknesses.


The most interesting types of heuristics for decision researchers are 
those that are not deliberate rules we set for ourselves but common 
shortcuts that seem to be universal. A few heuristics have been 
especially important to understanding human decision making, including 
anchoring and adjustment, availability, and representativeness.

Lecture 3—The Role of Heuristics in Decisions 
19
Anchoring and Adjustment


People use the anchoring-and-adjustment heuristic when making 
numerical estimates. The basic idea is that when you need to produce 
an estimate of something, such as someone’s height, you tend to start 
with some number that you know, then make some adjustment based 
on the particulars. If you were to try to estimate how tall someone is, 
you might start with the knowledge that the average man in the United 
States is 5 feet, 10 inches tall and try to estimate how much taller or 
shorter your subject is from that starting point. 


These kinds of estimates are a common precursor to many of the 
decisions we make. Are you going to invest in a rental property? That 
decision will involve some estimate about the likely return on the 
investment. Should you start a garden this spring? That decision will 
probably be based on an estimate of how much time it will take to plant 
and tend the garden. 


People often run into two particular problems when using the anchoring-
and-adjustment heuristic. The first is that they sometimes start with an 
inappropriate anchor. The second is that when people adjust, they tend 
to under-adjust, sticking too close to their starting point. 


Suppose someone were to ask you to estimate the temperature at which 
water boils at the top of Mount Everest. You probably know that at sea 
level, water boils at 212° F. You may even remember that the boiling 
point changes depending on air pressure. If you had started with 212° 
as an anchor and adjusted from there, you’d likely be fairly close to the 
real answer. But that’s not the answer researchers received when they 
ran an experiment using just this question.


First, before participants gave their estimates, the experimenters 
asked them to answer one of two questions: (1) whether the boiling 
point of water at the top of Mount Everest was above or below 50° 
F or (2) whether it was above or below 500° F. 


The initial question wasn’t hard to answer, but simply asking the 
question was enough to cause people to fall into of one of the 

How You Decide: The Science of Human Decision Making
20
traps of anchoring and adjustment: They started their estimates 
using the wrong anchor. It is as if System 1 was influenced by the 
salience of another number intruding just at the moment when the 
initial anchor was being generated. 


People who were asked whether the temperature was above or 
below 500° estimated an average temperature of 274°. Those who 
were asked whether it was above or below 50° estimated 134°.


People may have assumed that the anchor in those questions was 
intended to be informative. But what if the number clearly and obviously 
had nothing to do with the estimate at hand? 


In another demonstration of anchoring, researchers asked 
participants, “What percentage of countries in Africa are members 
of the UN?” But before accepting answers, the researchers spun 
a wheel—right in front of the participants—to generate a random 
number. Participants were asked whether the percentage was 
higher or lower than that random number, then were asked for their 
own estimates.


For example, when the wheel stopped on 10, participants were asked 
whether the percentage of African countries in the UN was higher 
or lower than 10%. Then, they made their estimates. The median 
estimate in this case was 25%. In the case where the experimenter 
spun a 65, the median value was 45%—a full 20% higher.


To understand how anchoring and adjustment works, let’s go back to 
the two-system model of cognition. 


Recall that one of the ways the two systems interact is in the 
influenced mode. Here, System 1 provides some response, but 
System 2 disagrees and stops the System 1 response. Instead 
of a clean override, however, System 1 influences or biases the 
response, even if we are not aware of it. 


Anchoring and adjustment might be considered another example 
of System 1 influencing the System 2 response. The results of 

Lecture 3—The Role of Heuristics in Decisions 
21
research on anchoring and adjustment suggest that System 1 can 
become fixated on a salient number—even numbers completely 
unrelated to the task at hand—and that those unrelated numbers 
can influence the System 2 response. 
Availability


People use the availability heuristic when they are trying to determine 
the likelihood of some event. These likelihood estimates affect all kinds 
of decisions, such as which colleges to apply to, where to eat lunch, or 
whether to buy travel insurance. 


Availability substitutes an easier problem for a more difficult one. For 
example, if you are estimating the likelihood of a flood in your area in 
the near future, you might try to think of examples of floods in areas 
similar to yours. If it’s easy to think of examples, then you may estimate 
the likelihood of a flood as relatively high.


Availability is an example of an informed interaction. In other words, 
the System 2 response is informed by evidence provided by System 1 
about how the mind works—in this case, how hard it was to remember 
something or imagine some outcome. With availability, your own effort 
becomes the input to your estimate.


The problem here is that many things can influence how easy it is to 
bring something to mind that have nothing to do with the likelihood 
of the event happening. In general, things that are more familiar, more 
recent, and more vivid will all be easier to recall or imagine. That means 
that the likelihood of events with any or all of those properties tends to 
be overestimated. 
Representativeness


Representativeness is like availability in that they are both ways of 
estimating probabilities. But where availability uses ease of recall 
as a cognitive shortcut, representativeness uses the representative 

How You Decide: The Science of Human Decision Making
22
characteristics of a category, schema, or stereotype to determine 
likelihood. Basically, representativeness is useful when you are trying to 
determine the likelihood that some specific thing is a member of some 
category. 


Representativeness generally works fairly well most of the time, 
but it can present two problems. The first problem relates to the 
law of small numbers. Any good statistician will tell you that to draw 
reliable conclusions about a population, you need a large sample of 
observations from that population. The law of small numbers refers to 
the misguided tendency people have to believe that small samples 
should be representative of a population. Essentially, they ignore or 
misunderstand the potential for variability in small samples.


Suppose you took a fair coin and flipped it four times, getting a 
tail each time. You then asked a friend to place a $10.00 bet on 
the outcome of the next flip. If your friend is like most people, he 
or she will put money on the flip coming up heads. Essentially the 
People dramatically 
overestimate the likelihood 
of getting attacked by a 
shark, in part because of 
the vividness of media 
coverage of such attacks.

Lecture 3—The Role of Heuristics in Decisions 
23
logic goes like this: Your friend knows that a fair coin should come 
up heads as often as it does tails; four tails in a row means that 
heads is now “due.”


But the coin doesn’t have a memory. It doesn’t know which side 
came up the last time it was flipped. Each flip is as likely to come 
up heads as tails, regardless of what happened in the past. 


To demonstrate the second problem with representativeness, consider 
this question: If you observe someone on the subway, what is the 
likelihood that that person has a Ph.D. versus not having a college 
degree? To make that kind of estimation, you’d probably start by looking 
the person over and trying to determine whether he or she “looks” like 
someone with a Ph.D. or someone without a degree. 


Let’s suppose you see this person doing something that seems 
intelligent, such as reading The New York Times Book Review, 
while riding the train. Surely, that would increase your prediction 
that this person has a Ph.D. In this case, you are using whatever 
evidence is available to improve your judgments, and that’s not 
entirely wrong. 


The problem here is that people make adjustments based on 
new information, and they often completely neglect the base-rate 
probabilities when they do. 


Reading the New York Times Book Review seems as if it’s a 
thoughtful and scholarly activity—characteristics we tend to 
associate with those who have a Ph.D. Thus, because this person 
resembles a stereotypical Ph.D. in a few important ways, we jump 
to the conclusion that he or she is likely to have a Ph.D. People 
may even say that, based on the evidence, it is more likely that the 
person has a Ph.D. than no degree at all.


But such estimates completely disregard the base rate, that is, the 
likelihood that a random stranger on a train would hold a Ph.D. It 

How You Decide: The Science of Human Decision Making
24
The representativeness heuristic is 
what allows us to see a spectacular 
high school athlete and 
confidently proclaim that he is sure 
to go pro, even though only about 
0.03% of high school basketball 
players are ever drafted.

Lecture 3—The Role of Heuristics in Decisions 
25
turns out that less than 1% of the U.S. population has a Ph.D., and 
about 70% do not hold college degrees. 


Unfortunately, representativeness causes many problems related to 
stereotyping. For example, evidence suggests that far too often, hiring 
decisions are made not based on information that actually correlates 
with eventual performance but, instead, on how well the person fits the 
stereotype of someone who does that job.
Suggested Reading
Kahneman, Slovic, and Tversky, Judgment under Uncertainty.
Tversky and Kahneman, “Judgment under Uncertainty.” 
Questions to Consider
1.	 What is the purpose of a heuristic? Why do people use them? What 
are the advantages and disadvantages relative to more effortful and 
accurate forms of decision making?
2.	 For which types of decisions might a person rely on each of the 
three heuristics discussed in this lecture? Think of times when you 
or someone you have observed may have used each heuristic.

26
Lecture 4
How Habits Make Decisions Easier
I
n this lecture, we’ll talk about habits, specifically, how they’re formed and 
what can trigger them. Psychologists already know a number of important 
features of habits: First, habits require some kind of cue or trigger to 
activate them. Second, habits are formed when the decisions or behavior 
triggered by some cue results in a consistent reward over time. And third, 
habits work by shifting something that would normally be a deliberative, 
effortful decision into an easy, automatic one. We’ll also see that the two-
system model allows us to better understand habits. 
Habits and the Two-System Model


The prototypical habit is a bad habit, something we wish we didn’t do 
but we find ourselves doing anyway, such as humming while working or 
smoking. From a psychological perspective, those are definitely habits, 
but habits are also much broader than that. When we think about habits, 
we shouldn’t limit ourselves to just automatic behaviors or even just to 
specific actions. Habits can also be any general tendency to respond to 
particular cues in predictable ways. Such cues can include the activation 
of certain desires or motivational states, the availability of certain 
memories, and the salience of certain decision strategies.


As we’ve learned, one of the predominant theories researchers use to 
characterize our decision-making machinery is the two-system model of 
cognition. We have one slow, deliberate, effortful system—System 2. This 
is the conscious mind, the part of the self to which we have direct access. 
And we have one fast, automatic, effortless system—System 1. This two-
system model provides us with one way of understanding habits.

Lecture 4—How Habits Make Decisions Easier 
27


One of the evolutionary benefits of having two cognitive systems, 
according to psychologists, is that the higher-order System 2 can train 
the lower-order System 1 to do repetitive tasks. 


This is a significant advantage to us because System 2 consumes 
attention and energy and is generally able to do only a limited 
number of things successfully at one time. System 1, in contrast, 
can be thought of as more or less free from a cognitive resources 
perspective. If we can train System 1 to take over some of the tasks 
that we currently have System 2 doing, System 2 can work on other, 
more important things.


This is the true benefit of habits; this is why we have habits and why, 
ultimately, they are a good thing for us as a species, even if they 
occasionally work against our better interests.


From a psychological perspective, habits are a general tendency 
for System 1 to respond in a certain way, based on exposure to 
a particular cue or trigger. Habits turn what would have been a 
deliberative, System 2 decision into a habitual, System 1 decision.
Training System 1


Training System 1 to adopt certain habits can be difficult but not 
because System 1 is a bad student. In fact, in almost any situation, 
System 1 is looking for opportunities to help; to automate what it 
has been programed to automate; to provide memories, emotions, 
or intuitions that seem as if they might be relevant to the situation at 
hand. Sometimes, System 1 provides just the information you need. 
More often, it provides the information you need, along with irrelevant 
information. And sometimes, System 1 is simply way off.


As an example, one study examined people who frequented live sporting 
events. The researchers hypothesized that people who go to these events 
often develop habitual behaviors associated with being at a game. 


In the study, the researchers subtly exposed participants to pictures 
of large stadiums and arenas. In particular, they had participants 

How You Decide: The Science of Human Decision Making
28
perform a visual search task, in which the background images 
were of either sports venues or kitchens. Then, in the context 
of an ostensibly unrelated task, they measured how loudly the 
participants spoke. They found that participants who had been 
exposed to images of a stadium actually spoke louder than people 
who had been exposed to images of kitchens. 


The logic is that when exposed to the image of a stadium, System 
1 jumps to attention. The stadium activates some of the thoughts, 
memories, and feelings typically associated with being at a sporting 
event. And one of the common behaviors for those attending live 
sporting events is that you typically need to speak much louder 
than usual to be heard by others. System 1 remembers this and 
helpfully pushes closer to the surface the intuition to speak louder, 
leading to the incongruous response of speaking louder even when 
there is not a need to.
Triggers


The most straightforward kind of trigger comes when some kind of 
environmental stimulus—some sight, sound, smell, taste, or touch—
kicks off a habitual behavior. 


For example, most animal-training programs use a simple pattern 
of stimulus-response-reward, reinforced through repetition. This is 
called conditioning. 


The animal becomes aware of some stimulus, such as a particular 
verbal command. If the animal performs some action after sensing 
the stimulus, then it receives a reward. Over time, it starts to 
understand that certain behaviors, when performed after the 
stimulus, elicit rewards; thus, we get habitual animal responses.


One way to think about habits is as the conscious System 2 mind 
training the intuitive System 1 mind into automatic responses through 
the simple process of stimulus-response-reward. Indeed, the major 
difference between habit formation and animal conditioning is not in 

Lecture 4—How Habits Make Decisions Easier 
29
the process itself. Rather, it stems mostly from the fact that humans are 
much more flexible in terms of what can serve as stimulus and what can 
serve as reward.


When you are training an animal, you are fairly limited in terms 
of stimulus. Depending on the animal, you can use some verbal 
commands, hand signals, or a whistle. But when you’re training yourself, 
the sky’s the limit. Even something situational and somewhat nebulous, 
such as the end of a meal, can serve as a cue that can kick off habitual 
behaviors, including a craving for dessert, coffee, or a cigarette. 
System 1 recognition of certain 
environmental cues can lead 
to all kinds of habitual decision 
making, such as the trigger of 
finishing dinner in a restaurant 
leading to the habitual 
decision to order dessert.

How You Decide: The Science of Human Decision Making
30


The other way habit formation differs from animal conditioning is in the 
breadth and variety of things that can serve as rewards. When scientists 
train rats and pigeons in a lab, the reward is usually a food pellet. A 
family pet might get trained using treats, attention, and affection. And 
people respond to the same types of rewards: food, affection, and 
approval. But people also respond to a much broader set of rewards, 
including cognitive efficiency. 


As you recall, habits are valuable because they free up System 2 
to do other things. The cognitive savings achieved can serve as a 
reward that can lead to a habit. 


Much to the consternation of marketers, many of our common 
purchases are the result of habitual decision making. When buying 
toothpaste, most of us don’t start with a complete survey of all 
the toothpastes available on the store shelves. We don’t carefully 
weigh the performance of all options every time we go to the store 
and only then reach a purchasing decision. 
For many people 
today, simply doing 
nothing now serves 
as a trigger to check 
their phones.

Lecture 4—How Habits Make Decisions Easier 
31


Instead, we tend to stick with the same brand we’ve always bought, 
because making thorough and well-informed decisions can be 
exhausting. Avoiding that work is a reward that can motivate the 
formation of habits.


Alleviating boredom can also serve as a reward. This is the primary 
reason that many of us have formed the habit of reaching for our phones 
any time we find ourselves with a few minutes of peace. We find being 
alone with our own thoughts aversive. Indeed, some research found that 
when experimenters gave people the choice between sitting alone and 
doing nothing and receiving mildly painful electric shocks, people chose 
to endure physical pain rather than be bored. 


Finally, habits among humans can form much faster than conditioning 
can train an animal. 
Summing Up Habits


Why are good habits in particular so difficult to form, while bad 
habits can form so quickly? The answer mostly comes down to reward 
reinforcement. For most of us, the activity of running offers some distant, 
nebulous rewards. If we go running every day, we may live a little longer, 
but that’s time at the end; we’re not getting that extra time in our 20s. 
That reward seems very diffuse. In contrast, the reward of not getting up 
early to run is immediate and palpable: You get to sleep longer. It’s not 
hard to understand why sleep wins out over running for so many of us in 
the habit formation war.


Habits are not insurmountable, uncontrollable urges. Because we 
sometimes talk about habits in the context of chemical dependencies—
such as smoking habits or drug habits—we may conclude that habits are 
forces compelling us to behave in one way or another, things that are 
nearly impossible for us to resist.


Although that certainly is an accurate description of some habits, 
remember that to psychologists and decision researchers, habits 

How You Decide: The Science of Human Decision Making
32
describe a broad class of cognitions and behaviors. Some are powerful 
and consuming, but many are just a general inclination to behave in a 
certain way—or to choose in a certain way—based on exposure to some 
specific cue or trigger.


The reason habits are important in understanding decision making is not 
because they are so powerful as to be irresistible, but because we are so 
willing not to resist them. When we think of habits as trained System 1 
responses, then we understand that habits will lead to actual decisions 
and behaviors only when System 2 either approves or neglects System 
1 urges. Habits don’t allow System 1 to highjack our minds and our 
decision making. 


Habits fit into a class of simplifying decision processes that includes 
heuristics and simplified decision rules. Like all these simplifying 
processes, habits are generally adaptive; they allow us to make 
decisions more efficiently. But as is also true of simplifying processes, 
this efficiency comes with some tradeoffs—namely, that habitual 
decisions will most often be those that appeal to System 1. And unless 
we are very careful in training System 1, those habitual decisions can 
easily become decisions we regret.
Suggested Reading
Duhigg, The Power of Habit. 
Wood and Neal, “A New Look at Habits and the Habit-Goal Interface.”
Questions to Consider
1.	 Why do people form habits? What advantages do habits provide?
2.	 What is the process by which habits are formed and reinforced? 
How can you use this knowledge to break a bad habit?

33
Lecture 5
Self-Regulation and Choice
I
n this course, we’ve described decision making as a machining process, in 
which our cognitive machinery processes raw informational input into the 
choices we ultimately make. The two-system model of cognition helps 
explain some of the strengths and limitations of our cognitive machinery. But 
like any machine, our cognitive machinery requires resources to run properly. 
One of the resources that our minds require to function well and make good 
decisions is known as the executive resource, or the ego resource. When 
this resource runs low, certain cognitive operations—especially those that 
require self-control or self-regulation—tend to not work as well.
Executive Function


The executive function is one important feature of which System 2 is in 
charge, but the two are not equivalent. The executive function is the 
control room of the brain, the part that directs the rest of the mind and 
the conscious. And it is where self-control resides.


The executive function is a set of cognitive faculties spread across the 
brain. Executive resources are theoretical constructs used to describe 
and explain observed phenomena.


The executive function is in charge of many things, but its self-regulatory 
functions are primarily related to four domains: attention control, 
emotion regulation, impulse override, and behavioral modification.


Attention control directs the attention where it should be, rather 
than where it seems to want to go. 


Emotion regulation is fairly straightforward. Sometimes, you feel 
some strong emotion, such as anger, but you are in a setting 
where it is inappropriate to express that emotion, such as at a staff 

How You Decide: The Science of Human Decision Making
34
meeting. Emotion regulation is that part of the executive function 
that keeps you from getting fired.


Impulse control is any tamping down of base urges. It allows you to 
stick to your diet and keeps you from blurting out what you really 
think of your friend’s new dress. 


Finally, behavioral modification takes place when you change some 
ingrained or automatic behavior.


One way of generalizing across all four of these domains is that they all 
describe a situation in which System 2 is trying to override a System 1 
response. Thus, one way to think about executive function failures is as 
System 2 failing to reign in System 1. 
When the executive function does not 
have enough resources to function 
properly, we start seeing more System 
1 responses slip through—more 
emotional outbursts, more cheating on 
diets, more skipping the gym.

Lecture 5—Self-Regulation and Choice 
35
Resource Depletion


Ironically, self-regulation is often what leads to self-regulation failures. In 
other words, whenever we exercise self-control in the four domains, we 
are consuming some portion of the limited pool of resources required to 
further operate the executive function. 


Consider the executive function as a machine requiring fuel to run 
properly. When you use a machine to do some work—say, your lawn 
mower—you consume some of the fuel from the fuel tank. You may be 
able to mow two or three times without having to worry about the fuel 
reserves. At some point, however, the work done by the machine will 
have burned through all the fuel, and the mower will stop working and 
won’t work again until you replenish the fuel supply.


You can think of executive function in the same way. Exercise self-control 
every once in a while, and there is no problem. But exercise a great 
deal of self-control over a short period of time, and the self-control 
“machine” runs low on fuel and stops working as well. Those resources 
will replenish with time, but over the short term, it’s possible to run low.


Of course, there is no separate fuel supply for each domain of self-
control. We don’t have one gas tank for sticking to a diet and a different 
one to keep us from venting our frustrations. There is a unitary executive 
resource that powers our unitary executive function. Thus, any taxing bit 
of self-regulation in any domain is likely to leave us prone to self-control 
failures in another domain. 
Research in Executive Resource Depletion


There are essentially two ways that depletion effects collide with decision 
making. The first we’ve already talked about: When our resources have 
been depleted, the decisions we are likely to make change—especially 
when those decisions involve exercising self-control. When executive 
resources are not available, we tend to favor System 1 decisions.

How You Decide: The Science of Human Decision Making
36


The second way that ego depletion interacts with decision making is 
that decision making can cause depletion. According to some recent 
research, the act of making a decision is an act of the executive function 
and, as such, consumes some of those precious resources that are also 
required for self-control. The result is that after making decisions, we 
may have fewer of those resources available for other things, such as 
self-regulation.


Researchers have run a number of experiments to investigate this 
phenomenon. In one study, some people were asked to make 
basic consumer choices in such categories as t-shirts, scented 
candles, and shampoos. People in the other condition saw some 
advertisements and were asked to rate how much they liked them.


After this, everyone had to perform a self-control task: to plunge 
his or her arm up to the elbow in a vat of freezing-cold water and 
hold it there as long as possible. 


Those in the control condition, who made no choices beforehand, 
were able to hold their arms in the water for, on average, 67 
seconds. People who had previously made several simple decisions 
were able to hold their arms under water for only about 28 seconds.


In another study, researchers intercepted people coming out of a 
shopping mall and administered a survey asking them about their 
decision making during that day’s shopping. 


At the end of the survey, participants were faced with a page of 
100 addition problems that each required summing two 3-digit 
numbers. People were asked to do as many as they could but were 
also told that they could quit any time they wished.


Consistent with the initial hypotheses, the researchers found that 
the more decisions the shopping-mall customers had made and the 
harder they had worked on their decisions that day, the fewer math 
problems they were willing to do and the fewer they got right.

Lecture 5—Self-Regulation and Choice 
37


Other research into a specific depletion effect investigated the effects 
of mindset switching. For psychologists, mindsets refer to any group 
of cognitive procedures that are geared toward preparing a person to 
react in a particular way. But we can think of these as what happens 
any time you mentally “switch gears” or take on different perspectives. 
When you think about a particular problem in multiple ways, you are 
probably engaging different mindsets. 


The researchers hypothesized that mentally switching gears 
required self-control, and as such, it consumed self-regulatory 
resources. The researchers also hypothesized that among the 
different types of mindsets or mental gears that people use are 
those associated with different types of decision-making strategies. 


Note that people can use different rules or strategies for making 
a decision based on the same set of underlying information. 
Some decision rules emphasize motion and action—for example, 
Many businesspeople find 
it helpful to wear suits of 
only one or two colors to 
minimize the decision-
making energy they must 
use throughout the day.

How You Decide: The Science of Human Decision Making
38
by eliminating options one by one until there is only one choice 
available. Other decision rules are more deliberative, actively 
comparing alternatives in a thorough way before making a choice. 


The researchers suspected that these types of decision rules were 
different enough that they might activate different mindsets in the 
people making the decisions. That meant that anyone required 
to switch between different styles of decision making would be 
especially likely to get depleted.


This hypothesis was tested in a number of experiments. Participants 
made choices in 10 categories: cell phones, refrigerators, 
apartments, camcorders, athletic shoes, PDAs, pillows, vacuum 
cleaners, deodorants, and MP3 players. In each category, they had 
to choose among 5 options, each described by several attributes.


Participants were also instructed exactly how they were to make 
their decisions. Some were told to make their decisions in a 
thorough and deliberative way, comparing each option to all the 
others on every attribute. Other participants were told to make 
their decisions in a way that emphasized motion by eliminating the 
options one at a time until they had a winner. Most important, some 
participants were instructed to switch between those two decision 
styles on every other choice. 


The dependent variable came from a different self-regulation 
domain: emotion regulation. People watched several minutes of 
a funny stand-up comedy routine while their facial reactions were 
filmed. They were told to show no emotion as they watched the 
funny clip. The dependent measure was how successful people 
were at suppressing their emotions and maintaining a neutral 
expression versus cracking the occasional smile.


On average, people were found to be about twice as bad at 
maintaining a neutral expression when they switched back and 
forth between decision strategies as they were when they used a 

Lecture 5—Self-Regulation and Choice 
39
single decision strategy. In short, changing the strategy or rules one 
uses to make decisions consumes executive resources, increasing 
the likelihood of self-control failures later.


This result was found to be true when people had to switch 
mindsets of all kinds—switching from thinking about something 
in an abstract way to a concrete way, or switching from approach 
to avoidance mindsets, or even switching between languages for 
bilinguals. Every time people switched between mindsets, they 
were subsequently worse at self-regulation relative to people who 
did the same tasks but didn’t switch mindsets.


The implications of this research are that people should try to 
avoid switching mental gears too frequently. If you have a job 
that requires you to wear multiple hats—such as an accountant 
who does both auditing and forecasting—it might be worthwhile 
to chunk those tasks so that you are not switching back and forth 
throughout the day. 
Self-Regulatory Depletion


If we think about depletion as primarily driven by trying to resist System 
1 impulses, we should remember that the same things will not deplete 
everyone equally. For example, for those who have never smoked, 
resisting a cigarette requires no self-control. For a long-time smoker, 
in contrast, System 1 has been trained to respond to the rewards of 
smoking. For that person, resisting the urge to have a cigarette requires 
effort from the executive function. 


The last thing we need to remember about self-regulatory depletion is 
that these effects are temporary. Our cognitive machinery can run low 
on resources in the short term, but over time, these resources replenish. 
Understanding how depletion works helps us understand the cognitive 
machinery of decision making better, and it may even help us make 
better decisions ourselves.

How You Decide: The Science of Human Decision Making
40
Suggested Reading
Baumeister and Tierney, Willpower.
Baumeister and Vohs, “Self-Regulation, Ego Depletion, and 
Motivation.”
Questions to Consider
1.	 Describe the role of the executive function in decision making. How 
does it facilitate or inhibit the choices we make?
2.	 What domains are subject to self-regulatory depletion? What types 
of decisions might be influenced by depletion effects?

41
Lecture 6
The Value Curve and Human 
Decisions
I
f you are interested in the cognitive machinery that manufactures 
decisions, then behavioral anomalies are gold mines. Those settings and 
situations where people consistently diverge from clean, rational models 
are clues about what is really going on inside a person’s mind. The godfathers 
of modern decision science are Nobel Prize–winner Daniel Kahneman and his 
longtime research partner, Amos Tversky. They called their fledgling decision 
model prospect theory because it was largely developed by examining how 
people evaluated different gambles, or prospects. The part of prospect 
theory that we will focus on in this lecture is called the value curve.
The Value Curve


The value curve takes objective value on the horizontal axis—something 
concrete and easy to measure, such as money—and translates it into 
subjective value—how happy it makes us or how much we like it. If we 
were completely unbiased in our assessments, this curve should be a 
straight line running at a 45-degree angle through the origin. We would 
value $1.00 as $1.00, and each additional $1.00 would be valued the 
same as any other. That would make sense, but that’s not the way our 
cognitive machinery works.


Instead, the value curve is not straight but more S-shaped. This S-shaped 
function has three properties that describe the process of how our 
minds translate objective value into subjective value: (1) The curve has a 
reference point at the origin that serves as the zero point; (2) the curve 
is characterized by diminishing sensitivity; and (3) the curve is kinked at 
the zero point, such that it is steeper in the domain of losses than it is in 
the domain of gains. 

How You Decide: The Science of Human Decision Making
42
Reference Points


The idea behind reference points is that almost every evaluation we 
make is not made in absolute terms but, rather, is relative to something 
else. Interestingly, these reference points are quite fluid and contextual—
even arbitrary. We are so dependent on reference points that when 
we don’t have good ones, we are often willing to use unimportant, 
erroneous, or even irrelevant reference points to make decisions.


Reference points are why infomercials always suggest a comparison 
price for whatever they are hawking and why sales promotions always 
tell you what the retail price was before it was discounted. If you were to 
evaluate the lower price in isolation, you may or may not even know that 
it was reduced. But the pre-discount price serves as a reference point.
Objectively, it doesn’t make 
sense that someone who wins 
third place should be happier 
than someone who wins second, 
but such evaluations are highly 
dependent on reference points.

Lecture 6—The Value Curve and Human Decisions 
43


Reference points can also affect how we evaluate our own successes 
and failures. In one study, psychologists Victoria Medvec, Scott Madey, 
and Thomas Gilovich showed that in sporting competitions, bronze 
medalists are often happier than silver medalists. 


For silver medalists in the Olympics, the natural reference point is 
gold; these athletes are painfully aware that they were almost the 
best in the world at something. 


For bronze medalists, the reference point is fourth place—getting 
nothing at all. They are generally thrilled just to be on the stand.


In another study, the behavioral economist Dan Ariely informed his 
students that he would be performing a poetry reading and passed 
around some sign-up sheets to allow them to reserve their spots. 


Some of the students received sheets asking them whether or 
not they would be willing to pay $10.00 to attend the reading; a 
subsequent question asked how much they would be willing to 
pay if not $10.00. Other students got a similar sheet, but they were 
asked whether they would be willing to attend if they were paid 
$10.00 to listen. They were then asked the same question about 
willingness to pay for a ticket.


When students were first asked whether they would come if they 
were paid $10.00, everyone subsequently demanded payment to 
have to listen to the reading. In contrast, when students were first 
asked if they would pay $10.00, all students indicated that they 
would be willing to pay some money to attend the reading. 


By making an unpleasant task seem like something to be sought 
after—something worthy of paying money for—people assumed 
it must actually have some value. When the reference point was 
negative—when people were offered money to endure the 
poetry reading—they concluded that it must be bad, and they all 
demanded payment for their attendance. 

How You Decide: The Science of Human Decision Making
44
Diminishing Sensitivity


The second property of the value curve is diminishing sensitivity. The 
idea here is that the further we get away from the reference point, the 
less sensitive we are to changes in the objective value.


If we return to the graph of the value function, diminishing sensitivity 
looks like a curve that gets flatter the farther we get from the origin. The 
larger the magnitude on the horizontal axis—which measures objective 
value—the harder it is to get an appreciable change on the vertical 
axis—which measures subjective value.


This idea was first articulated by a Swiss mathematician and physicist 
named Daniel Bernoulli in the early 1700s. The basic idea is that the 
more we have of something, the less we value more of it. 


Everybody appreciates being given $10.00, but how much you 
appreciate it depends on how wealthy you are. If you have 
nothing, you will appreciate that $10.00 a great deal. But if you’re a 
millionaire, it’s probably not going to be that exciting.


Kahneman and Tversky added to Bernoulli’s idea by pointing out 
that this principle holds not just for absolute wealth but relative to 
whatever the reference point happens to be. 


One example is based on a famous study conducted by the behavioral 
economist Richard Thaler. Suppose you were shopping at a store for 
a jacket and a calculator. You find a jacket you like for $15.00 and a 
calculator you like for $125.00. As you are checking out, a sales clerk 
says, “You know, this exact calculator is on sale for $5.00 off at the other 
branch of this store, about a 20-minute drive away.”


When Thaler asked a group of people whether they would be 
willing to drive across town in this situation to take advantage of 
the discount, only about 30% said they would.


A different group of people was given a similar vignette, with the 
jacket now costing $125.00 and the calculator, $15.00. Once again, 
the sales clerk let people know that they could drive 20 minutes 

Lecture 6—The Value Curve and Human Decisions 
45
away to save $5.00 on the calculator. This time, almost 70% of 
participants said that they would be willing to go to the other store.


The same effort would have to be expended to save the same $5.00, 
but because of diminishing sensitivity, a $5.00 discount on $125.00 
feels like much less than a $5.00 discount on $15.00. And that’s 
enough to motivate a change in the decision to drive 20 minutes.
Loss Aversion


Loss aversion describes the fact that people tend to be much more 
sensitive to losses than they are to gains of equal magnitude. In concrete 
terms, losing $10.00 feels much worse than winning $10.00 feels good. 
On average, the larger the 
dollar value of an item, the 
less sensitive we will be to 
differences in prices.

How You Decide: The Science of Human Decision Making
46


You can see this principle in action if you ask people how much upside 
they’d demand in order to flip a coin where the downside is they lose 
$10.00. Suppose I offered you a gamble in which I flip a fair coin and 
you call it in the air. If you’re right, you win $10.00, but if you’re wrong, 
you lose $10.00.


The expected value of this gamble is zero; thus, a cold, rational 
evaluation of the bet gives you no particular reason to play. But 
suppose I offer you a gamble with a positive expected value, such 
as $10.10 for a win against $10.00 for a loss. If you’re like most 
people, you still wouldn’t play.


For most people, the gamble would have to be closer to $20.00 
for a win against $10.00 for a loss before you’d be willing to take 
it. Across numerous similar studies, psychologists’ best estimate for 
the size of loss aversion is about 2.1. In other words, the gain of 
a particular gamble must be about twice as large as the loss for 
people to want to take the gamble.


And loss aversion is not limited to gambles. Some marketing professors 
ran an experiment in which they asked students at a university whose 
basketball team had just gotten into the NCAA Final 4 this question: 
What is the most you would be willing to pay for tickets to see the team 
play? The average was $166.00. The marketers then asked another 
group how much money they would demand to sell those same tickets. 
The average was $2,411.00, roughly 15 times more. This is known as the 
endowment effect. Once people feel that something is theirs, giving it 
up feels like a loss. 


On the value curve, loss aversion is represented by the fact that the curve 
is much steeper in the domain of losses. As it is usually represented, the 
slope of the curve on the negative side of the graph is about twice as 
steep as the slope on the positive side. 


Another example of loss aversion comes from religion. Most major 
religions have in common a belief in some kind of cosmic justice to be 

Lecture 6—The Value Curve and Human Decisions 
47
doled out in the afterlife: punishment for the wicked and reward for the 
virtuous. Many religions preach both heaven and hell, but they don’t 
always emphasize them to the same degree. 


Some researchers looked at the relative beliefs in heaven and hell 
using some data from international value surveys. All told, they 
got responses from more than 140,000 people in 67 countries. 
They created a belief index for each country by subtracting the 
proportion of people who believed in heaven from those who 
believed in hell. 


The researchers then looked at the actual behavior of the people 
in each country. One way religious beliefs can be evaluated is 
through the lens of how those beliefs affect the everyday decisions 
of people in those cultures. 


The researchers correlated belief in heaven and hell with national 
crime statistics and found a significant relationship between those 
two variables. The less a country believed in hell relative to heaven, 
the more crime took place in that country. And that was true across 
the religions under study. 


The value curve elegantly represents three key insights that drive much 
of human decision making: First, in making decisions, we are heavily 
dependent on reference points; second, as magnitudes get larger, we 
get less sensitive to changes; and finally, whether it’s betting on a coin 
toss or deciding whether or not to break the law, we are more sensitive 
to losses than we are to comparable gains.
Suggested Reading
Kahneman and Tversky, “Prospect Theory.”
Tversky and Kahneman, “Advances in Prospect Theory.”

How You Decide: The Science of Human Decision Making
48
Questions to Consider
1.	 What are the three properties of the value curve? What does each 
property mean with regard to how people make decisions?
2.	 Prospect theory has proven to be one of the most influential 
theories in all of social science. Why do you think that is? How 
do you think this theory might be applied outside the fields of 
psychology and economics? The theory has also generated some 
strenuous opposition. Why do you think that is?

49
Lecture 7
Emotional Influences on Decision 
Making
I
n this lecture, we’ll discuss the role of emotion in decision making, that 
is, how feelings can influence our decisions. Recall that we’ve divided the 
topics related to decision making into three groups based on where they 
fit in the process of “manufacturing” a decision. There is the informational 
input, which constitutes the raw materials we use to construct decisions, 
and there is the control panel we use to control the decision-construction 
process. We’ll talk about both those topics in subsequent lectures. Emotion 
fits in the category of cognitive machinery—those characteristics of our 
shared cognitive capacities and processes that can transform information, 
under the guidance of motivation, into a decision. 
Emotion and Decision Making


So far, we’ve taken a bounded rationality approach to understanding 
our cognitive machinery. We’ve talked about the limits our cognitive 
Research has shown that 
feeling socially isolated 
and lonely causes people 
to become more risk 
seeking in financial 
decision making.

How You Decide: The Science of Human Decision Making
50
machinery is under, and how those limitations lead to predictable biases 
in judgments. But we’ve still taken a mostly rational, logical approach to 
understanding decision making (a cold cognition approach). In taking 
this tack, we’ve followed the prejudice of decision researchers and 
philosophers going back hundreds of years.


It’s not that early theorists didn’t understand that emotion plays a role 
in decision making. But because decision research is often undertaken 
from the perspective of trying to improve or optimize decisions or of 
trying to understand rational or boundedly rational choices, emotions 
were seen as largely a distraction. 


In essence, emotion (hot cognition) was set up in opposition to the 
quasi-rational, cold-cognition processes that were supposed to drive 
decision making. This perspective—that emotion’s role in decision 
making is mostly a distraction that impairs decision making—has a 
pedigree going back to Plato. It is only relatively recently that many 
Early theorists argued that 
emotions would make 
“real” decision making 
worse and would do so 
in mostly uninteresting or 
uninformative ways.

Lecture 7—Emotional Influences on Decision Making 
51
decision researchers have started to adopt the view that emotions might 
be more than distractions in the decision-making process; instead, they 
are an integral part of the cognitive machinery of decision making. 


Opening the study of decision phenomena to the influence of emotions 
has led to a host of fascinating findings. For example, a June 2003 article 
in The Journal of Finance investigated the relationship between the 
weather and stock-market returns. The authors collected daily market 
performance data from the main stock exchanges in 26 countries over 
a period of 15 years; they found that there was a significant correlation 
between sunny mornings in the cities where the exchanges were located 
and positive daily returns. 


Another group of researchers, this time publishing in Applied Economics 
Letters, studied the association between the performance of the English 
national soccer team and the financial performance of England’s stock 
market, as measured by the FTSE 100 index. They uncovered two 
interesting relationships. 


First, the performance of the national football club was associated 
with predictable changes in the market. There was a mild positive 
effect when the team won but a much larger negative effect when 
it lost. 


Second, this relationship between national team losses and stock 
market performance got stronger the further the team got into 
tournament play. If the English team lost in an international match, 
that was bad. If it lost during a tournament-qualifying round, that 
was worse. On the few occasions when the English national team 
made it to a finals game in a tournament and lost, that was terrible. 
The stock-market losses the next day averaged 0.4%.
Decision Making without Emotion


The neuroscientist Antonio Damasio has built a case that although 
emotions can clearly bias decisions, the absence of emotions does not 

How You Decide: The Science of Human Decision Making
52
necessarily lead to better decision making. In fact, in some cases, the 
absence of emotions can leave a person unable to decide at all.


Damasio and his colleagues worked with people who had a specific, 
localized kind of brain damage. Sometimes, the damage came naturally, 
but most often, it was caused by surgery to remove tumors or fix some 
other problem.


Damasio’s team was interested in people whose brains had been 
damaged only in those areas that process emotions. They found that 
patients with this kind of localized damage—this inability to process 
emotions—were, cognitively speaking, high functioning. Many had very 
high IQs, but they were unable to make decisions.


When asked a simple question, such as which restaurant to go to for 
dinner, the emotion-impaired respondents will start listing advantages 
and disadvantages associated with each option—and they won’t stop 
for 10 minutes, 20 minutes, or more. 


It appears that without emotional cues (Damasio’s somatic markers) 
people are, in many instances, incapable of moving beyond deliberation 
to actually committing to a course of action. Based on the work of 
Damasio and others, it now appears that the rational and emotional 
systems are not constantly at odds. Instead, emotion is absolutely 
necessary in decision making; without emotion, our decision-making 
machinery simply won’t run properly.
Incorporating Emotions in Models of Decision Making


One of the more prominent theories that emotions are integral to 
decision making is known as the appraisal-tendency framework. 
This theory was developed by Jennifer Lerner from and Dacher 
Keltner. Appraisal-tendency is built primarily around the argument 
that understanding the role of emotion in decision making requires 
understanding the influences of specific emotional states because 
distinct emotions can lead to different outcomes.

Lecture 7—Emotional Influences on Decision Making 
53


Before the appraisal-tendency framework was developed, most research 
on emotion and decision making tended to focus only on the valence 
of the emotion (the intrinsic attractiveness or aversiveness of an event, 
object, or situation). Basically, researchers looked at whether decision 
making under positive emotions differed from decision making under 
negative emotions. Lerner and Keltner argued that emotions are more 
complex and nuanced than just positive and negative. 


Based on some earlier research, Lerner and Keltner asserted that 
emotions can be described by a matrix of six attributes that explain what 
each emotion does to someone: certainty, pleasantness, attentional 
activity, anticipated effort, personal control, and responsibility.


Pleasantness: whether the emotional state is pleasant or aversive


Attentional activity: whether the emotion causes people to become 
more alert and attentive versus being more relaxed and sedate 


Certainty: describes the degree to which the future feels predictable 
and understandable


Control: refers to how much one feels that individual agency can 
alter the current situation


Anticipated effort: an assessment of how much physical or mental 
exertion might be needed in the near future.


Responsibility: describes the extent to which one feels that blame 
or credit for a situation can be assigned to someone or something 
specific.
Utility of the Appraisal-Tendency Framework


To illustrate how the appraisal-tendency framework might be useful, 
consider anger and fear. Both of these have the same valence: negative. 
But they differ on most of the other six appraisal tendencies. 

How You Decide: The Science of Human Decision Making
54


For example, anger tends to be associated with a high degree of 
certainty, elevated levels of perceived individual control, and an 
assumption that specific others bear responsibility for problems. In 
contrast, fear is associated with a low degree of certainty and reduced 
perceived control. 


These differences lead to different predictions about how these two 
negative emotions affect decision making. We should expect someone 
who is angry to be more likely to choose action than someone who is 
sad, for example. Because sadness is associated with less certainty and 
less individual control, it tends to lead to passive decisions and inaction.


Ironically, some emotions of opposite valence remain similar on many 
other appraisal dimensions. Happiness, for example, tends to be high 
on certainty and individual control. This makes happiness similar to 
anger in some important ways. 


One of the predictions derived from the appraisal-tendency framework 
is that some emotions are associated with feeling confident in one’s 
own judgments and others are not. For example, disgust and happiness 
are both characterized by high levels of certainty, even though one is a 
negative emotion and one is positive. Fear and hope, in contrast, are 
both associated with low levels of certainty.


Some psychologists from Stanford used an autobiographical 
emotion-recall task to induce different emotional states in a group 
of participants. People were asked to remember a time in which 
they felt disgust, happiness, fear, or hope and to write a short essay 
about that experience.


After they re-experienced one of those emotional states, 
participants were asked to perform an ostensibly unrelated task: 
making predictions about the future. Participants indicated both 
their predictions and their levels of confidence in those predictions.


Consistent with the predictions of the appraisal-tendency 
framework, the participants who had previously felt disgust and 

Lecture 7—Emotional Influences on Decision Making 
55
happiness—the two high-confidence emotions—indicated they 
were significantly more confident in their predictions than were 
participants who felt fear or hope—the low-confidence emotions. 
The valence of the emotion had no effect on the confidence ratings.


Another set of researchers, led by Lisa Cavanaugh of the University 
of Southern California, built on this idea that individual emotions are 
characterized by specific attributes. They investigated the differences 
among several positive emotions with regard to prosocial decision 
making. 


They found that positive emotions of all kinds tended to increase 
prosocial behavior toward close others, such as local charities. 
However, this boost from positive emotions did not extend to 
prosocial choices that would benefit distant others, such as 
international charities.


The one exception was love. When feeling love as a generalized 
emotion, people were generous to everyone, regardless of 
distance. The researchers argued that love has a property of 
seeking to broaden connections with others, while other positively 
valenced emotions lack this characteristic.


Finally, researchers from New York University and Columbia University 
examined the differences between anxiety and sadness on decision 
making—in particular, on the risk preferences that drive particular types 
of decision making. Consistent with the appraisal-tendency framework, 
these researchers found that negative emotions would lead to different 
types of decisions because they are associated with different levels of 
perceived control. 
Conclusions on the Appraisal-Tendency Framework


The latest evidence suggests that emotions are not the enemy of cold, 
calculating, rational decision making. In fact, it appears that emotions 
are absolutely vital to decision making. Emotions are an indispensable 
component of the cognitive machinery that allows us to make decisions.

How You Decide: The Science of Human Decision Making
56


It is not the case that we may simply consider whether someone is in a 
good mood or a bad mood and anticipate his or her decision response 
from that. 


In fact, decision researchers have identified many important dimensions 
on which specific emotions differ; even seemingly similar emotions, such 
as love and compassion or anxiety and sadness, can differ on a number 
of dimensions. Those attributes can lead to the engagement of different 
cognitive gears and, ultimately, to different decision outcomes.
Suggested Reading
Duclos, Wan, and Jiang, “Show Me the Honey! Effects of Social 
Exclusion on Financial Risk-Taking.”
Hirshleifer and Shumway, “Good Day Sunshine: Stock Returns and the 
Weather.”
Lerner, Li, Valdesolo, and Kassam, “Emotion and Decision Making.”
Questions to Consider
1.	 What are some of the ways that emotion aids or facilitates decision 
making?
2.	 What are some of the specific appraisal tendencies on which 
emotions differ?

57
Lecture 8
How Goals Guide Our Decisions
T
his lecture marks our transition from discussing the machinery of 
decision-making—the cognitive processes involved in making 
choices—to the control panel we use to direct that machinery. The 
idea here is that our cognitive machinery must be directed toward some 
end—some goals that determine how the machinery is to be used. Just as 
some machines can be used for different purposes by adjusting the settings, 
we can think of the same basic sets of cognitive procedures being bent 
toward different ends, depending on the needs, goals, and desires of the 
decision maker. In this lecture, we’ll focus on goals as one of the knobs on 
the control panel. Goals direct our cognitive machinery in specific directions.
Defining Goals


Goals are psychological representations of desired end states. Most 
psychologists who study goals define end states rather broadly—
essentially, something, big or small, that would be different from the 
way the world exists now. 


The psychologists James Austin and Jeffrey Vancouver argued that 
end states can be “outcomes, events, or processes.” They can “range 
from biological set points … (e.g., body temperature) to complex 
cognitive depictions of desired outcomes (e.g., career success).” Such 
goals are motivational in the most basic sense: They are the reason we 
engage in actions. 


When we think of goals, we tend to think of something aspirational, 
to be worked on over time, such as getting a master’s degree. But to 
a psychologist, grabbing the blanket and throwing it over your legs 
because your feet are cold is also a goal-driven behavior. The desired 
end state—warmer toes—drove the decision to get the blanket. In 

How You Decide: The Science of Human Decision Making
58
thinking about goals, keep in mind that broad, higher-order goals reflect 
just a tiny portion of all the motivated behavior in which people engage.


Goal theorists have long argued that the gap between reality—the 
world as it currently is—and our desired end state creates a kind of 
psychological tension within us. That tension motivates decision making 
and, ultimately, actions. This idea was first championed by Kurt Lewin, 
a German psychologist in the 1930s. According to this tension systems 
view, a need is created by the gap between goal and reality, and needs 
generate tension. Because this tension is unpleasant, people move to 
resolve it by reducing the need and, thus, fulfilling the goal. 


Goals can be distinguished from other psychological constructs in part 
because once they have been activated, they tend to be enduring. In 
fact, evidence shows that under some circumstances, an unfulfilled goal 
will actually get stronger over time until it is fulfilled. 
Goal Hierarchies


One way to think about goals is in terms of goal hierarchies. In 1943, 
Abraham Maslow proposed a goal hierarchy with the most basic or 
foundational needs at the bottom and progressively higher-order 
needs on top: physiological, safety, belongingness, esteem, and self-
actualization. Unfortunately, researchers who have investigated the 
hierarchy have found little evidence to support the notion that people 
rank goals in the way Maslow proposed.


We could argue, however, that the list of goals Maslow created 
shouldn’t be completely disregarded. In business school, students learn 
about frameworks, which are useful because they organize information 
in a way that makes it easier to understand and interpret. We could put 
Maslow in the same category. The hierarchy makes predictions about 
goal-driven behavior that cannot be supported. But as a framework, it 
organizes goals into different categories, which can expand our view of 
what types of needs can motivate decision making. 

Lecture 8—How Goals Guide Our Decisions 
59
Intrinsic and Extrinsic Motivation


One area that researchers have investigated when looking at how 
motivation influences choices is the distinction between intrinsic and 
extrinsic motivation. 


Intrinsic motives are those that respond to internal rewards or 
punishments. We engage in some behavior because we like it, 
because it seems like the right thing to do, or because we would 
feel guilty if we didn’t. 


Extrinsic motivations are those that respond to external rewards 
or punishments. We may do something because we’re paid to, 
because we anticipate receiving praise, or because we’ll have to 
pay a fine if we don’t do it.


Interestingly, research so far suggests that providing an extrinsic 
motivation often kills the intrinsic motivation or, at least, reduces its 
strength. One fascinating study was conducted at daycare centers in 
The intrinsic sense of duty to 
help a friend is powerful, but 
if your friend offers you an 
extrinsic reward, you may think 
twice about the same request.

How You Decide: The Science of Human Decision Making
60
Israel that had a strict policy about pick-up time. At each of the daycare 
centers, there were about 10 late pick-ups per week.


Two behavioral economists worked with the owners of these 
facilities to introduce a fine to see if that changed the compliance 
rate. A fine of about $3.00 per child was levied against parents who 
were more than 10 minutes late. Normatively, we would expect the 
fine to increase compliance.


But within about a month of introducing the new policy, late 
pick-ups had doubled. The researchers argued that the extrinsic 
motivator of a small fine reduced the strength of the intrinsic 
motivator—guilt—that had kept parents compliant before. 


The basic finding here is that offering an extrinsic motivator appears 
to actually dampen the intrinsic motivation that had previously 
existed.
Goal Pursuit


One of the key determinants of goal pursuit is the perception of 
progress. It turns out that whether we think we are making progress 
toward a goal is a significant driver of how hard we continue working on 
it. But exactly how perceptions of progress affect us can be complicated.


One goal pursuit prediction is based on an observation made in the 
1930s by an animal psychologist named Clark Hull, who worked with 
rats. Hull found that the rats ran progressively faster the nearer they 
got to a reward, and he labeled this observation the goal-gradient 
hypothesis. This hypothesis recently received renewed interest as a 
possible phenomenon in humans.


In 2006, Ran Kivetz, Oleg Urminsky, and Yuhuang Zheng of Columbia 
University published a series of studies looking at customer behavior at 
a coffee shop, based on a punch-card loyalty program. 


Kivetz and his colleagues tracked each punch on the card and when 
the free coffee was redeemed. Sure enough, the closer people got 

Lecture 8—How Goals Guide Our Decisions 
61
to receiving the reward, the more frequently they stopped by the 
coffee shop to make another purchase.


In a separate study, once people redeemed their free coffee 
rewards, they were given another punch card to start the process 
over. But after the initial loyalty card had been redeemed, people 
reset back to their old purchase frequency.


In another test, the coffee shop gave out two versions of the loyalty 
card. Randomly, customers got a card that required either 10 or 12 
purchases to redeem a reward. But for the 12-purchase customers, 
the baristas immediately punched the card twice—just to be nice.


Both groups needed 10 purchases to get free coffee. The group 
with no initial punches took 15.6 days to make 10 purchases and 
At a coffee shop, a group that was 
endowed with phantom progress toward 
the goal of receiving free coffee returned 
to the shop more frequently and was 
more likely to complete all the purchases 
required to get the reward.

How You Decide: The Science of Human Decision Making
62
redeem the reward. But the group that had two free punches to 
start off took only 12.7 days to make the same 10 purchases.


We might conclude that perceived progress leads people to work 
harder toward a goal, but that’s only true sometimes. In another study, 
participants were given an arrow to color in to indicate how far they 
were from their ideal weight. If you were three pounds from your ideal 
weight, you would color in an arrow up to the three-pound mark. 


Everyone was asked the same question, but the size of the 
number line they were given to indicate an answer differed across 
conditions. For some participants, the number line went up only 
to 5. This meant that no matter how far you were from your ideal 
weight, you started coloring in that line and you just kept coloring. 
The effect was to make people feel very far from their goals.


In contrast, the rest of the participants saw a number line that went 
up to 25. For this group, most weight-loss goals required only a 
little bit of coloring. This condition imbued people with a false 
sense of progress.


After completing the coloring task, participants were given a gift: 
a choice between a chocolate bar and an apple. The goal-gradient 
hypothesis would predict that when people feel close to their goal, 
they should accelerate toward it and choose the apple.


Interestingly, in the condition where people felt far from their ideal 
weight, less than 60% of participants chose the chocolate bar over 
the apple. But in the condition where people were made to feel that 
they were closer to attaining their goal, 80% chose the chocolate.


As it turns out, perceived goal progress can sometimes motivate us 
and cause us to work harder. But sometimes, perceived progress 
can license us to slack off. When people felt as if they were closer 
to their ideal weight, they felt less pressure to restrain themselves. 
It weakened the goal, and they picked the indulgent option.

Lecture 8—How Goals Guide Our Decisions 
63


When does perceived progress toward a goal motivate us, and when 
does it license us to shirk? 


Recall the conditions under which Hull initially identified the 
goal-gradient phenomenon. The rats were pursuing some known 
objective—food—and they accelerated as they got closer to that 
reward. The cases where subsequent researchers have identified 
goal-gradient phenomena in people are similar: With a known 
objective—free coffee—people accelerated their purchases as they 
got closer to the reward. 


But many of the goals we pursue in life are not of that type. Often, 
we are not pursuing some narrowly defined and clearly understood 
objective. We want something more nebulous, such as happiness, 
success, or security. And even the intermediate goals we set to get 
there—such as reaching some “ideal” weight—are not definitively 
rewarding in the same way that the food pellet at the end of a 
maze would be.


Unless someone is going to give you a car when you reach your 
ideal weight, then there is no real prize. If you achieve that goal, 
you congratulate yourself, but then you need to wake up the next 
morning and choose between a banana and a Pop-Tart all over 
again. And it is for these “softer” goals, with no definitive end and 
weakly defined rewards, that we might expect licensing.


In fact, one commonly given bit of advice for people pursuing goals 
is to not tell others about your goals—and the reason is licensing. 
When you tell someone you are planning on starting a diet, just the 
act of talking about the goal can be registered by a part of the brain 
as making progress toward that goal. After all, if you’re telling people 
you’re on a diet, you must be doing pretty well—that’s got to count for 
something.

How You Decide: The Science of Human Decision Making
64
Suggested Reading
Fishbach and Dhar, “Goals as Excuses or Guides.”
Gneezy and Rustichini, “Incentives, Punishment, and Behavior.” 
Kivetz, Urminsky, and Zheng, “The Goal-Gradient Hypothesis 
Resurrected.”
Questions to Consider
1.	 How do intrinsic and extrinsic motivations differ from each other? 
2.	 What is the goal-gradient hypothesis? When might we expect a 
goal-gradient effect, and when might we expect a licensing effect?

65
Lecture 9
Reason-Based Choice
W
e would expect that asking someone to choose an option from 
a binary set should result in the same basic outcome as asking 
someone to reject one option from that set. But when one of the 
options is average (impoverished) and another has both strong advantages 
and disadvantages (enriched), people’s decisions are sensitive depending on 
whether they are asked to choose or reject one option from the set. In other 
words, people make decisions as if they were looking for a reason to choose 
or reject each option. Of course, saying that people make choices based on 
reasons is not a terribly groundbreaking insight. The important point here is 
that sometimes reason-based choices lead to strange outcomes. 
Inconsistencies in Reason-Based Choice 


One way reason-based choice can differ from normative, rational, 
consistent models of decision making is by changing the weight we 
put on various attributes in making decisions. Psychologist Eldar Shafir 
showed that the way a decision task is framed can naturally lead us to 
weight information differently when making decisions. If you’re asked 
which option to reject, you tend to over-weight negative information—
reasons to reject. If you’re asked to choose, you tend to over-weight 
positive information. This can lead to different outcomes in settings 
where we should expect consistency.


Another way reason-based choice can be problematic is that people 
sometimes rely on irrelevant reasons for choosing one option over 
another. In our lecture on heuristics, we saw how common it is, when 
making difficult decisions, for us to substitute an easier but less accurate 
question for a harder but more accurate question. The same thing can 
happen with the reasons we use to make decisions.

How You Decide: The Science of Human Decision Making
66
When people are making 
decisions, they may try to 
negotiate a tradeoff between such 
factors as price or quality, but they 
still sometimes make decisions 
based on reasons that have no 
relevance to the products.

Lecture 9—Reason-Based Choice 
67


As we all know, some companies run promotions offering incentives 
that are not related to the products they sell. For example, you 
might buy several packs of batteries, then mail in the UPC labels in 
exchange for a golf umbrella.


As long as it covers its costs, this kind of promotion should be 
strictly a good thing. People shouldn’t stop buying the product 
because of the promotion. After all, if they don’t want the umbrella, 
they don’t have to send in the UPC labels.


A group of marketing professors, however, made a different 
finding. They looked at this issue from a reason-based choice 
perspective and found that if you are looking for reasons to choose 
one brand of batteries over another, the fact that you don’t need 
a golf umbrella could serve as a reason not to choose the brand 
that’s running the promotion. 


Choosing a battery because it costs less, will last longer, or is more 
reliable are all reasonable justifications for the choice. But not 
choosing a particular brand of batteries because you don’t need a 
golf umbrella isn’t germane to the decision at all.


It’s possible that people use such promotional offers as quality signals. 
They may think that the promotion itself is a sign that the product isn’t 
worth the price being charged. However, some experiments have ruled 
out this explanation.


In one study run at the University of California at Berkeley, 
undergraduate business students were asked to imagine that it 
was several years in the future and they had decided to pursue an 
M.B.A. They had gotten into two schools (UCLA and Northwestern’s 
Kellogg School of Management) and were asked to pick one and 
give some reasons for their choice.


Participants were given a paper survey and were told that the 
experimenters had decided to save paper by printing two short 
surveys per page. There was a chance that some of the participants 

How You Decide: The Science of Human Decision Making
68
would get a form on which the survey on top had already been 
filled out by another student. If that was the case, students were 
instructed to ignore the other person’s answers and just fill out the 
survey on the bottom half of the page for themselves.


Of course, everyone got a survey that had already been filled in 
by an experimenter, indicating whether that student would choose 
Northwestern over UCLA. For half the participants, the “student” 
who had taken the top survey chose Northwestern but did not give 
any reasons for the choice. For the other half, the previous survey 
taker had chosen Northwestern because he or she had relatives in 
Chicago.


Learning that some random student has family in Chicago should 
not influence another student’s choice of schools, but interestingly, 
it did. The choice share of people choosing Northwestern over 
UCLA dropped from 43% to 23% (a 20-point drop) when students 
got a survey listing the reason for the choice as having many 
relatives in Chicago.
Entrapped by Reason


We often use reasons inappropriately to ease decision making, but our 
reliance on reasons can also entrap us and make what should be easy 
decisions more difficult.


In one experiment, conducted by Professor Itamar Simonson at Stanford, 
students were asked to imagine that it was the end of the fall semester, 
that they were feeling tired, and that they had just taken an exam that 
they weren’t sure they had passed. If they failed the exam, they would 
need to take it again after the winter break. 


Students had also just been presented with an attractive vacation 
package to Hawaii for an exceptionally low price. But the special 
deal would expire tomorrow, and they wouldn’t know whether they 
passed the exam until the day after tomorrow. 

Lecture 9—Reason-Based Choice 
69


Students were given three options: (1) Buy the vacation package 
now, (2) pass on the package, or (3) pay a nonrefundable $5.00 fee 
to reserve the chance to buy at the discounted price in two days—
after they found out how they did on the exam. Most students (61%) 
chose to pay the $5.00 fee and wait to buy the vacation package 
until after they had learned the outcome of the exam.


Simonson and his colleagues presented the same hypothetical 
situation to two additional groups of students, but in this case, 
people already knew the outcome of the exam. Half the students 
were told that they passed the exam, and half were told they had 
failed and would need to retake the exam after the break.


Amazingly, both groups responded in almost exactly the same way. 
Whether they had passed or failed, about 55% chose to purchase 
the vacation. 


In this scenario, the outcome of the exam didn’t matter in 
determining whether or not students would go on the trip; instead, 
it provided reasons for going. Those who passed could treat 
themselves, while those who failed could recuperate so that they 
were fresh to study for the exam again.


The reasons themselves didn’t appear to matter much—and either 
outcome would provide an equally viable reason for choosing to 
go. But until the exam question was resolved, students wouldn’t 
know which reason to use. This need to find a reason to justify our 
decisions can actually complicate the decision-making process. If 
we look for a reason and can’t find one, we can be stymied.
Irrelevant Attributes


One additional way that reason-based choices can lead to suboptimal 
decision making occurs when we focus on different attributes of the 
decision than the ones that will matter to us later.

How You Decide: The Science of Human Decision Making
70


Professor of Psychology Timothy Wilson and his colleagues asked a 
group of undergraduate women to evaluate some posters of the type 
that undergraduates often have in their dorm rooms. Some of the posters 
had a more aesthetic appeal, featuring reproductions of paintings by 
Monet and van Gogh. Others had a more cerebral appeal—humorous 
or motivational.


Half the participants were asked to rate how much they liked each 
of the posters on a 9-point scale. They then got to select one of the 
posters to take home. The procedure was the same for the other 
half of participants, but this group was asked to write down why 
they liked or disliked each poster before rating them and choosing 
one to keep.


Requiring reasons for the participants’ opinions changed the 
exercise from a neutral one that clarified existing preferences to 
one that appeared to influence the choices participants made. In 
particular, the reason manipulation shifted choices away from the 
aesthetic posters and toward the cerebral posters. 


When not prompted to provide reasons for their choices, fully 95% 
of the participants chose one of the posters of a famous painting. 
When asked to articulate reasons for their opinions, the share of art 
posters dropped to 64%.


Several weeks later, the experimenters followed up with each 
participant by phone and asked whether she still had the poster, 
whether she had hung it up, and whether she still liked it. Women 
in the control condition—those who were not asked to provide 
reasons for their choices—still liked their posters. But those who 
had to articulate the reasons for their choices were much less 
satisfied when they got their posters home.


We might think that people simply liked all the posters less when 
they had to provide reasons for their choices. But that wasn’t the 
case. In fact, if anything, people in the reasons condition initially 
indicated that they liked the posters more. What caused the change?

Lecture 9—Reason-Based Choice 
71


The way we enjoy art might generally be characterized as a System 
1 process. We tend to appreciate posters and artworks holistically, 
aesthetically, and automatically. But System 1 does not do well 
generating reasons; that’s a System 2 task. Thus, when participants 
were asked to generate reasons for their preferences, they 
switched from what likely would have been their natural, System 
1 way of appreciating a poster and, instead, imposed System 2 
judgements on it.


Further, the reasons that System 2 is likely to generate are System 2 
reasons, and System 2 often has difficulty articulating reasons that 
would appeal to System 1. Thus, by asking people to explain why 
they liked or disliked something, the experimenters were encouraging 
them to move from a System 1 evaluation mode into a System 2 
evaluation mode. This created a disconnect between preferences at 
the time of choice and preferences later, at the time of consumption.
Customers often rely on System 
1 cues in making decisions, 
while marketing professionals, 
product designers, and brand 
managers are more likely to use 
System 2 reasoning.

How You Decide: The Science of Human Decision Making
72


Reasons are one of the levers we have on our decision-making control 
panel. We don’t always use reason-based decision making, nor do our 
reasons have to be clearly and unambiguously articulated in order for them 
to influence our decision making. Of course, reasoning isn’t a bad way 
to make decisions either. However, the ways reasoning goes wrong are 
consistent, and that consistency tells us something interesting about the 
imperfect control panel we use to manage the decision-making process.
Suggested Reading
Shafir, Simonson, and Tversky. “Reason-Based Choice.”
Questions to Consider
1.	 How does a reason-based choice model differ from a utility-based 
choice model?
2.	 Recall some of the “reasons” documented in this lecture as being 
able to influence choice. Can you think of similar, context-based 
reasons that someone might choose a particular option from a set?

73
Lecture 10
Mental Accounting as a Factor in 
Decisions
T
he fungibility of money is one of its defining features. One dollar is 
equivalent to another dollar. But the University of Chicago’s Richard 
Thaler, one of the leaders in the field of behavioral economics, 
presented evidence of, the non-fungibility of money—at least in certain cases. 
It turns out that people treat the same dollar differently depending on how 
they have categorized that dollar mentally. The idea is that people categorize 
money and resources according to their intended use, and once they have 
performed this purely psychological categorization, they start to treat those 
categorized funds differently. One dollar is no longer equivalent to another.
Mental Accounts


Sometimes, people make mental accounts that mirror the types of 
accounts an accountant would make, such as budgets for entertainment, 
clothes, and savings. A good deal of research has looked into how and 
why people segregate and combine experiences and resources. 


One experiment was conducted by Dilip Soman of the University of 
Toronto and Amar Cheema of the University of Virginia. Participants 
were given 100 coupons for gambling. The coupons were worth $0.64 
and could be used to play or could be cashed in at any time. Most 
people chose to play the game. 


Players could trade 1 coupon for a roll of two dice. If the total was 
9 or higher, then the player won an additional 5 coupons that could 
not be used for further gambling; they could only be cashed out. 
Participants essentially faced the question of how many times they 
wanted to gamble before stopping.

How You Decide: The Science of Human Decision Making
74


The experimental manipulation was in how the coupons were 
delivered to the players. Some received all 100 coupons in a single 
sealed envelope; some received 4 sealed envelopes with 25 coupons 
in each; and some received 10 envelopes with 10 coupons in each.


Researchers found that the total number of bets placed decreased 
as the coupons were allocated to more envelopes. When all the 
coupons came from a single envelope, people bet, on average, 43 
coupons. When the coupons came in 4 envelopes, the average bet 
dropped to 25.5. When the coupons came in 10 envelopes, the 
average dropped to 16.


The multiple envelopes probably provided people with natural 
mental accounts. With all the coupons in a single envelope, people 
presumably gambled until they felt they had had enough. But with 
the pre-apportioned packets, people seemed more likely to decide 
that they would gamble a certain number of envelopes’ worth of 
coupons. The more envelopes available, the more opportunities to 
stop and declare the other coupons off limits.


If this explanation is accurate, then we should expect to find 
something else: Not only should people bet less overall when 
there are more envelopes, but they should also be more likely to 
use all the coupons in an opened envelope once that envelope 
has been opened.


Indeed, that was the second main finding from this study: People in 
the 1-envelope condition gambled the most coupons on average, 
despite the fact that in this condition, fully one-third of participants 
did not gamble at all. The rest tended to gamble a great deal. Of 
those who opened the envelope, the average bet was 64 coupons. 


When the coupons came in 4 envelopes, only two people chose 
not to gamble anything. The mode response was to gamble 1 full 
envelope: One-third gambled exactly 25 coupons—1 envelope’s 
worth. And one-half of all participants in this condition bet all the 

Lecture 10—Mental Accounting as a Factor in Decisions 
75
coupons in whatever envelope was the last one they opened: in 
other words, one-half of all participants bet 25, 50, or 75.


Similar results were found in the 10-envelope condition. Again, the 
mode response was to bet 1 envelope’s worth of coupons: One-
quarter of participants bet exactly 10 coupons. Nearly two-thirds 
of participants bet some multiple of 10, stopping only when they 
came to the end of an envelope.


The more “partitions” there were, the slower consumption was 
over all. People treated these divisions among otherwise equivalent 
options—these “accounts”—as meaningful, and it changed their 
consumption.
Mental Accounts in the Real World


Soman and Cheema took these findings to the field to see if creating 
mental accounts could do some real-world good. The researchers 
conducted an experiment with construction workers in rural India. These 
laborers were paid 670 rupees (about $15.50) a week. Their average six-
month savings rate was 0.75%. 


Working with social workers and financial advisors, the researchers 
developed a savings plan and selected a group of workers on which 
to test it. For participants, they specifically chose workers who were 
married, lived with a spouse, and had two children between the ages 
of 2 and 7. 


First, everyone received some counseling from the financial planners 
and was given a savings goal—6% or 12% of their income (about $1.00 
or $2.00) per week. 


Some participants received only the training and the goal. Members of 
another group received their pay with the savings already set aside in an 
envelope, although they were free to open the envelope at any time if 
they needed the money. Still another group received a sealed envelope 

How You Decide: The Science of Human Decision Making
76
with their savings target, but on the envelope was printed a picture of 
their children. Tearing open the envelope usually meant ripping through 
the picture of the children to get to the money inside.


The researchers found that people with higher savings goals tended to 
save more, and those with their savings partitioned into envelopes did 
better at saving than those who did not receive some of their money 
separately. Further, people saved more money when their children’s 
pictures were printed on the envelopes.


At the end of 14 weeks, participants with the goal of saving 6% saved 
about 270 rupees, or about $6.25. But when the goal money was placed 
in an envelope, the average jumped to about $8.60. When the goal was 
to save 12%, the effects were even more pronounced. The larger goal 
did not help at all in the baseline condition, but when combined with 
the envelopes, the average savings was $10.50. 
Personal financial advisors 
often advocate creating a 
budget each month and 
physically distributing the 
money into envelopes; this 
practice can have a surprisingly 
positive effect on savings.

Lecture 10—Mental Accounting as a Factor in Decisions 
77
Diminishing Sensitivity


Mental accounting has also been invoked to explain fundamental 
phenomena based on how we process positive and negative 
experiences. Consider the following two hypotheticals: 


In the first scenario, Mr. A wins two small lotteries in one day, one 
for $50.00 and one for $25.00. Mr. B wins one lottery for $75.00. In 
one study, Thaler found that 64% of participants thought that Mr. A 
would be happier.


In the second scenario, Mr. A received a letter from the IRS saying 
that he owes $100.00. On the same day, he received a letter from 
the state tax authority informing him that he owes $50.00. Mr. B 
received a single letter from the IRS telling him that he owes 
$150.00. Again, in a study, 75% of participants thought that Mr. A 
would be more upset.


To explain these findings, we must combine mental accounting with 
prospect theory. As you recall, in prospect theory, diminishing sensitivity 
is the idea that we get less sensitive to gains and losses the farther we 
are away from a reference point. Put another way, a given increase or 
decrease will be felt less acutely relative to a large magnitude than to a 
small magnitude.


The key ideas in prospect theory can be expressed as a curve on a two-
dimensional plane, with the horizontal axis representing objective value 
and the vertical axis representing subjective vale. Diminishing sensitivity 
is expressed graphically by curves that bend more toward the horizontal 
axis as they get farther from the origin.


When we evaluate a single gain or loss for a relatively large amount, we 
move out to the flat part of the curve, relatively far from the origin. But 
when we have two gain or loss experiences, we experience the steepest 
part of the curve—the part closest to the origin—twice. For this reason, 
we actually experience $25.00 + $50.00 as greater than $75.00. We feel 
two wins more positively than just one win.

How You Decide: The Science of Human Decision Making
78
Coupling Pain with Benefit


The notion that people can mentally combine or separate experiences 
is a powerful idea in mental accounting and can explain a great deal 
of common behavior that is at odds with the predictions of rational 
decision-making theories.


Consider the following example, created by Drazen Prelec of MIT and 
George Loewenstein of Carnegie Mellon University: 


Mr. A and Mr. B both joined health clubs. Mr. A’s club charged a fixed 
fee for each month of usage, payable at the end of the month. Mr. 
B’s club charged an hourly fee for using the health club, with the total 
payable at the end of the month. By chance, both men used the health 
club about the same amount, and both ended up getting a bill for the 
same amount at the end of the month. Who enjoyed himself more while 
at the health club?


Of the people who were asked this question, 38% said that the men 
would be indifferent. But of those who thought one man would be 
happier than the other, 48% thought that Mr. A would be happier, 
compared to only 14% who thought Mr. B would be happier.


Prelec and Loewenstein observed the same effect across three 
additional scenarios involving fixed versus variable fees. Indeed, 
researchers have documented a flat-rate bias in many consumer 
transactions. 


Prelec and Loewenstein attributed the preference for fixed rates 
over variable rates to the way consumers psychologically manage 
the “coupling” of costs and benefits. The researchers pushed the 
accounting metaphor a step further, suggesting that mental accounting 
might be most accurately described as a double-entry accounting 
system, to explain the dual effects of the pleasure of consuming and the 
pain of paying for consumption.


Some methods of purchase couple the pain and pleasure tightly. 
When you pay for something upfront using cash, the coupling is 
strong: The pain of payment is experienced at the same moment 

Lecture 10—Mental Accounting as a Factor in Decisions 
79
that the pleasure of consumption starts. But humans have 
developed numerous methods, such as prepayment and the use of 
credit cards, for decoupling the pain from the pleasure.


Similar logic applies to fixed versus variable pricing. When the cost 
is fixed, we experience the pain at once, and it is not as tightly 
coupled to the experience. But with variable pricing, the pain of 
payment is much more closely associated with the experience. 


Decoupling the pleasure of a purchase from the pain of payment is 
usually not a particularly good idea from a personal finance perspective. 
But our mental-accounting systems were not necessarily designed 
for optimal financial decision making. And from the standpoint of 
maximizing happiness over some moderate time horizons, this kind of 
decoupling is a strategy that works well—too well, for many of us.
The way we buy gasoline 
couples the pain of 
payment very closely 
with the benefits we get 
related to transportation.

How You Decide: The Science of Human Decision Making
80
Suggested Reading
Soman and Cheema, “Earmarking and Partitioning.”
Thaler, “Mental Accounting Matters.”
Questions to Consider
1.	 Mental accounting can be a rather nonintuitive phrase for some 
people. How is mental accounting defined? Give some examples of 
mental accounting as it has been studied in the literature.
2.	 Mental accounting can cause some biases that lead to poor 
decision making, but it can also be used strategically to produce 
positive results. What mental-accounting principles could you use 
to encourage someone to save money?

81
Lecture 11
The Role of Mindsets in Decision 
Making
O
ur minds are constantly trying to prepare us for whatever situations 
we happen to be facing. Thus, they are often spooling up a set of 
cognitive procedures to help us best respond to the environment 
around us. Once that set of cognitive procedures is activated, it tends to stay 
active for a while, thereby influencing subsequent judgments and decisions. 
In this lecture, we’ll explore the relationship between mindset and the 
decision-making process. As we’ll see, a mindset functions in part as one of 
the dials or buttons on our motivational control panel. In other words, when 
making a choice, sometimes the mindset that happens to be active will drive 
the decision. 
Growth versus Fixed Mindsets


One mindset theory that has proven popular both within psychology 
and with the public is based on Carol Dweck’s work on growth versus 
fixed mindsets. This is a learning theory that describes students’ beliefs 
about where their abilities come from.


Some students believe that intelligence, abilities, and talents are fixed 
traits. A person with a fixed mindset views success in some area as 
evidence of innate talent and failure as evidence of the lack of talent. 
People with a fixed mindset, therefore, spend time seeking out evidence 
of their own successes in those domains that are important to them and 
avoiding situations that might cause them to fail in those domains. 


In contrast, some students believe that abilities can be developed 
through hard work and persistence. In other words, someone with 
a growth mindset doesn’t see success as evidence of being smart 

How You Decide: The Science of Human Decision Making
82
but of having worked hard. And failures are not nearly as damaging 
to someone with a growth mindset. Failures are a natural part of the 
growth process, not evidence of an inherent shortcoming.


Dweck’s research suggests that people tend to chronically be in one 
state or another. That is, because of personality and how we were 
raised, we tend to fall into a fixed or a growth mindset. But research also 
supports the idea that through training and effort, people can change 
their mindsets. 
Mindsets and Cultural Differences


Nearly everyone agrees that culture plays a significant role in 
understanding human psychology in general and decision making in 
particular. But the term culture is difficult to define and study. Mindsets, 
however, have provided one approach for empirical psychologists to 
examine specific aspects and implications of culture. 


For example, a mindset theory called self-construal explains how people 
think about themselves: either as independent individuals, acting on 
their own volition and toward their own aims, or as interdependent 
members of a collective, such as a family or a company. The reality, of 
course, is that we are all both independent and interdependent. But at 
any point in time, we tend to think of ourselves predominantly in one 
way or the other.


This ties back to culture in the emphasis that certain cultures place on 
one of these views versus the other. As a result, people raised in certain 
cultures tend to adopt one mindset as their default or chronic setting.


Neither of these mindsets—interdependent or independent—is right or 
wrong, of course, and it is not the case that everyone within a culture 
has the same perspective. But people raised in a particular culture, on 
average, maintain a particular self-construal mindset most of the time.

Lecture 11—The Role of Mindsets in Decision Making 
83


Still, it’s important to note that people switch self-construal mindsets 
with relative ease. In fact, researchers can readily coax a person from 
one culture to think like a person from another culture.


For example, many research studies ask people to perform a simple 
reading task in which they circle all the pronouns in a paragraph. 
In some conditions, the paragraph is written in the first-person 
singular perspective: “I did this; I did that.” In other conditions, the 
paragraph is written in the first-person plural perspective “We did 
this; we did that.”


This simple task that focuses people on singular or plural pronouns 
has been found to be a robust way of inducing a temporary mindset 
switch. Focusing on “I” shifts people to an independent mindset—
at least for a few minutes—while focusing on “we” shifts people to 
an interdependent mindset.
Mindset-priming tasks 
are among the most 
common designs used in 
experimental psychology.

How You Decide: The Science of Human Decision Making
84
The Rubicon Model of Action Phases


One specific mindset theory that is especially important for decision 
theory is known as the Rubicon model of action phases. The insight here 
is that sometimes an action can best be understood by breaking it up 
into a series of phases that a person goes through to complete it.


This model was developed by two German psychologists, Peter 
Gollwitzer and Heinz Heckhausen. Essentially, they argued that any 
action can best be understood as a series of four consecutive stages. 
The two stages most relevant to our discussion come immediately 
before and immediately after the decision.


Before the decision a goal-setting stage. This is where options 
are evaluated and assessed, and desires are translated into goals. 
At the conclusion of the first stage, the decision is made, and we 
move from consideration to commitment.


The second stage is the planning stage. Now that a decision has 
been made, we make plans to put that decision into action.


Third comes the action itself, pursuing the goals from stage 1 
through to completion. 


Finally, the fourth phase is a post-action, assessment stage. Has the 
goal been satisfied, or are further strivings necessary?


The Rubicon model is predicated on the claim that each of these four 
phases is associated with a different set of cognitive processes. Because 
the mind needs to solve different problems at each stage, different sets 
of cognitive procedures are brought online. In other words, each phase 
is associated with a different mindset.


Before we decide, we are in deliberation mode. A deliberative mindset 
is attuned to evaluating options in terms of both desirability and 
feasibility. This is an exploratory frame of mind, in which we seek out 
information. Remember that at the outset of a decision, we might not 

Lecture 11—The Role of Mindsets in Decision Making 
85
even know which attributes will be important in making our final choice. 
A deliberative mindset is often associated with open-mindedness.


After we have made a decision, we are in implementation mode. An 
implemental mindset is much more focused. Now, we’ve zeroed in on 
the one course of action to take, and information about that option 
becomes paramount. In this sense, it is a close-minded mindset. 
Implemental mindsets are also partial to information that supports the 
chosen course of action. 


The differences between deliberative and implemental mindsets have 
been thoroughly explored by psychologists in the decades since the 
Rubicon model was first proposed. 


For example, in a series of studies, Gollwitzer and his colleagues 
asked participants in one condition to think about some upcoming 
decision they had to make, listing their thoughts or creating a pro/
Our thoughts are often 
much more concrete when 
we are in an implemental 
mindset and considering 
upcoming actions.

How You Decide: The Science of Human Decision Making
86
con list. In the other condition, people were asked to think about 
some decision they had already made but had not yet carried 
out. Sometimes, they would list the steps needed to carry out the 
decision; then, they would move on to another task. But researchers 
found that the deliberative or implemental mindset had already 
been activated and carried over to the subsequent task. 


One of these studies involved a creative writing task. Participants 
were first induced to activate either a deliberative or an implemental 
mindset. Then, they were given the starting portions of several fairy 
tales and were asked to write three sentences that continued the 
stories. One of the stories was the tale of a widowed king who was 
facing the choice of leading his army into war or staying home to 
protect his beloved daughter.


People’s responses were later coded on the basis of whether 
the story fragments portrayed the king as being deliberative 
or implemental. Thus, the sentence “The king wracked his brain 
wondering what to do.” was scored as deliberative. The sentence 
“The king ordered a trusted officer to stay at home at the castle 
and protect his daughter.” was scored as implemental.


When people had activated a deliberative or implemental mindset 
by thinking about decisions in their own lives, they carried that 
approach over into a seemingly unrelated writing task, essentially 
projecting their state of mind onto the protagonist of the story. 


Another of these studies involved giving participants a memory test. 
The Rubicon model predicts that people in different decision phases 
should remember different types of information more easily.


In this study, participants were induced to have an implemental or 
deliberative mindset by being asked to choose to take one of two 
versions of a creativity test. They were told that people differ in 
terms of what best solicits their creative instincts and that only by 
choosing the right version of the test would they get an accurate 
measure of their creative potential.

Lecture 11—The Role of Mindsets in Decision Making 
87


Some of the people were told about this test, then given time to 
deliberate and make their choices. After they made their choices, 
they were told that the actual test would come later; first, they had 
to do a different task. The rest of the participants were told about 
the two versions of the creativity test and were given some time to 
deliberate, but they were told that the test would come later, and 
they could make their decisions about it at that time.


In other words, some people made their choices, but hadn’t taken 
the test yet. This is the implemental mindset condition. Other 
people didn’t make a choice. This is the deliberative mindset 
condition.


Once the mindsets were activated, both groups performed an 
intervening task: They saw a list of the supposed thoughts of a 
person experiencing some kind of decision. Some of the thoughts 
were deliberative, dealing with the desirability and feasibility of the 
decision. Some thoughts were implemental, dealing with the steps 
required for the action to come to fruition.


Later, people were given a memory test over the thought listings 
they had seen. As predicted by the Rubicon model, those who 
had not yet made a decision (deliberative mindset) remembered 
the deliberative information better. Those who had already made a 
decision—about an unrelated test—were better able to remember 
implemental thoughts.


Mindsets are a powerful idea in psychology, helping us explain 
everything from culture to inference making to interpersonal 
relationships to stereotyping. From a decision-making perspective, the 
most influential mindset theory has arguably been the Rubicon model, 
which has proven to be compelling approach to understanding how 
goals and motivation can influence our choices.

How You Decide: The Science of Human Decision Making
88
Suggested Reading
Dweck, “The Secret to Raising Smart Kids.”
Gollwitzer, “Mindset Theory of Action Phases.”
Trope and Liberman, “Construal-Level Theory of Psychological Distance.”
Questions to Consider
1.	 How do mindsets differ from goals?
2.	 One specific mindset theory that relates to decision making is the 
Rubicon model. Why is it called the Rubicon model? What is the 
significance of that historical reference?

89
Lecture 12
How Consistency Drives Decisions
I
n his 1841 essay “Self-Reliance,” Ralph Waldo Emerson argued that 
people should trust themselves, throwing off the artificial constraints 
imposed by social pressures and institutional wauthority. One of the 
things constraining our genius, according to Emerson, is that we find 
ourselves molding our present behaviors and actions to be consistent with 
what we have said or done in the past. The empirical research since Emerson 
suggests that he was right: Consistency is a powerful motive. We’ve already 
discussed the importance of goals and motivations in general, and we’ve 
seen several frameworks for thinking about people’s motivations. In this 
lecture, we’ll focus on the motive to be consistent and examine the different 
ways this driver can affect decision making.
Sources of Consistency


When we talk about people being consistent, we are generally talking 
about the consistency of some combination of beliefs and behavior. In 
fact, we can consider consistency based on every permutation of the 
relationship between beliefs and behavior.


Beliefs can be consistent with our beliefs in the past (reinforcement). 
Moreover, beliefs tend to intensify over time for no other reason than 
that they have been previously held. Another type of consistency is the 
consistency of behavior with beliefs (consistency coherence). It’s also 
true that our behavior can be consistent with our previous behavior—not 
involving our beliefs or attitudes at all, just action leading to consistent 
action (habit). Perhaps the most interesting way that people can be 
consistent is when their beliefs conform to be consistent with behaviors 
(self-perception).

How You Decide: The Science of Human Decision Making
90
Coherence


Coherence is probably the most intuitive form of consistency. This is the 
idea that our behavior should be driven by—and, therefore, consistent 
with—our beliefs.


We generally act in a way that is consistent with our beliefs and attitudes, 
but sometimes, we do not. In fact, the correspondence between beliefs 
and attitudes assessed independently with behavior is not as close as 
we might expect.


Part of the problem is that early psychologists were often not measuring 
the right thing. Measures of attitudes have historically focused on the 
valence of the attitude, that is, how positive or negative the belief is. 
More recent research has discovered that attitude strength (security and 
stability) is a much better predictor of behavior than attitude valence. 
Coherence tells us that 
our behavior should be 
consistent with our beliefs; 
if we care about the 
environment, for example, 
we should recycle, drive 
fuel-efficient cars, and so on.

Lecture 12—How Consistency Drives Decisions 
91


We might expect attitude strength to be correlated with attitude 
valence. Often, the things about which we feel very positive or negative 
are also things about which we have very strong and stable beliefs. But 
this is not necessarily the case.


In psychology, such variables are called orthogonal. We can think of 
them as perpendicular axes in a two-dimensional space. For a given 
attitude valence—say, highly positive—you can hold that belief either 
weakly or strongly. Likewise, you can have an opinion that is very strong, 
but that opinion could be positive, negative, or relatively neutral. And it 
is the strength, not the valence, that ultimately predicts behavior. 
Reinforcement


Reinforcement refers to the fact that beliefs, once held, tend to be 
stable or even strengthen over time. One of the early demonstrations 
of the effect that came to be known as attitude polarization is especially 
evocative.


In one study run in the 1970s at Stanford University, 48 
undergraduates were chosen to participate in an experiment 
related to beliefs about capital punishment; half were proponents 
of capital punishment and half were opponents. People on both 
sides of the issue believed that the research into the deterrent 
efficacy of capital punishment favored their position.


Experimental subjects were told that they would be given two 
“randomly” selected studies on the deterrent efficacy of capital 
punishment to read. One of the studies presented research 
supporting the idea that capital punishment serves as a deterrent 
for crime, and the other study presented opposing research. 
Objectively, people should have left this exercise more or less 
where they were when they came in. It’s also possible that this 
exercise might moderate your views a bit. 


But after reading a set of balanced information, people’s beliefs 
about capital punishment became more extreme, and this was true 

How You Decide: The Science of Human Decision Making
92
for both groups. Presenting objectively balanced information to 
someone with an initial opinion can make that opinion even more 
extreme.


The researchers also took some follow-up measures to see what 
people thought about the research they had read. They found that 
when forced to engage with evidence contrary to their opinions, 
the participants actively argued against it. But the research that was 
supportive of their opinions was described as “well thought out,” 
“valid,” and “accurate.”


In 2002, a group of German psychologists looked at the role of differing 
opinions—and even conflict—in reducing the negative effects of 
reinforcement. They recruited adults to participate in a study on group 
decision making. 


The procedure was to provide each participant with some 
information about a business case. The participants played the role 
of a board member of a company that wanted to move some of its 
operations overseas.


Participants were given some initial information about two possible 
locations for the new plant. The prospects were described on 14 
attributes, including tax rates, economic growth rates, and so on. 
Based on this information, they made preliminary decisions and 
were then assigned to groups to make the final decision.


The researchers deliberately created both homogenous and 
heterogeneous groups—those in which two people supported one 
option, but the third leaned in the other direction.


Researchers found that the homogeneous groups tended to evince 
reinforcement biases. When given the opportunity to get more 
information before making their final decisions, the homogenous 
groups sought out less additional information overall. Even worse, 
the information homogenous groups sought tended to be of the 
confirmation-bias type. 

Lecture 12—How Consistency Drives Decisions 
93


To measure the magnitude of this bias, the researchers created a 
net bias index, in which the more positive the measure, the greater 
the confirmation bias. They found that homogenous groups had 
a bias score of more than 1. When there was one dissenting voice 
in the group, the bias measure moved from about 1 to –0.5. That 
means that having someone with a differing opinion did more than 
just eliminate the bias; it actually reversed it.


Further, the advantages of divergent opinions are hard to fake. 
These researchers also told some groups to take the perspective of 
someone who preferred the other option and to debate the decision 
from his or her point of view. This devil’s advocacy approach did 
some good, but again, it just reduced the reinforcement bias, 
without eliminating it. 
Self-Perception


Self-perception is the idea that our beliefs are often consistent with our 
behavior—the opposite pattern of coherence, in which our behavior is 
consistent with our beliefs. 


One of the most influential theories used to explain self-perception 
effects is Leon Festinger’s cognitive dissonance. Dissonance theory 
posits that we tend to feel an unpleasant stress whenever we experience 
an inconsistency within ourselves, including when our behavior is 
inconsistent with our beliefs. On some level, we recognize that believing 
one thing and doing another isn’t good. We can resolve this inconsistency 
by bringing our behavior in line with our beliefs—and sometimes people 
do that—or we can change our beliefs to be in line with our behavior. 


Benjamin Franklin once astutely noted that people tend to be nicer to 
those for whom they have done a favor. Indeed, if you witness yourself 
doing someone a favor, you recognize that this action is inconsistent 
with negative feelings toward that person. Thus, on some level, you 
reason that doing the favor means that you must like this person. You 
then change your beliefs to match your behavior.

How You Decide: The Science of Human Decision Making
94


In 1959, the psychologists Elliot Aronson and Judson Mills documented 
this phenomenon with regard to hazing. They gave female students 
the opportunity to participate in a discussion group, which turned out 
to be mostly a boring lecture. Everyone had to read a passage aloud 
to a male experimenter in order gain entry to the group. Some of 
the participants had to endure a slightly embarrassing hazing ritual, 
reading aloud a list of mildly improper words. Those in the severe-
embarrassment condition had to read aloud a sexually explicit passage 
containing several obscene words. 


Afterwards, everyone was asked to rate how enjoyable they 
thought the discussion group was. Those who had to endure the 
more embarrassing task subsequently rated the boring lecture as 
more enjoyable.


It seems that for those who were willing to endure the 
embarrassment to participate, the group must be worthwhile. This 
is behavior driving belief.
A smoker might cope 
with the dissonance of 
his unhealthy habit by 
convincing himself that 
smoking is not as dangerous 
as the scientists say, that 
he is young and healthy 
enough that the dangers of 
smoking are not that great 
for him, or that he will quit 
sometime soon.

Lecture 12—How Consistency Drives Decisions 
95


The most fascinating result of self-perception is when people use 
behavior to fool themselves, using a process called symbolic self-
completion, a term coined by the psychologist Robert Wicklund and 
his research partners. This is the idea that when an important part of a 
person’s self-image is threatened or incomplete in some way, then the 
person can bolster that part of his or her self-image through external, 
symbolic means.


Suppose you are an older man, and nature is working hard to 
convince you that you are not as young and virile as you used to 
be. If that part of your self-image is important to you, you might 
be tempted to surround yourself with external symbols of youth 
and virility, such as a sports car. Based on the fact that you now 
drive a smart, fast car, you update your beliefs about yourself, now 
confident in your youth and virility.


People don’t usually articulate such arguments to themselves, but 
the outcome is the same. It’s like a shell game that we play against 
ourselves. We rig the outcome to bolster our self-image, updating 
our beliefs through the performance of strategic, self-enhancing 
behaviors.


This symbolic self-completion behavior occurs only when people feel 
insecure about some aspect of the self.


For example, in one study, researchers went to a tennis club and 
interviewed both novice and expert players about what they wore 
to tennis practice. Based on some initial assessments, they knew 
that being a tennis player was an important part of the self-image 
of all the participants. 


The experts, who had been playing in tournaments for years, were 
more likely to feel secure in this aspect of their self-concept. The 
novice players, in contrast, were largely aspirational. They couldn’t 
point to many tournament victories or years spent on the court in 
practice, and their self-concept was on much shakier ground.

How You Decide: The Science of Human Decision Making
96


Both groups were asked the same question: “For playing tennis, do 
you prefer clothing of a particular company or brand?” Among the 
experts, only 14% said yes. But among the novices, 63% said that 
the brand of clothing they wore mattered when playing.


The interpretation of these results is that the novice players—
whose self-concept is less secure—bolster their self-image through 
external symbols.
Suggested Reading
Lord, Ross, and Lepper, “Biased Assimilation and Attitude Polarization.”
Wicklund and Gollwitzer, Symbolic Self-Completion.
Questions to Consider
1.	 Coherence and reinforcement both refer to beliefs or attitudes. 
How do coherence and reinforcement differ from each other? How 
might these ideas help you understand how decisions are made in 
different settings?
2.	 According to self-perception theory, what do hazing rituals have in 
common with coupon shopping?

97
Lecture 13 
Social Influences on Decision 
Making
E
arly in his career, a psychologist named Robert Cialdini set out to study 
persuasion. He did extensive fieldwork on the topic of how people 
persuade others, looking for similarities across the methods of what 
he called “compliance professionals.” He then took those insights into the 
lab to determine which methods worked best and why. The result has been 
a staggering amount of research into social influences on decision making—
how people’s choices and decisions are influenced by the intentional and 
incidental behaviors of others. In this lecture, we’ll cover three principles of 
social influence that arise from Cialdini’s research: reciprocation, social proof, 
and authority.
Reciprocation


Reciprocation is the idea that when we receive something from others, 
we tend to feel obligated to respond in kind. It seems clear that some 
degree of reciprocation is necessary for society to function properly; in 
fact, reciprocation may serve as the cornerstone of civilization. It is also a 
strong influence on the decisions we make.


Suppose, for example, that you’re faced with the decision of whether 
or not to make a donation to a charity. Charities and nonprofits are 
well aware of the power of reciprocation when asking you to make 
that decision. This is why letters requesting donations often come with 
address labels or some other small gift. 


Some researchers tested the power of reciprocity in a field study with a 
company that sold insurance to small businesses. This company wanted 

How You Decide: The Science of Human Decision Making
98
Surprising as it may seem, 
even something as simple as 
including some mints along 
with the bill in a restaurant 
has been found to lead to 
larger tips.

Lecture 13 —Social Influences on Decision Making 
99
to conduct market research to improve its sales processes, but it often 
had low response rates when it mailed out surveys to clients.


The researchers randomly assigned the small business clients on the 
mailing list to receive one of eight different mailers. Some clients 
received just the survey, politely asking for a response. About 20% 
of small businesses in this condition sent the survey back, which is 
objectively low for the purpose of getting good data. 


The other seven conditions all got the same survey, but the mailers 
also included either cash ($1.00 or $5.00) or checks made out to 
the receiver in amounts of $5.00, $10.00, $20.00, or $40.00. In 
the last condition, survey recipients were told that if they filled 
out the survey and returned it, they would be mailed $50.00 as 
compensation for their time.


Response rates increased in all six of the reciprocation conditions. 
When people found $1.00 in the envelope, the response rate 
went from about 20% to about 40%. It went up to about 50% with 
$5.00. When the survey included a check, recipients seemed to be 
relatively insensitive to the actual amount of the gift: From $5.00 up 
to $40.00, all the response rates hovered a little higher than 50%. 


Interestingly, the $50.00 offered in exchange for completed surveys 
netted only a 23% response rate—just a couple of points higher 
than offering people nothing at all.


In this scenario, business owners were confronted with a choice: to 
fill out the survey or not. For many owners, receiving a gift upfront 
influenced that choice. The gift seems to have prompted them to 
think, “Because you’ve done me a favor, I guess I owe you one in 
return.” And that thought seems to have driven a specific decision 
to fill out the survey.


Reciprocation can be a powerful tool in sales and negotiation settings, 
as well. In particular, reciprocation is at the core of the door-in-the-face 
technique. This tactic starts by asking people for something large that 

How You Decide: The Science of Human Decision Making
100
they are likely to reject. Then, after the rejection, the negotiator follows 
up with a smaller request. 


The principle at play here is reciprocal concession. After you reject 
the initial offer, the negotiator or salesperson comes back with 
something that you are likely to find more appealing. It’s not what 
he or she really wants, of course; that was the initial request. But 
the salesperson will be “generous” and meet you halfway. 


Reciprocation then kicks in, and you feel some pressure to respond 
in kind. Your decision-making process has just been manipulated.


What makes this logic here particularly ridiculous is that we are 
remarkably insensitive to the starting point. Almost anything can be 
made to seem more reasonable or attractive by simply going more 
extreme with the first request or proposal. 


Cialdini and some colleagues ran an experiment in the 1970s in which 
they told college students on campus that they were looking for 
volunteers for a county youth counseling program. They asked some 
students if they would be willing to chaperone a group of youth on a 
day trip to the zoo. Only 17% agreed to go on the trip.


Other students, however, received the door-in-the-face treatment. 
These students were first asked if they would be willing to volunteer 
two hours per week as a youth counselor for a minimum of two 
years. Almost everyone said no. 


Then, after refusing the big request, the students were asked if 
they’d be willing to chaperone the zoo trip, and the number of 
people who agreed jumped to 50%.


Of course, a few things need to happen in order for someone’s act of 
kindness to generate feelings of reciprocity. 


First, the gift must be understood as a gift—as something extra 
or unexpected. If it is interpreted as fulfilling an obligation or as 
nothing out of the ordinary, then it is less likely to trigger reciprocity. 

Lecture 13 —Social Influences on Decision Making 
101


The other key for reciprocity to affect decision making is that the 
gift or concession must seem sincere. If someone makes a gesture 
that is interpreted as being purely strategic and mercenary, people 
feel no obligation to return that gesture. 
Social Proof


Another social influence on decision making is social proof. This term 
refers to the idea that we tend to behave in ways that are consistent with 
what we perceive to be the social norms and preferences of others. 


Social proof is one reason that cultural phenomena go viral. Popularity 
begets popularity. There are many examples of celebrities, videos, 
Marketers long ago figured 
out the power of telling 
potential customers, 
“Everyone else is doing it”; 
this is why we see “#1 Best 
Seller” promoted in ads and 
on displays so frequently.

How You Decide: The Science of Human Decision Making
102
books, and activities that seem to have no redeeming value of their own 
but somehow become inexplicably popular. 


You can find evidence of social proof everywhere, including examples 
of people turning social proof to their advantage. If you’ve ever worked 
a job with a tip jar, you were probably told on your first day never to 
empty the jar completely. When the jar is empty, customers get the 
subtle signal that tipping is not the social norm. A few bills and coins 
in the jar, however, give the signal that tipping is customary. And that 
subtle pressure applied through social proof is effective. Faced with the 
decision to tip or not to tip, people are more likely to put money in the 
jar if it is not empty.


Social proof can also be used to help people lead more normal lives. In 
the 1960s, some researchers worked with a group of children who had a 
phobia of dogs. Their approach was remarkably simple.


Researchers had young children come into the office and watch 
another young child play with a dog for about 20 minutes. The 
exercise was then repeated the next day. 


After just four days, two-thirds of the study participants were willing 
to climb into a playpen with a dog and stay there even after all the 
adults left the room—only four days to go from phobia to close 
contact! This all took place through the power of social proof: 
Seeing someone else doing something normalizes that behavior, 
making it seem more reasonable and appropriate. 
Authority


Yet another type of social influence is authority. This term refers to the 
propensity for people to decide in ways that are thought to be in line 
with the desires of perceived authority figures. In short, we tend to 
comply with authority.


The most famous example of this principle comes from the notorious 
compliance experiments conducted by Stanley Milgram in the 1960s. 

Lecture 13 —Social Influences on Decision Making 
103


In these experiments, people were brought into a room and 
told they’d be participating in a research study on memory. One 
experimental subject took on the role of the Learner (actually an 
actor, hired by the experimenters) and was hooked up to wires that 
would give him an electric shock any time he got a question wrong 
on the memory test.


The role of the participant—the person whose reaction was the 
true focus of the study—was the Teacher. His or her job was to 
administer the electric shocks. The third person in the room was the 
Experimenter, who would let the Teacher know when to administer 
the shocks and in what voltage.


These experiments found that people were appallingly compliant 
to authority. The electric shocks were fake, but they seemed real 
to the people administering them. The experimental participants 
became visibly upset by the Learners’ reactions. Some even 
begged to stop the experiment. But a surprising number of them 
kept administering the shocks when they were instructed to.


If people are willing to respond to authority in a setting where 
the outcome is so psychologically cruel, we can certainly expect 
compliance with authority to be generally powerful in less extreme 
situations, as well. 


As with the other social influences we’ve discussed, it’s not unjustifiable 
for someone to defer to authority. Where the situation gets tricky is 
when we defer, not to legitimate authority, but to our perceptions of 
authority, based on setting, behavior, or environmental cues. 


For example, the authority figure in the Milgram experiment wasn’t 
a legitimate authority, such as a police officer. He was just a man—in 
some cases, wearing a lab coat—running a psychology experiment. 


In that situation, however, he seemed like an authority figure; 
thus, people responded as if that authority were real and valid. 
They could have chosen to stop applying shocks, but the mere 

How You Decide: The Science of Human Decision Making
104
perception of an authority figure in the room led them to make the 
morally dubious decision to continue.


Once again, marketers have latched onto the power of authority in 
persuasive messaging, which is why we find the trappings of authority 
in ads and other marketing communications. People who give advice in 
ads are often dressed or look or act in such a way as to make them seem 
as if they have some authority.


These social influences—reciprocation, social proof, and authority—by 
no means represent an exhaustive list of the ways other people can 
influence our choices, but they are powerful and robust factors that 
guide many of the decisions we make.
Suggested Reading
Cialdini, Influence.
Questions to Consider
1.	 What is reciprocation, and why does it work? What are the settings or 
conditions under which we should not expect reciprocation to work?
2.	 Think of examples of social proof from your own life. When has 
social proof worked on you? When have you resisted the pull to 
conform with the crowd?

105
Lecture 14
Nonconscious Influences on 
Decision Making
T
he most famous experiment on subliminal advertising was conducted 
in 1957 by James Vicary. He worked with a movie theater to inter-
splice subliminal messages into films, urging people to “Eat Popcorn” 
and “Drink Coca-Cola.” Consequently, popcorn sales increased by 57.5% 
and Coca-Cola sales increased by 18.1%. The study seemed to provide 
proof that people can reach inside our minds, using pictures too fast to 
process consciously, and force us to do things that we otherwise wouldn’t 
do. Interestingly, however, the Vicary study never took place, and as a result, 
the topic of nonconscious influences became unfashionable. As we’ll see, 
however, many things can influence our beliefs, decisions, and behavior in 
subtle ways without our consciously being aware of them. 
Clarifying Terminology


When we talk about nonconscious influences, it’s common to talk about 
subliminal stimuli, but these two terms are not interchangeable.


The root term liminal is from a Latin word meaning “threshold.” In 
decision-making research, it refers to the point at which a stimulus 
enters the conscious awareness—the subjective threshold. Above 
the subjective threshold, we are aware that we have seen, heard, 
touched, tasted, or smelled something. When we are aware of 
something, we say that the stimulus is supraliminal.


If something occurs below the subjective threshold, it is subliminal. 
Our senses picked it up and some part of our minds processed it, 
but this happened below the level of consciousness.

How You Decide: The Science of Human Decision Making
106


Whether something is subliminal or supraliminal may be a 
function of attention and motivation. If you are on the lookout, 
you might notice something that otherwise might have escaped 
your attention. Some things, such as words or pictures flashed at 
fractions of a second, will always be subliminal for everyone. Our 
conscious minds require some minimum exposure duration for a 
stimulus to register. But a stimulus can also be subliminal if you are 
just not paying attention to it. 


We also need to understand conscious and nonconscious influences. 


Conscious influences are those messages that we recognize as 
potentially influencing us, such as persuasive attempts, goal 
reminders, memory cues, and so on. Such attempts may or may not 
be successful, but we know that an attempt was made.
Signs on the side of the 
road can be subliminal 
if you are focused on 
the traffic around you.

Lecture 14—Nonconscious Influences on Decision Making 
107


Nonconscious influences are things that could influence us in some 
way even though we are not aware of their influence. 


The distinction between supraliminal and subliminal does not map 
cleanly onto conscious and nonconscious influences. 


It is not the case that nonconscious influences are always subliminal. 
It is true that if subliminal stimuli have any influence on us at all, that 
influence must be nonconscious. 


Obviously, if we are aware of the influence, then the stimulus must 
be supraliminal. But it is not true that the influence of supraliminal 
stimuli must be conscious. As we will see, the fact that we are aware 
of a stimulus does not mean that we are aware of its influence on us. 
Thus, for supraliminal stimuli, the influence can be either conscious 
or nonconscious.
Goal Activation


One type of nonconscious influence is goal activation. The idea here is 
that goals exist as cognitive structures, but not all goals are active all the 
time. 


Some goals are specific and intentional, such as becoming fluent in 
Spanish, but many are not deliberately set and are nearly universal 
across people. Thus, we may have the goal of being a nice person 
or being honest. 


Because all goals can’t be active at once, we tend to focus on just 
a few at a time. Sometimes, we consciously choose which goals 
to focus on, but sometimes, those goals are activated by things 
we encounter in the world around us. Once latent goals have been 
activated, they can influence our decisions and behavior.


In one series of studies, researchers investigated the ability of cold 
temperatures to activate the goal of feeling warm. These researchers 
argued that once the explicit goal of feeling warmer was activated, 
people would seek out, not just physical warmth, but any means of 

How You Decide: The Science of Human Decision Making
108
feeling warm, including the latent goal of emotional warmth. In short, 
they argued that environmental cold can trigger a general preference 
for warmness that would lead, in this case, to an increased preference 
for romantic movies relative to other movie genres.


In one study, researchers asked participants to evaluate a series 
of movies, including asking how much they would be willing to 
spend to be able to watch the movie right then. The experimental 
manipulation was to change the temperature of the room in which 
If you activate the 
latent goal of being 
healthy, you might 
order salad instead of a 
hamburger for lunch.

Lecture 14—Nonconscious Influences on Decision Making 
109
the experiment was conducted. For some participants, the room 
was kept at 75 degrees; for others, the temperature was in the 59- 
to 60-degree range. 


People evaluated movies of all types, and there was no difference in 
willingness to pay based on room temperature—with one exception. 
People were willing to pay about one-third more for romance movies 
when it was cold in the room relative to when it was hot.


This is an example of nonconscious influences not needing to be 
subliminal. The temperature of the room was supraliminal; people 
were conscious of it. Despite this, the influence was nonconscious; 
people were not aware that the temperature influenced their 
preference for movie type. 


A different group of researchers tested a similar theory, attempting to 
activate the latent goal of cleanliness by encouraging people to think 
about morally questionable behavior. They reasoned that when we 
act in an ethically compromised way—or when we remember or even 
think about behaving badly—the goal to purify or cleanse ourselves is 
activated. 


These researchers thought that feeling ethically dirty can activate 
the nonconscious desire to cleanse ourselves in all ways, including 
physically. They called this the Lady Macbeth effect. 


Experimental participants were made to feel guilty by writing about 
a time when they had been dishonest or by hand-copying a first-
person account of someone betraying a work colleague. When 
in this state of feeling morally dirty, participants were given an 
opportunity to feel physically clean. In one study, they were asked 
to rate the desirability of 10 common consumer products. Of the 
products, 5 had nothing to do with physical cleanliness (such as 
juice or batteries), while the other 5 were cleaning supplies.


The non-cleaning products were rated as equally attractive 
regardless of how salient guilt was to the participants. But when 

How You Decide: The Science of Human Decision Making
110
participants had thought about acting in an ethically compromised 
way, they rated the cleaning products as significantly more 
attractive. Supraliminal cues that prompted people to think about 
guilt had the nonconscious influence of increasing preferences for 
physical cleanliness.
Evaluative Conditioning


The basic idea with evaluative conditioning is that when you pair some 
target stimulus with something that has a strong positive or negative 
effect, eventually, some of that effect will rub off onto the target, causing 
you to like the target more or less because of it. Evaluative conditioning 
can be either conscious or nonconscious.


In one study, people were shown several pictures of a man going about 
a normal day. The pictures were specifically chosen to be neutral. After 
viewing all the pictures, participants were asked to rate the man’s 
personality.


Unbeknownst to the participants, between each picture, they saw a 
14-millisecond subliminal message. In one condition, it was a single 
repeated picture of a cute child playing with a cuddly toy. In the 
other condition, the picture was of a ferocious shark. Of course, the 
man was rated as much less nice when his image was paired with 
the shark than when it was paired with the child.


Such findings may make people nervous, but consider everything 
the experimenters did to find an effect. They used a neutral man 
in a neutral setting. People basically had nothing else on which to 
base their judgments other than the vague disquiet that comes 
from subliminal exposure to a shark. In such settings, subliminal 
conditioning is likely to have an effect. 


Could subliminal conditioning influence the decision to vote for one 
candidate versus another? In the 2000 presidential campaign, a staffer 
for George W. Bush inserted a subliminal message into a television 
ad. The ad warned voters about one of Al Gore’s policy proposals that 

Lecture 14—Nonconscious Influences on Decision Making 
111
would turn over too much power to government bureaucrats. As the 
words bureaucrats decide zoomed onto the screen, the word rats was 
also visible for about 1/30th of a second.


For most people, 1/30th of a second is fast enough to be subliminal 
because people aren’t paying attention or looking for it. But to be 
reliably subliminal to everyone, the message would have had to be 
tens or even hundreds of times faster. 


One reason this instance of subliminal messaging didn’t work is 
that the word rats by itself is not likely to be strongly affect-laden. 
Further, for such conditioning to work, there must be more than just 
a single pairing, even if people see the ad several times.


Finally, most of the ad featured Bush’s face and a message about 
his policy agenda. The ad swiped at Bush’s opponent only a couple 
of times. It is unlikely that people would process the negative effect 
associated with rats and be so attuned as to match it up with Gore 
rather than Bush.
Capabilities of Nonconscious Influences


In a 1959 experiment, people watched a 16-minute film during which the 
subliminal message beef was flashed 140 times. Afterward, participants 
completed a survey, in which they were asked, among other things, how 
hungry they were. It turned out that people were significantly hungrier 
after watching the film that repeatedly flashed the word beef than other 
people, who saw an unadulterated version of the film. 


After viewing the movie, people were given the option of having some 
food, and one of their options was beef sandwiches. Interestingly, 
there was no change in the preference for beef sandwiches after the 
subliminal exposure.


This simple experiment tells us a great deal about when nonconscious 
influences are likely to work and what their capabilities are. 

How You Decide: The Science of Human Decision Making
112


It is possible for stimuli or environmental cues to influence us by 
activating goals or through affect transfer, but those effects are 
likely to be small. Can someone make you hungry using subliminal 
trickery? The answer is: probably. But you would eventually get 
hungry regardless. 


Could subliminal advertising drive your decision to purchase a 
specific brand of food? This is much less likely. There are simply too 
many things that drive preference for a specific food, and many of 
those things have a much stronger influence on us. 


Nonconscious influences are all around us and probably influence us in 
small ways all the time. But most of these effects are small, and usually, 
they are nudges in directions we were already leaning.
Suggested Reading
Hassin, Uleman, and Bargh, eds., The New Unconscious.
Hong and Sun, “Warm It Up with Love.”
Zhong and Liljenquist, “Washing away Your Sins: Threatened Morality 
and Physical Cleansing.”
Questions to Consider
1.	 What is the difference between subliminal and supraliminal? How 
do these ideas relate to conscious and nonconscious psychological 
influences?
2.	 What are the limits on nonconscious influences? What types of 
influences are likely to affect behavior? What types are unlikely to 
make much difference?

113
Lecture 15
An Evolutionary View of Decision 
Making
E
volutionary forces have shaped our decision making primarily in two 
ways. First, the structure of the decision-making apparatus in our 
minds is a function of the way our minds have evolved over millennia. 
Second, evolutionary forces shaped a set of motives and drives that can be 
activated in each of us and can drive our decision making, even today. Put in 
the language of our manufacturing metaphor, a set of motivational buttons 
and levers was hardwired into our control panels. As we’ll see, those buttons 
and levers are hidden beneath the panel’s surface controls and can guide our 
decision-making machinery in ways of which we are unaware.
A Primer on Evolution


Evolution describes the adaptive changes in a species from generation 
to generation. These changes are generated and guided by the three 
basic components to the simplest theories of evolution.


The first component is random variation, which is produced in each 
generation. Some variations are adaptive, meaning that they help the 
individual in some way that is relevant to survival or procreation. But 
some random variation produces maladaptations—changes that hurt 
the individual’s chances of survival or procreation.


The second and third components are the twin forces of natural and 
sexual selection. These forces sort people based on genetic fitness and, 
ultimately, determine which random variants are adaptive and which are 
maladaptive. 

How You Decide: The Science of Human Decision Making
114


Both selection processes allow an individual’s genetic traits to 
be passed on to future generations. Natural selection, broadly 
speaking, refers to the process by which traits that promote survival 
are passed down from generation to generation. 


Sexual selection, of course, refers to those traits passed down 
genetically that tend to make an individual more attractive to 
potential mates or that enable an individual to fend off sexual rivals.


From these two forces, we can derive a host of specific psychological 
predictions. In particular, we can observe how these forces may 
have created predispositions to respond to certain environmental 
cues in ways that would have increased our ancestors’ chances of 
survival and reproduction.
Many bird species 
are characterized by 
ostentatious plumage 
that is used to attract 
potential mates.

Lecture 15—An Evolutionary View of Decision Making 
115
Evolutionary Goals


Two prominent psychologists in this area, Douglas Kenrick and Vladas 
Griskevicius, have developed a framework of seven evolutionary goals 
that can affect individual decision making, and they’ve tied each of 
these goals to an associated “subself.” The basic evolutionary goals are: 
self-protection, disease avoidance, affiliation, status, mate acquisition, 
mate retention, and kin care. 


Two of these goals are tied to natural selection, or survival: Self-
protection and disease avoidance both help to ensure that you live long 
enough to mate and pass on your genes. 


Three of the goals are tied to sexual selection, that is, producing 
offspring and ensuring its survival: mate acquisition, mate retention, and 
kin care. 


The other two goals, affiliation and status, are arguably driven by both 
natural and sexual selection. 


The goal to affiliate encourages us to get along with others and 
work in groups. For our prehistorical ancestors, working in groups 
increased the chances of survival, and getting along generally 
improved the chances of our offspring surviving and prospering. 


The same is true of status. High-status individuals are more likely to 
have increased mating opportunities and more likely to survive and 
have children that survive than are low-status individuals.


These seven latent goals wait below the surface, and in innumerable 
subtle ways, our environments can activate them. Even if we aren’t aware 
of it, these core evolutionary goals can play a part in both mundane and 
important decisions.


Kenrick and Griskevicius explain the activation and interplay of these 
goals in terms of different aspects of the self. We all have within us 
different self-concepts that are activated at different times in response 
to the environment. 

How You Decide: The Science of Human Decision Making
116
Affiliation Goal 


When testing the affiliation goal, psychologists derived the prediction 
that social rejection is likely to activate the goal to affiliate with others. 
These researchers further predicted that when the affiliation subself was 
active, people tend to be more accommodating in their evaluations of 
others. Think of it this way: If you are at a party, you have a series of 
decisions to make regarding whether or not to approach someone and 
introduce yourself. Such decisions can be influenced, in part, by the 
goal to affiliate. If you have a strong need to affiliate, you might start to 
see people as friendlier and more approachable.


To test this prediction, the researchers had participants first interact with 
a large group of people—mingling and making small talk—under the 
guise that they were involved in a study examining group dynamics. 


Next, participants were placed in their own small rooms to wait 
while the researchers ostensibly formed small groups. Everyone 
was given a piece of paper that read: “We are interested in forming 
groups in which the members like and respect each other. Below, 
please name the two people (out of those you met today) you 
would most like to work with.”


A few minutes later, a researcher came back to the room and said 
that, unfortunately, they couldn’t proceed with the small-group 
exercise. Participants were given one of two reasons for the change 
of plans. People in the high-social-acceptance condition were told 
that everyone else had selected them to be in their group. People 
in the low-social-acceptance condition were told that no one had 
selected them.


In a separate task, participants were asked to rate the “sociability” of a 
series of faces that had been pre-tested to be of moderate attractiveness 
and to have neutral expressions. People in the high-social-acceptance 
condition rated the faces as neutral, while those who had first been 
socially rejected saw the neutral faces as significantly nicer, friendlier, 
more attractive, and more desirable. It seems as if being rejected 

Lecture 15—An Evolutionary View of Decision Making 
117
activates the goal to affiliate, and that goal drives us to look for any 
opportunity to approach and bond with others. 


Perceptions of sociability matter because they affect decisions 
about how to interact with other people. Presumably, this change in 
perceptions of sociability would lead to differences in decisions about 
whether or not to approach a stranger at a social function. When the 
affiliation subself is active, our decisions will bend in the direction of 
connecting with other people and strengthening social bonds.
Self-Protection and Mate-Acquisition Goals


The decision of whether to conform to or diverge from the group can 
be driven by a variety of factors. From an evolutionary psychology 
perspective, the goal of affiliation clearly leads to conformity, as does 
the goal of self-protection. In contrast, divergence from the group tends 
to be a preferred strategy when the mate-acquisition goal is active. 


Some researchers tested these conflicting paths toward conformity and 
uniqueness. They first activated an evolutionary goal state by having 
people watch one of two movie clips. People in the mate-acquisition 
condition watched a few minutes from the romantic movie Before 
Sunset. In the self-protection condition, people saw a clip from The 
Shining, in which a writer tries to murder his family. 


After watching one of these clips, people were asked to participate 
in an ostensibly unrelated study in which they evaluated a number 
of proposed ads for various products. There were two versions 
of each ad, one relying on a popularity appeal and one using a 
uniqueness appeal.


Consistently, people who were in the self-protection condition 
rated the popularity appeals higher, while those in the mate-
acquisition condition responded more favorably to the ads with the 
uniqueness appeal.

How You Decide: The Science of Human Decision Making
118


If you are trying to attract a mate, the uniqueness appeal fits the 
bill. But if you are thinking about being chased down by a maniac, 
then being surrounded by people seems advantageous.


This matters because the decisions you make depend, in part, on how 
persuasive you find associated advertising appeals. And how persuasive 
you find those appeals is a function of which subself happens to be 
activated.
Mate-Acquisition Research


One major mediator of mate-acquisition behavior seems to be driven 
by changes in sex hormones. This means that men and women tend to 
behave differently when this goal state is activated.


The male response seems to be more easily activated by environmental 
cues, partly because testosterone levels are highly responsive to 
different situations. When testosterone levels increase as a result of a 
mate-acquisition goal, men tend to be more nonconforming. They also 
engage in more conspicuous consumption and become more gain-
seeking, creative, and risk-seeking.


In one study, researchers Richard Ronay and William von Hippel 
studied the behavior of teenagers at a skate park, using experts 
to rate the difficulty of the tricks they were trying. The researchers 
then had an attractive young woman enter the skate park to watch. 
Suddenly, the tricks got flashier and more dangerous. 


By taking saliva samples from some of the young men, the 
researchers confirmed that testosterone levels increased when the 
attractive girl appeared; this seems to have led to an increase in 
decisions to try risky stunts.


For women, mate-acquisition goals tend to be less situational and more 
cyclical. The hormones that drive female mate-acquisition behaviors 
seem to be less influenced by the immediate environment but driven 
instead by the ovulatory cycle.

Lecture 15—An Evolutionary View of Decision Making 
119


In one study, led by Kristina Durante, undergraduate women 
were asked to give a urine sample; the sample was used later to 
determine which participants were ovulating during the experiment. 
All participants were then asked to perform an online shopping 
task, where they could pick their favorites from a variety of clothing, 
shoes, and accessories.


When the researchers correlated the participants’ clothing 
preferences with hormone levels, they found that when they 
were ovulating, participants were more attracted to clothing and 
accessories that were independently rated as being more alluring. 
In short, the underlying goal state subtly influenced the kind of 
choices the women might have made on a shopping excursion.
Of course, status goals can lead to 
ostentatious displays, but status can 
also be gained by conspicuously 
consuming a virtuous product, such 
as a hybrid car.

How You Decide: The Science of Human Decision Making
120
Evolutionary Psychology as a Framework


In an earlier lecture, we talked about Maslow’s hierarchy of needs as one 
framework for categorizing the various motivations that drive people’s 
decision making. Consider evolutionary psychology—and the subselves 
framework—to be another approach for trying to organize the chaotic 
tangle of motivations that drive human decision making.


Where most of Maslow’s goals might be considered conscious goals, 
most evolutionary goals might be considered nonconscious. Often, we 
are not aware that these evolutionary goal states have been activated in 
us by some factor in the environment or in our own bodies.


These surprise motivations can be helpful or distracting. But even if 
they are not always well-suited to everyday decisions, they served our 
ancestors well enough for those traits to be passed down to us.
Suggested Reading
Kenrick and Griskevicius, The Rational Animal.
Questions to Consider
1.	 What is a “just-so” theory? Why is this criticism often applied to 
research on human evolution? What is the scientific defense against 
charges of creating just-so theories?
2.	 What are some of the differences in motivation caused by the seven 
subselves identified by Kenrick and Griskevicius?

121
Lecture 16
Regulatory Focus and Human 
Motivation
T
he idea that people approach rewards and avoid punishments is fairly 
basic and serves as one of the foundational insights that underlies 
entire schools of psychological thought, from decision making 
to animal learning. Indeed, for many years, it was thought that the major 
structure of goal-derived decision making fit into these two categories. But 
in the late 1990s, a psychologist at Columbia University named Tory Higgins 
suggested we could better understand the so-called pleasure principle 
by introducing another motivational factor that cut across approach and 
avoidance. The result was a motivational theory called self-regulatory focus, 
which we’ll discuss in this lecture.
Motivational States


To understand self-regulatory focus, let’s begin with a specific example 
involving the various motivations people might have for wanting to work 
hard at their jobs. 


Some people are motivated by the potential for gain. They work 
hard because they want promotions and raises. 


Others work hard to avoid getting fired. They don’t want to lose 
what they have.


Some people work hard because they want job security. Notice that 
both seeking a promotion and seeking job security are approach 
motivational states, but one group is approaching a gain, while the 
other is approaching a non-loss. This divides the general approach 
orientation into two categories based on what is being approached: 
gains or non-losses.

How You Decide: The Science of Human Decision Making
122


The same thing can be done for avoidance goals. Some people 
work hard because they want to avoid getting fired (a loss), but 
others work hard because they want to avoid getting stuck in their 
current jobs (a non-gain). 


Ultimately, these motivations change the control-panel settings that 
guide our cognitive decision-making machinery.


We can envision these four main motivational states as laid out on a grid.


Picture a vertical line intersected in the middle by a horizontal line. 
The top half of the vertical line indicates an approach motivation, 
while the bottom half indicates an avoidance motivation.


Bisecting this axis is a horizontal line that maps Higgins’s 
regulatory focus. On the left side of the horizontal axis is a 
promotion orientation, while on the right side is a prevention 
orientation. 


The four quadrants formed by the intersecting lines are the four 
goal states. Thus, in the upper-left quadrant, we find people 
with an approach motivation and a promotion orientation (a 
gain end state). These people tend to be motivated by securing 
advancement and happiness. In the upper-right quadrant, we 
find an approach motivation paired with a prevention orientation 
(a non-loss end state). These people tend to seek security and 
calmness.


The bottom two quadrants are avoidance motivations. In the 
bottom-left quadrant, avoidance is paired with a promotion 
orientation (an end state of avoiding non-gains). People in this 
motivational state want to avoid ending up sad or unfulfilled. In 
the bottom-right quadrant, avoidance motivation is paired with 
prevention orientation (an end state of avoiding losses). People in 
this state seek to mitigate threats and reduce anxiety.

Lecture 16—Regulatory Focus and Human Motivation 
123
Chronic Regulatory Focus


Research shows that people tend to naturally favor either a promotion 
orientation (in which the primary concern is approaching gains and 
avoiding non-gains) or a prevention orientation (in which the primary 
concern is avoiding losses and approaching non-losses). Psychologists 
refer to the tendency toward one of these orientations or the other as 
a chronic state.


Your chronic regulatory focus orientation is a function of many things, 
including your culture and the way you were raised.


It is not the case that one type of focus is better than another. These 
orientations are simply different ways people have of thinking about 
goals and motivations. Further, although we all tend to have a chronic 
preference for one of these states over the other, regulatory focus is 
relatively fluid and can be shifted easily. 
Research suggests 
that people raised in 
similar cultures tend to 
have a similar chronic 
regulatory focus.

How You Decide: The Science of Human Decision Making
124
Regulatory Fit


Regulatory focus has become popular among researchers because it is 
consistently able to predict behavior, and its predictive power comes 
from a simple idea. If you have a preference for thinking about gains 
and non-gains or about losses and non-losses, then you will respond 
to things that are framed in such a way as to be consistent with that 
regulatory focus. This is known as regulatory fit. 


Experiencing regulatory fit “feels” right. You’ll find this state to be more 
persuasive, more motivating, or more attractive.


For example, imagine these two scenarios: (1) You book a flight, 
but because you must postpone your ticket purchase, you end 
up spending an extra $50.00 above the usual cost. (2) You had 
the opportunity to save $50.00 on a ticket, but you missed the 
chance. 


In both cases, you are out $50.00 relative to what you might 
have spent. But in one scenario, the $50.00 came in the form of 
a loss. (Paying more than expected is generally coded as a loss.) 
The other is a non-gain—failing to take advantage of savings. For 
many people, the feelings elicited by those types of pain are not 
equivalent, even if they involve the same amount of money. 


Higgins and his colleagues found that people with chronic 
promotion orientations were more sensitive to scenarios about 
non-gains, while people with chronic prevention orientations were 
more sensitive to scenarios about losses.


The explanation given for the finding was regulatory fit. If you have 
a promotion orientation, you will tend to be more sensitive and 
react more strongly to gains and non-gains. It is as if your mind 
is more prepared to process those types of stimuli; thus, your 
reactions will be more finely attuned. In the case of aversive stimuli, 
a person with a promotion orientation will find non-gains more 
aversive than losses of a similar magnitude.

Lecture 16—Regulatory Focus and Human Motivation 
125
Goal Pursuit


Regulatory fit has also been used to explain the means by which people 
strive to achieve their goals. For example, if you want to lose weight, 
you could seek out foods with certain nutritional characteristics or you 
could seek to avoid certain foods.


Regulatory-fit theory predicts that the strategies people use in goal 
pursuit will be consistent with their regulatory focus. 


If you are a promotion person, it is likely that “eager” strategies will 
resonate with you. You’ll look for ways to make changes now, focus 
on ideal outcomes, and be motivated by thoughts of success. 


If you are a prevention person, then “vigilance” strategies are more 
likely to appeal to you. You’ll be motivated by thoughts of what will 
happen if you fail to meet your goal, and you’ll try to make sure 
that doesn’t happen.
Regulatory fit is especially useful 
when trying to tease apart why 
certain appeals, attributes, or 
options seem to interest some 
people but can fall flat with others.

How You Decide: The Science of Human Decision Making
126


When people pursue goals using strategies that conflict with their 
regulatory focus, they experience misfit and are generally less successful 
at achieving their goals. 
Persuasion


People in a promotion frame of mind tend to find gain-focused appeals 
more persuasive, while those with a prevention orientation seem drawn 
to arguments about avoiding losses and obtaining non-losses.


Angela Lee, from Northwestern University, and Jennifer Aaker, from 
Stanford, tested this proposition, presenting experimental participants 
with two versions of an ad for Welch’s grape juice. 


The text of one ad emphasized that grape juice can create energy, 
is delicious, and is fun to drink—a gain-focused message. The 
other ad focused on the health benefits of grape juice—its levels 
of antioxidants to reduce the risk of cancer and heart disease and 
flavonoids to help blood flow freely. Essentially, this ad focused on 
the ways grape juice could help someone avoid negative health 
outcomes, or losses.


The researchers found that after viewing the gain-focused ad, 
people with promotion orientations liked Welch’s grape juice 
more. In contrast, the loss-focused ad that emphasized health 
benefits led to prevention-oriented people liking Welch’s more. 
The ads were more persuasive when the message fit with the 
person’s regulatory focus.


The importance of regulatory fit in anticipating persuasive messages 
has also been tested in public-health messaging. Guangzhi Zhao and 
Connie Pechmann developed several versions of a 30-second anti-
smoking public service announcement. In their studies, the ads were 
seen as more persuasive when there was a high degree of regulatory 
fit.

Lecture 16—Regulatory Focus and Human Motivation 
127
Regulatory Fit and Decision Making


Research also suggests that regulatory fit has the potential to influence 
decision making at several points in the process, starting with the way 
information is acquired, through how that information is weighted, to 
the type of decision that is ultimately made.


Evidence shows that people construct preferences that are consistent 
with their regulatory focus. 


Imagine that you were evaluating new toothpastes from brands 
you’ve never heard of. Each toothpaste is described by several 
attributes, such as ability to freshen breath, control plaque, and 
so on. 


Much research in decision making suggests that you likely 
don’t have strong pre-formed preferences about which of these 
attributes is more important and, instead, form your preferences in 
the moment, based on the information you have available to you 
(known as constructed preferences). A regulatory fit perspective 
on constructed preferences predicts that you will construct your 
preferences to be consistent with your regulatory focus.


Researchers Jing Wang and Angela Lee tested this prediction 
by inducing a group of people to have either a promotion 
orientation or a prevention orientation. Then, they had the people 
evaluate toothpastes. They described various toothpastes using a 
combination of six attributes: three that were promotion focused 
(freshening breath, whitening teeth, and strengthening tooth 
enamel) and three that were prevention focused (preventing 
cavities, preventing gingivitis, and controlling plaque).


People with promotion orientations tended to form preferences 
for toothpastes that excelled on the promotion attributes, and 
prevention-oriented people formed preferences for toothpastes 
that were better on prevention attributes.

How You Decide: The Science of Human Decision Making
128


Finally, regulatory fit can even influence the types of decisions we 
are inclined to make. Often, the decisions we make are based not on 
certain outcomes but on probability estimates. There are four possible 
outcomes from a probability decision: (1) a hit, (2) an error of omission, 
(3) a correct rejection, or (4) an error of commission.


These four decision outcomes map fairly cleanly onto the four 
quadrants of the approach/avoidance matrix. For people with a 
promotion orientation, the regulatory-fit hypothesis would predict 
that they should favor decision strategies that are consonant 
with eager, gain-focused approaches. In other words, promotion-
oriented individuals should be primarily focused on maximizing hits 
and avoiding errors of omission. 


Prevention-oriented people, in contrast, are primarily focused on 
vigilant, loss-focused strategies. They want to maximize correct 
rejections and minimize errors of commission.


The end result is that regulatory fit can affect the strategies we use when 
making our decisions, encouraging more eager, gain-focused decisions 
or more vigilant, loss-focused ones.
Suggested Reading
Higgins, “Promotion and Prevention.”
Lee and Aaker, “Bringing the Frame into Focus: The Influence of 
Regulatory Fit on Processing Fluency and Persuasion.”
Molden, Lee, and Higgins, “Motivations for Promotion and Prevention.” 
Questions to Consider
1.	 How are promotion/prevention orientations different from 
approach/avoidance motivations?
2.	 What is regulatory fit? How does regulatory fit influence decision 
making?

129
Lecture 17
Decision Rules
I
n this lecture, we’ll discuss decision rules people use when making 
choices. This may seem like a hopelessly complex question, but to help 
us get a grasp on the topic, we’ll start with a stylized, simplified choice 
context. We can later build on this context, making things more complex 
and realistic. But what this simplified setting lacks in external validity—that 
is, real-world generalizability—it makes up for in internal validity. Simplified 
settings give us an uncluttered experimental perspective that lets us zero in 
on the kinds of decision rules people can use in any setting.
Case Study of Decision Rules


Let’s suppose that you are trying to decide where to go on vacation. You 
find three vacation packages that seem to have potential, and you find 
a travel website that has rated each of them on the four attributes that 
matter most to you: price, activities, hotel amenities, and hotel view. 


Each of these vacation packages excels in some areas and is deficient in 
others. The table below shows the ratings (on a 5-point scale) for each 
of the attributes under consideration. Because there is no clear winner, 
making a decision from this set requires making some tradeoffs.
Vacation
Price
Activities
Amenities
View
A
5
4
1
4
B
3
5
3
1
C
2
4
5
2


Even from this simplified consideration set, people have enormous 
flexibility in how they might approach this decision. (These insights 

How You Decide: The Science of Human Decision Making
130
come from the work of researchers Jim Bettman, John Payne, and 
Eric Johnson.) Possible strategies people can use vary on a number 
of important dimensions, including the amount of information 
processed, the order in which information is gathered (by attribute or 
by option), how the information is weighted (either compensatory or 
noncompensatory), and how accurate the decision rules are. 


With regard to accuracy, some choices can be evaluated as 
objectively right or wrong. If option A and option B are identical 
in every way, except that option B is $10.00 cheaper, then we 
have a clear winner. And the accuracy of a decision rule could be 
measured based on whether it leads someone to choose option B.


But most often, consideration sets are not nearly so clear cut. Even 
the simplified set of vacations we started with does not have an 
The fatal-flaw approach to decision 
making (noncompensatory) means 
that if one option, such as hotel 
activities or price, is not sufficiently 
good on some attribute, it is out of 
further consideration.

Lecture 17—Decision Rules 
131
obvious winner. In such cases, the most accurate decision is not the 
optimal one in an objective sense. Instead, accuracy is evaluated 
relative to what would be the best choice for you. 
Weighted-Additive Rule


The most accurate way of making decisions is to follow the weighted-
additive rule. This rule requires knowing which attributes are most 
important to you and the importance of each attribute relative to the 
others. Based on these ratings, the decision maker assigns weights to 
each attribute.


For example, suppose that the most important attribute to you is activities. 
You might assign that a decision weight of 0.4. For hotel amenities, you 
assign a weight of 0.3; for price, 0.2; and for hotel view, 0.1. (When 
following the weighted-additive rule, it’s traditional to make the attribute 
weight fractions add up to 1 when summed across all attributes.)


We then multiply the score given to each attribute on the travel website 
by our own decision weights, sum the results, and get an overall score 
for each option. Using this approach, Vacation C has the highest overall 
score, with 3.7. (See table below.) 
Vacation
Price × 
Weight  
(= 0.2)
Activities × 
Weight  
(= 0.4)
Amenities × 
Weight  
(= 0.3)
View × 
Weight  
(= 0.1)
Total
A
5(0.2)
4(0.4)
1(0.3)
4(0.1)
3.3
B
3(0.2)
5(0.4)
3(0.3)
1(0.1)
3.6
C
2(0.2)
4(0.4)
5(0.3)
2(0.1)
3.7


Obviously, the weighted-additive rule requires extensive information 
processing. We can’t come to an overall score for each option unless we 
evaluate all the information for each option on every attribute.

How You Decide: The Science of Human Decision Making
132


This decision rule also encourages by-option processing. We create a 
summary score for each option before moving on to the next one, and 
only the weighted total scores are ultimately compared.


Weighted-additive is a compensatory decision rule. One weakness 
won’t necessarily knock an option out of consideration. The rule relies 
on holistic assessments of the options.


The weighted-additive rule is an effortful way to make decisions, but it 
should also lead to the most accurate outcomes. If you know your own 
preferences well enough to accurately assign attribute weights and if 
you can accurately assess each option’s attribute performance, then this 
method will all but guarantee that you will get the best option.
Elimination-by-Aspects Rule


Another strategy, proposed by Amos Tversky, is the elimination-by-aspects 
rule. Using this rule, we drop options from consideration until we get a 
winner. To do this, we again need to know which attributes are most 
important to us. But even at this first stage, this rule is easier than weighted-
additive. We need to know only the order or ranking of the attributes; we 
don’t need to know exactly how important each is relative to the others. 


Again, suppose that you consider activities to be the most important 
attribute, followed by amenities, price, and view. We start by setting 
a minimum threshold for the most important attribute. If an option is 
not good enough on that attribute, then it is eliminated from further 
consideration.


Because activities are so important to you, you set a threshold of 4 for 
that attribute. The second most-important attribute is hotel amenities; 
for this, you are willing to accept anything that scored 3 or higher. 
Vacation A is now out because it scored only 1 on amenities. For the 
third most-important attribute, price, we assume a threshold of 3 again. 
We can now eliminate Vacation C because it scored 2 on price. Vacation 
B is the only remaining option.

Lecture 17—Decision Rules 
133
Vacation
Price 
Attribute 
rank: 3 
Cutoff 
value: <3
Activities 
Attribute 
rank: 1 
Cutoff 
value: <4
Amenities 
Attribute 
rank: 2 
Cutoff 
value: <3
View 
Attribute 
rank: 4 
Cutoff 
value: <2 
Elimination 
Order
A
5
4
1
4
Round 2
B
3
5
3
1
Winner
C
2
4
5
2
Round 3


Notice that using a different decision rule can lead to different outcomes, 
even for someone with a consistent and stable set of preferences. Here, 
you ended up with a different vacation.


Elimination-by-aspects is not as demanding in terms of the amount 
of information that needs to be processed. 


This method also differs in the order in which information is 
processed. This is a by-attribute decision rule. First, an attribute is 
selected; then, all the options are assessed on that attribute. Then, 
we move on to the next attribute, and the remaining options are 
assessed.


Finally, this is a noncompensatory rule. Unlike weighted-additive, if 
an option doesn’t make the cut on one of the early attributes, it’s 
out. It can’t make up for it by being great on another attribute.
Satisficing


Yet another decision rule is satisficing, identified by Herbert Simon. The 
purpose of this rule is not to come to the optimal conclusion; rather, the 
point is to find the first option that is good enough. 


As a formal decision process, satisficing requires rank-ordering the 
attributes in terms of importance and determining some cutoff threshold 
for those attributes. However, instead of working through the list and 

How You Decide: The Science of Human Decision Making
134
dropping options that are not good enough, satisficing looks for the first 
option that is good enough, according to the thresholds.


Let’s use the same attribute ranking and thresholds we used in the 
previous example. Vacation A makes the cut on activities, which means 
that we’re done. 
Vacation
Price 
Attribute 
rank: 3 
Cutoff 
value: <3
Activities 
Attribute 
rank: 1 
Cutoff 
value: <4
Amenities 
Attribute 
rank: 2 
Cutoff 
value: <3
View 
Attribute 
rank: 4 
Cutoff 
value: <1 
Evaluation
A
5
4
1
4
Winner
B
3
5
3
1
C
2
4
5
2


Of course, satisficing is highly sensitive to the order in which options are 
evaluated. If there were more than one option that satisfied the thresholds, 
then the first one to be encountered would be chosen. Given the often 
arbitrary way that information about options comes to us, satisficing can 
produce inconsistent choices over time, but it is fast and easy.
Revealed Preferences


Researchers have identified eight decision rules that people use to 
make choices. And each of them can return different choices—even for 
a person with the same basic set of preferences.


This finding—that people with relatively stable and well-defined 
preferences can make different choices depending on the decision rule 
they apply—challenges some economic models of decision making. 
Many of these normative models are based on the assumption of 
revealed preferences—that someone’s true preference structure can be 
inferred based on his or her behavior. 

Lecture 17—Decision Rules 
135


Like so many of the assumptions that underlie rational, normative decision 
models, this one seems reasonable. Choosing one option over another 
would seem to be fairly reasonable evidence about your true preferences. 
Nevertheless, the work on decision rules shows that this assumption is not 
always justified. The same underlying preferences can lead to different 
decision outcomes, depending on the decision rule used.


This insight led to a new way of thinking about decision making. 
Normative models of decision making largely assumed that people 
chose by selecting the option that maximized their utility, subject to 
some budget constraints. This means that making a choice is simply a 
matter of comparing each option to an internalized ideal point. 


But the work on decision rules suggests something different: that at least 
some of the time, we may have only a vague idea of what we want. With 
such general guidelines, we can select different decision rules and arrive 
at different outcomes. Rather than pointing to preexisting preferences, 
research on decision rules indicates that we often construct preferences 
in the decision situation itself. 
Real-World Decision Making


In the real world, we rarely encounter choice sets in which all the 
information is available and easily comparable for every option. But 
if we abstract a little, we can see how people might do something 
approximating those strategies. 


If we are thorough, we come reasonably close to a weighted-
additive mode of decision making. 


If we skim what’s available and pick the first option that seems good 
enough, we come close to satisficing.


What’s even more common in real life is that people use multiple 
decision rules at different stages in the decision process. One common 
strategy is to use an easy, noncompensatory rule, such as elimination-
by-aspects, when the choice set is large, but switch to a harder, more 

How You Decide: The Science of Human Decision Making
136
In buying a laptop, 
you may initially use 
an elimination-by-
aspect strategy to 
cull your options; 
you may then switch 
to a weighted-
additive strategy 
to arrive at a more 
accurate decision.

Lecture 17—Decision Rules 
137
accurate, compensatory rule when the choice set has been winnowed 
down to something more manageable.
Suggested Reading
Bettman, Luce, and Payne, “Constructive Consumer Choice Process.”
Payne, Bettman, and Johnson, The Adaptive Decision Maker.
Questions to Consider
1.	 What is the difference between compensatory and 
noncompensatory decision rules? What are the implications of each 
for decision making?
2.	 What is satisficing? How does it differ from a weighted-additive 
decision rule?

138
Lecture 18
How Context Influences Choice
W
e’ve been using the metaphor of manufacturing to describe 
the human decision-making process. We’ve talked through the 
cognitive machinery common to all of us and the complex and 
imperfect set of controls we have at our disposal to regulate that cognitive 
machinery. In this lecture, we’ll discuss the raw materials that serve as inputs 
to our decision-making process. In fact, the options we consider—how they 
are described, which options accompany them, and how many options we 
have—all serve as input to our decisions. And subtle, seemingly irrelevant 
changes in those raw materials can ultimately influence the choices we make. 
Choice Context and the Decoy Effect


From a decision-research standpoint, context can be defined as the 
immediate environment in which decision options are considered, 
including the composition of the set of options under consideration. 
Some contexts influence decision making by providing reasons for 
choosing a particular option.


Perhaps the most well-known phenomenon in this area is the decoy 
effect. This effect is seen at times when adding a third option to a set 
changes the relative preference for the original two options.


Suppose you were buying a car and found two cars that were more 
or less equivalent, but one offered a more comfortable ride and the 
other had better gas mileage. (See table below.) Decision scientist 
Itamar Simonson gave this choice 
set to a group of people in the 
late 1980s and found that about 
40% chose Car B—the one with 
the better gas mileage.
Car
Ride Quality
MPG
A
83
24
B
73
33

Lecture 18—How Context Influences Choice 
139


A different group of people saw 
the same two options but was 
also given a third car to consider: 
Car C. 


When given this three-option 
choice set, basically no one chose 
Car C, but the relative choice share of Car B shot up to more than 
60%. That is, adding Car C to the set made Car B more attractive 
than it was in the set with just A and B. The simplest explanation for 
this result is that Car C provided a reason for choosing Car B.


Notice that Car C is not uniformly worse than the other two; instead, 
it is asymmetrically dominated—dominated by one of the options 
but not the other. Car C was strictly worse than B. It had the same 
miles per gallon but a worse ride quality; thus, Car B dominates 
C. Car A had much better ride quality, but Car C had better 
gas mileage; thus, Car A does not dominate C. The asymmetric 
dominance provides a reason for choosing B.


The presence of Car C is not a particularly good reason for choosing 
Car B. But even though the decoy is objectively irrelevant, it can 
still influence choice. The way that raw material is presented affects 
the choice that is ultimately manufactured from it.


Psychologist Dan Ariely and colleagues tested the decoy effect in 
the context of evaluating the attractiveness of human faces. Using a 
computer simulator, the researchers created two faces (Tom and Jerry) 
of roughly similar levels of attractiveness. 


In each trial, people were shown the two baseline faces, plus a 
decoy face. The decoy was made by making one of the original 
faces—Tom or Jerry—slightly less attractive. 


In trials where there was a Jerry decoy in the mix, people tended 
to rate Jerry as the most attractive face in the bunch. In trials where 
there was a Tom decoy, Tom was viewed most favorably.
Car
Ride Quality
MPG
A
83
24
B
73
33
C
70
33

How You Decide: The Science of Human Decision Making
140


The vast majority of the research on the decoy effect was done in 
settings where people were presented with options laid out in tables, 
with the attribute values mostly expressed numerically. Later research has 
shown that when information is presented in somewhat more naturalistic 
settings, the evidence for the decoy effect becomes much weaker. 
Compromise Effect


The compromise effect is similar to the decoy effect. It also involves 
adding an option to a binary choice set and invokes reason-based 
decision making as its most prominent explanation. 


The compromise effect is rooted in the common human tendency toward 
extremeness aversion. There are certainly exceptions to this rule, but in 
many settings, people tend to avoid extreme options. In large sets, this 
often means that the highest and lowest options will be neglected. 


When dealing with three-option sets, the middle, or compromise, option 
tends to be preferred. Returning to our car example, if one car is better 
on ride quality, and another is better on gas mileage, we might expect to 
increase the choice share of one of the options by adding a more extreme 
option to the set that made one of the original two a compromise.


Suppose we add Car D to our original 
set. Car D is better than A on ride 
quality but worse on gas mileage. 
This makes Car A moderate on ride 
quality—not the best in the set but 
not the worst either. Car A is also 
moderate on mileage (see below). 
In such a context, we would expect 
the relative choice share of Car A to 
increase.


Note that this is different from the decoy effect. Car D is not a decoy; 
it’s not dominated by either of the other cars. If all you care about is ride 
Car
Ride Quality
MPG
A
83
24
B
73
33
C
70
33
D
93
18

Lecture 18—How Context Influences Choice 
141
The fact that the best-
selling wine in a restaurant 
tends to be the second 
least-expensive option 
is an example of the 
compromise effect at work.

How You Decide: The Science of Human Decision Making
142
quality, then Car D is the one for you. But adding Car D changes the 
relative preference for A and B. Car A suddenly becomes more attractive 
because it is neither the best nor the worst on any single dimension. 
And that becomes a reason for choosing it. 
No-Choice Options


Research has found that choices can even be influenced by whether or 
not the option not to choose is salient at the time of choice. 


In a series of studies conducted by marketing professors Jeff Parker 
and Rom Schrift, different groups of people were given identical choice 
sets—say, two cameras—in which the only difference was that some 
people were asked which camera they would choose, and some people 
were also given the option not to pick one but to keep looking for other 
options. Across the studies, the no-choice option wasn’t particularly 
popular, but just having that option available was enough to influence 
which of the two cameras people selected.


Parker and Schrift argue that the salience of a no-choice option changes 
the nature of the questions people ask themselves when evaluating 
options. 


When asked which of the two options they would choose (a forced-
choice scenario), people intuitively ask themselves, “Which option 
is better?” When trying to answer that question, people tend to 
do attribute-by-attribute comparisons across the options, and the 
outcome of this process usually favors easy-to-compare attributes. 
Attributes with numerical values are inclined to carry more weight 
than “squishier” attributes, such as brand. 


Contrast that with a choice set in which the option not to pick but 
to keep looking is salient. Now, instead of asking which is better, 
people first ask themselves whether either of the options is worth 
picking at all. When faced with that question, people tend to 
process information differently. Instead of attribute-by-attribute 
processing, they engage in option-by-option processing, in which 

Lecture 18—How Context Influences Choice 
143
easy-to-compare attributes are not nearly as influential. Instead, 
qualitative attributes, such as brand, start to shine.


When a choice set involves making a tradeoff between options for 
which one is better on easy-to-compare attributes and one is better 
on qualitative attributes, we can find preference reversals when 
people think about the possibility of looking for other options.
Environmental Factors


When we think about contextual influences on choice, we might also 
consider environmental factors. Perhaps surprisingly, even the tempo of 
music we hear can influence our decisions. As we all know, many people 
prefer to exercise to up-tempo, peppy music because it helps them feel 
energized and vigorous. It doesn’t seem strange, then, that music might 
have a similar effect while shopping. 


In one field study, Ronald Milliman worked with a restaurant to play 
either fast or slow music on different days to see how the difference 
affected customer behavior. 


In general, people were slower and more patient when the music 
was slow compared to when it was fast. Customers spent an 
average of 12 minutes longer at their tables, which led them to 
order an average of $9.00 more in drinks. 


The physical space that we are in when making a decision can also affect 
us. For example, one study showed that when people were in a confined 
physical space—such as narrow grocery store aisles—they were more 
inclined to seek variety when they made decisions.


Researchers from the University of Pennsylvania, MIT, and Stanford 
examined the influence of context on voting patterns. 


Polling in the United States takes place in many different places, 
such as schools, libraries, churches, and so on. Some of those 
contexts may be related to issues that the voters are considering. 
For example, in the fall of 2000, a proposition in Arizona was on 

How You Decide: The Science of Human Decision Making
144
The physical space that 
we are in when making a 
decision can affect us; one 
study showed that when 
people were in narrow 
grocery store aisles, they 
were more inclined to 
seek variety when they 
made decisions.

Lecture 18—How Context Influences Choice 
145
the ballot to increase state sales tax by 0.6% and steer that money 
toward education.


The researchers found that people who were assigned to a polling 
place in a school were significantly more likely to vote for the tax 
increase than were those who voted at all other types of polling 
locations.


This relationship remained significant even after controlling for 
demographics and political views: Being in the context of a public 
school when making the decision about public school funding 
seemed to have influenced the way people voted.
“Manufacturing” Decisions


In making physical objects, the raw material inputs are relatively 
straightforward. You may have different grades of steel, but an I-beam is 
an I-beam. In contrast, the informational inputs we use in manufacturing 
decisions are much more nuanced.


The information we receive, including the options we have to choose 
from and the attributes that describe those options, are the basis for 
our decisions, but the context in which that information is considered 
matters a great deal.


The context, including the other options under consideration, the physical 
setting we are in, and what we can see and hear, is part of the informational 
input our decision-making apparatus uses to manufacture decisions.


You can think of this as your mind is collecting all the surrounding 
information, just in case it is relevant. If everything worked optimally, it 
would then discard the material that is not important, leaving only the 
information that mattered.

How You Decide: The Science of Human Decision Making
146


But instead, once that surrounding raw material information has been 
collected, it’s used. In this way, the context can change the way we 
evaluate options, weight information, and ultimately, make decisions.
Suggested Reading
Huber, Payne, and Puto, “Adding Asymmetrically Dominated 
Alternatives.”
Parker and Schrift, “Rejectable Choice Sets.”
Simonson, “Choice Based on Reasons.” 
Questions to Consider
1.	 The decoy effect and the compromise effect both involve adding 
one option to a two-option set. What are the differences between 
the added options that lead to the decoy effect in one instance and 
the compromise effect in the other?
2.	 How does the option not to choose affect decision making, even 
when people end up choosing something?

147
Lecture 19
How Framing Effects Guide 
Decisions
O
ne of the foundational tenets of rational choice theories is that 
choices should be consistent across equivalent descriptions of the 
options. For example, suppose a doctor told you that you had a 
disease and that the best chance of a cure was a somewhat risky surgery. 
Rational choice theories tell us that it shouldn’t matter whether the doctor 
tells you that your chances of surviving the surgery are 90% or that your 
chances of dying during the surgery are 10%. The only difference between 
those two scenarios is the way in which the information is framed, which 
shouldn’t matter. But in fact, there are consistent, predictable settings in 
which framing can have a profound influence on decision making.
Status Quo Framing


Status quo framing effects are based on the observation that, all else 
equal, people tend to prefer the status quo. Of course, a preference for 
the status quo is not unjustifiable. After all, in many instances, there is a 
reason that the status quo option is the status quo. It may be the most 
preferred by the most people, or it may have been determined that this 
option is in the best interest of the largest number of people.


Regardless of why we generally like default options, we do. And this can 
lead to some surprising results. One of the pioneers in documenting the 
power of status quo options is Columbia University’s Eric Johnson. In 
one study, he and some colleagues looked at auto insurance choices. 


For many years, people have recognized that there is a great deal of 
litigation surrounding car accidents, and a few state legislatures have 
decided to tackle the problem by restricting the ability of people 

How You Decide: The Science of Human Decision Making
148
to sue over car crashes. However, rather than simply restrict those 
rights, these legislatures give people a choice: You can maintain a 
more robust set of options for using the courts, but you have to pay 
for that right upfront in the form of higher insurance rates.


Thus, when people in certain states signed up for auto insurance, 
they were given a choice between a robust option, which cost more 
but preserved the right to sue, and a restricted option, which was 
cheaper but limited the opportunities to sue in the event of an 
accident.


Some of these states decided that the robust option should be 
the default, and some states decided that the restricted option 
should be the default. In both cases, people were allowed to 
choose whichever option they wanted, but they could default to 
one option, whereas they would need to make an active decision to 
change to the other option.


Two states that passed such laws were Pennsylvania and New 
Jersey. Pennsylvania made the robust option the default, while 
New Jersey made the restricted option the default. In Pennsylvania, 
75% of motorists ended up paying more for the robust insurance. 
In New Jersey, only 20% opted for the more expensive insurance. 
This choice was not trivial. Pennsylvania residents ended up paying 
$200 million more on auto insurance, simply because the legislature 
decided to make one option the default instead of the other.


In another example, Johnson and another colleague looked at effective 
consent rates of organ donation across Europe and found a dramatic 
difference across countries. Austria, Belgium, France, Hungary, Portugal, 
Poland, and Sweden all had participation rates running from 85.9% to 
99.98%, while Denmark, the Netherlands, the United Kingdom, and 
Germany all had rates from about 4% to 27.5%.


The most parsimonious explanation for this disparity is that the 
first group of countries has an opt-out system for organ donation. 
Basically, in those countries, it is assumed that everyone is willing 

Lecture 19—How Framing Effects Guide Decisions 
149
to donate their organs after they die, but people can check a box if 
they do not want to participate. 


The countries with lower rates of participation have opt-in systems, 
where it is assumed that people do not want to participate unless 
they explicitly indicate that they do.


Thus, one way of framing the raw informational material that is fed into 
our decision-making machinery is to designate some of that information 
as the default or status quo. This type of information often seems to get 
preferential treatment by our decision-making machinery. 
Gain/Loss Framing


Another type of framing arises out of our discussion of prospect theory. 
Recall that Daniel Kahneman and Amos Tversky found that losses tend 
to evoke larger reactions in people and that people tend to be more 
sensitive to potential losses than to potential gains. It turns out that loss 
aversion holds not just for objective gains and losses but also in situations 
in which a given piece of information is framed in terms of gains or losses.


The experiment developed by Kahneman and Tversky to test this 
hypothesis started with this problem:


Imagine that the United States is preparing for the outbreak of an unusual 
Asian disease, which is expected to kill 600 people. Two alternative 
programs to combat the disease have been proposed. Assume that 
the exact scientific estimate of the consequences of the programs is as 
follows: If Program A is adopted, 200 people will be saved. If Program B 
is adopted, there is one-third probability that 600 people will be saved, 
and two-thirds probability that no people will be saved.


When Kahneman and Tversky ran this experiment, they found that 
72% chose Program A.


A different group of people read the same scenario about the 
same disease and its predicted death toll of 600 people. But they 

How You Decide: The Science of Human Decision Making
150
were given two different programs to choose from: “If Program 
C is adopted, 400 people will die. If Program D is adopted, 
there is one-third probability that nobody will die, and two-thirds 
probability that 600 people will die.” In the original study, 78% of 
people preferred Program D.


You may have already realized that these two pairs of programs are 
exactly the same. However, one is framed in terms of how many of 
the 600 who are at risk will be saved, and the other is framed in terms 
of how many of the 600 will die. That shouldn’t matter, but it does.


The way gain/loss framing most often plays out is by changing people’s 
risk preferences. In the domain of gains, people tend to be, in relative 
terms, risk averse. In other words, people love the sure gain. People 
value a 100% chance of getting some gain relative to an option with a 
probabilistic outcome.


In the domain of losses, people tend to become risk seeking; they hate 
the sure loss. Given a choice between a 100% chance of a loss and 
some probabilistic chance of a gain or a loss, people tend to be willing 
to roll the dice.


We see this is in Kahneman and Tversky’s problem. Should we save 200 
lives or roll the dice on perhaps saving more or perhaps saving less? 
Most people will go for the sure gain, happy that they saved some lives. 
Should we let 400 people die or roll the dice on a possibly better or 
worse outcome? Most people can’t stand the thought of losing all those 
lives and will prefer the riskier option.


You can see an interesting real-world illustration of gain/loss framing 
at the racetrack in the favorite-longshot bias: a systematic bias on the 
part of bettors in favor of longshots and against favorites. Along with 
this favorite-longshot bias comes another effect that is almost as well 
established: The bias toward longshots tends to be strongest in the last 
few races of the day.

Lecture 19—How Framing Effects Guide Decisions 
151


We can understand this increasing preference toward long-odds 
horses from the perspective of gain/loss framing. If you’ve been at 
the track for the last several hours, you have almost certainly lost 
money and are likely in a loss frame of mind. 


In that state, you realize that when the track closes, you will have 
locked in those losses, and because you are human, you hate that. 
Thus, you become risk seeking, picking riskier bets in hopes of 
producing the larger wins you need to return to the black.
Opportunity Cost Neglect


In the strictest sense, not all decision researchers would consider 
opportunity cost neglect a framing effect. Rather than communicate 
the same information in two different ways, as gain/loss framing 
does, opportunity cost neglect can be seen when information that is 
objectively not informative is added to the description of an option and, 
thereby, changes consumers’ preferences.
At the racetrack, the 
favorite-longshot bias 
comes into play in the 
last few races of the 
day; people tend to 
make riskier bets as 
the track gets closer 
to closing time.

How You Decide: The Science of Human Decision Making
152


Opportunity cost is an economic term for whatever you didn’t get by 
choosing whatever you chose. According to some models of economic 
decision making, the way you make any decision is by comparing a 
considered option to the opportunity costs. If the considered option is 
better than the foregone options, you take it. If it’s not, then you select 
one of the other things you could be doing instead.


According to this rationalistic view, pointing out that you are giving up 
some things in order to choose an option shouldn’t change things; that, 
in fact, is how you made the decision. But some decision researchers 
hypothesized that simply pointing out the opportunity costs might 
systematically change how people make decisions.


Shane Frederick at Yale University said that this idea came to him 
when he was shopping for a new stereo. He was debating between 
a more expensive model and a cheaper one when a helpful sales 
clerk pointed out that if Shane bought the cheaper one, he’d have 
A surprisingly compelling 
strategy for businesses 
is to focus customers on 
the fact that paying more 
money for a competitor’s 
offering will leave them 
with less money to use 
for other things.

Lecture 19—How Framing Effects Guide Decisions 
153
an extra $100.00 to spend on CDs for the stereo. Of course, the 
information the clerk provided shouldn’t have mattered, but by 
framing the options in terms of opportunity cost, the clerk changed 
their relative attractiveness.


Shane and his colleagues took this observation into the lab and 
found that if you remind people that a less expensive option costs 
less money and that money can be used to buy other things, you 
can increase the preference for the less-expensive option. 


You can also use opportunity cost neglect to your benefit if you are 
trying to save money. The next time you’re shopping for a big-ticket 
item, narrow your choices down to just a few reasonable options. Then, 
calculate the difference between the lowest-priced option and the others, 
and ask yourself: What could I do with that extra money? You may realize 
that the extra money would not be as valuable as the higher quality you’d 
get out of the more expensive option. But the research on opportunity 
cost neglect suggests that the simple act of making that price difference 
salient may be enough to turn you toward the cheaper option.
Suggested Reading
Frederick, Novemsky, Wang, Dhar, and Nowlis, “Opportunity Cost 
Neglect.”
Kahneman and Tversky, eds., Choices, Values, and Frames.
Questions to Consider
1.	 What are the similarities and differences between framing effects 
and context effects (discussed in the last lecture)?
2.	 How are robust framing effects a threat to normative (rational) 
models of decision making?

154
Lecture 20
The Role of Memory in Decisions 
I
n our effort to understand the decision-making process, we’ve been using 
the metaphor of raw materials. By this, we mean informational input 
about the options available to us. Our cognitive machinery interprets 
and compares this input before “manufacturing” a final decision. When we 
think about the “raw materials” of a decision, we’re often examining how 
information is communicated to us or how choice sets are constructed. In 
other words, we’re looking at factors that can be thought of as external 
to the decision maker. But we also consider internal factors, in particular, 
memory; indeed, memory is an integral part of many decisions we make. 
Memory Storage


Decades of research have been conducted on what kind of information 
gets remembered, that is, what is selected to be stored in long-
term memory. Many of these findings are not surprising: We tend to 
remember things better when they are repeated, emphasized, unusual 
or humorous, connected to music, personally relevant, or tied to 
preexisting memory structures.


Let’s imagine that you work for an organization that wants to decrease 
the incidence of injuries and deaths around trains. Aside from the 
occasional mechanical failure or engineering mistake, nearly all train 
accidents are the result of a common citizen making a foolish decision, 
such as standing too close to the edge of a subway platform.


If you want to prevent bad decisions when people are around train 
tracks, how do you get that message across in a memorable way? 
One possibility is to write a catchy and humorous song, as the Metro 
Rail system in Melbourne, Australia, did with “Dumb Ways to Die.” 

Lecture 20—The Role of Memory in Decisions  
155


The song is so upbeat and funny that you cannot help but sing 
along, and its message gets lodged firmly in memory as a result. 
In the months after the metro ran this campaign, Melbourne saw a 
21% reduction in accidents and deaths.


If you want someone to remember a message, a political candidate, or 
a brand name, you should pursue one or more of these strategies: Make 
your pitch unusual or funny, repeat it often, or set it to music. All these 
things increase the likelihood of a memory being encoded. 
Memory Recall


The influence of memory on decision making is not just a function of 
whether memories have been encoded but also whether or not they are 
retrieved at the right time. Some of the ability to retrieve information 
is a function of how information is indexed in memory. And of course, 
certain types of information are easy to retrieve, while others are difficult.


Are there more words in the English language that start with R or that 
have R as the third letter? People consistently guess that there are more 
words that start with R, but in reality, there are about 9,000 proper 
English words that start with R and more than 22,000 that have R as the 
third letter.


The reason people are so consistently off in their estimates about 
this question relates to the way our memories are indexed. It is 
relatively easy to think of examples of words that start with R. But 
our memory databases are not indexed to search by the third letter 
in a word. That makes retrieving examples exceedingly difficult. 


Thus, according to the availability heuristic, we assume that if it is 
hard to think of examples of something, there must be fewer of 
those things, and we fall prey to an error.


We can think of a similar situation when we use memory to aid decision 
making. Certain decision options are easier or harder to access simply 
because of the way our memories are organized. 

How You Decide: The Science of Human Decision Making
156


For example, if you are in the mood for tacos, you can probably 
generate a mental list of Mexican restaurants easily, but you may 
skip over other restaurants that serve Mexican food along with 
other selections.


The second group of restaurants is not categorized as Mexican in 
your memory. Thus, when you go mentally wandering through the 
library stacks of your memory looking for tacos, those restaurants 
won’t be shelved in the Mexican food section and won’t be 
included in your consideration set.
Retrieval is sometimes 
aided or inhibited by 
the natural structure of 
memory, and this ease or 
difficulty of retrieval can 
determine how memory 
influences subsequent 
decision making.

Lecture 20—The Role of Memory in Decisions  
157


Retrieval can also be aided by memory cues that happen at the time 
of decision making. If something in your environment makes a memory 
momentarily more accessible or if the memory is tied to a cue that 
is likely to be present at the time of choice, then that memory has a 
greater likelihood of influencing decision making.


In Quebec, Canada, there is a chain of pharmacies called FamiliPrix. 
Several years back, this chain had a problem: Market research 
indicated that the brand was generally well liked by customers, 
but when customers were asked to name pharmacies, FamiliPrix 
consistently came in third.


To combat this problem, FamiliPrix developed a brilliant ad 
campaign. It was a series of 15-second spots that all featured 
ordinary people going about their lives. Standing in the middle of 
the scene, unnoticed by everyone, was a pharmacist in a white lab 
coat. As the scene unfolded, something happened to a person on 
screen, such as an accident or illness, that would necessitate a trip to 
the pharmacy. The pharmacist would then shout, “Aha! FamiliPrix.”


The ads were funny, which made them memorable. But more 
important, they tied the message directly to memory cues—
situational triggers that would encourage people to remember the 
message at the time they were deciding which pharmacy to choose.


The idea that memory cues are vital to decision making was tested 
empirically by Jonah Berger of the Wharton School and Gráinne 
Fitzsimons of Duke University. These researchers decided to test various 
slogans designed to encourage undergraduates to eat more fruits and 
vegetables with their dining-hall meals.


The researchers started by pretesting two slogans: (1) “Live the 
healthy way; eat five fruits and veggies a day” and (2) “Each and 
every dining hall tray needs five fruits and veggies a day.” 


Although there was a clear preference for the first slogan, follow-up 
research showed that exposure to the second slogan increased fruit 
and vegetable consumption by an average of 25%.

How You Decide: The Science of Human Decision Making
158


The explanation these researchers gave is that the slogan about 
the dining hall trays had a memory trigger: When these students 
went to the dining hall to eat, the first thing they did was to pick 
up a tray. That environmental cue caused them to remember the 
message and to change their eating choices accordingly.
The Changing Influence of Memory


Is memory becoming less important over time as we gain access to more 
technological memory aids? The short answer is that memory seems to 
be less of an influence than it used to be. Technological changes have 
allowed us to use our memories in different, more strategic ways.


There is a phenomenon in memory research known as directed forgetting. 
The idea here is that although the brain can store an amazing amount of 
information, it is not limitless. Thus, to use that limited storage capacity 
efficiently, the mind prioritizes some bits of information over others. 


Sometimes, this selection process can feel haphazard, as when you 
forget the name of a dear friend but clearly remember a commercial 
jingle from your youth.


Often, however, information is stored in memory based on how 
important it seems at the time, and directed forgetting is the process 
of strategically not remembering things that seem less important.


In a 2011 paper entitled “Google Effects on Memory,” some researchers 
at Columbia, Wisconsin, and Harvard found that people may be inclined 
to use a specific form of directed forgetting in relation to information 
they acquire in the digital age. Specifically, people are less likely to 
bother to remember information if they expect it to be available for 
them to access easily later. Of course, with the Internet and powerful 
search engines, nearly everything is available for us to access easily.


A generation ago, if you were a movie buff, your mind was filled 
with trivia about which actors were in which movies, who directed 
what, and so on. But today, all those facts are stored in the Internet 
Movie Database and available with just a few taps of the fingers.

Lecture 20—The Role of Memory in Decisions  
159


Indeed, the authors of the “Google Effects” paper found that our 
brains seem to be adapting to the digital age. What is enhanced 
when we have an enormous trove of information at our fingertips is 
the memory for how to get at specific kinds of information. In other 
words, the Internet is shifting how we use our memories. 
As a result of technological 
advances, people may treat 
large classes of information 
as something they don’t have 
to remember because such 
information can be accessed 
quickly and easily.

How You Decide: The Science of Human Decision Making
160


It is rare for people to remember both a fact and where to find 
that fact. Instead, we tend to remember one or the other. And as 
we expect more information to be stored and easily available, we 
remember fewer facts and develop better memories for where to 
find them.


This finding has several implications for decision making. First, although 
there will always be a role for memory in decision making, it may be that 
that role is shrinking over time.


To the extent that we are turning to electronic sources and a kind of 
external extra memory storage for our brains, we should expect that 
some of the memory biases that currently affect decision making 
will be reduced and replaced with a new set of quirks associated 
with the way information is retrieved online. 


Humor and music might become less influential on decision 
making, while search engine optimization and keyword searches 
start to matter more.


From a decision-making perspective, we can think of memory as 
another source of raw material—information—that we can use when 
making decisions. The influence of memory on decision making is not 
just a function of what is stored but also whether it is remembered at the 
right time. 
Suggested Reading
Berger and Fitzsimons, “Dogs on the Street, Pumas on Your Feet: How 
Cues in the Environment Influence Product Evaluation and Choice.”
Sparrow, Liu, and Wegner, “Google Effects on Memory.”

Lecture 20—The Role of Memory in Decisions  
161
Questions to Consider
1.	 Recall is partially a function of how memories tend to be 
structured. Can you name a time when you were unable to retrieve 
some useful piece of information because it was stored in memory 
in a way that was incompatible with the demands of the decision 
you were making?
2.	 What are some of the factors that increase the likelihood that 
information will be stored in memory? If you were designing a 
message that you wanted people to remember, which of these 
factors could you realistically use to help get your message stored 
in your audience’s mind?

162
Lecture 21
Assortments, Variety, and Choice 
I
n the past few lectures, we’ve used the metaphor of raw materials 
to explore how certain inputs can influence our decisions. So far, the 
raw materials we’ve discussed include the types of options available, 
how those options are communicated, and the contexts in which they are 
evaluated. In this lecture, we’ll continue our discussion of raw materials 
by learning how the number of options considered can influence how we 
manufacture our decisions.
Choice Overload


In the late 1990s, two researchers from Stanford, Sheena Iyengar and 
Mark Lepper, conducted an experiment in which they gave people 
either 6 or 24 options of fancy jam to sample. The researchers found 
that giving people too many options can make the decision process 
onerous or even overwhelming. One of the consequences of this choice 
overload is that people opt not to make a choice at all.


Iyengar and Lepper’s work caused quite a stir among decision 
researchers because intuitively—even objectively—more options should 
always be better. The more options you have to choose from, the higher 
the likelihood that you’ll be able to find one that matches your ideal.


Of course, there is an easy solution to facing a choice set that is too 
large: Simply make it smaller by eliminating some options. But there is 
also compelling evidence that people don’t like fewer options.


Thus, when Iyengar and Lepper’s study was first published, it generated 
some criticism. With so many reasons to think that more options would 
be better, it seemed hard to believe that more options could cause 
negative consequences. The most common criticism leveled at this line 

Lecture 21—Assortments, Variety, and Choice  
163
of work was that it was not worth the time required to investigate all 
the options available for a trivial choice, such as selecting jam, but that 
when people make decisions that truly matter, they wouldn’t simply walk 
away just because there were too many options.


Iyengar and some colleagues followed up on the initial research, 
by investigating, among other things, participation rates in 401(k) 
retirement plans.


Defined-contribution retirement plans differ across companies in 
terms of how many mutual funds are offered to employees. Some 
companies offer their employees only a few funds to choose from; 
others offer dozens. As with almost any choice, objectively, the 
more funds you have to choose from, the better off you should be 
in terms of matching your goals to an investment vehicle. 


Despite this advantage, these researchers found that as companies 
offered their employees more mutual funds to choose from, there 
was a steady drop-off in participation rates. At companies that 
offered just a few funds, about 75% of employees participated in 
the retirement savings program. When firms offered more than 50 
funds, participation rates dropped to about 60%.


When people were given more options, some were sufficiently 
overwhelmed by the choice that they decided not to invest for 
retirement at all. Of course, this decision is not like picking a jam. 
The decision of whether or not to participate in a 401(k) program 
is arguably among the most important people will make in their 
professional lives. But having more options to choose from was 
enough to move some people from participating to not participating.
The Choice-Overload Effect


A number of explanations have been proposed for the choice-overload 
effect. One comes from Iyengar and Lepper, who posited that large 
choice sets can be demotivational. The effort they require—processing 
information and making comparisons—can sap our motivation to do 

How You Decide: The Science of Human Decision Making
164
additional research. When there is the option of not choosing, as with 
the jams, people simply don’t choose.


In one study of choice overload, the participants were students in 
two sections of an introductory psychology class at Stanford, and the 
manipulation was to change the requirements for an assignment across 
two sections of the same class. Both sections had the opportunity to 
write an essay for extra credit, based on a list of possible topics provided 
by the instructor. One section was given 6 possible essay topics, while 
the other was given 30.


The researchers were interested in both the percentage of students 
who chose to write an extra-credit essay and the quality of the essays 
that the students wrote. The essays were graded by assistants who 
were blind to the hypotheses and the experimental conditions. 


The study found that students were more likely to write the essay 
when they were given fewer possible topics to choose from. Of 
those who were given 6 topics, 74% wrote an essay, but only 60% 
wrote one when given the option of 30 topics. 
As much as people will tell you 
that they want more options, 
the reality is that for many 
products, people can easily 
find themselves overwhelmed.

Lecture 21—Assortments, Variety, and Choice  
165


Having more options can also change the reference point against 
which people evaluate options. This driver of over-choice effects was 
investigated empirically by Kristin Diehl from the University of Southern 
California and Cait Lamberton from the University of Pittsburgh. They 
found that people were systematically less satisfied with their choices 
when choosing from larger assortments relative to smaller assortments.


For example, in one study, participants were asked to imagine 
that they were shopping for a birthday card for a coworker. All 
the participants were asked to evaluate the same card to see how 
satisfied they would be with that selection. But half were told that 
the card had been chosen from a shop that had only 25 cards to 
choose from; the other half were told that the card came from a 
shop with 250 cards.


Despite the fact that everyone saw exactly the same card, 
participants were more satisfied if they were told that it came from 
a small shop than a large shop.
Assortment Effects


Choice overload has been shown to occur in a number of contexts, but 
it has also been shown not to occur in some consistent settings. 


One of the contexts in which having more options tends to be better 
is when people have an articulated ideal point. In fact, some theories 
of rational choice start with the assumption that people have an ideal 
point for every decision they make and simply search through the 
available options, choosing the one that is sufficiently close to that 
ideal. However, the underlying assumption here doesn’t have a great 
deal of empirical support. 


Even if people don’t always know exactly what they want all the 
time, sometimes they do. And research by Alexander Chernev of 
Northwestern University has found that when people have an articulated 
ideal point, the negative effects of large assortments become positive.

How You Decide: The Science of Human Decision Making
166


For example, in one of Chernev’s studies, he asked people to 
choose among an assortment of either 16 or 4 chocolates. Within 
these two assortments, each chocolate was described by four 
attributes: type, cocoa content, flavor, and nut content. Each 
attribute also had four values. Type could be solid chocolate, truffle, 
praline, or caramel; flavor could be original, vanilla, strawberry, or 
cherry; and so on.


Some participants were simply shown one of the assortments and 
asked to pick a chocolate. Other participants were first given the 
opportunity to articulate an ideal point. Before they were shown 
any particular chocolate, they were told the four attributes and 
asked to indicate which combination of attribute values would be 
their most preferred. 
According to rational choice 
models, when you’re buying a 
TV, you have some ideal TV in 
mind; as you peruse the available 
options in the store, you compare 
each one to the ideal and select 
the one that is the closest overall.

Lecture 21—Assortments, Variety, and Choice  
167


Among those who were given an assortment without any 
preparation, the typical choice overload effects were found. 
People were less confident in their choices when choosing from 
the 16-option assortment than from the 4-option assortment. 
But when people were first given the opportunity to articulate an 
ideal point, the effect flipped. People were more confident in their 
decisions when choosing from the larger assortment than from the 
smaller one.


Of course, this isn’t difficult to understand. When you have 
articulated exactly what you know you want, all you have to do is 
search for it. And with a larger assortment, the chances that you’ll 
find something close enough to what you want increase.


Another setting in which people don’t seem to be tripped up as much 
by choice overload can be seen when they are choosing between 
assortments that both carry relatively attractive options. 


Recall that even though people can become overwhelmed and 
demotivated by large choice sets, they are also are more attracted 
to larger assortments. This suggests that in many settings, people 
may make an initial decision—which assortment to choose from—
that causes them problems later when it comes time to actually 
make a choice. 


A typical setting for this issue to arise might be competing stores 
that offer different ranges of choice.


Some research has found that at least some of the attraction to larger 
choice sets is driven by uncertainty. If we are unsure about whether we 
will find something we like, we want the large choice set to increase our 
chances, even if it will require more work for us. But if both assortments 
are attractive, then the initial preference for the larger assortment is 
reduced.


For example, in one study, lunch was provided to adult students 
in an executive education class. Participants were given the option 
of one of two sandwich shops: one that offered an assortment of 9 

How You Decide: The Science of Human Decision Making
168
options and another that offered 38 options. But the students had 
to pick the restaurant before they could see the menu.


In one condition, both sandwich shops were described in relatively 
unflattering terms. In the other condition, both sandwich shops 
were described in glowing terms. 


When the restaurants were described as being not very good, only 
13% chose to order off the menu with fewer options. In the other 
condition, 40% chose to order from the smaller sandwich shop.


This finding may explain, in part, the success of stores that promote 
themselves on their small assortments and limited selections. The 
only retailers able to get away with that are those that promise 
extremely high-quality items, such as exclusive jewelers. 


A final setting in which choice overload is consistently not seen is when 
people are given decision tools, such as an easy-to-manage decision 
tree or search-and-sort functions, to help categorize the assortment. 
Overcoming Choice Overload


As we’ve seen, there are a couple of strategies for overcoming choice 
overload effects in your own life. First, whenever possible, articulate 
your preferences before you start looking. Many of the problems 
associated with larger choice sets are caused by people trying to form 
their opinions as they are evaluating the options. If you know exactly 
what you are looking for first, then the process becomes much easier.


Second, take advantage of decision aids, such as decision trees, search 
functions, and sorting tools. The more control you have over how the 
assortment is organized, the easier it will be for you to cull that over-
large set down to something manageable.

Lecture 21—Assortments, Variety, and Choice  
169
Suggested Reading
Chernev, “Product Assortment and Consumer Choice.”
Chernev and Hamilton, “Assortment Size and Option Attractiveness in 
Consumer Choice among Retailers.” 
Diehl and Poynor, “Great Expectations?! Assortment Size, Expectations, 
and Satisfaction.”
Iyengar and Lepper, “When Choice Is Demotivating.”
Questions to Consider
1.	 What reasons have researchers uncovered to explain why larger 
choice sets can cause problems for decision makers?
2.	 One question left largely unresolved by research on assortment/size 
effects is this: How large does a set of options need to be before 
people start to experience negative over-choice effects? Why have 
researchers not pinned this down? What factors do you think might 
affect how people are influenced by the number of options they 
have to choose from?

170
Lecture 22
How Evaluability Affects Decisions
I
n the mid-1990s, Chris Hsee, a decision researcher at the University 
of Chicago, demonstrated a concept that has come to be used to 
describe many decision-making phenomena. The basic idea rests on two 
observations: The first is that attributes differ in evaluability—in how easy it 
is for the decision maker to assess or pass judgment on the quality of the 
attribute. The second observation is that the importance of an attribute in 
decision making is a function of its evaluability. Attributes that are easier to 
evaluate tend to be given more weight in decision making than attributes 
that are harder to evaluate—even when that means prioritizing objectively 
less important features over more important features.
Evaluability Effects


It is probably not difficult to think of examples of evaluability effects in 
the decisions you’ve witnessed other people making. For example, if 
you look at surveys concerning hospital choice, you’ll find that people 
place a great deal of importance on the courtesy of staff and the 
appearance of facilities. 


Of course, those attributes are not trivial, and they could serve as 
signals of a high-quality, professional hospital. But it’s also true that 
those particular attributes—courtesy of staff and appearance of 
facilities—are easy for people to evaluate. 


In contrast, attributes that truly matter, such as the skill and 
competence of the medical staff, are nearly impossible for the 
average patient to assess firsthand. Thus, it is possible that ease 
of evaluating certain attributes (evaluability) leads people to give 
them more weight in the decision than they probably should.

Lecture 22—How Evaluability Affects Decisions 
171


An even clearer example involves criticisms leveled against colleges for 
the seemingly large amounts of money spent on such amenities as new 
dorms, upgraded athletic facilities, rock-climbing walls, and so on. 


There are many reasons for a university’s specific spending 
decisions, but evaluability may be an important driver. When a 
prospective student is trying to decide which school to attend, 
a few factors, such as the quality of the learning environment or 
the culture, are likely to be important but difficult to evaluate. In 
contrast, the quality of the gym equipment is much easier to assess.


In a paper published by the National Bureau of Economic Research, 
researchers found that some students appear to base their 
decisions about which college to attend, at least in part, on the 
amenities the college offers. The students most likely to be swayed 
by new gym equipment are those who are relatively less focused 
on academics and who come from wealthy families. Even more 
interesting, schools appear to adjust their spending—specifically, 
the ratio of amenity to academic spending—according to the types 
of students they’re trying to attract. 
Reference Information


What makes it easier or more difficult to evaluate an attribute? The 
answer boils down to whether or not we have reference information for 
the attribute under evaluation. 


In general, having a frame of reference means having some kind of 
experience with the attribute, often from your own past. If you make 
a particular kind of evaluation often enough, evaluating an attribute 
becomes second nature. 


A reference frame can also come from deliberate preparation: Imagine 
that you are buying your first refrigerator. You’re a novice, but because 
you consider this an important purchase, you educate yourself before 
you go to the store. After investigating what’s available, you get some 

How You Decide: The Science of Human Decision Making
172
idea of which levels of attribute performance would be acceptable and 
which would not.


Further, a reference frame can come through training. Nurses, for 
example, know the full range of numbers possible in a blood pressure 
check and can inform patients about whether their readings are too low 
or too high.


The reference frame that we need to make something evaluable requires 
some experience or expertise; unfortunately, many of the domains in 
which we make decisions are those in which we don’t have any particular 
expertise and only limited experience.
Low-Evaluability Attributes


Decision researchers have discovered several workarounds that people 
use when faced with a low-evaluability attribute in making a decision.


One solution in this situation is to perform relative evaluations. As it 
turns out, numerous strange outcomes can be demonstrated when one 
group of people is given multiple options to evaluate and others are 
given just the options in isolation. 


For example, Hsee and some colleagues showed people pictures 
of two options of soft-serve ice cream being sold by two vendors. 
One vendor sold 8 ounces of ice cream in a 10-ounce cup. The 
other vendor sold 7 ounces of ice cream in a 5-ounce cup. All the 
volumes were labeled, and—rationally—people indicated that 
they would be willing to pay more for more ice cream: $1.85 for 8 
ounces and $1.56 for 7 ounces.


But when a different group of people was asked to evaluate 
only one ice cream or the other, the preferences flipped. People 
indicated that they’d be willing to pay $2.26 for 7 ounces of ice 
cream but only $1.66 for 8 ounces. When people evaluated the two 
cups of ice cream independently, they were actually willing to pay 
more, on average, for less ice cream.

Lecture 22—How Evaluability Affects Decisions 
173


Because people didn’t have good reference information for the 
per-ounce price of ice cream, they looked at the pictures. In the 
8-ounce picture, the cup was only four-fifths full, but in the 7-ounce 
picture, the ice cream was piled well above the rim. The height of 
the cup became an easy but largely irrelevant reference point for 
evaluating the ice cream. People were less sensitive to the high-
quality information—the actual volume of the ice cream—and 
more sensitive to the low-quality information—the height of the ice 
cream relative to the cup—because the reference point made that 
the easier attribute to evaluate.


Joint evaluations allow us to use higher-quality external reference 
points. We can see how the other options are performing on any 
particular attribute and make our judgments accordingly. Luckily, many 
of the decisions we make are in the context of multiple options.
We are often in the position 
of being able to use joint 
evaluations when making 
decisions; this is why, for 
example, travel services 
provide you with multiple 
itineraries.

How You Decide: The Science of Human Decision Making
174
Social Comparisons


We can sometimes try to improve on joint evaluations by incorporating 
additional information. Some of these improvements come in the 
form of social comparisons. In some cases, we may not have precise 
reference information for a particular attribute, but we do have some 
idea of where our preferences fall relative to the preferences of others.


For example, suppose you go shopping for a new phone and see that 
the model you like comes with three levels of memory: 128 gigabytes, 
256 gigabytes, and 520 gigabytes. If you’re like most people, you 
probably don’t know your exact gigabyte needs. 


Instead, you may engage in a simple social comparison, asking 
yourself: Relative to the average user, how much storage capacity 
am I likely to need? 


If you’re a new parent taking endless pictures and videos of your 
children, you may need more than the average person; thus, you 
might pick the 520-gig model.


Drazen Prelec from MIT and his colleagues tested this idea in another 
study. They asked people to imagine that it had started raining and they 
had decided to buy a poncho to keep themselves dry. The vendor sold 
three sizes: 38, 40, or 42 inches long. Later, respondents were asked 
to give their height. When the researchers compared the results, not 
surprisingly, short people chose the 38-inch poncho, medium-sized 
people chose the 40-inch version, and tall people opted for the 42-inch 
version.


Different groups got the same question but with different lengths 
of poncho: 36, 38, and 40. Still another group got ponchos ranging 
from 34 to 38 inches, and another saw lengths of 32, 34, and 36.


In every group, short people chose the shortest option available, 
medium-sized people chose the middle option, and tall people 
chose the longest option—regardless of the actual size of the 
ponchos in the set. People made their evaluations by engaging in 
a kind of social comparison. The more difficult question would have 

Lecture 22—How Evaluability Affects Decisions 
175
been: What is the right length of poncho for me? Instead, people 
asked themselves the relatively easy question: How tall am I relative 
to the rest of the population?


Interestingly, most ponchos run between 50 and 52 inches long, 
which makes all of the options in this study comically short. If you 
had decent reference information, you would have chosen the 
longest one available, regardless of your height. 


People use a whole class of reference-point substitutes when they don’t 
have valid reference information for a particular attribute. We see this 
kind of thing all the time in eating behavior. 


Two decisions that we face, multiple times a day, are how much 
food to serve ourselves for a meal and when to stop eating. 


You would think that we would have good reference points for 
these decisions. But for a variety of reasons, the signals our body 
sends us to let us know that we are no longer hungry tend to be 
relatively easy to miss.


For this reason, people often use external signals as reference 
points. How do you know when you have served yourself enough 
food for the meal, and how do you know when you’re done? The 
answers are: when you’ve filled the plate and when you’ve emptied 
the plate. The problem with using plates as a reference frame, of 
course, is that plate size is variable.


Food consumption researchers Brian Wansink and Koert van 
Ittersum worked with a buffet restaurant to conduct a field 
experiment in which they changed the size of the plates customers 
were given. Sure enough, regardless of plate size, people tended 
to fill up their plates, and although they didn’t always empty 
them, they came close. Customers who used larger plates served 
themselves 52% more food and ate 45% more food than customers 
who used smaller plates.

How You Decide: The Science of Human Decision Making
176


In an even more dramatic example, Wansink brought people into the 
food lab at Cornell University to have them sample some soup. The 
experiment had two conditions. In one, people ate the soup from 
normal bowls. In the other, people ate from bowls that had small holes 
drilled into the bottoms. As the person ate, more hot soup was pumped 
slowly in from a reservoir under the table. Wansink found that people in 
the “bottomless bowl” condition ate about 75% more soup than those 
who ate from a standard bowl.


And that’s the danger with all external reference points: Joint evaluations 
tend to be better than separate evaluations; social comparisons tend 
to result in more accurate evaluations; and environmental cues, such as 
plate size, can help with evaluations—but none of these is perfect. As 
with any context-dependent evaluation, these evaluations are highly 
sensitive to the particular options under consideration or the particular 
cues being used. 
You would think that we would have 
good internal reference points for 
eating decisions, but in fact, it’s 
more common for people to use 
external signals, such as plate size, 
as reference points.

Lecture 22—How Evaluability Affects Decisions 
177
Suggested Reading
Hsee, “The Evaluability Hypothesis.” 
———, “Less Is Better: When Low-Value Options Are Valued More 
Highly Than High-Value Options.” 
Hsee and Zhang, “General Evaluability Theory.”
Wansink, Painter, and North, “Bottomless Bowls: Why Visual Cues of 
Portion Size May Influence Intake.”
Questions to Consider
1.	 How can the evaluability hypothesis explain the preference reversals 
that can occur between joint and separate evaluations of options?
2.	 Evaluability may be thought of as a specific type of a substitution 
heuristic (in which an easier problem or evaluation is substituted for 
a more difficult problem or evaluation). Explain evaluability from this 
perspective.

178
Lecture 23
Halo Effects and Choice
S
ometimes, the information we acquire to use in decisions can be 
influenced by our higher-order impressions. These impressions create 
attribute halos that can bias our interpretation of neutral, inconsistent, 
or ambivalent attributes. Halo effects occur when we allow an overall 
impression of a thing—such as an overall favorable impression of the Coca-
Cola brand—to influence our impression of specific attributes—such as taste. 
In other words, if—through marketing efforts, personal experience, or peer 
pressure—we come to believe that Coke tastes great, then that belief will 
color our experience when drinking Coke. Drinking exactly the same formula 
would not taste the same if it wasn’t Coke.
Early Research in Halo Effects


Halo effects are one of the major psychological justifications for the 
enormous resources that companies put into branding. Having an 
overall positive impression of a brand can bias subsequent evaluations 
of all kinds of attributes. But halo effects are not only a marketing 
phenomenon. They are a human phenomenon; they describe one way 
that people make evaluations and simplify decisions. 


The person credited with identifying halo effects is a psychologist 
named Edward Thorndike, in 1920. He was interested in how people 
evaluate other people. Thorndike noticed that when one person 
evaluated multiple characteristics of another person, the various 
evaluations tended to be far too correlated with one another. In other 
words, people tended to see others as more consistent across traits 
than they actually are.


In one of his studies, Thorndike had military officers rate soldiers 
on several dimensions: neatness, voice, physique, bearing, energy, 
intellect, and so on. 

Lecture 23—Halo Effects and Choice 
179


Where the natural variation among people would predict diverse 
profiles across such a diverse set of traits, that’s not what Thorndike 
found. Instead, there was a remarkable uniformity in the traits of 
any one soldier. 


The theory that underlies such halo effects is that people form an overall 
impression of something—say, a person or a university—then use that 
impression to fill in the gaps on any specific attributes they want to 
evaluate.


Imagine you are an army officer and are asked to evaluate the 10 
soldiers in your command on 12 attributes. 


It’s doubtful that you have a well-informed opinion about each 
soldier on every attribute. Even the most observant person is 
unlikely to have 120 evaluations filed away, although you have 
probably formed an overall impression of each individual as a 
soldier. 


When you have specific individuating information for a particular 
soldier on a particular trait, you’ll use that information. But if 
you don’t have that information, you’ll probably use your overall 
impression to fill in the blanks. You will complete the parts of that 
soldier’s profile that you are less certain of in such a way as to be 
consistent with the parts you are sure about.


If we think of decision making as a manufacturing process, halo effects 
fit under raw materials. They describe one way that we can make up 
for not having all the informational raw materials we need to make a 
decision. 


If you are an army officer suggesting soldiers for promotion, or a 
consumer trying to decide which car to buy, or a juror trying to choose an 
appropriate level of punishment for a criminal, you will almost never have 
all of the information you might like to make your decision. Rather than 
being paralyzed by what you don’t know, you can use impressions to fill 
in the blanks and give you at least some chance of making a decision.

How You Decide: The Science of Human Decision Making
180
Halo Effects as Decision Shortcuts


As with many of the decision shortcuts we’ve discussed, using 
impressions to guide our judgments doesn’t always lead us astray. 
Particularly if you have a rich, detailed, and well-informed impression of 
someone or something, that impression is likely to be more helpful and 
accurate than not having one. In fact, some research shows that under 
certain circumstances, relying on general impressions can lead to more 
accurate decision making.


The problem is that we often do not have detailed, accurate 
impressions. Instead, we have impressions that are informed by just a 
few observations, which we then use to over-generalize to unrelated 
traits and characteristics.


This explains why, in the research on halo effects, the influence that has 
been studied most often is attractiveness. People who are evaluated as 
attractive also tend to be thought of as more intelligent, kind, friendly, 
Controlling for other 
factors, attractive 
politicians are more 
likely to win elections.

Lecture 23—Halo Effects and Choice 
181
and trustworthy. Attractive people are assumed to be more successful 
or have a greater potential for success. One explanation for this is 
that physical attractiveness is important in how people form initial 
impressions of others. 
Halo Effects and Purchasing Decisions 


Halo effects seem to be influential in situations where we are forced to 
make decisions without solid reference points to rely on. Consider, for 
example, a typical grocery-shopping experience. 


At first blush, you might think that you have well-defined reference 
points for evaluating prices as a step toward making purchase decisions. 
You probably know how much to expect to pay for a gallon of milk or a 
loaf of bread. But a typical grocery or big-box store might have tens of 
thousands of individually priced items, and your reference prices for all 
those items are probably not well-defined. 


Research shows that when people evaluate prices in settings where they 
are not confident in their reference prices, they rely on overall impressions, 
specifically, on the price image of the store where they are shopping.


For example, in one study, people were asked to evaluate the price of 
a two-pack of ball-point pens priced at $2.89. They were then asked 
to rate the attractiveness of the price. The manipulation consisted of 
changing the store that was ostensibly selling the pens. When people 
were told that the pens came from Walmart, $2.89 was rated as a low 
price. When they were told that the pens came from a magazine shop in 
airport terminals, the same price was rated as high.


These same researchers also found that price perceptions can change 
what people choose to buy. The researchers showed different groups 
of people the same four products at the same four prices in a variety of 
categories. 


One-half of participants were told that they were seeing a selection 
of options from a low-priced grocery store, Food 4 Less; the rest 

How You Decide: The Science of Human Decision Making
182
were told that they were seeing options from a high-priced grocery 
store, Whole Foods.


One of the categories participants saw was pasta sauce—the same 
four brands at the same four prices. But half were told they were 
looking at an assortment from Food 4 Less, and half were told they 
were looking at an assortment from Whole Foods.


People tended shift their purchases depending on which store 
they thought they were buying from. When they thought they were 
buying from Whole Foods, they often bought the less-expensive 
options in the set. 


People assumed that all four of the pasta sauces at Whole Foods 
were expensive; thus, they selected one of the cheaper options. 
But when all the options were thought to be cheap, people thought 
they could treat themselves to a more expensive brand—even 
though the prices were exactly the same in both cases.
Halo Effects and Food Consumption


Halo effects can also affect decisions about where we eat and how 
much. Just as we can form a high-level impression of the prices at a 
store, we can also form a high-level impression of the healthiness of a 
restaurant. 


For example, McDonald’s is widely seen as being an unhealthy 
place to eat, while Subway benefits from a “health halo”; it is seen 
as being a generally healthy fast-food option.


According to the theories we’ve discussed, the fact that Subway 
has a reputation for healthier foods should lead people to make 
judgments about its foods that are biased in favor of that impression. 
When people are unsure about the actual healthfulness of the 
foods, they will see Subway foods as healthier than they actually 
are and healthier than similar foods coming from restaurants with a 
lower overall health image.

Lecture 23—Halo Effects and Choice 
183


Pierre Chandon, from the INSEAD business school, and Brian Wansink, 
from Cornell, tested this hypothesis. 


They sent research assistants to approach fast-food patrons 
at the conclusion of their meals to fill out a survey. The survey 
asked, among other things, for people to estimate the calories 
of the meal they had just consumed. As participants filled out the 
survey, the research assistants surreptitiously noted the meal that 
had been consumed, based on the wrappers left on the tray. The 
experimental condition consisted of whether the surveys were 
conducted at McDonald’s or Subway.


Consistent with a halo-effect hypothesis, Chandon and Wansink 
found that people eating at Subway underestimated the number of 
calories in their meal more than the people eating at McDonald’s. 
As a result of halo effects, people 
enjoy wine more when they think 
it costs $90 a bottle than when 
they think it costs $10 a bottle.

How You Decide: The Science of Human Decision Making
184


Using some statistics to control for actual differences in calories, the 
researchers estimated parameters that determined just how much 
people at each restaurant were underestimating. For a hypothetical 
1,000-calorie meal, McDonald’s patrons would, on average, 
estimate the meal to be 744 calories. Subway diners were even 
further off, estimating the meal to be only 585 calories.


When we are estimating something we’re not sure of, we can rely 
on our overall impressions of the store or restaurant to help. In this 
case, that “help” leads us to make even worse overall estimates, at 
least in terms of calorie count.


People can also form instant, snap impressions of a single meal and 
use that impression to guide their judgments. In a series of studies 
conducted by Alexander Chernev, people were shown a picture of a 
meal and asked to estimate the number of calories it contained. Some 
participants saw a meal consisting of a greasy hamburger. Other 
participants saw exactly the same hamburger, but this time, it was paired 
with three celery sticks.


Chernev found that people who saw the hamburger by itself 
estimated that it contained more calories than meals that consisted 
of both the hamburger and the celery. Some people estimated that 
the burger by itself was 697 calories. Other people estimated that 
the burger and the celery sticks together were 642 calories. That’s 
about an 8% reduction in calories by adding food to the plate. 


This is another halo effect. When making an estimate about the 
number of calories in a meal, people first form an impression of 
the meal as a whole, then use that impression to guide their calorie 
estimate. 


Halo effects are nearly everywhere. They represent a common way for 
people to overcome the limitations of not having full knowledge when 
making decisions. By using general impressions to fill in gaps, we are 
able to create enough information to feed into our cognitive machinery 
to produce a decision. 

Lecture 23—Halo Effects and Choice 
185
Suggested Reading
Chernev, “The Dieter’s Paradox.”
McClure, Li, Tomlin, Cypert, Montague, and Montague, “Neural 
Correlates of Behavioral Preference for Culturally Familiar Drinks.”
Thorndike, “A Constant Error in Psychological Ratings.”
Questions to Consider
1.	 How do halo-effect evaluations differ from reference-point 
evaluations?
2.	 What are the advantages and disadvantages of using halos as a 
decision-making tool?

186
Lecture 24
The Four Rs of Decision Making
A
s we’ve seen, there are multiple approaches to studying how people 
make decisions. Economists; sociologists; philosophers; doctors; 
statisticians; and of course, psychologists have all weighed in. But the 
general approach that underlies this work is not without some detractors. The 
biggest criticism leveled against theory development in psychology is that 
it seems to be getting increasingly granular and complex, rather than more 
elegant and general. Still, understanding the theories can help us understand 
others better, design situations that make certain choices more likely, and 
make better decisions ourselves. For this reason, we’ll close the course with a 
list of empirical generalizations—important principles to remember when you 
try to understand your own decision making or that of others.
Reference Points Matter


Many of the theories we’ve discussed are based on reference points or 
were about scenarios in which people lacked good reference points.


Loss aversion and its most prominent implication, the endowment 
effect, are both reference-point effects. We know that losses loom larger 
than gains, but how is a gain or loss determined? The answer is: by 
comparing it to a reference point. 


The behavioral economist Richard Thaler developed a stylized example 
to illustrate this point. Suppose you ran the only gas station in town, 
and your credit-card processor charges you a transaction fee ($0.05 per 
gallon) that you want to pass along to your customers. Should you:


Post a low price for gas on your street-side sign, then hit credit-card 
customers with the $0.05 per gallon penalty when they get to the 
pump? 

Lecture 24—The Four Rs of Decision Making 
187


Post the higher price for gas and offer cash customers a rate 
discounted by $0.05 cents per gallon?


To make your decision, you must predict how customers would respond 
to each of these mathematically equivalent options.


Suppose that the base price—the one advertised on the sign by 
the road—serves as the reference point. (Remember: Yours is the 
only gas station in town.) 


In the first case, your cash customers pay what they expected to 
pay: the posted price. Their experience will be relatively neutral. 
But the credit-card customers will pay a higher rate relative to the 
advertised price. For them, this higher price will be experienced as 
a loss, and they won’t be happy.
If you use some particular theory of 
decision making to design a new teaching 
approach in your classroom, remember 
that whatever theory you’ve chosen, there 
may be a half dozen equally valid theories 
at play in your classroom.

How You Decide: The Science of Human Decision Making
188


In contrast, if you post the higher base price, the credit-card 
customers pay the advertised rate; they are at their reference 
point and will experience a relatively neutral transaction. But the 
cash customers pay less than the reference point. They are in gain 
territory and feel great about buying gas from you.


Without changing the actual prices you charge either group, you’ve 
gone from some of your customers feeling neutral and the rest 
feeling unhappy to one group feeling happy and the rest neutral—
just by changing the reference point.


If we want to understand how people evaluate options and 
ultimately make decisions, we must understand what reference 
points they bring to those decisions.


Of course, we’ve also discussed some of the many decision shortcuts 
people use when they don’t have access to reference points, such as 
picking the status quo option, relying on halos, or avoiding extreme 
options.


If you want to understand and anticipate someone’s decision making, 
start with reference points. If this person is unlikely to have a well-
defined set of references, can you anticipate which workaround he or 
she is likely to use? Can you provide reference points that favor one 
option over another? 
Reasons Matter


Not surprisingly, people often make decisions by picking options they 
feel they can justify to others and to themselves. What is interesting, 
however, is that the reasons that drive choice don’t have to be logical 
or compelling. When making a choice where there is no clearly 
superior option, seemingly almost any reason can serve as grounds for 
the choice. 

Lecture 24—The Four Rs of Decision Making 
189


Reason-based choice is the explanation for the phenomenon discovered 
by Eldar Shafir that it is possible for the same option to be both more 
likely to be selected and more likely to be rejected. 


If an option has both positive and negative features, then choosing one 
of those options can focus us on the positive features—the ones that 
If you’re looking to 
influence a customer’s 
decision, you can provide 
reference points, such as 
uniqueness, quality, low 
price, and so on.

How You Decide: The Science of Human Decision Making
190
provide reasons for choosing one option over the other. In contrast, 
when rejecting one of those options, we tend to focus on negative 
attributes—those that provide reasons for eliminating an option.


If you are trying to understand someone’s decisions, ask yourself: What 
reasons did this person have for picking the options he or she did? 


You can look to the easy explanations, of course: Maybe the person 
simply liked this color or flavor the best.


But sometimes, the reasons driving choice are more trivial and 
contextual. Maybe this option was the most unique in the set, and 
the decision maker feels the need to stand out from the crowd. 
Maybe the options were equally attractive overall, but one option 
dominated on the more important attribute.
Resources Matter


The fact that people are limited in terms of attention, effort, and self-
control has two implications:


First, our decision making is a function of the resources we have 
available to us. We have different decision rules and multiple 
cognitive systems that are geared toward either making fast and 
easy, resource-conserving decisions or slow and deliberative, 
resource-consuming decisions. We will slip into the easier, resource-
conserving mode any time we are exhausted or distracted. 


Second, because decisions consume these limited resources, people 
have become strategic in how they spend them. We’ve developed 
satisficing rules, habitual responses, and availability heuristics. 


It is only when we really care about something that we typically bother 
to pull out the heavier artillery in our decision-making arsenals. This can 
lead to a resource mismatch between those creating a decision setting 
and those making the decision. 


If you are a brand manager at Tide, then Tide is one of the most 
important things in your life. Because you care about Tide, you 

Lecture 24—The Four Rs of Decision Making 
191
devote cognitive resources to making it better and effectively 
communicating its benefits to potential customers. 


But most potential customers care little about laundry detergent. 
They ignore new benefits promoted in the ads and stylish 
innovations in the package design. 


As a brand manager, what can you do about this mismatch? First, 
you can ask how many resources people are likely to devote to the 
decision you want them to make. Is the product something they care 
about? Are you talking to car enthusiasts about some new and novel 
engine part? Is the outcome of this decision consequential? Are you 
talking to someone who has just been diagnosed with heart disease 
about treatment options?


If so, the person is more likely to devote resources to that problem. 
As a result, the decision is likely to be based on a more thorough 
assessment of the information, more System 2 processing, more 
long-term thinking, and decision rules that facilitate making 
tradeoffs between options.


In contrast, if the decision is inconsequential, is likely to overwhelm 
the decision maker, or is likely to be made in a setting that will 
be distracting or exhausting, then you should anticipate that the 
person will not devote significant resources to the decision. Expect 
the incorporation of less information; a greater reliance on intuitive, 
System 1 processing; and the use of heuristics and simple and 
frugal decision rules.
Replacement Matters


Replacement is the idea that people have many workarounds when 
they are presented with difficult tasks; thus, they often substitute or 
replace a difficult task with an easier one. Many of the heuristics we’ve 
discussed, such as the availability heuristic, can be characterized as 
replacement.

How You Decide: The Science of Human Decision Making
192


Making estimates, including likelihood estimates, is difficult. Doing it 
right means gathering information and processing it carefully. Instead, 
people often use the availability heuristic to replace the difficult 
estimation problem with a much easier one. 


Which presidential candidate will best manage international crises 
and encourage economic growth at home, all while safeguarding civil 
liberties and keeping us safe? If that’s too difficult to determine, you 
might try to decide which candidate you’d rather have a beer with or 
which of them just seems more “presidential.”
A Final Word of Advice


Here’s one last bit of advice about applying decision-making theories in 
real life: Stack the deck. Don’t try to be elegant and subtle. If you want 
to change the way some group of people is making decisions, use a 
sledgehammer.


The reason for this is that human decisions have a high-causal density. It 
can take a great deal of effort to break through the noise. 


As an example, consider a program developed by Richard Thaler and 
finance professor Shlomo Benartzi to help people save more money 
toward retirement. The two turned to research on decision making for 
guidance and layered several theories on top of one another. 


The program, called Save More Tomorrow (SMarT), was not a 
typical savings plan. First, people who agreed to participate 
started off by contributing nothing to their savings accounts. 
Instead, they simply committed to start contributing a portion 
of their next raise and to increase that contribution with each 
subsequent raise.


This program cleverly takes advantages of several insights 
into decision making. First, it is difficult to resist immediate 
temptations, but in the future, those temptations are less 
tempting. Thus, if you’re asked if you are willing to start saving 

Lecture 24—The Four Rs of Decision Making 
193
three months from now, you are far more likely to say yes than if 
you’re asked to start saving now.


Second, the SMarT program respects loss aversion. By starting 
to save now, you will reduce the size of your current paycheck, 
which feels stretched enough as it is. But in this program, the 
contributions come as a reduction on an increase, which means 
that you never feel the loss.


Finally, although people were free to drop out of the plan at any 
time, the program front-loaded commitments to continue to 
increase contributions. We know that the status quo is compelling 
and that people often continue to do what they’ve always done 
out of habit. In this case, that means not changing anything and 
sticking with the plan.


By layering these insights on top of one another, Thaler and 
Benartzi created a successful tool for improving decision making. 
In the first test of the plan, employees who enrolled increased 
their average savings contributions from 3.5% to 11.6% in just 
a little over two years. And almost everyone who started in the 
program stayed.


The human brain still presents science with a host of mysteries. We 
have by no means figured it all out, but the science of decision making 
has uncovered some remarkable things. And it points the way toward 
more discoveries to be made in answering the question: How do we 
decide?
Suggested Reading
Plous, The Psychology of Judgment and Decision Making.
Thaler and Benartzi, “Save More Tomorrow: Using Behavioral 
Economics to Increase Employee Saving.”

How You Decide: The Science of Human Decision Making
194
Questions to Consider
1.	 What is the criticism of the descriptive (psychological) approach 
to studying decision making? What counterarguments might 
proponents of that approach use?
2.	 What are the four foundational ideas that summarize the key 
insights from this course?

195
Bibliography
Baumeister, Roy F., and John Tierney. Willpower: Rediscovering the Greatest 
Human Strength. Penguin Books, 2011.
Baumeister, Roy F., and Kathleen D. Vohs. “Self-Regulation, Ego Depletion, 
and Motivation.” Social and Personality Psychology Compass 1 (2007): 115–
128.
Berger, Jonah, and Grainne Fitzsimons. “Dogs on the Street, Pumas on 
Your Feet: How Cues in the Environment Influence Product Evaluation and 
Choice.” Journal of Marketing Research 45 (2008): 1–14.
Bettman, James R., Mary Frances Luce, and John W. Payne. “Constructive 
Consumer Choice Process.” Journal of Consumer Research 25 (1998): 
187–217.
Chernev, Alexander. “The Dieter’s Paradox.” Journal of Consumer 
Psychology 21 (2011): 178–183.
———. “Product Assortment and Consumer Choice: An Interdisciplinary 
Review.” Foundations and Trends in Marketing 6 (2011): 1–61.
Chernev, Alexander, and Ryan Hamilton. “Assortment Size and Option 
Attractiveness in Consumer Choice among Retailers.” Journal of Marketing 
Research 46 (2009): 410–420.
Cialdini, Robert B. Influence: The Psychology of Persuasion. Harper Business, 
2006.
Diehl, Kristin, and Cait Poynor. “Great Expectations?! Assortment Size, 
Expectations, and Satisfaction.” Journal of Marketing Research 47 (2010): 
312–322.

How You Decide: The Science of Human Decision Making
196
Duclos, Rod, Echo Wen Wan, and Yuwei Jiang. “Show Me the Honey! Effects 
of Social Exclusion on Financial Risk-Taking.” Journal of Consumer Research 
40 (2013).
Duhigg, Charles. The Power of Habit: Why We Do What We Do in Life and 
Business. Random House, 2012.
Dweck, Carol S. “The Secret to Raising Smart Kids.” Scientific American 
Mind (December 2007/January 2008): 36–43.
Fishbach, Ayelet, and Ravi Dhar. “Goals as Excuses or Guides: The Liberating 
Effect of Perceived Goal Progress on Choice.” Journal of Consumer Research 
32 (2005): 370–377.
Frederick, Shane, Nathan Novemsky, Jing Wang, Ravi Dhar, and Stephen 
Nowlis. “Opportunity Cost Neglect.” Journal of Consumer Research 36 
(2009): 553–561.
Gneezy, Uri, and Aldo Rustichini. “Incentives, Punishment, and Behavior.” 
In Advances in Behavioral Economics. Edited by Colin F. Camerer, George 
Loewenstein, and Matthew Rabin. Princeton University Press, 2004.
Gollwitzer, Peter M. “Mindset Theory of Action Phases.” In Theories of Social 
Psychology. Edited by Paul A. van Lange. Sage, 2012.
Hassin, Ran R., James S. Uleman, and John A. Bargh, eds. The New 
Unconscious. Oxford University Press, 2006.
Higgins, E. Tory. “Promotion and Prevention: Regulatory Focus as a 
Motivational Principle.” In Advances in Experimental Social Psychology, vol. 
30. Edited by Mark P. Zanna. Academic Press, 1998.
Hirshleifer, David, and Tyler Shumway. “Good Day Sunshine: Stock Returns 
and the Weather.” The Journal of Finance 58 (2003): 1009–1032.

Bibliography 
197
Hong, Jiewen, and Yacheng Sun. “Warm It Up with Love: The Effect of 
Physical Coldness on the Liking of Romance Movies.” Journal of Consumer 
Research 39 (2012): 293–306.
Hsee, Christopher K. “The Evaluability Hypothesis: An Explanation 
for Preference Reversals between Joint and Separate Evaluations.” 
Organizational Behavior and Human Decision Processes 67 (1996): 247–257.
———. “Less Is Better: When Low-Value Options Are Valued More Highly 
Than High-Value Options.” Journal of Behavioral Decision Making 11 (1998). 
Hsee, Christopher K., and Jiao Zhang. “General Evaluability Theory.” 
Perspectives on Psychological Science 5 (2010): 343–355.
Huber, Joel, John W. Payne, and Christopher Puto. “Adding Asymmetrically 
Dominated Alternatives: Violations of Regularity and the Similarity 
Hypothesis.” Journal of Consumer Research 9 (1982): 90–98.
Iyengar, Sheena S., and Mark R. Lepper. “When Choice Is Demotivating: Can 
One Desire Too Much of a Good Thing?” Journal of Personality and Social 
Psychology 79 (2000): 995–1006.
Kahneman, Daniel. “Maps of Bounded Rationality: Psychology for Behavioral 
Economics.” The American Economic Review 93 (2003): 1449–1475.
———. Thinking, Fast and Slow. Farrar, Straus and Giroux, 2011.
Kahneman, Daniel, Paul Slovic, and Amos Tversky. Judgment under 
Uncertainty: Heuristics and Biases. Cambridge University Press, 1982. 
Kahneman, Daniel, and Amos Tversky. “Prospect Theory: An Analysis of 
Decision under Risk.” Econometrica 47 (1979): 263–292.
———, eds. Choices, Values, and Frames. Cambridge University Press, 2000.

How You Decide: The Science of Human Decision Making
198
Kenrick, Douglas T., and Vladas Griskevicius. The Rational Animal: How 
Evolution Made Us Smarter Than We Think. Basic Books, 2013.
Kivetz, Ran, Oleg Urminsky, and Yuhuang Zheng. “The Goal-Gradient 
Hypothesis Resurrected: Purchase Acceleration, Illusionary Goal Progress, 
and Customer Retention.” Journal of Marketing Research 43 (2006): 39–58.
Larson, Jeffrey S., and Ryan Hamilton. “When Budgeting Backfires: How 
Self-Imposed Price Restraints Can Increase Spending.” Journal of Marketing 
Research 49 (2012): 218–230.
Lee, Angela Y., and Jennifer L. Aaker. “Bringing the Frame into Focus: The 
Influence of Regulatory Fit on Processing Fluency and Persuasion.” Journal 
of Personality and Social Psychology 86 (2004): 205–218.
Lerner, Jennifer S., Ye Li, Piercarlo Valdesolo, and Karim S. Kassam. “Emotion 
and Decision Making.” Annual Review of Psychology 66 (2015): 799–823.
Lord, Charles G., Lee Ross, and Mark R. Lepper. “Biased Assimilation 
and Attitude Polarization: The Effects of Prior Theories on Subsequently 
Considered Evidence.” Journal of Personality and Social Psychology 37 
(1979): 2098–2109.
McClure, Samuel M., Jian Li, Damon Tomlin, Kim S. Cypert, Latané M. 
Montague, and P. Read Montague. “Neural Correlates of Behavioral 
Preference for Culturally Familiar Drinks.” Neuron 44 (2004): 379–387.
Molden, Daniel, Angela Y. Lee, and E. Tory Higgins. “Motivations for 
Promotion and Prevention.” In Handbook of Motivation Science. Edited by 
J. Shah and W. Gardner. Guilford Press, 2008.
Parker, Jeffrey R., and Rom Schrift. “Rejectable Choice Sets: How Seemingly 
Irrelevant No-Choice Options Affect Consumer Decision Processes.” Journal 
of Marketing Research 48 (2011): 840–854.

Bibliography 
199
Payne, John W., James R. Bettman, and Eric J. Johnson. The Adaptive 
Decision Maker. Cambridge University Press, 1993.
Plous, Scott. The Psychology of Judgment and Decision Making. McGraw-
Hill, 1993.
Shadish, William R., Thomas D. Cook, and Donald T. Campbell. Experimental 
and Quasi-Experimental Designs for Generalized Causal Inference. 2nd ed. 
Wadsworth Publishing, 2001.
Shafir, Eldar, Itamar Simonson, and Amos Tversky. “Reason-Based Choice.” 
Cognition 49 (1993): 11–36.
Simonson, Itamar. “Choice Based on Reasons: The Case of Attraction and 
Compromise Effects.” Journal of Consumer Research 16 (1989): 158–174.
Soman, Dilip, and Amar Cheema. “Earmarking and Partitioning: Increasing 
Saving by Low-Income Households.” Journal of Marketing Research 48 
(2011): S14–S22.
Sparrow, Betsy, Jenny Liu, and Daniel M. Wegner. “Google Effects on 
Memory: Cognitive Consequences of Having Information at Our Fingertips.” 
Science 333 (2011): 776–778.
Thaler, Richard H. “Mental Accounting Matters.” Journal of Behavioral 
Decision Making 12 (1999): 183–206.
Thaler, Richard H., and Shlomo Benartzi. “Save More Tomorrow: Using 
Behavioral Economics to Increase Employee Saving.” Journal of Political 
Economy 112 (2004): S164–S187.
Thorndike, Edward L. “A Constant Error in Psychological Ratings.” Journal of 
Applied Psychology 4 (1920): 25–29.
Trope, Yaacov, and Nira Liberman. “Construal-Level Theory of Psychological 
Distance.” 117 (2010): 440–463.

How You Decide: The Science of Human Decision Making
200
Tversky, Amos, and Daniel Kahneman. “Judgment under Uncertainty: 
Heuristics and Biases.” Science 185 (1974): 1124–1131.
———. “Advances in Prospect Theory: Cumulative Representation of 
Uncertainty.” Journal of Risk and Uncertainty 5 (1992): 297–323.
Wansink, Brian, James E. Painter, and Jill North. “Bottomless Bowls: Why 
Visual Cues of Portion Size May Influence Intake.” Obesity 13 (2012): 93–100.
Wicklund, Robert A., and Peter M. Gollwitzer. Symbolic Self-Completion. 
Routledge, 1982.
Wood, Wendy, and David T. Neal. “A New Look at Habits and the Habit-
Goal Interface.” Psychological Review 114 (2007): 843–863.
Zhong, Chen-Bo, and Katie Liljenquist. “Washing away Your Sins: Threatened 
Morality and Physical Cleansing.” Science 313 (2006): 1451–1452.

201
Image Credits 
Page 5: © Digital Vision/Photodisc/Thinkstock.
Page 8: © Noel Hendrickson/DigitalVision/Thinkstock.
Page 11: © ziggy_mars/iStock/Thinkstock.
Page 14: © Jupiterimages/Stockbyte/Thinkstock.
Page 22: © RamonCarretero/iStock/Thinkstock.
Page 24: © Martin Poole/Photodisc/Thinkstock.
Page 29: © RicardoImagen/iStock/Thinkstock.
Page 30: © gpointstudio/iStock/Thinkstock.
Page 34: ©Wavebreak Media/Thinkstock.
Page 37: © tetmc/iStock/Thinkstock.
Page 42: © IPGGutenbergUKLtd/iStock/Thinkstock.
Page 45: © moodboard/Thinkstock.
Page 49: © Yuri/iStock/Thinkstock.
Page 50: © AbleStock.com/Thinkstock.
Page 59: © Shalom Ormsby/Blend Images/Thinkstock.
Page 61: © Wavebreakmedia/iStock/Thinkstock.
Page 66: © moodboard/Thinkstock.
Page 71: © nensuria/iStock/Thinkstock.
Page 76: © Runur/iStock/Thinkstock.
Page 79: © SbytovaMN/iStock/Thinkstock.
Page 83: © LuckyBusiness/iStock/Thinkstock.
Page 85: © Ryan McVay/Stockbyte/Thinkstock.
Page 90: © Paul Burns/Blend Images/Thinkstock.
Page 94: © HASLOO/iStock/Thinkstock.
Page 98: © miflippo/iStock/Thinkstock.
Page 101: © George Doyle/Stockbyte/Thinkstock.

How You Decide: The Science of Human Decision Making
202
Page 106: © Ron Chapple Stock/Ron Chapple Studios/Thinkstock.
Page 108: © George Doyle/Stockbyte/Thinkstock.
Page 114: © lirtlon/iStock/Thinkstock.
Page 119: © Elenathewise/iStock/Thinkstock.
Page 123: © Siri Stafford/Photodisc/Thinkstock.
Page 125: © michaeljung/iStock/Thinkstock.
Page 130: © slava296/iStock/Thinkstock.
Page 136: © Digital Vision/Photodisc/Thinkstock.
Page 141: © Steve Mason/Valueline/Thinkstock.
Page 144: © moodboard/Thinkstock.
Page 151: © marlenka/iStock/Thinkstock.
Page 152: © phive2015/iStock/Thinkstock.
Page 156: © Feverpitched/iStock/Thinkstock.
Page 159: © Andersen Ross/Blend Images/Thinkstock.
Page 164: © Noel Hendrickson/DigitalVision/Thinkstock.
Page 166: © .shock/iStock/Thinkstock.
Page 173: © Wavebreakmedia/iStock/Thinkstock.
Page 176: © svariophoto/iStock/Thinkstock.
Page 180: © Comstock/Stockbyte/Thinkstock.
Page 183: © Michael Blann/DigitalVision/Thinkstock.
Page 187: © Digital Vision/Thinkstock.
Page 189: © Digital Vision/Photodisc/Thinkstock.

