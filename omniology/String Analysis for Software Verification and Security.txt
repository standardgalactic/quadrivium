Tevﬁ k Bultan · Fang Yu
Muath Alkhalaf · Abdulbaki Aydin
String Analysis 
for Software 
Veriﬁ cation and 
Security

String Analysis for Software Veriﬁcation
and Security

Tevﬁk Bultan • Fang Yu • Muath Alkhalaf
Abdulbaki Aydin
String Analysis for Software
Veriﬁcation and Security
123

Tevﬁk Bultan
Department of Computer Science
University of California, Santa Barbara
Santa Barbara, CA, USA
Muath Alkhalaf
Computer Science Department
King Saud University
Riyadh, Saudi Arabia
Fang Yu
Department of Management
Information Systems
National Chenchi University
Taipei, Taiwan
Abdulbaki Aydin
Microsoft (United States)
Redmond, WA, USA
ISBN 978-3-319-68668-4
ISBN 978-3-319-68670-7
(eBook)
https://doi.org/10.1007/978-3-319-68670-7
Library of Congress Control Number: 2017956344
© Springer International Publishing AG 2017
This work is subject to copyright. All rights are reserved by the Publisher, whether the whole or part of
the material is concerned, speciﬁcally the rights of translation, reprinting, reuse of illustrations, recitation,
broadcasting, reproduction on microﬁlms or in any other physical way, and transmission or information
storage and retrieval, electronic adaptation, computer software, or by similar or dissimilar methodology
now known or hereafter developed.
The use of general descriptive names, registered names, trademarks, service marks, etc. in this publication
does not imply, even in the absence of a speciﬁc statement, that such names are exempt from the relevant
protective laws and regulations and therefore free for general use.
The publisher, the authors and the editors are safe to assume that the advice and information in this book
are believed to be true and accurate at the date of publication. Neither the publisher nor the authors or
the editors give a warranty, express or implied, with respect to the material contained herein or for any
errors or omissions that may have been made. The publisher remains neutral with regard to jurisdictional
claims in published maps and institutional afﬁliations.
Printed on acid-free paper
This Springer imprint is published by Springer Nature
The registered company is Springer International Publishing AG
The registered company address is: Gewerbestrasse 11, 6330 Cham, Switzerland

Preface
This monograph is mainly based on the research that has been conducted in the
Veriﬁcation Laboratory at the University of California, Santa Barbara, in the last
decade. String analysis has been an interesting and fruitful area to work on, leading
to many research results some of which are discussed here. We observe that the
research in analysis of string manipulating code is expanding due to the importance
of the correctness of the string manipulation code for dependability and security of
modern software systems. We hope that this monograph can inspire and motivate
more research in this area and accelerate the transition of string analysis research to
practice.
We would like to thank all current and past members of the Veriﬁcation
Laboratory for their help and support. We would also like to acknowledge the
support provided by the National Science Foundation (NSF) and the Defense
Advanced Research Projects Agency (DARPA) for the string analysis research at
the Veriﬁcation Laboratory.1
Santa Barbara, CA, USA
Tevﬁk Bultan
Taipei, Taiwan
Fang Yu
Riyadh, Saudi Arabia
Muath Alkhalaf
Redmond, WA, USA
Abdulbaki Aydin
1NSF under grants CCF 0916112, CNS-1116967, CCF-1423623, and CCF-1548848, and DARPA
under agreement number FA8750-15-2-0087. The U.S. Government is authorized to reproduce
and distribute reprints for Governmental purposes notwithstanding any copyright notation thereon.
The views and conclusions contained herein are those of the authors and should not be interpreted
as necessarily representing the ofﬁcial policies or endorsements, either expressed or implied, of
DARPA or the U.S. Government.
v

Contents
1
Introduction .................................................................
1
1.1
Common Vulnerabilities Due to String Manipulation Errors ......
4
1.2
Examples of String Manipulating Code and Errors.................
6
1.3
Overview..............................................................
12
2
String Manipulating Programs and Difﬁculty of Their Analysis .....
15
2.1
A Simple String Manipulation Language ...........................
15
2.2
Automated and Precise Veriﬁcation of String Programs
Is Not Possible........................................................
16
2.3
A Richer String Manipulation Language............................
18
2.4
Summary..............................................................
22
3
State Space Exploration ...................................................
23
3.1
Semantics of String Manipulation Languages ......................
23
3.2
Explicit State Space Exploration ....................................
26
3.2.1
Forward Reachability.......................................
27
3.2.2
Backward Reachability .....................................
28
3.3
Symbolic Exploration ................................................
29
3.3.1
Symbolic Reachability .....................................
30
3.3.2
Fixpoints ....................................................
31
3.4
Summary..............................................................
35
4
Automata Based String Analysis..........................................
37
4.1
A Lattice for Sets of Strings .........................................
37
4.2
Symbolic Reachability Analysis with Automata ...................
38
4.3
Symbolic Automata Representation .................................
41
4.3.1
MTBDD Representation ...................................
43
4.3.2
Modeling Non-Determinism Using Symbolic DFA ......
44
4.3.3
Symbolic vs. Explicit DFA.................................
45
4.4
Post-Condition Computation ........................................
45
4.4.1
Concatenation and Replace Operations....................
46
vii

viii
Contents
4.4.2
Post-Condition of Concatenation ..........................
47
4.4.3
Post-Condition of Replacement............................
48
4.5
Pre-Condition Computation .........................................
51
4.5.1
Pre-Condition of Concatenation ...........................
51
4.5.2
Pre-Condition of Replacement .............................
53
4.6
Summary..............................................................
55
5
Relational String Analysis .................................................
57
5.1
Relations Among String Variables ..................................
57
5.2
Multi-Track DFAs ....................................................
59
5.3
Relational String Analysis ...........................................
59
5.3.1
Word Equations .............................................
60
5.4
Construction of Multi-Track DFAs for Basic Word Equations ....
61
5.5
Symbolic Reachability Analysis.....................................
65
5.5.1
Forward Fixpoint Computation ............................
66
5.5.2
Summarization..............................................
68
5.6
Summary..............................................................
68
6
Abstraction and Approximation ..........................................
69
6.1
Regular Abstraction .................................................
69
6.2
Alphabet Abstraction ................................................
70
6.3
Relation Abstraction .................................................
74
6.4
Composing Abstractions ............................................
76
6.5
Automata Widening Operation ......................................
77
6.6
Summary..............................................................
80
7
Constraint-Based String Analysis ........................................
83
7.1
Symbolic Execution with String Constraints .......................
83
7.2
Automata-Based String Constraint Solving.........................
87
7.2.1
Mapping Constraints to Automata .........................
87
7.3
Relational Constraint Solving with Multi-Track DFA..............
93
7.3.1
Relational String Constraint Solving ......................
94
7.3.2
Relational Integer Constraint Solving .....................
95
7.3.3
Mixed String and Integer Constraint Solving .............
95
7.4
Model Counting ......................................................
96
7.4.1
Automata-Based Model Counting .........................
99
7.4.2
Counting All Solutions within a Given Bound ............ 101
7.5
Summary.............................................................. 102
8
Vulnerability Detection and Sanitization Synthesis..................... 103
8.1
Vulnerability Detection and Repair.................................. 104
8.2
Patching Algorithm .................................................. 111
8.3
Vulnerability Analysis ............................................... 112
8.4
Vulnerability Signatures ............................................. 114
8.5
Relational Signatures................................................. 116
8.6
Sanitization Generation .............................................. 119
8.7
Summary.............................................................. 122

Contents
ix
9
Differential String Analysis and Repair.................................. 123
9.1
Formal Modeling of Validation and Sanitization Functions........ 126
9.1.1
Post- and Pre-Image of a Sanitizer......................... 130
9.2
Discovering Client- and Server-Side Input Validation and
Sanitization Inconsistencies.......................................... 133
9.2.1
Extracting and Mapping Input Validation and
Sanitization Functions at the Client- and the
Server-Side.................................................. 133
9.2.2
Inconsistency Identiﬁcation ................................ 134
9.3
Semantic Differential Repair for Input Validation
and Sanitization ...................................................... 136
9.3.1
Differential Repair Problem................................ 140
9.3.2
Differential Repair Algorithm ............................. 141
9.4
Summary.............................................................. 147
10
Tools.......................................................................... 149
10.1
LIBSTRANGER ....................................................... 149
10.2
STRANGER ........................................................... 150
10.3
SEMREP .............................................................. 151
10.4
ABC................................................................... 153
11
A Brief Survey of Related Work .......................................... 155
11.1
String Analysis ....................................................... 155
11.1.1
Grammar Based String Analysis........................... 155
11.1.2
Automata-Based String Analysis .......................... 157
11.1.3
Hybrid String Analysis ..................................... 158
11.2
String Constraint Solvers ............................................ 158
11.2.1
Automata-Based Solvers ................................... 159
11.2.2
Bounded Solvers............................................ 160
11.2.3
Combination of Theories ................................... 161
11.2.4
Model Counting String Constraint Solvers ................ 161
11.3
Bug and Vulnerability Detection in Web Applications ............. 161
11.3.1
Client-Side Analysis........................................ 162
11.3.2
Server-Side Analysis ....................................... 162
11.4
Differential Analysis and Repair .................................... 163
11.4.1
Differential Analysis ....................................... 163
11.4.2
Differential Repair.......................................... 164
12
Conclusions.................................................................. 165
References......................................................................... 167

Chapter 1
Introduction
In computing, a sequence of characters is called a string. For example, “Hello,
World!” is a string (we use double quotes to indicate the beginning and end of
the string). This particular string is very familiar to programmers since the ﬁrst
programming assignment in many programming textbooks is to write a program
that outputs the string “Hello, World!” Although programmers become familiar with
the creation and manipulation of strings very early on in their training, errors in
string manipulating code is a major cause of software faults and vulnerabilities.
This indicates that string manipulation is a challenging task for programmers, and
automated techniques for analyzing string manipulating code, which is the topic of
this monograph, are very desirable.
Handling of strings in programming languages vary widely. In the C program-
ming language, characters are a basic data type, but strings are not. Strings are
represented as arrays of characters, which is a natural way to store strings. Since
strings do not have a type dedicated to them, basic operations on strings (such as
concatenating two strings) are not part of C, and are instead provided as library
functions (such as strcat, strcpy, strcmp, strlen).
In the Java programming language, strings are objects corresponding to the
instances of String class. String operations are provided as the methods of
the String class (such as the length, charat and concat methods) and the
String class is implemented by storing strings as arrays of characters. Java also
provides a string concatenation operator (“+”).
In the more recent JavaScript programming language, strings are supported as
one of the primitive data types, and strings can be constructed using operators such
as string concatenation operator “+”. JavaScript also provides a set of methods for
string manipulation (such as substring, indexOf, replace).
We see that different languages treat strings differently. In general, support for
string manipulation in programming languages has been increasing. This is due
to increasing use of string manipulation in implementation of modern software
© Springer International Publishing AG 2017
T. Bultan et al., String Analysis for Software Veriﬁcation and Security,
https://doi.org/10.1007/978-3-319-68670-7_1
1

2
1
Introduction
applications. Here are some common uses of string manipulation in modern
software development:
•
Input sanitization and validation: Many modern software applications are web-
based and the user inputs to web applications typically come in the string form
(for example a text ﬁeld entered by the user). Since any user with an Internet
connection can access web applications and interact with them, web application
developers have to assume that the user input could be malicious. There are well-
known cyber-attack techniques that involve a malicious user submitting hidden
commands via user input ﬁelds. Execution of these harmful commands can lead
to unauthorized access to or loss of data. To prevent such scenarios, application
developers have to either reject the user input that does not ﬁt expected patterns
(which is called input validation), or clean up the user input by removing
unwanted characters (which is called input sanitization). Both input validation
and sanitization involve string manipulation since user inputs are typically in
string form.
•
Query generation for back-end databases: Many modern software applications
use a back-end database to store data. When users interact with modern software
applications, user requests result in generation of a query that is sent to a back-
end database. The user request triggers a piece of code that constructs the
database query as a string. So, string manipulation is an essential part of query
generation.
•
Generation of data formats such as XML, JSON, and HTML: Modern software
applications typically use well-known data formats to store, exchange, or
describe data. XML and JSON are two of the widely used data formats. HTML
is the format used to describe web documents and to display user input forms
in web applications. Many modern applications dynamically create documents
in XML, JSON, or HTML format during program execution. Creation of XML,
JSON, or HTML documents involve manipulation of strings.
•
Dynamic code generation: Software applications are becoming increasingly
dynamic. For example, many modern web applications dynamically generate
code based on user requests. Web applications are multi-tiered systems where
part of the code is executed on web servers (that are typically hosted in compute-
clouds), and part of the code is executed on the client machine. It is common for
the server-side code to generate client-side code dynamically at runtime. Client-
code is generated using string manipulation.
•
Dynamic class loading and method invocation: Programming languages are
also becoming increasingly dynamic. Modern languages such as JavaScript and
PHP allow functions to be speciﬁed using string variables, where the invoked
methods or loaded classes depend on the values of the string variables at
runtime. Reﬂection in Java allows programs to load classes dynamically at
runtime. Similarly, in Objective-C, one can load classes from string variables.
This provides developers powerful means to adjust program executions according
to their runtime environment and status. However, since the loaded classes or
invoked methods depend on the values of string variables at runtime, malicious

1
Introduction
3
developers could manipulate string values to obfuscate the program behavior, and
prevent static detection of malicious behaviors such as accessing sensitive/private
APIs in Android/iOS mobile applications.
Due to extended use of strings in modern software development, errors in
string manipulating code or maliciously written string manipulating code can
have disastrous effects. It would be very helpful for developers to be able to
automatically check if the string manipulation code works correctly with respect
to their expectations. This is the core problem that string analysis addresses. String
analysis is a static program analysis technique that determines the values that a
string expression can take during program execution at a given program point. String
analysis can be used to solve many problems in modern software systems that relate
to string manipulation, such as:
•
String analysis can be used to identify security vulnerabilities by checking if a
security sensitive function can receive an input string that contains an exploit [78,
119, 130, 132]. This type of vulnerabilities are common in web applications when
user input is not adequately validated or sanitized.
•
Modern dynamic languages enable execution of dynamically generated code. For
example, in JavaScript, the eval function can be used to execute dynamically
generate code. The eval function takes a string value as an argument and
executes the JavaScript expression, variable, statement, or sequence of statements
that is given as the argument. So, in order to analyze the behavior of a JavaScript
program that uses the eval function, we ﬁrst need to understand the set of string
values that can be passed to the eval function as an argument. String analysis
can be used for this purpose [57].
•
For applications that dynamically generate data in XML, JSON or HTML
format, string analysis can be used to identify formatting errors in the generated
documents, which would then identify bugs in the XML, JSON or HTML
generating code [78].
•
For applications that dynamically generate queries for a back-end database, string
analysis can be used to identify the set of queries that are sent to the back-
end database by analyzing the code that generates the SQL queries. This can
be used to identify vulnerabilities, or to generate test queries for the back-end
database [118, 119].
•
For web applications where server-side code dynamically generates client-side
code, string analysis can be used to determine the client-side code that can be
generated [82, 83], and this can be used to analyze and ﬁnd potential problems in
the generated client-side code.
•
String analysis can also be used for automatically repairing faulty string manip-
ulation code. For example, input validation and sanitization functions can be
repaired automatically by identifying the set of input values that can cause a
vulnerability [128].
•
For programs that have classes loaded from strings, string analysis can be used in
advance to ﬁnd all potential values of loaded classes or invoked methods, for
example, for taming reﬂection in Java programs [22, 72]. Particularly, string

4
1
Introduction
analysis can be used to analyze complex string manipulation to improve the
precision of static taint/ﬂow analysis.
Like many other program-analysis problems, it is not possible to solve the string
analysis problem precisely (i.e., it is not possible to precisely determine the set
of string values that can reach a program point). However, one can compute
over- or under-approximations of possible string values. If the approximations
are precise enough, they can enable us to demonstrate existence or absence of
bugs and vulnerabilities in string manipulating code. String analysis has been
an active research area in the last decade, resulting in a wide variety of string-
analysis techniques such as, grammar-based string analysis [63, 78], automata-based
symbolic string analysis [26, 34, 55, 113, 114], string constraint solving [3, 12,
15, 71, 93, 112], string abstractions [21, 131], relational string analysis [133],
vulnerability detection using string analysis [100, 119, 129], differential string
analysis [5, 7], and automated repair using string analysis [5, 128].
1.1
Common Vulnerabilities Due to String Manipulation
Errors
Let us discuss the security vulnerabilities related to string manipulation errors
further. Security vulnerabilities in web applications are common. Ubiquity and
global accessibility of web applications make this a critical problem. Malicious
users all around the world can exploit vulnerable web applications resulting in
unauthorized access to private data or loss of critical information. Since web
applications are continuously in use without any available downtime for manual
analysis or repair, vulnerabilities in web applications should not only be discovered
fast, but should also be repaired fast. String analysis techniques can be used to
address this problem.
The Common Vulnerabilities and Exposures (CVE) repository keeps track of all
reported computer security vulnerabilities [30]. According to the CVE repository,
web application vulnerabilities form a signiﬁcant portion of all reported computer
security vulnerabilities. Two of the most common vulnerabilities in web applications
are: Cross-site Scripting (XSS) and SQL Injection (SQLI).
A XSS vulnerability results from the application inserting part of a malicious
user’s input in an HTML page that it renders. For example, a malicious user
can attack a web forum application by posting a comment that contains a link
that contains an executable script (such as JavaScript code) within the text of the
comment. The attack occurs, if, while viewing the comment, another user clicks on
the link that contains the malicious code. The victim’s browser will then execute
the malicious JavaScript code and this can result in stealing of browser cookies and
other sensitive data.
An SQL Injection vulnerability, on the other hand, results from the application’s
use of user input in constructing database queries. The attacker can invoke the
application with a malicious input that becomes part of an SQL command that the

1.1
Common Vulnerabilities Due to String Manipulation Errors
5
Fig. 1.1 Percentage of the Cross-site Scripting (XSS) and SQL Injection (SQLI) vulnerabilities
among all the computer security vulnerabilities reported in the CVE repository [30]
application executes. This permits the attacker to damage or get unauthorized access
to data stored in the back-end database of the application.
Figure 1.1 shows what percentage of all reported computer security vulnerabil-
ities are of these two types over the years, based on the vulnerabilities reported
in the CVE repository. Additionally, Open Web Application Security Project
(OWASP) compiles a top ten list to identify the most critical security ﬂaws in web
applications [84–86]. According to the OWASP top ten lists compiled in 2007,
2010 and 2013, XSS and SQLI are always among the top three web application
vulnerabilities.
XSS and SQLI vulnerabilities are caused by inadequate input validation and
sanitization. Any error in validation and sanitization of user input can lead to a
signiﬁcant vulnerability for a web application, and can be exploited by malicious
users all around the world. Input validation and sanitization in web applications
is crucial and challenging since communication between different layers of a web
application occurs through directives (commands) that often embed user input and
are written in many languages, such as XML, SQL, and HTML. Programs that
propagate and use malicious user inputs without validation and sanitization, or
with inadequate validation and sanitization, are vulnerable to attacks such as XSS
and SQLI.
One thing to note in Fig. 1.1 is that, the percentage of XSS and SQLI vulnera-
bilities among all reported security vulnerabilities increased signiﬁcantly between
2000 and 2006. This can be attributed to the signiﬁcant increase in web applications
during that time period, and the lack of techniques and tools and lack of awareness

6
1
Introduction
among software developers for eliminating these vulnerabilities. We see a decrease
in these vulnerabilities after 2006, although the number of web applications
continued to increase. This can be explained with better programming practices and
better techniques and tools for eliminating these vulnerabilities. However, we still
see that more than 15% of all computer security vulnerabilities are due to XSS
and SQLI ﬂaws in more recent years. Although, these two types of vulnerabilities
in web applications are notorious, and they are widely publicized, we continue
to see a signiﬁcant number of new XSS and SQLI vulnerabilities. This indicates
the challenging nature of writing string manipulation code for implementing input
validation and sanitization functions, and demonstrates the need for static analysis
techniques that can help programmers in preventing errors in string manipulating
code that can lead to security vulnerabilities.
1.2
Examples of String Manipulating Code and Errors
A web application typically expects the user input to be in a certain format for
many text ﬁelds (such as username, email, zip code, etc.). Since the user input can
contain typing errors, or may be purposefully written (by a malicious user) to violate
the expected format, the web application has to validate the user input using input
validation operations such as regular expression matching. Furthermore, the web
application may need to modify the input to put it in the expected format using
sanitization operations such as trimming white spaces from the beginning and the
end of an input or escaping problematic characters. Figure 1.2 shows an example
of a validation and sanitization function written in Java to validate and sanitize
email addresses in a web application called JGossip (http://sourceforge.net/projects/
Fig. 1.2 Server-side input validation code snippet written in Java

1.2
Examples of String Manipulating Code and Errors
7
Fig. 1.3 Part 1 of a client-side JavaScript code example demonstrating the complexity of input
validation and sanitization code
jgossipforum/). This is a server-side validation function that is executed after the
user input reaches to the web server. Line 5 checks that the email address value is
not null or empty after trimming space characters. Lines 6 and 7 validate the input
by matching against a regular expression using the Perl5Util package’s match
function. Note that regular expressions used in this type of validation code can be
quite complex and prone to errors.
Input validation code can be more complex than the example shown in Fig. 1.2.
Consider the example code shown in Figs. 1.3 and 1.4. This example shows parts of
a typical input validation and sanitization code used to validate a form in a Google
website. This is client-side code written in JavaScript. It is executed at the user’s
machine. This type of client-side input validation is commonly used since checking
the user input before sending it to the server can improve the responsiveness of the

8
1
Introduction
Fig. 1.4 Part 2 of a client-side JavaScript code example demonstrating the complexity of input
validation and sanitization code
Fig. 1.5 A server-side input sanitization code snippet written in PHP
application by preventing unnecessary communication over the network, and it can
also reduce the load of the server-side machines. Note that, this code (1) mixes the
input validation and sanitization of multiple HTML form ﬁelds at the same time,
and (2) mixes the actual code that does the input validation and sanitization with
other parts of the program that do error reporting and event handling. Due to its
complexity, it would not be surprising to encounter errors in this type of code, and
it is difﬁcult to analyze it.
Let us now look at some examples of erroneous input validation and sanitization
code to see what kind of bugs appear in real-world code. Figure 1.5 shows a
simpliﬁed version of a vulnerable PHP sanitization code that is taken from a web
application called MyEasyMarket [13].
The code starts with assigning the user input provided in the $_GET array
to the $www variable in line 2. Then, in line 3, it assigns a string constant to
the $l_otherinfo variable. Next, in line 4, the user input is sanitized using
the preg_replace command. This replace command gets three arguments: the
match pattern, the replace string and the target string. It ﬁnds all the substrings of
the target string that match the match pattern and replaces them with the replace
string. In the replace command shown in line 4, the match pattern is the regular
expression [^A-Za-z0-9 .-@://], the replace string is the empty string
(which corresponds to deleting all the substrings that match the match pattern), and
the target string is the value of the variable $www. After the sanitization step, the
PHP code outputs the concatenation of the variable $l_otherinfo, the string
constant ": ", and the variable $www.

1.2
Examples of String Manipulating Code and Errors
9
The replace operation in line 4 contains an error that leads to a XSS
vulnerability. The error is in the match pattern of the replace operation:
[^A-Za-z0-9 .-@://]. The goal of the programmer was to eliminate all
the characters that should not appear in a URL. The programmer implements
this by deleting all the characters that do not match the characters in the regular
expression [A-Za-z0-9 .-@://]. The programmer’s intention is to eliminate
everything other than alpha-numeric characters, and the ASCII symbols ., -, @,
:, and /. However, the regular expression is not correct. First, there is a harmless
error. The subexpression // can be replaced with / since repeating the symbol /
twice is unnecessary. More serious error is the following: The expression .-@ is the
union of all the ASCII symbols that are between the symbol . and the symbol @ in
the ASCII ordering. The programmer intended to specify the union of the symbols
., -, and @ but forgot that symbol - has a special meaning in regular expressions
when it is enclosed with symbols [ and ]. The correct expression should have been
.\-@. This error leads to a vulnerability because the symbol < (which can be used
to start a script to launch a XSS attack) falls between the symbol . and the symbol
@ in the ASCII ordering. So, the sanitization operation fails to delete the < symbol
from the input, leading to a XSS vulnerability.
Using string replace operations, such as the one in this example, to sanitize user
input is common practice in web applications. However, this type of sanitization is
error prone due to complex syntax and semantics of regular expressions.
Figure 1.6 shows a JavaScript email validation function taken from a telecommu-
nication company website (www.stc.co.sa). This function has a different problem
than the previous one. The previous PHP function was under constrained and
accepts bad inputs while this function is over constrained and rejects good inputs. In
line 10, the input email address is validated against the complex regular expression
in lines 5–9. The problem is that this regular expression does not allow email
addresses with capital letters. Although this problem is present in the client-side of
Fig. 1.6 A client-side email validation code snippet written in JavaScript

10
1
Introduction
the web application, it will affect the application’s correctness since it will prevent
some valid emails with capital letters to reach the server.
Web application developers often introduce redundant input validation and
sanitization code in the client and server-side code of a web application. The input
provided by the user can be validated and/or sanitized by the client-side code
(written usually in JavaScript) that is executed on the user’s machine to make sure
it is in the correct format. As we mentioned earlier, the advantage of validating
user input on the client-side (instead of doing it exclusively on the server-side)
is that it improves usability and responsiveness of the application by preventing
unnecessary communication with the server and reduces the server load at the same
time. When the user input reaches the server, the server-side code validates and/or
sanitizes the user input again. Although this may sound redundant, it is necessary
due to the fact that the users can be malicious, and a malicious user can bypass the
client-side validation by manually crafting the HTML request with malicious input.
So, it is necessary to validate and/or sanitize the user input again at the server-
side. However, this introduces possibility of another type of bug. The validation and
sanitization policies at the client and server-side code could be inconsistent.
Figure 1.7 shows the client-side input validation function in JGossip web appli-
cation (written in JavaScript) that corresponds to the server-side input validation
function (written in Java) in Fig. 1.2. Although both functions validate the same
Fig. 1.7 Client-side input validation code snippet written in JavaScript that corresponds to the
server-side code in Fig. 1.2 written in Java

1.2
Examples of String Manipulating Code and Errors
11
Fig. 1.8 Dynamic class loading with objective C in iOS applications
HTML input ﬁeld that is used to input an email address, they return different
results for the same input. On one hand, the client-side validation function rejects a
sequence of one or more white space characters, for which the condition on line 6
evaluates to false and the regular expression check on line 11 fails, thereby resulting
in the function returning false. However, for the same input, the second condition
on line 5 of the server-side validation function (Fig. 1.2) evaluates to false, due to
the trim function call, and the string is therefore accepted by the server. Accepting
white spaces as email addresses by the server might lead to failures (for example by
inserting invalid data to the back-end database). As a general policy, the server-side
input validation/sanitization code should be more strict than the client-side input
validation/sanitization code. If an application violates this policy, it could lead to
erroneous behavior or security vulnerabilities.
In iOS programming, Objective-C allows programmers to load classes from
strings. In contrast to static compilation, dynamic class loading provides runtime
beneﬁts such as function adjustment and delay loading until the code is needed.
However, during dynamic class loading, developers may bypass static checking of
potential exploits of iOS private/sensitive API usages. Figure 1.8 shows an example
that loads class ASIdentifierManager dynamically. The class enables the
developers to derive a shared instance of ASIdentifierManager to access
users’ advertisement data. After loading the framework AdSupport at line 1,
the class ASIdentifierManager is dynamically loaded from a string variable
name by calling the C-function NSClassFromString at line 3. Note that the
value of name is composed using three strings “AS”, “Identiﬁer”, and “Manager”.
That is to say, until the runtime, the loaded class is unknown and the class name
ASIdentifierManager does not even appear in the code. Once the class is
loaded, it then gets the value of a static ﬁeld named sharedManager at line 6.
Use of more complex string manipulation operations, such as replacement, or using
an external input value in construction of the class name can obfuscate the loaded
class further. Identifying NSClassFromString as a sensitive function, string
analysis can be used to derive its input values to uncover the loaded class statically.
Similarly, Java Reﬂection makes it possible to inspect classes, interfaces, ﬁelds
and methods at runtime, without knowing the names of the classes, methods etc.
at compile time. This enables Java developers instantiate new objects, invoke
methods and get/set ﬁeld values using reﬂection in applications (including Android
mobile applications). Figure 1.9 shows the fragment of an Android benchmark app

12
1
Introduction
Fig. 1.9 A reﬂective call example from an Android app (from DroidBench [37])
that uses reﬂective call to access the device ID. The reﬂective class is loaded at line
3 and the method composed by two strings “setIme” and “i” at line 5 is invoked to
set the device ID. In this case, string analysis can be used in advance to discover that
the method “setImei” (a sensitive method) has been invoked.
1.3
Overview
Below we provide a brief overview of the contents of the remaining chapters:
•
In Chap. 2 we ﬁrst present a simple language for writing programs with string
variables, and demonstrate that analyzing string manipulating programs is as
hard as analyzing programs in general. We then present an extended string
manipulation language to illustrate the types of string manipulating operations
that are commonly used in software development.
•
In Chap. 3 we ﬁrst provide a transition-system semantics for string manipulating
programs. We then discuss reachability analysis techniques starting with explicit
state exploration. We present ﬁxpoint characterization of reachability analysis
using pre- and post-condition functions.
•
In Chap. 4 we discuss the basic techniques for automata-based symbolic reach-
ability analysis of string manipulating programs. We discuss the symbolic
automata representation based on Multi-Terminal Binary Decision Diagrams
(MTBDD) and present the forward and backward symbolic reachability analysis
algorithms. Finally, we discuss how to compute the pre- and post-condition
functions for basic string manipulation operations using automata as a symbolic
representation.
•
In Chap. 5 we discuss relational string analysis using multi-track automata as a
symbolic representation. Relational string analysis is necessary for veriﬁcation
of properties that involve relations among multiple string variables.
•
In Chap. 6 we discuss several automated abstraction techniques for string manip-
ulating programs. We also present an automata-based widening operation for
approximating ﬁxpoints in symbolic reachability analysis of string manipulating
programs.

1.3
Overview
13
•
In Chap. 7 we discuss constraint-based string analysis. We present an automata-
based approach to string constraint solving. We end this chapter with a discussion
on model counting for string constraints.
•
In Chap. 8 we discuss how string analysis techniques can be used for auto-
matically detecting security vulnerabilities in web applications. We also present
techniques for automatically repairing identiﬁed vulnerabilities.
•
In Chap. 9 we discuss differential string analysis techniques. We start with a
formal characterization of input validation and sanitization functions. We then
present techniques for discovering inconsistencies between client- and server-
side input validation and sanitization functions in web applications. We also
present differential repair techniques for eliminating identiﬁed inconsistencies.
•
In Chap. 10 we present a set of analysis tools which implement the techniques
discussed in earlier chapters:
– LIBSTRANGER is an automata-based symbolic analysis library that supports
pre- and post-condition computations for string operations and widening
operation.
– STRANGER is an automata-based static vulnerability analysis tool for check-
ing input validation and sanitization vulnerabilities in PHP applications.
– SEMREP is a language agnostic tool for automatically repairing vulnerabilities
in web applications using differential analysis.
– ABC is an automata-based, model counting, string constraint solver.
•
In Chap. 11 we present a brief survey of related research results.
•
In Chap. 12 we provide our closing comments.

Chapter 2
String Manipulating Programs and Difﬁculty
of Their Analysis
The goal of string analysis is to determine the values that a string expression can take
during program execution at a given program point. Like many program analysis
problems, this turns out to be a difﬁcult problem. We can demonstrate the difﬁculty
of string analysis using a simple language for string manipulation.
2.1
A Simple String Manipulation Language
We deﬁne the syntax of our simple string manipulation language in Fig. 2.1. Each
program consists of a sequence of labeled statements. Statements can be assignment
statements, conditional or unconditional branch statements, input and output state-
ments, and assert statements. We have only one string operation (concatenation “:”)
and only one predicate (equality “D”) in this simple language.
In Fig. 2.2 we show a simple program in the simple string manipulation language
we described above. This program consists of two read statements followed by
two assignment statements that use string concatenation followed by a conditional
branch statement that uses the equality predicate followed by print and halt
statements.
Assume that we want to check if an assertion in a program written in this
language can ever fail. If we can do precise string analysis on programs written
in this language, then we can determine all possible values for all string expressions
in the program. So, then, we can check if it is possible to have an assertion violation.
Note that, we can easily transform assertion violation checks to reachability checks
where we check if a program statement is reachable. Given an assertion statement
assert exp;
© Springer International Publishing AG 2017
T. Bultan et al., String Analysis for Software Veriﬁcation and Security,
https://doi.org/10.1007/978-3-319-68670-7_2
15

16
2
String Manipulating Programs and Difﬁculty of Their Analysis
Fig. 2.1 Grammar for a very simple string manipulation language
Fig. 2.2 A simple string
manipulating program
we can easily transform it to a reachability check as follows:
if exp goto 2;
1: print "assertion violation";
2: print "assertion holds";
Checking the reachability of the statement 1 is equivalent to checking if it is possible
to have an assertion violation during some execution of the program.
2.2
Automated and Precise Veriﬁcation of String Programs
Is Not Possible
Let us deﬁne the halting problem for string programs as the problem of deciding,
given a string program P, where initially the string variables are initialized to the null
string, , whether P will halt (i.e., reach the halt statement) on some execution.
More generally, the reachability problem for string programs (which need not halt)
is the problem of deciding, given a string program P and a program state s (where a
program state s is deﬁned with the instruction label of an instruction in the program
and the values of all the variables), whether at some point during a computation, the
program state s will be reached. Note that, we deﬁne the halting and the reachability
conditions using existential quantiﬁcation over the execution paths, i.e., the halting
and the reachability conditions hold if there exists an execution path that halts or

2.2
Automated and Precise Veriﬁcation of String Programs Is Not Possible
17
reaches the target state, respectively. Hence, if the halting problem is undecidable,
then the reachability problem is undecidable.
It can be shown that the halting program for string programs is undecidable [134].
In fact, halting problem for string programs is undecidable even if we restrict the
number of string variables to 3. It is possible to show this by demonstrating that
string programs can simulate counter machines.
Counter machines are a simple and powerful computational model that can
simulate Turing Machines. A counter machine consists of a ﬁnite number of
counters (unbounded integer variables) and a ﬁnite set of instructions. Counter
machines have a very small instruction set that includes an increment instruction,
a decrement instruction, a conditional branch instruction that tests if a counter value
is equal to zero, and a halt instruction. So, during the execution of a counter machine,
at each step, a counter can be incremented by 1, decremented by 1, and tested for
zero. The counters can only assume nonnegative values. It is well-known that the
halting problem for two-counter machines, where both counters are initialized to 0,
is undecidable [79]. In fact, two counter machines can simulate Turing Machines.
We show that a two-counter machine M can be simulated by a string program
P with only three string variables X1; X2; X3. The program counter of M can be
represented as labels in the string program P. The instructions where the counter-
machine M halts will be represented with the halt instruction in the string program P.
We will use the lengths of the strings X1, X2 and X3 to simulate the values of the
counters C1 and C2. The value of C1 will be simulated by jX1j  jX3j, and the value
of C2 will be simulated by jX2j  jX3j.
The counter machine M starts from the initial conﬁguration .q0; 0; 0/ where q0
denotes the initial instruction and the two integer values represent the initial values
of counters C1 and C2, respectively. The initial state of the string program P will be
.q0; ; ; / where q0 is the label of the ﬁrst instruction, and the strings ; ;  are the
initial values of the string variables X1, X2 and X3, respectively. The instructions
of the counter-machine C can be simulated by instructions of a string program
as shown in Fig. 2.3 where each statement is followed by a goto statement that
transitions to the next instruction.
Fig. 2.3 Simulation of instructions of a counter machine with string program instructions

18
2
String Manipulating Programs and Difﬁculty of Their Analysis
Note that although this transformation allows the simulated counter values to
possibly take negative values, this can be ﬁxed by adding a conditional branch
instruction before each decrement that checks that the simulated counter value is
not zero before the instructions simulating the decrement instruction is executed.
The string program P constructed from the counter machine M based on these rules
will simulate M. Hence, solving the halting problem for string programs would
mean that we can solve the halting problem for counter machines. Since halting
problem for counter machines is undecidable, we conclude that halting problem for
string programs is also undecidable. Since 2-counter machines can simulate Turing
Machines we also observe that string programs with only 3 string variables can
simulate Turing Machines.
This discussion demonstrates that automatically and precisely checking reach-
ability properties of string manipulating programs is not possible. Reachability
problem for string manipulating programs in undecidable, hence it cannot be
precisely solved like many other program analysis problems. However, it is possible
to check reachability properties of string manipulating programs approximately. For
example, it would be possible to develop automated and approximate techniques
that guarantee there are no assertion violations (i.e., that there a no bugs) for some
programs. However, such sound veriﬁcation techniques could sometimes report
false positives, i.e., report assertion violations although no execution of the program
may have assertion violations. Similarly, it would be possible to develop automated
and approximate techniques that guarantee that there are assertion violations in
some programs. However, such complete veriﬁcation techniques could sometimes
report false negatives, i.e., they may not ﬁnd an assertion violation even though in
some execution of the program there may be an assertion violation.
When a program analysis problem is undecidable, it means that there does
not exist a sound and complete technique to solve it. Since we showed that
reachability for string programs is an undecidable problem, we conclude that there
is no automated veriﬁcation technique for string programs that can report assertion
violations for all string programs that contain assertion violations, and that can
report the absence of assertion violations for all string programs that do not contain
assertion violations.
2.3
A Richer String Manipulation Language
We have seen that, even with 3 string variables and a small instruction set,
string programs can simulate Turing Machines. Adding more string operations
does not increase the expressiveness of string manipulating programs theoretically.
However, in practice, string analysis has to deal with many other string manipulation
operations in addition to string concatenation. In Fig. 2.4 we give the syntax for an
extended string manipulation language.
Let us brieﬂy describe the semantics of extended string operations below.
We assume that ˙ denotes the set of all characters (i.e., the alphabet) in our
string manipulation language, and ˙ denotes the set of all strings (including the

2.3
A Richer String Manipulation Language
19
Fig. 2.4 Grammar for an
extended string manipulation
language
empty string ). The operations “:”, “”, and “j” correspond to regular expression
operations concatenation, Kleene closure and alternation.
•
match.s; r/ means that string s matches the string expression r (which could
be a regular expression). Let L.r/ denote the set of strings (i.e., the language)
deﬁned by the string expression r, then we deﬁne the semantics of match as:
match.s; r/ , s 2 L.r/
•
contains.s; t/ means that string t is a substring of string s:
contains.s; t/ , 9s1; s2 2 ˙ W s D s1ts2
•
begins.s; t/ means that string s begins with string t:
begins.s; t/ , 9s1 2 ˙ W s D ts1

20
2
String Manipulating Programs and Difﬁculty of Their Analysis
•
ends.s; t/ means that string s ends with string t:
ends.s; t/ , 9s1 2 ˙ W s D s1t
•
length.s/ denotes the length of the string s (for empty string, length
./ D 0):
.length.s/ D 0 , s D / ^ .length.s/ D n , 9c1; c2; : : : ; cn 2 ˙ W s D c1c2 : : : cn/
We also use jsj to denote the length of string s, i.e., length.s/ D jsj.
•
indexof.s; t/ denotes the smallest starting location of substring t in string s. If
x is not a substring of s (i.e, :contains.s; t/) then indexof.s; t/ D 1.
.indexof.s; t/ D 1 , :contains.s; t// ^
.indexof.s; t/ D n
, .9s1; s2 2 ˙ W s D s1ts2 ^ js1j D n/
^.8i < n W :.9s1; s2 2 ˙ W s D s1ts2 ^ js1j D i///
•
replace.s; p; t/ replaces the pattern string p in s with the target string t and
returns the result.
r D replace.s; p; t/ , ..:contains.s; p/ ^ r D s/ _
.9s3; s4; s5 2 ˙ W s D s3ps4 ^ r D s3ts5 ^ s5 D replace.s4; p; t/ ^
.8s6; s7 2 ˙ W s D s6ps7 ) js6j  js3j///
Note that, this description of the replace function semantics assumes that
pattern string p is a string value. In general, p could be a regular expression and
more than one substring of the source string s can match the regular expression
p. In that case, the semantics has to specify which matching substring will be
chosen for replacement. Typically, the longest matching substring is chosen for
replacement.
•
substring.s; i; j/ returns the substring of string s that starts at index i
(inclusive) and ends at index j (exclusive).
t D substring.s; i; j/ , 9s1; s2 2 ˙ W s D s1ts2 ^ js1j D i ^ jtj D j  i
•
charat.s; i/ returns the character that appears at the index i of the string s. The
semantics of charat is deﬁned as follows:
t D charat.s; i/ , 9c0; c1; : : : ; cn 2 ˙ W s D c0c1 : : : cn ^ 0  i  n ^ t D ci
•
reverse.s/ returns the reverse of the string v.
t D reverse.s/ , 9c0; c1; : : : ; cn 2 ˙ W s D c0c1 : : : cn ^ t D cn : : : c1c0

2.3
A Richer String Manipulation Language
21
Fig. 2.5 A code snippet (a) written in PHP and the corresponding code snippet (b) in the string
manipulation language
It is possible to extend the string manipulation language deﬁned in Fig. 2.4 even
further by adding more variations of string operations we deﬁned. For example, the
replace operation we deﬁned replaces all occurrences of substrings that match
the pattern. A variant of the replace operation replaces only the ﬁrst appearance of
the substring that matches the given pattern. Yet another variant replaces only the
last appearance of the substring that matches the given pattern. As another example,
the indexof operation we deﬁned returns the index of the ﬁrst appearance of
the given substring. A variant of this operation is the last-index-of operation that
returns the index of the last appearance of the given substring. The techniques we
discuss in this monograph can be extended to handle such extensions, but to keep
our discussions concise we restrict our scope to the operations deﬁned in Fig. 2.4.
Semantics of string manipulating programs can be deﬁned based on the semantics
of string manipulation operations we gave above.
Consider the PHP program segment that we showed in Chap. 1, Fig. 1.5. We can
model this function using the string manipulation language we introduced as shown
in Fig. 2.5. Note that the lines that correspond to each other are labeled with the same
line number. Since we did not introduce a complex regular expression syntax in
our string manipulation language, we did not provide the translation for the regular
expression used in the line 4 of the PHP code snippet. However, it is possible to
translate this PHP regular expression to a simple regular expression by just taking
disjunction of all the characters that correspond to the PHP regular expression.
String analysis techniques developed for the string manipulation language we
introduced in this chapter can be adopted to string analysis problems in modern
programming languages by either extracting a string program from a given program
by identifying the string expressions, or by implementing the string analysis
techniques in a static analysis tool for the given programming language.

22
2
String Manipulating Programs and Difﬁculty of Their Analysis
2.4
Summary
In this chapter we ﬁrst presented a basic set of string manipulating instructions and
then provided a larger set of instructions with more complex string operations. We
discussed the difﬁculty of analyzing string manipulating programs. If we assume
that string variables can take arbitrarily large string values, then even with a basic
set of instructions, veriﬁcation of string manipulating programs is an undecidable
problem. Hence, veriﬁcation of string manipulating programs cannot be fully
automated and precise at the same time. In the following chapters we discuss
automated techniques that use approximations and abstractions for string analysis.

Chapter 3
State Space Exploration
Before we can discuss string analysis and veriﬁcation techniques for string
manipulating programs, we ﬁrst need to discuss the semantics of string manipulating
programs in more detail.
3.1
Semantics of String Manipulation Languages
Semantics of string manipulating programs we deﬁned in Chap. 2 can be formalized
as transitions systems. A transition system T D .I; S; R/ consists of a set of states S,
a set of initial states I  S and a transition relation R  S  S. Let us ﬁrst deﬁne the
set of states of a string manipulating program written either in the language shown
in Fig. 2.1 or the extended language shown in Fig. 2.4. Each program state will
correspond to a program location. If we assume that all statements are labeled
with unique labels, we can use the labels of the statements to denote the possible
program locations. Let us use L to denote the set of program locations (i.e., the set
of statement labels). Each string variable will have a value from the set ˙ and each
integer variable will have a value from the set Z. Let us assume that we are given
a program with n string and m integer variables. Then, the set of states of the given
program is deﬁned as:
S D L  .˙/n  .Z/m
Let us assume that l1 2 L denotes the label of the ﬁrst statement of the program.
Then we can deﬁne the set of initial states of the program as:
I D fhl1; ; : : : ; ; 0; : : : ; 0ig
© Springer International Publishing AG 2017
T. Bultan et al., String Analysis for Software Veriﬁcation and Security,
https://doi.org/10.1007/978-3-319-68670-7_3
23

24
3
State Space Exploration
where the program counter is initialized to l1, all string variables are initialized
to  (i.e., empty string) and all integer variables are initialized to 0. Since we are
assuming all the variables are initialized, and that there is a single initial statement,
the set of initial states is a singleton set. It would not be a singleton set if we assume
that the variables are not initialized and their initial values are not known.
The transition relation (R) of the program is deﬁned by the semantics of the
statements of the program. The semantics of the statements can be inferred from the
semantics of the string operations we deﬁned in Chap. 2.
Given a statement labeled l, let rl  S  S denote tuples of program states
.s1; s2/ 2 rl such that, s1 is a program state at the program location l, and executing
statement l in program state s1 results in the program state s2. So, rl denotes the
transition relation of the statement l. Then the transition relation of the whole
program can be deﬁned as:
R D
[
l2L
rl
i.e., taking the union of all the transitions deﬁned by each statement of the program
gives us the transition relation of the whole program.
Note that, the transition relation of a string manipulating program can be an
inﬁnite state system if we do not put a bound on the lengths of the strings. The
undecidability of the reachability problem for string programs that we discussed in
Chap. 2 is due to unboundedness of the string variables. In our formal model for
string manipulating programs, each string variable has an inﬁnite set of possible
values (which is the set ˙), and hence, set of states of a string manipulating
program is inﬁnite.
Since no computer has an inﬁnite amount of memory, bounding all the domains is
a practical approach to program analysis and veriﬁcation. However, when a program
is analyzed or veriﬁed based on a given bound, obtained results are not guaranteed
to hold when the program execution exceeds that bound. So, assuming an inﬁnite
state space is a useful assumption if one wants to check a program’s behavior for
arbitrarily large state spaces.
Let us consider the string program example shown in Fig. 3.1. This program has
three string variables x, y and z. The initial state of this program is: hl; x; y; zi D
h1; ; ; i which means that initially program counter is 1, and string variables x,
y, z are initialized to the empty string .
The transition relation of the program is deﬁned as the union of the transition
relations of its instructions:
R D r1 [ r2 [ r3
Fig. 3.1 A simple string
manipulating program with
three string variables

3.1
Semantics of String Manipulation Languages
25
Fig. 3.2 A string
manipulating program that
copies a read string value
character by character
and
r1 D f.h1; ; ; i; h2; ab; ; i/g
r2 D f.h2; ab; ; i; h3; ab; cd; i/g
r3 D f.h3; ab; cd; i; h4; ab; cd; abcdi/g
where we assume that 4 is an implicit halt instruction.
Let us consider the string program example shown in Fig. 3.2. This program
reads a string value to the variable x and then it copies the value of string variable
x to string variable y one character at a time. The initial state of this program
is hl; x; y; ii D h1; ; ; 0i which means that initially program counter is 1, string
variables x and y are initialized to the empty string , and the integer variable i is
initialized to 0.
The transition relation of the program is deﬁned as the union of the transition
relations of its instructions:
R D r1 [ r2 [ r3 [ r4 [ r5
We assume that a read instruction can read any possible string value. So, the
transition relation for the instruction 1, r1 consists of an inﬁnite set of transitions,
where for each s 2 ˙:
.h1; ; ; 0i; h2; s; ; 0i/ 2 r1
Let us consider a state h2; ab; ; 0i where the value read to variable x is the string
“ab”. Following transitions are in the transition relation of this string program:
.h2; ab; ; 0i; h3; ab; ; 0i/ 2 r2
.h3; ab; ; 0i; h4; ab; a; 0i/ 2 r3
.h4; ab; a; 0i; h2; ab; a; 1i/ 2 r4
.h2; ab; a; 1i; h3; ab; a; 1i/ 2 r2
.h3; ab; a; 1i; h4; ab; ab; 1i/ 2 r3
.h4; ab; ab; 1i; h2; ab; ab; 2i/ 2 r4
.h2; ab; ab; 2i; h5; ab; ab; 2i/ 2 r2
where we assume that label 5 corresponds to the termination of the loop.

26
3
State Space Exploration
3.2
Explicit State Space Exploration
When the semantics of a program is deﬁned as a transition system .S; I; R/, assertion
checking corresponds to checking reachability in this transition system.
Let us consider the statements of the program. Each statement l has correspond-
ing transition relation rl. Using rl we can also deﬁne a POST W S ! S function as
follows:
s2 D POST.s1; l/ , .s1; s2/ 2 rl
POST.s1; l/ denotes the state that the program can go by executing statement l at
program state s1. Note that, in the above deﬁnition, we are assuming that the
transition system is deterministic, i.e., each state has at most one state that can be
reached from it after one step of execution. We can generalize to nondeterministic
systems if we allow POST function to return a set of states rather than a single state
(as we discuss in the next section).
We can also deﬁne the POST function for the overall program as follows:
s2 D POST.s1/ , 9l 2 L W s2 D POST.s1; rl/
s2 D POST.s1/ , .s1; s2/ 2 R
We can think of the POST function as computing the post-condition (or post-image)
of a given state.
For the string program example shown in Fig. 3.1, we have the following:
POST.h1; ; ; i; 1/
D POST.h1; ; ; i/
D h2; ab; ; i
POST.h2; ab; ; i; 2/ D POST.h2; ab; ; i/ D h3; ab; cd; i
POST.h3; ab; cd; i; 3/ D POST.h3; ab; cd; i/ D h4; ab; cd; abcdi
Similarly, for the string program example shown in Fig. 3.2, we have the
following:
POST.h2; ab; ; 0i/
D h3; ab; ; 0i
POST.h3; ab; ; 0i/
D h4; ab; a; 0i
POST.h4; ab; a; 0i/
D h2; ab; a; 1i
POST.h2; ab; a; 1i/
D h3; ab; a; 1i
POST.h3; ab; a; 1i/
D h4; ab; ab; 1i
POST.h4; ab; ab; 1i/ D h2; ab; ab; 2i
POST.h2; ab; ab; 2i/ D h5; ab; ab; 2i

3.2
Explicit State Space Exploration
27
Algorithm 1 REACHABILITYDFS
1: Stack := I;
2: RS := I;
3: while Stack ¤ ; do
4:
s := POP(Stack);
5:
s0 := POST.s/;
6:
if s0 62 RS then
7:
RS := RS[fs0g;
8:
PUSH(Stack, s0);
9:
end if
10: end while
11: return RS;
3.2.1
Forward Reachability
Let RS.I/, or simply RS, denote the set of states that are reachable from the initial
states I of a program, i.e.,
RS D fs j 9s0; s1; : : : ; sn W 8i < n W .si; siC1/ 2 R ^ s0 2 I ^ sn D sg
Using the POST function we can write a simple depth ﬁrst search algorithm for
computing reachable states of a program as shown in Algorithm 1.
For the string program example shown in Fig. 3.1, the set of reachable states RS
can be computed using the algorithm shown in Algorithm 1, and the result would be:
RS D fh1; ; ; i; h2; ab; ; i; h3; ab; cd; i; h4; ab; cd; abcdi/g
For the program shown in Fig. 3.2, the reachable states can be characterized as
follows:
hl; s1; s2; ii 2 RS ,
l D 1 ^ s1 D  ^ s2 D  ^ i D 0
_ l D 2 ^ s1; s3 2 ˙ ^ s1 D s2:s3 ^ i D length.s2/
_ l D 3 ^ s1; s3 2 ˙ ^ s1 D s2:s3 ^ i D length.s2/
_ l D 4 ^ s1; s3 2 ˙ ^ s1 D s2:s3 ^ i D length.s2/  1
_ l D 5 ^ s1 2 ˙ ^ s1 D s2 ^ i D length.s2/
The set of states S and the set of reachable states RS for the program shown in
Fig. 3.2 are inﬁnite. For inﬁnite states spaces, the explicit state exploration approach
shown in Algorithm 1 would not terminate, so we need to ﬁnd a different approach.
However, before we address this issue, let us consider backward reachability
problem.

28
3
State Space Exploration
3.2.2
Backward Reachability
Similar to the POST function we can also deﬁne a PRE function for backward
reachability. Even for deterministic systems one state can have multiple states that
can reach it in one step, so we need to deﬁne the PRE W S ! 2S function as follows:
s2 2 PRE.s1; l/ , .s2; s1/ 2 rl
s2 2 PRE.s1/
, 9l 2 L W s2 2 PRE.s1; rl/
s2 2 PRE.s1/
, .s2; s1/ 2 R
We can think of the PRE function as computing the pre-condition (or pre-image) of
a state.
For the string program example shown in Fig. 3.1, we have the following:
PRE.h2; ab; ; i/
D fh1; ; ; ig
PRE.h3; ab; cd; i/
D fh2; ab; ; ig
PRE.h4; ab; cd; abcdi/ D fh3; ab; cd; ig
We can ﬁnd all states that can reach a particular target state using a depth ﬁrst
search algorithm similar to the one shown in Algorithm 1 that starts from the target
state and uses the PRE function to compute backward reachability as shown in
Algorithm 2.
Using the Algorithm 2 we can compute the backward reachability set for a given
set of states. For the string program example shown in Fig. 3.1, we can compute the
following sets:
BRS.h3; ab; cd; i/
D fh1; ; ; i; h2; ab; ; ig
BRS.h4; ab; cd; abcdi/ D fh1; ; ; i; h2; ab; ; i; h3; ab; cd; ig
Algorithm 2 BACKWARDREACHABILITYDFS(P)
1: Stack := P;
2: BRS := P;
3: while Stack ¤ ; do
4:
s := POP(Stack);
5:
for s0 2 PRE.s/ do
6:
if s0 62 BRS then
7:
BRS := BRS[fs0g;
8:
PUSH(Stack, s0);
9:
end if
10:
end for
11: end while
12: return BRS;

3.3
Symbolic Exploration
29
Since assertion veriﬁcation can be reduced to reachability checks as we discussed
earlier, we can use the reachability algorithm above for verifying assertions. This
approach is called explicit state veriﬁcation since states of the transition system are
visited individually. One of the problems with this approach is, for large state spaces,
exploring state space one state at a time is computationally very expensive. In fact,
as we observed, for string manipulating programs, the state space is inﬁnite since we
allow strings of arbitrary length. For inﬁnite state systems explicit state veriﬁcation
cannot be used to prove absence of errors, but it can be used to prove existence of
errors (since a trace that is discovered by explicit state enumeration that leads to an
error state proves the existence of an error).
Explicit state veriﬁcation can be used to guarantee absence of errors in ﬁnite
state systems. For example, if we bound the variable domains in string programs
we can use explicit state veriﬁcation to explore the whole state space. However,
there is another problem. Although depth ﬁrst search algorithm explores the state
space in linear time with respect to the size of the transition system (where the size
of the transition system T D .S; I; R/ is jSj C jTj), the size of the transition system
is exponential in the number of variables in the input program. The exponential
growth of the state space of programs is called the state space explosion problem,
and it limits the scalability of explicit state veriﬁcation techniques for ﬁnite state
systems.
3.3
Symbolic Exploration
As an alternative to explicit state enumeration we can consider exploring the state
space using sets of states. Rather than exploring one state at a time, we will consider
exploring sets of states. In order to do this, we need to ﬁrst generalize the deﬁnition
of pre and post-condition functions to sets of states as follows: PRE W 2S ! 2S; POST W
2S ! 2S; where
POST.P; l/ D fs j 9s0 2 P W .s0; s/ 2 rlg
POST.P/
D fs j 9s0 2 P W .s0; s/ 2 Rg
PRE.P; l/ D fs j 9s0 2 P W .s; s0/ 2 rlg
PRE.P/
D fs j 9s0 2 P W .s; s0/ 2 Rg
We refer to POST and PRE as post-condition (or post-image) or pre-condition (or pre-
image) functions.
For example, for the string program example shown in Fig. 3.1, we have the
following:
POST.fh1; ; ; ig/
D fh2; ab; ; ig
POST.fh2; ab; ; ig/
D fh3; ab; cd; ig
POST.fh1; ; ; i; h2; ab; ; ig D fh2; ab; ; i; h3; ab; cd; ig

30
3
State Space Exploration
The set of states can be inﬁnite and using the set notation we can deﬁne the post-
condition of an inﬁnite set of states. For example, for the string program example
shown in Fig. 3.2, we have the following:
POST.fs j s D h3; x; ; 0ig/
D fs0 j s0 D h4; x; charat.x; 0/; 0ig
POST.fs j s D h3; x; y; iig/
D fs0 j s0 D h4; x; y:charat.x; i/; iig
POST.fs j s D h4; x; y; length.y/  1ig/ D fs0 j s0 D h4; x; y; length.y/ig
3.3.1
Symbolic Reachability
In order to explain forward and backward reachability computations on sets of
states, we ﬁrst deﬁne the lattice formed by the sets of states of the transition system.
Symbolic reachability algorithms deal with sets of states rather than individual
states. By processing multiple states at the same time, symbolic techniques can
converge to an answer with fewer iterations. For example, for the forward reach-
ability analysis, if we want to compute the set of states reachable from the set of
initial states, we can ﬁrst start with the initial states I. Then we can add all the
states reachable from initial states and continue adding new states until there is
nothing new to add. This is exactly what the depth-ﬁrst-traversal algorithm shown in
Algorithm 1 does, but it does the traversal one state at a time. Symbolic reachability
algorithms compute post-condition of a set of states in each iteration instead of
computing post-condition of one state at a time. With an appropriate symbolic
representation, symbolic algorithms can compute the post-condition of an inﬁnite
set of states in a single iteration.
The sets of states of a transition system form a partial order with respect to the
set inclusion (i.e., ). The progress in reachability computations can be expressed
with respect to this partial order. For the forward reachability computation, we start
with I, and if we are using a symbolic representation, in the next iteration we would
compute I [ POST.I/. Note that I  I [ POST.I/. We started with reachable states
I and we made some progress by computing a potentially larger set of states in the
next iteration. The goal of a forward symbolic reachability algorithm for computing
reachable states would be to compute a larger set of states (with respect to the partial
order) in each iteration and hopefully converge on the set of reachable states RS after
a number of iterations.
These concepts about forward and backward reachability computations can be
formalized by deﬁning a lattice formed by the sets of states of the transition system.
Given a transition system T D .S; I; R/, the power set of S, 2S forms a complete
lattice .2S; S; ;; ; [; \/, with the top element > D S, the bottom element ? D ;,
intersection \ as the meet (greatest lower bound) operator, union [ as the join (least
upper bound) operator, and the set containment  as the partial order. Then, PRE and
POST are functions that map elements of this lattice (sets of states) to the elements
of this lattice (sets of states).

3.3
Symbolic Exploration
31
Let us consider the string program example shown in Fig. 3.1. Here are some of
the set of states for this program:
I
D fh1; ; ; ig
POST.I/
D fh2; ab; ; ig
I [ POST.I/
D fh1; ; ; i; h2; ab; ; ig
POST.I [ POST.I//
D fh2; ab; ; i; h3; ab; cd; ig
I [ POST.I [ POST.I//
D fh1; ; ; i; h2; ab; ; i; h3; ab; cd; ig
POST.I [ POST.I [ POST.I///
D fh2; ab; ; i; h3; ab; cd; ig
I [ POST.I [ POST.I [ POST.I/// D fh1; ; ; i; h2; ab; ; i; h3; ab; cd; ig
and here is how these sets are related in terms of the partial order :
I  I [ POST.I/  I [ POST.I [ POST.I//  I [ POST.I [ POST.I [ POST.I///
Moreover, we can observe the following:
RS D I [ POST.I [ POST.I//
RS D I [ POST.RS/
We see that the set of reachable states RS is the limit of the sequence of states
we have been computing using the POST function. RS is greater than or equal to any
element in the sequence, and, once we reach RS, the sequence stops increasing with
respect to the partial order. We can explain these phenomena using the concept of
ﬁxpoints.
3.3.2
Fixpoints
Given a function F W 2S ! 2S, let F P denote the application of function F to set
P  S.
Given a function F, x is called a ﬁxpoint of the function if
Fx D x
Interestingly, as we show below, reachability properties can be expressed as
ﬁxpoints [136].
We use the lambda calculus notation for functions. A function with argument x
is written in lambda calculus as follows: x : F x
Consider the following function:
x : I [ POST.x/

32
3
State Space Exploration
The set of reachable states RS is a ﬁxpoint of this function, i.e.,
RS D I [ POST.RS/
We can see this as follows: First, RS  I [ POST.RS/ since I  RS, and any state
reachable from a reachable state should be reachable itself, i.e., POST.RS/  RS.
Next, we need to show that RS  I [ POST.RS/. According to the deﬁnition of RS,
the only way a state s can be in RS is, either 1) s 2 I, or 2) there exists a state in RS
that can reach s, which implies that RS  I [ POST.RS/.
Next, we are going to show that RS is in fact the least ﬁxpoint of this function.
I.e., RS is the smallest ﬁxpoint of the function x : I [ POST.x/ with respect to the
partial order .
Let x : F x denote the least ﬁxpoint of F, i.e., the smallest x such that F x D x.
Then, we claim that:
RS D x : I [ POST.x/
Note that, since RS is a ﬁxpoint of the function x : I [ POST.x/, and since x : I [
POST.x/ is the least ﬁxpoint of the function x : I[POST.x/ we conclude that x : I[
POST.x/  RS.
Next, we need to prove that RS  x : I[POST.x/ to complete the proof. Suppose
z is a ﬁxpoint of x : I [ POST.x/. Then we know that z D I [ POST.z/, which means
that POST.z/  z. So, all states that are reachable from z are in z. Since we also have
I  z, any path that is reachable from I must also be in z, which means that RS  z.
Since we showed that RS is contained in any ﬁxpoint of the function x : I [
POST.x/, it should also be contained in its least ﬁxpoint, since the least ﬁxpoint itself
is a ﬁxpoint. So we conclude that RS  x : I [ POST.x/ which concludes the proof.
Now, we discuss how to compute the least ﬁxpoint. We call a function F
monotonic, if p  q implies F p  F q. We have the following property from
the lattice theory [102]:
Let F W 2S ! 2S be a monotonic function. Then F always has a least ﬁxpoint,
which is deﬁned as
x : F x 	
\
f x j F x  x g
Since x : F x is the least ﬁxpoint of the function F, it is the intersection (greatest
lower bound) of all the ﬁxpoints of F. In fact, it is the intersection of all the ﬁxpoints
of F, i.e., it is the intersection of all the sets x where F x  x. This property is valid
even when S (hence the lattice) is inﬁnite.
Given a function F, Fi x is deﬁned as:
Fi x is deﬁned as F .F : : : .F
„
ƒ‚
…
i times
x//:

3.3
Symbolic Exploration
33
We deﬁne F0 as the identity relation. Then, we have the following property [102]:
Given a monotonic function F W 2S ! 2S, for all n,
x : F x 
n[
iD0
Fi ;
This property holds even when the lattice is inﬁnite.
Assume that we generate a sequence of approximations to the least
ﬁxpoint x : F x of a monotonic function F by generating the following sequence:
;; F ;; F2 ;; : : : ; Fi ;; : : :
This sequence is monotonically increasing since ; corresponds to the bottom
element of the lattice, and the function F is monotonic. If this sequence converges
to a ﬁxpoint, i.e., if we ﬁnd an i where Fi ; 	 FiC1 ;, then from the property
above, we know that it is the least ﬁxpoint, i.e., it is equal to x : F x.
Similarly, a monotonically decreasing sequence of approximations could be
generated to compute the greatest ﬁxpoint of a function [136]. In this monograph
we are focusing on least ﬁxpoints. Because of the duality between the least and the
greatest ﬁxpoints, the techniques described here can also be applied to computation
of greatest ﬁxpoint.
As an example for computing least ﬁxpoints, consider the computation of the
least ﬁxpoint for reachable states: RS D x : I [ POST.x/. We can compute this least
ﬁxpoint by generating the following sequence:
; _ I
„ƒ‚…
F ;
_ POST.I/
„
ƒ‚
…
F2 ;
_ POST .POST.I//
„
ƒ‚
…
F3 ;
_ POST .POST .POST.I/// _ : : :
When this sequence converges to a ﬁxpoint, the result will be equal to RS. This is
exactly the sequence we computed for the string program example shown in Fig. 3.1
above.
In Algorithm 3 we give the ﬁxpoint computation algorithm for the reachable
states based on this iterative approach. Note that this ﬁxpoint computation is
closely related to the state space exploration algorithm given in Algorithm 1. Both
algorithms ﬁrst add the initial states to the reachable states and then keep adding
states that are reachable from the initial states to the reachable states. They both stop
when there is no more state left to add (i.e., when exploration reaches a ﬁxpoint).
The ﬁxpoint computation algorithm traverses the state space in breadth-ﬁrst order
instead of the depth-ﬁrst traversal order used in Algorithm 1. Also the ﬁxpoint
exploration algorithm processes a set of states at each iteration whereas the explicit
state exploration algorithm processes a single state at each iteration.

34
3
State Space Exploration
Algorithm 3 REACHABILITYFIXPOINT
1: RS := I;
2: repeat
3:
RS0 := RS;
4:
RS := RS[POST.RS/;
5: until RS D RS0
6: return RS;
Algorithm 4 BACKWARDREACHABILITYFIXPOINT(P)
1: BRS := P;
2: repeat
3:
BRS0 := BRS;
4:
BRS := BRS[PRE.BRS/;
5: until BRS D BRS0
6: return BRS;
We can also compute backward reachability similarly using the PRE function as
shown in Algorithm 4.
In order to implement the ﬁxpoint computation algorithms we need a way to
represent the sets of states. In general this representation should support tests for
equivalence, emptiness, and membership, and meet (intersection) and join (union)
operations. If the state space is ﬁnite, explicit state enumeration would be one
such representation. Note that as the state spaces of the programs grow, explicit
state enumeration will become more expensive since the size of this representation
is linearly related to the number of states in the set it represents. Unfortunately,
as we discussed above, the state spaces of programs increase exponentially with
the number of variables. This state space explosion problem makes a naive
implementation of the explicit state enumeration infeasible. Moreover, as we have
seen for string programs, if we want to represent all possible string values during
reachability analysis, then the number of states becomes inﬁnite and an explicit state
representation becomes impossible.
The symbolic reachability analysis techniques use a symbolic representation for
encoding sets of states. Symbolic representations are mathematical objects (such
as formulas in some logic) with semantics corresponding to sets of states. We can
use such representations in encoding the sets of program states. Using a symbolic
representation we can implement the iterative ﬁxpoint computation algorithm and
compute the reachable states. As we discuss in the next chapter, in this monograph
we mainly focus on use of automata as a symbolic representation for sets of states
of string programs.

3.4
Summary
35
3.4
Summary
In this chapter we provided a basic survey of reachability analysis for veriﬁcation of
string manipulating programs starting with explicit state enumeration. We discussed
both forward and backward reachability analysis using depth-ﬁrst search where
states of a given string manipulating program are traversed one state at a time. Next,
we discussed symbolic reachability analysis, where the basic idea is to perform
state exploration using sets of states rather than traversing states one by one. We
discussed that reachability analysis corresponds to ﬁxpoint computations, and, in
order to develop a symbolic analysis framework for string manipulating programs,
we need to ﬁrst develop a symbolic representation that can represent sets of strings.
We discuss a symbolic representation for sets of strings in the next chapter.

Chapter 4
Automata Based String Analysis
In this chapter, we discuss using automata as a symbolic representation for string
analysis. To compute forward and backward reachability for string manipulating
programs, we can use automata-based symbolic string analysis where automata are
used as a symbolic representation to represents sets of states of the program. We can
iteratively compute an approximation of the least ﬁxpoint that corresponds to the
reachable values of the string expressions. Assume that we use one Deterministic
Finite Automaton (DFA) per string variable, per program point. i.e., each DFA
represents the set of values that a string variable can take at a particular program
point. In each iteration, given the current state DFA for a variable, we can compute
the pre- and post-state DFA. In order to implement this approach we have to
develop automata based algorithms for computing pre- and post-state computation
for common string operations such as concatenation, and replacement as we discuss
later in this chapter.
4.1
A Lattice for Sets of Strings
Given an automaton A, let L.A/ denote the set of values accepted by A. We focus
on minimized, deterministic ﬁnite automata (DFA) and deﬁne the following partial
order on automata: A1 v A2 if and only if L.A1/  L.A2/. Given two automata A1
and A2, we deﬁne A1 t A2 as an automaton such that L.A1 t A2/ D L.A1/ [ L.A2/,
and we deﬁne A1 u A2 as an automaton such that L.A1 u A2/ D L.A1/ \ L.A2/.
Given a regular expression r, we use A.r/ to denote an automaton that accepts
the set of strings that match the regular expression r. Similarly, given a set of strings
P  ˙, we use A.P/ to denote an automaton where L.A.P// D P. For example, the
automaton A.˙/ is an automaton that accepts every string, i.e., L.A.˙// D ˙,
and A.;/ is an automaton which does not accept any strings, i.e., L.A.;// D ;.
© Springer International Publishing AG 2017
T. Bultan et al., String Analysis for Software Veriﬁcation and Security,
https://doi.org/10.1007/978-3-319-68670-7_4
37

38
4
Automata Based String Analysis
All the operators we deﬁned above can be implemented using standard
construction algorithms from automata theory.
Using the partial order v we can deﬁne an automata lattice with the join (least
upper bound) operator t, the meet (greatest lower bound) operator u, the bottom
element ? D A.;/ and top element > D A.˙/. Note that the automata lattice
is an inﬁnite lattice and has inﬁnite chains such as ˙ D fag, A.;/ v A.fg/ v
A.f; ag/ v A.f; a; aag/ v A.f; a; aa; aaag/ 
 
 
 v A.a/. Hence, ﬁxpoint
computations during symbolic reachability analysis are not guaranteed to converge
when we use automata as a symbolic representation.
One approach for achieving convergence during ﬁxpoint computations on lat-
tices with inﬁnite chains, is to use a widening operator r to compute an over-
approximation of the least ﬁxpoint. The widening operator r over-approximates
the join operator, and it guarantees convergence. i.e., given two automata A1 and
A2, A1 t A2 v A1rA2, and the iterative least ﬁxpoint computations are guaranteed
to converge if we apply the widening operator at each iteration. After discussing
symbolic analysis with automata as a symbolic representation, in the following
chapters we discuss use of abstraction and approximation techniques, such as the
widening operator, in order to achieve convergence.
4.2
Symbolic Reachability Analysis with Automata
In the following discussion we represent each program with a set of labels L, where
each statement is marked with a unique label, and a set of ﬂow edges F  L  L
that denote the control ﬂow among the statements of the program. Let V denote the
set of string variables in the program, and let l1 2 L denote the ﬁrst statement of the
program.
We use an automata matrix of size jLjjVj to represent the states of the program.
Given a program location l and a variable v, and the automata matrix EA, the set
of strings accepted by automaton EAŒl; v, i.e., L.EAŒl; v/ denotes the set of values
that variable v can take at program location l. Given a jLj  jVj automata matrix
EA, EAŒl denotes the automata vector of size jVj that corresponds to the l’th row of
the automata matrix, which represents the set of values that variables can take at
program location l.
We can lift the partial order we deﬁned above for automata to automata vectors
as follows: EA1 v EA2 if and only if 8v W L. EA1Œv/  L. EA2Œv/. Again we can also
lift join, meet and widening operators to vectors of automata as follows:
8v W . EA1 t EA2/Œv D A1Œv t A2Œv;
8v W . EA1 u EA2/Œv D A1Œv u A2Œv;
8v W . EA1r EA2/Œv D A1ŒvrA2Œv:

4.2
Symbolic Reachability Analysis with Automata
39
Algorithm 1 FORWARDANALYSIS(L; F; V)
1: I WD fl j 8l0:.l0; l/ 62 Fg;
2: for l 2 L n I; v 2 V do
3:
EAŒl; v D A.;/;
4: end for
5: for l 2 I; v 2 V do
6:
EAŒl; v D Ainit.v/;
7: end for
8: queue WQ WD NULL;
9: WQ.enqueue(l1);
10: while WQ ¤ NULL do
11:
l WD WQ.dequeue();
12:
for .l; l0/ 2 F do
13:
if POST.EAŒl; .l; l0// 6v L.EAŒl0) then
14:
EA.l0/ D EA.l0/r.EA.l0/ t POST.EA.l/; l//;
15:
WQ.enqueue(l0);
16:
end if
17:
end for
18: end while
Hence, this deﬁnes a lattice for automata vectors with the bottom element
? D EA.;/; where 8v W EA.;/Œv D A.;/
and the top element
> D EA.˙/; where 8lv W EA.˙/Œv D A.˙/
Algorithm 1 computes the least ﬁxpoint that over-approximates the possible
values that string variables can take at any given program point [127, 129]. It is a
symbolic reachability computation that uses automata as a symbolic representation.
The algorithm ﬁrst deﬁnes the initial set I that corresponds to the set of labels
without incoming edges in F. These labels correspond to values that can be
initialized from the start such as user inputs (which can be assumed to take any
possible value) and constant strings. For labels in I, we assume that the algorithm
initializes the corresponding automata vectors according to the type of the statement
and the variables involved in the statement. For labels that are not in I, the algorithm
initializes the automata in each corresponding automata vector to A.;/ which is the
automaton that accepts no strings. i.e., initially we are assuming that no string value
is reachable. Then, the algorithm iteratively propagates the reachable string values
starting with the initial statements.
This algorithm is a worklist algorithm that stores statements to be processed in
a worklist, which is implemented as a queue. First, we put the ﬁrst statement l1
to the worklist. At each iteration one statement is removed from the worklist, its
post-condition is computed, and all successor statements are updated accordingly.
When the set of strings reachable at a successor statement changes due to the

40
4
Automata Based String Analysis
Algorithm 2 BACKWARDANALYSIS(L; F; V)
1: T WD fl j 8l0:.l; l0/ 62 Fg;
2: for l 2 L n T; v 2 V do
3:
EAŒl; v D A.;/;
4: end for
5: for l 2 T; v 2 V do
6:
EAŒl; v D Ainit.v/;
7: end for
8: queue WQ WD NULL;
9: WQ.enqueue(lt);
10: while doWQ ¤ NULL
11:
l WD WQ.dequeue();
12:
for .l; l0/ 2 F do
13:
if PRE.EAŒl; .l; l0// 6v L.EAŒl0) then
14:
EA.l0/ D EA.l0/r.EA.l0/ t PRE.EA.l/; l//;
15:
WQ.enqueue(l0);
16:
end if
17:
end for
18: end while
post-condition computation, then that successor statement is added to the worklist.
This continues until reachable string values stop changing, and, hence, the worklist
becomes empty. Note that, in order to guarantee convergence the algorithm uses the
widening operator r.
Similar to the forward analysis, one can deﬁne the backward analysis to compute
all potential input values that lead to the results at any given program point.
Algorithm 2 computes the least ﬁxpoint that over-approximates the possible
values that string variables can take that would lead to the results speciﬁed in the
target label lt [126, 128]. The terminal set T is deﬁned as the set of terminal labels
in F. These labels correspond to the automata matrix elements that can be initialized
as arguments for pre-condition computations. For example, these automata can be
computed via forward analysis to accept all reachable strings for the given program
point [126, 128].
This backward analysis algorithm is also a worklist algorithm that stores state-
ments to be processed in a worklist, which is implemented as a queue. First, we put
the target statement (lt) to the worklist. At each iteration one statement is removed
from the worklist, its pre-condition is computed, and predecessor statements are
updated accordingly. When the set of strings reachable at a predecessor statement
changes due to the pre-condition computation, then that predecessor statement is
added to the worklist. This continues until reachable string values stop changing,
and, hence, the worklist becomes empty. The algorithm also adopts the widening
operator r to guarantee convergence.
In order to implement the Algorithms 1 and 2 we need to implement (1) a data
structure for the automata that supports the join and widening operations, (2) can be
used to check the partial order among the automata, and (3) supports post-condition
and pre-condition operations. We discuss these below.

4.3
Symbolic Automata Representation
41
4.3
Symbolic Automata Representation
In order to reduce the memory usage during reachability analysis, we can use a
symbolic DFA representation. The basic idea is to represent the transition relation
of the automata symbolically using Multi Terminal Binary Decision Diagrams
(MTBDDs) [41]. In order to do this, we ﬁrst have to use a binary encoding of the
set of characters that can appear in a string, i.e., the alphabet ˙.
Given B D f0; 1g, a symbolic DFA A is a tuple hQ; q0; ˙B; ı; Fi where:
•
Q is a ﬁnite set of states.
•
q0 is the initial state.
•
Instead of using a regular alphabet ˙, where each character c is a single ASCII
printable symbol such as a and b, we use a symbolic binary alphabet ˙B  Bk
where k D log2.d j˙j e/ and each alphabet symbol ˛ is a k-bit string ˛ 2 Bk.
In our discussion in this section, we use character to refer to a non-symbolic
alphabet character c 2 ˙ and we use alphabet symbol to refer to a symbolic
alphabet symbol ˛ 2 ˙B. Each character c 2 ˙ is mapped to one and only one
corresponding alphabet symbol ˛c 2 ˙B and vice versa.
•
F  Q is ﬁnite set of accepting states.
•
ı W Q  ˙B ! Q is the transition relation.
Following our deﬁnition of ˙ and ˙B, we deﬁne a non-symbolic string w of length
n as a sequence of characters hc0; c1; : : : ; cn1i where each character ci 2 ˙
and its corresponding symbolic string wB as a sequence of alphabet symbols
h˛0; ˛1; : : : ; ˛n1i where each alphabet symbol ˛i 2 ˙B.
Let us deﬁne the relation ı W Q  ˙
B ! Q for the symbolic DFA A as follows:
ı.qi; / D qi, and given a string wB D h˛0; ˛1; : : : ; ˛n1i where each character
˛i 2 ˙B, ı.qi; wB/ D qj if there exists a sequence hqi; qiC1; qiC2; : : : ; qiCni 2
QnC1 such that: (1) qiCn D qj and (2) 80  l < n W ı.qiCl; ˛l/ D qiClC1.
A state q of A is a sink state if 8˛ 2 ˙B; ı.q; ˛/ D q and q … F. In the following
discussion, we assume that for all unspeciﬁed pairs .q; ˛/, ı.q; ˛/ goes to a sink
state. When visualizing a DFA we omit the sink state and the transitions that lead
to a sink state. We say that a string wB is accepted by A if ı.q0; wB/ 2 F. The
language of A or L.A/  ˙
B is the set of strings wB that are accepted by A. For
two states qi and qj in A, a transition between qi and qj on an alphabet symbol ˛ is
a tuple .qi; ˛; qj/ where ı.qi; ˛/ D qj and we write it like this .qi
˛! qj/. For two
states qi and qj in A, we say there is a path qi; qiC1; : : : ; qj of length n between qi and
qj if there is a string wB 2 ˙
B of length n such that ı.qi; wB/ D qj and we write it
like this .qi
wB
!

qj/.

42
4
Automata Based String Analysis
Fig. 4.1 Symbolic
representation of a DFA using
MTBDD
Example
Figure 4.1 shows an example symbolic DFA. At the top is the explicit DFA using an
explicit representation that uses character ranges. In the middle is the symbolic DFA
that uses binary alphabet symbols. In the bottom is the actual internal representation
using a Multi-terminal Binary Decision Diagram (MTBDD). The alphabet ˙ and
the corresponding symbolic alphabet ˙B is shown in Fig. 4.2. We have 16 characters
in ˙ which means that we need log2.d16e/ D 4 bits for the symbolic alphabet (i.e.,

4.3
Symbolic Automata Representation
43
Fig. 4.2 ˙ and corresponding ˙B for the sample symbolic DFA along with symbolic transition
labels and their corresponding explicit transitions
˙B  B4). Figure 4.2 shows each character c 2 ˙ and its corresponding alphabet
symbol ˛c 2 ˙B. For example, ˛a D 0000 and ˛l D 1011.
The sample DFA in Fig. 4.1 has four states Q D fS0; S1; S2; S3g. Our convention
is to label each state with a number n and refer to it in the text with Sn. The shaded
state S1 is the sink state and dashed edges represent transitions that go to sink state.
From now on we always omit sink states to simplify the ﬁgures (shaded states and
dashed edges will be used for other purposes). In the sample symbolic DFA in
the middle, we use symbolic labels such as
0
X
1
X
where the X symbol indicates that
the value could be 0 or 1. For example, from state S0 ! S2, an edge labeled
0
X
1
X
means that there are four transitions between these two states on alphabet symbols
0010; 0011; 0110 and 0111 (i.e., four transitions on characters c; d; g; h). Figure 4.2
shows each of the symbolic labels used in sample symbolic DFA and their meanings.
4.3.1
MTBDD Representation
Figure 4.1 shows at the bottom the Multi-terminal Binary Decision Diagram [41]
that is used as the actual internal representation of the sample symbolic DFA. The
second row in table at the top 0 1 2 3 represents DFA states while the ﬁrst
row in that table 1 1 1 1 represents state types which are either accepting
state 1 or rejecting state 1. The shaded nodes represent BDD nodes. Each circle-
shaped node has a number n that represents its level i.e., which BDD variable n
(in other words, which bit n in an alphabet symbol ˛ 2 ˙B) it corresponds to. Each
rectangle-shaped node has a number n that represents the destination state Sn that
the node corresponds to. Dashed line represents a BDD variable (bit) value of 0
while a regular line represents a BDD variable (bit) value of 1.
The symbolic transition relation works as follows: Suppose that we are in state
S0 and given alphabet symbol ˛c D 0010. Let us see how we go from state S0 to
state S2 on character c. We start from table cell 0 then go to a BDD node at level 0.
Then, looking at value of bit-0 of ˛c which is 0, we go to a BDD node at level 2.

44
4
Automata Based String Analysis
Notice that since we are in a BDD node at level 2, we will look at second BDD
variable (i.e., bit-2) skipping value of bit-1 as it does not affect which destination
state we will go to. Then we look at value of bit-2 which is 1 which means that we
go to destination state S2 (skipping value of bit-3).
Throughout the remaining of this text we use a representation of a DFA in a
ﬁgure that is a mixture of the top two representations in Fig. 4.1. On one hand,
we will have one edge only between each two states in the DFA (as we did in the
middle sample symbolic DFA). On the other hand, instead of labeling the edge with
a symbolic label like
1
X
X
X
we will label it with either character ranges such as [a-c]
or a character set such as fa; bg and ˙  fd; h; kg. In addition, we will always omit
the sink state and all transitions that go to it.
4.3.2
Modeling Non-Determinism Using Symbolic DFA
The MTBDD-based symbolic automata representation does not support non-
determinism directly. For a given alphabet symbol and an automata state, the
MTBDD data structure will only point to one target state. Therefore, we need to
implement the pre and post condition computations for string operations without
using the standard constructions based on the -transitions since the MTBDD-based
automata representation does not allow -transitions. We model non-determinism
in the MTBDD-based automata representation by extending the alphabet with
extra bits and then projecting them away using the on-the-ﬂy subset construction
algorithm. Projection is applied one bit at a time, and after projecting each bit
away, the size of the resulting automaton is reduced using MTBDD-based automata
minimization.
In other words, the project and determinize operation, denoted as PROJECT.A; i/,
where 1  i  k, converts a DFA A recognizing a language L over the alphabet
˙B  Bk, to a DFA A0 recognizing a language L0 over the alphabet ˙B  Bk1,
where L0 is the language that results from applying the tuple projection on the i-
th bit to each symbol of the alphabet. The process consists of removing the i-th
track of the MTBDD and determinizing the resulting MTBDD via on-the-ﬂy subset
construction. If we have a DFA A recognizing a language L over the alphabet ˙B 
Bk, and we want to add to A n non-deterministic transitions out from a state S on
some character c, we need to extend ˙B with l D dlog2.n/e extra bits to get ˙0
B 
BkCl. Then we determinize by projecting the extra l bits one bit at a time.
Figure 4.3 shows on the left part of a Non-deterministic FA with three non-
deterministic transitions on character a from state S0 to states S1; S2 and S3. On
the right it shows the corresponding symbolic DFA where ˙B  B2 and ˛a D 00.
To simulate non-determinism, we need to extend the alphabet ˙B by adding two
extra bits to represent three different symbols for character a namely a0; a1 and a2
where ˛a0 D 0000, ˛a1 D 0001 and ˛a2 D 0010. At the end, we determinize the
DFA by projecting bit-3 then bit-2.

4.4
Post-Condition Computation
45
Fig. 4.3 A symbolic DFA on
the right with ˙B  B2
simulating non-determinism
in the NFA on the left using
two extra bits
4.3.3
Symbolic vs. Explicit DFA
MTBDD-based symbolic DFA representation is more efﬁcient in terms of memory
than explicit DFA which means that, using symbolic DFA, our analysis consumes
less memory. Although both explicit and symbolic representation of sample DFA
shown in Fig. 4.1 seem to use the same number of transitions, bear in mind that a
BDD transition is labeled with a single bit while an explicit DFA transition is labeled
with 2 characters using 4 bits to represent each one (4 D log2.j˙j/). In general, the
difference between explicit and symbolic DFA in memory consumption becomes
more obvious as size of alphabet j˙j grows such as the case with j˙ASCIIj D 256
and j˙UNICODEj D 65;536. Furthermore, as we will see in the following chapters,
in order to perform relational string analysis, we use multi-track automata which
increases the size of the alphabet for the automata. For multi-track automata, use of
MTBDD-based symbolic DFA representation is crucial for memory efﬁciency.
4.4
Post-Condition Computation
In order to implement forward symbolic analysis, we need to compute post-
conditions of statements. In order to deﬁne post-condition on the symbolic rep-
resentation, we overload the POST operation, so that it not only works on sets of
states but also on automata that represent sets of states. Given an automata vector
EA where L.EAŒl/ denotes the set of values that variables can have just before the
execution of statement l, POST.EA; .l; l0// is the automata vector that represents the
set of values that the variables can take after the execution of the statement l and
before the execution of the successor statement l0.
In this section we focus on computing the post-condition of assignment state-
ments of the form: v WD sexpI where sexp is a string expression. Computing
post-condition of branch statements are discussed in Chaps. 5 and 7. In order to
compute the post-condition of these statements we need to construct automata for
different string operations. In the next section, we discuss how to do that with two
most common string operations: concat and replace. Note that, for the assignment
statements, POST.EA; .l; l0// only has to update one automaton in the automata vector

46
4
Automata Based String Analysis
EZ, all the other automata in the automata vector will remain the same. The only
automaton that needs to be updated is the automaton AŒv that accepts the set of
string values that string variable v can take. We discuss how to construct the updated
automaton using automata constructions for concat and replace operations.
4.4.1
Concatenation and Replace Operations
String operations concatenation and replacement are commonly used in modern
software applications to manipulate strings.
Consider the string expression x.y where x and y are two string variables. If
the value of the variable x is string w1 and the value of the variable y is string
w2, then the value of the expression x.y would be the string w1w2 corresponding
to the concatenation of the strings w1 and w2. In string analysis we are interested
in computing all possible values that string expressions can take. Hence, we are
interested in computing the set of possible values for the string expression x.y
given a set of string values for x and a set of string values for y. Let us assume
that the set of string values for x is denoted by the language L1 and the set of string
values for y is denoted by the language L2. Then, the set of values for the string
expression x.y corresponds to the concatenation of the two languages L1 and L2
which is deﬁned as the string set fw1w2 j w1 2 L1; w2 2 L2g. Since we use DFA to
represent sets of strings, we say a DFA A is the concatenation-DFA of A1 and A2 if
and only if A accepts the concatenation of L.A1/ and L.A2/, i.e.,
L.A/ D fw1w2 j w1 2 L.A1/; w2 2 L.A2/g:
We are also interested in computing the set of values that the string expression
replace(s, p, t) can have given sets of possible string values for s (the
source string), p (the match pattern), and t (the target string). We extend the
deﬁnition of the replace operation to languages as we did with the concatenation
operation above. We deﬁne the replacement operation on languages as follows.
Given A1, A2, and A3 that accept the original strings (s in replace(s, p, t)),
the match strings (p in replace(s, p, t)), and the replacement strings (t in
replace(s, p, t)), respectively, the replacement language of the DFA tuple
(A1, A2, A3) is deﬁned as the set
fw j k > 0; w1x1w2 : : : wkxkwkC1 2 L.A1/; w D w1c1w2 : : : wkckwkC1;
81  i  k; xi 2 L.A2/; ci 2 L.A3/;
81  i  k C 1; wi 62 fw0
1x0w0
2 j x0 2 L.A2/; w0
1; w0
2 2 ˙gg
We say a DFA A is the replaced-DFA of a DFA tuple .A1; A2; A3/ if and only if A
accepts the replacement language of the DFA tuple (A1, A2, A3). That is, A accepts
the set of strings generated from a string s accepted by A1 whose substrings that are
accepted by A2 are all replaced with any string r accepted by A3.

4.4
Post-Condition Computation
47
The replace(s, p, t) operation we deﬁned in Chap. 2 is a generic replace
operation and the language based replace operation we deﬁned above generalizes
it to sets of strings. There are many variations of replace operation semantics in
different programming languages. For example, in PHP programs, replacement
operations such as ereg_replace can use different replacement semantics such
as longest match or ﬁrst match. Our replacement operation provides an over
approximation of such more restricted replace semantics. For example, consider
L.A1/ D fbaabg, L.A2/ D aC (A2 accepts the language fa; aa; aaa; : : :g) and
L.A3/ D fcg. According to the longest match semantics, A only accepts bcb, in
which the longest match aa is replaced by c. In the ﬁrst match semantics, A only
accepts bccb, in which two matches a and a are replaced with c. Both of these are
included in the result obtained by our replacement operation. This over approx-
imation works well and does not raise too many false alarms in practice [127].
Indeed, we have observed that most statements in string manipulating programs
yield the same result with respect to the ﬁrst and longest match semantics, e.g.,
ereg_replace("<script *>","",$_GET["username"]);, which are
precisely modeled by the language-based replacement operation. On the other hand,
there have been techniques proposed for precise modeling of replace operation with
respect to different matching strategies using transducers [91]. The replacement
technique discussed below can be extended to different matching strategies using
a similar approach.
4.4.2
Post-Condition of Concatenation
Assume that we want to compute the post-condition of the following assignment
statement z := x . y. We assume that we are given two automata Ax and Ay
characterizing the set of string values that string variables x and y can take before
the assignment statement is executed. Given Ax and Ay, we deﬁne an operator
POSTCONCAT(DFA A1, DFA A2) that returns an automaton that accepts the set of
string values that the string expression x . y can take at that program point. Then,
we can compute the post-condition of the assignment statement by updating the
automaton for variable z as:
Az D POSTCONCAT.Ax; Ay/
where Az is the automaton that accepts the set of string values that string variable z
can take after the execution of the assignment statement.
POSTCONCAT(DFA A1, DFA A2) returns a DFA that accepts the concatenation
of strings accepted by A1 and A2. Given A1 D hQ1; q10; ˙; ı1; F1i and A2 D
hQ2; q20; ˙; ı2; F2i, the concatenation-DFA A = POSTCONCAT(DFA A1, DFA A2) can
be constructed as follows. Without loss of generality, we assume that Q1 \ Q2 is
empty. We ﬁrst construct an intermediate DFA A
0 D hQ
0; q10; ˙
0; ı
0; F
0i, where

48
4
Automata Based String Analysis
•
Q
0 D Q1 [ Q2
•
˙
0 D f˛0 j ˛ 2 ˙g [ f˛1 j ˛ 2 ˙g
•
8q; q0 2 Q1; ı
0.q; ˛0/ D q0, if ı1.q; ˛/ D q0
•
8q; q0 2 Q2; ı
0.q; ˛0/ D q0, if ı2.q; ˛/ D q0
•
8q 2 Q1; ı
0.q; ˛1/ D q0, if q 2 F1 and 9q0 2 Q2; ı2.q20; ˛/ D q0
•
F
0 D F1 [ F2, if q20 2 F2; F2, otherwise.
Then, A D PROJECT.A
0; k C 1/. Since both A1 and A2 are DFA, the subset
construction happens only when there exists q 2 F1 such that 9˛; q0; q
00; ˛ 2 ˙; q0 2
Q1; q
00 2 Q2; ı1.q; ˛/ D q0; ı2.q20; ˛/ D q
00.
4.4.3
Post-Condition of Replacement
In order to compute the post condition of an assignment statement of the form z
:= replace(s, p, t) we use a similar function: POSTREPLACE.
POSTREPLACE(DFA A1, DFA A2, DFA A3) returns a DFA that accepts the replaced
strings where A1 accepts the original strings, A2 deﬁnes the match, and A3 deﬁnes
the replacement. The replaced-DFA M = POSTREPLACE(DFA A1, DFA A2, DFA A3)
accepts strings that are obtained by taking a string that A1 accepts and replacing
all substrings that match L.A2/ with a string in L.A3/. Table 4.1 shows several
examples for M = POSTREPLACE(A1, A2, A3). M accepts an over approximation with
respect to the leftmost (ﬁrst) and longest match replace operations. In practice,
many string functions can be modeled using the replace operation. For example,
PHP replace operations such as preg_replace and ereg_replace that
have regular expressions as their arguments can be implemented using automata
constructions similar to the one we describe below. Also, other PHP functions such
as htmlspecialchars, tolower, toupper, str_replace, and trim can
be modeled using the replace operation.
To construct the replaced-DFA A = POSTREPLACE(A1, A2, A3), we insert marks
into automata, identify matching sub-strings by intersection of automata, and
then construct the ﬁnal automaton by replacing these matching sub-strings with
replacement. The details of automata constructions can be found in [129].
Here we use a running example to illustrate the idea (see Fig. 4.4). Consider
L.A1/ D fbaabg, L.A2/ D aC (A2 accepts the language fa; aa; aaa; : : :g) and
Table 4.1 Examples of
string replace operation
L.A1/
L.A2/
L.A3/
L.M/
{baaabaa}
{aa}
{c}
{bacbc, bcabc}
{baaabaa}
aC

{bb}
{baaabaa}
aCb
{c}
{baacaa, bacaa, bcaa}
{baaabaa}
aC
{c}
{bcccbcc, bcccbc,
bccbcc, bccbc, bcbcc, bcbc}
baCb
aC
{c}
bcCb

4.4
Post-Condition Computation
49
Fig. 4.4 Step 1 and Step 2: Add marks to sub strings and match. (a) A1. (b) A0
1: original strings
with substrings marked. (c) A2. (d) Ah. (e) A0
2: arbitrary strings with match marked
L.A3/ D fcg. Let jAj denote the number of states of A. An upper bound for each
intermediate automaton before projection and minimization is also described.
Step 1: We ﬁrst insert marks to identify all sub strings of in L.A1/. We use the
symbol ]1 to denote the beginning of a substring and the symbol ]2 to denote the
end of a substring. Given A1, we construct A
0
1, s.t.
L.A
0
1/ D fw0 j k > 0; w D w1x1w2 : : : wkxkwkC1 2 L.A1/;
w0 D w1]1x1]2w2 : : : wk]1xk]2wkC1g:
The example for constructing the automata A
0
1 with substrings of strings in L.A1/
identiﬁed with marks is shown in Fig. 4.4a and 4.4b. jA
0
1j is bounded by 2  jA1j.
Step 2: Next, we generate arbitrary strings with all substrings that are in L.A2/
identiﬁed with marks ]1 and ]2. Given the match automata A2, we construct A
0
2, s.t.
L.A
0
2/ D fw0 j k > 0; w0 D w1]1x1]2w2 : : : wk]1xk]2wkC1;
81  i  k; xi 2 L.A2/; 81  i  k C 1; wi 2 L.Ah/g;

50
4
Automata Based String Analysis
Fig. 4.5 Step 3 and 4: Construct the replaced automata by ﬁnding the path with replacement. (a)
A0: A10 u A
0
2. (b) A00: string replacement with auxiliary bits
where L.Ah/ is the set of strings which do not contain any substring that is in
L.A2/. The language L.Ah/ is deﬁned as the complement set of fw1xw2 j x 2
L.A2/; w1; w2 2 ˙g. As the example shown in Fig. 4.4c and 4.4d, for L.A2/ D aC,
Ah is the DFA that accepts .˙  fag/. Let A be the DFA accepting ˙. Ah can
be constructed by taking the complement of POSTCONCAT(POSTCONCAT(A, A2), A).
We obtain the DFA in Fig. 4.4d by applying this construction with minimization.
The corresponding A
0
2 for our example is shown in Fig. 4.4e. jA
0
2j is bounded by
jAhj C jA2j.
Step 3: Then, we ﬁnd matches in the original strings identiﬁed with marks. This
is done by computing the intersection language of A
0
1 and A
0
2 using automata product
operation. The intersection automata A
0 = A
0
1 u A
0
2 in our example is shown in
Fig. 4.5a. jA
0j is bounded by jA
0
1j  jA
0
2j.
Step 4: Finally, we replace all matches that are identiﬁed with marks with the
replacement string. We ﬁrst introduce a function reach W Q ! 2Q, which maps
a state to all its ]-reachable states in A. We say q0 is ]-reachable from q if there
exists w, q0 D ı.q; ]1w]2/. For instance, in Fig. 4.5, one can ﬁnd that reach.q1/ D
fq5; q7g and reach.q7/ D fq5g. Intuitively, one can think that each pair .q; q0/, where
q0 2 reach.q/, identiﬁes a word in L.A2/.
The idea to construct the ﬁnal automaton from A
0 is to, for each q and q0 2
reach.q/, insert paths between q and q0 that recognize a string in L.A3/. To deal
with nondeterminism with MTBDDs, we add extra bits to the alphabet as we did
in the construction of concatenation. Extra bits are added to the alphabet to make
transitions deterministic and later be projected away to yield the DFA with the
original alphabet.
The ﬁnal replaced-DFA A can then be constructed by iteratively projecting away
the extra bits (over ˙) in Fig. 4.5b. The subset construction is only applied when
needed.
The replaced-DFA of .A1; A2; A3/, where L.A1/ D fbaabg, L.A2/ D aC, and
L.A3/ D fcg, is A that accepts fbcb; bccbg.

4.5
Pre-Condition Computation
51
The subset construction may induce an exponential blow-up of the number of
states of the ﬁnal DFA. In fact, it has been shown that a potential exponential blow-
up of the number of states of the ﬁnal DFA is inevitable in a replacement operation
in some cases [129].
4.5
Pre-Condition Computation
In order to implement backward symbolic analysis, we need to compute pre-
conditions of statements. Below, we explain how we compute the pre-conditions
of the string operations which can then be used to compute pre-conditions of
statements. We will focus on computing the pre-condition of concatenation and
replacement operations as we did for post-condition computations. Speciﬁcally,
we will discuss the functions PRECONCATPREFIX(DFA A, DFA A2), PRECONCATSUF-
FIX(DFA A, DFA A1), and PREREPLACE(DFA A, DFA A2, DFA A3) which return
a DFA:
•
PRECONCATPREFIX.A; A2/ returns a DFA A1 such that A D POSTCONCAT.A1; A2/.
•
PRECONCATSUFFIX.A; A1/ returns a DFA A2 such that A D POSTCONCAT.A1; A2/.
•
PREREPLACE.A; A2; A3/ returns a DFA A1 such that A D POSTREPLACE.A1; A2; A3/.
Note that, similar to post-condition computations, we may not be able to com-
pute the precise pre-condition automaton. In such cases, we produce an over-
approximation of the pre-condition automaton.
4.5.1
Pre-Condition of Concatenation
To compute the pre-condition of concatenation operation, we introduce concatena-
tion transducers to specify the relation among its output and two input expressions.
Transducers are multi-track automata we use for pre-condition computation (these
are similar to the multi-track automata we use for relational string analysis we
discuss in the next Chapter).
A concatenation transducer is a multi-track DFA over the alphabet that consists
of 3 tracks (we discuss multi-track DFAs in more detail in the next chapter). The
3-track alphabet is deﬁned as ˙3 D ˙  .˙ [ fg/  .˙ [ fg/, where  62 ˙
is a special symbol for padding. We use wŒi (1  i  3) to denote the ith track
of w 2 ˙3. All tracks are aligned. wŒ1 2 ˙, wŒ2 2 ˙ is left justiﬁed,
and wŒ3 2 ˙ is right justiﬁed. We use w0Œ2; w0Œ3 2 ˙ to denote the -free
preﬁx of wŒ2 and the -free sufﬁx of wŒ3. We say w is accepted by a concatenation
transducer A if wŒ1 D w0Œ2:w0Œ3. Since a concatenation transducer binds the values
of different tracks character by character it is able to identify the preﬁx and sufﬁx
relations precisely.

52
4
Automata Based String Analysis
Fig. 4.6 Transducers for (a) X D .ab/C:Z and (b) X D Y:.ab/C
Below we show two examples of concatenation transducers. Let ˛ indicate any
character in ˙. In Fig. 4.6a, the third track of A can be used to identify all sufﬁxes
of X that follow any string in .ab/C. In Fig. 4.6b, the second track of A can be used
to identify all preﬁxes of X that are followed by any string in .ab/C.
In the following, we describe how to compute the pre-images of a concatenation
node using concatenation transducers.
PRECONCATPREFIX(DFA A, DFA A2) returns the preﬁx automata A1 such that A
= POSTCONCAT(A1,A2). Consider the assignment statement z := x . y, in the
pre-condition computation, we would like to compute the set of possible values for
variable x given the set of possible values for z and for y. We can use the function
PRECONCATPREFIX to compute the pre-condition automaton for variable x for the
statement z := x . y.
Given A D hQx; ˙; ıx; qx0; Fxi and A2 D hQz; ˙; ız; qz0; Fzi, PRECONCATPRE-
FIX(A, A2) returns A1 which is constructed using the following steps:
•
Extend A to a 3-track DFA A0, so that A0 accepts fw j wŒ1 2 L.A/g.
•
Construct the concatenation transducer At
that accepts fw j wŒ1
D
w0Œ2:w0Œ3; w0Œ3 2 L.A2/g.
At D hQ; ˙3; ı; q0; Fi, where:
– Q D fq0g [ Q2,
– 8a 2 ˙; ı.q0; .a; a; // D q0,
– 8a 2 ˙; ı.q0; .a; ; a// D q0 if ız.qz0; a/ D q0.
– 8q; q0 2 Q2; 8a 2 ˙; ı.q; .a; ; a// D q0 if ız.q; a/ D q0.
– F D fq0g [ F2 if qz0 2 F2. F D F2, otherwise.
•
Intersect A0 with At. The result accepts fw j wŒ1
D
w0Œ2:w0Œ3; wŒ1
2
L.A/; w0Œ3 2 L.A2/g. We then project away the ﬁrst and the third tracks. Let
the result be A0
1 D hQ1; ˙ [ fg; ı; q0
y0; F0
1i.

4.5
Pre-Condition Computation
53
•
Remove  tails, if any, to construct A1.
A1=hQ1; ˙; ı1; q10; F1i as:
– 8q; q0 2 Q1; 8a 2 ˙; ı1.q; a/ D q0 if ı0
1.q; a/ D q0.
– F1 D F0
1 [ F, where F D fq j 9q0 ¤ sink; ı0
1.q; / D q0g.
Similarly, PRECONCATSUFFIX(DFA A, DFA A1) returns the sufﬁx automata A2
such that A = POSTCONCAT(A1,A2). PRECONCATSUFFIX is used for computing the pre-
condition automaton for variable x for the statement z := x . y.
Again, let A D hQ; ˙; ı; q0; Fi, and A1 D hQ1; ˙; ı1; q10; F1i. PRECONCATSUF-
FIX(A, A1) constructs the automaton A2 using the following steps:
•
Extend A to a 3-track DFA A0, so that A0 accepts fw j wŒ1 2 L.A/g.
•
Construct the concatenation transducer At
that accepts fw j wŒ1
D
w0Œ2:w0Œ3; w0Œ2 2 L.A1/g. At D hQt; ˙3; ıt; q10; Fti, where:
– Qt D Q1 [ fqf g
– 8q; q0 2 Q1; 8a 2 ˙; ı.q; .a; a; // D q0 if ı1.q; a/ D q0.
– 8q 2 F1; 8a 2 ˙; ı.q; .a; ; a// D qf .
– 8a 2 ˙; ı.qf ; .a; ; a// D qf .
– Ft D fqf g [ F1.
•
Intersect A0 with At. The result A0 u At accepts fw j wŒ1 D w0Œ2:w0Œ3; wŒ1 2
L.Ax/; w0Œ2 2 L.A1/g. We then project away the ﬁrst and the second tracks. Let
the result be A0
2 D hQ0
2; ˙ [ fg; ı0
2; q0
z0; F0
2i.
•
Remove  heads if any and construct A2 D hQ2; ˙; ı2; q20; F2i as:
– Q2 D q0 [ Q0
2.
– 8q 2 Q0
2; 8a 2 ˙; ı2.q; a/ D q0 if there exists q0 2 Q0
2; ı0
2.q; a/ D q0.
– 8q 2 Q0
2; 8a 2 ˙; ı2.q0; a/ D q0 if there exists q0; q00 2 Q0
2, ı0
2.q00; / D q
and ı0
2.q; a/ D q0.
– F2 D fq0g [ F0
2, if 9q 2 F0
2 and there exists q0; q00 2 Q0
2, so that ı0
2.q00; / D q
and ı0
2.q; a/ D q0. F2 D F0
2, otherwise.
4.5.2
Pre-Condition of Replacement
PREREPLACE(DFA A, DFA A2, DFA A3) returns the automaton A1 such that A =
POSTREPLACE(A1,A2, A3).
Recall that a replace statement has three inputs: the original strings, the match
pattern, and the replacement pattern. Consider the replace statement in the form
z := replace(s, p, t). Let us consider to compute all potential original
strings (as the pre-image of the target strings) given regular sets characterizing
possible values of the resulting strings, the match pattern, and the replacement
pattern. Let Az = REPLACE(As, Ap, At), then our goal is to compute As, given Az; Ap;
and At.

54
4
Automata Based String Analysis
An intuitive potential solution of PREREPLACE(Az, Ap, At) is POSTREPLACE(Az, At,
Ap). However, since not all matches of At that appear in Az are due to the replacement
operation, this would be an incorrect solution. Consider a simple example. As,
Ap and At accepts faabg, fbg, and fag, respectively. Az = POSTREPLACE(As, Ap,
At) accepts faaag. A0
s = POSTREPLACE(Az, At, Ap) accepts fbbbg. Since fbbbg does
not include faabg, this intuitive approach is not correct. To address this issue,
a conservative solution is proposed in [129], where PREREPLACE(DFA Az, DFA
Ap, DFA At) is modeled as POSTREPLACE(Az, At, Ap t At). The result is an over
approximation of the pre-condition. Consider another simple example. As, Ap and
At accept fag, fag, and faag, respectively. Az = POSTREPLACE(As, Ap, At) accepts
faag. A0
s = POSTREPLACE(Az, At, Ap tAt) accepts fa; aag. In this case, L.As/ D fag 
L.A0
s/ D fa; aag.
Below we describe the construction [117] for PREREPLACE(DFA A1, DFA A2,
DFA A3). The steps are similar to the construction for POSTREPLACE. We ﬁrst insert
marks to identify all sub strings of strings in L.A1/. We construct A
0
1, s.t.
L.A
0
1/ D fw0 j k > 0; w D w1x1w2 : : : wkxkwkC1 2 L.A1/;
w0 D w1]1x1]2w2 : : : wk]1xk]2wkC1g:
Next, we construct A
0
2, s.t.
L.A
0
2/ D fw0 j k > 0; w0 D w1]1x1]2w2 : : : wk]1xk]2wkC1;
81  i  k; xi 2 L.A3/; 81  i  k C 1; wi 2 L.Ah/g;
where L.Ah/ is the set of strings which do not contain any substring in L.A2/. The
language L.Ah/ is deﬁned as the complement set of fw1xw2 j x 2 L.A2/; w1; w2 2
˙g. Let A be the DFA accepting ˙. Ah can be constructed by taking the
complement of POSTCONCAT(POSTCONCAT(A, A2), A). Note that here we still use
A2 to construct Ah. The intuition is to identify the parts that remain the same (the
substrings that are not in L.A2/) in the post image computation. We take intersection
of A
0
1 and A
0
2 to mark matches (in A3) and replace all these matches with A2 to
construct the ﬁnal automata similar to the construction presented for POSTREPLACE.
When A3 accepts an empty string, POSTREPLACE(A1, A2, A3) performs deletion.
I.e., it will delete all the matches in L.A1/. In this case, to compute the pre-
image of the target strings, we would not be able to ﬁnd any match of A3 (an
empty string in this case) to be replaced with A2. For instance, if we compute
PREREPLACE(DFA A1, DFA A2, DFA A3) with POSTREPLACE(A1, A3, A3 t A2) when
A3 accepts only an empty string, it will return A1 without any changes. To deal with
deletion, we conservatively generate A for PREREPLACE(DFA A1, DFA A2, DFA A3)
that accepts L.A2/ to be repeated arbitrary times between any character of L.A1/.
Formally speaking, A accepts the language fw0c0 : : : wncnwnC1 j c0 : : : cn 2 L.A1/;
8i; wi 2 L.A
2/g, where L.A
2/ denotes the closure of L.A2/.

4.6
Summary
55
4.6
Summary
In this chapter we discussed the use of automata as a symbolic representation for
analyzing string manipulating programs. Automata represent sets of strings and
support the operations needed for symbolic reachability analysis. Hence, automata
are a suitable symbolic representation for string analysis. We discussed symbolic
representation of automata where the transition relation of the automata are encoded
as Multi-terminal Binary Decision Diagrams (MTBDD). We discussed the post- and
pre-condition computations using automata as a symbolic representations, focusing
on the concatenation and replacement operations. In the following chapters we
discuss string analysis techniques that use automata as a symbolic representation.

Chapter 5
Relational String Analysis
The string analysis techniques we discussed in the previous chapter are not
relational, i.e., they cannot keep track of relationships among variables. An analysis
technique that is able to keep track of the relationships among the string variables,
can improve the precision of the string analysis and enable veriﬁcation of assertions
such as X1 D X2 where X1 and X2 are string variables. It is not possible to prove
such assertions using the techniques described in the previous chapter unless the set
of values for string variables are singleton sets.
5.1
Relations Among String Variables
Sometimes it is essential to keep relations among string variables to prove asser-
tions. Consider a simple branch statement in Fig. 5.1. Previous automata-based
string analysis techniques that use single-track automata are not able to prove the
assertion at the end of this program segment. Consider a symbolic analysis technique
that uses one automaton for each variable at each program point to represent the set
of values that the variables can take at that program point. Using this symbolic
representation we can do a forward ﬁxpoint computation to compute the reachable
state space of the program. For example, the automaton for variable X1 at the
beginning of statement 2, call it AX1;2, will recognize the set L.AX1;2/ D ˙ to
indicate that the input can be any string. Similarly, the automaton for variable X2 at
the beginning of statement 3, call it AX2;3, will recognize the set L.AX2;3/ D ˙.
The question is how to handle the branch condition in statement 3. If we are
using single track automata, all we can do at the beginning of statement 6 is the
following: L.AX1;6/ D L.AX2;6/ D L.AX1;3/ \ L.AX2;3/. The situation with the
else branch is even worse. All we can do at line 4 is to set L.AX1;4/ D L.AX1;3/
and L.AX2;4/ D L.AX2;3/. Both branches will result in L.AX1;7/ D ˙:c and
L.AX2;7/ D ˙, which is clearly not strong enough to prove the assertion.
© Springer International Publishing AG 2017
T. Bultan et al., String Analysis for Software Veriﬁcation and Security,
https://doi.org/10.1007/978-3-319-68670-7_5
57

58
5
Relational String Analysis
Fig. 5.1 An example with a
branch statement
Fig. 5.2 An example with a
loop
Relational string analysis can be used to verify the assertion in the above program
via modeling the relations among string variables. In the following, we use a
single multi-track automaton for each program point, where each track of the
automaton corresponds to one string variable. For the above example, the multi-
track automaton at the beginning of statement 3 will accept any pairs of strings
X1; X2 where X1; X2 2 ˙. However, the multi-track automaton at the beginning
of statement 6 will only accept pairs of strings X1; X2 where X1; X2 2 ˙ and
X1 D X2. We compute the post-condition .9X1:.X1 D X2/ ^ .X0
1 D X1:c//ŒX1=X0
1
and generate the multi-track automaton that only accepts pairs of strings X1; X2
where X1; X2 2 ˙ and X1 D X2:c. Similarly, the multi-track automaton at the
beginning of statement 4 will only accept pairs of strings X1; X2 where X1; X2 2 ˙
and X1 ¤ X2, and after the assignment, we will generate the multi-track automaton
that only accepts pairs of strings X1; X2 where X1; X2 2 ˙ and X1 D X2:c. Hence,
we are able to prove the assertion in statement 7.
Now, consider another string manipulation segment shown in Fig. 5.2, which
contains an inﬁnite loop. If we try to compute the reachable states of this program
by iteratively adding states that can be reached after a single step of execution,
our analysis will never terminate. We incorporate a widening operator to accelerate
our symbolic reachability computation and compute an over-approximation of the
ﬁxpoint that characterizes the reachable states. Note that the assertion in this
program segment is not explicitly established, i.e., there is no assignment, such as
X1 WD X2, or branch condition, such as X1 D X2, that implies that this assertion
holds. Also, the assertion speciﬁes the equality among two string variables. Analysis
techniques that encode reachable states using multiple single-track DFAs will raise
a false alarm, since, individually, X1 can be abb and X2 can be ab at program point
5, but they cannot take these values at the same time. It is not possible to express
such a constraint using single-track automata.
For this example, the multi-track automata based string analysis technique we
discuss in this Chapter terminates in three iterations and computes the precise result.
The multi-track automaton that characterizes the values of string variables X1 and
X2 at program point 5, call it A5, recognizes the language: L.A5/ D .a; a/.b; b/C.

5.3
Relational String Analysis
59
Since L.A5/  L.X1 D X2/, we conclude that the assertion holds. Although in
this case the result of our analysis is precise, it is not guaranteed to be precise in
general. However, it is guaranteed to be an over-approximation of the reachable
states. Hence, our analysis is sound and if we conclude that an assertion holds, the
assertion is guaranteed to hold for every program execution.
5.2
Multi-Track DFAs
We use multi-track DFAs to encode the relations among string variables, where each
track represents the value of a string variable.
A multi-track DFA is a DFA with an alphabet that consists of many tracks. An
n-track alphabet is deﬁned as .˙ [ fg/n, where  62 ˙ is a special symbol for
padding. We use wŒi (1  i  n) to denote the ith track of w 2 .˙ [ fg/n. An
aligned multi-track DFA is a multi-track DFA where all tracks are left justiﬁed (i.e.,
’s are right justiﬁed). That is, if w is accepted by an aligned n-track DFA A, then for
1  i  n, wŒi 2 ˙. We also use OwŒi 2 ˙ to denote the longest -free preﬁx
of wŒi. Aligned multi-track DFA languages are closed under intersection, union,
and homomorphism. Let Au be the aligned n-track DFA that accepts the (aligned)
universe, i.e., fw j 8i:wŒi 2 ˙g. The complement of the language accepted
by an aligned n-track DFA A is deﬁned by complement modulo alignment, i.e., the
intersection of the complement of L.A/ with L.Au/. For the following descriptions, a
multi-track DFA is an aligned multi-track DFA unless we explicitly state otherwise.
Consider the condition X1 D X2:txt where X1 is the same as X2 concatenated
with a constant string "txt". Figure 5.3 shows the multi-track DFA that models
this constraint. It accepts the set of two-track strings (the ﬁrst track is the value of X1
and the second track is the value of X2) such that the ﬁrst track has the same value
as the second track (staying at the state 0) until the second track hits and keeps the
rest as the padding symbol  (moving from state 0 to 1) to extend the ﬁrst track to a
constant string "txt" (and to state 2 and 3).
5.3
Relational String Analysis
The relational string analysis we present in this Chapter is based on the following
observations: (1) The transitions and the states of a string manipulating program can
be symbolically represented using word equations with existential quantiﬁcation, (2)
word equations can be represented/approximated using multi-track DFAs, which
Fig. 5.3 A multi-track DFA
that recognizes X1 D X2:txt

60
5
Relational String Analysis
are closed under intersection, union, complement, and projection, and (3) the
operations required during reachability analysis (such as equivalence checking) can
be computed on DFAs.
Before we discuss how to perform relational symbolic reachability analysis for
string manipulating programs, we introduce the word equations in this section. We
characterize word equations that can be expressed using multi-track DFAs, as well
as discuss the construction of these multi-track DFAs. Using these constructions,
in the next section, we show how to perform symbolic reachability analysis for
string manipulating programs. We iteratively compute post images of reachable
states represented as multi-track DFAs and join the results using automata widening
until reaching a ﬁxpoint.
5.3.1
Word Equations
A word equation is an equality relation of two words that concatenate variables from
a ﬁnite set X and words from a ﬁnite set of constants C. The general form of word
equations is deﬁned as v1 : : : vn D v0
1 : : : v0
m, where 8i; vi; v0
i 2 X [ C.
As shown in [134], word equations and Boolean combinations (:, ^ and _) of
these equations can be expressed using equations of the form X1 D X2c, X1 D cX2,
c D X1X2, X1 D X2X3, Boolean combinations of such equations and existential
quantiﬁcation. For example, a word equation f W X1 D X2dX3X4 is equivalent to
9Xk1; Xk2:X1 D X2Xk1 ^ Xk1 D dXk2 ^ Xk2 D X3X4.
Let f be a word equation over X D fX1; X2; : : : ; Xng and fŒc=X denote a new
equation where X is replaced with c for all X that appears in f. We say that an n-
track DFA A under-approximates f if for all w 2 L.A/, fŒ OwŒ1=X1; : : : ; OwŒn=Xn
holds. We say that an n-track DFA A over-approximates f if for any s1; : : : ; sn 2 ˙
where fŒs1=X1; : : : ; sn=Xn holds, there exists w 2 L.A/ such that for all 1  i 
n; OwŒi D si. We call A precise with respect to f if A both under-approximates and
over-approximates f. A word equation f is regularly expressible if and only if there
exists a multi-track DFA A such that A is precise with respect to f.
We will discuss how to construct the corresponding multi-track DFAs for the
basic forms of word equations: (1) X1 D X2c, (2) X1 D cX2, (3) c D X1X2, and (4)
X1 D X2X3.
Following have been shown in [134].
1. X1 D X2c, X1 D cX2, and c D X1X2 are regularly expressible, as well as their
Boolean combinations.
2. X1 D cX2 is regularly expressible but the corresponding A has exponential
number of states in the length of c.
3. X1 D X2X3 is not regularly expressible.
We are able to construct multi-track DFAs that are precise with respect to word
equations: X1 D X2c, X1 D cX2, and c D X1X2. Since X1 D X2X3 is not regularly
expressible, we describe how to compute DFAs that approximate such non-linear

5.4
Construction of Multi-Track DFAs for Basic Word Equations
61
word equations. Using the DFA constructions for these four basic forms we can
construct multi-track DFAs for all word equations and their Boolean combinations
(if the word equation contains a non-linear term then the constructed DFA will
approximate the equation, otherwise it will be precise). The Boolean operations
conjunction, disjunction and negation can be handled with intersection, union, and
complement modulo alignment of the multi-track DFAs, respectively. Existential
quantiﬁcation on the other hand, can be handled using homomorphism, where given
a word equation f and a multi-track automaton A such that A is precise with respect
to f, then the multi-track automaton A i is precise with respect to 9Xi:f where A i
denotes the result of erasing the ith track (by homomorphism) of A.
5.4
Construction of Multi-Track DFAs for Basic
Word Equations
Given a DFA A D hQ; ˙; ı; I; Fi, Q is the set of states, ˙ is the alphabet, ı W
Q  ˙ ! Q is the transition function, I 2 Q is the initial state, and F  Q is the
set of ﬁnal (accepting) states. We say a state q 2 Q is a sink state if q 62 F and
8a 2 ˙; ı.q; a/ D q. In the following construction functions, we ignore transitions
that go to sink states, and assume that all unspeciﬁed transitions go to sink states.
Before we give the construction functions, we generalize the problem of
constructing multi-track DFAs for word equations as follows. We assume that
each variable in X D fX1; X2; : : : ; Xng is associated with an automaton Ai D
hQi; ˙; ıi; Ii; Fii, where L.Ai/ denotes the set of values that the variable Xi can
take. Then, given a word equation f over X, we say that an n-track DFA A under-
approximates f within A1; : : : An, if for all w 2 L.A/, fŒ OwŒ1=X1; : : : ; OwŒn=Xn holds
and for all 1  i  n, OwŒi 2 L.Ai/. We say that an n-track DFA A over-approximates
f within A1; : : : An, if for any s1; : : : ; sn 2 ˙ where fŒs1=X1; : : : ; sn=Xn holds
and for all 1  i  n, si 2 L.Ai/, there exists w 2 L.A/ such that for all
1  i  n; OwŒi D si. Note that, for either case, for any word w 2 L.A/, for all
1  i  n; OwŒi 2 L.Ai/.
Below we deﬁne the construction function A that returns the corresponding
automata for each basic word equation.
Construction of A(X1 D X2c, A1, A2)
Let A1 D hQ1; ˙; ı1; I1; F1i, A2 D hQ2; ˙; ı2; I2; F2i be two DFAs that accept
possible values of variables X1 and X2, respectively. A(X1 D X2c, A1, A2) deﬁnes the
construction function of a 2-track DFA A D hQ; ˙; ı; I; Fi, such that A is precise
with respect to X1 D X2c within A1; A2.

62
5
Relational String Analysis
Let c D a1a2 : : : an, where 81  i  n; ai 2 ˙ and n is the length of the
constant string c. A(X1 D X2c, A1, A2) returns A D hQ; .˙ [ fg/2; ı; q0; Fi, which
is constructed as:
•
Q  Q1  Q2  f0; : : : ; ng,
•
I D .I1; I2; 0/,
•
8a 2 ˙; ı..r; p; 0/; .a; a// D .ı1.r; a/; ı2.p; a/; 0/,
•
8ai; p 2 F2; ı..r; p; i/; .ai; // D .ı1.r; ai/; p; i C 1/,
•
F D f.r; p; i/ j r 2 F1; p 2 F2; i D ng.
Note that A simulates A1 and A2 making sure that both tracks are the same until
a ﬁnal state of A2 is reached. Then, the second track reads the symbol  while
the ﬁrst track reads the constant c, and the automaton goes to a ﬁnal state when c is
consumed. jQj is O.jQ1jjQ2jCn/ since in the worst case Q will contain all possible
combinations of states in Q1 and Q2 followed with a tail of n states for recognizing
the constant c. For the automaton A resulting from the above construction we have,
w 2 L.A/ if and only if OwŒ1 D OwŒ2c, OwŒ1 2 L.A1/ and OwŒ2 2 L.A2/, i.e., A is
precise with respect to X1 D X2c (within A1; A2), and, hence, X1 D X2c is regularly
expressible.
Construction of A(X1 D cX2, A1, A2)
Let A1 D hQ1; ˙; ı1; I1; F1i, A2 D hQ2; ˙; ı2; I2; F2i be two DFAs that accept
possible values of variables X1 and X2, respectively. Below we present A(X1 D cX2,
A1, A2), the construction function that returns a 2-track DFA A, such that A is precise
with respect to X1 D cX2 within A1; A2. Let c D a1a2 : : : an, where 81  i  n; ai 2
˙ and n is the length of the constant string c.
The intuition behind the construction of A is as follows. In the initial stage
(denoted as init below), A makes sure that the ﬁrst track matches the constant c,
while recording the string that is read in the second track in a buffer (a vector of
symbols) stored in its state. After c is consumed, A goes to the next stage (denoted
as match below) and matches the symbols read in the ﬁrst track with the next symbol
stored in the buffer while continuing to store the symbols read in the second track
in the buffer. Note that, the kth symbol read in track 2 has to be matched with the
.k C n/th symbol read in track 1. So, the buffer stores the symbols read in track 2
until the corresponding symbol in track 1 is observed.
Let Ev be a size n vector. For 1  i  n; EvŒi 2 ˙ [f?g. The vector Ev0 D EvŒi WD a
is deﬁned as follows: Ev0Œi D a and 8j ¤ i, Ev0Œj D EvŒj. A D hQ; .˙ [fg/2; ı; I; Fi
is constructed as:
•
Q  Q1  Q2  f1; : : : ; ng  .˙ [ f?g/n  finit; matchg,
•
I D .I1; I2; 1; Ev?; init/, where 8i; Ev?Œi D ?,
•
8a 2 ˙; 1  i < n; ı..r; p; i; Ev; init/; .ai; a// D .ı1.r; ai/; ı2.p; a/; i C 1;
EvŒi WD a; init/,

5.4
Construction of Multi-Track DFAs for Basic Word Equations
63
•
8a 2 ˙; i D n; ı..r; p; i; Ev; init/; .ai; a// D .ı1.r; ai/; ı2.p; a/; 1; EvŒi WD a;
match/,
•
8a; b 2 ˙; 1  i < n; EvŒi D a; ı..r; p; i; Ev; match/; .a; b// D .ı1.r; a/; ı.p; b/;
i C 1; EvŒi WD b; match/,
•
8a; b 2 ˙; i D n; EvŒi D a; ı..r; p; i; Ev; match/; .a; b// D .ı1.r; a/; ı.p; b/; 1;
EvŒi WD b; match/,
•
8a 2 ˙; p 2 F2; 1  i < n; EvŒi D a; ı..r; p; i; Ev; match/; .a; // D .ı1.r; a/;
p; i C 1; EvŒi WD ?; match/,
•
8a 2 ˙; p 2 F2; i D n; EvŒi D a; ı..r; p; i; Ev; match/; .a; // D .ı1.r; a/;
p; 1; EvŒi WD ?; match/,
•
F D f.r; p; i; Ev?; match/ j r 2 F1; p 2 F2g.
Since A accepts the set fw j OwŒ1 D c OwŒ2; OwŒ1 2 L.A1/; OwŒ2 2 L.A2/g, X1 D
cX2 is regularly expressible. However, the number of states of A is exponential in c.
Below, we show that the exponential number of states is inevitable.
Intractability of X1 D cX2
Consider the equation X1 D cX2, where c is a constant string of length n. Let L.A1/
and L.A2/ be regular languages. Deﬁne the 2-track language:
L D f.x1x2; y1y2n/ j x1x2 2 L.A1/; y1y2 2 L.A2/; k  n; jx1x2j D k; jx1j D
jy1j D n; x1 D c; x2 D y1y2g
Note that any automaton A that accepts the language L deﬁned above will be
precise with respect to the the equation X1 D cX2 (within A1 and A2).
In fact, any nondeterministic ﬁnite automaton (NFA) A needs at least 2n states
to accept L. Let c D 1n and consider the regular languages L.A1/ D .0 C 1/C and
L.A2/ D .0 C 1/C. Suppose A is an NFA accepting L. Consider any pair of distinct
strings y1 and y0
1 of length n. Then A will accept the following 2-track strings:
.1nx2; y1y2n/, where x2; y1; y2 2 .0 C 1/C, k  n, j1nx2j D k; jy1j D n; x2 D
y1y2, and
.1nx0
2; y0
1y0
2n/, where x0
2; y0
1; y0
2 2 .0C1/C, k  n, j1nx0
2j D k; jy0
1j D n; x0
2 D y0
1y0
2
Suppose in processing .1nx2; y1y2n/, A enters state q after processing the initial
2-track segment .1n; y1/, and in processing .1nx0
2; y0
1y0
2n/, A enters state q0 after
processing the initial 2-track segment .1n; y0
1/. Then q ¤ q0; otherwise, A will also
accept .1nx2; y0
1y2n/. This is a contradiction, since x2 ¤ y0
1y2.
Since there are 2n distinct strings y of length n, it follows that A must have at
least 2n states.

64
5
Relational String Analysis
Construction of A(c D X1X2, A1, A2)
Below we brieﬂy describe A(c D X1X2, A1, A2), the construction function that
returns a 2-track DFA A, such that A is precise with respect to c D X1X2 within
the given regular sets characterizing possible values of X1 and X2. Assume that
c D a1 : : : an. We can split c to two strings a1 : : : ak and akC1 : : : an so that c D
a1 : : : akakC1 : : : an. There are nC1 such splits. For each of them, if a1 : : : ak 2 L.A1/
and akC1 : : : an 2 L.A2/, then if k  n  k, .a1 : : : ak; akC1 : : : an2kn/ should be
accepted by A and if k < n  k, .a1 : : : akn2k; akC1 : : : an/ should be accepted by
A. We can construct an automaton A with O.n2/ states that accepts this language by
explicitly checking each of these n C 1 cases. Since we can construct this 2-track
DFA, it follows that c D X1X2 is regularly expressible.
Construction of A(X1 D X2X3, A1, A2, A3)
Since it has been shown in [134] that X1 D X2X3 is not regularly expressible,
A(X1 D X2X3, A1, A2, A3) deﬁnes a conservative construction that accepts (over or
under) approximation of X1 D X2X3. We ﬁrst propose AC(X1 D X2X3, A1, A2, A3)
as an over approximation construction for X1 D X2X3. Let A1 D hQ1; ˙; ı1; I1; F1i,
A2 D hQ2; ˙; ı2; I2; F2i, and A3 D hQ3; ˙; ı3; I3; F3i accept values of X1, X2,
and X3, respectively. AC(X1 D X2X3, A1, A2, A3) returns the automata A D
hQ; .˙ [ fg/3; ı; I; Fi, which is constructed as follows.
•
Q  Q1  Q2  Q3  Q3,
•
I D .I1; I2; I3; I3/,
•
8a; b 2 ˙, ı..r; p; s; s0/; .a; a; b// D .ı1.r; a/; ı2.p; a/; ı3.s; b/; s0/,
•
8a; b 2 ˙, p 2 F2; s 62 F3; ı..r; p; s; s0/; .a; ; b// D .ı1.r; a/; p; ı3.s; b/;
ı3.s0; a//,
•
8a 2 ˙, p 2 F2; s 2 F3; ı..r; p; s; s0/; .a; ; // D .ı1.r; a/; p; s; ı3.s0; a//,
•
8a 2 ˙, p 62 F2; s 2 F3; ı..r; p; s; s0/; .a; a; // D .ı1.r; a/; ı2.p; a/; s; s0/,
•
F D f.r; p; s; s0/ j r 2 F1; p 2 F2; s 2 F3; s0 2 F3g.
The intuition is as follows: AC(X1 D X2X3, A1, A2, A3) returns the automata A
that traces A1, A2 and A3 on the ﬁrst, second and third tracks, respectively, and makes
sure that the ﬁrst and second tracks match each other. After reaching an accepting
state in A2, A enforces the second track to be  and starts to trace A3 on the ﬁrst track
to ensure the rest (sufﬁx) is accepted by A3. jQj is O.jQ1j  jQ2j  jQ3j C jQ1j 
jQ3j  jQ3j/. For all w 2 L.A/, the following hold:
•
OwŒ1 2 L.A1/; OwŒ2 2 L.A2/; OwŒ3 2 L.A3/,
•
OwŒ1 D OwŒ2w0 and w0 2 L.A3/,

5.5
Symbolic Reachability Analysis
65
Note that w0 may not be equal to OwŒ3, i.e., there exists w 2 L.A/, OwŒ1 ¤
OwŒ2 OwŒ3, and hence A is not precise with respect to X1 D X2X3. On the other hand,
for any w such that OwŒ1 D OwŒ2 OwŒ3, we have w 2 L.A/, hence A is a regular
over-approximation of X1 D X2X3.
Below, we deﬁne A(X1 D X2X3, A1, A2, A3) for the conservative construction of
a regular under-approximation of X1 D X2X3 (which is necessary for conservative
approximation of its complement set). We use the idea that if L.A2/ is a ﬁnite set
language, one can construct the DFA A that satisﬁes X1 D X2X3 by explicitly taking
the union of the construction of X1 D cX3 (by calling A(X1 D cX3, A1, A3)) for
all c 2 L.A2/. If L.A2/ is an inﬁnite set language, we construct a regular under-
approximation of X1 D X2X3 by considering a (ﬁnite) subset of L.A2/ where the
length is bounded. Formally speaking, for each k  0 we can construct Ak, so that
w 2 L.Ak/; OwŒ1 D OwŒ2 OwŒ3; OwŒ1 2 L.A1/, OwŒ3 2 L.A3/, OwŒ2 2 L.A2/ and
j OwŒ2j  k. It follows that Ak is a regular under-approximation of X1 D X2X3.
If L.A2/ is a ﬁnite set language, there exists k (the length of the longest accepted
word) where L.Ak/ is precise with respect to X1 D X2X3. If L.A2/ is an inﬁnite
set language, there does not exist such k so that L.Ak/ is precise with respect to
X1 D X2X3, as we have proven non-regularity of X1 D X2X3.
In fact, for an inﬁnite set language, we can always improve the precision by
increasing k, i.e., for all k1, there exists a k2 such that L.Ak1/  L.Ak2/ and k1 < k2.
While we cannot have precise construction of X1 D X2X3, it would be of interest
to deﬁne A(X1 D X2X3, A1, A2, A3) that returns the tightest regular under-
approximation of X1 D X2X3. We say a regular under-approximation A is tightest
if L.A/ is an under-approximation of X1 D X2X3 and for all A0 where A0 is an
under-approximation of X1 D X2X3 we have L.A0/  L.A/. Since the precision
of a regular under-approximation can be always improved by adding new words to
the language, the tightest regular under-approximation does not exist if L.A2/ is not
ﬁnite.
5.5
Symbolic Reachability Analysis
Based on the constructions we discussed above, we can further deﬁne a function
A(exp:word equation, b:bool) that takes a word equation as input and returns a
corresponding multi-track DFA, if necessary either over-approximating (if b D C)
or under-approximating (if b D ). We can use the A function to soundly approx-
imate all word equations and their boolean combinations, including existentially-
quantiﬁed word equations. The boolean operations conjunction, disjunction, and
negation on word equations are handled using intersection, disjunction, and comple-
ment of the corresponding multi-track DFAs, respectively; existentially-quantiﬁed
word equations are handled using homomorphisms (by projecting the track that
corresponds to the quantiﬁed variable).

66
5
Relational String Analysis
Given an assignment statement stmt of the form X WD exp we ﬁrst represent
it as a word equation of the form X0 D exp where exp is an expression on the
current state variables, and X0 denotes the next state variables. Then we abstract
stmt by constructing a multi-track automaton Astmt that over-approximates the
corresponding word equation as follows Astmt = A(X0 D exp, C). A branch condition
speciﬁed as an expression exp is similarly abstracted using A(X0 D X ^ exp, C)
for the then branch and A(X0 D X ^ :exp,C) for the else branch. The result of the
regular abstraction consists of the control ﬂow graph of the original program where
each statement in the control ﬂow graph is associated with a multi-track DFA that
over-approximates the behavior of the corresponding statement.
The relational symbolic reachability analysis consists of two phases. In the
ﬁrst phase, we use one multi-track DFA for each program point to symbolically
represent possible values of string variables at that program point, where each track
corresponds to one string variable. Our approach is based on a forward ﬁxpoint
computation on multi-track DFAs. We iteratively compute post-images of reachable
states and join the results until we reach a ﬁxpoint.
It is possible to extend symbolic reachability analysis to an inter-procedural
analysis using function summaries. During the forward ﬁxpoint computation if
we encounter a call to a function that has not been summarized, we go to the
second phase of the analysis, which is function summarization. Each function is
summarized when needed, and once a function is summarized, the summary DFA is
used to compute the return values at the call sites without going through the body of
the function. During the summarization phase, (recursive) functions are summarized
as unaligned multi-track DFAs that specify the relations among their inputs and
return values. We ﬁrst build (cyclic) dependency graphs to specify how the inputs
ﬂow to the return values. Each node in the dependency graph is associated with an
unaligned multi-track DFA that traces the relation among inputs and the value of
that node. We iteratively compute post images of reachable relations and join the
results until we reach a ﬁxpoint. Upon termination, the summary is the union of the
unaligned DFAs associated with the return nodes. To compose these summaries at
the call site, an alignment algorithm has been proposed in [134] to align (so that ’s
are right justiﬁed) an unaligned multi-track DFA.
This reachability analysis is sound but incomplete due to the following approxi-
mations: (1) regular approximation for non-linear word equations, (2) the widening
operation and (3) function summarization.
5.5.1
Forward Fixpoint Computation
The ﬁrst phase of the analysis is a standard forward ﬁxpoint computation on multi-
track DFAs. Each program point is associated with a single multi-track DFA, where
each track is associated with a single string variable X 2 X. We use AŒl to denote
the multi-track automaton at the program label l. The forward ﬁxpoint computation
algorithm (Algorithm 1) is a standard work-queue algorithm.

5.5
Symbolic Reachability Analysis
67
Algorithm 1 RELATIONALFORWARDRECAHABILITY(l0)
1: Init(A);
2: queue WQ;
3: WQ.enqueue(l0 W stmt0);
4: while WQ ¤ NULL do
5:
e := WQ.dequeue(); Let e be l W stmt;
6:
if stmt is seqstmt then
7:
m := POST(AŒl; stmt);
8:
PROPAGATE(m, l C 1);
9:
end if
10:
if stmt is if exp goto l0 then
11:
m := AŒlu A(exp, C);
12:
if L.m/ ¤ ; then
13:
PROPAGATE(m, l0);
14:
end if
15:
m := AŒlu A(:exp, C);
16:
if L.m/ ¤ ; then
17:
PROPAGATE(m, l C 1);
18:
end if
19:
end if
20:
if stmt is assert exp then
21:
m := A(exp, );
22:
if L.AŒl/ 6 L.m/ then
23:
ASSERTFAILED(l);
24:
else
25:
PROPAGATE(AŒl,l C 1);
26:
end if
27:
end if
28:
if stmt is goto L then
29:
for l0 2 L do
30:
PROPAGATE(AŒl,l0);
31:
end for
32:
end if
33: end while
Algorithm 2 PROPAGATE(m, l)
1: m0 := .m t AŒl/rAŒl;
2: if m0 6v AŒl then
3:
AŒl := m0;
4:
WQ.enqueue(l);
5: end if
Initially, for all labels l, L.AŒl/ D ;. We iteratively compute the post-images of
the statements and join the results to the corresponding automata. For a stmt in the
form: X:= sexp, the post-image is computed as:
POST.A; stmt/ 	 .9X:A u A.X0 D sexp; C//ŒX=X0:

68
5
Relational String Analysis
A(exp, b) calls the corresponding construction function, e.g., AC(X1 D X2X3, A1,
A2, A3), to return the DFA that accepts a regular approximation of exp, where
b 2 fC; g indicates the direction (over or under, respectively) of approximation if
needed. During the construction, we recursively push the negations (:) (and ﬂip
the direction) inside to the basic expressions (bexp), and use the corresponding
construction of multi-track DFAs discussed in the previous section.
During the ﬁxpoint computation, we report assertion failures if AŒl accepts some
string that violates the assertion labeled l. Note that at line 21 we compute an under
approximation of the assertion expression to ensure the soundness of our analysis.
Finally, a program label l is not reachable if L.AŒl/ is empty.
5.5.2
Summarization
We use function summaries to handle function calls. Each function f is summarized
as a ﬁnite state transducer, denoted as Af , which captures the relations among
input variables (parameters), denoted as Xp, and return values. The return values
are tracked in the output track, denoted as Xo. We discuss the generation of the
transducer Af below. For a stmt in the form X:= call f.e1; : : : ; en/, the post-image
is computed as:
POST.A; stmt/ 	 .9X; Xp1; : : : Xpn:A u AI u Af /ŒX=Xo;
where AI = A(V
i Xpi D ei, C). The process terminates when we reach a ﬁxpoint.
To accelerate the ﬁxpoint computation, we extend automata widening operators (dis-
cussed in Sect. 6.5), denoted as r, to multi-track automata. We identify equivalence
classes according to speciﬁc equivalence conditions and merge states in the same
equivalence class [17, 23]. The equality relations among tracks are preserved while
widening multi-track automata. That is, if L.A/  L.x D y/ and L.A0/  L.x D y/,
L.ArA0/  L.x D y/.
5.6
Summary
In this Chapter, we discussed the relational string veriﬁcation techniques based on
multi-track automata. The presented approach is capable of verifying properties that
depend on relations among string variables. We discussed the basic word equations
(over string concatenations) and the corresponding automata constructions. The
presented veriﬁcation technique is based on forward symbolic reachability analysis
with multi-track automata, conservative approximations of word equations and
function summarization.

Chapter 6
Abstraction and Approximation
Verifying string manipulating programs is a crucial problem in computer security.
String operations are used extensively within web applications to manipulate user
input, and their erroneous use is the most common cause of security vulnerabilities
in web applications. Unfortunately, verifying string manipulating programs is an
undecidable problem in general and any approximate string analysis technique has
an inherent tension between efﬁciency and precision. In this Chapter we present a
set of sound abstractions for strings and string operations that allow for both efﬁcient
and precise veriﬁcation of string manipulating programs. Particularly, we are able
to verify properties that involve implicit relations among string variables. We ﬁrst
describe an abstraction called regular abstraction which enables us to perform string
analysis using multi-track automata as a symbolic representation. We then introduce
two other abstractions—alphabet abstraction and relation abstraction—that can be
used in combination to tune the analysis precision and efﬁciency. We show that the
relation and alphabet abstractions can be composed with the regular abstraction (and
with each other) to obtain a family of abstractions. In fact, these abstractions form an
abstraction lattice that generalizes the string analysis techniques studied previously
in isolation, such as size analysis or non-relational string analysis.
6.1
Regular Abstraction
The regular abstraction maps a set of string tuples to a set of string tuples accepted
by a multi-track automaton. This enables us to use deterministic ﬁnite state automata
(DFAs) as a symbolic representation during string analysis. As we discussed earlier,
a multi-track automaton (or multi-track DFA) is a DFA that has transitions on tuples
of characters rather than single characters. For a given alphabet ˙ let ˙ D ˙[fg,
where  … ˙ is a special padding character. An n-track alphabet is deﬁned as
˙n D ˙  
 
 
  ˙ (n times). A track corresponds to a particular position in the
© Springer International Publishing AG 2017
T. Bultan et al., String Analysis for Software Veriﬁcation and Security,
https://doi.org/10.1007/978-3-319-68670-7_6
69

70
6
Abstraction and Approximation
n-tuple. A multi-track DFA is aligned if and only if for all words w accepted by
the DFA, w 2 ˙ (i.e., all padding is at the end of the word). Using aligned
multi-track automata gives us a representation that is closed under intersection and
can be converted to a canonical form after determinization and minimization. In
the following, multi-track DFAs are assumed to be aligned unless explicitly stated
otherwise.
As we discussed earlier, the statements of a string manipulating program can
be represented as word equations. A word equation is an equality relation between
two terms, each of which is a ﬁnite concatenation of string variables and string
constants. Regular abstraction abstracts a given program by mapping the word-
equations representing the program statements to multi-track DFAs. Since word
equations can not be precisely represented using multi-track automata, we use the
results presented in the previous chapter to construct a sound abstraction of the given
program (i.e., in the abstracted program the set of values that a variable can take is
a superset of the possible values that a variable can take in the concrete program).
Note that, since branch conditions can contain negated terms, we need to be able
to construct both an over- and an under-approximation of a given word equation.
We construct multi-track automata that precisely represent word equations when
possible, and either over- or under-approximate the word equations (as desired)
otherwise.
The abstract domain that results from the regular abstraction is deﬁned as a lattice
on multi-track automata over an alphabet ˙n. We denote this automata lattice as
LA D .A˙n; v; t; u; ?; >/, where A˙n is the set of multi-track automata over the
alphabet ˙n. For A1; A2 2 A˙n, A1 v A2 if and only if L.A1/  L.A2/. The bottom
element is deﬁned as L.?/ D ; and the top element is deﬁned as L.>/ D .˙n/.
There may be multiple automata that accept the same language; the lattice treats
these automata as equivalent. If we use minimized DFAs then there is a unique
automaton for each point in the lattice up to isomorphism. All of the multi-track
automata in this lattice are aligned [133] and hence all operations take aligned
automata as input and return aligned automata as output.
Since the family of regular languages is not closed under inﬁnite union, we
can use the widening operator from [17] as the join operator where A1 t A2 D
A1rA2. The meet operator can be deﬁned from the join operator using language
complement: let :A denote an automaton such that L.:A/ D L.>/  L.A/; then
A1 u A2 D :.:A1r:A2/.
Note that a similar automata lattice can also be deﬁned for single-track automata
over a single-track alphabet ˙ where LA D .A˙; v; t; u; ?; >/ as we discussed in
Chap. 4.
6.2
Alphabet Abstraction
This abstraction targets the values taken on by string variables, mapping multiple
alphabet symbols to a single abstract symbol. For example, consider a string variable
that can take the value fab; abcg from the alphabet ˙ D fa; b; cg. Abstracting the

6.2
Alphabet Abstraction
71
Fig. 6.1 The transducer
A˙;˙0 for alphabet abstraction
Fig. 6.2 An example DFA A,
where L.A/ D a < bC
Fig. 6.3 Extend A to a two-track automata A2
symbols b and c yields the value fa; a  g, where  stands for both b and c.
The concretization of this abstract value would yield the value fab; ac; abc; abb;
acb; accg. At the extreme, this abstraction can abstract out all alphabets symbols (in
the above example, this would yield the abstract value f;   g). In this case
the only information retained from the original value is the length of the strings; all
information about the content of the strings is lost. This abstraction is still useful in
checking properties related to string length—we will return to this point in Sect. 6.4.
Before giving formal deﬁnitions, let us start from a simple example. Consider
the concrete alphabet ˙ D fa; b; c; <g and the abstract alphabet ˙0 D f<; g,
where we intended to abstract away all symbols as  except <. We ﬁrs construct a
two track automata (also known as transducer) that maps the input track (concrete
values) to the output track (abstract values). In this case, we build A˙;˙0 as shown
in Fig. 6.1. The transducer can then be used to abstract concrete string values of an
automaton to its abstract string values (abstraction), or to concretize abstract string
values of an automaton to its concrete string values (concretization). Consider an
example DFA A that accepts a < bC as show in Fig. 6.2. Below we show how to
conduct abstraction and concretization with the transducer shown in Fig. 6.1.
The abstraction step is to construct an automata A˛ that accepts the abstract
strings of A. To do so, we ﬁrst extend A to a two track DFA A2 that has strings
in the ﬁrst track in L.A/ but arbitrary strings in the second track (Fig. 6.3). In these
ﬁgures, we use “*” to denote any alphabet symbol. Then, we take the intersection of
A2 and A˙;˙0 to restrict the string values in the second track to the abstract strings of
the values in the ﬁrst track. This step for our example results in A2
˛ (Fig. 6.4). As the
ﬁnal step of abstraction, we simply project away the ﬁrst track of A2
˛, and the result
is the automata A˛, where L.A˛/ D  < C, which accepts the set of abstract
strings of A (Fig. 6.5).

72
6
Abstraction and Approximation
Fig. 6.4 Take the intersection of A2 and A˙;˙0 as A2
˛
Fig. 6.5 The abstract
automata A˛ can be computed
by projecting away the ﬁrst
track of A2
˛
Fig. 6.6 Extend the abstract automata A˛ a two-track automata A2
˛
Fig. 6.7 Take the
intersection of A2
˛ and A˙;˙0
as A2

Fig. 6.8 The concrete
automata A (from A˛) can be
computed by projecting away
the second track of A2

The concretization step is to construct an automata that accepts the concrete
string values of the language of an abstract automata. To construct an automata
A that accepts the concrete strings of an abstract automata A˛ (Fig. 6.5), we ﬁrst
extend A˛ to a two track DFA A2
˛ (Fig. 6.6) that has strings in the second track
in L.A˛/ but arbitrary strings in the ﬁrst track. Similar to the abstraction step, we
take the intersection of A2
˛ and A˙;˙0 to restrict the string values in the ﬁrst track
corresponding the concrete strings of the values in the second track. In our example,
this step results in A2
 (Fig. 6.7), where the concrete string of the abstract string
in the second track is now in the ﬁrst track. As the ﬁnal step, we simply project
away the second track of A2
, and the result is the automata A (Fig. 6.8), where
L.A/ D .ajbjc/ < .ajbjc/C, which accepts all the concrete strings that can be
mapped to the abstract strings in L.A˛/ (Fig. 6.5). Note that L.A/ is a super set of
L.A/ (Fig. 6.2).
Let us formally deﬁne the alphabet abstraction. The alphabet abstraction is
parameterized by the choice of which symbols to abstract, hence it forms a family of
abstractions. This family forms an abstraction lattice L˙ called the alphabet lattice

6.2
Alphabet Abstraction
73
(distinct from the automata lattice introduced earlier). Let ˙, a ﬁnite alphabet, be the
concrete alphabet, and  62 ˙ be a special symbol to represent characters that are
abstracted away. An abstract alphabet of ˙ is deﬁned as ˙0 [ fg, where ˙0  ˙.
The abstract alphabets of ˙ form a complete lattice L˙ D .P.˙ [ fg/; v˙
; [; \; ?; >/ where the bottom element ? is ˙ [ fg, the top element > is
fg, and the join and meet operations correspond to set intersection and union,
respectively. The abstraction > corresponds to mapping all the symbols in the
concrete alphabet to a single symbol, whereas ? corresponds to no abstraction at
all. The partial order of L˙ is deﬁned as follows. Let 1; 2 be two elements in L˙,
1 v˙ 2; if 2  1; and 1 @˙ 2; if 1 v˙ 2 and 1 ¤ 2:
Let 1 v˙ 2. We deﬁne the representation function for alphabet abstraction as
follows: ˇ1;2 W ˙ ! ˙ where
ˇ1;2.w/ D fw0 j jw0j D jwj; 8i 1  i  jwj:.w.i/ 2 2 ) w0.i/ D w.i//
^.w.i/ 62 2 ) w0.i/ D /g:
The representation function simply maps the symbols that we wish to abstract to the
abstract symbol , and maps the rest of the symbols to themselves.
Since the symbolic analysis we deﬁned in Sect. 6.1 uses automata as a symbolic
representation, we have to determine how to apply the alphabet abstraction to
automata. We deﬁne the abstraction function ˛1;2 on automata using the repre-
sentation function ˇ1;2 as follows: Let A be a single track DFA over 1; then
˛1;2.A/ D A0 where A0 is a single track DFA over 2 such that L.A0/ D fw j
9w0 2 L.A/:ˇ1;2.w0/ D wg.
Note that there may be multiple automata A0 that satisﬁes this constraint.
However, since we use minimized multi-track DFAs they will all be equivalent.
We deﬁne the concretization function 2;1 similarly: Let A be a single track DFA
over 2; then 1;2.A/ D A0 where A0 is a single track DFA over 1 such that
L.A0/ D fw j 9w0 2 L.A/:ˇ1;2.w/ D w0g.
The deﬁnitions we give above are not constructive. We give a constructive
deﬁnition of the abstraction and concretization functions by ﬁrst deﬁning an
alphabet-abstraction-transducer that maps symbols that we wish to abstract to the
abstract symbol , and maps the rest of the symbols to themselves.
An alphabet-abstraction-transducer over 1 and 2 is a 2-track DFA A1;2 D
hQ; 1  2; ı; q0; Fi, where
•
Q D fq0; sinkg, F D fq0g, and
•
8a 2 2:ı.q0; .a; a// D q0,
•
8a 2 1  2:ı.q0; .a; // D q0.
Now, using the alphabet-abstraction-transducer, we can compute the abstraction
of a DFA as a post-image computation, and we can compute the concretization of
DFA as a pre-image computation. Let A be a single track DFA over 1 with track
X. A1;2.X; X0/ denotes the alphabet transducer over 1 and 2 where X and X0

74
6
Abstraction and Approximation
correspond to the input and output tracks, respectively. We deﬁne the abstraction
and concretization functions on automata as (where X0 7! X denotes renaming track
X0 as X):
•
˛1;2.A/ 	 .9X:A u A1;2.X; X0//ŒX0 7! X, and
•
1;2.A/ 	 9X0:.AŒX 7! X0 u A1;2.X; X0//.
The deﬁnition can be extended to multi-track DFAs. Let A be a multi-track DFA
over n
1 associated with fXi j 1  i  ng, ˛n
1 ;n
2 .A/ returns a multi-track DFA
over n
2. On the other hand, while A is a multi-track DFA over n
2 , n
1 ;n
2 .A/ returns
a multi-track DFA over n
1 . We use An
1 ;n
2 to denote the extension of the alphabet
transducer to multi-track alphabet, where we add ı.q0; .; // D q0 to An
1 ;n
2 to
deal with the padding symbol  and we use An
1 ;n
2 .Xi; X0
i/ to denote the alphabet
transducer associated with tracks Xi and X0
i. The abstraction and concretization of a
multi-track DFA A is done track by track as follows:
•
˛n
1 ;n
2 .A/ 	 8Xi:.9Xi:A u An
1 ;n
2 .Xi; X0
i//ŒX0
i 7! Xi, and
•
n
1 ;n
2 .A/ 	 8Xi:.9X0
i:AŒXi 7! X0
i u An
1 ;n
2 .Xi; X0
i//.
The abstraction lattice L˙ deﬁnes a family of Galois connections between the
automata lattices LA. Each element n in the abstraction lattice L˙n is associated
with an automata lattice Ln corresponding to multi-track automata with the
alphabet n. For any pair of elements in the abstraction lattice n
1 ; n
2 2 L˙n, if
n
1 @˙ n
2, then we can deﬁne a Galois connection between the corresponding
automata lattices Ln
1 and Ln
2 using the abstraction and concretization functions
˛n
1 ;n
2 and n
1 ;n
2 . We formalize this with the following property:
For any ˙n, and n
1; n
2 2 L˙n, if n
1 @˙ n
2 , the functions ˛n
1 ;n
2 and n
1 ;n
2 deﬁne
a Galois connection between the lattices Ln
1 and Ln
2 where for any A1 2 Ln
1 and
A2 2 Ln
2 :
˛n
1 ;n
2 .A1/ v A2 , A1 v n
1 ;n
2 .A2/
6.3
Relation Abstraction
In this section, we deﬁne the relation abstraction. This abstraction targets the
relations between string variables. The abstraction determines the sets of variables
that will be analyzed in relation to each other; for each such set the analysis
computes a multi-track automaton for each program point such that each track of
the automaton corresponds to one variable in that set. In the most abstract case
no relations are tracked at all—there is a separate single-track automaton for each
variable and the analysis is completely non-relational. On the other hand, in the most
precise case we have one single multi-track automaton for each program point.
Let X D fX1; : : : Xng be a ﬁnite set of variables. Let 	  2X where ; 62 	. We say
	 deﬁnes a relation of X if (1) for any x; x0 2 	, x 6 x0, and (2) S
x2	 x D X. The
set of 	 that deﬁnes the relations of X form a complete lattice, denoted as LX.

6.3
Relation Abstraction
75
•
The bottom of the abstraction lattice, denoted as 	?, is ffX1; X2; : : : ; Xngg. This
corresponds to the most precise case where, for each program point, a single
multi-track automaton is used to represent the set of values for all string variables
where each string variable corresponds to one track. This is the representation
used in the symbolic reachability analysis described in Chap. 5.
•
The top of the abstraction lattice, denoted as 	>, is ffX1g; fX2g; fX3g; : : : ; fXngg.
This corresponds to the most coarse abstraction where, for each program point,
n single-track automata are used and each automaton represents the set of
values for a single string variable. This corresponds to the approach we used
in Chap. 4 [13].
The partial order of the abstraction lattice LX is deﬁned as follows: Let 	1; 	2 be
two elements in LX,
•
	1 vX 	2, if for any x 2 	2, there exists x0 2 	1 such that x  x0.
•
	1 @X 	2 if 	1 vX 	2 and 	1 ¤ 	2.
The automata-based symbolic reachability analysis discussed in earlier chapters
can be generalized to a symbolic reachability analysis that works for each abstrac-
tion level in the abstraction lattice LX. To conduct symbolic reachability analysis for
the relation abstraction 	 2 LX, we store j	j multi-track automata for each program
point, where for each x 2 	, we have a jxj-track DFA, denoted as Ax, where each
track is associated with a variable in x.
In order to deﬁne the abstraction and the concretization functions, we deﬁne
the following projection and extension operations on automata. For x0  x, the
projection of Ax to x0, denoted as Ax #x0, is deﬁned as the jx0j-track DFA that accepts
fw0 j w 2 L.Ax/; 8Xi 2 x0:w0Œi D wŒi/g. Similarly, x0  x, the extension of Ax0
to x, denoted as Ax0 "x, is deﬁned as the jxj-track DFA that accepts fw j w0 2
L.Ax0/; 8Xi 2 x0:wŒi D w0Œi/g.
Let A D fAx j x 2 	g be a set of DFAs for the relation 	. The set of string
values represented by A is deﬁned as: L.A/ D L.
x2	 Ax "xu/, where xu D
fX1; X2; : : : ; Xng. I.e., we extend the language of every automaton in A to all string
variables and then take their intersection.
Now, let us deﬁne the abstraction and concretization functions for the relation
abstraction (which take a set of multi-track automata as input and return a set of
multi-track automata as output).
Let 	1 @X 	2; then ˛	1;	2.A1/ returns a set of DFAs fAx0 j x0 2 	2g, where
for each x0 2 	2, Ax0 D .
x2	1;x0\x¤; Ax "xu/ #x0, where xu D fXi j Xi 2 x; x 2
	1; x0 \ x ¤ ;g.
	1;	2.A2/ returns a set of DFAs fAx j x 2 	1g, where for each x 2 	1, Ax D
.
x02	2;x0\x¤;.Ax0 "xu// #x, where xu D fXi j Xi 2 x0; x0 2 	2; x0 \ x ¤ ;g.
Similar to the alphabet abstraction, the relation abstraction lattice LX also deﬁnes
a family of Galois connections. Each element of the relation abstraction lattice
corresponds to a lattice on sets of automata. For each 	 2 LX we deﬁne a lattice
L	 D .A	; v; t; u; ?; >/. Given two sets of automata A; A0
 2 A, A v A0

if and only if L.A/  L.A0
/. The bottom element is deﬁned as L.?/ D ;

76
6
Abstraction and Approximation
and the top element is deﬁned as L.>/ D .˙n/. The join operator is deﬁned as:
A t A0
 D fAxrA0
x j x 2 	; Ax 2 A; A0
x 2 A0
g and the meet operator is deﬁned
as: A u A0
 D f:.:Axr:A0
x/ j x 2 	; Ax 2 A; A0
x 2 A0
g.
For any pair of elements in the relation abstraction lattice 	1; 	2 2 LX, if 	1 @X
	2, then the abstraction and concretization functions ˛	1;	2 and 	1;	2 deﬁne a Galois
connection between L	1 and L	2. We formalize this with the following property:
For any 	1; 	2 2 LX, if 	1 @X 	2, then the functions ˛	1;	2 and 	1;	2 deﬁne a
Galois connection between L	1 and L	2 where for any A	1 2 L	1 and A0
	2 2 L	2:
˛	1;	2.A1/ v A0
2 , A1 v n
1 ;n
2 .A0
2/
6.4
Composing Abstractions
As shown in the two previous sections, both alphabet and relation abstractions form
abstraction lattices which allow different levels of abstraction. Combining these
abstractions leads to a product lattice where each point in this lattice corresponds
to the combination of a particular alphabet abstraction with a particular relation
abstraction. This creates an even larger set of Galois connections, one for each
possible combination of alphabet and relation abstractions. Given ˙ and X D
fX1; : : : ; Xng, we deﬁne a point in this product lattice as an abstraction class which
is a pair .	; / where 	 2 LX and  2 L˙. The abstraction classes of X and ˙ also
form a complete lattice, of which the partial order is deﬁned as: .	1; 1/ v .	2; 2/
if 	1 v 	2 and 1 v 2.
Given ˙ and X D fX1; : : : ; Xng, we can select any abstraction class in the product
lattice during our analysis. The selected abstraction class .	; / determines the
precision and efﬁciency of our analysis. If we select the abstraction class .	?; ?/,
we conduct our most precise relational string analysis. The relations among X will
be kept using one n-track DFA at each program point. If we select .	>; >/, we only
keep track of the length of each string variable individually. Although we abstract
away almost all string relations and contents in this case, this kind of path-sensitive
(w.r.t length conditions on a single variable) size analysis can be used to detect
buffer overﬂow vulnerabilities [36, 115]. If we select .	?; >/, then we will be
conducting relational size analysis. Finally, earlier string analysis techniques that
use DFAs, such as [13, 130], correspond to the abstraction class .	>; ?/, where
multiple single-track DFAs over ˙ are used to encode reachable states. As shown
in [13, 126, 130], this type of analysis is useful for detecting XSS and SQL Injection
vulnerabilities.
Figure 6.9 summarizes the different types of abstractions that can be obtained
using the abstraction framework we deﬁned. The alphabet and relation abstractions
can be seen as two knobs that determine the level of the precision of the string
analysis. The alphabet abstraction knob determines how much of the string content

6.5
Automata Widening Operation
77
Fig. 6.9 Some abstractions
from the abstraction lattice
and corresponding analyses
is abstracted away. In the limit, the only information left about the string values
is their lengths. On the other hand, the relation abstraction knob determines which
set of variables should be analyzed in relation to each other. In the limit, all values
are projected to individual variables. Different abstraction classes can be useful in
different cases.
6.5
Automata Widening Operation
The symbolic reachability analysis is a least ﬁxpoint computation. The process
terminates when a ﬁxpoint is reached. Since string systems are inﬁnite state systems,
the iterative reachability computation is not guaranteed to terminate. We incorporate
an automata widening operator that was proposed in [17], to accelerate the ﬁxpoint
computation. During the widening operation, we partition the states of the automata
to equivalence classes according to speciﬁc equivalence conditions and merge states
in the same equivalence class. We use the same equivalence conditions deﬁned
in [17] in our implementation of the widening operator.
Given two ﬁnite automata A D hQ; q0; ˙; ı; Fi and A0 D hQ0; q0
0; ˙; ı0; F0i, we
ﬁrst deﬁne the binary relation 	r on Q [ Q0 as follows. Given q 2 Q and q0 2 Q0,
we say that q 	r q0 and q0 	r q if and only if
8w 2 ˙: ı.q; w/ 2 F , ı0.q0; w/ 2 F0:
(6.1)
or q; q0 ¤ sink ^ 9w 2 ˙: ı.q0; w/ D q ^ ı0.q0
0; w/ D q0;
(6.2)
where ı.q; w/ is deﬁned as the state that A reaches after consuming w starting from
state q. In other words, condition 6.1 states that q 	r q0 if 8w 2 ˙, w is accepted
by A from q then w is accepted by A0 from q0, and vice versa. Condition 6.2 states
that q 	r q0 if 9w 2 , A reaches state q and A0 reaches state q0 after consuming w
from its initial state. For q1; q2 2 Q and q1 ¤ q2 we say that q1 	r q2 if and only if
9q0 2 Q0: q1 	r q0 ^ q2 	r q0 _ 9q ¤ q1; q2 2 Q: q1 	r q ^ q2 	r q
(6.3)
Similarly we can deﬁne q0
1 	r q0
2 for q0
1 2 Q0 and q0
2 2 Q0.

78
6
Abstraction and Approximation
Fig. 6.10 Widening automata. (a) A. (b) A0. (c) ArA0
It can be seen that 	r is an equivalence relation. Let C be the set of equivalence
classes of 	r. We deﬁne ArA0 D hQ00; q00
0; ˙; ı00; F00i by:
Q00 D C
q00
0 D c s.t. q0 2 c ^ q0
0 2 c
ı00.ci; / D cj s.t.
.8q 2 ci \ Q: ı.q; / 2 cj _ ı.q; / D sink/^
.8q0 2 ci \ Q0: ı0.q0; / 2 cj _ ı0.q0; / D sink/
F00 D f c j 9q 2 F [ F0: q 2 c g
In other words, the set of states of ArA0 is the set C of equivalence classes of 	r.
Transitions are deﬁned from the transitions of A and A0. The initial state is the class
containing the initial states q0 and q0
0. The set of ﬁnal states is the set of classes that
contain some of the ﬁnal states in F and F0. It can be shown that, given two automata
A and A0, L.A/ [ L.A0/  L.ArA0/ [17].
In Fig. 6.10, we give an example for the widening operation. L.A/ D f; abg
and L.A0/ D f; ab; ababg. The set of equivalence classes is C D fq00
0; q00
1g, where
q00
0 D fq0; q0
0; q2; q0
2; q0
4g and q00
1 D fq1; q0
1; q0
3g. L.ArA
0/ D .ab/.
As we discussed in earlier chapters, we use this widening operator iteratively
to compute an over-approximation of the least ﬁxpoint that corresponds to the
reachable values of string expressions. To simplify the discussion, let us assume
a program with a single string variable represented with one automaton A. Let Ai
represent the automaton computed at the ith iteration and let I denote the set of initial
values of the string variable. The ﬁxpoint computation will compute a sequence A0,
A1, . . . , Ai, . . . , where L.A0/ D I and L.Ai/ D L.Ai1/ [ L.POST.Ai1// where the
post-image for different statements can be computed as described in Chap. 4.

6.5
Automata Widening Operation
79
Formally speaking, L.A/ is a ﬁxpoint if L.A/= L.A/[L.POST.A//. L.A1/ is the
least ﬁxpoint if L.A1/ is a ﬁxpoint and for all other ﬁxpoint L.A/, L.A1/  L.A/.
We reach the least ﬁxpoint L.A1/ D L.Ai/ at the ith iteration when L.Ai/ D
L.Ai1/. Since we are dealing with an inﬁnite state system, the ﬁxpoint computation
may not converge.
Given the widening operator, we actually compute a sequence A0
0, A0
1, . . . ,
A0
i, . . . , that over-approximates the ﬁxpoint computation where A0
i is deﬁned as:
L.A0
0/ D L.A0/, and for i > 0, L.A0
i/ D L.A0
i1rAi/, where L.Ai/ D L.A0
i1/ [
L.POST.A0
i1//.
Let A0
1 denote the limit of this approximate sequence where there exists a j,
L.A0
1/ D L.A0
j/ D L.A0
j1/. Then we have the following result from [17]. We say
A1 D hQ1; q10; ˙; ı1; F1i is simulated by A2 D hQ2; q20; ˙; ı2; F2i if and only if
there exists a total function f W Q1 n fsinkg ! Q2 such that ı1.q; / D sink or
f.ı1.q; // D ı2.f.q/; / for all q 2 Q1 n fsinkg and  2 ˙. Furthermore, f.q10/ D
q20 and for all q 2 F1, f.q/ 2 F2. We say A D hQ; q0; ˙; ı; Fi is state-disjoint if
and only if for all q ¤ q0 2 Q, L.q/ ¤ L.q0/, where L.k/ D fw j ı.k; w/ 2 Fg, for
k 2 Q.
It has been shown that if (1) A1 exists, (2) A1 is a state-disjoint automaton,
and (3) A0 is simulated by A1, then if A0
1 exists (i.e., if the approximate sequence
converges) then L.A0
1/ D L.A1/.
Consider a simple program where a variable initialized to the empty string and
in each iteration of a loop the substring ab is concatenated to the variable. When
we use the symbolic forward reachability algorithm, the exact sequence A0, A1, . . . ,
Ai, : : : will never converge to the least ﬁxpoint, where L.A0/ D fg and L.Ai/ D
f.ab/k j 0  k  ig. However, A1 exists and L.A1/ D .ab/. In addition, A1
is a state-disjoint automaton, and A0 is simulated by A1. These conditions imply
that once the computation of the approximate sequence reaches the ﬁxpoint, the
ﬁxpoint is equal to A1 and the analysis is precise. Computation of the approximate
sequence is shown in Fig. 6.11. L.A0
i/ D L.A0
i1rAi/, where L.Ai/ D L.A0
i1/ [
L.POST.A0
i1// and POST.A/ returns an automaton that accepts fwab j w 2 L.A/g.
In this case, we reach the ﬁxpoint at the second iteration and A0
1 D A1 D A0
2.
A more general case that we commonly encounter in real programs is that we
start from a set of initial strings (accepted by Ainit), and concatenate an arbitrary
but ﬁxed set of strings (accepted by Atail) at each iteration. Based on the discussion
above, one can conclude that if the DFA A that accepts L.Ainit/L.Atail/ is state-
disjoint, then our analysis via widening will reach the precise least ﬁxpoint when it
terminates.
Fig. 6.11 The approximate
sequence of a converging
example. (a) A0
0. (b) A1. (c)
A0
1 and A0
2

80
6
Abstraction and Approximation
Fig. 6.12 The approximate sequence of a non-regular example. (a) A0
1. (b) A0
2. (c) A00
2
The automata widening operator deﬁned in [17] has two variations and only
the coarser version guarantees convergence. The coarser widening operator rc
is deﬁned the same as r except that we discard the condition q; q0 ¤ sink in
Eq. (6.2). In our implementation we start with the more precise version (r) and
after a constant number of steps switch to the coarser version (rc) to guarantee
convergence.
In general, the least ﬁxpoint L.A1/ may not exist, or even if it exists, the
language may not be regular. For instance, if we change the previous example to
that POST.A/ returns an automaton that accepts fawb j w 2 L.A/g instead, we
will have L.Ai/ D fakbk j 0  k  ig. Though the least ﬁxpoint L.A1/ D
fanbn j 0  ng exists, it is not a regular language. Let L.A0/ D L.A0
0/ D fg.
For the above example, A0
1 D A0
0r.A0
0 t POST.A0
0// and A0
2 D A0
1r.A0
1 t POST.A0
1//
are shown in Fig. 6.12a, b, respectively. The sequence does not converge. On the
other hand, if we apply the coarser widening operator at the second iteration, we get
A00
2 D A0
1rc.A0
1 t POST.A0
1// shown in Fig. 6.12c, and reach the ﬁxpoint at the next
iteration. The result is an over approximation of the least ﬁxpoint L.A1/.
6.6
Summary
Verifying string manipulating programs is an undecidable problem in general
and any approximate string analysis technique has an inherent tension between
efﬁciency and precision. In this Chapter we discussed a set of sound abstractions
and approximations for strings and string operations that allow for both efﬁcient
and precise veriﬁcation of string manipulating programs. Particularly, we introduced
two string abstractions—alphabet abstraction and relation abstraction—that can be

6.6
Summary
81
used in combination to tune the analysis precision and efﬁciency. We showed that
these abstractions form an abstraction lattice that generalizes the string analysis
techniques studied previously in isolation, such as size analysis or non-relational
string analysis. We also discussed the widening operation to approximate the set
of states that are characterized by automata. Widening is crucial for accelerating
ﬁxpoint computations and achieving convergence.

Chapter 7
Constraint-Based String Analysis
Analysis of string manipulating programs has been studied extensively in recent
years. One of the commonly used program analysis technique, symbolic execution,
can be applied to string manipulating programs. However, symbolic execution
of string manipulating programs is difﬁcult since solving string constraints is a
challenging problem. String constraint solving is challenging due to two main
reasons: (1) With the increasing usage of strings in modern software development,
programming languages provide increasingly complex string operations that need
to be handled by string constraint solvers. (2) String constraints are usually mixed
with integer constrains which requires solving integer constraints together with
string constraints. In this chapter, we ﬁrst provide an illustrative example of
the symbolic execution of a string manipulating program. Then, we discuss the
details of automata-based constraint solving and model counting extension to string
constraint solving.
7.1
Symbolic Execution with String Constraints
Symbolic execution is a program analysis technique to determine what input values
cause each path of a program to execute [65]. Symbolic execution assumes symbolic
values for the program inputs rather than using concrete values as normal execution
of the program would. Expressions encountered during symbolic execution are
expressed as functions of the symbolic variables. At any point during symbolic
execution, program state is described with the value of the program counter and
with a symbolic expressions known as the path condition (PC). A PC is a constraint
on input values that must be satisﬁed in order for a program to reach the location
that PC corresponds. The set of all possible executions of a program is represented
by a symbolic execution tree.
© Springer International Publishing AG 2017
T. Bultan et al., String Analysis for Software Veriﬁcation and Security,
https://doi.org/10.1007/978-3-319-68670-7_7
83

84
7
Constraint-Based String Analysis
Fig. 7.1 A Java string
manipulation example
Figure 7.1 shows a JAVA string manipulation example originally presented
as a command injection example in an earlier work [89] and used as a string
constraint solving example in Symbolic Path Finder1 (SPF). It is part of the WU-
FTPD implementation of the ﬁle transfer protocol. It is originally written in C
programming language and the example is converted from the original version. If
the input command contains substring "%n" an exception is thrown at line 22. In the
original implementation, this situation would allow user to alter program stack and
gain privileged access to server running the program. This example demonstrates
one application of symbolic execution, it checks feasibility of program execution
paths that may lead to a vulnerability.
Figure 7.2 represents the symbolic execution tree of site_exec function
in the example. Symbolic execution tree is built on the ﬂy based on a traversal
strategy (e.g., depth-ﬁrst, breadth-ﬁrst). Symbolic execution tree of our running
example is created by exploring program paths with depth-ﬁrst exploration strategy.
1http://babelﬁsh.arc.nasa.gov/trac/jpf/wiki/projects/jpf-symbc.

7.1
Symbolic Execution with String Constraints
85
Fig. 7.2 Symbolic execution tree of the example code in Fig. 7.1
Rectangles represent updates on string expressions and diamonds represent branch
points encountered during symbolic execution. Initially, all program variables
are replaced with symbolic variables, cmd=CMD, p=P, j=J, sp=SP, r=R,
l=L, buf=BUF, t=T and initial PC is set to true, PC0 D true. At line 3
symbolic variable P is assigned to concrete string with value "home/ftp/bin".

86
7
Constraint-Based String Analysis
At line 4 symbolic variable SP is assigned to a function of symbolic variable CMD.
Line 6 corresponds to a branch point where it checks the condition on symbolic
variable SP. In order to continue with the symbolic execution, PC is updated with
constraints on the symbolic variables for alternative paths, i.e., PC1 W SP D 1
and later on PC6 W SP ¤ 1 are generated. Satisﬁability of PC1 is checked using
string constraint solvers; if it is satisﬁable, symbolic execution continues to explore
deeper. Otherwise, if a path condition is unsatisﬁable, symbolic execution does not
continue for that path and it backtracks and checks satisﬁability of alternative PCs.
In the example, the symbolic execution tree shows six different feasible paths
represented by path constraints PC2, PC4, PC5, PC7, PC9, and PC10. Among
those PC4 and PC9 characterizes concrete program executions that can exploit the
vulnerability with the following conditions:
PC4 W SP D 1 ^ L  32 ^ T
PC9 W SP ¤ 1 ^ L  32 ^ T
where each PC can be expanded by writing them as function of symbolic variable
CMD:
PC4 W CMD:indexOf.0 0/ D 1 ^
CMD:substring.CMD:lastIndexOf.0=0//:length./ C
“home=ftp=bin00:length./  32 ^ .“home=ftp=bin00C
CMD:substring.CMD:lastIndexOf.0=0///:contains.“%n00/
PC9 W CMD:indexOf.0 0/ ¤ 1 ^
CMD:substring.CMD:lastIndexOf.0=0; CMD:indexOf.0 0///:length./
C “home=ftp=bin00:length./  32 ^ .“home=ftp=bin00C
CMD:substring.CMD:lastIndexOf.0=0; CMD:indexOf.0 0////
:contains.“%n00/
Expanded versions of path constraints PC4 and PC9 shows that string constraints
can be mixed with integer constraints. There are also complex string functions such
as lastIndexOf and substring where the result of the former can be a parameter to
the latter as in the above PCs. Type of the constraints that we get from the example
shows that string constraint solving is essential for symbolic execution of string
manipulating programs.

7.2
Automata-Based String Constraint Solving
87
7.2
Automata-Based String Constraint Solving
In the previous chapters we discussed how to construct automata for concatenation
and replace functions and word equations. In this section we discuss how to
construct automata for string constraints in general. Given a constraint and a
variable, our goal is to construct an automaton that accepts all strings, which, when
assigned as the value of the variable in the given constraint, results in a satisﬁable
constraint. This construction allows us to compute the post condition of both:
•
Branch statements: Since branch conditions are boolean expressions, i.e., con-
straints, and the post condition of a branch condition is the set of values that
satisfy the corresponding constraint; and
•
Assignment statements: Since we can rewrite the assignment statement v WD
sexpI as an equality v0 D sexp where v0 denotes the value of the variable v
after the assignment statement is executed, and computing the set of values for v0
that satisﬁes this constraint is equivalent the set of values v can take in the post
condition of the assignment statement.
Given a constraint F, let VF denote the set of variables that appear in F. Let
FŒs=v denote the constraint that is obtained from F by replacing all appearances
of v 2 VF with the string constant s. We deﬁne the truth set of the formula F for
variable v as F; v D fs j FŒs=v is satisﬁableg.
We identify three classes of constraints:
1. Single-variable constraints are constructed using at most one string variable (i.e.,
VF D fvg or VF D ;).
2. Pseudo-relational constraints are a set of constraints that we deﬁne in the next
section, for which the truth sets are regular (i.e., each F; v is a regular set).
3. Relational constraints are the constraints that are not pseudo-relational con-
straints (truth sets of relational constraints can be non-regular).
7.2.1
Mapping Constraints to Automata
Given a constraint F and a variable v, our goal is to construct an automaton A, such
that L.A/ D F; v. In this section, we focus on mapping string constraints to single-
track automata. In the next section we discuss constructing multi-track automata for
relational constraints.
7.2.1.1
Automata Construction for Single-Variable Constraints
Let us deﬁne an automata constructor function A such that, given a formula F and a
variable v, A.F; v/ is an automaton where L.A.F; v// D F; v. In this section we
discuss how to implement the automata constructor function A.

88
7
Constraint-Based String Analysis
Fig. 7.3 Syntax tree of the
formula
F  :match.x; .01// ^
length.x/  1
Fig. 7.4 The automata construction that traverses the syntax tree from the leaves towards the root
Consider the following string constraint F 	 :.x 2 .01// ^ length.x/  1 over
the alphabet ˙ D f0; 1g. Let us name the sub-constraints of F as C1 	 x 2 .01/,
C2 	 length.x/  1, F1 	 :C1, where F 	 F1 ^ C2. The automata construction
algorithm starts from the basic constraints at the leaves of the syntax tree (C1 and C2
in Fig. 7.3), and constructs the automata for them. Then it traverses the syntax tree
towards the root by constructing an automaton for each node using the automata
constructed for its children (where the automaton for F1 is constructed using the
automaton for C1 and the automaton for F is constructed using the automata for
F1 and C2). Figure 7.4 demonstrates the automata construction algorithm on our
running example.
Let A.˙/; A.˙n/; A.s/; and A.;/ denote automata that accept the languages
˙, ˙n, fsg, and ;, respectively. We construct the automaton A.F; v/ recursively
on the structure of the single-variable constraint F as follows:

7.2
Automata-Based String Constraint Solving
89
•
case VF D ; (i.e., there are no variables in F): Evaluate the constraint F. If
F 	 true then A.F; v/ D A.˙/, otherwise A.F; v/ D A.;/.
•
case F 	 :F1: A.F; v/ is constructed using A.F1; v/ and it is an automaton that
accepts the complement language ˙  L.A.F1; v//.
•
case F 	 F1 ^ F2 or F 	 F1 _ F2: A.F; v/ is constructed using A.F1; v/ and
A.F2; v/ using automata product, and it accepts the language A.F1; v/uA.F2; v/
or A.F1; v/ t A.F2; v/, respectively.
•
case F 	 match.v; R/: A.F; v/ is constructed using regular expression to
automata conversion algorithm and accepts all strings that match the regular
expression R.
•
case F 	 v D s: A.F; v/ D A.s/.
•
case F 	 length.v/ D n: A.F; v/ D A.˙n/.
•
case F 	 length.v/ < n: A.F; v/ is an automaton that accepts the language
f"g [ ˙1 [ ˙2 [ : : : [ ˙n1.
•
case F 	 length.v/ > n: A.F; v/ is constructed using A.˙nC1/ and A.˙/
and then constructing an automaton that accepts the concatenation of those
languages, i.e., ˙nC1˙.
•
case F 	 contains.v; s/: A.F; v/ is an automaton that is constructed using
A.˙/ and A.s/ and it accepts the language ˙s˙.
•
case F 	 begins.v; s/: A.F; v/ is constructed using A.˙/ and A.s/, and it
accepts the language s˙.
•
case F 	 ends.v; s/: A.F; v/ is constructed using A.˙/ and A.s/, and it
accepts the language ˙s.
•
case F 	 n D indexof.v; s/: Let Li denote the language ˙is˙. Automata that
accept the languages Li can be constructed using A.˙i/, A.s/, and A.˙/. Then
A.F; v/ is the automaton that accepts the language ˙ns˙.f"g[L1[L2[: : :[
Ln1/ which can be constructed using A.˙n/, A.s/, A.˙/, and the automaton
that accepts Li.
7.2.1.2
Pseudo-Relational Constraints
Pseudo-relational constraints are multi-variable constraints. Note that, using multi-
ple variables, one can specify constraints with non-regular truth sets. For example,
given the constraint F 	 x D y : y, F; x is not a regular set, so we cannot
construct an automaton precisely recognizing its truth set. Below, we deﬁne a class
of constraints called pseudo-relational constraints for which F; v is regular.
We assume that constraint F is converted to DNF form where F 	
_ n
iD1Fi,
Fi 	
^ m
jD1Cij, and each Cij is either a basic constraint or negation of a basic
constraint. The constraint F is pseudo-relational if each Fi is pseudo-relational.
Given F 	 C1 ^ C2 ^ : : : ^ Cn, where each Ci is either a basic constraint
or negation of a basic constraint, for each Ci, let VCi denote the set of variables that
appear in Ci. We call F pseudo-relational if the following conditions hold:

90
7
Constraint-Based String Analysis
1. Each variable v 2 VF appears in each Ci at most once.
2. There is only one variable, v 2 VF, that appears in more than one constraint Ci
where v 2 VCi ^ jVCij > 1, and in each Ci that v appears in, v is on the left hand
side of the constraint. We call v the projection variable.
3. For all variables v0 2 VF other than the projection variable, there is a single
constraint Ci where v0 2 VCi ^ jVCij > 1 and the projection variable v appears
in Ci, i.e., v 2 VCi.
4. For all constraints Ci where jVCij > 1, Ci is not negated in the formula F.
Many string constraints extracted from programs via symbolic execution are
pseudo-relational constraints, or can be converted to pseudo-relational constraints.
The projection variable represents either the variable that holds the value of the
user’s input to the program (for example, user input to a web application that
needs to be validated), or the value of the string expression at a program sink. A
program sink is a program point (such as a security sensitive function) for which it
is necessary to compute the set of values that reach to that program point in order to
check for vulnerabilities.
For example, following constraint is a pseudo-relational constraint extracted
from a web application (regular expressions are simpliﬁed):
.x D y : z/ ^ .length.y/ D 0/ ^ :.z 2 .0j1// ^ .x D t/ ^ :.t 2 0/
7.2.1.3
Automata Construction for Pseudo-Relational Constraints
Given a pseudo-relational constraint F and the projection variable v, we now discuss
how to construct the automaton A.F; v/ that accepts F; v. As above, we assume
that F is converted to DNF form where F 	 _ n
iD1Fi, Fi 	 ^ m
jD1Cij, and each Cij
is either a basic constraint or negation of a basic constraint.
In order to construct the automaton A.F; v/ we ﬁrst construct the automata
A.Fi; v/ for each Fi where A.Fi; v/ accepts the language Fi; v. Then we combine
the A.Fi; v/ automata using automata product such that A.F; v/ accepts the
language F1; v [ F2; v [ : : : [ Fm; v.
Since we discussed how to handle disjunction, from now on we focus on
constraints of the form F 	 C1 ^ C2 ^ : : : ^ Cn where each Ci is either a
basic constraint or negation of a basic constraint. For each Ci, let VCi denote the set
of variables that appear in Ci. If VCi is a singleton set, then we refer to the variable
in it as vCi.
First, for each single-variable constraint Ci that is not negated, we construct
an automaton that accepts the truth set of the constraint Ci, Ci; vCi, using the
techniques we discussed above for single-variable constraints. If Ci is negated, then
we construct the automaton that accepts the complement language ˙  Ci; vCi
(note that, only single-variable constraints can be negated in pseudo-relational
constraints). Let us call these automata A.Ci; vCi/ (some of which may correspond
to negated constraints).

7.2
Automata-Based String Constraint Solving
91
Then, for any variable v0 2 VF that is not the projection variable, we construct
an automaton A.F; v0/ which accepts the intersection of the languages A.Ci; v0/ for
all single-variable constraints that v0 appears in, i.e.,
L.A.F; v0// D
\
VCiDfv0g
L.A.Ci; v0//:
Next, for each multi-variable constraint Ci we construct an automaton that
accepts the language Ci; v where v is the projection variable as follows:
•
case Ci 	 v D v0: A.Ci; v/ D A.F; v0/.
•
case Ci 	 v D v1 : v2: A.Ci; v/ is constructed using the automata A.F; v1/
and A.F; v2/ and it accepts the concatenation of the languages L.A.F; v1// and
L.A.F; v2//.
•
case Ci 	 length.v/ D length.v0/: Given the automaton A.F; v0/, we construct
an automaton Alength.F;v0/ such that s 2 L.Alength.F;v0// , 9s0 W length.s/ D
length.s0/ ^ s0 2 L.A.F; v0//. Then, A.Ci; v/ D Alength.F;v0/.
•
case Ci 	 length.v/ < length.v0/: Given the automaton A.F; v0/ we ﬁnd the
length of the maximum word accepted by A.F; v0/, which is inﬁnite if A.F; v0/
has a loop that can reach an accepting state. If it is inﬁnite then A.Ci; v/ D
A.˙/. If not, then given the maximum length m, A.Ci; v/ is the automaton that
accepts the language f"g [ ˙1 [ ˙2 [ : : : [ ˙m1. Note that if m D 0 then
A.Ci; v/ D A.;/.
•
case Ci 	 length.v/ > length.v0/: Given the automaton A.F; v0/ we ﬁnd the
length of the minimum word accepted by A.F; v0/. Given the minimum length
m, A.Ci; v/ is the automaton that accepts the concatenation of the languages
accepted by A.˙mC1/ and A.˙/, i.e, ˙mC1˙.
•
case Ci 	 v D replace.v0; s; s/: Given the automaton A.F; v0/ we use the
construction presented in [129, 130] for language based replacement to construct
the automaton A.Ci; v/.
The ﬁnal step of the construction is to construct A.F; v/ using the automata A.Ci; v/
where L.A.F; v// D T
v2VCi L.A.Ci; v//.
For pseudo-relational constraints, the automaton A.F; v// constructed based on
the above construction accepts the truth set of the formula F for the projected
variable, i.e., L.A.F; v// D F; v. However, the replace function has different
variations in different programming languages (such as ﬁrst-match versus longest-
match replace) and the match pattern can be given as a regular expression. The
language-based replace automata construction we use [129, 130] over-approximates
the replace operation in some cases, which would then result in over-approximation
of the truth set: L.A.F; v//  F; v.

92
7
Constraint-Based String Analysis
Algorithm 1 AUTOMATAFORCONSTRAINT(F 	 C1 ^ C2 ^ : : : ^ Cn)
1: for v 2 VF do
2:
A.F; v/ WD A.˙/;
3: end for
4: i WD 0; done WD false;
5: while i < bound ^ :done do
6:
for each C 2 F and v 2 VC do
7:
construct A0 where L.A0/ D L.A.F; v// \ L.A.C; v//;
8:
A.F; v/ WD A0;
9:
end for
10:
if none of the L.A.F; v// changed during the current iteration of the while loop then
11:
done D true;
12:
end if
13:
i D i C 1;
14: end while
7.2.1.4
Automata Construction for Relational Constraints
For constraints that are not pseudo-relational, we extend the above algorithm to
compute an over approximation of F; v. In relational constraints, more than one
variable can be involved in multi-variable constraints which creates a cycle in
constraint evaluation.
Given a relational constraint in the form F 	 C1 ^ C2 ^ : : : ^ Cn, we start
with initializing each A.F; v/ to A.˙/, i.e., initially variables are unconstrained.
Then, we process each constraint as we described above to compute new automata
for the variables in that constraint using the automata that are already available for
each variable. We can stop this process at any time, and, for each variable v, we
would get an over-approximation of the truth-set A.F; v/  F; v. We can state
this algorithm as in Algorithm 1.
In order to improve the efﬁciency of the above algorithm, we ﬁrst build a
constraint dependency graph where, (1) a multi-variable constraint Ci depends on
a single variable constraint Cj if VCj  VCi, and (2) a multi-variable constraint
Ci depends on a multi-variable constraint Cj if VCj \ VCi
¤ ;. We traverse
the constraints based on their ordering in the dependency graph and iteratively
reﬁne the automata in case of cyclic dependencies. Note that, in the constructions
we described above we only constructed automaton for the variable on the left-
hand-side of a relational constraint using the automata for the variables on the
right-hand-side of the constraint. In the general case we need to construct automata
for variables on the right-hand-side of the relational constraints too. We do this
using techniques similar to the ones we described above. Constructing automata
for the right-hand-side variables is equivalent to the pre-image computations used
during backward symbolic analysis as discussed in Chap. 4 [125] and we use the
constructions given there. Finally, unlike pseudo-relational constraints, a relational
constraint can contain negation of a basic constraint Ci where jVCij > 1. In such
cases, in constructing the truth set of :Ci we can use the complement language
˙  Ci; v only if Ci; v is a singleton set. Otherwise, we construct an over
approximation of the truth set of :Ci.

7.3
Relational Constraint Solving with Multi-Track DFA
93
7.3
Relational Constraint Solving with Multi-Track DFA
In the previous section we present algorithms to construct DFA that accept satisfying
values of the variables for a given formula. The algorithms we described generates
a single-track DFA for each variable. Instead, we can generate a multi-track DFA
that accepts tuples of variables. In this section, we discuss mapping relational string
and integer constraints to multi-track DFA.
Let us extend the automata constructor function A such that, given a formula
F and a set of variables v1; v1; : : : ; vn, A.F; v1; v1; : : : ; vn/ generates a n-track
multi-track DFA with by traversing the syntax tree of the formula (Algorithm 2).
The generated multi-track DFA contains a track for each variable appearing in the
formula. If a variable does not appear in the formula, the output multi-track DFA
still contains a track that accepts any input for that variable, i.e., it contains an
unconstrained track.
Algorithm 2 accepts input constraints of any form, e.g., DNF, CNF. Conjunctions
and disjunctions are handled with u and t operations, respectively. Since the
negation operator is not monotonic and since we sometimes over-approximate
solution sets for constraints, in line 3, we convert the given formula to negation
normal form (NNF) (by pushing negations to the children of boolean connectives).
We provide DFA constructions for the negated constraints that over-approximate
satisfying inputs to a given constraint when necessary.
Conjunction and disjunctions are handled by DFA product. The algorithm
makes sure that generated DFAs have the same number of tracks by passing all
variables that appear in the constraint to DFA constructor function. Next, we discuss
DFA construction for string and integer constraints that do not contain boolean
connectives except negation.
Algorithm 2 Multi-track DFA constructor function
1: function A(F; v1; v1; : : : ; vn)
2:
if F  :F then
3:
return A.ToNegationNormalForm.:F/; v1; v1; : : : ; vn/
4:
else if F  F1 _ F2 then
5:
return A.F1; v1; v1; : : : ; vn/ t A.F2; v1; v1; : : : ; vn/
6:
else if F  F1 ^ F2 then
7:
return A.F1; v1; v1; : : : ; vn/ u A.F2; v1; v1; : : : ; vn/
8:
else if F  v1 D v2c or F  v1 ¤ v2c then
9:
return A.v1 ˇ v2c; ˙1; ˙2; : : : ; ˙n/, where ˇ 2 fD; ¤g
10:
else if F  v1 D cv2 or F  v1 D cv2 then
11:
return A.v1 D cv2; ˙1; ˙2; : : : ; ˙n/, where ˇ 2 fD; ¤g
12:
else if F  c D v1v2 or F  c ¤ v1v2 then
13:
return A.c D v1v2; ˙1; ˙2; : : : ; ˙n/, where ˇ 2 fD; ¤g
14:
else if F  v1 D v2v3 or F  v1 ¤ v2v3 then
15:
return A.v1 D v2v3; ˙1; ˙2; ˙3; : : : ; ˙n/, where ˇ 2 fD; ¤g
16:
else if F is a linear integer arithmetic constraint then
17:
return A.F; v1; v1; : : : ; vn/
18:
end if
19: end function

94
7
Constraint-Based String Analysis
Fig. 7.5 Syntax tree of the formula F  x D ya ^ i D 2j ^ length.x/ D i
Fig. 7.6 The DFA
constructed for the constraint
C1  x D ya
Let us consider the following example F 	 x D ya^i D 2j^length.x/ D i where
x; y are string variables, i; j are the integer variables. Constraint C1 	 x D ya is a
relational string constraint, C2 	 i D 2j is a linear integer arithmetic constraint, and
C3 	 length.x/ D i is a mixed constraint, i.e., a constraint that contains both string
and integer variables. More speciﬁcally it is an integer constraint that includes length
of a string variable. To handle such constraints we introduce auxiliary variables. For
the constraint C3, we introduce an auxiliary integer variable lv that corresponds to
the length of the string variable v. In that case, we say VF D fx; y; i; j; lvg is the
set of variables for the constraint F. Algorithm 2 constructs multi-track DFAs by
traversing the syntax tree of the constraint in Fig. 7.5.
7.3.1
Relational String Constraint Solving
DFA construction function in Algorithm 2 constructs multi-track DFA for word
equations using the DFA constructions described in Chap. 5. If there are additional
variables passed to the constructor function, it generates an unconstrained track for
each additional variable. Consider the example constraint C1 in Fig. 7.5 again. DFA
constructor A.x D ya; ˙; ˙; ˙; ˙; ˙/ constructs the multi-track DFA that
encodes the relation between variables. Assume ˙ D fa; bg for string variables
and ˙ D f0; 1g for integer variables. Figure 7.6 shows the DFA generated for the

7.3
Relational Constraint Solving with Multi-Track DFA
95
constraint C1. For illustrative purposes, we omit to display unconstrained tracks for
the multi-track DFAs. For constraint C1 we do not show the unconstrained tracks
generated for the variables i, j, and lv.
There are also other string constraints such as begins; contains; ends and string
operations such as charat; indexof; substring. The multi-track DFA construction
algorithm can be expanded to handle such constraints and operations [11].
7.3.2
Relational Integer Constraint Solving
Integer automata constructor at line 17 in Algorithm 2 handles arithmetic constraints
consisting of linear equalities .D/, disequalities .¤/, and inequalities .<; ; >; /.
Given a linear integer arithmetic constraints F, function A ﬁrst extracts the
coefﬁcients of the of the integer terms in the form Pn
iD1 ci 
 vi C c0 ˝ 0 where ci
denotes integer coefﬁcients and vi denotes integer variables and ˝ 2 fD; ¤; >
; ; ; <g. Then, the automata construction techniques that rely on a binary adder
state machine construction is used to construct an automaton for the arithmetic
constraint [16].
Figure 7.7 shows the DFA constructed for the linear integer equality constraint
C2. Note that, we encode integer numbers as bit strings using 2’s complement form.
7.3.3
Mixed String and Integer Constraint Solving
Let us consider the example mixed constraint C3 	 length.x/ D i. We rewrite the
mixed constraint with auxiliary integer variable lv as lv D i which can be solved
as linear integer arithmetic constraints. The DFA constructor function for the linear
integer arithmetic constraint solver converts string lengths into a binary encoded
DFA and updates the equation based on the string lengths. It also generates a string
DFA for the variable x where the lengths of the string variable satisfy the integer
Fig. 7.7 The DFA
constructed for the constraint
C2  i D 2j

96
7
Constraint-Based String Analysis
Fig. 7.8 The DFA
constructed for the constraint
C3  length.x/ D i
constraints [11]. As a result a multi-track DFA that contains tracks for the variables
x, i, and lv is generated. For illustrative purposes, instead of displaying one multi-
track DFA for all variables, we display a separate multi-track DFA for each variable
type. Figure 7.8 shows the generated DFAs for the string and integer variables.
So far we have constructed DFAs for the leaves C1, C2, and C3 of the constraint F.
When handling conjunctions, we compute the values for the auxiliary variable lv and
string variable V by implementing string lengths to binary encoded integer variable
conversion, and binary encoded integer variable to string variable conversion [11].
For example, the algorithm ﬁrst computes a DFA for the sub constraint F1 and
computes the DFA for the formula F. When processing the conjunction for F1,
the values for the lv and v are computed with mixed constraint handling. When
processing the ﬁnal conjunction for the formula F, the same procedure is applied
again. Figure 7.9 shows the ﬁnal DFAs constructed for the string and integer
variables for the constraint F.
7.4
Model Counting
Model counting is an extension to constraint solving where instead of just answering
to the question “Does there exist a model that satisﬁes a given constraint?” we try to
answer the question “How many models are there that satisﬁes a given constraint?”
We provide an example below to demonstrate a use case for model counting. Model
counting constraint solvers are crucial tools for quantitative program analysis.
Strength of a Password Policy
Consider the example in Fig. 7.10 which is a C string manipulation example that
is originally presented as a use case for model counting in [75]. On UNIX, users
use the PASSWD utility to change their passwords. The example is a simpliﬁed

7.4
Model Counting
97
Fig. 7.9 The DFAs
constructed for the constraint
F  x D ya ^ i D
2j ^ length.x/ D i
version of a C code called OBSCURE which is used by PASSWD utility to check
the password strength. At line 1, string_checkher_helper functions checks
if any of the parameters is a substring of the other one (strcasestr function
works as a case insensitive substring check). At line 8, string_checker func-
tion calls string_checkher_helper function twice; ﬁrst with the original
parameters and then by reversing the input parameter p1. If strength check fails,
obscure_msg function warns user for the similarity to the old password.
Suppose an attacker learns old password and the constraints imposed on new
password by OBSCURE utility. The model counting question is, how many possible
new password values are there for the attacker to try?
Let us assume old password is “abc-16” and attacker is trying to estimate the
number of all possible new passwords. The obscure function checks if one does
not contain the other or its reverse in a case insensitive manner. The example code
updates the password only if the new password is not too similar to the old one. A
symbolic execution tool can identify PCs that result in the password update, i.e., the
relation between new password and old password can be expressed in terms of a PC.
For example, the following is a path constraint that leads to the password update:

98
7
Constraint-Based String Analysis
Fig. 7.10 A string manipulation example in C language
strcasestr(NEW_P, "abc-16") D NULL ^
strcasestr("abc-16", NEW_P) D NULL ^
strcasestr(NEW_P, "61-cba") D NULL ^
strcasestr("61-cba", NEW_P) D NULL
A string model counter can count number of solutions to symbolic variable
NEW_P that satisﬁes the given PC. This information can be used for inferring the
value of the new password if an attacker knows the value of the old password.
Using model counting, one can assess the likelihood of an attacker guessing the
new password, hence, can evaluate the strength of the password policy.

7.4
Model Counting
99
7.4.1
Automata-Based Model Counting
In this section, we describe how to perform model counting by making use of the
automata constructed by the constraint solving procedure we discussed earlier. The
model counting problem is to determine the size of F, which we denote #F. A
formula can have inﬁnitely many models. However, we can count the number of
models within an inﬁnite space of solutions restricted to a ﬁnite range for the free
variables. Hence, we perform parameterized model counting for string constraints,
in which #F.b/ is a function over parameters b, which bounds the length of string
solutions.
The constraint solving procedure described in this chapter produces a ﬁnal
automaton, A, for each variable in a given formula. If multi-track automaton is
used, a ﬁnal multi-track automaton A is constructed for a given formula. The model
counting techniques we discuss here works for any DFA whether it is a single-track
or multi-track. The only difference is in the interpretation of the count results; the
former counts solutions to a single variable, whereas the latter counts solutions to
tuples of variables. We make use of function #FA.k/ that works identical for single-
track and multi-track automata.
We rely on the observation that counting the number of strings of length k in
a regular language, L, is equivalent to counting the number of accepting paths of
length k in the DFA that accepts L. That is, by using a DFA representation, we
reduce the parameterized model counting problem to counting the number of paths
of a given length in a graph. In a DFA, there is exactly one accepting path for every
recognized string. Thus, there is no loss of precision due to the model counting
procedure; any loss of precision comes from the over-approximations of non-regular
constraints in the solving phase.
Let T be the transfer matrix of a DFA A. The matrix entry Ti;j is the number of
transitions from state si to state sj. We compute uTkv, where u is the row vector such
that ui D 1 if and only if i is the start state and 0 otherwise, and v is the column
vector where vi D 1 if and only if i is an accepting state and 0 otherwise. Matrix
multiplication based counting method is parameterized in the following sense: after
a constraint is solved, we can count the number of solutions of any desired size k by
computing uTkv, without re-solving the constraint.
Consider the DFA A for the constraint F 	 :match.x; .01// presented in
Fig. 7.11a. Let L.A/ (L.A/ D F; x D F ) be the language over ˙ D f0; 1g
that satisﬁes the formula F. Then L.A/ is described by the expression ˙  .01/.
We ﬁrst apply a transformation and add an extra state, snC1. The resulting
automaton is a DFA A0 with -transitions from each of the accepting states of A
to snC1 where  is a new padding symbol that is not in the alphabet of A. Thus,
L.A0/ D L.A/ 
  and furthermore jL.A/ij D jL.A0/iC1j. That is, the augmented
DFA A0 preserves both the language and count information of A. Recalling the
ﬁnal automaton from Fig. 7.11a, the corresponding augmented DFA is shown in
Fig. 7.11b. (Ignore the dashed  transition for the time being.)

100
7
Constraint-Based String Analysis
Fig. 7.11 (a) The original DFA A, and (b) the augmented DFA A0 used for model counting (sink
state omitted)
For our example, we show the transition matrix T and its exponentiations T2
and T3:
T D
2
664
0 1 0 0
1 0 0 0
1 1 2 0
0 1 1 0
3
775 ; T2 D
2
664
1 0 0 0
0 1 0 0
3 3 4 0
2 1 2 0
3
775 ; T3 D
2
664
0 1 0 0
1 0 0 0
7 7 8 0
3 4 4 0
3
775
Here, T2;1 is 1 because there is a single transition to state 2 from state 1, T3;3 is
2 because there are two transitions from state 3 to itself, T4;2 is 1 because there is a
single () transition to state 4 from state 2, and so on for the remaining entries.
If we look at the entry T4;1, we can tell the number of transitions to accepting
state from start state. In other words this is equivalent to number of paths from start
state to the accepting state with lengths equal to 0. The same entry on the matrix
T2 gives us the number of paths from start state to the accepting state with lengths
equal to 1. We can see that T2
4;1 D 2 as there are strings “0” and “1” from the
initial state to the accepting state with length 1 (omitting ). Similarly, T3
4;1 D 3 as
there strings “00”, “10”, and “11” from the initial state to the accepting state
with length 2 (omitting ).
The matrix multiplication method relies on computing uTkv and so we seek to
implement an efﬁcient method for computing this product. The time and space
complexity trade-offs between various methods of computing uTkv for counting
are well-studied [88, 99]. We note that one may compute Tk using matrix-matrix
multiplication with successive squaring, or one may perform left-to-right vector-
matrix multiplication. While successive squaring has a better worst-case time
complexity bound, we found that due to typically high sparsity of DFA transfer
matrices, it is both faster and less memory intensive to use repeated vector-matrix
multiplication. The value of uTkv may simply be computed left to right: uTkv D
.uT/Tk1v. This prevents us from using a divide and conquer technique, but with
the beneﬁt that at each step we are multiply a 1  n vector by a sparse n  n matrix.
Hence, we need only keep track of the sparse matrix T and a single n-dimensional
vector of large integers at each step. In our exploration of model counting algorithms
for DFA, we have found this to be the best approach.

7.4
Model Counting
101
Another way to compute the number of paths of length k accepted by A is to
employ algebraic graph theory [18] and analytic combinatorics [39] to perform
model counting. A preferable solution is to derive a symbolic function that given
a length bound k outputs the number of solutions within bound k. One way to
achieve this is to use the transfer matrix method [39, 88, 99] to produce an ordinary
generating function which in turn yields a linear recurrence relation that is used
to count constraint solutions. Given a DFA A and length k we can compute the
generating function gA.z/ such that the kth Taylor series coefﬁcient of gA.z/ is equal
to jLk.A/j using the transfer-matrix method [39, 99].
From A0 we construct the .n C 1/  .n C 1/ transfer matrix T. A0 has n C 1 states
s1; s2; : : : snC1. Then the generating function for A is
gA.z/ D .1/n det.I  zT W n C 1; 1/
z det.I  zT/
;
(7.1)
where .M W i; j/ denotes the matrix obtained by removing the ith row and jth column
from M, I is the identity matrix, det M is the matrix determinant, and n is the number
of states in the original DFA A. The number of accepting paths of A with length
exactly k, i.e. jL.A/kj, is then given by ŒzkgA.z/ which can be computed through
symbolic differentiation.
Applying Eq. (7.1) results in the following GF:
gA0.z/ D det.I  zT W n; 1/
z det.I  zT/
D
2z  z2
1  2z  z2 C 2z3 :
(7.2)
7.4.2
Counting All Solutions within a Given Bound
The above described method gives a generating function that encodes each jL.A/ij
where i is the length bound separately. Instead, we seek a generating function that
encodes the number of all solutions within a bound.
The method described above computes the number of string solutions of length
exactly k. It is of interest to compute #FA.k/, the number of solutions within a given
bound. This is accomplished easily by using a common “trick” that is often used
to simplify graph algorithms. We add a single -cycle (the dashed transition in
Fig. 7.11b) to the accepting state of the augmenting DFA A0. Then L.A0/kC1 D
Sk
iD0 L.A/i 
 ki and the accepting paths of strings in L.A0/kC1 are in one-to-one
correspondence with the accepting paths of strings in Sk
iD0 L.A/i. Consequently,
jL.A0/kC1j D Pk
iD0 jL.A/ij. We apply the transfer matrix method on A0 to count all
solutions within a given length bound.
We have shown model counting methods for counting strings of a given length.
The same methods can perform model counting for any type of DFA that has
different encodings, e.g., single-track string DFA, multi-track string DFA, multi-
track binary encoded integer DFA [16].

102
7
Constraint-Based String Analysis
7.5
Summary
In this chapter we discussed string constraint solving and model counting using
automata-based techniques. We discussed automata based constraint solving
techniques using single-track automata and multi-track automata. We discussed
automata constructions for non-relational, relational and mixed constraints. We
showed that automata-based string constraint solving leads to a model-counting
string constraint solver that, given a constraint, generates (1) an automaton that
accepts all solutions to the given string constraint, and (2) a model-counting
function that, given a length bound, returns the number of solutions within that
bound.

Chapter 8
Vulnerability Detection and Sanitization
Synthesis
Web application development is error prone and results in applications that are
vulnerable to attacks by malicious users. The global accessibility of Web appli-
cations makes this an extremely serious problem. According to the Open Web
Application Security Project (OWASP)’s top ten list that identiﬁes the most serious
web application vulnerabilities, the top three vulnerabilities in 2007 [84] were:
(1) Cross Site Scripting (XSS) and (2) Injection Flaws (such as SQL Injection).
Even after it has been widely reported that web applications suffer from these
vulnerabilities, XSS and SQL Injection vulnerabilities remained among the top three
vulnerabilities listed in OWASP’s top ten list in 2010 [85] and 2013 [86].
A XSS vulnerability results from the application inserting part of the user’s input
in the next HTML page that it renders. Once the attacker convinces a victim to click
on a URL that contains malicious HTML/JavaScript code, the user’s browser will
then display HTML and execute JavaScript that can result in stealing of browser
cookies and other sensitive data. An SQL Injection vulnerability, on the other hand,
results from the application’s use of user input in constructing database statements.
The attacker can invoke the application with a malicious input that is part of an SQL
command that the application executes. This permits the attacker to damage or get
unauthorized access to data stored in a database.
As we stated earlier, all these vulnerabilities are caused by improper string
manipulation in server-side code. Programs that propagate and use malicious
user inputs with improper sanitization on the server-side are vulnerable to these
well-known attacks. The attacks that exploit the vulnerabilities related to string
manipulation can be characterized as attack patterns, i.e., regular expressions
that specify potential attack strings. In this chapter we demonstrate how to use
these attack patterns as security policies against which we verify and repair
vulnerabilities.
© Springer International Publishing AG 2017
T. Bultan et al., String Analysis for Software Veriﬁcation and Security,
https://doi.org/10.1007/978-3-319-68670-7_8
103

104
8
Vulnerability Detection and Sanitization Synthesis
8.1
Vulnerability Detection and Repair
In this chapter, we present automata-based vulnerability detection and repair
synthesis techniques for web applications [128]. We focus on vulnerability analysis
of web applications written in PHP, however, the approach we present is applicable
to all web application development languages.
The approach we present for detecting and repairing web application vulnerabil-
ities consists of three main phases: (1) taint analysis, (2) vulnerability analysis, and
(3) sanitization analysis as summarized in Fig. 8.1 [128]. Taint analysis is conducted
ﬁrst to ﬁnd out tainted sinks, where input of a sensitive function depends on the
value of a user input. For example, for SQL Injection vulnerabilities, a tainted sink
could be a mysql_query() function whose input value depends on an external user
name. As another example, for XSS vulnerabilities, a tainted sink could be an echo
function whose input value depends on a user input. For each tainted sink, the taint
analysis generates a dependency graph to specify how the user input ﬂows to the
sink. If there are any tainted sinks detected during taint analysis, then vulnerability
analysis is conducted on the dependency graph of each tainted sink. On the other
hand, if there are no tainted sinks found, the input program is considered secure.
Vulnerability analysis is carried out as a forward symbolic reachability analysis.
The goal of vulnerability analysis is to determine, given an arbitrary user input,
whether a string value that matches the attack pattern can reach the sink of the
dependency graph. We use automata-based forward symbolic reachability analysis
to compute the set of string values that can reach each node of the dependency graph.
This is done by assuming that user input nodes can take any possible string value,
and then propagating the post-images of string operations until a ﬁxpoint of the
automata associated with the sink has been reached. Upon termination, we take the
intersection of the DFA of the sink node with the attack pattern. If the intersection
is empty, we claim that the tainted sink is not vulnerable. If not, a vulnerability is
reported along with a DFA that accepts the reachable attack strings (the strings that
are in the intersection).
Once we have an automaton characterizing the attack strings that can reach
the sink, we conduct sanitization analysis to repair the identiﬁed vulnerability.
Sanitization analysis consists of vulnerability signature generation (generating a
characterization of user inputs that can exploit the identiﬁed vulnerability) and patch
synthesis (using the generated vulnerability signature as a ﬁlter to block or modify
user inputs). A vulnerability signature is a DFA that accepts an over approximation
of strings that a malicious user can provide as input that can lead to a string value at
the sink that matches the attack pattern.
When a detected vulnerability depends on a single user input, we use the
single-track DFA representation and backward reachability analysis to construct the
vulnerability signature. When the detected vulnerability depends on multiple user
inputs we use forward reachability analysis with multi-track automata to keep the
relation among inputs and generate a relational vulnerability signature.

8.1
Vulnerability Detection and Repair
105
Fig. 8.1
Web application sanitization analysis process
Below we ﬁrst give a simple example that has only one user input to illustrate
the whole process of detecting and repairing a vulnerability with a vulnerability
signature that is characterized as a single-track DFA. Then, we use another example
that has two user inputs to illustrate vulnerability detection and repair with a
relational signature that is characterized as a multi-track DFA.

106
8
Vulnerability Detection and Sanitization Synthesis
Fig. 8.2 A simple example
Consider the PHP script shown in Fig. 8.2. This script starts with assigning the
user input provided in the _GET array to the variable name in line 2. It concatenates
a constant string with variable name and assigns it to another variable out in line
3. Then it simply outputs the variable out using the echo statement in line 4.
The echo statement in line 4 is a sink statement since it can contain a Cross Site
Scripting (XSS) vulnerability. For example, a malicious user can provide an input
that contains the string constant <script and execute a command leading to a
XSS attack. In order to prevent this vulnerability, it is necessary to sanitize the user
inputs before using them in an echo statement. Let us assume that the attack pattern
for this vulnerability is speciﬁed using the following regular expression ˙ < ˙
(where ˙ denotes any ASCII character).
Vulnerability Analysis
We ﬁrst perform a forward symbolic reachability analysis that uses one DFA
for each variable at each program point to represent the set of values that the
variables can take. During forward analysis we iteratively update these DFAs by
computing post-conditions (forward image) of program statements. For example,
the post-condition computation for an assignment statement takes a set of DFAs
characterizing the values of the string variables at the right-hand-side of the
assignment (before the assignment is executed) as input, and returns a DFA
characterizing the possible values of the left-hand-side variable after the assignment
statement is executed.
During forward analysis we characterize all the user input as ˙, i.e., the
user can provide any string as input. Any variable that is assigned an input is
represented by a DFA that accepts the language ˙ at the next program point
after the assignment. For example for the small script shown in Fig. 8.2, the forward
analysis will generate a DFA for the variable name at the beginning of statement
3 that accepts the language ˙. Computing the post-condition of the statement
3 will generate a DFA for the variable out at the beginning of statement 4 that
accepts the language NAME : ˙. When symbolic reachability analysis reaches
a ﬁxpoint each string variable at each program point is associated with a DFA
that characterizes all possible values that variable can take at that program point.
This analysis is conservative in the sense that the resulting DFAs accept an over-
approximation of all possible values of the variables they represent. Note that
approximation is inevitable since string analysis problem is undecidable as we
discussed in Chap. 2.
When the forward analysis converges, we take the intersection (using automata
product) of the language of the DFA that corresponds to the string expression at
the sink statement with the attack pattern. In our running example statement 3 is

8.1
Vulnerability Detection and Repair
107
a sink statement, and the DFA that corresponds to the string expression at line 4
(which is simply the variable out) accepts the language NAME : ˙. When we
take the intersection of this language with the attack pattern we obtain an automaton
that accepts the language NAME : ˙ < ˙. This automaton characterizes all
possible attack strings at the sink statement. Since the language of this automaton is
not empty, we know that the program is vulnerable.
Vulnerability Signature Generation
Next, we ﬁgure out which input values can create the attack strings at the sink
statement. In the single-track DFA based approach, this is done with a backward
symbolic reachability analysis. We start with the DFA that characterizes the attack
strings (i.e, the DFA we compute at the end of the vulnerability analysis) and
propagate the results backwards until we reach an input. During backward analysis
we iteratively update these DFAs by computing pre-condition (backward image) of
program statements. For example, the pre-condition computation for an assignment
statement takes a DFA characterizing the values of the string variable at the left-
hand-side of the assignment (after the assignment is executed) as input, and returns
a set of DFAs characterizing the possible values of the variables that are at the right-
hand-side of the assignment before the assignment statement is executed. For the
example shown in Fig. 8.2, backward analysis computes the pre-condition for the
assignment statement in line 3 and generates a DFA for the variable name at the
end of statement 2 that accepts the language ˙ < ˙. When we compute the
pre-condition of the assignment statement in line 2 we reach an input and generate
the vulnerability signature for the input _GET["name"] as a DFA that accepts the
language ˙ < ˙.
Sanitization Generation
The last phase of the analysis generates a patch that removes the vulnerability.
The vulnerability signature gives an over-approximation of all possible input values
that can exploit the vulnerability. Hence, if we do not allow input values that match
the vulnerability signature then we can remove the vulnerability. In the match-and-
block strategy we generate a patch that simply checks if the input string matches
the vulnerability signature. If it does, it halts the execution without executing the
rest of the script. The patch generated for the small example in Fig. 8.2 based on the
vulnerability signature ˙ < ˙ and using the match-and-block strategy is shown
in Fig. 8.4a. Note that the patched script will block any input string that contains the
symbol <.
In the match-and-sanitize strategy, instead of blocking the execution, we modify
the input in a minimal way to guarantee that the modiﬁed input cannot lead to any
attack strings. We do this by analyzing the vulnerability signature DFA. Consider
the DFA for the vulnerability signature ˙ < ˙ shown in Fig. 8.3 (we use ˙f<g
to indicate any symbol other than <). Our goal is to ﬁnd a minimal set of characters,
such that if we remove those characters from a given string, the resulting string will
not be accepted by the DFA. As we discuss in Sect. 8.6, this corresponds to ﬁnding
a cut in the graph deﬁned by the states and the transitions of the DFA, i.e., ﬁnding
a set of edges such that when we remove them, there are no paths left in the graph

108
8
Vulnerability Detection and Sanitization Synthesis
Fig. 8.3 A single-track
vulnerability signature for the
example in Fig. 8.2
Fig. 8.4 Patches for the example in Fig. 8.2. (a) Patch 1 using match-and-block strategy. (b) Patch
2 using match-and-sanitize strategy
from the initial state of the DFA to a ﬁnal state. Note that each edge of the DFA is
labeled with a symbol. After we ﬁnd a cut, if we take the union of the symbols of
the edges in the cut, we obtain a set of symbols such that any string accepted by the
DFA must include at least one of the symbols in that set.
We use a min-cut algorithm to compute a cut that contains minimum number of
edges. Then we generate a patch that deletes all the characters from the input that
appear on the edges included in the cut set. For the DFA shown in Fig. 8.3, the min-
cut algorithm returns the single edge labeled with the symbol < (colored in red).
So we generate a patch that deletes all the < symbols from the input as shown
in Fig. 8.4b. Note that, unlike the patch shown in Fig. 8.4a, the patch generated
based on the match-and-sanitize strategy continues to execute the script after the
sanitization.
Relational Vulnerability Signature Generation
Consider the simple script shown in Fig. 8.5. This example is similar to the one
shown in Fig. 8.2 with one signiﬁcant difference: there are two input variables that
both contribute to the string expression used at the sink statement at line 5.

8.1
Vulnerability Detection and Repair
109
Fig. 8.5 A simple example
with two user inputs
Assume that we use the single-track automata based analysis described above to
analyze this script. The set of attack strings generated for the sink statement at line
5 will again be: NAME : ˙ < ˙. However, the result of the backward analysis
will be different. The crucial step is the pre-condition computation for the statement
in line 4. The input to this pre-condition computation will be a DFA that accepts the
attack strings characterized by the regular expression given above. The result of the
pre-condition computation will generate two DFAs, one for the variable name and
one for the variable title, and these DFAs will characterize all possible values
these two variables can take just before the execution of statement in line 4 that can
lead to generation of an attack string at the sink statement in line 5. When we do
this pre-condition computation we get two DFAs that accept the same language ˙,
i.e., any value of either variable can lead to an attack string. Although this is a sound
approximation it fails to capture the information that at least one of these variables
should contain the character <. Note that this condition cannot be expressed as a
constraint on an individual variable, it identiﬁes a relation between the two string
variables.
The relational analysis we present uses a single multi-track automaton (MDFA)
for each program point to capture the relationship between the input values and
possible values of string expressions in the program. We use a forward analysis
that operates on the dependency graph. We show the dependency graph for the
example from Fig. 8.5 in Fig. 8.7. We write the string expression in the program and
its corresponding string operation that corresponds to each node in the dependency
graph. The analysis starts from the input nodes and traverses the dependency graph
while generating one MDFA for each internal node of the dependency graph. For
an input node, each MDFA has one track for each input variable and one track
for the string expression that corresponds to that node, and represents the relation
between them. The concatenation of two nodes results in an MDFA that has the
union of input tracks of two nodes and has its string expression recorded in another
track that concatenates the values of string expressions of two nodes. In Fig. 8.7 we
show a string constraint on the right side of each internal node. That string constraint
characterizes the set of strings accepted by the MDFA for that node. For example, for
node n3, the string constraint is n3 D i1:i2 which indicates that the string expression
that corresponds to node n3 is equal to the concatenation of input i1 and input i2.
When the analysis reaches a sink node, we intersect the track that corresponds
to the string expression for the sink node (in our example this would be the track
that corresponds to node n6) with the attack pattern DFA (by extending the attack
pattern DFA to an MDFA by adding extra tracks that accept all strings). After the
intersection, we project away the track for the sink node, leaving only the tracks

110
8
Vulnerability Detection and Sanitization Synthesis
Fig. 8.6 A multi-track
vulnerability signature for the
example in Fig. 8.5
Fig. 8.7 Dependency graph
for the input nodes. The resulting MDFA represents the relational vulnerability
signature. For our example, the vulnerability signature MDFA is shown in Fig. 8.6
(where each transition is marked with two symbols, one for each track, and if a
track is marked with the symbol  then that means that no symbol from that track
is consumed when that transition is taken). Note that this automaton accepts tuples
of strings, where either the ﬁrst string in the tuple or the second string in the tuple
contains at least one < symbol.
The patches shown in Fig. 8.4 for the single input case are generated by
converting the standard DFA representation to a regular expression and then using
the PHP preg_match function to generate the match part of the patch. For the
relational case, when we generate two regular expressions, one for each input, from
the automaton shown in Fig. 8.6, we again get ˙ for both inputs, so all inputs
match. This is acceptable if we use the match-and-sanitize strategy since, although
all the input strings will be considered potentially vulnerable, only a small set of
symbols that relate to the vulnerability will be replaced. For example, the patch

8.2
Patching Algorithm
111
Fig. 8.8 Patch for the example from Fig. 8.5
generated using this approach for the example in Fig. 8.5 is shown in Fig. 8.8.
However, if we use the match-and-block approach using the regular expression ˙,
we will block all the inputs which is not acceptable. As we discuss in Sect. 8.6, in
such cases it is necessary to generate match statements that use automata simulation
instead of automata to regular expression conversion.
In order to generate the sanitization statements from relational vulnerability
signatures, we ﬁnd a min-cut in the vulnerability signature MDFA as we did for
the single-track case. Then, for each track, we take the union of the symbols on
that track for all the edges in the min-cut. In order to sanitize the input we need to
remove the symbols for each track from the input that corresponds to that track. For
example, based on the min-cut shown in Fig. 8.6 (colored in red), we need to delete
the symbol < both from the inputs _GET["name"] and _GET["title"]. The
automatically generated replace statements for this example are shown in Fig. 8.8.
8.2
Patching Algorithm
Our patching algorithm (Algorithm 1) takes four inputs (1) the PHP web application
that needs to be analyzed and ﬁxed, (2) the attack patterns that characterize possible
attacks, (3) the patching strategy to follow and (4) a speciﬁcation of output functions
that should be considered as sinks.
The algorithm starts (lines 1,2) by running dependency and taint analysis on the
input program. Dependency analysis computes data dependencies in the application
and generates dependency graphs, one graph per each speciﬁed sink. After that,
taint analysis helps to identify potentially vulnerable sinks (i.e., sinks that depend
on external input).
The output of these two analyses is a set of tainted dependency graphs which
show how external inputs ﬂow into potentially vulnerable sinks. Figure 8.7 shows
the dependency graph for the PHP code in Fig. 8.5. Formally, a dependency graph
G D hN; Ei is a directed graph, where N is a ﬁnite set of nodes and E  N  N

112
8
Vulnerability Detection and Sanitization Synthesis
is a ﬁnite set of directed edges. An edge .ni; nj/ 2 E identiﬁes that the value of nj
depends on the value of ni, e.g., assign the value of the variable associated with ni
to the variable associated with nj in the program. Each node n 2 N can be (1) a
normal node including input, constant, variable, or (2) an operation
node including concat and replace.
An input node identiﬁes the data from untrusted parties, e.g., an input from
web forms. A constant node is associated with a constant value. Both nodes
have no predecessors.
A concat node n has two predecessors: the preﬁx node (n:p) and the sufﬁx node
(n:s), and stores the concatenation of any value of the preﬁx node and any value of
the sufﬁx node in n.
A replace node n has three predecessors: the target node (n:t), the match node
(n:m), and the replacement node (n:r). For each value of n:t it: (1) identiﬁes all the
matches, i.e., any value of n:m, that appear in n:t, (2) replaces all these matches in
n:t with any value of n:r, and (3) stores the result in n.
For n 2 N, Succ.n/ D fn0 j .n; n0/ 2 Eg is the set of successors of n. Pred.n/ D
fn0 j .n0; n/ 2 Eg is the set of predecessors of n. For a dependency graph G, we also
deﬁne Root.G/ D fn j Pred.n/ D ;g and Leaf.G/ D fn j Succ.n/ D ;g.
Given the extracted dependency graphs, the algorithm proceeds to the three main
stages (1) vulnerability analysis, (2) signature and relational signature generation
and (3) sanitization synthesis (lines 3–18). The algorithm uses two arrays POST
and PRE to communicate analysis results among the three stages and we will discuss
these two arrays in more details later. In the following three sections, we explain the
algorithms used for each of the three stages.
8.3
Vulnerability Analysis
The goal of the vulnerability analysis is to detect vulnerabilities in the input program
so that they can be patched later. Given the set of tainted dependency graphs
extracted from the input program, the patching algorithm (Algorithm 1 lines 5–
7) runs vulnerability analysis on each of these graphs to detect if it contains a
vulnerability with respect to an attack pattern.
The vulnerability analysis algorithm (Algorithm 2) takes the following inputs:
a tainted dependency graph (G), an attack pattern (attkPtrn) speciﬁed as a regular
expression and represented as a DFA, and two automata arrays POST and PRE.
It works by ﬁrst approximating—as a regular language—the set of string values
that may reach a node n in the input graph G (lines 1–5). This approximation is
carried out using forward symbolic reachability analysis (Algorithm 3) which we
explain later. Then, it compares the language associated with the sink node with the
language of the attkPtrn (line 7–12). If the two languages intersect, this means that
a vulnerability is found. In fact, the language of the intersection (i.e., language of
DFA tmp) contains the set of reachable attack strings at the sink node that can be

8.3
Vulnerability Analysis
113
Algorithm 1 PATCHER(Prog; AttkPtrns; Strategy; SinkSpec)
1: Sinks :=GETSINKS(G; SinkSpecs);
2: TaintedDepGraphs := DEPANDTAINTANALYSIS(Prog; Sinks);
3: for each G 2 TaintedDepGraphs do
4:
array POST; PRE;
5:
for each attkPtrn 2 AttkPtrns do
6:
isVul := VULANALYSIS(G; attkPtrn; POST; PRE);
7:
if isVul D true then
8:
InputNodes := GETINPUTNODES(G);
9:
if jInputNodesj D 1 then
10:
vulSig := VULSIGGEN(G; InputNodes; POST; PRE);
11:
else
12:
vulSig := RELSIGGEN(G; InputNodes; attkPtrn);
13:
end if
14:
patch := GENERATEPATCH(vulSig);
15:
report patch;
16:
end if
17:
end for
18: end for
Algorithm 2 VULANALYSIS(G; attkPtrn; POST; PRE)
1: INIT(POST; PRE);
2: for each inputNode 2 InputNodes.G/ do
3:
POSTŒinputNode WD ˙;
4: end for
5: FORWARDANALYSIS(G; POST);
6: sink := GETSINK(G);
7: tmp: = POSTŒsink u attkPtrn;
8: if L.tmp/ ¤ ; then
9:
PREŒsink WD tmp;
10:
return true;
11: else
12:
return false;
13: end if
used to exploit the vulnerability. This language is used later in the next phases to
compute bad inputs and construct a patch.
The algorithm associates each node n in G with its automata by utilizing the two
automata arrays POST and PRE. POSTŒn is the DFA accepting all possible values
that node n can take. PREŒn is the DFA accepting all possible values that node n can
take to exploit the vulnerability. The size of both arrays is bounded by jNj. Initially
(line 1), all these automata accept nothing, i.e., their language is empty. Then (lines
2–4), each input node is associated with ˙ indicating that any string value can be
taken as input.
We use a forward symbolic reachability analysis (Algorithm 3) based on a
standard work queue algorithm. We iteratively update the automata array POST
until a ﬁxpoint is reached. At line 6, A(n) returns a DFA that: (1) accepts arbitrary
strings if n is an input node, (2) accepts an empty string if n is a variable node,

114
8
Vulnerability Detection and Sanitization Synthesis
Algorithm 3 FORWARDANALYSIS(G; POST)
1: queue WQ WD NULL;
2: WQ.enqueue(Root.G/);
3: while WQ ¤ NULL do
4:
n := WQ.dequeue();
5:
if n 2 Root.G/ then
6:
tmp := A(n);
7:
else if n is concat then
8:
tmp : = POSTCONCAT(POSTŒn:p, POSTŒn:s);
9:
else if n is replace then
10:
tmp : = POSTREPLACE(POSTŒn:t, POSTŒn:m, POSTŒn:r);
11:
else
12:
tmp : = F
n02Pred.n/ POSTŒn0;
13:
end if
14:
tmp := .tmp t POSTŒn/rPOSTŒn;
15:
if tmp 6 POSTŒn then
16:
POSTŒn := tmp;
17:
WQ.enqueue(Succ.n/);
18:
end if
19: end while
or (3) accepts the constant value if n is a constant node. At lines 8 and 10, we
incorporate two automata-based string manipulating functions that we have deﬁned
in Chap. 4:
•
POSTCONCAT(DFA A1, DFA A2) returns a DFA A that accepts fw1w2 j w1 2
L.A1/; w2 2 L.A2/g.
•
POSTREPLACE(DFA A1, DFA A2, DFA A3) returns a DFA A that accepts
fw1c1w2c2 : : : wkckwkC1 j k > 0; w1x1w2x2 : : : wkxkwkC1 2 L.A1/; 8i, xi 2 L.A2/;
wi does not contain any substring accepted by A2; ci 2 L.A3/g.
At line 14, we incorporate the automata widening operator r that we have deﬁned
in Chap. 6 to accelerate the ﬁxpoint computation, which ensures termination and
returns the least ﬁxpoint under certain conditions. Upon termination of the while
loop (lines 3 to 19) POSTŒn records the DFA whose language includes all possible
string values that n can take.
8.4
Vulnerability Signatures
When our patching algorithm (Algorithm 1) ﬁnds a vulnerability, the next step
is to compute the vulnerability signature (lines 7–13). The vulnerability signature
is the set of input values that can be used to exploit a discovered vulnerability
and it is represented in our analysis using a DFA. Depending on the number of
inputs that ﬂow into a vulnerable sink in a dependency graph (line 9), there are
two vulnerability signature generation algorithms: (1) a non-relational vulnerability

8.4
Vulnerability Signatures
115
Algorithm 4 VULSIGGEN(G; In; POST; PRE)
1: n := GETINPUTNODE(In);
2: sink := GETSINK(G);
3: path := GETPATH(G; n; sink);
4: PRE := BACKWARDANALYSIS(G; path; sink; POST; PRE);
5: return PREŒn;
signature generation algorithm (Algorithm 4) which is used when there is only a
single input that can ﬂow into the vulnerable sink, and (2) a relational vulnerability
signature generation algorithm (Algorithm 6) which is used when there is more than
one input that can ﬂow into the vulnerable sink.
In this section we present our non-relational vulnerability signature generation
algorithm (Algorithm 4) and leave the other one for the next section. Algorithm 4
uses a backward symbolic reachability computation based on single-track DFAs
(line 4). It starts by ﬁnding a path between each pair of an input node n and a
vulnerable sink s (lines 1–3). This is done to optimize the analysis since, during the
backward analysis, we only need to process the nodes on this path. Then, it calls
backward analysis algorithm (Algorithm 5) to compute the vulnerability signature.
Given a vulnerable sink s, backward analysis starts the computation using the
input value PREŒs. Recall that, during the vulnerability analysis phase, PREŒs is
set to the intersection of POSTŒs and attkPtrn. Similar to the forward analysis, the
computation is based on a standard work queue algorithm.
We ﬁrst put the predecessors of s into the work queue (lines 2–6). We iteratively
update the PRE array (by adding pre-images) until we reach a ﬁxpoint. If the
successor of n is an operation node, the pre-image (tmp) of n is computed in lines 13,
15 and 19 by calling the deﬁned automata-based functions: PRECONCATPREFIX,
PRECONCATSUFFIX, and PREREPLACE which we deﬁne in Chap. 4. Otherwise,
the pre-image of n is directly derived from the successor of n (line 22). Note
that POSTŒn records all possible values that n can take. We use this information
during the pre-image computation by restricting the arguments of operations such
as replace. We union the pre-images of n as tmp0 at line 24.
Since we are interested only in reachable values of n, i.e., PREŒn  POSTŒn by
deﬁnition, we intersect tmp0 with POSTŒn at line 26. Similar to the forward analysis,
we widen the result at line 27 to accelerate the ﬁxpoint computation. At line 28,
we intersect tmp0 with POSTŒn again to remove unreachable values (that might
have been introduced due to widening) at node n. If tmp0 accepts more values than
PREŒn, we update PREŒn at line 30 and add the predecessors of n to the working
queue at line 31. Upon termination, PREŒn—where n is the input node—records the
DFA that accepts all possible values of n that may exploit the identiﬁed vulnerability.

116
8
Vulnerability Detection and Sanitization Synthesis
Algorithm 5 BACKWARDANALYSIS(G; path; sink; POST; PRE)
1: queue WQ D NULL;
2: for each n 2 Pred.sink/ do
3:
if n 2 path then
4:
WQ.enqueue();
5:
end if
6: end for
7: while WQ ¤ NULL do
8:
n := WQ.dequeue();
9:
tmp0 := NULL;
10:
for each n0 2 Succ.n/ do
11:
if n0 is concat then
12:
if n is n0:l then
13:
tmp := PRECONCATPREFIX(PREŒn0, POSTŒn0:r);
14:
else
15:
tmp := PRECONCATSUFFIX(PREŒn0, POSTŒn0:l);
16:
end if
17:
else if n0 is replace then
18:
if n is n0:t then
19:
tmp := PREREPLACE(PREŒn0, POSTŒn0:m, POSTŒn0:r);
20:
end if
21:
else
22:
tmp := PREŒn0;
23:
end if
24:
tmp0 := tmp0 t tmp;
25:
end for
26:
tmp0 := tmp0 u POSTŒn;
27:
tmp0 := .tmp0 t PREŒn/rPREŒn;
28:
tmp0 := tmp0 u POSTŒn;
29:
if tmp0 6 PREŒn then
30:
PREŒn := tmp0;
31:
for each n0 2 Pred.n/ do
32:
if n0 2 path then
33:
WQ.enqueue(n0);
34:
end if
35:
end for
36:
end if
37: end while
38: return PRE;
8.5
Relational Signatures
For a vulnerable dependency graph G with multiple inputs contributing to the vul-
nerability, our patching algorithm (line 12) calls the relational signature generation
algorithm (Algorithm 6) to generate a relational vulnerability signature. A relational
vulnerability signature A of n inputs is a MDFA over the n-track alphabet ˙n,
deﬁned as .˙  fg/  : : :  .˙  fg/ (n times), where  62 ˙ is the special
symbol for padding. We further restrict A, so that all tracks are aligned and for any
w 2 L.A/, wŒi 2 ˙ (1  i  n). Let w0Œi denote the longest -free substring
of wŒi.

8.5
Relational Signatures
117
Algorithm 6 RELSIGGEN(G; In; attkPtrn)
1: INIT(MPOST; G; In);
2: sink := GETSINK(G);
3: queue WQ := NULL;
4: for n 2 In [ Root.G/ do
5:
WQ.enqueue(Succ.n/);
6: end for
7: while WQ ¤ NULL do
8:
n := WQ.dequeue();
9:
if n is concat then
10:
A : = CONCATSIGNATURE(MPOSTŒn:p, MPOSTŒn:s);
11:
else
12:
A : = F
n02Pred.n/ MPOSTŒn0;
13:
end if
14:
A := .A t Œn/rMPOSTŒn;
15:
if A 6 MPOSTŒn then
16:
MPOSTŒn := A;
17:
WQ.enqueue(Succ.n/);
18:
end if
19: end while
20: A:= MPOSTŒsinku EXTEND(attkPtrn, jInj);
21: Project the output track away from A;
22: return A;
Given a dependency graph G, a set of input nodes In, a sink node sink, and an
attack pattern attkPtrn, our goal is to generate a relational vulnerability signature
A such that: (1) A is an jInj-track MDFA. Each track is associated with an input
variable Xn, n 2 In. (2) For any word w (wŒi 2 ˙), we have w 2 L.A/ if
the following condition holds: if we set w0Œi as the initial value of the input node
i and propagate the values of the nodes along with G accordingly, the value of the
node sink matches the pattern attkPtrn. I.e., w identiﬁes the malicious inputs whose
combination may exploit the vulnerability.
The algorithm to generate a relational vulnerability signature is shown in Algo-
rithm 6. We perform forward ﬁxpoint computation on the dependency graph where
replace nodes are ignored. Our relational vulnerability signature algorithm is
not capable of handling replace statements. However, since we run the vulnerability
signature generation after a vulnerability is detected, we argue that it is reasonable to
ignore the sanitization statements in the code (which is the typical use for the replace
statements). After we generate the relational vulnerability signature, the existing
sanitization statements can be commented out and replaced with the automatically
generated sanitization statements.
Similar to the other analyses we presented, we use a standard work queue
algorithm incorporating the automata widening operator. Each node is associated
with a signature, an i+1-track MDFA where the ﬁrst i tracks are associated with
some input variables, e.g., Xn; n 2 In, and the last track (output track) is associated
with Xo used to represent the values of the current node. More speciﬁcally, i
(0  i  jInj) is the number of the input variables whose values have been used

118
8
Vulnerability Detection and Sanitization Synthesis
to construct the values of the current node. We use a MDFA vector MPOST where
MPOSTŒn is the signature associated with node n and it speciﬁes the relations
among the values of the input variables and the values of n.
Initially, for each input node n 2 In, MPOSTŒn is a 2-track MDFA (associated
with Xn and Xo) that accepts the identity relation on Xn and Xo, i.e., the value of the
current node is equal to the value of the input variable Xn. For a node n 2 Root.G/ n
In, MPOSTŒn is a single-track DFA (associated with Xo) that either accepts ˙ if
n is a variable node, or accepts a constant value if n is a constant node. I.e.,
the current value of the node is an arbitrary string or a constant. In both cases, it is
not related to any input variable. For the rest, i.e., n 62 Root.G/, MPOSTŒn accepts
an empty set.
After we initialize MPOST at line 1, we perform the ﬁxpoint computation.
Between lines 7 and 19, we iteratively update the signature at each node until the
queue is empty (reaching a ﬁxpoint). To deal with the union or widening operator
on A1 and A2 that may be associated with the different sets of input variables, say
X1 and X2, we extend both tracks to X1 [ X2 and Xo by padding s in the added
tracks. We then apply standard union or widening to these extended MDFAs.
Below we describe how to concatenate two signatures: CONCATSIGNATURE(A1,
A2), where A1 is the signature of the preﬁx node and A2 is the signature of the sufﬁx
node. Let A1 D hQ1; ˙1; ı1; I1; F1i be a MDFA whose tracks are associated with
the set of input variables X1 and Xo where ˙1 D .˙ [ /jX1j  ˙. Let A2 be a
MDFA whose tracks are associated with the set of input variables X2 and Xo where
˙2 D .˙ [ /jX2j  ˙. We ﬁrst extend A1 and A2 to two MDFA A
1 and A
2 that
are associated with X1 [ X2 and Xo. We extend A1 (preﬁx) to A
1 by adding  in the
added tracks, while we extend A2 (sufﬁx) to A
2 by adding  in both the added tracks
and the common tracks that are also associated with A1. CONCATSIGNATURE(A1,
A2) returns the .jX1 [ X2j C 1/-track MDFA that accepts the concatenation of A
1
and A
2.
As for an example, lets consider the signature A1 that has $title as its input
variable (Fig. 8.9a). A1 speciﬁes that the value of the output track (out) is equal
to the value of the input track. Lets consider A2 as another signature that speciﬁes
equality but has $name as its input variable (Fig. 8.9b). Both have two tracks, one
for the input track and one for the output track. We have A
1 (Fig. 8.9c) and A
2
(Fig. 8.9d) as the extended automata of A1 and A2, respectively. Both have three
tracks: two input tracks for $title and $name, and one for the output track. Note that
the added track is ﬁlled with the padding symbol . Figure 8.9e shows the result of
the concatenation of these two signatures. The result also has three tracks. For an
accepted word, we have the ﬁrst track value equal to the output track (circulate in
state 0) and then the second track value equal to the output track (move from state 0
to 1 and then stay in state 1).
After reaching a ﬁxpoint, at line 20, we intersect the signature of sink with
the attack pattern on the output track. This is done by the standard intersection
of MPOSTŒsink and the multi-track extension of attkPtrn. EXTEND(attkPtrn, jInj)
returns an jInj+1-track MDFA that accepts fw j wŒXo 2 attkPtrng.

8.6
Sanitization Generation
119
Fig. 8.9 Signature concatenation. (a) A1. (b) A2. (c) A
1. (d) A
2. (e) CONCATSIGNATURE(A1, A2)
Algorithm 7 GENERATEPATCH(vulSig)
1: if Strategy = match-and-block then
2:
patch := GENERATEBLOCKINGSIMULATOR(vulSig);
3: else
4:
˙mc := MINCUT(vulSig);
5:
patch := GENERATESANITIZER(˙mc);
6: end if
7: return patch;
After the intersection, the output track identiﬁes the reachable attack strings, and
the input tracks identify all the malicious inputs whose combination can yield an
attack string. At line 21, we project away the output track from A, and return the
result at line 22 as the relational vulnerability signature of hG; In; attkPtrni.
8.6
Sanitization Generation
In this section we describe ﬁnal phase of Algorithm 1 (line 14) in which we generate
sanitization statements given a vulnerability signature that is characterized either as
a standard single-track automaton (DFA) or a multi-track automaton (MDFA). As
shown in Algorithm 7, we use two sanitization strategies: match-and-block (lines
1–3) and match-and-sanitize (lines 4–6).
In order to implement the match-and-block and match-and-sanitize strategies we
need to generate code for the match and replace statements.

120
8
Vulnerability Detection and Sanitization Synthesis
Match Generation
There are two ways of doing matching: (1) Regular-expression-based matching:
Generate a regular expression from the vulnerability signature automaton and then
use the PHP function preg_match to check if the input matches the generated
regular expression, or (2) Automata-simulation-based matching: Generate code that,
given an input string, simulates the vulnerability signature automaton to determine
if the input string is accepted by the vulnerability signature automaton, i.e., if the
input string matches the vulnerability signature.
We ﬁrst tried the regular-expression-based matching approach. However, this
approach ends up being very inefﬁcient. The alphabet of the vulnerability signature
automata consists of the 256 ASCII characters and the vulnerability signature
automata can have a large number of states if there are a lot of complex string
manipulation operations in the code. In one of the examples we analyzed the
vulnerability signature automaton consists of 811 states. The size of the regular
expression generated from the vulnerability signature automaton can be exponential
in the number of states of the automaton [56]. Hence, we may end up with very
large regular expressions.
In order to do efﬁcient matching we use the DFA simulation algorithm which has
linear time complexity [56]. Given the vulnerability signature DFA, we generate a
function that takes a string as input, simulates the DFA, and returns true if the DFA
accepts the string or false otherwise (line 2). We insert the match function instead
of the preg_match statements shown in the patches in Figs. 8.4 and 8.8.
For the relational vulnerability signatures, we use a similar approach. Given a
relational vulnerability signature characterized as an MDFA, we generate code that
simulates the MDFA during the match generation. The MDFA simulation algorithm
is similar to the DFA simulation algorithm, it just keeps a separate pointer for each
input string to keep track of how much of each track is processed at any given time
and advances the state of the MDFA based on the tuples of input symbols and the
transition relation of the MDFA. The simulation time for MDFA is linear in the total
length of the input strings.
Replace Generation
For the match-and-sanitize strategy, our automated sanitization generation algo-
rithm takes the vulnerability signature automaton as input, and it generates a replace
statement that modiﬁes a given input string in such a way that the modiﬁed string
is not accepted by the vulnerability signature automaton (meaning that the modiﬁed
string cannot cause an attack). We modify the input strings by just deleting a set
of characters using the preg_replace function (our approach can be extended
so that escape characters can be inserted in front of a set of characters rather than
deleting them). In order to prevent extensive modiﬁcation to the input, the set of
characters to be deleted should be as small as possible. The question is how can we
identify the set of characters to be deleted?
First, we will formalize this problem in automata-theoretic terms. Let A D
hQ; ˙; ı; q0; Fi denote a DFA where Q is the set of states, ˙ is the alphabet,
ı  Q  ˙  Q is the transition relation, q0 2 Q is the initial state, and F  Q

8.6
Sanitization Generation
121
is the set of accepting states. L.A/ denotes the language accepted by A. We say
S  ˙ is an alphabet-cut of A, if L.A/ \ LNS D ;, where LNS D .˙  S/ is the set
of all strings that do not contain any character in S. The min-alphabet-cut problem
is ﬁnding the alphabet-cut Smin, such that for any other alphabet-cut S, jSminj  jSj.
For the example automaton in Fig. 8.3 the min-alphabet-cut is f<g.
The min-alphabet-cut problem can also be stated in graph-theoretic terms. Given
a DFA A, an edge-cut of A is a set of transitions E  ı such that, if the set of
transitions in E are removed from the transition relation ı, then none of the states
in F are reachable from the initial state q0. Let SE denote the set of symbols of the
transitions in E. If E is an edge-cut of A then SE is an alphabet-cut of A. Hence,
ﬁnding the min-alphabet-cut is equivalent to ﬁnding an edge-cut with minimum
set of distinct symbols. For the example automaton in Fig. 8.3, the min-edge-cut is
f.0; <; 1/g, which also corresponds to the min-alphabet-cut.
Note that, if the vulnerability signature DFA accepts the empty string, then there
will not be any edge (or alphabet) cut since the initial state would be an accepting
state. For the rest of our discussion we will assume that the DFA for the vulnerability
signature does not accept the empty string (we can easily handle the cases where it
accepts the empty string by ﬁrst testing if the input string is empty and then inserting
a single character to the input if it is).
The min-alphabet-cut problem is NP-hard [128]. This can be proven by a
reduction from the vertex cover problem. A vertex cover of a graph G D .V; E/
is a set of vertices such that each edge of the graph is incident to at least one
vertex of the set. The problem of ﬁnding a minimum vertex cover is known to
be NP-complete. Vertex cover problem can be reduced to the min-alphabet-cut
problem as follows. Given G D .V; E/ we build an automaton A D hQ; ˙; ı; q0; Fi
with the set of states Q D E [ fq0; qFg, the initial state q0, set of ﬁnal states
F D fqFg, alphabet ˙ D V, and the transition relation ı deﬁned as follows:
e D .v; v0/ 2 E ) .q0; v; e/ 2 ı ^ .e; v0; qF/ 2 ı. The min-alphabet-cut for
the automaton A is the minimum vertex cover for the graph G.
Since the min-alphabet-cut problem is intractable, rather than trying to ﬁnd the
optimum solution, we can consider using efﬁcient heuristics that give a reasonably
small cut that is not necessarily the optimum solution. In fact, there is a very good
candidate for a heuristic solution. Given a DFA A, a min-edge-cut of A is an edge-cut
Emin such that for any other edge-cut E, jEminj  jEj. Note that the min-edge-
cut minimizes the number of edges in the edge-cut whereas the min-alphabet-cut
minimizes the set of symbols on the edges in the edge-cut. Interestingly, even
though the min-alphabet-cut problem is intractable, there is an efﬁcient algorithm
for computing the min-edge-cut. We use the Ford-Fulkerson’s max-ﬂow min-cut
algorithm [29] to ﬁnd a min-edge-cut Emin (line 4) where the complexity of the
algorithm is O.jıj2/. Note that jSminj  jEminj, i.e., the min-edge-cut provides and
upper bound for the min-alphabet-cut. So if the min-edge-cut is small, then the set of
distinct symbols on the edges of the min-edge-cut will give us a good approximation
of the Smin.

122
8
Vulnerability Detection and Sanitization Synthesis
Once we compute an alphabet-cut S using our heuristic, we generate a
preg_replace statement that deletes the symbols in S from the input, making
sure that the resulting string does not match the vulnerability signature (line 5).
The deﬁnition of the min-alphabet-cut problem is different for multi-track
automata. Given an n-track MDFA A over .˙ [ /n, we say an n-tuple S D
.S1; : : : Sn/, where Si  ˙, is an alphabet-cut of A, if L.A/ \ LNS D ;, where
LNS D ...˙ S1/[/: : : ..˙ Sn/[/// is the set of all strings whose ith track
does not contain any character in Si. Let jSj D jS1j C : : : C jSnj. The min-alphabet-
cut problem for a MDFA A is ﬁnding the alphabet cut Smin of A, such that for any
alphabet cut S of A, jSminj  jSj.
Since min-alphabet-cut is intractable for single-track DFA, it is also intractable
for MDFA. We use min-edge-cut also as an approximation for min-alphabet-cut for
MDFA. When we ﬁnd a min-edge-cut, we compute the corresponding multi-track
alphabet-cut by computing a set of symbols for each track by collecting the set of
distinct symbols (other than ) on each track on the edges in the min-edge-cut (line
4). The resulting alphabet cut is an n-tuple S D .S1; : : : ; Sn/, where each Si is the set
of symbols for track i, i.e., input i.
Once we compute the alphabet-cuts, we generate one preg_replace state-
ment for each input variable i, that deletes every symbol in Si from the input i so
that the resulting input strings do not match the vulnerability signature (line 5).
8.7
Summary
In this chapter we discussed how to detect web application vulnerabilities and how
to synthesize sanitization code that repairs them via string analysis. Speciﬁcally,
we discussed techniques that generate a characterization of inputs that can exploit
an identiﬁed vulnerability (called vulnerability signature) and we discussed how
to generate sanitization statements that eliminate the identiﬁed vulnerability. Since
many critical security vulnerabilities in web applications are caused by inadequate
manipulation of input strings, and given the prevalence of erroneous input validation
and sanitization in web applications, it would be valuable to have an approach that
automatically generates provably correct sanitizers. The technique we presented is
code-sensitive, i.e., it takes into account how the application code manipulates the
input value before it reaches a sink. By synthesizing customized repairs for web
applications, the techniques we discuss provide a sound approach to ensuring that
the detected vulnerabilities (with respect to the given attack patterns) have been
eliminated.

Chapter 9
Differential String Analysis and Repair
Effectiveness of policy-based bug detection and repair that we presented in previous
chapter depends on the correctness and precision of the written policies in char-
acterizing good and bad string values. It is often possible, for instance, to encode
well-known attacks into security policies (in the form of attack patterns) and write
down policies for common input ﬁelds such as email address and zip code. In
other cases, however, the checks to be performed on the inputs are speciﬁc to the
functionality of the web application, and the input validation may be tightly coupled
with and dependent on the application logic. Because they are speciﬁc to individual
applications, there are no pre-speciﬁed policies that can be used to assess these types
of input checks. In these cases, to make sure that the input validation is adequate,
it would be necessary to specify a different policy for each different application,
which is a tedious and error-prone task.
In this chapter, we present a differential analysis and repair approach [5, 7] for
analyzing and repairing validation and sanitization functions in web applications.
This new approach eliminates the need to write manual speciﬁcations by exploiting
redundancy in input validation and sanitization code.
Web application developers often introduce redundant input validation and
sanitization code in the client and server-side code of a web application. The
checks done on the client-side improve the responsiveness of the application by
preventing unnecessary communication with the server and reduce the server load
at the same time. However, since a malicious user can by-pass the client-side checks,
it is necessary to re-validate and re-sanitize at the server-side. Moreover, many
applications repeat the checks for different types of ﬁelds in different parts of the
application which can be exploited to obtain multiple instances of the validation
and sanitization code with the same intended functionality. Finally, across different
applications, one can easily ﬁnd multiple instances of validation and sanitization
code used to check standard formats (such as email) or to protect against same class
of vulnerabilities (such as SQL injection and XSS). Using the differential analysis
and repair techniques presented in this chapter, we exploit these redundancies
© Springer International Publishing AG 2017
T. Bultan et al., String Analysis for Software Veriﬁcation and Security,
https://doi.org/10.1007/978-3-319-68670-7_9
123

124
9
Differential String Analysis and Repair
Fig. 9.1 JavaScript and HTML code snippets for client-side validation
within and application and across applications, to automatically detect and repair
differences between input validation and sanitization functions by comparing them
against each other.
A Motivating Example
Let us take a look at this example taken from a real web application called
JGOSSIP (http://sourceforge.net/projects/jgossipforum/), a message board written
using Java technology. Figures 9.1 and 9.2 show two snippets of client- and server-
side validation code, respectively, from this application (we slightly simpliﬁed the
code to make it more readable and self-contained).1 The user ﬁlls the client-side
form, shown on lines 18–22 of Fig. 9.1, by providing an email address to the HTML
input element with name “email” and by clicking on the “Submit” button. When this
button is clicked, the browser invokes the JavaScript function validateEmail,
which is assigned to the onsubmit event of the form. This function ﬁrst fetches
the email address supplied by the user from the corresponding form ﬁeld. It then
checks if this address has zero length and, if so, accepts the empty address on line 6.
Otherwise, on lines 9 and 10, the function creates two regular expressions. The
1We present the original functions rather than the IVSL extracted sanitizers to show an example
of an actual difference between two validation functions written in different languages in a web
application.

9
Differential String Analysis and Repair
125
Fig. 9.2 Java server-side validation code snippet
ﬁrst one speciﬁes three patterns that the email address should not match: a single
space character, a string with the @ symbol on both ends, and the string “@.”. The
second one speciﬁes a pattern that the email address should match: start with a set
of alphanumeric characters, followed by symbol @, further followed by another set
of alphanumeric characters, and ﬁnally terminated by a dot followed by two to four
additional alphanumeric characters. If the email address does not match the ﬁrst
regular expression and matches the second one, this function returns true, indicating
acceptance of the email address (line 12), and the form data is sent to the server.
Otherwise, the function rejects the email address by returning false on line 14. This
results in an alert message to inform the user that the email provided is invalid.
When the form data is received by the server, it is ﬁrst passed to the server-side
validation function. For the speciﬁc form in this example, the validation function
used is method validateEmail from class Validator, which is shown in
Fig. 9.2. This method calls a routine on line 3 to extract the value contained in the
email ﬁeld from the form object (bean) and stores it in variable val. It then uses
library Perl5Util to perform the regular expression match operations, which
allows for using the same Perl style regular expression syntax used in the client.
First, the method checks whether the email string is null or has zero length after
applying the trim function, on line 5. If so, it accepts the string. Otherwise, it
checks the address using the same regular expressions used on the client side. As
shown on lines 6–12, the address is accepted if it satisﬁes these regular expression
checks, and it is used for further processing on the server side (e.g., it may be sent
as a query string to the database); otherwise, it is rejected on the server side, and the
user is taken back to the form.
As shown in this example, the regular expression checks are similar on both
ends, which emphasizes that validations on both ends should allow or reject the
same set of inputs. Otherwise, there would be mismatches that may create problems

126
9
Differential String Analysis and Repair
for the application. If the server side is less strict than the client side, this would be
considered a vulnerability (even when such a vulnerability is not exploitable) since
it violates a common security policy that server-side checks should not be weaker
than the client-side checks: a malicious user could bypass the client-side checks
and submit to the server an address that does not comply with the required format,
which may result in an attack. For example, an attacker could inject SQL code in
the email that may result in an SQL injection attack [42]. In general, server-side
checks that are less strict than the client-side checks could lead to two types of
undesirable behaviors: (1) the server side allows some wrong or malicious data to
enter the system, leading to failures or attacks; (2) the client side rejects legitimate
values that should be accepted, resulting in the user being unable to access some of
the functionality provided by the web application.
In our example, the client-side validation code shown in Fig. 9.1 rejects a
sequence of one of more white space characters (e.g., “ ”), for which the condition
on line 6 evaluates to false and the regular expression check on line 11 fails, thereby
resulting in the function returning false. However, for the same input, the second
condition on line 5 of the server-side validation method (Fig. 9.2) evaluates to false,
due to the trim function call, and the string is therefore accepted by the server.
This would lead to white spaces being accepted as email addresses by the server,
which might in turn lead to failures (e.g., the web application might try to send an
email to the user, which would fail due to an invalid email address) or attacks, such
as a denial-of-service attack.
9.1
Formal Modeling of Validation and Sanitization
Functions
In this section we formally specify what we mean by input validation and sanitiza-
tion functions. Input validation and sanitization operations in web applications can
be characterized using three types of functions: (1) pure validator, (2) pure sanitizer
and (3) validating-sanitizer functions [5]. Each of these three types of functions can
further be characterized as either a single-input or multi-input functions. We ﬁrst
deﬁne the single-input version of each of the three function types then generalize
the deﬁnition to multi-input functions.
Pure Validators
A single-input pure validator is a total function:
Fv W ˙ ! f?; >g
that takes a string s 2 ˙ and returns either > indicating that the string is valid and
should be accepted or ? indicating the string is not valid and should be rejected.

9.1
Formal Modeling of Validation and Sanitization Functions
127
Fig. 9.3 An example of a JavaScript pure validator
A multi-input pure validator is a total function:
Fv W .˙/n ! f?; >g
that takes a tuple of strings .s1; s2; : : : ; sn/ 2 .˙/n and returns either > indicating
that all these strings are valid and should be accepted or ? indicating one of the
strings si is not valid and hence the tuple .s1; s2; : : : ; sn/ should be rejected.
Note that, a pure validator does not change the value of the input string, it either
accepts or rejects it as it is. Figure 9.3 shows a JavaScript single-input pure validator
that validates email addresses. The function makes sure that the email address is not
empty (line 2) and that it matches the regular expression for valid email addresses
(line 6). If these two conditions are satisﬁed then it accepts the input by returning
true (line 10) otherwise it rejects it by returning false (lines 3,7). Notice that the
email address value is not modiﬁed by the function.
Pure Sanitizers
A single-input pure sanitizer is a total function:
Fs W ˙ ! ˙
that maps an input string s 2 ˙ to an output string s0 2 ˙.
A multi-input pure sanitizer is a total function:
Fs W .˙/n ! ˙
that maps an input tuple of strings .s1; s2; : : : ; sn/ 2 .˙/n to an output string
s0 2 ˙.
Note that, a pure sanitizer does not reject any input string, however, it may
modify some of the input strings. Figure 9.4 shows a PHP single-input pure sanitizer

128
9
Differential String Analysis and Repair
Fig. 9.4 An example of a
PHP pure sanitizer function
Fig. 9.5 An example of a
PHP validating sanitizer
function
function. The function modiﬁes its input by escaping each " character with a \
character (line 2) then it returns the new modiﬁed value. Notice that the function
does not reject any invalid input that contains the character ".
Validating Sanitizers
A single-input validating-sanitizer is a function:
Fvs W ˙ ! f?g [ ˙
that takes an input string s 2 ˙ and either returns ? indicating that s is invalid or
maps s to output string s0 2 ˙.
A multi-input validating-sanitizer is a function:
Fvs W .˙/n ! f?g [ ˙
that takes a tuple of strings .s1; s2; : : : ; sn/ 2 .˙/n and either returns ? indicating
that one or more of the string values si is invalid or maps .s1; s2; : : : ; sn/ to output
string s0 2 ˙ by modifying and/or combining one or more of the components si of
the input tuple.
Note that, a validating-sanitizer may reject some inputs and modify some others.
For the rest of the dissertation we call a validating-sanitizer function a sanitizer for
short. We model all input validation and sanitization operations in web applications
as sanitizers. Note that, one can simulate a pure validator using a sanitizer: If an
input is rejected by the validator, it is rejected by the sanitizer and if it is accepted
by the validator it is returned without modiﬁcation by the sanitizer. Obviously, any
pure sanitizer is also a sanitizer that never rejects an input. Hence, by just focusing
on sanitizers we are able to analyze all three types of behavior.
Figure 9.5 shows an example of a PHP single input validating-sanitizer function.
The function validates the length of the input on line 2. Then, it sanitizes the input by
deleting the character < on line 5. Finally, the function validates the result again to
make sure it is not empty on line 6. This shows how input validation and sanitization
operations are mixed.

9.1
Formal Modeling of Validation and Sanitization Functions
129
Input Validation vs. Sanitization
Some examples of validation operations that are used in practice are PHP
function preg_match, JavaScript function indexof and Java function
contains which are utilized usually through branch conditions without modifying
the values of string variables. Examples of sanitization operations are JavaScript
and Java replace functions and PHP functions trim, addslashes and
htmlspecialchars. These sanitization operations are typically used to update
the string variables.
In web applications, there is typically a relationship between data read and write
operations and the use of either input validation or input sanitization. In case of a
data read operation that will not change the backend database, input sanitization can
be used in order to convert potentially malicious user inputs into benign ones. This
should not affect the database since these sanitized values will only be used to query
the database but not to change its state.
In case of a data write operation that will change the backend database, the use
of validation vs. sanitization depends on weather or not the input value is used later
to query the database. If the value is going to be used later to query the database,
then input validation is used to make sure that the input is in a correct format that
matches the format of the data type expected by the database. For example, when
signing up in a website, input ﬁelds such as username are usually validated only and
not sanitized. The reason is that, if a sanitizer modiﬁes a username value during sign
up without the user’s knowledge, then the user may not be able to use the original
value s/he signed up with to login. Preventing attack strings that may come through
these ﬁelds is done by validation operations. On the other hand, input ﬁelds for
contents, such as messages in a forum, are sanitized even when they are entered into
the database since they are not used to query the database later on.
Composing Sanitizer Functions
Sanitizer functions can be composed together to produce a new sanitizer function.
This maybe necessary in practice if different types of attacks are expected and
different sanitization functions are used to prevent them. However, as we discuss
later in this chapter, composition of sanitizer functions can have subtle effects that
may lead to sanitization errors.
Here we will consider the composition of single-input sanitizers only. We for-
mally deﬁne the sanitizer composition as follows: Given two single-input sanitizer
functions F1 and F2, their composition, F1 ı F2 W ˙ ! ˙ [ f?g, is a sanitizer
function deﬁned as:
F1 ı F2.x/ D
(
?
if F2 D ?
F1.F2.x//
if F2.x/ ¤ ?

130
9
Differential String Analysis and Repair
9.1.1
Post- and Pre-Image of a Sanitizer
In this section we discuss computing the post-image (i.e., post-condition) or pre-
image (i.e., pre-condition) of a sanitizer function. In our discussion of symbolic
reachability analysis in Chap. 4, we discussed computing pre and post-images of
string operations and statements. In this section we generalize the pre and post-
image deﬁnitions to full sanitizer functions.
Post-Image
Given an input, we call the set of strings returned by a sanitizer function its
post-image (which is the set of strings that reach the return statement). Formally
speaking, given a sanitizer F with n input variables, the set of strings returned by F
when the input language for each input variable vi is restricted to Li where Li  ˙
is deﬁned as:
POST.F; .L1; : : : ; Ln// D fs j 9.s1; : : : ; sn/ 2 L1  
 
 
  Ln W 9s 2 ˙ W
F.s1; : : : ; sn/ D sg
We call this set the post-image of sanitizer F with respect to L1  
 
 
  Ln.
We can compute the post-image of a sanitizer using automata-based forward
symbolic string analysis techniques discussed in Chap. 4. In general, we can not
precisely compute POST.F; .L1; : : : ; Ln// due to undecidability of string analysis
as we discussed in Chap. 2. Instead, we compute an over-approximation of this set,
namely, POSTC.F; .L1; : : : ; Ln//  POST.F; .L1; : : : ; Ln//. This means that, we may
conclude that certain strings are accepted and returned by F when they are not. Since
we are using automata-based symbolic string analysis, the result of the post-image
computation is an automaton that accepts the language POSTC.F; .L1; : : : ; Ln//, and
we denote this automaton as A.POSTC.F; .L1; : : : ; Ln///.
Figure 9.6 shows a sanitizer function F1 along with Venn Diagrams illustrating
its domain and co-domain. Function F1 represents a single-input sanitizer function
F1 W ˙ ! ˙ [ f?g where ˙ D fa; bg. Assuming ˙ as input, the function’s
post-image POST.F1; ˙/ = faa; bb; bag (notice that we always exclude ? from
post-image as it does not represent a returned string value).
Pre-Image
Given a sanitizer function F with n number of input variables and a set of strings
L  ˙ in the co-domain of F, we call the set of input tuples of strings that is
mapped by F to L the pre-image of F with respect to L and we deﬁne it as:
PRE.F; L/ D f.s1; : : : ; sn/ j 9s 2 L W F.s1; : : : ; sn/ D sg
We can use automata-based backward symbolic string analysis techniques we
discussed in Chap. 4 to compute the pre-image of a sanitizer. Again, due to over-
approximation, we compute the set PREC.F; L/  PRE.F; L/.

9.1
Formal Modeling of Validation and Sanitization Functions
131
Fig. 9.6 Example of
post-image (shaded areas) for
a sanitizer function F1
assuming input to be ˙
where ˙ D fa; bg
In this chapter, we focus on non-relational analysis, i.e., we do not use relational
string analysis techniques we discussed in Chap. 5. This means that for a sanitizer
F with more than one input variable the pre-image computation would return the
set .˙/n which is not a useful approximation. Hence, to compute the pre-image of
sanitizers with more than one input, it is necessary to use relational string analysis
techniques.
Figure 9.7 shows the sanitizer function F1 along with its pre-image. Given the
set faa; bag, the pre-image PRE.F1; faa; bag/ D faa; abg.
Negative Pre-Image
We call the set of strings that are rejected by a sanitizer F the negative pre-image
of F. For a given sanitizer function F, this set is deﬁned as:
PRE?.F/ D f.s1; : : : ; sn/ j F.s1; : : : ; sn/ D ?g
Again, we use automata-based backward symbolic string analysis techniques we
discussed in Chap. 4 to compute an over approximation of the negative pre-image,
PREC
?.F/, where PREC
?.F/  PRE?.F/. This means that, we may conclude that
certain strings are rejected by F when they are not. On the other hand, since we
are computing an over-approximation, any string that is rejected by F is guaranteed
to be in PREC
?.F/. Since we are using automata-based symbolic string analysis,
the result of the negative pre-image computation is an automaton that accepts the
language PREC
?.F/, and we denote this automaton as A.PREC
?.F//.
Figure 9.8 shows the negative pre-image of sanitizer F1. PRE?.F1/ D ˙ 
faa; bb; abg.

132
9
Differential String Analysis and Repair
Fig. 9.7 Example of pre-image (the shaded area on the left) of sanitizer function F1 given a subset
of the co-domain of F1 (shaded area on the right)
Fig. 9.8 Example of a negative pre-image (the shaded area on the left) of sanitizer function F1
which is mapped by F1 to ? (i.e., rejected)
Negative Post-Image
Negative post-image does not characterize a subset of the input or the output of
a sanitizer. Given a sanitizer F and a set of possible input values L, the negative
post-image of F with respect to L, POST?.F; L/, is the set of strings that reach the
negative sinks (i.e., reach the reject statements) in F.

9.2
Discovering Client- and Server-Side Input Validation and Sanitization...
133
As with previous image computations, in general, we can not precisely compute
POST?.F; L/ due to undecidability of string analysis. Instead we compute an over-
approximation of this set, namely, POSTC
?.F; L/  POST?.F; L/. This means that,
we may conclude that a string can reach a negative sink when it does not. Since we
are using automata-based symbolic string analysis, the result of the negative post-
image computation is an automaton that accepts the language POSTC
?.F; L/, and we
denote this automaton as A.POSTC
?.F; L//.
9.2
Discovering Client- and Server-Side Input Validation and
Sanitization Inconsistencies
In this section, we present a differential string analysis technique to discover
inconsistencies between the client- and the server-side code in web applications [7].
The presented approach (1) extracts and maps input validation functions at the
client and server sides, (2) models input validation functions as deterministic ﬁnite
automata (DFAs) using string analysis techniques from Chap. 4, and (3) identiﬁes
and reports inconsistencies in corresponding input validation functions.
9.2.1
Extracting and Mapping Input Validation and
Sanitization Functions at the Client- and the Server-Side
In order to extract validation and sanitization functions, we ﬁrst need to identify
entry points of the web application, that is, points where user input is read. At the
client side, such points correspond to input ﬁelds in web forms. Web application
frameworks typically let developers specify the input ﬁelds of a web application, and
the JavaScript validation functions to be applied to each ﬁeld in a conﬁguration ﬁle.
By leveraging this information, one can identify (1) the set of validated and sanitized
inputs on the client side, and (2) the corresponding set of JavaScript functions that
are used for validating and sanitizing such inputs.
The identiﬁcation of the input validation and sanitization code on the server side
is similar to that of the client side, with the difference that validation and sanitization
is typically performed using a different language (for example, Java instead of
JavaScript) and that parameters are read through calls to input functions. Similar to
the client side, web application frameworks also allow developers to specify server
side inputs and corresponding validation and sanitization functions. Therefore, an
analysis of the web application’s conﬁguration ﬁle can also provide us with (1)
the set of validated and sanitized inputs for the server side and (2) the set of Java
functions that are used for validating and sanitizing each of those inputs.
It is worth noting that web applications could also perform input validation
checks directly in the code, without explicitly specifying inputs and corresponding

134
9
Differential String Analysis and Repair
validating functions in a conﬁguration ﬁle. In such cases, static and dynamic
program analysis techniques can be used to extract input validation and sanitization
functions [4]. One approach is to use crawling to ﬁnd input ﬁelds and corresponding
sinks in a web application. When the crawler hits a web page with an HTML form, it
can ﬁll it out automatically using a set of pre speciﬁed values and submit it. Then, for
each HTML input ﬁeld, client-side validation and sanitization code (in JavaScript)
can be dynamically extracted, resulting with one sanitizer function per each input
ﬁeld. On the server-side, one can also collect the execution traces to ﬁgure out the
inputs and the sinks (where the inputs ﬂow into) and the code that is executed
during crawling. This information can later on be used to extract the server-side
sanitizer functions and to map server-side sanitizer functions to client-side sanitizer
functions [4].
9.2.2
Inconsistency Identiﬁcation
Given a client-side validator/sanitizer Fc and a server-side validator/sanitizer Fs for
an HTML input ﬁeld i, the inconsistency identiﬁcation is the problem of ﬁnding if
Fc and Fs return different output values for the same set of inputs. Two functions Fc
and Fs are inconsistent if POST.Fs; ˙/ ¤ POST.Fc; ˙/.
Algorithm 1 identiﬁes inconsistencies between client- and server-side valida-
tor/sanitizer functions. The algorithm takes as its input a client-side single-input
validator/sanitizer Fc and a server-side single-input validator/sanitizer Fs both
working on the same input ﬁeld i and the type of the functions (identifying if
they are validators of sanitizers). In the algorithm, each variable that has a name
starting with A represents a DFA, each variable with a name starting with F
represents a validator or sanitizer. The algorithm uses the DFA operations u; t; ; :
which correspond to the automata union, intersection, difference, and complement
operations; A is the automata constructor function, and we use L to denote the
language accepted by an automaton. The algorithm starts by computing two DFAs:
Ac.i/ (client side) and As.i/ (server side), where Ac.i/ D A.POSTC.Fc; ˙// and
As.i/ D A.POSTC.Fs; ˙// (lines 1,2).
Using Ac.i/ and As.i/, we construct two new automata:
•
Asc.i/ where Asc.i/ D As.i/  Ac.i/ (line 3), and
•
Acs.i/ where Acs.i/ D Ac.i/  As.i/ (line 18).
We call Asc.i/ and Acs.i/ difference signatures, where:
•
L.Asc.i// contains strings that are accepted and returned by the server side but
rejected by the client side, and
•
L.Acs.i// contains strings that are accepted and returned by the client side but
rejected by the server side.
Let us now consider various scenarios for the difference signatures. If
L.Asc.i// D L.Acs.i// D ;, this means that our analysis could not identify

9.2
Discovering Client- and Server-Side Input Validation and Sanitization...
135
Algorithm 1 INCONSISTENCYIDENTIFICATION(Fc; Fs; type)
1: Ac WD A(POSTC(Fc; ˙));
2: As WD A(POSTC(Fs; ˙));
3: Asc WD As  Ac;
4: if L.Asc/ ¤ ; then
5:
if type D validators then
6:
Find w 2 L.Asc/;
7:
if .Fc.w/ D ?/ ^ .Fs.w/ ¤ ?/ then
8:
Report Bug in Server-Side Validator Fs; return w; //counter example
9:
end if
10:
else
11:
Asi WD A(PREC(Fs; Asc));
12:
Find w 2 L.Asi/;
13:
if (.Fc.w/ D ?/ ^ .Fs.w/ ¤ ?/ then
14:
Report Bug in Server-Side Sanitizer Fs; return w; //counter example
15:
end if
16:
end if
17: end if
18: Acs WD Ac  As;
19: if L.Acs/ ¤ ; then
20:
if type D validators then
21:
Find w 2 L.Acs/;
22:
if .Fs.w/ D ?/ ^ .Fc.w/ ¤ ?/ then
23:
Report Bug in Client-Side Validator Fc; return w; //counter example
24:
end if
25:
else
26:
Aci WD A(PREC(Fc; Acs));
27:
Find w 2 L.Aci/;
28:
if .Fs.w/ D ?/ ^ .Fc.w/ ¤ ?/ then
29:
Report Bug in Client-Side Sanitizer Fc; return w; //counter example
30:
end if
31:
end if
32: end if
any difference between the client- and server-side validation functions, so we
have no errors to report. Note that, due to over-approximation in our analysis, this
does not mean that the client and server-side validation functions are proved to be
equivalent. It just means that our analysis could not identify an error.
If L.Asc.i// ¤ ;, there might be an error in the server-side validation function
(line 4). A server-side input validation function should not accept a string value that
is rejected by the client-side input validation function—as we discussed earlier, this
would be a security vulnerability that should be reported to the developer. Due to
over-approximation in our analysis, however, our result could be a false positive. To
prevent generating false alarms, we validate the error as follows.
We try to ﬁnd an example input string that would result in the difference between
the client and server-side. Since a validator does not modify its input, then we do
not need to compute the preimage of the difference. Instead, we generate a string
s 2 L.Asc.i// and execute both the client and server-side input validation functions
by providing s as the input value for the input ﬁeld i. If client-side function rejects

136
9
Differential String Analysis and Repair
the string, and server-side function accepts it, then we are guaranteed that there is
a problem with the application and report the string s as a counter-example to the
developer. If we cannot ﬁnd such a string s, then we do not report an error (lines
5–9).
If we have sanitizers then we need to do pre-image computation to get the set of
input values that resulted in the difference. Then we generate the example from this
set, i.e., generate s 2 PREC.Fs; Asc/ (lines 10–16).
We also check if L.Acs.i// ¤ ; and, if so, we again generate a string
to demonstrate the inconsistency between the client and server-side validation
functions. Note that client-side validation functions accepting a value that the server
rejects may not be as severe a problem as their counterpart (lines 19–32). It is
nevertheless valuable to report this kind of inconsistencies because ﬁxing them
can improve the performance and response time of the web application and prevent
client-side vulnerabilities [94].
9.3
Semantic Differential Repair for Input Validation
and Sanitization
After ﬁnding the differences between two input validation and sanitization func-
tions, the next step is to repair the functions against each other to remove the
difference. In this section we present a semantic differential repair algorithm [5]
that exploits redundancies in input validation and sanitization, within an application
and across applications, to automatically repair input validation and sanitization
functions by comparing them against each other.
An Example
Let us give an overview of the automated differential repair technique that
strengthens the validation and sanitization functionality of a given target function
based on a given reference function. Consider the example functions shown in
Fig. 9.9. We are showing the original functions written in PHP language to help
the reader when comparing the original functions with the generated patches.
The reference function starts with a validation check that blocks any string that is
longer than 4 characters. This is followed by a sanitization operation which replaces
the character < with  (i.e., deletes <). Finally, the result of the sanitization operation
goes through another validation check that blocks the empty string. The target
function in Fig. 9.9 does not do any validation. It only sanitizes the input string
by replacing the character " with the string “\"” (i.e., it escapes the double quote
characters).
The goal of the differential repair technique is to strengthen the validation and
sanitization operations in the target function as much as the reference function.
More precisely, the goal is to make sure that the repaired target function does not
return a string that is not returned by the reference function or the original target
function. Before explaining how the differential repair technique works on these

9.3
Semantic Differential Repair for Input Validation and Sanitization
137
Fig. 9.9 A small, but
illustrative example, showing
a target function to be
repaired based on a reference
function
two functions, we would like to discuss two potential repair techniques that may
seem to be the natural choice in this case and explain why they do not work. This
would help the reader to understand the motivation behind the choices that were
made in development of the differential repair algorithm.
Repair by Composition
One question we may ask is: why not simply run two sanitizers one after
another? Due to lack of idempotency in some string sanitization operations, one
can not blindly compose two given sanitizers to get a stronger one without ﬁrst
computing the difference between them. For example, composing a reference and
a target sanitizers that have some differences but at the same time share the
following sanitization operation preg_replace(’/"/’, ’\"’, $x)—which
escapes the " with a \—is problematic. Since this operation is not idempotent,
the composition would result in double escaping i.e., “ab"c” would become
“ab\\"c” instead of “ab\"c”. Furthermore, we repair sanitizers that are extracted
from different programming languages (and different applications in some cases).
The original two pieces of code where we extracted the two sanitizers from are
written in different languages with different semantics and contain other logic
related to the functionality of the application where they were extracted from.
This shows the importance of the (1) extraction phase in removing code unrelated
to validation and sanitization and (2) using a language agnostic string analysis
framework in which the semantic differences are handled by reducing them to
differences between regular languages.
The goal of repair is to make sure that the post-image of the repaired function
does not contain any string that is not in the post-image of the reference function
and the original target function.
The post-image for the reference function in Fig. 9.9 is the language of all strings
that are shorter than 5 characters and not empty and do not contain the character
<, while the post-image for the target function is the language of all strings that do

138
9
Differential String Analysis and Repair
not contain the character " unless it is preceded by the character \. For example,
the string “foo” is an element in the reference function’s post-image while the
string “foo<” is not since it contains the < character. Also, the strings “foo”
and “foo\"bar” are elements in the target function’s post-image while the string
“foo"bar” is not since it contains the character " without being preceded by the
character \.
The differential repair algorithm we discuss below works in three phases, where
each phase generates a patch-function with a speciﬁc purpose: (1) a validation patch,
(2) a length patch, and (3) a sanitization patch. The ﬁnal repair is obtained by
applying the composition of all three patch-functions together as we explain below.
Validation patch
The purpose of this phase is to generate a patch that makes sure that the repaired
function rejects all the inputs that are rejected by the reference function. Figure 9.10
shows the validation-patch produced in this phase of the repair algorithm for our
running example. The validation patch blocks all input strings that are either empty,
Fig. 9.10 The repaired function that is generated by our differential repair algorithm for the target
function shown in Fig. 9.9

9.3
Semantic Differential Repair for Input Validation and Sanitization
139
consist of one or more < characters or longer than 4 characters. For example, the
strings “”, “<”, “<<<” and “<html>” will be blocked by the validation patch. On
the other hand, the strings “fo” and “<a>” will not be blocked.
The validation patch blocks the inputs that generate a string that is in the post-
image of the target function but not in the post-image of the reference function. Note
that our algorithm is able detect that some input strings are blocked by the reference
function only after being sanitized such as the string “<<<” (which is ﬁrst converted
to empty string by deletion of < and then blocked by the reference function). So, for
this case, to make sure that the string “<<<” is not in the post-image of the repaired
function, the validation patch blocks it.
Length patch
The purpose of this phase is to make sure that (1) the maximum length of the
strings that are in the post-image of the repaired function is not bigger than the
maximum length of the strings that are in the post-image of the reference function
and (2) the minimum length of the strings that are in the post-image of the repaired
function is not smaller than the minimum length of the strings that are in the post-
image of the reference function.
For the reference function in our example, the minimum length is 1, since it
blocks the empty string, and the maximum length is 4. On the other hand, for the
target function, after the validation patch is applied, the minimum length is 1 since
it also blocks the empty string, but the maximum length is not 4 but 8. The reason
is that the sanitization in the target function escapes the " character so that an input
string of length 4 like “""""” (which passes the validation patch) is escaped to
produce the string “\"\"\"\"” at the sink, which is of length 8.
This example shows that due to the sanitization operation in the target function,
we get a length difference in the post-image languages even though the validation
patch has already blocked all strings longer than 4. To address this issue we generate
a length patch that blocks any input string that results in a string longer than 4
characters at the target sink even if the input string itself is shorter than 4 characters.
For example, the length patch blocks the string “"a"” although it has 3 characters
only since it will result in the string “\"a\"” of length 5 at the sink which is longer
than 4 characters. On the other hand, the string “foo” will not be blocked by the
length patch since it will reach the sink as it is, 3 characters long.
Figure 9.10 shows the length patch-function for our example. Note that the
function assumes that the validation patch function is applied before it so it only
blocks things not blocked by the validation patch function. In Sect. 9.3.2.2 we
explain how to automatically generate the length patch-function.
Sanitization patch
The purpose of this ﬁnal phase is to take care of the differences that are due to
sanitization operations. Our goal is to make sure that the post-image of the repaired
function is a subset of the post-image of the reference function.
In our example, there is one sanitization operation in the reference function
in which the character < is deleted. Even after application of the validation and
length patches, this behavior would not be fully replicated at the repaired target

140
9
Differential String Analysis and Repair
function. Although the validation patch will prevent some strings such as “<<<”
from reaching the sink at the repaired function, there are still other strings, such as
“a<b” for example, that will still be in the post-image of the repaired function but
not in the post-image of the reference function, since the character < gets deleted.
The goal of the sanitization patch is to remedy such situations, and make sure that
the sanitization operations in the target function are as strong as the sanitization
operations in the reference function.
Unlike the previous two phases, the sanitization patch does not block the input
strings that are found in the difference between the post-images of the target and
reference functions. Instead we use the min-cut algorithm we discussed in Chap. 8 to
generate sanitization code that will delete (or escape) certain characters in the input
strings such that the difference between the two post-images is removed. Using this
min-cut algorithm, our differential repair algorithm will generate the sanitization
patch-function shown in Fig. 9.10. This function does not block input strings that
contain the character <, but rather, deletes this character from these input strings
and returns the corresponding string without that character. This repair simulates the
same sanitization behavior of the reference function in the new repaired function. In
Chap. 8 we explained the min-cut algorithm and how to automatically generate the
sanitization patch.
Given the ﬁnal sanitization phase, one might think that the ﬁrst two phases
are redundant. However, without the ﬁrst two phases, the repair generated by our
approach can become too conservative by rejecting all input strings or by deleting
all characters from the input string. Dividing the repair generation to three separate
phases enables us to generate a combined repair that is not overly conservative.
The ﬁnal result of the differential repair algorithm for our running example is
shown in Fig. 9.10. The repaired function, is obtained by composing the three patch-
functions, in the order in which they were introduced here, with the original target
function.
Using the extraction techniques we discussed earlier in this chapter, we extract
one sanitizer function per input ﬁeld which characterizes all the validation and
sanitization operations that are used for that particular ﬁeld. Validation and sanitiza-
tion operations involve use of regular expressions and validation operations such as
string match, substring, and sanitization operations such as string replace,
trim, addslashes, htmlspecialchars, etc.
9.3.1
Differential Repair Problem
Given a target sanitizer function FT and a reference sanitizer function FR, the goal
of differential repair is to generate a new sanitizer function FP, called a patch, such
that when FT is patched by composing it with FP, the resulting repaired function
returns a string only if FR and FT can both return that string. I.e., we want to make
sure that a string is not in the post-image of the repaired function if it is not in the
post-image of FT or FR.

9.3
Semantic Differential Repair for Input Validation and Sanitization
141
In order to formalize this, let us deﬁne the difference between the post-images of
two sanitizer functions F1 and F2 as follows:
DIFF.F1; F2/ D fx j 9y 2 ˙ W F1.y/ D x ^ .8z 2 ˙ W F2.z/ ¤ x/g
which is the set of strings that are in the post-image of F1 but not in the post-image of
F2. Given this deﬁnition (along with the deﬁnition of sanitizer’s composition from
Sect. 9.1), the differential repair problem is to automatically construct a patch FP
such that DIFF.FT ı FP; FR/ D ;, which means when we compose FT with FP we
want to make sure that the result, FT ı FP, is at least as strict as FR, i.e., its post-
image is a subset of the post-image of FR. We call this new composed function the
differential repair FDR, where FDR D FT ı FP.
Note that, due to the way we are constructing the differential repair, by
composing the target function FT with the automatically generated patch FP, we
guarantee that the repaired function FDR is at least as strict as FT, i.e., its post-image
is also a subset of the post-image of FT.
9.3.2
Differential Repair Algorithm
Given a target sanitizer FT and a reference sanitizer FR, our differential repair
algorithm consists of three phases that produce three patches: (1) The validation
patch generation phase produces FV, (2) the length patch generation phase produces
FL, and (3) the sanitization patch generation phase produces FS. The result of
our differential repair algorithm is a patch that is the composition of these three
individual patches: FS ı FL ı FV and the repair we generate is the composition of
this patch with the target function, i.e., FDR D FT ı FS ı FL ı FV.
Differential repair algorithm is shown in Algorithm 2. The algorithm takes a
target sanitizer FT and a reference sanitizer FR as input and generates sanitizer
FDR as output which corresponds to differential repair of FT with respect to FR.
The differential repair algorithm computes post or pre-images of given sanitizers
as DFA using the automata based string analysis techniques we discussed in
previous chapters. As before, the DFA operations u; t; ; : correspond to the
automata union, intersection, difference, and complement operations; A is the
automata constructor function, and we use L to denote the language accepted by
an automaton. In the remaining part of this section we discuss the three phases of
the Algorithm 2.
9.3.2.1
Phase I: Validation Patch Generation
Our goal is to generate a validation patch FV such that:
8x 2 ˙ W FR.x/ D ? ) FT ı FV.x/ D ?;

142
9
Differential String Analysis and Repair
Algorithm 2 DIFFERENTIALREPAIR(FT; FR)
1: A1 WD A(PREC
?.FR));
2: A2 WD A(PREC
?.FT));
3: if (L.A1  A2/ ¤ ;) then
4:
AV WD A1  A2;
5:
FV WD GENERATEBLOCKINGSIMULATOR(AV);
6: else
7:
FV WD IDENTITYFUNCTION; AV WD A.;/;
8: end if
9: A1 WD A(POSTC(FR; ˙));
10: A2 WD A(POSTC(FT; L.:AV/));
11: Ad D A2  A1;
12: if (L.Ad/ ¤ ;) then
13:
if (lenmin(A2) < lenmin(A1) _ lenmax(A2) > lenmax(A1)) then
14:
A3 WD RESTRICTLENGTH(A2; A1);
15:
AL WD A(PREC(FT; L.A2  A3/));
16:
FL WD GENERATEBLOCKINGSIMULATOR(AL);
17:
A2 WD A3;
18:
else
19:
FL WD IDENTITYFUNCTION;
20:
end if
21:
Ad WD A2  A1;
22:
if (L.Ad/ ¤ ;) then
23:
Amc WD A(PREC(FT; L.Ad/));
24:
˙mc WD MINCUT(Amc);
25:
FS WD GENERATESANITIZER(˙mc; A1);
26:
else
27:
FS WD IDENTITYFUNCTION;
28:
end if
29: else
30:
FS WD FL WD IDENTITYFUNCTION;
31: end if
32: FDR WD FT ı FS ı FL ı FV; return FDR;
i.e., the validation patch FV guarantees that FT ı FV does not accept inputs that FR
rejects. In order to compute the validation patch, we ﬁrst need to identify the set of
strings that are rejected by FT and FR i.e., their negative pre-images.
As we said before, it is not possible to compute the pre or post-image of
a sanitizer precisely due to undecidability of string analysis problem. We use
automata-based backward symbolic string analysis techniques discussed in Chap. 4
to compute an over approximation of the negative pre-image, PREC
?.F/, where
PREC
?.F/  PRE?.F/. This means that, we may conclude that certain strings are
rejected by F when they are not. On the other hand, since we are computing an over-
approximation, any string that is rejected by F is guaranteed to be in PREC
?.F/. Since
we are using automata-based symbolic string analysis, the result of the negative
pre-image computation is an automaton that accepts the language PREC
?.F/, and we
denote this automaton as A.PREC
?.F//.

9.3
Semantic Differential Repair for Input Validation and Sanitization
143
In lines 1 and 2 of Algorithm 2 we construct two automata A1 and A2, that
accept an over-approximation of the negative pre-images of FT and FR, respectively,
where L.A1/ D PREC
?(FR) and L.A2/ D PREC
?(FT). The next step (line 3) checks
if the reference function FR rejects more input values than the target function FT
by computing the difference between negative pre-images of A1 and A2. If the
difference is empty then FV is assigned the identity function (line 7) which is a
sanitizer function that returns the input as it is without blocking any value (i.e.,
it is a no-op). If the difference is not empty, the target function must be patched to
reject the values rejected by the reference function. To achieve this we automatically
generate a patch that rejects only the strings that are rejected by FR but not FT.
Note that the validation patch we generate is not sound due to over-approximation
of the negative pre-image of the target function FT. The set of strings that are
in PREC
?(FR) u (PREC
?(FT) PRE?(FT)) will not be blocked by the patch we
generate, whereas they should be blocked in order to reach our precise goal. We can
make the validation patch sound by blocking all the strings in PREC
?(FR) without
computing the set difference with PREC
?(FT), but, that would result in generation of
a validation patch in many cases even when it is not necessary. Our experiments
indicate that the imprecision in our pre-image computation is not a problem in
practice since for all the examples we manually checked we observe that PREC
?(FR)
u (PREC
?(FT)PRE?(FT)) D ;.
Figure 9.11 shows the validation patch automaton AV that is automatically
generated for the example shown in Fig. 9.9 where ˙ represents the ASCII
characters. To save space we collapsed all transitions between any two states si and
sj into one transition tij. We annotate this transition with a set of characters ˙C  ˙
such that if a character c is in ˙C then there is a transition on c between si and sj.
The sink state along with transitions into and out of it are omitted.
Since our analysis represents the set of strings at each program point using DFA,
we generate the patch repair function FV based on the DFA that is computed by
our analysis. The validation patch code that is generated with GENERATEBLOCK-
INGSIMULATOR ﬁlters the inputs by simulating the resulting automaton AV in
Fig. 9.11 to determine if the input string is accepted by AV. If the input string is
accepted by the automaton AV, then FV will return ? to block the input, otherwise
it will return the input string without modiﬁcation.
Fig. 9.11 The validation patch automaton AV for the example in Fig. 9.9. The validation patch FV
blocks the strings accepted by this automaton

144
9
Differential String Analysis and Repair
9.3.2.2
Phase II: Length Patch Generation
The goal of length patch generation is to generate a patch FL such that:
8x 2 ˙ W
..9y; z 2 ˙ W jFR.y/j  jFT ı FV.x/j  jFR.z/j/ ) FLcal.x/ D x/ ^
.:.9y; z 2 ˙ W jFR.y/j  jFT ı FV.x/j  jFR.z/j/ ) FLcal.x/ D ?/
i.e., given the target function FT composed with the validation patch FV, FL rejects
any input string that will cause the output of FT ı FV to contain a string of length
longer or shorter than all the strings in the output of the reference function FR.
The validation patch makes sure that any input string rejected by the reference
sanitizer is also rejected by the repaired target sanitizer. However, this does not
mean that the set of strings that are returned by the repaired target sanitizer and the
reference sanitizer are the same after the validation patch since they may be using
different sanitization operations. The length patch is the ﬁrst step in establishing
that the repaired target sanitizer does not return any string that is not returned by
the reference sanitizer. The length patch makes sure that the length of any string
returned by the repaired target function is not larger or smaller than all the strings
returned by the reference sanitizer.
The lines 9–20 in Algorithm 2 construct the length patch. The lines 9 and 10
compute an over-approximation of the post-images i.e., the automata that accept
the set of strings that are returned by the reference sanitizer and the target sanitizer
that is composed with the validation patch. The lines 11 and 12 in Algorithm 2
check if there are any strings that are returned by the target sanitizer composed with
the validation patch that are not returned by the reference sanitizer by checking if
POSTC(FT; L.:AV// POSTC(FR; ˙) D ;. If the difference is empty, then we
consider FT ı FV to be as strict as FR and the analysis concludes by assigning
IDENTITYFUNCTION (i.e., no-op) to length and sanitization patches FL and FS (line
30).
Note that, due to over-approximation in our analysis, it is not guaranteed that
FT ı FV is as strict as FR even if the difference is empty. However, again manual
inspection of our experiments indicate that our approximate analysis always ﬁnds
the differences if they exist since the precision of our post-image computation is
quite good in practice.
If a difference is found, then we check if the difference corresponds to a length
difference in line 13. Let us ﬁrst deﬁne lenmax and lenmin for an automaton. Given an
automaton A, lenmax.A/ D 1 if A accepts an inﬁnite set, and lenmax.A/ is the length
of the longest string accepted by A otherwise. We can check if lenmax.A/ D 1 by
checking if there are cycles in A on any path from the starting state to an accepting
state. If there is at least one cycle, then lenmax.A/ D 1. If there are no cycles,
then lenmax.A/ is ﬁnite, and we use a depth ﬁrst search to compute the length of the
longest string accepted by A. On the other hand, given an automaton A, lenmin.A/ is

9.3
Semantic Differential Repair for Input Validation and Sanitization
145
Fig. 9.12 The length patch automaton AL for the example in Fig. 9.9. The length patch FL rejects
the strings accepted by this automaton
the length of the shortest string accepted by A. If the start state is an accepting state
then lenmin.A/ D 0. Otherwise, lenmin.A/ is computed by ﬁnding the length of the
shortest path from the start state to an accepting state.
If a length difference is found, then we restrict the length of the set of strings
accepted by FT to remove the length difference using the following operation in
line 14:
RESTRICTLEN.A2; A1/ 	 A2 u
lenmax.A1/
G
iDlenmin.A1/
˙i
After the length restriction, in line 15, we use backward symbolic reachability
analysis (that we discussed in Chap. 4) to compute an over-approximation of the
set of input strings that cause the length discrepancy i.e., PREC.F; L/  PRE.F; L/.
Note that, this over-approximation may result in blocking input strings that do not
contribute to the length discrepancy.
In line 16 we generate the length patch FL that blocks the strings that are accepted
by the automaton AL in Fig. 9.12 and returns the strings rejected by AL without
any change. Figure 9.12 shows the length patch automaton AL that our algorithm
computes for the example shown in Fig. 9.9.
9.3.2.3
Phase III: Sanitization Patch Generation
The third and ﬁnal phase in the repair algorithm is the sanitization patch generation,
which results in a patch function FS such that:
8x 2 ˙ W .8y 2 ˙ W FR.y/ ¤ x/ )
.8z 2 ˙ W FT ı FS ı FL ı FV.z/ ¤ x/
which means that, after adding the sanitization patch FS to the previously generated
patches, we want the differential repair FDR D FT ı FS ı FL ı FV to be as strict as
FR in terms of the set of strings it returns.

146
9
Differential String Analysis and Repair
The lines 21–28 in Algorithm 2 generate the sanitization patch. First, in the lines
21, 22, we check if there is a difference between what FT returns (after validation
and sanitization patches are applied) and what FR returns assuming any input. If
no difference is found, then we consider FT ı FL ı FV to be as strict as FR and
the analysis concludes by assigning IDENTITYFUNCTION to FS (line 27). This
indicates that there is no sanitization patch. Note that, as we discussed before, due
to over-approximation our repair algorithm can miss differences, however we have
not observed this in our experiments.
If a difference is found, then, in the line 23, we compute an over-approximation of
the set of input strings that result in such a difference. The set L.Amc/ represents an
over-approximation of the set of all input strings that are the cause of the difference
between the set of strings returned by FR and FT ı FL ı FV. We call Amc the mincut
automaton and in the line 24 we use this mincut automaton to generate a mincut
alphabet using the approach discussed in Chap. 8, such that if the symbols in the
mincut alphabet are removed from the input strings, then the difference between
the post-images of FR and FT ı FL ı FV disappear. Figure 9.13 shows the mincut
automaton Amc for our running example in Fig. 9.9 along with the mincut edges
which correspond to the mincut alphabet ˙mc D {< }.
Then, in the line 25, we generate the sanitization patch FS to either delete or
escape the set of symbols in the mincut alphabet. Finally, in the lines 32 and 33, we
construct and return the differential repair function FDR as the composition of the
target function FT with the three patch functions generated during the three phases
of the repair algorithm.
Code Generation Heuristics
Once we compute an alphabet-cut ˙mc, we generate the sanitization patch FS
with a replace statement that deletes the symbols in ˙mc from the input, making
Fig. 9.13 The mincut automaton Amc for the example in Fig. 9.9. The dotted line shows the mincut
edges with the corresponding mincut alphabet f<g

9.4
Summary
147
sure that the resulting string does not match Amc. Although the function FS is a sound
repair that will guarantee that POSTC.FT ı FS ı FL ı FV; ˙/  POSTC.FR; ˙/,
we apply two heuristics to generate more accurate repair functions.
The ﬁrst heuristic is the escape heuristic. We look at the automaton A1 generated
in line 9 of the Algorithm 2 (which represents all the string values returned by FR),
and check if all the characters in the mincut alphabet ˙mc are always preceded by
the same single character e. If that is the case, we call the character e the escape
character. Formally speaking, given DFA A1 D hQ1; q0; ˙; ı1; FRi, we check that
8q 2 Q1; 8c 2 ˙mc W ı1.q; c/ ¤ sink ) .8q0 2 Q1 W ı1.q0; c0/ D q ) c0 D e/.
If this is the case, then the sanitization patch FS we generate uses the replace
operation to escape all the characters in the mincut alphabet ˙mc (instead of deleting
them) by prepending them with the escape character e.
The second heuristic we use is the trim heuristic. Here, if we get a mincut ˙mc
which contains space characters, we ﬁrst check if A1 accepts any string that contains
a space character (which can be determined by checking if transitions on space
characters always go to the sink). If not, then we generate a patch that deletes the
space characters as in our basic mincut based patch generation algorithm. If A1
does accept a string that contains a space character, then we check if it is the case
that the strings accepted by A1 do not start or end with space characters. Formally
speaking, given DFA A1 D hQ1; q0; ˙; ı1; FRi, we check that for all space character
s ı1.q0; s/ D sink and 8q 2 Q1 W ı1.q; c/ 2 FR ) c ¤ s/. If so, then we generate
patch FS which uses the trim function to delete the space characters from the
beginning and end of each input string.
9.4
Summary
In this chapter we argued that the redundancy in client and server-side validation
and sanitization code in web applications can be exploited to identify potential
inconsistencies in validation and sanitization policies. Differential string analysis
techniques can be used to identify such inconsistencies automatically. We presented
a formal model for input validators and sanitizers as a basis for differential analysis.
Then, we demonstrated that, automata-based symbolic string analysis techniques
can be used to identify inconsistencies between input validators or sanitizers.
Finally, we presented a differential repair approach that automatically strengthens
an existing sanitizer to make it at least as strong as a given reference sanitizer.

Chapter 10
Tools
In this chapter we discuss several tools that implement the techniques we described
in the earlier chapters. The tools we discuss are: An automata based string analysis
library called LIBSTRANGER [127], a vulnerability analysis tool for PHP programs
built on LIBSTRANGER called STRANGER [127], an automated repair tool for string
manipulating code called SEMREP [5], and an automata-based constraint solver for
string constraints called ABC [12].
10.1
LIBSTRANGER
LIBSTRANGER [127] is a string manipulation library that handles all core string and
automata operations described in Chap. 4 such as general language replacement,
concatenation, intersection, union, widen and special replace operations. During
the string forward and backward analysis carried out by STRANGER and SEMREP,
all string and automata manipulation operations that are needed to compute the
post and pre-images of string operations are available in LIBSTRANGER. LIB-
STRANGER uses the MONA library [24] for symbolic representation of automata
using MTBDDs.
The core of LIBSTRANGER is implemented in C language as a shared library
libstranger.so to get faster computation time and to have a tight control on
memory. A C++/Java class called StrangerAutomaton is available to encapsulate the
low level algorithms and data structures and provide a higher level interface to the
library. We used JNA (Java Native Access) to bridge the C language and Java code.
LIBSTRANGER along with its source code and manual is available at: https://github.
com/vlab-cs-ucsb/LibStranger.
© Springer International Publishing AG 2017
T. Bultan et al., String Analysis for Software Veriﬁcation and Security,
https://doi.org/10.1007/978-3-319-68670-7_10
149

150
10
Tools
10.2
STRANGER
STRANGER [127] (STRing AutomatoN GEneratoR) implements the techniques
discussed in Chap. 8 to check the correctness of string validation and sanitization
functions in Web applications with respect to known attacks.
STRANGER is implemented in Java and uses PIXY [60] as a front end and the
string manipulation library LIBSTRANGER (see 10.1) along with MONA [24] for
automata manipulation. STRANGER takes a PHP program and a set of attack patterns
as input and automatically analyzes the given program and reports the possible
vulnerabilities (such as XSS or SQL Injection characterized as attack patterns)
in the program. For each input that leads to a vulnerability, it also outputs the
vulnerability signature, i.e., an automaton (in a dot format) that characterizes all
possible string values for this input which may exploit the vulnerability, along with
the patch generated using the mincut algorithm. STRANGER and several benchmarks
are available at http://www.cs.ucsb.edu/~vlab/stranger.
The architecture of STRANGER is shown in Fig. 10.1. The tool consists of mainly
two modules: (1) the vulnerability analysis module that uses PIXY to parse PHP
code and perform the taint analysis and then performs the vulnerability analysis
and repair and (2) the string analysis module that implements the post- and pre-
image computation and uses LIBSTRANGER and MONA for automata manipulation
operations.
The ﬁrst step in the vulnerability analysis is done by PIXY [60], a taint analysis
tool for detecting web application vulnerabilities. PIXY parses the PHP program
and constructs the control ﬂow graph (CFG). PHP programs do not have a single
entry point as in some other languages such as C and Java, so we process each
script by itself along with all ﬁles included by that script. The CFG is passed to the
taint analyzer in which alias and dependency analyses are performed to generate
dependency graphs. If no tainted data ﬂow to the sink, taint analysis reports the
dependency graph to be secure; otherwise, the dependency graph is considered to
be tainted and passed to the vulnerability analyzer for more inspection.
The vulnerability analyzer implements our repair algorithm (see Chap. 8).
Fig. 10.1 The architecture of STRANGER

10.3
SEMREP
151
The vulnerability analyzer uses symbolic string analysis similar to post- and pre-
image computation from Chap. 4 (that is modiﬁed slightly to work with dependency
graphs).
The dependency graphs are pre-processed to optimize the image computation.
First, a new acyclic dependency graph is built where all the nodes in a cycle (iden-
tifying cyclic dependency relations) are replaced by a single strongly connected
component (SCC) node. The vulnerability analysis is conducted on the acyclic graph
so that the nodes that are not in a cycle are processed only once.
In the forward analysis, we propagate the post images to nodes in topological
order, initializing input nodes to DFAs accepting arbitrary strings. Upon termina-
tion, we intersect the language of the DFA of the sink node with the attack pattern.
If the intersection is empty, we conclude that the sink is not vulnerable with respect
to the attack pattern. Otherwise, we perform the backward analysis and propagate
the pre images to nodes in the reverse topological order, initializing the sink node
to a DFA that accepts the intersection of the result of the forward analysis and the
attack pattern. Upon termination, the vulnerability signatures are the results of the
backward analysis for each input node. For both analyses, when we hit an SCC
node, we switch to a work queue ﬁxpoint computation on nodes that are part of the
SCC represented by the SCC node.
During the ﬁxpoint computation we apply automata widening on reachable states
to accelerate the convergence of the ﬁxpoint computation. We added the ability to
choose when to apply the widening operator. This option enables computation of the
precise ﬁxpoint in cases where the ﬁxpoint computations converges after a certain
number of iterations without widening. We also incorporate a coarse widening
operator that guarantees the convergence to avoid potential inﬁnite iterations of the
ﬁxpoint computation.
10.3
SEMREP
SEMREP is a tool for analysis and repair of validation and sanitization functions
in web applications. SEMREP implements a language-agnostic automated semantic
differential repair algorithm from Chap. 9 to analyze and repair validation and
sanitization functions in web applications. Most of SEMREP is implemented in
C++. MinCut algorithm and patch generator are implemented in Java. SEMREP uses
the LIBSTRANGER library along with MONA library for automata manipulation
operations. Source code for latest version along with the manual are available online
from https://github.com/vlab-cs-ucsb/SemRep.
SemRep consists of two modules: (1) the differential repair module which
implements the differential repair algorithm in Chap. 9 and (2) the symbolic string
analysis module which computes the pre and post-images of a sanitizer. Figure 10.2
shows the architecture of the tool.
The tool takes as input the dependency graphs (see Chap. 8) of two sanitizer
functions. After parsing the dependency graphs, difference computation component

152
10
Tools
Fig. 10.2 The architecture of SEMREP
will send each graph to negative pre-image computation component. In general,
image computation components use forward and backward string analyses to
compute post and pre-images of the function represented by the dependency graph
similar to the way done in STRANGER. Each node in the dependency graph will
be annotated with a DFA (stored in an object of type StrangerAutomaton)
that accepts all possible string values that may reach this node going forward or
backward. (Negative) Pre-image component annotates the input node with the
(negative) pre-image DFA while post-image component annotates the return
node with the post-image DFA.
After negative pre-image computation component ﬁnishes, the difference compu-
tation component uses the two DFAs associated with the input nodes to calculate
the validation patch. Next, it will annotate the input node in the target dependency
graph with the validation patch DFA (if a validation patch is needed) and send
the two dependency graphs to the post-image computation component. Then, it
checks to ﬁnd out if there is a length difference between the validation-patched
target and the reference by checking the length difference between post-image DFAs
that are associated with the return nodes. If a difference is found, it will (1)
restrict the length of the DFA at the target return node by the length of the
DFA at the reference return node and (2) annotate the return node at the
target with the new length-restricted DFA indicating that the language of this DFA
represents the preferred output. It then sends the target dependency graph to pre-
image computation component to compute the pre-image for this preferred output
which represents the length patch DFA.
Then, if after the length restriction there is still a difference between the DFAs
at the sinks (return nodes), the difference computation component will annotate
the return node of the target dependency graph with the DFA that represents
this difference (which we call sanitization difference DFA), indicating a non-
preferred output, and sends that dependency graph to the pre-image computation
component. The pre-image computation component annotates the input node with

10.4
ABC
153
the sanitization patch DFA. Then, the difference computation component sends the
sanitization patch DFA along with the validation and length patch DFAs to the patch
generation component.
The patch generation component will do the following: (1) Generate the code for
the validation and length patches in the preferred programming language provided
in the patch language input. These patches are functions that simulate the validation
and length-patch DFAs. (2) Send the sanitization patch DFA to the mincut algorithm
and uses the returned mincut alphabet to generate the code for the sanitization patch.
10.4
ABC
In this section we discuss the tool ABC (Automata-Based model Counter) that
implements the automata construction and model counting techniques for string
constraints. ABC is implemented based on the algorithms described in Chap. 7.
ABC source code is available online at: https://github.com/vlab-cs-ucsb/SemRep.
Figure 10.3 represents the high-level architecture of ABC. We can divide ABC
into two main components: (1) A compilation module which performs syntactic
operations, (2) automata constructor module for constraint solving and model
counting.
ABC aims to supports SMTLIB language speciﬁcation as an input language in
order to support different types of symbolic execution tools. However, there is no
standard language syntax for string theory in SMTLIB speciﬁcations. Hence, ABC
Fig. 10.3 ABC architecture

154
10
Tools
follows the syntax that CVC4 SMT solver uses for the string theory [73]. Once an
input constraint is given to ABC, it ﬁrst parses it and Formula Transformer pushes
negations down into the boolean connectives. It also checks for syntactic level opti-
mizations that can be done such as constant folding and constant propagation. Next,
Formula Optimizer optimizes the input formula based on equivalence relations. It
also generates implied numeric constraints for the string constraints that have non-
regular truth sets. Next, Dependency Analyzer checks for the dependencies between
variables and divides the input constraint into groups that does not share any
common variable. At the end of compilation phase an Abstract Syntax Tree (AST)
of the input constraint along with the additional information on variables are passed
to automata-construction module. Constraint Solver is responsible for managing
automata construction for different theories. Integer Constraint Solver and String
Constraint Solver modules implements the algorithms described in Chap. 7. ABC
also provides an automata manipulation library that models string operations from
different programming languages. ABC automata manipulation library is extended
from LIBSTRANGER1 library and depends on MONA2 automata manipulation
library. Model Counter implements the automata-based model counting algorithms
described in Chap. 7. ABC provides support for matrix exponentiation based model
counting using big number libraries available to C++ and symbolic model counting
using MATHEMATICA.3
ABC is implemented using the C++ programming language. ABC is imple-
mented as an autotools project to support portability among different systems. It
can be installed as an executable or as a C++ shared library. ABC also provides a
JNI interface which makes it easily available for JAVA applications.
1https://github.com/vlab-cs-ucsb/LibStranger.
2https://github.com/cs-au-dk/MONA.
3https://www.wolfram.com/mathematica/.

Chapter 11
A Brief Survey of Related Work
In this chapter we provide a brief survey of related research work. We ﬁrst give an
overview of alternative approaches to string analysis, followed by a discussion on
recent work on string constraint solvers. We discuss application of string analysis
and string constraint solving techniques to bug and vulnerability detection in web
applications. We conclude the section with a discussion in differential analysis and
program repair techniques.
11.1
String Analysis
As we stated before, string analysis refers to static and dynamic techniques for
reasoning about string expressions in a program. The goal of string analysis is
to compute possible values that string expressions can take during the execution
of the program. String analysis is necessary for veriﬁcation of programs that use
extensive string manipulation. It is especially crucial for vulnerability analysis
in web applications. Below we discuss different technical approaches for string
analysis.
11.1.1
Grammar Based String Analysis
JSA [26] is a static string analyzer for Java programs that has been very inﬂuential.
Given a Java program, JSA ﬁrst constructs a directed ﬂow graph for every speciﬁed
hotspot that captures the ﬂow of strings and string operations while abstracting away
the rest of the program. Nodes of the ﬂow graph represent string constants, variables,
expressions, and operations while edges represent possible data ﬂows. Hotspots
represent the program points where the user of the tool is interested in ﬁnding out
© Springer International Publishing AG 2017
T. Bultan et al., String Analysis for Software Veriﬁcation and Security,
https://doi.org/10.1007/978-3-319-68670-7_11
155

156
11
A Brief Survey of Related Work
the string values that can reach them. This ﬂow graph is then transformed into a
context free grammar (CFG) such that each nonterminal represents a node in the
graph and each terminal represents a constant string. The grammar has the property
that for a node n in the ﬂow graph, the associated nonterminal An has L.An/ (the
set of strings that can be derived from nonterminal An) that contains all possible
string values the string variable or expression represented by that node may take
during program execution. This grammar is then over-approximated (using Mohri-
Nederhof algorithm) using a ﬁnite state automaton A such that L.A/ (language
accepted by the automaton A) represents an over approximation of string values
that may reach the hotspot.
JSA has been applied to statically analyzing the XML transformations in Java
programs [66] by using DTD schemas as types and modeling the effects of XML
transformation operations. Grammar-based string analysis technique has also been
used to check for errors in dynamically generated SQL query strings in Java-based
web applications [118]. Grammar-based string analysis technique has also been
applied to analyzing executable programs for the x86 architecture [27].
Grammar-based string analysis approach has been extended by providing support
for string-based replacement operations in PHP applications [78]. In this extension
the whole HTML output of a PHP program is characterized all at once instead of
one hotspot at a time. Instead of converting the resulting CFG into an automaton and
then giving the results represented as an automaton, this technique stops after the
CFG creation phase and directly uses the resulting CFG in two ways. First, it checks
XSS attacks by intersecting the resulting CFG language with a regular expression
language that represents the dangerous output that contains an XSS attack. Second,
it checks for HTML output well-formedness by checking if the CFG language is
a subset of HTML CFG language. Since this problem is undecidable, it bounds
the depth of tag-nesting in HTML CFG language which converts it into a regular
language. If the subset check succeeds then program’s output is valid otherwise
the bound is increased and a test is done again. To model PHP string operations
such as str_replace, ﬁnite state transducers are used where a transducer transforms
a CFG language based on a string operation by computing its post image under that
operation.
The string analyzer presented in [78] was later used to check for SQL injection
vulnerabilities in PHP applications [119]. First, a CFG language that approximates
strings that may reach an SQL hotspot is computed. Nonterminals in this CFG are
annotated with taint values from taint analysis. Then for each tainted nonterminal,
two checks are applied. First check determines if it is in a literal string syntactic
position in an SQL query. If so, then the second check determines if it has a non-
empty intersection with a regular language that represents strings with odd number
of un-escaped quotes. If so then it is considered to be vulnerable. A similar approach
to check for XSS vulnerabilities is used in [120].

11.1
String Analysis
157
11.1.2
Automata-Based String Analysis
A symbolic automata representation is proposed in [52] and ﬁnite state transducers
based on this representation are used to analyze behaviors of sanitization operations
in [109, 113]. The resulting tool, called Bek, is able to identify whether a target
string is a valid output of a sanitization routine. Later on, this line of research was
extended to string encoding and decoding operations [32, 33, 38, 108]. These tools
limit their analysis to single-input sanitizers.
The automata-based symbolic reachability analysis techniques we discuss in
Chap. 4 also use a symbolic automata representation but involve computation of
ﬁxpoints to determine reachable string values rather than modeling the sanitizers
directly using transducers [129, 130].
Rex [110, 111] combines SMT solving (using Z3 [76]) with symbolic automata
and is effective in encoding and manipulating strings having large alphabets such
as Unicode. This is a related approach to the MTBDD based symbolic automata
encoding we discuss in Chap. 4 [129, 130].
As we discussed in Chap. 5, automata representation can be generalized to multi-
track automata, and multi-track automata can be used to model relations between
string variables [133, 134]. Rather than using multi-track automata to encode the
relationship between input and output of a sanitizer, in this approach, multi-track
automata is used to keep track of the relationships among the variables in a given
program state.
Language-based replacement has been discussed in computational linguis-
tics [45, 61, 80, 107]. These algorithms are based on the composition of ﬁnite
state transducers. By composing speciﬁc transducers, constraints like longest
match and ﬁrst match can be precisely modeled. The transducer-based replacement
function [80] has been implemented in Finite State Automata utilities (FSA) [106],
where automata are stored and manipulated using an explicit representation.
A widening method to analyze strings has been investigated in [25]. The
widening operator is deﬁned on strings and the widening of a set of strings is
achieved by applying the widening operator pairwise to each string pair. The
widening operator we discuss in Chap. 6 is deﬁned on automata, and was originally
proposed in the context of automata representation of arithmetic constraints [17].
A path- and index- sensitive string analysis based on Monadic Second-Order
Logic (M2L) [51] has been proposed in [103]. This technique statically encodes
string operations that are used in java sanitization code into M2L and then checks if
a string generated by the sanitization code satisﬁes a pre-speciﬁed constraint using
an M2L constraint solver such as MONA [24].

158
11
A Brief Survey of Related Work
11.1.3
Hybrid String Analysis
Static analysis techniques typically suffer from lack of scalability or loss of
precision, or both. One approach is to use hybrid techniques that combine static
analysis techniques with dynamic techniques in order to improve both precision and
scalability.
In AMNESIA [50], SQL Injection attacks are fought by ﬁrst applying static
string analysis to approximate the syntactic structure of an SQL query at a hotspot
in a program. Then dynamic monitoring is used to enforce this structure when
executing the program. The key insights behind this approach is that information
needed to predict the possible structure of SQL queries in a web application is
contained within the application’s code. So an SQLI attack, by injecting additional
SQL statements into a query, would violate that structure. AMNESIA uses the static
string analysis tool JSA [26] to analyze the application code and automatically build
a model for the legitimate queries. This analysis is applied per each hotspot in the
application in which an SQL query, stored in a string variable, is sent to the database
for execution. The model used is a non-deterministic ﬁnite automaton. The alphabet
of the automaton is SQL keywords and operators, delimiters and place holders
for input string values. After that, at runtime, all dynamically generated queries
are monitored and checked for compliance with previously statically generated
automaton model. Queries that violate the model are classiﬁed as illegal, prevented
from executing on the database, and reported to the application developers and
administrators.
Saner is a tool [13] that combines dynamic and static techniques to verify PHP
programs. It supports language-based replacement by incorporating FSA tool [106]
and if a sanitizer is found to be vulnerable, then a dynamic analysis is performed to
check using a predeﬁned set of dangerous test cases if sanitization operations could
miss any of these test cases. This approach only supports bounded computation for
loops, and it approximates variables updated in a loop as arbitrary strings if the
computation does not converge within a given ﬁxed bound.
11.2
String Constraint Solvers
There has been signiﬁcant amount of work on string constraint solving in recent
years [2, 44, 53, 54, 63, 71, 73, 93, 104, 135]. Constraint solving has received a lot
of attention since it is used by symbolic execution tools which have become very
popular. String constraint solvers are used speciﬁcally to deal with constraints that
involve string variables.
Decidability problem for string constraints extracted from path conditions for
programs using .NET string library has been studied in [21]. The .NET string library
is modeled using a ﬁrst order language called the string library language. It has
been shown that the satisﬁability of the string library language where the length

11.2
String Constraint Solvers
159
of string variables is ﬁxed and the replace operation is omitted is decidable. If the
length is not ﬁxed but replace is still omitted then the decidability problem is open.
If replace is introduced then the satisﬁability problem is undecidable for constraints
with multiple variables. Hence, it is known that for some classes of string constraints
it is not possible to have both a sound and complete constraint solver, and it is
necessary to use approximations.
There has been three main research directions in string constraint solving:
(1) Automata based solvers that map string constraints to automata [12, 40, 53,
54, 96, 130, 133, 134], (2) Bounded solvers that use bounded encodings such
as bit-vectors [21, 63, 71, 93], and (3) String constraint solvers that focus on
combination of theories [3, 15, 105, 112, 135]. Automata-based constraint solvers
use different types of automata encodings for constraints, and they use approx-
imations for constraints that are non-regular. Bit-vector based solvers support
core string operations such as equality, membership, concatenation, and string
length equations. Additional complex operations can be encoded using core string
operations to some extent. Bounding the length of the strings allows bit-vector
based solvers to handle length equations effectively. Some string constraint solvers
are based on Satisﬁability-Modulo-Theories (SMT) frameworks, and in addition
to supporting core string operations, these solvers can also support some complex
string operations such as replace operation and combination of string and numeric
constraints. Bit-vector based solvers have limited support for mixed string con-
straints. Compared to the bit-vector based approaches, SMT solvers support several
different theories and they are more expressive in terms of mixed constraints.
11.2.1
Automata-Based Solvers
Symbolic execution has been used to perform string analysis on Java programs
where tracing path constraints and encoding the values of string variables are
handled using automata [96]. Symbolic execution has also been used to ﬁnd SQL
injection vulnerabilities in .NET applications, where automata are used to represent
string constraints and support string-based replacement (as opposed to language-
based replacement) [40] Finite state transducers have been used to model constraints
in PHP web applications for test input generation [121]. This approach is based on
concolic execution [95], where results of a concrete execution are used to collect
constraints on program execution. These constraints are then used to generate new
test cases.
An automata-based decision procedure for solving equations over regular lan-
guage variables using partial state space construction has been presented in [53, 54].
Since this work uses a single track automata encoding, it can only provide an
approximation for solving equations over string variables. One potential solution
is using multi-track automata to model relations among string variables [133, 134].
Rex [110, 111] uses symbolic automata to solve string constraints involving regular
expressions.

160
11
A Brief Survey of Related Work
Automata based string constraint solving techniques we discuss in Chaps. 5
and 7 use a symbolic automata representation, and represent the solution sets
of constraints using automata [12, 130, 133, 134]. Using multi-track automata,
relational constraints on multiple variables can also be represented.
11.2.2
Bounded Solvers
In [21] a string constraint solver that solves string constraint in two phases is
presented. First, a string constraint is abstracted into an integer constraint by
replacing each string variable with an unquantiﬁed integer variable. After solving
the generated integer constraint with an SMT solver, results are used to ﬁx (i.e.,
bound) the lengths of the strings. Then the original string constraint is solved after
ﬁxing the length of strings variables in it.
HAMPI [63] allows string constraints to be speciﬁed as a membership in a
context free language or a regular language. Then a higher bound on string variables’
lengths is speciﬁed which converts the constraint into a constraint on a ﬁnite (i.e.,
regular) language. The ability to specify constraints with context free languages is
only a convenience feature which makes it much easier to specify constraints on
variables that hold a context free language values such as SQL queries. Given an
input constraint, it is normalized into a core string constraint where each constraint
is of the form x D R or x ¤ R where R is a regular expression. A simple algorithm is
provided to convert a bounded CFG into a regular expression. Then core constraints
are translated into a quantiﬁer-free logic of bit-vectors constraints which are passed
into a special constraint solver called STP. If there is a solution, HAMPI decodes
the output bit-vectors into a string solution.
A string constraint solver called Kaluza [1] was built on top of the HAMPI. It
uses the same approach of bounding the lengths of the execution paths (by bounding
loops) and using a bounded string solver. Kaluza is used by KUDZU—a symbolic
execution framework for JavaScript—to solve string constraints in JavaScript and
generate new input that is used to explore more execution paths.
On one hand, bounded solvers are able to handle a larger set of string operations
and predicates compared to automata-based string solvers. However, since they
bound the length of strings they may miss some solutions that we can catch
especially given how well our automata-based algorithms scale well with length.
Automata based string constraint solving techniques we discuss in earlier
chapters do not bound the length of the strings, and instead use automata to encode
solution sets of constraints which can be arbitrarily large, and even inﬁnite.

11.3
Bug and Vulnerability Detection in Web Applications
161
11.2.3
Combination of Theories
An earlier research focus in analysis of string manipulation in programs was size
analysis. Size analysis focuses on statically identifying all possible lengths of a
string expression at a program point. This type of analysis can be used to identify
and eliminate buffer overﬂow errors in programs for example [36, 43, 116]. There
have been extensions of automata-based string analysis techniques that can handle
both string and numeric constraints in programs by representing linear arithmetic
constraints as automata as we discussed in Chap. 7 [132].
More recently, there has been a lot of work on SMT-based string constraint
solvers [3, 15, 105, 135] that provide decision procedures for various fragments of
string theories and which can be integrated with other decision procedures within
the SMT framework. These approaches are not strictly restricted to bounded strings
like the bounded string constraint solvers and can determine satisﬁability of string
constraints for unbounded domains in some cases.
11.2.4
Model Counting String Constraint Solvers
A model counting constraint solver does not only determines if a constraint is
satisﬁable, but it also determines the number of solutions to the constraint within
a given bound. SMC is a model counter for string constraints [75]. SMC utilizes
generating functions to count the number of strings that match to an unambiguous
regular expression. In general, SMC generates a model-count range which consists
of an upper bound and a lower bound. SMC cannot determine the precise model
count for a regular expression constraint such as x 2 .ajb/jab, and it cannot
propagate string values across logical connectives which reduces its precision.
In Chap. 7 we discuss an automata-based model counting approach for string
constraints, which reduces the model counting problem to path counting [12]. This
approach has been implemented as the model counting string constraint solver ABC
discussed in Chap. 10. Automata based representation used in ABC allows precise
model counting across logical connectives.
11.3
Bug and Vulnerability Detection in Web Applications
As we discussed in Chap. 1, one of the main motivations for string analysis
is the prevalence of string manipulation code in web applications. There has
been a signiﬁcant amount of research on bug and vulnerability detection in web
applications, and we provide a brief survey below. We ﬁrst present work done on
the client-side then move on to the server-side.

162
11
A Brief Survey of Related Work
11.3.1
Client-Side Analysis
Static analysis of Javascript programs has been an active research topic [9, 9, 47–
49, 58, 59, 62]. Static control [48], information [28] and taint [47] ﬂow analyses have
been used for Javascript programs to detect security vulnerabilities. For example,
GATEKEEPER [46] uses static analysis to verify the enforcement of security
policies written in Datalog on JavaScript widgets.
In general, though, pure static analyses for Javascript suffer from loss of precision
which hinder their applicability in practice. The reason is, Javascript is a dynamic
language and the dynamic features of the language are used heavily [90]. Hybrid
analyses that combine static and dynamic analyses, or combination of string analysis
with string analysis may improve the precision and reduce the rate of false alarms.
For example, since objects and arrays in Javascript are maps from strings to strings,
string analysis maybe useful during static analysis.
In addition to static analysis, dynamic analysis techniques have been used in [1,
6, 35, 64, 94] to extract and/or analyze Javascript code. FLAX [94] uses dynamic
analysis techniques to discover client side validation vulnerabilities. The authors use
dynamic taint analysis to extract validation code related to a certain sink and then
use random fuzzing to test this sink.
In [1] authors developed a symbolic execution framework for JavaScript. At the
core of their framework there is a string constraint solver called KUDZU that is
built on top of the bounded string solver HAMPI [63]. Static string analysis can be
combined with dynamic extraction techniques in order to apply it to JavaScript code
which is hard to analyze using only static techniques [6].
11.3.2
Server-Side Analysis
There has been many static vulnerability detection techniques that have been
developed for PHP and Java web applications. Many of these techniques such
as [26, 78, 103, 118–120] are based exclusively on static string analysis and we
discuss them in more detail in the next section. Pixy [60] uses different static
analysis techniques to build dependency graphs that represent the data ﬂow from
sources to sinks in a PHP web application. Then, it uses taint analysis to detect if
there are vulnerabilities in web applications. The STRANGER [127] and SEMREP [5]
tools discussed in Chap. 10 use Pixy as a front end, and improve the precision of
vulnerability analysis by using string analysis techniques [5, 7, 126, 128].
In [124], the problem of statically detecting SQL injection vulnerabilities in PHP
scripts is addressed using a three-tier approach. Information is computed bottom-
up for the intra-block, intra-procedural, and inter-procedural scope. As a result, the
analysis is ﬂow-sensitive and inter-procedural. Traditional data ﬂow analysis is used
to determine whether unchecked user inputs can reach security-sensitive functions
(called sinks) without being properly checked. However, any information about the

11.4
Differential Analysis and Repair
163
possible strings that a variable might hold is not computed. Thus, some types of
vulnerabilities might be missed. RIPS [31] uses the same technique with extensive
modeling for PHP built-in functions and libraries and extends this approach to
other types of vulnerabilities such cross-site scripting (XSS) and malicious ﬁle
execution (MFE). Phantm [67] runs the PHP web application to solve include
statements and conﬁguration values, and then uses the dynamically collected data to
improve precision of static analysis. Apollo [10] uses dynamic symbolic execution
to generate test cases for the web application. It applies some techniques to minimize
the conditions on the inputs that cause a failure to provide better error reporting.
Dynamic symbolic execution along with grammar based string analysis has also
been used to generate test inputs for PHP web applications [121]. Saner [13] mixes
string-based static and dynamic techniques to discover vulnerabilities.
11.4
Differential Analysis and Repair
Analyzing differences between code segments can be useful in many contexts. As
we have seen with client- and server-side code in web applications, sometimes one
can use one part of code as a speciﬁcation for another part of code. Another scenario
would be to provide reference validation or sanitization code that developers can use
in implementing their own validation and sanitization code. Yet another scenario
would be to determine the affects of changes between different versions of code.
Differential analysis and repair techniques automatically analyze code segments
with respect to each other in order to identify bugs and vulnerabilities or to repair
them.
11.4.1
Differential Analysis
Differential analysis techniques [68–70, 87] typically stop after ﬁnding differences
between different pieces of code without trying to repair it. In [87], differential
symbolic execution is used to ﬁnd differences between original and refactored code
by summarizing procedures into symbolic constraints and then comparing different
summaries using an SMT solver. SYMDIFF [68] computes the difference between
two different functions in a language agnostic way by reducing both functions to
Boggie [14] intermediate language then ﬁnds semantic differences using the Z3
SMT solver [76].
There are several specialized differential analysis techniques that focus on web
applications. In NoTamper [19] the authors analyze client-side script code using
dynamic symbolic execution to generate test cases that are subsequently used as
inputs to the server side of the application. Since the approach relies on dynamic
(black-box) testing, it can suffer from limited code coverage. In a recent follow
up paper [20], a new tool called WAPTEC is presented, which uses symbolic

164
11
A Brief Survey of Related Work
execution of the server code to guide the test case generation process and expand
coverage. MiTV [101] uses dynamic symbolic execution engine Pex [77] to test
the correctness of user input validation functions for .NET web applications. These
functions are ﬁrst classiﬁed according to the type of input they validate. Then each
validation function is tested by comparing it to a subset of the functions under the
same class.
Differential string analysis techniques we discussed in Chap. 9 involve extraction
of client- and server-side validation and sanitization routines and their analysis using
automata-based string analysis techniques [5, 7].
11.4.2
Differential Repair
Differential program repair [8, 81, 92, 97, 98, 122, 123] became an active topic
recently. In [122, 123], detected bugs are repaired based on manually written test
suites using genetic algorithms. The abstract syntax tree (AST) of the program is
randomly mutated multiple times by deleting, swapping and/or copying subtrees
related to the execution path taken by the test suite. Mutation is done until a
mutated version passes the original test suite. Correctness of repairs generated by
this approach depends on the effectiveness of the test suite.
In [97, 98], access control problems in PHP programs are detected by comparing
a possibly buggy AST with one that is considered to be correct and then patch the
difference by inserting statements from the latter into the former. In contrast to these
syntactic repair approaches, the differential repair techniques we discuss in Chap. 9
rely on semantic analysis of the code [5, 7].
In [81, 92], test suites are used to ﬁnd bugs then symbolic execution is used to ﬁnd
constraints on variables that result in such bugs. Using the solution to the negation
of these constraints, a patch is synthesized for the program such that it passes all test
suites.
In [74] a set of sanitizers are automatically placed in a sanitizer free program
based on a user deﬁned policy and a ﬂow graph. The sanitizers are placed in the
ﬂow graph such that they satisfy the speciﬁed policy and at the same time avoid
idempotency problems. The techniques we discussed in Chap. 9 [5, 7] takes the
existing sanitization code into account and places the repair/patch before the original
code, instead of changing the code. This avoids interference with the original
sanitization code that may have side-effects.

Chapter 12
Conclusions
String manipulation is an increasingly important part of modern software
development. And, it can be error prone due to complexity of string expressions.
Many software bugs are caused by errors in manipulation of string values in
programs. Moreover, string manipulation errors can be very costly. One of the
leading causes of software security vulnerabilities is string manipulation errors. We
argue that automated analysis of string expressions in programs is one of the critical
problems in software dependability.
In this monograph we presented automata-based symbolic string analysis tech-
niques for ﬁnding and eliminating bugs and security vulnerabilities in string
manipulating programs.
After presenting an overview of common scenarios for using string manipulation
in programs, we gave examples of common errors and vulnerabilities that are due
to string manipulation. We showed that precise automated analysis of strings is not
possible in general even for very basic string operations such as concatenation. We
also provided an overview of more complex string operations that are commonly
used in programming.
We gave an overview of state space exploration techniques, including explicit
state, symbolic, forward and backward analyses and ﬁxpoint computations. We
argued that automata can be used as a symbolic representation for string analysis,
and we presented a symbolic encoding of automata. We discussed how pre- and
post-condition of common string manipulation operations can be computed using
automata, and how they can be used in symbolic reachability analysis to compute
possible values that string expressions can take during program execution.
We discussed two extensions to basic symbolic reachability analysis for string
expressions using automata: (1) Relational string analysis using multi-track
automata which enables us to keep track of relations among string variables during
reachability analysis; and (2) Automated abstraction and approximation techniques
which enable us to limit the blow-up experienced during static string analysis and
accelerate ﬁxpoint computations in order to achieve convergence.
© Springer International Publishing AG 2017
T. Bultan et al., String Analysis for Software Veriﬁcation and Security,
https://doi.org/10.1007/978-3-319-68670-7_12
165

166
12
Conclusions
Next, we discussed automata-based string constraint solving techniques. In
the last decade, symbolic execution has become the dominant technology for
veriﬁcation of software. However, ability of symbolic execution tools in analyzing
string manipulating code has been very limited. Novel string constraint solving
techniques can improve applicability of symbolic execution to string manipulating
code.
We also discussed model counting for string constraints. Model counting is a
crucial problem for quantitative program analysis. By mapping string constraints to
automata, we can reduce model counting problem to path counting and use existing
techniques from algebraic graph theory for model counting for string constraints.
We discussed how automata-based string analysis techniques can be used for
vulnerability detection in web applications. Furthermore, we showed that automata-
based string analysis techniques can be used to synthesize sanitizers that can be used
to repair vulnerabilities in existing code.
We extended the discussion on vulnerability detection and repair to differential
analysis where the idea is to detect vulnerabilities by detecting inconsistencies
between different pieces of code, and repair the vulnerabilities by eliminating
identiﬁed inconsistencies.
We gave an overview of a set of tools that implement the automata-based string
analysis techniques we discussed. Furthermore, we provided a survey of related
results from the research literature.
We believe that string analysis will continue to be an important problem in
software dependability. Scalable string analysis techniques are sorely needed and we
hope that the topics we discussed in this monograph would inspire other researchers
to make further contributions in this area.

References
1. Prateek Saxena, Devdatta Akhawe, Steve Hanna, Feng Mao, Stephen McCamant, and Dawn
Song. A symbolic execution framework for javascript. In Proceedings of the IEEE Symposium
on Security and Privacy, pages 513–528, 2010.
2. Parosh Aziz Abdulla, Mohamed Faouzi Atig, Yu-Fang Chen, Lukás Holík, Ahmed Rezine,
Philipp Rümmer, and Jari Stenman. String constraints for veriﬁcation. In Proceedings of the
26th International Conference on Computer Aided Veriﬁcation (CAV), pages 150–166, 2014.
3. Parosh Aziz Abdulla, Mohamed Faouzi Atig, Yu-Fang Chen, Lukáš Holík, Ahmed Rezine,
Philipp Rümmer, and Jari Stenman. Computer Aided Veriﬁcation: 27th International Con-
ference, CAV 2015, San Francisco, CA, USA, July 18–24, 2015, Proceedings, Part I,
chapter Norn: An SMT Solver for String Constraints, pages 462–469. Springer International
Publishing, Cham, 2015.
4. Muath Alkhalaf. Automatic Detection and Repair of Input Validation and Sanitization Bugs.
Dissertation, University of California Santa Barbara, 2014.
5. Muath Alkhalaf, Abdulbaki Aydin, and Tevﬁk Bultan. Semantic differential repair for input
validation and sanitization. In Proceedings of the 2014 International Symposium on Software
Testing and Analysis (ISSTA 2014), 2014.
6. Muath Alkhalaf, Tevﬁk Bultan, and Jose L. Gallegos. Verifying client-side input validation
functions using string analysis. In Proceedings of the 2012 International Conference on
Software Engineering, pages 947–957, 2012.
7. Muath Alkhalaf, Shauvik Roy Choudhary, Mattia Fazzini, Tevﬁk Bultan, Alessandro Orso,
and Christopher Kruegel. Viewpoints: differential string analysis for discovering client-
and server-side input validation inconsistencies. In Proceedings of the 2012 International
Symposium on Software Testing and Analysis (ISSTA), pages 56–66, 2012.
8. Jesper Andersen and Julia L. Lawall. Generic patch inference. In Proceedings of the 2008
23rd IEEE/ACM International Conference on Automated Software Engineering, ASE ’08,
pages 337–346, Washington, DC, USA, 2008. IEEE Computer Society.
9. Christopher Anderson, Paola Giannini, and Sophia Drossopoulou. Towards type inference for
javascript. In ECOOP 2005-Object-Oriented Programming, pages 428–452. Springer, 2005.
10. Shay Artzi, Adam Kiezun, Julian Dolby, Frank Tip, Daniel Dig, Amit Paradkar, and
Michael D Ernst. Finding bugs in web applications using dynamic test generation and explicit-
state model checking. Software Engineering, IEEE Transactions on, 36(4):474–494, 2010.
© Springer International Publishing AG 2017
T. Bultan et al., String Analysis for Software Veriﬁcation and Security,
https://doi.org/10.1007/978-3-319-68670-7
167

168
References
11. Abdulbaki Aydin. Automata-based Model Counting String Constraint Solver for Vulnerability
Analysis. Dissertation, University of California Santa Barbara, 2017.
12. Abdulbaki Aydin, Lucas Bang, and Tevﬁk Bultan. Computer Aided Veriﬁcation: 27th Interna-
tional Conference, CAV 2015, San Francisco, CA, USA, July 18–24, 2015, Proceedings, Part
I, chapter Automata-Based Model Counting for String Constraints, pages 255–272. Springer
International Publishing, Cham, 2015.
13. Davide Balzarotti, Marco Cova, Vika Felmetsger, Nenad Jovanovic, Engin Kirda, Christopher
Kruegel, and Giovanni Vigna. Saner: Composing static and dynamic analysis to validate
sanitization in web applications. In Proceedings of the 2008 IEEE Symposium on Security
and Privacy, SP ’08, pages 387–401, Washington, DC, USA, 2008. IEEE Computer Society.
14. Mike Barnett, Bor-Yuh Evan Chang, Robert DeLine, Bart Jacobs, and K. Rustan M. Leino.
Boogie: A modular reusable veriﬁer for object-oriented programs. In Proceedings of the 4th
International Conference on Formal Methods for Components and Objects, FMCO’05, pages
364–387, Berlin, Heidelberg, 2006. Springer-Verlag.
15. Clark Barrett, Christopher L. Conway, Morgan Deters, Liana Hadarean, Dejan Jovanovi´c, Tim
King, Andrew Reynolds, and Cesare Tinelli. Computer Aided Veriﬁcation: 23rd International
Conference, CAV 2011, Snowbird, UT, USA, July 14–20, 2011. Proceedings, chapter CVC4,
pages 171–177. Springer Berlin Heidelberg, Berlin, Heidelberg, 2011.
16. Constantinos Bartzis and Tevﬁk Bultan. Efﬁcient symbolic representations for arithmetic con-
straints in veriﬁcation. International Journal of Foundations of Computer Science (IJFCS),
14(4):605–624, August 2003.
17. Constantinos Bartzis and Tevﬁk Bultan. Widening arithmetic automata. In R. Alur and
D. Peled, editors, Proceedings of the 16th International Conference on Computer Aided
Veriﬁcation (CAV 2004), volume 3114 of Lecture Notes in Computer Science, pages 321–
333. Springer-Verlag, July 2004.
18. Norman Biggs. Algebraic Graph Theory. Cambridge Mathematical Library. Cambridge
University Press, 1993.
19. Prithvi Bisht, Timothy Hinrichs, Nazari Skrupsky, Radoslaw Bobrowicz, and V. N. Venkatakr-
ishnan. Notamper: automatic blackbox detection of parameter tampering opportunities in web
applications. In Proceedings of the 17th ACM conference on Computer and communications
security, CCS ’10, pages 607–618, New York, NY, USA, 2010. ACM.
20. Prithvi Bisht, Timothy Hinrichs, Nazari Skrupsky, and V. N. Venkatakrishnan. Waptec:
Whitebox analysis of web applications for parameter tampering exploit construction. In
Proceedings of the 18th ACM Conference on Computer and Communications Security, CCS
’11, pages 575–586, New York, NY, USA, 2011. ACM.
21. Nikolaj Bjørner, Nikolai Tillmann, and Andrei Voronkov. Path feasibility analysis for string-
manipulating programs. In Proceedings of the 15th International Conference on Tools and
Algorithms for the Construction and Analysis of Systems: Held As Part of the Joint European
Conferences on Theory and Practice of Software, ETAPS 2009,, TACAS ’09, pages 307–321,
Berlin, Heidelberg, 2009. Springer-Verlag.
22. Eric Bodden, Andreas Sewe, Jan Sinschek, Hela Oueslati, and Mira Mezini. Taming
reﬂection: Aiding static analysis in the presence of reﬂection and custom class loaders. In
Proceedings of the 33rd International Conference on Software Engineering, ICSE ’11, pages
241–250, New York, NY, USA, 2011. ACM.
23. Ahmed Bouajjani, Peter Habermehl, and Tomáš Vojnar. Abstract regular model checking. In
Rajeev Alur and Doron A. Peled, editors, Computer Aided Veriﬁcation: 16th International
Conference, CAV 2004, Boston, MA, USA, July 13–17, 2004. Proceedings, pages 372–386,
Berlin, Heidelberg, 2004. Springer Berlin Heidelberg.
24. BRICS. The MONA project. http://www.brics.dk/mona/.
25. Tae-Hyoung Choi, Oukseh Lee, Hyunha Kim, and Kyung-Goo Doh. A practical string
analyzer by the widening approach. In APLAS, pages 374–388, 2006.
26. Aske Simon Christensen, Anders Møller, and Michael I. Schwartzbach. Precise analysis of
string expressions. In Proc. 10th International Static Analysis Symposium, SAS ’03, volume
2694 of LNCS, pages 1–18. Springer-Verlag, June 2003.

References
169
27. Mihai Christodorescu, Nicholas Kidd, and Wen-Han Goh. String analysis for x86 binaries.
In Proceedings of the 6th ACM SIGPLAN-SIGSOFT Workshop on Program Analysis for
Software Tools and Engineering (PASTE 2005). ACM Press, September 2005.
28. Ravi Chugh, Jeffrey A Meister, Ranjit Jhala, and Sorin Lerner. Staged information ﬂow for
javascript. In ACM Sigplan Notices, volume 44, pages 50–62. ACM, 2009.
29. Thomas H. Cormen, Charles E. Leiserson, and Ronald L. Rivest. Introduction to Algorithms.
MIT Press, 1990.
30. CVE. Common Vulnerabilities and Exposures. http://www.cve.mitre.org.
31. Johannes Dahse and Thorsten Holz. Simulation of built-in php features for precise static code
analysis. In Proceedings of Network and Distributed System Security (NDSS’14) Symposium,
2014.
32. Loris D’Antoni and Margus Veanes. Equivalence of extended symbolic ﬁnite transducers. In
Computer Aided Veriﬁcation, pages 624–639. Springer, 2013.
33. Loris D’Antoni and Margus Veanes. Minimization of symbolic automata. In Proceedings
of the 41st annual ACM SIGPLAN-SIGACT symposium on Principles of programming
languages, pages 541–554. ACM, 2014.
34. Loris D’antoni and Margus Veanes. Extended symbolic ﬁnite automata and transducers. Form.
Methods Syst. Des., 47(1):93–119, August 2015.
35. Mohan Dhawan and Vinod Ganapathy. Analyzing information ﬂow in javascript-based
browser extensions. In Computer Security Applications Conference, 2009. ACSAC’09.
Annual, pages 382–391. IEEE, 2009.
36. Nurit Dor, Michael Rodeh, and Mooly Sagiv. Cssv: towards a realistic tool for statically
detecting all buffer overﬂows in c. SIGPLAN Not., 38(5):155–167, 2003.
37. DroidBench.
Droidbench
benchmarks.
https://github.com/secure-software-engineering/
DroidBench.
38. Loris D’Antoni and Margus Veanes. Static analysis of string encoders and decoders. In
Proceedings of the 14th International Conference on Veriﬁcation, Model Checking, and
Abstract Interpretation (VMCAI), pages 209–228, 2013.
39. Philippe Flajolet and Robert Sedgewick. Analytic Combinatorics. Cambridge University
Press, New York, NY, USA, 1 edition, 2009.
40. Xiang Fu, Xin Lu, Boris Peltsverger, Shijun Chen, Kai Qian, and Lixin Tao. A static analysis
framework for detecting sql injection vulnerabilities. In COMPSAC, pages 87–96, 2007.
41. Masahiro Fujita, Patrick C. McGeer, and Jerry Chih-Yuan Yang. Multi-terminal binary
decision diagrams: An efﬁcient data structure for matrix representation. Formal Methods in
System Design, 10(2/3):149–169, 1997.
42. William G. J. Halfond, Jeremy Viegas, and Alessandro Orso. A classiﬁcation of sql injection
attacks and countermeasures. In Proceedings of the International Symposium on Secure
Software Engineering, 2006.
43. Vinod Ganapathy, Somesh Jha, David Chandler, David Melski, and David Vitek. Buffer
overrun detection using linear programming and static analysis. In Proceedings of the 10th
ACM Conference on Computer and Communications Security, pages 345–354, 2003.
44. Vijay Ganesh, Mia Minnes, Armando Solar-Lezama, and Martin C. Rinard. Word equations
with length constraints: What’s decidable? In Proceedings of the 8th International Haifa
Veriﬁcation Conference (HVC), pages 209–226, 2012.
45. Dale Gerdemann and Gertjan van Noord. Transducers from rewrite rules with backreferences.
In Proceedings of the 9th Conference of the European Chapter of the Association for
Computational Linguistics, pages 126–133, 1999.
46. Salvatore Guarnieri and Benjamin Livshits. Gatekeeper: mostly static enforcement of security
and reliability policies for javascript code. In Proceedings of the 18th conference on
USENIX security symposium, SSYM’09, pages 151–168, Berkeley, CA, USA, 2009. USENIX
Association.
47. Salvatore Guarnieri, Marco Pistoia, Omer Tripp, Julian Dolby, Stephen Teilhet, and Ryan
Berg. Saving the world wide web from vulnerable javascript. In Proceedings of the 2011
International Symposium on Software Testing and Analysis, pages 177–187. ACM, 2011.

170
References
48. Arjun Guha, Shriram Krishnamurthi, and Trevor Jim. Static analysis for ajax intrusion
detection. In Proceedings of the International World Wide Web Conference. Citeseer, 2009.
49. Arjun Guha, Claudiu Saftoiu, and Shriram Krishnamurthi. The essence of javascript. In
ECOOP 2010–Object-Oriented Programming, pages 126–150. Springer, 2010.
50. William G. J. Halfond and Alessandro Orso. Amnesia: analysis and monitoring for neutral-
izing sql-injection attacks. In ASE ’05: Proceedings of the 20th IEEE/ACM international
Conference on Automated software engineering, pages 174–183, New York, NY, USA, 2005.
ACM.
51. Jesper G. Henriksen, Jakob Jensen, Michael Jørgensen, Nils Klarlund, Robert Paige,
Theis Rauhe, and Anders Sandholm. Mona: Monadic second-order logic in practice. In
E. Brinksma, W. R. Cleaveland, K. G. Larsen, T. Margaria, and B. Steffen, editors, Tools
and Algorithms for the Construction and Analysis of Systems: First International Workshop,
TACAS ’95 Aarhus, Denmark, May 19–20, 1995 Selected Papers, pages 89–110, Berlin,
Heidelberg, 1995. Springer Berlin Heidelberg.
52. Pieter Hooimeijer, Ben Livshits, David Molnar, Prateek Saxena, and Margus Veanes. Fast and
Precise Sanitizer Analysis with Bek. In Usenix Security Symposium, 2011.
53. Pieter Hooimeijer and Westley Weimer. A decision procedure for subset constraints over
regular languages. In Proceedings of the ACM SIGPLAN Conference on Programming
Language Design and Implementation (PLDI), pages 188–198, 2009.
54. Pieter Hooimeijer and Westley Weimer. Solving string constraints lazily. In Proceedings of
the 25th IEEE/ACM International Conference on Automated Software Engineering (ASE),
pages 377–386, 2010.
55. Pieter Hooimeijer and Westley Weimer. Strsolve: solving string constraints lazily. Automated
Software Engineering, 19(4):531–559, 2012.
56. John E. Hopcroft, Rajeev Motwani, and Jeffrey D. Ullman. Introduction to Automata Theory,
Languages, and Computation (3rd Edition). Addison-Wesley Longman Publishing Co., Inc.,
Boston, MA, USA, 2006.
57. Simon Holm Jensen, Peter A. Jonsson, and Anders Møller. Remedying the eval that men
do. In Proceedings of the 2012 International Symposium on Software Testing and Analysis
(ISSTA), pages 34–44, 2012.
58. Simon Holm Jensen, Magnus Madsen, and Anders Møller. Modeling the html dom and
browser api in static analysis of javascript web applications. In Proceedings of the 19th
ACM SIGSOFT symposium and the 13th European conference on Foundations of software
engineering, pages 59–69. ACM, 2011.
59. Simon Holm Jensen, Anders Møller, and Peter Thiemann. Type analysis for javascript. In
Static Analysis, pages 238–255. Springer, 2009.
60. Nenad Jovanovic, Christopher Krügel, and Engin Kirda. Pixy: A static analysis tool for
detecting web application vulnerabilities. In S&P, pages 258–263, 2006.
61. Lauri Karttunen. The replace operator. In Proceedings of the 33rd annual meeting on
Association for Computational Linguistics, pages 16–23, 1995.
62. Vineeth Kashyap, John Sarracino, John Wagner, Ben Wiedermann, and Ben Hardekopf. Type
reﬁnement for static analysis of javascript. In Proceedings of the 9th symposium on Dynamic
languages, pages 17–26. ACM, 2013.
63. Adam Kiezun, Vijay Ganesh, Philip J. Guo, Pieter Hooimeijer, and Michael D. Ernst. Hampi:
a solver for string constraints. In Proceedings of the 18th International Symposium on
Software Testing and Analysis (ISSTA), pages 105–116, 2009.
64. Haruka Kikuchi, Dachuan Yu, Ajay Chander, Hiroshi Inamura, and Igor Serikov. Javascript
instrumentation in practice. In Programming Languages and Systems, pages 326–341.
Springer, 2008.
65. James C. King. Symbolic execution and program testing. Commun. ACM, 19(7):385–394,
July 1976.
66. Christian Kirkegaard, Anders Møller, and Michael I. Schwartzbach. Static analysis of xml
transformations in java. IEEE Transactions on Software Engineering, 30(3), March 2004.

References
171
67. Etienne Kneuss, Philippe Suter, and Viktor Kuncak. Phantm: Php analyzer for type mismatch.
In Proceedings of the Eighteenth ACM SIGSOFT International Symposium on Foundations
of Software Engineering, FSE ’10, pages 373–374, New York, NY, USA, 2010. ACM.
68. Shuvendu K. Lahiri, Chris Hawblitzel, Ming Kawaguchi, and Henrique Rebêlo. Symdiff: A
language-agnostic semantic diff tool for imperative programs. In Proceedings of the 24th
International Conference on Computer Aided Veriﬁcation (CAV), pages 712–717, 2012.
69. Shuvendu K. Lahiri, Kenneth L. McMillan, Rahul Sharma, and Chris Hawblitzel. Differential
assertion checking. In Proceedings of the 2013 9th Joint Meeting on Foundations of Software
Engineering (ESEC/FSE), pages 345–355, 2013.
70. Shuvendu K. Lahiri, Kapil Vaswani, and C A. R. Hoare. Differential static analysis:
Opportunities, applications, and challenges. In Proceedings of the FSE/SDP Workshop on
Future of Software Engineering Research, pages 201–204, 2010.
71. Guodong Li and Indradeep Ghosh. PASS: string solving with parameterized array and interval
automaton. In Proceedings of the 9th International Haifa Veriﬁcation Conference (HVC),
pages 15–31, 2013.
72. Li Li, Tegawendé F Bissyandé, Damien Octeau, and Jacques Klein. Droidra: taming reﬂection
to support whole-program analysis of android apps. In Proceedings of the 25th International
Symposium on Software Testing and Analysis, pages 318–329. ACM, 2016.
73. Tianyi Liang, Andrew Reynolds, Cesare Tinelli, Clark Barrett, and Morgan Deters. A
DPLL(T) theory solver for a theory of strings and regular expressions. In Proceedings of
the 26th International Conference on Computer Aided Veriﬁcation (CAV), pages 646–662,
2014.
74. Benjamin Livshits and Stephen Chong. Towards fully automatic placement of security
sanitizers and declassiﬁers. In Proceedings of the 40th Annual ACM SIGPLAN-SIGACT
Symposium on Principles of Programming Languages, POPL ’13, pages 385–398, New York,
NY, USA, 2013. ACM.
75. Loi Luu, Shweta Shinde, Prateek Saxena, and Brian Demsky. A model counter for constraints
over unbounded strings. In Proceedings of the ACM SIGPLAN Conference on Programming
Language Design and Implementation (PLDI), page 57, 2014.
76. Microsoft Inc. Z3 SMT Solver. http://z3.codeplex.com.
77. Microsoft Research. Pex. http://research.microsoft.com/en-us/projects/pex/.
78. Yasuhiko Minamide. Static approximation of dynamically generated web pages. In Proceed-
ings of the 14th International World Wide Web Conference (WWW), pages 432–441, 2005.
79. Marvin L. Minsky. Recursive unsolvability of Post’s problem of Tag and other topics in the
theory of Turing machines. In Ann. of Math (74), pages 437–455, 1961.
80. Mehryar Mohri and Richard Sproat. An efﬁcient compiler for weighted rewrite rules. In
Proceedings of the 34th annual meeting on Association for Computational Linguistics, pages
231–238. Association for Computational Linguistics, 1996.
81. Hoang Duong Thien Nguyen, Dawei Qi, Abhik Roychoudhury, and Satish Chandra. Semﬁx:
Program repair via semantic analysis. In Proceedings of the 2013 International Conference
on Software Engineering, ICSE ’13, pages 772–781, Piscataway, NJ, USA, 2013. IEEE Press.
82. Hung Viet Nguyen, Christian Kästner, and Tien N. Nguyen. Building call graphs for
embedded client-side code in dynamic web applications. In Proceedings of the 22nd ACM
SIGSOFT International Symposium on Foundations of Software Engineering (FSE-22), pages
518–529, 2014.
83. Hung Viet Nguyen, Christian Kästner, and Tien N. Nguyen. Varis: IDE support for embedded
client code in PHP web applications. In Proceedings of the 37th IEEE/ACM International
Conference on Software Engineering (ICSE), pages 693–696, 2015.
84. OWASP. Top 10 2007. https://www.owasp.org/index.php/Top_10_2007.
85. OWASP. Top 10 2010. https://www.owasp.org/index.php/Top_10_2010-Main.
86. OWASP. Top 10 2013. https://www.owasp.org/index.php/Top_10_2013-T10.
87. Suzette J. Person. Differential Symbolic Execution. PhD thesis, Lincoln, NB, USA, 2009.
AAI3365729.

172
References
88. Bala Ravikumar and Gerry Eisman. Weak minimization of DFA - an algorithm and applica-
tions. Theor. Comput. Sci., 328(1–2):113–133, 2004.
89. Gideon Redelinghuys, Willem Visser, and Jaco Geldenhuys. Symbolic execution of programs
with strings. In Proceedings of the South African Institute for Computer Scientists and
Information Technologists Conference, SAICSIT ’12, pages 139–148, New York, NY, USA,
2012. ACM.
90. Gregor Richards, Sylvain Lebresne, Brian Burg, and Jan Vitek. An analysis of the dynamic
behavior of javascript programs. In Proceedings of the 2010 ACM SIGPLAN conference on
Programming language design and implementation, PLDI ’10, pages 1–12, New York, NY,
USA, 2010. ACM.
91. Yuto Sakuma, Yasuhiko Minamide, and Andrei Voronkov. Translating regular expression
matching into transducers. J. Applied Logic, 10(1):32–51, 2012.
92. Hesam Samimi, Max Schäfer, Shay Artzi, Todd Millstein, Frank Tip, and Laurie Hendren.
Automated repair of html generation errors in php applications using string constraint solving.
In Proceedings of the 2012 International Conference on Software Engineering, ICSE 2012,
pages 277–287, Piscataway, NJ, USA, 2012. IEEE Press.
93. Prateek Saxena, Devdatta Akhawe, Steve Hanna, Feng Mao, Stephen McCamant, and Dawn
Song. A symbolic execution framework for javascript. In Proceedings of the 31st IEEE
Symposium on Security and Privacy, 2010.
94. Prateek Saxena, Steve Hanna, Pongsin Poosankam, and Dawn Song. Flax: Systematic
discovery of client-side validation vulnerabilities in rich web applications. In Proceedings
of the Network and Distributed System Security Symposium (NDSS), 2010.
95. Koushik Sen, Darko Marinov, and Gul Agha. Cute: a concolic unit testing engine for c.
In Proceedings of the 10th European Software Engineering Conference held jointly with
13th ACM SIGSOFT International Symposium on Foundations of Software Engineering
(ESEC/FSE 05), pages 263–272, 2005.
96. Daryl Shannon, Sukant Hajra, Alison Lee, Daiqian Zhan, and Sarfraz Khurshid. Abstracting
symbolic execution with string analysis. In TAICPART-MUTATION, pages 13–22, 2007.
97. Sooel Son, Kathryn S. McKinley, and Vitaly Shmatikov. Rolecast: Finding missing security
checks when you do not know what checks are. In Proceedings of the 2011 ACM Interna-
tional Conference on Object Oriented Programming Systems Languages and Applications,
OOPSLA ’11, pages 1069–1084, New York, NY, USA, 2011. ACM.
98. Sooel Son, Kathryn S. McKinley, and Vitaly Shmatikov. Fix me up: Repairing access-control
bugs in web applications. In NDSS, 2013.
99. Richard P. Stanley. Enumerative Combinatorics: Volume 1. Cambridge University Press, New
York, NY, USA, 2nd edition, 2011.
100. Zhendong Su and Gary Wassermann. The essence of command injection attacks in web
applications. In Conference Record of the 33rd ACM SIGPLAN-SIGACT Symposium on
Principles of Programming Languages, POPL ’06, pages 372–382, New York, NY, USA,
2006. ACM.
101. Kunal Taneja, Nuo Li, Madhuri R. Marri, Tao Xie, and Nikolai Tillmann. Mitv: multiple-
implementation testing of user-input validators for web applications. In ASE, pages 131–134,
2010.
102. Alfred Tarski. A lattice-theoretical ﬁxpoint theorem and its applications. Paciﬁc Journal of
Mathematics, 5:285–309, 1955.
103. Takaaki Tateishi, Marco Pistoia, and Omer Tripp. Path- and index-sensitive string analysis
based on monadic second-order logic. In Proceedings of the 2011 International Symposium
on Software Testing and Analysis, ISSTA ’11, pages 166–176, New York, NY, USA, 2011.
ACM.
104. Minh-Thai Trinh, Duc-Hiep Chu, and Joxan Jaffar. S3: A symbolic string solver for
vulnerability detection in web applications. In Proceedings of the ACM SIGSAC Conference
on Computer and Communications Security (CCS), pages 1232–1243, 2014.

References
173
105. Minh-Thai Trinh, Duc-Hiep Chu, and Joxan Jaffar. S3: A symbolic string solver for vulnera-
bility detection in web applications. In Proceedings of the 2014 ACM SIGSAC Conference on
Computer and Communications Security, CCS ’14, pages 1232–1243, New York, NY, USA,
2014. ACM.
106. Gertjan van Noord. FSA utilities toolbox. http://odur.let.rug.nl/~vannoord/Fsa/.
107. Gertjan van Noord and Dale Gerdemann. An extendible regular expression compiler for ﬁnite-
state approaches in natural language processing. In Proc. of the 4th International Workshop
on Implementing Automata (WIA), pages 122–139. Springer-Verlag, July 1999.
108. Margus Veanes. Symbolic string transformations with regular lookahead and rollback. In
Proceedings of the 9th Ershov Informatics Conference (PSI’14). Springer, 2014.
109. Margus Veanes and Nikolaj Bjørner. Symbolic automata: The toolkit. In TACAS, pages 472–
477, 2012.
110. Margus Veanes, Nikolaj Bjørner, and Leonardo De Moura. Symbolic automata constraint
solving. In Logic for Programming, Artiﬁcial Intelligence, and Reasoning, pages 640–654.
Springer, 2010.
111. Margus Veanes, Peli De Halleux, and Nikolai Tillmann. Rex: Symbolic regular expression
explorer. In Software Testing, Veriﬁcation and Validation (ICST), 2010 Third International
Conference on, pages 498–507. IEEE, 2010.
112. Margus Veanes, Peli de Halleux, and Nikolai Tillmann. Rex: Symbolic regular expression
explorer. In Proceedings of the 2010 Third International Conference on Software Testing,
Veriﬁcation and Validation, ICST ’10, pages 498–507, Washington, DC, USA, 2010. IEEE
Computer Society.
113. Margus Veanes, Pieter Hooimeijer, Benjamin Livshits, David Molnar, and Nikolaj Bjorner.
Symbolic ﬁnite state transducers: algorithms and applications. In Proceedings of the 39th
annual ACM SIGPLAN-SIGACT symposium on Principles of programming languages, POPL
’12, pages 137–150, New York, NY, USA, 2012. ACM.
114. Margus Veanes, Todd Mytkowicz, David Molnar, and Benjamin Livshits. Data-parallel
string-manipulating programs. In Proceedings of the 42Nd Annual ACM SIGPLAN-SIGACT
Symposium on Principles of Programming Languages, POPL ’15, pages 139–152, New York,
NY, USA, 2015. ACM.
115. David Wagner, Jeffrey S. Foster, Eric A. Brewer, and Alexander Aiken. A ﬁrst step towards
automated detection of buffer overrun vulnerabilities. In Proc. of the Network and Distributed
System Security Symposium, pages 3–17, 2000.
116. David Wagner, Jeffrey S. Foster, Eric A. Brewer, and Alexander Aiken. A ﬁrst step towards
automated detection of buffer overrun vulnerabilities. In In Network and Distributed System
Security Symposium, pages 3–17, 2000.
117. Hung-En Wang, Tzung-Lin Tsai, Chun-Han Lin, Fang Yu, and Jie-Hong R. Jiang. String
analysis via automata manipulation with logic circuit representation. In Computer Aided
Veriﬁcation - 28th International Conference, CAV 2016, Toronto, ON, Canada, July 17–23,
2016, Proceedings, Part I, pages 241–260, 2016.
118. Gary Wassermann, Carl Gould, Zhendong Su, and Premkumar Devanbu. Static checking of
dynamically generated queries in database applications. volume 16, New York, NY, USA,
September 2007. ACM.
119. Gary Wassermann and Zhendong Su. Sound and precise analysis of web applications
for injection vulnerabilities. In Proceedings of the ACM SIGPLAN 2007 Conference on
Programming Language Design and Implementation (PLDI), pages 32–41, 2007.
120. Gary Wassermann and Zhendong Su. Static detection of cross-site scripting vulnerabilities. In
Proceedings of the 30th International Conference on Software Engineering, ICSE ’08, pages
171–180, New York, NY, USA, 2008. ACM.
121. Gary Wassermann, Dachuan Yu, Ajay Chander, Dinakar Dhurjati, Hiroshi Inamura, and
Zhendong Su. Dynamic test input generation for web applications. In Proceedings of the
ACM/SIGSOFT International Symposium on Software Testing and Analysis (ISSTA 2008),
pages 249–260, 2008.

174
References
122. Westley Weimer, Stephanie Forrest, Claire Le Goues, and ThanhVu Nguyen. Automatic
program repair with evolutionary computation. Commun. ACM, 53(5):109–116, May 2010.
123. Westley Weimer, ThanhVu Nguyen, Claire Le Goues, and Stephanie Forrest. Automatically
ﬁnding patches using genetic programming. In Proceedings of the 31st International Con-
ference on Software Engineering, ICSE ’09, pages 364–374, Washington, DC, USA, 2009.
IEEE Computer Society.
124. Yichen Xie and Alex Aiken. Static detection of security vulnerabilities in scripting languages.
In USENIX-SS’06: Proceedings of the 15th conference on USENIX Security Symposium,
pages 13–13, Berkeley, CA, USA, 2006. USENIX Association.
125. Fang Yu. Automatic Veriﬁcation of String Manipulating Programs. PhD thesis, University of
California, Santa Barbara, 2010.
126. Fang Yu, Muath Alkhalaf, and Tevﬁk Bultan. Generating vulnerability signatures for string
manipulating programs using automata-based forward and backward symbolic analyses. In
ASE, 2009.
127. Fang Yu, Muath Alkhalaf, and Tevﬁk Bultan. Stranger: An automata-based string analysis
tool for php. In TACAS, 2010.
128. Fang Yu, Muath Alkhalaf, and Tevﬁk Bultan. Patching vulnerabilities with sanitization
synthesis. In Proceedings of the 33rd International Conference on Software Engineering
(ICSE), pages 251–260, 2011.
129. Fang Yu, Muath Alkhalaf, Tevﬁk Bultan, and Oscar H. Ibarra. Automata-based symbolic
string analysis for vulnerability detection. Formal Methods in System Design, 44(1):44–70,
2014.
130. Fang Yu, Tevﬁk Bultan, Marco Cova, and Oscar H. Ibarra. Symbolic string veriﬁcation: An
automata-based approach. In 15th International SPIN Workshop on Model Checking Software
(SPIN), pages 306–324, 2008.
131. Fang Yu, Tevﬁk Bultan, and Ben Hardekopf. String abstractions for string veriﬁcation. In
Proceedings of the 18th International SPIN Conference on Model Checking Software, pages
20–37, Berlin, Heidelberg, 2011. Springer-Verlag.
132. Fang Yu, Tevﬁk Bultan, and Oscar H. Ibarra. Symbolic string veriﬁcation: Combining string
analysis and size analysis. In 15th International Conference on Tools and Algorithms for the
Construction and Analysis of Systems (TACAS 2009), pages 322–336, 2009.
133. Fang Yu, Tevﬁk Bultan, and Oscar H. Ibarra. Relational string veriﬁcation using multi-track
automata. In CIAA, pages 290–299, 2010.
134. Fang Yu, Tevﬁk Bultan, and Oscar H. Ibarra. Relational string veriﬁcation using multi-track
automata. Int. J. Found. Comput. Sci., 22(8):1909–1924, 2011.
135. Yunhui Zheng, Xiangyu Zhang, and Vijay Ganesh. Z3-str: A z3-based string solver for web
application analysis. In Proceedings of the 9th Joint Meeting on Foundations of Software
Engineering (ESEC/FSE), pages 114–124, 2013.
136. Edmund M. Clarke, Orna Grumberg, and Doron A. Peled. Model Checking. MIT Press, 2001.
http://books.google.de/books?id=Nmc4wEaLXFEC

