Springer Series in Operations Research 
and Financial Engineering
The Logic 
of Logistics
David Simchi-Levi
Xin Chen
Julien Bramel
Theory, Algorithms, and Applications 
for Logistics Management
Third Edition

Springer Series in Operations Research
and Financial Engineering
Series Editors:
Thomas V. Mikosch
Sidney I. Resnick
Stephen M. Robinson
For further volumes:
http://www.springer.com/series/3182


David Simchi-Levi • Xin Chen • Julien Bramel
The Logic of Logistics
Theory, Algorithms, and Applications
for Logistics Management
Third Edition
123

David Simchi-Levi
Massachusetts Institute of Technology
Cambridge, MA, USA
Julien Bramel
Pine River Capital Management
New York, NY, USA
Xin Chen
University of Illinois at Urbana-Champaign
Urbana, IL, USA
ISSN 1431-8598
ISSN 2197-1773 (electronic)
ISBN 978-1-4614-9148-4
ISBN 978-1-4614-9149-1 (eBook)
DOI 10.1007/978-1-4614-9149-1
Springer New York Heidelberg Dordrecht London
Library of Congress Control Number: 2013953645
© Springer Science+Business Media New York 1997, 2005, 2014
This work is subject to copyright. All rights are reserved by the Publisher, whether the whole or part of the
material is concerned, speciﬁcally the rights of translation, reprinting, reuse of illustrations, recitation, broad-
casting, reproduction on microﬁlms or in any other physical way, and transmission or information storage and
retrieval, electronic adaptation, computer software, or by similar or dissimilar methodology now known or here-
after developed. Exempted from this legal reservation are brief excerpts in connection with reviews or scholarly
analysis or material supplied speciﬁcally for the purpose of being entered and executed on a computer system,
for exclusive use by the purchaser of the work. Duplication of this publication or parts thereof is permitted only
under the provisions of the Copyright Law of the Publisher’s location, in its current version, and permission
for use must always be obtained from Springer. Permissions for use may be obtained through RightsLink at the
Copyright Clearance Center. Violations are liable to prosecution under the respective Copyright Law.
The use of general descriptive names, registered names, trademarks, service marks, etc. in this publication does
not imply, even in the absence of a speciﬁc statement, that such names are exempt from the relevant protective
laws and regulations and therefore free for general use.
While the advice and information in this book are believed to be true and accurate at the date of publication,
neither the authors nor the editors nor the publisher can accept any legal responsibility for any errors or omissions
that may be made. The publisher makes no warranty, express or implied, with respect to the material contained
herein.
Printed on acid-free paper
Springer is part of Springer Science+Business Media (www.springer.com)

To my wife, Yu, and my children, Jennifer, Jonathan and Hannah, for their love
and support.
Xin Chen
In memory of Professor Uriel Rothblum, a friend, a colleague, and a scholar,
whose research spans theory and applications.
David Simchi-Levi


Preface
We are pleased to introduce the third edition of the book, and we are thankful to
those who used the book in research and practice and to those who sent us com-
ments and feedback. As before, our objective is to present, in an easily accessible
manner, logistics and supply chain models, algorithms, and tools. In this edition,
we have attempted to build on the positive elements of the ﬁrst two editions and
to include what we have learned in the last few years, since the publication of the
second edition.
In the last two decades, the academic community has focused on addressing
many supply chain challenges. In some cases, the focus is on characterizing the
structure of the optimal policy and identifying algorithms that generate the best
possible policies. When this is not possible, the focus has been on an approach
whose purpose is to ascertain characteristics of the problem or of an algorithm
that are independent of the speciﬁc problem data. That is, the approach deter-
mines characteristics of the solution or the solution method that are intrinsic to
the problem and not the data. This approach includes the so-called worst-case and
average-case analyses, which, as illustrated in the book, help not only to under-
stand characteristics of the problem or solution methodology, but also to provide
speciﬁc guarantees of eﬀectiveness. In many cases, the insights obtained from these
analyses can then be used to develop practical and eﬀective algorithms for speciﬁc
complex logistics problems. Finally, game-theoretic approaches have been applied
in the last few years to provide more insights to supply chain models involving
competition and collaboration.
We have made several important changes to the third edition of this text. Many
of these changes have been a result of new research or consulting engagement we
have completed in the last few years. Our major changes include
vii

viii
Preface
• a new chapter on game theory, where we introduce the reader to key concepts
and techniques (Chap. 3),
• a new chapter on supply chain competition and collaboration, where we
extensively apply game theory (Chap. 11),
• a new chapter on process ﬂexibility, where we explain the power of limited
degree of ﬂexibility (Chap. 13),
• a new section (Sect. 2.3) on discrete convex analysis,
• a new section (Sect. 9.6) on stochastic inventory models with positive lead
times.
Additionally, we have extended the materials on integrated inventory and pricing
models, including three new sections on the economic lot sizing model with pricing
(Sect. 8.4), demand models (Sect. 10.2), and an alternative approach for deriving
the structure of optimal policies (Sect. 10.5).
As before, this book is written for graduate students, researchers, and practi-
tioners interested in the mathematics of logistics and supply chain management.
We assume the reader is familiar with the basics of linear programming and prob-
ability theory and, in a number of sections, complexity theory and graph theory,
although in many cases these can be skipped without loss of continuity.
Parts of this book are based on work we have done either together or with
others. Indeed, some of the chapters originated from papers we have published in
journals such as Mathematics of Operations Research, Mathematical Programming,
Operations Research, and IIE Transactions. We rewrote most of these, trying to
present the results in a simple yet general and uniﬁed way. However, a number of
key results, proofs, and discussions are reprinted without substantial change. Of
course, in each case this was done by providing the appropriate reference and by
obtaining permission of the copyright owner. In the case of Operations Research
and Mathematics of Operations Research, it is the Institute for Operations Re-
search and the Management Sciences (INFORMS). Chapter 13 is heavily based
on the paper by David Simchi-Levi and Yehua Wei, “Understanding the Perfor-
mance of the Long Chain and Sparse Designs in Process Flexibility,” which was
published in Operations Research in 2012. Chapter 14 borrows extensively from
“Supply Chain Design and Planning—Applications of Optimization Techniques
for Strategic and Tactical Models,” written by Ana Muriel and David Simchi-Levi
and published in the Handbooks in Operations Research and Management Science,
the volume on Supply Chain Management, S. Graves and A. G. Kok, eds., North-
Holland, Amsterdam. Similarly, Chap. 20 borrows extensively from Designing and
Managing the Supply Chain, written by David Simchi-Levi, Philip Kaminsky, and
Edith Simchi-Levi and published by McGraw-Hill in 2007.
Cambridge, MA
David Simchi-Levi
Urbana-Champaign, IL
Xin Chen
New York, NY
Julien Bramel

Acknowledgments
It is our pleasure to acknowledge all those who helped us with the ﬁrst, second,
and third editions of this manuscript. First, we would like to acknowledge the
contribution of our colleague Dr. Frank Chen, of the Chinese University of Hong
Kong. Similarly, we are indebted to our colleague Professor Rafael Hassin, of Tel-
Aviv University, and a number of referees, in particular, Professor James Ward
of Purdue University, for carefully reading the manuscript and providing us with
detailed comments and suggestions. We also would like to thank friends and col-
leagues Zhan Pang, Jin Qi, Diego Klabjan, Nir Halman, and Chenxi Zeng, whose
inputs greatly improved the manuscript. In addition, we thank our former and cur-
rent Ph.D. students Philip Kaminsky, Ana Muriel, Jennifer Ryan, Victor Martinez
de Albeniz, Yehua Wei, Yan Zhao, Xiangyu Gao, Zhenyu Hu, and Limeng Pan,
who read through and commented on various chapters or parts of earlier drafts.
Our joint research and their comments and feedback were invaluable.
We would like to thank Edith Simchi-Levi, who is the main force behind the
development of the network planning systems described in Chap. 20 and who care-
fully edited many parts of the book.
It is also a pleasure to acknowledge the support provided by the National Sci-
ence Foundation, the Oﬃce of Naval Research, the Fund for the City of New York,
Accenture, Bayer Business Services, DHL, Ford Motors Corporation, General Mo-
tors Corporation, Michelin, NASA, PwC, SAP, and Xerox. Their support made
the development of some of the theory presented in the book possible.
Of course, we would like to thank our editors, Donna Chernyk and Achi Dosanjh,
of Springer, who encouraged us throughout and helped us complete the project.
Also, thanks to Ehrlich, Jamie, and the editorial staﬀat Springer in New York for
their help.
ix


Contents
1
Introduction
1
1.1
What Is Logistics Management?
. . . . . . . . . . . . . . . . . . .
1
1.2
Managing Cost and Uncertainty
. . . . . . . . . . . . . . . . . . .
3
1.3
Examples . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
4
1.4
Modeling Logistics Problems
. . . . . . . . . . . . . . . . . . . . .
7
1.5
Logistics and Supply Chain in Practice . . . . . . . . . . . . . . . .
8
1.6
Evaluation of Solution Techniques
. . . . . . . . . . . . . . . . . .
9
1.7
Additional Topics . . . . . . . . . . . . . . . . . . . . . . . . . . . .
10
1.8
Book Overview . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
11
Part I
Performance Analysis Techniques
13
2
Convexity and Supermodularity
15
2.1
Convex Analysis
. . . . . . . . . . . . . . . . . . . . . . . . . . . .
15
2.1.1
Convex Sets and Convex Functions . . . . . . . . . . . . . .
15
2.1.2
Continuity and Diﬀerentiability Properties . . . . . . . . . .
18
2.1.3
Characterization of Convex Functions
. . . . . . . . . . . .
23
2.1.4
Convexity and Optimization
. . . . . . . . . . . . . . . . .
25
2.2
Supermodularity . . . . . . . . . . . . . . . . . . . . . . . . . . . .
27
2.3
Discrete Convex Analysis
. . . . . . . . . . . . . . . . . . . . . . .
35
2.3.1
L♮-Convexity . . . . . . . . . . . . . . . . . . . . . . . . . .
36
2.3.2
M ♮-Convexity . . . . . . . . . . . . . . . . . . . . . . . . . .
39
2.4
Exercises
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
42
xi

xii
Contents
3
Game Theory
45
3.1
Noncooperative Game Theory . . . . . . . . . . . . . . . . . . . . .
46
3.1.1
Deﬁnition and Existence of Nash Equilibrium . . . . . . . .
47
3.1.2
Uniqueness of Nash Equilibrium
. . . . . . . . . . . . . . .
50
3.2
Cooperative Game Theory . . . . . . . . . . . . . . . . . . . . . . .
52
3.2.1
Core . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
55
3.2.2
Nucleolus . . . . . . . . . . . . . . . . . . . . . . . . . . . .
59
3.2.3
Shapley Value . . . . . . . . . . . . . . . . . . . . . . . . . .
61
3.3
Exercises
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
63
4
Worst-Case Analysis
65
4.1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
65
4.2
The Bin-Packing Problem . . . . . . . . . . . . . . . . . . . . . . .
66
4.2.1
First-Fit and Best-Fit . . . . . . . . . . . . . . . . . . . . .
68
4.2.2
First-Fit Decreasing and Best-Fit Decreasing . . . . . . . .
71
4.3
The Traveling Salesman Problem . . . . . . . . . . . . . . . . . . .
72
4.3.1
A Minimum Spanning Tree-Based Heuristic . . . . . . . . .
73
4.3.2
The Nearest-Insertion Heuristic . . . . . . . . . . . . . . . .
75
4.3.3
Christoﬁdes’ Heuristic . . . . . . . . . . . . . . . . . . . . .
78
4.3.4
Local Search Heuristics
. . . . . . . . . . . . . . . . . . . .
80
4.4
Exercises
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
81
5
Average-Case Analysis
85
5.1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
85
5.2
The Bin-Packing Problem . . . . . . . . . . . . . . . . . . . . . . .
86
5.3
The Traveling Salesman Problem . . . . . . . . . . . . . . . . . . .
91
5.4
Exercises
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
96
6
Mathematical Programming-Based Bounds
99
6.1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
99
6.2
An Asymptotically Tight Linear Program . . . . . . . . . . . . . .
100
6.3
Lagrangian Relaxation . . . . . . . . . . . . . . . . . . . . . . . . .
103
6.4
Lagrangian Relaxation and the Traveling Salesman Problem . . . .
105
6.4.1
The 1-Tree Lower Bound
. . . . . . . . . . . . . . . . . . .
106
6.4.2
The 1-Tree Lower Bound and Lagrangian Relaxation . . . .
107
6.5
The Worst-Case Eﬀectiveness of the 1-Tree Lower Bound
. . . . .
108
6.6
Exercises
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
112
Part II
Inventory Models
115
7
Economic Lot Size Models with Constant Demands
117
7.1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
117
7.1.1
The Economic Lot Size Model
. . . . . . . . . . . . . . . .
117

Contents
xiii
7.1.2
The Finite-Horizon Model . . . . . . . . . . . . . . . . . . .
119
7.1.3
Power-of-Two Policies . . . . . . . . . . . . . . . . . . . . .
121
7.2
Multi-Item Inventory Models
. . . . . . . . . . . . . . . . . . . . .
122
7.2.1
Introduction
. . . . . . . . . . . . . . . . . . . . . . . . . .
122
7.2.2
Notation and Assumptions
. . . . . . . . . . . . . . . . . .
124
7.2.3
Worst-Case Analyses . . . . . . . . . . . . . . . . . . . . . .
125
7.3
A Single-Warehouse Multiretailer Model . . . . . . . . . . . . . . .
129
7.3.1
Introduction
. . . . . . . . . . . . . . . . . . . . . . . . . .
129
7.3.2
Model and Analysis
. . . . . . . . . . . . . . . . . . . . . .
130
7.4
Exercises
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
134
8
Economic Lot Size Models with Varying Demands
137
8.1
The Wagner–Whitin Model . . . . . . . . . . . . . . . . . . . . . .
137
8.2
Models with Capacity Constraints
. . . . . . . . . . . . . . . . . .
143
8.3
Multi-Item Inventory Models
. . . . . . . . . . . . . . . . . . . . .
146
8.4
Single-Item Models with Pricing
. . . . . . . . . . . . . . . . . . .
148
8.5
Exercises
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
150
9
Stochastic Inventory Models
151
9.1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
151
9.2
Single-Period Models . . . . . . . . . . . . . . . . . . . . . . . . . .
152
9.2.1
The Model
. . . . . . . . . . . . . . . . . . . . . . . . . . .
152
9.3
Finite-Horizon Models . . . . . . . . . . . . . . . . . . . . . . . . .
153
9.3.1
Model Description . . . . . . . . . . . . . . . . . . . . . . .
153
9.3.2
K-Convex Functions . . . . . . . . . . . . . . . . . . . . . .
155
9.3.3
Main Results . . . . . . . . . . . . . . . . . . . . . . . . . .
158
9.4
Quasiconvex Loss Functions . . . . . . . . . . . . . . . . . . . . . .
159
9.5
Inﬁnite-Horizon Models
. . . . . . . . . . . . . . . . . . . . . . . .
163
9.6
Models with Positive Lead Times . . . . . . . . . . . . . . . . . . .
169
9.7
Multi-Echelon Systems . . . . . . . . . . . . . . . . . . . . . . . . .
172
9.8
Exercises
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
174
10 Integration of Inventory and Pricing
177
10.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
177
10.2 Demand Models
. . . . . . . . . . . . . . . . . . . . . . . . . . . .
178
10.3 Single-Period Stochastic Models . . . . . . . . . . . . . . . . . . . .
179
10.4 Finite-Horizon Models . . . . . . . . . . . . . . . . . . . . . . . . .
183
10.4.1 Model Description . . . . . . . . . . . . . . . . . . . . . . .
183
10.4.2 Symmetric K-Convex Functions
. . . . . . . . . . . . . . .
185
10.4.3 Additive Demand Functions . . . . . . . . . . . . . . . . . .
190
10.4.4 General Demand Functions . . . . . . . . . . . . . . . . . .
193
10.4.5 Special Case: Zero Fixed Ordering Cost . . . . . . . . . . .
194
10.5 Alternative Approach to the Optimality of (s, S, p) Policies . . . .
194
10.6 Extensions and Challenges . . . . . . . . . . . . . . . . . . . . . . .
200

xiv
Contents
10.7 Risk-Averse Inventory Models . . . . . . . . . . . . . . . . . . . . .
201
10.7.1 Expected Utility Risk-Averse Models . . . . . . . . . . . . .
203
10.7.2 Exponential Utility Risk-Averse Models . . . . . . . . . . .
205
10.8 Exercises
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
207
Part III
Competition, Coordination and Design
Models
211
11 Supply Chain Competition and Collaboration Models
213
11.1 Inventory and Pricing Competition . . . . . . . . . . . . . . . . . .
213
11.2 Inventory Centralization Games . . . . . . . . . . . . . . . . . . . .
216
11.2.1 Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
217
11.2.2 Inventory Games with a Linear Ordering Cost
. . . . . . .
219
11.2.3 Inventory Games with Quantity Discounts . . . . . . . . . .
222
11.3 Exercises
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
228
12 Procurement Contracts
229
12.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
229
12.2 Wholesale Price Contracts . . . . . . . . . . . . . . . . . . . . . . .
231
12.3 Buy-Back Contracts . . . . . . . . . . . . . . . . . . . . . . . . . .
233
12.4 Revenue-Sharing Contracts
. . . . . . . . . . . . . . . . . . . . . .
234
12.5 Portfolio Contracts . . . . . . . . . . . . . . . . . . . . . . . . . . .
235
12.6 Exercises
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
239
13 Process Flexibility
241
13.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
241
13.2 Supermodularity and Incremental Beneﬁts of Long Chains . . . . .
244
13.2.1 Supermodularity in Arc Capacities . . . . . . . . . . . . . .
245
13.2.2 Incremental Beneﬁts in Long Chains . . . . . . . . . . . . .
249
13.3 Characterizing the Performance of Long Chains . . . . . . . . . . .
250
13.3.1 Decomposition of a Long Chain . . . . . . . . . . . . . . . .
251
13.3.2 Characterization and Optimality . . . . . . . . . . . . . . .
253
13.3.3 Computing the Performance of a Long Chain . . . . . . . .
254
13.4 Performance of Long Chains . . . . . . . . . . . . . . . . . . . . . .
257
13.5 Extensions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
261
13.6 Exercises
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
262
14 Supply Chain Planning Models
263
14.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
263
14.2 The Shipper Problem
. . . . . . . . . . . . . . . . . . . . . . . . .
264
14.2.1 The Shipper Model . . . . . . . . . . . . . . . . . . . . . . .
265
14.2.2 A Set-Partitioning Approach
. . . . . . . . . . . . . . . . .
266
14.2.3 Structural Properties . . . . . . . . . . . . . . . . . . . . . .
270

Contents
xv
14.2.4 Solution Procedure . . . . . . . . . . . . . . . . . . . . . . .
271
14.2.5 Computational Results . . . . . . . . . . . . . . . . . . . . .
274
14.3 Safety Stock Optimization . . . . . . . . . . . . . . . . . . . . . . .
279
14.4 Exercises
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
280
15 Facility Location Models
283
15.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
283
15.2 An Algorithm for the p -Median Problem . . . . . . . . . . . . . . .
284
15.3 An Algorithm for the Single-Source Capacitated Facility
Location Problem . . . . . . . . . . . . . . . . . . . . . . . . . . . .
287
15.4 A Distribution System Design Problem . . . . . . . . . . . . . . . .
291
15.5 The Structure of the Asymptotic Optimal Solution . . . . . . . . .
296
15.6 Exercises
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
297
Part IV
Vehicle Routing Models
299
16 The Capacitated VRP with Equal Demands
301
16.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
301
16.2 Worst-Case Analysis of Heuristics . . . . . . . . . . . . . . . . . . .
303
16.3 The Asymptotic Optimal Solution Value . . . . . . . . . . . . . . .
307
16.4 Asymptotically Optimal Heuristics . . . . . . . . . . . . . . . . . .
308
16.5 Exercises
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
312
17 The Capacitated VRP with Unequal Demands
313
17.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
313
17.2 Heuristics for the CVRP . . . . . . . . . . . . . . . . . . . . . . . .
313
17.3 Worst-Case Analysis of Heuristics . . . . . . . . . . . . . . . . . . .
317
17.4 The Asymptotic Optimal Solution Value . . . . . . . . . . . . . . .
320
17.4.1 A Lower Bound . . . . . . . . . . . . . . . . . . . . . . . . .
321
17.4.2 An Upper Bound . . . . . . . . . . . . . . . . . . . . . . . .
324
17.5 Probabilistic Analysis of Classical Heuristics . . . . . . . . . . . . .
326
17.5.1 A Lower Bound . . . . . . . . . . . . . . . . . . . . . . . . .
328
17.5.2 The UOP(α) Heuristic . . . . . . . . . . . . . . . . . . . . .
330
17.6 The Uniform Model
. . . . . . . . . . . . . . . . . . . . . . . . . .
332
17.7 The Location-Based Heuristic . . . . . . . . . . . . . . . . . . . . .
335
17.8 Rate of Convergence to the Asymptotic Value . . . . . . . . . . . .
337
17.9 Exercises
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
338
18 The VRP with Time-Window Constraints
341
18.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
341
18.2 The Model
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
341
18.3 The Asymptotic Optimal Solution Value . . . . . . . . . . . . . . .
343
18.4 An Asymptotically Optimal Heuristic
. . . . . . . . . . . . . . . .
349
18.4.1 The Location-Based Heuristic . . . . . . . . . . . . . . . . .
349

xvi
Contents
18.4.2 A Solution Method for CVLPTW
. . . . . . . . . . . . . .
351
18.4.3 Implementation . . . . . . . . . . . . . . . . . . . . . . . . .
353
18.4.4 Numerical Study . . . . . . . . . . . . . . . . . . . . . . . .
353
18.5 Exercises
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
356
19 Solving the VRP Using a Column-Generation Approach
359
19.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
359
19.2 Solving a Relaxation of the Set-Partitioning Formulation . . . . . .
360
19.3 Solving the Set-Partitioning Problem . . . . . . . . . . . . . . . . .
364
19.3.1 Identifying Violated Clique Constraints
. . . . . . . . . . .
366
19.3.2 Identifying Violated Odd Hole Constraints . . . . . . . . . .
366
19.4 The Eﬀectiveness of the Set-Partitioning Formulation
. . . . . . .
367
19.4.1 Motivation
. . . . . . . . . . . . . . . . . . . . . . . . . . .
368
19.4.2 Proof of Theorem 19.4.1 . . . . . . . . . . . . . . . . . . . .
369
19.5 Exercises
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
372
Part V
Logistics Algorithms in Practice
377
20 Network Planning
379
20.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
379
20.2 Network Design . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
380
20.3 Strategic Safety Stock . . . . . . . . . . . . . . . . . . . . . . . . .
391
20.4 Resource Allocation
. . . . . . . . . . . . . . . . . . . . . . . . . .
397
20.5 Summary
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
400
20.6 Exercises
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
402
21 A Case Study: School Bus Routing
403
21.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
403
21.2 The Setting . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
404
21.3 Literature Review
. . . . . . . . . . . . . . . . . . . . . . . . . . .
406
21.4 The Problem in New York City . . . . . . . . . . . . . . . . . . . .
407
21.5 Distance and Time Estimation
. . . . . . . . . . . . . . . . . . . .
409
21.6 The Routing Algorithm
. . . . . . . . . . . . . . . . . . . . . . . .
411
21.7 Additional Constraints and Features . . . . . . . . . . . . . . . . .
415
21.8 The Interactive Mode
. . . . . . . . . . . . . . . . . . . . . . . . .
417
21.9 Data, Implementation, and Results . . . . . . . . . . . . . . . . . .
418
References
421
Index
441

List of Tables
3.1
The prisoner’s dilemma
. . . . . . . . . . . . . . . . . . . . . . . .
46
3.2
Payoﬀs of matching penny game
. . . . . . . . . . . . . . . . . . .
47
3.3
Payoﬀs of coordination game without communication . . . . . . . .
51
3.4
The generalized form of the prisoner’s dilemma . . . . . . . . . . .
63
10.1 Summary of results for the inventory (and pricing) problems
. . .
200
10.2 Summary of results for ﬁnite-horizon risk-neutral and
risk-averse models
. . . . . . . . . . . . . . . . . . . . . . . . . . .
207
14.1 Test problems generated as in Balakrishnan and Graves . . . . . .
275
14.2 Computational results for layered networks. Balakrishnan
and Graves’ results (B&G) vs. those of our linear
programming-based heuristic (LPBH)
. . . . . . . . . . . . . . . .
275
14.3 Computational results for general networks. Balakrishnan
and Graves’ results (B&G) vs. those of our linear
programming-based heuristic (LPBH)
. . . . . . . . . . . . . . . .
276
14.4 Linear and setup costs used for all the test problems . . . . . . . .
277
14.5 Inventory costs and diﬀerent ranges for the diﬀerent test
problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
277
14.6 Computational results for a single warehouse
. . . . . . . . . . . .
278
15.1 Computational results for the p -median algorithm
. . . . . . . . .
288
15.2 Computational results for the single-source CFLP algorithm . . . .
291
xvii

xviii
List of Tables
18.1 Computational results: Part I . . . . . . . . . . . . . . . . . . . . .
354
18.2 Computational results: Part II
. . . . . . . . . . . . . . . . . . . .
355
20.1 Network planning characteristics . . . . . . . . . . . . . . . . . . .
401
21.1 General Education routing
. . . . . . . . . . . . . . . . . . . . . .
418

List of Figures
1.1
The logistics network . . . . . . . . . . . . . . . . . . . . . . . . .
2
2.1
Examples of convex sets and nonconvex sets . . . . . . . . . . . .
16
2.2
Illustration of the deﬁnition of convex function . . . . . . . . . . .
17
2.3
Illustration of the deﬁnition of subgradient . . . . . . . . . . . . .
22
4.1
An example for the minimum spanning tree-based algorithm
with n = 18
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
75
4.2
An example for the nearest-insertion algorithm with n = 8 . . . .
78
4.3
The matching and the optimal traveling salesman tour . . . . . .
79
4.4
An example for Christoﬁdes’ algorithm with n = 7
. . . . . . . .
80
5.1
The two traveling salesman tours constructed by the
partitioning algorithm
. . . . . . . . . . . . . . . . . . . . . . . .
92
5.2
Region-partitioning example with n = 17, q = 3, h = 2,
and t = 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
93
5.3
The tour generated by the region-partitioning algorithm
. . . . .
94
5.4
The segments S1, . . . , Sk and the corresponding Eulerian graph
.
95
7.1
Inventory level as a function of time . . . . . . . . . . . . . . . . .
118
7.2
Inventory level as a function of time under policy P . . . . . . . .
120
8.1
The plotted points and the function g . . . . . . . . . . . . . . . .
141
9.1
Illustration of the properties of K-convex functions . . . . . . . .
157
xix

xx
List of Figures
10.1
Illustration of the properties of a symmetric K-convex
function
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
187
12.1
Illustration of the structure of the optimal ordering policy
. . . .
239
13.1
Conﬁgurations for ﬂexibility designs . . . . . . . . . . . . . . . . .
243
13.2
The increase in incremental beneﬁt . . . . . . . . . . . . . . . . .
243
13.3
G(C5) for the max-weight circulation associated
with P(d, Cn, u) . . . . . . . . . . . . . . . . . . . . . . . . . . . .
248
13.4
Illustration for the proof of Theorem 13.2.2 . . . . . . . . . . . . .
248
13.5
The performance of long chains vs. the performance of full
ﬂexibility . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
257
14.1
Example of expanded network . . . . . . . . . . . . . . . . . . . .
266
14.2
Piecewise linear and concave cost structure . . . . . . . . . . . . .
267
14.3
Illustration of the model
. . . . . . . . . . . . . . . . . . . . . . .
279
16.1
Every group contains Q customers with interdistance zero
. . . .
302
16.2
An optimal traveling salesman tour in G(t, s) . . . . . . . . . . . .
303
16.3
Solution obtained by the ITP heuristic . . . . . . . . . . . . . . .
306
20.1
The APS screen representing data prior to optimization
. . . . .
382
20.2
The APS screen representing the optimized logistics network . . .
382
20.3
The APS screen representing data prior to aggregation . . . . . .
384
20.4
The APS screen representing data after aggregation . . . . . . . .
385
20.5
Transportation rates for shipping 4,000 lb . . . . . . . . . . . . . .
387
20.6
How to read the diagrams
. . . . . . . . . . . . . . . . . . . . . .
392
20.7
Current safety stock locations . . . . . . . . . . . . . . . . . . . .
393
20.8
Optimized safety stock locations . . . . . . . . . . . . . . . . . . .
394
20.9
Optimized safety stock with reduced lead time . . . . . . . . . . .
394
20.10 Current supply chain . . . . . . . . . . . . . . . . . . . . . . . . .
395
20.11 Optimized supply chain . . . . . . . . . . . . . . . . . . . . . . . .
396
20.12 Global vs. local optimization . . . . . . . . . . . . . . . . . . . . .
397
20.13 The extended supply chain: from manufacturing to order
fulﬁllment
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
398
20.14 Comparison of manual vs. optimized scenarios . . . . . . . . . . .
401

1
Introduction
1.1
What Is Logistics Management?
For many companies, the ability to eﬃciently match demand and supply is key to
their success. Failure to do so could lead to loss of revenue, reduced service levels,
impacted reputation, and decline in the company’s market share. Unfortunately,
recent developments such as intense market competition, product proliferation,
and the increase in the number of products with a short life cycle have created
an environment where customer demand is volatile and unpredictable. In such
an environment, traditional operations strategies such as building inventory, in-
vesting in capacity buﬀers, or increasing committed response time to consumers
do not oﬀer a competitive advantage. Therefore, many companies are looking for
eﬀective strategies to respond to market changes without signiﬁcantly increasing
cost, inventory, or response time. This has motivated a continuous evolution of the
management of logistics systems.
In these systems, items are produced at one or more factories, shipped to ware-
houses and distribution centers for intermediate storage, and then shipped to
retailers or customers. Consequently, to reduce cost and improve service levels,
logistics strategies must take into account the interactions of these various levels
in this logistics network, also referred to as the supply chain. This network consists
of suppliers, manufacturing centers, warehouses, distribution centers, and retailer
outlets, as well as raw materials, work-in-process inventory, and ﬁnished products
that ﬂow between the facilities; see Fig. 1.1.
D. Simchi-Levi et al., The Logic of Logistics: Theory, Algorithms, and Applications
for Logistics Management, Springer Series in Operations Research and Financial Engineering,
DOI 10.1007/978-1-4614-9149-1 1, © Springer Science+Business Media New York 2014
1

2
1. Introduction
FIGURE 1.1. The logistics network
The goal of this book is to present the state-of-the-art in the science of logistics
management. But what exactly is logistics management? According to the Council
of Supply Chain Management Professionals (CSCMP), a nonproﬁt organization of
business personnel, it is that part of the business that
plans, implements, and controls the eﬃcient, eﬀective forward and re-
verses ﬂow and storage of goods, services and related information be-
tween the point of origin and the point of consumption in order to meet
customers’ requirements.
This deﬁnition leads to several observations. First, logistics management takes
into consideration every facility that has an impact on cost and plays a role in
making the product conform to customer requirements: from supplier and manu-
facturing facilities, through warehouses and distribution centers, to retailers and
stores. Indeed, in some supply chain analyses, it is necessary to account for the
suppliers’ suppliers and the customers’ customers because they have an impact on
supply chain performance.
Second, the objective of logistics management is to be eﬃcient and cost-eﬀective
across the entire system; total systemwide costs, from transportation and distri-
bution to inventories of raw materials, work-in-process, and ﬁnished goods, are
to be minimized. Thus, the emphasis is not on simply minimizing transportation
cost or reducing inventories but, rather, on taking a systems approach to logistics
management.

1.2 Managing Cost and Uncertainty
3
Finally, because logistics management evolves around planning, implementing,
and controlling the logistics network, it encompasses many of the ﬁrm’s activities,
from the strategic level through the tactical to the operational level.
Following Hax and Candea’s (1984) treatment of production-inventory systems,
logistical decisions are typically classiﬁed into three levels.
• The strategic level deals with decisions that have a long-lasting eﬀect on
the ﬁrm. This includes decisions regarding the number, location, and capaci-
ties of warehouses and manufacturing plants, or the ﬂow of material through
the logistics network.
• The tactical level typically includes decisions that are updated anywhere
between once every week, month, or quarter. This includes purchasing and
production decisions, inventory policies, and transportation strategies, in-
cluding the frequency with which customers are visited.
• The operational level refers to day-to-day decisions such as scheduling,
routing, and loading trucks.
Finally, what about supply chain management? What is the diﬀerence between
supply chain management and logistics management? It is insightful to review the
CSCMP deﬁnition. According to the CSCMP,
Supply chain management encompasses the planning and management
of all activities involved in sourcing and procurement, conversion, and
all logistics management activities.
Thus, according to this deﬁnition, supply chain management includes logistics
management as well as the coordination and collaboration with business partners
such as suppliers, third-party service providers, and customers. In this book, we will
focus on models important to both logistics as well as supply chain management.
1.2
Managing Cost and Uncertainty
What makes logistics, or supply chain management, diﬃcult? Although we will
discuss a variety of challenges throughout this text, they can all be related to one
or both of the following observations:
1. It is challenging to design and operate a logistics system so that systemwide
costs are minimized and systemwide service levels are maintained. Indeed, it
is frequently diﬃcult to operate a single facility so that costs are minimized
and the service level is maintained. The diﬃculty increases signiﬁcantly when
an entire system is being considered.
2. Uncertainty is inherent in every logistics network; customer demand can
never be forecast exactly, travel times will never be certain, and machines

4
1. Introduction
and vehicles will break down. Logistics networks need to be designed to
eliminate as much uncertainty as possible and to deal eﬀectively with the
uncertainty that remains.
One reason it is diﬃcult to manage cost and uncertainty is due to supply chain
dynamics. Indeed, in recent years, many suppliers and retailers have observed that
while customer demand for speciﬁc products does not vary much, inventory and
back-order levels ﬂuctuate considerably across their supply chain. For instance,
in examining the demand for Pampers disposal diapers, executives at Procter &
Gamble noticed an interesting phenomenon.
As expected, retail sales of the product were fairly uniform; there is no particular
day or month in which the demand is signiﬁcantly higher or lower than in any other.
However, the executives noticed that distributors’ orders placed to the factory
ﬂuctuated much more than retail sales. In addition, P&G’s orders to its suppliers
ﬂuctuated even more. This increase in variability as we travel up in the supply
chain is referred to as the bullwhip eﬀect.
Even when demand is known precisely (e.g., because of contractual agreements),
the planning process needs to account for demand and cost parameters varying
over time due to the impact of seasonal ﬂuctuations, trends, advertising and pro-
motions, competitors’ pricing strategies, and so forth. These time-varying demand
and cost parameters make it diﬃcult to determine the most eﬀective supply chain
strategy, that is, the one that minimizes systemwide costs and conforms to cus-
tomer requirements.
1.3
Examples
In this section, we introduce some of the logistics management issues that form
the basis of the problems studied in the ﬁrst four parts of the book. These issues
span a large spectrum of logistics management decisions, at each of the three levels
mentioned above. Our objective here is to brieﬂy introduce the questions and the
tradeoﬀs associated with these decisions.
Network Conﬁguration
Consider the situation where several plants are producing products to serve a set
of geographically dispersed retailers. The current set of facilities, that is, plants
and warehouses, is deemed to be inappropriate, and management wants to re-
organize or redesign the distribution network. This may be due, for example, to
changing demand patterns or the termination of a leasing contract for a num-
ber of existing warehouses. In addition, changing demand patterns may entail a
change in plant production levels, a selection of new suppliers, and, in general,
a new ﬂow pattern of goods throughout the distribution network. The goal is to
choose a set of facility locations and capacities, to determine production levels
for each product at each plant, and to set transportation ﬂows between facilities,

1.3 Examples
5
either from plant to warehouse or from warehouse to retailer, in such a way that
total production, inventory, and transportation costs are minimized and various
service-level requirements are satisﬁed.
Production Planning
A manufacturing facility must produce to meet demand for a product over a ﬁxed
ﬁnite horizon. In many real-world cases, it is appropriate to assume that demand is
known over the horizon. This is possible, for example, if orders have been placed in
advance or contracts have been signed specifying deliveries for the next few months.
Production costs consist of a ﬁxed amount, corresponding, say, to machine setup
costs or times, and a variable amount, corresponding to the time it takes to produce
one unit. A holding cost is incurred for each unit in inventory. The planner’s
objective is to satisfy demand for the product in each period and to minimize
the total production and inventory costs over the ﬁxed horizon. Obviously, this
problem becomes more diﬃcult as the number of products manufactured increases.
Inventory Control and Pricing Optimization
Consider a retailer that maintains an inventory of a particular product. Since cus-
tomer demand is random, the retailer has information regarding the probabilistic
distribution of demand only. The retailer’s objective is to decide at what point
to reorder a new batch of products, and how much to order. Typically, ordering
costs consist of two parts: a ﬁxed amount, independent of the size of the order, for
example, the cost of sending a vehicle from the warehouse to the retailer; and a
variable amount dependent on the number of products ordered. A linear inventory
holding cost is incurred at a constant rate per unit of product per unit of time.
The retailer must determine an optimal inventory policy to minimize the expected
cost of ordering and holding inventory. In some situations, the price at which the
product is sold to the end customer is also a decision variable. In this case, demand
is not only random but is also aﬀected by the selling price. The retailer’s objective
is thus to ﬁnd an inventory policy and a pricing strategy maximizing expected
proﬁt over the ﬁnite, or inﬁnite, horizon.
Procurement Strategies and Supply Contracts
In traditional logistics strategies, each party in the network focuses on its own proﬁt
and hence makes decisions with little regard to their impact on other partners.
Relationships between suppliers and buyers are established by means of supply
contracts that specify pricing and volume discounts, delivery lead times, qual-
ity, returns, and so forth. The question, of course, is whether supply contracts
can also be used to replace the traditional strategy with one that optimizes the
performance of the entire network. In particular, what is the impact of volume
discount and revenue-sharing contracts on supply chain performance? Are there
pricing strategies that can be applied by suppliers to incentivize buyers to order

6
1. Introduction
more products while at the same time increasing the supplier’s proﬁt? What are
the risks associated with supply contracts, and how can these risks be minimized?
Process Flexibility
In the last few years, companies have been looking for new ways to respond to
change in demand volume and mix without increasing inventory, capacity, or re-
sponse time. One possible way to achieve that objective is to invest in process
ﬂexibility, where each plant is capable of producing multiple products. In this
case, when the demand for one product is higher than expected while the demand
for a diﬀerent product is lower than expected, a ﬂexible manufacturing system can
quickly make adjustments by shifting production capacities appropriately. Unfor-
tunately, ﬂexibility does not come free, and hence the questions are how much
ﬂexibility is needed, how can one achieve ﬂexibility, and what are the potential
beneﬁts of a (small) investment in ﬂexibility?
Integration of Production, Inventory, and Transportation
Decisions
Consider the problem faced by companies that rely on LTL (less than truckload)
carriers for the distribution of products across their supply chain. Typically, these
carriers oﬀer volume discounts to encourage larger shipments; as a result, the
transportation charges borne by the shipper are often piecewise linear and concave.
In this case, the timing and routing of shipments need to be coordinated so as to
minimize systemwide costs, including production, inventory, transportation, and
shortage costs, by taking advantage of economies of scale oﬀered by the carriers.
Vehicle Fleet Management
A warehouse supplies products to a set of retailers using a ﬂeet of vehicles of limited
capacity. A dispatcher is in charge of assigning loads to vehicles and determining
vehicle routes. First, the dispatcher must decide how to partition the retailers
into groups that can be feasibly served by a vehicle, that is, whose loads ﬁt in a
vehicle. Second, the dispatcher must decide what sequence to use so as to minimize
cost. Typically, one of two cost functions is possible: In the ﬁrst, the objective is to
minimize the number of vehicles used, while in the second, the focus is on reducing
the total distance traveled. The latter is an example of a single-depot capacitated
vehicle routing rroblem (CVRP), where a set of customers has to be served by a
ﬂeet of vehicles of limited capacity. The vehicles are initially located at a depot
(in this case, the warehouse) and the objective is to ﬁnd a set of vehicle routes of
minimal total length.
Truck Routing
Consider a truck that leaves a warehouse to deliver products to a set of retailers.
The order in which the retailers are visited will determine how long the delivery
will take and at what time the vehicle can return to the warehouse. Therefore, it

1.4 Modeling Logistics Problems
7
is important that the vehicle follow an eﬃcient route. The problem of ﬁnding the
minimal length route, in either time or distance, from a warehouse through a set
of retailers is an example of a traveling salesman problem (TSP). Clearly, truck
routing is a subproblem of the ﬂeet management example above.
Packing Problems
In many logistics applications, a collection of items must be packed into boxes,
bins, or vehicles of limited size. The objective is to pack the items such that
the number of bins used is as small as possible. This problem is referred to as
the bin-packing problem (BPP). For example, it appears as a special case of the
CVRP when the objective is to minimize the number of vehicles used to deliver the
products. Bin-packing also appears in many other applications, including cutting
standard-length wire or paper strips into speciﬁc customer order sizes. It also often
appears as a subproblem in other combinatorial problems.
1.4
Modeling Logistics Problems
The reader observes that most of the problems and issues described in the previ-
ous section are fairly well deﬁned mathematically. These are the types of issues,
questions, and problems addressed in this book. Of course, many issues important
to logistics or supply chain management are diﬃcult to quantify and therefore to
address mathematically; we will not cover these in this book. This includes topics
related to information systems, outsourcing, third-party logistics, strategic part-
nering, etc. For a detailed analysis of these topics, we refer the reader to the book
by Simchi-Levi et al. (2007) or the more recent book by Simchi-Levi (2010).
The fact that the examples provided in the previous section can be defined
mathematically is, obviously, meaningless unless all required data are available.
As we discuss in Part V of this book, ﬁnding, verifying, and tabulating the data
are typically very problematic. Indeed, inventory holding costs, production costs,
extra vehicle costs, and warehouse capacities are often diﬃcult to determine. Fur-
thermore, identifying the data relevant to a particular logistics or supply chain
problem adds another layer of complexity to the data-gathering problem. Even
when the data do exist, there are other diﬃculties related to modeling complex
real-world problems. For example, in our analysis we ignore issues such as varia-
tions in travel times, variable yields in production, inventory shrinkage, forecast-
ing, crew scheduling, and so on. These issues complicate logistics and supply chain
practice considerably.
For most of this book, we assume that all relevant data, for example, production
costs, production times, warehouse ﬁxed costs, travel times, and holding costs, are
given. As a result, each logistics or supply chain problem analyzed in Parts I–IV
is well deﬁned and thus merely a mathematical problem.

8
1. Introduction
1.5
Logistics and Supply Chain in Practice
How are logistics and supply chain problems addressed in practice? That is, how
are these diﬃcult problems solved in the real world? In our experience, companies
use several approaches. First and foremost, as in other aspects of life, people tend
to repeat what has worked in the past. That is, if last year’s safety stock level
was enough to avoid backlogging demands, then the same level might be used this
year. If last year’s delivery routes were successful, that is, all retailers received
their deliveries on time, then why change them? Second, there are so-called rules
of thumb that are widely used and, at least on the surface, may be quite eﬀec-
tive. For example, it is our experience that many logistics managers often use the
“20/80 rule,” which says that about 20 % of the products contribute to about 80 %
of the total cost and therefore it is suﬃcient to concentrate eﬀorts on these critical
products. Logistics network design, to give another example, is an area where a
variety of rules of thumb are used. One such rule might suggest that if your com-
pany serves the continental United States and it needs only one warehouse, then
this warehouse should probably be located in the Chicago area; if two are required,
then one in Los Angeles and one in Atlanta should suﬃce. Finally, some companies
try to apply the experience and intuition of logistics experts and consultants, the
idea being that what has worked well for a competitor should work well for itself.
Of course, while all these approaches are appealing and quite often result in
logistics strategies that make sense, it is not clear how much is lost by not foc-
using on the best (or close to the best) strategy for the particular case at hand.
Indeed, recently, with the advent of cheap computing power, it has become increas-
ingly aﬀordable for many ﬁrms, not just large ones, to acquire and use sophisti-
cated advance planning systems (APS) to optimize their logistics and supply chain
strategies. In these systems, data are entered, reviewed, and validated, various alg-
orithms are executed, and a suggested solution is presented in a user-friendly way.
Provided the data are correct and the system is solving the appropriate problem,
these APS can substantially reduce systemwide cost. Also, generating a satisfac-
tory solution that managers can implement is typically only arrived at after an
iterative process in which the user evaluates various scenarios and assesses their
impact on costs and service levels. Although this may not exactly be considered
“optimization” in a strict sense, it usually serves as a useful tool for the system’s
user.
These planning systems have as their nucleus models and algorithms in some
form or another. In some cases, the system may simply be a computerized version
of the rules of thumb above. In more and more instances, however, these systems
apply techniques that have been developed by the operations, management science,
and computer science research communities.
In this book, we present the current state-of-the-art in mathematical research in
the area of logistics. Some of the problems listed above represent diﬃcult stochas-
tic optimization problems that require concepts such as convexity and super-
modularity, and their extensions for their analysis. Some problems require the
use of methods from game theory in order to understand how diﬀerent supply

1.6 Evaluation of Solution Techniques
9
chain partners respond to various challenges. Other problems have at their core
extremely diﬃcult combinatorial problems in the class called NP-Hard problems.
This implies that it is very unlikely that one can construct an algorithm that will
always ﬁnd the optimal solution, or the best possible decision, in computation time
that is polynomial in the “size” of the problem. The interested reader can refer
to the excellent book by Garey and Johnson (1979) for details on computational
complexity. Therefore, in many cases, an algorithm that consistently provides the
optimal solution is not considered a reachable goal, and hence heuristic, or ap-
proximation, methods are employed.
1.6
Evaluation of Solution Techniques
A fundamental research question is how to evaluate heuristic or approximation
methods. Such methods can range from simple “rules of thumb” to complex, com-
putationally intensive, mathematical programming techniques. In general, these
are methods that will ﬁnd good solutions to the problem in a reasonable amount
of time. Of course, the terms “good” and “reasonable” depend on the heuristic and
on the problem instance. Also, what constitutes reasonable time may be highly
dependent on the environment in which the heuristic will be used; that is, it de-
pends on whether or not the algorithm needs to solve the logistics problem in real
time.
Assessing and quantifying a heuristic’s eﬀectiveness is of prime concern.
Traditionally, the following methods have been employed.
• Empirical comparisons: Here, a representative sample of problems is cho-
sen and the performance of a variety of heuristics is compared. The compar-
ison can be based on solution quality or computation time, or a combination
of the two. This approach has one obvious drawback: deciding on a good set
of test problems. The diﬃculty, of course, is that a heuristic may perform
well on one set of problems but may perform poorly on the next. As pointed
out by Fisher (1995), this lack of robustness forces practitioners to “patch
up” the heuristic to ﬁx the troublesome cases, leading to an algorithm with
growing complexity. After considerable eﬀort, a procedure may be created
that works well for the situation at hand. Unfortunately, the resulting algo-
rithm is usually extremely sensitive to changes in the data and may perform
poorly when transported to other environments.
• Worst-case analysis: In this type of analysis, one tries to determine the
maximum deviation from optimality, in terms of relative error, that a heuris-
tic can incur on any problem instance. For example, a heuristic for the BPP
might guarantee that any solution constructed by the heuristic uses at most
50 % more bins than the optimal solution. Or a heuristic for the TSP might
guarantee that the length of the route provided by the heuristic is at most
twice the length of the optimal route. Using a heuristic with such a guarantee

10
1. Introduction
allays some of the fears of suboptimality, by guaranteeing that we are within
a certain percentage of optimality. Of course, one of the main drawbacks of
this approach is that a heuristic may perform very well on most instances that
are likely to appear in a real-world application but may perform extremely
poorly on some highly contrived instances. Hence, when we compare algo-
rithms, it is not clear that a heuristic with a better worst-case performance
guarantee is necessarily more eﬀective in practice.
• Average-case analysis: Here, the purpose is to determine a heuristic’s av-
erage performance. This is stated as the average relative error between the
heuristic solution and the optimal solution under speciﬁc assumptions on the
distribution of the problem data. This may include probabilistic assumptions
on the depot location, demand size, item size, time windows, vehicle capaci-
ties, etc. As we shall see, while these probabilistic assumptions may be quite
general, this approach also has its drawbacks. The most important includes
the fact that an average-case analysis is usually only possible for large-size
problems. For example, in the BPP, if the item sizes are uniformly distributed
(between zero and the bin capacity), then a heuristic that will be “close to
optimal” is one that ﬁrst sorts the items in nonincreasing order and then,
starting with the largest item, pairs each item with the largest item with
which it ﬁts. In what sense is it close to optimal? The analysis shows that
as the problem size increases (the number of items increases), the relative
error between the solution created by the heuristic and the optimal solution
decreases to zero. Another drawback is that in order for an average-case
analysis to be tractable, it is sometimes necessary to assume independent
customer behavior. Finally, determining what probabilistic assumptions are
appropriate in a particular real-world environment is not a trivial problem.
Because of the advantages and potential drawbacks of each of the approaches,
we agree with Fisher (1980) that these should be treated as complementary ap-
proaches rather than competing ones. Indeed, it is our experience that the logistics
algorithms that are most successfully applied in practice are those with good per-
formance in at least two of the above measures.
We should also point out that characterizing the worst-case or average-case
performance of a heuristic may be technically very diﬃcult. Therefore, a heuristic
may perform very well on average, or in the worst case, but proving this fact may
be beyond our current abilities.
1.7
Additional Topics
We emphasize that due to space and time considerations, we have been obliged
to omit some important and interesting results. These include results regarding
yield management, machine scheduling, random yield in production, and dynamic

1.8 Book Overview
11
and stochastic ﬂeet management models, among others. We refer the reader to
Graves et al. (1993), Ball et al. (1995), De Kok and Graves (2003), Simchi-Levi
et al. (2004), and ¨Ozer and Phillips (2012) for excellent surveys of these and other
related topics.
Also, while many elegant and strong results concerning approaches to certain
logistics problems exist, there are still many areas where little, if anything, is
known. This is, of course, partly due to the fact that as the models become more
complex and integrate more and more issues that arise in practice, their analysis
becomes more diﬃcult.
Finally, we remark that it is our ﬁrmly held belief that logistics and supply chain
management are one of the areas in which a rigorous mathematical analysis yields
not only elegant results but, even more importantly, has had, and will continue to
have, a signiﬁcant impact on the practice of logistics and supply chains.
1.8
Book Overview
This book is meant as a survey of a variety of results covering most topics in
the area of logistics. The reader should have a basic understanding of complexity
theory, linear programming, probability theory, and graph theory. Of course, the
book can be read easily without the reader’s delving into the details of each proof.
The book is organized as follows. In Part I, we concentrate on performance anal-
ysis techniques. Speciﬁcally, in Chap. 2, we introduce the concepts, and associated
properties, of convexity, supermodularity, and discrete convexity. In Chap. 3, we
provide a concise introduction to some of the key concepts and results in game
theory. In Chap. 4, we discuss some of the basic tools required to perform worst-
case analysis, while in Chap. 5, we cover average-case analysis. Finally, in Chap. 6,
we investigate the performance of mathematical programming-based approaches.
Part II concentrates on production and inventory problems. We start with lot
sizing in two diﬀerent deterministic environments, one with constant demand
(Chap. 7) and the second with varying demand (Chap. 8). Chapter 9 focuses on
stochastic inventory models, while Chap. 10 presents new results for the coordina-
tion of inventory and pricing decisions. The chapter distinguishes between models
appropriate for risk-neutral and risk-averse decision makers.
Part III deals with supply chain design and coordination models. These include
Chap. 11, which focuses on competition and collaboration models in supply chains,
and Chap. 12 on eﬀective supply contracts, such as buy back, revenue-sharing,
and portfolio contracts. Chapter 13 deals with process ﬂexibility, and Chap. 14 ad-
dresses models that integrate production, inventory, and transportation decisions
across the supply chain. Finally, Chap. 15 analyzes distribution network conﬁgu-
ration and facility location, also referred to as site selection, problems.
In Part IV, we consider vehicle routing problems, paying particular attention
to heuristics with good worst-case or average-case performance. Chapter 16 con-
tains an analysis of the single-depot capacitated vehicle routing problem when

12
1. Introduction
all customers have equal demands, while Chap. 17 analyzes the case of customers
with unequal demands. In Chap. 18, we perform an average-case analysis of the
vehicle routing problem with time window constraints. We also investigate set-
partitioning-based approaches and column generation techniques in Chap. 19.
In Part V, we look at the practice of logistics management and in particular
at issues related to the design, development, and implementation of APS. Specif-
ically, in Chap. 20, we look at network planning issues from logistics network de-
sign, through inventory positioning, all the way to resource allocation. Finally, in
Chap. 21, we report on the development of a decision support tool for school bus
routing and scheduling in the City of New York.

Part I
Performance Analysis
Techniques

2
Convexity and Supermodularity
The
concepts
of
convexity
and
supermodularity
are
important
in
the
optimization and economics literature. These concepts have been widely applied
in the analysis of a variety of supply chain models, from stochastic, multi-period
inventory problems to pricing models. Hence, in this chapter, we provide a brief int-
roduction to convexity and supermodularity, focusing on materials most relevant
to our context. We also brieﬂy introduce some concepts and results from discrete
convex analysis, which interestingly is an elegant combination of both convexity
and submodularity. For more details, readers are referred to the three excellent
books Rockafellar (1970) on convex analysis, Topkis (1998) on supermodularity,
and Murota (2003) on discrete convex analysis.
2.1
Convex Analysis
2.1.1
Convex Sets and Convex Functions
Before we present the deﬁnition of convex sets, we introduce some notations that
will be used. Throughout this book, we use ℜn to denote an n-dimensional Euc-
lidean space, and“⊆” and “⊂” for set inclusion and strict set inclusion, respectively.
For a set C, we write x ∈C if x is an element of C.
Deﬁnition 2.1.1 A set C ⊆ℜn is called convex if, for any x, x′ ∈C and λ ∈
[0, 1], (1 −λ)x + λx′ ∈C.
D. Simchi-Levi et al., The Logic of Logistics: Theory, Algorithms, and Applications
for Logistics Management, Springer Series in Operations Research and Financial Engineering,
DOI 10.1007/978-1-4614-9149-1 2, © Springer Science+Business Media New York 2014
15

16
2. Convexity and Supermodularity
Geometrically, a set is convex if and only if for any two points in the set, the
line segment between these two points also lies in the set (Fig. 2.1). Here are some
simple examples of convex sets: an interval in ℜ1; a disk and a square in ℜ2; a
sphere and a cube in ℜ3. Also note that a set of solutions of a system of linear
inequalities, that is, {x ∈ℜn : Ax ≤b}, is convex, where A is a linear mapping
from ℜn to ℜm and b is a vector in ℜm. Finally, the intersection of convex sets is
also convex, and convexity is preserved under a linear transformation; namely, the
set AC + b := {Ax + b|x ∈C} is still convex if C is.
FIGURE 2.1. Examples of convex sets and nonconvex sets
Deﬁnition 2.1.2 Given a convex set C in ℜn, a function f : C →ℜis convex
over set C if, for any x, x′ ∈C and λ ∈[0, 1],
f((1 −λ)x + λx′) ≤(1 −λ)f(x) + λf(x′).
(2.1)
f is strictly convex if the inequality (2.1) holds strictly for any x, x′ ∈C with
x ̸= x′ and λ ∈(0, 1). Finally, f is called (strictly) concave if −f is (strictly)
convex.
Remark: When f is (strictly) convex over ℜn, we simply say that f is (strictly)
convex. From now on, we mainly focus on the case when C = ℜn to simplify our
presentation. In fact, almost all the results about convex functions deﬁned over ℜn
hold for convex functions deﬁned over a convex subset of ℜn, possibly with minor
modiﬁcation.
Sometimes it is convenient to work with functions that take the value of inﬁnity.
In this case, for a given convex set C in ℜn, a function f : C →¯ℜis convex over C
in the extended sense if the inequality (2.1) still holds for f, where ¯ℜ= ℜ∪{∞}.
The arithmetic convention here includes ∞+ ∞= ∞, 0 · ∞= 0, and α · ∞= ∞
for α > 0. Of course, usually we can restrict ourselves to the eﬀective domain of
function f, which is deﬁned as follows:
dom(f) := {x ∈C | f(x) < ∞}.

2.1 Convex Analysis
17
But on some occasions, it is more economical to use convex functions in the ex-
tended sense. Finally, for a convex function f : C →ℜ, deﬁne
ˆf(x) =
 f(x), if x ∈C,
∞, otherwise.
It is easy to see that ˆf : ℜn →ℜ∪{∞} is convex in the extended sense.
It is also interesting to point out that if a function f : ℜn →ℜis continuous, then
the convexity of the function f is equivalent to the following midpoint convexity:
For any x, x′ ∈ℜn, f((x + x′)/2) ≤1/2(f(x) + f(x′)). This is left as an exercise.
We now establish a connection between convex sets and convex functions through
the epigraph mapping. The epigraph of a function f : C →ℜis deﬁned as
epi(f) := {(x, α) | x ∈C, α ∈ℜ, f(x) ≤α}.
It is easy to verify that a function f is convex on a convex set C if and only if its
epigraph epi(f) is convex. The epigraph mapping allows us to translate properties
of convex sets into results about convex functions.
The graphical meaning of a convex function is clear; see Fig. 2.2 for an illustra-
tion. In fact, a function f is convex if and only if for any given x and x′, the curve
((1 −λ)x+ λx′), f((1 −λ)x+ λx′)) for λ ∈[0, 1] always lies below the line segment
connecting two points (x, f(x)) and (x′, f(x′)). Obviously, a linear function is both
convex and concave.
FIGURE 2.2. Illustration of the deﬁnition of convex function
In the following, we summarize some useful properties of convex functions. The
proof for those properties is straightforward.
Proposition 2.1.3
(a) Any nonnegative linear combination of convex functions is convex. That is,
if fi : ℜn →ℜare convex for i = 1, 2, . . . , m, then for any scalar αi ≥0,
m
i=1 αifi is also convex.

18
2. Convexity and Supermodularity
(b) A composition of a convex function and an aﬃne function is still convex.
That is, if f : ℜm →ℜis convex, then for any linear mapping A from Rn
to Rm and a vector b in ℜm, f(Ax + b) is also a convex function of x ∈ℜn.
(c) A composition of a nondecreasing convex function and a convex function
is still convex. That is, if f : ℜ→ℜis convex and nondecreasing and
g : ℜn →ℜis convex, then f(g(x)) is convex.
(d) If fk : ℜn →ℜis convex for k = 1, 2, . . . and limk→∞fk(x) = f(x) for any
x ∈ℜn, then f(x) is convex.
(e) Assume that a function f(·, ·) is deﬁned on the product space ℜn × ℜm.
If f(·, y) is convex for any given y ∈ℜm, then for a random vector ζ in
ℜm, Eζ[f(x, ζ)] is convex, provided it is well deﬁned. As a special case, if
f : ℜn →ℜis convex, then Eζ[f(x −ζ)] is also convex.
A weaker deﬁnition of convex functions is quasiconvex, which is also commonly
used.
Deﬁnition 2.1.4 A function f : ℜn →ℜis called quasiconvex on a convex set C
if, for any x, x′ ∈ℜn and λ ∈[0, 1],
f((1 −λ)x + λx′) ≤max{f(x), f(x′)}.
The quasiconvexity of function f : ℜn →ℜis equivalent to the fact that −f is
unimodal. That is, if x∗is a global maximizer of function −f, then for any x ∈ℜn,
−f((1 −λ)x + λx∗) is a nondecreasing function of λ for λ ∈[0, 1].
For a function f : C →ℜand a given α ∈ℜ, deﬁne the level set of f as
Lα(f) := {x ∈C | f(x) ≤α}.
One can show, from the deﬁnition of quasiconvexity, that f is quasiconvex on a
convex set C if and only if the level set Lα(f) is convex for any α ∈ℜ.
2.1.2
Continuity and Diﬀerentiability Properties
In this section, we discuss the continuity and diﬀerentiability properties of convex
functions. Before we proceed to prove the continuity of convex functions, observe
that the convexity of a function f : ℜn →ℜis equivalent to the following: For any
xi ∈ℜn, λi ∈ℜwith λi ≥0 (i = 1, 2, . . ., m) and m
i=1 λi = 1,
f(
m

i=1
λixi) ≤
m

i=1
λif(xi).
(2.2)
This is a special case of Jensen’s inequality.

2.1 Convex Analysis
19
Theorem 2.1.5 If f : ℜn →ℜis convex, then it is continuous.
Proof. We only need to show, without loss of generality, that f is continuous at
x = 0.
First, we argue that f(x) is bounded above over the set S = {x ∈ℜn | ∥x∥1 =
n
i=1 |xi| ≤1}. Let ei (i = 1, 2, . . ., n) be a unit vector in ℜn with 1 at its ith
component and 0 at other components, and let en+i = −ei (i = 1, 2, . . . , n). Then
for any x ∈S, there exists λi ≥0 (i = 1, 2, . . ., 2n) with 2n
i=1 λi = 1 such that
x = 2n
i=1 λiei. Therefore, (2.2) implies that f(x) ≤maxi=1,2,...,2n f(ei).
We now show that for any sequence xk ∈ℜn (k = 1, 2, . . .,) convergent to x = 0,
f(xk) converges to f(0). Since xk converges to 0, we can assume without loss of
generality that xk ∈S for all k. The deﬁnition of convex functions implies that
f(xk) ≤(1 −∥xk∥1)f(0) + ∥xk∥1f(xk/∥xk∥1).
Letting k tend to inﬁnity, we have
lim
k→∞f(xk) ≤f(0),
where lim denotes the upper limit of a sequence. Also, observe that 0 = (1 −
∥xk∥1
1+∥xk∥1 )xk +
∥xk∥1
1+∥xk∥1 (−
xk
∥xk∥1 ). Again, the deﬁnition of convex functions implies
that
f(0) ≤(1 −
∥xk∥1
1 + ∥xk∥1
)f(xk) +
∥xk∥1
1 + ∥xk∥1
f(−xk/∥xk∥1).
When k goes to inﬁnity, we have
f(0) ≤lim
k→∞
f(xk),
where lim denotes the lower limit of a sequence. Thus, limk→∞f(xk) = f(0) for any
sequence
xk
convergent
to
x
=
0,
and
therefore
f
is
continuous
at 0.
It is appropriate to point out that if the domain of a convex function is not
the whole space, it may not be continuous at the boundary points [for instance,
f : [0, 1] →ℜwith f(x) = 0 for x ∈(0, 1] and f(0) = 1]. However, it is always
continuous at the interior points of its domain. A natural question is whether it is
also diﬀerentiable at these interior points. Unfortunately, it is not always the case.
For example, the absolute value function |x| is convex while not diﬀerentiable at
x = 0. Even though a convex function may not be diﬀerentiable, we will show in
the following that for a convex function, its directional derivative always exists and
possesses nice properties. Recall that for any x, y ∈ℜn, the directional derivative
of a function f : ℜn →ℜat x is deﬁned as follows:
f ′(x; y) := lim
t↓0
f(x + ty) −f(x)
t
.

20
2. Convexity and Supermodularity
For a function f deﬁned on one-dimensional space, let f ′
+(x) = f ′(x; 1) and
f ′
−(x) = −f ′(x; −1), and deﬁne
Df(x, t) := f(x + t) −f(x)
t
.
The following result, which has been widely applied, is helpful in establishing the
monotonicity properties of f ′
+ and f ′
−.
Proposition 2.1.6 Assume that a function f : ℜ→ℜis convex. Then for any
x, x′, t, t′ ∈ℜwith x ≤x′ and 0 < t ≤t′ or x < x + t ≤x′ < x′ + t′,
Df(x, t) ≤Df(x′, t′).
(2.3)
In particular, when t = t′, f has increasing diﬀerences; that is, for any x ≤x′,
t ≥0,
f(x + t) −f(x) ≤f(x′ + t) −f(x′).
Proof. Observe that x ≤x + t, x′ ≤x′ + t. There exist λ, λ′ ∈[0, 1] such that
x + t = (1 −λ)x + λ(x′ + t) and x′ = (1 −λ′)x + λ′(x′ + t). The deﬁnitions of λ
and λ′ imply that λ + λ′ = 1. From the convexity of f, we have
f(x + t) ≤(1 −λ)f(x) + λf(x′ + t)
and
f(x′) ≤(1 −λ′)f(x) + λ′f(x′ + t).
Adding the two inequalities together and rearranging terms, we have that
f(x + t) −f(x) ≤f(x′ + t) −f(x′).
(2.4)
Thus, a convex function has increasing diﬀerences.
We now assume that 0 < t ≤t′. From the convexity of f, we have that
f(x′ + t) ≤

1 −t
t′

f(x′) + t
t′ f(x′ + t′),
which immediately implies that
f(x′ + t) −f(x′)
t
≤f(x′ + t′) −f(x′)
t′
.
This inequality, together with the inequality (2.4), implies the inequality (2.3).
Finally, assume that x < x + t < x′ < x′ + t′. Again, the convexity of f implies
that
f(x + t) ≤(1 −λ)f(x) + λf(x′)
and
f(x′) ≤(1 −λ′)f(x + t) + λ′f(x′ + t′),

2.1 Convex Analysis
21
where λ =
t
x′−x and λ′ =
x′−(x+t)
(x′+t′)−(x+t). The above inequalities are equivalent to
the following:
f(x + t) −f(x)
t
≤f(x′) −f(x + t)
x′ −(x + t)
and
f(x′) −f(x + t)
x′ −(x + t)
≤f(x′ + t′) −f(x′)
t′
.
Therefore, the inequality (2.3) holds if x < x + t < x′ < x′ + t′. The continuity of
convex functions implies that (2.3) is still true if x < x + t ≤x′ < x′ + t′.
Theorem 2.1.7 Assume that f : ℜ→ℜis convex. Then
(a) f ′
+ and f ′
−are well deﬁned, and for any x, x′ ∈ℜwith x < x′, f ′
−(x) ≤
f ′
+(x) ≤f ′
−(x′).
(b) For any ﬁxed x ∈ℜ,
f(x + t) −f(x) ≥ξt ∀t ∈ℜ
if and only if ξ ∈[f ′
−(x), f ′
+(x)].
Proof. From (2.3), we know that Df(x, t) is a nondecreasing function of t for
t > 0 (simply let x′ = x) and is bounded below by Df(x′, t′) for any x < x′ and
0 < t′ < x′ −x. Therefore,
f ′
+(x) = inf
t↓0 Df(x, t).
Similarly, Df(x −t, t) is nonincreasing in t, and hence
f ′
−(x) = sup
t↓0
Df(x −t, t).
Indeed, deﬁne a new convex function g(x) = f(−x) and the nonincreasing property
of Df(x −t, t) follows from applying Proposition 2.1.6 to the function g.
Again from (2.3), it is easy to see that for any x < x′ and 0 < t < x′ −x,
Df(x −t, t) ≤Df(x, t) ≤Df(x′ −t, t).
Letting t ↓0 yields f ′
−(x) ≤f ′
+(x) ≤f ′
−(x′). Thus, part (a) is true.
Finally, part (b) is a direct consequence of the proof for part (a).
Theorem 2.1.7 part (b) implies that for any ξ ∈[f ′
−(x), f ′
+(x)], the function
f(x′) always lies above the line Lx = {(x′, f(x) + ξ(x′ −x)) | x′ ∈ℜ} for any
x; see Fig. 2.3 for an illustration. This result can be extended to convex functions
deﬁned in ℜn. For this purpose, we introduce the concept of subgradient.

22
2. Convexity and Supermodularity
FIGURE 2.3. Illustration of the deﬁnition of subgradient
Deﬁnition 2.1.8 Given a function f : ℜn →ℜ, ξ ∈ℜn is a subgradient of the
function f at x ∈ℜn if, for any t ∈ℜn,
f(x + t) −f(x) ≥⟨ξ, t⟩,
(2.5)
where ⟨ξ, t⟩= n
i=1 ξiti is the inner product between ξ and t. Let the subdiﬀerential
∂f(x) be the set of all subgradients of f at x.
The following theorem characterizes properties of subgradients. The proof of
these properties is omitted since it is quite involved; see Rockafellar (1970) for
more details.
Theorem 2.1.9 Assume that a function f : ℜn →ℜis convex. The following
results hold.
(a) For any x ∈ℜn, ∂f(x) is nonempty, convex, and compact.
(b) For any x, y ∈ℜn, the directional derive of f can be expressed as follows:
f ′(x; y) =
sup
ξ∈∂f(x)
⟨ξ, y⟩.
(c) f is diﬀerentiable at x ∈ℜn if and only if ∂f(x) = {∇f(x)}, where ∇f(x)
denotes the gradient of f at x.
(d) For any compact set C ⊂ℜn, ∪x∈C∂f(x) is compact.
Remark: If the domain of f is not the whole space, Theorem 2.1.9 may fail at
the boundary points of its domain. For example, consider the convex function
f : [0, 1] →ℜwith f(0) = 1 and f(x) = 0 for x ∈(0, 1]. Clearly, it is not
continuous and has no subgradient at x = 0.
We now present the general form of Jensen’s inequality.

2.1 Convex Analysis
23
Proposition 2.1.10 Let f be a convex function over ℜand ζ a random variable
with ﬁnite expectation E[ζ]. We have
f(E[ζ]) ≤E[f(ζ)].
Proof. This proposition can be proven by using the special case of Jensen’s in-
equality (2.2) and the continuity of convex functions as well as the deﬁnition of
expectations. We present an alternative approach based on the properties of sub-
gradients.
Choose any ξ ∈∂f(E[ζ]). From the deﬁnition of subgradients, we have that
f(ζ) −f(E[ζ]) ≥⟨ξ, ζ −E[ζ]⟩.
Taking expectations on both sides yields f(E[ζ]) ≤E[f(ζ)].
2.1.3
Characterization of Convex Functions
The concept of convexity is widely used in optimization. However, identifying
convex functions is not always simple. In this section, we give some suﬃcient and
necessary conditions for a diﬀerentiable function to be convex.
Theorem 2.1.11 Consider a function f : ℜn →ℜ.
(a) If f is diﬀerentiable, then f is convex if and only if for any x, x′ ∈ℜn,
f(x′) −f(x) ≥⟨∇f(x), x′ −x⟩,
(2.6)
where ⟨x, y⟩= n
i=1 xiyi is the inner product of x, y ∈ℜn.
(b) If f is diﬀerentiable, then f is strictly convex if the inequality (2.6) holds
strictly for any x ̸= x′.
(c) If f is continuously diﬀerentiable, then f is convex if and only if ∇f is
monotone; that is, for any x, x′ ∈ℜn, ⟨∇f(x′) −∇f(x), x′ −x⟩≥0.
(d) If f is twice continuously diﬀerentiable, then f is convex if and only if ∇2f(x)
is positive semideﬁnite for any x ∈ℜn.
(e) If f is twice continuously diﬀerentiable, then f is strictly convex if ∇2f(x)
is positive deﬁnite for any x ∈ℜn.
(f) Assume that f(x) = xT Qx for a symmetric matrix Q of order n and x ∈ℜn.
Then f is convex if and only if Q is positive semideﬁnite. And f is strictly
convex if and only if Q is positive deﬁnite.

24
2. Convexity and Supermodularity
Proof. Assume that f is diﬀerentiable. Pick any x, x′ ∈ℜn and deﬁne
φ(λ) := f(x + λ(x′ −x)).
First, notice that f(x) is convex in x if and only if φ(λ) is convex for λ ∈[0, 1] for
any picked x, x′ ∈ℜn. Also, observe that
φ′(λ) = ⟨∇f(x + λ(x′ −x)), x′ −x⟩.
If φ(λ) is convex in λ, then Theorem 2.1.7 part (b) implies that
f(x′) −f(x) = φ(1) −φ(0) ≥φ′(0) = ⟨∇f(x), x′ −x⟩.
Hence, the inequality (2.6) holds for any x, x′ ∈ℜn. On the other hand, if the
inequality (2.6) is true for any x, x′ ∈ℜn, then for any z = (1 −λ)x + λx′ with
λ ∈[0, 1], we have
f(x) −f(z) ≥⟨∇f(z), x −z⟩
and
f(x′) −f(z) ≥⟨∇f(z), x′ −z⟩.
Multiplying the ﬁrst inequality by (1 −λ) and the second inequality by λ and
summing them up, we end up with
f((1 −λ)x + λx′) ≤(1 −λ)f(x) + λf(x′).
Thus, f is convex and part (a) is true. Obviously, from the above argument, one
can see that f is strictly convex if the inequality (2.6) holds strictly. Therefore,
part (b) holds.
For part (c), notice that if φ(λ) is convex, then Theorem 2.1.7 part (a) implies
that φ′(0) ≤φ′(1). Thus,
⟨∇f(x′) −∇f(x), x′ −x⟩= φ′(1) −φ′(0) ≥0.
On the other hand, if ∇f is monotone, then for any λ′ ≥λ ≥0,
φ′(λ′) = ⟨∇f(x + λ′(x′ −x)), x′ −x)⟩≥⟨∇f(x + λ(x′ −x)), x′ −x)⟩= φ′(λ).
Therefore, φ′(λ) is nondecreasing, and hence
φ(λ) = φ(0) +
 λ
0
φ′(ξ)dξ ≤φ(0) + λφ′(λ)
(2.7)
and
φ(λ) = φ(1) −
 1
λ
φ′(ξ)dξ ≤φ(1) −(1 −λ)φ′(λ).
(2.8)
Multiplying the ﬁrst inequality by (1 −λ) and the second inequality by λ and
summing them up, we end up with
φ(λ) ≤(1 −λ)φ(0) + λφ(1);
(2.9)

2.1 Convex Analysis
25
that is, φ is convex for λ ∈[0, 1]. Thus, f is convex. Also, notice that from the
above proof, ∇f is monotone if and only if φ′(λ) is nondecreasing for λ ∈[0, 1].
We now assume that f is twice continuously diﬀerentiable. In this case,
φ′′(λ) = ⟨x′ −x, ∇2f(x + λ(x′ −x))(x′ −x)⟩.
Notice that for any 0 ≤λ ≤λ′ ≤1,
φ′(λ′) −φ′(λ) =
 λ′
λ
φ′′(ξ)dξ.
Therefore, if ∇2f(x) is positive semideﬁnite for any x ∈ℜn, then φ′′(ξ) ≥0 for
any ξ, and hence φ′(λ) is nondecreasing, which in turn implies that f is convex
as we already proved for part (c). On the other hand, the convexity of f implies
that φ′ is nondecreasing, which in turn implies that φ′′(λ) ≥0 for any λ ∈[0, 1].
In particular, we have
0 ≤φ′′(0) = ⟨x′ −x, ∇2f(x)(x′ −x)⟩.
Since x′ ∈ℜn is arbitrary, we have that ∇2f(x) is positive semideﬁnite. This
proves part (d).
If ∇2f(x) is positive deﬁnite for any x ∈ℜn, then for x ̸= x′, φ′(λ) is strictly
increasing for λ ∈[0, 1] and at least one of the inequalities (2.7) and (2.8) holds
as a strict inequality. Hence, the inequality (2.9) holds strictly. This implies that
φ, and therefore f is strictly convex. Thus, part (e) holds.
Finally, for part (f), we only need to prove that if f is strictly convex, then Q is
positive deﬁnite. The remaining results are special cases of parts (d) and (e). If f is
strictly convex, then part (d) implies that Q is positive semideﬁnite. Assume to the
contrary that Q is not positive deﬁnite. There exists a nonzero vector z ∈ℜn such
that f(z) = ⟨z, Qz⟩= 0. Therefore, for any x ∈ℜn, f(x + λz) = f(x) + 2λ⟨x, Qz⟩,
which is a linear function of λ. Thus, f is not strictly convex, a contradiction.
Hence, Q is positive deﬁnite if f is strictly convex.
2.1.4
Convexity and Optimization
Convexity plays an important role in optimization theory. In particular, we show
in the following that a local minimizer of a convex minimization problem, namely,
the problem of minimizing a convex function, is a global minimizer of this problem,
and the ﬁrst-order optimality condition is both suﬃcient and necessary for a point
to be a global minimizer. As we shall see, this result has implications both for
optimization theory and for algorithms.
Theorem 2.1.12 Assume that f : ℜn →ℜis convex. If x∗is a local minimizer
of f, then x∗is a global minimizer of f. Furthermore, x∗is a global minimizer of
f if and only if 0 ∈∂f(x∗).

26
2. Convexity and Supermodularity
Proof. If x∗is a local minimizer, then there exists a ball Bϵ(x∗) = {x ∈ℜn | ∥x −
x∗∥2 < ϵ} for some ϵ > 0 such that f(x) ≥f(x∗) for any x ∈Bϵ(x∗). Moreover,
for any x ∈ℜn, there exists λ ∈(0, 1) such that (1 −λ)x∗+ λx ∈Bϵ. From the
deﬁnition of convexity, we have
f(x∗) ≤f((1 −λ)x∗+ λx) ≤(1 −λ)f(x∗) + λf(x).
The inequality implies that f(x∗) ≤f(x) for any x ∈ℜn. Hence, x∗is a global
minimizer of f, and from the deﬁnition of a subgradient, we have 0 ∈∂f(x∗).
Finally, if 0 ∈∂f(x∗), then the deﬁnition of a subgradient implies that f(x) ≥
f(x∗) for any x ∈ℜn. In other words, x∗is a global minimizer of the function f.
Therefore, x∗is a global minimizer of f if and only if 0 ∈∂f(x∗).
The following result is a straightforward consequence of the deﬁnition of strictly
convex functions.
Theorem 2.1.13 A strictly convex function f : ℜn →ℜhas at most one local
and global minimizer.
We now consider the convex function maximization problem. If f : ℜ→ℜis
convex, then from the deﬁnition of convexity, one can see that either a or b is
an optimal solution for the problem maxx∈[a,b] f(x). More generally, we have the
following result regarding the convex function maximization problem.
Theorem 2.1.14 Assume that a set C ⊂ℜn is compact and f : ℜn →ℜis
convex. Then maxx∈C f(x) achieves maximization at an extreme point x∗of C.
That is, there exists no x, x′ ∈C with x ̸= x′ such that x∗= (x + x′)/2.
We provide some intuition to the theorem instead of a formal proof. Assume that
a maximizer of f(x) over the set C, x∗, is not an extreme point of C. Then there
exist x, x′ ∈C with x ̸= x′ such that x∗= (x + x′)/2. Let L = {x∗+ t(x′ −x) ∈
C|t ∈ℜ} be a line segment in C. It is clear, from the deﬁnition of convexity, that
all points on the line segment L are maximizers of the function f(x). Let ˆx be one
of the endpoints of L. If ˆx is an extreme point of C, we are done; otherwise, we
can repeat the above process and the theorem follows since such a process cannot
proceed an inﬁnite number of times.
The following proposition shows that under some conditions, convexity is pre-
served under optimization operations.
Proposition 2.1.15 Given a function f(·, ·) deﬁned on the product space ℜn ×
ℜm,
(a) If f(·, y) is convex for any given y ∈ℜm, then for any set C ⊂ℜm, the
function h : ℜn →ℜ∪{∞} deﬁned by
h(x) := sup
y∈C
f(x, y)
is also convex (possibly in the extended sense).

2.2 Supermodularity
27
(b) Assume that for any x ∈ℜn, there is an associated set C(x) ⊂ℜm and
C := {(x, y) | y ∈C(x), x ∈ℜn} is convex. If f is convex and the function
g(x) :=
inf
y∈C(x)f(x, y)
is well deﬁned, then g is also convex over ℜn.
Proof. To prove part (a), observe that for any given y ∈C, the set
epi(f(·, y)) = {(x, α) | x ∈ℜn, α ∈ℜ, f(x, y) ≤α}
is convex. Therefore, epi(h) = ∩y∈Cepi(f(·, y)) is a convex set, which implies that
h is convex.
For part (b), let us ﬁx x, x′ ∈ℜn and λ ∈[0, 1]. From the deﬁnition of an
inﬁmum, there exists, for any given ϵ > 0, y, y′ ∈C such that
f(x, y) ≤g(x) + ϵ and f(x′, y′) ≤g(x′) + ϵ.
(2.10)
Since C is convex, we have that ((1 −λ)x + λx′, (1 −λ)y + λy′) ∈C. Thus,
(1 −λ)y + λy′ ∈C((1 −λ)x + λx′) and
g((1 −λ)x + λx′)
≤
f((1 −λ)x + λx′, (1 −λ)y + λy′)
≤
(1 −λ)f(x, y) + λf(x′, y′)
≤
(1 −λ)g(x) + λg(x′) + ϵ,
where the second inequality holds since f(·, ·) is convex and the last inequality
follows from (2.10). Since ϵ is arbitrary, we conclude that g is convex.
2.2
Supermodularity
In this section, we introduce the concept of supermodularity. Though this concept
can be deﬁned on general partially ordered sets, for our purpose we focus on the
Euclidean space ℜn with the standard partial order ≤; that is, for any x, x′ ∈ℜn,
x ≤x′ if and only if xi ≤x′
i for i = 1, 2, . . . , n.
To
present
the
deﬁnition
of
supermodularity,
we
ﬁrst
introduce
two
operations, join and meet operations, in ℜn. For any two points x = (x1, x2, . . . , xn)
and x′ = (x′
1, x′
2, . . . , x′
n) in ℜn, deﬁne their join as
x ∨x′ = (max{x1, x′
1}, max{x2, x′
2}, . . . , max{xn, x′
n}),
and their meet as
x ∧x′ = (min{x1, x′
1}, min{x2, x′
2}, . . . , min{xn, x′
n}).
Of course, if x ≤x′, namely, xi ≤x′
i for i = 1, 2, . . ., n, then x ∨x′ = x′ and
x ∧x′ = x. A set X ⊆ℜn is called a lattice if for any x, x′ ∈X, x ∨x′, x ∧x′ ∈X.
Note that X is called a sublattice of ℜn in some literature as it inherits the inﬁmum
and supremum from ℜn.

28
2. Convexity and Supermodularity
Deﬁnition 2.2.1 Suppose X is a lattice in ℜn and a function f : X →ℜ. The
function f is supermodular on the set X if, for any x, x′ ∈X,
f(x) + f(x′) ≤f(x ∨x′) + f(x ∧x′).
(2.11)
f is strictly supermodular if the inequality (2.11) holds strictly for unordered pairs
x and x′; that is, none of x ≤x′ nor x ≥x′ is true. A function f is (strictly)
submodular if −f is (strictly) supermodular.
A closely related and more intuitive concept is (strictly) increasing diﬀerences.
Given X ⊆ℜn and T ⊆ℜm, a function f : X × T →ℜhas (strictly) increasing
diﬀerences if for any t, t′ ∈T with t ≤t′ (t < t′), f(x, t′) −f(x, t) is (strictly)
increasing in x ∈X. Notice that a function g : X →ℜis called increasing if for
any x, x′ ∈X with x ≤x′, g(x) ≤g(x′).
This concept can be extended to functions deﬁned on sets with a product struc-
ture Πn
i=1Xi, where Xi is a subset of some Euclidean space. For this purpose, we
deﬁne, for a function f : Πn
i=1Xi →ℜ, any pair of indexes i, j ∈{1, 2, . . ., n} and
any vector
ˆxij = (x1, . . . , xi−1, xi+1, . . . , xj−1, xj+1, . . . , xn) ∈Πl=1:n,l̸=i,jXl,
a function
fˆxij(xi, xj) = f(x1, . . . , xi−1, xi, xi+1, . . . , xj−1, xj, xj+1, . . . , xn).
The function f : Πn
i=1Xi →ℜhas (strictly) increasing diﬀerences if the function
fˆxij(xi, xj) has (strictly) increasing diﬀerences for any pair of distinct indexes
i, j ∈{1, 2, . . ., n} and any vector ˆxij ∈Πl=1:n,l̸=i,jXl.
The following result shows that for functions deﬁned on ℜn, the concept of
supermodularity is equivalent to the property of increasing diﬀerences.
Theorem 2.2.2 A function f : ℜn →ℜis (strictly) supermodular if and only
if f has (strictly) increasing diﬀerences when ℜn is regarded as the product of n
one-dimensional real space.
Proof. Assume that f has increasing diﬀerences. Then, for any x, x′ ∈ℜn, we have
f(x) −f(x ∧x′) = n
i=1(f(x1, . . . , xi, xi+1 ∧x′
i+1, . . . , xn ∧x′
n)
−f(x1, . . . , xi−1, xi ∧x′
i, xi+1 ∧x′
i+1, . . . , xn ∧x′
n))
≤n
i=1(f(x1 ∨x′
1, . . . , xi−1 ∨x′
i−1, xi, x′
i+1, . . . , x′
n)
−f(x1 ∨x′
1, . . . , xi−1 ∨x′
i−1, xi ∧x′
i, x′
i+1, . . . , x′
n))
= n
i=1(f(x1 ∨x′
1, . . . , xi−1 ∨x′
i−1, xi ∨x′
i, x′
i+1, . . . , x′
n)
−f(x1 ∨x′
1, . . . , xi−1 ∨x′
i−1, x′
i, x′
i+1, . . . , x′
n))
= f(x ∨x′) −f(x′),
where the inequality holds since f has increasing diﬀerences and the second equal-
ity holds since {xi, x′
i} = {xi ∨x′
i, xi ∧x′
i}. Hence, f is supermodular.

2.2 Supermodularity
29
Assume now that f is supermodular. For any pair of distinct indexes i, j ∈
{1, 2, . . ., n}, any vector
ˆxij = (x1, . . . , xi−1, xi+1, . . . , xj−1, xj+1, . . . , xn) ∈ℜn−2
and xi, x′
i, xj, x′
j ∈ℜwith xi ≤x′
i and xj ≥x′
j , let
x = (x1, . . . , xi−1, xi, xi+1, . . . , xj−1, xj, xj+1, . . . , xn)
and
x′ = (x1, . . . , xi−1, x′
i, xi+1, . . . , xj−1, x′
j, xj+1, . . . , xn).
The supermodularity of f implies that
fˆxij(xi, xj) −fˆxij(xi, x′
j)
=
f(x) −f(x ∧x′)
≤
f(x ∨x′) −f(x′)
=
fˆxij(x′
i, xj) −fˆxij(x′
i, x′
j).
Thus, f has increasing diﬀerences.
Finally, the equivalence of the strict supermodularity and the strictly increasing
diﬀerences can be established by following a similar argument.
If a function f : ℜn →ℜis diﬀerentiable, it is easy to verify that f is supermod-
ular if and only if the partial derivative ∂f(x)
∂xi
is nondecreasing in xj for all distinct
indexes i and j and for any x ∈ℜn. Furthermore, if f is twice diﬀerentiable, then
f is supermodular if and only if
∂2f(x)
∂xi∂xj ≥0 for any distinct indexes i and j and
for any x ∈ℜn.
From the deﬁnition of supermodularity, we can easily conclude that a separable
function f : ℜn →ℜis both supermodular and submodular. In fact, the reverse
is essentially true.
Theorem 2.2.3 A function f : ℜn →ℜis both supermodular and submodular if
and only if f is separable; that is, there exist functions fi : ℜ→ℜ(i = 1, 2, . . . , n)
such that f(x) = n
i=1 fi(xi) for any x = (x1, x2, . . . , xn) ∈ℜn.
Proof. The “if” part is obvious, since as we already pointed out, a function deﬁned
on ℜis both supermodular and submodular. Hence, we focus on the “only if” part.
Assume that f : ℜn →ℜis both supermodular and submodular. Then
f(x)
=
f(0) + n
i=1(f(x1, . . . , xi−1, xi, 0, . . . , 0) −f(x1, . . . , xi−1, 0, 0, . . . , 0))
=
f(0) + n
i=1(f(0, . . . , 0, xi, 0, . . . , 0) −f(0)),
where the second equality holds since from Theorem 2.2.2, f has both increasing
diﬀerences and decreasing diﬀerences. Therefore, f is separable.
In the following, we present some examples of supermodular functions, whose
proof is left as an exercise.

30
2. Convexity and Supermodularity
Theorem 2.2.4
(a) The function f(x, z) = n
i=1 xizi is supermodular on the product space ℜn ×
ℜn, where x, z ∈ℜn.
(b) The Cobb–Douglas function f(x) = xα1
1 xα2
2 · · · xαn
n
for αi ≥0 is super-
modular on the set {x|x = (x1, x2, . . . , xn) ≥0}.
(c) The function f(x, z) = −n
i=1 |xi −zi|p is supermodular on (x, z) ∈ℜ2n for
any p ≥1.
(d) If fi(z) is increasing (decreasing) on ℜfor i = 1, 2, . . . , n, then the function
f(x) = mini∈{1,2,...,n} fi(xi) is supermodular on ℜn.
We now list below some useful properties about supermodular functions. Some of
these properties are similar to Proposition 2.1.3, which deals with convex functions.
Proposition 2.2.5
(a) Any nonnegative linear combination of supermodular functions is supermod-
ular. That is, if fi : ℜn →ℜ(i = 1, 2, . . ., m) are supermodular, then for
any scalar αi ≥0, m
i=1 αifi is still supermodular.
(b) If fk is supermodular for k = 1, 2, . . . and limk→∞fk(x) = f(x) for any
x ∈ℜn, then f(x) is supermodular.
(c) A composition of an increasing (decreasing) convex function and an increas-
ing supermodular (submodular) function is still supermodular. That is, if
f : ℜ→ℜis convex and nondecreasing (nonincreasing) and g : ℜn →ℜis
increasing and supermodular (submodular), then f(g(x)) is supermodular.
(d) Assume that a function f(·, ·) is deﬁned in the product space ℜn × ℜm. If
f(·, y) is supermodular for any given y ∈ℜm, then for a random vector ζ in
ℜm, Eζ[f(x, ζ)] is supermodular, provided it is well deﬁned.
(e) Assume that A is a lattice in ℜn × ℜm and a function f(·, ·) : A →ℜis
supermodular. For any x ∈ℜn, let S(x) = {y ∈ℜm | (x, y) ∈A} and
Πy(A) = {x ∈ℜn | S(x) ̸= ∅}. Then Πy(A) is a lattice. If the function
g(x) =
sup
y∈S(x)
f(x, y)
is ﬁnite on Πy(A), then g is supermodular over Πy(A).
Proof. Parts (a), (b), and (d) follow directly from the deﬁnition of supermodular
functions.
We now prove part (c). Assume that g is increasing and supermodular and f is
convex and nondecreasing. For any x, x′ ∈ℜn, since g is increasing, we conclude

2.2 Supermodularity
31
that g(x ∧x′) ≤g(x), g(x′) ≤g(x ∨x′). Therefore, there exist λ, λ′ ∈[0, 1] such
that
g(x) = (1 −λ)g(x ∧x′) + λg(x ∨x′) and g(x′) = (1 −λ′)g(x ∧x′) + λ′g(x ∨x′).
Adding the two equalities together gives us
g(x) + g(x′) = (2 −λ −λ′)g(x ∧x′) + (λ + λ′)g(x ∨x′).
Since g is supermodular, we must have either g(x ∧x′) = g(x ∨x′) or λ + λ′ ≤1.
In the ﬁrst case, clearly
f(g(x)) + f(g(x′)) = f(g(x ∧x′)) + f(g(x ∨x′)).
In the second case,
f(g(x)) + f(g(x′))
≤
f(g(x ∧x′)) + f(g(x ∨x′))
+
(1 −λ −λ′)(f(g(x ∨x′)) −f(g(x ∧x′)))
≤
f(g(x ∧x′)) + f(g(x ∨x′)),
where the ﬁrst inequality follows from the convexity of function f and the second
inequality holds since λ + λ′ ≤1, f is nondecreasing, and g is increasing. Hence,
f(g(x)) is supermodular. Obviously, the above argument holds true when f is
convex and nonincreasing and g is increasing and submodular.
For part (e), for any x, x′ ∈Πy(A) and any y ∈S(x), y′ ∈S(x′), we have that
(x ∧x′, y ∧y′) ∈A and (x ∨x′, y ∨y′) ∈A.
Thus, y∧y′ ∈S(x∧x′) and y∨y′ ∈S(x∨x′), which imply that x∧x′, x∨x′ ∈Πy(A)
and Πy(A) is a lattice. From the supermodularity of f, we have that
f(x, y) + f(x′, y′)
≤
f(x ∧x′, y ∧y′) + f(x ∨x′, y ∨y′)
≤
g(x ∧x′) + g(x ∨x′).
Finally, taking the supremum for y ∈S(x) and y′ ∈S(x′) in the left-hand side of
the above inequality, we have
g(x) + g(x′) ≤g(x ∧x′) + g(x ∨x′).
Thus, g is supermodular on Πy(A).
The following result establishes some connections between convexity and super-
modularity.
Theorem 2.2.6 Let X be a lattice in ℜn and ai ∈ℜ(i = 1, 2, . . . , n). For a
function f : ℜ→ℜ, deﬁne g : ℜn →ℜwith g(x) := f(n
i=1 aixi) for any
x = (x1, x2, . . . , xn) ∈ℜn. We have the following.
(a) If ai ≥0 for i = 1, 2, . . ., n, and f is convex, then g is supermodular on X.

32
2. Convexity and Supermodularity
(b) If n = 2, a1 > 0, a2 < 0, and f is concave, then g is supermodular on X.
Suppose, in addition, that for any x, x′ with x ≤x′, x ∈X implies x′ ∈X,
ℜ= {n
i=1 αixi | x ∈X}, and f is continuous.
(c) If n ≥2, a1 > 0, a2 > 0, and g is supermodular on X, then f is convex.
(d) If n ≥2, a1 > 0, a2 < 0, and g is supermodular on X, then f is concave.
(e) If n ≥3, a1 > 0, a2 > 0, a3 < 0, and g is supermodular on X, then f is a
linear function.
Proof. First, observe that for any x, x′ ∈ℜn,
n

i=1
aixi −
n

i=1
ai(xi ∧x′
i) =
n

i=1
ai(xi ∨x′
i) −
n

i=1
aix′
i.
(2.12)
We now prove part (a). Since ai ≥0, we have
n

i=1
ai(xi ∧x′
i) ≤
n

i=1
aixi,
n

i=1
aix′
i ≤
n

i=1
ai(xi ∨x′
i).
Therefore, there exist λ, λ′ ∈[0, 1] such that
n

i=1
aixi = (1 −λ)
n

i=1
ai(xi ∧x′
i) + λ
n

i=1
ai(xi ∨x′
i)
and
n

i=1
aix′
i = (1 −λ′)
n

i=1
ai(xi ∧x′
i) + λ′
n

i=1
ai(xi ∨x′
i).
Moreover, (2.12) implies λ + λ′ = 1. Thus, from the convexity of f, we have that
g(x) + g(x′)
=
f(n
i=1 aixi) + f(n
i=1 aix′
i)
≤
f(n
i=1 ai(xi ∧x′
i)) + f(n
i=1 ai(xi ∨x′
i))
=
g(x ∧x′) + g(x ∨x′).
Hence, g is supermodular on X.
For part (b), we argue that for any x = (x1, x2) and x′ = (x′
1, x′
2),
f(a1x1 + a2x2) −f(a1(x1 ∧x′
1) + a2(x2 ∧x′
2))
≤f(a1(x1 ∨x′
1) + a2(x2 ∨x′
2)) −f(a1x′
1 + a2x′
2).
(2.13)
If x ≤x′ or x ≥x′, it is obvious that the inequality (2.13) holds true. Otherwise,
assume, without loss of generality, that x1 = x1 ∨x′
1 and x2 = x2 ∧x′
2. We have,
from (2.12), that
2

i=1
aixi −
2

i=1
ai(xi ∧x′
i) =
2

i=1
ai(xi ∨x′
i) −
2

i=1
aix′
i ≥0.

2.2 Supermodularity
33
It is also easy to verify that
a1x1 + a2x2 ≥a1(x1 ∨x′
1) + a2(x2 ∨x′
2).
Hence, Proposition 2.1.6, together with the above inequality, implies the inequality
(2.13), and thus g is supermodular.
To prove part (c), ﬁx any z, z′ ∈ℜwith z ≤z′. Choose x ∈ℜn such that
n
i=1 aixi = z. Let ϵ = (z′ −z)/(2a1) ≥0 and δ = (z′ −z)/(2a2) ≥0. Also, let
y = x + ϵe1, y′ = x + δe2, and x′ = x + ϵe1 + δe2, where ei is the unit vector with
0 at all components except 1 at its ith component. From the deﬁnitions of ϵ and
δ, we have that n
i=1 aiyi = n
i=1 aiy′
i = (z + z′)/2 and n
i=1 aix′
i = z′. Hence,
the supermodularity of g implies that
f((z + z′)/2) −1/2(f(z) + f(z′)) = 1/2(g(y) + g(y′) −g(x) −g(x′)) ≤0,
since x = y ∧y′ and x′ = y ∨y′. Thus, the convexity of the function f follows from
this inequality and the continuity of f.
We now prove part (d). Fix any z, z′ ∈ℜwith z ≤z′. Choose x ∈ℜn such that
n
i=1 aixi = (z + z′)/2. Let ϵ = (z′ −z)/(2a1) ≥0 and δ = −(z′ −z)/(2a2) ≥0.
Also, let y = x + ϵe1, y′ = x + δe2, and x′ = x + ϵe1 + δe2. From the deﬁnitions of
ϵ and δ, we have that n
i=1 aiyi = z′, n
i=1 aiy′
i = z, and n
i=1 aix′
i = (z + z′)/2.
Hence, the supermodularity of g implies that
f((z + z′)/2) −1/2(f(z) + f(z′)) = 1/2(g(x) + g(x′) −g(y) −g(y′)) ≥0,
since x = y ∧y′ and x′ = y ∨y′. Thus, the concavity of the function f follows from
this inequality and the continuity of f.
Finally, if n ≥3, a1 > 0, a2 > 0, and a3 < 0, the proof for parts (c) and (d)
implies that f is both convex and concave, and hence f is linear.
One of the most widely used properties associated with supermodularity is on the
monotonicity of the sets of optimal solutions of a class of parametric optimization
problems. To present this property, deﬁne a new concept of increasing set function.
Let S(t) be a set function in ℜn parameterized by t ∈T ⊂ℜm; that is, for a
parameter t ∈T , S(t) is a subset of ℜn. The set function S(t) is called increasing
in t if for any t, t′ ∈T with t ≤t′, x ∈S(t), and x′ ∈S(t′), we have that
x ∧x′ ∈S(t) and x ∨x′ ∈S(t′).
The concept of increasing set functions is diﬀerent from set inclusion. To see this,
notice that S(t) = [t, +∞) is an increasing set function for t ∈ℜ, but S(t′) ⊂S(t)
for t < t′. However, for an increasing set function S, it is straightforward to show
that given t, t′ ∈T with t ≤t′, for any x ∈S(t), there exists a point x′ ∈S(t′)
and for any x′ ∈S(t′), there exists a point x ∈S(t) such that x ≤x′.
Proposition 2.2.7 Let S(t) be an increasing set function in ℜn parameterized by
t ∈T ⊂ℜm. We have that S(t) is a lattice of ℜn for any t ∈T . If, in addition,
S(t) is nonempty and compact for any t ∈T , then S(t) has a largest element and
a smallest element, which are increasing in t, respectively.

34
2. Convexity and Supermodularity
Proof. It is straightforward to see from the deﬁnition of increasing set function
that S(t) is a lattice of ℜn for any t ∈T . We now show that S(t) has a largest
and a smallest element if S(t) is compact. Let x∗= (x∗
1, x∗
2, . . . , x∗
n) ∈ℜn with
x∗
i = supx∈S(t) xi, i = 1, 2, . . . , n. Since S(t) is compact, there exists xi ∈S(t)
such that xi
i = x∗
i , i = 1, 2, . . ., n. Hence, x∗= x1 ∨x2 ∨. . . ∨xn ∈S(t) since S(t)
is a lattice. Obviously, x∗is the largest element of S(t).
To show that the largest element of S(t), denoted as ¯x(t), is increasing, note
that for any t, t′ ∈T with t ≤t′, ¯x(t′) ≤¯x(t) ∨¯x(t′) ∈S(t′). Since ¯x(t′) is the
largest element of S(t′), we must have ¯x(t′) = ¯x(t) ∨¯x(t′) ≥¯x(t).
The properties regarding the smallest element of S(t) can be established
similarly.
Under some supermodularity assumptions, the sets of optimal solutions for a
collection of optimization problems parameterized by a parameter are increasing
in the parameter. In addition, for a given parameter, there exist a largest and a
smallest optimal solution, which are increasing in the parameter as well. Consider
the parametric optimization problem
max
x∈S(t) g(x, t).
Let A := {(x, t) | t ∈T, x ∈S(t)} ⊂ℜn × ℜm, and S∗(t) := argmaxx∈S(t)
g(x, t).
Theorem 2.2.8 Assume that S(t) is increasing in t ∈T , and g(x, t) : A →ℜis
supermodular in x for any ﬁxed t ∈T and has increasing diﬀerences in (x, t).
(a) S∗(t) is increasing in t on {t ∈T | S∗(t) ̸= ∅}.
(b) Assume, in addition, that S(t) is a nonempty and compact set of ℜn for any
t ∈T , and g(x, t) is continuous in x on S(t) for any t ∈T . Then S∗(t) is
a nonempty and compact lattice and thus there exist ¯x(t), x(t) ∈S∗(t) such
that for any x ∈S∗(t), x(t) ≤x ≤¯x(t). Furthermore, ¯x(t) and x(t) are
increasing.
Proof. To prove part (a), pick any t, t′ ∈T with t ≤t′ such that S∗(t) and S∗(t′)
are nonempty. For any x ∈S∗(t) and x′ ∈S∗(t′), x ∧x′ ∈S(t) and x ∨x′ ∈S(t′),
since S(t) is increasing in t. We have that
0
≥
g(x ∨x′, t′) −g(x′, t′)
≥
g(x, t′) −g(x ∧x′, t′)
≥
g(x, t) −g(x ∧x′, t)
≥
0,
where the ﬁrst and last inequalities follow from the optimality of x and x′ for t
and t′, respectively, the second inequality from the supermodularity of g in x for
any ﬁxed t, and the third inequality from the increasing diﬀerences property of

2.3 Discrete Convex Analysis
35
g in (x, t). Thus, x ∧x′ ∈S∗(t) and x ∨x′ ∈S∗(t′), which implies that S∗(t) is
increasing in t on {t ∈T | S∗(t) ̸= ∅}.
If g(x, t) is continuous in x and S(t) is nonempty and compact, the set of optimal
solutions S∗(t) is also nonempty and compact for any t ∈T . Part (b) follows
Proposition 2.2.7 directly.
To conclude this subsection, we present an extension of a ﬁxed-point theorem due
to Tarski (1955), which will be useful to prove the existence of a Nash equilibrium
of supermodular games in the next section.
Theorem 2.2.9 Let C be a nonempty and compact lattice of ℜn. If S is an in-
creasing set function mapping any point x ∈C to a nonempty and compact lattice
that itself is a subset of C, then the set of ﬁxed points E = {x ∈C : x ∈S(x)} is
nonempty and has a largest and a smallest ﬁxed point. If, in addition, S depends
on a parameter t ∈T ⊂ℜm and for ﬁxed x ∈C, S(x, t) is increasing in t, then
the largest and the smallest ﬁxed points increase in t.
Proof. Deﬁne a set
¯C = {x ∈C : ∃y ∈S(x) such that y ≥x}.
The set ¯C is nonempty since it includes the smallest element of C, which is guar-
anteed to exist by Proposition 2.2.7.
Let ¯x = sup{x : x ∈¯C}. Since C is a compact set, ¯x is well deﬁned. We show
that ¯x is a ﬁxed point. Note that for x ∈¯C, there exists a yx ∈S(x) such that
yx ≥x. Since S is increasing and x ≤¯x for any x ∈¯C, there exists a point
¯yx ∈S(¯x) such that ¯yx ≥yx. Therefore, ¯y = sup{¯yx : x ∈¯C} ∈S(¯x) since
S(¯x) is a compact lattice. Because yx ≥x for any x ∈¯C, we have that ¯y ≥¯x.
Thus, there exists a point z ∈S(¯y) such that z ≥¯y and ¯y ∈¯C. However, ¯x
is the least upper bound of ¯C and ¯y ≥¯x. We must have that ¯x = ¯y ∈S(¯x).
Thus, E is nonempty and ¯x is its largest element. Similarly, we can show that
x = inf{x ∈C : ∃y ∈S(x) such that y ≤x} is the smallest ﬁxed point in E.
If S also depends on a parameter t ∈T , deﬁne for a given t ∈T
¯C(t) = {x ∈C : ∃y ∈S(x, t) such that y ≥x}.
From the argument in the previous paragraph, it suﬃces to show that ¯C(t) is
increasing in t if S(x, t) is increasing in t for any ﬁxed x ∈C. To see this, pick
two points t, t′ ∈T with t ≤t′ and x ∈¯C(t) and x′ ∈¯C(t′). By deﬁnition, there
exist y ∈S(x, t) and y′ ∈S(x′, t′) such that y ≥x and y′ ≥x′. Since S(x, t) is
increasing in t for any ﬁxed x ∈C, there exists a point z ∈S(x, t′) such that
z ≥y ≥x. Therefore, x ∨x′ ≤z ∨y′ ∈S(x ∨x′, t′) and x ∨x′ ∈¯C(t′). Similarly,
we can show that x ∧x′ ∈¯C(t). Thus, ¯C(t) is increasing in t.
2.3
Discrete Convex Analysis
In this section, we give a brief introduction to discrete convex analysis. Some of
the concepts and results there have been demonstrated useful to inventory models,
and we expect they can ﬁnd more applications in supply chain management.

36
2. Convexity and Supermodularity
Discrete convex analysis can be treated as an extension of convex analysis to
combinatorial structures. It aims at building a uniﬁed theoretical framework for
tractable discrete optimization problems. Two key concepts, L♮-convexity and M ♮-
convexity deﬁned on either real variables or integer variables, play prominent roles
(here L and M stand for “lattice” and “matroid,” respectively). In the following,
we use the notation F to denote either the real space ℜor the set with all integers
Z and F+ to denote the set of nonnegative elements in F. Recall ¯ℜ= ℜ∪+∞.
2.3.1
L♮-Convexity
Deﬁnition 2.3.1 (L♮-Convexity) A function f : Fn →¯ℜis L♮-convex if for
any x, x′ ∈Fn, α ∈F+,
f(x) + f(x′) ≥f((x + αe) ∧x′) + f(x ∨(x′ −αe)),
(2.14)
where e is the n-dimensional all-ones vector. A function f is L♮-concave if −f is
L♮-convex.
Inequality (2.14) is called translation submodular. Notice that in the above
deﬁnition, if f(x) = +∞or f(x′) = +∞, inequality (2.14) is assumed to hold aut-
omatically. Thus, for an L♮-convex function f, its eﬀective domain V = dom(f) =
{x ∈Fn|f(x) < +∞} is an L♮-convex set; that is, it satisﬁes the following
condition:
∀x, x′ ∈V and α ∈F+, (x + αe) ∧x′ ∈V and x ∨(x′ −αe) ∈V.
Let δV : Fn →¯ℜbe the indicator function of a given set V ⊂Fn; that is, δV(x) = 0
if x ∈V and +∞otherwise. It is easy to verify that the set V is L♮-convex if and
only if its indicator function δV is L♮-convex.
We sometimes say a function f is L♮-convex on a set V ⊂Fn with the under-
standing that V is an L♮-convex set and the extension of f to the whole space
Fn by deﬁning f(x) = +∞for x ̸∈V is L♮-convex. It is also straightforward to
show that an L♮-convex function f restricted to an L♮-convex set V by deﬁning
f(x) = +∞for x ̸∈V is also L♮-convex. From the deﬁnition of L♮-convexity, it is
clear that if f : ℜn →¯ℜis L♮-convex, then fZ : Zn →¯ℜis also L♮-convex, where
fZ(x) = f(x) for any x ∈Zn.
We have the following equivalent deﬁnition of L♮-convexity.
Proposition 2.3.2 A function f : Fn →¯ℜis L♮-convex if and only if g(x, ξ) :=
f(x −ξe) is submodular on (x, ξ) ∈Fn × S, where S is the intersection of F and
any unbounded interval in ℜ.
Proof. Assume that f is L♮-convex. Consider any two vectors (x, ξ) ∈Fn × S and
(x′, ξ′) ∈Fn × S. Without loss of generality, assume that ξ ≥ξ′. Let α = ξ −ξ′.
We have that α ∈F+ and
g(x, ξ) + g(x′, ξ′)
=
f(x −ξe) + f(x′ −ξ′e)
≥
f((x −ξe + αe) ∧(x′ −ξ′e))
+f((x −ξe) ∨(x′ −ξ′e −αe))
=
f(x ∧x′ −ξ′e) + f(x ∨x′ −ξe)
=
g(x ∧x′, ξ ∧ξ′) + g(x ∨x′, ξ ∨ξ′),

2.3 Discrete Convex Analysis
37
where the inequality follows from the L♮-convexity of f and the second equality
from the deﬁnition of α. Thus, g is submodular.
On the other hand, assume that g is submodular. For any x, x′ ∈Fn and α ∈F+,
since S is the intersection of F and an unbounded interval in ℜ, it is clear that we
can ﬁnd a pair ξ ∈S and ξ′ ∈S such that ξ = α + ξ′. We have that
f(x) + f(x′) = g(x+ξe, ξ)+g(x′+ξ′e, ξ′)
≥g((x+ξe) ∧(x′+ξ′e), ξ ∧ξ′)+g((x+ξe) ∨(x′+ξ′e), ξ ∨ξ′)
= g((x+ξ′e+αe) ∧(x′+ξ′e), ξ′)+g((x+ξe) ∨(x′+ξe −αe), ξ)
= f((x + αe) ∧x′) + f(x ∨(x′ −αe)),
where the inequality follows from the submodularity of g. Hence, f is L♮-convex.
In the following we present some examples of L♮-convex functions and L♮-convex
sets, whose proof is left as an exercise.
Proposition 2.3.3
(a) Given any univariate convex functions gi : ℜ→¯ℜ(i = 1, · · · , n) and hij :
ℜ→¯ℜ(i ̸= j), the function f : ℜn →¯ℜdeﬁned by
f(x) :=
n

i=1
gi(xi) +

i̸=j
hij(xi −xj)
is L♮-convex. As a special case, any linear function is L♮-convex.
(b) A quadratic function f : ℜn →ℜdeﬁned by f(x) = n
i,j=1 aijxixj with
aij = aji ∈ℜis L♮-convex if and only if the matrix A with its ijth component
being aij is a diagonally dominated M-matrix; that is,
aij ≤0, ∀i ̸= j, aii ≥0, and
n

j=1
aij ≥0, ∀i.
(c) A twice continuously diﬀerentiable function f : ℜn →ℜis L♮-convex if and
only if its Hessian is a diagonally dominated M-matrix.
(d) For a given vector a ∈ℜn and a nondecreasing univariate function f : ℜ→
ℜ, the function g : ℜn →ℜdeﬁned by g(x) = f(maxi=1:n{ai + xi}) is
L♮-convex.
(e) A set with a representation {x ∈Fn : l ≤x ≤u, xi −xj ≤vij, ∀i ̸= j}, is
L♮-convex in the space Fn, where l, u ∈Fn and vij ∈F (i ̸= j). In fact, any
closed L♮-convex set in the space Fn can have such a representation.
We now list below some useful preservation properties about L♮-convex func-
tions. Some of these properties are similar to but more restrictive compared with
those in Proposition 2.2.5, which deals with supermodular functions.

38
2. Convexity and Supermodularity
Proposition 2.3.4
(a) Any nonnegative linear combination of L♮-convex functions is L♮-convex.
That is, if fi : Fn →¯ℜ(i = 1, 2, . . ., m) are L♮-convex, then for any scalar
αi ≥0, m
i=1 αifi is also L♮-convex.
(b) If fk is L♮-convex for k = 1, 2, . . . and limk→∞fk(x) = f(x) for any x ∈Fn,
then f(x) is L♮-convex.
(c) Assume that a function f(·, ·) is deﬁned on the product space Fn × Fm. If
f(·, y) is L♮-convex for any given y ∈Fm, then for a random vector ζ in
Fm, Eζ[f(x, ζ)] is L♮-convex, provided it is well deﬁned.
(d) If f : Fn →¯ℜis an L♮-convex function, then g : Fn × F →¯ℜdeﬁned by
g(x, ξ) = f(x −ξe) is also L♮-convex.
(e) Assume that A is an L♮-convex set of Fn × Fm and f(·, ·) : Fn × Fm →¯ℜ
is an L♮-convex function. Then the function
g(x) = infy:(x,y)∈A f(x, y)
is L♮-convex over Fn if g(x) ̸= −∞for any x ∈Fn.
Proof. Parts (a), (b), and (c) are straightforward; thus, we only prove parts (d)
and (e). We ﬁrst prove part (d). To show that g(x, ξ) is L♮-convex on Fn × F,
notice that for any (x, ξ, ζ) ∈Fn × F × F, g(x −ζe, ξ −ζ) = g(x, ξ), which
is independent of ζ and submodular in (x, ξ). Therefore, from Proposition 2.3.2,
g(x, ξ) is L♮-convex.
To prove part (e), we assume without loss of generality that A = Fn × Fm;
otherwise, we can focus on the restriction of f on A. From the deﬁnition of g, we
have
g(x −ξe) =
inf
y∈F m f(x −ξe, y) =
inf
y∈F m f(x −ξe, y −ξe).
Since f is L♮-convex, from Proposition 2.3.2, the function f(x −ξe, y −ξe) is
submodular in (x, y, ξ) ∈Fn × Fm × F. The preservation of the supermodularity
property in Proposition 2.2.5 part (e) then implies that g(x −ξe) is submodular
for (x, ξ) ∈Fn × F, and thus from Proposition 2.3.2, g is L♮-convex.
Since an L♮-convex function is submodular, we can prove monotonicity proper-
ties of optimal solutions similar to the ones in Theorem 2.2.8. In a simple setting
presented below, one can also show that the optimal solutions have bounded sensi-
tivities. The result was ﬁrst established by Zipkin (2008) to analyze the structural
properties of stochastic inventory models with lost sales.
Lemma 2.3.5 Let g(x, ξ) : Fn × F →¯ℜbe L♮-convex, and let ξ(x) be the
largest optimal solution (assuming existence) of the optimization problem f(x) =
minξ∈F g(x, ξ) for any x ∈dom(f). Then ξ(x) is nondecreasing in x ∈dom(f),
but ξ(x + ωe) ≤ξ(x) + ω for any ω > 0 with ω ∈F and ξ(x) + ω ∈dom(f).

2.3 Discrete Convex Analysis
39
Proof. The statement that ξ(x) is nondecreasing in x ∈dom(f) follows directly
from Theorem 2.2.8. We now prove that ξ(x + ωe) ≤ξ(x) + ω. Deﬁne
ge(x, ξ, ω) = g(x −ωe, ξ −ω).
The L♮-convexity of function g(x, ξ), together with Proposition 2.3.2, implies the
submodularity of function ge(x, ξ, ω). For any given ξ′ ∈ℜwith ξ′ > ξ(x) + ω,
consider two vectors (x, ξ′ −ω, −ω) and (x, ξ(x), 0). Since ω > 0 and ξ′ −ω > ξ(x),
(x, ξ′ −ω, −ω) ∧(x, ξ(x), 0) = (x, ξ(x), −ω),
(x, ξ′ −ω, −ω) ∨(x, ξ(x), 0) = (x, ξ′ −ω, 0),
and we have that for any ξ′ > ξ(x) + ω,
g(x + ωe, ξ′) −g(x + ωe, ξ(x) + ω)
=
ge(x, ξ′ −ω, −ω) −ge(x, ξ(x), −ω)
≥
ge(x, ξ′ −ω, 0) −ge(x, ξ(x), 0)
=
g(x, ξ′ −ω) −g(x, ξ(x))
>
0,
where the ﬁrst inequality follows from the submodularity of ge(x, ξ, ω) and the
last inequality from the assumption of ξ(x) and ξ′. The above inequalities imply
that ξ′ cannot be optimal for the optimization problem minξ∈F g(x + ωe, ξ) for
any ξ′ > ξ(x) + ω.
2.3.2
M♮-Convexity
We now introduce the M ♮-convexity. For a given x ∈Fn, deﬁne its positive support
set
supp+(x) = { i | xi > 0 }.
Let ei ∈Fn be the unit vector with 1 at its ith component for i = 1, 2, . . . , n and
e0 be the vector zero.
Deﬁnition 2.3.6 (M ♮-Convexity) A function f : Fn →¯ℜis M ♮-convex if the
exchange property holds; that is, for any x, x′ ∈dom(f), i ∈supp+(x −x′), there
exist an index j ∈supp+(x′ −x) ∪{0} and a positive number α0 ∈F such that
f(x) + f(x′) ≥f(x −α(ei −ej)) + f(x′ + α(ei −ej))
(2.15)
for any α ∈F with 0 ≤α ≤α0. A function f is M ♮-concave if −f is M ♮-convex.
Similar to L♮-convexity, a set V ∈Fn is called an M ♮-convex set if its indicator
function δV is M ♮-convex. It is clear that the eﬀective domain of an M ♮-convex
function is M ♮-convex. We can also prove that M ♮-convexity is preserved when
taking the limit of a sequence of M ♮-convex functions.
Unfortunately, unlike L♮-convexity, M ♮-convexity is less amicable for analysis.
In fact, an M ♮-convex function restricted to an M ♮-convex set is not necessarily
M ♮-convex, and neither is the sum of two M ♮-convex functions.
A subclass of M ♮-convex functions, relatively easier to deal with, is the so-
called laminar convex functions, deﬁned as the sum of univariate convex functions
indexed by a laminar family.

40
2. Convexity and Supermodularity
Deﬁnition 2.3.7 A nonempty set L consisting of subsets of {1, 2, . . ., n} is called
a laminar family if for any X, Y ∈L, X ∩Y = ∅or X ⊆Y or X ⊇Y . A function
f : Fn →¯ℜis a laminar convex function if it can be represented as
f(x) =

S∈L
fS(

i∈S
xi),
where fS are univariate convex functions and L is a laminar family.
We now present a few facts about M ♮-convex functions and laminar convex
functions, whose proof is left as an exercise.
Theorem 2.3.8
(a) A laminar convex function f : Fn →¯ℜis M ♮-convex.
(b) Any separable convex function, deﬁned as the sum of univariate convex func-
tions, is laminar convex and thus M ♮-convex. As a special case, any linear
function is laminar convex and M ♮-convex.
(c) The intersection of the sets of L♮-convex and M ♮-convex functions is exactly
the set of separable convex functions.
(d) A quadratic function f : ℜn →ℜdeﬁned by f(x) = n
i,j=1 aijxixj with
aij = aji ∈ℜis M ♮-convex in Zn if and only if it is laminar convex, which
is also equivalent to the following condition:
aij ≥0, ∀i, j = 1, . . . , n, and aij ≥min{aik, ajk} for k ̸∈{i, j}.
(2.16)
(e) A quadratic function f : ℜn →ℜdeﬁned by f(x) = n
i,j=1 aijxixj with
aij = aji ∈ℜis M ♮-convex in ℜn if and only if for any γ > 0, A + γI is
nonsingular and (A + γI)−1 is a diagonally dominated M-matrix, where A
is a matrix with aij at its ijth component.
(f) The inﬁmal convolution of two M ♮-convex functions f1, f2 : Fn →¯ℜ, deﬁned
as
g(x) =
min
u,v∈F n,u+v=x(f1(u) + f2(v)),
remains M ♮-convex in Fn if g(x) > −∞for any x ∈Fn.
L♮-convex functions and M ♮-convex functions enjoy nice properties for optimiza-
tion. For example, as we present below, these functions deﬁned on Zn are convex
extendable (its proof is not trivial; readers are referred to Murota 2003), and simi-
lar to Theorem 2.1.12, a local minimizer of an L♮-convex function or an M ♮-convex
function is guaranteed to be a global minimizer. We refer to Murota (2003) for
eﬃcient algorithms for the minimization of L♮-convex functions and M ♮-convex
functions and elegant duality properties between the two classes of functions.

2.3 Discrete Convex Analysis
41
Theorem 2.3.9 L♮-convex functions and M ♮-convex functions deﬁned on Zn are
convex extendable. That is, for any L♮-convex or M ♮-convex function f : Zn →¯ℜ,
there exists a convex function f e : ℜn →¯ℜsuch that f e(x) = f(x) for any x ∈Zn.
Theorem 2.3.10
(a) Assume that f : Zn →¯ℜis L♮-convex. A vector x∗∈dom(f) is a global
minimizer of f if and only if it is a local minimizer in the sense that
f(x∗) ≤min{f(x∗+ v), f(x∗−v)}, for any v ∈{0, 1}n.
(b) Assume that f : Zn →¯ℜis M ♮-convex. A vector x∗∈dom(f) is a global
minimizer of f if and only if it is a local minimizer in the sense that
f(x∗) ≤min{f(x∗−ei + ej)}, for any i, j ∈{0, 1, . . ., n}.
Proof. The “if” direction in both parts (a) and (b) is straightforward. We now
prove the “only if” direction of part (a) by induction on ∥x −x∗∥1, where for any
given x ∈ℜn, ∥x∥1 = n
i=1 |xi|. For any x ∈Zn with ∥x−x∗∥1 = 1, we have from
the deﬁnition of local minimizers that f(x∗) ≤f(x) since x = x∗+ei or x = x∗−ei
for some i. Assume that f(x∗) ≤f(x) for any x ∈Zn with ∥x−x∗∥1 ≤k. Consider
any x ∈Zn with ∥x −x∗∥1 = k + 1. If x∗and x are unordered, it is easy to verify
that
∥x ∧x∗−x∗∥1 < ∥x −x∗∥1 and ∥x ∨x∗−x∗∥1 < ∥x −x∗∥1,
and by the induction assumption, f(x∧x∗) ≥f(x∗) and f(x∨x∗) ≥f(x∗), which
together with the deﬁnition of L♮-convexity imply that
f(x) ≥f(x ∧x∗) + f(x ∨x∗) −f(x∗) ≥f(x∗).
If x∗and x are ordered, without loss of generality assume that x ≤x∗. It is clear
that x ≤(x + e) ∧x∗≤x∗and x ≤x ∨(x∗−e) ≤x∗. If x = x ∨(x∗−e), we
immediately have from the deﬁnition of local minimizers that f(x∗) ≤f(x). If
x ̸= x ∨(x∗−e), we have that
∥(x + e) ∧x∗−x∗∥1 < ∥x −x∗∥1 and ∥x ∨(x∗−e) −x∗∥1 < ∥x −x∗∥1,
and by the induction assumption,
f((x + e) ∧x∗) ≥f(x∗) and f(x ∨(x∗−e)) ≥f(x∗).
Again from the deﬁnition of L♮-convexity, we have that
f(x) ≥f((x + e) ∧x∗) + f(x ∨(x∗−e)) −f(x∗) ≥f(x∗).
We now prove the “only if” direction of part (b) by induction on ∥x −x∗∥1. For
any x ∈Zn with ∥x −x∗∥1 = 1, it is clear from the deﬁnition of local minimizers
that f(x∗) ≤f(x) since x = x∗+ ei or x = x∗−ei for some i. Assume that

42
2. Convexity and Supermodularity
f(x∗) ≤f(x) for any x ∈Zn with ∥x −x∗∥1 ≤k. Consider any x ∈Zn with
∥x −x∗∥1 = k + 1. We have that there exist some i ∈supp(x −x∗) ∪{0} and
j ∈supp(x∗−x) ∪{0} with i ̸= j such that ∥x −(ei −ej) −x∗∥1 < ∥x −x∗∥1, and
thus,
f(x) ≥f(x −(ei −ej)) + f(x∗+ (ei −ej)) −f(x∗) ≥f(x∗),
where the ﬁrst inequality follows from the deﬁnition of M ♮-convexity and the
second inequality from the induction assumption and the deﬁnition of local mini-
mizers.
2.4
Exercises
Exercise 2.1. Assume that a function f : ℜn →ℜis continuous.
(a) Prove that f is convex if and only if it satisﬁes the midpoint convexity;
namely, for any x, x′ ∈ℜn,
f
x + x′
2

≤1
2(f(x) + f(x′)).
(b) Prove that f is convex if and only if it satisﬁes the equidistance convexity;
that is, for any x, x′ ∈ℜn and α ∈[0, 1],
f(x) + f(x′) ≥f(x −α(x −x′)) + f(x′ + α(x −x′)).
Exercise 2.2. (Private Communication with Peng Sun) Assume that f : ℜ→ℜis
convex, and random variables X1, X2, . . . , are nonnegative and independently and
identically distributed. Prove that E[f(n
i=1 Xi)] is convex on the set of natural
numbers.
Exercise 2.3. Prove Theorem 2.2.4.
Exercise 2.4.
Assume that a function f(·, ·) is deﬁned on the product space
ℜn × ℜm and f(·, y) is convex for any given y ∈ℜm. Let ζ be a random vector in
ℜm. Prove the following:
(a) The exponential function exp(x) is strictly increasing and convex.
(b) The function Eζ[exp(w + f(x, ζ))] is jointly convex in x and w.
(c) The function ln (Eζ[exp(f(x, ζ))]) is convex.
Exercise 2.5.
If f : ℜn ×ℜm →ℜis quasiconvex, show that g(x) = miny f(x, y)
is also quasiconvex provided that g is well deﬁned.

2.4 Exercises
43
Exercise 2.6.
Assume that A is a lattice in the product space ℜn × ℜm. Prove
that the set function S(t) = {x ∈ℜn|(x, t) ∈A} is increasing on the set {t ∈
ℜm|S(t) ̸= ∅}.
Exercise 2.7. Let Z be the set of all integers in ℜ. Prove that a function f is
convex on Z if and only if either of the following two conditions holds:
(a) Δf(x) is nondecreasing, where Δf(x) = f(x + 1) −f(x).
(b) There exists a convex function g on ℜsuch that g(x) = f(x) for all x ∈Z.
In other words, g is a convex extension of f.
Exercise 2.8. Prove that a function f : Zn →¯ℜis L♮-convex if and only if for
any x, x′ ∈Zn, the following discrete midpoint convexity holds:
f(x) + f(x′) ≥f
x + x′
2
	
+ f

x + x′
2

,
(2.17)
where for any x ∈ℜn, ⌊x⌋is an n-dimensional integer vector derived by rounding
down each component of x to its nearest integer, and ⌈x⌉is an n-dimensional
integer vector derived by rounding up each component of x to its nearest integer.
Exercise 2.9. Prove Theorem 2.3.3.
Exercise 2.10. Prove that the set of minimizers of an L♮-convex (M ♮-convex)
function is L♮-convex (M ♮-convex).
Exercise 2.11. Prove that any L♮-convex (M ♮-convex) set S ⊂Zn is hole-free;
that is, S is exactly the intersection of the convex hull of S and Zn.
Exercise 2.12. Prove Theorem 2.3.8.
Exercise 2.13. Prove the following statements by providing counterexamples:
(a) a quadratic M ♮-convex function in ℜn may not be laminar convex; (b) the
condition in (2.16) is suﬃcient but not necessary for a quadratic function to be
M ♮-convex in ℜn.
Exercise 2.14. Prove or disprove the following statement: The inﬁmal convolu-
tion of two laminar convex functions deﬁned on the same laminar family remains
laminar convex.
Exercise 2.15. Prove Theorem 2.3.9.
Exercise 2.16. The deﬁnitions of L♮-convex functions and M ♮-convex functions
on ℜn are diﬀerent from the original ones in Murota and Shioura (2004), which
explicitly impose the convexity condition. You are asked to show that they are

44
2. Convexity and Supermodularity
equivalent under the continuity assumption; that is, continuous L♮-convex func-
tions and M ♮-convex functions deﬁned on ℜn are convex. Is the continuity as-
sumption dispensable?
Exercise 2.17. Prove that an M ♮-convex function f : Zn →¯ℜis supermodular
in Zn.
Exercise 2.18. (Chen et al. 2012b) Consider the following optimization problem
parameterized by two-dimensional vectors x ∈S = {Ay : y ∈D}:
f(x)
=
max
g(y)
s.t.
Ay = x,
y ∈D,
where A is a nonnegative 2 × n matrix, D is a closed convex lattice of ℜn, and
g : D →ℜ. Show that if g is concave and supermodular on D, then so is f on S.
Exercise 2.19. (Hu 2011) For i = 1, 2, . . . , m, let Di be a subset of ℜ2 and
gi : Di →ℜ. Deﬁne
f(x)
=
max
m
i=1 gi(xi)
s.t.
m
i=1 xi = x,
xi ∈Di ∀i = 1, 2, . . . , m.
Show that if Di are L♮-convex sets and gi are L♮-concave functions, then f is
L♮-concave.

3
Game Theory
Game theory provides a powerful mathematical framework for modeling and ana-
lyzing systems with multiple decision makers, referred to as players, with possibly
conﬂicting objectives. A game studied in game theory consists of a set of players,
a set of strategies (or moves) available to the players, and their payoﬀs (or util-
ities) for each combination of their strategies. Depending on whether the players
can sign enforceable binding agreements, game theory consists of two branches:
noncooperative game theory and cooperative game theory. Noncooperative game
theory provides concepts and tools to study the behaviors of the players when they
make their decisions independently. Cooperative game theory, on the other hand,
assumes that it is possible for the players to sign enforceable binding agreements
and provides concepts describing basic principles these binding agreements should
follow. Both noncooperative game theory and cooperative game theory have been
widely used in many disciplines, such as economics, political science, social science,
as well as biology and computer science, among others. They have also received
considerable attention in supply chain management literature in recent years. In
this chapter, we provide a concise introduction to some of the key concepts and
results that are most relevant in our context. We refer to Osborne (2003) and
Myerson (1997) for both noncooperative game theory and cooperative game the-
ory, Fudenberg and Tirole (1991) and Ba¸sar and Olsder (1999) for noncooperative
game theory, Vives (2000) on oligopoly pricing from the perspective of noncoop-
erative game theory, and Peleg and Sudh¨olter (2007) for cooperative game theory,
respectively.
D. Simchi-Levi et al., The Logic of Logistics: Theory, Algorithms, and Applications
for Logistics Management, Springer Series in Operations Research and Financial Engineering,
DOI 10.1007/978-1-4614-9149-1 3, © Springer Science+Business Media New York 2014
45

46
3. Game Theory
3.1
Noncooperative Game Theory
Noncooperative
games
can
be
represented
in
both
extensive
form
and
normal form. A game in extensive form speciﬁes the sequence of moves of the
players and the associated information structure based on which the players decide
their moves, while a game in normal form is a simultaneous move game in which
the players move only once and at the same time. Whether to represent a game in
either extensive form or normal form depends on which form is more convenient for
a speciﬁc application. For example, a Stackelberg game in which one player, ref-
erred to as the leader, makes its move ﬁrst followed by the moves of other players,
referred to as the followers, after observing the leader’s move, is naturally described
in extensive form. However, mathematically, any extensive form representation of
a game can be equivalently translated into a game in normal form, and a game in
normal form can be treated as an extensive form game with simultaneous moves.
For our purpose, we will restrict our attention to games in normal form here.
A game in normal form is speciﬁed by a triple (N, {Si}i∈N, {ui}i∈N), where N =
{1, 2 . . ., n} is the set of players, Si is the set of strategies of player i, ui : S →ℜis
player i’s payoﬀas a function of the composition of all players’ strategies, referred
to as a strategy proﬁle, and S = Πi∈NSi is the set of all strategy proﬁles. All these
elements are common knowledge to the players. That is, the players know these
elements, they know the other players know these elements, they know the other
players know the other players know these elements, and so on.
A simple example of a noncooperative game is the famous prisoner’s dilemma.
In this game, two criminals, referred to as Players 1 and 2, are arrested and im-
prisoned. They have to decide independently whether to betray the other or keep
silent. If both criminals keep silent, each of them will serve one year in prison; if
both betray, each serves two years; if one betrays and the other keeps silent, the
one who betrays is set free and the other will serve three years.
The normal form of the prisoner’s dilemma is speciﬁed by (N, {Si}i∈N,
{ui}i∈N), where N = {1, 2}, S1 = S2 = {Silent, Betray}, and the payoﬀof each
player is the negative of the number of years served in prison by the player. The
payoﬀs of the game can be described in Table 3.1. In the table, the ﬁrst column
speciﬁes the strategies of Player 1 and the ﬁrst row speciﬁes the strategies of Player
2. In each cell, the ﬁrst number is the payoﬀof Player 1 and the second number
is the payoﬀof Player 2, given their corresponding strategies.
Silent
Betray
Silent
−1,
−1
−3,
0
Betray
0,
−3
−2,
−2
TABLE 3.1. The prisoner’s dilemma

3.1 Noncooperative Game Theory
47
3.1.1
Deﬁnition and Existence of Nash Equilibrium
Given the speciﬁcation of a game, one is interested in predicating its outcome—
which strategies the players will take and what payoﬀeach of them will receive.
In this respect, the Nash equilibrium is one of the most important concepts in
noncooperative game theory.
Deﬁnition 3.1.1 Given a game (N, {Si}i∈N, {ui}i∈N), a strategy proﬁle s∗=
(s∗
1, . . . , s∗
n) ∈S is a Nash equilibrium (in pure strategies) if for any i ∈N,
ui(s∗) ≥ui(si, s∗
−i) ∀si ∈Si,
where for a given s ∈S, s−i ∈Πj̸=iSj is the strategy proﬁle of all players except
player i.
The above deﬁnition says that in a Nash equilibrium, any player’s strategy
maximizes its own payoﬀassuming that the other players’ strategies are speciﬁed
in the Nash equilibrium; that is, for any i ∈N,
s∗
i ∈argmaxsi∈Siui(si, s∗
−i).
Clearly, a Nash equilibrium speciﬁes basic requirements rational players would
respect and is often used as an appropriate predication of their behaviors. In fact,
when playing the game, a player may conjecture the strategies of other players.
In an equilibrium, the conjectures of the players are correct and the players, if
rational, would respectively maximize their payoﬀs given their conjectures.
Consider the prisoner’s dilemma. For Player 1, it is clear that its best strategy
is to betray Player 2 no matter what strategy Player 2 takes. Similarly, Player 2’s
best strategy is to betray Player 1. Thus, the strategy proﬁle (Betray, Betray) is
a Nash equilibrium. It is interesting to observe that both players can be better
oﬀby keeping silent. However, the strategy proﬁle (Silent, Silent) is not a Nash
equilibrium.
Despite its conceptual appealing, the concept of Nash equilibrium faces several
theoretical and practical diﬃculties. One of the main diﬃculties is that a game
may not admit any Nash equilibrium, as demonstrated in the following matching
penny game. In this game, two players, Player 1 and Player 2, each of whom has a
penny, need to decide independently which side to show. If the sides of the pennies
match, namely, both players show either heads or tails, Player 1 collects both
pennies and thus has a gain of one penny; otherwise, Player 2 collects both pennies
and has a gain of one penny. Formally, we face a game (N, {Si}i∈N, {ui}i∈N), with
N = {1, 2}, S1 = S2 = {Head, Tail}, and (u1, u2) described in Table 3.2.
Head
Tail
Head
+1,
−1
−1,
+1
Tail
−1,
+1
+1,
−1
TABLE 3.2. Payoﬀs of matching penny game

48
3. Game Theory
The matching penny game is a zero-sum game in which the total payoﬀof the
two players is zero for any strategy proﬁle. It does not have a Nash equilibrium. To
see this, notice that for any strategy chosen by Player 1, Player 2’s best response
is to pick a diﬀerent strategy, while for any strategy chosen by Player 2, Player
1’s best response is to follow the same strategy. Thus, any strategy proﬁle is not
a Nash equilibrium.
We ﬁrst present a set of conditions under which the existence of a Nash equi-
librium is guaranteed.
Theorem 3.1.2 Given a game (N, {Si}i∈N, {ui}i∈N), if for any player i ∈N,
its strategy set Si is a nonempty, convex, and compact set in a Euclidean space,
its payoﬀfunction ui is continuous in s ∈S and quasiconcave in si ∈Si, then the
game has a Nash equilibrium. If, in addition, the game is symmetric, namely, for
any i, j ∈N, Si = Sj, and ui(si, s−i) = uj(s′
j, s′
−j) if si = s′
j and s−i and s′
−j are
the same when ignoring the identities of the players, there is a symmetric Nash
equilibrium.
The proof is an application of the well-known Kakutani ﬁxed-point theorem,
which we state in the following without proof.
Theorem 3.1.3 Let C be a nonempty, compact, and convex subset of ℜn. Let T
be a set-valued operator that maps any x ∈C to a nonempty and convex subset of
C. If the set {(x, y) : x ∈C, y ∈T (x)}, referred to the graph of T , is closed, then
T has a ﬁxed point. That is, there exists an x ∈C such that x ∈T (x).
To gain some intuition, let’s look at a simple case with a function f : [0, 1] →
[0, 1]. If f is continuous, then one can see directly from a graph that the curve
y = f(x) must intersect the line y = x at some x ∈[0, 1]; that is, a ﬁxed point
exists.
Theorem 3.1.2 is an immediate consequence of the Kakutani ﬁxed-point theo-
rem. To see this, denote for any s ∈S, Ti(s) = argmaxs′
i∈Siui(s′
i, s−i), the best
response of player i given the strategies of the other players, and note that a Nash
equilibrium is exactly a ﬁxed point of the best response operator T = (T1, . . . , Tn),
which maps a strategy proﬁle in S to a subset of S. The continuity of ui together
with the compactness of Si implies that T has a closed graph, and the quasicon-
cavity of each player’s payoﬀin its own strategy together with the convexity of the
strategy set implies that T (x) is convex for any x ∈S. Thus, T has a ﬁxed point
and the game has a Nash equilibrium. To show that a symmetric game admits a
symmetric equilibrium, denote for any ˜s ∈S1, ˜T(˜s) = argmaxs′
1∈Siu1(s′
1, ˜s, . . . , ˜s).
Again, the conditions in Theorem 3.1.2 imply that ˜T has a ﬁxed point ˜s∗, and
therefore the symmetric strategy proﬁle (˜s∗, ˜s∗, . . . , ˜s∗) is a Nash equilibrium. We
emphasize that ˜s∗is a ﬁxed point of ˜T. In most cases, it is not a global maximizer
of u1(s, s, . . . , s). A common mistake we have seen is to claim that if (s0, s0, . . . , s0)
is a symmetric equilibrium, then s0 is a global maximizer of u1(s, s, . . . , s), or vice
versa.

3.1 Noncooperative Game Theory
49
A diﬀerent set of conditions to guarantee the existence of a Nash equilibrium
without quasiconcavity of the payoﬀfunctions is based on supermodularity. Specif-
ically, a game (N, {Si}i∈N, {ui}i∈N) is called (strictly) supermodular if, for each
i ∈N, Si is a lattice, and ui is (strictly) supermodular in si ∈Si for any ﬁxed
s−i ∈Πj̸=iSj and has (strictly) increasing diﬀerences in (si, s−i) on Si × Πj̸=iSj.
For simplicity, we restrict our discussion to cases in which Si is a lattice in a
Euclidean space. We have the following theorem about a Nash equilibrium for
supermodular games.
Theorem 3.1.4 Given a supermodular game (N, {Si}i∈N, {ui}i∈N), if for i ∈N,
Si is nonempty and compact, ui is continuous in si ∈Si for any ﬁxed s−i ∈
Πj̸=iSj, then the set of Nash equilibria is nonempty and has a largest and a smallest
element. If, in addition, the payoﬀfunctions ui are parameterized by t ∈T ⊆ℜm
and have increasing diﬀerences in (si, t) for any ﬁxed s−i ∈Πj̸=iSj, the largest
and the smallest Nash equilibria are increasing in t.
Proof. We prove this theorem using the generalized Tarski ﬁxed-point theorem,
Theorem
2.2.9.
Again,
for
any
s
∈
S,
let
Ti(s)
=
argmaxs′
i∈Si
ui(s′
i, s−i) and T = (T1, . . . , Tn). Our assumption on ui(si, s−i) together with The-
orem 2.2.8 implies that Ti(s), as a subset of Si, is a nonempty and compact lattice
for any s ∈S and Ti is increasing. Thus, T (s), as a subset of S, is a nonempty and
compact lattice for any s ∈S and T is increasing. From Theorem 2.2.9, the set of
ﬁxed points of T , or equivalently the set of Nash equilibria, is nonempty and has
a largest and a smallest element.
If, in addition, the payoﬀfunctions ui (i ∈N) are parameterized by t ∈T ⊆
ℜm and have increasing diﬀerences in (si, t) for any ﬁxed s−i ∈Πj̸=iSj, from
Theorem 2.2.8, the set Ti(s, t) = argmaxs′
i∈Siui(s′
i, s−i, t) is increasing in t as well.
The remaining argument is similar to the one in the previous paragraph using the
second part of Theorem 2.2.9.
One remedy for games without Nash equilibria in pure strategies is to allow
mixed strategies. Speciﬁcally, a mixed strategy for a player i with a strategy set
Si is a probability distribution deﬁned over Si. Let Σi be the set of all mixed
strategies of player i and Σ = Σ1 × . . . × Σn. We now deﬁne a Nash equilibrium
in mixed strategies.
Deﬁnition 3.1.5 Given a game (N, {Si}i∈N, {ui}i∈N), a strategy proﬁle σ∗=
(σ∗
1, . . . , σ∗
n) ∈Σ is a Nash equilibrium in mixed strategies if, for any i ∈N,
ui(σ∗) ≥ui(si, σ∗
−i) ∀si ∈Si,
where, for a given σ, σ−i is the strategy proﬁle of all players except player i and
ui(σ) is the expected payoﬀ.
Unlike the case with a Nash equilibrium in pure strategies, one can show using
Theorem 3.1.2 that a Nash equilibrium in mixed strategies always exists for games
with ﬁnite (pure) strategies. Indeed, using mixed strategies can be regarded as a

50
3. Game Theory
way to convexify the payoﬀs and the strategy sets of a game. Come back to the
matching penny game. We now show it has a unique Nash equilibrium in mixed
strategies. For this purpose, let σ1 = (x1, x2) ∈Σ1 = {(x1, x2) : x1 + x2 = 1, x1 ≥
0, x2 ≥0}, which speciﬁes a mixed strategy of choosing “Head” and “Tail” with
probabilities x1 and x2, respectively. Similarly, let σ2 = (y1, y2) ∈Σ2(= Σ1). We
have u1(σ) = (x1 −x2)(y1 −y2) and u2(σ2) = −u1(σ). The deﬁnition of a Nash
equilibrium in mixed strategies implies that
u1(σ∗) = (x∗
1 −x∗
2)(y∗
1 −y∗
2) ≥u1((1, 0), σ∗
2) = y∗
1 −y∗
2,
u1(σ∗) = (x∗
1 −x∗
2)(y∗
1 −y∗
2) ≥u1((0, 1), σ∗
2) = −(y∗
1 −y∗
2).
Thus,
|y∗
1 −y∗
2| ≤u1(σ∗) ≤|x∗
1 −x∗
2||y∗
1 −y∗
2| ≤|y∗
1 −y∗
2|.
If y∗
1 ̸= y∗
2, we must have |x∗
1 −x∗
2| = 1; that is, σ∗
1 must be a pure strategy.
Symmetrically, if x∗
1 ̸= x∗
2, σ∗
2 must be a pure strategy. However, as demonstrated
earlier, the matching penny game does not have a Nash equilibrium in pure strate-
gies. Thus, we must have σ∗
1 = σ∗
2 = (1/2, 1/2). That is, both players choose their
pure strategies with equal probability, resulting in zero expected payoﬀs for each
of the players.
Though the existence of a Nash equilibrium in mixed strategies can be guaran-
teed even when a Nash equilibrium in pure strategies does not exist, it is not clear
how mixed strategies would be implemented in supply chain management settings.
Thus, we mainly focus on a Nash equilibrium in pure strategies and simply refer
to it as a Nash equilibrium when there is no confusion.
3.1.2
Uniqueness of Nash Equilibrium
Another diﬃculty with the concept of Nash equilibrium is that a game may have
multiple equilibria. In this case, it often depends on factors that are not included
in the formal description of the game to determine which equilibrium would be
an appropriate outcome. Consider a game in which two friends, again referred to
as Player 1 and Player 2, decide independently between two locations, A and B,
for lunch. If it happens that they pick the same location, they enjoy each other’s
company and get a payoﬀof 1 each; otherwise, they eat alone and get a payoﬀ
of 0 (Table 3.3). This is a coordination game without communication. Similar to
the matching penny game, we can present the payoﬀs of the players in a table
format. One can easily check that the game has two Nash equilibria, (A, A) and
(B, B). From the description of the game, it is not clear how one player can make
a right guess of the move of the other player and whether any equilibrium could
be realized.
Thus, in many applications, it is desirable to establish the uniqueness of a Nash
equilibrium. There are three basic approaches for this purpose, which are termed
the “contraction,” “univalence,” and “index theory” approaches, respectively.

3.1 Noncooperative Game Theory
51
A
B
A
+1,
+1
−1,
−1
B
−1,
−1
+1,
+1
TABLE 3.3. Payoﬀs of coordination game without communication
The ﬁrst approach is based on the contraction principle, which says that a
contraction operator in a Euclidean space (or, more generally, complete space)
has a unique ﬁxed point. Speciﬁcally, given a subset C of a Euclidean space, an
operator T : C →C is a contraction if there exists a constant α with 0 < α < 1
such that for any x, x′ ∈C, ∥T (x) −T (x′)∥≤α∥x −x′∥, where ∥· ∥is a norm (for
example, the commonly used 1-norm, 2-norm, or ∞-norm). If C is closed, then T
has a unique ﬁxed point in C. If, in addition, C is compact, it suﬃces to require
∥T (x) −T (x′)∥< ∥x −x′∥for any x, x′ ∈C. A suﬃcient condition for the best
response operator T to be a contraction is that the ∞-norm of the Jacobian of T
is less than 1.
Under the assumptions in Theorem 3.1.2, if one can show that the best re-
sponse operator is single-valued and a contraction, then we have a unique Nash
equilibrium. One suﬃcient condition for the case in which the strategy sets Si are
one-dimensional is the diagonal dominance of the second-order derivatives of the
payoﬀs
∂2ui(s)
∂2si
+

j̸=i

∂2ui(s)
∂si∂sj
 < 0, ∀s ∈S, i ∈N,
(3.1)
which implies that the ∞-norm of the Jacobian of T is less than 1. To see this,
observe that if all equilibria are interior points of the strategy sets and the payoﬀ
functions
are
diﬀerentiable,
we
have
the
ﬁrst-order
optimality
condition
∇ui(s′
i, s−i)|s′
i=Ti(s) = 0 for i ∈N, where ∇iui(s) is the gradient of ui with
respect to si. From the implicit function theorem, ∂Ti(s)
∂si
= 0 and for j ̸= i,
∂Ti(s)
∂sj
= −
∂2ui(s′
i, s−i)
∂2si
−1 ∂2ui(s′
i, s−i)
∂si∂sj
|s′
i=Ti(s).
The ∞-norm of the Jacobian of T is given by
max
i∈N

j∈N

∂Ti(s)
∂sj
 .
Similar conditions can be derived when the strategy sets Si are multidimensional.
The second approach is based on analyzing the ﬁrst-order optimality conditions
of all players’ maximization problems. A key condition for the uniqueness of a
Nash equilibrium is the diagonally strict concavity of the payoﬀfunctions. Deﬁne
∇u(s) = [∇1u1(s), . . . , ∇nun(s)]T .
Deﬁnition 3.1.6 The payoﬀfunctions {ui}i∈N are diagonally strictly concave on
S if for any s, s′ ∈S,
(s −s′)T (∇u(s) −∇u(s′)) < 0.

52
3. Game Theory
When the strategy sets Si are one-dimensional, the condition (3.1) implies that
the payoﬀfunctions are diagonally strictly concave.
Denote G(s) the Jacobian of ∇u(s). It is straightforward to show that if G(s) +
G(s)T is negative deﬁnite for any s ∈S, then the payoﬀfunctions are diagonally
strictly concave. Some additional technical conditions are also needed. Speciﬁcally,
we assume that the strategy sets have explicit algebraic representations:
Si = {si ∈ℜni|hij(si) ≥0, j = 1, . . . , τi},
(3.2)
where ni and τi are positive integers and hij : ℜni →ℜ.
The following uniqueness result is due to Rosen (1965).
Theorem 3.1.7 Consider a game (N, {Si}i∈N, {ui}i∈N). Assume that Si is com-
pact and has the representation (3.2), where hij is concave, and there exists some
x0
i ∈ℜni such that hij(x0
i ) > 0 for any nonlinear function hij. If the payoﬀ
functions are diagonally strictly concave on S, then the game has a unique Nash
equilibrium.
The existence of a Nash equilibrium follows from Theorem 3.1.2. The conditions
on hij are imposed so that we can write down the ﬁrst-order optimality conditions,
commonly referred to as the Karush–Kuhn–Tucker (KKT) conditions, and the
diagonally strict concavity of the payoﬀfunctions is suﬃcient for the uniqueness
of a solution to the KKT conditions.
The third approach is based on the Poincar´e–Hopf index theorem. Consider a
function g : C →ℜm, where C is a nonempty compact set in ℜm. An implication
of the Poincar´e–Hopf index theorem is that under some boundary condition on C,
g(a) = 0 has a unique solution if the determinant of −G(a) is positive whenever
g(a) = 0, where G(a) is the Jacobian of g. To gain some intuition, consider a
diﬀerentiable function g : [0, 1] →ℜwith g(0) > 0 and g(1) < 0. Clearly, g(a) = 0
has at least one solution. It cannot have multiple solutions. To see this, let a∗be
any solution of g(a) = 0; then for a > a∗, g(a) is less than zero until it reaches
zero for the ﬁrst time at some a′. However, it is impossible since g has a negative
derivative at a′.
If all equilibria are interior points of the strategy sets and the payoﬀfunctions are
diﬀerentiable, then any equilibrium s∗would be a solution of the equation system
∇u(s) = 0. The index theory thus provides an approach to check the uniqueness
of a Nash equilibrium. That is, if the determinant of the Jacobian of −∇u(s) is
positive at the equilibria, then we have a unique Nash equilibrium. This approach
is less restrictive but harder to check than the other two approaches.
3.2
Cooperative Game Theory
Cooperative games can be represented in either coalitional form or strategic form.
Cooperative strategic games assume that the players can make binding agreements
on the choice of strategies, while cooperative coalitional games assume that they

3.2 Cooperative Game Theory
53
can make binding agreements on the distribution of payoﬀs. Since many applica-
tions can be naturally formulated in coalitional form and the players focus more
on the choice of stable payoﬀs rather than on the choice of stable strategies, as
any combination of strategies can be supported by a binding agreement, we will
only consider cooperative games in coalitional form.
Cooperative coalitional games can be divided into two categories: transferrable
utilities and nontransferrable utilities. A coalitional game with transferrable utili-
ties is a pair (N, V ), where N = {1, 2, . . ., n} is the set of all players and referred to
as the grand coalition, and V is the characteristic function that maps any subset S
of N, called a coalition, to a real number with V (∅) = 0. If a coalition S forms, its
value V (S) can be allocated in any possible way among its members by allowing
side payments. That is, a feasible payoﬀvector x of the players in S satisﬁes the
condition x(S) ≤V (S), where we use the notation x(S) to denote 
i∈S xi and xi
is the payoﬀto player i. A coalitional game with nontransferrable utilities is a pair
(N, V ), where again N = {1, 2, . . ., n} is the set of all players, and V is a mapping
that associates a set in a Euclidean space with each coalition S. For simplicity, we
focus on coalitional games with transferrable utilities and we simply refer to them
as coalitional games or cooperative games in coalition form.
Depending on the properties of the characteristic functions, we can deﬁne mono-
tonic, superadditive, and convex games. Speciﬁcally, a coalition game (N, V ) is
called monotonic if
V (S) ≤V (T ), ∀S ⊆T ⊆N;
that is, the larger a coalition in terms of set inclusion, the higher the worth of the
coalition. A coalition game (N, V ) is called superadditive if
V (S ∪T ) ≥V (S) + V (T ), ∀S, T ⊆N, S ∩T = ∅;
namely, combining two independent coalitions leads to a higher value. A coalition
game (N, V ) is called convex if
V (S) + V (T ) ≤V (S ∪T ) + V (S ∩T ), ∀S, T ⊆N.
A convex game is also referred to as a supermodular game since v is supermodular
as a set function. One can show that a game (N, V ) is convex if and only if
V (S ∪{i}) −V (S) ≤V (T ∪{i}) −V (T ), ∀S ⊆T ⊆N, i ̸∈T ;
(3.3)
that is, the marginal contribution of a player is increasing with respect to set
inclusion. Since V (∅) = 0, a convex game is superadditive.
Given a cooperative game (N, V ), one would like to know how the coalition
value should be distributed among the players. We will introduce several solution
concepts: the core, the nucleolus, and the Shapley value. A solution concept spec-
iﬁes for each game a set of payoﬀvectors in ℜn whose ith components represent
the values allocated to player i, under the assumption that the grand coalition
forms. If the players do not form the grand coalition, we can restrict these solution
concepts to whatever coalitions the players form. In cooperative game theory, most

54
3. Game Theory
solution concepts can be derived from a list of axioms, which stipulate properties
a reasonable allocation should respect. We list some of the properties desirable for
a solution concept σ(N, V ).
• Eﬃciency: Any payoﬀvector x ∈σ(N, V ) is eﬃcient; namely, x(N) = V (N),
or, equivalently, the grand coalition value V (N) is fully allocated, where for
any set S ⊆N and any vector z ∈ℜn, z(S) = 
i∈S zi.
• Individual rationality: Any payoﬀvector x ∈σ(N, V ) is individually rational;
namely, xi ≥V ({i}) for all i ∈N, or, equivalently, no player receives less
than what he can get on his own.
• Group rationality: Any payoﬀvector x ∈σ(N, V ) is group rational; namely,
x(S) ≥V (S) for all S ⊆N, or, equivalently, no group of players receives less
than what the group can get on its own.
• Symmetry: If the marginal contributions of two players i and j are the same
for all S ⊆N \ {i, j}, then any payoﬀvector x ∈σ(N, V ) should assign the
same value to i and j; that is, xi = xj.
• Anonymity: For a game (N, V ) and any permutation π of N,
σ(N, V π) = {xπ : x ∈σ(N, V )},
where V π(S) = V ({π(i)}i∈S) and for any x ∈ℜn, xπ is a vector such that
xπ
i = xπ(i). That is, the names of the players would not aﬀect their payoﬀs.
• Superadditivity: Given two games (N, V ) and (N, V ′), σ(N, V )+σ(N, V ′) ⊆
σ(N, V + V ′), where (N, V + V ′) is a game whose characteristic function is
the sum of those of (N, V ) and (N, V ′).
• Additivity: Given two games (N, V ) and (N, V ′), σ(N, V + V ′) = σ(N, V ) +
σ(N, V ′).
• Covariance under strategic equivalence: Given a game (N, V ), a scalar α > 0
and β ∈ℜn, σ(N, αV + β) = ασ(N, V ) + β, where in the game (N, αV + β),
for any S ⊆N, (αv + β)(S) = αV (S) + β(S).
• Null player: For any x ∈σ(N, V ), xi = 0 if player i has zero marginal
contribution added to any S; that is, V (S ∪{i}) = V (S).
The eﬃciency property is sometimes referred to as the Pareto optimality. Group
rationality implies individual rationality. Additivity implies superadditivity and
covariance under strategic equivalence.
Another desirable property for a solution concept is consistency. To present it,
we need to deﬁne reduced games. Given a game (N, V ), for a nonempty set S ⊂N
and a payoﬀvector x ∈ℜn, deﬁne a reduced game (S, Vx,S) as follows: Vx,S(∅) = 0,
Vx,S(S) = V (N) −x(N \ S), and
Vx,S(T ) =
max
T ′⊆N\S V (T ∪T ′) −x(T ′) ∀∅̸= T ⊂S.

3.2 Cooperative Game Theory
55
A solution concept σ(N, V ) is consistent if for any x ∈σ(N, V ), xS ∈σ(S, Vx,S),
where xS = (xi)i∈S. It is called weakly consistent if for any x ∈σ(N, V ) and
1 ≤|S| ≤2, xS ∈σ(S, Vx,S), where |S| is the cardinality of S. The consistency
properties basically say that if a payoﬀis reasonable in the grand coalition, any
coalition should accept that the payoﬀs allocated to them are reasonable.
Here are some monotonicity properties that a solution concept σ(N, V ) may
want to satisfy. Among them, the coalitional monotonicity and strong monotonicity
are deﬁned for a single-valued solution concept. In this case, we simply use σ(N, V )
to denote the payoﬀvector when there is no confusion.
• Aggregate monotonicity: For two games (N, V ) and (N, V ′), if V (N)≥
V ′(N), V (S) = V ′(S) for all S ⊂N, then for any x ∈σ(N, V ′), there
exists y ∈σ(N, V ) such that yi ≥xi for all i ∈N.
• Coalitional monotonicity: For two games (N, V ) and (N, V ′), if V (T )≥
V ′(T ) for some T ⊆N and V (S) = V ′(S) for all S with T ̸= S ⊆N,
then σ(N, V )i ≥σ(N, V ′)i for any i ∈T .
• Strong monotonicity: For two games (N, V ) and (N, V ′) and any i ∈N,
σ(N, V )i ≥σ(N, V ′)i if
V (S ∪{i}) −V (S) ≥V ′(S ∪{i}) −V ′(S) ∀S ⊆N.
In the following, we introduce the concepts of the core, the nucleolus, and the
Shapley value and present their properties.
3.2.1
Core
The core of a game (N, V ), denoted by C(N, V ), is the set of eﬃcient payoﬀvectors
that are group rational. That is,
C(N, V ) = {x ∈ℜn : x(N) = V (N), x(S) ≥V (S) ∀S ⊂N}.
Clearly, the core is a polyhedral set that can be deﬁned by 2n linear inequalities.
A payoﬀvector x in the core, called a core allocation, implies that based on this
allocation x, no group of players has incentive to deviate from the grand coalition
and thus the grand coalition is stable. It also implies that the allocation is fair in
the sense that no group would subsidize its complement since for any S ⊂N,
x(N \ S) = x(N) −x(S) ≤V (N) −V (S);
that is, the payoﬀto the group N \ S is no more than its added value to the grand
coalition. The core is attractive because it satisﬁes several plausible properties.
Theorem 3.2.1 The core C(N, V ) if nonempty satisﬁes the following properties:
(a) eﬃciency, (b) individual rationality, (c) group rationality, (d) anonymity, (e)
superadditivity, (f) covariance under strategic equivalence, (g) null player, (h) con-
sistency, and (i) aggregate monotonicity.

56
3. Game Theory
Proof. We only prove parts (g) and (h). The other parts are straightforward. To
prove part (g), note that for a null player, V (S ∪{i}) = V (S) for any S ⊂N.
Speciﬁcally, V ({i}) = 0 and V (N \ {i}) = V (N). For any x ∈C(N, V ), we have
that xi ≥V ({i}). On the other hand,
xi = x(N) −x(N \ {i}) ≤V (N) −V (N \ {i}) = 0.
Thus, xi = 0.
We now show that the core is consistent. To see this, let x ∈C(N, V ). For any
nonempty sets S ⊂N and T ⊂S, xS(S) = x(N) −x(N \ S) = Vx,S(S), and there
exists T ′ ⊆N \ S such that
Vx,S(T ) = V (T ∪T ′) −x(T ′) = V (T ∪T ′) −x(T ∪T ′) + x(T ) ≤xS(T ).
Thus, xS is in the core of the reduced game (S, Vx,S).
Unfortunately, the core of a game may be empty, and even if it is nonempty,
ﬁnding an allocation in the core is usually computationally challenging. In fact,
determining whether a given vector is in the core or not can be challenging as well
since the core is deﬁned by an exponential number (in n) of linear inequalities.
In the following, we present a suﬃcient and necessary condition for the existence
of a nonempty core credited to Bondareva (1963) and Shapley (1967). For this
purpose, deﬁne for any S ⊆N, the characteristic vector χS as a vector in ℜn with
χi
S =

1, if i ∈S
0, if i ̸∈S.
A collection B of subsets of N is called balanced if there exist positive numbers
δS, S ∈B, such that

S∈B
δSχS = χN.
The collection {δS}S∈B is called a system of balancing weights associated with
B. A game is called balanced if for any balanced collection B and any associated
system of balancing weights {δS}S∈B,

S∈B
δSV (S) ≤V (N).
Theorem 3.2.2 (The Bondareva–Shapley theorem) A cooperative coalitional
game (N, V ) has a nonempty core if and only if it is balanced.
Proof. Notice that the core of (N, V ) is nonempty if and only if V (N) is the optimal
objective value of the linear program
max
x(N)
s.t.
x(S) ≥V (S), ∀S ⊆N.

3.2 Cooperative Game Theory
57
Let y(S) be the dual variable associated with the inequality indexed by S. The
dual of the above linear program is
min

S⊆N V (S)y(S)
s.t.

S:i∈S y(S) = 1, ∀i ∈N,
y(S) ≥0.
Since V (N) is the objective value of the dual for the feasible solution {y0(S)}S⊆N
with y0(N) = 1 and y0(S) = 0 for S ⊂N, from the strong duality theorem, the
core is nonempty if and only if for any feasible solution {y(S)}S⊆N of the dual,
V (N) ≤

S⊆N
V (S)y(S).
For any feasible solution {y(S)}S⊆N of the dual, we can deﬁne a balanced collec-
tion B = {S : y(S) > 0} and its associated system of balanced weights δS = y(S)
for S ∈B. On the other hand, any system of balancing weights {δS}S∈B associated
with a balanced collection B can be extended to be a feasible solution {y(S)}S⊆N
for the dual by deﬁning y(S) = δS if S ∈B and 0 otherwise. Therefore, the core
is nonempty if and only if for any balanced collection B and its associated system
of balancing weights {δS}S∈B,
V (N) ≤

S⊆N
V (S)y(S) =

S∈B
δSV (S);
that is, the game is balanced.
Though general cooperative games may have empty cores, the core of a convex
game is always nonempty and has a nice characterization. We will show that the
following greedy algorithm will construct an extreme point of the core. Given a
permutation π of {1, 2, . . ., n}, let Sπ
i = {j : π(j) ≤i} for any i = 1, . . . , n and
Sπ
0 = ∅. Deﬁne for i = 1, . . . , N,
xπ
π(i) = V (Sπ
i ) −V (Sπ
i−1);
that is, the payoﬀthe greedy algorithm assigns to player π(i) is the marginal
contribution added to the players in Sπ
i−1.
Theorem 3.2.3 For a convex game (N, V ), the set of extreme points of the core
is exactly {xπ : π is a permutation}.
Proof. It is suﬃcient to prove that the payoﬀvector, denoted as x∗, associated
with the identity permutation π with π(i) = i for any i ∈N is an extreme point
of the core. According to its deﬁnition, for i ∈N,
x∗
i = V (Si) −V (Si−1), ∀i ∈N,
and x = (x1, . . . , xn), where Si = {1, 2, . . ., i}.

58
3. Game Theory
We ﬁrst show that x∗is in the core. Notice that
x∗(N) =

i∈N
(V (Si) −V (Si−1)) = V (N).
For any S ⊂N, let S = {i1, . . . , ik} with i1 < i2 . . . < ik, and deﬁne for any j ≤k,
ˆSj = {i1, . . . , ij}. We have for any j = 1, . . . , k,
x∗
ij
=
V (Sij) −V (Sij−1)
=
V (Sij−1 ∪{ij}) −V (Sij−1)
≥
V ({Sij−1 ∩S} ∪{ij}) −V (Sij−1 ∩S)
=
V ( ˆSj) −V ( ˆSj−1),
where the inequality follows from the supermodularity of the characteristic func-
tion V . Therefore,
x∗(S) =
k

j=1
x∗
ij ≥
k

j=1
(V ( ˆSj) −V ( ˆSj−1)) = V (S),
which implies that x is in the core.
To show that x∗is an extreme point of the core, consider the following opti-
mization problem:
min

i∈N fixi
s.t.
x ∈C(N, V ),
(3.4)
where f = (f1, . . . , fn) is a given vector in ℜn with f1 > f2 > . . . > fn. It suﬃces
to show that x∗is a unique optimal solution of the above optimization problem.
For this purpose, note that for any given payoﬀvector x in the core,

i∈N fixi
=

i∈N fi(x(Si) −x(Si−1))
=

i∈N\{n}(fi −fi−1)x(Si) + fnx(Sn)
≥

i∈N\{n}(fi −fi−1)V (Si) + fnV (N)
=

i∈N fi(V (Si) −V (Si−1))
=

i∈N fix∗
i ,
where the inequality holds since x ∈C(N, V ), and the last inequality follows from
the deﬁnition of x∗. Since fi is strictly decreasing in i, the inequality would hold
as a strict inequality if x(Si) ̸= V (Si) for some i ∈N \ {n}. If x(Si) = V (Si) for
all i ∈N, x = x∗. Hence, x∗is the unique optimal solution of problem (3.4) and
therefore an extreme point of the core.
To show that no extreme point exists other than those in {xπ
: π is a
permutation}, it suﬃces to show that for any given vector f, the optimization
problem (3.4) has an optimal solution in {xπ : π is a permutation}. In fact, with-
out loss of generality, assume that
f1 ≥f2 ≥. . . ≥fn.
Following an analysis similar the one in the above paragraph, we can show that
x∗is optimal to problem (3.4).

3.2 Cooperative Game Theory
59
Of course, it is possible that xπ = xπ′ for diﬀerent permutations π and π′.
However, if the characteristic function V is strictly supermodular, namely,
V (S) + V (T ) < V (S ∪T ) + V (S ∩T ) ∀S, T ⊆N with S ̸⊆T, T ̸⊆S,
then one can show that xπ ̸= xπ′ (see Exercise 3.5).
For cooperative games with empty cores, an alternative solution concept is the
ϵ-core. For a given real number ϵ, the ϵ-core Cϵ of a game (N, V ) is given as
Cϵ = {x ∈ℜn : x(N) = V (N), x(S) ≥V (S) −ϵ ∀∅̸= S ⊂N}.
That is, a payoﬀvector x is in the ϵ-core if it is eﬃcient and a group of players
won’t be better oﬀif it deviates from the grand coalition to form a subcoalition
by paying a cost ϵ. Clearly, Cϵ ⊆Cϵ′ if ϵ ≤ϵ′ and Cϵ is nonempty for large ϵ.
The least-core of a game (N, V ) is deﬁned as the intersection of all nonempty
ϵ-cores of (N, V ), or equivalently Cϵ0, where ϵ0 is the smallest ϵ such that Cϵ is
nonempty.
3.2.2
Nucleolus
As shown in the previous subsection, the core may be empty and even if nonempty,
it may not be unique. In contrast, the nucleolus exists and is unique. Since the
nucleolus is a singleton, it is often referred to as the unique element in it. To
present its deﬁnition, we ﬁrst deﬁne the lexicographic order. A vector x ∈ℜn is
smaller than a vector y ∈ℜn in the lexicographic order if there exists an index
k ∈{1, . . . , n −1} such that
xi = yi ∀i ≤k, xk+1 < yk+1.
We use x <lex y and x ≤lex y if x is smaller than y and x is smaller than or equal
to y in the lexicographic order, respectively. Consider a game (N, V ). For a given
payoﬀvector x ∈ℜn, deﬁne the excess of coalition S under payoﬀx as
ex(S) = V (S) −x(S) ∀∅̸= S ⊂N,
which is the diﬀerence of the value of and the proposed payoﬀto coalition S. Let
θ(ex) be a vector in ℜ2n−2 whose components consist of the excesses ex(S) in
decreasing order. That is, its ﬁrst element is the largest ex(S), its second compo-
nent is the second-largest ex(S), and so on. It is straightforward to show that for
i = 1, . . . , 2n −2, θi(ex) is a continuous function of x. In addition, if x is in the
core of (N, V ), then θi(ex) ≤0 for all i = 1, . . . , 2n −2.
The nucleolus of the game (N, V ), denoted by N(N, V ), consists of optimal solu-
tions minimizing θ(ex) over all eﬃcient payoﬀvectors in terms of the lexicographic
order. That is, given a payoﬀvector x ∈N(N, V ),
θ(ex) ≤lex θ(ey) for any eﬃcient payoﬀvector y.
One can argue that the nucleolus is the most equitable allocation because it se-
quentially minimizes the excess of the worst-treated coalitions.

60
3. Game Theory
Theorem 3.2.4 For a given game (N, V ), we have the following:
(a) The nucleolus N(N, V ) is always nonempty and is a singleton.
(b) If (N, V ) is superadditive, the nucleolus is individually rational.
(c) The nucleolus belongs to the core if the core is nonempty.
Proof. To prove part (a), we ﬁrst describe a procedure to ﬁnd an element of the
nucleolus. Given any eﬃcient payoﬀvector y0, let
δ = max
∅̸=S⊂N ey0(S).
To search for the nucleolus, it suﬃces to focus on payoﬀvectors in the set
I0 = {y ∈ℜn : y(N) = y0(N), yi ≥V ({i}) −δ},
which is nonempty since y0 ∈I0 and compact. Since θi(θy) is continuous in y, for
i = 1, . . . , 2n −2, we can recursively show that
Ii = argminy∈Ii−1θi(ey)
is nonempty and compact as well. The set I2n−2 is exactly the nucleolus, which is
clearly nonempty.
We now show that the nucleolus is a singleton. Assume to the contrary that
x, y ∈I2n−2 with x ̸= y. The above procedure implies that θ(ex) = θ(ey). Let
S1, S2, . . . , S2n−2 be an ordered sequence of all nonempty proper subsets of N so
that θi(ex) = ex(Si) and let k be the smallest index such that θk(ey) ̸= ey(Sk).
We assume that
either ex(Sl) < ex(Sk) or ey(Sl) < θk(ey) = ex(Sk) ∀l > k.
This assumption can be made without loss of generality. In fact, if the assumption
does not hold, there exists l with l > k such that ex(Sl) = ex(Sk) = ey(Sl). We can
simply consider a new sequence in which the positions of Sk and Sl are switched.
Repeat the process until we end up with a sequence satisfying the assumption.
Deﬁne z = x+y
2 . For any l ≤k, since ex(Sl) = ey(Sl), we have that θl(z) =
θl(x) = ez(Sl), and for any l ≥k,
ez(Sl) = (ex(Sl) + ey(Sl))/2 < ex(Sk) = θk(ex).
Therefore, θk(ez) < θk(ex), which contradicts the assumption that x has the min-
imum θk(ex) in terms of the lexicographic order. Thus, the nucleolus is unique.
To prove part (b), let x be the nucleolus and i ∈argmaxj∈N(V ({j}) −xj).
Assume to the contrary that V ({i}) > xi. We claim i ∈S for any S ⊂N such
that θ1(ex) = ex(S); that is, S ∈argmax ˆSex( ˆS). In fact, if i ̸∈S, from the
superadditive property of V , ex is superadditive and

3.2 Cooperative Game Theory
61
ex(S ∪{i}) ≥ex(S) + ex({i}) = ex(S) + V ({i}) −xi > ex(S),
which contradicts the deﬁnition of S.
Deﬁne a new payoﬀvector y such that yi = xi + ϵ and yj = xj −
ϵ
n−1 for j ̸= i
for some small ϵ > 0. Pick any S ∈argmax ˆSex( ˆS). Since i ∈S, we have that
ey(S) = ex(S) −ϵn −|S|
n −1 < ex(S) = θ1(ex).
For any ˆS with ex( ˆS) < θ1(ex), as long as ϵ is suﬃciently small, y(S) −x(S) is
small and
ey( ˆS) = ex( ˆS) −(y( ˆS) −x( ˆS)) < θ1(ex) −ϵn −|S|
n −1 = ey(S).
Thus, S ∈argmax ˆSex( ˆS) or, equivalently, ey(S) = θ1(ey). However, θ1(ey)
< θ1(ex), which contradicts the deﬁnition of the nucleolus. Thus, the nucleolus
is individually rational.
Finally, if the core is nonempty, pick any core allocation z. Again, let x be the
nucleolus. By deﬁnition,
V (S) −x(S) = ex(S) ≤θ1(ex) ≤θ1(ez) ≤0 ∀∅̸= S ⊂N.
Thus, the nucleolus is in the core.
Loosely speaking, if the core is nonempty, its nucleolus occupies a center position
in the sense that the minimum distance to any boundary of the core is as large as
possible.
In addition to what we proved in the above theorem, the nucleolus satisﬁes the
following properties.
Theorem 3.2.5 The nucleolus N(N, V ) satisﬁes the following properties: (a) ef-
ﬁciency, (b) anonymity, (c) symmetry, (d) covariance under strategic equivalence,
(e) null player, and (f) consistency.
Parts (a) and (b) of the above theorem are obvious. However, the proof of the
remaining parts is involved and is left as an exercise.
3.2.3
Shapley Value
The Shapley value is another single-valued solution concept. For a cooperative
game (N, V ), the Shapley value φ ∈ℜn is given by
φi =

S⊆N\{i}
|S|!(n −|S| −1)!
n!
(V (S ∪{i}) −V (S)) ∀i ∈N.
The Shapley value can be interpreted as follows. The players arrive one by one
to form the grand coalition, and all possible arrival sequences are equally likely.

62
3. Game Theory
When Player i arrives and ﬁnds a set of players S has arrived, he receives a payoﬀ
V (S ∪{i}) −V (S), his marginal contribution added to S. The Shapley value of
Player i is his expected marginal contribution. To see this, note that there are n!
diﬀerent arrival sequences in total and each arrival sequence, corresponding to a
permutation of {1, 2, . . ., n}, is equally likely. In addition, the number of diﬀerent
arrival sequences in which the players in S are exactly those who arrive before i is
|S|!(n −|S| −1)!, the product of the number of diﬀerent arrival sequences of the
ﬁrst |S| players before i and that of the remaining n −|S| −1 players after i.
The Shapley value is widely used because it is unique and enjoy several plausible
properties.
Theorem 3.2.6 The Shapley value satisﬁes the following properties: (a) eﬃciency,
(b) symmetry, (c) anonymity, (d) additivity, (e) null player, (f) (strong) aggregate
monotonicity, (g) coalitional monotonicity, and (h) strong monotonicity.
To show that the Shapley value is eﬃcient, recall that the Shapley value of player
i can be interpreted as Player i’s expected marginal contribution added to its
predecessors when any arrival sequence is equally likely. Thus, for any given arrival
sequence, the total marginal contribution added to their predecessors of all players
is exactly V (N). Thus, 
i∈N φi = V (N). It is straightforward to show that the
Shapley value satisﬁes the remaining properties.
Interestingly, the Shapley value is a unique solution concept that satisﬁes the
above properties.
Theorem 3.2.7 The Shapley value is a unique solution concept that satisﬁes the
eﬃciency, symmetry, additivity, and null player properties. It is also a unique
solution concept that satisﬁes the eﬃciency, symmetry, and strong monotonicity
properties.
The proof of the theorem is left as an exercise.
For a convex game, we have shown that for any permutation of {1, 2, . . .,
n}, π, the greedy algorithm gives a payoﬀvector xπ in the core, which is exactly
the vector of marginal contributions added to their predecessors of the players
if the arrival sequence is (π(1), π(2), . . . , π(n)), with p(i) denoting the i arrival.
Therefore, the Shapley value is the convex combination of payoﬀvectors xπ for all
permutations π and thus is in the core. Actually, it is in the center of gravity of
the core since the weights of the payoﬀvectors xπ, the extreme points of the core,
are 1/n!.
Theorem 3.2.8 For a convex game (N, V ), the Shapley value is in the core.
Unfortunately, for a nonconvex game, the Shapley value may not be core allo-
cations even when the core is nonempty.

3.3 Exercises
63
3.3
Exercises
Exercise 3.1. Consider the generalized form of the prisoner’s dilemma in which
the two prisoners’ payoﬀs are speciﬁed in general values (Table 3.4). Find the
TABLE 3.4. The generalized form of the prisoner’s dilemma
Silent
Betray
Silent
A,
A
C,
B
Betray
B,
C
D,
D
equilibria of the game for all possible values of A, B, C, and D.
Exercise
3.2. Consider
a
game
(N, {Si}i∈N, {ui}i∈N).
If
Si
is
one-
dimensional and ui is smooth for all i ∈N, show that the diagonally dominant
conditions (3.1) on the second derivatives of ui are suﬃcient for the best response
operator to be a contraction and thus a unique equilibrium exists. Extend the
diagonal dominance conditions to multidimensional case.
Exercise 3.3. Provide the detailed proof of Theorem 3.1.7.
Exercise 3.4. Prove that a game (N, V ) is convex if and only if (3.3) holds.
Exercise 3.5. Show that for a cooperative game with a strictly supermodular
characteristic function, a diﬀerent permutation π of {1, 2, . . ., n} leads to a diﬀerent
extreme point xπ of its core in Sect. 3.2.1.
Exercise 3.6. Prove that the nucleolus is a unique solution concept for the class
of all cooperative coalitional games that satisﬁes the eﬃciency, consistency, co-
variance under strategic equivalence, and anonymity properties.
Exercise 3.7. Prove Theorem 3.2.5.
Exercise 3.8. Prove Theorem 3.2.7.
Exercise 3.9. Consider the cooperative coalitional game (N, V ) with N={1, 2, 3}
and the characteristic function given by
V (∅) = 0, V ({i}) = 0 ∀i ∈N, V (S) = α ∀|S| = 2, V (N) = 1,
where α is parameter. Compute the core, the nucleolus, and the Shapley value.
Exercise 3.10. Consider the cooperative production game in which k players
collaborate to produce n products using m resources. Assume that player l (l =
1, . . . , n) has a resource vector bl ∈ℜm. One unit of product j (j = 1, . . . , n)

64
3. Game Theory
can be sold at a proﬁt rj and takes aij units of resource i (i = 1, . . . , m) to
produce. To determine how the proﬁt should be distributed among the players if
they decide to cooperate, we can formulate this as a production game (K, V ) with
K = {1, 2, . . ., k} and for any coalition S, V (S) being the maximum proﬁt the
coalition can generate by pooling their resources together. Is the game convex?
Show that it has a nonempty core. Is the Shapley value in the core?

4
Worst-Case Analysis
4.1
Introduction
Since most complicated logistics problems, for example, the bin-packing problem
and the traveling salesman problem, are NP-Hard, it is unlikely that polynomial-
time algorithms will be developed for their optimal solutions. Consequently, a great
deal of work has been devoted to the development and analyses of heuristics.
In this chapter, we demonstrate one important tool, referred to as worst-case
performance analysis, which establishes the maximum deviation from optimality
that can occur for a given heuristic algorithm. We will characterize the worst-
case performance of a variety of algorithms for the bin-packing problem and the
traveling salesman problem. The results obtained here serve as important building
blocks in the analysis of algorithms for vehicle routing problems.
Worst-case eﬀectiveness is essentially measured in two diﬀerent ways. Take a
generic problem, and let I be a particular instance. Let Z∗(I) be the total cost of
the optimal solution, for instance, I. Let ZH(I) be the total cost of the solution
provided by the heuristic H on instance I. Then, the absolute performance ratio
of heuristic H is deﬁned as
RH .= inf

r ≥1 | ZH(I)
Z∗(I) ≤r, for all I

.
This measure, of course, is speciﬁc to the particular problem. The absolute per-
formance ratio is often achieved for very small problem instances. It is therefore
D. Simchi-Levi et al., The Logic of Logistics: Theory, Algorithms, and Applications
for Logistics Management, Springer Series in Operations Research and Financial Engineering,
DOI 10.1007/978-1-4614-9149-1 4, © Springer Science+Business Media New York 2014
65

66
4. Worst-Case Analysis
desirable to have a measure that takes into account problems of large size only.
This measure is the asymptotic performance ratio. For a heuristic H, this ratio is
deﬁned as
RH
∞
.= inf

r ≥1 | ∃n such that ZH(I)
Z∗(I) ≤r, for all I with Z∗(I) ≥n

.
This measure sometimes gives a more accurate picture of a heuristic’s performance.
Note that RH
∞≤RH.
In general, it is important also to show that no better worst-case bound (for a
given heuristic) is possible. This is usually achieved by providing an example, or
family of examples, where the bound is tight, or arbitrarily close to tight.
In this chapter, we will analyze several heuristics for two diﬃcult problems,
the bin-packing problem and the traveling salesman problem, along with their
worst-case performance bounds.
4.2
The Bin-Packing Problem
The bin-packing problem (BPP) can be stated as follows: Given a list of n real
numbers L = (w1, w2, . . . , wn), where we call wi ∈(0, 1] the size of item i, the
problem is to assign each item to a bin such that the sum of the item sizes in a
bin does not exceed 1, while minimizing the number of bins used. For simplicity,
we also use L as a set, but this should cause no confusion. In this case, we write
i ∈L to mean wi ∈L.
Many heuristics have been developed for this problem since the early 1970s.
Some of the more popular ones are ﬁrst-ﬁt (FF), best-ﬁt (BF), ﬁrst-ﬁt decreasing
(FFD), and best-ﬁt decreasing (BFD) analyzed by Johnson et al. (1974). First-
ﬁt and best-ﬁt assign items to bins according to the order they appear in the
list without using any knowledge of subsequent items in the list; these are online
algorithms. First-ﬁt can be described as follows: Place item 1 in bin 1. Suppose we
are packing item j; place item j in the lowest indexed bin whose current content
does not exceed 1−wj. The BF heuristic is similar to FF except that it places item
j in the bin whose current content is the largest but does not exceed 1 −wj. In
contrast to these heuristics, FFD ﬁrst sorts the items in nonincreasing order of their
size and then performs FF. Similarly, BFD ﬁrst sorts the items in nonincreasing
order of their size and then performs BF. These are called oﬄine algorithms.
Let bH(L) be the number of bins produced by a heuristic H on list L. Similarly,
let b∗(L) be the minimum number of bins required to pack the items in list L; that
is, b∗(L) is the optimal solution to the bin-packing problem deﬁned in list L.
The best asymptotic performance bounds for the FF and BF heuristics are given
in Garey et al. (1976), where they show that
bFF(L) ≤
17
10b∗(L)


4.2 The Bin-Packing Problem
67
and
bBF(L) ≤
17
10b∗(L)

.
Here ⌈x⌉is deﬁned as the smallest integer greater than or equal to x.
The best asymptotic performance bounds for FFD and BFD have been obtained
by Baker (1985), who shows that
bFFD(L) ≤11
9 b∗(L) + 3
and
bBFD(L) ≤11
9 b∗(L) + 3.
Johnson et al. (1974) provides instances with arbitrarily large values of b∗(L) such
that the ratios bFF(L)
b∗(L) and bBF(L)
b∗(L) approach 17
10 and instances where bFFD(L)
b∗(L)
and
bBFD(L)
b∗(L)
approach 11
9 . Thus, the maximum deviation from optimality for all lists
that are suﬃciently “large” is no more than 70 % times the minimal number of
bins in the case of FF and BF, and 22.2 % in the case of FFD and BFD.
We now show that by using simple arguments, one can characterize the absolute
performance ratio for each of the four heuristics. We start, however, by demon-
strating that in general we cannot expect to ﬁnd a polynomial-time heuristic with
absolute performance ratio less than 3
2.
Lemma 4.2.1 Suppose there exists a polynomial-time heuristic H for the BPP
with RH < 3/2; then P = NP.
Proof. We show that if such a heuristic exists, then we can solve the NP-Complete
2-partition problem in polynomial time. This problem is deﬁned as follows: Given
a set A = {a1, a2, . . . , an}, does there exist an A1 ⊂A such that 
ai∈A1 ai =

ai∈A\A1 ai?
For a given instance A of 2-partition, we construct an instance L of the bin-
packing problem with items sizes ai and bins of capacity 1
2

A ai Observe that if
there exists an A1 such that 
A1 ai = 
A\A1 ai = 1
2

A ai, then the heuristic H
must ﬁnd a solution such that bH(L) = 2. On the other hand, if there is no such
A1 in the 2-partition problem, then the corresponding bin-packing problem has no
solution with fewer than three bins, and hence bH(L) ≥3.
Consequently, to solve the 2-partition problem, apply the heuristic H to the
corresponding bin-packing problem. If bH(L) ≥3, there is no subset A1 with the
desired property. Otherwise, there is one. Since 2-partition is NP-Complete , this
implies P = NP.
Let XF be either FF or BF, and let XFD be either FFD or BFD. In this section,
we prove the following result due to Simchi-Levi (1994).
Theorem 4.2.2 For all lists L,
bXF(L)
b∗(L) ≤7
4

68
4. Worst-Case Analysis
and
bXFD(L)
b∗(L)
≤3
2.
In view of Lemma 4.2.1, it is clear that FFD and BFD have the best possible
absolute performance ratios for the bin-backing problem among all polynomial-
time heuristics. As Garey and Johnson (1979, p. 128) point out, it is easy to
construct examples in which an optimal solution uses two bins while FFD or BFD
uses three bins. Similarly, Johnson et al. give examples in which an optimal solution
uses 10 bins while FF and BF use 17 bins. Thus, the absolute performance ratio
for FFD and BFD is exactly 3
2, while it is at least 1.7 and no more than 7
4 for FF
and BF.
We now deﬁne the following terms, which will be used throughout this section.
An item is called large if its size is (strictly) greater than 0.5; otherwise, it is called
small. Deﬁne a bin to be of type I if it has only small items and of type II if it is
not a type I bin; that is, it has at least one large item in it. A bin is called feasible
if the sum of the item sizes in the bin does not exceed 1. An item is said to ﬁt in a
bin if the bin resulting from the insertion of this item is a feasible bin. In addition,
a bin is said to be opened when an item is placed in a bin that was previously
empty.
4.2.1
First-Fit and Best-Fit
The proof of the worst-case bounds for FF and BF, the ﬁrst part of Theorem 4.2.2,
is based on the following observation. Recall XF = FF or BF.
Lemma 4.2.3 Consider the jth bin opened by XF (j ≥2). Any item that was
assigned to it before it was more than half-full does not ﬁt in any bin opened by
XF prior to bin j.
Proof. The property is clearly true for FF, and in fact holds for any item assigned
to the jth bin, j ≥2, not necessarily to items assigned to it before it was more
than half-full. To prove the property for BF, suppose by contradiction that item i
was assigned to the jth bin before it was more than half-full, and this item ﬁts in
one of the previously opened bins, say the kth bin. Clearly, in that case, i cannot
be the ﬁrst item assigned to the jth bin since BF would not have opened a new
bin if i ﬁts in one of the previously opened bins. Let the levels of bins k and j,
just before the time item i was packed by BF, be αk and αj, and let item h be
the ﬁrst item in bin j. Hence, wh ≤αj ≤1
2 by the hypothesis. Since BF assigns
an item to the bin where it ﬁts with the largest content, and item i would have ﬁt
in bin k, we have αj > αk. Thus, αk < 1
2, meaning that item H would have ﬁt in
bin k, a contradiction.
We use Lemma 4.2.3 to construct a lower bound on the minimum number of
bins. For this purpose, we introduce the following procedure. For a given integer v,
2 ≤v ≤bXF(L), select v bins from those produced by XF. Index the v bins in the

4.2 The Bin-Packing Problem
69
order they are opened, starting with 1 and ending with v. Let Xj be the set of items
assigned by XF to the jth bin before it was more than half-full, j = 1, 2, . . . , v.
Let Sj be the set of items assigned by XF to the jth bin, j = 1, 2, . . ., v. Observe
that Xj ⊆Sj for all j = 1, 2, . . ., v.
Procedure LBBP (Lower-Bound Bin-Packing)
Step 1: Let X′
i = Xi, i = 1, 2, . . . , v.
Step 2: For i = 1 to v −1, do
Let j = max{k : X′
k ̸= ∅}.
If j ≤i, stop.
Else, let u be the smallest item in X′
j.
Set Si ←Si ∪{u} and X′
j ←X′
j\{u}.
In view of Lemma 4.2.3, it is clear that Procedure LBBP generates nonempty
subsets S1, S2, . . . , Sm, for some m ≤v, such that 
i∈Sj wi > 1 for j ≤m−1 and
possibly for j = m. This is true since by Lemma 4.2.3, item u (as deﬁned in the
LBBP procedure), originally assigned to bin j before it was more than half-full,
does not ﬁt in any bin i with i < j. Then the following must hold.
Lemma 4.2.4 max

| v
j=m+1 Xj|, m −1

< v
j=1

i∈Sj wi.
Proof. Since bins 1, 2, . . . , m −1 generated by Procedure LBBP are not feasible,
we have v
j=1

i∈Sj wi > m−1. Note that every item in v
j=m+1 Xj is moved by
Procedure LBBP to exactly one Sj, j = 1, 2, . . . , m−1, and possibly to Sm. Thus,
if Sm is feasible, that is, no (additional) item is assigned by Procedure LBBP to
Sm, then | v
j=m+1 Xj| ≤m−1 < v
j=1

i∈Sj wi. On the other hand, if an item is
assigned by Procedure LBBP to Sm,, then none of the subsets Sj, j = 1, 2, . . . , m,
is feasible, and therefore, m = | v
j=m+1 Xj| < v
j=1

i∈Sj wi.
We are now ready to prove the ﬁrst part of Theorem 4.2.2, that is, establish the
upper bound on the absolute performance ratio of the XF heuristic. Let c be the
number of large items in the list L. Without loss of generality, assume bXF(L) > c
since otherwise the solution produced by XF is optimal. So bXF(L) −c > 0 is the
number of type I bins produced by XF. We consider the following two cases.
Case 1: c is even. In this case, we partition the bins produced by XF into two sets.
The ﬁrst set includes only type I bins, while the second set includes the remaining
bins produced by XF, that is, all the type II bins. Index the bins in the ﬁrst set in
the order they are opened, from 1 to bXF(L) −c. Let v = bXF(L) −c, and apply
Procedure LBBP to the set of type I bins, producing m bins out of which at least
m −1 are infeasible. Then
Lemma 4.2.5 If c is even,
max
 c
2 + m,
2(bXF(L) −m) −3c
2

≤b∗(L).

70
4. Worst-Case Analysis
Proof. Combining Lemma 4.2.4 with the fact that no two large items ﬁt in the
same bin, we have 
i∈L wi > m−1+ c
2. On the other hand, every bin in an optimal
solution is feasible, and therefore, 
i∈L wi ≤b∗(L). Since c is even, m+ c
2 ≤b∗(L).
Since we applied Procedure LBBP only to the type I bins produced by XF, each
one of these bins has at least two items except possibly one that may have only
one item. Hence, 2(bXF(L) −m −c −1) + 1 ≤| v
j=m+1 Xj| and therefore, using
Lemma 4.2.4,
2(bXF(L) −m −c −1) + c
2 + 1 <

i∈L
wi ≤b∗(L)
or
2(bXF(L) −m −c −1) + c
2 + 2 ≤b∗(L).
Rearranging the left-hand side gives the second lower bound.
Theorem 4.2.6 If c is even,
bXF(L) ≤7
4b∗(L).
Proof. From Lemma 4.2.5, we have 2(bXF(L) −m) −3c
2 ≤b∗(L). Hence,
bXF(L) ≤b∗(L)
2
+ 3c
4 + m
= b∗(L)
2
+ (m + c
2) + c
4
≤7
4b∗(L)
since m + c
2, b∗(L) and c are lower bounds.
Case 2: c is odd. In this case, we partition the set of all bins generated by the XF
heuristic in a slightly diﬀerent way. The ﬁrst set of bins, called B1, comprises all
the type I bins except the last type I bin opened by XF. The second set is made
up of the remaining bins; that is, these are all the type II bins together with the
type I bin not included in B1. We now apply Procedure LBBP to the bins in B1
[with v = bXF(L) −c −1], producing m bins out of which at least m −1 bins are
not feasible.
Lemma 4.2.7 If c is odd,
max
 c
2 + m + 1
2,
2(bXF(L) −m) −3c
2 −1
2

≤b∗(L).
Proof. Take one of the type II bins and “match” it with the only type I bin not in
B1; the total weight of these two bins is more than 1. Thus, using Property 4.2.4,

4.2 The Bin-Packing Problem
71
we have c−1
2 +1+(m−1) < 
i∈L wi ≤b∗(L), which proves the ﬁrst lower bound.
To prove the second lower bound, we use the fact that every bin in B1 has at least
two items, and therefore, 2(bXF(L)−m−c−1) ≤| v
j=m+1 Xj|. Using Property 2.2,
we get
2(bXF(L) −m −c −1) + c −1
2
+ 1 <

i∈L
wi ≤b∗(L)
or
2(bXF(L) −m −c −1) + c −1
2
+ 2 ≤b∗(L).
Rearranging the left-hand side gives the second lower bound.
Theorem 4.2.8 If c is odd,
bXF(L) ≤7
4b∗(L) −1
4.
Proof. From Lemma 4.2.7, we have 2(bXF(L) −m) −3c
2 −1
2 ≤b∗(L). Hence,
bXF(L) ≤b∗(L)
2
+ m + 3c
4 + 1
4
= b∗(L)
2
+

m + c
2 + 1
2

+ c
4 −1
4
≤7
4b∗(L) −1
4.
4.2.2
First-Fit Decreasing and Best-Fit Decreasing
The proof of the worst-case bounds for FFD and BFD is based on Lemma 4.2.3.
This lemma states that if a bin produced by these heuristics contains only items
of size at most 1
2, then the ﬁrst two items assigned to the bin cannot ﬁt in any bin
opened prior to it.
Let XFD denote either FFD or BFD. Index the bins produced by XFD in the
order they are opened. We consider three cases. First, suppose bXFD(L) = 3p for
some integer p ≥1. Consider the bin with index 2p + 1. If this bin contains a
large item, we are done since in that case b∗(L) > 2p = 2
3bXFD(L). Otherwise, bins
2p + 1 through 3p must contain at least 2p −1 small items, none of which can ﬁt
in the ﬁrst 2p bins. Hence, the total sum of the item sizes exceeds 2p −1, meaning
that b∗(L) ≥2p = 2
3bXFD(L).
Suppose bXFD(L) = 3p + 1. If bin 2p + 1 contains a large item, we are done.
Otherwise, bins 2p + 1 through 3p + 1 contain at least 2p + 1 small items, none
of which can ﬁt in the ﬁrst 2p bins, implying that the total sum of the item sizes
exceeds 2p and hence b∗(L) ≥2p + 1 > 2
3bXFD(L).

72
4. Worst-Case Analysis
Similarly, suppose bXFD(L) = 3p + 2. If bin 2p + 2 contains a large item, we are
done. Otherwise, bins 2p + 2 through 3p + 2 contain at least 2p + 1 small items,
none of which can ﬁt in the ﬁrst 2p + 1 bins, implying the sum of the item sizes
exceeds 2p + 1, and hence b∗(L) ≥2p + 2 > 2
3bXFD(L).
4.3
The Traveling Salesman Problem
Interesting worst-case results have been obtained for another combinatorial prob-
lem that plays an important role in the analysis of logistics systems: the traveling
salesman problem (TSP). The problem can be deﬁned as follows: Let G = (V, E)
be a complete undirected graph with vertices V , |V | = n, and edges E, and let
dij be the length of edge (i, j). [We use the term length to designate the “cost” of
using edge (i, j). The most general formulation of the TSP allows for completely
arbitrary “lengths,” and, in fact, in many applications the physical distance is
irrelevant and the dij simply represents the cost of sequencing j immediately after
i.] The objective in the TSP is to ﬁnd a tour that visits each vertex exactly once
and whose total length is as small as possible. The problem has been analyzed
extensively in the last three decades; see Lawler et al. (1985) for an excellent sur-
vey and, in particular, the chapter written by Johnson and Papadimitriou (1985),
which includes some of the worst-case results presented here.
We shall examine a variety of heuristics for the TSP and show that, for an
important special case of this problem, heuristics with strong worst-case bounds
exist. We start, however, with a negative result, due to Sahni and Gonzalez (1976),
which states that, in general, ﬁnding a heuristic for the TSP with a constant worst-
case bound is as hard as solving any NP-Complete problem, no matter what the
bound.
To present the result, let I be an instance of the TSP. Let L∗(I) be the length
of the optimal traveling salesman tour through V . Given a heuristic H, let LH(I)
be the length of the tour generated by H.
Theorem 4.3.1 Suppose there exist a polynomial-time heuristic H for the TSP
and a constant RH such that for all instances I,
LH(I)
L∗(I) ≤RH;
then P = NP.
Proof. The proof is in the same spirit as the proof of Lemma 4.2.1. Suppose such
a heuristic exists. We will use it to solve the NP-Complete Hamiltonian cycle
problem in polynomial time. The Hamiltonian cycle problem is deﬁned as follows.
Given a graph G = (V, E), does there exist a simple cycle (a cycle that does not
visit a point more than once) in G that includes all of V ? To answer this question,
we construct an instance I of the TSP and apply H to it; the length of the tour
generated by H will tell us whether G has a Hamiltonian cycle.

4.3 The Traveling Salesman Problem
73
The instance I is deﬁned on a complete graph whose set of vertices is V and
the length of each edge {i, j} is
dij =
 1,
if {i, j} ∈E;
|V |RH,
otherwise.
We distinguish between two cases depending on whether G contains a Hamilto-
nian cycle. If G does not contain a Hamiltonian cycle, then any traveling salesman
tour in I must contain at least one edge with length |V |RH, and hence the length
of the tour generated by H is at least |V |RH + |V | −1.
On the other hand, if G has a Hamiltonian cycle, then I must have a tour of
length |V |. This is true since we can use the Hamiltonian cycle as a traveling
salesman tour for the instance I in which the vertices appear on the traveling
salesman tour in the same order they appear in the Hamiltonian cycle. Thus, if G
has a Hamiltonian cycle, heuristic H applied to I must provide a tour of length no
more than |V |RH.
Consequently, we have a method for solving the Hamiltonian cycle problem:
Apply H to the TSP deﬁned on the instance I. If LH(I) ≤|V |RH, then there
exists a Hamiltonian cycle in G. Otherwise, there is no such cycle in G. Finally,
since H is assumed to be polynomial, we conclude that P = NP.
The theorem thus implies that it is very unlikely that a polynomial-time heuris-
tic for the TSP with a constant absolute worst-case bound exists. However, there
is an important version of the traveling salesman problem that excludes the above
negative result. This is when the distance matrix {dij} satisﬁes the triangle in-
equality assumption.
Deﬁnition 4.3.2 A distance matrix satisﬁes the triangle inequality assumption if
for all i, j, k ∈V , we have dij ≤dik + dkj.
In many logistics environments, the triangle inequality assumption is not a very
restrictive one. It merely states that traveling directly from point (vertex) i to
point (vertex) j is at most the cost of traveling from i to j through the point k.
In the next four sections, we describe and analyze diﬀerent heuristics developed
for the TSP. To simplify the presentation in what follows, we write L∗instead of
L∗(I); this should cause no confusion.
4.3.1
A Minimum Spanning Tree-Based Heuristic
The following algorithm provides a simple example of how a ﬁxed worst-case bound
is possible for the TSP when the distance matrix satisﬁes the triangle inequality
assumption. In this case, the bound is 2; that is, the heuristic provides a solution
with total length at most 100 % above the length of an optimal tour.
A spanning tree of a graph G = (V, E) is a connected subgraph with |V | −1
edges spanning all of V. The cost (or weight) of a tree is the sum of the length of
the edges in the tree. A minimum spanning tree (MST) is a spanning tree with
minimum cost. It is well known and easy to show that a minimum spanning tree

74
4. Worst-Case Analysis
can be found in polynomial time [see, for example, Papadimitriou and Stieglitz
(1982)]. If W ∗denotes the weight (cost) of the minimum spanning tree, then we
must have W ∗≤L∗since deleting any edge from the optimal tour results in a
spanning tree.
The minimum spanning tree can be used to ﬁnd a feasible traveling salesman
tour in polynomial time. The idea is to perform a depth-ﬁrst search [see Aho et al.
(1974)] over the minimum spanning tree and then to do simple improvements on
this solution. Formally, this is done as follows (Johnson and Papadimitriou 1985).
A Minimum Spanning Tree-Based Heuristic
Step 1: Construct a minimum spanning tree and color its edges white, and all
other edges black.
Step 2: Let the current vertex (denoted v) be an arbitrary vertex.
Step 3: If one of the edges adjacent to v in the MST is white, color it black and
proceed to the vertex at the other end of this edge. Else (all edges from
v are black), go back along the edge by which the current vertex was
originally reached.
Step 4: Let this vertex be v. Stop if v is the vertex you started with and all edges
of MST are black. Otherwise, go to step 3.
Observe that the above strategy produces a tour that starts and ends at one
of the vertices and visits all other vertices in the graph covering each arc twice.
This is not a very eﬃcient tour since some vertices may be visited more than once.
To improve on this tour, we can modify the above strategy as follows: Instead of
going back to a visited vertex, we can use a shortcut strategy in which we skip
this vertex, and go directly to the next unvisited vertex. The triangle inequality
assumption implies that the above modiﬁcation will not increase the length of the
tour and, in fact, may reduce it.
Let LMST be the length of the traveling salesman tour generated by the above
strategy. We clearly have
LMST ≤2W ∗≤2L∗,
where the ﬁrst inequality follows since without shortcuts, the length of the tour
is exactly 2W ∗. This proves that the worst-case bound of the algorithm is at
most 2. It remains to verify that the worst-case bound of this heuristic cannot be
improved. For this purpose, consider Fig. 4.1, the example constructed by Johnson
and Papadimitriou (1985). Here, W ∗= n
3 + n
3 (1−ϵ)+2ϵ−1, LMST ≈2n
3 + 2n
3 (1−ϵ),
and L∗= 2n
3 .

4.3 The Traveling Salesman Problem
75
4.3.2
The Nearest-Insertion Heuristic
Before describing this heuristic, we consider the following intuitively appealing
strategy, called the nearest-neighbor heuristic. Given an instance I of the TSP,
start with an arbitrary vertex and ﬁnd the vertex not yet visited that is closest to
the current vertex. Travel to this vertex. Repeat this until all vertices are visited;
then go back to the starting vertex.
Unfortunately, Rosenkrantz et al. (1977) show the existence of a family of in-
stances for the TSP with arbitrary n with the following property. The length of the
tour generated by the nearest-neighbor heuristic on each instance in the family is
O(log n) times the length of the optimal tour. Thus, the nearest-neighbor heuristic
does not have a bounded worst-case performance.
This comes as no surprise since the algorithm obviously suﬀers from one major
weakness. This “greedy” strategy tends to begin well, inserting very short arcs
into the path, but ultimately it ends with arcs that are quite long. For instance,
the last edge added, the one connecting the last node to the starting node, may be
very long due to the fact that at no point does the heuristic consider the location
of the starting vertex and possible ending vertices.
One way to improve the performance of the nearest-neighbor heuristic is pre-
sented in the following variant, called the nearest-insertion (NI) heuristic, devel-
oped and analyzed by Rosenkrantz et al. Informally, the heuristic works as follows:
At each iteration of the heuristic, a Hamiltonian cycle containing a subset of the
vertices is constructed. The heuristic then selects a new vertex not yet in the cycle
that is “closest” in a speciﬁc sense and inserts it between two adjacent vertices in
FIGURE 4.1. An example for the minimum spanning tree-based algorithm with n = 18

76
4. Worst-Case Analysis
the cycle. The process stops when all vertices are in the cycle. Formally, this is
done as follows.
The Nearest-Insertion Heuristic
Step 1: Choose an arbitrary node v and let the cycle C consist of only v.
Step 2: Find a node outside C closest to a node in C; call it k.
Step 3: Find an edge {i, j} in C such that dik + dkj −dij is minimal.
Step 4: Construct a new cycle C by replacing {i, j} with {i, k} and {k, j}.
Step 5: If the current cycle C contains all the vertices, stop. Otherwise, go to
step 2.
Let LNI be the length of the solution obtained by the nearest-insertion heuristic.
Then
Theorem 4.3.3 For all instances of the TSP satisfying the triangle inequality,
LNI ≤2L∗.
We start by proving the following interesting result. Let T be a spanning tree
of G and let W(T ) be the weight (cost) of that tree; that is, W(T ) is the sum of
the length of all edges in the tree T . Then
Lemma 4.3.4 For every spanning tree T ,
LNI ≤2W(T ).
Proof. We prove the lemma by matching each vertex we insert during the execution
of the algorithm with a single edge of the given tree T . To do that, we describe a
procedure that will be carried out in parallel to the nearest-insertion heuristic.
The Dual Nearest-Insertion Procedure
Step 1: Start with a family T of trees that, at ﬁrst, consists of only the tree T .
Step 2: Given k (the vertex selected in step 2 of NI), ﬁnd the unique tree in T
containing k. Let this tree be Tk.
Step 3: Let ℓbe the unique vertex in Tk that is in the current cycle.
Step 4: Let h be the vertex adjacent to ℓon the unique path from ℓto k. Replace
Tk in T with two trees obtained from Tk by deleting edge {ℓ, h}.
Step 5: If T contains n trees, stop. Otherwise, go to step 2.

4.3 The Traveling Salesman Problem
77
The dual nearest-insertion procedure is carried out in parallel to the nearest-
insertion heuristic in the sense that each time step 1 is performed in the latter
procedure, step 1 is performed in the former procedure. Each time step 2 is per-
formed in the latter, step 2 is performed in the former, etc.
Observe that each time step 4 of the dual nearest-insertion procedure is per-
formed, the set of trees T is updated so that each tree in T has exactly one vertex
from the current cycle and each vertex of the current cycle belongs to exactly one
tree. This is true since when edge {ℓ, h} is deleted, two subtrees are constructed,
one containing the vertex ℓand the other containing the vertex k. Edge {ℓ, h} is
the one we associate with the insertion of vertex k.
Let m be the vertex in the current cycle to which vertex k (not in the cycle)
was closest. That is, m is the vertex such that dkm is the smallest among all duv,
where u is in the cycle and v is outside the cycle. Let m + 1 be one of the vertices
on the cycle adjacent to m. Finally, let edge {i, j} be the edge deleted from the
current cycle. Clearly, inserting k into the current cycle increases the length of the
tour by
dik + dkj −dij ≤dmk + dk,m+1 −dm,m+1 ≤2dmk,
where the left-hand inequality holds because of step 3 of the nearest-insertion
heuristic and the right-hand inequality holds in view of the triangle inequality
assumption. Of course, this is true only when the cycle contains at least two
vertices. When it contains exactly one vertex, that is, when the nearest-insertion
algorithm enters step 2 for the ﬁrst time, inserting k into the current cycle increases
the length of the tour by exactly 2dmk.
Since ℓis in the current cycle and h is not, dmk ≤dℓh. Hence, the increase in
the cost of the current cycle is no more than 2dℓh. Finally, since this relationship
holds for every edge of T and the corresponding inserted vertex, we have
LNI ≤2W(T ).
To ﬁnish the proof of Theorem 4.3.3, apply Theorem 4.3.4 with T ∗; thus,
W ∗= W(T ∗) < L∗≤LNI ≤2W(T ∗).
This completes the proof of the theorem.
To see that the bound is tight, consider the example (constructed by Rosenkrantz
et al. 1977) depicted in Fig. 4.2. In this example, the length of every edge connecting
two consecutive vertices on the perimeter is 1 while all other edges have length
2. Thus, the optimal traveling salesman tour visits the vertices according to their
appearance on the circle, and therefore, L∗= n. It is easy to see that the nearest-
insertion heuristic generates the tour depicted in Fig. 4.2b with cost LNI = 2n−2.

78
4. Worst-Case Analysis
FIGURE 4.2. An example for the nearest-insertion algorithm with n = 8
4.3.3
Christoﬁdes’ Heuristic
In 1976, Christoﬁdes presented a very simple algorithm that currently has the
best-known worst-case performance bound for the TSP. To present the algorithm,
we need to state several properties of graphs.
Lemma 4.3.5 Given a graph with at least two vertices, the number of vertices
with odd degree is even.
Deﬁnition 4.3.6 An Eulerian tour is a tour that traverses all edges of a graph
exactly once.
Deﬁnition 4.3.7 An Eulerian graph is a graph that has an Eulerian tour.
Then it is a simple exercise to show the following.
Lemma 4.3.8 A connected graph is Eulerian if and only if the degree of each
vertex is even.
Christoﬁdes’ algorithm starts with a minimum spanning tree. Of course, this
tree (as any other tree) is not Eulerian, since some of the vertices have odd degree.
We can augment the graph (by adding suitably chosen arcs) so that it becomes
Eulerian. In fact, we would like to add a number of arcs connecting odd-degree
vertices so that they then have even degree. To do this, we will ﬁnd a minimum
weight matching among the odd-degree vertices.
Given a graph with an even number of vertices, a matching is a subset of edges
with the property that every vertex is the endpoint of exactly one edge of the sub-
set. In the minimum-weight matching problem, the objective is to ﬁnd a matching
whose total length of all its edges is minimum. This problem can be solved in
O(n3), where n is the number of vertices in the graph [see Lawler (1976)].
Lemma 4.3.5 tells us that the number of vertices with odd degree in the MST is
even. Thus, adding the edges of a matching deﬁned on those odd-degree vertices
clearly increases the degree of each of these vertices by one. The resulting graph
is Eulerian, by Lemma 4.3.8. Of course, to minimize the total cost, we would
like to select the edges of a minimum-weight matching. Finally, the Eulerian tour

4.3 The Traveling Salesman Problem
79
generated is transformed into a traveling salesman tour using shortcuts, similarly
to what was done in the minimum spanning tree-based heuristic of Sect. 4.3.1.
Let LC be the length of the tour generated by Christoﬁdes’ heuristic. We prove
the following:
Theorem 4.3.9 For all instances of the TSP satisfying the triangle inequality,
we have
LC ≤3
2L∗.
Proof. Recall that W ∗.= W(T ∗) is the cost of the MST and let W(M ∗) be the
weight of the minimum-weight matching, that is, the sum of edge lengths of all
edges in the optimal matching. Because of the triangle inequality assumption,
LC ≤W(T ∗) + W(M ∗).
We already know that W(T ∗) ≤L∗. It remains to show that W(M ∗) ≤
1
2L∗.
For this purpose, index the vertices of odd degree in the minimum spanning
tree i1, i2, . . . , i2k according to their appearance on an optimal traveling sales-
man tour. Consider two feasible solutions for the minimum-weight matching prob-
lem deﬁned on these vertices. The ﬁrst matching, denoted M 1, consists of edges
{i1, i2}, {i3, i4}, . . . , {i2k−1, i2k}. The second matching, denoted M 2, consists of
edges {i2, i3}, {i4, i5}, . . . , {i2k, i1}.
We clearly have W(M ∗) ≤
1
2[W(M 1) + W(M 2)]. The triangle inequality as-
sumption tells us that W(M 1)+W(M 2) ≤L∗; see Fig. 4.3. Hence, W(M ∗) ≤1
2L∗
and, consequently,
L∗≤W(T ∗) + W(M ∗) ≤3
2L∗.
As in the two previous heuristics, this bound is tight. Consider the example
depicted in Fig. 4.4 for which L∗= n while LC = n −1 + n−1
2 .
FIGURE 4.3. The matching and the optimal traveling salesman tour

80
4. Worst-Case Analysis
FIGURE 4.4. An example for Christoﬁdes’ algorithm with n = 7
4.3.4
Local Search Heuristics
Some of the oldest and, by far, the most extensively used heuristics developed for
the traveling salesman problem are the so-called k-opt procedures (k ≥2). These
heuristics, part of the extensive class of local search procedures, can be described
as follows. Given a traveling salesman tour through the set of vertices V , say the
sequence
{i1, i2 . . . , iu1, iu2, . . . , iv1, iv2, . . . , in},
an ℓ-exchange is a procedure that replaces ℓedges currently in the tour by ℓ
new edges so that the result is again a traveling salesman tour. For instance, a
2-exchange procedure replaces edges {iu1, iu2} and {iv1, iv2} with {iu1, iv1} and
{iu2, iv2} and results in a new tour:
{i1, i2 . . . , iu1, iv1, iv1−1, . . . , iu2, iv2, iv2+1, . . . , in}.
An improving ℓ-exchange is an ℓ-exchange that results in a tour whose total length
(cost) is smaller than the cost of the original tour.
A k-opt procedure starts from an arbitrary traveling salesman tour and, us-
ing improving ℓ-exchanges, for ℓ≤k, successively generates tours of smaller and
smaller length. The procedure terminates when no improving ℓ-exchange is found
for all ℓ≤k. Let LOPT(k) be the length of the tour generated by a k-opt heuristic,
for k ≥2.
Recently, Chandra et al. (1999) obtained interesting results on the worst-case
performance of the k-opt heuristic. They show
Theorem 4.3.10 For all instances of the TSP satisfying the triangle inequality,
we have
LOPT(2)
L∗
≤4√n.
In addition, there exists an inﬁnitely large family of TSP instances satisfying the
triangle inequality assumption for which
LOPT(2)
L∗
≥1
4
√n.
They also provide a lower bound on the worst-case performance of k-opt for all
k ≥3.

4.4 Exercises
81
Theorem 4.3.11 There exists an inﬁnitely large family of TSP instances satis-
fying the triangle inequality assumption with
LOPT(k)
L∗
≥1
4n
1
2k
for any k ≥2.
Thus, the above results indicate that the worst-case performances of k-opt
heuristics are quite poor. By contrast, many researchers and practitioners have
reported that k-opt heuristics can be highly eﬀective; see, for instance, Golden
and Stewart (1985).
This raises a fundamental dilemma. Although worst-case analysis provides a
rigid guarantee on a heuristic’s performance, it suﬀers from being highly deter-
mined by certain pathological examples. Is there a more appropriate measure to
assess the eﬀectiveness of a particular heuristic, one that would assess the eﬀec-
tiveness on an average or realistic example? We will try to address this question
in the next chapter.
4.4
Exercises
Exercise 4.1.
Prove Lemma 4.3.8.
Exercise 4.2.
The 2-TSP is the problem of designing two tours that together
visit each of the customers and use the same starting point. Show that any algo-
rithm for the TSP can solve this problem as well.
Exercise 4.3.
(Papadimitriou and Stieglitz 1982) Consider the n-city TSP in
which the triangle inequality assumption holds. Let c∗> 0 be the length of an
optimal tour, and let c′ be the length of the second-best tour. Prove (c′ −c∗)/c∗≤
2
n.
Exercise 4.4.
Prove that in every completely connected directed graph (a graph
in which between every pair of vertices there is a directed edge in one of the two
possible directions), there is a directed Hamiltonian path.
Exercise 4.5.
Let ZC be the length of the tour provided by Christoﬁdes’ heuris-
tic, and let Z∗be the length of the optimal tour. Construct an example with
ZC = 3
2Z∗.
Exercise 4.6.
Prove that for any graph G, there exists an even number of nodes
with odd degree.

82
4. Worst-Case Analysis
Exercise 4.7.
Let G be a tree with n ≥2 nodes. Show that
(a) There exist at least two nodes with degree 1.
(b) The number of arcs is n −1.
Exercise 4.8.
Consider the n-city TSP deﬁned with distances dij. Assume that
there exist a, b ∈IRn such that for each i and j, dij = ai + bj. What is the length
of the optimal traveling salesman tour? Explain your solution.
Exercise 4.9.
Consider the TSP with the triangle inequality assumption and
two prespeciﬁed nodes s and t. Assume that the traveling salesman tour has to
include edge (s, t) (that is, the salesman has to travel from s directly to t). Modify
Christoﬁdes’ heuristic for this model and show that the worst-case bound is 3
2.
Exercise 4.10.
Show that a minimum spanning tree T satisﬁes the following
property. When T is compared with any other spanning tree T ′, the kth-shortest
edge of T is no longer than the kth-shortest edge of T ′, for k = 1, 2, . . ., n −1.
Exercise 4.11.
(Papadimitriou and Stieglitz 1982) The wandering salesman
problem (WSP) is a traveling salesman problem except that the salesman can
start wherever he or she wishes and does not have to return to the starting city
after visiting all cities.
(a) Describe a heuristic for the WSP with worst-case bound 3
2.
(b) Show that the same bound can be obtained for the problem when one of the
endpoints of the path is speciﬁed in advance.
Exercise 4.12.
(Papadimitriou and Stieglitz 1982) Which of the following prob-
lems remain essentially unchanged (complexity-wise) when they are transformed
from minimization to maximization problems? Why?
(a) Traveling salesman problem
(b) Shortest path from s to t
(c) Minimum-weight matching
(d) Minimum spanning tree
Exercise 4.13.
Suppose there are n jobs that require processing on m machines.
Each job must be processed by machine 1, then by machine 2, . . . , and ﬁnally by
machine m. Each machine can work on at most one job at a time, and once it
begins work on a job it must work on it until completion, without interruption.
The amount of time machine j must process job i is denoted pij ≥0 (for i =
1, 2, . . ., n and j = 1, 2, . . . , m). Further suppose that once the processing of a job
is completed on machine j, its processing must begin immediately on machine j+1
(for j ≤m −1). This is a ﬂow shop with no wait-in-process.

4.4 Exercises
83
Show that the problem of sequencing the jobs so that the last job is completed
as early as possible can be formulated as an (n + 1)-city TSP. Speciﬁcally, show
how the dij values for the TSP can be expressed in terms of the pij values.
Exercise 4.14.
Consider the bin-packing problem with items of size wi, i =
1, 2, . . ., n, such that 0 < wi ≤1. The objective is to ﬁnd the minimum number
of unit-size bins b∗needed to pack all the items without violating the capacity
constraint.
(a) Show that n
i=1 wi is a lower bound on b∗.
(b) Deﬁne a locally optimal solution to be one where no two bins can be feasibly
combined into one. Show that any locally optimal solution uses no more than
twice the minimum number of bins, that is, no more than 2b∗bins.
(c) The next-ﬁt heuristic is the following. Start by packing the ﬁrst item in bin
1. Then each subsequent item is packed in the last-opened bin if possible,
or else a new bin is opened and it is placed there. Show that the next-ﬁt
heuristic produces a solution with at most 2b∗bins.
Exercise 4.15.
(Anily et al. 1994) Consider the bin-packing problem and the
next-ﬁt increasing heuristic. In this strategy, items are ordered in a nondecreasing
order according to their size. Start by packing the ﬁrst item in bin 1. Then each
subsequent item is packed in the last-opened bin if possible, or else a new bin is
opened and it is placed there. Show that the number of bins produced by this
strategy is no more than 7
4 times the optimal number of bins. For this purpose,
consider the following two steps.
(a) Consider the following procedure. First, order the items in nondecreasing
order of their size. When packing bin i ≥1, follow the packing rule: If the
bin is currently feasible (i.e., the total load is no more than 1), then assign
the next item to this bin; otherwise, close this bin, open bin i+1, and put this
item in bin i + 1. Show that the number of bins generated by this procedure
is a lower bound on the minimal number of bins needed.
(b) Relate this lower-bounding procedure to the number of bins produced by the
next-ﬁt increasing heuristic.
Exercise 4.16.
Given a network G = (V, E), and edge length le for every e ∈E,
assume that edge (u, v) has a variable length x. Find an expression for the length
of the shortest path from s to t as a function of x.
Exercise 4.17.
A complete directed network G = (V, A) is a directed graph such
that for every pair of vertices u, v ∈V , there are arcs u →v and v →u in A with
nonnegative arc lengths d(u, v) and d(v, u), respectively. The network G = (V, A)
satisﬁes the triangle inequality if, for all u, v, w ∈V , d(u, v) + d(v, w) ≥d(u, w).

84
4. Worst-Case Analysis
A directed cycle is a sequence of vertices v1 →v2 →· · · →vℓ→v1 without
any repeated vertex other than the ﬁrst and last ones. If the cycle contains all the
vertices in G, then it is said to be a directed Hamiltonian cycle. To keep notation
simple, let dij .= d(vi, vj).
A directed cycle containing exactly k vertices is called a k-cycle. The length of
a cycle is deﬁned as the sum of arc lengths used in the cycle. A directed network
G = (V, A) with |V | ≥k is said to be k-symmetric if, for every k-cycle v1 →v2 →
· · · →vk →v1 in G,
d12 + d23 + · · · + dk−1,k + dk1 = d1k + dk,k−1 + · · · + d32 + d21.
In other words, a k-symmetric network is a directed network in which the length
of every k-cycle remains unchanged if its orientation is reversed.
(a) Show that the asymmetric traveling salesman problem on a |V |-symmetric
network (satisfying the triangle inequality) can be solved via solving a cor-
responding symmetric traveling salesman problem. In particular, show that
any heuristic with a ﬁxed worst-case bound for the symmetric traveling sales-
man problem can be used for the asymmetric traveling salesman problem on
a |V |-symmetric network to obtain a result with the same worst-case bound.
(b) Prove that any 3-symmetric network is k-symmetric for k = 4, 5, . . ., |V |.
Thus, part (a) can be used if we have a 3-symmetric network. Argue that a
3-symmetric network can be identiﬁed in polynomial time.

5
Average-Case Analysis
5.1
Introduction
Worst-case performance analysis is one method of characterizing the eﬀectiveness
of a heuristic. It provides a guarantee on the maximum relative diﬀerence between
the solution generated by the heuristic and the optimal solution for any possible
problem instance, even those that are not likely to appear in practice. Thus, a
heuristic that works well in practice may have a weak worst-case performance,
if, for example, it provides very bad solutions for one (or more) pathological in-
stance(s).
To overcome this important drawback, researchers have recently focused on
probabilistic analysis of algorithms with the objective of characterizing the aver-
age performance of a heuristic under speciﬁc assumptions on the distribution of
the problem data. As pointed out, for example, by Coﬀman and Lueker (1991),
probabilistic analysis is frequently quite diﬃcult and even the analysis of simple
heuristics can often present a substantial challenge. Therefore, usually the anal-
ysis is asymptotic. That is, the average performance of a heuristic can only be
quantiﬁed when the problem size is extremely large.
As we demonstrate in Parts II and IV, an asymptotic probabilistic analysis is
useful for several reasons:
D. Simchi-Levi et al., The Logic of Logistics: Theory, Algorithms, and Applications
for Logistics Management, Springer Series in Operations Research and Financial Engineering,
DOI 10.1007/978-1-4614-9149-1 5, © Springer Science+Business Media New York 2014
85

86
5. Average-Case Analysis
1. It can foster new insights into which algorithmic approaches will be eﬀec-
tive for solving large problems.That is, the analysis provides a framework
where one can analyze and compare the performance of heuristics on large
problems.
2. For problems with fast rates of convergence, the analysis can sometimes
explain the observed empirical behavior of heuristics for more reasonable-
size problems.
3. The approximations derived from the analysis can be used in other models
and may lead to a better understanding of the tradeoﬀs in more complex
problems integrating vehicle routing with other issues important to the ﬁrm,
such as inventory control.
In this chapter, we present some of the basic tools used in the analysis of the
average performance of heuristics. Again, we use the bin-packing problem and the
traveling salesman problem as the “raw materials” on which to present them.
5.2
The Bin-Packing Problem
The bin-packing problem provides a very well-studied example for which to demon-
strate the beneﬁts of a probabilistic analysis.
Without loss of generality, we scale the bin capacity q so that it is 1. Consider
the item sizes w1, w2, w3 . . . to be independently and identically distributed on
(0, 1] according to some general distribution Φ. In this section, we demonstrate two
elegant and powerful techniques that can be used in the analysis of b∗
n, the random
variable representing the optimal solution value on the items w1, w2, . . . , wn. The
ﬁrst is the theory of subadditive processes and the second is the theory of martingale
inequalities.
Subadditive Processes
Let {an}, n ≥1, be a sequence of positive real numbers. We say that the
sequence is subadditive if for all n and m, we have an + am ≥an+m. The following
important result was proved by Kingman (1976) and Steele (1990), whose proof
we follow.
Theorem 5.2.1 If the sequence {an}, n ≥1 is subadditive, then there exists a
constant γ such that
lim
n→∞
an
n = γ.
Proof. Let γ = limn→∞
an
n . For a given ϵ, select n such that an
n ≤γ + ϵ. Since the
sequence {an} is subadditive, we have
anm ≤an + an(m−1).

5.2 The Bin-Packing Problem
87
Making a repeated use of this inequality, we get anm ≤man, which implies
anm
nm ≤γ + ϵ.
For any k, 0 ≤k ≤n, deﬁne ℓ.= nm + k. Using subadditivity again, we have
aℓ= anm+k ≤anm+k−1 + a1
≤anm + ka1
≤anm + na1,
where the second inequality is obtained by repeating the ﬁrst one k times. Thus,
aℓ
ℓ= anm+k
nm + k ≤anm + na1
nm + k
≤anm
nm + a1
m ≤γ + ϵ + a1
m .
Taking the limit with respect to m, we have
lim
ℓ→∞
aℓ
ℓ≤γ + ϵ + lim
m→∞
a1
m = γ + ϵ.
The proof is therefore complete since ϵ was chosen arbitrarily.
It is clear that the optimal solution of the bin-packing problem possesses a
subadditivity-like property; that is, for any sets S, T ⊆N:
b∗(S ∪T ) ≤b∗(S) + b∗(T ),
where b∗(S) denotes the optimal solution to the bin-packing problem on a set
S ⊆N. Using similar arguments as in the above analysis shows that there exists a
constant γ such that the optimal solution to the bin-packing problem b∗
n satisﬁes
lim
n→∞
b∗
n
n = γ
(a.s.).
In addition, γ is dependent only on the item size distribution Φ.
The Uniform Model
To illustrate the concepts just developed, consider the case where Φ is the uni-
form distribution on [0, 1]. In order to pack a set of n items drawn randomly from
this distribution, we use the following sliced interval partitioning heuristic with
parameter r (SIP(r)). It works as follows. For any ﬁxed positive integer r ≥1, the
set of items N is partitioned into the following 2r disjoint subsets, some of which
may be empty:
Nj =

k ∈N
1
2

1 −j + 1
r

< wk ≤1
2

1 −j
r

,
j = 1, 2, . . . , r −1,
and
N j =

k ∈N
1
2

1 + j −1
r

< wk ≤1
2

1 + j
r

,
j = 1, 2, . . ., r −1.

88
5. Average-Case Analysis
Also,
N0 =

k ∈N
1
2

1 −1
r

< wk ≤1
2

and
N r =

k ∈N
1
2

1 + r −1
r

< wk

.
The number of items in each Nj (respectively, N j) is denoted by nj (respectively,
nj) for all possible values of j.
Note that for any j = 1, 2, . . . , r −1, one bin can hold an item from Nj together
with exactly one item from N j. The SIP(r) heuristic generates pairs of items, one
item from Nj and one from N j, for every j = 1, 2, . . . , r −1. The items in N0 ∪N r
are put in individual bins; one bin is assigned to each of these items.
For any j = 1, 2, . . ., r −1, we arbitrarily match one item from Nj with exactly
one item from N j; one bin holds each such pair. If nj = nj, then all the items in
Nj ∪N j are matched. If, however, nj ̸= nj, then we can match exactly min{nj, nj}
pairs of items. The remaining |nj −nj| items in Nj ∪N j that have not yet been
matched are put one per bin. Thus, the total number of bins used is
n0 + nr +
r−1

j=1
max{nj, nj}.
The heuristic clearly generates a feasible solution to the bin-packing problem.
Since
lim
n→∞
nj
n = lim
n→∞
nj
n = 1
2r
(a.s.)
for all j = 1, 2, . . . , r,
we have
γ = lim
n→∞
b∗
n
n ≤lim
n→∞
1
n

n0 + nr +
r−1

j=1
max{nj, nj}

= 1
2 + 1
2r
(a.s.).
Since this holds for any r > 1, we see that γ ≤1
2. Since γ ≥E(w) (see Exercise 5.4),
then γ ≥1
2 and we conclude that γ = 1
2 for the uniform distribution on [0, 1].
Using this idea, we can actually devise an asymptotically optimal heuristic for
instances where the item sizes are uniformly distributed on [0, 1]. To formally
deﬁne this property, let Z∗
n be the cost of the optimal solution to the problem on
a problem of size n, and let ZH
n be the cost of the solution provided by a heuristic
H. Let the relative error of a heuristic H on a particular instance of n points be
eH
n = ZH
n −Z∗
n
Z∗n
.
Deﬁnition 5.2.2 Let Ψ be a probability measure on the set of instances I. A
heuristic H is asymptotically optimal for Ψ if almost surely
lim
n→∞eH
n = 0,
where the problem data are generated randomly from Ψ.

5.2 The Bin-Packing Problem
89
That is, under certain assumptions on the distribution of the data, H generates
solutions whose relative error tends to zero as n, the number of points, tends to
inﬁnity. The above SIP(r) heuristic is not asymptotically optimal since for any
ﬁxed r, the relative error converges to 1
r.
A truly asymptotically optimal heuristic can easily be constructed. The following
heuristic is called MATCH. First, sort the items in nonincreasing order of the item
sizes. Then take the largest item, say item i, and match it with the largest item
with which it will ﬁt. If no such item exists, then put item i in a bin alone.
Otherwise, put item i and the item it was matched with in a bin together. Now
repeat this until all items are packed. The proof of asymptotic optimality is given
as an exercise (Exercise 5.11).
An additional use for the bin-packing constant γ is as an approximation for
the number of bins needed. When n is large, the number of bins required to
pack n random items from Φ is very close to nγ. How close the random variable
representing the number of bins is to nγ is discussed next.
Martingale Inequalities
Consider the stochastic processes {Xn} and {Yn} with n ≥0. We say that the
stochastic process {Xn} is a martingale with respect to {Yn} if, for every n ≥0,
we have
(i) E[Xn] < +∞, and
(ii) E[Xn+1|Y1, . . . , Yn] = Xn.
To get some insight into the deﬁnition of a martingale, consider someone playing
a sequence of fair games. Let Xn = Yn be the amount of money the player has at
the end of the nth game. If {Xn} is a martingale with respect to {Yn}, then this
says that the expected amount of money the player will have at the end of the
(n + 1)st game is equal to what the player had at the beginning of that game Xn,
regardless of the game’s history prior to state n. See Karlin and Taylor (1975) for
details.
Consider now the random variable
Dn .= E[Xn+1|Y1, . . . , Yn] −E[Xn+1|Y1, . . . , Yn−1].
The sequence {Dn} is called a martingale diﬀerence sequence if E[Dn] = 0 for every
n ≥0. Azuma (1967) developed the following interesting inequality for martingale
diﬀerence sequences; see also Stout (1974) or Rhee and Talagrand (1987).
Lemma 5.2.3 Let {Di}, i = 1, 2, . . . , n, be a martingale diﬀerence sequence. Then
for every t > 0, we have
Pr


i≤n
Di
 > t

≤2 exp

−t2/

2

i≤n
||Di||2
∞

,
where ||Di||∞is a uniform upper bound on the Dis.

90
5. Average-Case Analysis
The lemma can be used to establish upper bounds on the probable deviations
of both
• b∗
n from its mean E[b∗
n], and
•
b∗
n
n from its asymptotic value γ.
For this purpose, deﬁne
Di =
 E[b∗
n|w1, . . . , wi] −E[b∗
n|w1, . . . , wi−1],
if i ≥2;
E[b∗
n|w1] −E[b∗
n|∅],
if i = 1,
where E[b∗
n|w1, . . . , wi] is the random variable that represents the expected optimal
solution value of the bin-packing problem obtained by ﬁxing the sizes of the ﬁrst i
items and averaging on all other item sizes. Clearly, E[b∗
n|w1, . . . , wn] = b∗
n, while
E[b∗
n|∅] = E[b∗
n]. Hence, n
i=1 Di = b∗
n −E[b∗
n]. Furthermore, the sequence Di
deﬁnes a martingale diﬀerence sequence with the property that Di ≤1 for every
i ≥1.
Applying Lemma 5.2.3, we obtain the following upper bound:
Pr

|b∗
n −E[b∗
n]| > t

= Pr

n

i=1
Di
 > t

≤2 exp

−t2/(2n)

.
This bound can now be used to construct an upper bound on the likelihood that
b∗
n diﬀers from its asymptotic value by more than some ﬁxed amount.
Theorem 5.2.4 For every ϵ > 0, there exists an integer n0 such that for all
n ≥n0,
Pr
b∗
n
n −γ
 > ϵ

< 2 exp

−nϵ2
2

.
Proof. Theorem 5.2.1 implies that limn→∞E[ b∗
n
n ] = γ, and therefore, for every
ϵ > 0 and k ≥2, there exists n0 such that for all n ≥n0, we have
E
b∗
n
n

−γ
 < ϵ
k .
Consequently,
Pr
b∗
n
n −γ
 > ϵ

≤Pr
b∗
n
n −E[b∗
n]
n
 +
E[b∗
n]
n
−γ
 > ϵ

≤Pr
b∗
n
n −E[b∗
n]
n
 + ϵ
k > ϵ

≤Pr
b∗
n −E[b∗
n]
 > nϵ(k −1)
k

≤2 exp

−nϵ2(k −1)2
2k2

.

5.3 The Traveling Salesman Problem
91
Since this last inequality holds for arbitrary k
≥
2, this completes the
proof.
These results demonstrate that b∗
n is, in fact, very close to nγ, and this is true
for any distribution of the item sizes. Therefore, it suggests that nγ may serve as
a good approximation for b∗
n in other, more complex, combinatorial problems.
5.3
The Traveling Salesman Problem
In this section, we demonstrate an important use for the tools presented above. Our
objective is to show how probabilistic analysis can be used to construct eﬀective
algorithms with certain attractive theoretical properties.
Let x1, x2, . . . , xn be a sequence of points in the Euclidean plane (IR2), and let
L∗
n be the length of the optimal traveling salesman tour through these n points.
We start with a deterministic upper bound on L∗
n developed by Few (1955). We
follow Jaillet’s (1985) presentation.
Theorem 5.3.1 Let a × b be the size of the smallest rectangle that contains
x1, x2 . . . , xn; then
L∗
n ≤

2(n −2)ab + 2(a + b).
Proof. For an integer m (to be determined), partition the rectangle of size a × b
(where a is the length and b is the height) into 2m equal-width horizontal strips.
This creates 2m+1 horizontal lines and two vertical lines (counting the boundaries
of the rectangle). Label the horizontal lines 1, 2, . . . , 2m+1 moving downward. Now
temporarily delete all horizontal lines with an even label. Connect each point xi,
i = 1, 2 . . . , n, with two vertical segments, to the closest (odd-labeled) horizontal
line. A path through x1, . . . , xn can now be constructed by proceeding from, say,
the upper left-hand corner of the a × b rectangle and moving from left to right
on the ﬁrst horizontal line, picking up all points that are connected (with the two
vertical segments) to this line. Then we proceed downward and cover the third
horizontal line from right to left. This continues until we reach the end of the
2m+1st line. This path can be extended to a traveling salesman tour by returning
from the last point to the ﬁrst by adding at most one vertical and one horizontal
line (we avoid diagonal movements for the sake of simplicity). Now repeat this
procedure with the even-labeled horizontal lines and, in a similar manner, create a
path through all the customers. Extend this path to a traveling salesman tour by
adding one horizontal line and one vertical segment of length b −b
m. See Fig. 5.1.
Clearly, the sum of the length of the two traveling salesman tours is
a(2m + 1) + nb
m + 2b + a + 2

b −b
m

.
Since L∗
n is no larger than either of these two tours, we have
L∗
n ≤a + 2b + ma + (n −2) b
2m.

92
5. Average-Case Analysis
FIGURE 5.1. The two traveling salesman tours constructed by the partitioning algorithm
The right-hand side is convex in m; hence, we minimize on m. That is, we choose
m∗=

b(n −2)
2a

;
then
L∗
n ≤a + 2b + m∗a + b(n −2)
2m∗
≤a + 2b + a

b(n −2)
2a
+ 1

+ b(n −2)
2

2a
(n −2)b
=

2(n −2)ab + 2(a + b).
The above result implies that the length of the optimal traveling salesman tour
is at most O(√n). In 1959, Beardwood et al. showed that the rate of growth of L∗,
when customer locations are independent and identically distributed, is Θ(√n).
Speciﬁcally, they prove the following result.
Theorem 5.3.2 Let x1, x2, . . . , xn be a sequence of independent random variables
having a distribution μ with compact support in IR2. Then there exists a constant
β > 0, independent of the distribution μ, such that with probability 1,
lim
n→∞
L∗
n
√n = β

IR2 f 1/2(x)dx,
where f is the density of the absolutely continuous part of the distribution μ.
Since Beardwood et al. proved this result, many researchers have proved it using
a variety of techniques. One of these methods is based on the concept of Euclidean
subadditive processes (Steele 1981), which is a generalization of the concept of
subadditive processes described earlier.
In this subsection, we are not going to prove the result, but rather concentrate on
its algorithmic implications. Speciﬁcally, we will describe the following polynomial-
time algorithm, which is asymptotically optimal. The heuristic was suggested by
Karp (1977) although we have modiﬁed it in several places for the purpose of
clarifying the presentation.

5.3 The Traveling Salesman Problem
93
FIGURE 5.2. Region-partitioning example with n = 17, q = 3, h = 2, and t = 1
A Region-Partitioning Heuristic
In the region-partitioning heuristic, the region containing the points is sub-
divided into subregions such that each nonempty subregion contains exactly q
customers (except possibly for one) and where q is to be determined later. The
heuristic then constructs an optimal traveling salesman tour on the set of points
within or bordering each subregion and then connects these tours to form a trav-
eling salesman tour through all the points.
To generate subregions each with exactly q points, except for possibly one subre-
gion where there may be fewer points, we use the following strategy: The smallest
rectangle with sides a and b containing the set of points x1, x2, . . . , xn is partitioned
by means of horizontal and vertical lines. First, the region is divided by t vertical
lines such that each subregion contains exactly (h + 1)q points except possibly
the last one. This is done precisely as follows: Temporarily index the customers in
increasing order of their horizontal coordinate. Place the vertical lines so that the
jth vertical line (for j ≤t) goes through the customer with index j(h + 1)q. Each
of these t + 1 subregions is then partitioned by means of h horizontal lines into
h + 1 smaller subregions such that each contains exactly q points except possibly
the last one. More precisely, this is done as follows: In each vertical strip, index
the customers in increasing order of their vertical coordinates. Place the horizontal
lines so that the jth horizontal line (for j ≤h) goes through the customer with
index jq. See Fig. 5.2 for an example.
To solve the traveling salesman problems within each subregion, we use a dy-
namic programming algorithm developed by Held and Karp (1962). It ﬁnds an opti-
mal traveling salesman tour through m points in running time, which is O(m22m).
If we choose q = ⌈log n⌉, then solving the traveling salesman problem for a sin-
gle region takes O(n log2 n), and since the number of subregions is no more than
1 + n/ log n, the total time spent solving these traveling salesman problems is
O(n2 log n).

94
5. Average-Case Analysis
FIGURE 5.3. The tour generated by the region-partitioning algorithm
After ﬁnding optimal traveling salesman tours within each subregion, observe
that this collection of traveling salesman tours can be easily transformed into
a single traveling salesman tour through all the points. This is true since this
collection of tours, along with the lines added as above, deﬁnes an Eulerian graph,
where the degree of each point (node) is either two or four (a point that is on the
boundary of two subregions will have degree 4). Thus, this tour can be transformed
into a single traveling salesman tour, and using shortcuts can further reduce its
length. See Fig. 5.3.
To guarantee that each nonempty subregion has exactly q points, except for
maybe one, h and t must satisfy
t =

n
(h + 1)q

−1
and
t(h + 1)q < n ≤(t + 1)(h + 1)q.
This is achieved by choosing h = ⌈

n
q −1⌉.
Let LRP be the length of the tour generated by the above region-partitioning
heuristic. To establish the quality of the heuristic, we need to ﬁnd an upper bound
on LRP; this is provided by the following.
Lemma 5.3.3
LRP ≤L∗+ 3
2P RP,
where P RP is the sum of the perimeters of all subregions generated by the region-
partitioning heuristic.
Proof. Let Lj be the length of the optimal traveling salesman tour in subregion
j = 1, 2, . . . , ⌈n
q ⌉. Similarly, let L∗
j be the sum of the lengths of all segments of the
optimal traveling salesman tour through all n customers that are contained in the
jth subregion, for j ≥1. Since the collection of tours and lines constructed above

5.3 The Traveling Salesman Problem
95
deﬁnes an Eulerian graph, we have LRP ≤
j Lj. Also, by deﬁnition, we have
L∗= 
j L∗
j. Thus, it is suﬃcient to show that
Lj ≤L∗
j + 3
2Pj,
(5.1)
where Pj is the perimeter of subregion j.
To prove inequality (5.1), assume there are exactly k continuous segments S1, . . . ,
Sk, of the globally optimal traveling salesman tour, in subregion j; see Fig. 5.4. Let
the 2k endpoints of these segments be y1, y2, . . . , y2k ordered consecutively around
the boundary of subregion j. Without loss of generality, we assume that
ℓ(y1y2) + ℓ(y3y4) + · · · + ℓ(y2ky2k−1) ≤ℓ(y2y3) + ℓ(y4y5) + · · · + ℓ(y2ky1),
where ℓ(yiyi+1) is the distance between points yi and yi+1 along the perimeter
of the jth subregion. We construct a feasible solution for the traveling salesman
problem deﬁned by the points xi that are in the jth subregion. The tour is based
on (i) the segments S1, . . . , Sk, (ii) two copies of each segment y1y2, y3y4, . . . ,
y2k−1y2k, and (iii) one copy of each segment y2y3, y4y5, . . . , y2ky1.
FIGURE 5.4. The segments S1, . . . , Sk and the corresponding Eulerian graph
Observe (Fig. 5.4) that the above three components deﬁne an Eulerian graph
whose set of vertices is the points xi that belong to the jth subregion plus all the
points yi, for i = 1, 2, . . . , 2k. This implies that the graph has an Eulerian tour
whose cost is no more than
L∗
j + 3
2Pj.

96
5. Average-Case Analysis
This tour can be converted into a traveling salesman tour, using shortcuts, and
therefore,
Lj ≤L∗
j + 3
2Pj.
Summing these up on j completes the proof.
We can now prove the following result due to Karp.
Theorem 5.3.4 Under the conditions of Theorem 5.3.2, with probability 1,
lim
n→∞
L∗
√n = lim
n→∞
LRP
√n .
Proof. Lemma 5.3.3 implies
L∗≤LRP ≤L∗+ 3
2P RP.
Hence, we need to evaluate the quantity P RP. Note that the number of vertical
lines added in the construction of the subregions is t ≤

n
q . Each of these lines is
counted twice in the quantity P RP.
In the second step of the RP heuristic, we add h horizontal lines, where h ≤

n
q .
These horizontal lines are also counted twice in P RP. It follows that
P RP ≤2
n
q (a + b) + 2(a + b) ≤2

n
log n(a + b) + 2(a + b),
where the right-side inequality is justiﬁed by the deﬁnition of q.
Consequently,
LRP
√n ≤L∗
√n + 3
2
P RP
√n
≤L∗
√n + 3(a + b)
√log n + 3(a + b)
√n
.
Taking the limit as n goes to inﬁnity proves the theorem.
5.4
Exercises
Exercise 5.1.
A lower bound on β. Let X(n) = {x1, x2, . . . , xn} be a set of points
uniformly and independently distributed in the unit square. Let ℓj be the distance
from xj ∈X(n) to the nearest point in X(n) \ xj. Let L(X(n)) be the length of
the optimal traveling salesman tour through X(n). Clearly, E(L(X(n))) ≥nE(ℓ1).
We evaluate a lower bound on β in the following way.

5.4 Exercises
97
(a) Find Pr(ℓ1 ≥ℓ).
(b) Use (a) to calculate a lower bound on E(ℓ1) =
 ∞
0
Pr(ℓ1 ≥ℓ)dℓ.
(c) Use Stirling’s formula to approximate the bound when n is large.
(d) Show that 1
2 is a lower bound on β.
Exercise 5.2.
An upper bound on β. (Karp and Steele 1985) The strips method
for constructing a tour through n random points in the unit square dissects the
square into 1
Δ horizontal strips of width Δ, and then follows a zigzag path, visiting
the points in the ﬁrst strip in left-to-right order, then the points in the second strip
in right-to-left order, etc., ﬁnally returning to the initial point from the ﬁnal point
of the last strip. Prove that when Δ is suitably chosen, the expected length of the
tour produced by the strips method is at most 1.16√n.
Exercise 5.3.
Consider the TSP deﬁned on a set of points N indexed 1, 2, . . . , n.
Let Z∗be the length of the optimal tour. Consider now the following strategy:
Starting with point 1, the salesman moves to the closest point in the set N \ {1},
say point 2. The salesman then constructs an optimal traveling salesman tour
deﬁned on this set of n −1 points (N \ {1}) and then returns to point 1 through
point 2. Show that the length of this tour is no larger than 3Z∗/2. Is the bound
tight?
Exercise 5.4.
Prove that the bin-packing constant γ satisﬁes 1 ≤γ/E(w) ≤2,
where E(w) is the expected item size.
Exercise 5.5.
The harmonic heuristic with parameter M, denoted H(M), is the
following. For each k = 1, 2, . . ., M −1, items of size
1
k+1 < wi ≤1
k are packed
separately, at most k items per bin. That is, items of size greater than 1
2 are packed
one per bin, items of size 1
3 < wi ≤1
2 are packed two per bin, and so forth. Finally,
items of size wi ≤
1
M are packed separately from the rest using ﬁrst-ﬁt.
Given n items drawn randomly from the uniform distribution on ( 1
6, 0], what is
the asymptotic number of bins used by H(5)?
Exercise 5.6.
Suggest a method to pack n items drawn randomly from the
uniform distribution on [ 1
3, 1]. Can you prove that your method is asymptotically
optimal? What is the bin-packing constant (γ) for this distribution?
Exercise 5.7.
Suggest a method to pack n items drawn randomly from the
uniform distribution on [0, 5
12]. Can you prove that your method is asymptotically
optimal? What is the bin-packing constant (γ) for this distribution?
Exercise 5.8.
Suggest a method to pack n items drawn randomly from the uni-
form distribution on [ 1
40, 59
120]. Can you prove that your method is asymptotically
optimal? What is the bin-packing constant (γ) for this distribution?

98
5. Average-Case Analysis
Exercise 5.9.
(Dreyfus and Law 1977) The following is a dynamic programming
procedure to solve the TSP. Let city 1 be an arbitrary city. Deﬁne the following
function:
fi(j, S) = the length of the shortest path from city 1 to
city j visiting cities in the set S, where |S| = i.
Determine the recursive formula and solve the following instance.
The distances between cities
dij
1
2
3
4
5
1
0
3
1
5
4
2
1
0
5
4
3
3
5
4
0
2
1
4
3
1
3
0
3
5
5
2
4
1
0
Exercise 5.10.
What is the complexity of the dynamic program developed in
the previous exercise?
Exercise 5.11.
(Coﬀman and Lueker 1991) Consider ﬂipping a fair coin n times
in succession. Let Xn represent the random variable denoting the maximum excess
of the number of heads over tails at any point in the sequence of n ﬂips. It is known
that E(Xn) is Θ(√n). From this, argue that
E[ZMATCH
n
] = n
2 + Θ(√n).
Exercise 5.12.
Assume n cities are uniformly distributed in the unit disc. Con-
sider the following heuristic for the n-city TSP. Let di be the distance from city i
to the depot. Order the points so that d1 ≤d2 ≤· · · ≤dn. For each i = 1, 2, . . . , n,
draw a circle of radius di centered at the depot; call this circle i. Starting at the
depot, travel directly to city 1. From city 1, travel to circle 2 in a direction along
the ray through city 1 and the depot. When circle 2 is reached, follow circle 2 in
the direction (clockwise or counterclockwise) that results in a shorter route to city
2. Repeat this same step until city n is reached; then return to the depot. Let
ZH
n be the length of this traveling salesman tour. What is the asymptotic rate of
growth of ZH
n ? Is this heuristic asymptotically optimal?

6
Mathematical Programming-Based
Bounds
6.1
Introduction
An important method of assessing the eﬀectiveness of any heuristic is to compare
it to the value of a lower bound on the cost of an optimal solution. In many
cases, this is not an easy task; constructing strong lower bounds on the optimal
solution may be as diﬃcult as solving the problem. An attractive approach for
generating a lower bound on the optimal solution to an NP-Complete problem is
the following mathematical programming approach. First, formulate the problem
as an integer program; then relax the integrality constraint and solve the resulting
linear program.
What problems do we encounter when we try to use this approach? One diﬃculty
is deciding on an integer programming formulation. There are myriad possible
formulations from which to choose. Another diﬃculty may be that in order to
formulate the problem as an integer program, a large (sometimes exponential)
number of variables are required. That is, the resulting linear program may be
very large, so that it is not possible to use standard linear programming solvers.
The third problem is that it is not clear how tight the lower bound provided by
the linear relaxation will be. This depends on the problem and the formulation.
In the sections below, we demonstrate how a general class of formulations can
provide tight lower bounds on the original integer program. In later chapters,
we show that these and similar linear programs can be solved eﬀectively and
implemented in algorithms that solve logistics problems to optimality or near
optimality.
D. Simchi-Levi et al., The Logic of Logistics: Theory, Algorithms, and Applications
for Logistics Management, Springer Series in Operations Research and Financial Engineering,
DOI 10.1007/978-1-4614-9149-1 6, © Springer Science+Business Media New York 2014
99

100
6. Mathematical Programming-Based Bounds
6.2
An Asymptotically Tight Linear Program
Again, consider the bin-packing problem. There are many ways to formulate the
problem as an integer program. The one we use here is based on formulating it as
a set-partitioning problem. The idea is as follows. Let F be the collection of all
sets of items that can be feasibly packed into one bin; that is,
F .= {S ⊆N :

i∈S
wi ≤1}.
For any i ∈N and S ∈F, let
αiS =
 1,
if i ∈S,
0,
otherwise.
Let
yS =
 1,
if the set of items S are placed in a single bin,
0,
otherwise.
Then the set-partitioning formulation of the bin-packing problem is the following
integer program: /
Problem P :
Min

S∈F
yS
s.t. 
S∈F
αiSyS = 1,
∀i ∈N,
(6.1)
yS ∈{0, 1},
∀S ∈F.
In this section, we prove that the relative diﬀerence between the optimal solution
of the linear relaxation of Problem P and the optimal solution of Problem P (the
integer solution) tends to zero as |N| = n, the number of items, increases. First,
we need the following deﬁnition.
Deﬁnition 6.2.1 A function φ is Lipschitz continuous of order q on a set A ⊆IR
if there exists a constant K such that
|φ(x) −φ(y)| ≤K|x −y|q, ∀x, y ∈A.
Our ﬁrst result of this section is the following.
Theorem 6.2.2 Let the item sizes be independently and identically distributed
according to a distribution Φ, which is Lipschitz continuous of order q ≥1 on
[0, 1]. Let bLP
n
be the value of the optimal solution to the linear relaxation of P,
and let b∗
n be the value of the optimal integer solution to P, that is, the value of
the optimal solution to the bin-packing problem. Then, with probability 1,
lim
n→∞
1
nbLP
n
= lim
n→∞
1
nb∗
n.

6.2 An Asymptotically Tight Linear Program
101
To prove the theorem, we consider a related model. Consider a discretized bin-
packing problem in which there are a ﬁnite number W of item sizes. Each dif-
ferent size deﬁnes an item type. Let ni be the number of items of type i, for
i = 1, 2, . . ., W, and let n = W
i=1 ni be the total number of items. Clearly,
this discretized bin-packing problem can be solved by formulating it as the set-
partitioning problem P. To obtain some intuition about the linear relaxation of
P, we ﬁrst introduce another formulation closely related to P.
Let a bin assignment be a vector (a1, a2, . . . , aW ), where ai ≥0 are integers, and
such that a single bin can contain a1 items of type 1, along with a2 items of type
2, . . . , along with aW items of type W, without violating the capacity constraint.
Index all the possible bin assignments 1, 2, . . ., R, and note that R is independent
of n. The bin-packing problem can be formulated as follows. Let
Air = number of items of type i in bin assignment r,
for each i = 1, 2, . . ., W and r = 1, 2, . . ., R. Let
yr = number of times bin assignment r is used in the optimal solution.
The new formulation of the discretized bin-packing problem is
Problem PD :
Min
R

r=1
yr
s.t.
R

r=1
yrAir ≥ni,
∀i = 1, 2, . . . , W,
yr ≥0 and integer,
∀r = 1, 2, . . . , R.
Let b∗
D be the value of the optimal solution to Problem PD and let bLP
D be the
optimal solution to the linear relaxation of Problem PD. Clearly, Problem P and
Problem PD have the same optimal solution values; that is, b∗= b∗
D. On the other
hand, bLP is not necessarily equal to bLP
D . However, it is easy to see that any feasible
solution to the linear relaxation of Problem P can be used to construct a feasible
solution to the linear relaxation of Problem PD, and therefore,
bLP ≥bLP
D .
(6.2)
The following is the crucial lemma needed to prove Theorem 6.2.2.
Lemma 6.2.3
bLP ≤b∗≤bLP
D + W ≤bLP + W.
Proof. The leftmost inequality is trivial, while the rightmost inequality is due
to (6.2). To prove the central inequality, note that in Problem PD there are W
constraints, one for each item type. Let yr, for r = 1, 2, . . ., R, be an optimal

102
6. Mathematical Programming-Based Bounds
solution to the linear relaxation of Problem PD and observe that there exists such
an optimal solution with at most W positive variables, one for each constraint.
We construct a feasible solution to Problem PD by rounding the linear solution
up; that is, for each r = 1, 2, . . . , R with yr > 0, we make yr = ⌈yr⌉, and for each
r = 1, 2, . . ., R with yr = 0, we make yr = 0. Hence, the increase in the objective
function is no more than W.
Observe that the upper bound on b∗obtained in Lemma 6.2.3 consists of two
terms. The ﬁrst, bLP, is a lower bound on b∗, which clearly grows with the number
of items n. The second term (W) is independent of n. Therefore, the upper bound
on b∗of Lemma 6.2.3 is dominated by bLP; consequently, we see that for large n,
b∗≈bLP, exactly what is implied by Theorem 6.2.2.
We can now use the intuition developed in the above analysis of the discrete
bin-packing problem to prove Theorem 6.2.2.
Proof. It is clear that bLP ≤b∗, and therefore, limn→∞bLP/n ≤limn→∞
b∗/n. To prove the upper bound, partition the interval (0, 1] into k ≥2 subinter-
vals of equal length. Let Nj be the set of items whose size w satisﬁes j−1
k
< w ≤j
k,
and let |Nj| = nj, j = 1, 2, . . . , k. We construct a new bin-packing problem where
item sizes take only the values
j
k, j = 1, 2, . . . , k −1 and where the number of
items of size j
k is min{nj, nj+1}, j = 1, 2, . . . , k −1. We refer to this instance of
the bin-packing problem as the reduced instance. For this reduced instance, deﬁne
b∗, bLP, and bLP
D to be the obvious quantities.
It is easy to see that we can always construct a feasible solution to the original
bin-packing problem by solving the bin-packing problem deﬁned on the reduced
instance and then assigning each of the remaining items to a single bin. This
results in
b∗≤b∗+
k−1

j=1
|nj −nj+1| + nk
≤bLP
D + k +
k−1

j=1
|nj −nj+1| + nk
(using Lemma 6.2.3)
≤bLP + k +
k−1

j=1
|nj −nj+1| + nk.
We now argue that bLP ≤bLP. This must be true since every item in the reduced
instance can be associated with a unique item in the original instance whose size
is at least as large. Thus, every feasible solution to the linear relaxation of the
set-partitioning problem deﬁned on the original instance is feasible for the same
problem on the reduced instance. Hence,
b∗≤bLP + k +
k−1

j=1
|nj −nj+1| + nk.

6.3 Lagrangian Relaxation
103
The strong law of large numbers and the mean value theorem imply that for a
given j = 1, . . . , k, there exists sj such that
lim
n→∞
nj
n = 1
kφ(sj),
where φ is the density of item sizes. Hence,
lim
n→∞
1
n|nj −nj+1| = 1
k |φ(sj) −φ(sj+1)|
≤1
k K(sj+1 −sj)q
(by Lipschitz continuity)
≤
2
kq+1 K

since sj+1 −sj ≤2
k

≤2
k2 K
(since q ≥1).
Consequently,
lim
n→∞
b∗
n ≤lim
n→∞
bLP
n + K(2k −1)
k2
.
Since this holds for arbitrary k, this completes the proof.
In fact, it appears that the linear relaxation of the set-partitioning formulation
may be extremely close to the optimal solution in the case of the bin-packing
problem. Chan et al. (1998) show that the worst-case eﬀectiveness of the set-
partitioning lower bound (the linear relaxation), that is, the maximum ratio of the
optimal integer solution (b∗) to the optimal linear relaxation bLP, is 4
3. They also
provide an example that achieves this bound. That is, for any number of items
and any set of item weights, the linear program is at least 75 % of the optimal
solution.
6.3
Lagrangian Relaxation
In
1971,
Held
and
Karp
applied
a
mathematical
technique
known
as
Lagrangian relaxation to generate a lower bound on a general integer (linear)
program. Our discussion of the method follows the elegant presentation of Fisher
(1981). We start with the following integer program:
Problem P :
Z = Min
cx
s.t.
Ax = b,
(6.3)
Dx ≤e,
(6.4)
x ≥0 and integer,

104
6. Mathematical Programming-Based Bounds
where x is an n-vector, b is an m-vector, e is a k-vector, A is an m×n matrix, and
D is a k×n matrix. Let the optimal solution to the linear relaxation of Problem P
be ZLP. The Lagrangian relaxation of constraints (6.3) with multipliers u ∈IRm is
Problem LRu :
ZD(u) = Min
cx + u(Ax −b)
s.t.
Dx ≤e,
(6.5)
x ≥0
and integer.
The following is a simple observation.
Lemma 6.3.1 For all u ∈IRm, ZD(u) ≤Z.
Proof. Let x be any feasible solution to Problem P. Clearly, x is also feasible for
LRu, and since ZD(u) is its optimal solution value, we get
ZD(u) ≤cx + u(Ax −b) = cx.
Consequently, ZD(u) ≤Z.
Remark: If the constraints Ax = b in Problem P are replaced with the constraints
Ax ≤b, then Lemma 6.3.1 holds for u ∈IRm
+ .
Since ZD(u) ≤Z holds for all u, we are interested in the vector u that provides
the largest possible lower bound. This is achieved by solving Problem D, called
the Lagrangian dual, deﬁned as follows:
Problem D : ZD = max uZD(u).
Problem D has a number of important and interesting properties.
Lemma 6.3.2 The function ZD(u) is a piecewise linear concave function of u.
This implies that ZD(u) attains its maximum at a nondiﬀerentiable point. This
maximal point can be found using a technique called subgradient optimization,
which can be described as follows: Given an initial vector u0, the method generates
a sequence of vectors {uk} deﬁned by
uk+1 = uk + tk(Axk −b),
(6.6)
where xk is an optimal solution to Problem LRuk and tk is a positive scalar called
the step size. Polyak (1967) shows that if the step sizes t1, t2, . . . , are chosen such
that limk→∞tk = 0 and 
k≥0 tk is unbounded, then ZD(uk) converges to ZD.
The step size commonly used in practice is
tk = λk(UB −ZD(uk))
n
i=1(aixk −bi)2 ,

6.4 Lagrangian Relaxation and the Traveling Salesman Problem
105
where UB is an upper bound on the optimal integer solution value (found using a
heuristic), aixk −bi is the diﬀerence between the left-hand side and the right-hand
side of the ith constraint in Axk ≤b, and λk is a scalar satisfying 0 < λk ≤2.
Usually, one starts with λ0 = 2 and cuts it in half every time ZD(u) fails to increase
after a number of iterations.
It is now interesting to compare the Lagrangian relaxation lower bound (ZD) to
the lower bound achieved by solving the linear relaxation of the set-partitioning
formulation (ZLP).
Theorem 6.3.3
ZLP ≤ZD.
Proof.
ZD = max
u

min
x cx + u(Ax −b)
Dx ≤e, x ≥0 and integer

≥max
u

min
x cx + u(Ax −b)
Dx ≤e, x ≥0

= max
u
max
v

ve −ub
vD ≤c + uA, v ≤0

(by strong duality)
= max
u,v

ve −ub
vD ≤c + uA, v ≤0

= min
y

cy
Ay = b, Dy ≤e, y ≥0

(by strong duality)
= ZLP.
We say a mathematical Program P possesses the integrality property if the solu-
tion to the linear relaxation of P always provides an integer solution. An inspection
of the above proof reveals the following corollary.
Corollary 6.3.4 If Problem LRu possesses the integrality property, then ZD=ZLP.
6.4
Lagrangian Relaxation and the Traveling Salesman
Problem
Held and Karp (1970, 1971) developed the Lagrangian relaxation technique in the
context of the traveling salesman problem. They show some interesting relation-
ships between this method and a graph-theoretic problem called the minimum-
weight 1-tree problem.

106
6. Mathematical Programming-Based Bounds
6.4.1
The 1-Tree Lower Bound
We start by deﬁning a 1-tree. For a given choice of vertex, say vertex 1, a 1-tree is
a tree having vertex set {2, 3, . . ., n} together with two distinct edges connected to
vertex 1. Therefore, a 1-tree is a graph with exactly one cycle. Deﬁne the weight of
a 1-tree to be the sum of the costs of all its edges. In the minimum-weight 1-tree
problem, the objective is to ﬁnd a 1-tree of minimum weight. Such a 1-tree can be
constructed by ﬁnding a minimum spanning tree on the entire network excluding
vertex 1 and its corresponding edges and by adding to the minimum spanning tree
the two edges incident to vertex 1 of minimum cost.
We observe that any traveling salesman tour is a 1-tree tour in which each
vertex has a degree 2. Moreover, if a minimum-weight 1-tree is a tour, then it is
an optimal traveling salesman tour. Thus, the minimum-weight 1-tree provides a
lower bound on the length of the optimal traveling salesman tour.
Unfortunately, this bound can be quite weak. However, there are ways to improve
it. For this purpose, consider the vector π = {π1, π2, . . . , πn} and the following
transformation of the distances {dij}:
d′
ij
.= dij + πi + πj.
Let L∗be the length of the optimal tour with respect to the distance matrix
{dij}. It is clear that the same tour is also optimal with respect to the distance
matrix {d′
ij}. To see that, observe that any traveling salesman tour S of cost L
with respect to {dij} has a cost L + 2 n
i=1 πi with respect to {d′
ij}. Thus, the
diﬀerence between the length of any traveling salesman tour in {dij} and {d′
ij} is
constant, independent of the tour.
Observe also that the above transformation of the distances does change the
minimum 1-tree. How can this idea be used? First, enumerate all possible 1-trees
and let dk
i be the degree of vertex i in the kth 1-tree. Let Tk be the weight (cost)
of that 1-tree (before transforming the distances). This implies that the cost of
that 1-tree after the transformation is exactly
Tk +

i∈V
dk
i πi.
Thus, the minimum-weight 1-tree on the transformed distance matrix is obtained
by solving
min
k

Tk +

i∈V
dk
i πi

.
Since, in the transformed distance matrix, the optimal traveling salesman tour
does not change while the 1-tree provides a lower bound, we have
L∗+ 2

i∈V
πi ≥min
k

Tk +

i∈V
dk
i πi

,
which implies
L∗≥min
k

Tk +

i∈V
(dk
i −2)πi
 .= w(π).

6.4 Lagrangian Relaxation and the Traveling Salesman Problem
107
Consequently, the best lower bound is obtained by maximizing the function w(π)
over all possible values of π. How can we ﬁnd the best value of π? Held and Karp
(1970, 1971) use the subgradient method described in the previous section. That
is, starting with some arbitrary vector π0, in step k the method updates the vector
πk according to
πk+1
i
= πk
i + tk(dk
i −2),
where πk
i is the ith element in the vector πk, and tk, the step size, equals
tk = λk(UB −w(πk))
n
i=1(dk
i −2)2 .
6.4.2
The 1-Tree Lower Bound and Lagrangian Relaxation
We now relate the 1-tree lower bound to a Lagrangian relaxation associated with
the following formulation of the traveling salesman problem. For every e ∈E, let
de be the cost of the edge and let xe be a variable that takes on the value 1 if the
optimal tour includes the edge and the value 0 otherwise. Given a subset S ⊂V ,
let E(S) be the set of edges from E such that each edge has its two endpoints in
S. Let δ(S) be the collection of edges from E in the cut separating S from V \S.
The traveling salesman problem can be formulated as follows:
Problem P ′ :
Z∗= Min

e∈E
dexe
s.t.

e∈δ(i)
xe = 2,
∀i = 1, 2, . . ., n,
(6.7)

e∈E(S)
xe ≤|S|−1, ∀S ⊆V \{1}, S̸=∅,
(6.8)
0 ≤xe ≤1,
∀e ∈E,
(6.9)
xe
integer,
∀e ∈E.
(6.10)
Constraints (6.7) ensure that each vertex has an edge going in and an edge
going out. Constraints (6.8), called subtour elimination constraints, forbid integral
solutions consisting of a set of disjoint cycles.
Observe that constraints (6.7) can be replaced by the following constraints:

e∈δ(i)
xe = 2,
∀i = 1, . . . , n −1,
(6.11)

e∈E
xe = n.
(6.12)

108
6. Mathematical Programming-Based Bounds
This is true since constraints (6.11) are exactly constraints (6.7) for i = 1, . . . , n−1.
The only missing constraint is 
e∈δ(n) xe = 2. Therefore, it is suﬃcient to show
that (6.12) holds if and only if this one holds. To see this, calculate

e∈E
xe = 1
2
n

i=1

e∈δ(i)
xe
= 1
2
n−1

i=1

e∈δ(i)
xe + 1
2

e∈δ(n)
xe
= (n −1) + 1
2

e∈δ(n)
xe.
Thus, 
e∈E xe = n if and only if 
e∈δ(n) xe = 2.
The resulting formulation of the traveling salesman problem is

Min

e∈E
dexe
(6.8), (6.9), (6.10), (6.11), and (6.12)

.
We can now use the Lagrangian relaxation technique described in Sect. 6.3 and
get the following lower bound on the length of the optimal tour:
max
u

min
x

i,j∈V
(dij + ui + uj)xij
(6.8), (6.9), (6.10), and (6.12)

.
Interestingly enough, Edmonds (1971) showed that the extreme points of the
polyhedron deﬁned by constraints (6.8)–(6.10) and (6.12) is the set of all 1-trees;
that is, the optimal solution to a linear program deﬁned on these constraints must
be integral. Thus, we can apply Corollary 6.3.4 to see that the lower bound ob-
tained from the 1-tree approach is the same as the linear relaxation of Problem P ′.
6.5
The Worst-Case Eﬀectiveness of the 1-Tree Lower
Bound
We conclude this chapter by demonstrating that the Held and Karp (1970, 1971)
1-tree relaxation provides a lower bound that is not far from the length of the
optimal tour. For this purpose, we show that the Held and Karp lower bound can
be written as follows:
Problem HK :
ZLP = Min

e∈E
dexe
s.t. 
e∈δ(i)
xe = 2,
∀i = 1, 2, . . ., n,
(6.13)

6.5 The Worst-Case Eﬀectiveness of the 1-Tree Lower Bound
109

e∈δ(S)
xe ≥2, ∀S ⊆V \{1}, S̸=∅,
(6.14)
0 ≤xe ≤1,
∀e ∈E.
(6.15)
Lemma 6.5.1 The linear relaxation of Problem P ′ is equivalent to Problem HK.
Proof. We ﬁrst show that any feasible solution x to the linear relaxation of Problem
P ′ is feasible for Problem HK. Since 
e∈S xe ≤|S|−1, 
e∈E(V \S) xe ≤n−|S|−1,
and 
e∈E(V ) xe = n (why?), we get 
e∈δ(S) xe ≥2.
Similarly, we show that any feasible solution ˜x to Problem HK is feasible for the
linear relaxation of Problem P ′. The feasibility of ˜x in Problem HK implies that

i∈S

e∈δ(i) ˜xe = 2|S|. However,

i∈S

e∈δ(i)
˜xe = 2

e∈E(S)
˜xe +

e∈δ(S)
˜xe = 2|S|,
and since 
e∈δ(S) ˜xe ≥2, we get 
e∈E(S) ˜xe ≤|S| −1.
Shmoys and Williamson (1990) have shown that the Held and Karp lower bound
(Problem HK) has a particular monotonicity property, and as a consequence, they
obtain a new proof of an old result from Wolsey (1980), who showed the following:
Theorem 6.5.2 For every instance of the TSP for which the distance matrix
satisﬁes the triangle inequality, we have Z∗≤3
2ZLP .
The proof presented here is based on the monotonicity property established
by Shmoys and Williamson (1990) . However, we use a powerful tool discovered
by Goemans and Bertsimas (1993), called the parsimonious property. This is a
property that holds for a general class of network design problems.
To present the property, consider the following linear program deﬁned on the
complete graph G = (V, E). Associated with each vertex i ∈V is a given number
ri, which is either 0 or 2. Let V2 = {i ∈V |ri = 2}.
We will analyze the following linear program (here ND stands for network
design).
Problem ND :
Min

e∈E
dexe
s.t. 
e∈δ(i)
xe = ri,
∀i = 1, 2, . . ., n,
(6.16)

e∈δ(S)
xe ≥2,
∀S ⊂V, V2 ∩S ̸= ∅,
V2 ∩(V \S) ̸= ∅,
(6.17)
0 ≤xe ≤1,
∀e ∈E.
(6.18)
It is easy to see that when V2 = V , this linear program is equivalent to the linear
program Problem HK. We now provide a short proof of the following result.

110
6. Mathematical Programming-Based Bounds
Lemma 6.5.3 The optimal solution value to Problem ND is unchanged if we omit
constraint (6.16).
Our proof is similar to the proof presented in Bienstock and Simchi-Levi (1993);
see also Bienstock et al. (1993a), which uses a result of Lovasz (1979). In his book
of problems (Exercise 6.51), Lovasz presents the following result, together with a
short proof. But ﬁrst, we need a deﬁnition.
Deﬁnition 6.5.4 An undirected graph G is k-connected between two vertices i
and j if there are k (node) disjoint paths between i and j.
Lemma 6.5.5 Let G be an Eulerian multigraph and s ∈V (G), such that G is
k-connected between any two vertices diﬀerent from s. Then, for any neighbor u
of s, there exists another neighbor w of s, such that the multigraph obtained from
G by removing {s, u} and {s, w} and adding a new edge {u, w} (the splitting-oﬀ
operation) is also k-connected between any two vertices diﬀerent from s.
Lovasz’s
proof
of
Lemma
6.5.5
can
be
easily
modiﬁed
to
yield
the
following.
Lemma 6.5.6 Let G be an Eulerian multigraph, Y ⊆V (G) and s ∈V (G), such
that G is k-connected between any two vertices of Y diﬀerent from s. Then, for
any neighbor u of s, there exists another neighbor w of s, such that the multigraph
obtained from G by removing {s, u} and {s, w} and adding a new edge {u, w} is
also k-connected between any two vertices of Y diﬀerent from s.
We can now prove Lemma 6.5.3.
Proof. Let V0 = V \V2; that is, V0 = {i ∈V |ri = 0}. Let Problem ND′ be Problem
ND without (6.16). Finally, let ˜x be a rational vector feasible for Problem ND′,
chosen such that (i) ˜x is optimal for Problem ND′, and (ii) subject to (i), 
e∈E ˜xe
is minimized.
Let M be a positive integer, large enough so that ˜v = 2M ˜x is a vector of even
integers. We may regard ˜v (with a slight abuse of notation) as the incidence vector
of the edge-set ˜E of a multigraph ˜G with vertex set V . Clearly, ˜G is Eulerian, and
by (6.17), it is 4M-connected between any two elements of V2.
Now suppose that for some vertex s, 
e∈δ({s}) ˜xe > rs (i.e., s has a degree
larger than 2Mrs in ˜G). Let us apply Lemma 6.5.6 to s and any neighbor u of s
(where Y = V2), and let ˜H be the resulting multigraph, with incidence vector ˜z.
Clearly,

e∈E
de˜ze ≤

e∈E
de˜ve,
and so

e∈E
de
˜ze
2M ≤

e∈E
de˜xe.

6.5 The Worst-Case Eﬀectiveness of the 1-Tree Lower Bound
111
Moreover,

e∈E
˜ze
2M =

e∈E
˜xe −
1
2M .
Hence, by the choice of ˜x, z =
˜z
2M cannot be feasible for Problem ND′.
If s ∈V0, then by Lemma 6.5.6, z is feasible for Problem ND′. Thus, we must
have s ∈V2 and, in fact, 
e∈δ({t}) ˜xe = 0 for all t ∈V0. In other words, ˜E spans
precisely V2, ˜G is 4M-connected, and 
e∈δ({s}) ≥4M + 2. But we claim now that
the multigraph ˜H is 4M-connected. For by Lemma 6.5.6, it could only fail to be
4M-connected between s and some other vertex, but the only possible cut of size
less than 4M is the one separating s from V \{s}. Since this cut has at least 4M
edges, the claim is proved. Consequently, again we obtain that z is feasible for
Problem ND′, a contradiction. In other words, 
e∈E ˜ve = 2Mri for all i; that is,
(6.16) holds.
An immediate consequence of Lemma 6.5.3 is that in Problem HK, one can
ignore constraint (6.13) without changing the value of its optimal solution. This
new formulation reveals the following monotonocity property of the Held and Karp
lower bound: Let A ⊆V and consider the Held and Karp lower bound on the length
of the optimal traveling salesman tour through the vertices in A; that is,
Problem HK(A) :
ZLP (A) = Min

e∈E
dexe
s.t.

e∈δ(S)
xe ≥2,
∀S ⊂A,
(6.19)
0 ≤xe ≤1,
∀e ∈E.
(6.20)
Since any feasible solution to Problem HK(V ) is feasible for Problem HK(A), the
cost of this linear program is monotone with respect to the set of nodes A.
We are ready to prove Theorem 6.5.2.
Proof.
Section
4.3.3
presents
and
analyzes
the
heuristic
developed
by
Christoﬁdes for the TSP which is based on constructing a minimum spanning
tree plus a matching on the nodes of odd degree. Observe that a similar heuristic
can be obtained if we start from a 1-tree instead of a minimum spanning tree.
Thus, the length of the optimal tour is bounded by W(T ∗
1 ) + W(M ∗(A)), where
W(T ∗
1 ) is the weight (cost) of the best 1-tree and W(M ∗(A)) is the weight of
the optimal weighted matching deﬁned on the set of odd-degree nodes in the best
1-tree, denoted by A.
We argue that W(M ∗(A)) ≤1
2ZLP(A). Let x be an optimal solution to Problem
HK(A). It is easy to see that the vector 1
2x is feasible for the following constraints:

e∈δ(i)
xe = 1,
∀i ∈A,
(6.21)

112
6. Mathematical Programming-Based Bounds

e∈E(S)
xe ≤1
2(|S| −1),
∀S ⊂A, S ̸= ∅, |S| ≥3, |S| is odd,
(6.22)
0 ≤xe ≤1,
∀e ∈E.
(6.23)
A beautiful result of Edmonds (1965) tells us that these constraints are suﬃcient
to formulate the matching problem as a linear program. Consequently,
W(M ∗(A)) ≤1
2ZLP (A) ≤1
2ZLP(V ) = 1
2ZLP,
and therefore,
L∗≤W(T ∗
1 ) + W(M ∗(A))
≤ZLP + 1
2ZLP
≤3
2ZLP .
6.6
Exercises
Exercise 6.1.
Prove Lemma 6.3.2.
Exercise 6.2.
Show that a lower bound on the cost of the optimal traveling
salesman tour can be given by
2
|N| max
i∈N

j∈N
dij,
where N is the set of cities and dij is the distance from city i to city j.
Exercise 6.3.
Consider an instance of the bin-packing problem where there are
mj items of size wj ∈(0, 1] for j = 1, 2, . . ., n. Deﬁne a bin conﬁguration to be
a vector c = (c1, c2, . . . , cn) with the property that ci ≥0 for i = 1, 2, . . ., n and
n
j=1 cjwj ≤1. Enumerate all possible bin conﬁgurations. Let there be M such
conﬁgurations. Deﬁne Cjk to be the number of items of size wj in bin conﬁguration
k, for k = 1, 2, . . ., M and j = 1, 2, . . ., n.
Formulate an integer program to solve this bin-packing problem using the follow-
ing variables: xk is the number of times conﬁguration k is used, for k = 1, 2, . . ., M.
Exercise 6.4.
A function u : [0, 1] →[0, 1] is dual-feasible if, for any sets of
numbers w1, w2, . . . , wk, we have
k

i=1
wi ≤1 ⇒
k

i=1
u(wi) ≤1.

6.6 Exercises
113
(a) Given an instance of the bin-packing problem with item sizes w1, w2,
. . . , wn and a dual-feasible function u, prove that n
i=1 u(wi) ≤b∗.
(b) Assume n is even. Let half of the items be of size 2
3 and the other half of size
1
2. Find a dual-feasible function u that satisﬁes
n

i=1
u(wi) = b∗.
Exercise 6.5.
Consider a list L of n items of sizes in ( 1
3, 1
2]. Let bLP be the
optimal fractional solution to the set-partitioning formulation of the bin-packing
problem, and let b∗be the optimal integer solution to the same formulation. Prove
that
b∗≤bLP + 1.
Exercise 6.6.
Prove that if a graph has exactly 2k vertices of odd degree, then
the set of edges can be partitioned into k paths such that each edge is used exactly
once.

Part II
Inventory Models

7
Economic Lot Size Models
with Constant Demands
7.1
Introduction
Production planning is also an area where diﬃcult combinatorial problems appear
in day-to-day logistics operations. In this chapter, we analyze problems related
to lot sizing when demands are constant and known in advance. Lot sizing in
this deterministic setting is essentially the problem of balancing the ﬁxed costs of
ordering with the costs of holding inventory. In this chapter, we look at several
diﬀerent models of deterministic lot sizing. First, we consider the most basic single-
item model, the economic lot size model. Then we look at coordinating the ordering
of several items with a warehouse of limited capacity. Finally, we look at a one-
warehouse multiretailer system.
7.1.1
The Economic Lot Size Model
The classical economic lot size model, introduced by Harris (1915) (see Erlenkotter
1990 for an interesting historical discussion), is a framework where we can see the
simple tradeoﬀs between ordering and storage costs. Consider a facility, possibly
a warehouse or a retailer, that faces a constant demand for a single item and
places orders for the item from another facility in the distribution network, which
is assumed to have an unlimited quantity of the product. The model assumes the
following.
D. Simchi-Levi et al., The Logic of Logistics: Theory, Algorithms, and Applications
for Logistics Management, Springer Series in Operations Research and Financial Engineering,
DOI 10.1007/978-1-4614-9149-1 7, © Springer Science+Business Media New York 2014
117

118
7. Economic Lot Size Models with Constant Demands
FIGURE 7.1. Inventory level as a function of time
• Demand is constant at a rate of D items per unit time.
• Order quantities are ﬁxed at Q items per order.
• A ﬁxed setup cost K is incurred every time the warehouse places an order.
• A linear inventory carrying cost h, also referred to as the holding cost, is
accrued for every unit held in inventory per unit time.
• The lead time, that is, the time that elapses between the placement of an
order and its receipt, is zero.
• The initial inventory is zero.
• The planning horizon is inﬁnite.
The objective is to ﬁnd the optimal ordering policy minimizing the total purchasing
and carrying cost per unit of time without shortage.
Like all models, this is a simpliﬁed version of what might actually occur in prac-
tice. The assumption of a known ﬁxed demand over the inﬁnite horizon is clearly
unrealistic. The lead time is most likely positive, and the requirement of a ﬁxed
order quantity is restrictive. As we shall see, all these assumptions can be easily
relaxed while maintaining a relatively simple optimal policy. For the purposes of
understanding the basic tradeoﬀs in the model, we keep the assumptions listed
above.
It is easy to see that an optimal ordering policy must satisfy the zero-inventory-
ordering property, which says that every order is received precisely when the in-
ventory level drops to zero. This can be seen by considering the case where an
order is placed when the inventory level is not zero. In that case, the cost is not
increased if we simply wait until the inventory is zero to order.
To ﬁnd the optimal ordering policy in the economic lot size model, we con-
sider the inventory level as a function of time (see Fig. 7.1). This is the so-called
saw-toothed inventory pattern. We refer to the time between two successive re-
plenishments as a cycle time. Thus, the total inventory cost in a cycle of length

7.1 Introduction
119
T is
K + hT Q
2
,
and since Q = T D, the average total cost per unit of time is
KD
Q
+ hQ
2 .
Hence, the optimal order quantity is
Q∗.=

2KD
h
.
This quantity is referred to as the economic order quantity (EOQ); it is the quan-
tity at which the inventory setup cost per unit of time ( KD
Q ) equals the inventory
holding cost per unit of time ( hQ
2 ).
We now see how some of our assumptions can be relaxed, without losing any of
the model’s simplicity. Consider the case in which the initial inventory is positive,
say at level I0; then the ﬁrst order for Q∗items is simply delayed until time I0
D .
Further, the assumption of zero lead time can also be easily relaxed. In fact, the
model can handle any deterministic lead time L. To do this, simply place an order
for Q∗items when the inventory level is DL. On the other hand, relaxing the
assumptions of ﬁxed demands and inﬁnite planning horizon requires signiﬁcant
changes to the above solution.
7.1.2
The Finite-Horizon Model
To make the model more realistic, we now introduce a ﬁnite horizon, say t. For
instance, in the retail apparel industry, such a horizon may represent an 8–12-week
period, for example, the “winter season,” in which demand for the product might
be assumed to be constant and known. We also relax the assumption that the
order quantities are ﬁxed. We seek an inventory policy on the interval [0, t] that
minimizes the ordering and carrying costs.
For this purpose, consider any inventory policy, say, P, that places m ≥1 orders
in the interval [0, t]. Clearly, the ﬁrst order must be placed at time zero and the last
must be placed so that the inventory at time t is zero. For any i, 1 ≤i ≤m−1, let
Ti be the time between the placement of the ith order and the (i+1)st order and let
Tm be the time between the placement of the last order and t. Thus, by deﬁnition,
t = m
i=1 Ti, and P places the jth order at time j
i=1 Ti, for 1 ≤j ≤m. Again,
it is clear that the policy P must satisfy the zero-inventory-ordering property.
Figure 7.2 illustrates the inventory level of policy P.
For policy P, let I(τ) be the inventory level at time τ ∈[0, t]. Thus, the total
cost per unit of time associated with P is
1
t

Km + h
 t
0
I(τ)dτ

.

120
7. Economic Lot Size Models with Constant Demands
FIGURE 7.2. Inventory level as a function of time under policy P
The only thing we know about the function I(τ) is that it decreases at a rate of D
(a slope of −D) between orders and reaches zero exactly m times. Thus, we can
express the total inventory up to time t as a function of the time between orders
{Ti}i=1,...,m as follows:
m

i=1
Ti · DTi
2
= D
2
m

i=1
T 2
i .
Consequently, if m orders are placed, we can ﬁnd the best times to place them by
solving
Min
 m

i=1
T 2
i

m

i=1
Ti = t, Ti ≥0, ∀i = 1, 2, . . . , m

.
The optimal solution to this convex optimization problem is Ti =
t
m for each
i = 1, 2, . . . , m. Hence, an optimal policy must have the following property.
Property 7.1.1 For a problem with one product over the interval [0, t], the inven-
tory policy with minimum cost that places m orders is achieved by placing orders
of equal size at equally spaced points in time.
The property thus implies that the total purchasing and carrying cost per unit
time associated with P is at least
Km
t
+ hDt
2m .
Consequently, by selecting the value of m that minimizes this value, we can con-
struct a policy of minimal cost. Let
α = t

hD
2K ,
and thus the best value of m is either ⌊α⌋or ⌈α⌉, depending on which yields the
smaller cost. Thus, our policy in the ﬁnite-horizon case is, in fact, very similar to
the inﬁnite-horizon case. Orders are placed at regularly spaced intervals of time,
and, of course, the orders are of the same size each time.

7.1 Introduction
121
7.1.3
Power-of-Two Policies
Consider the inﬁnite-horizon model described in Sect. 7.1. For this model, we know
that the average total cost per unit of time is
KD
Q
+ hQ
2
= K
T + hT D
2
.= f(T ),
where T is the time between orders. In this subsection, following Muckstadt and
Roundy (1993), we introduce a new class of policies called power-of-two policies.
To simplify the analysis, and in accordance with the notation used in the lit-
erature (see Roundy 1985 and Muckstadt and Roundy 1993), let g .=
hD
2 , and
hence
f(T ) = K
T + gT.
Observe that the function f(T ) motivates another interpretation of the model.
We can consider the problem to be an economic lot size model with unit demand
rate, that is, D = 1, and inventory holding cost 2g. The optimal reorder interval
is T ∗=

K
g , and the total cost per unit time is f(T ∗) = 2√Kg.
One diﬃculty with the economic lot size model is that the optimal reorder
interval T ∗may take on any value and thus might lead to highly impractical
optimal policies. For instance, reorder intervals of
√
3 days, or √π weeks, would
not be easy to implement. That is, the model might specify that orders be placed on
Monday of one week, Thursday of the next, Tuesday of the next week, and so forth,
a schedule of orders that may not have an easily recognizable pattern. Therefore,
it is natural to consider policies where the reorder interval T is restricted to values
that would entail easily implementable policies. One such restriction is termed the
power-of-two restriction. In this case, T is restricted to be a power-of-two multiple
of some ﬁxed base planning period TB; that is,
T = TB2k,
k ∈{0, 1, 2, 3, . . .}.
(7.1)
Such a policy is called a power-of-two policy. The base planning period TB may
represent a day, week, or month, for example, and is usually ﬁxed beforehand. It
represents the minimum possible reorder interval.
Restricting ourselves to power-of-two policies requires addressing the following
issues.
• How does one ﬁnd the best power-of-two policy, the one minimizing the cost
over all possible power-of-two policies?
• How far from optimal is the best policy of this type?
We start by answering the ﬁrst question. Let T ∗=

K
g be the optimal (unre-
stricted) reorder interval, and let T be the optimal power-of-two reorder interval.
Since f is convex, the optimal k in (7.1) is the smallest integer k satisfying
f(TB2k) ≤f(TB2k+1)

122
7. Economic Lot Size Models with Constant Demands
or
K
TB2k + gTB2k ≤
K
TB2k+1 + gTB2k+1.
Hence, k is the smallest integer such that

K
2g =
1
√
2T ∗≤TB2k = T.
Thus, ﬁnding the optimal power-of-two policy is straightforward.
Observe that by the deﬁnition of the optimal k, it must also be true that
T = TB2k ≤

2K
g
=
√
2T ∗,
and hence the optimal power-of-two policy, for a given base planning period TB,
must be in the interval [ 1
√
2T ∗,
√
2T ∗]. It is easy to verify that
f
 1
√
2T ∗
= f(
√
2T ∗) = 1
2
 1
√
2 +
√
2

f(T ∗),
and hence, since f is convex, we have
f(T )
f(T ∗) ≤1
2
 1
√
2 +
√
2

≈1.06.
Consequently, the average inventory purchasing and carrying cost of the best
power-of-two policy is guaranteed to be within 6 % of the average cost of the
overall minimum policy. The reader can see that this property is a result of the
“ﬂatness” of the function f around its minimum.
This restriction, to power-of-two multiples of the base planning period, will also
prove to be quite useful later in a more general setting.
7.2
Multi-Item Inventory Models
7.2.1
Introduction
The previous models established optimal inventory policies for single-item models.
It is simple to show that without the presence of joint order costs, a problem
with several items each facing a constant demand can be handled by solving each
item’s replenishment problem separately. In reality, the management of a single
warehouse inventory system involves coordinating inventory orders to minimize
cost without exceeding the warehouse capacity. The warehouse capacity limits the
total volume held by the warehouse at any point in time. This constraint ties
together the diﬀerent items and necessitates careful coordination (or scheduling)
of the orders. That is, it is important to know not only how often an item is

7.2 Multi-Item Inventory Models
123
ordered, but also exactly the point in time at which each order takes place. This
problem is called the economic warehouse lot scheduling problem (EWLSP). The
scheduling part, hereafter called the staggering problem, is exactly the problem
of time-phasing the placement of the orders to satisfy the warehouse capacity
constraint. Unfortunately, this problem has no easy solution, and consequently it
has attracted a considerable amount of attention in the last three decades.
The earliest known reference to the problem appears in Churchman et al. (1957)
and subsequently in Holt (1958) and Hadley and Whitin (1963). These authors
were concerned with determining lot sizes that made an overall schedule satisfy
the capacity constraint, and not with the possibility of phasing the orders to avoid
holding the maximum volume of each item at the same time. Thus, they only
considered what are called independent solutions, wherein every item is replenished
without any regard for coordination with other items.
Several authors considered another class of policies called rotation cycle policies
wherein all items share the same order interval. Homer (1966) showed how to
optimally time-phase (stagger) the orders to satisfy the warehouse constraint for
a given common order interval. Page and Paul (1976), Zoller (1977), and Hall
(1988) independently rediscovered Homer’s result. At the end of his paper devoted
to rotation-cycle policies, Zoller indicates the possibility of partitioning the items
into disjoint subsets, or clusters, if the assumption of a rotation policy “proves
to be too restrictive.” This is precisely Page and Paul’s partitioning heuristic.
In their heuristic, all the items in a cluster share a common order interval. The
orders are then optimally staggered within each cluster, but no attempt is made to
time-phase the orders of diﬀerent clusters. Goyal (1978) argued that such a time-
phasing across the diﬀerent clusters may lead to a further reduction in warehouse
space requirements. Hartley and Thomas (1982) and Thomas and Hartley (1983)
considered the two-item case in detail.
A number of studies have been concerned with the strategic version of the
EWLSP in which the warehouse capacity is not a constraint but rather a deci-
sion variable. These include Hodgson and Howe (1982), Park and Yun (1985),
Hall (1988), Rosenblatt and Rothblum (1990), and Anily (1991). In this model,
the inventory carrying cost consists of two parts; one part is proportional to the
average inventory, while the second part is proportional to the peak inventory. A
component of the latter cost, discussed in Silver and Peterson (1985), is the cost
of leasing the storage space. This cost is typically proportional to the size of the
warehouse, and not to the inventories actually stored in it.
Deﬁne a policy to be a stationary order size policy if all replenishments of an item
are of the same size. Likewise, a stationary order intervals policy has all orders for
an item equally spaced in time. It is easily veriﬁed that an optimal stationary order
size (respectively, stationary order interval) policy is also a stationary order interval
(respectively, a stationary order size) policy if every order of an item is received
precisely when the inventory of that item drops to zero; that is, it also satisﬁes
the zero-inventory-ordering property. Thus, it is natural to consider policies that
have all three properties: stationary order size, stationary order interval, and zero
inventory ordering. We call such policies stationary order size and interval policies,

124
7. Economic Lot Size Models with Constant Demands
in short, SOSI policies. Two “extreme” cases of SOSI policies are the independent
solutions and the rotation-cycle policies deﬁned above. All the authors cited above
considered SOSI policies exclusively. Zoller claims that SOSI policies are the only
rational alternative, and most authors agree that SOSI policies are much easier
to implement in practice. In his Ph.D. thesis, however, Hariga (1988) investigated
both time-variant and stationary order sizes. He was motivated to study time-
variant order sizes by their successful application in resolving the feasibility issue
in the economic lot scheduling problem (ELSP) (see Dobson 1987).
Anily’s paper departs from earlier work on the EWLSP in its focus on the
worst-case performance of heuristics. In her paper, Anily restricts herself to the
class of SOSI policies for the strategic model. She proves lower bounds on the
minimum-required warehouse size and on the total cost for this class of policies.
She presents a partitioning heuristic of which the best independent solution and
the best rotation-cycle policies are special cases. This partitioning heuristic is
similar to the one proposed by Page and Paul for the tactical model although the
precise methods for ﬁnding the partition are diﬀerent. Anily proves that the ratio
of the cost of the best independent solution to her lower bound is at most
√
2. She
also provides a data-dependent bound for the best rotation cycle, derived from
Jones and Inman’s (1989) work on the economic lot size problem. As a result,
her partitioning heuristic is at least as good as either special case and thus has a
worst-case bound of
√
2 relative to SOSI policies.
In this section, we determine easily computable lower bounds on the cost of the
EWLSP as well as some simple heuristics for the problem. These bounds are used
to determine the worst-case performance of these heuristics on diﬀerent versions
of the problem. First, in Sect. 7.2.2, we introduce notation, state assumptions, and
formally deﬁne the strategic and tactical versions of the EWLSP. In Sect. 7.2.3,
we establish the worst-case results. The discussion in this section is based on the
work of Gallego et al. (1996).
7.2.2
Notation and Assumptions
Let N = {1, 2, . . ., n} be a set of n items each facing a constant unit demand rate
(this can be done without loss of generality). An ordering cost Ki is incurred each
time an order for item i is placed. A linear holding cost 2hi is accrued for each
unit of item i held in inventory per unit of time. Demand for each item must be
met over an inﬁnite horizon without shortages or backlogging.
The volume of inventory of item i held at a given point in time is the product
of its inventory level at that time and the volume usage rate of item i, denoted by
γi > 0. The volume usage rate is deﬁned as the volume displaced by one unit of
item i. Without loss of generality, we select the unit of volume so that n
i=1 γi = 1.
The objective in the strategic version of the EWLSP is to minimize the long-
run average inventory carrying and ordering cost plus a cost proportional to the
maximum volume held by the warehouse at any point in time. Formally, for any
inventory policy P, let V (P) denote the maximum inventory volume held by the

7.2 Multi-Item Inventory Models
125
warehouse, and let C(P) be the long-run average inventory carrying and holding
cost incurred by this policy. Then the objective is to ﬁnd a policy P minimizing
Z(P) .= C(P) + V (P).
The tactical version of the EWLSP has also received much attention in the lit-
erature. There, the objective is to ﬁnd a policy P minimizing the long-run average
inventory carrying and holding costs subject to the inventory always being less
than the warehouse capacity. Hence, the tactical version can be formulated as fol-
lows: Find a policy P minimizing C(P) subject to V (P) ≤v, where v denotes the
available warehouse volume.
7.2.3
Worst-Case Analyses
Preliminaries
We present here two simple results that are used in subsequent analyses.
Given a SOSI policy, let T = {T1, T2, . . . , Tn} be the vector of reorder intervals,
where Ti is the reorder interval of item i. For any such vector T , let V (T ) denote
the maximum volume of inventory held by the warehouse over all points in time.
The following provides a simple upper bound on V (T ).
Lemma 7.2.1 For any vector T = {T1, T2, . . . , Tn}, we have
V (T ) ≤
n

i=1
γiTi.
Proof. Clearly, the inventory level of item i, at any moment in time, is no more
than Ti (recall demand is 1 for all i).
For the next result, we need some additional notation. Consider any inventory
policy P and any time interval [0, t]. Let V (P, t) be the maximum inventory held
by the warehouse in policy P over the interval [0, t], and let C(P, t) be the average
inventory holding and carrying cost incurred over [0, t]. Let mi be the number of
times the warehouse places an order for item i over the interval [0, t]. For τ ∈[0, t],
let Ii(τ) be the inventory level of item i at time τ. Let vi(τ) be the volume of
inventory held by item i at time τ; that is, vi(τ) = γiIi(τ). Also, let v(τ) =
n
i=1 vi(τ) be the volume of inventory held by the warehouse at time τ.
Lemma 7.2.2 For any inventory policy P and time interval [0, t], we have
1
2
n

i=1
γit
mi
≤
n

i=1
1
t γi
 t
τ=0
Ii(τ)dτ ≤V (P, t).

126
7. Economic Lot Size Models with Constant Demands
Proof. Clearly, v(τ) ≤V (P, t) for all τ ≤t. Taking the integral up to time t > 0
gives
V (P, t) ≥1
t
 t
τ=0

i
vi(τ)dτ
= 1
t
 t
τ=0

i
γiIi(τ)dτ
=

i
1
t γi
 t
τ=0
Ii(τ)dτ
≥

i
1
2
γit
mi
,
where the last inequality follows from Property 7.1.1, which states that when mi
orders for a single item are placed over the interval [0, t], the average inventory
level is minimized by placing equal orders at equally spaced points in time.
The Strategic Model
Consider the following heuristic for the strategic version of the EWLSP. Use the
vector of reorder intervals T that solves
ZH = min
T
 
i
Ki
Ti
+ hiTi

+

i
γiTi

.
Clearly, the vector T can be found in O(n) time by solving n separate economic
lot scheduling models, and
ZH = 2

i

Ki(hi + γi).
(7.2)
By Lemma 7.2.1, ZH must provide an upper bound on the optimal solution value
of the strategic model.
We now construct a lower bound on the optimal solution value over all possible
inventory policies. The lower bound is the cost of the optimal policy if the ware-
house cost were based on average inventory rather than maximum inventory. This
bound will be used to prove the worst-case result.
Lemma 7.2.3 A lower bound on the optimal solution value over all possible in-
ventory strategies is given by
ZLB = 2

i

Ki(hi + γi/2).
(7.3)
Proof. We show that ZLB ≤C(P, t) + V (P, t) for all possible inventory policies
P and for all t > 0. Given an inventory policy P, where mi orders for item i are
placed over a time interval [0, t], then

7.2 Multi-Item Inventory Models
127
C(P, t) = 1
t

i

miKi + 2hi
 t
τ=0
Ii(τ)dτ

.
Combining this cost with the lower bound obtained in Lemma 7.2.2 on V (P, t)
yields the following lower bound on C(P, t) + V (P, t):
C(P, t) + V (P, t) ≥1
t

i

miKi + 2hi
 t
τ=0
Ii(τ)dτ

+ 1
t

i
γi
 t
τ=0
Ii(τ)dτ
= 1
t

i

miKi + (2hi + γi)
 t
τ=0
Ii(τ)dτ

≥

i

Ki
mi
t

+ (2hi + γi)
2
 t
mi

.
The last inequality again follows from Property 7.1.1. Minimizing the last expres-
sion with respect to
t
mi for each i ∈N proves the result.
We now show that this heuristic is eﬀective in terms of worst-case performance.
Theorem 7.2.4
ZH
ZLB ≤
√
2.
Proof. Combining (7.2) and (7.3), we get
ZH
ZLB =
2 
i

Ki(hi + γi)
2 
i

Ki(hi + γi/2)
≤
√
2.
Can this bound be improved? The following example shows that the bound is
tight as the number of items grows to inﬁnity. Consider an example n items with
Ki = K, hi = 0 and γi = γ = 1
n for all i ∈N. Clearly,
ZH = 2n

Kγ.
We now construct a feasible solution whose cost approaches the lower bound ZLB
as n goes to inﬁnity. Consider a feasible policy P with identical reorder intervals
denoted by ˜T. To reduce the maximum volume V ( ˜T ), we stagger the orders such
that item i is ordered at times ˜T[ (i−1)
n
+ k] for k ≥0. Then the maximum volume
of inventory is (n+1)
2
˜Tγ. Hence, the cost of policy P is
Z(P) = nK
˜T
+ n + 1
2
˜Tγ.
Minimizing with respect to ˜T gives
Z(P) =

2n(n + 1)Kγ.

128
7. Economic Lot Size Models with Constant Demands
Consequently,
ZH
ZLB ≥
ZH
Z(P) =
2n√Kγ

2n(n + 1)Kγ
.
The limit of this last quantity is
√
2 (as n goes to inﬁnity); hence, along with
Theorem 7.2.4, we see that an example can be constructed where the worst-case
ratio is arbitrarily close to
√
2.
The Tactical Model
For the tactical version of the EWLSP, a simple heuristic denoted HW ﬁrst
proposed by Hadley and Whitin (1963) is to solve
Problem P HW : CHW = Min

i

hiTi + Ki
Ti

s.t.

i
γiTi ≤v,
T ≥0.
We show that the HW heuristic has a worst-case performance bound of 2 with re-
spect to all feasible policies. We do so by proving that the solution to the following
nonlinear program provides a lower bound on the cost of any feasible policy.
Problem P LB : CLB = Min

i

hiTi + Ki
Ti

s.t.
1
2

i
γiTi ≤v,
(7.4)
T ≥0.
Lemma 7.2.5 CLB is a lower bound on the cost of any feasible inventory policy.
Proof. Consider any feasible policy P over the interval [0, t] that places mi orders
for item i in [0, t]. From Lemma 7.2.2, we have ∀t > 0,
v ≥V (P, t) ≥1
2

i
γi
mi
t.
The average inventory holding and carrying cost incurred over the interval [0, t] is
C(P, t)= 1
t

i

miKi + 2hi
 t
τ=0
Ii(τ)dτ

≥

i

Ki
mi
t

+ hi
 t
mi

.
(7.5)

7.3 A Single-Warehouse Multiretailer Model
129
Again, the last inequality follows from Property 7.1.1.
Thus, by replacing
t
mi with Ti for all i ≥1, we see that minimizing (7.5) subject
to 1
2

i γit/mi ≤v provides a lower bound on C(P, t).
We now prove the worst-case bound.
Theorem 7.2.6
CHW
CLB ≤2.
Proof. Let T LB = {T LB
1
, T LB
2
, . . . , T LB
n
} be the optimal solution to P LB. Obvi-
ously, T ′
i = 1
2T LB
i
is feasible for P HW . Hence,
CHW ≤

i

hiT ′
i + Ki
T ′
i

= 1
2

i
hiT LB
i
+ 2

i
Ki
T LB
i
≤2CLB.
As in the strategic version, the worst-case bound provided by the above theorem
can be shown to be tight. To do so, consider the case where all items are identical
with Ki = K, hi = 0 and γi = γ = 1
n for all i ∈N. The solution to problem P HW
is clearly Ti = v for all i ∈N, so CHW = nK
v . Consider now a feasible policy
P with identical reorder intervals denoted by ˜T such that an order for item i is
placed at times ˜T[ (i−1)
n
+ k] for k ≥0. The maximum volume occupied by policy
P is (n+1)
2
˜Tγ. So ˜T =
2v
(n+1)γ is feasible and C(P) = K(n+1)
2v
. Hence,
lim
n→∞
CHW
C(P) = lim
n→∞
nK/v
K(n + 1)/2v = 2.
By performing a similar analysis, one can obtain worst-case bounds on the per-
formance of heuristics for other versions of the EWLSP. For instance, for the joint
replenishment version of the strategic model, where an additional setup cost K0 is
incurred whenever an order for one or more items is placed, the worst-case bound
of a heuristic, similar to the one described for the EWLSP, can be shown to be
√
3. The worst-case bound on the tactical version of the joint replenishment model
can be shown to be 2
√
2.
7.3
A Single-Warehouse Multiretailer Model
7.3.1
Introduction
Many distribution systems involve replenishing the inventories of geographically
dispersed retailers. Consider a distribution system in which a single warehouse

130
7. Economic Lot Size Models with Constant Demands
supplies a set of retailers with a single product. Each retailer faces a constant
retailer-speciﬁc demand that must be met without shortage or backlogging. The
warehouse faces orders for the product from the diﬀerent retailers and in turn
places orders to an outside supplier. A ﬁxed, facility-dependent, setup cost is
charged each time the warehouse or the retailers receive an order, and an in-
ventory carrying cost is accrued at each facility at a constant facility-dependent
rate. The objective is to determine simultaneously the timing and sizes of retailer
deliveries to the warehouse as well as replenishment strategies at the warehouse
so as to minimize the long-run average inventory purchasing and carrying costs.
In the absence of a ﬁxed setup cost charged when the warehouse places an order,
the problem can be decomposed into an economic lot size model for each retailer.
That is, the existence of this cost ties together the diﬀerent retailers, requiring
the warehouse to coordinate its orders and deliveries to the diﬀerent retailers. It
is well known that optimal policies can be very complex, and thus the problem
has attracted a considerable amount of attention in recent years (see Graves and
Schwarz 1977, Roundy 1985). The latter paper presents the best approach cur-
rently available for this model; it suggests a set of power-of-two reorder intervals
for each facility and shows that the cost of this solution is within 6 % of a lower
bound on the optimal cost. In this section, we present this method along with the
worst-case bound.
7.3.2
Model and Analysis
Consider a single warehouse (indexed by 0) that supplies n retailers, indexed
1, 2, . . ., n. We will use the term facility to designate either the warehouse or a
retailer. We make the following assumptions.
• Each retailer faces a constant demand rate of Di units, for i = 1, 2, . . ., n.
• The setup cost for an order at a facility is Ki, for i = 0, 1, . . . , n.
• The holding cost is h′
0 at the warehouse and h′
i at retailer i, with h′
i ≥h′
0
for each i = 1, 2, . . . , n.
• No shortages are allowed.
As demonstrated by several researchers, policies for this problem may be quite
complex, and thus it is of interest to restrict our attention to a subset of all feasible
policies. A popular subset of policies is the set of nested and stationary policies. A
nested policy is characterized by having each retailer place an order whenever the
warehouse does. As in the previous section, stationarity implies that reorder inter-
vals are constant for each facility. It is easy to show that any policy should satisfy
the zero-inventory-ordering property. Roundy (1985) showed that, although ap-
pealing from a coordination point of view, nested policies may perform arbitrarily
badly in one-warehouse, multiretailer systems. We therefore will not restrict our-
selves to nested policies. We concentrate on policies where each retailer’s reorder

7.3 A Single-Warehouse Multiretailer Model
131
intervals are a power-of-two multiple of a base planning period TB. Below, we as-
sume the base planning period is ﬁxed. The worst-case bound reduces to 1.02 if it
can be chosen optimally although we omit this extension.
Let’s ﬁrst determine the cost of an arbitrary power-of-two policy T = {T0, T1, . . . ,
Tn} that satisﬁes the zero-inventory-ordering property. If we consider the inven-
tory at the warehouse, then it does not have the saw-toothed pattern. To overcome
this diﬃculty, it is convenient to introduce the notion of system inventory as well
as echelon holding cost rates. Retailer i’s system inventory is deﬁned as the inven-
tory at retailer i plus the inventory at the warehouse that is destined for retailer
i. If we consider the system inventory of retailer i, then it has the saw-toothed
pattern. Echelon holding cost rates are deﬁned as h0 = h′
0 and hi = h′
i −h′
0. For
simplicity, deﬁne gi = 1
2hiDi and gi = 1
2h0Di for each i = 1, 2, . . . , n. To compute
the cost of such a policy, we separate each item in the warehouse’s inventory into
categories depending on the retailer for which the item is destined. Let Hi(T0, Ti)
be the average cost of holding inventory for retailer i at the warehouse and at
retailer i. We claim
Hi(T0, Ti) = giTi + gi max{T0, Ti}.
To prove this, consider the two cases:
Case 1: Ti ≥T0. Since T is a power-of-two policy, Ti ≥T0 implies that the
warehouse places an order every time the retailer does. Therefore, the warehouse
never holds inventory for retailer i, and the average holding cost is
1
2h′
iTiDi = 1
2(hi + h0)TiDi = (gi + gi)Ti.
Case 2: Ti < T0. Consider the portion of the warehouse inventory that is destined
for retailer i. Using the echelon holding cost rates, that is, inventory at retailer i
is charged at a rate of hi and system inventory is charged at a rate of h0, we have
Hi(T0, Ti) = 1
2hiDiTi + 1
2h0DiT0 = giTi + giT0.
Therefore, the average cost of a power-of-two policy T is given by

i≥0
Ki
Ti
+

i≥1
Hi(T0, Ti).
(7.6)
Our objective then is to ﬁnd the power-of-two policy T that minimizes (7.6).
Our approach to solving this problem is to ﬁrst minimize the average cost over
all vectors T ≥0. That is, we solve this problem when the restriction to power-of-
two vectors is relaxed. We then round the solution T to a vector whose elements
are the power-of-two multiple of TB.
For a ﬁxed value of T0, we consider the following problem:
bi(T0) = inf
Ti>0
Ki
Ti
+ Hi(T0, Ti)

.
(7.7)

132
7. Economic Lot Size Models with Constant Demands
To solve this problem, let τ′
i
.=

Ki
gi+gi , let τi .=

Ki
gi , and note that τ′
i ≤τi for
all i ≥1. Then one can show that
bi(T0) =
⎧
⎪
⎨
⎪
⎩
2

Ki(gi + gi)
if T0 < τ′
i,
Ki
T0 + (gi + gi)T0
if τ ′
i ≤T0 ≤τi,
2√Kigi + giT0
if τi < T0.
That is, if T0 < τ′
i, it is best to choose T ∗
i = τ′
i. If τ ′
i ≤T0 ≤τi, then choose
T ∗
i = T0. If T0 > τi, it is best to choose T ∗
i = τi.
We now consider minimizing
B(T0) .= K0
T0
+
n

i=1
bi(T0)
over all T0 > 0. The function B is of the form
K(T0)
T0
+ M(T0) + H(T0)T0
over any interval where K(), M(), and H() are constant. For any T0, deﬁne the
sets G(T0) .= {i : T0 < τ ′
i}, E(T0) .= {i : τ′
i ≤T0 ≤τ′
i}, and L(T0) .= {i : τi < T0}.
Then K(), M(), and H() are constant on those intervals where G(), E(), and L()
do not change. To ﬁnd the minimum of B, consider the intervals induced by the
2n values τ′
i and τi for i = 1, 2, . . . , n. Say T0 falls in some speciﬁc interval; then
we set
T ∗
i =
⎧
⎪
⎨
⎪
⎩
τ ′
i
if i ∈G(T0),
T0
if i ∈E(T0),
τi
if i ∈L(T0).
The sets G, E, and L change only when T0 crosses a breakpoint τ′
i or τi for some
i ≥1. Speciﬁcally, if T0 moves from right to left across τi, retailer i moves from
L to E. If T0 moves from right to left across τ′
i, retailer i moves from E to G.
This suggests a simple algorithm to minimize B(T0). Start with T0 larger than the
largest breakpoint, and let L = {1, 2, . . ., n} and G = E = ∅. We then successively
decrease T0, moving from interval to interval. On each interval we need only check
that

K(T0)
H(T0) falls in the same subinterval as T0. In this case, we set T ∗
0 =

K(T0)
H(T0)
since B(T0) is strictly convex in T0. Let B∗.= B(T ∗
0 ) = infT0≥0{B(T0)}; then this
value is clearly a lower bound on the cost of any power-of-two policy.
We now want to prove that this value is a lower bound on the cost of any
policy. For notational convenience, we abbreviate G∗= G(T ∗
0 ), E∗= E(T ∗
0 ), and
L∗= L(T ∗
0 ). Let K = K0 + 
i∈E∗Ki, G = 
i∈E∗(gi + gi) + 
i∈L∗gi, and
M = 2
√
KG. We also deﬁne for each i ≥0
Gi =
⎧
⎪
⎨
⎪
⎩
gi + gi,
if i ∈G∗,
gi,
if i ∈L∗,
Ki
(T ∗
0 )2 ,
if i ∈E∗∪{0},

7.3 A Single-Warehouse Multiretailer Model
133
Gi = gi + gi −Gi, and Mi = 2√KiGi. In this way, we can write B∗as
B∗= M +

i∈L∗∪G∗
Mi.
(7.8)
We now prove that B∗is a lower bound on any policy. We ﬁrst show that, in
fact, B∗= 
i≥0 Mi. From (7.8), we need only show that M = 
i∈E∗∪{0} Mi,
M = 2
√
KG = 2 K
T ∗
0
= 2

i∈E∗∪{0}
Ki
T ∗
0
= 2

i∈E∗∪{0}
Ki

Ki/Gi
= 2

i∈E∗∪{0}

KiGi
=

i∈E∗∪{0}
Mi.
Consider any policy over an interval [0, t′] for t′ > 0. We show that the total
cost associated with this policy over [0, t′] is at least B∗t′. Let mi be the number
of orders placed by facility i ≥0 in the interval [0, t′]. Let Ii(t) be the inventory
at facility i ≥1 at time t, and let Si(t) be the system inventory of facility i ≥1 at
time t. Clearly, the total inventory holding cost is

i≥1
 t′
0

hiIi(t) + h0Si(t)

dt.
We will show that this is no smaller than

i≥1
 t′
0

HiIi(t) + HiSi(t)

dt,
where Hi = 2Gi
Di and Hi = 2Gi
Di for each i = 0, 1, . . ., n. For this purpose, consider
the quantity HiIi(t) + HiSi(t) for each i ≥1. There are three cases to consider.
Case 1: i ∈G∗. Then Gi = gi+gi and Gi = gi+gi−Gi = 0, and since Si(t) ≥Ii(t)
for all t > 0, we have
hiIi(t) + h0Si(t) ≥HiIi(t) + HiSi(t).
Recall that hi = 2gi
Di , h0 = 2gi
Di , Hi = 2Gi
Di , and Hi = 2Gi
Di .
Case 2: i ∈L∗. Then Gi = gi and Gi = gi + gi −Gi = gi; hence,
hiIi(t) + h0Si(t) = HiIi(t) + HiSi(t).

134
7. Economic Lot Size Models with Constant Demands
Case 3: i ∈E∗. Then Gi =
Ki
(T ∗
0 )2 and Gi = gi+gi−Gi. Observe that, by deﬁnition,
if i ∈E, then τ′
i ≤T ∗
0 ≤τi, which implies gi ≤Gi ≤gi + gi. Since Si(t) ≥Ii(t)
for all t ≥0, then
hiIi(t) + h0Si(t) = HiIi(t) + HiSi(t) + (Hi −hi)(Si(t) −Ii(t))
≥HiIi(t) + HiSi(t).
(7.9)
Therefore, our lower bound on the inventory holding cost can be written as

i≥1
 t′
0

HiIi(t) + HiSi(t)

dt =

i≥0
 t′
0
HiIi(t)dt,
where we have deﬁned I0(t) =
1
H0

i≥1 HiSi(t).
Hence, the total cost per unit of time under this policy is at least
1
t′

i≥0

Kimi +
 t′
0
HiIi(t)dt

≥

i≥0

Ki
mi
t′ + Gi
t′
mi

≥2

i∈L∗∪G∗

KiGi + 2

i∈E∗∪{0}

KiGi
=

i≥0
Mi = B∗,
where the ﬁrst inequality follows from Property 7.1.1 and the fact that G0 =

i≥1 Gi (see Exercise 7.7). We have thus established that B∗is a lower bound on
the total cost per unit time of any policy.
Finally, for each i ∈G∗∪L∗, select a power-of-two policy (a value of k) such
that
1
√
2
T ∗
i ≤TB2k ≤
√
2T ∗
i .
For each i ∈E∗∪{0}, select a power-of-two policy (a value of k) such that
1
√
2T ∗
0 ≤TB2k ≤
√
2T ∗
0 .
It is a simple exercise (Exercise 7.4) to show that the policy constructed in this
manner has cost at most 1.06 times the cost of the lower bound.
7.4
Exercises
Exercise 7.1.
Consider the economic lot size model, and let K be the setup cost,
h the holding cost per item per unit of time, and D the demand rate. Shortage is

7.4 Exercises
135
not allowed and the objective is to ﬁnd an order quantity so as to minimize the
long-run average cost. That is, the objective is to minimize
C(Q) = KD
Q
+ hQ
2 ,
where Q is the order quantity. Suppose the warehouse can order only an integer
multiple of q units. That is, the warehouse can order q, or 2q, or 3q, and so on.
(a) Prove that the optimal order quantity Q∗has the following property. There
exists an integer m such that Q∗= mq and

m −1
m
≤Qe
Q∗≤

m + 1
m
,
where Qe, the economic order quantity, is
Qe =

2KD
h
.
(b) Suppose now that m ≥2. Show that C(Q∗) ≤1.06C(Qe).
Exercise 7.2.
(Zavi 1976) Consider the economic lot size model with inﬁnite
horizon and deterministic demand D items per unit of time. When the inventory
level is zero, production of Q items starts at a rate of P items per unit of time,
P ≥D. The setup cost is K$ and the holding cost is h$/item/time. Every time
production starts at a level of P items/time, we incur a cost of αP, α > 0.
(a) What is the optimal production rate?
(b) Suppose that due to technological constraints, P must satisfy 2D ≤P ≤3D.
What are the optimal production rate and the optimal order quantity?
Exercise 7.3.
Consider the economic lot size model over the inﬁnite horizon.
Assume that when an order of size Q is placed, the items are delivered by trucks
of capacity q, and thus the number of trucks used to deliver Q is ⌈Q
q ⌉, where ⌈m⌉is
the smallest integer greater than or equal to m. The setup cost is a linear function
of the number of trucks used: It is K0 +⌈Q
q ⌉K. The holding cost is h $/item/time,
and shortage is not allowed. What is the optimal reorder quantity?
Exercise 7.4.
Prove that the heuristic for the single-warehouse, multiretailer
model described in Sect. 7.3 provides a solution within 1.06 of the lower bound.
Exercise 7.5.
Consider the power-of-two policies described in the single-product
model of Sect. 7.1.3. Describe how you could generate a power-of-three policy (a
policy where each Ti = 3kTB for some integer k ≥0). What is the eﬀectiveness
(in terms of worst-case performance) of the best power-of-three policy?

136
7. Economic Lot Size Models with Constant Demands
Exercise 7.6.
(Porteus 1985) The Japanese concept of JIT (just-in-time) advo-
cates reducing setup cost as much as possible. To analyze this concept, consider
the economic lot size model with constant demand of D items per year, holding
cost h $ per item per year, and current setup cost K0. Suppose you can lease
a new technology that allows you to reduce the setup cost from K0 to K at an
annual leasing cost of A −Bln(K) dollars. That is, reducing the setup cost from
the current setup cost, K0, to K will annually cost A−Bln(K) dollars. Of course,
we assume that A −B ln(K0) = 0, which implies that using the current setup
cost requires no leasing cost. What is the optimal setup cost? What is the optimal
order quantity in this case?
Exercise 7.7.
Show that in the proof of the lower bound, B∗, for the single-
warehouse, multiretailer model, we have G0 = 
i≥1 Gi.
Exercise 7.8.
Prove (7.9).

8
Economic Lot Size Models
with Varying Demands
Our analysis of inventory models so far has focused on situations where demand
was both known in advance and constant over time. We now relax this latter
assumption and turn our attention to systems where demand is known in advance
yet varies with time. This is possible, for example, if orders have been placed
in advance, or contracts have been signed specifying deliveries for the next few
months. In this case, a planning horizon is deﬁned as those periods where demand
is known. Our objective is to identify optimal inventory policies for single-item
models as well as heuristics for the multi-item case. We also present extensions to
single-item models with price-dependent demand.
8.1
The Wagner–Whitin Model
Assume we must plan a sequence of orders, or production batches, over a T -period
planning horizon. In each period, a single decision must be made: the size of the
order or production batch.
We make the following assumptions:
• Demand during period t is known and denoted by dt > 0.
• The per-unit order cost is c and a ﬁxed order cost K is incurred every time
an order is placed; that is, if y units are ordered, the order cost is cy +Kδ(y)
[where δ(y) = 1 if y > 0, and 0 otherwise].
• There is a holding cost h > 0 per unit per period.
D. Simchi-Levi et al., The Logic of Logistics: Theory, Algorithms, and Applications
for Logistics Management, Springer Series in Operations Research and Financial Engineering,
DOI 10.1007/978-1-4614-9149-1 8, © Springer Science+Business Media New York 2014
137

138
8. Economic Lot Size Models with Varying Demands
• Initial inventory is zero.
• Lead times are zero; that is, an order arrives as soon as it is placed.
• All ordering and demand occur at the start of the period. Inventory holding
cost is charged on the amount on hand at the end of the period.
The problem is to decide how much to order in each period so that demands
are met without backlogging and the total cost, including the cost of ordering and
holding inventory, is minimized. This basic model was ﬁrst analyzed by Wagner
and Whitin (1958b) and has now been called the Wagner–Whitin model.
Let yt be the amount ordered in period t, and let It be the amount of product
in inventory at the end of period t. Using these variables, we can formulate the
problem as follows:
Problem WW : Min
T

t=1

Kδ(yt) + cyt + hIt

s.t.
It = It−1 + yt −dt,
t = 1, 2, . . ., T,
(8.1)
I0 = 0,
(8.2)
It, yt ≥0,
t = 1, 2, . . ., T .
(8.3)
Here constraints (8.1) are called the inventory-balance constraints, while (8.2) sim-
ply speciﬁes the initial inventory. Note that the inventory can also be rewritten
as It = t
i=1(yi −di), and therefore the It variables can be eliminated from the
formulation.
In the above model, it is clear that the total variable order cost incurred will be
ﬁxed and independent of the schedule of orders, and thus we ignore this cost in
our analysis until we talk about models with price-dependent demand.
Wagner and Whitin make the following important observation.
Theorem 8.1.1 Any optimal policy is a zero-inventory-ordering policy, that is, a
policy in which
ytIt−1 = 0, for t = 1, 2, . . ., T.
Proof. The proof is quite simple. By contradiction, assume there is an optimal
policy in which an order is placed in period t even though the inventory level at
the beginning of this period [It−1] is positive. We will demonstrate the existence
of another policy with a lower total cost. Evidently, the It−1 items of inventory
were ordered in various periods prior to t. Thus, if we instead order these items
in period t, we save all the holding cost incurred from the time they were each
ordered.
Thus, ordering only occurs when inventory is zero. A simple corollary is that
in an optimal policy, an order is of size equal to satisfy demands for an integer
number of subsequent periods.

8.1 The Wagner–Whitin Model
139
Using the above property, Wagner and Whitin developed a dynamic program-
ming algorithm to determine those periods when ordering takes place. By con-
structing a simple acyclic network with nodes V = {1, 2, . . ., T + 1}, we can view
the problem of determining a policy as a shortest-path problem. Formally, let ℓij,
the length of arc (i, j) in this network, be the cost of ordering in period i to
satisfy the demands in periods i, i + 1, . . ., j −1, for all 1 ≤i < j ≤T + 1. That is,
ℓij = K + h
j−1

k=i
(k −i)dk.
All other arcs have ℓij = +∞. The length of the shortest path from node 1 to
node T + 1 in this acyclic network is the minimal cost of satisfying the demands
for periods 1 through T . The optimal policy, that is, a speciﬁcation of the periods
in which an order is placed, can be easily reconstructed from the shortest path
itself. This procedure is clearly O(T 2).
Most of the assumptions made above can be relaxed without changing the basic
solution methodology. For example, one can consider problem data that are period-
dependent (e.g., ct, ht, or Kt). The assumption of zero lead times can be relaxed if
one assumes the lead times are known in advance and deterministic. In that case,
if an order is required in period t, then it is ordered in period t −L, where L is
the lead time.
Researchers have also considered order costs that are general concave functions
of the amount ordered, that is, ct(y). The problem can be formulated as a network
ﬂow problem with concave arc costs. This was the approach of Zangwill (1966),
who also extended the model to handle backlogging although the solution method
is only computationally attractive for small problems.
The Wagner–Whitin model can also be useful if demands during periods well
into the future are not known. This idea is embodied in the following theorem.
Theorem 8.1.2 Let t be the last period a setup occurs in the optimal order policy
associated with a T -period problem. Then for any problem of length T ∗> T , it is
necessary to consider only periods {j : t ≤j ≤T ∗} as candidates for the last setup.
Furthermore, if t = T , the optimal solution to a T ∗-period problem has yt > 0.
This result is useful since it shows that if an order is placed in period t, the optimal
policy for periods 1, 2, . . ., t −1 does not depend on demands beyond period t.
Surprisingly, even though the Wagner–Whitin solution procedure is extremely
eﬃcient, often simple approximate yet intuitive heuristics may be more appealing
to managers. For example, this may be the reason for the popularity of the Silver
and Meal (1973) heuristic or the part-period balancing heuristic of Dematteis
(1968). One important reason is the sensitivity of the optimal strategy to changes
in forecasted demands dt, t = 1, 2, . . ., T . Indeed, in practice, these forecasted
demands are typically modiﬁed “on the ﬂy.” These changes typically imply changes
in the optimal strategy. Some of the previously mentioned heuristics are not as
sensitive to these changes while producing optimal or near-optimal strategies. For
another approach, see Federgruen and Tzur (1991).

140
8. Economic Lot Size Models with Varying Demands
Researchers have shown that it is possible to take advantage of the special
cost structure in the Wagner–Whitin model and use it to develop faster exact
algorithms [i.e., O(T )]. This includes the work of Aggarwal and Park (1993) and
Park, Federgruen and Tzur (1991) and Wagelmans et al. (1992).
We sketch here the O(T ) algorithm of Wagelmans et al.,
which is the most
intuitive of those proposed. It is a backward dynamic programming approach.
Deﬁne dij = j
t=i dt for i, j = 1, 2, . . . , T , that is, the demand from period i to
period j. To describe the algorithm, we will slightly change the way we account
for the holding cost. If an item is ordered in period i, then we are charged Hi .=
(T −i + 1)h per unit. That is, we incur the holding cost until the end of the time
horizon. As long as we remember to subtract the constant h T
i=1 d1i from our
ﬁnal cost, then we are charged exactly the right amount. With this in mind, deﬁne
G(i) to be cost of an optimal solution with a planning horizon from period i to
period T , for i = 1, 2, . . . , T . For convenience, deﬁne G(T + 1) = 0. Then
G(i) =
min
i<t≤T +1{K + Hidi,t−1 + G(t)}
= K +
min
i<t≤T +1{Hidi,t−1 + G(t)}.
(8.4)
The ﬁnal cost is then G(1) −h T
i=1 d1i. Using this recursion, which is just a
reformulation of the shortest-path recursion discussed earlier, we clearly ﬁnd that
the complexity is O(T 2). Wagelmans et al.’s O(T ) algorithm is based on the crucial
observation that with careful implementation, the total amount of time spent
ﬁnding the period that minimizes (8.4) over the entire running of the algorithm
is O(T ).
Consider the calculation of G(i). It is useful to plot the points (djT , G(j)) for
j = i+1, i+2, . . ., T +1, where the point (dT +1,T , G(T +1)) is simply the origin. Let
E be the lower convex envelope of these points; then deﬁne the function g(x) = y
if and only if (x, y) ∈E. It is clear that g is a piecewise linear convex function on
[0, di+1,T ], with g(di+1,T ) = G(i + 1) and g(0) = 0. See Fig. 8.1.
Deﬁne the breakpoints of g to be all the points x where g changes slope in
addition to the points x = 0 and x = di+1,T . If x is a breakpoint, then x = djT
for some period j ∈{i + 1, i + 2, . . . , T + 1}. Let there be r breakpoints and let
i + 1 = t(1) < t(2) < . . . < t(r) = T + 1 denote the corresponding periods. These
periods are called eﬃcient because of the following.
Theorem 8.1.3
min
i<t≤T +1{Hidi,t−1 + G(t)} = min
1≤p≤r{Hidi,t(p)−1 + G(t(p))}.
Proof. Suppose that j (with i + 1 < j < T + 1) is not an eﬃcient period, and let k
and ℓ(with k < j < ℓ) be the two consecutive eﬃcient periods straddling j. The
slope of g on [dℓT , dkT ] is equal to [G(k) −G(ℓ)]/dk,ℓ−1; hence,
g(djT ) = G(ℓ) + G(k) −G(ℓ)
dk,ℓ−1
dj,ℓ−1.
Furthermore, G(j) ≥g(djT ).

8.1 The Wagner–Whitin Model
141
FIGURE 8.1. The plotted points and the function g
There are two cases to consider.
Case 1: Hi ≥G(k)−G(ℓ)
dk,ℓ−1
. Then
Hidi,j−1 + G(j) ≥Hidi,k−1 + Hidk,j−1 + g(djT )
≥Hidi,k−1 + G(k) −G(ℓ)
dk,ℓ−1
dk,j−1 + G(ℓ) + G(k) −G(ℓ)
dk,ℓ−1
dj,ℓ−1
= Hidi,k−1 + G(k).
Case 2: Hi < G(k)−G(ℓ)
dk,ℓ−1
. Then
Hidi,j−1 + G(j) ≥Hidi,ℓ−1 −Hidj,ℓ−1 + g(djT )
≥Hidi,ℓ−1 −G(k) −G(ℓ)
dk,ℓ−1
dj,ℓ−1 + G(ℓ) + G(k) −G(ℓ)
dk,ℓ−1
dj,ℓ−1
= Hidi,ℓ−1 + G(ℓ).
In both cases, the minimum occurs at an eﬃcient period.
Being able to quickly ﬁnd the eﬃcient period p that achieves the minimum is
therefore crucial to the complexity of the algorithm. This step is aided by the
following result.
Lemma 8.1.4 Let k and ℓ, k < ℓbe two consecutive eﬃcient periods. If
G(k) −G(ℓ)
dk,ℓ−1
< Hi,
then
Hidi,k−1 + G(k) < Hidi,ℓ−1 + G(ℓ);
otherwise,
Hidi,k−1 + G(k) ≥Hidi,ℓ−1 + G(ℓ).

142
8. Economic Lot Size Models with Varying Demands
Proof. Suppose that
G(k)−G(ℓ)
dk,ℓ−1
< Hi; then G(k) < Hidk,ℓ−1 + G(ℓ). Adding
Hidi,k−1 to both sides results in Hidi,k−1 + G(k) < Hidi,ℓ−1 + G(ℓ). The other
case can be shown in a similar fashion.
We now describe speciﬁcally how to ﬁnd the eﬃcient period achieving the min-
imum in (8.4). This is done by keeping an up-to-date list L of the current eﬃcient
periods. Let ℓ(p) be the index of the eﬃcient period immediately following eﬃcient
period p; that is, p < ℓ(p). From Lemma 8.1.4 and the convexity of g, it follows
that the value of j that achieves the minimum of
min
i<j≤T +1{Hidi,j−1 + G(j)}
corresponds to the period q(i) deﬁned by
q(i) .= min

T + 1, min

p ∈L | p < T + 1 and G(p) −G(ℓ(p))
dp,ℓ(p)−1
< Hi

,
because then
Hidi,p−1 + G(p) ≥Hidi,ℓ(p)−1 + G(ℓ(p)),
for p ∈L and p < q(i),
and
Hidi,p−1 + G(p) < Hidi,ℓ(p)−1 + G(ℓ(p)),
for p ∈L and p ≥q(i).
In fact, it is easy to determine q(i) from q(i + 1). Note that q(i + 1) ∈L and
as long as q(i + 1) is eﬃcient, it has the same successor ℓ(i + 1) in L. Using the
deﬁnition of q(i + 1), we obtain
G(q(i + 1)) −G(ℓ(q(i + 1)))
dq(i+1),ℓ(q(i+1))−1
< Hi+1 ≤Hi.
Hence, it follows that q(i) ≤q(i + 1); that is, the values of q(i) are decreasing in
i. Therefore, starting at q(i + 1), we successively decrement by one until we ﬁnd
q(i). The total amount of time spent searching for q(i) in the entire algorithm is
therefore O(T ).
To complete the complexity result, we must be able to quickly update the list of
eﬃcient periods, that is, update the lower convex envelope. After calculating G(i)
and plotting the point (diT , G(i)), we search for the smallest eﬃcient period t(s)
such that the slope of the line segment connecting (diT , G(i)) to (dt(s),T , G(t(s)))
is greater than the slope of the line segment connecting (dt(s+1),T , G(t(s + 1))) to
(dt(s),T , G(t(s))) (thus maintaining convexity). Then the new eﬃcient periods are
i and the periods from t(s) to t(r) ≡T + 1; the eﬃcient periods between i + 1 and
t(s)−1 become ineﬃcient. Since a period can become ineﬃcient at most once, one
can verify that the total amount of work spent updating the list L over the entire
algorithm is O(T ).

8.2 Models with Capacity Constraints
143
8.2
Models with Capacity Constraints
An important generalization of the Wagner–Whitin model is the inclusion of upper
bounds on the amount that can be ordered or produced in a given period. This
corresponds to adding the following constraints to Problem WW:
yt ≤Ct,
t = 1, 2, . . . , T.
(8.5)
The values Ct ≥0 correspond to the maximum amount that can be ordered (or
produced) in period t due to, for example, limited production capacities.
In this case, the problem is not as simple as before; Florian et al. (1980) show
that, in general, the problem is NP-Complete . Florian and Klein (1971) pro-
pose a dynamic programming approach that involves solving a sequence of acyclic
shortest-path problems for the special case where Ct = C for all t. Love (1973) de-
vises an algorithm based on characterizing the extreme points of the solution space
for the general problem. The branch-and-bound algorithm of Baker et al. (1978)
seems to be the most computationally eﬀective although it is not polynomial.
We sketch here the approach of Florian and Klein. For now, assume unequal
capacities; most of the structural results proved by Florian and Klein hold in this
more general case. Clearly, a feasible solution exists if and only if
i

j=1
Cj ≥
i

j=1
dj,
for i = 1, 2, . . ., T.
We therefore assume this is satisﬁed. Let
P = {y ∈IRT : y satisﬁes (8.1), (8.2), (8.3) and (8.5)},
and let D be the set of extreme points of P. Since the objective function is concave
(why?), we know an optimal solution will exist in D.
Florian and Klein prove the following inventory decomposition property.
Theorem 8.2.1 Suppose that the constraint
Ik = 0, for some k ∈[1, . . . , T −1],
is added to Problem WW and
i

j=k+1
Cj ≥
i

j=k+1
dj,
for i = k + 1, . . . , T
holds. Then an optimal solution to the original problem can be found by indepen-
dently ﬁnding solutions to the problems for the ﬁrst k periods and for the last T −k
periods.

144
8. Economic Lot Size Models with Varying Demands
This is clearly a generalization of Theorem 8.1.2. Following this idea, call a
period t a regeneration point if It = 0. Deﬁne a production sequence Sij, where
0 ≤i < j ≤T , to be
Sij = {(yi+1, yi+2, . . . , yj) | Ii = Ij = 0, Ik > 0 for i < k < j}.
Clearly, any production plan can be decomposed into a set of production sequences.
Deﬁne a production sequence Sij to be capacity-constrained if the production level
in at most one period k (i + 1 ≤k ≤j) satisﬁes 0 < yk < Ck and all other
production levels are either zero or at their capacities.
The authors then characterize the extreme points of P in the following way.
Theorem 8.2.2
y ∈D ⇐⇒y consists of capacity-constrained production sequences only.
This characterization is done in several steps. First:
Lemma 8.2.3 If y ∈D, then y consists only of capacity-constrained production
sequences.
Proof. Suppose y ∈D and Sij is a production sequence of y that is not capacity-
constrained. This means there are at least two periods, say k and ℓ(i + 1 ≤k <
ℓ≤j), in which 0 < yk < Ck and 0 < yℓ< Cℓ. Without loss of generality, we can
assume there are only two periods of this type.
Let
δ = 1
2 min{yk, Ck −yk, yℓ, Cℓ−yℓ,
min
i+1≤t<j It},
and let en be the (j −i)-component vector with a 1 in the nth position and 0s
everywhere else. Deﬁne two production sequences
S′
ij = Sij −δek−i + δeℓ−i
and
S′′
ij = Sij + δek−i −δeℓ−i.
Note that production sequence S′
ij simply represents a shifting of production from
period k to period ℓ, while sequence S′′
ij represents the opposite shift. They are
clearly feasible, and since δ > 0, they are distinct. However, Sij = 1
2(S′
ij + S′′
ij), a
contradiction.
Lemma 8.2.4 If y′ and y′′ are distinct feasible production plans and y = 1
2(y′ +
y′′), then y′ and y′′ share all the regeneration points of y.
Proof. Let period k be a regeneration point of y. Then
0 =
k

t=1
(yt −dt) = 1
2

k

t=1
(y′
t −dt) +
k

t=1
(y′′
t −dt)

= 1
2(I′
k + I′′
k ).
Since I′
k, I′′
k ≥0, both I′
k and I′′
k must be zero.

8.2 Models with Capacity Constraints
145
Lemma 8.2.5 If a feasible plan y consists only of capacity-constrained production
sequences, then y ∈D.
Proof. Assume to the contrary that y ̸∈D. Then there exist feasible plans y′ and
y′′ such that y = 1
2(y′ + y′′).
From Lemma 8.2.4, y′ and y′′ share the regeneration points of y. Let i and j be
two such successive regeneration points, and let Sij, S′
ij, and S′′
ij be the associated
distinct production sequences of y, y′, and y′′, respectively. Evidently,
Sij = 1
2(S′
ij + S′′
ij).
We show that the only possibility is Sij = S′
ij = S′′
ij. For this purpose, consider any
period k, i + 1 ≤k ≤j, and observe that yk can take only three possible values.
Either yk = 0, in which case y′
k = y′′
k = 0, or yk = Ck, in which case y′
k = y′′
k = Ck
or 0 < yk < Ck. Since Sij is a capacity-constrained sequence, at most one period,
say period ℓ, i + 1 ≤ℓ≤j, has 0 < yℓ< Cℓ. But the total production between
period i + 1 and period j must be equal to total demands over the same periods,
and hence yℓ= y′
ℓ= y′′
ℓ. Consequently, Sij = S′
ij = S′′
ij.
This completes the proof of Theorem 8.2.2.
It is now clear that an optimal solution must be made up of a sequence of
optimal capacity-constrained production sequences. However, determining these
sequences can be quite tedious and computationally expensive. To make the prob-
lem tractable, Florian and Klein consider the case where the capacity constraints
are identical and equal to C. The demand between any two periods, say periods i
and j, can then be written as mC + p, where m is an integer and p < C. Then
Corollary 8.2.6 If Ct = C for all t, an optimal production sequence has a number
of periods in which the production levels are equal to C, at most one period where
the production level is 0 < p < C, and the remaining periods have zero production
levels.
This simpliﬁes the problem considerably; for example, consider determining the
optimal production sequence between regeneration points i and j. From Corol-
lary 8.2.6, in each period k ∈{i + 1, i + 2, . . . , j}, the production is 0, C, or p for
some p ∈(0, C). Let Yk = k
ℓ=i+1 yk, for i < k ≤j, that is, the amount produced
between periods i + 1 and k in this production sequence. Then Yk can only take
on values in {0, p, C, C + p, 2C, . . . , mC, mC + p}.
Thus, we can construct a network where the vertices correspond to the possible
values of Yk for each i < k ≤j with directed edges (Yk, Yk+1) deﬁned by the
following:
• If Yk = ℓC, ℓ= 0, 1, . . ., m, then there are three edges emanating from this
vertex: one to Yk+1 = ℓC (corresponding to no production in period k); one
to Yk+1 = ℓC + p (corresponding to production of p in period k); and one to
Yk+1 = (ℓ+ 1)C (corresponding to production of C in period k).

146
8. Economic Lot Size Models with Varying Demands
• If Yk = ℓC +p, ℓ= 0, 1, . . . , m, then there are two edges emanating from this
vertex: one to Yk+1 = ℓC + p (corresponding to no production in period k)
and one to Yk+1 = (ℓ+1)C+p (corresponding to production of C in period k).
After creating an artiﬁcial initial vertex Y0, we see that every path from Y0 to
Yj represents a feasible capacity-constrained production sequence. If we assign
arc costs equal to the cost of producing and storing the corresponding product
amounts, it is clear that ﬁnding the optimal production sequence from i to j is no
harder than solving the shortest-path problem on this network. The complexity of
this procedure is clearly proportional to (j−i)2, thus determining that the optimal
production sequence between all pairs of periods is O(T 4).
To determine the optimal production plan over the entire planning horizon,
Florian and Klein solve another shortest-path problem on a network similar to
the one formulated in Sect. 8.1. That is, the length of an arc (i, j) in this network
is the total cost of the optimal production sequence from i to j. After solving
the shortest-path problem, we can ﬁnd the optimal set of regeneration points by
checking the shortest path. This step is O(T 2).
8.3
Multi-Item Inventory Models
In many practical situations, the coordination of inventory and ordering policies
involves a variety of diﬀerent products, and this complicates the problem consider-
ably. Consider the uncapacitated case once again, and assume there are n products.
Each product faces a known demand during the next T periods. In addition, a ﬁxed
order cost of Ki is incurred every time product i is ordered.
For each product i, deﬁne the following:
• Let yit be the amount of product i ordered in period t, for t = 1, 2, . . ., T .
• Let hi be the inventory holding cost for product i.
• Let Iit be the amount of product i in inventory at the start of period t, for
t = 1, 2, . . ., T .
• Let dit be the demand in period t for product i, for t = 1, 2, . . . , T .
If we make the same assumptions as in the Wagner–Whitin model, the problem
is then
Problem P : Min
T

t=1
n

i=1

Kiδ(yit) + hiIit

s.t. Iit = Ii,t−1 + yit −dit,
i = 1, 2, . . . , n, t = 1, 2, . . ., T,
(8.6)
Ii0 = 0,
i = 1, 2, . . . , n,
(8.7)
Iit, yit ≥0,
i = 1, 2, . . ., n, t = 1, 2, . . . , T.
(8.8)
Here (8.6) are inventory-balance constraints for each product, while (8.7) specify
the starting inventory for each product.

8.3 Multi-Item Inventory Models
147
It is easy to see that P decomposes into m single-product problems. Each of
these single-product problems can be solved using the algorithms for the Wagner–
Whitin model.
A more realistic version of this problem is when a joint setup cost K0 is present.
This cost is incurred whenever any product is ordered. The problem then becomes
Problem P ′ :
Min
T

t=1

K0δ(
n

i=1
yit) +
m

i=1

Kiδ(yit) + hiIit

s.t. (8.6), (8.7), and (8.8).
Unfortunately, this problem is considerably more diﬃcult to solve than the
simple Wagner–Whitin model. In fact, Arkin et al. (1989) prove that it is NP-
Complete. Several researchers have proposed heuristics for this problem, includ-
ing Silver (1976), Atkins and Iyogun (1988), and Joneja (1990). We present here
Joneja’s approach.
Joneja’s cost-covering heuristic proceeds period by period in a forward direction.
Speciﬁcally, at period t, the ordering policy of periods 1, 2, . . ., t −1 has been
determined and the decision is which items to order, if any, in period t. Let ti be
the last period in which item i was ordered. Let Hit denote the total inventory
holding cost incurred by item i since period ti assuming no order for item i is
placed in period t. That is,
Hit = hi
t

j=ti+1
(j −ti)dij.
Intuitively, if we forget for the moment the joint order cost and Hit > Ki, then
it is worth ordering item i in period t, since it costs more to keep an item in
inventory from period ti (the last time item i was ordered) to t than to order it
in period t. The quantity max{Hit −Ki, 0} can be seen as the savings that are
accrued by ordering item i in period t. This approach is basically the Silver–Meal
heuristic adapted to the multiple-item case. With the joint order cost present, an
order should be placed only if the total savings accrued by ordering a set of items
in period t exceeds the joint order cost. Therefore, Joneja proposes the following
ordering rule.
Rule 1. In period t, order those items i such that Hit ≥Ki if n
i=1 max{Hit −
Ki, 0} ≥K0.
Joneja shows that this single rule is not quite strong enough to ensure that the
schedule of orders is cost-eﬃcient. For instance, consider the following example
with two products. The holding costs are equal (h1 = h2 = 1). Pick an integer m
and set the demands to

148
8. Economic Lot Size Models with Varying Demands
d1t = 0, for t = 1, 2, . . . , m −1,
d1m = K0 + K1
m −1 ,
d2t = 0, for t = 1, 2, . . . , m,
d2,m+1 = K0 + K2
m
.
With Rule 1, item 1 will be ordered at time m, but not item 2. Item 2 will
be ordered at time m + 1. If both items were ordered at time m, then we pay
h2d2,m+1 = K0+K2
m
in extra holding costs but save K0 in ordering costs. Therefore,
for large m, we see that we can be far from optimal.
To counteract this behavior, Joneja proposes the following additional feature.
Let t0 be the time at which the last joint order was placed, and assume item i was
not included in this order (since Hit0 < Ki). It may, in some cases, be advantageous
to order item i at time t0 even though Rule 1 would specify the opposite. Deﬁne
Sit = hi(t0 −ti)
t

j=t0
dij.
Then Sit is the savings in inventory holding cost accrued by ordering item i at
time t0. Since a joint order is already placed in period t0, the following rule was
proposed.
Rule 2. In period t, if the last joint order was in period t0, item i was not ordered
in period t0, and Sit ≥Ki, then order item i in period t0.
Computational
experiments
with
this
heuristic,
whose
complexity
is
O(nT ), show that it produces solutions fairly close to optimal.
8.4
Single-Item Models with Pricing
The previous models focusing solely on inventory replenishment can be naturally
extended to settings in which demand is endogenously determined by pricing deci-
sions. For simplicity, we only consider the extension of Problem WW. Speciﬁcally,
assume that at the beginning of period t (t = 1, 2, . . ., T ), we can set a selling price
pt in addition to the ordering quantity yt. The demand in period t is assumed to
be a continuous function of the current period selling price pt, denoted as dt(pt).
We are now facing an integrated inventory and pricing model. The objective is to
ﬁnd a sequence of order quantities xt and prices pt so as to maximize the total
proﬁt over the planning horizon.

8.4 Single-Item Models with Pricing
149
Upon denoting a pricing plan (p1, p2, . . . , pT ) and its corresponding demand
sequence (d1(p1), d2(p2), . . . , dT (pT )), we ﬁnd that a mathematical model for the
integrated inventory and pricing problem is
Max
T
t=1 ptdt(pt) −C(d1(p1), d2(p2), . . . , dT (pT ))
s.t.
pt ∈[pt, pt], t = 1, 2, . . ., T,
(8.9)
where a lower bound pt and an upper bound pt on the selling price pt are imposed
to prevent a low proﬁt margin and an unreasonable high price, respectively. In
the objective function of the above problem, the ﬁrst term is the total revenue,
and the second term C(d1(p1), d2(p2), . . . , dT (pT )) is the minimum ordering and
inventory holding cost over the planning horizon for a given pricing plan, which is
the optimal objective value of Problem WW when (d1, d2, . . . , dT ) is replaced by
(d1(p1), d2(p2), . . . , dT (pT )). Notice that unlike the models in the previous sections,
the variable order cost cannot be ignored here.
To develop an eﬃcient algorithm, observe that Theorem 8.1.1 still holds; that is,
any optimal replenishment policy is a zero-inventory-ordering policy. To see this,
simply note that given any ﬁxed price sequence (p1, p2, . . . , pT ), Problem (8.9) is
equivalent to Problem WW. It is clear that for any ordering plan with the zero-
inventory-ordering property, it suﬃces to specify the ordering periods. Speciﬁcally,
if periods i and j (i < j) are two consecutive ordering periods in such an ordering
plan, the zero-inventory-ordering property implies that the demand at period t
(i ≤t < j) is ﬁlled by the order placed at period i only, and thus the marginal
cost of satisfying period t’s demand is given by c+(t−i)h. The associated optimal
price for period t with i ≤t < j can then be derived, independent of other periods’
prices, by solving the following optimization problem:
vit =
max
ptdt(pt) −(c + (t −i)h)dt(pt)
s.t.
pt ∈[pt, pt],
(8.10)
where the objective function is the proﬁt of period t, when taking into account the
marginal cost of satisfying the demand of that period. The dynamic programming
algorithm of Wagner and Whitin can be easily adopted here. We can construct
the same acyclic network. The only diﬀerence is that when we deﬁne the acyclic
network, the length of arc (i, j) with 1 ≤i < j ≤T + 1 is given by
ℓij = K −
j−1

t=i
vit,
which is the negative of the maximum total proﬁt obtained from satisfying demand
from period i to period j−1 with a single order at period i. With this modiﬁcation,
the length of a shortest path from node 1 to node T + 1 in the acyclic network
gives the negative of the maximum total proﬁt over the planning horizon. The
optimal ordering periods can be easily reconstructed from the shortest path, and
the optimal prices can be derived through Problem (8.10) once the corresponding
ordering periods are known. The algorithm involves solving O(T 2) single-variable

150
8. Economic Lot Size Models with Varying Demands
optimization problems of the form (8.10) and ﬁnding a shortest path in the acyclic
network that can be done in O(T 2).
The extension presented here ﬁrst appeared in Wagner and Whitin (1958a)
around the same time they developed Problem WW. The algorithm in Sect. 8.2
can also be easily modiﬁed to deal with integrated inventory and pricing models
with capacity constraints. We refer to Deng and Yano (2006), Geunes et al. (2006),
and Chen and Simchi-Levi (2012) for details. For integrated inventory and pricing
models with stochastic demand, see Chap. 10.
8.5
Exercises
Exercise 8.1. Assume order costs are general concave and time-dependent func-
tions of the number of items produced. Also, assume holding costs are general
concave and time-dependent functions of the number of items held in inventory.
Prove that the zero-inventory-ordering property holds in this general setting as
well.
Exercise
8.2. The
Silver–Meal
heuristic
works
as
follows.
Let
d1, d2,
. . . , dn be the demands in the n-period planning horizon. Deﬁne C(T ) to be the
per-period average holding and setup cost under the condition that the current
order covers demand in the next T periods. Then C(1) = K, C(2) = 1
2(K + hd2),
and so on. In the Silver–Meal heuristic, we calculate these until C(i) > C(i −1).
In this case, we stop and produce in period 1 to meet the demand of the ﬁrst i −1
periods. We then start over with the ith period.
Construct an example where the Silver–Meal heuristic provides a nonoptimal
solution.
Exercise 8.3. Consider the integrated inventory and pricing model in Sect. 8.4
with one additional requirement that the prices are the same throughout the plan-
ning horizon. Develop an eﬃcient algorithm to solve it. Can you extend your
algorithm to cases in which the parameters are time-dependent?

9
Stochastic Inventory Models
9.1
Introduction
The inventory models considered so far are all deterministic in nature; demand
is assumed to be known and either constant over the inﬁnite horizon or varying
over a ﬁnite horizon. In many logistics systems, however, such assumptions are not
appropriate. Typically, demand is a random variable whose distribution may be
known.
Stochastic inventory models have attracted considerable attention in the last
three decades. The pioneering work of Arrow, Harris and Marschak (1951), Scarf
(1960), Iglehart (1963a and b), and Veinott and Wagner (1965) for a single ware-
house, Clark and Scarf (1960) for multi-echelon systems, Eppen and Schrage (1981)
and Federgruen and Zipkin (1984a–c) for distribution systems, and Rosling (1989)
for assembly systems all represent milestones in our understanding of complex
stochastic logistics systems. More recently, the works of Zheng (1991), Zheng and
Federgruen (1991), Chen and Zheng (1994), and Zipkin (2008) reveal new insights
and provide more eﬃcient algorithms for these problems. For recent reviews, we
refer the reader to Lee and Nahmias (1993), Porteus (1990), and Zipkin (2000).
In this chapter, we review some of the main results in stochastic inventory
models. We start with the analysis of a single-warehouse model. To build our int-
uition, Sect. 9.2 considers a single-period model. In Sects. 9.3 and 9.4, we show
that the insight obtained in the previous section can be used to analyze a mul-
tiperiod model. Section 9.5 extends the analysis further to the inﬁnite-horizon
D. Simchi-Levi et al., The Logic of Logistics: Theory, Algorithms, and Applications
for Logistics Management, Springer Series in Operations Research and Financial Engineering,
DOI 10.1007/978-1-4614-9149-1 9, © Springer Science+Business Media New York 2014
151

152
9. Stochastic Inventory Models
model. Models with positive lead times are addressed in Sect. 9.6. Finally, Sect. 9.7
describes the development of interesting bounds on the optimal cost for multi-
echelon systems.
9.2
Single-Period Models
9.2.1
The Model
Consider a risk-neutral company that designs, produces, and sells winter fashion
items such as ski jackets and coats. About six months before the winter season, the
company must commit itself to speciﬁc production quantities for all its products.
Since there is no clear indication as to how the market will respond to the new
designs, these decisions are typically based on realized sales from the last few years,
current economic conditions, and professional judgment.
To assist management in selecting production quantities, the marketing depart-
ment assumes that demand D for each new product is randomly distributed, gen-
erated from a product-speciﬁc distribution with continuous cdf F(·). Additional
information available to the decision makers includes the variable production cost
per unit c, the selling price per unit r, and the salvage value per unit v. Clearly,
these variables should satisfy r > c > v; otherwise, the problem can trivially be
solved.
Since demand is a random variable, the decision concerning how many units
to produce is based on the expected cost z(y), which is a function of the amount
produced, y. This expected cost is
z(y) = cy −rE[min(y, D)] −vE[max(0, y −D)]
for y ≥0,
where E(·) denotes the expectation. Note that
E[min(y, D)] =
 y
0
DdF(D) + y
 ∞
y
dF(D).
Adding and subtracting the quantity r
 ∞
y DdF(D) to z(y), we get
z(y) = cy −rE[D] −r
 ∞
y
(y −D)dF(D) −v
 y
0
(y −D)dF(D).
(9.1)
The objective is, of course, to choose y so as to minimize the expected cost z(y).
This is known as the newsboy problem or newsvendor problem.
Taking the derivative of z(y) with respect to y and using the Leibnitz rule, we
get the ﬁrst-order optimality condition:
c −r(1 −Pr{D ≤y}) −v Pr{D ≤y} = 0,
which implies that the optimal production quantity S should satisfy
Pr{D ≤S} = r −c
r −v .

9.3 Finite-Horizon Models
153
Since, by assumption, r−c < r−v and F(D) is continuous, a ﬁnite value S, S > 0,
always exists. In addition, it can easily be veriﬁed that the expected cost z(y) is
convex
for y ∈(0, ∞) and that the value of z(y) tends to inﬁnity as y →∞.
Hence, the quantity S is a minimizer of z(y).
Observe that, implicitly, three assumptions have been made in the above anal-
ysis. First, there is no initial inventory. Second, there is no ﬁxed setup cost for
starting production. Third, the excess demand is lost; that is, if the demand D
happens to be greater than the produced quantity y, then the additional revenue
r(D −y) is lost.
The tools developed so far allow us to extend the above results to models with
initial inventory y0 and setup cost K. We now relax the ﬁrst two assumptions.
Observe that the expected cost of producing (y −y0) units is
K −cy0 + z(y).
Hence, S clearly minimizes this expected cost if we decide to produce. Conse-
quently, there are two cases to consider.
1. If y0 ≥S, we should not produce anything.
2. If y0 < S, the best we can do is to raise the inventory to level S. However,
this is optimal only if −cy0 + z(y0), the cost associated with not producing
anything, is larger than or equals K −cy0 + z(S), the cost associated with
producing S −y0. That is, if y0 < S, it is optimal to produce S −y0 only if
z(y0) ≥K + z(S).
Let s be a number such that
z(s) = K + z(S).
The discussion above implies that the optimal policy is of the (s, S) type.
Deﬁnition 9.2.1 An (s, S) policy is a policy in which we order S−y0 if the initial
inventory level y0 is at or below s, and do not order otherwise.
The quantity S is called the order-up-to level, while s is referred to as the reorder
point. In the special case with zero ﬁxed ordering cost, we have s = S and the
policy reduces to a base stock policy: When the initial inventory level is no more
than S, make an order to raise the inventory level to S; otherwise, no order is
placed.
9.3
Finite-Horizon Models
9.3.1
Model Description
We are now ready to consider the ﬁnite-horizon (multiperiod) inventory problem.
This problem can be described as follows. At the beginning of each period, for exa-
mple, each week or every month, the inventory of a certain item at the warehouse

154
9. Stochastic Inventory Models
is reviewed and the inventory level is noted. Then an order may be placed to raise
the inventory level up to a certain level. Replenishment orders arrive instantly.
The cases with the nonzero lead times will be discussed in Sect. 9.6.
We assume that demands for successive periods are independently and iden-
tically distributed (iid). If the demand exceeds the inventory on hand, then the
additional demand is backlogged and is ﬁlled when additional inventory becomes
available. Thus, the backlogged units are viewed as negative inventory. The inv-
entory left over at the end of the ﬁnal period has a value of c per unit, and all
unﬁlled demand at this time can be backlogged at the same cost c. As we shall
see, these assumptions ensure that the expected (gross) revenue in each period is
a constant, and therefore we will not include the revenue term in our formulation.
Lost sales models are addressed in 9.6.
Costs include ordering, holding, and backorder costs. Ordering cost consists of
a setup cost, K, charged every time the warehouse places a replenishment order,
and a proportional purchase cost c. There are a holding cost of h+ for each unit
of the inventory on hand at the end of a period and a backorder cost of h−per
unit whenever demand exceeds the inventory on hand. To avoid triviality, we
assume h−, h+ > 0 (why?). The objective is to determine an inventory policy that
minimizes the expected cost over T periods. In what follows, we show that an
(st, St) policy is optimal. Of course, an (st, St) policy is similar to the (s, S) policy
described earlier except that the parameters s and S may vary from period to
period.
To characterize the optimal policy for the ﬁnite-horizon model, we ﬁrst develop
a dynamic programming formulation of the problem. Let xt be the inventory level
at the beginning of period t (before possible ordering).
If the inventory level immediately after ordering is y, then the expected one-
period inventory holding and backorder cost for that period is
G(y) = h+

D
max(y −D, 0)dF(D) + h−

D
max(D −y, 0)dF(D),
(9.2)
which is called the one-period loss function. Since the maximum of convex func-
tions is convex and convexity is preserved under integration, we see that G(y) is
convex.
Given a policy Y = (y1, y2, · · · , yT ), where yt is the order-up-to level (random
variable) of period t and may be contingent upon other variables, the sum of the
total expected proportional purchasing cost and salvage value P is given by
P = E

T

t=1
c(yt −xt) −c(yT −DT )

,
where Dt is the realized demand in period t. Noting that xt+1 = yt −Dt, we have
P = cE[y1 −x1 + y2 −(y1 −D1) + · · · + yT −(yT −1 −DT −1) + DT −yT ]
= cT E[D].

9.3 Finite-Horizon Models
155
Thus, P is independent of the ordering policy, and we can drop oﬀthe linear
ordering cost component from the formulation. This observation is quite intuitive,
since all backlogged demand is ﬁlled at the end of the last period, while all rem-
aining inventory left at this period is salvaged, both at the same price c. We also
remark that whenever possible, we will suppress the subscript t from Dt (because
demands are iid) and yt.
Recall that xt is the inventory level, prior to ordering, at the beginning of per-
iod t. To formulate the dynamic program, deﬁne the following two expected cost
functions. Let Gt(xt) be the expected cost for the remaining T −t + 1 periods if
we do not order in period t, and act optimally in the remaining T −t periods.
Let zt(xt) be the minimal expected cost incurred through the remaining T −t + 1
periods if we act optimally in period t and all the remaining T −t periods. It follows
that for t = 1, 2, . . . , T ,
Gt(y) = G(y) +

D
zt+1(y −D)dF(D)
(9.3)
and
zt(x) = Miny≥x
{Kδ(y −x) + Gt(y)},
(9.4)
where zT +1(x) = 0 for any x, and δ(u) is 1 if u > 0 and it is 0 otherwise.
Note that if we order up to the level y > xt in period t, the cost for the ﬁnal
T −t + 1 periods is K + Gt(y).
Notice that the functions Gt(y) and zt(y) are not convex and may even have
many local minima. In order to show that an (s, S) policy is optimal for this model,
we employ the concept of K-convexity, introduced by Scarf (1960), which provides
us with a powerful tool to analyze stochastic inventory models with ﬁxed ordering
cost.
9.3.2
K-Convex Functions
Deﬁnition 9.3.1 A real-valued function f is called K-convex for K ≥0 if, for
any x0 ≤x1 and λ ∈[0, 1],
f((1 −λ)x0 + λx1) ≤(1 −λ)f(x0) + λf(x1) + λK.
(9.5)
Below we summarize properties of K-convex functions.
Lemma 9.3.2
(a) A real-valued convex function is also 0-convex and hence K-
convex for all K ≥0. A K1-convex function is also a K2-convex function
for K1 ≤K2.
(b) If f1(y) and f2(y) are K1-convex and K2-convex, respectively, then for α, β ≥
0, αf1(y) + βf2(y) is (αK1 + βK2)-convex.
(c) If f(y) is K-convex and ζ is a random variable, then Eζ[f(y −ζ)] is also
K-convex, provided E[|f(y −ζ)|] < ∞for all y.

156
9. Stochastic Inventory Models
(d) Assume that f is a continuous K-convex function and f(y) →∞as |y| →∞.
Let S be a minimum point of f and s be any element of the set
{x|x ≤S, f(x) = f(S) + K}.
Then the following results hold.
(i) f(S) + K = f(s) ≤f(y), for all y ≤s.
(ii) f(y) is a nonincreasing function on (−∞, s).
(iii) f(y) ≤f(z) + K for all y, z with s ≤y ≤z.
Proof. Parts (a), (b), and (c) are straightforward and are left as an exercise. Hence,
we focus on part (d).
Let S be a minimum point of function f and let s be any element of the set
{x|x ≤S, f(x) = f(S) + K}.
The existence of s and S is guaranteed since f is continuous and f(y) →∞as
|y| →∞.
Consider any y and y′ with y ≤y′ ≤s; there exists a λ ∈[0, 1] such that
y′ = (1 −λ)y + λS. The K-convexity of the function f(x) implies that
f(y′) ≤(1 −λ)f(y) + λ(f(S) + K) = (1 −λ)f(y) + λf(s).
(9.6)
Part (d) (i) follows from (9.6) upon letting y′ = s, which immediately implies part
(d) (ii).
Finally, consider any y and z with s ≤y ≤z. If y ≤S, there exists a λ ∈[0, 1]
such that y = (1 −λ)s + λS. Since f(x) is K-convex and S is a global minimizer
of the function f, we have
f(y) ≤(1 −λ)(f(s) −K) + λf(S) + K = f(S) + K ≤f(z) + K.
If y ≥S, there exists a λ ∈[0, 1] such that y = (1 −λ)S + λz. Again, the K-
convexity of the function f and the deﬁnition of S imply that
f(y) ≤(1 −λ)f(S) + λf(z) + λK ≤f(z) + K.
Figure 9.1 gives an illustration of the properties of K-convex functions in
Lemma 9.3.2 part (d).
Proposition 9.3.3 If f(x) is a K-convex function, then function
φ(x) = Miny≥x
Qδ(y −x) + f(y)
is max{K, Q}-convex.

9.3 Finite-Horizon Models
157
FIGURE 9.1. Illustration of the properties of K-convex functions
Proof. We only need to discuss the case K ≥Q. In fact, when K ≤Q, the K-
convexity of f(x) implies the Q-convexity of f(x), and the Q-convexity of the
function φ(x) follows from the case for K ≥Q. Hence, we assume that K ≥Q.
Let E = {x | φ(x) = f(x)} and O = {x | φ(x) < f(x)}. We show that for any
x0, x1 and λ ∈[0, 1] with x0 ≤x1,
φ(xλ) ≤(1 −λ)φ(x0) + λφ(x1) + λK,
where xλ = (1 −λ)x0 + λx1. We consider four diﬀerent cases.
Case 1: x0, x1 ∈E. In this case,
φ(xλ)
≤
f(xλ)
≤
(1 −λ)f(x0) + λf(x1) + λK
=
(1 −λ)φ(x0) + λφ(x1) + λK,
where the second inequality follows from the K-convexity of the function f(x).
Case 2: x0, x1 ∈O. In this case, let φ(xi) = Q + f(yi) for i = 0, 1 with yi ≥xi
and let yλ = (1 −λ)y0 + λy1. It is clear that y0 ≤y1 and yλ ≥xλ. Furthermore,
φ(xλ)
≤
Q + f(yλ)
≤
(1 −λ)(Q + f(y0)) + λ(Q + f(y1)) + λK
=
(1 −λ)φ(x0) + λφ(x1) + λK,
where the second inequality follows from the K-convexity of the function f(x).
Case 3: x0 ∈E, x1 ∈O. Let φ(x1) = Q + f(y1) with y1 ≥x1. Let xλ = (1 −
μ)x0 + μy1 with μ ≤λ. Then
φ(xλ)
≤
f(xλ)
≤
(1 −μ)f(x0) + μf(y1) + μK
=
(1 −λ)φ(x0) + λφ(x1) + μK
+
(λ −μ)(f(x0) −f(y1)) −λQ
≤
(1 −λ)φ(x0) + λφ(x1) + μK −λQ + (λ −μ)Q
≤
(1 −λ)φ(x0) + λφ(x1) + λK,

158
9. Stochastic Inventory Models
where the second inequality follows from the K-convexity of the function f(x) and
the third inequality holds since f(x0) ≤Q + f(y1).
Case 4: x0 ∈O, x1 ∈E. Let φ(x0) = Q + f(y0) for y0 ≥x0. We distinguish
between two diﬀerent cases.
Subcase 1: xλ ≤y0. In this case,
φ(xλ)
≤
Q + f(y0)
=
(1 −λ)(Q + f(y0)) + λf(x1) + λ(Q + f(y0) −f(x1))
≤
(1 −λ)φ(x0) + λφ(x1) + λQ,
where the last inequality holds since f(y0) ≤f(x1).
Subcase 2: xλ ≥y0. Let xλ = (1 −μ)y0 + μx1 with μ ≤λ. Then
φ(xλ)
≤
f(xλ)
≤
(1 −μ)f(y0) + μf(x1) + μK
=
(1 −λ)φ(x0) + λφ(x1) + μK
+
(λ −μ)(f(y0) −f(x1)) −(1 −λ)Q
≤
(1 −λ)φ(x0) + λφ(x1) + λK,
where the second inequality follows from the K-convexity of the function f(x) and
the last inequality holds since f(y0) ≤f(x1).
9.3.3
Main Results
It remains to show that an (st, St) policy is optimal for every t, t = 1, 2, . . . , T .
For this purpose, it is suﬃcient to prove that the function Gt(y) is K-convex, and
Gt(y) →∞as |y| →∞, for each period t, t = 1, 2, . . ., T .
Theorem 9.3.4
(a) For any t = 1, 2, . . . , T , Gt(y) and zt(y) are continuous
and lim|y|→∞Gt(y) = ∞.
(b) For any t = 1, 2, . . . , T , Gt(y) and zt(y) are K-convex.
(c) For any t = 1, 2, . . . , T , there exist two parameters st and St such that it is
optimal to make an order to raise the inventory level to St when the initial
inventory level is no more than st and to order nothing otherwise.
Proof. We prove by induction. For t = T , GT (y) = G(y) for all y. Hence, GT (y) is
continuous and K-convex (in fact, convex), and lim|y|→∞GT (y) = ∞.
Assume that Gt(y) is continuous and K-convex, and lim|y|→∞Gt(y) = ∞. Then
Lemma 9.3.2 part (d) allows us to show that there exist two parameters st and St
with st ≤St such that St minimizes Gt(y) and Gt(st) = Gt(St)+K. Furthermore,
zt(y) =

K + Gt(St), if y ≤st,
Gt(y), otherwise.

9.4 Quasiconvex Loss Functions
159
Since Gt(st) = Gt(St) + K, zt(y) is continuous and Proposition 9.3.3 implies that
zt(y) is K-convex.
Finally, Gt−1(y) = G(y) + E[zt(y −D)]. Therefore, Gt−1(y) is continuous, and
from Lemma 9.3.2 part (c), Gt−1(y) is K-convex. Moreover, lim|y|→∞Gt−1(y) =
∞, since zt(y) ≥Gt(St) for any y.
So far we assume that demands are identically distributed and the cost parame-
ters, c, h+ and h−, are time-independent. These assumptions can be easily relaxed
and an (s, S) policy is still optimal. Indeed, in Chap. 10, we analyze the ﬁnite-
horizon inventory and pricing model, including the inventory model analyzed in
this section as a special case, under more general assumptions.
9.4
Quasiconvex Loss Functions
The above proof on the optimality of (st, St) policies relies on the fact that the one-
period loss function G(y) is convex. In many practical situations, this assumption
is not appropriate. For instance, consider the previous model, but assume that
whenever a shortage occurs, an emergency shipment is requested. Suppose further
that this emergency shipment incurs a ﬁxed cost plus a linear cost proportional
to the shortage level. It can be easily shown that the new loss function G(y) is, in
general, not convex.
To overcome this diﬃculty, Veinott (1966) oﬀers a diﬀerent yet elegant proof for
the optimality of (st, St) policies under the assumption that G(y) is quasiconvex.
Here we provide a slightly simpliﬁed proof suggested by Chen (1996) for the model
considered here. Recall the concept of quasiconvexity. A function f is quasiconvex
on a convex set X if for any x and y ∈X and 0 ≤λ ≤1,
f(λx + (1 −λ)y) ≤max{f(x), f(y)}.
As we already pointed out in Chap. 2, a convex function is also quasiconvex, and
f is quasiconvex if
−f(x) is unimodal.
Consider the dynamic program (9.3)–(9.4). In the analysis below, we use the
following assumptions on G(y).
(i) G(y) is continuous and quasiconvex.
(ii) G(y) > infx G(x) + K as |y| →∞.
Other assumptions on ordering costs and demands are the same as in the previous
section.
If (i) and (ii) hold, there is a number y∗that minimizes G(y). In addition, there
are two numbers s(≤y∗) and S(≥y∗) such that
G(S) = G(y∗) + K,
(9.7)
G(s) = G(y∗) + K.
(9.8)

160
9. Stochastic Inventory Models
It is also worth mentioning that G(y) is nonincreasing in y on (−∞, y∗] and non-
decreasing in y on (y∗, ∞).
To prove the optimality of an (st, St) policy for all t, we need the next two
lemmas.
Lemma 9.4.1 For t = 1, . . . , T , and y ≤y′,
zt(y) ≤zt(y′) + K and
(9.9)
Gt(y′) −Gt(y) ≥G(y′) −G(y) −K.
(9.10)
Proof. It follows that
zt(y)
= min{Gt(y), K + minx≥y Gt(x)}
≤K + minx≥y Gt(x)
≤K + minx≥y′ Gt(x)
≤K + zt(y′).
We also provide an alternative proof here. The result obviously holds for y′ = y.
Now assume that y′ > y. Suppose that at the beginning of the period, the inventory
level prior to any ordering is y. Consider the following strategy: We ﬁrst raise the
inventory level up to y′ and then act optimally as if we started with the inventory
level y′ (prior to any ordering). Such a strategy incurs cost equal to K + zt(y′).
Because this strategy is not necessarily optimal, it follows that
zt(y) ≤K + zt(y′),
which also proves (9.9).
Inequalities in (9.9) imply that
Gt(y′) −Gt(y)
= G(y′) −G(y) + E[zt+1(y′ −D)] −E[zt+1(y −D)]
≥G(y′) −G(y) −K,
which completes the proof.
A function f : ℜ→ℜis called non-K-decreasing if for any x and x′ with x ≤x′,
f(x) ≤f(x′) + K. The above lemma thus implies that zt(y) and Gt(y) −G(y) are
non-K-decreasing. The following lemma, on the other hand, illustrates that zt(y)
and Gt(y) are nonincreasing for y ≤y∗.
Lemma 9.4.2 For t = 1, . . . , T and y ≤y′ ≤y∗,
Gt(y′) −Gt(y) ≤G(y′) −G(y) ≤0 and
(9.11)
zt(y′) ≤zt(y).
(9.12)
Proof. The proof is by induction. Note that G(y) is decreasing in y for y ≤y∗.

9.4 Quasiconvex Loss Functions
161
For t = T , GT (y′)−GT (y) = G(y′)−G(y) ≤0, which implies that minx≥y′ GT (x)
= minx≥y GT (x). Then
zT (y′) = min{GT (y′), K + min
x≥y′ GT (x)}
≤min{GT (y), K + min
x≥y′ GT (x)}
= min{GT (y), K + min
x≥y GT (x)} = zT (y).
Assume that for t + 1 ≥0 and y ≤y′ ≤y∗,
Gt+1(y′) −Gt+1(y) ≤G(y′) −G(y) ≤0 and
zt+1(y′) ≤zt+1(y).
Now it follows immediately that
Gt(y′) −Gt(y) = G(y′) −G(y) + E[zt+1(y′ −D)] −E[zt+1(y −D)]
= G(y′) −G(y) + E[zt+1(y′ −D) −zt+1(y −D)]
≤G(y′) −G(y) ≤0
(9.13)
and
zt(y′) = min{Gt(y′), K + min
x≥y′ Gt(x)}
≤min{Gt(y), K + min
x≥y Gt(x)} = zt(y).
This completes the proof.
We are now ready to show the optimality result.
Theorem 9.4.3 (Veinott 1966) If (i) and (ii) hold, an (st, St) policy is optimal
for the model (9.4). Moreover, s ≤st ≤y∗and y∗≤St ≤S.
Proof. The proof proceeds in several steps. We start with the assumption that
Gt(y) is continuous in y. This assumption will be conﬁrmed at the end.
(1) St is a global minimizer of Gt(y). For this purpose, we ﬁrst show that Gt(y)
is decreasing for y ≤y∗, which follows directly from (9.11). Because Gt(y) is
continuous, there exists a number St that minimizes Gt(y) over [y∗, S]. Now it is
clear that St minimizes Gt(y) on (−∞, S). By the deﬁnition of S and Lemma 9.4.1,
it follows that for y > S(≥y∗),
Gt(y) −Gt(y∗) ≥G(y) −G(y∗) −K
≥G(S) −G(y∗) −K = 0,
where G(y) ≥G(S) due to the quasiconvexity of G(y). Hence, St is indeed a global
minimizer of Gt(y) and y∗≤St ≤S.

162
9. Stochastic Inventory Models
(2) There exists a number st such that
Gt(St) + K = Gt(st) and s ≤st ≤y∗.
The deﬁnitions of St, s, and y∗imply that
Gt(St) + K −Gt(s) ≤Gt(y∗) + K −Gt(s)
≤G(y∗) + K −G(s) = 0,
where the ﬁrst inequality follows from the deﬁnition that St is the minimizer of
Gt(y), while the second inequality holds due to Lemma 9.4.2. From the deﬁnition
of y∗and Lemma 9.4.1, we see
Gt(St) + K −Gt(y∗) ≥G(St) −G(y∗) −K + K ≥0.
Together with the continuity assumption of Gt(y) and the fact that Gt(y) is
decreasing on (−∞, y∗], the above two inequalities imply that there exists a number
st such that
Gt(St) + K = Gt(st) and s ≤st ≤y∗.
(3) For y∗< y < y′,
[K + Gt(y′)] −Gt(y) ≥0.
This follows directly from Lemma 9.4.1 and the fact that G(y′) ≥G(y):
Gt(y′) −Gt(y) ≥G(y′) −G(y) −K ≥−K.
Note that this observation implies that placing an order does not reduce the ex-
pected cost when y > y∗.
(4) We conclude, therefore, that an (st, St) policy is optimal.
(5) It remains to prove that Gt(y) is continuous in y.
Again, we proceed by induction. It is true for t = T because GT (y) = G(y) [by
assumption (i)]. Suppose now that Gt+1(y) is continuous for t < T . From (4),
zt+1(y) =

K + Gt+1(St)
if y ≤st,
Gt+1(y)
if y ≥st.
Hence, zt+1 is continuous. Finally, the continuity of E[zt+1(y−D)] follows from the
continuity of function zt+1 and the uniform continuity theorem, which basically
says that a continuous function is uniformly continuous over a compact set.
The above proof for the optimality of (st, St) policies is based on the assumption
that demands are independent and identically distributed. If demands are not
independent and identically distributed, Lemma 9.4.2 will generally fail to hold
for the following reason. In the proof of Lemma 9.4.2, we require that zt+1(y′ −
D) −zt+1(y −D) ≤0 for all D in (9.13), which holds only if y −D ≤y′ −D ≤y∗.
When demands are not independent and identically distributed, the minimizer of
G(y) may vary from period to period, and the requirement that zt+1(y′ −D) −
zt+1(y −D) ≤0 may not be met. In the proof based on K−convexity, however,
no requirement is imposed upon demands. Thus, while the result in this section
is more general than the results of Sect. 9.3 when demands are independent and
identically distributed, it is not a generalization of the ﬁrst.

9.5 Inﬁnite-Horizon Models
163
9.5
Inﬁnite-Horizon Models
In this section, we consider a discrete-time inﬁnite-horizon model in which an order
may be placed by the warehouse at the beginning of any period. To simplify the
analysis, we focus on discrete inventory levels and assume a discrete distribution
of the one-period demand D. Let pj = Pr{D = j} for j = 0, 1, 2, . . .. The objective
is to minimize the long-run expected cost per period. All other assumptions and
notations are identical to those in the previous section.
This problem has attracted considerable attention in the last three decades. The
intuition developed in the previous section (for the ﬁnite-horizon models) suggests
and is proved by Iglehart (1963b) and Veinott and Wagner (1965), that an (s, S)
policy is optimal for the inﬁnite-horizon case. A simple proof is proposed by Zheng
(1991). Various algorithms have been suggested by Veinott and Wagner (1965),
Bell (1970), and Archibald and Silver (1978) as well as others; see, for instance,
Porteus (1990) or Zheng and Federgruen (1991). This section describes a simple
proof for the optimality of a stationary (s, S) policy given by Zheng (1991) and
sketches an algorithm developed by Zheng and Federgruen (1991) for ﬁnding the
optimal (s, S) policy. We follow those papers, as well as the insight provided in
Denardo (1996).
Let c(s, S) be the long-run average cost associated with the (s, S) policy. Given a
period and an initial inventory y, recall that the loss function G(y) is the expected
holding and shortage cost minus revenue at the end of the period. In what follows,
the loss function G(y) is assumed to be quasiconvex and G(y) →∞as |y| →∞.
Let M(j) be the expected number of periods that elapse until the next order is
placed when starting with s + j units of inventory. That is, M(j) is the expected
number of periods until the total demand is no less than j units. It is obvious that
for all j, we have
M(j) =
j

k=0
pk[1 + M(j −k)] +
∞

k=j+1
pk
(9.14)
=
∞

k=0
pkM(j −k) + 1,
with M(j) = 0 for j ≤0.
Let F(s, y) be the expected total cost in all periods until placing the next order,
when we start with y units of inventory.
Observe that since orders are received immediately, each time an order is placed,
the inventory level increases to S. Hence, replenishment times can be viewed as
regeneration points; see Ross (1970). The theory of regeneration processes tells us
that
c(s, S) =
F(s, S)
M(S −s).
(9.15)
That is, c(s, S), the long-run average cost, is the ratio of the expected cost be-
tween successive regeneration points and the expected time between successive
regeneration points.

164
9. Stochastic Inventory Models
To calculate M(S −s), one need only solve the recursive equation (9.14). In
addition,
F(s, S) = K + H(s, S),
where H(s, y) is the expected holding and shortage cost until placing the next
order, when starting with y units of inventory. How can we calculate the quantity
H(s, S)? For this purpose, observe that M(j + 1) ≥M(j) and let
m(j) .= M(j + 1) −M(j),
for j = 1, 2, 3, . . .. To interpret m(j), observe that for any j, j < S −s, M(j + 1)
is the expected time until demand exceeds j units. Thus, the deﬁnition of M(j)
implies that m(j) is the expected number of periods, prior to placing the next
order, for which the inventory level is exactly S −j. Hence,
H(s, S) =
S−s−1

j=0
m(j)G(S −j).
(9.16)
An alternative way of computing H(s, y) is as follows:
H(s, y) = G(y) +
∞

j=0
pjH(s, y −j), for y > s,
(9.17)
and H(s, y) = 0 for y ≤s. To summarize, for a (s, S) policy, we have
c(s, S) =
K + S−s−1
j=0
m(j)G(S −j)
M(S −s)
.
Let y∗be any minimizer of the loss function G. Zheng and Federgruen’s algo-
rithm as well as Zheng’s proof are essentially based on the following results, which
characterize the properties of the optimal (s, S) policies.
Lemma 9.5.1 For any given (s, S) policy, there exists another (s′, S′) policy with
s′ < y∗≤S′ such that c(s′, S′) ≤c(s, S).
Proof. Observe that G(y) is a quasiconvex function of y and therefore G(y) is
nonincreasing for y ≤y∗and nondecreasing for y ≥y∗. Consider now s ≥y∗.
Equation (9.16) together with the quasiconvexity of G(y) implies that H(s−1, S −
1) ≤H(s, S). Hence, c(s, S) ≥c(s−1, S −1). Suppose now that y∗> S. A similar
argument shows that H(s+1, S +1) ≤H(s, S), and hence c(s, S) ≥c(s+1, S +1),
which completes the proof.
The following result is useful for our analysis.
Lemma 9.5.2 Assume s0 < y∗< S. For a given ρ, we have that
(a) If ρ ≤G(s0), then for any s < s0, there exists 0 < β ≤1 such that
c(s, S) ≥βc(s0, S) + (1 −β)ρ.

9.5 Inﬁnite-Horizon Models
165
(b) If ρ ≥G(s0 + 1), then for any s0 < s < y∗, there exists 0 < β ≤1 such that
c(s0, S) ≤βc(s, S) + (1 −β)ρ.
Proof. For part (a), let β = M(S −s0)/M(S −s) and observe that 0 < β ≤1.
From the deﬁnition of c(s, S), we have
c(s, S) =
K + S−s0−1
j=0
m(j)G(S −j) + S−s−1
j=S−s0 m(j)G(S −j)
M(S −s)
=
c(s0, S)M(S −s0) + S−s−1
j=S−s0 m(j)G(S −j)
M(S −s)
≥
c(s0, S)M(S −s0) + S−s−1
j=S−s0 m(j)ρ
M(S −s)
= βc(s0, S) + (1 −β)ρ,
where the inequality holds since the loss function G is quasiconvex. Finally, the
proof of part (b) follows from a similar argument and is left as an exercise.
We are ready to provide a useful characterization of the optimal reorder levels
for a given order-up-to level.
Lemma 9.5.3 For a given order-up-to level S, a reorder level s0 < y∗is optimal
[i.e., c(s0, S) = mins≤S c(s, S)] if
G(s0) ≥c(s0, S) ≥G(s0 + 1).
(9.18)
Similarly, for any order-up-to level S, there exists an optimal reorder level s0 such
that s0 < y∗and (9.18) holds.
Proof. The optimality of s0 for s0 satisfying (9.18) follows from Lemma 9.5.2 upon
letting ρ = c(s0, S).
We now prove the second part of the result. For any s < y∗, there exists an
s0 < y∗such that G(s0) ≥c(s, S) ≥G(s0 + 1) since G(y) →∞for y →∞and
c(s, S) > minx G(x). Upon letting ρ = c(s, S), Lemma 9.5.2 implies that c(s0, S) ≤
c(s, S). If s0 satisﬁes (9.18), then we are done; otherwise, there exist s1 < y∗such
that s1 > s0 and G(s1) ≥c(s0, S) ≥G(s1 + 1). Again from Lemma 9.5.2, we
have c(s1, S) ≤c(s0, S). If s1 satisﬁes (9.18), we are done; otherwise, repeat this
process. This process has to be ﬁnite since y∗is an upper bound, and thus we end
up with a reorder point satisfying (9.18), which is optimal from the ﬁrst part of
the result.
An immediate byproduct of the lemma is an algorithm for ﬁnding an optimal
reorder point s0 for any given S.
Corollary 9.5.4 For any value of S, s0 = max{y < y∗|c(y, S) ≤G(y)} is the
optimal reorder level associated with S.

166
9. Stochastic Inventory Models
Proof. Let
α = M(S −s −1)
M(S −s)
and observe that (9.15) and (9.16) imply that
c(s, S) = αc(s + 1, S) + (1 −α)G(s + 1).
(9.19)
The deﬁnition of s0 implies that
G(s0) ≥c(s0, S) and G(s0 + 1) < c(s0 + 1, S).
In addition, using (9.19), we have c(s0, S) > G(s0 + 1). Hence, (9.18) holds and
by Lemma 9.5.3, s0 is an optimal reorder point associated with S.
Lemma 9.5.5 For two order-up-to levels S0, S ≥y∗, let s0 and s with s0, s < y∗
be the corresponding optimal reorder points, respectively. Moreover, assume that
G(s0) ≥c(s0, S0) ≥G(s0 + 1).
The (s, S) policy improves on (has smaller cost than) (s0, S0) if and only if
c(s0, S) < c(s0, S0).
Proof. We only need to show that if c(s, S) < c(s0, S0), then c(s0, S) < c(s0, S0).
By contradiction, assume c(s0, S) ≥c(s0, S0). Upon letting ρ = c(s0, S) ≥
c(s0, S0) ≥G(s0 + 1), we have from Lemma 9.5.2 part (b) that
c(s, S) ≥c(s0, S) ≥c(s0, S0),
which is a contradiction.
Finally, we provide a characterization of the optimal order-up-to level for a given
reorder level s. For this purpose, deﬁne
φ(i, s, S) =
 0, if i ≤s,
G(i) −c(s, S) + ∞
j=0 pjφ(i −j, s, S), otherwise .
(9.20)
From the recursive forms (9.14) and (9.17), we have that for i > s,
φ(i, s, S) = H(s, i) −c(s, S)M(i −s)
and φ(S, s, S) = −K.
Lemma 9.5.6 For a given reorder level s, if an order-up-to level S0 is optimal
(c(s, S0) = infs≤S c(s, S)), then c(s, S0) ≥G(S0).

9.5 Inﬁnite-Horizon Models
167
Proof. Assume that c(s, S) < G(S) for some S ≥s. Then there exists an inventory
level i with s < i < S such that −K = φ(S, s, S) > φ(i, s, S). This implies that
c(s, S) > K + H(s, i)
M(i −s)
= c(s, i).
Thus, S cannot be optimal.
From the above proof, we can also see that if an order-up-to level S is opti-
mal for a given reorder level s, then φ(i, s, S) ≥−K = φ(S, s, S) for any i. The
following characterization of the properties of the best (s, S) policy is an imme-
diate consequence of Lemma 9.5.1, Lemma 9.5.3, Lemma 9.5.6, and the above
observation.
Lemma 9.5.7 There exists an (s∗, S∗) policy such that the following hold:
(a) c∗≡c(s∗, S∗) = infs≤S c(s, S);
(b) s∗< y∗≤S∗;
(c) G(s∗) ≥c∗≥G(s∗+ 1);
(d) G(S∗) ≤c∗;
(e) φ(i) ≥−K = φ(S∗) for any i, where φ(i) ≡φ(i, s∗, S∗).
Furthermore, these results suggest the following simple algorithm. Start with
S0 = y∗and ﬁnd the best reorder point s0 applying Corollary 9.5.4. Now increase S
by increments of 1 each time comparing c(s0, S0) to c(s0, S). If c(s0, S) < c(s0, S0),
set S0 = S and ﬁnd the corresponding reorder point. Continue until you’ve identi-
ﬁed (s0, S0) such that no S, S > S0 has c(s0, S) < c(s0, S0) and G(S) > c(s0, S0).
So far we’ve characterized the properties of the best (s, S) policy, the (s∗, S∗)
policy, and we’ve described how to ﬁnd such a policy. We are now ready to prove
that this stationary (s∗, S∗) policy is optimal for the inﬁnite-horizon model. Of
course, as is common for the general inﬁnite-horizon dynamic program, one might
attempt to prove that there exists a function h such that the following optimality
equation holds:
h(x) + c∗= Miny≥x
{Kδ(y −x) + G(y) +
∞

j=0
pjh(y −j)}.
(9.21)
In fact, one can prove that the function φ deﬁned in Lemma 9.5.7 satisﬁes the above
optimality equation (9.21). Unfortunately, since the function h is unbounded, there
is no result in dynamic programming that allows us to claim the optimality of the
stationary (s∗, S∗) policy without further justiﬁcation. Hence, we follow a diﬀerent
approach. In particular, we focus on a relaxed model where negative order is
allowed and whenever a negative order is placed, a ﬁxed cost K is charged.

168
9. Stochastic Inventory Models
We construct a bounded function h satisfying the optimality equation for the
relaxed model
h(x) + c∗= Miny
{Kδ(|y −x|) + G(y) +
∞

j=0
pjh(y −j)}.
(9.22)
The construction of function h is as follows:
h(i) =
⎧
⎨
⎩
0, if i ≤s∗,
O(i), for s∗< i ≤S∗,
min{0, O(i)}, otherwise,
(9.23)
where O(i) = G(i) −c∗+ ∞
j=0 pjh(i −j).
We now prove that −K ≤h(i) ≤0 for any i. First notice that O(i) = φ(i)
for i ≤S∗; hence, from Lemma 9.5.7 part (e), we have that h(i) ≥−K for
i ≤S∗. Moreover, using Lemma 9.5.7 part (c), we can show that h(i) ≤0 for
any s∗< i ≤S∗and consequently, h(i) ≤0 for any i. Thus, it suﬃces to prove
O(i) ≥−K for i > S∗. Assume to the contrary that there exists an i′ such
that O(i′) < −K, and without loss of generality let i′ be the smallest one. Then
h(i) ≥−K for any i < i′. In addition, there must exist an i′′ such that S∗< i′′ < i′
and O(i′′) > 0; otherwise, for any i with s∗< i ≤i′, O(i) ≤0, and therefore
h(i) = O(i) = φ(i) ≥−K from Lemma 9.5.7 part (e). This implies that G(i′′) > c∗.
However, since G is quasiconvex and i′′ > S∗≥y∗, we can prove by induction that
h(i) ≥−K for any i. This is a contradiction since h(i′) = O(i′) < −K. Hence,
−K ≤h(i) ≤0 for any i.
In summary, −K ≤h(i) ≤0 for any i, h(S∗) = −K and O(i) ≥−K for any
i > s∗. It is straightforward to verify that h(i) satisﬁes the optimality equation of
the relaxed model (9.22), and a modiﬁed (s∗, S∗) policy attains the minimization
in the optimality equation. In the modiﬁed policy, make an order to raise the
inventory level to S∗whenever the initial inventory level is no more than s∗; do
not make any order when the initial inventory lies between s∗+ 1 and S∗; for an
inventory level above S∗, make a negative order to reduce the inventory level to
S∗or do nothing depending on which choice is more cost-eﬀective.
We claim that the modiﬁed (s∗, S∗) policy is optimal for the relaxed model and
its associated long-run average cost c∗is optimal. Indeed, this claim follows from
well-known results for inﬁnite-horizon dynamic programming under an average
cost criterion since as we just proved, the function h is bounded; for details, one
may refer to any standard dynamic programming textbook, for instance, Theo-
rem 2.1, p. 93, in Ross (1983). Also observe that the modiﬁed (s∗, S∗) policy is
diﬀerent from the (s∗, S∗) policy in at most one period: When the initial inventory
level is too high, we may make a negative order to reduce the inventory level to
S∗and after that the inventory level will never exceed S∗. Because the outcome
of a ﬁnite number of periods will not aﬀect the long-run average cost, it is safe to
claim that the stationary (s∗, S∗) policy is optimal for the relaxed model and its
associated cost c∗is the optimal average cost. Finally, notice that the stationary
(s∗, S∗) policy is feasible for the original model, and the optimal average cost of

9.6 Models with Positive Lead Times
169
the original model is no less than the optimal average cost of the modiﬁed model.
Thus, this stationary (s∗, S∗) policy is optimal for the original inﬁnite-horizon
model and its associated cost c∗is the optimal long-run average cost.
9.6
Models with Positive Lead Times
So far we have assumed zero lead times. Under this assumption, if demand that
cannot be ﬁlled right away is lost instead of being backlogged, the analysis in the
previous sections can be modiﬁed and our main results are still valid (you are asked
to show that the analysis in Sect. 9.3 can be carried over to lost sales models in
the exercise). However, if a ﬁxed delivery lead time has to be incorporated, there
is a signiﬁcant diﬀerence between lost sales models and backlogging models.
For the case with backlogging, the models discussed in the previous sections but
allowing for positive lead times can be transformed into corresponding ones with
zero lead time using a fairly simple cost accounting scheme, proposed by Scarf
(1960) for the ﬁnite-horizon models. In this scheme, the cost allocated to period
t is the ordering cost plus the expected inventory holding and backorder cost of
period t+l instead of period t, where l denotes the lead time. The rationale behind
this is that the inventory cost incurred by the ordering decision at period t will
only take eﬀect after the order arrives l periods later.
To calculate the inventory holding and backorder cost of period t + l, simply
observe that it only depends on the inventory position at the warehouse, deﬁned
as the inventory at that warehouse plus inventory in transit to the warehouse, at
period t. Indeed, the on-hand inventory level at period t+ l is the diﬀerence of the
inventory position at period t immediately after placing the order, referred to as
the inventory order-up-to position, and the cumulative demand from period t to
period t + l −1. Thus, given the inventory order-up-to position y at period t, we
can write the expected inventory holding and backorder cost of period t + l as
ˆG(y) = h+

ˆ
D
max(y −ˆD, 0)d ˆF( ˆD) + h−

ˆ
D
max( ˆD −y, 0)d ˆF( ˆD),
(9.24)
where ˆF is the cdf of the total demand during the lead time plus one period.
A backlogging model with a positive lead time l can then be transformed into
a new one with zero lead time in which ˆG(y) is treated as the one-period loss
function. With this understanding, the dynamic program (9.3)–(9.4) in Sect. 9.3
can be modiﬁed by replacing the loss function G(·) with ˆG(·) so that for t =
1, 2, . . ., T −l,
ˆGt(y) = ˆG(y) +

D
ˆzt+1(y −D)dF(D)
and
ˆzt(x) = Miny≥x
{Kδ(y −x) + ˆGt(y)}.
It is not hard to show that the optimal inventory order-up-to position can be deter-
mined by solving the above dynamic program, and all the analysis and structural

170
9. Stochastic Inventory Models
properties in Sects. 9.3 and 9.4 can be carried over to this new dynamic program.
For the inﬁnite-horizon counterpart, it suﬃces to replace the loss function G(·) by
ˆG(·) without changing the analysis in Sect. 9.5.
Unfortunately, this observation no longer works for lost sales models. In fact,
though the inventory cost incurred by the ordering decision at period t is still
a function of the on-hand inventory level at period t + l, its dependence on the
inventory at the warehouse and in transit to the warehouse at period t is more
complicated, and the inventory position at period t alone is not suﬃcient. Conse-
quently, the structure of the optimal policy is much more complex. In the remainder
of this section, we focus on a stochastic inventory model with lost sales, positive
lead time, and zero setup cost. Our analysis is based on Zipkin (2008), in which
the concept of L♮-convexity introduced in Chap. 2 plays a critical role.
To completely describe the inventory system, at the beginning of period t after
receiving the order placed l periods ago but before placing an order at the cur-
rent period, let si (i = 0, . . . , l −1) be the inventory level at the warehouse plus
the amount of inventory that will arrive within i periods. The state of the inv-
entory system can be described by s = [s0, s1, . . . , sl−1]. Note that sl−1 is the
inventory position before placing an order. Let sl be the inventory order-up-to
position. Given the realized demand D at period t, the state of the next period,
˜s = [˜s0, ˜s1, . . . , ˜sl−1], is given by
˜si = si+1 −s0 ∧D ∀i = 0, 1, . . . , l −1,
and the expected cost for the remaining T −t + 1 periods immediately after an
order is placed to raise the inventory position to sl if we act optimally in the
remaining T −t periods can be represented as
ˇGt(s, sl, D) = h+ max(s0 −D, 0) + h−max(D −s0, 0) + ˇzt+1(˜s).
The expected cost incurred through the remaining T −t + 1 periods if we act
optimally in period t and the remaining T −t periods, ˇzt(s), can then be derived
by the following dynamic program:
ˇzt(s) = Minsl≥sl−1
{c(sl −sl−1) + E[ ˇGt(s, sl, D)]},
where the feasible set of the states is
S = {(s0, s1, . . . , sl−1) : 0 ≤s0 ≤s1 ≤. . . ≤sl−1}.
Note that unlike the backlogging models, we need to keep the linear ordering cost
component in the formulation.
Lemma 9.6.1 For any s ∈S and sl ≥sl−1, ˇzt(s) and ˇGt(s, sl, D) are L♮-convex.
Proof. Clearly, S is L♮-convex from Proposition 2.3.3 part (e), and so does the set
{(s, sl) : s ∈S, sl−1 ≤sl}. From Proposition 2.3.4 parts (c) and (e), it suﬃces to

9.6 Models with Positive Lead Times
171
show the L♮-convexity of ˇGt(s, sl, D). For this purpose, we claim that ˇGt(s, sl, D)
equals the optimal objective value of the following optimization problem:
Min
h+(s0 −u) + h−(D −u) + ˇzt+1(s2 −u, . . . , sl−1 −u, sl −u)
s.t.
0 ≤u ≤D,
u ≤s0.
To see it, note that the optimization problem allows the ﬁrm to hold inventory even
when there is unsatisﬁed demand. However, since we face a stationary system, it
can never be optimal to hold inventory and reject demand at the same time since it
is more cost-eﬀective to ﬁll one-unit current demand than one-unit future demand
by avoiding any additional holding cost. Therefore, the optimal u is min(D, s0)
and our claim is correct. Finally, Proposition 2.3.4 part (d) implies that the above
objective function is L♮-convex. Thus, Proposition 2.3.4 part (e) is applicable and
ˇGt(s, sl, D) is L♮-convex.
Having established the L♮-convexity of ˇzt(s) and ˇGt(s, sl, D), we can derive the
monotonicity of the optimal inventory order-up-to position s∗
l (s) and the optimal
ordering quantity s∗(s)−sl−1. Let x0 be the on-hand inventory and xi the inventory
in transit that is to arrive in i period (i > 0) and x = [x0, x1, . . . , xl−1].
Theorem 9.6.2 The optimal inventory order-up-to position s∗
l (s) is increasing
in s. However, s∗
l (s + ξe) ≤s∗
l (s) + ξ for any ξ ≥0. Thus, the optimal ordering
quantity x∗
l (x) as a function of x satisﬁes the following inequalities:
x∗
l (x) ≥x∗
l (x + ξe1) ≥x∗
l (x + ξe2) ≥. . . ≥x∗
l (x + ξel−1) ≥x∗
l (x) −ξ ∀ξ ≥0,
where ei is the unit vector with 1 at the ith element.
Proof. The claim on the optimal inventory order-up-to position s∗
l (s) follows dir-
ectly from Lemma 2.3.5. To prove the claim on the optimal ordering quantity
x∗
l (x), note that x∗
l (x) = s∗
l (s) −sl−1. Thus, for any i ≤l −2 and ξ ≥0,
x∗
l (x + ξei+1) = s∗
l (s0, . . . , si, si+1 + ξ, . . . , sl−1 + ξ) −sl−1 −ξ
≤s∗
l (s0, . . . , si−1, si + ξ, . . . , sl−1 + ξ) −sl−1 −ξ
= x∗
l (x + ξei)
≤s∗
l (s + ξe) −sl−1 −ξ
≤s∗
l (s) −sl−1
= x∗
l (x),
where e is the all-1s vector. Here the ﬁrst two inequalities hold since s∗
l (s) is
increasing in s, and the last inequality holds since s∗
l (s + ξe) ≤s∗
l (s) + ξ for ξ ≥0.
To prove that x∗
l (x + ξel−1) ≥x∗
l (x) −ξ, note that
x∗
l (x + ξel−1) = s∗
l (s + ξel−1) −sl−1 −ξ ≥s∗
l (s) −sl−1 −ξ = x∗
l (x) −ξ,
where the inequality follows from the monotonicity of s∗
l (s) in s.

172
9. Stochastic Inventory Models
If x∗
l (x) is diﬀerentiable, the above theorem implies that
0 ≥∂x∗
l (x)
∂x1
≥∂x∗
l (x)
∂x2
≥. . . ≥∂x∗
l (x)
∂xl−1
≥−1;
that is, the optimal ordering quantity has bounded monotone sensitivities. Speciﬁ-
cally, it decreases in the on-hand inventory and the inventory in transit. In addition,
it is more sensitive to newer outstanding orders than older outstanding orders and
the on-hand inventory with bounded sensitivities.
9.7
Multi-Echelon Systems
Consider a distribution system with a single warehouse, denoted by the index 0,
and n retailers, indexed from 1 to n. Incoming orders from an outside vendor with
unlimited stock are received by the warehouse that replenishes the retailers. We
refer to the warehouse or the retailers as facilities. The transportation lead time
to facility i = 0, 1, 2, . . ., n, is a constant Li.
As in the previous section, we analyze a discrete-time model in which customer
demands are independent and identically distributed and are faced only by the
retailers. Every time a facility places an order, it incurs a setup cost Ki, i =
0, 1, 2, . . ., n. The echelon inventory holding cost (see Chap. 7) is h+
i
at facility
i, i = 0, 1, 2, . . ., n. Finally, demand is backlogged at a penalty cost of h−
i , i =
1, 2, . . ., n, per unit per period. The objective is to ﬁnd a centralized strategy, that
is, a strategy that uses systemwide inventory information, so as to minimize the
long-run average system cost.
As the reader no doubt understands, the analysis of stochastic distribution
models is quite diﬃcult and ﬁnding an optimal strategy is close to impossible;
consider the diﬃculty involved in ﬁnding an approximate solution for its deter-
ministic, constant-demand counterpart; see Chap. 7. As a result, limited literature
is available. The rare exceptions are the approximate strategy suggested by Eppen
and Schrage (1981) and the lower bounds developed by Federgruen and Zipkin
(1984a–c) and Chen and Zheng (1994). We brieﬂy describe these two bounds here.
For this purpose, let the echelon inventory position at a facility be deﬁned as
the echelon inventory at that facility plus inventory in transit to that facility.
Consider the following approach suggested by Federgruen and Zipkin (1984a–c).
Given an inventory position yi at retailer i, let the loss function Gi(yi) be
Gi(yi) = h+
i max{0, yi −D} + (h−
i + h+
0 ) max{0, D −yi},
where D is the total demand faced by retailer i during Li + 1 periods (see the end
of the previous section for a discussion).
Consider now any inventory policy with echelon inventory of y units at the
warehouse and inventory position yi at retailer i. The expected one-period holding
and shortage cost in the system is
G(y) = h+
0 (y −μ) +
n

i=1
Gi(yi),

9.7 Multi-Echelon Systems
173
where μ is the expected single-period systemwide demand. Since, by deﬁnition,
y ≥n
i=1 yi, a lower bound on G(y) is obtained by ﬁnding
G0(y) .= Miny1,...,yn

h+
0 (y −μ) +
n

i=1
Gi(yi)|
n

i=1
yi ≤y

.
(9.25)
Thus, a lower bound on the long-run average system cost CF Z is obtained by
solving a single-facility inventory problem with loss function G0 and setup cost
K0. Notice that this bound does not take into account the retailer-speciﬁc setup
costs. This is incorporated in the next-lower bound of Chen and Zheng (1994).
To describe their lower bound, consider the following assembly-distribution sys-
tem associated with the original distribution system. In the assembly-distribution
system, each retailer sells a product consisting of two components. A basic com-
ponent, denoted by a0, and a retailer-speciﬁc component, denoted by ai. Each
retailer receives component a0 from the warehouse, which receives it from the
outside supplier. On the other hand, component ai is supplied directly from the
vendor to retailer i. The arrival of a basic component at retailer i is coordinated
with the arrival of component ai. That is, at the time the warehouse delivers basic
components to retailer i, the same number of ai components is shipped to the re-
tailer from the supplier. These two shipments arrive at the same time and the ﬁnal
product is assembled, each containing one basic component and one ai component.
To ensure that the original distribution system and the assembly-distribution
system are, in some sense, equivalent, we allocate cost in the new system as follows.
Associated with retailer i is a single-facility inventory model with setup cost Ki,
holding cost h+
i , and shortage cost h+
0 +h−
i . The delivery lead time to the facility is
Li and the demand is distributed according to the demand faced by retailer i. This
is, of course, a standard inventory model for which an (si, Si) policy is optimal.
Let Ci be the long-run average cost associated with this optimal policy. Given an
inventory position y, let Gi(y) be the associated loss function. Finally, let
Gi
i(y) =
 Ci
if y ≤si,
Gi(y)
if y > si,
and G0
i (y) = Gi(y) −Gi
i(y).
In the assembly-distribution system, costs are charged as follows. A setup cost
K0 is allocated to the basic component and a setup cost Ki to each component ai,
and an expected holding and penalty cost, that is, loss function, of G0
i to the basic
component and Gi
i to component ai. Notice that since shipments are coordinated,
there is no diﬀerence between the long-run average cost in the original system and
in the assembly-distribution system.
To ﬁnd a lower bound on the long-run average cost of the original system,
we consider a relaxation of the assembly-distribution system in which the basic
components can be sold independently of the other components. Thus, Ci, i =
1, 2, . . ., n, is exactly the long-run average cost associated with the distribution of
component ai. Let C0 be a lower bound on the long-run average cost of the basic

174
9. Stochastic Inventory Models
component. Consequently, n
i=0 Ci is a lower bound on the long-run average cost
of the original distribution system.
It remains to ﬁnd C0. This is obtained following the approach suggested by
Federgruen and Zipkin and described above. For this purpose, we replace Gi by
G0
i in (9.25) and take CF Z as C0.
9.8
Exercises
Exercise 9.1. In (9.1), we assume that F(D) is continuous. Now suppose that
F(D) is not necessarily continuous. Does there exist an S such that z(y) is mini-
mized at y = S? If there exists such an S, how can you determine it?
Exercise 9.2. Prove (9.19).
Exercise 9.3. It is now June and your company has to make a decision regarding
how many ski jackets to produce for the coming winter season. It costs c dollars
to produce one ski jacket, which can be sold for r dollars. Ski jackets not sold
during the winter season are lost. Suppose your marketing department estimates
that demand during the season can take one of the values D1, D2, . . . , Dk, k ≥3.
Since this is a new product, they do not know what probabilities to attach to each
possible demand Di; that is, they do not have estimates of pi, the probability that
demand during the winter season will be Di, i = 1, 2, . . . , k. They have, however,
a good estimate of average demand μ and the variance of the demand σ2. Your
objective is to ﬁnd the production quantity y that will protect you against the
worst probability distribution possible while maximizing proﬁt. For this purpose,
you would like to consider the following optimization model:
MAXIMIZE y MINIMIZE p1...,pk∈P Average Proﬁt,
(9.26)
where P is the set of all possible discrete distribution functions with mean μ and
variance σ2.
(a) Write an expression for the average proﬁt as a function of the production
quantity y and the unknown probabilities p1, p2, . . . , pk.
(b) Suppose we have already determined the production quantity y. Write a
linear program that identiﬁes the worst possible distribution, that is, the
one that minimizes average proﬁt.
(b) Given a value of y, characterize the worst possible distribution; that is, iden-
tify the number of demand points that have positive probabilities in the
probability distribution found in the previous question.
(c) Can you formulate a linear program that ﬁnds the optimal production quan-
tity; that is, can you write a linear program that solves equation (9.26)?

9.8 Exercises
175
Exercise 9.4. Consider the following discrete version of the newsboy problem.
Demand for product can take the values D1, D2, . . . , Dn, n ≥3, with probabilities
p1, p2, . . . , pn, where n
i=1 pi = 1. Let r be a known selling price per unit and
c be a known cost per unit. Our objective is to ﬁnd an order quantity y that
maximizes expected proﬁt. Prove that the optimal order quantity that maximizes
the expected proﬁt must be one of the demand points, D1, D2, . . . , Dn.
Exercise 9.5. Prove Lemma 9.3.2, parts (a), (b), and (c).
Exercise 9.6. Consider the newsboy problem with demand D being a random
variable whose density, f(D), is known. Let r be a known selling price per unit
and c be a known cost per unit. Assume no initial inventory and no salvage value.
The objective is to ﬁnd an order quantity y that maximizes expected proﬁt.
(a) Let a service level be deﬁned as the probability that demand is no more
than the order quantity, y. Our objective is to ﬁnd the order quantity, y,
that maximizes expected proﬁt subject to the requirement that the service
level is at least α. What is the optimal order quantity as a function of α, c,
r, and f(D)?
(b) Suppose there is no service-level requirement; however, there is a capacity
constraint, C, on the amount we can order. That is, the order quantity,
y, cannot be more than C. What is the optimal order quantity, y, that
maximizes expected proﬁt subject to the capacity constraint, C?
(c) Suppose there is a service-level requirement, α, and a capacity constraint,
C. What is the optimal order quantity, y, that maximizes expected proﬁt
subject to the constraints that service level is at least α and the capacity
constraint, C?
Exercise 9.7. Prove that a function f : ℜ→ℜis K-convex if and only if for any
z ≥0, b > 0, and any y, we have
K + f(y + z) ≥f(y) + z
b (f(y) −f(y −b)).
Exercise 9.8. Prove Lemma 9.5.2, part (b).
Exercise 9.9. (Pang 2011) If a function f : ℜ→ℜis K-convex and non-K-
decreasing, then for λ ≥γ ≥0, the function f(λx+ −γ(−x)+) is K-convex. Use
this result to show that the analysis in Sect. (9.3) can be carried over to lost sales
models with zero lead time.

10
Integration of Inventory and Pricing
10.1
Introduction
In the previous chapters, we analyzed the traditional inventory models, which focus
on eﬀective replenishment strategies and typically assume that a commodity’s price
is exogenously determined. In recent years, however, a number of industries have
used innovative pricing strategies to manage their inventory eﬀectively. For exa-
mple, techniques such as revenue management have been applied in the airlines,
hotels, and rental car agencies—integrating price, inventory control, and quality of
service; see Kimes (1989). In the retail industry, to name another example, dynam-
ically pricing commodities can provide signiﬁcant improvements in proﬁtability, as
shown by Gallego and van Ryzin (1994).
These developments call for models that integrate inventory control and pricing
strategies. Such models are clearly important not only in the retail industry, where
price-dependent demand plays an important role, but also in manufacturing en-
vironments in which production/distribution decisions can be complemented with
pricing strategies to improve the ﬁrm’s bottom line.
The coordination of replenishment strategies and pricing policies has been
the focus of many papers, starting with the work of Whitin (1955), who analyzed
the celebrated newsvendor problem with price-dependent demand. For a review,
the reader is referred to Eliashberg and Steinberg (1991), Petruzzi and Dada
(1999), Federgruen and Heching (1999), Yano and Gilbert (2002), Elmaghraby
and Keskinocak (2003), Chan, Shen, Simchi-Levi and Swann (2004), or Chen and
Simchi-Levi (2012).
D. Simchi-Levi et al., The Logic of Logistics: Theory, Algorithms, and Applications
for Logistics Management, Springer Series in Operations Research and Financial Engineering,
DOI 10.1007/978-1-4614-9149-1 10, © Springer Science+Business Media New York 2014
177

178
10. Integration of Inventory and Pricing
In this chapter, we review some of the main progress on stochastic models.
We ﬁrst present regularity conditions on demand modeling and some commonly
used demand models in Sect. 10.2. We then analyze the single-period models in
Sect. 10.3. The ﬁnite-horizon models based on Chen and Simchi-Levi (2004a) are
analyzed in Sect. 10.4, followed in Sect. 10.5 by an alternative approach due to
Huh and Janakiraman (2008). A brief description of extensions and challenges is
presented in Sect. 10.6. Finally, in Sect. 10.7, we focus on risk-averse inventory
(and pricing) models based on Chen, Sim, Simchi-Levi and Sun (2007).
10.2
Demand Models
To make optimal pricing decisions, it is pivotal that we know the volume of a
product that customers are willing to purchase at a speciﬁc price. The relation-
ship between the volume and price gives rise to a demand model. The demand of
a product can depend on many variables other than price, such as quality, brand
name, and competitor’s prices; these variables change in each scenario. Here, how-
ever, we restrict our discussion to demand models of a single product in which
price is the only variable.
Economic theory provides us with basic demand models derived from the clas-
sical rational choice theory of consumer behavior (we refer to van Ryzin 2012 and
Chap. 7 in Talluri and van Ryzin (2004) , as well as the references therein for
more details). Built upon this theory, several regularity conditions are imposed
on deterministic demand functions of a single product. Let [p, ¯p] be the feasible
domain of price.
Assumption 10.2.1 For a given selling price p ∈[p, ¯p], the demand function,
D(p), satisﬁes the following conditions:
(a) D(p) is continuous in p.
(b) D(p) is strictly decreasing in p and thus has an inverse D−1(d).
(c) D(p) ∈[0, +∞).
(d) The revenue, D−1(d)d, is concave in d.
These regularity conditions are quite intuitive and not restrictive in most cases.
They are imposed to avoid unnecessary technical complications. Some commonly
used deterministic demand functions include
• the linear demand d(p) = b −ap for p ∈[0, b/a] (a > 0 and b ≥0),
• the exponential demand d(p) = eb−ap (a > 0 and b > 0),
• the iso-elasticity demand d(p) = bp−a (a > 1 and b > 0) [note that the price
elasticity of demand, e(p), is the relative change in demand in response to a
relative change in price, i.e., e(p) = −pd′(p)
d(p) ],

10.3 Single-Period Stochastic Models
179
• the Logit demand d(p) = Ω
e−ap
1+e−ap , which is the product of the market size
Ω and the probability that a customer with a coeﬃcient of price sensitivity
a buys at price p.
It is straightforward to check that the above demand functions satisfy the regu-
larity conditions in Assumption 10.2.1.
In stochastic settings, the demand of a product, denoted by D(p, ϵ), is often
represented as a function of the price p and a random noise ϵ independent of p.
Sometimes it is important to specify the format that the random noise ϵ enters the
demand function. For our purpose, we focus on stochastic demand models under
the following assumptions.
Assumption 10.2.2 For a given price p, the demand is given by
D(p, ϵ) = αD(p) + β,
(10.1)
where D(p) satisﬁes Assumption 10.2.1, ϵ = (α, β), and α is a nonnegative random
variable with E[α] = 1 and E[β] = 0.
An implicit assumption here is that the realized demand D(p, ϵ) is always non-
negative, which imposes some conditions on the selling price and the two random
variables α and β. Observe that, by scaling and shifting, the assumptions E[α] = 1
and E[β] = 0 can be made without loss of generality.
A special case of this demand function is the additive demand function. In this
case, the demand function is of the form D(p, ϵ) = D(p) + β. Another special case
of the demand function (10.1) is the model with multiplicative demand. In this
case, the demand function is of the form D(p, ϵ) = αD(p), where α is a random
variable.
Observe that for additive demand in which α = 1, the demand variance is in-
dependent of the price, while the coeﬃcient of variation (the ratio of standard
deviation and mean) is dependent on the price. In contrast, for multiplicative de-
mand in which β = 0, the coeﬃcient of variation does not depend on the price
while the variance does. In single-product settings with decreasing expected de-
mand d(p), a higher price leads to a higher uncertainty for additive demand but a
lower uncertainty for multiplicative demand.
10.3
Single-Period Stochastic Models
We start by analyzing a single-period problem in which a risk-neutral retailer has
to decide on its stock level and the selling price of a single product. In this problem,
demand is stochastic and depends on the selling price. In particular, we assume
that the demand follows Assumption 10.2.2. An ordering and pricing decision is
made before the realization of the demand uncertainty. The unit ordering cost is c
and unsatisﬁed demand is ﬁlled with an emergency order. Let h(x) be the inventory

180
10. Integration of Inventory and Pricing
holding/disposal cost or the emergency ordering cost when the inventory level after
satisfying the demand is x. A common form of h(x) is as follows:
h(x) = h+ max(0, x) + h−max(0, −x),
(10.2)
where h+ is the unit inventory holding/disposal cost if h+ is nonnegative or the
unit salvage value if it is negative, and h−is the unit cost for the emergency order.
We assume that h(x) is convex and 0 is a minimizer of the function cx + h(x). For
h(x) having the particular form (10.2), the above assumptions imply that
h−≥c ≥max{0, −h+}.
That is, the salvage value is no more than the normal unit ordering cost, which in
turn is no more than the unit cost for the emergency order.
For a given stock level y and a selling price p, the expected proﬁt of the retailer
is calculated as follows:
v(y, p) = E[pD(p, ϵ)] −cy −E[h(y −D(p, ϵ))].
Assumption 10.2.2 implies that there is a one-to-one correspondence between the
selling price p and the expected demand d. Thus, we have an equivalent represen-
tation for the retailer’s expected proﬁt:
φ(y, d) = R(d) −cy −E[h(y −αd −β)].
The objective of the retailer is to ﬁnd a stock level and a selling price, correspond-
ingly an associated expected demand, so as to maximize the retailer’s expected
proﬁt, namely,
max
y≥0,d∈[d, ¯d] φ(y, d),
(10.3)
where d and ¯d are the lower and upper bounds of the expected demand corre-
sponding to the upper and lower bounds of the selling price; that is,
d = D−1(¯p), and ¯d = D−1(p).
Notice that φ(y, d) is jointly concave in y and d, and hence the above optimization
can be solved eﬃciently.
Our intention here is to compare the selling prices under deterministic and
stochastic demands. In particular, we show that there is a signiﬁcant diﬀerence
between the additive demand case and the multiplicative demand case. Before we
proceed to our main result of this section, we need the following lemma.
Lemma 10.3.1 Let f be a convex function over ℜ. Then for any x, d, η ≥0,
E[f(x −αd)] ≤E[f(x + η −α(d + η))],
where α is a nonnegative random variable with E[α] = 1.

10.3 Single-Period Stochastic Models
181
Proof. Notice that a convex function has nondecreasing diﬀerences. Hence, we have
that for any x, d, η, α ≥0,
f(x −αd) −f(x −αd −(α −1)η) ≤f(x) −f(x −(α −1)η).
Taking expectation on both sides of the above inequality and using Jensen’s in-
equality give us the result.
Now we are ready to present one of our main results of this section. For sim-
plicity, we assume that the expected revenue is strictly concave in the expected
demand so that the optimization problem (10.3) has a unique optimal d.
Theorem 10.3.2 Under the assumption that the expected revenue is strictly con-
cave in the expected demand, the optimal selling price for the additive demand case
equals the optimal selling price for the deterministic demand case, which, on the
other hand, is no more than the optimal selling price for the multiplicative demand
case.
Proof. It suﬃces to prove that there exist (y∗
d, d∗
d), (y∗
a, d∗
a), and (y∗
m, d∗
m) opti-
mal for problem (10.3) with deterministic, additive, and multiplicative demand,
respectively, such that d∗
a = d∗
d ≥d∗
m.
First, notice that
φ(y, d) = R(d) −cd −E[c(y −αd −β) + h(y −αd −β)].
For the deterministic demand case with α = 1 and β = 0, since 0 is a minimizer
for the function cx + h(x), it is optimal to set a selling price such that the realized
demand is d∗
d, which solves
max
d∈[d, ¯d] R(d) −cd,
and to order the demand exactly, that is, y∗
d = d∗
d.
Now we prove that there exists an optimal solution (y∗
a, d∗
a) for problem (10.3)
with additive demand such that d∗
a = d∗
d. If d∗
a < d∗
d, then (y∗
a + η, d∗
a + η) gives an
objective value no less than that given by (y∗
a, d∗
a) for a suﬃciently small positive
η. If d∗
a > d∗
d, we distinguish between two cases. First, y∗
a > 0. In this case,
(y∗
a −η, d∗
a −η) gives an objective value no less than that given by (y∗
a, d∗
a) for
a suﬃciently small positive η. Second, y∗
a = 0. In this case, (0, d∗
a −η) gives an
objective value no less than that given by (y∗
a, d∗
a) for a suﬃciently small positive η,
since 0 is a minimizer of the function cx+ h(x). Therefore, there exists an optimal
solution (y∗
a, d∗
a) for problem (10.3) with additive demand such that d∗
a = d∗
d.
Finally, we argue that there exists an optimal solution (y∗
m, d∗
m) for problem
(10.3) with multiplicative demand such that d∗
m ≤d∗
d. Assume that d∗
m > d∗
d.
Again, we distinguish between two cases. First, y∗
m > 0. In this case, Lemma 10.3.1
implies that (y∗
m −η, d∗
m −η) gives an objective value no less than that given by
(y∗
m, d∗
m) for a suﬃciently small positive η. Second, y∗
m = 0. Similar to the argument
for the additive demand case, (0, d∗
m −η) gives an objective value no less than that
given by (y∗
m, d∗
m) for a suﬃciently small positive η, since 0 is a minimizer of the

182
10. Integration of Inventory and Pricing
function cx+h(x). Therefore, there exists an optimal solution (y∗
m, d∗
m) for problem
(10.3) with multiplicative demand such that d∗
m ≤d∗.
The above theorem thus implies that there is a signiﬁcant diﬀerence between
the additive demand case and the multiplicative demand case. To understand
this diﬀerence, notice that the variance of the additive demand is independent of
the selling price, while the variance of the multiplicative demand is a decreasing
function of the selling price. Thus, for the multiplicative demand case, the retailer
tends to choose a higher selling price so as to decrease the variability of the demand.
In the above discussion, we assume a zero initial inventory level and zero ﬁxed
ordering cost. Now let x be the initial inventory level, let y be the target stock
level, and also assume that the ﬁxed ordering cost is K. In this case, we face the
following problem:
max
y≥x,d∈[d, ¯d] −Kδ(y −x) + φ(y, d) + cx,
(10.4)
where δ(u) = 1 for u > 0 and δ(0) = 0.
In the following, we will show that a simple policy, referred to as the (s, S, p)
policy, is optimal for problem (10.4). In such a policy, the inventory is managed
based on an (s, S) policy and the optimal price p(x) is a function of the initial
inventory level x. Moreover, for the special case with zero ﬁxed ordering cost,
a base stock list price policy is optimal: The inventory is managed based on a
base stock policy, and the optimal price is a nonincreasing function of the initial
inventory level.
Theorem 10.3.3 For problem (10.4), an (s, S, p) policy is optimal. Furthermore,
for the special case with zero ﬁxed ordering cost, a base stock list price policy is
optimal.
Proof. First, notice that Theorem 2.2.6 implies that the function φ(x, d) is super-
modular. Thus, from Theorem 2.2.8, there exists a nondecreasing function d(x)
such that d(x) maximizes φ(x, d) for any given inventory level x.
Now let S be a maximizer of the function φ(x, d(x)) + cx and let s satisfy
φ(s, d(s)) + cs = φ(S, d(S)) + cS −K.
Since φ(x, d) is jointly concave in (x, d), φ(x, d(x)) is a concave function. This
allows one to show that the optimal inventory level is managed based on the (s, S)
policy. Moreover, the optimal price is a function of the initial inventory level: If
x is no more than s, the optimal price is D−1(d(S)); if x is greater than s, the
optimal price is the D−1(d(x)).
Finally, for the special case with zero ordering cost, we have s = S and the
optimal selling price is D−1(d(max(S, x))). Hence, a base stock list price policy is
optimal.

10.4 Finite-Horizon Models
183
10.4
Finite-Horizon Models
10.4.1
Model Description
In this section, we focus on a ﬁnite-horizon model. Unlike the single-period models,
the structure of the optimal policies are signiﬁcantly diﬀerent between the additive
demand case and the multiplicative demand case, as we will demonstrate in this
section.
Consider a ﬁrm that has to make replenishment and pricing decisions over a
ﬁnite time horizon with T periods.
Demands in diﬀerent periods are independent of each other. For each period t,
t = 1, 2 . . . , T , let dt be the demand and pt be the selling price in period t. We
assume that dt = αtDt(pt) + βt, which is time-dependent and satisﬁes Assump-
tion 10.2.2. Notice that in this section, the random perturbation ϵ, the demand
function D(p, ϵ), and the expected revenue function R(d) are indexed by t to de-
note time dependence. The selling price pt is restricted in an interval. In particular,
let pt and ¯pt be the lower and upper bounds of the selling price pt, respectively.
Let xt be the inventory level at the beginning of period t, just before placing an
order. Similarly, yt is the inventory level at the beginning of period t after placing
an order. The ordering cost function includes both a ﬁxed cost and a variable cost
and is calculated for every t, t = 1, 2, . . ., as
Kδ(yt −xt) + ct(yt −xt).
Lead time is assumed to be zero, and hence an order placed at the beginning of
period t arrives immediately before demand for the period is realized.
Unsatisﬁed demand is backlogged. Let x be the inventory level carried over
from period t to the next period. Since we allow backlogging, x may be positive
or negative. A cost ht(x) is incurred at the end of period t, which represents the
inventory holding cost when x > 0 and the shortage cost if x < 0.
Given a discount factor γ with 0 < γ ≤1, an initial inventory level, x1 = x, and
a pricing and replenishment policy, let
V γ
T (x) =
T

t=1
γt−1(−Kδ(yt −xt) −ct(yt −xt) −ht(xt+1) + ptDt(pt, ϵt))
(10.5)
be the T -period total discounted proﬁt for a realization of the random perturba-
tions ϵt, where xt+1 = yt −Dt(pt, ϵt).
The objective is to decide on ordering and pricing policies to maximize the total
expected discounted proﬁt over the entire planning horizon. That is, the objective
is to maximize
E[V γ
T (x)]
(10.6)
for any initial inventory level x and any 0 < γ ≤1.
To ﬁnd the optimal strategy that maximizes (10.6), let vt(x) be the maximum
total expected discounted proﬁt when T −t periods remain in the planning horizon

184
10. Integration of Inventory and Pricing
and the inventory level at the beginning of period t is x. A natural dynamic
program that can be applied to ﬁnd the policy maximizing (10.6) is as follows. For
t = 1, 2, . . . , T,
vt(x) = ctx +
max
y≥x,¯pt≥p≥pt
−Kδ(y −x) + ˆgt(y, p)
(10.7)
with vT +1(x) = 0 for any x, where
ˆgt(y, p) := −cty + E[pDt(p, ϵt) −ht(y −Dt(p, ϵt)) + γvt+1(y −Dt(p, ϵt))].
Observe that the single-period proﬁt function
−ct(y −x) + E[pDt(p, ϵt) −ht(y −Dt(p, ϵt))]
is not necessarily a concave function of the selling price p, since Dt(p, ϵt) may be
a nonlinear function of p. Fortunately, for the general demand functions (10.1),
we can represent the formulation (10.7) only with respect to the expected demand
rather than with respect to the price, which allows us to show that the single-
period proﬁt function is jointly concave in terms of the inventory level and expected
demand. Let
dt = Dt(¯pt) and
¯dt = Dt(pt).
Assumption 10.2.1 implies that there is a one-to-one correspondence between the
selling price pt ∈[pt, ¯pt] and the expected demand Dt(pt) ∈[dt, ¯dt].
Denote the expected demand at period t by d = Dt(p). Also, let
φt(x) = vt(x)−ctx, hγ
t (y) = ht(y)+(ct−γct+1)y, and ˆRt(d) = Rt(d)−ctd, (10.8)
where cT +1 = 0 and Rt is the expected revenue function with
Rt(d) = dD−1
t (d),
which, by Assumption 10.2.1, is a concave function of expected demand d. These
functions, φt(x), hγ
t (y), and ˆRt(d), allow us to transform the original problem into
a problem with zero variable ordering cost.
Speciﬁcally, the dynamic program (10.7) can be written as
φt(x) = max
y≥x −Kδ(y −x) + ft(y)
(10.9)
with φT +1(x) = 0 for any x, where
ft(y) = max ¯dt≥d≥dtgt(y, d),
(10.10)
with
gt(y, d) = Hγ
t (y, d) + γE[φt+1(y −αtd −βt)]
(10.11)
and
Hγ
t (y, d) := −E[hγ
t (y −αtd −βt)] + ˆRt(d).

10.4 Finite-Horizon Models
185
Thus, most of our focus is on the transformed problem (10.9), which has a
similar structure to problem (10.7). In this transformed problem, one can think
of hγ
t as being the holding and shortage cost function, ˆRt as being the revenue
function, and the variable ordering cost is equal to zero.
For technical reasons, we need the following assumption on the revenue functions
and on the holding and shortage cost functions.
Assumption 10.4.1 For t = 1, 2, . . ., ht is convex and Hγ
t (y, d) is well deﬁned
for any y and d ∈[dt, ¯dt]. Therefore, Hγ
t (y, d) is jointly concave in y and d and
consequently,
Qγ
t (x) :=
max
¯dt≥d≥dt
Hγ
t (x, d)
(10.12)
is concave. Furthermore, we assume that for any t,
lim
|x|→∞Qγ
t (x) = −∞.
Notice that one can think of Hγ
t (y, d) as being the expected single-period proﬁt
excluding the ordering cost for a given inventory level y and a selling price associ-
ated with a given expected demand, and Qγ
t (x) as being the maximum expected
single-period proﬁt excluding the ordering cost for a given inventory level x by
choosing the best selling price.
10.4.2
Symmetric K-Convex Functions
To motivate the technique used for characterizing the optimal policies for the
integrated inventory and pricing models, it is useful to relate our problem to the
celebrated stochastic inventory control problem discussed in Chap. 9. In that prob-
lem, demand is assumed to be exogenously determined, while here demand depends
on price. Other assumptions regarding the framework of the model are similar to
those made in Chap. 9. In order to prove that an (s, S) policy is optimal for the
stochastic inventory models, we employed the concept of K-convexity. It is clear
from Deﬁnition 9.3.1 that one signiﬁcant diﬀerence between K-convexity and tra-
ditional convexity is that (9.5) is not symmetric with respect to x0 and x1, and
thus it cannot be trivially extended to multidimensional space.
It turns out that this asymmetry is the main barrier when trying to identify the
optimal policy to the integrated inventory and pricing problem with nonadditive
demand functions. Indeed, there exist counterexamples that show that the function
φt is not necessarily K-concave and an (s, S) inventory policy is not necessarily
optimal for the ﬁnite-horizon model with multiplicative demand functions. This
motivates the development of a new concept, the symmetric K-concave function,
which allows us to characterize the optimal policy in the general demand case.
Deﬁnition 10.4.2 A function f : ℜn →ℜis called symmetric K-convex for
K ≥0 if, for any x0, x1 ∈ℜn and λ ∈[0, 1],

186
10. Integration of Inventory and Pricing
f((1 −λ)x0 + λx1) ≤(1 −λ)f(x0) + λf(x1) + max{λ, 1 −λ}K.
(10.13)
A function f is called symmetric K-concave if −f is symmetric K-convex.
Observe that similar to the concept of convexity, the symmetric K-convexity
is deﬁned in a multidimensional space while the K-convexity is only deﬁned in
one-dimensional space. Moreover, a K-convex function is a symmetric K-convex
function. The following results describe properties of symmetric K-convex func-
tions, properties that are parallel to those summarized in Lemma 9.3.2 and Propo-
sition 9.3.3.
Lemma 10.4.3
(a) A real-valued convex function is also symmetric 0-convex
and hence symmetric K-convex for all K ≥0. A symmetric K1-convex func-
tion is also a symmetric K2-convex function for K1 ≤K2.
(b) If f1(y) and f2(y) are symmetric K1-convex and symmetric K2-convex, re-
spectively, then for α, β ≥0, αf1(y) + βf2(y) is symmetric (αK1 + βK2)-
convex.
(c) If f(y) is symmetric K-convex and ζ is a random variable, then E[f(y −ζ)]
is also symmetric K-convex, provided E[|f(y −ζ)|] < ∞for all y.
(d) Assume that f : ℜ→ℜis a continuous symmetric K-convex function and
f(y) →∞as |y| →∞. Let S be a global minimizer of f and s be any element
from the set
X := {x|x ≤S, f(x) = f(S) + K and f(x′) ≥f(x) for any x′ ≤x}.
Then we have the following results:
(i) f(s) = f(S) + K and f(y) ≥f(s) for all y ≤s.
(ii) f(y) ≤f(z) + K for all y, z with (s + S)/2 ≤y ≤z.
Proof. Parts (a), (b), and (c) follow directly from the deﬁnition of symmetric K-
convexity. Hence, we focus on part (d). Since f is continuous and f(y) →∞as
|y| →∞, X is not empty. Part (d)(i) is a direct consequence of the fact that s ∈X.
To prove part (d)(ii), we consider two cases. First, for any y, z with S ≤y ≤z,
there exists λ ∈[0, 1] such that y = (1 −λ)S + λz, and we have from the deﬁnition
of symmetric K-convexity that
f(y) ≤(1 −λ)f(S) + λf(z) + max{λ, 1 −λ}K ≤f(z) + K,
where the second inequality follows from the fact that S minimizes f(x).
In the second case, consider y such that S ≥y ≥(s + S)/2. In this case, there
exists 1 ≥λ ≥1/2 such that y = (1 −λ)s + λS, and from the deﬁnition of
symmetric K-convexity, we have that

10.4 Finite-Horizon Models
187
f(y) ≤(1 −λ)f(s) + λf(S) + λK = f(S) + K ≤f(z) + K
since f(s) = f(S) + K. Hence, (i) and (ii) hold.
Figure 10.1 provides an illustration of the property of a symmetric K-convex
function in Lemma 10.4.3 part (d). Notice that there might exist a set A ⊆(s, (s+
S)/2) such that f(x) > f(S) + K for x ∈A.
FIGURE 10.1. Illustration of the properties of a symmetric K-convex function
We now present another important property of symmetric K-convex functions,
which allows us to prove the symmetric K-concavity of the functions φt(x) and
gt(y, d) by dynamic programming backward induction.
Proposition 10.4.4 If f : ℜ→ℜis a symmetric K-convex function, then the
function
φ(x) = min
y≤x Qδ(x −y) + f(y)
is symmetric max{K, Q}-convex. Similarly, the function
ψ(x) = min
y≥x Qδ(x −y) + f(y)
is also symmetric max{K, Q}-convex.
Proof. We only need to prove the symmetric max{K, Q}-convexity of function
φ(x). The second part of the result follows from the symmetric property of the
symmetric K-convexity.
If Q ≥K, we know that f(x) is also a symmetric Q-convex function by Lemma
10.4.3 part (a). Hence, it suﬃces to prove that in the case K ≥Q, the symmet-
ric K-convexity of the function f(x) implies the symmetric K-convexity of the
function φ(x). Thus, in the remaining part of the proof, we assume that K ≥Q.
Observe that φ(x) ≤f(x) for any x and φ(x) ≤Q + f(y) for any y ≤x. Let
E = {x | φ(x) = f(x)} and R = {x | φ(x) < f(x)}. We want to show that for any
x0, x1 and λ ∈[0, 1] with x0 ≤x1,

188
10. Integration of Inventory and Pricing
φ(xλ) ≤(1 −λ)φ(x0) + λφ(x1) + max{λ, 1 −λ}K,
(10.14)
where xλ = (1 −λ)x0 + λx1. We will consider four diﬀerent cases.
Case 1: x0, x1 ∈E. In this case,
φ(xλ)
≤
f(xλ)
≤
(1 −λ)f(x0) + λf(x1) + max{λ, 1 −λ}K
=
(1 −λ)φ(x0) + λφ(x1) + max{λ, 1 −λ}K,
where the second inequality follows from the symmetric K-convexity of the func-
tion f(x).
Case 2: x0, x1 ∈R. In this case, let φ(xi) = Q + f(yi) for i = 0, 1, with yi ≤xi,
and let yλ = (1 −λ)y0 + λy1. It is clear that y0 ≤y1 and yλ ≤xλ. Furthermore,
φ(xλ)
≤
Q + f(yλ)
≤
(1 −λ)(Q + f(y0)) + λ(Q + f(y1)) + max{λ, 1 −λ}K
=
(1 −λ)φ(x0) + λφ(x1) + max{λ, 1 −λ}K,
where the second inequality follows from the symmetric K-convexity of the func-
tion f(x).
Case 3: x0 ∈R, x1 ∈E. Let φ(x0) = Q + f(y0) with y0 ≤x0. We will distinguish
between two cases.
Subcase 1: f(y0) −f(x1) ≤K −Q. In this case,
φ(xλ)
≤
Q + f(y0)
=
(1 −λ)(Q + f(y0)) + λf(x1) + λ(Q + f(y0) −f(x1))
≤
(1 −λ)φ(x0) + λφ(x1) + λK.
Subcase 2: f(y0) −f(x1) ≥K −Q. Let xλ = (1 −μ)y0 + μx1 with λ ≤μ. Then
φ(xλ) ≤f(xλ)
≤(1 −μ)f(y0) + μf(x1) + max{μ, 1 −μ}K
= (1 −λ)φ(x0) + λφ(x1) + max{μ, 1 −μ}K
+ (μ −λ)(f(x1) −f(y0)) −(1 −λ)Q
≤(1 −λ)φ(x0) + λφ(x1) + max{μ, 1 −μ}K −(1 −μ)Q −(μ −λ)K
≤(1 −λ)φ(x0) + λφ(x1) + max{λ, 1 −λ}K,
where the second inequality follows from the symmetric K-convexity of the func-
tion f(x), and the third inequality follows from the assumption that f(y0) −
f(x1) ≥K −Q.
Case 4: x0 ∈E, x1 ∈R. Let φ(x1) = Q+ f(y1) for y1 ≤x1. Again, we distinguish
between two diﬀerent cases.

10.4 Finite-Horizon Models
189
Subcase 1: y1 ≤xλ. In this case,
φ(xλ)
≤
Q + f(y1)
=
(1 −λ)f(x0) + λ(Q + f(y1)) + (1 −λ)(Q + f(y1) −f(x0))
≤
(1 −λ)φ(x0) + λφ(x1) + (1 −λ)Q,
where the last inequality holds since f(y1) ≤f(x0).
Subcase 2: y1 ≥xλ. Let xλ = (1 −μ)x0 + μy1 with λ ≤μ. Then
φ(xλ)
≤
f(xλ)
≤
(1 −μ)f(x0) + μf(y1) + max{μ, 1 −μ}K
=
(1 −λ)φ(x0) + λφ(x1) + max{μ, 1 −μ}K
+
(μ −λ)(f(y1) −f(x0)) −λQ,
(10.15)
where the second inequality follows from the symmetric K-convexity of the func-
tion f(x). On the other hand, since x0 ≤xλ,
φ(xλ)
≤
Q + f(x0)
=
(1 −λ)φ(x0) + λφ(x1)
+
λ(f(x0) −f(y1)) + (1 −λ)Q.
(10.16)
If
μ
≤
1
2,
then
inequality
(10.15)
implies
inequality
(10.14)
since
max{μ, 1 −μ} = 1 −μ ≤1 −λ and f(y1) ≤f(x0).
Now assume that μ ≥1
2. Multiplying (10.15) by λ/μ and (10.16) by (μ −λ)/μ
and adding them together, we have
φ(xλ) ≤(1 −λ)φ(x0) + λφ(x1) + λK −(λ
μ −(1 −λ))Q.
(10.17)
If λ ≥1
2, then λ
μ −(1 −λ) ≥0, which, together with inequality (10.17), implies
(10.14). On the other hand, if λ ≤1
2, we have that
λK −(λ
μ −(1 −λ))Q = (1 −λ)K + (2λ −1)(K −Q) + λQ(1 −1
μ) ≤(1 −λ)K,
which, together with inequality (10.17), implies (10.14).
In the following, we show that, like convex functions, the symmetric K-convexity
can be preserved under optimization operations.
Lemma 10.4.5 Let f(·, ·) : ℜn × ℜm →ℜbe symmetric K-convex. Assume that
for a given x ∈ℜn, there is an associated set C(x) ⊂ℜm and
C := {(x, y) | y ∈C(x), x ∈ℜn}
is convex. Furthermore, assume that
φ(x) = min
y∈C(x)f(x, y)
is well deﬁned and the minimization is attainable for any x. Then f is symmetric
K-convex.

190
10. Integration of Inventory and Pricing
Proof. For any x0, x1 ∈ℜn and λ ∈[0, 1], let y0 ∈C(x0) and y1 ∈C(x1) such that
φ(x0) = f(x0, y0) and φ(x1) = f(x1, y1). Then
(1 −λ)y0 + λy1 ∈C((1 −λ)x0 + λx1)
and
φ((1 −λ)x0 + λx1)
≤
f((1 −λ)x0 + λx1, (1 −λ)y0 + λy1)
≤
(1 −λ)f(x0, y0) + λf(x1, y1) + max{λ, 1 −λ}K
=
(1 −λ)φ(x0) + λφ(x1) + max{λ, 1 −λ}K.
Therefore, f is symmetric K-convex.
In the following, we focus on characterizing the optimal solution for the ﬁnite-
horizon model. Speciﬁcally, our objective is to identify pricing and replenishment
policies that solve (10.7) or its equivalent (10.9).
However, under the additive demand model, this concept is not needed. Indeed,
we prove in Sect. 10.4.3 that, for additive demand functions, the function φt is
K-concave and hence the optimal policy for problem (10.9) is an (s, S, p) policy.
Formally, in this policy, every period, t, the inventory policy is characterized by
two parameters, the reorder point, st, and the order-up-to level, St. An order of
size St −xt is made at the beginning of period t if the initial inventory level at the
beginning of the period, xt, is smaller than st. Otherwise, no order is placed. The
selling price in period t, pt, is a function of the inventory level after an order was
made.
It turns out that for the additive demand model, the optimal policy and the
analysis are signiﬁcantly diﬀerent from the optimal policy for the general demand
case. In fact, in this case, the symmetric K-convexity is not needed. Speciﬁcally, we
show, in Sect. 10.4.3, that when the demand function is additive, the function φt
is K-concave for any t, and hence an (s, S, p) policy is optimal for problem (10.9).
Formally, in this policy, every period, t, the inventory policy is characterized by
two parameters, the reorder point, st, and the order-up-to level, St. An order of
size St −xt is made at the beginning of period t if the initial inventory level at the
beginning of the period, xt, is smaller than st. Otherwise, no order is placed. The
selling price in period t, pt, is a function of the inventory level after an order was
made.
For more general demand functions, that is, multiplicative plus additive func-
tions, the function φt is not necessarily K-concave and an (s, S, p) policy is not
necessarily optimal. Indeed, in this case, we show, in Sect. 10.4.4, that φt is sym-
metric K-concave, which allows us to characterize the optimal policy for the gen-
eral demand model. Finally, in Sect. 10.4.5, we show that our results imply that
in the special case with zero ﬁxed cost and general demand functions, a base stock
list price policy is optimal.
10.4.3
Additive Demand Functions
In the additive demand model, the demand function is assumed to be of the form
dt = Dt(pt) + βt,
where βt is a random variable.

10.4 Finite-Horizon Models
191
Observe that a special case of this demand function is the additive linear demand
function in which dt = bt −atpt + βt, with bt, at > 0 for t = 1, 2, . . . , T .
In the following, we show, by induction, that ft(y) is a K-concave function of
y and φt(x) is a K-concave function of x. Therefore, the optimality of an (s, S, p)
policy follows directly from Lemma 9.3.2.
To prove that ft(y) is a K-concave function of y, we need the following lemma.
Lemma 10.4.6 Assume that r is concave on a bounded interval [d, ¯d] and w : ℜ→
ℜis continuous. Then there exists an optimal solution d(x) of the optimization
problem
f(x) = max
d∈[d, ¯d] r(d) + w(x −d)
(10.18)
such that x −d(x) is nondecreasing in x. If w is K-concave, then f is also K-
concave.
Proof. Deﬁne a new variable ˜d = x −d. We have that
f(x) =
max
x−˜d∈[d, ¯d]
r(x −˜d) + w( ˜d).
Our assumption, together with Theorem 2.2.6, implies that the objective function
of the above optimization problem is supermodular in (x, ˜d). It is also easy to
verify that the constraint set is a lattice. Thus, from Theorem 2.2.8, there exists
an optimal solution ˜d(x) that is nondecreasing in x. The ﬁrst part of the lemma
follows since d(x) = x −˜d(x) is optimal to problem (10.18).
To prove the second part of the lemma, take any x, x′ with x ≤x′ and λ ∈[0, 1].
Since f is K-concave and ˜d(x) is nondecreasing, we have that
f((1 −λ)x + λx′) ≥r((1 −λ)d(x) + λd(x′)) + w((1 −λ) ˜d(x) + λ ˜d(x′))
≥(1 −λ)r(d(x)) + λr(d(x′)) + (1 −λ)w( ˜d(x))
+λw( ˜d(x′)) −λk
= (1 −λ)f(x) + λf(x′) −λk,
where the ﬁrst inequality and the equality follow from the deﬁnition of ˜d(·) and
d(·), and the second inequality from the concavity of r(d) and K-concavity of w(x)
as well as the monotonicity of ˜d(x). Thus, f is K-concave.
We are now ready to prove our main results for the additive demand model.
Theorem 10.4.7
(a) For any t = 1, 2, . . ., T , gt(y, d) is jointly continuous in
(y, d), and hence for any ﬁxed y, gt(y, d) has a ﬁnite maximizer dt(y) such
that y −dt(y) is nondecreasing in y. Furthermore,
lim
|y|→∞gt(y, d) = −∞for any d ∈[dt, ¯dt] uniformly .
(b) For any t = 1, 2, . . . , T , ft(y) and φt(x) are K-concave.

192
10. Integration of Inventory and Pricing
(c) For any t = 1, 2, . . . , T , there exist st and St with st ≤St such that it
is optimal to order St −xt and set the selling price pt(xt) = D−1
t (dt(St))
when the initial inventory level xt < st, and not to order anything and set
pt(xt) = D−1
t (dt(xt)) when xt ≥st.
Proof. We prove by induction. For period T , part (a) follows directly from As-
sumption 10.4.1. Parts (b) and (c) hold since fT (y) is concave.
Assume that parts (a), (b), and (c) hold for t + 1. Since gt+1(y, d) is contin-
uous, ft+1(y) = maxd∈[dt, ¯dt] gt+1(y, d), and hence, φt+1(x) = max{ft(x), K +
miny≥x ft(y)} are also continuous, which implies that gt(y, d) is continuous in
(y, d) as well. Note that gt(y, d) can be expressed as the sum of a concave function
of d and a K-concave function of y−d since φt+1(x) is K-concave. Therefore, from
Lemma 10.4.6, ft(y) is K-concave, and from Proposition 9.3.3, φt is K-concave as
well. Thus, part (b) holds for period t.
In addition, we have again by Lemma 10.4.6 that for any ﬁxed y, gt(y, d) has a
ﬁnite maximizer dt(y) such that y −dt(y) is nondecreasing in y. The optimality of
the (st+1, St+1) policy implies that
E[φt+1(y −d −βt)] ≤φt+1(St+1)
for any (y, d), and hence, lim|y|→∞gt(y, d) = −∞for any d ∈[dt, ¯dt] uniformly by
Assumption 10.4.1. Therefore, part (a) holds for period t.
We now prove part (c). Since ft(y) is K-concave, Lemma 9.3.2 part (d) implies
that there exist st and St such that St maximizes ft(y) and st is the smallest value
of y such that ft(St) = ft(y) + K, and
φt(x) =
 −K + ft(St)
if x ≤st,
ft(x)
if x ≥st.
Hence, part (c) holds.
Finally, the optimality of the price function pt(xt) follows from the deﬁnition of
dt(y).
Thus, Theorem 10.4.7 implies that an (s, S, p) policy is optimal when the de-
mand is additive. In addition, there exists an optimal solution dt(y) maximizing
(10.10) such that y −dt(y) is a nondecreasing function of y. That is, the higher the
initial inventory level at the beginning of time period t, yt, the higher the expected
inventory level at the end of period t, yt −dt(yt).
An interesting question is whether a list price policy is optimal, as is the case for
the single-period model with no ﬁxed cost. Unfortunately, this property does not
hold for the ﬁnite-horizon model, as illustrated by Chen and Simchi-Levi (2004a).
Indeed, although there is incentive to lower the selling price to reduce inventory,
there is also incentive to raise the price in order to slow the depletion of inventory
and delay the incurring of ﬁxed ordering cost.

10.4 Finite-Horizon Models
193
10.4.4
General Demand Functions
In this section, we focus on the model with general demand functions (10.1). Ob-
serve that the additive demand function analyzed in the previous section is a spe-
cial case of the general demand function (10.1). More importantly, multiplicative
demand functions of the form dt = αtDt(p), where Dt(p) = atp−bt (at > 0, bt > 1),
or demand functions of the form dt = βt + αt(bt −atp) (at > 0, bt > 0) are also
special cases.
To characterize the optimal policy for the model with the demand functions
(10.1), one might consider using the same approach applied in Sect. 10.4.3. Unfor-
tunately, in this case, the function y −αtdt(y) is not necessarily a nondecreasing
function of y for all possible αt, as is the case for additive demand functions. Hence,
the approach employed in Sect. 10.4.3 does not work in this case. In fact, as demon-
strated in Chen and Simchi-Levi (2004a), the function gt(y, dt(y))and φt(x) are in
general not K-concave, and an (s, S, p) policy is not necessarily optimal.
To overcome these diﬃculties, we apply the concept of symmetric K-convexity
introduced in Sect. 10.4.2. Speciﬁcally, in the following, we show, by induction,
that gt(y, d) is a symmetric K-concave function of (y, d) and φt(x) is a symmetric
K-concave function of x. Hence, a characterization of the optimal pricing and
ordering policies follows from Lemma 10.4.3.
Theorem 10.4.8
(a) For any t, gt(y, d) is continuous in (y, d), and hence for
any ﬁxed y, gt(y, d) has a ﬁnite maximizer dt(y). Furthermore,
lim
|y|→∞gt(y, d) = −∞for any d ∈[dt, ¯dt] uniformly .
(b) For any t = 1, 2, . . . , T , gt(y, d) and φt(x) are symmetric K-concave.
(c) For any t = 1, 2, . . ., T , there exist st and St with st ≤St and a set At ⊆
[st, (st +t)/2] such that it is optimal to order St −xt and set the selling price
pt = D−1
t (dt(St)) when the initial inventory level xt < st or xt ∈At, and
not to order anything and set pt = D−1
t (dt(xt)) otherwise.
Proof. The proof of part (a) is similar to that of part (a) in Theorem 10.4.7. We
now focus on part (b).
By induction, φT +1(x) = 0 is symmetric 0-concave. From the symmetric K-
concavity of φt+1(x), we have that E[φt+1(y −αtd −βt)] is symmetric K-concave.
Also, we have that Hγ
t (y, d) is concave by Assumption 10.4.1. Hence, gt(y, d) is
symmetric γK-concave, and hence by Lemma 10.4.5, the function ft(y) is symmet-
ric γK-concave. Finally, ft(y) is symmetric K-concave by Lemma 10.4.3 part (a),
and the symmetric K-concavity of φt(x) follows from Proposition 10.4.4. Thus,
part (b) holds.
We now prove part (c). From Lemma 10.4.3 part (d), we have
φt(x) =

−K + ft(St)
if x ∈It,
ft(x)
if x ̸∈It,

194
10. Integration of Inventory and Pricing
where St is the maximizer of ft(y) and
It = {y ≤St | ft(y) ≤ft(St) −K}.
Furthermore, φt(x) ≥ft(x) for any x and φt(x) ≥−K + ft(St) for any x ≤St.
Let st be deﬁned as the smallest value of y such that ft(St) = ft(y) + K. Note
that from Lemma 10.4.3 part (d), (−∞, st] ⊂It and [(st + St)/2, ∞) ⊂(It)c, the
complement of It. Part (c) follows from Lemma 10.4.3 and part (b) by deﬁning
At = It ∩[st, (st + St)/2].
Again, the optimality of the price function pt(xt) follows from the deﬁnition of
dt(y).
Theorem 10.4.8 thus implies that the optimal policy for problem (10.7) is an
(s, S, A, p) policy. Such a policy is characterized by two parameters, st and St,
and a set At ⊆[st, (st + St)/2], possibly empty. When the inventory level xt at
the beginning of the period t is less than st or xt is in the set At, an order of
size St −xt is made. Otherwise, no order is placed. Thus, it is possible that an
order will be placed when the inventory level xt ∈[st, (st + St)/2], depending on
the problem instance. In any case, if an order is placed, it is always to raise the
inventory level to St.
10.4.5
Special Case: Zero Fixed Ordering Cost
We now apply our results to the zero-ﬁxed-cost case.
Corollary 10.4.9 Consider our model with zero ﬁxed ordering cost and general
demand functions (10.1). In this case, a base stock list price policy is optimal.
Proof. By Theorem 10.4.8, the functions φt(x) and ft(y), t = 1, 2, . . . , T , are
symmetric 0-concave and hence, from Deﬁnition 10.4.2, concave. The optimality
of the base stock inventory policy follows directly from the concavity of ft(y) for
t = 1, 2, . . . , T .
We now show that dt(y) is nondecreasing, and therefore the optimal price pt(y) is
nonincreasing. In fact, in the zero ﬁxed ordering cost case, gt(y, d) can be expressed
as r(d)+E[w(y−αd)] for some concave function w, and thus Theorem 2.2.6 implies
that gt(y, d) is supermodular. From Theorem 2.2.8, there exists dt(y), which is
nondecreasing.
10.5
Alternative Approach to the Optimality of (s, S, p)
Policies
The analysis in the previous section builds upon the concept of K-convexity and
its extension, symmetric K-convexity. In this section, we provide an alternative

10.5 Alternative Approach to the Optimality of (s, S, p) Policies
195
approach developed by Huh and Janakiraman (2008) to prove the optimality of
(s, S, p) policies for the model in Sect. 10.4. The approach is essentially an exten-
sion of the one in Sect. 9.4 for stochastic inventory models to integrated inventory
and pricing models. Similar to Sect. 9.4, we focus on stationary systems. That is,
the inventory holding and backorder cost function ht and parameters ct, dt, and
¯dt are all time-independent, and the random variables (αt, βt) (t = 1, 2 . . ., T ) are
iid across time. Thus, we drop the subscript t of dt, ¯dt, and Hγ
t in the dynamic
program (10.9)–(10.10) in this section.
We assume that Hγ(y, d) is continuous in (y, d) and lim|x|→∞Qγ(x) = −∞,
where Qγ(x) = maxd∈[d, ¯d] Hγ(x, d). With these assumptions, the functions φt and
ft are continuous, and lim|x|→∞φt(x) = lim|x|→∞ft(x) = −∞. Thus, the related
optimal solutions exist in the dynamic program (10.9)–(10.10). Let y0 be a global
maximizer of Qγ(x). We make the following assumption.
Assumption 10.5.1
(a) For any y1 and y2 with y2 ≤y1 ≤y0 and d2 ∈[d, ¯d],
there exists a d1 ∈[d, ¯d] such that
Hγ(y1, d1) ≥Hγ(y2, d2) and y1 −αd1 −β ≥y2 −αd2 −β
for any realization of (α, β).
(b) For any y1 and y2 with y0 ≤y1 ≤y2 and d2 ∈[d, ¯d], there exists a d1 ∈[d, ¯d]
such that
Hγ(y1, d1) ≥Hγ(y2, d2) and y1 −αd1 −β ≤max{y2 −αd2 −β, y0}
for any realization of (α, β).
Observe that given (y, d) and the realization of (α, β) at a period, y −αd −
β, represents the initial inventory level of the next period. Assumption 10.5.1
indicates that for any (y2, d2), if y1 is closer to y0—the inventory level that attains
the highest single-period expected proﬁt—than y2, we can always ﬁnd an expected
demand level d1 (correspondingly a selling price) such that (y1, d1) incurs a higher
single-period expected proﬁt than (y2, d2). This implies that Qγ is quasiconcave.
In addition, the initial inventory level of the next period resulting from (y1, d1) is
closer to y0 than that from (y2, d2), or one can raise the inventory level y1−αd1−β
to y0 by placing an order in the case with y0 ≤y1 ≤y2. The approach in this
section is applicable for demand models more general than the linear one presented
here, for which we refer to Huh and Janakiraman (2008).
We now present conditions under which Assumption 10.5.1 is valid. Recall the
deﬁnitions of hγ
t and ˆR in (10.8).
Proposition 10.5.2 Assume additive demand, namely, α = 1. If E[hγ
t (x −β)] is
quasiconvex and ˆR(d) is quasiconcave, then Assumption 10.5.1 holds.
Proof.
Let d0 be a global maximizer of ˆR over [d, ¯d] and let x0 be a global
minimizer of E[hγ
t (x −β)]. Since Hγ(y, d) = ˆR(d) −E[hγ
t (y −d −β)], y0 = d0 + x0
is a global maximizer of Qγ.

196
10. Integration of Inventory and Pricing
First, consider the case with y2 ≤y1 ≤y0. For any ﬁxed d2 ∈[d, ¯d], deﬁne
d1 = min{(y1 −y2) + d2, d0}.
If d1 = (y1 −y2) + d2, we have that
y1 −d1 −β = y2 −d2 −β, d2 ≤d1 ≤d0
and
Hγ(y1, d1) = ˆR(d1) −E[hγ
t (y1 −d1 −β)]
≥ˆR(d2) −E[hγ
t (y2 −d2 −β)] = Hγ(y2, d2),
where the inequality follows from the quasiconcavity of ˆR.
If d1 = d0, we have that d0 ≤(y1 −y2) + d2. Hence,
y0 −d0 −β ≥y1 −d1 −β ≥y2 −d2 −β,
which implies that
Hγ(y1, d1) = ˆR(d1) −E[hγ
t (y1 −d1 −β)]
≥ˆR(d2) −E[hγ
t (y2 −d2 −β)] = Hγ(y2, d2),
where the inequality follows from the deﬁnition of d0 and the quasiconvexity of
E[hγ
t (x −β)]. Thus, Assumption 10.5.1 part (a) holds.
For the case with y2 ≤y1 ≤y0, deﬁne
d1 = max{(y1 −y2) + d2, d0}.
Assumption 10.5.1 part (b) follows from a similar argument.
Lemma 10.5.3 Under Assumption 10.5.1, for any y2
t ≤y1
t ≤y0,
ft(y1
t ) ≥ft(y2
t );
for y0 ≤y1
t ≤y2
t ,
ft(y1
t ) ≥ft(y2
t ) −γK.
Proof. At period t, we compare two systems with initial inventory levels y1
t and y2
t ,
referred to as systems y1 and y2, respectively. Assume that system y2 follows an
optimal strategy that attains ft(y2
t ), the expected total discounted proﬁt, for the
remaining T −t + 1 periods if we act optimally in the remaining T −t + 1 periods
except that no order is placed at period t. For a given sample path of the system,
namely, a realization of system uncertainties, denote (x2
l , y2
l , d2
l ) as the inventory
level before placing the order, the inventory level after receiving the order, and
the expected demand level of period l of system y2 following the optimal strategy,
respectively. We will construct a feasible strategy for system y1 and compare its
expected total discounted proﬁt with ft(y2
t ). Let (x1
l , y1
l , d1
l ) be the inventory level

10.5 Alternative Approach to the Optimality of (s, S, p) Policies
197
before placing the order, the inventory level after receiving the order, and the
expected demand level of period l of system y1 along this sample path under this
strategy, respectively. Note that xi
l+1 = yi
l −αldi
l −βl for a realization (αl, βl) and
i = 1, 2.
We now describe the process of constructing a strategy for system y1. For the
case with y2
t ≤y1
t ≤y0, according to Assumption 10.5.1 part (a), we can pick a
d1
t ∈[d, ¯d] such that
Hγ(y1
t , d1
t) ≥Hγ(y2
t , d2
t) and x2
t+1 ≤x1
t+1 ≤y0.
(10.19)
For the case with y0 ≤y1
t ≤y2
t , according to Assumption 10.5.1 part (b), we can
select a d1
t ∈[d, ¯d] such that
Hγ(y1
t , d1
t) ≥Hγ(y2
t , d2
t) and x1
t+1 ≤max{x2
t+1, y0}.
In either case, we end up with two possibilities:
(1) x1
t+1 < y2
t+1 or (2) y2
t+1 ≤x1
t+1 ≤y0.
In the ﬁrst case, for system y1, place an order to raise the inventory level from x1
t+1
to y2
t+1 at period t + 1, use d2
t+1, and follow the strategy of system y2 thereafter.
In the second case, for system y1, order nothing at period t+1. Thus, y1
t+1 = x1
t+1
and y2
t+1 ≤y1
t+1 ≤y0. We then repeat the process at period t+1 and later periods
if necessary until systems y1 and y2 end up with the same inventory level or we
reach the end of the planning horizon.
From the description of the process, for y2
t ≤y1
t ≤y0, it is clear that at any
period l with l ≥t, the realized proﬁt of system y1 is always no less than that of
system y2. Note that when x1
t+1 < y2
t+1, system y2 must have placed an order at
period t+1. Since this is true along any sample path, we have that ft(y1
t ) ≥ft(y2
t ).
The case with y0 ≤y1
t ≤y2
t is similar except that when x1
t+1 < y2
t+1, system
y1 needs to place an order at period t + 1, while system y2 may not. Therefore,
ft(y1
t ) ≥ft(y2
t ) −γK.
The above lemma allows us to show the optimality of (s, S, p) policy under
Assumption 10.5.1.
Theorem 10.5.4 Consider the ﬁnite-horizon model described in Sect. 10.4. If
the system is stationary and Assumption 10.5.1 holds, then an (s, S, p) policy is
optimal.
Proof. Let St be a global maximizer of ft with St ≥y0. Its existence is guaranteed
by our assumptions on Hγ and Lemma 10.5.3. Let st = min{x|ft(x) = ft(St)−K}.
Since ft is continuous and lim|x|→∞ft(x) = −∞, st is well deﬁned. In addition,
st ≤y0 since from Lemma 10.5.3, ft(y) ≥ft(St)−γK for any y with St ≥y ≥y0.
We show that the (st, St) inventory policy is optimal. To see this, note that for
any y1
t ≤st, ft(y1
t ) ≤ft(st) = ft(St) −K. Thus, it is optimal to place an order

198
10. Integration of Inventory and Pricing
to raise the inventory level to St. On the other hand, for any inventory level y1
t
above st, it is optimal not to place an order. In fact, if y1
t ∈[st, y0],
ft(y1
t ) ≥ft(st) = ft(St) −K,
and if y1
t ≥y0, from Lemma 10.5.3,
ft(y1
t ) ≥ft(y2
t ) −γK ≥ft(y2
t ) −K ∀y0 ≤y1
t ≤y2
t ,
which implies that it is better oﬀnot to place an order.
Interestingly, using a similar approach but under a less restrictive assumption,
we can show that a stationary (s, S, p) policy is optimal for a corresponding
inﬁnite-horizon model with stationary parameters and general demand functions
under the discounted proﬁt criterion.
Assumption 10.5.5
(a) For any y1 and y2 with y2 ≤y1 ≤y0 and d2 ∈[d, ¯d],
there exists d1 ∈[d, ¯d] such that
Hγ(y1, d1) ≥Hγ(y2, d2).
(b) The same as Assumption 10.5.1 part (b).
Again, the above assumption implies that Qγ is quasiconcave.
Proposition 10.5.6 If Hγ(y, d) is quasiconcave in (y, d), then Assumption 10.5.5
holds.
Proof. Let d0 be the global maximizer of Hγ(y0, d) for d ∈[d, ¯d]. For any y1
and y2 with y2 ≤y1 ≤y0 or y0 ≤y1 ≤y2 and d2, let λ ∈[0, 1] such that
y1 = (1 −λ)y0 + λy2. Deﬁne
d1 = (1 −λ)d0 + λd2.
From the quasiconcavity of Hγ, we have that
Hγ(y1, d1) ≥min{Hγ(y0, d0), Hγ(y2, d2)} = Hγ(y2, d2).
For y0 ≤y1 ≤y2 and any realization of (α, β),
y1 −αd1 −β = (1 −λ)(y0 −αd0 −β) + λ(y2 −αd2 −β)
≤max{y0 −αd0 −β, y2 −αd2 −β}
≤max{y0, y2 −αd2 −β}.
Thus, Assumption 10.5.5 holds.
When ˆR is concave and hγ is convex, Hγ is concave and thus quasiconcave. It
would be interesting to identify other conditions under which Hγ is quasiconcave
or Assumption 10.5.5 holds.

10.5 Alternative Approach to the Optimality of (s, S, p) Policies
199
Lemma 10.5.7 Under Assumption 10.5.5, for any y2
t ≤y1
t ≤y0 or y0 ≤y1
t ≤y2
t ,
ft(y1
t ) ≥ft(y2
t ) −γK.
Proof. The proof is similar to that for Lemma 10.5.3. The only exception is that
for the case with y2
t ≤y1
t ≤y0, we may no longer claim x2
t+1 ≤x1
t+1 in (10.19)
under Assumption 10.5.5. In this case, we cannot exclude the possibility that
system y1 places an order at period t + 1 to raise the inventory level from x1
t+1
to y2
t+1 while system y2 does not order at period t + 1. Thus, for y2
t ≤y1
t ≤y0,
ft(y1
t ) ≥ft(y2
t ) −γK instead of ft(y1
t ) ≥ft(y2
t ).
Theorem 10.5.8 Consider the inﬁnite-horizon counterpart of the model described
in Sect. 10.4 with stationary parameters and γ ∈(0, 1). If Assumption 10.5.5 holds,
then a stationary (s, S, p) policy is optimal.
Proof. For the inﬁnite-horizon counterpart of the model described in Sect. 10.4
with stationary parameters and γ ∈(0, 1), we can show that ft is well deﬁned and
continuous and lim|x|→∞ft(x) = −∞. In addition, it is independent of t, and thus
we drop the subscript of ft in the proof.
Let S be a global maximizer of f and s = max{x|f(x) = f(S) −K, x ≤
min{S, y0}}. We show that it is optimal to follow the (s, S) policy. The deﬁni-
tion of s implies that for any x ∈(s, min{S, y0}], it is optimal not to order. From
Lemma
10.5.7,
for
any
given
x
with
x
≥
min{S, y0},
if
S ≤x ≤y0,
f(x) ≥f(S) −λK ≥f(S) −K;
and if x ≥y0, then for any y ≥x,
f(x) ≥f(y) −λK ≥f(y) −K.
Thus, for any x ≥s, it is optimal not to order.
It remains to prove that for any x ≤s, it is optimal to place an order to raise
the inventory level to S. First, observe that at the inventory level s, the expected
proﬁt generated by the strategy of not ordering now but ordering up to S at the
next period is given by Qγ(s) + γ(f(S) −K), which by deﬁnition is no more than
f(s) = f(S) −K. Therefore,
Qγ(s) ≤(1 −γ)(f(S) −K).
Assume that it is not optimal to order for some x ≤s. Start with the initial
inventory level x at any period, without loss of generality, at the ﬁrst period.
Given an optimal strategy, let τ be the ﬁrst time that an order is placed for a
realization of the uncertainties. Clearly, τ is a stopping time and we have that
x = x1 ≥x2 . . . ≥xτ,
where xt denotes the inventory level at the beginning of period t. At period t < τ,
no order is placed and the proﬁt is no more than Qγ(xt). Thus, for the realization

200
10. Integration of Inventory and Pricing
of the uncertainties, the total discounted proﬁt from periods 1 to τ −1 is no more
than

t<τ
γt−1Qγ(xt).
Since Qγ is quasiconcave, Qγ(xt) ≤Qγ(s) for t < τ and the above proﬁt is no
more than

t<τ
γt−1Qγ(s) ≤(f(S) −K)(1 −γτ−1).
At period τ, it is optimal to raise the inventory level to S, since S is a global
maximizer of f and x ≤S. Conditioning on τ, the net present value of the total
expected discounted proﬁt from periods τ to T = ∞is (1 −γ)τ−1(f(S) −K).
Therefore, starting with x, the total expected discounted proﬁt over the inﬁnite
planning horizon is no more than f(S) −K. However, this proﬁt can be obtained
by placing an order at period 1 to raise the inventory level to S. Thus, for any
x ≤s, it is optimal to place an order to raise the inventory level to S.
10.6
Extensions and Challenges
In Sect. 10.4, we show by employing the classic concept of K-convexity that an
(s, S, p) policy is optimal for the additive demand case. By using a weaker concept
of symmetric K-convexity, we show that an (s, S, A, p) policy is optimal for the
general demand case. Theorem 10.5.8 in Sect. 10.5 shows that a stationary (s, S, p)
policy is optimal for the inﬁnite-horizon counterpart with stationary parameters
and general demand functions under the discounted proﬁt criterion. Based on
the concept of symmetric K-concavity, Chen and Simchi-Levi (2004b) provide a
uniﬁed proof for the optimality of a stationary (s, S, p) policy for the inﬁnite-
horizon model under either the discounted proﬁt or the average proﬁt criterion.
Table 10.1 is a summary of structural results of the inventory (and pricing) models.
TABLE 10.1. Summary of results for the inventory (and pricing) problems
Inventory model
Joint inventory and pricing model
No ﬁxed
Base stock
Base stock list price policy
cost
policy
Fixed
(s,S)Policy
Finite-horizon case
Inﬁnite-
ordering
Additive
General
horizon
cost
demand
demand
case
(s,S,p)
(s,S,A,p)
(s,S,p)
Policy
Policy
Policy
Of course, it is appropriate to point out that many of our results in this chap-
ter may not hold for problems with discrete prices (see Chen 2003). Indeed, if

10.7 Risk-Averse Inventory Models
201
price is restricted to take values from a discrete set, even the single-period proﬁt
function may not be concave, and our analysis no longer works. This fact imposes
a signiﬁcant challenge for solving the integrated inventory and pricing models,
since in order to solve these models, one usually discretizes inventory levels and
discrete prices. Thus, a natural question is whether one can design eﬃcient algo-
rithms by employing the structural results of optimal policy identiﬁed in previous
subsections.
Another challenge for the integrated inventory and pricing models analyzed in
this section is the zero-lead-time assumption. This is not the case for the standard
inventory control problems with backlogging. In fact, for the standard stochastic
inventory models, the structural results of the optimal policies can be generally
extended to models with deterministic lead time, as we pointed out at the begin-
ning of Sect. 9.6. The idea is to transfer a model with a positive lead time to one
with a similar structure while with zero lead time. However, this technique is not
valid here, since for our models with a positive lead time, the two decisions—the
ordering decision and the pricing decision—will take eﬀect at diﬀerent times. Yet,
as demonstrated by Pang et al. (2012) , the concept of L♮-convexity can still be
useful, and the results in Sect. 9.6 can be extended to the integrated inventory and
pricing models with positive lead times and backlogging. Speciﬁcally, they show
that the optimal ordering quantity decreases in the on-hand inventory and the
inventory in transit and is more sensitive to newer outstanding orders than older
outstanding orders and the on-hand inventory with bounded sensitivities. The op-
timal price decreases in the on-hand inventory and the inventory in transit as well.
However, it is more sensitive to older outstanding orders and the on-hand inven-
tory than newer outstanding orders. More recently, Chen et al. (2012a) extend the
models and results to perishable products with ﬁnite lifetimes.
In this chapter, we restrict our eﬀort to backlogging models. Lost sales models
are much more complicated to deal with. In this case, even in the single-period
model, the expected revenue pE[min(x, D(p, ϵ))] as a function of p and x may
not be well behaved. Many papers in the literature focus on the existence and
uniqueness of the optimal solutions, the concavity or quasiconcavity of the ex-
pected proﬁt functions, and comparative statics analysis. We refer to Chen and
Simchi-Levi (2012) for references.
Finally, a few recent papers analyze integrated inventory and pricing models with
price adjustment cost (Chen, Zhou and Chen 2011 and Chen and Hu 2012) and
models in which demand depends on not only the current price but also previous
prices (Chen et al. 2012c). Again, we refer to Chen and Simchi-Levi (2012) for a
survey of these new developments.
10.7
Risk-Averse Inventory Models
All the inventory (and pricing) models discussed so far focus on risk-neutral deci-
sion makers, that is, inventory managers who are insensitive to proﬁt variations.
Evidently, not all inventory managers are risk-neutral; many planners are willing

202
10. Integration of Inventory and Pricing
to trade oﬀlower expected proﬁt for downside protection against possible losses.
Indeed, experimental evidence suggests that for some products, the so-called high-
proﬁt products, decision makers are risk-averse; see Schweitzer and Chachon (2000)
for more details. Unfortunately, traditional inventory control models fall short of
meeting the needs of risk-averse planners. For instance, traditional inventory mod-
els do not suggest mechanisms to reduce the chance of unfavorable proﬁt levels.
Thus, it is important to incorporate the notions of risk aversion in a broad class
of inventory models.
The literature on risk-averse inventory models is quite limited and mainly focuses
on single-period problems or is based on mean–variance tradeoﬀs. For instance,
Lau (1980) analyzes the classical newsvendor model, in which he maximizes the
decision maker’s expected utility of total proﬁt or the probability of achieving
a certain level of proﬁt. Eeckhoudt, Gollier and Schlesinger (1995) focus on the
impact of risk and risk aversion in the newsvendor model when risk is measured
by expected utility functions.
Chen and Federgruen (2000) analyze the mean–variance tradeoﬀs in newsven-
dor models as well as some standard inﬁnite-horizon inventory models. Speciﬁcally,
in the inﬁnite-horizon models, Chen and Federgruen focus on the mean–variance
tradeoﬀof customer waiting time as well as the mean–variance tradeoﬀs of inven-
tory levels. Mart´ınez-de-Alb´eniz and Simchi-Levi (2006) study the mean–variance
tradeoﬀs faced by a manufacturer signing a portfolio of option contracts with its
suppliers and having access to a spot market.
Assuming a linear ordering cost, Bourakiz and Sobel (1992) minimize the ex-
pected exponential utility of the present value of costs over a ﬁnite planning horizon
or an inﬁnite horizon. In particular, they show that a base stock policy is optimal.
So far, all the papers referenced above assume that demand is exogenous. A rare
exception is Agrawal and Seshadri (2000) who consider a risk-averse retailer that
has to decide on its ordering quantity and selling price for a single period. They
demonstrate that diﬀerent assumptions on the demand–price function may lead
to diﬀerent properties of the selling price.
In this section, we discuss a general framework for incorporating risk aversion
in multiperiod inventory (and pricing) models, in which risk is measured based
on increasing and concave utility functions. Our analysis is based on Chen, Sim,
Simchi-Levi and Sun (2007).
The assumptions made in the risk-averse models are similar to those in the joint
inventory and pricing models analyzed in Sect. 10.4. One exception is that demand
is a linear function of the selling price; that is, Dt(p) is a linear function of p. More
importantly, the objective of the risk-averse decision maker is to maximize the
expected utility of the total discounted proﬁt over the planning horizon. That is,
the objective is to maximize
E[u(V γ
T (x))]
(10.20)
for any initial inventory level x and any given 0 < γ ≤1, where u(·) is a utility
function and V γ
T (x)) is deﬁned in (10.5).

10.7 Risk-Averse Inventory Models
203
We require the utility function, u(x), to be increasing so that more is always
preferred over less. Of course, if u(x) is a linear and increasing function, the model
(10.20) yields the same optimal solution as the risk-neutral model of (10.6). We
also assume that the utility function is concave so that the marginal satisfaction
of gaining a dollar is never more than the marginal loss of satisfaction associated
with losing the same amount of money. It is appropriate to point out that expected
utility theory is widely used in microeconomics and ﬁnance literature.
In the next subsection, we discuss the risk-averse framework based on a general
increasing and concave utility function. This is followed by a subsection on models
based on an important special case, the exponential utility.
10.7.1
Expected Utility Risk-Averse Models
Unlike the risk-neutral models analyzed in Sect. 10.4, the objective function (10.20)
in its current form appears not to be decomposable and is not amenable to the
dynamic programming approach. To deal with this issue, we introduce a new
variable w to denote the wealth accumulated from the beginning of the planning
horizon up to the current period. Thus, the state of the problem at period t can
now be modeled as the inventory level xt and the accumulated wealth from period
T to period t, wt.
Consider the expected utility measure. Let Wt(x, w) be the maximum utility
achievable starting at the beginning of period t with an initial inventory level x
and an accumulated wealth w. The dynamic program can be written as follows.
Let
WT +1(x, w) = u(w),
and for t = 1, 2, . . ., T ,
Wt(x, w) =
max
y≥x,¯pt≥p≥pt
E[Wt+1(x+, ¯w+)],
(10.21)
where
x+ = y −Dt(p, ϵt)
and
¯w+ = w + γt−1(−Kδ(y −x) −ct(y −x) + pDt(p, ϵt) −ht(y −Dt(p, ϵt)). (10.22)
We would like to emphasize that in this section, Dt(p, ϵt) is linear in p. Also notice
that here we assume, without loss of generality, that WT +1(x, w) is independent
of x, which implies zero salvage value. Finally, we have
max E[u(V γ
T (x))] = W1(x, 0).
Instead of working with the dynamic program (10.21), we ﬁnd that it is more
convenient to work with an equivalent formulation. Let
Ut(x, w) = Wt(x, w −γt−1ctx).

204
10. Integration of Inventory and Pricing
The dynamic program (10.21) becomes
Ut(x, w) =
max
y≥x,¯pt≥p≥pt
E[Ut+1(x+, w+)],
(10.23)
where
w+ = w + γt−1(−Kδ(y −x) + ft(y, p, ϵt))
and
ft(y, p, ϵt) = −(ct −γct+1)y + (p −γct+1)Dt(p, ϵt) −ht(y −Dt(p, ϵt)).
(10.24)
We have the following observation, which can be easily veriﬁed by induction.
Lemma 10.7.1 For any period t and ﬁxed x, Ut(x, w) is increasing in w.
Interestingly, this observation allows us to show that a wealth-dependent base
stock inventory policy is optimal when there is zero ﬁxed ordering cost.
Theorem 10.7.2 Assume that K = 0. In this case, Ut(x, w) is jointly concave in
x and w for any period t. Furthermore, a wealth-dependent base stock inventory
policy is optimal for the risk-averse inventory (and pricing) problem (10.20).
Proof. We prove by induction. Obviously, UT +1(x, w) is jointly concave in x and
w. Assume that Ut+1(x, w) is jointly concave in x and w. We now prove that a
wealth-dependent base stock inventory policy is optimal and Ut(x, w) is jointly
concave in x and w.
First, notice that for any realization of ϵt, ft is jointly concave in (y, p), which
implies that w+ is jointly concave in (w, x, y, p).
Since x+ is a linear function of (y, p) and w+ is jointly concave in (w, x, y, p),
Lemma 10.7.1 allows us to show that Ut+1(x+, w+) is jointly concave in (w, x, y, p).
This implies that E[Ut+1(x+, w+)] is jointly concave in (w, x, y, p).
We now prove that a w-dependent base stock inventory policy is optimal. Let
y∗(w) be an optimal solution for the problem
max
y

max
¯pt≥p≥pt
E[Ut+1(x+, w+)]
 
.
Since E[Ut+1(x+, w+)] is concave in y for any ﬁxed w, it is optimal to order up
to y∗(w) when x < y∗(w) and not to order otherwise. In other words, a state-
dependent base stock inventory policy is optimal.
Finally, according to Proposition 2.1.15, Ut(x, w) is jointly concave.
Recall that in the case of a risk-neutral decision maker, a base stock list price
policy is optimal. Theorem 10.7.2 thus implies that in the case of an increasing
concave utility risk measure, the optimal policy is quite diﬀerent. Indeed, in these
cases, the base stock level depends on the total proﬁt accumulated from the be-
ginning of the planning horizon, and it is not clear whether a list price policy is
optimal.
Stronger results exist for models based on the exponential utility risk measure,
as is demonstrated in the next subsection.

10.7 Risk-Averse Inventory Models
205
10.7.2
Exponential Utility Risk-Averse Models
We now focus on exponential utility functions of the form u(w) = b(1−exp(−w/b))
with parameter b > 0. The beauty of exponential utility functions is that we can
essentially separate x and w as is illustrated in the next theorem.
Theorem 10.7.3 For any time period t, there exists a function Gt(x) such that
Ut(x, w) = u(w + γt−1Gt(x)).
Proof. We prove by induction. For t = T + 1, GT +1(x) = 0 for any x. Assume that
there exists a function Gt+1(x) such that
Ut+1(x, w) = u(w + γtGt+1(x)).
From the recursion (10.21), we have that
Ut(x, w) = maxy≥x,¯pt≥p≥pt bE[1 −exp(−(w+ + γtGt+1(y −Dt(p, ϵt))/b)]
= b −b exp(−w/b) miny≥x,¯pt≥p≥pt
exp(γt−1/b(Kδ(y −x) −Lt(y, p)/b))
= u(w + γt−1Gt(x)),
where
Lt(y, p) = −b/γt−1 ln

E[exp(−γt−1(ft(y, p, ϵt) + γGt+1(y −Dt(p, ϵt))/b)]

and
Gt(x) =
max
y≥x,¯pt≥p≥pt
−Kδ(y −x) + Lt(y, p).
(10.25)
Thus, the result is true.
The theorem thus implies that the optimal policy is independent of the accu-
mulated wealth when exponential utility functions are used, which signiﬁcantly
simpliﬁes the problem. In fact, the optimal policy can be found by solving prob-
lem (10.25). Furthermore, this theorem, together with Theorem 10.7.2, implies
that when there is zero ﬁxed ordering cost, a base stock inventory policy is op-
timal under the exponential utility risk criterion independent of whether or not
price is a decision variable.
Before we present our main result for the problem with K > 0, recall the famous
H¨older inequality.
Theorem 10.7.4 Assume p, q > 0 with 1/p + 1/q = 1. If f and g are continuous
functions on ℜwith

ℜ|f(x)|pdx < ∞and

ℜ|g(x)|qd(x) < ∞, then

ℜ
|f(x)g(x)|dx ≤

ℜ
|f(x)|pdx
1/p 
ℜ
|f(x)|qdx
1/q
.

206
10. Integration of Inventory and Pricing
An important corollary of the H¨older inequality is as follows.
Theorem 10.7.5 If a function f is convex, K-convex, or symmetric K-convex,
then the function
g(x) = ln(E[exp(f(x −ξ))])
is also convex, K-convex, or symmetric K-convex, respectively.
Proof. We only prove the case with K-convexity; the other two cases can be proven
by following similar steps.
Deﬁne M(x) = E[exp(f(x −ξ))]. It suﬃces to prove that for any x0, x1 with
x0 ≤x1 and any λ ∈[0, 1],
M(xλ) ≤M(x0)1−λM(x1)λ exp(λK),
where xλ = (1 −λ)x0 + λx1. Notice that
M(xλ)
≤
E[exp((1 −λ)f(x0 −ξ) + λf(x1 −ξ) + λK)]
=
exp(λK)E[exp((1 −λ)f(x0 −ξ)) exp(λf(x1 −ξ))]
≤
exp(λK)E[exp(f(x0 −ξ))]1−λE[exp(f(x1 −ξ))]λ
=
M(x0)1−λM(x1)λ exp(λK),
where the ﬁrst inequality holds since f is K-convex and the second inequality
follows from the H¨older inequality with 1/p = 1 −λ and 1/q = λ.
We can now present the optimal policy for the risk-averse multiperiod inventory
(and pricing) problem with exponential utility function.
Theorem 10.7.6
(a) If price is not a decision variable (i.e., pt = ¯pt for each t),
Gt(x) and Lt(y, p) are K-concave and an (s, S) inventory policy is optimal.
(b) If price is a decision variable, Gt(x) and Lt(y, p) are symmetric K-concave
and an (s, S, A, p) policy is optimal.
Proof. We only provide a sketch of the proof; the complete proof is left as an ex-
ercise. The main idea of the proof is as follows: If Gt+1(x) is K-concave when
price is not a decision variable (or symmetric K-concave when price is a de-
cision variable), then, by Theorem 10.7.5, Lt(y, p) is K-concave (or symmetric
K-concave). The remaining parts follow directly from Lemma 9.3.2 and Proposi-
tion 9.3.3 for K-concavity (or Lemma 10.4.3 and Proposition 10.4.4 for symmetric
K-concavity).
We observe the similarities and diﬀerences between the optimal policy under the
exponential utility measure and the one under the risk-neutral case. Indeed, when
demand is exogenous, that is, price is not a decision variable, an (s, S) inventory
policy is optimal for the risk-neutral case; see Theorem 9.3.4. Theorem 10.7.6
implies that this is also true under the exponential utility measure. Similarly, for
the more general inventory and pricing problem, Theorem 10.4.8 implies that an

10.8 Exercises
207
TABLE 10.2. Summary of results for ﬁnite-horizon risk-neutral and risk-averse models
Price not a decision
Price is a decision
K = 0
K > 0
K = 0
K > 0
Risk-neutral
Base stock
model
Base stock
(s, S)
List price
(s, S, A, p)
Exponential
utility
Base stock
(s, S)
Base stock
(s, S, A, p)
Increasing &
Wealth-dependent
Wealth-dependent
concave utility
Base stock
?
Base stock
?
(s, S, A, p) policy is optimal for the risk-neutral case. Interestingly, this policy is
also optimal for the exponential utility case.
Of course, the results for the risk-neutral case are a bit stronger. Indeed, if
demand is additive, Theorem 10.4.7 suggests that an (s, S, p) policy is optimal.
Unfortunately, it is not clear whether this result still holds for the risk-averse
inventory and pricing problem under exponential risk measure.
The structural results of the optimal policies for the ﬁnite-horizon risk-averse
models as well as risk-neutral models are summarized in Table 10.2. For inﬁnite-
horizon models with exponential utility and ﬁxed ordering cost, Chen and Sun
(2012) prove that like the inﬁnite-horizon risk-neutral model, a stationary (s, S, p)
is optimal.
10.8
Exercises
Exercise 10.1. Prove Theorem 10.7.5 by Exercise 2.4.
Exercise 10.2. Complete the proof of Theorem 10.7.6.
Exercise 10.3. Recall the single-period model analyzed in Sect. 10.3. We modify
the model as follows. Instead of placing an emergency order to satisfy shortages,
we assume that unsatisﬁed demand is lost. In this case, h(x) is the penalty cost
for lost sales if x < 0. Show that the optimal selling for the additive demand case
is no more than that for the deterministic demand case, which in turn is no more
than that for the multiplicative demand case.
Exercise 10.4. Building on the concept of symmetric K-convexity, Ye and
Duenyas (2007) introduce the concept of (K, Q)-convexity. A real-valued func-
tion f is called (K, Q)-convex for K, Q ≥0 if, for any x0, x1 with x0 ≤x1 and
λ ∈[0, 1],
f((1−λ)x0+λx1) ≤(1−λ)f(x0)+λf(x1)+λK+(1−λ)Q−min{λ, 1−λ} min{K, Q}.
It is easy to see that (K, 0)-convexity is exactly the K-convexity and the (K, K)-
convexity is the symmetric K-convexity. Prove the following.

208
10. Integration of Inventory and Pricing
(a) A (K, Q)-convex function is also (K′, Q′)-convex for K ≤K′ and Q ≤Q′.
A real-valued convex function is (0, 0)-convex and hence (K, Q)-convex for
all K, Q ≥0.
(b) If g1(y) and g2(y) are (K1, Q1)-convex and (K2, Q2)-convex, respectively,
and (K1 −Q1)(K2 −Q2) ≥0, then for α, β ≥0, αg1(y) + βg2(y) is (αK1 +
βK2, αQ1 + βQ2)-convex.
(c) If g(y) is (K, Q)-convex and w is a random variable, then E{g(y −w)} is
also (K, Q)-convex, provided E{|g(y −w)|} < ∞for all y.
(d) Assume that g is a continuous (K, Q)-convex function with K ≥Q and
g(y) →∞as |y| →∞. Deﬁne
S = min{ x | g(x) ≤g(y), for any y},
s = min{ x | g(x) = g(S) + K},
s′ = sup{x | x ≤S, g(x′) ≥g(S) + (K −Q) for any x′ ≤x},
and
u = inf{x | x ≥S, g(x′) ≥g(S) + Q for all x′ ≥x}.
Then s ≤s′ ≤S ≤u, and we have the following results.
(i) g(s) = g(S) + K and g(y) ≥g(s) for all y ≤s.
(ii) g(u) = g(S) + Q and g(y) ≥g(u) for all y ≥u.
(iii) g(y) ≤g(z) + Q for all y, z with z ≤y ≤s′.
(iv) g(y) ≤g(z) + K for all y, z with s′ ≤y ≤z.
(v) g(y) ≤g(z) + K for all y, z with (s + S)/2 ≤y ≤z.
Exercise 10.5. (Chen and Simchi-Levi 2009) Given a (K, Q)-convex function f,
prove that the function
g(x) = min
y≤x Qδ(y −x) + f(y)
is also (K, Q)-convex, where δ(x) = 1 for x > 0 and δ(x) = 0 otherwise. Similarly,
h(x) = min
y≥x Kδ(y −x) + f(y)
is also (K, Q)-convex.
Exercise 10.6. (Chen and Simchi-Levi 2009) Assume that f : ℜ→ℜis (K, Q)-
convex. Prove that there exists a convex function f(x) such that
f(x) ≤f(x) ≤f(x) + max{K, Q}, for any x.

10.8 Exercises
209
Exercise 10.7. (Chen, Zhang and Zhou 2010) A function f is quasi-K-concave
with changeover a if it is increasing on (−∞, a] and non-K-increasing on [a, ∞).
Prove the following statement: If r(·) is a diﬀerentiable concave function and w(·) is
a continuously diﬀerentiable quasi-K-concave function with some ﬁnite changeover
ξ0, then the function f(·) deﬁned by f(x) = maxd∈[d, ¯d] r(d) + w(x −d) is quasi-K-
concave with a ﬁnite changeover no less than ξ0. Is the diﬀerentiability assumption
dispensable?

Part III
Competition, Coordination
and Design Models

11
Supply Chain Competition
and Collaboration Models
In this chapter, we analyze decentralized supply chain systems with independent
retailers, each of which—facing uncertain demand—needs to decide its stock level
and selling price in a single period. In Sect. 11.1, the retailers compete on prices for
which noncooperative game theory is appropriate. In Sect. 11.2, the retailers do not
compete and have incentives to form coalitions that place joint orders and share
inventory due to risk-pooling eﬀects and economies of scale. The model and analy-
sis in Sects. 11.1 and 11.2 are based on Bernstein and Federgruen (2004) and Chen
(2009), respectively. Our intention is to provide a snapshot of the applications of
game theory to supply chain management. For surveys on this topic, see Cachon
and Netessine (2004) and Nagarajan and Soˇsi´c (2008).
11.1
Inventory and Pricing Competition
Consider a system with n independent retailers. Let N = {1, 2, . . ., n} denote the
set of retailers. Each retailer faces a single-period problem similar to the one in
Sect. 10.3. Speciﬁcally, retailer i (i ∈N), facing demand uncertainty, has to decide
on its stock level yi and a selling price pi ∈[pi, ¯pi] of a single product before the
realization of the demand uncertainty. Demand is ﬁlled as much as possible from
the on-hand inventory, and unsatisﬁed demand is ﬁlled with an emergency order.
For retailer i, let ci be the unit ordering cost, h−
i the unit emergency ordering cost,
and h+
i the unit inventory holding/disposal cost if h+
i is nonnegative or the unit
salvage value if it is negative. Assume that
D. Simchi-Levi et al., The Logic of Logistics: Theory, Algorithms, and Applications
for Logistics Management, Springer Series in Operations Research and Financial Engineering,
DOI 10.1007/978-1-4614-9149-1 11, © Springer Science+Business Media New York 2014
213

214
11. Supply Chain Competition and Collaboration Models
h−
i ≥ci ≥max{0, −h+
i }.
As we pointed out in Sect. 10.3, this implies that the salvage value is no more than
the normal unit ordering cost, which in turn is no more than the unit cost for the
emergency order. To avoid trivial cases, we also assume that pi ≥h−
i .
The demand of retailer i (i ∈N), Di(p, αi), is a deterministic function of the
prices of all retailers, p = (p1, . . . , pn), times a nonnegative random noise αi with
a continuous cdf Fi(·). That is,
Di(p, αi) = di(p)αi.
Without loss of generality, assume E[αi] = 1. The expected demand di(p) =
E[Di(p, αi)] (i ∈N) is assumed to be diﬀerentiable in p. We also assume
∂di(p)
∂pi
≤0, ∂di(p)
∂pj
≥0 ∀j ̸= i.
The ﬁrst inequality indicates that a higher selling price of a retailer leads to a
lower demand of itself, which is reasonable under most circumstances. The second
inequality implies that a higher selling price of a retailer leads to higher demands
of other retailers, which implies that the products oﬀered by the retailers are
substitutable. One additional assumption is imposed on di(p).
Assumption 11.1.1 For i ∈N, di(p) is log-supermodular; that is, log di(p) is
supermodular.
Several plausible demand functions satisfy these assumptions:
• the linear demand
di(p) = bi −

j∈N
aijpj (bi > 0, aii > 0, and aij ≤0 ∀i, j ∈N, i ̸= j);
• the exponential demand
di(p) = ebi−
j∈N aijpj (aii > 0 and aij ≤0 ∀i, j ∈N, i ̸= j);
• the Cobb–Douglas demand
di(p) = biΠj∈Np−aij
j
(bi > 0, aii > 1, and aij ≤0 ∀i, j ∈N, i ̸= j);
• the constant elasticity of substitution demand
di(p) = Ω
p−r−1
i

j∈N p−r
j
(Ω > 0, r > 0);

11.1 Inventory and Pricing Competition
215
• the Logit demand
d(p) = Ω
e−aipi
1 + 
j∈N e−ajpj (Ω > 0, ai > 0 ∀i ∈N).
Given the vector of stock levels y = (y1, . . . , yn) and the price vector p, retailer
i’s strategy set is ˆSi = [0, ∞) × [pi, ¯pi] and its expected proﬁt is given by
vi(y, p) = pidi(p)−ciyi−h+
i E[max(yi −di(p)αi, 0) −h−
i E[max(di(p)αi −yi, 0)]
= pidi(p) −ℓi

yi
di(p)

di(p),
where
ℓi(y) = h−
i −(h−
i −ci)y + (h−
i + h+
i )E[max(y −αi, 0)].
Since a retailer’s expected proﬁt depends on other retailers’ decisions, the system
can be modeled as a noncooperative game (N, { ˆSi}i∈N, {vi}i∈N). Assume that all
the costs, demand functions, and the structure of the game are common knowledge.
The concept of Nash equilibrium is a natural predication of the outcome of the
system.
Since a retailer’s stocking decision has no impact on other retailers, its best
stock level in response to the price vector p can be easily derived as the optimal
ordering quantity of a newsvendor problem. Speciﬁcally, retailer i’s optimal stock
level is given by
yi(p) = di(p)F −1
i
(ρi),
where F −1
i
(ρi) is a solution of ℓ′
i(y) = 0 and ρi =
h−
i −ci
h−
i +h+
i . With this stock level,
retailer i’s reduced expected proﬁt is now a function of the price vector only:
πi(p) = di(p)(pi −ℓi
!
F −1
i
(ρi)
"
).
We end up with a reduced game (N, {Si}i∈N, {πi}i∈N), where Si = [pi, ¯pi]. Since
πi(p) can be easily shown to be log-supermodular by Assumption 11.1.1, the game
(N, {Si}i∈N, {πi}i∈N) belongs to the class of log-supermodular games and thus
shares the properties of supermodular games in Theorem 3.1.4.
Theorem 11.1.2 Under Assumption 11.1.1, the set of Nash equilibria of the red-
uced game (N, {Si}i∈N, {πi}i∈N) is nonempty and has a largest and a smallest
element. In addition, the largest and smallest Nash equilibria are increasing in
ci, h+
i , and h−
i (i ∈N).
Proof. It remains to prove the second part. From Theorem 3.1.4, it suﬃces to
show that πi(p) has increasing diﬀerences in (pi, wi) for any ﬁxed p−i, where
wi is ci, h+
i , or h−
i . Given the formulation of π(p), we only need to prove that
∂ℓi(F −1
i
(ρi))
∂ci
,
∂ℓi(F −1
i
(ρi))
∂h+
i
, and
∂ℓi(F −1
i
(ρi))
∂h−
i
are nonnegative.

216
11. Supply Chain Competition and Collaboration Models
Since F −1
i
(ρi) is a solution of ℓ′
i(y) = 0, we have that
∂ℓi
!
F −1
i
(ρi)
"
∂h−
i
= (1 −F −1
i
(ρi)) + E[max(F −1
i
(ρi) −αi, 0)]
+ℓ′
i(y)|y=F −1
i
(ρi))
∂F −1
i
(ρi)
∂h−
i
= (1 −F −1
i
(ρi)) + E[max(F −1
i
(ρi) −αi, 0)]
≥0.
Similarly,
∂ℓi
!
F −1
i
(ρi)
"
∂ci
= F −1
i
(ρi) ≥0
and
∂ℓi
!
F −1
i
(ρi)
"
∂h+
i
= E[max(F −1
i
(ρi) −αi, 0)] ≥0.
Thus, the largest and smallest Nash equilibria are increasing in ci, h+
i , and h−
i .
Since the expected proﬁt of a retailer is nondecreasing in the other retailers’
prices, the largest Nash equilibrium is preferable by all retailers. Indeed, let p∗
be a Nash equilibrium and ¯p∗be the largest Nash equilibrium. We have that for
i ∈N,
πi(¯p∗) ≥πi(p∗
i , ¯p∗
−i) ≥πi(p∗),
where the ﬁrst inequality follows from the deﬁnition of Nash equilibrium and the
second one holds since πi(p) is nondecreasing in pj (j ̸= i).
For any equilibrium, p∗, of the reduced game, it is clear that (y(p∗), p∗) is an equi-
librium
of
the
game
(N, { ˆSi}i∈N, {vi}i∈N),
where
y(p)
=
(y1(p), . . . ,
yn(p)). It would be interesting to see how y(p∗) changes with ci, h+
i , h−
i
when
p∗is either the largest or the smallest equilibrium.
Finally, from (3.1) in Chap. 3, a suﬃcient condition for the uniqueness of a Nash
equilibrium is the diagonally dominant condition:
−∂2 log πi(p)
∂2pi
>

j̸=i
∂2 log πi(p)
∂pi∂pj
, i ∈N.
In the exercise, you are asked to provide conditions on the demand functions listed
earlier under which the diagonally dominant condition holds.
11.2
Inventory Centralization Games
In recent years, many companies have started exploring innovative collaboration
strategies in an eﬀort to improve their supply chain eﬃciency and ultimately the
bottom line. Firms are employing strategies such as forming long-term alliances

11.2 Inventory Centralization Games
217
and building collaborative logistics to reduce their supply chain costs. There are
numerous examples of collaboration in supply chains. For instance, Good Neigh-
bor Pharmacy is a retailers’ cooperative network of 2, 700 independently owned
and operated pharmacies, and Aﬃliated Foods Midwest supplies more than 850
independent food-retailer members in 12 midwestern U.S. states with a full line of
grocery products.
Indeed, to compete with big box retailers, it is common for independent gro-
cery stores, hardware stores, and pharmacies to form retailers’ cooperative groups,
business entities that employ economies of scale on behalf of retailer-members to
get discounts from manufacturers and to pool marketing. To join a retailers’ coop-
erative, a store would typically pay a membership fee and purchase certain stock
in the cooperative in return for its voting share. In addition, a store is usually
required to purchase a minimum amount of inventory from the cooperative. The
operating proﬁts of the cooperative are returned to the member stores in cash
or stock rebate (see Stankevich 1996). Over the years, retail cooperative groups
have developed a variety of popular groupwide programs, such as insurance, pen-
sion plans, inventory management, pricing assistance, logistics, warehousing, store
design and layout, site selection, and employee training (see Ghosh 1994).
These innovative strategies raise a variety of important and challenging ques-
tions on managing supply chains. For instance, for a group of companies in a supply
chain, how should they cooperate, what possible outcomes can be achieved, and
how do the players share the costs and beneﬁts? Indeed, getting all players to agree
on how to share costs and beneﬁts was identiﬁed as one of the major barriers to
collaborative commerce according to a European Chemical Transport Association
white paper.
In this section, we consider a distribution system with multiple retailers that
may place joint orders and keep inventory at a central warehouse. The retailers
are interested in this type of cooperation for two reasons. First, retailers can take
advantage of the risk-pooling eﬀect by delaying the allocation of inventory. Second,
exploiting economies of scale allows retailers to reduce their costs or increase their
proﬁts.
The cost-allocation problem among the retailers can be modeled as a cooper-
ative game, referred to as an inventory centralization game. We will show that
under certain conditions, an inventory centralization game has a nonempty core,
which implies that no group of retailers will be better oﬀby deviating from the
cooperation.
11.2.1
Model
Assume that in the distribution system, there are m warehouses and n retailers.
The retailers order from the outside suppliers through the warehouses and sell a
single type of goods in a single period. Let W = {1, 2, · · ·, m} and N = {1, 2, · · ·, n}
be the sets of suppliers and retailers, respectively. The retailers are assumed to be
noncompeting and allowed to make their selling price decisions. Each retailer’s
demand depends on its own selling price and a common random variable—the

218
11. Supply Chain Competition and Collaboration Models
market signal, ω. To satisfy their demand, the retailers, taking advantage of
risk-pooling eﬀects, may form coalitions to place joint orders through the ware-
houses before observing the market signal, while the inventories are allocated to
the retailers after the market signal is revealed. Let Zj ⊆W be the set of ware-
houses that can be used to supply retailer j if she does not cooperate with other
retailers. If retailer j together with some other retailers decides to form a group
S, referred to as a coalition, by placing joint orders and sharing inventory, her
demand can be served by the inventory at any warehouse in ∪j∈SZj.
The sequence of events is as follows. Before observing the realization of the
market signal, each warehouse places an order by paying an ordering cost of ci(yi)
for an order quantity yi at warehouse i. After the market signal ω is revealed, the
retailers decide their selling prices pj(ω), which depend on the market signal ω,
and all goods at the warehouses are allocated to the retailers; say, xij(ω) units
of goods are shipped from warehouse i to retailer j. The transportation cost of
sending one unit of goods from warehouse i to retailer j is sij. For each retailer
j, if the total amount of goods received from the warehouses is more than the
realized demand, a per-unit holding cost of h+
j for excess inventory is incurred. On
the other hand, we make the following assumption regarding unsatisﬁed demand.
Assumption 11.2.1 Unsatisﬁed demand at retailer j is ﬁlled by an emergency
order, which incurs a per-unit emergency ordering cost of h−
j .
The demand of each retailer is random and depends on the realization of the
market signal ω and its own selling price. Speciﬁcally, we focus on demand func-
tions of the following forms:
Assumption 11.2.2 For j ∈N, the demand function of retailer j given its price
pj satisﬁes
˜dj = Dj(pj, ω) := βj(ω) −αj(ω)pj,
(11.1)
where αj and βj are two nonnegative random variables, represented as functions
of the market signal ω.
To avoid technical complications, we assume that the sample space Ω of ω is
ﬁnite. However, this assumption can be relaxed if necessary.
We further assume that pj and ¯pj are the lower and upper bounds of pj(ω),
respectively. Thus, the feasible set of retailer j’s price decision pj(·) is given by
Pj = {pj(·) : pj ≤pj(ω) ≤¯pj, ∀ω ∈Ω}.
The inventory centralization problem for a coalition of retailers S ⊆N can be
formulated as a two-stage stochastic programming model with recourse. In this
model, yi, i = 1, 2, · · ·, m, is the ﬁrst-stage decision variable. After the market
signal ω is revealed, a recourse decision should be made, which is the amount of
goods sent from i to j, namely, xij(ω), for all i ∈∪j∈SZj and j ∈S, and the
selling price pj(ω). Let vj(ω) be the total amount of goods received by retailer j.
For the coalition S, the objective is to maximize the expected total proﬁt of all
retailers in S.

11.2 Inventory Centralization Games
219
Denote the maximum expected proﬁt of the coalition S by v(S), which can be
written as the optimal value of the following two-stage stochastic programming
problem with recourse:
V (S) =
Max

j∈S
{E[Rj(pj(ω), ω) −fj(vj(ω) −βj(ω) + αj(ω)pj(ω))]}
−

i∈∪j∈SZj
(ci(yi) +

j∈S
sijE[xij(ω)])
s.t.
yi −

j∈S
xij(ω) = 0,
i ∈∪j∈SZj, ω ∈Ω,
vj(ω) −

i∈∪j∈SZj
xij(ω) = 0,
j ∈S, ω ∈Ω,
xij(ω) ≥0,
j ∈S, i ∈∪j∈SZj, ω ∈Ω,
pj(·) ∈Pj,
j ∈S,
(11.2)
where the maximization is taken over (yi, xij(·), pj(·), vj(·)), Rj is the realized
revenue function for a given selling price r and a realization of the marker signal ω:
Rj(r, ω) = r(βj(ω) −αj(ω)r),
and fj represents the inventory holding cost or emergency ordering cost
fj(χ) = h+
j χ+ + h−
j (−χ)+.
In the above model, the term in the ﬁrst summation in the objective function
is the expected revenue minus the expected inventory holding cost and emergency
ordering cost. The term in the second summation in the objective function is
the regular ordering cost and the transportation cost. The ﬁrst constraint implies
that no warehouse holds inventory. The second constraint speciﬁes that the total
amount of goods received by a retailer equals the total amount sent to the retailer
from the warehouses.
Now the pair (N, V ) with V given by (11.2) for each coalition S ⊆N deﬁnes a
cooperative inventory centralization game.
11.2.2
Inventory Games with a Linear Ordering Cost
In this subsection, we assume that the ordering cost ci(yi) is linear; by slightly
abusing the notation, we also use ci to denote the unit ordering cost. Since the rea-
lized revenue Rj(pj(ω), ω) is concave in pj(ω) by Assumption 11.2.2 and fj(χ) is
convex, problem (11.2) is a concave maximization problem with linear constraints,
which allows us to apply the elegant duality theory for convex minimization prob-
lems with linear constraints. For this purpose, deﬁne the Lagrangian function

220
11. Supply Chain Competition and Collaboration Models
LS(y, p, v, x, λ, μ, π) =

j∈S
!
E[Rj(pj(ω), ω) −fj(vj(ω) −βj(ω) + αj(ω)pj(ω))]"
−

i∈∪j∈SZj
(ciyi +

j∈S
sijE[xij(ω)])
+

i∈∪j∈SZj
E[λi(ω)(yi −

j∈S
xij(ω))]
+

j∈S
E[μj(ω)(

i∈∪j∈S
xij(ω) −vj(ω)))]
+

j∈S,i∈∪j∈SZj
E[πij(ω)xij(ω)]
=

j∈S
ψj(pj, vj, μj) +

i∈∪j∈SZj
yi(E[λi(ω)] −ci)
+

j∈S,i∈∪j∈SZj
E[xij(ω)(πij(ω) −sij −λi(ω) + μj(ω))],
where y = (yi)i∈∪j∈SZj, d = (dj)j∈S, v = (vj)j∈S, λ = (λi)i∈∪j∈SZj, μ = (μj)j∈S,
π = (πij)j∈S,i∈∪j∈SZj, and
ψj(pj, vj, μj) = E[Rj(pj(ω), ω) −fj(vj(ω) −βj(ω) + αj(ω)pj(ω)) −μj(ω)vj(ω)].
(11.3)
Consider the dual function γS(λ, μ, π) deﬁned by
γS(λ, μ, π) =
Sup
LS(y, p, v, x, λ, μ, π)
s.t.
pj(·) ∈Pj,
j ∈S.
The duality theorem for convex minimization problems with linear constraints
implies that V (S) is equal to the optimal objective value of the dual problem (see,
for instance, page 299 of Bertsekas 1995):
V (S)
=
Min
γS(λ, μ, π)
s.t.
πij(ω) ≥0,
j ∈S, i ∈∪j∈SZj, ω ∈Ω.
(11.4)
Let (λ∗, μ∗, π∗) be optimal for the dual problem (11.4) with S = N. Then, again,
the duality theorem implies that
V (N)
=
Max
LN(y, p, v, x, λ∗, μ∗, π∗)
s.t.
pj(·) ∈Pj,
j ∈N.
(11.5)
Deﬁne for j ∈N,
lj =
Max
ψj(pj, vj, μ∗
j)
s.t.
pj(·) ∈Pj.
We claim that (l1, l2, . . . , ln) is in the core of the cooperative game (N, V ).

11.2 Inventory Centralization Games
221
Theorem 11.2.3 The vector l = (l1, l2, . . . , ln) is in the core of the cooperative
game (N, V ).
Proof. Notice that in the optimization problem (11.5), no constraint is imposed
on the decision variables yi and xij(ω). Thus, we must have
E[λ∗
i (ω)] −ci = 0,
i ∈∪j∈NZj, ω ∈Ω,
(11.6)
and
π∗
ij(ω) −sij −λ∗
i (ω) + μ∗
j(ω) = 0,
j ∈N, i ∈∪j∈NZj, ω ∈Ω.
(11.7)
Therefore,
LS(y, p, v, x, λ∗, μ∗, π∗) =

j∈S
ψj(pj, vj, μ∗).
This, together with (11.5), implies that

j∈N
lj = V (N).
In addition, since (λ∗, μ∗, π∗) is feasible for problem (11.4),

j∈S
lj = γS(λ∗, μ∗, π∗) ≥V (S).
Thus, l = (l1, l2, . . . , ln) is in the core of the cooperative game (N, V ).
From the above proof, we know that the optimal dual variables (λ∗, μ∗, π∗) must
satisfy constraints (11.6) and (11.7). We now provide some intuition of the dual
variables and the constraints. In the dual, we attempt to allocate the ordering
cost and the transportation cost to each unit of goods received by the retailers.
Speciﬁcally, let the dual variable μ∗
j(ω) be the charge for each unit of goods received
by retailer j to compensate for its ordering cost and transportation cost and λ∗
i (ω)
be a charge for each unit of goods sent out by warehouse i to compensate its
ordering cost if the market signal turns out to be ω. The constraint (11.6) implies
that the average unit charge by warehouse i should be enough to cover its ordering
cost ci. Since π∗
ij(ω) ≥0, the dual constraint (11.7) implies that this unit charge
μ∗
j(ω) at retailer j should be no more than the unit price, λ∗
i (ω), charged by
warehouse i plus the transportation cost sij. On the other hand, if there is a
shipment from warehouse i to retailer j, then π∗
ij(ω) = 0 by the complementarity
slackness condition, and the dual constraint (11.7) implies that this unit charge
μ∗
j(ω) is enough to compensate for the unit price, λ∗
i (ω), charged by warehouse i
plus the transportation cost sij.

222
11. Supply Chain Competition and Collaboration Models
11.2.3
Inventory Games with Quantity Discounts
In this subsection, we assume that the supplier provides quantity discounts to
encourage large orders, or a third-party carrier provides volume discounts to enc-
ourage larger shipments. Speciﬁcally, we make the following assumption.
Assumption 11.2.4 We assume that ci(y)/y is nonincreasing. That is, the larger
the ordering quantity, the lower the average unit ordering cost.
For technical reasons, we assume that ci(y) is lower semicontinuous. That is,
limy→x ci(y) ≥ci(x) for any x. Further, we assume ci(y) →∞as y →∞. Under
these assumptions, problem (11.2) has an optimal solution for any S ⊆N.
Our assumption on the ordering cost is quite general. Indeed, we don’t require
ci(x) to be continuous, monotone, convex, or concave. Moreover, it includes several
commonly used discounts: incremental discounts and all-units discounts. The con-
cave ordering cost analyzed in Chen and Zhang (2009) and the less-than-truckload
(LTL) volume discount function (see Muriel and Simchi-Levi 2003) are also imp-
ortant special cases.
Given this general ordering cost structure, unfortunately, the corresponding coo-
perative game may have an empty core. Indeed, in a special case of the inventory
centralization games in which price is not a decision variable, Chen and Zhang
(2009) show that for a distribution system with multiple warehouses, the core
of the corresponding cooperative game may be empty even if the ordering costs
involve only ﬁxed costs and demand is deterministic.
Thus, in this subsection, we focus on inventory centralization games with a single
warehouse (N, V ). Since we analyze inventory games with a single warehouse, in
the following analysis, we drop the index associated with the warehouses. In this
case, the value of a coalition S can be deﬁned as
V (S) =
Max
−c(y) + g(y, S)
s.t.
y ≥0,
(11.8)
where
g(y, S) = E[gS(y, ω)],
(11.9)
with
gS(y, ω) =
Max

j∈S
gj(pj, xj, ω)
s.t.
y −

j∈S
xj = 0,
xj ≥0,
j ∈S,
pj ≤pj ≤¯pj,
j ∈S,
and
gj(pj, xj, ω) = Rj(pj, ω) −fj(xj −βj(ω) + αj(ω)pj) −sjxj.
It is clear that given the general quantity discount function c(y), the objective
function of the above optimization problem is neither convex nor concave. Thus,

11.2 Inventory Centralization Games
223
analyzing it directly appears to be quite challenging. To get around this challenge,
we construct another inventory centralization game (N, ˜V ) with a linear ordering
cost, which is known to have a nonempty core, such that ˜V (S) ≥V (S) for any
S ⊂N and ˜V (N) = V (N). If this could be done, then we could prove that any
element in the core of the game (N, ˜V ) is in the core of the game (N, V ). We show
that this is true by ﬁrst proving that for Problem (11.8), the bigger a coalition is,
the larger the optimal ordering quantity should be. For this purpose, we deﬁne for
any given scalar ˆc ≥0 an inventory centralization game (N, Vˆc) with the ordering
cost being ˆcx. In this game, for any S ⊆N,
Vˆc(S) =
Max
−ˆcy + g(y, S)
s.t.
y ≥0.
For any nonempty set S ⊆N, let y∗(S) be the smallest optimal solution of
problem (11.8) that is guaranteed to exist when c(y) is lower-semicontinuous and
limy→+∞c(y) = +∞.
Lemma 11.2.5 For any given S ⊆N, let y∗(S) be the smallest optimal ordering
quantity for the postponed pricing model (11.8)–(11.9). We have y∗(S1) ≤y∗(S2)
for S1 ⊆S2.
Proof. We prove this result by contradiction. Assume that there exist S1, S2 ⊆N
with S1 ⊂S2 such that y∗(S1) > y∗(S2). Let (x1
j(ω), p1
j(ω))j∈S1 be the optimal
inventory allocation and pricing associated with the optimal ordering quantity
y∗(S1) for problem (11.8)–(11.9) with S = S1. Similarly, let (x2
j(ω), p2
j(ω))j∈S2 be
the optimal inventory allocation and pricing associated with the optimal ordering
quantity y∗(S2) for problem (11.8)–(11.9) with S = S2.
The deﬁnition of y∗(S1) and y∗(S2) implies that
−c(y∗(S1)) + gS1(p1, x1) > −c(y∗(S2)) + gS1(p3, x3)
(11.10)
for any p3
j(·) ∈Pj and x3
j(·) with
y∗(S2) =

j∈S1
x3
j(ω), ∀ω ∈Ω,
(11.11)
where for any S ⊆N, (xj(ω), pj(ω))j∈S,
ˆgS(p, x) =

j∈S
E[gj(pj(ω), xj(ω), ω)].
Similarly,
−c(y∗(S2)) + gS2(p2, x2) ≥−c(y∗(S1)) + gS2(p4, x4)
(11.12)
for any p4
j(·) ∈P (p)
j
and x4
j(·) with
y∗(S1) =

j∈S2
x4
j(ω), ∀ω ∈Ω.

224
11. Supply Chain Competition and Collaboration Models
Speciﬁcally, let
p4
j(ω) = p2
j(ω), x4
j(ω) = x2
j(ω), ∀j ∈S2 \ S1, ω ∈Ω.
This, together with inequality (11.12), implies that
−c(y∗(S2)) + gS1(p2, x2) > −c(y∗(S1)) + gS1(p4, x4)
(11.13)
for any p4
j(·) ∈Pj and x4
j(·) (j ∈S1) with
y∗(S1) −y∗(S2) =

j∈S1
(x4
j(ω) −x2
j(ω)), ∀ω ∈Ω.
(11.14)
Adding the two inequalities (11.10) and (11.13) together gives us that
gS1(p1, x1) + gS1(p2, x2) > gS1(p3, x3) + gS1(p4, x4)
(11.15)
for any p3
j(·), p4
j(·) ∈Pj (j ∈S1) (x3
j(·))j∈S1 satisfying (11.11) and (x4
j(·))j∈S1
satisfying (11.14).
Deﬁne
λ(ω) =
y∗(S1) −y∗(S2)
y∗(S1) −
j∈S1 x2
j(ω).
Since

j∈S1
x2
j(ω) ≤

j∈S2
x2
j(ω) = y∗(S2) < y∗(S1),
we have that λ(ω) ∈[0, 1]. For j ∈S1, let
x3
j(ω) = (1 −λ(ω))x1
j(ω) + λ(ω)x2
j(ω),
p3
j(ω) = (1 −λ(ω))p1
j(ω) + λ(ω)p2
j(ω),
and
x4
j(ω) = λ(ω)x1
j(ω) + (1 −λ(ω))x2
j(ω),
p4
j(ω) = λ(ω)p1
j(ω) + (1 −λ(ω))p2
j(ω).
It is clear that (x3
j(·))j∈S1 satisﬁes (11.11) and (x4
j(·))j∈S1 satisﬁes (11.14). In
addition,
x3
j(ω) + x4
j(ω) = x1
j(ω) + x2
j(ω)
and
p3
j(ω) + p4
j(ω) = p1
j(ω) + p2
j(ω).
Thus, the concavity of the realized revenue function Rj implies that
Rj(p3
j(ω), ω) + Rj(p4
j(ω), ω) ≥Rj(p1
j(ω), ω) + Rj(p2
j(ω), ω),

11.2 Inventory Centralization Games
225
and the convexity of fj implies that
−fj(x3
j(ω) −βj(ω) + αj(ω)p3
j(ω)) −fj(x4
j(ω) −βj(ω) + αj(ω)p4
j(ω))
≥−fj(x1
j(ω) −βj(ω) + αj(ω)p1
j(ω)) −fj(x2
j(ω) −βj(ω) + αj(ω)p2
j(ω)).
Adding the two inequalities together and taking expectation with respect to ω give
us an inequality that contradicts the inequality (11.15). Thus, y∗(S1) ≤y∗(S2).
It is also important to point out that Lemma 11.2.5 is independent of how the
retailers’ demands are correlated. In addition, this result is true for any ordering
cost as long as the relevant quantities are well deﬁned.
Lemma 11.2.6 There exists a scalar ˆc∗such that for any S ⊆N, Vˆc∗(S) ≥V (S)
and Vˆc∗(N) = V (N).
Proof. We consider two cases. First, assume that y∗(N) = 0. Lemma 11.2.5 implies
that y∗(S) = 0 for any nonempty set S ⊆N. If we choose a suﬃciently large ˆc∗,
say ˆc∗≥Max
j∈N max{¯pj, qj}, it is easy to see that 0 is also an optimal solution
for problem maxy≥0 −ˆc∗y + g(y, S). Thus, in this case, Vˆc∗(S) = V (S) for any
S ⊆N.
We now assume that y∗(N) > 0. For simplicity of notation, let y∗= y∗(N).
Upon denoting c∗= c(y∗)/y∗, we have that
V (N)
=
−c(y∗) + g(y∗, N)
=
−c∗y∗+ g(y∗, N)
≤
maxy≥0 −c∗y + g(y, N)
=
Vc∗(N).
Since y∗> 0, we have that
V (N)
=
maxy≥0 −c(y) + g(y, N)
>
g(0, N)
=
limˆc→∞Vˆc(N).
The continuity of Vˆc(N) as a function of ˆc, together with the above two inequalities,
implies that there exists a ˆc∗such that V (N) = Vˆc∗(N).
Deﬁne ˆx = sup{x ≥0 : c(x)/x ≥ˆc∗}. Let ˆy∗be the smallest optimal solution
for the problem miny≥0 −ˆc∗y + g(y, N). We claim that ˆy∗≤ˆx.
Assume to the contrary that ˆy∗> ˆx. The deﬁnition of ˆx together with the
monotonicity of c(x)/x implies that c(ˆy∗)/ˆy∗< ˆc∗. Thus,
Vˆc∗(N)
=
−ˆc∗ˆy∗+ g(ˆy∗, N)
<
−c(ˆy∗) + g(ˆy∗, N)
≤
−c(y∗) + g(y∗, N)
=
V (N),
which contradicts the fact that V (N) = Vˆc∗(N). Thus, ˆy∗≤ˆx.

226
11. Supply Chain Competition and Collaboration Models
Deﬁne a new function ˜c(x) as follows:
˜c(x) =
 ˆc∗x, for 0 ≤x < ˆx,
c(x), otherwise .
The following properties of ˜c(x) will be useful for our analysis. First, ˜c(x) ≤c(x)
for any x. This follows directly from the monotonicity of c(x)/x. Second, ˜c(x)
preserves the lower semicontinuity of c(x). To show this, it suﬃces to prove that
˜c(x) is lower-semicontinuous at x = ˆx. Notice that
lim
y→ˆx+
˜c(y) = lim
y→ˆx+
c(y) ≥c(ˆx) = ˜c(ˆx),
while
lim
y→ˆx−
˜c(y) = ˆc∗ˆx ≥lim
y→ˆx+
ˆxc(y)/y ≥c(ˆx) = ˜c(ˆx),
(11.16)
where the ﬁrst inequality and the second inequality follow from the deﬁnition of ˆx
and the lower semicontinuity of c(x), respectively. Notice that (11.16) implies that
˜c(y) ≤ˆc∗y, for any 0 ≤y ≤ˆx.
(11.17)
Third, ˆy∗is also optimal for the problem maxy≥0 −˜c(y) + g(y, N). Indeed, the
deﬁnition of ˆy∗together with the fact ˆy∗≤ˆx implies that for any 0 ≤y < ˆx,
−˜c(ˆy∗) + g(ˆy∗, N) ≥−ˆc∗ˆy∗+ g(ˆy∗, N) ≥−ˆc∗y + g(y, N) = −˜c(y) + g(y, N),
where the ﬁrst inequality follows from (11.17). For y ≥ˆx,
−˜c(ˆy∗) + g(ˆy∗, N)
≥
−ˆc∗ˆy∗+ g(ˆy∗, N)
=
−c(y∗) + g(y∗, N)
≥
−c(y) + g(y, N)
=
−˜c(y) + g(y, N),
where the ﬁrst equality follows from the deﬁnition of ˆy∗and ˆc∗. Thus, ˆy∗is also
optimal for the problem maxy≥0 −˜c(y) + g(y, N).
We are now ready to prove that for any S ⊂N, Vˆc∗(S) ≥V (S). Let ˜y∗(S) be
the smallest optimal solution for the problem maxy≥0 −˜c(y) + g(y, S). Notice that
˜c(x) is lower-semicontinuous. Hence, ˜y∗(S) is well deﬁned. Lemma 11.2.5 implies
that for any S ⊂N, ˜y∗(S) ≤ˆy∗≤ˆx.
We claim that
ˆc∗˜y∗(S) = ˜c(˜y∗(S)).
(11.18)
Indeed, if ˜y∗(S) < ˆx, we have from the deﬁnition of ˜c(·) that ˆc∗˜y∗(S) = ˜c(˜y∗(S)).
On the other hand, if ˜y∗(S) = ˆx and ˆc∗˜y∗(S) > ˜c(˜y∗(S)) = c(˜y∗(S)), we have that
ˆy∗= ˜y∗(S) and
Vc∗(N) = −ˆc∗ˆy∗+ g(ˆy∗, N) < −c(ˆy∗) + g(ˆy∗, N) ≤V (N),
which is a contradiction. Thus, in this case, (11.18) follows from (11.17).

11.2 Inventory Centralization Games
227
Finally, we have that
Vˆc∗(S)
=
maxy≥0 −ˆc∗y + g(y, S)
≥
−ˆc∗˜y∗(S) + g(˜y∗(S), S)
=
−˜c(˜y∗(S)) + g(˜y∗(S), S)
=
maxy≥0 −˜c(y) + g(y, S)
≥
maxy≥0 −c(y) + g(y, S)
=
V (S),
where the second equality follows from (11.18) and the last inequality from the
fact that ˜c(y) ≤c(y) for any y ≥0. The proof is now complete.
We can now prove that the core of (N, V ) is nonempty.
Theorem 11.2.7 Under Assumption 11.2.4, the inventory centralization game
(N, V ) with the characteristic value function deﬁned by (11.8)–(11.9) has a non-
empty core. Let (N, Vˆc∗) be the inventory centralization game with marginal ord-
ering cost ˆc∗, where ˆc∗is deﬁned in Lemma 2. Then any element in the core of
(N, Vˆc∗) is also in the core of (N, V ).
Proof. The proof is straightforward. Let l = (lj)j∈N be an element in the core of
(N, Vˆc∗). We have that for any S ⊆N,

j∈S
lj ≥Vˆc∗(S) ≥V (S).
In addition,

j∈N
lj = Vˆc∗(N) = V (N).
Hence, l = (lj)j∈N is also in the core of (N, V ). Since (N, Vˆc∗) is an inventory
centralization game with a linear ordering cost, Theorem 11.2.3 implies that it has
a nonempty core. Thus, (N, V ) has a nonempty core as well.
Our approach to prove the nonemptiness of the core of a cooperative game
(N, V ) with quantity discount suggests a way to ﬁnd an allocation in the core in
three steps. First, solve
V (N) = max
y≥0 −c(y) + g(y, N).
Second, given V (N), ﬁnd a ˆc∗such that
V (N) = max
y≥0 −ˆc∗y + g(y, N).
Third, ﬁnd an allocation in the core of the inventory centralization game (N, Vˆc∗)
with a linear ordering cost by employing the duality approach in Sect. 11.2.2.
Theorem 11.2.7 implies that this allocation is in the core of (N, V ).

228
11. Supply Chain Competition and Collaboration Models
11.3
Exercises
Exercise
11.1. For
the
linear
demand,
the
exponential
demand,
the
Cobb–Douglas demand, the constant elasticity of substitution demand, and the
Logit demand in Sect. 11.1, provide conditions under which the payoﬀfunctions
satisfy the diagonally dominant conditions.
Exercise 11.2. Show that the inventory centralization games are not convex in
general.
Exercise 11.3. The inventory centralization game analyzed in Sect. (11.2) ass-
umes that pricing decisions are made after the market signal is revealed. Do we
have similar results if pricing decisions are made before the realization of the
market signal?
Exercise 11.4. Consider a special case of the inventory centralization game with
a single warehouse, the newsvendor game, in which pricing decisions are ﬁxed,
the ordering cost is linear, and the retailers have identical transportation costs sj,
inventory holding costs h+
j , and emergency ordering costs h−
j . Simplify the dual
derived in Sect. (11.2.2). Find an optimal solution of the dual in closed form and
an associated (dual-based) core allocation. Does the dual-based core allocation
satisfy any of the monotonicity properties in Sect. 3.2?

12
Procurement Contracts
12.1
Introduction
The inventory models discussed in Chap. 9 focus on characterizing the optimal
replenishment policy for a single facility given some assumptions, such as lead
time and yield, of its supplier. This of course emphasizes the need, in many cases,
to develop direct relationships with suppliers. These relationships can take many
forms, both formal and informal, but often, to ensure adequate supplies and timely
deliveries, buyers and suppliers typically agree on supply contracts. These con-
tracts address issues that arise between a buyer and a supplier, whether the buyer
is a manufacturer purchasing raw materials from a supplier or a retailer purchas-
ing manufactured goods from a manufacturer. In a supply contract, the buyer and
supplier may agree on
• pricing and volume discounts,
• minimum and maximum purchase quantities,
• delivery lead times,
• product or material quality,
• product return policies.
As we will see, supply contracts are very powerful tools that can be used for far
more than ensuring adequate supply and demand for goods.
D. Simchi-Levi et al., The Logic of Logistics: Theory, Algorithms, and Applications
for Logistics Management, Springer Series in Operations Research and Financial Engineering,
DOI 10.1007/978-1-4614-9149-1 12, © Springer Science+Business Media New York 2014
229

230
12. Procurement Contracts
To illustrate the importance and impact of diﬀerent types of supply contracts on
supply chain performance, consider a typical two-stage supply chain consisting of
a retailer and a supplier. In such a supply chain, the retailer places orders trying
to maximize its own proﬁt and the supplier reacts to the orders placed by the
retailer. This process is referred to as a sequential supply chain since decisions are
made sequentially. Thus, in a sequential supply chain, each party determines its
own course of action independent of the impact of its decisions on other parties;
clearly, this cannot be an eﬀective strategy for supply chain partners.
It is natural to look for mechanisms that enable supply chain entities to move
beyond this sequential process and toward global optimization. Of course, this
may be quite diﬃcult since, in a typical supply chain, diﬀerent parties may have
diﬀerent, sometimes even conﬂicting, objectives. Thus, it is important to identify
mechanisms that maximize the eﬃciency of the supply chain while allowing diﬀer-
ent parties to focus on their own objectives. One way to achieve this goal is to use
contracts specifying the transactions between supply chain parties such that every
party’s objective is aligned with the objective of the entire supply chain. We will
refer to such a contract as a contract that coordinates the supply chain.
To illustrate how supply contracts can be used to coordinate the supply chain, we
investigate in this chapter a simpliﬁed supply chain consisting of two risk-neutral
decision makers, a supplier and a retailer. The retailer faces uncertain demands
and needs to procure a certain quantity of a single product from the supplier.
The supplier then produces and delivers the order to the retailer before demand
is realized. The two parties negotiate and form a contract regarding the terms of
the transactions.
A simple example of such a contract is the wholesale contract that we have
seen in the analysis of the newsvendor problem; see Chap. 9, Sect. 9.2, in which
the supplier speciﬁes a wholesale price, while the retailer places an order to the
supplier and the payment is proportional to the quantity purchased by the retailer.
Unfortunately, as we will see in the next section, this simple wholesale contract
does not coordinate the supply chain in general.
Several supply contracts have been proposed to achieve system eﬃciencies.
Among those contracts, the buy-back contracts and the revenue-sharing contracts
are commonly used in some industries due to their eﬀectiveness and simplicity.
In fact, under the setting to be speciﬁed later on in this chapter, the two contracts
coordinate the supply chain; that is, these contracts allow supply chain partners
to achieve global optimization, in other words, maximize supply chain expected
proﬁt.
Furthermore, in these contracts, the retailer’s optimal strategy, namely, the opt-
imal ordering quantity, together with the supplier’s optimal strategy, namely, the
optimal cost parameters speciﬁed in the contracts, consists of a Nash equilibrium.
Thus, neither the retailer nor the supplier could increase its proﬁt by unilaterally
deviating from its optimal strategies.
Interestingly, the buy-back contracts and the revenue-sharing contracts are
shown to be equivalent under our model setting. The literature on supply contracts
that coordinate the supply chain system is quite extensive and is still expanding.
We refer the reader to the review paper by Cachon (2003) for more details.

12.2 Wholesale Price Contracts
231
Of course, eﬀective supply contracts are important not only in the retail industry.
In the electronics industry, there has been a marked increase in purchasing volume
as a percentage of the ﬁrm’s total sales. For instance, between 1998 and 2000, out-
sourcing in the electronic industry increased from 15% of all components to 40%.
This increase in the level of outsourcing implies that the procurement function
becomes critical for an original equipment manufacturer (OEM) to remain in con-
trol of its destiny. As a result, many OEMs focus on closely collaborating with the
suppliers of their strategic components. In some cases, this is done using eﬀective
supply contracts that try to coordinate the supply chain.
A diﬀerent approach has been applied by OEMs for nonstrategic components.
In this case, products can be purchased from a variety of suppliers, and ﬂexibility
to market conditions is perceived as more important than a permanent relationship
with the suppliers. Indeed, commodity products, for instance, electricity, computer
memory, steel, oil, grain, or cotton, are typically available from a large number of
suppliers and can be purchased in spot markets. Because these are highly stan-
dard products, switching from one supplier to another is not considered a major
problem.
Thus, in this chapter, we also introduce and analyze portfolio contracts based on
the recent work of Mart´ınez-de-Alb´eniz and Simchi-Levi (2005). In these contracts,
the buyer signs a portfolio of supply contracts, contracts that provide the buyer
with the appropriate tradeoﬀbetween price and ﬂexibility.
12.2
Wholesale Price Contracts
In a wholesale contract, the supplier speciﬁes a wholesale price and in return,
the retailer decides how much to order from the supplier. Speciﬁcally, when the
retailer places an order, its payment to the supplier is proportional to the quantity
it orders. Thus, in this case, the retailer is facing a newsvendor problem and chooses
the optimal ordering quantity according to the newsvendor model we analyzed in
Chap. 9 Sect. 9.2. Of course, the supplier anticipates the reaction of the retailer
and takes it into account when deciding its wholesale price. This is the so-called
Stackelberg game between the supplier and the retailer, in which the supplier is
the leader and the retailer is the follower.
The setting in this model is as follows. The retailer places an order from the
supplier before the realization of the uncertain demand and sells the product to its
customers at a unit price r. Let F be the cumulative distribution function of the
demand. The function F is assumed to be strictly increasing and diﬀerentiable.
For simplicity, we assume that unsatisﬁed demand is lost and there is no penalty
cost for lost sales. In addition, leftover inventory is salvaged with unit price v.
Finally, we assume that the supplier has no production capacity limit, and its unit
production cost is c with v < c < r.
Before proceeding to analyze the Stackelberg game between the supplier and
the retailer, we ﬁrst discuss the optimal production quantity of the entire system

232
12. Procurement Contracts
assuming that the supplier and the retailer belong to a centralized system. In this
case, the objective is to maximize the system’s expected proﬁt. Given the produc-
tion quantity q, the proﬁt for the total supply chain is
π0(q)
=
−cq + rED[min(q, D)] + vED[max(q −D, 0)]
=
(r −c)q −(r −v)ED[max(q −D, 0)].
This is exactly the classical newsvendor problem analyzed in Chap. 9, Sect. 9.2.
Thus, the optimal production quantity for the total supply chain is
q0 = F −1
 r −c
r −v

,
where F −1 is the inverse function of the cumulative distribution function F.
We now analyze the Stackelberg game between the supplier and the retailer.
Assume for now that the unit wholesale price of the supplier is w. As we already
noticed, the retailer is facing a newsvendor model. Again from the analysis of the
newsvendor model, we can determine the optimal ordering quantity for the retailer
as follows:
q(w) = F −1
r −w
r −v

.
(12.1)
Of course, here we assume r > w > v to avoid trivial cases. Notice that q(w) ≥q0
only if w ≤c. However, this implies that the supplier makes a nonpositive proﬁt.
Thus, the supplier prefers a higher wholesale price, and in this case, the retailer
always tends to order less than q0, the quantity that is optimal for the entire
supply chain. We refer to this behavior as double marginalization. Of course,
this behavior has an intuitive explanation. Since the retailer bears all the risk for
overstocking, it has no incentive to order more and thus tries to reduce its risk
exposure by reducing inventory levels.
As we already pointed out, the supplier anticipates this behavior of the retailer
when setting its wholesale price. From (12.1), there is a one-to-one correspondence
between the optimal ordering quantity of the retailer and the wholesale price set
by the supplier, since F is strictly increasing. Therefore, given the optimal ordering
quantity of the retailer q, the wholesale price is
w(q) = r −(r −v)F(q).
The objective of the supplier is to maximize its own proﬁt, which can be written
as a function of the ordering quantity of the retailer:
πs(q) = (w(q) −c)q = ((r −c) −(r −v)F(q))q.
Of course, if the cumulative distribution function F is too general, there is no
guarantee that the supplier has a unique optimal wholesale price. Hence, we focus
on demands with increasing generalized failure rate (IGFR) distributions, namely,
distributions such that qF ′(q)/(1 −F(q)) is increasing. Notice that several com-
monly used distributions, such as the normal distribution and the exponential
distribution, are IGFR distributions.

12.3 Buy-Back Contracts
233
We now show that for IGFR demand distributions, the optimal wholesale price
of the supplier is unique. First, observe that the ﬁrst-order optimality condition
implies that the retailer’s ordering quantity, associated with the supplier optimal
wholesale price, satisﬁes
π′
s(q) = −(c −v) + (r −v)(1 −F(q) −F ′(q)q) = 0,
or
1 −
qF ′(q)
1 −F(q) = c −v
r −v
1
1 −F(q).
(12.2)
Notice that the left-hand side of the above equation is decreasing in q while the
right-hand side of the equation is increasing in q. Hence, there is a unique solution
q∗for Equation (12.2), and therefore w(q∗) is the unique optimal wholesale price
of the supplier. Furthermore, it is easy to verify that π′
s(q) < 0 for q < q∗and
π′
s(q) > 0 for q > q∗. In other words, πs(q) is decreasing for q < q∗and increasing
for q > q∗. Thus, πs(q) is unimodal.
In summary, for the wholesale contract, there exists a unique Nash equilibrium
for the Stackelberg game between the supplier and the retailer when the demand
distribution is IGFR. In addition, in such a contract, the retailer always orders
less than the quantity that would be optimal for the entire supply chain due to
the fact that it bears all the risks of overstocking. Thus, the wholesale contract
does not coordinate the supply chain.
12.3
Buy-Back Contracts
The previous discussion reveals that wholesale contracts do not coordinate the
supply chain, since the retailer bears all the risks of overstocking and tends to
order less than the amount that would be optimal for the entire system. Thus,
one might expect that the retailer is willing to order more and hence improve the
performance of the supply chain if the supplier would share some of its risks.
Buy-back contracts provide such a mechanism for the supplier to share the risks
with the retailer. In such a contract, the supplier speciﬁes a wholesale price wb and
a buy-back price b. This contract is similar to the wholesale price contract; that is,
the retailer orders from the supplier according to a wholesale price wb. However,
one signiﬁcant diﬀerence is that in addition to a unit salvage value v for unsold
items, the retailer can get a refund from the supplier for a unit price b.
Given a wholesale price wb, a buy-back price b, and an order quantity q, the
retailer’s expected proﬁt is
πb
r(wb, b, q)
=
−wbq + rED[min(q, D)] + (b + v)ED[max(q −D, 0)]
=
(r −wb)q −(r −b −v)ED[max(q −D, 0)].
Consider now a wholesale price wb and a buy-back price b satisfying the following
requirements:
r −wb = λ(r −c) and r −b −v = λ(r −v)

234
12. Procurement Contracts
for some λ ∈[0, 1], or alternatively,
wb = r −λ(r −c) and b = (1 −λ)(r −v).
This implies that the expected proﬁt of the retailer is given by
πb
r(wb, b, q) = λπ0(q).
Hence, the optimal order quantity of the retailer equals q0, the optimal production
quantity of the entire supply chain. Similarly, the expected proﬁt of the supplier
is given by
πb
s(wb, b, q) = (1 −λ)π0(q).
Thus, the supplier’s optimal production quantity is also equal to q0. Therefore,
the system’s expected proﬁt is maximized and the buy-back contract coordinates
the supply chain. Furthermore, in this case, the retailer receives λ of the system’s
expected proﬁt and the supplier seizes (1 −λ) of the system’s expected proﬁt.
12.4
Revenue-Sharing Contracts
A diﬀerent contract that allows for risk sharing between suppliers and retailers is
the so-called revenue-sharing contract. In a revenue-sharing contract, the retailer
and the supplier agree on the wholesale price, typically a discounted wholesale
price, and in return the supplier receives a given fraction of the revenue from each
unit sold by the retailer. Of course, since the supplier receives some of the revenue,
it has an incentive to reduce the wholesale price and hence increase the amount
ordered by the retailer.
Assume that the wholesale price is wr and the supplier receives a fraction (1−φ)
of the retailer’s revenue. Thus, the retailer’s proﬁt is
πr
r(wr, φ, q)
=
−wrq + φ(rED[min(q, D)] + vED[max(q −D, 0)])
=
(φr −wr)q −φ(r −v)ED[max(q −D, 0)].
If we choose φ and wr such that
φr −wr = λ(r −c)
and
φ = λ
for some λ ∈[0, 1], then
πr
r(wr, φ, q) = λπ0(q).
Similarly, the supplier’s expected proﬁt is given by
πr
s(wb, b, q) = (1 −λ)π0(q).

12.5 Portfolio Contracts
235
Thus, both the retailer’s optimal ordering quantity and the the supplier’s optimal
production quantity equal q0, the optimal production quantity for the entire supply
chain. Hence, the system’s expected proﬁt is achieved, and the revenue-sharing
contract coordinates the supply chain.
Furthermore, if the wholesale price is wr(λ) = λc and the retailer shares a
fraction φ(λ) = λ of its expected revenue with the supplier, the retailer receives
a fraction λ of the system’s expected proﬁt and the supplier seizes (1 −λ) of the
system’s expected proﬁt.
Notice that both the buy-back contract with parameters (wb(λ), b(λ)) and the
revenue-sharing contract with parameters (wr(λ), φ(λ)) coordinate the supply
chain and have the same allocation of the system’s expected proﬁt to the sup-
plier and the retailer.
In fact, a revenue-sharing contract with parameters (wr(λ), φ(λ)) is equivalent
to the following contract: The wholesale price is wr(λ) + (1 −λ)r, and the retailer
receives r for each sold unit and gets a refund equal to (1 −λ)r −(1 −φ(λ))v
from the supplier for each salvaged unit. It is easy to verify that this is exactly the
buy-back contract with parameters (wb(λ), b(λ)).
The following example illustrates the impact of supply contracts in practice.
Until 1998, video rental stores used to purchase copies of newly released movies
from the movie studios for about $65 and rent them to customers for $3. Because
of the high purchase price, rental stores did not buy enough copies to cover peak
demand, which typically occurs during the ﬁrst 10 weeks after a movie is released
on video. The result was a low customer service level; in a 1998 survey, about 20%
of customers could not get their ﬁrst choice of movie. Then, in 1998, Blockbuster
Video entered into a revenue-sharing contract with the movie studios in which
the wholesale price was reduced from $65 to $8 per copy, and, in return, studios
were paid about 30–45% of the rental price of every rental. This revenue-sharing
contract had a huge impact on Blockbuster revenue and market share. Today,
revenue sharing is used by most large video rental stores; see Cachon and Lariviere
(2005).
12.5
Portfolio Contracts
A recent trend for many industrial manufacturers has been outsourcing; ﬁrms are
considering outsourcing everything from production and manufacturing to the pro-
curement function itself. Indeed, in the mid-1990s, there was a signiﬁcant increase
in purchasing volume as a percentage of the ﬁrm’s total sales. Between 1998 and
2000, outsourcing in the electronics industry increased from 15% of all components
to 40%.
Of course, the increase in the level of outsourcing implies that the procure-
ment function becomes critical for a manufacturer to remain in control of its
destiny. Thus, an eﬀective procurement strategy has to focus on both driving costs
down and reducing risks. These risks include both inventory and ﬁnancial risks.

236
12. Procurement Contracts
By inventory risks, we refer to inventory shortages, while ﬁnancial risks refer to
the purchasing price, which is uncertain if the procurement strategy depends on
spot markets.
A traditional procurement strategy that eliminates ﬁnancial risk is the use of
ﬁxed commitment contracts. These contracts specify a ﬁxed amount of supply to
be delivered at some point in the future; the supplier and the manufacturer agree
on both the price and the quantity delivered to the manufacturer. Thus, in this
case, the manufacturer bears no ﬁnancial risk while taking huge inventory risks
due to uncertainty in demand and the inability to adjust order quantities.
One way to reduce inventory risk is through option contracts, in which the buyer
prepays a relatively small fraction of the product price up-front, in return for a
commitment from the supplier to reserve capacity up to a certain level. The initial
payment is typically referred to as a reservation price or premium. If the buyer does
not exercise the option, the initial payment is lost. The buyer can purchase any
amount of supply up to the option level, by paying an additional price, agreed to
at the time the contract is signed, for each unit purchased. This additional price
is referred to as the execution price or exercise price. Of course, the total price
(reservation plus execution price) paid by the manufacturer for each purchased
unit is typically higher than the unit price in a ﬁxed commitment contract.
Evidently, option contracts provide the manufacturer with the ﬂexibility to
adjust order quantities depending on realized demand, and hence these contracts
reduce inventory risk. Thus, these contracts shift risks from the manufacturer to
the supplier since the supplier is now exposed to customer demand uncertainty.
This is in contrast to ﬁxed commitment contracts in which the manufacturer takes
all the risk.
Thus, consider a single-period model in which the manufacturer can procure
a single product from multiple sources. For example, consider automotive man-
ufacturing companies purchasing steel or PC manufacturers procuring memory
units.
The manufacturer faces stochastic demand D and sells the ﬁnished product at
a unit selling price r. Unsold items have a unit salvage value v. Most importantly,
we assume that there are a total of n suppliers and before the planning horizon,
the retailer signs an option contract with each supplier. That is, the manufacturer
reserves capacity xi with the ith supplier for a reservation cost vi per unit of
capacity reserved and pays an execution fee of wi for each unit ordered from the
supplier, after demand is realized. Thus, the procurement strategy of the retailer
is a portfolio contract consisting of n option contracts with parameters (vi, wi, xi).
The class of portfolio contracts contains several widely used contracts. This
includes, for instance, long-term contracts, buy-back contracts, and ﬂexibility con-
tracts. A long-term contract speciﬁes a ﬁxed amount of supply, x, to be delivered
at a predetermined time in the future for a given price, ˆv. Thus, it is equivalent to a
portfolio contract consisting of only one option contract with parameters (ˆv, 0, x),
that is, with positive reservation price and zero execution cost. In the long-term
contract, the buyer bears all the risks of overstocking or understocking due to
uncertain demand and its inability to adjust order quantity.

12.5 Portfolio Contracts
237
A ﬂexibility contract speciﬁes a ﬁxed amount of supply, x, for a given price,
ˆv. In addition, in this contract, the amount to be delivered and paid can diﬀer
from the speciﬁed quantity by no more than a given percentage, say α, deter-
mined upon signing the contract. That is, the order quantity is within the interval
[(1 −α)x, (1 + α)x]. The ﬂexibility contract is equivalent to a portfolio contract
consisting of a long-term contract with parameters (ˆv, 0, (1 −α)x) and an option
contract with parameters (0, ˆv, 2αx).
Given that the retailer has to procure q units from the suppliers, it can choose
an appropriate combination of suppliers so that its cost is minimized. Let R(q) be
the optimal cost for procuring q units from the n suppliers. We have
R(q) = n
i=1 vixi+
min
n
i=1 wiqi
s.t.
 n
i=1 qi = q,
0 ≤qi ≤xi, for all i = 1, 2, . . ., n.
(12.3)
It is easy to prove that R(q) is a convex piecewise linear function of q.
Given an initial inventory level I and the order quantity q, the buyer’s expected
proﬁt is
f(I, q) = G(I + q) −R(q),
where
G(q) = rE[min(q, D)] + vE[max(0, q −D)].
In the following, we characterize the optimal replenishment policy for the ret-
ailer. First, we present a result that illustrates how the optimal order quantity
changes monotonically as a function of the initial inventory level when the retailer’s
ordering cost function is convex while its revenue function is concave.
Theorem 12.5.1 Assume that the ordering cost function R is convex and the
revenue function G is concave. Moreover, f(I, q) →∞for q →∞for any I.
Then there exists a function q∗(I) solving
max
q≥0 f(I, q)
(12.4)
such that q∗(I) is nonincreasing and I + q∗(I) is nondecreasing.
Proof. First, observe that q is an optimal solution for the optimization prob-
lem (12.4) if and only if q′ = −q is optimal for the following problem:
max
q′≤0 g(I, q′) := G(I −q′) −R(−q′).
(12.5)
Let q′(I) = min{ q′ ≤0 | q′ solves (12.5)}. Since G is concave, Theorem 2.2.6
implies that g(I, q′) is supermodular. Therefore, from Theorem 2.2.8, we have that
q′(I) is nondecreasing. Thus, q∗(I) = −q′(I) solves (12.4) and is nonincreasing.
To prove the remaining part of the theorem, observe that q is an optimal solution
for the optimization problem (12.4) if and only if I′ = I + q is optimal for the
following problem:
max
I′≥I g(I, I′) := G(I′) −R(I′ −I).
(12.6)

238
12. Procurement Contracts
Since R is convex, Theorem 2.2.6 implies that g(I, I′) is supermodular.
Therefore, from Theorem 2.2.8 and the deﬁnition of q∗(I), we have that I′(I) =
I + q∗(I) is nondecreasing.
The above result implies that the optimal ordering quantity is a nonincreasing
function of the initial inventory level, while the end period inventory level, I +
q∗(I) −E[D], is a nondecreasing function of the initial inventory level.
Finally, we characterize the structure of the optimal ordering policy of the ret-
ailer when a portfolio contract is employed by the retailer. As we already pointed
out, the order cost function R(q) is convex piecewise linear. In fact, without loss
of generality, assume that w1 ≤w2 ≤. . . ≤wn. Deﬁne z0 = 0 and zi = i
j=1 xj
for i = 1, 2, . . . , n. Then
R(q) =
n

j=1
vjxj +
i−1

j=1
wjxj + wi(q −zi−1), for q ∈[zi−1, zi].
Hence, for q ∈(zi−1, zi), dR(q)
dq
= wi, and for q = zi, ∂R(q) = [wi, wi+1].
Theorem 12.5.2 If the ordering cost function R(q) is given by (12.3), then there
exist inventory levels fi (i = 1, 2, . . . , 2n + 1) with
∞= f0 ≥f1 ≥. . . ≥f2n ≥f2n+1 = 0
such that
(a) For I ∈[f2i, f2i−1), it is optimal to set I′ = I + q to a constant level such
that wi ∈∂G(I + q).
(b) For I ∈[f2i+1, f2i), it is optimal to set the ordering quantity q to the constant
level zi.
Proof. For i = 1, 2, . . . , n, let
qi = max{q∗≥0 | q∗maximizes G(q) −wiq subject to q ≥0}.
Theorem 2.2.4 and Theorem 2.2.8 imply that qi ≤qi−1 for i = 2, 3, . . . , n.
Let f0 = ∞, f2n+1 = 0,
f2i−1 = max(qi −zi−1, 0), and f2i = max(qi −zi, 0), i = 1, 2, . . . , n.
Then ∞= f0 ≥f1 ≥. . . ≥f2n ≥f2n+1 = 0. We claim that fi (i = 0, 1, . . . , 2n+1)
satisﬁes parts (a) and (b).
First, notice that for I ∈[f2i, f2i−1) ̸= ∅, we have qi > 0 and q = qi −I ∈
(zi−1, zi]. The ﬁrst-order optimality condition implies that wi ∈∂G(qi). Hence,
q∗(I) = qi −I is optimal for problem (12.4), since we have 0 ∈∂(G(I + q) −
R(q))|q=q∗(I). Thus, part (a) is true.
On the other hand, for I ∈[f2i+1, f2i) with i ≥1, we claim that the opti-
mal ordering quantity q∗(I) = zi. In fact, observe that for I = f2i, we have

12.6 Exercises
239
q∗(I) = qi −I = zi and for I = f2i+1 > 0, we have q∗(I) = qi+1 −I = zi. Thus,
Theorem 12.5.1 implies that for I ∈[f2i+1, f2i), q∗(I) = zi is optimal. Finally, for
I ≥f1, it is clear that q∗(I) = 0 is optimal. Hence, part (b) holds.
Figure 12.1 illustrates the structure of the optimal ordering policy identiﬁed in
Theorem 12.5.2 for a case with n = 2.
z2
q1
q2
order−up−to level
f2
f4
f1
f3
f5=0
order quantity
z1
Inventory level
f2
f4
f1
f3
f5=0
Inventory level
z2
FIGURE 12.1. Illustration of the structure of the optimal ordering policy
12.6
Exercises
Exercise 12.1. Prove that the normal distribution and the exponential distribu-
tion have increasing generalized failure rate (IFGR).
Exercise 12.2. As we have shown in Sect. 12.2, wholesale contracts do not co-
ordinate the supply chain in general. Now assume that the supplier is willing to
provide an all-unit quantity discount. Design an all-unit quantity discount con-
tract coordinating the supply chain; that is, ﬁnd a per-unit wholesale price w(q)
as a decreasing function of the order quantity q such that the optimal ordering
quantity of the retailer and the optimal production quantity of the supplier equal
the optimal production quantity of the whole system.

240
12. Procurement Contracts
Exercise 12.3. Show that a buy-back contract is a special case of portfolio
contracts.
Exercise 12.4. Show that Theorem 12.5.2 implies the optimality of a modiﬁed
base stock policy. In such a policy, there exist inventory target levels bi ≥0 (i =
1, · · · , n) with bi ≤max(0, bi+1 −xi+1) for i = 1, · · · , n −1, such that it is optimal
to order nothing if I ≥bi, order bi −I if I ∈[max(0, bi −xi), bi], or order xi
otherwise.
Exercise 12.5. Consider a single manufacturer and a single supplier. Six months
before demand is realized, the manufacturer has to sign a supply contract with
the supplier. Let D be a random variable representing demand and f(D) be the
demand density function. Let p be the selling price, that is, the price at which the
manufacturer sells products to consumers.
The sequence of events is as follows. Procurement contracts are signed in Febru-
ary and demand is realized during a short period of 10 weeks that starts in August.
Components are delivered from the supplier to the manufacturer at the beginning
of August, and the manufacturer produces items to customer orders. Thus, we can
ignore any inventory holding cost. We will assume that unsold items at the end of
the 10-week selling period have zero value. Finally, assume that the manufacturer
can also purchase additional items in the spot market. Let s be a random variable
representing the per-unit spot market price and f(s) be its density function. The
objective is to identify a procurement strategy so as to maximize expected proﬁt.
Assume the supplier oﬀers an option contract in which the per-unit reservation
price is v and the per-unit execution price is w. Given the existence of the spot
market, how much capacity should the manufacturer reserve with the supplier
when the contract is signed in February?

13
Process Flexibility
13.1
Introduction
For many manufacturing ﬁrms, the ability to match demand and supply is key
to their success. Failure to do so could lead to loss of revenue, reduced service
levels, negative impact on reputation, and decline in the company’s market share.
Unfortunately, recent developments, such as intense market competition, prod-
uct proliferation, and the increase in the number of products with a short life
cycle, have created an environment where customer demand is volatile and unpre-
dictable. In such an environment, traditional operations strategies such as building
inventory, investing in capacity buﬀers, or increasing committed response time to
consumers do not oﬀer manufacturers a competitive advantage. Therefore, many
manufacturers have started to adopt an operations strategy known as process ﬂex-
ibility to better respond to market changes without signiﬁcantly increasing cost,
inventory, or response time (see Simchi-Levi 2010).
Process ﬂexibility is deﬁned as the ability to “build diﬀerent types of products
in the same manufacturing plant or on the same production line at the same
time” (Jordan and Graves 1995). For example, in “full” (process) ﬂexibility, each
plant is capable of producing all products. In this case, when the demand for one
product is higher than expected while the demand for a diﬀerent product is lower
than expected, a ﬂexible manufacturing system can quickly make adjustments by
shifting production capacities appropriately. By contrast, in a “dedicated” strategy
(sometimes called “no ﬂexibility”), each plant is responsible for a single product
and hence does not have the same ability to match supply with demand.
D. Simchi-Levi et al., The Logic of Logistics: Theory, Algorithms, and Applications
for Logistics Management, Springer Series in Operations Research and Financial Engineering,
DOI 10.1007/978-1-4614-9149-1 13, © Springer Science+Business Media New York 2014
241

242
13. Process Flexibility
Because of its eﬀectiveness in responding to uncertainties, process ﬂexibility has
gained signiﬁcant attention in several industries, in particular, in the automotive
industry. Evidently, it is often too expensive to achieve a high degree of ﬂexi-
bility, for example, full ﬂexibility, and as a result, sparse or partial ﬂexibility is
implemented instead. One set of sparse ﬂexibility designs is the 2-ﬂexibility des-
igns. A ﬂexibility design is a 2-ﬂexibility design if each plant produces exactly two
products and demand for each product can be satisﬁed from exactly two plants.
Of course, there are many ways to implement sparse designs, and the challenge is
to identify an eﬀective one. An important concept analyzed in the literature and
applied in practice by various companies is the concept of the long chain. The
ﬁrst to observe the power of the long chain were Jordan and Graves (1995), who,
through empirical analysis, showed that the long-chain design can provide almost
as much beneﬁt as full ﬂexibility. In particular, Jordan and Graves (1995) found
that for randomly generated demand, the expected amount of demand that can
be satisﬁed by a long-chain design is very close to that of a full ﬂexibility design.
Though the analysis and results can be extended to more general settings, for
simplicity, we focus on balanced manufacturing systems, that is, manufacturing
systems with an equal number of plants and products, and each plant has a equal
capacity. Given a balanced manufacturing system, a ﬂexibility design A is repre-
sented by the arc set of a directed bipartite graph, where an arc from plant node
i to product node j implies that plant i is capable of producing product j. For
example, if A is a dedicated design, then A has exactly n arcs such that each
plant node is incident to one arc and each product node is incident to one arc.
By contrast, if A is a full ﬂexibility design, then A has arcs connecting every
plant node to all product nodes.
Because A is represented by a bipartite graph, applying standard graph theory
notation, we deﬁne an undirected cycle in A to be a set of arcs that forms a
cycle when the arc directions are ignored. A ﬂexibility design A is a long chain
if its arcs form exactly one undirected cycle containing all plant and product
nodes (see Fig. 13.1 for an example). A closed chain is deﬁned as an induced
subgraph in A that forms an undirected cycle, while an open chain is an induced
subgraph in A that forms an undirected line (one arc less than an undirected
cycle). Figure 13.1 presents an example of an open and a closed chain. It can be
seen that any 2-ﬂexibility design, where each product/plant node is incident to
two arcs, is the union of a number of closed chains.
The results presented in this chapter are motivated by a few observations made
in the literature regarding the eﬀectiveness of the long-chain ﬂexibility design. The
ﬁrst is an observation that has been made in (Graves 2008 and Hopp et al. 2004)
regarding the performance of the long chain for a balanced system when product
demands are independent and identically distributed (iid). The observation states
that if one starts with a dedicated design and adds arcs to create the long chain,
the incremental beneﬁts, or the change in performance, associated with each added
arc is increasing.
To illustrate this observation, consider an example with six plants and six prod-
ucts, where the demand for each product is equal to 0.8, 1, or 1.2 with equal

13.1 Introduction
243
FIGURE 13.1. Conﬁgurations for ﬂexibility designs
probabilities, and the capacity of each plant is 1. Then we start with a dedicated
ﬂexibility design (the dashed arcs in Fig. 13.2a) and add arcs (1, 2), (2, 3), . . . ,
(5, 6), and (6, 1) one at a time, until we complete the long chain. Each time we
add such an arc, we determine the expected sales associated with the resulting de-
sign at that time. Figure 13.2b displays the performance of the ﬂexibility designs
at diﬀerent stages, as well as the incremental beneﬁts when a new arc is added.
The incremental beneﬁts increase as we add more arcs. The biggest impact, sur-
prisingly, occurs when we add the last arc and close the long chain.
This example also illustrates the second observation. The long chain is an ef-
fective ﬂexibility design; in this case, it achieves the same performance as that
of full ﬂexibility. Indeed, numerous empirical papers reported that the long-chain
ﬂexibility design is more eﬀective than other 2-ﬂexibility designs, and its expected
sales is almost the same as that of full ﬂexibility.
To explain the eﬀectiveness of the long chain, we start in Sect. 13.2 by establish-
ing a supermodularity property and apply it to prove that the incremental beneﬁts
FIGURE 13.2. The increase in incremental beneﬁt

244
13. Process Flexibility
are increasing as the long chain is constructed. Section 13.3 illustrates that the
performance of a long chain can be characterized by the diﬀerence in the perfor-
mances of two open chains. This result allows us to show that the long-chain design
maximizes expected sales among all 2-ﬂexibility design strategies. In Sect. 13.4,
we then apply the previous results to compare the performance of the long chain
to that of full ﬂexibility. Finally, we present some extensions beyond long chains
and balanced systems in Sect. 13.5.
13.2
Supermodularity and Incremental Beneﬁts of Long
Chains
Consider a balanced manufacturing system of size n facing random demand. In such
a system, there are n plants, each of which has unit capacity, and n diﬀerent
products. We will use the vector D to denote the random demand distribution,
and d a particular random instance. Since in practice demand is never negative,
D is assumed to be nonnegative.
For a balanced system of size n, we say that its demand, D, is exchangeable if
[D1, . . . , Dn] equals [Dπ(1), .., Dπ(n)] in distribution for any π that is a permutation
of {1, 2, . . ., n}. We note that any identically and independently distributed (iid)
demand is exchangeable, but not all exchangeable demands are iid.
Next, we deﬁne several classes of ﬂexibility designs for balanced manufacturing
systems. For any integer n ≥2, the dedicated design for a balanced system of size
n, Dn, is deﬁned as Dn = {(i, i)|i = 1, 2, . . ., n}; a long-chain ﬂexibility design
for a balanced system of size n, Cn, is deﬁned as Cn = Dn ∪{(i, i + 1) | i =
1, 2, . . ., n −1} ∪{(n, 1)}; and the full ﬂexibility design for a balanced system of
size n, Fn, is deﬁned as Fn = {(i, j) | i, j = 1, 2, . . . , n}. In ﬂexibility designs, we
refer to an arc (i, i) as a dedicated arc and arc (i, j), i ̸= j as a ﬂexible arc. We also
deﬁne open chain Lk as Lk = Dk ∪{(i, i + 1)|i = 1, . . . , k −1}, for any integer
k ≥0. One can think of Lk as the open chain that connects plant 1 to product k.
Note that Lk is simply Ck \ {(k, 1)}.
Given a random instance of the demand, d, the maximum sales that can be
achieved by a ﬂexibility design A with arc capacities u, denoted by P(d, A , u), is
deﬁned as
P(d, A , u) =
Min

1≤i,j≤n fij
s.t.
n
i=1 fij ≤dj, ∀1 ≤j ≤n,
n
j=1 fij ≤1, ∀1 ≤i ≤n,
fij ≤uij, ∀1 ≤i, j ≤n,
fij ≥0, ∀(i, j) ∈A ,
fij = 0, ∀(i, j) /∈A .
It is not diﬃcult to see that this optimization problem is a max-ﬂow problem,
and as a result, we refer to fij as the ﬂow on arc (i, j). Note that when the arc

13.2 Supermodularity and Incremental Beneﬁts of Long Chains
245
capacities are 1, the capacity constraints are redundant. In this case, the above
optimization problem is referred to as the optimization problem associated with
P(d, A ), or simply, P(d, A ), when there is no ambiguity.
Under random demands D, we deﬁne the performance, also referred to as exp-
ected sales, of A to be E[P(D, A )], where E[·] is the expectation of a random
variable with respect to D. For succinctness, we also use [A ] to denote this quantity
when the random vector D is given.
13.2.1
Supermodularity in Arc Capacities
In this subsection, we show that P(d, A , u) is supermodular in the capacities of
ﬂexible arcs in A . For this purpose, we ﬁrst present a classical result by Gale and
Politof (1981) on supermodularity of the maximum-weight circulation problem. We
then note that P(d, A , u) can be computed by solving an equivalent maximum-
weight circulation problem, and the result by Gale and Politof (1981) applies.
In a maximum-weight circulation problem, we are given a directed graph G and
for each arc γ, a weight wγ, a lower bound lγ, and an upper bound uγ on the arc
ﬂow. A ﬂow f is called a circulation if it satisﬁes the ﬂow-balance constraints; that
is, at each node, the inﬂow equals the outﬂow. The maximum-weight circulation
problem is to ﬁnd a feasible circulation f satisfying the lower and upper bound
constraints such that the total weight 
γ wγfγ is maximized. For a set of arcs
S and any vector ξ indexed by the arcs, let ξS = (ξγ)γ∈S, a vector consisting of
components of ξ with indices in S. The following theorem from Gale and Politof
(1981) illustrates that the optimal objective value of the problem, denoted as
F(w, l, u), is supermodular in the capacities of arcs that are in series (pairwise).
Note that two arcs α, β are said to be in series if, for any (undirected) cycle C
containing both α and β, α and β have the same direction.
Theorem 13.2.1 If S contains only arcs that are in series (pairwise), F(w, l, u)
is supermodular in uS.
Proof. In view of Theorem 2.2.2, we only need to show that for any two arcs α and
β in S, F(w, l, u) has increasing diﬀerences in (uα, uβ) when other components
of u are ﬁxed. Given two capacity vectors u and u′ with uij = u′
ij for all (i, j)
except α and β, assume without loss of generality that uα > u′
α and uβ < u′
β. Let
f and f ′ be the optimal circulations in the graph given in the maximum-weight
circulation problem with capacities u and u′, respectively. It suﬃces to construct
two circulations g and g′ such that g and g′ are feasible for the maximum-weight
circulation problems with capacities u ∧u′ and u ∨u′, respectively, and
g + g′ = f + f ′.
If f ≤u ∧u′, or f ′ ≤u ∧u′, simply let g = f and g′ = f ′, or g = f ′ and g′ = f.
Assume that u′
α < fα ≤uα and uβ < f ′
β ≤u′
β. Let ξ = f −f ′. Clearly, ξ is a
circulation with ξα > 0 and ξβ < 0. We now show that ξ can be decomposed as

246
13. Process Flexibility
the summation of several conformal circuits. That is, there exist simple cycles Cl
and scalars tl > 0 for l = 1, . . . , τ for some integer τ such that
ξ =
τ

l=1
tlf l,
(13.1)
where f l
γ = sign(ξγ) if γ ∈Cl (regardless of direction) and zero otherwise. To see
this, start from any node, say node i0, incident to an arc (i0, i1) with ξi0i1 ̸= 0.
Without loss of generality, assume ξi0i1 > 0; otherwise, consider −ξ. Since ξ is a
circulation, node i1 must be incident to an arc (i1, i2) or (i2, i1) for some node
i2 such that either ξi1i2 > 0 or ξi2i1 < 0. Similarly, node i2 must be incident to
an arc (i2, i3) or (i3, i2) for some node i3 such that either ξi2i3 > 0 or ξi3i2 < 0.
Continue the process until the ﬁrst time we meet a node that has appeared before,
say node iν. Let iκ be the node visited immediately before the second time we
visit iν. In this case, we end up with a simple cycle iνiν+1 · · · iκiν, denoted by C1.
Let C+
1 and C−
1 be the sets of arcs on C1 in the same direction as C1 and in the
opposite direction as C1, respectively. Let
t1 = min
γ∈C1 |ξγ|,
and f 1
γ = 1 for γ ∈C+
1 and −1 for γ ∈C−
1 . Clearly, f 1 is a circulation with
f 1 = sign(ξγ) for γ ∈C1 and zero otherwise. Our construction implies that the
circulation ξ −t1f 1 has at least one more arc with zero ﬂow than the circulation
ξ. By repeating the above construction, we can show that (13.1) holds.
Note that for any l = 1, . . . , τ, f l
α takes values 0 or 1 because fα > f ′
α and f l
β
takes values 0 or −1 because fβ < f ′
β. In addition, since α and β are in series, it
is impossible to have f l
α = 1 and f l
β = −1 simultaneously for any cycle f l.
Deﬁne new circulations
g = f −

l=1:τ,f lα=1
tlf l, g′ = f ′ +

l=1:τ,f lα=1
tlf l.
We have that g + g′ = f + f ′ and
g = f ′ +

l=1:τ,f l
α=0
tlf l, g′ = f −

l=1:τ,f l
α=0
tlf l.
We claim that g and g′ are feasible for the maximum-weight circulation problems
with capacities u ∧u′ and u ∨u′, respectively. Notice that for any arc γ, since f l
γ
has the same sign as fγ −f ′
γ if γ ∈Cl, we have that
gγ = fγ −

l=1:τ,f lα=1
tlf l
γ ∈[min(fγ, f ′
γ), max(fγ, f ′
γ)].
Similarly,
g′
γ ∈[min(fγ, f ′
γ), max(fγ, f ′
γ)].

13.2 Supermodularity and Incremental Beneﬁts of Long Chains
247
Thus, for any arc γ diﬀerent from α and β,
gγ, g′
γ ∈[lγ, uγ].
For the arc α, since f l
α = 0 for α ̸∈Cl,
gα = f ′
α ∈[lα, min(uα, u′
α)], g′
α = fα ∈[lα, max(uα, u′
α)].
For the arc β, since f l
α = 1 implies that f l
β = 0, we have that
gβ = fβ ∈[lβ, min(uβ, u′
β)], g′
β = f ′
β ∈[lβ, max(uβ, u′
β)].
Thus, g and g′ are feasible for the maximum-weight circulation problems with
capacities u ∧u′ and u ∨u′, respectively.
To apply the above theorem, we convert the optimization problem of computing
P(d, A , u) to an equivalent maximum-weight circulation problem. Speciﬁcally, let
G(A ) be the underlying graph, which contains A , an additional node s, an arc
from s to each of the plant nodes, and an arc from each of the product nodes to s.
Set the weight of each plant to product arc (that is, the arcs in A ) to 1 and the
weight of every other arc to zero. The upper bound (capacity) on the ﬂow on an
arc from s to plant i is set to be 1 for all i = 1, 2, . . ., n; the upper bound for the
ﬂow on an arc connecting product j to s is set to be dj for all j = 1, 2, . . ., n; and
the upper bound for the ﬂow on every arc (i, j) ∈A is set to be uij. Finally, we
set the lower bound for the ﬂow on every arc in G(A ) to be 0. It is straightforward
to show that P(d, A , u) can be computed by identifying a circulation satisfying
the lower and upper bounds on ﬂows with a maximum weight.
The underlying graph of the maximum-weight circulation problem, G(A ), is
illustrated in Fig. 13.3 for A = C5, of long chain for a balanced system of size 5.
Recall that ﬂexible arcs in a long chain of size n are arcs from the set {(i, i + 1) :
i = 1, 2, . . . , n −1} ∪{(n, 1)}.
Theorem 13.2.2 Let A be a ﬂexibility design for a balanced system of size n,
and A ⊆Cn. Let S be the set of all ﬂexible arcs in A . We have that P(d, A , u)
is supermodular in uS. Hence, for any subsets X, Y of S,
P(d, A \ (X ∩Y )) + P(d, A \ (X ∪Y )) ≥P(d, A \ X) + P(d, A \ Y ).
Proof. We ﬁrst show that ﬂexible arcs are in series (pairwise). Consider any two
ﬂexible arcs α and β and let C be an arbitrary (undirected) simple cycle in G(Cn)
containing both α and β. If C does not contain node s, then C must be the
undirected cycle that contains every plant to product arcs in Cn. In that case, it
is easy to verify that α and β have the same direction in C. Otherwise, suppose C
contains s. In such a case, C can be decomposed into four pieces, X1, X2, α, and
β, where X1, X2 are the two paths between α and β. Without loss of generality, we
assume X1 contains s. Since α and β cannot be incident to the same node, both X1
and X2 are nonempty. As X2 does not contain s, all arcs in X2 are plant-to-product

248
13. Process Flexibility
FIGURE 13.3. G(C5) for the max-weight circulation associated with P(d, Cn, u)
arcs (i.e., X2 ⊆Cn). Because of the structure of Cn, X2 contains an odd number
of arcs. Moreover, the path in X2 ∪{α} ∪{β} has alternating directions for every
two consecutive arcs and therefore, α and β have the same direction in C. This is
illustrated by Fig. 13.4. Since this is true for any arbitrary undirected cycle C, α
and β are in series in G(Cn). From Theorem 13.2.1, P(d, A , u) is supermodular
in uS.
FIGURE 13.4. Illustration for the proof of Theorem 13.2.2
To complete the proof, deﬁne u and u′ as follows:
uγ =

1,
γ ∈A \ X,
0,
γ ∈X,
u′
γ =

1,
γ ∈A \ Y,
0,
γ ∈Y.

13.2 Supermodularity and Incremental Beneﬁts of Long Chains
249
Clearly,
P(d, A \ X) = P(d, A , u),
P(d, A \ Y ) = P(d, A , u′),
P(d, A \ (X ∩Y )) = P(d, A , u ∨u′),
and
P(d, A \ (X ∪Y )) = P(d, A , u ∧u′).
Thus, the inequality in the theorem holds since P(d, A , u) is supermodular in uS
and X, Y ⊆S.
Since the theorem holds for any realization of demand, it must also be true in
expectation.
Corollary 13.2.3 For any ﬂexible arcs α, β in A ⊆Cn, E[P(D, A , u)] is super-
modular in uα and uβ for any random distributions D.
The corollary thus suggests that any two ﬂexible arcs in the long chain comple-
ment each other. That is, the existence of one ﬂexible arc increases the marginal
beneﬁt that can be gained when the other ﬂexible arc is added.
13.2.2
Incremental Beneﬁts in Long Chains
Corollary 13.2.3 is useful to prove that the incremental beneﬁts associated with
adding arcs to the long chain is increasing. Consider the following sequence of
ﬂexibility designs: L n
1 , L n
2 , L n
3 , . . . , L n
n , Cn, where we deﬁne L n
1
= Dn and
L n
k
= Lk ∪{(i, i)|i = k + 1, . . . , n}. In words, L n
k is simply the open chain
from plant 1 to product k plus the dedicated arcs connecting plants i to prod-
ucts i for all k < i ≤n. One can think of the sequence L n
2 , ..., L n
n , Cn as
diﬀerent stages of constructing Cn, by starting at L n
1
= Dn and adding ﬂex-
ible arcs (1, 2), (2, 3), . . . , (n −1, n), (n, 1) sequentially. Finally, recall that Cn is
the long chain of size n. In the following, we show that the incremental beneﬁt,
[L n
k ] −[L n
k−1], is nondecreasing with k.
Theorem 13.2.4 For any balanced system of size n with exchangeable demand,
we have
[L n
2 ] −[L n
1 ] ≤[L n
3 ] −[L n
2 ] ≤. . . ≤[L n
n ] −[L n
n−1] ≤[Cn] −[L n
n ].
Proof. Fix any 1 ≤k ≤n−1. Let α = (1, 2), β = (k, k+1). Note that by deﬁnition,
E[P(D, L n
k+1)] = [L n
k+1]
and
E[P(D, L n
k+1 \ {β})] = E[P(D, L n
k )] = [L n
k ].

250
13. Process Flexibility
Let Dσ = [D2, D3, . . . , Dn, D1]. Observe that
E[P(D, L n
k+1 \ {α, β})] = E[P(Dσ, L n
k+1 \ {α, β})] = E[P(D, L n
k−1)] = [L n
k−1]
and
E[P(D, L n
k+1 \ {α})] = E[P(Dσ, L n
k )] = E[P(D, L n
k )] = [L n
k ],
where the above equalities hold since the random vector D is exchangeable.
By Corollary 13.2.3, we have
E[P(D, L n
k+1)] + E[P(D, L n
k+1 \ {α, β})] ≥E[P(D, L n
k+1 \ {α})]
+ E[P(D, L n
k+1 \ {β})].
Thus, [L n
k+1] −[L n
k ] ≥[L n
k ] −[L n
k−1], for k = 2, ..., n −1.
To show [L n
n ] −[L n
n−1] ≤[Cn] −[L n
n ], let α = (1, 2), β = (n, 1) and let
Dσ = [D2, D3, . . . , Dn, D1]. Then
E[P(D, Cn)] = [Cn],
E[P(D, Cn \ {β})] = [L n
n ],
E[P(D, Cn \ {α, β})] = E[P(Dσ, L n
n−1)] = [L n
n−1],
and
E[P(D, Cn \ {α})] = E[P(Dσ, L n
n )] = [L n
n ].
Again by Corollary 13.2.3,
E[P(D, Cn)] + E[P(D, Cn \ {α, β})] ≥E[P(D, Cn \ {α})] + E[P(D, Cn \ {β})],
which implies that [Cn] −[L n
n ]
≥
[L n
n ] −[L n
n−1]. This completes the
proof.
Observe that the proof of Theorem 13.2.4 requires the application of the super-
modularity result (Theorem 13.2.2), which holds deterministically for any ﬁxed-
demand instance. By contrast, Theorem 13.2.4 holds only stochastically under
exchangeable demand but does not hold for any ﬁxed-demand instance.
13.3
Characterizing the Performance of Long Chains
In this section, we show that in a balanced system of size n with exchangeable
demand, the performance of the long chain can be characterized by the diﬀer-
ence between the performances of two open chains, which allows us to show that
the long chain is optimal among a class of ﬂexibility designs and develop an eﬃ-
cient algorithm to compute its expected performance. Like the previous section,
we start by developing several properties of the long chain when the demand is
deterministic.

13.3 Characterizing the Performance of Long Chains
251
13.3.1
Decomposition of a Long Chain
In this subsection, we ﬁx an arbitrary demand instance d. Throughout the sub-
section, when some integer k appears in a statement, we are, in fact, referring to
some i ∈{1, ..., n} congruent to k modulo n. For example, if plant n+ 3 appears in
a statement, then we are referring to plant 3; and if fn+1,n+2, the ﬂow from plant
n + 1 to product n + 2 appears in a statement, then we are referring to f1,2, the
ﬂow from plant 1 to product 2.
First, we start with the following lemma.
Lemma 13.3.1 Suppose P(d, Cn \ {α}) = P(d, Cn), where α is a ﬂexible arc in
Cn. Then, for any set X ⊆S, where S is the set of all ﬂexible arcs in Cn, we have
that
P(d, Cn \ (X ∪{α})) = P(d, Cn \ X).
Proof. If α ∈X, the result is trivial as X∪{α} = X. Otherwise, by Theorem 13.2.2,
P(d, Cn \ (X ∪{α})) + P(d, Cn) ≥P(d, Cn \ X) + P(d, Cn \ {α}),
which, together with the assumption that P(d, Cn) = P(d, Cn \ {α}), implies that
P(d, Cn \ (X ∪{α})) ≥P(d, Cn \ X).
Since by deﬁnition, P(d, Cn \ (X ∪{α}))
≤
P(d, Cn \ X), the lemma
holds.
Next, we show that the sales associated with Cn can be expressed as a sum of
n quantities, where each quantity is the diﬀerence of the sales associated with two
open chains in Cn.
Theorem 13.3.2 For any ﬁxed-demand instance d on balanced system of size n,
we have
P(d, Cn) =
n

i=1
(P(d, Cn \ {(i, i + 1)}) −P(d, Cn \ {(i −1, i), (i, i), (i, i + 1)})).
Proof. Since the demand instance d is ﬁxed, for the sake of succinctness, we use
P(A ) to denote P(d, A ) in the proof. We also deﬁne αi = (i, i + 1) and βi = (i, i)
for i = 1, 2, . . ., n [note that αn = (n, 1) as n + 1 is congruent with 1 modular n].
We ﬁrst claim that there is some i∗such that P(Cn) = P(Cn \ {αi∗}). Indeed,
given an optimal solution of the maximum-ﬂow problem deﬁning P(Cn), f ∗, if
f ∗
αi > 0 for any i = 1, . . . , n, deﬁne a new ﬂow ˆf such that
ˆfαi = f ∗
αi −δ, ˆfβi = f ∗
βi + δ ∀i = 1, . . . , n,
where δ = mini=1:n f ∗
αi. Let f ∗
αi∗= δ. Clearly, ˆf is feasible for the design Cn\{αi∗}
and generates exactly the same amount of total ﬂow as f ∗for the design Cn.

252
13. Process Flexibility
Thus, Cn is optimal for the maximum-ﬂow problem deﬁning P(Cn \ {αi∗}) and
P(Cn) = P(Cn \ {αi∗}). Without loss of generality, we assume that i∗= n, as we
can always relabel each plant (and product) i by i −i∗.
For each 1 ≤k1 ≤k2 ≤n, deﬁne Lk1→k2 = {(i, i)|i = k1, k1+1, . . . , k2}∪{(i, i+
1)|i = k1, k1 + 1, . . . , k2 −1}, and for each 1 ≤k2 < k1 ≤n, deﬁne Lk1→k2 =
{(i, i)|i = k1, k1 +1 . . ., n, 1, 2, . . . , k2}∪{(i, i+1)|i = k1, . . . , n, 1, . . . , k2 −1}. One
can think of Lk1→k2 as the open chain connecting plant k1 to product k2 in the
balanced system of size n.
By the deﬁnition of α and β, we have that for i = 1, . . . , n −1,
P(Cn \ {αi}) −P(Cn \ {αi−1, αi, βi})
= P(Cn \ {αi}) −P(Cn \ {αi−1, αi}) + min{1, di}
= P(Cn \ {αi, αn}) −P(Cn \ {αi−1, αi, αn}) + min{1, di}
= P(L1→i) + P(L(i+1)→n) + min{1, di}
−

P(L1→(i−1)) + P(L(i+1)→n) + min{1, di}

= P(L1→i) −P(L1→(i−1)),
(13.2)
where the ﬁrst equality holds since Cn\{αi−1, αi} is the union of two disjoint comp-
onents {βi} and Cn\{αi−1, αi, βi}, the second equality follows from Lemma 13.3.1,
and the third equality holds since Cn \{αi, αn} is the disjoint union of components
L1→i and L(i+1)→n, and Cn \ {αi−1, αi, αn} is the disjoint union of L1→(i−1),
L(i+1)→n and {βi}. Similarly,
P(Cn \ {α1}) −P(Cn \ {αn, α1, β1})
= P(Cn \ {α1}) −P(Cn \ {αn, α1}) + min{1, d1}
= P(Cn \ {α1, αn}) −P(Cn \ {α1, αn}) + min{1, d1}
= min{1, d1},
(13.3)
where the ﬁrst equality holds since Cn \ {αn, α1} is the union of two disjoint
components {β1} and Cn \ {αn, α1, β1} and the second inequality follows from
Lemma 13.3.1.
Finally,
P(Cn \ {αn}) −P(Cn \ {αn−1, αn, βn}) = P(L1→n) −P(L1→(n−1)).
(13.4)
Now, applying Equations (13.2)–(13.4), we obtain that
n
i=1(P(Cn \ {αi}) −P(Cn \ {αi−1, αi, βi}))
= min{1, d1} + n
i=2(P(L1→i) −P(L1→(i−1)))
= min{1, d1} + P(L1→n) −P(L1→1)
= P(L1→n)
= P(Cn \ {αn})
= P(Cn).
This completes the proof.

13.3 Characterizing the Performance of Long Chains
253
We note that Cn \ {(i, i + 1)} is an open chain connecting plant i + 1 to product
i, while Cn \ {(i −1, i), (i, i), (i, i + 1)} is an open chain connecting plant i + 1 to
product i −1.
13.3.2
Characterization and Optimality
With Theorem 13.3.2, we can now characterize the performance of the long chain
using the performances of open chains.
Theorem 13.3.3 For any balanced system of size n with exchangeable demand
D, we have
[Cn] = n([Ln] −[Ln−1]).
Proof. Theorem 13.3.2 states that for any d that is an instance of D,
P(d, Cn) =
n

i=1
(P(d, Cn\{(i, i+1)})−P(d, Cn\{(i−1, i), (i, i), (i, i+1)})). (13.5)
Since D is exchangeable, for any 1 ≤i ≤n,
E[P(D, Cn \ {(i, i + 1)})] = [Ln],
E[P(D, Cn \ {(i −1, i), (i, i), (i, i + 1)})] = [Ln−1].
Thus, the theorem follows by integrating over all random instances of D on
Equation (13.5).
Theorem 13.3.3 provides insights on the performance of long chains. Indeed,
it relates the expected performance of a long chain, [Cn], with the diﬀerence in
the expected performances of two open chains, [Ln] and [Ln−1], which are much
easier to compute and analyze.
An immediate corollary of Theorem 13.3.3 is that the long chain is optimal
among all 2-ﬂexibility designs.
Corollary 13.3.4 Consider a balanced system of size n with exchangeable
demand. Let F2 be the set of all 2-ﬂexibility designs of the system. That is, F2
is the set of all ﬂexibility designs where each plant node and each product node are
incident to exactly two arcs. Then we have
[Cn] = arg max
A ∈F2[A ].
In words, the long chain maximizes expected sales among all 2-ﬂexibility designs
in the system.
Proof. Consider a 2-ﬂexibility design A ∈F2. A must consist of several closed
chains (i.e., induced subgraphs in A that form undirected cycles) denoted by

254
13. Process Flexibility
SC1, SC2, ..., SCk. Let ni be the number of products and plants in the closed
chain SCi. Since the system size is n, k
i=1 ni = n. Now, by Theorem 13.3.3, we
have
[A ]
= k
i=1 ni([Lni] −[Lni−1])
= k
i=1 ni([L n
ni] −[L n
ni−1] + E[min{1, D1}])
≤k
i=1 ni([L n
n ] −[L n
n−1] + E[min{1, D1}])
= k
i=1 ni([Ln] −[Ln−1])
= n([Ln] −[Ln−1])
= [Cn],
where the second and third equalities follow from the deﬁnition of L n
k , and the
inequality from Theorem 13.2.4.
13.3.3
Computing the Performance of a Long Chain
In this subsection, we present a method to compute [Cn], the performance of
the long chain, based on Theorem 13.3.2. We focus on balanced systems with iid
demand. Because we consider systems of arbitrary sizes, we let D be an inﬁnite
random vector with iid entries, where Di is the random demand for product i
generated by a given distribution D for all i ≥1.
Since
[Cn]
n
is the diﬀerence of [Ln] and [Ln−1] by Theorem 13.3.3, we ﬁrst
introduce a greedy algorithm that ﬁnds the optimal solution of the linear program
associated with P(d, Ln), where d is an instance of D.
Finding the Optimal Solution f ∗for P(d, Ln)
Step 1: Set f ∗
1,1 = min(1, d1).
Step 2: For k = 2 to n,
set f ∗
k−1,k = min{1 −f ∗
k−1,k−1, dk} and f ∗
k,k = min{1, dk −f ∗
k−1,k}.
Showing that f ∗is optimal for the open chain Ln is straightforward and is left
as an exercise.
Given a random demand vector D, let Fij be the random ﬂow on arc (i, j)
returned by the above algorithm, for 1 ≤i, j ≤n. For each integer 1 ≤k ≤n −1,
deﬁne Wk = 1 −Fkk and W0 = 0. Wk can be thought of as the remaining capacity
in plant k after the production of product k at plant k is determined.
To develop a method to compute the performance of the long chain, assume that
the support of D lies in { i
N |i = 0, 1, 2, . . .} for some N ≥1. Under this assumption,
we let pi = Pr(D =
i
N ), for any i = 0, 1, . . . , 2N −1, and p2N = Pr(D ≥2), where
Pr(·) denotes the probability mass function of D.
Since the support of D lies in { i
N |i = 0, 1, 2, . . .}, it is easy to see that the
support of Fkk lies in { i
N |i = 0, 1, 2, . . ., N}. Since Wk = 1 −Fkk, the support set
of Wk is also { i
N |i = 0, 1, 2, . . ., N}. As a result, the distribution of Wk can be

13.3 Characterizing the Performance of Long Chains
255
described by a row vector qk with N + 1 elements, where its ith component qk
i
equals Pr(Wk =
i
N ), for i = 0, 1, . . . , N. The following lemma illustrates how qk
can be computed.
Lemma 13.3.5 qk+1 = qkA = q0Ak+1 for 0 ≤k ≤n −1, where q0 = [1 0 0 . . . 0]
A =
⎡
⎢⎢⎢⎢⎢⎢⎣
2N
i=N pi
pN−1
pN−2
· · ·
p1
p0
2N
i=N+1 pi
pN
pN−1
· · ·
p2
p0 + p1
...
...
...
...
...
...
p2N−1 + p2N
p2N−2
p2N−3
· · ·
pN
N−1
i=0 pi
p2N
p2N−1
p2N−2
· · ·
pN+1
N
i=0 pi
⎤
⎥⎥⎥⎥⎥⎥⎦
.
Proof. Since W0 is 0 by deﬁnition, q0 = [1 0 0 . . . 0]. Because the demand is inde-
pendent and Wk only depends on D1, . . . , Dk, Wk is independent of Dk+1. Hence,
we have for 1 ≤i ≤N −1,
qk+1
i
= Pr

Wk+1 = i
N

=
N

j=0
Pr(Wk = j)Pr

Dk+1 = 1 −i
N + j
N

=
N

j=0
qk
j pN−i+j.
In addition,
qk+1
0
= Pr(Wk+1 = 0) =
N

j=0
Pr(Wk = j)Pr

Dk+1 ≥1 + j
N

=
N

j=0
qk
j
2N

l=N+j
pN+l
and
qk+1
N
= Pr(Wk+1 = 1) =
N

j=0
Pr(Wk = j)Pr

Dk+1 ≤j
N

=
N

j=0
qk
j
j

l=0
pl.
Thus, qk+1 = qkA.
A direct consequence of Lemma 13.3.5 is that the following matrix multiplica-
tions can be used to determine the performance of the long chain when demands
are iid and the support of a product demand is a subset of { i
N |i = 0, 1, 2, . . .}.
Theorem 13.3.6
[Cn]
n
= [Ln] −[Ln−1] = qn−1π = q0An−1π, where π is a vector
of size N + 1, with
πi =
N+i

j=1
jpj + (N + i)
2N

j=N+i+1
pj,
∀0 ≤i ≤N.
Proof. The algorithm described above implies that [Ln]−[Ln−1] can be written as
the expectation of Fn−1n+Fnn, which is equal to E[min{1+Wn−1, Dn}]. Moreover,

256
13. Process Flexibility
E[min{1 + Wn−1, Dn}]
=
N
i=0 Pr
!
Wn−1 = i)E[min{Dn, 1 + i
N }
"
=
N
i=0 qn−1
i
(N+i
j=1 jpj + (N + i) 2N
j=N+i+1 pj).
Hence, we have that [Ln] −[Ln−1] = qn−1π. Apply Theorem 13.3.3, and we are
done.
The matrix multiplication method developed here to compute the performance
of the long chain is polynomial in N and n. Indeed, computing q0An−1π re-
quires O(nN 2) operations if one sequentially evaluates q0Ai for i = 1, . . . , k, or
O(N 2.807 log n) operations if one starts by determining An−1 using the classical
algorithm from Strassen (1969).
The matrix multiplication method can be used to compute the per-product
performance of the long chain for an inﬁnite-size system. Observe that the matrix
A is the transition matrix of a Markov chain with states
i
N for each i = 0, 1, . . . , N.
Since we focus on a balanced system with E[D] = 1, we can show that the states
in the Markov chain can be partitioned into two sets, a set containing states,
including state 0, that communicate with each other and the other set containing
inessential states. It is well known that limn→∞q0An−1 = q∗, where q∗A = q∗,
q∗
0 > 0, and q∗
j = 0 for any inessential states j. Thus, to compute limn→∞
[Cn]
n ,
one can solve for q∗by ﬁnding the eigenvectors of A and then compute q∗π, which
gives limn→∞
[Cn]
n .
We can apply the matrix multiplication method for general iid demands as an
approximation algorithm to compute the performance of long chains. In this case,
one can approximate the performance of the long chain by discretizing the demand
distribution on the set of { i
N |i = 0, 1, 2, . . .} for some integer N. Clearly, as N
increases, the error of the approximation decreases while the running time grows.
Speciﬁcally, it is straightforward to show that the error of the approximation is
bounded by
n
2N . Interestingly, computational experience suggests that the error is
much smaller than this bound.
Moreover, the matrix multiplication method is fairly fast even for large N. For
example, when N = 1000 and n = 100, q0An−1π can be computed within 2 s using
Matlab on a standard 2.1 GHz laptop. Hence, even for general iid demands, the
matrix multiplication method can quickly approximate the performance of a large
long chain very accurately.
Figure 13.5 presents computational results obtained using the matrix multipli-
cation method for three diﬀerent iid demand distributions:
• Normal: Demand for a product is a discretized normal random variable
with mean 1 and standard deviation of 0.33 on the support set of { i
14|i =
0, 1, . . . , 28};
• Uniform: Demand for a product is uniformly distributed on the set { i
10|i =
0, 1, 2, . . ., 9, 11, 12, . . ., 20};
• Asymmetric: Demand for a product is equal to 4
5 with probability 0.4, 1
with probability 0.5, and 2 with probability 0.1.

13.4 Performance of Long Chains
257
For each distribution, Fig. 13.5 depicts [Fn]
n
(the per-product performance of
full ﬂexibility), [Cn]
n
(the per-product performance of the long chain), and
[Cn]
[Fn]
(the ratio between the performance of the long chain and the performance of full
ﬂexibility design) for n = 1, . . . , 30.
FIGURE 13.5. The performance of long chains vs. the performance of full ﬂexibility
Figure 13.5 reveals several interesting observations. First, [Fn]
n
−[Cn]
n , that is,
the gap between the ﬁll rates of full ﬂexibility and the long chain, is increasing,
while the ratio [Cn]
[Fn] is decreasing. In addition, Fig. 13.5 suggests that the quantity
[Cn]
n , the ﬁll rate of the long chain, is increasing but converges to a constant very
quickly.
13.4
Performance of Long Chains
In this section, we present several analytical results that provide justiﬁcations to
the observations in Fig. 13.5. The following theorem illustrates that the quantity
[Fn]
n
−[Cn]
n
is indeed nondecreasing with n. Its proof is a bit involved and hence
omitted.

258
13. Process Flexibility
Theorem 13.4.1 For any integer n ≥2 and iid demand,
[Fn]
n
−[Cn]
n
≤[Fn+1]
n + 1 −[Cn+1]
n + 1 ≤min{1, E[D]} −γ,
where γ = limk→∞
[Ck]
k .
Note that the ﬁll rate of Cn (and Fn) is equal to
[Cn]
nE[D] (and
[Fn]
nE[D]). Thus, The-
orem 13.4.1 implies that the smaller the system size, the smaller the gap between
the ﬁll rate of full ﬂexibility and that of the long chain. This suggests that the
long chain is more eﬀective relative to full ﬂexibility for smaller systems.
Moreover, Theorem 13.4.1 can be used to bound the gap between the ﬁll rate
of full ﬂexibility and that of the long chain for systems of any size. Since for
many iid demand with E[D] = 1, γ is close to 1, as shown in Chou et al. (2010),
Theorem 13.4.1 implies that for any size system, the performance of the long chain
is close to that of full ﬂexibility. For example, when D is normal with mean 1 and
standard deviation 0.33, γ = 0.96. Therefore, for this demand distribution, we
have that the gap between the ﬁll rate of full ﬂexibility and that of the long chain
for systems of any size is at most 4 %.
Though the ratio of the performance of long chain to that of full ﬂexibility,
[Cn]
[Fn] ≥[Cn+1]
[Fn+1], is observed to be nonincreasing empirically in Chou et al. (2008),
whether it can be proven analytically remains an open question. Of course, if
[Cn]
[Fn] ≥[Cn+1]
[Fn+1] indeed holds, it follows that
[Cn]
[Fn] ≥lim
k→∞
[Ck]/k
[Fk]/k = lim
k→∞
γ
min{E[D], 1},
∀n ≥2,
(13.6)
where, as before, γ = limk→∞
[Ck]
k
and limk→∞
[Fk]
k
= min{E[D], 1} by the weak
law of large numbers. This would provide a lower bound on the ratio of the per-
formance of the long chain to that of full ﬂexibility for any system size.
A slightly weaker lower bound of the ratio when E[D] = 1 is provided by Simchi-
Levi et al. (2012).
Corollary 13.4.2 Suppose demand is iid and E[D] = 1; then
[Cn]
[Fn] ≥1 −(1 −γ)n
[Fn]
,
where γ = limk→∞
[Ck]
k .
Proof. By Theorem 13.4.1,
[Fi]
i
−[Ci]
i
≤[Fi+1]
i + 1 −[Ci+1]
i + 1 ,
∀i ≥1.
Thus,
[Fi]
i
−[Fi+1]
i + 1 ≤[Ci]
i
−[Ci+1]
i + 1 ,
∀i ≥1.
(13.7)

13.4 Performance of Long Chains
259
Now, adding inequality (13.7) for all i ≥n, we have that
[Fn]
n
−limk→∞
[Fk]
k
≤[Cn]
n
−limk→∞
[Ck]
k .
(13.8)
But
lim
k→∞
[Fk]
k
= 1,
lim
k→∞
[Ck]
k
= γ,
and substituting those into inequality (13.8), we have
[Fn]
n
−1 ≤[Cn]
n
−γ,
which leads to the inequality in the statement of this corollary.
To explain the power of the lower bound in Corollary 13.4.2, let δn =
n
[Fn] −1,
which implies that 1 −(1−γ)n
[Fn]
= γ −δn(1 −γ). Since [Fn]
n
is nondecreasing with n
(readers are asked to prove this claim in the exercises), δn is nonincreasing. Thus,
if δk ≈0 for some small integer k, then Corollary 13.4.2 provides a lower bound for
[Cn]
[Fn] that is close to γ for all n ≥k. Indeed, for many distributions with E[D] = 1,
δk ≈0 for small k. For example, suppose the distribution of D is normal with
mean 1 and standard deviation 0.33; then
3
[F3] = 1.08, which implies δ3 = 0.08.
Since γ = 0.96, by applying Corollary 13.4.2, we have that
[Cn]
[Fn] ≥γ −δ3(1 −γ) = 0.96 −0.04 × 0.08 = 0.9568,
∀n ≥3.
That is, when demand is normal with mean 1 and standard deviation 0.33, the
long chain of any size greater than 2 achieves at least 95.68 % of the performance
of full ﬂexibility.
Finally, we focus on the per-product performance (and ﬁll rate, which is linearly
proportional to the per-product performance) of the long chain as a function of
system size. We start by showing that
[Cn]
n
is nondecreasing with n under iid
demand.
Theorem 13.4.3 Under iid demand D, we have
[Cn]
n
≤[Cn+1]
n+1 , for any integer
n ≥2.
Proof. Since D is iid, the ﬁrst n (and n + 1) entries in D are exchangeable for a
balanced system of size n (and n + 1). Thus, by Theorem 13.2.4, we have that
[L n
n ] −[L n
n−1] ≤[L n+1
n+1 ] −[L n+1
n
],
which is equivalent to
[Ln] −[Ln−1] −E[min{D, 1}] ≤[Ln+1] −[Ln] −E[min{D, 1}]

260
13. Process Flexibility
and hence implies that
[Ln] −[Ln−1] ≤[Ln+1] −[Ln].
Applying Theorem 13.3.3 completes the proof.
The theorem thus states that [Cn]
n , as well as the ﬁll rate associated with a long
chain, increases with the number of products, n. This phenomenon is analogous
to the classical “risk-pooling” eﬀect associated with demand aggregation, except
that here we aggregate across capacities.
Interestingly, Fig. 13.5 suggests that the ﬁll rate of the long chain quickly con-
verges to a constant. This is shown in the next theorem, where we prove that the
convergence rate is exponential for arbitrary iid, nondegenerate demands.
Theorem 13.4.4 When demands are iid and nondegenerate, there exist constants
c > 0 and K > 0 such that
[Cn+1]
n + 1 −[Cn]
n
≤Ke−cn,
for any n ≥2.
Proof. From the deﬁnition of Wn−1, we have that [Cn]
n
= E[min{1+Wn−1(D), Dn}].
Let D2 = [D2, D3, . . .]. We have
[Cn+1]
n+1 −[Cn]
n
= E[min{1 + Wn(D), Dn+1}]−E[min{1 + Wn−1(D2), Dn+1}]
= E[min{1 + Wn(D), Dn+1} −min{1 + Wn−1(D2), Dn+1}]
≤Pr(Wn(D) ̸= Wn−1(D2)),
where the last inequality is true because
min{1 + Wn(D), Dn+1} −min{1 + Wn−1(D2), Dn+1}
never exceeds 1. Note that for any particular random instance d, Wn(d)=Wn−1(d2)
if Wi(d) = 0 for some 1 ≤i ≤n or Wi(d2) = 1 for some 1 ≤i ≤n −1. Thus,
Pr(Wn(D) ̸= Wn−1(D2)) ≤Pr(Wi(D) > 0, Wi(D2) < 1, ∀1 ≤i ≤n).
Therefore, we have
[Cn+1]
n + 1 −[Cn]
n
≤Pr(Wi(D) > 0, Wi(D2) < 1, ∀1 ≤i ≤n).
Now, since D is nondegenerate and iid, there exists some t such that
p = Pr(
t

j=1
(Dj −1) ≥1) > 0.

13.5 Extensions
261
If some instance d satisﬁes the condition
Wi(d) > 0, Wi(d2) < 1, ∀1 ≤i ≤n,
then we must have that
kt+1

j=2+(k−1)t
(dj −1) < 1
for any 1 ≤k ≤⌊n−1
t ⌋. Hence,
[Cn+1]
n+1 −[Cn]
n
≤Pr(Wi(D) > 0, Wi(D2) < 1, ∀1 ≤i ≤n)
≤Pr
kt+1
j=2+(k−1)t(Dj −1) < 1, ∀1 ≤k ≤⌊n−1
t ⌋

= (1 −p)⌊n−1
t
⌋
≤Ke−cn
for some constants K > 0 and c > 0.
Figure 13.5 and Theorem 13.4.4 show that
[Cn]
n
≈
[Cn+t]
n+t
for any t provided
that n is large. Hence, it implies that in a system with a large number of plants
and products, it is not necessary to have a long-chain design that connects all
the plants and products. A collection of several chains, each of which has a large
number of plants and products, can be as eﬀective.
13.5
Extensions
In the previous section, we focused on long chains for balanced systems and were
mainly concerned with the average performance. In addition, we assumed that
production quantities are decided only after demand is realized. Various extensions
can be found in Chou et al. (2010, 2011, 2012). In Chou et al. (2010), in addition to
analyzing the asymptotic average performance of long chains, the authors analyze
a system with general demand and supply. They show using random sampling that
there exists a sparse ﬂexibility structure that achieves a performance nearly as well
as the full ﬂexibility structure on average. Speciﬁcally, in a manufacturing system
with n plants and m products, there exists a ﬂexible design A with O

(n+m)U
Lϵ

links such that E[P(D, A )] ≥(1 −ϵ)E[P(D, F)], where U = max
D
E[D] and L =
min
D
E[D].
Since the random sampling approach reveals very few insights regarding the
ﬂexibility structure, Chou et al. (2011) show that the so-called graph expander
structure, a sparse but highly connected graph, often used in communication net-
works, can achieve a performance nearly as good as the full ﬂexibility structure
in the worst case. For a balanced system, for any ϵ ∈(0, 1), there exists a graph

262
13. Process Flexibility
expander A with no more than Δ arcs incident to each plant node such that
P(d, A ) ≥(1 −ϵ)P(d, F) for any instance d, as long as
Δ ≥−1 + log2 U + (U + 1) log2 e
−log2(1 −ϵ)
+ U + 1.
The authors extend the concept of graph expander to derive a similar result for
general systems.
Finally, Chou et al. (2012) analyze a setting in which only a portion of the pro-
duction can be postponed until the realization of demand. They show that in this
case, though the performance of long chains deteriorates when the postponement
level is moderate, a sparse structure with a small amount of additional ﬂexibility
can performnearly as well as the full ﬂexibility structure.
13.6
Exercises
Exercise 13.1. (Murota and Shioura 2005) Consider the maximum-weight circu-
lation problem described in Sect. 13.2. Let S be an arc set consisting of arcs that
are in series (pairwise). Show that F(w, l, u) is M ♮-convex in wS, and L♮-concave
in lS and in uS.
Exercise 13.2. (Murota and Shioura 2005) In a directed graph, two arcs α, β
are said to be in parallel if any (undirected) cycle C containing both α and β
orients them in the opposite direction. Let P be an arc set consisting of arcs that
are in parallel (pairwise). Show that F(w, l, u) is L♮-convex in wP , M ♮-concave in
lP and in uP .
Exercise 13.3. Show that f ∗computed in the algorithm in Sect. 13.3.3 is indeed
optimal for P(d, Ln).
Exercise 13.4. Show that [Fn]
n
is nondecreasing in n. Note that the average sales
of the full ﬂexibility design, [Fn], is given by E[min{n, n
i=1 Di}].

14
Supply Chain Planning Models
14.1
Introduction
In the last decade, many companies have recognized that important cost savings
and improved service levels can be achieved by eﬀectively integrating produc-
tion plans, inventory control, and transportation policies throughout their supply
chains. The focus of this chapter is on planning models that integrate decisions
across the supply chain for companies that rely on third-party carriers. These mod-
els are motivated in part by the great development and growth of many competing
transportation modes, mainly as a consequence of deregulation of the transporta-
tion industry. This has led to a signiﬁcant decrease in transportation costs charged
by third-party distributors and, therefore, to an ever-growing number of companies
that rely on third-party carriers for the transportation of their goods.
One important mode of transportation used in the retail, grocery, and elec-
tronic industries is the less-than-truckload (LTL) mode, which is attractive when
shipment sizes are considerably less than truck capacity. Typically, LTL carriers
oﬀer volume, or quantity, discounts to their clients to encourage demand for larger,
more proﬁtable shipments. In this chapter, we model these discounts as a piecewise
linear concave function of the quantity shipped.
Similarly, production costs can often be approximated by piecewise linear and
concave functions of the quantity produced, that is, setup plus linear manufactur-
ing costs. These economies of scale motivate the shipper to coordinate the produc-
tion, routing, and timing of shipments over the transportation network to minimize
systemwide costs. In what follows, we refer to this problem as the shipper problem.
D. Simchi-Levi et al., The Logic of Logistics: Theory, Algorithms, and Applications
for Logistics Management, Springer Series in Operations Research and Financial Engineering,
DOI 10.1007/978-1-4614-9149-1 14, © Springer Science+Business Media New York 2014
263

264
14. Supply Chain Planning Models
This planning model, while quite general, is based on several assumptions that
are consistent with the view of modern logistics networks. Indeed, the model deals
with situations in which all facilities are part of the same logistics network, and
information is available to a central decision maker whose objective is to optimize
the entire system. Thus, distribution problems in the retail and grocery indus-
tries are special cases of our model where the logistics network does not include
manufacturing facilities.
The model also applies to situations in which suppliers and retailers are en-
gaged in strategic partnering. For instance, in a vendor-managed inventory (VMI)
partnership, point-of-sales data are transmitted to the supplier, which is responsi-
ble for the coordination of production and distribution, including managing retail
inventory and shipment schedules. Hence, in this case, the model includes manu-
facturing facilities, warehouses, and retail outlets.
This deterministic tactical model is motivated, in part, by our experience with
a number of companies that apply similar models on a rolling-horizon basis. That
is, they consider forecast demand for the next 52 weeks and allow the model
to generate a production, transportation, and inventory schedule for the entire
planning horizon. The use of a rolling horizon implies that these companies employ
the plan generated by the model only for a few time periods, say for the ﬁrst three
or four weeks. As time goes on, they update the demand forecasts and run the
model again.
While this model is deterministic, in practice, safety stocks are determined ex-
ogenously and incorporated into the minimum inventory level that should be main-
tained at the beginning of each period. Of course, an important question when
managing inventory in a complex supply chain is where to keep safety stock? The
answer to this question clearly depends on the desired level of service, the logis-
tic network, the demand forecast and forecast error, as well as lead times and
lead-time variability. Thus, in Sect. 14.3, we discuss models for positioning and
optimizing safety stock in the supply chain. We start in the next section with our
modeling approach and results for the shipper problem.
14.2
The Shipper Problem
In this section, we focus on the shipper problem under piecewise linear and con-
cave production and transportation costs, and use properties resulting from the
concavity of the cost function to devise an eﬃcient algorithm.
The objective of the shipper is to ﬁnd a production plan, an inventory policy,
and a routing strategy to minimize the total cost and satisfy all the demands.
Backlogging of demands may be allowed, incurring a known penalty cost, which
is a function of the length of the shortage period and the level of shortage. In
this case, four diﬀerent costs must be balanced to obtain an overall optimal pol-
icy: production costs; LTL shipping charges; holding costs incurred when carrying
inventory at some facility; and penalty costs for delayed deliveries.

14.2 The Shipper Problem
265
To formulate this tactical problem, we ﬁrst incorporate the time dimension into
the model by constructing the so-called expanded network. This expanded net-
work is used to formulate the shipper problem as a set-partitioning problem. The
formulation is found to have surprising properties, which are used to develop an
eﬃcient algorithm and to show that the linear programming relaxation of the
set-partitioning formulation is tight in certain special cases (Sect. 14.2.4). Compu-
tational results, demonstrating the performance of the algorithm on a set of test
problems, are reported in Sect. 14.2.5.
14.2.1
The Shipper Model
Consider a generic transportation network, G = (N, A), with a set of nodes N
representing the suppliers, warehouses, and customers. Customer demands for the
next T periods are assumed to be deterministic, and each of them is considered a
separate commodity, characterized by its origin, destination, size, and the time
period when it is demanded. Our problem is to plan production and route ship-
ments over time to satisfy these demands while minimizing the total production,
shipping, inventory, and penalty costs.
A standard technique to eﬃciently incorporate the time dimension into the
model is to construct the following expanded network. Let τ1, τ2, . . . , τT be an
enumeration of the model’s relevant time periods. In the original network, G, each
node i is replaced by a set of nodes i1, i2, . . . , iT . We connect node iu with node
jv if and only if τv −τu is exactly the time it takes to travel from i to j. Thus, arc
iu →jv represents freight being carried from i to j starting at time τu and ending
at time τv. We call such arcs shipping links. In order to account for penalties
associated with delayed shipments, a new node is created for each commodity
and serves as its ultimate sink. For a given commodity, a link between a node
representing its associated retailer at a speciﬁc time period and its corresponding
sink node represents the penalty cost of delivering a speciﬁc shipment in that time
period; it is called the penalty link. Similarly, to include production decisions in
the network model, we add for each node it, corresponding to a production facility
(supplier) i at a particular point in time t, a dummy node i′
t and an arc from
i′
t to it whose cost represents the piecewise linear concave manufacturing costs.
Observe that these production links have the same cost structure as the shipping
links. Consequently, in our analysis of the network model, we will include them
in the set of shipping links. Finally, we add links (il, il+1) for l = 1, 2, . . ., T −1,
referred to as inventory links.
Let GT = (V, E) be the expanded network. Figure 14.1 illustrates the ex-
panded network for a simple scenario where the shipping and inventory costs have
to be balanced over a time horizon of just three periods and shortages are not
allowed. For simplicity, we assume that travel times are zero.
Observe that, using the expanded network, we can formulate the shipper prob-
lem as a concave-cost multicommodity network ﬂow problem.

266
14. Supply Chain Planning Models
Simple Scenario
Associated Expanded Network
Period 3
Period 2
Period 1
FIGURE 14.1. Example of expanded network
14.2.2
A Set-Partitioning Approach
To describe our modeling approach, we introduce the following notation. Let K =
{1, 2, . . ., K} be the index set of all commodities, or diﬀerent demands with ﬁxed
origin and destination, and let wk, k = 1, 2, . . ., K, be their corresponding size.
For instance, commodity k = 1 may correspond to a demand of w1 = 100 units
that need to be shipped from a certain supplier to a certain retailer and must
arrive by a particular period of time or incur delay penalties. Let the set of all
possible paths for commodity k be Pk, and let cpk be the sum of inventory and
penalty costs incurred when commodity k is shipped along path p ∈Pk. Observe
that the shipping cost associated with a path will depend on the total quantity
of all commodities being sent along each of its shipping links and, consequently,
it can’t be added to the path cost a priori. Thus, each shipping edge, whose cost
must be globally computed, needs to be considered separately. Let the set of all
shipping edges be SE, and for each edge e ∈SE, let ze be the total sum of weight
of the commodities traveling on that edge.
We assume that the cost of a shipping edge e, e ∈SE, of the expanded net-
work GT (V, E), is Fe(ze), a piecewise linear and concave cost function that
is nondecreasing in the total quantity, ze, of the commodities sharing edge e. As
presented in Balakrishnan and Graves (1989), this special cost structure allows
for a formulation of the problem as a mixed integer linear program. For this pur-
pose, the piecewise linear concave functions are modeled as follows. Let R be the
number of diﬀerent slopes in the cost function, which we assume, without loss of
generality, is the same for all edges to avoid cumbersome notation. Let M r−1
e
, M r
e ,
r = 1, . . . , R, denote the lower and upper limits, respectively, on the interval of
quantities corresponding to the rth slope of the cost function associated with edge
e. Note that M 0
e = 0 and M R
e can be set to the total quantity of all commodities
that may use arc e. We associate with each of these intervals, say r, a variable cost
per unit, denoted by αr
e, equal to the slope of the corresponding line segment, and
a ﬁxed cost, f r
e , deﬁned as the y-intercept of the linear prolongation of that seg-
ment. See Fig. 14.2 for a graphical representation. Observe that the cost incurred
by any quantity on a certain range is the sum of its associated ﬁxed cost plus the

14.2 The Shipper Problem
267
Fe(ze)
ze
Me
2
Me
1
Me
0
fe
1
fe
3
fe
2
Slope
αe
1
Slope
αe
2
Slope
αe
3
FIGURE 14.2. Piecewise linear and concave cost structure
cost of sending all units at its corresponding linear cost. That is, we can express
the arc ﬂow cost function, Fe(ze), as
Fe(ze) = f r
e + αr
eze
if ze ∈(M r−1
e
, M r
e ]. Clearly,
Property 14.2.1 The concavity and monotonicity of the function Fe imply that
1. α1
e > α2
e > . . . > αR
e ≥0,
2. 0 ≤f 1
e < f 2
e < . . . < f R
e ,
3. Fe(ze) = minr=1,...,R

f r
e + αr
eze

. The minimum is achieved at a unique
index s, unless ze = M s
e , in which case the two consecutive indexes s and
s + 1 lead to the same minimum cost.
We are now ready to introduce an integer linear programming formulation of
the shipper problem for this special cost structure. Recall that ze denotes the total
ﬂow on edge e, and let zek be the quantity of commodity k that is shipped along
that edge. For all e ∈SE and r = 1, . . . , R, deﬁne the interval variables,
xr
e =
 1,
if ze ∈(M r−1
e
, M r
e ],
0,
otherwise,
and, in addition, for every k, k ∈K, let the quantity variables be
zr
ek =
 zek,
if ze ∈(M r−1
e
, M r
e ],
0,
otherwise.

268
14. Supply Chain Planning Models
In order to relate these edge ﬂows to path ﬂows, we deﬁne, for each e ∈SE and
p ∈K
k=1 Pk,
δe
p =
 1,
if shipping link e is in path p,
0,
otherwise.
Finally, let variables
ypk =
 1,
if commodity k follows path p in the optimal solution
0,
otherwise,
for each k ∈K and p ∈Pk. These variables are referred to as path ﬂow variables.
Observe that deﬁning these variables as binary variables implies that for every
commodity k, only one of the variables ypk takes a positive value. This reﬂects a
common business practice in which each commodity, that is, items originated at
the same source and destined to the same sink in the expanded network, is shipped
along a single path. These integrality constraints are, however, not restrictive, as
pointed out in Property 14.2.2 below, since the problem is uncapacitated and the
cost functions concave.
In the set-partitioning formulation of the shipper problem, the objective is to
select a minimum-cost set of feasible paths. Thus, we formulate the shipper prob-
lem for piecewise linear concave edge costs as the following mixed integer linear
program, which we denote by Problem P.
Problem P :
Min
K

k=1

p∈Pk
ypkcpk +

e∈SE
R

r=1

f r
e xr
e + αr
e(
K

k=1
zr
ek)

s.t.

p∈Pk
ypk = 1,
∀k = 1, 2, . . ., K,
(14.1)

p∈Pk
δe
pypkwk =
R

r=1
zr
ek,
∀e ∈SE, k = 1, . . . , K, (14.2)
zr
ek ≤wkxr
e
∀e, r, k,
(14.3)
K

k=1
zr
ek ≤M r
e xr
e,
∀e ∈SE, r = 1, . . . , R,
(14.4)
K

k=1
zr
ek ≥M r−1
e
xr
e,
∀e ∈SE, r = 1, . . . , R,
(14.5)
R

r=1
xr
e ≤1
∀e ∈SE,
(14.6)
ypk ∈{0, 1},
∀k = 1, 2, . . ., K, and p ∈Pk,
(14.7)
xr
e ∈{0, 1},
∀e ∈SE, and r = 1, 2, . . . , R,
(14.8)
zr
ek ≥0,
∀e ∈SE, ∀k = 1, 2, . . . , K,
and r = 1, 2, . . ., R.

14.2 The Shipper Problem
269
In this formulation, constraints (14.1) ensure that exactly one path is selected
for each commodity and constraints (14.2) set the total ﬂow on an edge e to be
equal to the total ﬂow of all the paths that use that edge. Constraints (14.3)–(14.6)
are used to model the piecewise linear concave function. Constraints (14.3) specify
that if some commodity k is shipped on edge e using cost index r, the associated
interval variable, xr
e, must be 1. Constraints (14.4) and (14.5) make sure that if
cost index r is used on edge e, then the total ﬂow on that edge must fall in its
associated interval, [M r−1
e
, M r
e ]. Finally, constraints (14.6) indicate that at most
one cost range can be selected for each edge.
Let Z∗be the optimal solution to Problem P. Let ZRx and ZRy be the optimal
solutions to relaxations of Problem P, where the integrality constraints of inter-
val (x) and path ﬂow (y) variables, respectively, are dropped. A consequence of
Property 14.2.1 is the following result.
Property 14.2.2 We have
Z∗= ZRx = ZRy.
To ﬁnd a robust and eﬃcient heuristic algorithm for Problem P, we study
the performance of a relaxation of Problem P that drops integrality and re-
dundant constraints. Although constraints (14.3) are not required for a correct
mixed integer programming formulation of the problem, we keep them because
they signiﬁcantly improve the performance of the linear programming relaxation
of Problem P. In fact, Croxton et al. (2003), show that, without them, the lin-
ear programming relaxation of this model approximates the piecewise linear cost
functions by their lower convex envelope. Furthermore, keeping these constraints
makes constraints (14.4)–(14.6) redundant in the correct mixed integer program-
ming formulation, as a direct consequence of Property 14.2.1, part 3, and in the
linear programming relaxation of Problem P as well, as Lemma 14.2.3 below shows.
This will be useful to considerably reduce the size of the formulation of the problem
while preserving the tightness of its linear programming relaxation.
Let Problem P R
LP be the linear program obtained from Problem P by relaxing
the integrality constraints and constraints (14.4)–(14.6). That is,
Problem P R
LP :
Min
K

k=1

p∈Pk
ypkcpk +

e∈SE
R

r=1

f r
e xr
e + αr
e(
K

k=1
zr
ek)

s.t.
(14.1) −(14.3)
ypk ≥0,
∀k = 1, 2, . . ., K, and p ∈Pk,
xr
e ≥0,
∀e ∈SE, and r = 1, 2, . . ., R,
zr
ek ≥0,
∀e ∈SE, ∀k = 1, 2, . . ., K,
and r = 1, 2, . . . , R.
Chan, Muriel and Simchi-Levi (1999), prove the following.

270
14. Supply Chain Planning Models
Lemma 14.2.3 The optimal solution value to Problem P R
LP is equal to the optimal
solution value to the linear programming relaxation of Problem P.
14.2.3
Structural Properties
To analyze the relaxed problem, we start by ﬁxing the fractional path ﬂows and
study the behavior of the resulting linear program. Let y = (ypk) be the vector of
path ﬂows in a feasible solution to the relaxed linear program, Problem P R
LP .
Observe that, given the vector of path ﬂows y, the amount of each commodity
sent on each edge is known and, thus, Problem P R
LP can be decomposed into
multiple subproblems, one for every edge. Each subproblem determines the cost
that the linear program associates with the corresponding edge ﬂow. We refer to
the subproblem associated with edge e as the ﬁxed-ﬂow subproblem on edge e, or
Problem FF e
y .
Let the proportion of commodity k shipped along edge e be
γek =

p∈Pk
δe
pypk.
We use Equation (14.2); the equality R
r=1 zr
ek = wkγek must clearly hold; that
is, the sum of all the ﬂows of commodity k on the diﬀerent cost intervals on edge
e must be equal to the total quantity, wkγek, of commodity k that is shipped on
that edge.
For each edge e, the total shipping cost on e, as well as the value of the corre-
sponding variables zr
ek and xr
e, which Problem P R
LP associates with the vector of
path ﬂows y, can be obtained by solving the ﬁxed-ﬂow subproblem on edge e:
Problem FF e
y :
Min
R

r=1
[f r
e xr
e + αr
e
K

k=1
zr
ek]
s.t.
zr
ek ≤wkxr
e
∀k = 1, . . . , K, and r = 1, . . . , R, (14.9)
R

r=1
zr
ek = wkγek,
∀k = 1, . . . , K,
(14.10)
zr
ek ≥0,
∀k = 1, . . . , K, and r = 1, . . . , R,
xr
e ≥0,
∀r = 1, . . . , R.
Let C∗
e (y) ≡C∗
e (γe1, . . . , γeK) be the optimal solution to the ﬁxed-ﬂow sub-
problem on edge e for a given vector of path ﬂows y or, equivalently, for given
corresponding proportions γe1, . . . , γeK of the commodities shipped on that edge.
The following theorem determines the solution to the subproblem.
Theorem 14.2.4 For any given edge e ∈SE, let the proportion γek of commodity
k to be shipped on edge e be known and ﬁxed, for k = 1, 2, . . ., K, and let the

14.2 The Shipper Problem
271
commodities be indexed in nondecreasing order of their corresponding proportions,
that is,
γe1 ≤γe2 ≤. . . ≤γeK.
Then the optimal solution to the ﬁxed-ﬂow subproblem on edge e is
C∗
e (γe1, . . . , γeK) =
K

k=1
Fe(
K

i=k
wi)[γek −γek−1],
(14.11)
where γe0 := 0.
Intuitively, the above theorem just says that in an optimal solution to the ﬁxed-
ﬂow subproblem associated with any edge e, fractions of commodities are consol-
idated to be shipped at the cheapest possible cost per unit. At ﬁrst, a fraction
γe1 of all commodities 1, 2, . . ., K is available. Thus, these commodities get con-
solidated to achieve a cost per unit of Fe(K
k=1 wk)/ K
k=1 wk, that is, the cost
per unit associated with sending the full K commodities on that edge, and the
available fraction γe1 is sent incurring a cost of γe1Fe(K
k=1 wk). At that point,
none of commodity 1 is left and a fraction (γe2 −γe1) is the maximum available
simultaneously from all commodities 2, 3, . . ., K. These commodities are consoli-
dated again, and that fraction, (γe2 −γe1), from each commodity is sent at a cost
(γe2 −γe1)Fe(K
k=2 wk). This process continues until the desired proportion of
each commodity has been sent.
14.2.4
Solution Procedure
Theorem 14.2.4 provides a simple expression of the cost that the relaxed problem,
Problem P R
LP , assigns to any given fractional path ﬂows, and thus it allows for
the eﬃcient computation of the impact of modifying the ﬂow in a particular path.
This is the key to the algorithm developed in this section. Indeed, the algorithm
transforms an optimal fractional solution to the linear program P R
LP into an integer
solution by modifying path ﬂows, choosing for each commodity the path that leads
to the lowest increase in the objective of the linear program.
The Linear Programming-Based Heuristic:
Step 1: Solve the linear program, Problem P R
LP . Initialize k = 1.
Step 2: For each arc, compute a marginal cost, which is the increase in cost
incurred in the ﬁxed-ﬂow subproblem by augmenting the fractional ﬂow of
commodity k to 1. Note that this is easy to compute using Theorem 14.2.4.
Step 3: Determine a path for commodity k by ﬁnding the minimum-cost path on
the expanded network with edge costs equal to the marginal costs.
Step 4: Update the ﬂows and the costs on each link (again employing Theo-
rem 14.2.4) to account for commodity k being sent along that path.

272
14. Supply Chain Planning Models
Step 5: Let k = k + 1, and repeat steps (2)–(5) until k = K + 1.
Evidently, the eﬀectiveness of this heuristic depends on the tightness of the linear
programming relaxation of Problem P. For this reason, we study the diﬀerence
between integer and fractional solutions to Problem P. Chan et al. (1999), show
that in some special cases an integer solution can be constructed from the optimal
fractional solution of Problem P R
LP without increasing its cost. In particular, using
Theorem 14.2.4, they prove the following result.
Theorem 14.2.5 In the following cases:
1. single period, multiple suppliers, multiple retailers, two warehouses,
2. two periods, single supplier, multiple retailers, single warehouse,
3. two periods, multiple supplier, multiple retailers, single warehouse using a
cross-docking strategy,
4. multiple periods, single supplier, single retailer, single warehouse that uses a
cross-docking strategy,
the solution to the linear programming relaxation of Problem P is the optimal
solution to the shipper problem. That is,
Z∗= ZLP.
Furthermore, in the ﬁrst three cases, all extreme point solutions to the linear pro-
gram are integer.
The cross-docking strategy referred to in the last two cases is a strategy in
which the stores are supplied by central warehouses that do not keep any stock
themselves. That is, in this strategy, the warehouses act as coordinators of the
supply process and as transshipment points for incoming orders from outside ven-
dors.
The theorem thus demonstrates the exceptional performance of the linear pro-
gramming relaxation, and consequently of the heuristic, in some special cases. A
natural question at this point is whether these results can be generalized. The
answer is no in general. To show this, Chan et al. (1999) construct examples with
a single supplier, a single warehouse, and multiple retailers and time periods, for
which
Z∗
ZLP →∞,
as the number of retailers and time periods increases.
Lemma 14.2.6 The linear programming relaxation of Problem P can be arbitrar-
ily weak, even for a single-supplier, single-warehouse, multiretailer case in which
demand for the retailers is constant over time.

14.2 The Shipper Problem
273
It is important to point out that the instances in which the heuristic solution is
found to be arbitrarily bad are characterized by the unrealistic structure of the
shipping cost. In these instances, the shipping cost between two facilities is a pure
ﬁxed charge (regardless of quantity shipped) in some periods, linear (with no ﬁxed
charges) in others, and yet prohibitively expensive so that nothing can be shipped
in the remaining periods. The following examples illustrate this structure.
Example of weak linear programming solution: Consider a three-period,
single-warehouse model in which a single supplier delivers goods to a warehouse
that, in turn, replenishes inventory of three retailers over time. The warehouse
uses a cross-docking strategy; thus, it does not keep any inventory. Let the trans-
portation cost be a ﬁxed charge of 100 for any shipment from the supplier to
the warehouse at any period. Transportation from the warehouse to retailer i,
i = 1, 2, 3, is very large for shipments made in period i (in other words, retailer
i cannot be reached in period i) and negligible for periods j ̸= i. Let the inven-
tory cost be negligible for all retailers at all periods, and let the demand for each
retailer be 0 units in periods 1 and 2 and 100 units in period 3.
Observe that in order to reach the three retailers, shipments need to be made in
at least two diﬀerent periods. Thus, the optimal integer solution is 200. However,
in the solution to the linear program, 50 units are sent to each of the “reachable”
retailers in each period, and a transportation cost of 50 is charged at each period
(as stated in Theorem 14.2.4, since only a fraction of 1/2 of the commodities is
sent on any edge, exactly that fraction of the ﬁxed cost is charged). Thus, the
optimal fractional solution is 150 and the ratio of integer to fractional solutions is
3/2.
In this instance, even if fractional and integer solutions are diﬀerent, the lin-
ear programming-based heuristic generates the optimal integer solution. However,
we can easily extend the above scenario to instances for which the diﬀerence be-
tween the solution generated by the heuristic and the optimal integer solution is
arbitrarily large.
Example of weak heuristic solution: For that purpose, we add n new periods
to the above setting. In period 4, the ﬁrst of the new periods, the cost for shipping
from supplier to warehouse is linear at a rate of 1/3, and the cost for shipping from
the warehouse to each of the three retailers is 0. In all the other n −1 periods, the
cost of shipping is very high, and thus no shipments will be made after period 4.
Inventory costs at all retailers and all periods are negligible. Demand for each of
the three retailers at each of the new n periods is 100, while demand during the
ﬁrst three periods is 0. It is easy to see that the optimal integer and fractional
solutions are identical to those in the three-period case, with costs of 200 and
150, respectively. However, the heuristic algorithm will always choose to ship each
commodity in period 4, since the increase in cost in the corresponding path would
be 1/3 × 100, while it is at least 50 in any of the ﬁrst three periods. Thus, the
total cost of the heuristic solution is 1/3 × 100 × n and the gap with the optimal
integer solution arbitrarily large.

274
14. Supply Chain Planning Models
The following section reports the performance of the algorithm on a set of ran-
domly generated instances.
14.2.5
Computational Results
The computational tests carried out are divided into three categories:
1. single-period layered networks,
2. general networks,
3. multiperiod, single-warehouse distribution problems:
• pure distribution instances.
• production/distribution instances.
The ﬁrst two categories are of special interest because they allow us to compare
our results with those reported by Balakrishnan and Graves (1989), henceforth
B&G. The third set of problems models practical situations in which each of the
retailers is assigned to a single warehouse and production and transportation costs
have to be balanced with inventory costs over time.
In the three categories, the tests were run on a Sun SPARC20 and CPLEX was
used to solve the linear program, Problem P R
LP , using an equivalent formulation
where path ﬂow variables are replaced by ﬂow-balance constraints. During our
computational work, we observed that the dual simplex method is more eﬃcient
than the primal simplex method in solving these highly degenerate problems, an
observation also made by Melkote (1996). This is usually the case for programs
with variable upper-bound constraints, such as our constraints zr
ek ≤wkxr
e. We
should also point out that most of the CPU time reported in our tests is used in
solving the linear program. Thus, to enhance the computational performance of our
algorithm and increase the size of the problems that it is capable of handling, we see
the need for future research to focus on eﬃciently solving the linear program. For
instance, the original set-partitioning formulation, Problem P R
LP , could be solved
faster using column-generation techniques. In these tests, however, we focused on
evaluating the quality of the integer solutions provided by the heuristic and the
tightness of the linear programming relaxation.
We now discuss each class of problems and the eﬀectiveness of our algorithm.
Single-Period Layered Networks
B&G present exceptional computational results for single-period layered networks.
In these instances, commodities ﬂow from the manufacturing facilities to distribu-
tion centers, where they are consolidated with other shipments. These shipments
are then sent to a number of warehouses, where they are split and shipped to their
ﬁnal destinations. Thus, every commodity must go through two layers of interme-
diate points: consolidation points, also referred to as distribution centers, and
breakbulk points, or warehouses.

14.2 The Shipper Problem
275
TABLE 14.1. Test problems generated as in Balakrishnan and Graves
Number of
Problem class
nodes
LTL1
LTL2
LTL3
LTL4
LTL5
Source
4
5
6
8
10
Consolidn
5
10
12
15
20
Breakbulk
5
10
12
15
20
Destn
4
5
6
8
10
Arcs
42–47
131–141
190–207
309–312
358–372
Commodities
10
20
30
50
60
TABLE 14.2. Computational results for layered networks. Balakrishnan and Graves’ re-
sults (B&G) vs. those of our linear programming-based heuristic (LPBH)
B&G
LPBH
Problem
LB/UB
LP/heuristic
Avg. CPU time
class
percentage
percentage
in seconds
LTL1
99.8
100
1.04
LTL2
100
100
7.94
LTL3
99.6
100
20.74
LTL4
99.1
100
55.72
LTL5
99.5
100
100.48
To test the performance of our algorithm and to compare it with that of B&G,
we generated instances of the layered networks following the details given in their
paper. In this computational work, we considered ﬁve diﬀerent problem classes,
referred to as LTL1–LTL5.
Table 14.1 shows the sizes of the diﬀerent classes of problems. For each of these
classes, the ﬁrst column (B&G) of Table 14.2 presents the average ratio between
the upper bounds generated by the heuristic proposed by B&G and a lower bound
on the optimal solution, over ﬁve randomly generated instances. The numbers
are taken from their paper. We do not include, though, their average CPU times
because the machines they use are completely diﬀerent than ours and, in addition,
they do not report the total computational time for the entire algorithm. The
second and third columns report the average deviation from optimality and the
computational performance of the linear programming-based heuristic (LPBH)
over 10 random instances, for each of the problem classes. In all of them, our
algorithm ﬁnds the optimal integer solution; furthermore, the solution to the
linear program in the ﬁrst step of our algorithm is integer, providing the optimal
solution to the problem.
Of course, since in all previous instances, the linear program provided the opti-
mal integer solution, the performance of our procedure has not really been tested.
In the following subsections, we present computational results for problem classes
in which the solution to the linear program is not always integer.

276
14. Supply Chain Planning Models
TABLE 14.3. Computational results for general networks. Balakrishnan and Graves’
results (B&G) vs. those of our linear programming-based heuristic (LPBH)
Size
B&G
LPBH
Problem No. of
No. of
No. of
LB/UB
LP/Heuristic Avg. CPU time
class
nodes
arcs
comm. percentage
percentage
in seconds
GEN1
10
47–54
10
99.9
100
2.18
GEN2
15
109–136
20
98.7
99.53
24.04
GEN3
20
196–235
30
98.4
99.88
139.83
GEN4
30
364–428
50
96.2
98.59
1313.06
GEN5
40
340–370
60
98.5
99.98
159.57
General Networks
In this subsection, we report on the performance of our algorithm on general
networks, in which every node can be an origin and/or a destination, generated
exactly as they are generated by B&G. These results, together with those of B&G,
are reported in Table 14.3. In this category, B&G consider ﬁve diﬀerent problem
classes, referred to as GEN1,. . ., GEN5, and generate ﬁve random instances for
each of them. We, in turn, solve 10 diﬀerent randomly generated instances for each
of the problem classes. Again, we do not include their average CPU times due to
the reasons mentioned above.
Multiperiod, Single-Warehouse Distribution Problems
Here we consider a single-warehouse model where a set of suppliers replenishes
the inventory of a number of retailers over time. We test two diﬀerent types of in-
stances: pure distribution instances in which the routing and timing of shipments
are to be determined, and production/distribution instances in which the produc-
tion schedule is also integrated with the transportation and inventory decisions.
A. Pure Distribution Instances
We assume that shortages are not allowed and analyze three diﬀerent strategies:
1. Classical inventory/distribution strategy: Material always ﬂows from the sup-
pliers through a single warehouse, where it can be held as inventory.
2. Cross-docking strategy: All material ﬂows through the warehouse, where ship-
ments are reallocated and immediately sent to the retailers.
3. A distribution strategy that allows for direct shipments: Items may be sent
either through the warehouse or directly to the retailer. The warehouse may
keep inventory.
For each strategy, we analyze diﬀerent situations where the number of suppliers
is either 1, 2, or 5, the number of retailers is 10, 12, or 20, and the number of periods
is 8 or 12. For each combination of the number of suppliers, retailers, and periods
presented in Table 14.6, 10 instances are generated. The retailers and suppliers
are randomly located on a 1000 × 1000 grid, while the warehouse is randomly

14.2 The Shipper Problem
277
TABLE 14.4. Linear and setup costs used for all the test problems
Type of arc
α1
e
α2
e
α3
e
Setup
Supplier–whs.
0.15
0.105
0.084
25
Whs.–retailer
0.25
0.20
0.16
10
TABLE 14.5. Inventory costs and diﬀerent ranges for the diﬀerent test problems
Problem
Inventory cost
Supplier–whs. cost Whs.–retailer cost
Class
Warehouse Retailer Range 1
Range 2
Range 1 Range 2
I1
200
400
I2
5
10
800
1500
300
600
I3
300
600
I4
150
300
I5
10
20
1000
2000
200
400
I6
200
400
C1
200
400
C2
10
20
800
1500
300
600
C3
300
600
C4
150
300
C5
10
20
1000
2000
200
400
C6
200
400
D1
150
300
D2
10
20
500
1000
200
400
D3
200
400
assigned to the 400 × 400 subgrid at the center. Demand is generated for each
retailer–supplier pair at each time period, except for the cases with ﬁve suppliers,
in which each of these pairs has an associated demand with probability 1/3. These
demands are generated from a uniform distribution on the integers in the interval
[0, 100).
All suppliers and retailers are linked to the warehouse, and the distance associ-
ated is the corresponding Euclidean distance between the nodes of the grid. In the
case of a distribution strategy that allows for direct shipments, shipping edges from
each of the suppliers to each of the retailers are added. The holding costs per unit
of inventory are diﬀerent at the warehouses and retailer facilities and are presented
in Table 14.5. All holding costs at the suppliers are set to zero. Two shipping cost
functions, representing the cost per item per unit distance, are considered: The
ﬁrst is assigned to shipments from the suppliers to the warehouse. The second
is incurred by the material ﬂowing from the warehouse to the retailers. The cost
function (dollars per mile per unit) associated with direct shipments is equal to
that of shipments from the warehouse to a retailer. Both functions have an ini-
tial setup cost for using the link and three diﬀerent linear rates depending on the
quantity shipped; see Table 14.4. However, the ranges to which those linear costs

278
14. Supply Chain Planning Models
TABLE 14.6. Computational results for a single warehouse
Problem Number of Number of Number of LP/heuristic CPU time
Strategy
class
suppliers
stores
periods
percentage in seconds
I1
1
100
65.21
Classical
I2
2
10
12
100
187.37
inventory/
I3
5
100
163.23
distribution
I4
1
99.946
83.5
strategy
I5
2
20
8
100
210.51
I6
5
99.953
200.68
C1
1
100
60.0
C2
2
10
12
100
174.13
Cross-
C3
5
100
159.06
docking
strategy
C4
1
100
79.73
C5
2
20
8
100
202.83
C6
5
100
186.0
Direct
D1
1
100
51.23
shipments
D2
2
12
8
100
165.83
allowed
D3
5
99.921
117.27
correspond are diﬀerent for the diﬀerent problem classes. This is done so that, in
an optimal solution, shipments are consolidated, and thus the concave cost func-
tion plays an important role in the analysis. These ranges and the corresponding
problem classes are presented in Table 14.5.
Observe (see Table 14.6) that in most of the instances tested, the linear program
is tight and it provides the optimal integer solution. In only three of the 150
instances generated is the solution to the linear program not integer; in such cases,
our algorithm ﬁnds a solution that is within 0.8 % from the optimal fractional
solution.
B. Production/Distribution Instances
This section demonstrates the eﬀectiveness of the algorithm when applied to pro-
duction/distribution systems, that is, systems in which one needs to coordinate
production planning, inventory control, and transportation strategies over time.
For that purpose, we consider the same set of problems, I1–I3, as in the classical
inventory/distribution strategy described in the previous section, and add produc-
tion decisions at each of the supplier sites. This is incorporated into the model, as
explained in Sect. 14.2.
We consider a ﬁxed setup cost for producing at any period plus a certain cost
per unit. The setup cost is varied in the set {50, 100, 500, 1000}, and the linear
production cost is set to 1. The inventory holding rate at the supplier site (after
production) is set to half of that at the warehouse. For the 60 diﬀerent instances
generated, the linear programming relaxation gave an integer solution every time.

14.3 Safety Stock Optimization
279
14.3
Safety Stock Optimization
As observed earlier, the shipper model analyzed earlier is deterministic; safety
stocks are determined exogenously and incorporated into the minimum inventory
level that should be maintained at the beginning of each period. The objective of
this section is to present a model for positioning and optimizing safety stock in
the supply chain.
For this purpose, consider a single-product, single-facility, periodic-review in-
ventory model. Let SI be the amount of time it takes from placing an order until
the facility receives a shipment; this time is referred to as the incoming service
time. Let S be the committed service time made by the facility to its own
customers, and let T be the processing time at the facility. Of course, we must
assume that SI + T > S; otherwise, no inventory is needed in the facility.
We assume that the facility manages its inventory following a periodic review
policy and that demand is independent and identically distributed across time
periods following a normal distribution. Given deterministic SI, S, and T , and
with no setup costs, the level of safety stock that the facility needs to keep (see
Exercise 14.1) is equal to
zh
√
SI + T −S,
where z is the safety stock factor associated with a speciﬁed level of service and
h is the inventory holding cost. The value SI + T −S is referred to as the facility
net lead time.
To understand our model, consider the following two-stage supply chain with
facility 2 feeding facility 1, which serves the end customer (Fig. 14.3). Deﬁne SIi,
Si, and Ti as before for i = 1, 2. Thus, S1 is the committed service time to the
end customer, S2 is the commitment that facility 2 makes to facility 1, and hence
S2 = SI1. Finally, SI2 is the supplier commitment to facility 2.
Our objective is to minimize the total supply chain cost without aﬀecting, or
pushing, inventory to the supplier. Observe that if we reduce S2 = SI1, we will
aﬀect inventory at both facility 1 and facility 2. Indeed, by reducing the committed
service time that facility 2 makes to facility 1, inventory at facility 1 is reduced,
but inventory at the second facility is increased. Thus, our objective is to develop a
model that selects the appropriate level of commitment that one facility makes to
its downstream facility so as to minimize the total, or more precisely, systemwide
safety stock cost.
IS2
T1
S1
S2=IS1
stage 2
stage 1
T2
customers
FIGURE 14.3. Illustration of the model

280
14. Supply Chain Planning Models
For this purpose, consider a supply network G(N, A), which is acyclic, with N
facilities and where A is the set of edges. Let D ⊂N be the set of customers, or
demand points, with Sj being an upper bound on the commitment to be made to
customer j, j ∈D.
Following our discussion, we formulate the problem of setting commitments and
safety stock levels as the following nonlinear optimization problem.
Problem SS :
Min
N

j=1
zjhjΦ(Xj)
s.t.
Xj = SIj + Tj −Sj,
∀j = 1, . . . , N,
(14.12)
Xj ≥0,
∀j = 1, . . . , N,
(14.13)
SIj −Si ≥0,
∀(i, j) ∈A,
(14.14)
Sj ≤Sj,
∀j ∈D,
(14.15)
Sj, SIj ≥0,
∀j = 1, . . . , N,
(14.16)
where Φ(Xj) = Xj.
Observe that in this formulation, there are two sets of decision variables. The
ﬁrst is Sj, the commitment made by facility j to all its downstream facilities. The
second is the implied incoming service time to facility j. This incoming service
time is the maximum of the committed service time of all the upstream facilities
feeding facility j.
Thus, constraint (14.12) deﬁnes the net lead time at facility j. Constraint (14.14)
forces the incoming service time for facility j to be no smaller than the commitment
that each facility i with (i, j) ∈A makes to facility j. Finally, constraint (14.15)
forces the commitment to the end customer to be no larger than the target.
Of course, the challenge is to solve this formulation eﬀectively. Graves and
Willems (2000) propose a dynamic programming algorithm, while Magnanti et al.
(2003)
develop an eﬃcient algorithm based on a similar approach to what is
described earlier for the shipper problem.
14.4
Exercises
Exercise 14.1. Consider a single-product, single-facility, inﬁnite-horizon, periodic-
review model. Assume that the inventory is managed based on a stationary base
stock policy and unsatisﬁed demand is backlogged. At each period, demand arrives
according to a normal distribution N(μ, σ). (Let’s assume that the probability of
having negative demand is negligible.) Let SI be the incoming service time, S be
the committed service time, and T be the processing time at the facility. Finally,
assume that the initial inventory level equals the base stock level and assume the
service level is α, which is deﬁned as the probability that the demand can be

14.4 Exercises
281
fully satisﬁed from current on-hand inventories. Show that the base stock level is
(SI +T −S)μ+Ψ−1(α)
√
SI + T −Sσ, where Ψ−1 is the inverse of the cumulative
distribution function of the standard normal distribution.
Exercise 14.2. Assume, in Problem SS of Sect. 14.3, that the supply network
reduces to a serial supply chain. Show that Si = 0 or Si = Si+1 + Ti, where
stage i+ 1 serves stage i. Based on this observation, propose an algorithm to solve
Problem SS.

15
Facility Location Models
15.1
Introduction
One of the most important aspects of logistics is deciding where to locate new
facilities such as retailers, warehouses, or factories. These strategic decisions are a
crucial determinant of whether materials will ﬂow eﬃciently through the distribu-
tion system.
In this chapter, we consider several important warehouse location problems: the
p -median problem; the single-source capacitated facility location problem; and a
distribution system design problem. In each case, the problem is to locate a set
of warehouses in a distribution network. We assume that the cost of locating a
warehouse at a particular site includes a ﬁxed cost (e.g., building costs, rental
costs, etc.) and a variable cost for transportation. This variable cost includes the
cost of transporting the product to the retailers as well as possibly the cost of
moving the product from the plants to the warehouse. In general, the objective is
to locate a set of facilities so that the total cost is minimized subject to a variety
of constraints, which might include
• Each warehouse has a capacity, which limits the area it can supply.
• Each retailer receives shipments from one and only one warehouse.
• Each retailer must be within a ﬁxed distance of the warehouse that supplies
it, so that a reasonable delivery lead time is ensured.
D. Simchi-Levi et al., The Logic of Logistics: Theory, Algorithms, and Applications
for Logistics Management, Springer Series in Operations Research and Financial Engineering,
DOI 10.1007/978-1-4614-9149-1 15, © Springer Science+Business Media New York 2014
283

284
15. Facility Location Models
Location analysis has played a central role in the development of the operations
research ﬁeld. In this area lie some of the discipline’s most elegant results and
theories. We note here the paper of Cornu´ejols et al. (1977) and the two excel-
lent books devoted to the subject by Mirchandani and Francis (1990) and Daskin
(1995). Location problems encompass a wide range of problems such as the loca-
tion of emergency services (ﬁrehouses or ambulances), the location of hazardous
materials, and problems in telecommunications network design, just to name a
few.
In the next section, we present an exact algorithm for one of the simplest location
problems, the p -median problem. We then generalize this model and algorithm to
incorporate additional factors important to the design of the distribution network,
such as warehouse capacities and ﬁxed costs. In Sect. 15.4, we present a more
general model where all levels of the distribution system (plants and retailers)
are taken into account when deciding warehouse locations. We also present an
eﬃcient algorithm for its solution. All of the algorithms developed in this chapter
are based on the Lagrangian relaxation technique described in Sect. 6.3, which
has been applied successfully to a wide range of location problems. Finally, in
Sect. 15.5, we describe the structure of the optimal solution to problems in the
design of large-scale logistics systems.
15.2
An Algorithm for the p -Median Problem
Consider a set of retailers geographically dispersed in a region. The problem is to
choose where in the region to locate a set of p identical warehouses. We assume
there are m ≥p sites that have been preselected as possible locations for these
warehouses. Once the p warehouses have been located, each of n retailers will get
its shipments from the warehouse closest to it. We assume the following:
• There is no ﬁxed cost for locating at a particular site.
• There is no capacity constraint on the demand supplied by a warehouse.
Note that the ﬁrst assumption also encompasses the case where the ﬁxed cost is
not site-dependent, and therefore the ﬁxed setup cost for locating p warehouses is
independent of where they are located.
Let the set of retailers be N, where N = {1, 2, . . ., n}, and let the set of potential
sites for warehouses be M, where M = {1, 2, . . ., m}. Let wi be the demand or
ﬂow between retailer i and its warehouse for each i ∈N. We assume that the cost
of transporting the wi units of product from warehouse j to retailer i is cij, for
each i ∈N and j ∈M.
The problem is to choose p of the m sites where a warehouse will be located in
such a way that the total transportation cost is minimized. This is the p -median
problem.
The continuous version of this problem, where any point is a potential warehouse
location, was ﬁrst treated as early as 1909 by Weber. The discrete version was
analyzed by Kuehn and Hamburger (1963) as well as Hakimi (1964), Manne (1964),
Balinski (1965), and many others.

15.2 An Algorithm for the p -Median Problem
285
We present here a highly eﬀective approach to the problem. Deﬁne the following
decision variables:
Yj =
 1,
if a warehouse is located at site j,
0,
otherwise,
for j ∈M, and
Xij =
 1,
if retailer i is served by a warehouse at site j,
0,
otherwise,
for i ∈N and j ∈M. The p -median problem is then
Problem P : Min
n

i=1
m

j=1
cijXij
s.t.
m

j=1
Xij = 1,
∀i ∈N,
(15.1)
m

j=1
Yj = p,
(15.2)
Xij ≤Yj,
∀i ∈N, j ∈M,
(15.3)
Xij, Yj ∈{0, 1},
∀i ∈N, j ∈M.
(15.4)
Constraints (15.1) guarantee that each retailer is assigned to a warehouse. Con-
straint (15.2) ensures that p sites are chosen. Constraints (15.3) guarantee that a
retailer selects a site only from among those that are chosen. Constraints (15.4)
force the variables to be integer.
This formulation can easily handle several side constraints. If a handling fee is
charged for each unit of product going through a warehouse, these costs can be
added to the transportation cost along all arcs leaving the warehouse. Also, if a
particular limit is placed on the length of any arc between retailer i and warehouse
j, this can be incorporated by simply setting the per-unit shipping cost (cij) to
+∞. In addition, the model can be easily extended to cases where a set of facilities
is already in place and the choice is whether to open new facilities or expand the
existing facilities.
Let Z∗be an optimal solution to Problem P. One simple and eﬀective technique
to solve this problem is the method of Lagrangian relaxation described in Sect. 6.3.
As described in Sect. 6.3, Lagrangian relaxation involves relaxing a set of con-
straints and introducing them into the objective function with a multiplier vector.
This provides a lower bound on the optimal solution to the overall problem. Then,
using a subgradient search method, we iteratively update our multiplier vector in
an attempt to increase the lower bound. At each step of the subgradient procedure
(i.e., for each set of multipliers), we also attempt to construct a feasible solution
to the location problem. This step usually consists of a simple and eﬃcient sub-
routine. After a prespeciﬁed number of iterations, or when the solution found is
within a ﬁxed error tolerance of the lower bound, the algorithm is terminated.

286
15. Facility Location Models
To solve the p -median problem, we choose to relax constraints (15.1). We in-
corporate these constraints in the objective function with the multiplier vector
λ ∈IRn. The resulting problem, call it Pλ, with optimal objective function value
Zλ, is
Min
n

i=1
m

j=1
cijXij +
n

i=1
λi
 m

j=1
Xij −1

subject to (15.2) −(15.4).
Disregarding constraint (15.2) for now, the problem decomposes by site; that is,
each site can be considered separately. Let Subproblem P j
λ, with optimal objective
function value Zj
λ, be the following:
Min
n

i=1
(cij + λi)Xij
s.t. Xij ≤Yj,
∀i ∈N,
Xij ∈{0, 1},
∀i ∈N,
Yj ∈{0, 1}.
Solving Subproblem P j
λ
Assume λ is ﬁxed. In Problem P j
λ, site j is either selected (Yj = 1) or not
(Yj = 0). If site j is not selected, then Xij = 0 for all i ∈N, and therefore,
Zj
λ = 0. If site j is selected, then we set Yj = 1 and assign exactly those retailers
i with cij + λi < 0 to site j. In this case:
Zj
λ =
n

i=1
min{cij + λi, 0}.
(15.5)
We see that P j
λ is solved easily and its optimal objective function value is given
by (15.5).
To solve Pλ, we must now reintroduce constraint (15.2). This constraint forces
us to choose only p of the m sites. In Pλ, we can incorporate this constraint by
choosing the p sites with smallest values Zj
λ. To do this, let π be a permutation of
the numbers 1, 2, . . ., m such that
Zπ(1)
λ
≤Zπ(2)
λ
≤Zπ(3)
λ
≤· · · ≤Zπ(m)
λ
.
Then the optimal solution to Pλ has the objective function value:
Zλ .=
p

j=1
Zπ(j)
λ
−
n

j=1
λj.

15.3 An Algorithm for the Single-Source Capacitated Facility Location Problem
287
The value Zλ is a lower bound on the optimal solution of Problem P for any
vector λ ∈IRn. To ﬁnd the best such lower bound, we consider the Lagrangian
dual:
max
λ {Zλ}.
Using the subgradient procedure (described in Sect. 6.3), we can iteratively im-
prove this bound.
Upper Bounds
It is crucial to construct good upper bounds on the optimal solution value as the
subgradient procedure advances. Clearly, solutions to Pλ will not necessarily be
feasible to Problem P. This is due to the fact that the constraints (15.1) (that each
retailer choose one and only one warehouse) may not be satisﬁed. The solution to
Pλ may have facilities choosing a number of sites. If, in the solution to Pλ, each
retailer chooses only one site, then this must be the optimal solution to P, and
therefore, we stop. Otherwise, there are retailers that are assigned to several or
no sites. A simple heuristic can be implemented that ﬁxes those retailers that are
assigned to only one site and assigns the remaining retailers to these and other
sites by choosing the next site to open in the ordering deﬁned by π. When p sites
have been selected, we can do a simple check that each retailer is assigned to its
closest site (of those selected); doing so can further improve the solution.
Computational Results
Below we give a table listing results of various computational experiments
(Table 15.1). The retailer locations were chosen uniformly over the unit square.
For simplicity, we made each retailer location a potential site for a warehouse;
thus, m = n. The cost of assigning a retailer to a site was the Euclidean dis-
tance between the two locations. The values of wi were chosen uniformly over the
unit interval. We applied the algorithm mentioned above to many problems and
recorded the relative error of the best solution found and the computational time
required. The algorithm is terminated when the relative error is below 1% or when
a prespeciﬁed number of iterations is reached. The numbers below “Error” are the
relative errors averaged over 10 randomly generated problem instances. The num-
bers below “CPU time” is the CPU time averaged over the 10 problem instances.
All computational times are on an IBM RISC 6000 Model 950.
15.3
An Algorithm for the Single-Source Capacitated
Facility Location Problem
Consider the p -median problem, where we make the following two changes in our
assumptions:
• The number of warehouses to locate (p) is not ﬁxed beforehand.

288
15. Facility Location Models
TABLE 15.1. Computational results for the p -median algorithm
n
p
Error
CPU time
10
3
0.3%
0.2 s
20
4
1.7%
2.6 s
50
5
1.4%
20.7 s
100
7
1.3%
87.7 s
200
10
2.4%
715.4 s
• If a warehouse is located at site j:
◦A ﬁxed cost fj is incurred, and
◦There is a capacity qj on the amount of demand it can serve.
The problem is to decide where to locate the warehouses and then how the retailers
should be assigned to the open warehouses in such a way that the total cost is
minimized. We see that the problem is considerably more complicated than the
p -median problem. We now have capacity constraints on the warehouses, and
therefore a retailer will not always be assigned to its nearest warehouse. Allowing
the optimization to choose the appropriate number of warehouses also adds to the
level of diﬃculty.
This problem is called the single-source capacitated facility location problem
(CFLP), or sometimes the capacitated concentrator location problem (CCLP).
This problem was successfully used in Chap. 17 as a framework for solving the
capacitated vehicle routing problem.
Using the same decision variables as in the p -median problem, we formulate the
single-source CFLP as the following integer linear program:
Min
n

i=1
m

j=1
cijXij +
m

j=1
fjYj
s.t.
m

j=1
Xij = 1,
∀i ∈N,
(15.6)
n

i=1
wiXij ≤qjYj,
∀j ∈M,
(15.7)
Xij, Yj ∈{0, 1},
∀i ∈N, j ∈M.
(15.8)
Constraints (15.6) (along with the integrality conditions (15.8)) ensure that each
retailer is assigned to exactly one warehouse. Constraints (15.7) ensure that the
warehouse’s capacity is not exceeded and also that if a warehouse is not located
at site j, no retailer can be assigned to that site.
Let Z∗be the optimal solution value of single-source CFLP. Note we have re-
stricted the assignment variables (X) to be integer. A related problem, where this
assumption is relaxed, is simply called the (multiple-source) capacitated facility
location problem. In that version, a retailer’s demand can be split between any

15.3 An Algorithm for the Single-Source Capacitated Facility Location Problem
289
number of warehouses. In the single-source CFLP, it is required that each retailer
have only one warehouse supplying it. In many logistics applications, this is a
realistic assumption since without this restriction, optimal solutions might have
a retailer receive many deliveries of the same product (each for, conceivably, a
very small amount of the product). Clearly, from a managerial, marketing, and
accounting point of view, restricting deliveries to come from only one warehouse
is a more appropriate delivery strategy.
Several algorithms have been proposed to solve the CFLP in the literature; all
are based on the Lagrangian relaxation technique. This includes Neebe and Rao
(1983), Barcelo and Casanovas (1984), Klincewicz and Luss (1986), and Pirkul
(1987). The one we derive here is similar to Pirkul’s algorithm, which seems to be
the most eﬀective.
We apply the Lagrangian relaxation technique by including constraints (15.6)
in the objective function. For any λ ∈IRn, consider the following problem Pλ:
Min
n

i=1
m

j=1
cijXij +
m

j=1
fjYj +
n

i=1
λi
 m

j=1
Xij −1

subject to (15.7) −(15.8).
Let Zλ be its optimal solution and note that
Zλ ≤Z∗, ∀λ ∈IRn.
To solve Pλ, as in the p -median problem, we separate the problem by site. For a
given j ∈M, deﬁne the following problem P j
λ, with the optimal objective function
value Zj
λ:
Min
n

i=1
(cij + λi)Xij + fjYj
s.t.
n

i=1
wiXij ≤qjYj,
Xij ∈{0, 1},
∀i ∈N,
Yj ∈{0, 1}.
Solving P j
λ
Problem P j
λ can be solved eﬃciently. In the optimal solution to P j
λ, Yj is either
0 or 1. If Yj = 0, then Xij = 0 for all i ∈N. If Yj = 1, then the problem is no
more diﬃcult than a single constraint 0–1 knapsack problem, for which eﬃcient
algorithms exist; see, for example, Nauss (1976). If the optimal knapsack solution
is less than −fj, then the corresponding optimal solution to Pj
λ is found by setting
Yj = 1 and Xij according to the knapsack solution, indicating whether retailer i

290
15. Facility Location Models
is assigned to site j. If the optimal knapsack solution is more than −fj, then the
optimal solution to P j
λ is found by setting Yj = 0 and Xij = 0 for all i ∈N.
The solution to Pλ is then given by
Zλ .=
m

j=1
Zj
λ −
n

i=1
λi.
For any vector λ ∈IRn, this is a lower bound on the optimal solution Z∗. In order
to ﬁnd the best such lower bound, we use a subgradient procedure.
Note that if the problem has a constraint on the number of warehouses (facilities)
that can be opened (chosen), this can be handled in essentially the same way as
it was handled in the algorithm for the p -median problem.
Upper Bounds
For a given set of multipliers, if the values {X} satisfy (15.6), then we have
an optimal solution to Problem P, and we stop. Otherwise, we perform a simple
subroutine to ﬁnd a feasible solution to P. The procedure is based on the observa-
tion that the knapsack solutions found when solving Pλ give us some information
concerning the beneﬁt of setting up a warehouse at a site (relative to the current
vector λ). If, for example, the knapsack solution corresponding to a given site is
0, that is, the optimal knapsack is empty, then this is most likely not a “good”
site to select at this time. In contrast, if the knapsack solution has a very negative
cost, then this is a “good” site. Given the values Zj
λ for each j ∈M, let π be a
permutation of 1, 2, . . ., m such that
Zπ(1)
λ
≤Zπ(2)
λ
≤· · · ≤Zπ(m)
λ
.
The procedure we perform allocates retailers to sites in a myopic fashion. Let
M be the minimum possible number of warehouses used in the optimal solution
to CFLP. This can be found by solving the bin-packing problem deﬁned on the
values wi with bin capacities Qj; see Sect. 4.2. Starting with the “best” site, in
this case site π(1), assign the retailers in its optimal knapsack to this site. Then,
following the indexing of the knapsack solutions, take the next-“best” site [say site
j .= π(2)] and solve a new knapsack problem: one deﬁned with costs cij .= cij + λi
for each retailer i still unassigned. Assign all retailers in this knapsack solution to
site j. If this optimal knapsack is empty, then a warehouse is not located at that
site, and we go on to the next site. Continue in this manner until M warehouses
are located.
The solution may still not be a feasible solution to P since some retailers may
not be assigned to a site. In this case, unassigned retailers are assigned to sites
that are already chosen, where they ﬁt with minimum additional cost. If needed,
additional warehouses may be opened following the ordering of π. A local im-
provement heuristic can be implemented to improve on this solution, using simple
interchanges between retailers.

15.4 A Distribution System Design Problem
291
Computational Results
We now report on various computational experiments using this algorithm
(Table 15.2). The retailer locations were chosen uniformly over the unit square.
Again, for simplicity, we made each retailer location a potential site for a ware-
house; thus, m = n. The ﬁxed cost of a site was chosen uniformly between 0 and
1. The cost of assigning a retailer to a site was the Euclidean distance between
the two locations. The values of wi were chosen uniformly over the interval 0 to
1
2 with warehouse capacity equal to 1. We applied the algorithm mentioned above
to 10 problems and recorded the average relative error of the best solution found
and the average computation time required. The algorithm is terminated when the
relative error is below 1% or when a prespeciﬁed number of iterations is reached.
The numbers below “Error” are the relative errors averaged over the 10 randomly
generated problem instances. The numbers below “CPU Time” are the CPU time
averaged over the 10 problem instances. All computational times are on an IBM
RISC 6000 Model 950.
TABLE 15.2. Computational results for the single-source CFLP algorithm
n
Error
CPU time
10
1.2%
1.2 s
20
1.0%
8.1 s
50
1.1%
110.0s
100
1.1%
558.3s
15.4
A Distribution System Design Problem
So far, the location models we have considered have been concerned with minimiz-
ing the costs of transporting products between warehouses and retailers. We now
present a more realistic model that considers the cost of transporting the product
from manufacturing facilities to the warehouses as well.
Consider the following warehouse location problem. A set of plants and retailers
are geographically dispersed in a region. Each retailer experiences demands for a
variety of products that are manufactured at the plants. A set of warehouses must
be located in the distribution network from a list of potential sites.
The cost of locating a warehouse includes the transportation cost per unit from
warehouses to retailers but also the transportation cost from plants to warehouses.
In addition, as in the CFLP, there is a site-dependent ﬁxed cost for locating each
warehouse.
The data for the problem are the following:
• L = number of plants; we will also let L = {1, 2, . . ., L};
• J = number of potential warehouse sites; also let J = {1, 2, . . ., J};

292
15. Facility Location Models
• I = number of retailers; also let I = {1, 2, . . ., I};
• K = number of products; also let K = {1, 2, . . ., K};
• W = number of warehouses to locate;
• cℓjk = cost of shipping one unit of product k from plant ℓto
warehouse site j;
• djik = cost of shipping one unit of product k from warehouse
site j to retailer i;
• fj = ﬁxed cost of locating a warehouse at site j;
• vℓk = supply of product k at plant ℓ;
• wik = demand for product k at retailer i;
• sk = volume of one unit of product k;
• qj = capacity (in volume) of a warehouse at site j.
We make the additional assumption that a retailer gets delivery for a product
from one warehouse only. This does not preclude solutions where a retailer gets
shipments from diﬀerent warehouses, but these shipments must be for diﬀerent
products. On the other hand, we assume that the warehouse can receive shipments
from any plant and for any amount of product.
The problem is to determine where to locate the warehouses, how to ship the
product from the plants to the warehouses, and also how to ship the product from
the warehouses to the retailers. This problem is similar to that analyzed by Pirkul
and Jayaraman (1996).
We again use a mathematical programming approach. Deﬁne the following de-
cision variables:
Yj =
 1,
if a warehouse is located at site j,
0,
otherwise,
and
Uℓjk = amount of product k shipped from plant ℓto warehouse j,
for each ℓ∈L, j ∈J, and k ∈K. Also, deﬁne
Xjik =
 1,
if retailer i receives product k from warehouse j,
0,
otherwise,
for each j ∈J, i ∈I, and k ∈K.

15.4 A Distribution System Design Problem
293
Then the distribution system design problem can be formulated as the following
integer program:
Min
L

ℓ=1
J

j=1
K

k=1
cℓjkUℓjk +
I

i=1
J

j=1
K

k=1
djikwikXjik +
J

j=1
fjYj
s.t.
J

j=1
Xjik = 1,
∀i ∈I, k ∈K,
(15.9)
I

i=1
K

k=1
skwikXjik ≤qjYj,
∀j ∈J,
(15.10)
I

i=1
wikXjik =
L

ℓ=1
Uℓjk,
∀j ∈J, k ∈K,
(15.11)
J

j=1
Uℓjk ≤vℓk
∀ℓ∈L, k ∈K,
(15.12)
J

j=1
Yj = W,
(15.13)
Yj, Xjik ∈{0, 1},
∀i ∈I, j ∈J, k ∈K,
(15.14)
Uℓjk ≥0,
∀ℓ∈L, j ∈J, k ∈K.
(15.15)
The objective function measures the transportation costs between plants and ware-
houses, those costs between warehouses and retailers, and also the ﬁxed cost of
locating the warehouses. Constraints (15.9) ensure that each retailer/product pair
is assigned to one warehouse. Constraints (15.10) guarantee that the capacity of
the warehouses is not exceeded. Constraints (15.11) ensure that there is a con-
servation of the ﬂow of products at each warehouse; that is, the amount of each
product arriving at a warehouse from the plants is equal to the amount being
shipped from the warehouse to the retailers. Constraints (15.12) are the supply
constraints. Constraints (15.13) ensure that we locate exactly W warehouses.
The model can handle several extensions, such as a warehouse handling fee or
a limit on the distance of any link used just as in the p -median problem. Another
interesting extension is when there is a ﬁxed number of possible warehouse types
from which to choose. Each type has a speciﬁc cost along with a speciﬁc capacity.
The model can easily be extended to handle this situation (see Exercise 15.1).
As in the previous problems, we will use Lagrangian relaxation. We relax con-
straints (15.9) (with multipliers λik) and constraints (15.11) (with multipliers θjk).
The resulting problem is

294
15. Facility Location Models
Min
L

ℓ=1
J

j=1
K

k=1
cℓjkUℓjk +
J

j=1
I

i=1
K

k=1
djikwikXjik +
J

j=1
fjYj
+
J

j=1
K

k=1
θjk

I

i=1
wikXjik −
L

ℓ=1
Uℓjk

+
I

i=1
K

k=1
λik

1 −
J

j=1
Xjik

,
subject to (15.10), (15.12) −(15.15).
Let Zλ,θ be the optimal solution to this problem. This problem can be decom-
posed into two separate problems P1 and P2:
Problem P1 : Z1 .=Min
L

ℓ=1
J

j=1
K

k=1
[cℓjk −θjk]Uℓjk
s.t.
J

j=1
Uℓjk ≤vℓk, ∀ℓ∈L, k ∈K,
(15.16)
Uℓjk ≥0,
∀ℓ∈L, j ∈J, k ∈K.
Problem P2 : Z2 .=Min
J

j=1
I

i=1
K

k=1
[djikwik −λik + θjkwik]Xjik +
J

j=1
fjYj,
s.t.
I

i=1
K

k=1
skwikXjik ≤qjYj,
∀j ∈J
(15.17)
J

j=1
Yj = P,
(15.18)
Yj, Xjik ∈{0, 1},
∀i ∈I, j ∈J, k ∈K.
Solving P1
Problem P1 can be solved separately for each plant/product pair. In fact, the
objective functions of each of these subproblems can be improved (without loss in
computation time) by adding the constraints
sk
L

ℓ=1
Uℓjk ≤qj,
∀j ∈J, k ∈K.
(15.19)
For each plant/product combination, say plant ℓand product k, sort the J values
cj .= cℓjk −θjk. Starting with the smallest value of cj, say cj′, if cj′ ≥0, then the

15.4 A Distribution System Design Problem
295
solution is to ship none of this product from this plant. If cℓj′k < 0, then ship as
much of this product as possible along arc (ℓ, j′) subject to satisfying constraints
(15.16) and (15.19). Then if the supply vℓk has not been completely shipped, do
the same for the next-cheapest arc, as long as it has negative reduced cost (c).
Continue in this manner until all of the product has been shipped or the reduced
costs are no longer negative. Then proceed to the next plant/product combination,
repeating this procedure. Continue until all the plant/product combinations have
been scanned in this fashion.
Solving P2
Solving Problem P2 is similar to solving the subproblem in the CFLP. For now,
we can ignore constraints (15.18). Then we separate the problem by warehouse. In
the problem corresponding to warehouse j, either Yj = 0 or Yj = 1. If Yj = 0, then
Xjik = 0 for all i ∈N and k ∈K. If Yj = 1, then we get a knapsack problem with
NK items, one for each retailer/product pair. Let Zj
2 be the objective function
value when Yj is set to 1 and the resulting knapsack problem is solved. After
having solved each of these, let π be a permutation of the numbers 1, 2, . . . , J such
that
Zπ(1)
2
≤Zπ(2)
2
≤· · · ≤Zπ(J)
2
.
The optimal solution to P2 is to choose the W smallest values:
Z2 .=
W

j=1
Zπ(j)
2
.
For ﬁxed vectors λ and θ, the lower bound is
Zλ,θ .= Z1 + Z2 +
I

i=1
K

k=1
λik.
To maximize this bound, that is,
max
λ,θ {Zλ,θ},
we again use the subgradient optimization procedure.
Upper Bounds
At each iteration of the subgradient procedure, we attempt to construct a fea-
sible solution to the problem. Consider Problem P2. Its solution may have a re-
tailer/product combination assigned to several warehouses. We determine the set
of retailer/product combinations that are assigned to one and only one retailer and
ﬁx these. Other retailer/product combinations are assigned to warehouses using
the following mechanism. For each retailer/product combination, we determine
the cost of assigning it to a particular warehouse. After determining that this as-
signment is feasible (from a warehouse-capacity point of view), we calculate the

296
15. Facility Location Models
assignment cost as the cost of shipping all of the demand for this retailer/product
combination through the warehouse plus the cost of shipping the demand from the
plants to the warehouse (along one or more arcs from the warehouse to the plants).
For each retailer/product combination, we determine the penalty associated with
assigning the shipment to its second-best warehouse instead of its best warehouse.
We then assign the retailer/product combination with the highest such penalty
and update all arc ﬂows and remaining capacities. We continue in this manner
until all retailer/product combinations have been assigned to warehouses.
Computational results for this problem appear at the end of Chap. 20.
15.5
The Structure of the Asymptotic Optimal Solution
In this section, we describe a region-partitioning scheme to solve large instances
of the CFLP.
Assume there are n retailers located at points {x1, x2, . . . , xn}. Each retailer
also serves as a potential site for a warehouse of ﬁxed capacity q. The ﬁxed cost
of locating a warehouse at a site is assumed to be proportional to the distance the
site is from a manufacturing facility located at x0, which is assumed (without loss
of generality) to be the origin (0, 0). Retailer i has a demand wi, which is assumed
to be less than or equal to q. Without loss of generality, we assume q = 1, and
therefore, wi ∈[0, 1] for each i ∈N. Let α be the per-unit cost of transportation
between warehouses and the manufacturing facility, and let β be the per-unit cost
of transportation between warehouses and retailers.
We assume the retailer locations are independently and identically distributed
in a compact region A ⊂IR2 according to some distribution μ. Assume the retailer
demands are independently and identically distributed according to a probability
measure φ on [0, 1]. The bin-packing constant associated with the distribution φ
(denoted by γφ or simply γ) is the asymptotic number of bins used per item in an
optimal packing of the retailer demands into unit size bins, when items are drawn
randomly from the distribution φ (see Sect. 5.2).
The following theorem shows that if the retailer locations and demand sizes
are random (from a general class of distributions), then as the problem size in-
creases, the optimal solution has a very particular structure. This structure can
be exploited using a region-partitioning scheme, as demonstrated below.
Theorem 15.5.1 Let xk, k = 1, 2, . . . , n, be a sequence of independent random
variables having a distribution μ with compact support in IR2. Let ∥x∥be the Eu-
clidean distance between the manufacturing facility and the point x ∈IR2, and
let
E(d) =

∥x∥dμ(x).

15.6 Exercises
297
Let the demands wk, k = 1, 2, . . . , n, be a sequence of independent random variables
having a distribution φ with bin-packing constant equal to γ. Then, almost surely,
lim
n→∞
1
nZ∗
n = αγE(d).
This analysis demonstrates that simple approaches that consider only the ge-
ography and the packing of the demands can be very eﬃcient on large problem
instances. Asymptotically, this is, in fact, the optimal strategy. This analysis also
demonstrates that, asymptotically, the cost of transportation between retailers and
warehouses becomes a very small fraction (eventually zero) of the total cost.
15.6
Exercises
Exercise 15.1. In the distribution system design problem, explain how the so-
lution methodology changes when there is a ﬁxed number of possible warehouse
capacities. For example, at each site, if we decide to install a warehouse, we can
install a small, medium, or large one.
Exercise 15.2. Prove Theorem 15.5.1.
Exercise 15.3. Show how any instance of the bin-packing problem (see Part I)
can be formulated as an instance of the single-source CFLP.
Exercise 15.4. Consider Problem P1 of Sect. 15.4.
(a) Show that this formulation can be strengthened by adding the constraints:
L

ℓ=1
K

k=1
skUℓjk ≤qj,
∀j ∈J.
(b) Show that this new formulation can be transformed to a specialized kind of
linear program called a transportation problem.
(c) Why might we not want to use this stronger formulation?
Exercise 15.5. (Mirchandani and Francis 1990) Deﬁne the uncapacitated facility
location problem (UFLP) in the following way. Let Fj be the ﬁxed charge of
opening a facility at site j, for j = 1, 2, . . . , m.
Problem UFLP
: Min
n

i=1
m

j=1
cijXij +
m

j=1
FjYj
s.t.
m

j=1
Xij = 1,
∀i ∈N,

298
15. Facility Location Models
Xij ≤Yj,
∀i ∈N, j ∈M,
Xij, Yj ∈{0, 1},
∀i ∈N, j ∈M.
Show that UFLP is NP-Hard by showing that any instance of the NP-Hardnode
cover problem can be formulated as an instance of UFLP. The node cover problem
is deﬁned as follows: Given a graph G and an integer k, does there exist a subset
of k nodes of G that cover all the arcs of G? (Node v is said to cover arc e if v is
an endpoint of e.)
Exercise 15.6. (Mirchandani and Francis 1990) It appears that the p -median
problem can be solved by solving the resulting problem UFLP (see Exercise 15.5)
for diﬀerent values of F = Fj, ∀j, until a value F ∗is found where the UFLP opens
exactly p facilities. Show that this method does not work by giving an instance
of a 2-median problem for which no value of F provides an optimal solution to
UFCLP with two open facilities.

Part IV
Vehicle Routing Models

16
The Capacitated VRP with Equal
Demands
16.1
Introduction
A large part of many logistics systems involves the management of a ﬂeet of vehicles
used to serve warehouses, retailers, and/or customers. In order to control the costs
of operating the ﬂeet, a dispatcher must continuously make decisions on how much
to load on each vehicle and where to send it. These types of problems fall under
the general class of vehicle routing problems mentioned in Chap. 1.
The most basic vehicle routing problem (VRP) is the single-depot capacitated
vehicle routing problem (CVRP). It can be described as follows: A set of customers
has to be served by a ﬂeet of identical vehicles of limited capacity. The vehicles are
initially located at a given depot. The objective is to ﬁnd a set of routes for the
vehicles of minimal total length. Each route begins at the depot, visits a subset of
the customers, and returns to the depot without violating the capacity constraint.
Consider the following scenario. A customer requests w units of product. If we
allow this load to be split between more than one vehicle (i.e., the customer gets
several deliveries, which together sum up to the total load requested), then we can
view the demand for w units as w diﬀerent customers each requesting one unit of
product located at the same point. The capacity constraint can then be viewed
as simply the maximum number of customers (in this new problem) that can be
visited by a single vehicle. This is the capacity Q ≥1. Therefore, if we allow this
splitting of demands, and this may not be a desirable property (we investigate the
unsplit-demand case in Chap. 17), there is no loss in generality in assuming that
D. Simchi-Levi et al., The Logic of Logistics: Theory, Algorithms, and Applications
for Logistics Management, Springer Series in Operations Research and Financial Engineering,
DOI 10.1007/978-1-4614-9149-1 16, © Springer Science+Business Media New York 2014
301

302
16. The Capacitated VRP with Equal Demands
each customer has the same demand, namely, one unit, and the vehicle can visit
at most Q of these customers on a route. Therefore, this model is sometimes called
the CVRP with splittable demands or the ECVRP.
We denote the depot by x0 and the set of customers by N = {x1, x2, . . . , xn}.
The set N0 .= N ∪{x0} designates all customers and the depot. The customers
and the depot are represented by a set of nodes on an undirected graph G =
(N0, E). We denote by di the distance between customer i and the depot, by
dmax .= maxi∈N di the distance from the depot to the furthest customer, and by
dij the distance between customer i and customer j. The distance matrix {dij} is
assumed to be symmetric and to satisfy the triangle inequality; that is, dij = dji
for all i, j and dij ≤dik + dkj for all i, k, j. We denote the optimal solution value
of the CVRP by Z∗and the solution provided by a heuristic H by ZH.
In what follows, the optimal traveling salesman tour plays an important role.
So, for any set S ⊆N0, let L∗(S) be the length of the optimal traveling salesman
tour through the set of points S. Also, let Lα(S) be the length of an α-optimal
traveling salesman tour through S, that is, one whose length is bounded from
above by αL∗(S), α ≥1.
The graph depicted in Fig. 16.1, which is denoted by G(t, s), also plays an im-
portant role in our worst-case analyses. It consists of s groups of Q nodes and
another s −1 nodes, called white nodes, separating the groups. The nodes within
the same group have zero interdistance and each group is connected to the depot
by an arc of unit length. The white nodes are of zero distance apart and t units’
distance away from the depot. Each white node is connected to the two groups
of nodes it separates by an arc of unit length. Note that when 0 ≤t ≤2, G(t, s)
satisﬁes the triangle inequality [if an edge (i, j) is not shown in the graph, then the
distance between node i and node j is deﬁned as the length of the shortest path
from i to j]. Also note that whenever 0 ≤t ≤2, the tour depicted in Fig. 16.2 is
an optimal traveling salesman tour of length 2s.
FIGURE 16.1. Every group contains Q customers with interdistance zero

16.2 Worst-Case Analysis of Heuristics
303
FIGURE 16.2. An optimal traveling salesman tour in G(t, s)
In this chapter, we analyze this problem using the two tools developed earlier,
worst-case and average-case analyses. Later, in Chap. 17, we will analyze a more
general model of the CVRP.
16.2
Worst-Case Analysis of Heuristics
A simple heuristic for the CVRP, suggested by Haimovich and Rinnooy Kan (1985)
and later modiﬁed by Altinkemer and Gavish (1990), is to partition a traveling
salesman tour into segments, such that each segment of customers is served by a
single vehicle; that is, each segment has no more than Q points. The heuristic,
called the iterated tour-partitioning (ITP) heuristic, starts from a traveling sales-
man tour through all n = |N| customers and the depot. Starting at the depot
and following the tour in an arbitrary orientation, the customers and the depot
are numbered x(0), x(1), x(2), . . . , x(n), where x(0) is the depot. We partition the
path from x(1) to x(n) into ⌈n
Q⌉(or ⌈n
Q⌉+ 1) disjoint segments, such that each one
contains no more than Q customers, and connect the endpoints of each segment to
the depot. The ﬁrst segment contains only customer x(1). All the other segments
contain exactly Q customers, except maybe the last one. This deﬁnes one feasible
solution to the problem. We can repeat the above construction by shifting the end-
points of all but the ﬁrst and last segments up by one position in the direction of
the orientation. This can be repeated Q−1 times, producing a total of Q diﬀerent
solutions. We then choose the best of the set of Q solutions generated.
It is easy to see that for a given traveling salesman tour, the running time of
the ITP heuristic is O(nQ). The performance of this heuristic clearly depends
on the quality of the initial traveling salesman tour chosen in the ﬁrst step of
the algorithm. Hence, when the ITP heuristic partitions an α-optimal traveling

304
16. The Capacitated VRP with Equal Demands
salesman tour, it is denoted ITP(α). To establish the worst-case behavior of the
algorithm, we ﬁrst ﬁnd a lower bound on Z∗and then calculate an upper bound
on the cost of the solution produced by the ITP(α) heuristic.
Lemma 16.2.1 Z∗≥max{L∗(N0), 2
Q

i∈N di}.
Proof. Clearly, Z∗≥L∗(N0) by the triangle inequality. To prove Z∗≥2
Q

i∈N di,
consider an optimal solution in which N is partitioned into subsets {N1, N2, . . . ,
Nm}, where each set Nj is served by a single vehicle. Clearly,
Z∗=

j
L∗(Nj ∪{x0}) ≥

j
2 max
i∈Nj di ≥

j
2
|Nj|

i∈Nj
di
≥

j
2
Q

i∈Nj
di = 2
Q

i∈N
di.
Lemma 16.2.2 ZITP(α) ≤2
Q

i∈N di + (1 −1
Q)αL∗(N0).
Proof. We prove the lemma by ﬁnding the cumulative length of the Q solutions
generated by the ITP heuristic. The ith solution consists of the segments
{x(1), x(2), . . . , x(i)}, {x(i+1), x(i+2), . . . , x(i+Q)}, . . . , {x(i+1+⌊n−i
Q ⌋Q), . . . , x(n)}.
Thus, among the Q solutions generated, each customer x(i), 2 ≤i ≤n −1
appears exactly once as the ﬁrst point of a segment and exactly once as the last
point. Therefore, in the cumulative length of the Q solutions, the term 2dx(i) is
incurred for each i, 2 ≤i ≤n −1. Customer x(1) is the ﬁrst point of a segment in
each of the Q solutions, and in the ﬁrst one it is also the last point. Thus, the term
dx(1) appears Q + 1 times in the cumulative length. Similarly, x(n) is always the
last point of a segment in each of the Q solutions, and once the ﬁrst point. Thus,
the term dx(n) appears Q + 1 times in the cumulative length as well. Finally, each
one of the arcs (x(i), x(i+1)) for 1 ≤i ≤n −1 appears in exactly Q −1 solutions
since it is excluded from only one solution. These arcs, together with the Q −1
arcs connecting the depot to x(1) and Q −1 arcs connecting the depot to x(n),
form Q −1 copies of the initial traveling salesman tour selected in the ﬁrst step
of the heuristic. Thus, if the initial traveling salesman tour is an α-optimal tour,
the cumulative length of all Q tours is
2

i∈N
di + (Q −1)Lα(N0)
≤2

i∈N
di + (Q −1)αL∗(N0).

16.2 Worst-Case Analysis of Heuristics
305
Hence,
ZITP(α) ≤2
Q

i∈N
di + (1 −1
Q)αL∗(N0).
Combining upper and lower bounds, we obtain the following result.
Theorem 16.2.3
ZITP(α)
Z∗
≤1 +

1 −1
Q

α.
(16.1)
For example, if Christoﬁdes’ polynomial-time heuristic (α = 1.5) is used to
obtain the initial traveling salesman tour, we have
ZITP(1.5)
Z∗
≤5
2 −3
2Q.
The proof of the worst-case result for the ITP(α) heuristic suggests that if we
can improve the bound in (16.1) for α = 1, then the bound can be improved for
any α > 1. However, the following theorem, proved by Li and Simchi-Levi (1990),
says that this is impossible; that is, the bound
ZITP(1)
Z∗
≤2 −1
Q
is sharp.
Theorem 16.2.4 For any integer Q ≥1, there exists a problem instance with
ZITP(1)/Z∗= 2 −1
Q.
Proof. Let us consider the graph G(0, q). A solution obtained by the ITP heuristic
is shown in Fig. 16.3. In this solution,
ZITP(1) = 2 + 2 + 4 + 4 + · · · + 4
)
*+
,
Q−2 times
+2 = 4Q −2.
One can construct a solution that has Q vehicles serve the Q groups of customers
and the (Q + 1)st vehicle serve the other Q −1 nodes. Thus,
Z∗≤2Q.
Hence,
ZITP(1)
Z∗
≥2 −1
Q.
This, together with the upper bound of (16.1), completes the proof.
Another variant of the tour-partitioning heuristic is the optimal partitioning
(OP) heuristic described by Beasley (1983). The algorithm takes a traveling sales-
man tour and optimally partitions it into a set of feasible routes; that is, each
route contains at most Q customers.

306
16. The Capacitated VRP with Equal Demands
FIGURE 16.3. Solution obtained by the ITP heuristic
Given a traveling salesman tour through the customers and the depot, the heuris-
tic numbers the points x(0), x(1), . . . , x(n) in order of appearance on the tour, where
x(0) is the depot. Deﬁne
Cjk =
⎧
⎪
⎨
⎪
⎩
the distance traveled by a vehicle that starts at x(0) visits,
customers x(j+1), x(j+2), . . . , x(k) and returns to x(0),
if k −j ≤Q;
∞,
otherwise.
If we ﬁnd the shortest path from x(0) to x(n) in the acyclic graph [with nodes x(i),
0 ≤i ≤n, and arcs (x(i), x(j)) for 0 ≤i < j ≤n], where the distance between x(j)
and x(k) is Cjk, we will have an optimal partition of the traveling salesman tour
into feasible routes. For example, if the shortest path from x(0) to x(n) is x(0) →
x(t) →x(u) →x(n), then three tours are formed, namely, (x(0), x(1), . . . , x(t), x(0)),
(x(0), x(t+1), x(t+2), . . . , x(u), x(0)), and (x(0), x(u+1), x(u+2), . . . , x(n), x(0)).
For a given traveling salesman tour, the above shortest-path problem can be
solved in O(nQ) time, including the time required to evaluate the costs Cjk.
When the OP heuristic partitions an α-optimal traveling salesman tour, it is
denoted OP(α). The partitions considered by the OP(α) heuristic include all Q
of the partitions generated by the ITP(α) heuristic. Therefore, ZOP(α) ≤ZITP(α),
and hence, its worst-case bound is at least as good; that is,
ZOP(α)
Z∗
≤1 +

1 −1
Q

α.
The next theorem implies that for α = 1, this bound is asymptotically sharp; that
is, ZOP(1)/Z∗tends to 2 when Q approaches inﬁnity.
Theorem 16.2.5 For any integer Q ≥1, there exists a problem instance with
ZOP(1)/Z∗arbitrarily close to 2 −
2
Q+1.

16.3 The Asymptotic Optimal Solution Value
307
Proof. Consider the graph G(1, Kq + 1), where K is a positive integer. It is easy
to check that
ZOP(1) = 2(KQ + 1) + 2KQ.
On the other hand, consider the solution in which KQ+1 vehicles serve the KQ+1
groups of customers and another K vehicles serve the other nodes. Hence,
Z∗≤2(KQ + 1) + 2K,
and therefore,
lim
K→∞
ZOP(1)
Z∗
≥2 −
2
Q + 1.
16.3
The Asymptotic Optimal Solution Value
In this and the following section, we assume that the customers are points in
the plane and that the distance between any pair of customers is given by the
Euclidean distance. Assume, without loss of generality, that the depot is the point
(0, 0) and ||x|| designates the distance from the depot to the point x ∈IR2. The
results discussed in this section and the next are mainly based on Haimovich and
Rinnooy Kan (1985).
The upper bound of Lemma 16.2.2 has two cost components; the ﬁrst component
is proportional to the total “radial” cost between the depot and the customers.
The second component is proportional to the “circular” cost: the cost of traveling
between customers. This cost is related to the cost of the optimal traveling sales-
man tour. As discussed in Chap. 2, for large n, the cost of the optimal traveling
salesman tour grows like √n, while the total radial cost between the depot and
the customers grows like n. Therefore, it is intuitive that when the number of cus-
tomers is large enough, the ﬁrst cost component will dominate the second. This
observation is now formally proven.
Theorem 16.3.1 Let xk, k = 1, 2, . . . , n, be a sequence of independent random
variables having a distribution μ with compact support in IR2. Let
E(d) =

IR2 ||x||dμ(x).
Then, with probability 1,
lim
n→∞
Z∗
n = 2
QE(d).
Proof. Lemma 16.2.1 and the strong law of large numbers tell us that
lim
n→∞
Z∗
n ≥2
QE(d)
(a.s.).
(16.2)

308
16. The Capacitated VRP with Equal Demands
On the other hand, from Lemma 16.2.2,
Z∗
n ≤ZITP(1)
n
≤
2
nQ

i∈N
di +

1 −1
Q
L∗(N0)
n
.
From Chap. 5, we know that there exists a constant β > 0, independent of the
distribution μ, such that with probability 1,
lim
n→∞
L∗(N0)
√n
= β

IR2 f 1/2(x)dx,
where f is the density of the absolutely continuous part of the distribution μ.
Hence,
lim
n→∞
Z∗
n ≤2
QE(d)
(a.s.).
This together with (16.2) proves the theorem.
The following observation is in order. Haimovich and Rinnooy Kan prove The-
orem 16.3.1 merely assuming E(d) is ﬁnite rather than the stronger assumption
of a compact support. However, the restriction to a compact support seems to be
satisfactory for all practical purposes. The following is another important general-
ization of Theorem 16.3.1. Assume that a cluster of wk customers (rather than a
single customer) is located at point xk, k = 1, 2, . . . , n. The theorem then becomes
lim
n→∞
Z∗
n = 2
QE(w)E(d),
(16.3)
where E(w) is the expected cluster size, provided that the cluster size is indepen-
dent of
the
location. This
follows from a
straightforward adaptation of
Lemmas 16.2.1 and 16.2.2.
16.4
Asymptotically Optimal Heuristics
The proof of the previous theorem (Theorem 16.3.1) reveals that the ITP(α)
heuristic provides a solution whose cost approaches the optimal cost when n tends
to inﬁnity. Indeed, replacing ITP(1) by ITP(α) in the previous proof gives the
following theorem.
Theorem 16.4.1 Under the conditions of Theorem 16.3.1 and for any ﬁxed α ≥1,
the ITP(α) heuristic is asymptotically optimal.
As is pointed out by Haimovich and Rinnooy Kan (1985), iterated tour-
partitioning heuristics, although asymptotically optimal, hardly exploit the spe-
cial topological structure of the Euclidean plane in which the points are located. It
is therefore natural to consider region-partitioning (RP) heuristics that are more
geometric in nature.

16.4 Asymptotically Optimal Heuristics
309
Haimovich and Rinnooy Kan consider three classes of regional partitioning
schemes. In rectangular region partitioning (RRP), one starts with a rectangle
containing the set of customers N and cuts it into smaller rectangles. In polar
region partitioning (PRP) and circular region partitioning (CRP), one starts with
a circle centered at the depot and partitions it by means of circular arcs and radial
lines. We shall shortly discuss each one of these in detail.
In each case, the RP heuristics construct subregions of the plane, where subre-
gion j contains a set of customers N(j). These subregions are constructed so that
each one of them has exactly Q customers except possibly one.
Since every subset N(j) has no more than Q customers, each of these RP heuris-
tics allocates one vehicle to each subregion. The vehicles then use the following
routing strategy. The ﬁrst customer visited is the one closest to the depot among
all the customers in N(j). The rest are visited in the order of an α-optimal travel-
ing salesman tour through N(j). After visiting all the customers in the subregion,
the vehicle returns to the depot through the ﬁrst (closest) customer. It is therefore
natural to call these heuristics RP(α) heuristics. In particular, we have RRP(α),
PRP(α), and CRP(α).
Lemma 16.4.2 ZRP (α) ≤2
Q

i∈N di + 2dmax + α 
j L∗(N(j)).
Proof. We number the subsets N(j) constructed by the RP(α) heuristic so that
|N(j)| = Q for every j ≥2 and |N(1)| ≤Q. It follows that the total distance
traveled by the vehicle that visits subset N(j), for j ≥2, is
≤2 min
i∈N(j) di + αL∗(N(j))
≤2
Q

i∈N(j)
di + αL∗(N(j)),
while the total distance traveled by the vehicle that visits N(1) is no more than
2dmax + αL∗(N(1)).
Taking the sum over all subregions, we obtain the desired result.
The quality of the upper bound of Lemma 16.4.2 depends, of course, on the
quantity 
j L∗(N(j)). This value was analyzed in Chap. 5, where it was shown
that for any RP heuristic,

j
L∗(N(j)) ≤L∗(N) + 3
2P RP ,
(16.4)
where P RP is the sum of perimeters of the subregions generated by the RP heuris-
tic. For this reason, we analyze the quantity P RP in each of the three region-
partitioning heuristics.

310
16. The Capacitated VRP with Equal Demands
Rectangular Region Partitioning
This heuristic is identical to the one introduced for the traveling salesman prob-
lem in Sect. 5.3. The smallest rectangle with sides a and b containing the set of
customers N is partitioned with horizontal and vertical lines. First, the region is
subdivided by t vertical lines such that each subregion contains exactly (h + 1)Q
points except possibly the last one. Each of these t + 1 subregions is then parti-
tioned with h horizontal lines into h+1 smaller subregions such that each contains
exactly Q points except possibly for the last one.
As before, h and t should satisfy
t =

n
(h + 1)Q

−1
and
t(h + 1)Q < n ≤(t + 1)(h + 1)Q.
The unique integer that satisﬁes these conditions is h = ⌈

n
Q −1⌉. Note that the
number of vertical lines added is t ≤

n
Q, and each of these lines is counted twice
in the quantity P RRP.
In the second step of the RRP, we add h horizontal lines, where h ≤

n
Q. These
horizontal lines are also counted twice in P RRP. It follows that
P RRP ≤2
 n
Q(a + b) + 2(a + b) ≤8dmax
 n
Q + 8dmax.
Polar Region Partitioning
The circle with radius dmax containing the set N and centered at the depot is
partitioned in exactly the same way as in the previous partitioning scheme, with
the exception that circular arcs and radial lines replace vertical and horizontal
lines. Using the same analysis, one can show
P PRP ≤6πdmax
 n
Q + 2πdmax + 2dmax.
(16.5)
Circular Region Partitioning
This scheme partitions the circle centered at the depot with radius dmax into h
equal sectors, where h is to be determined. Each sector is then partitioned into
subregions via circular arcs, such that each subregion contains exactly Q customers
except possibly the one closest to the depot. Thus, at most h subregions, each from
one sector, have less than Q customers. These subregions (with the depot on their
boundary) are then repartitioned with radial cuts such that at most h −1 of them
have exactly Q customers each except for possibly the last one.

16.4 Asymptotically Optimal Heuristics
311
The total length of the initial radial lines is hdmax. The length of an inner
circular arc bounding a subregion containing a set N(j) is no more than
2π
h
min
i∈N(j) di ≤2π
h

i∈N(j) di
|N(j)|
=
2π 
i∈N(j) di
hQ
,
while the length of the outer circle is 2πdmax. Finally, the repartitioning of the
central subregions adds no more than hdmax
2
. Thus,
P CRP ≤2

hdmax + 2π 
i∈N di
hQ
+ hdmax
2

+ 2πdmax.
Taking h =

4π 
i∈N di
3Qdmax

, we obtain the following upper bound on P CRP :
P CRP ≤4

3πdmax
1
Q

i∈N
di + (3 + 2π)dmax.
The reader should be aware that all of these partitioning schemes can be im-
plemented in O(n log n) time. We now have all the necessary ingredients for an
asymptotic analysis of the performance of these partitioning heuristics.
Theorem 16.4.3 Under the conditions of Theorem 16.3.1 and for any ﬁxed α ≥
1, RRP(α), PRP(α), and CRP(α) are asymptotically optimal.
Proof. Lemma 16.4.2, together with (16.4), provides the following upper bound on
the total distance traveled by all vehicles in the solution produced by the above
RP heuristics:
ZRP (α) ≤2
Q

i∈N
di + 2dmax + αL∗(N) + 3
2αP RP .
By the strong law of large numbers and the fact that the distribution has compact
support, 1
n

i∈N di converges almost surely to E(d), while dmax
n
converges almost
surely to 0. Furthermore, L∗(N)
n
converges to 0 almost surely; see the proof of The-
orem 16.3.1. Finally, from the analysis of each of the region-partitioning heuristics
and the fact that the points are in a compact region, P RP
n
converges almost surely
to zero as well.
In conclusion, we see that the CVRP with equal demands is asymptotically solv-
able via several diﬀerent region-partitioning schemes. In fact, since each customer
has the same demand, the packing of the customers’ demands into the vehicles
is a trivial problem. Any Q customers can ﬁt. The more diﬃcult problem, when
demands are of diﬀerent sizes, presents complicating bin-packing features, which
will prove to be more diﬃcult.

312
16. The Capacitated VRP with Equal Demands
16.5
Exercises
Exercise 16.1.
Consider the following version of the capacitated vehicle routing
problem (CVRP). You are given a network G = (V, A) with positive arc lengths.
Assume that E ⊆A is a given set of edges that have to be “covered” by vehicles.
The vehicles are initially located at a depot p ∈V . Each vehicle has a “capacity”
q; that is, each vehicle can cover no more than q edges from E. Once a vehicle
starts an edge in E, it has to cover all of it. The objective is to design tours for
vehicles so that all edges in E are covered, vehicles’ capacities are not violated,
and the total distance traveled is as small as possible.
(a) Suppose we want ﬁrst to ﬁnd a single tour that starts at the depot p, traverses
all edges in E, and ends at p and whose total cost (length) is as small as
possible. Generalize Christoﬁdes’ heuristic for this case.
(b) Consider now the version of the CVRP described above and suggest two
possible lower bounds on the optimal cost of the CVRP.
(c) Describe a heuristic algorithm based on a tour-partitioning approach using,
as the initial tour, the tour you found in part (a). What is the worst-case
bound of your algorithm?
Exercise 16.2.
Derive (16.3).
Exercise 16.3.
Consider an n-customer instance of the CVRP with equal de-
mands. Assume there are m depots and at each depot is an unlimited number of
vehicles of limited capacity. Suggest an asymptotically optimal region-partitioning
scheme for this case.
Exercise 16.4.
Consider an n-customer instance of the CVRP with equal de-
mands. There are K customer types: A customer is of type k with independent
probability pk > 0. Customers of diﬀerent types cannot be served together in the
same vehicle. Devise an asymptotically optimal heuristic for this problem. If K is
a function of n, what conditions on K(n) are necessary to ensure that this same
heuristic is asymptotically optimal?
Exercise 16.5.
Derive (16.5).

17
The Capacitated VRP with Unequal
Demands
17.1
Introduction
In this chapter, we consider the capacitated vehicle routing problem with unequal
demands (UCVRP). In this version of the problem, each customer i has a demand
wi and the capacity constraint stipulates that the total amount delivered by a
single vehicle cannot exceed Q. We let Z∗
u denote the optimal solution value of
UCVRP, that is, the minimal total distance traveled by all vehicles.
In this version of the problem, the demand of a customer cannot be split over sev-
eral vehicles; that is, each customer must be served by a single vehicle. This, more
general, version of the model is sometimes called the CVRP with unsplit demands.
The version where demands may be split is dealt with in Chap. 16. Splitting a
customer’s demand is often physically impossible or managerially undesirable due
to customer service or accounting considerations.
17.2
Heuristics for the CVRP
A great deal of work has been devoted to the development of heuristics for the
UCVRP; see, for example, Christoﬁdes (1985), Fisher (1995), and Federgruen and
Simchi-Levi (1995), or Bertsimas and Simchi-Levi (1996). Following Christoﬁdes,
we classify these heuristics into the four categories:
• constructive methods;
• route-ﬁrst–cluster-second methods;
D. Simchi-Levi et al., The Logic of Logistics: Theory, Algorithms, and Applications
for Logistics Management, Springer Series in Operations Research and Financial Engineering,
DOI 10.1007/978-1-4614-9149-1 17, © Springer Science+Business Media New York 2014
313

314
17. The Capacitated VRP with Unequal Demands
• cluster-ﬁrst–route-second methods;
• incomplete optimization methods.
We will describe the main characteristics of each of these classes and give exa-
mples of heuristics that fall into each.
Constructive Methods
The savings algorithm suggested by Clarke and Wright (1964) is the most imp-
ortant member of this class. This heuristic, which is the basis for a number of
commercial vehicle routing packages, is one of the earliest heuristics designed for
this problem and, without a doubt, the most widely known. The idea of the savings
algorithm is very simple: Consider the depot and n demand points. Suppose that
initially we assign a separate vehicle to each demand point. The total distance
traveled by a vehicle that visits demand point i is 2di, where di is the distance
from the depot to demand point i. Therefore, the total distance traveled in this
solution is 2 n
i=1 di.
If we now combine two routes, say we serve i and j on a single trip (with the
same vehicle), the total distance traveled by this vehicle is di + dij + dj, where dij
is the distance between demand points i and j. Thus, the savings obtained from
combining demand points i and j, denoted sij, is
sij = 2di + 2dj −(di + dj + dij) = di + dj −dij.
The larger the savings sij, the more desirable it is to combine demand points i
and j. Based on this idea, Clarke and Wright suggest the following algorithm.
The Savings Algorithm
Step 1: Start with the solution that has each customer visited by a separate
vehicle.
Step 2: Calculate the savings sij = d0i + dj0 −dij ≥0 for all pairs of customers i
and j.
Step 3: Sort the savings in nonincreasing order.
Step 4: Find the ﬁrst feasible arc (i, j) in the savings list, where
(1) i and j are on diﬀerent routes,
(2) both i and j are either the ﬁrst or last visited on their
respective routes, and
(3) the sum of demands of routes i and j is no more than Q.
Add arc (i, j) to the current solution and delete arcs (0, i) and (j, 0). Delete
arc (i, j) from the savings list.
Step 5: Repeat step 4 until no more arcs satisfy the conditions.

17.2 Heuristics for the CVRP
315
Additional constraints, which might be present, can easily be incorporated into
step 4. Usually, a simple check can be performed to see whether combining the
tours containing i and j violates any of these constraints.
Other examples of heuristics that fall into this class are the heuristics of Gaskel
(1967), Yellow (1970), and Russell (1977). In particular, the ﬁrst two are modiﬁ-
cations of the savings algorithm.
Route-First–Cluster-Second Methods
Traditionally, this class has been deﬁned as follows. The class consists of those
heuristics that ﬁrst construct a traveling salesman tour through all the customers
(route ﬁrst) and then partition the tour into segments (cluster second). One vehicle
is assigned to each segment and visits the customers according to their appearance
on the traveling salesman tour.
As we shall see in the next section, some strong statements can be made about
the performance of this class’s heuristics. For this purpose, we give a more precise
deﬁnition of the class here.
Deﬁnition 17.2.1 A heuristic is a route-ﬁrst–cluster-second heuristic if it ﬁrst
orders the customers according to their locations, disregarding demand sizes, and
then partitions this ordering to produce feasible clusters. These clusters consist of
sets of customers that are consecutive in the initial order. Customers are then
routed within their cluster depending on the speciﬁc heuristic.
This deﬁnition of the class is more general than the traditional deﬁnition given
above. The disadvantage of this class, of which we will give a rigorous analysis,
can be highlighted by the following simple example. Consider a routing strategy
that orders the demands in such a way that the sequence of demand sizes in the
order is (9, 2, 9, 2, 9, 2, 9, 2, . . .). If the vehicle capacity is 10, then any partition of
this tour must assign one vehicle to each customer. This solution would consist of
half of the vehicles going to pick up two units (using 20 % of the vehicle capacity)
and returning to the depot, not a very eﬃcient strategy. By contrast, a routing
strategy that looks at the demands at the same time as it looks at customer
locations would clearly ﬁnd a more intelligent ordering of the customers: one that
sequences demands eﬃciently to decrease total distance traveled.
The route-ﬁrst–cluster-second class includes classical heuristics such as the opti-
mal partitioning heuristic introduced by Beasley (1983), and the sweep algorithm
suggested by Gillett and Miller (1974).
In the optimal partitioning heuristic, one tries to ﬁnd an optimal traveling sales-
man tour, or, if this is not possible, a tour that is close to optimal. This provides
the initial ordering of the demand points. The ordering is then partitioned in an
eﬃcient way into segments. This step can be done by formulating a shortest-path
problem. See Sect. 16.2 for details.
In the sweep algorithm, an arbitrary demand point is selected as the starting
point. The other customers are ordered according to the angle made among them,
the depot, and the starting point. Demands are then assigned to vehicles following

316
17. The Capacitated VRP with Unequal Demands
this initial order. In eﬀect, the points are “swept” in a clockwise direction around
the depot and assigned to vehicles. Then eﬃcient routes are designed for each
vehicle. Speciﬁcally, the sweep algorithm is the following.
The Sweep Algorithm
Step 1: Calculate the polar coordinates of all customers, where the center is the
depot and an arbitrary customer is chosen to be at angle 0. Reorder the
customers so that
0 = θ1 ≤θ2 ≤· · · ≤θn.
Step 2: Starting from the unrouted customer i with smallest angle θi, construct
a new cluster by sweeping consecutive customers i + 1, i + 2 . . . until the
capacity constraint will not allow the next customer to be added.
Step 3: Continue step 2 until all customers are included in a cluster.
Step 4: For each cluster constructed, solve the TSP on the subset of customers
and the depot.
In both of these methods, additional constraints can easily be incorporated into
the algorithm.
We note that, traditionally, researchers have classiﬁed the sweep algorithm as a
cluster-ﬁrst–route-second method and not as a route-ﬁrst–cluster-second method.
Our opinion is that the essential part of any vehicle routing algorithm is the clus-
tering phase of the algorithm, that is, how the customers are clustered into groups
that can be served by individual vehicles. The speciﬁc sequencing within a cluster
can and, for most problems, should be done once these clusters are determined.
Therefore, a classiﬁcation of algorithms for the CVRP should be solely based on
how the clustering is performed. Thus, the sweep algorithm can be viewed as an
algorithm of the route-ﬁrst–cluster-second class since the clustering is performed
on a ﬁxed ordering of the nodes.
Cluster-First–Route-Second Methods
In this class of heuristics, the clustering is the most important phase. Customers
are ﬁrst clustered into feasible groups to be served by the same vehicle (cluster
ﬁrst) without regard to any preset ordering, and then eﬃcient routes are designed
for each cluster (route second).
Heuristics of this class are usually more technically sophisticated than the pre-
vious class, since determining the clusters is often based on a mathematical pro-
gramming approach. This class includes the following three heuristics:
• the two-phase method (Christoﬁdes et al. 1978);
• the generalized assignment heuristic (Fisher and Jaikumar 1981);
• the location-based heuristic (Bramel and Simchi-Levi 1995).

17.3 Worst-Case Analysis of Heuristics
317
The ﬁrst two heuristics use, in a ﬁrst step, the concept of seed customers.
The seed customers are customers that will be in separate vehicles in the solution
and around which tours are constructed. In both cases, the performance of the
algorithm depends highly on the choice of these seeds. Placing the CVRP in the
framework of a diﬀerent combinatorial problem, the location-based heuristic sel-
ects the seeds in an optimal way and creates, at the same time, tours around these
seeds. Thus, instead of decomposing the process into two steps, as is done in the
two-phase method and the generalized assignment heuristic, the location-based
heuristic simultaneously picks the seeds and designs tours around them. We will
discuss this heuristic in detail in Sect. 17.7.
Incomplete Optimization Methods
These methods are optimization algorithms that, due to the prohibitive com-
puting time involved in reaching an optimal solution, are terminated prematurely.
Examples of these include
• cutting-plane methods (Cornu´ejols and Harche 1993),
• minimum K-tree methods (Fisher 1994).
The disadvantage of incomplete optimization methods is that they still require
large amounts of processing time, and they can handle problems with usually no
more than 100 customers.
17.3
Worst-Case Analysis of Heuristics
In the worst-case analysis presented here, we assume that the customer demands
w1, w2, . . . , wn and the vehicle capacity Q are rationals. Hence, without loss of
generality, we assume that Q and wi are integers. Furthermore, we may assume
that Q is even; otherwise, one can double Q as well as each wi, i = 1, 2, . . . , n,
without aﬀecting the problem. The following two-phase route-ﬁrst–cluster-second
heuristic was suggested by Altinkemer and Gavish (1987). In the ﬁrst phase, we
relax the requirement that the demand of a customer cannot be split. Each cus-
tomer i is replaced by wi-unit demand points that are zero distance apart. We then
apply the ITP(α) heuristic (see Sect. 16.3) using a vehicle capacity of Q
2 . In the
second phase, we convert the solution obtained in Phase I to a feasible solution to
the original problem without increasing the total cost. This heuristic is called the
unequal-weight iterated tour-partitioning [UITP(α)] heuristic.
We now describe the second-phase procedure. Our notation follows the one sug-
gested by Haimovich et al. (1988). Let m = 
i∈N wi be the number of demand
points in the expanded problem. Recall that in the ﬁrst phase an arbitrary orienta-
tion of the tour is chosen. The customers are then numbered x(0), x(1), x(2), . . . , x(n),
in order of their appearance on the tour, where x(0) is the depot. The ITP(α)
heuristic partitions the path from x(1) to x(n) into ⌈2m
Q ⌉(or ⌈2m
Q ⌉+ 1) disjoint

318
17. The Capacitated VRP with Unequal Demands
segments such that each one contains no more than Q
2 demand points and connects
the endpoints of each segment to the depot. The segments are indexed by j =
1, 2, . . ., ⌈2m
Q ⌉, such that the ﬁrst customer of the jth segment is x(bj) and the
last customer is x(ej). Hence, the jth segment, denoted by Sj, includes customers
{x(bj), · · · , x(ej)}. Obviously, if x(ej) = x(bj+1) for some j, then the demand of cus-
tomer x(ej) is split between the jth and (j + 1)th segments; therefore, these are
not feasible routes. On the other hand, if x(ej) ̸= x(bj+1) for all j, then the set of
routes is feasible.
We now transform the solution obtained in the ﬁrst phase into a feasible solution
without increasing the total distance traveled. We use the following procedure.
The Phase 2 Procedure
Step 1: Set S′
j = ∅, for j = 1, 2, . . ., ⌈2m
Q ⌉.
Step 2: For j = 1 to ⌈2m
Q ⌉−1, do
If x(ej) = x(bj+1), then
If bj+1
i=bj wx(i) ≤Q, then let S′
j = {x(bj), · · · , x(ej)} and
let x(bj+1) = x(bj+1+1);
else let S′
j = {x(bj), · · · , x(ej−1)} and x(bj+1) = x(ej)
else, let S′
j = {x(bj), · · · , x(ej)}.
We argue that the procedure generates feasible sets S′
j for j = 1, 2, . . ., ⌈2m
Q ⌉.
Note that the jth set can be enlarged only in the (j −1)st and jth iterations
(if at all). Moreover, if it is enlarged in the jth iteration, it is clearly done feasibly in
view of the test bj+1
i=bj wx(i) ≤Q. On the other hand, if Sj is enlarged in the (j−1)st
iteration, at most Q
2 demand points are added, thus ensuring feasibility. This can be
veriﬁed as follows. Assume to the contrary that in the (j −1)st iteration more than
Q
2 demand points are transferred from S′
j−1 to Sj so that in the (j −1)st iteration
x(ej−1) = x(bj). Since the original set Sj−1 contains at most Q
2 demand points, we
must have shifted demand points in the (j −2)nd iteration from Sj−2 to Sj−1 [and,
in particular, x(bj−1) = x(ej−2)], part of which are now being transferred to Sj. This
implies that x(∗) .= x(ej−2) = x(bj−1) = x(ej−1) = x(bj), where ej−2, bj−1, ej−1, and
bj refer to the original sets Sj−2, Sj−1, and Sj. In other words, at the beginning
of the (j −1)st iteration, the set S′
j−1 contains a single customer x(∗). But then,
shifting x(bj) = x(∗) backward to S′
j−1 is feasible, contradicting the fact that more
than Q
2 demand points need to be shifted forward from S′
j−1 to S′
j. Therefore, the
procedure generates feasible sets and we have the following worst-case bound.
Theorem 17.3.1
ZUITP(α)
Z∗
u
≤2 + (1 −2
Q)α.
Proof. Recall that in the ﬁrst phase, the vehicle capacity is set to Q
2 . Hence, using
the bound of Lemma 16.2.2, we obtain the following upper bound on the length

17.3 Worst-Case Analysis of Heuristics
319
of the tours generated in Phase I of the UITP(α) heuristic:
4
Q

i∈N
diwi +

1 −2
Q

αL∗(N0).
(17.1)
In the second phase of the algorithm, the tour obtained in the ﬁrst phase is
converted into a feasible solution with total length no more than (17.1). To verify
this, we need only to analyze those segments whose endpoints are modiﬁed by the
procedure.
Suppose that Sj and S′
j diﬀer in their starting point; then S′
j must start with
x(bj+1). This implies that arc (x(bj), x(bj+1)), which is part of the Phase I solution,
does not appear in the jth route. The triangle inequality ensures that the sum of
the length of arcs (x(0), x(bj)) and (x(bj), x(bj+1)) is no smaller than the length of
arc (x(0), x(bj+1)). A similar argument can be applied if Sj and S′
j diﬀer in their
terminating point. Consequently, for every segment j, for j = 1, 2, . . . , ⌈2m
Q ⌉, the
length of the jth route according to the new partition is no longer than the length
of the jth route according to the old partition. Hence,
ZUITP(α) ≤4
Q

i∈N
diwi +

1 −2
Q

αL∗(N0).
Clearly, Z∗
u ≥Z∗, and therefore using the lower bound on Z∗developed in
Lemma 16.2.1 completes the proof.
The UITP heuristic was divided into two phases to prove the above worst-case
result. However, if the optimal partitioning heuristic is used in the unequal-weight
model, the actual implementation is a one-step process. This is done as follows.
Given a traveling salesman tour through the set of customers and the depot, we
number the nodes x(0), x(1), . . . , x(n) in order of their appearance on the tour,
where x(0) is the depot. We then deﬁne a distance matrix with cost Cjk, where
Cjk =
⎧
⎪
⎪
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎪
⎪
⎩
the distance traveled by a vehicle that starts
at x(0), visits customers x(j+1), x(j+2), . . . , x(k),
and returns to x(0),
if k
i=j+1 wx(i) ≤Q;
∞,
otherwise.
As in the equal-demand case (see Sect. 16.2), it follows that a shortest path from
x(0) to x(n) in the directed graph with distance cost Cjk corresponds to an optimal
partition of the traveling salesman tour. This version of the heuristic, developed
by Beasley and called the unequal-weight optimal partitioning (UOP) heuristic,
also has ZUOP(α)/Z∗≤2 + (1 −2
Q)α. The following theorem, proved by Li and
Simchi-Levi (1990), implies that when α = 1, this bound is asymptotically tight
as Q approaches inﬁnity.
Theorem 17.3.2 For any integer Q ≥1, there exists a problem instance with
ZUOP(1)/Z∗
u (and therefore ZUITP(1)/Z∗
u) arbitrarily close to 3 −
6
Q+2.

320
17. The Capacitated VRP with Unequal Demands
Proof. We modify the graph G(2, Kq+1), where K is a positive integer, as follows.
Now, every group—instead of containing Q customers—contains only one customer
with demand Q. The other KQ customers have unit demand. The optimal traveling
salesman tour is again as shown in Fig. 16.2, and the solution obtained by the
UOP(1) heuristic is to have 2KQ + 1 vehicles, each one of them serving only one
customer. Thus,
ZUOP(1) = 2(KQ + 1) + 4KQ.
The optimal solution to this problem has KQ + 1 vehicles serve those customers
with demand Q,, and K other vehicles serve the unit demand customers. Hence,
Z∗
u = 2(KQ + 1) + 4K.
Therefore,
lim
K→∞
ZUOP(1)
Z∗u
= lim
K→∞
2(KQ + 1) + 4KQ
2(KQ + 1) + 4K
= 3 −
6
Q + 2.
17.4
The Asymptotic Optimal Solution Value
In the probabilistic analysis of the UCVRP, we assume, without loss of generality,
that the vehicle’s capacity Q equals 1, and the demand of each customer is no
more than 1. Thus, vehicles and demands in a capacitated vehicle routing problem
correspond to bins and item sizes (respectively) in a bin-packing problem. Hence,
for every routing instance, there is a unique corresponding bin-packing instance.
Assume the demands w1, w2, . . . , wn are drawn independently from a distribu-
tion Φ deﬁned on [0, 1]. Assume customer locations are drawn independently from
a probability measure μ with compact support in IR2. We assume that di > 0 for
each i ∈N since customers at the depot can be served at no cost. In this section,
we ﬁnd the asymptotic optimal solution value for any Φ and any μ. This is done
by showing that an asymptotically optimal algorithm for the bin-packing problem,
with item sizes distributed like Φ, can be used to solve, in an asymptotic sense,
the UCVRP.
Given the demands w1, w2, . . . , wn, let b∗
n be the number of bins used in the
optimal solution to the corresponding bin-packing problem. As demonstrated in
Theorem 5.2.4, there exists a constant γ > 0 (depending only on Φ) such that
lim
n→∞
b∗
n
n = γ
(a.s.).
(17.2)
We shall refer to the constant γ as the bin-packing constant and omit the depen-
dence of γ on Φ in the notation.
The following theorem was proved by Simchi-Levi and Bramel (1990). Recall,
without loss of generality, the depot is positioned at (0, 0) and ||x|| represents the
distance from the point x ∈IR2 to the depot.

17.4 The Asymptotic Optimal Solution Value
321
Theorem 17.4.1 Let xk, k = 1, 2, . . . , n, be a sequence of independent random
variables having a distribution μ with compact support in IR2. Let
E(d) =

IR2 ||x||dμ(x).
Let the demands wk, k = 1, 2, . . . , n, be a sequence of independent random variables
having a distribution Φ with support on [0, 1], and assume that the demands and the
locations of the customers are independent of each other. Let γ be the bin-packing
constant associated with the distribution Φ; then, almost surely,
lim
n→∞
1
nZ∗
u = 2γE(d).
Thus, the theorem fully characterizes the asymptotic optimal solution value of
the UCVRP, for any reasonable distributions Φ and μ. An interesting observation
concerns the case where the distribution of the demands allows perfect packing,
that is, when the wasted space in the bins tends to become a small fraction of the
number of bins used. Formally, Φ is said to allow perfect packing if almost surely
limn→∞
b∗
n
n = E(w). Karmarkar (1982) proved that a nonincreasing probability
density function (with some mild regularity conditions) allows perfect packing.
Rhee (1988) completely characterizes the class of distribution functions Φ, which
allow perfect packing. Clearly, in this case, γ = E(w). Thus, Theorem 17.4.1 indi-
cates that allowing the demands to be split or not does not change the asymptotic
objective function value. That is, the UCVRP and the ECVRP can be said to be
asymptotically equivalent when Φ allows perfect packing.
To prove Theorem 17.4.1, we start by presenting in Sect. 17.4.1 a lower bound
on the optimal objective function value. In Sect. 17.4.2, we present a heuristic for
the UCVRP based on a simple region-partitioning scheme. We show that the cost
of the solution produced by the heuristic converges to our lower bound for any Φ
and μ, thus proving the main theorem of the section.
17.4.1
A Lower Bound
We introduce a lower bound on the optimal objective function value Z∗
u. Let A ⊂
IR2 be the compact support of μ and deﬁne dmax .= supx∈A{||x||}. For a given
ﬁxed positive integer r ≥1, partition the circle with radius dmax centered at the
depot into r rings of equal width. Let dj
.= (j −1) dmax
r
for j = 1, 2, . . . , r, r + 1,
and construct the following 2r sets of customers:
Sj =

xk ∈N
dj < dk ≤dj+1

for j = 1, . . . , r,
and
Fj =
r-
i=j
Si
for j = 1, 2, . . ., r.
Note that Fr ⊆Fr−1 ⊆· · · ⊆F1 = N since dk > 0 for all yk ∈N.

322
17. The Capacitated VRP with Unequal Demands
In the lemma below, we show that |Fr| grows to inﬁnity almost surely as n
grows to inﬁnity. This implies that |Fj| also grows to inﬁnity almost surely for
j = 1, 2, . . . , r, since |Fj+1| ≤|Fj|, for j = 1, 2, . . ., r −1. The proof follows from
the deﬁnitions of compact support and dmax.
Lemma 17.4.2
lim
n→∞
|Fr|
n
= p (a.s.) for some constant p > 0.
For any set of customers T ⊆N, let b∗(T ) be the minimum number of vehicles
needed to serve the customers in T ; that is, b∗(T ) is the optimal solution to the
bin-packing problem deﬁned by item sizes equal to the demands of the customers
in T . We can now present a family of lower bounds on Z∗
u that hold for diﬀerent
values of r ≥1.
Lemma 17.4.3
Z∗
u > 2dmax
r
r

j=2
b∗(Fj)
for any r ≥1.
Proof. Given an optimal solution to the UCVRP, let K∗
r be the number of vehicles
in the optimal solution that serve at least one customer from Sr, and for j =
1, 2, . . ., r −1, let K∗
j be the number of vehicles in the optimal solution that serve
at least one customer in the set Sj but do not serve any customers in Fj+1. Also,
let V ∗
j be the number of vehicles in the optimal solution that serve at least one
customer in Fj. By these deﬁnitions, V ∗
j = r
i=j K∗
i , for j = 1, 2, . . . , r; hence,
K∗
j = V ∗
j −V ∗
j+1 for j = 1, 2, . . . , r −1, and K∗
r = V ∗
r .
Note that V ∗
j ≥b∗(Fj), for j = 1, 2, . . . , r, since V ∗
j represents the number of
vehicles used in a feasible packing of the demands of customers in Fj, while b∗(Fj)
represents the number of bins used in an optimal packing.
By the deﬁnition of K∗
j and dj, Z∗
u > 2 r
j=1 djK∗
j and therefore,
Z∗
u > 2drV ∗
r +
r−1

j=1
2dj

V ∗
j −V ∗
j+1

= 2d1V ∗
1 +
r

j=2
2(dj −dj−1)V ∗
j
= 2
r

j=2
(dj −dj−1)V ∗
j
(since d1 = 0)
≥2
r

j=2
(dj −dj−1)b∗(Fj)
[since V ∗
j ≥b∗(Fj)]
= 2
r

j=2
dmax
r
b∗(Fj).

17.4 The Asymptotic Optimal Solution Value
323
Note that Lemma 17.4.3 provides a deterministic lower bound; that is, no
probabilistic assumptions are involved. Lemmas 17.4.2 and 17.4.3 are both req-
uired to provide a lower bound on 1
nZ∗
u that holds almost surely.
Lemma 17.4.4 Under the conditions of Theorem 17.4.1, we have
lim
n→∞
1
nZ∗
u ≥2γE(d)
(a.s.).
Proof. Lemma 17.4.3 implies that
lim
n→∞
1
nZ∗
u ≥2dmax
r
lim
n→∞
r

j=2
b∗(Fj)
n
= 2dmax
r
r

j=2
lim
n→∞
b∗(Fj)
|Fj|
lim
n→∞
|Fj|
n .
From Lemma 17.4.2, |Fj| grows to inﬁnity almost surely as n grows to inﬁnity,
for j = 1, 2, . . . , r. Moreover, since demands and locations are independent of each
other, the demands in Fj, j = 1, 2, . . ., r, are distributed like Φ. Therefore,
lim
n→∞
b∗(Fj)
|Fj|
=
lim
|Fj|→∞
b∗(Fj)
|Fj|
= γ
(a.s.).
Hence, almost surely,
lim
n→∞
1
nZ∗
u ≥2dmax
r
r

j=2
γ lim
n→∞
|Fj|
n
= 2dmax
r
γ lim
n→∞
1
n
r

j=2
|Fj|.
Since
Fj =
r-
i=j
Si
for j = 1, 2, . . ., r,
we have |Fj| = r
i=j |Si|; hence, almost surely,
lim
n→∞
1
nZ∗
u ≥2dmax
r
γ lim
n→∞
1
n
r

j=2
r

i=j
|Si|
= 2dmax
r
γ lim
n→∞
1
n
r

j=2
(j −1)|Sj|.

324
17. The Capacitated VRP with Unequal Demands
By the deﬁnition of dj,
lim
n→∞
1
nZ∗
u ≥2γ lim
n→∞
1
n
r

j=2
dj|Sj| = 2γ lim
n→∞
1
n
r

j=1
dj|Sj|,
since d1 = 0 and |S1| ≤n. By the deﬁnition of dj and Sj, dj ≥dk −dmax
r , for all
xk ∈Sj. Then almost surely,
lim
n→∞
1
nZ∗
u ≥2γ lim
n→∞
1
n

xk∈N
(dk −dmax
r
)
= 2γ lim
n→∞
1
n

xk∈N
dk −2γ dmax
r
= 2γE(d) −2γ dmax
r
.
This lower bound holds for arbitrarily large r; hence,
lim
n→∞
1
nZ∗
u ≥2γE(d)
(a.s.).
In the next section, we show that this lower bound is tight by presenting an
upper bound on the cost of the optimal solution that asymptotically approaches
the same value.
17.4.2
An Upper Bound
We prove Theorem 17.4.1 by analyzing the cost of the following three-step heuristic
that provides an upper bound on Z∗
u. In the ﬁrst step, we partition the area A
into subregions. Then, for each of these subregions, we ﬁnd the optimal packing of
the customers’ demands in the subregion, into bins of unit size. Finally, for each
subregion, we allocate one vehicle to serve the customers in each bin.
The Region-Partitioning Scheme
For a ﬁxed h > 0, let G(h) be an inﬁnite grid of squares with side
h
√
2 and edges
parallel to the system coordinates. Recall that A is the compact support of the
distribution function μ, and let A1, A2, . . . , At(h) be the intersection of the squares
of G(h) with the compact support A that have μ(Ai) > 0. Note t(h) < ∞since A
is compact and t(h) is independent of n.
Let N(i) be the set of customers located in subregion Ai, and deﬁne n(i) .=
|N(i)|. For every i = 1, 2, . . ., t(h), let b∗(i) be the minimum number of bins
needed to pack the demands of customers in N(i). Finally, for each subregion
Ai, i = 1, 2, . . . , t(h), let nj(i) be the number of customers in the jth bin of this
optimal packing, for each j = 1, 2, . . . , b∗(i).

17.4 The Asymptotic Optimal Solution Value
325
We now proceed to ﬁnd an upper bound on the value of our heuristic. Recall
that for each bin produced by the heuristic, we send a single vehicle to serve all
the customers in the bin. First, the vehicle visits the customer closest to the depot
in the subregion to which the bin belongs, then serves all the customers in the bin
in any order, and then returns to the depot through the closest customer again.
Let d(i) be the distance from the depot to the closest customer in N(i), that is, in
subregion Ai. Note that since each subregion Ai is a subset of a square of side
h
√
2,
the distance between any two customers in Ai is no more than h. Consequently,
using the method just described, we calculate that the distance traveled by the
vehicle that serves all the customers in the jth bin of subregion Ai is no more than
2d(i) + h(nj(i) + 1).
Therefore,
Z∗
u ≤
t(h)

i=1
b∗(i)

j=1

2d(i) + h(nj(i) + 1)

≤2
t(h)

i=1
b∗(i)d(i) + 2nh.
(17.3)
This inequality will be coupled with the following lemma to ﬁnd an almost sure
upper bound on the cost of this heuristic.
Lemma 17.4.5 Under the conditions of Theorem 17.4.1, we have
lim
n→∞
1
n
t(h)

i=1
b∗(i)d(i) ≤γE(d)
(a.s.).
Proof. Let pi .= μ(Ai) be the probability that a given customer xk falls in subregion
Ai. Since pi > 0, by the strong law of large numbers, limn→∞
n(i)
n
= pi almost
surely, and therefore n(i) grows to inﬁnity almost surely as n grows to inﬁnity.
Thus, we have
lim
n→∞
b∗(i)
n(i) =
lim
n(i)→∞
b∗(i)
n(i) = γ
(a.s.).
Hence,
lim
n→∞
1
n
t(h)

i=1
b∗(i)d(i) = lim
n→∞
1
n
t(h)

i=1
b∗(i)
n(i) n(i)d(i)
≤lim
n→∞
1
n
t(h)

i=1
b∗(i)
n(i)

xk∈N(i)
dk [since d(i) ≤dk, ∀xk ∈N(i)]
=
t(h)

i=1
lim
n→∞
b∗(i)
n(i)
lim
n→∞
1
n

xk∈N(i)
dk
= γ lim
n→∞
1
n

xk∈N
dk.

326
17. The Capacitated VRP with Unequal Demands
Using the strong law of large numbers, we have
lim
n→∞
1
n
t(h)

i=1
b∗(i)d(i) ≤γE(d)
(a.s.),
which completes the proof of this lemma.
Remark: A simple modiﬁcation of the proof of Lemma 17.4.5 shows that the ine-
quality that appears in the statement of the lemma can be replaced by equality
(see Exercise 17.5).
We can now ﬁnish the proof of the Theorem 17.4.1. From (17.3), we have
1
nZ∗
u ≤2
n
t(h)

i=1
b∗(i)d(i) + 2h.
Taking the limits and using Lemma 17.4.5, we obtain
lim
n→∞
1
nZ∗
u ≤2γE(d) + 2h
(a.s.).
Since this inequality holds for arbitrarily small h > 0, we have
lim
n→∞
1
nZ∗
u ≤2γE(d)
(a.s.).
This upper bound combined with the lower bound of Lemma 17.4.4 proves the
main theorem.
17.5
Probabilistic Analysis of Classical Heuristics
Bienstock et al. (1993a) analyzed the average performance of heuristics that belong
to the route cluster ﬁrst–class second. Recall our deﬁnition of this class: all those
heuristics that ﬁrst order the customers according to their locations and then
partition this ordering to produce feasible clusters.
It is clear that the UITP(α) and UOP(α) heuristics described in Sect. 17.3 belong
to this class. As mentioned in Sect. 17.2, the sweep algorithm suggested by Gillett
and Miller can also be viewed as a member of this class.
Bienstock et al. show that the performance of any heuristic in this class is
strongly related to the performance of a noneﬃcient bin-packing heuristic called
next-ﬁt (NF). The next-ﬁt bin-packing heuristic can be described in the following
manner. Given a list of n items, start with item 1 and place it in bin 1. Suppose
we are packing item j; let bin i be the highest indexed nonempty bin. If item j
ﬁts in bin i, then place it there; else place it in a new bin indexed i + 1. Thus,
NF is an online heuristic; that is, it assigns items to bins according to the order in
which they appear, without using any knowledge of subsequent items in the list.

17.5 Probabilistic Analysis of Classical Heuristics
327
The NF heuristic possesses some interesting properties that will be useful in
the analysis of the class route ﬁrst–cluster second. Assume the items are indexed
1, 2, . . ., n and let a consecutive heuristic be one that assigns items to bins such
that items in any bin appear consecutively in the sequence. The following is a
simple observation.
Property 17.5.1 Among all consecutive heuristics, NF uses the least number
of bins.
The next property is similar to a property developed in Sect. 5.2 for b∗
n, the
optimal solution to the bin-packing problem.
Property 17.5.2 Let the item sizes w1, w2, . . . , wn, . . . in the bin-packing problem
be a sequence of independent random variables and let bNF
n
be the number of bins
produced by NF on the items 1, 2, . . . , n. For every t ≥0,
Pr

|bNF
n
−E(bNF
n )| > t

≤2 exp(−t2/8n).
(17.4)
A direct result of this property is the following. The proof is left as an exercise
(Exercise 17.2).
Corollary 17.5.3 For any n ≥1,
bNF
n
≤E(bNF
n ) + 4

n log n
(a.s.).
The next property is a simple consequence of the theory of subadditive processes
(see Sect. 5.2) and the structure of solutions generated by NF.
Property 17.5.4 For any distribution of item sizes, there exists a constant γNF >
0 such that limn→∞
bNF
n
n
= γNF almost surely, where bNF
n
is the number of bins
produced by the NF packing and γNF depends only on the distribution of the item
sizes.
These properties are used to prove the following theorem, the main result of this
section.
Theorem 17.5.5
(i) Let H be a route-ﬁrst–cluster-second heuristic. Then, under the assumptions
of Theorem 17.4.1, we have
lim
n→∞
1
nZH ≥2γNFE(d)
(a.s.).
(ii) The UOP(α) heuristic is the best possible heuristic in this class; that is, for
any ﬁxed α ≥1, we have
lim
n→∞
1
nZUOP(α) = 2γNFE(d)
(a.s.).

328
17. The Capacitated VRP with Unequal Demands
In view of Theorems 17.4.1 and 17.5.5, it is interesting to compare γNF to γ
since the asymptotic error of any heuristic H in the class of route ﬁrst–cluster
second satisﬁes
lim
n→∞ZH/Z∗
u ≥lim
n→∞ZUOP(α)/Z∗
u = γNF/γ.
Although in general the ratio is diﬃcult to characterize, Karmarkarwas able to
characterize it for the case when the item sizes are uniformly distributed on an
interval (0, a] for 0 < a ≤1. For instance, for a satisfying 1
2 < a ≤1, we have
γNF/γ = 2
a

1
12a3 (15a3 −9a2 + 3a −1) +
√
2
1 −a
2a

tanh
1 −a
√
2a

,
so that when the item sizes are uniform (0, 1], the above ratio is 4
3, which implies
that UOP(α) converge to a value that is 33.3 % more than the optimal cost, a
very disappointing performance for the best heuristic currently available in terms
of worst-case behavior.
Moreover, heuristics in the route-ﬁrst–cluster-second class can never be asymp-
totically optimal for the UCVRP, except in some trivial cases (e.g., demands are
all the same size). In fact, Theorem 17.5.5 clearly demonstrates that the route-
ﬁrst–cluster-second class suﬀers from misplaced priorities. The routing (in the ﬁrst
phase) is done without any regard to the customer demands, and thus this leads
to a packing of demands into vehicles that is at best like the next-ﬁt bin-packing
heuristic. This is clearly suboptimal in all but trivial cases, one being when cus-
tomers have equal demands, and thus we see the connection with the results of the
previous chapter. Therefore, this theorem shows that an asymptotically optimal
heuristic for the UCVRP must use an asymptotically optimal bin-packing heuristic
to pack the customer demands into the vehicles.
In the next two subsections, we prove Theorem 17.5.5 by developing a lower
bound (Sect. 17.5.1) on ZH and an upper bound on ZUOP(α) (Sect. 17.5.2).
17.5.1
A Lower Bound
In this section, we present a lower bound on the solution produced by these
heuristics. Let H denote a route-ﬁrst–cluster-second heuristic.
As in Sect. 17.4.1, let A be the compact support of the distribution μ, and
deﬁne dmax .= supx∈A{||x||}. Given a ﬁxed integer r ≥1, deﬁne dj = (j −1) dmax
r
for j = 1, 2, . . . , r, and construct the following r sets of customers:
Fj =

xk ∈N
dj < dk

for j = 1, . . . , r.
Note that Fr ⊆Fr−1 ⊆. . . ⊆F1, and F1 = N since, without loss of generality,
dk > 0 for all xk ∈N.
Let the customers be indexed x1, x2, . . . , xn according to the order determined
by the heuristic H in the route-ﬁrst phase.

17.5 Probabilistic Analysis of Classical Heuristics
329
For any set of customers T ⊆N, let bNF(T ) be the number of bins generated
by the next-ﬁt heuristic when applied to the bin-packing problem deﬁned by item
sizes equal to the demands of the customers in T , packed in the order of increasing
index.
Lemma 17.5.6 For any r ≥1,
ZH
n > 2dmax
r
r

j=2
bNF(Fj).
Proof. For a given solution constructed by H, let V (Fj) be the number of vehicles
that serve at least one customer in Fj, for j = 1, 2, . . ., r. By this deﬁnition,
V (Fj) −V (Fj+1), j = 1, 2, . . ., r −1, is exactly the number of vehicles whose
farthest customer visited is in Fj but not in Fj+1, and trivially V (Fr) is the
number of vehicles whose farthest customer visited is in Fr. Hence,
ZH
n > 2drV (Fr) +
r−1

j=1
2dj

V (Fj) −V (Fj+1)

= 2d1V (F1) +
r

j=2
2(dj −dj−1)V (Fj).
For a given subset of customers Fj, j = 1, 2, . . . , r, the V (Fj) vehicles that
contain these customer demands (in the solution produced by H) can be ordered
in such a way that the customer indices are in increasing order. Disregarding the
demands of customers in these vehicles that are not in Fj, this represents the
solution produced by a consecutive packing heuristic on the demands of customers
in Fj. By Property 17.5.1, we must have V (Fj) ≥bNF(Fj), for every j = 1, 2, . . . , r.
This, together with d1 = 0, dj −dj−1 = dmax
r , implies that
ZH
n > 2
r

j=2
dmax
r
bNF(Fj).
This lemma is used to derive an asymptotic lower bound on the cost of the solu-
tion produced by H that holds almost surely. The proof of the lemma is identical
to the proof of Lemma 17.4.4.
Lemma 17.5.7 Under the conditions of Theorem 17.4.1, we have
lim
n→∞
1
nZH
n ≥2γNFE(d)
(a.s.).
In the next section, we show that this lower bound is asymptotically tight in the
case of UOP(α) by presenting an upper bound that approaches the same value.

330
17. The Capacitated VRP with Unequal Demands
17.5.2
The UOP(α) Heuristic
We prove Theorem 17.5.5 by ﬁnding an upper bound on ZUOP(α)
n
. Let Lα be
the length of the α-optimal tour selected by UOP(α). Starting at the depot and
following the tour in an arbitrary orientation, the customers and the depot are
numbered x(0), x(1), x(2), . . . , x(n), where x(0) is the depot. Select an integer m .=
⌈nβ⌉for some ﬁxed β ∈( 1
2, 1), and note that for each such β, we have limn→∞m
n =
0 [i.e., m = o(n)] and limn→∞
√n
m = 0 [i.e., √n = o(m)]. We partition the path
from x(1) to x(n) into m + 1 segments, such that each one contains exactly ⌊n
m⌋
customers, except possibly the last one.
Number the segments 1, 2, . . . , m+1 according to their appearance on the travel-
ing salesman tour, where each segment has exactly ⌊n
m⌋customers except possibly
segment m + 1. Let Li (respectively, Ni) be the length of (respectively, subset of
customers in) segment i, 1 ≤i ≤m + 1. Finally, let ni = |Ni|, i = 1, 2, . . ., m + 1.
To obtain an upper bound on the cost of UOP(α), we apply the next-ﬁt heuristic
to each segment separately, where items are packed in bins in the same order they
appear in the segment. This gives us a partition of the tour that must provide an
upper bound on the cost produced by UOP(α). Let bNF
i
be the number of bins pro-
duced by the next-ﬁt heuristic when applied to the customer demands in segment i.
We assign a single vehicle to each bin produced by the above procedure, each of
which starts at the depot, visits the customers assigned to its corresponding bin
in the same order as they appear on the traveling salesman tour, and then returns
to the depot. Let di be the distance from the depot to the farthest customer in Ni.
Clearly, the total distance traveled by all the vehicles that serve the customers in
segment i, 1 ≤i ≤m + 1, is no more than
2bNF
i
di + Li.
Hence,
ZUOP(α) ≤2
m+1

i=1
bNF
i
di + Lα
≤2
m

i=1
bNF
i
di + 2bNF
m+1dmax + αL∗.
(17.5)
Lemma 17.5.8 Under the conditions of Theorem 17.4.1, we have
lim
n→∞
1
n
m

i=1
bNF
i
di ≤γNFE(d)
(a.s.).
Proof. Since the number of customers in every segment i, 1 ≤i ≤m, is exactly
ni = ⌊n
m⌋and limn→∞m
n = 0, we have for a given i, 1 ≤i ≤m,
bNF
i
≤E(bNF
i
) +

9Kni log ni
(a.s.),
for any K ≥2.

17.5 Probabilistic Analysis of Classical Heuristics
331
We now show that, for suﬃciently large n, these m inequalities hold
simultaneously almost surely. To prove this, note that Property 17.5.2 tells us
that, for ni large enough, the probability that one such inequality does not hold is
no more than 2 exp(−K log ni) = 2n−K
i
. Thus, the probability that at least one of
these inequalities is violated is no more than 2m( n
m −1)−K. By the Borel–Cantelli
lemma, these m inequalities hold almost surely if 
n m(
m
n−m)K < ∞. Choosing
K > 1+β
1−β > 3 shows that this holds for any m = ⌈nβ⌉, where 1
2 < β < 1.
Thus,
lim
n→∞
1
n
m

i=1
bNF
i
di ≤γNF lim
n→∞
m

i=1
1
mdi
(a.s.).
Clearly, di ≤dk + Li for every xk ∈Ni and every i = 1, 2, . . . , m. Thus,
di ≤
. n
m
/−1 
xk∈Ni
dk

+ Li
for every i = 1, 2 . . ., m.
Hence,
lim
n→∞
m

i=1
1
mdi ≤lim
n→∞
1
n −m

xk∈N
dk + lim
n→∞
1
mLα
≤lim
n→∞
1
n −m

xk∈N
dk + α lim
n→∞
1
mL∗.
Applying the strong law of large numbers and using limn→∞m
n = 0, we have
lim
n→∞
1
n −m

xk∈N
dk = E(d)
(a.s.).
Now from Chap. 5, we know that the length of the optimal traveling salesman
tour through a set of k points independently and identically distributed in a given
region grows almost surely like
√
k. This together with limn→∞
√n
m = 0 implies
that
lim
n→∞
L∗
m = 0
(a.s.).
These facts complete the proof.
We can now complete the proof of Theorem 17.4.1. From (17.5) and Lemma 5.2.1,
we have
lim
n→∞
1
nZUOP(α)
n
≤2γNFE(d) + 2dmax lim
n→∞
1
nbNF
m+1 + α lim
n→∞
1
nL∗
(a.s.).
Finally, using Beardwood et al.’s (1959) result (see Theorem 5.3.2) and the fact
that the number of points in segment m + 1 is at most
n
m, we obtain the desired
result.

332
17. The Capacitated VRP with Unequal Demands
17.6
The Uniform Model
To our knowledge, no polynomial-time algorithm that is asymptotically optimal
is known for the UCVRP for general Φ. We now describe such a heuristic for the
case where Φ is uniform on the interval [0, 1]. In the unit interval, it is known that
there exists an asymptotically optimal solution to the bin-packing problem with
at most two items per bin. This forms the basis for the heuristic for the UCVRP,
called optimal matching of pairs (OMP). It considers only feasible solutions in
which each vehicle visits no more than two customers. Among all such feasible
solutions, the heuristic ﬁnds the one with the minimum cost. This can be done by
formulating the following integer linear program.
For every xk, xl ∈N, let
ckl =
⎧
⎪
⎨
⎪
⎩
dk + dkl + dl,
if k ̸= l and wk + wl ≤1;
2dk,
if k = l;
∞,
otherwise.
The integer program to solve is
Problem P :
Min

k≤l
cklXkl
s.t. 
l≥k
Xkl +

l<k
Xlk = 1,
∀k = 1, 2, . . . , n,
(17.6)
Xkl ∈{0, 1},
∀k ≤l.
(17.7)
For k < l, Xkl is 1 if a vehicle delivers items to customers xk and xl and is 0
otherwise. Constraint (17.6) ensures that each customer is visited.
It is not hard to see that P can be solved in polynomial time since it is no more
than a classical weighted matching problem deﬁned on a speciﬁc graph. Deﬁne the
following graph G = (N, E), where each customer xk is represented by two nodes
vk and v′
k, for k = 1, 2, . . . , n. The set of edges of G is deﬁned as follows:
E ={(vk, v′
k)|xk ∈N}
∪{(vk, vl)|xk ∈N, xl ∈N, k ̸= l, wk + wl ≤1}
∪{(v′
k, v′
l)|xk ∈N, xl ∈N, k ̸= l, wk + wl ≤1}.
Thus, G has 2n vertices. The length of edge (vk, vl), for k ̸= l, is ckl, of edge
(vk, v′
k) is ckk, and of edge (v′
k, v′
l) is 0, for all k and l.
Note that any given feasible solution to P can be transformed into a feasible
solution to the matching problem on G with the same cost. For any feasible solution
to P, choose edge (vk, v′
k) if customer k is served by a vehicle that does not serve
any other customer and choose edges (vk, vl) and (v′
k, v′
l) if customers xk and xl

17.6 The Uniform Model
333
are visited together. Similarly, any feasible solution to the matching problem can
be transformed into a feasible solution to P with the same cost. Hence, the two
problems are equivalent.
An optimal matching in G can be found in O(n3) using Lawler’s (1976) algorithm.
The main result of this section is the following.
Theorem 17.6.1 Let xk, k = 1, 2, . . . , n, be a sequence of independent random
variables having a distribution μ with compact support in IR2. Let
E(d) =

IR2 ||x||dμ(x).
Let the demands wk, k = 1, 2, . . . , n, be a sequence of independent random variables
having a uniform distribution on [0, 1], and assume that the demands and the
location of the customers are independent of each other. Then, the OMP heuristic
is asymptotically optimal. That is, with probability 1,
lim
n→∞
Z∗
u
n = lim
n→∞
ZOMP
n
= E(d).
To prove that the OMP heuristic is asymptotically optimal, we approximate its
performance by that of the sliced region-partitioning heuristic with parameters h
and r (SRP(h, r)). For any ﬁxed positive integer r ≥1, the set N is partitioned
into the following 2r disjoint subsets, some of which may be empty:
Nj =

xk ∈N
1
2

1 −j + 1
r

< wk ≤1
2

1 −j
r

,
j = 1, 2, . . . , r −1,
and
N j =

xk ∈N
1
2

1 + j −1
r

< wk ≤1
2

1 + j
r

,
j = 1, 2, . . ., r −1.
Also,
N0 =

xk ∈N
1
2

1 −1
r

< wk ≤1
2

and
N r =

xk ∈N
1
2

1 + r −1
r

< wk

.
The number of customers in each Nj (respectively, N j) is denoted by nj (respec-
tively, nj) for all possible values of j.
Note that for any j = 1, 2, . . . , r −1, one vehicle can deliver the demand of a
customer from Nj together with the demand of exactly one customer from N j.
The SRP(h, r) heuristic generates pairs of customers, one customer from Nj and
one from N j, for every j = 1, 2, . . ., r−1, using the same region-partitioning scheme
used in the proof of Theorem 17.4.1 (Sect. 17.4.2). The customers in N0 ∪N r are
served separately; a single vehicle is assigned to each of these customers.

334
17. The Capacitated VRP with Unequal Demands
For every subregion Ai, i = 1, 2, . . ., t(h), generated by the grid G(h) (see
Sect. 17.4.2) and for every j = 1, 2, . . . , r −1, let Nj(i) [respectively, N j(i)] be
the subset of points in Nj (respectively, N j) that fall in subregion Ai. Also, let
nj(i) = |Nj(i)| and nj(i) = |N j(i)|.
In each subregion Ai, i = 1, 2, . . ., t(h), and for any j = 1, 2, . . ., r −1, we arbi-
trarily match one customer from Nj(i) with exactly one customer from N j(i); one
vehicle serves each such pair. If nj(i) = nj(i), then all customers in Nj(i) ∪N j(i)
are matched and therefore visited in pairs. If, however, nj(i) ̸= nj(i), then we can
match exactly min{nj(i), nj(i)} pairs of customers. The remaining |nj(i) −nj(i)|
customers in Nj(i)∪N j(i) that have not yet been matched are each served by one
vehicle. Thus, the total number of vehicles used in subregion Ai is
n0(i) + nr(i) +
r−1

j=1
max{nj(i), nj(i)}.
The heuristic clearly generates a feasible solution to the UCVRP. Moreover, this
solution is feasible for P, as each vehicle visits at most two customers. Thus,
ZOMP ≤ZSRP (h,r)
for any r ≥1 and h > 0.
We now proceed by ﬁnding an upper bound on ZSRP (h,r). Essentially the same
analysis as in Sect. 17.4.2 shows that the total distance traveled by all vehicles is
no more than
2
t(h)

i=1
d(i)

n0(i) + nr(i) +
r−1

j=1
max{nj(i), nj(i)}

+ 2nh.
Since
lim
n(i)→∞
nj(i)
n(i) =
lim
n(i)→∞
nj(i)
n(i) = 1
2r
(a.s.)
for all j = 1, 2, . . . , r,
we have
lim
n(i)→∞
1
n(i)

n0(i) + nr(i) +
r−1

j=1
max{nj(i), nj(i)}

= 1
2 + 1
2r
(a.s.).
The remainder of the proof is identical to the proof of the upper bound of
Theorem 17.4.1.
Therefore, the OMP is asymptotically optimal when demands are uniformly
distributed between 0 and 1. In fact, the proof can be extended to a larger class of
demand distributions. For example, for any demand distribution with symmetric
density, one with f(x) = f(1 −x) for x ∈[0, 1], one can show that the same result
holds.

17.7 The Location-Based Heuristic
335
17.7
The Location-Based Heuristic
Bramel and Simchi-Levi (1995) used the insight obtained from the analysis of the
asymptotic optimal solution value (see Theorem 17.4.1 above and the discussion
that follows it) to develop a new and eﬀective class of heuristics for the UCVRP
called location-based heuristics. Speciﬁcally, this class of heuristics was motivated
by the following observations.
A byproduct of the proof of Theorem 17.4.1 is that the region-partitioning
scheme used to ﬁnd an upper bound on Z∗
u is asymptotically optimal. Unfor-
tunately, the scheme is not polynomial since it requires, among other things,
optimally solving the bin-packing problem. But, the scheme suggests that, asymp-
totically, the tours in an optimal solution will be of a very simple structure con-
sisting of two parts. The ﬁrst is the round trip the vehicle makes from the depot
to the subregion (where the customers are located); we call these the simple tours.
The second is the additional distance (we call this insertion cost) accrued by vis-
iting each of the customers it serves in the subregion. Our goal is therefore to
construct a heuristic that assigns customers to vehicles so as to minimize the sum
of the length of all simple tours plus the total insertion costs of customers into each
simple tour. If done carefully, the solution obtained is asymptotically optimal.
To construct such a heuristic, we formulate the routing problem as another
combinatorial problem commonly called [see, e.g., Pirkul (1987)] the single-source
capacitated facility location problem (CFLP). This problem can be described as
follows: Given m possible sites for facilities of ﬁxed capacity Q, we would like to
locate facilities at a subset of these m sites and assign n retailers, where retailer i
demands wi units of a facility’s capacity, in such a way that each retailer is assigned
to exactly one facility, the facility capacities are not exceeded, and the total cost
is minimized. A site-dependent cost is incurred for locating each facility; that is,
if a facility is located at site j, the setup cost is vj, for j = 1, 2, . . . , m. The cost of
assigning retailer i to facility j is cij (the assignment cost), for i = 1, 2, . . ., n and
j = 1, 2, . . . , m.
The single-source CFLP can be formulated as the following integer linear pro-
gram. Let
yj =

1,
if a facility is located at site j,
0,
otherwise,
and let
xij =

1,
if retailer i is assigned to a facility at site j,
0,
otherwise.
Problem CFLP : Min
n

i=1
m

j=1
cijxij +
m

j=1
vjyj
s.t.
m

j=1
xij = 1,
∀i,
(17.8)

336
17. The Capacitated VRP with Unequal Demands
n

i=1
wixij ≤Q,
∀j,
(17.9)
xij ≤yj,
∀i, j,
(17.10)
xij ∈{0, 1},
∀i, j,
(17.11)
yj ∈{0, 1},
∀j.
(17.12)
Constraints (17.8) ensure that each retailer is assigned to exactly one facility,
and constraints (17.9) ensure that the facility’s capacity constraint is not violated.
Constraints (17.10) guarantee that if a retailer is assigned to site j, then a facility
is located at that site. Constraints (17.11) and (17.12) ensure the integrality of the
variables.
In formulating the UCVRP as an instance of the CFLP, we set every customer
xj in the UCVRP as a possible facility site in the location problem. The length
of the simple tour that starts at the depot visits customer xj and then goes back
to the depot is the setup cost in the location problem (i.e., vj = 2dj). Finally, the
cost of inserting a customer into a simple tour in the UCVRP is the assignment
cost in the location problem (i.e., cij = di + dij −dj). This cost should represent
the added cost of inserting customer i into a simple tour through the depot and
customer j. Consequently, when i is added to a tour with j, the added cost is
cij = di +dij −dj, so that vj +cij = di +dij +dj. However, when a third customer
is added, the calculation is not so simple, and therefore, the values of cij should, in
fact, represent an approximation to the cost of adding i to a tour that goes through
customer j and the depot. Hence, ﬁnding a solution for the CVRP is obtained by
solving the CFLP with the data as described above. The solution obtained from
the CFLP is transformed (in an obvious way) to a solution to the CVRP.
Although NP-Hard, the CFLP can eﬃciently, but approximately, be solved by
the familiar Lagrangian relaxation technique (see Chap. 15), as described in Pirkul
or Bramel and Simchi-Levi (1995), or by a cutting-plane algorithm, as described
in Deng and Simchi-Levi (1992).
We can now describe the location-based heuristic (LBH):
The Location-Based Heuristic
Step 1: Formulate the UCVRP as an instance of the CFLP.
Step 2: Solve the CFLP.
Step 3: Transform the solution obtained in step 2 into a solution for the UCVRP.
Variations of the LBH can also be applied to other problems; we discuss this
and related issues in the next chapter, where we consider a more general vehicle
routing problem.
The LBH algorithm was tested on a set of 11 standard test problems taken from
the literature. The problems are in the Euclidean plane, and they vary in size from
15 to 199 customers. The performance of the algorithm on these test problems
was found to be comparable to the performance of most published heuristics. This

17.8 Rate of Convergence to the Asymptotic Value
337
includes both the running time of the algorithm as well as the quality (value) of
the solutions found; see Bramel and Simchi-Levi (1995) for a detailed discussion.
One way to explain the excellent performance of the LBH is by analyzing its
average performance. Indeed, a proof similar to the proof of Theorem 17.4.1 reveals
[see also Bramel and Simchi-Levi (1995)] that
Theorem 17.7.1 Under the assumptions of Theorem 17.4.1, there are versions
of the LBH that are asymptotically optimal; that is,
lim
n→∞
1
nZLBH = 2γE(d)
(a.s).
Finally, we observe that the generalized assignment heuristic due to Fisher and
Jaikumar (1981) can be viewed as a special case of the LBH in which the seed
customers are selected by a dispatcher. In the second step, customers are assigned
to the seeds in an eﬃcient way by solving a generalized assignment problem. The
advantage of the LBH is that the selection of the seeds and the assignment of
customers to seeds are done simultaneously, and not sequentially as in the gener-
alized assignment heuristic. Note that neither of these heuristics (the LBH or the
generalized assignment heuristic) requires that potential seed points be customer
locations; both can be easily implemented to start with seed points that are sim-
ply points on the plane. A byproduct of the analysis, therefore, is that when the
generalized assignment heuristic is carefully implemented (i.e., “good” seeds are
selected), it is asymptotically optimal as well.
17.8
Rate of Convergence to the Asymptotic Value
While the results in the two previous sections completely characterize the asymp-
totic optimal solution value of the UCVRP, they do not say anything about the
rate of convergence to the asymptotic solution value. See Psaraftis (1984) for an
informal discussion of this issue.
To get some intuition on the rate of convergence, it is interesting to determine the
expected diﬀerence between the optimal solution for a given number of customers
n, and the asymptotic solution value (i.e., 2γE[d]). This can be done for the
uniform model discussed in Sect. 17.6.
In this case, Bramel et al. (1991) and, independently, Rhee (1991) proved the
following strong result.
Theorem 17.8.1 Let xk, k = 1, 2, . . . , n, be a sequence of independent random
variables uniformly distributed in the unit square [0, 1]2. Let the demands wk, k =
1, 2, . . ., n, be drawn independently from a uniform distribution on (0, 1]. Then
E[Z∗
n] = nE[d] + Θ(n2/3).
The proof of Theorem 17.8.1 relies heavily on the theory of three-dimensional
stochastic matching, which is outside the scope of our survey. We refer the reader to
Coﬀman and Lueker (1991, Chap. 3) for an excellent review of matching problems.

338
17. The Capacitated VRP with Unequal Demands
Rhee has also found an upper bound on the rate of convergence to the asymptotic
solution value, for general distribution of the customers’ locations and their
demands. Using a new matching theorem developed together with Talagrand, she
proved
Theorem 17.8.2 Under the assumptions of Theorem 17.4.1, we have
2nγE[d] ≤E[Z∗
n] ≤2nγE[d] + O((n log n)2/3).
17.9
Exercises
Exercise 17.1.
Consider the following heuristic for the CVRP with unequal
demands. All customers of demand wi > 1
2 are served individually, one customer
per vehicle. To serve the rest, apply the UITP heuristic with vehicle capacity Q.
Prove that this solution can be transformed into a feasible solution to the CVRP
with unequal demands. What is the worst-case bound of this heuristic?
Exercise 17.2.
Prove Corollary 17.5.3.
Exercise 17.3.
Given a seed point i, assume you must estimate the cost of the
optimal traveling salesman tour through a set of points S ∪{i} using the following
cost approximation. Starting with 2di, when each point j is added to the tour, add
the cost cij = dj + dij −di. That is, show that for any r ≥1, there is an example
where the approximation is r times the optimal cost.
Exercise 17.4.
Construct an example of the single-source CFLP where each
facility is a potential site (and vice versa) in which an optimal solution chooses a
facility, but the demand of that facility is assigned to another chosen site.
Exercise 17.5.
Show that Lemma 17.4.5 can be replaced by an equality instead
of an inequality.
Exercise 17.6.
Prove that the version of the LBH with setup costs vj = 2dj and
assignment costs cij = di + dij −dj is asymptotically optimal.
Exercise 17.7.
Explain why the following constraints can or cannot be inte-
grated into the savings algorithm.
(a) Distance constraint. Each route must be at most λ miles long.
(b) Minimum route size. Each route must pick up at least m points.
(c) Mixing constraints. Even indexed points cannot be on the same route as odd
indexed points.

17.9 Exercises
339
Exercise 17.8.
Consider an instance of the CVRP with n customers. A customer
is red with probability p and blue with probability 1 −p, for some p ∈[0, 1]. Red
customers have loads of size 2
3, while blue customers have loads of size 1
3. What is
limn→∞Z∗
n as a function of p?

18
The VRP with Time-Window Constraints
18.1
Introduction
In many distribution systems, in addition to the load that has to be delivered to it,
each customer speciﬁes a period of time, called a time window, in which this deliv-
ery must occur. The objective is to ﬁnd a set of routes for the vehicles, where each
route begins and ends at the depot, that serves a subset of the customers without
violating the vehicle capacity and time-window constraints, while minimizing the
total length of the routes. We call this model the vehicle routing problem with
time windows (VRPTW).
Due to the wide applicability and the economic importance of the problem,
variants of it have been extensively studied in the vehicle routing literature; for a
review, see Solomon and Desrosiers (1988). Most of the work on the problem has
focused on an empirical analysis, while very few papers have studied the problem
from an analytical point of view. This is done in an attempt to characterize the
theoretical behavior of heuristics and to use the insights obtained to construct
eﬀective algorithms. Some exceptions are the recent works of Federgruen and van
Ryzin (1997) and Bramel and Simchi-Levi (1996). Here we describe the results of
the latter paper.
18.2
The Model
To formally describe the model we analyze here, let the index set of the n customers
be denoted N = {1, 2, . . ., n}. Let xk ∈IR2 be the location of customer k ∈N.
Assume, without loss of generality, that the depot is at the origin and, by rescaling,
D. Simchi-Levi et al., The Logic of Logistics: Theory, Algorithms, and Applications
for Logistics Management, Springer Series in Operations Research and Financial Engineering,
DOI 10.1007/978-1-4614-9149-1 18, © Springer Science+Business Media New York 2014
341

342
18. The VRP with Time-Window Constraints
that the vehicle capacity is 1 and that the length of the working day is 1. We assume
vehicles can leave and return to the depot at any time. Associated with customer
k is a quadruplet (wk, ek, sk, lk), called the customer parameters, which represents,
respectively, the load that must be picked up, the earliest starting time for service,
the time required to complete the service, called the service time, and the latest
time service can end. Clearly, feasibility requires that ek + sk ≤lk and wk, ek, lk ∈
[0, 1], for each k ∈N.
For any point x ∈IR2, let ∥x∥denote the Euclidean distance between x and the
depot. Let dk .= ∥xk∥be the distance between customer k and the depot. Also, let
djk .= ∥xj −xk∥be the distance between customer j and customer k. Let Z∗
t be
the total distance traveled in an optimal solution to the VRPTW, and let ZH
t be
the total distance traveled in the solution provided by a heuristic H.
Consider the customer locations to be distributed according to a distribution μ
with compact support in IR2. Let the customer parameters {(wk, ek, sk, lk) : k ∈
N} be drawn from a joint distribution Φ with a continuous density φ. Let C be the
support of φ; that is, C is a subset of {(a1, a2, a3, a4) ∈[0, 1]4 : a2+a3 ≤a4}. Each
customer is therefore represented by its location in the Euclidean plane along with
a point in C. Finally, we assume that a customer’s location and its parameters are
independent of each other.
In our analysis we associate a job with each customer. The parameters of job
k are the parameters of customer k, that is, (wk, ek, sk, lk), where wk is referred
to as the load of job k and, using standard scheduling terminology, ek represents
the earliest time job k can begin processing, sk represents the processing time
and lk denotes the latest time the processing of the job can end. The value of ek
can be thought of as the release time of job k, that is, the time it is available for
processing. The value of lk represents the due date for the job. Each job can be
viewed abstractly as simply a point in C. Occasionally, we will refer to customers
and jobs interchangeably; this convenience should cause no confusion.
To any set of customers T ⊆N with parameters {(wk, ek, sk, lk) : k ∈T }, we
associate a corresponding machine scheduling problem as follows. Consider the set
of jobs T and an inﬁnite sequence of parallel machines. Job k becomes available for
processing at time ek and must be ﬁnished processing by time lk. The objective
in this scheduling problem is to assign each job to a machine such that (i) each
machine has at most one job being processed on it at a given time, (ii) the pro-
cessing time of each job starts no earlier than its release time and ends no later
than its due date, and (iii) the total load of all jobs assigned to a machine is no
more than 1, and the number of machines used is minimized. In our discussion
we refer to (ii) as the job time-window constraint and to (iii) as the machine load
constraint.
Scheduling problems have been widely studied in the operations research liter-
ature; see Lawler et al. (1993) and Pinedo (1995). Unfortunately, no paper has
considered the scheduling problem in its general form with the objective function
of minimizing the number of machines used.
Observe that in the absence of time window constraints, the scheduling problem
is no more than a bin-packing problem. Indeed, in that case, the VRPTW reduces

18.3 The Asymptotic Optimal Solution Value
343
to the model analyzed in the previous chapter, the CVRP. Thus, our strategy is
to try to relate the machine scheduling problem to the VRPTW in much the same
way as we used results obtained for the bin-packing problem in the analysis of the
CVRP. As we shall shortly see, this is much more complex.
Let M ∗(S) be the minimum number of machines needed to schedule a set S of
jobs. It is clear that this machine scheduling problem possesses the subadditivity
property, described in Sect. 5.2. This implies that if M ∗
n is the minimum number
of machines needed to schedule a set of n jobs whose parameters are drawn inde-
pendently from a distribution Φ, then there exists a constant γ > 0 (depending
only on Φ) such that limn→∞M ∗
n/n = γ (a.s.).
In this chapter, we relate the solution to the VRPTW to the solution to the
scheduling problem deﬁned by the customer parameters. That is, we show that
asymptotically the VRPTW is no more diﬃcult to solve than the corresponding
scheduling problem. Our main result is the following.
Theorem 18.2.1 Let x1, x2, . . . , xn be independently and identically distributed
according to a distribution μ with compact support in IR2, and deﬁne
E(d) =

IR2 ∥x∥dμ(x).
Let the customer parameters {(wk, ek, sk, lk) : k ∈N} be drawn independently
from Φ. Let M ∗
n be the minimum number of machines needed to feasibly schedule
the n jobs corresponding to these parameters, and limn→∞
M∗
n
n = γ (a.s.). Then
lim
n→∞
1
nZ∗
t = 2γE(d)
(a.s.).
We prove this theorem (in Sect. 18.3) by introducing a lower bound on the
optimal solution value and then developing an upper bound that converges to
the same value. The lower bound uses a similar technique to the one developed
in Chap. 17. The upper bound can be viewed as a randomized algorithm that
is guaranteed to generate a feasible solution to the problem. That is, diﬀerent
runs of the algorithm on the same data may generate diﬀerent feasible solutions.
In Sect. 18.4, we show that the analysis leads, in a natural way, to the development
of a new deterministic algorithm that is asymptotically optimal for the VRPTW.
Though not polynomial, computational evidence shows that the algorithm works
very well on a set of standard test problems.
18.3
The Asymptotic Optimal Solution Value
We start the analysis by introducing a lower bound on the optimal objective
function value Z∗
t . First, let A be the compact support of μ, and deﬁne dmax .=
sup{∥x∥: x ∈A}. Pick a ﬁxed integer r ≥1, and deﬁne dj
.= (j −1) dmax
r
, for
j = 1, 2, . . . , r. Now deﬁne the sets:
Fj =

k ∈N| dj < dk

for j = 1, 2, . . ., r.

344
18. The VRP with Time-Window Constraints
For any set T ⊆N, let M ∗(T ) be the minimum number of machines needed to
feasibly schedule the set of jobs {(wk, ek, sk, lk) : k ∈T }. The next lemma provides
a deterministic lower bound on Z∗
t and is analogous to Lemma 17.4.3 developed
for the VRP with capacity constraints.
Lemma 18.3.1
Z∗
t > 2dmax
r
r

j=2
M ∗(Fj).
Proof. Let V ∗
j be the number of vehicles in an optimal solution to the VRPTW
that serve a customer from Fj, for j = 1, 2, . . . , r. By this deﬁnition, V ∗
r is exactly
the number of vehicles whose farthest customer visited is in Fr, and V ∗
j −V ∗
j+1
is exactly the number of vehicles whose farthest customer visited is in Fj \ Fj+1.
Observe that if V ∗
j = V ∗
j+1, then there are no vehicles whose farthest customer
visited is in Fj \ Fj+1. Consequently,
Z∗
t > 2drV ∗
r +
r−1

j=1
2dj(V ∗
j −V ∗
j+1)
= 2d1V ∗
1 +
r

j=2
2(dj −dj−1)V ∗
j
= 2dmax
r
r

j=2
V ∗
j .
We now claim that for each j = 1, 2, . . . , r, V ∗
j ≥M ∗(Fj). This should be clear
from the fact that the set of jobs in Fj can be feasibly scheduled on V ∗
j machines
by scheduling the jobs at the times they are served in the VRPTW solution.
We can now determine the asymptotic value of this lower bound. This can be
done in a similar manner to that of Chap. 17, and hence we omit the proof here.
Lemma 18.3.2 Under the conditions of Theorem 18.2.1,
lim
n→∞
1
nZ∗
t ≥2γE(d)
(a.s.).
We prove Theorem 18.2.1 by approximating the optimal cost from above by that
of the following four-step heuristic. In the ﬁrst step, we partition the region where
the customers are distributed into subregions. In the second step, we randomly
separate the customers of each subregion into two sets. Then for each subregion,
we solve a machine scheduling problem deﬁned on the customers in one of these
sets. Finally, we use this schedule to specify how to serve all the customers in the
subregion.
Pick an ϵ > 0, and let δ be given by the deﬁnition of continuity of φ; that is,
δ > 0 is such that for all x, y ∈C with ||x −y|| < δ, we have |φ(x) −φ(y)| < ϵ.
Finally, pick a Δ < min{ δ
√
2, ϵ}.

18.3 The Asymptotic Optimal Solution Value
345
Let G(Δ) be an inﬁnite grid of squares of diagonal Δ, that is, of side
Δ
√
2, with
edges parallel to the system coordinates. Recall that A is the compact support of
μ, and let A1, A2, . . . , At(Δ) be the subregions of G(Δ) that intersect A and have
μ(Ai) > 0.
Let N(i) be the indices of the customers located in subregion Ai, and deﬁne
n(i) = |N(i)|. For each customer k ∈N(i), with parameters (wk, ek, sk, lk), we
associate a job with parameters (wk, ek, sk + Δ, lk + Δ). For any set T ⊆N of
customers, let M ∗
Δ(T ) be the minimum number of machines needed to feasibly
schedule the set of jobs {(wk, ek, sk + Δ, lk + Δ) : k ∈T }. In addition, for any set
T of customers, let T (i) = N(i) ∩T , for i = 1, 2, . . ., t(Δ).
For the given grid partition and for any set T ⊆N of customers, the following
is a feasible way to serve the customers in N. All subregions are served separately;
that is, no customers from diﬀerent subregions are served by the same vehicle.
In subregion Ai, we solve the machine scheduling problem deﬁned by the jobs
{(wk, ek, sk + Δ, lk + Δ) : k ∈T (i)}. Then, for each machine in this scheduling
solution, we associate a vehicle that serves the customers corresponding to the jobs
on that machine. The customers are visited in the exact order they are processed
on the machine, and they are served in exactly the same interval of time as they
are processed. This is repeated for each machine of the scheduling solution. The
customers of the set N(i)\T (i) are served one vehicle per customer. This strategy
is repeated for every subregion, thus providing a solution to the VRPTW.
We will show that for a suitable choice of the set T , this routing strategy is
asymptotically optimal for the VRPTW. An interesting fact about the set T is
that it is a randomly generated set; that is, each time the algorithm is run, it
results in diﬀerent sets T .
The ﬁrst step is to show that, for any set T ⊆N (possibly empty), the solu-
tion produced by the above-mentioned strategy provides a feasible solution to the
VRPTW. This should be clear from the fact that having an extra Δ units of time
to travel between customers in a subregion is enough since all subregions have
diagonal Δ. Therefore, any sets of customers scheduled on a machine together can
be served together by one vehicle. Customers of N(i) \ T can clearly be served
within their time windows since they are served individually, one per vehicle.
We now proceed to ﬁnd an upper bound on the value of this solution. For each
subregion Ai, let nj(i) be the number of jobs on the jth machine in the optimal
schedule of the jobs in T (i), for each j = 1, 2, . . . , M ∗
Δ(T (i)). Let d(i) be the
distance from the depot to the closest customer in N(i), that is, in subregion Ai.
Using the routing strategy described above, we specify that the distance traveled
by the vehicle serving the customers whose job was assigned to the jth machine
of subregion Ai is no more than
2d(i) + Δ(nj(i) + 1).

346
18. The VRP with Time-Window Constraints
Therefore,
Z∗
t ≤
t(Δ)

i=1
M∗
Δ(T (i))

j=1

2d(i) + Δ(nj(i) + 1)

+

k /∈T
2dk
≤2
t(Δ)

i=1
M ∗
Δ(T (i))d(i) + 2nΔ +

k /∈T
2dk.
Dividing by n and taking the limit, we have
lim
n→∞
1
nZ∗
t ≤2
t(Δ)

i=1
lim
n→∞
1
nM ∗
Δ(T (i))d(i) + 2Δ + lim
n→∞
1
n

k /∈T
2dk
= 2
t(Δ)

i=1
lim
n→∞
n(i)
n
M ∗
Δ(T (i))
n(i)
d(i) + 2Δ + lim
n→∞
1
n

k /∈T
2dk
≤2
t(Δ)

i=1
lim
n→∞
n(i)
n
lim
n→∞
M ∗
Δ(T (i))
n(i)
d(i) +
2Δ + lim
n→∞
1
n

k /∈T
2dk.
(18.1)
In order to relate this quantity to the lower bound of Lemma 18.3.2, we must
choose the set T appropriately. For this purpose, we make the following obs-
ervation. Recall that φ is the continuous density associated with the distribu-
tion Φ. The customer parameters (wk, ek, sk, lk) of each of the customers of N
are drawn randomly from the density φ. Associated with each customer is a job
whose parameters are perturbed by Δ in the third and fourth coordinates, that is,
(wk, ek, sk +Δ, lk +Δ). This is equivalent to randomly drawing the job parameters
from a density that we call φ′. The density φ′ can be found simply by translating φ
by Δ in the third and fourth coordinates, that is, for each x = (θ1, θ2, θ3, θ4) ∈IR4,
φ′(x) = φ′(θ1, θ2, θ3, θ4) = φ(θ1, θ2, θ3−Δ, θ4−Δ). Finally, for each x ∈IR4, deﬁne
ψ(x) .= min{φ(x), φ′(x)} and let q .=

IR4 ψ < 1.
The n jobs (or customer parameters) {yk .= (wk, ek, sk + Δ, lk + Δ) : k ∈N}
are drawn randomly from the density φ′, and our task is to select the set T ⊆N.
To simplify presentation, we refer interchangeably to the index set of jobs and to
the set of jobs itself; that is, k ∈N will have the same interpretation as yk ∈N,
where yk .= (wk, ek, sk + Δ, lk + Δ).
For each job yk, generate a random value, call it uk, uniformly in [0, φ′(yk)]. The
point (yk, uk) ∈IR5 is a point below the graph of φ′; that is, uk ≤φ′(yk). Deﬁne
T as the set of indices of jobs whose uk value falls below the graph of φ; that is,
T .= {k ∈N : uk ≤φ(yk)}. Then the set of jobs {yk : k ∈T } can be viewed as a
random sample of |T | jobs drawn randomly from the density ψ
q .

18.3 The Asymptotic Optimal Solution Value
347
In order to relate this upper bound to the lower bound, we need to present the
following lemma.
Lemma 18.3.3 For
T
generated
as
above
and
for
each
subregion
Ai,
i = 1, 2, . . . , t(Δ),
lim
n→∞
M ∗
Δ(T (i))
n(i)
≤γ,
(a.s.).
Proof. To prove the result for a given subregion Ai, we construct a feasible schedule
for the set of jobs {yk = (wk, ek, sk + Δ, lk + Δ) : k ∈T (i)}. Generate n(i) −|T (i)|
jobs randomly from the density
1
1 −q [φ −ψ].
Call this set of jobs D, for dummy jobs. From the construction of the sets D and
T (i), it is a simple exercise to show that the parameters of the jobs in D ∪T (i)
are distributed like φ.
A feasible schedule of the jobs in T (i) is obtained by optimally scheduling the
jobs in D ∪T (i) using, say, Mi machines. The number of machines needed to
schedule the jobs in T (i) is obviously no more than Mi, since the jobs in D can
simply be ignored. Thus, we have the bound
M ∗
Δ(T (i)) ≤Mi.
Now dividing by n(i) and taking the limits, we get
lim
n→∞
M ∗
Δ(T (i))
n(i)
≤lim
n→∞
Mi
n(i) = γ, (a.s.),
since the set of jobs D ∪T (i) is just a set of n(i) jobs whose parameters are drawn
independently from the density φ.
Lemma 18.3.3 thus reduces (18.1) to
lim
n→∞
1
nZ∗
t ≤2
t(Δ)

i=1
γ lim
n→∞
n(i)
n d(i) + 2Δ + lim
n→∞
1
n

k /∈T
2dk
= 2γ lim
n→∞
1
n
t(Δ)

i=1
n(i)d(i) + 2Δ + lim
n→∞
1
n

k /∈T
2dk
≤2γ lim
n→∞
1
n

k∈N
dk + 2Δ + lim
n→∞
1
n

k /∈T
2dk
= 2γE(d) + 2Δ + lim
n→∞
1
n

k /∈T
2dk
≤2γE(d) + 2Δ + 2dmax lim
n→∞
1
n|N \ T |.
The next lemma determines an upper bound on limn→∞1
n|N \ T |.

348
18. The VRP with Time-Window Constraints
Lemma 18.3.4 Given ϵ > 0 and T generated as above,
lim
n→∞
1
n|N \ T | < (1 + ϵ)2ϵ
(a.s.).
Proof. By the strong law of large numbers, the limit is equal to the probability
that a job of N is not in the set T . The probability of a particular job yk not being
in T is simply
⎧
⎪
⎨
⎪
⎩
φ′(yk)−φ(yk)
φ′(yk)
,
if φ′(yk) ≥φ(yk),
0,
otherwise.
Hence, almost surely,
lim
n→∞
1
n|N \ T | =

IR4 max
φ′(x) −φ(x)
φ′(x)
, 0

φ′(x)dx
≤

IR4
φ′(x) −φ(x)
φ′(x)
φ′(x)dx
=

IR4 |φ′(x) −φ(x)|dx
=

IR4 |φ′(θ1, θ2, θ3, θ4) −φ(θ1, θ2, θ3, θ4)|d(θ1, θ2, θ3, θ4)
=

IR4|φ(θ1, θ2, θ3−Δ, θ4−Δ)−φ(θ1, θ2, θ3, θ4)|d(θ1, θ2, θ3, θ4)
< (1 + Δ)2ϵ
< (1 + ϵ)2ϵ,
where the second-to-last inequality follows from ∥(θ1, θ2, θ3 −Δ, θ4 −Δ) −(θ1, θ2,
θ3, θ4)∥≤Δ
√
2 < δ and the continuity of φ.
We now have all the necessary ingredients to ﬁnish the proof of Theorem 18.2.1;
thus,
lim
n→∞
1
nZ∗
t ≤2γE(d) + 2dmax(1 + ϵ)2ϵ + 2Δ
(a.s.).
Since ϵ was arbitrary, and recalling that Δ < ϵ, we have
lim
n→∞
1
nZ∗
t ≤2γE(d)
(a.s.).
This upper bound combined with the lower bound proves Theorem 18.2.1.

18.4 An Asymptotically Optimal Heuristic
349
18.4
An Asymptotically Optimal Heuristic
In this section, we generalize the LBH heuristic developed for the CVRP (see
Chap. 17) to handle time window constraints. Similar to the original LBH, we
prove that the generalized version is asymptotically optimal for the VRPTW.
We refer to this more general version of the heuristic also as the location-based
heuristic; this should cause no confusion.
18.4.1
The Location-Based Heuristic
The LBH can be viewed as a three-step algorithm. In the ﬁrst step, the parame-
ters of the VRPTW are transformed into data for a location problem called the
capacitated vehicle location problem with time windows (CVLPTW), described
below. This location problem is solved in the second step. In the ﬁnal step, we
transform the solution to the CVLPTW into a feasible solution to the VRPTW.
The Capacitated Vehicle Location Problem with Time Windows
The capacitated vehicle location problem with time windows (CVLPTW) is
a generalization of the single-source capacitated facility location problem (see
Sect. 17.7) and can be described as follows: We are given m possible sites to locate
vehicles of capacity Q. There are n customers geographically dispersed in a given
region, where customer i has wi units of product that must be picked up by a
vehicle. The pickup of customer i takes si units of time and must occur in the
time window between times ei and li; that is, the service of customer i can start
at any time t ∈[ei, li −si]. The objective is to select a subset of the possible sites,
to locate one vehicle at each site, and to assign the customers to the vehicles.
Each vehicle must leave its site, pick up the load of customers assigned to it in
such a way that the vehicle capacity is not exceeded and all pickups occur within
the customer’s time window, and then return to its site. The costs are as follows:
A site-dependent cost is incurred for locating each vehicle; that is, if a vehicle is
located at site j, the setup cost is vj, for j = 1, 2, . . ., m. The cost of assigning
customer i to the vehicle at site j is cij (the assignment cost), for i = 1, 2, . . . , n
and j = 1, 2, . . . , m. We assume that there are enough vehicles and sites so that a
feasible solution exists.
The CVLPTW can be formulated as the following mathematical program. Let
yj =

1,
if a vehicle is located at site j,
0,
otherwise,
and let
xij =

1,
if customer i is assigned to the vehicle at site j,
0,
otherwise.

350
18. The VRP with Time-Window Constraints
For any set S ⊆N, let fj(S) = 1 if the set of customers S can be feasibly served
in their time windows by one vehicle that starts and ends at site j (disregarding
the capacity constraint), and 0 otherwise.
Problem P : Min
n

i=1
m

j=1
cijxij +
m

j=1
vjyj
s.t.
m

j=1
xij = 1,
∀i,
(18.2)
n

i=1
wixij ≤Q,
∀j,
(18.3)
xij ≤yj,
∀i, j,
(18.4)
fj({i : xij = 1}) = 1, ∀j,
(18.5)
xij, yj ∈{0, 1},
∀i, j.
(18.6)
Constraints (18.2) ensure that each customer is assigned to exactly one vehicle,
and constraints (18.3) ensure that the vehicle’s capacity constraint is not violated.
Constraints (18.4) guarantee that if a customer is assigned to the vehicle at site
j, then a vehicle is located at that site. Constraints (18.5) ensure that the time-
window constraints are not violated. Constraints (18.6) ensure the integrality of
the variables.
The Heuristic
To relate the CVLPTW to the VRPTW, consider each customer in the VRPTW
to be a potential site for a vehicle; that is, the set of potential sites is exactly the set
of customers, and therefore, m = n. Picking a subset of the sites in the CVLPTW
corresponds to picking a subset of the customers in the VRPTW; we call this set
of selected customers the seed customers. These customers are those that will form
simple tours with the depot.
In order for the LBH to perform well, the costs of the CVLPTW should app-
roximate the costs of the VRPTW. The setup cost for locating a vehicle at site
j (vj), or, in other words, of picking customer j as a seed customer, should
be the cost of sending a vehicle from the depot to customer j and back (i.e.,
the length of the simple tour). Hence, we set vj = 2dj for each j ∈N. The assign-
ment cost cij is the cost of assigning customer i to the vehicle at site j. There-
fore, this cost should represent the added cost of inserting customer i into the
simple tour through the depot and customer j. Consequently, when i is added
to a tour with j, the added cost is cij = di + dij −dj, so that vj + cij =
di + dij + dj. This cost is exact for two and sometimes three customers. How-
ever, as the number of customers increases, the values of cij in fact represent an
approximation to the cost of adding i to a tour that goes through customer j and
the depot. In Sect. 18.4.3, we present values of cij that we have found to work well
in practice.

18.4 An Asymptotically Optimal Heuristic
351
Once these costs are determined, the second step of the LBH consists of solving
the CVLPTW. The solution provided is a set of sites (seed customers) and a set
of customers assigned to each of these sites (to each seed). This solution can then
be easily transformed into a solution to the VRPTW, since a set of customers that
can be feasibly served starting from site j can also be feasibly served starting from
the depot.
18.4.2
A Solution Method for CVLPTW
The computational eﬃciency of the LBH depends on the eﬃciency with which the
CVLPTW can be solved. We therefore present a method to solve the CVLPTW.
As discussed earlier, the CVLPTW without constraints (18.5) is simply the
single-source capacitated facility location problem (CFLP) for which eﬃcient sol-
ution methods exist based on the celebrated Lagrangian relaxation technique; see
Sect. 6.3. For the CVLPTW, we use a similar method, although the speciﬁcs are
more complex in view of the existence of these time window constraints.
In this case, for a given multiplier vector λ ∈IRn, constraints (18.2) are relaxed
and put into the objective function with the multiplier vector. The resulting prob-
lem can be separated into n subproblems (one for each of the n sites), since con-
straints (18.2) are the only constraints that relate the sites to one another. The
subproblem for site j is
Problem Pj : Min
n

i=1
cijxij + vjyj
s.t.
n

i=1
wixij ≤Q
xij ≤yj,
∀i,
fj({i : xij = 1}) = 1,
xij ∈{0, 1}, ∀i and yj ∈{0, 1},
where cij .= cij + λi, for each i ∈N.
In the optimal solution to Problem Pj, yj is either 0 or 1. If yj = 0, then xij = 0
for all i ∈N, and the objective function value is 0. If yj = 1, then the problem
reduces to a diﬀerent, but simpler, routing problem. Consider a vehicle of capacity
Q initially located at site j. The driver gets a proﬁt of pij .= −cij for picking up
the wi items at customer i in the time window (ei, li). The pickup operation takes
si units of time. The objective is to choose a subset of the customers, to pick up
their loads in their time windows, without violating the capacity constraint, using
a vehicle that must begin and end at site j, while maximizing the driver’s proﬁt.
Let G∗
j be the maximum proﬁt attainable at site j; that is, G∗
j is the optimal
solution to the problem just described for site j. This implies that vj −G∗
j is the
optimal solution value of Problem Pj given that yj = 1. Therefore, we can write
the optimal solution to Problem Pj as simply min{0, vj −G∗
j}.

352
18. The VRP with Time-Window Constraints
Unfortunately, in general, determining the values G∗
j for j ∈N is NP-Hard.
We can, however, determine upper bounds on G∗
j; call them Gj. This provides a
lower bound on the optimal solution to Problem Pj, which is equal to min{0, vj −
Gj}. We use the simple bound given by Gj
.= 
{i:pij>0} pij. Consequently,
n
j=1 min{0, vj −Gj} −n
i=1 λi is a lower bound on the optimal solution
to the CVLPTW.
To generate a feasible solution to the VRPTW at each iteration of the procedure,
we use information from the upper bounds on proﬁt Gj for j ∈N. After every
iteration of the lower bound (for each multiplier), we renumber the sites so that
G1 ≥G2 ≥· · · ≥Gn. The upper bounds on proﬁt are used as an estimate of
the proﬁtability of placing a vehicle at a particular site. For example, site 1 is
considered to be a “good” site (or seed customer), since a large proﬁt is possible
there. A large proﬁt for site j corresponds to a seed customer where neighboring
customers can be feasibly served from it at low cost. Therefore, a site with large
proﬁt is selected as a seed customer since it will tend to have neighboring customers
around it that can be feasibly served by a vehicle starting at that site.
To generate a feasible solution to the CVLPTW, we do the following: Starting
with j = 1 in the new ordering of the sites (customers), we locate a vehicle at
site j. For every customer still not assigned to a site, we ﬁrst determine if this
customer can be feasibly served with the customers that are currently assigned
to site j. Then, of the customers that can be served from this site, we determine
the one that will cause the least increase in cost, that is, the one with minimum
cij over all customers i that can be served from this site. We then assign this
customer to the site. We continue until no more customers can be assigned to site
j, due to capacity or time constraints. We then increment j to 2 and continue
with site 2. After all customers have been feasibly assigned to a site, we obtain a
feasible solution whose cost is compared to the cost of the current best solution.
As we ﬁnd solutions to the CVLPTW, we also generate feasible solutions to the
VRPTW, using the information from the lower bound to the CVLPTW. Starting
with j = 1, pick customer j as a seed customer. Then, for every customer that
can be feasibly served with this seed, we determine the added distance this would
entail; that is, we determine the best place to insert the customer into the current
tour through the customers assigned to seed j. We choose the customer that causes
the least increase in distance traveled as the one to assign to seed j. This idea is
similar to the nearest-insertion heuristic discussed in Sect. 4.3.2. We then continue
trying to add customers in this way to seed j. Once no more can be added to this
tour (due to capacity or time constraints), we increment j to 2, select seed customer
2, and continue. Once every customer appears in a tour, that is, every customer
is assigned to a seed, we have a feasible solution to the VRPTW corresponding to
the current set of multipliers. The cost of this solution is compared to the cost of
the current best solution.
Multipliers are updated using (6.6). The step size is initially set to 2 and halved
after the lower bound has not improved in a series of 30 iterations. After the step
size has reached a preset minimum (0.05), the heuristic is terminated.

18.4 An Asymptotically Optimal Heuristic
353
18.4.3
Implementation
It is clear that many possible variations of the LBH can be implemented depending
on the type of assignment costs (cij) used. In the computational results discussed
below, the following have been implemented.
direct cost: cij = 2dij,
and
nearest-insertion cost: cij = di + dij −dj.
Direct cost cij has the advantage that, when several customers are added to the
seed, the resulting cost, which is the sum of the setup costs and these direct costs,
is an upper bound on the length of any eﬃcient route through the customers. On
the other hand, the nearest-insertion cost works well because it is accurate at least
for tours through two customers, and often for tours through three customers as
well.
Several versions of the LBH have been implemented and tested. In the ﬁrst, the
star-tours (ST) heuristic, the direct assignment cost is used, while in the second,
the seed-insertion (SI) heuristic, the nearest-insertion assignment cost is applied.
Observe that the LBH is not a polynomial-time heuristic. However, as we shall
shortly demonstrate, the running times reported on standard test problems are
very reasonable and are comparable to the running times of many heuristics for
the vehicle routing problem.
The ST heuristic is of particular interest because it is asymptotically optimal as
demonstrated in the following lemma. The proof is similar to the previous proofs
and is therefore omitted.
Lemma 18.4.1 Let n customers, indexed by N, be independently and identically
distributed according to a distribution μ with compact support in IR2. Deﬁne
E(d) =

IR2 ||x||dμ(x).
Let the customer parameters {(wk, ek, sk, lk) : k ∈N} be jointly distributed like
Φ. In addition, let M ∗
n be the minimum number of machines needed to feasibly
schedule the jobs {(wk, ek, sk, lk) : k ∈N}, and let limn→∞M ∗
n/n = γ, (a.s.).
Then
lim
n→∞
1
nZST = lim
n→∞
1
nZ∗
t = 2γE(d)
(a.s.).
18.4.4
Numerical Study
Tables 18.1 and 18.2 summarize the computational experiments with the stan-
dard test problems of Solomon (1986). The problem set consists of 56 problems
of various types. All problems consist of 100 customers and one depot, and the
distances are Euclidean. Problems with the “R” preﬁx are problems where the
customer locations are randomly generated according to a uniform distribution.

354
18. The VRP with Time-Window Constraints
TABLE 18.1. Computational results: Part I
CPU
CPU
Solomon’s
Problem
Alg. ST
time (s)
Alg. SI
time (s)
best solution
C201
591.6
245.9
591.6
260.5
591
C202
∗652.8
276.1
∗640.8
262.7
731
C203
∗692.2
309.2
∗741.1
308.9
786
C204
∗721.6
335.9
782.3
340.6
758
C205
713.8
250.8
699.9
258.8
606
C206
770.8
257.3
∗722.8
283.3
730
C207
767.2
265.7
708.9
275.8
680
C208
736.2
287.7
660.2
272.4
607
R201
∗1665.3
207.1
∗1533.4
209.6
1,741
R202
∗1485.3
276.4
∗1484.3
248.5
1,730
R203
∗1371.5
406.5
∗1349.3
389.0
1,567
R204
1096.7
532.0
1077.0
538.2
1,059
R205
1472.3
287.0
∗1329.4
312.6
1,471
R206
∗1237.0
412.2
∗1283.7
374.2
1,405
R207
∗1217.7
484.8
∗1162.9
453.9
1,241
R208
∗966.1
587.8
∗959.9
612.6
1,046
R209
∗1276.1
394.8
∗1262.8
355.7
1,418
R210
∗1312.5
380.7
∗1340.6
388.6
1,425
R211
1080.9
474.7
1141.3
488.7
1,016
RC201
∗1873.8
203.5
∗1841.7
185.8
1,880
RC202
∗1742.1
227.8
∗1705.1
241.0
1,799
RC203
∗1417.5
331.5
∗1471.1
300.1
1,550
RC204
∗1139.6
437.7
∗1190.3
411.5
1,208
RC205
∗1830.5
233.0
∗1878.9
214.0
2,080
RC206
1640.1
259.0
1607.5
248.2
1,582
RC207
∗1566.4
294.2
∗1557.3
272.3
1,632
RC208
1254.8
345.7
1298.7
317.3
1,194
∗indicates that the LBH improves upon the best solution known
Problems with the “C” preﬁx are problems where the customer locations are clus-
tered. Problems with the “RC” preﬁx are a mixture of both random and clustered.
In addition, all of the problems have a constraint on the latest time T0 at which a
vehicle can return to the depot. For a full description of these problems, we refer
the reader to Solomon.
We compare the performance of the LBH against the heuristics of Solomon and
the column-generation approach of Desrochers et al. (1992). The latter method
was able to solve eﬀectively 7 of the 56 test problems; we describe this approach
in the next chapter.
To compare the LBH to these solution methods, we implemented a time-window
reduction phase before the start of the heuristic. Here, the earliest time for service
ek is replaced by max{ek, dk}; in that way, vehicles leave the depot no earlier than

18.4 An Asymptotically Optimal Heuristic
355
TABLE 18.2. Computational results: Part II
CPU
CPU
Solomon’s DDS solution
Problem Alg. ST time (s) Alg. SI time (s) best solution
value
C101
828.9
74.1
828.9
67.0
829
827.3
C102
982.8
82.9 1043.4
73.1
968
827.3
C103
∗1015.1
95.9 1232.9
88.4
1,026
C104
∗980.9
105.4
∗976.1
114.5
1,053
C105
∗828.9
79.7
860.8
67.3
829
C106
852.9
82.8
880.1
66.7
834
827.3
C107
828.9
83.1
841.2
74.7
829
827.3
C108
852.9
88.6
853.6
80.9
829
827.3
C109
991.0
88.6 1014.5
83.1
829
R101
1983.7
57.2 2071.2
39.9
1,873
1607.7
R102
1789.0
70.8 1821.4
57.4
1,843
1434.0
R103
1594.5
88.6 1599.1
67.9
1,484
R104
1242.0
106.2 1237.3
81.0
1,188
R105
1604.4
67.0 1696.2
52.0
1,502
R106
1606.9
78.0 1589.2
70.0
1,460
R107
∗1324.9
92.4 1361.2
70.4
1,353
R108
1202.6
107.5 1205.5
101.1
1,134
R109
1504.7
78.5 1491.8
69.6
1,412
R110
1380.9
92.0 1434.4
69.4
1,211
R111
1422.1
91.7 1432.4
69.5
1,202
R112
1248.1
105.2 1284.6
79.4
1,086
RC101
2045.1
60.6 2014.4
45.0
1,867
RC102
1806.6
68.7 1969.5
52.2
1,760
RC103
1708.9
81.7 1716.3
69.6
1,641
RC104
1372.1
93.5 1458.8
79.5
1,301
RC105
∗1826.3
68.9 2036.8
51.3
1,922
RC106
1710.8
68.0 1804.8
50.5
1,611
RC107
1593.2
76.4 1630.9
64.9
1,385
RC108
1421.0
84.7 1493.8
65.5
1,253
∗indicates that the LBH improves upon the best solution known
time 0. In addition, the latest time service can end lk is replaced by min{lk, T0−dk}.
The LBH can then be run as it is described in Sect. 18.4.1.
As can be seen in the tables, both the ST and SI heuristics have been imple-
mented. CPU times are in seconds on a Sun SPARC Station II. In Tables 18.1
and 18.2, the column “Solomon’s best solution” corresponds to the best solution
found by Solomon. Solomon tested eight diﬀerent heuristics on problem sets R1
and C1, and six heuristics on problems RC1, R2, C2, and RC2. We see that the
ST heuristic provides a better solution than Solomon’s heuristics in 25 of the 56
problems, while the SI heuristic provides a better solution in 21 of the 56 problems.
In Table 18.2, the column “DDS solution value” corresponds to the value of the
solution found using the column-generation approach of Desrochers et al.

356
18. The VRP with Time-Window Constraints
18.5
Exercises
Exercise 18.1.
You are given a network G = (V, A), where |V | = n, d(i, j) is
the length of edge (i, j) and a speciﬁed vertex a ∈V . One service unit is located
at a and has to visit each vertex in V so that the total waiting time of all vertices
is as small as possible. Assume the waiting time of a vertex is proportional to the
total distance traveled by the server from a to the vertex. The total waiting time
(summed up over all customers) is then
(n −1)d(a, 2) + (n −2)d(2, 3) + (n −3)d(3, 4) + · · · + d(n −1, n).
The delivery man problem (DMP) is the problem of determining the tour that
minimizes the total waiting time.
Assume that G is a tree with d(i, j) = 1 for every (i, j) ∈A. Show that any tour
that follows a depth-ﬁrst search starting from a is optimal.
Exercise 18.2.
Consider the delivery man problem described in Exercise 18.1.
A delivery man currently located at the depot must visit each of n customers. Let
ZDM be the total waiting time in the optimal delivery man tour through the n
points. Let Z∗be the total time required to travel the optimal traveling salesman
tour through the n points.
(a) Prove that
ZDM ≤
n
2

Z∗.
(b) One heuristic proposed for this problem is the nearest-neighbor (NN) heuris-
tic. In this heuristic, the vehicle serves the closest unvisited customer next.
Provide a family of examples to show that the heuristic does not have a ﬁxed
worst-case bound.
Exercise 18.3.
Consider the vehicle routing problem with distance constraints.
Formally, a set of customers has to be served by vehicles that are all located at
a common depot. The customers and the depot are presented as the nodes of
an undirected graph G = (N, E). Each customer has to be visited by a vehicle.
The jth vehicle starts from the depot and returns to the depot after visiting a
subset Nj ⊆N. The total distance traveled by the jth vehicle is denoted by
Tj. Each vehicle has a distance constraint λ: No vehicle can travel more than
λ units of distance (i.e., Tj ≤λ). We assume that the distance matrix satisﬁes
the triangle inequality assumption. Also, assume that the length of the optimal
traveling salesman tour through all the customers and the depot is greater than λ.
(a) Suppose the objective function is to minimize the total distance traveled. Let
K∗be the number of vehicles in an optimal solution to this problem. Show
that there always exists an optimal solution with total distance traveled
> 1
2K∗λ. Does this lower bound hold for any optimal solution?

18.5 Exercises
357
(b) Consider the following greedy heuristic: Start with the optimal traveling
salesman tour through all the customers and the depot. In an arbitrary
orientation of this tour, the nodes are numbered (i0, i1, . . . , in) ≡S in order
of appearance, where n = the number of customers, i0 is the depot, and
i1, i2, . . . , in are the customers. We break the tour into KH segments and
connect the endpoints of each segment to the depot. This is done in the
following way. Each vehicle j, 1 ≤j < KH, starts by traveling from the
depot to the ﬁrst customer iq not visited by the previous j −1 vehicles
and then visits the maximum number of customers according to S without
violating the distance constraint upon returning to the depot.
Show that KH ≤min{n, ⌈T −2dm
λ−2dm ⌉}, where T is the length of the optimal travel-
ing salesman tour and dm is the distance from the depot to the farthest customer.
Exercise 18.4.
Consider the pickup and delivery problem. Here customers are
pickup customers with probability p and delivery customers with probability 1−p.
Assume a vehicle capacity of 1. If customer i is a pickup customer, then a load
of size wi ≤1 must be picked up at the customer and brought to the depot.
If customer i is a delivery customer, then a load of size wi ≤1 must be brought
from the depot to the customer. Assume pickup sizes are drawn randomly from a
distribution with bin-packing constant γP and delivery sizes are drawn randomly
from a distribution with bin-packing constant γD. A pickup and a delivery can be
in the vehicle at the same time.
(a) Develop a heuristic H for this problem and determine limn→∞ZH
n as a func-
tion of p, γP , and γD.
(b) Assume all pickups are of size
1
3 and deliveries are of size
2
3. Suggest a
better heuristic for this case. What is limn→∞ZH
n
as a function of p for this
heuristic?

19
Solving the VRP Using a
Column-Generation Approach
19.1
Introduction
A classical method, ﬁrst suggested by Balinski and Quandt (1964) , for solving
the VRP with capacity and time-window constraints, is based on formulating the
problem as a set-partitioning problem. (See Chap. 6 for a general discussion of set
partitioning.) The idea is as follows: Let the index set of all feasible routes be
{1, 2, . . ., R} and let cr be the length of route r. Deﬁne
αir =
 1,
if customer i is served in route r,
0,
otherwise,
for each customer i = 1, 2, . . ., n and each route r = 1, 2, . . . , R. Also, for every
r = 1, 2, . . . , R, let
yr =
 1,
if route r is in the optimal solution,
0,
otherwise.
In the set-partitioning formulation of the VRP, the objective is to select a minimum-
cost set of feasible routes such that each customer is included in some route. It is
D. Simchi-Levi et al., The Logic of Logistics: Theory, Algorithms, and Applications
for Logistics Management, Springer Series in Operations Research and Financial Engineering,
DOI 10.1007/978-1-4614-9149-1 19, © Springer Science+Business Media New York 2014
359

360
19. Solving the VRP Using a Column-Generation Approach
Problem S :
Min
R

r=1
cryr
s.t.
R

r=1
αiryr ≥1,
∀i = 1, 2, . . . , n,
(19.1)
yr ∈{0, 1},
∀r = 1, 2, . . . , R.
Observe that we have written constraints (19.1) as inequality constraints instead
of equality constraints. The formulation with equality constraints is equivalent if
we assume the distance matrix {dij} satisﬁes the triangle inequality; therefore, each
customer will be visited exactly once in the optimal solution. The formulation with
inequality constraints will prove to be easier to work with from an implementation
point of view.
Cullen et al. (1981) was the ﬁrst to use this formulation successfully to design
heuristic methods for the VRP. Later, Desrochers et al. (1992) used it in con-
junction with a branch-and-bound method to generate optimal or near-optimal
solutions to the VRP. Similar methods have been used to solve crew scheduling
problems, such as Hoﬀman and Padberg (1993).
Of course, the set of all feasible routes is extremely large, and one cannot expect
to generate it completely. Even if this set is given, it is not clear how to solve the
set-partitioning problem since it is a large-scale integer program. Any method
based on this formulation must overcome these two obstacles. We start here, in
Sect. 19.2, by showing how the linear relaxation of the set-partitioning problem
can be solved to optimality without enumerating all possible routes. In Sect. 19.3,
we combine this method with a polyhedral approach that generates an optimal or
near-optimal solution to the VRP. Finally, in Sect. 19.4, we provide a probabilistic
analysis that helps explain why a method of this type will be eﬀective.
To simplify the presentation, we assume no time-window constraints exist; the
extension to the more general model is straightforward, for the most part. The
interested reader can ﬁnd some of these extensions in Desrochers et al. (1992).
19.2
Solving a Relaxation of the Set-Partitioning
Formulation
To solve the linear relaxation of Problem S without enumerating all the routes,
Desrochers et al. (1992) use the celebrated column-generation technique. A thor-
ough explanation of this method is given below, but the general idea is as follows.
A portion of all possible routes is enumerated, and the resulting linear relaxation
with this partial route set is solved. The solution to this linear program is then
used to determine if there are any routes not included that can reduce the objective
function value. This is the column-generation step. Using the values of the optimal
dual variables (with respect to the partial route set), the program generates a new

19.2 Solving a Relaxation of the Set-Partitioning Formulation
361
route, and the linear relaxation is resolved.This is continued until one can show
that an optimal solution to the linear program is found, one that is optimal for
the complete route set.
Speciﬁcally, this is done by enumerating a partial set of routes, 1, 2, . . . , R′, and
formulating the corresponding linear relaxation of the set-partitioning problem
with respect to this set:
Problem S′ :
Min
R′

r=1
cryr
s.t.
R′

r=1
αiryr ≥1,
∀i = 1, 2, . . ., n,
(19.2)
yr ≥0,
∀r = 1, 2, . . . , R′.
Let y be the optimal solution to Problem S′, and let π be the corresponding
optimal dual variables. We would like to know whether y (or equivalently, π) is
optimal for the linear relaxation of Problem S (respectively, the dual of the linear
relaxation of Problem S). To answer this question, observe that the dual of the
linear relaxation of Problem S is
Problem SD :
Max
n

i=1
πi
s.t.
n

i=1
αirπi ≤cr,
∀r = 1, 2, . . . , R,
(19.3)
πi ≥0,
∀i = 1, 2, . . . , n.
Clearly, if π satisﬁes every constraint (19.3), then it is optimal for Problem SD,
and therefore, y is optimal for the linear programming relaxation of Problem S.
How can we check whether π satisﬁes every constraint in Problem SD? Observe
that the vector π is not feasible in Problem SD if we can identify a single constraint,
r, such that
n

i=1
αirπi > cr.
Consequently, if we can ﬁnd a column r minimizing the quantity cr −n
i αirπi
and this quantity is negative, then a violated constraint is found. In that case,
the current vector π is not optimal for Problem SD. The corresponding column
just found can be added to the formulation of Problem SP , which is solved again.
The process repeats itself until no violated constraint (column) is found; in this
case, we have found the optimal solution to the linear relaxation of Problem S
(the vector y) and the optimal solution to Problem SD (the vector π).

362
19. Solving the VRP Using a Column-Generation Approach
Our task is then to ﬁnd a column, or a route, r minimizing the quantity
cr −
n

i
αirπi.
(19.4)
We can look at this problem in a diﬀerent way. Suppose we replace each distance
dij with a new distance d′
ij deﬁned by
d′
ij
.= dij −πi
2 −πj
2 .
Then a tour u1 →u2 →. . . →uℓwhose length using {dij} is ℓ−1
i=1 duiui+1 + duℓu1
has, using {d′
ij}, a length
ℓ−1

i=1
d′
uiui+1 + d′
uℓu1 =
ℓ−1

i=1
duiui+1 + duℓu1 −
ℓ

i=1
πui.
Hence, ﬁnding a route r that minimizes (19.4) is the same as using the distance
matrix {d′
ij} to ﬁnd a minimum-length tour that starts and ends at the depot, visits
a subset of the customers, and has a total load no more than Q. Unfortunately,
this itself is an NP-Hard problem, and so we are left with a method that is not
attractive computationally.
To overcome this diﬃculty, the set-partitioning formulation, Problem S, is mod-
iﬁed to allow routes to visit the same customer more than once. The purpose of
this modiﬁcation will be clear in a moment. This model, call it Problem SM (where
M stands for the “modiﬁed” formulation), is deﬁned as follows: Enumerate all fea-
sible routes, satisfying the capacity constraint, that may visit the same customer a
number of times; each such visit increases the total load by the demand of that cus-
tomer. Let the number of routes (columns) be RM, and let cr be the total distance
traveled in route r. For each customer i = 1, 2, . . . , n and route r = 1, 2, . . ., RM,
let
ξir = number of times customer i is visited in route r.
Also, for each r = 1, 2, . . . , RM, deﬁne
yr =
 1,
if route r is in the optimal solution,
0,
otherwise.
The VRP can be formulated as
Problem SM :
Min
RM

r=1
cryr
s.t.
RM

r=1
ξiryr ≥1,
∀i = 1, 2, . . . , n,
(19.5)
yr ∈{0, 1},
∀r = 1, 2, . . . , RM.

19.2 Solving a Relaxation of the Set-Partitioning Formulation
363
This is the set-partitioning problem solved by Desrochers et al. (1992), and
therefore, it is not exactly Problem S. Clearly, the optimal integer solution to
Problem SM is the optimal solution to the VRP. However, the optimal solution
values of the linear relaxations of Problem SM and Problem S may be diﬀerent.
Of course, the linear relaxation of Problem SM provides a lower bound on the
linear relaxation of Problem S.
To solve the linear relaxation of Problem SM, we use the method described above
(for solving Problem S): We enumerate a partial set of R′
M routes; solve Problem
S′
M, which is the linear relaxation of Problem SM deﬁned only on this partial
list; use the dual variables to see whether a column not in the current partial list
with n
i=1 ξirπi > cr exists. If such a column(s) exists, we add it (them) to the
formulation and solve the resulting linear program again. Otherwise, we have the
optimal solution to the linear relaxation of Problem SM.
The modiﬁcation we have made makes the column-generation step computa-
tionally easier. This can now be found in pseudopolynomial time using dynamic
programming.
For this purpose, we need the following deﬁnitions. Given a path P = {0, u1, u2,
. . . , uℓ}, where it is possible that ui = uj for i ̸= j, let the load of this path be
ℓ
i=1 wui. That is, the load of the path is the sum, over all customers in P, of the
demand of a customer multiplied by the number of times that customer appears
in P. Let fq(i) be the cost [using {d′
ij}] of the least-cost path that starts at the
depot and terminates at vertex i with total load q. This can be calculated using
the recursion
fq(i) = min
j̸=i

fq−wi(j) + d′
ij

,
(19.6)
with the initial conditions
fq(i) =
 d′
0i
if q = wi,
+∞
otherwise.
Finally, let f 0
q (i) = fq(i)+ d′
0i. Thus, f 0
q (i) is the length of a least-cost tour that
starts at the depot, visits a subset of the customers, of which customer i is the last
to be visited, has a total load q, and terminates at the depot. Observe that ﬁnding
f 0
q (i) for every q, 1 ≤q ≤Q, and every i, i ∈N, requires O(n2Q) calculations. The
recursion chooses the predecessor of i to be a node j ̸= i. This requires repeat visits
to the same customer to be separated by at least one visit to another customer.
In fact, expanding the state space of this recursion can eliminate two-loops: loops of
the type . . . i, j, i . . .. This forces repeat visits to the same customer to be separated
by visits to at least two other customers. This can lead to a stronger relaxation
of the set-partitioning model. For a more detailed discussion of this recursion, see
Christoﬁdes et al. (1981).
If there exist a q, 1 ≤q ≤Q, and i, i ∈N with f 0
q (i) < 0, then the current
vectors y and π are not optimal for the linear relaxation of Problem SM. In such
a case, we add the column corresponding to this tour [the one with negative f 0
q (i)]
to the set of columns in Problem S′
M. If, on the other hand, f 0
q (i) ≥0 for every q
and i, then the current y and π are optimal for SM.

364
19. Solving the VRP Using a Column-Generation Approach
To summarize, the column-generation algorithm can be described as follows.
The Column-Generation Procedure
Step 1: Generate an initial set of R′
M columns.
Step 2: Solve Problem S′
M and ﬁnd y and π.
Step 3: Construct the distance matrix {d′
ij} and ﬁnd f 0
i (q) for all i ∈N and
1 ≤q ≤Q.
Step 4: For every i and q with f 0
i (q) < 0, add the corresponding column to R′
M
and go to step 2.
Step 5: If f 0
i (q) ≥0 for all i and q, stop.
The procedure produces a vector y that is the optimal solution to the linear
relaxation of Problem SM. This is a lower bound on the optimal solution to the
VRP.
19.3
Solving the Set-Partitioning Problem
In the previous section, we introduced an eﬀective method for solving the linear
relaxation of the set-partitioning formulation of the VRP, Problem SM. How can
we use this solution to the linear program to ﬁnd an optimal or near-optimal
integer solution?
We’ll start with the set of columns present at the end of the column-generation
step (the set E); one approach to generating an integer solution to the set-
partitioning formulation is to use the branch-and-bound method. This method
consists of splitting the problem into easier subproblems by ﬁxing the value of
a branching variable. The variable (in this case, a suitable choice is yr for some
route r) is set to either 1 or 0. Each of these subproblems is solved using the same
method; that is, another variable is branched. At each step, tests are performed to
see if the entire branch can be eliminated; that is, no better solution than the one
currently known can be found in this branch. The solution found by this method
will be the best integer solution among all the solutions in E. This solution will
not necessarily be the optimal solution to the VRP, but it may be close.
Another approach that will generate the same integer solution as the branch-
and-bound method is the following. Given a fractional solution to SM, we can
generate a set of constraints that will cut oﬀthis fractional solution. Then we
can resolve this linear program; if it is integer, we have found the optimal integer
solution (among the columns of E). If it is still fractional, then we can continue
generating constraints and resolving the linear program until an integer solution
is found. Again, the best integer solution found using this method may be close to
optimal. This is the method successfully used by Hoﬀman and Padberg (1993) to
solve crew scheduling problems.

19.3 Solving the Set-Partitioning Problem
365
Formally, the method is as follows.
The Cutting-Plane Algorithm
Step 1: Generate an initial set of R′
M columns.
Step 2: Use column generation to solve Problem S′
M.
Step 3: If the optimal solution to Problem S′
M is integer, stop.
Else, generate cutting planes separating this solution.
Add these cutting planes to the linear program S′
M.
Step 4: Solve the linear program S′
M. Go to step 3.
To illustrate this constraint-generation step (step 3), we make use of a number of
observations. First, let E be the set of routes at the end of the column-generation
procedure. Clearly, we can split E into two subsets. One subset Em includes every
column r for which there is at least one i with ξir ≥2; these columns are called
multiple-visit columns. The second subset Es includes the remaining columns; these
columns are referred to as single-visit columns. It is evident that an optimal sol-
ution to the VRP will use no columns from Em. That is, there always exists a
single-visit column of at most the same cost that can be used instead. We there-
fore can immediately add the following constraint to the linear relaxation of Prob-
lem SM:

r∈Em
yr = 0.
(19.7)
To generate more constraints, construct the intersection graph G. The graph G
has a node for each column in Es. Two nodes in G are connected by an edge if
the corresponding columns have at least one customer in common. Observe that
a solution to the VRP where no customer is visited more than once can be repre-
sented by an independent set in this graph. That is, it is a collection of nodes on
the graph G such that no two nodes are connected by an edge.
These observations give rise to two inequalities that can be added to the
formulation:
1. We select a subset of the nodes of G, say K, such that every pair of nodes
i, j ∈K is connected by an edge of G. Each set K, called a clique, must
satisfy the following condition:

r∈K
yr ≤1.
(19.8)
Clearly, if there is a node j ̸∈K such that j is adjacent to every i ∈K, then
we can replace K with K ∪{j} in inequality (19.8) to strengthen it (this is
called lifting). In that sense, we would like to use inequality (19.8) when the
set of nodes K is maximal in that sense.

366
19. Solving the VRP Using a Column-Generation Approach
2. Deﬁne a cycle C = {u1, u2, . . . , uℓ} in G such that node ui is adjacent to
ui+1, for each i = 1, 2, . . . , ℓ−1, and node uℓis adjacent to node u1. A cycle
C is called an odd cycle if the number of nodes in C, |C| = ℓ, is odd. An odd
cycle is called an odd hole if there is no arc connecting two nodes of the cycle
except the ℓarcs deﬁning the cycle. It is easy to see that in any optimal
solution to the VRP, each odd hole must satisfy the following property:

r∈C
yr ≤|C| −1
2
.
(19.9)
19.3.1
Identifying Violated Clique Constraints
Hoﬀman and Padberg suggest several procedures for clique identiﬁcation, one of
which is based on the fact that small problems can be solved quickly by enumer-
ation. For this purpose, select v to be the node with minimum degree among all
nodes of G. Clearly, every clique of G containing v is a subset of the neighbors
of v, denoted by neigh(v). Thus, starting with v as a temporary clique, that is,
K = {v}, we add an arbitrary node w from neigh(v) to K. We now delete from
neigh(v) all nodes that are not connected to a node of K, in this case either v or
w. Continue adding nodes in this manner from the current set neigh(v) to K until
either there is no node in neigh(v) connected to all nodes in K, or neigh(v) = ∅.
In the end, K will be a maximal clique. We can then calculate the weight of this
clique, that is, the sum of the values (in the linear program) of the columns in
the clique. If the weight is more than 1, then the corresponding clique inequality
is violated. If not, then we continue the procedure with a new starting node. The
method can be improved computationally by, for example, always choosing the
“heaviest” among those nodes eligible to enter the clique.
19.3.2
Identifying Violated Odd Hole Constraints
Hoﬀman and Padberg use the following procedure to identify violated odd hole
constraints. Suppose y is the current optimal solution to the linear program and
G is the corresponding intersection graph. Starting from an arbitrary node v ∈
G, construct a layered graph Gℓ(v) as follows. The node set of Gℓ(v) is the
same as the node set of G. Every neighbor of v in G is connected to v by an
edge in Gℓ(v). We refer to v as the root, or level-0 node, and we refer to the
neighbors of v as level-1 nodes. Similarly, nodes at level k ≥2 are those nodes
in G that are connected (in G) to a level-k −1 node but are not connected
to any node at level < k −1. Finally, each edge (ui, uj) in Gℓ(v) is assigned
a length of 1 −yui −yuj ≥0. Now pick a node u in Gℓ(v) at level k ≥2
and ﬁnd the shortest path from u to v in Gℓ(v). Delete all nodes at levels i
(1 ≤i < k) that are either on the shortest path or adjacent to nodes along
this shortest path (other than nodes that are adjacent to v). Now pick another
node w that is adjacent (in G) to u in level k. Find the shortest path from w
to v in the current graph Gℓ(v). Combining these two paths with the arc (u, w)

19.4 The Eﬀectiveness of the Set-Partitioning Formulation
367
creates an odd hole. If the total length of this cycle is less than 1, then we have
found a violated odd hole inequality. If not, we continue with another neigh-
bor of u and repeat the process. We can then choose a node diﬀerent from u
at level k. If no violated odd hole inequality is found at level k, we proceed to
level k + 1. This subroutine can be repeated for diﬀerent starting nodes (v) as
well.
19.4
The Eﬀectiveness of the Set-Partitioning
Formulation
The eﬀectiveness of this algorithm depends crucially on the quality of the initial
lower bound; this lower bound is the optimal solution to the linear relaxation of
Problem SM. If this lower bound is not very tight, then the branch-and-bound or
the constraint-generation method will most likely not be computationally eﬀective.
On the other hand, when the gap between the lower bound and the best integer
solution is small, the procedure will probably be eﬀective.
Fortunately, many researchers have reported that the linear relaxation of the
set-partitioning problem, Problem SM, provides a solution close to the optimal
integer solution [see, e.g., Desrochers et al. (1992)]. That is, the solution to the lin-
ear relaxation of Problem SM provides a very tight lower bound on the solution of
the VRP. For instance, in their paper, Desrochers et al. report an average relative
gap between the optimal solution to the linear relaxation and the optimal integer
solution of only 0.733 %. A possible explanation for this observation is embod-
ied in the following theorem, which states that asymptotically the relative error
between the optimal solution to the linear relaxation of the set-partitioning model
and the optimal integer solution goes to zero as the number of customers increases.
Consider again the general VRP with capacity and time-window constraints.
Theorem 19.4.1 Let the customer locations x1, x2, . . . , xn be a sequence of in-
dependent random variables having a distribution μ with compact support in IR2.
Let the customer parameters (see Chap. 18) be independently and identically dis-
tributed like Φ. Let ZLP be the value of the optimal fractional solution to S, and
let Z∗be the value of the optimal integer solution to S, that is, the value of the
optimal solution to the VRP. Then
lim
n→∞
1
nZLP = lim
n→∞
1
nZ∗
(a.s.).
The theorem thus implies that the optimal solution value of the linear program-
ming relaxation of Problem S tends to the optimal solution of the vehicle routing
problem as the number of customers tends to inﬁnity. This is important since, as
shown by Bramel and Simchi-Levi (1997), other classical formulations of the VRP
can lead to diverging linear and integer solution values (see Exercise 19.8).
In the next section, we motivate Theorem 19.4.1 by presenting a simpliﬁed model
that captures the essential ideas of the proof. Finally, in Sect. 19.4.2, we provide

368
19. Solving the VRP Using a Column-Generation Approach
a formal proof of the theorem. Again, to simplify the presentation, we assume no
time-window constraints exist; for the general case, the interested reader is referred
to Bramel and Simchi-Levi (1997).
19.4.1
Motivation
Deﬁne a customer type to be a location x ∈IR2 and a customer demand w; that
is, a customer type deﬁnes the customer location and a value for the customer
demand. Consider a discretized vehicle routing model in which there are a ﬁnite
number W of customer types and a ﬁnite number m of distinct customer locations.
Let ni be the number of customers of type i, for i = 1, 2, . . . , W, and let n =
W
i=1 ni be the total number of customers. Clearly, this discretized vehicle routing
problem can be solved by formulating it as a set-partitioning problem. To obtain
some intuition about the linear relaxation of S, we introduce another formulation
of the vehicle routing problem closely related to S.
Let a vehicle assignment be a vector (a1, a2, . . . , aW ), where ai ≥0 are integers,
and such that a single vehicle can feasibly serve a1 customers of type 1, and a2 cus-
tomers of type 2, . . . , and aW customers of type W together without violating the
vehicle capacity constraint. Index all the possible vehicle assignments 1, 2, . . . , Ra
and let cr be the total length of the shortest feasible route serving the customers
in vehicle assignment r. (Note that Ra is independent of n.) The vehicle routing
problem can be formulated as follows. Let
Air = number of customers of type i in vehicle assignment r,
for each i = 1, 2, . . ., W and r = 1, 2, . . ., Ra. Let
yr = number of times vehicle assignment r is used in the optimal solution.
The new formulation of this discretized VRP is
Problem SN :
Min
Ra

r=1
yrcr
s.t.
Ra

r=1
yrAir ≥ni,
∀i = 1, 2, . . ., W,
yr ≥0 and integer,
∀r = 1, 2, . . ., Ra.
Let Z∗
N be the value of the optimal solution to Problem SN and let ZLP
N
be the
optimal solution to the linear relaxation of Problem SN. Clearly, Problem S and
Problem SN have the same optimal solution values, that is, Z∗= Z∗
N, while their
linear relaxations may be diﬀerent. Deﬁne c .= maxr=1,2,...,Ra{cr}; that is, c is the
length of the longest route among the Ra vehicle assignments. Using an analysis
identical to the one in Sect. 6.2, we obtain

19.4 The Eﬀectiveness of the Set-Partitioning Formulation
369
Lemma 19.4.2
ZLP ≤Z∗≤ZLP
N + Wc ≤ZLP + Wc.
Observe that the upper bound on Z∗obtained in Lemma 19.4.2 consists of two
terms. The ﬁrst, ZLP, is a lower bound on Z∗, which clearly grows with the number
of customers n. The second term (Wc) is the product of two numbers that are
ﬁxed and independent of n. Therefore, the upper bound on Z∗of Lemma 19.4.2 is
dominated by ZLP, and consequently, we see that for large n, Z∗≈ZLP, exactly
what is implied by Theorem 19.4.1. Indeed, much of the proof of the following
section is concerned with approximating the distributions μ (customer locations)
and Φ (customer demands) with discrete distributions and forcing the number of
diﬀerent customer types to be independent of n.
19.4.2
Proof of Theorem 19.4.1
It is clear that ZLP ≤Z∗; therefore, limn→∞
1
n(Z∗−ZLP) ≥0. The interesting
part is to ﬁnd an upper bound on Z∗that involves ZLP and use this upper bound
to show that limn→∞1
n(Z∗−ZLP) ≤0. We do this in essentially the same way as
in Sect. 19.4.1. We successively discretize the problem by introducing a sequence
of vehicle routing problems whose optimal solutions are “relatively” close to Z∗.
The last vehicle routing problem is a discrete problem, which, therefore, as in
Sect. 19.4.1, can be directly related to the linear relaxation of its set-partitioning
formulation. This linear program is also shown to have an optimal solution close
to ZLP.
To prove the upper bound, let N be the index set of customers, with |N| = n,
and let Problem P be the original VRP. Let A be the compact support of the
distribution of the customer locations (μ), and deﬁne dmax .= sup{∥x∥: x ∈A},
where ∥x∥is the distance from point x ∈A to the depot. Finally, pick a ﬁxed
k > 1.
Discretization of the Locations
We start by constructing the following vehicle routing problem with discrete
locations. Deﬁne Δ .=
1
k and let G(Δ) be an inﬁnite grid of squares of diag-
onal Δ, that is, of side
Δ
√
2, with edges parallel to the system coordinates. Let
A1, A2, . . . , Am(Δ) be the subregions of G(Δ) that intersect A and have μ(Ai) > 0.
Since A is bounded, m(Δ) is ﬁnite for each Δ > 0. For convenience, we omit the
dependence of m on Δ in the notation. For each subregion, let Xi be the centroid
of subregion Ai, that is, the point at the center of the grid square containing Ai.
This deﬁnes m points X1, X2, . . . , Xm; note that a customer is at most Δ
2 units
from the centroid of the subregion in which it is located.
Construct a new VRP, called P(m), deﬁned on the customers of N. Each of the
customers in N is moved to the centroid of the subregion in which it is located.
Let Z∗(m) be the optimal solution to P(m). We clearly have
Z∗≤Z∗(m) + nΔ.
(19.10)

370
19. Solving the VRP Using a Column-Generation Approach
Discretization of the Customer Demands
We now describe a VRP where the customer demands are also discretized in
much the same way as it is done in Sect. 6.2. Partition the interval (0, 1] into
subintervals of size Δ(= 1
k). This produces k segments and I .= k −1 points in the
interval (0, 1), which we call corners.
We refer to each centroid–corner pair as a customer type; each centroid deﬁnes
a customer location and each corner deﬁnes the customer demand. It is clear that
there are mI possible customer types. An instance of a fully discretized vehicle
routing problem is then deﬁned by specifying the number of customers of each of
the mI types.
For each centroid j = 1, 2, . . ., m and corner i = 1, 2, . . ., I, let
Nji =

h ∈N : i −1
k
< wh ≤i
k and xh ∈Aj

.
Finally, for every j = 1, 2, . . . , m and i = 1, 2, . . . , I, let nji = |Nji|.
We now deﬁne a fully discretized vehicle routing problem Pk(m), whose optimal
solution value is denoted Z∗
k(m). The vehicle routing problem Pk(m) is deﬁned
as having min{nji, nj,i+1} customers located at centroid j with customer demand
equal to i
k, for each i = 1, 2, . . ., I and j = 1, 2, . . ., m.
We have the following result.
Lemma 19.4.3
Z∗(m) ≤Z∗
k(m) + 2dmax
m

j=1
I

i=1
|nji −nj,i+1|.
Proof. Observe:
(i) In Pk(m), the number of customers at centroid j and with demand deﬁned by
corner i is min{nji, nj,i+1}.
(ii) In P(m), each customer belongs to exactly one of the subsets Nji, for j =
1, 2, . . . , m and i = 1, 2, . . ., I.
(iii) In P(m), the customers in Nji have smaller loads than the customers of
Pk(m) at centroid j with demand deﬁned by corner i.
Given an optimal solution to Pk(m), let us construct a solution to P(m). For
each centroid j = 1, 2, . . . , m and corner i = 1, 2, . . ., I, we pick any max{nji −
nj,i+1, 0} customers from Nji and serve them in individual vehicles. The remaining
min{nji, nj,i+1} customers in Nji can be served with exactly the same vehicle
schedules as in Pk(m). This can be done due to (iii); therefore, one can always serve
customers with a demand of P(m) in the same vehicles in which the customers of
Pk(m) are served.
Now Pk(m) is fully discrete, and we can apply results as in Sect. 19.4.1. Let
ZLP
k (m) be the optimal solution to the linear relaxation of the set-partitioning
formulation of the routing problem Pk(m). Let c be deﬁned as in Sect. 19.4.1; that
is, it is the cost of the most expensive tour among all the possible routes in Pk(m).

19.4 The Eﬀectiveness of the Set-Partitioning Formulation
371
Lemma 19.4.4
Z∗
k(m) ≤ZLP
k (m) + mIc.
Proof. Since the number of customer types is at most mI, we can formulate Pk(m)
as the integer program, like Problem SN, described in Sect. 19.4.1, with mI con-
straints. The bound then follows from Lemma 19.4.2.
Recall that ZLP is the optimal solution to the linear relaxation of the set-
partitioning formulation of the VRP deﬁned by Problem P. Then
Lemma 19.4.5
ZLP
k (m) ≤ZLP + nΔ.
Proof. Let {yr : r = 1, 2, . . ., R} be the optimal solution to the linear relaxation of
the set-partitioning formulation of Problem P. We can assume (see Exercise 19.3)
that R
r=1 yrαir = 1, for each i = 1, 2, . . . , n. We construct a feasible solution to
the linear relaxation of the set-partitioning formulation of Pk(m) using the values
yr. Since every customer in Pk(m) assigned to centroid j and corner i can be
associated with a customer in P with xk ∈Aj and whose demand is at least as
large, each route r with yr > 0 can be used to construct a route r′ feasible for
Pk(m). Since in Pk(m) the customers are at the centroids instead of at their original
locations, we modify the route so that the vehicle travels from the customer to its
centroid and back. Thus, the length (cost) of route r′ is at most the cost of route
r in P plus nrΔ, where nr is the number of customers in route r.
To create a feasible solution to the linear relaxation of the set-partitioning for-
mulation to Pk(m), we take the solution to the linear relaxation of P and create
the routes r′ as above. Therefore,
ZLP
k (m) ≤ZLP +
R

r=1
yrnrΔ ≤ZLP + nΔ.
We can now prove Theorem 19.4.1.
Z∗≤Z∗(m) + nΔ
≤Z∗
k(m) + 2dmax
m

j=1
I

i=1
|nji −nj,i+1| + nΔ
≤ZLP
k (m) + mIc + 2dmax
m

j=1
I

i=1
|nji −nj,i+1| + nΔ
≤ZLP + mIc + 2dmax
m

j=1
I

i=1
|nji −nj,i+1| + 2nΔ.

372
19. Solving the VRP Using a Column-Generation Approach
We now need to show that ZLP is the dominant part of the last upper bound.
We do that using the following lemma.
Lemma 19.4.6 There exists a constant K such that
lim
n→∞
1
n
m

j=1
I

i=1
|nji −nj,i+1| ≤2K
k .
Proof. In Sect. 6.2, we prove that given i and j, there exists a constant K such
that
lim
n→∞
1
n|nji −nj,i+1| ≤2K
k2 .
Therefore, a similar analysis gives
lim
n→∞
1
n
m

j=1
I

i=1
|nji −nj,i+1| ≤
m

j=1
μ(Aj)2K
k
= 2K
k .
Finally, observe that each tour in Pk(m) has a total length no more than 1 since
the truck travels at a unit speed and the length of each working day is 1. Hence,
mIc = O(1), and therefore,
lim
n→∞
1
n(Z∗−ZLP) ≤4dmax
K
k + 2Δ
= 2
k (2Kdmax + 1).
Since K is a constant and k was arbitrary, we see that the right-hand side can be
made arbitrarily small. Therefore,
0 ≤lim
n→∞
1
n(Z∗−ZLP) ≤lim
n→∞
1
n(Z∗−ZLP) ≤0.
We conclude this chapter with the following observation. The proof of Theo-
rem 19.4.1 also reveals an upper bound on the rate of convergence of ZLP to its
asymptotic value. Indeed (see Exercise 19.1), we have
E(Z∗) ≤E(ZLP) + O(n3/4).
(19.11)
19.5
Exercises
Exercise 19.1.
Prove the upper bound on the convergence rate (19.11).
Exercise 19.2.
Consider an undirected graph G = (V, E), where each edge (i, j)
has a cost cij and each vertex i ∈V a nonnegative penalty πi. In the prize-
collecting traveling salesman problem (PCTSP), the objective is to ﬁnd a tour

19.5 Exercises
373
that visits a subset of the vertices such that the length of the tour plus the sum of
the penalties of all vertices not in the tour is as small as possible. Show that the
problem can be formulated as a longest-path problem between two prespeciﬁed
nodes of a new network.
Exercise 19.3.
Consider the bin-packing problem. Let wi be the size of item i,
i = 1, . . . , n, and assume the bin capacity is 1. An important formulation of the
bin-packing problem is as a set-covering problem. Let
F = {S :

i∈S
wi ≤1}.
Deﬁne
αiS =
 1,
if item i is in S,
0,
otherwise,
for each i = 1, 2, . . ., n and each S ∈F. Finally, for any S, S ∈F, let
yS =
 1,
if the items in S are packed in a single bin with no other items,
0,
otherwise.
In the set-covering formulation of the bin-packing problem, the objective is to
select a minimum number of feasible bins such that each item is included in some
bin. It is the following integer program.
Problem P :
Min

S∈F
yS
s.t. 
S∈F
ySαiS ≥1,
∀i = 1, 2, . . ., n,
(19.12)
yS ∈{0, 1},
∀S ∈F.
Let Z∗be the optimal solution to Problem P, and let ZLP be the optimal solution
to the linear relaxation of Problem P. We want to prove that
Z∗≤2ZLP.
(19.13)
(a) Formulate the dual of the linear relaxation of Problem P.
(b) Show that n
i=1 wi ≤ZLP.
(c) Argue that Z∗≤2 n
i=1 wi. Conclude that (19.13) holds.
(d) An alternative formulation to Problem P is obtained by replacing constraints
(19.12) with equality constraints. Call the new problem Problem PE. Show
that the optimal solution value of the linear relaxation of Problem P equals
the optimal solution value of the linear relaxation of Problem PE.

374
19. Solving the VRP Using a Column-Generation Approach
Exercise 19.4.
Recall the dynamic program given by (19.6). Let
f = min
i∈N
min
wi≤q≤Q fq(i).
Consider the function deﬁned as follows:
gq(i) =
min
wi≤q′≤q{fq′(i) + fq−q′+wi(i)},
for each i ∈N and wi ≤q ≤Q. Now deﬁne g = mini∈N minwi≤q≤Q gq(i). Show
that f = g.
Exercise 19.5.
Develop a dynamic programming procedure for the column-
generation step similar to fq(i) that avoids two-loops (loops of the type . . . i, j, i . . .).
What is the complexity of this procedure?
Exercise 19.6.
Develop a dynamic programming procedure for the column-
generation step in the presence of time-window constraints. What is required of
the time-window data in order for this to be possible? What is the complexity of
your procedure?
Exercise 19.7.
Develop a dynamic programming procedure for the column-
generation step in the presence of a distance constraint on the length of any route.
What is required of the distance data in order for this to be possible? What is the
complexity of your procedure?
Exercise 19.8.
Consider an instance of the VRPTW with n customers. Given a
subset of the customers S, let b∗(S) be the minimum number of vehicles required
to carry the demands of customers in S; that is, b∗(S) is the solution to the bin-
packing problem deﬁned on the demands of all customers in S. For i = 1, 2, . . . , n
and j = 1, 2, . . ., n, let
xij =
 1,
if a vehicle travels directly between points i and j,
0,
otherwise.
Let 0 denote the depot and deﬁne cij as the cost of traveling directly between
points i and j, for i, j = 0, 1, 2, . . ., n. Let ti represent the time a vehicle arrives
at the location of customer i; also, for every i and j, such that i < j, deﬁne
Mij = max{li + dij −ej, 0}, where dij ≡∥Yi −Yj∥. Then the following is a valid
formulation of the VRPTW:
Problem P ′ :
Min

i<j
cijxij
s.t.

i<j
xij +

i>j
xji = 2,
∀i = 1, 2, . . ., n,

i,j∈S
xij ≤|S| −b∗(S),
∀S ⊂{1, 2, . . ., n}, 2 ≤|S| ≤n −1,

19.5 Exercises
375
ei ≤ti ≤li −si,
1 ≤i ≤n,
ti + si + dij −tj ≤Mij(1 −xij),
1 ≤i < j ≤n,
xij ∈{0, 1},
1 ≤i < j ≤n,
(19.14)
x0j ∈{0, 1, 2},
j = 1, 2, . . ., n.
(19.15)
The case x0j = 2 corresponds to a vehicle serving only customer j. The linear
programming relaxation of P ′ is obtained by replacing constraints (19.14) and
(19.15) by their linear equivalents.
Construct an instance of the VRPTW in which the fractional and integer solu-
tions to the above linear program do not approach the same value asymptotically.

Part V
Logistics Algorithms
in Practice

20
Network Planning
20.1
Introduction
In this chapter, we present some of the issues involved in the practice of supply
chain design and planning. These are issues that are often not dealt with in tra-
ditional operations research analyses. However, they are essential in transforming
raw data and problem characteristics into modeling assumptions, input data, and
decisions.
Our focus is on what we call network planning—the process by which the ﬁrm
structures and manages the supply chain in order to
• ﬁnd the right balance among inventory, transportation, and manufacturing
costs,
• match supply and demand under uncertainty by positioning inventory eﬀec-
tively,
• utilize resources eﬀectively in a dynamic environment.
Of course, this is a complex process, which requires a hierarchical approach in
which decisions on network design, inventory positioning and management, as well
as resource utilization are combined to reduce cost and increase service level. Thus,
we divide the network planning process into three steps:
1. Network design: This includes decisions on the number, locations, and size
of manufacturing plants and warehouses, the assignment of retail outlets to
D. Simchi-Levi et al., The Logic of Logistics: Theory, Algorithms, and Applications
for Logistics Management, Springer Series in Operations Research and Financial Engineering,
DOI 10.1007/978-1-4614-9149-1 20, © Springer Science+Business Media New York 2014
379

380
20. Network Planning
warehouses, and so on. Major sourcing decisions are also made at this point,
and the typical planning horizon is a few years.
2. Inventory positioning: This includes identifying stocking points as well as
selecting facilities that will produce to stock, and thus keep inventory, and
facilities that will produce to order and hence keep no inventory.
3. Resource allocation: Given the structure of the logistics network and the
location of stocking points, the objective in this step is to determine when
and how much to produce or purchase and where and when to store inven-
tory. These decisions require identifying the optimal tradeoﬀbetween setup
costs and times, and inventory and transportation costs, taking into account
production, sourcing, and warehousing capacities as well as other business
rules and constraints.
In this chapter, we analyze each of these steps and provide examples of the
processes involved.
20.2
Network Design
Network design determines the physical conﬁguration and infrastructure of the
supply chain. As explained in Chap. 1, network design is a strategic decision that
has a long-lasting eﬀect on the ﬁrm. Network design involves decisions related to
plant and warehouse location as well as distribution and sourcing.
The supply chain infrastructure typically needs to be reevaluated due to changes
in demand patterns, product mix, production processes, sourcing strategies, or the
cost of running facilities. In addition, mergers and acquisitions may mandate the
integration of diﬀerent logistics networks.
In the discussion below, we concentrate on the following key strategic decisions:
1. determining the appropriate number of facilities such as plants and ware-
houses;
2. determining the location of each facility;
3. determining the size of each facility;
4. allocating space for products in each facility;
5. determining the production requirements in each plant;
6. determining sourcing requirements;
7. determining distribution.
The objective is to design or reconﬁgure the logistics network in order to
minimize annual system-wide cost, including production and purchasing costs,

20.2 Network Design
381
inventory holding costs, facility costs (storage, handling, and ﬁxed costs), and
transportation costs, subject to a variety of service-level requirements. In this set-
ting, the tradeoﬀs are clear. Increasing the number of warehouses typically yields
• an improvement in the service level due to the reduction in the average travel
time to the customers,
• an increase in inventory costs due to increased safety stocks required to
protect each warehouse against uncertainties in customer demands,
• an increase in overhead and setup costs,
• a reduction in outbound transportation costs: transportation costs from the
warehouses to the customers,
• an increase in inbound transportation costs: transportation costs from the
suppliers and/or manufacturers to the warehouses.
In essence, the ﬁrm must balance the costs of opening new warehouses with
the advantages of being close to the customer. Thus, warehouse-location decisions
are crucial determinants of whether the supply chain is an eﬃcient channel for
the distribution of products.
We describe below some of the issues related to data collection and the cal-
culation of costs required for the optimization models. Some of the information
provided is based on logistics textbooks such as Ballou (1992), Johnson and Wood
(1986), and Robeson and Copacino (1994).
Figures 20.1 and 20.2 present two screens of a typical advance planning system
(APS); the user would see these screens at diﬀerent stages of optimization. One
screen represents the network prior to optimization, and the other represents the
optimized network.
Data Collection
A typical network conﬁguration problem involves large amounts of data, includ-
ing information on
1. the locations of customers, retailers, existing warehouses and distribution
centers, manufacturing facilities, and suppliers,
2. all products, including volumes, and special transport modes (e.g., refriger-
ated),
3. annual demand for each product by customer location,
4. transportation rates by mode,
5. warehousing costs, including labor, inventory carrying charges, and ﬁxed
operating costs,
6. shipment sizes and frequencies for customer delivery,

382
20. Network Planning
FIGURE 20.1. The APS screen representing data prior to optimization
FIGURE 20.2. The APS screen representing the optimized logistics network

20.2 Network Design
383
7. order processing costs,
8. customer service requirements and goals,
9. production and sourcing costs and capacities.
Data Aggregation
A quick look at the above list suggests that the amount of data involved in any
optimization model for this problem is overwhelming. For instance, a typical soft
drink distribution system has between 10,000 and 120,000 accounts (customers).
Similarly, in a retail logistics network, such as Wal-Mart or JC Penney, the number
of diﬀerent products that ﬂow through the network is in the thousands or even
hundreds of thousands.
For that reason, an essential ﬁrst step is data aggregation. This is carried out
using the following procedure:
1. Customers located in close proximity to each other are aggregated using a
grid network or other clustering technique. All customers within a single cell
or a single cluster are replaced by a single customer located at the center
of the cell or cluster. This cell or cluster is referred to as a customer zone.
A very eﬀective technique that is commonly used is to aggregate customers
according to the ﬁve-digit or three-digit zip code. Observe that if customers
are classiﬁed according to their service levels or frequency of delivery, they
will be aggregated together by classes. That is, all customers within the same
class are aggregated independently of the other classes.
2. Items are aggregated into a reasonable number of product groups, based on
(a) Distribution pattern. All products picked up at the same source and
destined to the same customers are aggregated together. Sometimes
there is a need to aggregate not only by distribution pattern but also
by logistics characteristics, such as weight and volume. That is, consider
all products having the same distribution pattern. Within these prod-
ucts, we aggregate those SKUs with similar volume and weight into one
product group.
(b) Product type. In many cases, diﬀerent products might simply be vari-
ations in product models or style or might diﬀer only in the type of
packaging. These products are typically aggregated together.
An important consideration, of course, is the impact on the model’s eﬀectiveness
of replacing the original detailed data with the aggregated data. We address this
question in two ways.
1. Even if the technology exists to solve the logistics network design prob-
lem with the original data, it may still be useful to aggregate data because
our ability to forecast customer demand at the account and product levels

384
20. Network Planning
FIGURE 20.3. The APS screen representing data prior to aggregation
is usually poor. Because of the reduction in variability achieved through
aggregation, forecast demand is signiﬁcantly more accurate at the aggre-
gated level.
2. Various researchers report that aggregating data into about 150–200 points
usually results in no more than a 1 % error in the estimation of total trans-
portation costs; see Ballou (1992) and House and Jamie (1981).
In practice, the following approach is typically used when aggregating the data:
• Aggregate demand points for 150–200 zones. If customers are classiﬁed into
classes according to their service levels or frequency of delivery, each class
will have 150–200 aggregated points.
• Make sure each zone has approximately an equal amount of total demand.
This implies that the zones may be of diﬀerent geographic sizes.
• Place the aggregated points at the center of the zone.
• Aggregate the products into 20–50 product groups.
Figure 20.3 presents information about 3,220 customers all located in North
America, while Fig. 20.4 shows the same data after aggregation using a three-digit
zip code, resulting in 217 aggregated points.

20.2 Network Design
385
FIGURE 20.4. The APS screen representing data after aggregation
Transportation Rates
The next step in constructing an eﬀective distribution-network design model is to
estimate transportation costs. An important characteristic of most transportation
rates, including truck, rail, and others, is that the rates are almost linear with
distance but not with volume. We distinguish here between transportation costs
associated with an internal and an external ﬂeet.
Estimating transportation costs for company-owned trucks is typically quite
simple. It involves annual costs per truck, annual mileage per truck, annual amount
delivered, and the truck’s eﬀective capacity. All this information can be used to
easily calculate the cost per mile per SKU.
Incorporating transportation rates for an external ﬂeet into the model is more
complex. We distinguish here between two modes of transportation: truckload,
referred to as TL, and less than truckload, referred to as LTL.
In the United States, TL carriers subdivide the country into zones. Almost every
state is a single zone, except for certain big states, such as Florida or New York,
which are partitioned into two zones. The carriers then provide their clients with
zone-to- zone table costs. This database provides the cost per mile per truckload
between any two zones. For example, to calculate the TL cost from Chicago,
Illinois, to Boston, Massachusetts, one needs to get the cost per mile for this pair
and multiply it by the distance from Chicago to Boston. An important property
of the TL cost structure is that it is not symmetric; that is, it is typically more
expensive to ship a fully loaded truck from Illinois to New York than from New
York to Illinois.

386
20. Network Planning
In the LTL industry, the rates typically belong to one of three basic types of
freight rates: class, exception, and commodity. The class rates are standard rates
that can be found for almost all products or commodities shipped. They are found
with the help of a classiﬁcation tariﬀthat gives each shipment a rating or a class.
For instance, the railroad classiﬁcation includes 31 classes, ranging from 400 to
13, that are obtained from the widely used Uniform Freight Classiﬁcation. The
National Motor Freight Classiﬁcation, on the other hand, includes only 23 classes,
ranging from 500 to 35. In all cases, the higher the rating or class, the greater the
relative charge for transporting the commodity. There are many factors involved
in determining a product’s speciﬁc class. These include product density, ease or
diﬃculty of handling and transporting, and liability for damage.
Once the rating is established, it is necessary to identify the rate basis number.
This number is the approximate distance between the load’s origin and destination.
With the commodity rating or class and the rate basis number, the speciﬁc rate
per hundred pounds (hundred weight, or cwt) can be obtained from a carrier tariﬀ
table (i.e., a freight rate table).
The two other freight rates, namely, exception and commodity, are specialized
rates used to provide either less expensive rates (exception), or commodity-speciﬁc
rates (commodity). For an excellent discussion, see Johnson and Wood (1986) and
Patton (1994). Most carriers provide a database ﬁle with all of their transportation
rates; these databases are typically incorporated into advance planning systems.
The proliferation of LTL carrier rates and the highly fragmented nature of
the trucking industry have created the need for sophisticated rating engines.
An example of such a rating engine that is widely used is SMC3’s RateWare (see
www.smc3.com). This engine can work with various carrier tariﬀtables as well as
SMC3’s CzarLite, one of the most widely used and accepted forms of nationwide
LTL zip code-based rates. Unlike an individual carrier’s tariﬀ, CzarLite oﬀers a
market-based price list derived from studies of LTL pricing on a regional, interre-
gional, and national basis. This provides shippers with a fair pricing system and
prevents any individual carrier’s operational and marketing bias from overtly inf-
luencing the shipper choice. Consequently, CzarLite rates are often used as a base
for negotiating LTL contracts among shippers, carriers, and third-party logistics
providers.
In Fig. 20.5, we provide the LTL cost charged by one carrier for shipping 4,000
pounds as a function of the distance from Chicago. The cost is given for two
classes, class 100 and class 150. As you can see, in this case, the transportation
cost function is not linear with distance.
Warehouse Costs
Warehousing and distribution center costs include three main components:
1. Handling costs: These include labor and utility costs that are proportional
to annual ﬂow through the warehouse.

20.2 Network Design
387
FIGURE 20.5. Transportation rates for shipping 4,000 lb
2. Fixed costs: These capture all cost components that are not proportional
to the amount of material that ﬂows through the warehouse. The ﬁxed cost
is typically proportional to warehouse size (capacity); the cost is a stepwise
function of the warehouse capacity: That is, this cost is ﬁxed in certain ranges
of the warehouse size.
3. Storage costs. These represent inventory holding costs, which are propor-
tional to average positive inventory levels.
Thus, estimating the warehouse handling costs is fairly easy, while estimating the
other two cost values is quite diﬃcult. To see this diﬀerence, suppose that during
the entire year 1,000 units of product are required by a particular customer. These
1,000 units are not required to ﬂow through the warehouse at the same time,
so the average inventory level will likely be signiﬁcantly lower than 1,000 units.
Thus, when constructing the data for the APS, we need to convert these annual
ﬂows into actual inventory amounts over time. Similarly, annual ﬂow and average
inventory associated with this product tell us nothing about how much space is
needed for the product in the warehouse. This is true because the amount of space
that the warehouse needs is proportional to peak inventory, not annual ﬂow or
average inventory.
An eﬀective way to overcome this diﬃculty is to utilize the inventory turnover
ratio. This is deﬁned as the annual sales divided by the average inventory level.
Speciﬁcally, in our case, the inventory turnover ratio is the ratio of the total annual
outﬂow from the warehouse to the average inventory level. Thus, the average
inventory level is the total annual ﬂow divided by the inventory turnover ratio.
Multiplying the average inventory level by the inventory holding cost gives the
annual storage costs. Finally, to calculate the ﬁxed cost, we need to estimate the
warehouse capacity. This is done in the next subsection.
Warehouse Capacities
Another important input to the distribution-network design model is the actual
warehouse capacity. It is not immediately obvious, however, how to estimate
the actual space required, given the speciﬁc annual ﬂow of material through the

388
20. Network Planning
warehouse. Again, the inventory turnover ratio suggests an appropriate approach.
As before, the annual ﬂow through a warehouse divided by the inventory turnover
ratio allows us to calculate the average inventory level. Assuming a regular ship-
ment and delivery schedule, such as that given in Fig. 7.1, it follows that the
required storage space is approximately twice that amount. In practice, of course,
every pallet stored in the warehouse requires an empty space to allow for access and
handling; thus, considering this space as well as space for aisles, picking, sorting,
and processing facilities, as well as automatic guided vehicles (AGVs), we typically
multiply the required storage space by a factor (> 1). This factor depends on the
speciﬁc application and allows us to assess the amount of space available in the
warehouse more accurately. A typical factor used in practice is 3. This factor would
be used in the following way. Consider a situation where the annual ﬂow through
the warehouse is 1,000 units and the inventory turnover ratio is 10.0. This implies
that the average inventory level is about 100 units and, hence, if each unit takes
10 ft2 of ﬂoor space, the required space for the products is 2,000 ft2. Therefore, the
total space required for the warehouse is about 6,000 ft2.
Potential Warehouse Locations
It is also important to eﬀectively identify potential locations for new warehouses.
Typically, these locations must satisfy a variety of conditions:
• geographical and infrastructure conditions;
• natural resources and labor availability;
• local industry and tax regulations;
• public interest.
As a result, only a limited number of locations would meet all the requirements.
These are the potential location sites for the new facilities.
Service-Level Requirements
There are various ways to deﬁne service levels in this context. For example,
we might specify a maximum distance between each customer and the warehouse
serving it. This ensures that a warehouse will be able to serve its customers within
a reasonable time. Sometimes we must recognize that for some customers, such as
those in rural or isolated areas, it is harder to provide the same level of service that
most other customers receive. In this case, it is often helpful to deﬁne the service
level as the proportion of customers whose distance to their assigned warehouse
is no more than a given distance. For instance, we might require that 95 % of the
customers be situated within 200 miles of the warehouses serving them.
Future Demand
As observed in Chap. 1, decisions at the strategic level, which include
distribution-network design, have a long-lasting eﬀect on the ﬁrm. In particular,

20.2 Network Design
389
decisions regarding the number, location, and size of warehouses have an impact
on the ﬁrm for at least the next three to ﬁve years. This implies that changes
in customer demand over the next few years should be taken into account when
designing the network. This is most commonly addressed using a scenario-based
approach incorporating net present value calculations. For example, various pos-
sible scenarios representing a variety of possible future demand patterns over the
planning horizon can be generated. These scenarios can then be directly incorpo-
rated into the model to determine the best distribution strategy.
Model and Data Validation
The previous subsections document the diﬃculties in collecting, tabulating, and
cleaning the data for a network-conﬁguration model. Once this is done, how do we
ensure that the data and model accurately reﬂect the network-design problem?
The process used to address this issue is known as model and data validation.
This is typically done by reconstructing the existing network conﬁguration using
the model and collected data, and comparing the output of the model to existing
data.
The importance of validation cannot be overstated. Valuable output of the
model conﬁgured to duplicate current operating conditions includes all costs—
warehousing, inventory, production, and transportation—generated under the cur-
rent network conﬁguration. These data can be compared to the company’s acc-
ounting information. This is often the best way to identify errors in the data,
problematic assumptions, modeling ﬂaws, and so forth.
In one project we are aware of, for example, the transportation costs calculated
during the validation process were consistently underestimating the costs suggested
by the accounting data. After a careful review of the distribution practices, the
consultants concluded that the eﬀective truck capacity was only about 30 % of the
truck’s physical capacity; that is, trucks were being sent out with very little load.
Thus, the validation process not only helped calibrate some of the parameters used
in the model but also suggested potential improvements in the utilization of the
existing network.
It is often also helpful to make local or small changes in the network conﬁgu-
ration to see how the system estimates their impact on costs and service levels.
Speciﬁcally, this step involves positing a variety of what-if questions. This includes
estimating the impact of closing an existing warehouse on system performance. Or,
to give another example, it allows the user to change the ﬂow of material through
the existing network and see the changes in the costs. Often, managers have good
intuition about what the eﬀect of these small-scale changes on the system should
be, so they can more easily identify errors in the model. Intuition about the eﬀect
of radical redesign of the entire system is often much less reliable. To summarize,
the model-validation process typically involves answering the following questions:
• Does the model make sense?
• Are the data consistent?

390
20. Network Planning
• Can the model results be fully explained?
• Did you perform sensitivity analysis?
Validation is critical for determining the validity of the model and data, but
the process has other beneﬁts. In particular, it helps the user make the connection
between the current operations, which were modeled during the validation process,
and possible improvements after optimization.
Key Features of a Network-Conﬁguration APS
One of the key requirements of any advance planning system for network design
is ﬂexibility. In this context, we deﬁne ﬂexibility as the ability of the system to
incorporate a large set of preexisting network characteristics. Indeed, depending
on the particular application, a whole spectrum of design options may be appro-
priate. At one end of this spectrum is the complete reoptimization of the existing
network. This means that each warehouse can be either opened or closed and all
transportation ﬂows can be redirected. At the other end of the spectrum, it may
be necessary to incorporate the following features in the optimization model:
1. Customer-speciﬁc service-level requirements.
2. Existing warehouses. In most cases, warehouses already exist and their leases
have not yet expired. Therefore, the model should not permit the closing of
these warehouses.
3. Expansion of existing warehouses. Existing warehouses may be expandable.
4. Speciﬁc ﬂow patterns. In a variety of situations, speciﬁc ﬂow patterns (e.g.,
from a particular warehouse to a set of customers) should not be changed,
or perhaps more likely, a certain manufacturing location does not or cannot
produce certain SKUs.
5. Warehouse-to-warehouse ﬂow. In some cases, material may ﬂow from one
warehouse to another warehouse.
6. Production and bill of materials. In some cases, assembly is required and
needs to be captured by the model. For this purpose, the user needs to
provide information on the components used to assemble ﬁnished goods. In
addition, production information down to the line level can be included in
the model.
It is not enough for the advance planning system to incorporate all of the features
described above. It also must have the capability to deal with all these issues
with little or no reduction in its eﬀectiveness. The latter requirement is directly
related to the so-called robustness of the system. This stipulates that the relative
quality of the solution generated by the system (i.e., cost and service level) should
be independent of the speciﬁc environment, the variability of the data, or the
particular setting. If a particular advance planning system is not robust, it is
diﬃcult to determine how eﬀective it will be for a particular problem.

20.3 Strategic Safety Stock
391
20.3
Strategic Safety Stock
Important questions when designing the logistics network and when managing
inventory in a complex supply chain are where to keep safety stock and, similarly,
which facilities should produce to stock and which should produce to order? The
answers to these questions clearly depend on the desired service level, the supply
network, lead times as well as a variety of operational issues and constraints.
Thus, our focus is on a strategic model that allows the ﬁrm to position safety
stock eﬀectively in its supply chain.
To illustrate the tradeoﬀs and the impact of strategically positioning safety stock
in the supply chain, consider the following example.
ElecComp Inc. is a large contract manufacturer of circuit boards and other high-
tech parts. The company sells about 27,000 high-value products whose life cycle
is relatively short. Competition in this industry forces ElecComp to commit to
short lead times to its customers; this committed service time to the customers is
typically much shorter than manufacturing lead time. Unfortunately, the manu-
facturing process is quite complex, including a complex sequence of assemblies at
diﬀerent stages.
Because of the long manufacturing lead time and the pressure to provide cus-
tomers with a short response time, ElecComp kept inventory of ﬁnished products
for many of its SKUs. Thus, the company managed its supply chain based on
long-term forecast, the so-called push-based supply chain strategy. This make-to-
stock environment required the company to build safety stock and resulted in huge
ﬁnancial and shortage risks.
Executives at ElecComp had long recognized that this push-based supply chain
strategy was not the appropriate strategy for their supply chain. Unfortunately,
because of the long lead time, a pull-based supply chain strategy, in which manu-
facturing and assembly are done based on realized demand, was not appropriate
either.
Thus, ElecComp focused on developing a new supply chain strategy whose obj-
ectives are
1. reducing inventory and ﬁnancial risks,
2. providing customers with competitive response times.
This could be achieved by
• determining the optimal location of inventory across the various stages of
the manufacturing and assembly process,
• calculating the optimal quantity of safety stock for each component at each
stage.
Thus, the focus of redesigning ElecComp’s supply chain was on a hybrid strategy
in which a portion of the supply chain is managed based on push, that is, a make-
to-stock environment, while the remaining portion of the supply chain is managed

392
20. Network Planning
FIGURE 20.6. How to read the diagrams
based on pull, or a make-to-order strategy. Evidently, the supply chain stages
that produce to stock will be the locations where the company keeps safety stock,
while the make-to-order stages will keep no stock at all. Hence, the challenge
was to identify the location in the supply chain in which the strategy is switched
from a push-based, namely, a make-to-stock strategy, to a pull-based, that is, a
make-to-order supply chain strategy. This location is referred to as the push–pull
boundary.
ElecComp developed and implemented the new push–pull supply chain strategy,
and the impact was dramatic! For the same customer lead times, safety stock was
reduced by 40–60%, depending on product line. More importantly, with the new
supply chain structure, ElecComp concluded that they could cut lead times to
their customers by 50 % and still enjoy a 30 % reduction in safety stock.
Below we describe how this was achieved for a number of product lines.
An Illustrative Example
To understand the analysis and the beneﬁt experienced by ElecComp, consider
Fig. 20.6, in which a ﬁnished product (Part I) is assembled in a Dallas facility from
two components, one produced in the Montgomery facility and one in a diﬀerent
facility in Dallas. Each box provides information about the value of the product
produced by that facility; numbers under each box are the processing time at that
stage; bins represent safety stock. Transit times between facilities are provided as
well. Finally, each facility provides a committed response time to the downstream
facilities. For instance, the assembly facility quotes 30 days’ response time to its
customers. This implies that any order can be satisﬁed in no more than 30 days.
The Montgomery facility quotes an 88-day response time to the assembly facility.
As a result, the assembly facility needs to keep inventory of ﬁnished products in
order to satisfy customer orders within its 30 days’ committed service time.

20.3 Strategic Safety Stock
393
FIGURE 20.7. Current safety stock locations
Observe that if somehow ElecComp can reduce the committed service time from
the Montgomery facility to the assembly facility from 88 days to say 50 or perhaps
40 days, the assembly facility will be able to reduce its ﬁnished goods inventory
while the Montgomery facility will need to start building inventory. Of course,
ElecComp’s objective is to minimize system-wide inventory and manufacturing
costs; this is precisely what Inventory AnalystTM from LogicTools allows users to
do. By looking at the entire supply chain, the tool determines the appropriate
inventory level at each stage.
For instance, if the Montgomery facility reduces its committed lead time to
13 days, then the assembly facility does not need any inventory of ﬁnished goods.
Any customer order will trigger an order for Parts II and III. Part II will be
available immediately, since the facility producing Part II holds inventory, while
Part III will be available at the assembly facility in 15 days: 13 days’ committed
response time by the manufacturing facility plus 2 days’ transportation lead time.
It takes another 15 days to process the order at the assembly facility; therefore, the
order will be delivered to the customers within the committed service time. Thus,
in this case, the assembly facility produces to order, that is, a pull-based strategy,
while the Montgomery facility needs to keep inventory and hence is managed based
on push, that is, a make-to-stock strategy.
Now that the tradeoﬀs are clear, consider the product structure depicted in
Fig. 20.7. Light boxes (parts 4, 5, and 7) represent outside suppliers, whereas dark
boxes represent internal stages within ElecComp’s supply chain. Observe that the
assembly facility commits a 30-day response time to the customers and keeps
inventory of ﬁnished goods. More precisely, the assembly facility and the facility
manufacturing Part II both produce to stock. All other stages produce to order.
Figure 20.8 depicts the optimized supply chain that provides customers with the
same 30-day response time. Observe that by adjusting the committed service time
of various internal facilities, the assembly system starts producing to order and
keeps no ﬁnished goods inventory. On the other hand, the Raleigh and Montgomery
facilities need to reduce their committed service time and hence keep inventory.

394
20. Network Planning
FIGURE 20.8. Optimized safety stock locations
FIGURE 20.9. Optimized safety stock with reduced lead time
So where is the push and where is the pull in the optimized strategy? Evidently,
the assembly facility and the Dallas facility that produces Part II both operate
now in a make-to-order fashion—a pull strategy—while the Montgomery facility
operates in a make-to-stock fashion, a push-based strategy. The impact on the
supply chain is a 39 % reduction in safety stock!
At this point it was appropriate to analyze the impact of a more aggressive
quoted lead time to the customers. That is, ElecComp executives considered red-
ucing quoted lead times to the customers from 30 to 15 days. Figure 20.9 depicts
the optimized supply chain strategy in this case. The impact was clear. Relative
to the baseline (Fig. 20.7), inventory was down by 28 %, while response time to
the customers is halved.
Finally, Figs. 20.10 and 20.11 present a more complex product structure. Fig-
ure 20.10 provides information about the supply chain strategy before optimiza-
tion, and Fig. 20.11 depicts the supply chain strategy after optimizing the push–
pull boundary as well as inventory levels at diﬀerent stages in the supply chain.
Again, the beneﬁt is clear. By correctly selecting which stage is going to produce
to order and which is producing to stock, ElecComp reduced the inventory cost by
more than 60 % while maintaining the same quoted lead time to the customers.

20.3 Strategic Safety Stock
395
FIGURE 20.10. Current supply chain
Summary
Using a multistage inventory optimization technology (Inventory AnalystTM
from LogicTools), ElecComp was able to signiﬁcantly reduce inventory cost while
maintaining and sometimes signiﬁcantly decreasing quoted service times to the
customers. This was achieved by
1. Identifying the push–pull boundary; that is, identifying supply chain stages
that should operate in a make-to-stock fashion and hence keep safety stock.
The remaining supply chain stages operate in a make-to-order fashion and
thus keep no inventory. This is done by pushing inventory to less costly
locations in the supply chain.
2. Taking advantage of the risk-pooling concept. This concept suggests that
demand for a component used by a number of ﬁnished products has smaller
variability and uncertainty than that of the ﬁnished goods.
3. Replacing traditional supply chain strategies that are typically referred to
as sequential, or local, optimization by a globally optimized supply chain
strategy. In a sequential, or local, optimization strategy, each stage tries to
optimize its proﬁt with very little regards to the impact of its decisions on
other stages in the same supply chain. On the other hand, in a global supply
chain strategy, one considers the entire supply chain and identiﬁes strategies
for each stage that will maximize the supply chain performance.

396
20. Network Planning
FIGURE 20.11. Optimized supply chain
To better understand the impact of the new supply chain paradigm employed
by ElecComp, consider Fig. 20.12, where we plot the total inventory cost against
the quoted lead time to the customers. The upper tradeoﬀcurve represents the
traditional relationship between cost and quoted lead time to the customers. This
curve is a result of locally optimizing decisions at each stage in the supply chain.
The lower tradeoﬀcurve is the one obtained when the ﬁrm globally optimizes the
supply chain by locating the push–pull boundary correctly.
Observe that this shift of the tradeoﬀcurve, due to optimally locating the push–
pull boundary, implies the following:
1. For the same quoted lead time, the company can signiﬁcantly reduce cost,
or
2. For the same cost, the ﬁrm can signiﬁcantly reduce lead time.
Finally, notice that the curve representing the traditional relationship between
cost and customer quoted lead time is smooth, while the new tradeoﬀcurve rep-
resenting the impact of optimally locating the push–pull boundary is not, with
jumps in various places. These jumps represent situations in which the location of
the push–pull boundary changes and signiﬁcant cost savings are achieved.
Our experience is that those employing the new supply chain paradigm, like Elec-
Comp, typically chose a supply chain strategy that both reduce cost andcustomer

20.4 Resource Allocation
397
FIGURE 20.12. Global vs. local optimization
quoted lead time. This strategy allows ElecComp to satisfy demand much faster
than their competitors and develop a cost structure that enables competitive
pricing.
20.4
Resource Allocation
Supply chain master planning is deﬁned as the process of coordinating and all-
ocating production and distribution strategies and resources to maximize proﬁt
or minimize systemwide cost. In this process, the ﬁrm considers forecast demand
for the entire planning horizon, such as the next 52 weeks, as well as safety stock
requirements. The latter are determined, for instance, based on models similar to
the one analyzed in the previous section.
The challenge of allocating production, transportation, and inventory resources
in order to satisfy demand can be daunting. This is especially true when the ﬁrm
is faced with seasonal demand, limited capacities, competitive promotions, or high
volatility in forecasting. Indeed, decisions such as when and how much to produce,
where to store inventory, and whether to lease additional warehouse space may
have enormous impact on supply chain performance.
Traditionally, the supply chain planning process was performed manually with
a spreadsheet and was done by each function in the company independently of
other functions. That is, the production plan would be determined at the plant,
independently from the inventory plan, and would typically require the two plans
to be somehow coordinated at a later time. This implies that divisions typically
end up “optimizing” just one parameter, usually production costs.
In modern supply chains, however, this sequential process is replaced by a pro-
cess that takes into account the interaction between the various levels of the supply

398
20. Network Planning
FIGURE 20.13. The extended supply chain: from manufacturing to order fulﬁllment
chain and identiﬁes a strategy that maximizes supply chain performance. This is
referred to as global optimization, and it necessitates the need for an optimization-
based advance planning system. These systems, which model the supply chain as
large-scale mixed integer linear programs, are analytical tools capable of consider-
ing the complexity and dynamic nature of the supply chain.
Typically, the output from the tool is an eﬀective supply chain strategy that
coordinates production, warehousing, transportation, and inventory decisions. The
resulting plan provides information on production quantities, shipment sizes, and
storage requirements by product, location, and time period. This is referred to as
the supply chain master plan.
In some applications, the supply chain master plan serves as an input for a
detailed production scheduling system. In this case, the production scheduling
system employs information about production quantities and due dates received
from the supply chain master plan. This information is used to propose a detailed
manufacturing sequence and schedule. This allows the planner to integrate the
back end of the supply chain—manufacturing and production—and the front end
of the supply chain—demand planning and order replenishment; see Fig. 20.13.
This diagram illustrates an important issue. The focus of order replenishment
systems, which are part of the pull portion of the supply chain, is on the service
level. Similarly, the focus of the tactical planning, that is, the process by which
the ﬁrm generates a supply chain master plan, which is in the push portion of the
supply chain, is on cost minimization or proﬁt maximization. Finally, the focus in
the detailed manufacturing scheduling portion of the supply chain is on feasibility.
That is, the focus is on generating a detailed production schedule that satisﬁes all
production constraints and meets all the due-date requirements generated by the
supply chain master plan.
Of course, the output from the tactical planning process, namely, the supply
chain master plan, is shared with supply chain participants to improve coordination
and collaboration. For example, the distribution center managers can now better
use this information to plan their labor and shipping needs. Distributors can share
plans with their suppliers and customers in order to decrease costs for all partners
in the supply chain and promote savings. Speciﬁcally, distributors can realign
territories to better serve customers, store adequate amounts of inventory at the
customer site, and coordinate overtime production with suppliers.

20.4 Resource Allocation
399
In addition, supply chain master planning tools can identify potential supply
chain bottlenecks early in the planning process, allowing the planner to answer
questions such as
• Will leased warehouse space alleviate capacity problems?
• When and where should the inventory for seasonal or promotional demand
be built and stored?
• Can capacity problems be alleviated by rearranging warehouse territories?
• What impact do changes in the forecast have on the supply chain?
• What will be the impact of running overtime at the plants or outsourcing
production?
• What plant should replenish each warehouse?
• Should the ﬁrm ship by sea or by air? Shipping by sea implies long lead
times and therefore requires high inventory levels. On the other hand, using
air carriers reduces lead times and hence inventory levels but signiﬁcantly
increases transportation cost.
• Should we rebalance inventory between warehouses or replenish from the
plants to meet unexpected regional changes in demand?
Another important capability that tactical planning tools have is the ability to
analyze demand plans and resource utilization to maximize proﬁt. This enables
balancing the eﬀect of promotions, new product introductions, and other planned
changes in demand patterns and supply chain costs. Planners now are able to
analyze the impact of various pricing strategies as well as identify markets, stores,
or customers that do not provide the desired proﬁt margins.
A natural question is when should one focus on cost minimization and when on
proﬁt maximization? While the answer to this question may vary from instance to
instance, it is clear that cost minimization is important when the structure of the
supply chain is ﬁxed or at times of a recession and therefore oversupply. In this
case, the focus is on satisfying all demand at the lowest cost by allocating resources
eﬀectively. On the other hand, proﬁt maximization is important at time of growth,
namely, at the time when demand exceeds supply. In this case, capacity can be
limited because of the use of limited natural resources or because of expensive
manufacturing processes that are hard to expand, as is the case in the chemical
and electronic industries. In these cases, deciding who to serve and for how much
is more critical than costs savings.
Finally, an eﬀective supply chain master planning tool must also be able to help
the planners improve the accuracy of the supply chain model. This, of course,
is counterintuitive since the accuracy of the supply chain master planning model
depends on the accuracy of the demand forecast that is an input to the model. How-
ever, notice that the accuracy of the demand forecast is typically time-dependent.
That is, the accuracy of forecast demand for the ﬁrst few time periods, for ins-
tance, the ﬁrst 10 weeks, is much higher than the accuracy of demand forecast for

400
20. Network Planning
later time periods. This suggests that the planner should model the early portion
of the demand forecast at a great level of detail, that is, apply weekly demand
information. On the other hand, demand forecasts for later time periods are not
as accurate, and hence the planner should model the later demand forecast month
by month or by groups of 2–3 weeks each. This implies that later demand fore-
casts are aggregated into longer time buckets, and hence, due to the risk-pooling
concept, the accuracy of the forecast improves.
In summary, supply chain master planning helps address fundamental tradeoﬀs
in the supply chain such as setup cost versus holding costs or production lot sizes
versus capacities. It takes into account supply chain costs such as production,
supply, warehousing, transportation, taxes, and inventory, as well as capacities
and changes in the parameters over time.
This example illustrates how supply chain master planning can be used dyn-
amically and consistently to help a large food manufacturer manage the supply
chain. The food manufacturer makes production and distribution decisions at the
division level. Even at the division level, the problems tend to be large-scale.
Indeed, a typical division may include hundreds of products, multiple plants,
many production lines within a plant, multiple warehouses (including overﬂow
facilities), bill-of-material structures to account for diﬀerent packaging options,
and a 52-week demand forecast for each product for each region. The forecast ac-
counts for seasonality and planned promotions. The annual forecast is important
because a promotion late in the year may require production resources relatively
early in the year. Production and warehousing capacities are tight, and products
have a limited shelf life that needs to be integrated into the analysis. Finally, the
scope of the plan spans many functional areas, including purchasing, production,
transportation, distribution, and inventory management. Traditionally, the supply
chain planning process was performed manually with a spreadsheet and was done
by each function in the company. That is, the production plan would be done at
the plant, independently from the inventory plan, and would typically require the
two plans to be somehow coordinated at a later time. This implies that divisions
typically end up “optimizing” just one parameter, usually production costs. The
tactical planning APS introduced in the company allows the planners to reduce
systemwide cost and better utilize resources such as manufacturing and warehous-
ing. Indeed, a detailed comparison of the plan generated by the tactical tool with
the spreadsheet strategy suggests that the optimization-based tool is capable of
reducing total costs across the entire supply chain. See Fig. 20.14 for illustrative
results.
20.5
Summary
Optimizing supply chain performance is diﬃcult because of conﬂicting objectives,
demand and supply uncertainties, and supply chain dynamics. However, through
network planning, which combines network design, inventory positioning, and

20.5 Summary
401
FIGURE 20.14. Comparison of manual vs. optimized scenarios
Network
Inventory
Resource
design
positioning
allocation
Decision
Infrastructure
Safety
Production
focus
stock
distribution
Planning
Years
Months
Months
horizon
Aggregation
Family
Item
Classes
level
Frequency
Yearly
Monthly/
Monthly/
weekly
weekly
Return on
High
Medium
Medium
investment
Implementation
Very
Short
Short
short
User
Very
few
few
few
TABLE 20.1. Network planning characteristics
resource allocation, the ﬁrm can globally optimize supply chain performance. This
is achieved by considering the entire network, taking into account production,
warehousing, transportation, and inventory costs, as well as service-level require-
ments.
Table 20.1 summarizes the key dimensions of each of the planning activities, net-
work design, inventory positioning/management, and supply chain master plan-
ning. The table shows that network design involves long-term plans, typically over
years, is done at a high level and can yield high returns. The planning horizon for
supply chain master planning is months or weeks, the frequency of replanning is
high (e.g., every week), and it typically delivers quick results as well. Inventory

402
20. Network Planning
planning is focused on short-term uncertainty in demand, lead time, processing
time, or supply. The frequency of replanning is high, such as monthly planning
to determine appropriate safety stock based on the latest forecast and forecast
error. Inventory planning can also be used more strategically to identify locations
in the supply chain where the ﬁrm keeps inventory, as well as to identify stages
that produce to stock and those that produce to order.
20.6
Exercises
Exercise 20.1. Consider n independent and identically distributed random vari-
ables, X1, X2, . . . , Xn. Let Sn =
1
n
n
i=1 Xi. Find the variance of the random
variable Sn as a function of the variance of Xi.

21
A Case Study: School Bus Routing
21.1
Introduction
We now turn our attention to a case study in transportation logistics. We highlight
particular issues that arise when implementing an optimization algorithm in a real-
life routing situation. The case concerns the routing and scheduling of school buses
in the ﬁve boroughs of New York City.
Many of the vehicle routing problems we have discussed so far (see Part II)
have been simpliﬁed versions of the usually more complex problems that appear
in practice. Typically, a vehicle routing problem will have many constraints on
the types of routes that can be constructed, including multiple vehicle types, time
and distance constraints, complex restrictions on what items can be in a vehicle
together, and so forth. The problems that appear in the context of school bus
routing and scheduling could be characterized as the most diﬃcult types of vehi-
cle routing problems since they have aspects of all these constraints. This is the
problem we will consider here.
School bus routing and scheduling is an area where, in general, computerized
algorithms can have a large impact. User-friendly software that call routing and
scheduling algorithms at the click of a button and that result in workable sol-
utions can greatly aﬀect the day-to-day operations of a dispatching unit. With
increasingly aﬀordable high-speed computing power in desktop computers and
the possibility of displaying geographic information on-screen, it is not surprising
that many communities are using expert systems to perform the daunting task of
routing and scheduling their school buses. In most cases, this has led to improved
solutions in fractions of the time that was previously required.
D. Simchi-Levi et al., The Logic of Logistics: Theory, Algorithms, and Applications
for Logistics Management, Springer Series in Operations Research and Financial Engineering,
DOI 10.1007/978-1-4614-9149-1 21, © Springer Science+Business Media New York 2014
403

404
21. A Case Study: School Bus Routing
Unfortunately, providing workable solutions for such an application as this is
not as simple as just “clicking” the right button. Anyone who has been involved
in a real-life optimization application knows that much discussion is involved in
determining what the problem is and how we are to “solve” it. In this chapter, we
concern ourselves with some of the details that make it possible to put modeling
assumptions and algorithms into action.
21.2
The Setting
The New York City school system is composed of 1,069 schools and approximately
one million students. Most of these students either walk to school or are given pub-
lic transportation passes. About 125,000 students ride school buses that are leased
by the Board of Education. The majority, or about 83,000, of these are classiﬁed
as General Education students. These students walk to their neighborhood bus
stop in the morning and wait for a bus to take them to school. In the afternoon, a
bus takes them from their school and drops them oﬀback at their bus stop. The
rest of these students with particular needs, classiﬁed as Special Education, are
picked up and dropped oﬀdirectly at their homes.
This is one distinction that makes the transportation policies governing Special
Ed students fundamentally diﬀerent from those of General Ed students. Another
fundamental diﬀerence is that, in many cases, Special Ed students enroll in schools
with speciﬁc services and therefore may be bused over long distances. General Ed
students usually go to schools only a few miles from their homes and almost
exclusively to schools within the same borough. In addition, Special Ed students,
such as wheelchair-bound students, are transported in specially designed vehicles
with much smaller carrying capacities.
For General Ed student transportation, currently the Board of Education leases
approximately 1,150 buses a year. Many companies bid for the contract to trans-
port the students; currently, the companies winning contracts are responsible for
designing the routes. Independent of the company, the leasing cost to the Board is
approximately $80,000 annually for each bus (and driver). The total yearly bud-
get for General Education student transportation alone is therefore close to $100
million.
The routing of Special Education students is done diﬀerently. Using colored
pins and large maps placed on walls, a team of inspectors/routers at the Board of
Education Oﬃce of Pupil Transportation mark the students’ homes and schools.
Then, using their knowledge of the geography and street conditions acquired
through their many years of work, they literally string pins together to form
routes. Although the inspectors clearly do this well, this is very time-consuming.
For example, a group of ﬁve people took approximately three months to manually
generate routes just for the Borough of Manhattan.
Several years ago, the New York City Board of Education appropriated funds to
develop a computerized system, called CATS (computer-assisted transportation

21.2 The Setting
405
system). This system is supposed to help in the design of routes for both the
General and Special Ed students. The project consists of three phases, discussed
next.
Phase I: Replicate the pinning-and-stringing approach on a computer. The purpose
of this phase is to emulate on the computer screen what was previously done with
maps, pins, and string. First, a database is needed to keep track of all relevant
student and school information. The student data consist of address, bus stop,
and school. For each school, the data consist of an address, as well as starting
and ending times for all sessions. This makes data easily retrievable and updat-
able, and provides some of the basic information that is needed for routing and
scheduling. In addition to the database, a method of generating maps on the com-
puter is needed as well; this is the geographic information system (GIS). These
systems, widely available only in the last few years, truly oﬀer a new dimension
to many decision-support systems. With this software, color-coded objects des-
ignating students or schools can easily be displayed on a computer screen. This
enables the user to visualize the relative locations of important points. In addi-
tion, the user can “click and drag” with a mouse and get information about the
area outlined. This information can include U.S. Census data such as number of
households, median age, income, etc. More importantly, in this application, by
designating two points, the GIS can calculate exact locations (latitude and longi-
tude coordinates) and also the distance between the two points along the street
network. By “stringing” together a series of points, the software can give the total
distance traveled. When this phase is completed, inspectors currently designing
Special Ed routes will be able to “click” on bus stops with a mouse and “string”
them together on the computer screen. This is the method called “blocking and
stringing.”
Phase II: Extend the functionality developed in Phase I to the General Education
stop-to-school service. The goal is to create a system whereby one could construct
routes for the General Ed population on the computer screen. For example, by
choosing a set of schools with a mouse, the pertinent bus stops (those with stu-
dents going to the set of schools) are highlighted. The inspector can then string
together the stops and schools to form a route directly on the computer screen, or
again let the computer determine a good route through the stops. The immedi-
ate visualization of a possible solution (routes) along with relevant statistics (bus
load, total travel time, total students picked up) makes it much easier to check
the feasibility of the routes. This alone considerably simpliﬁes the task of building
eﬃcient routes.
Phase III: Create an optimization module. The aim here is to build software that
uses the student and school data and the GIS to generate eﬃcient bus routes and
schedules meeting existing transportation policies. The software should include
subroutines that check the feasibility of suggested routes or design routes for any
subset of the population, be it a school, a district, a borough, or the entire city.
This is the phase in which we are the most interested.

406
21. A Case Study: School Bus Routing
We present here a range of issues related to the development of this optimization
module (Phase III) and to the problem of routing buses through the New York
City streets. We focus on routing the General Ed students; the routing of Special
Ed students is currently being done at the Oﬃce of Pupil Transportation using
the “blocking-and-stringing” approach.
In Sect. 21.3, we give a short summary of some of the important papers that
have appeared in the literature in the area of school bus routing and scheduling
and related vehicle routing problems. In Sect. 21.4, we present details of the school
bus routing and scheduling problem in Manhattan. In Sect. 21.5, we give a brief
overview of the methodologies we used to estimate distances, travel times, and the
pickup and dropoﬀtimes.
When a computerized system for this problem is being designed, it is important
to consider the following questions. First, is it possible to design an algorithm that
will generate quality solutions in a reasonable amount of computing time? Second,
are routes constructed by the computerized system truly driveable? Third, what is
the best way to make these computerized algorithms of use to the people designing
the routes? To answer the ﬁrst two questions, we designed a school bus routing
and scheduling algorithm and ran it on the Manhattan data. The algorithm is pre-
sented in Sect. 21.6. To answer the third question, in Sect. 21.8, we discuss some
of the ways in which a computerized system for school bus routing can be made
more interactive. In Sect. 21.9, we present results on the Manhattan data.
21.3
Literature Review
In the operations research literature, we ﬁnd quite a few references to the problem
as well as many diﬀerent solution techniques. A standard way the school bus
routing and scheduling problem has been analyzed is to decompose it into two
problems: a route-generation problem, where simple routes are designed (usually
with only one school); and a route scheduling problem, where these routes are
linked to form longer routes (routes that visit more than one school).
As early as 1969, Newton and Thomas looked at a bus routing problem for a sin-
gle school. Using some of the ﬁrst local improvement procedures for vehicle routing
problems, they designed a tour through all the bus stops and then partitioned it
into smaller feasible routes that each could be covered by a bus.
In 1972, Angel et al. considered a clustering approach to generating routes. First,
bus stops are grouped by their proximity using a clustering algorithm. Then an
attempt is made to ﬁnd minimum-length routes through these clusters in such a
way that the constraints are satisﬁed. Finally, some clusters are merged if this
is feasible. The algorithm was applied to an instance consisting of approximately
1,500 students and 5 schools in Indiana.
In 1972, Bennett and Gazis considered the problem of generating routes. They
modiﬁed the savings algorithm of Clarke and Wright (1964) (see Sect. 17.2). They
also experimented with diﬀerent objective functions, such as minimizing total
student-miles. The problem considered had 256 bus stops and approximately 30
routes in Toms River, New Jersey.

21.4 The Problem in New York City
407
In 1979, Bodin and Berman used a 3-opt procedure to generate an initial
traveling salesman tour that is then partitioned into feasible routes. This algo-
rithm uses two additional components: a lookahead feature and a bus stop splitter.
The lookahead feature allows the initial order to be changed slightly. The bus stop
splitter allows a bus stop to be split into smaller bus stops. Two problems were
studied. One dealt with a school district in a densely populated suburban area with
13,000 students requiring bus transportation each day and 25 schools. A second
district, also in a suburban area, had 4,200 students transported.
In 1984, Swersey and Ballard addressed only the problem of scheduling a set
of routes that had already been designed. Given a set of routes that delivered all
students from their bus stops to their schools, the authors devised a method to ﬁnd
the minimum number of buses that could “cover” these routes. This scheduling
problem can be formulated as a diﬃcult integer program. The authors used some
simple cutting planes to solve it heuristically. The size of the problem considered
was approximately 30–38 buses and 100 routes.
Finally, in 1986, Desrosiers et al. studied a bus routing problem in Montr´eal,
Canada. Using several techniques, depending on whether the stops were in rural or
urban areas, they generated a set of routes. To schedule them, they formulated the
problem as an integer program and solved it using a column-generation approach.
The problem solved had 60 schools and 20,000 students.
21.4
The Problem in New York City
Depending on how generally it is formulated, the school bus routing and scheduling
problem can take many forms. In its most general form, the problem consists of
a set of students distributed in a region who have to be brought to and from
their schools every school day. The problem consists of determining bus stop loc-
ations, assigning students to bus stops, and ﬁnally routing and scheduling the
buses so as to minimize the total operating cost while following all transportation
guidelines. The diﬃculty, of course, is that each of these subproblems is dependent
and therefore should be looked at simultaneously. That is, any determination of
bus stop locations, and who gets assigned to each, clearly has an impact on the
routes and schedules of the buses. Hence, an integrated approach is required to
avoid suboptimality. However, due to the complexity and the size of the problem,
this has historically never been attempted. In addition, often it is not necessarily
possible to reoptimize all aspects of the problem, such as bus stop locations or
assignments.
To understand why this problem is so complex, consider, for instance, the bus
stop location problem on its own. There are numerous constraints and require-
ments: No more than a certain number of students can be assigned to the same
bus stop; bus stops cannot be within a certain distance of each other; each student
must be within a short walk of the bus stop and must not cross a major thorough-
fare; and so on.

408
21. A Case Study: School Bus Routing
In our case, the Board of Education decided that the bus stops that are currently
being used will remain in use. Thus, the position of the bus stops as well as
which students are assigned to each were assumed ﬁxed. These stops satisfy all
the requirements mentioned above. Our routing and scheduling problem thus starts
with a set of bus stops, each with a particular number of students assigned to it
destined for a particular school. Each school has starting and ending times for each
session. In addition to bus stop and school data, it is assumed that the distance
and travel time between any two points in the area are readily available. This issue
will be discussed in more detail in Sect. 21.5.
We formally deﬁne a route as follows. A route is a sequence of stops and possibly
several schools that can be feasibly driven by one bus. For example, routes for the
morning problem always start with a pickup at a stop and end with dropoﬀat a
school. In contrast, an afternoon route always starts with a pickup at a school and
ends with a dropoﬀat a stop.
The goal is to design a set of minimum-cost routes satisfying all existing trans-
portation guidelines. The major cost component to the Board of Education is the
cost of leasing each bus and driver, and hence the objective is essentially to mini-
mize the number of buses needed to feasibly transport the students. Clearly, safety
is the ﬁrst consideration, and it is the view of the Board of Education that bus
routes that meet all transportation guidelines provide a high level of safety. The
rest is up to the drivers.
Route feasibility is the most complex aspect of the problem. There are numerous
side constraints. First, the bus can hold only a limited number of students at one
time (capacity constraint). Second, each student must not be on the bus for more
than a speciﬁc amount of time and/or distance (time or distance constraint). This
is motivated by the simple observation that the less time spent on the bus, the
safer and more desirable it is for the students. And ﬁnally, there are restrictions
on the time a bus can arrive at a school in the morning, and on the time a bus
can leave the school in the afternoon (time-window constraints). In many school
bus routing and scheduling problems, transportation policies specify that students
from diﬀerent schools not be put on the same bus at the same time; that is, no
mixed loads are allowed. Clearly, allowing mixed loads provides increased ﬂexibility
and therefore can lead to savings in cost. In New York City, for the most part,
mixed loads are allowed. We list here the primary constraints. There are several
other constraints, which we talk about in Sect. 21.7.
We will deal exclusively here with the problem of delivering the students to
their school in the morning. Researchers have noted that this problem is usually
more critical than the afternoon problem for two reasons. First, in the afternoon,
the time windows are usually less constraining. For example, in Manhattan (in
the morning), school starting times fall between 7:30 and 9:00 a.m. That gives
roughly a one-and-a-half-hour time window to pick up all students and take them
to their schools. In the afternoon, schools end at times over a wider range: anywhere
between 1:00 and 4:15 p.m. Second, traﬃc congestion is usually higher in the
morning hours than in the afternoon hours when the students are being bused.
Therefore, it is very likely more buses will be needed in the morning than in the

21.5 Distance and Time Estimation
409
afternoon. Indeed, our computational experiments reported in Sect. 21.9 verify that
this is true in Manhattan. Note that the solution found in the morning cannot be
simply replicated in the afternoon, that is, having each bus travel the same route
as in the morning but in the opposite direction. This is true since the sequencing
of school ending times in the afternoon is diﬀerent from the sequencing of school
starting times; therefore, schools visited in one order in the morning cannot always
be visited in the same or opposite order in the afternoon.
For the morning problem in Manhattan, the speciﬁc problem parameters are
given below. During the 1992–1993 academic year, 4,619 students were transported
by school buses from 838 bus stops to 73 schools. The constraints were as follows.
• Vehicle capacity constraint. At most 66 students can be on the bus at one
time.
• Distance constraint. Each student cannot be on the bus for more than 5 miles.
• Time-window constraints. Buses must arrive at a school no earlier than
25 min before and no later than 5 min before the start of school.
• The earliest pickup must not be before 7:00 a.m.
• Mixed loads are allowed.
The 5-mile distance constraint is not applied uniformly to all students; students
in District 6 (upper Manhattan) are often transported out of their district due to
overcrowding. Therefore, since this involves longer trips, sometimes traversing most
of the island, the 5-mile constraint is not applied to these students. Approximately
36% of the students in our application were in this group.
The Manhattan school bus routing problem presents many challenges. First of
all, the number of bus stops and schools is much larger than those encountered in
most vehicle routing applications. Second, there are many diﬃculties involved in
calculating accurate distances and travel times in New York City. We now consider
these two points.
21.5
Distance and Time Estimation
To accurately estimate distances, one needs a precise geographic representation of
the area. This is achieved using a geographic information system (GIS,) which is
based on data ﬁles built from satellite photographs. These ﬁles store geographic
objects, such as streets, highways, parks, and rivers, that can be presented on a
computer screen. An important feature is the ability to calculate the exact latitudes
and longitudes of any point. When the GIS is given a street address, the process of
geocoding returns the coordinates of the address with very high accuracy. Having
these coordinates makes it easy to calculate “as the crow ﬂies,” or “Euclidean,”
distances. Some GISs also have the capability of calculating exact road network
distances, that is, the distance between two points on the actual street network,
sometimes even taking into account one-way streets.

410
21. A Case Study: School Bus Routing
The Oﬃce of Pupil Transportation at the Board of Education uses a GIS called
MapInfo for Windows. The MapInfo version used by the City does not have a street
network representation of New York City. However, such a network has been dev-
eloped by a subcontractor; therefore, accurate shortest distances between any two
points along the street network are readily available. The current version also takes
into account one-way streets. Although incorporating one-way street information
may seem like a trivial task, it turned out to be very diﬃcult. We believe most
current geographic information systems are highly inaccurate with regard to one-
way streets and are probably unusable without substantial error checking. The
New York City Department of Transportation does not keep the information in
an easily retrievable format. We had to resort to checking the one-way street sign
database at the NYC DOT to reconstruct accurate information about one-way
streets. Inevitably, the data collection and error checking were extremely time-
consuming.
Estimating accurate travel times in New York City is probably the trickiest
part of the problem. As described above, a GIS with a street network represen-
tation simpliﬁes the calculation of street distances. In addition, in the GIS, each
data structure corresponding to a street segment has space to store the average
travel speed and/or travel time along the segment. These estimates would make
it possible to calculate travel times along any path. The diﬃculty lies, of course,
in determining these travel speeds.
Most existing vehicle routing implementations that we are aware of use a ﬁxed
travel speed throughout the area of interest. Travel times are then determined by
simply dividing the distance traveled by this universal speed. This method is most
likely not satisfactory for New York City. Anyone who has driven in New York
City knows the multitude of diﬀerent street types and congestion levels that can
produce a wide variety of diﬀerent travel speeds. We decided to try to get some
idea of the average speed in diﬀerent parts of New York City.
In addition to performing various timing experiments, we obtained several
reports from the New York City Department of Transportation. These include
“Midtown Auto Speeds—Spring 1992” and “Midtown Auto Speeds—Fall 1992.”
These reports provide data on Midtown Manhattan average travel speeds as well as
some data on the variance of these speeds. (Midtown Manhattan is deﬁned as the
rectangular area between First and Eighth Avenues and 30th and 60th Streets.)
The data seem to suggest that speeds vary from an average of 6 miles per hour up
to about 14 miles per hour, depending on street type, direction, and time of day.
Our approach was to choose an estimate of speed that would be speciﬁc to each
district; thus, a district in the Bronx would not have the same speed estimate
as one in Midtown Manhattan. These range from about 7 to 12 miles per hour.
An important observation made when collecting data was that when a bus expe-
rienced below-average travel times (above-average speeds) along the beginning of
the route, the bus driver will slow down or spend more time at the stops to get
back on schedule. In addition, since the students have a scheduled pickup time,
the bus cannot, as a rule, leave early. It must wait until a speciﬁc time before leav-
ing the bus stop. If the bus experiences above-average travel times (below-average

21.6 The Routing Algorithm
411
speeds), then the bus driver can speed up (slightly) and make sure to leave as
soon as all students are on the bus. Consequently, the travel time is not quite as
random as one might think.
To make sure that school buses meet the time-window constraints, simply having
information about travel time along the streets of New York City is not suﬃcient.
The time to pick up students from their bus stops and to drop oﬀstudents at
their schools must also be taken into account. By riding the buses, we collected
data on the time it takes to pick up or drop oﬀstudents at stops or at schools.
A linear regression was performed on the data, providing the following model for
the pickup time:
PT ime = 19.0 + 2.6N,
where PT ime = pickup time (in s), and N = the number of students picked up
at the bus stop. This regression was performed on 30 data points. The R2 was
77.7 % and the p-value of the independent variable was very small (< 0.001). The
regression performed on the dropoﬀtimes resulted in the equation
DT ime = 29.0 + 1.9N,
where DT ime = dropoﬀtime (in s), and N = the number of students dropped
oﬀat the school. This regression was performed on 30 data points. Here the R2
was 41.9 % and the p-value of the independent variable was 0.01 %. In our imple-
mentation, we used these equations to determine approximate pickup and dropoﬀ
times.
Overall, the approximations and calculations made in testing the optimization
module were designed with the goal of ensuring that a route constructed by the
algorithm would be a driveable one. The next question is how to generate a good
feasible solution to the school bus routing and scheduling problem.
21.6
The Routing Algorithm
There are many existing algorithms for school bus routing and scheduling. Numer-
ous communities throughout the world have implemented computerized algorithms
to perform these tasks. Overall, the success seems to be universally recognized.
Almost all papers published in the literature mention cost savings of around
5–10%. We recognize that it may be useless to even contemplate the meaning
of these savings numbers since the savings may come not only from a reduction
in cost but also from increased control of the bus routes. The magnitude of the
“savings” is also highly dependent on what methods were in use before the com-
puterized system was put into place.
Transferability seems to be the critical factor. It is diﬃcult to compare algo-
rithms for this problem directly from the literature. Each problem has its own
version of the constraints and even objectives. It is not always simple or even pos-
sible to take an existing algorithm in use in one community and simply apply it
to another. Each problem has its peculiarities and may also have very diﬀerent

412
21. A Case Study: School Bus Routing
constraints. For instance, in an implementation in Montr´eal, the people designing
the routes have the freedom to change existing school starting and ending times at
their convenience. Clearly, this added ﬂexibility can simplify the problem to some
extent and can lead to additional savings in cost. In New York City, this was not
possible.
Finally, this is all within the framework of an optimization problem, which we
have seen is extremely diﬃcult to solve. There is an absence of any strong lower
bounds on the minimum number of buses required.
In determining what type of algorithm to apply to this large vehicle routing
problem, we considered several important aspects of the problem and also the
setting in which the algorithm would be used.
Eﬃciency This is an extremely large problem, so the solution method must be
eﬃcient in computation time and in space requirement. While we might want
to optimize by district, the fact is that some districts have as many as 1,500
bus stops. Even though complete optimization of the solution might only be
done once a year, the time involved in testing and experimenting with the
problem parameters is reduced considerably if the algorithm is time- and
space-eﬃcient.
Transparency The algorithm would most likely need to be constructive in na-
ture, thereby providing a dispatcher with the ability of viewing the algorithm
progression in real time. This makes it possible to detect “problem routes”
and correct errors without having to wait until the termination of the algo-
rithm. That is, the approach should build routes in a sequential fashion and
not, for example, work for hours and ﬁnally, in the last moments, provide a
solution.
Flexibility The heuristic should be ﬂexible enough to handle not only the con-
straints currently in place, but also additional constraints that might be
imposed in the future.
Interactivity From our discussions with the inspectors, it is clear that the algo-
rithm implemented must have an interactive component that would allow an
experienced inspector to help construct routes using his or her prior knowl-
edge. That is, the algorithm must be able to work in two diﬀerent modes.
First, it must be able to act like a black box, where data are input and a
solution is output. Second, it must also serve as an interactive tool, where
a starting solution can be presented along with a set of unrouted stops and
the algorithm ﬁnds the best way to add on to this starting solution.
Multiple solutions The algorithm should be capable of producing a series of
solutions, not simply one solution. This last point is important since each
solution would have to be checked by an inspector, and it is possible that
the inspector will rule out some solutions.
Finally, the urban nature of our application, in contrast to many of the problems
seen in the literature, should also be taken into account. As many researchers have

21.6 The Routing Algorithm
413
noted [see Bodin and Berman (1979) and Chapleau et al. (1983)], the vehicle
capacity constraint tends to be the most binding constraint when routing in an
urban area. This is due to the general rule that the bus will tend to “ﬁll up” before
the time constraints become an issue. Therefore, it seems as though algorithms
developed for the capacitated vehicle routing problem (CVRP) (see Chap. 17)
should be a good starting point. The diﬃculty is that the CVRP generally has a
diﬀerent objective function: Minimize the total distance traveled, not the number
of vehicles used. Fortunately [see Chap. 17 or Bramel et al. (1991)], if the number of
pickup points is very large and distances follow a general norm, when the distance is
minimized, a byproduct of the solution is that the minimum number of vehicles will
be used. Observe that distances in New York City come from the street network,
not from a norm; however, since the blocks are short and somewhat uniform in
size, the street network distance is fairly close to a norm distance, and similar
results most likely hold.
For these reasons, our starting point for the algorithm for the school bus routing
and scheduling problem was the location-based heuristic (LBH) (see Sect. 17.7)
developed for the CVRP. This algorithm has the important property that it is
asymptotically optimal for the CVRP (see Sect. 17.7); that is, the relative error
between the value of the solution generated by the algorithm and the optimal
solution value tends to zero as the number of pickup points increases.
Due to the size and complexity of the problem, we made several changes to the
LBH. The algorithm is serial in nature, as it constructs one route at a time and
not in parallel. To describe the algorithm, let the bus stops be indexed 1, 2, . . . , n.
Let a route run by a single bus be denoted Ri. Let a full solution to the school bus
routing and scheduling problem be written as a set of routes {R1, R2, . . . , RM},
where M is the number of buses used. For each bus stop j, let school [j] be the
index of the school to which the students at stop j are destined. Let U be the set
of indices of all unvisited pickup points.
The following algorithm creates one solution to the school bus routing and
scheduling problem. More solutions can be generated by starting the algorithm
with diﬀerent random seeds.
Randomized LBH:
Let U = {1, 2, . . ., n} and m = 0.
while (U ̸= ∅) do
{
Pick a seed stop from U using a selection criterion. Call it j.
Let U ←U \ {j}.
Let the current route be Rm = {j →school[j]}.
repeat
{
For each i ∈U, calculate ci =routelength(i, Rm).
Let ck = mini∈U{ci}.
If ck < +∞, then

414
21. A Case Study: School Bus Routing
{
Let Rm ←buildroute(k, Rm).
Let U ←U \ {k}.
}
} until ck = +∞.
m ←m + 1.
}
M ←m.
The heuristic solution is {R1, R2, . . . , RM}.
The selection of the seed stops can be done in one of several diﬀerent ways.
One approach is to simply select these stops at random from the set of unvisited
stops. Another approach is to select stops with large loads or stops that have
tight delivery windows (i.e., the distance and time constraints force these stops
to be delivered almost directly from the stop to the school with very few stops in
between). Other criteria were used according to which constraints were binding at
particular stops.
The function routelength(i, R) determines the approximate cost of inserting stop
i into route R. Route R consists of a path through several stops and schools. While
preserving the order of the stops and schools in route R, we determine the best
insertion point for stop i. We check each consecutive pair of points (either stops
or schools) along route R and check whether stop i can be inserted between these
two. If school[i] is not in route R, then we must ﬁnd not only the best insertion
point for stop i, but also the best insertion point for school[i]. It is possible that no
insertion point(s) can be found that results in a feasible route. Checking whether
a stop can be inserted requires checking all the constraints. If no feasible insertion
point exists, then the value of routelength(i, R) is made +∞. This indicates that it
is not possible (while preserving the order of R) to insert stop i into route R. If an
insertion is found that results in a feasible route, then the value of routelength(i, R)
is made to be exactly the additional distance traveled.
To illustrate the diﬃculty of this step, consider simply the capacity constraint.
In the case of the CVRP, all loads are dropped oﬀat the same point (the ﬁnal
stop); therefore, the maximum load that is carried by the vehicle is when it picks
up its last load. Therefore, it is easy to check whether a stop can be added to a
route since we need only check that the maximum load is less than the vehicle
capacity. This maximum load is always at the last stop, so the calculation is
easy. By contrast, performing a similar calculation in the school bus routing and
scheduling problem is much more complicated since there is more than one dropoﬀ
point. Checking feasibility when adding a stop to a route requires knowing when
the student is getting on and oﬀthe bus, since this will aﬀect whether there is
room for a student at future points on the bus route. Therefore, checking whether
the capacity constraint is violated in the school bus routing problem is much more
complicated than in the CVRP.
The function buildroute(k, R) creates the route that results from the insertion of
stop k into route R. Again, stop k is simply inserted between the two consecutive

21.7 Additional Constraints and Features
415
points (stops or schools) that result in the shortest total route. This route is
guaranteed to be feasible since ck < +∞.
The algorithm satisﬁes the requirements that we described above. It runs eﬃ-
ciently for problems of a large size and builds routes sequentially. It is very ﬂexible
in the sense that constraints of almost any type can be included (e.g., disallowing
mixed loads for some schools). Of course, each additional constraint causes the
algorithm to take a little longer to ﬁnd a solution. In terms of its interactivity (see
the next section for details), the algorithm can be used in an interactive mode if
this is desired. In this mode, a partial routing solution can be used as a starting
point and unrouted stops can be added eﬃciently. The inspector can also have a
major impact on the routes generated by the algorithm via the selection of the
seed points (see Sect. 21.8 below for a further discussion on this point). Since the
algorithm can be easily randomized (by randomizing the seed stop selection pro-
cedure), starting the algorithm with diﬀerent random numbers makes it generate
diﬀerent solutions. Finally, the most important advantage of this heuristic is that
it does not decompose the problem into subproblems, but solves the routing and
scheduling components simultaneously.
21.7
Additional Constraints and Features
In the course of the implementation of our algorithm, several additional “soft”
constraints came to our attention. These are subtle rules that inspectors used when
constructing feasible routes, which were only determined once a set of routes were
shown to the inspectors.
Limit on the number of buses to a particular school This is best expla-
ined with an example. Consider the situation where a school, say school
A, has a late starting time relative to other schools, say 9:30 a.m., where
all other schools start at 9 a.m., and assume only a dozen of the students
from school A require bus service. Previously, if a solution required 20 buses
to serve all schools, routers would take one of these and have it alone serve
school A. That is, some time between 9 and 9:30 a.m., one bus would pick
up the dozen students and deliver them to school A. Since 20 buses are used
in the solution, this solution is equivalent to, for example, having 6 of the
20 buses each deliver 2 students to school A between 9 and 9:30 a.m. This,
from a cost point of view, is just as good a solution. However, school A may
only be able to handle one or two buses at a time due to limited driveway
space. We therefore needed to add a constraint on the number of buses that
could deliver students to each school. This constraint only became active for
a few schools.
Multilevel relational distance constraints When a driver is delivering pack-
ages to warehouses or to customers, a distance constraint is usually set on
the complete route and thus is limited to the driver’s working day. When a

416
21. A Case Study: School Bus Routing
bus driver is delivering students to schools, the distance constraint is really
student-speciﬁc. That is, each student’s trip is limited, not just the driver’s.
In the school bus routing and scheduling problem, the distance constraint
also illustrates the diﬃculty of modeling, through simple constraints, a real-
life problem. To illustrate this, consider the 5-mile distance constraint discussed
earlier. We found that this simple constraint was actually unsatisfactory for
this problem. For example, if a student was only 1 mile from school, then
it was not considered desirable to have him or her end up traveling 5 miles
on the bus. This student (and maybe more vociferously his or her parents)
would not consider this an equitable solution. We therefore decided to imple-
ment what we call a relational distance constraint. That is, for a multiplier
α, say α = 2, a student could not travel on the bus for more than α times
the distance the student’s bus stop was from school. The question was then
to what do we set α? We determined that the best rule was to divide the
region around a particular school into concentric rings. For example, if the
ﬁrst ring was 3 miles in radius, then a stop that was d ≤3 miles from the
school would have a distance constraint (on the bus) of α1d miles. Ring i
was assigned a multiplier αi, and this was repeated for each ring. Although
it took some time to determine appropriate multipliers, eventually this is the
type of distance constraint that was implemented.
Waiting-time constraint Another constraint that did not come to our atten-
tion until we presented our routes to the inspectors was the waiting-time
constraint. Again, this is something that is speciﬁc to the routing of people
as opposed to packages. Consider a simple problem with two schools, school
A starting at 8 a.m. and school B starting at 9 a.m. At 7:30 a bus picks
up both students for schools A and B and then arrives at school A in the
time window (say at 7:45) and drops oﬀonly those students who are going
to school A. Since school B starts at 9 a.m., the bus waits for half an hour
at school A until proceeding to pick up some more students for school B and
then arriving at school B at 8:45 and dropping oﬀall the students. A route
of this type, where students wait on the bus for half an hour, was deﬁnitely
not deemed acceptable. Therefore, we needed to add a constraint on the
amount of time a bus (with students on it) can wait idle. Five minutes was
the number that was eventually used.
Route balancing It is desirable that the routes in a solution be of similar
duration and total distance. It does not seem fair if one driver serves morn-
ing routes from 7 to 7:30 a.m. while another works from 7 to 9:30 a.m. The
balancing of the workloads is partially achieved by implementation of a route-
balance() subroutine that is called once, at the end of the algorithm. This
subroutine essentially moves stops and schools from heavily loaded routes to
less heavily loaded routes while maintaining feasibility of the solution. This
seemed to work very well.

21.8 The Interactive Mode
417
Single-route optimization Once a solution is determined, we may (and should)
optimize the sequencing of the stops and schools on each route individually.
That is, given a set of stops and schools that can be feasibly served by one
bus, in terms of service level, what is the “best” route to actually drive?
An objective that guarantees a high service level is to minimize the total
number of student-miles traveled (see, e.g., Bennett and Gazis (1972)). For
each route created, we call a procedure called route-opt(), which minimizes
the total number of student-miles while maintaining feasibility of the route.
21.8
The Interactive Mode
As we mentioned earlier, the complete rescheduling of all buses might only be done
once a year (in August). However, throughout the course of the school year, there
are quite a few small changes that must be made to the solution. These changes
could be caused by, for example:
• A school that previously did not request bus service does request service in
mid-year.
• A student changes address or school.
• A school’s session time changes.
One option might be simply to reoptimize all routes that are aﬀected by the
changes. This might cause major disruptions in a large number of routes. These
disruptions may translate to disruptions in the parents’ morning schedules, which
might overload the Oﬃce of Pupil Transportation telephone switchboard.
In essence, it is desirable to implement the changes while making the fewest dis-
ruptions to other students’ schedules.
This was the impetus for the development of the algorithm’s interactive mode.
Here it is possible to start the algorithm with a number of routes already created
and to simply add stops to or delete stops from these routes. Let’s consider what
happens when a stop is added to an existing set of routes. The user has the ability
to select from one of three options:
• Complete reoptimization. This corresponds to starting the reoptimization
from scratch, that is, throwing away all previously created routes. Optimiza-
tion then starts with all new stops added to the list of stops.
• Single-route reoptimization. This corresponds to selecting a route and check-
ing whether a particular stop can be added to it. This is done through a
simple route-check() subroutine. In this case, the route may be completely
resequenced.
• No reoptimization. In this case, the stop is simply inserted between two stops
on existing routes without any reoptimization.

418
21. A Case Study: School Bus Routing
Deleting a stop is somewhat easier to do; the user simply clicks the mouse on
the stop in question and deletes it from the current solution. The fact that this
may actually render the remaining route infeasible is a good illustration of the
complexity of the bus routing and scheduling problem. This is due to the waiting-
time constraint mentioned in the previous section. In either case, the user can
specify whether a reoptimization of the route is desired.
These optimization tools proved quite useful as they provided simple ways to
test what-if scenarios, tests that previously would have taken weeks, if not months.
21.9
Data, Implementation, and Results
To assess the eﬀectiveness of our algorithm, we attempted to solve the problem
using the Manhattan data given to us by the Oﬃce of Pupil Transportation, that
is, to use our algorithm to generate a solution and to check it for actual drivability.
We solved both the morning and the afternoon problem. We ﬁrst calculated
the shortest-distance matrix between all 911 points of interest (838 stops and 73
schools) along the street network. In our implementation, we used a speed of 8 miles
per hour for the entire borough. This was the lowest average speed in Midtown
Manhattan along a street or avenue between 7 and 10 a.m. (the time interval
that the bus would be traveling in the morning) reported by the Department of
Transportation. We feel that this average speed is quite conservative and that, on
average, a bus can travel more quickly. One reason for this is that the measurement
was made in Midtown Manhattan, a location with very high congestion throughout
the day.
The algorithm was run on a PC (486DX2/50 megahertz) under Windows over
a period of several hours. To generate its ﬁrst feasible solution, the algorithm
takes about 40 min. We repeated the algorithm 40 times, keeping track of the best
solution. The algorithm has as output a detailed schedule and directions for each
bus.
In order to determine the sensitivity of the results to some of the assumptions we
have made, we ran the algorithm with several settings for the average travel speed.
We used 8, 10, and 12 mph. Note again that these speeds are conservative, as we
have also taken into account the time to stop and pick up or drop oﬀstudents.
The following table lists the number of buses used in the best solutions found for
each of these settings and for the morning and afternoon problems (Table 21.1).
TABLE 21.1. General Education routing
Universal
Number of buses used
speed (mph)
Morning
Afternoon
8
74
67
10
64
60
12
59
56

21.9 Data, Implementation, and Results
419
As a comparison, these solutions use substantially fewer buses than are currently
in use. We do not expect that the number of buses used will be as low as indicated
by our preliminary results, due to the fact that the routes have not been checked
by the inspectors. However, it is reasonable to assume that they will serve as a
starting solution that can be modiﬁed by the inspectors.

References
Aggarwal, A., & Park, J. K. (1993). Improved algorithms for economic lot-size
problems. Operation Research, 41, 549–571.
Agrawal, V., & Seshadri, S. (2000). Impact of Uncertainty and Risk Aversion
on Price and Order Quantity in the Newsvendor Problem. Manufacturing and
Service Operations Management, 2(4), 410–423.
Aho, A. V., Hopcroft, J. E., & Ullman, J. D. (1974). The design and analysis of
computer algorithms. Reading, MA: Addison-Wesley.
Altinkemer, K., & Gavish, B. (1987). Heuristics for unequal weight delivery prob-
lems with a ﬁxed error guarantee. Operation Research Letter, 6, 149–158.
Altinkemer, K., & Gavish, B. (1990). Heuristics for delivery problems with con-
stant error guarantees. Transportation Science, 24, 294–297.
Angel, R. D., Caudle, W. L., Noonan, R., & Whinston, A. (1972). Computer-
assisted school bus scheduling. Management Science, 18, 279–288.
Anily, S. (1991). Multi-item replenishment and storage problems (MIRSP): heuris-
tics and bounds. Operation Research, 39, 233–239.
Anily, S., Bramel, J., & Simchi-Levi, D. (1994). Worst-case analysis of heuristics
for the bin-packing problem with general cost structures. Operation Research,
42, 287–298.
D. Simchi-Levi et al., The Logic of Logistics: Theory, Algorithms, and Applications
for Logistics Management, Springer Series in Operations Research and Financial Engineering,
DOI 10.1007/978-1-4614-9149-1, © Springer Science+Business Media New York 2014
421

422
References
Archibald, B., & Silver, E. A. (1978). (s, S) policies under continuous review and
discrete compound Poisson demand. Management Science, 24, 899–908.
Arkin, E., Joneja, D., & Roundy, R. (1989). Computational complexity of uncapac-
itated multi-echelon production planning problems. Operation Research Letter,
8, 61–66.
Arrow, K., Harris, T., & Marschak , J. (1951). Optimal inventory policy. Econo-
metrica, 19, 250–272.
Atkins, D. R., & Iyogun, P. (1988). A heuristic with lower bound performance
guarantee for the multi-product dynamic lot-size problem. IIE Transactions,
20, 369–373.
Azuma, K. (1967). Weighted sums of certain dependent random variables. Tohoku
Mathematical Journal, 19, 357–367.
Baker, B. S. (1985). A new proof for the ﬁrst-ﬁt decreasing bin packing algorithm.
Journal of Algorithms, 6, 49–70.
Baker, K. R., Dixon, P., Magazine, M. J., & Silver, E. A. (1978). An algorithm for
the dynamic lot-size problem with time-varying production capacity constraints.
Management Science, 24, 1710–1720.
Balakrishnan, A., & Graves, S. (1989). A composite algorithm for a concave-cost
network ﬂow problem. Networks, 19, 175–202.
Balinski, M. L. (1965). Integer programming: methods, uses, computation. Man-
agement Science, 12, 253–313.
Balinski, M. L., & Quandt, R. E. (1964). On an integer program for a delivery
problem. Operation Research, 12, 300–304.
Ball, M. O., Magnanti, T. L., Monma, C. L., & Nemhauser, G. L. (Eds.) (1995).
Network routing, Handbooks in operations research and management science.
Amsterdam: North-Holland.
Ballou, R. H. (1992). Business logistics management (3rd ed.). Englewood Cliﬀs,
NJ: Prentice-Hall.
Barcelo, J., & Casanovas, J. (1984). A heuristic Lagrangian algorithm for the
capacitated plant location problem. European Journal of Operational Research,
15, 212–226.
Ba¸sar, T., & Olsder, G. J. (1999). Dynamic noncooperative game theory (Clas-
sics in applied mathematics). Philadelphia: Society for Industrial and Applied
Mathematics.
Beasley, J. (1983). Route ﬁrst–cluster second methods for vehicle routing. Omega,
11, 403–408.

References
423
Beardwood, J., Halton, J. L., & Hammersley, J. M. (1959). The shortest path
through many points. Proceedings of the Cambridge Philosophical Society, 55,
299–327.
Bell, C. (1970). Improved algorithms for inventory and replacement stock prob-
lems. SIAM Journal on Applied Mathematics, 18, 558–566.
Bennett, B., & Gazis, D. (1972). School bus routing by computer. Transportation
Research, 6, 317–326.
Bertsekas, D. P. (1987). Dynamic programming. Englewood Cliﬀs, NJ: Prentice-
Hall.
Bertsekas, D. P. (1995). Nonlinear programming. Boston: Athena Scientiﬁc.
Bernstein, F., & Federgruen, A. (2004). Dynamic inventory and pricing models for
competing retailers. Naval Research Logistics, 51, 258–274.
Bertsimas, D., & Simchi-Levi, D. (1996). The new generation of vehicle routing
research: robust algorithms addressing uncertainty. Operation Research, 44, 286–
304.
Bienstock, D., & Simchi-Levi, D. (1993). A note on the prize collecting traveling
salesman problem. Working Paper, Columbia University.
Bienstock, D., Bramel, J., & Simchi-Levi, D. (1993a). A probabilistic analysis of
tour partitioning heuristics for the capacitated vehicle routing problem with
unsplit demands. Mathematics of Operations Research, 18, 786–802.
Bienstock, D., Goemans, M., Simchi-Levi, D., & Williamson, D. (1993b). A note
on the prize collecting traveling salesman problem. Mathematical Programming,
59, 413–420.
Bodin, L., & Berman, L. (1979). Routing and scheduling of school buses by com-
puter. Transportation Science, 13, 113–129.
Bondareva, O. (1963). Some applications of linear programming methods to the
theory of cooperative games (in Russian). Problemy Kybernetiki, 10, 119–139.
Bourakiz, M., & Sobel, M. J. (1992). Inventory control with an exponential utility
criterion. Operation Research, 40, 603–608.
Braca, J., Bramel, J., Posner, B., & Simchi-Levi, D. (1997). A computerized ap-
proach to the New York City school bus routing problem. IIE Transactions, 29,
693–702.
Bramel, J., & Simchi-Levi, D. (1995). A location based heuristic for general routing
problems. Operation Research, 43, 649–660.

424
References
Bramel, J., & Simchi-Levi, D. (1996). Probabilistic analysis and practical algo-
rithms for the vehicle routing problem with time windows. Operation Research,
44, 501–509.
Bramel, J., & Simchi-Levi, D. (1997). On the eﬀectiveness of set covering formu-
lations for the vehicle routing problem. Operation Research, 45, 295–301.
Bramel, J., Coﬀman Jr., E. G., Shor, P., & Simchi-Levi, D. (1991). Probabilistic
analysis of algorithms for the capacitated vehicle routing problem with unsplit
demands. Operation Research, 40, 1095–1106.
Cachon, G. (2003). Supply chain coordination with contracts. In S. Graves, T. de
Kok Supply chain management: design, coordination and operation (Handbook of
operations research and management science (Vol. 11, pp. 229–340). Amsterdam:
Elsevier.
Cachon, G., & Lariviere, M. (2005). Supply chain coordination with revenue shar-
ing contracts: strengths and limitations. Management Science, 51, 30–44.
Cachon, G., & Netessine, S. (2004). Game theory in supply chain analysis. In
D. Simchi-Levi, S. D. Wu, Z. J. Max Shen (Eds.) Handbook of quantitative supply
chain analysis: modeling in the eBusiness era. Boston: Kluwer Academic.
Chapleau, L., Ferland, J. A., & Rousseau, J.-M. (1983). Clustering for routing in
dense area. European Journal of Operational Research, 20, 48–57.
Chan, L. M. A., Simchi-Levi, D., & Bramel, J. (1998). Worst-case analyses, lin-
ear programming and the bin-packing problem. Mathematical Programming, 83,
213–227.
Chandra, B., Karloﬀ, H., & Tovey, C. (1999). New results on the old k-opt al-
gorithm for the traveling salesman problem. SIAM Journal on Computing, 28,
1998–2029.
Chan, L. M. A., Muriel, A., & Simchi-Levi, D. (1999). Production/distribution
planning problems with piece-wise linear and concave cost structures. North-
western University.
Chan, L. M. A., Max Shen, Z. J., Simchi-Levi, D., & Swann, J. (2004). Coor-
dination of pricing and inventory (Chapter 3) In D. Simchi-Levi, S. D. Wu,
Z. J. Max Shen (Eds.) Handbook of quantitative supply chain analysis: modeling
in the eBusiness era. Boston: Kluwer Academic.
Chen, Y. F. (1996). On the optimality of (s, S) policies for quasiconvex loss func-
tions. Working Paper, Northwestern University.
Chen, X. (2003). Coordinating inventory control and pricing strategies (Ph.D. Dis-
sertation, Massachusetts Institute of Technology)

References
425
Chen, X. (2009), Inventory centralization games with price-dependent demand and
quantity discount. Operation Research, 57, 1394–1406.
Chen, F., & Federgruen, A. (2000). Mean-variance analysis of basic inventory
models. Working paper, Columbia University.
Chen, X., & Hu, P. (2012). Joint pricing and inventory management with deter-
ministic demand and costly price adjustment. Operation Research Letter, 40,
385–389.
Chen, X., & Simchi-Levi, D. (2004a). Coordinating inventory control and pricing
strategies with random demand and ﬁxed ordering cost: the ﬁnite horizon case.
Operation Research, 52, 887–896.
Chen, X., & Simchi-Levi, D. (2004b). Coordinating inventory control and pricing
strategies with random demand and ﬁxed ordering cost: the inﬁnite horizon case.
Mathematics of Operations Research, 29, 698–723.
Chen, X., & Simchi-Levi, D. (2009). A new approach for the stochastic cash bal-
ance problem with ﬁxed costs. Probability in the Engineering and Informational
Sciences, 23, 545–562.
Chen, X., & Simchi-Levi, D. (2012). Pricing and inventory management. P. Philips,
¨O. ¨Ozer (Eds.) Oxford handbook of pricing management (pp. 784–822). Oxford:
Oxford University Press.
Chen, X., & Sun, P. (2012). Optimal structural policies for ambiguity and risk
averse inventory and pricing models. SIAM Journal on Control and Optimiza-
tion, 50, 133–146.
Chen, X., & Zhang, J. (2009). A stochastic programming approach to inventory
centralization games. Operation Research, 57, 840–851.
Chen, F., & Zheng, Y. S. (1994). Lower bounds for multi-echelon stochastic inven-
tory systems. Management Science, 40, 1426–1443.
Chen, X., Sim, M., Simchi-Levi, D., & Sun, P. (2007). Risk aversion in inventory
management. Operation Research, 55, 828–842.
Chen, X., Zhang, Y., & Zhou, S. (2010). Integration of inventory and pricing
decisions with costly price adjustments. Operation Research, 58, 1012–1016.
Chen, X., Zhou, S., & Chen, F. (2011). Preservation of quasi-K-concavity and
its application to joint inventory-pricing models with concave ordering costs.
Operation Research, 58, 1012–1016.
Chen, X., Pang, Z., & Pan, L. (2012a). Coordinating inventory control and pric-
ing strategies for perishable products. Working Paper, University of Illinois at
Urbana-Champaign.

426
References
Chen, X., Hu, P., & He, S. (2012b). Preservation of supermodularity in two di-
mensional parametric optimization problems and its applications. This paper
has been accepted by Operations Research.
Chen, X., Hu, P., Shum, S., & Zhang, Y. (2012c). Stochastic inventory model with
reference price eﬀects. Working Paper.
Chou, M., Teo, C., & Zheng, H. (2008). Process ﬂexibility: design, evaluation, and
applications. Flexible Services and Manufacturing J., 20(1), 59–94.
Chou, M., Chua, G., Teo, C., & Zheng, H. (2010). Design for process ﬂexibility:
eﬃciency of the long chain and sparse structure. Operation Research, 58, 43–58.
Chou, M., Chua, G., Teo, C., & Zheng, H. (2011). Processs ﬂexibility revisited:
the graph expander and its applications. Operation Research, 59, 1090–1105.
Chou, M., Chua, G., Teo, C., & Zheng, H. (2012). On the performance of sparse
process structures in partial postponement production systems. Working Paper.
Christoﬁdes, N. (1976). Worst-case analysis of a new heuristic for the traveling
salesman problem. Report 388, Graduate School of Industrial Administration,
Carnegie-Mellon University, Pittsburgh, PA.
Christoﬁdes, N. (1985). Vehicle routing. In E. L. Lawler, J. K. Lenstra, A. H. G.
Rinnooy Kan, D. B. Shmoys (Eds.) The traveling salesman problem: a guided
tour of combinatorial optimization (pp. 431–448). New York: Wiley.
Christoﬁdes, N., Mingozzi, A., & Toth, P. (1978). The vehicle routing problem. In
N. Christoﬁdes, A. Mingozzi, P. Toth, C. Sandi (Eds.) Combinatorial optimiza-
tion (pp. 318–338). New York: Wiley.
Christoﬁdes, N., Mingozzi, A., & Toth, P. (1981). Exact algorithms for the ve-
hicle routing problem based on spanning tree and shortest path relaxations.
Mathematical Programming, 20, 255–282.
Churchman, C. W., Ackoﬀ, R. L., & Arnoﬀ, E. L. (1957). Introduction to operations
research. New York: Wiley.
Clark, A. J., & Scarf, H. E. (1960). Optimal policies for a multi-echelon inventory
problem. Management Science, 6, 475–490.
Clarke, G., & Wright, J. W. (1964). Scheduling of vehicles from a central depot to
a number of delivery points. Operation Research, 12, 568–581.
Coﬀman, E. G. Jr., & Lueker, G. S. (1991). Probabilistic analysis of packing and
partitioning algorithms. New York: Wiley.
Cornu´ejols, G., & Harche, F. (1993). Polyhedral study of the capacitated vehicle
routing problem. Mathematical Programming, 60, 21–52.

References
427
Cornu´ejols, G., Fisher, M. L., & Nemhauser, G. L. (1977). Location of bank ac-
counts to optimize ﬂoat: an analytical study of exact and approximate algo-
rithms. Management Science, 23, 789–810.
Council of Supply Chain Management Professionals: http://www.cscmp.org/.
Council on Logistics Management, mission statement, Council on Logistics Man-
agement Web Site: www.clm1.org/mission.html.
Croxton K. L., Gendron, B., Magnanti, T. L. (2003). A comparison of mixed-
integer programming models for non-convex piecewise linear cost minimization
problems. Management Science, 49, 1268–1273.
Cullen, F., Jarvis, J., & Ratliﬀ, D. (1981). Set partitioning based heuristics for
interactive routing. Networks, 11, 125–144.
Daskin, M. S. (1995). Network and discrete location: models algorithms and appli-
cations. New York: Wiley.
De Kok, A. G., & Graves, S. C. (Eds.) (2003). Supply chain management: design,
coordination and operations, Handbooks in operations research and management
science. Amsterdam: North-Holland.
Dematteis, J. J. (1968). An economic lot sizing technique: the part-period algo-
rithm. IBM Systems Joumal, 7, 30–38.
Denardo, E. V. (1996). Dynamic programming. In Avriel, M., Golany, B. (Eds.),
Mathematical programming for industrial engineers (pp. 307–384). Englewood
Cliﬀs, NJ: Marcel Dekker.
Deng, Q., & Simchi-Levi, D. (1992). Valid inequalities, facets and computa-
tional results for the capacitated concentrator location problem. Working Paper,
Columbia University.
Deng, S., & Yano, C. (2006). Joint production and pricing decisions with setup
costs and capacity constraints. Management Science, 52, 741–756.
Desrosiers, J., Ferland, J. A., Rousseau, J.–M., Lapalme, G., & Chapleau, L.
(1986). TRANSCOL: A multi-period school bus routing and scheduling system.
TIMS Studies in the Management Sciences, 22, 47–71.
Desrochers, M., Desrosiers, J., & Solomon, M. (1992). A new optimization algo-
rithm for the vehicle routing problem with time windows. Operation Research,
40, 342–354.
Dobson, G. (1987). The economic lot scheduling problem: a resolution of feasibility
using time varying lot sizes. Operation Research, 35, 764–771.
Dreyfus, S. E., & Law, A. M. (1977). The art and theory of dynamic programming.
New York: Academic Press.

428
References
Edmonds, J. (1965). Maximum matching and a polyhedron with 0,1-vertices. Jour-
nal of Research of the National Bureau of Standards B, 69B, 125–130.
Edmonds, J. (1971). Matroids and the greedy algorithm. Mathematical Program-
ming, 1, 127–136.
Eeckhoudt, L., Gollier, C., & Schlesinger, H. (1995). The risk-averse (and prudent)
newsboy. Management Science, 41(5), 786–794.
Eliashberg, J., & Steinberg, R. (1991). Marketing-production joint decision mak-
ing. In J. Eliashberg, J. D. Lilien (Eds.) Management science in marketing, Vol.
5 of Handbooks in Operations Research and Management Science. Amsterdam:
North-Holland.
Elmaghraby, W., & Keskinocak, P. (2003). Dynamic pricing in the presence of
inventory considerations: research overview, current practices, and future direc-
tions. Management Science, 49, 1287–1309.
Eppen, G., & Schrage, L. (1981). Centralized ordering policies in a multiwarehouse
system with lead times and random demand. In L. Schwarz (Ed.) Multi-level
production/inventory control systems: theory and practice. Amsterdam: North-
Holland.
Erlenkotter, D. (1990). Ford Whitman Harris and the economic order quantity
model. Operation Research, 38, 937–946.
Federgruen, A., & Heching, A. (1999). Combined pricing and inventory control
under uncertainty. Operation Research, 47(3), 454–475.
Federgruen, A., & van Ryzin, G. (1997). Probabilistic analysis of a generalized bin
packing problem with applications to vehicle routing and scheduling problems.
Operation Research, 45, 596–609.
Federgruen, A., & Simchi-Levi, D. (1995). Analytical Analysis of Vehicle Routing
and Inventory Routing problems. In M. O. Ball, T. L. Magnanti, C. L. Monma,
G. L. Nemhauser (Eds.) Handbooks in operations research and management sci-
ence, the volume on Network routing (pp. 297–373). Amsterdam: North-Holland.
Federgruen, A., & Tzur, M. (1991). A simple forward algorithm to solve general
dynamic lot sizing models with n periods in O(n log n) or O(n) time. Manage-
ment Science, 37, 909–925.
Federgruen, A., & Zipkin, P. (1984a). Approximation of dynamic, multi-location
production and inventory problems. Management Science, 30, 69–84.
Federgruen, A., & Zipkin, P. (1984b). Computational issues in the inﬁnite horizon,
multi-echelon inventory model. Operation Research, 32, 818–836.

References
429
Federgruen, A., & Zipkin, P. (1984c). Allocation policies and cost approximation
for multi-location inventory systems. Naval Research Logistic Quarterly, 31, 97–
131.
Few, L. (1955). The shortest path and the shortest road through n points. Math-
ematika, 2, 141–144.
Fisher, M. L. (1980). Worst-case analysis of algorithms. Management Science, 26,
1–17.
Fisher, M. L. (1981). The lagrangian relaxation method for solving integer pro-
gramming problems. Management Science, 27, 1–18.
Fisher, M. L. (1994). Optimal solution of vehicle routing problems using minimum
K-trees. Operation Research, 42, 626–642.
Fisher M. L. (1995). Vehicle routing. In M. O. Ball, T. L. Magnanti, C. L. Monma,
G. L. Nemhauser (Eds.) Handbooks in operations research and management sci-
ence, the volume on Network routing (pp. 1–33) Amsterdam: North-Holland.
Fisher, M. L., & Jaikumar, R. (1981). A generalized assignment heuristic for vehicle
routing. Networks, 11, 109–124.
Florian, M., & Klein, M. (1971). Deterministic production planning with concave
costs and capacity constraints. Management Science, 18, 12–20.
Florian, M., Lenstra, J. K., & Rinnooy Kan, A. H. G. (1980). Deterministic produc-
tion planning: algorithms and complexity. Management Science, 26, 669–679.
Fudenberg, D., & Tirole, J. (1991). Game theory. Cambridge, MA: MIT Press.
Gale, D., & Politof, T. (1981). Substitutes and complements in network ﬂow prob-
lems. Discrete Applied Mathematics, 3, 175–186.
Gallego, G., & van Ryzin, G. (1994). Optimal dynamic pricing of inventories with
stochastic demand over ﬁnite horizons. Management Science, 40, 999–1020.
Gallego, G., Queyranne, M., & Simchi-Levi, D. (1996). Single resource multi-item
inventory system. Operation Research, 44, 580–595.
Garey, M. R., & Johnson, D. S. (1979). Computers and intractability. New York:
W. H. Freeman and Company.
Garey, M. R., Graham, R. L., Johnson, D. S., & Yao, A. C. (1976). Resource
constrained scheduling as generalized bin packing. Journal of Combinatorial
Theory, Series A, 21, 257–298.
Gaskel, T. J. (1967). Bases for vehicle ﬂeet scheduling. Operational Research Quar-
terly, 18, 281–295.

430
References
Geunes, J., Romeijn, E., & Taaﬀe, K. (2006). Requirements planning with pricing
and order selection ﬂexibility. Operation Research, 54, 394–401.
Ghosh, A. (1994). Retail management (2nd ed.). New York, NY: Dryden Press
Harcourt Brace College Publishers.
Gillett, B. E., & Miller, L. R. (1974). A heuristic algorithm for the vehicle dispatch
problem. Operation Research, 22, 340–349.
Goemans M. X., & Bertsimas, D. J. (1993). Survivable networks, linear program-
ming relaxations and the parsimonious property. Mathematical Programming,
60, 145–166.
Golden, B. L., & Stewart, W. R. (1985). Empirical analysis of heuristics. In E. L.
Lawler, J. K. Lenstra, A. H. G. Rinnooy Kan, D. B. Shmoys (Eds.) The traveling
salesman problem: a guided tour of combinatorial optimization (pp. 207–249).
New York: Wiley.
Goyal, S. K. (1978). A note on “multi-product inventory situation with one re-
striction.” Journal of the Operational Research Society, 29, 269–271.
Graves, S. C. (2008). Flexibility principles. In Building intuition: insights from
basic operations management models and principles (Chapter 3, pp. 33–51) New
York: Springer.
Graves, S. C., & Schwarz, L. B. (1977). Single cycle continuous review policies for
arborescent production/inventory systems. Management Science, 23, 529–540.
Graves, S. C., & Willems, S. P. (2000). Optimizing strategic safety stock placement
in supply chains.” Manufacturing Service Operation Managemant, 2, 68–83.
Graves, S. C., Rinnooy Kan, A. H. G., & Zipkin, P. H. (Eds.) (1993). Logistics of
production and inventory. In Handbooks in operations research and management
science. Amsterdam: North-Holland.
Hadley, G., & Whitin, T. M. (1963). Analysis of inventory systems. Englewood
Cliﬀs, NJ: Prentice-Hall.
Haimovich, M., & Rinnooy Kan, A. H. G. (1985). Bounds and heuristics for ca-
pacitated routing problems. Mathematics of Operations Research, 10, 527–542.
Haimovich, M., Rinnooy Kan, A. H. G., & Stougie, L. (1988). Analysis of heuristics
for vehicle routing problems. In B. L. Golden, A. A. Assad (Eds.) Vehicle routing:
methods and studies (pp. 47–61). New York, NY: Elsevier Science Publishers,
B.V.
Hakimi, S. L. (1964) Optimum locations of switching centers and the absolute
centers and medians of a graph. Mathematics of Operations Research, 12, 450–
459.

References
431
Hall, N. G. (1988). A multi-item EOQ model with inventory cycle balancing. Naval
Research Logistics, 35, 319–325.
Hariga, M. (1988). The warehouse scheduling problem (Ph. D. Thesis, School of
Operations Research and Industrial Engineering, Cornell University).
Harris, F. (1915). Operations and costs. Factory management series (pp. 48–52).
Chicago: A. W. Shaw Co.
Hartley, R., & Thomas, L. C. (1982). The deterministic, two-product, inventory
system with capacity constraint. Journal of the Operational Research Society,
33, 1013–1020.
Hax, A. C., & Candea, D. (1984). Production and inventory management. Engle-
wood Cliﬀs, NJ: Prentice-Hall.
Held, M., & Karp, R. M. (1962). A dynamic programming approach to sequencing
problems. SIAM Journal on Applied Mathematics, 10, 196–210.
Held, M., & Karp, R. M. (1970). The traveling salesman problem and minimum
spanning trees. Mathematics of Operations Research, 18, 1138–1162.
Held, M., & Karp, R. M. (1971). The traveling salesman problem and minimum
spanning trees: part II. Mathematical Programming, 1, 6–25.
Hodgson, T. J., & Howe, T. J. (1982). Production lot sizing with material-handling
cost considerations. IIE Trans, 14, 44–51.
Hoﬀman, K. L., & Padberg, M. (1993). Solving airline crew scheduling problems
by branch-and-cut. Management Science, 39, 657–682.
Holt, C. C. (1958). Decision rules for allocating inventory to lots and cost founda-
tions for making aggregate inventory decisions. Journal of Industrial Engineer-
ing, 9, 14–22.
Homer, E. D. (1966). Space-limited aggregate inventories with phased deliveries.
Journal of Industrial Engineering, 17, 327–333.
Hopp, W., Tekin, E., & Van Oyen, M. (2004). Beneﬁts of skill chaining in serial
production lines with cross-trained workers. Management Science, 50, 83–98.
House, R. G., & Jamie, K. D. (1981). Measuring the impact of alternative market
classiﬁcation systems in distribution planning. Journal of Business Logistics, 2,
1–31.
Hu, P. (2011). Coordinated pricing and inventory management (Ph.D. Disserta-
tion, University of Illinois at Urbana-Champaign)
Huh, T., & Janakiraman, G. (2008). (s, S) optimality in joint inventory-pricing
control: an alternate approach. Mathematics of Operations Research, 56, 783–
790.

432
References
Iglehart, D. (1963a). Optimality of (s, S) policies in the inﬁnite horizon dynamic
inventory problem. Management Science, 9, 259–267.
Iglehart, D. (1963b). Dynamic programming and stationary analysis in inventory
problems. In H. Scarf, D. Guilford, M. Shelly (Eds.) Multi-stage inventory models
and techniques (pp. 1–31). Stanford, CA: Stanford University Press.
Jaillet, P. (1985). Probabilistic traveling salesman problem (Ph.D. Dissertation,
Operations Research Center, Massachusetts Institute of Technology, Cambridge,
MA)
Johnson, D. S., & Papadimitriou, C. H. (1985). Performance guarantees for heuris-
tics. In E. L. Lawler, J. K. Lenstra, A. H. G. Rinnooy Kan, D. B. Shmoys
(Eds.)The traveling salesman problem: a guided tour of combinatorial optimiza-
tion (pp. 145–180). New York: Wiley.
Johnson, J. C., & Wood, D. F. (1986). Contemporary physical distribution and
logistics. New York: Macmillan.
Johnson, D. S., Demers, A., Ullman, J. D., Garey, M. R., & Graham, R. L. (1974).
Worst-case performance bounds for simple one-dimensional packing algorithms.
SIAM Journal on Computing, 3, 299–325.
Joneja, D. (1990). The joint replenishment problem: new heuristics and worst-case
performance bounds. Mathematics of Operations Research, 38, 711–723.
Jones, P. C., & Inman, R. R. (1989). When is the economic lot scheduling problem
easy? IIE Trans, 21, 11–20.
Jordan, W., & Graves, S. C. (1995). Principles on the beneﬁts of manufacturing
process ﬂexibility. Management Science, 41, 577–594.
Karmarkar, N. (1982). Probabilistic analysis of some bin-packing algorithms. Pro-
ceedings of 23rd Annual Symposium on Foundations of Computer Science, 107–
111.
Karlin, S., & Taylor, H. M. (1975). A ﬁrst course in stochastic processes. San
Diego, CA: Academic.
Karp, R. M. (1977). Probabilistic analysis of partitioning algorithms for the trav-
eling salesman problem. Mathematics of Operations Research, 2, 209–224.
Karp, R. M., & Steele, J. M. (1985). Probabilistic analysis of heuristics. In E. L.
Lawler, J. K. Lenstra, A. H. G. Rinnooy Kan, D. B. Shmoys (Eds.) The traveling
salesman problem: a guided tour of combinatorial optimization (pp. 181–205).
New York: Wiley.
Karp, R. M., Luby, M., & Marchetti-Spaccamela, A. (1984). A probabilistic analy-
sis of multidimensional bin packing problems. Proceedings of 16th Annual ACM
Symposium on Theory of Computing, 289–298.

References
433
Kimes, S. E. (1989). A tool for capacity-constrained service ﬁrms. Journal of Op-
erations Management, 8(4), 348–363.
Kingman, J. F. C. (1976). Subadditive processes. Lecture Notes in Mathematics
539, 168–222. Berlin: Springer.
Klincewicz, J. G., & Luss, H. (1986). A lagrangian relaxation heuristic for capaci-
tated facility location with single-source constraints. Journal of the Operational
Research Society, 37, 495–500.
Kuehn, A. A., & Hamburger, M. J. (1963). A heuristic program for location ware-
houses. Management Science, 9, 643–666.
Lau, H. S. (1980) The newsboy problem under alternative optimization objectives.
Journal of the Operational Research Society, 31, 525–535.
Lawler, E. L. (1976). Combinatorial optimization: networks and matroids. New
York: Holt, Rinehart and Winston.
Lawler, E. L., Lenstra, J. K., Rinnooy Kan, A. H. G., & Shmoys, D. B. (Eds.)
(1985). The traveling salesman problem: a guided tour of combinatorial opti-
mization. New York: Wiley.
Lawler, E. L., Lenstra, J. K., Rinnooy Kan, A. H. G., & Shmoys, D. B. (1993).
Sequencing and scheduling: algorithms and complexity. In S. C. Graves, A. H.
G. Rinnooy Kan, P. H. Zipkin (Eds.) Handbooks in operations research and
management science, the Volume on Logistics of production and inventory (pp.
445–522). Amsterdam: North-Holland.
Lee, H. L., & Nahmias, S. (1993). Single product, single location models. In S.
C. Graves, A. H. G. Rinnooy Kan, P. H. Zipkin (Eds.) Handbooks in operations
research and management science, the Volume on Logistics of production and
inventory (pp. 3–55). Amsterdam: North-Holland.
Li, C. L., & Simchi-Levi, D. (1990). Worst-case analysis of heuristics for the multi-
depot capacitated vehicle routing problems. ORSA Journal on Computing, 2,
64–73.
Lindsey (1996). A communication to the AGIS-L list server.
Lovasz, L. (1979). Combinatorial problems and exercises. Amsterdam: North-
Holland.
Love, S. F. (1973). Bounded production and inventory models with piecewise con-
cave costs. Management Science, 20, 313–318.
Magnanti, T. L., Shen, Z-J. M., Shu, J., Simchi-Levi, D., & Teo, C-P. (2003).
Inventory placement in acyclic supply chain networks. Working Paper. Operation
Research Letter, 34, 228–238.

434
References
Manne, A. S. (1964). Plant location under economies of scale—decentralization
and computation. Management Science, 11, 213–235.
Mart´ınez-de-Alb´eniz, V., & Simchi-Levi, D. (2005). A portfolio approach to pro-
curement contracts. Production and Operations Management, 14, 90–114.
Mart´ınez-de-Alb´eniz V., & Simchi-Levi, D. (2006). Mean-variance trde-oﬀs in sup-
ply contracts. Naval Research Logistics, 53, 603–616.
Maxwell, W. L., & Singh, H. (1983). The eﬀect of restricting cycle times in the
economic lot scheduling problem. IIE Trans, 15, 235–241.
Melkote, S. (1996). Integrated models of facility location and network design
(Ph.D. thesis, Northwestern University).
Mirchandani, P. B., & Francis, R. L. (1990). Discrete location theory. New York:
Wiley.
Muckstadt, J. M., & Roundy, R. O. (1993). Analysis of multistage production
systems. In S. C. Graves, A. H. G. Rinnooy Kan, P. H. Zipkin (Eds.) Hand-
books in operations research and management science, the volume on Logistics
of production and inventory (pp. 59–131). Amsterdam: North-Holland.
Murota, K. (2003). Discrete convex analysis. Philadelphia: Society for Industrial
and Applied Mathematics.
Muriel, A., & Simchi-Levi, D. (2003). Supply chain design and planning – ap-
plications of optimization techniques for strategic and tactical models. In de.
Kok, S. Graves (Eds.) Handbooks in operations research and management sci-
ence (Vol. 11): Supply chain management: design, coordiation and operation.
Boston: Elsevier.
Murota, K., & Shioura, A. (2004). Conjugacy relationship between M-convex and
L-convex functions in continuous variables. Mathematical Programming, 101,
415–433.
Murota, K., & Shioura, A. (2005). Substitutes and complements in network ﬂows
viewed as discrete convexity. Discrete Mathematics, 2, 256–268.
Myerson, R. B. (1997). Game theory: Analysis of Conﬂict. Cambridge, MA: Har-
vard University Press.
Nagarajan, M., & Soˇsi´c, G. (2008). Game-theoretic analysis of cooperation among
supply chain agents: review and extensions. European Journal of Operational
Research, 187(3), 719–745.
Nauss, R. M. (1976). An eﬃcient algorithm for the 0-1 knapsack problem. Man-
agement Science, 23, 27–31.

References
435
Neebe, A. W., & Rao, M. R. (1983). An Algorithm for the ﬁxed-charged assigning
users to sources problem. Journal of the Operational Research Society, 34, 1107–
1113.
Newton, R. M., & Thomas, W. H. (1969). Design of school bus routes by computer.
Socio-Economic Planning Science, 3, 75–85.
Osborne, M. J. (2003). An introduction to game theory. New York, Oxford: Oxford
University Press.
¨Ozer, ¨O., & Phillips, R. (Eds.) (2012). The oxford handbook of pricing management.
New York, Oxford: OUP Oxford.
Page, E., & Paul, R. J. (1976). Multi-product inventory situations with one re-
striction. Journal of the Operational Research Society, 27, 815–834.
Pang, Z. (2011). Optimal dynamic pricing and inventory control with stock dete-
rioration and partial backordering. Operation Research Letter, 39, 375–379.
Pang, Z., Chen, Y. F., & Feng, Y. (2012). A note on the structure of joint inventory-
pricing control with leadtimes. Operation Research, 60, 581–587.
Papadimitriou, C. H., & Stieglitz, K. (1982). Combinatorial optimization: algo-
rithms and complexity. Englewood Cliﬀs, NJ: Prentice-Hall.
Park, K. S., & Yun, D. K. (1985). Optimal scheduling of periodic activities. Op-
eration Research, 33, 690–695.
Patton, E. P. (1994). Carrier rates and tariﬀs. In J. A. Tompkins, D. Harmelink
(Eds.) The distribution management handbook (Chapter 12). New York:
McGraw-Hill.
Peleg, B., & P. Sudh¨olter (2007). Introduction to the theory of cooperative games
(2nd ed.). Berlin: Springer.
Petruzzi, N. C., & Dada, M. (1999). Pricing and the newsvendor model: a review
with extensions. Operation Research, 47, 183–194.
Pinedo, M. (1995). Scheduling: theory, algorithms and systems. Englewood Cliﬀs,
NJ: Prentice-Hall.
Pirkul, H. (1987). Eﬃcient algorithms for the capacitated concentrator location
problem. Computers and Operations Research, 14, 197–208.
Pirkul, H., & Jayaraman, V. (1996). Production, transportation and distribution
planning in a multi-commodity tri-echelon system. Transportation Science, 30,
291–302.
Polyak, B. T. (1967). A general method for solving extremum problems (in Rus-
sian). Doklady Akademmi Nauk SSSR, 174 , 33–36.

436
References
Porteus, E. L. (1985). Investing in reduced setups in the EOQ model. Management
Science, 31, 998–1010.
Porteus, E. L. (1990). Stochastic inventory theory. In D. P. Heyman, M. J. Sobel
(Eds.) Handbooks in operations research and management science, the volume
on Stochastic models (pp. 605–652). Amsterdam: North-Holland.
Psaraftis, H. N. (1984). On the practical importance of asymptotic optimality in
certain heuristic algorithms. Networks, 14, 587–596.
Rhee, W. T. (1988). Optimal bin packing with items of random sizes. Mathematics
of Operations Research, 13, 140–151.
Rhee, W. T. (1991). An asymptotic analysis of capacitated vehicle routing. Work-
ing Paper, The Ohio State University, Columbus, OH.
Rhee, W. T., & Talagrand, M. (1987). Martingale inequalities and NP-complete
problems. Mathematics of Operations Research, 12, 177–181.
Robeson, J. F., & Copacino, W. C. (Eds.) (1994). The logistics handbook. New
York: Free Press.
Rockafellar, R. T. (1970). Convex analysis. Princeton, NJ: Princeton University
Press.
Rosen, J. B. (1965). Existence and uniqueness of equilibrium points for concave
N-person games. Econometrica, 33, 520–534.
Ross, Sheldon M. (1983). Introduction to Stochastic Dynamic Programming. Aca-
demic Press, INC., London.
Rosenblatt, M., & Rothblum, U. (1990). On the single resource capacity problem
for multi-item inventory systems. Operation Research, 38, 686–693.
Rosenkrantz, D. J., Stearns, R. E., & Lewis II, P. M. (1977). An analysis of several
heuristics for the traveling salesman problem. SIAM Journal on Computing, 6,
563–581.
Ross, S. (1970). Applied Probability models with optimization applications. San
Francisco: Holden-Day.
Rosling, K. (1989). Optimal inventory policies for assembly systems under random
demand. Operation Research, 37, 565–579.
Roundy, R. (1985). 98%-eﬀective integer-ratio lot-sizing for one-warehouse multi-
retailer systems. Management Science, 31, 1416–1430.
Russell, R. A. (1977). An eﬀective heuristic for the M-tour traveling salesman
problem with some side constraints. Operation Research, 25, 521–524.

References
437
Sahni, S., & Gonzalez, T. (1976). P-complete approximation algorithms. Journal
of the Association for Computing Machinery, 23, 555–565.
Scarf, H. E. (1960). The optimalities of (s, S) policies in the dynamic inventory
problem. In K. Arrow, S. Karlin, P. Suppes (Eds.) Mathematical methods in the
social sciences (pp. 196–202). Stanford, CA: Stanford University Press.
Schweitzer, M., & Chachon, G. (2000). Decision bias in the newsvendor problem
with a known demand distribution: experimental evidence. Management Sci-
ence, 46(3), 404–420.
Shapley, L. (1967), On balanced sets and cores. Naval Research Logistics Quarterly,
14, 453–460.
Shmoys, D., & Williamson, D. (1990). Analyzing the held-karp TSP bound: a
monotonicity property with application. Information Processing Letters, 35,
281–285.
Silver, E. A. (1976). A simple method of determining order quantities in joint
replenishments under deterministic demand. Management Science, 22, 1351–
1361.
Silver, E. A., & Meal, H. C. (1973). A heuristic for selecting lot size quantities for
the case of a deterministic time-varying demand rate and discrete opportunities
for replenishment. Production and Inventory Management, 14, 64–74.
Silver, E. A., & Peterson, R. (1985). Decision systems for inventory management
and production planning. New York: Wiley.
Simchi-Levi, D. (1994), New worst case results for the bin-packing problem. Naval
Research Logistics, 41, 579–585.
Simchi-Levi, D. (2010). Operations rules: delivering customer value through ﬂexible
operations. Cambridge, MA: MIT Press.
Simchi-Levi, D., & Bramel, J. (1990). On the optimal solution value of the capac-
itated vehicle routing problem with unsplit demands. Working Paper, Depart-
ment of IE&OR, Columbia University, New York.
Simchi-Levi, D., Kaminsky, P., & Simchi-Levi, E. (2003). Designing and managing
the supply chain (2nd ed.). Burr Ridge, IL: McGraw-Hill.
Simchi-Levi, D., Kaminsky, P., & Simchi-Levi, E. (2007). Designing and managing
the supply chain (3rd ed.). concepts, Strategies and Case Studies. McGraw-Hill.
Simchi-Levi, D., Wu, D., & Shen, Z. J. (Eds). (2004). Handbook of quantitative
supply chain analysis: modeling in the E-business era. New York: Springer.
Simchi-Levi, D., Wei, Y. (2012) Understanding the Performance of the Long Chain
and Sparse Designs in Process Flexibility. Operations Research, 60(5), 1125–1141

438
References
Solomon, M. M. (1986). On the worst-case performance of some heuristics for the
vehicle routing and scheduling problem with time window constraints. Networks,
16, 161–174.
Solomon, M. M., & Desrosiers, J. (1988). Time window constrained routing and
scheduling problems: a survey. Transportation Science, 22, 1–13.
Stankevich, D. (1996). Ace of diamonds. Discount Merchandiser, 38(8), 28–37.
Steele, J. M. (1981). Subadditive euclidean functionals and nonlinear growth geo-
metric probability. Annals of Probability, 9, 365–375.
Steele, J. M. (1990). Lecture notes on “probabilistic analysis of algorithms.”
Stout, W. F. (1974). Almost sure convergence. New York: Academic.
Strassen, V. (1969). Gaussian elimination is not optimal. Nmerische Mathematik,
13, 354–356.
Swersey, A. J., & Ballard, W. (1984). Scheduling school buses. Management Sci-
ence, 30, 844–853.
Talluri, K., & van Ryzin, G. (2004). The theory and practice of revenue manage-
ment. New York: Springer.
Tarski, A. (1955). A lattice-theorectical ﬁxpoint theorem and its applications.
Paciﬁc Journal of Mathematics, 5, 285–309.
Thomas, L. C., & Hartley, R. (1983). An algorithm for limited capacity inventory
problem with staggering. Journal of the Operational Research Society, 34, 81–85.
Topkis, D. M. (1998). Supermodularity and complementarity. Princeton, NJ:
Princeton University Press.
van Ryzin, G. (2012). Models of demand. In P. Philips, ¨O. ¨Ozer (Eds.) Oxford hand-
book of pricing management (pp. 340–380). Oxford: Oxford University Press.
Veinott, A. (1966). On the optimality of (s, S) inventory policies: new condition
and a new proof. Journal SIAM Applied Mathematics, 14, 1067–1083.
Veinott, A., & Wagner, H. (1965). Computing optimal (s, S) inventory policies.
Management Science, 11, 525–552.
Vives, X. (2000). Oligopoly pricing: old ideas and new tools. Cambridge, MA: MIT
Press.
Wagner, H. M., & Whitin, T. M. (1958a). Dynamic problems in the theory of the
ﬁrm. Naval Research Logistics Quarterly, 5, 53–74.
Wagner, H. M., & Whitin, T. M. (1958b). Dynamic version of the economic lot
size model. Management Science, 5, 89–96.

References
439
Wagelmans, A., Van Hoesel, S., & Kolen, A. (1992). Economic lot sizing: an
O(n log n) algorithm that runs in linear time in the Wagner–Whitin case. Oper-
ation Research, 40(Suppl 1), S145–S156.
Weber, A. (1909). In C. J. Friedrich (Ed. and transl.) Theory of the location of
industries. Chicago: Chicago University Press.
Whitin, T. M. (1955). Inventory control and price theory. Management Science,
2, 61–80.
Wolsey, L. (1980). Heuristic analysis, linear programming and branch and bound.
Mathematical Programming Study, 13, 121–134.
Yano, C., & Gilbert, S. (2002). Coordinated pricing and production/procurement
decisions: a review. In A. Chakravarty, J. Eliashberg (Eds.) Managing busi-
ness interfaces: marketing, engineering and manufacturing perspectives. Boston:
Kluwer Academic.
Ye, Q., & Duenyas, I. (2007). Optimal capacity investment decisions with two-sided
ﬁxed-capacity adjustment costs. Operation Research, 55, 272–283.
Yellow, P. (1970). A computational modiﬁcation to the savings method of vehicle
scheduling. Operational Research Quarterly, 21, 281–283.
Zangwill, W. I. (1966). A deterministic multi-period production scheduling model
with backlogging. Management Science, 13(1), 105–199.
Zavi, A. (1976). Introduction to operations research, part II: dynamic programming
and inventory theory (in Hebrew). Tel-Aviv: Dekel.
Zheng, Y. S. (1991). A simple proof for the optimality of (s, S) policies for inﬁnite
horizon inventory problems. Journal of Applied Probability, 28, 802–810.
Zheng, Y. S., & Federgruen, A. (1991). Finding optimal (s, S) policies is about as
simple as evaluating a single policy. Operation Research, 39, 654–665.
Zipkin, P. H. (2000). Foundations of inventory management. Burr Ridge, IL: Irwin.
Zipkin, P. H. (2008). On the structure of lost-sales inventory models. Operation
Research, 56, 937–944.
Zoller, K. (1977). Deterministic multi-item inventory systems with limited capac-
ity. Management Science, 24, 451–455.

Index
(s, S) policy, 153
L♮-convex function, 36, 40, 170
L♮-convex set, 36, 37
M ♮-convex function, 39, 40
M ♮-convex set, 39
ϵ-core, 59
k-opt procedures, 80
k−connected, 110
p -median problem, 283–290, 293, 298
(strictly) increasing diﬀerences, 28
¨Ozer, ¨O., 11
1-tree, 106
2-partition problem, 67
absolute performance ratio, 65
additivity, 54, 62
Aggarwal, A., 140
aggregate monotonicity, 55
Agrawal, V., 202
Aho, A. V., 74
Altinkemer, K., 303, 317
Angel, R. D., 406
Anily, S., 83, 123
anonymity, 54, 55, 61–63
Archibald, B., 163
Arkin, E., 147
Arrow, K., 151
assembly-distribution system, 173
asymptotic performance ratio, 66
asymptotically optimal, 88
Atkins, D. R., 147
average-case analysis, 10
Azuma, K., 89
Ba¸sar, T., 45
Baker, B. S., 67
Baker, K. R., 143
Balakrishnan, A., 266, 274, 275
balanced, 56
Balinski, M. L., 284, 359
Ball, M. O., 11
Ballard, W., 407
Barcelo, J., 289
base planning period, 121
base stock policy, 153
Beardwood, J., 92, 331
Beasley, J., 305, 315
Bell, C., 163
D. Simchi-Levi et al., The Logic of Logistics: Theory, Algorithms, and Applications
for Logistics Management, Springer Series in Operations Research and Financial Engineering,
DOI 10.1007/978-1-4614-9149-1, © Springer Science+Business Media New York 2014
441

442
Index
Bennett, B., 406, 417
Berman, L., 407, 413
Bernstein, F., 213
Bertsekas, D. P., 220
Bertsimas, D. J., 109, 313
best-ﬁt, 66
best-ﬁt decreasing, 66
Bienstock, D., 110, 326
bin-packing constant, 296, 320
bin-packing problem, 66, 86, 100, 297,
320, 332, 373
Bodin, L., 407, 413
Bondareve, O., 56
Borel–Cantelli lemma, 331
Bouakiz, M, 202
Bramel, J., 316, 320, 335–337, 341, 367,
368, 413
branch and bound, 364
Cachon, G., 202, 213, 230
Candea, D., 3
capacitated concentrator location
problem, 288
capacitated facility location problem,
335, 349
capacitated vehicle location problem
with time windows, 349
capacitated vehicle routing problem,
301
Casanovas, J., 289
Chan, L. M. A., 103, 177, 269, 272
Chandra, P., 80
Chapleau, L., 413
Chen, F., 151, 172, 173, 202
Chen, X., 44, 150, 177, 178, 192, 193,
200–202, 208, 209, 222
Chen, Y. F., 159, 201
Chen. X., 207
Chou, M., 258, 261, 262
Christoﬁdes’ heuristic, 78, 81, 82, 111,
305, 312
Christoﬁdes, N., 78, 313, 316, 363
Chua, G., 258, 261, 262
Churchman, C. W., 123
circular region partitioning, 309, 310
Clark, A. J., 151
Clarke, G., 314, 406
clique, 365
cluster-ﬁrst–route-second, 316
coalitional form, 52
coalitional monotonicity, 55, 62
Coﬀman, E. G., Jr., 85, 98, 337
column-generation, 360
common knowledge, 46
consecutive heuristic, 327
consistency, 55, 56, 61, 63
convex extendable, 40
convex game, 53, 57
convexity, 8, 15
cooperative game, 52
core, 55, 62, 217
Cornu´ejols, G., 284, 317
Council of Supply Chain Management
Professionals, 2
covariance under strategic equivalence,
54, 55, 61, 63
crew scheduling problems, 364
Croxton, K. L., 269
Cullen, F., 360
cutting-plane methods, 317
cycle time, 118
Dada, M., 177
Daskin, M. S., 284
De Kok, 11
delivery man problem, 356
Dematteis, J. J., 139
Denardo, E. V., 163
Deng, Q., 336
Deng, S., 150
depth-ﬁrst search, 74
Desrochers, M., 354, 360, 363, 367
Desrosiers, J., 341, 407
diagonally dominated M-matrix, 37
discrete convex analysis, 35
Dobson, G., 124
double marginalization, 232
Dreyfus, S. E., 98
dual-feasible, 112
Duenyas, I., 207

Index
443
dynamic program, 98, 374
dynamic programming, 93, 98, 363, 374
echelon holding cost, 131
echelon inventory position, 172
economic lot scheduling problem, 124
economic lot size model, 117, 134, 135
economic order quantity (EOQ), 119,
135
economic warehouse lot scheduling
problem, 123
Edmonds, J., 108, 112
Eeckhoudt, L., 202
eﬃciency, 54, 55, 61–63
Eliashberg, G., 177
Elmaghraby, W., 177
Eppen, G., 151, 172
equidistance convexity, 42
Erlenkotter, D., 117
Eulerian graph, 78, 94
Eulerian tour, 78
Federgruen, A., 139, 140, 151, 163, 172,
177, 202, 213, 313, 341
Feng, Y., 201
Few, L., 91
ﬁrst-ﬁt, 66
ﬁrst-ﬁt decreasing, 66
Fisher, M. L., 9, 10, 103, 313, 316, 317,
337
Florian, M., 143
Francis, R. L., 284, 297, 298
Fudenberg, D., 45
Gallego, G., 124, 177
game theory, 8
Garey, M. R., 9, 66, 68
Gaskel, T. J., 315
Gavish, B., 303, 317
Gazis, D., 406, 417
Gendron, B., 269
generalized assignment heuristic, 316,
337
geocoding, 409
geographic information system, 409
geographic information system (GIS),
405
Geunes, J., 150
Ghosh, A., 217
Gilbert, S., 177
Gillett, B. E., 315
global minimizer, 40
Goemans, M. X., 109
Golden, B. L., 81
Gollier, C., 202
Gonzalez, T., 72
Goyal, S. K., 123
Graves, S. C, 275
Graves, S. C., 11, 130, 266, 274, 275,
280
greedy algorithm, 57
group rationality, 54, 55
Hadley, G., 123, 128
Haimovich, M., 303, 307, 308, 317
Hakimi, S. L., 284
Hall, N. G., 123
Hamburger, M. J., 284
Hamiltonian cycle problem, 72
Hamiltonian path, 81
Harche, F., 317
Hariga, M., 124
harmonic heuristic, 97
Harris, F., 117
Harris, T., 151
Hartley, R., 123
Hax, A. C., 3
He, S., 44
Heching, A., 177
Held, M., 93, 103, 105, 107, 108
Hodgson, T. J., 123
Hoﬀman, K. L., 360, 364
Holt, C. C., 123
Homer, E. D., 123
Howe, T. J., 123
Hu, P., 44, 201
Huh, T., 195
Iglehart, D., 151, 163
incomplete optimization methods, 317

444
Index
increasing generalized failure rate
(IGFR), 232
increasing set function, 33
independent set, 365
independent solutions, 123
individual rationality, 54, 55, 60
inﬁmal convolution, 40
Inman, R. R., 124
integrality property, 105
intersection graph, 365
inventory centralization game, 216,
217, 219, 222, 228
inventory decomposition property,
143
inventory position, 169
inventory-balance constraints, 138
iterated tour-partitioning, 303
Iyogun, P., 147
J. Rosen, 52
Jaikumar, R., 316, 337
Jaillet, P., 91
Janakiraman, G., 195
Jayaraman, V., 292
Jensen’s inequality, 18, 22, 181
Johnson, D. S., 9, 66–68, 72, 74
join, 27
joint setup cost, 147
Joneja, D., 147
Jones, P. C., 124
K-convexity, 155, 175
Kakutani ﬁxed-point theorem, 48
Karlin, S., 89
Karmarkar, N., 321
Karp, R. M., 92, 93, 97, 103, 105, 107,
108
Keskinocak, P., 177
Kimes, S. E., 177
Kingman, J. F. C., 86
Klein, M., 143
Klincewicz, J. G., 289
knapsack problem, 289, 295
Kuehn, A. A., 284
Lagrangian dual, 104
Lagrangian relaxation, 103, 105, 284,
285, 289, 293, 336, 351
laminar convex function, 39, 40
laminar family, 40
lattice, 27
Lau, H. S., 202
Law, A. M., 98
Lawler, E. L., 72, 78, 333, 342
layered graph, 366
least-core, 59
Lee, H. L., 151
Leuker, G. S., 98
Li, C. L., 305, 319
local minimizer, 40
location-based heuristic, 316
log-supermodular, 214
loss function, 154
Lovasz, L., 110
Love, S. F., 143
Lueker, G. S., 85, 337
Luss, H., 289
machine scheduling problem, 342
Magnanti, T. L., 269, 280
Manne, A. S., 284
Marschak, J., 151
Mart´ınez-de-Alb´eniz, V., 202, 231
martingale inequalities, 89
MATCH heuristic, 89
matching, 78
meet, 27
Melkote, S., 274
midpoint convexity, 42
Miller, L. R., 315
minimum K-tree methods, 317
minimum spanning tree–based
heuristic, 74
Mirchandani, P. B., 284, 297, 298
monotone optimal solutions, 38
Muckstadt, J. M., 121
Muriel, A., 222, 269, 272
Murota, K., 15, 43, 262
Myerson, R., 45

Index
445
Nagarajan, M., 213
Nahmias, S., 151
Nash equilibrium, 35, 47, 215, 230
Nauss, R. M., 289
nearest-insertion heuristic, 75, 76
nearest-neighbor heuristic, 75, 356
Neebe, A. W., 289
nested, 130
Netessine, S., 213
network design, 109
newsboy problem, 152
newsvendor game, 228
newsvendor problem, 152, 177, 215,
230–232
Newton, R. M., 406
next-ﬁt, 83, 326
next-ﬁt increasing, 83
node cover problem, 298
non-K-decreasing, 160, 175
nontransferrable utilities, 53
NP-complete, 67, 72, 99, 143, 147
NP-hard, 9, 65, 298, 336, 352, 362
nucleolus, 59
null player, 54, 55, 61, 62
odd hole, 366
oﬄine algorithms, 66
Olsder, G., 45
online algorithms, 66
optimal matching of pairs, 332, 333
optimal partitioning, 305, 319
optimal partitioning heuristic, 315
order-up-to-level, 153
Osborne, M., 45
Padberg, M., 360, 364
Page, E., 123
Pan, L., 201
Pang, Z., 175, 201
Papadimitriou, C. H., 72, 74, 81, 82
Park, J. K., 140
Park, K. S., 123
parsimonious property, 109
part-period balancing heuristic, 139
Paul, R. J., 123
Peleg, B., 45
perfect packing, 321
Peterson, E., 123
Petruzzi, N. C., 177
Phillips, R., 11
pickup and delivery problem, 357
Pinedo, M., 342
Pirkul, H., 289, 292, 335
planning horizon, 137
polar region partitioning, 309, 310
Polyak, B. T., 104
Porteus, E. L., 136, 151, 163
power-of-two policies, 121
prize-collecting traveling salesman
problem, 372
probabilistic analysis, 85
production sequence, 144
properties of L♮-convex functions, 37
Psaraftis, H. N., 337
quadratic L♮-convex function, 37
quadratic M ♮-convex function, 40
Quandt, R. E., 359
quasiconvex, 18, 42, 159, 163, 195
Rao, M. R., 289
rate of convergence, 337, 372
rectangular region partitioning, 309,
310
regeneration point, 144, 163
region partitioning, 93, 324
reorder point, 153
Rhee, W. T., 89, 321, 337
Rinnooy Kan, A. H. G., 303, 307, 308
Rockafellar, T., 15, 22
Rosenblatt, M., 123
Rosenkrantz, D. J., 75, 77
Rosling, K., 151
Ross, S., 163, 168
rotation cycle policies, 123
Rothblum, U., 123
Roundy, R., 121, 130
route-ﬁrst–cluster-second, 315
Russell, R. A., 315

446
Index
Sahni, S., 72
savings, 314
savings algorithm, 314, 406
Scarf, H. E., 151, 155, 169
Schlesinger, H., 202
Schrage, L., 151, 172
Schwarz, L. B., 130
Schweitzer, M., 202
seed customers, 317, 337, 350
seed-insertion heuristic, 353
Seshadri, S., 202
set-partitioning, 359
set-partitioning problem, 100
Shapley value, 61
Shapley, L., 56
Shen, M., 177, 280
Shioura, A., 43, 262
Shmoys, D., 109
shortcut, 74
Shu, J., 280
Shum, S., 201
Silver, E. A., 123, 147, 163
Silver–Meal heuristic, 139, 147
Silver-Meal heuristic, 150
Sim, M., 178, 202
Simchi-Levi, D., 7, 11, 67, 110, 150,
177, 178, 192, 193, 200–202,
208, 222, 231, 269, 272, 280,
305, 313, 316, 319, 320,
335–337, 341, 367, 368
Simchi-Levi10, 7
sliced interval partitioning heuristic, 87
sliced region-partitioning heuristic, 333
Soˇsi´c, G., 213
Sobel, M. J., 202
Solomon, M. M., 341, 353
solution concept, 53
spanning tree, 73
splittable demands, 302
Stackelberg game, 46, 231
staggering problem, 123
Stankevich, D., 217
star-tours heuristic, 353
stationary, 130
stationary order sizes and intervals, 124
Steele, J. M., 86, 92, 97
Steiglitz, K., 74, 81, 82
Steinberg, R., 177
Stewart, W. R., 81
Stout, W. F., 89
Strassen. V., 256
strategic form, 52
strong monotonicity, 55, 62
subadditive processes, 86, 327
subgradient optimization, 104, 285, 295
submodular, 36
subtour elimination, 107
Sudh¨olter, P., 45
Sun, P., 178, 202, 207
superadditive game, 53
superadditivity, 54
superaddivity, 55
supermodular, 214
supermodular game, 35, 49, 53, 215
supermodularity, 8, 15, 27, 194
Swann, J., 177
sweep algorithm, 315, 316, 326
Swersey, A. J., 407
symmetry, 54, 61, 62
system inventory, 131
Talagrand, M., 89
Talluri, K., 178
Tarski ﬁxed-point theorem, 35, 49
Tarski, A., 35
Taylor, H. M., 89
Teo, C-P., 280
Teo, C., 258, 261, 262
the Bondareva–Shapley theorem, 56
Thomas, L. C., 123
Thomas, W. H., 406
time window, 341
Tirole, J., 45
Topkis, D., 15
transferrable utilities, 53
translation submodular, 36
traveling salesman problem, 72, 91, 105
triangle inequality, 73
two-phase method, 316
Tzur, M., 139, 140

Index
447
unequal-weight iterated tour
partitioning, 317
unimodal, 159
unsplit demands, 313
van Ryzin, G., 177, 178, 341
vehicle routing problem, 301
vehicle routing problem with distance
constraints, 356
vehicle routing problem with time
windows, 341
Veinott, A., 151, 159, 161, 163
Vives X., 45
Wagelmans, A., 140
Wagner, H., 138, 150, 151, 163
wandering salesman problem, 82
weak consistency, 55
Weber, A., 284
Whitin, T. M., 123, 128, 138, 150, 177
Willems, S., 280
Williamson, D., 109
Wolsey, L., 109
worst-case analysis, 9
worst-case eﬀectiveness, 65
Wright, J. W., 314, 406
Yano, C., 150, 177
Ye, Q., 207
Yellow, P., 315
Yun, D. K., 123
Zangwill, W. I., 139
Zavi, A., 135
zero-inventory-ordering property, 118,
119, 130, 131, 138
Zhang, J., 222
Zhang, Y., 201, 209
Zheng, H., 258, 261, 262
Zheng, Y. S., 151, 163, 172, 173
Zhou, S., 201, 209
Zipkin, P. H., 151, 170, 172
Zoller, K., 123

