

Risk Assessment


Risk Assessment
Tools, Techniques, and Their
Applications
Lee T. Ostrom
Cheryl A. Wilhelmsen
A John Wiley & Sons, Inc., Publication

Copyright 2012 by John Wiley & Sons, Inc. All rights reserved.
Published by John Wiley & Sons, Inc., Hoboken, New Jersey.
Published simultaneously in Canada.
No part of this publication may be reproduced, stored in a retrieval system, or transmitted in
any form or by any means, electronic, mechanical, photocopying, recording, scanning, or
otherwise, except as permitted under Section 107 or 108 of the 1976 United States Copyright
Act, without either the prior written permission of the Publisher, or authorization through
payment of the appropriate per-copy fee to the Copyright Clearance Center, Inc., 222
Rosewood Drive, Danvers, MA 01923, (978) 750-8400, fax (978) 750-4470, or on the web at
www.copyright.com. Requests to the Publisher for permission should be addressed to the
Permissions Department, John Wiley & Sons, Inc., 111 River Street, Hoboken, NJ 07030,
(201) 748-6011, fax (201) 748-6008, or online at http://www.wiley.com/go/permission.
Limit of Liability/Disclaimer of Warranty: While the publisher and author have used their best
efforts in preparing this book, they make no representations or warranties with respect to the
accuracy or completeness of the contents of this book and speciﬁcally disclaim any implied
warranties of merchantability or ﬁtness for a particular purpose. No warranty may be created
or extended by sales representatives or written sales materials. The advice and strategies
contained herein may not be suitable for your situation. You should consult with a professional
where appropriate. Neither the publisher nor author shall be liable for any loss of proﬁt or any
other commercial damages, including but not limited to special, incidental, consequential, or
other damages.
For general information on our other products and services or for technical support, please
contact our Customer Care Department within the United States at (800) 762-2974, outside the
United States at (317) 572-3993 or fax (317) 572-4002.
Wiley also publishes its books in a variety of electronic formats. Some content that appears in
print may not be available in electronic formats. For more information about Wiley products,
visit our web site at www.wiley.com.
Library of Congress Cataloging-in-Publication Data:
Ostrom, Lee T., author.
Risk assessment : tools, techniques, and their applications / Lee T. Ostrom, Cheryl
A. Wilhelmsen.
pages cm
Includes index.
ISBN 978-0-470-89203-9 (hardback)
1.
Risk assessment–Statistical methods. 2.
Probabilities.
I. Wilhelmsen, Cheryl A.,
1933- author. II. Title.
QA273.O74 2012
361.1–dc23
2012020141
Printed in the United States of America.
10 9 8 7 6 5 4 3 2 1

Contents
List of Figures
xiii
List of Tables
xvii
Acknowledgments
xxi
1 Introduction to Risk Assessment
1
1.1
Terminology, 6
1.2
Performing Risk Assessments, 6
1.3
Risk Assessment Team, 7
1.3.1
Team Approach, 7
1.3.2
Team Representatives, 10
References, 11
2 Risk Perception
13
2.1
Knowledge Level, 15
References, 20
3 Risks and Consequences
21
3.1
Introduction, 21
3.2
Risk and Consequence, 21
3.3
Credible Consequences, 24
3.4
Summary, 25
References, 25
4 Ecological Risk Assessment
26
4.1
Introduction, 26
4.2
Deep Water Horizon, 29
4.3
Love Canal, 34
4.4
Minimata Methylmercury, 36
4.5
Agent Orange, 38
4.6
Seveso, Italy, 40

vi
Contents
4.7
Risk of Ecological Disasters, 41
4.8
Ecological Risk Assessment, 41
4.8.1
Example Ecological Risk Assessment, 45
4.9
Summary, 53
References, 54
5 Task Analysis Techniques
56
5.1
What is Task Analysis? 56
5.2
Why a Task Analysis? 57
5.3
When to use Task Analysis? 58
5.4
Task Analysis Process, 58
Step 1: Data Collection Information, 59
Step 2: Recording the Data, 60
Step 3: Data Analysis, 63
References, 63
6 Preliminary Hazards Analysis
64
6.1
Description, 65
6.1.1
Process of Preliminary Hazards Analysis, 66
6.1.2
Hazard Class, 69
6.1.3
Examples of Hazardous Energy Sources, 69
6.2
Using Process Hazard for Procedure Design, 72
6.2.1
Purpose of Process, 72
6.2.2
Initial Basic Procedure Steps, 72
6.2.3
Analysis, 73
6.2.4
Using the Results of the Analysis, 73
6.3
Using PHA for Preliminary Product Design, 75
Step 1: Determine Functions of the Crib, 76
Step 2: Determine Required/Critical
Speciﬁcations, 76
Step 3: Determine Major Systems/Subsystems of
the Crib, 76
Step 4: Determine Important Components of Each
System/Subsystem, 77
Step 5: Determine Operating Modes of the Crib, 77
6.4
Summary, 79
References, 79

Contents
vii
7 Primer on Probability and Statistics
81
7.1
Introduction, 81
7.2
Probability Theory, 85
7.3
Combining Probabilities, 87
7.4
Conditional Probability, 88
7.5
Probability Distributions, 89
7.6
Using Probability, 92
7.7
Summary, 95
References, 96
8 Developing Probabilities
97
8.1
Risk Assessment Data, 97
8.1.1
Introduction, 97
8.1.2
Hardware Failure Rate Data, 97
8.1.3
Manufacture, 98
8.1.4
Historical Data, 98
8.1.5
Government and Military Handbooks, 98
8.1.6
Commercial Data Sources, 98
8.1.7
Operational Data and Testing, 99
8.1.8
Failure Rate Calculations, 100
8.1.9
Accident Data, 103
8.1.10 Monte Carlo Simulation, 106
8.1.11 Human Error Probabilities, 107
8.1.12 Delphi Method, 108
8.1.13 Summary of the Delphi Process, 115
8.2
Overall Summary, 116
References, 116
9 Failure Mode and Effects Analysis
118
9.1
Introduction, 119
9.1.1
Description, 119
9.1.2
Why is a Failure Mode and Effects Analysis
Effective? 119
9.1.3
Types of Failure Mode and Effects Analyses, 120
9.1.4
Failure Mode and Effects Analysis Process, 120
9.2
Summary, 134
References, 134

viii
Contents
10 Human Reliability Analyses
135
10.1 Introduction, 135
10.1.1 Purpose, 135
10.1.2 Background, 135
10.1.3 Bounding the System, 136
10.1.4 Summary Points, 139
10.2 Task Analysis, 139
10.2.1 Summary Points, 140
10.3 HRA Modeling, 141
10.3.1 Summary Points, 143
10.4 Quantifying Human Error Probability (HEP), 144
10.4.1 Summary Points, 148
10.5 Documentation, 148
10.5.1 Summary Points, 149
10.6 Use of Human Reliability Analysis Techniques for
Analyzing Procedures, 149
10.6.1 Procedure, 149
10.6.2 Procedure with Inspection Steps, 151
References, 151
11 Critical Incident Technique
153
11.1 Introduction, 153
11.2 Method, 153
11.3 Building on the Results of a Critical Incident Technique
Session, 157
Step 1: Ramp Agent observes Anomaly on Aircraft
Cargo Door, 158
Step 2: Ramp Agent Discusses Damage with
Supervisor, 160
Step 3: Ramp Agent Discusses Decision to Report
Damage to Maintenance Control with
Supervisor, 160
Step 4: Ramp Agent Decides to Report Damage to
Maintenance Control, 161
Step 5: Ramp Agent Shows Maintenance Control
the Damage, 161
11.4 Summary, 162
References, 162

Contents
ix
12 Event Tree and Decision Tree Analysis
163
12.1 Event Trees, 163
12.1.1 Case Study, 167
12.2 Decision Trees, 168
12.2.1 Problem, 170
12.3 Case Study: Chernobyl, 175
12.3.1 Analysis of the Event, 178
12.3.2 Event Tree Analysis, 179
12.4 Summary, 180
References, 180
13 Critical Function Analysis
181
13.1 Introduction, 181
13.1.1 United Flight 232, 183
13.1.2 Air Canada Flight 143, 185
13.2 Critical Functions, 187
13.3 Conducting a Critical Function Analysis, 190
13.3.1 Critical Function of a Small Business, 192
13.3.2 Chemical Reactor Critical Function
Analysis, 193
13.3.3 Emergency Management Planning, 195
13.4 Summary, 197
References, 201
14 Basic Fault Tree Analysis Technique
203
14.1 History, 203
14.2 Application, 204
14.3 Fault Tree Construction, 205
14.4 Event Symbols, 205
14.5 Logic Gates, 207
14.6 Analysis Procedure, 208
14.6.1 Deﬁning the Problem, 208
14.6.2 Constructing the Fault Tree, 209
14.6.3 Analyzing the Fault Tree, 210
14.6.4 Documenting the Results, 211
14.7 Examples of Fault Tree Analysis, 211
14.7.1 Simple Example, 211
14.7.2 Modeling Success Using Fault Tree Analysis, 214

x
Contents
14.7.3 Fault Tree Analysis for Use in Accident
Investigation, 215
14.8 Summary, 221
References, 221
15 Probabilistic Risk Assessment
223
15.1 Description, 223
15.2 Requirements of the Risk Assessment, 224
15.3 Simpliﬁed PRA Procedure, 224
15.4 Hazard Identiﬁcation and Evaluation, 225
15.5 Qualitative Risk Assessment, 225
15.6 Quantitative Risk Assessment, 226
15.7 Uses of PRA, 229
15.8 Conclusion, 230
References, 230
16 Qualitative and Quantitative Research Methods
Used in Risk Assessment
231
16.1 What is Qualitative Research? 231
16.1.1 Narrative Research, 232
16.1.2 Phenomenological Description, 233
16.1.3 Grounded Theory Research, 234
16.1.4 Ethnographic Research, 235
16.1.5 Case Study Research, 236
16.2 Quantitative, 238
16.3 Risk Assessment Perspective, 240
16.3.1 Aviation Study, 241
16.3.2 Design, 245
16.4 Conclusion, 247
References, 247
17 Vulnerability Analysis Technique
249
17.1 Introduction, 249
17.2 Case Study 1: Intruder, 251
17.3 Case Study 2: Multipurpose Academic Building, 254
17.3.1 Methods of Collecting Information, 255
17.3.2 Task Analysis, 257
17.3.3 Risk Assessment, 259
Reference, 276

Contents
xi
18 Developing Risk Model for Aviation Inspection
and Maintenance Tasks
277
18.1 Introduction, 277
18.2 Failure Mode and Effect Analysis, 277
18.3 Event Tree and Fault Tree Analysis, 279
18.4 Summary, 290
References, 291
19 Risk Assessment and Community Planning
292
19.1 Introduction, 292
19.2 Example Analysis, 296
19.2.1 Preliminary Hazard Analysis for Site A, 298
19.2.2 Preliminary Hazard Analysis for Site B, 298
19.2.3 Preliminary Hazard Analysis for Site C, 303
19.3 Summary, 307
References, 307
20 Risk of an Epidemic
309
20.1 Introduction, 309
20.2 Plague Example, 311
20.3 Tularemia Example, 312
20.4 Anthrax Example, 312
20.5 Ebola Example, 313
20.6 Smallpox Example, 313
20.7 TB Example, 314
20.8 Typhoid Fever Example, 314
20.9 Inﬂuenza Example, 315
20.10 Example of Measles, Mumps, and Rubella, 315
20.11 Polio Example, 316
20.12 Pertussis (Whooping Cough), 316
20.13 Cholera Example, 317
20.14 Summary, 318
References, 318
21 Process Plant Risk Assessment Example
319
21.1
Introduction, 319
21.1.1 Phillips Houston Chemical Complex, 319
21.1.2 BP Texas City Reﬁnery, 323

xii
Contents
21.2
Example Analysis, 327
21.2.1 Preliminary Hazard Analysis, 331
21.2.2 Sample Failure Mode and Effect Analysis, 334
21.2.3 Sample Event Trees, 334
21.2.4 Sample Fault Trees, 334
21.2.5 Sample PRA, 334
21.3
Summary, 344
References, 344
22 Industry Speciﬁc Case Studies
346
22.1
Case Study 1: Overview, 346
22.1.1 Introduction, 347
22.1.2 Approach, 349
22.1.3 Summary, 354
22.2
Case Study 2: Overview, 354
22.2.1 Introduction, 355
22.2.2 Approach, 356
22.2.3 Conclusions, 359
22.3
Case Study 3: Overview, 362
22.3.1 Introduction, 363
22.3.2 Purpose Statement, 363
22.3.3 Airport Security Risk Assessment Process, 364
22.3.4 Summary, 369
22.4
Case Study 4: Overview, 369
22.4.1 Introduction, 369
22.4.2 Food Safety Risk Assessment, 371
References, 375
23 Restaurant Risk Assessment Case Study
376
23.1
Introduction, 376
Glossary
381
Acronyms
386
Index
389

List of Figures
1.1
Bathtub curve
5
4.1
Yeast growth
27
4.2
ERA process ﬂow (26)
44
4.3
Proposed layout of PPI west coast location
46
4.4
Example conceptual model for proposed PPI
51
5.1
Hierarchical task analysis diagram
61
5.2
Time line
62
5.3
Operational sequence diagram
62
6.1
Infant crib
77
7.1
Discrete distribution
89
7.2
Tree diagrams of coin ﬂip
95
7.3
Tree diagram of being dealt two hearts
96
8.1
Binning failures
102
8.2
Relative probability scale
112
8.3
First-round voting
113
8.4
Results of the second round
114
10.1 SCRAM actions for Verify Rods Inserted. The operations
personnel should validate this sequence of steps and the
sequence changed or notes added as needed
141
10.2 HRA event tree method
142
10.3 Verify Rods Inserted
143
10.4 Another view of Veriﬁed Rods
144
10.5 HRA event structure of coolant ﬂush procedure
150
10.6 Modiﬁed event tree
151
11.1 Process map from interview
156
11.2 Process map symbols
157

xiv
List of Figures
11.3 Generic process map for trade group
158
11.4 Simple incident process map
159
12.1 Event tree
164
12.2 Event tree with path probabilities
165
12.3 Event tree for a portion of a small-break LOCA
166
12.4 Event tree for Tulsa event ﬁgure
168
12.5 Decision tree 1 format
169
12.6 Decision tree 2
170
12.7 Decision tree 3
175
12.8 Chernobyl event sequence
178
13.1 Interconnection of critical functions
189
13.2 Flight during an engine failure event
189
13.3 Critical functional analysis for convenience store
194
13.4 Critical functional analysis of a chemical reactor system
195
13.5 Critical functions during process upset
196
13.6 Rural county critical functions
200
14.1 Switches representing AND gates
208
14.2 Switches representing OR gates
208
14.3 Fault tree analysis of coolant ﬂushing task
214
14.4 Partial fault tree of sprinkler system failure
216
14.5 Fault tree for success model
216
14.6 Fault tree for TAM Linhas Aereas Flight 3054
220
16.1 Quantitative research step process
239
16.2 Investigation cycle
242
16.3 Example of the design for the visual crack study given to
inspectors (12)
246
18.1 Event tree
287
18.2 Event tree with path probabilities
287
18.3 Example fault tree
290
19.1 General layout of the Medium City
297
19.2 Fault tree for chemical release event for location A
303
19.3 Fault tree for chemical release event for location C
306

List of Figures
xv
20.1 Simpliﬁed cholera epidemic fault tree
310
21.1 Plant diagram
329
21.2 Fault tree for failing to pump chemical A into the reactor 339
21.3 Fault tree for a VAD chemical batch
340
21.4 Sample fault tree for chemical A or B spill
341
21.5 Sample fault tree for ignition source
342
22.1 Robot arm and unitized doses of medications
347
22.2 Station where robot arm drops unitized doses in bag for
delivery to patients
348
22.3 Unitized doses of medication on the pick rack
348
22.4 Unitized dose packaging. (a) Step 1: drug is selected. (b)
Step 2: pills are poured onto packaging machine.
(c) Step 3: pills are loaded into hopper. (d) Step 4: pills
are packaged
350
22.5 Fault tree analysis
352
22.6 Moving fast
355
22.7 F-16s up close
356
22.8 Process ﬂow for hydrazine leak
358
22.9 Event tree
374
22.10 Food safety fault tree 1
374
22.11 Food safety fault tree 2
375


List of Tables
1.1
Risk Assessment Tools
8
4.1
Farm Chemicals Found in the Soil on Proposed
Building Site
46
4.2
Chemicals Used to Manufacture Widget A
48
5.1
Required Types of Information
59
5.2
Methods of Collecting Information
60
5.3
Examples of Data Recording
61
5.4
Analysis Techniques
63
6.1
Example of Hazard List for Grill
70
6.2
Example of Hazard List
71
6.3
Examples of Hazardous Energy Sources
72
6.4
Analysis of Procedure
74
6.5
Partial PHA of Infant Crib
78
7.1
Dice Probabilities
83
7.2
Probabilities of Dice Events
84
7.3
Probabilities of Second Round
85
7.4
Dice Matrix
93
8.1
Example Failure Rate Data
99
8.2
Hardware Failure Data
101
8.3
Binning of the Data
102
8.4
Accident Probabilities
104
8.5
Space Shuttle Flight Stats
104
9.1
FMEA
121
9.2
Process Steps
122
9.3
Failure Modes
122
9.4
Effect of Potential Failures
123

xviii
List of Tables
9.5
Potential Causes of the Failures
124
9.6
Control Measures
127
9.7
Criticality
129
9.8
Example of a Risk Matrix
130
9.9
Criticality Analysis
131
10.1 Recovery Action
142
10.2 THERP Tables
145
10.3 Control Switches
145
10.4 Total HEP Calculations
147
12.1 Accident Sequence
164
12.2 Event Sequence with Probabilities
165
12.3 Decision Tree 1 Analysis
170
12.4 Accident Classiﬁcation and Associated Cost
172
12.5 Probability of Accidents
173
12.6 Cost of Accidents
174
12.7 Events to be Analyzed in Chernobyl Event
179
13.1 Functions of the Major Components of a Space Shuttle
182
13.2 Lower Level Crew Life Support Functions of Orbiter
183
13.3 Critical Functions of a Commercial Airplane
188
13.4 Flight Critical Systems for F-22 Raptor
191
13.5 Critical Functions for Continuity of Operations
198
13.6 Secondary Critical Continuity of Operations Functions
200
14.1 Common Fault Tree Symbols
206
14.2 Logic Gates
207
14.3 More Complicated Logic Gates
209
14.4 Rules for Constructing Fault Tree
210
14.5 Basic Events
213
14.6 Credible Failures
215
14.7 Credible Events
217
17.1 Partial Vulnerability Assessment of a Community
Hospital
252
17.2 Building Hazards
267

List of Tables
xix
17.3 Natural Hazards
268
17.4 Man-Made Hazards
269
17.5 Building Hazards
271
17.6 Natural Hazards
273
17.7 Man-Made Hazards
274
17.8 Sample Sources of Information for a Vulnerability Study
275
18.1 Example of FMEA Table
280
18.2 Process Steps for Checking a Chip Detector
281
18.3 Failures Associated with Each Step
281
18.4 Effect of Potential Failures
282
18.5 Complete FMEA for Chip Detector Task
283
18.6 Accident Sequence
286
18.7 Event Sequence with Probabilities
286
19.1 List of Chemicals
298
19.2 Preliminary Hazard Analysis for Site A
299
19.3 Preliminary Hazard Analysis for Site B
301
19.4 Preliminary Hazard Analysis for Site C
304
19.5 Probabilities for Basic Events
306
19.6 Chemical Release Spill Calculations
307
21.1 Key Issues in 1983 Phillips Explosion
321
21.2 Time line of Events Leading to the Texas City Explosion
325
21.3 Chemical Properties
328
21.4 Plant Symbols
330
21.5 Plant Component Reliability Data
331
21.6 Sample Preliminary Hazard Analysis for Process Plant
332
21.7 Sample Failure Mode and Effect Analysis for Process Plant 335
21.8 Fire Event Tree for Process Analysis
338
21.9 Event Tree Sequence for Chemical Fore and Subsequent
Release of Chemical C
342
21.10 Failure Rate Data
343
21.11 Combined Failure Rates
343
22.1 Original Cut Sets
360

xx
List of Tables
22.2 Modiﬁed Cut Sets
361
22.3 Four Parts of the Airport Security Screening Process
and their Purpose
364
22.4 Revised Cut Set
367
22.5 Cut Sets
368
22.6 Food Safety Preliminary Hazards
372
23.1 Restaurant Risk Assessment
377

Acknowledgments
We wish to thank all the individuals who helped us bring this project
together:
Dr. Barbara Kanki of NASA Ames Research Center for her con-
tinued support in risk assessment over the years.
Cherlyn Jewkes and Rachelle Wilhelmsen for their help with edit-
ing and formatting.
Dawn Dieckmann for her help with reference checking.
Warren “Dewey” Plaster, John Ostrom, David E. Fry, Rochelle
Mason, Val Sealey, Eric Roy, and Louis Valenti for their contri-
butions to the case studies.
Kyle Williams for critical review of the document early in its life.
Laura Ostrom for the chapter titled Risk of an Epidemic.
Also, all the graduate students who provided comments or infor-
mation over the years.


CHAPTER 1
Introduction to Risk
Assessment
On any given day, in every corner of the world people are actively
working, going to school, driving or taking mass transit to work, relax-
ing at home or on vacation, or even working at home. Some people
are even ﬁnding the time to sleep. Those who are working perform
jobs that range from cleaning animal kennels to being the head of
state of a country and every type of job in between. Every job, in fact,
every activity a human performs, has a hazard associated with it. The
common hazards we all are exposed to include
• slips, trips, and falls;
• illness and disease;
• food borne illness;
• transportation: car accidents, pedestrian accidents, and bicycle
accidents;
• sports: organized sports (football, basketball, soccer) accidents,
individual sports accidents (skiing, water sports, skate boarding);
• electrical;
• ﬁres;
• snow removal.
Risk Assessment: Tools, Techniques, and Their Applications, First Edition.
Lee T. Ostrom, Cheryl A. Wilhelmsen.
2012 John Wiley & Sons, Inc. Published 2012 by John Wiley & Sons, Inc.

2
CHAPTER 1 Introduction to Risk Assessment
On top of these more common hazards, every job has speciﬁc
hazards associated with it. The major hazards associated with cleaning
animal cages, for example, include
• being attacked by the animal;
• the bacteria, viruses, and parasites that might be in the animal
waste;
• the design of the cage might pose problems: size, shape, material
of construction, and sharp edges;
• the maintenance of the cage might pose problems: cleanliness,
jagged metal or wood, and faulty locks/latches/gates/door;
• the condition of the ﬂoor;
• the electrical and/or Heating Ventilation and Air Conditioning
(HVAC) system in the building;
• the building’s environmental conditions.
The major hazards associated with being a head of state include
• stress from decision making;
• stress from the potential for war;
• stress from political rivals;
• potential for assassination;
• potential for transportation accidents: airplane crashes (i.e.,
the President of Poland died in an airplane crash in Russia in
2010 (1).)
Hazardous occupations, for instance, ﬁre ﬁghting, have numerous
hazards associated with day-to-day activities. Risk assessment tools
and techniques can be used to analyze individual jobs for risks. It is
obvious that every activity the President does is analyzed for hazards.
Jobs or tasks such as ﬁre ﬁghting, chemical plant worker, electrician,
and even ofﬁce workers are usually analyzed using tools such as job
hazard analysis (2).
The focus of this book is on analyzing complex systems, tasks, and
combinations of tasks for hazards and the associated risks. Most of the
major accidents that occur each year result from a series of events that
come together in an accident chain or sequence and result in numerous

CHAPTER 1 Introduction to Risk Assessment
3
deaths, environmental consequences, and property destruction. These
accidents can occur anytime in the system’s life cycle. One of the
events from history that demonstrates this is the sinking of the Swedish
ship Wasa (pronounced Vasa) on August 10, 1628 (3). The ship was
fabricated between 1626 and 1628. In those days, engineering of the
ships was performed by the shipwright, and he used his experience
to determine factors such as center of mass and the amount of ballast
the ship should have. Because of various events, pressure was put on
the shipbuilders to complete the ship ahead of the planned delivery
time. The ship was completed and ready for sail on August 10, 1628.
The ship was very ornately decorated and was heavily laden with
armament. As the ship left port on its maiden voyage on that calm
morning, a gust of wind hit the ship, ﬁlling her sails. The ship heeled
to port and the sailors cut the sheets. The ship righted itself, but then
another gust of wind hit the ship and it tipped to port far enough that
water entered the gun ports. This was the event that led to the loss
of the ship and approximately 30–50 lives. However, the loss of the
ship was probably due to one of the two design ﬂaws. The ﬁrst factor
being that the ship was probably too narrow for its height, and second,
the ship did not carry enough ballast for the weight of its guns on the
upper decks. A contributing factor was the height above sea level
of the gun ports that allowed water to enter the ports when the ship
listed to port. Since, as stated above, engineering of ships was more
seat of the pants than a systematic design process, the real reason(s)
for the disaster can only be speculated. The ship was raised from her
watery grave in 1959 and has since been moved to a beautiful museum
facility in Stockholm. Therefore, the ship itself can be studied, but
other factors such as whether the guns were properly secured, how
much provisions were on the ship, and so forth will remain a mystery.
The Wasa accident occurred in the ship’s initial phases of its life cycle.
Accidents can occur in any phase of a system’s life cycle.
A much more recent accident occurred on December 24, 2008,
in Rancho Cordova in which a natural gas leak caused an explosion
and ﬁre, killing one person and injuring ﬁve others including one
ﬁreﬁghter and a utility worker. The explosion also destroyed one
house completely and severely damaged two others adjacent to the
destroyed house. Several other houses in the neighborhood were
damaged. Paciﬁc Gas and Electric Company, the utility owner
and operator, operates 42% of California’s natural gas pipe lines.

4
CHAPTER 1 Introduction to Risk Assessment
According to Paciﬁc Gas and Electric Company, the property damage
from this explosion and ﬁre was $267,000 (4). The incident involved
piping that had been originally installed in 1977 and repaired in
2006. The accident investigators found that a piece of piping that was
used in the repair was actually polyethylene pipe used as packing
when transporting the ASTM D-2513 grade polyethylene piping.
The wall thickness of the packing piping did not meet speciﬁcations
and there were no print lines of the piping used in the repair. The
repair personnel, for whatever reason, selected a piece of the packing
piping as the repair material, rather than ensuring the pipe was of the
proper grade. Therefore, as with the Wasa event, human error was
the primary driver in the event. Although, in both events, hardware
components were involved as well.
Risk assessment tools and techniques, if applied systematically and
appropriately, can point out these types of vulnerabilities in a system.
The key term here is “systematic.” A risk assessment must be sys-
tematic in nature to be most effective. A risk assessment should begin
early in the life cycle of complex systems. Preliminary hazard analysis
(PHA) is an example of a tool that can be applied at the earliest phase
of system development. As the design of a system progresses other
tools can be applied, such as failure mode and effect analysis (FMEA)
and fault tree analysis (FTA). Probabilistic risk assessment (PRA) and
human reliability analysis (HRA) are techniques used to analyze very
complex systems. These tools usually require a well-developed design,
an operating philosophy, and at least working copies of procedures to
provide enough material to perform analyses. However, even mature
systems beneﬁt from risk assessments. The analyses performed on the
space shuttle after the Columbia accident are a good example (5).
These assessments pointed out vulnerabilities of the space craft that
were previously unidentiﬁed or viewed as being not as important.
Using the six sigma/total quality management philosophy of con-
tinuous improvement, risk assessment techniques applied throughout
the design life of a system can provide insights into safety that might
arise at various points of the system’s life cycle (6). Reliability engi-
neers use the bathtub curve to illustrate the classic life cycle of a
system (Fig. 1.1) (7). In the ﬁrst part of a system’s life, there is
a higher potential for early failure. The failure rate then decreases
to a steady state until some point in the future when systems wear out
or old age failure occurs.

CHAPTER 1 Introduction to Risk Assessment
5
Steady-state (random)
failures
Early failures or
infant mortality
Wear out or old
age failures
Warranty limit
FIGURE 1.1
Bathtub curve.
Manufacturers usually warranty a system, a car for instance, for
the period of time from birth till just before system wear out. This
way they maximize their public image, while minimizing their risks
or obligations.
Risk analysts are also interested in such curves but from a safety
perspective. Accidents commonly occur early in a system’s life cycle
because of several reasons, including
• mismatch of materials;
• hardware/software incompatibilities;
• lack of system understanding;
• operator inexperience or lack of training.
The system then enters a long phase of steady-state operation that,
as long as no changes perturbate the system, remains safe. In later
system life, accidents occur for the same reason as why systems wear
out, components wear out. However, in terms of accident risk, when
a component fails in old age it might lead to a catastrophic failure
of the system, for instance, the Aloha Flight 243 accident (8). In this
case, the aircraft structure had become fatigued with age and failed
during takeoff. Workers have fewer accidents in their later working
years; however, the severity of the injuries may be greater (9). In
addition, latent conditions can lay dormant for many years in a system
(10). These conditions could be a piece of bad computer code or a

6
CHAPTER 1 Introduction to Risk Assessment
piece of substandard pipe that when challenged leads to a failure.
Performing risk assessments on systems throughout their life cycle
can help to elucidate these vulnerabilities. Once these vulnerabilities
are found, measures can be taken to eliminate them and/or mitigate
the consequences of failures. This is the most important step of any
risk assessment. That is, eliminating the vulnerabilities and reducing
the risk of a system.
1.1 TERMINOLOGY
Risk assessment terminology will be presented throughout the book.
However, at this time, several key terms will be deﬁned.
Risk has been deﬁned in many ways, and for the purposes of
this book, risk is deﬁned as the probability of an unwanted event that
results in negative consequences. Kaplan and Garrick use a set of three
questions to deﬁne risk (11).
1. What can go wrong?
2. How likely is it?
3. What are the consequences?
Chapter 2 of this book deﬁnes risk in depth.
Probability is deﬁned as a measure of how likely it is that some
event will occur (12).
Hazard is deﬁned as a source of potential damage, harm, or adverse
health effects on something or someone under certain conditions at
work (13).
Severity is deﬁned as the degree of something undesirable (12).
Consequence is deﬁned as the effect, result, or outcome of some-
thing occurring earlier (12).
Vulnerability is deﬁned as a weakness in a system or human that
is susceptible to harm (12).
Threat is deﬁned as a source of danger (12). Threat and hazard
are considered analogous.
1.2 PERFORMING RISK ASSESSMENTS
There is no absolute rule as to how a risk assessment should be
performed and to what depth it should be performed. The NASA

1.3 Risk Assessment Team
7
PRA guide (14) provides some recommendations and the Nuclear
Regulatory Commission (NRC) provides numerous guideline docu-
ments on the topic (15). The Occupational Safety and Health Admin-
istration’s (OSHA) “Process Safety Management of Highly Hazardous
Chemicals” regulation (29CFR1910.119) (16) requires hazard analy-
ses be performed for certain types of chemical operations, and the
Department of Energy (DOE) speciﬁes risk assessments for certain
types of facilities (17). However, it is still up to the organization to
decide how in depth the analysis should be. This book discusses tools
that are effective for performing risk assessments, but the decision
as to when to use the tools is up to the risk analyst. Table 1.1 pro-
vides a list of the risk assessment tools discussed in this book and
at what point in an analysis they are traditionally used. In addition,
this book provides other techniques that can be used to enhance a risk
assessment, such as task analysis for determining human actions in
a process, the Delphi process for eliciting human error probabilities,
and the critical incident technique for developing risk scenarios.
1.3 RISK ASSESSMENT TEAM
Risk assessment is a systematic, step-by-step approach for evaluating
risk. It is the process for determining the probability of a risk occur-
ring and the consequence of that risk. It is a fundamental component
of an effective risk management program. This program is a basic
management tool consisting of risk assessment and risk control. Risk
assessment is the data gathering component, while risk control is the
application of the risk assessment evaluation.
1.3.1 Team Approach
Individuals will respond to a risk or perception of a hazard based on
their inﬂuences, environment, and biases. What one person may per-
ceive as a relatively low risk, another may consider highly dangerous
no matter what controls are in place. If one or two individuals are
asked to perform an assessment, some relevant factors may be missed
or ignored. When determining the best course of action for perform-
ing a risk assessment, it is important to remember people will bring
their own perceptions. Even in respect to experts, different experts will

8
CHAPTER 1 Introduction to Risk Assessment
TABLE 1.1
Risk Assessment Tools
Tool
Traditional use
Book chapter
Preliminary hazard
analysis (PHA)
This tool is used in the very
beginning of a risk assessment
and/or on a conceptual design of a
new system, process, or operation.
It is used to determine the
potential hazards associated with
or the potential threats poised to a
system, process, or operation.
This tool is also useful for
organizations to evaluate
processes that have been
performed for years to determine
the hazards associated with them.
5
Failure mode and
effect analysis
(FMEA)
This tool is used in system, process,
or operations development to
determine potential failure modes
within the system and provides
means to classify the failures by
their severity and likelihood. It is
usually performed after a PHA
and before more detailed analyses.
9
Failure mode, effects,
and criticality
analysis (FMECA)
FMECA extends FMEA by
including a criticality analysis that
is used to chart the probability of
failure modes against the severity
of their consequences. FMECA
can be used instead of an FMEA,
in conjunction with an FMEA or
after an FMEA has been
performed.
10
Event trees
Event trees are very useful tools to
begin to analyze the sequence of
events in potential accident
sequences. They also have utility
in analyzing accidents themselves.
Many variations of event trees
have been developed. This book
presents some of the more
common ones.
12

1.3 Risk Assessment Team
9
TABLE 1.1
(Continued)
Tool
Traditional use
Book chapter
Fault tree analysis
(FTA)
FTA is a risk analysis tool that uses
Boolean logic to combine events. The
lower level events are called basic
events, and they are combined with
Boolean logic gates into a tree
structure, with the undesired event of
interest at the top. This event is
called the top event. Although this
analysis tool is used to quantitatively
determine the overall probability of
an undesired event, it is also useful
from a qualitative perspective to
graphically show how these events
combine to lead to the undesired
event of interest. FTA has a wide
range of use from determining how
one’s checking account was
overdrawn, to determine why a space
shuttle crashed.
14
Human reliability
analysis (HRA)
HRA is related to the ﬁeld of human
factors engineering and ergonomics
and refers to the reliability of humans
in complex operating environments
such as aviation, transportation, the
military, or medicine. HRA is used to
determine the human operators’
contribution to risk in a system.
10
Probabilistic risk
assessment (PRA)
PRA is a systematic and
comprehensive methodology to
evaluate risks associated with
complex engineered systems,
processes, or operations such as
space craft, airplanes, or nuclear
power plant. PRA uses combinations
of all the other risk assessment tools
and techniques to build an integrated
risk model of a system. A fully
integrated PRA of a nuclear power
plant, for instance, can take years to
perform and can cost millions of
dollars. It is reserved for the most
complex of systems.
15

10
CHAPTER 1 Introduction to Risk Assessment
perceive different risks and from those perceptions, conclude different
results or controls. In general, you want to bring together a group of
people who work in the environment to work together as a team.
1.3.2 Team Representatives
Before any assessment of the risks can be started, a determination of
who should be involved or who makes up the risk assessment team
needs to be considered. The right group of people with the right mix
of experience. The team will be between 5 people up to 10–15, if
necessary. The team will include people from all sorts of different
jobs and experience.
Risk assessment is never a one man show; it should be conducted
by a multidisciplinary team, who has a thorough knowledge of the
work to be undertaken. Team members should include management,
process or facility engineers, technical personnel, supervisors, produc-
tion operators, maintenance staff, and safety personnel, if available.
The team members will vary from assessment to assessment, com-
pany to company, and industry to industry, but the following elements
are common:
1. Management should be involved to give practical application
in the decision-making process of risk reduction controls and
accepting residual risk level.
2. Engineers should be involved in the risk assessment process,
as they are involved in the development of the design decisions
that will impact the overall risk and risk controls.
3. Workers/Operators/Supervisors
should
be
involved
and
included in the team, as these people are the most familiar
with the tasks and uses for which the assessment will directly
effect. These are the individuals best suited to identify the
possible hazards associated with the end use. They can provide
valuable insights on the possible controls and the practical
application of those controls.
4. Health and Safety Professionals, if available, can offer valu-
able insights into what control measures might be available.
They can identify possible hazards and propose risk reduction
methods and their application.

References
11
5. Maintenance is another component that needs to be represented
to understand the ramiﬁcations of implementing controls on the
system or process being assessed.
The goal of the risk assessment team is to reduce risks to tolerable
or acceptable levels. This assessment is completed by
1. identifying hazards and/or potential hazards;
2. identifying users and/or tasks;
3. determining the level of risk;
◦low, acceptable
◦medium, moderately acceptable
◦high, not acceptable
4. evaluating potential controls—elimination, substitution, engi-
neering controls, administration controls, and/or use of personal
protective equipment;
5. developing a report;
6. implementation and review.
The resulting risk assessment report must be evaluated, approved,
and endorsed by senior management.
REFERENCES
1. Available at http://msnbc.msn.com: http://msnbc.msn.com/id/36352097/ ns/world
news-europe/. Retrieved 2011 Jan 25.
2. Available at www.osha.gov: http://www.osha.gov/Publications/osha3071.html.
Retrieved 2011 Jan 25.
3. Cederlaund CO. Vasa I, The Archaeology of a Swedish Warship of 1628; 2006.
4. Available at www.ntsb.gov: www.ntsb.gov/pulictn/2010/PAB1001.pdf. Retrieved
2011 Jan 25.
5. Colombia Accident Investigation Board, Final Report. NASA; 2003. Available at
http://caib.nasa.gov/news/report/default.html (retrieved March 2012).
6. Available at www.theiia.org: http://www.theiia.org/intAuditor/free-feature/2009/
december/risk-assessment-six-sigma-style/. Retrieved 2011 Jan 25.
7. Kececioglu D. Reliability Engineering Handbook. Englewood Cliffs (NJ):
Prentice-Hall; 1991.
8. Available at www.ntsb.gov: http://www.ntsb.gov/ntsb/GenPDF.asp?id=DCA88
MA054&rpt=fa. Retrieved 2011 Jan 25.

12
CHAPTER 1 Introduction to Risk Assessment
9. Available
at
http://.osha.europa.eu:
http://osha.europa.eu/en/prioritygroups/
ageingworkers/hazards html. Retrieved 2011 Jan 25.
10. Reason, J. (1990). Human Error. New York: Cambridge University Press.
11. Kaplan S, Garrick B. On the quantitive deﬁnition of risk. Risk Anal 1981;
1:11–27.
12. Available at http://wordnetweb.princeton.edu: http://wordnetweb.princeton.edu/
perl/webwn. Retrieved 2011 Jan 25.
13. Available at www.ccohs.ca: http://www.ccohs.ca/oshanswers/hsprograms/hazard
risk.html. Retrieved 2011 Jan 26.
14. Available at www.hq.nasa.gov: www.hq.nasa.gov/ofﬁce/codeq/doctree/praguide.
pdf. Retrieved 2011 Jan 26.
15. U.S. NRC. Available at http://www.nrc.gov/reading-rm/doc-collections/nuregs/
staff/sr1855/v1/sr1855v1.pdf. Retrieved 2010 Dec 31.
16. (n.d.). Available at www.osha.gov: http://www.osha.gov/pls/oshaweb/owastand.
display standard group?p toc level=1&p part number=1910. Retrieved 2011
Jan 25.
17. (n.d.). Available at www.doe.gov: www.doe.gov. Retrieved 2011 Jan 26.

CHAPTER 2
Risk Perception
Simply deﬁned, the word risk denotes some measure of uncertainty.
In casual use, risk implies negative consequence while opportunity
implies positive consequence (1).
Perception is the process of interpreting sensory stimuli by ﬁltering
it through one’s experiences and knowledge base. Note that perception
is not the same as sensation, as the latter term is physiological and the
former is learned (2).
Taken together, risk perception is an individual or group assess-
ment of the potential for negative consequence. Within emergency
management circles, understanding the public’s general perception of
risk (for instance, the isolated opinion contains peaks and valleys) is
useful in establishing the necessary level of preincident emergency
training, public relations and instructions/recommendations during the
incident, and postincident continuing communications. Risk perception
plays into the choices made as to what information is to be provided
and in what format—both inside the affected organization and outside.
From the company’s management structure to its blue-collar workers
to its colocated workers to the neighboring suburbs and beyond, risk
perception is as close to “the facts” as each person gets until their
vision is altered by some later, greater truth.
Like the proverbial two-edged sword, risk perception both serves
and hinders emergency management (EM) organizations and, subse-
quently, those protected and supported by the EM function. At one
Risk Assessment: Tools, Techniques, and Their Applications, First Edition.
Lee T. Ostrom, Cheryl A. Wilhelmsen.
2012 John Wiley & Sons, Inc. Published 2012 by John Wiley & Sons, Inc.

14
CHAPTER 2 Risk Perception
tapered end of the spectrum lies a band of Chicken Littles pointing at
the blue sky and warning of dire consequences; at the opposite, there
is a huddle of frumpy white-coated scientists swaddled in disdain.
The majority of us lay somewhere between these two, our placement
in demographics split into hundreds, even thousands, of layered and
skewed bell curves based on age and income, experience and educa-
tion, and innumerable other facets. It’s the endless variability of the
public that makes risk perception such a difﬁcult management issue.
But it can be managed.
While it is safe to say that there is a near-endless variation in per-
ception, cataloging allows one to build boxes around like perceptions
until they are within a deﬁned set. To build these boxes, you need to
know what factors affect the audience’s perception. Is the subject mat-
ter highly technical and beyond the bulk of the area’s laymen? Does
the vicinity you are considering have decades of experience with your
particular industry? Has that experience resulted in bad blood?
To understand what knowledge is relevant to your evaluation of
the audience’s risk perception, you have to consider the business you
are in. Examples of heightened sensitivity (and negative perception)
are those where the technology involved borders on black magic to
the layman. Fission and fusion and government weapons facilities
come immediately to mind, followed by sprawling laboratories where
the workers say little about what goes on inside their white walls.
The less he knows, the more Joe Q. public thinks and wonders and,
ultimately, worries. As a matter of comparison, let us consider two
hazards commonly found in high population areas: liquid petroleum
gas and lawn care chemicals.
Liquid petroleum gas (LPG), AKA LPG AKA propane, is a com-
mon fuel in the city and the country, in industrial areas and rural areas,
and at homes and businesses. Small containers, such as those used for
barbeques, propane-powered vehicle fuel tanks, and camp trailers can
be found literally everywhere. Larger containers, such as 30,000-gal
bulk tanks for distributors, can be found in most cities across the
country. At pier side, where massive ships unload, tanks may carry as
much as 50,000 tons of propane.
Decades of use and familiarity have made modern man comfort-
able with propane. The 250- and 500-gal tanks available at many
gas stations are no cause for concern (to the point that few of those
operating them even wear protective gloves or a face shield during

2.1 Knowledge Level
15
propane handling). The racks of reﬁllable barbeque propane bottles
stored outside most grocery stores are not either. Nor are the multiple
tractor-trailers carrying thousands of gallons of propane across town
and on every freeway.
A quick calculation shows that the 6000 gal of propane on any
given tanker truck contains approximately 549 million BTU—equal
to 138.4 tons of TNT or just over nine times the explosive force that
exploded over Hiroshima in August 1945. Still, it is just propane.
Right?
Suburban America believes in chemistry when it comes to their
pretty yards, colorful ﬂowers, and heavily laden vegetable gardens.
In just the care and feeding of their lawns, they rely on sprayed
fertilizers, pesticides, selective herbicides, fogs for trees, and powders
for annoying ants. If you watch Joe Q. public working with the likes
of these, often as not you will ﬁnd just a bit of care included. Service
companies warn you to keep your animals away from sprayed areas
until dry. Folks generally wear gloves and avoid spreading chemicals
on windy days. Some go as far as to wear dust masks. The point here
is that they think about it. Why? What is the difference between the
hazards of LPG and lawn care chemicals? They both are hazardous
but in different ways, and, generally speaking, both are accepted as
acceptable risks by the public.
2.1 KNOWLEDGE LEVEL
In this day and age, we are sensitive to the use, misuse, and abuse
of chemicals. Situation-stained landscapes such as Love Canal and
Bhopal are at the near edge of our memories and, if not, there is
always a chemical release or Resource Conservation and Recovery Act
(RCRA) violation or factory ﬁre spewing noxious fumes somewhere
on the news. With these constant reminders, we realize that, while
chemicals are necessary, they are also dangerous. And since there has
not been a recent, prominent example of a propane truck leveling a
city, it is just assumed to be not as dangerous. After all, it is just
propane, right?
To lay this issue solely at the feet of education is oversimplify-
ing it. First, this approach assumes that a well-informed public will
perceive the risks as the experts do and that a low probability of

16
CHAPTER 2 Risk Perception
an incident’s occurrence is enough to quantify the risk as insigni-
ﬁcant. This approach, while mathematically valid, does not consider
the emotional component the general public includes when they weigh
in. Teach them about a hazardous process, derive its accidents and
initiators, describe potential mitigations, and a deﬁnite chance exists
that you will just end up with hyperaware protestors. If for no other
reason than they now can quantify the results, regardless of the fact
that that particular set of results is considered highly unlikely in the
view of engineers and scientists. That is the power of emotion.
Then there is the cognoscente—those same scientists and engi-
neers mentioned earlier. This “trust me” crowd can undermine all
efforts an emergency management plan puts together with lackadaisi-
cal commitment and faint praise. Instead of objectively quantifying
the issues and assessing the necessary response, these types enable
the denial and Pollyannaish attitude often adopted in the burgeoning
moments of an incident. In comparison to all possible reactions, scien-
tiﬁc apathy is probably the most dangerous. Those smitten with it are
often the last to realize that the water has risen over their collective
chins and they do not know how to swim.
If data cannot adequately focus on one’s perception then those
factors that can are of some import. They are at least a subset of
the knowledge necessary to engage in successful emergency manage-
ment (assuming successful emergency management requires a targeted
risk perception). Subjectively speaking, the greatest inﬂuence on a
layman’s risk perception is probably experience. It is common for
mankind to live by the ideals, ideas, and rules of thumbs that are either
established or rooted in some past learning obtained solely through the
act of living or listening to those who lived before you. Unscientiﬁc?
Certainly. But, over time, the impact of experience has more history
than even science (witness the power of lore throughout time), so it
is worth listening to.
Ideals (or principles, if you had rather) are beliefs stemming from
some personal philosophy. They represent good versus bad and right
versus wrong, binaries and shades of gray that we choose to use to
guide our lives. One’s ideals are founded from so many avenues that
their mapping would look like a spider web. There is parental inﬂu-
ence, religious posturing, peer pressure, social paradigm, economic
stratiﬁcation, and a thousand other variables to contend with. Luckily,
for the analysts, it is also a social paradigm that most folks establish

2.1 Knowledge Level
17
their ideals early in life and stick to them. In addition, birds of a feather
ﬂock together—or like-thinking folks revolve within deﬁned cells that
are easier to measure and speak to than the individuals making them
up. For example, after conﬁrming the target ideal, it is possible to
predict the group or groups who weave this ideal into the foundation
of their belief system. For example, groups generally assigned the
“green” label can be expected to place harmony with the environment
above corporate proﬁt. Likewise, the technically minded will usually
couch their positions in concrete facts when queried for a position
on any contentious new theorem. Given a group’s anticipated ideals,
one has a leg up on pegging their expectations and, ultimately, their
perceptions.
Ideas are a bit of a quandary because, by deﬁnition, they do not
ﬁt into the accepted mold. Still, using a bit of risk analysis brain-
storming, a talented group of individuals can tag a good percentage of
the possible directions a new thought may take in a given emergency
situation and can therefore consider most of the new ideas. Of all the
unknowns, ideas are easily the easiest to account for. Even if the risk
analysis does not consider every possibility (an impossible feat itself),
it can create envelopes that all the possibilities fall into with a reason-
able degree of conﬁdence. This answer here is mostly left to science
and easy to control.
Rules of thumb (also termed as cognitive heuristics) are uncon-
sciously applied by most folks every day. Sailors predict the weather
with poetic prognostications formed on cloud structure and moon
auras. Investors buy and sell based on seemingly irrelevant politi-
cal and emotional trends that predicate the bullish or bearish market.
The military constructs offensive and defensive plans based on the
adversary’s holiday calendar and home country’s politics. The impact
of cognitive heuristics is the hardest to gather up and quantify, as these
rules vary from person to person based on their teacher’s experience
base. What was law to the teacher when the teacher was the student
may now be revised or rescinded simply by fresher experiences. Rules
of thumb are much like common sense in the sense that they are not
common, they change and adapt with use and over time (4).
With all this said, the above list of risk perception inﬂuences is
by no means conclusive; so many other factors come to bear that the
subject is worthy of tomes. Those mentioned here are only the tips of
the iceberg.

18
CHAPTER 2 Risk Perception
So, armed only with a few thoughts and the knowledge that risk
perception varies to an inﬁnite degree, how can one account for its
impact when developing an emergency management process? To start,
plan on providing the right information to the right ears. Select the
facts each group needs to hear and deliver the appropriate details for
each audience. This includes, among others, the general public, the
elected ofﬁcials, and those within the emergency management system.
The public wants to hear what the hazards are and know how and why
there is not a threat to little Johnny when he is running about in the
backyard. Elected ofﬁcials need about the same information, but they
need an entirely different delivery. Pepper your discourse with solid
and supportable statistics. Provide sound bites and concise thoughts.
The emergency management folks are the ones you need to save your
details for and while it is possible to give them too much detail, it is
better to err in this direction than the opposite way.
Communications are not what they used to be; there is much more
to work with beyond radio spots, television commercials, and door-to-
door ﬂiers. With a modest investment, those interested in maximizing
their safety posture’s exposure can put web sites up describing the
processes in question, the protections provided, and accident/release
potentials framed in real-world terms. Professional organizations allow
for presentations at conventions and training classes. Local centers for
higher education can be involved in preparing single day, multiday,
and semester long coursework that supports the professional growth
of those in the emergency management system and those employed
within the industry concerned about the hazard in question (3).
Establishing emergency management tours and ﬁre and rescue
plans ahead of time goes a long ways toward giving your emergency
response organizations a deeper level of conﬁdence in your, and their,
ability to respond to a problem. If you have a large or complex facility,
establishing a realistic emergency drill program that involves emer-
gency services will take that conﬁdence even further.
Facilities with a genuine ability to impact the habitability
of surrounding areas, such as large chemical plants, petroleum
processing facilities, and nuclear facilities, should establish a training
and response program for the general public within their affected
areas (sometimes termed as emergency planning zones or EPZs).
EPZs describe to the public what facility warning alarms sound like,

2.1 Knowledge Level
19
what actions should be taken when the alarm occurs, and provide
them with materials to keep their knowledge level fresh.
All of the above efforts play to both sides of the information
feeding into the public’s perception—the knowledge side and the
experience side.
With the broad spectrum of perspectives available, it is impor-
tant that one chooses the desired audience, as it is doubtful that you
will ﬁnd an approach that pleases everyone. Statistically speaking, an
organization’s best return for their dollar will come from targeting the
center of the risk perception bell curve and ﬁnding a way to include as
much of the standard deviation as responsible spending will allow. The
downside to this approach is that someone’s left out, and that some-
one, will undoubtedly be, courted to the edge by the Chicken Little or
White-Coated Doubter. To add injury to insult, this third sigma demo-
graphic is likely to beat the loudest and be the most inclined to play
whatever cards they have up their sleeve to make their point. What
should be done about them?
Short of something illegal, there are not many effective options
available. Optimally, the dissenters would be ignored and they would
go away because dealing with their proselytizing somehow imbues
it with signiﬁcance. When that is not possible, for whatever reason,
one has to once again consider what the right answer is from a risk
perspective standpoint.
Remember that perspective is learned. The audience that is consid-
ering the discordant rumblings of the dissenter believes they are learn-
ing something. Something valuable, in order to combat that impres-
sion, you have two choices: you will undermine the dissenter’s teach-
ings or you will provide more powerful teachings of your own.
There is an inherent failure in taking the negative approach (i.e.,
casting doubts on your dissenter) because interested parties paying
attention may see that as an attack on the person and not the idea.
That leaves option #2 providing more powerful teachings.
Assuming that one’s already splayed the relevant facts for all the
audience to see, the best “high road” option here may be speaking to
the criticisms of your detractors in a positive and fact-ﬁlled manner. Be
grateful that they are providing a new and exciting perspective to the
discussion. Embrace their thoughts and then discuss them thoroughly
while sifting through your bagful of data. Examine both and graciously
consider the difference between your perspective and theirs. In the end,

20
CHAPTER 2 Risk Perception
the audience, those whose perception you wish to inﬂuence, will make
up their minds based on ideals, ideas, and rules of thumb anyway and
if you have given them the education they require, that is the best you
can hope for.
REFERENCES
1. Berger B. Beating Murphy’s Law: the amazing science of risk. New York: Dell
Publishing; 1994.
2. Fielding R. (n.d.). Is it worth the risk? Risk perception. Available at www.pitt.
edu∼super1/lecture/lec4011/001.htm. Retrieved 2003 July 18.
3. Johnson BB. Advancing understanding of Knowledge’s role in lay risk perception.
1992. Available at http://www.fplc.edu/risk/vol14/summer/johnson.htm. Retrieved
2003 July 18.
4. Taylor I. Short Essay on Rules of Thumb for Development Planning. 2002.
Available
at
http://members.rogers.com:
http://members.rogers.com/iwtaylor/
development%20planning.htm. Retrieved 2003 July 22.

CHAPTER 3
Risks and Consequences
3.1 INTRODUCTION
In March 2011, a terrible 9.0 earthquake occurred off the coast
of Japan, and this generated an equally devastating tsunami (1).
Subsequent to these two natural events several nuclear power plants
had catastrophic failures, of which at this writing, have not been
fully ascertained. The natural events could not be predicted. In fact,
earthquake prediction is much less understood than is forecasting
the weather (2). However, the risk of a nuclear plant having a
catastrophic failure, even a meltdown after an earthquake, has been
analyzed (3). At some point, the beneﬁt of having nuclear electrical
power was found to be greater than the risk of a nuclear reactor
meltdown. In this chapter, the concept of risk and consequence is
discussed.
3.2 RISK AND CONSEQUENCE
Newton’s ﬁrst law states that every action has an equal or greater reac-
tion (4). Relating this to risk and consequence, it can be stated that
every human action has a consequence. Human actions, of course,
Risk Assessment: Tools, Techniques, and Their Applications, First Edition.
Lee T. Ostrom, Cheryl A. Wilhelmsen.
2012 John Wiley & Sons, Inc. Published 2012 by John Wiley & Sons, Inc.

22
CHAPTER 3 Risks and Consequences
range from drinking a glass of pure water that has very positive
consequences to launching a nuclear war that has very detrimental
consequences. With every action humans undertake, they are making
a calculation that the results of that action will have a positive, neu-
tral, or a minimally negative outcome. The actions are the risks, and
the outcomes are the consequences. In the course of a day, humans
make hundreds of decisions, and some of these decisions have major
implications on the rest of a person’s life.
Driving is always a good model of risk. Harold Blackman once
stated that if every human activity were as safe (unsafe) as driving,
risk analysts would not be needed (Private communication with Harold
Blackman, director of the Center for Advanced Energy Studies). What
does this mean? Well, driving is a very unsafe activity. Around 40,000
people are killed in the United States alone from driving-related acci-
dents (5). People are generally more afraid of ﬂying than of driving
or riding in a car. If ﬂying were as unsafe as driving then the air-
line industry would go away. If nuclear power plants operated as
unsafely as humans drive, the world would be highly contaminated
with radionuclides.
On any given day, drivers can be observed committing some very
risky driving maneuvers. They run red lights, cut in front of other
drivers, and change lanes rapidly without looking. It appears as though
they do not consider the consequences. The beneﬁt of doing these
maneuvers is the saving of seconds from their commute. In many
cases, it is just seconds. In fact, in many communities, the trafﬁc
lights are setup to control the rate of trafﬁc ﬂow, so even if a driver
commits several risky maneuvers, they probably will only arrive at
their destination at about the same time as the safe driver.
So, what are the consequences of risky driving?
• Drivers’ or passengers’ deaths
• Other drivers’ or passengers’ deaths
• Permanent disabling injuries
• Moderate injuries
• Property damage (most cars now cost well over $20,000)
• Loss of driving privileges
• Jail time

3.2 Risk and Consequence
23
• Tickets
• Bad reputation.
Driving recklessly can have very severe consequences, yet people
drive recklessly every day.
Consequences are a very important part of risk assessments. All of
the consequences need to be considered and should help to guide the
risk assessment. For instance, if a risk assessment is being performed
on a small chemical plant that produces very hazardous materials then
the following risks might be considered:
• off-site chemical release (major and minor);
• on-site chemical release (major and minor);
• ﬁres and explosions (major and minor);
• employee exposures (acute and chronic);
• transportation accidents;
• terrorist activities;
• damage to company reputation.
These are not all the possible consequences, but they are a good
start to help to guide how the risk assessment should be conducted.
The company or stakeholders and risk analysts need to bound the risk
assessment by the consequences of interest.
Going back to the events of March 2011 in Japan, it is obvi-
ous that when the site planning of nuclear power plants was being
conducted, the thought of a magnitude 9 earthquake and subsequent
tsunami was not considered. The San Onofre nuclear power plant
in California is designed to withstand a magnitude 7 earthquake (6).
However, as seen in Japan and the Indonesian earthquake in Decem-
ber 2004, earthquakes with a magnitude of greater than 7 are not
uncommon (7). Therefore, in future nuclear power plant construction,
it should be obvious that consideration needs to be made of all the
possible events and not of those that are most likely. In hindsight, the
Fukushima Nuclear Power plants should have been sited away from
the coast, so that any tsunami would not damage them to the point of
meltdown. Also, the safety systems should have been designed to sur-
vive the earthquake and tsunami. In the coming years, as the events in

24
CHAPTER 3 Risks and Consequences
Japan play out, the full consequences of the decision to site the plants
where they did will be understood.
The consequences of events such as Chernobyl and even
the Lockerbie bombing are felt quite strongly today, over 20
years since either event occurred (8). This is further evidence to
thoroughly consider all possible consequences when performing risk
assessments.
3.3 CREDIBLE CONSEQUENCES
In a meeting in 1990, a group of new engineers sat around a table
and discussed the possible risks to a research reactor in the middle
of the desert and the possible consequences. One possible scenario
was a large commercial airliner crashing into the reactor. On dis-
cussing the scenario, there was laughter in the room. On the morning
of September 11, 2001 that scenario became not just a “what if” but
a real disaster. Therefore, when determining the possible set of credi-
ble consequences of which to consider risk, ask at least the following
questions:
1. What are all the known hazards?
2. What are all the possible events involving these hazards?
3. Have these events occurred before?
4. How frequently have these events occurred?
5. What happens when these events occur?
6. How severe are the consequences of these events?
7. How hard is it to clean up the mess left by the event?
8. Who ultimately pays for the cleanup?
9. What values does the organization consider important?
Always involve a team of subject matter experts when developing
lists of possible consequences. The Delphi method discussed in
Chapter 7 is a good tool to aid in these types of activities. Never
dismiss a consequence until it is proven to be not credible. Then
consider all the credible consequences when performing the risk
assessment.

References
25
3.4 SUMMARY
As discussed above, all actions have consequences. Good eating habits
and exercise have positive consequences; reckless driving can have
very negative consequences. Question all the possible consequences
in the initial phases of a risk assessment and consider those that are
deemed to be credible. Do not toss out scenarios until they have been
analyzed.
In summary, human’s actions have consequences. The goal of risk
analysts is to help to determine which consequences are important
enough to consider in risk assessments and to analyze realistically
and appropriately.
REFERENCES
1. International Atomic Energy Agency (IAEA), IAEA International Fact Finding
Expert Mission of the Fukushima Dai-Ichi Npp Accident Following. The Great
East Japan Earthquake And Tsunami, Tokyo, Fukushima Dai-ichi, Fukushima
Dai-ni and Tokai Dai-ni, Japan, June 2011. Available at www.cnbc.com:
http://www.cnbc.com/id/42043590. Retrieved 2011 Mar 28.
2. Gad-el-Hak M. Engineering vs. disasters; 2008. Available at www.memagazine.org:
http://www.memagazine.org/contents/current/features/engvsdis/engvsdis.html.
Retrieved 2011 Mar 28.
3. Earthquake risk to Nuclear Power Plants; 2010. Nuclear Regulatory Com-
mission (NRC), Fact Sheet on Seismic Issues for Nuclear Power Plants.
http://www.nrc.gov/reading-rm/doc-collections/fact-sheets/fs-seismic-issues.html.
Retrieved 2011 Mar 28.
4. French A. Newtonian mechanics, The M.I.T. Introductory Physics Series. New
York: W.W. Norton & Company; 1971.
5. National Highway Trafﬁc Safety Administration. National Center for Statistics
and Analysis (NCSA). Available at http://www.nhtsa.gov/NCSA. Retrieved 2011
Mar 28.
6. Mello M. San Onofre Earthquake Protection; 2011. Available at OC Register
http://articles.ocregister.com/2011-03-12/12/news/28686252
1
nuclear-reactors-
plant-san-onofre. Retrieved 2011 Mar 28.
7. Indonesian Earthquake. Available at www.en.wikipedia.org: http://en.wikipedia.
org/wiki/2004 Indian Ocean earthquake. Retrieved 2011 Mar 28.
8. Lockerbie Bombing. Available at www.enwikipedia.org: http://en.wikipedia.org/
wiki/Lockerbie. Retrieved 2011 Mar 28.

CHAPTER 4
Ecological Risk
Assessment
4.1 INTRODUCTION
Widespread ecological disasters are nothing new on Earth. The Earth
has experienced countless such natural disasters over its history. One
of the ﬁrst such disasters that could most likely be the ﬁrst step in
progress toward current life forms on Earth is the advent of oxy-
gen. Oxygen-producing organisms began spewing free oxygen into
the atmosphere around 2.45 billion years ago, plus or minus a couple
years (1). This free oxygen tended to oxidize iron and the resulting
iron oxide precipitated out on the ﬂoors of the oceans. It thus removed
the dissolved iron from the oceans. These iron deposits are mined even
today (2, 3). Maybe if those inconsiderate cyanobacteria or blue-green
algae had not released free oxygen into the atmosphere, there would
be some other forms of life on the Earth.
The Earth has also had ice ages that have covered the entire globe
or a major portion of the northern or southern hemisphere with ice.
Thus, reducing the space that organisms could live to either in the
depths of oceans or on land closer to the equator. The Earth has
experienced hot, moist periods of time that allowed for the explosion of
new plant and animal species that drastically changed the environment.
Risk Assessment: Tools, Techniques, and Their Applications, First Edition.
Lee T. Ostrom, Cheryl A. Wilhelmsen.
2012 John Wiley & Sons, Inc. Published 2012 by John Wiley & Sons, Inc.

4.1 Introduction
27
In fact, what is amazing is that the Earth remained habitable for some
forms of life for hundreds of millions of years.
Plants and animals, in general, have the tendency to destroy their
living environment as they consume the resources they need to live.
The production of alcohol by yeast in the manufacture of beer and
wine is an excellent example of the cycle of an organism (4). Yeast
converts sugar to alcohol. Once the alcohol level in a fermentation vat
reaches somewhere between 4% and 12%, depending on the variety
of the yeast, they shutdown production due to the change in the envi-
ronment. The growth of the yeast has four distinct phases. They are
as follows:
1. Lag Phase. Yeast mature and acclimate to the environment.
2. Log or Expediential Phase. Yeast rapidly multiply, consuming
resources and generating waste, alcohol.
3. Deceleration Phase. Yeast growth slows due to lack of resour-
ces, sugar, and too much waste in the environment, alcohol.
4. Stationary Phase. Limited growth occurs due to lack of resour-
ces and too much waste.
Yeast literally eat themselves out of their environment. Figure 4.1
shows the four phases of yeast growth.
Yeast growth
Lag
phase
Log
phase
Time
Deceleration
phase
Stationary
phase
FIGURE 4.1
Yeast growth.

28
CHAPTER 4 Ecological Risk Assessment
Algae blooms in aquatic environments, over population of deer in
protected areas, and the lemming and predator balance in the arctic
are all examples of similar observable ecological disasters in which
animals or plants have a speciﬁc role.
Humans, of course, cause ecological disasters of their own. Those
of us who grew up in the 1950s, 1960s, and 1970s still remember
vividly the ecological problems that abounded in the United States
during those decades. In north Idaho, the Silver Valley around Kellogg,
ID, was under a constant layer of acrid smoke due to the lead smelters
in the area. Driving from Coeur d’Alene, ID, to Kellogg, one would go
from blue skies into a cloud of acrid smoke within a matter of 30 mi.
Trees could not grow on the mountain sides due to the chemicals
contained in the cloud of pollution. When vacationers ski in the Silver
Valley today, they see very few remnants of the ecological disaster that
once was blatantly obvious. The hill sides are once again tree covered
and the air is relatively clean. However, lead levels remain high in
the soil and on the bottom of Lake Coeur d’Alene (5). The primary
operator of the lead smelters was Bunker Hill. The area around the
Bunker Hill site was declared an Environmental Protection Agency
(EPA) Superfund Site in the early 1980s and a great mount has been
put into cleaning up the area.
More famous, or infamous, ecological disasters include the fol-
lowing:
• Chernobyl, Soviet Union (Belarus and Ukraine)
• Bhopal, India
• Deepwater Horizon, United States
• Love Canal, United States
• Minimata Methylmercury, Japan
• Agent Orange, Vietnam and the United States
• Seveso, Italy
The Bhopal and Chernobyl events are discussed in other
chapters. The following sections discuss attributes of the other events
listed.

4.2 Deep Water Horizon
29
4.2 DEEP WATER HORIZON
In the late spring and summer of 2010, the United States was dealing
with one of the worst oil spills to date (6–8). It occurred in the Gulf
of Mexico and involved the Deepwater Horizon drilling platform. The
Deepwater Horizon was an offshore oil platform owned by Transocean
Ltd (Transocean). The rig was drilling within the Macondo Prospect
oil ﬁeld approximately 50 miles southeast of Mississippi in approxi-
mately 5000 ft of water. The Deepwater Horizon was considered an
ultra-deepwater, dynamically positioned, column-stabilized, semisub-
mersible mobile offshore drilling unit (MODU) and could operate in
waters of up to 8000-ft deep. Semisubmersibles are rigs that have plat-
forms with hulls, columns, or pontoons that have sufﬁcient buoyancy
to cause the structure to ﬂoat, but with weight sufﬁcient enough to
keep the structure upright. The Deepwater Horizon housed 126 work-
ers, and its task was to drill wells, extract and process oil and natural
gas from the Gulf of Mexico, and export the products to shore. As with
any large venture, there are several principle players in an oil explo-
ration and development process. The rig was owned by Transocean,
but the principal developer of the Macondo Prospect oil ﬁeld was
British Petroleum Oil Company (BP). The Horizon had been leased
to BP on a 3-year contract for deployment in the Gulf of Mexico
following its construction. On April 20, 2010, an explosion on the
Deepwater Horizon and its subsequent sinking 2 days later resulted in
the largest marine oil spill in the history of the United States, which
resulted in the death of 11 workers.
On April 20, 2010, at 10:45 pm EST, a sudden explosion rocked
the Deepwater Horizon oil platform. The resulting ﬁre traveled so
fast that survivors stated they had less than 5 minutes to evacuate the
platform after the ﬁrst ﬁre alarm. The majority of the workers had
to evacuate the platform using the lifeboats from an auxiliary ship,
the M/V Damon B Bankston, a workboat assigned to the Deepwater
Horizon. The Bankston had been hired to service the large platform
oil rig. After the evacuation, 11 persons remained unaccounted for,
and rescue procedures were put into place.
The US Coast Guard launched a rescue operation. Two cutters,
four helicopters, and a rescue plane were involved in the search.
The Coast Guard conducted a 3-day search covering approximately

30
CHAPTER 4 Ecological Risk Assessment
5300 mi. They called off the search for the missing persons, conclud-
ing that the “reasonable expectations of survival” had passed. Ofﬁcials
concluded that the missing workers might have been near the area of
the blast and may not have been able to escape (7). After many inves-
tigations, it has been suggested that the cause of the explosion and
resulting ﬁre was a bubble of methane gas that escaped from the well
and rose up through the pipes, expanding and blowing out seals and
barriers as it rose before exploding on the oil rig.
The Deepwater Horizon had been tethered to the ocean ﬂoor by a
pipe used to extract oil called a riser. Because of the sinking platform,
the pipe was damaged. The damaged pipe began leaking tremendous
amount of oil in what is commonly known as a gusher. Huge quan-
tities of crude oil gushed from the riser pipe for approximately 3
months. A device called a blowout preventer (BOP) attached to the
pipe at the ocean ﬂoor level to prevent such an occurrence failed to
operate. Numerous attempts to manually operate the BOP also failed.
The rate of oil that was released from the riser soon became a hotly
debated issue. Real-time video feeds from the scene were played all
over the United States and in fact for the world to see. Eventually,
the resulting oil spill would cover almost 30,000 square miles of the
ocean, an area, depending on weather conditions, larger than the state
of South Carolina. The inaccuracies concerning the amount of oil
release from government responders conﬂicted with the estimates of
nongovernment scientists, who suggested that the oil release ﬁgures
were being underreported. Though, in reality, the exact quantity of
oil released was really not the issue. The real issue was how to clean
up the oil that was there and, subsequently, preventing future occur-
rences. According to the most reliable estimate, there was roughly ﬁve
million barrels of oil released by the Macondo well, with roughly 4.2
million barrels pouring into the waters of the Gulf of Mexico (7).
BP’s attempts to plug the leak had become a long and arduous task.
BP engineers’ initial plan was to use Remotely Operating Underwater
Vehicles (ROVs) to stop the leak by remotely activating the BOP.
The BOP was “a massive ﬁve story, 450 ton stack of shutoff valves,
rams, housings, tanks and hydraulic tubing that sits on top of the well”
(6, 7). As previously stated, the BOP failed to operate and speculation
was that gas hydrates entered and formed in the BOP after a methane
bubble rose up through the riser and blew out the seals and barriers
in the pipes, causing it to malfunction.

4.2 Deep Water Horizon
31
BP’s next and subsequent attempts had become exercises in
futility. On May 7, BP engineers decided they would use a “top hat”
or cofferdam to control the escaping oil from the broken riser. A
top hat is a containment dome that is maneuvered over a blowout to
collect the escaping oil so that it can be funneled through a pipe up to
an awaiting drill ship on the surface. Except this top hat was 98 tons
of steel. This project soon ﬂoundered because again, “the cofferdam
containment system failed, becoming iced up with methane hydrates
when hydrocarbons from the end of riser proved to have a higher gas
content than anticipated” (6). A second smaller top hat that weighed
a mere 2 tons, with the ability to be injected with alcohol to act as
an antifreeze to reduce the formation of gas hydrates was the next
course of action, but that plan was abandoned on May 12, when
engineers became unsure that the plan would work either. “The ﬁrst
signiﬁcant success at reducing the release of oil came on May 17,
2010 when robots inserted a four-inch diameter Riser Insertion Tube
Tool (RITT) into the Horizon’s riser, a twenty one-inch diameter pipe
between the well and the broken end of the riser on the seaﬂoor in
ﬁve-thousand feet of water” (7). The RITT is supposed to work like
a giant straw that siphons off the leaking oil and transports it to an
awaiting tanker on the surface. This attempt brought some success.
The company’s long-range plan was to initiate relief wells that
would intercept the bored out well at approximately 13,000 ft below
the ocean ﬂoor. After the relief wells were completed, heavy ﬂuids
and cement could be pumped down the damaged hole to kill the well,
this is referred to as a top kill. The only problem with this plan is it
would take a minimum of 90 days to accomplish. Thus, the reasoning
for the stopgaps put into play was to reduce the oil leak at the broken
riser early on after the explosion. On May 25, the RITT was disabled
for a “top kill” procedure scheduled for the following day. “On May
26, 2010, the U.S. government gave BP the approval to proceed with
a ‘top kill’ operation to stop the ﬂow of oil from the damaged well.
The procedure was intended to stop the ﬂow of oil and gas from the
damaged well and ultimately kill it by injecting heavy drilling ﬂuids
through the blowout preventer. On May 29, 2010, BP engineers said
that the ‘top kill’ technique had failed. Over thirty thousand barrels
of heavy mud was injected into the well in three attempts at rates of
up to 80 barrels a minute. Several different bridging materials had
been tried and still the operation did not overcome the ﬂow from the

32
CHAPTER 4 Ecological Risk Assessment
well” (7). After 86 days, and several failed attempts and efforts to seal
the leak, on July 15, BP succeeded in stopping the ﬂow of oil into the
Gulf of Mexico.
Much of the work on oil platforms has become automated in func-
tions below the waves and on the ocean ﬂoor. But human error still
manifests itself from time to time on these huge sea-going structures.
These drilling rigs are some of the largest moveable man-made struc-
tures in the world; as such they have become virtual cities aﬂoat
that will always have minor equipment failure and human error, not
to mention working in hurricane-prone environments. The Deepwater
Horizon was no different; it had a long history of spills, ﬁres, and
other mishaps before the Gulf oil spill in April 2010. There is even
a collision documented in its recent history. “Because vessels like
the Deepwater Horizon operate 24 hours a day, Coast Guard ofﬁcials
said minor equipment problems appear frequently. If these problems
are not corrected then such incidents could mushroom into bigger
concerns” (9). The agency responsible for investigating the safety of
offshore and gas operations is the US Department of the Interior’s
Minerals Management Service (MMS). The MMS had an extensive,
detailed inspection program to help ensure the safety of offshore oil
and gas operations. MMS inspectors are placed offshore on oil and
gas drilling rigs and production platforms to audit operator compliance
with extensive safety and environmental protection requirements.
The Deepwater Horizon had experienced many problems before.
• In 2005, the oil rig, still under contract with BP, “spilled 212
barrels of an oil based lubricant due to equipment failure and
human error. That spill was probably caused by not screwing
the pipe tightly enough and not adequately sealing the well with
cement, as well as a possible poor alignment of the rig, accord-
ing to records maintained by the federal Minerals Management
Service” (9). Actions were taken following that spill. The MMS
inspectors recommended increasing the amount of cement used
during this process and applying more torque when screwing in
its pipes.
• Also in 2005, a crane operator sparked a hazardous ﬁre onboard
Deep Horizon while refueling. His inattention caused diesel to
overﬂow, and a spark initiated a ﬁre on board. “In June 2003,
the rig ﬂoated off course in high seas, resulting in the release of

4.2 Deep Water Horizon
33
944 barrels of oil. MMS blamed bad weather and poor judgment
by the captain.”
• “A month later, equipment failure and high currents led to the
loss of an additional 74 barrels of oil” (9). These were just a
few of the mishaps that were reported, and investigated by the
MMS on the Deepwater Horizon before the blowout on April
2010.
The MMS, the caretaker of America’s federal lands and oceans,
and watchdog of the oil and gas drilling industry had come under
increasing criticism in the years before the Deepwater Horizon mishap.
“Investigators from the Interior Department’s inspector general’s ofﬁce
said more than a dozen employees, including the former director of
the oil royalty-in-kind program, took meals, ski trips, sports tickets
and golf outings from industry representatives. The report alleges that
the former director, Gregory W. Smith, also netted more than $30,000
from improper outside work” (10). Government ofﬁcials were also
alleged to have taken bribes so that they would direct the contracts
to favored clients. In the report, investigators said they “discovered
a culture of substance abuse and promiscuity” in which employees
accepted gratuities “with prodigious frequency” (10).
The responsibility for the initial cleanup was assumed by BP Oil
Corporation. Tony Haywood, Chief Executive Ofﬁcer (CEO), formally
verbalized to the American people that his company was taking full
responsibility for the disaster, “and where people can present legiti-
mate claims for damages we will honor them.” To augment the cost
of the cleanup, under the Federal Water Pollution Control Act, The
Oil Spill Liability Trust Fund (OSLTF), established in the Treasury
helped defer expenses of a federal response to oil pollution and to
help compensate claims for oil removal and damages as authorized by
the Oil Pollution Act (OPA) of 1990. “The OPA requires that respon-
sible parties pay the entire price tag for cleaning up after spills from
offshore drilling, including lost proﬁts, destroyed property and lost
tax revenue, but the statute caps their liability for economic damages
at $75 million. Aggressive collection efforts are consistent with the
‘polluter pays’ public policy underlying the OPA. BP and Transocean
have been named as responsible parties, although all claims are still
being processed centrally through the BP Corporation” (7).

34
CHAPTER 4 Ecological Risk Assessment
Many events led to the explosion on the Deepwater Horizon plat-
form. Numerous events took place that contributed to the disaster.
Working at great depths, 5000 ft or more, and pressures >2000 lb/in2
(13,789,514.56 Pa) should be reevaluated. Problems at these depths
have very real dangers and are unfamiliar. Most equipments used to
secure a well run amok have only been tested at depths half that of
the Deepwater Horizon’s. Guy Cantwell, a spokesman for the oil rig’s
owner Transocean Ltd, said that the Swiss-based company planned to
conduct its own investigation of what caused the explosion aboard the
Deepwater Horizon. “The industry is going to learn a lot from this.
That’s what happens in these kinds of disasters” he said, citing a 1988
explosion of the Piper Alpha rig in the North Sea and a 1979 blowout
of Mexico’s IXTOC I in the eastern Gulf (9). After the North Sea
incident in which 167 men were killed, Great Britain revamped its
safety requirements concerning deep water drilling. There is no doubt
that the same will happen in the United States. Numerous “well top-
ping” devices and associated installation accessories have already been
designed, built, and readied for future deployment, particularly where
gas hydrates are concerned. It seems as though deep water drilling is
here to stay.
At the time of writing of this book, we are only 1 year since this
event occurred. There is still much controversy as to the long-term
effects of the spill. Only time will tell what the long-term ecological
effects of the spill are.
4.3 LOVE CANAL
In 1920, Hooker Chemical (Hooker) had turned an area in Niagara
Falls into a municipal and chemical disposal site (11, 12). In
1953, the disposal site was ﬁlled and relatively modern methods
were applied to cover the disposal site. A thick layer of imper-
meable red clay sealed the dump. The idea was that the clay
would seal the site and prevent chemicals from leaking from the
landﬁll.
A city near the chemical disposal site wanted to buy it for urban
expansion. Despite the warnings made by Hooker, Niagara Falls
School Board eventually bought the site for the amount of $1. The
published literature on the event said that Hooker could not sell the

4.3 Love Canal
35
site for more money because they did not want to earn money off
the project. As part of the housing development process, the city
began to dig to develop a sewer. When construction crews dug up the
ground for the sewer, it damaged the red clay cap over the disposal
site. Blocks of homes and a school were built and the neighborhood
was named Love Canal.
Love Canal seemed like a normal, regular neighborhood. The only
thing that distinguished this neighborhood from others was the strange
chemical odors that often hung in the air and an unusual seepage
noticed by inhabitants in their basements and yards. Children in the
neighborhood often became sick. The families living in the Love Canal
housing area had a higher than normal rate of miscarriages and birth
defects (11).
Lois
Gibbs,
an
environmental
activist,
noticed
the
high
occurrence of illness and birth defects in the Love Canal area
and started documenting it. In 1978, newspapers revealed the
existence of the chemical waste disposal site in the Love Canal
area. Lois Gibbs started petitioning for closing the school located
near the disposal site. In August 1978, the effort was success-
ful
and
the NYS Health Department ordered
closing of
the
school.
When the waste site at Love Canal was assessed, the researchers
found over 130 lb of the highly toxic carcinogenic 2,3,7,8-tetra-
chlorodibenzo-p-dioxin (TCDD), a form of dioxin. A total of 20,000
tons of waste present in the landﬁll contained more than 248 different
types of chemicals. The waste consisted of pesticide residues and
chemical weapons research refuse, along with other organic and
inorganic compounds.
Owing to the breach of the clay cap, chemicals had entered homes,
sewers, yards, and waterways and it was decided that it was time for
the more than 900 families to be relocated away from the location.
President Carter provided Federal funds to move all the families to
a safer area. Hooker’s parent company was sued and settled for $20
million.
Even though most of the chemicals were not removed from the
chemical disposal site and despite protests by Gibbs’s organization,
some of the houses in Love Canal went up for sale some 20 years
later. The site was resealed and the surrounding area was cleaned and
declared safe. Today, a barbed wire fence isolates the worst area of

36
CHAPTER 4 Ecological Risk Assessment
the site from the areas that are not as contaminated. Hooker’s parent
company paid approximately $230 million to ﬁnance this cleanup.
They are now responsible for the management of the dumpsite. Today,
the Love Canal dumpsite is known as one of the major environmental
disasters of the century. Bacteria and other microbes might eventually
break down the organic materials into safer compounds, but this could
take hundreds, if not thousands of years. In the meantime, the area
is saddled with a mess. A natural or man-made disaster could again
release very nasty chemicals into the environment.
4.4 MINIMATA METHYLMERCURY
The Chisso Corporation ﬁrst opened a chemical factory in Minamata,
Japan, in 1908. Initially producing fertilizers, the factory followed the
nationwide expansion of Japan’s chemical industry, branching out into
production of acetylene, acetaldehyde, acetic acid, vinyl chloride, and
other chemicals. The Minamata factory became the most advanced
chemical company in Japan in the 1930s and 1940s. The waste prod-
ucts resulting from the manufacture of these chemicals were released
right into Minamata Bay. As with any chemical put into the envi-
ronment, these pollutants had an impact. Owing to the chemicals in
the environment, the ﬁsheries were damaged. The Chisso company
negotiated two separate compensation agreements with the ﬁshery
cooperative in the years of 1926 and 1943 (13).
The Chisso Minamata factory was very successful and it had a
very positive effect on the local economy (14). The area lacked other
industry and Chisso had great inﬂuence in Minamata. Over half of
the tax revenue of Minamata City authority came from Chisso and its
employees. Also, the company and its subsidiaries were responsible
for creating a quarter of all jobs in Minamata.
The Chisso Minamata factory ﬁrst started acetaldehyde production
in 1932. In the ﬁrst year, they produced 210 tons. Acetaldehyde is used
as a chemical intermediary in the production of numerous products,
for instance, vinyl. By 1951, production had jumped to 6000 tons/year
and reached a peak of 45,245 tons in 1960 (13). The Chisso factory’s
output amounted to between a quarter and a third of Japan’s total
acetaldehyde production. The chemical reaction used to produce the
acetaldehyde used mercury sulfate as a catalyst. A side reaction of the

4.4 Minimata Methylmercury
37
catalytic cycle led to the production of a small amount of an organic
mercury compound. This compound was methylmercury (15). This
very toxic compound was discharged into Minamata Bay from the
start of production in 1932 until 1968. Interesting enough, elemen-
tal mercury is poorly absorbed through the skin or through ingestion.
However, the vapors of elemental mercury are much more hazardous.
Methylmercury is very hazardous, as compared with elemental mer-
cury. In 1968, the production process was modiﬁed and mercury was
no longer used.
On April 21, 1956, a 5-year-old girl was examined at the Chisso
Corporation’s factory hospital in Minamata, Japan, a town on the
west coast of the southern island of Ky¯ush¯u. The symptoms the child
presented bafﬂed the physicians. The child had difﬁculty walking, dif-
ﬁculty speaking, and suffered convulsions. Two days later, her younger
sister also began to exhibit the same symptoms. This child was also
hospitalized. The girls’ mother informed doctors that her neighbor’s
daughter was also experiencing similar problems. After a house-to-
house investigation, eight other patients were found to be experiencing
the same symptoms and were hospitalized. On May 1, the hospital
director reported to the local public health ofﬁce the discovery of
an “epidemic of an unknown disease of the central nervous system,”
marking the ofﬁcial discovery of Minamata disease (16).
Medical researchers from the Kumamoto University began to
research the disorder. They found that the victims, often members of
the same family, were clustered in ﬁshing hamlets along the shore
of Minamata Bay. The staple food of victims was ﬁsh and shellﬁsh
from the bay. Local cats, which were fed scraps from the family
table, had similar symptoms and had died. This led the researchers
to believe that the outbreak was caused by some kind of food
poisoning. Contaminated ﬁsh and shellﬁsh were the prime suspects
in the investigation.
On November 4, the research group announced its initial ﬁndings:
“Minamata disease is rather considered to be poisoning by a heavy
metal . . . presumably it enters the human body mainly through ﬁsh
and shellﬁsh” (13).
The wastewater from the Chisso plant was immediately suspected
as the origin when the investigation identiﬁed a heavy metal as the
causal agent. The company’s own tests revealed that its wastewater
contained many heavy metals in high concentrations. These levels

38
CHAPTER 4 Ecological Risk Assessment
were sufﬁciently high to bring about serious environmental degrada-
tion. The metals included lead, mercury, manganese, arsenic, selenium,
thallium, and copper. All of these can be extremely toxic if released
into the environment. Identifying which particular poison was respon-
sible for the disease could be extremely difﬁcult. During the years of
1957 and 1958, many different theories were proposed for the cause of
the ailments. Initially, manganese was thought to be the causal agent
because it was found in large concentrations in ﬁsh and in the organs of
the deceased victims. Thallium, selenium, and a multiple contaminant
theory were also thought to be the toxic agent. In March 1958, visiting
British neurologist Douglas McAlpine suggested that the symptoms
shown by victims in Minamata resembled those of organic mercury
poisoning. From that point forward, the focus of the investigation
centered on mercury.
In February 1959, the distribution of mercury in Minamata Bay
was investigated. The results showed that large quantities of mercury
were detected in the aquatic environment: ﬁsh, shellﬁsh, and sludge
from the bay. At the entrance of the wastewater canal, there was
approximately 4.4 lb (2 kg) of mercury per ton of sediment. This
level would be economically viable to mine. The Chisso company did
set up a subsidiary to reclaim and sell the mercury recovered from
the sludge (13). Fifty years later, the legacy of Minamata Bay lives
on. Victims still receive payment for their injuries and methylmercury
still persists in the environment.
4.5 AGENT ORANGE
Agent Orange was the code name for one of the herbicides and defo-
liants used by the US military as part of its herbicidal warfare program
during the Vietnam War (16, 17). The campaign called Operation
Ranch Hand involved spraying the countryside with the chemicals
with the goal of defoliating the jungles and destroying crops.
Agent Orange was a 50:50 mixture of 2,4,5-T/2,4-D (17). It was
manufactured for the US Department of Defense primarily by Mon-
santo Corporation and Dow Chemical. The 2,4,5-T used to produce
Agent Orange was later discovered to be contaminated with 2,3,7,8-
tetrachlorodibenzodioxin, an extremely toxic dioxin compound. It was
given its name from the color of the orange-striped 55 US gal (200l)

4.5 Agent Orange
39
barrels that it was shipped in (17). It was the most widely used
herbicide during the war.
During the Vietnam War, between 1962 and 1971, the US military
sprayed nearly 20,000,000 US gal (75,700,000 l) of chemical herbi-
cides and defoliants in Vietnam, eastern Laos, and parts of Cambodia,
as part of the operation (16, 17).
Air Force records show that at least 6542 spraying missions took
place over the course of the operation (17). Approximately 12% of
the total area of South Vietnam had been sprayed with defoliating
chemicals by the end of the war. It is estimated that it was sprayed at
an average concentration of up to 13 times the recommended United
States Department of Agriculture (USDA) application rate for domes-
tic use. In South Vietnam, an estimated 10 million hectares of agricul-
tural land were affected (16). In some areas, TCDD concentrations in
soil and water were hundreds of times greater than the levels consid-
ered “safe” by the US EPA (16, 18). Overall, more than 20% of South
Vietnam’s forests were sprayed at least once over a 9-year period (18).
The legacy of the spraying during the war lives on. Approximately
17% of the forested land had been sprayed, and to this day, dioxins
contained in the chemicals remain in the soil. In many places, the
natural foliage has been replaced by invasive plant species. Animal
species diversity was also signiﬁcantly affected by the chemicals. For
instance, a Harvard biologist found 24 species of birds and 5 species
of mammals in a sprayed forest, while in two adjacent sections of
unsprayed forest, there were 145 and 170 species of birds and 30 and
55 species of mammals (19).
Movement of dioxins through the food web has resulted in bio-
concentration and biomagniﬁcation (20). The areas that were most
heavily contaminated with dioxins are the sites of former US air
bases where the chemicals were handled (17). The Vietnam Red Cross
reported as many as 3 million Vietnamese people have been affected
by Agent Orange, including at least 150,000 children born with birth
defects (21).
The problem with dioxins is that they are highly toxic, with no
safe levels of exposure, and the chemicals take a tremendous amount
of time to break down (22). This class of chemicals is produced as
a by-product during chemical production for legitimate use or when
chlorinated chemicals are burned. Vietnam is not the only place in the

40
CHAPTER 4 Ecological Risk Assessment
world where dioxins pose a threat. Seveso, Italy, also experienced an
environmental issue due to dioxin.
4.6 SEVESO, ITALY
During the middle of the day on July 10, 1976, an explosion occurred
in a 2,4,5-trichlorophenol (TCP) reactor in the ICMESA chemical
company in Meda, Italy (23–25). A cloud containing toxins escaped
into the atmosphere. The cloud contained high concentrations of
TCDD, a highly toxic form of dioxin. Downwind from the factory,
the dioxin cloud affected a densely populated area of 6-km length
and 1-km width. The toxins in the cloud immediately began killing
many animals. Seveso, a municipality that was close to the plant was
affected to a high degree. However, the dioxin cloud affected a total
of 11 communities.
Even though the media discusses Seveso when other major dis-
asters such as Bhopal and Chernobyl are discussed, the Seveso story
is different when it comes to handling the toxins (23). Polluted areas
within the affected areas were researched after the release and the
most severely contaminated soils were excavated and treated else-
where. Health effects experienced by the citizenry were immediately
recognized as a consequence of the chemical disaster. The victims
were compensated in relatively short time. A long-term plan of health
monitoring was also put into place. Seveso victims suffered from a
directly visible symptom known as chloracne and also from genetic
impairments (24).
The Seveso accident and the immediate reaction of authorities
led to the introduction of European regulation for the prevention and
control of heavy accidents involving toxic substances. This regulation
is now known as the Seveso Directive. This Directive is a central
guideline for European countries for managing industrial safety.
One of the most remarkable attributes of the Seveso accident was
that local and regional authorities had no idea the plant was a source
of chemical risk (23). The factory operated for more than 30 years
without a major incident. The public had no idea of the possibility
of an accident until it occurred in 1976. The European Directive was
created to ensure information concerning potential problems was avail-
able and to improve industrial safety. The Council of Ministers of the

4.8 Ecological Risk Assessment
41
European Committee adopted the Directive in 1982. It obligates appro-
priate safety measures, and also public information on major industrial
hazards, which is now known as the need to know principle (23).
4.7 RISK OF ECOLOGICAL DISASTERS
Unfortunately, the risk of another man-made ecological disaster looms
just around the corner. The dumping of the reactor cores from nuclear
powered ships into the Barrett’s Sea by the Russian military, the
other legacy nuclear sites in Russia, and other former Soviet Union
Republics poses a signiﬁcant potential threat to the environment. In
addition, many manufacturers in developing countries are displaying
the same lack of environmental concern that developed countries did
in the early to late 1900s. The resulting polluted bodies of water and
land have the potential to cause widespread environmental problems.
In addition, even well-run companies can have a process upset that
results in a chemical spill that could cause catastrophic harm to the
environment. New potential environmental problems could be released
into the environment at any point in time. For instance, there is little
research as to the impact of nanoparticles on the environment, yet
cosmetic companies are adding these to their products and each day
billions are washed down the drains. Only time will tell.
4.8 ECOLOGICAL RISK ASSESSMENT
Ecological risk assessment (ERA) is a process that is used to help
determine what risks are posed by an industry, government, or other
entity. It further provides a logical process to help eliminate or mitigate
such threats.
An ERA evaluates the potential adverse effects that human activ-
ities have on the living organisms (plants and animals) that make up
ecosystems. The risk assessment process provides a way to develop,
organize, and present scientiﬁc information so that it is relevant to
future and present environmental decisions. When conducted for a
particular place such as a forest or wetland, the ERA process can
be used to identify vulnerable and valued resources, prioritize data

42
CHAPTER 4 Ecological Risk Assessment
collection activity, and link human activities to their potential effects.
ERA results provide a basis for comparing different management
options and enabling decision makers and the public to make better
informed decisions about the management of ecological resources (26).
As EPA guidance states, ERAs are used to support many types of
management actions, including the regulation of hazardous waste sites,
industrial chemicals, and pesticides, or the management of watersheds
or other ecosystems affected by multiple nonchemical and chemical
stressors. The ERA process has several features that contribute to
effective environmental decision making (26):
• Through an iterative process, new information can be incorpo-
rated into risk assessments that can then be used to improve
environmental decision making.
• Risk assessments can be used to express changes in ecological
effects as a function of changes in exposure to stressors. This
capability may be particularly useful to decision makers, who
must evaluate tradeoffs, examine different alternatives, or deter-
mine the extent to which stressors must be reduced to achieve
a given outcome.
• Risk assessments explicitly evaluate uncertainty. Uncertainty
analysis describes the degree of conﬁdence in the assessment
and can help the risk manager focus research on those areas
that will lead to the greatest reductions in uncertainty.
• Risk assessments provide a basis for comparing, ranking, and
prioritizing risks. The results can also be used in cost-beneﬁt and
cost-effectiveness analyses that offer additional interpretation of
the effects of alternative management options.
• Risk assessments consider management goals and objectives
as well as scientiﬁc issues in developing assessment endpoints
and conceptual models during problem formulation. Such initial
planning activities help ensure that results will be useful to risk
managers.
The ERA approach contained in this book follows the EPA guide-
lines (26). However, a search of the literature does present many other
similar processes that can be used to assess ecological risk (27).

4.8 Ecological Risk Assessment
43
According to the EPA, the ERA process is based on two major
elements:
1. characterization of effects;
2. characterization of exposure.
These provide the focus for conducting the three phases of risk
assessment as illustrated in Figure 4.2:
1. problem formulation;
2. analysis;
3. risk characterization.
The three phases of risk assessment are enclosed by a dark solid
line.
Problem formulation is the ﬁrst phase. During problem formu-
lation, the purpose for the assessment is developed, the problem is
deﬁned, and a plan for analyzing and characterizing risk is also devel-
oped. Initial work in problem formulation includes the integration
of available information on potential sources of contaminates, poten-
tial stressors to the environment, potential effects, and ecosystem and
receptor characteristics. From this information, two products are gen-
erated: assessment endpoints and conceptual models. Either product
may be generated ﬁrst (the order depends on the type of risk assess-
ment), but both are needed to complete an analysis plan, the ﬁnal
product of problem formulation (26).
Analysis follows problem formulation. During the analysis phase,
data are evaluated to determine how exposure to potential environ-
mental stressors is likely to occur (characterization of exposure) and,
if an exposure was to occur, the potential and type of ecological effects
that could be expected (characterization of ecological effects). The ﬁrst
step in analysis is to determine the strengths and limitations of data
on potential exposures, potential effects, and ecosystem and receptor
characteristics. The products from these analyses are two proﬁles, one
for exposure and one for stressor response. These products provide
the basis for risk characterization (26, 28).
As part of the risk characterization phase, the potential exposure
and stressor–response proﬁles are integrated through the risk estima-
tion process. Risk characterization includes a summary of assumptions,

44
CHAPTER 4 Ecological Risk Assessment
Integrate available information
Problem
formulation
Assessment
end points
Conceptual
model
Analysis
plan
Characterization of exposure
A
n
a
l
y
s
i
s
Measures of
exposure
Exposure
analysis
Exposure
profile
Risk
estimation
Risk characterization
Stressor–
response
profile
Communicating results
Stressor–
response
profile
Ecological response
analysis
Measures of
ecosystem and
receptor
characterization
Measures of
effect
Iterate process as data becomes available
Characterization of ecological effects
FIGURE 4.2
ERA process ﬂow (26).

4.8 Ecological Risk Assessment
45
scientiﬁc uncertainties, and strengths and limitations of the analy-
ses. The ﬁnal product is a risk description in which the results of
the integration are presented, including an interpretation of ecological
adversity and descriptions of uncertainty and lines of evidence (26).
As with all risk assessments, ERAs are iterative in nature, as new
data become available. For instance, in some cases, the health effects
of chemicals are not fully elucidated until after the chemical or product
has been in use.
4.8.1 Example Ecological Risk Assessment
The following sections will provide an example of how an ERA can
be conducted. Note that all the information concerning organizations,
locations, and scenarios has been fabricated. The nature of the chem-
icals are factual, but the information provided is for illustration only
and not for reference. Also, this is not an exhaustive ERA, only a
partial, simple, example ERA.
Production Plant, Inc.
Production Plant, Inc. (PPI) has been in the widget manufacturing
business for 25 years. The product they manufacture is widget A (WA).
It is a stable product for the company and PPI plans for producing
these widgets for the foreseeable future. In this regard, PPI is planning
an expansion into a west coast state so that they can serve the Paciﬁc
Rim countries better. The plot of land they are proposing to build on
is approximately 20 acres and borders the Great River on one side,
and the land contains a small creek that only ﬂows during early winter
until mid-summer. Figure 4.3 shows the general layout of the property
and the proposed building location of the property. It also shows the
ﬂows of the waterways.
The proposed building site was previously used as farm land and
the farm-related chemicals found in the soil are shown in Table 4.1.
However, testing of Little Creek reveals that none of the farm
chemicals are leaching into the waterway under current conditions.
The land generally slopes toward the Great River. There is a 10-ft
elevation difference between the north end of the property and where
it borders the river. At the river’s edge, there is a 10-ft drop from the
property to the river for most of the year. During spring runoff, this

46
CHAPTER 4 Ecological Risk Assessment
North
Property boundary
Little
creek
Parking lot
Proposed plant
location
Utilities
Great river
Main highway
FIGURE 4.3
Proposed layout of PPI west coast location.
TABLE 4.1
Farm Chemicals Found in the Soil on Proposed Building Site
Product
Level detected
LC50
a (mg/l)
LD50
b (mg/kg)
Organophosphate A
50 ppb
0.1
10
Thiocarbamate C
1 ppm
20
25
Herbicide H
0.5 ppm
5
7
Fungicide X
10 ppb
100
120
aLC50 is lethal concentration for 50% of the population.
bLD50 is lethal dose to 50% of the population.
decreases to a 1- to 2-ft drop. The current vegetation on the land con-
sists of sage brush and nonnative grasses/weeds. Some bushy plants
are found by Little Creek. The current animals observed on the site
are widespread voles and gophers, raccoons near Little Creek, and
several bird species, including Great Horned Owls. The Great River
contains a wide range of ﬁshes, including Sturgeon, White Fish, Rain-
bow Trout, and Large Mouth Bass. There are also several mollusks and
crustaceans living in the river. Little Creek contains no ﬁsh because

4.8 Ecological Risk Assessment
47
it is dry for part of the year. Some frog species enter the creek during
wet periods.
The proposed land development process will entail digging up an
area of 140 ft × 100 ft for the proposed building’s foundation. The
soil will remain on site. The building will not have a basement, but the
soil will need to be removed to a depth of 2 ft so that the foundation
slab will be level. Therefore, approximately 28,000 ft3 of soil will be
disturbed.
The building process will consist of bringing in prepoured concrete
slabs and erecting in place. A further area of 5000 ft2 of land will
be disturbed by the erection equipment. An area of 180 ft × 100 ft
will also be paved for a parking lot. Therefore, ultimately, an area of
32,000 ft2 of the 86,000 total square footage of the land will no longer
be available to absorb rain water and snow melt.
The soil that will be excavated for the building site will be land-
scaped into rolling mounds on the south side of the building. The
mounds and land disturbed by the building process will be planted
with native vegetation once the building process is complete.
The utilities for the proposed factory will consist of electrical lines,
potable water, natural gas, and ethanol that will be supplied from a
neighboring plant. There will be three normal waste streams. These
are as follows:
• Normal sewage waste from the toilets and shower areas—
20,000 gal/day.
• Wash water containing biodegradable solvents and cleansers—
1000 gal/day.
• Process water containing ethanol, methanol, and trace amounts
of copper metal—500 gal/day. This will be stored in a tank for
pickup.
It is proposed that the normal sewage will be discharged into the
city system and that the wash water will be processed on site by means
of a digester. The processed waste water contains enough process
chemicals that a local company might be interested in obtaining it and
reprocessing it to remove the valuable contents.
The process for producing WA involves utilizing the chemicals
enlisted in Table 4.2.

48
CHAPTER 4 Ecological Risk Assessment
TABLE 4.2
Chemicals Used to Manufacture Widget A
Proposed quantity
Usage
Hazardous
Chemical
on site
volume
nature
LD50
a (mg/kg)
Copper
sulfate
1000 lb
10 lb/day
Moderately
toxic
300–470 (rat
and mammals)
Aluminum
chloride
2000 lb
100 lb/day
Corrosive and
moderately
toxic
380 (rat)
Ethanol
No onsite
storage—
supplied via
pipeline
20,000 gal/d
Flammable, low
toxicity
6300 (rabbit)
Methanol
1000 gal stored
on site
50 gal used/d
Flammable,
moderate to
low toxicity
5600 (rat)
aThese values are provided for example only and not for reference. Please consult the speciﬁc
material safety data sheet (MSDS) for correct toxicity data.
The Great River is 200 yards wide and 50 ft deep as it passes the
proposed plant site. It discharges into the Paciﬁc Ocean 100 mi below
the proposed site. A total of 100,000 people live below the plant site,
along the Great River.
Problem Formulation
As per the EPA ERA guidance, the ﬁrst step in the process of assessing
the impact of the proposed PPI is to develop the problem formulation.
In this regard, the potential sources of contaminants need to be iden-
tiﬁed. The potential sources of containments from the proposed PPI
include the following:
• Farm chemicals leaching out from the soil due to soil distur-
bance
• Spills from the following:
◦process upsets;
◦leaks from the ethanol supply line;
◦leaking process storage tanks and bins;
◦leaking process waste tank;

4.8 Ecological Risk Assessment
49
◦delivery trucks;
◦waste water digester;
◦cleaning chemical spills.
The assessment end points for this sample ERA that will be dis-
cussed are as follows:
• Reduction in species richness or abundance or increased fre-
quency of gross pathologies in ﬁsh communities resulting from
toxicity.
• Reduced richness or abundance of native plant species due to
the establishment of the plant.
• Reduction in abundance or production of terrestrial wildlife pop-
ulations resulting from toxicity.
The ecological assessment endpoints were selected based on meet-
ings that included representatives of the local EPA, PPI, state depart-
ment of environmental quality, and county planners.
1. The ﬁsh community in the Great River is considered to be
an appropriate endpoint community because it is ecologically
important and has a scale appropriate to the site.
2. The native plant life is considered to be an appropriate endpoint
community because of its ecological importance and due to the
amount of space the proposed PPI site will occupy.
3. The animal community is considered to be an appropriate end-
point community because it is ecologically important and due
to the potential number of small mammals and birds that might
be displaced by the PPI site.
This example ERA will consider the following measurement end
points:
• Fish
Single Chemical Toxicity Data. Chronic toxicity thresholds
for freshwater ﬁsh are expressed as chronic EC20s or
chronic values. These test end points correspond to the
assessment end points for this community.

50
CHAPTER 4 Ecological Risk Assessment
• Terrestrial Plants
Biological Survey Data. Quantitative plant survey data do
exist for the native and nonnative plants on the proposed
plant site.
• Terrestrial Animals
Single Chemical Toxicity Data. These include acute and
chronic toxicity thresholds for contaminants of concern
in birds and mammals with greater weight given to data
from long-term feeding studies with wildlife species.
Conceptual Model
Conceptual models are graphical representations of the relationships
among sources of contaminates, ambient media, and the endpoint
biota. Suter (27) has developed a complete guide on developing con-
ceptual models for ERAs. Figure 4.4 is an example conceptual model
that would be appropriate for the ERA for the proposed PPI.
In this ERA, the three areas that will be assessed are the impact
on ﬁsh in the Great River, the native plants growing on the pro-
posed PPI site and the area that will be disturbed by the construction
of the building and parking lot, and the animals inhabiting the PPI
property.
Analysis Plan
The analysis plan for the PPI ERA follows the problem formulation.
Therefore, in this example, the analysis plan will concern the ﬁsh in
the Great River, the terrestrial plants, and the terrestrial animals. These
analyses can be very involved and demanding. In this example, only
a ﬂavor of the types of analyses has been presented. In this regard, a
partial analysis of the risk to ﬁsh has been presented.
Risks to Fish
In this partial analysis, the risk to ﬁsh has been examined to a limited
degree. The ﬁsh are potentially exposed to contaminants in their nat-
ural environment, water. The contaminants in the water could come
from upstream of the proposed plant, from the 30 communities that
discharge treated water from sewage disposal plants, from farm runoff,

4.8 Ecological Risk Assessment
51
Contaminant
sources
Waste water,
ground water,
runoff, and
eroded soil
Surface
water
and
sediment
Aquatic biota
Aquatic
integrator
OU
Aquatic
integrator
OU
Small
herbivores
Small
omnivores
Terrestrial
integrator
OU
Small ground
invertibrates
Plants
Surface soil
Soil/litter
invertebrates
Source: Adapted from Suter (27).
FIGURE 4.4
Example conceptual model for proposed PPI.
from permitted and nonpermitted industrial plant discharge locations,
and from military bases. The contaminants that potentially harm ﬁsh
from the proposed PPI include the runoff from the ground that con-
tained the farm chemicals. It could come from a process upset and
a resulting spill of the industrial chemicals. It could come from a
spill from a delivery truck. Or it could come from things such as an
employee’s vehicle with a leaking fuel tank or oil leak. In a full ERA,
the following analyses would be performed:
• The aqueous chemical exposure model;

52
CHAPTER 4 Ecological Risk Assessment
• Fish chemical exposure burdens;
• Toxicity Tests. Determining how various exposures could affect
ﬁsh species.
These analyses can be quite involved and result in data that will
be used in the decision making concerning the design of the plant.
Because the proposed plant is to be located in an area that has had a
large amount of farm chemicals applied to the soil, the potential ﬁsh
body burden of farm chemicals in the ﬁsh population might already
be high. It might then be considered that water runoff from the pro-
posed plant would not pose a further signiﬁcant health risk to the
ﬁsh. However, since the construction of the plant will disrupt the soil,
there could be a much higher potential to release the chemicals into
the waterways via runoff.
As an example, the analysis found that the ﬁsh in the Great River
already carry a high body burden of farm chemicals, especially her-
bicide H. Addition of more chemicals into the river could not only
harm the ﬁsh but also harm birds that feed on the ﬁsh.
Risk Characterization
Risk characterization is the ﬁnal phase of an ERA. It is the culmina-
tion of the planning, problem formulation, and analysis of predicted
or observed adverse ecological effects related to the assessment end-
points. Completing risk characterization allows decision makers to
clarify the relationships between stressors, effects, and ecological enti-
ties and to reach conclusions regarding the occurrence of exposure and
the adversity of existing or anticipated effects. The analysts performing
the ERA use the results of the analysis phase to develop an estimate
of the risk posed to the ecological entities included in the assessment
endpoints identiﬁed in problem formulation, in this case, ﬁsh in the
Great River, terrestrial plants, and terrestrial animals. After estimat-
ing the risk, the assessor describes the risk estimate in the context of
the signiﬁcance of any adverse effects and lines of evidence support-
ing their likelihood. Finally, the analysts identify and summarize the
uncertainties, assumptions, and qualiﬁers in the risk assessment and
report the ﬁndings to decision makers.
Since this is a proposed plant, the ERA could be used to help
design the plant site to avoid or eliminate any threat found. For

4.9 Summary
53
instance, it is apparent that disrupting the soil has the potential of
releasing farm chemicals from soil. The analysis found that the ﬁsh
already carry a high body burden of these chemicals. Therefore, some-
thing needs to be done to eliminate or reduce the amount of chemicals
that could be released from the soil. How can this be accomplished?
Several things could be done. These include
• removing the soil from the site and placing it in an approved
landﬁll;
• laying a clay pad ﬁrst and then putting the excavated soil on the
pad and then placing a clay berm around the site to contain the
water runoff from the soil;
• placing a dike below the proposed site and collecting all the
water runoff and processing it to remove the pesticides.
A cost-beneﬁt analysis would need to be performed to help choose
the best solution. The ERA would then be updated to reﬂect the
changes in the plant design. For instance, if the proposed chemicals
were changed so that they posed less ecological risk then that aspect
of the ERA would be modiﬁed. An example of this would be the elim-
ination of the copper sulfate as a process chemical. A safer process
using something other than copper sulfate would signiﬁcantly reduce
the ecological risk posed by this plant. The goal, as with every risk
assessment, is to reduce the risk, in this case, the ecological risk.
4.9 SUMMARY
An ERA is a very systematic and very scientiﬁcally intensive analysis.
In this chapter, an abbreviated example was presented that provides
a ﬂavor of the types of analyses that are performed as a part of
an ERA. Experienced ERA analysts should be employed to perform
such an analysis to ensure every aspect of the ERA is performed
appropriately.

54
CHAPTER 4 Ecological Risk Assessment
REFERENCES
1. Biello D. The Origin of Oxygen in Earth’s Atmosphere: Scientiﬁc American.
2009. Available at http://www.scientiﬁcamerican.com/article.cfm?id=origin-of-
oxygen-in-atmosphere. Accessed 2011 Aug 22.
2. History of the Earth. Wikipedia. Available at http://en.wikipedia.org/wiki/History
of the Earth. Accessed 2011 Aug 19.
3. Raynolds RG. Roaming the rocky mountains and environs: geological ﬁeld trips.
Geological Society of America, Feb 28, 2008.
4. Yeast. 2011. Wikipedia. Available at http://en.wikipedia.org/wiki/Yeast. Accessed
2011 Aug.
5. Aiken K. 1998. Issues. uidaho.edu. Available at http://www.class.uidaho.edu/
kpgeorge/issues/bunkerhill/bunker.htm. Accessed 2011.
6. BP. Deepwater Horizon Accident Investigation Report (2010). Available at
http://www.bp.com/liveassets/bp_internet/globalbp/globalbp_uk_english/incident_
response/STAGING/local_assets/downloads_pdfs/Deepwater_Horizon_Accident_
Investigation_Report.pdf. Retrieved August 21, 2011.
7. Cleveland C. The Energy Watch. 2010. Available at http://www.theenergywatch.
com. Accessed 2010 Aug.
8. Deepwater Horizon. 2011. Wikipedia. Available at http://en.wikipedia.org/wiki/
DeepwaterHorizon. Accessed 2011 Aug.
9. Gulf oil spill. 2010, April. Nola.com. Available at http://www.nola.com/news/
gulf-oil-pill/index.ssf/2010/04/deepwaterhorizonrighadhist.html. Accessed 2011
Aug.
10. Report says oil agency ran amok. 2008. Washington post. Available at http://www.
washingtonpost.com/wp-dyn/content/article/2008/09/10/AR2008091001829.html.
Accessed 2011 Aug.
11. Gibbs LM, Nader R. Love Canal: the story continues. New Society Publishers;
Gabriola Island, BC Canada. April 1998.
12. Love Canal. 2011. Wikipedia. Available at http://en.wikipedia.org/wiki/Love
Canal. Accessed 2011 Aug.
13. Brown AM. 1992. Bitter sea: the human cost of Miniamata disease. Kosei Pub-
lishing Company; 1st English ed edition, Tokyo, Japan.
14. Minamata disease. 2011. Wikipedia. Available at http://en.wikipedia.org/wiki/
Minamatadisease. Accessed 2011 Aug.
15. USGS. Methylmercury deﬁnition page. 2011. Available at http://toxics.usgs.gov/
deﬁnitions/methylmercury.html. Accessed 2011 Aug 19.
16. Wilcox FA. Waiting for an army to die: the tragedy of Agent Orange. New York:
Seven Stories Press; 2011.
17. Agent Orange. ffrd.org. Available at http://ffrd.org/Voices/AgentOrange.htm.
Accessed 2011 Aug.
18. Stellman JM, Stellman SD, Christian R, Weber T, Tomasallo C. The extent and
patterns of usage of Agent Orange and other herbicides in Vietnam, Nature 2003;
422, 681–687.
19. Chiras DD. 2010. Environmental science. In: Bartlett J, editor. Environmental
Science. 8th ed. Burlington, MA. p. 499.

References
55
20. Vallero DA. Biomedical ethics for engineers: ethics and decision making in
biomedical and biosystem engineering. Waltham, MA: Academic Press; 2007.
21. Agent Orange: disease related to Agent Orange. Department of Veterans Affairs;
2010. Available at http://www.publichealth.va.gov/exposures/agentorange/disea
ses.asp. Accessed 2011 Aug 19.
22. Environmental Protection Agency. Dioxin. 2010. Available at http://cfpub.epa.
gov/ncea/CFM/nceaQFind.cfm?keyword=Dioxin. Accessed 2011 Sep.
23. Enzler S. Environmental disasters. Lenntech; 2006. Available at http://www.
lenntech.com/environmental-disasters.htmixzz1VtBe3lKH. Accessed 2011 Aug.
24. Hernan RE. This borrowed Earth: lessons from the ﬁfteen worst environmental
disasters around the world; 2010. New York: Palgrave Macmillan.
25. Sevesodisaster. 2011. Wikipedia. Available at http://en.wikipedia.org/wiki.seveso
disaster. Accessed 2011 Aug.
26. Environmental Protection Agency. Ecological risk assessment. 2011. Available at
http://www.epa.gov/superfund/programs/nrd/era.htm. Accessed 2011 Aug 19.
27. Suter G Guide for developing conceptual models for ecological risk assessments;
1996. Oak Ridge, TN: Oak Ridge National Laboratory, 21pp.
28. Suter GW. Ecological Risk Assessment. 2nd ed. Boca Raton, FL: CRC Press;
2006.

CHAPTER 5
Task Analysis
Techniques
This chapter provides a very high level overview of task analysis
techniques.
5.1 WHAT IS TASK ANALYSIS?
A task analysis is any process for assessing what a user does (task),
how the task is organized, and why it is done in a particular way and
using this information to design a new system or analyze an existing
system. Task analysis is an investigative process of the interaction of
operators and the equipment and/or machines they utilize. It is the pro-
cess of assessing and evaluating all observable tasks and then breaking
those tasks into functional units. These units allow for the evaluators
to develop design elements and appropriate training procedures and
identify potential hazards and risks.
Task analysis has been deﬁned as “the study of what an operator
(or team of operators) is required to do, in terms of actions and/or
cognitive processes, to achieve a system goal” (1). Approaches to
task analysis have been classiﬁed into three categories: normative,
descriptive, and formative. According to Vicente (2), normative
Risk Assessment: Tools, Techniques, and Their Applications, First Edition.
Lee T. Ostrom, Cheryl A. Wilhelmsen.
2012 John Wiley & Sons, Inc. Published 2012 by John Wiley & Sons, Inc.

5.2 Why A Task Analysis?
57
approaches “prescribe how a system should behave,” descriptive
approaches “describe how a system actually works in practice,”
and formative (also called predictive) approaches “specify the
requirements that must be satisﬁed so that the system could behave
in a new, desired way.” The nature of the work domain and the task
inﬂuence the type of analysis that is appropriate. Both the normative
and descriptive approaches are applicable to analyze existing systems,
while the formative approach can be applied to develop and design
a new system that will support work that has not been previously
done or to allow the work to be done in a new way. The normative
approach is appropriate for a very mechanical and predictable work
environment; as the work becomes more complex and unpredictable,
requiring more judgment, then the formative approach becomes a
better analysis tool (3).
5.2 WHY A TASK ANALYSIS?
Evaluation and design of a system using task analysis effectively inte-
grates the human element into the system design and/or operation.
In utilizing this analysis in system design, you effectively consider
the human as a component of the system to ensure efﬁcient and safe
operation. To be effective, the task analysis must look at the system
as comprising three interrelated components: human operator, equip-
ment, and environment. This systematic analysis of the tasks results in
equipment that is safer to use, easier to maintain, and operated using
effective procedures. Through a task analysis, you can build a concrete
and thorough description of the task and can attain a clear deﬁnition
of what other factors contribute to the system.
Task analysis provides a great deal of information and insight into
possible areas for performance improvement in systems, equipment,
and workers. It can also aid in identifying areas of waste, in terms
of time, resources, production, and dollars. A task analysis identiﬁes
weaknesses in the production process and in human performance. It
identiﬁes both what is working well and what is not working within the
current organization (4). And a task analysis can provide knowledge
of the tasks that the user wishes to perform. Therefore, it can be a
reference in which the value of the system functions and features can
be tested (3).

58
CHAPTER 5 Task Analysis Techniques
5.3 WHEN TO USE TASK ANALYSIS?
Ideally, a task analysis should be used when designing the system,
procedures, and training. Conducting a task analysis as part of the
design of any system or process should be one of the focuses. Those
systems that include humans as operators, maintainers, or support per-
sonnel should have each of the areas represented in the analysis phase
in order to incorporate the capabilities and limitations of the system.
This should be done in the analysis phase. Performing a task analysis
early in the design and with the user’s input helps to eliminate rework
down the road. It saves dollars and time.
The overall design process, as well as the task analysis, is con-
sidered iterative processes. In other words, design specs are presented
and the tasks needed to complete the job are incorporated into the
design process with continual changes until the ﬁnal design docu-
ments are approved. The user’s input is valuable because they are the
ones performing the tasks and have the knowledge as to the best ways
and resources to complete those tasks. There is always compromise
but the fact remains that the task analysis feeds into the design for a
successful overall system.
After the results of the task analysis are incorporated into the
system design, it is necessary to perform the analysis again to ensure
that the changes do not produce an unforeseen consequence. In
addition to providing useful information to incorporate into the design
of the system, task analysis information can be used to develop and
improve the personnel and training requirements. Task analysis can
be used to evaluate an existing system. If a new piece of equipment
is added or a problem has been identiﬁed, a task analysis can be used
to improve the system.
Task analyses are useful in many industries such as the auto indus-
try along with the maintenance of the automobiles, manufacturing and
assembly processes, business and ﬁnancial processes, medical indus-
try, and aviation industry.
5.4 TASK ANALYSIS PROCESS
There are hundreds of task analysis techniques with advantages and
disadvantages; therefore, you may want to use a mix of task analysis
methods during your assessment process.

5.4 Task Analysis Process
59
Step 1: Data Collection Information
Identifying the focus of the analysis helps in deciding what type of
information should be collected and how it should be gathered. Focus
on the system and what the results will be used for, such as in the
design of a new system, modifying an existing system, or developing
training.
Develop a list of tasks and positions associated with the overall
job. Provide descriptions of each task that characterize the task accord-
ing to issues of potential importance to the system, process, or job.
How complex the system may be and the eventual application of the
results will determine the level of analysis to be performed.
A system is composed of a job or jobs that ultimately lead to
a common goal. Those jobs can be broken into tasks that must be
performed in order to complete the job. The tasks can then be broken
down into steps or what is referred to as subtasks. Those steps need
to be performed in order to accomplish the overall task. Each task or
subtask can be deﬁned differently depending on the application. It is
very important that consistency be applied within a given analysis.
Table 5.1 lists the types of information that might be required in
order to complete a job.
Earlier we talked about the design and the analysis process as
being iterative. The data collected concerning the job and the tasks are
TABLE 5.1
Required Types of Information
Task information
Identify tasks involved in the process, system, or training
Identify subtasks involved in the tasks
Group and organize the subtasks involved in a task
Identify which subtasks have commonalities and are linked to each other
Identify the priority based on the criticality of the subtasks
Identify how frequently the subtasks occur under different conditions
Identify the sequence of the subtasks, depending on the occurrence
Identify which subtasks should be executed based on the event or a decision made
in a previous subtask or even task
Identify the goals or objectives for each subtask
Identify the knowledge the user has on how the system functions (i.e., tasks,
subtasks)

60
CHAPTER 5 Task Analysis Techniques
broken down into subtasks, and once reviewed, it might be necessary
to collect more details and information.
Step 2: Recording the Data
Some of the methods for collecting information in a task analysis are
shown in Table 5.2.
Document the information gathered utilizing the methods sug-
gested in Table 5.2. The data needs to be compiled in a format that
could be used to analyze and process the information. A simple and
straightforward format that can be used to organize and record the
collected data is a column format (Table 5.3).
Other examples of formats are hierarchical diagrams, operational
sequence diagrams, and timelines. Breaking down the tasks into sub-
tasks can be accomplished by the use of a hierarchical format. The
general tasks are listed at the top of the diagram. Detailed subtasks that
comprise each task are illustrated by branching off from the appropri-
ate task box (Fig. 5.1).
Timelines are used to deﬁne not only the sequence of steps that
make up the task but also the time that they occur and duration. This
TABLE 5.2
Methods of Collecting Information
Data collection methods
Observe and record information on the worker(s) performing the job. This can be
done as job shadowing or just taking notes as the worker (s) complete their duties.
Interview the worker(s) by asking questions about their job. These questions can be
open-ended questions or speciﬁc questions related to the speciﬁc task. The best
way to collect this information is to allow the worker(s) to remain anonymous.
This helps them to be more honest, knowing the management will not be able to
identify them speciﬁcally.
Review existing documentation such as standard operating procedures (SOPs), safety
and injury reports, training manuals, and any other previous surveys or analyses.
Checklists may be used to identify workplace concerns, human system interfaces,
ergonomics issues, environmental issues, and any other workplace concerns.
Surveys or questionnaires may be used to collect the worker(s) views of the system
or tasks.
Videotape or record the worker(s) performing the job or speciﬁc tasks involved in
completing the job.

5.4 Task Analysis Process
61
TABLE 5.3
Examples of Data Recording
Subtasks
Comments
Tools required
Feedback and displays
Remove
panel A
Panel A is 40 in from the
ground and is unobstructed.
The panel is removed by
unscrewing six-sheet metal
screws.
Phillips
screwdriver
Panel is clearly labeled
on both sides.
Close fuel
feed valves
B1 and B2
Fuel feed valves B1 and B2
are brass, quarter turn
valves. They are clearly
visible and located on
either side of the fuel ﬁlter.
None
The valves are open
when the stem are
in-line with the fuel
line and are closed
when the stem is
perpendicular to the
fuel line. The valves
are clearly labeled.
Remove fuel
ﬁlter B
The fuel ﬁlter is clear and is
mounted on the structure by
a spring clamp. The fuel
hoses slip over the nozzles
of the ﬁlter and are held by
spring clamps.
None
The spring clamps are
hand operated and snap
either open or closed.
Remove
fuel filter
Open panel A 
Close fuel feed
valves B1 and B2
Remove
fuel filter
Install new
fuel filter
Install fuel
filter
Open fuel
feed valves
B1 and B2
Close
panel A
Task level
steps
Subtasks
FIGURE 5.1
Hierarchical task analysis diagram.
presentation is particularly useful when there are several workers and
machines interacting and can help to identify when the worker and/or
machines are being overloaded or under loaded during the completion
of a task (Fig. 5.2).

62
CHAPTER 5 Task Analysis Techniques
Operator actions
Machine sequence
0
15
30
45
60
75 90
105
120
135
150
165
Load machine
Machine starts
Machine stops
Unload machine
Clean machine
FIGURE 5.2
Time line.
Symbol key
Operation
Transportation
Inspection
Delay
Storage
Operator A
moves part to
machine X–1
Machine X–1
mills part
Part
stored
iBin Z
Part
inspected
FIGURE 5.3
Operational sequence diagram.

References
63
TABLE 5.4
Analysis Techniques
Technique
Hierarchical Task Analysis is a broad approach used to represent the relationship
between the tasks and the subtasks. This is a useful approach in documenting the
system requirements as well as the ordering of the tasks.
Link Analysis identiﬁes the relationships between the components of a system and
represents the links between those components.
Operations Sequence Diagrams identiﬁes the order in which the tasks are performed
and identiﬁes the relations between the person, equipment and the time.
Time line Analysis is used to match up the process performance over time which
includes the task frequency, interactions with the other tasks, the worker(s), and
the duration of the task.
The use of operational sequence diagrams shows the sequence of
steps and the relationships between them in completing the task. This
method requires making a ﬂow chart of the task using standard sym-
bols to present the information (Fig. 5.3). Note the example provided
is very basic.
Step 3: Data Analysis
There are many ways to use the data obtained from task analyses.
Table 5.4 above lists some of the techniques that can be used with
task analysis data that can also aid in risk analyses. It is beyond the
scope of this guide to discuss these techniques beyond this table.
REFERENCES
1. Ainsworth BK. A guide to task analysis. London, England: Taylor and Francis;
1992.
2. Vicente KJ. Cognitive work analysis: toward safe, productive and healthy
computer-based work. Mahwah, NJ: Lawrence Erlbaum Associates; 1999.
3. Salvendy G. Handbook of human factors and ergonomics. 2nd ed. New York: John
Wiley & Sons, Inc.; 1997.
4. Group WE. Task analysis; 2007.

CHAPTER 6
Preliminary Hazards
Analysis
According to the Consumer Product Safety Commission (CPSC),
there are over 21,000 deaths and approximately 28 million injuries
associated with the 15,000 products under the commission’s jurisdic-
tion (1). The death of any child is an almost unbearable event for a
family, and an infant death is even more so. Infants die each year
because of poor product designs. Deaths associated with the designs
of cribs are one of the issues the CPSC deals with. One of the most
common causes of infant death due to crib design is when the infant
gets his or her head through the bars of the crib and then becomes
strangled when they cannot remove their head. This can happen one
of two ways: (i) an infant’s head is smaller than the opening or (ii)
an infant’s skull is still soft and can deform, which allows the head
to pass through the bars. Imagine the shock and horror of a young
parent when they discover that the infant they love has died because
its head passed through the bars of the crib and was subsequently
suffocated.
Manufacturers do not deliberately produce products that can hurt
children. However, when a product designer does not consider all the
possible consequences of their design, fatal accidents will happen.
Risk Assessment: Tools, Techniques, and Their Applications, First Edition.
Lee T. Ostrom, Cheryl A. Wilhelmsen.
2012 John Wiley & Sons, Inc. Published 2012 by John Wiley & Sons, Inc.

6.1 Description
65
Preliminary hazard analysis (PHA) will be the focus of this
chapter. Several applications of this tool will be explored. The partial
analysis of a piece of infant furniture will be one example.
6.1 DESCRIPTION
The PHA technique was developed by the US Army and is listed in
the US Military Standard System Safety Program Requirements (2).
PHAs have been proven to be cost effective in identifying hazards in
the beginning of a conceptual design phase. Because of its military
legacy, the PHA technique is sometimes used to review process areas
where energy can be released in an uncontrolled manner.
The main purpose of a PHA is to identify the hazardous states of
a system and its implications. In order to obtain maximum beneﬁt of
a PHA, it should occur as early as possible in the system’s life cycle.
Tasks and requirements involved in preparing a PHA should include
the following:
• Establish for purpose of the analysis
◦boundaries between the system, any system with which it
interacts, and the domain;
◦overall system structure and functionality.
• Identify
◦detailed list of hazards of the system based on preliminary
hazards list report and the requirements;
◦update hazards list;
◦accidents to the most practicable extent;
◦events of accident sequence and those that can be discounted;
◦record in hazards list.
• Assign
◦each accident a severity categorization and each accident
sequence a predicted qualitative/quantitative probability;
◦each hazard a preliminary random and systematic probability
target.
• Document
◦any safety features that are to be implemented during the
design and development phase.

66
CHAPTER 6 Preliminary Hazards Analysis
6.1.1 Process of Preliminary Hazards Analysis
Hazard analysis is usually performed during the early stages of design,
but it can also take place during different stages in the life cycle of
processes and facilities.
• For new processes and facilities, at the conceptual (work) design
phase, PHAs are performed to identify opportunities to eliminate
or reduce hazards. This is done before resources are committed
to engineering design and construction.
• During engineering design and construction, design hazards
analyses are performed to identify needed system changes
or process controls not identiﬁed at the conceptual design
phase.
• Before initial start-up of a new system or process, prestart-up,
operational readiness reviews are conducted to ensure that sys-
tems are in place to control all identiﬁed hazards.
• Process hazards analyses are conducted periodically during the
lifetime of operating facilities/processes, and every time a pro-
cess/facility undergoes signiﬁcant modiﬁcation. This is done to
identify any new hazards that may have occurred from a pro-
cess change and also to ensure that all hazards are adequately
controlled.
• When dealing with the decontamination and decommissioning
(D&D) and environmental restoration projects, hazard charac-
terizations are conducted to characterize hazards and, when
possible, to develop and deﬁne prioritized rankings for hazard
elimination.
• As in any process, especially during D&D, hazards can change
constantly, which requires hazards to be identiﬁed and con-
trolled.
The major goal of a PHA is the ability to identify and characterize
possible known hazards in the beginning of a design phase. Partial lists
of those hazards are listed below:

6.1 Description
67
• raw material, intermediate and ﬁnal products, and their reactiv-
ity;
• plant equipment;
• facility layout;
• operating environment;
• operational activities (testing, maintenance, etc.);
• interface among system components.
PHA identiﬁes known hazards such as explosions, radioactive
sources, pressure vessels or lines, toxic materials, high voltage,
machinery, and so on. PHA speciﬁes where each hazard will occur,
their signiﬁcance, and the method that will be used to eliminate the
hazards or how the associated risk will be controlled.
The probability of occurrence of an unexpected release of haz-
ardous energy or material (an accident) determines its credibility for
the purpose of PHA as follows:
Frequency of Occurrence (Per Year)
Less than10−6

Less than credible : events are expected not to
occur during the life cycle of the facility.
10−6 to 10−4



Credible and extremely unlikely : events will
probably not occur during the life
cycle of the facility.
10−4 to 10−2



Credible and unlikely : events may occur once
during the life cycle of the facility, for example,
natural phenomena, trained worker error.
10−2 to 10−1

Very likely: events may often occur, for example,
back strains, abrasions

68
CHAPTER 6 Preliminary Hazards Analysis
For most nonnuclear facilities, qualitative determinations of cred-
ibility are all that is necessary, while nuclear facilities require quanti-
tative determinations of credibility.
Quantitative measures are
0.1 −10 per year
0.001 −1 per year
0.0001 −0.001 per year
0.000001 −0.00001 per year
0.0000001 −0.000001 per year


Rare events
A PHA seeks to rank hazards in a qualitative measurement of the
worst potential consequence resulting from personnel error, environ-
mental conditions, design inadequacies, procedural deﬁciencies, and
system, subsystem and component failure, or malfunction. The cate-
gories are deﬁned as follows:
1. Class I Hazards: Negligible. A hazardous occurrence in which
the worst-case effects could cause less than minor injury, occu-
pational illness, or system damage.
2. Class II Hazards: Marginal effects. A hazardous occurrence in
which the worst-case effects could cause minor occupational
illness, or system damage.
3. Class III Hazards: Critical. A hazardous occurrence in which
the worst-case effects will cause severe (nondisabling) person-
nel injury, severe occupational illness, or major property or
system damage.
4. Class IV Hazards: Catastrophic. A hazardous occurrence in
which the worst-case effects will cause death, disabling per-
sonnel injury, or facility or system loss.
The most reliable solution when identifying PHAs is to eliminate
the source or cause of the hazards. If the source or cause cannot be
eliminated, the hazard should be reduced or redesigned as much as
possible, such as by
• redesigning, changing, or substituting equipment to remove the
sources (i.e., excessive temperature, noise, or pressure);

6.1 Description
69
• redesigning a process to possibly use less toxic chemicals;
• redesigning a workstation to relieve physical stress and remove
ergonomic hazards;
• designing general ventilation with sufﬁcient fresh outdoor air to
improve air quality and generally to provide a safe, healthful
atmosphere.
Once a PHA has been established a preliminary hazards list needs
to list details of the hazards and serve as the central reference that
documents the safety characteristics of the system being analyzed.
A hazards list should be kept for the entire life cycle of the system.
The structure of a hazards list should be as follows:
• Complete description of system and scope of use. This
should also include references that identify unique system
identiﬁers.
• Reference list to the system’s safety requirements.
• Accident severity categories, probability categories, equivalent
numerical probabilities, and accident risk classiﬁcation scheme
for the system.
There are numerous software programs speciﬁcally designed for
conducting PHAs. Standard word processing and spreadsheets can
assist with documenting the PHA results. Uses of ﬂowchart diagrams
and process modeling as discussed in Chapter 5, Task Analysis, are
also beneﬁcial when developing PHAs. Table 6.1 shows a hazard list,
and Table 6.2 presents a template for a PHA.
6.1.2 Hazard Class
Qualitative measure of signiﬁcance for the potential effect has already
been described in Section 6.1.1.
6.1.3 Examples of Hazardous Energy Sources
Table 6.3 lists some of the examples of hazardous energy sources.

TABLE 6.1
Example of Hazard List for Grill
Reference
Codes and
Accident
Relative likelihood
Accident risk
System
Subsystem
list
standards
categories
of occurrence
classiﬁcation
Propane
grill
Propane tank
Model 231
National Fire Protection
Association’s Pamphlet
58—LP-Gas Code, 1998
Edition (Code)
National Fire Protection
Association (NFPA) 58,
LP-Gas Code (2001 edition),
§§2.2.1.5 [DOT cylinders];
2.2.1.6 [Cylinder in ﬁre];
2.2.6.4 [Label]
29 Code of Federal Regulations
§1910.1200, Hazard
Communication
49 Code of Federal Regulations
§173.301 [Speciﬁcation,
Inspection]
Explosion
Valve Failure
Moderate
Moderate
Moderate
Low
Burner Assembly
—
American National Standards
Institute (ANSI) standard for
outdoor cooking gas appliances
Z21.58-1995 83EK
Uncontrolled
ﬂame
Low
Low
70

TABLE 6.2
Example of Hazard List
Event
Event
causing
causing
Accident
Hazardous
hazardous
Hazardous
potential
Potential
Hazard
Prevention
Subsystem
Mode
element
condition
condition
accident
accident
Effect
class
Measure
Hardware or
functional
element
being
analyzed
Applicable
system
phase or
mode of
operation
Hazardous
energy
system
Can be
personnel
error,
deﬁcient or
inadequate
design or
malfunction
Situation
that occurs
because of
a combina-
tion of
events
Undesired
event or
faults that
could cause
the
hazardous
condition
to become
the
identiﬁed
potential
accident
Any
potential
accident
that could
result
Possible
effects of
the
potential
accident
(list
everything
possible
and weed
out non
credible
items)
Qualitative
measure of
signiﬁcance
for the
potential
effect.
Class I:
Negligible
Class II:
Marginal
effects
Class III:
Critical
Class IV:
Catas-
trophic
Recommended
preventative
measures
(i.e.,
hardware,
procedures,
personnel)
71

72
CHAPTER 6 Preliminary Hazards Analysis
TABLE 6.3
Examples of Hazardous Energy Sources
Chemical energy
Electrical energy
Thermal energy
Corrosive materials
Capacitors
Steam
Flammable materials
Transformers
Fire
Toxic materials
Batteries
Friction
Reactive material
Exposed conductors
Chemical reaction
Oxygen deﬁciency
Static electricity
Spontaneous combustion
Carcinogens
Cryogenic materials
Ice, snow, wind, rain
Radiant energy
Kinetic energy
Pressure energy
Intense light
Pulley, belts, gears
Conﬁned gases
Lasers
Shears, sharp edges
Explosives
Ultraviolet
Pinch points
Noise
X-rays
Vehicles
Infrared sources
Mass in motion
Electron beam
Magnetic ﬁelds
Potential energy
Biological energy
RF ﬁelds
Falling
Pathogens (virus, bacteria, etc.)
Nuclear criticality
Falling objects
Allergens
High energy particles
Lifting
Tripping, slipping
Earthquakes
6.2 USING PROCESS HAZARD
FOR PROCEDURE DESIGN
PHA is most effectively used during the initial development of a
process and the procedures for performing that process. Also, it has
utility when updating/changing a process and its procedure. The fol-
lowing example illustrates its use for analyzing a maintenance pro-
cess/procedure.
6.2.1 Purpose of Process
Flushing an automobile cooling system.
6.2.2 Initial Basic Procedure Steps
1. Begin with the engine cold and ignition off. Remove the
radiator pressure cap.

6.2 Using Process Hazard for Procedure Design
73
2. Open the petcock at the bottom of the radiator and drain the
coolant into a bucket.
3. Close the petcock and ﬁll the radiator with water.
4. Start the engine and turn the heater control to hot. Add cooling
system cleaner and idle the engine for 30 min (or as per the
instructions on container).
5. Stop the engine and allow it to cool for 5 min. Drain the system.
6. Close the petcock, ﬁll the radiator with water, and let the engine
idle for 5 min.
7. Repeat step No. 5. Close the petcock.
8. Install new 50 : 50 mixture of water/ethylene glycol antifreeze/
coolant.
6.2.3 Analysis
Table 6.4 shows the analysis of the procedure. Note that in a PHA
the idea is to list the hazards and not to analyze each step in the
procedure. Failure mode and effect analysis and failure mode, effect,
and criticality analysis are better suited for analyzing the steps of the
procedure.
Note that there are two primary hazards associated with ﬂushing
the cooling system. They are the heat and pressure associated with
the hot coolant and the toxic nature of the coolant itself. The acci-
dent preventive measures in respect to the procedure will result in the
addition of two warnings and the substitution of ethylene glycol with
a nontoxic coolant.
6.2.4 Using the Results of the Analysis
The procedure has now been revised based on the ﬁndings from the
analysis. The new procedure reads as follows:
Warning: cooling system must be below 100 ◦F prior to draining.
1. Begin with the engine cold and ignition off. Remove the radi-
ator pressure cap.
Warning: ethylene glycol coolant is toxic and must be disposed of
in an appropriate manner.

TABLE 6.4
Analysis of Procedure
Event
Event
causing
causing
Accident
Hazardous
hazardous
Hazardous
potential
Potential
Hazard
preventive
Subsystem
Mode
element
condition
condition
accident
accident
Effect
class
measure
Cooling
system
Drain,
ﬂush, and
reﬁll
Heat and
pressure
Opening
radiator cap
or petcock
before
cooling
system has
sufﬁciently
cooled.
Release of
hot coolant,
water, and
steam
Mechanic
contacting
hot coolant,
water, and
steam.
Mechanic in
contact
with hot
coolant,
water, or
steam.
Severe burns Class III Ensure
cooling
system is
<100◦F
prior to
removing
radiator cap
in Step 1.
Ethylene
glycol
coolant
Not properly
storing
coolant.
Not
properly
disposing
of coolant.
Uncontrolled
toxic
material.
Child or
animal
could
consume
coolant.
Child or
animal
consuming
coolant.
Illness due
to ethylene
glycol
poisoning
or death
Class IV Replace
ethylene
glycol
coolant with
safer
chemicals.
74

6.3 Using PHA for Preliminary Product Design
75
2. Open the petcock at the bottom of the radiator and drain the
coolant into a bucket.
3. Close the petcock and ﬁll the radiator with water.
4. Start the engine and turn the heater control to hot. Add cooling
system cleaner and idle the engine for 30 min (or as per the
instructions on container).
Warning: cooling system must be below 100 ◦F prior to draining.
5. Stop the engine and allow it to cool for 5 min. Drain the system.
6. Close the petcock, ﬁll the radiator with water and let the engine
idle for 5 min.
7. Repeat step No. 5. Close the petcock.
8. Install new 50 : 50 mixture of water/nontoxic antifreeze/coolant.
6.3 USING PHA FOR PRELIMINARY
PRODUCT DESIGN
At the beginning of the chapter, we discussed the injuries that can
occur with poor design of infant furniture (3). We will now develop a
partial PHA for a proposed piece of infant furniture, a crib, using the
PHA technique.
The steps we use to do the analysis are as follows:
1. Determine function(s) of the crib.
2. Determine required speciﬁcations for the crib.
3. Determine major systems/subsystems of the crib.
4. Determine important components of each system/subsystem of
the crib.
5. Determine operating modes of the crib.
6. Determine hazards associated with each system/subsystem of
the crib in the identiﬁed operating modes.
7. Determine accident conditions.
8. Determine potential consequences.
9. Determine hazard class, if appropriate.
10. Determine preventative/mitigating measures.
To accomplish the PHA, we do the above steps in sequence.

76
CHAPTER 6 Preliminary Hazards Analysis
Step 1: Determine Functions of the Crib
The primary function of the crib is a place for the infant to sleep.
There are several secondary functions and/or unintended functions
that still can impact the safety of the crib. They can be things such as
a changing table or a storage area of baby toys.
Step 2: Determine Required/Critical
Speciﬁcations
The required/critical speciﬁcations of the crib can come from regula-
tions, case law, quality standards, previous accidents, manufacturing
requirements, style requirements, and company standards. These types
of requirements include items such as
• ability to hold up to 100 lb of bedding, toys, infant, and weight
of care giver as they lean against the device;
• safety;
• nontoxic coatings;
• nonﬂammable;
• water proof mattress.
Step 3: Determine Major Systems/Subsystems of
the Crib
The major system is the crib itself. The subsystems include
• legs;
• rails/end pieces;
• mattress;
• mattress support;
• side rail lowering mechanism;
• casters.
Some of these subsystems and know criteria are shown in
Figure 6.1.

6.3 Using PHA for Preliminary Product Design
77
Side rails
Critical width
infant’s head
can go
between bars
Mattress material
Crib finish
Nontoxic, low
risk of allergic
reaction, no
choking
hazards
Side rail
locking
mechanism
Side can drop
Nonflammable,
waterproof, nontoxic
FIGURE 6.1
Infant crib.
Step 4: Determine Important Components of
Each System/Subsystem
This can be a very tedious task and is where many errors can occur
in the design or safety analysis of a system. Just what is important?
It can be a critical bolt, screw, line of code, indicator light, and so
on. This is one of the reasons for the analysis in the ﬁrst place. In
a crib, it can be every part. The plastic sleeve on the top rail of the
sides can be critical, the side rail locking mechanism, the casters, the
mattress, and so on. In fact, the CPSC recently issued a bulletin on
the hazards of crib mattress supports (2). Therefore, in a device that
has been associated with so many deaths, a thorough analysis of all
components should be performed.
Step 5: Determine Operating Modes of the Crib
The operating modes, per se, are listed as follows:
• infant in crib;
• placing infant into crib;

TABLE 6.5
Partial PHA of Infant Crib
Event
Event
causing
causing
Accident
Hazardous
hazardous
Hazardous
potential
Potential
Hazard
preventive
Subsystem
Mode
element
condition
condition
accident
accident
Effect
class
measure
Side rails
Infant in
crib
Infant head
through
rails
The infant has
inadvertently
slipped
his/her head
through the
rails.
Potential
strangulation
Infant unable to
remove head
from between
rails and
becomes
exhausted
from struggle
Infant is
strangled
Death Class IV Ensure distance
between rails
is <1‰ infant
head width at
narrowest
point.
Infant
chews on
crib
Infant ingests
crib ﬁnish
Poisoning,
allergic
reaction, or
choking
Infant chews on
ﬁnish of rails
and ingests
ﬁnish or
material
Infant is
poisoned
by the
ﬁnish
Death
Use nontoxic
ﬁnish on the
crib that has a
low potential
for allergic
reaction.
Construct crib
from materials
that do not
create choking
hazards when
chewed on by
infants.
Infant
suffers
allergic
reaction
from ﬁnish
Rash
Infant
chokes on
pieces of
the crib
Death
78

References
79
• removing infant from crib;
• cleaning;
• assembly/disassembly.
The remaining steps are performed in sequence in relation to
the system, required/critical speciﬁcation, subsystem, component,
and operating mode as shown in Table 6.5 below. What we feel
is always the most critical step is doing something about the
hazards that are found. This is Step 10 in this process: determine
preventative/mitigating measures. In the case of a crib design, one
would want to eliminate any potential hazards. However, in other
industries, mitigating measures might be all that is needed.
The order of preference for hazard control is elimination
of the hazard by design or substituting a less hazardous mate-
rial/process/energy source is best. Next is using an engineering
control. These can be guards, lifting device in the case of ergonomic
hazards, or other mechanical barrier to the hazard. Next in preference
are administrative controls such as procedures, warnings, stay times in
radiation ﬁelds, and signage. Finally, personnel protective equipment
(PPE) is the least desired control for a hazard.
6.4 SUMMARY
PHA is a great tool for beginning to understand the hazards of a sys-
tem. In some cases, a PHA is all that is needed to analyze a simple
system. It is also the ﬁrst step in the hazard analysis of more com-
plicated systems. PHAs are usually done during the design phase of
a system. However, there are no rules that say it cannot be used after a
system has been put in place and used to eliminate hazards in existing
systems. As with any of the tools discussed in this book, determine the
hazards and then do something about them. The job is not complete
until the hazards are eliminated or mitigated. The analysis tools are a
means to an end, not the end themselves.
REFERENCES
1. Center for Chemical Process Safety (CCPS). Guidelines for Hazard Evaluation
Procedures, Second Edition with Worked Examples, Publication G18. New York:
American Institute of Chemical Engineers; 1992.

80
CHAPTER 6 Preliminary Hazards Analysis
2. Mil-Std-882B System Safety Program Requirements, Department of Defense
Washington, DC 20301, 1984, 1993.
3. Commission U. (c. n.d.) Available at http://www.cpsc.gov. Retrieved 2010, from
CPSC Warns Parents About Infant Strangulations Caused by Failure of Crib Hard-
ware document #5025: http://www.cpsc.gov/cpscpub/pubs/5025.html

CHAPTER 7
Primer on Probability
and Statistics
7.1 INTRODUCTION
Probability theory is thought to have evolved around 1654, with the
French mathematicians Blaise Pascal and Pierre de Fermat. The the-
ory was created in order to help gamblers in games of chance, such as
“Roulette,” “Dice,” “Craps,” and “Cards” (1). This chapter provides
only a brief overview of the concepts of probability. The readers are
referred to a text on probability and statistics for an in-depth discus-
sion.
Probability theory is an integral part of risk assessment. In fact,
they go hand in hand. Whether it is gambling at a casino or the
stock market or gambling with one’s life on the freeway, actions are
performed by people based on some knowledge or perception of the
probability of a successful/unsuccessful outcome. Many times risks
are taken and successful outcomes occur, and the common method of
explaining this is that the person was lucky or conversely people will
say they or someone else was unlucky if a negative outcome occurred.
Luck, of course, is deﬁned as a chance happening. Almost everyone
and every culture have some feeling or perception of luck. Most people
entering a casino hope they are lucky. They want a successful outcome.
If they are successful then they were lucky, if not, well Karma or bad
Risk Assessment: Tools, Techniques, and Their Applications, First Edition.
Lee T. Ostrom, Cheryl A. Wilhelmsen.
2012 John Wiley & Sons, Inc. Published 2012 by John Wiley & Sons, Inc.

82
CHAPTER 7 Primer on Probability and Statistics
luck or some other supernatural force caused them to be unlucky. This
superstitious view of luck or chance is different than viewing events
based on the probability they will occur.
All games of chance (luck) are based on some predeﬁned probabil-
ity of success and failure. All betting games at a casino have a house
edge. Card games, for instance, Blackjack or 21 has a house edge
of between 0.17 and 0.44% (2). A card game such as “Let it Ride,”
called a carnival game, has a house edge of approximately 3.5%.
Slot machines and other computer-based gambling devices can have
a house edge of 10%. This house edge can be governed by state law.
The dice game Craps is a good way of explaining the very basic
principles of probability and risk. In the game of Craps, a participant
rolls two dice. He/she is called the thrower. The casino ensures that
each die is fair. Meaning, the probability of any of the numbers on
the die coming up are equal. The die has six sides and, as we all
know, is numbered from one (1) to six (6). If the die is loaded or
one side has a higher probability of coming up then the casino can
be at a disadvantage. The Craps table is designed so the dice tumble
when they hit the table. This ensures randomness. Randomness plays
in favor of the casino. Throwers could manipulate the dice by sliding
them if the table did not contribute to the tumbling of the dice.
When a player walks up to a Craps table, they place a bet. There
are many bets that can be placed. Assume the player walks up to the
table when there is no number that is “On.” This will be explained
soon. The player lays down a bet of $10 on the pass line. At this
point the player is betting that one of two events will occur. Either
a seven (7) or an eleven (11) will be thrown and the player will be
paid even money ($10) or that the thrower will throw a four (4), ﬁve
(5), six (6), eight (8), nine (9), or ten (10). If the thrower throws
one of these numbers, no money is exchanged and a point number is
determined. The point number then becomes the “On” number. If the
thrower throws a two (2), three (3), or twelve (12), the player loses
his/her bet. This is a “Craps.” The thrower, whether it’s our player
or it’s another player, throws the dice. The probabilities of the 36
combinations of numbers coming up are shown in Table 7.1. These
probabilities or odds cannot be changed if the dice are fair and the
table provides a surface that ensures the dice will tumble.

7.1 Introduction
83
TABLE 7.1
Dice Probabilities
Probability
Outcome
Combined
Dice 1
Dice 2
Outcome
of event
group
Probability
1
1
2
1/36
2
1/36
1
2
3
1/36
3
2/36 or 1/18
2
1
3
1/36
2
2
4
1/36
4
3/36 or 1/12
1
3
4
1/36
3
1
4
1/36
2
3
5
1/36
5
4/36 or 1/9
3
2
5
1/36
1
4
5
1/36
4
1
5
1/36
2
4
6
1/36
6
5/36
4
2
6
1/36
1
5
6
1/36
5
1
6
1/36
3
3
6
1/36
1
6
7
1/36
7
6/36 or 1/6
6
1
7
1/36
2
5
7
1/36
5
2
7
1/36
3
4
7
1/36
4
3
7
1/36
2
6
8
1/36
8
5/36
6
2
8
1/36
3
5
8
1/36
5
3
8
1/36
4
4
8
1/36
3
6
9
1/36
9
4/36 or 1/9
6
3
9
1/36
4
5
9
1/36
5
4
9
1/36
4
6
10
1/36
10
3/36 or 1/12
6
4
10
1/36
5
5
10
1/36
5
6
11
1/36
11
2/36 or 1/18
6
5
11
1/36
6
6
12
1/36
12
1/36

84
CHAPTER 7 Primer on Probability and Statistics
TABLE 7.2
Probabilities of Dice Events
Approximate
Approximate
Event
Type of event
individual probability
combined probability
7
Advantageous to player
6/36 or 1/6 or 17%
22%
11
Advantageous to player
2/36 or 1/18 or 6%
4
Neutral event
3/36 or 1/12 or 8%
66%
5
Neutral event
4/36 or 1/9 or 11%
6
Neutral event
5/36 or 14%
8
Neutral event
5/36 or 14%
9
Neutral event
4/36 or 1/9 or 11%
10
Neutral event
3/36 or 1/12 or 8%
2
Advantageous to house
1/36 or 3%
12%
3
Advantageous to house
2/36 or 1/18 or 6%
12
Advantageous to house
1/36 or 3%
Table 7.2 shows the probabilities of the possible events at this
point in the game. For the simulation, assume on the ﬁrst throw a
six (6) comes up. This, as explained above, then becomes the point
number, and it is said to be “On.” The probability that a six (6) would
come up is 5/36 or approximately 14%. The probability that either a
seven (7) or an eleven (11) would come up is approximately 22%.
The probability that a two (2), three (3), or twelve (12) would come
up is approximately 12%.
So, what was the risk the player was taking? He risked his bet of
$10. He had a 12% probability of losing his $10. He had an approxi-
mately 22% probability of winning $10. There was an approximately
66% probability of a neutral event. Was there a risk beyond this bet?
No, the player can make a decision at this point to walk away from
the table. However, our player chooses to play one more time.
There are several betting options that can now occur, such as
placing a side bet on the point number behind the pass line, betting on
other numbers, and so on. Our player keeps his simple bet on the pass
line. He is now betting that a six (6) will come up. Table 7.3 shows
the probabilities of the possible events that our player is possibly
subjected to. At this point, the house has a 3% edge. To make a long
story short, at this point, a seven (7) is thrown and the player loses
his $10.

7.2 Probability Theory
85
TABLE 7.3
Probabilities of Second Round
Approximate
Approximate
Event
Type of event
individual probability
combined probability
6
Advantageous to player
5/36 or 14%
14%
2
Neutral event
1/36 or 3%
69%
3
Neutral event
2/36 or 1/18 or 6%
4
Neutral event
3/36 or 1/12 or 8%
5
Neutral event
4/36 or 1/9 or 11%
8
Neutral event
5/36 or 14%
9
Neutral event
4/36 or 1/9 or 11%
10
Neutral event
3/36 or 1/12 or 8%
11
Neutral event
2/36 or 1/18 or 6%
12
Neutral event
1/36 or 3%
7
Advantageous to house
6/36 or 1/6 or 17%
17%
7.2 PROBABILITY THEORY
Probability is deﬁned as the likelihood that the event will occur. Prob-
ability measures the uncertainty associated with the outcomes of a
random experiment. Some other terms or words used in place of
probability are chance, likelihood, uncertainty, and odds. Probability
is usually expressed as a fraction with the denominator represent-
ing the total number of ways things can occur and the numerator
representing the number of things that you are hoping will occur.
Probability is always a number between 0 and 1 or between 0% and
100%. Zero means that something cannot happen (impossible) and 1
or 100% means it is sure to happen. Another way to express this is
0 ≤P(A) ≤1, where A is the event. This expression is the ﬁrst basic
rule of probability (3).
There is also a rule that applies to two events, A and B, which
are mutually exclusive, that is, the two events cannot occur at the
same time. In this case, we express this as P(A or B) = P(A) + P(B).
Some textbooks will use mathematical symbols for the words “and”
and “or” and the expression would look like P(A ∪B) = P(A) ∩
P(B).
Although these rules of probability are extremely few and simple,
they are incredibly powerful in application. In order to understand

86
CHAPTER 7 Primer on Probability and Statistics
probability, you must know how many possible ways a thing can
happen. For instance, if you ﬂip a coin, there are two possible ways it
can land, either heads or tails. If we want to calculate the probability
of the coin landing on a head, we see that the head is one of two
possible ways so the probability is 1
2 or 0.5. The probabilities do not
change on the second or subsequent coin tosses. This is because the
events are independent. One event is not tied to a prior or future event.
As with the dice game, Craps, discussed above, every time one
tosses a coin or throws the dice, the probability of that individual event
occurring is the same. This concept is sometimes very difﬁcult for
people, whether engineers, politicians, or gamblers, to comprehend.
If a risk analysis of an airplane is performed and a probability of
the airplane breaking apart in mid-ﬂight is calculated as 1 event in
every 10,000 ﬂights, it does not mean the event will not occur on
its ﬁrst ﬂight. It has a 1 in 10,000 chance of occurring on the ﬁrst
and every subsequent ﬂight. The only time the probability changes
is if the assumptions on which the probability estimate was made
changes.
Let us reconsider the dice game. If a thrower throws two (2) sixes,
what is the probability on the next throw that double sixes will come
up again? The probability is the same, 1 out of 36. The two events are
independent. However, the probabilities change signiﬁcantly if one is
predicting the probability in advance that double sixes will be thrown
twice in a row. This will be explained in another section.
The probability of winning a major lottery is 1 out of 10,000,000.
A $1 ticket is purchased by our player. Our player wins. Next week
our player considers playing again. What is the probability our player
will win next week’s lottery? It is the same, 1 out of 10,000,000.
However, the probability of our player winning both lottery events is
1
10,000,000 ×
1
10,000,000
or
(1 × 10−7) × (1 × 10−7) = 1 × 10−14
This would be a very rare event, but since it is not “0,” it could
occur.

7.3 Combining Probabilities
87
7.3 COMBINING PROBABILITIES
When probabilities are combined, as with our lottery example above,
the probabilities are multiplied together to determine the ﬁnal proba-
bility for the combined events. The rules of Boolean Algebra are used
to combine probabilities (4).
The two most commonly used Boolean Algebra terms are the
logical “AND” and “OR.” When two probabilities are combined using
AND logic, as with our lottery example, the two probabilities are
multiplied together.
Winning the ﬁrst lottery AND winning the second lottery:
(1 × 10−7) × (1 × 10−7) = 1 × 10−14
In an accident analysis our events might appear something like:
A driver runs a red light AND the driver in the cross
street cannot stop.
Another example would be:
A terrorist gains access to a building AND is undetected.
A probability can be associated with the event and then combined to
develop an overall probability for the event.
The probability associated with a driver running a red light might
be 1/1000 red lights or 0.001. The probability associated with the
cross street driver not being able to stop might be 1/100 or 0.01.
Combining these two probabilities yields the overall probability of an
accident occurring because of the two events:
0.001 × 0.01 = 0.00001
The logical “OR” is used when several events can occur, but only
one of these events can lead to an outcome. For instance, an accident
can occur if any of the following events occur:
Fail to stop soon enough behind another vehicle–probability =
0.001;
Skid on ice and slide into another vehicle–probability = 0.0001;
Fail to yield when turning and another vehicle collides–probability
= 0.005.

88
CHAPTER 7 Primer on Probability and Statistics
In this case, the probabilities are added instead of multiplying
0.001 + 0.0001 + 0.005 = 0.0061
The structure of fault trees use these basic logical terms in their con-
struction. This will be explained in detail in Chapter 14.
7.4 CONDITIONAL PROBABILITY
Conditional probability is a probability whose sample space has been
limited to only those outcomes that fulﬁll a certain condition. It is
expressed as
P(A/B) = n(A ∩B)
which is the probability of event A given event B.
Events can be categorized into two main categories, single event
and compound event. A single event is when you only expect one
event to occur such as ﬂipping coins or rolling dice. It could even be
drawing a certain card, such as the ace of spades, from a deck of 52
cards.
A compound event is when two or more events or things are
happening. Frequently, we want to know the probability of two things
happening. In other words, one thing happens and then the other thing
happens. Since “and” means multiply, the probability of one event
must be multiplied by the probability of another event happening. An
example of this would be ﬂipping two heads in a row. The expression
would be 1
2 × 1
2 = 1
4.
Generally speaking, when working with probability, “and” means
to multiply and “or” means to add. However, you must be careful.
Here are three important rules for compound probabilities:
1. If A and B are independent, or the occurrence of one does not
affect the other, then P(A and B) = P(A) × (B).
2. If A and B are dependent, or the occurrence of one does affect
the other, then P(A and B) = P(A) × P(B) given that A has
occurred.
3. P(A or B) = P(A) + P(B) −P(A and B). [P(A and B) may
equal zero if A and B are “mutually exclusive” or that they
cannot happen simultaneously.

7.5 Probability Distributions
89
There are three basic terms of probability: experiment, sample
space, and event. An experiment is a process by which an observation,
or outcome, is obtained. A sample space means the set (S) of all
possible outcomes of an experiment. An event means any subset (E)
of the sample space. The events are subsets of S, but they are not
outcomes. When an event is certain, the E = S, like rolling a number
between 1 and 6 [E = 1, 2, 3, 4, 5, 6} = S], this is called a certain
event. If you were to say, the event to roll a 7, since the events are
subsets of the sample space and 7 is not contained in the sample set,
we say this is an impossible event. Obviously, only one die is used
for this event.
7.5 PROBABILITY DISTRIBUTIONS
The probabilities of events fall within one of several probability dis-
tributions. Using the Craps example again and using a bar chart to
display the distribution of events and their corresponding probabilities,
we see a very discrete distribution (Fig. 7.1).
A discrete distribution is just as it sounds, the values of the variable
are discrete. For instance, there is no such thing as a 7.5 on a pair of
dice. It is a value of 7 or 8. Same as with the probabilities of heads
or tails on a coin, they are discrete values.
Dice value
0.18
0.08
0.1
0.12
0.14
0.16
0.06
0.04
0.02
0
2.00
3.00
4.00
5.00
6.00
7.00
8.00
9.00
10.00 11.00 12.00
Probabilities
FIGURE 7.1
Discrete distribution.

90
CHAPTER 7 Primer on Probability and Statistics
Another example of a discrete distribution would be the probabil-
ities associated with a certain type of car being in a wreck. These are
discrete numbers associated with a certain type of vehicle. Common
types of discrete variables would be the
• number of times an electrical switch is thrown before failure;
• number of cycles of an airplane before failure of a component;
• number of demands on a ﬁre suppression system before failure;
• number of demands on a backup diesel generator before failure.
However, in some cases, depending on the range of values, a
discrete type distribution can appear continuous.
The alternative to discrete distributions is continuous distributions.
The number of hours drivers operate a vehicle between accidents can
range from some fraction of one to thousands of hours. The values
of the variable are continuous. Some common types of continuous
variables would be the:
• hours of operation of a pump, valve, piping, controller or other
mechanical piece of equipment before failure or between repairs;
• hours of operation of an airplane, ship, car, or train between
accidents or repairs.
Common types of continuous distributions used for risk assess-
ment are as follows:
• Normal distribution;
• Uniform distribution;
• Chi-square distribution;
• Weibull distribution;
• Poisson distribution;
• Exponential distribution.
Continuous probability distributions possess a probability density
function. As discussed above, a continuous random variable is the
one which can take a continuous range of values. For example, the
time between pump failures can have an inﬁnite number of values;

7.5 Probability Distributions
91
however, it has a probability zero because there are inﬁnitely many
other potential values.
The most important continuous probability distribution for risk
analysis and reliability engineering is the exponential distribution.
The exponential distribution is considered to be memoryless and is,
therefore, a good distribution to model the constant hazard rate of a
reliability bathtub curve (3).
The expected value or mean of a variable X that is exponentially
distributed is
E[X] = 1
λ
The variance of X is
Var[X] = 1
λ2
The median value is
m[X] = ln 2
λ
where λ is a rate parameter. When determining failure rates for com-
ponents the exponential distribution is one of the preferred continuous
distributions because an error factor can be calculated. The error fac-
tor is the ratio of the ninety-ﬁfth percentile to the median or ﬁftieth
percentile failure rate (4). For example, if the median value for a pump
failure is 2E–3 h and the ninety-ﬁfth percentile failure rate is 1.5E–2
the error factor is
1.5E −2
2E −3 = Error rate = 7.5
Other continuous probability distributions are used in risk assess-
ment, but are much more difﬁcult to apply for most common types
of applications. The Weibull distribution is the most widely used con-
tinuous distribution used in modeling reliability. In many cases, what
appears to be a continuous variable can be converted to a discrete
variable and can, therefore, be much more easily dealt with. Run time
hours on a pump can be binned into a set of predeﬁned bins, for
instance, low, medium, and high. As with any concept, the simpler
way information is presented, the more people will understand it and
be able to do something with it.

92
CHAPTER 7 Primer on Probability and Statistics
7.6 USING PROBABILITY
The following examples will explore more applications of probability.
Let us start by looking at ﬂipping a coin, which is a single event. The
total number of possible outcomes when ﬂipping a coin is 2, either
heads or tails. The two would be placed in the denominator. If we
wanted to know the probability that the outcome would be heads then
the expression would look like 1
2 or a 0.5% chance it would be heads.
Frequently, we want to know the probability of two things hap-
pening; in other words, one thing happens AND then another thing
happens (AND means multiply). You multiply the probability of one
thing happening by the probability of the other thing happening. What
is the probability of the following:
1. Flipping two heads in a row? [Answer: 1
2 × 1
2 = 1
4].
2. Flipping three heads in a row? [Answer: 1
2 × 1
2 × 1
2 = 1/6].
3. Flipping six heads in a row? [Answer 1
2 × 1
2 × 1
2 × 1
2 × 1
2 ×
1
2 = 1/64] (rolling one die twice is the same as rolling two
dice together once).
4. Drawing 2 aces? It depends on if you put the ﬁrst one back
before drawing the second. If you did put it back then it is 4/52
× 4/52 = 16/2704 or 1/169. If you did not put it back then
it is 4/52 × 3/51 = 12/2652 or 1/221. The second probability
is 3/51 because there are only 3 aces left and 51 cards left to
choose from after you successfully take out the ﬁrst ace. You
have a better chance of getting 2, aces if you put the ﬁrst one
back before drawing again.
5. Throwing an 11 using 2 dice? [Answer: 2/36 because there are
two ways of throwing an 11 {5 + 6 and 6 + 5}].
Now, look at one that is a little more complicated, such as rolling
two dice. There are 36 possible outcomes when rolling two dice. Using
Table 7.4, the probability that a three would be rolled could be deter-
mined.
There are two possible ways of rolling the two dice so that they
add up to three; therefore, the probability of rolling two dice so that
they add up to three is 2/36 or 1/18 chances.

7.6 Using Probability
93
TABLE 7.4
Dice Matrix
1
2
3
4
5
6
1
2
3
4
5
6
7
2
3
4
5
6
7
8
3
4
5
6
7
8
9
4
5
6
7
8
9
10
5
6
7
8
9
10
11
6
7
8
9
10
11
12
Using the matrix above, one could determine the possibility of
rolling two dice and rolling a 3 thrice in a row. The probability of
rolling a three was 1/9 as determined above. To ﬁnd the probability
of rolling a 3 thrice in a row, multiply 1/9 by itself thrice or 1/9 ×
1/9 × 1/9 = 1/729.
Suppose you have a bag containing 14 red marbles, 12 blue mar-
bles, and 18 green marbles.
1. What is the probability that if you pull out a marble at random
you get either a red or a blue marble? [P(red or blue)] There
are 44 total marbles and 26 chances to pull either a red or a
blue marble, so the probability is 26/44 or 13/22.
2. What is the probability of not getting a blue marble? [P(not
blue)] There are 44 total marbles and 32 are not blue, so the
probability is 32/44 or 8/11.
Suppose you roll two dice, a red one and a green one.
1. What is P(a sum of 4)? There are three ways of making a
sum of 4 (see matrix above) out of 36 possible sums, so the
probability is 3/36 or 1/12.
2. What is P(a sum of 5 or 6 or 7)? There are four ways of making
a sum of 5, ﬁve ways of making a sum of 6, and six ways of
making a sum of 7, so the probability of making a sum of 5 or
6 or 7 is 4/36 + 5/36 + 6/36 = 15/36 or 5/12.
When a polling agency says its conﬁdence level is 95%, it is
saying that the probability of its numbers being correct is 0.95. What

94
CHAPTER 7 Primer on Probability and Statistics
is the probability their numbers are wrong? (100% −95%) or (1 −
0.95) = 5% or 0.05.
An art class has 13 right-handers and 7 left-handers.
1. What is the probability that a student chosen at random from
the class is right-handed? There are 20 total students, so the
probability that the student would be a right-hander is 13/20.
2. If three students are chosen, and the ﬁrst two are right-handers,
what is the probability that the third is also a right-hander? Two
have already been picked and that leaves 18 students to choose
the third student from and only 11 are right-handed since two
have been chosen, so the probability that the student would be
a right-hander is 11/18.
Tree diagrams can help you to visualize a probability problem such
as ﬂipping a coin or rolling dice. The diagram helps you to visualize a
probability problem. Suppose you are going to ﬂip a coin three times.
You could see a tree diagram to visualize all of the possibilities. An
example of this is in Figure 7.2.
So, one of the possibilities would be T, H, H. There are eight
possible combinations when ﬂipping a coin three times in a row.
1. What is the probability of getting three heads in a row (H, H,
H)? There is only one branch that produces three heads in a
row (H, H, H), so the probability is 1/8.
2. What is the probability of getting two heads and one tail (in
any order)? There are three branches that have H, H, T (in any
order), so the probability is 3/8.
What is the probability of being dealt two hearts? Solve this prob-
lem by using Figure 7.3, a tree diagram.
To solve, multiply the probabilities along one whole “limb.” So
multiplying along the top limb, we have 13/52 × 12/51 = 0.06 or 6%.
With a tree diagram we can see other possible outcomes. For example,
looking along the very bottom “limb” the probability of not getting a
heart at all is 39/52 × 38/51 = 0.56 or 56%.
To summarize tree diagrams for probability
1. Conditional probabilities start at their condition.

7.7 Summary
95
H
H
H
H
T
T
T
T
H
H
H
T
T
T
FIGURE 7.2
Tree diagrams of coin ﬂip.
2. Nonconditional probabilities start at the beginning of the tree.
3. Multiply when moving horizontally across a limb.
4. Add when moving vertically from limb to limb.
7.7 SUMMARY
Probability theory is an integral part of risk assessment. Games of
chance such as Craps and card games that have discrete probabili-
ties associated with various outcomes are a good way of explaining
probability. Real life events such as car accident potentials might have

96
CHAPTER 7 Primer on Probability and Statistics
Not a heart
Heart
Heart
Heart
Not a heart
Not a heart
Probability of being
dealt two hearts
13/52
39/52
12/51
39/51
13/51
38/51
FIGURE 7.3
Tree diagram of being dealt two hearts.
either a discrete probability associated with them or continuous. For
most common types of risk assessments, however, the use of a discrete
probability is probably advised so that it is more understandable. The
readers are referred to a text on probability and statistics for a more
in-depth understanding on these topics.
REFERENCES
1. Laplace PS. Analytical theory of probability. Paris.
2. Available at Wizard of Odds: www.wizardofodds.com. Retrieved 2010 Dec 28.
3. Ross SM. 2009. First Course in Probability, 8th ed., New Jersey: Prentice Hall.
4. U.S. NRC. Available at http://www.nrc.gov/reading-rm/doc-collections/nuregs/
staff/sr1855/v1/sr1855v1.pdf. Retrieved 2010 Dec 31.

CHAPTER 8
Developing Probabilities
8.1 RISK ASSESSMENT DATA
8.1.1 Introduction
Finding data to populate risk assessments can sometimes be problem-
atic. For example, an analyst is in the process of performing a failure
mode and effect analysis on a new, complicated system. When the
analyst begins to populate the data tables with failure rates for vari-
ous failure modes, he/she hits a brick wall. No failure rate data. The
question becomes what to do next? Do a SWAG (“scientiﬁc” wild ass
guess), make it up (worse than a SWAG), or ﬁnd a subject matter
expert (SME) and have that person do a SWAG?
Data are available in many forms for hardware failure rates and for
human error probabilities (HEPs), and this chapter provides examples
of how to ﬁnd data and/or how to develop it.
8.1.2 Hardware Failure Rate Data
In the truest sense, hardware failure data are much easier to obtain,
than are HEPs. In many cases, failure rate data are available at the sys-
tem as well as the subsystem and component levels. Hardware failure
rate data can be obtained from the manufacture, historical data, gov-
ernment and military handbooks, and accident data or can be generated
from testing by the user (1).
Risk Assessment: Tools, Techniques, and Their Applications, First Edition.
Lee T. Ostrom, Cheryl A. Wilhelmsen.
2012 John Wiley & Sons, Inc. Published 2012 by John Wiley & Sons, Inc.

98
CHAPTER 8 Developing Probabilities
8.1.3 Manufacture
Failure rate data can be obtained from the manufacturer for certain
pieces of industrial equipment, for instance, pumps, valves, motors,
electrical panels, controllers, and even for components such as chips,
diodes, and resistors. These data are usually supplied on a product
data sheet or can be requested from the manufacture. In addition,
the product data sheets will sometimes supply failure modes for the
equipment. For instance, does a valve fail open or closed, and does a
control panel fail so that no spurious signal is sent?
8.1.4 Historical Data
Many organizations maintain internal databases of failure information
on the devices or systems that they produce, which can be used to
calculate failure rates for those devices or systems. For new devices
or systems that are similar in design and manufacture, the historical
data for similar devices or systems can serve as a useful estimate.
8.1.5 Government and Military Handbooks
The Reliability Information Analysis Center (RIAC) compiles data and
develops products for use in assessing the reliability of components
and their failure modes (2). Handbooks of failure rate data for various
components are available from government and commercial sources.
MIL-HDBK-217F, “Reliability Prediction of Electronic Equipment,”
is a military standard that provides failure rate data for many military
electronic components (MIL-HDBK-217F).
National laboratories have also carried out studies on the reliability
and failure modes of various systems and components in specialized
applications. For instance, the Idaho National Laboratory has con-
ducted numerous studies on the reliability of components for use in
fusion test reactors (3). Table 8.1 shows the types of data available
from these studies.
The error factor has been discussed in Chapter 7.
8.1.6 Commercial Data Sources
There are many commercially available failure rate data sources.
Loss prevention handbooks, insurance companies, data mining

8.1 Risk Assessment Data
99
TABLE 8.1
Example Failure Rate Data
Component
Failure mode
Failure rate
Error factor
Blowout panels
Fail on demand
1E-03/demand
Upper bound
Blowout panels
Leakage
1E-07/h
10
Blowout panels
Rupture
1E-09/h
10
Vent duct
Leakage
1E-11/m-h
10
Wet gas scrubber
Fail to operate
1E-02/demand
Upper bound
Wire mesh scrubber
Fail to function
1E-05/h
10
Gravel bed scrubber
Plugging
3E-06/h
10
Gravel bed scrubber
Internal rupture
5E-07/h
10
Gravel bed scrubber
Internal leakage
3E-06/h
10
Air dryer(refrigeration)
Fail to start
1E-02/demand
10
Air dryer (refrigeration)
Fail to operate
3E-05/h
10
HEPA ﬁlter
Plugging
3E-06/h
10
HEPA ﬁlter
Leakage
3E-06/h
10
HEPA ﬁlter
Rupture
5E-07/h
10
Source: Excerpted from EXT-98-00892 (MIL-HDBK-217F).
organizations, and trade organizations can be sources of data for use
and inclusion in risk assessments (4).
8.1.7 Operational Data and Testing
Within an organization, failure rate data can be calculated from failures
of components within a facility or multiple facilities. Accurate records
as to the failure need to be kept for these data to be useful. The types
of data that aid in a risk assessment would be as follows:
• How many hours, demands, or length of travel was on the device
when it failed?
• What other factors were involved, such as
◦environment: hot, cold, wet, or dry;
◦periodic maintenance performed or not;
◦how was the system operated?
Failures that lead to or are caused by accidents can aid in deter-
mining failure rates as well.

100
CHAPTER 8 Developing Probabilities
The most accurate source of data is to test samples of the actual
devices or systems in order to generate failure data. This is often pro-
hibitively expensive or impractical, so that the previous data sources
are often used instead.
8.1.8 Failure Rate Calculations
The failure rate of a system usually depends on time, with the rate
varying over the life cycle of the system. Aircraft structure is an excel-
lent example of a system that fails over time. A new aircraft structure,
whether aluminum or composite, has not been stressed. However, over
time and many thousands of cycles, an aircraft structure can become
weakened and can develop fatigue cracks.
Aloha Airlines Flight 243 had a catastrophic decompression and
a portion of the fuselage ripped off 23 min into a ﬂight from Hilo to
Honolulu, HI, on April 28, 1988 (5). The aircraft had more than 89,000
ﬂight cycles. The estimated life of the aircraft skin was approximately
75,000 cycles.
Table 8.2 shows failure data for a system. Failure rates can be eas-
ily calculated from such data. In fact, several types of failure rates can
be calculated. A more qualitative rate can be determined by binning the
failures into one of several bins, high number of hours (long-life com-
ponents), medium number of hours (medium life components), and
low number of hours (short-life components). In this case, the analyst
decides what constitutes the cutoffs for these values. These types of
rates are useful for analyses such as a failure mode and effect analysis
that have been discussed in this chapter or to provide the management
a rough order of magnitude estimate of the life of a component.
The ﬁrst step in this process is to construct the bins. The bins
for this example are shown in Figure 8.1. The components are binned
according to their failures. Those components that did not fail are
excluded from the bins. Using this method provides a great amount
of information, such as eight components had a long life, nine had a
medium life, and three had a short life. Added to this can be per-
formance data. Maybe the components that had a short life were
subjected to an adverse environment or were not maintained properly.
Table 8.3 shows the binning of the data by operating temperature and
the associated failure rates. Workers, management, and lay people can
sometimes understand a qualitative analysis such as this, rather than

8.1 Risk Assessment Data
101
TABLE 8.2
Hardware Failure Data
Component
Hours
Failure
Operating temperature (◦F)
1
12,000
Yes
70–100
2
8,000
No
70–100
3
3,000
Yes
121–130
4
11,000
Yes
101–120
5
7,000
Yes
121–130
6
6,500
Yes
121–130
7
9,300
Yes
70–100
8
12,400
No
70–100
9
1,200
Yes
140+
10
4,600
Yes
101–120
11
8,900
No
70–100
12
7,100
Yes
70–100
13
4,300
Yes
121–130
14
6,900
Yes
101–120
15
8,500
Yes
70–100
16
2,800
Yes
121–130
17
4,100
Yes
121–130
18
9,800
Yes
70–100
19
3,900
Yes
101–120
20
8,700
Yes
70–100
21
9,200
Yes
70–100
22
9,600
Yes
70–100
23
800
Yes
140+
a hard, cold number. In this example, it is evident that reducing the
operating temperature increases the life of the component.
The operating hours for the components are totaled and then
divided by the number of components to calculate a quantitative esti-
mate of the failure rate. In this example, there are 20 failures in
130,300 h, so the estimated failure rate is given by
20
130,300 = λ = 1.54E −4 failures/h
The inverse of this is the mean time between failures (MTBFs).
MTBF = 1
λ =
1
1.54E −4 = 6494 h

102
CHAPTER 8 Developing Probabilities
Component
9
16
23
1,200
2,800
800
Short- life
components
less than
3,000 h
Medium- life
components
3,000 – 7,999 h
Long- life
components
8,000+ h
Hours
Component
3
5
6
10
12
13
14
17
19
3,000
1
4
7
15
18
20
21
22
12,000
11,000
9,300
8,500
9,800
8,700
9,200
9,600
7,000
6,500
4,600
7,100
4,300
6,900
4,100
3,900
Hours
Component Hours
FIGURE 8.1
Binning failures.
TABLE 8.3
Binning of the Data
Operating temperatures (◦F)
70–100
101–120
121–140
140+
Failure rate (per hour)
1.08E-4
1.5E-4
2.1E-4
1E-3
MTBF (h)
9275
6600
4616
1000
N
8
4
6
2
MTBF is often used instead of the failure rate. The MTBF is an
important system parameter in systems where failure rate needs to
be managed, in particular for safety systems. The MTBF appears fre-
quently in the engineering design requirements and governs frequency
of required system maintenance and inspections (1). MTBF assumes
the unit can be repaired. MTBF is calculated directly by dividing the
total operating hours by the total number of failures, as shown below:
MTBF = θ = T
N
where
θ = MTBF,
T = is the total time, and
N = is the number of units.

8.1 Risk Assessment Data
103
Another useful term is mean time to failure (MTTF). MTTF
assumes that all systems fail in the same way. MTTF is calculated by
dividing the total amount of time of all components by the number
of units under test:
MTTF = γ = T
N
where
γ = MTTF,
T = is the total time, and
N = is the number of units under test.
8.1.9 Accident Data
On January 28, 1986, the space shuttle Challenger lifted off from
Cape Canaveral, and 73 s into the ﬂight, the space craft blew up. This
accident has been analyzed in great depth and it is not the intention
here to provide an analysis of the event. However, Table 8.4 lists some
interesting facts that help calibrate us concerning accident probabilities
before data about the shuttle program are presented.
The accident facts concerning the space shuttle program are as
follows.
Some studies place the probability that an accident similar to the
Challenger accident, where the vehicle is destroyed on launch, occur-
ring is 1 in 556.
The probability of an accident occurring during the entire mission
is 1 in 265. However, a study in the 1970s placed the odds of losing a
space shuttle as 1 in 50. The launch of the Challenger on January 28
was the 25th shuttle mission. After that accident, the actual probability
of losing a launch vehicle was 1 in 25 missions. Subsequent to the
accident, there were 87 successful launches. At this point, the risk
of losing a space shuttle fell to 1 in 113 launches. On January 16,
2003, the space shuttle Columbia failed on reentry. The probability
for a shuttle accident then raised to 2 in 113 missions. However,
the probability of losing a space shuttle on launch remained 1 in
113 missions and the probability of losing a space shuttle on reentry
became 1 in 113 missions. As of this writing, there have been 132
space shuttle ﬂights and 2 failures. However, this does not tell the

104
CHAPTER 8 Developing Probabilities
TABLE 8.4
Accident Probabilities
Accident type
Probability
Injury from ﬁreworks
5.1E-5
Injury from shaving
1.5E-4
Injury from using a chain saw
2.1E-4
Injury from mowing the lawn
2.7E-4
Fatally slipping in bath or shower
8.8E-4
Drowning in a bathtub
1.4E-6
Being killed sometime in the next year in any sort of
transportation accident
0.012
Being killed in any sort of nontransportation accident
0.014
Being killed by lightning
4.3E-7
Being murdered
5.5E-5
Getting away with murder
0.5
Dying from any kind of fall
5.0E-5
Dying from accidental drowning
1.2E-5
Dying from exposure to smoke, ﬁre, and ﬂames
1.2E-5
Dying in an explosion
9.3E-6
Dying in an airplane accident
2.8E-6
entire story. A failure rate can be calculated from the ﬂight hours,
which is probably a better way to describe the reliability of the system.
Table 8.5 contains ﬂight statistics for space shuttles (6, 7).
There were 2 failures in 30,946 ﬂight hours for a failure rate of
2 Failures
30,946 h = 6.5E −5 failures/h
TABLE 8.5
Space Shuttle Flight Stats
Orbiter
Year of ﬁrst ﬂight
Number of space ﬂights
Flight time
Enterprise 1977—landing tests only
0
0
Columbia
1981
28
300 d 17 h 46 min 42 s
Challenger
1983
10
62 d 7 h 56 min 15 s
Discovery
1984
38
351 d 17 h 50 min 41 s
Atlantis
1985
32
293 d 18 h 29 min 37 s
Endeavor
1992
24
280 d 9 h 39 min 44 s
Totals
132
1289 d 9 h 52 min 48 s
Total hours
30,946

8.1 Risk Assessment Data
105
A daily failure rate can also be calculated:
2 Failures
1289.4 days = 1.5E −3 failures/operating day
Finally, a yearly failure rate can be calculated:
1289.4 Operating days/365 days/year = 3.53 operating years
2 Failures
3.53 Years = 0.56 failures/operating year
Using these rates puts the accidents in a better perspective. One
accident in more than 15,000 operating hours is a reasonable rate for
a transportation vehicle. In 15,000 operating hours, a ﬂeet of ﬁve cars
would drive approximately 750,000 mi at 50 mi/h.
Rates similar to this can be calculated for all accident types, as
long as the numerator and denominator are valid or as valid as possible.
Injury and illness rates are usually calculated using standardized
formulas (8, 9). Though, in general, these rates are not as important for
risk assessments, there are times they do have utility. Injury frequency
rate can be calculated in several different ways. One way is based on
1,000,000 labor hours and is calculated using the following formula:
Accident frequency rate = (Number of accidents × 1,000,000)
Actual labor hours
For example, the accident frequency for an organization with 10 acci-
dents and 250,000 labor hours is given by
Accident frequency rate = (10 Accidents × 1,000,000)
250,000 labor hours
= 40 Accidents/million labor hours
The Bureau of Labor Statistics (BLS) uses a base of 100 full-time
workers instead of 1,000,000 labor hours. Therefore, using the BLS
formula, the rate becomes
BLS accident rate = (10 Accidents × 200,000)
250,000
=
8 Accidents
200,000 labor hours
Accident severity rates can be calculated using a variety of methods.
For instance, the BLS disabling injury rate is calculated using the

106
CHAPTER 8 Developing Probabilities
following formula:
BLS disabling injury severity rate
= (Total days charged × 1,000,000)
Labor hours of exposure
Illness rates are commonly calculated using two formulas (10).
The ﬁrst rate is an incidence rate. Incidence rate for a disease is the
number of new cases for a population. As an example, there is a town
with a population of 10,000. A ﬂu virus invades the town. The town’s
medical staff begins to monitor the town and during week 1, a total
of 150 people catch the ﬂu. During week 1, the incident rate for the
ﬂu becomes
Incident rate =
	150 New cases
10,000 Persons

× 100 = 1.5%
During week 2, another 400 new cases of the ﬂu are reported. The
incident rate for week 2 becomes
Incident rate =
	400 New cases
10,000 Persons

× 100 = 4%
The prevalence rate is the number of active cases of disease in a
population. In our mythical town of 10,000, there were 150 cases of
ﬂu during week 1 and 400 cases of ﬂu during the week 2. However,
80 of the people who caught the ﬂu during week 1 got well. So, during
week 2, there are 470 active cases of the ﬂu. The prevalence rate is
calculated using the following formula:
Prevalence rate =
	
470 Cases
10,000 Persons

× 100 = 4.7%
Many different versions of these calculations are available and this is
just a sample of the types of formulas that are used.
8.1.10 Monte Carlo Simulation
Monte Carlo simulation techniques are also used to aid in developing
and updating failure rates. The description and use of these techniques
are outside the scope of this book. Good sources of information on
this topic are David Vose’s (11) “Risk Analysis, A Quantitative Guide”
and Douglas Hubbard’s (12) “How to Measure Anything: Finding the
Value of Intangibles in Business.”

8.1 Risk Assessment Data
107
8.1.11 Human Error Probabilities
Chapter 10 discusses human reliability analysis in detail, along with
the technique for human error rate prediction (THERP), along with
other techniques. In this chapter, methods have been discussed on
how to develop HEPs and/or rates from other sources.
Developing reliable data on any human behavior is problematic
because humans do not always do what we want them to do. Therefore,
the goal is to develop the most reliable HEPs possible. Similar methods
are used to develop these data as were used to develop hardware data.
However, humans do not like to be monitored 24/7, so the number
of errors that humans commit, but then discover and correct before
an accident, cannot be absolutely determined. Also, most hardware
systems are designed to work in certain environments and tests can
be conducted to determine the changes in the reliability or life of
the system when the environment is altered. Humans operate in a
wide range of environments and how one human responds to a set
of environmental conditions and stress levels varies widely from how
another human might respond.
The ﬁrst American astronauts were said to have the right stuff
because they could handle environmental and psychological stress
much better than the average person (13). Some people handle cold
conditions better, some people hot conditions, some people can work
in noisy environments, and some people need complete silence. Even
with this, knowing where there is a higher probability for a human
to commit an error provides analysts with information they can use
to direct improvements to the system and make it less susceptible to
human error.
Modiﬁers to HEPs are called performance shaping factors (PSFs)
(14). PSFs allow risk analysts to help account for human response to
environmental and psychological stressors.
Common PSFs include the following:
• hot/cold;
• noise level
• light (too much or too little and/or quality of the light);
• vibration;
• physical ergonomics;

108
CHAPTER 8 Developing Probabilities
• experience;
• training;
• management;
• time (too much or not enough to perform the task);
• stress (too much or too little);
• equipment design;
• human machine interface;
• sequence of tasks.
In an ongoing study, Ostrom and Wilhelmsen (15) are developing
risk models, HEPs, and PSFs for aircraft maintenance and inspection
tasks. This work involves visiting airlines and third-party repair sta-
tions around the world collecting data on aircraft maintenance and
inspection and from these data developing parameters on the risk of
these operations.
Two methods of developing HEPs have been discussed. These
are the Delphi method, which is a formal approach to HEP develop-
ment, and using performance data, which a more informal approach
to develop HEPs.
8.1.12 Delphi Method
The Delphi approach to decision making has been in use for many
years (16, 17). It is a relatively simple technique to use but does
require a commitment on the part of the panel, who participate in the
Delphi sessions. The technique utilizes a panel of experts and a facil-
itator to work to consensus to develop HEP estimates and estimates
of hardware failure rates. It is systematic in nature and has been used
to help develop sales forecasts, to speculate on technology (military
and civilian), and even to aid in national policy making. The focus
of the following discussion is on developing HEP estimates using
an approach that Ostrom and coworkers (18) used to develop HEP
estimates for aircraft maintenance tasks. However, it can be applied
to hardware failure rates as well, with the correct panel. The room
where the Delphi process is conducted should be comfortable so that
the panel members feel at ease.

8.1 Risk Assessment Data
109
The steps in the Delphi process for developing HEPs are as
follows:
1. Select the panel.
2. Introduce the topic and calibrate the panel on the topic.
3. Present the parameters of the task to evaluate.
4. Perform the initial round of discussions on the error probability
and voting.
5. Discuss the results of the ﬁrst-round and second-round voting.
6. Discuss the results of the second round and repeat until con-
sensus is reached.
7. Develop PSFs.
These steps are discussed below in the context of an example.
This example is to develop HEPs for an aircraft inspection task. This
inspection task will be to determine the HEPs for visually inspecting
a composite aircraft panel for small anomalies. The determination of
the HEPs will be important in the development of a risk model for
the next generation, primarily composite aircraft.
Select the Panel
The panel should consist of SMEs in the ﬁeld of interest, along with an
expert in risk assessment and a facilitator. The SMEs should provide
representation for the complete process. For this example, our SMEs
should include the following:
• qualiﬁed inspectors from an airline;
• representation from a structures group from an aircraft manu-
facturer;
• composite repair person.
The qualiﬁed inspectors are on the panel to provide reliable esti-
mates of detection rates for composite anomalies. The representa-
tive from the structure group of an aircraft manufacturer provides
information on the materials of interest, the types of anomalies that
can develop, and data from the airline community as to the anoma-
lies and the relative rates of detection. The composite repair person

110
CHAPTER 8 Developing Probabilities
provides information on the anomalies seen in the ﬁeld and the types of
anomalies that are/are not detected.
The risk analyst on the panel ensures that the panel discussions
are pertinent to developing the HEPs of interest and to ensure the
HEPs and PSFs are reasonable. The facilitator should understand the
process, but does not need to be an SME. Instead, the facilitator should
be good at eliciting a response on the topic, keeping the group focused
on the goal and moving things along.
It is always best to select the panel so that the least biased data can
be developed. Therefore, the SMEs should, in our example, represent
several airlines. Generally, one should avoid selecting people who
commonly work with each other to break up, to the degree possible, the
interdependences that can develop between colleagues. In our ﬁctitious
panel, there are six inspectors, an aircraft manufacturer representative,
a composite repair person, and a risk analyst.
Introduce the Topic and Calibrate the Panel
The facilitator begins the process by brieﬂy introducing the panel.
Each panel member should introduce him/herself and brieﬂy discuss
his/her expertise. The facilitator next introduces the risk analyst. The
risk analyst discusses the task at hand, in this case developing HEPs
for the visual inspection of an aircraft composite panel. Next, the risk
analyst presents data on other types of similar tasks. In this example,
data on the probability of detection (POD) for fatigue cracks from the
visual inspection of aluminum aircraft panels might be presented (19):
• 0.005 probability of detecting a 0.1-in crack on a detailed
inspection;
• 0.05 probability of detecting a 0.5-in crack on a detailed
inspection;
• 0.99 probability of detecting a 2-in crack on a detailed
inspection.
The probability of not ﬁnding the cracks is then as follows:
• 0.1-in crack HEP is approximately 1.0−0.005 = 0.995;
• 0.5-in crack HEP is approximately 1.0−0.05 = 0.95;
• 2-in crack HEP is approximately 1.0−0.99 = 0.01.

8.1 Risk Assessment Data
111
The parameters of what constitutes a detailed inspection are also
presented. At this point, all questions are addressed.
Present the Parameters of the Task to Evaluate
The next step involves discussing the parameters of the task at hand.
That is to discuss developing HEPs for the visual inspection for
anomalies on composite aircraft panels. The aircraft manufacturer and
repair person might start this discussion with a presentation on the
types of anomalies that can be found. The inspectors might discuss
the types of anomalies they have seen. It is up to the risk analyst and
facilitator to ensure that only those items of interest are discussed. The
parameters as to the size and shape of the anomalies that will be the
focus of the Delphi session must also be presented. Of course, an air
craft panel that is destroyed will most likely be found. So, the panel
members are focused on developing HEPs on anomalies that are 2 in.
in diameter or smaller, since that is similar to the data presented in
step 2.
Perform the Initial Round of Discussions on the
Error Probability and Voting
The initial round of discussions on the HEP are initiated. Visuals,
such as a scale showing relative probabilities, can be used to focus
the panel. Figure 8.2 shows a scale used for this example.
The facilitator opens the discussion by telling the panel what size
and type of anomaly the panel will be asked to develop a HEP for.
In this case, a 0.5-in round dent on a composite panel that is 0.1 in.
in depth. The panel is asked if they have any questions or need any
additional information. For this ﬁrst round, only a nominal value will
be solicited. Meaning, the paint on the panel is in good shape, there
is adequate lighting, and so forth. The panel will ask questions and
discuss aspects of the task. At the end of the discussion, the panel is
asked to mark on the scale, either in private or publicly, what they
each think the probability of detecting that certain anomaly is. Each of
the panel, except the risk analyst, marks the scale. Figure 8.3 shows
how these marks might look. The panel takes a short break or is asked
to consider the next item. In either case, the risk analyst compiles the
results.

112
CHAPTER 8 Developing Probabilities
1.0
0.9
0.5
0.1
0.05
0.01
0.005
0.001
0.0005
0.0001
0.0
Probability
FIGURE 8.2
Relative probability
scale.
Discuss the Results of the First-Round
and Second-Round Voting
The results are presented to the panel after the votes are compiled
by the risk analyst. In our example, the probability of detecting this
anomaly ranges from a low of 0.0005 to a high of 0.9. This is a
very broad range. However, the majority of the panel’s votes were
between 0.005 and 0.1. Discussion is elicited by the facilitator as to
why panel members voted the way they did. It might be one panel has
not had much experience with this type of anomaly or had a very bad
experience missing a certain size anomaly. These types of issues are
discussed. In this example, it was found that the very low probability
of 0.0005 is due to the inspector’s lack of experience with composite
structure. The very optimistic 0.9 probability was also due to a single
inspector working in a hanger with very bright lights. The facilitator
and risk analyst discuss with the panel that these items might better be

8.1 Risk Assessment Data
113
Probability
1.0
0.9
0.5
0.1
0.05
0.01
0.005
0.001
0.0005
0.0001
0.0
FIGURE 8.3
First-round voting.
dealt with as PSFs and what they are trying to determine in a nominal
value. At this point, the second round of voting occurs. The results
are again compiled.
Discuss the Results of the Second Round
Figure 8.4 shows the results of the second round of voting. As the
ﬁgure shows, during this round, the results are much tighter. The facil-
itator again would elicit discussion concerning the voting. The panel
would then be asked to come to a consensus concerning the HEP. In
this case, the natural value would be a probability of 0.05. This is the
value the SMEs’ votes clustered around. Discussion concerning this
value would be elicited to see if it was a true consensus. If so, the
voting ends, if not, the voting continues until a consensus is reached.
Develop PSFs
The PSFs are developed in a similar fashion as the HEPs. Once the
HEP is developed for a certain task, the panel is asked to consider
how various parameters, such as experience, stress, lighting, and noise,

114
CHAPTER 8 Developing Probabilities
Probability
1.0
0.9
0.5
0.1
0.05
0.01
0.005
0.001
0.0005
0.0001
0.0
FIGURE 8.4
Results of the second
round.
might affect the HEP. The panel ﬁrst needs to come to consensus on
which PSFs are important. For this example, the panel decides that the
following PSFs are deemed important for detecting composite panel
anomalies:
• training;
• experience;
• lighting;
• time.
The panel comes to consensus that an inspector with 1 year or
less supervisory experience lacks the experience to perform composite
inspections with a high degree of reliability. A scenario is presented to
the panel, such as what would be the probability of an inspector with
1 year of experience ﬁnding the same anomaly? The panel again votes
on the topic and the process is repeated until a consensus is reached.

8.1 Risk Assessment Data
115
A multiplication factor is then developed for that parameter for the
HEP. In this case, the panel feels that an inspector with only 1 year
of experience has a probability of ﬁnding the anomaly of 0.5. Since
the nominal HEP for this task was found to be 0.05, the multiplier
for lack of experience is a multiplier of 10. Chapter 10 discusses how
these data are used.
8.1.13 Summary of the Delphi Process
The Delphi process is very useful for developing HEPs and corre-
sponding PSFs for use in human reliability analyses. It is also useful
for developing hardware failure rates. The keys to the process are hav-
ing an appropriate panel and facilitator to ensure the panel keeps on
track.
Developing Human Error Probabilities from
Other Sources
As stated earlier, HEPs are not as readily available as hardware failure
rates. However, the data can be developed from other sources. Some
of these sources include the following:
• results from human factors and psychological studies;
• operational and maintenance records;
• speciﬁc research studies.
Though these HEPs, depending on the source, might not be as
reliable as hardware failure rates, they are better than nothing. A com-
plex maintenance task can be considered, for example, aircraft engine
replacement. HEPs for speciﬁc aspects of the task can be developed
from postmaintenance inspection records or even records from rework.
For example, a maintenance team replacing a control unit of an engine
can be considered. In a given year, 100 such control units are replaced.
However, in ﬁve of these repairs, a functional check found that the
unit was not properly installed. A HEP can be developed for the task
by dividing the ﬁve failures by the 100 total tasks:
HEP =
5
100 = 0.05

116
CHAPTER 8 Developing Probabilities
Other factors surrounding this task can also be elucidated. Were
all the failures at one facility, in certain weather conditions, or on the
ramp or in the hanger?
These other factors are used to develop the PSFs for the HEP.
8.2 OVERALL SUMMARY
Hardware failure data and HEPs are available, but sometimes risk
analysts have to dig for them. Hardware failure rate data are available
from a variety of sources, including handbooks, databases, research
reports, and ﬁndings from accident investigations.
HEPs are available from standardized human reliability analysis
processes such as THERP, and they can be developed using tools such
as the Delphi process. The main point of this chapter is to use the best
data available for risk assessments.
REFERENCES
1. Ebeling CE. An introduction to reliability and maintainability engineering.
Boston, MA: McGraw-Hill; 1997.
2. Available at http://theRiAC.org. Accessed 2010 Dec 30.
3. Cadwalleder L. Component failure rate values from fusion safety assessment;
INEEL/EXT-98-00892, Idaho Falls, ID; 1998.
4. Mannan S. Lees’ Lost Prevention in the Process Industries: Hazard Identiﬁcation,
Assessment and Control. 3rd ed. Oxford, UK: Butterworth-Heinemann; 2005.
5. www.ntsb.gov. Available at http://www.ntsb.gov/ntsb/GenPDF.asp?id=DCA88
MA054&rpt=fa. Accessed 2011 Jan 25.
6. www.nasa.gov. Flight Statistics Space Shuttle. Available at http://www.nasa.gov/
centers/kennedy/news/facts/shuttlefacts-toc.html. Retrieved 2011, Jan 5.
7. www.wikipedia.org. Space Shuttle Program, Available at http://en.wikipedia.org.
wiki/Space Shuttle program. Accessed 2011 Jan 4.
8. Injuries, Illnesses, and Fatalities, Bureua of Labor Statistics, www.bls.gov.
http://www.bls.gov/iif/. Accessed 2011 Jan 8.
9. Hammer W, Price D. Occupational Safety Management and Engineering. 5th ed.
New Jersey: Prentice Hall; 2001.
10. Last JM. A Dictionary of Epidemiology. 4th ed. New York: Oxford University
Press; 2001.
11. Vose D. Risk Analysis, A Quantitative Guide. 2nd ed. New York: John Wiley &
Sons; 2000.
12. Hubbard D. How to measure anything: ﬁnding the value of intangibles in business.
New York: John Wiley & Sons; 2007.

References
117
13. Wolfe T. The right stuff. New York: Picador; 2008.
14. Gertman DI, Blackman HS. Human reliability and safety analysis data handbook.
New York: Interscience; 1993.
15. Ostrom L, Wilhelmsen CA. Developing risk models for aviation maintenance and
inspection. Int J Aviat Psychol 2008: 18: 30–42.
16. Brown BB. Delphi process: a methodology used for the elicitation of opinions of
experts. RAND; 1968.
17. Delbecq AL, Van De Ven AH, Gustafson DH, Van De Ven Delberg A. Group
techniques for program planning: a guide to nominal group and Delphi processes.
Green Briar Press; 1986.
18. Nelson W, Haney L, Richards R, Wilhelmsen C, Owen R, Ostrom L. Struc-
tured human error analysis for airplane maintenance and design. Idaho Falls, ID:
INEEL/EXT-97-01093; 1997.
19. Goranson U. Fatigue issues in aircraft maintenance and repairs. Int J Fatigue
1997:20(6):413–431.

CHAPTER 9
Failure Mode and Effects
Analysis
When an analyst begins to perform a risk analysis, he/she must
ﬁrst determine what exactly is being analyzed. For this, we must ﬁrst
determine what we consider a failure. Is a failure the total loss of
a spacecraft, aircraft, ship, or chemical plant? Or is it the failure to
ensure there are enough funds in an account before using a debit card?
On November 2, 2006 the NASA Mars Global Surveyor last commu-
nicated with Earth. Up to that point, the spacecraft that had been
launched in 1996 had operated four times as long as the design life
and sent back huge amounts of geographical data on the Red Planet.
Therefore, the mission was a great success. However, on November
2, 2006 after the spacecraft was directed to perform a routine adjust-
ment of its solar panels, it sent back that it had experienced a series of
alarms. The spacecraft then indicated that it had stabilized. However,
that was its ﬁnal transmission. Next, the spacecraft reoriented to an
angle that exposed one of two batteries carried on the spacecraft to
direct sunlight. This caused the battery to overheat and ultimately led
to the loss of both batteries. The communication antenna was not ori-
ented correctly and kept the orbiter from telling controllers its status.
The system’s programed safety response did not include making sure
the spacecraft orientation was thermally safe and it failed (1).
Risk Assessment: Tools, Techniques, and Their Applications, First Edition.
Lee T. Ostrom, Cheryl A. Wilhelmsen.
2012 John Wiley & Sons, Inc. Published 2012 by John Wiley & Sons, Inc.

9.1 Introduction
119
However, since it had already outperformed its original mission,
had it truly failed? We all would like the things we buy to live longer
than we expect. The B-52 is an example of an aircraft that has far out
lived its design life. In 1952, when the ﬁrst B-52 ﬂew, no one would
have expected it to still be a major player in the second decade of the
2000s. So, as originally stated, we have to have a ﬁrm understanding
of what a failure is before we begin an analysis.
9.1 INTRODUCTION
This section provides the basic instructions for performing a failure
mode and effects analysis (FMEA) and a failure mode, effects, and
criticality analysis (FMECA) for the purpose of analyzing procedures
for risk. Also provided are examples of commonly used symbols and
tables used in the analysis process. An example of how these tech-
niques are used for analyzing procedures is also provided.
9.1.1 Description
An FMEA is a detailed document that identiﬁes ways in which a
process or product can fail to meet critical requirements. It is a living
document that lists all the possible causes of failure from which a
list of items can be generated to determine types of controls or where
changes in the procedures should be made to reduce or mitigate risk.
The FMEA also allows procedure developers to prioritize and track
procedure changes (2).
9.1.2 Why is a Failure Mode and Effects Analysis
Effective?
The process is effective because it provides a very systematic approach
for evaluating a system or a procedure. It provides a means for iden-
tifying and documenting the following:
1. Potential areas of failure in process, system, component, or
procedure.
2. Potential effects of the process, system, component, or proce-
dure failing.

120
CHAPTER 9 Failure Mode and Effects Analysis
3. Potential failure causes.
4. Methods of reducing the probability of failure.
5. Methods of improving the means of detecting the causes of
failure.
6. Risk ranking of failures, allowing risk informed decisions by
those responsible.
7. A starting point from which the control plan can be created.
9.1.3 Types of Failure Mode and Effects
Analyses
1. Procedure. Documents and addresses failure points and modes
in procedures.
2. Process. Documents and addresses failure modes associated
with the manufacturing and assembly process.
3. Software. Documents and addresses failure modes associated
with software functions.
4. Design. Documents and addresses failure modes of products
and components long before they are manufactured and should
always be completed well in advance of prototype build.
5. System. Documents and addresses failure modes for system-
and subsystem-level functions early in the product concept
stage.
6. Project. Documents and addresses failures that could happen
during a major program.
7. This document focuses on using the FMEA process for ana-
lyzing procedures.
9.1.4 Failure Mode and Effects Analysis Process
An FMEA is somewhat more detailed than a PHA and is conducted
more on a step-by-step basis. Table 9.1 shows an example of an FMEA
table. Note that a great deal of what is contained in a PHA is also
contained in an FMEA. Therefore, this section focuses on the process
of performing an FMEA.
The following constitutes the steps of an FMEA. These steps will
be illustrated by use of an example.

TABLE 9.1
FMEA
Potential
Cause of
Possible
Item
failure mode
failure
effects
Probability
Criticality
Prevention
Step in
procedure,
part, or
component
How it can fail?
Failures can be
Pump not working;
Stuck valve;
No money in a
checking account;
Broken wire;
Software error;
System down;
Reactor melting
down
What caused
the failure:
Broken part;
Electrical
failure;
Human error;
Explosion;
Bug in software
Outcome of the
failures:
Nothing
System crash
Explosion
Fire
Accident
Environmental
release
How possible is it?
Can use numeric
values:
0.1, 0.01, or 1E-5
Can use a
qualitative
measure:
negligible, low
probability, high
probability.
How bad are the
results?
Can use dollar
value:
$10,
$1000,
or $1,000,000
Can use a
qualitative
measure: nil,
minimal
problems, major
problems.
What can be
done to
prevent either
failures or
results of the
failures?
121

122
CHAPTER 9 Failure Mode and Effects Analysis
TABLE 9.2
Process Steps
FMEA, starting a lawn mower
Process steps
Check gas and oil
Fill as necessary
Set controls
Initiate starter
The ﬁrst step is to create a ﬂow diagram of the procedure. This
is a relatively simple process in which a table or block diagram is
constructed that shows the steps in the procedure. Table 9.2 shows
the simple steps of starting a manual lawn mower. Note that this is a
reasonable analysis and not an exhaustive analysis.
Table 9.3 shows the failure modes associated with process steps.
TABLE 9.3
Failure Modes
FMEA, starting a lawn mower
Process steps
Potential failure modes
Check gas and oil
Unable to remove gas cap
Unable to remove oil plug
Unable to determine depth of oil
Oil or gas spill
Fill as necessary
No oil available
Gas station closed
No gas container
Overﬁll gas
Overﬁll oil
Water in gas or oil
Set controls
Controls broken
No instruction available
Controls out of adjustment
Initiate starter
Starter malfunction
Cord broken
Engine ﬂooded
Ignition system malfunction

9.1 Introduction
123
TABLE 9.4
Effect of Potential Failures
FMEA, starting a lawn mower
Process steps
Potential failure modes
Potential failure effects
Check gas and oil
Unable to remove gas cap
Delay in process or
personal injury
Unable to remove oil
plug
Delay in process
Unable to determine
depth of oil
Delay in process or the
potential to overﬁll oil
level
Oil or gas spill
Environmental damage or
potential for ﬁre
Fill as necessary
No oil available
Delay in process
Gas station closed
Delay in process
No gas container
Delay in process
Overﬁll gas
Potential for a ﬁre or
environmental damage
Overﬁll oil
Environmental damage
Water in gas or oil
Delay in process or
engine damage
Set controls
Controls broken
Delay in process
No instruction available
Delay in process
Controls out of
adjustment
Delay in process or
engine damage
Initiate starter
Starter malfunction
Delay in process and/or
repairs necessary
Cord broken
Delay in process and/or
repairs necessary
Engine ﬂooded
Delay in process
Ignition system
malfunction
Delay in process and/or
repairs necessary
Table 9.4 shows the effect of the potential failures.
Table 9.5 lists the potential causes of the failures.
The basic process is complete once these four steps are completed.
However, the next step in the FMEA process is very important for the
procedure development process, that is, providing a column listing
the control measures for each of the potential failure causes. This step
ensures that control measures are present and/or are adequate for each
cause. It is very important to ensure that causes are not dismissed until

TABLE 9.5
Potential Causes of the Failures
FMEA, starting a lawn mower
Process steps
Potential failure modes
Potential failure effects
Potential causes of failures
Check gas and oil
Unable to remove gas cap
Delay in process or personal
injury
Cap rusted or broken
Unable to remove oil plug
Delay in process
Operator error or plug cross
threaded
Unable to determine depth of oil
Delay in process or the potential
to overﬁll oil level
Operator error or poor lighting
Oil or gas spill
Environmental damage or
potential for ﬁre
Operator error
Fill as necessary
No oil available
Delay in process
Lack of planning
Gas station closed
Delay in process
Lack of planning
No gas container
Delay in process
Lack of planning
Overﬁll gas
Potential for a ﬁre or
environmental damage
Lack of adequate equipment or
operator error
124

Overﬁll oil
Environmental damage
Lack of adequate equipment or
operator error
Water in gas or oil
Delay in process or engine
damage
Poor practices
Set controls
Controls broken
Delay in process
Was not proper used on prior
occasion
No instruction available
Delay in process
Instructions not properly stored
on prior occasion
Controls out of adjustment
Delay in process or engine
damage
Controls not properly
maintained
Initiate starter
Starter malfunction
Delay in process and/or repairs
necessary
Inadequate inspection or
periodic maintenance
Cord broken
Delay in process and/or repairs
necessary
Inadequate inspection or
periodic maintenance
Engine ﬂooded
Delay in process
Improper use of controls
Ignition system malfunction
Delay in process and/or repairs
necessary
Inadequate inspection or
periodic maintenance
125

126
CHAPTER 9 Failure Mode and Effects Analysis
there is an adequate control measure in place. Table 9.6 shows a list
of the control measures for each cause.
An additional technique used in FMEAs is to add the dimension of
probability and criticality. This is known as a failure mode, effects, and
criticality analysis (FMECA). An FMECA is an especially important
technique for the assessment of risks in procedures because it can
aid in
1. The prioritization of steps/sections of procedures that need to
be changed or the process changed to reduce risk.
2. Pointing out where warnings, cautions, or notes need to be
added in procedures.
3. Pointing out where special precautions need to be taken or
specialized teams/individuals need to perform tasks.
The criticality is mainly a qualitative measure of how critical the
failure to the process really is. It is usually based on subject matter
experts’ opinion but can also be based on probability of occurrence
and/or on the consequence or effect.
For the purposes of an FMECA, rough calculations can be devel-
oped using
• historical data;
• a Delphi-like technique (3);
• accident data;
• subject matter expert(s);
• best estimate.
Table 9.7 presents a way to calculate criticality based on proba-
bility.
Note that the probability numbers in Table 9.7 provide an indica-
tion of the level of criticality and not an absolute failure probability.
Organizations have also developed risk matrices that can also be
used to indicate criticality. Table 9.8 shows such a matrix. Note that
these matrices provide a way to combine the probability of occur-
rence with severity of consequence. Also note that these matrices are
subjective in nature but do provide a way to systematically assess risk.

TABLE 9.6
Control Measures
FMEA, starting a lawn mower
Process steps
Potential failure modes
Potential failure effects
Potential causes of failures
Control measure
Check gas and
oil
Unable to remove gas cap
Delay in process or
personal injury
Cap rusted or broken
Cap maintenance program
Unable to remove oil
plug
Delay in process
Operator error or plug cross
threaded
Operator training
Unable to determine
depth of oil
Delay in process or the
potential to overﬁll oil
level
Operator error or poor
lighting
Operator training and
provide additional
lighting
Oil or gas spill
Environmental damage or
potential for ﬁre
Operator error
Operator training
Fill as
necessary
No oil available
Delay in process
Lack of planning
Ensure adequate oil is
available
Gas station closed
Delay in process
Lack of planning
Ensure fuel supply is
available
No gas container
Delay in process
Lack of planning
Provide equipment to
minimize spill potential
Overﬁll gas
Potential for a ﬁre or
environmental damage
Lack of adequate equipment
or operator error
Provide equipment to
minimize spill potential
Overﬁll oil
Environmental damage
Lack of adequate equipment
or operator error
Ensure fuel and oil
containers are not
exposed to sources of
water
(continued)
127

TABLE 9.6
(Continued)
FMEA, starting a lawn mower
Process steps
Potential failure modes
Potential failure effects
Potential causes of failures
Control measure
Water in gas or oil
Delay in process or
engine damage
Poor practices
—
Set controls
Controls broken
Delay in process
Inspection and periodic
maintenance
Institute inspection and
periodic maintenance
program
Lack of labeling on the
controls
Delay in process
Instructions not properly
stored on prior occasion
Ensure controls are
adequately labeled
Controls out of
adjustment
Delay in process or
engine damage
Controls not properly
maintained
Institute inspection and
periodic maintenance
program
Initiate starter
Starter malfunction
Delay in process and/or
repairs necessary
Inadequate inspection or
periodic maintenance
—
Cord broken
Delay in process and/or
repairs necessary
Inadequate inspection or
periodic maintenance
—
Engine ﬂooded
Delay in process
Improper use of controls
—
Ignition system
malfunction
Delay in process and/or
repairs necessary
Inadequate inspection or
periodic maintenance
—
128

9.1 Introduction
129
TABLE 9.7
Criticality
FMECA criticality
Criticality
Relative probability rates
Probability rates
Very high: failure is
almost inevitable
1 in 3 to 1 in 2
0.33 to >0.50
High: generally
associated with
processes similar to
previous processes that
have failed
1 in 20 to 1 in 8
0.05–0.125
Moderate: generally
associated with
processes that have
experienced occasional
failures
1 in 2000 to 1 in 80
0.005–0.0125
Low: isolated failures
associated with similar
processes
1 in 15,000
0.000067
Very low: only isolated
failures associated with
almost identical
processes
1 in 150,000
0.0000067
Remote: failure unlikely.
No failure ever
associated with an
almost identical
processes
1 in 1,500,000
0.00000067
The following example (Table 9.9) shows all the elements of an
FMECA developed for assessing the steps in the lawn-mower-starting
example. Note that probability can also be included. The ﬁrst step in
this process is to determine what “criticality” means in this context.
Is it how bad the consequences might be? Or how critical the step
is in the operation of the system? For this process, we will make the
assumption that criticality means how bad the consequences might be
if we do not perform the step correctly.
The high criticality step in this process concerns adding oil or fuel.
In these cases, warnings/cautions should be included in the procedure
or the system should be modiﬁed to include controls to prevent adding
fuel to a hot engine.

TABLE 9.8
Example of a Risk Matrix
Risk matrix
Probability of failure
Very low
Low
Moderate
High
probability
probability
probability
probability
Very high
(<1 in
(1 in 1,000,000
(1 in 100,000
(1 in 10,000
probability
Consequence
1,000,000)
to 1 in 100,000)
to 1 in 10,000)
to 1 in 100)
(>1 in 100)
No effect
—
—
—
—
—
Minor consequence (repair costs
<$100 or down time <1 h)
Low risk
Low risk
Low risk
Minor risk
Minor risk
Moderate consequence (repair
costs from $100 to $10,000 or
down time from 1 to 24 h)
Low risk
Low risk
Minor risk
Moderate risk
High risk
High consequence (repair costs
from $10,000 to $100,000 or
down time from 24 to 120 h or
minor environmental spill or
minor personal injury
Low risk
Minor risk
Moderate risk
High risk
Very high risk
Severe consequence (repair
costs >100,000 or down time
>120 h or major environmental
spill or severe injury or
fatality)
Minor risk
Moderate risk
High risk
Very high risk
Severe risk
130

TABLE 9.9
Criticality Analysis
FMECA, starting a lawn mower
Process
Potential failure
Potential failure
Potential causes
Control
Criticality
steps
modes
effects
of failures
measure
of step
Check gas
and oil
Unable to remove
gas cap
Delay in process or
personal injury
Cap rusted or
broken
Cap maintenance
program
Low criticality
Unable to remove
oil plug
Delay in process
Operator error or
plug cross
threaded
Operator training
—
Unable to
determine depth
of oil
Delay in process or
the potential to
overﬁll oil level
Operator error or
poor lighting
Operator training
and provide
additional lighting
—
Oil or gas spill
Environmental
damage or
potential for ﬁre
Operator error
Operator training
—
Fill as
necessary
No oil available
Delay in process
Lack of planning
Ensure adequate
oil is available
High criticality if
ﬁlling process is
done incorrectly
Gas station closed
Delay in process
Lack of planning
Ensure fuel supply
is available
—
No gas container
Delay in process
Lack of planning
Provide equipment
to minimize spill
potential
—
(continued)
131

TABLE 9.9
(Continued)
FMECA, starting a lawn mower
Process
Potential failure
Potential failure
Potential causes
Control
Criticality
steps
modes
effects
of failures
measure
of step
Overﬁll gas
Potential for a ﬁre
or environmental
damage
Lack of adequate
equipment or
operator error
Provide equipment
to minimize spill
potential
—
Overﬁll oil
Environmental
damage
Lack of adequate
equipment or
operator error
Ensure fuel and oil
containers are not
exposed to
sources of water
—
Water in gas or oil
Delay in process or
engine damage
Poor practices
—
—
Set controls
Controls broken
Delay in process
Inspection and
periodic
maintenance
Institute inspection
and periodic
maintenance
program
Low criticality
Lack of labeling on
the controls
Delay in process
Instructions not
properly stored on
prior occasion
Ensure controls are
adequately
labeled
—
Controls out of
adjustment
Delay in process or
engine damage
Controls not
properly
maintained
Institute inspection
and periodic
maintenance
program
—
132

Initiate
starter
Starter malfunction
Delay in process
and/or repairs
necessary
Inadequate
inspection or
periodic
maintenance
—
—
Cord broken
Delay in process
and/or repairs
necessary
Inadequate
inspection or
periodic
maintenance
—
Low criticality
Engine ﬂooded
Delay in process
Improper use of
controls
—
—
Ignition system
malfunction
Delay in process
and/or repairs
necessary
Inadequate
inspection or
periodic
maintenance
—
—
133

134
CHAPTER 9 Failure Mode and Effects Analysis
9.2 SUMMARY
FMEA and FMECA are very effective tools. They can be applied to
a broad range of applications and industries and are effective in eluci-
dating the vulnerabilities of a system and its subsystems. Like PHA,
FMEA and FMECA are applied early in the design life of a system
and are used to ensure that the system has no unidentiﬁed failure
points. As with the Mars Global Surveyor, we have to determine up
front what a failure is and what success is.
REFERENCES
1. Mars Global Surveyor (MGS) Spacecraft Loss of Contact, NASA White Paper
http://www.nasa.gov/pdf/174244main_mgs_white_paper_20070413.pdf. 2007, Re-
trieved March 2012-03-28.
2. Mil STD 882B. (n.d.). System safety program requirements, Department of Defense
Washington, DC 20301, 1984, 1993.
3. Gertman DI, Blackman HS. Human Reliabilty and Safety Analysis Handbook. New
York: John Wiley & Sons; 1994.

CHAPTER 10
Human Reliability
Analyses
10.1 INTRODUCTION
10.1.1 Purpose
The purpose of this chapter is to provide guidance on “how to” perform
a human reliability analysis (HRA). The methodology provided is not
intended to be used as a cookbook. Each situation requiring an HRA is
different. The references provide more detailed instructions, alternative
methods, and estimations of human error probability (HEP) values (1).
10.1.2 Background
The need for a methodical approach to perform HRAs originated from
the need to perform probabilistic risk assessments (PRAs) and proba-
bilistic safety assessments (PSAs). For this document, PRA and PSA
are considered interchangeable and only PRAs will be referred to.
While nuclear power plants may be the ﬁrst processes to come to mind
when discussing PRAs and HRAs, PRAs are performed on many pro-
cesses or activities. Examples are the assembly and disassembly of
nuclear weapons, petroleum reﬁnery operations, chemical processing
plants, and so on.
Risk Assessment: Tools, Techniques, and Their Applications, First Edition.
Lee T. Ostrom, Cheryl A. Wilhelmsen.
2012 John Wiley & Sons, Inc. Published 2012 by John Wiley & Sons, Inc.

136
CHAPTER 10 Human Reliability Analyses
PRAs typically focus on equipment failures. HRAs may be used
to analyze the human response to an equipment failure. The PRA may
also include a section that discusses the probability of human failure
being the initiating event. Even if a full-scale PRA is not performed, an
HRA may be beneﬁcial. Any process or activity that involves humans
is susceptible to human error. HRAs are used to quantify the prob-
ability of human errors. HRAs can also be used to identify steps or
activities in the process that can be targeted for changes that could
reduce the probability of human error (2).
The basic steps to perform an HRA include:
1. bounding the system;
2. task analysis;
3. HRA modeling;
4. quantifying the HEP;
5. documentation;
6. methodology.
10.1.3 Bounding the System
Bounding of the system to be analyzed is probably one of the most
important steps in the performance of an HRA. The system being
discussed is not a physical system but is a series of steps or actions
that involve the potential for human failure.
As stated above, HRAs are typically performed in support of
a PRA. The PRA may identify an equipment or human failure
that requires a human to respond to mitigate the failure. For
example, the failure may be the trip of a pump and the human is
required to start the other pump. While the PRA would analyze the
entire failure sequence, the HRA would focus only on the human
involvement (i.e., the probability of human failure, in the sequence of
events).
The same holds true for the failure sequences in the PRA that are
initiated by a human error. There may be automatic system responses
that occur, as a result of the initiating human error, but again, the
HRA would focus on the probability of human failure.

10.1 Introduction
137
For example, one accident usually analyzed in a nuclear power
plant PRA is a rupture in the reactor piping. This accident is commonly
called a loss-of-coolant accident or LOCA. A small portion of the
sequence of events in a LOCA would be
1. reactor coolant system rupture;
2. drywell pressure reaches 2 psig;
3. emergency core cooling system (ECCS) initiates;
4. reactor SCRAM (safety control rod axe man) signal initiated;
5. containment building isolates;
6. emergency ventilation systems start.
To help to keep track of the different HRAs, each should be given
a descriptive title. The sequence of events for a LOCA is referred to as
the LOCA sequence. The titles in the different sequences are identiﬁed
in parentheses.
The sequences and their relationship should be laid out using logic
diagrams.
The operators must take numerous actions as part of the LOCA
sequence. For example, the operators must
1. verify the ECCS initiates (ECCS Initiate);
2. take the actions for the reactor SCRAM (SCRAM Actions);
3. verify that the containment building isolates (Cnmt Isolation);
4. verify that the emergency ventilation systems start (Emerg Vent
Start).
In addition to verifying each of the automatic actions, if an auto-
matic action does not occur, the operators must manually perform the
action or take alternative action. For example, if the ECCS pumps
do not automatically initiate, the operators must manually start the
pumps. There are also numerous manual actions that must be taken
such as shutting down the generator, starting the equipment to mitigate
hydrogen production, and so on. Each of the sequence of steps would
have a probability of failure.

138
CHAPTER 10 Human Reliability Analyses
As you can see, this can easily get very complex, very fast. As a
rule of thumb, each individual HRA should be bounded to a series of
steps that have a measurable beginning and end (i.e., the start point
and successful completion of the steps can be distinctly identiﬁed).
These will be broken down to the lowest level possible.
As an example, look at the SCRAM Actions sequence. This
sequence breaks down into nine separate steps.
1. All control rods insert into the reactor core.
2. The operator places the reactor mode switch in the shutdown
position (MS Shutdown).
3. The operator veriﬁes all control rods fully inserted (Verify Rods
Inserted).
4. The operator veriﬁes reactor power is decreasing (Verify Rx
Power).
5. The operator selects and inserts the source range and interme-
diate range monitors (they monitor reactor power at low power
levels) (Insert SRM/IRM).
6. The operator veriﬁes reactor vessel level to be within the
correct band (Verify Rx Level).
7. The operator veriﬁes reactor pressure to be within the correct
band (Verify Rx Pressure).
8. The operator veriﬁes the reactor coolant pumps shift to slow
speed (Verify RCP Downshift).
9. The operator shifts the feed water control system to single
element (FW to Single Element).
Step 1 does not require human involvement. Therefore, they are
excluded from the HRA but are included for continuity. Steps 2
through 9 require the involvement of a human, the operator, to be com-
pleted. The HRA for the SCRAM Actions sequence of steps would
consist of several separate HRAs (i.e., an HRA for each step). A total
probability of failure for the entire SCRAM Actions sequence can then
be determined. The total probability for human failure of the SCRAM
Actions sequence can then be used along with the probabilities deter-
mined for the other steps to determine the probability of failure for
the LOCA sequence of events.

10.2 Task Analysis
139
The steps will be broken down using task analysis into the separate
actions the operator must perform. The HEPs will be determined for
each of these steps.
10.1.4 Summary Points
• The system will typically be deﬁned as an accident sequence by
the PRA.
• The accident sequence should be broken down into its separate
sequence of actions and steps.
• These sequences should be further broken down into a series of
steps that have a measurable beginning and an end.
• Task analysis will break these steps down into the separate
actions the operator must perform.
10.2 TASK ANALYSIS
The task analysis breaks down the steps to be analyzed into its small-
est set of actions. This breakdown must be very detailed. The task
analysis may include steps that do not require human involvement.
These additional steps are for continuity and will be eliminated dur-
ing the HRA Modeling stage of the HRA (See Chapter 5 for more
information on task analysis).
To perform the task analysis, information must be gathered on
what actions are needed to complete the system to be analyzed. This
information can come from procedures or other documentation that
describes the system and the sequence to be analyzed (3).
Walk-throughs of the sequence with personnel familiar with the
sequence are almost mandatory to ensure accuracy of the end result.
Walk-throughs with more than one person will improve the credibility
of the end result. Walk-throughs may also identify hidden problems
(i.e., missing procedural steps, poorly designed instrumentation, poorly
designed control layout, etc.) that may increase the probability of fail-
ure. Copious notes should be taken. Photographs or sketches of the
instrumentation and control layout should also be obtained.
As part of the task analysis, the recovery from failure steps need
to be identiﬁed. During the walk-through, the operations personnel

140
CHAPTER 10 Human Reliability Analyses
should be asked what steps they would take to recover from a failure
to perform a step or failure to perform a step properly.
The task analysis does not have a speciﬁed format; you can use
whatever is comfortable and ﬁts the situation. An example sequence
and method for the task analysis is as follows.
1. Make a text list of the steps based on the procedure. This is
typically a good place to start. Information from the walk-
through can be used to ﬂesh out the sequence.
2. Validate the list by walking through the sequence with the
personnel who operate the equipment. Add notes concerning
factors that may inﬂuence the completion of the actions, for
example, switch positions, panel layout, lighting, color coding,
and so on.
3. Lay out the steps in sequence showing the path to be followed,
branches to other steps, iteration of steps, and so on. This can
be done using ﬂowcharting software, text lists, sketching the
symbols by hand, and so on. Another method is to list each step
on a sticky note and then stick it in sequence on a wall or board.
The advantage of this method is that as you gain information
about the sequence, it is easy to rearrange the sticky notes.
4. Have the operating personnel validate the sequence.
This sequence should be done as many times as needed in order
to thoroughly understand the actions and the factors affecting their
performance.
We will use step 3, Verify Rods Inserted, from the SCRAM
Actions sequence as an example task analysis as shown in Figure 10.1.
10.2.1 Summary Points
• Task analysis breaks down the steps to be analyzed into its
smallest set of actions.
• The task analysis needs to be very detailed and include recovery
actions.
• The operators must validate the sequence.

10.3 HRA Modeling
141
Button has two positions. Spring
returns when not depressed.
Operator finds rod
deselect button
Operator pushes and
releases rod deselect
button
Operator finds all rods
button
Operator pushes and holds
all rods button
Operator veriﬁes all 164
rods indicate “Inserted”
1
2
3
4
5
Button has two positions and
locks in position. Light on in
deselect. 
If all rods button released, rod
indication goes blank
Sequence
Notes
See sketch for button layout.
See sketch for button layout.
FIGURE 10.1
SCRAM actions for Verify Rods Inserted. The
operations personnel should validate this sequence of steps and the
sequence changed or notes added as needed.
10.3 HRA MODELING
The purpose of the HRA model is to give a visual representation of
the sequence of steps that:
• shows the potential human errors and their mechanisms;
• shows recovery paths;
• enables error quantiﬁcation.
There are numerous methods for modeling the HRA. Examples are
HRA event trees, fault trees, generic error modeling (GEM) causation
diagrams, human error modeling/investigation tool (HERMIT), and
the human error rate assessment and optimizing system (HEROS) (3).
Regardless of the methods used, the end result needs to be each
step from the task analysis visually depicted as a failure with the

142
CHAPTER 10 Human Reliability Analyses
applicable recovery actions. For example, we will use the HRA event
tree method to model the task analysis done above on step 3, Verify
Rods Inserted. The ﬁrst step is to identify and number the actions in
the task analysis that involves a potential for human error as shown
in Figure 10.2.
Note that the step involving pushing the All Rods button is not
numbered. This is because the button only has two positions pushed
or not pushed. The Rod Deselect button is included because it must
be pushed until it locks in position.
In an HRA event tree, the steps are worded as negatives (i.e., a
failure to perform the action). The recovery actions are worded as
positives (i.e., successfully performing the recovery action). Written
as text, the example steps would look like Table 10.1.
The HRA event tree for step 3, Verify Rods Inserted, is depicted in
Figure 10.3 with the failures on the right side of the tree and successes
on the left side. Figure 10.4 shows another depiction of the same task.
If the sequence were laid out in a logic tree, it would look like
Figure 10.4.
1 - Operator
fails to find rod
deselect button
2 - Operator fails to
lock rod deselect
push button in
deselect button
3 - Operator fails to find all
rods button
4 - Operator fails to verify all
164 rods indicate “Inserted”
Success path – meaning
the
procedure is a success
Failure Paths
FIGURE 10.2
HRA event tree method.

10.3 HRA Modeling
143
TABLE 10.1
Recovery Action
Step
Failure action
Recovery action
1
Operator fails to ﬁnd Rod Deselect
button
Operator ﬁnds Rod Deselect button
2
Operator fails to lock Rod Deselect
push button in Deselect position
Operator locks Rod Deselect push
button in Deselect position
3
Operator fails to ﬁnd All Rods button
Operator ﬁnds All Rods button
4
Operator fails to verify all 164 rods
indicate:—(double dash)
Operator veriﬁes all 164 rods
indicate:—(double dash)
10.3.1 Summary Points
• The purpose of the HRA model is to give a visual representation
of the sequence of steps.
• Regardless of the methods used, the end result needs to be each
step from the task analysis visually depicted as a failure with
the applicable recovery actions.
• The steps are worded as negatives. The recovery actions are
worded as positives.
All rods not verified
fully inserted
Operator fails
to find rod
deselect button 
Operator fails to lock rod
deselect push button in
deselect position 
Operator fails to
find all rods button 
Operator fails to verify
all 164 rods indicate
inserted
FIGURE 10.3
Verify Rods Inserted.

144
CHAPTER 10 Human Reliability Analyses
1. Removes radiator
cap when engine is hot.
2. Fails to drain coolant.
3. Fails to close petcock
when filling with water.
4. Fails to run engine for 30
minutes.
5. Fails to allow engine to cool prior to
draining coolant.
6. Fails to close petcock before refilling
with water.
7. Fails to allow engine to cool prior to
draining.
8. Fails to refill with non-toxic coolant.
FIGURE 10.4
Another View of Veriﬁed Rods.
10.4 QUANTIFYING HUMAN ERROR
PROBABILITY (HEP)
HEP is deﬁned as the probability that when a given task is performed,
an error will occur. This should not be confused with “human reliabil-
ity,” that is, the probability that the task will be correctly performed.
Like other parts of the HRA, there are several methods for quan-
tifying the HEP. One of the most common methods is through use of
the technique for human error rate prediction (THERP) tables provided
in NUREG/CR-1278, “Handbook of Human Reliability Analysis with
Emphasis on Nuclear Power Plant Applications.” These tables provide
HEPs and the other necessary information to quantify HEPs in many
activities.
If HEP values are not in NUREG/CR-1278 then other sources that
may be used are as follows:

10.4 Quantifying Human Error Probability (HEP)
145
• Historical Data. This could be for the speciﬁc activity or similar
activities.
• Expert Advice. Personnel with experience in performing HRAs
can be consulted to obtain their estimation of the HEP.
• Testing. Simulations of the activity can be performed and data
collected.
• Other Literature. There have been numerous PRAs performed
on various processes. Data for same/similar activities can be
used.
The HEP value used for the step must be recorded, including the
source of the HEP. This can be done on the HRA event tree or in
table format.
THERP tables will be used as a source to continue the example
(Table 10.2).
It must be noted that item 2 of THERP Table 20-12 states “Select
wrong control on a panel of similar appearing controls identiﬁed by
labels only.” The other choices on the table are controls that are
arranged in well-delineated functional groups and controls that are
part of a well-deﬁned mimic layout. To choose the most correct item,
the analyst must refer back to the photographs, drawings, and sketches
that were made of the panel layout. In this case, the switches are laid
out as shown on Table 10.3.
The switches are color coded but the color is only visible when
they are lit. The All Rods push button only lights up when depressed.
The Rod Deselect push button lights up in the Deselect position. There
TABLE 10.2
THERP Tables
Step
Failure action
HEP
Sourcea
1
Operator fails to ﬁnd Rod Deselect
button
0.003
Table 20-12, item 2
2
Operator fails to lock Rod Deselect
push button in Deselect position
0.003
Table 20-12, item 10
3
Operator fails to ﬁnd All Rods button
0.003
Table 20-12, item 2
4
Operator fails to verify all 164 rods
indicate:—(double dash)
0.001
Table 20-11, item 1
aFrom Reference 5.

146
CHAPTER 10 Human Reliability Analyses
TABLE 10.3
Control Switches
All Rods
CRDM fault
Over travel in
Over Travel Out
Group
Individual drive
Gang drive
—
Rod Select
Rod Deselect
are no speciﬁc instructions as to position of the switches during normal
operations.
For the veriﬁcation of all rods, the operator must look at a well-
laid out mimic of the control rods relative positions to each other.
The background is ﬂat black and the indication lights (light-emitting
diodes, LEDs) are orange. Normally, the LEDs show a number that
is representative of the rod position for any rods that are selected.
If no rods are selected, the display is blank. During a SCRAM, an
emergency shutdown of a nuclear reactor, the indication shows the
double dashed line as the position for each rod.
The shift technical advisor (STA) using the computer also checks
the position of the control rods.
Other factors, commonly called performance shaping factors
(PSFs) need to be considered. These are things such as use of a
checkoff procedure, lighting, switch-layout, experience, time pressure,
dependence, and so on.
The example considers the following PSFs:
Is there a procedure that is followed? The steps are described in
a procedure; however, operators are required to commit the pro-
cedure steps to memory. They are expected to complete the full
SCRAM Actions sequence then refer to the procedure to verify
they have completed all steps. Because of the importance of the
step used in the example, as soon as the SCRAM is identiﬁed the
senior reactor operator is required to ask the reactor operator if all
rods are fully inserted. The individual steps are considered second
nature. Therefore, a value of 0.01 from Table 10.4 will be used.
Is there time pressure to complete the sequence? There is a high
time pressure to complete the sequence. All the actions in the
SCRAM Actions sequence must be completed as soon as practical.

10.4 Quantifying Human Error Probability (HEP)
147
TABLE 10.4
Total HEP Calculations
Step
Original HEP
Procedure
Time pressure
Final HEP
1
0.003
×0.01
×5
0.00015
2
0.003
×0.01
×5
0.00015
3
0.003
×0.01
×5
0.00015
4
0.001
×0.01
×5
0.00005
A rough estimate of the time it normally should take to complete
the SCRAM Actions sequence is 3 min. Therefore, the HEP must
be modiﬁed by the values listed in Table 10.4. In our example,
there is a heavy task load and a dynamic situation. The opera-
tors have experienced numerous SCRAMs during their training so
they should be considered skilled. The value from Table 10.4 is
multiplied by 5.
To calculate the total HEP for the task, the HEPs originally deter-
mined for the steps must be modiﬁed by the factors described above.
The total HEP for a sequence is either the sum or the product
of the individual HEPs. Looking back at the sequence laid out in a
logic tree, it can be seen that the steps in the Verify Rods Inserted
sequence are connected as an AND statement. Therefore, the product
of the individual HEPs is the HEP for the Verify Rods Inserted. This
value is
(0.00015) × (0.00015) × (0.00015) × (0.00005) = 1.7 × E −16
It is clear that this is a very small probability of failure.
If the actions are connected by OR statements then the total HEP
is the sum of the HEPs for the individual steps.
A factor that may need to be considered in some sequences is
dependence. Dependence is the relationship between the tasks. Chapter
10 of NUREG/CR-1278 provides a thorough discussion of how to
determine dependence. In our example, although there is an indepen-
dent check performed, dependence does not need to be considered,
that is, because the STA check does not verify that the operator did

148
CHAPTER 10 Human Reliability Analyses
the Verify Rods Inserted task. It only veriﬁes that the rods are fully
inserted. Dependence would exist if:
• second person veriﬁed any of the steps that the operator did, as
he did them; or
• the STA check in some way veriﬁed the operator had done his
check.
If the check is performed on each step then the dependence PSF
is applied to each step. If the check is performed at the end (i.e., on
the entire sequence) then the dependence PSF is applied to the HEP
for the sequence (6).
10.4.1 Summary Points
• HEP is deﬁned as the probability that when a given task is
performed, an error will occur.
• HEP values may come from NUREG/CR-1278, historical data,
expert advice, testing, or other literature.
• The HEP value used for the step must be recorded, including
the source of the HEP value.
• PSFs need to be considered. They may apply to the HEP values
for the individual steps or the HEP value for the sequence.
• For sequences logically connected using AND gates, the HEP
values are the product of the individual HEP values.
• For sequences logically connected using OR gates, the HEP
values are the sum of the individual HEP values.
10.5 DOCUMENTATION
As a rule of thumb, the documentation must be adequate so that the
results of the HRA can be reproduced. This means that it must include
the HRA models and the task analyses. All assumptions and references
must be identiﬁed. Sketches and photographs that support decisions or
assumptions also should be included. This does not mean that all ﬁeld
notes, operator interviews, and so on need to be in the ﬁnal report.
They should be retained as supporting documents.

10.6 Use of Human Reliability Analysis Techniques for Analyzing Procedures
149
The methodology described above shows several tables and lists.
These can be consolidated in the ﬁnal product.
10.5.1 Summary Points
• The documentation must be adequate so that the results of the
HRA can be reproduced.
• Lists tables, and so on can be combined in the ﬁnal report.
10.6 USE OF HUMAN RELIABILITY
ANALYSIS TECHNIQUES FOR ANALYZING
PROCEDURES
HRA techniques should be reserved for the most critical procedures.
For instance, HRA should not be used for analyzing simple main-
tenance procedures because of the cost of performing the analysis.
However, for critical operations, it is appropriate. Determining where
recovery actions, such as inspection steps, should be in procedures is
the best use of HRA techniques. Tools such as Tool for Human Error
Analysis (THEA) (5) can be used for such analyses. The following
analysis shows how HRA can be used to determine where recovery
actions should be placed.
A modiﬁed coolant ﬂush procedure will be used as the basis of
the example. Procedure is listed as follows
10.6.1 Procedure
Warning: cooling system must be below 100◦F prior to draining.
1. Begin with the engine cold and ignition off. Remove the radi-
ator pressure cap.
Warning: ethylene glycol coolant is toxic and must be disposed of
in an appropriate manner.
2. Open the petcock at the bottom of the radiator and drain the
coolant into a bucket.
3. Close the petcock and ﬁll the radiator with water.
4. Start the engine and turn the heater control to hot. Add cooling
system cleaner and idle the engine for 30 min (or as per the
instructions on container).

150
CHAPTER 10 Human Reliability Analyses
1. Mechanic fails to
ensure engine is
cool.
2. 2nd mechanic
fails to ensure
engine is cool.
3. Mechanic fails to
dispose of coolant
properly.
4. Coolant disposal
technician fails to dispose of
coolant properly.
Recovery path
Recovery path
FIGURE 10.5
HRA event structure of coolant ﬂush procedure.
Warning:cooling system must be below 100◦F prior to draining.
5. Stop the engine and allow it to cool for 5 min. Drain the system.
6. Close the petcock, ﬁll the radiator with water and let the engine
idle for 5 min.
7. Repeat step No. 5. Close the petcock.
8. Install new 50 : 50 mixture of water/nontoxic antifreeze/coolant.
Figure 10.5 is an HRA event tree representation of the procedure.
Eight failure paths were found for this procedure. Some of these failure
paths are more critical than others. Adding a recovery step will greatly
reduce the probability of a failure (see Reference 6 for a complete
discussion of recovery and dependency). However, an inspection or
other recovery step should be included if the PHA or FMEA/FMECA
has shown these steps as being critical. For instance, if there is a
0.01 probability of a failure and an inspection step is added that has a
probability of failure of 0.1 then the probability of failure is reduced
by a factor of 10.
(procedure step) 0.001 × (Inspection step) 0.1 = 0.001
In this procedure, the critical steps are those dealing with the
temperature of the cooling system and the toxicity of the coolant. Note
that dashed lines are used to indicate the recovery actions. Therefore,
inspection steps are added after steps 1, 2, 5, and 8. Steps 1 and 2,
including the inspection steps, are listed in the following section.

References
151
1. Mechanic fails to
ensure engine is cool
2. Second mechanic
fails to ensure
engine is cool
3. Mechanic fails to
dispose of coolant
properly
4. Coolant disposal
technician fails to dispose of
coolant properly
Recovery
path
Recovery path
FIGURE 10.6
Modiﬁed event tree.
10.6.2 Procedure with Inspection Steps
Warning: cooling system must be below 100◦F prior to draining.
1. Begin with the engine cold and ignition off.
2. Second mechanic veriﬁes engine is cool.
3. Remove the radiator pressure cap.
Warning: ethylene glycol coolant is toxic and must be disposed of
in an appropriate manner.
4. Open the petcock at the bottom of the radiator and drain the
coolant into a bucket.
5. Coolant disposal technician is contacted for disposing of
coolant.
Figure 10.6 shows how the HRA event tree would be modiﬁed
for steps 1 and 2.
REFERENCES
1. Ostrom LT, Wilhelmsen CA. THEA–Tool for Human Error Analysis, Presented
at the System Safety Society Conference, Seattle, WA, September 1998.
2. Galliers J, Sutcliffe S, Minocha S. An impact analysis method for safety—critical
user interface design. ACM Trans Comput Hum Interact 1999; 6(4): 341–369.
3. Guidelines for Hazard Evaluation Procedures, Battelle Columbus Division, The
Center for Chemical Process Safety; New York 1985.

152
CHAPTER 10 Human Reliability Analyses
4. Richei A, Hauptmanns U, Unger H. The error rate assessment and optimizing
system (HEROS). Reliab Eng Syst Saf 2001; 72.
5. Swain AD, Guttman HE. Handbook of Human Reliability Analysis with Emphasis
on Nuclear Power Plant Applications. Washington (DC): US Nuclear Regulatory;
1983. NUREG/CR-1278.
6. Gertman DI, Blackman HS. Human Reliability and Safety Analysis Handbook.
New York: John Wiley & Sons; 1994.

CHAPTER 11
Critical Incident
Technique
11.1 INTRODUCTION
A technique that has applicability to a wide range of risk assessments
is the critical incident technique (CIT). Forms of the CIT have been
in existence since the 1930s and were further developed by Colonel
John C. Flanagan during World War II (1, 2). CIT is a set of pro-
cedures used for collecting direct observations of human behavior
that have critical signiﬁcance and meet methodically deﬁned crite-
ria. CIT aids in the development of speciﬁc failure pathways that
can later be further developed into event, fault, or human reliability
event trees. The following discusses CIT and presents examples of
its use.
11.2 METHOD
As with the Delphi process, CIT can be conducted in many ways.
Kanki and Hobbs (3) used this form of CIT to develop process maps
of aviation maintenance and inspection tasks.
Risk Assessment: Tools, Techniques, and Their Applications, First Edition.
Lee T. Ostrom, Cheryl A. Wilhelmsen.
2012 John Wiley & Sons, Inc. Published 2012 by John Wiley & Sons, Inc.

154
CHAPTER 11 Critical Incident Technique
Process mapping is a technique that produces visual representa-
tions of the steps involved in industrial or other processes. This is
why it can be such a useful technique for developing initial failure
paths. It was originally developed for use in manufacturing industries
but has subsequently become a common tool in many industries
worldwide. Process mapping has been standardized by the American
National Standards Institute (ANSI); however, the system included
with the Microsoft Visio software has also become widely used.
Process maps have been found to be invaluable in revealing areas
for improvement in processes, including obstacles, bottlenecks, areas
where personnel lack formal guidance, coordination problems, and
problems with equipment or other hardware. Because of this, process
maps can also be used as the bases of simulations of industrial
processes.
Even in businesses where established systems have been in place
for many years, process maps can help to clarify the steps that are actu-
ally carried out, the people who perform the tasks, and the points at
which communication occurs. Although manuals and procedure docu-
ments are usually available, in many cases, only when information is
gathered from the people on the “shop ﬂoor” can the actual operational
steps in the process be established.
Process mapping involves describing the steps involved in a
process and placing them in time order. Each step is described and
identiﬁed as involving decisions, reference to documents, commu-
nication, inspection activities, or other specialized steps. Process
mapping is ideally suited to processes such as the maintenance of
aircraft (4).
The following discusses how Kanki and Hobbs (3) are using CIT
to develop process maps of aviation maintenance and inspection tasks
related to aircraft structural composite material. Their objective was
to describe the activities involved in the maintenance and inspection
of composite structures at different maintenance, repair, and over-
haul (MRO) operators, ultimately producing a single generic process
map for this process that will have applicability across operators. The
process-based modeling method could then be used to identify areas
of operational risk where future tools, techniques, or other aids could
prove useful.

11.2 Method
155
The CIT process used began with structured interviews conducted
with representatives of each of the following aviation professional and
trade groups:
• Aviation maintenance technicians (AMTs);
• Ramp personnel;
• Engineering staff;
• Inspectors;
• Composite shop personnel;
• Maintenance control.
Structured interviews were held with a cross section of aviation
personnel drawn from the groups outlined above. The interviews fol-
lowed a standard format. Participants received an introduction to the
project, including an explanation of the aims of the project, and how
their expertise would assist in achieving the goals of the project. Partic-
ipants were then asked to describe their job and their work experience.
During this introductory segment of the interview, participants were
free to mention any issues they wished to raise relevant to composite
structures.
A general ﬂow of the process as it was understood at that point
was explained; participants were then asked to describe from their
own experience a speciﬁc incident in which potential damage to a
structure was discovered, via a scheduled inspection, an unrelated task,
or the detection of a hazardous event. Their experience with previous
interviews found it most beneﬁcial to focus the participant’s attention
on a single case, rather than asking them to consider the entire range
of potential airworthiness issues during the interview.
As participants described an incident, the sequence of events was
laid out in front of them using paper notes or labels. This enabled
participants to comment on the ﬂow of events, rearrange the order of
events if necessary, and add detail to ensure that a complete picture
of the process was obtained. As the events were displayed in front of
the participant, open-ended probe questions were used to ensure that
the trade group of the people involved in each stage were identiﬁed
(e.g., AMTs, ramp personnel, pilots) and the location of the step was

156
CHAPTER 11 Critical Incident Technique
speciﬁed (e.g., gate, hangar, composite shop). Green-colored notes
were used to identify the tools, documents, and other resources nec-
essary to perform the step. Red notes were used to identify problem
areas that could interfere with the step.
The nature of the step was also identiﬁed as belonging to one of
the following categories:
• Decision;
• Inspection;
• Creation of document, entry of information, signature, or stamp;
• Communication (face to face, phone, or e-mail);
• Movement of aircraft or component;
• Repair;
• Obtain approval;
• Other.
The goal was to have a process ﬂow or map developed at the end
of each participant interview. Figure 11.1 shows the type of process
map that would be developed from each participant interview.
The desktop process maps created during the interviews were
converted into initial process maps using the methods and symbols
Source: Courtesy of Kanki and Hobbs.
FIGURE 11.1
Process map from interview.

11.3 Building on the Results of a Critical Incident Technique Session
157
Beginning/ending
of flow
Decision
Inspection
Delay
Documentation Direction of flow
Task/step
Communication
FIGURE 11.2
Process map symbols.
of the Microsoft Visio process mapping system (Mic11). Figure 11.2
shows the symbols used to populate the process charts.
Initial process maps for each participant were then combined into
a generic process map for each trade group at each MRO organization
as shown in Figure 11.3. In many cases, this involved removing case-
speciﬁc details in order to express the general sequence of events.
Process maps for each trade group at each MRO organization were
then combined into a generic overall process map for each operator.
To date, Kanki and Hobbs have developed generic process maps
for four MRO operations sites.
The beauty of the technique is it provides insights into a process
from the performer’s perspective. The technique is simple to apply,
but a large number of participants might be required to provide a broad
enough perspective of the process. Qualitative researchers use the term
saturation in regard to when enough data is collected from interviews
for the purpose of developing an understanding of a phenomenon (5).
It is the judgment of the researcher as to when saturation is reached.
Therefore, an exact number of participants is difﬁcult to calculate
before the interview process begins. Once data saturation occurs, no
further data need be collected.
11.3 BUILDING ON THE RESULTS
OF A CRITICAL INCIDENT TECHNIQUE
SESSION
The process ﬂow or map is just the ﬁrst step in the development
of a risk assessment, using the CIT. The process map can be used to
guide future interviews on the process with the intent of eliciting other

158
CHAPTER 11 Critical Incident Technique
Participant 1
Hand over process to
person B
Perform
inspection
X
Decision
point 1
Perform
step X
Create
document
Receive notification
from person A
Combined flow
Hand over process to
person B
Create
document
Perform
inspection
Y
Perform
step X
Decision
point 1
Perform
inspection
X
Event 1
occurs
Create
document
Create
document
Create
document
Participant 2
Perform
inspection
Y
Create
document
Event 1
occurs
FIGURE 11.3
Generic process map for trade group.
pertinent facts about a process of failure path. Figure 11.4 is a simple
process map of an incident.
The risk analyst can then use this process map as a guide for
interviewing participants on the attributes of the process. There are
ﬁve steps in this process. The questions a risk analyst might ask for
each step include the following.
Step 1: Ramp Agent observes Anomaly
on Aircraft Cargo Door
1. Approximately, how big was the anomaly?
2. Could you describe its appearance?
3. Do you normally perform a visual inspection of the cargo door
and/or is this a part of your normal job requirements?

Ramp agent
observes anomaly on
aircraft cargo door
Ramp agent
discusses damage
with supervisor
Ramp agent discusses
decision to report
damage to maintenance
control with supervisor
Ramp agent
decides to report damage
to maintenance
control
Ramp agent shows
maintenance
control the damage
FIGURE 11.4
Simple incident process map.
159

160
CHAPTER 11 Critical Incident Technique
4. Were you following a procedure when you performed the
inspection?
5. What time of day was it?
6. Was it overcast?
7. Was it bright sunshine?
8. If at night, did you use a ﬂashlight?
9. How did you perceive the lighting to be?
10. Do you wear corrective lenses?
11. Was it very noisy?
12. Were you wearing hearing protection?
13. Was anything obscuring your vision?
14. Was it hot or cold at that time?
15. Was the panel generally clean or dirty when you observed the
damage?
16. How often do you ﬁnd anomalies?
17. In your rough estimation, what is the probability that you could
ﬁnd such anomaly in the future?
Step 2: Ramp Agent Discusses Damage with
Supervisor
1. How is your relationship with your supervisor?
2. Did you show the damage to your supervisor?
3. What was your supervisors response?
4. Did the supervisor provide any guidance on reporting the dam-
age without your input?
Step 3: Ramp Agent Discusses Decision to
Report Damage to Maintenance Control with
Supervisor
1. How receptive was the supervisor in your desire to report the
damage?

11.3 Building on the Results of a Critical Incident Technique Session
161
2. Did the supervisor provide any insight into reporting the dam-
age?
3. Where did you discuss this?
Step 4: Ramp Agent Decides to Report Damage
to Maintenance Control
1. Why did you decide to report the damage to maintenance con-
trol?
2. Were you following a procedure or protocol when you reported
the damage?
3. In the past, were you rewarded for reporting damage?
4. What do you feel the consequences would be if you did not
report the damage?
5. How was your report received?
Step 5: Ramp Agent Shows Maintenance Control
the Damage
1. Had conditions changed from your initial observations?
2. How did maintenance control respond to your ﬁnding?
3. How did you feel after this interaction with maintenance con-
trol?
4. Did maintenance control provide you any feedback from your
ﬁnding?
The answers from these questions would then be used to further
ﬂesh out the parameters of the risk assessment.
The same type of process could be used for gaining insights into
hardware failures as well. In this case, the process map would be cre-
ated with the hardware system as the focus. The questions would then
relate to the hardware components’ successes and failures. There is
nothing that would prevent a combined human and hardware analysis
either. In fact, an integrated approach is always of beneﬁt.

162
CHAPTER 11 Critical Incident Technique
11.4 SUMMARY
CIT is a very useful tool in the risk analyst’s kit. The results from these
types of analyses can provide great insists into a process. It is an easy
technique to use but does require enough participants to attain data
saturation prior to the development of process maps or failure paths.
Although the focus of this chapter was on CIT, other accident analysis
techniques can be used as well with good results in the development of
risk assessments. Root cause analysis is, of course, a great technique
to use for aiding in a risk assessment (6). Whatever the technique, the
goal is always the same, develop the best risk assessment model as
possible.
REFERENCES
1. Flanagan J. The critical incident technique. Psychol Bull 1954; 51(4): 327–358.
2. Carlilsle K. Analyzing Jobs and Tasks. Englewood Cliffs (NJ): Educational Tech-
nology Publications; 1986.
3. Kanki B, Hobbs A. Development of An Approach for the Identiﬁcation of Opera-
tional Risks Associated with Inspection, Maintenance, and Repair of Damage: An
Application to Composite Structures. Moffet Field, CA: NASA Ames Research
Center; 2010.
4. Eiff G, Suckow M. Reducing accidents and incidents through control of process.
Special Issue on Aircraft Maintenance Human Factors, Int J Avaiat Psychol 2008;
18(1): 43–50.
5. Denzin NK, Lincoln YS. The Sage Handbook of Qualitative Research. 3rd ed.
Thousand Oaks (CA): Sage Publications; 2005.
6. Eicher R, Knox N. Mort users Manual; 1992.

CHAPTER 12
Event Tree and Decision
Tree Analysis
Two of the largest nuclear accidents, Three Mile Island and Cher-
nobyl, partially resulted from decisions made on the part of the power
plant operating or engineering staff. In the case of Chernobyl, the
accident was the result of a very bad decision on the part of the engi-
neering staff who decided to run a test while the reactor was at low
power. Three Mile Island accident, on the other hand, was initiated
by a hardware failure but escalated when the operating crew decided
to switch off the automatic safety system. The case study at the end
of the chapter will analyze a portion of the Chernobyl event using an
event tree.
12.1 EVENT TREES
An event tree is a graphical representation of a series of possible
events in an accident sequence. Using this approach assumes that as
each event occurs, there are only two outcomes, failure or success.
A success ends the accident sequence and the postulated outcome is
either the accident sequence terminated successfully or was mitigated
successfully. For instance, a ﬁre starts in a plant. This is the initi-
ating event. Then the ﬁre suppression system is challenged. If the
Risk Assessment: Tools, Techniques, and Their Applications, First Edition.
Lee T. Ostrom, Cheryl A. Wilhelmsen.
2012 John Wiley & Sons, Inc. Published 2012 by John Wiley & Sons, Inc.

164
CHAPTER 12 Event Tree and Decision Tree Analysis
TABLE 12.1
Accident Sequence
Event
Description
Possible outcomes
Fire
This is the initiating event
—
Fire suppression
system actuates
The ﬁre suppression system
detects the ﬁre and it
actuates
Success—system actuates
and controls the ﬁre
Failure—system fails to
control the ﬁre
Fire alarm system
actuates
Fire alarm system detects the
ﬁre and sends a signal to
the appropriate ﬁre
department. Fire department
arrives in time to extinguish
the ﬁre before major
damage occurs
Success—ﬁre is
extinguished prior to
major damage occurring
Failure—ﬁre causes
major damage
system actuates, the ﬁre is extinguished or suppressed and the event
sequence ends. If the ﬁre suppression system fails then the ﬁre is
not extinguished or suppressed and the accident sequence progresses.
Table 12.1 shows this postulated accident sequence. Figure 12.1 shows
this accident sequence in an event tree.
As in most of the risk assessment techniques, probabilities can be
assigned to the events and combined using the appropriate Boolean
logic to develop an overall probability for the various paths in the
Initiating event
Event 1
Event 2
End State
Fire
Fire suppression
system actuates
Fire alarm system
sends signal to fire
department
Success
Success
Failure
Failure
Severe
damage 
Moderate
damage 
Minimal
damage
FIGURE 12.1
Event tree.

12.1 Event Trees
165
Initiating event 
Event 1 
Path probability 
End State
Event 2
Fire
Fire suppression
system actuates 
Fire alarm system
sends signal to fire
department
 
 
 
0.001 × 0.99 =
0.00099 or 0.001
0.001 × 0.01 ×
0.995 =
0.00000995 or
0.00001
0.001 × 0.01 ×
0.005 =
0.00000005 
Failure
Success
Failure
Success
Severe
damage 
Moderate
damage 
Minimal
damage
FIGURE 12.2
Event tree with path probabilities.
event. Using our example from above, we will now add probabilities
to the events and show how the probabilities combine for each path.
Figure 12.2 shows the addition of path probability to the event tree.
Table 12.2 summarizes the probabilities for this event sequence.
TABLE 12.2
Event Sequence with Probabilities
Event
Description
Possible outcomes
Probability
Fire
This is the
initiating event
—
0.001
Fire suppression
system
actuates
The ﬁre
suppression
system detects the
ﬁre and it actuates
Success—system
actuates and
controls the ﬁre
0.99
Failure—system
fails to control the
ﬁre
0.01
Fire alarm
system
actuates
Fire alarm system
detects the ﬁre
and sends a signal
to the appropriate
ﬁre department.
Fire department
arrives in time to
extinguish the ﬁre
before major
damage occurs
Success—ﬁre is
extinguished prior
to major damage
occurring
0.995
Failure—ﬁre
causes major
damage
0.005

166
CHAPTER 12 Event Tree and Decision Tree Analysis
The result of this analysis tells us that the probability derived
for a ﬁre in which the ﬁre suppression system actuates and the
consequence is minimal damage is approximately 1/1000 or 1 × 10−3.
The probability derived for a ﬁre in which the ﬁre suppression
system fails to actuate but a ﬁre alarm signal is successfully
transmitted to the local ﬁre department and there is only moderate
damage is 1/100,000 or 1 × 10−5. Finally, the probability that
a ﬁre occurs and both the ﬁre suppression system and the ﬁre
alarm system fail and severe damage occurs is 5/10,000,000 or
5 × 10−8.
This approach is considered inductive in nature. Meaning the sys-
tem uses forward logic. A fault tree, discussed in this chapter, is
considered deductive because usually the analyst starts at the top event
and works down to the initiating event. In complex risk analyses, event
trees are used to describe the major events in the accident sequence
and each event can then be further analyzed using a technique most
likely being a fault tree. Figure 12.3 shows a much more complicated
event tree. It is part of the events from an analysis of a small-break
loss-of-coolant accident (LOCA) (1). Again, note this is not the com-
plete event tree, only a portion. Each of the events then comprises a
fault tree of its own. The entire analysis then feeds into a probabilistic
risk assessment.
Initiating event 
Event 2
Event 3
Event 4
Event 1
 
 
 
 
Small break loss
of coolant
accident
 
 
 
 
Reactor
trips
Auxiliary
feedwater
High pressure
injection
 
Feed
and
bleed
NO
NO
NO
NO
YES
YES
YES
YES
FIGURE 12.3
Event tree for a portion of a small-break LOCA.

12.1 Event Trees
167
12.1.1 Case Study
Transportation accidents involving hazardous materials, HazMat,
occur every day in the United States and around the world. On
May 01, 2001, in Ramona, Oklahoma, an accident occurred which
resulted in the release and explosion of hydrogen gas. A semitrailer
that contained horizontal mounted gas ﬁlled cylinders and a pickup
truck were involved in the accident. Both of these vehicles were
traveling northbound on Interstate 75 south of the town of Ramona,
OK. According to witnesses, the pickup truck veered into the path
of the semitrailer causing it to go out of control ﬂipping on its side,
and traveling 300 ft before it came to rest, the pickup truck also ran
off the road causing a rupture in the vehicles gas line igniting a ﬁre.
During the initial stages of the accident, relief valves were broken
off causing a leak of the hydrogen gas. According to the National
Transportation Safety Board (NTSB) report the semitrailer driver was
killed and the pickup truck driver was seriously injured.
At 14 : 15, the 911 dispatch center was notiﬁed of the incident,
and the local ﬁre department (Ramona Volunteer Fire Department)
was notiﬁed; at 14 : 16, the Washington County Emergency Manage-
ment Agency (EMA) started responding to the scene; between 14 : 16
and 14 : 21, an Air Gas employee driving southbound sees the vehicle
and notiﬁes the Air Gas corporation; the driver of the pickup truck
was extricated from the vehicle by local bystanders. 14 : 21 the Wash-
ington County Emergency Medical Service (EMS) requests assistance
from a private hazardous materials response team; 14 : 22, the Chief of
the local ﬁre department arrives and directs the ﬁreﬁghters to “cool”
the burning cylinders; the Washington County EMA requests addi-
tional manpower for mutual aid companies. 14 : 22 other ﬁreﬁghters
not involved in active ﬁreﬁghting attempt to extricate the truck driver.
14 : 25 the Emergency Operations Center (EOC) and emergency plan
are activated by the Washington County EMA. 14 : 30 Washington
County EMA and Oklahoma State Patrol ofﬁcer trained in hazardous
materials arrives on scene. 14 : 40 extrication attempts halt because of
the lack of water to suppress the ﬁre coming from the cylinders. The
Washington County EMA and Phillips Petroleum DART commander
advise the ﬁreﬁghters to stay away from the ends of the burning tanks
in the event of an explosion. 15 : 00 the Air Gas executive team arrives
on scene and offers assistance to the incident command team. 15 : 11

168
CHAPTER 12 Event Tree and Decision Tree Analysis
Initiating event
 
 
Event 1
Event 2
Event 3
Event 4
End State
 
 
 
Gas delivery
truck accident
 
 
Vehicle gas lines
rupture
 
Fire ignites
 
Gas bottles
leaking
 
Fire ignites
hydrogen
 
 
 
Catastrophic
fire
Major vehicle
fire
Major vehicle
fire
Fuel spill
Vehicle
accident
NO
NO
NO
NO
YES
YES
YES
YES
FIGURE 12.4
Event tree for Tulsa event ﬁgure.
the Tulsa OK HazMat team is requested to aid. 15 : 15 the truck driver
is extricated from the vehicle. 15 : 30–15 : 35 the Tulsa Hazardous
Materials team arrives on scene and assumes command. 1600 Air Gas
executive team member and safety director offers assistance to the
Tulsa OK HazMat team with their own response team called AERO.
17 : 15 the AERO team members arrive on scene. 18 : 30–18 : 40 the
scene is declared controlled and the Tulsa OK HazMat team goes into
service. At 00 : 20 the AERO team advises command that the cylinders
have vented and are properly cooled. 00 : 55 command is turned over
to the Oklahoma State Patrol, active ﬁreﬁghting, Hazardous Materials
response is terminated, 06 : 00 the highway then reopens (2).
An event tree can be used to represent the major events in this
accident sequence and can be used in the future by emergency response
personnel to determine what the critical events in the sequence were.
Figure 12.4 shows the event tree for this accident sequence.
12.2 DECISION TREES
Decision analysis is a very large topic, and there are risk profession-
als who are specialized only in decision analysis. In this book, we
will not attempt to present even a fraction of all the decision analysis

12.2 Decision Trees
169
tools available. In fact, we will focus on two types of decision trees.
Decision analysis and their associated tree analysis techniques assume
that a decision is being made under risk. All decisions have some risk
associated with them. The launch of the Challenger in 1986 was made
under risk. The obvious consequence of this decision was the loss of
the orbiter (3). We all make decisions everyday that affect our fam-
ily’s safety, ﬁnancial security, and health. Some of our decisions also
have the potential of affecting many other people as well. Elected ofﬁ-
cials, military leaders, heads of large corporations, and even university
presidents make decisions that can have far reaching effects.
The decisions concerning driving are some of the most important
ones we make. Driving is still one of the most hazardous things we
do. During an average year, approximately 35,000 people die from
car accidents in the United States. Decisions drivers make contribute
to a large number of these accidents. Drinking alcohol while driv-
ing is directly associated with approximately 12,000 persons dying in
alcohol-related trafﬁc accidents in 2008 (4).
There are several styles of decision trees. The style presented here
is one that is commonly used in industry. Inﬂuence diagrams are a
close cousin to this style of decision tree (5).
This style of decision tree is commonly used in production settings
to help determine the best alternative among many. Figure 12.5 shows
Decision
node
Alternatives
Chance
nodes
States of
nature
Consequence
nodes
FIGURE 12.5
Decision tree 1 format.

170
CHAPTER 12 Event Tree and Decision Tree Analysis
the general conﬁguration of this decision tree. For this tree, it is best
to provide an example and then work through the process.
12.2.1 Problem
In this scenario, you are evaluating four systems. Table 12.3 contains
the information about the systems.
Figure 12.6 shows the decision tree for this scenario.
TABLE 12.3
Decision Tree 1 Analysis
Probability of success and postulated related beneﬁts
System
Cost
Good, 0.30
Moderate, 0.50
Poor, 0.20
A
1,000,000
100,000,000
25,000,000
−4,000,000
B
750,000
80,000,000
35,000,000
−1,000,000
C
1,500,000
125,000,000
45,000,000
0
D
450,000
95,000,000
65,000,000
−80,000,000
System C
58,500,000
A
$1M
B
$750k
C
$1.5M
Good 0.30 X $100M
$30,000,000 
D
$450k
Moderate 0.50 X $25M
$12,500,000
Poor 0.20 X (-) $4M
(-)$800,000 
Good 0.30 X $80M
$24,000,000
Moderate 0.50 X 35M
$37,500,000
Poor 0.20 X (-)$1M
(-)$200,000
Good 0.30 X $125M
$37,500,000 
Moderate 0.50 X $45M
$22,500,000
Poor 0.20 X 0
0
Good 0.30 X $95M
$28,500,000 
Moderate 0.50 X $65M
$32,500,000
Poor 0.20 X (–)$80M
(–)$1.6M
Best
benefit
System
FIGURE 12.6
Decision tree 2.

12.2 Decision Trees
171
The following shows how the ﬁnal outcomes are derived from the
data.
System A
0.3 × 100,000,000 = 30,000,000
0.5 × 25,000,000 = 12,500,000
0.2 × (−)4,000,000 = (−)800,000
Average beneﬁt = $41,700,000
Cost is 1,000,000
Net beneﬁt = Beneﬁt −Cost = 41,700,000 – 1,000,000 =
$40,700,000
System B
0.3 × 80,000,000 = 24,000,000
0.5 × 35,000,000 = 17,500,000
0.2 × (−)1,000,000 = (−)200,000
Average beneﬁt = $41,300,000
Cost is 750,000
Net beneﬁt = Beneﬁt −Cost = 41,300,000 – 750,000 =
$40,550,000
System C
0.3 × 125,000,000 = 37,500,000
0.5 × 45,000,000 = 22,500,000
0.2 × 0 = 0
Average beneﬁt = $60,000,000
Cost is 1,500,000
Net beneﬁt = Beneﬁt −Cost = 60,000,000 – 1,500,000 =
$58,500,000
System D
0.3 × 95,000,000 = 28,500,000
0.5 × 65,000,000 = 32,500,000

172
CHAPTER 12 Event Tree and Decision Tree Analysis
0.2 × (−)80,000,000 = (−)1,600,000
Average beneﬁt = $45,000,000
Cost is 450,000
Net beneﬁt = Beneﬁt −Cost = 45,000,000 – 450,000 =
$44,550,000
So, how is this information used? Well, obviously, this is a con-
trived example and all of the options have great beneﬁt. System C
provides the best return on the investment. The other three options
are pretty much a wash. Another beneﬁt of System C is that there is
no potential for a negative outcome. An organization might be very
sensitive to not having any potential for a negative consequence.
This style of decision tree can easily be modiﬁed to provide
insights into safety attributes as well. Organizations place monetary
value on accident risks and consequences. For this example, we will
use the relationships in Table 12.4 to help develop this example.
In this scenario, we are evaluating three safety systems for a
process plant. The descriptions for these systems are contained in
Table 12.5.
The next step is to convert the accident data into costs. This is
shown in Table 12.6.
Figure 12.7 shows the decision tree that was developed for this
analysis.
In this scenario, instead of subtracting out the cost of the system,
we add it to the calculated cost. Performing the math generates the
following decision criteria.
TABLE 12.4
Accident Classiﬁcation and Associated Cost
Accident type
Description
Relative cost
Class A
Fatality or loss of property in excess
of $1,000,000
$1,000,000
Class B
Disabling injury or property loss
between $100,000 and $1,000,000
$100,000
Class C
Lost work day injury or property loss
between $10,000 and $100,000
$10,000
Class D
OSHA recordable injury or minor
property damage
$5,000

12.2 Decision Trees
173
TABLE 12.5
Probability of Accidents
Probability and
System
Description
Cost
associated cost
A
This system will provide
a high degree of safety
but has a high cost
$2,000,000
0.10: 1 Class A accident
0.30: 3 Class B accidents
0.20: 1 Class A and 3
Class C accidents
0.40: 1 Class D accident
B
The system will provide a
moderate degree of
safety at a moderate cost
$1,000,000
0.05: 2 Class A accidents
0.40: 1 Class A accident
and 4 Class B accidents
0.30: 5 Class B accidents
and 4 Class C accidents
0.25: 2 Class C accidents
and 6 Class D accidents
C
This system will provide
a marginal degree of
safety at a low cost
$500,000
0.20: 3 Class A accidents
0.40: 2 Class A accidents
and 5 Class B accidents
0.30: 1 Class A accidents
and 4 Class B accidents
0.10: 4 Class D accidents
System A
0.10 × $1,000,000 = $100,000
0.30 × $300,000 = $90,000
0.20 × $1,030,000 = $206,000
0.40 × $5000 = $2000
Total cost = $100,000+$90,000+$206,000+$2000+$2,000,000
(system cost) = $2,398,000
System B
0.05 × $2,000,000 = $100,000
0.40 × $1,400,000 = $560,000
0.30 × $540,000 = $162,000
0.25 × $50,000 = $12,500

174
CHAPTER 12 Event Tree and Decision Tree Analysis
TABLE 12.6
Cost of Accidents
Probability of
System
Description
Cost
accidents
A
This system will provide
a high degree of safety,
but has a high cost
$2,000,000
0.10: $1,000,000
0.30: $300,000
0.20: $1,030,000
0.40: $5000
B
The system will provide a
moderate degree of
safety at a moderate cost
$1,000,000
0.05: $2,000,000
0.40: $1,400,000
0.30: $540,000
0.25: $50,000
C
This system will provide
a marginal degree of
safety at a low cost
$500,000
0.20: $3,000,000
0.40: $2,500,000
0.30: $1,400,000
0.10: $20,000
Total cost=$100,000+$560,000+$162,000+$12,500+$1,000,000
(system cost) = $1,824,500
System C
0.20 × $3,000,000 = $600,000
0.40 × $2,500,000 = $1,000,000
0.30 × $1,400,000 = $420,000
0.10 × $20,000 = $2000
Total cost = $600,000+$1,000,000+$420,000+$2000+$500,000
(system cost) = $2,522,000
In this example, system B is the clear winner. However, this
example does not take into account the cost of lost business or repu-
tation in the event of a class A accident. These items can be factored
in as well.
For instance, besides the direct cost of a class A accident estimated
at $1,000,000, there might be a loss of business estimated at a cost
of $1,000,000 per occurrence. Therefore, this type of decision tree is
very utilitarian and can be adapted to a wide range of uses.

12.3 Case Study: Chernobyl
175
System B
1,854,500
A
$2M
B
$1M
C
$0.5M
0.10 X $1M
$100,000 
0.30 X $300k
$90k
0.20 X $1.03M
$206k
0.40 X $5k
$2k
0.30 X $1.4M
$420k
0.40 X $1.4M
$560k
0.30 X $540k
$162k 
0.25 X $50k
$12.5k
0.40 X $2.5M
$1M
Least cost 
System
0.05 X $2M
$100k
0.10 X $20k
$2k
0.20 X $3M
$600k 
FIGURE 12.7
Decision tree 3.
12.3 CASE STUDY: CHERNOBYL
On 25 April, 1986, prior to a routine shutdown, the reactor crew at
Chernobyl 4 began preparing for an experiment to determine how long
turbines would spin and supply power to the main circulating pumps
following a loss of main electrical power supply. This test had been
carried out at Chernobyl the previous year, but the power from the
turbine ran down too rapidly, so new voltage regulator designs were
to be tested (6).
Multiple operator actions, including the disabling of automatic
shutdown mechanisms, preceded the attempted experiment on the
morning of April 26. By the time that the operator began to shut down

176
CHAPTER 12 Event Tree and Decision Tree Analysis
the reactor, it was in an extremely unstable condition. The design of
the control rods caused a dramatic power surge as they were inserted
into the reactor.
The interaction of extremely hot fuel with the cooling water led to
fuel disintegration, along with rapid steam production and an increase
in reactor pressure. The design characteristics of the reactor were
such that substantial damage to even three or four fuel assemblies
could—and did—result in the failure of the reactor vessel. Extreme
pressure in the reactor vessel caused the 1000 ton cover plate of the
reactor to become partially detached. The fuel channels were damaged
and the control rods jammed, which by that time were only halfway
down. Intense steam generation then spread throughout the entire core.
The steam resulted from water being dumped into the core because
of the rupture of the emergency cooling circuit. A steam explosion
resulted and released ﬁssion products to the atmosphere. A second
explosion occurred a few seconds later that threw out fuel fragments
and blocks of hot graphite. The cause of the second explosion has
been disputed by experts, but it is likely to have been caused by the
production of hydrogen from zirconium–steam reactions.
Two workers died as a result of these explosions. The graphite
(about a quarter of the 1200 tons of it was estimated to have been
ejected) and fuel became incandescent and started a number of ﬁres,
causing the main release of radioactivity into the environment. A total
of about 14 EBq (14 × 1018 Bq) of radioactivity was released, over
half of it being from biologically inert noble gases.
About 200–300 tons of water per hour was injected into the intact
half of the reactor using the auxiliary feed water pumps. However, this
was stopped after half a day because of the danger of it ﬂowing into
and ﬂooding units 1 and 2. From the second to tenth day after the
accident, some 5000 tons of boron, dolomite, sand, clay, and lead
were dropped on to the burning core by helicopter in an effort to
extinguish the blaze and limit the release of radioactive particles.
It is estimated that all of the xenon gas, about half of the iodine
and cesium, and at least 5% of the remaining radioactive material in
the Chernobyl 4 reactor core (which had 192 tons of fuel) was released
in the accident. Most of the released material was deposited close to
the reactor complex as dust and debris. Lighter material was carried
by wind over the Ukraine, Belarus, Russia, and to some extent over
Scandinavia and Europe.

12.3 Case Study: Chernobyl
177
The casualties included ﬁreﬁghters who attended the initial ﬁres
on the roof of the turbine building. All these were put out in a few
hours, but radiation doses on the ﬁrst day were estimated to be up to
20,000 mSv, causing 28 deaths—6 of which were ﬁremen—by the
end of July 1986.
The Soviet Government made the decision to restart the remain-
ing three reactors. To do so, the radioactivity at the site would have
to be reduced. Approximately 200,000 people (“liquidators”) from all
over the Soviet Union were involved in the recovery and cleanup dur-
ing the years 1986 and 1987. Those individuals received high doses of
radiation, averaging around 100 mSv. Approximately 20,000 of the liq-
uidators received about 250 mSv and a few received 500 mSv. Later,
their numbers swelled to over 600,000 but most of them received only
relatively low radiation doses.
Causing the main exposure hazard were short-lived iodine-131
and caesium-137 isotopes. Both of these are ﬁssion products dispersed
from the reactor core, with half-lives of 8 days and 30 years, respec-
tively (1.8 EBq of I-131 and 0.085 EBq of Cs-137 were released).
About 5 million people lived in areas contaminated (above 37 kBq/m2
Cs-137), and about 400,000 lived in more contaminated areas of strict
control by authorities (above 555 kBq/m2 Cs-137).
Approximately 45,000 residents were evacuated from within a
10 km radius of the plant, notably from the plant operators’ town
of Pripyat on May 2 and 3. On May 4, all those living within a
30 km radius—a further 116,000 people from the more contami-
nated area—were evacuated and later relocated. Approximately 1000
of those evacuated have since returned unofﬁcially to live within the
contaminated zone. Most of those evacuated received radiation doses
of less than 50 mSv, although a few received 100 mSv or more.
Reliable information about the accident and the resulting contam-
ination was not made available to affected people for about 2 years
following the accident. This led the populace to be distrustful of the
Soviet Government and led to much confusion about the potential
health effects. In the years following the accident, a further 210,000
people were moved into less contaminated areas, and the initial 30 km
radius exclusion zone (2800 km2) was modiﬁed and extended to cover
an area of 4300 km2. This resettlement was owing to the application
of a criterion of 350 mSv projected lifetime radiation dose, although,
in fact, radiation in most of the affected area (apart from half a square

178
CHAPTER 12 Event Tree and Decision Tree Analysis
kilometer) fell rapidly after the accident so that average doses were
less than 50% above normal background of 2.5 mSv/year.
Recent studies have found that the area surrounding the reactors
is recovering, although background radiation levels are approximately
35 times normal background level (7). In fact, in 2010, the area sur-
rounding the reactor site was opened for tourism (8).
The consequences of this event are still felt today. Nuclear power
is viewed as being very dangerous by a large percentage of Ameri-
cans. Those exposed during the event have developed various forms
of cancer. For instance, in Belarus, thyroid cancer rates have risen
2,400% (9). The aftereffects of the event will take many generations
and possibly hundreds of years to resolve.
12.3.1 Analysis of the Event
This event has been analyzed and reanalyzed thousands of times
over the past 2 decades. In fact, in our teaching careers, we have
received hundreds of papers on the subject. Our goal here is to show
how an event can be used to aid in the analysis process. We will
also show how a decision tree could have helped to prevent the
accident.
Initiating event
Event 1
Event 2
Event 3
Event 4
 
 
 
Decision to
conduct
experiment
Reactor in shutdown
mode 
Automatic shutdown
mechanism disabled
Control rod
insertion
End state
NO
NO
NO
Power
surge and
steam
explosion 
YES
YES
YES
Unknown
Normal
shutdown
Unknown
FIGURE 12.8
Chernobyl event sequence.

12.3 Case Study: Chernobyl
179
12.3.2 Event Tree Analysis
As shown above, in the event tree analysis process, the entry point into
the tree is the initiating event. In the Chernobyl event, what was the
initiating event? Was it the reactor shutdown procedure or was it the
TABLE 12.7
Events to be analyzed in Chernobyl Event
Event
Description
Consequence
Alternative
Initiating event
Decision to
conduct
experiment
during reactor
shutdown
The decision to
conduct the
experiment
directly led to
the accident
If the decision to
not conduct this
experiment on an
operating reactor
the event would
not have occurred
Event 1
Reactor in
shutdown mode
This design of
reactor is
unstable at low
power
Maintaining reactor
power and not
doing the
shutdown would
have prevented
the accident
Event 2
Automatic
shutdown
mechanism
disabled
Once the
automatic
shutdown
mechanisms
were disabled,
the reactor
during the
shutdown phase
lost the ability
to be controlled
adequately
Not disabling the
mechanism would
have allowed the
reactor to shut
down normally
Event 3
Control rod
insertion
In this particular
reactor design,
when the
control rods are
inserted, there
can be and was
a rapid increase
in power before
the rods are
fully inserted
It is pure
speculation, but
there is a
possibility that if
the rods had not
been inserted or
inserted at a
different pace the
event would not
have occurred as
it did

180
CHAPTER 12 Event Tree and Decision Tree Analysis
experiment the engineers were running or something else? Table 12.7
lists the important events we will model in this demonstration analysis.
Note that some of the events one might want to model occurred well
before the accident, like the design of the reactor itself. Those events
that occurred after rod insertion were the result of the accident and
the reactor design.
Figure 12.8 shows the event tree developed for this event.
12.4 SUMMARY
Event and decision trees are highly effective tools that have broad
application in providing visual and analytical means to better under-
stand both simple as well as complex events. One can use the tools
to model events in failure, as well as success space to help better
understand them.
REFERENCES
1. NRC NUREG 0933 supplement; 2010.
2. Hazardous materials accident report release and ignition of hydrogen following
collision of a tractor-semitrailer with horizontally mounted cylinders and
a pickup truck near Ramona, Oklahoma May 1, 2001, NTSB/HZM-02/02
PB2002-917003 National Transportation Safety Board Notation 7371A 490 L.
Enfant Plaza, S.W., Adopted September 17, 2002, Washington, DC. Available at
https://www.ntsb.gov/Publictn/2002/HZM0202.htm. Retrieved 2011 Jan 10.
3. Report to the President: Actions to Implement the Recommendations of the
Presidential Commission on the Space Shuttle Challenger Accident. Available
at www.nasa.gov: http://history.nasa.gov/rogersrep/actions.pdf. Retrieved 1986
July 14.
4. Available at www.NHTSA.gov. Retrieved 2010 Dec 28.
5. Detwarasiti A, Shachter R. (n.d.). Inﬂuence diagrams for team decision analysis.
Decis Anal 2005: 2(4):207–228.
6. IAEA Report INSAG-7 Chernobyl Accident. Updating of INSAG-1 Safety Series
No. 75-INSAG-7. IAEA Vienna; 1991. p. 73.
7. Available at www.nuclearpowerdaily.com: http://www.nuclearpowerdaily.com/
reports/Tourists ﬂock to Chernobyl radiation zone 999.html. Retrieved 2011
Feb 17.
8. Available at www.villageofjoy.com: http://villageofjoy.com/chernobyl-today-a-
creepy-story-told-in-pictures/. Retrieved 2011 Feb 17.
9. Available at www.ratical.org: http://www.ratical.org/radiation/Chernobyl/Belarus
2001.html. Retrieved 2011 Jan 28.

CHAPTER 13
Critical Function Analysis
13.1 INTRODUCTION
When one conducts a search for “functional analysis” on any search
engine, a wide range of tools for various uses pops up. Some of
these tools involve analyzing behavior in psychological studies (1),
some involve computer networks (2), and some involve mathematical
analyses (1). Functional analysis techniques can also be used to ana-
lyze complex systems to ensure needed components of a system are in
place and available for use (3). Once again, when a Web search is con-
ducted for the word “function,” a wide range of deﬁnitions come up,
along with where a person can buy “function,” whatever that means.
Dictionarey.com (4) deﬁnes function as follows:
noun 1. the kind of action or activity proper to a person, thing, or
institution; the purpose for which something is designed or exists; role.
This is the deﬁnition that will be used in this chapter for function.
It is the kind of action or activity proper to a person, thing, or insti-
tution or the purpose for which something is designed. For instance,
a screw driver is designed to be used to tighten screws. There are
different types of screw drivers: ﬂat, Phillips, star, hex head, electric,
battery operated, and plain old manual ones. However, sometimes
screw drivers are used for other purposes, such as a hammer, a pry
Risk Assessment: Tools, Techniques, and Their Applications, First Edition.
Lee T. Ostrom, Cheryl A. Wilhelmsen.
2012 John Wiley & Sons, Inc. Published 2012 by John Wiley & Sons, Inc.

182
CHAPTER 13 Critical Function Analysis
bar, or a weapon to name a few. However, the function a screw driver
was designed to perform is to tighten screws. In a full tool kit, a screw
driver has only one function.
The space shuttle Columbia made its ﬁrst ﬂight on April 12, 1981
(5). There had been several ﬂights of the Space Shuttle Enterprise, but
these were test ﬂights and the Orbiter had been carried on or released
from a Boeing 747 (5). The last space shuttle ﬂight occurred on July
8, 2011. The space shuttle Atlantis made this ﬂight (5). The major
functions of the space shuttle ﬂeet were to carry crews and cargo into
Earth orbit. The shuttle was composed of several major components,
of which each had a function.
Table 13.1 contains the major components of any of the space
shuttles of the now retired ﬂeet and their corresponding functions
(6). It is apparent that the Orbiter has many more functions than the
boosters, for instance. Within each component of the system, there
are many if not hundreds of lower level functions associated with the
subcomponents of the system. Table 13.2 lists some of the lower level
functions that comprise the crew life support function of the Orbiter.
Each of the functions listed in Table 13.2 are important. Atmo-
spheric control, temperature control, radiation shielding, and the heat
shield are some of the more important functions. The Columbia acci-
dent was due to the failure of the heat shield component. The heat
shield was damaged during liftoff when a piece of foam insulation
from the external tank broke off and hit the leading edge of the wing
of the Orbiter (7). If that function would have been maintained, the
Orbiter would not have failed.
Nelson and Bagian (8) discuss the concept of critical function
approach or analysis (CFA) and the application of this concept to space
systems. CFA was developed as an analysis tool after the Three Mile
TABLE 13.1
Functions of the Major Components of a Space Shuttle
Component
Major function(s)
Orbiter
Crew life support, propulsion, return vehicle, cargo
transport, docking capability
Boosters
Propulsion
External tank
Fuel storage and supply for main engine in orbiter

13.1 Introduction
183
TABLE 13.2
Lower Level Crew Life Support Functions of Orbiter
Component
Function
Crew cabin
Ensures breathable gases are contained in vessel, provides
living space, and contains other life support systems
Atmospheric control
Supply oxygen to the crew, remove carbon dioxide and
other trace gases, ensure the gas components are in the
proper ratio, and ensure the humidity is at the correct
level
Water system
Produce water in the fuel cells, store water in one of four
tanks, remove bacteria, warm or chill the water, and
route excess water to waste disposal system
Food storage
Supply food to the crew
Radiation shielding
Protect crew from radiation
Heat shield
Protect crew from excessive heat during re-entry
Temperature control
Ensure crew areas are within a livable temperature
Island nuclear accident (9). The basic concept behind this approach is
that within each system, there are a set of critical functions that must
be maintained so that the system does not fail. The heat shielding on
the space shuttle Columbia is an example of a critical component that
maintained a critical function. Once the shielding failed, the space
shuttle failed. There was no recovery at that point because there was
no backup for that critical function. However, there was a backup for
the atmospheric system on the Orbiter. That was the crew space suits.
The space suits had a supply of oxygen that could support the crew
until the shuttle landed.
Two very dramatic commercial airline accidents demonstrate the
importance of functions to safe operation and airworthiness of air-
planes. These are as follows:
• United Flight 232;
• Air Canada Flight 143.
13.1.1 United Flight 232
United Airlines Flight 232 was a scheduled ﬂight from Stapleton Inter-
national Airport in Denver, Colorado, to O’Hare International Airport

184
CHAPTER 13 Critical Function Analysis
in Chicago (10–12). The ﬂight was then scheduled into Philadelphia
International Airport. On July 19, 1989, the DC-10, with tail regis-
tration number N1819U, took off normally at 2:09 pm (14:09). The
plane was in a shallow right turn at 3:16 pm (15:16) at 37,000 ft
when the fan disk of its tail-mounted General Electric CF6-6 engine
failed. The disk disintegrated and the debris was not contained by the
engine’s nacelle, a housing that protects the engine. The disintegrated
disk, along with pieces of nacelle, penetrated the aircraft tail section at
numerous places. This included the horizontal stabilizer. Airplanes are
designed with redundant systems. One of the problems with the DC-
10 design is that components of all three redundant hydraulic systems
are positioned closely together in the horizontal stabilizer. The shrap-
nel from the failed engine punctured the lines of all three hydraulic
systems and the hydraulic ﬂuid drained away rapidly (12).
Despite the loss of all three hydraulic systems, the crew was able
to attain and then maintain limited control by using the two remaining
engines. The crew steered by applying power to one engine over the
other, then gained altitude by applying power to both engines, and
they decreased altitude by reducing power on both engines. The crew
ﬂew the crippled jet to the Sioux Gateway Airport. They lined the
airplane up for landing on one of the runways. Without ﬂight controls,
they were unable to slow down the airplane for landing. The crew
was forced to attempt landing at much too high a speed and rate
of descent. On touchdown, the aircraft broke apart, caught ﬁre, and
rolled over. The largest section came to rest in a cornﬁeld next to the
runway. The crash of the airplane was very intense, but two thirds of
the occupants survived. However, 111 people died in the crash. The
cause of the engine failure was traced back to a manufacturing defect
in the fan disk. Microscopic cracks were found in the parts and there
were determined to be impurities in the castings. The cracking was
present during maintenance inspections and could possibly have been
detected by maintenance personnel (12).
The accident is considered a prime example of successful crew
resource management because of the manner in which the ﬂight
crew handled the emergency. The ﬂight crew, Captain Al Haynes, a
30,000-h pilot, First Ofﬁcer William Records, and Flight Engineer
Dudley Dvorak became well known as a result of their actions
that day, in particular, the captain, Alfred C. Haynes, and a DC-10
instructor on board, who offered his assistance, Dennis E. Fitch (11).

13.1 Introduction
185
13.1.2 Air Canada Flight 143
On July 23, 1983, Air Canada Flight 143, a Boeing 767-200 jet,
registration C-GAUN, c/n 22520/47, ran out of fuel at 41,000 ft
(12,500 m) mean sea level (MSL) altitude (11, 13, 14). The ﬂight
was approximately halfway through its ﬂight from Montreal, Quebec,
to Edmonton, Alberta, via a stop at Ottawa, Ontario. The airplane was
ﬂown from Toronto, Ontario, to Edmonton on July 22, 1983, where
it underwent routine checks. The next day, it was ﬂown to Montreal.
It departed Montreal, following a crew change, as Flight 143 for the
return trip to Edmonton via Ottawa. The Captain for this ﬂight was
Robert (Bob) Pearson and First Ofﬁcer Maurice Quintal at the controls.
At 41,000 ft (12,500 m), over Red Lake, Ontario, the aircraft’s
cockpit warning system sounded, indicating a fuel pressure problem
on the aircraft’s left side. The pilots turned it off assuming it was a
fuel pump failure (10). The crew knew that gravity would still feed
fuel to the aircraft’s two engines, even though the pump had failed.
At this point, the aircraft’s fuel gauges were inoperative. However,
the ﬂight management computer (FMC) indicated that there was still
sufﬁcient fuel for the ﬂight. The pilots subsequently realized the fuel
entry calculation into the FMC was incorrect. A few moments later, a
second fuel pressure alarm sounded. At this point, the pilots decided
to divert to Winnipeg, Manitoba. Within seconds, the left engine failed
and the crew began preparing for a single-engine landing (10).
They tried to restart the left engine and began communicating
their intentions to controllers in Winnipeg. The cockpit warning sys-
tem sounded again, this time with a long “bong” that no one in the
cockpit could recall having heard before (10). This was the “all engines
out” sound, an event that had never been simulated during training.
Within seconds, most of the instrument panels in the cockpit went dark,
in addition, the right-hand side engine stopped and the 767 lost all
power.
This 767-200 was one of the ﬁrst commercial airliners to include
an electronic ﬂight instrument system (EFIS). This system required
the electricity generated by the aircraft’s jet engines to operate. The
system went dead without electrical power. The auxiliary power unit
(APU) is a small jet engine in the tail section of large jet aircraft and
its purpose is to supply electricity, hydraulic power, and pneumatic
air for starting the other jet engines (15). Since there was no fuel,

186
CHAPTER 13 Critical Function Analysis
this engine failed as well. The airplane was left with only a few basic
battery-powered emergency ﬂight instruments. These provided basic
information with which to land the aircraft. However, there was not
a working vertical speed indicator that would be needed to land the
aircraft.
The main engines and APU also supply power for the hydraulic
systems without which the aircraft cannot be controlled. Commercial
aircraft need to have redundant systems to help in the event of this
kind of power failure. Boeing aircraft, such as the 767-200, usually
achieve this through the automated deployment of a ram air turbine
(RAT) (16). This is a small generator driven by a small propeller that is
driven by the forward motion of the aircraft. The higher the airspeed,
the more power the RAT generates. The lower the airplane’s airspeed,
the lower amount of power generated (16).
As the pilots were descending through 35,000 ft (11,000 m), the
second engine shut down. The crew immediately searched their emer-
gency checklist for the section on ﬂying the aircraft with both engines
out. There was no such section to be found. Fortunately, Captain Pear-
son was an experienced glider pilot. This gave him familiarity with
some ﬂying techniques almost never used by commercial pilots. To
have the maximum range and therefore the largest choice of possible
landing sites, he needed to ﬂy the 767 at the “best glide ratio speed.”
Making his best educated guess as to this airspeed for the 767, he ﬂew
the aircraft at 220 knots (410 km/h; 250 mph). First Ofﬁcer Maurice
Quintal began making calculations to see if they could reach Winnipeg.
He used the altitude from one of the mechanical backup instruments.
The distance traveled was supplied by the air trafﬁc controllers in Win-
nipeg. From this he calculated the aircraft had lost 5000 ft (1500 m) in
10 nautical miles (19 km; 12 mi), giving a glide ratio of approximately
12:1 for the airplane. The controllers and Quintal both calculated that
Flight 143 would not make it to Winnipeg (13).
First Ofﬁcer Quintal proposed landing at the former RCAF Station
Gimli. This was a closed air force base where he had once served as a
Canadian Air Force pilot. However, to complicate matters, the airstrip
had been converted to a race track complex that was in use that day
(13). Without power, the pilots had to try lowering the aircraft’s main
landing gear via a gravity drop but, due to the airﬂow, the nose wheel
failed to lock into position. The decreasing forward motion of the
aircraft also reduced the effectiveness of the RAT, making the aircraft

13.2 Critical Functions
187
increasingly difﬁcult to control because of the reduced power being
generated (13).
It became apparent as the ﬂight approached the runway that the
aircraft was too high and too fast. This raised the danger of running
off the runway before the aircraft could be stopped safely. The lack
of adequate hydraulic pressure prevented ﬂap/slat extension. These
devices are used under normal landing conditions to reduce the stall
speed of the aircraft for a safe landing. The pilots considered execut-
ing a 360◦turn to reduce speed and altitude. However, they decided
that they did not have enough altitude for this maneuver. Pearson
decided to execute a forward slip to increase drag and lose altitude.
This maneuver is commonly used with gliders and light aircraft to
descend more quickly without gaining forward speed.
When the wheels touched the runway, Pearson “stood on the
brakes,” blowing out two of the aircraft’s tires (13). The unlocked
nose wheel collapsed and was forced back into its well, causing the
aircraft’s nose to scrape along the ground. The plane also slammed
into the guard rail now separating the strip, which helped slow it down
(13). Because there was no fuel onboard, there was little chance of
a major ﬁre. A minor ﬁre in the nose area was extinguished by rac-
ers and course workers armed with ﬁre extinguishers. None of the 61
passengers were seriously hurt, but there were some minor injuries
when passengers exited the aircraft via the rear slides. The accident
has been nicknamed the “Gimli Glider” in recognition of the ﬂight
crew’s handling of the situation (11, 13).
13.2 CRITICAL FUNCTIONS
Obviously, in both these accidents, critical functions of the airplanes
failed. In both the cases, they were hardware components. The human
component in both accidents succeeded. The components of an air-
plane are listed in Table 13.3, along with the functions that failed or
succeeded in each event.
It is apparent from Table 13.3 that critical functions are dependent
on each other in modern commercial airliners. Figure 13.1 shows how
these functions are interconnected. Figure 13.2 shows how the diagram
would change if the engines failed, for instance.

TABLE 13.3
Critical Functions of a Commercial Airplane
Component
Critical function
United Flight 232
Air Canada Flight 143
Fuselage
Pressure control: pressure vessel for
crew and passenger cabin
Succeeded
Succeeded
Wings
Lift
Succeeded
Succeeded
Engines
Propulsion Also, motive force for
hydraulic system, electrical system,
pneumatic system for control systems
and other
Two engines succeeded. One
engine in the tail failed due to
catastrophic failure of fan disk.
Critical function was maintained
Both engines failed due to lack of
fuel
Fuel system
Supports propulsion
Succeeded
Failed due to incorrect calculation
during refueling
Auxiliary power
unit (APU)
Instruments: supplies auxiliary
electrical power, hydraulic power,
pneumatic power
Not needed
Failed due to lack of fuel
Electrical system
Instruments Supplies electrical power
to avionics, control systems, cabin
comfort systems
Succeeded Failed due to
catastrophic failure of engine in
tail and subsequent destruction of
the three redundant hydraulic
systems
Failed due to loss of engines
Hydraulic system
Control systems: supplies hydraulic
power for aircraft control systems
Succeeded, but to a limited degree.
Was powered by the RAT
Landing gear
system
Landing safely: provides a controlled
means to land the aircraft
Succeeded
Succeeded, but to a limited degree
Control surfaces
Control systems: provides aircraft the
ability to turn, to control lift, to
descend at a controlled rate, and to
control aircraft attitude
Failed due to failure of hydraulic
system
Succeeded, but to a limited degree
188

13.2 Critical Functions
189
Fuel
system
Hydraulic
system
Lift
Control
systems
Critical
function
Mission
Propulsion
Instruments
Cabin
pressure
Commercial
airliner
controlled flight
Component
Wings
In reserve
Electrical
system
Engines
APU
FIGURE 13.1
Interconnection of critical functions.
Wings
Fuel
system
Hydraulic
system
Control
systems
Mission
Instruments
Cabin
pressure
Commercial
airliner
flight emergency,
loss of engines
Electrical
system
APU
Lift
Critical
function
Critical
function not
supported
Component
Propulsion
FIGURE 13.2
Flight during an engine failure event.

190
CHAPTER 13 Critical Function Analysis
CFA then can be used to determine which critical functions
are needed to support the desired mission. A recent Web article on
www.globalsecurity.org listed the ﬂight critical systems for the F-22
Raptor (17). These are listed in Table 13.4.
An F-22 crashed in Alaska on November 16, 2011, killing the
pilot (18). The cause of the crash was found to be the Bleed Air
System, part of the Air Cycle System, which is listed above as one of
the critical functions required by the F-22 to ﬂy (19).
13.3 CONDUCTING A CRITICAL
FUNCTION ANALYSIS
Conducting a CFA is relatively straightforward. If anything, the prob-
lem with conducting a CFA is getting everyone involved to agree on
what constitutes a critical function. This approach can be used for a
wide variety of analyses. It can be used for complex system design, as
shown above, for use with emergency planning, for use with ﬁnancial
activities (20), and for military operations (21). Different organizations
might use various terms for aspects of a CFA. Nelson and Bagian (8)
use the following terms:
• mission;
• critical functions;
• tasks;
• resources;
• support systems.
It really depends on the depth of the analysis and how your organi-
zation deﬁnes the layers. For the purposes of this book, the following
terms and their deﬁnitions are provided:
• Mission. goal of process, organization, or task.
• Critical Function. What has to be in place to achieve or maintain
the mission.
• Component. System, job/person, part, tool, or other thing that
performs the activities that make up the critical function.

13.3 Conducting a Critical Function Analysis
191
TABLE 13.4
Flight Critical Systems for F-22 Raptor
Flight critical system
Function
Vehicle management
system (VMS)
The VMS provides integrated ﬂight and propulsion
control. The VMS enables the pilot to aggressively
and safely maneuver the F-22 to its maximum
capabilities
Utilities and
subsystems (U&S)
• Integrated vehicle subsystem controller
• Environmental control system
• Fire protection
• Auxiliary power generation system (APGS)
• Landing gear
• Fuel system
• Electrical system
• Hydraulics
• Arresting system
Integrated vehicle
subsystem controller
(IVSC)
The IVSC is the system responsible for aircraft
integration, control, and diagnostics
Environmental control
system (ECS)
The F-22 uses a totally integrated ECS that provides
thermal conditioning throughout the ﬂight envelope
for the pilot and the avionics
The ﬁve basic safety critical functions the ECS must
take care of include avionics cooling, adequate air to
the pilot, canopy defog, cockpit pressurization, and
ﬁre protection
Air cycle system
The air cycle conditions air from the engines for
various uses
Liquid cooling system
Unlike other ﬁghter aircraft, the F-22 uses liquid
cooling, rather than air cooling for the mission
avionics
Thermal management
system (TMS)
The TMS is used to keep the fuel cool
Fire protection
Fire protection is provided for the aircraft’s engine
bays, the auxiliary power unit (APU), and for dry
bays
The aircraft uses infrared and ultraviolet sensor for ﬁre
detection and Halon 1301 for ﬁre suppression
Auxiliary power
generation system
(APGS)
The APGS consists of an APU and a self-contained
stored energy system (SES)
(continued)

192
CHAPTER 13 Critical Function Analysis
TABLE 13.4
(Continued)
Flight critical system
Function
Landing gear
The F-22 utilizes tricycle landing gear, with the
standard two main gears (each with a single tire) and
a single-wheel, steerable nose landing gear assembly
Fuel system
There are eight fuel tanks on the F-22, including one
(designated F-1) in the forward fuselage behind the
pilot’s ejection seat. The others are located in the
fuselage and the wings. The F-22 will run on JP-8, a
naphthalene-based fuel with a relatively high ﬂash
point
Electrical, hydraulic,
and arresting systems
The F-22 uses a Smiths Industries 270 V, direct current
(DC) electrical system. It uses two 65-kW generators.
The hydraulic system includes four 72 gal/min pumps
and two independent 4000 psi systems
• Support. Utilities, materials, activities, or other items that sup-
port the components.
The following presents several examples of analyses and how the
layers of a CFA are linked. These sample analyses are as follows:
• small business;
• chemical reactor;
• emergency planning.
13.3.1 Critical Function of a Small Business
Take any small business and there are several critical functions that
must be maintained for the business to operate. A convenience store
(C Store) has been used for this example. Most readers of this book
have been to a C Store. This store has the following attributes:
• four gas pumps;
• 1 ea. 10,000 gal 87 octane gasoline tank;
• 1 ea. 10,000 diesel tank;
• 30 ft of beer and soda cooler;

13.3 Conducting a Critical Function Analysis
193
• 100 ft of room temperature storage;
• two soda fountains;
• one microwave food station.
The ﬁrst step for conducting a CFA is to deﬁne the mission and
critical functions of the store. The mission of the business is to make
money. The critical functions that are needed to allow the store to
make money are as follows:
• a location/building;
• a shopper friendly environment;
• products to sell;
• means to perform transactions (cashier or self-service station);
• appropriate operating licenses.
In this example, the goal is not to optimize the cash ﬂow but
only to stay open. Figure 13.3 shows the relationship of the critical
functions to the mission and the support functions.
It goes without saying that in the absence of any of the critical
functions, the store could not make money or not for very long. The
appropriate licenses critical function could be eliminated but within
short order; in most well-run cities, this would cause the business to
close soon.
13.3.2 Chemical Reactor Critical Function
Analysis
In this example, a CFA will be performed on a chemical reactor sys-
tem. The mission of the reactor is to produce a 5000-gal batch of
chemical D within the quality limits. The attributes of the reactor are
as follows:
• It is a 5500-gal-capacity batch reactor.
• Three chemicals are combined in the reactor to produce chem-
ical D. These chemicals are chemicals A, B, and C.
• The ratio of the three chemicals are as follows:
◦10% chemical A;

194
CHAPTER 13 Critical Function Analysis
Coolers
Gas pumps
and tanks
Heating and
cooling
Components
Bricks and
mortar
building
Lighting
Janitors
Shelving
Fast food
prep
equipment
Cash
register and
change
Cashier
Appropriate
licenses
Means to make
transactions
Mission
Location
Products to sell
Shopper
friendly
environment
Make money in a C
store
Electricity
Food delivery
Support functions
Banking support
Credit card
machine and
account
Inventory control
and product
ordering
Fuel delivery
Critical
functions
FIGURE 13.3
Critical functional analysis for convenience store.
◦30% chemical B;
◦60% chemical C.
• Chemicals have to be mixed in the proper ratio for 30 min to
ensure a successful batch.
• The reaction is exothermic. For each degree over 300◦F the
reactor reaches, the quality of the product is reduced. Chemical
E is the contaminant produced. The batch becomes 1% chemical
E for degree over the 300◦level.
• Increased temperature can cause a spike in reactor pressure. If
the pressure reaches 310◦F, the reactor pressure will near the
safety factor limits of the reactor. At this point, the rupture disk
will break and the gases produced will be directed to a scrubber
column.
• The product must have less than 2% chemical E to be successful.
In this regard, the critical functions of the system are as follows:
• pressure control;

13.3 Conducting a Critical Function Analysis
195
• temperature control;
• chemical metering;
• chemical mixing;
• safety systems.
Figure 13.4 shows the CFA for the reactor system. In the event of
a process upset, the mission becomes to prevent a catastrophic failure
of the pressure vessel. Figure 13.5 shows the relationship of the critical
functions needed to succeed in this mission.
13.3.3 Emergency Management Planning
One of the attributes of a modern emergency management plan is
a continuity of operations plan (COOP). COOP is a collection of
resources, actions, procedures, and information that is developed,
tested, and held in readiness for use in the event of a major
disruption
of
operations.
The
COOP
Multi-Year
Strategy
and
Program Management Plan (MYSPMP) should provide the guidance,
objectives, performance measures, enabling tasks, and resources
necessary for the organization to accomplish its overall mission and
essential functions to its priority and secondary mission.
The Federal Emergency Management Agency (FEMA) provides
guidance for ensuring critical functions of an organization are main-
tained via a COOP (22).
Mission
Quality 5000
gal batch
of chemical D
In
reserve
Safety
systems
Chemical
mixing
Chemical
metering
Temperature
control
Pressure
control
Reactor
vessel
intergrity
Reactor
cooling
system
Piping
system
Metering
pumps and
controllers
Mixing
motor and
agitator
Critical
functions
Components
FIGURE 13.4
Critical functional analysis of a chemical reactor system.

196
CHAPTER 13 Critical Function Analysis
Mission
Prevent rupture of
reactor vessel
Pressure
control
Pressure
relife
system
Scrubber
column
Reactor
vessel
integrity
Safety
systems
Critical
functions
Components
FIGURE 13.5
Critical functions during process upset.
FPC 65 lists the objectives of viable COOP program. These are
as follows:
1. ensuring the performance of essential functions/operations;
2. reducing loss of life and minimizing damage and losses;
3. executing as required, successful succession to ofﬁce with
accompanying authorities in the event a disruption renders
agency
leadership
unable,
unavailable,
or
incapable
of
assuming and performing their authorities and responsibilities
of ofﬁce;
4. reducing or mitigating disruptions to operations;
5. ensuring that alternate facilities are available from which to
continue to perform their essential functions;
6. protecting essential facilities, equipment, vital records, and
other assets;
7. achieving a timely and orderly recovery from a COOP situation
and maintenance of essential functions to both internal and
external clients;
8. achieving
a
timely
and
orderly
reconstitution
from
an
emergency and resumption of full service to both internal and
external clients;

13.4 Summary
197
9. ensuring and validating COOP readiness through a dynamic,
integrated test, training, and exercise program to support the
implementation of COOPs and programs.
FEMA states that there are critical essential functions that gov-
ernment organizations must be able to perform, either continuously
or without signiﬁcant disruption, during and following a crisis, if
required, in the assurance of COOP (21). The national essential func-
tions (NEFs) are listed in Table 13.5. Secondary functions are listed
in Table 13.6.
COOP is also important for corporations, state and county gov-
ernments, and small businesses. Within a rural county in Idaho, the
critical functions might not be as extensive as a major metropolitan
county such as New York. However, they are critical for the resi-
dents. Rural counties in the western states can be the size of entire
states in the east. Idaho county in Idaho comprises around 8500 square
miles and only has approximately 17,000 residents (23). Rhode Island
is approximately 1200 square miles in size and has over 1,000,000
residents (24). In fact, Idaho county is half the size of Switzerland
(approximately 15,000 square miles) (25).
The issues with such a big county, with very few residents from
a critical function perspective are as follows:
• tax base;
• distances between municipalities;
• emergency services to serve remote areas;
• schools and medical services;
• social services.
From a COOP perspective, ensuring such a county can operate
under disaster conditions is very important for ensuring the well-being
of its residents. Figure 13.6 shows how the critical functions for a rural
county might look.
13.4 SUMMARY
CFA is a very useful tool. It can be applied to a wide range of activ-
ities, systems, and organizations to determine if the critical functions

198
CHAPTER 13 Critical Function Analysis
TABLE 13.5
Critical Functions for Continuity of Operations
Critical function category
Critical functions
National essential functions
(NEFs)
Functions that represent the
overarching responsibilities of
the Executive Branch to lead
and sustain the country and
will generally be the primary
focus of the President
Preserve our Constitutional Form of
Government. Ensure the continued functioning
of our duly elected representative form of
government, and in particular, the functioning
of the three independent branches of
government. This NEF includes department and
agency functions that respect and implement
the check and balance relationship among the
three branches of the Federal government
Provide visible leadership to the Nation;
maintain the trust and conﬁdence of the
American people. This NEF includes
department and agency functions to
demonstrate that the Federal government is
viable, functioning, and effectively addressing
the emergency
Defend the country against all enemies, foreign
or domestic, and prevent and interdict future
attacks. This NEF includes department and
agency functions to protect and defend the
worldwide interests of the United States against
foreign or domestic enemies, to honor security
agreements and treaties with allies, and to
maintain military readiness and preparedness in
furtherance of national interests and objectives
Maintain and foster effective relationships with
foreign nations. This NEF includes department
and agency functions to maintain and
strengthen American foreign policy
Protect against threats to the homeland and bring
to justice perpetrators of crimes or attacks
against the nation, its citizens, or interests. This
NEF includes department and agency functions
to protect against, prevent, or interdict attacks
on the people or interests of the nation and to
identify, incarcerate, and punish those who
have committed violations of the law

13.4 Summary
199
TABLE 13.5
(Continued)
Critical function category
Critical functions
Provide rapid and effective response to and
recovery from the domestic consequences of an
attack or other incident. This NEF includes
department and agency functions to implement
response and recovery plans, including, but not
limited to, the National Response Plan
Protect and stabilize the nation’s economy;
ensure conﬁdence in ﬁnancial systems. This
NEF includes department and agency functions
to minimize the economic consequences of an
attack or other major impact on national or
international economic functions or activities
Protect and stabilize the nation’s economy;
ensure conﬁdence in ﬁnancial systems. This
NEF includes department and agency functions
to minimize the economic consequences of an
attack or other major impact on national or
international economic functions or activities
Provide for critical Federal government services
that address the national health, safety, and
welfare needs of the Nation. This NEF
includes department and agency functions that
ensure that the critical national-level needs of
the nation are met during an emergency with
regard to Federal government activity
that are required for a mission to be successfully achieved or main-
tained are properly and adequately supported. It can also be applied
to various phases of an activity, system, or organization to determine
if the critical functions would be maintained under varying or adverse
conditions. One of the difﬁculties with using the tool is getting all
parties to agree as to what constitutes a critical function and what
constitutes the components that support the critical functions. Also,
terminology does vary between analysts who use the tool. As with all
the tools and techniques discussed in this book, once the analysis is
performed, the results can be used to improve the situation.

200
CHAPTER 13 Critical Function Analysis
TABLE 13.6
Secondary Critical Continuity of Operations Functions
Critical function
category
Critical functions
Priority mission
essential functions
(PMEFs)
Those department-speciﬁc mission essential functions
that support the NEFs and ﬂow directly up from
supporting activities or capabilities within department
or agency COOP
Secondary mission
essential functions
(SMEFs)
Those mission essential functions that the department
must perform in order to bring about full resumption
of its normal functions, but which are not PMEFs.
Resumption of SMEFs may need to occur within a
very short period of time or only after several days
depending on the nature of the department’s mission
and the nature of the disruption to normal department
functions
Supporting activities
Those speciﬁc activities that the department must
conduct in order to perform its mission essential
functions
Capabilities
Communications, facilities, information, trained
personnel, and other assets necessary to conduct the
department’s mission essential functions and
supporting activities
Mission
Critical
functions
Primary
components
County
sheriff
office
Public
safety
Emergency
response
Medical
services
Road
maintenance
Utilities
Maintain
rural county
functions
Rural fire
districts
Rural
hospital
limited
services
Secondary
components
State
police
State fire
service
Federal
fire
services
City
hospital
(adjoining
county)
County
road
department
State
Highway
department
Utility
Cooperation
FIGURE 13.6
Rural county critical functions.

References
201
REFERENCES
1. Functional_analysis_(psychology).
Wikipedia;
2011.
Available
at
http://en.
wikipedia.org/wiki/Functional_analysis_(psychology). Accessed 2011 Aug.
2. Lahti L. Net response: functional network analysis. Available at: netpro. Accessed
2011 Aug.
3. Thomsona F, Mathias D, Nejad H, Go S. Functional risk modeling for lunar
surface systems. Moffett Field.
4. Function. Dictionary.com; 2011. Available at http://dictionary.reference.com/
browse/function. Accessed 2011 Aug.
5. Ryba J. Space shuttle; 2011, Sep 6. NASA. Available at http://www.nasa.gov/
mission_pages/shuttle/main/. Accessed 2011 Sep.
6. Dismukes K. Spacecraft; 2004, Apr 3. NASA. Available at http://spaceﬂight.nasa.
gov/history/shuttle-mir/spacecraft/s-orb-sscomponents-main.htm. Accessed 2011
Aug.
7. Wilson J. Columbia Home; 2006, Aug 23. NASA. Available at http://www.
nasa.gov/columbia/home/index.html. Accessed 2011 Aug.
8. Nelson WR, Bagian TM. Critical function models for operation of the Interna-
tional Space Station; 2000.
9. Corcoran W. Nuclear power plant safety functions; 1981.
10. Surhone LM, Tennoe MT, Henssonow SF. United Airlines Flight 232. Ript; 2011.
11. Reason J. The human contribution. Novato, CA: Arena; 2008.
12. United Flight 232, PBSO—910406. McDonnell Douglas; 1989, Jul 19.
13. Nelson WH. The Gimli glider. Wadenelson; 1997. Available at http://www.
wadenelson.com/gimli.html. Accessed 2011 Aug.
14. Williams M. The 156-tonne Gimli glider; 2003, Jul. Casa. Available at
http://www.casa.gov.au/fsa/2003/jul/22-27.pdf. Retrieved 2007-06-05. Accessed
2007 Jul 5.
15. Auxiliary power unit. Wikipedia; 2011. Available at http://en.wikipedia.org/wiki/
auxiliary_power_unit. Accessed 2011 Aug.
16. Ram_air_turbine. Wikipedia; 2011. Available at http://en.wikipedia.org/wiki/
Ram_air_turbine. Accessed 2011 Aug.
17. F-22 Raptor Flight Critical Systems. Global security; 2011, Jul 7. Available at
http://www.globalsecurity.org/military/systems/aircraft/f-22-fcas.htm.
Accessed
2011 Aug.
18. US Air Force. Ofﬁcials suspend F-22 crash recovery and restoration; 2010, Dec
1. Available at http://www.af.mil/news/story.asp?id=123232976. Accessed 2011
Aug.
19. Majumdar D. Bleed-air problem caused F-22 crash: sources. Defense News; 2011,
Sep 8. Available at http://www.defensenews.com/story.php?i=7624955. Accessed
2011 Sep.
20. Elliot D, Swartz E, Herbane B. Business continuity management: a critical man-
agement. Oxford, UK: Routledge; 2010.

202
CHAPTER 13 Critical Function Analysis
21. Wade NM. Battle Staff Smartbook: doctrinal guide to military decision making
and tactical operations. La Vergne, TN: Lightning Press; 2005.
22. Federal Emergency Management Agency (FEMA). Federal preparedness; 2004,
Jun 15. http://www.fema.gov/plan/prevent/rms/), Retrieved March 2011.
23. Idaho County. Idaho County; 2011, Jan 18. Available at http://www.idahocounty.
org/. Accessed 2011 Aug.
24. Rhode
Island.
Wikipedia;
2011.
http://en.wikipedia.org/wiki/Rhode_Island.
Accessed 2011 Aug.
25. Switzerland.
Wikipedia;
2011.
Available
at
http://en.wikipedia.org/wiki/
Switzerland. Accessed 2011 Aug.

CHAPTER 14
Basic Fault Tree Analysis
Technique
The fault tree analysis (FTA) technique is proven to be an effec-
tive tool for analyzing and identifying areas for hazard mitigation
and prevention, while in the planning phase or anytime, a systematic
approach to risk assessment is needed. FTA is used as an integral part
of a probabilistic risk assessment (PRA). In this chapter, we cover the
very basics of FTA. The NASA Fault Tree Handbook with Aerospace
Applications (1) is a complete guide to FTA.
14.1 HISTORY
Knowledge of the history of the need for FTA is useful for under-
standing the simple, yet powerful potential of the tool. This history
begins with the inception of mechanical vehicles. One common prob-
lem that plagued vehicles was malfunction and failures caused by
“little things.”
Steam engines blew up when pressure relief valves stuck closed.
Early autos scattered parts across the countryside as nuts and bolts
separated. Airplanes fell to earth because poorly designed ﬁttings tore
apart. Always it was the little things that failed and set up potentially
deadly chain reactions.
Risk Assessment: Tools, Techniques, and Their Applications, First Edition.
Lee T. Ostrom, Cheryl A. Wilhelmsen.
2012 John Wiley & Sons, Inc. Published 2012 by John Wiley & Sons, Inc.

204
CHAPTER 14 Basic Fault Tree Analysis Technique
Despite major advances in design and manufacturing techniques,
signiﬁcant numbers of accidents and failures continued to occur. Air-
plane accidents, attributable to training, accounted for over one third
of the losses during the WWII years 1941–1945. Over 14,000 major
accidents were recorded in the United States alone.
Often, the airplane accidents were attributed to “pilot error.” How-
ever, the majority of crashes should have been linked to a malfunction
of little things, such as a failed hydraulic pump, a broken feathering
stop, a missing lock nut and so on.
As technology became more exotic, technological advances
exceeded the average skill level for operation and maintenance of
advanced air vehicles. Because of the complexity of systems, nut and
bolt errors became even more frequent. Therefore, an improvement
in safety analysis was needed.
This technique had to be capable of handling systems of enormous
complexity and allow detailed analysis at the nuts and bolts level. The
basic premise behind the development of the tool was little things
cause accidents. The ﬁrst FTA was developed and applied by Bell
Telephone Laboratories in 1962, with the requirements in mind. The
tool was initially applied to the Minuteman Intercontinental Ballistic
Missile (ICBM). As a result of the FTA of that extremely complex
system and taking corrective measures, the missile was rated as one
of the safest in the United States Air Force (USAF) inventory (2).
14.2 APPLICATION
Fault trees graphically represent the interaction of failures and other
events in a system. Basic events are depicted at the bottom of the fault
tree and are linked via logic symbols (known as gates) to one or more
of the TOP events. These TOP events represent identiﬁed hazards or
system failure modes for which predicted reliability or availability data
are required. Typical TOP events might be as follows:
• total loss of production;
• explosion;
• toxic emission;
• safety system unavailable.

14.4 Event Symbols
205
As indicated, the fault tree begins at the end, so to speak. This top-
down approach starts by supposing that an accident takes place. It then
considers the possible direct causes that could lead to this accident.
Next it looks for the origins of these causes. Finally, it looks for ways
to avoid these origins and causes. The resulting diagram resembles a
tree, thus the name.
Fault trees can also be used to model success paths as well. In
this regard, they are modeled with the success at the top, and the basic
events are the entry-level success that put the system on the path to
success.
14.3 FAULT TREE CONSTRUCTION
The goal of fault tree construction is to model the system conditions
that can result in the undesired event. The analyst must acquire a
thorough understanding of the system before beginning the analysis.
A system description should be part of the analysis documentation.
The analysis must be bounded, both spatially and temporally, in order
to deﬁne a beginning and endpoint for the analysis.
The fault tree is a model that depicts graphically and logically
represents the various combinations of possible events, both fault and
normal, occurring in a system leading to the top event. The term event
denotes a dynamic change in state that occurs to a system element. Sys-
tem elements include hardware, software, human, and environmental
factors.
14.4 EVENT SYMBOLS
The symbols shown in Table 14.1 are the most common fault tree
symbols. These symbols represent speciﬁc types of fault and normal
events in FTA. In many simple trees only the basic event, undeveloped
event, and output event are used.
Events representing failures of equipment or humans (compo-
nents) can be divided into failures and faults. A component failure
is a malfunction that requires the component to be repaired before
it can successfully function again. For example, when a pump shaft
breaks, it is classiﬁed as a component failure. A component fault is a

206
CHAPTER 14 Basic Fault Tree Analysis Technique
TABLE 14.1
Common Fault Tree Symbols
Symbol name
Symbol
Description
Basic event
A basic initiating fault (or
failure event)
Undeveloped event
An event that is no further
developed. It is a basic event
that does not need further
resolution
Output event
An event that is dependent on
the logic of the input events
External event
(house event)
An event that is normally
expected to occur. In general,
these events can be set to occur
or not occur, that is, they have
a ﬁxed probability of 0 or 1
Conditioning event
A speciﬁc condition or
restriction that can apply to
any gate
Transfer
Indicates a transfer to a subtree
or continuation to another
location
malfunction that will “heal” itself once the condition causing the mal-
function is corrected. An example of a component fault is a switch
whose contacts fail to operate because they are wet. Once they are
dried, they will operate properly.

14.5 Logic Gates
207
Output events include the top event, or ultimate outcome, and
intermediate events, usually groupings of events. Basic events are used
at the ends of branches since they are events that cannot be further
analyzed. A basic event cannot be broken down without losing its
identity. The undeveloped event is also used only at the ends of event
branches. The undeveloped event represents an event that is not further
analyzed either because there is insufﬁcient data to analyze or because
it has no importance to the analysis.
14.5 LOGIC GATES
Logic gates are used to connect events. The two fundamental gates
are the AND and OR gates. Table 14.2 describes the gate functions
and also provides insight to their applicability.
Electrical circuits are used to illustrate the use of AND and OR
gates. Figure 14.1 is a picture of switches in series and the correspond-
ing fault tree. In order for the bulb to be lit, all the switches must be
in the closed position. The logic gate is an AND gate.
Figure 14.2 represents the OR gate logic. The bulb will be lit if
any of the switches are closed.
Other gates that can be used in more complicated trees are shown
in Table 14.3. These logic gates are used when representing complex
systems. Other gates can be used as well. These are usually very
specialized in nature and do not have widespread application.
TABLE 14.2
Logic Gates
Description
Symbol
Truth table
AND gate: The AND gate
indicates that the output
occurs if and only if all
the input events occur
Input A
Input B
Output
T
T
T
T
F
F
F
T
F
F
F
F
OR gate: The OR gate
indicates that the output
occurs if and only if at
least one of the input
events occur
T
T
T
T
F
T
F
T
T
F
F
F

208
CHAPTER 14 Basic Fault Tree Analysis Technique
Switch B
Switch C
Switch A
FIGURE 14.1
Switches representing AND gates.
Switch B
Switch C
Switch A
FIGURE 14.2
Switches representing OR gates.
14.6 ANALYSIS PROCEDURE
There are four steps to perform an FTA:
1. Deﬁning the problem.
2. Constructing the fault tree.
3. Analyzing the fault tree qualitatively.
4. Documenting the results.
14.6.1 Deﬁning the Problem
A top event and boundary conditions must be determined when deﬁn-
ing the problem. Boundary conditions include:

14.6 Analysis Procedure
209
TABLE 14.3
More Complicated Logic Gates
Symbol name
Symbol
Description
Voting OR
(k-out-of-n)
k
The output event occurs if k or
more of the input events occur
Inhibit
The input event occurs if all input
events occur and an additional
conditional event occurs
Priority AND
The output event occurs if all input
events occur in a speciﬁc
sequence
• system physical boundaries;
• level of resolution;
• initial conditions;
• not allowed events;
• existing conditions;
• other assumptions.
Top events should be precisely deﬁned for the system being
evaluated. A poorly deﬁned top event can lead to an inefﬁcient
analysis.
14.6.2 Constructing the Fault Tree
Construction begins at the top event and continues, level by level, until
all fault events have been broken into their basic events. Several basic
rules have been developed to promote consistency and completeness in
the fault tree construction process. These rules, as listed in Table 14.4,
are used to ensure systematic fault tree construction (3).

210
CHAPTER 14 Basic Fault Tree Analysis Technique
TABLE 14.4
Rules for Constructing Fault Tree
Fault tree statements
Write the statements that are entered in the event
boxes and circles as malfunctions. State precisely a
description of the component and the failure mode of
the component. The “where” and “what” portions
specify the equipment and its relevant failed state.
The “why” condition describes the state of the system
with respect to the equipment, thus explaining why
the equipment state is considered a fault. Resist the
temptation to abbreviate during construction
Fault event evaluation
When evaluating a fault event, ask the question “Can
this fault consist of an equipment failure?” If the
answer is yes, classify the fault event as a
“state-of-equipment” fault. If the answer is no,
classify the fault event as a “state-of-system” fault.
This classiﬁcation aids in the continued development
of the fault event
No miracles
If the normal functioning of equipment propagates a
fault sequence, assume that the equipment functions
normally. Never assume that the miraculous and
totally unexpected failure of some equipment
interrupts or prevents an accident from occurring
Complete each gate
All inputs to a particular gate should be completely
deﬁned before further analysis of any other gate. For
simple models, the fault tree should be completed in
levels, and each level should be completed before
beginning the next level. This rule may be unwieldy
when constructing a large fault tree
No gate-to-gate
Gate inputs should be properly deﬁned fault events;
that is, gates should never be directly connected to
other gates. Cutting short the fault tree development
process leads to confusion because the outputs of the
gate are not speciﬁed
14.6.3 Analyzing the Fault Tree
Many times, it is difﬁcult to identify all of the possible combina-
tions of failures that may lead to an accident by directly looking at
the fault tree. One method for determining these failure paths is the
development of “minimal cut sets.” Minimal cut sets are all of the
combinations of failures that can result in the top event. The cut sets
are useful for ranking the ways the accident may occur and are useful

14.7 Examples of Fault Tree Analysis
211
for quantifying the events, if the data are available. Large fault trees
require computer analysis to derive the minimal cut sets, but some
basic steps can be applied for simpler fault trees:
1. Uniquely identify all gates and events in the fault tree. If a
basic event appears more than once, it must be labeled with
the same identiﬁer each time.
2. Resolve all gates into basic events. Gates are resolved by plac-
ing them in a matrix with their events.
3. Remove duplicate events within each set of basic events iden-
tiﬁed.
4. Delete all supersets that appear in the sets of basic events.
By evaluating the minimal cut sets, an analyst may efﬁciently
evaluate areas for improved system safety.
14.6.4 Documenting the Results
The analyst should provide a description of the system being analyzed,
a discussion of the problem deﬁnition, a list of the assumptions, the
fault tree model(s), lists of minimal cut sets, and an evaluation of
the signiﬁcance of the minimal cut sets. Any recommendations should
also be presented.
14.7 EXAMPLES OF FAULT TREE
ANALYSIS
14.7.1 Simple Example
The following examples show the fundamentals of FTA. We start with
analyzing a simple cooling system ﬂushing procedure. This procedure
can also be analyzed using human reliability analysis (HRA) tech-
niques, but we use FTA at this point. The procedure reads as follows:
Warning: cooling system must be below 100◦F before draining.
1. Begin with the engine cold and ignition off.
2. Remove the radiator pressure cap.

212
CHAPTER 14 Basic Fault Tree Analysis Technique
Warning: ethylene glycol coolant is toxic and must be disposed of
in an appropriate manner.
3. Open the petcock at the bottom of the radiator and drain the
coolant into a bucket.
4. Close the petcock and ﬁll the radiator with water.
5. Start the engine and turn the heater control to hot. Add cooling
system cleaner and idle the engine for 30 min (or as per the
instructions on container).
Warning: cooling system must be below 100◦F before draining.
6. Stop the engine and allow it to cool for 5 min. Drain the
system.
7. Close the petcock, ﬁll the radiator with water, and let the
engine idle for 5 min.
8. Open petcock and drain the water.
9. Repeat steps 6–8.
10. Close the petcock.
11. Fill cooling system with 50 : 50 mixture of water/nontoxic
antifreeze/coolant.
The ﬁrst step will be to determine the credible top events. In this
case, it will be as follows:
Mechanic is burned.
Cooling ﬂushing failed.
In fact, the “mechanic is burned” top event can be grouped under
the “cooling ﬂushing failed” top event because if the mechanic was
burned then the task would fail in a sense.
From the procedure, we can identify several basic events. These
are shown in Table 14.5, along with their credibility.
Once the credibility of the failures is assessed, the next step is to
construct the fault tree. Do not include errors that were deemed to be
noncredible. The top event will be the cooling ﬂush failed. All the
basic events will be entry points into the tree. The tree is shown in
Figure 14.3.
Notice that the fault tree was built only using an OR gate and the
basic events. That is because only one of the credible failures can lead
to the failure of the task.

14.7 Examples of Fault Tree Analysis
213
TABLE 14.5
Basic Events
Failure
Description
Credible failure
Engine not
below 100◦F
before
beginning
ﬂushing
procedure
In this failure, the
mechanic begins the
coolant draining process
without ensuring the
engine is cool enough
This is a credible error. It happens
all the time to professional as
well as amateur mechanics.
Since the system is under
pressure a severe burn can occur
Failure to
remove
radiator cap
As it says, the mechanic
fails to remove the
radiator cap
This is not a credible error, unless
we are modeling the fact that the
mechanic does not do the task
at all
Failure to drain
radiator
The mechanic fails to
drain the radiator
This is not a credible error,
unless, again, we are modeling
the fact that the mechanic does
not do the task at all
Failure to close
petcock valve
This failure involves the
mechanic not closing or
incorrectly closing the
petcock valve. This error
can occur at least four
times in the procedure
This is a credible error and can
lead to an environmental spill
Failure to add
ﬂushing agent
The mechanic fails to add
the ﬂushing agent
This is a credible error because
the mechanic can get busy and
forget where they are in the
process
Failure to
remove
ﬂushing agent
The mechanic fails to
remove the ﬂushing
agent
This is a credible error because,
once again, the mechanic can get
busy and forget where they are
in the process. OR a shift change
occurs or job change over and
the second mechanic does not
know where in process they are.
This happens in the airline
industry every day
Failure to rinse
engine
The mechanic fails to
rinse the remaining
ﬂushing agent from the
engine
This might not be a catastrophic
error, once the engine is drained
of the ﬂushing agent. It depends
on how corrosive the ﬂushing
agent is
Failure to ﬁll
engine with
50/50 nontoxic
antifreeze mix
The mechanic fails to ﬁll
the cooling system with
the proper mixture, the
right amount of coolant,
or coolant at all
This again is a credible error

214
CHAPTER 14 Basic Fault Tree Analysis Technique
Cooling flush
failed
Engine
temperature
100°
Failure to
close
petcock
valve
Failure to
add
flushing
agent
Failure to
remove
flushing
agent
Failure to
rinse
engine
Failure to fill
coolant
system
FIGURE 14.3
Fault tree analysis of coolant ﬂushing task.
Next is a model of a simple hardware system failure, one that
most homeowners have experienced. That is of the sprinkler system
failure. The top event is sprinkler system failure. Table 14.6 contains
the credible failures that can lead to the top event.
In Figure 14.4, we have constructed a partial fault tree from these
failures. A full tree was not constructed to save space.
14.7.2 Modeling Success Using Fault Tree
Analysis
One of the useful attributes of FTA is that it can also be used to
model success paths as well as its more traditional use of modeling
failure paths. For instance, say that a hiker wants to climb Mt. Everest.
What must happen in order to do such a climb? Or say that someone
wants to pass a certiﬁcation examination or even complete a project
on time. What does that person need to do to succeed in those goals?
Obviously, there are many project management techniques that are
great at modeling success paths for projects. Network diagrams are
one example of a tool that can be used. However, FTA can also be
used to model this type of process.
So, let us say our goal is to write a technical book that has 12
chapters and meet the contractual requirements of the publisher. As
with modeling in the failure space, we need to develop the list of
credible events that must occur to succeed. Table 14.7 lists these.

14.7 Examples of Fault Tree Analysis
215
TABLE 14.6
Credible Failures
Failure
Description
Credible failure
Sprinkler head
failure 1
Sprinkler head fails
because it wore out
Yes, it is a credible failure
Sprinkler head
failure 2
Sprinkler head fails
because neighbor hits it
with their lawn mower
Yes, it is a credible failure
Sprinkler valve
failure 1
Sprinkler valve wears out
Yes, it is a credible failure
Sprinkler valve
failure 2
Sprinkler valve breaks due
to freezing
Yes, this failure though is
contingent on the system
not being properly drained
the fall before. So, we will
model it in this manner
Sprinkler controller
failure 1
The battery that backs up
the memory fails, and
after a power failure, the
system has lost its mind
Yes, it is a credible failure
Sprinkler controller
failure 2
The sprinkler controller
fails
Yes, it is a credible failure
Sprinkler pipe
failure 1
The sprinkler pipe breaks
due to freezing
Yes, this failure though is
contingent on the system
not being properly drained
the fall before. So, again,
we will model it in this
manner
Sprinkler pipe
failure 2
The sprinkler pipe breaks
due to digging in the yard
Yes, it is a credible failure
Though, in real life, an event tree is probably a better tool to model
this with, we develop the model using a fault tree. Chapter 12 shows
how this process can be modeled using an event tree. Figure 14.5
shows a fault tree for this process.
14.7.3 Fault Tree Analysis for Use in Accident
Investigation
The following provides a description of an actual accident involving
TAM Linhas A´ereas Flight 3054. An FTA will be constructed from
the information provided.

216
CHAPTER 14 Basic Fault Tree Analysis Technique
Sprinkler
system fails
Sprinkler
head fails
Sprinkler
head wears
out
Power
failure
Battery in
controller is
dead
Controller
fails
Controller fails
Neighbor
hits
head with
mower
FIGURE 14.4
Partial fault tree of sprinkler system failure.
Technical book
Rough
manuscript is
complete
Author 1
completes 6
chapters
Author 2
completes 6
chapters
Book is
properly
edited
Artwork
meets
publisher’s
criteria
Manuscript
is formatted
correctly
Manuscript
is submitted
on time
FIGURE 14.5
Fault tree for success model.

14.7 Examples of Fault Tree Analysis
217
TABLE 14.7
Credible Events
Success
Description
Credible
Author 1 completes
six chapters
Author 1 completes the
chapters assigned to
him/her
Yes, this has to occur to
succeed
Author 2 completes
six chapters
Author 2 completes the
chapters assigned to
him/her
Yes, this has to occur to
succeed
Editor’s changes
are appropriate
The Editor’s changes
must not change the
technical content of the
book and must be
grammatically
appropriate
Yes, this has to occur to
succeed
Artwork meets
requirements
The artwork has to meet
the Publisher’s
requirements to be
included
Yes, this has to occur to
succeed
Manuscript is
formatted
correctly
Besides the book needing
to meet technical and
grammatical
requirements, it also has
to be formatted correctly
Yes, this has to occur to
succeed
Manuscript is
submitted on time
The manuscript has to be
submitted on time to be
accepted
Yes, this has to occur to
succeed
On July 17, 2007, TAM Linhas A´ereas Flight 3054, an Airbus
A320-233 aircraft left Salgado Filho International Airport in Porto
Alegre, only to land in wet conditions and crash at Congonhas-S˜ao
Paulo International Airport in S˜ao Paulo, Brazil. When the ﬂight ﬁrst
touched down, it was raining, causing the plane to overrun the runway,
cross a highly busy main road during rush hour trafﬁc, and crash into
the TAM Express warehouse, which happened to be next to a gas
station that exploded with the force of the impact of the Airbus A320-
233, #789 (4). With 187 people on board, and 12 people on the ground,
there totaled 199 fatalities (5), causing this crash to be the highest in
deaths of any Latin American aviation accident. Not only was it the
most devastating in Latin America, but it was the worst Airbus A320
crash involving fatalities anywhere in the world (6).

218
CHAPTER 14 Basic Fault Tree Analysis Technique
Airbus A320-233 was registered as PR-MBK and had the manu-
facturer’s serial number of 789. The A320-233 was powered by two
International Aero V2527E-A5 engines. The A320-233, #789 was built
in February 1998 and took its ﬁrst ﬂight in March 1998 and had its
last ﬂight in July 2007 (7). TAM Linhas A´ereas was the last of four
companies to operate the A320-233, #789 in less than a decade. TAM
Linhas A´ereas did not come into position of the A320-233, #789 until
December 2006. Data collected from Flight International show that
as of April 30, the A320-233, #789 had mounted up to 20,379 ﬂying
hours and 9313 cycles (7).
The aircraft was dispatched for the ﬂight 3054 with a jammed
thrust reverser, a braking device on the aircraft. According to TAM,
the fault in the thrust reverser did not make the landing anymore
dangerous and that the mechanical problem was not known at the
time. It was later reported that the plane had trouble braking on the
S˜ao Paulo runway on July 16, the day before the crash, indicating that
they had prior knowledge that something was wrong with the braking
system (7).
Once the aircraft touched down in S˜ao Paulo, the pilots were
unable to slow the aircraft down at a normal rate. The aircraft was still
traveling at approximately 90 knots toward the end of the runway. The
aircraft took a hard left and overshot the runway where it cleared the
major roadway since the runway was elevated, but eventually collided
with the TAM Express building. Surveillance videos showed that the
aircraft touched down at a normal speed and at a normal spot on the
runway but the aircraft failed to properly slow down (8).
Authorities uncovered the ﬂight data recorder, which contained
information about what happened in the plane during ﬂight. The data
showed the following information. The thrusters had been in the climb
position just before touchdown as the engines were being controlled
by the computer system (4). An audio warning was given by the
computer 2 seconds before touchdown, warning the pilots that they
should manually take control of the throttle. When the aircraft touched
down, it was found that one thruster was in the idle position, while
the other was stuck in the climb position. In order for the spoilers to
deploy and assist in slowing the aircraft down, both thrusters must
be in the idle position. With different force being applied to each
side, it created a force that caused the plane to veer off to the left
uncontrollably (7).

14.7 Examples of Fault Tree Analysis
219
Before the accident, the airport became under increased scrutiny
due to a mid-air collision in September 2006. The airport was known
to have safety issues regarding operations in the rain as well as runway
characteristics for the trafﬁc going through it. One of these characteris-
tics involved the length of the runway (4). There are so many variables
that can affect the landing distance of an airplane that the airport had
failed to consider.
For example, if the aircraft’s approach speed is 20 knots higher
than normal, it will take the aircraft 25% longer to slow down. The
runway had been seen as a problem before the incident, and in Febru-
ary 2007, a judge had actually banned ﬂights using Fokker 100, Boeing
737-700s, and Boeing 737-800s stating that the runway needed to be
an additional 1275 ft in order to operate safely. The A320 was not
banned because the manufacture stated a shorter braking distance than
the banned aircraft. However, the ban was quickly lifted as the air-
line industry stated that they would be inconveniencing thousands of
passengers (6).
The root causes for the crash were that one of the reverse thrusters
was known to be out before the ﬂight, the runway was wet, and the
runway should have been longer. While TAM claims that the thrusters
should not have caused the crash, it is obvious that had the reverse
thruster been functioning, the aircraft would have most likely been
able to stop. Having grooves cut into the pavement to help reduce the
risk of hydroplaning could have prevented the moisture on the runway
and had the runway been longer, the aircraft would have had more
time to stop (4).
Pilot training might have also contributed to the accident. Even
though both pilots were very well trained and had plenty of experience.
Commander Kleyber Aguiar Lima, from Porto Velho, was born on
March 22, 1953, and worked for TAM from November 1987 to July
2007 and had over 14,000 ﬂight hours in his career, and Commander
Henrique Stephanini Di Sacco, from S˜ao Paulo, who was born on
October 29, 1954, joined TAM in 2006 and also had over 14,000
ﬂight hours in his career (5). They knew that one thruster was not
functional and should have planned the landing as if neither thruster
would work. They knew that the landing strip was short, they also
knew that the strip was wet. The combination of the short landing
strip and the wet landing strip along with the malfunctioning thrusters
should have alerted the pilots to take a different course of action.

220
CHAPTER 14 Basic Fault Tree Analysis Technique
Precautions should be taken to improve traction during wet
weather. This includes cutting grooves in the pavement to allow the
water to ﬂow off the runway increasing the traction when an aircraft
lands. This airport just ﬁnished with major renovations on the landing
strip, it should have been mandatory that the strip be 100% ﬁnished
before being allowed for use.
Also, warnings from the government stating that the runway was
much too short for larger airliners to land on were passed off way too
quickly. Governmental rulings should be respected and with that the
changes must be made no matter how necessary to ensure the safety
of all the passengers on all the planes. The airport ofﬁcials knew that
the runways were too short to handle such large planes, and yet, they
continued to allow those planes to ﬂy to not disrupt the economy.
As with most aircraft crashes, there are several factors that lead
to the crash. The following is a list of items that contributed to the
crash. This list is then used to construct the fault tree that is depicted
in Figure 14.6:
• Runway was wet.
• Rain in area.
Crash of TAM
linhas aèreas
flight 3054
Runway was
wet
Thrust
reverser not
working
Runway not
long enough
Rain in
area
No grooves
in tarmac to
allow water
to run off
Policy
allowed
plane to be
flown
Thrust
reverser
broken
Runway was
constructed
incorrectly
Pilots not
trained for
situation
Pilots not
trained for
situation
FIGURE 14.6
Fault tree for TAM Linhas A´ereas Flight 3054.

References
221
• No grooves cut in runway.
• Thrust reverser broken.
• Airline policy allowed aircraft to be ﬂown with broken thrust
reverser.
• Runway too short.
• Airport policy allowed larger planes to land on runway.
• Experienced pilots had not had training in this situation.
The fault tree is very useful in showing how all the individual fac-
tors come together to cause the ﬂight to crash. Is this all of them? No,
there are some decision processes that the pilots went through, which
are not shown. These can be better modeled using HRA techniques.
These are discussed in Chapter 10.
14.8 SUMMARY
The FTA technique has proven to be a very rigorous and valuable tool
for analyzing complex systems. Strengths include an ability to analyze
down to a great level of detail, a simple presentation, and a systematic
method for analysis. Fault trees are used in a variety of disciplines and
can model many types of systems.
The PRA chapter discusses how FTA is used in conjunction with
other techniques to analyze complex systems.
REFERENCES
1. Vesely W. et al. Fault tree handbook with aerospace applications. National
Aeronautics and Space Administration, Washington, DC; 2002. Available at
http://www.hq.nasa.gov/ofﬁce/codeq/doctree/fthb.pdf. Retrieved 2010 Jan 17.
2. Fuetz R, Tracy J. Introduction to fault tree analysis. Boeing Product Development
Airplane Group; 1965.
3. Center for Chemical Process Safety (CCPS). Guidelines for Hazard Evaluation
Procedures. 2nd ed. with Worked Examples. New York: American Institute of
Chemical Engineers; 1992.
4. CNN. Pilot in Brazilian crash tried to abort landing, ofﬁcial says; 2007, Jul 18.
5. TAM Press Releases. www.tam.com; 2007, Jul 22. Available at http://www.tam.
com.br/b2c/jsp/default.jhtml?adPagina=3&aArtigo=10743.
Accessed
2007
Dec 5.

222
CHAPTER 14 Basic Fault Tree Analysis Technique
6. Accident description; 2007, Jul 6. Available at: Aviation Safety Network.
Accessed 2007 Jul 6. Available at http://aviation-safety.net/database/record.php?
id=20070717-0. Retrieved March 2011.
7. Ionides N. TAM A320 crashes in Sao Paolo; 2007, Jul 18. www.ﬂightglobal.com.
Available
at
http://www.ﬂightglobal.com/articles/2007/07/18/215565/breaking-
news-tam-a320-crashes-in-sao-palo.html. Accessed 2007 Dec 10.
8. Brazil plane ﬂew with mechanical fault. News.com.Au; 2007 Jul 27. Available at
http://www.news.com.au/story/0,23599,22104315-23109,00.html. Accessed 2007
Dec 12.

CHAPTER 15
Probabilistic Risk
Assessment
15.1 DESCRIPTION
Risk assessment has been a tool/technique used by humanity for much
of recorded history. Whether to ﬁght or ﬂee in situations where sur-
vival is at stake, and the decision to run or engage the threat in
many cases would involve some assessment as to whether or not the
struggle would be winnable. In “History of the Peloponnesian War,”
Thucydides attributes the Greek general Pericle with stating that the
advantage the Athenian army had was their ability to predetermine
risk and consequences prior to engaging an enemy. In recent years,
with the signiﬁcant advances in technology, the need to provide deci-
sion makers with tools to deﬁne risk and minimize the consequences
of undesirable events, equipment, and human failure, new tools have
been required to make these decisions. Probabilistic risk assessment
(PRA) is one of these tools.
Used initially by the aviation and nuclear power industry, its use
has been incorporated by environmental regulators and industry in
making cleanup decisions, in computer security analysis, and in indus-
try as a decision-making tool for increasing safety during all aspects of
design, operations, and upkeep of facilities. It also provides an analysis
to make cost saving decisions by demonstrating where efforts should
Risk Assessment: Tools, Techniques, and Their Applications, First Edition.
Lee T. Ostrom, Cheryl A. Wilhelmsen.
2012 John Wiley & Sons, Inc. Published 2012 by John Wiley & Sons, Inc.

224
CHAPTER 15 Probabilistic Risk Assessment
be exerted to gain the most beneﬁt or where to avoid the expenditure
of large amounts of time and ﬁnancial resources pursuing efforts of
little or no practical gain (1).
15.2 REQUIREMENTS OF THE RISK
ASSESSMENT
Any assessment of risk requires an in-depth technical knowledge of
the systems/processes being evaluated. The ability to deﬁne the sys-
tem(s) affected as well as the response both with and without operator
intervention is imperative to a valid assessment. Also important is the
ability to recognize the adverse consequents in the event of a failure or
misoperation of the facility and its component systems. If utilized to
meet a regulatory requirement, any requirement of that agency needs
to be identiﬁed and veriﬁed in the ﬁnal product. Rigorous analysis and
documentation of that analysis will make it more defensible as well
as facilitating peer review of the ﬁnal product. Peer review should be
conducted on all risk assessments utilized for decision making.
15.3 SIMPLIFIED PRA PROCEDURE
Dr. Micheal G. Stamatelatos (National Aeronautics and Space Admin-
istration, NASA) presentation, “Risk Assessment and Management,
Tools and Applications,” summarized a methodology ﬂow for PRA.
These steps are summarized as follows:
1. identiﬁcation of end states of interest;
2. system familiarization and data collection;
3. identiﬁcation, selection, and screening of initiation events;
4. deﬁnition and modeling of all scenarios linking each initiating
event to the end states;
5. modeling of pivotal events;
6. risk quantiﬁcation for each pivotal event and scenario; risk
aggregation for all like end states;
7. full uncertainty analysis; sensitivity analysis as needed;
8. risk importance ranking (2).

15.5 Qualitative Risk Assessment
225
15.4 HAZARD IDENTIFICATION
AND EVALUATION
Why do a risk assessment? In many modern endeavors, the conse-
quence of misperformance and casualties resulting from internal and
external events can lead to dire consequences and liabilities, both civil
and criminal. In order to protect people and their environment and thus
avoid these liabilities, some methods of identifying the potential haz-
ards (consequences) and the causes within the operation that could lead
to these hazards/consequences must be utilized. In many cases, a haz-
ard analysis is performed to identify and classify the hazards from an
initiating event. There are several methods that have been developed to
perform this analysis utilizing different schemes to perform and docu-
ment the analysis. The individual technique utilized is not as important
as consistent and defensible application of the technique used in iden-
tiﬁcation and classiﬁcation. For example, an analyst would probably
not want to classify one of two events leading to human casualties
as severe and the other event as insigniﬁcant. Another possible error
would be to classify a short-term release exceeding EPA regulatory
standards with no quantiﬁable adverse environmental effects as critical
while characterizing an event that leads to an occupational exposure
that hospitalizes several workers and neighbors as negligible (3).
15.5 QUALITATIVE RISK ASSESSMENT
In a simple model of risk assessment, the two factors comprising risk
are evaluated. Probability and consequence are analyzed and assigned
nonnumerical values. These may include high, medium, low, and
intermediate. Values assigned to consequence may include none, unde-
sirable, unacceptable, and effect (no, little, and signiﬁcant). A simple
evaluation tool can be constructed by forming a grid with probability
and consequence forming the x- and y-axes. While relatively sim-
ple in concept, it has been demonstrated to be useful for decision
makers. However, its simplicity limits its functionality for more com-
plex decisions such as modeling and event over time, incorporating
several actions with multiple outcomes. In addition, the modeling of
uncertainty would be impossibly difﬁcult. So in many cases, a more
powerful tool is needed.

226
CHAPTER 15 Probabilistic Risk Assessment
15.6 QUANTITATIVE RISK ASSESSMENT
The performance of quantitative risk assessment is a more detailed
process than the qualitative assessment process. Expert system/process
knowledge is a prerequisite to begin the assessment process. This
expert knowledge is gained through system knowledge, event/process
knowledge, knowledge of normal and abnormal conditions and casu-
alty operating procedures, and research on speciﬁc failure information.
Failure information is not merely the rate at which the equipment fails.
Other factors include modes of failure, the sample sizes (how many
failures, how many of a particular component are utilized), environ-
ments that were utilized, operating time/cycles, repair time, frequency
of periodic maintenance, or testing. Sources for information on the
failure can come from a wide variety of sources including manufac-
turer and government testing, maintenance databases, and databases
on existing or suspected failures from the Nuclear Regulatory Com-
mission (NRC), NASA, and National Transportation Safety Board
(NTSB), among others. Since these analyses are often performed on
complex systems, this process is often costly and time consuming.
Because of these factors, this type of assessment is only performed
when required by regulation and liability management, or when an
appreciable cost beneﬁt is expected to be achieved.
The risk assessment process consists of determining possible
events that could occur with detrimental consequences; for example,
loss of coolant at a nuclear reactor, loss of insulation on the wing
of the space shuttle, and a cyber attack on the infrastructure of
the internet are some of the possibilities. Another possibility is to
determine an adverse consequence and to reverse engineer (deductive
reasoning), the events to determine possible causes of the event. After
the initiating events are identiﬁed, the event is modeled to determine
possible sequences and outcomes of the event. These processes are
used to develop the ﬂow path of the event or casualty. NASA uses
the term master logic diagram for this process. At this point in
the development, the process is still qualitative in nature. With the
determination of the ﬂow path, it is possible to determine the set of
events, which will lead to the undesired or casualty event. This set of
events is known as the cut set. The minimum cut set is deﬁned as the
set of events, which cannot be reduced in number, whose occurrence
causes the casualty (or undesired event) to occur (2).

15.6 Quantitative Risk Assessment
227
The ﬁrst two parts of this process are utilized to develop fail-
ure modes and effect analysis (FMEA) and fault tree analysis (FTA).
In these processes, the events are diagramed to show the logical
sequences with possible outcomes. One key difference between the
two methods is that FMEA is an inductive logic process, while FTA
is primarily a deductive process. As part of the analysis of the fault tree
or failure mode, the possible causes of event are introduced. During
this process, Boolean algebra is utilized to reﬁne the logic, enabling
the event to be modeled mathematically. It is at this point the process
begins to convert to a quantitative process. The application of Boolean
algebra allows multiple probabilities to be combined into a total prob-
ability based on the interrelation of the events. For example, a ﬁnal
event can occur if a multiple set of events occur then the probability
of that event occurring is the sum of the probability of the individual
events. If in order for an event to occur, several events must occur.
The probability is the product of the probabilities of the requisite
events. Of course, this is a simple analysis, in that, time sequenced
requirements are not accounted for. An additional beneﬁt is the use of
standardized symbols for the mathematical logic.
The next step in quantiﬁcation of risk is determination of the prob-
abilities of individual events happening. At this time, the uncertainty
(often identiﬁed as error factor) associated with event probability will
be required to be identiﬁed. Since all probability has a certain amount
of uncertainty associated with its derivation due to measurement and
calculation techniques, there should be uncertainty associated with all
probability values. Factors that affect uncertainty include sample size,
difference between laboratory determinations, and operating condi-
tions in installed environments.
Another factor affecting equipment failure is reliability, availabil-
ity, and maintenance. If operation of a certain piece of equipment is
part of the analysis then factors that affect whether the component
is available to respond form a valid part of the analysis. Answers to
questions such as what percentage of time the equipment is available
form a vital part of the analysis. If a fan belt fails once in a hundred
attempts to start and requires several hours to repair, that could impact
the analysis of risk. A system that is routinely maintained and restored
will have different failure rates than one where the components are run
to destruction (no maintenance other than corrective is performed).

228
CHAPTER 15 Probabilistic Risk Assessment
The failure probability of many components analyzed will be a
function as to whether it is a discrete or continuous function. The
most commonly utilized discrete distributions are the binomial dis-
tribution and the Poisson distribution. For probabilities that may be
determined with a continuous distribution, the gamma, log-normal
exponential, and Weibull distributions are among the most common
distributions. Trial-and-error analysis to develop curve ﬁtting tech-
niques has also been utilized. Also, the synthetic mixed distributions
have been utilized to demonstrate mixed distributions of different dis-
tributions. These mixed distributions are achieved by combining the
distribution curves for different failure curves. For example, a com-
ponent with a high failure rate for a short period of time after initial
installation may have an exponential distribution curve for that mode
of failure and a gamma distribution for a longer term failure mode
such as a belt or bearing failure. By combining the two distributions,
an integrated curve can be developed.
Determination of the statistical method is dependent on the con-
ditions of operation and failure. Generally, a continuous distribution
determination is made based on comparing the underlying assumptions
for the distribution with the physical nature of the problem.
Another factor introduced during this process is human perfor-
mance or human reliability analysis (HRA). Since events leading to
and subsequent to an event can be caused, mitigated, or exacerbated
by the actions and nonactions of the operators, an analysis of human
performance is necessary to adequately account for all possible out-
comes and probability of occurrences. Human errors are classiﬁed as
errors of commission, errors of omission, mistakes, lapses, and so
on. Several sources of data are available based on industry studies.
These studies address a wide variety of possible errors and need to be
carefully considered for applicability to the given situation.
After identiﬁcation and quantiﬁcation of the individual events, the
aggregation of the risk can occur. During this process, the risks and
associated uncertainties are calculated for the cut sets. Because much
of the information used to generate statistic input are from sources
other than test data, often Bayesian analysis techniques are used. The
use of Bayesian statistics is required because the probabilities utilized
are considered variables rather than precise values. Because of this
approach, conﬁdence interval testing becomes essential in providing
validity to the calculations.

15.7 Uses of PRA
229
Uncertainty can be calculated by several methods, the most com-
mon being Monte Carlo testing. This technique utilizes random num-
ber generation from numbers associated with the distribution of all the
variables and follows them through the fault tree to ﬁnd the value of
all independent variables for the combination of dependent variables
associated with the components. This method was developed during
World War II to assist in modeling nuclear weapons design and is
used today for many purposes.
Another factor that should be analyzed during the aggregation of
risk is sensitivity. Sensitivity of the model is analyzed to ensure that
uncertainties in the data do not lead to wide, and perhaps unaccept-
able, variations in the calculated result. This may lead the analyst
to recommend certain parameters be constrained to preclude these
results. These constraints may require implementation of operational
and engineering controls in order for the risk assessment to be valid.
If implementation of these constraints is beyond the assessor’s control
then any boundaries of the assessment should be clearly identiﬁed.
While this process may be performed on a simple problem, the
complexity of most problems will drive most analysts to use a com-
puter software program speciﬁcally written for that purpose. Soft-
ware is available from governmental sources and private (proprietary)
sources.
15.7 USES OF PRA
As stated earlier, the reason to perform a risk assessment is to demon-
strate safety to both the workers and the public, as well as, save cost
by utilizing available funds in the most efﬁcient manner. For the latter
purpose, the PRA becomes a decision-making tool to assign resources
such as component maintenance and replacement, or to let equipment
with low consequence of failure operate with less upkeep. Implemen-
tation of engineered and administrative controls taking decisions from
operators under duress, or to minimize/prevent misoperation, may be
determined or warranted. The possibilities are unlimited and depend
on the speciﬁc operation.
If utilized to demonstrate safety to obtain and/or maintain
an operating permit, there may be certain regulatory and policy
requirements that must be met to rely on the risk assessment. In

230
CHAPTER 15 Probabilistic Risk Assessment
such an environment, the validity of any decision-making tool must
be scientiﬁcally defensible and the regulatory agencies have issued
requirements for risk assessments used in permit issuance (4).
15.8 CONCLUSION
PRA can be a valuable tool in the identiﬁcation, documentation, and
management of risk. If developed and implemented properly, the tech-
niques can help save costs, damages, and even lives. However, the
utilization of PRA presupposes a certain level of consequence that
some people ﬁnd difﬁcult to understand and accept. This condition
can be even more pronounced when the person does not perceive
a real beneﬁt from the operation, while the operation creates a risk
and the consequences are life threatening. An example is: a physician
once told a patient while informing him of a diagnosis of cancer that
it really did not matter that the probability of getting the cancer was
only 1 in 15,000; he was the one.
REFERENCES
1. Fullwood RR, Hall RE. Probabilistic Risk Assessment in the Nuclear Power Indus-
try Fundamentals and Applications. New York: Pergamon Press; 1988.
2. Stamatelatos MG. Risk Assessment and Management, Tools and Application, pre-
sentation by Dr. Micheal G. Stamatelatos.
3. McCormick NJ. Reliability and Risk Analysis, Methods and Nuclear Power Appli-
cations. New York: Academic Press; 1981.
4. Modarres M, editor. Volumes I and II, Proceedings of PSA’99, International Topical
Meeting on Probabilistic Safety Assessment. Washington DC: American Nuclear
Society; 1999.

CHAPTER 16
Qualitative and
Quantitative Research
Methods Used in Risk
Assessment
16.1 WHAT IS QUALITATIVE RESEARCH?
Qualitative research is not very simple to deﬁne. Sure, there are deﬁ-
nitions from Wikipedia, psychologists, and anthropologists to name
a few but it depends on what the researcher is trying to capture.
The medical world views qualitative research as a type of scientiﬁc
research, which looks for answers to questions by way of predeﬁned
procedures. “Qualitative research is especially effective in obtaining
culturally speciﬁc information about the values, opinions, behaviors,
and social contexts of particular populations” (1).
Qualitative research explores topics in more depth and detail than
quantitative and is usually less expensive. You can also use it in trying
to understand the reasons behind the results of quantitative research.
You do not perform any statistical test with qualitative research. Focus
groups and individual in-depth interviews are common tools used in
qualitative research. Therefore, I guess a simple deﬁnition could be
deﬁned as methods that at least attempt to capture life as it is lived.
Risk Assessment: Tools, Techniques, and Their Applications, First Edition.
Lee T. Ostrom, Cheryl A. Wilhelmsen.
2012 John Wiley & Sons, Inc. Published 2012 by John Wiley & Sons, Inc.

232
CHAPTER 16 Qualitative and Quantitative Research Methods
Go back to what the researcher is trying to focus on. Different
researchers focus on different sources of data. A researcher could
use his/her own experiences or others’ experiences through behaviors,
speaking, writing, technology, artwork, and so on. There are variations
in how the researchers collect their data as well. Some look at the
“past” and collect artifacts, life histories, or literature; others look at
the “present” through observation of what is happening now.
In John W. Creswell’s book, he uses ﬁve approaches to qualitative
research in both the inquiry and the design phases. These are listed as
follows:
1. narrative research;
2. phenomenological research;
3. grounded theory research;
4. ethnographic research;
5. case study research (2).
16.1.1 Narrative Research
Creswell deﬁnes narrative research as “the term assigned to any text
or discourse, or, it might be text used within the context of a mode
of inquiry in qualitative research (Chase, 2005), with speciﬁc focus
on the stories told by individuals (Polkinghorne, 1995)” (2) Webster’s
dictionary deﬁnes it as “something that is narrated, e.g. story, account
or the representation in art of an event or story; also: an example
of such a representation” (3). There are many different deﬁnitions
depending on the particular study of interest. To make it simple think
of it as a method in how and why we make meaning in our lives, a way
to create and recreate our realities. It is a study of human beings by
verbal or written acts of someone telling someone else that something
happened.
There are different forms in narrative research such as:
1. Biographical study, which is a study where the researcher
writes and records the experiences of another person’s life.
2. Autobiography, which is written by the individual himself or
herself.

16.1 What Is Qualitative Research?
233
3. Oral history, which is a compilation of events and causes,
found in folklore, private situations, and single or multiple
episodes (2).
In terms of looking at risk assessment, this would be valuable
in writing up observations, performing some comparisons, and devel-
oping a risk assessment plan to mitigate against the risk. Narrative
research is a way of understanding experience. Mishler describes ref-
erence and temporal order as being the relationship between the order
in which events actually happened and the order in which they are
told in narration. Again, this is valuable in determining risk by look-
ing at an event such as an airplane crash. We actually look backward
in trying to determine the cause of the crash. We look at data from the
airlines, from personal observation of the event, and from any video
or pictures that might exist of the event. We write everything down,
compare, and look at the relationship between the order of the actual
crash and the order in which they have been narrated. This not only
helps in understanding how the event occurred but why, so we can
again mitigate our risks.
Narrative research can also help in developing pilot studies to
gather information that helps design objective research tools. It is used
in applied research and basic research and used in the social sciences
as well as medicine.
16.1.2 Phenomenological Description
All experiences have both an objective and subjective component;
therefore, to understand a phenomena, you need to understand both
sides. In doing so, you look at it from all perspectives, using all your
senses, thoughts, and feelings. When using your senses, you need to
be prepared to listen. It is easy to talk and reason, but we sometimes
really forget to listen. You cannot hear anything if you are too busy
telling what it is. This also means we need to put aside all our biases
and even our common sense so that we can be open to the phenomenon
and accept it. This is not very easy to do. We tend to want to explain
everything and use science to help. For example, a psychologist looks
for how to measure knowledge, and cause and effect, so they may
say that anger is really just nervous system activation or that our
thoughts are just neural activities. These explanations are not found

234
CHAPTER 16 Qualitative and Quantitative Research Methods
in experiences. Creswell states, “A phenomenological study describes
the meaning for several individuals of their lived experiences of a
concept or a phenomenon” (2). So in essence, you look for what is
common among several individuals in experiencing a phenomenon.
One example might be grief. We all experience grief at one point in
our lives and many books are written on the subject. Think about a
time in your life you have felt grief. Try to recall it fully and then
write it down. Then ﬁnd a book with others’ experiences with grief or
ﬁnd other individuals that have experienced grief and ﬁnd the com-
monalities. What makes grief? In order to understand the feelings the
individuals are experiencing, you need to listen to how they “feel.”
Spiegelberg puts it nicely, “Phenomenology begins in silence” (4).
Pain is another phenomenon that individuals experience differently
and the same. We tend to migrate to those individuals who may be
experiencing similar problems so we can relate our experiences with
them. We can experience or recall the phenomenon and hold it in our
awareness. We live it or are involved in it. All of these are aspects
of a phenomenon. It is important to write everything down and relate
your experience to similar experiences. A good way to understand
phenomenological research is to relate an experience such as drinking
hot chocolate. You have to actually drink the beverage, savoring the
experience and describing the sensual experience of the taste, smell,
feel, and so on. You could do the same with sounds such as music or
listening to a bird.
16.1.3 Grounded Theory Research
The phenomenological research emphasizes the meaning of an expe-
rience and the grounded theory generates, or discovers, a theory. The
theory is generated or “grounded” from the data collected in the nar-
rative or phenomenological research. Now the researcher can generate
a theory or explanation of a particular action, process, or interactions
that have been shaped by the views of the participants (2).
First, you need to understand what is happening and the roles of
the players involved. You can do this through observation, conver-
sation, and interview processes. Take notes and record, or code, the
key issues. A comparison of the data begins and a theory emerges.
Then compare the data to the theory. Links may emerge between cat-
egories and a category may appear to be central to the study. Keep

16.1 What Is Qualitative Research?
235
adding to the sample with more theoretical sampling searching for any
different properties. When you reach saturation, it is time to start the
sorting process where you group memos with similar memos and then
sequence them in an order to clarify your theory. You are ready to
write as the theory emerges.
There are two types of grounded theory research:
1. Systematic procedures, which “seeks to systematically develop
a theory that explains process, action, or interaction on a topic
(e.g., the process of developing a curriculum, the therapeutic
beneﬁts of sharing psychological test results with clients)” (2).
Basically, you conduct 20–30 interviews to collect data to sat-
urate the categories, you continue to collect data and analyze
and then collect more data and analyze.
2. Constructivist approach, which is where you look at multiple
realities and the complexities of particular worlds, views, and
actions.
This theory depends on the researcher’s view through relation-
ships, situation communications, and opportunities. This research
relies more on values and beliefs, feelings, and assumptions. The
researcher has more control of the study, which could be labeled as
suggestive, incomplete, and inconclusive (2).
16.1.4 Ethnographic Research
Ethnographic research goes further than the grounded study research in
the fact that it collects data from more than the 20–30 individuals and
focuses on an entire cultural group. This study describes learned and
shared patterns of the group’s behaviors, beliefs, and language. Again
the process involves observation but more into the daily lives of the
people. The following are three deﬁnitions of ethnographic research:
When used as a method, ethnography typically refers to ﬁeldwork
(alternatively, participant-observation) conducted by a single
investigator who “lives with and lives like” those who are studied,
usually for a year or more (5).
Ethnography literally means “a portrait of a people.” An
ethnography is a written description of a particular culture—the

236
CHAPTER 16 Qualitative and Quantitative Research Methods
customs, beliefs, and behavior—based on information collected through
ﬁeldwork (6).
Ethnography is the art and science of describing a group or culture.
The description may be of a small tribal group in an exotic land or a
classroom in middle-class suburbia (7).
The three types of data collection methods used in ethnography
research are as follows:
1. interviews;
2. observations;
3. documents.
These three types of collection methods then lead to three types
of data:
1. quotations;
2. descriptions;
3. excerpts of documents.
Does this sound familiar? It is a narrative description that includes
diagrams and charts to tell the story. This is a difﬁcult research
method as you need to be a participant and yet an observer to describe
the experience to the outsiders. There are debates as to whether a
researcher really needs to be a participant to understand the group
being studied. However, if the researcher does immerse themselves
into the group, then the goals must be made clear to the members
of the group and they must consent to the study beforehand. The
researcher cannot harm or exploit the group.
The analysis begins with compiling the raw data to get a total
picture. The data are assembled in order and organized into patterns
or categories. “The analysis process involves consideration of words,
tone, context, non-verbals, internal consistency, frequency, extensive-
ness, intensity, speciﬁcity of responses and big ideas.” Data reduction
strategies are essential in the analysis (8).
16.1.5 Case Study Research
“Case study research is a qualitative approach in which the investiga-
tor explores a bounded system (a case) or multiple bounded systems

16.1 What Is Qualitative Research?
237
(cases) over time, through detailed, in-depth data collection involving
multiple sources of information (e.g., observations interviews, audiovi-
sual material, and documents and reports), and reports a case descrip-
tion and case-based themes” (2).
This method has been used for many years and within many differ-
ent disciplines to examine real-life situations. There are many debates
about how valid and useful this research method is. Some believe it
is only useful as an exploratory tool, while others believe the intense
exposure biases the ﬁndings. However, many successful studies have
used this case study method. Robert K. Yin has done a great deal of
work in the ﬁeld of case study research and in essence has proposed
a six-step process for performing case study research.
1. Determine and deﬁne the research questions.
2. Select the cases and determine data gathering and analysis
techniques.
3. Prepare to collect the data.
4. Collect data in the ﬁeld.
5. Evaluate and analyze the data.
6. Prepare the report (9).
The research questions start with either “why” or “how” to help
limit conditions and how they interrelate. A literature review is con-
ducted to see what is already in the literature on the topic. This helps
deﬁne the questions about the problem and thus determines the method
of analysis. The researcher can then determine what evidence they
want to gather and what analysis techniques they will use (e.g., sur-
veys, observation, interviews, or documentation review). The study
must be constructed to ensure validity, both internal and external, as
well as reliability.
A large amount of data are generated with case study research;
therefore, it is important to organize the data systematically to prevent
oversaturation and forgetting the purpose of the study. A good way
of organizing the data would be the use of databases, which stores
the data so you can sort, categorize, and retrieve it when you are
ready for the analysis phase. In essence, case study research is very
complex with the large amounts of data to analyze and the multiple
sources of data. Researchers may use this method to build on a theory,

238
CHAPTER 16 Qualitative and Quantitative Research Methods
dispute a theory, or even develop a new theory. They do relate to
everyday experiences and help in understanding the complexity of
real-life situations.
16.2 QUANTITATIVE
Quantitative research is the opposite of qualitative research. A hypoth-
esis is generated that needs to be proved or disproved usually through
statistical and mathematical means. Randomize the study groups and
where you can, include a control group. You should only manipu-
late one variable at a time to keep the analysis less complex. The
research should be able to be conducted again and receive similar
results. Quantitative research works well with qualitative research and
after the facts and the data have been collected.
Quantitative research usually involves numbers that can be statis-
tically analyzed to achieve the results. Hard sciences use quantitative
research to answer speciﬁc answers. There are four types of quantita-
tive research methods:
1. Descriptive involves collecting data to answer questions or test
a hypothesis.
2. Correlational tries to determine whether there is a relationship
between two or more quantiﬁable variables. There is no cause
and effect relationship, only a correlation coefﬁcient number
between 0.00 and 1.00.
3. Cause–comparative establishes a cause and effect relation-
ship and compares the relationship without manipulating
the cause.
4. Experimental again establishes a cause and effect relationship
but this time during the comparison the cause is manipulated.
In experimental, the cause or independent variable makes the
difference and the effect is dependent on the independent vari-
able (10).
Figure 16.1 illustrates the steps followed in conducting a quanti-
tative research study. Most people have experienced some sort of a
quantitative inquiry. The data are collected in the form of a survey

16.2 Quantitative
239
Define the problem
Conduct
literature
review 
Form
hypotheses 
Conduct study
Subjects and
population 
Instruments
used
Follow the
design and
procedures
Results
Data and
statistics
Inferential
statistics
Discussion
Inferential
statistics
Conclusion and
recommendation
FIGURE 16.1
Quantitative
research step process.
or questionnaire where the questions are used to measure important
factors on a numerical level. Some examples are as follows:
• telephone surveys;
• mail surveys;

240
CHAPTER 16 Qualitative and Quantitative Research Methods
• online surveys;
• panel research.
16.3 RISK ASSESSMENT PERSPECTIVE
Now that we have looked at both, qualitative and quantitative research
methods, we now talk about the part they play in dealing with risk
assessment. Risk is applied across various organizations and varying
circumstances, which does not have the same meaning across the var-
ious disciplines, organizations, or even individuals. In other words,
there is not a “one size ﬁts all” risk assessment method. One thing
they do agree on is the term risk carries a negative connotation such as
destruction, harm, or some undesirable event. Risk, as we have talked
about in other chapters, possesses unknown and unpredictable results
or consequences so there is that “uncertainty” element. With qualita-
tive research, we try to piece the event or story back together through
the different forms of research such as narrative research. Once we
reconstruct the pieces, we can then analyze those pieces and that is
where the quantitative research methods come into play. Without the
gathering of information and piecing together, we could not perform
any statistical analysis because the data just would not exist.
Some form of risk assessment is used to make decisions and decid-
ing how much effort should be directed toward avoiding undesirable
events. A valid risk analysis should have a procedure in place to deter-
mine the appropriate consequence and likelihood levels. When talking
about qualitative analyses, this would mean having adequate descrip-
tions for each of the levels of consequence and likelihood. Here is an
example that helps illustrate how qualitative and quantitative methods
can be used to identify the cause of an undesirable event.
There had been an accident involving two aircraft colliding in air.
The Federal Aviation Administration (FAA) and the National Trans-
portation Safety Board (NTSB), along with various agencies, are called
to investigate what happened. They cordon off the crash site and then
identify potential hazards. There are many hazards involved with this
type of accident such as toxic chemical releases from the fuel and
materials that make up the aircraft, as well as possible buildings or
industries that were damaged in the accident. You need to look at

16.3 Risk Assessment Perspective
241
those hazards and decide who might be harmed and how. You decide
what the potential risk is, for example, illness or injury. This allows
you to come up with the best plan for preventing those risks. Then
develop precautions to minimize the risk such as protective clothing
and equipment. By putting safety policies in place, it can help reduce
any harmful incidents in the investigative process.
Once they have the scene cordoned off and the potential hazards
identiﬁed, they need to piece together what happened and why it hap-
pened. Interviews from eyewitnesses are conducted in which they ask
the individuals to tell them everything they saw and heard. Does this
sound familiar? It is telling a story as to what that person saw and
heard. You may have 20 eyewitnesses or you may only have a few.
Either way you record every detail those individuals tell you. You may
get conﬂicting stories and so you have to look for the similarities and
identify those. You then ask the eyewitnesses to retell their account
of the event again going through this type of process repeatedly. The
eyewitnesses are using their senses to try to recall what they saw,
heard, and even felt during the incident. This is utilizing the narrative
research portion of qualitative research.
Now, the investigators have narrowed down the similarities and
start to piece a scenario together. There will most likely be holes in
the research. Possible data recorders or Global Positioning Systems
(GPS) within the aircraft, if found, could be analyzed. This would
help collaborate the accounts of the eyewitnesses and validate the data
you have collected. Usually, data from recorders are things such as
latitude or longitude, speeds, and directions. These can be quantiﬁed,
and using a technology, the accident can be recreated. It is important
to recreate what exactly happened so as to avoid such accidents in
future. Figure 16.2 illustrates this process.
16.3.1 Aviation Study
Various industries use both qualitative and quantitative methods to
collect data needed in determining what risks their companies and
employees face. One particular industry that uses both qualitative
and quantitative methods in determining risk factors is the aviation
industry. This case study involves a qualitative/quantitative or what is
commonly referred to as a mixed method study to assess the risks and
reliability of visual inspections of aircraft.

242
CHAPTER 16 Qualitative and Quantitative Research Methods
Review/
update
Report
findings
Cordon
crash site
Identify
hazards
Evaluate
risks
Investigation cycle
Record
FIGURE 16.2
Investigation cycle.
There have been several studies in determining estimated inspector
reliability for ﬁnding structural cracks in commercial aircraft and a
set of probability of detection (POD) curves were developed in the
1980s (11). These curves were used as part of the basis of the damage
tolerance-rating concept used by a major airline to help determine
inspection and maintenance intervals. These curves indicated that the
inspectors have a relatively small probability of ﬁnding cracks of less
than one inch in length. Data that are more current needed to be
collected in determining how well the inspectors actually estimated
these lengths visually. Therefore, a visual line length measurement
study was developed to determine inspector reliability (12). This study
was needed because it would impact the estimated POD for the cracks.
For instance, if inspectors always underestimated the crack lengths,
then the POD would be less than what would be predicted from the
actual data. If the inspectors overestimated the crack lengths, the POD
would be more than what would be predicted from the actual data. In
addition, airline structural parts are usually painted with gray or green
paint. The question existed as to whether the color of the part affected
the visual line length estimates. There was very little research available
to compare the literature ﬁndings; however, a paper on a basic visual

16.3 Risk Assessment Perspective
243
training course was helpful in deﬁning some of the processes and skills
an inspector follows while performing his/her duties. These included
perception, recognition, and attention.
Perception processes are used to organize, interpret, and extract
sensory information. Knowledge about the situation can inﬂuence the
perception. In other words, a person’s knowledge of the situation in
terms of prior experiences and formal education can inﬂuence what is
perceived and how it is interpreted. “At an early age, we fail to under-
stand that changes in distance and lighting do not alter the perceived
object. As we age, we develop the capacity to perceive the object as
constant even if we are a short or long distance away or if lighting
changes occur.” “This is a learned skill that allows us to perceive
an object as constant, even though the environment may suggest the
object has changed in size (distance), and in color (lighting)” (14).
Recognition represents the ability to process complex stimuli to
identify it as a class of objects. Therefore, when you see a friend’s face,
listen to a Celine Dion song, or taste tuna ﬁsh, you can recognize each
one as something you previously experienced. We combine stimulus
information and previous experience to produce recognition.
The inspection process involves observing and recognizing cracks
on a part of the airplane. Since perceptions are based on prior experi-
ences, knowledge, and expectations, the inspector’s experience plays
an important role. The difference in the expectations and knowledge
contributes to differences in perception (14). One of the comments
made by the inspectors at the airline was that if they knew that a
particular part was prone to having more cracks, they inspected that
area more carefully.
“Attention to sensory cues is at the control of the observer.
Research has shown, however, that with highly practiced and routine
tasks, attention can be automaticized (performed with little conscious
awareness)” (14). Three types of attention are used in inspection
activities depending on the task involved. Some require focused
attention, some selective attention, and some divided attention. The
selective attention allows multiple inputs to be processed. Divided
attention gives the ability to monitor two sources of input simultane-
ously and the ability to produce two different responses. A resource
intensive task, such as visual inspection, requires focused attention
on a single source of input and processing.

244
CHAPTER 16 Qualitative and Quantitative Research Methods
Referring back to phenomenological concepts, you can see the
inspector’s use their senses as they see, hear, feel, think, and judge
how long the crack may be and where it may be located.
The qualitative portion of this study involved a written survey
before the actual experiment took place. The inspectors met with the
researchers and a questionnaire was completed. The following is an
example of the survey used in this particular case study to help deter-
mine the inspectors experience level and percentage cracks they felt
they detected in performing their task.
1. How long have you been with this airline?
2. How many years have you been an inspector?
3. Before becoming an inspector what was your occupation?
4. What percentage of cracks do you measure?
5. What percentage of cracks do you eyeball?
6. Do you wear eyeglasses?
7. Are the glasses bifocals or trifocals?
8. Do you wear contacts?
9. How many inspections do you complete in a day?
When conducting an inspection are the lighting conditions: Good
Adequate Poor (13).
The results from the questionnaire indicated that the inspectors
were well experienced and most cracks were measured visually rather
than measured with tools.
The quantitative method involved collecting measurable data. It is
usually good practice to include protocol instructions so everyone gets
the same information before answering the questions. The following
is an example of the protocol used in this particular case study.
Protocol Instructions
Purpose of the study is to determine: How well do inspectors determine
crack length visually?
We have been looking at crack propagation data from xyz airlines
and actual inspection data from the airlines. In our analysis, we need
to statistically bound the data by knowing how accurately inspectors

16.3 Risk Assessment Perspective
245
conduct a visual inspection. From this, we will better predict inspector
reliability. This is to the beneﬁt of the airlines.
You will be looking at a series of crack mockups made up of a
skin panel, a lug, and a ﬂoor beam. The crack lengths range from 1/8
to 2 in. Please give us your ﬁrst impression of the crack length. There
is no time limit, but we are looking for your ﬁrst impression.
16.3.2 Design
The study was designed with 3 different mocked up parts, 2 colors,
and 16 line lengths: 1/8 to 2 in (the range of cracks we primarily saw
in the data). The three different mocked up parts used in this study
consisted of drawings of a lug, a beam, and a ﬂat panel. The two
colors were gray and green. They are the main colors used in aircraft
parts. To help determine consistency, seven measurements of each
of the gray parts were repeated in random order. The measurements
repeated were 5/8 to 1 and 3/8 in. Therefore, the gray lug, beam, and
panel had additional data to analyze.
The mocked up parts were drawn on a 8.5 × 11 in colored card-
stock with the cracks drawn on the parts. These drawings were devel-
oped in AutoCAD to the speciﬁc measurements and each was hand
measured to ensure accuracy. Each mocked up part was laminated and
the back of the card contained a code number, which corresponded
with the correct measurement. Therefore, the cracks were true mea-
surements. The design for the study is illustrated in Figure 16.3.
Twenty inspectors completed the experiment, the spreadsheet con-
tained 96 × 20 = 1920 data points. The data analysis showed that
inspectors primarily underestimate the length of the small lines and
begin to overestimate the length of the larger lines (13).
This is only a portion of the actual study, but it illustrates how
using both quantitative and qualitative methods to collect the data can
help in determining risk assessments in any industry. This particular
mixed method approach determined the following:
1. Inspectors overestimate the length of 1 in. or less and begin to
underestimate the length of lines longer than 1 in. The relation-
ship between the estimates and line length can be represented
by a linear regression equation.

246
CHAPTER 16 Qualitative and Quantitative Research Methods
Methods and Design 
 
 
 
 
Independent Variables
Dependent Variable
crack lengths 
Packets
Inspector
Performance on the detection of
Colors
Order
Crack Length
*Block on the inspector
 
Method
(Randomizing order & color)
P1  2 sets of panel length cracks-(1 green & 1 gray) 
Same inspector 
 
P3 2 sets of floor beam length cracks-(1 green & 1 gray) 
 (2 × 3 × 16 = 96) 
One airline analyzed 
*Blocking on the inspector means how the control is used for
the design.  We block out the inspector for control.
P2  2 sets of lug length cracks-(1 green & 1 gray) 
FIGURE 16.3
Example of the design for the visual crack study given to
inspectors (13).
2. Mocked up part type did have an impact on the inspectors’
ability to estimate the line length. Lines drawn on the parts
without any points of reference such as the ﬂat panel appear
to inﬂuence the inspectors’ estimate more than when a refer-
ence point is available. For instance, the mocked up ﬂoor beam
with the holes of standard size allowed the inspectors a refer-
ence point; therefore, they appeared to estimate slightly more

References
247
accurately the length of the line. (This aspect could be further
studied for risk assessment involving the importance to safety
and quality in both industrial and military operations.)
3. The shift the inspectors were on also affected the estimates.
The swing shift was the least accurate and the graveyard shift
was the least consistent.
4. The color of the mocked up parts used in this study did not
affect the estimates.
5. Gender differences could not be determined.
The above case study illustrated that the best way to determine risk
assessment is to use a mixed method study. A combination of both the
qualitative and the quantitative information assesses risk assessment
from all aspect (14–16).
16.4 CONCLUSION
Qualitative and quantitative research methods are best used in tandem.
Various organizations and disciplines use risk assessment to determine
the extent of potential threats and risks associated with their organiza-
tion. Both qualitative and quantitative research methods can be used
in helping to assess those risks through observation, questionnaires,
interviews, surveys, and so on. Then the data can be derived from the
data collected. The results can be input and can be used to mitigate
and reduce risks.
REFERENCES
1. Qualitative Research Methods: A Data Collector’s Field Guide. FHI.org. Avail-
able at FHI.org: http://www.fhi.org/nr/rdonlyres/etl7vogszehu5s4stpzb3tyqlpp7roj
v4waq37elpbyei3tgmc4ty6dunbccfzxtaj2rvbaubzmz4f/overview1.pdf.
Retrieved
2011 Sep 19.
2. Creswell J. Qualitative Inquiry & Research Design—Choosing Among Five
Approaches. 2nd ed. Thousand Oaks (CA): Sage Publications; 2007.
3. Chase, 2005.
4. Polkinghorne, 1995.
5. Webster M. Merriam-webster.com 2011. Available at merriam-webster.com
http://www.merriam-webster.com/dictionary/narrative. Retrieved 2011 Sept 20.

248
CHAPTER 16 Qualitative and Quantitative Research Methods
6. Spiegelberg H. The Phenomenological Movement. The Netherlands: Kluwer Aca-
demic Publishers; 1982.
7. Van Maanen J. Ethnograhy. 2nd ed. London, Routledge: The Social Science
Encyclopedia; 1996.
8. Harris M. Cultural Anthropology. 5th ed. Needham Heights (MA): Allyn and
Bacon; 2000.
9. Fetterman DM. Ethnography. 2nd ed. Thousand Oaks (CA): Sage Publications;
1998.
10. Krueger AR. Focus Groups: A Practical guide for Applied Research. Thousand
Oaks (CA): Sage Publications; 1994.
11. Yin RK. Case Study Research: Design and Methods. Newbury Park (CA): Sage
Publications; 1984.
12. Ostrom LA. Probability of crack detection. System Safety Conference; 2002.
13. Wilhelmsen CA. Aviation Visual Measurement Accuracy; 2002.
14. Toquam JM. Basic Visual Observation Skills Training Course Appendix A. The
International Atomic Energy Agency, Department of Safeguards; 1995.
15. Boardman J. Risk–A four letter word. 39th APPEA Conference; Perth; 1999.
16. Ostrom LA. Guide for Developing and Evaluating Procedures Using Risk Assess-
ment Techniques; 2002.

CHAPTER 17
Vulnerability Analysis
Technique
17.1 INTRODUCTION
Vulnerability assessment and risk assessment are in essence the same.
They both seek to determine risks to a system, a building, a plant, a
ship, an airplane, a country, or people. However, vulnerability assess-
ment is usually more interested in determining vulnerabilities in a
system, building, plant, ship, airplane, country, or persons from per-
sons, organizations, or countries with intent on doing harm. It is also
common to call a risk assessment a vulnerability assessment if it
concerns natural disasters, such as earthquakes, hurricanes, tornados,
ﬂoods, or strong storms.
In this regard, the initiating event is someone, an organization, or a
country that wants to harm the system. In the case of a natural disaster,
the initiating event is an earthquake or tornado. The probability of the
initiating event, therefore, is 1.0 or 100%. The subsequent analysis
determines where in the system the vulnerabilities reside. The same
tools can be used to conduct vulnerability assessments that are used to
conduct a risk assessment. The outcome of a vulnerability assessment
is used by analysts to modify the system to reduce the probability of
a vulnerable component or to eliminate it.
Risk Assessment: Tools, Techniques, and Their Applications, First Edition.
Lee T. Ostrom, Cheryl A. Wilhelmsen.
2012 John Wiley & Sons, Inc. Published 2012 by John Wiley & Sons, Inc.

250
CHAPTER 17 Vulnerability Analysis Technique
Common parts of a vulnerability assessment are:
1. background
2. purpose
3. scope
4. assumptions
5. description of system
a. system attributes
b. system sensitivity
6. systems security
a. administrative security
b. physical security
c. technical security
d. software security
e. telecommunications security
f. personnel security
7. system vulnerabilities
a. technical vulnerability
b. personnel vulnerability
c. telecommunications vulnerability
d. environmental vulnerability
e. physical vulnerability.
Another common nomenclature difference between a risk assess-
ment and a vulnerability assessment is that usually the ﬁrst step in a
vulnerability assessment is called a threat assessment. This is analo-
gous to a hazard assessment in a risk assessment.
Two case studies are used to demonstrate how vulnerability assess-
ments are performed. The ﬁrst uses a preliminary hazard analysis
(PHA) approach to analyze a facility for vulnerabilities associated with
a potential intruder attack. The second is a much broader assessment
examining the vulnerabilities of a multipurpose academic building.

17.2 Case Study 1: Intruder
251
17.2 CASE STUDY 1: INTRUDER
One of the scariest types of events that have become far too com-
mon is an armed intruder who intends to do harm to the occupants
of a building. A vulnerability assessment can be used to help identify
those vulnerabilities of the building that can contribute to the event.
These types of assessments can be performed using PHA, failure mode
and effect analysis (FMEA), tree analysis techniques, and even prob-
abilistic risk assessment techniques. No matter what the technique
is, the vulnerability assessment assumes an intruder will attempt to
gain access to a building. The scenarios that are exercised during the
assessment must be realistic and reasonable. For instance, a realistic
and reasonable approach is to assume one or two armed individuals
will seek to kill and injure as many employees in a corporate ofﬁce
as possible. It is unreasonable and unlikely that a squad of ninjas with
intent of world domination will invade a local car dealership.
The types of intruder scenarios exercised for a community hospital
vulnerability assessment might include:
• disgruntled employee seeking revenge;
• disgruntled patient or family member seeking revenge;
• estranged father trying to abduct or harm a new baby;
• drug-related invasion of a pharmacy;
• mental patient reeks havoc;
• patient has a bad reaction to a drug and reeks havoc;
• random violence.
Hospitals are especially vulnerable because of the mix of patients,
staff, family members, and drugs. Most hospitals, until the present
time, were designed to be open and allow free movement between
ﬂoors and areas of the hospitals. With increased potential threats, hos-
pitals, as well as schools, will take on air of a secure facility. The
Federal Emergency Management Agency (FEMA) has a series of pub-
lications concerning improving the security and safety of facilities such
as hospitals and schools (http://www.fema.gov/plan/prevent/rms/) (1).
Table 17.1 shows an example of PHA type of analysis for a hos-
pital in response to the threat of an armed intruder. Note that this is
not a complete analysis.

TABLE 17.1
Partial Vulnerability Assessment of a Community Hospital
Threat
Location
Current situation
Potential events
Proposed mitigating factor
Armed
intruder
Main
lobby
Open lobby, with three
volunteers at a receiving desk
Three corridors, 60-in wide,
radiate from the lobby. There
are two cameras that monitor
the lobby. One security guard
monitors these cameras, along
with 22 more cameras.
Intruder can attack volunteers or
can walk past volunteers and
enter other parts of the hospital
Lobby is manned by two armed
security guards. Doors are
placed on the corridors, with
electronic locks that are
opened by the guard or by
code. Add a security guard to
the camera monitoring task
Armed
intruder
Neonatal
ward
The ward contains 16 beds for
new infants. It is a classic
neonatal ward, with a large
viewing window. The room is
separated from the hallway by
a door with an electronic lock
that requires a code
Intruder could walk in with a
staff person or watch a staff
person enter the code and then
use the code to gain entry to
the ward when no staffs are in
the room. A camera does not
monitor the door
Change the code pad with a
card reader. Update the access
codes on the cards at least on a
monthly basis. Consider
having a staff person in the
neonatal ward at all times. Add
a camera to monitor the door
252

Armed
intruder
Pharmacy
The pharmacy has three entrances.
There is an outside door that is
used to receive supplies from
delivery trucks. There is an
entrance from the main corridor
that is used by pharmacy staff
during the course of the day There
is a side door to the corridor that
leads to the operating rooms. The
outside entrance has a keypad
lock. The other two entrances
have card readers. The doors are
alarmed. The main entrance door
is a hollow-core door. The
dispensing window is made from
plate glass. There is a camera at
the dispensing window, but no
other cameras. One to two
pharmacists are on duty from
900am till 600pm. There are
atleast two pharmacy technicians
on duty at all times between
900am and 600pm. Response time
to the pharmacy from the security
ofﬁce is 5 min
An armed intruder could gain
access to the pharmacy during
nonworking hours. An intruder
could break through the main
entrance door and security guards
could not respond before the
intruder has time to grab
pharmaceuticals and vacate the
facility. An armed intruder could
force the pharmacists to produce
drugs during working hours. The
main entrance door and dispensing
window are not made of strong
enough materials. There is no
camera monitoring the main door.
Replace the main entrance door
with a stronger door. Replace the
glass in the dispensing window
with toughened polycarbonate or
bullet proof glass. Increase the
number of cameras to monitor all
entrances to the pharmacy
253

254
CHAPTER 17 Vulnerability Analysis Technique
17.3 CASE STUDY 2: MULTIPURPOSE
ACADEMIC BUILDING
The purpose of this vulnerability assessment was to determine the
risks associated with a multipurpose academic building. The building
contains classrooms, ofﬁces, and chemical, biological, and engineering
laboratories. The types of hazards analyzed for this risk assessment
fall into three basic categories: building, natural, and man-made. An
analysis of the building hazards due to the building itself and its asso-
ciated systems will determine the impact on all personnel who work
within the building. An analysis must also be performed on the impact
to those who are not working in the building such as personnel in other
university buildings and the public as well as to the environment in
the event of a release of hazardous materials. Natural and man-made
hazards will be analyzed for the same reasons. However, in this case,
the analysis must also address the hazards outside of the university
and their impact on the building. The basic requirement for conduct-
ing a risk assessment (or hazard assessment) comes from 29 CFR
1910.1200, “Hazard Communication,” and the “Superfund Amend-
ments Reauthorization Act (SARA) of 1986, Title III, The Emergency
Planning and Community Right-To-Know Act.”
The purpose of this risk assessment was to identify materials at
risk such as chemicals and potential energy sources such as mechanical
and electrical energy. Security of the building is included in this risk
assessment. Once all hazards have been identiﬁed, a qualitative assess-
ment was performed on the risk of each hazard that may cause harm.
Their modes of failure and their associated controls were then identi-
ﬁed. A PHA was not performed since the building was already built.
This risk assessment was conducted as a follow-up to construction. It
is assumed that the event would occur regardless of cause, probability,
and frequency. Many mitigations and controls are mandated by law
and codes regardless of their chances of occurring.
There are many requirements governing the hazards and their
controls. The Code of Federal Regulations (CFRs) set the minimum
standards for them. However, there are consensus codes established
by societies that implement and improve on the CFRs. Subject matter
experts (SMEs) are important to consult in order to determine these
codes and requirements. The following sources should be consulted,

17.3 Case Study 2: Multipurpose Academic Building
255
but not limited to, in order to determine which consensus codes to
apply.
1. American Conference of Industrial Hygienists (ACGIH)
2. American Glovebox Society (AGS)
3. American National Standards Institute (ANSI)
4. American Nuclear Society (ANS)
5. American Society of Heating, Refrigerating and Air Condition-
ing Engineers (ASHRAE)
6. American Society of Mechanical Engineers
7. Compressed Gas Association
8. National Fire Protection Agency (NFPA)
9. National Institute for Occupational Safety and Health (NIOSH)
10. Scientiﬁc Apparatus Manufactures Association (SAMA)
11. Sheet Metal and Air Conditioning Contractors’ National Asso-
ciation (SMACNA)
12. State and local planning, zoning, and building codes.
The ﬁre department has resources on hand to assist in proper
emergency response. These can assist in determining hazard controls
during emergency response. These sources would include the follow-
ing, which are available online.
1. CHEMTREC
2. Chemical Hazards Response Information System (CHRIS)
3. Computer-Aided
Management
of
Emergency
Operation
(CAMEO)
4. Emergency Response Guide (ERG).
17.3.1 Methods of Collecting Information
The following is a list of the various methods used to collect infor-
mation for the risk assessment:
1. Task Analysis

256
CHAPTER 17 Vulnerability Analysis Technique
a. The task analysis will aid in identifying the tasks performed
and the associated hazards with performance of those tasks.
This will identify the hazards the personnel will be exposed
to which require mitigation and controls plus any training
required. A task analysis is typically a table-top analysis
performed by the analyst and a group of SMEs
2. Observation of Personnel
a. Direct observation of personnel performing duties at the job
site supports the task analysis. It identiﬁes the hazards they
will be exposed to while working or by their being in the
proximity to hazards. Observation will assist in determining
those tasks performed that a table-top task analysis may
miss.
3. Walk Down of Building and Processes.
a. This will allow the analyst to actually see and identify the
actual hazards that are currently in place in the facility.
Applicable drawings and procedures should be used to assist
in identifying hazards. A walk down of the surrounding area
will identify the areas and people that the facility hazards
may affect and identify outside hazards that may affect the
facility. This will identify hazards that will affect the per-
sonnel in the facility, the public, and the environment.
4. Interviews with Subject Matter Experts (SMEs)
a. There are many types of hazards and controls associated
with any facility. No one person can be an expert in multi-
ple ﬁelds or know all requirements. Consulting with SMEs
for the various areas (chemical, biological, radiological, ﬁre,
electrical, industrial hygiene, etc.) is necessary to ensure all
hazards are identiﬁed and the appropriate code or standard
is applied. The following are those SMEs consulted for this
analysis.
1. Chemistry and Biology lab managers
2. Research lab manager
3. Maintenance supervisor
4. Public Safety Manager and ofﬁcers.
5. Local Fire Chief
6. Local Police department

17.3 Case Study 2: Multipurpose Academic Building
257
7. Local records department
8. Local building inspector
9. The architectural ﬁrm that designed the building
10. County emergency planner
11. Various SMEs for various functions such as industrial
hygiene, ﬁre safety, industrial safety, radiological con-
trols, chemical coordinators, and hazardous waste man-
agers. The ﬁre marshal and building contractor would
make valuable resources.
5. In addition to the regulatory requirements and consensus
code resources mentioned above, a review of existing docu-
mentation, policies statutes such as the following but are not
limited to
a. building drawings;
b. area maps;
c. local ordinances;
d. Idaho Statutes;
e. university policies.
17.3.2 Task Analysis
The following is a list of the various tasks performed in the building
by faculty and students.
1. Handle chemicals in laboratories (acids, bases, salts, ﬂamma-
bles, metals).
2. Grow biological cultures.
3. Handle radioactive materials.
4. Operate bunsen burners.
5. Operate laboratory natural gas shutoffs.
6. Operate compressed gas bottles.
7. Operate cryogenic systems.
8. Operate emergency eyewashes and showers.
9. Dispose of hazardous waste.
10. Operate ﬁre extinguishers.

258
CHAPTER 17 Vulnerability Analysis Technique
The following is a list of tasks performed by maintenance person-
nel in the building.
1. Operate the building ventilation system.
2. Operate electrical breakers and disconnects.
3. Operate natural gas shutoffs (laboratory and building).
4. Operate compressed gas bottles.
5. Operate cryogenic systems.
6. Operate and perform maintenance on emergency eye washes
and showers.
7. Dispose of hazardous waste.
8. Operate ﬁre extinguishers.
9. Operate and perform maintenance on boilers.
10. Mix and add water treatment chemicals.
11. Access cooling water sump and perform maintenance on cool-
ing water pumps.
12. Access cooling tower and perform maintenance on cooling
tower components.
13. Perform maintenance on electrical systems.
14. Perform maintenance on plumbing systems.
15. Perform maintenance on building structures.
16. Perform maintenance on elevator.
17. Perform maintenance on natural gas lines.
The following is a list of tasks performed by public safety in the
building.
1. Maintain lab and building security.
2. Enforce student code of conduct.
3. Enforce state and federal laws.
4. Render emergency medical aid.

17.3 Case Study 2: Multipurpose Academic Building
259
17.3.3 Risk Assessment
The risk assessment will include a description of the building
and systems and the surrounding area. It will also include the
hazards, both internal and external to the building; the risks and
consequences of those hazards; their likelihood; and their controls.
Hazard classiﬁcation for each hazard reﬂects the credible worst-case
potential consequence. Hazard classiﬁcations range from class I–IV.
Class I hazards are negligible. Class II hazards have marginal effects
with minor consequences. Class III hazards are critical in nature,
which can cause severe injury or damage to equipment or the facility.
Class IV hazards have catastrophic consequences leading to death,
disabling injuries, and loss of a facility or system. For the purposes
of this analysis, the hazards are basic and straightforward. Failure
is assumed regardless of the cause or mode. The controls will be
the same regardless. Therefore, a quantitative analysis, a fault tree
analysis, and a human reliability analysis event tree need not be
performed. It is assumed that there will be equipment failure or
human error.
General Description
The multipurpose academic building was designed in 1991; construc-
tion began in 1992 and was completed in 1994. It is located on a
hill approximately 100 ft from a major western river. The geographi-
cal area is a high plains desert with an annual rainfall of 14.21. The
desert contains grasses and sage brush with lava ﬂows. Farming is
predominant in the surrounding area. The building is located next to
a city park. There are ofﬁce buildings, residential areas, and research
laboratories in the vicinity. The local regional airport is located across
the river nearby to the west next to an Interstate. Major highways
are to the east a short distance away. Two railways are located to the
north as well as to the east in close proximity. The campus where the
building is located includes other buildings. The building conducts
research for various nonuniversity groups in the science, mechanics,
and materials (SIMM) Laboratory for the university. The building also
has a chemistry and biology lab for students. The following sections
describe in more detail the building.

260
CHAPTER 17 Vulnerability Analysis Technique
Building and Systems Design
1. Multipurpose Academic Building
a. 65,336 ft3.
b. Built to 2B seismic code.
c. Built to withstand 70 mph wind.
d. 33 lb/ft2 snow loading.
e. 30-in frost depth.
f. Located outside 100-year ﬂood plain on hill.
g. Construction type 2 for occupancy: 1 h ﬁre rating. A-3 and
B-2 occupancy for the number of people to occupy building,
number of exits, size of corridors, and number of sprinklers.
h. The steel framework and other structures are built to a 3-h
ﬁre rating. Interior materials are rated for 1 h. Stairs and
walls around laboratories rated for 2 h. Stairs are designed
for ﬁre safe area for rescue. Wall materials are ﬁre rated and
tested per Underwriters Laboratories (UL), Gypsum Asso-
ciation (GA), International Conference of Building Ofﬁcials
(ICBO), and American National Standards Institute (ANSI)
standards.
i. Elevator installed for third ﬂoor access for the disabled.
j. Building rated for importance factor of 1 (low).
k. Rooﬁng built to class A standards. It includes gypsum ther-
mal barrier, insulation, and single-ply material for rooﬁng
membrane.
l. Parking lot size built to accommodate faculty and students
and is lit at night.
m. Stormwater pollution prevention is not required, but there
is a drainage pit at the end of the parking lot for rainwater
runoff.
n. The building is not constructed to prevent ﬂooding. How-
ever, the foundation has been sealed for seepage. Planter
boxes in the front of the building have water weep holes
installed.
o. Access to the facility is by a park access road. Exiting
the facility can be by the normal access route or by the

17.3 Case Study 2: Multipurpose Academic Building
261
local laboratory ofﬁce building parking lot (access normally
restricted) or by the side entrance to park that leads to
another entrance/exit.
2. Ventilation
a. 16 ventilation fans located on top of the building.
b. 100% air exchange rate every 10 min.
c. Laboratory ventilation is separate from the rest of the build-
ing ventilation. Systems are redundant.
d. Ventilation is monitored by computer.
3. Natural Gas
a. Enters building on north side by the north exit. Supplies
the laboratories. Main shutoff is located where the gas line
meters the building. Laboratory shutoffs located at the lab-
oratory exits.
b. Natural gas supplies two maintenance buildings that are
next to the building just to the west. Shutoffs are located
next to each building.
4. Cooling Tower
a. A cooling tower for the ventilation heat recovery system is
located outside of the building next to the building on the
west side.
b. The cooling tower’s cooling water system has a sump with
pumps in the mechanical room.
5. Fire Water and Fire Systems
a. Fire water enters the building through the mechanical room.
All rooms and hallways have sprinkler systems. The piping
is ﬁlled with water (wet pipe). The system is monitored by
an electronic ﬁre alarm panel.
b. Fire alarm pull boxes are located at the exits.
c. Smoke detectors will activate the ﬁre alarm.
d. Fire extinguishers are located in the hallways near the exits
and half way down the hallways. Fire extinguishers are
located in each laboratory.

262
CHAPTER 17 Vulnerability Analysis Technique
e. Fire hydrants are located near the main entrance next to the
parking lot and at the south west corner of the building.
6. Plumbing
a. Supplies bathrooms, water fountains, and laboratories.
(Note: This is considered a nonhazard; however, for the
analysis, it will be considered as a source for contamination
of laboratory chemicals entering the environment via
sinks. If piping were to break, there are no hazards severe
enough to cause any problems.)
7. Electrical
a. Electrical power to the building is supplied by city power
via a transformer next to the south side of the parking lot.
Supply breakers for equipment are located in the mechan-
ical room.
8. Boilers
a. There are four 1M BTU boilers located in the Mechanical
Room for building heating.
9. Fume Hoods
a. In each laboratory.
b. Ventilation separate from main ventilation. Each hood has
a HEPA ﬁlter.
10. Glove Boxes
a. In the SIMM laboratory.
b. Ventilation separate from main ventilation.
11. Public Safety
a. The university employs its own security force. Public safety
is not law enforcement but will ensure all federal and state
laws are being enforced as well as local policies.
b. Public safety ofﬁcers have law enforcement background,
typically hired from the law enforcement academy. Some
are currently serving duty as law enforcement or have in
the past.

17.3 Case Study 2: Multipurpose Academic Building
263
Hazards
1. Chemicals (Class IV Hazards)
a. Assorted acids, bases, salts, ﬂammables, and metals. Inven-
tory and quantities are considered restricted on a need-to-
know basis. No more than 55 gal of materials in total is
present.
b. Satellite accumulation areas (SAA) for the laboratories and a
temporary accumulation area (TAA) in the SIMM laboratory
for disposal of hazardous waste.
c. Water puriﬁcation chemicals for cooling tower.
2. Compressed Gases (Class IV Hazards)
a. Compressed gases in bottles such as nitrogen, argon, helium,
and hydrogen in laboratories.
b. Argon Dewar in SIMM laboratory.
3. Radiological (Class II Hazards)
a. Small quantities of radiological materials are present. Types
and amounts considered restricted on a need-to-know basis.
4. Biological (Class II Hazards)
a. Small quantities of Escherichia coli and Salmonella.
b. Located in the biology laboratory’s refrigerator.
5. Systems (Class IV Hazards)
a. Building
1. Third ﬂoor not wheel chair accessible other than by ele-
vator.
b. Natural gas
1. Supplied to laboratories for Bunsen burners. Shutoffs to
laboratory gas supply located at exits. Building supply
and shutoff located north end of building.
c. Cooling tower sump
1. In mechanical room. Deep sump. Has lid with wench.
Access door to room locked.

264
CHAPTER 17 Vulnerability Analysis Technique
d. Electrical
1. Wiring
2. Flooding
3. Laboratories (chemicals)
4. Power outages.
e. Boilers
1. Steam
2. Electrical.
f. Fire
1. Electrical
2. Chemical (laboratories)
3. Lightning
4. Hydrogen
5. Natural gas
6. Combustibles (microwave oven cooking, cigarettes).
6. External Hazards
a. River/ﬂooding (class I hazards)
1. The river is located approximately 100 ft from the build-
ing. The building is on a hill and is approximately 25 ft
above the elevation of the river. The building is located
just outside of the 100-year ﬂood plain. The building
area did not ﬂood in 1976 when a local dam broke nor
did it ﬂood during the 1997 ﬂood.
2. Sources of ﬂooding include water from rapid snow melt
and storms. Another source is from the Palisades and
Ririe Dams if they were required to release excess water
from snow melt or if they fail.
b. Wildﬁres (class IV hazards)
1. The desert surrounding the area, mainly to the west
and southwest contains grasses and sage brush. There
is an open ﬁeld adjacent to the building. These are
ﬁre hazards with the potential to cause wildﬁres. The
area has frequent droughts, which increase the risk of
wildﬁres.

17.3 Case Study 2: Multipurpose Academic Building
265
c. Weather (class II hazards)
1. Thunderstorms can cause ﬂooding. Wildﬁres, structural
ﬁres, and power outages are caused by lightning strikes.
Thunderstorms can create high winds that can damage
structures. Power outages may occur.
2. Tornadoes/high winds may damage structures and cause
power outages.
3. Winter storms and blizzards can create high winds and
also heavy snow packs on roofs. With power outages,
there may be freezing temperatures inside the building,
which can rupture water pipes.
d. Earthquake (class IV hazards)
1. The town is located in a 2B seismic zone. Yellow-
stone National Park, located 110 miles from the town, is
seismically active. The high desert has volcanic buttes.
Two of the largest earthquakes in the continental United
States in the past 40 years have occurred within 150
miles of the town.
e. Electrical (class II hazards)
1. Power outages can result in the loss of building venti-
lation and loss of heating. Loss of heating in the winter
can result in water pipes freezing and bursting.
2. Electrical shock (class IV hazard) can severely injure or
cause death.
f. Local national laboratory (class I hazards due to location)
1. There is a national laboratory west of the building. It
conducts research with nuclear reactors and materials.
The facility also has hazardous chemicals. The closest
nuclear facility is located 30 miles west of the building.
2. The facility has a research laboratory in the town
approximately 1 mile away to the east. It may contain
small quantities of biohazards at any given time.
g. City (class III hazards)
1. The city has water pump houses located throughout
the city. Two are within 1 mile of the building.

266
CHAPTER 17 Vulnerability Analysis Technique
Each pump house has 2–150 lb chlorine bottles
for water treatment. South east of the city is the
water treatment plant that has a 1500 lb container of
chlorine. It is located approximately 2.5 miles from the
building.
2. The regional airport is located 1100 ft to the west of the
building across the river and the interstate.
h. Interstate, highways, and railways (class IV hazards)
1. Two railways, an interstate, and two highways are in
close proximity to the building. A railway to the north
east is 800 ft away. Another is located to the east and is
1.5 miles away. The interstate is to the west across the
river 1000 ft away. The highways are to the east 3500 ft
and 2.25 miles away, respectively.
2. This is considered by the local ﬁre department and
the County Director of Emergency Management to
be the most severe source of hazards in the county.
Trains and trucks transport many types of hazardous
materials. Depending on the material and the amount
and leak rate, the emergency planning zone can be
5 miles.
i. Palisades and Ririe Dams (class II hazards due to location)
1. Palisades Dam is located on the Snake River 56 miles
upstream from the town.
2. Ririe Dam is located on Willow Creek, a tributary of
the Snake River, 18 miles upstream of the town.
j. Security (class III hazards)
1. Typical threats may include disorderly conduct, stalking,
threats, and robbery. Violations of the university student
code of conduct is possible.
k. Administration building (class II hazards)
1. The administration building is constructed mainly of
wood. It is next to the building and connected by a
small walkway.

17.3 Case Study 2: Multipurpose Academic Building
267
Risks
1. Tables 17.2–17.4 are an assessment of the risks associated with
each hazard. This includes the consequences and frequency of
each hazard.
2. The hazards listed are building hazards, natural hazards, and
man-made hazards. Natural and man-made hazards are the
external hazards listed in the section titled “Hazards”.
TABLE 17.2
Building Hazards
Consequence
Frequency
Risk
Chemical
Splash chemicals on body
(burns) resulting in injury,
spills into city sanitary
drain system, ﬁre/explosion
with incompatible materials
Moderate
High
Biological
E. coli and Salmonella
contamination/illness
Extremely low Low
Radiological
Radiation
exposure/contamination
Extremely low High
Fire
Death or injury to personnel,
release of hazardous
chemicals and biohazards,
explosions from gas bottles
and natural gas lines
Low
High
Electrical
Electric shock/electrocution,
ﬁres, explosions from
natural gas or chemicals
Low
High for maintenance,
low for faculty and
students
Natural gas
Gas leak, ﬁre/explosion,
asphyxiation
Very low
Moderate
Compressed
gases
Asphyxiation, ﬁre due to
hydrogen leak, explosion
during ﬁre, injury due to
falling bottle or ﬂying parts
Very low
Moderate
Cryogenics
Frost bite, asphyxiation
Very low
Moderate
Conﬁned
space
Injury and/or drowning due
to falling in
Very low
Moderate
Heat
Burns due to contact with
boiler and piping surfaces
or hot water
Low
High

268
CHAPTER 17 Vulnerability Analysis Technique
TABLE 17.3
Natural Hazards
Consequence
Frequency
Risk
Flooding
Flooding of building, electrical
components; release of
chemicals, and biohazards
Extremely low
Very low
High
winds/tornadoes
Damage to building, windows;
Loss of electrical power and
ventilation, release of
hazardous chemicals,
radioactivity, and biohazards
High for winds,
very low for
tornadoes
Low for
damage,
moderate for
loss of power
and ventilation
Winter storms
Snow loading collapsing roof,
damage due to high winds
High
Moderate for
snow loading;
low for
building
damage
Wild ﬁres
Damage to building,
ﬁre/explosion, release of
hazardous chemicals,
radioactive material,
biohazards, damage to
compressed gas bottles
Moderate
Very low
Volcanic/seismic
activity
Damage to building,
ﬁre/explosion, release of
hazardous chemicals,
radioactive material,
biohazards, damage to
compressed gas bottles, dam
failure
Low
Very low
3. An airplane or jet crash is not analyzed because it is beyond all
likelihood, and if it did occur, actions would be similar to a ﬁre
or seismic event. There is no credible way to protect against
such an event.
4. The administration building is not included but is considered a
source of a ﬁre and the actions for a ﬁre are the same regardless
of the source.
5. Table 17.2 describes the building hazards. Table 17.3 describes
the natural hazards. Table 17.4 describes the man-made haz-
ards.

17.3 Case Study 2: Multipurpose Academic Building
269
TABLE 17.4
Man-Made Hazards
Consequence
Frequency
Risk
Power outage
Loss of ventilation and
release of hazardous
chemical vapors, buildup of
inert gases from
compressed gas bottles,
freezing of water pipes
Low
Moderate
Dam failure
Flooding, loss of power,
release of hazardous
chemicals, radioactive
material, biohazards,
ﬁre/explosion
Very low
Low for Palisades
Dam; moderate
for Ririe Dam due
to time of ﬂood
water arrival.
Palisades requires
22 h. Ririe
requires 3.5 h
Idaho National
Laboratory
Release of radioactive
materials, biohazards
Very low
Very low
Hazardous
materials from
trains and
highways
Release of hazardous
chemicals
Very low
Low
Chlorine Gas from
City of Idaho
Falls Water
System
Release of chlorine gas,
death/injury to public
Very low
Moderate
Diesel storage
tanks
Explosion, toxic fumes
Very low
Very low
Public safety
Robbery, violence, stalking,
intoxication, terrorism,
medical emergencies
Low
Low
Hazard Controls
1. Hazard controls are derived from a number of sources. The
general requirements (references) for each hazard control will
be included. SMEs and management will be responsible for
the correct implementation of the requirements and controls.
Since the building is under a university, it is considered a state
entity and is not required to follow federal laws. However, as
appropriate, the federal laws will be referenced as a resource.

270
CHAPTER 17 Vulnerability Analysis Technique
State laws will typically reference consensus codes (Interna-
tional Building Code (IBC), NFPA, ANSI, etc.) and hand off
to them. The most restrictive codes or statutes will be used.
2. To ensure the building is built to applicable codes, the city
building inspector will use software, “plan analyst” to enter
building design criteria. A report is then generated, which out-
lines all applicable speciﬁcations for building construction in
accordance with the IBC.
3. The IBC addresses: structure design, ﬁre safety, hazardous
material safety (in building design), and electrical, mechani-
cal, plumbing, and elevator systems. The IBC also hands off
to the International Fire Code.
4. According to Intermountain Gas Company, natural gas lines
are installed up to the gas meter by Intermountain Gas. Lines
inside the building are installed by contractor personnel. Inter-
mountain Gas uses numerous codes from the Ofﬁce of Pipeline
Safety, Public Utilities Commission, and the Department of
Transportation. The City Inspector says contractors will use
the International Fuel Gas Code.
5. The following are the hazards and their associated controls.
Note: Training will typically be a control for these hazards and
will not need to be mentioned below.
6. Table 17.5 discusses building hazards. Table 17.6 discusses
natural hazards. Table 17.7 discusses man-made hazards.
Conclusion
The building has numerous hazards, which can cause serious bodily
harm or death. The fact that it is a university setting does not make the
building and processes inherently safe. The identiﬁed hazards must be
mitigated or controlled in a manner consistent with established laws,
statutes, consensus codes, and best practices established by the federal
government, state and local governments and authorities, and recog-
nized associations. With the numerous regulations and standards that
must be followed an analyst must consult with appropriate SMEs in
order to properly identify the hazards and the requirements for mitigat-
ing and controlling the hazards. Without the proper assistance, it would

17.3 Case Study 2: Multipurpose Academic Building
271
TABLE 17.5
Building Hazards and Associated Standards/Regulations
Hazard
Controls
Requirement
Chemical
Ventilation, PPE, ﬂammable
storage containers and
segregation, glove
boxes/ventilation hoods,
chemical neutralization in
drain system, MSDS, spill
kits, emergency
eyewash/shower, satellite
accumulation areas and
temporary accumulation
area, electrical systems
constructed for laboratories,
sprinkler system, ﬁre alarm
system and ﬁre
extinguishers, locked
rooms, preventive
maintenance, evacuation
Note: Neutralization in
drain system removes the
requirement for a storm
water pollution prevention
plan. Drains will still be
monitored
• International Building
Code (IBC)
• 29 CFR 1926
• 29 CFR
1910.94/1000/1200/1450
• 40 CFR 262
• IDAPA 07, Title 07,
Chapter 1
• NFPA 1, 10, 30, 45,
91,101
• NEC
• Chemical Hygiene Plan
• Hazardous Waste
Management Policy and
Procedures Manual
• AGS-G001
• ANSI Z9.5
• ERG
• SARA Title I, III
• City Code Title 3
Chapter 2
Biological Hazards
PPE, approved storage,
cleanliness, locked rooms,
evacuation
• National Institute of
Health “Biosafety in
Microbiological and
Biomedical Laboratories”
Radiological
In accordance with NRC
license, posting, locked
rooms, evacuation
• NRC license, which
implements 10 CFR 19
and 20
• Radiation Safety Policy
Manual
• SARA Title I, III
• City Code Title 3
Chapter 2
Fire
Fire-resistant materials rated
for 1 h, construction type 2,
A-3 and B-2 occupancy,
sprinkler system, ﬁre alarm
• IBC, chapters
• 29 CFR 1926
• NFPA 1, 10, 101
• NFPA 70 (NEC)
(continued)

272
CHAPTER 17 Vulnerability Analysis Technique
TABLE 17.5
(Continued)
Hazard
Controls
Requirement
system and ﬁre
extinguishers, approved
smoking area, ﬁre
department access to
building and list of hazards,
electrical systems built to
code, housekeeping,
preventive maintenance,
evacuation. Note: these
controls apply to the TAB
Building catching on ﬁre
• SARA Title I, III
• City Code Title 3 Chapter 2
• The ﬁre department has a
list of hazards and access to
the Building
Electrical
Electrical systems built to
code for building and
laboratories, lockout/tagout
for maintenance, PPE for
live systems, maintenance
room locked
• 29 CFR 1926
• 29CFR 1910.147
• NFPA 70 (NEC)
• NFPA 45, 70E
Natural gas
Gas systems built to code,
shutoffs at exits,
ventilation, evacuation
• 29 CFR 1910
• NFPA 54
• SARA Title I, III
• City Code Title 3 Chapter 2
Compressed gas
PPE, approved bottles by
vendor, approved storage
(racks and chains),
ventilation, room locked,
evacuation
• 29 CFR 1910.101
• CGA P-1
• NFPA 45, 55
• ISU Chemical Hygiene Plan
• SARA Title I, III
• City Code Title 3 Chapter 2
Cryogenics
PPE, approved storage,
ventilation, room locked,
evacuation
• 29 CFR 1910.1450
• Chemical hygiene plan
Conﬁned space
Access cover, room locked
• 29 CRF 1910.146
Heat
Pressure vessels inspected
and certiﬁed, PPE,
preventive maintenance,
lockout/tagout for
maintenance, room locked
• 29 CFR 1926
• 29 CFR 1910.147
• NFPA 70 (NEC)
• ASME B.31.1
• IDAPA 17.06.01
Abbreviations: MSDS, material safety data sheet; NRC, Nuclear Regulatory Commission; PPE,
personnel protective equipment.

17.3 Case Study 2: Multipurpose Academic Building
273
TABLE 17.6
Natural Hazards and Associated Standards/Regulations
Hazard
Controls
Requirement
Flooding
Built outside ﬂood zone,
importance level 1,
evacuation
• IBC
• SARA Title I, III
• City Code Title 3
Chapter 2
High winds/tornado
Built to withstand 70 mph
winds, take shelter and
evacuate as appropriate
• IBC
• SARA Title I, III
• City Code Title 3
Chapter 2
Winter storms
Built class A roof, snow
loading to 33 lb/ft3,
evacuation
• IBC
• SARA Title I, III
• City Code Title 3
Chapter 2
Wild ﬁres
Evacuation
• SARA Title I, III
• City Code Title 3
Chapter 2
Volcanic/seismic activity
Built to 2B seismic code,
evacuation
• IBC
• SARA Title I, III
• City Code Title 3
Chapter 2
be impossible to adequately mitigate and control hazards sufﬁciently
to protect personnel, the public, and the environment. A task analysis
of the different duties of personnel is required to ensure the tasks they
perform are identiﬁed so that the appropriate mitigations and controls
are in place. A physical walk down of the facility using drawings, pro-
cedures, and SMEs is necessary to properly identify and document the
hazards. Hazards inside the building and on the outside are identiﬁed.
Observation of work being performed is another requirement. Not all
personnel are subjected to the same hazards. It depends on their job
assignments. Once this part of the analysis is performed, the hazards
are organized and their risks are analyzed. Mitigations and controls
are then determined.
Sample sources of information to perform a study of this type are
contained in Table 17.8.

274
CHAPTER 17 Vulnerability Analysis Technique
TABLE 17.7
Man-Made Hazards and Associated Standards/Regulations
Hazard
Controls
Requirement
Power outage
Evacuation, supplemental heat in
the winter for pipes if ventilation
maintained
• Chemical Hygiene Plan
• City Code Title 3
Chapter 2
Dam failure
Evacuation
• SARA Title I, III
• City Code Title 3
Chapter 2
National
laboratory
Evacuation
• SARA Title I, III
• City Code Title 3
Chapter 2
Hazardous
materials from
trains and
highways
Shelter in place or evacuation
• SARA Title, III
• City Code Title 3
Chapter 2
• ERG
Chlorine gas
from City of
Idaho Falls
water system
Shelter in place or evacuation
• SARA Title, III
• City Code Title 3
Chapter 2
Diesel storage
tanks
Shelter in place or evacuation
• SARA Title III
• City Code Title 3
Chapter 2
• ERG
Public safety
Public safety surveillance in day,
Idaho Falls police department
surveillance at night, shelter in
place or evacuation, call 911,
citizen’s arrest followed by police
arrest, enforcement of student
code of conduct, emergency
phones stationed thought campus,
increase security surveillance
consistent with Homeland Security
Advisory System threat level,
render ﬁrst aid until EMS arrives
• Idaho Statute Title 19
Chapter 6
• City Code Title 3
Chapter 1
• Public Safety Mission
Statement
Note: Public safety is a best management practice dictated by the Idaho State Board of
Education. There are no requirements to have public safety. However, the above requirements
outline derivation of authorities.

17.3 Case Study 2: Multipurpose Academic Building
275
TABLE 17.8
Sample Sources of Information for a Vulnerability Study
Organization
Source(s)
Emergency
management, ﬁre,
and security
FEMA. Available at
http://www.fema.gov/plan/prevent/rms/
National Fire Protection Agency. NFPA 1, Fire Code.
Quincy, MA; 2009.
National Fire Protection Agency. NFPA 101, Life Safety
Code. Quincy, MA; 2009.
National Fire Protection Agency. NFPA 484, Standard for
Combustible Metals. Quincy, MA; 2009.
National Fire Protection Agency. NFPA 30, Flammable
and Combustible Liquids Code. Quincy, MA; 2008.
National Fire Protection Agency. NFPA 72, National Fire
Alarm and Signaling Code. Quincy, MA; 2010.
National Fire Protection Agency. NFPA 484, Standard for
Combustible Metals. Quincy, MA; 2009.
United States Department of Transportation. Emergency
Response Guide. Washington, DC; 2008. Available at
http://www.ehso.com/ehsodot.php?URL=http%3A%2F%
2Fphmsa.dot.gov/staticﬁles/PHMSA/
DownloadableFiles/Files/erg2008_eng.pdf
10CFR1910 OSHA Standard
County Hazards Vulnerability Analysis
City and state codes
Laboratory safety
American Glovebox Society. AGS-G001, Guideline for
Gloveboxes. 3rd ed. 2007.
Centers For Disease Control and Prevention. National
Institutes of Health. Biosafety in Microbiological and
Biomedical Laboratories. 5th ed. 2009. Available at
http://www.cdc.gov/biosafety/publications/bmbl5/
index.htm
National Fire Protection Agency. NFPA 45, Standard on
Fire Protection for Laboratories Using Chemicals.
Quincy, MA; 2011.
National Fire Protection Agency. NFPA 91, Standard for
Exhaust Systems for Air Conveying of Vapors, Gases,
Mists, and Noncombustible Particulate Solids. Quincy,
MA; 2010
(continued)

276
CHAPTER 17 Vulnerability Analysis Technique
TABLE 17.8
(Continued)
Organization
Source(s)
Building requirements
Uniform Building Code
Compressed gases
American Society of Mechanical Engineers. ASME B31.1,
Power Piping: ASME Code for Pressure Piping; 2007.
Compressed Gas Association. CGA P-1, Safe Handling of
Compressed Gases in Containers; 2000.
29CFR1910 OSHA Standard
National Fire Protection Agency. NFPA 55, Compressed
Gases and Cryogenic Fluids Code. Quincy, MA; 2010.
State and Local Codes and Standards
Hazardous materials
and waste
Environmental Protection Agency. 40 CFR 262, Standards
Applicable to Generators of Hazardous Waste. Available
at http://ecfr.gpoaccess.gov/cgi/t/text/text-
idx?c=ecfr&sid=aab68f7aa9c461f1ae41bd67332dd4c3&
rgn=div5&view=text&node=40:25.0.1.1.3&idno=40
Superfund Amendments and Reauthorization Act of 1986
(SARA). SARA Title III—Emergency Planning and
Community Right-to-Know. Available at
http://epw.senate.gov/sara.pdf
29CFR1910 OSHA Standard
Radiation protection
Nuclear Regulatory Commission Regulations:
10CFR33 “Speciﬁc Domestic Licenses of Broad Scope for
By-Product Material”
10CFR Part 35 “Medical Use of Byproduct Material”
10CFR73 “Physical Protection of Plants and Materials”
Department of Energy Orders and Guidelines
REFERENCE
1. Federal Emergency management Agency (FMEA). Available http://www.fema.
gov/plan/prevent/rms/. Retrieved March 2011.

CHAPTER 18
Developing Risk Model
for Aviation Inspection
and Maintenance Tasks
18.1 INTRODUCTION
Risk assessment has been used to analyze a wide range of industries to
determine vulnerabilities with the ultimate purpose of eliminating the
sources of risk or reducing them to a reasonable level. The purpose
of this chapter is to show how risk assessment tools can be used to
develop risk models of aviation maintenance tasks. Two tools will
be discussed in this chapter, although many other methods exist. The
tools discussed in this chapter are as follows:
• failure mode and effect analysis (FMEA);
• event and fault tree analysis.
18.2 FAILURE MODE AND EFFECT
ANALYSIS
As discussed in prior chapters, FMEA is a detailed document that
identiﬁes ways in which a process or product can fail to meet critical
Risk Assessment: Tools, Techniques, and Their Applications, First Edition.
Lee T. Ostrom, Cheryl A. Wilhelmsen.
2012 John Wiley & Sons, Inc. Published 2012 by John Wiley & Sons, Inc.

278
CHAPTER 18 Developing Risk Model
requirements. It is a living document that lists all the possible causes of
failure from which a list of items can be generated to determine types
of controls or where changes in the procedures should be made to
reduce or mitigate risk. The FMEA also allows procedure developers
to prioritize and track procedure changes (1). The process is effective
because it provides a very systematic process for evaluating a system
or a procedure, in this instance. It provides a means for identifying
and documenting
1. potential areas of failure in process, system, component, or
procedure;
2. potential effects of the process, system, component, or proce-
dure failing;
3. potential failure causes;
4. methods of reducing the probability of failure;
5. methods of improving the means of detecting the causes of
failure;
6. risk ranking of failures, allowing risk informed decisions by
those responsible;
7. a starting point from which the control plan can be created.
FMEA can be used to analyze the following:
1. Process. Documents and addresses failure modes associated
with the manufacturing and assembly process.
2. Procedure. Documents and addresses failure points and modes
in procedures.
3. Software. Documents and addresses failure modes associated
with software functions.
4. Design. Documents and addresses failure modes of products
and components long before they are manufactured and should
always be completed well in advance of prototype build.
5. System. Documents and addresses failure modes for system-
and subsystem-level functions early in the product concept
stage.
6. Project. Documents and addresses failures that could happen
during a major program.

18.3 Event Tree and Fault Tree Analysis
279
A procedure analysis will be used to demonstrate how an FMEA
can be conducted. An FMEA is conducted on a step-by-step basis.
Table 18.1 shows an example of an FMEA table. The following con-
stitutes the steps of an FMEA. These steps will be illustrated by use
of an example.
The ﬁrst step is to create a ﬂow diagram of the procedure. This
is a relatively simple process in which a table or block diagram is
constructed that shows the steps in the procedure. Table 18.2 shows
the simple steps for checking an engine chip detector. Note that this
is a simple example and not an exhaustive analysis. Table 18.3 lists
the major, credible failures associated with each step in the process.
Table 18.4 shows the effect of the potential failures. Table 18.5 shows
the complete FMEA for the task.
FMEA is a relatively simple but powerful tool and has a wide
range of applicability for analyzing aircraft maintenance tasks.
18.3 EVENT TREE AND FAULT TREE
ANALYSIS
As discussed in Chapters 12 and 14, an event tree is a graphical
representation of a series of possible events in an accident sequence
(2). Using this approach assumes that as each event occurs there are
only two outcomes, failure or success. A success ends the accident
sequence and the postulated outcome is that the accident sequence
was either terminated successfully or mitigated successfully. For
instance, a ﬁre starts in an engine. This is the initiating event. Then
the automated system closes fuel feed. If the lack of fuel does
not extinguish the ﬁre, the next step is that the ﬁre suppression
system is challenged. If the system actuates the ﬁre suppression
system, the ﬁre is suppressed and the event sequence ends. If the ﬁre
suppression system fails, the ﬁre is not suppressed and the accident
sequence progresses. Table 18.6 shows this postulated accident
sequence. Figure 18.1 shows this accident sequence in an event
tree.
As in most of the risk assessment techniques, probabilities can be
assigned to the events and combined using the appropriate Boolean
logic to develop an overall probability for the various paths in the
event (Table 18.7). Using our example from above, we will now add

TABLE 18.1
Example of FMEA Table
Potential
Cause of
Possible
Criticality
Item
failure mode
failure
effects
Probability
(optional)
Prevention
Step in procedure,
part, or
component
How it can fail:
—pump not
working
—stuck valve
—no money in
a checking
account
—broken wire
—software
error
—system down
—reactor
melting down
What caused
the failure:
broken part
electrical
failure human
error explosion
bug in
software
Outcome of the
failures:
nothing system
crash
explosion ﬁre
accident
environmental
release
How possible is
it:
can use
numeric
values:
0.1, 0.01, or
1E-5
Can use a
qualitative
measure:
negligible, low
probability,
high
probability
How bad are
the results:
Can use dollar
value:
$10, $1000, or
$1,000,000
Can use a
qualitative
measure: nil,
minimal
problems,
major
problems
What can be
done to
prevent either
failures or
results of the
failures?
280

18.3 Event Tree and Fault Tree Analysis
281
TABLE 18.2
Process Steps for Checking a Chip Detector
Inspecting chip detector
Step number
Process steps
1
Cut and remove lock wire from oil drain Plug
2
Remove oil drain plug
3
Drain oil
4
Cut and remove lock wire from chip detector
5
Remove chip detector
6
Examine chip detector
7
Clean chip detector
8
Replace chip detector
9
Lock wire chip detector
10
Replace oil drain plug
11
Lock wire oil drain plug
12
Replace oil
TABLE 18.3
Failures Associated with Each Step
Inspecting chip detector
Process steps
Major failures
Cut and remove lock wire
from oil drain plug
No major failures that affect process outcome
Remove oil drain plug
No major failures that affect process outcome
Drain oil
No major failures that affect process outcome
Cut and remove lock wire
from chip detector
No major failures that affect process outcome
Remove chip detector
Improper removal can remove debris from
chip detector and cause false reading. Chip
detector can be damaged if improperly
removed
Examine chip detector
Aircraft maintenance technician (AMT) fails
to notice debris on chip detector
Clean chip detector
AMT fails to properly clean chip detector
Replace chip detector
AMT fails to properly install chip detector
Lock wire chip detector
AMT fails to properly lock wire chip detector
Replace oil drain plug
AMT fails to properly install oil drain plug
Lock wire oil drain plug
AMT fails to properly lock oil drain plug
Replace oil
AMT fails to properly replace oil

282
CHAPTER 18 Developing Risk Model
TABLE 18.4
Effect of Potential Failures
Inspecting chip detector
Process steps
Potential failure modes
Potential failure effects
Remove chip
detector
Improper removal can
remove debris from chip
detector and cause false
reading. Chip detector can
be damaged if improperly
removed
Engine could fail if chips
are not properly detected.
Added cost to replace
damaged chip detector
Examine chip
detector
Aircraft maintenance
technician (AMT) fails to
notice debris on chip
detector
Engine could fail if chips
are not properly detected
Clean chip detector
AMT fails to properly
clean chip detector
Debris could be placed
back into engine
Replace chip
detector
AMT fails to properly
install chip detector
Oil could leak past chip
detector. Threads of chip
detector could be
damaged
Lock wire chip
detector
AMT fails to properly lock
wire chip detector
Chip detector could
become lose and fall out,
leading to loss of engine
oil
Replace oil drain
plug
AMT fails to properly
install oil drain plug
Engine oil could leak out.
Oil drain plug could
become damaged
Lock wire oil drain
plug
AMT fails to properly lock
oil drain plug
Oil drain plug could
become loose and fall out
Oil drain plug could
become damaged
Replace oil
AMT fails to properly
replace oil
Engine could fail
probabilities to the events and show how the probabilities combine for
each path. Figure 18.2 shows the addition of path probability to the
event tree.
The result of this analysis tells us that the probability derived for a
ﬁre in which the fuel feed system stops fuel supply to engine actuates
and the consequence in minimal damage is approximately 1/1000 or
1 × 10−3. The probability derived for a ﬁre in which the fuel feed
system fails to actuate, but the ﬁre suppression system successfully

TABLE 18.5
Complete FMEA for Chip Detector Task
Procedure
Potential
Cause of
Possible
step
failure mode
failure
effects
Probability
Criticality
Prevention
Cut and remove
lock wire from
oil drain plug
No major failures
that affect
process outcome
AMT fails to
perform task
Delay in
performing task
Very low
Not critical
Ensure AMTs
follow work
schedule
Remove oil
drain plug
No major failures
that affect
process outcome
AMT fails to
perform task
Delay in
performing task
Very low
Not critical
Ensure AMTs
follow work
schedule
Drain oil
No major failures
that affect
process outcome
AMT Fails to
Perform Task
Delay in
performing task
Very Low
Not Critical
Ensure AMTs
follow work
schedule
Cut and remove
lock wire from
chip detector
No major failures
that affect
process outcome
AMT fails to
perform task
Delay in
performing task
Very low
Not critical
Ensure AMTs
follow work
schedule
Examine chip
detector
AMT fails to
notice debris on
chip detector.
AMT fails to
properly
perform task
Engine could fail
if chips are not
properly
detected. Added
cost to replace
damaged chip
detector
Moderate
Critical
Training,
procedures,
and inspection
oversight
(continued)
283

TABLE 18.5
(Continued)
Procedure
Potential
Cause of
Possible
step
failure mode
failure
effects
Probability
Criticality
Prevention
Clean chip
detector
AMT fails to
properly clean
chip detector
AMT fails to
properly
perform task
Engine could fail
if chips are not
properly
detected
Moderate
Critical
Training,
procedures,
and inspection
oversight
Replace chip
detector
AMT fails to
properly install
chip detector
AMT fails to
properly
perform task
Debris could be
placed back into
engine
Moderate
Critical
Training,
procedures,
and inspection
oversight
Lock wire chip
detector
AMT fails to
properly lock
wire chip
detector
AMT fails to
properly
perform task
Oil could leak
past chip
detector.
Threads of chip
detector could
be damaged
Moderate
Critical
Training,
procedures,
and inspection
oversight
Replace oil
drain plug
AMT fails to
properly install
oil drain plug
AMT fails to
properly
perform task
Chip detector
could become
lose and fall out,
leading to loss
of engine oil
Moderate
Critical
Training,
procedures,
and inspection
oversight
284

Lock wire oil
drain plug
AMT fails to
properly lock oil
drain plug
AMT fails to
properly
perform task
Engine oil could
leak out. Oil
drain plug could
become
damaged
Moderate
Critical
Training,
procedures,
and inspection
oversight
Replace oil
AMT fails to
properly replace
oil
AMT fails to
properly
perform task
Oil drain plug
could become
loose and fall
out. Oil drain
plug could
become
damaged.
Engine could
fail
Low
Critical
Training,
procedures,
and inspection
oversight
285

286
CHAPTER 18 Developing Risk Model
TABLE 18.6
Accident Sequence
Event
Description
Possible outcomes
Fire
This is the initiating event
—
Fuel feed is
stopped
The lack of fuel causes the
ﬁre to stop
Success: the ﬁre stops
Failure: the ﬁre continues
Fire suppression
system actuates
The ﬁre suppression system
detects the ﬁre and it
actuates
Success: system actuates and
controls the ﬁre
Failure: ﬁre destroys the
engine
TABLE 18.7
Event Sequence with Probabilities
Possible
Event
Description
outcomes
Probability
Fire
This is the initiating
event
—
0.001
Fuel feed stops
The automatic
controls stop fuel
ﬂow to the engine
Success: stopping fuel
ﬂow stops ﬁre
0.999
Failure: ﬁre continues
0.001
Fire suppression
system actuates
The ﬁre suppression
system detects the
ﬁre and it actuates
Success: system
actuates and controls
the ﬁre
0.99
Failure: system fails to
control the ﬁre
0.01
extinguishes the ﬁre and there is only moderate damage is 1E–6 or
1 × 10−6. Finally, the probability that a ﬁre occurs and both the fuel
feed system fails and ﬁre suppression system fails and severe damage
occurs is 1E - 8 or 5 × 10−8.
This approach is considered inductive in nature, meaning the sys-
tem uses forward logic. A fault tree, discussed in Chapter 14, is
considered deductive because usually the analyst starts at the top event
and works down to the initiating event. In complex risk analyses, event
trees are used to describe the major events in the accident sequence
and each event can then be further analyzed using a technique most
likely being a fault tree (3).
As indicated, the fault tree begins at the end, so to speak. This top-
down approach starts by supposing that an accident takes place (2).

18.3 Event Tree and Fault Tree Analysis
287
Initiating event
Fire
Fuel feed to
engine stops
Fire suppression
system actuates
Minimal
damage
Moderate
damage
Severe
damage
Success
Success
Failure
Failure
Event 1
Event 2
End state
FIGURE 18.1
Event tree.
Initiating
event
Fire
Fuel feed to
engine stops
Fire suppression
system actuates
Minimal
damage
Moderate
damage
Severe
damage
Success
Success
Failure
Failure
Event 1
Event 2
End state
Path
probability
0.001 × 0.999 =
0.00099 or 0.001
0.001 × 0.001 ×
0.99 = 1E − 6
0.001 × 0.001 ×
0.01 = 1E − 8
FIGURE 18.2
Event tree with path probabilities.

288
CHAPTER 18 Developing Risk Model
It then considers the possible direct causes that could lead to this
accident. Next, it looks for the origins of these causes. Finally, it looks
for ways to avoid these origins and causes. The resulting diagram
resembles a tree, thus the name.
Fault trees can also be used to model success paths as well. In
this regard, they are modeled with the success at the top and the basic
events are the entry level success that put the system on the path to
success.
The goal of fault tree construction is to model the system condi-
tions that can result in the undesired event. Before construction of a
fault tree, the analyst must acquire a thorough understanding of the
system. A system description should be part of the analysis. The anal-
ysis must be bounded, both spatially and temporally, in order to deﬁne
a beginning and end point for the analysis. The fault tree is a model
that graphically and logically represents the various combinations of
possible events, both fault and normal, occurring in a system leading
to the top event. The term event denotes a dynamic change of state that
occurs to a system element. System elements include factors related
to hardware, software, human, and environmental (2).
Events representing failures of equipment or humans (compo-
nents) can be divided into failures and faults. A component failure
is a malfunction that requires the component to be repaired before it
can successfully function again. For example, when a turbine blade in
an engine breaks, it is classiﬁed as a component failure. A component
fault is a malfunction that will “heal” itself once the condition causing
the malfunction is corrected. An example of a component fault is a
switch whose contacts fail to operate because they are wet. Once they
are dried, they will operate properly.
Output events include the top event, or ultimate outcome, and
intermediate events, usually groupings of events. Basic events are used
at the ends of branches since they are events that cannot be further
analyzed. A basic event cannot be broken down without losing its
identity. The undeveloped event is also used only at the ends of event
branches. The undeveloped event represents an event that is not further
analyzed either because there is insufﬁcient data to analyze or because
it has no importance to the analysis.
A top event and boundary conditions must be determined when
deﬁning the problem. Boundary conditions include:

18.3 Event Tree and Fault Tree Analysis
289
• system physical boundaries;
• level of resolution;
• initial conditions;
• not allowed events;
• existing conditions;
• other assumptions.
Top events should be precisely deﬁned for the system being eval-
uated. A poorly deﬁned top event can lead to an inefﬁcient analysis.
Construction begins at the top event and continues, level by level,
until all fault events have been broken into their basic events. Several
basic rules have been developed to promote consistency and complete-
ness in the fault tree construction process. Refer to Chapter 14 for a
discussion concerning the rules of constructing a fault tree.
Many times it is difﬁcult to identify all of the possible combina-
tions of failures that may lead to an accident by directly looking at
the fault tree. One method for determining these failure paths is the
development of “minimal cut sets.” Minimal cut sets are all of the
combinations of failures that can result in the top event. The cut sets
are useful for ranking the ways the accident may occur and are useful
for quantifying the events, if the data is available. Large fault trees
require computer analysis to derive the minimal cut sets, but some
basic steps can be applied for simpler fault trees.
1. Uniquely identify all gates and events in the fault tree.
2. If a basic event appears more than once, it must be labeled
with the same identiﬁer each time. Resolve all gates into basic
events.
3. Gates are resolved by placing them in a matrix with their
events.
4. Remove duplicate events within each set of basic events iden-
tiﬁed.
5. Delete all supersets that appear in the sets of basic events.
By evaluating the minimal cut sets, an analyst may efﬁciently
evaluate areas for improved system safety. The analyst should provide
a description of the system analyzed, as well as a discussion of the

290
CHAPTER 18 Developing Risk Model
Engine damage
from fire
Fuel feed failure
Fire initiates
in engine
Fuel feed
system fails
stop fuel
flow
Fire initiates
in engine
Fire
suppression
system fails
Fire suppression
system failure
FIGURE 18.3
Example fault tree.
problem deﬁnition, a list of the assumptions, the fault tree model(s),
lists of minimal cut sets, and an evaluation of the signiﬁcance of the
minimal cut sets. Any recommendations should also be presented. An
example of fault tree for the engine ﬁre is shown in Figure 18.3.
18.4 SUMMARY
This chapter discussed how common risk assessment techniques could
be used to perform risk assessments of aviation-related activities.
Almost all of the risk assessment tools and techniques presented and
discussed in this book can be applied to a wide range of aviation main-
tenance and inspection tasks. Also, they can, of course, be applied to
marine, rail, and other transportation tasks.

References
291
REFERENCES
1. Mil Std 882B System safety program requirements, Department of Defense Wash-
ington, DC 20301, 1984, 1993.
2. Vesely
W,
et al.
(pdf).
Fault
Tree
Handbook
with
Aerospace
Applica-
tions. National Aeronautics and Space Administration; 2002. Available at
http://www.hq.nasa.gov/ofﬁce/codeq/doctree/fthb.pdf. Retrieved 2010 Jan 17.
3. Modarres M. Risk Analysis in Engineering: Techniques, Tools, and Trends. 1st ed.
CRC Press; New York: 2006. ISBN: 1574447947.

CHAPTER 19
Risk Assessment and
Community Planning
19.1 INTRODUCTION
On December 24, 2008, a natural gas leak caused an explosion and
ﬁre. It killed one person and injured ﬁve others, including one ﬁre-
ﬁghter and a utility worker. The explosion also destroyed one house
completely and severely damaged two others adjacent to the destroyed
house. Several other houses in the neighborhood were damaged. The
neighborhood is located in Rancho Cordova, California. Paciﬁc Gas
and Electric Company, the utility owner and operator, operate 42%
of California’s natural gas pipe lines. According to Paciﬁc Gas and
Electric Company, the property damage was $267,000 (1–3).
The incident can be traced back to a phone call that Paciﬁc Gas
and Electric Company received on their Customer Contact Center Hot-
line at 9 : 16 am. The phone call was made by a resident of 10716
Paiute Way who reported a gas odor outside of her house. The Cus-
tomer Contact Center prepared a case ticket and contacted the Paciﬁc
Gas and Electric Dispatch Ofﬁce as part of their normal procedures.
A ﬁeld technician received the message and headed toward Paiute
Way to investigate the call. On arriving at the affected aforementioned
residence, the technician’s portable gas detector detected gas on her
initial approach across the yard. The technician, equipped only with
Risk Assessment: Tools, Techniques, and Their Applications, First Edition.
Lee T. Ostrom, Cheryl A. Wilhelmsen.
2012 John Wiley & Sons, Inc. Published 2012 by John Wiley & Sons, Inc.

19.1 Introduction
293
gas detectors suitable for indoor gas detection, contacted the dispatch
ofﬁce requesting equipment suitable for outdoor gas detection along
with the assistance from the maintenance and construction department.
On meeting with the resident who had reported the leak, the tech-
nician learned that she also smelled gas at her neighbor’s residence.
The technician called her dispatch ofﬁce to report the smell of gas at
this new residence; they dispatched a ﬁeld man, a leak investigator,
and a foreman to the scene at 10 : 28 am.
The technician then proceeded to 10712 Paiute Way. She did not
detect any leaks inside the residence; however, the male resident of
the house indicated that he knew where there was a natural gas leak in
his neighbor’s yard. He escorted the technician to 10708 Paiute Way.
Once in the yard, the technician detected a strong natural gas smell
originating from a small patch of dead grass.
The technician then proceeded to check the gas meters of all the
houses along this stretch of Paiute Way. She did not detect any unusual
gas meter readings that showed excessive gas ﬂows. The technician
then knocked on the door of 10708 Paiute Way. She did not receive
an answer, so she parked her truck out front and waited for the arrival
of the ﬁeld man, leak investigator, and foreman.
The leak investigator needed to stop by the Paciﬁc Gas and Electric
service center to pick up the ionization detector (a type of detector used
to locate outdoor natural gas leaks), but discovered a problem with his
truck brakes. The leak investigator had to transfer all his equipment
into another service truck delaying his departure by roughly an hour.
The foreman and leak technician ﬁnally arrived at Paiute Way
2 h and 47 min after the technician had requested the assistance from
dispatch. The technician relayed the information she had gathered and
then left the scene. The ﬁeld man arrived shortly thereafter.
They proceeded to track down the location of the leak with the
ionization detector. They reported a reading of 60,000 ppm, then
80,000 ppm, and ﬁnally, the device ﬂamed out and sounded an alarm.
This revealed that the gas-to-air mixture was so rich that it could not
support a ﬂame, indicating very strong amounts of natural gas. A man
from the neighborhood informed them that he remembered Paciﬁc Gas
and Electric Company ﬁxing a gas leak in this general area before. The
Paciﬁc Gas and Electric employees then noticed two sunken spots in
the grass, indicating that the area had indeed been excavated sometime
in the past.

294
CHAPTER 19 Risk Assessment and Community Planning
At 1 : 35 pm, the leak investigator knocked on the door of 10708
Paiute Way (the house at which the technician could not earlier get an
answer). After speaking with the residence of the house, the leak inves-
tigator closed the door and turned to head back to the leak when the
house exploded. The explosion killed the resident and injured ﬁve oth-
ers. The explosion was caused by gas leaking from the previous repair
done by Paciﬁc Gas and Electric Company in September 2006. The
gas then migrated into the home at 10708 Paiute Way and ultimately
exploded 2 years after the faulty repair.
These types of incidents are not all that uncommon. Natural Gas
Watch listed the natural gas explosions in just 1 week in June 2011
(4). These were as follows:
• In Duluth, Minnesota, a contractor severed a natural gas line that
forced the evacuation of hundreds of people from downtown
Duluth for several hours on the afternoon of Thursday, June 9.
• An explosion leveled a house in Billings, Montana, on the morn-
ing of Wednesday, June 8.
• In Detroit, Michigan, a man was thrown through his front win-
dow when his house blew up on Friday, June 10. Authorities
said preliminary reports indicate that the natural gas was the
cause.
• In Noblesville, Indiana, a gas leak sent organizers scrambling
to relocate the Noblesville Strawberry Festival after a natural
gas leak was discovered on the site that had been chosen for the
event on Monday, June 6. The leak’s discovery also precipitated
the evacuation of approximately 600 people, according to a story
in the Indianapolis Star.
In the United States, they are far less common than in other coun-
tries. A sampling of some of the other recent natural gas explosions
in other countries include the following:
• On Sunday, November 14, 2010, seven people, including a 9-
year-old boy, were tragically killed in an apparent natural gas
explosion at the Playa del Carmen resort in Mexico, according
to media reports (5).
• On January 14, 2011, at least six people were killed and 10
injured in two separate household gas explosions in Russia on

19.1 Introduction
295
Monday. At least six people, including two girls, the ﬁrst 4
months old and the second 6 years old, died after a household
gas explosion in Russia’s southern Stavropol Territory (6).
• Seven
people
were
injured
in
a
gas
explosion
in
the
Dnipropetrovsk region, eastern Ukraine, on Monday morning,
February 8, 2010, Interfax Ukraine News Agency reported (7).
The explosion occurred around 5am at a two-storey apartment
in Orzhonikitse, Dnipropetrovsk, according to the region’s
Ofﬁce of Ministry of Emergencies. The injured have been
hospitalized. One woman was in critical condition.
Risk assessment should be a major factor as communities plan
for growth and development, as well as for planning for emergencies.
Risks at the community level can include but are not limited to the
following:
• chemical releases and catastrophic ﬁres;
◦chemical plant and other process plant explosions,
◦train derailments,
◦truck accidents,
◦multiple structure ﬁres,
◦wild land ﬁres;
• natural disasters;
◦ﬂoods,
◦tornados,
◦hurricanes,
◦dust storms,
◦earthquakes,
◦high winds,
◦heavy snow and blizzards,
◦heat waves or extreme cold;
• transportation disruption;
◦highway accidents,
◦commuter train derailment,
◦transportation workers strikes,
◦power outages;
• widespread power outages;

296
CHAPTER 19 Risk Assessment and Community Planning
• airplane crash;
• loss of employers;
• loss of workforce;
• loss of tax base.
A good example of a repeating natural disaster is the ﬂooding
of the Red River. The Red River that ﬂows from North Dakota into
Manitoba and regularly ﬂoods the towns of Fargo, ND; Oakton, MN;
and Winnipeg, Manitoba, is a good example of river system where
ﬂoods occur frequently. Major ﬂoods have affected the river system
multiple times over the past 110 years. Most recently, ﬂoods have
affected the city of Fargo, ND, in 1997, 2008, and 2011. However,
residents continue to live in Fargo and businesses still remain open in
the ﬂood-prone areas (8).
Risk assessment techniques can and should be applied to the plan-
ning and development of communities to reduce the risks associated
with natural and man-made disasters. The following section presents
two examples of how these techniques can be applied to community
planning to reduce the potential for disasters.
19.2 EXAMPLE ANALYSIS
In this example, a corporation is planning on locating a new factory
in one of several locations within a city. A general map of Medium
City is shown in Figure 19.1. Approximately 50,000 people live in
this city. The city has the following:
• three ﬁre stations;
• one hospital;
• a community college;
• two grade schools;
• one high schools;
• one junior high schools;
• three minor factories;
• a train yard;
• a shopping mall.

19.2 Example Analysis
297
Airport
Factory
Location C
Fire
departmet
N
W
Train station
City mall
Residential area
Great river
Flood prone area
Junior high
High school
Hospital
Residential area
Residential area
Fire
department
1 mile
Fire
department
College
Grade
school
Grade
school
Factory
Factory
Location B
Location A
Prevalent wind
direction
E
S
FD
FD
FIGURE 19.1
General layout of the Medium City.
These are located on the map. The bulk of the city sits more than
12 ft above the river, but the western side of the city is only 6 ft
above the river. The river ﬂows west to east. In addition to the ﬂood
hazard, the city can experience tornados, high winds, thunderstorms,
and hail storms and has a moderate Earthquake risk. The prevalent
wind direction is from southwest to northeast.
The factory will manufacture food ﬂavorings. It will employ 2000
workers. It will use four chemicals to manufacture the ﬂavorings.
These chemicals are listed in Table 19.1.
There are several potential risks associated with the placement of
the factory. The risks are both to the city from the factory and to the
factory from the location in the city.
The risks to the factory from the placement of the factory in the
city include but are not limited to the following:
• ﬂooding hazard;
• weather hazards;

298
CHAPTER 19 Risk Assessment and Community Planning
TABLE 19.1
List of Chemicals
Hazardous
Quantity to be
Chemical
nature
stored on site
Chemical A
Highly ﬂammable, high vapor pressure
(gas at room temperature), highly toxic
10,000 gal
Chemical B
Combustible, solid at room temperature,
highly toxic
20,000 lb
Chemical C
Combustible, liquid at room temperature,
low toxicity
5,000 gal
Chemical D
Nonﬂammable, solid at room temperature,
nontoxic
10,000 lb
• response time from the ﬁre department if the travel distance is
too great.
The risks to the city from the factory include but are not limited
to the following:
• ﬁre and explosion hazards;
• toxic releases;
• trafﬁc increases.
Also listed on the map are the three possible sites for the new
plant. For each location, risk assessment tools can be used to help
elicit the risks for each potential site. The site with the least risks both
to the city from the factory and to the factory from the site can be
selected once the risks are determined. Preliminary hazard analysis
(PHA) is a tool that can be used in this process.
19.2.1 Preliminary Hazard Analysis for Site A
Table 19.2 lists the hazards for site A.
19.2.2 Preliminary Hazard Analysis for Site B
Table 19.3 lists the hazards for site B.

TABLE 19.2
Preliminary Hazard Analysis for Site A
Potential
Probable
Relative probability
Preventative
Hazard
event
cause
of occurrence
actions
Flooding
Factory is ﬂooded
Heavy rain or snow
melt causes Great
River to ﬂood above
6 ft
Great River exceeds
10 ft every 20 yr, but
has not been >12 ft
Build dike around
proposed plant that is
higher than 10 ft
Toxic chemicals
Chemical release from
proposed factory and
the wind directs the
cloud toward
schools, hospital, and
other factory location
Process upset releases
a cloud of chemicals
Chemical releases
occur approximately
once every 5 yr due
to process upsets.
Most releases are
small
Increase safety
measures to reduce
potential of process
upsets
Toxic chemicals
A liquid or solid
chemical spill could
inadvertently
contaminate the
Great River
A spill due to a tank
or storage container
rupture, process
upset, or delivery
truck spill could
occur and gravity or
rain water could
carry the material to
the river
Chemical releases
occur approximately
once every 5 yr due
to process upsets.
Most releases are
small
Build containment
dike around planned
facility to contain
potential spills
(continued)
299

TABLE 19.2
(Continued)
Potential
Probable
Relative probability
Preventative
Hazard
event
cause
of occurrence
actions
Fire
Fire occurs and
spreads quickly
through the facility.
Fire department
response time at this
site is approximately
5 min
Fire occurs due to
process upset or
maintenance actions
Fires occur within
similar facilities
approximately once
every 10 yr
Increase number of
ﬁxed ﬁre suppression
systems and train a
company ﬁre brigade
Trafﬁc
Trafﬁc congestion
around site hinders
movement of
workers into and out
of the site. Trafﬁc
can increase travel
time by 15 min
Trafﬁc in this area is
heavy because of
schools and
residential area
Trafﬁc studies have
shown trafﬁc to be
high 200 of 250
work days
Pay city to add
capacity to the roads
Transportation of
materials in and
out of the facility
Material trafﬁc into
and out of the plant
could be affected by
trafﬁc patterns
Trafﬁc in this area is
heavy because of
schools and
residential area
Trafﬁc studies have
shown trafﬁc to be
high 200 of 250
work days
Pay city to add
capacity to the roads
300

TABLE 19.3
Preliminary Hazard Analysis for Site B
Potential
Probable
Relative probability
Preventative
Hazard
event
cause
of occurrence
actions
Flooding
Factory is ﬂooded
Heavy rain or snow melt
causes Great River to
ﬂood above 12 ft
Great River exceeds 10 ft
every 20 yr, but has not
been >12 ft
Build low dike around
proposed plant that is
approximately 2 ft in
height to further reduce
potential for ﬂooding
Toxic chemicals
Chemical release from
proposed factory and the
wind directs the cloud
toward city mall and
residential area
Process upset releases a
cloud of chemicals
Chemical releases occur
approximately once
every 5 yr due to
process upsets. Most
releases are small
Increase safety measures
to reduce potential of
process upsets
Toxic chemicals
A liquid or solid chemical
spill could inadvertently
contaminate the Great
River
A spill due to a tank or
storage container
rupture, process upset,
or delivery truck spill
could occur and gravity
or rain water could carry
the material to the river
Chemical releases occur
approximately once
every 5 yr due to
process upsets. Most
releases are small
Build containment dike
around planned facility
to contain potential
spills
(continued)
301

TABLE 19.3
(Continued)
Potential
Probable
Relative probability
Preventative
Hazard
event
cause
of occurrence
actions
Fire
Fire occurs and spreads
quickly through the
facility. Fire department
response time at this site
is approximately 7 min
Fire occurs due to
process upset or
maintenance actions
Fires occur within similar
facilities approximately
once every 10 yr
Increase number of ﬁxed
ﬁre suppression systems
and train a company ﬁre
brigade
Trafﬁc
Trafﬁc congestion around
site hinders movement
of workers into and out
of the site. Trafﬁc can
increase travel time by
5 min
Trafﬁc in this area is
relatively heavy because
of the residential areas
Trafﬁc studies have
shown trafﬁc to be high
100 of 250 work days
Pay city to add capacity
to the roads
Transportation of
materials in and
out of the facility
Material trafﬁc into and
out of the plant could be
affected by trafﬁc
patterns
Trafﬁc in this area is
heavy because of the
residential areas
Trafﬁc studies have
shown trafﬁc to be high
100 of 250 work days
Pay city to add capacity
to the roads
302

19.2 Example Analysis
303
19.2.3 Preliminary Hazard Analysis for Site C
Table 19.4 lists the hazards for site C.
From these analyses, site C is selected. It poses the least
amount of risk to the factory from the city and from the factory to
the city.
Other risk assessment tools can also be used. For instance, failure
mode and affect analysis (FMEA), event trees, and fault trees, along
with other methods can be used to perform these analyses. Also, a
probabilistic analysis can be added, if probabilities can be assigned to
the various events.
Figure 19.2 shows how a fault tree for a potential chemical release
event from this proposed factory for location A might look. Figure 19.3
shows the fault tree for a similar event for location C. Using the prob-
abilities in Table 19.5 for the various basic events, one can calculate
the risk for a chemical release event that would affect the schools and
the hospital shown on the map in Figure 19.1.
Chemical
release
affects
high school
Chemical
release
Wind blows
cloud toward
schools and
hospital
Process
upset
releases
chemicals
There is no
rain
Wind is
between 5 and
15 miles per
hour 
Wind direction
is from south,
southwest, or
southeast
Delivery truck
releases
chemicals
Tank rupture
releases
chemicals
FIGURE 19.2
Fault tree for chemical release event for location A.

TABLE 19.4
Preliminary Hazard Analysis for Site C
Potential
Probable
Relative probability
Preventative
Hazard
event
cause
of occurrence
actions
Flooding
Factory is ﬂooded
Heavy rain in the
area causes
localized ﬂooding
around the plant
Downpours from
thunderstorms result
in localized ﬂooding
every 10 yr
Provide adequate
storm water
drainage and
catchment basin
to collect storm
water
Toxic chemicals
Chemical release from
proposed factory and
the wind directs the
farmland north and
east of the proposed
site location
Process upset
releases a cloud
of chemicals
Chemical releases
occur approximately
once every 5 yr due
to process upsets.
Most releases are
small
Increase safety
measures to
reduce potential
of process upsets
Fire
Fire occurs and
spreads quickly
through the facility.
Fire department
response time at this
site is approximately
3 min
Fire occurs due to
process upset or
maintenance
actions
Fires occur within
similar facilities
approximately once
every 10 yr
Increase number of
ﬁxed ﬁre
suppression
systems and train
a company ﬁre
brigade
304

Trafﬁc
Trafﬁc congestion
around site hinders
movement of
workers into and out
of the site. Trafﬁc
can increase travel
time by 3 to 5 min
Trafﬁc in this area
is heavy because
of the airport
Trafﬁc studies have
shown trafﬁc to be
high 250 of 250
work days, but only
during periods when
ﬂights are arriving or
departing from the
local, regional airport
Stagger shifts to
work around
heavy airport
trafﬁc
Transportation of
materials in and
out of the facility
Material trafﬁc into
and out of the plant
could be affected by
trafﬁc patterns
Trafﬁc in this area
is heavy because
of the airport
Trafﬁc studies have
shown trafﬁc to be
high 250 of 250
work days
Stagger delivery
times around
ﬂight schedules.
Also, utilize the
readily available
railroad for
deliveries
305

306
CHAPTER 19 Risk Assessment and Community Planning
Chemical
release
affects
high school
Chemical
release
Wind blows
cloud toward
schools and
hospital
Process
upset
releases
chemicals
There is no
rain
Wind is
between 5 and
15 miles per
hour 
Wind direction
is from the
north, northeast
or northwest
Delivery truck
releases
chemicals
Tank rupture
releases
chemicals
FIGURE 19.3
Fault tree for chemical release event for location C.
TABLE 19.5
Probabilities for Basic Events
Basic events
Probability
Process upset
1 in 5 yr or 1 every 1825 d
Storage tank rupture
1 in 10 yr or 1 in every 3650 d
Delivery truck leaking
1 in 2 yr or 1 in 730 d
Wind blowing from south, southwest,
or southeast
10 mo/yr or 1 in 0.83 yr (not blowing
from this direction = 0.017)
Wind blowing between 5 and 15 mi/h
1 mo/yr or 1 in 0.08
No rain
9 mo/yr or 0.75
Next, the probability of the conditions existing that might cause a
chemical release affecting a school or the hospital are calculated for
both locations A and B. These calculations are shown in Table 19.6.
These calculations show that there is more than ﬁve times less
likelihood the wind would blow a chemical release from location C
as from location A.

References
307
TABLE 19.6
Chemical Release Spill Calculations
Location
Probability
Location A
(0.20 + 0.10 + 0.50) × (0.83 × 0.083 × 0.75) = 0.041
or 1 in 24 yr
Location C
(0.20 + 0.10 + 0.50) × (0.16 × 0.083 × 0.75) = 0.0079
or 1 in 126 yr
In this example, both the qualitative and quantitative risk
assessments show that location C is the better location from a risk
perspective.
19.3 SUMMARY
Every year hundreds of events occur because of which a village, town,
or city is affected by man-made or natural disasters. In many of these
events, hundreds to thousands of people are affected. For instance,
during the December 26, 2004, Tsunami in Indonesia, over 2,00,000
people died (9). If the coastal residents had lived away from the coast
and not directly on it, tens of thousands of lives could have been
saved. If the Fukushima reactors would have been built away from
the coast and or better protected from Tsunamis, then the potential
for the reactors to be damaged would have been signiﬁcantly less.
A risk perspective must be applied to the placement of factories,
schools, residential areas, waste facilities, nuclear and conventional
power plants, and even highways to minimize the potential for loss of
life and destruction of the environment.
REFERENCES
1. NTSB Blames PG&E Litany of Failures In San Bruno Explosion. 2011. Available
at CBS San Francisco: http://sanfrancisco.cbslocal.com/2011/08/30/ntsb-reveals-
ﬁnal-san-bruno-pipe-explosion-report/. Retrieved 2011 Sept.
2. Pipeline Accident Report. 2010. Available at National Transportation Safety Board:
http://www.ntsb.gov/news/events/2011/san_bruno_ca/index.html. Retrieved 2011
Aug.
3. NTSB Report Slams PG&E for San Bruno Blast. 2011. Available at The California
Report: http://www.californiareport.org/archive/R201108310850/a. Retrieved 2011
Sept.

308
CHAPTER 19 Risk Assessment and Community Planning
4. This Week in Natural Gas Leaks and Explosions. 2011. Available at Natural Gas
Watch: http://www.naturalgaswatch.org/?p=585. Retrieved 2011 Aug.
5. Gas Explosion in Mexico Kills At Last Seven In Resort Area of Playa Del Carmen.
2010. Available at Latin American News Dispatch: http://latindispatch.com/
2010/11/15/gas-explosion-in-mexico-kills-at-last-seven-in-resort-area-of-playa-
del-carmen/. Retrieved 2011 Aug.
6. Six Killed, Ten Injured in Household Gas Explosions in Russia. 2008. Available
at Ria Novosti: http://en.rian.ru/russia/20080114/96601374.html. Retrieved 2011
Aug.
7. Home Gas Explosion Injures Seven in Eastern Ukraine. 2010. Available at English:
http://english.people.com.cn/90001/90777/90853/6890889.html.
Retrieved
2011
Aug.
8. The Fargo Flood Homepage. 2011. Available at North Dakota State University:
http://www.ndsu.edu/fargoﬂood/. Retrieved 2011 Aug.
9. 2004 Indian Ocean Earthquake and Tsunami. 2011. Available at wikipedia:
http://en.wikipedia.org/wiki/2004_Indian_Ocean_earthquake_and_tsunami.
Retrieved 2011 Aug.

CHAPTER 20
Risk of an Epidemic
20.1 INTRODUCTION
How do we calculate the risk of an epidemic? Over the course of
recorded history, there have been thousands, if not tens of thousands,
of epidemics. In many African countries, there is a yearly pattern of
meningitis that occurs. In some years, there are more districts within
a country that are affected and in some years, less, but it appears in
recent years that there is a constant threat of a meningitis epidemic
(1). Traditional risk assessment models are of little use in calculating
the threat of an epidemic. It is possible to use a tool such as fault
tree analysis to develop risk scenarios for epidemics, such as Cholera.
Figure 20.1 shows how such a tree might appear. It shows that several
factors have to come together before an epidemic can occur. It is
almost impossible to quantify any of the basic events shown in this
model. Epidemic models are used to calculate disease spread through
a population, but quantifying the probability that an organism will
infect a susceptible person is difﬁcult to impossible (2).
In reality, there is always a small risk that an endemic disease will
erupt, creating an epidemic, and there is really no quantiﬁable mea-
surement. The best way to think about the potential for epidemics is to
consider the potential cause, that is, endemic in nature versus bioterro-
rism versus susceptible population. There are numerous safeguards in
Risk Assessment: Tools, Techniques, and Their Applications, First Edition.
Lee T. Ostrom, Cheryl A. Wilhelmsen.
2012 John Wiley & Sons, Inc. Published 2012 by John Wiley & Sons, Inc.

310
CHAPTER 20 Risk of an Epidemic
Cholera outbreak
Patient 0 releases
cholera into the
environment
Patient 0
becomes
infected
Lack of
proper
sanitation
Population is
not vaccinated
for cholera
Population is
exposed to
cholera
Virulent
cholera
strain is
present
Flood or
other
disaster
FIGURE 20.1
Simpliﬁed cholera epidemic fault tree.
place that protect people from epidemics including vaccinations, early
mandatory reporting, isolation of infected individuals, and so on.
Primary Care Physicians (PCPs) take on a variety of responsibili-
ties. They coordinate care between various specialists and they monitor
a patient’s condition and keep track of a variety of medications. One
role that is often overlooked is the role of a PCP in an epidemic.
Often the ﬁrst person to see the “patient zero” in an infectious disease
outbreak will be an emergency medicine physician or a family prac-
tice physician. It is because of this that in primary care, vigilance and
caution must precede any preconceived notions about illness (3).
Sometimes a cold is not a cold. The majority of the time this is the
case, but very rarely, more sinister diseases slip through the cracks.
Looking solely at the role of the PCP in epidemic situations and at

20.2 Plague Example
311
some examples of situations that could occur, things that a PCP should
be vigilant on will become apparent.
Surveillance methods have been proposed that utilize general data
of normal, expected, common diagnoses at a given time of year and
allowed for the appearance of unexpected symptoms at a given time
in an unusual distribution to aid in the tracking and identifying of
potential epidemics. A study completed in 2001 utilized data pertaining
to upper respiratory infections from 1996 to 1999 and outlined the data
over the course of 12 months. They were then able to pinpoint outliers
during a particular time of year (4). This type of organization of data
can allow for the rapid identiﬁcation of an emerging pattern and aid
in the detection of a potential bioterrorist threat.
The PCP serves as a beacon for potential outbreaks and epidemics.
There is a set of guidelines, delineated in the article “Recognition of
Illness Associated with the Intentional Release of a Biologic Agent”
listed on the Center for Disease Control (CDC) web site, for the PCP
to follow if they suspect that a reportable disease has walked into their
ofﬁce (5).
20.2 PLAGUE EXAMPLE
The etiology of plague is a bacteria known as Yersinia pestis a gram-
negative rod (6). There is some question as to whether or not the
bacteria now endemic to the American Southwest is the same as the
historical cause of the bubonic plague in 1334 that killed off more
than 20 million people in Europe (7). Of course, there have been
multiple epidemics throughout history as a result of plague, but this
is the most notable example. The organism, Y. pestis, was discov-
ered in 1894 (8). Regardless of this, plague as we know it in the
southwest is very real and very deadly. Y. pestis is an organism that
can easily adapt to a wide variety of host organisms, which makes it
ideal as a harbinger of an epidemic. There are three forms of plague.
First is pneumonic plague, which is spread by aerosolized droplets
and presents as a type of pneumonia. This form of plague has a near
100% mortality. The affected person develops a lobar pneumonia,
which leads to necrosis and death. Without rapid administration of
antibiotics, the affected person will die within 18–24 h of onset. Sec-
ond is bubonic plague. Typically, this presents with lymphadenopathy,

312
CHAPTER 20 Risk of an Epidemic
and then, in 2–3 days, the patient develops chills, fever, and fatigue.
On the seventh day, the affected person develops buboes. Buboes are
nonﬂuctuant, warm, and tender. After the administration of antibi-
otics, these resolve after approximately 5 days. Third is septicemic
plague. This is bacteremia secondary to rapidly replicating Y. pestis.
This results in an overwhelming sepsis, leading to shock and dissemi-
nated intravascular coagulation (DIC). As a weapon, plague is a poor
agent. There are numerous, commonly used antibiotics that will effec-
tively treat plague. Plague has persisted despite human efforts because
it is transmitted primarily by ﬂeas. Fleas can transmit the disease to
rodents, and rodents then carry the disease across a broad area and
tend to congregate near humans. Public health ofﬁcials typically mon-
itor plague by identifying large numbers of rodents die off quickly and
collecting samples in and around their burrows. There is no current
vaccination against plague.
20.3 TULAREMIA EXAMPLE
Also found in the American southwest and most commonly in rabbits,
the causative agent is Franciscella tularemia, a gram-negative cocci
(6). This disease is not as virulent as anthrax and does not lead to
death as rapidly as plague; however, it continues to be one of the
highly monitored bioterrorism agents. It is not easily spread from
person to person. It is typically spread through bites from insects
carrying the organism. Spread through aerosolized droplets can occur
and would result in an abrupt onset of high fever, chills, pharyngitis,
and pneumonia. Risk of mortality would be approximately 30% or
more. When traveling through endemic areas, it is important to wear
clothing that covers all exposed areas and to use insect repellent. Those
who hunt rabbits and other small mammals should be cautious when
cleaning the carcasses.
20.4 ANTHRAX EXAMPLE
The causative agent is Bacillus anthracis, a gram-positive bacilli com-
monly found in soil and carried by herbivores such as cows and sheep
(6). As a spore-forming organism, it can lay dormant in the soil for

20.6 Smallpox Example
313
years. There are three forms of anthrax. The ﬁrst is gastrointestinal
anthrax. This is usually secondary to infected meat. When aerosolized,
anthrax can present as a viral disease of the upper respiratory tract with
fever. The spores are inhaled and brought into the lungs. From there,
they are carried to the mediastinal lymph nodes and release the active
bacteria. This carries a risk of 100% mortality without very early
use of antibiotics. In the anthrax letter attacks that occurred in 2001,
there were ﬁve fatalities. These were all from inhalational anthrax.
Death was after 7 days of symptoms and the deaths occurred without
prompt use of appropriate antibiotics. Treatment includes ciproﬂoxacin
or doxycycline. Cutaneous anthrax develops from spores being intro-
duced into an open wound through the skin. Initially, a painless blister
develops. Then, a black necrotic lesion develops. Prior to the common
use of antibiotics, this would lead to death in one-ﬁfth of all cases.
20.5 EBOLA EXAMPLE
Ebola virus is one of the three viruses that are described to cause
acute hemorrhagic fever, which has a high mortality, and belongs
to the family Filoviridae. In Filoviridae, there are four subspecies
found in four regions, three of which are found in Africa, the fourth
is found in the Philippines (6). There is multisystem involvement.
Spread via aerosolized droplets is possible, but it is typically spread
person to person through infected body ﬂuids with mortality of up to
90%. Temperatures are usually >38.3◦C, and the afﬂicted will usually
develop DIC. Contact with those who have died from these viruses
can lead to infection.
The only treatment that is currently available is supportive,
although ribavirin has been utilized, but there is no sufﬁcient data
at this time supporting this treatment. There is no known effective
vaccine.
20.6 SMALLPOX EXAMPLE
It is thought to be virtually extinct in the world but can still be found in
two isolated laboratories, one in the CDC headquarters in Atlanta, GA,
and the other in the Soviet Union. Small pox is caused by the variola

314
CHAPTER 20 Risk of an Epidemic
virus; the United States embarked on a global campaign to eliminate
small pox worldwide. Vaccination against smallpox ﬁrst occurred in
1796 by Edward Jenner who noticed that milk maids tended to never
develop smallpox (6). Through this observation, he was able to utilize
the pus from the cowpox blisters as an inoculum and thus rendering
the recipient immune to smallpox.
The risk of smallpox as an agent of bioterrorism is relatively slim;
however, since the end of the inoculation program against smallpox,
there is a greater chance that if released it would cause an epidemic.
20.7 TB EXAMPLE
The causative agent is Mycobacterium tuberculosis. It has a 5-year
mortality of 65%. Approximately 5 million cases were reported in
2005 (6). TB occurs in developing countries but has become increas-
ingly more common in the United States. It is increasingly more
dangerous, as there are several drug-resistant variants that have made
effective deﬁnitive treatment much more difﬁcult. Transmission is via
respiratory droplets from those with active tuberculosis. The devel-
opment of active disease really depends more on the host’s immune
response. Approximately 10% of those infected with latent TB will
develop active disease. There are several types of extrapulmonary
forms of tuberculosis that may result from a long-term tuberculosis
infection.
20.8 TYPHOID FEVER EXAMPLE
The story of “Typhoid Mary” is the most commonly referred to tale
of an asymptomatic carrier of a potentially deadly disease. Typhoid
in and of itself is relatively difﬁcult to spread without direct contact
with a carrier, in the case of “Typhoid Mary.”
Typhoid fever is caused by Salmonella typhi. It affects human
hosts only; it is spread through a fecal oral route. A vaccine is available
to Americans traveling to endemic regions, oral live attenuated vaccine
and an intravenous vaccine of the bacterial capsule. Approximately 4%
of those infected with S. typhi become chronic carriers and will be
completely asymptomatic (6). These carriers are then able to easily

20.10 Example of Measles, Mumps, and Rubella
315
transmit the bacteria to others. These individuals can be treated with a
short course of trimethoprim–sulfamethoxazole (TMP–SMX) but the
efﬁcacy of treatment is only 80%.
Eradication of typhoid fever is possible as the only current known
reservoir is humans; however, sanitation and safe food handling prac-
tices would have to change worldwide.
20.9 INFLUENZA EXAMPLE
Inﬂuenza is caused by an orthomyxovirus that belongs to three genera
(6). Inﬂuenza A virus is the causative agent for the vast majority
of the epidemics. The H and N antigens are present in inﬂuenza
A virus and routinely undergo “antigenic shift.” This periodic alter-
ation in the antigens present in the ﬂu virus does not allow persis-
tent immunity to develop in human beings. Thus, until 1957, the
most common subtype was the H1N1 subtype. After that, it shifted
to H2N2. This shift resulted in an epidemic in the United States,
killing more than 70,000 people. It typically presents in the early win-
ter months. The Spanish ﬂu epidemic of 1918 resulted in the death
of more than 650,000 people. The spread was exacerbated by the
wartime zeal and the many rallies set to increase support for the war
effort.
The virus is spread by aerosolized droplets. A person is contagious
until 2–3 days after symptoms have appeared. Often symptoms appear
quickly and the disease progresses rapidly. Inﬂuenza can lead to a
secondary bacterial pneumonia, which can be devastating.
20.10 EXAMPLE OF MEASLES, MUMPS,
AND RUBELLA
These are classically grouped together, as the features of these dis-
eases are somewhat similar. Measles is caused by Morbillivirus, which
is contagious and spread through aerosolized droplets. It is the ﬁfth
leading cause of childhood mortality worldwide, with less than 1%
occurring in the United States because of the relatively widespread
use of the measles vaccine. Symptoms include 2 days of upper respi-
ratory disease followed by a fever >105 F, which then leads to the

316
CHAPTER 20 Risk of an Epidemic
classic morbilliform rash, which includes the palms and soles. The
measles vaccine is a live attenuated virus given at 1 year of age.
Rubella or German measles is caused by Rubella virus of the
genus Rubivirus (6). The vaccine was introduced in 1969 with the last
pandemic occurring in 1964. It spreads via respiratory droplets and is
most severe when acquired by pregnant women. Intrauterine rubella
can lead to mental retardation, deafness, and heart disorders among
other complications. Maternal infection during the ﬁrst trimester of
pregnancy will have an incidence of 50% transmission to the fetus
resulting in more severe malformations than infection during subse-
quent trimesters of pregnancy.
Mumps is caused by paramyxovirus (6). The vaccine was intro-
duced in 1967. The disease can also be transmitted by respiratory
droplets. Rarely fatal after introduction of the vaccine, the incidence
in the United States was reduced to approximately 200 annually.
20.11 POLIO EXAMPLE
Polio is caused by an enterovirus; the least common manifestation
of poliomyelitis is paralysis (6). Initially, the affected individual will
develop a fever, sore throat, and headache, which will progress to
severe back pain and ﬁnally progressive muscle weakness. This occurs
in approximately 1% of those affected by polio.
There is a 1 in 2.5 million chance that a person will develop polio
from the oral polio vaccine. This is increased in an immunocompro-
mised population. Because of the use of the inactivated polio vaccine,
this has decreased to zero since 1999. Transmission of enterovirus is
through fecal oral route.
20.12 PERTUSSIS (WHOOPING COUGH)
The causative agent is Bordetella pertussis. It is a gram-negative bacil-
lus and releases a toxin that binds to the cilia in the respiratory tract
(6). It was discovered in 1906. There is a vaccine available that is
typically given in the ﬁrst year of life. The characteristic “whooping
cough” is typically present only in the very young and may often go
overlooked in an adult population. There is a booster available, which

20.13 Cholera Example
317
is recommended for those in their mid-20s and again in the elderly
population (6). Without a booster, a susceptible adult may develop
the disease and easily pass it along to an unvaccinated or under
vaccinated child. In uninfected populations, transmission is almost
100%. Before the development of the vaccine in the 1940s, approxi-
mately 200,000 people were affected annually. This fell to less than
1000 annually in the 1970s in the United States with a mortality of
almost 1% (9).
20.13 CHOLERA EXAMPLE
The Broad Street pump in London, England, in 1854 was the source of
a cholera outbreak affecting over 500 individuals (10). Dr. John Snow,
after interviewing many family members of those affected, found that
those individuals affected had all visited one water pump on Broad
Street. He then removed the water pump handle, and the cases of
cholera abruptly stopped. Dr. Snow, through his investigation, demon-
strated a clear epidemiologic process.
Vibrio cholera is a gram-negative bacteria that causes cholera (6).
It continues to cause epidemic outbreaks in India and Bangladesh.
The bacterium remains within the lumen of the bowel and releases an
endotoxin. This endotoxin stimulates the bowel to lose chloride and
bicarbonate, which also stimulates the release of sodium and water
resulting in profuse, watery diarrhea and mucous.
Prior to 1992, it was thought that there was only one subtype of
cholera that caused the profuse diarrheal illness; however, since that
time, a new subtype O139 has emerged in Bengal (11).
In the United States, the risk of a cholera epidemic is low, sec-
ondary to the water treatment facilities available with the last major
outbreak occurring in 1911 (10). It is also necessary to monitor shell-
ﬁsh as the optimal conditions for the growth of V. cholera are salty
coastal waters where clams are found. There have been a handful
of isolated cases in the Gulf areas of the United States. The risk of
a global pandemic from cholera is relatively low. There is a vaccine
available, as there is no immunity developed after infection. Treatment
of cholera includes ﬂuid replacement therapy as well as administration
of antibiotics such as doxycycline. This is not entirely curative, but it
can reduce the duration of symptoms.

318
CHAPTER 20 Risk of an Epidemic
20.14 SUMMARY
The aforementioned examples are the most common and most likely
candidates to cause an epidemic because of the relative ease of trans-
mission. There are other types of infectious processes that can spread
rapidly, but this chapter is constructed to provide a concise synopsis
of the potential for epidemic and the risk analysis thereof. Again, the
question of how do we realistically calculate the potential risk of an
epidemic is not what we need to ask but rather, how do we enforce
and educate the populous regarding the protective measure against
epidemics.
REFERENCES
1. WHO. World Health Organization; 2011. Available at http://apps.who.int/ghodata/
?vid=2440. Retrieved 2011 Sept 23.
2. Hethcote H. The mathematics of infectious diseases. Soc Ind Appl Math
2000;42(4):599–653.
3. Judith F, English MY. Bioterrorism readiness plan: a template for healthcare
facilities; 1999.
4. Lazarus RK. Using Automated Medical Records for Rapid Identiﬁcation of Ill-
ness Syndrome (Syndromic Surveillances): The Example of Lower Respiratory
Infection. Boston, MA: BMC Public Health; 2001.
5. MMWR. Recognition of illness associated with the intentional release of a bio-
logic agent; 2001. Available at Center for Disease Control: http://www.cdc.gov/
mmwr/preview/mmwrhtml/mm5041a2.htm. Retrieved 2011 Sept 21.
6. Anthony S, Fauci EB. Harrisons Principles of Internal Medicine. 17th ed. New
York: McGraw-Hill Professional; 2008.
7. Duncan CJ, Scott S. What caused the Black Death? Postgrad Med J
2005;81(955):315–320.
8. Welford M, Bossak H. Validation of inverse seasonal peak mortality in
medieval plagues, including the Black Death, in comparison to modern Yersinia
pestis-Variant diseases. PLoS One 2009;4(12):e8401. DOI: 10.1371/journal.
pone.0008401.
9. CDC. Center for Disease Control. 2011. Available at Center for Disease Control:
http://www.cdc.gov/cholera/epi.html. Retrieved 2011 Sept 23.
10. Snow J. On the Mode of Communication of Cholera. London: John Churchill;
1855.
11. CDC. Pertussis (Whooping Cough). 2011. Available at Center for Disease Con-
trol: http://www.cdc.gov/pertussis/clinical/index.html. Retrieved 2011 Sept 23.

CHAPTER 21
Process Plant Risk
Assessment Example
21.1 INTRODUCTION
A class of industrial facilities that have experienced catastrophic events
are process plants, speciﬁcally oil and chemical process plants. Some
of the most spectacular recent events are the following:
• Phillips Houston Chemical Complex incidents
• BP Texas City Reﬁnery ﬁre and explosion.
The series of events that led to these events are discussed below.
21.1.1 Phillips Houston Chemical Complex
The Phillips Houston Chemical Complex had endured several acci-
dents with fatalities spanning approximately a decade. Of the three
accidents with fatalities, one was due to an explosion of released
ﬂammable gases and two were explosions from highly reactive chemi-
cals. The result of the accidents brought on a great amount of pressure
from federal agencies, local communities, and unions for the manage-
ment of Phillips to implement a more comprehensive management of
safety.
Risk Assessment: Tools, Techniques, and Their Applications, First Edition.
Lee T. Ostrom, Cheryl A. Wilhelmsen.
2012 John Wiley & Sons, Inc. Published 2012 by John Wiley & Sons, Inc.

320
CHAPTER 21 Process Plant Risk Assessment Example
1989 Explosion
On October 23, 1989, while routine maintenance was being conducted,
approximately 85,000 lb of highly ﬂammable gases escaped from the
process equipment within a very brief period of time. This highly
ﬂammable vapor cloud was ignited by an unknown ignition source.
The resulting explosion and ﬁreball caused the death of 23 people and
injured another 314. The damage to the plant from the explosion and
ﬁres was estimated as being more than $700 million, and through the
disruption of production, an additional $700 million was lost (1). Two
of the known gases in the explosive mix were ethylene and isobutane.
A material safety data sheet (MSDS) from Nova Chemicals states
that ethylene is an extremely ﬂammable liqueﬁed gas (2). Ethylene has
a ﬂammable limit of 2.3–36%, meaning that the material will burn
in air from a concentration of 2.3% in air to a concentration of 36%.
On large spills, the initial evacuation is stated to be 2640 ft (800 m)
downwind.
Isobutane is also a very ﬂammable material. The lower ﬂammable
limit for this material is 1.8% and the upper ﬂammable limit is 8.4%
(3). Isobutane is also listed as a simple asphyxiant that targets the
central nervous system.
According to the U.S. Fire Administration, the workers of the
plant observed the leak and vapor cloud, but only had 60–90 seconds
to evacuate as the gases soon found an ignition source (4). The report
also states that there were plenty of sources of ignition in the imme-
diate area, which included ventilation fans, electrical switches, and
gas burn-off ﬂames. The actual ignition source will never be known.
The explosion within the complex measured at an estimated 500 ft by
750 ft and produced 3.5 on the Richter Scale 25 mi away, having an
estimate of 4.0 at the epicenter. Structures at a quarter of a mile away
had considerable damage. The U.S. Fire Administration listed several
key issues (4). These are provided in Table 21.1.
After a lengthy investigation, it was found that the backup protec-
tion was not used at the plant as required by Phillips’ own regulations.
Owing to this failure, OSHA charged Phillips Company in failure to
train maintenance personnel on “how to work safely with hazardous
chemicals.” The results were a $4 million ﬁne and the loss of $1.4
billion due to the accident, not to mention the loss of 23 lives (4).

21.1 Introduction
321
TABLE 21.1
Key Issues in 1983 Phillips Explosion
Issue
Comments
Cause of
explosion/ﬁre
Unknown whether human or mechanical failure. A 10-in high
pressure line carrying ethylene and/or isobutene emitted a
ﬂammable vapor cloud into a hostile environment
Building structure
Multistory structure encompassing several acres, primarily of
metal construction. Material carried through the pipes within
the structure was for the making of plastic pellets
Sprinkler system
Building/structures were equipped with sprinkler systems;
however, the force of the explosion severed water supplies
for the systems
Evacuation
Because explosion/ﬁre occurred almost immediately, planned
evacuation routes were not much help. Personnel simply
ﬂed the structure in all directions
Incident command
CIMA had a preﬁre plan that worked extremely well in all
phases
Casualties
Twenty-three people are known to have been killed. One was
still missing at the time of this report. Well in excess of 100
were injured in varying degrees
Fire department’s
right to know
Responding departments were all members of CIMA. CIMA
strictly adheres to Superfund Amendments and
Reauthorization Act (SARA) Title III and their own strict
guidelines that state all member companies must have an
open door policy
Enclave
Although this plant’s location was in an unincorporated area,
it still fell under the ruling law for both the state of Texas
and the city of Pasadena
The positive aspect of the accident was the reaction of the ﬁrst
responders. According to the U.S. Fire Administration, the use of a
preemergency plan by the Chemical Industry Mutual Aid (CIMA)
Organization, which had produced its own handbook, was invaluable
(4). Although initially very tragic, the preemergency plan proved suc-
cessful in response. The use of dual command with the company
ofﬁcial in the ﬁeld command post and the CIMA commanding the
central command post provided ease of operation, which would have
been hindered by a single command being overwhelmed. Also noted
was the accessibility of the plant before enhancing ﬁreﬁghter’s knowl-
edge of hazards, layout of the plant, and the availability of experts on

322
CHAPTER 21 Process Plant Risk Assessment Example
chemical ﬁres. The use of a separate staging area from the command
post prevented bottlenecking and provided trafﬁc control. During the
response operations, there were no additional deaths or injuries.
Incidents in 1999 and 2000 with Butadiene
The following two accidents involved butadiene. Butadiene is a color-
less, noncorrosive liqueﬁed gas with a mild aromatic or gasoline-like
odor (5). Butadiene is both explosive and ﬂammable because of its
low ﬂash point. Butadiene is used in several areas of the chemical
industry in the production of synthetic rubbers and resins, in which,
the annual growth of its use is estimated at 2% (6). The lower explo-
sive limit is 1.1% and the upper explosive limit is 16.3%. Of special
note is the ﬂash point, which is −76◦C. Therefore, butadiene is both
a ﬁre and explosion hazard.
1999 Explosion
The ﬁrst accident with butadiene took place on June 23, 1999, in the
K-Resin facility. A ﬂash ﬁre occurred in the reactor vessel resulting
in two deaths. Data on the accident show that a thermal runaway
was responsible for the ﬁre and explosion. Findings indicate that the
following caused the accident: “inadequate hazard evaluation during
management of change, inadequate procedures/training, inadequate
process hazards analysis, and inadequate emergency relief design” (6).
2000 Explosion
The second accident involving butadiene in the same facility occurred
on March 27, 2000. Butadiene in a storage tank was involved. The
storage tank was out of service and being cleaned. The absence of
any temperature and pressure gauges prevented personnel to have any
knowledge of any chemicals, especially the presence of the highly
volatile butadiene, The result was death of 1 person and injury of
71 (6).
Butadiene, A Reactive Chemical
These two accidents at the Houston Chemical Complex were due to the
use of butadiene, which is essential in manufacturing through reaction.
The hazards associated with reactivity are related to process-speciﬁc

21.1 Introduction
323
factors, such as operating temperatures, pressures, quantities handled,
concentrations, the presence of other substances, and impurities with
catalytic effects (7). Since Bhopal, federal agencies have been improv-
ing regulations on manufacturing processes in the chemical industry.
The U.S. Chemical Safety Board (CSB) conducted an investigation on
reactive chemicals by looking into 167 accidents over approximately
two decades. With the results, recommendations were given to OSHA
and EPA for regulatory changes (8).
The ﬁndings on uncontrolled chemical reactivity from 1989 to
2001 are as follows (7):
1. Of the 167 accidents, 48 resulted in death averaging about ﬁve
deaths a year.
2. Almost one third affected the public.
3. 42% of the incidents were ﬁre and explosions.
4. Causes and lessons learned were only reported in 20% of the
incidents.
5. 50% involved inadequate procedures for storage, handling, or
processing of chemicals.
21.1.2 BP Texas City Reﬁnery
Texas City was the site of a large industrial ﬁre and explosion on
March 23, 2005. When this explosion occurred, it was considered the
worst workplace accident in the United States for the period since
1989 (9, 10). The explosion was at the Texas City Reﬁnery that was
owned and operated by British Petroleum (BP). Fifteen workers were
killed and more than 170 others were injured in the blast. Before the
explosion, the Texas City Reﬁnery covered a vast amount of space
that was almost 2 mi2 in size and was considered the third largest
reﬁnery within the United States. The ofﬁcial report of the accident
cites the following as the causes of the ﬁre and subsequent explosion
(9, 10):
• The working environment had eroded over the years to one
characterized by resistance to change and lack of trust, moti-
vation, and a sense of purpose. Coupled with unclear expecta-
tions around supervisory and management behaviors this meant

324
CHAPTER 21 Process Plant Risk Assessment Example
that rules were not consistently followed, rigor was lacking,
and individuals felt disempowered from suggesting or initiating
improvements.
• Process safety, operations performance, and systematic risk
reduction priorities had not been set and consistently reinforced
by management.
• Many changes in a complex organization had led to the lack of
clear accountabilities and poor communication, which together
resulted in confusion in the workforce over roles and responsi-
bilities.
• A poor level of hazard awareness and understanding of process
safety on the site resulted in people accepting levels of risk that
are considerably higher than comparable installations. One con-
sequence was that temporary ofﬁce trailers were placed within
150 ft of a blowdown stack, which vented heavier than air hydro-
carbons to the atmosphere without questioning the established
industry practice.
• Given the poor vertical communication and performance man-
agement process, there was neither adequate early warning sys-
tem of problems nor any independent means of understanding
the deteriorating standards in the plant (Chemical Safety).
Table 21.2 contains a partial time line of the events leading to the
explosion and events subsequent to the explosion (9–11).
It is quite clear from the ﬁnal investigative reports that there were
several errors that not only contributed to the explosion but also caused
more people to be in harm’s way than needed to be or should have
been (9, 10).
The errors began long before the explosion when mobile work
trailers were placed on the site without submitting a change to the
siting plan and getting that change approved. Most of the people who
died in the explosion were in the mobile work trailers that should not
have been located there, as they were on an approved siting plan as
dictated by the reﬁnery’s own procedures.
The next error occurred while they were starting to get the Iso-
merization Unit running again and they had some issues during their
shift, which they were able to correct; however, they did not stay at
the site in order to brief the incoming shift supervisor or operator. So

21.1 Introduction
325
TABLE 21.2
Time line of Events Leading to the Texas City Explosion
Date
Event/activity
September 2004
BP sites the double-wide trailer between the Naphtha
Desulfurization Unit (NDU) and Isomerization (ISOM) units
to house contractor employees for turnaround work in the
nearby Ultracracker Unit
October 2004
The Texas City site leader meets with the R&M Chief
Executive and Senior Executive Team to discuss the 2004
incidents; management discusses how these incidents are the
result of casual compliance and personal risk tolerance
despite two of the three incidents being directly process
safety related
2004
The 2004 Process Safety Management (PSM) audit reveals
poor PSM performance of the Texas City reﬁnery,
especially in mechanical integrity, training, process safety
information, and management of change (MOC)
November 2004
Plant leadership meets with all site supervisors for a “Safety
Reality” presentation that declares that Texas City is not a
safe place to work
Late 2004
BP Group reﬁning leadership gives the Texas City reﬁnery
business unit leader a 25% budget cut “challenge” for 2005;
the business unit leader asks for more funds due to the
conditions of the reﬁnery, but less than half of the 25% cuts
are restored
Late 2004
The Telos survey is conducted to assess safety culture at the
reﬁnery and ﬁnds serious safety issues
2004
The reﬁnery-wide OCAM audit ﬁnds that only 25% of ISOM
unit operators are given performance appraisals annually
and that no individual operator development plans are being
developed for unit operators; the audit also ﬁnds that the
budget allows for no training beyond initial new employee
and OSHA-required refresher information
January–February
2005
Nine additional trailers are placed in the area between the
NDU and ISOM units
January 2005
The Telos Report is issued with recommendations to improve
the signiﬁcantly deﬁcient organizational and cultural
conditions of the Texas City reﬁnery
February 2005
The BP Group VP and the North American VP for Reﬁning
meet with reﬁnery managers in Houston, where they are
presented with information on the Telos report ﬁndings, the
deteriorating conditions of the reﬁnery, budget cuts,
inadequate training, pressures of production overshadowing
safety, and the 2004 fatality incidents
(continued)

326
CHAPTER 21 Process Plant Risk Assessment Example
TABLE 21.2
(Continued)
Date
Event/activity
2005
The 2005 Texas City HSSE Business Plan warns
management that that reﬁnery will likely “kill someone in
the next 12–18 months”
March 2005
The Texas City Process Safety Manager tells management
that PSM action item closure is still a signiﬁcant concern
and this metric is ﬁnally added to the site’s 1000-d goals
March 23, 2005
Explosion and ﬁre at the Texas City reﬁnery results in 15
fatalities and 180+ injuries
April 2005
Owing to 23 deaths at the Texas City reﬁnery in 30 yr, OSHA
puts BP onto its list of “Enhanced Enforcement Program for
Employers Who are Indifferent to Their Obligations”
July 2005
An incident in the RHU results in a shelter-in-place of the
community and $30 million in damage at the reﬁnery
August 2005
A release in the CFHU results in a shelter-in-place and $2
million in damage at the reﬁnery
September 2005
OSHA ﬁnes BP $21 million for 301 egregious willful
violations
December 13, 2005
During unit startup, a distillation tower at the BP Whiting
reﬁnery in Indiana is overﬁlled, resulting in ﬁre and damage
June 2006
Settlement Agreement’s independent auditor study and
recommendations. Included in the study are
recommendations to BPTCR to implement the ISA
S84.00.01 Standard for safety-instrumented systems
July 2006
An employee of a contractor was fatally injured when he was
crushed between a scissor lift and a pipe rack at BPTCR
January 2008
The top head blew off a pressure vessel resulting in the death
of a BP employee. BP was issued four serious citations
related to PSM
there was a lack of communication among the two shifts. During the
course of the day, several other factors occurred, which aided to the
lack of attention to detail and also communication problems among the
staff. There were several phone calls that were made during the shift
at critical moments, had they not occurred, the operators and/or their
supervisors would have potentially caught and rectiﬁed the problems
early on and ultimately averted the disaster. Also, the report cites that
when the supervisor and the crew went to lunch and even after that,
some critical events occurred. If these issues had been caught earlier,

21.2 Example Analysis
327
the problems could have been noted and corrective action could have
been taken (10).
The worst part of this disaster is that it could have been avoided.
By enforcing the reﬁnery’s own standards and ensuring that workers
are properly trained and supervised, the explosion could have been
avoided. In addition, if the mobile work trailers had not been moved
into the site without ﬁrst getting an approved change to the siting plan,
the majority of the people who lost their lives would not have been
in harm’s way (10).
This disaster, like most, ultimately came down to human error
(9, 10). In this case, there were many that contributed to the cause
of the explosion. Had better controls been in place, this may not
have occurred at all. In this case, the U.S. Government ﬁned BP with
record-setting ﬁnes for not following the rules and regulations. Had
veriﬁcation measures been enacted, a lot of death and destruction could
have been averted (12).
21.2 EXAMPLE ANALYSIS
This example provides the basic steps for performing a thorough risk
assessment of a process plant. For this example, the ﬁctitious chemical
reactor from Chapter 13, critical functional analysis, has been used as
the case. The attributes of the reactor are as follows:
• It is a 5500-gal-capacity batch reactor.
• Three chemicals are combined in the reactor to produce chem-
ical D. These chemicals are chemicals A, B, and C.
• The following amounts of chemicals are stored on-site:
◦20,000 gal of chemical A;
◦40,000 gal of chemical B;
◦60,000 gal of chemical C;
◦80,000 gal of chemical D.
• The ratio of the three chemicals are as follows:
◦10% chemical A;
◦30% chemical B;
◦60% chemical C.

328
CHAPTER 21 Process Plant Risk Assessment Example
• Chemicals have to be mixed in the proper ratio for 30 min to
ensure a successful batch.
• The reaction is exothermic. For each degree over 300◦F the
reactor reaches, the quality of the product is reduced. Chemical
E is the contaminant produced. The batch becomes 1% chemical
E for each degree over the 300◦F level.
• Increased temperature can cause a spike in reactor pressure. If
the pressure reaches 310◦F, the reactor pressure will near the
safety factor limits of the reactor. At this point, a rupture disk
will break and the gases produced will be directed to a scrubber
column.
• The product must have <2% chemical E to be successful.
The ﬁctitious chemicals used in this process and their physical
and hazardous properties are provided in Table 21.3.
Figure 21.1 shows the diagram of the plant. Table 21.4 contains a
list of the symbols that were used for the components of this ﬁctitious
plant.
Table 21.5 contains failure/reliability data for the components of
the plant, which have been used in the analyses.
There can be a large number of risk analyses performed even with
this relatively simple plant diagram and limited process information.
Therefore, only a few of the many possible example analyses have
TABLE 21.3
Chemical Properties
Boiling
Vapor
Explosive
Flash
Chemical
point
pressure
limits
LD50 or LC50
point
A
173◦F (78.5◦C) 5.7 kPa 20◦C 3.3–19% 3600 mg/kg
oral mouse
54◦F (12◦C)
B
180◦F (82◦C)
4.1 kPa 20◦C 2.4–8%
2745 mg/kg
oral rat
52◦F (11◦C)
C
47◦F (8.5◦C)
132 kPa 20◦C NA
5 ppm/1 h
inhalation rat
NA
D
214◦F (102◦C) 2 kPa 20◦C
3–9%
1 gm/kg oral
mouse
110◦F
E
240◦F (115◦C) 1 kPa 20◦C
NA
15 mg/kg oral
rat
160◦F (71◦C)

Chemical A
storage
P-2
P-14
P-15
V-2
V-3
Pump C
Pump B
P-18
P-19
V-5
V-6
P-21
P-20
P-22
Flow C
Flow B
Flow A
P-16
P-17
V-1
P-3
P-4
P-6
P-8
P-23
V-8
V-9
P-24
P-25
P-28
P-30
P-31
P-11
V-10
P-12
V-11
V-12
V-14
Pump D
Flow D
P-32
V-13
P-33
Storage tank
finished product
P-36
P-34
Heat
exchanger
P-7
V-7
V-4
Pump A
Chemical B
storage
Chemical C
storage
Temp
Press
Cooling jacket
Reactor vessel
P-35E-3
FIGURE 21.1
Plant diagram.
329

330
CHAPTER 21 Process Plant Risk Assessment Example
TABLE 21.4
Plant Symbols
Symbol
Description
Chemical A storage
Storage tank
v-1
Valve
Pump A
Pump
Flow B
Flow controller
Temp
Instrument
E-3
Mixer
Heat exchanger
Heat exchanger
Cooling jacket
Cooling jacket

21.2 Example Analysis
331
TABLE 21.5
Plant Component Reliability Data
Component
Failure type
Probability of failure
Chemical valves V-1
to V-11
Valve stem seal/shaft failure
1/10,000 valve operations
Cooling water valve
V-12, V-13, and
V-14
Valve stem seal/shaft failure
1/10,000 valve operations
Chemical pumps,
pumps A to C
Seal failure
1/500 demands
Motor fails and overheats
1/1000 demands
Cooling jacket
Weld failure
1/1000 operating hours
Heat exchanger
Weld failure
1/1000 operating hours
Flow
controller—chemical
Inaccurate ﬂow rate
Device needs calibrated
every 5000 operating hours
to ensure proper operation
Catastrophic failure and
leaks
1/2000 demands
Flow
controller—cooling
water
Inaccurate ﬂow rate
Device needs calibrated
every 5000 operating hours
to ensure proper operation
Catastrophic failure
1/20,000 operating hours
Chemical storage
tanks
Weld failure
1/30,000 operating hours
Operator
Fails to monitor
1/1000
Omits steps in a procedure
1/500
been presented. The example risk analyses that have been presented
are as follows:
• preliminary hazard analysis (PHA);
• failure mode and effect analysis (FMEA);
• event tree analysis;
• fault tree analysis (FTA);
• simpliﬁed probabilistic risk assessment (PRA).
21.2.1 Preliminary Hazard Analysis
Table 21.6 shows a sample of the items that would be included in a
PHA for the data presented.

TABLE 21.6
Sample Preliminary Hazard Analysis for Process Plant
Contingencies,
Probability
Probably
preventative
of
Hazard
Accident
cause
measures
failure
Severity
Comments
Chemical A
Spill
Seal leaks develop in
any of the following
valves: -1, V-4, or
V-7
Perform preventative
maintenance on
valve seals
1/10,000 valve
operations based on
vendor information
on valves. This is for
each valve
Toxicity of chemical
A is relatively low,
so severity is
moderate
Periodic maintenance
plans are in place to
inspect and repair
valve seals on a
12-mo basis
Pump A seal failure
Perform preventative
maintenance on
pump seals
1/500 operating hours
based on vendor
information on
pumps
Toxicity of chemical
A is relatively low,
so severity is
moderate
Periodic maintenance
plans are in place to
inspect and repair
pump seals on an
18-mo basis
Fire
Chemical A leaks
from pump or valves
and ignites from
static spark
Perform preventative
maintenance on
pump and valve
seals. Ground
process equipment
1/5 yr based on
operating experience
Chemical A is
considered a
ﬂammable liquid and
a ﬁre could spread to
the storage tanks and
process vessel. The
consequences could
be very severe that
could affect on-site
assets and the public
at large
Periodic maintenance
plans are in place to
inspect and repair
pump seals on an
18-mo basis. Periodic
maintenance plans
are in place to
inspect and repair
valve seals on a
12-mo basis. Process
equipment grounding
will be tested every
12 mo
332

Chemical C Spill Seal leaks develop in
any of the following
valves: -3, V-6, or
V-9
Perform preventative
maintenance on
valve seals. Chemical
detectors will be
installed to determine
if any of these valves
develop leaks.
1/10,000 valve
operations based on
vendor information
on valves. This is for
each valve.
Chemical C is highly
toxic and a spill
would have severe
on and off site
consequences.
Periodic maintenance
plans are in place to
inspect and repair
valve seals on a
6-mo basis. A
replacement valve is
being sought that
will have a higher
level of reliability.
Pump C seal failure
Perform preventative
maintenance on
pump seals
1/500 operating hours
based on vendor
information on
pumps
Chemical C is highly
toxic and a spill
would have severe
on and off site
consequences
Periodic maintenance
plans are in place to
inspect and repair
pump seals on an
18-mo basis. A
replacement valve is
being sought that
will have a higher
level of reliability
Chemical D Spill Seal leaks develop in
any of the following
valves: V-10 or V-11
Perform preventative
maintenance on
valve seals
1/10,000 valve
operations based on
vendor information
on valves. This is for
each valve
Low severity
Chemical D has a
very low possibility
of toxicity
333

334
CHAPTER 21 Process Plant Risk Assessment Example
21.2.2 Sample Failure Mode and Effect Analysis
The sample FMEA will present an analysis of operational aspects of
the process plant since the sample PHA presented an analysis of the
hardware aspects. Table 21.7 shows a partial FMEA for the process
plant.
21.2.3 Sample Event Trees
As discussed in previous chapters, event trees link events together in
a logical sequence. In full PRAs, event trees are used to show the
progression of events, and for each bifurcation of the event tree, there
might be a single event, a fault tree, or a human reliability model. So,
to perform the analysis, there has to be a sequence of events. For the
purposes of this example, the events of interest are as follows.
• V-4 fails and begins to leak
• Operator fails to detect change in chemical A ﬂow into the
reactor
• Pump A motor fails and overheats
• Operator fails to detect pump A motor failure
• Fire erupts.
Table 21.8 shows the event tree for this sequence.
21.2.4 Sample Fault Trees
There are possibly up to 100 individual fault trees that can be devel-
oped for various top events for this process plant. They, of course, can
all be rolled into one large fault tree. Figures 21.2 and 21.3 present
two sample fault trees. Figure 21.2 shows a fault tree for failing to
pump chemical A into the reactor. Figure 21.3 shows a fault tree for
a bad batch of chemical.
21.2.5 Sample PRA
PRAs are performed on only the highest risk, most complex, and/or
most valuable assets. Most likely, a PRA would not be performed

TABLE 21.7
Sample Failure Mode and Effect Analysis for Process Plant
RPN (risk
priority
Item,
Potential
Potential
number)
function,
failure
effects of
Potential
Current
1–10 (10 is Recommended
activity
mode
failure
Severity
cause(s)
Probability
controls
Criticality
highest)
actions
Reactor
cooling
Cooling
jackets
leaks and
loses
cooling
efﬁciency
Reactor
temperature
increases and
chemical E is
produced if
temperature is
increased
above
threshold
High
severity
Weld failure 1/1000
operating
hours. Data
from
operating
experience
Weld
inspection
every 12
mo
Very critical
9
Increase weld
inspection
frequency to
1 in 6 mo
Valve V-12
leaks and
causes loss
in cooling
efﬁciency
Reactor
temperature
increases and
chemical E is
produced if
temperature is
increased
above
threshold
High
severity
Seal failure
1/10,000
valve
operations
based on
vendor
information
on valves
Preventative
mainte-
nance is
performed
every 24
mo as per
vendor
instructions
Very critical
8
Perform
preventative
maintenance
on valve
seals every
12 mo
(continued)
335

TABLE 21.7
(Continued)
RPN (risk
priority
Item,
Potential
Potential
number)
function,
failure
effects of
Potential
Current
1–10 (10 is Recommended
activity
mode
failure
Severity
cause(s)
Probability
controls
Criticality
highest)
actions
Heat
exchanger
leaks and
causes loss
in cooling
efﬁciency
Reactor
temperature
increases and
chemical E is
produced if
temperature is
increased
above
threshold
High
severity
Weld failure 1/1000
operating
hours. Data
from
operating
experience
Weld
inspection
every 12
mo
Very critical
9
Increase weld
inspection
frequency to
1 in 6 mo
Reactor
temperature
is not
controlled
Reactor
temperature
increases and
chemical E is
produced if
temperature is
increased
above
threshold
High
severity
Flow
controller
ﬂow D fails
to allow
proper
amount of
cooling
water to
cooling
jacket
1/5000
operating
hours based
on vendor
data
Instrument
technicians
perform
diagnostic
tests every
4000 h
Very critical
9
Increase
diagnostic
inspection
frequency to
every 2500 h
336

Reactor
temperature
falls below
temperature
required to
maintain
reaction
Moderate
severity
Flow
controller
ﬂow D
allows too
much
cooling
water to
ﬂow
through
cooling
jacket
1/25,000
operating
hours based
on vendor
data
Instrument
technicians
perform
diagnostic
tests every
4000 h
Low
criticality
5
Operating
experience
shows that
this type of
ﬂow
controller
fails very
seldom in
this fashion
337

338
CHAPTER 21 Process Plant Risk Assessment Example
TABLE 21.8
Fire Event Tree for Process Analysis
Fire event
sequence
initiation 
Valve V-1
leaks 
Operator
fails to detect
change in
chemical A flow 
Pump A
overheats 
Operator fails
to detect pump
A over heating 
Fire initiates 
Outcome 
No 
Yes 
No 
Yes 
No 
Yes 
No 
Yes 
No 
Yes 
Normal operations 
Chemical A spill 
Chemical A spill 
Chemical A spill
and damaged pump 
Chemical A spill and
damaged pump 
Catastrophic fire 
on something as simple as our example process plant. However, the
following provides a ﬂavor of how a PRA would be performed on a
process plant.
A ﬁre and subsequent release of chemicals into the atmosphere
would most likely be the top event of interest for this plant. Chemicals
C and E would be the really bad actors that any prudent chemical plant
operator would not want in the environment. Therefore, this sample
PRA focuses on a ﬁre and subsequent release of chemical C. Once
again, this is only a sample analysis of its type being performed and
not a thorough and complete analysis.
The accident sequence to be monitored is as follows.
• Chemical A or B begins to leak.
• The operator fails to detect the leak.
• A overheated pump or static spark ignites the spilled chemical.
• The operator fails to detect the ﬁre.
• The ﬁre damages either the storage tank, piping, pumps, or
valves of the chemical C process line.
Table 21.9 shows the event tree sequence for this event.
Fault trees are then developed for each of the major events in the
sequence. Obviously, the operator actions are not complex, so HRA

21.2 Example Analysis
339
Failure to pump chemical A
to reactor vessel
Storage
tank
A empty
Flow
controller A
failed
Valve V-1
closed
Valve V-4
closed
Valve V-7
closed
Pump A
failed
One or more
valves closed
FIGURE 21.2
Fault tree for failing to pump chemical A into the reactor.
event trees would not be developed. Also, if a major ﬁre is developed,
it is almost certain that chemical C process equipment will be affected.
Therefore, fault trees would be developed for the follows:
• chemical spill;
• ignition source.
Figures 21.4 and 21.5 are the fault trees for these three events.
Failure probabilities are assigned to the basic events in the fault
trees. Table 21.10 shows these data, as well as the overall failure
probability for the individual trees.
The next step is to combine the failure probabilities. Table 21.11
shows the failure rates for the events in the sequence and the overall
failure rate. Rates are combined using Boolean AND logic since each
of the events has to occur for the sequence to progress. By the time
the failure rates are rolled up, the risk of the chemical C process
equipment being damaged by a ﬁre becomes negligible.

Chemical batch
fails quality test
Improper ratio of
chemical A, B, or C
Reactor
mixer
fails
Flow
controller A
fails
Flow
controller B
fails
Flow
controller C
fails
Technician
fails to test
chemical
ratio
Operator
fails to
monitor
temperature
Heat
exchanger
fails
Cooling
jacket
fails
Valve
V-12, fail
Valve
V-13, fail
Valve
V-14, fail
Reactor temperature
is not maintained
FIGURE 21.3
Fault tree for a VAD chemical batch.
340

Chemical A or B spill
Chemical A train
develops a leak
Chemical B train
develops a leak
Storage
tank
A leaks
Pump
A seal
leak
Valve
V-2
leaks
Valve
V-6
leaks
Valve
V-9
leaks
Flow
controller A
catastrophi-
cally
fails
Storage
tank
B leaks
Pump B
seal leak
Valve
V-1
leaks
Valve
V-4
leaks
Valve
V-7
leaks
Flow
controller B
catastrophi-
cally
fails
FIGURE 21.4
Sample fault tree for chemical A or B spill.
341

342
CHAPTER 21 Process Plant Risk Assessment Example
TABLE 21.9
Event Tree Sequence for Chemical Fore and Subsequent Release
of Chemical C
Event
sequence
initiates
Chemical
spill
Operator
fails to detect
leak
Ignition source
present
Operator fails
to detect fire
Fire damages
chemical C
process
equipment
Outcome 
No 
Yes 
No 
Yes 
No 
Yes 
No 
Yes 
No 
Yes 
Normal operations 
Chemical A or C spill 
Incipient Fire
Major chemical fire
Major chemical fire
Chemical C release
Ignition source is present
Process pump
overheats
Pump A
overheats
Pump B
overheats
Pump C
overheats
Static spark
FIGURE 21.5
Sample fault tree for ignition source.

21.2 Example Analysis
343
TABLE 21.10
Failure Rate Data
Fault
Basic
Failure
Failure rate for
tree
event
rate
the fault tree
Chemical spill
Valve V-1 failure
0.0001
0.0057
Valve V-4 failure
0.0001
Valve V-7 failure
0.0001
Storage tank failurea
0.000033
Pump A seal failure
0.002
Flow controller A failure
0.0005
Valve V-2 failure
0.0001
Valve V-5 failure
0.0001
Valve V-8 failure
0.0001
Storage tank failure
0.000033
Pump B seal failure
0.002
Flow controller B failure
0.0005
Ignition source
Pump A overheats
0.001
0.0031
Pump A overheats
0.001
Pump A overheats
0.001
Static sparkb
0.0001
aStorage tank failure was listed as 1/30,000 operating hours. It was assumed that at any point
in time, there is a 1/30,000 chance of a failure.
bA value that is reasonable can be used, if speciﬁc data are not available.
TABLE 21.11
Combined Failure Rates
Failure
Sequence
Failure
Sequence
contribution
designator
rate
Sequence
probability
Chemical spill
A
0.0057
A
0.0057
Operator fails to
detect leak
B
0.001
A × B
0.000057
Ignition source
C
0.0031
A × B × C
0.000000018
Operator fails to
detect ﬁre
D
0.001
A × B × C × D
Negligible
Probability ﬁre
damages process
equipment. Value
developed based on
operating experience
E
0.01
A × B × C × D × E
Negligible

344
CHAPTER 21 Process Plant Risk Assessment Example
Obviously, this is a simple analysis and error bounds have been
omitted. If an analyst is going to perform a PRA on a system such
as a nuclear power plant or a space vehicle, then bounding the error
rates is absolutely important. For a simple analysis, most operators
want to know what the prime drivers for failure are. The failures
with the highest priority can then be further analyzed, the equipment
modiﬁed/replaced, or other mitigation factors implemented to reduce
or eliminate the risk.
21.3 SUMMARY
This example shows the progress of a risk assessment from the very
simple PHA to the more complex PRA. As shown, a wealth of infor-
mation can be gained from each aspect of the analysis. In many cases,
an FMEA can provide the information necessary to make informed
decisions concerning risk associated with a process. Analysis tech-
niques such as PRA should be reserved for the most complex systems
or those systems that have the highest risk.
REFERENCES
1. EASHW. European Agency for Safety and Health. 2011. Available at osha.
europea.eu: http://osha.europa.eu/en/campaigns/hw2010/maintenance/accidents/4-
houston.pdf. Retrieved 2011 Sept 30.
2. Nova. Nova Chemicals; 2011. Available at Nova Chemicals: www.novachem.
com/ProductServices/documents/Ethylene_MSDS_EN.pdf. Retrieved 2011 Aug
25.
3. Airgas. Airgas; 2011. Available at Airgas: www.airgas.com/documents/pdf/001
030.pdf. Retrieved 2011 Aug 25.
4. Yates J. U.S. Fire Administration; 2011. Available at U.S. Fire Administration:
http://www.usfa.dhs.gov/downloads/pdf/publications/tr-035.pdf. Retrieved 2011
Aug 25.
5. ICIS. Butadiene; 2011. Available at http://www.icis.com/v2/chemicals/9075170/
Butadiene.html. Retrieved 2011 Aug 26.
6. OH. Phillips provides update on K-Resin plant accident; 2000. Available at
http://ehstoday.com/news/ehs_imp_33217/. Retrieved 2011 Aug 26.
7. RHI. Reactive Hazards Investigation; 2002. Available at http://orise.orau.gov/emi/
hazards-assessment/ﬁles/resources/reactive-hazards-investigation.pdf.
Retrieved
2011 Aug 26.
8. USCSB. United States Chemical safety Board; 2011. Available at http://www.csb.
gov/about/aboutus.aspx. Retrieved 2011 Aug 27.

References
345
9. BP. Isomerization unit explosion; 2005. Available at British Petroleum: http://
www.bp.com/liveassets/bp_internet/us/bp_us_english/STAGING/local_assets/
downloads/t/ﬁnal_report.pdf. Retrieved 2011 Aug 30.
10. USCSB. United States Chemical Safety Board; 2007. Available at United States
Chemical Safety Board: http://www.csb.gov/assets/document/CSBFinalReportBP.
pdf. Retrieved 2011 Aug 30.
11. USDOL. US Department of Labor OSHA; 2011. Available at http://www.
osha.gov/dep/bp/Timeline_BPTCR_Monitoring_Inspection.html. Retrieved 2011
Aug 30.
12. Greenhouse S. New York Times; 2009 Available at New York Times: http://www.
nytimes.com/2009/10/30/business/30labor.html. Retrieved 2011 Aug 3.

CHAPTER 22
Industry Speciﬁc Case
Studies
22.1 CASE STUDY 1: OVERVIEW
Pharmacy robot (PR) is owned by a pharmaceutical company and is
leased by the local hospital. This is the only pharmacy in the state to
implement the robotic technology in their everyday care of patients.
The technology includes the physician writing the drug order in trip-
licate and the pharmacist reads, interprets, and enters the drug order
into the software program that the PR reads. PR uses infrared lights to
read the bar code of each drug and ﬁlls the patient’s drugs for a 24-h
period. PR ﬁlls 112,000–115,000 prescription orders per month. The
robots error rating for picking and ﬁlling is zero; however, at the hos-
pital, there are 15–20 documented miss picks per month. These errors
are found to be human error in packaging processes and are corrected
when the pharmacist makes his check. Some errors occur by the nurse
dispensing the wrong drug to the wrong patient; these errors are few
and will hopefully be eliminated when the nurse servers are installed
later this year. Records indicate that before using PR, error rates for
dispensing and distributing drugs were much higher.
Risk Assessment: Tools, Techniques, and Their Applications, First Edition.
Lee T. Ostrom, Cheryl A. Wilhelmsen.
2012 John Wiley & Sons, Inc. Published 2012 by John Wiley & Sons, Inc.

22.1 Case Study 1: Overview
347
22.1.1 Introduction
Our risk assessment class at the University of Idaho performed an anal-
ysis of PR, the robotic prescription delivery system and the soon to
be used nurse servers, all in service at our local hospital. Figures 22.1
and 22.2 show the components of the robot. PR is a complex system
that ﬁlls an area of about 600 ft2. Figure 22.3 shows typical, unitized
doses of medication on the pick rack. According to the Institute of
Medicine Report issued in 1999, upwards of 98,000 Americans die
each year from avoidable medical errors, which is the eighth lead-
ing cause of death in the United States (1). Almost everyone knows
someone (or has at least read about someone), who received the wrong
medication as a patient in a health care facility. The human element is
the leading cause in drug errors: both miss picks and errors in dispens-
ing medication to patients. Taking into consideration the capabilities
and limitations of the human element, mistakes are greatly reduced
when we implement design and engineering processes where repeti-
tive manual processes were once used (2). In this chapter, we expound
on the abilities, process, and technology that PR has brought into the
health care facility, from the pharmacy to the patients’ room.
FIGURE 22.1
Robot arm and unitized doses of medications.

348
CHAPTER 22 Industry Speciﬁc Case Studies
FIGURE 22.2
Station where robot arm drops unitized doses in
bag for delivery to patients.
FIGURE 22.3
Unitized doses of medication on the pick rack.

22.1 Case Study 1: Overview
349
22.1.2 Approach
Our class made a ﬁeld trip to our local health care facility pharmacy
where the robot and software system have been successfully imple-
mented. The following describes what we saw as we watched the robot
do its job, where errors would most likely occur, and how technology
has decreased the possibility of errors occurring.
The robot and acudose cabinets were implemented in 2000. An
immediate reduction in mispick errors by the pharmacy in the ﬂoor
cart ﬁlls process occurred. The pharmacy dispenses 112,000–115,000
drugs to patients every month. Historical data show that in the third
quarter of the year 2000, there were reported 1424 errors. In the fourth
quarter of 2000 (the PR was installed and tested during this quarter),
errors were reduced to 568. During the ﬁrst quarter of 2001, the robot
was in full use and errors dropped to 79. By the third quarter of 2001
(1-year after initial implementation), errors dropped to 15, and in the
ﬁrst quarter of 2002, the errors were down to 6. It was determined
that the error rate for the robot was very low. The few mistakes that
are still happening are because of the human element.
The following events describe how the systems work:
1. Drugs are purchased and arrive at pharmacy in bottled or pack-
aged form.
2. Drugs are received and stocked on pharmacy shelves.
3. Drugs are received in the Unit Dose Packaging room and are
packaged and labeled (Fig. 22.4 shows part of this machine
and operation) with a bar code by the technician in one of two
ways:
a. The Bulk Packaging Machine. This machine stops at 50
packages. The technician then moves them to the holding
peg.
b. Plastic Wrap Machine. This is computerized; it takes
syringes, vials, and drug company unit dose pills and
packages them. This machine is self-stopping.
Note: Both packaging machines put a label (the name of the
drug and the strength), the National Drug Code (NDC) number,
and the bar code that the robot reads.

350
CHAPTER 22 Industry Speciﬁc Case Studies
(a)
(b)
(d)
(c)
FIGURE 22.4
Unitized dose packaging. (a) Step 1: drug is selected. (b) Step 2: pills
are poured onto packaging machine. (c) Step 3: pills are loaded into hopper. (d) Step 4:
pills are packaged.
4. Holding Point. Pharmacist checks original package/bottle to
make sure the correct drug and strength has been packaged and
labeled correctly. The pharmacist will check the NDC number
on the pill against the NDC on the original package/bottle.
Note: the NDC on the bar-code label cannot be read and ver-
iﬁed by the human eye. This code can only be read by the
robot.
5. Main Pharmacy Stocking. Technician takes packaged drugs off
pegs and loads the packages onto the rods on the wall outside
of the robot room.
6. Robot computer generates a report that tells the technician what
the robot is stocked out of inside the inner chamber.

22.1 Case Study 1: Overview
351
7. Using the robot report, the technician pulls the drug packages
from the pegs on the wall and loads the packages onto the pegs
on the server door.
8. The server door is moved/locked into place by the technician
and the robot begins to restock the rods on the walls of the
inner chamber.
9. Doctor writes prescriptions in triplicate form and puts it in a
box at the nurses station.
10. From 7:00 am to 11:00 pm daily, a pharmacist picks up the pre-
scriptions hourly and interprets the order and enters the order
into the Meditech computer system.
11. The order is read by the robot, picked, labeled, and dropped
into an envelope with the patients’ name and room number on
the labeled envelope for that patient.
12. At 6:00 am daily, the robot does the “cart ﬁll,” which pulls all
drugs on the patients proﬁle for the next 24 h.
13. Technicians move labeled envelopes from the robot holding
area to the delivery carts and take these carts to the assigned
ﬂoors.
14. Technician moves loaded envelopes from the pharmacy cart to
the ﬂoor cart. He must put the right envelope into the right
patients’ drawer.
15. Nurse is responsible for taking the right drug from the right
drawer and dispensing it to the right patient.
From the above sequence of events, it can be determined that
still the steps involving the human element are where error would
most likely occur. These steps include step 3 (the unit dose packaging
room), step 14 (technician moves labeled envelopes from pharmacy
cart to ﬂoor cart), and step 15 (nurse takes drug from ﬂoor cart and
gives to patient).
The unit dose packaging room is the ﬁrst place where an error
could occur that would start a chain of events. The technician uses
the right bar code, but has the wrong drug or he uses the wrong bar
code for the right drug or the pharmacist fails to verify the NDCs on
the drug and package/bottle. From here, the wrong drug could pass

352
CHAPTER 22 Industry Speciﬁc Case Studies
through the rest of the process and be given to the patient by the nurse.
See the fault tree analysis in Figure 22.5.
Steps 14 and 15 are the next opportunities for drug error. In
step 14, the technician could be interrupted or not paying attention
when moving/delivering/changing drugs from pharmacy cart to ﬂoor
cart. The pharmacy envelopes could be put into the wrong draw-
ers/envelopes on ﬂoor cart. In step 15, the nurse could be interrupted
or not paying attention when he/she is dispensing the drugs from the
ﬂoor cart to the patient. Our analysis shows that the nurse servers
would eliminate the errors in step 15.
PACKAGING-NURSE
DRUG-SELECTION
PCKGDOOR-FAILS
DR-FAILS
PHARMACIST-FAILS
PHARM-HOLDPT
NURSE-QA
NURSE-1
DATABS-FAILS
PHARMACIST-QA1
ROBOT-SNSRS-FAIL
BARCODE-FAILS
CMPTR-FAILS
DATABS-FAILS ROBOT-MNT-FAILS
PACKAGING-ROOM
BULK-PACKAGING
NURSE-SELECTION
BAR-CODE-1
WRONG-RX-2
PHARMACIST-QA0
BAR-CODE-0
NURSE-2
NURSE-3
DOSE
PILL-PACKAGE
PILL
WRONG-RX-1
WRONG-RX
Robot failed to
deliver correct
RX
Pckg door loaded
incorrectly
Pharmacist fails
to verify Dr RX 
Drug selection
process fails
Failure of
packaging/nurse
process
Nurse selects
wrong RX
Right drawer
wrong Rx
Failure to input
correct RX data
Nurse drug
selection
Failure at Pharm
chk hold Pt
Robot barcode
reader fails
Robot computer
database fails
Robot
computer fails
Robot fails from
Prvnt Mnt
Sensors fail on
robot
Wrong dose
right barcode
Failed to use
checklist
Unit dose
packaging for
syringes, vials and
pre-packaged meds
Wrong Rx right
barcode 
Right Pill
Wrong Barcode
Pharmacist fails
to verify Rx
Right dose
wrong barcode
Pharmacist fails
to verify Pill
Unit dose
packaging for pills
Failure in
Packaging Room
Wrong pill
right barcode
Technician Selects
Wrong RX
Technician Selects
wrong RX
Right Rx wrong
barcode
Dr fails to select
correct RX
ROBOTRXRV2
FIGURE 22.5
Fault tree analysis.

22.1 Case Study 1: Overview
353
The Nurse Servers
The nurse servers are cabinets that will be installed outside of each
patient room. It will include all the patients’ drugs, IV’s, chart, lab
work results, and anything else pertaining to that particular patient.
Everything will be bar-coded. The nurse server system is the imple-
mentation of a total bar-code system. As the nurse removes the drugs
from the cabinet (nurse server), she will scan her badge to document
who is dispensing the drug. She will scan the drug to document which
drug is being dispensed. Then she will scan the patient’s wristband,
which will include a bar code on it. This will document which patient
received the drug and what time/date it was dispensed. The pharmacy
technician will deliver the drugs to the nurse server cabinets located
outside of each patient’s room. This will eliminate the chance for error
in step 15. The nurse will only have access to one cabinet at one time
(one cabinet = one patient), this will eliminate the wrong drug being
removed from the ﬂoor cart drawer and given to the wrong patient.
Presently, on the ﬂoor carts, there are 10 drawers to choose from. With
the nurse server, there is only one cabinet (drawer) to choose from,
thus reducing errors by 10/1. Our observation is that the nurse server
is the solution to eliminate the chance of human errors in step 15.
Further Reducing the Potential for Error
Recommendations were generated as a part of our analysis to further
reduce the potential for error. The primary one is to create a total bar-
code/scan process from the pharmaceutical company to the patient.
Have the pharmaceutical company bar code the packages/bottles that
are delivered to the pharmacy. Have scanners in the packaging rooms
(step 3) and have the pharmacy technician carry a scanner (step 14).
In step 3, have the technician scan his identiﬁcation badge and the
packaged drug from the pharmaceutical company. This will generate
the bar code for the drug package that the robot will read (eliminating
human element on computer input in the packaging room).
In step 14, have the delivery technician scan his identiﬁcation
badge and the bar-coded envelope, scan the patients’ bar code on the
nurse server, and scan each drug as he loads them into the nurse server.
It is our observation that this would totally eliminate the already low
six drug errors in the ﬁrst quarter of 2002.

354
CHAPTER 22 Industry Speciﬁc Case Studies
22.1.3 Summary
This analysis demonstrated how robotic technology applied in a phar-
macy can reduce the potential error signiﬁcantly. However, errors can
still occur. A systematic analysis can point out where these error prone
areas are and can help in the formulation of solutions.
22.2 CASE STUDY 2: OVERVIEW
Hydrazine is a rocket fuel that is used in the space shuttle and in
today’s modern ﬁghter jets. It is a suspected human carcinogen, cor-
rosive, highly toxic, sensitizer; liver, kidney, nervous system, blood,
and lung toxin; skin and eye hazard; as well as an odorless, color-
less combustible liquid. An amount as little as 1 oz may be con-
sidered a spill. When a spill occurs, an emergency response team is
dispatched to stop and contain that spill. The emergency team con-
sists of two elements: the base ﬁre department and the hydrazine
response team.
The following section presents an analysis of a hydrazine spill.
Seven primary events were identiﬁed and an event tree was con-
structed. The event tree graphically represented the process ﬂow. The
event tree was analyzed and actions that may cause a failure of the
process were identiﬁed. Next, a preliminary hazard analysis (PHA)
was performed. An analysis of the PHA helped identify what actions
may fail and the way in which these actions might fail. The PHA
led to the development of the fault tree. The fault tree facilitates a
systematic computer analysis of the actions involved and their effects.
Where applicable, the failure of an action to achieve the desired results
was analyzed. The mode in which the failure occurred, the effects
of such a failure, and an attempt to determine just how critical to
the safe stoppage, containment, and clean up of the spill that failure
was will be analyzed. Safety of the personnel performing the work,
safety of the airplane, and the safety of the surrounding personnel was
considered.
Mitigations and interventions were discussed to determine ways
to reduce the risks when performing these actions. These mitigations
may include additional protective equipment, communications equip-
ment, personnel training, and procedures where additional hardware

22.2 Case Study 2: Overview
355
equipment is needed for the stoppage, containment, and cleanup of
the spill.
22.2.1 Introduction
Today’s ﬁghter plane requires a tremendous amount of thrust to propel
it into action against the enemy. Figure 22.6 shows an F-16 creating
vapor discs as it accelerates to supersonic speeds.
Hydrazine is a rocket fuel. It is used in the space shuttle and
in today’s modern ﬁghter jets. This fuel packs the energy required
by military combat planes. This fuel drives thousands of pounds of
ﬁghter plane and armament at speeds well in excess of a 1000 mph.
However, its use is not without risks. This risk assessment is being
performed to determine some of the vulnerabilities associated with this
power source. When a ﬁghter pilot goes into harm’s way, the threat
is obvious. For the men and women who maintain these weapons of
war, the threat is as real though not so obvious.
Hydrazine not only provides a vast amount of energy in a small
volume, it is a suspected human carcinogen, corrosive, highly toxic,
sensitizer; liver, kidney, nervous system, blood, and lung toxin; skin
and eye hazard; as well as an odorless, colorless combustible liquid.
FIGURE 22.6
Moving fast.

356
CHAPTER 22 Industry Speciﬁc Case Studies
22.2.2 Approach
My team met and watched a video of a drill that accurately portrayed
a simulation of a hydrazine leak from a Lockheed Martin F-16 ﬁghter
jet. We developed the ﬂow diagram, made notes from the video, and
pictured ourselves as participants in the drill. As participants of the
drill, we watched the video and cleared up any questions the analysis
team had.
A discussion of the basic events that occur during a spill is now
appropriate. When a spill occurs, an emergency response team is dis-
patched to stop and contain the spill. The emergency team consisted
of two elements: the base ﬁre department and the hydrazine response
team. This team decontaminates the tools used in the spill control and
spill area and renders the spilled hydrazine harmless by neutralization.
Figure 22.7 shows an F-16s up close.
The desired end result is the recovery of the F-16 with no contam-
ination of personnel and no release of hydrazine to the environment.
When a spill or a potential spill is reported, the pilot parks the jet with
the exhaust port downwind (right wing). This allows the hydrazine
response team to approach the airplane from up wind and extract the
pilot when it is necessary.
The pilot remains inside on portable oxygen until the emergency
response team conﬁrms that there is a spill or there is no spill. If
FIGURE 22.7
F-16s up close.

22.2 Case Study 2: Overview
357
it is conﬁrmed that there is no spill, then the pilot is extracted and
removed from the area. If a spill is conﬁrmed, the pilot remains inside
the sealed cockpit on portable breathing air until it is safe for him/her
to leave the aircraft.
The response team must perform such activities as don personal
protective equipment (PPE) and enter the area. They must contain
the leaking hydrazine with buckets and depressurize the emergency
power unit fuel system (to stop hydrazine leaks or spray). After the
spill is contained, the hydrazine response team extracts the pilot from
the aircraft and out of the area (usually with a portable breathing
apparatus). The pilot cannot remain on breathing air for the entire
spill cleanup process because he does not have that much oxygen on
board.
The risks do not stop there. After stopping the leak and containing
further spread of the liquid, the hydrazine response team begins the
process of cleaning up the spill. The liquid that is not caught in buckets
is absorbed and placed in a container where it can be diluted and
neutralized. The plane and the tools used must be decontaminated and
veriﬁed as clean. The PPE that the hydrazine response team is wearing
must be decontaminated and removed. Hydrazine contact is not the
only risk faced by the team. The PPE worn by the team is heavy and
hot. The team members run the risk of heat exhaustion and must be
carefully monitored. Team members may be rotated in and out of the
area as necessary for their protection.
The analysis team watched the video and broke the spill into the
events depicted in the ﬂow diagram. This ﬂow diagram (Fig. 22.8) is
unique in that it shows the basic events and the basic faults associated
with each event.
To assist the analysis teams in determining what activities were
most likely to fail and therefore pose the highest risk, a software
program called Saphire available from the Idaho National Engineering
and Environmental Laboratory (INEEL) was enlisted as the analysis
tool used. An event tree was constructed in this software and a fault
tree was extracted from this event tree. A sensitivity analysis was
conducted. This conﬁrmed the expected result. When all failures are
the result of human error, there is no redundancy built into the system
and all actions have an equal probability for failure. No one path is
more sensitive than another. The cut sets veriﬁed this premise.

A hydrazine spill is reported. The fire
department reports to the scene and
extinguishes the fire or mitigates the
possibility of a fire
The hydrazine spill response team
prepares the site for hydrazine
containment and cleanup
Evacuate
the area
Set up an operations
command point
upwind of the spill
Isolate (barricade)
the spill area
Response workers are
checked for fitness for
cleanup duty
The response cart is
checked prior to entry
Don personal protective
equipment
A safety briefing is
held
The hydrazine spill response
team enters the area for
containment and cleanup.
Stop the leak and contain
the spill
Cleanup spilled liquid
Decon area of plane contaminated
by hydrazine and tools used
Decon personnel
The valve is shut
isolating the
hydrazine tank
The hydrazine tank is
depressurized
Place the hydrazine
catch bucket under the
tank
Dilute spilled
hydrazine with demin
water, catching runoff
in a catch bucket. Use
cloth or paper towel to
absorb liquid
Hydrazine spill is cleaned up with no
adverse contamination of personnel or
the environment
Personnel are sprayed off
by the fire department
with the runoff being
caught and treated
Use bleach to neutralize
the hydrazine and
demin water to rinse
catch in bucket
Swab area to detect
if all hydrazine has
been cleaned up
Personal protective
equipment is
removed
FIGURE 22.8
Process ﬂow for hydrazine leak.
358

22.2 Case Study 2: Overview
359
Next, using technique for human error prediction (THERP) tables,
values were assigned to each event. Inadequate preparation of the
response accounts for 47.3% of the failures and the probability of
failure is 0.009 or 1 in 111.11 times the cart will not be prepared
properly. Rinse water not being collected while decontaminating the
air plane accounts for 36.8% of the failures and has a probability of
occurring of 0.007 or it will occur once in every 142.86 times. The
results of the cut sets generated are shown in Tables 22.1 and 22.2.
As the analysis team reviewed the fault tree, various risk mitiga-
tions were suggested. The method of choice proved to be a checklist
to help ensure all the actions required to stop and clean up the spill
were taken.
Checklists were included for the following cut sets:
1. Response cart preparation
2. Rinse and catching rinse water from personnel and plane decon-
tamination activities
3. Removal of response team PPE
4. Command post establishment
5. Safety brieﬁng
The implementation of these checklists causes a marked shift in
the probabilities of occurrence. This was reﬂected in the rearrangement
of some of the cut sets. Even with the checklist, the response cart
preparation activity is still the most likely activity to fail. However,
the probability of failure is 0.0045 or 1 in every 222 times. The simple
act of using a checklist doubled the probability of success. Failure to
adequately perform the decontamination of the plane was second and
dropped to 0.000003 or 1 in 333,333.
22.2.3 Conclusions
This demonstrates large shifts in probabilities based on relatively low
productivity and cost impact of introducing a checklist. When the most
probable failure has been identiﬁed, the effect of that (used in deter-
mining the importance of the failure) method to reduce the probability
or risk is more easily determined. Then placing them in the event and
fault trees can test those methods of risk reduction. Cost-effective

360
CHAPTER 22 Industry Speciﬁc Case Studies
TABLE 22.1
Original Cut Sets
Cut no. Cut set % Probability
Basic event
Description
1
47.3
9.0E-2
CART
Cart is not adequately
prepared
2
36.8
7.00E-2
PLANE DECON
Rinse water is not
contained
3
4.7
9.0E-3
RINSE & CATCH
WATER WHILE
DOFFING PPE
4
3.7
7.0E-3
DOFFING PPE
Personnel contaminated
while dofﬁng PPE
5
1.6
3.0E-3
ABSORB
Not all liquid is absorbed
6
1.6
3.0E-3
BARRICADE
Personnel fail to
barricade the area
7
1.6
3.0E-3
CHECK TEAM
Response team members
not ﬁt for duty
8
1.6
3.0E-3
COMMAND POST
Command post is not
established
9
1.6
3.0E-3
DETECT RESIDUAL
Not all areas are checked
to verify plane Decon
10
1.6
3.0E-3
EVACUATE
Nonteam members fail to
leave area
11
1.6
3.0E-3
PROTECTIVE
EQUIPMENT
Inadequate or incorrect
PPE staged
12
1.6
3.0E-3
SAFETY
Safety brieﬁng is
inadequate
13
0.5
1.0E-3
BUCKET
Bucket does not catch
hydrazine
14
0.5
1.0E-3
DILUTE
Hydrazine is not
sufﬁciently diluted
15
0.5
1.0E-3
TANK
Tank fails to depressurize
16
0.5
1.0E-3
VALVE
Valve fails to shut
17
0.0
0.0E-4
TOOLS
Rinse water is not
collected from tools
methods thus developed and tested can be implemented with some
degree of certainty of success.
A word of caution must be introduced at this point. The event tree
and fault trees must be developed and reviewed with guidance from
people who are very familiar with the process or types of processes

22.2 Case Study 2: Overview
361
TABLE 22.2
Modiﬁed Cut Sets
Cut set
Cut
no.
set %
Probability
Basic event
Description
1
58.8
4.5E-3
CART
Cart is not adequately
prepared and the cart
checklist is not followed
2
39.2
2.0E-3
TOOLS
Rinse water not collected
from tool Decon and the
checklist is not followed
3
2
1.5E-4
COMMAND-POST
Command post is not
established and the
checklist is not followed
4
0
1.0E-6
ABSORB
Not all liquid is absorbed
5
0
1.0E-6
BARRICADE
Personnel fail to
barricade the area
6
0
1.0E-6
BUCKET
Bucket is not placed to
rinse water or hydrazine
7
0
1.0E-6
CHECK TEAM
Response team member is
not ﬁt for duty
8
0
1.0E-6
DETECT-RESIDUAL
Not all residual hydrazine
is detected
9
0
1.0E-6
DILUTE
Not all contained
hydrazine was diluted
10
0
1.0E-6
EVACUATE
Nonteam members fail to
leave the area
11
0
1.0E-6
PLANE-DECON
Rinse water not contained
12
0
1.0E-6
PROTECTIVE EQUIP
Inadequate or incorrect
PPE staged
13
0
1.0E-6
RINSE & CATCH
Rinse water escapes to
the environment
14
0
1.0E-6
SAFETY
Safety brieﬁng is
inadequate
15
0
1.0E-6
TANK
Tank fails to depressurize
16
0
1.0E-6
VALVE
Valve does not shut
17
0
5.0E-8
DOFFING PPE
Personnel are
contaminated while
removing PPE and
checklist is not followed

362
CHAPTER 22 Industry Speciﬁc Case Studies
involved. These people can screen the trees not only for logic errors
but also to ensure that the results make sense. The Saphire program
is a useful tool but is not without its own set of faults. It is not an
intuitive program. Training on how to enter the data and interpret the
results is required. When the event tree was built and the fault and cut
sets were extracted, the results were not always logical. The ﬁrst time
the program was run, it indicated that the second most likely fault was
the airplane not being adequately decontaminated.
Saphire is designed to be downloaded from the Internet to any
computer having sufﬁcient capacity. However, this did not prove to be
the case. Certain Internet browsers such as the one used by America
Online (AOL) seem to be an obstacle to such downloads. It may
take several attempts on various Internet service providers to ﬁnd a
compatible Internet browser. Saphire seems to work well with either
Netscape or Internet Explorer.
The results were reviewed and because of the few steps and the
simple procedures involved, it was determined that this was not logi-
cally the place of the most likely failure. The THERP tables contain
correction factors that take into account the complexity of tasks. When
the correction factor was correctly applied, the decontamination of the
air plane event moved to number 11.
22.3 CASE STUDY 3: OVERVIEW
Since the 9/11 attack on the World Trade Centers, public interest has
been focused on our level of national security. This national security
concern has concentrated a great deal on airport security. This section
identiﬁes some of the vulnerable areas of airport security screening
processes that allow a person with a weapon or destructive device to
board a plane, causing a life-threatening event. This chapter also spec-
iﬁes other areas in the airport screening process, where packages or
luggage containing deadly weapons can pass through security proce-
dures and enter a plane and cause destruction. This study explores the
possible ways and avenues that can be taken to improve and increase
the reliability of the security screening processes of airports in ensuring
a safe working and living environment.

22.3 Case Study 3: Overview
363
22.3.1 Introduction
The intent of the following aviation risk assessment was to explore
the reliability of airport security systems in our national airports and
fulﬁll the requirements of the University of Idaho course ITED 504—
aviation, medical, and process risk assessment. The sequence of tasks
required to conduct this study consist of the following: identifying
airport security processes, developing a list of components used in
the security evaluation, and designing a ﬂow diagram of security
processes. A software program called Saphire, developed by the Idaho
Environmental and Engineering Laboratory for use in probability and
risk analysis for the Nuclear Regulatory Commission, was used to
develop an event tree and a fault tree for analyzing airport security
screening process. Then, a PHA was performed. This PHA identiﬁed
initiating events and potential consequences that can cause a hazard or
failure point within the airport security processes. A human reliability
analysis (HRA) was used to determine the relationship of the failures
in the security process associated with human error and their event
consequences. Minimal cut sets and event sequences exhibited the
shortest route from the failure to the consequences. This study
concluded by applying mitigations/interventions in determining the
actions required to reduce the risk of failure in the airport security
screening processes. The purpose of the airport security risk assessment
process is to identify vulnerable areas of the airport security screening
process and show changes that will improve security screening.
22.3.2 Purpose Statement
The following analysis hopes to identify speciﬁc areas within a local
airport security screening process that are vulnerable to cause the
screening processes to allow a person with a weapon or destructive
device to board a plane, causing a life-threatening event. It also hopes
to underline areas that need to be considered for improvement and to
increase the conﬁdence and reliability of the security screening pro-
cesses and ensure a safe and secure environment in the airport. Note
that not all possible issues were investigated because this was a stu-
dent analysis and not a thorough study. Changes to the fault tree logic,
for instance, might produce different results.

364
CHAPTER 22 Industry Speciﬁc Case Studies
22.3.3 Airport Security Risk Assessment Process
The basic process for the risk assessment involved several steps. The
ﬁrst step was a visit made to the airport and an interview and tour
conducted of the airport security screening process with the city police
ofﬁcer acting as the airport security chief. The purpose of the process
is to screen out those individuals with weapons or destructive devices
from getting on the plane and causing a life-threatening event.
The four parts of the airport security screening process are deﬁned
in Table 22.3. The airport security screening process goes through the
following basic steps: curbside check-in, where the vehicle is checked
visually for compliance; a ticket check-in, where the ticket agent
checks for photo ID, national ID, and ask the required bomb ques-
tions; a gate check-in, where the security person checks for boarding
pass and screen baggage with the X-ray machine; and a wand-portal
check, where the security person scans the passengers with the portal
and a hand wand. All these checks are designed to screen the passen-
gers and their luggage for life-threatening devices. If the passenger or
their luggage fails to pass the screening checks, they are removed and
taken to another security area for further screening and evaluation.
Nine primary events were identiﬁed and an event tree was con-
structed to graphically represent the process ﬂow. The event tree was
analyzed and actions identiﬁed, which may cause a failure of the pro-
cess. Next, a PHA was performed. An analysis of the PHA helped
identify the actions that may fail and the way in which they fail. The
TABLE 22.3
Four Parts of the Airport Security Screening Process and Their
Purpose
Part
Purpose
Curbside check-in
Security checks and ensures cars are not of a
suspicious nature and are not left unattended
Ticket check-in
Ticket agent checks for photo ID, national photo ID,
and ask the required bomb questions. There is a
baggage search station at this area also
Wand–portal check
Security persons check passengers using the portal and
a hand wand
Gate check-in
Security checks for boarding pass and screen baggage
with the X-ray machine

22.3 Case Study 3: Overview
365
PHA led to the development of the fault tree. The fault tree allows
a computer program to perform a systematic analysis of the actions
involved and their effects. The fault tree was used to perform a sen-
sitivity analysis. All the failures or basic events in the fault tree are
assigned the same numeric value, indicating the probability of occur-
rence. A cut set is generated. Three iterations of this analysis are
needed to identify a path most sensitive or most likely to alter the
outcome if changed.
Using the failure tree and where applicable, the failure of an action
to achieve the desired results will be analyzed. The mode in which
the failure occurred, the effects of such a failure, and an attempt to
determine just how critical it is to the security process and prevention
of a life-threatening event have been analyzed.
Mitigations and interventions have been discussed to determine
ways to reduce the risks of failure when performing these actions.
These mitigations may provide additional veriﬁcation at one or all the
steps in the process.
From a practical perspective, a class team met and discussed the
airport security risk assessment over the course of several class periods
with guidance from the instructor. They developed a ﬂow diagram
made from notes taken during the interview and tour at the airport,
from discussions held in class, from personal experiences of traveling
through the airport, and from current news reports commenting on
airport security.
To assist the team in determining what activities were most likely
to fail and therefore pose the highest risk, a software program called
Saphire was made available from the INEEL. An event tree was con-
structed with this software and a fault tree was extracted from this
event tree. A sensitivity analysis was conducted. This produced the
same results for all three sensitivity values, 0.01, 0.0025, and 1.0E-6,
used. When all failures are the result of human error, there is no redun-
dancy built into the system and all actions have an equal probability
for failure. The ﬁrst two cut sets showed the highest and most equal
percentages of failure followed by the next two cut sets in percentage.
The ﬁrst four cut sets at the top are due to human error with no checks
or veriﬁcation built into the system.
The fault tree for the airport security screening process was taken
through several exercises to arrive at a fault tree that exhibited various
checks and veriﬁcations that try to mitigate as many paths for failure

366
CHAPTER 22 Industry Speciﬁc Case Studies
as possible in the airport security screening process. Each exercise
involved manipulating various gates and basic events and assigning
values from the THERP tables to each of the basic events. Table 22.4
shows the cut set values derived from the ﬁnal input of human error
prediction (HEP) values to the basic events of the fault tree. Failure
of the ticket agent to check and verify a check for the fake national
ID accounts for 87.0% of the failures and the probability of failure
is 0.01 or 1 in 100.0 times that the persons with a fake ID will suc-
cessfully pass through the security screening process. The random
baggage search, curbside check-in, and bomb question account for a
total of 13.2% of the remaining failures and a total probability of fail-
ure of 0.0015 or 1.5 in 1000 times that a person will successfully pass
through these steps of the screening process. The results of the cut
sets generated are shown in Table 22.5.
Various risk mitigation measures were recommended during an
ongoing review of the fault tree by the analysis team. The method
of mitigation chosen was veriﬁcation and the use of checklists. These
were used to help ensure that all the actions required to screen threat-
ening persons were taken.
The veriﬁcation and checklists are used in the following cut sets:
1. Veriﬁcation of fake national ID.
2. Baggage search veriﬁcation.
3. Guard fails to verify vehicle.
4. Veriﬁcation of bomb question.
5. Veriﬁcation of photo ID.
6. X-ray operator fails to verify X-ray screen.
7. Portal operator fails to verify portal operation.
The use of these veriﬁcations and checklists produced a noticeable
difference in the probabilities of occurrence and the rearrangement of
some of the cut sets.
Table 15.4 showed that the bag search, the fake national ID, and
the curbside check-in were the easiest path for a person wanting to
pass through the screening process and not get caught. Instituting
veriﬁcations and checklist switched the easiest paths that a person
would take to get through the screening process. Using a checklist, the
bag search, curbside check-in, and ticket agent bomb question would

22.3 Case Study 3: Overview
367
TABLE 22.4
Revised Cut Set
Cut set
Cut
no.
set % Probability
Basic event
Description
1
87.0
1.0E-2
TA-FAILS-FAKE-NID-CHK,
TA-FAILS-VRFY-FAKE-NID
Ticket agent fails fake
national ID check,
ticket agent fails to
verify fake national ID
2
4.4
5.0E-4
BAG-SEARCH-FAILS,
BG-SRCH-VRFCTN-FAILS
Random baggage search
fails, baggage search
veriﬁcation fails
3
4.4
5.0E-4
CURBSIDE,
GUARD-FAILS-TO-VRFY
Curbside check-in fails,
guard fails to verify
vehicle
4
4.4
5.0E-4
TICKET-AGENT,
TICKET-AGENT1
Fails to pass bomb
question, ticket agent
fails to verify bomb
question
5
0.0
5.0E-7
PHOTO-ID, TA-FAILS-PH-ID,
TA-FAILS-PH-ID-VRFCTN
Passenger has no photo
ID, ticket agent fails to
ask for photo ID,
ticket agent fails to
verify photo ID
6
0.0
5.0E-13
TCK-BPASS-CHK-FAILS,
XRAYOPERATOR-ERROR,
XRAYPOWER-FAILURE,
XRAYSHIELDED-DEVIC,
XRY-OP-FAILS-TO-VERIFY
Ticket boarding pass
check fails, X-ray
operator error causes
failure, power loss
cause X-ray machine
failure, shielded device
fails, X-ray operator
fails to verify X-ray
screening
7
0.0
1.0E-13
PORTALOPERATOR-ERROR,
PORTALPOWER-FAILURE,
PRTL-FAILURE-SHLD-DEV,
PRTL-OP-FAILS-TO-VRFY,
WAND-CHECK
Operator error causes
portal device failure,
power loss causes
portal device failure,
shield device causes
portal failure, portal
operator fails to verify
portal operation,
random wand check
fails

368
CHAPTER 22 Industry Speciﬁc Case Studies
TABLE 22.5
Cut Sets
Cut set
Cut
no.
set % Probability
Basic event
Description
1
50
Note 1
BAG-SEARCH-FAILS
Random bag search fails
2
50
Note 1
FAKE-NID
Fake national ID
3
0.5
1.0E-4
CURBSIDE,
GUARD-FAILS
Curbside check-in fails,
guard fails to notice
vehicle
4
0.0
1.0E-6
AGENT-FAILS, FAKE-ID,
PHOTO-ID
Agent fails fake national
ID check, agent fails to
verify fake national ID
5
0.0
1.0E-8
PORTALOPERATOR-
ERROR,
PORTALPOWER-
FAILURE,
PORTALSHIELDED-
DEVICE,
WAND-CHECK
Operator error causes
portal device failure,
power failure causes
portal device failure,
shielded device causes
portal failure, portal
operator fails to verify
portal operation, random
wand check fails
6
0.0
1.0E-14
EMPLOYEE-INTEGRITY,
PASSENGER, TCKT-
BPASS-CHK-FAILS,
TICKET-AGENT,
XRAYOPERTOR-ERROR,
XRAYPOWER-FAILURE,
XRAYSHIELDED-
DEVICE
Ticket boarding pass
check fails, operator
error causes failure,
power failure causes
X-ray machine failure,
shielded device fails,
X-ray operator fails to
verify X-ray screening
Note 1: All probability values equaled the three sensitivity values of 0.01, 0.0025, and 1.0E-6.
fail to detect someone about 4% of the time or 5 in 10,000 times that
a person walked through the airport screening. The high probability
of failure of the ticket agent to check or successfully check for a fake
national ID is the most prevalent, 87% failure rate or 1.0 in 100.0
visual checks of national ID. There is a marked difference in which
path or cut set that would show the most failure in the screening
process and in the probabilities based on the use of veriﬁcations and
checklist. Their introduction into the screening process would probably
have a low impact on productivity and cost.

22.4 Case Study 4: Overview
369
22.3.4 Summary
Suggestions and recommendations are presented for ensuring that the
airport screening process is designed and operated in a manner that
ensures the maximum of safety to passengers and airport security
personnel. From the process of risk analysis and the use of the software
program from the INEEL, the checklist and veriﬁcations are shown
to produce the less risk of failure for the different paths of screening
process to fail in detecting an individual determined to get through
the airport screening and causing a life-threatening event. The process
of checking and verifying a fake national ID seems to be the most
vulnerable for failure. This may be due to the lack of hard numerical
data on national fake IDs, their prevalence in our society, and the ease
at which they can be mistaken for the real ID. This risk analysis may
warrant further research into this area of national security.
Conclusions
To ensure a level of conﬁdence and reliability in the airport security
screening process, the speciﬁc areas to focus on is the national identi-
ﬁcation check and the baggage search process as identiﬁed in the risk
analysis exercise.
22.4 CASE STUDY 4: OVERVIEW
22.4.1 Introduction
Food-borne disease outbreaks in the United States have become much
too common. Illness cause by Escherichia coli is one of the more com-
mon types of food-related illnesses. However, most of the food-borne
outbreaks in the United States are caused by Salmonella. Salmonella
is a bacterium that is mostly found in food products that are meat
based. Salmonella lives in the intestines of many animals, including
humans (3). The bacteria are excreted from feces onto food products.
When Salmonella are ingested, it will make humans sick, even though
Salmonella lives in the intestines naturally.
One reason that Salmonella outbreaks are not more common is
because the bacteria die when cooked at a high temperature. However,
fresh produce does not get cooked and some of the outbreaks are

370
CHAPTER 22 Industry Speciﬁc Case Studies
associated with vegetables such as lettuce, peppers, and even alfalfa
sprouts.
In 2008, there was a massive outbreak of Salmonella (1). Forty-
three states were affected and 1329 document cases of salmonellosis
were diagnosed from April 10, 2008, to July 31, 2008. The outbreak
was one of the largest outbreaks of Salmonella in the United States.
The source of the bacteria was said to be from Jalape˜no and Serrano
peppers, Cilantro, and possibly tomatoes from Mexico.
Most of the cases were reported from April 16 to July 9. During
this period, there were 1017 people who were diagnosed. Of these
cases, 203 people were hospitalized and 1 person died. At the begin-
ning of the outbreak, it was thought that tomatoes were the cause of
the outbreak. As the outbreak continued, it was found that peppers
and cilantro were also contaminated with Salmonella.
Most persons infected with Salmonella develop diarrhea, fever,
and abdominal cramps 12 to 72 h after infection. The illness usually
lasts for 4–7 days and most persons recover without treatment. How-
ever, in some cases, the diarrhea may be so severe that the patient
needs to be hospitalized. In these patients, the Salmonella infection
may spread from the intestines to the blood stream, and then to other
body sites and can cause death unless the person is treated promptly
with antibiotics. The elderly, infants, and those with impaired immune
systems are more likely to have a severe illness.
The following measures should be taken to reduce the potential
for a Salmonella outbreak:
• Food that is potentially infected by Salmonella should be heated
at temperatures of 55◦C (131◦F) for 1 h or to 60◦C (140◦F) for
half an hour (4).
• To protect against Salmonella infection, it is recommended that
food be heated for at least 10 min at 75◦C (167◦F).
• Cook poultry, ground beef, and eggs thoroughly. Do not eat or
drink foods containing raw eggs or raw (unpasteurized) milk.
• Do not hesitate to send back to the kitchen undercooked meat
products for further cooking.
• Wash hands, kitchen work surfaces, and utensils with soap and
water immediately after they have been in contact with raw meat
or poultry.

22.4 Case Study 4: Overview
371
• Be particularly careful with foods prepared for infants, the
elderly, and the immunocompromised.
• Wash hands with soap after handling reptiles, birds, or baby
chicks and after contact with pet feces.
• Avoid direct or even indirect contact between reptiles (turtles,
iguanas, other lizards, and snakes) and infants or immunocom-
promised persons.
• Do not work with raw poultry or meat and an infant (e.g., feed
and change diaper) at the same time.
• Mother’s milk is the safest food for young infants. Breast-
feeding prevents salmonellosis and many other health prob-
lems (5).
22.4.2 Food Safety Risk Assessment
Risk assessment models can be developed using the food safety param-
eters discussed above and the risk assessment tools and techniques
discussed in this book. For this case study, the following limited sam-
ple models were developed:
• PHA;
• event tree analysis;
• fault tree analysis.
However, this is not to say that other models cannot be developed
using other techniques.
Preliminary Hazard Analysis
Table 22.6 shows a limited PHA that was developed for the risk of
Salmonella from food handling in say a restaurant.
Event Tree Analysis
Event trees are best used to help describe how a more widespread
food-borne Salmonella outbreak could occur. Figure 22.9 shows an
event tree for such a purpose.

TABLE 22.6
Food Safety Preliminary Hazards
Potential hazard
Hazard scenarios
Hazard level
Probability
Mitigation actions
Food-borne
Salmonella
Chicken is not properly cooked
at appropriate temperatures for
an adequate length of time
High
High probability under the
following conditions
Inexperienced cooking staff
Train staff adequately
Cooking staff is very busy
Ensure staff prioritize tasks to ensure
chicken is cooked at the appropriately
Temperature indicators are
not working properly
Maintain and calibrate equipment
Food timers are not working
properly
Maintain and calibrate equipment
Deliberate undercooking of
food
Ensure staff do not undercook food
and take appropriate actions if staff
repeatedly undercook food
Vegetables are contaminated
with Salmonella during
preparation
High
High probability under the
following conditions
Preparation surfaces are not
adequately cleaned after
preparing meat Cutting
utensils are not adequately
cleaned after preparing
meat
Ensure surfaces and utensils are
disinfected using either high
temperature cleaning techniques or
chemical disinfecting agents after
they have been used to prepare meat
products Only use preparation
surfaces or utensils that have been
designated for preparing vegetables.
Clean all food preparation surfaces
and utensils regularly
372

Food is contaminated with
Salmonella by workers after
handling raw chicken
High
High probability under the
following conditions
Workers are not provided
disposable gloves for
handling food
An adequate supply of hypoallergenic
gloves of the appropriate size must
be provided to workers
Workers do not have an
adequate place to wash
their hands
Workers must be provided adequate
means to wash their hands and
allowed to do so between food
handling tasks
Workers do not have time to
wash their hands between
tasks
373

374
CHAPTER 22 Industry Speciﬁc Case Studies
No
Unsafe
Safe
Safe
Chicken is
adequately cooked
before eating?
Chicken becomes
contaminated with
salmonella?
Chicken factory fails
to follow food safety
regulations
No
Yes
FIGURE 22.9
Event tree.
Fault Tree Analysis
There are many ways to develop fault trees for the information pro-
vided in this case study. Figures 22.10 and 22.11 show two examples
of the types of fault trees that can be developed.
Chicken is
contaminated
with
salmonella?
Chicken is not
cooked
properly
Salmonella
outbreak
FIGURE 22.10
Food safety fault tree 1.

References
375
Salmonella
outbreak
People
choose to
eat raw
chicken
Chicken is
not cooked
properly
Cook
handles
raw chicken
Cook
handles
pet snake
Cook fails
to wash
their
hands
Chicken is
contaminated
FIGURE 22.11
Food safety fault tree 2.
REFERENCES
1. Foodborne Illness and Disease. Available at www.fsis.usda.gov: http://www.fsis.
usda.gov/factsheets/salmonella questions & answers/index.asp. Retrieved 2011
Jan 31.
2. Available at http://md-jd.info/abstract. 1999. Institute of Medicine report. Retrieved
January 31 2011.
3. Available at http://www.cdc.gov/salmonella/heidelberg/081811/index.html. August
1st 2011. Investigation Announcements: Multistate Outbreak of Human Salmonella
Heidelberg Infection.
4. Reinberg S. Salmonella Illnesses Now Largest Foodborne Outbreak in U.S. History.
HealthDay Reporter. 2008
5. To err is human: Building a safer health system; November 1999. Available at
www.nap.edu/books/0309068371/html

CHAPTER 23
Restaurant Risk
Assessment Case Study
23.1 INTRODUCTION
Accidents occur frequently in restaurants because there is a broad
range of hazards that exist in such establishments. These hazards
include
• cleaning chemicals;
• hot grease and cooking surfaces;
• slick ﬂoors;
• open ﬂames;
• knives and other cutting instruments;
• hot food;
• old food;
• steam;
• irate customers, well only if the food or service are bad.
A risk assessment can be performed using a combination of a
preliminary hazard assessment and failure mode and effect analysis
techniques. Table 23.1 shows an example analysis.
Risk Assessment: Tools, Techniques, and Their Applications, First Edition.
Lee T. Ostrom, Cheryl A. Wilhelmsen.
2012 John Wiley & Sons, Inc. Published 2012 by John Wiley & Sons, Inc.

TABLE 23.1
Restaurant Risk Assessment
Potential
Short-term
Responsible
Long-term
Hazards
accidents
Risk
solutions
person(s)
solution(s)
Slick ﬂoors in
kitchen area
Slips and falls
High
Regular cleaning
Janitorial staff
Coat ﬂoors with
high friction
coating
Clean food spills
All kitchen staff
Adequate lighting
Manager
Ensure cleaning
chemicals do not
increase slipperiness
Janitorial manager
Ensure staff wear proper
footwear
Manager
Heavy loads
Musculoskeletal
injuries
High
Ensure manual materials
handling equipment is
available
Manager
Purchase food
storage equipment
that reduces bulk
food handling
Ensure heavier items and
stored at the proper
work height
Manager
Train employees on
proper lifting techniques
Manager
(continued)
377

TABLE 23.1
(Continued)
Potential
Short-term
Responsible
Long-term
Hazards
accidents
Risk
solutions
person(s)
solution(s)
Contact with
hot grease
Burns
High
Train employees on
proper handling
techniques
Manager
Purchase enclosed
fryers
Provide personal
protective equipment
Manager
Contact with
steam
Burns
Moderate
Ensure steam handling
equipment is in good
repair
Manager
N/A
Ensure staff is trained on
how to handle steam
equipment failures
Manager
Food safety
Food related
illnesses
High
Ensure food storage areas
are at proper
temperatures
Manager
N/A
Ensure food is used
before expiration dates
Manager and cooks
Ensure employees are
eligible to handle food
Manager
378

Ensure employees wash
their hands regularly
Manager and all
employees
Ensure food warmers are
at proper temperatures
Manager and cooks
Ensure food is cooked to
proper serving
temperatures
Cooks
Knives and
sharp utensils
Cuts
High
Ensure knives are
properly stored
Manager and cooks
N/A
Provide personal
protective equipment
Manager
Provide knife cleaning
racks for dishwasher
Manager
Food
preparation
equipment
Cuts, abrasions,
and caught in
injuries
Moderate
Ensure guards are in
place
Manager and cooks
Purchase
equipment that
has lower
potential for
causing injuries
Ensure equipment is
properly maintained
Manager
Ensure employees and
trained on equipment
operation
Manager
(continued)
379

TABLE 23.1
(Continued)
Potential
Short-term
Responsible
Long-term
Hazards
accidents
Risk
solutions
person(s)
solution(s)
Ensure proper
lockout/tagout
procedures are used
during repair
Manager
Fire hazards
Employee and
customer
injuries
Low
Ensure electrical
equipment is properly
maintained
Manager
Upgrade ﬁre
extinguishing
equipment
Purchase
equipment that is
less prone to ﬁre
hazards
Ensure gas ﬁred cooking
equipment is properly
maintained
Manager
Reduce fuel loading in
the building
Manager and all
employees
Egress from
building in
case of
emergency
Employee and
customer
injuries
Moderate
Ensure adequate egress
routes
Manager
N/A
Ensure egress routes are
unlocked and
unobstructed
Manager and all
employees
380

Glossary
Accident An unexpected and undesirable event, especially one resulting in
damage or harm.
Acetaldehyde An organic chemical compound.
Anomalies Deviation or departure from the normal or common order, form,
or rule.
Basic event A fault or failure in an accident sequence that can occur, which
has an impact on the overall outcome or the top event of a probabilistic
risk assessment or fault tree analysis.
Bioconcentration Uptake and accumulation of a substance from water alone.
Biomagniﬁcation The increase in concentration of a substance such as the
pesticide, DDT.
Boundary conditions The values or conditions that constrain a system.
Chloracne An acnelike eruption of blackheads, cysts, and pustules.
Closed loop Materials do not enter or leave a system.
Component System, job/person, part, tool, or other thing that performs the
activities that make up the critical function.
Component failure An electronic or mechanical part of a system that ceases
to work. In risk assessment terms, this unit has an impact on the success
or failure of a system.
Component fault An electronic or mechanical part of a system that ceases
to work or ceases to work correctly. In risk assessment terms, this unit has
an impact on the success or failure of a system.
Conditional probability A probability whose sample space has been limited
to only those outcomes that fulﬁll a certain condition.
Consequences The positive or negative outcomes of decisions, events, or
processes.
Risk Assessment: Tools, Techniques, and Their Applications, First Edition.
Lee T. Ostrom, Cheryl A. Wilhelmsen.
2012 John Wiley & Sons, Inc. Published 2012 by John Wiley & Sons, Inc.

382
Glossary
Critical function What has to be in place to achieve or maintain the mission.
Cut set A set of basic events that lead to the top event in a probabilistic risk
assessment or fault tree.
Delphi process A structured communication technique, originally developed
as a systematic, interactive forecasting method, which relies on a panel of
experts.
Discrete distribution A statistical distribution that has speciﬁc values.
Event tree A graphical representation of the possible sequence of events that
might occur following an event that initiates an accident.
Failure mode and effects analysis (FMEA) A detailed document that iden-
tiﬁes the ways in which a process or product can fail to meet critical
requirements. It is a living document that lists all the possible causes of
failure from which a list of items can be generated to determine types of
controls or where changes in the procedures should be made to reduce or
mitigate risk.
Failure mode, effects, and criticality analysis (FMECA) The additional
dimension of probability and criticality added to FMEA(s) by the prior-
itization of steps/sections of procedures that need to be changed or the
process changed to reduce risk; pointing out where warnings, cautions, or
notes need to be added in procedures; and pointing out where special pre-
cautions need to be taken or specialized teams/individuals need to perform
tasks. The criticality is mainly a qualitative measure of how critical the
failure to the process really is based on subject matter experts’ opinion and
based on probability of occurrence and/or on the consequence or effect.
Fault tree analysis A form of safety analysis that assesses hardware safety to
provide failure statistics and sensitivity analyses that indicate the possible
effect of critical failures.
Gates Logic structures in a fault tree that connect basic events.
Hazard Any risk to which a worker is subject to as a direct result (in whole
or in part) of his being employed.
Hazmat Hazardous materials.
Human reliability analysis (HRA) Used to analyze the human response to
an equipment failure and any process or activity that involves humans is
susceptible to human error. HRAs are used to quantify the probability of
human errors and can be used to identify steps or activities in the process
that can be targeted for changes that could reduce the probability of human
error.
Hydrazine A colorless, fuming, corrosive hygroscopic liquid, H2NNH2,
used in jet and rocket fuels.

Glossary
383
Involuntary risks Those associated with activities that happen to us without
our prior consent or knowledge. Acts of nature such as being struck by
lightning, ﬁres, ﬂoods, tornados, and so on and exposure to environmental
contaminants are examples of involuntary risks.
Methylmercury A bioaccumulative environmental toxicant.
Minamata disease A neurological syndrome caused by severe mercury poi-
soning.
Mission Goal of process, organization, or task.
Nanoparticles A small object that behaves as a whole unit in terms of its
transport and properties.
Nomenclature The terminology used in a particular science, art, activity,
and so on.
Nominal value The value of a security that is set by the company issuing
it, unrelated to market value.
Perception The process of interpreting sensory stimuli by ﬁltering it through
one’s experiences and knowledge base.
Preliminary hazard analysis A hazard analysis performed at the very begin-
ning of a product or facility life cycle to determine the hazards.
Preliminary hazards list Hazards initially determined from an analysis.
Probabilistic risk assessment (PRA) Focuses on equipment failures and
may included a section that discusses the probability of human failure
being the initiating event.
Probability The likelihood that the event will occur.
Qualitative analysis Nonquantitative analysis. An analysis that is descriptive
in nature.
Quantitative analysis An analysis that seeks to determine the numerical
value of something.
Reverse engineer The process of discovering the technological principles
of a man-made device, object, or system through analysis of its struc-
ture, function, and operation. It often involves taking something (e.g., a
mechanical device, electronic component, or software program) apart and
analyzing its workings in detail to be used in maintenance or to try to
make a new device or program that does the same thing without using or
simply duplicating (without understanding) any part of the original.
Risk The potential for realization of unwanted, adverse consequences to
human life, health, property, or the environment; estimation of risk is usu-
ally based on the expected value of the conditional probability of the event
occurring times the consequence of the event given that it has occurred.

384
Glossary
Risk analysis A detailed examination, including risk assessment, risk evalua-
tion, and risk management alternatives, performed to understand the nature
of unwanted, negative consequences to human life, health, property, or
the environment; an analytical process to provide information regarding
undesirable events; the process of quantiﬁcation of the probabilities and
expected consequences for identiﬁed risks.
Risk assessment The process of establishing information regarding accept-
able levels of a risk and/or levels of risk for an individual, group, society,
or the environment.
Risk estimation The scientiﬁc determination of the characteristics of risks,
usually in as quantitative a way as possible. These include the magnitude,
spatial scale, duration, and intensity of adverse consequences and their
associated probabilities as well as a description of the cause and effect
links.
Risk evaluation A component of risk assessment in which judgments are
made about the signiﬁcance and acceptability of risk.
Risk homeostasis theory In any activity, people accept a certain level of
subjectively estimated risk to their health, safety, and other things they
value, in exchange for the beneﬁts they hope to receive from that activ-
ity (transportation, work, eating, drinking, drug use, recreation, romance,
sports, or whatever).
Risk identiﬁcation Recognizing that a hazard exists and trying to deﬁne
its characteristics. Often risks exist and are even measured for some time
before their adverse consequences are recognized. In other cases, risk iden-
tiﬁcation is a deliberate procedure to review and, it is hoped, anticipate
possible hazards.
Risk perception An individual or group assessment of the potential for neg-
ative consequence.
Statistically nonveriﬁable Risks from involuntary activities that are based
on limited data sets and mathematical equations.
Statistically veriﬁable Risks for voluntary or involuntary activities that have
been determined from direct observation.
Support Utilities, materials, activities, or other items that support the com-
ponents.
Target risk A speciﬁc level of risk an organization feels comfortable with
and aims to achieve.
Task analysis Task analysis is any processes of assessing what a user does
and why, step by step, and using this information to design a new system
or analyze an existing system.

Glossary
385
TOP events The event of interest in a probabilistic risk assessment or fault
tree analysis to which all other basic events feed.
Undeveloped event Events with little information or no information or those
that do not need to be developed because they concern things such as
weather or other natural events.
Voluntary risks Those associated with activities that we decide to undertake
(e.g., driving a car, riding a motorcycle, drinking, and driving).

Acronyms
AMTs
Aviation Maintenance Technicians
ANSI
American National Standards Institute
APU
Auxiliary Power Unit
BLS
Bureau of Labor Statistics
BP
British Petroleum Oil Company
CAMEO
Computer-Aided Management of Emergency Operation
CFR
Code of Federal Regulations
CHRIS
Chemical Hazards Response Information System
CIMA
Chemical Industry Mutual Aid Organization
CIT
Critical Incident Technique
COOP
Continuity of Operations Plan
CPSC
Consumer Product Safety Commission
CSB
Chemical Safety Board
D&D
Decontamination and Decommissioning
DIC
Disseminated Intravascular Coagulation
ECCS
Emergency Core Cooling System
EFIS
Electronic Flight Instrument System
EM
Emergency Management
EPZ
Emergency Planning Zones
ERA
Ecological Risk Assessment
ERG
Emergency Response Guide
FEMA
Federal Emergency Management Agency
FMC
Flight Management Computer
FMEA
Failure Mode and Effects Analysis
FMECA
Failure Mode Effects and Criticality Analysis
FTA
Fault Tree Analysis
GEM
Generic Error Modeling
Risk Assessment: Tools, Techniques, and Their Applications, First Edition.
Lee T. Ostrom, Cheryl A. Wilhelmsen.
2012 John Wiley & Sons, Inc. Published 2012 by John Wiley & Sons, Inc.

Acronyms
387
HEPs
Human Error Probabilities
HERMIT
Causation Diagrams, Human Error
Modeling/Investigation Tool
HEROS
Human Error Rate Assessment and Optimizing
System
HRA
Human Reliability Analysis
LED
Light-Emitting Diode
LOCA
Loss of Cooling Accident
LPG
Liquid Petroleum Gas
MMS
Minerals Management Service
MRO
Maintenance, Repair, and Overhaul
MSDS
Material Safety Data Sheet
MTBF
Mean Time Between Failures
MTTF
Mean Time to Failure
NASA
National Aeronautics and Space Administration
NDC
National Drug Code
NRC
Nuclear Regulatory Commission
NTSB
National Transportation Safety Board
OPA
Oil Pollution Act
PHA
Preliminary Hazards Analysis
POD
Probability of Detection
PPE
Personal Protective Equipment
PPI
Production Plant Inc.
PRA
Probabilistic Risk Assessments
PSA
Probabilistic Safety Assessments
PSF
Performance Shaping Factor
RAT
Ram Air Turbine
SCRAM
Safety Control Rod Axe Man
SME
Subject Matter Experts
STA
Shift Technical Advisor
TCDD
2,3,7,8-Tetrachlorodibenzo-p-dioxin
THERP
Technique for Human Error Rate Prediction


Index
Accident frequency rate, 105
Air Canada Flight 143, 185
Airport security system, 363–9
Aloha Flight 243, 5
Analysis phase, 43, 52, 58, 237
Analysis plan, 43–4, 50
Agent Orange, 38–40
Bathtub curve, 4–5, 91
Bayesian analysis, 228
Bhopal, 15, 28, 40, 323
Binning failures, 102
BLS accident rate, 105
BLS disabling injury severity rate, 106
Boolean logic, 9, 164, 279
British Petroleum Oil Company (BP),
29–34, 323–7
Bunker Hill, 28
Butadiene, 322
Case Studies, 167, 175–9, 236–47,
251–71, 346–80
See also
Airport security systems
Chernobyl
Hydrazine
Pharmacy robot (PR)
Restaurant Risk Assessment
Center for Disease Control (CDC), 311,
313
Challenger, 103–4, 169
Chernobyl, 24, 28, 175–9
Chisso Corporation, 36
Critical Function Approach or Analysis
(CFA), 181–200, 327
Risk Assessment: Tools, Techniques, and Their Applications, First Edition.
Lee T. Ostrom, Cheryl A. Wilhelmsen.
2012 John Wiley & Sons, Inc. Published 2012 by John Wiley & Sons, Inc.
Critical Incident Technique (CIT), 7,
153–62
Columbia, 4, 103–4, 182–3
Communications, 18
Component fault, 205–6, 288
Consumer Product Safety Commission
(CPSC), 64, 77
Continuity of operations plan (COOP),
195–7, 200
Control measures, 11, 123–7
Control rods, 138, 146, 176, 179
Cost-beneﬁt analysis, 53
Craps, 81–9
Cut set, 210–211, 226, 228, 289–90,
357–68
Cycle of an organism, 27
Decision analysis, 168–9
Decision tree, 163–80
Deepwater Horizon, 29–34
Delphi Process, 7, 108–15
Design hazards analyses, 66
Ecological Risk Assessment, 26–53
Lead smelters, 28
Yeast growth, 27
Emergency Management (EM), 13, 18
Emergency Planning Zones (EPZ), 19
Environmental Protection Agency
(EPA), 28, 42, 48–9, 225, 323
Epidemic, 309–18
Anthrax - Bacillus anthracis, 312–13
Cholera, 310, 317,
Ebola virus, 313
Franciscella tularemia, 312

390
Index
Epidemic (Continued)
Inﬂuenza, 315
Polio, 316
Small pox, 313–14
TB - Mycobacterium tuberculosis,
314
Typhoid - Salmonella typhi, 314–15
Whooping cough, Pertussis, 316
Yersinia pestis, 311–12
Ethnography research, 236
Event trees, 8, 163–6, 286, 303, 334,
371
HRA Event Tree, 141–51, 153,
338–9
Modiﬁed event tree, 151
see also Fault Tree
Explosion of 1989, 320–322
Explosion of 1999, 323
Explosion of 2000, 323
Failure
Early failure, 4–5
Old age failure, 4–5
Steady state failure, 4–5
Failure Mode and Effect Analysis
(FMEA), 4, 7, 118–34, 227, 251,
277–83, 334, 344
Failure Mode, Effects, and Criticality
Analysis (FMECA), 8, 119,
126–34
Failure rate, 4, 91, 97–116, 227–8, 339,
343
Fault Tree Analysis (FTA), 4, 9,
203–21, 227, 334
Fault Tree Symbols, 205–6
Logic gates, 9, 207–9
Federal Emergency Management
Agency (FEMA), 195, 197, 251,
275
Food–borne disease, 369
Great River, 45–52, 297–301
Hazard
Hazardous energy sources, 69–72
Hazardous Occupation, 2
Hazardous Process, 16
Lawn care chemicals, 14–15
Liquid petroleum gas, 15
see also Threat
Hazard controls, 255, 269–74
HazMat, 167–8
Hierarchical diagram, 60
Hierarchical Task Analysis, 61–3
Hooker Chemical, 34
Human error probabilities (HEPs), 97,
107–16, 135–8, 144–8, 366
Human Reliability Analysis (HRA), 4,
9, 135–51, 211, 228, 338, 263
Hydrazine, 354–61
Idaho National Engineering and
Environmental Laboratory
(INEEL), 357, 366, 369
Incident rate, 106
Iterative processes, 42, 58
Kanki and Hobbs, 153–7
Little Creek, 45–6
Link Analysis, 63
Lockerbie bombing, 24
Logic Diagrams, 137, 226
Logic gates, 9, 207–9
Lois Gibbs, 35
Loss-of-coolant accident (LOCA),
137–8, 166
Love Canal, 15, 28, 34–6
Mars Global Surveyor, 118, 134
Mean time to failure (MTTF), 103
Minimata Methylmercury, 28, 36–7
Mixed method study, 241, 247
Narrative research, 232–3, 240–41
NASA, 6–7, 118, 203, 224–6,
Natural Disasters, 26, 249, 295, 307
Earthquake, 21–3, 249, 265, 295, 297
Ice age, 26
Oxygen, 26

Index
391
Flooding of the Red River, 296
Operational sequence diagram, 60–63
Perception process, 243
Performance Shaping Factors (PSFs),
107–16, 146–8
Pharmacy robot (PR), 346–53
Phenomenon, 157, 233–4
Phillips Houston Chemical Complex,
319
Plant Symbols, 330
Preliminary Hazards Analysis (PHA), 4,
8, 64–79, 120, 250–251, 298,
331, 344, 354, 363–5, 371
Product Design, 64, 75–7
Prevalence rate, 106
Probability
Combination of, 82–94
Theory of, 81–95
Tree diagrams, 94–5
see also Uncertainty
Probability of Detection (POD), 110,
242
Probabilistic Safety Assessments
(PSAs), 135
Probabilistic Risk Assessment (PRA), 4,
9, 135–6, 203, 223–30, 334–44
Problem formulation, 42–52
Process mapping, 154–7
Production Plant, Inc. (PPI), 45–51
Qualitative research, 157, 231–41
Qualitative risk assessment, 225
Quantitative research, 231–47
Quantitative risk assessment, 226–7,
307
Rancho Cordova accident, 4, 292
Relative probability scale, 113
Restaurant Risk Assessment, 376–80
Risk, see
Consequence
Ecological risk
Risk analysis, 9, 17, 86, 91, 106, 118,
240, 363, 369
see also
Analysis phase
Analysis plan
Cost-beneﬁt analysis
Critical Function Approach or
Analysis (CFA)
Decision analysis
Design hazards analyses
Failure Mode and Effect Analysis
(FMEA)
Failure Mode, Effects, and Criticality
Analysis (FMECA)
Fault Tree Analysis (FTA)
Human Reliability Analysis (HRA)
Link Analysis
Preliminary Hazards Analysis (PHA)
Root cause analysis
Risk analyst, 5–7, 22–5, 107–12, 158
Risk Assessment
Assessment endpoints, 42–3, 49, 52
Chemical plant, 18, 23, 338
Conceptual models, 42, 50
Probability theory, 81, 85
Risk assessment team, 7–11
Risk characterization, 43–4, 52
Risk of Driving, 22–3, 169
Risk perception, 13–20
Audience’s perception, 20
Root cause analysis, 162
Rules of thumb (cognitive heuristic),
16–20, 138, 149
Safety Control Rod Axe Man
(SCRAM), 137–46
Salmonella, 163, 314, 369–75
Saphire, 357, 362–5
Severity, 6, 65, 69, 332
Seveso, 40–41
Six sigma/total quality management
philosophy, 4
Statistics, 81–96, 239
Subtask, 59–63
System’s Life Cycle, 3–5, 65
see also Bathtub curve

392
Index
TAM Linhas A’ereas Flight 3054,
215–20
Task Analysis
Data Collection, 59–60, 224, 236–7
Descriptive, 56–7
Formative, 56–7
Normative, 56–7
Record data, 60–61
Task Analysis Techniques, see
Hierarchical Task Analysis
Link Analysis
Operations Sequence Diagrams
Time line Analysis
Techniques, see
Critical Incident Technique (CIT)
Delphi process
Human Reliability Analysis (HRA)
Probabilistic Risk Assessment (PRA)
Technique for Human Error Rate
Prediction (THERP), 107, 144–5,
359–66
Texas City Reﬁnery, 319–26
Threat, 6–8, 41, 52, 198, 223, 250–252,
266, 311, 355
Three Mile Island, 163
Time line Analysis, 63
Timelines, 60
Tools, see
Event trees
Failure Mode and Effect Analysis
(FMEA)
Failure mode, effects, and criticality
analysis (FMECA)
Fault Tree Analysis (FTA)
Preliminary Hazards Analysis (PHA)
Tool for Human Error Analysis
(THEA), 149
Top event, 9, 166, 204–14, 286–9,
338
Uncertainty, 13, 42, 85, 227, 229
United Flight, 232, 183–4, 188
Verify Rods Inserted, 138–47
Vulnerability assessment, 249–54
Wasa accident, the, 3–4

