Stochastic Petri Nets:
Modelling, Stability, 
Simulation
Peter J. Haas
Springer

Springer Series in Operations Research
Editors:
Peter W. Glynn
Stephen M. Robinson

Peter J. Haas
Stochastic Petri Nets
Modelling, Stability, Simulation
With 71 Illustrations

Peter J. Haas
IBM Research Division
San Jose, CA 95120-6099
USA
peterh@almaden.ibm.com
Series Editors:
Peter W. Glynn
Stephen M. Robinson
Department of Management Science
Department of Industrial Engineering
and Engineering
University of Wisconsin–Madison
Terman Engineering Center
Madison, WI 53706-1572
Stanford University
USA
Stanford, CA 94305-4026
USA
Library of Congress Cataloging-in-Publication Data
Haas, Peter J. (Peter Jay)
Stochastic Petri nets : modelling, stability, simulation / Peter J. Haas.
p. cm. — (Springer series in operations research)
Includes bibliographical references and index.
ISBN 0-387-95445-7 (alk. paper)
1. Petri nets.
2. Stochastic analysis.
I. Title.
II. Series.
QA267 .H3 2002
511.3—dc21
2002019559
Printed on acid-free paper.
2002 Springer-Verlag New York, Inc.
All rights reserved. This work may not be translated or copied in whole or in part without the
written permission of the publisher (Springer-Verlag New York, Inc., 175 Fifth Avenue, New York,
NY 10010, USA), except for brief excerpts in connection with reviews or scholarly analysis. Use
in connection with any form of information storage and retrieval, electronic adaptation, computer
software, or by similar or dissimilar methodology now known or hereafter developed is forbidden.
The use in this publication of trade names, trademarks, service marks and similar terms, even if
they are not identified as such, is not to be taken as an expression of opinion as to whether or not
they are subject to proprietary rights.
Manufacturing supervised by Jerome Basma.
Camera-ready copy prepared from the author’s LaTeX2e files using Springer’s macros.
Printed and bound by Maple-Vail Book Manufacturing Co., York, PA.
Printed in the United States of America.
9 8 7 6 5 4 3 2 1
ISBN 0-387-95445-7
SPIN 10867072
Springer-Verlag
New York Berlin Heidelberg
A member of BertelsmannSpringer Science+Business Media GmbH

Preface
This book was motivated by a desire to bridge the gap between two impor-
tant areas of research related to the design and operation of engineering
and information systems. The ﬁrst area concerns the development of mathe-
matical tools for formal speciﬁcation of complex probabilistic systems, with
an eye toward subsequent simulation of the resulting stochastic model on
a computer. The second area concerns the development of methods for
analysis of simulation output.
Research on modelling techniques has been driven by the ever-increasing
size and complexity of computer, manufacturing, transportation, workﬂow,
and communication systems. Many engineers and systems designers now
recognize that the use of formal models has a number of advantages over
simply writing complicated simulation programs from scratch. Not only
is it much easier to generate software that is free of logical errors, but
various qualitative system properties—absence of deadlock, impossibility of
reaching catastrophic states, and so forth—can be veriﬁed far more easily
for a formal model than for an ad-hoc computer program. Indeed, certain
system properties can sometimes be veriﬁed automatically.
Our focus is on systems that can be viewed as making state transitions
when events associated with the occupied state occur. More speciﬁcally,
we consider discrete-event systems in which the stochastic state transi-
tions occur only at an increasing sequence of random times. The “Bedi-
enungsprozess” (service process) framework, developed by K¨onig, Matthes,
and Nawrotzki in the 1960s and early 1970s, provided the ﬁrst set of build-
ing blocks for formal modelling of general discrete-event systems. The mod-
ern incarnation of the Bedienungsprozess is the “generalized semi-Markov

viii
Preface
process” (gsmp). Although useful for a uniﬁed theoretical treatment of
discrete-event stochastic systems, the gsmp framework is not always well
suited to practical modelling tasks. In particular, the modeller is forced to
specify the “state of the system” directly as an abstract vector of random
variables. Such a speciﬁcation can be highly nontrivial: the system state
deﬁnition must be as concise as possible for reasons of eﬃciency, but must
also contain enough information so that (1) a sequence of state transitions
and transition times can be generated during a simulation run and (2) the
system characteristics of interest can be determined from such a sequence.
Stochastic Petri nets (spns), introduced in the 1980s, are very appealing in
that they not only have the same modelling power as gsmps (see Chapter 4)
but also admit a graphical representation that is well suited to top-down
and bottom-up modelling of complex systems.
In parallel to these advances in modelling, a rigorous theory of simulation
output analysis has been developed over the past 25 years. Much of this
theory pertains to the problem of obtaining point estimates and conﬁdence
intervals for long-run performance measures of interest. Such point and in-
terval estimates are typically used to compare alternative system designs
or operating policies. These estimates also form the basis for simulation-
based optimization procedures. Conﬁdence intervals can be particularly
diﬃcult to obtain, but are necessary to distinguish true diﬀerences in sys-
tem behavior from mere random ﬂuctuations. The basic idea is to view
each simulation run as the sample path of a precisely deﬁned stochastic
process. Point estimates and conﬁdence intervals are then established by
appealing to limit theorems for such processes.
Unfortunately, many of the results in the output-analysis literature have
not been provided in a form that is directly useful to practicing simula-
tion analysts. Typically, a speciﬁed estimation or optimization procedure
is shown to produce valid results if the output process of the simulation
has speciﬁed stochastic properties—for example, obeys speciﬁed limit the-
orems or has a sequence of regeneration points. Veriﬁcation of the required
properties for a speciﬁc (and usually complicated) simulation model often
turns out to be a formidable task. Indeed, when studying the long-run per-
formance of a speciﬁed system, it is often hard even to establish that the
simulation problem at hand is well posed in that the system is stable and
long-run performance measures actually exist.
This book is largely concerned with making a connection between mod-
elling practice and output-analysis theory. We illustrate the use of the spn
building blocks for modelling and discuss the basic principles that underlie
estimation procedures such as the regenerative method and the method of
batch means. Tying these topics together are veriﬁable conditions on the
building blocks of an spn under which the net is stable over time and spec-
iﬁed estimation procedures are valid. Our treatment highlights perhaps the
most appealing aspect of spns: the formalism is powerful enough to permit

Preface
ix
accurate modelling of a wide range of real-world systems and yet simple
enough to be amenable to stability and convergence analysis.
When studying the literature related to spns, one quickly encounters
a multitude of spn variants as well as a variety of other frameworks for
modelling discrete-event systems. Partly for this reason, we provide—in
addition to our other results—methods for comparing the modelling power
of diﬀerent discrete-event formalisms. Although we emphasize the compari-
son of spns with gsmps, our general approach provides a means for making
principled choices between alternative modelling frameworks. Our method-
ology can also be used to extend recurrence results and limit theorems
from one framework to another. This latter application of our modelling-
power theorems both simpliﬁes the proofs of certain results for spns and
makes the material in this book relevant not only to spns but also to the
general study of discrete-event systems. Indeed, this book can be viewed
as a survey of some fundamental stability, convergence, and estimation is-
sues for discrete-event systems, using spns as a convenient and appealing
framework for the discussion.
Our view of spns diﬀers from many in the literature in that we focus
on the close relationship between spns and gsmps. To some extent this
viewpoint is necessary: because we allow completely arbitrary clock-setting
distributions, the underlying marking process of an spn is not, in general,
a Markov or semi-Markov process. Our viewpoint also is advantageous,
in that it lets us exploit the many powerful results that have been es-
tablished for both gsmps and their underlying general state-space Markov
chains. We emphasize, however, that spns have unique features that require
extension—rather than straightforward adaptation—of results for gsmps.
The prime example is given by “immediate transitions,” which have no
counterpart in the gsmp model and lead to a variety of mathematical com-
plications.
The presentation is self-contained. Knowledge of basic probability theory,
statistics, and stochastic processes at a ﬁrst-year graduate level is needed
to understand the theory and examples. We occasionally use results from
the theory of Markov chains on a general state space—most of the techni-
cal complexities for such chains can safely be glossed over in our setting,
and the results we use are directly analogous to classical results for chains
with ﬁnite or countably inﬁnite state spaces. The Appendix summarizes
the key mathematical results used in the text. To increase accessibility,
we suppress measure-theoretic notation whenever possible—the Appendix
contains a discussion of basic measure-theoretic concepts and their relation
to the terminology used in the text. The more applied reader will wish
to focus primarily on the discussion of modelling techniques and on spe-
ciﬁc estimation methods. These topics are covered primarily in Chapter 1,
Chapter 2, Section 3.1.3, Section 6.3, Sections 7.2.2–7.2.4 and 7.3.3–7.3.5,
Sections 8.1, 8.2.2–8.2.4, 8.3.2, and 8.3.3, and Sections 9.1 and 9.3.

x
Preface
I am grateful to the IBM Corporation for support of this work and for the
resources of the Almaden Research Center. I also wish to thank Thomas
Kurtz and the Center for the Mathematical Sciences at the University of
Wisconsin–Madison for hospitality during the 1992–1993 academic year. I
have beneﬁtted from conversations with many colleagues over the years,
including Sigrun Andradottir, James Calvin, Donald Iglehart, Sean Meyn,
Joseph Mitchell, William Peterson, Karl Sigman, and Mary Vernon. Thanks
also are due to the students of the graduate course on simulation that I
taught at Stanford University during the 1998–1999 and 2000–2001 aca-
demic years. Shane Henderson provided valuable feedback on an initial
version of the manuscript. As is apparent from the notes and references in
the text, I am deeply indebted to Gerald Shedler, who introduced me to
both spns and stochastic simulation and who has co-authored most of the
papers I have written on these topics. Perhaps less apparent, but equally
important, are the technical insights and general encouragement that I have
received from Peter Glynn. The staﬀof Springer-Verlag has been exceed-
ingly helpful throughout the production of this book—special thanks go
to Achi Dosanjh for her help in jump-starting the project and to Kristen
Cassereau for her meticulous copyediting. Finally, I wish to thank my wife,
Laura, and my children, Joshua and Daniel, for their love, patience, and
support.
San Jose, California
Peter J. Haas
March 2002

Contents
Preface
vii
List of Figures
xv
Selected Notation
xix
1
Introduction
1
1.1
Modelling . . . . . . . . . . . . . . . . . . . . . . . . . . . .
2
1.2
Stability and Simulation . . . . . . . . . . . . . . . . . . . .
9
1.3
Overview of Topics . . . . . . . . . . . . . . . . . . . . . . .
13
2
Modelling with Stochastic Petri Nets
17
2.1
Building Blocks . . . . . . . . . . . . . . . . . . . . . . . . .
17
2.2
Illustrative Examples . . . . . . . . . . . . . . . . . . . . . .
24
2.2.1
Priorities: Producer–Consumer Systems . . . . . . .
24
2.2.2
Marking-dependent Transitions . . . . . . . . . . . .
31
2.2.3
Synchronization: Flexible Manufacturing System . .
41
2.2.4
Resetting Clocks: Particle Counter . . . . . . . . . .
45
2.2.5
Compound Events: Slotted Ring
. . . . . . . . . . .
47
2.3
Concise Speciﬁcation of New-Marking Probabilities . . . . .
49
2.3.1
Transition Firings That Never Occur . . . . . . . . .
50
2.3.2
Numerical Priorities . . . . . . . . . . . . . . . . . .
51
2.4
Alternative Building Blocks . . . . . . . . . . . . . . . . . .
64

xii
Contents
3
The Marking Process
69
3.1
Deﬁnition of the Marking Process . . . . . . . . . . . . . . .
70
3.1.1
General State-Space Markov Chains . . . . . . . . .
70
3.1.2
Deﬁnition of the Continuous-Time Process
. . . . .
72
3.1.3
Generation of Sample Paths . . . . . . . . . . . . . .
75
3.2
Performance Measures . . . . . . . . . . . . . . . . . . . . .
77
3.2.1
Simple Time-Average Limits and Ratios . . . . . . .
77
3.2.2
Conversion of Limit Results to Continuous Time . .
78
3.2.3
Rewards and Throughput . . . . . . . . . . . . . . .
81
3.2.4
General Functions of Time-Average Limits
. . . . .
86
3.3
The Lifetime of the Marking Process . . . . . . . . . . . . .
87
3.3.1
Absorption into the Set of Immediate Markings . . .
87
3.3.2
Explosions . . . . . . . . . . . . . . . . . . . . . . . .
90
3.3.3
Suﬃcient Conditions for Inﬁnite Lifetimes . . . . . .
91
3.4
Markovian Marking Processes . . . . . . . . . . . . . . . . .
92
3.4.1
Continuous-Time Markov Chains . . . . . . . . . . .
93
3.4.2
Conditional Distribution of Clock Readings . . . . .
95
3.4.3
The Markov Property . . . . . . . . . . . . . . . . .
102
4
Modelling Power
111
4.1
Generalized Semi-Markov Processes
. . . . . . . . . . . . .
113
4.2
Mimicry and Strong Mimicry . . . . . . . . . . . . . . . . .
116
4.2.1
Deﬁnitions
. . . . . . . . . . . . . . . . . . . . . . .
116
4.2.2
Suﬃcient Conditions for Strong Mimicry . . . . . . .
120
4.3
Mimicry Theorems for Marking Processes . . . . . . . . . .
127
4.3.1
Finite-State Processes . . . . . . . . . . . . . . . . .
128
4.3.2
Countable-State Processes . . . . . . . . . . . . . . .
132
4.4
Converse Results . . . . . . . . . . . . . . . . . . . . . . . .
136
5
Recurrence
145
5.1
Drift Criteria . . . . . . . . . . . . . . . . . . . . . . . . . .
146
5.1.1
Harris Recurrence and Drift . . . . . . . . . . . . . .
146
5.1.2
The Positive Density Condition . . . . . . . . . . . .
150
5.1.3
Proof of Theorem 1.22 . . . . . . . . . . . . . . . . .
157
5.2
The Geometric Trials Technique
. . . . . . . . . . . . . . .
164
5.2.1
A Geometric Trials Criterion . . . . . . . . . . . . .
165
5.2.2
GNBU Distributions . . . . . . . . . . . . . . . . . .
166
5.2.3
A Simple Recurrence Argument . . . . . . . . . . . .
172
5.2.4
Recurrence Theorems
. . . . . . . . . . . . . . . . .
174
5.2.5
Some Ad-Hoc Recurrence Arguments
. . . . . . . .
182
6
Regenerative Simulation
189
6.1
Regenerative Processes . . . . . . . . . . . . . . . . . . . . .
190
6.1.1
Deﬁnition of a Regenerative Process . . . . . . . . .
190
6.1.2
Stability of Regenerative Processes . . . . . . . . . .
193

Contents
xiii
6.1.3
Processes with Dependent Cycles . . . . . . . . . . .
197
6.2
Regeneration and Stochastic Petri Nets
. . . . . . . . . . .
202
6.2.1
General Conditions for Regenerative Structure
. . .
203
6.2.2
SPNs with Positive Clock-Setting Densities . . . . .
208
6.2.3
SPNs Satisfying Geometric Trials Criteria . . . . . .
217
6.2.4
The Regenerative Variance Constant . . . . . . . . .
228
6.3
The Regenerative Method . . . . . . . . . . . . . . . . . . .
230
6.3.1
The Standard Method . . . . . . . . . . . . . . . . .
231
6.3.2
Bias of the Point Estimator . . . . . . . . . . . . . .
238
6.3.3
Simulation Until a Fixed Time . . . . . . . . . . . .
240
6.3.4
Estimation to Within a Speciﬁed Precision
. . . . .
242
6.3.5
Functions of Cycle Means . . . . . . . . . . . . . . .
245
6.3.6
Gradient Estimation . . . . . . . . . . . . . . . . . .
250
6.3.7
A Characterization of the Regenerative Method . . .
262
6.3.8
Extension to Dependent Cycles . . . . . . . . . . . .
265
7
Alternative Simulation Methods
275
7.1
Limitations of the Regenerative Method . . . . . . . . . . .
276
7.2
Standardized Time Series
. . . . . . . . . . . . . . . . . . .
282
7.2.1
Limit Theorems
. . . . . . . . . . . . . . . . . . . .
282
7.2.2
STS Methods . . . . . . . . . . . . . . . . . . . . . .
288
7.2.3
Functions of Time-Average Limits
. . . . . . . . . .
293
7.2.4
Extensions
. . . . . . . . . . . . . . . . . . . . . . .
297
7.3
Consistent Estimation Methods . . . . . . . . . . . . . . . .
298
7.3.1
Aperiodicity and Harris Ergodicity . . . . . . . . . .
300
7.3.2
Consistent Estimation in Discrete Time . . . . . . .
302
7.3.3
Applications to Batch-Means and Spectral Methods
305
7.3.4
Functions of Time-Average Limits
. . . . . . . . . .
309
7.3.5
Consistent Estimation in Continuous Time
. . . . .
311
8
Delays
321
8.1
Speciﬁcation and Measurement of Delays
. . . . . . . . . .
323
8.1.1
Tagging . . . . . . . . . . . . . . . . . . . . . . . . .
324
8.1.2
Start Vectors . . . . . . . . . . . . . . . . . . . . . .
326
8.1.3
Examples of Delay Speciﬁcations . . . . . . . . . . .
328
8.2
Regenerative Methods for Delays . . . . . . . . . . . . . . .
340
8.2.1
Construction of Random Indices
. . . . . . . . . . .
341
8.2.2
The Extended Regenerative Method for Delays . . .
352
8.2.3
The Multiple-Runs Method . . . . . . . . . . . . . .
354
8.2.4
Limiting Average Delays . . . . . . . . . . . . . . . .
360
8.3
STS Methods for Delays . . . . . . . . . . . . . . . . . . . .
365
8.3.1
Stable Sequences of Delays
. . . . . . . . . . . . . .
366
8.3.2
Estimation Methods for Delays . . . . . . . . . . . .
373
8.3.3
Examples . . . . . . . . . . . . . . . . . . . . . . . .
377

xiv
Contents
9
Colored Stochastic Petri Nets
385
9.1
The CSPN Model . . . . . . . . . . . . . . . . . . . . . . . .
387
9.1.1
Building Blocks . . . . . . . . . . . . . . . . . . . . .
387
9.1.2
Modelling with CSPNs . . . . . . . . . . . . . . . . .
390
9.1.3
The Marking Process
. . . . . . . . . . . . . . . . .
397
9.2
Stability and Simulation . . . . . . . . . . . . . . . . . . . .
402
9.2.1
Recurrence
. . . . . . . . . . . . . . . . . . . . . . .
402
9.2.2
CSPNs and Regeneration . . . . . . . . . . . . . . .
406
9.2.3
CSPNs and STS Estimation Methods
. . . . . . . .
409
9.2.4
Consistent Estimation Methods . . . . . . . . . . . .
412
9.2.5
Delays . . . . . . . . . . . . . . . . . . . . . . . . . .
418
9.3
Symmetric CSPNs . . . . . . . . . . . . . . . . . . . . . . .
423
9.3.1
The Symmetry Conditions . . . . . . . . . . . . . . .
423
9.3.2
Exploiting Symmetry: Shorter Cycle Lengths . . . .
425
9.3.3
Exploiting Symmetry: Increased Eﬃciency . . . . . .
431
A Selected Background
447
A.1 Probability, Random Variables, Expectation . . . . . . . . .
447
A.1.1
Probability Spaces . . . . . . . . . . . . . . . . . . .
447
A.1.2
General Measures . . . . . . . . . . . . . . . . . . . .
449
A.1.3
Random Variables . . . . . . . . . . . . . . . . . . .
450
A.1.4
Expectation . . . . . . . . . . . . . . . . . . . . . . .
452
A.1.5
Moment Results for Random Sums . . . . . . . . . .
457
A.1.6
General Integrals . . . . . . . . . . . . . . . . . . . .
458
A.1.7
Conditional Expectation and Probability
. . . . . .
460
A.1.8
Stochastic Convergence
. . . . . . . . . . . . . . . .
462
A.2 Limit Theorems for Stochastic Processes . . . . . . . . . . .
467
A.2.1
Deﬁnitions and Existence Theorem . . . . . . . . . .
467
A.2.2
I.I.D., O.I.D., and Stationary Sequences . . . . . . .
470
A.2.3
Renewal Processes . . . . . . . . . . . . . . . . . . .
472
A.2.4
Discrete-Time Markov Chains . . . . . . . . . . . . .
474
A.2.5
Brownian Motion and FCLTs . . . . . . . . . . . . .
476
A.3 Terminology Used in the Text . . . . . . . . . . . . . . . . .
480
References
483
Index
499

List of Figures
1.1
spn building blocks . . . . . . . . . . . . . . . . . . . . . . .
3
1.2
spn representation of GI/G/1 queue . . . . . . . . . . . . .
4
1.3
Alternative spn representation of GI/G/1 queue
. . . . . .
7
2.1
Cyclic queues with feedback . . . . . . . . . . . . . . . . . .
20
2.2
spn representation of cyclic queues with feedback . . . . . .
20
2.3
Sets of new, old, and newly disabled transitions . . . . . . .
22
2.4
spn rep. of producer–consumer system (nonpreempt.)
. . .
25
2.5
Marking changes for spn rep. of producer–consumer sys. . .
28
2.6
spn rep. of producer–consumer sys. (preempt.-repeat)
. . .
29
2.7
spn rep. of producer–consumer sys. (preempt.-resume) . . .
31
2.8
spn representation of queue with batch arrivals . . . . . . .
32
2.9
Token ring . . . . . . . . . . . . . . . . . . . . . . . . . . . .
34
2.10 spn representation of token ring . . . . . . . . . . . . . . . .
35
2.11 Deterministic spn representation of token ring . . . . . . . .
37
2.12 An spn for modelling pri preemptions . . . . . . . . . . . .
38
2.13 spn representation of ﬂexible manufacturing system
. . . .
43
2.14 Alternative spn representation of manufacturing system . .
45
2.15 spn representation of particle counter
. . . . . . . . . . . .
46
2.16 Slotted ring . . . . . . . . . . . . . . . . . . . . . . . . . . .
48
2.17 spn representation of slotted ring . . . . . . . . . . . . . . .
48
2.18 Example of a transition ﬁring that never occurs . . . . . . .
50
2.19 Two scenarios in which transition e′ becomes disabled . . .
52
2.20 Manufacturing cell with robots . . . . . . . . . . . . . . . .
54

xvi
List of Figures
2.21 spn representation of manufacturing cell with robots . . . .
55
2.22 Collision-free bus network . . . . . . . . . . . . . . . . . . .
58
2.23 spn representation of collision-free bus network . . . . . . .
60
2.24 Timeline diagram for collision-free bus network . . . . . . .
62
3.1
Supply chain
. . . . . . . . . . . . . . . . . . . . . . . . . .
83
3.2
spn representation of supply chain . . . . . . . . . . . . . .
84
3.3
Absorption of the marking process into S′ . . . . . . . . . .
87
3.4
Example for proof of Theorem 4.10 . . . . . . . . . . . . . .
99
3.5
Non-Markovian spn with exponential clock-setting dist’ns .
103
3.6
Markovian spn with no simple timed transitions
. . . . . .
107
4.1
An spn that mimics cyclic queues with feedback
. . . . . .
118
4.2
State-transition diagram for two-state gsmp . . . . . . . . .
128
4.3
spn representation of two-state gsmp . . . . . . . . . . . . .
129
4.4
spn representation of gsmp (ﬁnite state space)
. . . . . . .
131
4.5
spn representation of gsmp (inﬁnite state space) . . . . . .
133
4.6
spn representation with no inhibitor inputs . . . . . . . . .
135
4.7
spn with dependent clock readings . . . . . . . . . . . . . .
136
5.1
Coupling of two Markov chains . . . . . . . . . . . . . . . .
148
5.2
An irreducible spn with a marking that is never hit
. . . .
153
5.3
Telephone system . . . . . . . . . . . . . . . . . . . . . . . .
154
5.4
Timeline diagram for telephone system . . . . . . . . . . . .
154
5.5
spn representation of telephone system . . . . . . . . . . . .
155
5.6
spn representation of cyclic queues . . . . . . . . . . . . . .
177
5.7
spn representation of cyclic queues (three tandem servers) .
181
6.1
spn representation of machine repair system . . . . . . . . .
210
6.2
spn representation of cyclic queues with feedback . . . . . .
226
7.1
Interactive video-on-demand system
. . . . . . . . . . . . .
277
7.2
spn representation of video-on-demand system
. . . . . . .
278
7.3
An spn with extremely long cycles . . . . . . . . . . . . . .
280
8.1
Positions of jobs in cyclic queues with feedback . . . . . . .
324
8.2
spn for measuring delays in cyclic queues with feedback . .
325
8.3
Manufacturing ﬂow-line with shunt bank . . . . . . . . . . .
330
8.4
spn rep. of manufacturing ﬂow-line with shunt bank . . . .
332
8.5
spn representation of airport shuttle . . . . . . . . . . . . .
336
8.6
Deﬁnition of one-dependent cycles
. . . . . . . . . . . . . .
342
8.7
Regenerative cycles for delays . . . . . . . . . . . . . . . . .
349
8.8
spn for comparison of estimation methods . . . . . . . . . .
358
8.9
Comparison of estimation methods . . . . . . . . . . . . . .
358
8.10 Deﬁnition of ˇN0, ˇN1, ˇN2, ˇZ1, ˇZ2, ˇY1, and ˇY2 . . . . . . . . .
362
8.11 Deﬁnition of one-dependent cycles (nonregenerative case)
.
368

List of Figures
xvii
8.12 Positions of jobs in cyclic queues (two servers/center)
. . .
378
8.13 spn rep. of cyclic queues (two servers/center) . . . . . . . .
379
9.1
cspn representation of machine repair system . . . . . . . .
390
9.2
cspn representation of token ring . . . . . . . . . . . . . . .
392
9.3
cspn representation of cyclic queues (nonidentical jobs)
. .
393
9.4
cspn representation of complaint processing system
. . . .
395
9.5
Cycles for delays in a cspn (two colors)
. . . . . . . . . . .
433
A.1 The function Un(t) in Donsker’s theorem . . . . . . . . . . .
478

This page intentionally left blank 

Selected Notation
s →s′
Marking s′ can be reached from marking s
in one step (see Deﬁnition 4.9 in Chapter 4)
s ; s′
Marking s′ can be reached from marking s
in a ﬁnite number of steps (see
Deﬁnition 4.9 in Chapter 4)
1A
Indicator of the set A
|A|
Number of elements in the set A
x ∧y
Minimum of x and y
x ∨y
Maximum of x and y
Cn = (Cn,1, . . . , Cn,M)
Vector of clock readings just after the nth
marking change
C(s)
Set of possible clock-reading vectors when
the marking is s
C[0, 1]
Space of continuous real-valued functions
on [0, 1]
Cl[0, 1]
Space of continuous ℜl-valued functions on
[0, 1]
D = { d1, . . . , dL }
Set of places

xx
Selected Notation
E
Set of transitions
E′
Set of immediate transitions
E(s)
Set of transitions enabled in marking s
E∗(s, c)
Set of transitions—starting with marking s
and clock-reading vector c—that trigger the
next marking change
E∗
n = E∗(Sn, Cn)
Set of transitions that trigger the (n + 1)st
marking change
¯φ
Recurrence measure for the underlying
chain of an spn that satisﬁes
Assumption PD (see Section 5.1.2)
F( · ; s′, e′, s, E∗)
Clock-setting distribution for new
transition e′ after a marking change from s
to s′ triggered by the ﬁring of the
transitions in E∗
F0( · ; e, s)
Initial clock-setting distribution for
transition e when the initial marking is s
γ(n)
Index of nth marking change at which the
new marking is timed
G
Marking set
G(e)
Set of markings in which transition e is
enabled
hq
Function used in drift criterion for stability:
hq(s, c) = exp

q max1≤i≤M ci

Hb
Set of states of the underlying chain such
that each clock reading is bounded above
by b
i.i.d.
Independent and identically distributed
I(e)
Set of normal input places for transition e
J(e)
Set of output places for transition e
L
Number of places
L(e)
Set of inhibitor input places for transition e
µ
Initial distribution of the underlying chain

Selected Notation
xxi
µ+
Initial distribution of the embedded chain
M
Number of transitions
ν0
Initial-marking distribution
N(s′; s, E∗)
Set of new transitions at marking change
from s to s′ triggered by the ﬁring of the
transitions in E∗
o.i.d.
One-dependent and identically distributed
o.d.s.
One-dependent and stationary
O(s′; s, E∗)
Set of old transitions at marking change
from s to s′ triggered by the ﬁring of the
transitions in E∗
ψ(s)
Number of ongoing delays when the
marking is s
Pµ
Probability law of the underlying chain
when the initial distribution is µ
P(s,c)
Probability law of the underlying chain
when the initial state is (s, c)
P

(s, c), A)
Transition kernel of the underlying chain:
P

(s, c), A) = P(s,c) { (S1, C1) ∈A }
P r
(s, c), A)
r-step transition kernel of the underlying
chain: P r
(s, c), A) = P(s,c) { (Sr, Cr) ∈A }
P(e)
Priority of transition e
r(s, e)
Speed of clock for transition e when
marking is s
ℜl
l-dimensional Euclidean space (ℜ= ℜ1
denotes the set of real numbers)
ℜ+
The set of nonnegative real numbers
Σ
State space of the underlying chain
Σ+
State space of the embedded chain
S
Timed marking set
S′
Immediate marking set

xxii
Selected Notation
s = (s1, s2, . . . , sL)
Fixed marking of an spn
|s|
Total number of tokens when the marking
is s
Sn = (Sn,1, . . . , Sn,L)
Marking of the spn just after the nth
marking change
{ (Sn, Cn): n ≥0 }
Underlying chain of the marking process
{ (S+
n , C+
n ): n ≥0 }
Embedded chain of the marking process:
(S+
n , C+
n ) = (Sγ(n), Cγ(n))
τ∆
Lifetime of the marking process
t∗(s, c)
Time—starting with marking s and
clock-reading vector c—until the next
marking change (holding-time function)
{ X(t): t ≥0 }
Marking process of an spn
ζn
Time of the nth marking change

1
Introduction
Predicting the performance of a computer, manufacturing, telecommuni-
cation, workﬂow, or transportation system is almost always a challenging
task. Such a system usually comprises multiple activities or processes that
proceed concurrently. In a typical computer workstation, for example, the
storage subsystem writes data to a disk while, at the same time, one or
more CPUs perform computations and a keyboard transmits characters to
a buﬀer. Activities often have precedence relationships: assembly of a part
in a manufacturing cell does not begin until assembly of each of its subparts
has completed. Moreover, speciﬁed activities may be synchronized in that
they must always start or terminate at the same time. Activities frequently
compete for limited resources, and one activity may have either preemptive
or nonpreemptive priority over another activity for use of a resource. To
further complicate matters, many of the component processes of a system—
such as the arrival process of calls to a telephone network—are random in
nature. Because of this complexity and randomness, developing mathemat-
ical models of the system under study is usually nontrivial. The standard
“network of queues” modelling framework, for example, can fail to capture
complex synchronization behavior or precedence constraints. Assessment of
system performance is equally diﬃcult. Models that are accurate enough to
adequately represent system behavior often cannot be analyzed using, for
example, methods based on the theory of continuous-time Markov chains
on a ﬁnite or countably inﬁnite state space.
This book is about stochastic Petri nets (spns), which have proven to be a
popular and useful tool for modelling and performance analysis of complex
stochastic systems. We focus on some fundamental issues that arise when

2
1. Introduction
modelling a system as an spn and studying the long-run behavior of the
resulting spn model using computer simulation. Speciﬁcally, we consider
the following questions:
• How can spns be used in practice to model computer, manufacturing,
and other systems of interest to engineers and managers?
• How large a class of systems can be modelled within the spn frame-
work? To what degree do various spn building blocks enhance mod-
elling power?
• Under what conditions on the building blocks is an spn model stable
over time, so that long-run simulation problems are well posed?
• What simulation-based methods are available for estimating long-run
performance characteristics? How can the validity of a given estima-
tion method be established for a particular spn model?
We address the ﬁrst question by providing numerous examples of both spn
models and modelling techniques. To address the remaining questions, we
study in detail the various stochastic processes associated with an spn.
1.1
Modelling
It is frequently useful to view a complex stochastic system as evolving over
continuous time and making state transitions when events associated with
the occupied state occur. Often the system is a discrete-event system in
that the stochastic state transitions occur only at an increasing sequence
of random times. In a discrete-event system, each of the several events
associated with a state competes to trigger the next state transition and
each of these events has its own stochastic mechanism for determining the
next state. At each state transition, new events may be scheduled and
previously scheduled events may be cancelled.
The spn framework provides a powerful set of building blocks for speci-
fying the state-transition mechanism and event-scheduling mechanism of a
discrete-event stochastic system. An spn is speciﬁed by a ﬁnite set of places
and a ﬁnite number of transitions along with a normal input function, an
inhibitor input function, and an output function (each of which associates
a set of places with a transition). A marking of an spn is an assignment
of token counts (nonnegative integers) to the places of the net. A transi-
tion is enabled whenever there is at least one token in each of its normal
input places and no tokens in any of its inhibitor input places; otherwise,
it is disabled. An enabled transition ﬁres by removing one token per place
from a random subset of its normal input places and depositing one token
per place in a random subset of its output places. An immediate transi-
tion ﬁres the instant it becomes enabled, whereas a timed transition ﬁres

1.1 Modelling
3
Figure 1.1. spn building blocks.
after a positive (and usually random) amount of time. In the context of
discrete-event systems, the marking of the spn corresponds to the state of
the system, and the ﬁring of a transition corresponds to the occurrence of
an event. In general, for a given marking, some transitions are enabled and
others are not, reﬂecting the fact that some events can occur and others
cannot possibly occur when a discrete-event system is in a given state—for
example, a “departure of customer” event cannot occur if the state is such
that no customers are in the system.
spns have a natural graphical representation (see Figure 1.1) that fa-
cilitates modelling of discrete-event systems. This bipartite graph of the
places and transitions of an spn determines the event-scheduling mecha-
nism. In the graphical representation of an spn, places are drawn as circles,
immediate transitions as thin bars, and timed transitions as thick bars. Di-
rected arcs connect transitions to output places and normal input places to
transitions; arcs terminating in open dots connect inhibitor input places to
transitions. Tokens are drawn as black dots. In Figure 1.1, for example, the
place containing a single token is an inhibitor input place for the leftmost
of the two timed transitions and a normal input place for the rightmost of
the two timed transitions; the place containing three tokens is an output
place for each of the timed transitions. Observe that the leftmost timed
transition is not enabled (because there is a token in the inhibitor input
place) and the other two transitions are both enabled.
Example 1.1 (GI/G/1 queue).
Consider a service center at which jobs
arrive one at a time for processing by a single server. The jobs queue for
service and are served one at a time in arrival order, that is, according to a
ﬁrst-come, ﬁrst-served service discipline. The server is never idle when jobs
are in the system. The times between successive arrivals to the system are

4
1. Introduction
e1 = arrival of job
e2 = completion of service
Figure 1.2. spn representation of GI/G/1 queue.
independent and identically distributed (i.i.d.) as a random variable A, and
successive service times are i.i.d. as a random variable B; interarrival times
are independent of service times. The distributions of the random variables
A and B need not be exponential. This system is usually called a GI/G/1
queue. Here the “GI” stands for “general and independent” interarrival
times, the “G” denotes a “general” service-time distribution, and the “1”
denotes the number of servers.
An spn representation of this system is displayed in Figure 1.2. In this
spn the tokens in place d2 correspond to the jobs in the system, the ﬁring of
timed transition e1 corresponds to the event “arrival of job,” and the ﬁring
of timed transition e2 corresponds to the event “completion of service.”
There is always exactly one token in place d1, so that transition e1 is
always enabled, reﬂecting the fact that the arrival process to the queue is
always active.1 Thus, the marking of the net in Figure 1.2—which we write
as (1, 3)—corresponds to the scenario in which three jobs are in the system;
one job is undergoing service and two jobs are waiting in queue. Transition
e2 is enabled if and only if place d2 contains one or more tokens, reﬂecting
the fact that the server is never idle when jobs are in the system and at
least one job must be in the system for the server to be busy. Whenever
transition e1 = “arrival of job” ﬁres, it deposits a token in place d2; this
token corresponds to the newly arrived job. Moreover, it removes a token
from place d1 and deposits a token in place d1 (so that the token count
remains unchanged). Whenever transition e2 = “completion of service”
ﬁres, it removes a token from place d2; this token corresponds to the job
that has just completed service and left the system. Observe that, for this
particular spn model, tokens are removed and deposited in a deterministic
manner: a transition removes exactly one token from each normal input
place and deposits one token in each output place whenever it ﬁres.
This spn model is appropriate for studying performance characteristics
such as the long-run average queue length or the long-run fraction of time
that the server is busy; see Example 2.2 in the next subsection. Observe that
1Place d1 is unnecessary if we adopt the convention that a transition with no input
places is always enabled.

1.1 Modelling
5
the model can also be used for studying these performance characteristics
under other service disciplines such as random service order or nonpreemp-
tive last-come, ﬁrst-served. This ﬂexibility results because the spn model
does not explicitly keep track of the arrival order of the jobs in the system.
This lack of information leads to complications, however, when studying
delay characteristics such as the long-run fraction of waiting times in the
queue that exceed a speciﬁed value. In Chapter 8 we discuss techniques for
estimating delays in spns such as the one in Figure 1.2.
Heuristically, an spn changes marking in accordance with the ﬁring of
a transition enabled in the current marking (or with the simultaneous ﬁr-
ing of two or more transitions enabled in the current marking). Here the
new marking may coincide with the current marking. The times at which
transitions ﬁre are determined by a stochastic mechanism. Speciﬁcally, a
clock is associated with each transition. The clock reading for an enabled
transition indicates the remaining time until the transition is scheduled to
ﬁre. Clocks run down at marking-dependent speeds, and a marking change
occurs when one or more clocks run down to 0. The transitions enabled in
a marking therefore compete to change the marking: the transitions whose
clocks run down to 0 ﬁrst are the “winners.”
At time 0 the initial marking and clock readings are selected according
to an initial probability distribution. At each subsequent marking change
there are three types of transitions:
1. A new transition is enabled in the new marking and either is not
enabled in the old marking—so that no clock reading is associated
with the transition just before the marking change—or is in the set of
transitions that triggers the marking change—so that the associated
clock reading is 0 just before the marking change. For such a tran-
sition, a new clock reading is generated according to a probability
distribution that depends only on the old marking, the new marking,
and the set of transitions that triggers the marking change.
2. An old transition is enabled in both the old and new markings and
is not in the set of transitions that triggers the marking change. The
clock for such a transition continues to run down (perhaps at a new
speed).
3. A newly disabled transition is enabled in the old marking and disabled
in the new marking. If the transition is not in the set of transitions
that triggers the marking change, then it is “cancelled” and its clock
reading is discarded. Otherwise, the clock associated with the transi-
tion has just run down to 0 and no new clock reading is generated.
As mentioned before, we distinguish between immediate transitions which
always ﬁre the instant they become enabled and timed transitions which

6
1. Introduction
ﬁre only after a positive amount of time elapses. The clock reading gener-
ated for a new immediate transition is always equal to 0 with probability 1,
whereas the clock reading generated for a new timed transition is always
positive with probability 1. If at least one immediate transition is enabled
in a marking—as in Figure 1.1—then the marking is immediate; otherwise,
the marking is timed. An immediate marking vanishes the instant it is
attained.
Example 1.2 (GI/G/1 queue). For the spn model in Figure 1.2, the set of
enabled transitions is { e1 } whenever the marking is (1, 0), that is, when-
ever there are no tokens in place d2 and hence no jobs in the system. Thus,
as expected, the only event that can occur when the system is empty is an
arrival of a job. Whenever the marking is of the form (1, n) with n > 0, the
set of enabled transitions is { e1, e2 }, reﬂecting the fact that either an ar-
rival of a job or a completion of service can occur when one or more jobs are
in the system; for such a marking the clock readings associated with transi-
tions e1 and e2 determine which event occurs ﬁrst. Whenever transition e1
ﬁres, corresponding to an “arrival of job” event, e1 immediately becomes
enabled again, and a new clock reading is generated as an independent sam-
ple from the distribution of the interarrival-time random variable A. The
time at which the clock next runs down to 0—so that transition e1 ﬁres—
corresponds to the next arrival of a job. Similarly, successive clock readings
for transition e2 are generated as mutually independent samples from the
distribution of the service-time random variable B. Transition e2 can be-
come enabled in two diﬀerent ways: (1) when the marking is (1, n) with
n ≥2 and transition e2 ﬁres, and (2) when the marking is (1, 0) and tran-
sition e1 ﬁres. In the former scenario, a job completes service and another
job immediately begins service, so that transition e2—which is enabled in
marking (1, n)—ﬁres and immediately becomes enabled again in the new
marking (1, n −1). In the latter scenario, a job arrives to an empty system
and immediately starts to undergo service, so that transition e2—which is
not enabled in marking (1, 0)—becomes enabled in the new marking (1, 1)
just after transition e1 ﬁres. Observe that whenever the marking is (1, 1)
and transition e2 ﬁres, so that a job completes service and leaves behind
an empty system, transition e2 is not enabled in the new marking (1, 0),
and so a new clock reading is not generated for e2 at this marking change.
Example 1.3 (Alternative model of GI/G/1 queue).
An alternative spn
model of the GI/G/1 queue is given in Figure 1.3. Here we distinguish
between a job undergoing service—represented by a token in place d3—and
jobs waiting in queue—represented by tokens in place d2. Transitions e1 and
e2 have the same interpretation and behavior as in the spn in Figure 1.2.
Transition e3 = “start of service” is immediate, reﬂecting the fact that a
job starts to undergo service at the same instant it is selected for service.
Whenever transition e3 ﬁres, it removes a token from place d2 and deposits

1.1 Modelling
7
e1 = arrival of job
e2 = completion of service
e3 = start of service
Figure 1.3. Alternative spn representation of GI/G/1 queue.
a token in place d3. Suppose, for example, that n ≥2 jobs are in the system
and transition e2 ﬁres, so that the marking changes from (1, n −1, 1) to
(1, n −1, 0). Then transition e3 becomes enabled and ﬁres immediately,
changing the marking to (1, n −2, 1). Similarly, whenever the system is
empty and transition e1 ﬁres, the marking changes from (1, 0, 0) to (1, 1, 0);
transition e3 then becomes enabled and ﬁres immediately, changing the
marking to (1, 0, 1). A marking of the form (1, n, 0) with n > 0 is immediate,
because transition e3 is always enabled in such a marking. Observe that,
due to the inhibitor arc, transition e3 never ﬁres when place d3 contains a
token, reﬂecting the fact that at most one job can undergo service at any
time. Although the spn in Figure 1.3 represents the service mechanism in
greater detail, the spn in Figure 1.2 is more convenient to work with in
practice: the latter spn has fewer places and transitions but can be used to
study any performance characteristic that can be studied using the former
spn.
The timed transitions enabled in the current marking usually correspond
to activities currently underway in the system, and the ﬁring of a timed
transition corresponds to the completion of an activity. spns are thus well
suited to representation of
• Concurrent activities, because more than one transition can be en-
abled in a marking.
• Synchronized activities, because the ﬁring of a transition can cause
one or more transitions to become enabled (or disabled) simultane-
ously.
• Activities with precedence relationships, because a transition cannot
become enabled until at least one token has been deposited in each
of its normal input places and all tokens have been removed from
each of its inhibitor input places. This deposit and removal of tokens
typically occurs when one or more “preceding” transitions ﬁre.
• Priorities among activities, because (1) a normal input place for a
“high-priority” transition can also be an inhibitor input place for a

8
1. Introduction
“low-priority” transition, (2) at a marking change, a token represent-
ing a limited system resource can be “routed” to the normal input
place for a “high-priority” transition, and (3) the clock for a “low-
priority” transition can be made to run down at zero speed whenever
the marking is such that a “high-priority” transition is enabled.
A token residing in a place can represent a system element such as a ma-
chine part on a conveyor or a job waiting in a queue. Alternatively, the
presence or absence of a token in a place can indicate whether or not a log-
ical condition holds. The token count in a place may be 0 or 1, for example,
based on whether or not the number of vehicles on a speciﬁed stretch of
road exceeds a given threshold. spns are conducive to both bottom-up and
top-down modelling. In bottom-up modelling, a detailed subnet is devel-
oped for each component of a system, and then the subnets are combined
to form the overall spn model. In top-down modelling, a preliminary spn
model is developed that captures the main interactions between the com-
ponents of the system without modelling each component in detail. Then
the subnets corresponding to the system components are each progressively
reﬁned until the model is suﬃciently detailed.
The marking process of an spn records the marking as it evolves over
continuous time. Formal deﬁnition of the process is in terms of a general
state-space Markov chain that describes the spn at successive marking
changes. This underlying chain records the marking of the net together
with the clock reading for each transition.
Many spn formalisms have been proposed in the literature. Our partic-
ular choice of spn model is motivated by several considerations:
1. Modelling power: As Chapter 4 shows, the class of spns we con-
sider has the same modelling power as “generalized semi-Markov
processes” (gsmps). This means that a wide variety of discrete-event
systems can be speciﬁed within our spn framework.
2. Simplicity: The spn formalism considered here, while powerful, con-
sists of relatively few building blocks.
3. Generality: Our spn model subsumes a number of models in the lit-
erature. The results in this book apply immediately to these latter
models and often apply to other spn models with minor modiﬁca-
tions.
A problem sometimes encountered when modelling with spns is that the
size of the spn graph can become very large. One approach to this problem
is to allow distinguishable tokens, so that the tokens in a place can convey
more information about the state of the system than the token count alone
imparts. The “colored spns” (cspns) considered in Chapter 9 are one such
extension of the basic spn model.

1.2 Stability and Simulation
9
1.2
Stability and Simulation
Engineers and systems designers are often interested in performance char-
acteristics such as the long-run average operating cost for a ﬂexible man-
ufacturing system, the long-run fraction of time a database is accessible,
or the long-run utilization of a communications link. When the system of
interest is modelled as an spn, each of these characteristics typically can
be speciﬁed as a time-average limit of the form
r(f) = lim
t→∞
1
t
 t
0
f

X(u)

du,
(2.1)
where f is a real-valued function and X(t) denotes the marking of the net
at time t ≥0. Other performance measures of interest can be expressed
as functions of such time-average limits or as (functions of) time-average
limits of the underlying chain used to deﬁne the marking process.
Example 2.2 (GI/G/1 queue).
Consider the spn in Figure 1.2. For a
marking s, write s = (s1, s2), where si (i = 1, 2) is the token count in place
di. Then the long-run average number of jobs in the system is given by
(2.1) with f(s) = f(s1, s2) = s2. The long-run fraction of time that at least
three jobs are in the system is given by (2.1) with
f(s) =

1
if s2 ≥3;
0
otherwise,
(2.3)
and the long-run fraction α of “busy time” (time when the system is
nonempty) that at least three jobs are in the system is given by r(f)/r(g),
where r( · ) is given by (2.1), f is deﬁned as in (2.3), and
g(s) =

1
if s2 ≥1;
0
otherwise.
To see this, observe that
α = lim
t→∞
 t
0 f

X(u)

du
 t
0 g

X(u)

du
= limt→∞(1/t)
 t
0 f

X(u)

du
limt→∞(1/t)
 t
0 g

X(u)

du
= r(f)
r(g) .
For n ≥0, let Sn = (Sn,1, Sn,2) be the marking and Cn = (Cn,1, Cn,2) the
vector of clock readings for transitions e1 and e2 just after the nth marking
change. Also, set
˜r(˜h) = lim
n→∞
1
n
n−1

j=0
˜h(Sj, Cj)
for each real-valued function ˜h deﬁned on the state space of the process
{ (Sn, Cn): n ≥0 }. Then the long-run fraction α of jobs arriving to an

10
1. Introduction
empty system is given by ˜r( ˜f)/˜r(˜g), where
˜f(s, c) = ˜f(s1, s2, c1, c2) =

1
if s2 = 0;
0
otherwise
and
˜g(s, c) = ˜g(s1, s2, c1, c2) =

1
if s2 = 0 or if s2 > 0 and c1 < c2;
0
otherwise.
To see this, observe that ˜g(Sn, Cn) = 1 if and only if e1 is the next transition
to ﬁre, because either e1 is the only transition enabled or both e1 and e2 are
enabled, but the clock for e1 runs down to 0 ﬁrst. That is, ˜g(Sn, Cn) = 1
if and only if the next event to occur is an arrival of a job for processing.
Similarly, ˜f(Sn, Cn) = 1 if and only if the system is empty, so that the
next event to occur is an arrival of a job (to the empty system) for pro-
cessing. Thus the quantity 	n−1
j=0 ˜g(Sj, Cj) counts the number of arrivals to
the system among the ﬁrst n marking changes, and 	n−1
j=0 ˜f(Sj, Cj) is the
number of arrivals to an empty system among the ﬁrst n marking changes.
It follows that
α = lim
n→∞
	n−1
j=0 ˜f(Sj, Cj)
	n−1
j=0 ˜g(Sj, Cj)
=
limn→∞(1/n) 	n−1
j=0 ˜f(Sj, Cj)
limn→∞(1/n) 	n−1
j=0 ˜g(Sj, Cj)
= ˜r( ˜f)
˜r(˜g)
as asserted.
In Section 3.2 we discuss the formal speciﬁcation of performance measures
in more detail.
Under certain restrictions on the building blocks of an spn, the mark-
ing process { X(t): t ≥0 } is a continuous-time Markov chain (ctmc) with
ﬁnite or countably inﬁnite state space; see Section 3.4. A variety of tech-
niques is then available for determining whether the time-average limits of
interest exist and, if so, for computing these limits either analytically or nu-
merically. In general, however, the stochastic process { X(t): t ≥0 } is not
a continuous-time Markov chain or even a semi-Markov process. Determin-
ing the existence of time-average limits then becomes a highly nontrivial
task and the limits, if they exist, must be estimated using computer simu-
lation.2 We focus primarily on problems for which simulation is required,
2Even when the marking process is a ctmc, the chain’s state space may be so large
that simulation is the only practical means of assessing long-run behavior. Similarly,
even when the performance measure of interest can be represented as a time-average
limit of the underlying chain of the marking process—or as a function of such limits—
simulation usually is required because the state space of the underlying chain is too
complex to admit analytical or numerical solution methods.

1.2 Stability and Simulation
11
and our discussion centers around stochastic process properties pertinent
to estimation methods for spns.
The usual reason for estimating time-average limits is to compare alter-
native system designs or operating policies, and real diﬀerences must be
distinguished from apparent diﬀerences caused by random ﬂuctuations. It
is therefore essential to provide not only an estimate of each time-average
limit of interest, but also an assessment of the precision of each estimate.
This assessment frequently takes the form of a conﬁdence interval. In gen-
eral, obtaining point estimates and conﬁdence intervals for time-average
limits is not an easy task, because successive observations of the marking
process are usually far from being either independent or identically dis-
tributed. Indeed, the evolution of the marking process can depend heavily
on the initial conditions of the simulation, even when the simulated time
is large, so that the resulting estimates suﬀer from “initialization bias.” To
obtain meaningful estimates, eﬀective methods are needed for selection of
the number of runs, the length of each run, the initial conditions for each
run, the quantities to be measured, and the form of the ﬁnal estimates.
The estimation problem is simpliﬁed considerably when { X(t): t ≥0 }
is a regenerative process, that is, when there exists an inﬁnite sequence of
random time points (called regeneration points) at which the process prob-
abilistically restarts. The regeneration points decompose sample paths of
the process into i.i.d. “cycles.” Under mild regularity conditions, the regen-
erative property guarantees the existence of time-average limits. Moreover,
the “regenerative method” for analysis of simulation output can be used to
obtain strongly consistent point estimates and asymptotic conﬁdence inter-
vals for time-average limits; the method requires observation of only a ﬁnite
portion of a single sample path of the marking process. It is often apparent
that the marking process of an spn probabilistically restarts whenever the
net is in a speciﬁed marking and a speciﬁed transition ﬁres, but it can be
diﬃcult to verify that such restarts occur inﬁnitely often with probability 1.
It is even harder to determine whether, as the method requires, both the
expected time between regeneration points and the “regenerative variance
constant” are ﬁnite. Establishing these properties often amounts to show-
ing that the underlying chain hits a speciﬁed set of states inﬁnitely often
with probability 1 and that the times between successive hits have ﬁnite
second moment. Thus stability properties such as recurrence are of central
importance to our discussion.
The regenerative method is not applicable when a sequence of regenera-
tion points cannot be found or when regenerations occur too infrequently.
Sometimes, however, strongly consistent point estimates and asymptotic
conﬁdence intervals for time-average limits can be obtained nonetheless,
using methods based on standardized time series (sts). Perhaps the best-
known sts method is the method of batch means (with the number of
batches independent of the simulation run length). A suﬃcient condition
for the validity of sts methods is that the output process

f

X(t)

: t ≥0


12
1. Introduction
obey a functional central limit theorem (fclt). Roughly speaking, a sto-
chastic process with time-average limit r obeys an fclt if the associated
cumulative (i.e., time-integrated) process, centered about the deterministic
function g(t) = rt and suitably compressed in space and time, converges in
distribution to a Brownian motion as the degree of compression increases.
The challenge, then, is to determine from an spn’s building blocks whether
or not such an fclt holds. As in the regenerative setting, this problem can
be reformulated as a stability question for the underlying chain.
It may also be possible to obtain point estimates and conﬁdence intervals
for time-average limits using consistent estimation methods such as vari-
able batch-means (in which the number of batches is an increasing function
of the simulation run length) or spectral methods. These methods assume
that the output process obeys an ordinary central limit theorem (clt) and
are based on consistent estimation of the variance constant that appears
in the clt. When applicable, consistent estimation methods yield conﬁ-
dence intervals that are asymptotically shorter and less variable than those
sts methods provide. As with regenerative and sts methods, determining
if a consistent estimation method is applicable to a speciﬁed spn model
amounts to analyzing the stability of the underlying chain.
The discussion so far has pertained to estimation of performance charac-
teristics that can be expressed in terms of time-average limits of the mark-
ing process or underlying chain, such as long-run utilization, availability,
and reliability. Frequently, however, assessment of delay phenomena also is
of interest. Examples of delays include the time to produce an item in a
ﬂexible manufacturing system, the time to compute the answer to a query
in a database management system, and the time to transmit a message from
one node to another in a communication network. Typically, such delays
correspond to lengths of certain “delay intervals” (random time intervals)
determined by marking changes of an spn, and the performance measures
of interest can be expressed in the form limn→∞(1/n) 	n−1
j=0 f(Dj), where
f is a real-valued function and { Dj : j ≥0 } is a sequence of delays. The
limiting average delay limn→∞(1/n) 	n−1
j=0 Dj can sometimes be estimated
indirectly, that is, without measuring lengths of individual delay intervals.
For general time-average limits of a sequence of delays, however, individual
lengths must be measured and then combined to form point and interval es-
timates. Because there can be more than one ongoing delay at a time point
and delays need not terminate in the order in which they start, measuring
individual lengths is a nontrivial step of the simulation. A mechanism is
needed to link the starts (left endpoints) and terminations (right endpoints)
of individual delay intervals.
When the marking process is regenerative and there are no ongoing de-
lays at any regeneration point, the sequence of delays is a regenerative pro-
cess in discrete time. Strongly consistent point estimates and asymptotic
conﬁdence intervals for time-average limits can therefore be obtained using

1.3 Overview of Topics
13
the regenerative method. When there are ongoing delays at each regener-
ation point, however, extensions of the standard regenerative method are
needed to obtain point estimates and conﬁdence intervals. When there is no
apparent sequence of regeneration points or regenerations occur too infre-
quently, sts methods can be used to obtain point estimates and asymptotic
conﬁdence intervals for time-average limits, provided that the sequence of
delays obeys an fclt. Verifying that such an fclt holds for a speciﬁc spn
model again amounts to establishing stability properties for the underlying
chain.
1.3
Overview of Topics
The remainder of the book is organized as follows. We give a formal descrip-
tion of the spn building blocks in Chapter 2 and, through a set of examples,
illustrate the use of spns as models of discrete-event systems. Methods are
provided for concise speciﬁcation of spn models in which more than one
transition can ﬁre simultaneously.
Chapter 3 focuses on basic properties of the marking process of an spn.
We give a formal deﬁnition of the marking process and show that this deﬁni-
tion leads to an algorithm for generating sample paths. Through examples,
we show that a wide variety of long-run performance measures can be rep-
resented as time-average limits of the marking process. Other performance
measures can be represented as functions of time-average limits, where the
limits are expressed in terms of either the marking process or the underly-
ing chain. In this connection, we discuss some general relationships between
limits in discrete and continuous time. Next, we show that a marking pro-
cess can exhibit pathological behavior in which, with positive probability,
an inﬁnite number of marking changes occur in a ﬁnite time interval. Con-
ditions that rule out such “explosions” are then developed. Finally, we give
conditions under which the marking process is a continuous-time Markov
chain with ﬁnite or countably inﬁnite state space.
Modelling-power issues are explored in Chapter 4. We ﬁrst show that
for every gsmp there exists an spn with a marking process that “strongly
mimics” the gsmp; in this sense, spns have at least the modelling power
of gsmps. This result provides a justiﬁcation for the spn formulation in-
troduced in Chapter 2. Indeed, since the spn building blocks often are
more convenient for modelling than the gsmp building blocks, the forego-
ing result establishes spns as an attractive general framework for modelling
and simulation analysis of discrete-event systems. The methodology used
to obtain the modelling-power result can also be used to assess the rela-
tive modelling power of diﬀerent spn formulations and the contribution of
individual spn building blocks to overall modelling power. For example,
in contrast to a well-known result from the theory of ordinary (untimed,

14
1. Introduction
deterministic) Petri nets, we show that inclusion of inhibitor input places
does not increase the modelling power of spns. We conclude the chapter by
establishing the converse of our main modelling-power result: for every spn
there exists a gsmp that strongly mimics the marking process of the spn.
This result permits direct application to spns of results from the theory of
gsmps. Moreover, when establishing stability properties for spns, the con-
verse result provides a useful tool for dealing with the various complications
caused by the presence of immediate transitions.
In Chapter 5 we provide techniques for showing that speciﬁed subsets of
the state space of the underlying chain are hit inﬁnitely often with prob-
ability 1. Such recurrence arguments are needed to establish, for speciﬁc
spn models, both the existence of time-average limits and the applicability
of various estimation methods. One approach to demonstrating recurrence
is to show that the underlying chain “drifts” toward a speciﬁed compact
subset of the state space whenever the chain lies outside this subset. We
give “positive density” conditions on the clock-setting distributions under
which a drift condition holds. An alternative approach that imposes less
stringent constraints on the clock-setting distributions is based on a “geo-
metric trials” recurrence criterion. This latter approach utilizes the detailed
structure of the spn model as well as properties of “gnbu” distributions.
Chapter 6 deals with estimation methods for spns in which the marking
process or underlying chain is regenerative. After summarizing the relevant
properties of regenerative processes, we give conditions on the building
blocks of an spn under which there exists a sequence of regeneration points
both for the marking process and for the underlying chain. We then show
how this regenerative structure can be used to obtain point estimates and
conﬁdence intervals for time-average limits. In addition to presenting the
basic method, we discuss techniques for reducing the bias of the standard
estimator, obtaining point estimates and conﬁdence intervals for functions
of time-average limits, and estimating gradients of time-average limits with
respect to system parameters. We also describe extensions of the basic
method that permit dependence between adjacent cycles.
Chapter 7 focuses on estimation methods that can be used when the
regenerative method is inapplicable. We ﬁrst consider methods based on
standardized time series. The discussion covers the general theory of stan-
dardized time series, as well as the sts-area, sts-maximum, and batch-
means methods. Based on stability results for general state-space Markov
chains, conditions on the building blocks of an spn are given under which
the output process obeys an fclt, so that sts methods are applicable. We
then give conditions under which various consistent estimation methods
can be applied. The idea is to ﬁrst adapt results from the literature to
obtain such conditions under the (unrealistic) assumption that the output
process of the simulation is stationary. We then use a “coupling” argument
to extend these results to the nonstationary setting usually found in prac-
tice. This development leads to conditions on the building blocks of an spn

1.3 Overview of Topics
15
under which a class of “quadratic-form” estimators are consistent for the
asymptotic variance. Included in this class are estimators for the method
of variable batch means and for various spectral methods.
Chapter 8 concerns delays in spns. We ﬁrst introduce a recursively de-
ﬁned sequence of random vectors, called “start vectors,” whose use provides
a means both for speciﬁcation of a sequence of delays { Dj : j ≥0 } and for
subsequent measurement of the delays during the course of a simulation
run. When there exists a sequence of regeneration points for the underly-
ing chain, the sequence of delays can be decomposed into one-dependent
stationary (o.d.s.) cycles. Various extensions of the standard regenerative
method can then be used to estimate general time-average limits—we com-
pare the statistical eﬃciency of two such extensions. These estimation
methods reduce to the standard regenerative method when there are no
ongoing delays at any regeneration point. If the performance measure of
interest is the limiting average delay, then a specialized estimation method
can be used that does not require measurement of individual delays. When
there is no apparent sequence of regeneration points for the underlying
chain but the clock-setting distributions satisfy positive density conditions
as in Chapter 5, it is still possible to decompose the sequence of delays into
o.d.s. cycles. Although the random indices that decompose sample paths
into such cycles cannot be determined explicitly, the mere existence of these
points implies that, under mild regularity conditions, time-average limits
are well deﬁned and the output process { f(Dj): j ≥0 } obeys an fclt. It
then follows that sts methods such as batch means can be used to obtain
strongly consistent point estimates and asymptotic conﬁdence intervals for
time-average limits.
Chapter 9 introduces colored stochastic Petri nets (cspns). A cspn is
similar to an ordinary spn, except that tokens come in diﬀerent “colors”
and a transition ﬁres “in a color.” An “input incidence function” and an
“output incidence function” determine the transitions enabled in a mark-
ing as well as the number of tokens of each color that are removed and
deposited when a transition ﬁres in a color. The primary appeal of cspns
for modelling of discrete-event systems is that such nets permit concise
speciﬁcation, especially when there are many subsystems of similar struc-
ture or behavior. Virtually all the simulation-based estimation methodology
developed for ordinary spns carries over to the cspn setting. When the net
exhibits “symmetry with respect to color,” modiﬁcations of the standard
regenerative method lead to shorter cycle lengths and—when estimating
delays—to increased statistical eﬃciency.

16
1. Introduction
Notes
Petri nets are named after Carl Adam Petri, who introduced the nets in
his 1962 Ph.D. dissertation. At present, the literature contains over 7000
books, papers, and reports dealing with Petri nets and their extensions.
Petri’s original nets are deterministic and involve no notion of time. Over-
views of the theory of such deterministic Petri nets can be found in the
books of Peterson (1981) and Reisig (1985) and the survey paper of Murata
(1989).
Symons (1978, 1980) proposed the use of transitions with random ﬁring
times together with transitions that take “an insigniﬁcant amount of time
to ﬁre” (that is, immediate transitions). Symons’ work, together with that
of Natkin (1980) and Molloy (1981), resulted in the ﬁrst spn models.
Ajmone Marsan et al. (1984, 1987) develop the “generalized spn” (gspn)
model, a type of spn in which each transition is either immediate or has
exponentially distributed ﬁring times. An introduction to gspns can be
found in Ajmone Marsan et al. (1995).
The spn formulation used in this book follows Haas and Shedler (1985b,
1989b). As indicated in Section 1.1, many of the results in the following
chapters can be adapted to other spn settings, for example, gspns.
In the literature, timed and immediate markings are also referred to
as “tangible” and “vanishing” markings, respectively. The mechanism for
scheduling the ﬁring of transitions is sometimes called the “race model with
enabling memory.”
The stochastic-process viewpoint that is central to our approach can be
traced back to the early work of Crane and Iglehart (1975), Whitt (1980),
and Iglehart and Shedler (1983), among others. A useful, complementary
view of spns and gsmps can be based on the notion of “stochastic timed
automata”—see Cassandras and LaFortune (1999) and Glasserman and
Yao (1994) for examples of this approach.
A number of important topics pertinent to general simulation methodol-
ogy lie outside the scope of our discussion. Such topics include choosing the
level of detail for a simulation model, selecting input probability distribu-
tions, generating random numbers, choosing data structures and algorithms
for generating sample paths, debugging a simulation model, and validating
model output against real-world data. Banks (1998), Bratley et al. (1987),
and Law and Kelton (2000), for example, discuss these aspects of simula-
tion. These references and others also discuss more elaborate versions of
the estimation methods given in this book—we focus on relatively simple
versions of the various methods because their validity can be rigorously
established for speciﬁc spn models.

2
Modelling with Stochastic Petri Nets
Stochastic Petri nets (spns) are well suited to representing concurrency,
synchronization, precedence, and priority. After presenting the basic spn
building blocks in Section 2.1, we give a series of examples in Section 2.2
that illustrates the use of spns for modelling discrete-event systems. We
pay particular attention to complications that arise in the speciﬁcation of
new-marking probabilities. These probabilities determine the mechanism by
which a transition removes tokens from a random subset of its normal input
places and deposits tokens in a random subset of its output places when
it ﬁres. Consideration of a queueing system with batch arrivals shows that
new-marking probabilities must be allowed to depend explicitly on the cur-
rent marking; that is, the spn formalism must include marking-dependent
transitions. By means of an example, we show how new-marking proba-
bilities for an spn with marking-dependent transitions can be speciﬁed in
a form suitable for processing by a computer program. Another compli-
cation arises when more than one transition can ﬁre at a time point. In
principle, new-marking probabilities must be deﬁned for all possible sets
of simultaneously ﬁring transitions, and there can be an extremely large
number of such sets. As shown in Section 2.3, concise speciﬁcation of new-
marking probabilities can be facilitated by assigning numerical “priorities”
to transitions.
2.1
Building Blocks
The basic elements of an spn “graph” are
• A ﬁnite set D = { d1, d2, . . . , dL } of places
• A ﬁnite set E = { e1, e2, . . . , eM } of transitions

18
2. Modelling with Stochastic Petri Nets
• A (possibly empty) set E′ ⊂E of immediate transitions
• Sets I(e), L(e), J(e) ⊆D of normal input places, inhibitor input pla-
ces, and output places, respectively, for each transition e ∈E
The transitions in E −E′ are called timed transitions. Denote by G the
ﬁnite or countably inﬁnite set of markings. For s ∈G we write s =
(s1, s2, . . . , sL), where sj is the number of tokens in place dj ∈D.
Deﬁnition 1.1. An spn is said to be k-bounded (k ≥1) if and only if
max(s1, s2, . . . , sL) ≤k
for each s = (s1, s2, . . . , sL) ∈G.
Thus an spn is k-bounded if and only if the token count in a place never
exceeds k.
Let E(s) be the set of transitions that are enabled when the marking is
s, that is, the set of transitions having at least one token in each normal
input place and no tokens in any inhibitor input place:
E(s) =

e ∈E : sj ≥1 for dj ∈I(e) and sj = 0 for dj ∈L(e)

.
A transition e ∈E −E(s) is disabled when the marking is s. In a dual
manner, set
G(e) = { s ∈G: e ∈E(s) }
for e ∈E, so that G(e) is the set of markings in which transition e is
enabled. Deﬁne the set S′ of immediate markings by
S′ = { s ∈G: E(s) ∩E′ ̸= ∅}
and the set S of timed markings by
S = G −S′ = { s ∈G: E(s) ∩E′ = ∅} .
According to this deﬁnition, an element of the marking set is an immediate
marking if at least one immediate transition is enabled. Heuristically, an
immediate marking vanishes the instant it is attained.
Example 1.2 (GI/G/1 queue).
For the spn in Figure 1.3—see Exam-
ple 1.3 in Chapter 1—we have D = { d1, d2, d3 }, E = { e1, e2, e3 }, and
E′ = { e3 }. The spn graph is formally described by setting
• I(e1) = { d1 }, I(e2) = { d3 }, I(e3) = { d2 }.
• J(e1) = { d1, d2 }, J(e2) = ∅, J(e3) = { d3 }.
• L(e1) = L(e2) = ∅, L(e3) = { d3 }.

2.1 Building Blocks
19
The set of markings is G = { 1 } × { 0, 1, 2, . . . } × { 0, 1 } (where × denotes
Cartesian product), and the set of immediate markings is
S′ = { (s1, s2, s3) ∈G: s2 > 0 and s3 = 0 } .
The sets of enabled transitions are given by
• E

(1, 0, 0)

= { e1 }.
• E

(1, n, 1)

= { e1, e2 } for n ≥0.
• E

(1, n, 0)

= { e1, e3 } for n ≥1.
Similarly, G(e1) = G, G(e2) = { 1 } × { 0, 1, 2, . . . } × { 1 }, and G(e3) =
{ 1 } × { 1, 2, . . . } × { 0 }.
The marking of an spn changes when one or more enabled transitions ﬁre.
For E∗⊆E(s), denote by p(s′; s, E∗) the probability that the new marking
is s′ given that the marking is s and the transitions in the set E∗ﬁre
simultaneously. For each s ∈G and E∗⊆E(s), the function p( · ; s, E∗) is
a probability mass function on G in that 	
s′∈G p(s′, s, E∗) = 1. Recall that
a transition removes at most one token from each of its normal input places
and deposits at most one token in each of its output places when it ﬁres.
We therefore permit p(s′; s, E∗) to be positive only if s = (s1, s2, . . . , sL),
s′ = (s′
1, s′
2, . . . , s′
L), and E∗satisfy
sj −

e∗∈E∗
1I(e∗)(dj) ≤s′
j ≤sj +

e∗∈E∗
1J(e∗)(dj)
(1.3)
for 1 ≤j ≤L. Here 1A denotes the indicator function of the set A, so that
the quantity 	
e∗∈E∗1I(e∗)(dj) is the number of transitions e∗∈E∗for
which dj is a normal input place and 	
e∗∈E∗1J(e∗)(dj) is the number of
transitions e∗∈E∗for which dj is an output place. Observe that the token
count of a place may increase or decrease by more than 1 when transitions
ﬁre simultaneously.
Example 1.4 (Cyclic queues with feedback). Consider a closed network
of queues with two single-server service centers and N (≥2) jobs; see
Figure 2.1. With ﬁxed probability p ∈(0, 1), a job that completes service
at center 1 moves to center 2 and with probability 1−p joins the tail of the
queue at center 1. A job that completes service at center 2 moves to center 1.
The queueing discipline at each center is ﬁrst-come, ﬁrst-served. Successive
service times at center i (i = 1, 2) are i.i.d. as a random variable Li having a
continuous distribution function. Observe that, with probability 1, a service
completion at center 1 and a service completion at center 2 never occur
simultaneously.
An spn model of this system is displayed in Figure 2.2. The tokens in
place di (i = 1, 2) correspond to the jobs at center i (either waiting or

20
2. Modelling with Stochastic Petri Nets
Figure 2.1. Cyclic queues with feedback (ﬁve jobs).
e1 = service completion at center 1
e2 = service completion at center 2
Figure 2.2. spn representation of cyclic queues with feedback.
in service). Whenever transition e2 ﬁres, it removes a token from place
d2 and deposits a token in place d1, reﬂecting the fact that a job that
completes service at center 2 moves to center 1. Whenever transition e1
ﬁres, it removes a token from place d1; moreover, it deposits a token in place
d2 with probability p and in place d1 with probability 1 −p. Equivalently,
with probability p, transition e1 removes a token from place d1 and deposits
a token in place d2 and, with probability 1 −p, removes and deposits no
tokens when it ﬁres. In this manner the spn model captures the feedback
mechanism in the network of queues. Formally, we have
p(s; s, {e1}) = 1 −p,
p

(s1 −1, s2 + 1); s, {e1}

= p,
p

(s1 + 1, s2 −1); s, {e2}

= 1
for s = (s1, s2) ∈G.
Now suppose that transitions e1 and e2 can ﬁre simultaneously. This
situation can arise, for example, if each service-time random variable Li
takes values in the set { 1, 2, 3, . . . }. Whenever e1 and e2 ﬁre simultaneously,
the spn changes marking as if one of the transitions ﬁres immediately after
the other (the order of the ﬁrings is immaterial). That is,
p

(s1 + 1, s2 −1); s, {e1, e2}

= 1 −p,
p(s; s, {e1, e2}) = p
for s = (s1, s2) ∈S.

2.1 Building Blocks
21
Often in applications the stochastic mechanism for removing and de-
positing tokens is degenerate and does not explicitly depend on the current
marking.
Deﬁnition 1.5. A transition e ∈E is said to be deterministic if and only
if, for all s = (s1, s2, . . . , sL) ∈G(e), we have p(s′; s, {e}) = 1, where s′ is
determined from s according to the relations
s′
j =





sj −1
if dj ∈I(e) ∩

D −J(e)

;
sj + 1
if dj ∈J(e) ∩

D −I(e)

;
sj
otherwise
for 1 ≤j ≤L.
Thus a transition e is deterministic if, with probability 1, it removes ex-
actly one token from each normal input place and deposits exactly one
token in each output place whenever it ﬁres (and no other transitions ﬁre
simultaneously).
Example 1.6 (Deterministic transitions).
For both the spn in Figure 1.2
and the spn in Figure 1.3, all transitions are deterministic. For the spn in
Figure 2.2, transition e2 is deterministic but transition e1 is not.
A clock is associated with each transition. The clock for an enabled tran-
sition records the remaining time until the transition is scheduled to ﬁre.
These clocks, along with the speeds at which the clocks run down, deter-
mine which of the enabled transitions trigger the next marking change.
Denote by r(s, e) (≥0) the speed (ﬁnite, deterministic rate) at which the
clock associated with transition e runs down when the marking is s ∈G(e).
The requirement that r(s, e) be ﬁnite is needed to ensure that timed tran-
sitions never ﬁre instantaneously. We require that r(s, e) = 1 for e ∈E′
and s ∈G(e). In particular, this means that zero speeds are not allowed
for immediate transitions; such transitions always ﬁre the instant they be-
come enabled. Typically in applications, all speeds for enabled transitions
are equal to 1. There exist models, however, in which speeds other than 1
as well as state-dependent speeds are convenient. For example, zero speeds
are needed for speciﬁcation of queueing systems with service interruptions
of the “preemptive-resume” type—see Example 2.3 in the following sec-
tion. State-dependent speeds are needed for queueing systems in which the
service eﬀort is divided among the jobs receiving service (the “processor
sharing” service discipline).
To avoid trivialities, we always assume without comment that
1. For each marking s ∈G, there exists a transition e ∈E(s) with
r(s, e) > 0.
2. For each transition e ∈E, there exists a marking s ∈G(e) with
r(s, e) > 0.

22
2. Modelling with Stochastic Petri Nets
Figure 2.3. Sets of new, old, and newly disabled transitions.
The assumption in (2) implies that L(e) ∩I(e) = ∅for e ∈E, so that no
place can be both a normal input place and an inhibitor input place for a
transition.
The initial marking s0 is selected according to an initial-marking dis-
tribution ν0 deﬁned on G. Then, for each enabled transition ei ∈E(s0),
an initial clock reading is generated according to an initial clock-setting
distribution function F0( · ; ei, s0). The distribution function ν0 may be de-
generate in the sense that ν0(s) = 1 for some s ∈G.
At a subsequent marking change from s to s′ triggered by the simultane-
ous ﬁring of the transitions in the set E∗, a ﬁnite clock reading is generated
for each new transition e′ ∈N(s′; s, E∗) = E(s′) −

E(s) −E∗
. Denote
the clock-setting distribution function—that is, the distribution function of
such a new clock reading—by F( · ; s′, e′, s, E∗). For e′ ∈E′, we require that
F(0; s′, e′, s, E∗) = 1 for s, s′, and E∗, so that immediate transitions always
ﬁre instantaneously. For e′ ∈E −E′, we require that F(0; s′, e′, s, E∗) = 0
for s, s′, and E∗, so that timed transitions never ﬁre instantaneously. For
each old transition e′ ∈O(s′; s, E∗) = E(s′) ∩

E(s) −E∗
, the old clock
reading is kept after the marking change. A transition in the set E(s)−E(s′)
is called a newly disabled transition, and we distinguish between two types
of newly disabled transitions.
1. For e′ ∈

E(s) −E(s′)

−E∗, transition e′ (which was enabled be-
fore the transitions in E∗ﬁred) is cancelled and the clock reading is
discarded.

2.1 Building Blocks
23
2. For e′ ∈

E(s) −E(s′)

∩E∗, the clock for transition e′ has run
down to 0 just before the marking change and no new clock reading
is generated.
Figure 2.3 illustrates these deﬁnitions.
When the marking is s and the set E∗of transitions that trigger a
marking change is a singleton set of the form E∗= { e∗}, we often write
p(s′; s, e∗) for p(s′; s, {e∗}), O(s′; s, e∗) for O(s′; e, {e∗}), and so forth.
Example 1.7 (GI/G/1 queue). For the spn in Figure 1.2, all speeds are
equal to 1. The clock-setting distribution functions are given by
F(x; s′, e1, s, E∗) ≡F(x; e1) = P { A ≤X }
and
F(x; s′, e2, s, E∗) ≡F(x; e2) = P { B ≤X } ,
where A and B are the interarrival-time and service-time random variables.
Observe that whenever a job arrives, the next arrival event is scheduled
immediately, so that e1 is always a new transition at a marking change
triggered by the ﬁring of e1. If place d2 contains no tokens just before
such a marking change—so that the job arrives to an empty system—
then the arriving job immediately goes into service and a “completion of
service” event is scheduled. That is, e2 is also a new transition at such a
marking change. Otherwise, if place d2 contains one or more tokens, then a
“completion of service” event has previously been scheduled, so that e2 is
an old transition rather than a new transition. Thus, for s = (s1, s2) ∈G,
N(s′; s, e1) =

{ e1, e2 }
if s2 = 0;
{ e1 }
if s2 > 0.
Similarly,
N(s′; s, e2) =

∅
if s2 = 1;
{ e2 }
if s2 > 1,
O(s′; s, e1) =

∅
if s2 = 0;
{ e2 }
if s2 > 0,
and
O(s′; s, e2) = { e1 } .
In each of these equations, s′ denotes the unique new marking when the
current marking is s and the speciﬁed transition ﬁres. Suppose that at time
0 a job arrives to an empty system. Then the initial-marking distribution
is
ν0(s) =

1
if s = (1, 1);
0
otherwise

24
2. Modelling with Stochastic Petri Nets
or, equivalently, ν0(s) = 1{(1,1)}(s). For the initial marking s0 = (1, 1),
we have E(s0) = { e1, e2 }; the initial clock-setting distribution functions
for transitions e1 and e2 are given by F(x; e1) and F(x; e2) as deﬁned
previously.
Observe that for each of transitions e1 and e2 in Example 1.7, the clock-
setting distribution function does not explicitly depend on the new mark-
ing, old marking, or set of transitions that trigger the marking change.
Such transitions frequently occur in practice and motivate the following
deﬁnition.
Deﬁnition 1.8. A timed transition e′ is said to be simple if there exists a
distribution function F( · ; e′) such that
F( · ; s′, e′, s, E∗) ≡F( · ; e′)
and
F0( · ; e′, s) ≡F( · ; e′)
for all s′, s, and E∗.
2.2
Illustrative Examples
The examples in this section illustrate the speciﬁcation of discrete-event
systems using the spn building blocks. These examples demonstrate various
modelling techniques and also highlight some important modelling issues.
2.2.1
Priorities: Producer–Consumer Systems
The activities in a system usually require various system resources. To
process a part in an automated manufacturing system, for example, a suit-
able machine is needed. To transmit a voice conversation over a telephone
system, a set of communication links must be available. When a resource
is scarce, competition among activities for use of the resource usually is
resolved by assigning relative priorities to the activities. The following ex-
amples show how immediate transitions, inhibitor input places, and zero
speeds can be used to model a variety of preemptive and nonpreemptive
priority schemes.
Example 2.1 (Producer–consumer system with nonpreemptive priority).
Consider a system consisting of two producers, two consumers, and two
buﬀers, each numbered 1 and 2. The producers share a single channel for
transmission (one at a time) of items to consumers. Producer i (i = 1, 2)
creates items for consumer i one at a time; items created but not yet trans-
mitted are placed in buﬀer i for transmission. Buﬀer i has ﬁnite capacity

2.2 Illustrative Examples
25
e1 = creation of item by producer 1
e2 = start of transmission to consumer 1
e3 = end of transmission to consumer 1
e4 = creation of item by producer 2
e5 = start of transmission to consumer 2
e6 = end of transmission to consumer 2
Figure 2.4. spn representation of producer–consumer system with nonpreemptive
priority and ﬁnite buﬀers.
Bi > 0; that is, an item created by producer i when the system already
contains Bi −1 items for consumer i causes the process of creation of items
for consumer i to shut down. This process remains shut down until the ﬁrst
subsequent end of transmission to consumer i. Producer–consumer pair 1
has nonpreemptive priority over producer–consumer pair 2 for use of the
channel. Items created by producer i are transmitted in the order in which
they are created. The successive times required by producer i to create an
item are i.i.d. as a positive random variable Ai with continuous distribution
function, and the successive times to transmit an item to consumer i are
i.i.d. as a positive random variable Li with continuous distribution function.
(All creation times and transmission times are mutually independent.)
This system can be speciﬁed as an spn with deterministic timed and
immediate transitions; see Figure 2.4 for B1 = 4 and B2 = 3. Let D =
{ d1, d2, . . . , d7 } be the set of places of the spn, E = { e1, e2, . . . , e6 } be
the set of transitions, and E′ = { e2, e5 } be the set of immediate transitions.

26
2. Modelling with Stochastic Petri Nets
Set
L(e5) = { d2 }
and L(ej) = ∅otherwise. Also set
I(e2) = { d2, d7 } ,
I(e5) = { d5, d7 } ,
and I(ej) = { dj } otherwise. Finally, set
J(e3) = { d1, d7 } ,
J(e6) = { d4, d7 } ,
and J(ej) = { dj+1 } otherwise.
The interpretation of the transitions is given in Figure 2.4, and the in-
terpretation of the places is as follows. Place d1 contains at least one token
if and only if producer 1 is creating an item. Place d3 contains one token if
and only if transmission of an item to consumer 1 is underway; otherwise,
place d3 contains no tokens. Similarly, there is at least one token in place
d4 if and only if producer 2 is creating an item and one token in place d6
if and only if transmission of an item to consumer 2 is underway. Place
d2 (resp., place d5) contains k (≥0) tokens if and only if k items are in
buﬀer 1 (resp., buﬀer 2) awaiting transmission. Place d7 contains one token
if and only if no transmission is underway; otherwise, place d7 contains no
tokens. Thus, in Figure 2.4 producer 1 is creating an item, a transmission
of an item to consumer 1 is underway, two items are awaiting transmission
to consumer 1, and three items are awaiting transmission to consumer 2.
The marking set G is the set of all elements (s1, s2, . . . , s7) ∈{ 0, 1, . . . ,
B1 }2 × { 0, 1 } × { 0, 1, . . . , B2 }2 × { 0, 1 }2 such that
1. s3 + s6 + s7 = 1.
2. s1 + s2 + s3 = B1.
3. s4 + s5 + s6 = B2.
The ﬁrst constraint reﬂects the fact that, at any time point, a transmis-
sion to consumer 1 is underway, a transmission to consumer 2 is underway,
or the channel is idle. Thus the token that resides in place d3, d6, or d7
represents the limited, shared channel resource. The second and third con-
straints reﬂect the fact that an item for consumer 1 (resp., consumer 2) is
either “waiting to be produced,” waiting to be transmitted, or undergoing
transmission. The immediate marking set S′ is given by
S′ =

(s1, s2, s3, s4, s5, s6, s7) ∈G: s7 = 1 and s2 + s5 > 0

.
It can be shown that |G| = 3B1B2+2B1+2B2+1, |S| = 2B1B2+B1+B2+1,
and |S′| = B1B2 + B1 + B2. (Here, as elsewhere, |A| denotes the number
of elements in the set A.)

2.2 Illustrative Examples
27
The new-marking probabilities are as follows. If e∗= e1 = “creation
of item by producer 1,” then the new-marking probability p(s′; s, e∗) = 1
when
s = (s1, s2, s3, s4, s5, s6, s7) and s′ = (s1 −1, s2 + 1, s3, s4, s5, s6, s7).
If e∗= e2 = “start of transmission to consumer 1,” then p(s′; s, e∗) = 1
when
s = (s1, s2, 0, s4, s5, 0, 1) and s′ = (s1, s2 −1, 1, s4, s5, 0, 0).
If e∗= e3 = “end of transmission to consumer 1,” then p(s′; s, e∗) = 1
when
s = (s1, s2, 1, s4, s5, 0, 0) and s′ = (s1 + 1, s2, 0, s4, s5, 0, 1).
If e∗= e4 = “creation of item by producer 2,” then p(s′; s, e∗) = 1 when
s = (s1, s2, s3, s4, s5, s6, s7) and s′ = (s1, s2, s3, s4 −1, s5 + 1, s6, s7).
If e∗= e5 = “start of transmission to consumer 2,” then p(s′; s, e∗) = 1
when
s = (B1, 0, 0, s4, s5, 0, 1) and s′ = (B1, 0, 0, s4, s5 −1, 1, 0).
If e∗= e6 = “end of transmission to consumer 2,” then p(s′; s, e∗) = 1
when
s = (s1, s2, 0, s4, s5, 1, 0) and s′ = (s1, s2, 0, s4 + 1, s5, 0, 1).
All other new-marking probabilities of the form p(s′; s, e∗) are equal to 0.
It can be seen from the above speciﬁcation that each transition e ∈E is
deterministic. Observe that transitions never ﬁre simultaneously because
the random variables A1, A2, L1, and L2 have continuous distribution
functions. Thus, new-marking probabilities of the form p(s′; s, E∗) with
|E∗| > 1 can be speciﬁed arbitrarily; in practice, this means that such
probabilities need not be speciﬁed at all.
The clock-setting distribution functions for timed transitions e1, e3, e4,
and e6 are F(x; s′, e1, s, e) = P { A1 ≤x }, F(x; s′, e4, s, e) = P { A2 ≤x },
F(x; s′, e3, s, e) = P { L1 ≤x }, and F(x; s′, e6, s, e) = P { L2 ≤x }, respec-
tively—observe that each of these transitions is simple. All speeds for en-
abled transitions are equal to 1.
The sequence of marking changes illustrated in Figure 2.5 shows how
the spn model captures the nonpreemptive priority of producer–consumer
pair 1 over producer–consumer pair 2 for use of the channel. When tran-
sition e3 = “end of transmission to consumer 1” ﬁres, it deposits a token
in place d7, indicating that the channel is available for transmission of an

28
2. Modelling with Stochastic Petri Nets
Figure 2.5. Marking changes for spn representation of producer–consumer system
with nonpreemptive priority and ﬁnite buﬀers.

2.2 Illustrative Examples
29
e1 = creation of item by producer 1
e2 = end of transmission to consumer 1
e3 = creation of item by producer 2
e4 = end of transmission to consumer 2
Figure 2.6. spn representation of producer–consumer system with preemp-
tive-repeat priority and ﬁnite buﬀers.
item. As shown in the ﬁgure, there are items awaiting transmission to con-
sumer 1 and items awaiting transmission to consumer 2; these items are
represented by the tokens in places d2 and d5, respectively. The presence of
tokens in place d2 causes immediate transition e2 = “start of transmission
to consumer 1” to ﬁre while simultaneously inhibiting the ﬁring of immedi-
ate transition e5 = “start of transmission to consumer 2.” When transition
e2 ﬁres, it deposits a token in place d3, causing transition e3 to become
enabled, and there is a start of transmission to consumer 1. Transition e2
also removes a token from place d7, indicating that the channel is now in
use.
Example 2.2 (Producer–consumer system with preemptive-repeat prior-
ity). Consider a producer–consumer system as in Example 2.1, but sup-
pose that producer–consumer pair 1 has preemptive-repeat priority over
producer–consumer pair 2. That is, whenever a transmission to consumer 2
is underway and producer 1 creates an item, the transmission to consumer 2
stops immediately and there is a start of transmission to consumer 1. The
next time the channel becomes available to producer–consumer pair 2,
the previously interrupted transmission to consumer 2 starts again from
scratch. Figure 2.6 displays an spn representation of this system. All tran-
sitions are deterministic and all speeds are equal to 1. The clock-setting
distribution functions for timed transitions e1, e2, e3, and e4 are given by

30
2. Modelling with Stochastic Petri Nets
F(x; s′, e1, s, e) = P { A1 ≤x }, F(x; s′, e3, s, e) = P { A2 ≤x }, F(x; s′, e2,
s, e) = P { L1 ≤x }, and F(x; s′, e4, s, e) = P { L2 ≤x }, respectively. The
preemptive-repeat priority of producer–consumer pair 1 over producer–
consumer pair 2 is modelled by making d2 an inhibitor input place for
transition e4. The idea is that the ﬁring of transition e1 = “creation of item
by producer 1” when transition e4 = “end of transmission to consumer 2”
is enabled and no tokens are in place d2 causes a token to be deposited
in place d2, transition e4 to become disabled, and the clock reading for
transition e4 to be discarded. When transition e4 next becomes enabled,
a new clock reading is generated, reﬂecting the fact that transmission to
consumer 2 starts from scratch.
In Example 2.2 observe that whenever a transmission of an item to con-
sumer 2 is preempted and subsequently repeated, a new clock reading is
generated for transition e4 = “end of transmission to consumer 2.” That
is, the duration of the repeated transmission is statistically independent of
the original transmission time. This type of preemption is sometimes called
preempt-repeat new (prn). If, for example, all items are of the same size
and the random variations in transmission times are caused by random
delays in the transmission process, then the preemption mechanism can
reasonably be modelled as prn. Suppose, however, that the transmission
process is deterministic and the random variations in transmission times
are caused by random variations in the sizes of the items. Then, for a
given item, the duration of the repeated transmission should be the same
as the original transmission time. This latter type of preemption is called
preempt-repeat identical (pri). Although activities subject to pri preemp-
tion cannot be modelled exactly within our spn framework, they can be
modelled approximately—see Example 2.8 in the next subsection.
Example 2.3 (Producer–consumer system with preemptive-resume prior-
ity). Consider a producer–consumer system as in Example 2.1, but sup-
pose that producer–consumer pair 1 has preemptive-resume priority over
producer–consumer pair 2. That is, as in Example 2.2, creation of an item
by producer 1 when a transmission to consumer 2 is underway always re-
sults in an interruption of the transmission. The next time the channel
becomes available to producer–consumer pair 2, however, the transmission
to consumer 2 resumes from the point at which it was interrupted. Fig-
ure 2.7 displays an spn representation of this system. All transitions are
deterministic and the clock-setting distributions are as in Example 2.2.
Zero speeds are used to model preemptive-resume behavior as follows. For
s = (s1, s2, s3, s4) ∈G(e4), set r(s, e4) = 1 if s2 = 0 and r(s, e4) = 0 oth-
erwise. All other speeds are equal to 1. Thus the ﬁring of transition e1 =
“creation of item by producer 1” when transition e4 = “end of transmis-
sion to consumer 2” is enabled causes the clock for transition e4 to stop
running down. The clock resumes running down when the token count in

2.2 Illustrative Examples
31
e1 = creation of item by producer 1
e2 = end of transmission to consumer 1
e3 = creation of item by producer 2
e4 = end of transmission to consumer 2
Figure 2.7. spn representation of producer–consumer system with preemp-
tive-resume priority and ﬁnite buﬀers.
place d2 next becomes 0, that is, when the channel next becomes available
to producer–consumer pair 2.
2.2.2
Marking-dependent Transitions
When a deterministic transition ﬁres, the number of tokens it removes from
each normal input place and deposits in each output place does not explic-
itly depend on the current marking. In general, however, transitions may
exhibit “marking dependence.” The following example shows that marking-
dependent transitions are needed to model certain discrete-event systems.
Example 2.4 (Queue with batch arrivals). Consider a queueing system
consisting of one single-server center. Jobs arrive at the center in batches
and are served one at a time. Whenever there is a completion of service and
the queue is not empty, the server immediately starts a new service; the job
to receive service is selected randomly and uniformly among the jobs wait-
ing in queue. Successive batch sizes are i.i.d. as a discrete random variable
B, successive service times are i.i.d. as a random variable L with continu-
ous distribution function, and successive interarrival times between batches
are i.i.d. as a random variable A with continuous distribution function. We
assume that, for i ≥1,
bi
def
= P { B = i } > 0.

32
2. Modelling with Stochastic Petri Nets
e1 = arrival of batch
e3 = entry into queue of job in batch
e4 = completion of service
Figure 2.8. spn representation of queue with batch arrivals.
This system can be speciﬁed as an spn with timed and immediate tran-
sitions and a countably inﬁnite marking set; see Figure 2.8. Place d1 always
contains exactly one token, reﬂecting the fact that the arrival process of
batches to the queue is always active. Place d4 contains k (≥0) tokens if
and only if there are k jobs at center 1 either waiting in queue or receiving
service. Transitions e1, e3, and e4 are deterministic. Places d2 and d3 are
used in conjunction with marking-dependent transition e2 to “generate”
the random size of each batch upon arrival.
The idea is that whenever transition e1 = “arrival of batch” ﬁres, it de-
posits a token in place d2 and immediate transition e2 becomes enabled.
Transition e2 then ﬁres a random number of times in succession before
becoming disabled, depositing a token in place d3 each time it ﬁres. The
probability that e2 ﬁres exactly i times—so that exactly i tokens are de-
posited in place d3—is equal to bi for i ≥1. When transition e2 ﬁres for the
last time and becomes disabled, leaving a total of, say, k tokens in place d3,
it removes the token in place d2 and (deterministic) transition e3 becomes
enabled. Transition e3 then ﬁres precisely k times in succession, removing
all k tokens from place d3 and depositing k tokens in place d4. Thus, when-
ever transition e1 ﬁres, the net eﬀect is to deposit a random number of
tokens in place d4; the distribution of the number of tokens deposited is
the same as the distribution of the random variable B.
The foregoing marking-dependent ﬁring mechanism for transition e2 is
speciﬁed as follows. Whenever place d3 contains k (≥0) tokens and tran-
sition e2 ﬁres, a token is deposited in place d3. With probability
pk =
bk+1
	∞
i=k+1 bi
=
bk+1
1 −	k
i=1 bi
,
(2.5)
a token also is removed from place d2, and transition e2 becomes disabled;
with probability 1−pk, a token is not removed from place d2, and transition

2.2 Illustrative Examples
33
e2 remains enabled. Formally, p(s′; s, e2) = pk when
s = (1, 1, k, m)
with k, m ≥0
and s′ = (1, 0, k + 1, m)
and p(s′; s, e2) = 1 −pk when
s = (1, 1, k, m)
with k, m ≥0
and s′ = (1, 1, k + 1, m);
otherwise, p(s′; s, e2) = 0. Observe that pk is simply the conditional prob-
ability that B = k + 1, given that B ≥k + 1. A simple calculation shows
that, for k ≥1, the probability that transition e2 ﬁres exactly k times
before becoming disabled is equal to bk.
It does not appear possible to model the queue with batch arrivals with-
out use of marking-dependent transitions.1 The following two examples
show that even when marking-dependent transitions are not needed, they
can reduce the complexity of the spn graph and the size of the marking
set. The examples also highlight the fact that the spn representation of a
discrete-event system need not be unique.
Example 2.6 (Token ring). Local area decentralized computer networks
are usually conﬁgured in a ring or bus topology. Consider a unidirectional
ring network having a ﬁxed number of ports, labelled 1, 2, . . . , N in the
direction of signal propagation. At each port, message packets arrive ac-
cording to a random process. A distinguished bit pattern, called a ring
token, circulates around the ring from one port to the next. The time for
the ring token to propagate from port j to the next port is a positive con-
stant Rj. When a port observes the ring token and has a packet queued for
transmission, the port converts the ring token to another distinguished bit
pattern called a connector and transmits the packet followed by the ring to-
ken; the ring token continues to propagate if the port has no packet queued
for transmission. Conceptually, the port “removes the token” from the ring
at the start of a transmission, “holds the token” while the transmission is
1Some spn variants associate a “multiplicity” with each arc between a place and a
transition. The ﬁring mechanism for a transition with N normal input places and M
output places is as follows. Denote by ni the multiplicity associated with the arc from
the ith normal input place to the transition (1 ≤i ≤N) and by mj the multiplicity
associated with the arc from the transition to the jth output place (1 ≤j ≤M). Then
the transition is enabled only if, for 1 ≤i ≤N, the ith normal input place contains ni
tokens; whenever such a transition ﬁres, it removes ni tokens from the ith normal input
place and deposits mj tokens in the jth output place. It can be shown that the use of
arc multiplicities does not increase the modelling power of the basic spn formalism, so
that this device is not suﬃcient to permit modelling of the queue with batch arrivals if
the batch size is unbounded.

34
2. Modelling with Stochastic Petri Nets
Figure 2.9. Token ring.
underway, and “releases the token” back onto the ring at the end of the
transmission. By destroying the connector preﬁx the port “removes” the
transmitted packet when it returns around the ring; see Figure 2.9. In the
ﬁgure, i, j, and k denote three of the N ports; T denotes the ring token;
C denotes a connector; and P1, P2, and P3 denote packets.
For simplicity, assume that at most one packet is awaiting transmission
at any time at any particular port; the successive times from end of trans-
mission by port j until the arrival of the next packet for transmission by
port j are i.i.d. as a positive random variable Aj with continuous distri-
bution function. Moreover, the successive times for port j to transmit a
packet are i.i.d. as a positive random variable Lj with continuous distribu-
tion function.
This system can be speciﬁed as an spn with marking-dependent transi-
tions; see Figure 2.10 for N = 2. The set of places of the spn is
D = { d1,1, d2,1, d3,1, d4,1, . . . , d1,N, d2,N, d3,N, d4,N } ,
and the set of transitions is
E = { e1,1, e2,1, e3,1, . . . , e1,N, e2,N, e3,N } .
All transitions are timed. (For clarity of exposition, we use double sub-
scripts to index places, transitions, and token counts.)
Place d1,j contains one token if and only if port j either is transmitting
a packet or has a packet queued for transmission. Place d2,j contains one
token if and only if port j is not transmitting a packet and has no packet

2.2 Illustrative Examples
35
e1,j = arrival of packet for transmission by port j
e2,j = end of transmission by port j
e3,j = observation of ring token by port j
Figure 2.10. spn representation of token ring (two ports).
queued for transmission. Place d3,j contains one token if and only if port j
is transmitting a packet, and place d4,j contains one token if and only if
the ring token is propagating from port j to the next port. Otherwise, a
place contains no tokens.
The marking set G (= S) is
G =

(s1,1, s2,1, . . . , s4,N) ∈{ 0, 1 }4N : s1,j + s2,j = 1 and
s2,js3,j = 0 for 1 ≤j ≤N; s3,1 + s4,1 + · · · + s3,N + s4,N = 1

.
It follows that |G| = 3N2N−1. In any marking there are exactly N + 1
tokens, and each place contains at most one token. Each of the disjoint
sets of places { d1,j, d2,j } contains exactly one token indicating whether
or not port j has a packet queued for transmission. The set of places

d3,1, d4,1, d3,2, d4,2, . . . , d3,N, d4,N

contains exactly one token indicating
the position and status of the ring token. There can never be tokens at
places d2,j and d3,j simultaneously, reﬂecting the fact that there can be
no arrival of a packet for transmission by port j during a transmission by
port j.
Transitions e1,j and e2,j are deterministic for 1 ≤j ≤N. Whenever
transition e3,j = “observation of ring token by port j” ﬁres, it removes a
token from place d4,j−1 and deposits a token either in place d3,j or in place

36
2. Modelling with Stochastic Petri Nets
d4,j, depending on whether (s1,j, s2,j) equals (1, 0) or (0, 1), respectively.
Thus, when the ring token arrives at port j, either port j starts transmission
or the ring token starts to propagate to the next port, depending on whether
port j has a packet queued for transmission. Formally, p(s′; s, e3,j) = 1
when
s = (s1,1 . . . , s3,j−1, 1, 1, 0, 0, 0, s1,j+1, . . . , s4,N)
and s′ = (s1,1, . . . , s3,j−1, 0, 1, 0, 1, 0, s1,j+1, . . . , s4,N),
and when
s = (s1,1, . . . , s3,j−1, 1, 0, 1, 0, 0, s1,j+1, . . . , s4,N)
and s′ = (s1,1, . . . , s3,j−1, 0, 0, 1, 0, 1, s1,j+1, . . . , s4,N).
All other new-marking probabilities p(s′; s, e3,j) are equal to 0. (In the
above speciﬁcation, a reference to port index j −1 is interpreted as a
reference to port index N when j = 1, and a reference to port index j + 1
is interpreted as a reference to port index 1 when j = N.)
The clock-setting distribution functions are given by F(x; s′, e1,j, s, e∗) =
P { Aj ≤x }, F(x; s′, e2,j, s, e∗) = P { Lj ≤x }, and F(x; s′, e3,j, s, e∗) =
1[Rj−1,∞)(x) for 1 ≤j ≤N. (Observe that each new clock reading for
transition e3,j is equal to the constant Rj−1 with probability 1.) All speeds
for enabled transitions are equal to 1.
As shown in the next example, the token ring of Example 2.6 can also be
represented as an spn with deterministic transitions; that is, no marking-
dependent transitions are required. An advantage of this representation is
that the spn graph completely determines the state-transition mechanism
of the net. A disadvantage is that the deterministic spn has more places,
transitions, and markings than the spn of Example 2.6. This situation is
typical; increasing the amount of information conveyed by the spn graph
usually increases the size and complexity of the graph.
Example 2.7 (Alternative representation of token ring).
The system
in Example 2.6 can be speciﬁed as an spn with deterministic timed and
immediate transitions and unit speeds; see Figure 2.11 for N = 2. Each
place contains at most one token. The interpretations of places d1,j, d2,j,
d3,j, and d4,j are exactly as in Example 2.6. Place d5,j contains one token
if and only if port j has just observed the ring token. The clock-setting
distribution functions for timed transitions are as in Example 2.6.
The marking set G is
G =

(s1,1, s2,1, . . . , s5,N) ∈{0, 1}5N : s1,j + s2,j + sj,3 = 1
for 1 ≤j ≤N; s3,1 + s4,1 + s5,1 + · · · + s3,N + s4,N + s5,N = 1

,
and
S′ =

(s1,1, s2,1, . . . , s5,N) ∈G: s5,j = 1 for some j


2.2 Illustrative Examples
37
e1,j = arrival of packet for transmission by port j
e2,j = end of transmission by port j
e3,j = observation of ring token by port j
e4,j = start of transmission by port j
e5,j = start of propagation from port j
Figure 2.11. Deterministic spn representation of token ring (two ports).
is the immediate marking set. For this spn, |G| = 5N2N−1, |S| = 3N2N−1,
and |S′| = 2N2N−1. Thus the marking set G is larger than the marking
set for the spn of Example 2.6 by a factor of about 1.7.
Observe that when transition e3,j = “observation of ring token by port j”
ﬁres, it removes a token from place d4,j−1 and deposits a token in place d5,j;
then immediate transition e4,j ﬁres if (s1,j, s2,j) equals (1, 0) and immediate
transition e5,j ﬁres if (s1,j, s2,j) equals (0, 1). Thus, when the ring token
arrives at port j, either port j starts transmission or the ring token starts
to propagate to the next port, depending on whether or not port j has a
packet queued for transmission.
Our next example shows how marking-dependent transitions can be used
to approximately model the pri preemption mechanism mentioned in the
previous subsection.
Example 2.8 (Modelling pri preemption).
Consider an activity that is
subject to pri preemption, and suppose that the duration of the activity
has distribution function H; for concreteness, suppose that H has support
on the nonnegative real line. Figure 2.12 shows a subnet that can be used
to model the activity; for this subnet, the ﬁring of transition e1 corresponds

38
2. Modelling with Stochastic Petri Nets
Figure 2.12. An spn for modelling pri preemptions.
to the completion of the activity. The idea is to ﬁx an integer N > 1 and
real numbers 0 = a0 < a1 < · · · < aN < aN+1 = ∞; whenever the activity
is underway and the initially scheduled duration of the activity is X, the
subnet “remembers” the unique integer k such that ak−1 < X ≤ak. When
a repetition of the activity is scheduled after a preemption, the activity
duration is generated according to H, conditional on the duration lying in
the interval (ak−1, ak]. By increasing N, the partition of the support of H
can be made ﬁner and ﬁner, so that the subnet captures the pri mechanism
with greater and greater ﬁdelity.
In more detail, the activity is initially scheduled when a token is deposited
in place d1—for simplicity, we assume that the set of places { d1, d3 } con-
tains no more than one token at any time. Immediate transition e2 then
ﬁres a random number of times in succession before becoming disabled,
depositing a token in place d4 each time it ﬁres; the probability that e2
ﬁres exactly k times, so that exactly k tokens are deposited in place d4, is
pk = H(ak)−H(ak−1) for k ∈{ 1, 2, . . . , N + 1 }. When e2 ﬁres for the last
time and becomes disabled, it removes a token from place d1 and deposits
a token in place d3, causing transition e1 to become enabled. The precise
speciﬁcation of the new-marking probabilities that deﬁne this ﬁring mech-
anism is similar to that given in Example 2.4 for the spn model of a queue
with batch arrivals.
Assuming that k tokens have been deposited in place d4, a new clock
reading for transition e1 is generated according to the conditional distribu-
tion
Hk(t) =





0
if t ≤ak−1;

H(t) −H(ak−1)

/

H(ak) −H(ak−1)

if ak−1 < t ≤ak;
1
if t > ak.
A preemption of the activity occurs when a token is deposited in place d2
and e1 becomes disabled. A subsequent removal of the token in place d2

2.2 Illustrative Examples
39
causes e1 to become reenabled, and the activity is repeated. At each such
repetition, a new clock reading for e1 is generated according to Hk. When
the activity ﬁnally completes and transition e1 ﬁres—removing the token in
place d3—deterministic transition e3 becomes enabled and ﬁres k times in
succession, removing all tokens from place d4. The subnet is then ready for
the next fresh start of the activity. This construction illustrates the utility of
letting the clock-setting distribution depend explicitly on the new marking,
since F(x; s′, e1, s, E∗) ≡F(x; s′, e1) = Hs′
4(x) for s′ = (s′
1, s′
2, s′
3, s′
4, . . .) ∈
G, s ∈G, and E∗⊆E(s).
We conclude our discussion of marking-dependent transitions by indicat-
ing how new-marking probabilities for an spn with such transitions can be
speciﬁed in a form suitable for processing by a computer program. In partic-
ular, we illustrate the speciﬁcation of new-marking probabilities in spsim,
a prototype software system developed at IBM for simulation of spns and
other stochastic processes. The spsim system takes as input a model de-
scription, written in the spsim speciﬁcation language, and automatically
translates this description into an executable simulation program.
Consider ﬁrst the spn model, given in Example 2.4, of the queue with
batch arrivals. The new-marking probabilities for this spn can be speciﬁed
by the following spsim statements:
\MARKING CHANGES
FOR (I* == 1) || (I* == 3) || (I* == 4)
DETERMINISTIC
FOR I* == 2
IF TRUE THEN
WITH PROB = P(S[3])
NEXT S’[2] = S[2] - 1;
S’[3] = S[3] + 1
WITH PROB = 1 - P(S[3])
NEXT S’[3] = S[3] + 1
The syntax of the spsim speciﬁcation language is similar to that of the C
programming language. In the above listing, we assume that a function P
has been deﬁned such that, for an integer-valued variable k, the expression
P(k) evaluates to the probability pk deﬁned in (2.5). (The spsim system
permits such user-deﬁned functions.) The ﬁrst line in the listing demarcates
the section of the model speciﬁcation in which new-marking probabilities
are deﬁned. The variable I* is a standard identiﬁer that denotes the index
of the transition that triggers the marking change. For example, if transition
e2 triggers the marking change, then I* is equal to 2. Similarly, S denotes
the current marking and S’ denotes the new marking. Brackets are used
to specify components of a marking: S[3] denotes the third component
of the current marking, that is, the token count in place d3. The idea
is that the logical expression in each FOR-clause is evaluated until a true
expression is found. Each such logical expression has the same syntax as a
logical expression in C and depends on the index I*. In the above listing,
for example, the == and || operators are logical equality and logical OR
operators as in C; the expression in the ﬁrst FOR-clause is true if the trigger

40
2. Modelling with Stochastic Petri Nets
transition is equal to e1, e3, or e4, and the expression in the second FOR-
clause is true if the trigger transition is equal to e2. For a well-speciﬁed
spn model, exactly one of the FOR-clauses contains a true expression. If
this FOR-clause is followed by the DETERMINISTIC keyword, then the new
marking S’ is generated from the current marking S by decrementing (by
1) the token count in each normal input place of the trigger transition
and incrementing the token count in each output place. Otherwise, the
FOR-clause is followed by one or more IF-clauses, exactly one of which is
assumed to contain a true logical expression. In the above listing, the logical
expression in the displayed IF-clause consists of the keyword TRUE, so that
the expression is always true. In general, the logical expression can depend
on both I* and S. Associated with each IF-clause are one or more WITH-
clauses. For the (unique) IF-clause that contains a true logical expression,
one of the associated WITH-clauses is randomly chosen according to the
speciﬁed probability, and the new marking S’ is generated by the speciﬁed
assignments to the components of S’. The components of S’ for which no
assignments are speciﬁed keep their values from the current marking S.
As a second example, consider the spn model of Example 2.6 with N = 5
ports, and suppose that transitions never ﬁre simultaneously. The new-
marking probabilities for this spn can be speciﬁed by the following spsim
statements:
\REPLACEMENTS
N IS 5
J* IS I*[2]
J*MINUS1 IS ((J* - 2) MOD N) + 1
\MARKING CHANGES
FOR (I*[1] == 1) || (I*[1] == 2)
DETERMINISTIC
FOR I*[1] == 3
IF S[1][J*] == 1 THEN
WITH PROB = 1 NEXT S’[4][J*MINUS1] = S[4][J*MINUS1] - 1;
S’[3][J*] = S’[3][J*] + 1
IF S[2][J*] == 1 THEN
WITH PROB = 1 NEXT S’[4][J*MINUS1] = S[4][J*MINUS1] - 1;
S’[4][J*] = S’[4][J*] + 1
As illustrated by the above listing, both transitions and components of
markings can have multiple indices. Brackets are used to specify a speciﬁc
index. For example, if the transition that triggers a marking change is e∗=
e3,5, then the standard identiﬁers I*[1] and I*[2] are equal to 3 and 5,
respectively. Similarly, if the current marking is s = (s1,1, s2,1, s3,1, s4,1, . . . ,
s1,5, s2,5, s3,5, s4,5), then the standard identiﬁer S[2][5] is equal to s2,5.
The ﬁrst statement in the \REPLACEMENTS section of the model description
speciﬁes that every subsequent occurrence of the identiﬁer N in the model
description is to be replaced by the symbol 5 before translation of the
model. The remaining statements in the \REPLACEMENTS section have a

2.2 Illustrative Examples
41
similar interpretation, and the statements in this section are executed in
the opposite order in which they appear. Thus, for example, the identiﬁer
S[4][J*MINUS1] is equal to the token count s4,4 whenever the current
marking is s = (s1,1, . . . , s4,5) and the trigger transition is e∗= e3,5. To see
this, observe that spsim generates the successive replacements
S[4][J*MINUS1] ⇒S[4][((J* - 2) MOD N) + 1]
⇒S[4][((I*[2] - 2) MOD N) + 1]
⇒S[4][((I*[2] - 2) MOD 5) + 1].
The rightmost expression is then evaluated with I*[2] equal to 5—here
MOD is the standard modulo operator. Because −1 mod n = n−1 for n ≥1,
it follows that, in general, J*MINUS1 is equal to N whenever J* is equal to
1 and to j −1 whenever J* is equal to j with 1 < j ≤N.
2.2.3
Synchronization: Flexible Manufacturing System
The following examples illustrate one way in which immediate transitions
and marking-dependent transitions can be used to model synchronized ac-
tivities, speciﬁcally, the synchronized unloading of manufactured parts. The
ﬁrst example also illustrates the utility of allowing the clock-setting distri-
bution function for a transition to depend explicitly on the current and
new markings.
Example 2.9 (Flexible manufacturing system).
Consider a ﬂexible man-
ufacturing system that produces two types of parts and has three machines
numbered 1, 2, and 3. Parts of type 1 require processing ﬁrst by machine 1
and then by machine 2. Two processes can produce parts of type 2. The
ﬁrst process consists of a fast intervention by machine 1 followed by a re-
ﬁnement performed by machine 2. The second process, performed entirely
by machine 3, is much slower but produces ﬁnished parts. The duration of
the reﬁnement operation performed by machine 2 on parts processed by
machine 1 is independent of the part type. Exactly three parts are in the
system at any time, and ﬁnished parts are unloaded (instantaneously) from
the system and immediately replaced by raw ones three at a time. Each
machine processes one part at a time. For machines 1 and 2, parts of type 2
have nonpreemptive priority over parts of type 1. For each of machines 1,
2, and 3, parts of the same type are processed according to a ﬁrst-come,
ﬁrst-served service discipline. A raw part loaded (instantaneously) into the
system is of type 1 with probability p ∈(0, 1) and is of type 2 with proba-
bility 1 −p. A part of type 2 goes to machine 1 with probability q ∈(0, 1)
and to machine 3 with probability 1 −q.
The successive times for machine 1 to process a part of type j are i.i.d.
as a positive random variable L1,j, the successive times for machine 2 to
process a part are i.i.d. as a positive random variable L2, and the successive

42
2. Modelling with Stochastic Petri Nets
times for machine 3 to process a part are i.i.d. as a positive random variable
L3. Each of these random variables has a continuous distribution function.
This system can be speciﬁed as an spn with (marking-dependent) timed
and immediate transitions; see Figure 2.13. Place d1 contains one token
if and only if machine 1 is processing a part; otherwise, place d1 contains
no tokens. Place d2 (resp., place d3) contains k (≥0) tokens if and only
if k parts are awaiting processing or being processed by machine 2 (resp.,
machine 3). Places d4, d5, and d6 each contain at most one token; there is a
total of k (≥0) tokens in places d4, d5, and d6 if and only if k ﬁnished parts
are awaiting unloading. Place d7 (resp., place d8) contains k (≥0) tokens
if and only if k raw parts of type 1 (resp., type 2) are awaiting processing
by machine 1. Place d9 contains one token if and only if machine 1 is idle;
otherwise, place d9 contains no tokens.
Transitions e1, e5, and e6 are deterministic. Whenever transition e2 =
“end of processing by machine 2” ﬁres, it removes a token from place d2
and deposits a token in one of places d4, d5, or d6; the token is deposited
in the lowest-numbered empty place. Formally, p(s′; s, e2) = 1 when
s = (s1, s2, s3, 0, 0, 0, s7, s8, s9)
and s′ = (s1, s2 −1, s3, 1, 0, 0, s7, s8, s9),
when
s = (s1, s2, s3, 1, 0, 0, s7, s8, s9)
and s′ = (s1, s2 −1, s3, 1, 1, 0, s7, s8, s9),
and when
s = (s1, s2, s3, 1, 1, 0, s7, s8, s9)
and s′ = (s1, s2 −1, s3, 1, 1, 1, s7, s8, s9).
Similarly, transition e3 = “end of processing by machine 3” removes a
token from place d2 and deposits a token in one of places d4, d5, or d6
whenever it ﬁres. Whenever transition e4 = “unloading of ﬁnished parts
and loading of raw parts” ﬁres, it removes one token from each of places
d4, d5, and d6. Moreover, if n1, n2, and n3 are nonnegative integers such
that n1 + n2 + n3 = 3, then with probability
p = 6(n1!n2!n3!)−1pn1qn2(1 −p)n2+n3(1 −q)n3
it deposits n1 tokens in place d7, n2 tokens in place d8, and n3 tokens
in place d3. That is, a total of three tokens is assigned to places d7, d8,
and d3 according to a multinomial probability distribution with respective
parameters p, (1 −p)q, and (1 −p)(1 −q).

2.2 Illustrative Examples
43
e1 = end of processing by machine 1
e2 = end of processing by machine 2
e3 = end of processing by machine 3
e4 = unloading of ﬁnished parts and loading of raw parts
e5 = start of processing by machine 1 for part of type 1
e6 = start of processing by machine 1 for part of type 2
Figure 2.13. spn representation of ﬂexible manufacturing system.

44
2. Modelling with Stochastic Petri Nets
The clock-setting distribution function for transition e1 = “end of pro-
cessing by machine 1” depends explicitly on the current and new mark-
ings: if s = (s1, s2, . . . , s9) and s′ = (s′
1, s′
2, . . . , s′
9), then F(x; s′, e1, s, e∗) =
P { L1,1 ≤x } when s′
7 = s7 −1 and F(x; s′, e1, s, e∗) = P { L1,2 ≤x } when
s′
8 = s8−1. The clock-setting distribution functions for the remaining timed
transitions are deﬁned in an obvious manner, and all speeds for enabled
transitions are equal to 1.
Observe that the nonpreemptive priority of parts of type 2 over parts of
type 1 for processing by machine 1 is modelled using inhibitor input places
and immediate transitions in a manner similar to the spn representation
of the producer–consumer system in Example 2.1.
As mentioned above, a token is deposited in one of places d4, d5, or d6
whenever transition e2 or transition e3 ﬁres—that is, whenever there is a
creation of a ﬁnished part by machine 2 or machine 3; the token is deposited
in the lowest-numbered empty place. Immediate transition e4 therefore
becomes enabled whenever a token is deposited in place d6, leaving exactly
one token in each of places d4, d5, and d6. In this manner, ﬁnished parts
are unloaded and raw parts are loaded three at a time.
The foregoing model is a “minimal” representation of the manufacturing
system that can be used to study performance measures such as the uti-
lization of each of the machines and the amount of time from when three
parts are simultaneously loaded into the system until the parts are simulta-
neously unloaded. The following example gives an alternative spn model of
the manufacturing system in which parts of each type may be more easily
tracked as they move through the system. This latter model permits the
study of many additional performance measures that are speciﬁc to a part
of type 1 or 2.
Example 2.10 (Alternative model of ﬂexible manufacturing system). The
system of Example 2.9 can also be represented by the spn in Figure 2.14.
In this spn, place d1,i,j contains n tokens if and only if n parts of type i
are either waiting to be processed or undergoing processing by machine j.
The manner in which tokens are deposited in places d4,1, d4,2, and d4,3
and then subsequently removed (simultaneously) by the ﬁring of transition
e3 is exactly analogous to the manner in which tokens are deposited in
places d4, d5, and d6 and then removed by the ﬁring of transition e4 in
the spn of Figure 2.13. The primary diﬀerence between the two spns is the
representation of machines 1 and 2. In the spn of Figure 2.13, machine i
(i = 1, 2) is represented by place di together with transition ei. In the
spn of Figure 2.13, machine 1 is represented by the token that resides in
one of places d3,1 (when the machine is idle), d2,1,1 (when the machine
is processing a part of type 1), or d2,2,1 (when the machine is processing
a part of type 2); machine 2 is modelled similarly. This representation of
each machine is similar to that of the channel in the producer–consumer

2.2 Illustrative Examples
45
e1,i,j = start of processing by machine j for part of type i
e2,i,j = end of processing by machine j for part of type i
e3 = unloading of ﬁnished parts and loading of raw parts
Figure 2.14. Alternative spn representation of ﬂexible manufacturing system.
models of Section 2.2.1 and—unlike the spn in Figure 2.13—makes explicit
the type of part that each machine is processing at each time point. Also
unlike the spn in Figure 2.13, the spn in Figure 2.14 explicitly displays the
nonpreemptive-priority mechanism for machine 2.
2.2.4
Resetting Clocks: Particle Counter
The clock for a transition e ∈E is not allowed to be reset when a transition
e∗̸= e triggers a marking change and transition e is enabled in both the
old and the new marking. The following example illustrates a technique for
getting around this restriction.
Example 2.11 (Particle counter). Suppose that particles arrive, one at a
time, at a counter. A particle arrives at time 0 and locks the counter for a
time interval of ﬁxed length T. If no further particles arrive in (0, T], the

46
2. Modelling with Stochastic Petri Nets
e1 = arrival of particle
e2 = end of locked time interval
e3 = resetting of locked time interval
e4 = extension of locked time interval
e5 = locking of counter
Figure 2.15. spn representation of particle counter.
counter becomes unlocked at time T; the next particle gets registered and
the counter is locked again for a time interval of length T. A particle that
arrives when the counter is locked does not get registered but extends the
locked interval so that the counter remains locked for an interval of length
T after the arrival. The successive interarrival times for particles are i.i.d.
as a random variable U with a continuous distribution function.
This system can be speciﬁed as an spn with deterministic timed and
immediate transitions; see Figure 2.15. Place d1 contains exactly one to-
ken, reﬂecting the fact that the arrival process of particles is always active.
Each of places d2, d3, and d4 contains at most one token. Place d2 con-
tains a token if and only if the counter is locked, place d3 contains a token
if and only if the arrival of a particle extends the locked time interval,
and place d4 contains a token if and only if a particle has just arrived.
All transitions are deterministic, and the clock-setting distribution func-
tions for timed transitions are given by F(x; s′, e1, s, e∗) = P { U ≤x } and
F(x; s′, e2, s, e∗) = 1[T,∞)(x). All speeds for enabled transitions are equal
to 1.

2.2 Illustrative Examples
47
Whenever the marking is (1, 1, 0, 0) and transition e1 ﬁres, so that a
particle arrives while the counter is locked, immediate transition e4 = “ex-
tension of locked time interval” ﬁres and timed transition e2 = “end of
locked time interval” becomes disabled. Immediate transition e3 = “reset-
ting of locked time interval” then ﬁres, transition e2 becomes enabled again,
and the clock for transition e2 is reset to the value T. In eﬀect, the clock
for transition e2 is reset whenever the marking is (1, 1, 0, 0) and transition
e1 ﬁres.
2.2.5
Compound Events: Slotted Ring
In many discrete-event systems, two or more events can occur simultane-
ously. As discussed in Section 2.3, the simultaneous occurrence of events
can substantially complicate the speciﬁcation of an spn model. Sometimes
these complications can be avoided by using a single transition to model
multiple events that occur simultaneously in the system.
Example 2.12 (Slotted ring). Consider a unidirectional ring network hav-
ing a ﬁxed number K of equal size slots and a ﬁxed number of equally
spaced ports, labelled 1, 2, . . . , N in the direction of signal propagation; see
Figure 2.16. At each port, constant-length message packets arrive according
to a random process; the length equals the slot size. The propagation delay
from one port to the next is a positive constant R. Assume that the number
N of ports is a multiple of K and, so that there is no loss of utilization due
to “unused bits,” the time to transmit a message packet is NR/K. The
lead “full/empty” (F/E) bit maintains the status of each slot. Subject to
the restriction that no port may hold more than one slot simultaneously, a
port that has a packet awaiting transmission and observes the status bit of
an empty slot sets the bit to 1 (full) and starts transmission. Transmission
ends when the slot contains the entire packet. When the status bit of the
ﬁlled slot propagates back to the sending port, it resets the bit to 0 (empty)
and releases the slot. The port releases the slot even if it has another packet
awaiting transmission; this rule ensures that all ports have an opportunity
to transmit. A port “holds” a slot from the time it sets the status bit to 1
until it releases the slot.
Assume that at most one packet awaits transmission at any time at any
particular port; the successive times from end of transmission by port j
until the arrival of the next packet for transmission by port j are i.i.d. as
a positive random variable Aj with continuous distribution function.
This system can be speciﬁed as an spn with timed transitions. For con-
creteness, suppose that there are N = 4 ports and K = 2 slots; see Fig-
ure 2.17. Set k1 = 3, k2 = 4, k3 = 1, and k4 = 2, and observe that the ﬁring
of transition e2,j (1 ≤j ≤N) corresponds to the simultaneous observation
of the slot 1 status bit by port j and the slot 2 status bit by port kj.

48
2. Modelling with Stochastic Petri Nets
Figure 2.16. Slotted ring.
e1,j = arrival of packet for transmission by port j
e2,j = observation of slot 1 status bit by port j
Figure 2.17. spn representation of slotted ring (two slots, four ports).

2.3 Concise Speciﬁcation of New-Marking Probabilities
49
Places d1,j and d3,j each contain at most one token. Place d1,j contains
a token if and only if port j is not transmitting a packet and has no packet
awaiting transmission. Place d3,j contains a token if and only if the status
bit for slot 1 is propagating from port j to the next port. Places d2,j and
d4,j each contain either one or two tokens. Place d2,j contains two tokens
if and only if port j holds slot 1, and place d4,j contains two tokens if
and only if port j holds slot 2. Because each of places d2,j and d4,j always
contains at least one token, transition e2,j is always enabled when place
d3,j−1 contains a token.
Transition e1,j is deterministic for 1 ≤j ≤4. Whenever the marking is
s = (s1,1, s2,1, . . . , s4,4) and transition e2,j = “observation of slot 1 status
bit by port j” ﬁres, a token is removed from place d3,j−1 and a token is
deposited in place d3,j, so that the slot 1 status bit starts to propagate to
the next port. Moreover, if s1,j = 0, s4,j = 1, and s2,l = 1 for 1 ≤l ≤4—so
that port j has a packet waiting for transmission, port j does not hold
slot 2, and no port holds slot 1—then a token also is deposited in place d2,j
and port j starts transmission of a packet in slot 1. Similarly, if s1,kj = 0,
s2,kj = 1, and s4,l = 1 for 1 ≤l ≤4, then a token is deposited in place
d4,kj and port kj starts transmission of a packet in slot 2. Furthermore, if
s2,j = 2—so that port j has been holding slot 1—then a token is removed
from place d2,j and port j releases slot 1. Similarly, if s4,kj = 2, then a
token is removed from place d4,kj and port kj releases slot 2. If s4,j = 2—
so that port j has just ended transmission of a packet in slot 2—then a
token is deposited in place d1,j and port j starts to wait for the arrival of a
packet. Similarly, if s2,kj = 2, then a token is deposited in place d1,kj and
port kj starts to wait for the arrival of a packet.
The clock-setting distribution functions are given by F(x; s′, e1,j, s, e∗) =
P { Aj ≤x } and F(x; s′, e2,j, s, e∗) = 1[R,∞)(x) for 1 ≤j ≤4. All speeds
for timed transitions are equal to 1.
2.3
Concise Speciﬁcation of New-Marking
Probabilities
Because our formulation of the spn model permits transitions to ﬁre si-
multaneously, speciﬁcation of new-marking probabilities potentially can be
burdensome. Given a timed marking s ∈S and ﬁxed marking s′ ∈G,
for example, 2|E(s)| −1 new-marking probabilities of the form p(s′; s, E∗)
must in principle be speciﬁed, one for each of the 2|E(s)| −1 nonempty
subsets E∗⊆E(s). In this section we discuss several techniques for concise
speciﬁcation of new-marking probabilities.

50
2. Modelling with Stochastic Petri Nets
Figure 2.18. Example of a transition ﬁring that never occurs.
2.3.1
Transition Firings That Never Occur
One elementary but useful technique for concise speciﬁcation is to simply
avoid specifying new-marking probabilities for transition ﬁrings that never
occur. That is, a new-marking probability p(s′; s, E∗) need not be speciﬁed
explicitly if with probability 1 the transitions in E∗never ﬁre simultane-
ously when the marking is s.
As an example, suppose that E∗contains both timed and immediate
transitions. If E∗⊆E(s) for some marking s, then s must be an immediate
marking, and only the transitions in E(s) ∩E′ (̸= E∗) ever ﬁre simulta-
neously when the marking is s. Hence probabilities of the form p( · ; s, E∗)
need not be speciﬁed.
As another example, suppose that each clock-setting distribution func-
tion is continuous and the marking s is timed. Then new-marking proba-
bilities of the form p(s′; s, E∗) with |E∗| > 1 need not be speciﬁed, because
with probability 1 timed transitions never ﬁre simultaneously. We have used
this technique in all of the examples in Section 2.2.
As a ﬁnal example, consider an spn as in Figure 2.18 with marking set
G = { s, s′, s′′ }, where
s = (1, 0, 1, 0),
s′ = (0, 1, 0, 1),
and
s′′ = (1, 0, 0, 1).
Suppose that the initial marking is s, that all speeds for enabled transitions
are equal to 1, and that each new clock reading for timed transition ei

2.3 Concise Speciﬁcation of New-Marking Probabilities
51
(i = 2, 3) is uniformly distributed on an interval [ai, bi]. Also suppose that
b2 < a3, so that new clock readings for transition e2 are always smaller
than new clock readings for transition e3. Observe that the new-marking
probabilities of the form p( · ; s′, e3) need not be speciﬁed explicitly, because
with probability 1 transition e3 never ﬁres when the marking is s′.
Remark 3.1. Suppose that we insist on specifying the new-marking prob-
abilities of the form p( · ; s′, e3). Observe that we must have p(s′; s′, e3) = 1
and p(s; s′, e3) = p(s′′; s′, e3) = 0 if (1.3) is to be satisﬁed. If we also set
p(s; s′′, e3) = 1, then transition e3 does not behave as a deterministic tran-
sition when it ﬁres and the marking is s′, but does behave as a deterministic
transition when it ﬁres and the marking is s′′. Because the former type of
transition ﬁring occurs with probability 0, we refer to e3 (with a slight
abuse of terminology) as a deterministic transition. In general, we refer to
a transition as “deterministic” if it behaves as a deterministic transition
except in scenarios that occur with probability 0.
2.3.2
Numerical Priorities
Many spns have the following property: whenever two or more transitions
ﬁre simultaneously, the net changes marking as if a subset of these transi-
tions ﬁre in succession. That is, there exists a representation of the form
p(s′; s, E∗) = p(s′; s, ej1, ej2, . . . , ejl)
whenever p(s′; s, E∗) is well deﬁned, where { ej1, ej2, . . . , ejl } ⊆E∗and
p(s′; s, ej1, ej2, . . . , ejl)
=

s1,s2,...,sl−1
p(s1; s, ej1)p(s2; s1, ej2) · · · p(s′; sl−1, ejl)
(3.2)
with the above sum taken over all sequences s1, s2, . . . , sl−1 such that
ejk ∈E(sk−1) for 2 ≤k ≤l. [Thus p(s′; s, ej1, ej2, . . . , ejl) is the prob-
ability that the new marking is s′ given that transitions ej1, ej2, . . . , ejl
successively trigger marking changes starting in marking s.] For such nets,
it often suﬃces to explicitly specify only the “singleton” new-marking prob-
abilities of the form p(s′; s, e∗) and then give succinct rules for expressing a
new-marking probability p(s′; s, E∗) in terms of the singleton probabilities.
These rules specify the elements of E∗that (in eﬀect) successively ﬁre and
the order in which they ﬁre. This approach is particularly eﬀective when
each transition is deterministic, so that speciﬁcation of singleton probabili-
ties is immediate. A simple and concise set of rules that suﬃces for all of the
spn models in this book can be based on the assignment of “priorities” to
the transitions of the net. To simplify the exposition we restrict attention
to spns in which all speeds are positive.
Before discussing priorities, we ﬁrst introduce the notion of transitions
in conﬂict.

52
2. Modelling with Stochastic Petri Nets
Figure 2.19. Two scenarios in which the ﬁring of deterministic transition e causes
transition e′ to become disabled.
Deﬁnition 3.3. Two transitions e and e′ are said to be in conﬂict if e and
e′ are both timed or both immediate and either
(i) I(e) ∩I(e′) ̸= ∅, or
(ii)

J(e) ∩L(e′)

∪

J(e′) ∩L(e)

̸= ∅.
According to this deﬁnition, two timed transitions or two immediate tran-
sitions are in conﬂict if one of the transitions, when it ﬁres, can potentially
cause the other transition to become disabled. Such disabling occurs when
e ﬁres and either removes a token from a normal input place for e′ (thereby
decreasing the token count to 0) or deposits a token in an inhibitor input
place for e′; see Figure 2.19. The transitive closure of the conﬂict relation
is an equivalence relation on the set E and partitions E into mutually dis-
joint equivalence classes called conﬂict sets. Observe that, by deﬁnition,
the transitions in a conﬂict set are either all timed or all immediate. Also
observe that if two transitions—both timed or both immediate—are in dif-
ferent conﬂict sets, then the ﬁring of one transition never causes the other
transition to become disabled.
To concisely specify the behavior of the net when transitions ﬁre simul-
taneously, we associate a priority (ﬁnite, nonnegative integer) with each
transition of the net. In the graphical representation of an spn, the priority
of a transition is displayed in parentheses next to the transition; a transi-
tion for which no priority is explicitly displayed has priority 0. Denote by
P(e) the priority of transition e ∈E. We assume throughout that the prior-
ities are such that P(e) ̸= P(e′) whenever e and e′ are in the same conﬂict
set with e ̸= e′. Heuristically, we deﬁne new-marking probabilities of the
form p(s′; s, E∗) in terms of the singleton probabilities and the priorities
by applying the following two rules:
1. Whenever transitions within a conﬂict set ﬁre simultaneously, the
transition with the highest priority is selected to remove and de-
posit tokens in accordance with its associated singleton new-marking
probabilities—that is, the net behaves as if the latter transition is the
only one in the set that ﬁres.
2. When transitions in diﬀerent conﬂict sets ﬁre simultaneously—and by
the rule in (1) we can assume that, in eﬀect, exactly one transition

2.3 Concise Speciﬁcation of New-Marking Probabilities
53
ﬁres in each set—the net behaves as if the transitions ﬁre sequentially
in order of decreasing priority.
Formally, suppose that all singleton new-marking probabilities have been
speciﬁed, along with priorities { P(e): e ∈E }. Denote by Q1, Q2, . . . , Qk
the conﬂict sets for the transitions. We specify a new-marking probabil-
ity of the form p(s′; s, E∗) as follows. Partition E∗into mutually disjoint
nonempty subsets E1, E2, . . . , El such that each subset Ei is of the form
E∗∩Qj for some j ∈{ 1, 2, . . . , k }. Then for 1 ≤i ≤l denote by ¯ei the
unique transition in Ei such that P(¯ei) = maxe∈Ei P(e). Finally, set
p(s′; s, E∗) = p(s′; s, ¯eπ(1), ¯eπ(2), . . . , ¯eπ(l)),
(3.4)
where ¯eπ(1), ¯eπ(2), . . . , ¯eπ(l) are the transitions ¯e1, ¯e2, . . . , ¯el ordered so that
P(¯eπ(1)) ≥P(¯eπ(2)) ≥· · · ≥P(¯eπ(l)).
(3.5)
In general, there may be more than one ordering such that (3.5) is satisﬁed.
For the deﬁnition in (3.4) to make sense, we require that the right side
of (3.4) have the same value for any two orderings. This requirement is
satisﬁed by many spns encountered in practice, for example, spns with no
marking-dependent transitions.
Example 3.6 (Manufacturing cell with robots). Consider a manufacturing
cell with two machines, two material-handling robots, two conveyors, a
loading area for incoming raw parts, and an unloading area for outgoing
ﬁnished parts. Robot 1 transfers raw parts, drawn as white squares in
Figure 2.20, from the loading area to conveyor 1 and transfers ﬁnished parts,
drawn as black squares, from conveyor 2 to the unloading area. Conveyor 1
moves raw parts to a designated position on the conveyor for transfer to
a machine. Robot 2 transfers raw parts from conveyor 1 to the lowest-
numbered available machine for processing and transfers ﬁnished parts from
the machines to conveyor 2. Conveyor 2 moves ﬁnished parts to a designated
position on the conveyor for transfer to the unloading area.
Raw parts are always available at the loading area. Each robot can handle
only one part at a time. After a robot completes a transfer, the arm of the
robot returns to a “null” position before starting another transfer. The arm
of robot 1 does not leave its null position to transfer a raw part to conveyor 1
while a part is on the conveyor. The arm of robot 2 does not leave its null
position to transfer a ﬁnished part to conveyor 2 while a part is on the
conveyor and does not leave its null position to transfer a raw part to a
machine while a part is at the machine. Thus, at any time there is at most
one part on each conveyor and at most one part at each machine. Transfer of
a ﬁnished part from conveyor 2 to the unloading area has (nonpreemptive)
priority over transfer of a raw part from the loading area to conveyor 1.
Transfer of a ﬁnished part from either machine to conveyor 2 has priority
over transfer of a raw part from conveyor 1 to either machine, and transfer

54
2. Modelling with Stochastic Petri Nets
Figure 2.20. Manufacturing cell with robots.
of a ﬁnished part from machine 1 to conveyor 2 has priority over transfer
of a ﬁnished part from machine 2.
The time for each of the actions performed by a robot is deterministic.
The time for a conveyor to move a part is deterministic and may depend on
the identity of the conveyor. The successive times for machine j to process
a raw part are i.i.d. as a positive random variable Lj with continuous dis-
tribution function. We assume that the deterministic times for the actions
performed by the robots and for the conveyors to move parts are such that
with probability 1 no two events ever occur simultaneously.
This system can be speciﬁed as an spn with deterministic timed and im-
mediate transitions; see Figure 2.21. The interpretation of the transitions
is given in Table 2.1. Each place contains at most one token; the interpre-
tation of the tokens is given in Table 2.2. All transitions are deterministic,
and all speeds for enabled transitions are equal to 1. The clock-setting
distribution functions are deﬁned in an obvious manner. Observe that the
clock-setting distribution functions for transitions e17 and e20 explicitly de-
pend on the current and new marking; no other clock-setting distribution
functions exhibit such explicit dependence.
As can be seen from Figure 2.21, the priorities are given by P(e18) =
1, P(e19) = 2, P(e21) = 2, P(e22) = 1, P(e23) = 4, P(e24) = 3, and
P(e) = 0 otherwise. The relative values of P(e18), P(e19), and so forth
reﬂect the relative priorities of the various operations performed by the
robots. Observe that we can model diﬀerent priority schemes for the robot
operations without needing to change the bipartite graph of places and
transitions.

2.3 Concise Speciﬁcation of New-Marking Probabilities
55
Figure 2.21. spn representation of manufacturing cell with robots.

56
2. Modelling with Stochastic Petri Nets
Table 2.1. Interpretation of Transitions in spn Representation of Manufacturing
Cell with Robots
Transition
Interpretation of Transition
e1
start of transfer of a raw part from the loading area to con-
veyor 1
e2
end of transfer of a raw part from the loading area to conveyor 1
e3
arrival of a raw part at the designated position on conveyor 1
e4
start of transfer of a raw part from conveyor 1 to machine 1
e5
end of transfer of a raw part from conveyor 1 to machine 1
e6
start of transfer of a raw part from conveyor 1 to machine 2
e7
end of transfer of a raw part from conveyor 1 to machine 2
e8
end of processing by machine 1
e9
end of processing by machine 2
e10
start of transfer of a ﬁnished part from machine 1 to conveyor 2
e11
end of transfer of a ﬁnished part from machine 1 to conveyor 2
e12
start of transfer of a ﬁnished part from machine 2 to conveyor 2
e13
end of transfer of a ﬁnished part from machine 2 to conveyor 2
e14
arrival of a ﬁnished part at the designated position on con-
veyor 2
e15
start of transfer of a ﬁnished part from conveyor 2 to the un-
loading area
e16
end of transfer of a ﬁnished part from conveyor 2 to the un-
loading area
e17
return of the arm of robot 1 to its null position
e18
start of movement of the arm of robot 1 from its null position
to the loading area
e19
start of movement of the arm of robot 1 from its null position
to conveyor 2
e20
return of the arm of robot 2 to its null position
e21
start of movement of the arm of robot 2 from its null position
to conveyor 1 (for transfer of a raw part to machine 1)
e22
start of movement of the arm of robot 2 from its null position
to conveyor 1 (for transfer of a raw part to machine 2)
e23
start of movement of the arm of robot 2 from its null position
to machine 1
e24
start of movement of the arm of robot 2 from its null position
to machine 2

2.3 Concise Speciﬁcation of New-Marking Probabilities
57
Table 2.2. Interpretation of Places in spn Representation of Manufacturing Cell
with Robots
Place
Interpretation of Token in Place
d1
the arm of robot 1 is moving from its null position to the loading
area
d2
robot 1 is transferring a raw part to conveyor 1
d3
a raw part is being moved to the designated position on con-
veyor 1
d4
a raw part is at the designated position on conveyor 1 awaiting
transfer to a machine
d5
the arm of robot 1 is moving from its null position to conveyor 1
(to transfer a raw part to machine 1)
d6
robot 1 is transferring a raw part to machine 1
d7
the arm of robot 1 is moving from its null position to conveyor 1
(to transfer a raw part to machine 2)
d8
robot 1 is transferring a raw part to machine 2
d9
machine 1 is processing a part
d10
a ﬁnished part is at machine 1 awaiting transfer to conveyor 2
d11
machine 2 is processing a part
d12
a ﬁnished part is at machine 2 awaiting transfer to conveyor 2
d13
the arm of robot 2 is moving from its null position to machine 1
d14
robot 2 is transferring a ﬁnished part from machine 1 to con-
veyor 2
d15
the arm of robot 2 is moving from its null position to machine 2
d16
robot 2 is transferring a ﬁnished part from machine 2 to con-
veyor 2
d17
a ﬁnished part is being moved to the designated position on
conveyor 2
d18
a raw part is at the designated position on conveyor 2 awaiting
transfer to the unloading area
d19
the arm of robot 1 is moving from its null position to conveyor 2
d20
robot 1 is transferring a ﬁnished part from conveyor 2 to the
unloading area
d21
the arm of robot 1 is returning to its null position
d22
the arm of robot 1 is in its null position
d23
the arm of robot 2 is returning to its null position
d24
the arm of robot 2 is in its null position

58
2. Modelling with Stochastic Petri Nets
Figure 2.22. Collision-free bus network.
Example 3.7 (Collision-free bus network).
Consider a local area bus net-
work with N ports, numbered 1, 2, . . . , N from left to right; see Figure 2.22.
Port j transmits and monitors message packets on the bidirectional bus at
tap B(j). In addition to the bus, a unidirectional (left to right) logic con-
trol wire also links the ports. Associated with each port j is a ﬂip-ﬂop S(j)
called the send ﬂip-ﬂop. Port j sets S(j) to 1 and resets S(j) to 0. The
signal P(j), called the OR-signal, is tapped at the control wire input to
port j and is the inclusive OR of the observed values of the send ﬂip-ﬂops
of all ports to the left. Denote by T the propagation delay from end to
end along the bus plus a small ﬁxed quantity. Let R(j) be the propagation
delay along the control wire from port j to port N for 1 ≤j ≤N; thus
R(1) > R(2) > . . . > R(N) = 0. Assume that signal propagation along the
control wire is slower than along the bus in the sense that R(1) > T.
Distributed control scheme A1 is speciﬁed in terms of an algorithm for
an individual port. When port j is not transmitting a packet and has no
packets awaiting transmission, the arrival of a packet for transmission by
port j initiates execution of the algorithm. If another packet is awaiting
transmission by port j when this execution of the algorithm ends, the next
execution begins immediately.

2.3 Concise Speciﬁcation of New-Marking Probabilities
59
Algorithm A1
1. Set S(j) to 1.
2. Wait for a time interval R(j) + T.
3. Wait until the bus is observed at B(j) to be idle and P(j) = 0; then
start transmission of the packet, simultaneously resetting S(j) to 0.
Control scheme A1 is simple and asynchronous and provides collision-free
communication among ports; that is, no two ports transmit signals that
become electrically superimposed on the bus.
Assume that at most one packet awaits transmission at any time at any
particular port; the successive times from end of transmission by port j
until the arrival of the next packet for transmission by port j are i.i.d.
as a positive random variable Aj with continuous distribution function.
The successive times for port j to transmit a packet are i.i.d. as a positive
random variable Lj with continuous distribution function. Transmission
times are long in the sense that P { Lj > R(1) + T } = 1.
Denote the propagation delay along the bus between port i and port j
by T(i, j). Thus
T(i, j) = T(j, i) < T
and
T(i, j) + T(j, k) = T(i, k)
for i < j < k or i > j > k.
This system can be speciﬁed as an spn with deterministic timed and
immediate transitions and a ﬁnite marking set; see Figure 2.23. (The ﬁgure
displays the subnet that corresponds to a generic port j, where 1 < j < N.
The modiﬁcations required to obtain the subnet corresponding to port 1 or
port N are straightforward.) The interpretation of the transitions is given
in Table 2.3. Place d6,j contains at most j −1 tokens for 2 ≤j ≤N,
and all other places contain at most one token. There is a token in place
d6,j corresponding to each port k (< j) such that port j has observed the
setting (to 1) of port k’s ﬂip-ﬂop but has not yet observed the resetting
(to 0) of this ﬂip-ﬂop. Thus place d6,j contains at least one token if and
only if P(j) = 1. The interpretation of the remaining places in the net is
given in Table 2.4. The clock-setting distribution functions are deﬁned in
an obvious manner, and all speeds for enabled transitions are equal to 1.
As can be seen from the ﬁgure, P(e6,j) = P(e8,j) = 1 and P(e9,j,k) = 2 for
1 ≤k < j ≤N; the priorities for all other events are equal to 0.
Observe that, irrespective of propagation delays, transitions e5,j (1 ≤
j ≤N) and e6,j can ﬁre simultaneously, and similarly for transitions e7,j
and e8,j; that is, a port can observe an end of transmission and a start of
transmission simultaneously. Indeed, transitions e5,j and e6,j ﬁre simulta-
neously at time t whenever, at time t−T(i, j) (with i < j), a packet awaits
transmission by port i, the OR-signal P(i) is equal to 0, and port i observes

60
2. Modelling with Stochastic Petri Nets
Figure 2.23. spn representation of collision-free bus network.

2.3 Concise Speciﬁcation of New-Marking Probabilities
61
Table 2.3. Interpretation of Transitions in spn Representation of Collision-free
Bus Network
Transition
Interpretation of Transition
e1,j
setting (to 1) of ﬂip-ﬂop by port j
e2,j
end of wait for R(j) + T
e3,j
start of transmission by port j
e4,j
end of transmission by port j
e5,j
observation by port j of start of transmission by a port to the
left
e6,j
observation by port j of end of transmission by a port to the
left
e7,j
observation by port j of start of transmission by a port to the
right
e8,j
observation by port j of end of transmission by a port to the
right
e9,j,k
observation by port j of the setting (to 1) of ﬂip-ﬂop by port k
e10,j,k
observation by port j of the resetting (to 0) of ﬂip-ﬂop by port k
Table 2.4. Interpretation of Places in spn Representation of Collision-free Bus
Network
Place
Interpretation of Token in Place
d1,j
there is no packet awaiting transmission by port j and port j
is not transmitting a packet
d2,j
port j has set its ﬂip-ﬂop but has not yet completed the R(j)+T
wait
d3,j
port j has completed the R(j) + T wait but has not started
transmission
d4,j
port j is transmitting a packet
d5,j
port j is observing transmission of a packet (by some port k
with k ̸= j) on the bus
d7,j
the initial bit of a packet is propagating from port j to port j+1
d8,j
the ﬁnal bit of a packet is propagating from port j to port j +1
d9,j
the initial bit of a packet is propagating from port j to port j−1
d10,j
the ﬁnal bit of a packet is propagating from port j to port j −1
d11,j,k
the signal that port k has set its ﬂip-ﬂop (to 1) is propagating
from port j to port j + 1
d12,j,k
the signal that port k has reset its ﬂip-ﬂop (to 0) is propagating
from port j to port j + 1

62
2. Modelling with Stochastic Petri Nets
Figure 2.24. Timeline diagram for collision-free bus network.
an end of transmission by port l with l < i; see the timeline diagram in
Figure 2.24. (Roughly speaking, packets transmitted by ports i and l propa-
gate “back to back” on the bus.) The assignment of priorities to transitions
ensures that the marking changes as if e6,j ﬁres and then e5,j ﬁres, that is,
as if port j ﬁrst observes an end of transmission and then observes a start
of transmission. Also observe that transitions e5,j and e6,j need not ﬁre
simultaneously, so that an attempt to model the simultaneous occurrence
of the corresponding events in the system by using a single transition as
in the slotted ring of Example 2.12 leads to a messy and complicated spn
model.
Depending on the value of the propagation delays, other transitions may
also ﬁre simultaneously. For example, transitions e5,j and e7,l ﬁre simul-
taneously at time t if, for some l < i < j, transition e3,i ﬁres at time
t −T(i, j) and T(i, j) = T(i, l). That is, port l and port j simultaneously
observe the start of transmission of a packet by port i if port l and port j
are equidistant from port i; see Figure 2.24. Whenever transitions e5,j and
e7,l ﬁre simultaneously, the marking changes as if e5,j and then e7,l ﬁres or,
equivalently, as if e7,l and then e5,j ﬁres. The priorities for these two tran-
sitions are both equal to 0, reﬂecting the fact that the new marking does
not depend on the ﬁring order. As another example, transitions e2,j and
e9,j,i can ﬁre simultaneously; that is, port j can simultaneously complete
a wait of length R(j) + T and observe the setting of a ﬂip-ﬂop by port i.
These events occur simultaneously if, for example, the packet interarrival-

2.3 Concise Speciﬁcation of New-Marking Probabilities
63
time distributions have support on the positive integers and the constants
R(j), T, and so forth have integer values. Suppose that transitions e2,j and
e9,j,i ﬁre simultaneously and that
1. There is a packet awaiting transmission by port j,
2. P(j) = 0, and
3. The bus is observed to be idle by port j
just before this transition ﬁring. Because P(e9,j,i) > P(e2,j), the marking
changes as if e9,j,i ﬁres and then e2,j ﬁres, and port j does not start trans-
mission of a packet. Had the order of the priorities been reversed, port j
would have started transmission of a packet.
The method of priorities can be generalized in various ways. We conclude
our discussion by describing an extension in which two or more immediate
transitions in a conﬂict set are allowed to have equal priorities. The idea
is that, within each conﬂict set, the enabled immediate transitions having
the highest priority are allowed to ﬁre simultaneously, provided that the
corresponding behavior of the spn at such a ﬁring is speciﬁed explicitly.
Speciﬁcally, when the current (immediate) marking is s, denote by Ej(s)
(1 ≤j ≤k) the set of enabled immediate transitions within the jth conﬂict
set that have the highest priority:
Ej(s) = { e ∈E′ ∩E(s) ∩Qj : P(e) ≥P(e′) for all e′ ∈E′ ∩E(s) ∩Qj } ,
where, as before, Q1, Q2, . . . , Qk are the conﬂict sets. In general, one or
more of the sets E1(s), E2(s), . . . , Ek(s) may be empty; enumerate the non-
empty subsets as ¯E1(s), ¯E2(s), . . . , ¯El(s), where l = l(s) ≤k. Then, for our
extension, all new-marking probabilities of the form p

s′; s, ¯Ei(s)

must be
speciﬁed in addition to the singleton new-marking probabilities. The pri-
orities of the transitions then determine the eﬀective order in which the
simultaneous transition ﬁrings for the diﬀerent conﬂict sets occur. The de-
tails are as follows. We abuse notation slightly and denote by P
 ¯Ei(s)

the
common priority of the transitions in ¯Ei(s). For arbitrary markings s and s′
and transition sets E1, E2, . . . , El ⊆E, we can deﬁne quantities of the form
p(s′; s, E1, E2, . . . , El) in analogy to (3.2); that is, p(s′; s, E1, E2, . . . , El) is
the probability that the new marking is s′ given that the sets of transitions
E1, E2, . . . , El successively trigger marking changes starting in marking s.
We then set
p(s′; s, E∗) = p

s′; s, ¯Eπ(1)(s), ¯Eπ(2)(s) . . . , ¯Eπ(l)(s)

,
(3.8)
where ¯Eπ(1)(s), ¯Eπ(2)(s) . . . , ¯Eπ(l)(s) are the sets ¯E1(s), ¯E2(s) . . . , ¯El(s) or-
dered so that
P
 ¯Eπ(1)(s)

≥P
 ¯Eπ(2)(s)

≥· · · ≥P
 ¯Eπ(l)(s)

.
(3.9)

64
2. Modelling with Stochastic Petri Nets
As before, we require that the right side of (3.8) have the same value for
any two orderings that satisfy (3.9).
Example 3.10 (Manufacturing cell with nondeterministic robots).
Con-
sider a manufacturing cell as in Example 3.6, except that if
(i) robot 2 is in its null position,
(ii) a raw part is on conveyor 1 awaiting transfer to a machine, and
(iii) there is no part either at machine 1 or machine 2,
then with ﬁxed probability q ∈(0, 1) robot 1 transfers the raw part to ma-
chine 1 and with probability 1−q transfers the part to machine 2. Similarly,
whenever robot 2 is in its null position and there is a ﬁnished part at both
machine 1 and machine 2 awaiting transfer to conveyor 2, with probability
q robot 1 transfers the ﬁnished part at machine 1 to conveyor 2 and with
probability 1 −q transfers the ﬁnished part at machine 2 to conveyor 2.
As in Example 3.6, transfer of a ﬁnished part from either machine to con-
veyor 2 has priority over transfer of a raw part from conveyor 1 to either
machine.
This system can be speciﬁed as an spn exactly as in Example 3.6, except
that P(e21) = P(e22) = 1 and P(e23) = P(e24) = 2, and the new-marking
probabilities are modiﬁed as follows. As before, all transitions are deter-
ministic. For s ∈G(e21) ∩G(e22) and s′ ∈G, set
p(s′; s, {e21, e22}) = qp(s′; s, e21) + (1 −q)p(s′; s, e22).
Similarly, for s ∈G(e23) ∩G(e24) and s′ ∈G, set
p(s′; s, {e23, e24}) = qp(s′; s, e23) + (1 −q)p(s′; s, e24).
Then, for s ∈S′, s′ ∈G, and E∗= E(s)∩E′, the new-marking probability
p(s′; s, E∗) is deﬁned as in (3.8).
2.4
Alternative Building Blocks
One drawback of our spn formulation is that the marking set G must
be speciﬁed—at least in principle—before speciﬁcation of the new-marking
probabilities, speeds, and clock-setting distributions. In this section we con-
sider an alternative set of spn building blocks that avoids this requirement.
Denote by ZL
+ the set of all nonnegative, integer-valued vectors of length
L. Then the building blocks consist of

2.4 Alternative Building Blocks
65
• A ﬁnite set D = { d1, d2, . . . , dL } of places
• A ﬁnite set E = { e1, e2, . . . , eM } of transitions
• A (possibly empty) set E′ ⊂E of immediate transitions
• Sets I(e), L(e), J(e) ⊆D of normal input places, inhibitor input
places, and output places, respectively, for each e ∈E
• A clock-setting distribution function F( · ; e) for each e ∈E −E′
• An initial marking ¯s0 ∈ZL
+
• A probability mass function ˜p( · ; E∗) on { −1, 0, 1 }L for each E∗⊆E
There is no function r(s, e); all clocks run down to 0 at unit rate. Moreover,
the clock-setting distribution functions do not explicitly depend on the
old marking, new marking, or set of transitions that trigger the marking
change. The mechanism by which tokens are removed and deposited when
the transitions in the set E∗⊆E ﬁre simultaneously also is independent
of the old and new markings: when the marking is s and the transitions
in E∗ﬁre, the new marking is of the form s + U(E∗), where the random
variable U(E∗) takes values in the set { −1, 0, 1 }L and has probability mass
function ˜p( · ; E∗). We assume that ˜p(u; E∗) = P { U(E∗) = u } > 0 only if
u = (u1, u2, . . . , uL) satisﬁes the following two conditions.
1. ui = −1 only if di ∈
e∈E∗I(e).
2. ui = 1 only if di ∈
e∈E∗J(e).
We refer to spns that have the above building blocks as restricted spns.
A transition e of a restricted spn is said to be deterministic if ˜p(u; { e }) =
1, where u = (u1, u2, . . . , uL) is given by
ui =





−1
if di ∈I(e) −J(e);
1
if di ∈J(e) −I(e);
0
otherwise
for 1 ≤i ≤L. Thus with probability 1 the new marking is s + u when the
marking is s and a deterministic transition e ﬁres.
The marking set G of a restricted spn need not be speciﬁed explicitly.
Rather, G can be deﬁned in terms of the building blocks as follows. Write
s →s′ for s, s′ ∈ZL
+ if P { s + U(E∗) = s′ } > 0 for some E∗⊆E(s).
We say that s′ ∈ZL
+ is reachable from s ∈ZL
+ and write s ; s′ if either
s →s′ or there exist markings s(1), s(2), . . . , s(n) ∈∈ZL
+ (n ≥1) such that
s →s(1) →· · · →s(n) →s′. Given these deﬁnitions, take
G =

s ∈ZL
+ : ¯s0 ; s

,

66
2. Modelling with Stochastic Petri Nets
the set of markings reachable from the initial marking ¯s0. New-marking
probabilities can be deﬁned in terms of the building blocks by setting
p(s′; s, E∗) = ˜p(s −s′; E∗) for s′, s ∈ZL
+ and E∗⊆E(s).
Deterministic spns form an important subclass of restricted spns. An
spn is deterministic if every transition is deterministic and, whenever more
than one immediate transition becomes enabled in a marking, the marking
changes as if exactly one of the transitions—selected according to a prob-
ability distribution—ﬁres. Thus, for E∗= { ei1, ei2, . . . , eil } ⊆E′, we have
the representation
˜p( · ; E∗) =
l

k=1
ak ˜p( · ; eik),
where a1, a2, . . . , al are probabilities that depend on E∗and sum to 1.
All our results for standard spns as deﬁned in Section 2.1 automatically
apply to restricted and deterministic spns. It is intuitively clear that re-
stricted spns have less modelling power than standard spns. Nonetheless,
restricted spns can model a usefully large class of discrete-event stochastic
systems. It can be shown in particular that for any gsmp with ﬁnite state
space, unit speeds, and a ﬁxed initial state, there exists a restricted spn
with a marking process that behaves the same way—more precisely, the
marking process “strongly mimics” the gsmp as deﬁned in Chapter 4. If,
with probability 1, events in the gsmp never occur simultaneously, then the
gsmp can be strongly mimicked using a deterministic spn. Moreover, for
any spn having unit speeds, a ﬁnite marking set, a ﬁxed initial marking, and
timed transitions that with probability 1 never ﬁre simultaneously, there
exists a deterministic spn that behaves the same way; see Remarks 3.2 and
4.11 in Chapter 4.
In practice, it is often convenient to exploit the full generality of our origi-
nal spn formulation to obtain a concise representation of a speciﬁed system.
Indeed, as shown by the queue with batch arrivals in Example 2.4, this gen-
erality sometimes is essential. On the other hand, if a system can be mod-
elled as a deterministic spn, then key properties such as k-boundedness,
“liveness,” and the existence of “invariants” can be determined using analy-
sis techniques for ordinary Petri nets. An spn is live if at least one transition
is enabled in each reachable marking, and an invariant is a linear algebraic
relation between the token counts in the places of the net that holds for
every reachable marking.
Notes
The discussion of spn building blocks in Section 2.1 follows Haas and
Shedler (1989b). Both the notation and the formulation of the building
blocks were originally motivated by the discussion of generalized semi-

2. Notes
67
Markov processes in Whitt (1980). As shown in Chapter 4, spns and gsmps
are closely related.
Kosaraju (1973) uses an untimed version of the producer–consumer sys-
tem to illustrate the limited modelling power of ordinary Petri nets without
inhibitor input places; see Section 7.1 in Peterson (1981). A discussion of
pri preemption can be found in Bobbio et al. (1995). The descriptions of
ring and bus networks are based on work in Eswaran et al. (1978) and
Loucks et al. (1982); see also Iglehart and Shedler (1983, 1984) and Haas
and Shedler (1985a, 1985b). The ﬂexible manufacturing system and the
manufacturing cell with robots are presented in Ajmone Marsan et al.
(1987) and Viswanadham and Narahari (1988), respectively; the current
exposition of these models is based on the discussion in Haas and Shedler
(1992). The particle-counter model of Example 2.11 corresponds to the
“type II counter” described in Section 5.3 of Karlin and Taylor (1975); see
also Haas and Shedler (1991).
The spsim prototype system for simulation of stochastic processes was
developed by Jochens and Shedler (1989). spsim can be used to specify and
simulate both gsmps and spns. For details of the original spsim system
and subsequent extensions, see Jochens and Shedler (1989), Bergman and
Shedler (1993), and Shedler (1994).
Hack (1975) originally suggested the use of numerical priorities in ordi-
nary Petri nets. Priority schemes of various types have since been incorpo-
rated into spn formalisms; see, for example, Chapter 4 in Ajmone Marsan
et al. (1995). The latter reference also discusses various notions of conﬂict
between transitions. As indicated in Section 2.3, we view priorities not as
a basic spn building block, but rather as a convenient means for concise
speciﬁcation of the new-marking probabilities. For nets in which an en-
abled transition always remains enabled until it ﬁres, Haas and Shedler
(1987c) give conditions under which the value of the right side of (3.4) is
independent of the ordering π.
The spns deﬁned in Section 2.4 (especially the deterministic spns) are
similar in spirit to many spn formulations in the literature. For such nets,
the set G is called the reachability set of the spn. Determining the reachabil-
ity set—or properties of the reachability set such as ﬁniteness, k-bounded-
ness, and liveness—is nontrivial. As mentioned previously, analysis methods
for ordinary Petri nets are applicable when all transitions are deterministic;
see Peterson (1981) and Reisig (1985) for an introduction to some of these
methods, and see Janˇcar (2000) and Kosten and Tchoudaikina (1998) for
recent discussions about the reachability problem.

This page intentionally left blank 

3
The Marking Process
The marking process of an spn records the marking as it evolves over con-
tinuous time. As discussed in Section 3.1, formal deﬁnition of the marking
process is in terms of an underlying general state-space Markov chain that
describes the net at successive marking changes. This deﬁnition leads to an
algorithm for generating sample paths of the process.
Many performance measures such as long-run utilization, average rev-
enue, availability, and throughput can be speciﬁed as time-average limits
of the marking process or underlying chain—or as functions of such lim-
its. In Section 3.2 we illustrate the speciﬁcation of long-run performance
measures through a variety of examples. In the process, we show how limit
theorems in discrete time can be used to obtain limit theorems in contin-
uous time. These results highlight the key role of the underlying chain in
the analysis of long-run spn behavior.
The “lifetime” of a marking process is the supremum of the successive
times at which the marking changes. The lifetime must be almost surely
(a.s.) inﬁnite for time-average limits to be well deﬁned. For some spns,
however, inﬁnitely many marking changes can occur in a ﬁnite time in-
terval, so that the lifetime is ﬁnite. Such pathological behavior occurs if
the process is absorbed into the set S′ of immediate markings or if the
marking changes occur ever more rapidly so that the sequence of occur-
rence times has an accumulation point. In the presence of nonexponential
clock-setting distributions, this latter type of “explosion” can occur with
probability 1 even when the expected time between successive marking
changes increases linearly. In Section 3.3 we give conditions under which
the lifetime is a.s. inﬁnite. These conditions are mild and are satisﬁed by

70
3. The Marking Process
most spns encountered in practice. Our proof rests on a “geometric trials”
recurrence criterion, which also is used in subsequent chapters to estab-
lish the regenerative property for both marking processes and sequences of
delays.
When the marking process of an spn is a continuous-time Markov chain
(ctmc), the sequence of successive timed markings forms a discrete-time
Markov chain and, given this sequence, the successive times between state
transitions of the marking process are independent and exponentially dis-
tributed. This special structure makes it possible, in principle, to compute
time-average limits either analytically or numerically. One might expect
that the marking process of an spn is a ctmc if each clock-setting distri-
bution is exponential. This result is not quite true: the marking process can
fail to have the Markov property when the clock-setting distribution func-
tion explicitly depends on the current and new marking. In the absence of
such explicit dependence, however, the Markov property does indeed hold,
as shown in Section 3.4. The proof of this result leads to explicit formulas
for the elements of the inﬁnitesimal generator matrix of the process. As
a key step in establishing the Markov property, we determine the condi-
tional distribution of the clock-reading vector, given the “partial history” of
the underlying chain of the marking process. This conditional distribution
plays a central role in the recurrence and regeneration results developed in
subsequent chapters.
3.1
Deﬁnition of the Marking Process
In this section we deﬁne the marking process of an spn in terms of a Markov
chain that takes values in an uncountably inﬁnite set. To prepare for this
deﬁnition, we ﬁrst give a brief introduction to general state-space Markov
chains.
3.1.1
General State-Space Markov Chains
A Markov process is a stochastic process whose future evolution depends
on the past and present only through the current state. Consider a Markov
process that evolves in discrete time and takes values in an arbitrary state
space Γ. If Γ is ﬁnite or countably inﬁnite—the simplest and most familiar
case—then the process is called a discrete-time Markov chain (dtmc); see
Section A.2.4 for a discussion of dtmcs. A time-homogeneous dtmc can
be characterized in terms of an initial distribution together with a “tran-
sition matrix.” The (i, j)th entry of the matrix is the probability, starting
in state i, that the chain next hits state j. When Γ is uncountably inﬁ-
nite, however, the probability that the chain hits a speciﬁed element of Γ
typically is equal to 0, and the notion of a transition matrix is not useful.

3.1 Deﬁnition of the Marking Process
71
The appropriate generalization of the transition matrix is the transition
kernel P: the quantity P(z, A) is the probability, starting in state z, that
the chain next hits a state that is an element of the set A.
Deﬁnition 1.1. The discrete-time stochastic process { Zn : n ≥0 } deﬁned
on a probability space (Ω, F, Pµ) and taking values in Γ is a (time-homo-
geneous) general state-space Markov chain with initial distribution µ and
transition kernel P if
Pµ { Z0 ∈A } = µ(A)
(1.2)
and
Pµ { Zn+1 ∈A | Zn, Zn−1, . . . , Z0 } = P(Zn, A) a.s.
(1.3)
for n ≥0 and A ⊆Γ.
We write Pµ for the probability law of the chain to emphasize the depen-
dence on the initial distribution µ. We sometimes refer to a family of chains
having a speciﬁed transition kernel P and indexed by the initial distribu-
tion µ somewhat loosely as “the chain with transition kernel P.” Similarly,
we sometimes say that a speciﬁed property holds for “the” chain “when
the initial distribution is µ,” meaning of course that the property holds for
a speciﬁc member of the family.
Typically, µ and P are completely determined by the values { µ(A): A ∈
A } and { P(z, A): z ∈Γ and A ∈A }, respectively, where A is a collection
of subsets of Γ that have a relatively simple form. For example, when S
is a ﬁnite or countably inﬁnite set and Γ ⊆S × ℜK
+ for some K ≥1, we
usually can take A to be the collection of all sets of the form
A = { s } × [0, a1] × [0, a2] × · · · × [0, aK],
where s ∈S and a1, a2, . . . , aK ≥0.
The ﬁnite-dimensional distributions of the chain can be computed using
the relation
Pµ { Z0 ∈A0, Z1 ∈A1, . . . , Zn ∈An }
=

A0
µ(dz0)

A1
P(z0, dz1) · · ·

An−1
P(zn−2, dzn−1)P(zn−1, An)
(1.4)
for n ≥0 and A0, A1, . . . , An ⊆Γ. Denote by Eµ the expectation operator
associated with Pµ. When the initial state is equal to z ∈Γ with probabil-
ity 1, that is, µ({z}) = 1, we often write Pz for the probability law of the
chain and Ez for the associated expectation. Deﬁne the n-step transition
kernels for the chain by setting P n(z, A) = Pz { Zn ∈A } for n ≥0; observe
that P 0(z, A) = 1A(z) and P 1(z, A) = P(z, A). It follows from (1.4) that
the kernels { P n : n ≥0 } satisfy the Chapman–Kolmogorov equations:

72
3. The Marking Process
P n+m(z, A) =

Γ
P n(z, dz′)P m(z′, A)
(1.5)
for z ∈Γ, A ⊆Γ and m, n ≥0.
A chain can be deﬁned by specifying an initial distribution µ and tran-
sition kernel P: for any choice of µ and P there exist a probability space
(Ω, F, Pµ) and a stochastic process { Zn : n ≥0 } such that (1.2) and (1.3)
hold. A standard construction of { Zn : n ≥0 } from µ and P uses Kol-
mogorov’s existence theorem (Proposition 2.1 in the Appendix). In this
construction, Ω= Γ∞, so that each ω ∈Ωhas the form ω = (ω0, ω1, . . .),
where ωn ∈Γ for n ≥0. The chain is then deﬁned as the coordinate
projection function on Γ∞: Zn(ω) = ωn for n ≥0.
A general state-space Markov chain enjoys the strong Markov property,
which asserts that the equality in (1.3) holds when the deterministic index
n is replaced by a stopping time N:
Pµ { ZN+1 ∈A | ZN, ZN−1, . . . , Z0 } = P(ZN, A) a.s.
(1.6)
for A ⊆Γ. Here N is a stopping time with respect to the chain { Zn : n ≥0 }
if for each n ≥0 the occurrence or nonoccurrence of the event { N = n }
is completely determined by Z0, Z1, . . . , Zn; see Section A.1.5 for further
discussion of stopping times.
3.1.2
Deﬁnition of the Continuous-Time Process
Formal deﬁnition of the marking process proceeds as follows. Recall that
G is the set of markings of the spn, S is the set of timed markings, and
S′ is the set of immediate markings. Similarly, E is the set of transitions
and E′ (⊆E) is the set of immediate transitions. Finally, recall that E(s)
is the set of enabled transitions and r(s, e) is the speed at which the clock
for enabled transition e runs down when the marking is s. Denote by C(s)
the set of possible clock-reading vectors when the marking is s:
C(s) =

c = (c1, . . . , cM): ci ≥0
and ci > 0 if and only if ei ∈E(s) −E′ 
.
Here the ith component of a clock-reading vector c = (c1, . . . , cM) is the
clock reading associated with transition ei. Implicit in our deﬁnition is the
convention that the reading on the clock for a disabled transition is 0.
Beginning in marking s with clock-reading vector c = (c1, . . . , cM) ∈C(s),
the time t∗(s, c) to the next marking change is given by
t∗(s, c) =
min
{ i: ei∈E(s) } ci/r(s, ei),
(1.7)
where ci/r(s, ei) is taken to be +∞when r(s, ei) = 0. We sometimes refer
to t∗as the holding-time function of the spn. The set of transitions E∗(s, c)

3.1 Deﬁnition of the Marking Process
73
that ﬁre simultaneously and trigger the next marking change is given by
E∗(s, c) = { ei ∈E(s): ci −t∗(s, c)r(s, ei) = 0 } .
(1.8)
Observe that E∗(s, c) = E′ ∩E(s) whenever s ∈S′ and E∗(s, c) ⊆E −E′
whenever s ∈S; in the former case, t∗(s, c) = 0.
Next consider a general state-space Markov chain { (Sn, Cn): n ≥0 } tak-
ing values in the set
Σ =

s∈G

{ s } × C(s)

,
where Sn = (Sn,1, Sn,2, . . . , Sn,L) represents the marking and Cn = (Cn,1,
Cn,2, . . . , Cn,M) represents the clock-reading vector just after the nth mark-
ing change. The transition kernel of the chain is given by
P

(s, c), A

= p(s′; s, E∗)

ei∈N
F(ai; s′, ei, s, E∗)

ei∈O
1[0,ai](c∗
i )
(1.9)
for all sets
A = { s′ } ×

(c′
1, c′
2, . . . , c′
M) ∈C(s′): 0 ≤c′
i ≤ai for 1 ≤i ≤M

,
where c∗
i = ci −t∗(s, c)r(s, ei), E∗= E∗(s, c), N = N(s′; s, E∗), and
O = O(s′; s, E∗). The right side of (1.9) is the probability, beginning
with marking s and clock-reading vector c, that the spn changes marking
to s′ with the reading c′
i on the clock associated with enabled transition
ei ∈E(s′) set to a value in [0, ai]. Speciﬁcation of the transition kernel P
for each set A of the above form is suﬃcient to uniquely determine P.
In more detail, the leftmost term on the right side of (1.9) is the prob-
ability that the new marking is s′ when the current marking is s and the
transitions in E∗= E∗(s, c) ﬁre simultaneously. Each remaining term rep-
resents the conditional probability that the clock for a transition ei has a
value in [0, ai] just after the marking change, given that the new marking is
s′. The probabilities for the new transitions are multiplied together, since
clocks for such transitions are set independently. For each old transition
ei ∈O(s′; s, E∗), the clock reading changes deterministically from ci to
c∗
i = ci −t∗(s, c)r(s, ei). The probability that the clock reading for ei has
a value in [0, ai] just after the marking change is therefore equal to 0 or
1, depending on whether c∗
i ∈[0, ai]. Thus the joint probability that the
clock for each old transition ei has a value in [0, ai] is a product of indica-
tor functions as in (1.9). For a transition ei ̸∈E(s′), the associated clock
reading is 0 by convention, so that ei ∈[0, ai] with probability 1 for any
ai ≥0; the right side of (1.9) is therefore implicitly multiplied by a factor
of 1 for each such ei.
Denote by µ the initial distribution of the chain; that is, for any subset
B ⊆Σ, the quantity µ(B) represents the probability that (S0, C0) ∈B.
Denote by Pµ the probability law of the chain when the initial distribution is

74
3. The Marking Process
µ. As discussed in Section 2.1, the initial marking s0 is selected according to
a (possibly degenerate) initial-marking distribution function ν0 and then,
for each enabled transition ei ∈E(s0), the corresponding clock reading
c0,i is generated according to an initial clock-setting distribution function
F0( · ; ei, s0). Thus the initial distribution µ is of the form
µ(A) = ν0(s0)

e∈E(s0)
F0(ai; e, s0)
(1.10)
for all sets
A = { s0 } ×

(c0,1, . . . , c0,M) ∈C(s0): 0 ≤c0,i ≤ai for 1 ≤i ≤M

.
Example 2.2 in the Appendix contains further details about the construc-
tion of the chain { (Sn, Cn): n ≥0 }.
Finally, construct a continuous-time process {X(t): t ≥0} from { (Sn,
Cn): n ≥0 } in the following manner. Let ζn (n ≥0) be the (nonnegative,
real-valued) time of the nth marking change: ζ0 = 0 and
ζn =
n−1

k=0
t∗(Sk, Ck)
(1.11)
for n ≥1. Let ∆̸∈G and set
X(t) =

SN(t)
if N(t) < ∞;
∆
if N(t) = ∞,
(1.12)
where
N(t) = sup { n ≥0: ζn ≤t } .
(1.13)
The stochastic process { X(t): t ≥0 } deﬁned by (1.12) is the marking pro-
cess of the spn. By construction, the marking process takes values in the
set S ∪{ ∆} and has piecewise-constant, right-continuous sample paths.
Observe that X(t) = ∆for at least one ﬁnite time point t if and only if the
lifetime of the marking process, deﬁned by
τ∆= sup
n≥0
ζn,
is ﬁnite. As with Markov chains, we sometimes use loose terminology when
referring to a family of marking processes that diﬀer only in the initial
distribution µ.
We often denote by E∗
n = E∗(Sn, Cn) the random set of transitions that
ﬁre simultaneously and trigger the (n + 1)st marking change (n ≥0) and
by t∗
n = t∗(Sn, Cn) the time between the nth and (n+1)st marking change.
Let { γ(n): n ≥0 } be the indices of the successive marking changes at
which the new marking is timed: γ(−1) = −1 and
γ(n) = inf { j > γ(n −1): Sj ∈S }
(1.14)

3.1 Deﬁnition of the Marking Process
75
for n ≥0. Deﬁne the embedded chain { (S+
n , C+
n ): n ≥0 } by setting
(S+
n , C+
n ) = (Sγ(n), Cγ(n))
(1.15)
for n ≥0. Suppose that Pµ { Sn ∈S i.o. } = 1, so that each random index
γ(n) is a.s. ﬁnite—suﬃcient conditions for this assumption to hold are
given in Section 3.3.1. Because each random index γ(n) is a stopping time
with respect to the underlying chain { (Sn, Cn): n ≥0 }, it follows from the
strong Markov property for { (Sn, Cn): n ≥0 } that { (S+
n , C+
n ): n ≥0 } is
indeed a well-deﬁned general state-space Markov chain. Denote by Σ+ and
µ+ the state space and initial distribution, respectively, of the embedded
chain:
Σ+ = { (s, c) ∈Σ: s ∈S }
and
µ+(A) = Pµ

(S+
0 , C+
0 ) ∈A

for A ⊆Σ+.
3.1.3
Generation of Sample Paths
The form of the transition kernel in (1.9) leads to the following algorithm
for generating sample paths of the underlying chain { (Sn, Cn): n ≥0 }.
Algorithm 1.16 (Sample path generation for the underlying chain)
1. (Initialization) Set ζ = 0. Select an initial marking s ∈G accord-
ing to the probability mass function ν0. For each enabled transition
ei ∈E(s), generate a corresponding clock reading ci according to
the clock-setting distribution function F0( · ; ei, s). Set ci = 0 for each
ei ̸∈E(s).
2. Determine the set E∗of transitions that ﬁre simultaneously and trig-
ger the next marking change: ei ∈E∗if and only if ci/r(s, ei) ≤
cj/r(s, ej) for all j ̸= i. Also determine the time t∗to the next mark-
ing change as t∗= ci∗/r(s, ei∗), where i∗is any index such that
ei∗∈E∗.
3. Generate the new marking s′ according to the probability mass func-
tion p( · ; s, E∗).
4. For each transition ei ∈N(s′; s, E∗) = E(s′) −

E(s) −E∗
, gen-
erate a new clock reading c′
i according to the distribution function
F( · ; s′, ei, s, E∗).
5. For each transition ei ∈O(s′; s, E∗) = E(s′) ∩

E(s) −E∗
, set c′
i =
ci −t∗(s, c)r(s, ei).
6. For each transition ei ∈

E(s) −E∗
−E(s′), set c′
i = 0.

76
3. The Marking Process
7. Go to step 2 and iterate with s′ playing the role of s and c′ the role
of c.
At each marking change, the sets of transitions that become enabled and
disabled must be determined. A naive approach to this task examines each
transition e ∈E; a better approach is as follows. Recall that I(e), L(e),
and J(e) are the sets of normal input places, inhibitor input places, and
output places, respectively, for transition e ∈E. Set
B1(e∗) = { e ∈E : I(e) ∩J(e∗) ̸= ∅or L(e) ∩I(e∗) ̸= ∅}
and
B2(e∗) = { e ∈E : I(e) ∩I(e∗) ̸= ∅or L(e) ∩J(e∗) ̸= ∅} .
The deﬁnition of the set B2(e∗) is closely related to the deﬁnition of conﬂict
in Section 2.3.2: if e ∈B2(e∗), then transition e∗, upon ﬁring, can poten-
tially remove a token from a normal input place for transition e or deposit
a token in an inhibitor input place. The set B1(e∗) is deﬁned in the oppo-
site manner: if e ∈B1(e∗), then transition e∗, upon ﬁring, can potentially
deposit a token in a normal input place for transition e or remove a token
from an inhibitor input place. Observe that, at a marking change from s
to s′ triggered by the simultaneous ﬁring of the transitions in E∗,
N(s′; s, E∗) ⊆

e∗∈E∗
B1(e∗)
(1.17)
and

E(s) −E∗
−E(s′) ⊆

e∗∈E∗
B2(e∗).
(1.18)
Typically, the sets B1(e∗) and B2(e∗) are small for each e∗∈E∗and
the set E∗is also small. Thus, even when the set E is large, relatively
few transitions need be examined to update the set of enabled transitions
from E(s) to E(s′). Moreover, the sets { B1(e∗), B2(e∗): e∗∈E } can be
computed prior to generation of sample paths and then quickly accessed as
needed.
A sample path of the marking process can be obtained from a sample
path of the chain { (Sn, Cn): n ≥0 }. As in (1.14), let { γ(n): n ≥0 } be
the indices of the successive marking changes at which the new marking
is timed. Also let ζn be the time of the nth marking change as deﬁned
in (1.11). A sample path of the marking process can be represented as a
sequence { (Xn, Tn): n ≥0 }, where Tn = ζγ(n) and Xn = X(Tn). The fol-
lowing algorithm produces a realization of the sequence { (Xn, Tn): n ≥0 }.

3.2 Performance Measures
77
Algorithm 1.19 (Sample path generation for the marking process)
1. (Initialization) Set k = −1, n = 0, and T0 = 0.
2. Increment k by 1.
3. If t∗(Sk, Ck) = 0, increment k by 1 repeatedly until t∗(Sk, Ck) > 0.
4. Set Xn = Sk and Tn+1 = Tn + t∗(Sk, Ck).
5. Increment n by 1 and go to step 2.
3.2
Performance Measures
Long-run performance measures for an spn are usually speciﬁed in terms
of the marking process { X(t): t ≥0 } or underlying chain { (Sn, Cn): n ≥
0 }. In this section we give a brief survey of typical long-run performance
measures and show that each such measure can be expressed as a function
of time-average limits of the underlying chain. Thus an understanding of
the long-run behavior of the underlying chain is essential when studying
the long-run behavior of an spn.
3.2.1
Simple Time-Average Limits and Ratios
Many performance measures of interest can be expressed as limits of the
form
r(f) = lim
t→∞
1
t
 t
0
f

X(u)

du,
(2.1)
r(f1, f2) = lim
t→∞
 t
0 f1

X(u)

du
 t
0 f2

X(u)

du
,
(2.2)
or
˜r( ˜f 1, ˜f 2) = lim
n→∞
	n
j=0 ˜f 1(Sk, Ck)
	n
k=0 ˜f2(Sk, Ck)
,
(2.3)
where f, f1, and f2 are real-valued functions deﬁned on G, and ˜f 1 and ˜f 2
are real-valued functions deﬁned on Σ.
Example 2.4 (Producer–consumer system with nonpreemptive priority).
For the system of Example 2.1 in Chapter 2, let r be the long-run fraction
of time that the channel is busy; this quantity is often referred to as the
utilization of the channel. Suppose that this system is modelled using the
spn in Figure 2.4. Then r can be speciﬁed as a limit of the form (2.1),

78
3. The Marking Process
where f(s) = 1 −s7 for s = (s1, s2, . . . , s7) ∈G. Suppose that the channel
generates revenue at rate βi whenever a transmission to consumer i is
underway (i = 1, 2). Then the system’s long-run average revenue is of the
form (2.1), where f(s) = β1s3 + β2s6 for s = (s1, s2, . . . , s7) ∈G.
Example 2.5 (System availability). Measures of long-run system availabil-
ity often are of the form (2.1). Here f(s) = 1 if the marking s corresponds
to a state in which the system is operational, and f(s) = 0 otherwise.
Example 2.6 (Manufacturing cell with robots). For the system of Exam-
ple 3.6 in Chapter 2, let r be the long-run utilization of robot 1 relative to
robot 2. Suppose that this system is modelled using the spn in Figure 2.21.
Then r can be speciﬁed as a limit of the form (2.2), where f1(s) = 1 −s22
and f2(s) = 1 −s24 for s = (s1, s2, . . . , s24) ∈G.
Example 2.7 (Token ring). For the system of Example 2.6 in Chapter 2, let
r be the long-run fraction of ring-token arrival times at port 1 at which there
is a packet awaiting transmission. Suppose that this system is modelled
using the spn in Figure 2.10 and that, with probability 1, two or more
events never occur simultaneously. Then r can be speciﬁed as a limit of the
form (2.3), where
˜f 1(s, c) =

1
if E∗(s, c) = { e3,1 } and s1,1 = 1;
0
otherwise
and
˜f 2(s, c) =

1
if E∗(s, c) = { e3,1 };
0
otherwise.
3.2.2
Conversion of Limit Results to Continuous Time
This section is concerned with the problem of obtaining limit theorems
for continuous-time performance measures—that is, performance measures
expressed in terms of the marking process—from limit theorems for the
underlying chain. Theorem 2.9 below, although elementary, provides a use-
ful and general means of converting discrete-time results into limit the-
orems in continuous time. Let { Xn : n ≥0 }, { Yn : n ≥1 }, { Y ′
n : n ≥1 },
and { ∆n : n ≥1 } be sequences of a.s. ﬁnite real-valued random variables
with each Y ′
n and ∆n nonnegative, and let x, y, y′, w, w′, and δ be ﬁnite
constants with y′ ≥0 and δ > 0. Moreover, suppose that each Yk and Y ′
k can
be represented in terms of a real-valued stochastic process { Z(t): t ≥0 }
as
Yk = Z(Tk) −Z(Tk−1)

3.2 Performance Measures
79
and
Y ′
k =
sup
Tk−1≤t≤Tk
Z(t) −Z(Tk−1)
,
where T0 = 0 and Tk = 	k
j=1 ∆j for k ≥1. Theorem 2.9 is useful when we
can establish limit results of the form
lim
n→∞
1
n
n−1

k=0
Xk = x a.s.,
(2.8a)
lim
n→∞
1
n
n

k=1
∆k = δ a.s.,
(2.8b)
lim
n→∞
1
n
n

k=1
Xk−1∆k = w a.s.,
(2.8c)
lim
n→∞
1
n
n

k=1
|Xk−1|∆k = w′ a.s.
(2.8d)
lim
n→∞
1
n
n

k=1
Yk = y a.s.,
(2.8e)
or
lim
n→∞
1
n
n

k=1
Y ′
k = y′ a.s..
(2.8f)
For t ≥0, set N(t) = sup { n ≥0: Tn ≤t } and X(t) = XN(t).
Theorem 2.9. Let the sequences { Xn : n ≥0 }, { Yn : n ≥0 }, { Y ′
n : n ≥
0 }, and { ∆n : n ≥1 } be as above.
(i) If (2.8a) holds, then limn→∞Xn/n = 0 a.s..
(ii) Without further conditions, limt→∞N(t) = ∞a.s.. If, moreover,
(2.8b) holds, then limt→∞N(t)/t = 1/δ a.s..
(iii) If (2.8a) and (2.8b) hold, then limt→∞(1/t) 	N(t)
k=0 Xn = x/δ a.s..
(iv) If (2.8b) and (2.8c) hold, and either (2.8d) holds or |Xn−1|∆n/n →0
a.s., then limt→∞(1/t)
 t
0 X(u) du = w/δ a.s..
(v) If (2.8b) and (2.8e) hold, and either (2.8f) holds or Y ′
n/n →0 a.s.,
then limt→∞Z(t)/t = y/δ a.s..
Remark 2.10.
Of course, if (2.8d) holds for some ﬁnite nonnegative w′,
then (2.8c) holds for some ﬁnite w. Similarly, (2.8e) holds whenever (2.8f)
holds.

80
3. The Marking Process
Proof. The assertion in (i) follows from the fact that
lim
n→∞
Xn
n = lim
n→∞

1
n
n

k=1
Xk −
n −1
n

1
n −1
n−1

k=1
Xk

= x −x = 0 a.s..
The ﬁrst part of the assertion in (ii) follows because each ∆n is a.s. ﬁnite
by assumption: formally,
P

lim
t→∞N(t) = ∞

= P { ∆n < ∞for n ≥1 }
≥1 −
∞

n=1
P { ∆n = ∞}
= 1,
where we have used Bonferroni’s inequality [Proposition 1.1(vi) in the Ap-
pendix]. To prove the remaining part of the assertion in (ii), observe that
TN(t) ≤t ≤TN(t)+1 for t ≥0, so that
TN(t)
N(t) ≤
t
N(t) ≤TN(t)+1
N(t) .
(2.11)
Thus, by (2.8b) and the fact that, as discussed above, limt→∞N(t) = ∞
a.s., the outermost terms in (2.11) each converge to δ with probability 1, and
the desired result follows. The assertion in (iii) follows from the assertions
in (i) and (ii), because N(t) →∞a.s. and
lim
t→∞
1
t
N(t)

k=0
Xn = lim
t→∞
N(t)
t
1
N(t)
N(t)

k=0
Xn = δ−1 x a.s..
The assertion in (iv) follows directly from the assertion in (v)—take Z(t) =
 t
0 X(u) du and observe that Y ′
n ≤|Xn−1|∆n for n ≥1. To prove the
assertion in (v), assume without loss of generality that Z(0) = 0 and write
lim
t→∞
Z(t)
t
= lim
t→∞

1/N(t)
 	N(t)
k=1 Yk + R1(t)

1/N(t)
 	N(t)
k=1 ∆k + R2(t)
,
where R1(t) =

Z(t) −Z(TN(t))

/N(t) and R2(t) = (t −TN(t))/N(t). It
suﬃces to show that the remainder terms R1(t) and R2(t) each converge
to 0 a.s. as t →∞. To show that limt→∞R1(t) = 0 a.s., observe that
|R1(t)| ≤
Y ′
N(t)+1
N(t)
for t ≥0. Since N(t) →∞a.s., the desired result follows immediately,
provided that Y ′
n/n →0 a.s.. If (2.8f) holds, then this latter convergence
follows from the assertion in (i). An almost identical argument shows that
R2(t) →0 a.s., and the desired result follows.

3.2 Performance Measures
81
Example 2.12 (Time-average limits of the marking process). For an spn
with ﬁnite marking set G and underlying chain { (Sn, Cn): n ≥0 }, deﬁne
the holding-time function t∗as in (1.7) and let f be a ﬁnite real-valued
function deﬁned on G. In later chapters we show that, under appropriate
stability conditions,
lim
n→∞
1
n
n−1

k=0
t∗(Sk, Ck) = δ a.s.,
lim
n→∞
1
n
n−1

k=0
f(Sk)t∗(Sk, Ck) = w a.s.,
and
lim
n→∞
1
n
n−1

k=0
|f(Sk)| t∗(Sk, Ck) = w′ a.s.
for ﬁnite constants δ, w, and w′ with δ > 0. It then follows from Theo-
rem 2.9(iv) that a time-average limit of the form (2.1) can be expressed in
the form (2.3), where ˜f 1(s, c) = f(s)t∗(s, c) and ˜f 2(s, c) = t∗(s, c). Simi-
larly, a time-average limit of the form (2.2) can be expressed in the form
(2.3), where ˜f 1(s, c) = f1(s)t∗(s, c) and ˜f 2(s, c) = f2(s)t∗(s, c).
3.2.3
Rewards and Throughput
Consider an spn model in which rewards accrue continuously over time and
also at an increasing sequence of random time points—the latter type of
rewards are sometimes called impulse rewards. Speciﬁcally, suppose that
• Rewards accrue at ﬁnite rate q(s) whenever the marking is equal to
s ∈S.
• Starting with marking s and clock-reading vector c just after a mark-
ing change, an impulse reward equal to v(s, c) accrues at the next
marking change.
For example, the function v might have the form
v(s, c) =

v0
if s = ˜s and E∗(s, c) = { ˜e };
0
otherwise
for some ˜s ∈G and ˜e ∈E(˜s), so that an impulse reward of v0 accrues
whenever the current marking is equal to ˜s and transition ˜e ﬁres. Denote
by R(t) the (random) total reward earned over the interval [0, t]. Formally,
set ˜h(s, c) = q(s)t∗(s, c) + v(s, c) for (s, c) ∈Σ and set
R(t) =
N(t)

k=0
˜h(Sk, Ck) −D1(t) −D2(t),
(2.13)

82
3. The Marking Process
where N(t) is the number of marking changes in the interval (0, t], D1(t) =
q(SN(t))(ζN(t)+1 −t), and D2(t) = v(SN(t), CN(t)).
Theorem 2.14. Suppose that
lim
n→∞
1
n
n−1

k=0
t∗(Sk, Ck) = δ a.s.
and
lim
n→∞
1
n
n−1

k=0
˜h(Sk, Ck) = x a.s.
for ﬁnite constants δ and x with δ > 0. Also suppose that sups∈S |q(s)| < ∞
and sup(s,c)∈G |v(s, c)| < ∞. Then
lim
t→∞
R(t)
t
= x
δ a.s..
Proof. Set ¯v = sup(s,c)∈G |v(s, c)| and ¯q = sups∈S |q(s)|, and set
Y ′
n =
sup
ζn−1≤t≤ζn
R(t) −R(ζn−1)

for n ≥1. Observe that Y ′
n ≤¯qt∗(Sn−1, Cn−1) + ¯v for n ≥1, so that
Y ′
n/n →0 a.s. by Theorem 2.9(i). The desired result now follows from
Theorem 2.9(v)—take Z(t) = R(t) and ∆n = t∗(Sn−1, Cn−1).
Remark 2.15.
The assumption in Theorem 2.14 that sups∈S |q(s)| < ∞
and sup(s,c)∈G |v(s, c)| < ∞can be replaced by the assumption that
lim
n→∞
Y ′′
n
n = 0 a.s.,
where Y ′′
k
= |q(Sk)|t∗(Sk, Ck) + |v(Sk, Ck)| for k ≥0. Indeed, we have
limn→∞Y ′
n/n ≤limn→∞Y ′′
n /n = 0 a.s., so that the desired result follows
from Theorem 2.9(v) as before. Of course, limn→∞Y ′′/n = 0 a.s. whenever
lim
n→∞
1
n
n−1

k=0
Y ′′
k < ∞a.s.,
by Theorem 2.9(i).
Example 2.16 (Supply chain). Consider a simple “make-to-stock” supply
chain for the manufacture and sale of ﬁnished items. The system consists
of two suppliers (numbered 1 and 2), an original equipment manufacturer

3.2 Performance Measures
83
Figure 3.1. Supply chain.
(oem), a truck, a warehouse, and a retail outlet; see Figure 3.1. The suppli-
ers are located near the oem and the warehouse is located near the retail
outlet, but the oem and warehouse are at some distance from each other.
Supplier i (i = 1, 2) provides raw parts of type i, and the oem produces ﬁn-
ished items from these raw parts. Periodically—in expectation of demand
for ﬁnished items—an order for one or more batches of parts of type 1
is sent to supplier 1 and, simultaneously, an order for the same number
of batches of parts of type 2 is sent to supplier 2. Each supplier ﬁlls its
respective order by delivering one batch at a time to the oem. The oem
produces ﬁnished items one batch at a time—the manufacture of a batch
of ﬁnished items requires one batch each of the two types of raw parts.
The oem is never idle when at least one batch of each type of raw part is
available. The truck conveys ﬁnished items to the warehouse one batch at
a time. To satisfy customer demands, the retail outlet periodically orders
a batch of ﬁnished items from the warehouse. If at least one batch is avail-
able, then the order is immediately ﬁlled; if no batches are available, then
the order is lost to the oem, and the batch of ﬁnished items is provided by
a competitor.
The time between successive placements of an order for raw parts is a
positive constant. The number of batches of raw parts in an order is a
positive integer constant that can depend (deterministically) on the state
of the system just before the placement of the order—that is, on the number
of batches of ﬁnished items on the truck and in the warehouse, the number
of unﬁlled orders at each of the suppliers, and the current supply of raw
parts at the oem. The successive times for a supplier to deliver a batch
of raw parts are i.i.d. as a positive random variable, as are the successive
times to manufacture a batch of ﬁnished items, the successive times to
convey a batch of ﬁnished items to the warehouse (and return the truck to
the oem), and the times between successive orders of ﬁnished items by the
retail outlet.
This system can be speciﬁed as an spn with timed and immediate tran-
sitions; see Figure 3.2. Each of places d1 and d9 always contains exactly one
token, reﬂecting the fact that the placement of orders for both raw parts
and ﬁnished items is always ongoing. Place d4 (resp., d5) contains n (≥0)

84
3. The Marking Process
e1 = placement of order for raw parts
e4 = delivery of batch of raw parts by supplier 1
e5 = delivery of batch of raw parts by supplier 2
e6 = creation of batch of ﬁnished items
e7 = delivery of batch of ﬁnished items to warehouse
e8 = placement of order by retail outlet
e9 = fulﬁllment of order for ﬁnished items
e10 = loss of order for ﬁnished items
Figure 3.2. spn representation of supply chain.

3.2 Performance Measures
85
tokens if and only if supplier 1 (resp., supplier 2) has a backlog of n batches
of raw parts that have been ordered but not yet delivered. Place d6 (resp.,
d7) contains n tokens if and only if there are n batches of parts of type 1
(resp., type 2) at the oem. Place d8 contains n tokens if and only if there
are n batches of ﬁnished items either awaiting shipment or being conveyed
to the warehouse. Place d10 contains n tokens if and only if there are n
batches of ﬁnished items at the warehouse. Place d11 contains one token if
an order from the retail outlet is being ﬁlled; otherwise, place d11 contains
no tokens. Place d12 contains one token if an order from the retail outlet
is about to be lost; otherwise, place d12 contains no tokens. We assume
throughout that transitions never ﬁre simultaneously.
All transitions except e2 and e8 are deterministic, and all speeds for en-
abled transitions are equal to 1. Whenever the marking is s and transition
e1 = “placement of order for raw parts” ﬁres, a token is deposited in place
d2 and transition e2 becomes enabled. By means of a mechanism similar
to that used for transition e2 in the spn model of the queue with batch
arrivals—see Example 2.4 in Chapter 2—transition e2 ﬁres m(s) times in
succession before becoming disabled, thereby depositing m(s) tokens in
place e3 and leaving place d2 with zero tokens. Here m(s) is a positive inte-
ger that depends in general on the marking s in which e1 ﬁres. Transition
e3 then ﬁres m(s) times in succession, depositing m(s) tokens in each of
places d4 and d5. In this manner, an order for m(s) batches of raw parts
is placed at each supplier. Whenever transition e8 = “placement of order
by retail outlet” ﬁres and place d10 contains at least one token, a token is
deposited in place d11; if place d10 contains no tokens, then a token is de-
posited in place d12. Thus the order is ﬁlled if at least one batch of ﬁnished
items is at the warehouse and is lost otherwise.
Denote by ai the cost to the oem of a batch of type i parts (i = 1, 2),
and suppose that the oem pays the supplier at the time of the order.
Similarly, denote by b the cost to the retail outlet of a batch of ﬁnished
items, and suppose that the retail outlet pays the oem at the time of the
order. Next, denote by h the cost to the oem of conveying a batch of parts
to the warehouse, and suppose that the oem pays the trucker at the time
of delivery. Finally, denote by u the inventory cost to the oem per unit
time for each batch of ﬁnished items stored at the warehouse, and denote
by w the remaining costs to the oem per unit time.
Deﬁne a reward structure as in (2.13) by setting q(s) = w + u · s10 and
v(s, c) =









−(a1 + a2)
if E∗(s, c) = { e2 };
−h
if E∗(s, c) = { e7 };
b
if E∗(s, c) = { e9 };
0
otherwise
for s = (s1, s2, . . . , s12) ∈G and c ∈C(s). Then the long-run average
reward coincides with the long-run average proﬁt to the oem.

86
3. The Marking Process
By specializing the foregoing reward structure, we can formally specify
a variety of throughput characteristics in discrete-event systems.
Example 2.17 (Throughput of manufacturing cell with robots). For the
spn in Figure 2.21, deﬁne a reward structure as in (2.13) by setting q(s) ≡0
and
v(s, c) =

1
if E∗(s, c) = { ˜e };
0
otherwise,
where ˜e = e16 = “end of transfer of a ﬁnished part from conveyor 2 to
the unloading area.” Then the long-run average reward coincides with the
long-run throughput of the manufacturing system.
3.2.4
General Functions of Time-Average Limits
As discussed above, many performance measures of interest can be ex-
pressed as ratios of time-average limits of the underlying chain.1 Other
performance measures can be expressed as more general functions of such
time-average limits.
Example 2.18 (Central moments). Let f be a real-valued function deﬁned
on S, and suppose that
lim
t→∞
1
t
 t
0
f

X(u)

du = r(f) a.s.
for some ﬁnite constant r(f). In this setting, long-run central moments may
also be of interest, for example, the long-run variance v(f) deﬁned by
v(f) = lim
t→∞
1
t
 t
0

f

X(u)

−r(f)
2
du.
If
lim
t→∞
1
t
 t
0
f 2
X(u)

du = r(f 2) a.s.
for some ﬁnite constant r(f 2), then we can write v(f) = r(f 2) −r2(f). Set
˜f 1(s, c) = f(s)t∗(s, c), ˜f 2(s, c) = f 2(s)t∗(s, c), and ˜f 3(s, c) = t∗(s, c) for
(s, c) ∈Σ. Also set
˜r( ˜f i) = lim
n→∞
1
n
n−1

k=0
˜f i(Sk, Ck)
1There has been no discussion so far of performance measures that pertain to system
delays. Such performance measures are treated at length in Chapter 8.

3.3 The Lifetime of the Marking Process
87
Figure 3.3. Absorption of the marking process into S′.
for i = 1, 2, 3. Provided that ˜r( ˜f 1), ˜r(| ˜f 1|), ˜r( ˜f 2), and ˜r( ˜f 3) are each well
deﬁned, an application of Theorem 2.9(iv) establishes the representation
v(f) = g

˜r( ˜f 1), ˜r( ˜f 2), ˜r( ˜f 3)

, where g(r1, r2, r3) = (r2/r3)−(r1/r3)2. Anal-
ogous representations can be obtained for higher central moments.
3.3
The Lifetime of the Marking Process
Limits of the form limt→∞(1/t)
 t
0 f

X(u)

du are not well deﬁned when
the lifetime τ∆of the marking process is ﬁnite, because f

X(t)

is not
deﬁned for t ≥τ∆. In this section we show how this pathological situation
can occur, and then we give mild conditions under which τ∆= ∞a.s., so
that the state space of the marking process can be restricted from S ∪{ ∆}
to S.
3.3.1
Absorption into the Set of Immediate Markings
The lifetime τ∆is ﬁnite if and only if an inﬁnite number of marking changes
occur in a ﬁnite time interval. This can occur if the sequence { Sn : n ≥0 }
is absorbed into the set S′ of immediate markings. Indeed, write τ∆=
	∞
n=0 t∗(Sn, Cn) and observe that the number of positive terms in the sum
is ﬁnite unless { Sn : n ≥0 } hits the set S of timed markings inﬁnitely
often.
Example 3.1 (Absorption into S′). Consider an spn with deterministic
transitions as in Figure 3.3. The marking set is G = { (1, 0, 0), (0, 1, 0),
(0, 0, 1) } and the initial marking is (1, 0, 0), as pictured in the ﬁgure. Af-
ter leaving timed marking (1, 0, 0), the marking process then alternates
between the immediate markings (0, 1, 0) and (0, 0, 1), never returning to
(1, 0, 0).
Although in general it can be hard to determine whether Pµ{ Sn ∈
S i.o. } = 1, the criterion given in Theorem 3.2 below often can be veriﬁed
in practice. For s ∈S′ and s′ ∈G, write s →s′ if p

s′; s, E(s) ∩E′
> 0.
We write S′ ; S if for each s′ ∈S′ there exists s ∈S such that either
s′ →s or there exist markings s(1), s(2), . . . , s(n) ∈S′ (n ≥1) such that
s′ →s(1) →· · · →s(n) →s.

88
3. The Marking Process
Theorem 3.2. Suppose that S′ is ﬁnite. Then Pµ{ Sn ∈S i.o. } = 1 for
any initial distribution µ if and only if S′ ; S.
Example 3.3 (Producer–consumer system with nonpreemptive priority).
For the spn of Example 2.1, observe that S′ is ﬁnite because G is ﬁnite.
It is trivial to verify that S′ ; S, and thus Pµ { Sn ∈S i.o. } = 1 by
Theorem 3.2.
Proving the necessity of the condition S′ ; S in Theorem 3.2 is triv-
ial. To prove suﬃciency, we use the following generalization of the Borel–
Cantelli lemma (Proposition 1.3 in the Appendix).
Lemma 3.4 (Geometric trials). Let { Yn : n ≥0 } be a sequence of ran-
dom variables deﬁned on a probability space (Ω, F, P) and taking values in
a set S, and let A be a ﬁxed subset of S. Suppose that there exists δ ∈(0, 1]
such that
P { Yn ∈A | Yn−1, . . . , Y0 } ≥δ a.s.
(3.5)
for n ≥1. Then P { Yn ∈A i.o. } = 1.
Proof. Deﬁne a sequence of random indices by I0 = 0 and
Ik = inf { n > Ik−1 : Yn ∈A }
for k ≥1. It suﬃces to show that P { Ik < ∞} = 1 for k ≥0 because then,
using Bonferroni’s inequality,
P { Yn ∈A i.o. } = P { Ik < ∞for k ≥0 }
≥1 −
∞

k=0
P { Ik = ∞}
= 1.
We use an inductive argument to show that each Ik is a.s. ﬁnite. Observe
that I0 is a.s. ﬁnite by deﬁnition and assume for induction that Ik is a.s.
ﬁnite for some value of k. Using (3.5) it follows that
P { Ik+1 −Ik > n, Ik = j }
= P { Yj+n ̸∈A, . . . , Yj+1 ̸∈A, Ik = j }
= E

P

Yj+n ̸∈A, . . . , Yj+1 ̸∈A, Ik = j
 Yj+n−1, . . . , Y0

= E

1{Yj+n−1̸∈A,...,Yj+1̸∈A,Ik=j}P { Yj+n ̸∈A | Yj+n−1, . . . , Y0 }

≤E

1{Yj+n−1̸∈A,...,Yj+1̸∈A,Ik=j}(1 −δ)

= (1 −δ)P { Ik+1 −Ik > n −1, Ik = j } ,
so that
P { Ik+1 −Ik > n, Ik = j } ≤(1 −δ)nP { Ik = j }
(3.6)

3.3 The Lifetime of the Marking Process
89
for n ≥1 and j ≥0. Because P { Ik < ∞} = 1 by the induction hypothesis,
we can sum (3.6) over j to obtain
P { Ik+1 −Ik > n } ≤(1 −δ)n
for n ≥1 so that, by Proposition 1.1(iv) in the Appendix, Ik+1 −Ik and
hence Ik+1 is a.s. ﬁnite.
It follows from the proof of Lemma 3.4 that
P { τA > n } ≤(1 −δ)n
(3.7)
for n ≥0, where τA = inf { n ≥1: Yn ∈A }.
Proof of Theorem 3.2. We prove suﬃciency only. For each s ∈S′, we
can ﬁnd an integer k = k(s) ≥1 and a sequence of markings s1 ∈S′, s2 ∈
S′, . . . , sk−1 ∈S′, sk ∈S, depending on s, such that s →s1 →s2 →· · · →
sk−1 →sk; such a sequence exists because S′ ; S. There may in fact be
many such sequences—ﬁx one and set
δ(s) = p

s1; s, E′ ∩E(s)

k

j=2
p

sj; sj−1, E′ ∩E(sj−1)

.
Next, set δ = mins∈S′ δ(s) > 0. Deﬁne an increasing sequence of random
indices { β(n): n ≥0 } by setting β(0) = 0 and
β(n) =





β(n −1) + k(Sβ(n−1))
if Sβ(n−1) ∈S′;
β(n −1) + 1
if Sβ(n−1), Sβ(n−1)+1 ∈S;
β(n −1) + 1 + k(Sβ(n−1)+1)
if Sβ(n−1) ∈S, Sβ(n−1)+1 ∈S′
for n ≥1. Also ﬁx an initial distribution µ and set
Qn(s) = Pµ

Sβ(n−1)+1 = s | Sβ(n−1), Sβ(n−2), . . . , Sβ(0)

for n ≥1 and s ∈G. Each β(n) is an a.s. ﬁnite stopping time with respect
to { (Sn, Cn): n ≥0 }, and straightforward manipulations using the strong
Markov property together with the form of the transition kernel in (1.9)
show that
Pµ

Sβ(n) ∈S | Sβ(n−1), Sβ(n−2), . . . , Sβ(0)

≥1S′(Sβ(n−1)) · δ(Sβ(n−1))
+ 1S(Sβ(n−1)) ·

s∈S
1 · Qn(s) +

s∈S′
δ(s) · Qn(s)

≥δ a.s.
(3.8)
for n ≥1. Lemma 3.4 now implies that Pµ

Sβ(n) ∈S i.o.

= 1, and hence
Pµ { Sn ∈S i.o. } = 1.

90
3. The Marking Process
Remark 3.9. Let TS = inf { n ≥1: Sn ∈S } be the ﬁrst hitting time after
0 of the set of timed transitions and set k = sups∈S′ k(s), where k( · ) is
deﬁned as in the proof of Theorem 3.2. It follows from (3.7) and (3.8) that,
under the conditions of the theorem, k < ∞and
Pµ { TS > l } ≤(1 −δ)⌊l/k⌋≤aρl
(3.10)
for l ≥0, where a = (1 −δ)−1, ρ = (1 −δ)1/k, and ⌊x⌋is the greatest
integer less than or equal to x.
Remark 3.11.
We can relax the requirement in Theorem 3.2 that S′ be
ﬁnite. In particular, the conclusion of the theorem holds provided that
S′ ; S and infs∈S′ δ(s) > 0. When establishing the latter condition, we
are free to make each δ(s) as large as possible by deﬁning δ(s) in terms of
the most likely path from s to the set S of timed markings.
3.3.2
Explosions
Even when { Sn : n ≥0 } does not get absorbed into the set S′, an inﬁnite
number of marking changes can occur in a ﬁnite time interval if the marking
changes occur ever more rapidly so that the times { ζn : n ≥0 } have an
accumulation point. We then say that an explosion has occurred at time
τ∆< ∞.
Example 3.12 (An explosive spn). Consider an spn with a single place d1
and a single timed transition e1 such that d1 is both a normal input place
and an output place for e1. Whenever transition e1 ﬁres, it deposits a token
in place d1 (and does not remove a token from d1). The initial marking is
s = (1), so that with probability 1 the sequence of successive markings
is (1), (2), (3), and so forth. All speeds are equal to 1, and the clock-
setting distribution functions are given by F0

x; e1, (1)

= P { A1 ≤x }
and F

x; (n), e1, (n −1), e1

= P { An ≤x } for n ≥2, where { An : n ≥1 }
is a sequence of random variables such that A1 = 1 with probability 1 and
An =

1/n2
with probability (n2 −1)/n2;
(n5 −n2 + 1)/n2
with probability 1/n2
for n ≥2. Thus, starting from marking (n), the time until the next mark-
ing change is distributed as An and the expected time until this marking
change is E [An] = n. Trivially, Pµ { Sn ∈S i.o. } = 1. For this spn, τ∆is
distributed as 	
n≥1 An. It follows from the three-series theorem (Proposi-
tion 1.32 in the Appendix) that
P { τ∆< ∞} = P
 
n≥1
An < ∞

= 1.

3.3 The Lifetime of the Marking Process
91
Thus, an inﬁnite number of marking changes occur in a ﬁnite time inter-
val with probability 1 even though the expected time between successive
marking changes increases linearly.
3.3.3
Suﬃcient Conditions for Inﬁnite Lifetimes
The following theorem gives conditions under which the lifetime of an spn
is a.s. inﬁnite. The idea is to uniformly bound the speeds from above and
impose a uniform bound—over all the clock-setting distribution functions
for timed transitions—on the amount of probability mass that can be close
to 0.
Theorem 3.13. Suppose that
(i) Pµ { Sn ∈S i.o. } = 1,
(ii) sups,e r(s, e) < ∞, and
(iii) there exists a > 0 such that
sup
e′∈E−E′ sup
s′,s,E∗F(a; s′, e′, s, E∗) < 1.
Then Pµ

τ∆= ∞

= 1.
Observe that the conditions of Theorem 3.13 hold if either of the following
conditions hold:
• S′ ; S and the marking set G is ﬁnite.
• The condition in (i) holds and there are only ﬁnitely many distinct
speeds and distinct clock-setting distribution functions.
Proof. First suppose that the transitions { e1, e2, . . . , eM } are all timed.
Set r = sups,e r(s, e) and b = supe′∈E−E′ sups′,s,E∗F(a; s′, e′, s, E∗). De-
note by Nn (n ≥1) the (random) set of new transitions just after the nth
marking change: Nn = N(Sn; Sn−1, E∗
n−1). Next, denote by Ik (k ≥0) the
indicator variable that equals 1 if, at marking changes kM, kM + 1, . . . ,
(k + 1)M, each new clock reading exceeds the constant a:
Ik =

1
if Cn,i > a for ei ∈Nn and kM ≤n < (k + 1)M;
0
otherwise,
where we take N0 = E(S0). Because there are only M transitions, at least
one transition must become enabled in the time interval [ζkM, ζ(k+1)M]
and also ﬁre in this interval. Because all speeds are bounded above by r, it

92
3. The Marking Process
follows that ζ(k+1)M −ζkM > a/r whenever Ik = 1. Using the hypothesis
in (iii) and writing F = 1 −F, we have
Pµ { CkM,i > a for ei ∈NkM | Ik−1, . . . , I0 }
= Eµ

Pµ{ CkM,i > a for ei ∈NkM | NkM, SkM,
SkM−1, E∗
kM−1, Ik−1, . . . , I0 }
 Ik−1, . . . , I0

= Eµ


ei∈NkM
F(a; SkM, ei, SkM−1, E∗
kM−1)
 Ik−1, . . . , I0

≥Eµ

(1 −b)|NkM|  Ik−1, . . . , I0

≥(1 −b)M a.s.
for k ≥0. The above calculations can be repeated for sets NkM+1 through
N(k+1)M−1 to yield the inequality Pµ { Ik = 1 | Ik−1, . . . , I0 } ≥(1 −b)M 2
a.s. for k ≥0. Using the geometric trials lemma, we ﬁnd that
Pµ { τ∆= ∞} = Pµ

sup
n≥0
ζn = ∞

≥Pµ

ζ(k+1)M −ζkM > a/r i.o.

≥Pµ { Ik = 1 i.o. }
= 1,
and the desired result follows. Now suppose that there are one or more
immediate transitions. Then the argument is almost the same as above,
but we work with the embedded chain { (S+
n , C+
n ): n ≥0 } deﬁned at the
end of Section 3.1.2.
Example 3.14 (Producer–consumer system with nonpreemptive priority).
As discussed previously, S′ ; S for the spn in Example 2.1. Because the
marking set G is ﬁnite, it then follows that the lifetime of the marking
process is a.s. inﬁnite.
3.4
Markovian Marking Processes
In this section we show (Theorem 4.21) that the marking process of an
spn is a time-homogeneous ctmc provided that the clock associated with
each transition is always set according to a ﬁxed exponential distribution.
Though intuitively plausible, this result is nontrivial to establish because
the distribution of the clock-reading vector after a marking change, and
hence the time between successive marking changes, is extremely complex
for general clock-setting distributions. The proof of Theorem 4.21 rests

3.4 Markovian Marking Processes
93
on a representation (Lemma 4.10) of the conditional distribution of the
clock-reading vector given the “partial history” of the underlying chain of
the marking process. The proof also exploits the close connection between
the deﬁnition of the marking process and the standard construction of a
“minimal” ctmc.
3.4.1
Continuous-Time Markov Chains
Before proceeding with our main results we brieﬂy review some basic facts
about ctmcs. In the ctmc setting, the analog of the transition matrix of
a dtmc—see Section A.2.4—is the transition function P t. The quantity
P t(s, s′) is the probability, starting in state s, that the chain is in state s′
exactly t time units later.
Deﬁnition 4.1. Let { X(t): t ≥0 } be a stochastic process deﬁned on a
probability space (Ω, F, P), taking values in a ﬁnite or countably inﬁnite
set S and having piecewise-constant, right-continuous sample paths. The
process { X(t): t ≥0 } is a (time-homogeneous) continuous-time Markov
chain with initial distribution ν and transition function P t if
P { X(0) = s } = ν(s)
and
P { X(t + u) = s | X(v): 0 ≤v ≤t } = P u
X(t), s

a.s.
(4.2)
for s ∈S and t, u ≥0.
Proposition 4.3 below characterizes the structure of a ctmc { X(t): t ≥
0 } prior to a possible “explosion” (as deﬁned below). Let { ξn : n ≥0 } be
the sequence of successive state-transition times for the ctmc: ξ0 = 0 and
ξn = inf { t > ξn−1 : X(t) ̸= X(ξn−1) }. For n ≥0, denote by Yn = X(ξn)
the state hit by the chain at time ξn and by Tn = ξn+1 −ξn the holding
time in state Yn. If the chain is absorbed into state s, so that X(t) = s
for all t ≥ξn and some n ≥0, then we use the convention that ξn+1 =
ξn+2 = · · · = ∞and Tn = Tn+1 = · · · = ∞. When q = 0, we take the
exponential distribution with intensity q to be the improper distribution
with unit probability mass at +∞. If
τ∆
def
= sup
n≥0
ξn < ∞,
then we say that an explosion has occurred at time τ∆; if τ∆is a.s. inﬁnite,
then we say that the ctmc is nonexplosive.
Proposition 4.3. The stochastic process { Yn : n ≥0 } is a discrete-time
Markov chain. Moreover, there exist nonnegative numbers { q(s): s ∈S }
such that, given { Yn : n ≥0 }, the random variables { Tn : n ≥0 } are mu-
tually independent and P { Tn ≤x } = 1 −e−q(Yn)x for x ≥0 and n ≥0.

94
3. The Marking Process
We call { q(s): s ∈S } the intensity vector of the ctmc and { Yn : n ≥0 }
the embedded jump chain of the ctmc. The transition matrix of the em-
bedded jump chain is denoted by W = { W(s, s′): s, s′ ∈S }; observe that
W(s, s) = 0 for s ∈S.
Proposition 4.5 below is suggested by Proposition 4.3 and provides a
means of constructing a ctmc from a vector q0 = { q0(s): s ∈S } of non-
negative real numbers, a stochastic matrix W0 = { W0(s, s′): s′, s ∈S },
and a probability distribution ν = { ν(s): s ∈S }. [We allow W0(s, s) > 0
for one or more states s ∈S.] To start the construction, deﬁne random vari-
ables { Yn : n ≥0 } and { Tn : n ≥0 } on a probability space (Ω, F, P) such
that (1) the stochastic process { Yn : n ≥0 } is a dtmc with initial distri-
bution ν and transition matrix W0 and (2) given { Yn : n ≥0 }, the random
variables { Tn : n ≥0 } are mutually independent and each Tn has an expo-
nential distribution with intensity q0(Yn). Kolmogorov’s existence theorem
ensures that such a deﬁnition is possible. Set ζ0 = 0 and ζn = 	n−1
i=0 Ti for
n ≥1. Fix ∆̸∈S and set
X(t) =

SN(t)
if N(t) < ∞;
∆
if N(t) = ∞,
(4.4)
where N(t) = sup { n ≥0: ζn ≤t }.
Proposition 4.5. The stochastic process { X(t): t ≥0 } deﬁned by (4.4) is
a time-homogeneous ctmc with initial distribution ν. The intensity vector q
is given by q(s) = q0(s)

1−W0(s, s)

for s ∈S, and the transition matrix W
for the embedded jump chain is given by W(s, s′) = W0(s, s′)/

1−W0(s, s)

for s, s′ ∈S with s ̸= s′.
When P { τ∆< ∞} > 0 there is, in general, more than one way to deﬁne
the process after time τ∆so that it has piecewise-constant sample paths
and satisﬁes the Markov property. All such processes behave identically up
to time τ∆. Fix s ∈S and u ≥0, and observe that for each such process
{ ¯X(t): t ≥0 } we have
P{ ¯X(u) = s } = P{ ¯X(u) = s, u < τ∆} + P{ ¯X(u) = s, u ≥τ∆}.
Moreover, the ﬁrst term on the right side of the above equation is the same
for each process. For the particular process { X(t): t ≥0 } deﬁned by (4.4),
we have X(u) = ∆for u ≥τ∆, so that the second term on the right side is
0. Hence P { X(u) = s } ≤P{ ¯X(u) = s } for any process { ¯X(t): t ≥0 } as
above, and for this reason the process deﬁned by (4.4) is called the minimal
ctmc.
The special structure of a ctmc makes it possible (at least in prin-
ciple) to compute time-average limits either analytically or numerically.
Such computations are based on Proposition 4.6 below. Let { X(t): t ≥0 }
be a minimal ctmc with state space S, intensity vector q, and embed-
ded jump chain { Yn : n ≥0 } having transition matrix W. Denote by W n

3.4 Markovian Marking Processes
95
(n ≥0) the nth power of the matrix W and set τs = inf { n > 0: Yn = s }.
The chain { X(t): t ≥0 } is irreducible if for each s, s′ ∈S there exists
n = n(s, s′) ∈(0, ∞) such that W n(s, s′) > 0 and is positive recurrent if it
is irreducible and Es [τs] < ∞for s ∈S; here Es denotes the expectation
when the ctmc starts in state s. Thus a ctmc is irreducible if the embed-
ded jump chain is irreducible (as deﬁned in Section A.2.4), and similarly for
positive recurrence. It can be shown that an irreducible ctmc with a ﬁnite
state space is necessarily positive recurrent. The inﬁnitesimal generator
matrix Q = { Q(s, s′): s, s′ ∈S } of the ctmc is deﬁned by setting
Q(s, s′) = q(s)W(s, s′)
for s ̸= s′ and
Q(s, s) = −q(s).
The matrix Q is also known as the intensity matrix or diﬀerential matrix of
the ctmc. Heuristically, starting in state s at time t, the probability that
the chain jumps from s to s′ during the interval [t, t+∆t] is approximately
equal to Q(s, s′)∆t+o(∆t) when ∆t is small. Similarly, the probability that
the chain jumps from s to some other state during the interval [t, t + ∆t]
is approximately equal to q(s)∆t + o(∆t). A probability distribution π on
S is said to be a stationary distribution for { X(t): t ≥0 } if and only if
	
s∈S π(s)P t(s, s′) = π(s′) for s′ ∈S and t ≥0. Thus, if the initial state
of the ctmc is selected according to π, then X(t) is distributed according
to π at each time t > 0.
Proposition 4.6. Suppose that the ctmc { X(t): t ≥0 } is nonexplosive,
irreducible, and positive recurrent. Then there exists a unique stationary
distribution π on the state space S of the chain. This distribution is deter-
mined as the normalized solution of the system of linear equations
πQ = 0,
(4.7)
where π is interpreted as a row vector. Moreover, if f is a real-valued func-
tion such that 	
s∈S |f(s)|π(s) < ∞, then
lim
t→∞
1
t
 t
0
f

X(u)

du =

s∈S
f(s)π(s) a.s.
for any initial distribution of the chain.
3.4.2
Conditional Distribution of Clock Readings
To establish the Markov property for a marking process, we need to deter-
mine the distribution of the clock-reading vector just after each marking

96
3. The Marking Process
change. Although the unconditional distribution of the clock-reading vec-
tor usually is complicated, it is possible to calculate certain conditional
distributions. The key result in this direction is Lemma 4.10 below.
To prepare for Lemma 4.10, we ﬁrst deﬁne the “partial history” of the
underlying chain of an spn. Let { X(t): t ≥0 } be the marking process of
an spn and let { (Sn, Cn): n ≥0 } be the underlying chain. Recall the
deﬁnitions of t∗and E∗from (1.7) and (1.8), respectively, and set t∗
n =
t∗(Sn, Cn) and E∗
n = E∗(Sn, Cn) for n ≥0.
Deﬁnition 4.8. The partial history of the underlying chain up to the nth
marking change (n ≥1) is the collection
Fn =

S0, E∗
0, t∗
0, S1, E∗
1, t∗
1, . . . , Sn−1, E∗
n−1, t∗
n−1, Sn

.
(4.9)
When n = 0, take F0 = { S0 }.
The partial history records the sequence of states, holding times, and sets
of trigger events, but does not record detailed information about individual
clock readings. Observe, however, that when a clock is set at time ζk and
runs down to 0 at time ζl, triggering a marking change, detailed information
about readings on the clock during [ζk, ζl] can be inferred from Fn provided
that l ≤n. If a transition is an old transition at time ζn, then one can
infer from Fn the amount of time that has elapsed on the associated clock
since the clock was most recently set; no other information about the clock
reading is available.
A random variable γ taking values in the nonnegative integers is said to
be a stopping time with respect to the increasing sequence { Fn : n ≥0 } if
for each n ≥0 the occurrence or nonoccurrence of the event { γ = n } is
completely determined by the values of the random variables in Fn. For a
stopping time γ we write
Fγ =

γ, S0, E∗
0, t∗
0, S1, E∗
1, t∗
1, . . . , Sγ−1, E∗
γ−1, t∗
γ−1, Sγ

.
Recall the deﬁnition of the set of new transitions N(s′; s, E∗) from Sec-
tion 3.1.2, and let α(n, i) be the index (less than or equal to n) of the
latest marking change at which the clock associated with enabled transi-
tion ei ∈E(Sn) was set: α(0, i) = 0 and
α(n, i) = max

k : 1 ≤k ≤n and ei ∈N(Sk; Sk−1, E∗
k−1)

for n ≥1. If the maximum is taken over an empty set, deﬁne α(n, i) = 0; if
ei ̸∈E(Sn), set α(n, i) = n. Next, denote by Zn,i the amount of time that
has elapsed on the clock associated with transition ei between ζα(n,i) and
ζn: Zn,i = Cα(n,i),i −Cn,i.
We are now ready to state Lemma 4.10. The lemma asserts that the
clock readings { Cγ,i : ei ∈E −E′ } are conditionally independent, given
the partial history up to a stopping time γ. If ei ∈E(Sγ), then the condi-
tional probability that the clock reading Cγ,i exceeds xi is computed as the

3.4 Markovian Marking Processes
97
probability that a sample from the clock-setting distribution for ei exceeds
Zγ,i+xi given that the sample exceeds Zγ,i. We use the convention 0/0 = 0
throughout. For ease of exposition, we state our result for spns in which
each timed transition is “simple” as in Deﬁnition 1.8 of Chapter 2.
Lemma 4.10. Suppose that each timed transition is simple, and let γ be
an a.s. ﬁnite stopping time with respect to { Fn : n ≥0 }. Then
Pµ { Cγ,i > xi for ei ∈H | Fγ }
=
 
ei∈H F(xi + Zγ,i; ei)/F(Zγ,i; ei)
if H ⊆E(Sγ);
0
otherwise
(4.11)
with probability 1 for any subset H ⊆E −E′ and nonnegative numbers
{ xi : ei ∈H }.
Proof. It suﬃces to prove the result when γ ≡k for an arbitrary but ﬁxed
constant k ≥0 because then, for a general stopping time γ,
Pµ { Cγ,i > xi for ei ∈H | Fγ }
=
∞

k=0
Pµ { Cγ,i > xi for ei ∈H, γ = k | Fγ }
=
∞

k=0
1{γ=k}Pµ { Ck,i > xi for ei ∈H | Fk }
=
∞

k=0
1{γ=k}1{H⊆E(Sk)}

ei∈H
F

xi + Zk,i; ei

F

Zk,i; ei

=

1{H⊆E(Sγ)}

ei∈H
F

xi + Zγ,i; ei

F

Zγ,i; ei

 ∞

k=0
1{γ=k}
= 1{H⊆E(Sγ)}

ei∈H
F

xi + Zγ,i; ei

F

Zγ,i; ei

a.s.,
and the desired result follows. To this end, ﬁx H, { xi : ei ∈H }, and k ≥0.
If γ ≡k = 0, then (4.11) clearly holds, so suppose that k > 0. By stan-
dard properties of conditional probability—see (1.27) in the Appendix—it
suﬃces to show that
Pµ { Ck,i > xi for ei ∈H, A } = Eµ
!
1A

ei∈H
F

xi + Zk,i; ei

F

Zk,i; ei

"
(4.12)
for all sets A of the form
A =

α(k, i) = li for ei ∈E, Sm = sm for 0 ≤m ≤k,
E∗(Sm, Cm) = ˜Em for 0 ≤m < k,
Cm,i ≤xm,i for 0 ≤m < li and ei ∈E

,

98
3. The Marking Process
where 0 ≤li ≤k, 0 ≤xm,i < ∞, sm ∈G, ˜Em ⊆E(sm), and E(sk) ⊇H.
Fix such a set A. Because both sides of (4.12) are trivially equal to zero
if Pµ { A } = 0, assume without loss of generality that A has positive Pµ-
probability. Then A has the representation
A =

Sm = sm for 0 ≤m ≤k, E∗(Sm, Cm) = ˜Em for 0 ≤m < k,
Cm,i ≤xm,i for 0 ≤m < li and ei ∈E

;
that is, the random variables { α(k, i): ei ∈H } do not appear explicitly in
the representation of A because the values of these random variables are
determined by the values of S0, S1, . . . , Sk and E∗(S0, C0), E∗(S1, C1), . . . ,
E∗(Sk, Ck). Thus there exist sets A0, A1, . . . , Ak ⊆Σ such that
{ Ck,i > xi for ei ∈H, A }
= { (S0, C0) ∈A0, (S1, C1) ∈A1, . . . , (Sk, Ck) ∈Ak } .
For example, if m < min { li : ei ∈H }, then
Am = { sm } ×

c = (c1, . . . , cM) ∈C(sm):
E∗(sm, c) = ˜Em, ci ≤xm,i for ei ∈E

;
and if m = k, then
Am = { sk } ×

c = (c1, . . . , cM) ∈C(sk): ci > xi for ei ∈H

.
Using (1.4), we then have
Pµ { Ck,i > xi for ei ∈H, A }
= Pµ { (S0, C0) ∈A0, (S1, C1) ∈A1, . . . , (Sk, Ck) ∈Ak }
=

A0
µ

d(s0, c0)
 
A1
P

(s0, c0), d(s1, c1)

· · ·

Ak
P

(sk−1, ck−1), d(sk, ck)

,
(4.13)
where µ and P are the initial distribution and transition kernel, respec-
tively, of the underlying chain { (Sn, Cn): n ≥0 }.
The equality in (4.12) follows from (4.13) upon substituting the explicit
expressions (1.10) and (1.9) for µ and P, respectively, into the multiple
integral and using Fubini’s theorem (Proposition 1.25 in the Appendix) to
interchange the order of integration. Because these calculations are messy,
we illustrate the basic ideas by giving the calculations for a simple speciﬁc
spn. Consider an spn with four places and three (simple) deterministic
transitions as in Figure 3.4. All speeds for enabled transitions are equal
to 1. Set s = (1, 1, 0, 0) and s′ = (0, 1, 1, 0), and suppose that the initial

3.4 Markovian Marking Processes
99
Figure 3.4. Example for proof of Theorem 4.10.
marking is equal to s with probability 1. We now establish (4.12) with
k = 1, H = { e2 }, and
A =

α(1, 1) = 1, α(1, 2) = 0, α(1, 3) = 1,
S0 = s, S1 = s′, E∗(S0, C0) = { e1 } , and C0,1 ≤x0,1

.
We can write
Pµ { C1,2 > x2, A } = Pµ { (S0, C0) ∈A0, (S1, C1) ∈A1 } ,
where
A0 = { s } × { (c1, c2, c3) ∈C(s): c1 < c2 and c1 ≤x0,1 }
and
A1 = { s′ } × { (c1, c2, c3) ∈C(s′): c2 > x2 } .
Write Fi(x) = F(x; ei) for i = 1, 2 and observe that
Pµ { C1,2 > x2, A }
=

A0
µ

d(s0, c0)

P

(s0, c0), A1)
=
 x0,1
0
 ∞
y1
1(x2,∞)(y2 −y1) dF2(y2)dF1(y1)
=
 x0,1
0
 ∞
0
 ∞
0
1(x2,∞)(y2 −y1)1(y1,∞)(u)
F 2(y1)
dF2(u)dF2(y2)dF1(y1)
=
 x0,1
0
 ∞
y1
F 2(x2 + y1)
F 2(y1)
dF2(y2)dF1(y1)
= Eµ
!
1A
F 2(x2 + Z1,2)
F 2(Z1,2)
"
,

100
3. The Marking Process
where the fourth equality is obtained by interchanging the order of inte-
gration for the innermost two integrals and the last equality exploits the
fact that Z1,2 = C0,1 whenever event A occurs.
Remark 4.14. Let Eγ ⊆E(Sγ) be a random set of transitions whose el-
ements are completely determined by Fγ. For an arbitrary ﬁxed subset
H ⊆E −E′, we have
1{Eγ=H}Pµ { Cγ,i > xi for ei ∈Eγ | Fγ }
= 1{Eγ=H}Pµ { Cγ,i > xi for ei ∈H | Fγ }
= 1{Eγ=H}

ei∈H
F(xi + Zγ,i; ei)/F(Zγ,i; ei)
= 1{Eγ=H}

ei∈Eγ
F(xi + Zγ,i; ei)/F(Zγ,i; ei) a.s.,
where the second equality follows from Lemma 4.10. Summing over all
subsets H ⊆E −E′, we ﬁnd that
Pµ { Cγ,i > xi for ei ∈Eγ | Fγ } =

ei∈Eγ
F(xi + Zγ,i; ei)/F(Zγ,i; ei) a.s..
Remark 4.15. Lemma 4.10 can be generalized in a straightforward way to
spns in which the timed transitions need not be simple. Set
Un(x; ei) =

F(x; Sα(n,i), ei, Sα(n,i)−1, E∗
α(n,i)−1)
if α(n, i) > 0;
F0(x; ei, S0)
if α(n, i) = 0
and U n = 1 −Un for n ≥0. The conditional distribution of the clock
readings is then given by
Pµ { Cγ,i > xi for ei ∈H | Fγ }
=
 
ei∈H U γ(xi + Zγ,i; ei)/U γ(Zγ,i; ei)
if H ⊆E(Sγ);
0
otherwise.
(4.16)
The following result is an immediate consequence of Lemma 4.10 and
gives a justiﬁcation for “memoryless property” arguments in spns with
exponential clock-setting distributions.
Corollary 4.17. Suppose that γ is an a.s. ﬁnite stopping time with respect
to { Fn : n ≥0 }. Also suppose that each timed transition ei ∈E −E′ is
simple with F(x; ei) = 1 −e−v(i)x for some v(i) ∈(0, ∞). Then
Pµ { Cγ,i ≤xi for 1 ≤i ≤M | Fγ } =

ei∈E(Sγ)∩(E−E′)

1 −e−v(i)xi
a.s.
for x1, x2, . . . , xM ≥0.

3.4 Markovian Marking Processes
101
The following variant of Lemma 4.10 is sometimes useful. Set ˜Fn =
Fn −{ Sn } for n ≥0.
Corollary 4.18. Suppose that each timed transition is simple, and let γ
be an a.s. ﬁnite stopping time with respect to { ˜Fn : n ≥0 }. Then
Pµ { Sγ = ¯s and Cγ,i > xi for ei ∈H | ˜Fγ }
=

p(¯s; Sγ−1, E∗
γ−1)  
ei∈H F(xi + Zγ,i; ei)/F(Zγ,i; ei)
if H ⊆E(¯s);
0
otherwise
with probability 1 for any marking ¯s ∈G, subset H ⊆E −E′, and nonneg-
ative numbers { xi : ei ∈H }.
Proof. Fix ¯s, H, and { xi : ei ∈H }. We give the proof for the case H ⊆
E(¯s); the proof for the case H ̸⊆E(¯s) is similar. Set g(s) = 1{¯s}(s) and
h(c) =  
ei∈H 1(xi,∞)(ci) for s ∈G and c = (c1, c2, . . . , cM) ∈C(s).
Also, for s′ ∈G and u = (s, E∗, z, t∗) with s ∈G, E∗⊂E(s), z =
(z1, z2, . . . , zM) ∈ℜM
+ , and t∗≥0, set
w(s′, u) =

ei∈H∩N(s′;s,E∗)
F(xi)

ei∈H∩O(s′;s,E∗)
F(xi + zi + t∗r(s, ei); ei)
F(zi + t∗r(s, ei); ei)
.
With this notation, the assertion of the corollary can be written as
Eµ[g(Sγ)h(Cγ) | ˜Fγ] = p(¯s; Sγ−1, E∗
γ−1)w(¯s, Uγ−1),
where Uγ−1 = (Sγ−1, E∗
γ−1, Zγ−1, t∗
γ−1) and Zγ−1 = (Zγ−1,1, . . . , Zγ−1,M).
Using Lemma 4.10 and the fact that Uγ−1 is determined by ˜Fγ, we ﬁnd
that
Eµ[g(Sγ)h(Cγ) | ˜Fγ] = Eµ

Eµ[g(Sγ)h(Cγ) | Fγ]
 ˜Fγ

= Eµ

g(Sγ) Eµ[h(Cγ) | Fγ]
 ˜Fγ

= Eµ[g(Sγ)w(Sγ, Uγ−1) | ˜Fγ]
= w(¯s, Uγ−1)Eµ[g(Sγ) | ˜Fγ] a.s..
Set Gn = { (S0, C0), (S1, C1), . . . , (Sn, Cn) } for n ≥0, and observe that
˜Fn ⊆Gn−1 for each n. Using the strong Markov property for the underlying
chain and the speciﬁc form of the transition kernel, we have
Eµ[g(Sγ) | ˜Fγ] = Eµ

Eµ[g(Sγ) | Gγ−1]
 ˜Fγ

= Eµ

p(¯s; Sγ−1, E∗
γ−1)
 ˜Fγ

= p(¯s; Sγ−1, E∗
γ−1) a.s.,
and the desired result follows.

102
3. The Marking Process
Lemma 4.19 is similar to Lemma 4.10 and is used in subsequent chapters.
Two clock readings Cγ,i and Cγ′,i′ observed at random marking changes γ
and γ′, respectively, are said to be disjoint if either (1) i ̸= i′ or (2) i = i′
and, with probability 1, transition ei ﬁres or becomes disabled between
marking changes γ and γ′. Lemma 4.19 asserts that the clock readings in a
collection are conditionally mutually independent, given the partial history
up to a stopping time γ, if the clock readings are pairwise disjoint and each
clock reading observed after γ corresponds to a new clock setting.
Lemma 4.19. Let γ, γ1, γ2, . . . , γn+m (m, n ≥0) be a.s. ﬁnite stopping
times with respect to { Fn : n ≥0 }, and let Cγ1,i1, . . . , Cγn,in, Cγn+1,in+1,
. . . , Cγn+m,in+m be pairwise disjoint clock readings. Suppose that each timed
transition is simple and, with probability 1,
(i) max1≤l≤n γl ≤γ ≤minn+1≤l≤n+m γl, and
(ii) eil ∈N(Sγl; Sγl−1, E∗
γl−1) for n + 1 ≤l ≤n + m.
Then
Pµ { Cγl,il > xl for 1 ≤l ≤n + m | Fγ }
=
n

l=1
Pµ { Cγl,il > xl | Fγ }
n+m

l=n+1
F(xl; eil)
with probability 1 for all x1, x2, . . . , xn+m ≥0.
The intuition behind the proof of Lemma 4.19 is as follows. If γl > γ,
then Fγ contains no information that will “distort” the conditional dis-
tribution of the new clock reading Cγl,il to be anything other than that
of an independent sample from F( · ; eil). This assertion follows because
γ is a stopping time. If γl < γ and the transition enabled just after the
γlth marking change ﬁres before the γth marking change, then the infor-
mation in Fγ completely determines the value of Cγl,il. It follows that the
conditional probability of the event { Cγl,il > xl } factors out of the joint
conditional probability expression—see Proposition 1.29 in the Appendix.
If γl < γ and the transition enabled just after the γlth marking change
has not ﬁred before the γth marking change, then the event { Cγl,il > xl }
can be reexpressed as an event of the form { Cγ,il > x′
l }, and Lemma 4.10
applies.
3.4.3
The Markov Property
The following example shows that even when all clock-setting distributions
are exponential, the marking process may not be a ctmc if the intensities
depend on the current marking, new marking, and set of transitions that
trigger the marking change.

3.4 Markovian Marking Processes
103
Figure 3.5. Non-Markovian spn with exponential clock-setting distributions.
Example 4.20 (Non-Markovian spn with exponential clock-setting distri-
butions).
Consider an spn with two places and two deterministic timed
transitions as in Figure 3.5. Fix N > 1, and suppose that the initial marking
for this spn is (N, 0) with probability 1, so that the two places always con-
tain a total of N tokens—in the ﬁgure, N = 3. All speeds for enabled tran-
sitions are equal to 1. Transition e1 is simple, with F(x; e1) = 1 −e−v(0)x.
The clock-setting distribution function for transition e2 is given by
F

x; (s1 + 1, s2 −1), e2, (s1, s2), e2

= 1 −e−v(1)x
for (s1, s2) ∈G with s2 ≥1, and
F

x; (N −1, 1), e2, (N, 0), e1

= 1 −e−v(2)x,
where v(0), v(1), and v(2) are positive numbers with v(1) ̸= v(2). This spn
corresponds to a ﬁnite-capacity single-server queue in which the service-
time distribution for the job that initiates a busy period diﬀers from the
service-time distribution for the other jobs that arrive during the busy
period. Using (4.16), it can be shown that
Pµ { Ck,2 > x | Sk = (N −1, 1), Sk−1 = (N, 0) } = e−v(2)x,
but
Pµ { Ck,2 > x | Sk = (N −1, 1), Sk−1 = (N −2, 2) } = e−v(1)x
for x ≥0. Thus, given the sequence of markings { Sn : n ≥0 }, the holding
time in state Sk = (N −1, 1) is exponentially distributed but the intensity
depends on more than just Sk. The marking process cannot possibly be a
ctmc, as this would contradict Proposition 4.3.
Theorem 4.21 asserts that the marking process is a ctmc provided that
each timed transition is simple and has an exponential clock-setting dis-
tribution. Recall from (1.14) that the random indices { γ(n): n ≥0 } cor-
respond to the successive marking changes at which the new marking is
timed. For timed markings s, s′ ∈S, let p+(s′; s, E∗) be the probability
that the next timed marking is s′ when the current marking is s and the
transitions in E∗trigger a marking change:
p+(s′; s, E∗) =


p(s1; s, E∗)
k

j=2
p

sj; sj−1, E′ ∩E(sj−1)


,

104
3. The Marking Process
where the summation is over all ﬁnite sequences s1, . . . , sk (k ≥1) such
that sk = s′ and sj ∈S′ for 1 ≤j < k.
Theorem 4.21. Suppose that each timed transition ei ∈E −E′ is sim-
ple with F(x; ei) = 1 −e−v(i)x for some v(i) ∈(0, ∞). Also suppose that
Pµ { Sn ∈S i.o. } = 1. Then the marking process { X(t): t ≥0 } is a time-
homogeneous ctmc. The initial distribution is given by
ν(s) = Pµ

Sγ(0) = s

for s ∈S, the intensity vector is given by
q(s) =

ei∈E(s)

1 −p+(s; s, ei)

r(s, ei)v(i)
for s ∈S, and the transition matrix for the embedded jump chain is given
by
W(s, s′) =
	
ei∈E(s)
r(s,ei)v(i)
q(s)
p+(s′; s, ei)
if s′ ̸= s;
0
if s′ = s
for s′, s ∈S. If sups,e r(s, e) < ∞, then the chain is nonexplosive.
To prove Theorem 4.21, we need the following result, which speciﬁes the
conditional joint distribution of the clock-reading vector Cγ(n) and marking
Sγ(n+1), given the partial history Fγ(n). For n ≥0 and 1 ≤i ≤M, deﬁne
a (random) distribution function Un,i on [0, ∞) by setting
Un,i(x) =

1 −e−v(i)x
if ei ∈E(Sγ(n));
1[0,∞)(x)
if ei ̸∈E(Sγ(n))
for x ≥0. Set
Un(x) =
M

i=1
Un,i(xi)
for n ≥0 and x = (x1, x2, . . . , xM) ∈[0, ∞)M.
Lemma 4.22. Suppose that each timed transition ei ∈E −E′ is sim-
ple with F(x; ei) = 1 −e−v(i)x for some v(i) ∈(0, ∞). Also suppose that
Pµ { Sn ∈S i.o. } = 1. Then
Pµ

Cγ(n),i ≤xi for 1 ≤i ≤M, Sγ(n+1) = s | Fγ(n)

=

[0,x1]×···×[0,xM]
p+
s; Sγ(n), E∗(Sγ(n), c)

dUn(c) a.s.
(4.23)
for any n ≥0, s ∈S, and x1, x2, . . . , xM ≥0.

3.4 Markovian Marking Processes
105
Proof. Fix n ≥0, s ∈S, and x1, x2, . . . , xM ≥0. Observe that γ(n),
which is a.s. ﬁnite by hypothesis, is also a stopping time with respect to
{ Fn : n ≥0 }. Because Sγ(n) is determined by the values of the random
variables in Fγ(n), it follows from Corollary 4.17 that
Pµ

Sγ(n) = s, Cγ(n),i ≤xi for 1 ≤i ≤M | Fγ(n)

= 1{s}(Sγ(n))
M

i=1
Un,i(xi) a.s.
(4.24)
for s ∈S. Moreover, using (1.9) and the strong Markov property, it is
straightforward to show that
Pµ

Sγ(n+1) = s | Sγ(n), Cγ(n)

= p+
s; Sγ(n), E∗(Sγ(n), Cγ(n))

a.s.
(4.25)
for s ∈S and n ≥0. Finally, we have
Pµ

Cγ(n),i ≤xi for 1 ≤i ≤M, Sγ(n+1) = s | Fγ(n)

= Eµ

Pµ

Cγ(n),i ≤xi for 1 ≤i ≤M, Sγ(n+1) = s | Fγ(n), Cγ(n)

 Fγ(n)

= Eµ

Pµ

Sγ(n+1) = s | Fγ(n), Cγ(n)
 M

i=1
1{Cγ(n),i≤xi}
 Fγ(n)

= Eµ

p+
s; Sγ(n), E∗(Sγ(n), Cγ(n))
 M

i=1
1{Cγ(n),i≤xi}
 Fγ(n)

a.s.,
(4.26)
where the third equality follows from the strong Markov property and
(4.25). It follows directly from (4.24) that the rightmost expression in (4.26)
is equal to the right side of (4.23).
Proof of Theorem 4.21. Set Tn = t∗(Sγ(n), Cγ(n)) and Yn = Sγ(n) for
n ≥0, where the sequence of random indices { γ(n): n ≥0 } is deﬁned by
(1.14). Also set q0(s) = 	
ei∈E(s) r(s, ei)v(i) for s ∈S and
W0(s, s′) =

ei∈E(s)
r(s, ei)v(i)
q0(s)
p+(s′; s, ei)
for s, s′ ∈S. Comparing the deﬁnition of the process { X(t): t ≥0 } to that
of a minimal ctmc, we see that if
(i) { Yn : n ≥0 } is a dtmc with transition matrix W0, and

106
3. The Marking Process
(ii) given { Yn : n ≥0 }, the random variables { Tn : n ≥0 } are mutually
independent and each Tn is exponentially distributed with intensity
q0(Yn),
then the ﬁrst two assertions of the theorem follow. The conditions in (i)
and (ii) hold if and only if
Pµ

Y0 = s0, T0 > t0, . . . , Yn = sn, Tn > tn, Yn+1 = sn+1

= Pµ { Y0 = s0 }
n

k=0
e−q0(sk)tkW0(sk, sk+1)
(4.27)
for n ≥0, s0, . . . , sn+1 ∈S, and t0, . . . , tn ≥0. To establish (4.27), observe
that
Pµ

Tn > t, Yn+1 = s | Fγ(n)

= Pµ

min
ei∈E(Sγ(n)) r−1
Sγ(n), ei)Cγ(n),i > t, Sγ(n+1) = s
 Fγ(n)

=

ei∈E(Sγ(n))
Pµ

E∗
γ(n) = { ei } , r−1
Sγ(n), ei)Cγ(n),i > t,
Sγ(n+1) = s
 Fγ(n)

=

ei∈E(Sγ(n))
r(Sγ(n), ei)v(i)
	
ek∈E(Sγ(n)) r(Sγ(n), ek)v(k)
p+(s; Sγ(n), ei) exp

−	
ek∈E(Sγ(n))r(Sγ(n), ek)v(k)t

=

ei∈E(Sγ(n))
r(Sγ(n), ei)v(i)
q(Sγ(n))
p+(s; Sγ(n), ei)e−q(Sγ(n))t
= W0(Yn, s)e−q0(Yn)t a.s.
for n ≥0, t ≥0, and s ∈S. Here the third equality follows from Lemma 4.22
and the well-known fact that if X1, X2, . . . , Xn are mutually independent
exponential random variables with respective intensities q1, q2, . . . , qn, then,
setting Mn = min(X1, X2, . . . , Xn) and q∗= q1 + q2 + · · · + qn,
P { Mn = Xi and Mn > x } =
 qi
q∗

e−q∗x
for 1 ≤i ≤n and x ≥0. Thus,
Pµ

Tn > t, Yn+1 = s
 Y0, . . . , Yn, T0, . . . , Tn−1

= Eµ

Pµ

Tn > t, Yn+1 = s
 Fγ(n)
  Y0, . . . , Yn, T0, . . . , Tn−1


3.4 Markovian Marking Processes
107
Figure 3.6. Markovian spn with no simple timed transitions.
= Eµ

W0(Yn, s)e−q(Yn)t  Y0, . . . , Yn, T0, . . . , Tn−1

= W0(Yn, s)e−q(Yn)t a.s.
(4.28)
for n ≥0, t ≥0, and s ∈S. A simple inductive argument using (4.28)
yields (4.27), and the ﬁrst two assertions of the theorem follow. To prove
the ﬁnal assertion, observe that if sups,e r(s, e) < ∞, then the conditions
of Theorem 3.13 are satisﬁed and the lifetime of the marking process is
inﬁnite; equivalently, the chain is nonexplosive.
The conditions in Theorem 4.21 are suﬃcient but not necessary for the
marking process to be a time-homogeneous ctmc. The following example
shows that the marking process may be a ctmc even when one or more
timed transitions are not simple.
Example 4.29 (Markovian spn with no simple timed transitions). Con-
sider an spn with two places and three transitions as in Figure 3.6. The
marking set is G = { (1, 0), (0, 1), (0, 2) }. Whenever place d1 contains a
token and transitions e1 and e2 ﬁre simultaneously, the token is removed
from place d1. Moreover, either one token is deposited in place d2 or two
tokens are deposited, each scenario occurring with probability 1/2. When-
ever place d2 contains exactly one token and transition e3 ﬁres, the token
is removed from place d2 and a token is deposited in place d1. Whenever
place d2 contains two tokens and transition e3 ﬁres, a token is removed from
place d2 (and no tokens are deposited in place d1). Thus the new-marking
probabilities are given by
p

(0, 1); (1, 0), {e1, e2}

= 1/2,
p

(0, 2); (1, 0), {e1, e2}

= 1/2,
p

(1, 0); (0, 1), e3

= 1,
p

(0, 1); (0, 2), e3

= 1,

108
3. The Marking Process
and p(s′; s, E∗) = 0 otherwise. The distribution function of new clock read-
ings for timed transition e3 is given by
F

x; (0, 1), e3, (1, 0), {e1, e2}

= 1 −e−v(1)x,
F

x; (0, 2), e3, (1, 0), {e1, e2}

= 1 −e−v(2)x,
and
F

x; (0, 1), e3, (0, 2), e3

= 1 −e−v(1)x,
where v(1), v(2) > 0 and v(1) ̸= v(2). With probability 1, the initial mark-
ing is equal to (1, 0). Using arguments similar to the proof of Theorem 4.21,
it can be shown that the marking process is a ctmc with state space
S = { (0, 1), (0, 2) }. The intensity vector is given by
q(s) =

v(1)/2
if s = (0, 1);
v(2)
if s = (0, 2),
and the transition matrix for the embedded jump chain is given by
W(s, s′) =

1
if s′ ̸= s;
0
if s′ = s.
Notes
Our deﬁnition of the marking process follows Haas and Shedler (1989b).
As with the spn building blocks, this deﬁnition was originally motivated
by the discussion of generalized semi-Markov processes in Whitt (1980).
A comprehensive treatment of general state-space Markov chains can be
found in Meyn and Tweedie (1993a); see also Asmussen (1987a, Section I.6),
Chung (1967, Section 9.2), and Durrett (1991, Section 5.6).
Chiola (1991) ﬁrst proposed eﬃcient methods, based essentially on the
relations in (1.17) and (1.18), for updating the set of currently enabled
transitions when generating sample paths of the marking process. Tech-
niques for eﬃcient generation of sample paths on parallel computers have
been studied by Ferscha and Richter (1997), among others.
The assertion in Theorem 2.9(ii) is often presented in the context of
renewal theory, in which the starting assumption is that the sequence
{ ∆n : n ≥1 } consists of i.i.d. random variables; see, for example, p. 58
of Ross (1983). The result in Theorem 2.9(iv) appears as Proposition 2 in
Glynn and Iglehart (1988).
For some recent discussions about simulation of supply chains, see, for
example, the papers of Archibald et al. (1999), Ingalls and Kasales (1999),

3. Notes
109
and Viswanadham and Raghavan (2000). With a concomitant increase in
complexity, the model in Example 2.16 can be extended so that, for ex-
ample, the order size for raw parts also depends on explicit forecasts of
customer demand.
The suﬃcient conditions given in Theorem 3.13 for the lifetime of a mark-
ing process to be a.s. inﬁnite can be viewed as an extension of the suﬃcient
condition for ctmcs given in Theorem 3.23 of C¸inlar (1975, Chapter 8).
This latter condition requires that sups q(s) < ∞. Other conditions that
rule out explosions in ctmcs can be found in Section 8.3 in C¸inlar and
in Sections II.2 and II.3 in Asmussen (1987a). The geometric trials lemma
(Lemma 3.4) used in the proof of Theorem 3.13 can be derived from the
martingale convergence theorem; see Hall and Heyde (1980, Corollary 2.3).
Our treatment of ctmcs follows Asmussen (1987a). Alternative char-
acterizations of recurrence and irreducibility in ctmcs, as well as other
aspects of the fundamental theory of continuous-time chains, can be found
in Asmussen’s book, as well as in the books of Chung (1967), C¸inlar (1975),
Karlin and Taylor (1975), and Kohlas (1982).
Much of the literature on spns concerns nets in which the marking pro-
cess is Markovian. In this setting, the marking process is typically deﬁned
directly as a ctmc, essentially by specifying an inﬁnitesimal generator ma-
trix in terms of the spn building blocks. A typical goal is to compute
the stationary probability distribution of the marking process by solving
the system of equations in (4.7). This task can be nontrivial, especially
when the size of the state space S is very large. Consequently, much eﬀort
has been expended in developing eﬃcient solution techniques. One class of
techniques tries to exploit symmetries in the model; in the ctmc setting
these techniques sometimes are referred to as “lumping” methods. spn-type
frameworks have proven to be convenient for specifying model symme-
tries and for using these symmetries to facilitate computation of stationary
probabilities; see Chiola et al. (1988, 1993). A number of authors such as
Boucherie (1994) and Coleman (1993) have studied spns for which the sys-
tem of equations in (4.7) has a “product-form” solution that is amenable
to eﬃcient computation. Techniques for obtaining bounds and approxima-
tions to time-average limits have been investigated by Campos et al. (1994)
and others. Recently, attention has focused on numerical methods for spns
in which the marking process contains an embedded semi-Markov process
(Choi et al., 1994) and on spns in which the clock-setting distributions are
either deterministic or exponential (Lindemann and Shedler, 1996; Puliaﬁto
et al., 1998). When a Markovian marking process is suﬃciently complex so
that simulation is an attractive alternative, the Markov property can be
exploited to increase simulation eﬃciency—see Hordijk et al. (1976) and,
for an extension of the idea to semi-Markovian marking processes, Fox and
Glynn (1985).
A markedly diﬀerent approach to both the analysis and simulation of
certain spns is to focus not on the stochastic processes associated with

110
3. The Marking Process
the net, but rather on a set of recursive equations that directly describes
the sequence of transition ﬁring times. See, for example, Baccelli (1992),
Baccelli and Canales (1993), and Baccelli et al. (1993, 1996).

4
Modelling Power
The examples in Chapter 2 show how the spn building blocks can be used to
formally specify a variety of discrete-event stochastic systems. The question
then arises as to exactly how large a class of discrete-event systems can
be modelled within the spn framework. Although this question cannot be
answered precisely, the modelling power of spns can usefully be compared
with that of generalized semi-Markov processes (gsmps).
The gsmp is the traditional model for the underlying stochastic process
of a discrete-event system, and a wide range of computer, communication,
manufacturing, and transportation systems have been modelled as gsmps.
Thus gsmps are a good benchmark for assessment of modelling power.
Moreover, the methodology that we develop for comparing the spn and
gsmp formalisms can be used to investigate a variety of other modelling
power questions that arise in the study of discrete-event stochastic systems.
For example, it may be of interest to determine whether inhibitor input
places actually increase the modelling power of spns.
Although gsmps are similar to spns, the two formal systems diﬀer in the
event-scheduling mechanism, the state-transition mechanism, and the form
of the state space. A gsmp is a continuous-time stochastic process that
makes a state transition when one or more “events” associated with the
occupied state occur. Unlike an spn state, which is a vector of token counts,
a gsmp state can be an element of an arbitrary ﬁnite or countably inﬁnite
set. Moreover, the set of “active” (i.e., scheduled) events associated with a
gsmp state is explicitly speciﬁed by the modeller—and can be an arbitrary
subset of the set of all events—whereas the set of enabled transitions asso-
ciated with the marking of an spn is determined by the spn graph. Events

112
4. Modelling Power
associated with a state compete to trigger the next state transition, and
each set of trigger events has its own probability distribution for determin-
ing the new state. In contrast to the new-marking probabilities of an spn,
there are no constraints on the state-transition probabilities of a gsmp. At
each state transition, new events may be scheduled. For each of these new
events, a clock indicating the time until the event is scheduled to occur is
set according to a probability distribution that depends on the old state,
the new state, and the set of events that triggers the state transition. Clock
readings for new events are always positive with probability 1, so that there
is no analog of an immediate transition. If a scheduled event is not in the
set of events that triggers a state transition but is associated with the new
state, then its clock continues to run down (at a state-dependent speed); if
such an event is not associated with the new state, it is cancelled and the
corresponding clock reading is discarded. As with the marking process of an
spn, a gsmp is deﬁned in terms of a general state-space Markov chain that
describes the state and clock-reading vector at successive state-transition
times. Further details of the gsmp formalism are given in Section 4.1.
As can be seen from the foregoing description, gsmps have a more general
state-transition mechanism, event-scheduling mechanism, and form of the
state space than spns. This greater degree of generality means, however,
that it can be hard to come up with the “right” state deﬁnition and set
of events from scratch when modelling a complex system as a gsmp. Also,
gsmps are not particularly amenable to top-down or bottom-up modelling.
For these reasons the spn building blocks often are easier to use than the
gsmp building blocks. Because of their more specialized structure, however,
it might be conjectured that spns have less modelling power than gsmps.
In Section 4.3 we show that, on the contrary, spns have at least the mod-
elling power of gsmps; this result establishes spns as an attractive general
framework for performance analysis of discrete-event stochastic systems.
Speciﬁcally, for any gsmp there exists an spn with a marking process such
that the two processes (and their underlying chains) have the same ﬁnite-
dimensional distributions under an appropriate mapping between the state
spaces. This notion of “strong mimicry” is discussed in Section 4.2.
To establish the modelling power result, we use the building blocks of
the given gsmp to construct a “canonical” spn. We then display a mapping
from the state space of the underlying chain of the canonical spn to the
state space of the underlying chain of the gsmp that preserves the initial
distribution, transition kernel, and holding-time function. In general, the
canonical spn has random inputs and outputs as well as timed and imme-
diate transitions, and the number of tokens in a place is unbounded. When
the state space of the given gsmp is ﬁnite, there exists a 2-bounded canon-
ical spn; if no scheduled events of the gsmp can be cancelled, only timed
transitions are required. When the state space of the gsmp is ﬁnite and the
current state and trigger event uniquely determine the next state, there

4.1 Generalized Semi-Markov Processes
113
exists a 1-bounded canonical spn in which all transitions are deterministic.
No inhibitor input places are needed in any of the canonical spns.
Is the modelling power of spns strictly greater than that of gsmps? In
light of the above modelling power results, such an assertion might appear
plausible because an spn can have one or more immediate transitions but a
gsmp does not have “immediate events.” Indeed, one can easily construct
an spn that is not a “special case” of a gsmp in that the embedded chain
is not the underlying chain of any gsmp and the marking process does not
coincide with any gsmp—see Example 4.1 below, as well as the adjacent
discussion of the particle-counter model. In Section 4.4, however, we show
(Theorem 4.6) that for any spn with timed and immediate transitions there
exists a gsmp that strongly mimics the marking process of the spn. The
state of the canonical gsmp consists essentially of a timed marking along
with a representation of how the clock associated with each timed transition
was set since the last timed marking. The events of the gsmp correspond
to the timed transitions. In combination with the results of Section 4.3,
Theorem 4.6 shows that spns have the same modelling power as gsmps.
Also, as shown in Chapter 5, Theorem 4.6 is useful when establishing re-
currence properties for spns—the theorem provides a means of avoiding
complications caused by the presence of immediate transitions.
4.1
Generalized Semi-Markov Processes
The basic components of a gsmp model are
• A ﬁnite or countably inﬁnite set S of states
• A ﬁnite set E = { e1, e2, . . . , eM } of events
• A mapping s →E(s) from S to the nonempty subsets of E
• State-transition probabilities of the form p(s′; s, E∗)
• Finite nonnegative speeds of the form r(s, e)
• Clock-setting distribution functions of the form F( · ; s′, e′, s, E∗)
The set E(s) is the set of active events in state s, that is, the set of all
events that can possibly occur in state s. Observe that E(s) is a gsmp
building block that is explicitly speciﬁed by the modeller. In contrast, a
set E(s) in an spn is speciﬁed indirectly by means of the normal input
and inhibitor input functions. Similarly to a new-marking probability in
an spn, the state-transition probability p(s′; s, E∗) is the probability that
the new state is s′ given that the events in E∗occur simultaneously in
state s. As in an spn, a clock is associated with each event e ∈E. The
clock for an active event records the remaining time until the event is

114
4. Modelling Power
scheduled to occur; r(s, e) is the speed at which the clock associated with
event e runs down in state s. At a transition from s to s′ triggered by
the simultaneous occurrence of the events in the set E∗, a clock reading
is generated for each new event e′ ∈N(s′; s, E∗) = E(s′) −(E(s) −E∗)
according to F( · ; s′, e′, s, E∗). We assume that F(0; s′, e′, s, E∗) = 0 for
e′ ∈E, so that an event never occurs at the instant that it becomes active.
(Thus a gsmp has no analog of an immediate transition.) For each old event
e′ ∈O(s′; s, E∗) = E(s′) ∩(E(s) −E∗), the old clock reading is kept after
the state transition. For e′ ∈(E(s) −E∗) −E(s′), event e′ (that was active
before the events in E∗occurred) is cancelled after the state transition and
the clock reading is discarded. When the state is s and the set E∗of events
that simultaneously trigger a state transition is E∗= { e∗}, we often write
p(s′; s, e∗) for p(s′; s, {e∗}), and so forth.
The gsmp is the stochastic process that records the state of the system
as it evolves over continuous time. Similarly to the marking process of an
spn, the formal deﬁnition of a gsmp is in terms of a general state-space
Markov chain { (Sn, Cn): n ≥0 }, where Sn represents the state and Cn =
(Cn,1, Cn,2, . . . , Cn,M) represents the clock-reading vector just after the nth
state transition. The state space of the chain is Σ = 
s∈S

{ s } × C(s)

,
where C(s) is the set of possible clock-reading vectors in state s:
C(s) =

c = (c1, . . . , cM): ci ≥0 and ci > 0 if and only if ei ∈E(s)

.
As with spns, the initial state s0 is selected according to an initial-
state distribution ν0 deﬁned on S. Then, for each active event ei ∈E(s0),
an initial clock reading is generated according to an initial clock-setting
distribution function F 0( · ; ei, s0). Thus the initial distribution µ of the
underlying chain is of the form
µ(A) = ν0(s0)

e∈E(s0)
F 0(ai; e, s0)
for all sets
A = { s0 } ×

(c0,1, . . . , c0,M) ∈C(s0): 0 ≤c0,i ≤ai for 1 ≤i ≤M

.
The transition kernel of the chain is speciﬁed in terms of the gsmp build-
ing blocks by a formula identical to (1.9) in Chapter 3. In this speciﬁcation,
we deﬁne the following quantities identically to their spn counterparts:
t∗(s, c) =
min
{ i: ei∈E(s)}

cir−1(s, ei)

,
c∗
i (s, c) = ci −t∗(s, c)r(s, ei),
and
E∗(s, c) = { ei ∈E(s): c∗
i (s, c) = 0 }

4.1 Generalized Semi-Markov Processes
115
for s ∈S, c = (c1, c2, . . . , cM) ∈C(s), and ei ∈E(s). In the preceding
deﬁnition of the holding-time function t∗, we take cir−1(s, ei) to be +∞
when r(s, ei) = 0. Beginning in state s with clock-reading vector c, the
quantity t∗(s, c) is the time to the next state transition and E∗(s, c) is the
trigger event set; that is, the set of events that trigger the state transition.
The gsmp is the stochastic process { X(t): t ≥0 }, where X(t) is the
state of the system at time t ≥0. Formal speciﬁcation of { X(t): t ≥0 } in
terms of the chain { (Sn, Cn): n ≥0 } proceeds exactly as in (1.11)–(1.13)
in Chapter 3. As with the marking process of an spn, the gsmp takes
values in the set S ∪{ ∆} and has piecewise-constant, right-continuous
sample paths. Here ∆corresponds to the state of the system after a possible
explosion; such explosions are ruled out whenever
1. sups,e r(s, e) < ∞.
2. There exists a > 0 such that sups′,e′,s,E∗F(a; s′, e′, s, E∗) < 1.
The proof of this assertion is almost identical to that of Theorem 3.13 in
Chapter 3.
Example 1.1 (Cyclic queues). Consider a closed network of queues with
two single-server service centers and K (≥2) jobs. A job that completes
service at center 1 moves to center 2; a job that completes service at center 2
moves to center 1. Both queueing disciplines are ﬁrst-come, ﬁrst-served.
Successive service times at center i (i = 1, 2) are i.i.d. as a positive random
variable Li. Initially, all jobs are at center 2 and a job is just starting
service. Let X(t) be the number of jobs waiting or in service at center 2 at
time t.
Formal speciﬁcation of the process { X(t): t ≥0 } is as a gsmp with state
space S = { 0, 1, . . . , K } and event set E = { e1, e2 }, where ei = “service
completion at center i.” For s ∈S, event e1 ∈E(s) if and only if s < K
and e2 ∈E(s) if and only if s > 0. The state-transition probabilities are
given by p(s + 1; s, e1) = 1 for 0 ≤s < K, p(s −1; s, e2) = 1 for 0 < s ≤K,
p(s; s, {e1, e2}) = 1 for 0 < s < K, and p(s′; s, E∗) = 0 otherwise.
The clock-setting distribution functions are given by F(x; s′, ei, s, E∗) =
P { Li ≤x } for i = 1, 2, and all speeds are equal to 1. The initial-state
distribution is given by ν0(K) = 1, and the initial clock-setting distribution
function for e2 is F 0(x; e2, K) = P { L2 ≤x }.
Observe that the sets of new events are given by N(1; 0, e1) = { e1, e2 },
N(s+1; s, e1) = { e1 } for 0 < s < K−1, N(K; K−1, e1) = ∅, N(0; 1, e2) =
∅, N(s −1; s, e2) = { e2 } for 1 < s < K, N(K −1; K, e2) = { e1, e2 }, and
N(s; s, {e1, e2}) = { e1, e2 } for 0 < s < K. The sets of old events are given
by O(1; 0, e1) = ∅, O(s + 1; s, e1) = { e2 } for 0 < s < K, O(s −1; s, e2) =
{ e1 } for 1 ≤s < K, O(K −1; K, e2) = ∅, and O(s; s, {e1, e2}) = ∅for
0 < s < K. The set

E(s) −E∗
−E(s′) of cancelled events equals ∅for
s, s′ ∈S and E∗⊆E(s).

116
4. Modelling Power
In analogy with spns—see (4.9) in Chapter 3—we can deﬁne the partial
history of the underlying chain { (Sn, Cn): n ≥0 } of a gsmp. Set t∗
n =
t∗(Sn, Cn) and E∗
n = E∗(Sn, Cn) for n ≥0. Then the partial history Fn
of the underlying chain up to the nth state transition (n ≥1) is deﬁned by
Fn =

S0, E∗
0, t∗
0, S1, E∗
1, t∗
1, . . . , Sn−1, E∗
n−1, t∗
n−1, Sn

.
[Take F0 = { S0 }.] The following result can be established using an argu-
ment similar to the proof of Lemma 4.10 in Chapter 3.
Lemma 1.2. Let γ be an a.s. ﬁnite stopping time with respect to { Fn : n ≥
0 }. Then, with probability 1,
Pµ

Cγ,i > xi for ei ∈H | Fγ

=
 
ei∈H Pµ

Cγ,i > xi | Fγ

if H ⊆E(Sγ);
0
otherwise
for any subset H ⊆E and nonnegative numbers { xi : ei ∈H }.
Lemma 1.2 asserts that the clock readings of a gsmp, observed at a stopping
time γ, are conditionally independent given the partial history up to the
γth state transition.
4.2
Mimicry and Strong Mimicry
In this section we formalize (in Deﬁnitions 2.1 and 2.7) two senses in which
the marking process of an spn can mimic a gsmp. We then give suﬃcient
conditions (Theorem 2.10) for “strong” mimicry.
4.2.1
Deﬁnitions
Let { X(t): t ≥0 } be a gsmp with state space S, holding-time function t∗,
and underlying chain { (Sn, Cn): n ≥0 } having initial distribution µ. Also
let { X(t): t ≥0 } be the marking process of an spn with timed marking
set S, holding-time function t∗, and underlying chain { (Sn, Cn): n ≥0 }
having initial distribution µ.
Deﬁnition 2.1. The marking process { X(t): t ≥0 } is said to mimic the
gsmp { X(t): t ≥0 } if there exists a mapping λ from S onto S such that
{ X(t): t ≥0 } and { λX(t): t ≥0 } have the same ﬁnite-dimensional dis-
tributions; that is,
Pµ{ X(t1) = s1, . . . , X(tm) = sm }
= Pµ { λX(t1) = s1, . . . , λX(tm) = sm }
for m ≥1, 0 ≤t1 < t2 < · · · < tm, and s1, s2, . . . , sm ∈S.

4.2 Mimicry and Strong Mimicry
117
Because both { X(t): t ≥0 } and { X(t): t ≥0 } have piecewise-constant
sample paths, the ﬁnite-dimensional distributions of these processes com-
pletely determine their continuous-time properties. For example, if the pro-
cess { X(t): t ≥0 } mimics { X(t): t ≥0 } and
Pµ

lim
t→∞
1
t
 t
0
f

X(u)

du = r(f)

= 1
as t →∞for a real-valued function f and constant r(f), then it can be
shown that
Pµ

lim
t→∞
1
t
 t
0
f

λX(u)

du = r(f)

= 1.
The following example shows, however, that even if the marking process
of an spn mimics a gsmp, the behavior of the spn and gsmp may appear
diﬀerent when the two models are observed at successive marking changes
(resp., state transitions).
Example 2.2 (Cyclic queues with feedback).
Consider the network of
queues of Example 1.4 in Chapter 2. Recall that the system consists of
two single-server service centers and N (≥2) jobs. With ﬁxed probability
p ∈(0, 1), a job that completes service at center 1 moves to center 2 and
with probability 1−p joins the tail of the queue at center 1. A job that com-
pletes service at service center 2 moves to center 1. The queueing discipline
at each center is ﬁrst-come, ﬁrst-served. Suppose that successive service
times at center i (i = 1, 2) are independent and exponentially distributed
with mean 1/qi. Also suppose that initially all jobs are at center 2 and a job
starts service. Let X(t) be the number of jobs waiting or in service at ser-
vice center 2 at time t. Formal speciﬁcation of the process { X(t): t ≥0 } is
as a gsmp with state space S = { 0, 1, . . . , N } and event set E = { e1, e2 },
where ei = “service completion at center i.” To model the feedback, we
set p(s; s, e1) = 1 −p and p(s + 1; s, e1) = p for 0 ≤s < N. The clock-
setting distributions are given by F(x; s′, e1, s, E∗) = 1 −exp(−q1x) and
F(x; s′, e2, s, E∗) = 1 −exp(−q2x). The remaining details of the speciﬁca-
tion are left to the reader.
An argument similar to the proof of Theorem 4.21 in Chapter 3 shows
that the process { X(t): t ≥0 } is a ctmc. The intensity vector q is
q = (pq1, pq1 + q2, pq1 + q2, . . . , pq1 + q2, q2),
(2.3)
the transition matrix W is
W =









0
1
0
0
. . .
0
0
0
b
0
a
0
. . .
0
0
0
0
b
0
a
. . .
0
0
0
...
...
...
...
...
...
...
...
0
0
0
0
. . .
b
0
a
0
0
0
0
. . .
0
1
0









,
(2.4)

118
4. Modelling Power
e1 = service completion at center 1
e2 = service completion at center 2
Figure 4.1. An spn that mimics cyclic queues with feedback.
where a = pq1/(pq1 +q2) and b = q2/(pq1 +q2), and the initial distribution
v is
v = (0, 0, . . . , 0, 1).
(2.5)
Next, consider an spn with two timed deterministic transitions as in Fig-
ure 4.1; in every marking, the two places contain a combined total of exactly
N tokens. The clock-setting distribution functions are F(x; s′, e1, s, e) =
1 −exp(−pq1x) and F(x; s′, e2, s, e) = 1 −exp(−q2x). All speeds for en-
abled transitions are equal to 1. The initial-marking distribution is given
by ν0

(0, N)

= 1 and the initial clock-setting distribution function for e2
is F0

x; e2, (0, N)

= 1 −exp(−q2x).
Denote the marking process of the spn by { X(t): t ≥0 } and deﬁne a
mapping λ: S →S by λs = s2 for s = (s1, s2) ∈S. An application of
Theorem 4.21 in Chapter 3 shows that the process { λX(t): t ≥0 } is a
ctmc with intensity vector q, transition matrix W, and initial distribution
v given by (2.3)–(2.5), respectively. Because the intensity vector, transi-
tion matrix, and initial distribution are the same for { λX(t): t ≥0 } and
{ X(t): t ≥0 }, these two processes have the same ﬁnite-dimensional distri-
butions. Thus the marking process of the spn mimics the gsmp. Observe,
however, that the spn model does not exhibit the feedback behavior that
occurs in the gsmp model. In this sense the spn model does not behave
identically to the gsmp model even though the marking process of the spn
mimics the gsmp.
The following example illustrates a stronger notion of mimicry that more
eﬀectively captures the notion of identical stochastic behavior.
Example 2.6 (Cyclic queues with feedback).
Modify the spn of Exam-
ple 2.2 so that F(x; s′, e1, s, e) = 1−exp(−q1x). Also modify the new-mark-
ing probabilities so that p(s; s, e1) = 1 −p and p

(s1 −1, s2 + 1); s, e1

= p
for s = (s1, s2) ∈S. This spn is similar to the spn given in Example 1.4 of
Chapter 2. The marking process of this spn mimics { X(t): t ≥0 } in the
sense of Deﬁnition 2.1 (under the mapping λ of Example 2.2). The marking
process also mimics { X(t): t ≥0 } in the following, stronger sense. Denote

4.2 Mimicry and Strong Mimicry
119
the underlying chain of { X(t): t ≥0 } by { (Sn, Cn): n ≥0 } and the state
space of { (Sn, Cn): n ≥0 } by Σ. Similarly, let { (Sn, Cn): n ≥0 } be
the underlying chain of the marking process and Σ be the state space of
{ (Sn, Cn): n ≥0 }. Deﬁne the mapping φ: Σ →Σ by φ(s, c) = (λs, c). It
can be shown that { φ(Sn, Cn): n ≥0 } and { (Sn, Cn): n ≥0 } have the
same ﬁnite-dimensional distributions. Thus marking changes with “feed-
back” of a token mimic the feedback-type state transitions of the gsmp.
Motivated by the above discussion, we give the following deﬁnition. Re-
call from Deﬁnition 1.15 in Chapter 3 that the embedded chain { (S+
n , C+
n ) :
n ≥0 } of the marking process records the marking and clock-reading vec-
tor at each marking change for which the new marking is timed. As before,
we denote the state space of the embedded chain by Σ+ and the initial
distribution by µ+.
Deﬁnition 2.7. The marking process { X(t): t ≥0 } is said to strongly
mimic the gsmp { X(t): t ≥0 } if
(i) there exists a mapping λ from S onto S such that the processes
{ X(t): t ≥0 } and { λX(t): t ≥0 } have the same ﬁnite-dimensional
distributions; and
(ii) there exists a mapping φ from Σ+ onto Σ of the form φ(s, c) =

λs, η(s, c)

such that the discrete-time processes { (Sn, Cn): n ≥0 }
and { φ(S+
n , C+
n ): n ≥0 } have the same ﬁnite-dimensional distribu-
tions.
Clearly, strong mimicry implies mimicry by deﬁnition. On the other hand,
Example 2.2 shows that mimicry need not imply strong mimicry; that is,
condition (i) of Deﬁnition 2.7 can hold while condition (ii) fails to hold.
The following example shows that, conversely, there can exist a mapping
φ = (λ, η) such that { (Sn, Cn): n ≥0 } and { φ(S+
n , C+
n ): n ≥0 } have the
same ﬁnite-dimensional distributions but { X(t): t ≥0 } and { λX(t): t ≥
0 } do not. Thus condition (i) in Deﬁnition 2.7 is not redundant.
Example 2.8 (Alternating renewal process with constant holding times).
Consider a gsmp with state space S = { 1, 2 } and event set E = { e }.
The state-transition probabilities are p(2; 1, e) = p(1; 2, e) = 1 and the
clock-setting distribution functions are
F(x; 1, e, 2, e) = 1[1,∞)(x)
and
F(x; 2, e, 1, e) = 1[2,∞)(x).
All speeds r(s, e) for active events are equal to 1. The gsmp is initially in
state 1 and the initial clock reading is equal to 1. Thus the gsmp visits
state 1 for one time unit, then visits state 2 for two time units, then visits
state 1 for one time unit, and so forth.
Next, consider an spn with two timed deterministic transitions as in
Figure 4.1, except that in every marking the two places contain a com-
bined total of exactly one token, so that the marking set G (= S) is

120
4. Modelling Power
G = { (0, 1), (1, 0) }. The clock-setting distribution functions are
F

x; (1, 0), e1, (0, 1), e2

= 1[2,∞)(x)
and F

x; (0, 1), e2, (1, 0), e1

= 1[1,∞)(x).
All speeds for enabled transitions are equal to 1. The initial marking of
the spn is (1, 0) and the initial clock reading for transition e1 is equal to
2. Thus the marking process visits state (1, 0) for two time units, then
visits state (0, 1) for one time unit, then visits state (1, 0) for two time
units, and so forth. The embedded chain { (S+
n , C+
n ): n ≥0 } coincides with
the underlying chain { (Sn, Cn): n ≥0 } because there are no immediate
transitions.
Set λ(1, 0) = 1, λ(0, 1) = 2, η

(1, 0), (2, 0)

= 1, and η

(0, 1), (0, 1)

= 2.
With probability 1, the successive states of { (Sn, Cn): n ≥0 } are (1, 1),
(2, 2), (1, 1), (2, 2), . . . and the successive states of { (S+
n , C+
n ): n ≥0 }
are

(1, 0), (2, 0)

,

(0, 1), (0, 1)

,

(1, 0), (2, 0)

,

(0, 1), (0, 1)

, . . . , so that
condition (ii) of Deﬁnition 2.7 holds. Condition (i) of Deﬁnition 2.7 fails to
hold with λ deﬁned as above: for example,
Pµ { X(1.5) = 1 } = 0 ̸= 1 = Pµ { λX(1.5) = 1 } .
4.2.2
Suﬃcient Conditions for Strong Mimicry
Theorem 2.10 below gives suﬃcient conditions for strong mimicry and hence
for mimicry. This result asserts that the marking process of an spn strongly
mimics a gsmp if there exists a mapping φ that preserves the initial distri-
bution and transition kernel of the embedded chain and also preserves the
holding-time function. The conditions of the theorem ensure that
Pµ{ (S0, C0) ∈A } = Pµ{ φ(S+
0 , C+
0 ) ∈A },
Pµ{ (Sn+1, Cn+1) ∈A
 (Sn, Cn) = (s, c)

}
= Pµ

φ(S+
n+1, C+
n+1) ∈A
 φ(S+
n , C+
n ) = (s, c)

,
and
t∗
φ(S+
n , C+
n )

= t∗(S+
n , C+
n )
for A ⊆Σ, (s, c) ∈Σ, t ≥0, and n ≥0.
We use the following notation throughout. If φ is a mapping from a set
Σ to another set Σ and A is a subset of Σ, then φ−1A denotes the set
{ x ∈Σ: φx ∈A } and φA (where A ⊆Σ) denotes the set { φx: x ∈A }.
With a slight abuse of notation, we also denote by φ the mapping from Σ∞
to Σ∞given by
φ(x0, x1, . . .) = (φx0, φx1, . . .)

4.2 Mimicry and Strong Mimicry
121
for x0, x1, . . . ∈Σ. Similarly, if D (resp., D) is a set of functions from [0, ∞)
to Σ (resp., Σ), we denote by φ the mapping from D to D deﬁned by setting
φx = x, where x(t) = φ

x(t)

for t ≥0.
Theorem 2.10 requires the existence of a mapping φ—from the state
space of the embedded chain of the spn to the state space of the underly-
ing chain of the gsmp—that preserves initial distributions and transition
kernels. In applications it is convenient to ignore this preservation require-
ment when dealing with zero-probability events. To this end, we introduce
the notion of an “inaccessible” set.
Deﬁnition 2.9. Let φ be a mapping from Σ+ onto Σ. A set H ⊆Σ is said
to be inaccessible with respect to φ if
Pµ{ (Sn, Cn) ∈H for some n ≥0 }
= Pµ{ φ(S+
n , C+
n ) ∈H for some n ≥0 } = 0.
Theorem 2.10. Suppose that there exist a mapping φ from Σ+ onto Σ of
the form φ(s, c) =

λs, η(s, c)

and a set H inaccessible with respect to φ
such that
(i) t∗
φ(s, c)

= t∗(s, c) for all (s, c) ∈Σ+,
(ii) µ(A) = µ+(φ−1A) for all A ⊆Σ −H, and
(iii) P

φ(s, c), A

= P +
(s, c), φ−1A

for all (s, c) ∈Σ+ −φ−1H and
A ⊆Σ −H.
Then { X(t): t ≥0 } strongly mimics { X(t): t ≥0 }.
Proof. We ﬁrst show that { (Sn, Cn): n ≥0 } and { φ(S+
n , C+
n ): n ≥0 }
have the same ﬁnite-dimensional distributions. Set P 1(x, A) = P(x, A) for
A ⊆Σ and x ∈Σ and recursively deﬁne
P n(x, A1, . . . , An) =

A1
P n−1(y, A2, . . . , An) P(x, dy)
for n ≥2, A1, A2, . . . , An ⊆Σ, and x ∈Σ. Similarly, deﬁne probabilities
P n(x, A1, . . . , An) for n ≥1, A1, A2, . . . , An ⊆Σ+, and x ∈Σ+ in terms of
P +. It follows from (1.4) in Chapter 3 that
Pµ { A } = Pµ

(S0, C0) ∈A0, (S1, C1) ∈A1, . . . , (Sn, Cn) ∈An

=

A0
µ(dz0)

A1
P(dz1, z0) · · ·

An
P(dzn, zn−1)
=

A0
P n(x, A1, . . . , An) µ(dx)
(2.11)
for every n ≥0 and set
A = A0 × A1 × · · · × An × Σ × Σ × · · · ⊆Σ∞.
(2.12)

122
4. Modelling Power
A corresponding result holds for Pµ. We now show that the probabilities
P n and P n satisfy
P n(φx, A1, . . . , An) = P n(x, φ−1A1, . . . , φ−1An)
(2.13)
for all n ≥1, x ∈Σ+ −φ−1H, and sets A1, A2, . . . , An ⊆Σ −H. First,
observe that the assertion (2.13) reduces to condition (iii) when n = 1.
Assume for induction that (2.13) holds for a ﬁxed value of n and observe
that
P n+1(φx, A1, . . . , An+1) =

A1
P n(y, A2, . . . , An+1) P(φx, dy)
=

A1
P n(y, A2, . . . , An+1) P +(x, φ−1dy)
=

φ−1A1
P n(φy, A2, . . . , An+1) P +(x, dy)
=

φ−1A1
P n(y, φ−1A2, . . . , φ−1An+1) P +(x, dy)
= P n+1(x, φ−1A1, . . . , φ−1An+1),
where the second equality follows from condition (iii), the third equality fol-
lows from a “change-of-variable” result (Proposition 1.24 in the Appendix),
and the fourth equality follows from the induction hypothesis. Using (2.11),
condition (ii), and (2.13), we ﬁnd that
Pµ { A } =

A0
P n(x, A1, . . . , An) µ(dx)
=

A0
P n(x, A1, . . . , An) µ+(φ−1dx)
=

φ−1A0
P n(φx, A1, . . . , An) µ+(dx)
=

φ−1A0
P n(x, φ−1A1, . . . , φ−1An) µ+(dx)
= Pµ

φ−1A

for any set A ⊆Σ∞of the form (2.12) with each Ai a subset of Σ−H. For a
general set A of the form (2.12), the above argument and the inaccessibility
assumption on H together imply that
Pµ { A } = Pµ { A ∩B } = Pµ

φ−1(A ∩B)

= Pµ

φ−1A

,
where B = (Σ −H)n × Σ∞. Thus the processes { (Sn, Cn): n ≥0 } and
{ φ(S+
n , C+
n ): n ≥0 } have the same ﬁnite-dimensional distributions.

4.2 Mimicry and Strong Mimicry
123
It remains to show that the processes { X(t): t ≥0 } and { λX(t): t ≥0 }
have the same ﬁnite-dimensional distributions. For ease of exposition, sup-
pose that { (Sn, Cn): n ≥0 } and { (S+
n , C+
n ): n ≥0 } each has been de-
ﬁned using the standard construction for general state-space Markov chains
discussed at the end of Section 3.1.1. Thus the underlying sample spaces
of the chains are Σ∞and Σ∞, respectively.1 Set Γ = S × ℜ+ and let Ψ
be the mapping from Σ to Γ deﬁned by Ψ(s, c) =

s, t∗(s, c)

. Also let
D(S) be the set of possible sample paths of the process { X(t): t ≥0 };
that is, D(S) is the set of right-continuous piecewise-constant functions
from [0, ∞) to S ∪{ ∆}. Next deﬁne a mapping Φ from Γ∞to D(S) as
follows: for g =

(s0, t0), (s1, t1), . . .

∈Γ∞and t ≥0, set
n(g, t) = inf { n ≥0: t0 + t1 + · · · + tn > t } ,
and then set Φg = x, where x is the unique element of D(S) that satisﬁes
x(t) =

sn(g,t)
if n(g, t) < ∞;
∆
if n(g, t) = ∞.
It follows from these deﬁnitions that2 X(t, ω) = (ΦΨω)(t) for ω ∈Σ∞and
t ≥0. Deﬁne sets D(S) and Γ and mappings Ψ and Φ in a similar manner,
and let θ be the mapping from Σ∞to (Σ+)∞deﬁned by
θ

(s0, c0), (s1, c1), . . .

=

(sγ(0), cγ(0)), (sγ(1), cγ(1)), . . .

,
where γ( · ) is deﬁned by (1.14) in Chapter 3. Observe that X(t, ω) =
(ΦΨθω)(t) for ω ∈Σ∞and t ≥0. To establish mimicry, it therefore suﬃces
to show that
Pµ

Ψ−1Φ−1A

= Pµ

θ−1Ψ−1Φ−1λ−1A

(2.14)
for A ⊆D(S). To this end, set Λ(s, t) = (λs, t) for (s, t) ∈Γ. Observe that
by condition (i)
Ψφx = ΛΨx
(2.15)
for x ∈Σ. Also observe that by deﬁnition
Λ−1Φ−1A = Φ−1λ−1A
(2.16)
for A ⊆D(S). Since { (Sn, Cn): n ≥0 } and { φ(S+
n , C+
n ): n ≥0 } have
the same ﬁnite-dimensional distributions, it also follows that
Pµ { B } = Pµ

θ−1φ−1B

(2.17)
1When the foregoing chains are each deﬁned on some probability space other than
the standard one, the proof goes through almost exactly as described, except that an
additional mapping comes into play for each chain, namely the mapping from an element
of the sample space to the corresponding sample path of the chain.
2Recall here the notational conventions introduced just before Deﬁnition 2.9.

124
4. Modelling Power
for B ⊆Σ∞. Thus, for a set A ⊆D(S),
Pµ

Ψ−1Φ−1A

= Pµ

θ−1φ−1Ψ−1Φ−1A

= Pµ

θ−1Ψ−1Λ−1Φ−1A

= Pµ

θ−1Ψ−1Φ−1λ−1A

by (2.15)–(2.17), and (2.14) follows.
The quantities µ+ and P + often can be computed in a straightforward
manner from µ and P when verifying the conditions of Theorem 2.10.
Moreover, it suﬃces to examine only sets A of the form
A = { s } × { (c1, . . . , cM): 0 ≤ci ≤ai for 1 ≤i ≤M } .
(2.18)
Example 2.19 (Producer–consumer system with nonpreemptive priority).
As discussed in Example 2.1 in Chapter 2, the producer–consumer system
with nonpreemptive priority can be modelled as an spn—see Figure 2.4.
This system can also be modelled within the gsmp framework. Speciﬁcally,
set X(t) =

U1(t), U2(t), V (t)

, where Ui(t) denotes the number of items
awaiting transmission in buﬀer i at time t and
V (t) =



i
if transmission of an item to consumer i
is underway at time t;
0
if no transmission is underway at time t.
Formal speciﬁcation of the process { X(t): t ≥0 } is as a gsmp. The state
space S is the set of all elements
(u1, u2, v) ∈{ 0, 1, . . . , B1 } × { 0, 1, . . . , B2 } × { 0, 1, 2 }
such that
1. v > 0 whenever u1 + u2 > 0.
2. u1 + 1{1}(v) ≤B1.
3. u2 + 1{2}(v) ≤B2.
The event set is E = { e1, e2, e3 }, where ei = “creation of item by producer
i” (i = 1, 2) and e3 = “end of transmission.” For s = (u1, u2, v), ei ∈E(s)
(i = 1, 2) if and only if ui + 1{i}(v) < Bi, and e3 ∈E(s) if and only if
v > 0.
The state-transition probabilities are as follows. If e = e1 = “creation of
item by producer 1,” then p(s′; s, e) = 1 when
s = (u1, u2, v) with v > 0
and
s′ = (u1 + 1, u2, v)
and when
s = (0, 0, 0)
and
s′ = (0, 0, 1).

4.2 Mimicry and Strong Mimicry
125
If e = e2 = “creation of item by producer 2,” then p(s′; s, e) = 1 when
s = (u1, u2, v) with v > 0
and
s′ = (u1, u2 + 1, v)
and when
s = (0, 0, 0)
and
s′ = (0, 0, 2).
If e = e3 = “end of transmission,” then p(s′; s, e) = 1 when
s = (u1, u2, v) with u1 > 0
and
s′ = (u1 −1, u2, 1),
when
s = (0, u2, v) with u2 > 0
and
s′ = (0, u2 −1, 2),
and when
s = (0, 0, v)
and
s′ = (0, 0, 0).
All other state-transition probabilities p(s′; s, e) are equal to 0. For s, s′ =
(u′
1, u′
2, v′) ∈S and e ∈E(s), the clock-setting distribution functions
are F(x; s′, e1, s, e) = P { A1 ≤x }, F(x; s′, e2, s, e) = P { A2 ≤x }, and
F(x; s′, e3, s, e) = P { Lv′ ≤x }. All speeds for active events are equal to 1.
We now establish conditions (i)–(iii) of Theorem 2.10 with
H = { (s, c) ∈Σ: |E∗(s, c)| > 1 } .
For s = (s1, . . . , s7) ∈S and c = (c1, c2, . . . , c6) ∈C(s), set η(s, c) =
(c1, c2, c3), where c1 = c1, c2 = c4, and
c3 =

c3
if s3 = 1;
c6
if s6 = 1.
Also set λs = (u1, u2, v), where u1 = s2, u2 = s5 and
v =





1
if s3 = 1;
2
if s6 = 1;
0
if s7 = 1.
Finally, set φ(s, c) =

λs, η(s, c)

. Denote the initial distribution of the
gsmp by µ and set
µ(A) = µ

φ(A ∩Σ+)

for A ⊆Σ. To see that condition (i) holds, ﬁx
s = (s1, s2, 1, s4, s5, 0, 0)
and
c = (c1, 0, c3, c4, 0, 0),
(2.20)
where s1 + s2 = B1 −1 and s4 + s5 = B2. Then λs = (s2, s5, 1), η(s, c) =
(c1, c4, c3), and
t∗
φ(s, c)

= min(c1, c3, c4) = t∗(s, c).

126
4. Modelling Power
Similar computations establish condition (i) for every other pair (s, c) ∈
Σ+. Now ﬁx A ⊆Σ. Observe that φ is a one-to-one mapping, so that
there exists a unique subset B ⊆Σ+ such that A = φB. It follows from
the deﬁnition of µ that µ+(B) = µ(B) = µ(φB). Formal substitution of
B = φ−1A into the latter expression yields µ(A) = µ+(φ−1A). Since A
is arbitrary, this establishes condition (ii). Finally, ﬁx s and c as in (2.20)
with s2 ≥1 and c3 < min(c1, c4), and observe that (s, c) ∈Σ+ −φ−1H.
Set
A = { (s2 −1, s5, 1) } ×

(c′
1, c′
2, c′
3): 0 ≤c′
i ≤ai for 1 ≤i ≤3

.
Then
P

φ(s, c), A

= 1[0,a1](c1 −c3)1[0,a2](c4 −c3)P { L1 ≤a3 } .
On the other hand,
φ−1A = { (s1 + 1, s2 −1, 1, s4, s5, 0, 0) }
×

(c′
1, 0, c′
3, c′
4, 0, 0): 0 ≤c′
1 ≤a1, 0 ≤c′
3 ≤a3, and 0 ≤c′
4 ≤a2

and
P +
(s, c), φ−1A

= 1[0,a1](c1 −c3)1[0,a2](c4 −c3)P { L1 ≤a3 }
= P

φ(s, c), A

.
Similar computations establish condition (iii) for every other pair (s, c) ∈
Σ+ −φ−1H and set A ⊂Σ of the form (2.18). Thus the marking process
of the spn strongly mimics the gsmp.
We conclude this section by giving a corollary to Theorem 2.10 that is
applicable to spns with no immediate transitions. Although the scope of
this result is somewhat limited, the conditions on the building blocks of
the spn and gsmp are relatively easy to check.3
Corollary 2.21. Suppose that E′ = ∅. Also suppose that there exist a
mapping λ from S to S and a one-to-one mapping ψ from E to E such
that
(i) E(λs) = ψE(s),
(ii) p(λs′; λs, ψE∗) = p(s′; s, E∗),
(iii) F( · ; λs′, ψe′, λs, ψE∗) = F( · ; s′, e′, s, E∗),
3In the presence of immediate transitions, it appears diﬃcult to state simple corollar-
ies to Theorem 2.10 that involve direct conditions on the building blocks. This diﬃculty
arises from the fact that clocks can be set at marking changes for which either the old
or new marking is immediate.

4.3 Mimicry Theorems for Marking Processes
127
(iv) r(λs, ψe) = r(s, e),
(v) F 0( · ; ψe, λs) = F0( · ; e, s), and
(vi) ν0(λs) = ν0(s)
for all s, s′, e, e′, and E∗. Then { X(t): t ≥0 } strongly mimics { X(t): t ≥
0 }.
Proof. Write E = { e1, e2, . . . , eM } and E = { e1, e2, . . . , eM }, and as-
sume without loss of generality that ψei = ei for 1 ≤i ≤M. For s ∈S
and c = (c1, c2, . . . , cM) ∈C(s), set η(s, c) ≡η(c) = c and φ(s, c) =

λs, η(s, c)

. Then, for example, we have
t∗(s, c) =
min
{ i: ei∈E(s) } ci/r(s, ei)
=
min
{ i: ei∈E(s) } ci/r(λs, ψei)
=
min
{ i: ei∈E(λs)}
ci/r(λs, ei)
= t∗
φ(s, c)

for (s, c) ∈Σ+, and condition (i) of Theorem 2.10 holds. Similar arguments
then establish the remaining conditions of Theorem 2.10.
Remark 2.22.
Observe that if with probability 1 the transitions in a set
E∗never ﬁre simultaneously when the marking is s and similarly for the
set ψE∗and state λs, then the conclusion of Corollary 2.21 holds even if
conditions (ii) and (iii) fail to hold for s and E∗. Similarly, if ν0(s) = 0,
then the conclusion of Corollary 2.21 holds even if condition (v) fails to
hold for marking s and a transition e ∈E(s). Such “strengthenings” of
Corollary 2.21 are directly analogous to the use of the inaccessible set H
in Theorem 2.10 and are applied throughout without further comment.
4.3
Mimicry Theorems for Marking Processes
In this section we show that spns have at least the modelling power of
gsmps. We start by providing some modelling-power results for several re-
stricted classes of gsmps. As might be expected, each of these classes can
be mimicked by a correspondingly restricted class of spns. Our ﬁrst result
concerns gsmps with a ﬁnite state space in which the current state and
trigger event set uniquely determine the next state. Any such gsmp can
be mimicked by the marking process of a 1-bounded spn with determinis-
tic timed and immediate transitions. Our next result asserts that for any
gsmp with a ﬁnite state space there exists a 2-bounded spn having a mark-
ing process that strongly mimics the gsmp; if events are never cancelled,

128
4. Modelling Power
Figure 4.2. State-transition diagram for two-state gsmp with E(1) = { e1, e2 }
and E(2) = { e1 }.
no immediate transitions are required. Finally, we show in Theorem 3.4
that for any gsmp having a countably inﬁnite state space there exists a
2-bounded spn having a marking process that strongly mimics the gsmp.
Each of these results is proved in the same way: we use the building blocks
of the gsmp to construct a canonical spn and then display mappings that
satisfy the conditions of Theorem 2.10 or Corollary 2.21.
4.3.1
Finite-State Processes
Theorem 3.1. Suppose that all nonzero state-transition probabilities of a
gsmp with ﬁnite state space are equal to 1. Then there exists a 1-bounded
spn with deterministic transitions having a marking process that strongly
mimics the gsmp.
Proof. Without loss of generality, suppose that the state space of the
gsmp is S = { 1, 2, . . . , K } and the event set is E = { e1, e2, . . . , eM }.
Denote the state-transition probabilities by p(s′; s, E∗), the set of active
events in state s by E(s), and so forth.
As mentioned above, the idea is to construct a canonical spn and then
show that the marking process of this spn mimics the gsmp. We illustrate
the basic ideas that underlie the canonical spn construction by means of
a simple example. Consider a gsmp with state space S = { 1, 2 }, event
set E = { e1, e2 }, and active event sets given by E(1) = { e1, e2 } and
E(2) = { e1 }. The state-transition probabilities are given by p(2; 1, e1) =
p(1; 1, e2) = p(1; 2, e1) = 1; see Figure 4.2. Each event is “simple” in that
the clock-setting distribution for the event does not depend explicitly on
the old state, new state, or set of trigger events. All speeds for active events
are equal to 1. The canonical spn for this gsmp is displayed in Figure 4.3.
Place dj (j = 1, 2) contains a token if and only if the current state of the
gsmp is j, and place d1,i contains a token (i = 1, 2) if and only if event ei
(of the gsmp) is currently active. There is a token in place d2,i if and only
if event ei has just occurred, and there is a token in place d3,i if and only
if active event ei is to be cancelled. All the transitions are deterministic.
When there is a token in place d1, for example, and transition e1,1 ﬁres
(i.e., the gsmp is in state 1 and event e1 occurs), a token is deposited in
place d2,1, and exactly one of the immediate transitions of the form ei,j,k
becomes enabled, namely e1,1,2. When e1,1,2 ﬁres, it removes a token from

4.3 Mimicry Theorems for Marking Processes
129
e1,i = event ei (of the gsmp) triggers a state transition
e2,i = event ei (of the gsmp) is cancelled
ei,j,k = the gsmp makes a transition from state j to k when event ei occurs
Figure 4.3. spn representation of two-state gsmp.
place d1 and deposits a token in place d2; such a ﬁring corresponds to a
transition of the gsmp from state 1 to state 2. Moreover, e1,1,2 deposits
tokens in places d1,1 and d3,2 when it ﬁres, so that
1. Transition e1,1—which corresponds to event e1 of the gsmp—becomes
enabled.
2. Immediate transition e2,2 becomes enabled and ﬁres, causing tran-
sition e1,2—which corresponds to event e2 of the gsmp—to become
disabled.
Thus the transitions become enabled or disabled in accordance with the
event-scheduling mechanism of the gsmp. The clock-setting distribution
and speeds for transition e1,i (i = 1, 2) are the same as the clock-setting
distribution and speeds for event ei in the gsmp.
For a general gsmp, the canonical spn is constructed along similar lines.
The spn has a place dj for each state j of the gsmp and a transition e1,i for
each event ei. If the gsmp makes a transition from state j to k when event
ei occurs, then the canonical spn contains a deterministic transition ei,j,k.
If the events in a set E∗=

ei1, ei2, . . . , eil

can occur simultaneously in
the gsmp and trigger a transition from state j to k, then the spn contains
an immediate transition denoted ei1,...,il,j,k. The set of normal input places

130
4. Modelling Power
is
I(ei1,...,il,j,k) = { dj } ∪{ d2,i1, d2,i2, . . . , d2,il } ,
and the set of output places is
J(ei1,...,il,j,k) = { dk } ∪{ d1,l : el ∈N(k; j, E∗) }
∪

d3,l : el ∈

E(j) −E∗
−E(k)

.
We use the extended priority scheme discussed at the end of Section 2.3.2 to
handle simultaneous transition ﬁrings. Speciﬁcally, we set P(ei1,...,il,j,k) = 1
and P(ei,j,k) = 0 for all i, j, and k so that when ei1,...,il,j,k ﬁres simultane-
ously with transitions ei1,j,k, ei2,j,k, . . . , eim,j,k, the net behaves as if only
ei1,...,il,j,k ﬁres. The priorities for transitions of the form e2,i are all equal
to 0, so that when two or more such transitions ﬁre, the net behaves as if
these transitions ﬁre sequentially (in arbitrary order).
The speeds for the spn are given by r(s, e1,i) = r(λs, ei), where λs = j for
s = (s1, . . . , sj−1, 1, sj+1, . . . , sK, . . .) ∈S. The clock-setting distribution
functions are given by
F( · ; s′, e1,l, s, ei,j,k) = F( · ; k, el, j, ei).
Set φ(s, c) =

λs, η(s, c)

for (s, c) ∈Σ+, where η(s, c) = (c1,1, c2,1, . . . ,
cM,1) for s ∈S and c = (c1,1, c1,2, . . . , c1,M, . . .) ∈C(s). Finally, set µ(A) =
µ

φ(A ∩Σ+)

for A ⊆Σ. Tedious but straightforward calculations show
that the mapping φ satisﬁes the conditions of Theorem 2.10. Thus the
marking process of the above spn strongly mimics the gsmp.
Remark 3.2. The canonical spn constructed in the proof of Theorem 3.1
can be used with relatively minor modiﬁcations to prove the assertion in
Section 2.4 that for any gsmp with a ﬁnite state space, unit speeds, and a
ﬁxed initial state, there exists a restricted spn with a marking process that
strongly mimics the gsmp. The primary changes in the canonical spn are
that
• For each event in the gsmp there are, in general, several corresponding
timed transitions in the spn, one for each of the distinct distribution
functions used in the gsmp to set the clock for the event.
• The spn contains a deterministic immediate transition of the form
ei,j,k for each i, j, and k such that p(k; j, ei) > 0, and similarly for
transitions of the form ei1,...,il,j,k.
If, with probability 1, events in the gsmp never occur simultaneously, then
the canonical spn is deterministic in the sense of Section 2.4.
Theorem 3.3 concerns gsmps with ﬁnite state space and arbitrary state-
transition probabilities.

4.3 Mimicry Theorems for Marking Processes
131
ei = event ei (of the gsmp) triggers a state transition
Figure 4.4. spn representation of gsmp with ﬁnite state space and no cancelled
events.
Theorem 3.3. For any gsmp with ﬁnite state space there exists a 2-bound-
ed spn with random inputs and outputs having a marking process that
strongly mimics the gsmp. If active events are never cancelled, no imme-
diate transitions are required.
Proof. Consider an arbitrary but ﬁxed gsmp and, as in the proof of
Theorem 3.1, suppose that the state space of the gsmp is of the form
S = { 1, 2, . . . , K } and the event set is E = { e1, e2, . . . , eM }. First sup-
pose that

E(s)−E∗
−E(s′) = ∅for all s′, s, and E∗, so that active events
are never cancelled. Construct a canonical spn with ﬁnite state space as in
Figure 4.4. Place dj contains two tokens if and only if the gsmp is in state j;
otherwise, place dj contains one token. Place d1,j contains one token if and
only if event ej is active; otherwise, place d1,j contains no tokens. Whenever
place dj contains two tokens and transition ei ﬁres, one token is removed
from each of places dj and d1,i. Moreover, one token is deposited in exactly
one of places d1, d2, . . . , dK; the probability that the token is deposited in
place dk (1 ≤k ≤K) is p(k; j, ei). Finally, given that a token is deposited
in place dk, tokens are deposited in places d1,i1, d1,i2, . . . , d1,il, where the
indices i1, i2, . . . , il are such that4 N(k; j, ei) =

ei1, ei2, . . . , eil

. Similar
marking changes occur when two or more transitions ﬁre simultaneously.
Formally,
p(s′; s, E∗) = p(λs′; λs, ψE∗),
4Recall that N(k; j, ei) is the set of new events for the gsmp when ei triggers a
transition from state j to k.

132
4. Modelling Power
where
λs = j such that sj = 2
for s = (s1, . . . , sK, s1,1, . . . , sM,1) ∈S and ψei = ei for 1 ≤i ≤M. The
speeds for the spn are given by r(s, e) = r(λs, ψe) and the clock-setting
distribution functions by
F( · ; s′, e′, s, E∗) = F( · ; λs′, ψe′, λs, ψE∗).
The initial-marking distribution is given by ν0(s) = ν0(λs) and the initial
clock-setting distributions by F0( · ; e, s) = F 0( · ; ψe, λs). It now follows
from Corollary 2.21 that the marking process of the canonical spn strongly
mimics the gsmp.
Now suppose that event ei of the gsmp can be cancelled. The proof
proceeds almost exactly as above, except that we modify the canonical spn
by adding an immediate transition and corresponding input place. This
new transition and new place are used to mimic the cancellation of events
in the same manner as transition e2,2 and place d3,2 are used in Figure 4.3.
4.3.2
Countable-State Processes
We now give a mimicry result for gsmps with a countably inﬁnite state
space.
Theorem 3.4. For any gsmp with a countably inﬁnite state space there
exists an spn with random inputs and outputs, timed transitions, and imme-
diate transitions having a marking process that strongly mimics the gsmp.
No inhibitor input places are required.
Proof. Consider a gsmp with state space S = { 1, 2, . . . } and event set
E = { e1, e2, . . . , eM }. First suppose that, with probability 1, events in the
gsmp never occur simultaneously. Construct a canonical spn consisting of a
place d0 and M identical subnets—one subnet for each event in the gsmp.
Figure 4.5 displays place d0 and the subnet corresponding to a generic
gsmp event ei. For ease of exposition, we ﬁrst display a canonical spn that
has inhibitor input places and then show how to modify the spn to contain
only normal input places.
Place d0 contains s tokens if and only if the gsmp is in state s. Place d0,i
contains one token if and only if event ei of the gsmp is active; otherwise,
place d0,i contains no tokens.
Suppose that place d0 contains s tokens and transition e0,i ﬁres; this
scenario corresponds to the occurrence of event ei in state s. Then either
transition e3,i ﬁres a random number of times in succession before becom-
ing disabled—resulting in a random number of tokens being deposited in

4.3 Mimicry Theorems for Marking Processes
133
e0,i = event ei (of the gsmp) triggers a state transition
Figure 4.5. spn representation of gsmp with countably inﬁnite state space.
place d0—or transition e1,i ﬁres a random number of times in succession—
resulting in a random number of tokens being removed from place d0. The
mechanism by which either transition e3,i or e1,i ﬁres is essentially the same
as in the spn model of a queue with batch arrivals given in Section 2.2.2;
the probability that place d0 contains s + l tokens after the assorted im-
mediate transitions stop ﬁring is p(s + l; s, ei), where −(s −1) ≤l < ∞.
Moreover, similarly to the previous canonical spns, tokens are deposited in
places of the form d0,j or d5,j so that transitions of the form e0,j become
enabled or disabled in accordance with the event-scheduling mechanism of
the gsmp.
In more detail, transition e0,i deposits a token in either place d3,i or
place d1,i when it ﬁres; the token is deposited in place d3,i with probability
qu = 	∞
j=1 p(s + j; s, ei) and in place d1,i with probability 1 −qu. (Here
qu is the probability that the new state s′ satisﬁes s′ > s.) If the token
is deposited in place d3,i, then immediate transition e3,i ﬁres a random
number of times, in the following manner. Whenever e3,i ﬁres with k −1
tokens in place d0 and j −1 tokens in place d3,i (k ≥s + 1 and j ≥1),
one token is deposited in each of places d0 and d3,i, bringing the respective

134
4. Modelling Power
token counts to k and j, respectively. Moreover, with probability
pu(k, j, i) = p(k; k −j, ei)
) ∞

l=0
p(k + l; k −j, ei)
*−1
,
a token is also deposited in place d4,i, which causes e3,i to become disabled
and immediate transition e4,i to become enabled, while with probability
1 −pu(k, j, i) no token is deposited in place d4,i and e3,i continues to ﬁre.
[Observe that pu(k, j, i) is the conditional probability that the new state is
k = s + j, given that the new state is greater than or equal to s + j.] When
a token is deposited in place d4,i, transition e4,i ﬁres repeatedly, removing
all tokens from place d3,i and, upon the last of these ﬁrings, removing the
token in place d4,i. The overall probability p that e3,i ﬁres exactly j times
and then becomes disabled is
p = qu

1 −pu(s + 1, 1, i)

1 −pu(s + 2, 2, i)

· · ·

1 −pu(s + j −1, j −1, i)

pu(s + j, j, i)
= p(s + j; s, ei).
When e3,i ﬁres and deposits a token in place d4,i (thereby leaving the ﬁnal
token count in place d0 equal to s + j), a token is also deposited in place
d0,m (1 ≤m ≤M) if em ∈N(s + j; s, ei) and in place d5,m if em ∈

E(s)−{ ei }

−E(s+j). The clock for each newly enabled transition e0,m
is set according to the distribution function F( · ; s + j, em, s, ei). Thus the
spn emulates the event-scheduling mechanism of the gsmp at a transition
from state s to s + j. Observe that the sole purpose of place d3,i is to keep
count of the number of times that transition e3,i has ﬁred, allowing the spn
to “remember” that the initial token count in place d0 was s. Transitions
e1,i and e2,i ﬁre in an analogous manner, changing the token count in place
d0 from s to s −j with probability p(s −j; s, ei).
The speeds for the canonical spn are given by r(s, e) = r(λs, ψe), where
λs = s0
for s = (s0, s0,1, . . . , s5,1, . . . , s0,M . . . , s5,M) ∈S and ψe0,i = ei for 1 ≤i ≤
M. For s ∈S and c = (c0,1, . . . , c5,1, . . . , c0,M, . . . , c5,M) ∈C(s), set
η(s, c) = (c0,1, c0,2, . . . , c0,M).
Finally, the initial distribution is given by µ(A) = µ(φA) for A ⊆Σ, where
φ(s, c) =

λs, η(s, c)

for (s, c) ∈Σ. A straightforward argument shows that
the conditions of Theorem 2.10 hold, so that the marking process of the
canonical spn strongly mimics the gsmp.
Now suppose that two or more events of the gsmp can occur simultane-
ously. The proof proceeds almost exactly as above, except that we modify

4.3 Mimicry Theorems for Marking Processes
135
Figure 4.6. spn representation with no inhibitor inputs.
the canonical spn by adding additional subnets, each of which corresponds
to a set E∗of events that can occur simultaneously.
The inhibitor input places used in the construction of the canonical spn
are convenient, but not essential. An spn always can be modiﬁed so that (1)
the modiﬁed spn has no inhibitor input places and (2) the marking process
of the modiﬁed spn strongly mimics the marking process of the original spn
in a sense analogous to Deﬁnition 2.7. This modiﬁcation depends critically
on the use of random outputs and immediate transitions and is illustrated
using the subnet in the top portion of Figure 4.6. This subnet captures
the various possible relationships between a place and a transition. To
eliminate the need for inhibitor input places, modify the subnet by adding
two places d2 and d3 and a deterministic immediate transition e5 as in the
bottom portion of Figure 4.6. The idea is to modify the subnet so that
place d2 contains one token if and only if place d1 contains no tokens and
contains no tokens only if place d1 contains at least one token. To this end,
we change the new-marking probabilities so that the transitions behave as
follows. Whenever place d1 contains only one token and transition e2 ﬁres
and removes this token, e2 also deposits a token in place d2. Whenever
there is one token in place d2, no tokens in place d1, and transition e4 ﬁres
and deposits a token in d1, transition e4 also removes the token in d2. If,
rather than e4, transition e1 ﬁres and deposits a token in d1, then e1 also
deposits a token in place d3, which causes immediate transition e5 to ﬁre

136
4. Modelling Power
Figure 4.7. spn with dependent clock readings.
and remove the token in d2. Otherwise, transitions e1, e2, e3, and e4 remove
and deposit tokens as in the original spn.
4.4
Converse Results
Because spns may have immediate transitions, the marking process of an
spn need not behave like a gsmp. Consider, for example, the spn model of
the particle counter from Example 2.11 in Chapter 2—see Figure 2.15. Re-
call that when the marking process makes a state transition from (1, 1, 0, 0)
to (1, 1, 0, 0) triggered by the ﬁring of transition e1, the clock for transition
e2 appears to be reset. Such resetting is not allowed in the gsmp frame-
work. There also exist spns in which the clock readings just after a speciﬁed
marking change are conditionally dependent given the partial history of the
embedded chain up to the marking change.5 As shown by Lemma 1.2, such
dependence cannot occur in gsmps.
Example 4.1 (spn with dependent clock readings).
Consider the spn
displayed in Figure 4.7. The set of immediate markings is S′ = { (0, 1, 0, 0, 0,
0), (0, 0, 0, 0, 1, 0) } and the set of timed markings is the set of all elements
5In analogy to the partial history Fn of the underlying chain—see Section 3.4.2—we
deﬁne the partial history F+
n of the embedded chain by setting F+
0 = { S+
0 } and F+
n =
{ S+
0 , E+
0 , t+
0 , S+
1 , E+
1 , t+
1 , . . . , S+
n−1, E+
n−1, t+
n−1, S+
n } for n ≥1, where t+
n = t∗(S+
n , C+
n )
and E+
n = E∗(S+
n , C+
n ) for n ≥0.

4.4 Converse Results
137
(s1, s2, . . . , s6) ∈{ 0, 1 }6 such that s2 = s5 = 0, s1+s3 = 1, and s4+s6 = 1.
All transitions except e1 are deterministic. Whenever transition e1 ﬁres, it
removes one token from each of places d1 and d4 and deposits one token
in either place d2 or d5; the token is deposited in place d2 with probability
1/2 and in place d5 with probability 1/2. The clock-setting distributions
for transitions e3 and e5 are given by
F(x; s′, e3, s, e∗) ≡F(x; e3, e∗) =

1[1,∞)(x)
if e∗= e2;
1[2,∞)(x)
if e∗= e4
and F(x; s′, e5, s, e∗) ≡F(x; e5, e∗) = F(x; e3, e∗). All speeds for enabled
transitions are equal to 1. Suppose that the initial marking is (1, 0, 0, 1, 0, 0)
and let γ be the random index of the ﬁrst marking change at which the
new marking is (0, 0, 1, 0, 0, 1) Observe that, for example,
P

Cγ,3 = 2, Cγ,5 = 2 | F+
γ

= 1/2
but
P

Cγ,3 = 2 | F+
γ

P

Cγ,5 = 2 | F+
γ

= 1/4.
That is, the clock readings for transitions e3 and e5 just after the γth
marking change are not conditionally independent given F+
γ . It follows that
the marking process cannot be a gsmp, as this would violate Lemma 1.2.
In light of the foregoing examples, one might conjecture that there exist
spns that cannot be mimicked by gsmps (in a sense analogous to mimicry
of gsmps by spns). In this section we show that, to the contrary, for any spn
with timed and immediate transitions, there exists a gsmp that strongly
mimics the marking process of the spn. It then follows from this result and
the results in Section 4.3 that spns and gsmps have the same modelling
power.
The deﬁnition of strong mimicry by a gsmp of the marking process of
an spn is analogous to Deﬁnition 2.7. As before, let { X(t): t ≥0 } be a
gsmp with state space S and underlying chain { (Sn, Cn): n ≥0 }, and let
{ X(t): t ≥0 } be a marking process of an spn with timed marking set S
and underlying chain { (Sn, Cn): n ≥0 }.
Deﬁnition 4.2. The gsmp { X(t): t ≥0 } is said to strongly mimic the
marking process { X(t): t ≥0 } if
(i) there exists a mapping λ from S onto S such that { X(t): t ≥0 } and
{ λX(t): t ≥0 } have the same ﬁnite-dimensional distributions, and
(ii) there exists a mapping φ from Σ onto Σ+ of the form φ(s, c) =

λs, η(s, c)

such that the discrete-time processes { (S+
n , C+
n ): n ≥0 }
and { φ(Sn, Cn): n ≥0 } have the same ﬁnite-dimensional distribu-
tions.

138
4. Modelling Power
To prove our main result, we use the building blocks of the spn to con-
struct a canonical gsmp that strongly mimics the marking process. The
state of the gsmp consists essentially of a timed marking along with a rep-
resentation of how the clock associated with each timed transition was set
since the last timed marking. The events of the gsmp correspond to the
timed transitions. If, moreover, enabled transitions of the spn can become
disabled and then enabled again during a sojourn in the set of immediate
markings (resulting in an apparent “resetting” of the corresponding clocks),
then the canonical gsmp requires additional events and further augmenta-
tion of the state space. The following examples illustrate these ideas and
motivate our general construction of the canonical gsmp.
Example 4.3 (Particle counter).
Using the building blocks of the spn
shown in Figure 2.15, construct a gsmp with state space
S = { (1, 0, 0, 0, 0), (1, 1, 0, 0, 1), (1, 1, 0, 0, 2) }
and event set
E =

e1, e2,1, e2,2

.
Observe that each state is of the form s = (s, u), where s is a timed marking
of the spn and u ∈{ 0, 1, 2 }. The idea is that events e2,1 and e2,2 correspond
to transition e2 and at most one of these events is active at any time.
Whenever the clock for transition e2 is “reset,” event e2,i is cancelled and
event e2,3−i becomes active, where i = 1 or 2. The state of the gsmp consists
of the marking s of the spn along with a component u that keeps track of
whether e2,1 or e2,2 is currently active. Some details of the construction are
as follows.
For s = (s, u) ∈S,
e2,1 ∈E(s) if and only if e2 ∈E(s) and u = 1
and
e2,2 ∈E(s) if and only if e2 ∈E(s) and u = 2.
All speeds r(s, e) for active events are equal to 1.
If e∗= e1, then the state-transition probability p(s′; s, e∗) = 1 when
s = (1, 0, 0, 0, 0)
and
s′ = (1, 1, 0, 0, 1),
when
s = (1, 1, 0, 0, 1)
and
s′ = (1, 1, 0, 0, 2),
and when
s = (1, 1, 0, 0, 2)
and
s′ = (1, 1, 0, 0, 1).
If e∗= e2,1, then p(s′; s, e∗) = 1 when
s = (1, 1, 0, 0, 1)
and
s′ = (1, 0, 0, 0, 0).

4.4 Converse Results
139
If e∗= e2,2, then p(s′; s, e∗) = 1 when
s = (1, 1, 0, 0, 2)
and
s′ = (1, 0, 0, 0, 0).
All other state-transition probabilities p(s′; s, e) are equal to 0. The clock-
setting distribution functions are given by F(x; s′, e1, s, e∗) = P { U ≤x }
and F(x; s′, e2,1, s, e∗)
=
F(x; s′, e2,2, s, e∗)
=
1[T,∞)(x). This gsmp
strongly mimics the marking process of the spn.
Example 4.4 (spn with dependent clock readings). Consider the spn of
Example 4.1. Using the building blocks of the spn, construct a gsmp with
event set E = { e1, e3, e5 } and state space S consisting of all elements
(s1, s2, . . . , s6, v) ∈S × { 0, 2, 4 } such that v = 0 whenever min(s3, s6) = 0.
The idea is that whenever the spn changes marking from (1, 0, 0, 1, 0, 0)
to (0, 1, 0, 0, 0, 0) to (0, 0, 1, 0, 0, 1)—so that the clocks for transitions e3
and e5 are set according to F( · ; e3, e2) and F( · ; e5, e2)—the gsmp makes
a transition from state (1, 0, 0, 1, 0, 0, 0) to state (0, 0, 1, 0, 0, 1, 2). Simi-
larly, whenever the spn changes marking from (1, 0, 0, 1, 0, 0) to (0, 0, 0,
0, 1, 0) to (0, 0, 1, 0, 0, 1)—so that the clocks for transitions e3 and e5 are
set according to F( · ; e3, e4) and F( · ; e5, e4)—the gsmp makes a transi-
tion from state (1, 0, 0, 1, 0, 0, 0) to state (0, 0, 1, 0, 0, 1, 4). Thus the last
component of the gsmp state is used to keep track of the distribution
function used to set the clocks for transitions e3 and e5. Formally, we set
p(s′; s, e1) = 1/2 when s = (1, 0, 0, 1, 0, 0, 0) and s′ = (0, 0, 1, 0, 0, 1, 2), and
when s = (1, 0, 0, 1, 0, 0, 0) and s′ = (0, 0, 1, 0, 0, 1, 4). Moreover, for s, s′ =
(s′
1, . . . , s′
6, v′) ∈S and i = 3, 5, we set F( · ; s′, ei, s, e1) = F( · ; ei, ev′). The
remaining building blocks are deﬁned in an obvious way. For example, the
speeds are given by r(s, e) = r(λs, ψe), where λ(s1, . . . , s6, v) = (s1, . . . , s6)
for s = (s1, . . . , s6) ∈S and ψei = ei for i = 1, 3, 5. This gsmp strongly
mimics the marking process of the spn.
Theorem 4.5 is analogous to Theorem 2.10 and gives suﬃcient conditions
under which a gsmp strongly mimics the marking process of an spn.
Theorem 4.5. Suppose that there exists a mapping φ from Σ onto Σ+ of
the form φ(s, c) =

λs, η(s, c)

such that
(i) t∗
φ(s, c)

= t∗(s, c) for all (s, c) ∈Σ,
(ii) µ+(A) = µ(φ−1A) for all A ⊆Σ+, and
(iii) P +
φ(s, c), A

= P

(s, c), φ−1A

for all (s, c) ∈Σ and A ⊆Σ+.
Then { X(t): t ≥0 } strongly mimics { X(t): t ≥0 }.
Theorem 4.6. For any spn with timed and immediate transitions, there
exists a gsmp that strongly mimics the marking process of the spn.

140
4. Modelling Power
Proof. Consider a ﬁxed but arbitrary spn, and assume without loss of
generality that the set of timed transitions is E −E′ = { e1, e2, . . . , em }
and the set of immediate transitions is E′ = { em+1, em+2, . . . , eM }. We
construct a canonical gsmp as follows. Whenever the spn changes marking
to (timed) marking s, the gsmp makes a state transition to state s =
(s, w, u). The component
w =

¯s(1), s(1), v(1), ¯s(2), s(2), v(2), . . . , ¯s(m), s(m), v(m)

records how each clock was set since the last timed marking. The quantities
s(i) and ¯s(i) are the old and new markings when the clock for timed tran-
sition ei was set. The vector v(i) =

v1(i), v2(i), . . . , vM(i)

encodes the set
E∗(i) of transitions that ﬁred simultaneously and triggered the marking
change from s(i) to ¯s(i): vj(i) = 1 if ej ∈E∗(i) and vj(i) = 0 if ej ̸∈E∗(i).
If the clock for transition ei was not set since the last timed marking, then

¯s(i), s(i), v(i)

= (0L, 0L, 0M), where 0n denotes a 0-vector of length n.
As suggested by Example 4.3, the gsmp must have—in general—two events
ei,1 and ei,2 that correspond to timed transition ei (1 ≤i ≤m); at most one
of these events is active at any time. The component u = (u1, u2, . . . , um)
keeps track of which events are active: ui equals 2 if event ei,2 is active,
equals 1 if event ei,1 is active, and equals 0 if neither ei,1 nor ei,2 is active.
Thus, for s = (s, w, u) ∈S and 1 ≤i ≤m,
ei,1 ∈E(s) if and only if ei ∈E(s) and ui = 1
and
ei,2 ∈E(s) if and only if ei ∈E(s) and ui = 2.
For deﬁniteness, we always enable ei,1 in preference to ei,2; e.g., if E(s) ∩

ei,1, ei,2

= ∅and the gsmp makes a transition to a state s′ = (s′, w′, u′)
such that ei ∈E(s′), then ei,1 ∈E(s′). The speeds of the gsmp are deﬁned
by setting r

s, ei,j

= r(s, ei) for s = (s, w, u) ∈S and ei,j ∈E(s).
For s = (s, w, u) ∈S, E∗= { ei1,j1, ei2,j2, . . . , eil,jl } ⊆E(s), and s′ =
(s′, w′, u′) ∈S with w′ =

¯s′(1), s′(1), v′(1), . . . , ¯s′(m), s′(m), v′(m)

, the
state-transition probability p(s′; s, E∗) is of the form
p(s′; s, E∗) =

s(0),...,s(k)
p

s(1); s(0), E∗
p

s(2); s(1), E(s(1)) ∩E′
· · · p

s(k); s(k−1), E(s(k−1)) ∩E′
,
where E∗= { ei1, ei2, . . . , eil }. Here the sum is over all sequences s =
s(0), s(1), . . . , s(k−1), s(k) = s′ with s(j) ∈S′ for 0 < j < k that are con-
sistent with the values of u, u′, w, and w′. For example, if u3 = 1 and
u′
3 = 2—indicating that the clock for e3 was reset at least once—then, to be
consistent, a sequence must contain at least one s(j) for which e3 ̸∈E(s(j)).

4.4 Converse Results
141
At a state transition for which p(s′; s, E∗) > 0, the clock-setting distribu-
tion function for a new event ei,j is given by
F( · ; s′, ei,j, s, E∗) = F

· ; ¯s′(i), ei, s′(i), E∗(i)

,
where E∗(i) =

ej : v′
j(i) = 1

.
Deﬁne the initial distribution µ of the gsmp as follows. For each s ∈
S select w(s) and u(s) such that

s, w(s), u(s)

∈S and write θ1(s) =

s, w(s), u(s)

; thus, θ1 is a one-to-one mapping from S to a proper subset
of S. For s ∈S and c = (c1, c2, . . . , cm, 0, 0, . . . , 0) ∈C(s), set θ2(s, c) =
(c1,1, c1,2, . . . , cm,1, cm,2), where
(ci,1, ci,2) =





(0, 0)
if ui(s) = 0;
(ci, 0)
if ui(s) = 1;
(0, ci)
if ui(s) = 2
for 1 ≤i ≤m. Finally, set
µ(A) = µ+(θ−1A)
for A ⊆Σ, where
θ(s, c) =

θ1(s), θ2(s, c)

for (s, c) ∈
s∈S

{ s } × C(s)

.
For s = (s, w, u) ∈S and c = (c1,1, c1,2, . . . , cm,1, cm,2) ∈C(s), set λs = s
and η(s, c) = (c1, c2, . . . , cM), where
ci =





0
if ui = 0;
ci,1
if ui = 1;
ci,2
if ui = 2r
for 1 ≤i ≤m and ci = 0 for m < i ≤M. Deﬁne the mapping φ: Σ →
Σ by φ(s, c) =

λs, η(s, c)

for (s, c) ∈Σ. Straightforward calculations
show that the mapping φ satisﬁes the conditions of Theorem 4.5, so that
{ X(t): t ≥0 } strongly mimics { X(t): t ≥0 }.
Remark 4.7. Observe that if the spn has a ﬁnite marking set, the gsmp
constructed in the proof of Theorem 4.6 has a ﬁnite state space. Moreover,
if (with probability 1) no timed transitions of the spn ﬁre simultaneously,
then (with probability 1) no events of the gsmp occur simultaneously. Also
observe that if all enabled timed transitions remain enabled when there is
a marking change and the new marking is immediate, it suﬃces for the
events of the gsmp to be in one-to-one correspondence with the transitions
of the spn and for the state of the gsmp to be of the form s = (s, w).
Remark 4.8. It follows directly from Theorems 3.4 and 4.6 that spns and
gsmps have the same modelling power.

142
4. Modelling Power
We conclude this chapter by showing that an “irreducible” spn with ﬁnite
state space can always be mimicked by an “irreducible” gsmp. Recall from
Section 3.3.1 that, for s ∈S′ and s′ ∈G, we write s →s′ if p

s′; s, E(s) ∩
E′
> 0. Extend this notation to the case where s ∈S and s′ ∈G by
writing s →s′ if p(s′; s, e)r(s, e) > 0 for some e ∈E(s). Next, write s ; s′
if either s →s′ or there exist markings s(1), s(2), . . . , s(n) ∈G (n ≥1) such
that s →s(1) →· · · →s(n) →s′. Clearly, the relation ; is transitive.
Deﬁnition 4.9. An spn with marking set G is said to be irreducible if
s ; s′ for each s, s′ ∈G.
We can deﬁne the relation ; for a gsmp in a completely analogous manner
and say that a gsmp is irreducible if s ; s′ for all s, s′ ∈S.
In general, the canonical gsmp constructed in the proof of Theorem 4.6
need not be irreducible even if the marking process of the spn is irreducible.
The construction can be modiﬁed, however, to obtain an irreducible gsmp
that strongly mimics the marking process of the spn when the marking set
is ﬁnite.
Corollary 4.10. For any irreducible spn with a ﬁnite marking set, there
exists an irreducible gsmp with a ﬁnite state space that strongly mimics the
marking process of the spn.
The idea of the proof is as follows. Consider the gsmp constructed in The-
orem 4.6 with (ﬁnite) state space S and event set E. For the gsmp, write
s ↭s′ if s ; s′ and s′ ; s. Observe that the relation ↭is an equivalence
relation on S and, since S is ﬁnite, induces a ﬁnite number of equivalence
classes on S. At least one of these equivalence classes, say S0 ⊆S, must
be closed; that is, s′ ∈S0 whenever s ∈S0 and s ; s′. (Otherwise, there
exist two states s and s′ that belong to diﬀerent equivalence classes but
s ↭s′, a contradiction.) It follows from the irreducibility of the spn that
for each s ∈S there exists at least one pair (w, u) such that (s, w, u) ∈S0.
Now consider the gsmp with state space S0 and event set E0 = E such
that E0(s), p0(s′; s, E∗), r0(s, e), and F 0( · ; s′, e′, s, E∗) coincide with the
quantities E(s), p(s′; s, E∗), r(s, e), and F( · ; s′, e′, s, E∗) deﬁned in Theo-
rem 4.6 for s, s′ ∈S0. Deﬁne the initial distribution µ0 analogously to µ
in Theorem 4.6, but deﬁne the mapping θ so that µ0 is concentrated on
Σ0 = 
s∈S0

{ s } × C(s)

. This gsmp is irreducible and the mapping φ (as
in Theorem 4.6) satisﬁes the conditions of Theorem 4.5.
Remark 4.11. The foregoing results can be used to establish the assertion
given in Section 2.4 that for any spn having unit speeds, a ﬁnite marking
set, a ﬁxed initial marking, and timed transitions that with probability 1
never ﬁre simultaneously, there exists a “deterministic spn” that behaves
the same way. The idea is that, as shown in this section, the marking process
of the former spn can be strongly mimicked by a gsmp having a ﬁnite state
space, unit speeds, a ﬁxed initial state, and events that with probability 1

4. Notes
143
never occur simultaneously. This gsmp can in turn be strongly mimicked
by a deterministic spn; see Remark 3.2.
Notes
Our discussion of modelling power follows Haas and Shedler (1988, 1989a,
1991); these references give further details of the canonical spn and gsmp
constructions. In the literature for ordinary (untimed, deterministic) Petri
nets, modelling power is deﬁned in terms of the possible sequences of mark-
ings of the net; there is no notion either of the probability that a given
sequence is realized or of marking changes occurring at continuous time
points. For example, a Petri net is said to mimic a Turing machine—see
Motwani and Raghavan (1995, p. 16)—if, for any initial state of the ma-
chine, the net generates the same sequence of states as the machine under
an appropriate mapping between the state spaces. It is well known that
inhibitor input places are needed for Petri nets to have the same modelling
power as Turing machines in the sense that for any Turing machine there
exists a Petri net that mimics the machine; see Peterson (1981, Sec. 7.3).
This result is in contrast to the theorems in Section 4.3, which show that
permitting inhibitor input places does not increase the modelling power of
the spn formalism.
The gsmp model originated in the work of Matthes (1962) and K¨onig et
al. (1967, 1974). Our formulation follows the treatment in Whitt (1980),
modiﬁed as in Shedler (1993, Ch. 6) to permit simultaneous occurrence of
events. Interesting discussions of the role of gsmps in the study of discrete-
event systems can be found in Glynn (1989b), Glasserman (1991), and
Glasserman and Yao (1994). There is also a large literature dealing with
conditions under which the steady-state distribution of a gsmp depends
on the clock-setting distribution functions only through their means; see,
for example, Miyazawa (1993), Coyle and Taylor (1995), and references
therein.

This page intentionally left blank 

5
Recurrence
The marking process of an spn must be stable for time-average limits to
be well deﬁned and for simulation-based estimation techniques to be appli-
cable. Although nontrivial, establishing stability properties for a speciﬁed
spn is therefore a key step in a methodologically sound simulation study.
Stability of the marking process typically follows from stability of the
underlying general state-space Markov chain used to deﬁne the marking
process. Perhaps the most basic notion of stability for such a chain is
“Harris recurrence.” A Harris recurrent chain has the property that any
“dense enough” set of states is hit inﬁnitely often with probability 1. Thus
a Harris recurrent chain is stable in that it does not systematically drift oﬀ
toward the outer reaches of the state space—ﬁx a dense set of states that
is compact, and observe that the chain repeatedly returns to this set. We
require that each target set be dense because an individual state typically
is hit with probability 0 when the state space of the chain is uncountably
inﬁnite.
As discussed in Section 5.1, one means for establishing Harris recurrence
is to show that
1. The chain is “φ-irreducible” in that any (dense enough) set of states
can be reached with positive probability from any initial state.
2. The chain “drifts” toward a speciﬁed “petite” subset of the state
space whenever the chain lies outside of this subset.
We consider irreducible ﬁnite-state spns with positive speeds and give “pos-
itive density” and moment conditions on the clock-setting distributions
under which a drift condition holds.
In the context of regenerative simulation—see Chapter 6—it usually suf-
ﬁces to show that the chain hits a speciﬁed set of states inﬁnitely often with

146
5. Recurrence
probability 1. The successive times at which the chain hits the set typically
correspond to “regeneration points” at which the chain probabilistically
restarts. The foregoing drift approach can be specialized to establish the
desired recurrence property for the speciﬁed set. Alternatively, the geo-
metric trials technique described in Section 5.2 can be used to establish
recurrence. This technique, which is based on Lemma 3.4 in Chapter 3,
exploits the detailed structure of the spn model and avoids the somewhat
restrictive positive density assumptions used in the drift approach.
5.1
Drift Criteria
In this section, we formally deﬁne φ-irreducibility and Harris recurrence
and present a drift criterion for recurrence (Theorem 1.13). We then give
conditions (Theorem 1.22) on the building blocks of an spn under which
the drift criterion is satisﬁed.
5.1.1
Harris Recurrence and Drift
Just as irreducibility and (positive) recurrence play a key role in the the-
ory of Markov chains with a ﬁnite or countably inﬁnite state space, φ-
irreducibility and (positive) Harris recurrence, deﬁned below, are central to
the study of general state-space chains. Consider such a chain { Zn : n ≥0 }
with state space Γ, along with a nontrivial measure φ—see Section A.1.2—
on subsets of Γ.
Deﬁnition 1.1. The chain { Zn : n ≥0 } is φ-irreducible if for each z ∈Γ
and A ⊆Γ with φ(A) > 0, there exists n > 0 (possibly depending on both
z and A) such that P n(z, A) > 0.
Thus a chain is φ-irreducible if any “dense enough” set of states (as mea-
sured by φ) can be reached from any initial state after a ﬁnite num-
ber of steps with positive probability. Not surprisingly, φ-irreducibility
can also be characterized in terms of “hitting times” to suﬃciently dense
sets. Speciﬁcally, denote by τA the hitting time of a set A ⊆Γ: τA =
inf { n ≥1: Zn ∈A }. Then { Zn : n ≥0 } is φ-irreducible if and only if
Pz { τA < ∞} > 0 for all z ∈Γ and A ⊆Γ with φ(A) > 0.
Example 1.2 (Random walk on the real line).
Deﬁne a discrete-time
process { Zn : n ≥0 } by setting Z0 = 0 and Zn = Zn−1 + Xn, where
{ Xn : n ≥1 } is a sequence of i.i.d. real-valued random variables. Then
{ Zn : n ≥0 } is a Markov chain with transition kernel P(z, A) = P{ X1 ∈
A −z }, where A −z = { x −z : x ∈A } is the set A translated by z.
Suppose that X1 has a density function f that is positive on the real line.
Fix a set A ⊆ℜsuch that µLeb(A) > 0, where µLeb denotes Lebesgue
measure—see Section A.1.2 for a discussion of µLeb. Observe that µLeb(A−

5.1 Drift Criteria
147
z) = µLeb(A) > 0 for z ∈Γ because Lebesgue measure is invariant under
translation. It follows that P(z, A) =

A−z f(x) dx > 0 because the integral
of a positive function over a set of positive Lebesgue measure is always
positive—see Lemma 1.23 in the Appendix. Thus P n(z, A) > 0 for A ⊆Γ,
z ∈Γ, and n = 1, and the chain is φ-irreducible with φ = µLeb.
In applications the measure φ often is a modiﬁcation of (possibly multi-
dimensional) Lebesgue measure.
Deﬁnition 1.3. The chain { Zn : n ≥0 } is Harris recurrent with recur-
rence measure φ if it is φ-irreducible and Pz { Zn ∈A i.o. } = 1 for all z ∈Γ
and A ⊆Γ with φ(A) > 0.
Harris recurrence can be viewed as a strengthening of φ-irreducibility: from
any initial state, every dense enough set of states not only can be reached
with positive probability, but also is hit inﬁnitely often with probability 1.
A Harris recurrent chain admits an invariant measure, that is, a measure
π0 on subsets of Γ that satisﬁes

P(z, A) π0(dz) = π0(A)
(1.4)
for A ⊆Γ. The measure π0 is unique to within a multiplicative constant. If
π0(Γ) < ∞, then π( · ) = π0( · )/π0(Γ) is an invariant probability measure,
and (1.4) can be rewritten as Pπ { Z1 ∈A } = π(A) for A ⊆Γ. That is, if
the initial state of the chain Z0 is distributed according to π, then Z1 is also
distributed according to π. (It then follows from the Markov property that
Zk is distributed according to π for k ≥0 and that the chain is “stationary”
as deﬁned in Section A.2.2.)
Deﬁnition 1.5. The chain { Zn : n ≥0 } is positive Harris recurrent with
recurrence measure φ if it is Harris recurrent with recurrence measure φ
and admits an invariant probability measure.
Given a positive Harris recurrent chain with invariant probability mea-
sure π and a real-valued function f deﬁned on Γ, we often write
π(f) =

f(z) π(dz) = Eπ [f(Z0)]
for the expected value of a function f with respect to π, and write
π(|f|) =

|f(z)| π(dz).
The quantity π(f) is well deﬁned and ﬁnite whenever π(|f|) < ∞.
As with chains on a ﬁnite or countably inﬁnite state space, chains on
a general state space can exhibit “periodic” or “aperiodic” behavior. To
makes these concepts precise, we ﬁrst deﬁne the notion of a “d-cycle.”

148
5. Recurrence
Figure 5.1. Coupling of two Markov chains (coupling epoch N = 6).
Deﬁnition 1.6. A d-cycle of a φ-irreducible chain { Zn : n ≥0 } is a ﬁ-
nite collection { Γ1, Γ2, . . . , Γd } of disjoint subsets of Γ such that φ

Γ −
d
i=1 Γi

= 0 and P(x, Γi+1) = 1 for x ∈Γi and 1 ≤i ≤d. (Take Γi+1 = Γ1
when i = d.)
Thus if the initial state of the chain is an element of, say, Γ1, then with
probability 1 the chain will next hit the set Γ2, and so forth, according to
the pattern Γ1 →Γ2 →· · · →Γd →Γ1 →· · · ad inﬁnitum. The set of
states that do not belong to any Γi is “negligible” in that the φ-measure
of this set is 0. It can be shown that at least one d-cycle always exists for
a φ-irreducible chain.
Deﬁnition 1.7. The period of a φ-irreducible chain { Zn : n ≥0 } is the
largest d for which a d-cycle exists; the chain is called aperiodic if d = 1
and periodic if d > 1.
Closely tied to the aperiodicity property is the notion of a “Harris er-
godic” chain.
Deﬁnition 1.8. The chain { Zn : n ≥0 } is Harris ergodic if it is positive
Harris recurrent and aperiodic.
Our primary interest in Harris ergodic chains stems from the fact that
they are amenable to “coupling” arguments.
Deﬁnition 1.9. The chain { Zn : n ≥0 } admits coupling if for any two
initial distributions µ and λ there exist on a common probability space
versions { Zn(µ): n ≥0 } and { Zn(λ): n ≥0 } of the chain—having re-
spective initial distributions µ and λ—along with an a.s. ﬁnite random
index N such that Zn(µ) = Zn(λ) for n ≥N.
Thus, with probability 1 the two sample paths merge into a single path
after a ﬁnite number of state transitions; see Figure 5.1.

5.1 Drift Criteria
149
Proposition 1.10. A chain { Zn : n ≥0 } having a stationary distribution
admits coupling if and only if it is Harris ergodic.
By choosing the initial distribution λ in Deﬁnition 1.9 to be the invariant
distribution π, Proposition 1.10 often can be used to extend results for
a stationary Harris ergodic chain to a nonstationary version of the chain
having some arbitrary initial distribution µ ̸= π. In Chapter 7 we use
this approach to establish the validity of certain “consistent estimation”
methods for spns.
Proposition 1.13 below gives conditions under which a chain { Zn : n ≥
0 } is positive Harris recurrent. A key hypothesis of Proposition 1.13 is
that the chain drift toward a speciﬁed “petite” subset of the state space
whenever the chain lies outside this subset.
Deﬁnition 1.11. A subset B ⊆Γ is petite with respect to the chain { Zn :
n ≥0 } if there exist a probability distribution q on the nonnegative integers
and a nontrivial measure ψ such that
inf
z∈B
∞

n=0
q(n)P n(z, A) ≥ψ(A)
for all A ⊆Γ.
Equivalently, the subset B is petite if there exists a nonnegative integer-
valued random variable N, independent of { Zn : n ≥0 }, such that
inf
z∈B Pz { ZN ∈A } ≥ψ(A)
for all A ⊆Γ. A trivial example of a petite set is given by B = { ¯z },
where ¯z ∈Γ; for this set, the above inequality holds with N ≡1 and
ψ( · ) = P(¯z, · ). It can be shown that there exists at least one petite set of
positive φ-measure for a φ-irreducible chain. In applications, compact (i.e.,
closed and bounded) sets often serve as petite sets. The following result
gives a useful characterization of petiteness.
Proposition 1.12. Suppose that the chain { Zn : n ≥0 } is φ-irreducible.
A set B ⊆Γ is petite with respect to { Zn : n ≥0 } if for each set A ⊆Γ
with φ(A) > 0 there exists a ﬁnite positive integer n = n(A) such that
inf
z∈B Pz { τA ≤n } > 0.
For real-valued functions f and g, both deﬁned on Γ, write f = O(g) if
supx∈Γ |f(x)|/|g(x)| < ∞. (Here we take 0/0 = 0.)
Proposition 1.13. Suppose that the chain { Zn : n ≥0 } is φ-irreducible.
Also suppose that there exist a petite set B, an integer m ≥1, a function
v: Γ →[1, ∞), and a real number β ∈(0, 1) such that
Ez [v(Zm) −v(Z0)] ≤−βv(z)
(1.14)

150
5. Recurrence
for all z ∈Γ −B, and
sup
z∈B
Ez [v(Zm) −v(Z0)] < ∞.
(1.15)
Then { Zn : n ≥0 } is positive Harris recurrent with recurrence measure φ
and hence admits an invariant probability measure π. Moreover, π(|f|) < ∞
for any function f such that f = O(v).
For z ̸∈B, the quantity v(z) can be viewed as the “distance” between state
z and the set B. The quantity Ez [v(Zm) −v(Z0)] in (1.14) and (1.15) is
called the m-step expected drift of the chain. Thus the condition in (1.14)
asserts that the m-step expected drift is strictly negative whenever the
chain lies outside B; the exact “rate of drift” is speciﬁed by the function
βv. The condition in (1.14) is usually called a “geometric” drift criterion:
whenever the chain lies outside B, the distance function v is required to de-
crease in expectation not merely by some positive amount but by a factor1
of β.
5.1.2
The Positive Density Condition
In this section we give conditions—encapsulated in the “positive density
assumption” PD given below—under which the embedded chain of the
marking process of an spn is φ-irreducible and satisﬁes the drift criteria for
stability in (1.14) and (1.15). As usual, we assume that the initial distri-
bution of the underlying chain is of the form given by (1.10) in Chapter 3.
Denote by G+ the set of distribution functions on [0, ∞) that have a
convergent LaPlace–Stieltjes transform in a neighborhood of the origin.
That is, F ∈G+ if and only if there exists aF > 0 such that
 ∞
0
eux dF(x) <
∞for u ∈[0, aF ]. Observe that each distribution function F ∈G+ has ﬁnite
moments of all orders. Many common distribution functions belong to G+,
for example, the uniform, exponential, gamma, beta, and truncated normal
distributions.
A nonnegative function G is a component of a distribution function F
if G is not identically equal to 0 and G ≤F. If G is a component of F
and G is absolutely continuous—see Section A.1.3—so that G has a density
function g, then we say that g is a density component of F. For example,
let X be a random variable such that X = 2 with probability 0.5 and
X takes on a value randomly and uniformly distributed between 0 and 1
with probability 0.5. The distribution function F of X can be written as
1A more general form of drift criterion is obtained by replacing βv by some arbitrary
function g : Γ →[1, ∞). When g(z) ≡c for some c > 0, the drift criterion reduces to a
general state-space version of Foster’s criterion (Proposition 2.18 in the Appendix) for
positive recurrence in chains with a countable state space.

5.1 Drift Criteria
151
F = 0.5F1 + 0.5F2, where F1(x) = 1[2,∞)(x) for x ≥0 and
F2(x) =





0
if x < 0;
x
if 0 ≤x ≤1;
1
if x > 1.
The function G(x) = 0.5F2(x) is a component of F and g(x) = 0.5·1[0,1](x)
is a density component. Observe that in this example F has a density
component even though F is not absolutely continuous. In general, if F
is the distribution function of a random variable X and F has a density
component g, then P { a ≤X ≤b } ≥
 b
a g(x) dx for −∞< a ≤b < ∞.
If F is absolutely continuous with density function f, then f is trivially a
density component of F.
Deﬁnition 1.16. Assumption PD is said to hold for a speciﬁed spn if
(i) the marking set G is ﬁnite,
(ii) the spn is irreducible as in Deﬁnition 4.9 of Chapter 4,
(iii) all speeds are positive, and
(iv) there exists 0 < ¯x < ∞such that each clock-setting distribution
function F( · ; s′, e′, s, e∗) and F0( · ; e′, s) with e′ ∈E −E′ belongs to
G+ and has a density component that is positive and continuous on
(0, ¯x).
If Assumption PD holds and each clock-setting distribution F( · ; s′, e′, s, e∗)
and F0( · ; e′, s) is absolutely continuous with corresponding density func-
tion f( · ; s′, e′, s, e∗) and f0( · ; e′, s), then we always take the “density com-
ponents” to be f and f0 by convention.
As usual, denote by Σ and Σ+ the state spaces of the underlying chain
{ (Sn, Cn): n ≥0 } and embedded chain { (S+
n , C+
n ): n ≥0 }, respectively.
Whenever Assumption PD holds, we deﬁne ¯φ be the unique measure on
subsets of Σ+ such that
¯φ

{ s } × [0, x1] × [0, x2] × · · · × [0, xM]

=

{i: ei∈E(s)}
min(xi, ¯x)
(1.17)
for all s ∈S and x1, x2, . . . , xM ≥0. If, for example, a set B ⊆Σ+ is of
the form B = { s } × A with E(s) = E, then ¯φ(B) is equal to the Lebesgue
measure of the set A ∩[0, ¯x]M.
Remark 1.18. Observe that if Assumption PD holds, then there exists a
real number q > 0 such that
 ∞
0
eqx dF(x; s′, e′, s, e∗) < ∞
(1.19)

152
5. Recurrence
and
 ∞
0
eqx dF0(x; e′, s) < ∞
(1.20)
for all s′, s, e′, and e∗.
Now consider an spn with marking set G, timed marking set S, transition
set E, and underlying and embedded chains with respective state spaces Σ
and Σ+. For b > 0, denote by Hb the set of all states (s, c) ∈Σ+ such that
each clock reading is bounded above by b:
Hb =

(s, c) ∈Σ+ :
max
1≤i≤M ci ≤b

.
(1.21)
Finally, set
hq(s, c) = exp

q max
1≤i≤M ci

for q ≥0, s ∈S, and c = (c1, c2, . . . , cM) ∈C(s).
Theorem 1.22. If Assumption PD holds, then
(i) the embedded chain { (S+
n , C+
n ): n ≥0 } is ¯φ-irreducible, where ¯φ is
deﬁned by (1.17), and
(ii) for each b > 0 the set Hb deﬁned by (1.21) is petite with respect to
{ (S+
n , C+
n ): n ≥0 }.
Moreover, for some m ≥1, all q satisfying (1.19) and (1.20), and all
suﬃciently large b,
(iii) sup(s,c)∈Hb E(s,c)

hq(S+
m, C+
m) −hq(S+
0 , C+
0 )

< ∞, and
(iv) there exists β ∈(0, 1) such that
E(s,c)

hq(S+
m, C+
m) −hq(S+
0 , C+
0 )

≤−βhq(s, c)
for (s, c) ∈Σ+ −Hb.
The proof of Theorem 1.22 is rather long and is given in the next subsection.
Remark 1.23.
The irreducibility Assumption PD requires is a structural
property of the net and does not by itself imply irreducibility for the un-
derlying chain, embedded chain, or marking process. Indeed, in the absence
of constraints on the clock-setting distributions there can exist markings
s, s′ ∈S such that s is hit with positive probability and s ; s′, but
Pµ { Sn = s and Sn+k = s′ for some n, k ≥0 } = 0.
(1.24)
Such a situation is illustrated in Example 1.25 below. Theorem 1.22 shows,
however, that such anomalous behavior is ruled out by the remaining con-
ditions in Deﬁnition 1.16.

5.1 Drift Criteria
153
Figure 5.2. An irreducible spn with a marking that is never hit.
Example 1.25 (Irreducible spn with a marking that is never hit).
Con-
sider an spn with three places and four timed transitions as in Figure 5.2.
The state space of the spn is G = S = { (1, 0, 0), (0, 1, 0), (0, 0, 1) }. Suppose
that each timed transition ei is deterministic and simple, with each succes-
sive new clock reading for ei uniformly distributed on a speciﬁed interval
[ai, bi]. Also suppose that Pµ { S0 = (1, 0, 0) } = 1. Observe that this spn is
irreducible; in particular, s →s′, where s = (1, 0, 0) and s′ = (0, 0, 1). If
b1 < a2, however, then with probability 1 transition e1 always ﬁres before
transition e2, so that (1.24) holds. Moreover, setting A = s′ × C(s′), we
see that Pµ { (Sn, Cn) ∈A i.o. } = 0 for any initial distribution µ—we em-
phasize that the probability of hitting A inﬁnitely often is 0 even though
¯φ(A) > 0 for any choice of ¯x > 0, where ¯φ is deﬁned by (1.17). Of course,
this spn does not satisfy Assumption PD since the clock-setting distribu-
tion function for transition e2 does not have a density component that is
positive on an interval of the form (0, ¯x).
The following result is an immediate consequence of Proposition 1.13
and Theorem 1.22.
Corollary 1.26. Suppose that Assumption PD holds for an spn. Then
the embedded chain of the marking process is positive Harris recurrent with
recurrence measure ¯φ given by (1.17) and hence admits a stationary distri-
bution π. Moreover, if q satisﬁes (1.19) and (1.20), then π(|f|) < ∞for
any function f such that f = O(hq).
Example 1.27 (Telephone system). Consider a telephone system with N
telephones connected to a switchboard by lines numbered 1, 2, . . . , N. The
switchboard has K links numbered 1, 2, . . . , K, each of which can connect
any two lines, subject to the restriction that only one connection at a time
can be made to each line; see Figure 5.3. If more than one link is available
and the called line is not in use, a placed call is connected (instantaneously)
on the lowest-numbered available link. The system is a lost-call system in
the sense that any call is immediately lost if no connection can be made
when it is placed. A call is lost if at least one link is available but the called

154
5. Recurrence
Figure 5.3. Telephone system.
Figure 5.4. Timeline diagram for telephone system (six lines, two links). A circled
number represents the link on which a call is connected, and a number displayed
above an ×, ∇, or 2 represents the destination of a call (or attempted call).

5.1 Drift Criteria
155
e1,i = call placed at line i
e2,m = end of call connected on link m
Figure 5.5. spn representation of telephone system.
line is in use (a busy call) and a call is lost if no link is available (a blocked
call). Figure 5.4 shows a timeline diagram for the telephone system with
N = 6 lines and K = 2 links. The initial call (placed at line 1 to line 3) is
connected on link 1 and the next call (placed at line 5 to line 3) is connected
on link 2. The third call (placed at line 2 to line 6) is a blocked call and
the fourth call (placed at line 6 to line 5) is a busy call.
Successive durations of calls placed at line i are i.i.d. as a positive ran-
dom variable Li, and the successive times from the end of a call placed or
received at line i to the next call placed at line i are i.i.d. as a positive
random variable Ai. After a lost call placed at line i, the time to the next
call placed at line i is also distributed as Ai. Whenever a call is placed at
line i, the called line is line j with (independent) probability pij. A line
cannot place a call to itself, and thus pii = 0 for 1 ≤i ≤N.
This system can be speciﬁed as a 2-bounded spn with unit speeds, N +K
timed transitions, and N deterministic immediate transitions. The spn con-

156
5. Recurrence
sists of N subnets corresponding to the N lines and K subnets correspond-
ing to the K links; Figure 5.5 displays subnets for a generic line i and a
generic link m. Place d1,i contains one token if and only if line i is idle;
otherwise, place d1,i contains no tokens. Place d2,i,m contains two tokens
if and only if a call placed or received at line i is connected on link m;
otherwise, place d2,i,m contains one token. Place d3,m contains one token if
and only if a call is connected on link m; otherwise, place d3,m contains no
tokens. Place d4,i contains one token if line i has just received a call and is
about to be connected; otherwise, place d4,i contains no tokens.
The spn behaves as follows. Denote by J(s) ⊆{ 1, 2, . . . , N } the set of
idle lines when the marking is s, by M(s) ⊆{ 1, 2, . . . , K } the set of idle
links, and by m(s) the smallest element in M(s). Suppose that the marking
is s ∈S and transition e1,i = “call placed at line i” ﬁres (1 ≤i ≤N).
If M(s) = ∅, so that the call is blocked, then no tokens are removed
or deposited and a new clock reading is generated for transition e1,i. If
M(s) ̸= ∅, then
1. With probability 1 −	
j∈J(s) pi,j the called line is busy: no tokens
are removed or deposited and a new clock reading is generated for
transition e1,i.
2. With probability pi,j (j ∈J(s)), the call placed at line i is successfully
connected to line j on link m, where m = m(s): transition e1,i removes
one token from place d1,i and deposits one token in each of places
d2,i,m, d2,j,m, d3,m, and d4,j.
Observe that when a token is deposited in place d4,j as in (2) above, im-
mediate transition e3,j ﬁres and removes the token in place d1,j, thereby
causing transition e1,j to become disabled. Now suppose that transition
e2,m = “end of call connected on link m” ﬁres (1 ≤m ≤K) and each
of places d2,i,m and d2,j,m contains two tokens for some i and j. Then one
token is removed from each of places d2,i,m, d2,j,m, and d3,m, and one token
is deposited in each of places d1,i and d1,j, so that link m, line i, and line j
each become idle.
Suppose that for some a > 0 the random variables L1, L2, . . . , LN each
are distributed according to a uniform distribution on [0, a] and A1, A2, . . . ,
AN are each distributed according to an exponential distribution function
with intensity q for some q > 0. Also suppose that we wish to show that
P { Sn = ˜s i.o. } = 1, where ˜s is the unique timed marking in which all links
are idle. Equivalently, we wish to show that P { (Sn, Cn) ∈A i.o. } = 1,
where A = { (s, c) ∈Σ+ : s = ˜s }. It is not hard to show that s ; ˜s and
˜s ; s′ for all s, s′ ∈G, so that the spn is irreducible. Thus Assumption PD
holds with ¯x = a and the embedded chain { (S+
n , C+
n ): n ≥0 } is Harris
recurrent with recurrence measure ¯φ. Because ¯φ(A) = aN > 0, the desired
result follows from Corollary 1.26.

5.1 Drift Criteria
157
The following example shows how Corollary 1.26 can be used in an in-
direct way to show that a speciﬁed subset of Σ −Σ+ is hit inﬁnitely often
with probability 1 by the underlying chain.
Example 1.28 (Flexible manufacturing system).
For the spn of Exam-
ple 2.9 in Chapter 2, recall that the ﬁring of transition e4 corresponds to
the unloading of ﬁnished parts and the loading of raw parts. Suppose we
wish to show that P { (Sn, Cn) ∈A i.o. } = 1, where
A = { (s, c) ∈Σ : E∗(s, c) = { e4 } } ⊂Σ −Σ+
and E∗is given by (1.8) in Chapter 3. Also suppose that there exists
0 < ¯x ≤∞such that each of the distribution functions for the processing-
time random variables L1,1, L1,2, L2, and L3 belongs to G+ and has a
density component that is positive and continuous on (0, ¯x). Then Assump-
tion PD holds because the spn is irreducible with ﬁnite marking set and
positive speeds. Set A+ = { (s, c): s = ¯s }, where ¯s = (0, 0, 1, 1, 1, 0, 0, 0, 0).
Whenever the marking is ¯s, there are two ﬁnished parts in the system
and machine 3 is processing a part. Observe that A+ ⊂Σ+ and ¯φ(A+) =
¯x > 0, so that P { (S+
n , C+
n ) ∈A+ i.o. } = 1 by Corollary 1.26 and hence
P { (Sn, Cn) ∈A+ i.o. } = 1. The desired result now follows because (Sn+1,
Cn+1) ∈A whenever (Sn, Cn) ∈A+.
5.1.3
Proof of Theorem 1.22
For ease of exposition, we assume throughout that all speeds are equal to
1 and that all transitions are simple as in Deﬁnition 1.8 of Chapter 3. We
assume initially that all transitions are timed, so that the embedded chain
coincides with the underlying chain; we then show how to extend the proof
to handle immediate transitions.
Irreducibility and Petite Sets
Suppose that Assumption PD holds and that all transitions are timed. Thus
there exists 0 < ¯x ≤∞such that each clock-setting distribution function
has a density component that is positive and continuous on (0, ¯x). We
establish both the ¯φ-irreducibility of { (Sn, Cn): n ≥0 } and the petiteness
of Hb for b ≥0 through a sequence of lemmas.
Lemma 1.29. Let A ⊆Σ satisfy ¯φ(A) > 0. Then for each ¯s ∈S there
exist a set ¯B = ¯B(¯s, A) ⊆C(¯s) ∩[0, ¯x]M, an integer n = n(¯s, A) ≤|S|, and
a real number δ = δ(¯s, A) > 0 such that
(i) ¯φ

{ ¯s } × ¯B

> 0, and
(ii) P n
(s, c), A

≥δ for all (s, c) ∈{ ¯s } × ¯B.

158
5. Recurrence
Proof. For s, s′ ∈S with s ̸= s, let d(s, s′) be the smallest integer k such
that s →s1 →· · · →sk = s′ for some s1, s2, . . . , sk ∈S. Because the spn
is irreducible, the “distance measure” d is well deﬁned with d ≤|S|. For
n ≥1, denote by µLeb
n
Lebesgue measure on ℜn.
It suﬃces to prove the lemma for a set A of the form { ¯s′ } × ¯A, where
¯A ⊆[0, ¯x]M ∩C(¯s′). For this choice of A, we show that the conclusion of the
lemma holds with n(¯s, A) = d(¯s, ¯s′). Suppose at ﬁrst that d(¯s, ¯s′) = 1, so
that p(¯s′; ¯s, ¯e) > 0 for some ¯e ∈E(¯s). We construct the desired set ¯B when
O(¯s′; ¯s, ¯e) ̸= ∅and E(¯s′) = E; the construction for each other possible
scenario is similar. Under our assumptions, ¯φ(A) = µLeb
M ( ¯A) > 0. Assume
without loss of generality that O(¯s′; ¯s, ¯e) = { e1, e2, . . . , ek } for some 1 ≤
k < M and that ¯e = eM. Thus E(¯s) = { e1, . . . , ek, eM } and N(¯s′; ¯s, ¯e) =
{ ek+1, ek+2, . . . , eM }. Set ¯Aϵ = ¯A∩[ϵ, ¯x−ϵ]M, where ϵ ∈(0, ¯x/2) is chosen
small enough so that µLeb
M ( ¯Aϵ) > 0. For v = (v1, v2, . . . , vk) ∈[ϵ, ¯x−ϵ]k, set
¯Aϵ(v) =

(a1, a2, . . . , aM−k) ∈[ϵ, ¯x −ϵ]M−k :
(v1, . . . , vk, a1, . . . , aM−k) ∈¯Aϵ

.
Because µLeb
M ( ¯Aϵ) > 0 and, by Fubini’s theorem (Proposition 1.25 in the
Appendix),
µLeb
M ( ¯Aϵ) =

[ϵ,¯x−ϵ]k µLeb
M−k
 ¯Aϵ(v)

µLeb
k
(dv),
there exist a set Q ⊆[ϵ, ¯x−ϵ]k and a real number γ > 0 such that µLeb
k
(Q) >
0 and µLeb
M−k
 ¯Aϵ(v)

> γ for v ∈Q—see Lemma 1.22 in the Appendix. We
now show that the desired set ¯B is given by
¯B =

c = (c1, c2, . . . , cM) ∈C(¯s):
0 < cM < ϵ and (c1 −cM, c2 −cM, . . . , ck −cM) ∈Q

.
We see by inspection that ¯B ⊆[0, ¯x]M. Moreover, it follows from Fubini’s
theorem and the invariance of Lebesgue measure under translation that
¯φ

{ ¯s } × ¯B

= ϵµLeb
k
(Q) > 0. For 1 ≤i ≤M −k let f( · ; ek+i) be
a density component of F( · ; ek+i) as in Assumption PD, and for y =
(y1, y2, . . . , yM−k) ∈ℜM−k set w(y) =  M−k
i=1
f(yi; ek+i). By the continu-
ity and positivity assumptions on the density components, it follows that
w∗def
=
inf
y∈[ϵ,¯x−ϵ]M−k w(y) > 0.

5.1 Drift Criteria
159
Observe that ci ≥cM + ϵ for 1 ≤i ≤k whenever c = (c1, c2, . . . , cM) ∈¯B,
so that E∗(¯s, c) = { eM } and
P

(¯s, c), { ¯s′ } × ¯A) ≥P

(¯s, c), { ¯s′ } × ¯Aϵ)
≥p(¯s′; ¯s, eM)

¯
Aϵ(˜c)
w(y)µLeb
M−k(dy)
≥δ,
where ˜c = (c1 −cM, c2 −cM, . . . , ck −cM) ∈Q and δ = p(¯s′; ¯s, eM)w∗γ > 0.
This establishes the lemma when d(¯s, ¯s′) = 1. The general result follows in a
straightforward manner by induction on d(¯s, ¯s′), using the above argument
together with the Chapman–Kolmogorov equations—see (1.5) in Chapter 3.
We now partition Σ into a ﬁnite collection Q of mutually disjoint subsets.
Elements (s, c) = (s, c1, c2, . . . , cM) and (s′, c′) = (s′, c′
1, c′
2, . . . , c′
M) belong
to the same subset Q ∈Q if and only if s = s′ and the clock readings are
in the same relative order, that is,
ci



<
=
>


cj
if and only if
c′
i



<
=
>


c′
j
for all 1 ≤i, j ≤M. For each Q ∈Q and ϵ > 0 set
Qϵ =

(s, c) ∈Q: c ∈[0, ϵ]M 
.
Lemma 1.30. Let A ⊆Σ satisfy ¯φ(A) > 0. Then for each Q ∈Q there
exist real numbers ϵ = ϵ(Q, A) > 0 and δ = δ(Q, A) > 0 together with an
integer n = n(Q, A) ≤|S| + M such that P n
(s, c), A

≥δ for (s, c) ∈Qϵ.
Proof. For ease of exposition, we prove the lemma under the assumption
that E(s) = E for all s ∈S; extending the proof to handle arbitrary sets
of active events is straightforward. We also ﬁx ¯s ∈S and give the proof
for the set Q = { (¯s, c1, c2, . . . , cM) ∈Σ: c1 < c2 < · · · < cM }, the proof for
each other set in Q being similar. Let s1, s2, . . . , sM ∈S be such that
p0
def
= p(s1; ¯s, e1)p(s2; s1, e2) · · · p(sM; sM−1, eM) > 0.
By Lemma 1.29 there exist a set ¯B = ¯B(sM, A) ⊆C(sM) ∩[0, ¯x]M, a
real number δ0 = δ0(sM, A) > 0, and an integer l = l(sM, A) ≤|S| such
that ¯φ

{ sM } × ¯B

= µLeb
M ( ¯B) > 0 and P l
(s, c), A

≥δ0 for all (s, c) ∈
{ sM } × ¯B. Set ¯Bϵ = ¯B ∩[ϵ, ¯x −ϵ]M, where ϵ ∈(0, ¯x/2) is chosen small
enough so that µLeb
M ( ¯Bϵ) > 0. Fix ¯c = (¯c1, ¯c2, . . . , ¯cM) ∈C(¯s) such that
0 < ¯c1 < ¯c2 < · · · < ¯cM < ϵ. It suﬃces to show that
P M+l
(¯s, ¯c), A

≥δ > 0,
(1.31)

160
5. Recurrence
where δ does not depend explicitly on ¯c. For y = (y1, y2, . . . , yM) ∈ℜM
+ , set
w(y) =  M
i=1 f(yi; ei), where f( · ; e) is a density component of F( · ; e) as in
Assumption PD. Also set v = v(¯c) = (¯cM −¯c1, ¯cM −¯c2, . . . , ¯cM −¯cM−1, 0)
and denote by ¯Bϵ + v the set ¯Bϵ translated by the vector v. Observe that
P M
(¯s, ¯c), { ¯s } × ¯Bϵ)

≥P(¯s,¯c)

S1 = s1, S2 = s2, . . . , SM = sM,
(C1,1, C2,2, . . . , CM,M) ∈¯Bϵ + v

≥p0

¯
Bϵ+v
w(y) µLeb
M (dy).
(1.32)
By construction, v ≤(ϵ, ϵ, . . . , ϵ), so that ¯Bϵ + v ⊆[ϵ, ¯x]M and hence
w(y) > 0 for all y ∈¯Bϵ+v. Since, in addition, µLeb
M ( ¯Bϵ+v) = µLeb
M ( ¯Bϵ) > 0,
it follows that the rightmost term in (1.32) is positive. This term can be
viewed as a (continuous) function of v. Denote by v∗the value of v that
minimizes this function over the compact set [0, ϵ]M. It follows from the
Chapman–Kolmogorov equations that (1.31) holds with
δ = δ0p0

¯
Bϵ+v∗w(y) µLeb
M (dy) > 0.
Lemma 1.33. The chain { (Sn, Cn): n ≥0 } is ¯φ-irreducible, where ¯φ is
deﬁned by (1.17). Moreover, the set Hb deﬁned by (1.21) is petite with
respect to { (Sn, Cn): n ≥0 } for each b > 0.
Proof. Fix a set A ⊆Σ with ¯φ(A) > 0. Using notation as in Lemma 1.30,
set n = n(A) = maxQ∈Q n(Q, A) ≤|S| + M, ϵ = minQ∈Q ϵ(Q, A) > 0, and
δ = minQ∈Q δ(Q, A) > 0. It follows from Lemma 1.30 that
P(s,c) { τA ≤n } ≥δ > 0
(1.34)
for all (s, c) ∈Σϵ, where Σϵ =

(s, c) ∈Σ: c ∈[0, ϵ)M 
. We now derive
an analogous result for the hitting time of the set Σϵ, starting from an
arbitrary state (¯s, ¯c) ∈Σ.
For k ≥0, set Wk = 1 if ϵ/2 < Cn,i < ϵ for ei ∈N(Sn; Sn−1, E∗
n−1) and
kM ≤n < (k+1)M; otherwise, set Wk = 0. Thus Wk is the indicator of the
event in which, at marking changes kM, kM +1, . . . , (k+1)M −1, each new
clock reading lies in the interval (ϵ/2, ϵ). Observe that2 ζ(k+1)M −ζkM > ϵ/2
whenever Wk = 1. Denote by ⌈x⌉the smallest integer greater than or equal
to x. Setting
k∗(¯c) =
.
2 max
1≤i≤M ¯ci/ϵ
/
2Recall from (1.11) in Chapter 3 that ζn is the time of the nth marking change.

5.1 Drift Criteria
161
and γ(¯c) =  M
i=1

F(ϵ; ei) −F(ϵ/2; ei)
Mk∗(¯c), we ﬁnd that
P Mk∗(¯c)
(¯s, ¯c), Σϵ

≥P(¯s,¯c)

W1 = · · · = Wk∗(¯c) = 1

≥γ(¯c) > 0. (1.35)
By (1.34) and (1.35),
P(¯s,¯c) { τA ≤Mk∗(¯c) + n(A) } ≥γ(¯c)δ.
(1.36)
The desired results follow immediately from (1.36) and Proposition 1.12.
Expected Drift
We now establish the assertions in (iii) and (iv) of Theorem 1.22 with m
equal to M (the total number of transitions). This result completes the
proof of the theorem under the assumption that there are no immediate
transitions. For ease of exposition, we suppose that E(s) = E for all s ∈S;
the argument is similar when E(s) ⊂E for one or more markings s ∈S.
(Indeed, the disabling of transitions can only accelerate the drift toward a
set Hb.) We frequently write E [X; B] = E [X1B], where 1B = 1 if event B
occurs and 1B = 0 otherwise. Denote by x ∨y the maximum of x and y.
To establish Theorem 1.22(iii), we actually prove the stronger result that
sup
(s,c)∈Σ
E(s,c) [hq(SM, CM) −hq(S0, C0)] < ∞.
It suﬃces to show that
sup
(s,c)∈Q
E(s,c) [hq(SM, CM) −hq(S0, C0)] < ∞
(1.37)
for Q ∈Q, where Q is a ﬁnite partition of Σ as in Lemma 1.30. We give the
argument for a subset Q ∈Q such that (s, c) = (s, c1, c2, . . . , cM) ∈Q only
if cM > ci for 1 ≤i < M; the argument for each other element of Q is sim-
ilar. For 1 ≤i ≤M and j ≥1, denote by Ai,j the jth successive new clock
reading generated for transition ei. Thus { Ai,j : 1 ≤i ≤M, j ≥1 } is a
collection of mutually independent random variables with Pµ { Ai,j ≤x } =
F(x; ei) for all i and j. Set
A′ =
min
1≤i,j≤M Ai,j
and
A′′ =
max
1≤i,j≤M Ai,j.
Denote by B the event in which CM,M > Ci,M for 1 ≤i < M and
eM ∈O(Sn+1; Sn, E∗
n) for 0 ≤n < M. Thus event B occurs if and only if
transition eM does not ﬁre during the ﬁrst M marking changes and, just af-
ter the Mth marking change, the clock reading for transition eM is greater

162
5. Recurrence
than the clock readings for the other transitions. Fix a state (s, c) ∈Q, and
observe that
E(s,c) [hq(SM, CM) −hq(S0, C0); B]
= E(s,c)[eq(cM−ζM) −eqcM ; B]
≤0.
Next, denote by Bc the complement of event B. Observe that if the initial
state is an element of Q and event Bc occurs, then the clock with the largest
reading just after the Mth marking change was set sometime during the
ﬁrst M marking changes. It follows that
E(s,c) [hq(SM, CM) −hq(S0, C0); Bc] ≤E(s,c) [hq(SM, CM); Bc]
≤E(s,c)

eqA′′; Bc
≤
M

i=1
M

j=1
E(s,c)

eqAi,j
= M
M

i=1
γq(i),
(1.38)
where γq(i) =
 ∞
0
eqx dF(x; ei) < ∞. Thus
E(s,c) [hq(SM, CM) −hq(S0, C0)]
= E(s,c) [hq(SM, CM) −hq(S0, C0); B]
+ E(s,c) [hq(SM, CM) −hq(S0, C0); Bc]
≤M
M

i=1
γq(i)
< ∞.
Because (s, c) is an arbitrary element of Q, (1.37) holds.
To establish Theorem 1.22(iv), ﬁx b > 0 and (s, c) ∈(Σ−Hb)∩Q, where
Q is as before. Thus cM > ci for 1 ≤i < M and cM > b. Suppose that event
B occurs, so that transition eM does not ﬁre during the ﬁrst M marking
changes. If follows that, during the ﬁrst M marking changes, the clock for
at least one transition in { e1, e2, . . . , eM−1 } is set and then runs down to 0.
Of these transitions, select the one with the smallest index. Denote by A∗
the length of the interval from the ﬁrst time during [0, ζM] that the clock
for this distinguished transition is set until the clock runs down to 0. Thus
A∗is a (randomly determined) element of the set { Ai,j : 1 ≤i, j ≤M } and
ζM ≥A∗. Using the mean-value theorem we ﬁnd that, for some random

5.1 Drift Criteria
163
variable W with 0 ≤W ≤A∗/cM,
E(s,c) [hq(SM, CM) −hq(S0, C0); B]
= E(s,c)

eq(cM−ζM) −eqcM ; B

≤E(s,c)

eqcM(1−A∗/cM) −eqcM ; B

= E(s,c)

−qA∗eqcM(1−W ); B

≤−qeqcM E(s,c)

A∗e−qA∗; B

≤−qeqcM θ,
(1.39)
where θ = E(s,c)

A′e−qA′′
. Observe that θ does not depend on (s, c) and
that θ < ∞under our distributional assumptions. It follows from (1.38)
and (1.39) that
E(s,c) [hq(S2, C2) −hq(S0, C0)] ≤g(b)hq(s, c),
where g(b) = Me−qb 	M
i=1 γq(i) −qθ. Fix ϵ ∈(0, 1) small enough so that
β
def
= ϵqθ < 1.
Clearly, g(b) →−qθ as b →∞, so that if b is suﬃciently large, then
g(b) ≤−β and Theorem 1.22(iv) holds for (s, c) ∈(Σ −Hb) ∩Q. Similar
arguments apply to each other element of Q, and the desired result follows.
Immediate Transitions
We have established Theorem 1.22 under the assumption that all tran-
sitions are timed. We now extend this result to spns with one or more
immediate transitions. Because it appears hard to modify the foregoing
proof to handle this general case, we apply an indirect approach.
By Corollary 4.10 in Chapter 4, there exists an irreducible gsmp with a
ﬁnite state space that strongly mimics the marking process of the spn. Let
{ (Sn, Cn): n ≥0 } be the underlying chain of this gsmp. Denote by Σ the
state space of the underlying chain and by µ the initial distribution. Also
let ψ be the mapping from Σ onto Σ+ such that { (S+
n , C+
n ): n ≥0 } and
{ ψ(Sn, Cn): n ≥0 } have the same ﬁnite-dimensional distributions. Deﬁne
a function hq on Σ analogously to the function hq deﬁned on Σ+. Similarly,
for b > 0, deﬁne a set Hb ⊆Σ analogously to the set Hb ⊆Σ+. It follows
from the speciﬁc deﬁnition of Σ given in the proof of Corollary 4.10 in
Chapter 4 that
hq

ψ(s, c)

= hq(s, c)
(1.40)
for (s, c) ∈Σ and q ≥0. Moreover, for b > 0,
ψ(Σ −Hb) = Σ+ −Hb.
(1.41)

164
5. Recurrence
Observe that the proof thus far can be applied essentially without change
to establish the assertions of Theorem 1.22 for the underlying chain of the
mimicking gsmp. We can therefore pick b > 0 large enough so that
E(s,c)

hq(Sm, Cm) −hq(S0, C0)

≤−βhq(s, c)
for some β ∈(0, 1) and all (s, c) ∈Σ−Hb, where m is the number of events
in the gsmp. Now ﬁx (s, c) ∈Σ+−Hb. By (1.41), there exists (s, c) ∈Σ−Hb
such that ψ(s, c) = (s, c). We then have
E(s,c)

hq(S+
m, C+
m) −hq(S+
0 , C+
0 )

= E(s,c)

hq

ψ(Sm, Cm)

−hq

ψ(S0, C0)

= E(s,c)

hq(Sm, Cm) −hq(S0, C0)

≤−βhq(s, c)
= −βhq(s, c),
where the ﬁrst equality follows from Corollary 4.10 in Chapter 4 and the
remaining two equalities follow from (1.40). Thus we have established The-
orem 1.22(iv). The remaining assertions of Theorem 1.22 are proved in a
similar manner.
5.2
The Geometric Trials Technique
The results in the previous section give conditions under which the embed-
ded chain { (S+
n , C+
n ): n ≥0 } hits any dense enough set of states inﬁnitely
often with probability 1. As discussed earlier, it sometimes suﬃces to show
that the embedded or underlying chain hits one particular set of states
inﬁnitely often with probability 1, that is,
P { (Sn, Cn) ∈A i.o. } = 1
(2.1)
for some speciﬁed set A ⊂Σ. Such a set is said to be recurrent with respect
to { (Sn, Cn): n ≥0 }. If Assumption PD holds and A ⊆Σ+ with ¯φ(A) > 0,
then (2.1) follows immediately from Corollary 1.26.
In this section, we give methods for establishing recurrence that do not
require positive density assumptions on the clock-setting distribution func-
tions. Such methods are useful because many spn models have one or more
clock-setting distribution functions that have support on some ﬁnite or
countably inﬁnite set of points or on an interval not of the form [0, u]. In
spn models of computer networks, for example, propagation delays often
are modelled as deterministic constants, leading to degenerate clock-setting
distribution functions that put all of the probability mass on a single point;
see Examples 2.6, 2.7, 2.12, and 3.7 in Chapter 2. Similarly, in spn mod-
els of manufacturing systems, the time required for a robot to execute a

5.2 The Geometric Trials Technique
165
movement or for a conveyor to transport a part often is modelled as a de-
terministic constant or as a random variable that is bounded away from 0;
see Example 3.6 in Chapter 2.
Sometimes the detailed structure of a speciﬁed spn model can be ex-
ploited in a direct way to establish recurrence, as illustrated by the follow-
ing example.
Example 2.2 (Flexible manufacturing system). As in Example 1.28, sup-
pose we wish to show that (2.1) holds with
A = { (s, c) ∈Σ : E∗(s, c) = { e4 } } .
We can establish (2.1) without imposing the positive density assumptions
on the clock-setting distributions that are used in Example 1.28. The only
requirement is that L1,1, L1,2, L2, and L3 each be a.s. ﬁnite. Denote by
θ(n) the random index of the nth marking change at which the under-
lying chain hits the set A. By considering the possible sample paths of
{ (Sn, Cn): n ≥0 }, it can be seen that θ(0) ≤9 for any choice of initial
state and, moreover, θ(n) −θ(n −1) ≤9 for n ≥1. Thus each θ(n) is a.s.
ﬁnite and (2.1) holds.
Although brute-force recurrence arguments as in Example 2.2 do not
require positive density assumptions on the clock readings, they are ap-
plicable only to extremely simple spn models. In the remainder of this
section we therefore focus on a geometric trials technique that avoids the
positive density assumptions of Corollary 1.26 and can be used to establish
recurrence even in very complex spn models.
5.2.1
A Geometric Trials Criterion
It can often be diﬃcult to show directly that P { (Sn, Cn) ∈A i.o. } = 1
for a speciﬁed set A. In such cases the following two-step approach can
be useful. First, ﬁnd a set B ⊃A for which it is easy to show that
P { (Sn, Cn) ∈B i.o. } = 1. Equivalently, ﬁnd a set B for which it is easy
to show that β(n) is a.s. ﬁnite for n ≥1, where β(n) is the random index
of the nth marking change at which the underlying chain hits the set B.
Next, show that
Pµ

(Sβ(n), Cβ(n)) ∈A i.o.

= 1.
Throughout, we restrict attention to sets of the form A = { (s, c) ∈Σ: s ∈
¯G }, where ¯G ⊆G. Thus the goal is to show that
Pµ

Sβ(n) ∈¯G i.o.

= 1.
(2.3)
In this case, the set ¯G is said to be recurrent; if ¯G = { ¯s } for some ¯s ∈
G, then ¯s is said to be recurrent. The primary tool for establishing (2.3)
is the geometric trials lemma—Lemma 3.4 in Chapter 3—which we now

166
5. Recurrence
recast as Lemma 2.4. In the lemma { Fn : n ≥0 } denotes the increasing
sequence of partial histories of the underlying chain { (Sn, Cn): n ≥0 };
see Section 3.4.2.
Lemma 2.4. Let { β(n): n ≥1 } and { α(n): n ≥1 } be increasing sequen-
ces of a.s. ﬁnite random indices such that each α(n) and each β(n) is
a stopping time with respect to { Fn : n ≥0 } and, moreover, β(n −1) ≤
α(n) < β(n) for n ≥1. [Take β(0) = 0.] Suppose that
Pµ

Sβ(n) ∈¯G
 Fα(n)

≥δ a.s.
(2.5)
for some δ > 0 and all n ≥1. Then Pµ

Sβ(n) ∈¯G i.o.

= 1.
Proof. Fix n ≥1 and set
Zn =

1
if Sβ(n) ∈¯G;
0
otherwise.
Observe that the values of Z1, Z2, . . . , Zn−1 are completely determined by
Fβ(n−1), and hence by Fα(n), so that
Pµ { Zn = 1 | Zn−1, . . . , Z1 }
= Eµ

Pµ

Zn = 1 | Fα(n)
  Zn−1, . . . , Z1

= Eµ

Pµ

Sβ(n) ∈¯G | Fα(n)
  Zn−1, . . . , Z1

≥Eµ [ δ | Zn−1, . . . , Z1]
= δ a.s.,
and the desired result follows from the geometric trials lemma.
The random times { α(n): n ≥0 } are chosen for convenience; as discussed
in the following subsections, (2.5) can be more easily established for some
random times than for others.
5.2.2
GNBU Distributions
When establishing recurrence using Corollary 1.26, we require that the spn
be irreducible and each clock-setting distribution function have a density
component that is positive and continuous on an interval of the form (0, ¯x].
Use of Lemma 2.4, on the other hand, leads to conditions on the spn
building blocks that depend on the particular spn of interest. A typical
requirement is that certain of the new clock readings be generated according
to “gnbu” distribution functions. The class of gnbu distribution functions
generalizes the “new better than used” distribution functions that arise in
the statistical theory of reliability.

5.2 The Geometric Trials Technique
167
Deﬁnition 2.6. A distribution function F with support on [0, ∞) is new
better than used (nbu) if and only if
F(x + y) ≤F(x)F(y)
for x, y ≥0, where F = 1 −F.
Suppose, for example, that F is the distribution function for the random
lifetime L of a machine and that P { L > y } > 0 for some y > 0. If F is
nbu, then
P { L −y > x | L > y } ≤P { L > x }
for x ≥0. That is, the survival probability for a machine of age y is less than
the corresponding survival probability for a new machine. Equivalently,
P { L −y ≤x | L > y } ≥P { L ≤x }
for x ≥0, so that the residual lifetime of a machine of age y is stochastically
smaller—see Deﬁnition 1.7 in the Appendix—than the lifetime of a new
machine.
nbu distributions arise frequently in applications. For example, the dis-
tribution function of a random variable L is nbu if L is a.s. equal to a
ﬁxed constant. Moreover, an absolutely continuous distribution function
F with density function f is nbu if the failure rate r(t) = f(t)/F(t) is
nondecreasing in t. Examples of such distributions include the exponential
distribution (which has a constant failure rate), the Weibull distribution
with shape parameter greater than 1, the gamma distribution with shape
parameter greater than 1, and the truncated normal distribution.
If a distribution function F is nbu, then for suﬃciently large x the ratio
F(x + y)/F(y) is bounded away from 1 as a function of y. The generalized
nbu (gnbu) distribution functions are characterized by this boundedness
property.
Deﬁnition 2.7. A distribution function F with support on [0, ∞) is gnbu
with lower bound x∗if and only if
sup
y≥0
F(x + y)
F(y)
< 1
(2.8)
for x > x∗, where we take 0/0 = 0.
Observe that if (2.8) holds for x = x0, then (2.8) holds for any x ≥x0.
Lemma 2.9 gives some conditions under which a distribution function is
gnbu. Recall that the essential supremum of a distribution function F,
written ess sup F, is deﬁned as sup { x: F(x) < 1 }. Similarly, the essential
inﬁmum of F, written ess inf F, is deﬁned as inf { x: F(x) > 0 }.

168
5. Recurrence
Lemma 2.9. Suppose that F is the distribution function of a nonnegative
random variable.
(i) If F is nbu, then F is gnbu with lower bound x∗= ess inf F.
(ii) If F is absolutely continuous with a density function f that is positive
on (ess inf F, ∞) and satisﬁes
lim
y→∞
f(x∗+ y)
f(y)
< 1
(2.10)
for some x∗> 0, then F is gnbu with lower bound max(x∗, ess inf F).
(iii) If F is absolutely continuous with a density function f that is positive
on a ﬁnite interval [a, b] and equal to 0 elsewhere, then F is gnbu
with lower bound x∗= a.
(iv) If there exist a continuous nbu distribution function G and a constant
c ∈(0, ∞) such that
lim
x→∞
F(x)
G(x) = c,
then F is gnbu.
Proof. If F is nbu and x > ess inf F, then
sup
y≥0
F(x + y)
F(y)
≤F(x) < 1.
To prove the assertion in (ii), pick x > max(x∗, ess inf F) and observe
that
lim
y→∞
F(x + y)
F(y)
≤lim
y→∞
F(x∗+ y)
F(y)
= lim
y→∞
f(x∗+ y)
f(y)
< 1
where the equality follows from l’Hopital’s rule. Pick b > 0 and v < 1 such
that F(x + y)/F(y) ≤v for y > b. Because x > ess inf F and f is positive
on (ess inf F, ∞), the continuous function g(y) = F(x + y)/F(y) is strictly
less than 1 for all y ∈[0, b]. Set u = sup0≤y≤b g(y) and observe that u < 1
because a continuous function attains its maximum value over a compact
set. The desired result now follows because
sup
y≥0
F(x + y)
F(y)
= max
)
sup
0≤y≤b
F(x + y)
F(y)
, sup
y>b
F(x + y)
F(y)
*
≤max(u, v)
< 1.
To prove the assertion in (iii), it suﬃces to show that (2.8) holds for
every x ∈(a, b). Pick such an x and observe that, under our assumptions,

5.2 The Geometric Trials Technique
169
F is strictly decreasing on [a, b]. Also observe that F(x + y)/F(y) < 1 for
y = 0 and
F(x + y)
F(y)
< F(x + y)
F(x)
< 1
for 0 < y < x. For y ≥x, we have F(y) ≥F(y + x), with F(y) = F(y + x)
only if y > b, in which case F(x + y)/F(y) = 0.
To prove the assertion in (iv), pick x, ϵ > 0 such that
F(x + y)
G(x + y) ≤c + ϵ
for y ≥0. It follows from the nbu property of G that
sup
y≥0
F(x + y)
F(y)
≤(c + ϵ)G(x)
)
inf
y≥0
F(y)
G(y)
*−1
.
(2.11)
It suﬃces to show that
inf
y≥0
F(y)
G(y) > 0,
since then the term on the right side of (2.11) is less than 1 for suﬃciently
large x. The above inequality follows by an argument similar to the proof of
the assertion in (ii)—use the fact that, since G is continuous, the function
h(y) = F(y)/G(y) is lower semicontinuous and hence attains its inﬁmum
over any interval of the form [0, b].
Many distribution functions are gnbu but not nbu. For example, if F
is any non-nbu distribution function such that F(u) = 1 for some u < ∞,
then F is gnbu with lower bound u. Other examples include mixtures of
exponential distributions and gamma distributions with shape parameter
less than 1. To establish the gnbu property for these distributions, apply
Lemma 2.9(ii); alternatively, Lemma 2.9(iv) can be used to show that mix-
tures of exponential distributions are gnbu—take G(x) = 1−exp(−bx) for
an appropriate constant b. The foregoing gamma distribution functions,
far from being nbu, are new worse than used (nwu) in that F(x + y) ≥
F(x)F(y) for x, y ≥0 (with strict inequality for at least one value of x and
y).
As shown by the following result, a gnbu distribution has ﬁnite moments
of all orders.
Lemma 2.12. If F is gnbu, then
 ∞
0
xr dF(x) < ∞for r ≥0.
Proof. Let x∗be the gnbu lower bound for F. Fix x > x∗and set
γ = γ(x) = sup
y≥0
F(x + y)
F(y)
< 1.

170
5. Recurrence
An easy inductive argument shows that F(kx + y) ≤γkF(y) for y ≥0 and
k ∈{ 0, 1, 2, . . . }. In particular, F(kx) ≤γk. Fix r > 1 and use a standard
identity—see (1.13) in the Appendix—to obtain
 ∞
0
yr dF(y) =
 ∞
0
ryr−1F(y) dy
=
∞

k=0
 (k+1)x
kx
ryr−1F(y) dy
≤rxr
∞

k=0
(k + 1)r−1γk
< ∞.
We conclude this section by establishing some additional properties of
gnbu distributions that are useful when verifying the geometric trials re-
currence criterion in (2.5).
Lemma 2.13. Let A1, A2, . . . , Am be mutually independent random vari-
ables with distribution functions F1, F2, . . . , Fm, and suppose that each Fi
is gnbu with lower bound x∗
i . Then
sup
y1,...,ym≥0
P
 m

i=1
(Ai −yi) > x
 Ai > yi for 1 ≤i ≤m

< 1
(2.14)
for x > x∗
1 + x∗
2 + · · · + x∗
m.
Proof. The proof is by induction on m. For m = 1 the desired result (2.14)
reduces to (2.8). Assume for induction that (2.14) holds for some m ≥1.
Fix ϵ > 0, x > x∗
1 + x∗
2 + · · · + x∗
m+1 + ϵ, and y1, y2, . . . , ym+1 ≥0. Deﬁne
events G, Hm, and Hm+1 by setting
G =
 m

i=1
(Ai −yi) ≤x −x∗
m+1 −ϵ

,
Hm = { Ai > yi for 1 ≤i ≤m } ,
and
Hm+1 = { Ai > yi for 1 ≤i ≤m + 1 } .
Also set
γm+1 = sup
y≥0
F m+1(x∗
m+1 + ϵ + y)
F m+1(y)
.
Recall that 1H denotes the random variable that equals 1 if event H occurs
and equals 0 otherwise and that Hc denotes the complement of event H.
Setting
θ =
sup
y1,...,ym≥0
P{ Gc | Hm },

5.2 The Geometric Trials Technique
171
we ﬁnd that
P
 m+1

i=1
(Ai −yi) > x
 Hm+1

= E
!
P
 m+1

i=1
(Ai −yi) > x
 Hm+1, A1, . . . , Am
  Hm+1
"
= E

1Hm

F m+1

ym+1 + x −	m
i=1(Ai −yi)

F m+1

ym+1

  Hm+1

≤E

1Hm∩G

F m+1

ym+1 + x −	m
i=1(Ai −yi)

F m+1

ym+1


+ 1Hm∩Gc
 Hm+1

≤E

1Hm∩G

F m+1

ym+1 + x∗
m+1 + ϵ

F m+1

ym+1


+ 1Hm∩Gc
 Hm+1

≤γm+1P{ G | Hm } + P{ Gc | Hm }
≤γm+1(1 −θ) + θ.
Since θ < 1 by the induction hypothesis, γm+1 < 1 by (2.8), and y1, y2, . . . ,
ym+1 are arbitrary, the desired result follows.
An immediate consequence of (2.14) is that
inf
y1,...,ym≥0 P
 m

i=1
(Ai −yi) ≤x
 Ai > yi for 1 ≤i ≤m

> 0
(2.15)
for x > x∗
1 + x∗
2 + · · · + x∗
m. This latter inequality can be generalized as
follows.
Lemma 2.16. For some m ≥1, let A1, A2, . . . , Am, B, Q be nonnegative
random variables with respective distribution functions F1, F2, . . . , Fm, G,
H. Suppose that A1, . . . , Am are mutually independent and independent of
both B and Q, and that each Fi is gnbu with lower bound x∗
i . Also suppose
that x∗
1 + · · · + x∗
m + b < q, where b = ess inf G and q = ess sup H. Then
inf
y1,...,ym≥0 P
 m

i=1
(Ai −yi) + B ≤Q
 Ai > yi for 1 ≤i ≤m

> 0.
The result in Lemma 2.16 follows directly from (2.15) after conditioning
on B and Q.

172
5. Recurrence
5.2.3
A Simple Recurrence Argument
gnbu distributional assumptions often can be combined with a “sample
path condition” and a “positivity condition” to establish the geometric
trials recurrence criterion in (2.5). We illustrate our general approach by
means of a simple example.
Example 2.17 (Token ring). For the system of Example 2.6 in Chapter 2,
suppose that the distribution function Fj of each interarrival-time random
variable Aj is nbu. Recall that Rj is the time for the ring token to propagate
from port j to the next port, and suppose that
ess inf Fj < RN
(2.18)
for 1 ≤j ≤N.
Consider the spn representation of the token ring given in Figure 2.10,
and denote by β(n) + 1 the random index of the nth marking change at
which transition e3,1 = “observation of ring token by port 1” ﬁres—thus
E∗(Sβ(n), Cβ(n)) = { e3,1 } and Sβ(n) is the marking just before the ﬁring
of e3,1. Suppose we wish to show that Pµ{ Sβ(n) = ¯s i.o. } = 1, where
¯s = (1, 0, 0, 0, . . . , 1, 0, 0, 0, 1, 0, 0, 1). Observe that the marking is ¯s if and
only if all ports have a packet awaiting transmission and the ring token
is propagating from port N to port 1. Let α(n) be the index of the nth
marking change at which transition e3,1 becomes enabled—that is, at which
the ring token begins to propagate from port N to port 1—and suppose
that α(1) = 0. Observe that there can be at most 2N packet arrivals, N
observations of the ring token by a port, and N packet transmissions in the
time interval [ζβ(n)+1, ζβ(n+1)+1]. It follows that
β(n + 1) −β(n) =

β(n + 1) + 1

−

β(n) + 1

≤4N.
Similarly, β(1) ≤4N. Thus each β(n), and hence each α(n), is a.s. ﬁnite.
Set ¯G = { ¯s }. Fix n ≥1 and denote by In the random set of indices
of the ports having no packet awaiting transmission at time ζα(n). Clearly,
Sβ(n) ∈¯G [that is, Sβ(n) = ¯s] if for each j ∈In there is an arrival in the
interval [ζα(n), ζβ(n)+1) of a packet for transmission by port j. Thus
Pµ

Sβ(n) ∈¯G
 Fα(n)

≥Pµ

Cα(n),1,j ≤RN for j ∈In
 Fα(n)

a.s..
As in Section 3.4.2, deﬁne Zn,1,j to be the amount of time that has elapsed
on the clock for transition e1,j between the most recent clock-setting time

5.2 The Geometric Trials Technique
173
prior to ζn and time ζn itself. Since each Fj is nbu, it follows from Re-
mark 4.14 in Chapter 3 that
Pµ

Cα(n),1,j ≤RN for j ∈In
 Fα(n)

=

j∈In
)
1 −F j(RN + Zα(n),1,j)
F j(Zα(n),1,j)
*
≥

j∈In
Fj(RN)
≥
N

j=1
Fj(RN) a.s..
Each quantity Fj(RN) is positive by (2.18), so that (2.5) holds with δ =
 N
j=1 Fj(RN). The desired result now follows from Lemma 2.4. Observe
that Corollary 1.26 cannot be used to establish recurrence: the clock-setting
distribution functions for transitions e3,1, e3,2, . . . , e3,N are degenerate and
therefore do not satisfy the positive density condition in Assumption PD.
The key steps of the recurrence argument in the foregoing example are
as follows:
1. Show that Sβ(n) ∈¯G if the clock readings for the enabled events in
a speciﬁed set ˜E are “small enough” just after the α(n)th marking
change. This implication constitutes the “sample path condition.” In
Example 2.17, ˜E = { e1,1, . . . , e1,N } and “small enough” means that
each clock reading is less than RN.
2. Require that each event in ˜E has an nbu clock-setting distribution
function. Then the probability that the clock readings at time ζα(n)
for the enabled events in ˜E are small enough is bounded below by
the probability that fresh samples from the clock-setting distribu-
tions are small enough. This step in the argument rests on an ap-
propriate representation of conditional clock-reading distributions; in
Example 2.17, we use the representation given by Lemma 4.10 in
Chapter 3.
3. Impose a “positivity condition” on the clock-setting distribution func-
tions which ensures that the latter probability in (2) is positive. This
positive probability value serves as the constant δ in (2.5), and the
desired result follows. In Example 2.17, the positivity condition is
given by (2.18).
It is easy to weaken the nbu assumption in the foregoing argument and
require only that each Fj be gnbu with lower bound x∗
j satisfying
x∗
j < RN.
(2.19)

174
5. Recurrence
Set γj(x) = supy≥0 F j(x + y)/F j(y) for 1 ≤j ≤N. Then
Pµ

Cα(n),1,j ≤RN for j ∈In
 Fα(n)

=

j∈In
)
1 −F j(RN + Zα(n),1,j)
F j(Zα(n),1,j)
*
≥

j∈In

1 −γj(RN)

≥
N

j=1

1 −γj(RN)

a.s..
It follows from (2.19) and the deﬁnition of the gnbu property that

1 −
γj(RN)

> 0 for each j, so that (2.5) holds with δ =  N
j=1

1 −γj(RN)

.
In the remainder of the chapter, we show how arguments such as those
given above can be extended and applied to a variety of spn models. In
each of our examples, one or more of the clock-setting distribution functions
fails to satisfy the positive density condition in Assumption PD, so that
Corollary 1.26 is not applicable.
5.2.4
Recurrence Theorems
We can extend the argument in Example 2.17 not only by replacing the
nbu distributional assumptions with weaker gnbu assumptions, but also
by using more elaborate sample path and positivity conditions. Theo-
rem 2.21 below is a general result in this direction and is applicable to
a variety of models encountered in practice. In the theorem the sequences
{ β(n): n ≥1 } and { α(n): n ≥0 } are as in Lemma 2.4, and we deﬁne
Gα to be the state space of the process

Sα(n) : n ≥1

. In addition,
{ k(i, j, s): s ∈Gα, 1 ≤i, j ≤M } is a collection of ﬁnite nonnegative
integers such that
k(i, j)
def
= sup
s∈Gα
k(i, j, s) < ∞
(2.20)
for each i and j. Finally, denote by α(n, j, l) (n ≥1, 1 ≤j ≤M, and
l ≥1) the random index of the lth marking change after α(n) at which
transition ej becomes enabled and by An,j,l = Cα(n,j,l),j the value of the
corresponding new clock reading for ej. For ease of exposition, we suppose
that all transitions are simple and all speeds are equal to 1; extending the
results in this section to the general case is straightforward.

5.2 The Geometric Trials Technique
175
Theorem 2.21. Let ˜E ⊆E −E′, eq ∈E −E′, and ¯G ⊆G; and let
{ x∗
i : ei ∈˜E } be a collection of nonnegative numbers. Also let { β(n): n ≥
1 } and { α(n): n ≥0 } be as in Lemma 2.4 and { k(i, j, s): s ∈Gα, 1 ≤
i, j ≤M } be nonnegative integers satisfying (2.20). Set ˜En = ˜E ∩E(Sα(n))
and Kn(i, j) = k(i, j, Sα(n)), and suppose that
(i) for each ei ∈˜E the clock-setting distribution function F( · ; ei) is
gnbu with lower bound x∗
i ,
(ii) eq ∈N(Sα(n); Sα(n)−1, E∗
α(n)−1) and
Pµ

Sβ(n) ∈¯G | Fα(n)

≥Pµ

Cα(n),i +
M

j=1
Kn(i,j)

l=1
An,j,l < Cα(n),q, ei ∈˜En
 Fα(n)

a.s.
(2.22)
for n ≥0, and
(iii) the positivity condition
x∗
i +
M

j=1
k(i, j)yj < z
for ei ∈˜E
(2.23)
holds, where z = ess sup F( · ; eq) and yj = ess inf F( · ; ej) for 1 ≤j ≤
M.
Then Pµ{ Sβ(n) ∈¯G i.o. } = 1.
Proof. Fix n ≥1. For ei ∈˜E, write Fi( · ) = F( · ; ei) and set γi(x) =
supy≥0 F i(x + y)/F i(y). Also write
Un,i = Cα(n),q −
M

j=1
Kn(i,j)

l=1
An,j,l
and set Gn = { Un,i : ei ∈˜En }. Next, set
˜U i = Bq −
M

j=1
k(i,j)

l=1
Aj,l,
where Bq is an independent sample from F( · ; eq) and each Aj,l is an in-
dependent sample from F( · ; ej). Observe that Kn(i, j) ≤k(i, j) a.s. for
each i and j, so that ˜U i is stochastically smaller than Un,i for each i. As
before, denote by Zn,i the amount of time that has elapsed on the clock

176
5. Recurrence
for transition ei between the most recent clock-setting time prior to ζn and
time ζn itself. We then have
Pµ

Sβ(n) ∈¯G | Fα(n)

≥Pµ

Cα(n),i ≤Un,i for ei ∈˜En
 Fα(n)

= Eµ
!
P

Cα(n),i ≤Un,i for ei ∈˜En
 Fα(n), Gn
  Fα(n)
"
= Eµ
 
ei∈˜
En
)
1 −F i(Un,i + Zα(n),i)
F i(Zα(n),i)
*  Fα(n)

≥E
 
ei∈˜
E

1 −γi( ˜U i)


a.s.,
where the ﬁrst inequality follows from condition (ii) of the theorem and
the second equality follows from Lemmas 4.10 and 4.19 in Chapter 3. To
complete the proof, let wi (i ∈˜E) be the essential supremum of the dis-
tribution of ˜U i and observe that wi = z −	M
j=1 k(i, j)yj. Next, write
˜E = { ei1, ei2, . . . , eir } and, for u = (u1, u2, . . . , ur) ∈ℜr
+, set
g(u) =
r

m=1

1 −γim(um)

.
Denote by H the distribution function of the random vector ( ˜U i1, . . . , ˜U ir),
and set R = [x∗
i1, wi1] × · · · × [x∗
ir, wir]. Observe that
E
 
ei∈˜
E

1 −γi( ˜U i)


≥δ,
where δ =

R g dH. Condition (i) of the theorem implies that g is positive
on the set R, and condition (iii) implies that

R dH > 0. Thus δ > 0—see
Lemma 1.23 in the Appendix—and the desired result follows by Lemma 2.4.
Example 2.24 (Cyclic queues). Consider a closed network of queues with
two single-server service centers and N (≥2) jobs. A job that completes ser-
vice at center 1 moves to center 2; a job that completes service at center 2
moves to center 1. Both queueing disciplines are ﬁrst-come, ﬁrst-served.
Successive service times at center i (i = 1, 2) are i.i.d. as a positive ran-
dom variable Li. The random variable L1 is uniformly distributed on the
interval [a, b] for some 0 < a < b, and the random variable L2 is uniformly

5.2 The Geometric Trials Technique
177
e1 = service completion at center 1
e2 = service completion at center 2
Figure 5.6. spn representation of cyclic queues (ﬁve jobs).
distributed on the interval [0, (N −1)a + ϵ] for some ϵ > 0. This system
can be speciﬁed as an spn with two timed deterministic transitions as in
Figure 5.6.
Denote by β(n)+1 the random index of the nth marking change at which
transition e2 ﬁres. Suppose we wish to show that Pµ{ Sβ(n) = ¯s i.o. } = 1,
where ¯s = (0, N). Let α(n) be the random index of the nth marking change
at which transition e2 becomes enabled. Clearly, every β(n) and α(n) is
a.s. ﬁnite. Observe that Sβ(n) = ¯s if all the jobs at center 1 at time ζα(n)
complete service and move to center 2 during the interval [ζα(n), ζβ(n)+1),
so that
Pµ

Sβ(n) = ¯s | Fα(n)

≥Pµ

Cα(n),1 + An,1,1 + · · · + An,1,J < Cα(n),2
 Fα(n)

a.s.,
where J = Sα(n),1 −1 and An,1,1, An,1,2, . . . are the successive center 1
service times that start after ζα(n). That is, (2.22) holds with
• ¯G = { ¯s },
• eq = e2,
• ˜E = { e1 },
• k(i, j, s) = s1 −1 for i = 1, j = 1 and s = (s1, s2) ∈Gα, and
k(i, j, s) = 0 otherwise.
By Lemma 2.9(iii), the distribution function of L1 is gnbu with lower
bound x∗
1 = a. Moreover, Gα = { (s1, s2) ∈S : s1 ≤N −1 }. Thus the pos-
itivity condition (2.23) holds with
x∗
1 +
M

j=1
k(1, j)y1 = x∗
1 + k(1, 1)y1 = a + (N −2)a = (N −1)a
and z = (N −1)a + ϵ. The desired result now follows from Theorem 2.21.

178
5. Recurrence
Example 2.25 (Producer–consumer system with nonpreemptive priority).
For the system of Example 2.1 in Chapter 2, suppose that the creation-time
random variables A1 and A2 are each distributed as Y + a, where a is a
positive constant and Y is an exponential random variable with intensity q
for some q > 0. Also suppose that the distribution of the transmission-time
random variable L1 has an essential supremum that exceeds max

(B1 −
1)a, B2a

, where B1 and B2 are the respective capacities of buﬀers 1 and 2
as before. Denote by β(n)+1 the random index of the nth marking change
at which transition e3 = “end of transmission to consumer 1” ﬁres.
Suppose we wish to show that Pµ{ Sβ(n) = ¯s i.o. } = 1, where ¯s =
(0, B1−1, 1, 0, B2, 0, 0). The marking is ¯s if and only if there are B1 items in
buﬀer 1—one of which is being transmitted to consumer 1—and B2 items
in buﬀer 2.
Denote by α(n) the random index of the nth marking change at which
transition e2 = “start of transmission to consumer 1” ﬁres. Using the fact
that producer–consumer pair 1 has nonpreemptive priority over producer–
consumer pair 2 for use of the channel, it is straightforward to show that
each β(n), and hence each α(n), is a.s. ﬁnite.
Fix n ≥1 and observe that Sβ(n) = ¯s if producers 1 and 2 create Sα(n),1
and Sα(n),4 items, respectively, in the interval [ζα(n), ζβ(n)+1). Suppose that
at time ζα(n) both producer 1 and producer 2 are creating an item. Then the
foregoing event certainly will occur if, starting at time ζα(n), the residual
creation time Cα(n),1 plus the sum of the next Sα(n),1 −1 creation times
for producer 1 is less than ζβ(n)+1 −ζα(n), and similarly for Cα(n),4 plus
the sum of the next Sα(n),4 −1 creation times for producer 2. A similar
analysis holds for other possible scenarios at time ζα(n), and it follows that
(2.22) holds with
• ¯G = { ¯s },
• eq = e3,
• ˜E = { e1, e4 },
• k(i, i, s) = si −1 for i = 1, 4 and s = (s1, s2, . . . , s7) ∈Gα, and
k(i, j, s) = 0 otherwise.
By Lemma 2.9(ii), the common distribution of A1 and A2 is gnbu with
lower bound a, and the positivity condition (2.23) holds with
x∗
1 +
M

j=1
k(1, j)yj = x∗
1 + k(1, 1)y1 = a + (B1 −2)a = (B1 −1)a
and, similarly,
x∗
4 +
M

j=1
k(4, j)yj = x∗
4 + k(4, 4)y4 = a + (B2 −1)a = B2a.

5.2 The Geometric Trials Technique
179
The desired result now follows from Theorem 2.21.
Example 2.26 (Collision-free bus network).
For the system of Exam-
ple 3.7 in Chapter 2, suppose that the interarrival-time random variables
A2, A3, . . . , AN have gnbu distribution functions with respective lower
bounds x∗
2, x∗
3, . . . , x∗
N. Also suppose that
x∗
j + R(j) + T < z
(2.27)
for 2 ≤j ≤N, where z is the essential supremum of the distribution of
the transmission-time random variable L1. Denote by β(n) + 1 the ran-
dom index of the nth marking change at which transition e4,1 = “end of
transmission by port 1” ﬁres.
Suppose we wish to show that Pµ{ Sβ(n) = ¯s i.o. } = 1, where ¯s is the
unique marking such that ¯s3,j = 1 for 2 ≤j ≤N and ¯s4,1 = 1. The marking
is ¯s if and only if a transmission by port 1 is underway and ports 2 through
N each have a packet awaiting transmission, have completed the R(j) + T
wait, and have observed the setting (to 1) of the ﬂip-ﬂop by all ports to
the left.
Denote by α(n) the random index of the nth marking change at which
transition e3,1 = “start of transmission by port 1” ﬁres. Using the fact that
the OR-signal for port 1 is always equal to 0 (since there are no ports to
the left), it can be shown that each β(n), and hence each α(n), is a.s. ﬁnite.
Fix n ≥1 and suppose that at time ζα(n) no port has a packet awaiting
transmission. Observe that Sβ(n) = ¯s if each port j (2 ≤j ≤N) receives
a packet for transmission and completes the R(j) + T wait in the interval
[ζα(n), ζβ(n)+1). A similar analysis holds for other possible scenarios at time
ζα(n), and it follows that (2.22) holds with3
• ¯G = { ¯s },
• eq = e4,1,
• ˜E = { el,j : l = 1, 2 and 2 ≤j ≤N },
• k

{1, j}, {2, j}, s

= 1 for 2 ≤j ≤N and s ∈Gα such that s1,j = 1,
and k( · , · , s) = 0 otherwise.
Each clock-setting distribution function F( · ; e1,j) is gnbu by assumption.
Moreover, it follows from our previous discussion that each (degenerate)
distribution function F( · ; e2,j) is nbu and hence gnbu with lower bound
x∗
2,j = R(j)+T by Lemma 2.9. Observe that each inequality in the positiv-
ity condition (2.23) is of the form x∗
j + R(j) + T < z or x∗
2,j < z. Because
x∗
2,j = R(j)+T, it follows from (2.27) that the positivity condition in (2.23)
holds. The desired result now follows from Theorem 2.21.
3For this spn model, each transition is doubly or triply subscripted, and the notation
in (2.22) is modiﬁed accordingly.

180
5. Recurrence
The next result is a variant of Theorem 2.21 in which the sample path
condition consists of a single inequality, but this inequality involves a sum
of residual clock readings. The proof is similar to that of Theorem 2.21
and uses Lemma 2.16. In the theorem, the sequences { β(n): n ≥1 } and
{ α(n): n ≥0 } are as in Lemma 2.4 and, as before, Gα is the state space
of the process

Sα(n) : n ≥1

. In addition, { k(j, s): s ∈Gα, 1 ≤j ≤M }
is a collection of ﬁnite nonnegative integers such that
k(j)
def
= sup
s∈Gα
k(j, s) < ∞
(2.28)
for each j. As before, the quantity α(n, j, l) is the random index of the lth
marking change after α(n) at which transition ej becomes enabled, and
An,j,l = Cα(n,j,l),j.
Theorem 2.29. Let ˜E ⊆E −E′, eq ∈E −E′, and ¯G ⊆G; and let
{ x∗
i : ei ∈˜E } be a collection of nonnegative numbers. Also let { β(n): n ≥
1 } and { α(n): n ≥0 } be as in Lemma 2.4 and { k(j, s): s ∈Gα, 1 ≤j ≤
M } be nonnegative integers satisfying (2.28). Set ˜En = ˜E ∩E(Sα(n)) and
Kn(j) = k(j, Sα(n)), and suppose that
(i) for each ei ∈˜E the clock-setting distribution function F( · ; ei) is
gnbu with lower bound x∗
i ,
(ii) eq ∈N(Sα(n); Sα(n)−1, E∗
α(n)−1) and
Pµ

Sβ(n) ∈¯G | Fα(n)

≥Pµ
 
ei∈˜
En
Cα(n),i +
M

j=1
Kn(j)

l=1
An,j,l < Cα(n),q
 Fα(n)

a.s.
(2.30)
for n ≥0, and
(iii) the positivity condition

ei∈˜
E
x∗
i +
M

j=1
k(j)yj < z
(2.31)
holds, where z = ess sup F( · ; eq) and yj = ess inf F( · ; ej) for 1 ≤j ≤
M.
Then Pµ{ Sβ(n) ∈¯G i.o. } = 1.
Example 2.32 (Cyclic queues). Consider a closed network of queues with
three single-server service centers and N (≥2) jobs. A job that completes
service at center i (i = 1, 2) moves to center i + 1; a job that completes

5.2 The Geometric Trials Technique
181
e1 = service completion at center 1
e2 = service completion at center 2
e3 = service completion at center 3
Figure 5.7. spn representation of cyclic queues (three tandem servers and six
jobs).
service at center 3 moves to center 1. All queueing disciplines are ﬁrst-
come, ﬁrst-served. Successive service times at center i (i = 1, 2, 3) are i.i.d.
as a positive random variable Li. Both L1 and L2 have a truncated normal
distribution with density f(x) = (2/π)−1/2 exp(−x2/2) for x ≥0. L3 is
uniformly distributed on [1, 5]. This system can be speciﬁed as an spn with
three timed deterministic transitions as in Figure 5.7.
Denote by β(n)+1 the random index of the nth marking change at which
transition e3 = “service completion at center 3” ﬁres. Suppose we wish to
show that Pµ{ Sβ(n) = ¯s i.o. } = 1, where ¯s = (0, 0, N). Let α(n) be the
random index of the nth marking change at which transition e3 becomes
enabled. Clearly, every β(n) and α(n) is a.s. ﬁnite. Fix n ≥1 and observe
that Sβ(n) = ¯s if each of the jobs at centers 1 and 2 at time ζα(n) moves to
center 3 during the interval [ζα(n), ζβ(n)+1). Suppose there are at least two
jobs at center 1 and at center 2 at time ζα(n). Then, for a job waiting in
queue at center 1, the time for the job to move to center 3 is the sum of
the job’s residual waiting time (in queue) at center 1, the job’s next service
time at center 1, the job’s next waiting time at center 2, and the job’s next
service time at center 2. An upper bound Un on this total time is obtained
by summing
1. The residual service time of the job in service at center 1 (at time
ζα(n))
2. The next center 1 service time for each job in queue at center 1
3. The next center 2 service time for each job in queue at center 1
4. The residual service time of the job in service at center 2
5. The next center 2 service time for each job in queue at center 2
Indeed, Un is an upper bound on the time for any job at center 1 or 2 to
move to center 3. Thus Sβ(n) = ¯s if Un does not exceed ζβ(n)+1 −ζα(n) =

182
5. Recurrence
Cα(n),3. A similar analysis applies to each other possible scenario at time
ζα(n), and (2.30) holds with
• ¯G = { ¯s },
• eq = e3,
• ˜E = { e1, e2 },
• k(1, s) = s1 −1, k(2, s) = s1 + s2 −1, and k(3, s) = 0 for s =
(s1, s2, s3) ∈Gα.
As mentioned previously, the truncated normal distribution is nbu and
hence gnbu with lower bound 0. Because the essential inﬁmum of this
distribution also is equal to 0, the positivity condition (2.31) holds trivially.
The desired result now follows from Theorem 2.21.
5.2.5
Some Ad-Hoc Recurrence Arguments
The foregoing recurrence theorems, though applicable to a variety of spn
models, certainly do not cover all possible spns of interest. We conclude
the present chapter by showing how Lemmas 4.10 and 4.19 in Chapter 3,
Lemma 2.16 in the current chapter, and extensions of these results can
be used to establish recurrence directly for some speciﬁc spn models. For
each model, the idea is to show that there exists a collection of positive
constants { δ(s+): s+ ∈Gα } such that
Pµ

Sβ(n) ∈¯G
 Fα(n)

≥δ(Sα(n)) a.s.
(2.33)
for n ≥0; here { β(n): n ≥1 } and { α(n): n ≥1 } are as in Lemma 2.4
and Gα is the state space of

Sα(n) : n ≥1

. Provided that the set Gα
is ﬁnite, the inequality in (2.5) holds because δ(Sα(n)) ≥δ a.s., where
δ = mins+∈Gα δ(s+) > 0. The recurrence of A then follows from Lemma 2.4.
Example 2.34 (Manufacturing cell with robots). For the system of Exam-
ple 3.6 in Chapter 2, denote by R1 the (constant) time for robot 1 to return
to its null position after transfer of a part to conveyor 1; we assume that
this time is greater than the time for robot 1 to return to its null position
after transfer of a part to the unloading area. Similarly, denote by R2 the
(constant) time for robot 2 to return to its null position after transfer of
a part to machine 1. Suppose that the machine 2 processing-time random
variable L2 has an exponential distribution with intensity q for some q > 0.
Also suppose that the distribution function of the machine 1 processing-
time random variable L1 has an inﬁnite essential supremum. Denote by
β(n) + 1 the random index of the nth marking change at which transition
e8 = “end of processing by machine 1” ﬁres.

5.2 The Geometric Trials Technique
183
Suppose we wish to show that Pµ{ Sβ(n) = ¯s i.o. } = 1, where ¯s is the
unique marking such that ¯s4 = ¯s9 = ¯s11 = ¯s22 = ¯s24 = 1 and ¯sj =
0 otherwise. The marking is ¯s if and only if machines 1 and 2 are each
processing a part, a part is on conveyor 1 awaiting transfer to a machine,
no parts are on conveyor 2, and each robot is in its null position.
Denote by α(n) the random index of the nth marking change at which
transition e8 becomes enabled. Using the fact that robot 2 transfers raw
parts from conveyor 1 to the lowest-numbered available machine and that
transfer of a part from machine 1 has priority over transfer of a part either
to or from machine 2, it can be shown that each β(n), and hence each α(n),
is a.s. ﬁnite.
We claim that there exists a collection of positive constants { δ(s+): s+ ∈
Gα } such that (2.33) holds. To see this, ﬁx n ≥1 and suppose, for example,
that Sα(n) = s+, where s+
4 = s+
9 = s+
11 = s+
21 = s+
23 = 1 and s+
j
= 0
otherwise. Then each machine is processing a part, a part is on conveyor 1
awaiting transfer to a machine, no parts are on conveyor 2, and each robot
is returning to its null position. Observe that R = max(R1, R2) is an upper
bound on the time for both robots to return to their null positions. Also
observe that Sβ(n) = ¯s if each robot returns to its null position in the
interval [ζα(n), ζβ(n)+1) and machine 2 does not ﬁnish processing a part in
this interval. It follows from Lemma 4.10 in Chapter 3 that, given Fα(n),
the conditional probability that the transitions ﬁre in this way is bounded
below by
δ(s+) =
 ∞
R
e−qx dF(x; e8),
on the set { Sα(n) = s+ }. The constant δ(s+) is the probability that an in-
dependent sample A8 from the clock-setting distribution function F( · ; e8)
and an independent sample A9 from the (exponential) clock-setting distri-
bution function F( · ; e9) satisfy R < A8 < A9. Note that δ(s+) is positive
since ess sup F( · ; e8) = ess sup F( · ; e9) = ∞by assumption. A similar
analysis can be performed for each state s+ ∈Gα, and the desired result
follows.
Example 2.35 (Telephone system). For the system of Example 1.27, sup-
pose that N > 5 and M > 2, and that the call-length random variables
L1, L2, L3, . . . , LN have a common distribution function H that is gnbu
with lower bound x∗. Also suppose that the waiting-time random variables
A1, A2, . . . , AN are each distributed according to an exponential distribu-
tion function with intensity q for some q > 0. Finally, suppose that
x∗< ess sup H.
(2.36)
Denote by β(n) + 1 the random index of the nth marking change at which
transition e2,1 = “end of call connected on link 1” ﬁres.
Suppose we wish to show that Pµ{ Sβ(n) ∈¯G i.o. } = 1, where ¯s ∈¯G
if and only if ¯s3,1 = 1 and ¯s3,m = 0 for 2 ≤m ≤K. The marking is an

184
5. Recurrence
element of ¯G if and only if a call is connected on link 1 and all other links
are idle.
Denote by α(n) the random index of the nth marking change at which
transition e2,1 becomes enabled. Using the fact that a placed call always
is connected on the lowest available link, it is not hard to show that each
β(n), and hence each α(n), is a.s. ﬁnite.
We claim that there exists a collection of positive constants { δ(s+): s+ ∈
Gα } such that (2.33) holds. To see this, ﬁx n ≥1 and suppose, for example,
that Sα(n) = s+, where s+
2,1,1 = s+
2,2,1 = s+
2,3,2 = s+
2,4,2 = 2 and s+
1,j = 1 for
5 ≤j ≤N. That is, at time ζα(n) lines 1 and 2 are connected on link 1,
lines 3 and 4 are connected on link 2, and no other lines are connected.
Clearly, Sβ(n) ∈¯G if the call underway on link 2 completes before time
ζβ(n)+1 and no calls are placed in the interval [ζα(n), ζβ(n)+1). It follows
that
Pµ

Sβ(n) ∈¯G
 Fα(n)

≥Pµ

Cα(n),2,2 ≤Cα(n),2,1, Cα(n),1,j > Cα(n),2,1 for 5 ≤j ≤N,
and Cν(n,j),1,j > Cα(n),2,1 for j = 3, 4
 Fα(n)

on the set { Sα(n) = s+ }, where ν(n, j) (1 ≤j ≤4) is the random index
of the ﬁrst marking change after α(n) at which transition e1,j becomes en-
abled. A straightforward application of Lemmas 4.10 and 4.19 in Chapter 3
shows that the right side of the above inequality is bounded below by
δ(s+) =
 ∞
x∗γ(x) dH(x),
on the set { Sα(n) = s+ }, where
γ(x) =
)
1 −sup
y≥0
H(x + y)
H(y)
*
e−(N−2)qx
for x ≥0. The gnbu assumption on H implies that γ is positive on (x∗, ∞),
and the positivity condition in (2.36) implies that
 ∞
x∗dH > 0. It follows
that δ(s+) > 0. A similar analysis can be performed for each state s+ ∈Gα,
and the desired result follows.
Example 2.37 (Cyclic queues with feedback). For the network of Exam-
ple 1.4 in Chapter 2, suppose that the service-time distribution at center 1
is gnbu and that the essential supremum of the service-time distribution
at center 2 is inﬁnite. Represent this system by an spn as in Example 2.6
in Chapter 4, and denote by β(n)+1 the random index of the nth marking
change at which transition e2 = “service completion at center 2” ﬁres. Also
denote by α(n) the random index of the nth marking change at which e2
becomes enabled. It is easy to see that transition e1 ﬁres inﬁnitely often

5.2 The Geometric Trials Technique
185
with probability 1, and an application of the Borel–Cantelli lemma (Propo-
sition 1.3 in the Appendix) shows that, with probability 1, inﬁnitely many
service completions at center 1 result in a job moving from center 1 to cen-
ter 2. It follows that transition e2 ﬁres inﬁnitely often with probability 1,
and hence every α(n) and β(n) is a.s. ﬁnite.
Suppose we wish to show that Pµ{ Sβ(n) = ¯s i.o. } = 1, where ¯s = (0, N).
We claim that there exists a collection of positive constants { δ(s+): s+ ∈
Gα } such that (2.33) holds. To see this, ﬁx n ≥1 and suppose, for example,
that Sα(n) = s+, where s+ = (m, N −m) with m > 0. Clearly, Sβ(n) = ¯s
if all m jobs at center 1 complete service and move to center 2 during the
interval [ζα(n), ζβ(n)+1). It follows that
Pµ

Sβ(n) = ¯s
 Fα(n)

≥Pµ

Cα(n),1 +
m−1

l=1
Cα(n,1,l),1 < Cα(n),2
and Sν(n,1,l),1 = m −l for 1 ≤l ≤m
 Fα(n)

,
on the set { Sα(n) = s+ }, where α(n, 1, l) is the random index of the lth
marking change after α(n) at which transition e1 becomes enabled and
ν(n, 1, l) is the random index of the lth marking change after α(n) at which
e1 ﬁres. Recall that p is the probability that a job moves to center 2 upon
completion of service at center 1. An argument similar to the proof of
Lemma 4.10 in Chapter 3 shows that the right side of the above inequality
is bounded below by
δ(s+) = pm inf
y≥0 P { (A1 −y) + A2 + · · · + Am < B|A1 > y } ,
on the set { Sα(n) = s+ }, where the random variables A1, A2, . . . , Am are
i.i.d. according to F( · ; e1) and B is distributed according to F( · ; e2). It fol-
lows from Lemma 2.16 that δ(s+) > 0. A similar analysis can be performed
for each state s+ ∈Gα, and the desired result follows.
Example 2.38 (Token ring). We can weaken the positivity condition used
to establish recurrence for the marking ¯s in Example 2.17. (Recall that the
marking ¯s corresponds to the state in which all ports have a packet awaiting
transmission and the ring token is propagating from port N to port 1.) The
idea is to use Lemma 4.19 in Chapter 3 rather than Lemma 4.10 in that
chapter. Speciﬁcally, denote by Rj,1 = 	N
i=j Ri the time for the token
to propagate from port j to port 1, and suppose that each interarrival
distribution Fj satisﬁes
ess inf Fj < Rj,1;
(2.39)
cf. (2.18). Also suppose that each Fj is nbu. As in Example 2.17, let β(n)+1
be the random index of the nth marking change at which transition e3,1 =

186
5. Recurrence
“observation of ring token by port 1” ﬁres. Unlike Example 2.17, set α(n) =
β(n −1) for n ≥1. Fix n ≥1 and denote by ν(n, j) the ﬁrst time at or
after ζα(n) at which the ring token begins to propagate from port j to the
next port. Observe that Sβ(n) = ¯s if each transition e1,j ﬁres in the interval
[ζν(n,j), ζβ(n)+1], and thus
Pµ

Sβ(n) = ¯s
 Fα(n)

≥Pµ

Cν(n,j),1,j ≤Rj,1 for 1 ≤j ≤N
 Fα(n)

.
We now bound the term on the right:
Pµ

Cν(n,j),1,j ≤Rj,1 for 1 ≤j ≤N
 Fα(n)

= Eµ

Pµ

Cν(n,j),1,j ≤Rj,1 for 1 ≤j ≤N
 Fν(n,N)
  Fα(n)

= Eµ

Pµ

Cν(n,N),1,N ≤RN,1
 Fν(n,N)

Pµ

Cν(n,j),1,j ≤Rj,1 for 1 ≤j ≤N −1
 Fν(n,N)
  Fα(n)

≥FN(RN,1)
Eµ

Pµ

Cν(n,j),1,j ≤Rj,1 for 1 ≤j ≤N −1
 Fν(n,N)
  Fα(n)

≥FN(RN,1) Pµ

Cν(n,j),1,j ≤Rj,1 for 1 ≤j ≤N −1
 Fα(n)

a.s.,
where the second equality is a consequence of Lemma 4.19 in Chapter 3
and the ﬁrst inequality is, in the usual way, a consequence of Lemma 4.10
in Chapter 3 and the nbu assumption on each Fj. Iterating the above cal-
culations, we obtain (2.5) with δ =  N
j=1 Fj(Rj,1). The positivity condition
in (2.39) ensures that δ > 0.
Notes
Our discussion of φ-irreducibility and Harris recurrence follows Meyn and
Tweedie (1993a); see also Glynn and Meyn (1996) and Haas (1999a, 1999c).
In particular, the proof of Proposition 1.13 can be found in these references.
Proposition 1.12 is due to Sean Meyn; see Haas (1999c). A proof of Propo-
sition 1.10 can be found in Asmussen (1987a, Section VI.3). The function
v that appears in the drift conditions is sometimes called a “stochastic
Lyapunov function” in analogy to the ordinary Lyapunov functions that
are used to establish stability for systems governed by nonlinear diﬀeren-
tial equations. Extensions of stability results to continuous-time Markov
processes can be found in papers by Meyn and Tweedie (1993b, 1993c).
Some of the results in the literature require that a 1-step drift criterion
hold for a chain { Zn : n ≥0 }. If an m-step drift criterion (m > 1) holds
with a distance function v, then a 1-step drift criterion holds with distance
function w(z) = Ez [v(Z0) + v(Z1) + · · · + v(Zm−1)]; see Haas (1999c).

5. Notes
187
Some early results on stability for general discrete-event systems can be
found in the work of K¨onig et al. (1967, 1974). These authors consider ﬁnite-
state irreducible gsmps in which events are never cancelled and in which
each clock-setting distribution function has ﬁnite mean and a density that is
positive on (0, ∞). They show that such gsmps converge in total variation—
see Deﬁnition 1.38 in the Appendix—to a unique stationary distribution,
and hence are “Harris ergodic” as deﬁned in Section 5.1.1. Sigman (1990a)
establishes a drift criterion for closed networks of queues; this work inspired
the drift results in the current chapter. There is a large literature concerned
with specialized techniques for stability analysis of speciﬁc types of discrete-
event systems such as “polling” systems and multiclass networks of queues;
see, for example, Altman et al. (1992) and Dai (1995).
Our discussion of the positive density conditions follows Haas (1999a,
1999b, 1999c). In these papers a variant of Theorem 1.22 is given in which
the requirement that each clock-setting distribution function be an element
of G+ is weakened to require only that each distribution have a ﬁnite rth
moment for some r ≥1. The resulting (weaker) drift condition is then
E(s,c)

gr(S+
m, C+
m) −gr(S+
0 , C+
0 )

≤−βgr−1(s, c)
for (s, c) ∈Σ+ −Hb, where gr(s, c) = 1 + max1≤i≤M cr
i .
The spn representation of the telephone system model originally ap-
peared in Haas and Shedler (1991).
When verifying Assumption PD, it typically is straightforward to verify
the positive density and moment conditions on the clock-setting distri-
butions and the positivity requirement on the speeds, since the modeller
speciﬁes the clock-setting distributions and speeds. It then remains to deter-
mine whether the marking set is ﬁnite and whether the spn is irreducible.
(These properties also need to be veriﬁed when computing steady-state
performance measures analytically or numerically for more tractable spns
such as nets with exponential clock-setting distributions.) When the mark-
ing set G is speciﬁed explicitly, determining whether |G| < ∞is trivial.
In practice, however, G is often deﬁned implicitly as the set of markings
reachable (in the sense of the relation ; in Section 2.4) from some speciﬁed
set of initial markings; it can then be nontrivial to determine whether G
is ﬁnite. Under various restrictions on the form of the new-marking prob-
abilities and speeds, both ﬁniteness and irreducibility can be checked, at
least in principle, by constructing “coverability graphs” using an algorithm
similar to that given in Section 4.2.1 of Peterson (1981). This approach is
applicable, for example, to deterministic spns—see Section 2.4—having no
inhibitor arcs. In general, however, the problem of determining ﬁniteness
and irreducibility can be diﬃcult: the marking set can be so large that
the computational costs of the coverability analysis are prohibitive or there
may exist no algorithm that is guaranteed to terminate. The problem of
determining whether |G| < ∞, for example, is “undecidable” over the class
of all spns. On the other hand, there are many spn models of practical

188
5. Recurrence
interest for which ﬁniteness and irreducibility can be veriﬁed based on the
analyst’s understanding of the system under study. In such models the dif-
ﬁculty of determining time-average limits arises not so much from the size
or complexity of the marking set or spn graph, but rather from the fact
that the clock-setting distributions are nonexponential.
Iglehart and Shedler (1983) originally proposed the use of the geometric
trials lemma together with nbu distributional assumptions to establish
recurrence. This approach was extended and applied in a variety of contexts
by Haas and Shedler (1985a, 1986, 1987a, 1987b, 1989b, 1992, 1993b). A
good introduction to nbu distributions, failure rates, and related concepts
can be found in Barlow and Proschan (1975).
The sample path conditions in Theorems 2.21 and 2.29 can be combined.
The resulting sample path condition consists of a set of inequalities as in
(2.22), with each inequality involving sums of residual clock readings as in
(2.30); see Haas and Shedler (1987a, 1987b) for examples.

6
Regenerative Simulation
A regenerative stochastic process has the characteristic property that there
exists an inﬁnite sequence of random times at which the process probabilis-
tically restarts. As discussed in Section 6.1, the essence of regeneration is
that the evolution of the process between any two successive regeneration
points is an independent probabilistic replica of the process in any other
such “cycle.” Under mild regularity conditions, time-average limits for a
regenerative process are well deﬁned and ﬁnite, provided that the regen-
erative cycle length has ﬁnite mean. The value of a time-average limit is
determined by the expected behavior of the process in a single regenerative
cycle—a fact that has important implications for simulation analysis. Un-
der some additional regularity conditions, the time-average limit can also
be interpreted as a steady-state or limiting mean. Most of these results
extend to the setting of “od-equilibrium” and “od-regenerative” processes.
Such processes are similar to regenerative processes in that sample paths
can be decomposed into identically distributed cycles, but diﬀer in that
adjacent cycles need not be independent.
In Section 6.2 we give conditions on the new-marking probabilities, clock-
setting distributions, and other building blocks of an spn under which
there exist regeneration points for the marking process { X(t): t ≥0 } or
the underlying chain { (Sn, Cn) : n ≥0 } or both. These conditions further
guarantee both the existence and ﬁniteness of a large class of time-average
limits. Our key assumption is that there exist a distinguished marking ¯s
and a distinguished set of transitions ¯E such that the marking process
probabilistically restarts whenever the marking is ¯s and the transitions in
¯E ﬁre simultaneously. The random times at which this probabilistic restart

190
6. Regenerative Simulation
occurs correspond to the successive times at which the underlying chain hits
a distinguished set of states. The results in Chapter 5 can be used to show
that the chain hits the distinguished set inﬁnitely often with probability 1,
so that each regeneration point is a.s. ﬁnite. Extensions of these results
can be used to show that integrals or sums of the output process over a
regenerative cycle—as well as the cycle length itself—have ﬁnite moments.
By exploiting the special structure of a regenerative process, we can
obtain strongly consistent point estimates and asymptotic conﬁdence in-
tervals for time-average limits based on simulation of a ﬁnite portion of
a single sample path. The resulting “regenerative method” for analysis of
simulation output is presented in Section 6.3. We also outline extensions of
the basic method that deal with excessive bias in the estimator, simulation
up to a speciﬁed time, a priori precision requirements, estimation of non-
linear functions of time-average limits, estimation of gradients of time-
average limits with respect to model parameters, and dependence between
adjacent cycles.
6.1
Regenerative Processes
In this section we formally deﬁne the regenerative property and give con-
ditions under which time-average limits for regenerative processes are well
deﬁned and ﬁnite. We then extend these results to processes with one-
dependent cycles.
6.1.1
Deﬁnition of a Regenerative Process
We ﬁrst consider processes that evolve over continuous time. For the se-
quence of random times { Tk : k ≥0 } deﬁned below, set τk = Tk −Tk−1 for
k ≥1.
Deﬁnition 1.1. The stochastic process { X(t): t ≥0 } with state space S
is a regenerative process in continuous time if there exists an increasing
sequence 0 ≤T0 < T1 < T2 < · · · of a.s. ﬁnite random times such that the
post-Tk process { X(Tk + t): t ≥0; τk+l : l ≥1 }
(i) is distributed as the post-T0 process { X(T0 + t): t ≥0; τl : l ≥1 },
and
(ii) is independent of the pre-Tk process { X(t): 0 ≤t < Tk; τ1, . . . , τk }
for k ≥1.
The sequence { Tk : k ≥0 } of regeneration points is a (possibly delayed) re-
newal process—see Section A.2.3 in the Appendix—that decomposes sam-
ple paths of { X(t): t ≥0 } into i.i.d. cycles; the kth cycle is { X(t): Tk−1 ≤

6.1 Regenerative Processes
191
t < Tk }. The random variable τk deﬁned above is the length of the kth
cycle.
When T0 = 0 the process { X(t): t ≥0 } is called a nondelayed regen-
erative process; otherwise, it is called a delayed regenerative process. For
a delayed regenerative process { X(t): t ≥0 }, the “0th cycle” { X(t): 0 ≤
t < T0 } need not have the same distribution as the other cycles. Sim-
ilarly, the length of this cycle—denoted by τ0—need not have the same
distribution as τ1, τ2, and so forth.
Remark 1.2. Checking whether a stochastic process { X(t): t ≥0 } satisﬁes
Deﬁnition 1.1 amounts to verifying whether
P

X(Tk + t1) ∈A1, . . . , X(Tk + tn) ∈An,
τk+1 ≤u1, . . . , τk+m ≤um
 X(t): 0 ≤t < Tk

= P

X(T0 + t1) ∈A1, . . . , X(T0 + tn) ∈An,
τ1 ≤u1, . . . , τm ≤um

a.s.
(1.3)
for all k, m, n ≥1, t1, . . . , tn ≥0, u1, . . . , um ≥0, and A1, A2, . . . , An ⊆S.
If the state space S is ﬁnite or countably inﬁnite, then (1.3) need only
be veriﬁed for sets A1, A2, . . . , An such that each Ai is of the form Ai =
{ si } for some si ∈S. Similarly, if S is a subinterval of ℜ+, then we can
restrict attention to sets A1, A2, . . . , An such that each Ai is of the form
Ai = [0, ai] ∩S for some ai > 0. Analogous simpliﬁcations apply when S is
a subset of a Cartesian product: if, for example, S ⊆S1 × S2, where S1 is
ﬁnite or countably inﬁnite and S2 is a subinterval of ℜ+, then (1.3) need
only be veriﬁed for sets A1, A2, . . . , An such that each Ai is of the form
Ai = { si } × ([0, ai] ∩S2) with si ∈S1 and ai > 0.
If, as often happens, each regeneration point Tk is a stopping time1 with
respect to { X(t): t ≥0 }, then the cycle lengths { τk : k ≥1 } are deter-
mined by the process { X(t): t ≥0 }, and it suﬃces to show that
P

X(Tk + t1) ∈A1, . . . , X(Tk + tn) ∈An
 X(t): 0 ≤t < Tk

= P { X(T0 + t1) ∈A1, . . . , X(T0 + tn) ∈An } a.s.
for k, n ≥1, t1, . . . , tn ≥0, and A1, A2, . . . , An ∈S, where—as discussed
above—S is an appropriate class of subsets of S.
Remark 1.4. If { X(t): t ≥0 } is a regenerative process in continuous time,
then

f

X(t)

: t ≥0

is a regenerative process in continuous time for
1Let { X(t): t ≥0 } be a continuous-time stochastic process with sample paths that
are right-continuous and have limits from the left. A real-valued random variable T is said
to be a stopping time with respect to { X(t): t ≥0 } if the occurrence or nonoccurrence
of the event { T ≤t } is completely determined by { X(u): 0 ≤u ≤t } for t ≥0.

192
6. Regenerative Simulation
any function f. In contrast, the Markov property is not preserved under
arbitrary mappings.
Example 1.5 (Continuous-time Markov chain). Consider an irreducible
ctmc { X(t): t ≥0 } with a ﬁnite state space S and initial state s ∈S. Let
Tk be the kth time at which the chain hits state s. As discussed in Sec-
tion 3.4, each state of the chain—and in particular state s—is hit inﬁnitely
often with probability 1, so that each Tk is a.s. ﬁnite. Moreover, each Tk is
a stopping time with respect to the ctmc. It follows immediately from the
strong Markov property for ctmcs that
P

X(Tk + t1) = s1, . . . , X(Tk + tn) = sn
 X(t): 0 ≤t < Tk

= P { X(t1) = s1, . . . , X(tn) = sn } a.s.
for k ≥1, n ≥1, and t1, t2, . . . , tn ≥0. Thus the random times { Tk : k ≥0 }
form a sequence of regeneration points for the process { X(t): t ≥0 }, and
the ctmc is a nondelayed regenerative process.
The successive times { T ′
k : k ≥0 } at which the ctmc makes a transition
from state s (to some other state) also form a sequence of regeneration
points for { X(t): t ≥0 }—the regenerative property again follows from
the strong Markov property. Observe that P { X(T ′
k) = · } = W(s, · ) for
k ≥0, where W is the transition matrix of the embedded jump chain (see
Section 3.4.1). All the foregoing results also hold for an irreducible positive
recurrent ctmc with a countably inﬁnite state space.
We now consider discrete-time processes. For the sequence of random
indexes { θ(k): k ≥0 } deﬁned below, set τk = θ(k) −θ(k −1) for k ≥1.
Deﬁnition 1.6. The stochastic process { Zn : n ≥0 } with state space Γ is
a regenerative process in discrete time if there exists an increasing sequence
0 ≤θ(0) < θ(1) < θ(2) < · · · of a.s. ﬁnite random times such that the
post-θ(k) process { Zθ(k)+n, τk+n+1 : n ≥0 }
(i) is distributed as the post-θ(0) process

Zθ(0)+n, τn+1 : n ≥0

, and
(ii) is independent of the pre-θ(k) process

Z0, . . . , Zθ(k)−1; τ1, . . . , τk

for k ≥1.
As for regenerative processes in continuous time, the sequence { θ(k): k ≥
0 } of regeneration points is a (possibly delayed) discrete-time renewal pro-
cess that decomposes sample paths of { Zn : n ≥0 } into i.i.d. cycles; the
random variable τk is the length of the kth cycle. Observe that each τk
takes values in the positive integers.
Example 1.7 (Discrete-time Markov chain). Consider an irreducible dtmc
{ Zn : n ≥0 } with a ﬁnite state space Γ. Fix a state z ∈Γ and let θ(k)
be the random index of the kth state transition at which the chain hits z.

6.1 Regenerative Processes
193
As in Example 1.5, each θ(k) is a.s. ﬁnite, and it follows from the strong
Markov property that the random indices { θ(k): k ≥0 } form a sequence
of regeneration points for { Zn : n ≥0 }. In analogy to Example 1.5, we
note that the random indices { θ(k) + 1: k ≥0 } also form a sequence of
regeneration points for { Zn : n ≥0 }.
Example 1.8 (Waiting time in a single-server queue). Consider a queue-
ing system with one single-server service center. Jobs arrive according to a
renewal process and are served according to a ﬁrst-come, ﬁrst-served queu-
ing discipline. The server is never idle when there are jobs in the system.
Successive service times are i.i.d. and independent of the arrival process.
Jobs are numbered in arrival order, and we assume that job 0 arrives at
time 0. Denote by Un+1 the time between the arrival of job n and job n+1,
by Vn the service time for job n, and by Dn the waiting time in queue for
job n. Under our assumptions, { Un : n ≥1 } and { Vn : n ≥0 } each form
a sequence of i.i.d. random variables, and the Ui’s are independent of the
Vi’s. The waiting times obey the following recursive relationship: D0 = 0
and
Dn+1 = (Dn + Vn −Un+1)+
(1.9)
for n ≥0, where x+ = max(x, 0). It follows from (1.9) and the assumptions
on the sequences { Un : n ≥1 } and { Vn : n ≥0 } that { Dn : n ≥0 } is a
discrete-time Markov chain with state space ℜ+. We say that a busy period
starts whenever a job arrives to an empty service center. Denote by θ(n)
the number of the job that initiates the nth busy period, so that Dθ(n) = 0
for n ≥0. Provided that E [V1] < E [U1], each θ(n) is a.s. ﬁnite, and it
then follows from the strong Markov property that the random indices
{ θ(k): k ≥0 } form a sequence of regeneration points for { Dn : n ≥0 }.
We assume henceforth and without further comment that the state space
S in Deﬁnition 1.1 is always a subset of d-dimensional Euclidean space ℜd
for some d ≥1, and similarly for the state space Γ in Deﬁnition 1.6.
6.1.2
Stability of Regenerative Processes
We ﬁrst give conditions under which time-average limits for a continuous-
time or discrete-time regenerative process are well deﬁned and ﬁnite. We
then give further conditions under which a time-average limit can also be
interpreted as a steady-state or limiting mean.
Time-Average Limits
Consider a regenerative stochastic process { X(t): t ≥0 } with state space
S and regeneration points { Tk : k ≥0 }. As before, denote by τk the length
of the kth regenerative cycle. For each real-valued function f deﬁned on S,

194
6. Regenerative Simulation
set
Yk(f) =
 Tk
Tk−1
f

X(u)

du
(1.10)
for k ≥0. (Take T−1 = 0.) Also deﬁne the function |f| by setting |f|(s) =
|f(s)| for s ∈S, so that
Yk(|f|) =
 Tk
Tk−1
f

X(u)
 du
for k ≥1. It follows from the deﬁnition of a regenerative process that the
sequence

 
Yk(f), τk

: k ≥1

consists of i.i.d. random pairs.2 Set
r(f) = E [Y1(f)]
E [τ1]
(1.11)
and observe that r(f) is well deﬁned and ﬁnite if r(|f|) < ∞.
Theorem 1.12. Suppose that E [τ1] < ∞. Then r(|f|) < ∞and
lim
t→∞
1
t
 t
0
f

X(u)

du = r(f) a.s.
(1.13)
for any real-valued function f such that Y0(|f|) < ∞a.s. and E [Y1(|f|)] <
∞.
Remark 1.14. Observe that
Yk(|f|) ≤τk sup
s∈S
|f(s)|
for k ≥0 and any real-valued function f. Thus if f is bounded or the
state space S is ﬁnite, then for q ≥0 we have E [Y q
1 (|f|)] < ∞whenever
E [τ q
1 ] < ∞. Moreover, Y0(|f|) < ∞a.s. because τ0 = T0 < ∞a.s. by
deﬁnition.
Remark 1.15.
Suppose that E [τ1] < ∞and f is nonnegative. Then the
convergence in (1.13) holds without any further conditions, provided that
we allow r(f) to be inﬁnite.
Proof. Fix a function f such that Y0(|f|) < ∞a.s. and E [Y1(|f|)] < ∞.
Clearly, the contribution of

f

X(t)

: 0 ≤t ≤T0

to the time-average
limit is a.s. negligible, so assume without loss of generality that T0 = 0. We
have
1
n
n

k=1
Yk(f) →E [Y1(f)] a.s.,
2For a delayed regenerative process, the random variable Y0(f) need not have the
same distribution as Y1(f), Y2(f), and so forth. For a nondelayed regenerative process,
Y0(f) is identically zero.

6.1 Regenerative Processes
195
1
n
n

k=1
Yk(|f|) →E [Y1(|f|)] a.s.,
and
1
n
n

k=1
τk →E [τ1] a.s.
as n →∞by the strong law of large numbers (slln) for i.i.d. random
variables. The desired result now follows from Theorem 2.9(v) in Chapter 3;
in the theorem, take Z(t) =
 t
0 f

X(u)

du for t ≥0 and ∆k = τk for k ≥1,
and use the fact that supTk−1≤t≤Tk
Z(t)−Z(Tk−1)
 ≤Yk(|f|) for k ≥1.
For a discrete-time regenerative process { Zn : n ≥0 } with state space Γ,
an analog to Theorem 1.12 can be obtained by applying Theorem 1.12 to
the continuous-time process { X(t): t ≥0 }, where X(t) = Z⌊t⌋and ⌊x⌋is,
as before, the greatest integer less than or equal to x. (This trick often can
be used to obtain results for discrete-time processes from corresponding
results for continuous-time processes.) We state the resulting theorem for
ease of reference. Suppose that the random indices { θ(k): k ≥0 } form a
sequence of regeneration points for the process { Zn : n ≥0 }. As before,
set τk = θ(k) −θ(k −1) for k ≥0. (Take θ(−1) = 0.) For each real-valued
function f deﬁned on Γ, set
Yk(f) =
θ(k)−1

j=θ(k−1)
f(Zj)
(1.16)
for k ≥0, and set
r(f) = E [Y1(f)]
E [τ1]
.
(1.17)
Theorem 1.18. Suppose that E [τ1] < ∞. Then r(|f|) < ∞and
lim
n→∞
1
n
n−1

j=0
f(Zj) = r(f) a.s.
for any real-valued function f such that Y0(|f|) < ∞a.s. and E [Y1(|f|)] <
∞.
Limiting Distributions
When a time-average limit r(f) exists for a regenerative process, it is natu-
ral to ask whether the process has a limiting distribution and, if so, whether
r(f) can be interpreted as a steady-state or limiting mean. Theorems 1.20
and 1.25 show that under mild regularity conditions the answer to these
questions is aﬃrmative, provided that the regenerative cycle length has
ﬁnite mean.

196
6. Regenerative Simulation
For a real-valued function f deﬁned on S, denote by D(f) the subset
of points of S at which f is discontinuous. Recall from Section A.1.8 that
we write X(t) ⇒X as t →∞if and only if limt→∞P { X(t) ≤x } =
P { X ≤x } for all x at which the function F(x) = P { X ≤x } is continu-
ous.
Deﬁnition 1.19. The real-valued random variable X is said to be periodic
with period d if d is the largest real number such that
∞

n=0
P { X = nd } = 1.
If no such number d exists, then X is said to be aperiodic. If X is aperiodic,
then the distribution function of X also is said to be aperiodic.
In the following, Yk(f) is given by (1.10) and r(f) is given by (1.11).
Theorem 1.20. Suppose that the cycle length τ1 is aperiodic with E [τ1] <
∞and that { X(t): t ≥0 } has right-continuous sample paths. Then there
exists a random variable X such that
(i) X(t) ⇒X as t →∞,
(ii) f

X(t)

⇒f(X) as t →∞for any real-valued function f such that
P { X ∈D(f) } = 0,
(iii) E [f(X)] = r(f) for any real-valued function f such that E [Y1(|f|)] <
∞or E [ |f(X)| ] < ∞, and
(iv) limt→∞E

f

X(t)

= E [f(X)] for any real-valued function f such
that sups∈S |f(s)| < ∞and P { X ∈D(f) } = 0.
The proof of the assertions in (i) and (iii) uses the key renewal theorem
(Proposition 2.16 in the Appendix) and is beyond the scope of the current
discussion. The assertion in (ii) follows immediately from the assertion in (i)
and the continuous mapping theorem (Proposition 1.42 in the Appendix).
The assertion in (iv) follows from the assertion in (ii) and the uniform inte-
grability of

f

X(t)

: t ≥0

—see Proposition 1.50 in the Appendix. As
discussed in Section A.1.8, P { X ∈D(f) } = 0 for any function f whenever,
as with the marking process of an spn, the state space of { X(t): t ≥0 } is
ﬁnite or countably inﬁnite.
Remark 1.21. The ﬁrst assertion of the theorem is that { X(t): t ≥0 } has
a limiting distribution. The form of this distribution follows from the ratio
formula
E [f(X)] = E [Y1(f)]
E [τ1]
(1.22)
in the third assertion of the theorem. In particular, ﬁx a subset A ⊆S
and take f = 1A in (1.22). Then the limiting probability that X(t) ∈A as

6.1 Regenerative Processes
197
t →∞is equal to the expected time that { X(t): t ≥0 } spends in the set
A during a regenerative cycle divided by the expected length of the cycle.
Remark 1.23. Theorem 1.20 as given above is well suited to the spn ap-
plications that are the focus of our discussion. There exist many variants
of this result, however. In the ﬁnal assertion of the theorem, for example,
the requirement that f be bounded on S can be replaced by the weaker
requirement that the process

f

X(t)

: t ≥0

be uniformly integrable—
see Deﬁnition 1.49 in the Appendix. As another example, the requirement
that the sample paths of { X(t): t ≥0 } be right-continuous can be re-
placed by the requirement that the distribution function of τ1 be “spread
out” as deﬁned in Section A.2.3. Under this latter condition, it can be
shown that { X(t): t ≥0 } converges to X in total variation. As discussed
in Section A.1.8, convergence in total variation is stronger than convergence
in distribution.
We next give an analog of Theorem 1.20 for a discrete-time regenerative
process { Zn : n ≥0 } with state space Γ.
Deﬁnition 1.24. The integer-valued random variable X is said to be pe-
riodic in discrete time with period d if d ≥2 and d is the largest integer
such that
∞

n=0
P { X = nd } = 1.
If no such integer d exists, then X is said to be aperiodic in discrete time.
In the following, Yk(f) is given by (1.16) and r(f) is given by (1.17).
Theorem 1.25. Suppose that the cycle length τ1 is aperiodic in discrete
time with E [τ1] < ∞. Then there exists a random variable Z such that
(i) Zn ⇒Z as n →∞,
(ii) f(Zn) ⇒f(Z) as n →∞for any real-valued function f such that
P { Z ∈D(f) } = 0,
(iii) E [f(Z)] = r(f) for any real-valued function f such that E [Y1(|f|)] <
∞or E [ |f(Z)| ] < ∞, and
(iv) limn→∞E [f(Zn)] = E [f(Z)] for any real-valued function f such that
supz∈Γ |f(z)| < ∞and P { Z ∈D(f) } = 0.
6.1.3
Processes with Dependent Cycles
When considering the behavior of the underlying or embedded chain of an
spn or the properties of a sequence of delays in an spn having a regenerative
marking process—see Chapter 8—we are led to consider processes in which

198
6. Regenerative Simulation
there can be some limited dependence between cycles. Such processes also
arise when studying certain functions of a regenerative process—see Ex-
ample 1.30 below. Fortunately, as discussed in this subsection, most of the
key stability results for regenerative processes hold in this broader setting.
Speciﬁcally, we consider stochastic processes with sample paths that
can be decomposed into cycles that are identically distributed—in fact,
stationary—and one-dependent.3 Such processes are called od-regenerative
processes. Time-average limits for an od-regenerative process are well de-
ﬁned and ﬁnite provided that the cycle length has ﬁnite mean. An od-
equilibrium process is an od-regenerative process in which the cycle lengths
(though not necessarily the cycles themselves) are mutually independent.
Under mild conditions, a time-average limit for an od-equilibrium pro-
cess can also be interpreted as a limiting or steady-state mean. Thus od-
equilibrium processes enjoy the same long-run stability properties as regen-
erative processes. We focus on processes in discrete time, since our primary
application of the results in this section is to the underlying or embedded
chain of an spn or to a sequence of delays in an spn.
OD-Regenerative Processes
We start with the following deﬁnition. As before, set τk = θ(k) −θ(k −1)
for k ≥1.
Deﬁnition 1.26. The stochastic process { Zn : n ≥0 } with state space Γ
is an od-regenerative process in discrete time if there exists an increasing
sequence 0 ≤θ(0) < θ(1) < θ(2) < · · · of a.s. ﬁnite random times such
that the post-θ(k) process { Zθ(k)+n, τk+n+1 : n ≥0 }
(i) is distributed as the post-θ(0) process { Zθ(0)+n, τn+1 : n ≥0 } for
k ≥1, and
(ii) is independent of the pre-θ(k −1) process { Z0, Z1, . . . , Zθ(k−1)−1; τ1,
τ2, . . . , τk−1 } for k ≥2.
The random indices { θ(k): k ≥0 } are called od-regeneration points for the
process { Zn : n ≥0 } and serve to decompose sample paths of { Zn : n ≥0 }
into one-dependent stationary (o.d.s.) cycles. The quantity τk is the length
of the kth such cycle.
Time-average limits exist for an od-regenerative process under the same
conditions as for an ordinary regenerative process. Let { Zn : n ≥0 } be
an od-regenerative process with state space Γ and od-regeneration points
{ θ(k): k ≥0 }. For a real-valued function f deﬁned on Γ, deﬁne Yk(f)
3As discussed in Section A.2.2, a sequence of random variables { Xn : n ≥0 } is sta-
tionary if (X0, X1, . . . , Xk) and (Xn, Xn+1, . . . , Xn+k) are identically distributed for all
k, n ≥0. The sequence is one-dependent if Xn+j is independent of { X0, X1, . . . , Xn }
for each n ≥0 and j > 1.

6.1 Regenerative Processes
199
(k ≥1) as in (1.16) and r(f) as in (1.17). Observe that the sequence

 
Yk(f), τk

: k ≥1

consists of o.d.s. random vectors.
Theorem 1.27. Suppose that E [τ1] < ∞. Then r(|f|) < ∞and
lim
n→∞
1
n
n−1

j=0
f(Zj) = r(f) a.s.
for any real-valued function f such that Y0(|f|) < ∞a.s. and E [Y1(|f|)] <
∞.
The proof of this result is essentially the same as for Theorem 1.12, except
that we use the slln for one-dependent and identically distributed (o.i.d.)
random variables—see Proposition 2.7 in the Appendix.
In general, od-regeneration points { θ(k): k ≥0 } do not form a renewal
process in discrete time, so that results as in Theorem 1.25 cannot be
extended to this setting.
OD-Equilibrium Processes
As with an od-regenerative process, set τk = θ(k) −θ(k −1) for k ≥1.
Deﬁnition 1.28. The stochastic process { Zn : n ≥0 } with state space Γ
is an od-equilibrium process in discrete time if there exists an increasing
sequence 0 ≤θ(0) < θ(1) < θ(2) < · · · of a.s. ﬁnite random times such
that, for k ≥1, the post-θ(k) process { Zθ(k)+n, τk+n+1 : n ≥0 }
(i) is distributed as the post-θ(0) process { Zθ(0)+n, τn+1 : n ≥0 },
(ii) is independent of the pre-θ(k −1) process { Z0, Z1, . . . , Zθ(k−1)−1; τ1,
τ2, . . . , τk−1 }, and
(iii) is independent of τk.
The random indices { θ(k): k ≥0 } are called od-equilibrium points for the
process { Zn : n ≥0 } and serve to decompose sample paths of { Zn : n ≥0 }
into o.d.s. cycles. The deﬁnition of an od-equilibrium process is almost
identical to Deﬁnition 1.26, except for the additional requirement in (iii).
This latter condition ensures that the cycle lengths are i.i.d. and hence that
the sequence of points { θ(k): k ≥0 } is a renewal process in discrete time.
Example 1.29 (Discrete-time Markov chain). Consider a recurrent dtmc
{ Xn : n ≥0 } and let { θ(k): k ≥0 } be the successive times that the chain
jumps out of a speciﬁed state s. Fix an integer l ≥1 and set ˜θ(k) = θ(k)+l
for k ≥0. Then the random indices { ˜θ(k): k ≥0 } typically form a sequence
of od-equilibrium points for the process { Xn : n ≥0 }. To see this, observe
that, as discussed in Example 1.7, the random indices { θ(k): k ≥0 } form
a sequence of regeneration points for the chain, and thus the cycle lengths

200
6. Regenerative Simulation
{ ˜θ(k) −˜θ(k −1): k ≥1 } = { θ(k) −θ(k −1): k ≥1 } are i.i.d.. Moreover,
the ˜θ(k)-cycles are identically distributed. For each k, however, there is, in
general, no probabilistic restart at time ˜θ(k), so that the adjacent cycles
demarcated by ˜θ(k) are typically dependent. Nonadjacent ˜θ(k)-cycles are
always separated by at least one point θ(l) and are therefore independent.
Example 1.30 (Pairwise mapping of a regenerative process).
Let { Zn :
n ≥0 } be a regenerative process with state space Γ and regeneration points
{ θ(k): k ≥0 }. For a real-valued function f deﬁned on Γ × Γ, set Wn =
f(Zn, Zn+1) for n ≥0. Although the cycles of the process { Wn : n ≥0 }
deﬁned by the points { θ(k): k ≥0 } clearly are identically distributed, they
may not be independent—indeed, Wθ(k)−1 and Wθ(k) may both depend ex-
plicitly on Zθ(k). Observe, however, that for k ≥2 the post-θ(k) process
{ Wθ(k)+n, τk+n+1 : n ≥0 } is determined by

Zθ(k)+n, τk+n+1 : n ≥0

whereas Uk = { W0, W1, . . . , Wθ(k−1)−1; τ1, τ2, . . . , τk } is determined by
{ Z0, Z1, . . . , Zθ(k−1); τ1, τ2, . . . , τk }. It follows from the regenerative struc-
ture of { Zn : n ≥0 } that the post-θ(k) process is independent of Uk. Thus
the random indices { θ(k): k ≥0 } form a sequence of od-equilibrium points
for { Wn : n ≥0 }. Note that if Zθ(k) ≡z for some z ∈Γ and each k ≥0,
then { Wn : n ≥0 } is, in fact, a regenerative process.
Since od-equilibrium processes are a subclass of od-regenerative pro-
cesses, Theorem 1.27 applies. Thus—under mild regularity conditions—
time-average limits of an od-equilibrium process are well deﬁned and ﬁ-
nite provided that the cycle length has ﬁnite mean. Moreover, since the
points { θ(k): k ≥0 } form a renewal process, the proof of Theorem 1.25
applies essentially without change to establish the following result for an od-
equilibrium process { Zn : n ≥0 }. In the theorem, we deﬁne Yk(f) (k ≥1)
as in (1.16) and r(f) as in (1.17).
Theorem 1.31. Suppose that the cycle length τ1 is aperiodic in discrete
time with E [τ1] < ∞. Then there exists a random variable Z such that
(i) Zn ⇒Z as n →∞,
(ii) f(Zn) ⇒f(Z) as n →∞for any real-valued function f such that
P { Z ∈D(f) } = 0,
(iii) E [f(Z)] = r(f) for any real-valued function f such that E [Y1(|f|)] <
∞or E [ |f(Z)| ] < ∞, and
(iv) limn→∞E [f(Zn)] = E [f(Z)] for any real-valued function f such that
f is bounded and P { Z ∈D(f) } = 0.
Perhaps the most important examples of od-equilibrium processes are
Harris recurrent Markov chains. Proposition 1.32 asserts that any Harris
recurrent chain is an od-equilibrium process and gives a representation of
the invariant measure of the chain in terms of cycles. The proposition also

6.1 Regenerative Processes
201
asserts that the cycle length has moments of all orders, provided that the
chain satisﬁes a geometric drift condition.
Proposition 1.32. Let { Zn : n ≥0 } be a Harris recurrent Markov chain
with state space Γ and initial distribution µ. Then there exists at least one
sequence { θ(k): k ≥0 } of od-equilibrium points for { Zn : n ≥0 }. For any
such sequence, the measure π0 deﬁned for A ⊆Γ by
π0(A) = Eµ
θ(1)−1

n=θ(0)
1A(Zn)

is an invariant measure for the chain. If, moreover, the stability conditions
(1.14) and (1.15) in Chapter 5 hold for some choice of B, v, and β, and if
the initial distribution µ satisﬁes

v(z) µ(dz) < ∞, then the cycle length
τ1 = θ(1) −θ(0) satisﬁes Eµ[erτ1] < ∞for suﬃciently small r > 0 (and
hence has ﬁnite moments of all orders).
Remark 1.33. Observe that a Harris recurrent chain { Zn : n ≥0 } is positive
Harris recurrent if and only if π0(Γ) = Eµ [τ1] < ∞, in which case the
measure π given by
π(A) = π0(A)
π0(Γ) = Eµ [Y1(1A)]
Eµ [τ1]
=
Eµ
	θ(1)−1
n=θ(0) 1A(Zn)

Eµ [τ1]
(1.34)
for A ⊆Γ is the unique invariant probability measure of the chain. If,
moreover, the chain is aperiodic in the sense of Section 5.1.1, then τ1 is
aperiodic in the sense of Deﬁnition 1.19, and it follows from Theorem 1.31
that Zn ⇒Z, where Z is distributed according to π. Thus a Harris ergodic
chain converges in distribution to a unique invariant probability measure.
The proof of Proposition 1.32 rests on the rather deep fact that for a
φ-irreducible chain there exists a set C ⊆Γ such that φ(C) > 0 and
P r(z, · ) = bλ( · ) + (1 −b)Q(z, · ),
z ∈C,
(1.35)
for some r ≥1, b ∈(0, 1], probability distribution λ, and transition kernel
Q—indeed, it can be shown that any set A ⊆Γ with φ(A) > 0 contains such
a “C-set.” It follows from the Harris recurrence that C is hit inﬁnitely often
with probability 1. The decomposition in (1.35) permits construction of a
version of the chain together with a sequence { θ(k): k ≥0 } of random in-
dices that serve as od-equilibrium points. The construction uses a sequence
{ In : n ≥0 } of i.i.d. Bernoulli random variables with Pµ { In = 1 } = 1 −
Pµ { In = 0 } = b. The idea is to generate successive states of the chain ac-
cording to the initial distribution µ and transition kernel P until the ﬁrst
time M ≥0 such that ZM ∈C. If IM = 1, then generate ZM+r according
to λ; if IM = 0, then generate ZM+r according to Q(ZM, · ). Next, gen-
erate the intermediate states ZM+1, ZM+2, . . . , ZM+r−1 according to the

202
6. Regenerative Simulation
appropriate conditional distribution (conditioned on the endpoint values
ZM and ZM+r). Now iterate this procedure starting from state ZM+r. De-
note by θ(0), θ(1), . . . the successive times at which the state of the chain is
generated according to λ. Using the strong Markov property as in (1.6) in
Chapter 3, it is straightforward to show that the cycles formed by the points
{ θ(k): k ≥0 } are identically distributed and have i.i.d. lengths; each cycle
consists of at least r state transitions. By construction, each Zθ(k) depends
at most on Zθ(k)−1, Zθ(k)−2, . . . , Zθ(k)−r+1 (via the conditioning described
above). It follows that the post-θ(k) process { Zθ(k)+n, τk+n+1 : n ≥0 } is
independent of { Zn : 0 ≤n ≤θ(k) −r } and { τl : 0 ≤l ≤k }, so that the
cycles are one-dependent. Observe that when (1.35) holds with r = 1, then
the random indices { θ(k): k ≥0 } form a sequence of regeneration points
for the chain. Indeed, it can be shown that (1.35) must hold with r = 1 for
a sequence of regeneration points to exist.
The ﬁnal result in this section can be viewed as a partial converse to
Proposition 1.32.
Proposition 1.36. Suppose that there exists a sequence { θ(k): k ≥0 } of
od-regeneration points for a Markov chain and Eµ [θ(1) −θ(0)] < ∞. Then
the chain is positive Harris recurrent.
Proof. Denote by Γ the state space of the chain and by µ the initial
distribution. Suppose that π(A) > 0 for a ﬁxed set A ⊆Γ, where π is deﬁned
by (1.34). It follows from Theorem 1.27 that limn→∞(1/n) 	n−1
j=0 1A(Zj) =
π(A) > 0 a.s., and hence
Pµ { Zn ∈A i.o. } = Pµ
 ∞

n=0
1A(Zn) = ∞

= 1.
Thus the chain { Zn : n ≥0 } is Harris recurrent with recurrence measure π.
It then follows from Remark 1.33 that the chain is actually positive Harris
recurrent since Eµ [θ(1) −θ(0)] < ∞.
6.2
Regeneration and Stochastic Petri Nets
In this section we give conditions on the building blocks of an spn under
which there exists a sequence of regeneration points for the marking process
or the underlying chain or both. Theorem 2.2 gives general suﬃcient con-
ditions for such regenerative structure. Theorems 2.24, 2.31, 2.36, and 2.44
reﬁne these conditions when Assumption PD of Chapter 5 holds or a geo-
metric trials criterion is satisﬁed. These results also give conditions under
which integrals or sums of the output process over a regenerative cycle—as
in (1.10) or (1.16)—have ﬁnite moments. In particular, these results give
conditions under which the cycle length has ﬁnite moments.

6.2 Regeneration and Stochastic Petri Nets
203
Throughout this section, we consider an spn with marking set G, timed
marking set S, transition set E, immediate transition set E′, marking pro-
cess { X(t): t ≥0 }, and underlying chain { (Sn, Cn): n ≥0 }. Recall that
the chain takes values in Σ = 
s∈G

{ s } × C(s)

, that ζn is the epoch (in
continuous time) of the nth marking change, and that E∗
n = E∗(Sn, Cn)
is the set of transitions that ﬁre simultaneously and trigger the (n + 1)st
marking change.
6.2.1
General Conditions for Regenerative Structure
For a marking ¯s ∈G and set of transitions ¯E ⊆E(¯s), denote by { θ(k): k ≥
0 } the indices of the successive marking changes at which the marking is
¯s and the transitions in ¯E ﬁre simultaneously: θ(−1) = 0 and
θ(k) = inf

n > θ(k −1): Sn−1 = ¯s and E∗
n−1 = ¯E

(2.1)
for k ≥0. In accordance with our usual notation, we denote by O(s′; ¯s, ¯E)
the set of transitions in E −¯E that are enabled both before and after a
marking change from ¯s to s′ triggered by the simultaneous ﬁring of the
transitions in ¯E.
Theorem 2.2. Let ¯s ∈G and ¯E ⊆E(¯s). Suppose that
Pµ

(Sn, E∗
n) = (¯s, ¯E) i.o.

= 1.
Also suppose that for each s′ such that p(s′; ¯s, ¯E) > 0, either
(a) O(s′; ¯s, ¯E) = ∅, or
(b) O(s′; ¯s, ¯E) ̸= ∅and the clock for each transition ei ∈O(s′; ¯s, ¯E) is
always set according to an exponential distribution with ﬁxed intensity
v(ei).
Then the random times { ζθ(k) : k ≥0 } deﬁned via (2.1) form a sequence
of regeneration points for { X(t): t ≥0 }. If, in particular, the condition
in (a) holds for all s′ such that p(s′; ¯s, ¯E) > 0, then the random indices
{ θ(k): k ≥0 } form a sequence of regeneration points (in discrete time)
for { (Sn, Cn): n ≥0 }.
Theorem 2.2 asserts that the successive times at which the marking is
¯s and transitions in ¯E ﬁre simultaneously form a sequence of regeneration
points for the marking process. Heuristically, at each time ζθ(k) the new
marking Sθ(k) is generated according to the ﬁxed probability mass function
p( · ; ¯s, ¯E). The clock for each newly enabled transition ei ∈N(Sθ(k); ¯s, ¯E)
is set according to a distribution function F( · ; Sθ(k), ei, ¯s, ¯E) that depends
on the history of the marking process only through the new marking Sθ(k).
The clock for each old transition ei ∈O(Sθ(k); ¯s, ¯E) has been set at some
previous time according to an exponential distribution with ﬁxed intensity

204
6. Regenerative Simulation
v(ei); the memoryless property of the exponential distribution—see Corol-
lary 4.17 in Chapter 3—implies that the remaining time on the clock is
exponentially distributed with intensity v(ei) regardless of the past history
of the marking process. Thus, the joint distribution of the new marking
and the clock-reading vector is the same at each time ζθ(k). Because the
future evolution of the marking process depends only on the new marking
and the clock-reading vector, the regenerative property follows. The formal
proof of Theorem 2.2 is given at the end of the subsection.
Deﬁnition 2.3. A marking ¯s ∈G is a single state if E(¯s) = { ¯e } for some
¯e ∈E.
Remark 2.4.
Observe that the condition in (a) always holds for a sin-
gle state. Thus, if an spn has a recurrent single state, then there exists
a sequence of regeneration points for both the marking process and the
underlying chain. In practice—as illustrated by the examples in the follow-
ing subsections—regeneration points for spns with nonexponential clock-
setting distributions are almost always deﬁned in terms of a single state.
Example 2.5 (Flexible manufacturing system).
For the spn of Exam-
ple 2.9 in Chapter 2, the immediate marking ¯s = (0, 0, 0, 1, 1, 1, 0, 0, 1) is
a single state with ¯e = e4 = “unloading of ﬁnished parts and loading of
raw parts.” When the marking is ¯s, all machines are idle and three ﬁnished
parts are awaiting unloading. Suppose that the clock-setting distribution
functions satisfy conditions as in Example 1.28 in Chapter 5 or Example 2.2
in Chapter 5, so that ¯s is recurrent. Denote by { θ(k): k ≥0 } the indices
of the successive marking changes at which the marking is ¯s and transition
e4 ﬁres. Then, by Theorem 2.2, the random indices { θ(k): k ≥0 } form
a sequence of regeneration points for the underlying chain and the ran-
dom times { ζθ(k) : k ≥0 } form a sequence of regeneration points for the
marking process.
Remark 2.6.
Suppose that the conditions of Theorem 2.2 hold for two
initial distributions µ and µ′. Then by Theorem 2.2 the random times
{ ζθ(k) : k ≥0 } deﬁned via (2.1) form a sequence of regeneration points for
the marking process under either initial distribution. If the cycle length τ1
is aperiodic with Eµ [τ1] < ∞, then Eµ′ [τ1] < ∞and Theorem 1.20 implies
that X(t) ⇒X under µ and X(t) ⇒X′ under µ′. But, setting Tk = ζθ(k)
for k ≥0, we see that
Pµ { X ∈A } =
Eµ
 T1
T0 1A

X(u)

du

Eµ [τ1]
=
Eµ′
 T1
T0 1A

X(u)

du

Eµ′ [τ1]
= Pµ′ { X′ ∈A }

6.2 Regeneration and Stochastic Petri Nets
205
for any set A ⊆S. Thus the limiting distribution of the marking pro-
cess does not depend on the initial distribution. Similarly, the value of a
time-average limit does not depend on the initial distribution. Analogous
remarks apply in the discrete-time setting.
Remark 2.7.
If the conditions of Theorem 2.2 hold with ¯s ∈E′—as in
Example 2.5—then the regeneration points for the marking process may
not be detectable from the sample paths of the marking process alone. This
is not an issue in practice, however. Indeed—as indicated in Section 3.1.3—a
sample path of the marking process is usually generated by ﬁrst generating
a sample path of the underlying chain, and the regeneration points are
detectable from the latter sample path.
Remark 2.8. In general, { X(t): t ≥0 } is a delayed regenerative process un-
der the conditions of Theorem 2.2. Suppose, however, that the spn behaves
as if at time 0 the marking is ¯s and the transitions in ¯E ﬁre simultaneously.
That is, suppose that the initial distribution of the underlying chain is
equal to ψ, where
ψ(H) = p(s′; ¯s, ¯E)

ei∈N(s′;¯s, ¯
E)
F(xi; s′, ei, ¯s, ¯E)

ei∈O(s′;¯s, ¯
E)

1 −e−v(ei)xi
(2.9)
for all sets
H = { s′ } ×

(c′
1, . . . , c′
M) ∈C(s′): 0 ≤c′
i ≤xi for 1 ≤i ≤M

.
(2.10)
Then we can take θ(0) = 0, so that { X(t): t ≥0 } is a nondelayed regen-
erative process.
Remark 2.11. If the marking process of an spn is regenerative, then—since
the regeneration points are a.s. increasing by deﬁnition—there exists δ > 0
such that Pµ { τ1 > δ } > 0. It follows that the expected cycle length is posi-
tive. Moreover, the Borel–Cantelli lemma implies that Pµ { τk > δ i.o. } = 1,
so that the lifetime of the marking process is a.s. inﬁnite.
Remark 2.12. Let ¯s, ¯E, and { θ(k): k ≥0 } be as in Theorem 2.2. Suppose
that Pµ{ (Sn, E∗
n) = (¯s, ¯E) i.o. } = 1 and the condition in Theorem 2.2(b)
holds for all s′ such that p(s′; ¯s, ¯E) > 0. Although the random times
{ ζθ(k) : k ≥0 } form a sequence of regeneration points for the marking
process, the random indices { θ(k): k ≥0 } do not form a sequence of re-
generation points for the underlying chain { (Sn, Cn): n ≥0 }. To see this,
ﬁx k ≥0 and observe that, for ei ∈O(Sθ(k); ¯s, ¯E), the clock reading Cθ(k),i
is completely determined by { (Sn, Cn): 0 ≤n ≤θ(k) −1 }. It follows that,
in general, the cycles of the underlying chain formed by the θ(k)’s are not
mutually independent (or even m-dependent for some ﬁxed m ≥1). Inter-
estingly, it can be shown—by taking expectations in (2.18) and using the
strong Markov property—that the cycles are identically distributed.

206
6. Regenerative Simulation
Remark 2.13.
Let ¯s ∈G and ¯E ⊆E(¯s), and deﬁne { θ(k): k ≥0 } as in
(2.1). Also let ¯S′ ⊆G be such that p(¯s′; ¯s, ¯E) > 0 for ¯s′ ∈¯S′. Denote by
˜θ(k) the index of the kth marking change at which the old marking is ¯s,
the set of transitions that trigger the marking change is ¯E, and the new
marking is an element of ¯S′; thus { ˜θ(k): k ≥0 } is a random subsequence
of { θ(k): k ≥0 }. Suppose that Pµ{ (Sn, E∗
n) = (¯s, ¯E) i.o. } = 1 and that
O(¯s′; ¯s, ¯E) = ∅for ¯s′ ∈¯S′. Then a straightforward modiﬁcation of the
proof of Theorem 2.2 shows that the random indices { ˜θ(k): k ≥0 } form a
sequence of regeneration points for the underlying chain. Moreover, if Wn =
f(Sn, Cn, Sn+1, Cn+1) for some function f and all n ≥0, and if ¯S′ = { ¯s′ }
for some ¯s′ ∈G, then the latter random indices also form a sequence of
regeneration points for the process { Wn : n ≥0 }; see Remark 1.30. Similar
observations hold in continuous time for the marking process. Virtually all
the results in this section can be modiﬁed in a straightforward manner to
encompass regeneration points of the form { ˜θ(k): k ≥0 }.
Remark 2.14. Let ¯E ⊆E and let ¯G ⊂G be a set of markings such that
• ¯E ⊆E(¯s) for all ¯s ∈¯G, and
• p( · ; ¯s, ¯E) = p( · ; ¯s′, ¯E) for ¯s, ¯s′ ∈¯G, and
• Pµ{ Sn ∈¯G and E∗
n = ¯E i.o. } = 1.
Set θ(−1) = 0 and
θ(k) = inf

n > θ(k −1): Sn−1 ∈¯G and E∗
n−1 = ¯E

(2.15)
for k ≥0. Then the conclusions of Theorem 2.2 hold for the sequence
{ θ(k): k ≥0 } if either (1) the condition in Theorem 2.2(a) holds for all
¯s ∈¯G, or (2) for each s′ ∈G is such that p(s′; ¯s, ¯E) > 0 for some ¯s ∈¯G, the
clock for each transition ei ∈E(s′) is always set according to an exponential
distribution with ﬁxed intensity v(ei).
Remark 2.16. If there exists a sequence { θ(k): k ≥0 } of regeneration
points for the underlying chain as in Theorem 2.2, then there exists a se-
quence of regeneration points for the embedded chain { (S+
n , C+
n ): n ≥0 }.
This latter sequence is deﬁned as follows. Recall from (1.14) in Chapter 3
that γ(n) (n ≥0) is the index of the nth marking change at which the
new marking is timed. Set α(k) = inf { n ≥θ(k): Sn ∈S } for k ≥0.
Then deﬁne θ+(k) for k ≥0 via the relation γ

θ+(k)

= α(k), so that
(S+
θ+(k), C+
θ+(k)) = (Sα(k), Cα(k)) for each k. A straightforward modiﬁcation
of the proof of Theorem 2.2 shows that the random indices { θ+(k): k ≥0 }
form a sequence of regeneration points for the embedded chain.
Proof of Theorem 2.2. Each θ(k) is a stopping time with respect to
the underlying chain, and both { X(t): t ≥ζθ(k) } and { τn : n > k } are

6.2 Regeneration and Stochastic Petri Nets
207
completely determined by the process { (Sn, Cn): n ≥θ(k) }. To prove the
ﬁrst assertion of the theorem, it therefore suﬃces to show that
Pµ

(Sθ(k), Cθ(k)) ∈H0, . . . , (Sθ(k)+n, Cθ(k)+n) ∈Hn
 X(t): 0 ≤t < ζθ(k)

= Pψ { (S0, C0) ∈H0, . . . , (Sn, Cn) ∈Hn } a.s.
(2.17)
for k, n ≥0 and subsets H0, . . . , Hn ⊆Σ of the form (2.10), where ψ
is deﬁned as in (2.9); cf. Remark 1.2. To establish (2.17), ﬁx k ≥0 and
consider an arbitrary but ﬁxed set H of the form (2.10). Recall from Sec-
tion 3.4.2 the deﬁnition of the partial history Fn of the underlying chain
up to the nth marking change, and of the modiﬁed partial history ˜Fn given
by ˜Fn = Fn −{ Sn }. Observe that θ(k) is a stopping time with respect to
the increasing sequence of modiﬁed partial histories { ˜Fn : n ≥0 }. Using
the deﬁnition of θ(k) together with Corollary 4.18 in Chapter 3, we ﬁnd
that
Pµ

(Sθ(k), Cθ(k)) ∈H
 ˜Fθ(k)

= ψ(H)
= Pψ { (S0, C0) ∈H } a.s..
(2.18)
A straightforward inductive argument using the strong Markov property
then shows that
Pµ

(Sθ(k), Cθ(k)) ∈H0, . . . , (Sθ(k)+n, Cθ(k)+n) ∈Hn
 ˜Fθ(k)

= Pψ { (S0, C0) ∈H0, . . . , (Sn, Cn) ∈Hn } a.s.
(2.19)
for n ≥0 and subsets H0, . . . , Hn ⊆Σ of the form (2.10). Because the
process { X(t): 0 ≤t < ζθ(k) } is completely determined by ˜Fθ(k), (2.17)
follows from (2.19) by a simple application of Proposition 1.30 in the Ap-
pendix.
To prove the second assertion, observe that each θ(k) is a stopping time
with respect to the underlying chain. By the strong Markov property for
the underlying chain and the speciﬁc form of the transition kernel P—see
(1.9) in Chapter 3—we have
Pµ

(Sθ(k), Cθ(k)) ∈H
 Gk

= P

(Sθ(k)−1, Cθ(k)−1), H

= Pψ { (S0, C0) ∈H } a.s.
for H ⊆Σ, where Gk = { (S0, C0), . . . , (Sθ(k)−1, Cθ(k)−1) }. An inductive
argument then shows that
Pµ

(Sθ(k), Cθ(k)) ∈H0, . . . , (Sθ(k)+n, Cθ(k)+n) ∈Hn
 Gk

= Pψ { (S0, C0) ∈H0, . . . , (Sn, Cn) ∈Hn } a.s.
for n ≥0 and H0, . . . , Hn ⊆Σ. The desired result now follows from a
discrete-time analog of Remark 1.2.

208
6. Regenerative Simulation
6.2.2
SPNs with Positive Clock-Setting Densities
Using Theorem 2.2 and the results in Section 5.1, we obtain Theorem 2.24
below, which is applicable when Assumption PD holds—that is, when the
marking set is ﬁnite, the spn is irreducible, all speeds are positive, and
the clock-setting distributions for the timed transitions have convergent
LaPlace–Stieltjes transforms and density components that are positive and
continuous on an interval of the form (0, ¯x].
To prepare for Theorem 2.24, we ﬁrst introduce the notion of a “polynom-
ially dominated” function. Recall from Section 3.1.2 that Σ+ = { (s, c) ∈
Σ: s ∈S } is the state space of the embedded chain { (S+
n , C+
n ): n ≥0 },
and set
˜gq(s, c) =

1 + max1≤i≤M cq
i
if (s, c) ∈Σ+;
1
if (s, c) ∈Σ −Σ+
for s ∈G, c = (c1, c2, . . . , cM) ∈C(s), and q ≥0. As in Chapter 5, write
˜f = O(˜g) for real-valued functions ˜f and ˜g deﬁned on Σ if (with 0/0 = 0)
sup
(s,c)∈Σ
| ˜f(s, c)|/|˜g(s, c)| < ∞.
Deﬁnition 2.20. A real-valued function ˜f deﬁned on Σ is polynomially
dominated if ˜f = O(˜gq) for some q ≥0.
Thus a function ˜f is polynomially dominated if | ˜f| is bounded above on Σ+
by a polynomial function of the maximum clock reading and is bounded
above on Σ −Σ+ by a constant.
Example 2.21 (Holding-time function). Suppose that there exists r > 0
such that r(s, e) ≥r for all s ∈S and e ∈E(s)—such an r exists, for
example, if S is ﬁnite and all speeds are positive. Recall the deﬁnition of
the holding-time function t∗from (1.7) in Chapter 3, and observe that
t∗(s, c) =
min
{i: ei∈E(s)} ci/r(s, ei) ≤
max
{i: ei∈E(s)} ci/r ≤r−1
1 + max
1≤i≤M ci

for s ∈S and c = (c1, c2, . . . , cM) ∈C(s). Because, trivially, t∗(s, c) = 0 <
1/r for (s, c) ∈Σ −Σ+, we see that t∗(s, c) ≤r−1˜g1(s, c) for (s, c) ∈Σ and
hence t∗is polynomially dominated.
For a sequence of random indices { θ(k): k ≥0 } deﬁned as in (2.1), set
Yk(f) =
 ζθ(k)
ζθ(k−1)
f

X(u)

du
(2.22)
for each real-valued function f deﬁned on S and
˜Y k( ˜f) =
θ(k)−1

j=θ(k−1)
˜f(Sj, Cj)
(2.23)
for each real-valued function ˜f deﬁned on Σ.

6.2 Regeneration and Stochastic Petri Nets
209
Theorem 2.24. Let ¯s ∈S and ¯e ∈E(¯s). Suppose that Assumption PD
holds. Also suppose that for each s′ such that p(s′; ¯s, ¯e) > 0 either
(a) O(s′; ¯s, ¯e) = ∅or
(b) O(s′; ¯s, ¯e) ̸= ∅and the clock for each transition ei ∈O(s′; ¯s, ¯e) is
always set according to an exponential distribution with ﬁxed intensity
v(ei).
Then
(i) the random times { ζθ(k) : k ≥0 } deﬁned via (2.1) with ¯E = { ¯e } form
a sequence of regeneration points for the marking process { X(t): t ≥
0 },
(ii) Eµ [Y r
1 (|f|)] < ∞for r ≥0 and any real-valued function f deﬁned on
S, where Y1(f) is deﬁned by (2.22), and
(iii) Eµ [ ˜Y r
1(| ˜f|)] < ∞for r ≥0 and any polynomially dominated function
˜f deﬁned on Σ, where ˜Y1( ˜f) is deﬁned by (2.23).
If, in particular, the condition in (a) holds for all s′ such that p(s′; ¯s, ¯e) > 0,
then also
(iv) the random indices { θ(k): k ≥0 } form a sequence of regeneration
points for { (Sn, Cn) : n ≥0 }.
We defer the proof of the theorem to the end of the subsection.
Remark 2.25. Under the conditions of Theorem 2.24 the cycle lengths τ1 =
ζθ(1) −ζθ(0) and ˜τ1 = θ(1) −θ(0) for the marking process and underlying
chain each have ﬁnite moments of all orders. This assertion follows by
taking f ≡1 and ˜f ≡1 in the theorem.
Remark 2.26.
Observe that Eµ [ ˜Y r
1(| ˜f|)] < ∞for r ≥0 and any poly-
nomially dominated function ˜f even when—as discussed in Remark 2.12—
the random indices { θ(k): k ≥0 } do not form a sequence of regeneration
points for the underlying chain { (Sn, Cn): n ≥0 }.
Remark 2.27. Suppose that the conditions of Theorem 2.24 are satisﬁed.
Because each clock-setting distribution has a density component that is
continuous and positive on an interval of the form (0, ¯x), the time τ1 be-
tween successive regeneration points of the marking process is aperiodic.
Moreover, the marking process has right-continuous sample paths by deﬁ-
nition. Thus Theorem 1.20 applies, so that time-average limits can also be
viewed as limiting or steady-state means. When applying Theorem 1.20(iv),
observe that sups∈S f(s) < ∞for any real-valued function f deﬁned on S,
because S is ﬁnite by hypothesis.

210
6. Regenerative Simulation
e1,j = stoppage of machine j
e2,j = start of repair for machine j
e3 = end of repair
Figure 6.1. spn representation of machine repair system (four machines).
Example 2.28 (Machine repair). Consider a group of N (≥1) machines
(numbered 1, 2, . . . , N) under the care of a single repairperson. Whenever
a machine stops and the repairperson is idle, the repairperson immediately
starts to repair the machine. Whenever the repairperson completes a repair
and at least one machine is stopped, the repairperson immediately starts to
repair the lowest-numbered stopped machine; if no machines are stopped,
then the repairperson becomes idle. The successive times (lifetimes) be-
tween end of repair and the next stoppage of machine j are i.i.d according
to a gamma distribution, and the successive times for the repairperson to
repair (and restart) machine j are i.i.d. according to a uniform distribution
on [0, uj] for some constant uj ∈(0, ∞).
This system can be speciﬁed as an spn with timed and immediate transi-
tions and a ﬁnite marking set; see Figure 6.1 for N = 4. Each place contains
at most one token. There is a token in place d1,j if and only if machine j
is running and a token in place d2,j if and only if machine j is stopped and
awaiting repair. There is a token in place d3 if and only if the repairperson
is repairing a machine and a token in place d4 if and only if the repairper-
son is idle. All speeds for enabled transitions are equal to 1. Each timed
transition e1,j and immediate transition e2,j is deterministic. Priorities are
displayed for each transition e2,j; these priorities are used to model the
service discipline described above. Whenever transition e3 = “completion

6.2 Regeneration and Stochastic Petri Nets
211
of repair” ﬁres, it removes a token from place d3 and deposits a token in
place d1,j∗, where j∗is the unique index such that neither place d1,j∗nor
d2,j∗contains any tokens just before the ﬁring of e3. Thus the repairperson
becomes available to repair another machine and the machine that has just
completed repair starts running.
Observe that the marking ¯s in which ¯s1,1 = · · · = ¯s1,N = 0, ¯s2,1 = ¯s4 = 0,
¯s2,2 = · · · = ¯s2,N = 1, and ¯s3 = 1 is a single state with E(¯s) = { e3 }. (All
machines are stopped and a repair of machine 1 is underway whenever the
marking is ¯s.) Moreover, the spn is irreducible. To see this, let ˆs be the
marking in which all machines are running. Then, for s, s′ ∈S, an easy ar-
gument shows that s ; ˆs and ˆs ; s′, so that s ; s′. Each clock-setting dis-
tribution function for a timed transition has a convergent LaPlace–Stieltjes
transform in a neighborhood of the origin and a density function that is pos-
itive and continuous on the interval (0, ¯x], where ¯x = min1≤j≤N uj. Thus
Assumption PD holds and the conditions of Theorem 2.24 are satisﬁed.
Example 2.29 (Producer–consumer system with nonpreemptive priority).
For the system of Example 2.1 in Chapter 2 with buﬀer capacities B1 and
B2, suppose that the creation-time random variables A1 and A2 are each
distributed according to a truncated normal distribution on [0, ∞). Also
suppose that the transmission-time random variables L1 and L2 are each
distributed according to a beta distribution. For the spn in Figure 2.4,
observe that the marking ¯s = (0, B1 −1, 1, 0, B2, 0, 0) is a single state with
E(¯s) = { e3 }, where e3 = “end of transmission to consumer 1.” There are
B1 items in buﬀer 1, B2 items in buﬀer 2, and a transmission to consumer 1
is in progress whenever the marking is ¯s. Setting ˜s = (B1, 0, 0, B2, 0, 0, 1),
it is straightforward to show that s ; ˜s and ˜s ; s′ for any s, s′ ∈G, so
that the spn is irreducible. It follows that Assumption PD holds and the
conditions of Theorem 2.24 are satisﬁed.
Example 2.30 (Telephone system).
For the system of Example 1.27 in
Chapter 5, suppose that successive durations of calls placed at line i are
i.i.d. according to a uniform distribution on [0, u] for some u > 0 and the
successive times from the end of a call placed or received at line i to the
next call placed at line i are i.i.d. according to an exponential distribution
with intensity q for some q > 0. Consider the spn given in Figure 5.5,
and let ¯G be the set of markings in which there is a call connected on
link 1 and all other links are idle. Set ¯e = e2,1 = “end of call connected on
link 1,” and observe that the pair ( ¯G, { ¯e }) satisﬁes the conditions given
in Remark 2.14. Example 1.27 in Chapter 5 shows that Assumption PD
holds. It then follows from Corollary 1.26 in Chapter 5 and Remark 2.14
that
• The random times { ζθ(k) : k ≥0 } deﬁned via (2.15) form a sequence
of regeneration points for the marking process of the spn.

212
6. Regenerative Simulation
• Eµ [Y r
1 (|f|)] < ∞for r ≥0 and any real-valued function f deﬁned on
S, where Y1(f) is deﬁned by (2.22).
The assumption in Theorem 2.24 that ¯s is a timed marking can be re-
laxed. In particular, we have the following result, the proof of which is
sketched at the end of the subsection.
Theorem 2.31. Let ¯s ∈S′ and ¯E = E(¯s) ∩E′. Suppose that Assump-
tion PD holds. Also suppose that for each s′ such that p(s′; ¯s, ¯E) > 0 ei-
ther
(a) O(s′; ¯s, ¯E) = ∅or
(b) O(s′; ¯s, ¯E) ̸= ∅and the clock for each transition ei ∈O(s′; ¯s, ¯E) is
always set according to an exponential distribution with ﬁxed intensity
v(ei).
Then
(i) the random times { ζθ(k) : k ≥0 } deﬁned via (2.1) form a sequence
of regeneration points for the marking process { X(t): t ≥0 },
(ii) Eµ [Y r
1 (|f|)] < ∞for r ≥0 and any real-valued function f deﬁned on
S, where Y1(f) is deﬁned by (2.22), and
(iii) Eµ [ ˜Y r
1(| ˜f|)] < ∞for r ≥0 and any polynomially dominated function
˜f deﬁned on Σ, where ˜Y1( ˜f) is deﬁned by (2.23).
If, in particular, the condition in (a) holds for all s′ with p(s′; ¯s, ¯E) > 0,
then also
(iv) the random indices { θ(k): k ≥0 } form a sequence of regeneration
points for { (Sn, Cn) : n ≥0 }.
We conclude this subsection by giving the proof of Theorem 2.24. To
this end, we need the following lemma, which follows immediately from
Corollary 1.26 in Chapter 5 and Proposition 1.32. In the lemma, we take
θ(−1) = 0.
Lemma 2.32. Suppose that Assumption PD holds. Then there exists at
least one sequence { θ+(k): k ≥0 } of od-equilibrium points for the embed-
ded chain { (S+
n , C+
n ) : n ≥0 }. For any such sequence, the cycle length
˜τ +
k = θ+(k) −θ+(k −1) has ﬁnite moments of all orders for k ≥0.
Proof of Theorem 2.24. The sequence { θ(k) −1: k ≥0 } corresponds
to the successive times at which the chain { (Sn, Cn): n ≥0 } hits the set
A = { (s, c) ∈Σ: s = ¯s and E∗(s, c) = { ¯e } }. By Corollary 1.26 in Chap-
ter 5, there exists ¯x > 0 such that the embedded chain { (S+
n , C+
n ): n ≥0 }
is positive Harris recurrent with recurrence measure ¯φ given by (1.17) in
Chapter 5. Clearly, ¯φ(A) > 0, so that the embedded chain—and hence the

6.2 Regeneration and Stochastic Petri Nets
213
underlying chain—hits the set A inﬁnitely often with probability 1 and
each θ(k) is a.s. ﬁnite. The assertions in (i) and (iv) now follow from The-
orem 2.2. The assertion in (ii) for a speciﬁed function f follows from the
assertion in (iii) with ˜f(s, c) = f(s)t∗(s, c). The remainder of the proof
is therefore devoted to establishing the assertion in (iii). To this end, ﬁx
r > 0 and a polynomially dominated function ˜f; without loss of generality,
suppose that ˜f is nonnegative. Also suppose for ease of exposition that
θ(0) = 0.
We ﬁrst establish the assertion in (iii) when the condition in (a) holds for
all s′ with p(s′; ¯s, ¯e) > 0, so that { θ(k): k ≥0 } is a sequence of regeneration
points for the underlying chain. Write ˜Y 1( ˜f) = ˜Y +
1 ( ˜f) + ˜Y ′
1( ˜f), where
˜Y +
1 ( ˜f) =
θ(1)−1

n=θ(0)
˜f(Sn, Cn)1S(Sn)
and
˜Y ′
1( ˜f) =
θ(1)−1

n=θ(0)
˜f(Sn, Cn)1S′(Sn).
Because
Eµ
 ˜Y r
1( ˜f)

≤crEµ
 ˜Y +
1 ( ˜f)
r
+ crEµ
 ˜Y ′
1( ˜f)
r
for a ﬁnite constant cr depending only on r—see (1.12) in the Appendix
for a discussion of the “cr-inequality”—it suﬃces to show that ˜Y +
1 ( ˜f) and
˜Y ′
1( ˜f) each have ﬁnite moments of all orders.
We ﬁrst consider ˜Y +
1 ( ˜f). Recall from Remark 2.16 that the regener-
ation points { θ(k): k ≥0 } for the underlying chain induce a sequence
of regeneration points { θ+(k): k ≥0 } for the embedded chain, and set
˜τ +
1 = θ+(1) −θ+(0). Using the Cauchy–Schwarz inequality, we have
Eµ
 ˜Y +
1 ( ˜f)
r
= Eµ
θ+(1)−1

n=θ+(0)
˜f(S+
n , C+
n )
r
≤Eµ

(˜τ +
1 )r
max
θ+(0)≤n≤θ+(1)−1
˜f r(S+
n , C+
n )

≤E1/2
µ

(˜τ +
1 )2r
E1/2
µ

max
θ+(0)≤n≤θ+(1)−1
˜f 2r(S+
n , C+
n )

≤E1/2
µ

(˜τ +
1 )2r
E1/2
µ
 ˜Y +
1 ( ˜f 2r)

.
(2.33)
It therefore suﬃces to show that ˜τ +
1 has ﬁnite moments of all orders and
that Eµ
 ˜Y +
1 ( ˜f 2r)

< ∞. The ﬁniteness of the moments of ˜τ +
1 follows from
Lemma 2.32, since the regeneration points { θ+(k): k ≥0 } are also od-
equilibrium points. To show that ˜Y +
1 ( ˜f 2r) has ﬁnite mean, observe that the

214
6. Regenerative Simulation
function ˜f 2r is polynomially dominated, so that π+( ˜f 2r) < ∞by Corol-
lary 1.26 in Chapter 5—here π+ is the invariant probability measure of the
embedded chain. The ﬁniteness of Eµ
 ˜Y +
1 ( ˜f 2r)

then follows from the ratio
formula
π+( ˜f 2r) = Eµ
 ˜Y +
1 ( ˜f 2r)

Eµ

˜τ +
1

;
see Remark 1.33.
We now consider ˜Y ′
1( ˜f). Recall from (1.14) in Chapter 3 that { γ(n): n ≥
0 } are the indices of the successive marking changes at which the new
marking is timed—since θ(0) = 0 by assumption, we have θ+(0) = γ(0).
For k ≥0, denote by Uk the reward (as measured by ˜f) that the underlying
chain accumulates during the sojourn in the set Σ −Σ+ that ends at the
γ(k)th marking change:
Uk =
γ(k)−1

n=γ(k−1)+1
˜f(Sn, Cn).
Then ˜Y ′
1( ˜f) = 	˜τ +
1 −1
k=0 Uk. Because the function ˜f is polynomially domi-
nated by hypothesis, and hence bounded on Σ −Σ+,
˜Y ′
1( ˜f) ≤ψ
˜τ +
1 −1

k=0
Mk,
where ψ = sup(s,c)∈Σ−Σ+ ˜f(s, c) < ∞and Mk = γ(k) −γ(k −1) −1 is the
length of the kth sojourn in Σ −Σ+. Because ˜τ +
1 has ﬁnite moments of all
orders, it suﬃces to show that
Eµ
˜τ +
1 −1

k=0
M 2r
k

< ∞,
(2.34)
for then the ﬁniteness of Eµ
 ˜Y ′
1( ˜f)
r
follows by a computation analogous
to (2.33). To establish (2.34), deﬁne a vector Hk = (Hk,1, Hk,2, . . . , Hk,M)
that, in eﬀect, records for each transition e the most recent distribution
used to set the clock for e between the γ(k −1)st and γ(k)th marking
change. Speciﬁcally, set
Hk,i =

(Sξ(k,i); Sξ(k,i)−1, E∗
ξ(k,i)−1)
if ξ(k, i) > 0;
(∆, ∆, ∅)
if ξ(k, i) = 0
for 1 ≤i ≤M, where
ξ(k, i) = sup

γ(k −1) < j ≤γ(k): ei ∈N(Sj; Sj−1, E∗
j−1)


6.2 Regeneration and Stochastic Petri Nets
215
for 1 ≤i ≤M and n ≥1—set ξ(n, i) = 0 if the supremum is taken over an
empty set. Denote by H the state space of the process { Hn : n ≥1 }, and
ﬁx s′, s ∈S and h ∈H. It follows from (3.10) in Chapter 3 that there exist
constants a ∈(0, ∞) and ρ ∈[0, 1) such that
Pµ

Mk > n | Sγ(k−1) = s

≤aρn
for s ∈S. Thus
Pµ

Mk > n | Sγ(k−1) = s, Sγ(k) = s′, Hk = h

≤
Pµ

Mk > n | Sγ(k−1) = s

Pµ

Sγ(k) = s′, Hk = h | Sγ(k−1) = s

≤
aρn
u(s′, s, h),
where u(s′, s, h) = Pµ

Sγ(k) = s′, Hk = h | Sγ(k−1) = s

. (The function u
is well deﬁned because the latter probability does not depend explicitly
on k.) Set ¯u = mins′,s,h u(s′, s, h), where the minimum is taken over all
s′, s ∈S and h ∈H such that u(s′, s, h) is positive, and observe that ¯u > 0.
We then have
Pµ

Mk > n | Sγ(k−1) = s, Sγ(k) = s′, Hk = h

≤bρn,
where b = a/¯u < ∞. Fix q ≥1 and use a standard moment inequality—see
(1.16) in the Appendix—to obtain
Eµ

M q
k | Sγ(k−1) = s, Sγ(k) = s′, Hk = h

≤βq
for all s′, s ∈S and h ∈H, where βq = bq 	∞
n=0(n + 1)q−1ρn < ∞. Next,
set
G = { ˜τ +
1 , Sγ(0), Sγ(1), . . . , Sγ(˜τ +
1 ), H1, H2, . . . , H˜τ +
1 }
and observe that, given G, the random variables M0, M1, . . . , M˜τ +
1 −1 are
conditionally independent. Moreover, the distribution of each Mk depends
on G only through Sγ(k−1), Sγ(k), and Hk. It follows that
Eµ
˜τ +
1 −1

k=0
M q
k

= Eµ

Eµ
˜τ +
1 −1

k=0
M q
k
 G


= Eµ
˜τ +
1 −1

k=0
Eµ [M q
k | G]

= Eµ
˜τ +
1 −1

k=0
Eµ

M q
k | Sγ(k−1), Sγ(k), Hk


≤βqEµ

˜τ +
1


216
6. Regenerative Simulation
for q ≥1, which implies (2.34).
We now establish the assertion in (iii) when the condition in (b) holds
for at least one marking s′ such that p(s′; ¯s, ¯e) > 0. As discussed in Re-
mark 2.12, the random indices { θ(k): k ≥0 } do not, in general, form a
sequence of regeneration points—or even of od-equilibrium points—for the
underlying chain, so that the previous argument does not apply directly.
We can, however, argue as follows. By Lemma 2.32 there exists a sequence
of od-equilibrium points for the embedded chain; these points decompose
sample paths of the embedded chain into o.d.s. cycles. It is not hard to
see that these points also decompose sample paths of the underlying chain
into o.d.s. cycles, and hence induce a sequence of od-regeneration points
{ θ′(k): k ≥0 } for the underlying chain. Observe that
˜Y 1( ˜f) ≤
N

k=0
˜Zk( ˜f),
where N is the number of points of the sequence { θ′(k): k ≥0 } that lie
in the interval [0, θ(1)] and ˜Zk( ˜f) = 	θ′(k)−1
n=θ′(k−1) ˜f(Sn, Cn) for k ≥0. [We
take θ′(−1) = 0.] An argument almost identical to the ﬁrst part of the
proof shows that ˜Zk( ˜f) has ﬁnite moments of all orders. By a computation
analogous to (2.33), it then suﬃces to show that the random variable N
has ﬁnite moments of all orders. For k ≥0, set Ik = 1 if at least one
point of the sequence { θ(k): k ≥0 } lies in the interval [θ′(k −1), θ′(k)];
otherwise, set Ik = 0. Observe that I1, I2, . . . is an o.i.d. sequence, and set
p = Pµ { I1 = 0 }. Because each θ(k) is a.s. ﬁnite, it follows that p < 1—
otherwise, 	∞
k=0 Pµ { Ik = 1 } = 0, so that Pµ { Ik = 1 i.o. } = 0 by the ﬁrst
Borel–Cantelli lemma (Proposition 1.2 in the Appendix), which leads to a
contradiction. For k ≥1, we have
Pµ { N > k } ≤Pµ

I1 = 0, I3 = 0, . . . , Il(k) = 0

= Pµ { I1 = 0 } Pµ { I3 = 0 } · · · Pµ

Il(k) = 0

,
where l(k) = k −1 if k is even and l(k) = k if k is odd. It follows that
Pµ { N > k } ≤p⌊k/2⌋≤cρk
for k ≥2, where c = 1/p and ρ = p1/2. Because the distribution of N has
a geometrically decreasing right tail, N has moments of all orders.
To prove Theorem 2.31, use the positive Harris recurrence of the embed-
ded chain to show that Pµ { S+
n = s+ i.o. } = 1 for a timed marking s+ such
that s+ ; ¯s, where at least one path from s+ to ¯s has no intermediate
timed markings. Then use a geometric trials argument to show that ¯s is
recurrent. Now proceed as in the proof of Theorem 2.24.

6.2 Regeneration and Stochastic Petri Nets
217
6.2.3
SPNs Satisfying Geometric Trials Criteria
Theorems 2.36 and 2.44 below complement Theorems 2.24 and 2.31 and
are meant to be used in conjunction with the geometric trials technique
developed in Chapter 5. For a ﬁxed set of transitions ¯E ⊆E, set β(−1) =
−1 and
β(n) = inf

k > β(n −1): E∗(Sk, Ck) = ¯E

(2.35)
for n ≥0. According to this deﬁnition, Sβ(n) is the marking just before
the nth marking change at which the transitions in ¯E ﬁre simultaneously.
For a marking ¯s ∈G with ¯E ⊆E(¯s), deﬁne { θ(k): k ≥0 } as in (2.1)
to be the random indices of the successive marking changes at which the
marking is ¯s and the transitions in ¯E ﬁre simultaneously. Thus { θ(k): k ≥
0 } is a random subsequence of { β(n) + 1: n ≥0 }. Here we take β(0) =
−1 whenever θ(0) = 0—see Remark 2.8. Recall from Section 3.4.2 the
deﬁnition of { Fn : n ≥0 }, the increasing sequence of partial histories of
the underlying chain. Also deﬁne Y1(f) by (2.22).
Theorem 2.36. Let ¯s ∈G and ¯E ⊆E(¯s). Suppose that each random index
β(n) deﬁned in (2.35) is a.s. ﬁnite. Let { α(n): n ≥1 } be an increasing
sequence of random indices such that each α(n) is a stopping time with
respect to { Fk : k ≥0 } and β(n −1) ≤α(n) < β(n). Suppose that
Pµ

Sβ(n) = ¯s
 Fα(n)

> δ a.s.
for some δ > 0 and all n ≥0. Also suppose that for each s′ with p(s′; ¯s, ¯E) >
0 either
(a) O(s′; ¯s, ¯E) = ∅or
(b) O(s′; ¯s, ¯E) ̸= ∅and the clock for each transition ei ∈O(s′; ¯s, ¯E) is
always set according to an exponential distribution with ﬁxed intensity
v(ei).
Then the random times { ζθ(k) : k ≥0 } deﬁned via (2.1) form a sequence of
regeneration points for the marking process { X(t): t ≥0 }. Moreover, for
any bounded real-valued function f deﬁned on S, the cycle sum Y1(|f|) has
ﬁnite mean if
lim inf
n≥0 Eµ

ζβ(n+1)+1 −ζβ(n)+1

< ∞
and ﬁnite rth moment (r > 1) if
lim inf
n≥0 Eµ

(ζβ(n+1)+1 −ζβ(n)+1)r+ϵ
< ∞
(2.37)
for some ϵ > 0.
Proof. For ease of exposition, suppose that θ(0) = 0. By Lemma 2.4 in
Chapter 5, Pµ{ Sβ(n) = ¯s i.o. } = 1, so that each θ(k) is a.s. ﬁnite. The ﬁrst
assertion of the theorem then follows from Theorem 2.2.

218
6. Regenerative Simulation
To prove the remaining assertions, deﬁne a sequence of random indices
{ λ(k) : k ≥0 } by writing θ(k) = β

λ(k)

+ 1 for k ≥0. Thus the kth
regeneration point corresponds to the λ(k)th time that the transitions in ¯E
ﬁre simultaneously. Set ηk = λ(k)−λ(k−1) for k ≥1 and Dn = ζβ(n+1)+1−
ζβ(n)+1 for n ≥0. Observe that the random variables { ηk : k ≥1 } are i.i.d.
and, as shown in (3.7) in Chapter 3,
Pµ { η1 > k } ≤(1 −δ)k
for k ≥1, so that η1 has moments of all orders. It suﬃces to show that, for
r ≥1 and ϵ ≥0,
Eµ
!η1−1

n=0
Dr+ϵ
n
"
< ∞
(2.38)
whenever (2.37) holds. Indeed, taking r = 1 and ϵ = 0 in (2.38) shows that
the cycle length τ1 = ζθ(1) −ζθ(0) has ﬁnite mean; since f is bounded by
assumption, the second assertion of the theorem follows (cf. Remark 1.14).
If (2.37) holds for some r > 1 and ϵ > 0, then—using (2.38) and performing
a calculation analogous to (2.33) but based on H¨older’s inequality—we ﬁnd
that
Eµ [τ r
1 ] = Eµ
!)η1−1

n=0
Dn
*r"
≤Eµ

ηr
1 max
0≤n<η1 Dr
n

≤Eϵ/(r+ϵ)
µ
!
ηr(r+ϵ)/ϵ
1
"
Er/(r+ϵ)
µ
!
max
0≤n<η1 Dr+ϵ
n
"
≤Eϵ/(r+ϵ)
µ
!
ηr(r+ϵ)/ϵ
1
"
Er/(r+ϵ)
µ
!η1−1

n=0
Dr+ϵ
n
"
< ∞,
and the ﬁnal assertion of the theorem follows from the boundedness of f.
To establish (2.38), observe that the random indices { λ(k): k ≥0 } form
a sequence of regeneration points for the discrete-time process { Dn : n ≥
0 }. Moreover, η1 is aperiodic in discrete time. Thus, by Theorem 1.25(i),
there exists a nonnegative random variable D such that Dn ⇒D as n →
∞. Theorem 1.25(ii) then implies that Dr+ϵ
n
⇒Dr+ϵ. Using a version
of Fatou’s lemma for convergence in distribution (Proposition 1.48 in the
Appendix), we ﬁnd that
Eµ

Dr+ϵ
≤lim inf
n→∞Eµ

Dr+ϵ
n

< ∞,

6.2 Regeneration and Stochastic Petri Nets
219
where the last inequality is a restatement of (2.37). Thus
Eµ

Dr+ϵ
= Eµ
	η1−1
n=0 Dr+ϵ
n

Eµ[η1]
by Theorem 1.25(iii), and (2.38) follows.
The following result—and easily derived extensions of this result—can
be useful when verifying that (2.37) holds.
Lemma 2.39. Let ei ∈E −E′ and let β be an a.s. ﬁnite stopping time
with respect to the sequence { Fn : n ≥0 } of partial histories of the under-
lying chain. Suppose that ei is simple and that the clock-setting distribution
function F( · ; ei) is gnbu. Then Eµ[Cr
β,i] < ∞for r ≥0.
Proof. Fix r ≥1 and write Fi( · ) = F( · ; ei). By hypothesis, Fi is gnbu
with some lower bound x∗. Set γi(x) = supy≥0 F i(x + y)/F i(y) for x ≥0.
As in Section 3.4.2, deﬁne Zn,i to be the amount of time that has elapsed
on the clock for transition ei between the most recent clock-setting time
prior to ζn and time ζn itself. Using Lemma 4.10 in Chapter 5 and (1.13)
in the Appendix, we have
Eµ

Cr
β,i

= Eµ

Eµ

Cr
β,i
 Fβ

= Eµ
 ∞
0
rxr−1 F i(x + Zβ,i)
F i(Zβ,i)
dx

≤
 ∞
0
rxr−1γi(x) dx.
Fix x > x∗, so that γi(x) < 1. As in the proof of Lemma 2.12 in Chapter 5,
F i(kx + y) ≤γk
i (x)F i(y) for y ≥0 and k ∈{ 0, 1, 2, . . . }. It follows that
γi(kx) ≤γk
i (x) for each nonnegative integer k. We can now argue as in the
proof of Lemma 2.12 in Chapter 5 to show that
 ∞
0
rxr−1γi(x) dx =
∞

k=0
 (k+1)x
kx
ryr−1γi(y) dy
≤rxr
∞

k=0
(k + 1)r−1γk
i (x)
< ∞,
and the desired result follows.
Sometimes a discrete-time version of the condition in (2.37) is easier
to verify than (2.37) itself. In this connection the following result can be
useful.

220
6. Regenerative Simulation
Theorem 2.40. Suppose that the conditions of Theorem 2.36 hold. Also
suppose that the marking set G is ﬁnite and all speeds are positive. Then,
for any real-valued function f deﬁned on S, the cycle sum Y1(|f|) has ﬁnite
mean if each clock-setting distribution has ﬁnite mean and
lim inf
n≥0 Eµ

β(n + 1) −β(n)

< ∞,
(2.41)
and Y1(|f|) has ﬁnite rth moment (r > 1) if each clock-setting distribution
has ﬁnite rth moment and
lim inf
n≥0 Eµ

β(n + 1) −β(n)
r+ϵ
< ∞
(2.42)
for some ϵ > 0.
Proof. Fix r ≥1 and ϵ ≥0 such that ϵ > 0 if r > 1 and ϵ = 0 if r = 1.
For ease of exposition, suppose that each transition is simple and that all
speeds are equal to 1. As in the proof of Theorem 2.36, it suﬃces to show
that τ1 has ﬁnite rth moment. Observe that
τ1 ≤
M

i=1
Ni

k=1
Cη(i,k),i,
where Ni is the number of marking changes in the interval [ζθ(0), ζθ(1)) at
which the clock for transition ei is set and η(i, k) is the index of the kth
such marking change. An application of the cr-inequality shows that
Eµ [τ r
1 ] ≤M r−1
M

i=1
Eµ
) Ni

k=1
Cη(i,k),i
*r
,
and so it suﬃces to show that
Eµ
) Ni

k=1
Cη(i,k),i
*r
< ∞
for 1 ≤i ≤M. Fix i and observe that Ni ≤˜τ1 for 1 ≤i ≤M, where
˜τ1 = θ(1) −θ(0). An argument almost identical to the proof of Theo-
rem 2.36 shows that Eµ [˜τ r
1 ] < ∞, so that each Ni has ﬁnite rth moment.
Set Gk =

(S0, C0), (S1, C1), . . . , (Sη(i,k), Cη(i,k))

for k ≥1, and observe
that, for each k, the random variable Cη(i,k),i is determined by Gk and is
independent of Gk−1. Moreover, Ni + 1 is a stopping time with respect
to { Gk : k ≥1 }. Finally, it follows from Lemma 4.19 in Chapter 3 that
Cη(i,1),i, Cη(i,2),i, . . . are i.i.d. with common distribution function F( · ; ei).

6.2 Regeneration and Stochastic Petri Nets
221
Using Proposition 1.20 in the Appendix, we ﬁnd that
Eµ
) Ni

k=1
Cη(i,k),i
*r
≤Eµ
)Ni+1

k=1
Cη(i,k),i
*r
≤brEµ [(Ni + 1)r] Eµ

Cr
η(i,1),i

< ∞,
for some constant br < ∞, and the desired result follows.
Remark 2.43. The requirement in Theorem 2.40 that G be ﬁnite can be
replaced by the requirement that infs,e r(s, e) > 0 and that there be a
ﬁnite number of distinct clock-setting distribution functions for the timed
transitions. Then the conclusion of the theorem holds for any bounded
function f.
Theorem 2.44 gives conditions under which the underlying chain is a
regenerative process in discrete time. The proof is analogous to that of
Theorem 2.36.
Theorem 2.44. Let ¯s ∈G and ¯E ⊆E(¯s). Suppose that each random index
β(n) deﬁned in (2.35) is a.s. ﬁnite. Let { α(n): n ≥1 } be an increasing
sequence of random indices such that each α(n) is a stopping time with
respect to { Fk : k ≥0 } and β(n −1) ≤α(n) < β(n). Suppose that
Pµ

Sβ(n) = ¯s
 Fα(n)

> δ a.s.
for some δ > 0 and all n ≥0. Also suppose that O(s′; ¯s, ¯E) = ∅for all
s′ with p(s′; ¯s, ¯E) > 0. Then the random indices { θ(k): k ≥0 } deﬁned
via (2.1) form a sequence of regeneration points for the underlying chain
{ (Sn, Cn) : n ≥0 }. Moreover, for any bounded real-valued function ˜f
deﬁned on Σ, the cycle sum ˜Y 1(| ˜f|) has ﬁnite mean if
lim inf
n≥0 Eµ

β(n + 1) −β(n)

< ∞
and ﬁnite rth moment (r > 1) if
lim inf
n≥0 Eµ

β(n + 1) −β(n)
r+ϵ
< ∞
for some ϵ > 0.
The following result can be useful when verifying that (2.41) and (2.42)
hold or, equivalently, when verifying that the conditions of Theorem 2.44
hold—see Example 2.51 below.

222
6. Regenerative Simulation
Lemma 2.45. Let { Xn : n ≥1 } be a sequence of i.i.d. nonnegative ran-
dom variables and let Y be a nonnegative random variable independent of
{ Xn : n ≥1 }. Set N = inf { n ≥1 : X1 + · · · + Xn > Y }. Then for r ≥1
there exist ﬁnite constants ar and br (depending only on r) such that
E [N r] ≤arE [Y r] + br.
Proof. Fix r ≥1 and set N(t) = inf { n ≥1 : X1 + · · · + Xn > t } for
t ≥0. Pick α > 0 such that P { X1 ≥α } > 0 and set
¯Xn =

0
if Xn < α;
α
if Xn ≥α
for n ≥1. Deﬁne ¯N(t) analogously to N(t), but in terms of

 ¯Xn : n ≥0

.
Clearly, ¯Xn ≤Xn for each n, so that N(t) ≤¯N(t) for each t. Fixing t ≥0
and viewing each ¯Xn as the time (possibly 0) between a pair of successive
“events,” we see that ¯N(t) can be interpreted as the number of events
that occur in the interval [0, t], where an event always occurs at time 0.
By construction, events occur only at times 0, α, 2α, . . . and the number of
events that occur at each such time has a geometric distribution with mean
q = 1/P { X1 ≥α }. Thus ¯N(t) is distributed as 	l(t)
i=1 Gi, where l(t) =
⌊t/α + 1⌋and { Gi : i ≥1 } is a sequence of i.i.d. random variables having
a common geometric distribution with mean q. Using the cr-inequality, we
have
E [N r(t)] ≤E[ ¯N r(t)] = E
!) l(t)

i=1
Gi
*r"
≤lr−1(t)E
! l(t)

i=1
Gr
i
"
= lr(t)E [Gr
i ] .
Because lr(t) ≤2r−1(tr/αr + 1), we have
E [N r(t)] ≤artr + br,
where ar = 2r−1E [Gr
i ] /αr < ∞and br = 2r−1E [Gr
i ] < ∞—the ﬁniteness
of ar and br follows from the fact that geometric random variables have
ﬁnite moments of all orders. Thus
E [N r] = E [E [N r(Y ) | Y ]] ≤E [arY r + br] ,
and the desired result follows.
Example 2.46 (Producer–consumer system with nonpreemptive priority).
For the system of Example 2.1 in Chapter 2, suppose that the creation-
time random variables A1 and A2 are each distributed as Y + a, where
a is a positive constant and Y is an exponential random variable with
intensity q for some q > 0. Also suppose that the distribution of the
transmission-time random variable L1 has an essential supremum that ex-
ceeds max

(B1 −1)a, B2a

. Finally, suppose that the transmission-time

6.2 Regeneration and Stochastic Petri Nets
223
random variable L2 has a gnbu distribution. Consider the spn represen-
tation of the producer–consumer system given in Figure 2.4, and observe
that ¯s = (0, B1 −1, 1, 0, B2, 0, 0) is a single state with ¯e = e3 = “end
of transmission to consumer 1.” Recall that the marking is ¯s if and only
if there are B1 items in buﬀer 1—one of which is being transmitted to
consumer 1—and B2 items in buﬀer 2. As in Example 2.25 in Chapter 5,
denote by β(n)+1 the random index of the nth marking change (n ≥1) at
which transition e3 ﬁres and by α(n) the index of the nth marking change
at which transition e3 becomes enabled. It was shown in this example that
every α(n) and β(n) is a.s. ﬁnite and that Pµ

Sβ(n) = ¯s
 Fα(n)

> δ
for some δ > 0. It follows from Theorems 2.36 and 2.44 that the random
indices { θ(k): k ≥0 } deﬁned via (2.1) form a sequence of regeneration
points for the underlying chain and the random times { ζθ(k) : k ≥0 } form
a sequence of regeneration points for the marking process.
Fix n ≥0 and consider the time between the end of transmission to
consumer 1 at time ζβ(n)+1 and the next end of transmission to consumer 1.
If, at time ζβ(n)+1, buﬀer 1 contains at least one item awaiting transmission,
then immediate transition e2 ﬁres and another transmission to consumer 1
starts instantaneously, at the (β(n) + 2)nd marking change. If no items
are awaiting transmission, then there is a delay until producer 1 ﬁnishes
creating an item for transmission. At this point, there may be a further
delay if a transmission to consumer 2 is in progress. When transition e6
ﬁres—ending the latter transmission—transition e2 ﬁres and a transmission
to consumer 1 starts instantaneously. It follows that
ζβ(n+1)+1 −ζβ(n)+1 = 1A2∪A3Cβ(n)+1,1 + 1A3Cν(n),6
+ 1A1Cβ(n)+2,3 + 1A2Cν(n)+1,3 + 1A3Cλ(n)+1,3,
(2.47)
where ν(n) is the index of the ﬁrst marking change after β(n) + 1 at which
transition e1 = “creation of item by producer 1” ﬁres, λ(n) is the ﬁrst
marking change after ν(n) at which transition e6 = “end of transmission
to consumer 2” ﬁres, and the events A1, A2, and A3 are given by
A1 =

Sβ(n)+1,2 > 0

,
A2 =

Sβ(n)+1,2 = 0 and Sν(n),6 = 0

,
and
A3 =

Sβ(n)+1,2 = 0 and Sν(n),6 = 1

.
In (2.47), we take 1A3Cλ(n)+1,3 = 0 if λ(n) = ∞. Using Lemmas 4.10
and 4.19 in Chapter 3, it can be shown that the quantity 1A1Cβ(n)+2,3 +
1A2Cν(n)+1,3 + 1A3Cλ(n)+1,3 is distributed as an independent random sam-
ple from the distribution of L1. Because, as discussed in Example 2.25 in

224
6. Regenerative Simulation
Chapter 5, the distribution of A1 is gnbu, it follows from Lemma 2.39
that Cβ(n)+1,1 has ﬁnite moments of all orders. Similarly, Cν(n),6 has ﬁnite
moments of all orders. Thus if, for example, E

Lr+ϵ
1

< ∞for some r > 1
and ϵ > 0, then an application of the cr-inequality yields (2.37).
Example 2.48 (Manufacturing cell with robots). For the system of Exam-
ple 3.6 in Chapter 2, denote by R1 the (constant) time for robot 1 to return
to its null position after transfer of a part to conveyor 1. Similarly, denote
by R2 the (constant) time for robot 2 to return to its null position after
transfer of a part to machine 1. Suppose that the processing-time random
variable L2 has an exponential distribution with intensity q for some q > 0.
Also suppose that the distribution function of the processing-time random
variable L1 has an inﬁnite essential supremum. For the spn representation
of the manufacturing cell given in Figure 2.21, let ¯s be the unique marking
such that ¯s4 = ¯s9 = ¯s11 = ¯s22 = ¯s24 = 1 and ¯sj = 0 otherwise—the mark-
ing is ¯s if and only if machines 1 and 2 are each processing a part, a part is
on conveyor 1 awaiting transfer to a machine, no parts are on conveyor 2,
and each robot is in its null position. Recall that e8 = “end of processing
by machine 1,” and observe that ¯s and ¯E = { e8 } satisfy the condition in
(b) of Theorem 2.36. As in Example 2.34 in Chapter 5, denote by β(n) + 1
the random index of the nth marking change at which transition e8 ﬁres
and by α(n) the index of the nth marking change at which transition e8
becomes enabled. It was shown in this example that every α(n) and β(n)
is a.s. ﬁnite, and that Pµ

Sβ(n) = ¯s
 Fα(n)

> δ for some δ > 0. It follows
from Theorem 2.36 that the random times { ζθ(k) : k ≥0 } deﬁned via (2.1)
form a sequence of regeneration points for the marking process. Additional
conditions under which (2.37) holds can be obtained in a manner similar
to Example 2.46.
Example 2.49 (Telephone system).
For the system of Example 1.27 in
Chapter 5 with K links and N lines, suppose that K > 2 and N > 2K +2,
and that the call-length random variables L1, L2, L3, . . . , LN have a com-
mon distribution function H that is gnbu with lower bound x∗. Also sup-
pose that the waiting-time random variables A1, A2, . . . , AN are each dis-
tributed according to an exponential distribution function with intensity q
for some q > 0. Finally, suppose that x∗< ess sup H. For the spn represen-
tation of the telephone system given in Figure 5.5, denote by ¯G the set of
markings in which a call is connected on link 1 and all other links are idle.
Recall that e2,1 = “end of call connected on link 1,” and—as mentioned in
Example 2.30—the pair ( ¯G, { e2,1 }) satisﬁes the conditions in Remark 2.14.
As in Example 2.35 in Chapter 5, denote by β(n) + 1 the random index
of the nth marking change at which transition e2,1 ﬁres and by α(n) the
index of the nth marking change at which transition e2,1 becomes enabled.
It was shown in this example that every α(n) and β(n) is a.s. ﬁnite, and
that Pµ

Sβ(n) ∈¯G
 Fα(n)

> δ for some δ > 0. In light of Remark 2.14,

6.2 Regeneration and Stochastic Petri Nets
225
it can be seen that the random times { ζθ(k) : k ≥0 } deﬁned via (2.1) form
a sequence of regeneration points for the marking process.
Fix n ≥0 and consider the time between the end, at time ζβ(n)+1, of
the call connected on link 1 and the next end of a call connected on link 1.
This time has two components: the time D1(n) until the next call is placed
on link 1 and the time D2(n) until this call is completed. Suppose for
simplicity that a line is equally likely to place a call to any of the other
lines, and denote by In the number of idle lines at time ζβ(n)+1. Arguing as
in previous examples, we ﬁnd that D2(n) is distributed as D2, where D2 is
an independent sample from the distribution H; since H is gnbu, D2 has
ﬁnite moments of all orders. We can obtain upper bounds on the moments
of D1(n) by considering an artiﬁcial scenario in which the calls that are
connected at time ζβ(n)+1 (on links other than link 1) never end. In this
scenario, each of the N −In lines that are busy at time ζβ(n)+1 remains
busy forever and therefore can never place a call that is connected on link 1.
It follows that the random variable D1(n) is stochastically dominated—see
Deﬁnition 1.7 in the Appendix—by the time D′
1(n) until the next call is
placed on link 1 under the artiﬁcial scenario. Given In, the random variable
D′
1(n) is conditionally distributed as the sum of M exponential random
variables with intensity Inq, where M has a geometric distribution with
parameter Vn = (In −1)/N and corresponds to the number of busy calls
before the next successful call. This assertion follows from the memoryless
property of the exponential distribution (as in Corollary 4.17 in Chapter 3)
and other standard properties of the exponential distribution. An easy
argument using LaPlace–Stieltjes transforms—see Proposition 1.17 in the
Appendix—shows that D′
1(n) is exponentially distributed with intensity
VnInq. Observe that In ≥N −2(K −1) a.s., so that VnIn ≥l a.s., where
l = (N −2K+2)(N −2K+1)/N. It follows that D′
1(n)—and hence D1(n)—
is stochastically dominated by D1, where D1 is exponentially distributed
with intensity lq. Because D1 has moments of all orders, Proposition 1.15
in the Appendix implies that D1(n) has moments of all orders. Thus
Eµ

ζβ(n+1)+1 −ζβ(n)+1
v
≤E [(D1 + D2)v] ≤2v−1
E [Dv
1] + E [Dv
2]

for v ≥1, where the rightmost expression is ﬁnite, and it follows that, for
example, (2.37) holds for r > 1 and ϵ > 0.
Example 2.50 (Token ring).
For the system of Example 2.6 in Chap-
ter 2, suppose that the distribution function Fj of each interarrival-time
random variable Aj is nbu. Recall that Rj is the time for the ring token
to propagate from port j to the next port, and suppose that ess inf Fj <
RN for 1 ≤j ≤N. Consider the spn representation of the token ring
given in Figure 2.10, and observe that ¯s = (1, 0, 0, 0, . . . , 1, 0, 0, 0, 1, 0, 0,
1) is a single state with ¯e = e3,1 = “observation of ring token by port 1.”
The marking is ¯s if and only if all ports have a packet awaiting trans-
mission and the ring token is propagating from port N to port 1. As in

226
6. Regenerative Simulation
e1 = completion of service at center 1
e2 = completion of service at center 2
Figure 6.2. spn representation of cyclic queues with feedback (three jobs).
Example 2.17 in Chapter 5, denote by β(n) + 1 the random index of the
nth marking change at which transition e3,1 ﬁres and by α(n) the index
of the nth marking change at which transition e3,1 becomes enabled. It
was shown in this example that every α(n) and β(n) is a.s. ﬁnite and that
Pµ

Sβ(n) = ¯s
 Fα(n)

> δ for some δ > 0. It follows from Theorems 2.36
and 2.44 that the random indices { θ(k): k ≥0 } deﬁned via (2.1) form a
sequence of regeneration points for the underlying chain and the random
times { ζθ(k) : k ≥0 } form a sequence of regeneration points for the mark-
ing process.
We can use Theorem 2.36 to show that Y1(|f|) has ﬁnite moments. Specif-
ically, observe that
Eµ

(ζβ(n+1)+1 −ζβ(n)+1)r+ϵ
≤E
!) N

j=1
(Rj + Lj)
*r+ϵ"
for r, ϵ, n ≥0 where, as before, the successive times for port j to transmit
a packet are i.i.d. as Lj. If, for example, E[Lr+ϵ
j
] < ∞for each j and some
r > 1 and ϵ > 0, then an application of the cr-inequality yields (2.37).
A proof of this result based on Theorem 2.40 is perhaps even easier—as
shown in Example 2.17 in Chapter 5, β(n) −β(n + 1) ≤4N for n ≥0, so
that (2.42) holds for r, ϵ ≥0.
Example 2.51 (Cyclic queues with feedback).
Consider the closed net-
work of queues of Example 1.4 in Chapter 2, and suppose that successive
service times at center i (i = 1, 2) are i.i.d. as a positive random variable Li,
where the distribution of L1 is gnbu and the distribution of L2 is continu-
ous and has an inﬁnite essential supremum. This system can be represented
by an spn similar to that in Example 2.6 of Chapter 4; see Figure 6.2 for
N = 3 jobs. For this spn, p(s; s, e1) = 1−p and p

(s1 −1, s2 +1); s, e1

= p
for s = (s1, s2) ∈S.
The marking ¯s = (0, N) is a single state with E(¯s) = { e2 }. As in
Example 2.37 in Chapter 5, denote by β(n) + 1 the random index of the
nth marking change at which transition e2 ﬁres and by α(n) the random

6.2 Regeneration and Stochastic Petri Nets
227
index of the nth marking change at which e2 becomes enabled. It was
shown in this example that every α(n) and β(n) is a.s. ﬁnite, and that
Pµ

Sβ(n) = ¯s
 Fα(n)

> δ for some δ > 0. It follows from Theorems 2.36
and 2.44 that the random indices { θ(k): k ≥0 } deﬁned via (2.1) form a
sequence of regeneration points for the underlying chain and the random
times { ζθ(k) : k ≥0 } form a sequence of regeneration points for the marking
process.
We now consider moments of cycle sums—in particular, we give condi-
tions on the clock-setting distributions under which (2.37) holds. Observe
that the time between two successive service completions at center 2 is
the sum of two components: the time from the ﬁrst service completion at
center 2 to the next start of service at center 2, and the time from the
next start of service at center 2 to the second service completion at cen-
ter 2. The second component is simply a center 2 service time. The ﬁrst
component is equal to 0 if two or more jobs are at center 2 just before the
ﬁrst service completion at center 2. Otherwise, the ﬁrst component is equal
to the time from the ﬁrst service completion at center 2 to the next time
at which a job completes service at center 1 and moves to center 2; this
time interval equals the residual service time at center 1 (measured at the
time of the ﬁrst service completion at center 2) plus the sum of a random
number—possibly 0—of center 1 service times. It follows that
Eµ

(ζβ(n+1)+1 −ζβ(n)+1)r+ϵ
≤E
!)
An + Cβ(n)+1,1 +
M(n)

j=1
Bn,j
*r+ϵ"
for r, ϵ, n ≥0, where An is the ﬁrst new clock reading generated for tran-
sition e2 after time ζβ(n), Bn,j is the jth new clock reading generated
for transition e1 after time ζβ(n), and M(n) is the number—starting at
time ζβ(n)—of successive service completions at center 1 at which the job
completing service joins the tail of the queue at center 1. It follows from
Lemma 2.39 that Cβ(n)+1,1 has ﬁnite moments of all orders. Moreover, since
the common distribution of the i.i.d. sequence { Bn,j : j ≥1 } is gnbu—and
hence has ﬁnite moments of all orders—and since M(n) is independent of
the sequence { Bn,j : j ≥1 } and has a geometric distribution with ﬁnite
moments of all orders, it follows that the sum Bn,1 + Bn,2 + · · · + Bn,M(n)
has ﬁnite moments of all orders; see Remark 1.21 in the Appendix. If, for
instance, E[Lr+ϵ
2
] < ∞for some r > 1 and ϵ > 0, then an application of
the cr-inequality yields (2.37).
Similar arguments establish (2.42). Speciﬁcally, consider the number of
marking changes between two successive ﬁrings of transition e2—that is,
the number of events between two successive completions of service at cen-
ter 2. If no jobs are at center 2 just after the ﬁrst service completion,
then a random number M of jobs complete service at center 1 before a
job moves to center 2 and the next center 2 service begins. During this
center 2 service, N0 additional service completions occur at center 1 for

228
6. Regenerative Simulation
a total of M + N0 events between the two center 2 service completions.
If, on the other hand, one or more jobs are at center 2 just after the ﬁrst
service completion, then the total number of events is simply N0. As noted
above, M has a geometric distribution and hence has ﬁnite moments of all
orders. Moreover, N0 is stochastically dominated by the random variable
N = inf { n ≥1 : X1 + · · · + Xn > Y }, where each Xi is an independent
sample from the distribution of L1 and Y is an independent sample from
the distribution of L2. If, for example, E

Lr+ϵ
2

< ∞for some r > 1 and
ϵ > 0, then E [N r+ϵ] < ∞by Lemma 2.45, and an application of the
cr-inequality yields (2.42).
6.2.4
The Regenerative Variance Constant
Suppose that there exists a sequence { ζθ(k) : k ≥0 } of regeneration points
for the marking process of an spn with Eµ [τ1] < ∞, where τ1 = ζθ(1)−ζθ(0)
as usual. Deﬁne Yk( · ) by (2.22) and let f be a function deﬁned on S
with Y0(|f|) < ∞a.s. and Eµ [Y1(|f|)] < ∞. Then, by Theorem 1.12,
limt→∞(1/t)
 t
0 f

X(u)

du = r(f) with r(f) = Eµ [Y1(f)] /Eµ [τ1]. As dis-
cussed in the next section, the “regenerative variance constant”
σ2(f) = Varµ [Y1(f) −r(f)τ1]
must be positive and ﬁnite for the regenerative method to be applicable.
Similarly, the regenerative variance constant
˜σ2( ˜f) = Varµ [ ˜Y 1( ˜f) −˜r( ˜f)˜τ1]
(2.52)
must be positive and ﬁnite for the regenerative method to be applicable to
the underlying chain of an spn—here ˜r( ˜f) = Eµ[ ˜Y 1( ˜f)]/Eµ[˜τ1] with ˜Y 1( ˜f)
given by (2.23) and ˜τ1 given by θ(1) −θ(0).
The variance constant σ2(f) is well deﬁned and ﬁnite whenever Eµ[τ 2
1 ]
and Eµ

Y 2
1 (|f|)

are both ﬁnite, and similarly for ˜σ2( ˜f). To see that the
ﬁrst assertion holds, observe that Eµ

Y 2
1 (f)

< ∞, Eµ [Y1(|f|)] < ∞, and
r(|f|) < ∞whenever Eµ

Y 2
1 (|f|)

< ∞. Because Eµ [Y1(f) −r(f)τ1] = 0,
it then follows from the Cauchy–Schwarz inequality that
σ2(f) = Eµ

Y1(f) −r(f)τ1
2
≤Eµ[Y 2
1 (f)] + 2r(|f|)Eµ[ |Y1(f)τ1| ] + Eµ[τ 2
1 ]
≤Eµ[Y 2
1 (f)] + 2r(|f|)E1/2
µ
[Y 2
1 (f)]E1/2
µ
[τ 2
1 ] + Eµ[τ 2
1 ]
< ∞
as asserted. By Remark 1.14, σ2(f) < ∞whenever Eµ[τ 2
1 ] < ∞and either
f is bounded or the state space S is ﬁnite. Analogous observations hold
for ˜σ2( ˜f). Thus the results in the previous subsections can be used to

6.2 Regeneration and Stochastic Petri Nets
229
establish ﬁniteness of the regenerative variance constant. For example, it
follows that if the spn has a single state and Assumption PD holds, then
σ2(f) < ∞for any real-valued function f deﬁned on S and ˜σ2( ˜f) < ∞for
any polynomially dominated function ˜f deﬁned on Σ.
In practice, the regenerative variance constant is virtually always pos-
itive. For example, we have the following result, which shows that under
mild conditions, σ2(f) is positive when Assumption PD holds.
Theorem 2.53. Suppose that the conditions of Theorem 2.24 hold for
some marking ¯s and transition ¯e, so that the random indices

ζθ(k) : k ≥0

deﬁned via (2.1) with ¯E = { ¯e } form a sequence of regeneration points for
the marking process. Then σ2(f) > 0 for any real-valued function f deﬁned
on S such that f(s) ̸= f(s′) for some s, s′ ∈S.
Proof. (Sketch) It suﬃces to show that Y1(f)/τ1 is not a.s. equal to a
constant. For ease of exposition, suppose that all speeds are equal to 1,
that each transition is simple, and that θ(0) = 0. Under the hypotheses of
the theorem, there exists ¯x > 0 such that the clock-setting distribution for
each timed transition e ∈E −E′ can be written in the form
F( · ; e) = peF1( · ; e) + (1 −pe)F2( · ; e),
where pe ∈(0, 1], both F1 and F2 are proper distribution functions, and F1
is absolutely continuous with density function f1 positive and continuous
on (0, ¯x). We can modify the usual construction of the marking process
slightly so that each new clock reading for a timed transition e is generated
in two steps. First a Bernoulli random variable X is generated such that
P { X = 1 } = 1 −P { X = 0 } = pe. If X = 1, then the clock reading is
generated as an independent sample from F1; otherwise, the clock reading is
generated as an independent sample from F2. Let { In : n ≥0 } be indicator
random variables such that In = 1 if, at the nth marking change, the clock
reading for each new timed transition e is generated as a sample from
F1( · ; e); otherwise, In = 0. If there are no new timed transitions at the
nth marking change, then In = 1 by convention.
Fix k ≥1, ˜s0, ˜s1, . . . ˜sk−1 ∈G −{ ¯s }, and ˜e0, ˜e1, . . . , ˜ek−1 ∈E such that
p(˜s0; ¯s, ¯e)p(˜s1; ˜s0, ˜e0) · · · p(˜sk−1; ˜sk−2, ˜ek−2)p(¯s; ˜sk−1, ˜ek−1) > 0
and f(˜si) ̸= f(˜sj) for some 0 ≤i, j ≤k. Such a selection is possible because
of the assumed irreducibility of the spn. Consider the event A given by
A =

Sk = ¯s, Sj = ˜sj for 0 ≤j < k, Cj ≤¯x for 0 ≤j ≤k,
Ij = 1 for 0 ≤j ≤k, and E∗(Sj, Cj) = { ˜ej } for 0 ≤j < k

.
An inductive argument on k shows that Pµ { A } > 0. It therefore suﬃces
to show that, for an arbitrary ﬁxed constant c, Pµ { Y1(f)/τ1 = c; A } = 0,
because then
Pµ { Y1(f)/τ1 = c } = Pµ { Y1(f)/τ1 = c; Σ −A } ≤Pµ { Σ −A } < 1.

230
6. Regenerative Simulation
To this end, set E∗
n = E∗(Sn, Cn) and t∗
n = t∗(Sn, Cn) for n ≥0. Us-
ing Lemma 4.10 in Chapter 3 and an inductive argument on k, it can be
shown that the joint cumulative distribution function F(x0, x1, . . . , xk) =
Pµ { t∗
0 ≤x0, t∗
1 ≤x1, . . . , t∗
k ≤xk } is absolutely continuous on (0, ¯x)k, con-
ditional on the event A. Observe that Y1(f, ω)/τ1(ω) = c for ω ∈A if and
only if 	k
j=0 cjt∗
j(ω) = 0, where cj = f(˜sj) −c. Because f(˜si) ̸= f(˜sj)
for some 0 ≤i, j ≤k by assumption, it follows that (c0, c1, . . . , ck) ̸=
(0, 0, . . . , 0), and hence the set
B =

(t0, t1, . . . , tk) ∈(0, ¯x)k : c0t0 + c1t1 + · · · + cktk = 0

is a strict linear subspace of (0, ¯x)k. Thus the event { (t∗
0, t∗
1, . . . , t∗
k) ∈B; A }
has Pµ-probability equal to 0, so that Pµ { Y1(f)/τ1 = c; A } = 0.
In the discrete-time setting, the quantity ˜σ2( ˜f) is almost always posi-
tive in applications for which ˜f is nonconstant and takes values in a ﬁ-
nite set. Typically, the degenerate situations in which ˜σ2( ˜f) = 0 can be
detected a priori and the associated estimation problem is trivial. For ex-
ample, consider the machine repair model of Example 2.28. Suppose we
wish to estimate ˜r( ˜f) = limn→∞(1/n) 	n−1
j=0 ˜f(Sj, Cj), where ˜f(s, c) = 1
if E∗(s, c) ⊂{ e1,1, e1,2, . . . , e1,N } and ˜f(s, c) = 0 otherwise. Observe that
with probability 1 two machines never stop simultaneously and that the
number of repairs in a regenerative cycle is always equal to the number
of stoppages. Associated with each stoppage and subsequent repair of ma-
chine j (1 ≤j ≤N) are three transition ﬁrings: transitions e1,j, e2,j, and
e3 each ﬁre once. It follows that ˜Y 1( ˜f) = ˜τ1/3 with probability 1. Thus
˜r( ˜f) = 1/3, ˜σ2( ˜f) = Varµ [ ˜Y 1( ˜f) −˜r( ˜f)˜τ1] = 0, and the estimation prob-
lem is trivial. As another example, suppose that the marking set G can
be partitioned into d disjoint subsets G1, G2, . . . , Gd such that s′ ∈Gi+1
whenever s ∈Gi and s →s′. (Take Gi+1 = G1 when i = d.) Consider
a function ˜f such that ˜f(s, c) = ˜f(s′, c′) whenever s, s′ ∈Gi for some
1 ≤i ≤d. Set v = 	d
i=1 ˜f(si), where si ∈Gi for 1 ≤i ≤d. Then there
exists a positive integer-valued random variable K1 such that ˜Y 1( ˜f) = K1v
and ˜τ1 = K1d, so that ˜r( ˜f) = v/d and ˜σ2( ˜f) = 0. Again, the estimation
problem is trivial.
6.3
The Regenerative Method
The results in Section 6.2 give conditions under which the marking process
or underlying chain of an spn is a regenerative process and integrals or sums
over a regenerative cycle have ﬁnite moments. In this section we examine
the implications of such regenerative structure for the analysis of simulation
output.

6.3 The Regenerative Method
231
6.3.1
The Standard Method
We ﬁrst describe the simplest version of the regenerative method as applied
to the marking process and underlying chain of an spn. Extensions to this
“standard regenerative method” are given in the following subsections.
Regenerative Simulation of the Marking Process
Let { X(t): t ≥0 } be the marking process of an spn. Suppose that we
have identiﬁed a sequence { Tk : k ≥0 } of regeneration points and wish
to estimate a time-average limit of the form limt→∞(1/t)
 t
0 f

X(u)

du,
where f is a real-valued function deﬁned on S. The regenerative method for
analysis of simulation output provides strongly consistent point estimates
and asymptotic conﬁdence intervals for time-average limits. For ease of
exposition, we assume throughout that T0 = 0, so that { X(t): t ≥0 } is a
nondelayed regenerative process.
Set τk = Tk −Tk−1 for k ≥1 as in Section 6.1, so that τk is the length
of the kth cycle. Also set
Yk(f) =
 Tk
Tk−1
f

X(u)

du
for k ≥1. Typically, each regeneration point coincides with a marking
change, so that Tk = ζθ(k) for k ≥0, where { θ(k): k ≥0 } is a sequence of
a.s. ﬁnite random indices. We can then write
Yk(f) =
θ(k)−1

n=θ(k−1)
f(Sn)t∗(Sn, Cn),
where { (Sn, Cn): n ≥0 } is the underlying chain. Recall from Section 6.1
that the sequence

 
Yk(f), τk

: k ≥1

consists of i.i.d. random pairs. Sup-
pose that Eµ[τ1] < ∞and Eµ[Y1(|f|)] < ∞; Section 6.2 gives conditions
on the building blocks of an spn under which the quantities τ1 and Y1(|f|)
have ﬁnite moments. It then follows from Theorem 1.12 that
r(f) = Eµ [Y1(f)]
Eµ [τ1]
(3.1)
is well deﬁned and ﬁnite, and
lim
t→∞
1
t
 t
0
f

X(u)

du = r(f) a.s..
If, in addition, τ1 is aperiodic, then there exists a random variable X—
independent of the initial distribution µ—such that X(t) ⇒X as t →∞
and r(f) = E [f(X)]. That is, the time-average limit r(f) can also be
interpreted as a steady-state mean.

232
6. Regenerative Simulation
To estimate r(f), observe a ﬁxed number n of cycles of { X(t): t ≥0 }
and measure the quantities Y1(f), Y2(f), . . . , Yn(f) and τ1, τ2, . . . , τn. Set
ˆr(n) =
¯Y (n)
¯τ(n) ,
where
¯Y (n) = 1
n
n

k=1
Yk(f)
and
¯τ(n) = 1
n
n

k=1
τk.
Writing
ˆr(n) =
¯Y (n)/n
¯τ(n)/n
and applying the strong law of large numbers (slln) for i.i.d. random
variables to both numerator and denominator, we see that
lim
n→∞ˆr(n) = r(f) a.s..
Thus ˆr(n) is strongly consistent for r(f).
We now consider the problem of obtaining an asymptotic conﬁdence
interval for r(f). Set
σ2(f) = Varµ [Y1(f) −r(f)τ1]
= Varµ [Y1(f)] −2r(f)Covµ [Y1(f), τ1] + r2(f)Varµ [τ1] .
(3.2)
The quantity σ2(f) is the regenerative variance constant discussed in Sec-
tion 6.2.4. As shown below, the i.i.d. cycle structure of the marking process
implies that, for large n, the distribution of the estimator ˆr(n) is approx-
imately normal with mean r(f) and variance σ2(f)/[n¯τ 2(n)]. This result
cannot be used directly to obtain a conﬁdence interval since σ2(f) is un-
known. From n cycles, however, a natural estimator of σ2(f) is given by
s2(n) = s11(n) −2ˆr(n)s12(n) + ˆr2(n)s22(n),
(3.3)
where
s11(n) =
1
n −1
n

k=1

Yk(f) −¯Y (n)
2,
s22(n) =
1
n −1
n

k=1

τk −¯τ(n)
2,

6.3 The Regenerative Method
233
and
s12(n) =
1
n −1
n

k=1

Yk(f) −¯Y (n)

τk −¯τ(n)

.
The quantities s11(n), s22(n), and s12(n) are the usual unbiased estimators
of Varµ [Y1(f)], Covµ [Y1(f)τ1], and Varµ [τ1]. Estimation of σ2(f) by s2(n)
leads to the desired interval. More precisely, we have the following result.
Theorem 3.4. Suppose that Eµ[τ 2
1 ] < ∞, Eµ[Y 2
1 (|f|)] < ∞, and σ2(f) >
0. Then
lim
n→∞s2(n) = σ2(f) a.s.
and
√n

ˆr(n) −r(f)

s(n)/¯τ(n)
⇒N(0, 1)
as n →∞, where N(0, 1) is a standard (mean 0, variance 1) normal ran-
dom variable.
Proof. Write
s11(n) =
1
n −1
n

k=1
Y 2
k (f) −
n
n −1
¯Y 2(n)
for n ≥1. Applying the slln for i.i.d. random variables to each of the
two terms on the right, we see that limn→∞s11(n) = Varµ [Y1(f)] a.s..
Similar observations apply to s22(n) and s12(n), and the ﬁrst assertion of
the theorem follows. Next, set Zk(f) = Yk(f)−r(f)τk for k ≥1 and observe
that the sequence { Zk(f): k ≥0 } consists of i.i.d. random variables with
common mean 0 and common variance σ2(f). As discussed in Section 6.2.4,
we have 0 < σ2(f) < ∞under the assumptions of the theorem. It then
follows from the central limit theorem (clt) for i.i.d. random variables that
n1/2 ¯Z(n)/σ(f) ⇒N(0, 1) as n →∞, where ¯Z(n) = (1/n) 	n
k=1 Zk(f).
After some simple algebra, we ﬁnd that
√n

ˆr(n) −r(f)

σ(f)/¯τ(n)
⇒N(0, 1)
as n →∞. Because limn→∞s2(n) = σ2(f) a.s., it follows that s(n) ⇒σ(f)
as n →∞, and the second assertion of the theorem follows from Slutsky’s
theorem (Proposition 1.43 in the Appendix).

234
6. Regenerative Simulation
Fix p ∈(0, 1) and let zp be the unique nonnegative real number such
that P { −zp ≤N(0, 1) ≤zp } = p. Then
lim
n→∞Pµ

ˆr(n) −zp s(n)
¯τ(n)√n ≤r(f) ≤ˆr(n) + zp s(n)
¯τ(n)√n

= lim
n→∞Pµ

−zp ≤
√n

ˆr(n) −r(f)

s(n)/¯τ(n)
≤zp

= p.
Thus the random interval with endpoints ˆr(n)±zp s(n)/

¯τ(n)√n

contains
the unknown constant r(f) approximately 100p% of the time when n is
large.
Based on the above discussion, we obtain the following estimation pro-
cedure.
Algorithm 3.5 (Regenerative method for the marking process)
1. Select a sequence { Tk : k ≥0 } of regeneration points for the process
{ X(t): t ≥0 }.
2. Simulate the process { X(t): t ≥0 } and observe a ﬁxed number n of
cycles deﬁned by the random times { Tk : k ≥0 }.
3. Compute the length τk of the kth cycle and the quantity Yk(f) =
 Tk
Tk−1 f

X(u)

du for 1 ≤k ≤n.
4. Form the strongly consistent point estimate ˆr(n) = ¯Y (n)/¯τ(n) for
r(f).
5. Form the asymptotic 100p% conﬁdence interval
!
ˆr(n) −zp s(n)
¯τ(n) √n, ˆr(n) + zp s(n)
¯τ(n) √n
"
(3.6)
for r(f), where s(n) is deﬁned as in (3.3).
Remark 3.7. Observe that zp = Φ−1
(1+p)/2

, where Φ is the distribution
function of N(0, 1).
Remark 3.8.
It is often desirable to compute the conﬁdence interval for
r(f) by means of a single pass through the data. If sample path observa-
tions have been generated previously and stored on disk, then the use of a
single-pass algorithm can substantially reduce the I/O and computational
costs of producing the interval estimate. If sample path observations are
being generated on the ﬂy, then the use of such an algorithm avoids the
need to store the observations. Clearly, the quantities ¯Y (n) and ¯τ(n) can
easily be computed in one pass. Computation of the variance estimator

6.3 The Regenerative Method
235
s2(n)—that is, computation of s11(n), s22(n), and s12(n)—is trickier. For
example, computing s11(n) in a single pass by using the representation
(n −1)s11(n) = 	n
k=1 Y 2
k (f) −n ¯Y 2(n) can lead to numerical instability.
An alternative approach is to set w11(1) = w22(1) = w12(1) = 0 and then
recursively set
w11(k) = w11(k −1) + D1(k)
k
D1(k)
k −1 ,
w22(k) = w22(k −1) + D2(k)
k
D2(k)
k −1 ,
and
w12(k) = w12(k −1) + D1(k)
k
D2(k)
k −1
for k ≥2, where
D1(k) =
k−1

j=1
Yj(f) −(k −1) Yk(f)
and
D2(k) =
k−1

j=1
τj −(k −1) τk.
Then s11(n) = w11(n)/(n −1), s22(n) = w22(n)/(n −1), and s12(n) =
w12(n)/(n −1). Finally, compute s2(n) as in (3.3). The recursions for w11
and w22 are each numerically stable, because Di(k) (i = 1, 2) is computed
as the diﬀerence between two numbers of similar (and moderate) magni-
tude and the term that is added to wii(n −1) to produce wii(n) is always
nonnegative. The main deﬁciency in this method arises from possible can-
cellation or roundoﬀerrors in the calculation of w12(n)—unlike w11(n) and
w22(n), the term that is added to w12(n −1) to produce w12(n) need not
always be nonnegative. In practice, however, the method usually produces
acceptable results, provided that calculations are performed using double-
precision arithmetic.
Regenerative Simulation of the Underlying Chain
The regenerative method for the underlying chain is similar to the re-
generative method for the marking process. Suppose that there exists a
sequence { θ(k): k ≥0 } of regeneration points for { (Sn, Cn): n ≥0 } and
that we wish to estimate a time-average limit limn→∞(1/n) 	n−1
j=0 ˜f(Sj, Cj)
for some real-valued function ˜f deﬁned on Σ.

236
6. Regenerative Simulation
Set ˜τk = θ(k) −θ(k −1) and
˜Y k( ˜f) =
θ(k)−1

n=θ(k−1)
˜f(Sn, Cn)
(3.9)
for k ≥1; the sequence

  ˜Y k( ˜f), ˜τk

: k ≥1

consists of i.i.d. random
pairs. Suppose that Eµ[˜τ1] < ∞and Eµ[ ˜Y 1(| ˜f|)] < ∞, so that
˜r( ˜f) = Eµ [ ˜Y 1( ˜f)]
Eµ [˜τ1]
is well deﬁned and ﬁnite, and
lim
n→∞
1
n
n−1

j=0
˜f(Sj, Cj) = ˜r( ˜f) a.s..
(3.10)
If, in addition, ˜τ1 is aperiodic in discrete time, then ˜r( ˜f) can also be inter-
preted as a steady-state mean.
To estimate ˜r( ˜f), observe a ﬁxed number n of cycles of { (Sn, Cn): n ≥0 }
and measure the quantities ˜Y 1( ˜f), ˜Y 2( ˜f), . . . , ˜Y n( ˜f) and ˜τ1, ˜τ2, . . . , ˜τn. Set
ˆr(n) =
¯Y (n)
¯τ(n) ,
where
¯Y (n) = 1
n
n

k=1
˜Y k( ˜f)
and
¯τ(n) = 1
n
n

k=1
˜τk.
(3.11)
As in the regenerative method for the marking process, ˆr(n) is strongly
consistent for ˜r( ˜f).
To obtain an asymptotic conﬁdence interval for ˜r( ˜f), set
˜σ2( ˜f) = Varµ [ ˜Y 1( ˜f) −˜r( ˜f)˜τ1]
(3.12)
and
s2(n) = ˜s11(n) −2ˆr(n)˜s12(n) + ˆr2(n)˜s22(n),
(3.13)
where
˜s11(n) =
1
n −1
n

k=1
 ˜Y k( ˜f) −¯Y (n)
2,
˜s22(n) =
1
n −1
n

k=1

˜τk −¯τ(n)
2,

6.3 The Regenerative Method
237
and
˜s12(n) =
1
n −1
n

k=1
 ˜Y k( ˜f) −¯Y (n)

˜τk −¯τ(n)

.
Provided that Eµ[˜τ 2
1 ] < ∞, Eµ[ ˜Y 2
1(| ˜f|)] < ∞, and ˜σ2( ˜f) > 0, we have
lim
n→∞s2(n) = ˜σ2( ˜f) a.s.
and
√n

ˆr(n) −˜r( ˜f)

s(n)/¯τ(n)
⇒N(0, 1).
As before, the above clt leads to a procedure for obtaining an asymptotic
conﬁdence interval.
Algorithm 3.14 (Regenerative method for the underlying chain)
1. Select a sequence { θ(k): k ≥0 } of regeneration points for the process
{ (Sn, Cn): n ≥0 }.
2. Simulate the process { (Sn, Cn): n ≥0 } and observe a ﬁxed number
n of cycles deﬁned by the random indices { θ(k): k ≥0 }.
3. Compute the length ˜τk of the kth cycle and the quantity ˜Y k( ˜f) =
	θ(k)−1
n=θ(k−1) ˜f(Sn, Cn) for 1 ≤k ≤n.
4. Form the strongly consistent point estimate ˆr(n) = ¯Y (n)/¯τ(n) for
˜r( ˜f).
5. Form the asymptotic 100p% conﬁdence interval
!
ˆr(n) −zp s(n)
¯τ(n) √n, ˆr(n) + zp s(n)
¯τ(n) √n
"
for ˜r( ˜f), where s(n) is deﬁned as in (3.13) and zp is the (1 + p)/2
quantile of the standard normal distribution.
Although a comprehensive treatment of the regenerative method is be-
yond the scope of the current discussion, we outline some key issues and
important extensions in the following subsections. For convenience, we of-
ten restrict the discussion to either simulation of the marking process or
simulation of the underlying chain; unless otherwise indicated, results ob-
tained in the one setting carry over with obvious modiﬁcations to the other.

238
6. Regenerative Simulation
6.3.2
Bias of the Point Estimator
Suppose that we wish to estimate the quantity r(f) = Eµ [Y1(f)] /Eµ [τ1]
for a speciﬁed function f, based on simulation of the marking process.
Although the estimators ¯Y (n) and ¯τ(n) are unbiased for Eµ [Y1(f)] and
Eµ [τ1], it does not follow that the ratio ˆr(n) = ¯Y (n)/¯τ(n) is unbiased for
r(f). Indeed, the following result can be established.
Proposition 3.15. Suppose that sups∈S |f(s)| < ∞and Eµ[τ 4
1 ] < ∞.
Then
Eµ [ˆr(n)] = r(f) −Eµ

Y1(f) −r(f)τ1

τ1

nE2µ [τ1]
+ o(n−1).
(3.16)
Proposition 3.15 asserts that ˆr(n) is biased for r(f), with the bias decreasing
at rate n−1 as n →∞. Recall that the mean-squared error of the estimator
ˆr(n) is deﬁned by
MSEµ [ˆr(n)] = Eµ

ˆr(n) −r(f)
2
= Varµ [ˆr(n)] + Bias2
µ [ˆr(n)] .
Under suitable regularity conditions, it can be shown that the variance
of ˆr(n) converges to 0 at rate n−1, so that MSEµ [ˆr(n)] = O(n−1) and
the mean-squared error is dominated by the variance as n becomes large.
Several alternative estimators for r(f) have been proposed that attempt to
reduce the bias when n is small. If we estimate the bias term in (3.16) and
subtract this estimate from ˆr(n), we obtain the Tin estimator:
ˆr1(n) = ˆr(n) + 1
n2
n

k=1

Yk(f) −ˆr(n)τk

τk
¯τ 2(n)
.
Jackkniﬁng is another well-known technique for reducing the bias of an
estimator. In the current setting, the jackknife estimator of r(f) is
ˆr2(n) = nˆr(n) −n −1
n
n

k=1
ψk,
where
ψk =
	
i̸=k Yi(f)
	
i̸=k τi
.
Both ˆr1(n) and ˆr2(n) typically have a bias of O(n−2).
Set
s2
i (n) =
1
n −1
n

k=1

Yk(f) −ˆri(n)τk
2
¯τ 2(n)
for i = 1, 2. Also set ˆr0(n) = ˆr(n) and s0(n) = s(n); thus ˆr0(n) and s0(n)
are the standard estimators of r(f) and σ2(f). As usual, let zp be the

6.3 The Regenerative Method
239
Table 6.1. Simulation Results for Token Ring with Fixed-Sized Packets: Point
Estimates and 95% Conﬁdence-Interval Half-Widths for the Long-Run Utilization
(True Value = 0.4462)
Number of Cycles Simulated
Estimator
2
10
50
100
1000
5000
standard
0.3333
0.4167
0.4209
0.4299
0.4419
0.4457
±0.2904
±0.1349
±0.0584
±0.0377
±0.0127
±0.0057
Tin
0.3745
0.4362
0.4252
0.4317
0.4421
0.4457
±0.2585
±0.1236
±0.0571
±0.0374
±0.0127
±0.0057
jackknife
0.4524
0.4430
0.4255
0.4317
0.4421
0.4457
±0.2833
±0.1200
±0.0570
±0.0374
±0.0127
±0.0057
(1+p)/2 quantile of the standard normal distribution. Under the conditions
of Theorem 3.4, it can be shown that ˆr1(n) and ˆr2(n) are each strongly
consistent for r(f), and
!
ˆri(n) −zp sj(n)
√n
, ˆri(n) + zp sj(n)
√n
"
is an asymptotic 100p% conﬁdence interval for i, j = 0, 1, 2.
Example 3.17 (Token ring with ﬁxed-sized packets).
We illustrate the
various estimators discussed so far in the context of a computer network
similar to that in Example 2.6 of Chapter 2 with N = 4 ports. The key
diﬀerence from the original example is that, for each port, the time to
transmit a packet is a deterministic constant L. Also, for each port, the time
for the ring token to propagate to the next port is a deterministic constant
R, and the successive times from end of transmission until the arrival of the
next packet for transmission are i.i.d. as an exponential random variable
with intensity q.
Suppose that this system is modelled by an spn as in Figure 2.10 of
Chapter 2 and consider the successive times { Tn : n ≥0 } at which the
marking is ¯s = (0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1)—so that each port has
a packet awaiting transmission—and transition e3,1 = “observation of ring
token by port 1” ﬁres. Using Lemma 4.19 in Chapter 3, an ad-hoc recur-
rence argument similar to those in Examples 2.34 and 2.38 in Chapter 5
shows that each Tn is a.s. ﬁnite. An application of Theorem 2.2 then shows
that the random times { Tn : n ≥0 } form a sequence of regeneration points
for the marking process. Moreover, it follows from Theorem 2.40 that the
regenerative cycle length τ1 has ﬁnite moments of all orders.
We therefore can use the regenerative method to estimate the long-run
utilization r(f) = limt→∞(1/t)
 t
0 f

X(u)

du, where f(s) = 1 if a trans-
mission is underway when the marking is s and f(s) = 0 otherwise. For-
mally, f(s) = max1≤j≤4 s3,j for s = (s1,1, s1,2, . . . , s4,4) ∈G. It is not hard
to see that the cycle length τ1 is aperiodic, so that—by Theorem 1.20—

240
6. Regenerative Simulation
the quantity r(f) can also be interpreted as the steady-state or limiting
probability that a transmission is underway.
Table 6.1 displays point estimates and 95% conﬁdence intervals for r(f)
based on the standard, Tin, and jackknife estimators; results are reported
for varying simulation run lengths. The parameter values used in the sim-
ulation are L = 0.15, R = 0.05, and q = 1.0. For each simulation, the Tin
and jackknife point estimators are closer to the true value than the stan-
dard estimator, with the jackknife estimator slightly outperforming the Tin
estimator. The diﬀerences between the point estimators become negligible,
however, as the simulation run length becomes large (≥50 cycles). The
half-widths of the 95% conﬁdence intervals are comparable (at every run
length) for the three estimation methods and decrease roughly as n−1/2,
where n is the number of simulated cycles.
6.3.3
Simulation Until a Fixed Time
One common variation of the basic regenerative method is to simulate
the marking process until a ﬁxed (simulated) time t. Point estimates and
conﬁdence intervals are computed as in Algorithm 3.5, except that statistics
are computed for the random number n(t) of cycles completed by time t.
This procedure is justiﬁed by Theorem 3.18. In the theorem, ˆr(n), ¯τ(n),
and s2(n) are deﬁned as in Theorem 3.4.
Theorem 3.18. Under the conditions of Theorem 3.4, the estimators
ˆr

n(t)

, ¯τ

n(t)

, and s2
n(t)

are strongly consistent for r(f), Eµ [τ1], and
σ2(f), and
4
n(t)

ˆr

n(t)

−r(f)

s

n(t)

/¯τ

n(t)

⇒N(0, 1)
as t →∞.
Proof. Because Eµ [τ1] < ∞, it follows that each τk is a.s. ﬁnite, which
implies that n(t) →∞a.s. as t →∞; see Theorem 2.9(ii) in Chapter 3.
The ﬁrst assertion of the theorem now follows immediately from the strong
consistency of ˆr(n), ¯τ(n), and s2(n); see Theorem 3.4. Set Zk(f) = Yk(f)−
r(f)τk for k ≥1. The remainder of the proof proceeds similarly to the
proof of Theorem 3.4, except that we apply the random-index clt for
i.i.d. random variables (Proposition 2.5 in the Appendix) to the sequence
{ Zk : k ≥0 } rather than the ordinary clt. To apply the random-index
clt, it suﬃces to show that n(t)/t converges to a positive ﬁnite constant
a.s. as t →∞. Because limn→∞(1/n) 	n
k=1 τk = Eµ [τ1] a.s. by the slln for
i.i.d. random variables, Theorem 2.9(ii) in Chapter 3 implies that n(t)/t →
1/Eµ [τ1] ∈(0, ∞) a.s. as t →∞, and the desired result follows.

6.3 The Regenerative Method
241
Thus replacement of n by n(t) in Algorithm 3.5 yields a strongly consistent
point estimator and an asymptotic conﬁdence interval for r(f). It can be
shown that Biasµ

ˆr

n(t)

= O(t−1).
An alternative procedure is to continue the simulation until the ﬁrst
regeneration point Tn(t)+1 after time t. Using renewal theory, it can be
shown that Biasµ

ˆr

n(t) + 1

= O(t−2), and a bias reduction is obtained.
One disadvantage of this bias-reduction procedure is that the length of the
simulation is now random, and the additional eﬀort required to simulate
the marking process in the interval [t, Tn(t)+1] can be nonnegligible.
The following result leads to a low-bias estimator that does not require
simulation of the marking process beyond time t. In the following, set
ˆr3(t) = (1/t)
 t
0 f

X(u)

du for t ≥0.
Proposition 3.19. Suppose that the cycle length τ1 is aperiodic, T0 = 0,
Eµ[τ 2
1 ] < ∞, and Eµ[Y 2
1 (|f|)] < ∞. Then
Eµ [ˆr3(t)] = r(f) −
1
tEµ [τ1]Eµ
! T1
0
u

f

X(u)

−r(f)

du
"
+ o(t−1).
Estimating the bias term and using the approximation 1/Eµ [τ1] ≈n(t)/t
leads to the estimator
ˆr4(t) = ˆr3(t) + 1
t2
n(t)

k=1
 Tk
Tk−1
(u −Tk−1)

f

X(u)

−ˆr3(t)

du.
It can be shown that Biasµ [ˆr4(t)] = o(t−1), provided that τ1 is aperiodic,
T0 = 0, Eµ[τ 5
1 ] < ∞, and Eµ[Y 5
1 (|f|)] < ∞. In practice, the bias typically
is O(t−2). Moreover, under the conditions of Theorem 3.4,
4
n(t)

ˆr4(t) −r(f)

s

n(t)

/¯τ

n(t)

⇒N(0, 1),
so that an asymptotic conﬁdence interval for r(f) can be based on the esti-
mator ˆr4(t); the asymptotic eﬃciency of the conﬁdence-interval procedures
based on ˆr4(t) and ˆr

n(t)

is the same in that the lengths of the asymptotic
conﬁdence intervals are identical.
Example 3.20 (Token ring).
We compare estimators ˆr4(t) and ˆr

n(t)

using the spn and sequence of regeneration points in Example 3.17. Ta-
ble 6.2 displays point estimates and 95% conﬁdence intervals for the long-
run utilization r(f) deﬁned in Example 3.17. For each simulation length,
the number of completed cycles is given in parentheses. Observe that the
estimator ˆr4(t) is always closer to r(f) than is ˆr

n(t)

, although the dif-
ference between the two estimators becomes small as the simulation run
length increases.

242
6. Regenerative Simulation
Table 6.2. Simulation Results for Token Ring: Point Estimates and 95% Conﬁ-
dence-Interval Half-Widths for the Long-Run Utilization (True Value = 0.4462)
Simulation Length t
estimator
2.0
5.0
10.0
100.0
1000.0
5000.0
(3)
(7)
(14)
(139)
(1389)
(6808)
ˆr

n(t)

0.2727
0.4074
0.4098
0.4321
0.4430
0.4465
±0.2916
±0.2264
±0.1132
±0.0306
±0.0110
±0.0048
ˆr4(t)
0.3450
0.4495
0.4237
0.4345
0.4432
0.4465
±0.2916
±0.2264
±0.1132
±0.0306
±0.0110
±0.0048
Note: The number of completed cycles is given in parentheses.
6.3.4
Estimation to Within a Speciﬁed Precision
The goal of a simulation often is to estimate the quantity r(f) to within
a speciﬁed precision with a speciﬁed probability; equivalently, we wish to
obtain a conﬁdence interval for r(f), where both the conﬁdence level and
length of the interval are speciﬁed a priori. Speciﬁcally, suppose that we
wish to estimate r(f) to within ±ϵg

r(f)

with probability approximately
equal to p, where the parameters ϵ and p are speciﬁed a priori and the
function g (assumed positive and continuous) determines the type of preci-
sion criterion. For example, if g(x) = 1 for all x, then we have an absolute
precision requirement; that is, we wish to estimate r(f) to within ±ϵ with
probability p. If g(x) = x, then we have a relative precision requirement;
that is, we wish to estimate r(f) to within ±100ϵ%. If g(x) = max(x, d)
for some d > 0, then we have a hybrid precision requirement in which
we estimate r(f) to within a relative precision if r(f) is “large” (greater
than d) and to within an absolute precision if r(f) is “small” (less than
d). Approaches to this problem include the use of pilot runs and sequential
estimation procedures.
Pilot Runs
Denote by n∗the (unknown) number of cycles required to satisfy the afore-
mentioned precision criterion, and suppose that the precision parameter ϵ
is small enough so that n∗is relatively large. In particular, suppose that
n∗is large enough so that s2(n∗) ≈σ2(f) and ¯τ(n∗) ≈Eµ [τ1]. Set the
half-width of the conﬁdence interval in (3.6) equal to ϵg

r(f)

and use the
foregoing approximations to obtain the expression
n∗≈
z2
p σ2(f)
E2µ [τ1] ϵ2g2
r(f)
.
(3.21)
From (3.21), we derive the following two-stage procedure. Choose a small
number n0 and create a short pilot run by simulating the marking process

6.3 The Regenerative Method
243
for n0 cycles. Estimate σ2(f), Eµ [τ1], and r(f) by s2(n0), ¯τ(n0), and ˆr(n0).
Substitute these estimates into (3.21) to obtain a value for n∗. Then simu-
late the marking process for n∗cycles and use Algorithm 3.5 to obtain the
ﬁnal point and interval estimates.
Sequential Procedures
The idea behind a sequential procedure is to run the simulation until the
precision criterion appears to be satisﬁed. More precisely, set
N(ϵ) = min

n ≥2: s(n) > 0 and
zp s(n)
¯τ(n)g

ˆr(n)
√n < ϵ
5
for ϵ > 0 and p ∈(0, 1). (We have suppressed the dependence of N(ϵ) on p
in our notation.) The sequential procedure consists of simulating precisely
N(ϵ) cycles and then computing point estimates and conﬁdence intervals as
in Algorithm 3.5. Observe that the number N(ϵ) of cycles to be simulated
is a random variable. Under the conditions of Theorem 3.4, it can be shown
by an argument almost identical to the proof of Theorem 3.18 that
4
N(ϵ)

ˆr

N(ϵ)

−r(f)

s

N(ϵ)

/¯τ

N(ϵ)

⇒N(0, 1)
as ϵ →0. That is, the random interval
I =

ˆr

N(ϵ)

−
zp s

N(ϵ)

¯τ

N(ϵ)
 4
N(ϵ)
, ˆr

N(ϵ)

+
zp s

N(ϵ)

¯τ

N(ϵ)
 4
N(ϵ)

is an asymptotic 100p% conﬁdence interval for r(f) as ϵ →0. Equiva-
lently, the probability that the estimator ˆr

N(ϵ)

is within ±ϵg

r(f)

of
the unknown constant r(f) converges to the speciﬁed value p as the pre-
cision parameter ϵ becomes small. A sequential estimation procedure with
this property is said to be asymptotically consistent. The procedure is also
asymptotically eﬃcient in that
lim
ϵ→0 ϵ2N(ϵ) =
z2
pσ2(f)
E2µ [τ1] g2
r(f)
 a.s..
Heuristically, as the precision requirement becomes increasingly stringent,
the number of cycles simulated approaches the “minimal” required number
as in (3.21).
In practice, care has to be taken so that the procedure does not terminate
too soon. Premature termination can result in actual coverage probabili-
ties that are lower than the nominal probability p. This “undercoverage”
problem is particularly acute for larger values of ϵ. There are a number of
ways in which undercoverage can be reduced while retaining the desirable
properties of asymptotic eﬃciency and consistency. These include

244
6. Regenerative Simulation
Table 6.3. Simulation Results for Token Ring with Fixed-Sized Packets: Empiri-
cal Coverage Probabilities When Estimating Long-Run Utilization with Nominal
Coverage Probability of 95%, Based on 1000 Simulation Repetitions
Precision
Stopping Rule
1%
5%
10%
20%
N(ϵ)
0.9230
0.9100
0.8520
0.8030
(7833)
(305)
(69)
(16)
N ′(ϵ)
0.9470
0.9450
0.9380
0.9150
(8216)
(355)
(97)
(28)
N ′′(ϵ)
0.9280
0.9090
0.8700
0.8300
(7847)
(310)
(72)
(19)
Note: The average number of simulated cycles is given
in parentheses.
• Requiring that some minimum number of cycles be simulated before
termination is allowed
• Requiring that the stopping condition—that is, the requirement that
the current conﬁdence-interval half-width be smaller than ϵg

r(f)

—
be satisﬁed not just once, but k times for some k > 1
• Simulating N ′(ϵ) cycles, where
N ′(ϵ) = min

n ≥2: s(n) > 0 and an +
zp s(n)
¯τ(n)g

ˆr(n)
√n < ϵ

and { an : n ≥1 } is a sequence of constants such that an ↓0
• Simulating N ′′(ϵ) cycles, where
N ′′(ϵ) = min

n ≥2: s(n) > 0 and
tp,n s(n)
¯τ(n)g

ˆr(n)
√n < ϵ

and { tp,n : n ≥1 } is a sequence of constants such that tp,n ↓zp
A typical choice for the constant an is an = 1/n and tp,n is often taken to
be the (1 + p)/2 quantile of the Student’s t distribution with n degrees of
freedom. The foregoing methods can be used in combination.
Example 3.22 (Token ring with ﬁxed-sized packets).
We compare the
stopping rules N(ϵ), N ′(ϵ), and N ′′(ϵ) using the spn and sequence of re-
generation points in Example 3.17. As before, the goal is to estimate the
long-run utilization. Table 6.3 displays—for various levels of precision—the
empirical coverage probability corresponding to a nominal coverage prob-
ability of 95%, based on 1000 simulation replications. Average run lengths
(in cycles) are given in parentheses. For example, when the desired pre-
cision is ±5% and we use stopping rule N(ϵ), the average simulation run

6.3 The Regenerative Method
245
length is 305 cycles and the empirical coverage probability is only 0.9100.
That is, the estimated long-run utilization lies within ±5% of the true value
(0.4462) in only 91% of the 1000 simulation repetitions, rather than the de-
sired 95%. The situation is even worse for a desired precision of ±20%: the
true coverage probability in this case is approximately 80%. As can be seen
from the table, use of either the stopping rule N ′(ϵ) or N ′′(ϵ) increases the
coverage probability relative to N(ϵ). For example, use of the stopping rule
N ′(ϵ) with a desired precision of ±5% increases the average simulation run
length to 355 cycles and increases the coverage to 94.5%. Overall, use of
N ′(ϵ) yielded the best results in our experiments.
6.3.5
Functions of Cycle Means
As discussed in Section 3.2, a wide variety of performance measures can
be expressed as nonlinear functions of time-average limits of the under-
lying chain { (Sn, Cn): n ≥0 }. In this section we consider the problem
of estimating such performance measures in the presence of regenerative
structure.
In light of (3.10), it can be seen that—when there exists a sequence
{ θ(k): k ≥0 } of regeneration points for the underlying chain—the perfor-
mance measures discussed in Section 3.2 can be rewritten in the form
r = g

α( ˜f 1), α( ˜f 2), . . . , α( ˜f l)

,
(3.23)
where g is a real-valued function deﬁned on ℜl (l ≥1), ˜f 1, ˜f 2, . . . , ˜f l are
real-valued functions deﬁned on Σ, and α( ˜fi) is the cycle mean given by
α( ˜f i) = Eµ
θ(1)−1

j=θ(0)
˜f i(Sj, Cj)

for 1 ≤i ≤l. According to this notation, α( ˜f i) = Eµ [ ˜Y 1( ˜f i)], where ˜Y k( ˜f)
is deﬁned by (3.9).
Example 3.24 (Time-average limits). Suppose that the cycle length ˜τ1 =
θ(1) −θ(0) has ﬁnite mean and let ˜f be a function such that ˜Y 0(| ˜f|) <
∞a.s. and Eµ [ ˜Y 1(| ˜f|)] < ∞. Then limn→∞(1/n) 	n−1
j=0 ˜f(Sj, Cj) has the
representation
g

α( ˜f 1), α( ˜f 2)

= α( ˜f 1)
α( ˜f2)
,
(3.25)
where ˜f 1 = ˜f and ˜f 2(s, c) = 1 for (s, c) ∈Σ. Similarly, under suitable
conditions a time-average limit of the form limt→∞(1/t)
 t
0 f

X(u)

du
can be represented in the form (3.25), where ˜f 1(s, c) = f(s)t∗(s, c) and
˜f 2(s, c) = t∗(s, c) for (s, c) ∈Σ.

246
6. Regenerative Simulation
Example 3.26 (Long-run variance). Suppose that τ1 = ζθ(1) −ζθ(0) has ﬁ-
nite mean and let the function f satisfy Y0(|f|) < ∞a.s. and Eµ [Y1(|f|)] <
∞. Then the long-run average value of the output process, that is, the value
of limt→∞(1/t)
 t
0 f

X(u)

du, is well deﬁned and equal to the quantity r(f)
given by (3.1). As in Example 2.18 in Chapter 3, the long-run variance
v(f) = lim
t→∞
1
t
 t
0

f

X(u)

−r(f)
2
du
may be of interest. If the cycle length τ1 is aperiodic and Eµ

Y1(f 2)

< ∞,
then X(t) ⇒X as t →∞and v(f) can also be interpreted as a steady-
state variance: v(f) = Var [f(X)]. Set ˜f 1(s, c) = f(s)t∗(s, c), ˜f 2(s, c) =
f 2(s)t∗(s, c), and ˜f 3(s, c) = t∗(s, c) for (s, c) ∈Σ. Provided that ˜Y 1( ˜f2) <
∞, we have the representation v(f) = g

α( ˜f 1), α( ˜f 2), α( ˜f 3)

, where
g(a1, a2, a3) =
a2
a3

−
a1
a3
2
.
An Estimation Procedure
To obtain strongly consistent point estimates and asymptotic conﬁdence
intervals for a performance measure r as in (3.23), suppose that the function
g is diﬀerentiable in a neighborhood of α =

α( ˜f 1), α( ˜f 2), . . . , α( ˜f l)

with
partial derivatives g1, g2, . . . , gl. Simulate n cycles of the underlying chain,
and compute the quantities
¯Yi(n) = 1
n
n

k=1
˜Y k( ˜f i)
for 1 ≤i ≤l; for convenience, write ¯Y (n) =
 ¯Y1(n), ¯Y2(n), . . . , ¯Yl(n)

. Form
the point estimate
ˆr(n) = g
 ¯Y (n)

= g
 ¯Y1(n), ¯Y2(n), . . . , ¯Yl(n)

,
(3.27)
and denote by V (n) the l ×l sample covariance matrix whose (i, j)th entry
is given by
Vi,j(n) =
1
n −1
n

k=1
 ˜Y k(fi) −¯Yi(n)
 ˜Y k(fj) −¯Yj(n)

.
Denote by ∇g = (g1, g2, . . . , gl) the gradient of g, and set4
w(n) = ∇g
 ¯Y (n)
t V (n) ∇g
 ¯Y (n)

=
l

i=1
l

j=1
gi
 ¯Y (n)

gj
 ¯Y (n)

Vi,j(n).
(3.28)
4Here and elsewhere, all vectors are assumed to be column vectors and xt denotes
the transpose of x.

6.3 The Regenerative Method
247
Finally, let zp be the (1+p)/2 quantile of the standard normal distribution
and form the interval
In =

ˆr(n) −zp
4
w(n)
√n
, ˆr(n) + zp
4
w(n)
√n

for r. The following result shows that ˆr(n) is strongly consistent for r and
that In is an asymptotic 100p% conﬁdence interval for r.
Theorem 3.29. Let ˜f 1, ˜f 2, . . . , ˜f l (l ≥1) be real-valued functions de-
ﬁned on Σ such that α(| ˜f i|) < ∞for 1 ≤i ≤l, and let g be a real-
valued function deﬁned on ℜl that is diﬀerentiable in a neighborhood of
α =

α( ˜f 1), α( ˜f 2), . . . , α( ˜f l)

. Then limn→∞ˆr(n) = r and
√n

ˆr(n) −r

4
w(n)
⇒N(0, 1),
(3.30)
as n →∞, where r, ˆr(n), and w(n) are deﬁned as in (3.23), (3.27), and
(3.28).
Proof. Set ˜Y k =
 ˜Y k( ˜f 1), ˜Y k( ˜f 2), . . . , ˜Y k( ˜f l)

for k ≥1, and observe
that, by the regenerative property, the sequence { ˜Y k : k ≥1 } consists of
i.i.d. random vectors. Applying the slln for i.i.d. random variables to this
sequence (componentwise), we ﬁnd that ¯Y (n) →α a.s. as n →∞. It fol-
lows from the diﬀerentiability of g at α that g is continuous at α, and
the strong consistency of ˆr(n) follows immediately. To establish the con-
vergence in (3.30), observe that, by the clt for ℜl-valued random vectors
(Proposition 2.6 in the Appendix),
√n
 ¯Y (n) −α

⇒N(0, B)
as n →∞, where N(0, B) denotes an l-dimensional normal random vec-
tor having mean (0, 0, . . . , 0) and covariance matrix B = ∥bij∥with bij =
Covµ
 ˜Y 1( ˜f i), ˜Y 1( ˜f j)

for 1 ≤i, j ≤l. Using the delta method—see Propo-
sition 1.45 in the Appendix—it follows that
√n

ˆr(n) −r

⇒∇g(α)t N(0, B).
By standard properties of the multivariate normal distribution, the random
variable ∇g(α)t N(0, B) has a (univariate) normal distribution with mean
0 and variance ρ = ∇g(α)t B ∇g(α). Thus
√n

ˆr(n) −r

√ρ
⇒N(0, 1).
As in the proof of Theorem 3.4, the slln for i.i.d. random variables can be
used to show that limn→∞w(n) = ρ a.s., and (3.30) follows from Slutsky’s
theorem.

248
6. Regenerative Simulation
Example 3.31 (Ratio estimation).
Suppose that r = g

α( ˜f 1), α( ˜f 2)

,
where g(x, y) = x/y. Then ˆr(n) = ¯Y1(n)/ ¯Y2(n). Moreover, using the no-
tation in the proof of Theorem 3.29, ∇g(x, y) = (1/y, −x/y2), and ρ =
(b11−2rb12+r2b22)/α2( ˜f 2). Taking ˜f 2(s, c) = 1 for (s, c) ∈Σ and ˜f 1 = ˜f for
a speciﬁed function ˜f, we see that α( ˜f 2) = Eµ [˜τ1] and ρ = ˜σ2( ˜f)/E2
µ [˜τ1],
where ˜σ2( ˜f) is given by (3.12). Similarly, w(n) coincides with s2(n)/¯τ 2(n),
where s2(n) and ¯τ(n) are given by (3.13) and (3.11). Thus the above es-
timation procedure reduces to the standard regenerative method for the
underlying chain. Similarly, taking ˜f 1(s, c) = f(s)t∗(s, c) for (s, c) ∈Σ
and ˜f 2 = t∗, we obtain the standard regenerative method for the marking
process.
When—as is typical—the function g is nonlinear, the estimator ˆr(n) is
biased for r, especially for small values of n. Appropriate modiﬁcations
of the bias-reduction techniques discussed in Section 6.3.2 can be used to
handle this problem. For example, we can apply the jackknife method by
setting
ˆrJ(n) = 1
n
n

i=1
J(i)(n),
where
J(i)(n) = ng
 ¯Y1(n), . . . , ¯Yl(n)

−(n −1)g
 ¯Y (i)
1 (n), . . . , ¯Y (i)
l
(n)

and
¯Y (i)
j
(n) =
1
n −1

k̸=i
˜Y k( ˜f j).
Under the conditions of Theorem 3.29, it can be shown that ˆrJ(n) is
strongly consistent for r and

ˆrJ(n) −zp
4
w(n)
√n
, ˆrJ(n) + zp
4
w(n)
√n

is an asymptotic 100p% conﬁdence interval for r, where w(n) is deﬁned by5
(3.28).
Extensions
The foregoing results carry over essentially without change to performance
measures of the form r = g

α(f1), α(f2), . . . , α(fl)

, where
α(fi) = Eµ
! T1
T0
fi

X(u)

du
"
5As in Section 6.3.2, alternative conﬁdence intervals can be obtained by using variance
estimators other than w(n).

6.3 The Regenerative Method
249
for 1 ≤i ≤l and Tk = ζθ(k) for k ≥0. Indeed, the methods described
above can be applied to any performance measure of the form
r = g

Eµ[Y1], Eµ[Y2], . . . , Eµ[Yl]

,
(3.32)
where each Yi is a random variable that is completely determined by the
behavior of the marking process or underlying chain over a cycle; Yi need
not be the integral (or sum) of a function over the cycle.
Example 3.33 (Discounted reward). Suppose that T0 = 0 and that rewards
accrue continuously at rate q(s) whenever the marking is s ∈S. Also
suppose that the performance measure r of interest is the β-discounted
reward, deﬁned as
r = Eµ
! ∞
0
e−βuq

X(u)

du
"
.
Using the regenerative property, we can write
r = Eµ
! T1
0
e−βuq

X(u)

du
"
+ Eµ
!
e−βT1
 ∞
T1
e−β(u−T1)q

X(u)

du
"
= Eµ
! T1
0
e−βuq

X(u)

du
"
+ Eµ

e−βT1
r,
so that
r = Eµ
 T1
0
e−βuq

X(u)

du

1 −Eµ[e−βT1]
.
Thus r is of the form (3.32), where g(x, y) = x/(1 −y),
Y1 =
 T1
0
e−βuq

X(u)

du,
and Y2 = exp(−βT1).
Example 3.34 (Mean time to failure). Suppose that the system mod-
elled by the spn is considered to be in a failed state when the current
marking is an element of a subset Af ⊂S; when the marking is an el-
ement of S −Af the system is considered operational. Suppose that the
initial marking is an element of S −Af, and deﬁne the time to failure
as tf = inf { t > 0: X(t) ∈Af }. A common measure of system reliabil-
ity is the mean time to failure r = Eµ [tf]. Suppose that T0 = 0 and
Pµ { tf ≤T1 } > 0. Writing x ∧y = min(x, y) and using the regenerative
property, we ﬁnd that
r = Eµ [tf; tf ≤T1] + Eµ [tf; tf > T1]
= Eµ [tf; tf ≤T1] + Eµ [T1; tf > T1] + Eµ [tf −T1; tf > T1]
= Eµ [tf ∧T1] + Eµ[tf −T1 | tf > T1]Pµ { tf > T1 }
= Eµ [tf ∧T1] + r Pµ { tf > T1 } .

250
6. Regenerative Simulation
It follows that
r = Eµ [tf ∧T1]
Pµ { tf ≤T1 }.
Thus r is of the form (3.32), where g(x, y) = x/y, Y1 = tf ∧T1 and
Y2 =

1
if tf ≤T1;
0
if tf > T1.
If the system is highly reliable, so that r is very large, then specialized
variance-reduction techniques must be used when estimating r.
6.3.6
Gradient Estimation
Engineers and systems designers are often interested in studying the sen-
sitivity of long-run system performance to changes in the values of vari-
ous system parameters. Such parameters might correspond, for example,
to processing rates for various machines in a manufacturing cell or rout-
ing probabilities in a communication network. If the parameter values are
under the designer’s control, then a typical goal of the analysis is to ﬁnd pa-
rameter settings that maximize the performance measure of interest. When
the system under study is modelled as an spn, the clock-setting distribu-
tions or new-marking probabilities, or both, are speciﬁed as functions of a
parameter vector λ. A sensitivity analysis is then carried out by estimat-
ing the gradient of a time-average limit with respect to λ. Such gradient
estimates are also a key ingredient of many simulation-based optimization
procedures.
A classical technique for estimating gradients is to use ﬁnite-diﬀerence
approximations. This approach is expensive, requiring multiple simulation
runs at diﬀerent settings of the parameter values. To address this problem,
several gradient-estimation methods have been developed that require only
a single run; these include the likelihood ratio method and inﬁnitesimal
perturbation analysis (ipa). This subsection contains an introduction to
the likelihood ratio method for gradient estimation in the setting of spns
having a regenerative underlying chain.
An Example
We ﬁrst motivate the gradient estimation problem in more detail.
Example 3.35 (Machine repair). Consider the system of Example 2.28,
but now suppose that the successive lifetimes of each machine are i.i.d.
according to a uniform distribution on the interval [0, 1] and the succes-
sive times for the repairperson to repair (and restart) a machine are i.i.d.
according to an exponential distribution with intensity λ. Whenever the
repairperson is repairing a machine, costs accrue at rate λ2. Each stopped

6.3 The Regenerative Method
251
machine accrues costs at rate β. Suppose that the system is modelled by
an spn as in Figure 6.1. Then the long-run average cost can be expressed
as
r(λ) = r(λ; g) = lim
t→∞
1
t
 t
0
g

X(u), λ

du,
where { X(t): t ≥0 } is the marking process of the spn and
g(s, λ) = λ2s3 + β
N

j=1
s2,j
for s = (s1,1, s2,1, . . . , s1,N, s2,N, s3, s4) ∈S. The quantity r′(λ)—that is,
the derivative of r(λ) with respect to λ—measures the sensitivity of the
long-run average cost with respect to the repair rate, and estimation of
this quantity is of intrinsic interest. Moreover, estimates of r′(λ) can be
used to compute the value λ∗that minimizes the long-run average cost. A
classical method for computing λ∗is the Robbins–Monro algorithm, which
is based on the recursion
λn+1 = max(λn −a
nDn+1, 0)
for n ≥0. Here a > 0, λ0 is an arbitrary initial starting value and
{ Dn : n ≥1 } is a sequence of derivative estimates that satisfy
Eµ

Dn+1
 Dn, λn, Dn−1, λn−1, . . . , D0, λ0

= r′(λn).
It can be shown that limn→∞λn = λ∗a.s. and, moreover, that n1/2(λn −
λ∗) ⇒σN(0, 1) as n →∞for some σ > 0. Thus the estimates converge to
λ∗with probability 1 and the convergence rate is O(n−1/2) in probability.
Likelihood Ratios
We illustrate the main idea underlying the likelihood-ratio method for
gradient estimation by means of a very simple example. Consider a ran-
dom variable X having exponential density function f(x; λ) = λ exp(−λx)
for some λ > 0, and suppose that we wish to estimate the derivative of
r(λ) = E [g(X, λ)] with respect to λ, where g is a speciﬁed real-valued
function deﬁned on ℜ+ × ℜ+. The primary diﬃculty in estimating the
derivative of r is that the parameter λ determines the value of r(λ) not
only explicitly as an argument of the function g, but also implicitly as a
parameter of the distribution of X. This problem can be avoided as follows.

252
6. Regenerative Simulation
Fix λ0 > 0 and observe that
r(λ) = E [g(X, λ)]
=
 ∞
0
g(x, λ)f(x; λ) dx
=
 ∞
0
g(x, λ) f(x; λ)
f(x; λ0)f(x; λ0) dx
= E [g(Y, λ)L(Y ; λ)] ,
where Y is an exponential random variable with intensity λ0 and
L(Y ; λ) = f(Y ; λ)
f(Y ; λ0) =
 λ
λ0

e−(λ−λ0)Y .
The key point is that λ determines the value of E [g(Y, λ)L(Y ; λ)] only
as an explicit argument of the functions g and L—the distribution of Y
does not depend on λ. The function L is a likelihood ratio; heuristically,
L(x; λ) is the likelihood of observing the realized value X = x assuming
that X has the distribution F( · ; λ) relative to the likelihood of observing
this realized value assuming that X has the distribution F( · ; λ0). Write
˜g(y, λ) = g(y, λ)L(y; λ) for y, λ ≥0 and formally diﬀerentiate with respect
to λ to obtain
r′(λ0) = d
dλE [˜g(Y, λ)]

λ=λ0
= E[˜g′(Y, λ0)] = E [h(Y )] ,
where
h(y) = g(y, λ0)L′(y; λ0) + g′(y, λ0) = g(y, λ0)f ′(y, λ0)
f(y, λ0) + g′(y, λ0)
for y ≥0 and a prime denotes the derivative of the corresponding function
with respect to λ. The foregoing derivation uses the fact that L(Y ; λ0) = 1
and is valid provided that the expectation and derivative operators can be
interchanged; such an interchange is permissible under mild conditions on
the function g. Thus to estimate r′(λ0), generate n i.i.d. random variables
Y1, Y2, . . . , Yn with common distribution function F( · ; λ0) and form the
estimator Dn = (1/n) 	n
i=1 h(Yn). It follows easily that Dn is unbiased
and strongly consistent for r′(λ0). Moreover, standard arguments for i.i.d.
random variables show that
I =
!
Dn −zps(n)
√n , Dn + zps(n)
√n
"
is an asymptotic 100p% conﬁdence interval for r′(λ0), where
s2(n) =
1
n −1
n

i=1

h(Yi) −Dn
2.

6.3 The Regenerative Method
253
Observe that, in the above derivation, the likelihood-ratio representation
r(λ) = E [g(Y, λ)L(Y ; λ)] is well deﬁned because f(x; λ0) > 0 for x ≥0. For
an arbitrary distribution function F( · ; λ) with density function f( · ; λ), the
likelihood-ratio representation is valid provided that
f(x; λ) = 0
whenever
f(x; λ0) = 0.
(3.36)
The Likelihood-Ratio Method for SPNs
We now indicate how the foregoing methodology can be extended to the
spn setting. For simplicity, attention is restricted to spns with unit speeds
in which all transitions are simple. Moreover, λ is a single real-valued pa-
rameter, so that the gradient reduces to a simple derivative—in practice,
the techniques that we discuss would be used to estimate each element of
a gradient vector and the derivatives described below would be computed
as partial derivatives.
In the following, only the clock-setting distribution functions, initial-
marking distribution, and new-marking probabilities are allowed to de-
pend on λ. Accordingly, we use the notation F( · ; e, λ), ν0(s, λ), and p(s′; s,
E∗, λ) for these building blocks—in general, the likelihood-ratio method is
inapplicable to problems in which G, E, or r(s, e) depends on λ. We also
write µ( · ; λ) to indicate the dependence of the initial distribution µ on λ
(through both ν0 and the clock-setting distribution functions). Similarly,
we write P( · , · , λ) to indicate the dependence on λ of the transition kernel
of the underlying chain. Finally, we modify our usual notation and write
Pλ and Eλ to denote probabilities and expectations when the parameter
value is equal to λ.
Suppose that each clock-setting distribution function is absolutely con-
tinuous and that Assumption PD holds for each λ in some open interval Λ.
In analogy with the assumption in (3.36), we require for each e ∈E −E′
that the support set { x: f(x; e, λ) > 0 } not depend on λ, where f( · ; e, λ)
is the density of F( · ; e, λ). For example, we do not allow F(x; e, λ) to be
a uniform distribution on the interval [0, λ]. Similarly, we require that the
support set { s: ν0(s, λ) > 0 } not depend on λ and—for each s ∈G and
E∗⊆E(s)—the support set { s′ : p(s′; s, E∗, λ) > 0 } not depend on λ. Fi-
nally, suppose that for all λ ∈Λ there exists a sequence of regeneration
points { θ(n): n ≥0 } for the underlying chain { (Sn, Cn): n ≥0 } and that
the sequence is deﬁned independently of λ. Such a sequence exists, for ex-
ample, if the spn has a single state ¯s with E(¯s) = { ¯e }—our assumptions
guarantee that ¯s is recurrent for λ ∈Λ, and the desired regeneration points
correspond to the successive marking changes at which the marking is ¯s
and transition ¯e ﬁres. For convenience, assume that θ(0) = 0 set θ = θ(1).

254
6. Regenerative Simulation
Fix real-valued functions g1 and g2, each deﬁned on G × ℜ, and denote
by
r(λ) = r(λ; g1, g2) = lim
t→∞
 t
0 g1

X(u), λ

du
 t
0 g2

X(u), λ

du
(3.37)
the performance measure of interest when the parameter value is equal to
λ. Of course, if g2(x, λ) ≡1 for all x and λ, then r(λ) reduces to a standard
time-average limit: r(λ) = limt→∞(1/t)
 t
0 g1

X(u), λ

du. The goal is to
estimate the derivative r′(λ) = dr(λ)/dλ. To this end, write Zn = (Sn, Cn)
for n ≥0 and set
˜hi(Zn, λ) = gi(Sn, λ)t∗(Zn)
(3.38)
for i = 1, 2, where t∗is deﬁned as in (1.7) in Chapter 3. Theorem 2.24
implies that r(λ) = α(˜h1; λ)/α(˜h2; λ) for λ ∈Λ, where
α(˜h; λ) = Eλ
θ−1

n=0
˜h(Zn, λ)

.
(3.39)
Thus
r′(λ) = α′(˜h1; λ)α(˜h2; λ) −α(˜h1; λ)α′(˜h2; λ)
α2(˜h2; λ)
.
The quantities α(˜h1; λ) and α(˜h2; λ) are straightforward to estimate, so the
crux of the problem is the estimation of α′(˜h1; λ) and α′(˜h2; λ).
To estimate α′(˜h1; λ) at a ﬁxed value λ = λ0 ∈Λ, we can use a likelihood-
ratio approach analogous to the one described in the simpler setting. For
z = (s, c1, c2, . . . , cM), z′ = (s′, c′
1, c′
2, . . . , c′
M) ∈Σ and λ ∈Λ, set
v(z, λ) = ν0(s, λ)

ei∈E(s)∩(E−E′)
f(ci; ei, λ)
and
q(z, z′, λ) = p(s′; s, E∗, λ)

ei∈N
f(c′
i; ei, λ)

ei∈O
1{ci−t∗}(c′
i),
where E∗= E∗(z), N = N(s′; s, E∗) ∩(E −E′), O = O(s′; s, E∗), and
t∗= t∗(z). The function v( · , λ) can be viewed as the “density” of the
initial distribution µ( · , λ) and the function q(z, · , λ) can be viewed as
the “density” of the transition kernel P(z, · , λ). Then, ﬁxing λ0 ∈Λ, the
natural analog of the likelihood ratio L(Y ; λ) in the previous example is
L(Z0, Z1, . . . , Zθ−1; λ) = v(Z0, λ)
v(Z0, λ0)
θ−2

j=0
q(Zj, Zj+1, λ)
q(Zj, Zj+1, λ0).
Here L represents the relative likelihood of observing the realized values
Z0, Z1, . . . , Zθ−1 of the underlying chain over the ﬁrst regenerative cycle

6.3 The Regenerative Method
255
under the parameter values λ and λ0. Observe that, in the above expression,
v(Z0, λ)
v(Z0, λ0) = ν0(S0, λ)
ν0(S0, λ0)

ei∈E(S0)∩(E−E′)
f(C0,i; ei, λ)
f(C0,i; ei, λ0)
and
q(Zj, Zj+1, λ)
q(Zj, Zj+1, λ0) = p(Sj+1; Sj, E∗, λ)
p(Sj+1; Sj, E∗, λ0)

ei∈N
f(Cj+1,i; ei, λ)
f(Cj+1,i; ei, λ0)
for 0 ≤j ≤θ−2, where E∗= E∗(Zj) and N = N(Sj+1; Sj, E∗)∩(E −E′).
We also have L(Z0, Z1, . . . , Zθ−1; λ0) = 1 and
L′(Z0, Z1, . . . , Zθ−1; λ0) = v′(Z0, λ0)
v(Z0, λ0) +
θ−2

j=0
q′(Zj, Zj+1, λ0)
q(Zj, Zj+1, λ0)
where, as before, a prime denotes the derivative of the corresponding func-
tion with respect to λ. In the above expression, we have
v′(Z0, λ0)
v(Z0, λ0) = ν′
0(S0, λ0)
ν0(S0, λ0) +

ei∈E(S0)∩(E−E′)
f ′(C0,i; ei, λ0)
f(C0,i; ei, λ0)
(3.40)
and
q′(Zj, Zj+1, λ0)
q(Zj, Zj+1, λ0) = p′(Sj+1; Sj, E∗, λ0)
p(Sj+1; Sj, E∗, λ0) +

ei∈N
f ′(Cj+1,i; ei, λ0)
f(Cj+1,i; ei, λ0)
(3.41)
for 0 ≤j ≤θ −2.
Proceeding formally as in the simpler example, we ﬁnd that α′(˜h1; λ0) =
Eλ0

Y (1)
, where
Y (1) =
θ−1

j=0
˜h′
1(Zj, λ0)
+
θ−1

j=0
˜h1(Zj, λ0)

v′(Z0, λ0)
v(Z0, λ0) +
θ−2

j=0
q′(Zj, Zj+1, λ0)
q(Zj, Zj+1, λ0)

.
Thus an unbiased and strongly consistent estimator of α′(˜h1; λ0) can be
obtained as an average of n i.i.d. copies of Y (1). We focus, however, on a
variant of this estimator that often has somewhat better empirical behavior.
Observe that, for 0 ≤j ≤θ −2 and λ ∈Λ,
Eλ0
! q(Zj, Zj+1, λ)
q(Zj, Zj+1, λ0)
 Zj, Zj−1, . . . , Z0
"
= 1 a.s.,

256
6. Regenerative Simulation
so that
Eλ0
!q′(Zj, Zj+1, λ0)
q(Zj, Zj+1, λ0)
 Zj, Zj−1, . . . , Z0
"
= 0 a.s..
A straightforward conditioning argument then establishes the alternative
representation α′(˜h1; λ0) = Eλ0

W (1)
, where
W (1) =
θ−1

j=0
˜h′
1(Zj, λ0) +
θ−1

j=0
˜h1(Zj, λ0)

v′(Z0, λ0)
v(Z0, λ0) +
j−1

l=0
q′(Zl, Zl+1, λ0)
q(Zl, Zl+1, λ0)

.
(3.42)
Observe that Y (1) contains many terms that are equal to 0 in expectation,
whereas W (1) replaces each of those terms by its expected value, namely 0.
A formal derivation analogous to the one given above leads to the rep-
resentation α′(˜h2; λ0) = Eλ0

W (2)
, where
W (2) =
θ−1

j=0
˜h′
2(Zj, λ0) +
θ−1

j=0
˜h2(Zj, λ0)

v′(Z0, λ0)
v(Z0, λ0) +
j−1

l=0
q′(Zl, Zl+1, λ0)
q(Zl, Zl+1, λ0)

.
(3.43)
The following result summarizes the foregoing discussion.
Proposition 3.44. Let λ0 ∈ℜand let g1 and g2 be real-valued functions
deﬁned on G×ℜand diﬀerentiable at the point λ0. Deﬁne r(λ) = r(λ; g1, g2)
as in (3.37) and suppose that
(i) each clock-setting distribution function is absolutely continuous and
Assumption PD holds for each λ in a neighborhood Λ of λ0,
(ii) for each clock-setting density function f( · ; e, λ), the support set { x :
f(x; e, λ) > 0 } does not depend on λ,
(iii) the support set { s: ν0(s, λ) > 0 } does not depend on λ,
(iv) for each s ∈G and E∗⊆E(s), the support set { s′ : p(s′; s, E∗, λ) >
0 } does not depend on λ, and
(v) for λ ∈Λ there exists a sequence of regeneration points { θ(n): n ≥0 }
(deﬁned independently of λ) for the underlying chain { Zn : n ≥0 }.
Then
r′(λ0) = Eλ0[W (1)]α(˜h2; λ0) −α(˜h1; λ0)Eλ0[W (2)]
α2(˜h2; λ0)
,
where ˜h1 and ˜h2 are as in (3.38), α(˜h; λ) is deﬁned as in (3.39), and W (1)
and W (2) are given by (3.42) and (3.43).
Remark 3.45. It can be shown that the interchange of derivative and ex-
pectation in the formal derivation above is valid if
Eµ[er˜τ1] < ∞
(3.46)

6.3 The Regenerative Method
257
for suﬃciently small r > 0. The condition in (3.46) is implied by Assump-
tion PD. Indeed, if all transitions are timed, then (3.46) follows from The-
orem 1.22 in Chapter 5 and Proposition 1.32. If at least one transition is
immediate, then the desired result can be established using an argument
similar to the proof of Theorem 2.24(iii).
Remark 3.47. The above result actually applies almost unchanged to esti-
mation of the derivative for any long-run performance measure that can be
expressed in the form r(λ) = α(˜h1; λ)/α(˜h2; λ), where ˜h1(z, λ) and ˜h2(z, λ)
are each polynomially dominated and diﬀerentiable at λ0. Examples include
performance measures of the form
r(λ) = lim
n→∞
	n
j=0 ˜h1(Zn, λ)
	n
j=0 ˜h2(Zn, λ)
and
r(λ) = lim
t→∞
R(t, λ)
t
,
where R(t, λ) is a parameterized version of a long-run average reward as
in Section 3.2.3. Indeed, Proposition 3.44 can easily be extended to perfor-
mance measures of the form r(λ) = v(α1, α2, . . . , αk, λ), where v is diﬀer-
entiable, αi = α(˜hi; λ) for 1 ≤i ≤k, and each function ˜hi is polynomially
dominated and diﬀerentiable at λ0.
Set Q1,j = 	θ(j)−1
n=θ(j−1) ˜h1(Zn, λ) and Q2,j = 	θ(j)−1
n=θ(j−1) ˜h2(Zn, λ), and
let Q3,j and Q4,j be the respective values of W (1) and W (2) in the jth
regenerative cycle. Then a strongly consistent estimate of r′(λ0) is given
by
ˆr′(n) =
¯Q3(n) ¯Q2(n) −¯Q1(n) ¯Q4(n)
¯Q2
2(n)
,
where ¯Qi(n) = (1/n) 	n
j=1 Qi,j for 1 ≤i ≤4. Moreover, because r′(λ0)
is of the form (3.32), the techniques of Section 6.3.5 can be used to con-
struct an asymptotic conﬁdence interval for r′(λ0). Speciﬁcally, for q =
(q1, q2, q3, q4) ∈ℜ4, set
u1(q) = −q4/q2
2,
u2(q) = (2q1q4 −q2q3)/q3
2,
u3(q) = 1/q2
2,
u4(q) = −q1/q2
2,
and let u = (u1, u2, u3, u4). The ℜ4-valued function u(q) is the gradient
of f(q) = (q3q2 −q1q4)/q2
2. Write ¯Q(n) =
 ¯Q1(n), ¯Q2(n), ¯Q3(n), ¯Q4(n)

—
where each ¯Qi(n) is deﬁned as above—and set U(n) = u
 ¯Q(n)

. Also let

258
6. Regenerative Simulation
V (n) be the 4 × 4 matrix whose (i, j)th entry is
Vi,j(n) =
1
n −1
n

k=1

Qi,k −¯Qi(n)

Qj,k −¯Qj(n)

,
and set
w(n) = U(n)t V (n) U(n).
(3.48)
Then
√n

ˆr′(n) −r′(λ0)

4
w(n)
⇒N(0, 1).
The foregoing results lead to the following algorithm.
Algorithm 3.49 (Regenerative method for gradient estimation)
1. Select a sequence 0 = θ(0), θ(1), θ(2), . . . of regeneration points for
the underlying chain { Zn : n ≥0 }.
2. Simulate a cycle of the underlying chain using parameter value λ0
and observe Z0, Z1, . . . , Zθ−1.
3. Compute the quantities
Q1,1 =
θ−1

j=0
˜h1(Zj, λ0),
Q2,1 =
θ−1

j=0
˜h2(Zj, λ0),
Q3,1 =
θ−1

j=0
˜h′
1(Zj, λ0)
+
θ−1

j=0
˜h1(Zj, λ0)

v′(Z0, λ0)
v(Z0, λ0) +
j−1

l=0
q′(Zl, Zl+1, λ0)
q(Zl, Zl+1, λ0)

,
Q4,1 =
θ−1

j=0
˜h′
2(Zj, λ0)
+
θ−1

j=0
˜h2(Zj, λ0)

v′(Z0, λ0)
v(Z0, λ0) +
j−1

l=0
q′(Zl, Zl+1, λ0)
q(Zl, Zl+1, λ0)

,
where v′(Z0, λ0)/v(Z0, λ0) is computed according to (3.40) and each
q′(Zl, Zl+1, λ0)/q(Zl, Zl+1, λ0) is computed according to (3.41).
4. Repeat steps 2 and 3 a total of n times to obtain { Qi,j : 1 ≤i ≤
4, 1 ≤j ≤n }.

6.3 The Regenerative Method
259
5. Form the strongly consistent point estimate
ˆr′(n) =
¯Q3(n) ¯Q2(n) −¯Q1(n) ¯Q4(n)
¯Q2
2(n)
for r′(λ0), where ¯Qi(n) = (1/n) 	n
j=1 Qi,j for 1 ≤i ≤4.
6. Form the asymptotic 100p% conﬁdence interval

ˆr′(n) −zp
4
w(n)
√n
, ˆr′(n) + zp
4
w(n)
√n

for r′(λ0), where w(n) is deﬁned as in (3.48) and zp is the (1 + p)/2
quantile of the standard normal distribution.
Example 3.50 (Cyclic queues with feedback). We illustrate the likelihood-
ratio method for gradient estimation using the closed network of queues in
Example 1.4 of Chapter 2. Suppose that successive service times at center i
(i = 1, 2) are i.i.d. according to an exponential distribution with intensity qi
and that the intensities depend on a parameter 0 < λ < 2 via the relations
q1 = q1(λ) = λ and q2 = q2(λ) = λ3/2. Also suppose that the routing
probability p (with which a job completing service at center 1 moves to
center 2) depends on λ via the relation p = p(λ) = 0.5 + λ/4. Finally,
suppose that there are N = 4 jobs and that the system is modelled by the
spn in Figure 2.2.
Consider the relative utilization r(λ) of the two servers, which is deﬁned
as the long-run ratio of the amount of time that the server at center 1 is
busy to the amount of time that the server at center 2 is busy. Formal
deﬁnition of r(λ) is via (3.37), with
gi(s) =

1
if si > 0;
0
otherwise
for s = (s1, s2) ∈G and i = 1, 2. Observe that the marking ¯s = (4, 0) is a
single state and the successive marking changes at which the marking is ¯s
and transition e1 = “service completion at center 1” ﬁres form a sequence
of regeneration points for the underlying chain. It is straightforward to
verify that the remaining conditions of Proposition 3.44 hold, so that we
can use Algorithm 3.49 to estimate r′(λ0), where λ0 is any ﬁxed parameter
value. For z = (s, c) and i = 1, 2, we have ˜hi(z, λ) ≡˜hi(z) = gi(s)t∗(s, c).
It follows that ˜h′
1 ≡0 and ˜h′
2 ≡0, so that
Q3,k =
θ(k)−1

j=θ(k−1)
˜h1(Zj, λ0)Rj,k

260
6. Regenerative Simulation
and
Q4,k =
θ(k)−1

j=θ(k−1)
˜h2(Zj, λ0)Rj,k
for k ≥1 in Algorithm 3.49, where
Rj,k = v′(Zθ(k−1), λ0)
v(Zθ(k−1), λ0) +
θ(k−1)+j−1

l=θ(k−1)
q′(Zl, Zl+1, λ0)
q(Zl, Zl+1, λ0) .
Because the clock-setting densities are given by
f(x; ei, λ) = qi(λ) exp

−qi(λ)x

for i = 1, 2, it follows that
f ′(x; e1, λ)
f(x; e1, λ) = 1 −q1(λ)x
q1(λ)
= 1 −λx
λ
def
= ψ1(x, λ)
and
f ′(x; e2, λ)
f(x; e2, λ) = q′
2(λ)
q2(λ)

1 −q2(λ)x

= 3
2λ

1 −λ3/2x
 def
= ψ2(x, λ).
Similarly, since for s = (s1, s2) and s′ = (s′
1, s′
2)
p(s′; s, e∗, λ) =









p(λ)
if s′
1 = s1 −1;
1 −p(λ)
if s = s′;
1
if s′
1 = s1 + 1;
0
otherwise,
it follows that
p′(s′; s, e∗, λ)
p(s′; s, e∗, λ) =





ψ3(λ)
if s′
1 = s1 −1;
ψ4(λ)
if s = s′;
0
otherwise,
where
ψ3(λ) = p′(λ)
p(λ) =
1
λ + 2
and
ψ4(λ) = −p′(λ)
1 −p(λ) =
−1
2 −λ.
Thus, for z = (s, c) = (s1, s2, c1, c2) and z′ = (s′, c′) = (s′
1, s′
2, c′
1, c′
2),
v′(z, λ)
v(z, λ) =

ψ1(c1, λ) + ψ2(c2, λ) + ψ3(λ)
if s = (3, 1);
ψ1(c1, λ) + ψ4(λ)
if s = (4, 0)

6.3 The Regenerative Method
261
and
q′(z, z′, λ)
q(z, z′, λ) =















ψ3(λ) + 1{s′
1>0}ψ1(c′
1, λ)
+ 1{s2=0}ψ2(c′
2, λ)
if s′
1 = s1 −1;
ψ4(λ) + ψ1(c′
1, λ)
if s = s′;
1{s1=0}ψ1(c′
1, λ) + 1{s′
2>0}ψ2(c′
2, λ)
if s′
1 = s1 + 1;
0
otherwise.
Although the foregoing formulas may seem algebraically somewhat com-
plex, the corresponding simulation procedure is straightforward. The sim-
ulation of the kth regenerative cycle (k ≥1) is initialized by setting
Qi,k = 0 for i = 1, 2, 3, 4. Then we set the current marking s equal to
(3, 1) with probability p or (4, 0) with probability 1 −p; these two sce-
narios correspond to the movement of the job that completes service at
center 1 at time ζθ(k−1) either to center 2 or to the tail of the queue
at center 1. In the former case we generate new clock readings c1 and
c2 that correspond to newly scheduled service completions at centers 1
and 2; in the latter case we generate only a single new clock reading c1.
Then we set R0,k = ψ1(c1, λ0) + ψ2(c2, λ0) + ψ3(λ0) if s = (3, 1) and
R0,k = ψ1(c1, λ0) + ψ4(λ0) if s = (4, 0). In general, just after the jth mark-
ing change (j ≥0) during the kth regenerative cycle, the holding time t∗
in the current marking s is computed, and
• Q1,k is incremented by g1(s) · t∗.
• Q2,k is incremented by g2(s) · t∗.
• Q3,k is incremented by Rj,k · g1(s) · t∗.
• Q4,k is incremented by Rj,k · g2(s) · t∗.
The next marking s′ is then computed, and new events corresponding to
the marking change from s to s′ are scheduled as necessary by generating
new clock readings. If a new clock reading Ai is generated for transition ei
(i = 1, 2), then the quantity Rj,k is incremented by ψi(Ai, λ0). Moreover, if
the marking change from s to s′ corresponds to a completion of service at
center 1, then Rj,k is incremented either by ψ3(λ0) or by ψ4(λ0), the former
if the job completing service moves to center 2 and the latter if the job joins
the tail of the queue at center 1. At this point Rj,k has been updated to
Rj+1,k, and the simulation proceeds to the next marking change.
Table 6.4 displays simulation results for the system of cyclic queues when
λ0 = 1.1. As can be seen, the point estimator for the derivative of the long-
run relative utilization is much more variable than the point estimator for
the long-run relative utilization itself: the conﬁdence-interval half-widths
for r′(λ) are over 4 times as long as those for r(λ), and the normalized half-
widths (i.e., the half-widths divided by the corresponding point estimates)

262
6. Regenerative Simulation
Table 6.4. Simulation Results for Cyclic Queues with Feedback: Point Estimates
and 95% Conﬁdence-Interval Half-Widths for the Long-Run Relative Utilization
r(λ0) and Derivative r′(λ0), Where λ0 = 1.1 (True Values are r(λ0) = 1.3533
and r′(λ0) = 0.1786)
number of cycles simulated (×103)
estimand
10
50
100
500
1000
r(λ0)
1.3508
1.3510
1.3463
1.3513
1.3518
±0.0259
±0.0115
±0.0081
±0.0037
±0.0026
r′(λ0)
0.1241
0.1654
0.1920
0.1781
0.1783
±0.1124
±0.0477
±0.0346
±0.0159
±0.0111
are almost 40 times as long. This phenomenon often arises in gradient
estimation problems.
6.3.7
A Characterization of the Regenerative Method
To clarify the relationship between the regenerative method and the estima-
tion methods introduced in subsequent chapters, we focus on yet another
variant of the basic method. In this variant, the marking process is sim-
ulated until a ﬁxed (simulated) time t and the point estimator of r(f) is
computed as quantity
¯r(t) = 1
t
 t
0
f

X(u)

du.
Suppose that Eµ [τ1] < ∞, Y0(|f|) < ∞a.s., and Eµ [Y1(|f|)] < ∞. Then,
by Theorem 1.12, the estimator ¯r(t) is strongly consistent for r(f). Conﬁ-
dence intervals can be based on the following result, which is of independent
interest as a fundamental clt for regenerative processes. In the theorem,
r(f) and σ2(f) are deﬁned as in (3.1) and (3.2).
Theorem 3.51. Suppose that { X(t): t ≥0 } is a regenerative process with
state space S and regeneration points { Tn : n ≥0 }, and let f be a real-
valued function deﬁned on S. Under the conditions of Theorem 3.4,
√
t

¯r(t) −r(f)

⇒σ0N(0, 1),
as t →∞, where σ2
0 = σ2(f)/Eµ [τ1].
Proof. Assume without loss of generality that T0 = 0. As in Section 6.3.3,
denote by n(t) the random number of cycles completed by time t, and write
√
t

¯r(t) −r(f)

= 1
√
t
 Tn(t)
0

f

X(u)

−r(f)

du
+ 1
√
t
 t
Tn(t)

f

X(u)

−r(f)

du.
(3.52)

6.3 The Regenerative Method
263
As in the proof of Theorem 3.18, n(t)/t →1/Eµ [τ1] a.s. as t →∞, and the
estimators ˆr

n(t)

, ¯τ

n(t)

, and s2
n(t)

are strongly consistent for r(f),
Eµ [τ1], and σ2(f). Using Theorem 3.18 and Slutsky’s theorem, we have
1
√
t
 Tn(t)
0

f

X(u)

−r(f)

du
=
n(t)
t
1/2
s

n(t)

4
n(t)

ˆr

n(t)

−r(f)

s

n(t)

/¯τ

n(t)

⇒σ0N(0, 1)
as t →∞. It therefore suﬃces to show that the second term on the right
in (3.52) converges to 0 with probability 1. To this end, observe that

1
√
t
 t
Tn(t)

f

X(u)

−r(f)

du

≤Yn(t)+1(|f|)
√
t
+ |r(f)|τn(t)+1
√
t
=
n(t)
t
1/2 Yn(t)+1(|f|)
4
n(t)
+ |r(f)|
n(t)
t
1/2 τn(t)+1
4
n(t)
.
Because limt→∞n(t) = ∞a.s., it suﬃces to show that
Yn(|f|)
√n
→0 a.s.
and
τn
√n →0 a.s.
as t →∞. We establish the second convergence result—the proof of the
ﬁrst result is almost identical. Observe that
lim
n→∞
1
n
n

k=1
τ 2
k = Eµ

τ 2
1

a.s.
because, by the regenerative property, { τk : k ≥0 } is a sequence of i.i.d.
variables and Eµ[τ 2
1 ] < ∞by assumption. Thus τ 2
n/n →0 a.s. by Theo-
rem 2.9(i) in Chapter 3, and the desired result follows.
Using the above result together with the strong consistency of the esti-
mators s(n) and ¯τn, it follows that
√
t

¯r(t) −r(f)

ˆσ0(t)
⇒N(0, 1)
as t →∞, where
ˆσ2
0(t) = s2
n(t)

¯τ

n(t)
 .

264
6. Regenerative Simulation
In the usual way, we obtain the following asymptotic 100p% conﬁdence
interval for r(f) based on simulation until time t:
!
¯r(t) −zp ˆσ0(t)
√
t
, ˆr(n) + zp ˆσ0(t)
√
t
"
.
(3.53)
As discussed in subsequent chapters, many output processes (not neces-
sarily regenerative) have the property that the time average ¯r(t)—suitably
normalized—converges in distribution to σN(0, 1) for some σ2 ∈(0, ∞).
The crux of the regenerative method is the consistent estimation of the
variance constant σ2. Indeed, observe that the point estimator ¯r(t) does
not depend on the cycles—it is simply the time average of the output
process over the simulated time interval—but the estimator ˆσ2
0(t) depends
crucially on the cycle structure.
In general, estimation methods can be characterized as being of the “con-
sistent-estimation” type, in which σ2 is estimated explicitly, or of the “can-
cellation” type. The latter type of estimation method rests on limit the-
orems in which σ2 has been cancelled out, so that explicit estimation is
not required. The regenerative method is therefore a consistent-estimation
method; some cancellation methods are introduced in the next chapter.
Remark 3.54. Suppose that the marking process { X(t): t ≥0 } obeys a
clt with variance constant σ2, and let { ˇX(t): t ≥0 } be a strictly station-
ary version—see Section A.2.2—of the marking process. Such a stationary
version exists whenever the expected cycle length is ﬁnite. Provided that
 ∞
0
Cov

f
 ˇX(0)

, f
 ˇX(u)
 du < ∞,
(3.55)
we have the representation
σ2 = 2
 ∞
0
Cov

f
 ˇX(0)

, f
 ˇX(u)

du,
and σ2 can also be viewed as a limiting variance:
lim
t→∞t Var
!1
t
 t
0
f
 ˇX(u)

du
"
= σ2.
It can be shown that (3.55) holds whenever the distribution function of
τ1 is spread out—see Deﬁnition 2.15 in the Appendix—and the quantities
Eµ

τ 2
1

, Eµ

Y 2
1 (|f|)

, and Eµ

Y1(f 2)

are ﬁnite. If, moreover, the bias of
¯r(t) for the nonstationary version of the marking process is O(t−1)—as is
typical—then σ2 is also a limiting variance for the nonstationary version:
lim
t→∞t Varµ
!1
t
 t
0
f

X(u)

du
"
= σ2.

6.3 The Regenerative Method
265
Analogous results hold for a discrete-time regenerative process { Xn : n ≥
0 }. In the discrete-time setting,
σ2 = Var
 ˇX0

+ 2
∞

n=1
Cov

f( ˇX0), f( ˇXn)

and, rather than being spread out, the distribution function of τ1 must be
aperiodic in discrete time.
Remark 3.56. In practice, there may exist more than one sequence of re-
generation points for the marking process, raising the question of which
sequence is preferable. It can be shown that the variance constant σ2
0 in
Theorem 3.51 is insensitive to the choice of regeneration points. It follows
that the length of the conﬁdence interval for r(f) based on a simulation of
length t is asymptotically insensitive to the choice of regeneration points
as t →∞. More precisely, let L1(t) and L2(t) be the respective (random)
lengths of a 100p% conﬁdence interval for r(f) based on a simulation of
length t and two diﬀerent sequences of regeneration points—here p ∈(0, 1)
is arbitrary but ﬁxed and the conﬁdence interval is computed as in (3.53).
Then L1(t)/L2(t) →1 a.s. as t →∞. Although the asymptotic length
of the conﬁdence interval does not depend on the choice of regeneration
points, the variance of the estimator s(n)—and hence of the conﬁdence-
interval length—is extremely sensitive to the choice of regeneration points.
Contrary to some folklore, the variance of s(n) is not necessarily mini-
mized by choosing the sequence in which regeneration points occur most
frequently. Determination of the optimal choice of regeneration points is
an open problem.
6.3.8
Extension to Dependent Cycles
In this subsection we focus on estimation methods for od-regenerative pro-
cesses in discrete time. In particular, suppose that there exists a sequence of
od-regeneration points { θ(k): k ≥0 } for the process { Zn : n ≥0 } and we
wish to estimate a time-average limit limn→∞(1/n) 	n−1
j=0 f(Zj) for some
real-valued function f. We consider two possible approaches: an extension
of the standard regenerative method and a “multiple-runs” method.
The former approach is based on a development similar to that of the
standard regenerative method. Set τk = θ(k) −θ(k −1) and
Yk(f) =
θ(k)−1

n=θ(k−1)
f(Zn)
for k ≥1; the sequence

 
τk, Yk(f)

: k ≥1

consists of o.d.s. random
pairs. Suppose that Eµ[τ1]
<
∞and Eµ[Y1(|f|)]
<
∞. Then, by

266
6. Regenerative Simulation
Theorem 1.27,
r(f) = Eµ [Y1(f)]
Eµ [τ1]
is well deﬁned and ﬁnite, and
lim
n→∞
1
n
n−1

j=0
f(Zj) = r(f) a.s..
If, in addition, { Zn : n ≥0 } is in fact an od-equilibrium process and τ1 is
aperiodic in discrete time, then r(f) can also be interpreted as a steady-
state mean.
To estimate r(f), observe a ﬁxed number n of cycles of { Zn : n ≥0 } and
measure the quantities Y1(f), Y2(f), . . . , Yn(f) and τ1, τ2, . . . , τn. Set
ˆr(n) =
¯Y (n)
¯τ(n) ,
where
¯Y (n) = 1
n
n

k=1
Yk(f)
and
¯τ(n) = 1
n
n

k=1
τk.
It follows from the slln for o.i.d. random variables that ˆr(n) is strongly
consistent for r(f).
To obtain an asymptotic conﬁdence interval for r(f), set
σ2(f) =Varµ [Y1(f) −r(f)τ1]
+ 2Covµ [Y1(f) −r(f)τ1, Y2(f) −r(f)τ2]
and
s2(n) =
1
n −1
n

k=1
(Yk(f) −ˆr(n)τk)2
+
2
n −1
n−1

k=1

Yk(f) −ˆr(n)τk

Yk+1(f) −ˆr(n)τk+1

.
(3.57)
Provided that Eµ[τ 2
1 ] < ∞, Eµ[Y 2
1 (|f|)] < ∞, and σ2(f) > 0, we have
lim
n→∞s2(n) = σ2(f) a.s.

6.3 The Regenerative Method
267
and
√n

ˆr(n) −r(f)

s(n)/¯τ(n)
⇒N(0, 1).
These results are derived as in the proof of Theorem 3.4, but we use the
slln for o.i.d. random variables (Proposition 2.7 in the Appendix) and the
clt for o.d.s. random variables (Corollary 2.10 in the Appendix).
Algorithm 3.58 (Extended regenerative method)
1. Select a sequence { θ(k): k ≥0 } of od-regeneration points for the
process { Zn : n ≥0 }.
2. Simulate the process { Zn : n ≥0 } and observe a ﬁxed number n of
cycles deﬁned by the random indices { θ(k): k ≥0 }.
3. Compute the length τk of the kth cycle and the quantity Yk(f) =
	θ(k)−1
n=θ(k−1) f(Zn) for 1 ≤k ≤n.
4. Form the strongly consistent point estimate ˆr(n) = ¯Y (n)/¯τ(n) for
r(f).
5. Form the asymptotic 100p% conﬁdence interval
!
ˆr(n) −zp s(n)
¯τ(n) √n, ˆr(n) + zp s(n)
¯τ(n) √n
"
for r(f), where s(n) is given by (3.57) and zp is the (1+p)/2 quantile
of the standard normal distribution.
The extended regenerative method is almost identical to the standard re-
generative method, except that the variance constant reﬂects the depen-
dence between adjacent cycles.
Under the conditions of this subsection, an alternative estimation pro-
cedure based on multiple runs can be used to obtain a strongly consistent
point estimate and asymptotic conﬁdence interval for r(f). For convenience,
assume that θ(0) = 0. Simulate the process { Zn : n ≥0 } up to the random
time θ(1) to create { Zn,1 : 0 ≤n < θ1(1) }, and set
Y1,1(f) =
θ1(1)−1

n=0
f(Zn,1)
and τ1,1 = θ1(1). Repeat this step m times to create m independent repli-
cates and produce { Zn,i : 0 ≤n < θi(1) } for 1 ≤i ≤m. Then compute
point estimates and conﬁdence intervals for r(f) as in the standard re-
generative method. Speciﬁcally, take ¯YM(m) = (1/m) 	m
i=1 Y1,i(f) and

268
6. Regenerative Simulation
¯τM(m) = (1/m) 	m
i=1 τ1,i, where Y1,i(f) = 	θi(1)
n=0 f(Zn,i) and τ1,i = θi(1)
for 1 ≤i ≤m. The estimator
ˆrM(m) =
¯YM(m)
¯τM(m)
is strongly consistent for r(f). An asymptotic 100p% conﬁdence interval
for r(f) is given by
!
ˆrM(n) −zp sM(n)
¯τM(n) √n, ˆrM(n) + zp sM(n)
¯τM(n) √n
"
,
where
s2
M(m) =
1
m −1
m

i=1

Y1,i(f) −ˆrM(m)τ1,i
2.
The estimator s2
M(m) is strongly consistent for σ2
M(f), where
σ2
M(f) = Varµ [Y1,1(f) −r(f)τ1,1] = Varµ [Y1(f) −r(f)τ1] .
One way of viewing the above procedure is as follows. Instead of gener-
ating a sample path of the original od-regenerative process { Zn : n ≥0 },
we generate a sample path of the process { Yn : n ≥0 }, where
(Y0, Y1, . . .) = (Z0,1, Z1,1, . . . , Zθ1(1)−1,1, Z0,2, Z1,2, . . . , Zθ2(1)−1,2, . . .).
A sample path of the process { Yn : n ≥0 } is obtained by independently
simulating cycles of { Zn : n ≥0 } and then “gluing” the cycles together.
The process { Yn : n ≥0 } is regenerative and has the same time-average
limits as { Zn : n ≥0 }. In the multiple-runs method, we simply apply the
standard regenerative method to the process { Yn : n ≥0 }.
Suppose that—as often occurs in practice—successive cycle quantities
are positively correlated:
Covµ [Y1(f) −r(f)τ1, Y2(f) −r(f)τ2] > 0.
Comparing the deﬁnitions of σ2(f) and σ2
M(f), we see that the multiple-
runs method produces asymptotically narrower conﬁdence intervals than
the extended regenerative method. That is, the multiple-runs method has
greater asymptotic eﬃciency than the extended regenerative method and
is thus the estimation procedure of choice.
Remark 3.59. As with the standard regenerative method, the variance es-
timators s2(n) and s2
M(m) for the extended regenerative method and the
multiple-runs method can be computed by means of a single pass through
the data. For example, the variance constant σ2(f) in the extended regen-
erative method can be rewritten as
σ2(f) = Varµ [Y1(f)] −2r(f)Covµ [Y1(f), τ1] + r2(f)Varµ [τ1]
+ 2Covµ [Y1(f), Y2(f)] −2r(f)Covµ [Y2(f), τ1]
−2r(f)Covµ [Y1(f), τ2] + 2r2(f)Covµ [τ1, τ2] ,

6. Notes
269
and each term on the right side can be estimated using one-pass formulas.
If { Zn : n ≥0 } is an od-equilibrium process, then Covµ [τ1, τ2] = 0 in the
above expansion.
Remark 3.60. The foregoing development for od-regenerative processes in
discrete time carries over in an obvious way to od-regenerative processes in
continuous time—replace cycle sums by cycle integrals, and so forth.
Notes
Regenerative processes were originally deﬁned by Smith (1955, 1958). Some
important early papers include Brown and Ross (1972) and Miller (1972,
1974a). The books of C¸inlar (1975) and Ross (1983) contain readable in-
troductions to renewal theory and include proofs of Proposition 1.20(i)
and (iii). Other classic treatments of renewal theory and regenerative pro-
cesses include Karlin and Taylor (1975) and Asmussen (1987a). Some of
the terminology associated with regenerative processes varies among au-
thors. For example, some authors would say that the distribution of the
continuous-time cycle length τ1 is either “arithmetic with span d” or “not
arithmetic” rather than saying that τ1 is either “periodic with period d”
or “aperiodic.” Similarly, these authors would say that the distribution of
the discrete-time cycle length τ1 is either “arithmetic with span d > 1”
or “arithmetic with span 1” rather than saying that τ1 is either “periodic
in discrete time with period d” or “aperiodic in discrete time.” Asmussen
(1987a) uses the terminology “lattice” and “nonlattice” rather than “arith-
metic” and “not arithmetic,” although the term “lattice” typically is used
to describe the distribution of a random variable that takes values in a set
of the form { a, a ± d, a ± 2d, . . . } with a ̸= 0 in general.
Inspection of the proof of Theorem 1.12 shows that the moment condition
E [Y1(|f|)] < ∞can be replaced by the weaker condition E [U1(f)] < ∞,
where
Uk(f) =
sup
Tk−1≤t≤Tk

 t
Tk−1
f

X(u)

du

for k ≥1. When E [τ1] < ∞and Y0(|f|) < ∞a.s., Asmussen (1987a) shows
that the condition E [U1(f)] < ∞is in fact necessary and suﬃcient for the
conclusion of the theorem to hold.
Our deﬁnition of an od-regenerative process follows Sigman (1990b).
Smith (1955) originally deﬁned an equilibrium process as one in which the
cycle lengths are i.i.d. and the cycles themselves are stationary—Thorisson
(2000) and others call such a process a “wide-sense regenerative” process.
Deﬁnition 1.28 imposes the additional requirement that the cycles be one-
dependent. Processes with dependent cycles are discussed at length in Tho-
risson (2000), as well as in Fox and Glynn (1987), Glynn (1994), Glynn and

270
6. Regenerative Simulation
Iglehart (1989), Glynn and Sigman (1992), Kalashnikov (1994), and Sig-
man and Wolﬀ(1993). In the context of queueing networks, the notion
of od-equilibrium structure is closely related to the idea of “renovating”
events. For discussions of renovating events and related topics, see, for ex-
ample, Asmussen and Foss (1993), Borovkov (1984), Borovkov and Foss
(1992), Foss and Kalashnikov (1991), Morozov (1994a, 1994b, 1998), and
Morozov and Sigovtsev (2000).
Discussions of the decomposition in (1.35) can be found in Asmussen
(1987a, Section VI.3), Glynn (1982b), Glynn and L’Ecuyer (1995), Hen-
derson and Glynn (1999a, 2001), and Meyn and Tweedie (1993a)—the
treatment in Glynn and L’Ecuyer (1995) is especially detailed. The idea
of using (1.35) to establish wide-sense regenerative structure originated in
the work of Athreya and Ney (1978) and Nummelin (1978). As discussed
in Glynn (1982b), Glynn and L’Ecuyer (1995), and Henderson and Glynn
(2001), a sequence of od-equilibrium points for a Harris chain can be ob-
tained after generating the sample path of the chain. The idea is to identify
the ﬁrst time M at which the chain { Zn : n ≥0 } hits the distinguished set
C and then generate a Bernoulli random variable I with success proba-
bility b l(ZM+r)/pr(ZM, ZM+r), where l( · ) and pr(z, · ) are appropriately
deﬁned “densities” of λ( · ) and P r(z, · ). If I = 1, then a regeneration point
is declared to occur at time M + r. Starting at time M + r, this process is
then repeated to identify successive regeneration points.
The second assertion of Proposition 1.32 follows from Theorem VI.3.2 in
Asmussen (1987a) and—as discussed in Haas (1999b)—the ﬁnal assertion
follows from results in Roberts and Tweedie (1999); see also Glynn and
L’Ecuyer (1995, Proposition 4). Nummelin (1984, Theorem 4.3) has shown
that (1.35) must hold with r = 1 for there to exist a sequence of regenera-
tion points for a Harris recurrent Markov chain; see Henderson and Glynn
(2001). In practice, the od-equilibrium points for the underlying chain of
an spn usually cannot be identiﬁed explicitly and are used primarily as a
theoretical device for establishing stability properties. Recent results due to
Henderson and Glynn (1999a) indicate, however, that explicit identiﬁcation
may be possible at least for certain simple models.
Numerous authors have established the regenerative property for indi-
vidual models with special structure; perhaps the most general results of
this type are those given for closed networks of queues by Borovkov (1986),
Kaspi and Mandelbaum (1992), and Haas and Shedler (1987a); see also
Morozov (1994a, 1994b, 1998). Glynn (1989b) gives suﬃcient conditions
for regeneration in gsmps when each clock-setting distribution has a haz-
ard rate bounded above and below by ﬁnite positive constants. Suﬃcient
conditions for regeneration in gsmps based on geometric trials recurrence
criteria are given by Haas and Shedler (1985a, 1987b, 1992) and Iglehart
and Shedler (1983). Reﬁnements and extensions of these results in the spn
setting are given by Haas and Shedler (1986, 1989b, 1993b). The bounding

6. Notes
271
technique used to prove Lemma 2.45 is taken from the proof of Proposi-
tion 3.2.2 in Ross (1983).
Using results in Glynn and Haas (2002b), the assertion in Remark 2.25
about cycle-length moments can be sharpened. Speciﬁcally, consider an
irreducible spn with ﬁnite marking set and positive speeds. Suppose that
there exists 0 < ¯x < ∞such that each clock-setting distribution function
F( · ; s′, e′, s, e∗) and F0( · ; e′, s) with e′ ∈E −E′ has a density component
that is positive and continuous on (0, ¯x). Also suppose that there exists
a sequence { θ(k): k ≥0 } of regeneration points for the underlying chain
and hence a sequence

ζθ(k) : k ≥0

of regeneration points for the marking
process. If each clock-setting distribution has ﬁnite qth moment (q ≥1),
then so do the cycle lengths τ1 = ζθ(1) −ζθ(0) and ˜τ1 = θ(1) −θ(0) for the
marking process and underlying chain. This assertion remains true when
{ θ(k): k ≥0 } is a sequence of od-equilibrium points or od-regeneration
points. The foregoing results lead to conditions under which cycle quantities
Y1(|f|) and ˜Y 1(| ˜f|) as in Theorem 2.24 have ﬁnite moments of various
orders—see, for example, the notes at the end of Chapter 7.
Crane and Iglehart (1975) were the ﬁrst to focus on the application of
regenerative-process theory to analysis of simulation output. Good expos-
itory treatments of the regenerative method can be found in Crane and
Lemoine (1977) and Shedler (1993). Aspects of the basic theory are also
discussed in Glynn and Iglehart (1987, 1993). Chan et al. (1983) discuss
the one-pass formulas mentioned in Remark 3.8 for computation of s11(n)
and s22(n). These authors also give other numerically stable one-pass and
two-pass procedures for computing variance-type quantities. The extended
regenerative method and multiple-runs method given in Section 6.3.8 are
discussed and compared by Glynn (1994) and also by Haas and Shedler
(1996).
The regenerative method can be used to obtain asymptotic conﬁdence
intervals under somewhat weaker assumptions than those given in The-
orem 3.4. For example, asymptotic conﬁdence intervals for r(f) can be
obtained even when Eµ[Y 2
1 (f)] = Eµ[τ 2
1 ] = ∞, provided that
1. Eµ [Y1(f) −r(f)τ1] = 0, and
2. 0 < Eµ

Y1(f) −r(f)τ1
2
< ∞;
see Glynn and Iglehart (1993). The conditions in Theorem 3.51 can simi-
larly be weakened.
As discussed in Remark 3.56, some quantities in regenerative simula-
tion are sensitive to the particular choice of regeneration points and other
quantities are not. See Calvin (1994) for a detailed discussion of this issue.
The results referred to in Remark 3.54 follow from a continuous-time
version of Lemma 3 on p. 172 of Billingsley (1968), Theorem 5.5 in Glynn
(1989a), and Corollary (2.3) in Glynn and Iglehart (1986a).

272
6. Regenerative Simulation
The sequential estimation procedures discussed in Section 6.3.4 are due
to Lavenberg and Sauer (1977). Glynn and Whitt (1992b) give general
conditions on a simulation under which such procedures are valid. An early
discussion of pilot runs can be found in Cox (1952), where the procedure
is called “double sampling” and the observations collected during the pilot
run are incorporated into the ﬁnal estimates.
Iglehart (1975) originally considered using the Tin and jackknife estima-
tors, among others, to reduce the bias of the standard regenerative point
estimator. Extensions of the jackknife estimator to general nonlinear func-
tions of cycle means as in Section 6.3.5 can be based, for example, on
results in Glynn and Heidelberger (1992). General discussions of the jack-
knife method for bias reduction can be found in Miller (1974b) and the
book of Efron and Tibshirani (1993). The low-bias estimators ˆr

n(t) + 1)
and ˆr4(t) in Section 6.3.3 are due to Meketon and Heidelberger (1982)
and Glynn (1987, 1994), respectively. Henderson and Glynn (2001) ex-
tend the results in Meketon and Heidelberger (1982) to the setting of one-
dependent cycles. Heidelberger and Lewis (1981) describe a “regression-
adjusted” regenerative point estimator that attempts to correct for bias;
the authors’ “sectioning” approach permits extended formal and graphi-
cal analysis of bias, skewness, and departures from normality in the point
estimator. Glynn and Heidelberger (1990, 1992) consider bias issues for
simulation problems in which the allowable computation cost is bounded.
When comparing the asymptotic eﬃciency of conﬁdence-interval proce-
dures in Section 6.3.3, we have deﬁned relative eﬃciency in terms of the
relative lengths of the conﬁdence intervals. A more comprehensive deﬁni-
tion of eﬃciency would explicitly consider computation costs; see Glynn
and Whitt (1992a).
In our empirical comparison of bias-reduction techniques—see Exam-
ples 3.17, 3.20, and 3.22—we cite exact values for the utilization of the
token ring with ﬁxed-sized packets. These values can be found in Shedler
(1993); the results are given in the context of a “patrolling repairman”
model that is essentially the same as the token ring model.
Various authors have considered the problem of estimating steady-state
quantities other than means, such as quantiles (Iglehart, 1976; Seila, 1982)
and central moments (Glynn and Iglehart, 1986b). Fox and Glynn (1989)
and Glynn and Heidelberger (1992) discuss the problem of estimating dis-
counted costs in the regenerative setting, and Iglehart and Stone (1983)
discuss techniques for exploiting regenerative structure when estimating ex-
treme values. Variance-reduction techniques for estimating the mean time
to failure and related performance measures for highly reliable systems are
described, for example, in Goyal et al. (1992) and Heidelberger et al. (1994).
Our discussion of gradient estimation follows Glynn (1989c). The proof
of Proposition 3.44 follows from results in Glasserman and Glynn (1992)
and Glynn and L’Ecuyer (1995). The book of Glasserman (1991) gives a
good introduction to ipa methods for gradient estimation. Expository treat-

6. Notes
273
ments of the likelihood-ratio method—also known as the “score-function”
method—can be found in the books of Rubinstein and Melamed (1998) and
Rubinstein and Shapiro (1993). Nakayama and Shahabuddin (1998) study
conditions on the building blocks of a gsmp under which the likelihood-
ratio method can be used to estimate gradients of ﬁnite-time performance
measures. See Andradottir (1998) for an overview of how gradient estimates
are used when optimizing a stochastic system via simulation.
The basic Robbins–Monro algorithm described in Section 6.3.6 can ex-
hibit poor performance in practice, and there are ongoing eﬀorts to improve
both the rate of convergence and the stability of the algorithm. Moreover,
the basic algorithm has been extended to handle feasibility constraints and
multiple decision parameters. ´Olafsson and Shi (1999) describe an alter-
native optimization approach that exploits regenerative structure. Closely
related to these optimization procedures are methods for “ranking and
selection” as surveyed in Goldsman and Nelson (1998). Heidelberger and
Iglehart (1979) and Iglehart (1977), in particular, describe the application
of the regenerative method to comparing the steady-state performance of
two or more systems.
Heidelberger (1979) and Iglehart and Lewis (1979) discuss schemes for
reducing the variance of the standard point estimator for the regenerative
method, and Glynn (1982a) gives methods for improving the coverage of
the standard conﬁdence interval. Some other variance-reduction techniques
related to regenerative simulation are given in Calvin and Nakayama (2000)
and Henderson and Glynn (1999b). Asmussen (1987b) considers the behav-
ior of the regenerative method when simulating queues in heavy traﬃc.

This page intentionally left blank 

7
Alternative Simulation Methods
The previous chapter concerns spns in which regeneration points exist for
the marking process or underlying chain or both. For such nets, regener-
ative methods often can be used to obtain strongly consistent point esti-
mates and asymptotic conﬁdence intervals for time-average limits of the
form r = limt→∞¯r(t), where ¯r(t) = (1/t)
 t
0 f

X(u)

du for some function
f. This chapter deals with methods for estimation of time-average limits
when regenerative methods are not applicable. This situation can occur ei-
ther because there is no apparent sequence of regeneration points or because
regenerations occur so infrequently that the method is impractical—in Sec-
tion 7.1 we give examples of both types of scenario.
The discussion centers on spns for which Assumption PD of Chapter 5
holds. For such nets, the limit r is well deﬁned and ﬁnite, and the time
average ¯r(t) obeys a clt; that is, ¯r(t)—suitably normalized—converges
in distribution to a normal random variable with mean r and variance
σ2 for some σ2 ∈(0, ∞). Indeed, we show (Theorem 2.17) that under
Assumption PD a stronger convergence result holds: the output process

f

X(t)

: t ≥0

obeys a functional central limit theorem (fclt). That is,
the associated cumulative (i.e., time-integrated) process, centered about the
deterministic function g(t) = rt and suitably compressed in space and time,
converges in distribution to a Brownian motion as the degree of compression
increases. The ordinary clt for ¯r(t) can be viewed as a consequence of this
fclt—see Section A.2.5 for a general discussion of fclts. To establish the
fclt, we show that, under Assumption PD, the underlying chain has od-
regenerative structure—see Lemma 2.5 below—and the desired result then
follows from an fclt for od-regenerative processes.
In Section 7.2 we consider estimation methods that are based on “stan-
dardized time series” (sts). The idea is to use the foregoing fclt to derive
a limit theorem for ¯r(t) similar to the ordinary clt, but in which the vari-

276
7. Alternative Simulation Methods
ance constant σ2 has been “cancelled out.” This approach contrasts with
the regenerative method, which consistently estimates σ2 to obtain a con-
ﬁdence interval for r—see Section 6.3.7. The method of batch means (with
the number of batches independent of the simulation run length) is prob-
ably the best known sts method. An extension of the basic batch-means
method can be used to obtain point estimates and conﬁdence intervals for
nonlinear functions (such as ratios) of time-average limits. We emphasize
that although the validity of sts methods hinges on the existence of od-
regenerative structure, these methods do not require explicit identiﬁcation
of the od-regeneration points; it suﬃces merely to show that they exist.
Section 7.3 is concerned with methods that consistently estimate σ2 but
do not require an explicit sequence of regeneration points. In general, such
methods yield conﬁdence intervals with lengths that are asymptotically
shorter and less variable than the lengths of conﬁdence intervals produced
by cancellation methods. Besides requiring that Assumption PD hold, we
also require that the spn of interest be “aperiodic,” which implies (Corol-
lary 3.5) that the underlying chain is Harris ergodic as deﬁned in Sec-
tion 5.1.1. We ﬁrst consider the problem of estimating time-average limits
of the underlying chain, and assume that a clt holds in discrete time with
variance constant ˜σ2. Our focus is on estimators of ˜σ2 that have a “localized
quadratic-form” representation. Using results from the literature together
with properties of Harris ergodic chains, it is often possible to show that
a speciﬁed quadratic-form estimator is consistent for ˜σ2 when the initial
distribution is the invariant distribution π, so that the underlying chain is
stationary. If, however, a localized quadratic-form estimator is consistent
for ˜σ2 when the initial distribution is π, then (Theorem 3.15) the estima-
tor is consistent for ˜σ2 under any initial distribution—we establish this
assertion using a coupling argument. Some speciﬁc quadratic-form estima-
tors for which consistency can be established include those produced by
the method of “variable” batch means (in which the number of batches is
an increasing function of the simulation run length), as well as by certain
“spectral” methods—see Theorems 3.20 and 3.26. The foregoing results
can be extended to establish consistent estimation methods for nonlinear
functions of time-average limits of the underlying chain, and this extension
in turn leads to consistent estimation methods for time-average limits of
the marking process.
7.1
Limitations of the Regenerative Method
In this section we give two examples for which the regenerative method is
inapplicable. In the ﬁrst example, there is no apparent sequence of regen-
eration points.

7.1 Limitations of the Regenerative Method
277
Figure 7.1. Interactive video-on-demand system.
Example 1.1 (Interactive video on demand). Consider a system with a
video-game server and N > 1 channels for the playing of multiperson in-
teractive video games; see Figure 7.1. Games are played one at a time on
each channel with two or more customers participating in each game. A
customer participates in at most one game at a time. Once a game starts,
none of the participants leaves the game and no additional customers join
the game. When the game ends, all the participants immediately disconnect
from the system. There are M ≥1 diﬀerent games stored at the server,
and more than one instance of a game may be played simultaneously and
independently (on diﬀerent channels). Customers submit requests to play
speciﬁed games. A customer request is either accepted or rejected by the
system after a bounded random delay and according to the following mech-
anism. The server maintains M buﬀers; buﬀer j (1 ≤j ≤M) has ﬁnite
capacity B > 1 and contains requests for game j. Associated with each
channel i is a positive integer L(i) ≤B. Game j may start on channel i
only if channel i is available for game j, that is, only if no game is currently
underway on the channel and at least L(i) requests are in buﬀer j. When-
ever buﬀer j contains B requests and a new request for game j arrives, the
arriving request is immediately rejected. Whenever buﬀer j is empty and a
request for game j arrives, the request is placed in buﬀer j and a bounded
random-length waiting period begins—up to B −1 additional requests for
game j may arrive and be placed in buﬀer j during this waiting period.
If, at the end of the waiting period, at least one channel is available for
game j, then all the requests in buﬀer j are accepted. Speciﬁcally, the cor-
responding customers are notiﬁed of their acceptance, a channel is selected
randomly and uniformly from the set of available channels, and there is
an immediate start of game j on the selected channel. If no channels are
available at the end of the waiting period, then all the requests in buﬀer j
are rejected. In either case, buﬀer j instantaneously becomes empty. The
successive times between requests for game j are i.i.d. as a random vari-
able Aj with continuous distribution function, the successive lengths of the
waiting periods for game j are i.i.d. as a bounded random variable Wj, and
the successive playing times of game j are i.i.d. as a random variable Tj.

278
7. Alternative Simulation Methods
ej,1 = arrival of request for game j
ej,2 = end of waiting period for game j
ej,3 = rejection of request for game j
ei,4 = end of game on channel i
ei,5 = disconnection of customer from channel i
ej,i,1 = start of game j on channel i
Figure 7.2. spn representation of video-on-demand system.

7.1 Limitations of the Regenerative Method
279
This system can be speciﬁed as an spn with ﬁnite marking set, unit
speeds, N+2M timed transitions, and (N+1)M+N immediate transitions.
The spn consists of N subnets corresponding to the N channels and M
subnets corresponding to the M buﬀers; Figure 7.2 displays subnets for a
generic channel i and a generic buﬀer j. All the places except { dj,4 : 1 ≤
j ≤M } and { di,5 : 1 ≤i ≤N } contain either zero or one token. Place dj,1
(1 ≤j ≤M) always contains one token, reﬂecting the fact the arrival
process of requests for game j is always active. Place dj,2 contains a token
if and only if a waiting period for game j is underway. Place dj,3 contains
a token if and only if a request for game j is being rejected due to lack of
available channels. Place dj,4 contains k (≥0) tokens if and only buﬀer j
contains k requests. Place di,5 contains k tokens if and only if k customers
are playing a game together on channel i. Place di,6 contains a token if and
only if customers are disconnecting from channel i. Place dj,i,1 (1 ≤j ≤M
and 1 ≤i ≤N) contains a token if and only if game j is about to start on
channel i.
Whenever dj,4 contains less than B tokens and transition ej,1 = “ar-
rival of request for game j” ﬁres, a token is deposited in place dj,4. If
dj,4 contains zero tokens just before the ﬁring of ej,1, then a token is also
deposited in place dj,2 when ej,1 ﬁres, and a waiting period for game j
starts. Whenever place dj,4 contains B tokens and transition ej,1 ﬁres,
no tokens are removed from or deposited in any of the places in the net,
and the arriving request for game j is rejected. For 1 ≤j ≤M, denote
by Ij(s) the set of channels available to game j when the marking is s:
Ij(s) = { 1 ≤i ≤N : L(i) ≤sj,4 and si,5 = 0 }. Denote by |Ij(s)| the num-
ber of elements in Ij(s). When the marking is s and transition ej,2 = “end
of waiting period for game j” ﬁres, a token is removed from place dj,2.
If |Ij(s)| > 0, then a token is also deposited in exactly one of the places
{ dj,i,1 : i ∈Ij(s) }; a token is deposited in place dj,i,1 (i ∈Ij(s)) with prob-
ability 1/|Ij(s)|. If |Ij(s)| = 0, then a token is deposited in place dj,3. That
is, game j starts on a randomly selected available channel; if no channel
is available, then the video server starts rejecting the requests in buﬀer j.
When the marking is s and transition ej,i,1 = “start of game j on chan-
nel i” ﬁres, a token is removed from place dj,4 and a token is deposited
in place di,5. If sj,4 = 1, then a token is also removed from place dj,i,1.
Thus when place dj,4 contains k (> 0) tokens and a token is deposited
in place dj,i,1, transition ej,i,1 ﬁres k times in succession, removing all the
tokens in place dj,4—as well as the token in place dj,i,1—and depositing k
tokens in place di,5; this sequence of ﬁrings causes transition ei,4 = “end
of game on channel i” to become enabled, and k customers start to play
game j on channel i. Transition ej,3 = “rejection of request for game j” be-
haves in a similar manner: when place dj,4 contains k tokens and a token is
deposited in place dj,3, transition ej,3 ﬁres k times in succession, removing
the token in place dj,3 and all the tokens in place dj,4. Thus the k requests
in buﬀer j are all rejected and there is no start of game j. When place di,5

280
7. Alternative Simulation Methods
Figure 7.3. An spn with extremely long cycles.
contains k tokens and transition ei,4 = “end of game on channel i” ﬁres, a
token is deposited in place di,6 and immediate transition ei,5 = “disconnec-
tion of customer from channel i” becomes enabled. Transition ei,5 then ﬁres
k times in succession, removing the token in place di,6 and all the tokens in
place di,5. With probability 1 timed transitions never ﬁre simultaneously;
this property is a consequence of our assumption that for each game the
distribution function of the time between successive requests is continuous.
All speeds are equal to 1. The clock-setting distribution functions for
timed transitions are given by F(x; s′, ej,1, s, E∗) = P { Aj ≤x }, F(x; s′,
ej,2, s, E∗) = P { Wj ≤x }, and F(x; s′, ei,4, s, E∗) = P { Tl ≤x } for 1 ≤
j ≤M, 1 ≤i ≤N, and all s′, s, and E∗, where l = l(s) is the unique index
such that 1 ≤l ≤M and sl,i,1 = 1.
Suppose that each Aj has a gamma distribution with noninteger shape
parameter, each Wj has a uniform distribution on [0, wj] for some constant
wj > 0, and each Tj has a truncated normal distribution. Also suppose that
more than one game is stored at the server so that M > 1. Then there is no
apparent sequence of regeneration points for the marking process. Indeed,
{ e1,1, e2,1, . . . , eM,1 } ⊆E(s) for all s ∈S and hence the marking process
{ X(t): t ≥0 } does not have a single state.
The second example, though artiﬁcial, is characteristic of a class of prob-
lems for which the regenerative method is applicable in principle but not
in practice.
Example 1.2 (spn with extremely long cycles). Consider an spn consisting
of a single simple transition—recall Deﬁnition 1.8 in Chapter 3—and N
places, where N is an extremely large number; see Figure 7.3. The marking
set is G =

s(1), s(2), . . . , s(N) 
, where s(i) (1 ≤i ≤N) is the unique
marking in which place di contains exactly two tokens and each other place
contains exactly one token. The new-marking probabilities are of the form
p(s(j); s(i), e) = 1
N + ϵij,
where each real number ϵij is small—so that, in particular, each p(s(j); s(i),
e) is positive—and p( · ; s(i), e) ̸= p( · ; s(j), e) for i ̸= j. The idea is that,
starting in marking s(i), the next marking is selected according to a dis-
tribution that is “almost” a uniform distribution over the markings in
G. Suppose that we wish to estimate a time-average limit of the form

7.1 Limitations of the Regenerative Method
281
limt→∞(1/t)
 t
0 f

X(u)

du with f(s(i)) = v + δi for 1 ≤i ≤N, where
v is a ﬁxed constant and δ1, δ2, . . . , δN are small numbers that sum to 0.
Also suppose that each new clock reading for transition e is uniformly dis-
tributed on [0, 1]. Fix an integer i0 ∈{ 1, 2, . . . , N } and observe that s(i0)
is a single state. It follows from Theorems 2.24 and 1.12 in Chapter 6 that
the successive times T0, T1, . . . at which the marking is s(i0) and transition
e ﬁres form a sequence of regeneration points for the marking process, and
lim
t→∞
1
t
 t
0
f

X(u)

du = v0 a.s.,
where v0 ≈v. It is intuitively clear that this simulation problem is well
behaved—initialization eﬀects die out quickly and the time average of the
output process converges rapidly to v0. The expected number of marking
changes between successive regenerations, however, is O(N), so that the
regenerative method is diﬃcult to apply when N is very large.
Remark 1.3. Actually, an eﬃcient nonstandard version of the regenerative
method can, at least in theory, be applied to the spn in Example 1.2. The
idea is to set
q(s(j)) = 1
N + min
1≤i≤N ϵij
for 1 ≤j ≤N and write p(s′; s, e) = bp1(s′; e) + (1 −b)p2(s′; s, e) for
s′, s ∈G, where b = 	
s∈G q(s), p1(s′; e) = q(s′)/b, and p2(s′; s, e) =

p(s′; s, e) −q(s′)

/(1 −b). Whenever the current marking is s and transi-
tion e ﬁres, the next state is generated according to p1( · ; e) with probabil-
ity b and according to p2( · ; s, e) with probability 1 −b. The regeneration
points for the marking process correspond to the successive times at which
the new marking is generated according to p1. This procedure is similar to
the construction—described in Section 6.1.3—of od-equilibrium points for
a Harris recurrent Markov chain. Unfortunately, for the real-world analogs
of the foregoing spn model, each eij typically is computed on the ﬂy ac-
cording to some complicated algorithm. Determination of a “minorizing”
distribution p1 is then highly nontrivial.
Some simulation problems are inherently badly behaved and are not
amenable either to the regenerative method or to alternative estimation
methods. For example, suppose that the marking process { X(t): t ≥0 }
corresponds to the number of jobs in a GI/G/1 queue, as in Example 1.1
of Chapter 1. Also suppose that the queue experiences “heavy traﬃc” in
that the expected interarrival time E [A] and expected service time E [B]
are such that E [B] /E [A] is slightly less than 1. Time-average limits of
functions of the marking process are well deﬁned and ﬁnite, and the suc-
cessive times that a job arrives to an empty queue form a sequence of
regeneration points for the process { X(t): t ≥0 }. The expected time be-
tween successive regeneration points is extremely long, however, so that

282
7. Alternative Simulation Methods
the standard regenerative method is not practical. On the other hand, be-
cause the process { X(t): t ≥0 } takes an extremely long time to settle
into a steady-state regime in heavy traﬃc, alternative simulation methods
are also unlikely to perform well for this problem. In contrast, the prob-
lem in Example 1.2, while not amenable to regenerative simulation, can be
handled by the methods provided in the following sections.
7.2
Standardized Time Series
In this section, we give sllns and fclts for the embedded chain and mark-
ing process of an spn. These results form the basis of sts estimation meth-
ods, which yield strongly consistent point estimates and asymptotic con-
ﬁdence intervals for time-average limits. For one particular sts method,
the method of batch means, we show how to obtain point estimates and
conﬁdence intervals for functions of time-average limits.
7.2.1
Limit Theorems
sllns and fclts for the stochastic processes associated with an spn can
be based on corresponding results for od-regenerative processes. We ﬁrst
discuss these latter results.
Limit Theorems for OD-Regenerative Processes
Let { Zn : n ≥0 } be an od-regenerative process with state space Γ and od-
regeneration points { θ(k): k ≥0 }. For an Rl-valued function f deﬁned on
Γ (where l ≥1), set
Yk(f) =
θ(k)−1

n=θ(k−1)
f(Zn)
for k ≥1 and
r(f) = E [Y1(f)]
E [τ1]
,
where τ1 = θ(1)−θ(0) as usual. These deﬁnitions are essentially the same as
in Section 6.3.8, except that now both Yk(f) and r(f) are random vectors
of length l. Throughout, we write x < ∞for x = (x1, x2, . . . , xl) if each xi
is ﬁnite.
The proof of Theorem 1.27 in Chapter 6 applies essentially without
change to establish the following l-dimensional extension.

7.2 Standardized Time Series
283
Theorem 2.1. Suppose that E [τ1] < ∞. Then r(|f|) < ∞and
lim
n→∞
1
n
n−1

j=0
f(Zj) = r(f) a.s.
for any ℜl-valued function f such that E [Y1(|f|)] < ∞.
We now state an fclt for od-regenerative processes. For l ≥1, denote
by Cl[0, 1] the space of continuous ℜl-valued functions on [0, 1] and by
⇒weak convergence on Cl[0, 1]; see Section A.2.5. Weak convergence on
Cl[0, 1] generalizes to a sequence of ℜl-valued random functions—that is, a
sequence of ℜl-valued stochastic processes—the usual notion of convergence
in distribution of a sequence of ℜl-valued random variables.
Given an ℜl-valued function deﬁned on Γ, deﬁne a sequence of Cl[0, 1]-
valued random functions U1(f), U2(f), . . . by setting
Un(f)(t) =
1
√n
 nt
0

f(Z⌊u⌋) −r(f)

du
(2.2)
for 0 ≤t ≤1 and n ≥0; recall that ⌊x⌋is the greatest integer less than or
equal to x. Observe that
Un(f)(t) = Vi,n
def
=
1
√n
i−1

j=0

f(Zj) −r(f)

for t = i/n (i = 0, 1, . . . , n). If i/n < t < (i + 1)/n for some i, then the
value of Un(f)(t) is obtained by linearly interpolating between Vi,n and
Vi+1,n. Setting Sn(f) = f(Z0) + f(Z1) + · · · + f(Zn) for n ≥0, we can
view each function Uk(f)( · ) as a “standardized” version of the time series
{ Sn(f): n ≥0 } in the same way that n−1/2
Sn(f) −r(f)

can be viewed
as a standardized version of the sum Sn(f).
Denote by W (l) =

 
W (l)
1 (t), W (l)
2 (t), . . . , W (l)
k (t)

: 0 ≤t ≤1

a stan-
dard l-dimensional Brownian motion on [0, 1]; see Section A.2.5. For l ≥1,
denote by ∥x∥the Euclidean norm of x = (x1, x2, . . . , xl); that is, ∥x∥=
(x2
1 + x2
2 + · · · + x2
l )1/2.
Proposition 2.3. Suppose that Eµ

τ 2
1

< ∞and let f be an ℜl-valued
function deﬁned on Γ such that Eµ

∥Y1(|f|)∥2
< ∞. Then there exists an
l × l matrix Q(f) such that Un(f) ⇒Q(f)W (l) as n →∞for any initial
distribution of the process, where Un(f) is deﬁned by (2.2).
Limit Theorems for SPNs
We now apply the foregoing results in the spn setting. Let { X(t): t ≥0 }
be the marking process of an spn with marking set G, timed marking set S,
and transition set E. Also let Σ be the state space of the underlying chain

284
7. Alternative Simulation Methods
{ (Sn, Cn): n ≥0 }. Recall from Deﬁnition 2.20 in Chapter 6 the notion
of a polynomially dominated function. Given a sequence { θ(k): k ≥0 } of
od-regeneration points for the underlying chain and a real-valued function
˜f deﬁned on Σ, set
˜Y k( ˜f) =
θ(k)−1

n=θ(k−1)
˜f(Sn, Cn)
(2.4)
for k ≥1.
Lemma 2.5. Suppose that Assumption PD holds. Then there exists a se-
quence { θ(k): k ≥0 } of od-regeneration points for the underlying chain
{ (Sn, Cn): n ≥0 }. Moreover, ˜Y 1(| ˜f|) has ﬁnite moments of all orders for
any polynomially dominated real-valued function ˜f deﬁned on Σ.
The idea of the proof is as follows. There exists at least one sequence of
od-equilibrium points for the embedded chain { (S+
n , C+
n ): n ≥0 }—see
Lemma 2.32 in Chapter 6. As discussed in the proof of Theorem 2.24(iii)
in Chapter 6, these points also decompose sample paths of the underly-
ing chain into o.d.s. cycles and induce a sequence { θ(k): k ≥0 } of od-
regeneration points for the underlying chain. The remaining assertion fol-
lows by an argument almost identical to the proof of Theorem 2.24(iii) in
Chapter 6.
Using Proposition 1.36 in Chapter 6, we obtain the following corollary.
Corollary 2.6. Suppose that Assumption PD holds. Then the underlying
chain { (Sn, Cn): n ≥0 } is positive Harris recurrent.
Remark 2.7. If Assumption PD holds for an spn having no immediate
transitions, then the od-regeneration points in Lemma 2.5 are also od-
equilibrium points—that is, the cycle lengths are not only stationary, but
also mutually independent. In general, however, the sequence { θ(k) :
k ≥0 } decomposes sample paths of the underlying chain into cycles
with lengths that are stationary and one-dependent. To see that these
assertions hold, consider the (k + 1)st such cycle, which is demarcated
by the random indices θ(k) and θ(k + 1). As discussed above, these ran-
dom indices correspond to od-equilibrium points θ+(k) and θ+(k + 1), for
the embedded chain. Recall that the construction of these od-equilibri-
um points rests on a decomposition of the r-step transition kernel of the
embedded chain for some r ≥1—see (1.35) in Chapter 6—and that the
process { (S+
n , C+
n ): n ≥θ+(k) } depends on the history of the embedded
chain through { (S+
n , C+
n ): θ+(k) −r ≤n < θ+(k) }. It follows that the
process { (Sn, Cn): n ≥θ(k) } depends on the history of the underlying
chain through Hk = { (Sn, Cn): β(k) ≤n < θ(k) }, where β(k) is the
random index of the underlying chain that corresponds to the random in-
dex θ+(k) −r of the embedded chain. In general, therefore, information

7.2 Standardized Time Series
285
about ˜τk yields information about θ(k) −β(k), which yields information
about Hk, which yields information about { (Sn, Cn): n ≥θ(k) } and hence
about ˜τk+1. Thus the cycle lengths ˜τk and ˜τk+1 are, in general, dependent.
If, however, there are no immediate transitions, then the embedded and
underlying chains coincide, so that θ+(k) = θ(k) and β(k) = θ(k) −r for
k ≥0, and hence ˜τk = r+β(k)−θ(k−1). By construction, ˜τk+1 is indepen-
dent of β(k)−θ(k −1), and hence of ˜τk. Indeed, the od-regeneration points
in Lemma 2.5 may also be od-equilibrium points even in the presence of
immediate transitions, provided that the random variable θ(k)−β(k) is a.s.
equal to a ﬁxed constant. This latter condition holds, for example, when
there exists m ≥1 such that the spn visits exactly m immediate markings
between each successive visit to the set of timed markings.
Using Lemma 2.5, Theorem 2.1, and Proposition 2.3, we obtain the fol-
lowing slln and fclt for processes of the form { ˜f(Sn, Cn): n ≥0 }, where
˜f = ( ˜f 1, ˜f 2, . . . , ˜f l) is an ℜl-valued function deﬁned on Σ. For such a func-
tion, set
˜r( ˜f) = Eµ [ ˜Y 1( ˜f)]
Eµ [˜τ1]
,
(2.8)
where ˜Y k( ˜f) is deﬁned as in (2.4) and ˜τk = θ(k)−θ(k −1). The function ˜f
is said to be polynomially dominated if each ˜f j is polynomially dominated
in the sense of Deﬁnition 2.20 in Chapter 6.
Theorem 2.9. Suppose that Assumption PD holds, so that there exists a
sequence { θ(k): k ≥0 } of od-regeneration points for the underlying chain
{ (Sn, Cn): n ≥0 }. Then ˜r(| ˜f|) < ∞and
lim
n→∞
1
n
n−1

j=0
˜f(Sj, Cj) = ˜r( ˜f) a.s.
for any polynomially dominated ℜl-valued function ˜f deﬁned on Σ, where
˜r( ˜f) is deﬁned as in (2.8).
Remark 2.10. When, as discussed in Remark 2.7, the od-regeneration points
in Lemma 2.5 are also od-equilibrium points, the quantity ˜r( ˜f) can be
interpreted not only as a time-average limit, but also as a steady-state
mean, provided that an additional aperiodicity condition holds. To deﬁne
this condition, we recall the notation s →s′ and s ; s′ from Deﬁnition 4.9
in Chapter 4. A d-cycle of an spn is a ﬁnite collection { G1, G2, . . . , Gd }
of disjoint subsets of G such that s′ ∈Gi+1 whenever s ∈Gi and s →
s′. (Take Gd+1 = G1.) The period of the spn is the largest d for which
a d-cycle exists; the spn is called aperiodic if d = 1 and periodic (with
period d) if d > 1. Theorem 3.4 in the following section asserts that, in the
presence of Assumption PD, aperiodicity of the spn implies aperiodicity
of the underlying chain in the sense of Section 5.1.1. It then follows—see

286
7. Alternative Simulation Methods
Remark 1.33 in Chapter 6—that there exists a random vector (S, C) such
that (Sn, Cn) ⇒(S, C) as n →∞for any initial distribution µ. Moreover,
E [ ˜f(S, C)] = ˜r( ˜f) for any polynomially dominated ℜl-valued function ˜f
deﬁned on Σ.
Suppose that there exists a sequence { θ(k): k ≥0 } of od-regeneration
points for the underlying chain { (Sn, Cn): n ≥0 }. For an ℜl-valued func-
tion ˜f deﬁned on Σ, deﬁne a sequence of Cl[0, 1]-valued random functions
˜U 1( ˜f), ˜U 2( ˜f), . . . by setting
˜U n( ˜f)(t) =
1
√n
 nt
0

˜f(S⌊u⌋, C⌊u⌋) −˜r( ˜f)

du
(2.11)
for 0 ≤t ≤1 and n ≥1, where ˜r( ˜f) is given by (2.8).
Theorem 2.12. Suppose that Assumption PD holds, so that there exists a
sequence { θ(k): k ≥0 } of od-regeneration points for the underlying chain,
and let ˜f be a polynomially dominated ℜl-valued function deﬁned on Σ.
Then there exists an l × l matrix Q( ˜f) such that ˜U n( ˜f) ⇒Q( ˜f)W (l) as
n →∞for any initial distribution µ.
sllns and fclts for processes of the form

f

X(t)

: t ≥0

can be
obtained from the corresponding results for the underlying chain. Recall
from (1.7) in Chapter 3 the deﬁnition of the holding-time function t∗. When
there exists a sequence { θ(k): k ≥0 } of od-regeneration points for the
underlying chain, set
r(f) = Eµ [ ˜Y 1(ft∗)]
Eµ[ ˜Y1(t∗)]
(2.13)
for each ℜl-valued function f deﬁned on S, where (ft∗)(s, c) = f(s)t∗(s, c)
for (s, c) ∈Σ and ˜Y k( ˜f) is deﬁned as in (2.4).
Theorem 2.14. Suppose that Assumption PD holds, so that there exists a
sequence { θ(k): k ≥0 } of od-regeneration points for the underlying chain.
Then r(|f|) < ∞and
lim
t→∞
1
t
 t
0
f

X(u)

du = r(f) a.s.
for any ℜl-valued function f deﬁned on S, where r(f) is given by (2.13).
Proof. Because the function t∗is polynomially dominated, so is the func-
tion |ft∗|. Thus, by Theorem 2.9,
lim
n→∞
1
n
n−1

j=0
|(ft∗)(Sj, Cj)| = Eµ [ ˜Y 1(|ft∗|)]
Eµ [˜τ1]
a.s.,

7.2 Standardized Time Series
287
lim
n→∞
1
n
n−1

j=0
(ft∗)(Sj, Cj) = Eµ [ ˜Y 1(ft∗)]
Eµ [˜τ1]
a.s.,
and
lim
n→∞
1
n
n−1

j=0
t∗(Sj, Cj) = Eµ [ ˜Y 1(t∗)]
Eµ [˜τ1]
a.s.,
where the three limits are well deﬁned and ﬁnite. The desired result now
follows from Theorem 2.9(iv) in Chapter 3.
Remark 2.15.
Observe that, under the conditions of Theorem 2.14, the
time-average limit r(f) also has the representation
r(f) = π(ft∗)
π(t∗) ,
where π is the invariant probability measure of the underlying chain and
the notation π(f) is deﬁned as in Section 5.1.1.
For an ℜl-valued function f deﬁned on S, set
Uν(f)(t) =
1
√ν
 νt
0

f

X(u)

−r(f)

du
(2.16)
for 0 ≤t ≤1 and ν > 0. Just as the discrete-time slln in Theorem 2.9 can
be used in Theorem 2.14 to obtain a continuous time slln, the discrete-
time fclt in Theorem 2.12 can be used to obtain an fclt in continuous
time.
Theorem 2.17. Suppose that Assumption PD holds and let f be an ar-
bitrary ℜl-valued function deﬁned on S. Then there exists an l × l matrix
Q(f) such that Uν(f) ⇒Q(f)W (l) as ν →∞for any initial distribution
µ.
We omit the proof, which is similar to that of Theorem 3.51 in Chapter 6
but uses Proposition 2.25 in the Appendix instead of the random-index
clt.
Remark 2.18. The sllns and fclts in Theorems 2.9, 2.12, 2.14, and 2.17
can be established under weaker moment conditions than those in Assump-
tion PD. In particular, the slln for the marking process requires only ﬁnite
ﬁrst moments and the fclt requires only ﬁnite second moments—see the
notes at the end of the chapter.
Remark 2.19.
When an spn is not irreducible but the remaining condi-
tions in Assumption PD hold, the quantity limt→∞(1/t)
 t
0 f

X(u)

du is,

288
7. Alternative Simulation Methods
in general, equal to a random variable whose distribution depends on the
initial distribution µ. The limit theorems in this subsection and the estima-
tion methods in subsequent subsections still apply, however, provided that
the marking process is restricted to an irreducible closed subset of G—that
is, a subset B ⊂G such that s ; s′ for all s, s′ ∈B and s ̸; s′ for all
s ∈B and s′ ∈G −B.
7.2.2
STS Methods
Under Assumption PD, time-average limits of the form
r(f) = lim
t→∞
1
t
 t
0
f

X(u)

du
(2.20)
and
˜r( ˜f) = lim
n→∞
1
n
n−1

j=0
˜f(Sn, Cn)
are well deﬁned and ﬁnite, where f and ˜f are real-valued functions deﬁned
on S and Σ, respectively, and ˜f is polynomially dominated. Moreover, we
can obtain point estimates and conﬁdence intervals for such limits using
sts methods.
STS Methods in Continuous Time
Fix a real-valued function f and set
¯Yν(t) = 1
ν
 νt
0
f

X(u)

du
for 0 ≤t ≤1 and ν > 0. Also set ˆrν = ¯Yν(1). By Theorem 2.14, the point
estimator ˆrν is strongly consistent for r(f).
To obtain asymptotic conﬁdence intervals for r(f), we proceed as follows.
Denote by C[0, 1] the set of continuous real-valued functions deﬁned on
[0, 1]. For a mapping ξ from C[0, 1] to ℜ, let D(ξ) be the set of discontinuity
points for ξ. That is, x ∈D(ξ) if limn→∞ξ(xn) ̸= ξ(x) for some sequence
x1, x2, . . . ∈C[0, 1] with limn→∞sup0≤t≤1 |xn(t) −x(t)| = 0. Next, denote
by Ξ the set of mappings from C[0, 1] to ℜsuch that ξ ∈Ξ if and only if
(i) ξ(ax) = aξ(x) for a ∈ℜ+ and x ∈C[0, 1].
(ii) ξ(x −be) = ξ(x) for b ∈ℜand x ∈C[0, 1], where e(t) = t for
0 ≤t ≤1.
(iii) P { ξ(W) > 0 } = 1.
(iv) P { W ∈D(ξ) } = 0.

7.2 Standardized Time Series
289
Here W = { W(t): 0 ≤t ≤1 } is a standard one-dimensional Brownian
motion. Fix a mapping ξ ∈Ξ and set ξν = ξ( ¯Yν). Theorem 2.17 (with
l = 1) guarantees the existence of a nonnegative constant σ(f) such that
Uν(f) ⇒σ(f)W
(2.21)
as ν →∞, where Uν(f) is given by (2.16). We focus throughout on the
nondegenerate case in which σ(f) > 0; as discussed in Section 6.2.4, σ(f)
typically is positive provided that f(s) ̸= f(s′) for some s, s′ ∈S. The
convergence in (2.21), the properties in (i), (ii), and (iv), and the continuous
mapping theorem (Proposition 1.42 in the Appendix) together imply that
√νξν = ξ
√ν
 ¯Yν −r(f)e

= ξ

Uν(f)

⇒σ(f)ξ(W)
and
√ν

ˆrν −r(f)

= Uν(f)(1) ⇒σ(f)W(1)
(2.22)
as ν →∞, where ⇒denotes ordinary convergence in distribution and the
two sequences converge jointly. Using the property in (iii), it follows that
ˆrν −r(f)
ξν
⇒σ(f)W(1)
σ(f)ξ(W) = W(1)
ξ(W)
(2.23)
as ν →∞. Choosing zp so that P{ −zp ≤W(1)/ξ(W) ≤zp } = p (where
0 < p < 1), we obtain the asymptotic 100p% conﬁdence interval
[ˆrν −ξνzp, ˆrν + ξνzp]
(2.24)
for r(f). A key feature of this conﬁdence interval is that there is no need (as
in regenerative simulation) to consistently estimate the variance constant
σ2(f) that appears in the clt in (2.22); the variance constant has been
“cancelled out” in (2.23).
Of course, to choose appropriate values of zp we need to determine the
distribution of W(1)/ξ(W). Observe in this connection that by deﬁnition
of Brownian motion, W(1) has a standard (mean 0, variance 1) normal
distribution. Moreover, it can be shown that W(1) is independent of ξ(W).
Diﬀerent choices of the mapping ξ lead to diﬀerent estimation procedures.
Example 2.25 (Batch means with ﬁxed number of batches). Fix b ≥2
and take
ξ(x) =

b
b −1
b

i=1

x(i/b) −x

(i −1)/b

−x(1)/b
2
1/2
.
(2.26)
It can be shown that when ξ is deﬁned by (2.26), the conditions in (i)–
(iv) hold and the limiting random variable W(1)/ξ(W) has a Student’s t
distribution with b −1 degrees of freedom. Thus, setting
¯Xν(i) = ¯Xν(i; f) =
1
ν/b
 iν/b
(i−1)ν/b
f

X(u)

du
(2.27)

290
7. Alternative Simulation Methods
for 1 ≤i ≤b and ν > 0, we ﬁnd that the interval in (2.24) is an asymptotic
100p% conﬁdence interval for r(f) when zp is the (1 + p)/2 quantile of the
Student’s t distribution with b −1 degrees of freedom and
ξν = 1
√
b


1
b −1
b

i=1

¯Xν(i) −1
b
b

j=1
¯Xν(j)


2

1/2
.
According to the foregoing formulas, the batch means conﬁdence interval
based on simulation of the marking process over a time interval [0, ν] is
obtained by decomposing the sample path of the process into b disjoint
“batches” (intervals) of length ν/b—typically, 10 ≤b ≤30. The “batch
mean” ¯Xν(i) is the average of

f

X(t)

: t ≥0

over the ith such interval,
and the random variable ξν is equal to b−1/2 times the sample standard
deviation of the batch means. Observe that, in practice, ¯Xν(i) can be com-
puted from a sample path of the chain { (Sn, Cn): n ≥0 } using the formula
¯Xν(i) =
1
ν/b
N(ti)

n=N(ti−1)
f(Sn)

min(ζn+1, ti) −max(ζn, ti−1)

,
where tj = jν/b for 0 ≤j ≤b, ζn is the time of the nth marking change,
and N(t) is the number of marking changes in (0, t].
In forming the conﬁdence interval, the batch means { ¯Xν(i): 1 ≤i ≤b }
are treated as if they are independent, normally distributed random vari-
ables. The intuition underlying this approximation rests on the plausible
assumption that observations of the output process

f

X(t)

: t ≥0

at
widely separated time points are essentially independent. When the batch
length is large, most of the observations within a batch are far apart in
time from observations in the other batches, so that batch means should
be “almost” independent. Because each batch mean is an average of many
observations, it is also plausible that a clt holds, so that each batch mean is
approximately normally distributed. The discussion in this section shows
that, under Assumption PD, the error in the conﬁdence interval arising
from the independence and normality assumptions indeed becomes negli-
gible as the length of each of the b batches—equivalently, the length ν of
the simulation—becomes large.
Example 2.28 (sts area method). Fix m ≥1 and take
ξ(x) =
m−1

i=0
) 1
0
(Ψi ◦x)(t) dt
*21/2
,
where (Ψi ◦x)(t) = x

(i + t)/m

−(1 −t)x(i/m) −tx

(i + 1)/m

. It can
be veriﬁed that ξ satisﬁes the conditions in (i)–(iv) and that W(1)/ξ(W)

7.2 Standardized Time Series
291
is distributed as
√
12Tm, where Tm has a Student’s t distribution with
m degrees of freedom. Thus the interval in (2.24) is an asymptotic 100p%
conﬁdence interval for r(f) when zp is the (1+p)/2 quantile of the Student’s
t distribution with m degrees of freedom and
ξ2
ν = 12
m−1

i=0
A2
i ,
where
Ai = 1
ν
 1
0
)
Zi(λu) −uZi(λ)
*
du
with λ = ν/m and
Zi(u) =
 iλ+u
iλ
f

X(t)

dt
for 0 ≤u ≤λ. To obtain a representation of Ai more amenable to compu-
tation, observe that
Ai = 1
λν
 λ
0
Zi(v) dv −Zi(λ)
2ν
= 1
λν
)
λZi(λ) −
 λ
0
u dZi(u)
*
−Zi(λ)
2ν
= 1
ν
 λ
0
)1
2 −u
λ
*
dZi(u)
= 1
ν
 λ
0
)1
2 −u
λ
*
f

X(iλ + u)

du,
where the second equality follows from an integration by parts. Setting
tj = jλ for j ≥0, we can also express each Ai in terms of the underlying
chain:
Ai =
1
2νλ
N(ti+1)

n=N(ti)

λf(Sn)(ui,n −li,n) −f(Sn)(u2
i,n −l2
i,n)

,
where ui,n = min(ζn, ti+1), li,n = max(ζn, ti), and, as before, N(t) is the
number of marking changes in (0, t].
Example 2.29 (sts maximum method). Fix m ≥1 and take
ξ(x) =
m−1

i=0

(Ψi ◦x)(t∗
i )
2/

t∗
i (1 −t∗
i )

1/2
,
where Ψi ◦x is as in Example 2.28 and t∗
i is the smallest value in [0, 1]
such that (Ψi ◦x)(t∗
i ) ≥(Ψi ◦x)(t) for 0 ≤t ≤1. It can be veriﬁed that

292
7. Alternative Simulation Methods
ξ satisﬁes the conditions in (i)–(iv) and that W(1)/ξ(W) is distributed
as T3m/
√
3, where T3m has a Student’s t distribution with 3m degrees of
freedom. Setting λ = ν/m and
Bi(t) = 1
ν
 (i+t)λ
iλ
f

X(u)

du −t
ν
 (i+1)λ
iλ
f

X(u)

du
for 0 ≤i < m and 0 ≤t ≤1, we see that the interval in (2.24) is an
asymptotic 100p% conﬁdence interval for r(f) when zp is the (1 + p)/2
quantile of the Student’s t distribution with 3m degrees of freedom and
ξ2
ν = 1
3
m−1

i=0
A2
i ,
where
Ai =
Bi(t∗
i )

t∗
i (1 −t∗
i )
1/2
and t∗
i is the smallest value in [0, 1] that maximizes Bi( · ).
STS Methods in Discrete Time
Now consider a ﬁxed polynomially dominated real-valued function ˜f, and
set
ˆrn = (1/n)
n−1

j=0
˜f(Sj, Cj)
for n ≥0. By Theorem 2.9, the point estimator ˆrn is strongly consistent
for ˜r( ˜f). Asymptotic conﬁdence intervals for ˜r( ˜f) are obtained as follows.
Observe that, by Theorem 2.12, ˜U n( ˜f) ⇒˜σ( ˜f)W as n →∞, where ˜U n( ˜f)
is deﬁned by (2.11) and ˜σ( ˜f) is a nonnegative ﬁnite constant. Suppose that
˜σ( ˜f) > 0, as is typical when ˜f is nonconstant and takes values in a ﬁnite
set—see Section 6.2.4. Then the discrete-time version of any method based
on standardized time series can be used to obtain asymptotic conﬁdence
intervals for ˜r( ˜f). That this assertion holds can be seen by applying the
derivation of the sts method in continuous time to the process X(t) =
˜f(S⌊t⌋, C⌊t⌋).
For example, the method of batch means can be applied by ﬁxing b ≥2
and simulating the underlying chain for n = bm state transitions, where
m ≥1. The sample path is then decomposed into b batches of length
m. Finally, a 100p% conﬁdence interval for ˜r( ˜f) is computed as described
previously, except that each ¯Xν(i) is deﬁned in terms of a sum rather than
an integral:
¯Xν(i) = 1
m
m−1

j=0
˜f(Sim+j, Cim+j).

7.2 Standardized Time Series
293
Similarly, after ﬁxing m ≥1 and simulating the underlying chain for
n = lm state transitions, the sts area method yields an asymptotic 100p%
conﬁdence interval for ˜r( ˜f) of the form [ˆrn −ξnzp, ˆrn + ξnzp]. Here
ˆrn = 1
n
n−1

j=0
˜f(Sj, Cj),
zp is the (1 + p)/2 quantile of the Student’s t distribution with m degrees
of freedom, and
ξ2
ν = 12
m−1

i=0
A2
i ,
with
Ai = 1
n
l−1

j=0
1
2 −j
l −1
2l

˜f(Sil+j, Cil+j).
Alternatively, the sts maximum method yields an asymptotic 100p% con-
ﬁdence interval for ˜r( ˜f) of the form [ˆrn −ξnzp, ˆrn + ξnzp]. Here
ˆrn = 1
n
n−1

j=0
˜f(Sj, Cj),
zp is the (1 + p)/2 quantile of the Student’s t distribution with 3m degrees
of freedom, and
ξ2
ν = 1
3
m−1

i=0
A2
i ,
where each Ai is deﬁned as follows. Set
Bi(t) = 1
n
⌊lt⌋−1

j=0
˜f(Sil+j, Cil+j) −t
n
l−1

j=0
˜f(Sil+j, Cil+j)
for 0 ≤t ≤1, and denote by k∗
i the smallest value of k in { 0, 1, . . . , l } such
that Bi(k∗
i /l) ≥Bi(k/l) for k in { 0, 1, . . . , l }. Then
Ai =
Bi(k∗
i /l)
(k∗
i /l)

1 −(k∗
i /l)
1/2 .
7.2.3
Functions of Time-Average Limits
Let f1 and f2 be real-valued functions deﬁned on S such that f1(s) ̸= f1(s′)
for some s, s′ ∈S and similarly for f2. Also suppose that f1 and f2 are
linearly independent in that a1f1(s) + a2f2(s) = 0 for all s ∈S only if

294
7. Alternative Simulation Methods
a1 = a2 = 0. Under Assumption PD we can obtain point estimates and
conﬁdence intervals for the limiting ratio
r = r(f1, f2) = lim
t→∞
 t
0 f1

X(u)

du
 t
0 f2

X(u)

du
.
(2.30)
Some performance measures of this type are given in Section 3.2.1 and in
Example 2.37 below. Because the bias of naive point estimators can be
large, especially when the run length is small, we develop a point estimator
based on combining the batch-means method given in Section 7.2.2 with
the jackknife technique discussed in earlier chapters. Fix b ≥2 and set
Jν(i) = b
	b
j=1 ¯Xν(j; f1)
	b
j=1 ¯Xν(j; f2)
−(b −1)
	
j̸=i ¯Xν(j; f1)
	
j̸=i ¯Xν(j; f2)
for 1 ≤i ≤b, where ¯Xν(i; f) is deﬁned as in (2.27). Then set
ˆr(J)
ν
= 1
b
b

i=1
Jν(i).
(2.31)
The following result shows that ˆr(J)
ν
is strongly consistent for r.
Theorem 2.32. If Assumption PD holds, then ˆr(J)
ν
→r a.s. as ν →∞.
Proof. Set
¯Yν(fj)(t) = 1
ν
 νt
0
fj

X(u)

du
for 0 ≤t ≤1, ν > 0, and j = 1, 2. Also set Λb
i(x) = x(i/b) −x

(i −
1)/b

for x ∈C[0, 1] and 1 ≤i ≤b. Fix i and j. By Theorem 2.14,
limν→∞¯Yν(fj)(1) = r(fj) a.s., where r(fj) is given by (2.13). It is known
that such an slln implies a functional slln:
lim
ν→∞sup
0≤t≤1
| ¯Yν(fj)(t) −r(fj)t| = 0 a.s.;
that is, ¯Yν(fj) →r(fj)e a.s. in C[0, 1] as ν →∞, where e(t) = t for
0 ≤t ≤1. Since Λb
i is a continuous mapping from C[0, 1] to ℜ, it follows
that Λb
i
 ¯Yν(fj)

→Λb
i

r(fj)e

a.s. as ν →∞. By deﬁnition of Λb
i and
¯Yν(fj), this convergence is equivalent to limν→∞¯Xν(i; fj) = r(fj) a.s.. It
then follows easily that limν→∞Jν(i) = r a.s. for 1 ≤i ≤b, and hence
ˆr(J)
ν
→r a.s. as ν →∞.
To obtain conﬁdence intervals, observe that by Theorem 2.17 there exists
a 2 × 2 matrix Q(f) such that
Uν(f) ⇒Q(f)W (2)
(2.33)

7.2 Standardized Time Series
295
as ν →∞for any initial distribution µ, where Uν(f) is deﬁned by (2.16)
and W (2) is a standard two-dimensional Brownian motion. An extension
of the argument in Section 6.2.4 shows that Q(f) is nonsingular except
in degenerate cases, and we assume that Q(f) is nonsingular throughout.
Using the convergence in (2.33) together with an argument similar in spirit
of the proof of Theorem 2.32, it can be shown that
√
b(ˆr(J)
ν
−r)
s(J)
ν
⇒Tb−1
as ν →∞, where Tb−1 denotes a random variable having a Student’s t
distribution with b −1 degrees of freedom and
s(J)
ν
=
!
1
b −1
b

i=1

Jν(i) −ˆr(J)
ν
2
"1/2
.
Thus

ˆr(J)
ν
−s(J)
ν zp
√
b
, ˆr(J)
ν
+ s(J)
ν zp
√
b

(2.34)
is an asymptotic 100p% conﬁdence interval for r, where zp is the (1 + p)/2
quantile of the Student’s t distribution with b −1 degrees of freedom.
Arguments analogous to those given above lead to point and interval
estimators for discrete-time ratios of the form
˜r( ˜f 1, ˜f 2) = lim
n→∞
	n
j=0 ˜f 1(Sj, Cj)
	n
j=0 ˜f2(Sj, Cj)
,
(2.35)
provided that Assumption PD holds and ˜f i is polynomially dominated for
i = 1, 2. The estimation formulas are almost identical to the continuous-
time formulas, except that each ¯Xν(i) is deﬁned as a sum rather than an
integral.
Remark 2.36. Observe that, by virtue of Theorem 2.14, a time-average limit
r(f) as in (2.20) can also be viewed as a time-average limit ˜r( ˜f 1, ˜f 2) as in
(2.35) with ˜f 1(s, c) = f(s)t∗(s, c) and ˜f 2(s, c) = t∗(s, c) for (s, c) ∈Σ. Thus
a jackknifed batch-means estimator of r(f) is available as an alternative to
the simple batch-means estimator given in Section 7.2.2. Little is known
about the relative performance of these estimators—in the experiments
reported in Example 3.35 below, the jackknifed batch-means estimator had
a longer expected conﬁdence-interval length and a higher empirical coverage
probability than the simple estimator when the simulation run length was
small. The performance of the estimators was quite similar for large run
lengths.
The foregoing batch-means methodology can be extended to permit es-
timation not just of ratios but also of arbitrary diﬀerentiable real-valued

296
7. Alternative Simulation Methods
functions of time-average limits. Speciﬁcally, suppose that we wish to es-
timate r = g(α1, α2, . . . , αl) for some l ≥1 and a real-valued function g
deﬁned on ℜl, where
αi = lim
t→∞
1
t
 t
0
fi

X(u)

du
for 1 ≤i ≤l and each fi is a real-valued function deﬁned on S. Also suppose
that each fi is nonconstant and f1, f2, . . . , fl are linearly independent. Then
a strongly consistent point estimator and asymptotic 100p% conﬁdence
interval for r are given by (2.31) and (2.34) as before, except that
Jν(i) = bg

¯A1, ¯A2, . . . , ¯Al

−(b −1)g

¯A(i)
1 , ¯A(i)
2 , . . . , ¯A(i)
l

,
where
¯Aj = 1
b
b

l=1
¯Xν(l; fj)
and
¯A(i)
j
=
1
b −1

l̸=i
¯Xν(l; fj).
An analogous extension is valid in the discrete-time setting.
Example 2.37 (Interactive video on demand). For the system of Exam-
ple 1.1, suppose that more than one game is stored at the server and that
the system is modelled by an spn as in Figure 7.2. Also suppose, as before,
that each interrequest-time random variable Aj has a gamma distribution
with noninteger shape parameter, each waiting-time random variable Wj
has a uniform distribution on [0, wj], and each playing-time random vari-
able Tj has a truncated normal distribution. As discussed previously, there
is no apparent sequence of regeneration points for the marking process of
the spn.
Let ¯s ∈S be the unique marking such that each of places d1,1, d2,1, . . . ,
dM,1 contains one token and no other place contains a token; all buﬀers are
empty and no games are underway when the marking is ¯s. For s, s′ ∈G,
it is not hard to see that s ; ¯s and ¯s ; s′, so that s ; s′. Thus the spn
is irreducible. Since the marking set G is ﬁnite and all speeds are positive,
it follows from the form of the clock-setting distribution functions that
Assumption PD holds with u = min1≤j≤M wj. The methods of Section 7.2.2
and the current section therefore can be used to obtain strongly consistent
point estimates and asymptotic conﬁdence intervals for time-average limits
of the form (2.20), (2.30), or (2.35). A number of pertinent performance
characteristics can be expressed as limits of this type. For example, suppose
that a customer pays an amount v per unit of game time. Then the long-
run average rate at which the system generates revenue can be expressed

7.2 Standardized Time Series
297
as a limit of the form
r(f) = lim
t→∞
1
t
 t
0
f

X(u)

du,
where f(s) = (s1,5 + · · · + sN,5)v. The long-run relative utilization of chan-
nel i (1 ≤i ≤N) can be expressed as a limit of the form
r(f1, f2) = lim
t→∞
 t
0 f1

X(u)

du
 t
0 f2

X(u)

du
,
where f1(s) = 1{1,2,...,B}(si,5) and f2(s) = 	N
l=1 1{1,2,...,B}(sl,5). The long-
run fraction of requests for game j that get immediately rejected can be
expressed as a limit of the form
˜r( ˜f 1, ˜f 2) = lim
n→∞
	n
j=0 ˜f 1(Sj, Cj)
	n
j=0 ˜f2(Sj, Cj)
,
where
˜f 1(s, c) =

1
if E∗(s, c) = { ej,1 } and sj,4 = B;
0
otherwise
and
˜f 2(s, c) =

1
if E∗(s, c) = { ej,1 };
0
otherwise.
Here the set-valued function E∗is deﬁned as in (1.8) in Chapter 3.
7.2.4
Extensions
It can be shown that the augmented chain

(Sn, Cn, Sn+1, Cn+1): n ≥0

inherits the stability properties of the underlying chain, and the forego-
ing sts methods can be extended to yield point estimates and conﬁdence
intervals for limits such as
˜r( ˜f 1, ˜f 2) = lim
n→∞
	n
j=0 ˜f 1(Sj, Cj, Sj+1, Cj+1)
	n
j=0 ˜f2(Sj, Cj, Sj+1, Cj+1)
.
For example, consider the spn model of the interactive video-on-demand
system in Example 1.1 together with the sequence of times at which there
is an end of waiting period for game j (1 ≤j ≤M). Suppose that we
wish to estimate the long-run fraction of these times at which there is an
immediate start of game j on channel i (1 ≤i ≤N). This long-run fraction
can be expressed as a limit of the above form with
˜f 1(s, c, s′, c′) =

1
if sj,2 = 1 and s′
j,i,1 = 1;
0
otherwise

298
7. Alternative Simulation Methods
and
˜f 2(s, c, s′, c′) =

1
if sj,2 = 1 and s′
j,2 = 0;
0
otherwise.
This long-run performance measure needs to be expressed in terms of the
augmented chain rather than the usual underlying chain because a game
always starts on a channel chosen randomly and uniformly from among the
available channels.
In light of the results in Section 3.2, it is apparent that the estimation
methods in this section can be adapted to handle a variety of performance
measures of interest. For example, consider the spn in Example 1.1 and
suppose that each participant in a game pays a ﬁxed amount u at the start
of the game. The revenue R(t) generated by the system in the interval [0, t]
can then be represented as in (2.13) in Chapter 3, where q(s) ≡0 and
v(s, c) =

u
if E∗(s, c) = { ej,i,1 } for some 1 ≤j ≤M and 1 ≤i ≤N;
0
otherwise.
By Theorem 2.14 in Chapter 3, the long-run average rate at which the
system generates revenue can be expressed as a limit of the form (2.35),
where ˜f 1 = v and ˜f 2 = t∗. Such a limit can then be handled by the methods
of Section 7.2.3.
7.3
Consistent Estimation Methods
Consider an spn with an underlying chain { (Sn, Cn): n ≥0 } having state
space Σ, together with a real-valued function ˜f deﬁned on Σ, such that
lim
n→∞¯r(n; ˜f) = ˜r( ˜f) a.s.
(3.1)
for some ﬁnite constant ˜r( ˜f) and
√n

¯r(n; ˜f) −˜r( ˜f)

˜σ( ˜f)
⇒N(0, 1)
(3.2)
as n →∞for some constant ˜σ( ˜f) ∈(0, ∞), where
¯r(n; ˜f) = 1
n
n−1

j=0
˜f(Sj, Cj).
(3.3)
Suppose that we can ﬁnd an estimator Vn that is consistent for the variance
constant ˜σ2( ˜f) in (3.2), that is, an estimator Vn that converges to ˜σ2( ˜f) in

7.3 Consistent Estimation Methods
299
probability as n →∞or, equivalently,1 Vn ⇒˜σ2( ˜f) as n →∞. Then an
application of Slutsky’s theorem shows that
√n

¯r(n; ˜f) −˜r( ˜f)

V 1/2
n
⇒N(0, 1),
so that

¯r(n; ˜f) −zp V 1/2
n
√n
, ¯r(n; ˜f) + zp V 1/2
n
√n

is an asymptotic 100p% conﬁdence interval for ˜r( ˜f), where zp is the (1+p)/2
quantile of the standard normal distribution. This section is concerned with
methods for obtaining point estimates and conﬁdence intervals based on
consistent estimation of the variance constant. Recall from Section 6.3.7
that the regenerative method is one such “consistent estimation method.”
Our emphasis in this section is on alternative methods that do not require
regenerative structure. As mentioned previously, the lengths of conﬁdence
intervals based on consistent estimation methods are, asymptotically, both
smaller in expectation and less variable than the lengths of conﬁdence in-
tervals based on cancellation methods (such as sts methods).
Because we focus throughout on spns that satisfy Assumption PD, The-
orems 2.9 and 2.12 imply that the slln and clt in (3.1) and (3.2) hold
for any polynomially dominated function ˜f—here we use the fact that, as
discussed in Section A.2.5, an ordinary clt holds whenever an fclt holds.
For the marking process, continuous-time analogs of (3.1) and (3.2) follow
from Theorems 2.14 and 2.17. As mentioned in Remark 2.18, the foregoing
sllns and clts can be established under weaker moment conditions than
those in Assumption PD.
This section is concerned with conditions on the building blocks of an
spn under which various “quadratic-form” estimators of the variance con-
stant are consistent. We ﬁrst show that if Assumption PD holds and the
spn is aperiodic, then the underlying chain is aperiodic and hence Har-
ris ergodic. We then show that if a “localized” quadratic-form variance
estimator is consistent when applied to a stationary version of a Harris
ergodic underlying chain, then the estimator is consistent when applied
to any speciﬁed version of the chain. The idea is to couple the speciﬁed
version with a stationary version, that is, to construct the two versions
on a common probability space such that they coincide after some a.s.
ﬁnite random time. Finally, we establish consistency for some speciﬁc vari-
ance estimators—including the variable batch-means estimator and certain
spectral estimators—under arbitrary initial conditions. Our strategy is to
invoke known results that establish the consistency of these estimators for
stationary processes and then apply the foregoing coupling argument.
1See Proposition 1.39 in the Appendix.

300
7. Alternative Simulation Methods
7.3.1
Aperiodicity and Harris Ergodicity
Recall (1) the deﬁnition of an aperiodic spn from Remark 2.10 and (2) the
deﬁnition of an aperiodic chain in Section 5.1.1. The following result relates
these two notions of aperiodicity.
Theorem 3.4. Let { (Sn, Cn): n ≥0 } be the underlying chain of an ape-
riodic spn. If Assumption PD holds, then { (Sn, Cn): n ≥0 } is aperiodic.
As discussed in Section 5.1.1, a positive Harris recurrent Markov chain that
is also aperiodic is called Harris ergodic. Corollary 3.5 is an immediate
consequence of Theorem 3.4 and Corollary 2.6.
Corollary 3.5. Let { (Sn, Cn): n ≥0 } be the underlying chain of an ape-
riodic spn. If Assumption PD holds, then { (Sn, Cn): n ≥0 } is Harris er-
godic.
To establish Theorem 3.4, we need two preliminary lemmas. The ﬁrst,
Lemma 3.6, is a well-known number-theoretic result.
Lemma 3.6. Let L be a countably inﬁnite set of nonnegative integers that
is closed under addition, and suppose that the elements in L have greatest
common divisor 1. Then the set L contains all integers greater than some
n0.
Lemma 3.7. Suppose that Assumption PD holds for an aperiodic spn with
underlying chain { (Sn, Cn): n ≥0 }, and let A ⊆Σ satisfy ¯φ(A) > 0, where
¯φ is deﬁned as in (1.17) of Chapter 5. Then
P(s,c) { (Si+nd, Ci+nd) ∈A for some n ≥1 } > 0
for each (s, c) ∈Σ, d ∈{ 1, 2, . . . }, and i ∈{ 0, 1, . . . , d −1 }.
Proof. Fix i, d, and (s, c). For ease of exposition suppose that all speeds
are equal to 1, and without loss of generality assume that the set A is of the
form A = { s′ } × H for some s′ ∈S and H ⊆C(s′). Consider all possible
paths of the form s′ →s1 →· · · →sm = s′ and denote by L the set of
lengths of these paths. (We allow intermediate visits to s′ along a path.)
The set L is closed under addition and, by the aperiodicity of the spn, the
elements in L have greatest common divisor 1. By Lemma 3.6, the set L
contains all integers greater than some n0. It follows that for each state
s0 ∈S and integer l ≥0 there exists a path s0 →s1 →· · · →sm = s′ such
that l + m = i + nd for some n ≥0. Fix such a path for each s0 and l,
and denote the length of the path by m(s0, l). An argument similar to the
proof of Lemma 1.29 in Chapter 5 shows that for each s0 ∈S and l ≥0
there exist B = B(s0, l) ⊆{ s0 } × C(s0) and δ1 = δ1(s0, l) > 0 such that
¯φ(B) > 0 and
inf
(¯s,¯c)∈B P m(s0,l)
(¯s, ¯c), A

≥δ1.

7.3 Consistent Estimation Methods
301
Next, set
Σϵ =

(¯s, ¯c) ∈Σ: ¯c ∈[0, ϵ)M 
for ϵ > 0. Arguing as in the proof of Lemma 1.30 in Chapter 5, it can be
shown that there exists a ﬁnite partition Q of Σ into disjoint subsets and
a constant ϵ > 0 such that for each Q ∈Q and l ≥0 there exist a state
s0 = s0(Q), a real number δ2 = δ2(Q, l) > 0, and an integer b = b(Q) ≥1
such that
inf
(¯s,¯c)∈Q∩Σϵ P b
(s, c), B(s0, l)

≥δ2.
(3.8)
Write m∗(Q, l) = m

s0(Q), l

and δ∗
1(Q, l) = δ1

s0(Q), l

. Also, for n ≥0,
denote by Qn the unique element Q ∈Q such that (Sn, Cn) ∈Q. Finally,
arguing as in the proof of Lemma 1.33 in Chapter 5, it can be shown
that for any (¯s, ¯c) ∈Σ and ϵ > 0 there exist δ3 = δ3(ϵ, ¯s, ¯c) > 0 and
k = k(ϵ, ¯s, ¯c) < ∞such that
P k
(¯s, ¯c), Σϵ

≥δ3.
Choose ϵ > 0 so that (3.8) holds, and set
J = k(ϵ, s, c) + b(Qk(ϵ,s,c)) + m∗
Qk(ϵ,s,c), k(ϵ, s, c) + b(Qk(ϵ,s,c))

.
A straightforward conditioning argument then shows that
P(s,c) { (SJ, CJ) ∈A } ≥δ,
where
δ = δ(ϵ, s, c) = min
Q∈Q δ∗
1

Q, k(ϵ, s, c) + b(Q)

· min
Q∈Q δ2

Q, k(ϵ, s, c) + b(Q)

· δ3(ϵ, s, c) > 0.
The desired result now follows because, by construction, J −i is divisible
by d.
Proof of Theorem 3.4. Suppose that, contrary to the statement of the
theorem, the spn is aperiodic and Assumption PD holds, but { (Sn, Cn) :
n ≥0 } is periodic with period d. Let Σ1, Σ2, . . . , Σd ⊂Σ be the disjoint
subsets in the d-cycle for the underlying chain, and assume without loss of
generality that the initial distribution µ satisﬁes µ(Σ1) = 1. There must
exist s ∈G such that Ai(s) =

s × C(s)

∩Σi ̸= ∅and Aj(s) =

s ×
C(s)

∩Σj ̸= ∅for some i ̸= j, with both Ai(s) and Aj(s) having positive
¯φ-measure. Otherwise, the spn would be periodic with period d and sets
S1, S2, . . . , Sd in the d-cycle given by
Si = { s ∈G: s × C(s) ⊆Σi }
for 1 ≤i ≤d. Since ¯φ

Ai(s)

> 0, it follows from Lemma 3.7 that
Pµ { (Sj−1+nd, Cj−1+nd) ∈Ai(s) for some n ≥0 } > 0.
Thus Ai(s) ∩Σj ̸= ∅, contradicting the assumed disjointness of Σi and
Σj.

302
7. Alternative Simulation Methods
7.3.2
Consistent Estimation in Discrete Time
Let ¯r(n; ˜f) be deﬁned as in (3.3). As discussed previously, if Assumption PD
holds, then for any polynomially dominated function ˜f there exist constants
˜r( ˜f) and ˜σ( ˜f) such that limn→∞¯r(n; ˜f) = ˜r( ˜f) a.s. and √n

¯r(n; ˜f) −
˜r( ˜f)

⇒˜σ( ˜f)N(0, 1) as n →∞. Our goal is to ﬁnd estimators consistent
for ˜σ2( ˜f). We assume that ˜σ2( ˜f) > 0, and the estimators that we consider
are of the form
Vn = Vn( ˜f) =
n

i=0
n

j=0
˜f(Si, Ci) ˜f(Sj, Cj)q(n)
i,j ,
(3.9)
where each q(n)
i,j is a ﬁnite constant and q(n)
i,j = q(n)
j,i for all i, j. As discussed
in Section 7.3.3, this class of quadratic-form estimators includes both batch
means and spectral estimators.
When Assumption PD holds, it follows from Corollary 2.6 and the dis-
cussion in Section 5.1.1 that there exists an invariant probability measure
π for the underlying chain { (Sn, Cn): n ≥0 }. By applying general results
on consistent variance estimation for stationary processes, it can sometimes
be established that Vn( ˜f) ⇒˜σ2( ˜f) for a speciﬁed estimator Vn( ˜f) when the
initial distribution of the underlying chain is π. The following two propo-
sitions are useful in this connection and are obtained by direct application
of some well-known results for Harris ergodic chains.
Proposition 3.10. Let { (Sn, Cn): n ≥0 } be the underlying chain of an
aperiodic spn, and let ˜f be a polynomially dominated real-valued function
deﬁned on Σ. Suppose that Assumption PD holds, so that there exists an
invariant distribution π for the chain and { ˜f(Sn, Cn): n ≥0 } obeys a clt
with variance constant ˜σ2( ˜f). Then ˜σ2( ˜f) has the representation
˜σ2( ˜f) = lim
n→∞nVarπ

1
n
n−1

j=0
˜f(Sj, Cj)

.
(3.11)
Proposition 3.12. Suppose that Assumption PD holds for an aperiodic
spn. Then there exist ρ ∈(0, 1) and c ∈[0, ∞) such that
Covπ [ ˜f 1(S0, C0), ˜f 2(Sk, Ck)]
 ≤cρk
for k ≥0 and any polynomially dominated functions ˜f 1 and ˜f 2.
When the consistency of Vn( ˜f) for ˜σ2( ˜f) can be established under initial
distribution π, the key problem is then to show that Vn( ˜f) ⇒˜σ2( ˜f) even
when the initial distribution µ is not equal to π. Coupling arguments are
often employed to extend convergence results from a stationary to a non-
stationary setting, and use of this approach leads to Theorem 3.15 below.
To state the theorem, we need the following deﬁnition.

7.3 Consistent Estimation Methods
303
Deﬁnition 3.13. A quadratic-form estimator Vn is said to be localized
if there exist a constant a1 ∈(0, ∞) and sequences { a2(n): n ≥0 } and
{ m(n): n ≥0 } of nonnegative constants with a2(n) →0 and m(n)/n →0
such that
|q(n)
i,j | ≤

a1/n
if |i −j| ≤m(n);
a2(n)/n
if |i −j| > m(n).
(3.14)
A localized estimator has the property that, as more and more observations
of the output process are obtained, the inﬂuence of any one observation on
the value of the estimator becomes negligible.
Theorem 3.15. Let { (Sn, Cn): n ≥0 } be the underlying chain of an ape-
riodic spn, and let ˜f be a polynomially dominated real-valued function
deﬁned on Σ. Suppose that Assumption PD holds, so that there exists
an invariant distribution π for the chain and { ˜f(Sn, Cn): n ≥0 } obeys
a clt with variance constant ˜σ2( ˜f). If a localized quadratic-form estima-
tor Vn( ˜f) satisﬁes Vn( ˜f) ⇒˜σ2( ˜f) when the initial distribution is π, then
Vn( ˜f) ⇒˜σ2( ˜f) for any initial distribution.
Proof. Fix an arbitrary initial distribution µ, and write Zn = ˜f(Sn, Cn)
throughout. Corollary 3.5 implies that the underlying chain is Harris er-
godic. By Proposition 1.10 in Chapter 5, the chain admits coupling. Thus
there exist an a.s. ﬁnite random index T and versions { Zn : n ≥0 } and
{ Z′
n : n ≥0 } of the chain, all deﬁned on a common probability space
(Ω, F, P), such that the two versions have respective probability laws Pµ
and Pπ, and Zn = Z′
n for n ≥T. Denote by Vn and V ′
n the quadratic-form
estimator computed for the ﬁrst and second versions of the chain, respec-
tively. We prove the result under the assumption that supn m(n) = ∞, the
proof for the case supn m(n) < ∞being similar. Moreover, without loss of
generality we can assume that m(n) →∞as n →∞; otherwise, replace
m(n) by M(n) = max1≤k≤n m(k) in the following argument and observe
that (i) the estimator Vn is localized with respect to M(n) whenever it is lo-
calized with respect to m(n) and (ii) M(n)/n →0 whenever m(n)/n →0.
Suppose that n is suﬃciently large so that n > T + m(n). Then we have
Vn =
n

i=T
n

j=T
Z′
iZ′
jq(n)
i,j + R1(n) + R2(n) + R3(n),
where
R1(n) =
T −1

i=0
T −1

j=0
ZiZjq(n)
i,j ,
R2(n) =
T −1

i=0
n

j=T
ZiZ′
jq(n)
i,j ,

304
7. Alternative Simulation Methods
and
R3(n) =
n

i=T
T −1

j=0
Z′
iZjq(n)
i,j .
Clearly, R1(n) →0 a.s. as n →∞since each q(n)
i,j
is O(1/n). Assume
without loss of generality that a1 ≥supn a2(n) in Deﬁnition 3.13, and
observe that
|R2(n)| ≤
T −1

i=0
|Zi|

a1
n
T +m(n)

j=T
|Z′
j| + a2(n)
n
n

j=T +m(n)
|Z′
j|

.
Under our hypotheses, we have
lim
n→∞
1
m(n)
T +m(n)

j=T +1
|Z′
j| = E[ |Z′
1| ] < ∞a.s.
by Theorem 2.9, so that
lim
n→∞
a1
n
T +m(n)

j=T +1
|Z′
j| = lim
n→∞
a1m(n)
n

1
m(n)
T +m(n)

j=T +1
|Z′
j|
= 0 · E[ |Z′
1| ]
= 0 a.s..
Similarly, since a2(n) →0, we have
lim
n→∞
a2(n)
n
n

j=T +m(n)
|Z′
j| ≤lim
n→∞
a2(n)
n
n

j=0
|Z′
j| = 0 · E[ |Z′
1| ] = 0 a.s.,
so that R2(n) →0 a.s.. An almost identical argument shows that R3(n) →0
a.s.. In a similar manner, we have
V ′
n =
n

i=T
n

j=T
Z′
iZ′
jq(n)
i,j + R′(n),
where R′(n) →0 a.s.. Thus V ′
n −Vn →0 a.s., and the desired result follows
from the converging-together lemma (Proposition 1.44 in the Appendix).

7.3 Consistent Estimation Methods
305
7.3.3
Applications to Batch-Means and Spectral Methods
In this section we discuss some speciﬁc estimators of ˜σ2( ˜f) that satisfy the
conditions of the previous subsection.
Batch Means
For a stationary process { Zn : n ≥0 } with variance constant
˜σ2 = lim
n→∞nVar

1
n
n−1

j=0
Zj

,
(3.16)
the standard (discrete time) batch means estimator of ˜σ2 based on b batches
of length m is given by
V (B)
n
=
m
b −1
b

j=1
 ¯Xn(j) −¯Xn
2
(3.17)
for n = bm (the case that we always consider), where
¯Xn(j) = 1
m
jm−1

i=(j−1)m
Zi
(3.18)
is the jth batch mean (1 ≤j ≤b) and ¯Xn = (1/b) 	b
j=1 ¯Xn(j). The
reasoning behind this estimator is the same as in Section 7.2.2: for large n,
write
˜σ2 ≈nVar

1
n
n−1

j=0
Zj

= 1
nVar
 b

j=1
m ¯Xn(j)

= m2
n Var
 b

j=1
¯Xn(j)

.
Assuming that, to a good approximation, the batch means are i.i.d., we
have
m2
n Var
 b

j=1
¯Xn(j)

≈bm2
n Var[ ¯Xn(1)] = mVar[ ¯Xn(1)].
Estimating Var[ ¯Xn(1)] by the sample variance of the batch means yields
the estimator in (3.17).
If the number of batches remains ﬁxed as the simulation run length
n increases—as in Section 7.2.2—then V (B)
n
is not consistent for ˜σ2 in
general, and batch means is a cancellation method. We therefore assume
that b = b(n) and m = m(n) with b(n) →∞and m(n) →∞as n →∞.
Typically, b(n) = O(na) and m(n) = O(n1−a) for some a ∈(0, 1); one
popular choice is a = 2/3, which results in variance estimators that have
small mean-squared errors.
By expanding the formula for the mean-squared error of Vn and using
inequalities of the Cauchy–Schwarz type to bound the resulting terms, the
following general result can be established.

306
7. Alternative Simulation Methods
Proposition 3.19. Let { Zn : n ≥0 } be a stationary process with ﬁnite
variance constant ˜σ2, and let V (B)
n
be the batch-means estimator of ˜σ2.
Suppose that E[Z12
n ] < ∞and, for p, q, k ≥0,
Cov [Zp
0, Zq
k]
 ≤c(p, q)k−9/2,
where c(p, q) ∈(0, ∞). Also suppose that m(n) →∞and b(n) →∞as
n →∞. Then
lim
n→∞E

V (B)
n
−˜σ22
= 0,
and hence V (B)
n
⇒˜σ2.
Note that the ﬁnal assertion of the proposition is a consequence of the
fact that L2-convergence implies convergence in probability—see Proposi-
tion 1.39(v) in the Appendix.
In the spn setting and for a speciﬁed function ˜f, the estimator V (B)
n
is deﬁned as in (3.17) and (3.18), with Zn = ˜f(Sn, Cn) for n ≥0. The
following result gives conditions on ˜f and on the building blocks of an spn
under which V (B)
n
is consistent for ˜σ2( ˜f).
Theorem 3.20. Let { (Sn, Cn): n ≥0 } be the underlying chain of an ape-
riodic spn, and let V (B)
n
be given by (3.17) and (3.18) with Zn = ˜f(Sn, Cn),
where ˜f is a polynomially dominated real-valued function deﬁned on Σ.
Suppose that Assumption PD holds, so that { ˜f(Sn, Cn): n ≥0 } obeys a
clt with variance constant ˜σ2( ˜f). Also suppose that the number of batches
b = b(n) and batch length m = m(n) satisfy b(n) →∞and m(n) →∞as
n →∞. Then V (B)
n
⇒˜σ2( ˜f) as n →∞.
Proof. There exists an invariant distribution π for the underlying chain
{ (Sn, Cn): n ≥0 } and, by Proposition 3.10, ˜σ2( ˜f) can be represented as a
limiting variance of the form (3.11). Proposition 1.13 in Chapter 5 implies
that Eπ[| ˜f q(Sn, Cn)|] < ∞for q ≥0, and Proposition 3.12 implies that
|Covπ [ ˜f p(S0, C0), ˜f q(Sk, Ck)] | = o(kl) for l ∈{ 1, 2, . . . } and p, q ≥0. We
therefore can apply Proposition 3.19 to show that V (B)
n
⇒˜σ2( ˜f) when the
initial distribution is π. Observe that V (B)
n
can be written in the form (3.9),
with
q(n)
i,j =



(n + 1)−1
if (Si, Ci) and (Sj, Cj) are in the
same batch;
−

b(n −m + 1)
−1
otherwise.
Clearly, V (B)
n
is a localized estimator, and an application of Theorem 3.15
yields the desired result.
Spectral Methods
Let { Zn : n ≥0 } be a stationary process with common mean r = E [Z0]
and variance constant ˜σ2 as in (3.16). Classical spectral estimators of ˜σ2

7.3 Consistent Estimation Methods
307
based on observations Z0, Z1, . . . , Zn−1 have the form
V (S)
n
=
m−1

h=−(m−1)
λ(h/m) ˆRh,
(3.21)
where
ˆRh =
1
n −|h|
n−|h|−1

i=0
(Zi −¯Zn)(Zi+|h| −¯Zn)
(3.22)
and ¯Zn = (1/n) 	n−1
i=0 Zi. The function λ is the “lag window,” and we
assume throughout that the “window length” m = m(n) satisﬁes m(n) →
∞and m2(n)/n →0. Here ˆRh (h ≥0) estimates the lag-h covariance
ρ(h) = Cov [Z0, Zh] .
Diﬀerent choices of the lag window lead to diﬀerent estimators. Well-known
windows include the modiﬁed Bartlett window λ(h) = 1−|h|, the Hanning
window λ(h) = 0.5+0.5 cos(πh), and the Parzen window 1−h2. In general,
we consider the class Λ of windows such that λ ∈Λ if and only if
1. λ is continuous on [−1, 1].
2. λ(x) = λ(−x).
3. λ(0) = 1.
4. λ(x) = 0 for x ̸∈[−1, 1].
5. sup−1≤x≤1 |λ(x)| < ∞.
6. limx→0

1 −λ(x)

/|x|q = α for some q, α ∈(0, ∞).
It can be shown that all the foregoing windows belong to Λ.
The following result from the time-series literature gives conditions under
which V (S)
n
⇒˜σ2. To state this result, we use the fact that any stationary
time series { Zn : n ≥0 } can be extended to a two-sided stationary time
series { Zn : −∞< n < ∞}.
Proposition 3.23. Let V (S)
n
be given by (3.21) and (3.22) with λ ∈Λ,
and suppose that the window length m = m(n) satisﬁes m(n) →∞and
m2(n)/n →0. Also suppose that
∞

n=0
np|ρ(n)| < ∞
(3.24)
for p ≥0 and
∞

i,j,k=−∞
|κ(i, j, k)| < ∞,
(3.25)

308
7. Alternative Simulation Methods
where
κ(i, j, k) = Eπ

Zn −r

Zn+i −r

Zn+j −r

Zn+k −r

−ρ(i)ρ(j −k) −ρ(j)ρ(i −k) −ρ(k)ρ(i −j).
Then
lim
n→∞E

V (S)
n
−˜σ22
= 0,
and hence V (S)
n
⇒˜σ2.
In the spn setting and for a speciﬁed function ˜f, the estimator V (S)
n
is
deﬁned by (3.21) and (3.22) with Zn = ˜f(Sn, Cn) for n ≥0. Theorem 3.26
gives conditions under which V (S)
n
is consistent for ˜σ2( ˜f).
Theorem 3.26. Let { (Sn, Cn): n ≥0 } be the underlying chain of an ape-
riodic spn. Also let V (S)
n
be deﬁned by (3.21) and (3.22) with λ ∈Λ and
Zn = ˜f(Sn, Cn), where ˜f is a polynomially dominated real-valued function
deﬁned on Σ. Suppose that Assumption PD holds, so that { ˜f(Sn, Cn): n ≥
0 } obeys a clt with variance constant ˜σ2( ˜f). Also suppose that the spec-
tral window length m = m(n) satisﬁes m(n) →∞and m2(n)/n →0. Then
V (S)
n
⇒˜σ2( ˜f) as n →∞.
Proof. (Sketch) Write Wn = (Sn, Cn) for n ≥0 and let π be the invariant
probability measure of the underlying chain. A conditioning argument in
combination with Proposition 3.12 shows that there exist β ∈(0, 1) and
C ∈(0, ∞) such that
Eπ

ˆf1(Wn) ˆf2(Wn+i) ˆf3(Wn+j) ˆf4(Wn+k)
 ≤Cβiβj−iβk−j
for all integers 0 ≤i < j < k and polynomially dominated real-valued
functions ˜f 1, ˜f 2, ˜f 3, ˜f 4, where ˆfi(w) = ˜f i(w) −π( ˜f i) for 1 ≤i ≤4. Simi-
lar inequalities can be established for other orderings of i, j, and k (e.g.,
k < j ≤0 < i), as well as for products of two or three terms. (Indeed,
Proposition 3.12 applies to products of two terms.) Using these inequali-
ties, we can then show that (3.24) holds for p ≥0 and that (3.25) holds,
where ρ(n) = Covπ [ ˜f(W0), ˜f(Wn)] and
κ(i, j, k) = Eπ

ˆf(Wn) ˆf(Wn+i) ˆf(Wn+j) ˆf(Wn+k)

−ρ(i)ρ(j −k) −ρ(j)ρ(i −k) −ρ(k)ρ(i −j)
with ˆf(w) = ˜f(w) −π( ˜f). Propositions 3.10 and 3.23 then imply that
V (S)
n
⇒˜σ2( ˜f) when the initial distribution is π. We can write the estimator
V (S)
n
in the form (3.9), with
q(n)
i,j = λ(|i −j|/m)
n + 1
−
1
2(n + 1)2
m−1

h=−(m−1)
c(n)
i,j (h)λ(h/m)

7.3 Consistent Estimation Methods
309
and
c(n)
i,j (h) = I(i ≥|h|) + I(i < n −|h|)
+ I(j ≥|h|) + I(j < n −|h|) −2

1 −
|h|
n + 1

.
[Here I(A) is the indicator of the condition in A.] It can be seen by
inspection that V (S)
n
is a localized estimator so that, by Theorem 3.15,
V (S)
n
⇒˜σ2( ˜f) for any initial distribution.
7.3.4
Functions of Time-Average Limits
Our development is similar to that in Section 6.3.5. Fix l ≥1 and let
˜f = ( ˜f 1, ˜f 2, . . . , ˜f l) be an ℜl-valued function deﬁned on Σ that is poly-
nomially dominated in the sense that each ˜f i is polynomially dominated
for 1 ≤i ≤l. If Assumption PD holds, then there exists an l-vector
˜r( ˜f) =

˜r( ˜f 1), ˜r( ˜f 2), . . . , ˜r( ˜f l)

such that ¯r(n; ˜f) →˜r( ˜f) a.s., where
¯r(n; ˜f) = 1
n
n−1

j=0
˜f(Sn, Cn)
as before—of course, ¯r(n; ˜f) is now an l-vector. We consider estimation
methods for quantities of the form
r = g

˜r( ˜f)

= g

˜r( ˜f 1), ˜r( ˜f 2), . . . , ˜r( ˜f l)

,
(3.27)
where g: ℜl →ℜis diﬀerentiable in a neighborhood of ˜r( ˜f).
Since diﬀerentiability implies continuity, it follows from the a.s. conver-
gence of ¯r(n; ˜f) to ˜r( ˜f) that the estimator rn = g

¯r(n; ˜f)

is strongly
consistent for r. To obtain an asymptotic conﬁdence interval for r, we
start with the following result, which is a consequence of Theorem 2.9,
Proposition 3.10, and the Cram´er–Wold theorem (Proposition 1.46 in the
Appendix).
Theorem 3.28. Let { (Sn, Cn): n ≥0 } be the underlying chain of an ape-
riodic spn, and let ˜f = ( ˜f 1, ˜f 2, . . . , ˜f l) be a polynomially dominated ℜl-
valued function deﬁned on Σ. Suppose that Assumption PD holds, so that
there exists an invariant measure π for the chain and ¯r(n; ˜f) →˜r( ˜f) a.s.
for some ﬁnite l-vector ˜r( ˜f). Then
√n

¯r(n; ˜f) −˜r( ˜f)

⇒N(0, W)
as n →∞, where N(0, W) is a multivariate normal random vector with
covariance matrix W = ∥ws,t∥given by
ws,t = lim
n→∞nCovπ

¯r(n; ˜f s), ¯r(n; ˜f t)

.
(3.29)

310
7. Alternative Simulation Methods
When the conclusion of Theorem 3.28 holds, an application of the delta
method—see Proposition 1.45 in the Appendix—shows that
√n(rn −r) ⇒σN(0, 1)
as n →∞, where
σ2 = ∇g

˜r( ˜f)
t W ∇g

˜r( ˜f)

.
Our goal, then, is to consistently estimate σ2.
Given a quadratic-form variance estimator as in Section 7.3.2 with coef-
ﬁcients q(n)
i,j , we can deﬁne an l × l matrix Wn = ∥Vn(s, t)∥, where
Vn(s, t) =
n

i=0
n

j=0
˜f s(Si, Ci) ˜f t(Sj, Cj)q(n)
i,j
for s, t ∈{ 1, 2, . . . , l }. For the batch-means estimator of the previous sub-
section, the calculations that establish the convergence Vn(s, s) ⇒ws,s
when the initial distribution is π can be modiﬁed in a straightforward way
to show that Vn(s, t) ⇒ws,t for s ̸= t. Thus Wn ⇒W when the initial
distribution is π and the conditions of Theorem 3.20 hold. Similarly, for the
spectral estimators of the previous subsection, Wn ⇒W when the initial
distribution is π and the conditions of Theorem 3.26 hold.
The coupling argument used to establish Theorem 3.15 can similarly be
extended to obtain Theorem 3.30 below. In the theorem, the matrix Wn is
said to be a localized estimator of W if and only if each q(n)
i,j satisﬁes (3.14).
Theorem 3.30. Let { (Sn, Cn): n ≥0 } be the underlying chain of an ape-
riodic spn, and let ˜f be a polynomially dominated ℜl-valued function de-
ﬁned on Σ. Suppose that Assumption PD holds, so that there exists an
invariant distribution π for the chain and { ˜f(Sn, Cn): n ≥0 } obeys a clt
with covariance matrix W. If a localized estimator Wn satisﬁes Wn ⇒W
when the initial distribution is π, then Wn ⇒W for any initial distribution.
The foregoing results can be combined to yield conﬁdence intervals for
r = g

˜r( ˜f)

. Suppose, for example, that Wn is the batch-means estimator
of W and the conditions of Theorem 3.20 hold, or that Wn is a spectral
estimator of W and the conditions of Theorem 3.26 hold. Set
σ2
n = ∇g

¯r(n; ˜f)
t Wn ∇g

¯r(n; ˜f)

for n ≥1. Since ¯r(n; ˜f) →˜r( ˜f) a.s. by Theorem 3.28 and Wn ⇒W by The-
orem 3.30, it follows from the diﬀerentiability (and hence continuity) of g at
˜r( ˜f) together with the continuous mapping theorem—see Proposition 1.42
in the Appendix—that σ2
n ⇒σ2. Thus
√n(rn −r)
σn
⇒N(0, 1),

7.3 Consistent Estimation Methods
311
and
!
rn −zp σn
√n , rn + zp σn
√n
"
is an asymptotic 100p% conﬁdence interval for r, where zp is the (1 + p)/2
quantile of the standard normal distribution.
7.3.5
Consistent Estimation in Continuous Time
As before, we assume that the spn of interest is aperiodic and that As-
sumption PD holds, so that, by Theorem 2.14, ¯r(t; f) →r(f) a.s. for some
ﬁnite constant r(f) and any real-valued function f deﬁned on G; here
¯r(t; f) = 1
t
 t
0
f

X(u)

du
as before. We now ﬁx f and consider the problem of obtaining an asymp-
totic conﬁdence interval for r(f). As before, let t∗be the holding-time
function and set (ft∗)(s, c) = f(s)t∗(s, c). Using Theorems 2.9 and 2.14,
we ﬁnd that
r(f) = lim
t→∞¯r(t; f) = Eµ [ ˜Y 1(ft∗)]
Eµ[ ˜Y1(t∗)]
= Eµ [ ˜Y 1(ft∗)] /Eµ[˜τ1]
Eµ[ ˜Y1(t∗)]/Eµ[˜τ1]
= ˜r(ft∗)
˜r(t∗) ,
where ˜r( ˜f) = limn→∞(1/n) 	n−1
j=0 ˜f(Sn, Cn) as before. Thus r(f) can be
expressed in the form (3.27) with ˜f = (ft∗, t∗) and g(x, y) = x/y. We
therefore can apply the methods of the previous subsection.
Let ∥q(n)
i,j ∥be a set of coeﬃcients such that, for any polynomially domi-
nated functions ˜f s and ˜f t deﬁned on Σ, the quadratic-form estimator
Vn( ˜f s, ˜f t) =
n

i=0
n

j=0
˜f s(Si, Ci) ˜f t(Sj, Cj)q(n)
i,j
is consistent for ws,t, where ws,t is given by (3.29). (The coeﬃcients for
the variable batch-means and spectral methods satisfy this condition, for
example.) Then
!
ˆrn −zp σn
√n , ˆrn + zp σn
√n
"
(3.31)
is an asymptotic 100p% conﬁdence interval for r(f), where
ˆrn = ¯r(n; ft∗)
¯r(n; t∗) ,
σ2
n =
1
¯r2(n; t∗)

Vn(1, 1) −2ˆrnVn(1, 2) + ˆr2
nVn(2, 2)

,
(3.32)

312
7. Alternative Simulation Methods
and zp is the (1 + p)/2 quantile of the standard normal distribution. Here
¯r(n; ˜f) is deﬁned as in (3.3),
Vn(1, 1) =
n

i=0
n

j=0
(ft∗)(Si, Ci) (ft∗)(Sj, Cj) q(n)
i,j ,
Vn(1, 2) =
n

i=0
n

j=0
(ft∗)(Si, Ci) t∗(Sj, Cj) q(n)
i,j ,
and
Vn(2, 2) =
n

i=0
n

j=0
t∗(Si, Ci) t∗(Sj, Cj) q(n)
i,j .
Example 3.33 (Variable batch means). For real-valued functions ˜f and ˜g
deﬁned on Σ, extend the notation in (3.17) and (3.18) by setting
V (B)
n
( ˜f, ˜g) =
m
b −1
b

j=1
 ¯Xn(j; ˜f) −¯Xn( ˜f)
 ¯Xn(j; ˜g) −¯Xn(˜g)

,
where
¯Xn(j; ˜h) = 1
m
jm−1

i=(j−1)m
˜h(Si, Ci)
and
¯Xn(˜h) = 1
b
b

j=1
¯Xn(j; ˜h)
for ˜h = ˜f, ˜g. Then, for the method of variable batch means in continuous
time, the variance constant σ2
n that appears in the conﬁdence-interval for-
mula (3.31) is given by (3.32), with Vn(1, 1) = V (B)
n
(ft∗, ft∗), Vn(2, 2) =
V (B)
n
(t∗, t∗), and Vn(1, 2) = V (B)
n
(ft∗, t∗).
Example 3.34 (Spectral methods).
For real-valued functions ˜f and ˜g
deﬁned on Σ, extend the notation in (3.21) and (3.22) by setting
V (S)
n
( ˜f, ˜g) = λ(0) ˆR0( ˜f, ˜g) +
m−1

h=1
λ(h/m) ˆRh( ˜f, ˜g) +
m−1

h=1
λ(h/m) ˆRh(˜g, ˜f),
where
ˆRh( ˜f, ˜g) =
1
n −h
n−h−1

i=0
 ˜f(Si, Ci) −¯Zn( ˜f)

˜g(Si+h, Ci+h) −¯Zn(˜g)

,

7.3 Consistent Estimation Methods
313
Table 7.1. Simulation Results for Cyclic Queues with Feedback: Point Estimates
and 95% Conﬁdence-Interval Half-Widths for the Long-Run Average Number of
Jobs at Center 1 (True Value = 2.5823)
Simulation Length
Estimator
50
100
1000
10000
100000
regenerative (jack.)
2.6027
2.5908
2.5775
2.5833
2.5823
±0.6529
±0.5152
±0.1819
±0.0579
±0.0183
batch means (cont.)
2.6393
2.6059
2.5795
2.5834
2.5823
±0.5030
±0.4506
±0.1896
±0.0606
±0.0191
batch means (discr.)
2.6507
2.6097
2.5798
2.5835
2.5823
±0.6022
±0.5044
±0.1919
±0.0611
±0.0191
sts area
2.6393
2.6059
2.5795
2.5834
2.5823
±0.2362
±0.2645
±0.1780
±0.0598
±0.0193
spectral (Bartlett)
2.6446
2.6058
2.5795
2.5834
2.5823
±0.5399
±0.4267
±0.1618
±0.0549
±0.0179
spectral (Parzen)
2.6446
2.6058
2.5795
2.5834
2.5823
±0.5791
±0.4588
±0.1725
±0.0571
±0.0183
spectral (Hanning)
2.6446
2.6058
2.5795
2.5834
2.5823
±0.5448
±0.4326
±0.1657
±0.0563
±0.0182
var. batch means
2.6437
2.6051
2.5792
2.5834
2.5823
±0.5544
±0.4292
±0.1629
±0.0550
±0.0179
Note: Each reported number is an average over 500 simulation repetitions.
¯Zn( ˜f) = 1
n
n−1

i=0
˜f(Si, Ci),
and
¯Zn(˜g) = 1
n
n−1

i=0
˜g(Si, Ci).
Then, for a spectral method in continuous time with lag window λ, the
variance constant σ2
n that appears in the conﬁdence-interval formula (3.31)
is given by (3.32), with Vn(1, 1) = V (S)
n
(ft∗, ft∗), Vn(2, 2) = V (S)
n
(t∗, t∗),
and Vn(1, 2) = V (S)
n
(ft∗, t∗).
Example 3.35 (Cyclic queues with feedback). We illustrate the various
estimation methods discussed in this chapter using the closed network of
queues in Example 1.4 of Chapter 2. Similarly to Example 3.50 of Chap-
ter 6, successive service times at center i (i = 1, 2) are i.i.d. according to an
exponential distribution with intensity qi, where q1 = 1.1 and q2 = (1.1)3/2.
The routing probability (with which a job completing service at center 1
moves to center 2) is p = 0.775. There are N = 4 jobs, and we model the
system using the spn in Figure 2.2. For this model, there are roughly 1.7
transitions per time unit.

314
7. Alternative Simulation Methods
Table 7.2. Simulation Results for Cyclic Queues with Feedback: Empirical Cov-
erage Probabilities when Estimating the Long-Run Average Number of Jobs at
Center 1 with Nominal Coverage Probability of 95%, Based on 500 Simulation
Repetitions
Simulation Length
Estimator
50
100
1000
10000
100000
regenerative
0.798
0.852
0.926
0.946
0.948
batch means (cont.)
0.770
0.860
0.938
0.946
0.949
batch means (discr.)
0.816
0.886
0.942
0.946
0.948
sts area
0.436
0.636
0.930
0.960
0.951
spectral (Bartlett)
0.782
0.842
0.902
0.938
0.947
spectral (Parzen)
0.800
0.854
0.918
0.942
0.946
spectral (Hanning)
0.788
0.844
0.908
0.940
0.948
var. batch means
0.786
0.838
0.904
0.932
0.945
We use the following methods to estimate r(f), the long-run average
number of jobs at center 1:
1. The regenerative method with jackkniﬁng. We use the variant of the
standard regenerative discussed in Section 6.3.2. The regeneration
points are the successive times at which there is a completion of
service at center 1 with all jobs at center 1. Estimates are based on
the number of cycles completed in [0, t], where t is the simulation
length. A cycle is approximately 2.5 time units long on average.
2. The method of batch means in continuous time. Estimates are based
on b = 20 batches.
3. The method of batch means in discrete time. We use the jackknife
technique as in Remark 2.36. Estimates are based on approximately2
b = 20 batches.
4. The sts area method. We use a value of m = 20.
5. Spectral methods. We use the approach described in Example 3.34
with modiﬁed-Bartlett, Parzen, and Hanning lag windows. The win-
dow length is m(n) = n1/3, rounded to the nearest integer.
2When the length of the simulation is t, denote by n(t) the total number of discrete-
time observations: n(t) = sup { n ≥0: t∗(S0, C0) + · · · + t∗(Sn−1, Cn−1) ≤t }. In gen-
eral, the nominal batch length n(t)/b is not an integer, and so we choose the batch
length to be either m′ = ⌊n(t)/b⌋or m′ = ⌈n(t)/b⌉. The actual number of batches is
therefore b′ = ⌊n(t)/m′⌋, and we choose m′ so as to minimize n(t) −b′m′, the number
of discarded observations.

7. Notes
315
6. The method of variable batch means. We use the approach described
in Example 3.33 with the number of batches approximately equal to
b(n) = n2/3.
Point estimates and 95% conﬁdence-interval half-widths for r(f) are dis-
played in Table 7.1. Each displayed number represents an average over
500 i.i.d. simulation repetitions. Thus, for example, when the simulation
length is t = 100 time units, the expected value of the jackknifed regen-
erative estimator is approximately 2.5908, the bias of the point estimator
is approximately 2.5908 −2.5823 = 0.0085, and the expected half-width
of the 95% conﬁdence interval is 0.5152. Table 7.2 displays empirical cov-
erage probabilities, also based on 500 i.i.d. simulation repetitions. These
probabilities correspond to the nominal coverage probability of 95%.
In this example, the various estimation methods yield fairly similar point
estimates and conﬁdence intervals. Observe that the empirical probabili-
ties tend to be less than the nominal value, with the undercoverage being
particularly severe at small run lengths. This is perhaps to be expected,
since the coverage of an asymptotic conﬁdence interval is only guaranteed
to be close to the nominal value when the run length is large. When the
simulation length is large (105 time units), there is essentially no bias in the
point estimators, and the coverage of each algorithm is close to the nominal
value of 0.95. Moreover, the conﬁdence-interval lengths for the consistent
estimation methods are slightly shorter than those for the sts methods.
The performance of each of the nonregenerative methods is in general
sensitive to the settings of the various algorithm parameters. For exam-
ple, the sts area method does not perform well at short run lengths, with
coverages of 0.436 and 0.636 at run lengths of 50 and 100 time units, re-
spectively. When the parameter m is decreased from m = 20 to m = 5,
however, the empirical coverage increases dramatically, with respective val-
ues of 0.808 and 0.878 and half-widths of 0.6389 and 0.5716—values that
are comparable to the other methods. An important open problem is to
develop theoretically sound and practically eﬀective methods for setting
parameter values.
Notes
The video-on-demand system in Example 1.1 is closely related to the mod-
els of noninteractive video-on-demand studied by Aggarwal et al. (1995)
and Pyssysalo and Ojala (1995). Example 1.2 was suggested by Peter
Glynn. The method discussed in Remark 1.3 for dealing with the prob-
lem in Example 1.2 was pointed out by Shane Henderson and is closely
related to ideas in Andradottir et al. (1994), Glynn (1989b), and Hender-
son and Glynn (1999b). Minh (1987) provides a specialized technique for
regenerative simulation of GI/G/k queues in heavy traﬃc.

316
7. Alternative Simulation Methods
The discussion of sts methods for spns follows Haas (1999a, 1999c).
Some basic references on the method of batch means include Conway (1963)
and Brillinger (1973). Schmeiser (1982) gives recommendations on the num-
ber of batches. Schruben (1983) introduced the general class of sts methods
and specialized the approach to yield the sts maximum and sts area meth-
ods. Other sts methods include the method of spaced batch means (with
the number of batches independent of the simulation run length) as given
by Fox et al. (1991) and the sts weighted-area method (Goldsman et al.,
1990; Goldsman and Schruben, 1990).
In general, it can be diﬃcult to determine for a speciﬁc spn and function
f whether the output process

f

X(t)

: t ≥0

obeys an slln, so that the
time-average limit is well deﬁned. It is even harder to determine whether
sts methods can be used to estimate the time-average limit, assuming that
it exists. Birkhoﬀ’s ergodic theorem gives general conditions under which a
stochastic process obeys an slln; see, for example, Breiman (1968, Chap-
ter 6) or Durrett (1991, Section 6.2). A key condition of the ergodic theorem
is that the process be stationary. Brillinger (1973) establishes the validity of
the batch-means method under the stationarity assumption, and Schruben
(1983) establishes an analogous result for the sts maximum and sts area
methods. In the simulation setting, however, the initial marking and clock
readings of an spn usually cannot be selected so as to ensure stationarity.
Glynn and Iglehart (1990) were the ﬁrst to avoid stationarity conditions by
showing that sts methods are applicable under the sole assumption that
the output process obeys an fclt. They also showed that the method of
batch means (with the number of batches independent of the simulation
run length) can be viewed as an sts method. In addition, they showed that
consistent estimation methods lead to shorter and less variable asymptotic
conﬁdence-interval lengths than cancellation methods.
The idea behind the proof of the fclt in Proposition 2.3 is that { Yk(f) :
k ≥1 } is a sequence of o.d.s. random vectors. It therefore follows from a
multivariate extension of Proposition 2.24 in the Appendix that the process
{ Yk(f): k ≥1 } satisﬁes an fclt. A standard random-time-change argu-
ment using Proposition 2.25 in the Appendix—see the proof of Theorem 1
in Glynn and Whitt (1987)—then yields the desired result. In an anal-
ogous manner, Theorem 2.12 and a random-time-change argument yield
Theorem 2.17; see Haas (1999a, 1999c) for details.3
The convergence results in Remark 2.10 can be strengthened consider-
ably. See, for example, Meyn and Tweedie (1993a, Chapters 13–16) for the
discrete-time case and Meyn and Tweedie (1993b, 1993c) for the continu-
ous-time case.
3Haas (1999a, 1999c) actually uses a slightly diﬀerent form of the fclt for the un-
derlying chain than Theorem 2.12, but the argument is essentially identical.

7. Notes
317
Our discussion of the general theory of sts methods follows Glynn and
Iglehart (1990). The original paper contains some minor errors in the au-
thors’ demonstration that the sts area method and sts maximum method
follow as special cases of the general theory—certain Student’s t statistics
are formed without dividing the χ2 statistic in the denominator by the
degrees of freedom. Our presentation of the computationally eﬃcient rep-
resentation of the quantity Ai in the sts area method follows the discussion
in Goldsman et al. (1990). See Glynn and Whitt (1988, Theorem 4) for a
proof of the assertion that an slln implies a functional slln.
The extended batch-means methodology in Section 7.2.3 is due to Mu˜noz
and Glynn (1997). Mu˜noz and Glynn (2001) extend the methods of Sec-
tion 7.2.2 to the multivariate setting and provide techniques for construct-
ing a simultaneous conﬁdence region for two or more time-average limits.
For discussions of the method of variable batch means, see, for example,
Carlstein (1986), Chien (1989), Chien et al. (1997), Damerdji (1994, 1995),
and Song and Schmeiser (1995). It is shown in Damerdji and Goldsman
(1995) that many sts methods have variants that are consistent estima-
tion methods. Many authors have studied spectral estimation methods,
both within the general setting of time-series analysis (Anderson, 1971;
Brockwell and Davis, 1987; Grenander and Rosenblatt, 1984) and within
the speciﬁc setting of simulation (Bratley et al., 1987; Damerdji, 1991; Hei-
delberger and Welch, 1981). Song and Schmeiser (1993) give quadratic-
form representations for a variety of estimators, including batch-means
and spectral estimators. Note that our formulas diﬀer from those in Song
and Schmeiser (1993) by a factor of n; the latter paper is concerned with
Varπ [¯r(n)] rather than nVarπ [¯r(n)].
The method of batch means studied in this chapter has the property that
the batches are disjoint. Variants of the basic method allow some degree of
overlap between batches. The terminology “overlapping batch means” typi-
cally refers to the method in which the batches have maximal overlap. That
is, batch 1 consists of observations Z0, Z1, . . . , Zm−1, batch 2 consists of
observations Z1, Z2, . . . , Zm, and so forth. Song and Schmeiser (1993) give
a quadratic-form representation for the overlapping-batch-means estima-
tor. The method of overlapping batch means was ﬁrst studied by Meketon
and Schmeiser (1984). These authors noted that the method of overlap-
ping batch means and the spectral method with the Bartlett window are
asymptotically equivalent as the run length becomes large; see also Song
and Schmeiser (1993) and Welch (1987).
Damerdji (1991, 1994, 1995) and Damerdji and Goldsman (1995) estab-
lish the validity of several consistent estimation methods when the output
process of the simulation obeys a strong invariance principle (also called
a strong approximation). Roughly speaking, a strong invariance principle
is a strengthening of an fclt in which convergence to a limiting Brown-
ian motion holds with probability 1. The appeal of this approach is that,
when a strong invariance principle holds, the estimator of the variance con-

318
7. Alternative Simulation Methods
stant not only converges in distribution—see Damerdji (1995)—but often
with probability 1; see Damerdji (1991, 1994) and Damerdji and Goldsman
(1995). This latter “strong” consistency is needed, for example, to estab-
lish the validity of sequential stopping rules for simulations; see Glynn and
Whitt (1992b). It is highly nontrivial, however, to establish strong invari-
ance principles for speciﬁc estimation methods. For example, it appears
diﬃcult—using currently known suﬃcient conditions for the strong invari-
ance principle—to establish the validity of estimation methods such as the
popular version of variable batch means in which the number of batches
grows as the 2/3 power of the run length.
In this chapter, sllns, fclts and clts for both the marking process
and underlying chain of an spn are established under Assumption PD—
see Theorems 2.9, 2.12, 2.14, and 2.17, as well as the results in (3.1) and
(3.2). All of these results can be established under weaker conditions on
the moments of the clock-setting distributions—that is, the clock-setting
distribution functions need not be elements of G+. The idea is to adapt
certain results established by Glynn and Haas (2002b) for gsmps. For sim-
plicity, suppose that all transitions are timed. Let t∗be the usual holding-
time function and for u ≥0 denote by Hu the set of real-valued functions
˜f deﬁned on Σ such that | ˜f(s, c)| ≤a + b

t∗(s, c)
u for some a, b ≥0.
Also suppose that there exists a sequence { θ(k): k ≥0 } of od-regeneration
points for the underlying chain, and deﬁne ˜Y ( ˜f) as in (2.4). It follows from
Glynn and Haas (2002b) that if each clock-setting distribution function
has ﬁnite rth moment, where r = q max(u, 1) for some q ∈{ 1, 2, . . . } and
u ≥0, then Eµ[ ˜Y q(| ˜f|)] < ∞for any function ˜f ∈Hu. In particular,
if each clock-setting distribution function has ﬁnite rth moment—where
r = 2 max(u, 1) for some u ≥0—and satisﬁes the remaining conditions
of Assumption PD, then the output process { ˜f(Sn, Cn): n ≥0 } obeys an
slln, clt, and fclt for any ˜f ∈Hu. It follows that the continuous-time
process

f

X(t)

: t ≥0

obeys an slln, clt, and fclt for any real-valued
function f, provided that each clock-setting distribution function has ﬁnite
second moment and the remaining conditions of Assumption PD hold.
See Billingsley (1986, Theorem A21) for a proof of Lemma 3.6. Propo-
sitions 3.10 and 3.12 follow from Theorems 17.5.3 and Theorem 16.1.5 in
Meyn and Tweedie (1993a), respectively. The proof of Proposition 3.19 fol-
lows from the proof of Corollary 1 in Chien et al. (1997). In this corollary,
the requirement that
Cov [Zp
0, Zq
k]
 ≤c(p, q)k−9/2 for p, q, k ≥0 is replaced
by the requirement that { Zn : n ≥0 } is φ-mixing (see Section A.2.2) with
φk = O(k−9). Examination of the proof of the corollary shows that the sole
purpose of the latter assumption is to bound covariances of the foregoing
type, using the inequality
Cov [Zp
0, Zq
k]
 ≤2
8
φkE[Z2p
0 ]E[Z2q
k ],

7. Notes
319
which follows from Lemma 1 in Section 20 of Billingsley (1968). The discus-
sion of spectral estimators follows Anderson (1971), who shows that each
of the lag windows mentioned in the text belongs to the class Λ, and whose
Theorems 9.4.3 and 9.4.4 jointly imply Proposition 3.23. For some esti-
mation methods, consistency of the variance estimator can be established
under weaker conditions than are given here—see Glynn and Haas (2002a).
As discussed in Example 3.35, most of the simulation methods discussed
in this chapter have parameters for which values must be chosen: num-
ber of batches, batch lengths, lag-window lengths, and so forth. Currently,
there is scant theoretical guidance on how to set these parameters. Even
the choice of simulation run length is nontrivial. It seems reasonable to
use a sequential stopping rule to determine the run length—indeed, sev-
eral sequential estimation methods have been proposed in the literature.
As mentioned above, however, the estimator of the variance constant σ2(f)
or ˜σ2( ˜f) must be strongly consistent for such methods to be valid. In the
absence of regenerative structure, strong consistency of variance estimators
has only been established under the assumption that the output process
obeys a strong invariance principle as in Damerdji (1991, 1995, 1994). Be-
cause strong invariance principles are hard to establish for speciﬁc models,
the behavior of most sequential estimation methods is not well understood
at present. Law and Kelton (2000, Section 9.5.3) discuss the empirical per-
formance of various ﬁxed-length and sequential estimation methods and
provide references to a number of experimental studies.

This page intentionally left blank 

8
Delays
Our discussion up to this point has centered around performance measures
that can be expressed as time-average limits—or functions of time-average
limits—that involve the marking process or underlying chain of an spn.
Such measures include long-run system reliability, availability, and cost, as
well as throughput and discounted cost. Assessment of computer, communi-
cation, manufacturing, and transportation systems, however, often involves
analysis of long-run delay characteristics. Examples of such characteristics
include the long-run average time to produce an item in a ﬂexible man-
ufacturing system, the long-run fraction of queries in a database system
that require more than a speciﬁed amount of time to compute, and the
long-run average revenue generated by telephone traﬃc under a graduated
rate structure. When the system of interest is modelled as an spn, each
of these latter characteristics can be expressed as a time-average limit of
the form limn→∞(1/n) 	n−1
j=0 f(Dj), where f is a real-valued function and
D0, D1, . . . is a sequence of delays determined by the marking changes of
the net. Other delay characteristics—such as the long-run variability in the
time required to transmit a message packet from one node to another in
a communication network—can be expressed as functions of time-average
limits. As with time-average limits deﬁned in terms of the marking process,
time-average limits deﬁned in terms of delays often cannot be computed
analytically or numerically, but must be estimated using simulation.
A delay in an spn is computed as the length of a corresponding “delay
interval”—that is, a random time interval—whose start (left endpoint) and
termination (right endpoint) each coincide with a marking-change epoch.

322
8. Delays
Sometimes the limiting average delay limn→∞(1/n) 	n−1
j=0 Dj can be esti-
mated indirectly, that is, without measuring lengths of individual delay
intervals. For general time-average limits of a sequence of delays, however,
individual lengths must be measured and then combined to form point and
interval estimates. Speciﬁcation and subsequent measurement of individ-
ual delays is a decidedly nontrivial step of the simulation: in general, there
can be more than one ongoing delay at a time point and delays need not
terminate in the order in which they start.
In Section 8.1 we introduce a recursively generated sequence of real-
valued random vectors, determined by the sample paths of the underlying
chain, to provide the link between the starts and terminations of individual
delay intervals. Heuristically, the nth such “start vector” records the starts
of all ongoing delays and newly started delays at the nth marking change.
The values of the starts and the order of the starts in the start vector
together summarize the history of the net and comprise suﬃcient infor-
mation to measure individual delays. At each marking change, the current
time may be inserted, old starts may be deleted, and the components of
the start vector may be permuted according to a mechanism that depends
explicitly on the current marking, new marking, and set of transitions that
trigger the marking change. Deleted starts are subtracted from the cur-
rent time to compute delays. This method for specifying and measuring
delays avoids the need to “tag” individual entities in the system (such as
customers) by using either distinguishable tokens or additional places and
transitions.
Section 8.2 focuses on estimation of delay characteristics when the spn
under study has a recurrent single state, so that there exist sequences of
regeneration points for both the underlying chain and the marking process.
When the characteristic of interest is the limiting average delay, point and
interval estimates can be obtained by directly applying results in Chapters 6
and 7. One means of doing this is to ﬁrst express—as in Little’s law—the
limiting average delay in terms of the long-run average length of the start
vector and the long-run average number of starts per unit time. For general
time-average limits, the situation is usually more complex. When there are
no ongoing delays at any regeneration point for the marking process, the
sequence of delays is a regenerative process in discrete time. Under suitable
moment conditions, the standard regenerative method for analysis of simu-
lation output can then be used to obtain strongly consistent point estimates
and asymptotic conﬁdence intervals for time-average limits of the sequence
of delays. When there are ongoing delays at each regeneration point, how-
ever, the standard regenerative method is not applicable—see Example 2.5.
To handle this situation, we construct a sequence of random indices that
decomposes sample paths of the sequence of delays into one-dependent sta-
tionary (o.d.s.) cycles. The idea is to identify a sequence of regeneration
points for the marking process such that all delays that start during a cycle
terminate by the end of the next cycle. Under suitable moment conditions,

8.1 Speciﬁcation and Measurement of Delays
323
an extension (as in Section 6.3.8) of the standard regenerative method to
one-dependent cycles can then be used to estimate general time-average
limits—recall that this extended regenerative method is based on a single
simulation run. Also as in Section 6.3.8, an estimation method based on
multiple runs can be applied—we compare the statistical eﬃciency of these
two methods in Section 8.2.3.
We next consider spns to which the foregoing methods cannot be ap-
plied, either because there is no apparent sequence of regeneration points
for the marking process or underlying chain, or because regenerations oc-
cur too infrequently. If Assumption PD holds for such an spn, then there
exists a sequence of od-regeneration points that decomposes sample paths
of the underlying chain into o.d.s. cycles; see Chapter 7. In Section 8.3, we
show that the output process { f(Dj): j ≥0 } inherits this od-regenerative
structure under mild regularity conditions on the start-vector mechanism.
Moreover, the sum of the output process over a cycle has ﬁnite moments of
all orders provided that f is polynomially dominated. Unlike in Section 8.2,
the cycles of the output process usually cannot be determined explicitly,
and neither the regenerative method nor its extensions can be applied. The
mere existence of these cycles, however, implies that the output process
obeys an fclt. It then follows as in Chapter 7 that sts methods such as
the method of batch means can be used to obtain strongly consistent point
estimates and asymptotic conﬁdence intervals for time-average limits. In
addition, an extension of the method of batch means can be used to ob-
tain point estimates and conﬁdence intervals for functions of time-average
limits.
8.1
Speciﬁcation and Measurement of Delays
A sequence of delays in an spn is speciﬁed in terms of starts { Aj : j ≥0 }
and terminations { Bj : j ≥0 }. These nonnegative random variables are de-
ﬁned on the same probability space as the underlying chain { (Sn, Cn): n ≥
0 }. We restrict attention to sequences { Aj : j ≥0 } and { Bj : j ≥0 } such
that Aj = ζα(j) and Bj = ζβ(j) for j ≥0, where α(j) and β(j) are a.s.
ﬁnite random indices. That is, we restrict attention to delays that start
and terminate only at marking changes. We also focus on sequences for
which the α(j)’s are nondecreasing, so that delays are enumerated in start
order. The β(j)’s need not be nondecreasing, however, reﬂecting the fact
that there can be more than one ongoing delay at a time point and delays
need not terminate in the order in which they start.
The key challenge when specifying and measuring delays is to link the
starts and terminations of individual delay intervals. After brieﬂy discussing
methods based on tagging, we introduce the method of start vectors, which
is our preferred approach. As always, we restrict attention to spns for which

324
8. Delays
Figure 8.1. Positions of jobs in cyclic queues with feedback.
the marking process has an inﬁnite lifetime—see Section 3.3—so that
Pµ

sup
n≥0
ζn = ∞

= 1.
(1.1)
8.1.1
Tagging
Methods based on tagging for measuring individual delays in an spn with
indistinguishable tokens may require a large number of additional places
and transitions.
Example 1.2 (Cyclic queues with feedback). For the closed network of
queues of Example 1.4 in Chapter 2, consider the delay intervals from
whenever a job completes service at center 2 (and moves to center 1) to
when the job next completes service at center 2, and suppose that we wish
to measure the combined sequence of delays for all N jobs. Using additional
places and transitions, we can tag each of the jobs and keep track of the
jobs as they traverse the network.
We number the jobs from 1 to N and, to specify the position of each job
in the network, we conceptually order the jobs in a “job stack.” The jobs
at center 1 are closer to the top of the stack than the jobs at center 2. At
each center, jobs appear in the job stack in the order in which they join
the tail of the queue, the latest to join being closest to the top of the job
stack. The job at the top of the job stack is said to be in position 1, the
next job in position 2, and so forth; see Figure 8.1 for N = 5 jobs.
Observe that when a job completes service at center 1 and moves to
center 2, the jobs retain their positions. When a job completes service at
center 1 and joins the tail of the queue at center 1, it goes into position
1; the position of each other job at center 1 increases by 1. When a job
completes service at center 2, it goes into position 1; the position of each
other job in the network increases by 1.
We use 2N places and N immediate transitions to maintain the position
of each job in the network; see Figure 8.2 for N = 3 jobs. The transitions
have the following interpretation: eN+1 = “completion of service at cen-
ter 1,” eN+2 = “completion of service at center 2,” and ej = “decrease
of position for job j” for 1 ≤j ≤N. Place d2N+i (i = 1, 2) contains n

8.1 Speciﬁcation and Measurement of Delays
325
Figure 8.2. spn for measuring delays in cyclic queues with feedback by tagging
(three jobs).
tokens if and only if n jobs are waiting or in service at center i, and place
dj (1 ≤j ≤N) contains n tokens if and only if job j is in position n. Place
dN+j contains one token if and only if there has just been a completion
of service for job j and the job is about to join the tail of the queue at
center 1; otherwise, place dN+j contains no tokens.
The idea is as follows. Suppose that the marking is s = (s1, s2, . . . , s2N+2)
with sj = N for some j (1 ≤j ≤N) and transition eN+2 ﬁres—that
is, job j is in service at center 2 and there is a completion of service at
center 2. Then one token is removed from place d2N+2, and one token is
deposited in each of the places d2N+1, d1, d2, . . . , dj−1, dj+1, . . . , dN, and
dN+j. The newly enabled immediate transition ej then ﬁres repeatedly,
removing one token from place dj each time until exactly one token remains
in this place. At the last of these ﬁrings, the token in place dN+j is removed
so that transition ej becomes disabled. In this manner the position of job j
(which is represented by the number of tokens in place dj) is set to 1 and
the position of each other job is incremented by 1. Now suppose that the
marking is s = (s1, s2, . . . , s2N+2) with sj = s2N+1 for some 1 ≤j ≤N
and transition eN+1 ﬁres—that is, job j is in service at center 1 and there
is a completion of service at center 1. With probability 1 −p, one token
is deposited in place dN+j and in each place dl such that 1 ≤l ≤N and
sl < s2N+1 (i.e., such that job l is at center 1); transition ej then ﬁres
repeatedly until exactly one token remains in place dj. With probability p,
one token is removed from place d2N+1 and one token is deposited in place
d2N+2. In this manner the position of job j is set to 1 and the position of
each other job at center 1 is incremented by 1 if job j joins the tail of the
queue at center 1, and the positions of the jobs remain unchanged if job j
moves to center 2. The foregoing construction heavily uses the fact that
new-marking probabilities can explicitly depend on the current marking.
A delay for job j terminates (and the next delay for job j starts) whenever
the marking process makes a state transition from s = (s1, s2, . . . , s2N+2)

326
8. Delays
to s′ = (s′
1, s′
2, . . . , s′
2N+2), where sj = N and s′ = s except that s′
2N+1 =
s2N+1 + 1, s′
2N+2 = s2N+2 −1, s′
j = 1, and s′
l = sl + 1 for all 1 ≤l ≤N
with l ̸= j. Observe that this approach to measuring individual delays has
the undesirable property that—unlike the original spn in Figure 2.2—the
number of places and transitions is proportional to the number of jobs,
and the spn graph must be modiﬁed whenever the number of jobs changes.
Use of distinguishable tokens (as in the colored spns of Chapter 9) provides
another means for tagging, but, again, the resulting net is more complicated
than the net of Figure 2.2.
8.1.2
Start Vectors
We now give a method for specifying and measuring delays that avoids
the need for tagging. The idea is to use a sequence of real-valued random
vectors, called start vectors, to construct the sequences { Aj : j ≥0 } and
{ Bj : j ≥0 }. The sequence { Vn : n ≥0 } of start vectors is determined by
the sample paths of the chain { (Sn, Cn): n ≥0 } and provides the link
between the starts and terminations of the individual delay intervals. The
nth start vector Vn records the starts of delay intervals for all ongoing delays
and newly started delays at time ζn, that is, all starts Aj = ζα(j) such that
α(j) ≤n < β(j). Usually (but not necessarily) the positions of the starts
in the start vector correspond to the locations in the system of entities,
such as jobs or customers, for whom a delay is underway. We assume that
the current marking determines the length of the start vector and denote
this length by ψ(s) when the current marking is s. Some components of
Vn may be equal to −1. As discussed below, lengths are never computed
for delay intervals with negative starts, so that negative components of a
start vector can be used to ensure that speciﬁed deletions do not result
in the computation of a delay. The negative components typically serve as
placeholders and correspond to entities in the system at time 0 for whom
no delay is underway. The initial start vector is a speciﬁed vector, denoted
v0(S0), that is determined by the initial marking S0 and has components
that are equal to 0 or −1. Take v0(S0) to be the empty vector ∅when
ψ(S0) = 0.
Whenever the transitions in the set E∗ﬁre simultaneously and trigger
a marking change from s to s′, a new start vector is obtained from the
current start vector by
1. Inserting the current time at zero or more positions speciﬁed by an
index vector iα(s′; s, E∗)
2. Deleting components at zero or more positions speciﬁed by an index
vector iβ(s′; s, E∗)
3. Permuting the components according to an index vector iπ(s′; s, E∗)

8.1 Speciﬁcation and Measurement of Delays
327
Components are deleted one at a time in the order in which the indices
appear in the vector iβ(s′; s, E∗). For each nonnegative component that
is deleted, the length of a delay interval is computed by subtracting the
deleted component from the current time. These deleted components are
the left endpoints of delay intervals for the delays that terminate at the cur-
rent time. Deleted components equal to −1 are not used to compute lengths
of delay intervals and are simply discarded. Observe that a component can
be inserted and then immediately deleted—this scenario corresponds to a
delay Dj = 0, such as when a job arrives at an empty queue and immedi-
ately goes into service, thereby avoiding a wait in line.1
For a real-valued nonempty vector v = (v1, v2, . . . , vk) and a nonempty
index vector i = (i1, i2, . . . , il), denote by Del(v, i) the vector of length
k −l obtained from v by deleting the components at positions i1, i2, . . . , il.
Similarly, denote by Ins(v, i, ζ) the vector of length k + l obtained from v
by inserting the value ζ ∈ℜto the right of the components at positions
i1, i2, . . . , il. For example, if v = (v1, v2, v3, v4, v5) and i = (0, 2, 2, 3, 5),
then Ins(v, i, ζ) = (ζ, v1, v2, ζ, ζ, v3, ζ, v4, v5, ζ). If v = ∅, set Ins(v, i, ζ) =
(ζ, ζ, . . . , ζ), where the vector on the right side is of length l. Finally, for
a vector v of length k and a vector i = (i1, i2, . . . , ik) of distinct indices
with 1 ≤i1, i2, . . . , ik ≤k, set Per(v, i) = (vi1, vi2, . . . , vik) so that Per(v, i)
is the vector of length k obtained from v by permuting the components
according to the index vector i. By convention, Del(v, ∅) = Ins(v, ∅, ζ) =
Per(v, ∅) = v.
The sequence { Vn : n ≥0 } is generated recursively. Set V0 = v0(S0), and
then set
V ′
n = Ins

Vn−1, iα(Sn; Sn−1, E∗
n−1), ζn

,
V ′′
n = Del

V ′
n, iβ(Sn; Sn−1, E∗
n−1)

,
and
Vn = Per

V ′′
n , iπ(Sn; Sn−1, E∗
n−1)

for n ≥1. As usual, E∗
k = E∗(Sk, Ck) for k ≥0, so that E∗
n−1 is the set of
transitions that trigger the nth marking change.
Construct the sequence { Dj : j ≥0 } from the sequence { Vn : n ≥0 } as
follows. Denote by A′
j (j ≥0) the jth nonnegative component deleted
from a start vector in the sequence { Vn : n ≥0 } and by B′
j the time at
which A′
j is deleted. Then [A′
0, B′
0], [A′
1, B′
1], [A′
2, B′
2], . . . is the sequence of
delay intervals, enumerated in order of increasing terminations. If there
are no immediate transitions, obtain the sequence { (Aj, Bj): j ≥0 } by
rearranging the sequence { (A′
j, B′
j): j ≥0 } in order of increasing starts
1Thus, strictly speaking, Vn records starts for ongoing delays and newly started delays
of positive duration.

328
8. Delays
and set Dj = Bj −Aj for j ≥0. If at least one transition is immediate,
two delays can start at the same point in continuous time but at diﬀerent
marking changes. In this case we determine2 for j ≥0 the random index
α′(j) for which A′
j = ζα′(j) and obtain the sequence { (α(j), Aj, Bj): j ≥0 }
by rearranging the sequence { (α′(j), A′
j, B′
j): j ≥0 } in order of increasing
value of the random indices. Then we compute Dj as before.
Denote by nα(s′; s, E∗) and nβ(s′; s, E∗) the lengths of the vectors
iα(s′; s, E∗) and iβ(s′; s, E∗), respectively, for each s′, s, and E∗. The num-
ber of delays that start at time ζn is equal to nα(Sn; Sn−1, E∗
n−1) for n ≥1.
Denote by Vn,i the ith component of the vector Vn for 1 ≤i ≤ψ(Sn), and
set
K = inf { n ≥0: Vn,i ̸= −1 for 0 ≤i ≤ψ(Sn) } .
(1.3)
The number of delays that terminate at time ζn is less than or equal to
nβ(Sn; Sn−1, E∗
n−1) for 1 ≤n ≤K and equal to nβ(Sn; Sn−1, E∗
n−1) for
n > K. Similarly, the total number of newly started delays (of positive
duration) and ongoing delays at the nth marking change is less than or
equal to ψ(Sn) for 0 ≤n < K and equal to ψ(Sn) for n ≥K.
8.1.3
Examples of Delay Speciﬁcations
The following examples illustrate the use of start vectors for speciﬁcation
of delays. As usual, we write iα(s′; s, e) for iα(s′; s, {e}), and so forth.
Example 1.4 (Cyclic queues with feedback).
Consider the delay intervals
from whenever a job completes service at center 2 to when the job next
completes service at center 2, and suppose that we wish to estimate time-
average limits of the sequence of delays for all N jobs. The method of start
vectors can be used to specify and measure individual delays in the spn of
Figure 2.2—this spn is much less complicated than the spn of Figure 8.2.
The start vector Vn records for each of the N jobs in the network the
most recent time during the interval [0, ζn] at which there was a completion
of service at center 2 and the job moved to center 1. If a job has never moved
from center 2 to center 1 during the interval [0, ζn], then the corresponding
component of Vn is equal to −1. The components of the start vector are
ordered from left to right according to increasing positions—as deﬁned in
Example 1.2—of the corresponding jobs in the network.
2To obtain the sequence { α′(j): j ≥0 }, use an auxiliary sequence { Wn : n ≥0 }
of random vectors. The components of each Wn are “starts” but expressed as in-
dices of marking changes rather than as points in continuous time. More speciﬁ-
cally, set W0 = v0(S0). Then set W ′
n = Ins

Wn−1, iα(Sn; Sn−1, E∗
n−1), n

, W ′′
n =
Del

W ′
n, iβ(Sn; Sn−1, E∗
n−1)

, and Wn = Per

W ′′
n , iπ(Sn; Sn−1, E∗
n−1)

for n ≥1. The
random index α′(j) is then the jth nonnegative component deleted from a vector in the
sequence { Wn : n ≥0 }.

8.1 Speciﬁcation and Measurement of Delays
329
Formally, set ψ(s) = N for s ∈G. Also set
iα(s′; s, E∗) =

(0)
if E∗= { e2 };
∅
otherwise
and
iβ(s′; s, E∗) =

(N + 1)
if E∗= { e2 };
∅
otherwise.
Thus, whenever there is a completion of service at center 2 and a job moves
to the tail of the queue at center 1, the new start vector is obtained from
the current start vector by inserting the current time to the left of the
ﬁrst component, deleting the rightmost component,3 and then subtracting
the latter component from the current time to compute a delay if the
component is nonnegative. Next, for s = (s1, s2), s′ = (s′
1, s′
2) ∈G and
E∗⊆E(s), set iπ(s′; s, E∗) = (s1, 1, 2, . . . , s1 −1, s1 + 1, s1 + 2, . . . , N)
if E∗= { e1 } and s′
1 = s1 > 1. Otherwise, set iπ(s′; s, E∗) = ∅. Thus,
whenever there are s1 (> 1) jobs at center 1 and a job completes service at
center 1 and joins the tail of the queue at center 1, the new start vector is
obtained from the current start vector by cyclically permuting the ﬁrst s1
components. Otherwise, the components are unchanged—in particular, no
permutation is needed when E∗= { e2 }.
Suppose that at time 0 there is a completion of service at center 2 with
all jobs at center 2, so that the initial marking is s0 = (1, N −1) and a
delay starts at time 0. We then set v0(s0) = (0, −1, −1, . . . , −1), where
the vector on the right side is of length N. Because N −1 components of
v0(s0) are equal to −1, there are N −1 marking changes at which there is
a completion of service at center 2 and no delay is computed. At the time
ζ of each such marking change, the job completing service at center 2 has
not previously completed service at center 2 during the interval [0, ζ] and
ζ is not an element of the sequence { Bj : j ≥0 } of terminations.
Table 8.1 displays a possible sequence of markings, transitions, and start
vectors (in both continuous and discrete time) in a system with N = 3
jobs. At time ζ0 = 0 one job is at center 1 and two jobs are at center 2.
Because a delay starts at time 0 by assumption, the leftmost component
of both V0 and W0 is equal to 0. At time ζ1 = 1.3 there is a completion of
service at center 2 and the marking changes from s = (1, 2) to s′ = (2, 1).
Because iα

(2, 1); (1, 2), e2

= (0) and iβ

(2, 1); (1, 2), e2

= (N + 1), the
vector V1 is obtained from V0 by inserting the current time (1.3) to the left
of the ﬁrst component and then deleting the rightmost component (−1).
Similarly, the vector W1 is obtained from W0 by inserting the index of the
3Although the length of each start vector Vn is always equal to N for this model,
the length of the intermediate vector V ′
n is equal to N + 1 whenever there is a service
completion at center 2 at time ζn. Thus the “N +1” term in the deﬁnition of iβ(s′; s, E∗).

330
8. Delays
Table 8.1. Sequences of Markings, Transitions, and Start Vectors
n
Sn
E∗
n−1
ζn
Vn
Wn
0
(1, 2)
–
0
(A0 = A′
1)
(0, −1, −1)
(0, −1, −1)
1
(2, 1)
{ e2 }
1.3
(A1 = A′
0)
(1.3, 0, −1)
(1, 0, −1)
2
(2, 1)
{ e1 }
1.8
(0, 1.3, −1)
(0, 1, −1)
3
(1, 2)
{ e1 }
2.1
(0, 1.3, −1)
(0, 1, −1)
4
(2, 1)
{ e2 }
2.5
(2.5, 0, 1.3)
(4, 0, 1)
5
(3, 0)
{ e2 }
3.2
(B1 = B′
0)
(3.2, 2.5, 0)
(5, 4, 0)
6
(2, 1)
{ e1 }
3.7
(3.2, 2.5, 0)
(5, 4, 0)
7
(3, 0)
{ e2 }
3.8
(B0 = B′
1)
(3.8, 3.2, 2.5)
(7, 5, 4)
Figure 8.3. Manufacturing ﬂow-line with shunt bank.
current marking change (1) to the left of the ﬁrst component and then
deleting the rightmost component (−1). Since the component deleted from
V0 is equal to −1, it is not used to compute the length of a delay interval.
Thus, at time ζ1 a delay starts but no delay terminates. At time ζ2 = 1.8 a
job completes service at center 1 and joins the tail of the queue at center 1.
The start vector V2 is obtained from V1 by cyclically permuting the ﬁrst two
components in accordance with the vector iπ

(2, 1); (2, 1), e1

, and similarly
for the vector W2. At time ζ5 = 3.2 there is a completion of service at
center 2, and a delay terminates. Since ζ5 is the ﬁrst time at which a delay
terminates and the rightmost components in the vectors V4 and W4 are
equal to 1.3 and 1, respectively, we have β′(0) = 5, α′(0) = 1, B′
0 = 3.2,
and A′
0 = 1.3. Similarly, a delay terminates at time ζ7 = 3.8, and we
have β′(1) = 7, α′(1) = 0, B′
1 = 3.8, and A′
1 = 0. After rearrangement
in order of increasing starts, we obtain α(0) = 0, β(0) = 7, α(1) = 1,
β(1) = 5, [A0, B0] = [0, 3.8], [A1, B1] = [1.3, 3.2], D0 = 3.8 −0 = 3.8, and
D1 = 3.2 −1.3 = 1.9.
Example 1.5 (Manufacturing ﬂow-line with shunt bank).
Consider a
manufacturing ﬂow-line with two work stations numbered 1 and 2, a con-
veyor, and a shunt bank; see Figure 8.3. Parts passing through the ﬂow-

8.1 Speciﬁcation and Measurement of Delays
331
line are ﬁrst processed at station 1 and then moved one at a time by the
conveyor to station 2 for further processing. The shunt bank provides tem-
porary storage for parts that have been processed at station 1 but cannot
yet be transferred onto the conveyor—parts are transferred to and from
the shunt bank in a “last-in, ﬁrst-out” manner. At most one part can be
at a station or on the conveyor at any time, and the shunt bank can store
no more than B (≥1) parts at a time. Raw parts are always available for
processing at station 1. The details of ﬂow-line operation are as follows.
• Whenever a part completes processing at station 1 and the conveyor
is unoccupied—that is, no part is on the conveyor and no part is
being transferred from the shunt bank to the conveyor—the part at
station 1 is instantaneously transferred onto the conveyor and pro-
cessing of the next raw part begins at station 1. If the conveyor is
occupied and fewer than B parts are in the shunt bank, then the
part at station 1 is transferred to the shunt bank—upon completion
of the transfer, processing of the next raw part begins at station 1.
If B parts are in the shunt bank, then the part remains at station 1
and the station becomes blocked. Station 1 remains blocked until the
conveyor becomes unoccupied, at which time the part at station 1
is instantaneously transferred to the conveyor and processing of the
next raw part begins at station 1.
• Whenever a part is transferred onto the conveyor (from station 1 or
from the shunt bank), the conveyor immediately begins to move the
part to station 2.
• Whenever there is an end of transfer of a part to the shunt bank and
the conveyor is unoccupied, transfer of the part from the shunt bank
to the conveyor starts immediately.
• Whenever either (i) a part arrives at station 2 on the conveyor and
station 2 is idle or (ii) a part completes processing at station 2 and
another part is on the conveyor at the station, the part on the con-
veyor is instantaneously transferred to station 2 and processing of the
part begins.
• Whenever a part is transferred from the conveyor to station 2, sta-
tion 1 is not blocked, and the shunt bank contains at least one part,
transfer of a part from the shunt bank onto the conveyor begins.
The time for the conveyor to move a part from station 1 to station 2 is a
deterministic constant. The time for transfer of a part from station 1 to the
shunt bank is also a deterministic constant, as is the time for transfer of a
part from the shunt bank to the conveyor. The successive times to process
a part at station i are i.i.d. as a positive random variable Li.

332
8. Delays
e1 = end of processing of part at station 1
e2 = transfer of part from station 1 to conveyor
e3 = end of movement on conveyor of part from station 1 to station 2
e4 = transfer of part from conveyor to station 2
e5 = end of processing of part at station 2
e6 = end of transfer of part from station 1 to the shunt bank
e7 = start of transfer of part from the shunt bank to the conveyor
e8 = end of transfer of part from the shunt bank to the conveyor
Figure 8.4. spn representation of manufacturing ﬂow-line with shunt bank.
A part is said to be in stage 1 of the manufacturing process if the part
is at station 1; in stage 2 if the part is being transferred from station 1 to
the shunt bank; in stage 3 if the part is at the shunt bank; in stage 4 if the
part is being transferred from the shunt bank to the conveyor; in stage 5 if
the part is on the conveyor; and in stage 6 if the part is being processed at
station 2.
This system can be speciﬁed as a spn with a ﬁnite marking set; see
Figure 8.4. Places d1, d2, . . . , d7 can each contain zero or one token. Place d8
can contain up to B tokens—the number of tokens in place d8 corresponds
to the number of parts in the shunt bank. Whenever the marking is s =
(s1, s2, . . . , s8) and transition e1 = “end of processing of part at station 1”
ﬁres, a token is removed from place d1. Moreover, if either s3 + s4 + s7 = 0
(the conveyor is unoccupied) or s3 + s4 + s7 > 0 and s8 = B (the conveyor
is occupied and B parts are in the shunt bank), then a token is deposited
in place d2; otherwise, a token is deposited in place d6, so that transfer of
a part from station 1 to the shunt bank starts. All other transitions are
deterministic. All speeds for enabled transitions are equal to 1.

8.1 Speciﬁcation and Measurement of Delays
333
Consider the delay intervals from whenever there is a start of processing
at station 1 for a part to when there is an end of processing at station 2
for the part, and suppose that we wish to estimate time-average limits of
the sequence of delays for all parts. The method of start vectors can be
used to specify and measure individual delays in the spn of Figure 8.4.
The start vector Vn records, for each part in a stage of the manufacturing
process at time ζn, the time at which there was a start of processing at
station 1 for the part. The components of the start vector are ordered
from left to right according to increasing stages of the corresponding parts.
Starts corresponding to parts at the shunt bank are ordered from left to
right according to increasing arrival times at the shunt bank.
Formally, set ψ(s) = s1 + s2 + · · · + s8 for all s = (s1, s2, . . . , s8) ∈G.
Also set
iα(s′; s, E∗) =

(0)
if s1 = 0 and s′
1 = 1;
∅
otherwise
and
iβ(s′; s, E∗)

ψ(s)

if E∗= { e5 };
∅
otherwise
for s, s′ = (s′
1, s′
2, . . . , s′
8) ∈G and E∗⊆E(s). Thus, whenever there is
a start of processing at station 1, the new start vector is obtained from
the current start vector by inserting the current time to the left of the
ﬁrst component; whenever there is an end of processing at station 2, the
new start vector is obtained by deleting the rightmost component. Next,
set iπ(s′; s, E∗) =

2, 3, . . . , s8 + 1, 1, s8 + 2, s8 + 3, . . . , ψ(s)

if s8 > 0 and
either E∗= { e2 } or E∗= { e6 }, that is, if the shunt bank is not empty
and there is an end of transfer of a part from station 1 to either the shunt
bank or the conveyor. Thus the new start vector is obtained by cyclically
permuting the components so that the start for the transferred part appears
to the right of the starts for the parts at the shunt bank. Otherwise, set
iπ(s′; s, E∗) = ∅, so that the components of the start vector are unchanged.
Suppose that at time 0 there is an end of processing at station 1 and there
are no parts at the shunt bank, on the conveyor, or at station 2. Then the
initial marking is s0 = (0, 1, 0, 0, 0, 0, 0, 0), no delays start at time 0, and
we set v0(s0) = (−1).
Example 1.6 (Manufacturing cell with robots).
For the manufacturing
cell of Example 3.6 in Chapter 2, a part is said to be in stage 1 of the
manufacturing process if the part is being transferred from the loading
area to conveyor 1; in stage 2 if the part is on conveyor 1; in stage 3 if
the part is being transferred from conveyor 1 to a machine; in stage 4 if
the part is at a machine; in stage 5 if the part is being transferred from
a machine to conveyor 2; in stage 6 if the part is on conveyor 2; and in
stage 7 if the part is being transferred from conveyor 2 to the unloading
area.

334
8. Delays
Consider the delay intervals from whenever (the arm of robot 1 arrives at
the loading area and) robot 1 starts to transfer a raw part from the loading
area to conveyor 1 to when robot 1 completes transfer of the part to the
unloading area. Suppose that we wish to estimate time-average limits of
the sequence of delays for all parts. The method of start vectors can be
used to specify and measure individual delays in the spn of Figure 2.21.
The start vector Vn records, for each part in a stage of the manufacturing
process at time ζn, the time at which robot 1 started to transfer the raw
part from the loading area to conveyor 1. The components of the start
vector are ordered from left to right according to increasing stages of the
corresponding parts. If there is a part at each machine—that is, if there
are two parts in stage 4—the start corresponding to the part at machine 1
appears to the left of the start corresponding to the part at machine 2.
Formally, set ψ(s) = s2 + s3 + s4 + s6 + s8 + s9 + s10 + s11 + s12 + s14 +
s16 + s17 + s18 + s20 for s = (s1, . . . , s24) ∈G. Also set
iα(s′; s, E∗) =

(0)
if E∗= { e1 };
∅
otherwise
and
iβ(s′; s, E∗) =

ψ(s)

if E∗= { e16 };
∅
otherwise
for s, s′ ∈G and E∗⊆E(s). Thus, whenever robot 1 starts to transfer
a raw part from the loading area to conveyor 1, the new start vector is
obtained from the current start vector by inserting the current time to the
left of the ﬁrst component; whenever robot 1 completes transfer of the part
from a machine to the unloading area, the new start vector is obtained by
deleting the rightmost component. Next, set n(s) = s2 + s3 + s4 + s8 and
m(s) = s2 + s3 + s4 + s6 + s8 + s9 + s10, and then set
iπ(s′; s, E∗) =

1, . . . , n(s) −1, n(s) + 1, n(s), n(s) + 2, . . . , ψ(s)

if E∗= { e7 } and s9 + s10 = 1, and
iπ(s′; s, E∗) =

1, . . . , m(s) −1, m(s) + 1, m(s), m(s) + 2, . . . , ψ(s)

if E∗= { e10 } and s11 + s12 = 1. Otherwise, set iπ(s′; s, E∗) = ∅. Thus,
whenever there is an end of transfer of a raw part from conveyor 1 to
machine 2 with a part at machine 1, the new start vector is obtained from
the current start vector by interchanging the components associated with
the two parts. A similar interchange occurs whenever there is a start of
transfer of a part from machine 1 to conveyor 2 with a part at machine 2.
Otherwise the components of the current and new start vectors coincide.
Suppose that at time 0 there are parts only at the loading area and
the arm of robot 1 has just left its null position to transfer a raw part

8.1 Speciﬁcation and Measurement of Delays
335
from the loading area to conveyor 1. Then the initial marking is s0 =
(1, 0, 0, . . . , 0, 1), no delays start at time 0, and we set v0(s0) = ∅.
Example 1.7 (Token ring). For the system of Example 2.6 in Chapter 2,
consider the delay intervals from whenever a packet arrives at a port for
transmission until the end of transmission of the packet. Suppose that we
wish to estimate time-average limits of the sequence of delays for all ports.
The method of start vectors can be used to specify and measure individual
delays in the spn of Figure 2.10. The start vector Vn records, for each packet
awaiting or under transmission at time ζn, the time at which the packet
arrived. The components of the start vector are ordered from left to right
according to increasing indices of the arrival ports for the corresponding
packets.
Formally, denote by m(k, s) the total number of ongoing delays corre-
sponding to packets at ports 1 through k when the marking is s: m(0, s) = 0
and m(k, s) = s1,1+s1,2+· · ·+s1,k for 1 ≤k ≤N and s = (s1,1, . . . , s4,N) ∈
G. Set ψ(s) = s1,1 + s1,2 + · · · + s1,N for s ∈G and set
iα(s′; s, E∗) =

m(j −1, s)

if E∗= { e1,j } for some 1 ≤j ≤N;
∅
otherwise
and
iβ(s′; s, E∗) =

m(j, s)

if E∗= { e2,j } for some 1 ≤j ≤N;
∅
otherwise
for s, s′ ∈G and E∗⊆E(s). Thus, whenever m packets are either awaiting
or under transmission at ports 1 through j−1 (where 1 ≤j ≤N) and there
is an arrival of a packet at port j, the new start vector is obtained from the
current start vector by inserting the current time to the right of the mth
component; whenever m packets are either awaiting or under transmission
at ports 1 through j and there is an end of transmission by port j, the
new start vector is obtained by deleting the mth component. Finally, set
iπ(s′; s, E∗) = ∅for all s′, s, and E∗—the components of the start vector
need never be permuted because the order of the starts in the start vector is
determined by the indices of the ports at which the corresponding packets
arrived.
Suppose that at time 0 no packets are awaiting or under transmission,
and the ring token has just arrived at port 1. Then the initial marking is
s0 = (0, 1, 0, 1, 0, 1, 0, 0 . . . , 0, 1, 0, 0), no delays start at time 0, and we set
v0(s0) = ∅.
Example 1.8 (Airport shuttle). Consider an airport shuttle that provides
transportation service to N stations numbered 1, 2, . . . , N. The shuttle has
seats for K (≥1) passengers and moves from station to station in a strictly

336
8. Delays
e1,i = arrival of shuttle at station i
e2,j,i = disembarkment at station i of passengers from station j
e3,i = boarding of passengers at station i
e4,i = arrival of passenger for boarding at station i
Figure 8.5. spn representation of airport shuttle.
deﬁned order: 1, 2, . . . , N, 1, 2, . . .. Passengers who wish to board the shuttle
at station i arrive at station i according to a renewal process and disembark
at station j (̸= i) with probability pi,j. Passengers who arrive for boarding
at station i queue (and subsequently board the shuttle) in the order in
which they arrive at the station. Each station i has a ﬁnite capacity Bi—
passengers arriving at the station when there are already Bi passengers
in queue are turned away. At each station, passengers disembark before
any waiting passengers board the shuttle. Passengers board and disembark
instantaneously. The successive times for the shuttle to travel from station i
to station i + 1 are i.i.d. as a positive random variable Li, and the times
between successive arrivals of passengers at station i for boarding are i.i.d.
as a positive random variable Ai. (When i = N take station i+1 as station 1
and when i = 1 take station i −1 as station N.)

8.1 Speciﬁcation and Measurement of Delays
337
This transportation system can be speciﬁed as an spn with ﬁnite marking
set—Figure 8.5 displays the subnet corresponding to a generic station i.
Places d1,i, d2,i, and d3,i (1 ≤i ≤N) each contain at most one token.
Place d1,i contains a token if and only if the shuttle is travelling from
station i−1 to station i, place d2,i contains a token if and only if passengers
are disembarking at station i, and place d3,i contains one token if and only
if passengers are boarding at station i. Place d6,i always contains exactly
one token, reﬂecting the fact that the arrival process of passengers who
board at station i is always active. Place d4,j,i (1 ≤i, j ≤N with i ̸= j)
contains k tokens if and only if there are k passengers on the shuttle who
boarded at station j and wish to disembark at station i. Place d5,i contains
k tokens if and only if k passengers are queued at station i (awaiting the
shuttle). All speeds for enabled transitions are equal to 1.
The complete description of the transition-ﬁring mechanism is rather
tedious, so we give a brief overview and leave the details to the reader.
Consider throughout the subnet corresponding to a ﬁxed station i. Sup-
pose that place d1,i contains a token, the set of places { d4,k,l : 1 ≤k, l ≤
N with k ̸= l } contains a total of m tokens (m ≤K), the set of places
{ d4,1,i, . . . , d4,N,i } contains a total of n tokens (1 ≤n ≤m), and place d5,i
contains k tokens (k ≥1). Thus the shuttle is travelling to station i carrying
m passengers, n of whom wish to disembark at station i, and k passengers
are at station i waiting to board the shuttle. When transition e1,i = “ar-
rival of shuttle at station i” ﬁres, it removes a token from place d1,i and
deposits a token in place d2,i. The transitions in the set { e2,1,i, . . . , e2,N,i }
then ﬁre a total of n times, removing all tokens from the places in the set
{ d4,1,i, . . . , d4,N,i }, so that n passengers disembark. At the last of these
ﬁrings, a token also is removed from place d2,i and a token is deposited in
place d3,i. Transition e3,i = “boarding of passengers at station i” then ﬁres
l = min(k, K −m + n) times, removing l tokens from place d5,i. Whenever
transition e3,i ﬁres and removes a token from place d5,i, it also deposits a to-
ken in exactly one of places d4,i,1, . . . , d4,i,i−1, d4,i,i+1, . . . , d4,i,N; the token
is deposited in place d4,i,j with probability pi,j. Moreover, transition e3,i
removes a token from place d3,i and deposits a token in place d1,i+1 when
it ﬁres for the lth time, so that the shuttle begins to travel to station i + 1.
If no passengers wish to disembark at station i and/or there are no
passengers at station i waiting to board the shuttle, then the corresponding
stages in the foregoing sequence are skipped. For example, if the set of
places { d4,1,i, . . . , d4,N,i } contains zero tokens and place d5,i contains zero
tokens, then transition e1,i removes a token from place d1,i and deposits
a token in place d1,i+1 when it ﬁres, so that no passengers disembark or
board at station i. The behavior of transition e4,i = “arrival of passenger
for boarding at station i” is relatively simple. Whenever place d5,i contains
less than Bi tokens and transition e4,i ﬁres, a token is deposited in place
d5,i; whenever place d5,i contains exactly Bi tokens and transition e4,i ﬁres,
no tokens are removed or deposited.

338
8. Delays
To facilitate speciﬁcation of the new-marking probabilities, we assign
priorities to the transitions in the set { e2,1,i, . . . , e2,N,i }; speciﬁcally, we
set P(e2,j,i) = j for 1 ≤j ≤N. Whenever passengers disembark at sta-
tion i, the enabled transition e2,j,i with the highest priority ﬁres multiple
times in succession, then the enabled transition e2,j′,i with the second-
highest priority ﬁres multiple times in succession, and so forth. Thus we
need only explicitly specify singleton new-marking probabilities of the form
p(s′; s, e2,j,i) in order to formally describe the behavior of the net when pas-
sengers disembark.
Consider the delay intervals from whenever a passenger arrives at a sta-
tion for boarding to when the passenger disembarks, and suppose that we
wish to estimate time-average limits of the sequence of delays for all pas-
sengers. The method of start vectors can be used to specify and measure
individual delays in the spn of Figure 8.5. The start vector Vn records, for
each passenger in the system at time ζn, the time at which the passenger
arrived at a station for boarding. The components of the start vector are
ordered so that
1. Starts corresponding to passengers who originally arrived at station i
for boarding appear to the left of starts corresponding to passengers
who originally arrived at station j whenever i < j.
2. starts corresponding to passengers waiting in queue at station i (1 ≤
i ≤N) appear to the left of starts corresponding to passengers who
originally arrived at station i for boarding and are currently on the
shuttle.
3. Starts corresponding to passengers waiting in queue at station i (1 ≤
i ≤N) appear from left to right in decreasing order of arrival time.
4. Starts corresponding to passengers on the shuttle who originally ar-
rived at station i and wish to disembark at station j appear to the
left of the starts corresponding to passengers who originally arrived
at station i and wish to disembark at station k whenever j < k.
5. Starts corresponding to passengers on the shuttle who originally ar-
rived at station i and wish to disembark at station j appear from left
to right in decreasing order of arrival time at station i.
Formal speciﬁcation of the start-vector mechanism is as follows. When
the marking is s ∈G, denote by mj(s) the number of passengers currently
in the system who originally arrived at station j:
mj(s) = s5,j +

i̸=j
s4,j,i.
Moreover, if the marking s is such that at least one passenger is waiting in
queue at station j, let lj(s) be the position in the start vector corresponding

8.1 Speciﬁcation and Measurement of Delays
339
to the next passenger at station j who will board the shuttle:
lj(s) = m1(s) + · · · + mj−1(s) + s5,j.
Finally, let nj,i(s) be the position of the rightmost of the starts correspond-
ing to those passengers who originally arrived at station j, are currently
on the shuttle, and wish to disembark at some station k with k < i:
nj,i(s) = lj(s) + s4,j,1 + s4,j,2 + · · · + s4,j,i−1.
Observe that if no such passengers exist, then nj,i(s) is the position cor-
responding to the next passenger at station j who will board the shuttle.
Using the foregoing notation, set ψ(s) = 	N
i=1 mi(s) for s ∈G. Also set
iα(s′; s, E∗) =

m1(s) + · · · + mi−1(s)

if E∗= { e4,i } for some 1 ≤i ≤N; otherwise, set iα(s′; s, E∗) = ∅. Next,
set
iβ(s′; s, E∗) =

m1(s) + · · · + mj−1(s) + s5,j + s4,j,1 + s4,j,2 + · · · + s4,j,i

if E∗= { e2,j,i } for some 1 ≤i, j ≤N with i ̸= j; otherwise, set iβ(s′; s,
E∗) = ∅. Finally, set
iπ(s′; s, E∗) =

1, 2, . . . , lj(s) −1, lj(s) + 1, lj(s) + 2, . . . ,
nj,i(s), lj(s), nj,i(s) + 1, nj,i(s) + 2, . . . , ψ(s)

if s′
4,j,i = s4,j,i + 1 for some 1 ≤i, j ≤N with i ̸= j; otherwise, set
iπ(s′; s, E∗) = ∅. Thus, whenever a passenger boards the shuttle at sta-
tion j and wishes to disembark at station i, the start corresponding to
this passenger is moved to the right of the starts corresponding to those
passengers who originally arrived at station j, are currently on the shuttle,
and wish to disembark at some station k with k < i.
Suppose that at time 0 no passengers are in the system and the shut-
tle is travelling to station 1. Then the initial marking is s0 = (s1,1, . . . ,
s6,N), where s1,1 = s6,1 = s6,2 = · · · = s6,N = 1 and all other components
of s0 are equal to 0. No delays start at time 0, and we set v0(s0) = ∅.
The foregoing spn and start-vector mechanism can also be used to study
delays experienced by passengers who board the shuttle at station j and
disembark at station i, where i and j are ﬁxed—see Remark 3.18 below.
Remark 1.9. The “loop” airport shuttle system of Example 1.8 is closely
related to a “bidirectional” shuttle system. In particular, suppose that the
number of stations N can be written in the form N = 2L and that the
travel time from station L to station L + 1 is identically 0, as is the travel
time from station 2L to station 1. Also suppose that the interarrival-time
random variables AL and A2L are each a.s. inﬁnite, so that no passengers

340
8. Delays
arrive at stations L or 2L. Finally, suppose that pi,1 = pi,L+1 = 0 for all
i, so that passengers never disembark at stations 1 or L + 1. This system
coincides with a bidirectional shuttle system having L stations—the shuttle
travels in either a “northbound” direction (from station 1 to station L) or
a “southbound” direction (from station L to station 1). That is, the shuttle
moves from station to station in the order 1, 2, . . . , L, L−1, . . . , 1, 2, . . .. The
idea is to identify station j (1 ≤j ≤L) in the loop shuttle system with the
northbound platform of station j in the bidirectional shuttle system, and
station 2L−j +1 in the loop shuttle system with the southbound platform
of station j in the bidirectional shuttle system.
8.2
Regenerative Methods for Delays
In this section we provide methods for estimating general time-average
limits of the form limn→∞(1/n) 	n−1
j=0 f(Dj), where the sequence of delays
{ Dj : j ≥0 } is determined from the marking changes of an spn by means
of start vectors. We also provide specialized estimation methods in this
setting for the limiting average delay limn→∞(1/n) 	n−1
j=0 Dj.
Our key assumption is that there exists a sequence of regeneration points
for the marking process { X(t): t ≥0 } and for the underlying chain
{ (Sn, Cn): n ≥0 }. In particular, we suppose throughout that there ex-
ists a recurrent single state ¯s, so that E(¯s) = { ¯e } for some ¯e ∈E and
Pµ { Sn = ¯s i.o. } = 1. The regeneration points then correspond to the suc-
cessive times at which the marking is ¯s and transition ¯e ﬁres. That is, if we
set θ(0) = 0 and
θ(k) = inf

n > θ(k −1): Sn−1 = ¯s and E∗
n−1 = { ¯e }

(2.1)
for k ≥1, then the random indices { θ(k): k ≥0 } form a sequence of regen-
eration points for { (Sn, Cn): n ≥0 } and the random times { ζθ(k) : k ≥0 }
form a sequence of regeneration points for { X(t): t ≥0 }. Implicit in this
deﬁnition is the assumption—made for convenience—that the net behaves
as if at time 0 the marking is ¯s and transition ¯e ﬁres. The initial start vector
V0 is deﬁned accordingly: conditional on S0, compute V0 by taking a vector
of length ψ(¯s) with each component equal to −1 and then inserting the cur-
rent time (0) at positions speciﬁed by the index vector iα(S0; ¯s, ¯e), deleting
components at positions speciﬁed by the index vector iβ(S0; ¯s, ¯e), and per-
muting the components according to the index vector iπ(S0; ¯s, ¯e). We also
suppose that the starts { Aj : j ≥0 }, the terminations { Bj : j ≥0 }, and
the random index K that is deﬁned by (1.3) satisfy
Pµ { K < ∞} = 1,
(2.2)
Pµ { Aj < ∞} = Pµ { Bj < ∞} = 1
(2.3)

8.2 Regenerative Methods for Delays
341
for j ≥0, and
Pµ

lim
j→∞Aj = ∞

= 1.
(2.4)
Observe that, by the a.s. ﬁniteness of the clock readings, ζK < ∞a.s.
whenever K < ∞a.s..
There are two basic scenarios to consider, as illustrated by the two types
of delays in the following example.
Example 2.5 (Cyclic queues with feedback).
For the network of queues
in Example 1.2, consider the delay intervals from whenever a job completes
service at center 2 to when the job next completes service at center 1 and
moves to center 2, and suppose that we wish to estimate time-average lim-
its of the sequence of delays for all N jobs. Under suitable assumptions
on the distributions of the service-time random variables L1 and L2—see
Example 2.12 below—the successive random times at which there is a com-
pletion of service at center 2 with all other jobs at center 2 form a sequence
of regeneration points for the marking process. Observe that there are no
ongoing delays at any regeneration point.
In contrast, consider the delay intervals from whenever a job completes
service at center 2 to when the job next completes service at center 2 and
the sequence of delays for all N jobs. There are at least N −1 ongoing
delays at any time point and hence at any regeneration point.
When there are no ongoing delays at any regeneration point for the
marking process—see Figure 8.7 below—it is intuitively clear that the re-
generation points decompose the delays into i.i.d. blocks. The sequence of
delays therefore is a regenerative process in discrete time, and we can es-
timate time-average limits using methods as in Chapter 6. This scenario
holds, for example, whenever
(i) ψ(¯s) = 0 or
(ii) all delays are of positive length and nβ(s; ¯s, ¯e) = ψ(¯s) for all s such
that p(s; ¯s, ¯e) > 0.
The situation is not so simple, however, when there are ongoing delays at
each regeneration point, as in Figure 8.6. In the following, we treat these
two scenarios in a uniform manner and provide general estimation methods
that are applicable under either scenario—we then show that each of these
methods reduces in eﬀect to the standard regenerative method when there
are no ongoing delays at any regeneration point.
8.2.1
Construction of Random Indices
To obtain point estimates and conﬁdence intervals for time-average limits,
we ﬁrst construct a sequence { ˇγ(k): k ≥0 } of random indices that de-
composes sample paths of { Dj : j ≥0 } into o.d.s. cycles. Extensions of the

342
8. Delays
Figure 8.6. Deﬁnition of one-dependent cycles.
standard regenerative method as in Section 6.3.8 can then be used to obtain
strongly consistent point estimates and asymptotic conﬁdence intervals.
Deﬁnition of the Indices
In the following discussion, we assume that there exist ﬁxed index vectors
jα and jβ—of respective lengths |jα| and |jβ|—such that
iα(s′; ¯s, ¯e) = jα
and
iβ(s′; ¯s, ¯e) = jβ
(2.6)
for all s′ ∈G with p(s′; ¯s, ¯e) > 0. The condition in (2.6) asserts that,
whenever the marking is ¯s and transition ¯e ﬁres, the number and positions
of the starts inserted into and deleted from the current start vector do
not depend explicitly on the new marking s′. This condition implies that
the start vector contains exactly ψ(¯s) + |jα| −|jβ| components at each
time ζθ(k). Moreover, the number of these components that correspond to
ongoing delays—and hence the number that correspond to newly started
delays—is the same for each time ζθ(k) > ζK.
We start with the sequence { ζθ(k) : k ≥0 } of regeneration points for the
marking process and recursively construct a subsequence { ζˇθ(k) : k ≥0 }.
The random times { ζˇθ(k) : k ≥0 } also form a sequence of regeneration
points, but with longer cycles. All delays that start during one of these
longer cycles terminate by the end of the next such cycle. To construct the
sequence { ζˇθ(k) : k ≥0 }, take ˇθ(0) = θ(0) = 0. Then, given ˇθ(k), wait until
the ﬁrst marking change ˇν(k) at which all ongoing delays at the ˇθ(k)th
marking change have terminated, and take as ˇθ(k + 1) the smallest θ(l)
such that θ(l) ≥ˇν(k). Equivalently, take as ˇθ(k + 1) the ﬁrst θ(l) after the

8.2 Regenerative Methods for Delays
343
ˇθ(k)th marking change such that all ongoing delays at the θ(l)th marking
change started no sooner than the ˇθ(k)th marking change. If there are no
ongoing delays at the ˇθ(k)th marking change, take as ˇθ(k + 1) the smallest
θ(l) such that θ(l) > ˇθ(k). For k = 0, take as ˇθ(1) the smallest θ(l) such
that θ(l) ≥K. To complete the construction, set ˇγ(0) = 0 and
ˇγ(k) = inf

j > ˇγ(k −1): α(j −1) < ˇθ(m) ≤α(j) for some m ≥0

(2.7)
for k ≥1. These ideas are illustrated in Figure 8.6. In the ﬁgure, vertical
dashed lines indicate times that are elements of { ζθ(k) : k ≥0 }−{ ζˇθ(k) : k ≥
0 }; vertical solid lines indicate times that are elements of { ζθ(k) : k ≥
0 } ∩{ ζˇθ(k) : k ≥0 }. The delays Dˇγ(k) are circled.
Properties of the Construction
The pertinent properties of the foregoing construction are summarized in
Theorem 2.8 below—estimation methods for delays rest on these properties.
For k ≥1, denote by δk the number of delays that start during the interval
[ζθ(k−1), ζθ(k)) and set τk = ζθ(k)−ζθ(k−1). Deﬁne a real-valued function f to
be polynomially dominated to degree b (where b ≥0) if |f(x)| = O(xb + 1).
Theorem 2.8. Let { Dj : j ≥0 } be a sequence of delays determined from
the underlying chain of a marking process using the method of start vectors.
Suppose that there exists a recurrent single state ¯s and that the conditions
in (2.2)–(2.4) and (2.6) hold. Then
(i) the random indices { ˇγ(k): k ≥0 } deﬁned by (2.7) form a sequence
of od-equilibrium points for { Dj : j ≥0 },
(ii) the random indices { ˇγ(k): k ≥0 } also form a sequence of regenera-
tion points for { Dj : j ≥0 }, provided that there are no ongoing delays
at the θ(k)th marking change for k ≥0, and
(iii) the cycle sum
ˇY1(|f|) = 	ˇγ(1)−1
j=ˇγ(0) |f(Dj)| has ﬁnite rth moment for
any real-valued function f that is polynomially dominated to degree b
(where r, b ≥1), provided that Eµ [δrp
1 ] < ∞and Eµ[τ rbq
1
] < ∞for
nonnegative real numbers p and q with p−1 + q−1 = 1.
We defer the proof until the end of the subsection. It follows from the
theorem that Eµ
 ˇY r
1 (|f|)

< ∞whenever f is polynomially dominated to
degree b and both Eµ[δr(b+1)
1
] and Eµ[τ r(b+1)
1
] are ﬁnite—take p = b + 1
and q = (b + 1)/b.
Remark 2.9. The ﬁnal assertion of the theorem holds when b = 0, p = 1,
and q = ∞, provided that we take rbq = 0. Thus, if Eµ [δr
1] < ∞for some
r ≥1, then Eµ
 ˇY r
1 (|f|)

< ∞for any bounded function f. For example, the
cycle length ˇδ1 = ˇγ(1) −ˇγ(0) satisﬁes Eµ[ˇδr
1] < ∞whenever Eµ [δr
1] < ∞
(take f ≡1).

344
8. Delays
Remark 2.10. The crux of the ﬁnal assertion is that the cycles of { Dj : j ≥
0 } have well-behaved moments whenever the cycles of the underlying chain
and marking process have well-behaved moments. Observe that Eµ [δr
1] <
∞whenever
(i) Eµ

θ(1) −θ(0)
r
< ∞, and
(ii) sups′,s,E∗nα(s′; s, E∗) < ∞, so that the number of delays that start
at a marking change is bounded.
The techniques in Section 6.2 can be used to show that quantities such as
θ(1) −θ(0) and τ1 have ﬁnite moments.
Remark 2.11. When the condition in (2.6) is violated, there is an additional
dependency between the delays in adjacent θ(k)-cycles, and the conclusion
of Theorem 2.8 may not hold. Speciﬁcally, the number and positions of the
starts deleted from the current start vector at the ˇθ(k)th marking change
may depend explicitly on the new marking Sˇθ(k). Of course, delays that
start at or after time ζˇθ(k) also depend on Sˇθ(k). The condition in (2.6)
can be dropped, however, if the theorem is slightly modiﬁed. The idea is
to change the deﬁnition of the random indices { ˇθ(k): k ≥0 }. Speciﬁcally,
given ˇθ(k), wait until the ﬁrst marking change ˇν(k) at which all of the
ongoing delays at the ˇθ(k)th marking change have terminated, and take as
ˇθ(k + 1) the smallest θ(l) such that θ(l) is strictly greater than ˇν(k). It can
then be shown that the conclusion of the theorem holds for the resulting
random indices { ˇγ(k): k ≥0 } even when (2.6) does not hold. Of course,
the corresponding regenerative cycles for the process { Dj : j ≥0 } typically
are longer than the original cycles.
Examples
Example 2.12 (Cyclic queues with feedback).
Suppose that the service-
time distribution at center 1 is gnbu and that the essential supremum of the
service-time distribution at center 2 is inﬁnite. The marking ¯s = (0, N) is a
single state with E(¯s) = { e2 }. As shown in Example 2.37 in Chapter 5, ¯s is
recurrent, so that each θ(k) deﬁned by (2.1) is a.s. ﬁnite. The regeneration
points { ζθ(k) : k ≥0 } are the successive random times at which there is a
service completion at center 2 with all jobs at center 2.
Consider the delay intervals from whenever a job completes service at
center 2 to when the job next completes service at center 2, and suppose
that we wish to estimate time-average limits of the sequence of delays for all
N jobs. Because the marking ¯s is recurrent, (2.2) and (2.3) hold. Moreover,
since the marking set G is ﬁnite and there are no immediate transitions, it
follows from Theorem 3.13 in Chapter 3 that (1.1) holds, and hence that
(2.4) holds. The condition in (2.6) holds trivially since the new marking
is s′ = (1, N −1) whenever the marking is ¯s and transition ¯e ﬁres. The

8.2 Regenerative Methods for Delays
345
random indices { ˇγ(k): k ≥0 } deﬁned by (2.7) therefore form a sequence
of od-equilibrium points for the process { Dj : j ≥0 }.
To understand the foregoing result intuitively, observe that at each time
ζˇθ(k) a delay terminates and a new delay starts for the job that just com-
pleted service at center 2. The length of the new delay interval is Dˇγ(k).
The sequence { Dj : j ≥ˇγ(k) } is determined by { (Sn, Cn): n ≥ˇθ(k) } ac-
cording to a mechanism that does not depend on either k or the precise
values of the components of Vˇθ(k). Hence, the sequence { Dj : j ≥ˇγ(k) } is
distributed as { Dj : j ≥0 }. There are N −1 ongoing delays at time ζˇθ(k),
corresponding to the N −1 jobs waiting in the queue at center 2 just be-
fore time ζˇθ(k). Clearly, the delays { Dj : j ≥ˇγ(k) } may depend on these
N−1 delays, which are a subset of { Dj : ˇγ(k−1) ≤j < ˇγ(k) }. By construc-
tion, however, the terminations that correspond to { Dj : 0 ≤j < ˇγ(k −1) }
occur before ζˇθ(k). It follows that these latter delays are determined by

(Sn, Cn): 0 ≤n < ˇθ(k)

and thus are independent of { Dj : j ≥ˇγ(k) }.
To show that cycle sums of the form
ˇY1(|f|) =
ˇγ(1)−1

j=ˇγ(0)
|f(Dj)|
have ﬁnite moments, we can use Theorem 2.8(iii). To apply this result
it must be shown that τ1 and δ1 have ﬁnite moments. Finiteness of the
moments of τ1 and δ1 can be established using Theorems 2.36, 2.40, and
2.44 in Chapter 6—see Example 2.51 in Chapter 6.
Example 2.13 (Manufacturing ﬂow-line with shunt bank). Marking ¯s =
(1, 0, 0, 0, 0, 0, 0, 0) is a single state with E(¯s) = { e1 }. Under suitable con-
ditions on the distributions of the processing-time random variables L1 and
L2, the marking ¯s is recurrent and each θ(k) deﬁned by (2.1) is a.s. ﬁnite.
The regeneration points { ζθ(k) : k ≥0 } are the successive random times at
which there is an end of processing at station 1 with no other parts in the
system.
Consider the delay intervals from whenever there is a start of processing
at station 1 for a part to when there is an end of processing at station 2
for the part, and suppose that we wish to estimate time-average limits of
the sequence of delays for all parts. The recurrence of ¯s implies that (2.2)
and (2.3) hold, and it follows from (1.1) that (2.4) holds. The condition
in (2.6) holds trivially since the new marking is s′ = (0, 1, 0, 0, 0, 0, 0, 0)
whenever the marking is ¯s and transition ¯e = e1 ﬁres. The random indices
{ ˇγ(k): k ≥0 } deﬁned by (2.7) therefore form a sequence of od-equilibrium
points for the process { Dj : j ≥0 }.
As in the previous example, Theorem 2.8(iii) can be used to show that
cycle sums of the form ˇY1(|f|) = 	ˇγ(1)−1
j=ˇγ(0) |f(Dj)| have ﬁnite moments
under suitable assumptions on the moments of L1 and L2.

346
8. Delays
Extension to Alternative Regeneration Points
The random indices { θ(k): k ≥0 } used to construct the sequence of od-
equilibrium points { ˇγ(k): k ≥0 } correspond to the successive times at
which the current marking is a single state ¯s and a distinguished transition
¯e ﬁres. Other choices of { θ(k): k ≥0 } are possible. For example, suppose
that there exists a marking ¯s with E(¯s) = { ¯e0, ¯e1, . . . , ¯el } (where l ≥1)
such that
F(x; s′, ¯ei, s, E∗) ≡F(x; ¯ei) = 1 −exp(−λix)
for 1 ≤i ≤l. Let { θ(k): k ≥0 } be the sequence of random indices that
correspond to the successive times at which the marking is ¯s and transi-
tion ¯e0 ﬁres. Suppose that at each time ζθ(k) transitions ¯e1, ¯e2, . . . , ¯el are
old transitions. Also suppose that (2.2), (2.3), and (2.4) hold and that
(2.6) holds with ¯e = ¯e0. Finally, assume for convenience that each interval
[ζθ(k), ζθ(k+1)] contains at least one start. Then the sequence of random
indices { ˇγ(k): k ≥0 } constructed from the sequence { θ(k): k ≥0 } de-
composes sample paths of the sequence { Dj : j ≥0 } into o.d.s. cycles.
To see that this assertion holds, set
Gk =

Sˇθ(k−1), t∗
ˇθ(k−1), E∗
ˇθ(k−1),
Sˇθ(k−1)+1, t∗
ˇθ(k−1)+1, E∗
ˇθ(k−1)+1, . . . , Sˇθ(k)−1, t∗
ˇθ(k)−1, E∗
ˇθ(k)−1

for k ≥1, where, as usual, t∗
n = t∗(Sn, Cn) and E∗
n = E∗(Sn, Cn) for
n ≥0. It follows from (2.19) in Chapter 6 that the sequence { Gk : k ≥1 }
consists of i.i.d. random vectors. Since Gk and Gk+1 completely determine
both the number of delays that start during the interval [ζˇθ(k−1), ζˇθ(k))
and the length of the corresponding delay intervals, the desired result
follows. As discussed in Remark 2.12 in Chapter 6, the random indices
{ θ(k): k ≥0 } do not form a sequence of regeneration points for the chain
{ (Sn, Cn): n ≥0 }, but the random times { ζθ(k) : k ≥0 } do form a se-
quence of regeneration points for the marking process { X(t): t ≥0 }.
Example 2.14 (Manufacturing cell with robots). Suppose that the succes-
sive times for machine 1 to process a part are i.i.d. according to a distribu-
tion function that has support on (0, ∞). Also suppose that the successive
times for machine 2 to process a part are i.i.d. according to an exponential
distribution. Consider the delay intervals from whenever robot 1 starts to
transfer a raw part from the loading area to conveyor 1 to when robot 1
completes transfer of the part to the unloading area, and suppose that we
wish to estimate time-average limits for the sequence of delays for all parts.
A simple inductive argument shows that (2.2) and (2.3) hold, and it fol-
lows from (1.1) that (2.4) holds. Denote by ¯s = (¯s1, ¯s2, . . . , ¯s24) the unique
marking in which ¯s4 = ¯s9 = ¯s11 = ¯s22 = ¯s24 = 1 and ¯sj = 0 otherwise, and
let { ζθ(k) : k ≥0 } be the successive random times at which the marking is
¯s and transition ¯e = e8 ﬁres. Thus ζθ(k) is the kth successive time at which

8.2 Regenerative Methods for Delays
347
machine 1 completes processing of a part, machine 2 is processing a part,
a raw part is on conveyor 1 awaiting transfer to a machine, no parts are on
conveyor 2, and the arm of each robot is in its null position. Observe that
E(¯s) = { e8, e9 } and the clock for transition e9 is always set according to a
ﬁxed exponential distribution. The condition in (2.6) holds trivially since
the new marking is always equal to a unique ﬁxed marking ¯s′ whenever
the marking is ¯s and transition ¯e ﬁres. It follows that the sequence of ran-
dom indices { ˇγ(k): k ≥0 } constructed from the sequence { θ(k): k ≥0 }
decomposes sample paths of the sequence { Dj : j ≥0 } into o.d.s. cycles.
Using techniques similar to those in the proof of Theorem 2.24 in Chap-
ter 6, we can extend the assertion in Theorem 2.8(iii) to the current setting.
Cycle sums of the form ˇY1(|f|) = 	ˇγ(1)−1
j=ˇγ(0) |f(Dj)| then can be shown to
have ﬁnite moments under appropriate moment conditions on the process-
ing-time distribution for machine 1; the required arguments are similar to
those used in Example 2.51 of Chapter 6.
Proof of Theorem 2.8
To prove Theorem 2.8, we require the following lemma, which concerns
a sequence X, X1, X2, . . . of i.i.d. random variables taking values in a set
S, along with a set A ⊂S with P { X ∈A } > 0. Deﬁne a sequence of
a.s. ﬁnite random indices { I(n): n ≥0 } by setting I(0) = 0 and I(n) =
inf { i > I(n −1): Xi ∈A } for n ≥1.
Lemma 2.15. The random subsequence

XI(n) : n ≥1

consists of i.i.d.
random variables with common distribution given by
P

XI(n) ∈B

= P { X ∈B | X ∈A }
for B ⊆S.
Proof. Fix integers k ≥1 and 1 ≤i1 < i2 < · · · < ik, along with subsets
B1, B2, . . . , Bk ⊆S, and set J = { 1, 2, . . . , ik } −{ i1, i2, . . . , ik }. Then
P

XI(n) ∈Bn for 1 ≤n ≤k
 I(1) = i1, . . . , I(k) = ik

= P{ Xin ∈Bn for 1 ≤n ≤k
 Xin ∈A for 1 ≤n ≤k; Xj ∈S −A for j ∈J }
= P { Xin ∈A ∩Bn for 1 ≤n ≤k; Xj ∈S −A for j ∈J }
P { Xin ∈A for 1 ≤n ≤k; Xj ∈S −A for j ∈J }
=
k

n=1
P { X ∈A ∩Bn }
P { X ∈A }
.
Multiplying the above equality by Pµ { I(1) = i1, . . . , I(k) = ik } and sum-
ming over all possible values of i1, . . . , ik yields the desired result, since k
and B1, B2, . . . , Bk are arbitrary.

348
8. Delays
We also need the following consequence of Proposition 1.20 in the Ap-
pendix. Consider a sequence { Fn : n ≥1 }, where each Fn is a collection
of random variables and Fn ⊂Fn+1 for n ≥1. Also consider a positive
integer-valued random variable N that is a stopping time with respect to
{ Fn : n ≥1 }—that is, for each k ≥1 the occurrence or nonoccurrence of
the event { N ≤k } is determined by the values of the random variables
in Fk. Finally, let SN = 	N
n=1 Xn, where { Xn : n ≥1 } is a sequence of
i.i.d. random variables such that Xn is determined by Fn for n ≥1 and
independent of Fn−1 for n ≥2. Then for r ≥0 there exists a constant br
(depending only on r) such that
E[|SN|r] ≤brE [|X1|r] E [N r] .
(2.16)
As before, set ˇδk = ˇγ(k) −ˇγ(k −1), so that ˇδk is the number of de-
lays that start during the interval [ζˇθ(k−1), ζˇθ(k)). Proving the ﬁrst as-
sertion of Theorem 2.8 amounts to showing that the post-ˇγ(k) process
{ (Dˇγ(k)+n, ˇδk+n+1): n ≥0 }
(i) is distributed as { (Dˇγ(0)+n, ˇδn+1): n ≥0 } for k ≥1,
(ii) is independent of { D0, D1, . . . , Dˇγ(k−1)−1; ˇδ1, ˇδ2, . . . , ˇδk−1 } for k ≥2,
and
(iii) is independent of ˇδk for k ≥0.
To this end, suppose that there is at least one ongoing delay at each re-
generation point ζθ(k). It follows that there is at least one ongoing delay
at each point ζˇθ(k), so that ˇγ(k) is simply the index of the ﬁrst delay that
starts after time ζˇθ(k): ˇγ(k) = inf{ j ≥0 : α(j) ≥ˇθ(k) }. Observe that each
ˇθ(k) is an a.s. ﬁnite stopping time with respect to the underlying chain
{ (Sn, Cn): n ≥0 }. Moreover, for each k the random variables in the se-
quence

 ˇθ(l + 1) −ˇθ(l): l ≥k

are determined by

(Sn, Cn): n ≥ˇθ(k)

according to a mechanism that does not depend explicitly on either k or
the precise values of the components of Vˇθ(k)—indeed, it can easily be seen
that
• The number of ongoing delays and the location of the corresponding
starts within the vector Vˇθ(k) are determined according to the func-
tions iα(Sˇθ(k); ¯s, ¯e), iβ(Sˇθ(k); ¯s, ¯e), and iπ(Sˇθ(k); ¯s, ¯e) and hence are
determined by Sˇθ(k).
• The number of marking changes until these ongoing delays terminate
is determined by the sequence of start-vector insertions, deletions,
and permutations that occurs after the ˇθ(k)th marking change, and
this sequence is in turn determined by the evolution of the underlying
chain after the ˇθ(k)th marking change.

8.2 Regenerative Methods for Delays
349
Figure 8.7. Regenerative cycles for delays.
An application of the strong Markov property then shows that the ran-
dom indices { ˇθ(k): k ≥0 } form a sequence of regeneration points for
the chain { (Sn, Cn): n ≥0 }. It follows from the deﬁnition of the sequence
{ Vn : n ≥0 } that for k ≥1 the post-ˇγ(k) process { (Dˇγ(k)+n, ˇδk+n+1): n ≥
0 } is determined by

(Sn, Cn): n ≥ˇθ(k)

according to a mechanism that
does not depend explicitly on k or on the precise values of the entries
in Vˇθ(k). Hence, by the regenerative property of the chain, the post-ˇγ(k)
process is distributed as the post-ˇγ(0) process. Thus, the assertion in (i)
holds. To see that the assertions in (ii) and (iii) hold, ﬁx k ≥2 and
observe that by construction the terminations B0, B1, . . . , Bˇγ(k−1)−1 are
all less than or equal to ζˇθ(k). The condition in (2.6) ensures that the
number and positions of the starts deleted from the current start vector
at time ζˇθ(k) do not depend explicitly on the new marking Sˇθ(k). Thus
the collection of random variables { D0, D1, . . . , Dˇγ(k−1)−1; ˇδ1, ˇδ2, . . . , ˇδk } is
determined completely by the process

(Sn, Cn): 0 ≤n < ˇθ(k)

. By the
regenerative property of the chain, the post-ˇγ(k) process is independent
of { D0, D1, . . . , Dˇγ(k−1)−1; ˇδ1, ˇδ2, . . . , ˇδk }, as desired. A similar argument
shows that the post-ˇγ(1) process is independent of ˇγ(1), and the ﬁrst as-
sertion of the theorem follows.
To prove the second assertion of the theorem, suppose that there are
no ongoing delays at any regeneration point ζθ(k), so that ˇθ(k) = θ(k)
for k ≥0. When each interval [ζθ(k), ζθ(k+1)] contains at least one start,
each ˇγ(k) is, as before, the index of the ﬁrst delay that starts after time
ζθ(k). An argument almost identical to the one given above then shows
that the random indices { ˇγ(k): k ≥0 } decompose the sample paths of
the sequence { Dj : j ≥0 } into i.i.d. cycles and hence form a sequence of
regeneration points. The situation is more complicated when, with positive

350
8. Delays
probability, at least one interval contains no starts. Then each ˇγ(k) is no
longer simply the index of the ﬁrst delay that starts after time ζθ(k), and
our previous arguments cannot be applied directly. For example, ˇγ(2) in
Figure 8.7 is not the index of the ﬁrst delay that starts after time ζθ(2). To
handle this situation, we assign to each “empty” interval a ﬁctitious delay
and work with the sequence of random variables consisting of the ﬁctitious
delays together with the original delays. Speciﬁcally, with each interval
[ζθ(k), ζθ(k+1)] that contains no starts we associate a ﬁctitious delay with
a value of −1 and a start index α equal to θ(k). Let

D′
j : j ≥0

be the
sequence consisting of the original delays together with the ﬁctitious delays,
ordered by increasing starts, and deﬁne the sequences { α′(j): j ≥0 } and
{ ˇγ′(k): k ≥0 } accordingly. Also set ˇδ′
k = ˇγ′(k) −ˇγ′(k −1) for k ≥1.
The previous arguments applied to

D′
j : j ≥0

show that the sequence
{ X′
k : k ≥0 } consists of i.i.d. random vectors, where
X′
k = (ˇδ′
k, D′
ˇγ′(k), D′
ˇγ′(k)+1, . . . , D′
ˇγ′(k+1)−1).
Observe that the sequence { Xk : k ≥0 }, where
Xk = (ˇδk, Dˇγ(k), Dˇγ(k)+1, . . . , Dˇγ(k+1)−1),
can be viewed as a random subsequence of { X′
k : k ≥0 }. By Lemma 2.15,
the sequence { Xk : k ≥0 } inherits the i.i.d. property of { X′
k : k ≥0 }, and
the desired result follows.
For k ≥1, set ˇτk = ζˇθ(k) −ζˇθ(k−1), and recall that τk = ζθ(k) −ζθ(k−1),
that ˇδk = ˇγ(k) −ˇγ(k −1) is the number of delays that start during the
interval [ζˇθ(k−1), ζˇθ(k)), and that δk is the number of delays that start during
the interval [ζθ(k−1), ζθ(k)). To prove the ﬁnal assertion of the theorem, it
suﬃces to show that, for r ≥1,
Eµ
ˇδr
1

< ∞
whenever
Eµ [δr
1] < ∞
(2.17)
and
Eµ [ˇτ r
1 ] < ∞
whenever
Eµ [τ r
1 ] < ∞.
(2.18)
To see that the desired result follows from (2.17) and (2.18), ﬁx constants
r, b, p, and q as in the statement of the theorem, along with a function f
that is polynomially dominated to degree b. Observe that
ˇY1(|f|) ≤aˇδk

(ˇτ1 + ˇτ2)b + 1

for some ﬁnite nonnegative constant a. Since

(ˇτ1 + ˇτ2)b + 1
r ≤2(b+1)r−2(ˇτ rb
1 + ˇτ rb
2 ) + 2r−1

8.2 Regenerative Methods for Delays
351
by two applications of the cr-inequality, it follows from H¨older’s inequality
that
Eµ
 ˇY r
1 (|f|)

≤a′
Eµ
ˇδr
1ˇτ rb
1

+ Eµ
ˇδr
1ˇτ rb
2

+ Eµ
ˇδr
1

≤2a′E1/p
µ
ˇδrp
1

E1/q
µ
[ˇτ rbq
1
] + a′Eµ
ˇδr
1

,
where a′ = 2(b+1)r−1ar. Since Eµ [δrp
1 ] and Eµ[τ rbq
1
] are ﬁnite by hypothesis,
the desired result follows.
We complete the argument by establishing (2.17); the proof of (2.18) is
similar. First suppose that there are no ongoing delays at any regeneration
point ζθ(k) and that each interval [ζθ(k−1), ζθ(k)) contains at least one start.
Then ˇδk = δk for k ≥1 and (2.17) follows trivially. Next suppose that there
are no ongoing delays at any regeneration point ζθ(k) and that one or more
intervals of the form [ζθ(k−1), ζθ(k)) contain no starts. For k ≥1, let Jk be
the indicator variable for the event that there is at least one start in the
interval [ζθ(k−1), ζθ(k)):
Jk =

1
if 	∞
n=0 1[θ(k−1),θ(k))

α(n)

> 0;
0
otherwise.
Observe that Pµ { J1 = 1 } > 0 by (2.4) so that, using Lemma 2.15,
Eµ
ˇδr
1

=
Eµ[δr
1J1]
Pµ { J1 = 1 } ≤
Eµ[δr
1]
Pµ { J1 = 1 } < ∞,
as desired. Finally, suppose that there are ongoing delays at each regener-
ation point ζθ(k), and write
ˇδ1 =
N

k=1
δk,
(2.19)
where N is the number of points of the sequence { θ(k): k ≥0 } that lie
in the interval
ˇθ(0), ˇθ(1)

. Since Eµ [δr
1] < ∞by hypothesis, the desired
result follows from (2.16), provided that Eµ [N r] < ∞—take Xn = δn and
Fn = { (Sj, Cj): 0 ≤j ≤θ(n) −1 } .
We therefore ﬁnish the proof by showing that N has ﬁnite moments of all
orders, using an argument similar to the ﬁnal part of the proof of Theo-
rem 2.24 in Chapter 6. For k ≥1, let ν(k) be the index of the ﬁrst marking
change after θ(k) such that all ongoing delays at the θ(k)th marking change
have terminated, and set Λk = ν(k)−θ(k); if there are no ongoing delays at
time ζθ(k), then set Λk = 0. Also set Λ0 = K, where K is deﬁned by (1.3).

352
8. Delays
Observe that { Λk : k ≥0 } is a sequence of identically distributed random
variables. We claim that there exists m ≥1 such that
Pµ { Λk < θ(k + m) −θ(k) } > 0
for k ≥0; otherwise, since (1.1) implies that limk→∞θ(k) = ∞a.s., it fol-
lows from Bonferroni’s inequality—Proposition 1.1(vi) in the Appendix—
that
Pµ { K = ∞} = Pµ { Λ0 = ∞} = Pµ { Λ0 ≥θ(m) −θ(0) for m ≥1 } = 1,
contradicting (2.2). For l ≥0, set Jl = 1 if Λlm ≥θ

(l + 1)m

−θ(lm);
otherwise, set Jl = 0. It follows from (2.1) and (2.6) that each Jl is de-
termined by

(Sn, Cn): θ(lm) ≤n < θ

(l + 1)m
 
. Since { θ(k): k ≥0 }—
and hence { θ(lm): l ≥0 }—is a sequence of regeneration points for the un-
derlying chain, it follows that { Jl : l ≥0 } is a sequence of i.i.d. random
variables with p = Pµ { J1 = 1 } < 1. Thus
Pµ { N > lm } ≤Pµ { J0 = 1, J1 = 1, . . . , Jl−1 = 1 } = pl
for l ≥1, so that the distribution of N/m has geometrically decreasing tail
probabilities and hence N has ﬁnite moments of all orders.
8.2.2
The Extended Regenerative Method for Delays
Suppose that we have constructed a sequence of od-equilibrium points
{ ˇγ(k): k ≥0 } as above and wish to estimate time-average limits of the
form limn→∞(1/n) 	n−1
j=0 f(Dj), where f is a real-valued function. Under
the moment conditions given below, it follows from Theorem 1.27 in Chap-
ter 6 that such time-average limits exist a.s.. Moreover, the extended re-
generative method developed in Section 6.3.8 can be applied in the current
setting to obtain strongly consistent point estimates and asymptotic conﬁ-
dence intervals for time-average limits.
As before, set ˇδk = ˇγ(k) −ˇγ(k −1) for k ≥1, so that ˇδk is the length of
the kth cycle. Let f be a real-valued function and set
ˇYk(f) =
ˇγ(k)−1

j=ˇγ(k−1)
f(Dj)
for k ≥0. By the od-equilibrium property, the sequence { ˇδk : k ≥1 } con-
sists of i.i.d. random variables and the sequence

  ˇYk(f), ˇδk

: k ≥1

con-
sists of o.d.s. random vectors. Suppose that Eµ[ˇδ1] < ∞and Eµ[ ˇY1(|f|)] <
∞. It then follows from Theorem 1.27 in Chapter 6 that
lim
n→∞
1
n
n−1

j=0
f(Dj) = Eµ
 ˇY1(f)

Eµ[ˇδ1]
def
= r(f) a.s..

8.2 Regenerative Methods for Delays
353
To obtain estimates for the quantity r(f), observe a ﬁxed number n of
cycles of { Dj : j ≥0 } and measure the quantities ˇY1(f), ˇY2(f), . . . , ˇYn(f)
and ˇδ1, ˇδ2, . . . , ˇδn. Set ˆr(n) = ¯Y (n)/¯δ(n), where ¯Y (n) = (1/n) 	n
k=1 ˇYk(f)
and ¯δ(n) = (1/n) 	n
k=1 ˇδk. Next, take
ˇs2(n) =
1
n −1
n

k=1
( ˇYk(f) −ˆr(n)ˇδk)2
+
2
n −1
n−1

k=1
( ˇYk(f) −ˆr(n)ˇδk)( ˇYk+1(f) −ˆr(n)ˇδk+1)
as an estimator of
ˇσ2(f) = Varµ
 ˇY1(f) −r(f)ˇδ1

+ 2Covµ
 ˇY1(f) −r(f)ˇδ1, ˇY2(f) −r(f)ˇδ2

.
As discussed in Section 6.3.8, we have ˆr(n) →r(f) a.s., ˇs2(n) →ˇσ2(f)
a.s., and
√n

ˆr(n) −r(f)

ˇs(n)/¯δ(n)
⇒N(0, 1)
as n →∞, where N(0, 1) is a standard normal random variable and ⇒
denotes convergence in distribution. These results lead directly to the fol-
lowing estimation procedure.
Algorithm 2.20 (Extended regenerative method for delays)
1. Select a single state ¯s and deﬁne the corresponding sequence { ˇθ(k) :
k ≥0 } of random indices for the underlying chain { (Sn, Cn): n ≥0 }.
2. Deﬁne the corresponding sequence {ˇγ(k): k ≥0 } of random indices
for the sequence { Dj : j ≥0 } of delays via (2.7).
3. Simulate the marking process { X(t): t ≥0 } and observe a ﬁxed
number n of cycles deﬁned by the random indices { ˇγ(k): k ≥0 }.
4. Compute the length ˇδk of the kth cycle and the quantity ˇYk(f) =
	ˇγ(k)−1
j=ˇγ(k−1) f(Dj) for 1 ≤k ≤n.
5. Form the strongly consistent point estimate ˆr(n) = ¯Y (n)/¯δ(n) for
r(f).
6. Form the asymptotic 100p% conﬁdence interval
!
ˆr(n) −zp ˇs(n)
¯δ(n) √n, ˆr(n) + zp ˇs(n)
¯δ(n) √n
"
for r(f), where zp is the (1 + p)/2 quantile of the standard normal
distribution.

354
8. Delays
Remark 2.21. If ˇδ1 is aperiodic with ﬁnite mean, then Dj ⇒D as j →∞
and r(f) = E [f(D)]—see Theorem 1.31 in Chapter 6. Thus, under these
conditions the quantity r(f) can be interpreted not only as a time-average
limit but also as a steady-state mean.
Remark 2.22. Algorithm 2.20 can be simpliﬁed when there are no ongoing
delays at any regeneration point ζθ(k). Then ˇθ(k) = θ(k) for k ≥0, and the
random indices { ˇγ(k): k ≥0 } form a sequence of regeneration points for
{ Dj : j ≥0 }. It follows that
Covµ[ ˇY1(f) −r(f)ˇδ1, ˇY2(f) −r(f)ˇδ2] = 0,
and the quantity ˇs(n) in the conﬁdence interval (3.6) can be replaced by
s(n)
def
=

1
n −1
n

k=1
( ˇYk(f) −ˆr(n)ˇδk)2
1/2
.
The resulting estimation procedure coincides with the standard regenera-
tive method.
Remark 2.23.
Strongly consistent point estimates and asymptotic conﬁ-
dence intervals for r(f) can also be based on simulation of the process
{ X(t): t ≥0 } for a ﬁxed (simulated) time u. Compute statistics for the
random number n(u) of cycles completed by time u. Then ˆr

n(u)

→r(f)
a.s. and
4
n(u)

ˆr

n(u)

−r(f)

ˇs

n(u)

/¯δ

n(u)

⇒N(0, 1)
(2.24)
as u →∞. The proof of this assertion is similar to that of Theorem 3.18
in Chapter 6 but uses Corollary 2.10 in the Appendix.
8.2.3
The Multiple-Runs Method
As an alternative to the extended regenerative method, the multiple-runs
method introduced in Section 6.3.8 can be used in the current setting to
obtain strongly consistent point estimates and asymptotic conﬁdence in-
tervals for time-average limits of a sequence of delays.
Suppose that the condition in (2.6) holds with jα and jβ deﬁned so that
there is always at least one ongoing delay at each regeneration point ζθ(n).
Deﬁne sequences

 ˇθ(k): k ≥0

, { ˇγ(k): k ≥0 }, and {
 ˇYk(f), ˇδk

: k ≥1 }
as before, and suppose that for a ﬁxed real-valued function f we have
Eµ[ˇδ1] < ∞and Eµ[ ˇY1(|f|)] < ∞, so that
lim
n→∞
1
n
n−1

j=0
f(Dj) = Eµ
 ˇY1(f)

Eµ[ˇδ1]
def
= r(f) a.s..

8.2 Regenerative Methods for Delays
355
Denote by T the time required to observe the ﬁrst cycle of the sequence
{ Dj : j ≥0 }:
T = max{Bj : 0 ≤j < ˇγ(1)}.
Observe that there is at least one ongoing delay at each time ζˇθ(k), so
that ζˇθ(1) < T ≤ζˇθ(2). To obtain estimates for r(f), simulate the process
{ X(t): t ≥0 } up to the random time T to create { X1(t): 0 ≤t ≤T1 } and
{ Dj,1 : 0 ≤j < ˇγ1(1) }. Repeat this step m times to create m independent
replicates and produce { Xi(t): 0 ≤t ≤Ti } and { Dj,i : 0 ≤j < ˇγi(1) }
for 1 ≤i ≤m. Then compute point estimates and conﬁdence intervals for
r(f) as in the standard regenerative method, treating the latter sequences
as regenerative cycles. The precise algorithm is as follows.
Algorithm 2.25 (Multiple-runs method for delays)
1. Using a ﬁxed number m of independent simulation runs, generate the
“cycles” { Dj,i : 0 ≤j < ˇγi(1) } for 1 ≤i ≤m.
2. Compute the length ˇδ1,i = ˇγi(1) of the ith cycle and the quantity
ˇY1,i(f) =
ˇγi(1)−1

j=0
f(Dj,i)
for 1 ≤i ≤m.
3. Form the strongly consistent point estimate ˆrM(m) = ¯YM(m)/¯δM(m)
for r(f), where
¯YM(m) = 1
m
m

i=1
ˇY1,i(f)
and
¯δM(m) = 1
m
m

i=1
ˇδ1,i.
4. Compute the quantity
ˇs2
M(m) =
1
m −1
m

i=1

ˇY1,i(f) −ˆrM(m)ˇδ1,i
2
as an estimator that is strongly consistent for
ˇσ2
M(f) = Varµ
 ˇY1(f) −r(f)ˇδ1

.
5. Form the asymptotic 100p% conﬁdence interval
!
ˆr(n) −zp ˇsM(m)
¯δM(m) √m, ˆr(n) + zp ˇsM(m)
¯δM(m) √m
"
for r(f), where zp is the (1 + p)/2 quantile of the standard normal
distribution.

356
8. Delays
Remark 2.26. Analogously to the extended regenerative method, point and
interval estimates can be based on the random number of runs completed
within a total budget of u units of simulated time. Compute statistics for
the random number m(u) = inf{ m ≥0: 	m
i=1 Ti ≤u } of completed
runs as in the standard regenerative method. Then, by Theorem 3.18 in
Chapter 6, we have ˆrM

m(u)

→r(f) a.s. and
4
m(u)

ˆrM

m(u)

−r(f)

ˇsM

m(u)

/¯δM

m(u)

⇒N(0, 1)
(2.27)
as u →∞.
Remark 2.28. As discussed previously, the variance estimators ˇs2(n) and
ˇs2
M(m) for the extended regenerative method and the multiple-runs method
can be computed by means of a single pass through the data—see Re-
mark 3.59 in Chapter 6.
For a ﬁxed value of p ∈(0, 1), we take the asymptotic relative eﬃciency
(are) of the extended regenerative and multiple-runs methods to be the
limiting ratio of the lengths of the 100p% conﬁdence intervals for r(f)
as the simulated time becomes large. Denote by I(u; p) the length of the
100p% conﬁdence interval for r(f) produced by the extended regenerative
method based on a budget of u units of simulated time, and let IM(u; p) be
the corresponding length for the multiple-runs method. The central limit
theorems in (2.24) and (2.27) imply that
I(u; p) =
2 zp ˇs

n(u)

¯δ

n(u)
 4
n(u)
and
IM(u; p) =
2 zp ˇsM

m(u)

¯δM

m(u)
 4
m(u)
.
Using Theorem 2.9 in Chapter 3 along with the sllns for i.i.d. and o.i.d.
random variables, it is straightforward to show that
lim
u→∞
m(u)
u
=
1
Eµ [T] a.s.,
lim
u→∞
n(u)
u
=
1
Eµ[ζˇθ(1)] a.s.,
and
lim
m→∞
¯δM(m) = lim
n→∞
¯δ(n) = Eµ
ˇδ1

a.s..
These results imply that the are is given by
lim
u→∞
I(u; p)
IM(u; p) =
ˇσ(f)
ˇσM(f)

Eµ[ζˇθ(1)]
Eµ [T]
1/2
a.s.

8.2 Regenerative Methods for Delays
357
for all p ∈(0, 1).
Observe that
Eµ[ζˇθ(1)] ≤Eµ [T] ≤2Eµ[ζˇθ(1)]
and, by the Cauchy–Schwarz inequality,
Covµ
 ˇY1(f) −r(f)ˇδ1, ˇY2(f) −r(f)ˇδ2

≤Varµ
 ˇY1(f) −r(f)ˇδ1

.
We thus obtain the elementary bounds
0 ≤
ˇσ(f)
ˇσM(f)

Eµ[ζˇθ(1)]
Eµ [T]
1/2
≤
√
3.
If Covµ
 ˇY1(f) −r(f)ˇδ1, ˇY2(f) −r(f)ˇδ2

≥0, then ˇσ(f)/ˇσM(f) ≥1 and we
obtain the sharper bounds
1
√
2 ≤
ˇσ(f)
ˇσM(f)

Eµ[ζˇθ(1)]
Eµ [T]
1/2
≤
√
3.
(2.29)
Recall from Section 6.3.8 that the multiple-runs method is more eﬃcient
than the extended regenerative method when these methods are used to
estimate time-average limits of the marking process or underlying chain. In
contrast, the foregoing bounds suggest that, in the context of estimating
time-average limits for delays, neither the extended regenerative method
nor the multiple-runs method is more eﬃcient in all situations. The reason
for this discrepancy is as follows. As in Section 6.3.8, the point estimator
of r(f) in the multiple-runs method typically has lower variance than the
estimator in the extended regenerative method. The variance is lower be-
cause the cycles in the former method are independent and there are no
covariance eﬀects. On the other hand, the multiple-runs method is more
expensive to execute, for the following reason. Generation of the kth cycle
of the delay process requires simulation of the marking process over an
interval of the form [ζˇθ(k), Tk], where Tk > ζˇθ(k+1). In the multiple-runs
method, the marking process must, in eﬀect, be simulated over the interval
[ζˇθ(k+1), Tk] twice—once to generate the kth replicate and once to generate
the (k+1)st replicate—whereas the extended regenerative method requires
simulation over this interval only once. Indeed, the following example shows
that the are can be arbitrarily close to
√
2 or to 1/
√
2. In the latter case,
we have Covµ
 ˇY1(f) −r(f)ˇδ1, ˇY2(f) −r(f)ˇδ2

> 0, and so the lower bound
in (2.29) is tight.
Example 2.30 (Comparison of the extended regenerative and multiple-
runs methods for delays). Consider an spn with two places and two deter-
ministic timed transitions as in Figure 8.8. Suppose that the two transitions

358
8. Delays
Figure 8.8. spn for comparison of estimation methods.
Figure 8.9. Comparison of estimation methods.
never ﬁre simultaneously. Deﬁne a sequence of delays via start vectors by
setting ψ

(1, 0)

= 2, ψ

(0, 1)

= 1,
iα(s′;s,E∗) =

(0)
if E∗= { e2 };
∅
otherwise,
iβ(s′; s, E∗) =

(2)
if E∗= { e1 };
∅
otherwise,
and iπ(s′; s, E∗) ≡∅. To initialize the sequence of start vectors, set V0 =
(0, −1). The marking s = (0, 1) is a single state, so that the successive
times

ζθ(k) : k ≥0

at which transition e2 ﬁres form a sequence of regen-
eration points for the marking process. Deﬁne sequences { ζˇθ(k) : k ≥0 }
and { ˇγ(k): k ≥0 } as before—see Figure 8.9. In the ﬁgure, Xk denotes the
time from the start of the kth cycle to the next ﬁring of transition e1 and
Yk denotes the time from the ﬁring of e1 until the end of the kth cycle. Ob-
serve that the random variables X1, X2, ... coincide with the successive new
clock readings for transition e1 and the random variables Y1, Y2, ... coincide
with the successive new clock readings for transition e2. Take f(x) = x for
x ≥0. Because ˇδk ≡1 for k ≥1 and { (Xk, Yk): k ≥0 } is a sequence of
i.i.d. pairs with each Xk and Yk independent, an easy calculation shows

8.2 Regenerative Methods for Delays
359
that
ˇσ2(f)
ˇσ2
M(f) = 4Var [X1] + Var [Y1]
2Var [X1] + Var [Y1]
and
Eµ[ζˇθ(1)]
Eµ [T]
= E [X1] + E [Y1]
2E [X1] + E [Y1].
Suppose that, for some n > 0,
X1 =

0
with probability (n −1)/n;
n
with probability 1/n,
so that E [X1] = 1 and Var [X1] = n −1, and suppose that Y1 = n with
probability 1. Then the are of the extended regenerative and multiple-runs
methods is given by
are =
√
2
)1 + n
2 + n
*1/2
,
which converges to
√
2 as n becomes large. On the other hand, if we switch
the deﬁnitions of X1 and Y1, then
are =
) n + 1
2n + 1
*1/2
,
which converges to 1/
√
2 as n becomes large.
Example 2.31 (Cyclic queues with feedback). We compare the extended
regenerative and multiple-runs methods for delays using the network of
queues in Example 1.2. Successive service times at center i (i = 1, 2) are
i.i.d. according to an exponential distribution with intensity qi, where q1 =
1.5 and q2 = 1. The routing probability (with which a job completing
service at center 1 moves to center 2) is p = 0.6. There are N = 4 jobs,
and—as in Example 1.4—we model the system using the spn in Figure 2.2.
We consider the delay intervals from whenever a job completes service at
center 2 to when the job next completes service at center 2, and estimate the
limiting average delay. (In the following section we provide some specialized
techniques for estimating this particular performance measure.) Both the
extended regenerative and multiple-runs methods are based on the sequence
of od-equilibrium points for delays deﬁned in Example 2.12.
Table 8.2 displays estimates of ˇσ2(f), ˇσ2
M, Covµ[ ˇY1(f) −r(f)ˇδ1, ˇY2(f) −
r(f)ˇδ2], Eµ[ζˇθ(1)], Eµ [T], and the are of the two methods, based on 106
cycles. As can be seen, the covariance between adjacent cycles is positive,
so that the variance constant for the extended regenerative method exceeds
the variance constant for the multiple-runs method. The additional expense
per cycle for the multiple-runs method (as measured by Eµ [T] −Eµ[ζˇθ(1)])

360
8. Delays
Table 8.2. Simulation Results for Cyclic Queues with Feedback: Estimated Quan-
tities for Comparison of Extended Regenerative and Multiple-Runs Methods,
Based on 106 Cycles
ˇσ2(f)
ˇσ2
M(f)
Cov
Eµ[ζˇθ(1)]
Eµ [T]
are
145.9
136.5
4.7
11.3
14.3
0.92
Note: “Cov” = Covµ[ ˇY1(f) −r(f)ˇδ1, ˇY2(f) −r(f)ˇδ2].
Table 8.3. Simulation Results for Cyclic Queues with Feedback: Point Esti-
mates and 95% Conﬁdence-Interval Half-Widths for the Limiting Average Delay
Through Both Centers (True Value = 5.2924)
Number of cycles simulated (×103)
0.1
1
10
100
1000
5.4969
5.3510
5.2872
5.2905
5.2904
±0.1990
±0.0883
±0.0281
±0.0088
±0.0028
is suﬃciently large so that the are is less than 1 and the extended regener-
ative method is more eﬃcient overall. Table 8.3 displays typical simulation
results based on the extended regenerative method.
In practice, a small pilot run can be used to estimate the are and select
the more eﬃcient of the two estimation methods.
8.2.4
Limiting Average Delays
Under the moment conditions given below, the limiting average delay
r = lim
n→∞
1
n
n−1

j=0
Dj
exists a.s., and both point estimates and conﬁdence intervals for the limiting
average delay can be obtained without measuring the lengths of individual
delay intervals. Recall that ψ(s) is the length of the start vector when
the marking is s and that the number of newly started delays is given by
nα(s′; s, E∗) whenever the transitions in the set E∗ﬁre simultaneously and
trigger a marking change from s to s′. Set
Zk =
 ζθ(k)
ζθ(k−1)
ψ

X(t)

dt =
θ(k)−1

n=θ(k−1)
ψ(Sn)t∗(Sn, Cn),
τk = ζθ(k) −ζθ(k−1), and δk = 	θ(k)−1
n=θ(k−1) nα(Sn; Sn−1, E∗
n−1) for k ≥1.
Because Zk, τk, and δk are determined by { (Sn, Cn): θ(k −1) ≤n < θ(k) }

8.2 Regenerative Methods for Delays
361
for k ≥1, it follows that the sequence { (Zk, τk, δk): k ≥1 } consists of i.i.d.
random vectors. The proof of the following result is given at the end of the
subsection.
Theorem 2.32. Suppose that Eµ [Z1] < ∞and Eµ [δ1] < ∞and that
(2.2)–(2.4) hold. Then
lim
n→∞
1
n
n−1

j=0
Dj = Eµ [Z1]
Eµ[δ1] a.s..
(2.33)
It follows from (2.33) that a version of the standard regenerative method
can be used to obtain strongly consistent point estimates and asymptotic
conﬁdence intervals for the limiting average delay.
Algorithm 2.34 (Regenerative method for the limiting average delay)
1. Select a single state ¯s and deﬁne a corresponding sequence {θ(k): k ≥
0 } of random indices as in (2.1).
2. Simulate the marking process { X(t): t ≥0 } and observe a ﬁxed
number n of cycles deﬁned by the random times

ζθ(k) : k ≥0

.
3. Compute the number of starts δk in the kth cycle and the quantity
Zk =
 ζθ(k)
ζθ(k−1) ψ

X(t)

dt for 1 ≤k ≤n.
4. Form the strongly consistent point estimate ˆr(n) = ¯Z(n)/¯δ(n) for r,
where ¯Z(n) = (1/n) 	n
k=1 Zk and ¯δ(n) = (1/n) 	n
k=1 δk.
5. Set
s2(n) =
1
n −1
n

k=1

Zk −ˆr(n)δk
2
and form the asymptotic 100p% conﬁdence interval
!
ˆr(n) −zp s(n)
¯δ(n) √n, ˆr(n) + zp s(n)
¯δ(n) √n
"
for r(f), where zp is the (1 + p)/2 quantile of the standard normal
distribution.
Remark 2.35. As usual, we can write s2(n) in the form
s2(n) = s11(n) −2ˆr(n)s12(n) + ˆr2(n)s22(n),
where
s11(n) =
1
n −1
n

k=1

Zk −¯Z(n)
2,

362
8. Delays
Figure 8.10. Deﬁnition of ˇ
N0, ˇ
N1, ˇ
N2, ˇZ1, ˇZ2, ˇY1, and ˇY2.
s22(n) =
1
n −1
n

k=1

δk −¯δ(n)
2,
and
s12(n) =
1
n −1
n

k=1

Zk −¯Z(n)

δk −¯δ(n)

.
We can then use one-pass methods as in Remark 3.8 in Chapter 6 to com-
pute s2(n) during the course of the simulation.
Remark 2.36.
Observe that the Algorithm 2.34 is applicable even when
there are ongoing delays at each regeneration point ζθ(k), so that the se-
quence { Dj : j ≥0 } does not inherit regenerative structure.
Remark 2.37. The limiting average delay can also be estimated using the
extended regenerative method or the multiple-runs method. It can be shown
that the point estimators in all three methods have the same asymptotic
variability. Algorithm 2.34, however, does not incur the cost of measuring
each individual delay and therefore is asymptotically more eﬃcient than the
other two algorithms in the sense of providing shorter conﬁdence intervals
for equivalent simulation cost.
Proof of Theorem 2.32. We give the proof when (2.6) holds; a modi-
ﬁcation as in Remark 2.11 can be used to handle the case in which (2.6)

8.2 Regenerative Methods for Delays
363
does not hold. Deﬁne sequences of random indices { ˇθ(k): k ≥0 } and
{ ˇγ(k): k ≥0 } as in Section 8.2.1. As shown in the proof of Theorem 2.8,
the random indices

 ˇθ(k): k ≥0

form a sequence of regeneration points
for the chain { (Sn, Cn): n ≥0 } and the random times { ζˇθ(k) : k ≥0 } form
a sequence of regeneration points for the process { X(t): t ≥0 }. Set
ˇYk =
ˇγ(k)−1

j=ˇγ(k−1)
Dj,
ˇδk = ˇγ(k) −ˇγ(k −1),
ˇNk =
ˇγ(k)−1

j=ˇγ(k−1)
(Bj −ζˇθ(k))+,
and
ˇZk =
 ζˇ
θ(k)
ζˇ
θ(k−1)
ψ

X(t)

dt
for k ≥1. Denote by Kn (n ≥0) the number of components of the start
vector Vn that are equal to −1, and set ˇN0 = 	∞
n=0 Kn(ζn+1−ζn). Observe
that
ˇZk = ˇNk−1 +
ˇγ(k)−1

j=ˇγ(k−1)
min(Dj, ζˇθ(k) −Aj)
for k ≥1. Figure 8.10 illustrates these deﬁnitions when there are exactly
two ongoing delays at each regeneration point and exactly two components
of the initial start vector V0 are equal to −1. In the ﬁgure an arrow point-
ing to the horizontal axis indicates a marking-change epoch at which a
deleted component is equal to −1. Labels of the form li,j denote lengths of
horizontal line segments.
As shown in the proof of Theorem 2.8, Eµ[δ1] < ∞implies Eµ[ˇδ1] < ∞.
An almost identical argument shows that Eµ[Z1] < ∞implies Eµ[ ˇZ1] < ∞.
Because 0 ≤
ˇN0 ≤
ˇZ1, it then follows that Eµ
 ˇN0

< ∞. Next ob-
serve that

 ˇNn : n ≥0

is a sequence of i.i.d. random variables, so that
Eµ
 ˇNk

< ∞for k ≥1. Finally, observe that ˇY1 = ˇZ1 + ˇN1 −ˇN0, so
that Eµ
 ˇY1

= Eµ
 ˇZ1

< ∞. As shown in the proof of Theorem 2.8, the
sequence { ˇγ(k): k ≥0 } of random indices decomposes sample paths of the
sequence { Dj : j ≥0 } into o.d.s. cycles and
lim
n→∞
1
n
n−1

j=0
Dj = Eµ
 ˇY1

Eµ[ˇδ1] a.s..
(2.38)

364
8. Delays
As Eµ
 ˇY1

= Eµ
 ˇZ1

, however, we have
Eµ
 ˇY1

Eµ[ˇδ1] = Eµ
 ˇZ1

Eµ[ˇδ1] = Eµ [Z1]
Eµ [δ1] .
(2.39)
To obtain the second equality, we express the numerator and the denomina-
tor on the left side as random sums—cf. (2.19)—and apply Wald’s identity
[Proposition 1.19(i) in the Appendix]. The desired result now follows from
(2.38) and (2.39).
As before, let τk = ζθ(k) −ζθ(k−1) for k ≥1. Under the additional as-
sumption that Eµ [τ1] < ∞, an alternative proof of Theorem 2.32 can be
based on the following version of Little’s law.
Proposition 2.40. Let { [Aj, Bj]: j ≥0 } be a sequence of (possibly emp-
ty) random intervals such that the Aj’s are nondecreasing, and set Dj =
Bj −Aj for j ≥0. Denote by NA(t) the number of An’s that lie in the
interval [0, t], and similarly deﬁne NB(t). Suppose that there exist ﬁnite
positive constants l and λ such that
lim
t→∞
NA(t)
t
= λ a.s.
and
lim
t→∞
1
t
 t
0

NA(u) −NB(u)

du = l a.s..
Also suppose that limj→∞Dj/j = 0 a.s.. Then there exists a ﬁnite positive
constant w such that
lim
n→∞
1
n
n−1

j=0
Dj = w a.s.
and l = λw.
To prove Theorem 2.32, denote by NA(t) and NB(t) the number of delays
that start and terminate, respectively, during the interval [0, t]. Observe
that NA(t) −NB(t) = ψ

X(t)

for t ≥ζK, where the random index K
is deﬁned by (1.3). It follows from the slln for i.i.d. random variables
together with Theorem 2.9(v) in Chapter 3 that
λ
def
= lim
t→∞
NA(t)
t
= Eµ [δ1]
Eµ [τ1] ∈(0, ∞) a.s..
(2.41)

8.3 STS Methods for Delays
365
Similarly, by Theorem 1.12 in Chapter 6,
l
def
= lim
t→∞
1
t
 t
0

NA(u) −NB(u)

du
= lim
t→∞
1
t
 t
0
ψ

X(u)

du
= Eµ [Z1]
Eµ [τ1]
< ∞a.s..
Provided that limj→∞Dj/j = 0 a.s., the desired result then follows from
Proposition 2.40.
To see that limj→∞Dj/j = 0 a.s., deﬁne a sequence

 ˇθ(k): k ≥0

of
a.s. ﬁnite regeneration points for { (Sn, Cn): n ≥0 } as in Section 8.2.1.
Set Hk = ζˇθ(k+2) −ζˇθ(k) for k ≥0. The random variables in the sequence
{ Hk : k ≥0 } are o.i.d. and Eµ[H0] = 2Eµ[ζˇθ(1)] < ∞; the ﬁniteness follows
from (2.18), which is valid in the current setting. Next, set K(t) = sup{ k ≥
0: ζˇθ(k) ≤t } for t ≥0, and observe that
Dj
j
≤HK(Aj)
j
= HK(Aj)
K(Aj)
K(Aj)
Aj
Aj
j
for j ≥0. Observe that limj→∞Aj = ∞a.s. by (2.4) and limt→∞K(t) = ∞
because each ζˇθ(k) is a.s. ﬁnite—see Theorem 2.9(ii) in Chapter 3. Moreover,
(2.41) and the identity NA(Aj) = j + 1 for j ≥0 jointly imply that
lim
j→∞
Aj
j
= λ−1 < ∞a.s..
It therefore suﬃces to show that
lim
k→∞
Hk
k
= 0
and
lim
t→∞
K(t)
t
< ∞
with probability 1. Almost-sure convergence of Hk/k to 0 follows from the
slln for o.i.d. random variables together with Theorem 2.9(i) in Chapter 3,
and the latter theorem also implies that limt→∞K(t)/t = 1/Eµ[ζˇθ(1)] < ∞
a.s..
8.3
STS Methods for Delays
This section deals with sts methods for estimating time-average limits of a
sequence of delays. Such methods are useful when there is no apparent (or
usable) sequence of regeneration points for the underlying chain or marking

366
8. Delays
process, so that the methods of Section 8.2 are not applicable. When trying
to apply sts methods, we face the usual problem: it is highly nontrivial
to determine for a speciﬁc spn, start-vector mechanism, and function f
whether the output process { f(Dj): j ≥0 } obeys an slln and whether
sts methods are valid.
As in Chapter 7, we focus on spns that satisfy Assumption PD, so that
there exists a sequence of od-regeneration points that decompose the sam-
ple paths of the underlying chain into o.d.s. cycles. In Section 8.3.1 we
show that under Assumption PD and some mild regularity conditions on
the start-vector mechanism, the output process { f(Dj): j ≥0 } inherits
the od-regenerative property. Moreover, for suitable functions f the sum
of the process over a cycle has ﬁnite moments of all orders. Unlike in Sec-
tion 8.2, the cycles of the output process usually cannot be determined
explicitly, and neither the extended regenerative method for delays nor the
multiple-runs method can be applied. The mere existence of these cycles,
however, implies that the output process obeys an fclt. As in Chapter 7,
it then follows—see Section 8.3.2—that sts methods such as the method
of batch means can be used to obtain strongly consistent point estimates
and asymptotic conﬁdence intervals for time-average limits and functions
of time-average limits.
8.3.1
Stable Sequences of Delays
Consider a sequence of delays { Dj : j ≥0 } determined from the under-
lying chain { (Sn, Cn): n ≥0 } of an spn using the method of start vectors.
Lemma 2.5 in Chapter 7 gives conditions under which the underlying chain
is an od-regenerative process and cycle sums have ﬁnite moments of all
orders. As shown below, these stability properties are inherited by the se-
quence { Dj : j ≥0 } provided that the start-vector mechanism is “regular”
in the sense of Deﬁnition 3.1 below. The idea is to exploit the regularity
of the start-vector mechanism and construct a sequence { ˇγ(k): k ≥0 } of
random indices that decomposes sample paths of { Dj : j ≥0 } into o.d.s.
cycles.
Regular Start-Vector Mechanisms
To prepare for Deﬁnition 3.1, set
E(s) =

{ e } : e ∈E(s) and r(s, e) > 0

if s ∈S;
{ E(s) ∩S′ }
if s ∈S′
for s ∈G. Thus, assuming that each timed transition has a continuous
clock-setting distribution function, we have E∗∈E(s) if and only if the
transitions in E∗can potentially trigger a marking change when the cur-
rent marking is s. Denote by X the set of all inﬁnite-length sequences

8.3 STS Methods for Delays
367
(s(0), E(0), s(1), E(1), . . .) such that E(k) ∈E(s(k)) and p(s(k+1); s(k), E(k))
> 0 for k ≥0. For an element x = (s(0), E(0), s(1), E(1), . . .) ∈X, recur-
sively deﬁne a sequence of vectors v0, v1, . . . by setting v0(x) equal to the
vector of length ψ(s(0)) whose components are all equal to −1 and then
setting
v′
n(x) = Ins

vn−1(x), iα(s(n); s(n−1), E(n−1)), 0

,
v′′
n(x) = Del

v′
n(x), iβ(s(n); s(n−1), E(n−1))

,
and
vn(x) = Per

v′′
n(x), iπ(s(n); s(n−1), E(n−1))

for n ≥1. Denote by ι(x) the smallest integer n such that vn(x) =
(0, 0, . . . , 0); if such an integer n does not exist, then set ι(x) = ∞.
Deﬁnition 3.1. A start-vector mechanism for a speciﬁed spn is said to be
regular if
(i) there exists s ∈S and { e∗} ∈E(s) such that nα(s′; s, e∗) > 0 for all
s′ with p(s′; s, e∗) > 0, and
(ii) there exists x = (s(0), E(0), s(1), E(1), . . .) ∈X such that ι(x) < ∞.
As shown below, the technical condition in (i) ensures that, with proba-
bility 1, there are inﬁnitely many starts and, moreover, each o.d.s. cycle
contains at least one start. This condition typically holds in practice. In
many spn models, for example, a delay starts whenever some speciﬁed
timed transition ﬁres—see also Remark 3.8 below. The condition in (ii) is
needed to ensure that each delay terminates with probability 1. Roughly
speaking, this condition asserts that there exists a ﬁnite sequence of mark-
ing changes such that (1) timed transitions do not ﬁre simultaneously at
any marking change, and (2) all the components of the start vector at the
beginning of the sequence are deleted by the end of the sequence.
Construction of Random Indices
We now construct the sequence { ˇγ(k): k ≥0 } of random indices for the
process { Dj : j ≥0 }. For ease of exposition, we describe the construction
when there are no immediate transitions—the modiﬁcations required for
the general case are straightforward. Suppose that Assumption PD holds.
Then, as discussed in Section 6.1.3, the transition kernel of the underlying
chain satisﬁes
P r
(s, c), ·

= bλ( · ) + (1 −b)Q

(s, c), ·

,
(s, c) ∈C,
(3.2)
for some C ⊆Σ, r ≥1, b ∈(0, 1], λ, and Q. Indeed, any subset A ⊆Σ
such that ¯φ(A) > 0 contains a subset C for which a decomposition of the

368
8. Delays
Figure 8.11. Deﬁnition of one-dependent cycles (nonregenerative case).
form (3.2) exists—here ¯φ is the recurrence measure deﬁned by (1.17) in
Chapter 5. Also as discussed in Section 6.1.3, the decomposition in (3.2)
can be used to construct a version of the chain along with4 a sequence
{ θ(k): k ≥0 } of od-regeneration points. Recall that the construction uses
a sequence { In : n ≥0 } of i.i.d. Bernoulli random variables and that the
post-θ(k) process is not just independent of the chain prior to θ(k −1), but
is actually independent of the chain prior to θ(k) −r.
We proceed in a manner similar to what we do in Section 8.2.1 and
recursively construct a subsequence { ˇθ(k): k ≥0 } of { θ(k): k ≥0 } such
that the random indices in the subsequence also form a sequence of od-
regeneration points for the chain, but with longer cycles. The subsequence
retains the “enhanced independence” property referred to above: the post-
ˇθ(k) process is independent of the chain prior to ˇθ(k) −r, where r is as in
(3.2). As before, the point of the construction is that all delays that start
during one of these longer cycles terminate by the end of the next such
cycle. Indeed, we require that all such delays terminate at least r marking
changes before the end of the next cycle.
To initialize the construction of { ˇθ(k): k ≥0 }, set ˇν(−1) = max(K, M),
where K is deﬁned by (1.3) and M is the random index of the ﬁrst marking
change at which all newly started delays at time 0 have terminated; when
there are no newly started delays at time 0, take ˇν(−1) = K. Then take
as ˇθ(0) the smallest θ(l) such that θ(l) ≥ˇν(−1) + r. In general, given
ˇθ(k), let ˇν(k) be the index of the ﬁrst marking change after ˇθ(k) such that
4As discussed in the notes at the end of Chapter 6, a sequence of od-regeneration
points can be obtained after the sample path of the chain has been generated. The
simultaneous construction of the od-regeneration points and the sample path, however,
is more convenient for our purposes.

8.3 STS Methods for Delays
369
all ongoing and newly started delays at the ˇθ(k)th marking change have
terminated. Then take as ˇθ(k+1) the smallest θ(l) such that θ(l) ≥ˇν(k)+r;
when there are no ongoing or newly started delays at the ˇθ(k)th marking
change, take as ˇθ(k + 1) the smallest θ(l) such that θ(l) > ˇθ(k).
To complete the construction of { ˇγ(k): k ≥0 }, set ˇγ(−1) = −1 and
ˇγ(k) = inf

j > ˇγ(k −1): α(j −1) < ˇθ(m) < α(j) for some m ≥0

(3.3)
for k ≥0, where we take α(−1) = 0. These ideas are illustrated in Fig-
ure 8.11. In the ﬁgure the delays Dˇγ(k) are circled, and a vertical dashed
line to the left of a solid line at time ζˇθ(k) indicates the time point ζˇθ(k)−r.
Two complete ˇγ(k)-cycles { D3, D4 } and { D5, D6, D7 } are displayed, as
well as the beginning of a third cycle { D8, . . . }. Observe that the delays in
the third cycle are determined by the evolution of the marking process from
time ζˇθ(2) onward and are hence independent of the delays { Dj : j ≤4 },
which are determined by the evolution of the marking process before time
ζˇθ(2)−r.
Properties of the Construction
We now state our key result. In the following, a real-valued function f is
said to be polynomially dominated if f is polynomially dominated to degree
b—in the sense of Section 8.2.1—for some b ≥0.
Theorem 3.4. Let { Dj : j ≥0 } be a sequence of delays determined from
the underlying chain of a marking process by means of a regular start-vector
mechanism, and suppose that Assumption PD holds. Then
(i) the sequence of delays satisﬁes the conditions in (2.2)–(2.4),
(ii) the random indices { ˇγ(k): k ≥0 } deﬁned by (3.3) form a sequence
of od-regeneration points for { Dj : j ≥0 }, and
(iii) the cycle sum ˇY1(|f|) = 	ˇγ(1)−1
j=ˇγ(0) |f(Dj)| has ﬁnite moments of all
orders for any polynomially dominated function f.
Remark 3.5. In Section 8.2 the conditions in (2.2)–(2.4) are fundamental
hypotheses. In the current section, these conditions are consequences of
Assumption PD and the regularity of the start-vector mechanism. Also
observe that the random indices { ˇγ(k): k ≥0 } in Theorem 2.8 form a
sequence of od-equilibrium points for { Dj : j ≥0 }, but the corresponding
random indices in Theorem 3.4 only form a sequence of od-regeneration
points.
To prove Theorem 3.4, we need the following result, which extends the
inequality in (2.16) to a sequence of o.i.d. random variables.

370
8. Delays
Lemma 3.6. Let SN = 	N
n=1 Xn, where { Xn : n ≥1 } is a sequence of
o.i.d. random variables and N is a stopping time with respect to an increas-
ing sequence { Fn : n ≥1 } such that Xn is determined by Fn for n ≥1 and
independent of Fn−2 for n ≥3. Then for r ≥0 there exists a constant br
(depending only on r) such that
E[|SN|r] ≤brE [|X1|r] E [(N + 2)r] .
Proof. Fix r ≥0 and observe that |SN| ≤	L
i=1 Yi + 	M
i=1 Zi, where
L = ⌊N/2⌋+ 1, M = ⌈N/2⌉+ 1, Yi = |X2i|, and Zi = |X2i−1|. Moreover,
E [|SN|r] ≤crE
!) L

i=1
Yi
*r"
+ crE
!) M

i=1
Zi
*r"
(3.7)
for some ﬁnite constant cr by (1.12) in the Appendix. Observe that { Yi : i ≥
1 } is a sequence of i.i.d. random variables with E [Y r
i ] = E [|X1|r] for i ≥1.
Also observe that, for n ≥1, the value of Yn is determined by the values of
the random variables in F′
n = F2n. Moreover, Yn+1 is independent of F′
n.
Finally, L is a stopping time with respect to { F′
n : n ≥1 }, because N is a
stopping time with respect to { Fn : n ≥1 } and L = k (k ≥1) if and only
if either N = 2k −2 or N = 2k −1. It follows from (2.16) that there exists
a constant b′
r (depending only on r) such that
E
!) L

i=1
Yi
*r"
≤b′
rE [|X1|r] E [Lr] .
An analogous argument shows that
E
!) M

i=1
Zi
*r"
≤b′
rE [|X1|r] E [M r] ,
and the desired result follows from (3.7), since
E [Lr + M r] ≤2E [(L + M)r] = 2E [(N + 2)r] .
Proof of Theorem 3.4. (Sketch) To establish the ﬁrst assertion of The-
orem 3.4, let s and e∗be as in Deﬁnition 3.1(i). Corollary 1.26 in Chap-
ter 5 implies that, under Assumption PD, the underlying chain is Harris
recurrent with recurrence measure ¯φ given by (1.17) in Chapter 5. It then
follows that there are inﬁnitely many marking changes at which the mark-
ing is s and transition e∗ﬁres, so that there are inﬁnitely many starts.
Because nα(s′; s, e∗) is ﬁnite for each s′, it follows from (1.1) that (2.4)
holds. Next, let x = (s(0), E(0), s(1), E(1), . . .) be a ﬁxed element of X such
that ι(x) < ∞, and set Zn = (Sn, Cn, . . . , Sn+l, Cn+l) for n ≥0, where

8.3 STS Methods for Delays
371
l = ι(x). Set
A =

(s0, c0, . . . , sl, cl) ∈Σl :
sk = s(k) and E∗(sk, ck) = E(k) for 0 ≤k ≤l

,
and observe that all ongoing and newly started delays at time ζn terminate
by time ζn+l whenever Zn ∈A. Using the Harris recurrence of the un-
derlying chain together with a geometric trials argument, it can be shown
that Pµ { Zn ∈A i.o. } = 1. Thus each delay terminates with probability 1.
Because each new clock reading is a.s. ﬁnite, each ζn is a.s. ﬁnite, and both
(2.2) and (2.3) hold.
The remainder of the proof is similar to that of Theorem 2.8. As be-
fore, assume for ease of exposition that there are no immediate transi-
tions. The ﬁrst step in establishing the second assertion of the theorem
is to show that the random indices

 ˇθ(k): k ≥0

form a sequence of
od-regeneration points for the underlying chain, with the enhanced inde-
pendence property alluded to earlier. To this end, ﬁx k ≥1 and let Lk
be the unique a.s. ﬁnite integer-valued random variable such that ˇθ(k) =
θ(Lk). Also ﬁx a set B = B1 × B2, where B1 ⊆Σ and B2 ⊆{ 0, 1 }.
Finally, let A be any event whose occurrence or nonoccurrence is deter-
mined by

(Sn, Cn, In): 0 ≤n ≤ˇθ(k) −r

, where { In : n ≥0 } is the se-
quence of Bernoulli random variables used in the construction of the se-
quence { θ(k): k ≥0 } and r is as in (3.2). Observe that events of the form
{ ˇθ(j) −ˇθ(j −1) ≤xj for 1 ≤j ≤k −1 } are of this type. We claim that
Pµ

(Sˇθ(k), Cˇθ(k), Iˇθ(k)) ∈B
 Lk = j, A

= Pµ

(Sθ(j), Cθ(j), Iθ(j)) ∈B
 Lk = j, A

= Pµ

(Sθ(j), Cθ(j), Iθ(j)) ∈B

= λ′(B),
where λ′(B) = λ′(B1 × B2) = λ(B1)η(B2) with η(B2) = P { I0 ∈B2 } and
λ as in (3.2). Only the second equality requires explanation. To see that this
equality holds, observe that the occurrence or nonoccurrence of the event
{ Lk = j } ∩A is determined by Hj = { (Sn, Cn, In): 0 ≤n ≤θ(j) −r }.
The equality then follows because (Sθ(j), Cθ(j), Iθ(j)) is independent of Hj
by construction. Multiplying the above result by Pµ { Lk = j | A } and sum-
ming over j, we obtain
Pµ

(Sˇθ(k), Cˇθ(k), Iˇθ(k)) ∈B
 A

= λ′(B),
and a simple inductive argument using the strong Markov property then
extends the above equality to show that
Pµ

(Sˇθ(k)+n, Cˇθ(k)+n, Iˇθ(k)+n) ∈Hn for 0 ≤n ≤m
 A

= Pλ′ { (Sn, Cn, In) ∈Hn for 0 ≤n ≤m }

372
8. Delays
for any m ≥0 and sets H0, H1, . . . , Hm ⊆Σ × { 0, 1 }. Because the random
variables in the sequence

 ˇθ(k + 1 + n) −ˇθ(k + n): n ≥0

are determined
by the process { (Sn, Cn, In): n ≥ζˇθ(k) }, it follows that the random indices

 ˇθ(k): k ≥0

form a sequence of od-regeneration points for the underlying
chain and that the post-ˇθ(k) process is independent of the chain prior to
ˇθ(k) −r.
To complete the proof of the second assertion of the theorem, assume
that each interval [ζˇθ(k−1), ζˇθ(k)] contains at least one start—because the
start-vector mechanism is regular, we can ensure that this condition holds
by ﬁrst choosing ¯s ∈S and ¯e ∈E(s) such that nα(s′; ¯s, ¯e) > 0 for all s′
with p(s′; ¯s, ¯e) > 0 and then choosing the set C in (3.2) such that
C ⊆{ (s, c) ∈Σ: s = ¯s and E∗(s, c) = { ¯e } } .
An argument almost identical to that in the proof of Theorem 2.8 then
shows that the random indices { ˇγ(k): k ≥0 } deﬁned by (3.3) form a se-
quence of od-regeneration points for { Dj : j ≥0 }.
The proof of the ﬁnal assertion of the theorem similarly parallels the
proof of Theorem 2.8(iii). The main diﬀerences are as follows.
• The result in (2.16) is replaced by Lemma 3.6.
• The existence of ﬁnite moments for δ1 and τ1 is no longer a hypothesis
of the theorem, but rather a consequence of Lemma 2.5 in Chapter 7.
• The random variables { Λk : k ≥0 } are deﬁned by ﬁrst letting ν(k)
be the index of the ﬁrst state transition after θ(k) such that all newly
started and ongoing delays at the θ(k)th state transition have termi-
nated, and then setting Λk = ν(k) + r −θ(k), where r is as in (3.2).
The indicator random variables { Jl : l ≥0 } are then i.i.d. as before.
Remark 3.8. With some additional work (involving geometric trials argu-
ments), the notion of regularity in Theorem 3.4 can be weakened. Speciﬁ-
cally, Deﬁnition 3.1(i) can be modiﬁed to require only that there exist s ∈
S −S′, s′ ∈G, and E∗∈E(s) such that p(s′; s, E∗) > 0 and nα(s′; s, E∗) >
0. In fact, we can allow s to be immediate. For this latter relaxation,
we identify a timed marking s+ and a transition e+ such that either (1)
p(s; s+, e+) > 0 or (2) there exist immediate markings s(1), s(2), . . . , s(k)
(k ≥1) such that p(s(1); s+, e+) > 0 and s(1) →s(2) →· · · →s(k) →s.
We then choose the set C in (3.2) such that C ⊆{ s+ } × C0(s+), where
C0(s+) = { c+ ∈C(s+): E∗(s+, c+) = { e+ } }.
A Limit Theorem for Delays
Combining Theorem 3.4 with Theorem 2.1 in Chapter 7 and Proposition 2.3
in Chapter 7, we obtain the following corollary—recall that Cl[0, 1] denotes

8.3 STS Methods for Delays
373
the set of continuous ℜl-valued functions deﬁned on [0, 1] and that we write
C[0, 1] for C1[0, 1].
Corollary 3.9. Let { Dj : j ≥0 } be a sequence of delays determined from
the underlying chain of a marking process by means of a regular start-vector
mechanism, and let f be a polynomially dominated ℜl-valued function de-
ﬁned on ℜ+ (l ≥1). Suppose that Assumption PD holds. Then
(i) there exists a ﬁnite constant r(f) ∈ℜl such that
lim
n→∞
1
n
n−1

j=0
f(Dj) = r(f) a.s.,
and
(ii) there exists an l×l matrix Q(f) such that Un(f) ⇒Q(f)W (l) as n →
∞for any initial distribution µ, where ⇒denotes weak convergence
on Cl[0, 1], W (l) is a standard l-dimensional Brownian motion, and
Un(f)(t) =
1
√n
 nt
0

f(D⌊u⌋) −r(f)

du
(3.10)
for 0 ≤t ≤1 and n ≥0.
8.3.2
Estimation Methods for Delays
In this subsection we focus on estimation methods that follow from the
foregoing results for sequences of delays.
Standardized Time Series
When the start-vector mechanism is regular and Assumption PD holds,
the time-average limit r(f) of the output process { f(Dj): j ≥0 } is well-
deﬁned and ﬁnite for any polynomially dominated real-valued function f,
and we can obtain point estimates and conﬁdence intervals for r(f) using
sts methods. To this end, ﬁx f and set
¯Yn(t) = 1
n
 nt
0
f(D⌊u⌋) du
for 0 ≤t ≤1 and n ≥1. Also set
ˆrn = ¯Yn(1) = 1
n
n−1

j=0
f(Dj).
By Corollary 3.9(i), the point estimator ˆrn is strongly consistent for r(f).
To obtain asymptotic conﬁdence intervals for r(f), we proceed as in Sec-
tion 7.2.2. Speciﬁcally, deﬁne the set Ξ of mappings from C[0, 1] to ℜas in

374
8. Delays
Section 7.2.2 and ﬁx ξ ∈Ξ. Let σ(f) be a nonnegative constant such that
Un(f) ⇒σ(f)W
as n →∞, where Un(f) is given by (3.10) and W = { W(t): 0 ≤t ≤1 } is a
standard one-dimensional Brownian motion. The existence of σ(f) follows
from Corollary 3.9(ii) with l = 1, and we assume throughout that σ(f) > 0.
Finally, set ξn = ξ( ¯Yn). Arguing as in Section 7.2.2, we ﬁnd that
ˆrn −r(f)
ξn
⇒σ(f)W(1)
σ(f)ξ(W) = W(1)
ξ(W),
(3.11)
and
[ˆrn −ξnzp, ˆrn + ξnzp]
(3.12)
is an asymptotic 100p% conﬁdence interval for r(f), where p ∈(0, 1) and
zp is a positive constant such that P{ −zp ≤W(1)/ξ(W) ≤zp } = p.
As discussed in Section 7.2.2, the batch-means conﬁdence interval is ob-
tained as a special case of the interval in (2.24). Fix b ≥2 and suppose
that we can write the simulation run length as n = bm. Setting
¯Xn(i) = ¯Xn(i; f) = 1
m
im−1

j=(i−1)m
f(Dj)
(3.13)
for 1 ≤i ≤b and n > 0, we ﬁnd that the interval in (3.12) is an asymptotic
100p% conﬁdence interval for r(f) when zp is the (1 + p)/2 quantile of the
Student’s t distribution with b −1 degrees of freedom and
ξn = 1
√
b


1
b −1
b

i=1

¯Xn(i) −1
b
b

j=1
¯Xn(j)


2

1/2
.
That is, the batch-means conﬁdence interval based on simulation of delays
D0, D1, . . . , Dn is obtained by decomposing the sequence f(D0), f(D1), . . . ,
f(Dn) into b disjoint batches of length m. The quantity ¯Xn(i) is the ith
batch mean, and we treat the batch means as if they were i.i.d. normal
random variables when forming a conﬁdence interval—the limit result in
(3.11) shows that this approximation becomes increasingly accurate as the
simulation run length becomes large.
The other sts methods discussed in Section 7.2.2 are also applicable. If
we ﬁx m ≥1 and simulate the underlying chain for n = lm state transitions,
then the sts area method yields an asymptotic 100p% conﬁdence interval
for r(f) of the form [ˆrn −ξnzp, ˆrn + ξnzp]. Here
ˆrn = 1
n
n−1

j=0
f(Dj),

8.3 STS Methods for Delays
375
zp is the (1 + p)/2 quantile of the Student’s t distribution with m degrees
of freedom, and
ξ2
ν = 12
m−1

i=0
A2
i ,
with
Ai = 1
n
l−1

j=0
1
2 −j
l −1
2l

f(Dil+j).
Alternatively, the sts maximum method yields an asymptotic 100p% con-
ﬁdence interval for ˜r( ˜f) of the form [ˆrn −ξnzp, ˆrn + ξnzp]. Here
ˆrn = 1
n
n−1

j=0
f(Dj),
zp is the (1 + p)/2 quantile of the Student’s t distribution with 3m degrees
of freedom, and
ξ2
ν = 1
3
m−1

i=0
A2
i ,
where each Ai is deﬁned as follows. Set
Bi(t) = 1
n
⌊lt⌋−1

j=0
f(Dil+j) −t
n
l−1

j=0
f(Dil+j)
for 0 ≤t ≤1, and denote by k∗
i the smallest value of k in { 0, 1, . . . , l } such
that Bi(k∗
i /l) ≥Bi(k/l) for k in { 0, 1, . . . , l }. Then
Ai =
Bi(k∗
i /l)
(k∗
i /l)

1 −(k∗
i /l)
1/2 .
Functions of Time-Average Limits
As in Section 7.2.3, we can use an extension of the batch-means method to
estimate functions of time-average limits of a sequence of delays. Speciﬁ-
cally, let { Dj : j ≥0 } be a sequence of delays that is speciﬁed by means
of a regular start-vector mechanism, and suppose that we wish to obtain
strongly consistent point measures and asymptotic conﬁdence intervals for
a performance measure of the form
r = g(α1, α2, . . . , αl)
(l ≥1), where g is a real-valued function deﬁned on ℜl,
αi = lim
n→∞
1
n
n−1

j=0
fi(Dj)

376
8. Delays
for 1 ≤i ≤l, and each fi is a polynomially dominated real-valued function.
Also suppose that each fi is nonconstant and f1, f2, . . . , fl are linearly
independent. Note that, by Corollary 3.9, each αi is well deﬁned and ﬁnite
under Assumption PD.
Fix b ≥2 and set
Jn(i) = bg

¯A1, ¯A2, . . . , ¯Al

−(b −1)g

¯A(i)
1 , ¯A(i)
2 , . . . , ¯A(i)
l

,
for 1 ≤i ≤b, where
¯Aj = 1
b
b

k=1
¯Xn(k; fj)
and
¯A(i)
j
=
1
b −1

k̸=i
¯Xn(k; fj).
and ¯Xn(k; f) is deﬁned as in (3.13). Then set ˆr(J)
n
= (1/b) 	b
i=1 Jn(i). The
following result shows that ˆr(J)
n
is strongly consistent for r; the proof is
essentially the same as that of Theorem 2.32 in Chapter 7.
Theorem 3.14. Suppose that Assumption PD holds and that g is diﬀer-
entiable in a neighborhood of α = (α1, α2, . . . , αl). Then ˆr(J)
n
→r a.s. as
n →∞.
To obtain conﬁdence intervals, observe that by Corollary 3.9(ii) there
exists an l × l matrix Q(f) such that
Un(f) ⇒Q(f)W (l)
(3.15)
as n →∞for any initial distribution µ, where f = (f1, f2, . . . , fl), Un(f) is
deﬁned by (3.10) and W (l) is a standard l-dimensional Brownian motion.
The matrix Q(f) is nonsingular except in degenerate cases, and we assume
that Q(f) is nonsingular throughout. As in Section 7.2.3, it follows from
the convergence in (3.15) that
√
b

ˆr(J)
n
−r

/s(J)
n
⇒Tb−1 as n →∞, where
Tb−1 denotes a random variable having a Student’s t distribution with b−1
degrees of freedom and s(J)
n
=

1/(b −1)
 	b
i=1

Jn(i) −ˆr(J)
n
21/2. Thus

ˆr(J)
n
−s(J)
n zp
√
b
, ˆr(J)
n
+ s(J)
n zp
√
b

is an asymptotic 100p% conﬁdence interval for r, where zp is the (1 + p)/2
quantile of the Student’s t distribution with b −1 degrees of freedom.

8.3 STS Methods for Delays
377
Limiting Average Delays
As in the regenerative setting, the task of measuring individual delays can
be avoided when the performance measure of interest is the limiting aver-
age delay limn→∞(1/n) 	n−1
j=0 Dj. Set Zn = (Sn, Cn, Sn+1, Cn+1) for n ≥0
and deﬁne functions f1, f2, and f3 on Σ×Σ by ˜f 1(s, c, s′, c′) = ψ(s)t∗(s, c),
˜f 2(s, c, s′, c′) = nα

s′; s, E∗(s, c)

, and ˜f 3(s, c, s′, c′) = t∗(s, c). Under As-
sumption PD, there exists a sequence { θ(k): k ≥0 } of od-regeneration
points for the underlying chain, and it is not hard to see that the random
indices { θ(2k): k ≥0 } form a sequence of od-regeneration points for the
process { Zn : n ≥0 }. Moreover, the expected cycle length is ﬁnite, and cy-
cle sums of the process { ˜f(Zn): n ≥0 } have ﬁnite moments of all orders
for ˜f = ˜f 1, ˜f 2, or ˜f 3. It then follows from Theorem 1.27 in Chapter 6 and
Theorem 2.9 in Chapter 3 that there exist ﬁnite nonnegative constants l
and λ such that, with probability 1,
lim
t→∞
1
t
 t
0
ψ

X(u)

du = lim
n→∞
	n
j=0 ˜f 1(Zj)
	n
j=0 ˜f3(Zj)
= l
and
lim
t→∞
NA(t)
t
= lim
n→∞
	n
j=0 ˜f 2(Zj)
	n
j=0 ˜f3(Zj)
= λ,
where NA(t) is the number of delays that start during the interval [0, t]. It
then follows by a Little’s-law argument similar to the alternative proof of
Theorem 2.32 that
lim
n→∞
1
n
n−1

j=0
Dj = l/λ = lim
n→∞
	n
j=0 ˜f 1(Zj)
	n
j=0 ˜f2(Zj)
a.s.;
the only changes in the proof involve the replacement of several cited limit
theorems for i.i.d. random variables with corresponding results for o.d.s.
random variables. Thus the limiting average delay can be expressed as the
limit of a ratio of sums as in Section 7.2.4. As discussed in that section,
“jackknifed batch means” methods can be used to obtain point estimates
and conﬁdence intervals for such ratios; there is no need to measure indi-
vidual delays.
8.3.3
Examples
We conclude by illustrating the application of our results to some speciﬁc
spn models.
Example 3.16 (Cyclic queues with four servers). Consider a closed net-
work of queues with two service centers, two servers at each center, and N
(> 4) jobs numbered 1, 2, . . . , N. At each center, jobs form a single queue

378
8. Delays
Figure 8.12. Positions of jobs in cyclic queues with feedback (two servers per
center).
and are served by one of two servers, numbered 1 and 2, according to a
ﬁrst-come, ﬁrst-served queueing discipline; whenever a job joins an empty
queue and both servers are idle, there is an immediate start of service by
server 1. With ﬁxed probability p ∈(0, 1), a job that completes service at
center 1 moves to center 2 and with probability 1 −p joins the tail of the
queue at center 1. Upon completion of service at center 2, the job moves
to center 1. Successive service times by server j at center i are i.i.d. as a
positive random variable Li,j with continuous distribution function.
We specify the position of each job in the network by ordering the N jobs
in a job stack—see Figure 8.12 for N = 8 jobs. The ordering is essentially
the same as that in Example 1.2; the main modiﬁcation is that a job being
served by server 1 appears closer to the top of the stack than a job being
served by server 2.
This system can be speciﬁed as an spn with a ﬁnite marking set; see
Figure 8.13. For i, j ∈{ 1, 2 }, transition ei,j = “completion of service by
server j at center i” and transition ei,2+j = “start of service by server j
at center i.” All the transitions are deterministic; we use priorities on the
immediate transitions to model the fact that a job is always served by the
lowest-numbered available server. All speeds for enabled transitions are
equal to 1.
Consider the delay intervals from whenever a job completes service at
center 2 (and moves to center 1) to when the job next completes service at
center 2. Individual delays can be speciﬁed and measured using the method
of start vectors in a manner similar to Example 1.4. Set ψ(s) = N for s ∈G.
Also set
iα(s′; s, E∗) =

(0)
if E∗= { e2,1 } or { e2,2 };
∅
otherwise

8.3 STS Methods for Delays
379
Figure 8.13. spn representation of cyclic queues with feedback (two servers per
center).
and
iβ(s′; s, E∗) =





(s1,1 + s1,2 + s1,3 + s2,3 + 2)
if E∗= { e2,1 };
(s1,1 + s1,2 + s1,3 + s2,3 + s2,1 + 2)
if E∗= { e2,2 };
∅
otherwise
for s = (s1,1, s1,2, s1,3, s2,1, s2,2, s2,3), s′ ∈G, and E∗⊆E(s). (The “+2”
terms in the above deﬁnition are a consequence of the fact that, after an
insertion and before a deletion, the start vector temporarily contains N +1
components.) Finally, letting m = s1,1 + s1,3,
(i) set iπ(s′; s, E∗) = (s1,3 + 1, 1, 2, . . . , s1,3, s1,3 + 2, s1,3 + 3, . . . , N) if
E∗= { e1,1 }, s2,3 = s′
2,3, and s1,3 > 0,
(ii) set iπ(s′; s, E∗) = (m + 1, 1, 2, . . . , m, m + 2, m + 3, . . . , N) if E∗=
{ e1,2 }, s2,3 = s′
2,3, and m > 0,
(iii) set iπ(s′; s, E∗) = (1, 2, . . . , s1,3 −1, s1,3 + 1, s1,3, s1,3 + 2, . . . , N) if
E∗= { e1,4 } and s1,1 = 1,
(iv) set iπ(s′; s, E∗) = (1, 2 . . . , N −2, N, N −1) if E∗= { e2,4 } and
s2,1 = 1, and
(v) set iπ(s′; s, E∗) = ∅otherwise.
In the above speciﬁcation of iπ, the ﬁrst two cases handle the cyclic per-
mutation that occurs when a job completes service at center 1 and joins
the tail of the queue at center 1. The third case handles the situation in
which, at center 1, a job starts to undergo a service by server 2 and thereby

380
8. Delays
“overtakes” a job currently undergoing a service by server 1, and the fourth
case handles the analogous situation at center 2. For all other situations,
no permutation is needed. Suppose that at time 0 all jobs are at center 1
and there is a start of service by each of the servers at center 1. Then we
set V0 = (0, 0, −1, . . . , −1).
Suppose that (1) for j ∈{ 1, 2 } the service-time random variable L1,j
has a uniform distribution on [0, wj], where wj > 0 is a speciﬁed constant
and (2) the random variables L2,1 and L2,2 each have a hyperexponential
distribution. Under these distributional assumptions, there is no apparent
sequence of regeneration points for the underlying chain or the marking
process. Indeed, |E(s)| > 1 for all s ∈G, so that there is no single state,
and there is no memoryless property to exploit. It can easily be seen, how-
ever, that Assumption PD holds. Moreover, we claim that the start-vector
mechanism is regular. The only nontrivial step in establishing regularity is
showing that ι(x) < ∞for some x ∈X. To this end, however, we need only
consider a scenario in which all jobs are initially at center 2 and then, at
center 2, there is a service completion by server 2 followed by N −2 suc-
cessive service completions by server 1 and then a ﬁnal service completion
by server 2. Formally, let x be any element (s(0), E(0), s(1), E(1), . . .) ∈X
such that
s(0) = (0, 0, 0, 1, 1, N −2),
E(0) = { e2,2 } ,
E(1) = { e1,3, e2,4 } ,
E(2) = { e2,1 } ,
E(3) = { e1,4, e2,3 } ,
E(4) = { e2,1 } ,
E(j) = { e2,3 } and E(j+1) = { e2,1 } for 5 ≤j ≤3 + 2(N −4),
and
E(5+2(N−4)) = { e2,2 } .
Then ι(x) = 6 + 2(N −4) < ∞.
Because the conditions of Theorem 3.4 and Corollary 3.9 are satisﬁed,
any time-average limit of the form
r(f) = lim
n→∞
1
n
n−1

j=0
f(Dj)
is guaranteed to exist, provided that the (real-valued) function f is poly-
nomially dominated. Moreover, we can use sts methods as in Section 8.3.2
to obtain strongly consistent point estimates and asymptotic conﬁdence in-
tervals for r(f). For example, if f(x) = 1(u,∞)(x), then r(f) is the long-run

8.3 STS Methods for Delays
381
fraction of delays that exceed u time units. If f(x) = cx for some constant
c, then r(f) is the long-run average cost due to delays when the cost per
time unit of delay is c for each delay.
Using the “jackknifed batch-means” method of Section 8.3.2, we can also
estimate functions of time-average limits of the form
r = g(α1, α2, . . . , αl),
where αi = limn→∞(1/n) 	n−1
j=0 fi(Dj) for 1 ≤i ≤l, each fi is a polynomi-
ally dominated real-valued function, and g is a real-valued function diﬀeren-
tiable in a neighborhood of α = (α1, α2, . . . , αl). For example, if f1(x) = x,
f2(x) = x2, and g(x, y) = y −x2, then r is the long-run variance of the
sequence of delays. As another example, suppose that f1(x) = 1(u,∞)(x)
and f2(x) = 1(v,∞)(x), where v > u, and that g(x, y) = y/x. Then r is the
long-run fraction of “long” delays that exceed v time units, where a delay
is considered “long” if it exceeds u time units.
Example 3.17 (Airport shuttle). For the shuttle system of Example 1.8,
suppose that each travel-time random variable Li has a truncated normal
distribution and each interarrival-time random variable Ai has a Wald dis-
tribution. Clearly, the spn of Figure 8.5 has no single state, so that neither
the marking process nor the underlying chain has an apparent sequence of
regeneration points.
Assumption PD holds for this spn, however. Indeed, the only nontrivial
step in establishing Assumption PD is to demonstrate irreducibility. This
can be done by showing that s ; ¯s and ¯s ; s for all s ∈G, where
¯s is the unique marking in which no passengers are in the system and
the shuttle is travelling to station 1—that is, ¯s = (s1,1, . . . , s6,N), where
s1,1 = s6,1 = s6,2 = · · · = s6,N = 1 and all other components of ¯s are equal
to 0.
Not only does Assumption PD hold, but the start-vector mechanism de-
scribed in Example 1.8 is regular. In Deﬁnition 3.1(i), take s = (s1,1, . . . ,
s6,N) to be any ﬁxed timed marking with s5,1 < B1 (so that the num-
ber of passengers in queue at station 1 is less than the maximum capacity
B1) and take e∗= e4,1 = “arrival of passenger for boarding at station 1.”
Veriﬁcation of the condition in Deﬁnition 3.1(ii) is similarly straightfor-
ward. Let s = (s1,1, . . . , s6,N) be the unique ﬁxed marking in which the
shuttle is at station 1, there is only one passenger in the system, and this
passenger boarded the shuttle at station 2 and is about to disembark:
s4,2,1 = 1, s4,j,i = 0 for (j, i) ̸= (2, 1), s5,i = 0 for 1 ≤i ≤N, and s2,1 = 1.
Next, set x = (s, { e∗} , s′), where e∗= e2,2,1 = “disembarkment at sta-
tion 1 of passengers from station 2,” and s′ is the unique marking such that
p(s′; s, e2,2,1) > 0. Then ι(x) = 1.
Thus the conditions of Theorem 3.4 and Corollary 3.9 are satisﬁed. We
can therefore use sts methods to obtain strongly consistent point estimates
and asymptotic conﬁdence intervals for time-average limits deﬁned in terms

382
8. Delays
of the sequence { Dj : j ≥0 } given in Example 1.8. We can also estimate
functions of such time-average limits by using the jackknifed batch-means
techniques of Section 8.3.2.
Remark 3.18. It can be shown that under the conditions of Theorem 3.4, the
estimation methods described in this and the previous subsection extend
to real-valued functions f that depend both on the delay and on speciﬁed
states of the marking process during the corresponding delay interval.
For example, our methods extend to functions of time-average limits of
the form ˜r(f) = limn→∞(1/n) 	n−1
j=0 f(Dj, Sα(j)) where, as before, ζα(j)
is the start of jth delay interval. As an application, consider the closed
network of queues discussed in this subsection and suppose we wish to
estimate the limiting average delay only for those delays that start with
an arrival to an empty queue. This limit is of the form ˜r(f1)/˜r(f2), where
f1(d, s) = d 1A(s), f2(d, s) = 1A(s), and A = { (s1,1, . . . , s2,3) ∈G: s1,3 =
1 and s1,1 = s1,2 = 0 }.
As another example, our methods extend to functions of time-average
limits of the form ˜r(f) = limn→∞(1/n) 	n−1
j=0 f(Dj, Sβ(j)−1). To see the
usefulness of this particular extension, recall the airport shuttle of Exam-
ple 1.8. For ﬁxed i and j, consider the delay intervals as in the example,
but only for those passengers that board the shuttle at station j and dis-
embark at station i. Suppose that we wish to estimate the limiting average
delay for all such passengers. This limit is of the form ˜r(f1)/˜r(f2), where
f1(d, s) = d 1A(s), f2(d, s) = 1A(s), and A = { (s1,1, . . . , s6,N) ∈G: s2,i =
1, s4,j,i > 0, and s4,l,i = 0 for j < l ≤N }.
Notes
Iglehart and Shedler (1980) and Shedler (1987) use tagging to specify delays
in networks of queues—in this work, tagging is implemented by means of a
job-stack ordering and an augmented state space. In the setting of queue-
ing systems, delays are sometimes referred to as “passage times” because
they correspond to the time for a job to pass from a speciﬁed initial posi-
tion in the network to a speciﬁed ﬁnal position. The tagging approach has
been applied in the more general settings of gsmps (Iglehart and Shedler,
1984; Shedler, 1993) and colored spns (Haas and Shedler, 1993b). In the
latter setting, tagging is accomplished by means of distinguished tokens.
The abovementioned papers systematically develop the use of the standard
regenerative method to obtain point estimates and conﬁdence intervals for
time-average limits of a sequence of delays—see also Prisgrove and Shedler
(1986) for a discussion of regenerative simulation of delays in “symmetric”
spns.

8. Notes
383
The extended regenerative method and multiple-runs method for delays
are developed in papers by Haas and Shedler (1993a, 1995, 1996); the latter
method is based on an idea of Glynn (1994). For a proof of the clt in
(2.24), see Fox and Glynn (1987). The conclusion that neither the extended
regenerative method nor the multiple-runs method is always more eﬃcient
remains true if—as in Glynn and Whitt (1992a)—we extend the notion of
relative asymptotic eﬃciency to incorporate simulation costs explicitly and
to quantify losses due to the discrepancy between r(f) and its estimate.
The version of Little’s law in Proposition 2.40 is due to Glynn and Whitt
(1986), and the assertion in Remark 2.37 of equal asymptotic variability
rests on results in Glynn and Whitt (1989).
The discussion in Section 8.3 follows Haas (1999b). As in previous chap-
ters, the moment condition in Assumption PD can be weakened by, for
example, adapting results in Glynn and Haas (2002b). For example, it
can be shown that the rth moment of a cycle sum of the output process
{ f(Dj): j ≥0 } is ﬁnite whenever f is polynomially dominated to degree
b (≥0) and each clock-setting distribution function has ﬁnite r(b + 1)st
moment.
In related work, Glynn (1982b) considers sequences of delays determined
by an underlying Harris recurrent Markov chain in which there is at most
one ongoing delay at any time point. He establishes the existence of od-
regeneration points for such sequences by obtaining a representation of the
form Dj = f(ξj) for j ≥0, where { ξj : j ≥0 } is a Harris chain and f is a
real-valued function.
Under the conditions of Theorem 3.4, the techniques of Mu˜noz and Glynn
(2001) can be used to construct conﬁdence regions for multidimensional lim-
its of the form limn→∞(1/n) 	n−1
j=0 f(Dj), where f is a ℜl-valued function
for some l > 1.
The topic of delays in spns has also been treated by Baccelli et al. (1993),
Baccelli and Schmidt (1996), Campos et al. (1989), Molloy (1982), Mup-
pala et al. (1994), Natkin (1985), and Xie et al. (1999), among others. This
work has, for the most part, focused on speciﬁc types of delays and partic-
ular kinds of spns—for example, “cycle times” between successive ﬁrings
of a ﬁxed transition in “stochastic marked graphs” with exponentially dis-
tributed ﬁring times. The primary emphasis has been on the development
of exact and approximate analytical expressions and bounds for average
delays. Baccelli et al. (1993) derive suﬃcient conditions for time-average
convergence of sequences of cycle times in stochastic marked graphs with
general ﬁring times.
The manufacturing line with a shunt bank—along with many other sto-
chastic models of manufacturing systems—is discussed in Buzacott and
Shanthikumar (1993). The airport shuttle model is adapted from Shedler
(1993).

This page intentionally left blank 

9
Colored Stochastic Petri Nets
Use of the standard set of spn building blocks to model very large or com-
plex systems can sometimes result in nets that have an enormous number
of places and transitions. One popular strategy for obtaining more concise
speciﬁcations in such cases is to associate “colors” with both tokens and
transitions and to work with “colored stochastic Petri nets” (cspns). This
approach is especially eﬀective when the system under study is composed
of many subsystems having a similar structure or behavior.
A cspn is speciﬁed by a ﬁnite set of places, a ﬁnite number of transitions,
and a ﬁnite set of colors, along with an “input incidence function” and an
“output incidence function.” A marking of a cspn is an assignment of
nonnegative integers to the places of the net and represents the number of
tokens of each color in each place. Each transition can be simultaneously
“enabled in” one or more colors. A transition is enabled in a speciﬁed color
whenever each “input place” contains a suﬃcient number of tokens of each
color—both the set of input places and the required number of tokens of
each color in each input place are speciﬁed by the input incidence function.
A transition enabled in a color “ﬁres in” the color by instantaneously
removing tokens from input places and depositing tokens in “output places”
in a deterministic manner—the set of output places is speciﬁed by the
output incidence function. A transition may ﬁre in a color only if it is
enabled in the color. For each place, the number (possibly zero) of tokens
removed from and deposited in the place is speciﬁed by the input and
output incidence functions; this number depends only on the transition
that ﬁres, the ﬁring color, and the identity of the place. The color of a
token in a place remains ﬁxed until the token is removed from the place.
A clock is associated with each possible (transition, ﬁring color) pair.
Whenever a transition is enabled in a speciﬁed color, the corresponding
clock reading indicates the remaining time until the transition is scheduled

386
9. Colored Stochastic Petri Nets
to ﬁre in the color. As with ordinary spns, each transition is either immedi-
ate or timed. A marking change occurs when one or more clocks run down
to 0. When exactly one clock (associated with a transition and color) runs
down to 0, the transition ﬁres in the color. When several clocks run down
to 0 simultaneously, the corresponding (transition, color) pairs “qualify”
to trigger the next marking change. One of these pairs is selected for ﬁring
according to a speciﬁed probability distribution.
An initial marking is speciﬁed at time 0, and initial clock readings are
selected according to initial probability distributions. At each subsequent
marking change, transitions may become enabled in one or more colors.
Whenever a transition becomes enabled in a color, a clock reading is se-
lected according to a ﬁxed probability distribution that depends only on
the transition and the color. If a transition is enabled in a color and, at the
next marking change, does not ﬁre in the color but remains enabled in the
color, then the associated clock continues to run down; if the transition is
not enabled in the color after the next marking change, then the associated
clock reading is discarded.
Because tokens are removed and deposited in essentially a deterministic
manner, cspns have somewhat less modelling power than ordinary spns—
see the discussion at the end of Section 9.1. A wide variety of interesting
systems can be modelled within the cspn framework, however, and the
advantages of concisely representing these systems often outweigh the dis-
advantages due to loss of modelling power.
In Section 9.1 we present the cspn building blocks, along with examples
that illustrate the use of cspns for modelling of discrete-event stochastic
systems. We also deﬁne the marking process of a cspn; as with ordinary
spns, the marking process records the marking as it evolves over continuous
time and is deﬁned in terms of a general state-space Markov chain that de-
scribes the net at successive marking changes. Stability conditions, as well
as conditions for the applicability of estimation methods, closely resemble
those for ordinary spns. We therefore do not describe these results in great
detail, but content ourselves with stating some of the key theorems in Sec-
tion 9.2. More interesting is the study of cspns whose behavior is invariant
under permutations of the colors. Such “symmetric” cspns correspond to
systems composed of identical subsystems. In Section 9.3 we describe two
ways in which symmetry can be exploited when using regenerative simula-
tion to estimate long-run performance characteristics. The ﬁrst technique
decomposes the sample path of the marking process or underlying chain
into independent, nonidentically distributed blocks—the appeal of this ap-
proach is that the associated “blocking points” typically occur more fre-
quently than the usual regeneration points. The second technique exploits
symmetry to increase statistical eﬃciency when estimating time-average
limits for a sequence of delays in a cspn.

9.1 The CSPN Model
387
9.1
The CSPN Model
In this section we present the basic cspn building blocks, along with illus-
trative examples of cspn speciﬁcations. We also deﬁne the key stochastic
processes associated with a cspn.
9.1.1
Building Blocks
The basic elements of a cspn graph are
• A ﬁnite set D = { d1, d2, . . . , dL } of places
• A ﬁnite set E = { e1, e2, . . . , eM } of transitions
• A (possibly empty) set E′ ⊂E of immediate transitions
• A ﬁnite set U of colors with a ﬁxed enumeration
• Color domains UD(d) ⊆U for d ∈D and UE(e) ⊆U for e ∈E
• An input incidence function w−and an output incidence function w+,
each deﬁned on 
e∈E,d∈D({ e } × UE(e) × { d } × UD(d)

and taking
values in the nonnegative integers
For d ∈D, the color domain UD(d) ⊆U is the set of colors that may
be assigned to a token in place d. Similarly, for e ∈E, the color domain
UE(e) ⊆U is the set of possible ﬁring colors for transition e. Thus there
can be a token of color l in place d only if (d, l) ∈D, where
D =

d∈D

{ d } × UD(d)

.
Similarly, transition e can ﬁre in color i only if (e, i) ∈E, where
E =

e∈E

{ e } × UE(e)

.
Denote by E′ the subset of E corresponding to the immediate transitions:
E′ =

e∈E′

{ e } × UE(e)

.
The input incidence function w−and the output incidence function w+
determine when a transition is enabled in a color and the number of to-
kens removed and deposited when a transition ﬁres in a color. Speciﬁcally,
transition e is enabled in color i if and only if, for all (d, l) ∈D, place d
contains at least w−(e, i, d, l) tokens of color l. Whenever transition e ﬁres
in color i, exactly w−(e, i, d, l) tokens of color l are removed from place d

388
9. Colored Stochastic Petri Nets
and exactly w+(e, i, d, l) tokens of color l are deposited in place d for all
(d, l) ∈D.
The graphical representation of a cspn is similar to that of an ordinary
spn: places are drawn as circles, immediate transitions as thin bars, and
timed transitions as thick bars. There is a directed arc from place d to tran-
sition e if and only if w−(e, i, d, l) > 0 for some i ∈UE(e) and l ∈UD(d),
and place d is said to be an input place of transition e. Similarly, there is a
directed arc from transition e to place d if and only if w+(e, i, d, l) > 0 for
some i ∈UE(e) and l ∈UD(d), and place d is said to be an output place
of transition e. Tokens are drawn as black dots with corresponding colors
displayed nearby.
The label on an arc from a transition to a place indicates the number of
tokens of each color deposited in the place whenever the transition ﬁres. To
indicate the number of tokens of each color that are deposited in a place,
we use “formal-sum” notation. For example, an arc from transition e to
place d has the label “1 · i + 3 · j” if transition e deposits exactly one token
of color i and three tokens of color j in place d whenever it ﬁres—that is,
for all l ∈UE(e), w+(e, l, d, k) = 1 if k = i, w+(e, l, d, k) = 3 if k = j, and
w+(e, l, d, k) = 0 otherwise. We sometimes abbreviate an expression such
as “1·i” simply as “i.” The special symbol “I” in a label denotes the ﬁring
color of the transition. For example, an arc from transition e to place d
has the label “2 · I” if, for all i ∈UE(e), transition e deposits two tokens
of color i in place d (and no tokens of any other color) whenever it ﬁres
in color i. As another example, in a cspn with U = { 1, 2, . . . , N }, an arc
from transition e to place d has the label “2 · I + 3 · (I + 1)” if transition
e deposits two tokens of color i and three tokens of color i + 1 in place
d whenever it ﬁres in color i—for i = N, the color i + 1 is taken as the
color 1. An arc without an explicit label has an implicit label of “1 · I” or,
equivalently, “I.” We use analogous notation for a label on an arc from a
place to a transition. For example, an arc from place d to transition e has
the label “1 · 0 + 2 · I” if, for all i ∈UE(e), transition e is enabled in color i
only if place d contains at least one token of color 0 and two tokens of
color i. Moreover, transition e removes one token of color 0 and two tokens
of color i from place d whenever it ﬁres in color i.
A marking of a cspn is an assignment of token counts, by color, to
the places of the net. We represent a marking as a pair (s, u). The ﬁrst
component s = (s1, s2, . . . , sL) is a vector of nonnegative integers as in an
ordinary spn, where sj is the number of tokens in place dj ∈D. We write
|s| = s1 + s2 + · · · + sL. The second component u = (u1, u2, . . . , u|s|) ∈U |s|
records the color of each of the |s| tokens. In the vector u, the colors of the
tokens in place di appear to the left of the colors of the tokens in place dj
whenever i < j; for each place the colors of the tokens in the place appear
from left to right in the order of the ﬁxed enumeration of the set U of
colors. Given a marking (s, u), we denote by uj(i) the number of tokens of

9.1 The CSPN Model
389
color i in place dj:
uj(i) =
s1+···+sj

k=s1+···+sj−1+1
1{ i }(uk).
Observe that 	
i∈U uj(i) = sj for 1 ≤j ≤L. Denote by
(s(0), u(0)) =

(s(0)
1 , . . . , s(0)
L ), (u(0)
1 , . . . , u(0)
J )

the initial marking of the net, where J = |s(0)|.
For a marking (s, u), set
E(s, u) =

(e, i) ∈E : uj(l) ≥w−(e, i, dj, l) for (dj, l) ∈D

.
Transition e is enabled in color i when the marking is (s, u) if and only if
(e, i) ∈E(s, u); otherwise, transition e is disabled in color i.
The marking changes when a transition enabled in a color ﬁres in the
color. Whenever the marking is (s, u) and transition e ﬁres in color i, the
new marking (s′, u′) is given by
u′
j(l) = uj(l) −w−(e, i, dj, l) + w+(e, i, dj, l)
for (dj, l) ∈D. Thus, s, u, e, and i uniquely determine (s′, u′), and we write
(s′, u′) = g(s, u, e, i). The function g is called the new-marking function.
A clock is associated with each pair (e, i) ∈E. Whenever transition e
is enabled in color i, the clock associated with the pair (e, i) records the
remaining time until e is scheduled to ﬁre in color i. When the mark-
ing is (s, u) and transition e∗ﬁres in color i∗, an a.s. ﬁnite clock reading
is generated for each pair (e, i) ∈N(s, u, e∗, i∗) = E(s′, u′) −

E(s, u) −
{ (e∗, i∗) }

—here (s′, u′) = g(s, u, e∗, i∗) is the unique new marking. De-
note the clock-setting distribution function by F( · ; e, i). As with ordinary
spns, we require that F(0; e, i) = 1 for (e, i) ∈E′ and F(0; e, i) = 0 for
(e, i) ∈E−E′, so that immediate transitions always ﬁre instantaneously and
timed transitions never ﬁre instantaneously. For (e, i) ∈O(s, u, e∗, i∗) =
E(s′, u′) ∩

E(s, u) −{ (e∗, i∗) }

—where, as above, (s′, u′) is the unique
new marking—transition e is enabled in color i in marking (s, u) and re-
mains enabled in color i in marking (s′, u′) after e∗ﬁres in color i∗; in this
case the old clock reading for (e, i) is kept after the marking change. For
(e, i) ∈

E(s, u) −{ (e∗, i∗) }

−E(s′, u′), transition e—which was enabled
in color i before transition e∗ﬁred in color i∗—becomes disabled in color i,
and the clock reading is discarded. Of course, when transition e∗ﬁres in
color i∗, either e∗is enabled in color i∗in the new marking (s′, u′) and a
new clock reading is generated according to F( · ; e∗, i∗)—cf. the foregoing
deﬁnition of N(s, u, e∗, i∗)—or e∗is not enabled in color i∗and no new
clock reading is generated.

390
9. Colored Stochastic Petri Nets
(e1, i) = stoppage of machine i
(e2, i) = start of repair for machine i
(e3, i) = end of repair for machine i
Figure 9.1. cspn representation of machine repair system (four machines).
Whenever the (transition, color) pairs in a set E∗(with |E∗| > 1) qual-
ify to trigger a marking change, exactly one pair is selected for ﬁring. For
(e, i) ∈E∗, denote by q(e, i; E∗) the probability that transition e is selected
to ﬁre in color i. These ﬁring probabilities satisfy 	
(e,i)∈E∗q(e, i; E∗) =
1. For ease of exposition, we focus throughout on nets in which, with
probability 1, no two clocks for timed transitions ever run down to 0
simultaneously—the ﬁring probabilities are used to deal exclusively with
situations in which two or more pairs in E′ simultaneously qualify to trigger
the next marking change.
clocks corresponding to immediate transitions are enabled simultane-
ously.
9.1.2
Modelling with CSPNs
This subsection contains several examples that illustrate the use of the
cspn building blocks for formal speciﬁcation of discrete-event systems.
Example 1.1 (Machine repair). Consider the system of N machines under
the care of a single repairperson from Example 2.28 in Chapter 6. Suppose
that the successive times (lifetimes) between end of repair and the next
stoppage of machine j are i.i.d according to a random variable Lj with
ﬁnite mean, and the successive times for the repairperson to repair (and
restart) machine j are i.i.d. according to a random variable Rj with ﬁnite
mean.
The machine repair model can be speciﬁed concisely as an N-bounded
cspn in which colors record the identity of the machines; see Figure 9.1 for
N = 4. The set of colors is U = { 0, 1, 2, . . . , N }, and the color domains
are given by UD(dj) = { 1, 2, . . . , N } for 1 ≤j ≤3, UD(d4) = { 0 }, and

9.1 The CSPN Model
391
U(ek) = { 1, 2, . . . , N } for 1 ≤k ≤3. Place d1 contains a token of color i
if and only if machine i is running, place d2 contains a token of color i if
and only if machine i is awaiting repair, and place d3 contains a token of
color i if and only if machine i is under repair. Place d4 contains a token of
color 0 if and only if the repairperson is idle; otherwise, place d4 contains
no tokens.
The input incidence function is given by
w−(e1, i, d1, l) = w−(e2, i, d2, l) = w−(e3, i, d3, l) = 1{i}(l)
for 1 ≤i, l ≤N,
w−(e2, i, d4, 0) = 1
for 1 ≤i ≤N, and w−(e, i, d, l) = 0 otherwise. The output incidence
function is given by
w+(e1, i, d2, l) = w+(e2, i, d3, l) = w+(e3, i, d1, l) = 1{i}(l)
for 1 ≤i, l ≤N,
w+(e3, i, d4, 0) = 1
for 1 ≤i, l ≤N, and w+(e, i, d, l) = 0 otherwise. According to this speciﬁ-
cation, transition e1 is enabled in color i (1 ≤i ≤N) if and only if place d1
contains at least one token of color i; when transition e1 ﬁres in color i, it
removes one token of color i from place d1 and deposits one token of color i
in place d2. Transition e2 is enabled in color i if and only place d2 contains
at least one token of color i and place d4 contains at least one token of
color 0; when transition e2 ﬁres in color i, it removes one token of color i
from place d2, removes one token of color 0 from place d4, and deposits one
token of color i in place d3. Transition e3 is enabled in color i if and only
if place d3 contains at least one token of color i; when transition e3 ﬁres in
color i, it removes one token of color i from place d3, deposits one token of
color i in place d1, and deposits one token of color 0 in place d4.
The ﬁring probabilities are deﬁned for E∗⊆{ (e2, 1), (e2, 2), . . . , (e2, N) }
by
q(e2, i; E∗) =

1
if i = i∗;
0
if i ̸= i∗,
where i∗= min { i: e2,i ∈E∗}. This deﬁnition reﬂects the fact that the
repairperson always selects the lowest-numbered stopped machine for ser-
vice. The clock-setting distribution functions are given by F(x; e1, i) =
P { Li ≤x } and F(x; e3, i) = P { Ri ≤x } for 1 ≤i ≤N. We assume that,
with probability 1, no two clocks corresponding to timed transitions ever
run down to 0 simultaneously.
It is instructive to compare the cspn representation of the machine re-
pair system in Figure 9.1 to the spn representation in Figure 6.1. Clearly,
representing the system as a cspn results in a more concise graph of places
and transitions.

392
9. Colored Stochastic Petri Nets
(e1, i) = arrival of packet for transmission by port i
(e2, i) = end of transmission by port i
(e3, i) = observation of ring token by port i + 1
(e4, i) = start of transmission by port i
(e5, i) = start of propagation from port i
Figure 9.2. cspn representation of token ring (four ports).
Example 1.2 (Token ring). The ring network of Example 2.6 in Chapter 2
can be speciﬁed as a 1-bounded cspn in which colors record both the port
at which a packet arrives and the location of the ring token; see Figure 9.2
for N = 4 ports. The set of colors is U = { 1, 2, . . . , N }. Moreover, UD(d) =
{ 1, 2, . . . , N } for d ∈D and UE(e) = { 1, 2, . . . , N } for e ∈E. Place d1
contains a token of color i if and only if port i is not transmitting a packet
and there is no packet awaiting transmission by port i. Place d2 contains
a token of color i if and only if there is a packet awaiting transmission
by port i. Places d3, d4, and d5 each contain at most one token. Place d3
contains a token of color i if and only if port i is transmitting a packet. Place
d4 contains a token of color i if and only if the ring token is propagating
to port i + 1. Place d5 contains a token of color i whenever port i observes
the ring token. Thus, in Figure 9.2, ports 1, 2, and 4 each have a packet
awaiting transmission and the ring token is propagating to port 3.
Observe that the arc from transition e3 to place d5 has the label “1 ·
(I + 1).” This label indicates that whenever transition e3 ﬁres in color i
(1 ≤i < N), it deposits one token of color i + 1 in place d5, and whenever
transition e3 ﬁres in color N, it deposits one token of color 1 in place
d5. Also observe that immediate transitions e4 and e5 are never enabled
simultaneously, so that ﬁring probabilities need not be explicitly deﬁned.
In the next example colors are used in a queueing system model to dis-
tinguish between jobs having diﬀerent service requirements.

9.1 The CSPN Model
393
(e1, i) = start of service to job i at center 1
(e2, i) = end of service to job i at center 1
(e3, i) = return of job i to queue at center 1
(e4, i) = arrival of job i at center 2
(e5, i) = start of service to job i at center 2
(e6, i) = end of service to job i at center 2
Figure 9.3. cspn representation of cyclic queues with feedback and four stochas-
tically nonidentical jobs.
Example 1.3 (Cyclic queues with feedback and stochastically nonidentical
jobs).
Consider the queueing system of Example 1.4 in Chapter 2, but
now suppose that the N jobs have nonidentical service requirements. In
particular, suppose that successive service times for job i at center j are
i.i.d. according to a continuous distribution function Fi,j. Also suppose
that whenever there is a service completion at a center with one or more
jobs waiting in queue, each of these jobs is equally likely to be selected for
service.
This system can be speciﬁed as an N-bounded cspn in which colors
record the identity of jobs at each center; see Figure 9.3 for N = 4. The set
of colors is U = { 0, 1, . . . , N }, and we have UD(d) = { 1, 2, . . . , N } for d ∈
D −{ d3, d7 }, UD(d) = { 0 } for d ∈{ d3, d7 }, and UE(e) = { 1, 2, . . . , N }
for e ∈E.
Except for places d1 and d5, each place contains at most one token.
Place d1 contains a token of color i if and only if job i is waiting in queue
at center 1, and place d2 contains a token of color i if and only if job i
is undergoing service at center 1. Place d3 contains a token of color 0 if
and only if the server at center 1 is idle. Place d4 contains a token of
color i if and only if service has just ended for job i at center 1. In this
case, immediate transitions e3 and e4 are enabled simultaneously in color i.
With probability 1 −p, transition e3 ﬁres in color i, and job i joins the tail

394
9. Colored Stochastic Petri Nets
of the queue at center 1; with probability p, transition e4 ﬁres in color i,
and job i moves to center 2. That is, q(e3, i; E∗) = 1−p and q(e4, i; E∗) = p
for 1 ≤i ≤N, where E∗= { (e3, i), (e4, i) }. The interpretations of places
d5, d6, and d7 are similar to the interpretations of places d1, d2, and d3,
respectively, but for center 2 rather than center 1.
Whenever there are k ≥1 tokens of respective (distinct) colors i1, i2, . . . ,
ik in place d1, no tokens in place d2, and a single token of color 0 in
place d3, the pairs in the set E∗= { (e1, i1), (e1, i2), . . . , (e1, ik) } qualify
to trigger the next marking change. The ﬁring probabilities are deﬁned as
q(e1, i; E∗) = 1/k for (e, i) ∈E∗, so that each pair in E∗is equally likely
to trigger the next marking change—this deﬁnition reﬂects the fact that
each job is equally likely to be selected for service. Transition e5 behaves
analogously.
The clock-setting distribution functions are given by F( · ; e2, i) = Fi,1( · )
and F( · ; e6, i) = Fi,2( · ) for 1 ≤i ≤N.
The following example shows how colors can be used to identify related
subtasks in a workﬂow system.
Example 1.4 (Complaint processing). Consider a system for the process-
ing of customer complaints. The complaints arrive one at a time and are
processed asynchronously and in parallel. An arriving complaint is regis-
tered and evaluated, and then a questionnaire is sent to the complainant.
A complaint is evaluated as “process” with probability p1 ∈(0, 1) and as
“archive” with probability 1 −p1. If the complaint is evaluated as “pro-
cess” (resp., “archive”), then the complaint is processed (resp., archived)
when the questionnaire is returned or when a timeout period of determin-
istic length L (> 0) elapses, whichever occurs ﬁrst. After a complaint is
processed it undergoes a quality inspection, which it passes with probabil-
ity p2 ∈(0, 1). If the complaint passes the inspection, then it is archived;
otherwise, it undergoes processing again. The system can handle at most
N (> 1) complaints; when the system is processing N −1 complaints and
another complaint arrives, the arrival process for complaints shuts down
(i.e., any further complaints are routed to a diﬀerent processing center).
This process remains shut down until the ﬁrst subsequent completion of
archiving for a complaint. The times between successive arrivals of com-
plaints are i.i.d. as a positive random variable, as are the successive times
to register and evaluate a complaint, the successive times to return a ques-
tionnaire, the successive times to process and inspect a complaint, and the
successive times to archive a complaint.
The complaint processing system can be speciﬁed as an N-bounded
cspn; see Figure 9.4 for N = 7. Places d1, d3, d5, and d10 each contain
at most one token; the remaining places contain between 0 and N to-
kens. The set of colors is U = { 0, 1, 2, . . . , N }. Moreover, UD(d1) = { 0 },

9.1 The CSPN Model
395
Figure 9.4. cspn representation of complaint processing system.

396
9. Colored Stochastic Petri Nets
Table 9.1. Interpretation of (Transition, Color) Pairs in cspn Representation of
Complaint Processing System
(Transition, Color)
Interpretation of (Transition, Color)
(e1, i)
assignment of color i to the next arriving complaint
(e2, i)
arrival of complaint (of color i)
(e3, i)
completion of registration and evaluation for com-
plaint (of color i)
(e4, i)
evaluation of complaint (of color i) as “process”
(e5, i)
evaluation of complaint (of color i) as “archive”
(e6, i)
return of questionnaire for complaint (of color i)
(e7, i)
end of timeout period for complaint (of color i)
(e8, i)
completion of processing for complaint (of color i)
(e9, i)
failure of inspection for complaint (of color i)
(e10, i)
passing of inspection for complaint (of color i)
(e11, i)
completion of archiving for complaint (of color i)
Table 9.2. Interpretation of (Place, Color) Pairs in cspn Representation of Com-
plaint Processing System
(Place, Color)
Interpretation of Token of Given Color in Place
(d1, 0)
the next arrival of a complaint can be scheduled
(d2, i)
color i is available to be assigned to an arriving complaint
(d3, i)
the arrival process of complaints is active and the next com-
plaint to arrive is assigned color i
(d4, i)
a complaint (of color i) is being registered and evaluated
(d6, i)
a questionnaire for complaint (of color i) has been sent but
not returned
(d7, i)
a complaint (of color i) is awaiting or undergoing processing
(d8, i)
a complaint (of color i) has completed processing and is
being archived
(d9, i)
a questionnaire for a complaint (of color i) has been re-
turned and the complaint is being either processed or
archived
(d10, i)
a complaint (of color i) has just been inspected
UD(d) = { 1, 2, . . . , N } for d ∈D −{ d1 }, and UE(e) = { 1, 2, . . . , N } for
e ∈E.
The interpretations of the transitions and places are given in Tables 9.1
and 9.2. The idea is to assign a color between 1 and N to each arriving
complaint such that the complaints in the system have distinct colors;
colors are “recycled” as necessary. In more detail, a token of color i in
place d2 means that color i is available to be assigned to the next arriving
complaint. Whenever place d2 contains one or more tokens and place d1
contains a token of color 0—so that it is time to schedule the next arrival of

9.1 The CSPN Model
397
a complaint by depositing a token in place d3—each pair (e1, i) with u2(i) =
1 becomes qualiﬁed to trigger the next marking change, and exactly one
of these pairs is selected (randomly and uniformly) for ﬁring. If immediate
transition e1 ﬁres in color i (where 1 ≤i ≤N), then a token of color i
is deposited in place d3 and the color i is assigned to the next arriving
complaint. This color-assignment mechanism is formally speciﬁed by setting
q(e1, i1; E∗) = q(e1, i2; E∗) = · · · = q(e1, ik; E∗) = 1/k
for E∗= { (e1, i1), (e1, i2), . . . , (e1, ik) } (where 1 ≤k ≤N and the ij’s are
distinct). The color assigned to a complaint is recycled when the complaint
is archived. Speciﬁcally, whenever e11 = “completion of archiving for com-
plaint” ﬁres in a color i, it removes a token of color i from each of places
d8 and d9 and deposits a token of color i in place d2, so that color i is
available to be assigned to the next arriving complaint. Observe that the
role of place d1 and immediate transition e1 is to ensure that at most one
arrival of a complaint is scheduled at any time.
The remaining ﬁring probabilities are deﬁned in a straightforward way:
q(e4, i; E∗) = 1 −q(e5, i; E∗) = p1
for E∗= { (e4, i), (e5, i) }, and
q(e10, i; E∗) = 1 −q(e9, i; E∗) = p2
for E∗= { (e9, i), (e10, i) }.
9.1.3
The Marking Process
The marking process of a cspn records the marking as it evolves over
continuous time. As with an ordinary spn, formal deﬁnition of the marking
process is in terms of a general state-space Markov chain that describes the
net at successive marking changes.
Deﬁne new-marking probabilities as follows. For a marking (s, u) and a
pair (e, i) ∈E(s, u), set
p(s′, u′; s, u, e, i) =

1
if (s′, u′) = g(s, u, e, i);
0
otherwise,
and for a subset E∗⊆E(s, u) set
p(s′, u′; s, u, E∗) =

(e,i)∈E∗
q(e, i; E∗)p(s′, u′; s, u, e, i).
For a marking (s, u) such that E(s, u) ∩E′ = ∅, write (s, u) →(s′, u′) if
p(s′, u′; s, u, e, i) > 0 for some (e, i) ∈E(s, u). Similarly, for (s, u) such that

398
9. Colored Stochastic Petri Nets
E(s, u) ∩E′ ̸= ∅, write (s, u) →(s′, u′) if p

s′, u′; s, u, E(s, u) ∩E′
> 0.
Finally, write (s, u) ; (s′, u′) if either (s, u) →(s′, u′) or there exist n ≥1
and markings (s(1), u(1)), (s(2), u(2)), . . . , (s(n), u(n)) such that
(s, u) →(s(1), u(1)) →· · · →(s(n), u(n)) →(s′, u′).
The marking set H of the cspn is deﬁned as the set
H =

(s, u): (s(0), u(0)) ; (s, u)

,
where (s(0), u(0)) is the initial marking. To avoid trivialities, we always
assume without comment that E(s, u) ̸= ∅for (s, u) ∈H and that, for each
pair (e, i) ∈E, there exists a marking (s, u) ∈H such that (e, i) ∈E(s, u).
Deﬁne the set of immediate markings by
H′ = { (s, u) ∈H : E(s, u) ∩E′ ̸= ∅}
and the set of timed markings by
H −H′ = { (s, u) ∈H : E(s, u) ∩E′ = ∅} .
Example 1.5 (Machine repair).
Suppose that all machines are running
at time 0. Then the initial marking is (s(0), u(0)), where s(0) = (N, 0, 0, 1),
u(0)
4 (0) = 1, u(0)
1 (i) = 1 for 1 ≤i ≤N, and u(0)
j (i) = 0 otherwise. The
marking set H is the set of all markings (s, u) =

(s1, s2, s3, s4), u) such
that
(i) 	3
j=1 uj(i) = 1 for 1 ≤i ≤N,
(ii) s3 + s4 = 1, and
(iii) u4(0) = s4.
The set H′ of immediate markings is given by H′ = { (s, u) ∈H : s4 =
1 and s2 > 0 }.
Denote by C(s, u) the set of possible clock-reading vectors when the mark-
ing is (s, u). In the cspn setting, a clock-reading vector c is a nonnegative
real-valued vector of length r = 	
e∈E |UE(e)|. The clock readings for tran-
sition ej appear to the left of the clock readings for transition ek whenever
j < k. For each transition e the clock readings for colors { i: i ∈UE(e) }
appear from left to right in the order of the ﬁxed enumeration of the
set U of colors. Given a clock-reading vector c, we denote by ck(i) the
clock reading for transition ek and color i—that is, ck(i) = cm, where
m = 	k−1
j=1 |UE(ej)| + 	
l≤i 1UE(ek)(l). Thus
C(s, u) =

c = (c1, . . . , cr): ck(i) ≥0
and ck(i) > 0 only if (ek, i) ∈E(s, u) −E′ 
.

9.1 The CSPN Model
399
Beginning in marking (s, u) with clock-reading vector c, the time t∗(s, u, c)
to the next marking change is given by
t∗(s, u, c) =
min
{ i,k : (ek,i)∈E(s,u) } ck(i),
and the set of (transition, color) pairs that qualify to trigger the next mark-
ing change is given by
E∗(s, u, c) = { (ek, i) ∈E(s, u): c∗
k(i; s, u, c) = 0 } ,
where c∗
k(i; s, u, c) = ck(i)−t∗(s, u, c). As mentioned previously, we assume
that with probability 1 timed transitions never ﬁre simultaneously, and so
we can restrict attention to the following two cases:
1. (s, u) ∈H −H′ and E∗(s, u, c) = { (e, i) } for some (e, i) ∈E −E′.
2. (s, u) ∈H′ and E∗(s, u, c) = E(s, u) ∩E′.
Next consider a discrete-time Markov chain { (Sn, Un, Cn): n ≥0 } tak-
ing values in the set
Υ =

(s,u)∈H

{ s } × { u } × C(s, u)

,
where (Sn, Un) represents the marking and Cn represents the clock-reading
vector just after the nth marking change. We denote by
• Sn,j the number of tokens in place dj
• Un,j(i) the number of tokens of color i in place dj
• Cn,k(i) the clock reading for transition ek and color i
just after the nth marking change. The transition kernel of the chain is
given by
P

(s, u, c), A

=

(ek,i)
q(ek, i; E∗)

(ej,l)∈N
F

aj,l; ej, l)

(ej,l)∈O
1[0,aj,l]

c∗
j(l)

for all sets
A = { s′ } × { u′ } × { c′ ∈C(s′, u′): 0 ≤c′
j(l) ≤aj,l for (ej, l) ∈E },
where c∗
j(l) = c∗
j(l; s, u, c), E∗= E∗(s, u, c), N = N(s, u, ek, i), O = O(s, u,
ek, i), and the sum is taken over all (ek, i) ∈E∗such that g(s, u, ek, i) =
(s′, u′).
The initial distribution µ of the chain is given by
µ(A) = 1{(s(0),u(0))}(s, u)

(ej,l)∈E(s(0),u(0))
F(aj,l; ej, l)

400
9. Colored Stochastic Petri Nets
for all sets
A = { s } × { u } ×

c ∈C(s, u): 0 ≤cj(l) ≤aj,l for (ej, l) ∈E

.
That is, (s(0), u(0)) is selected as the initial marking and then, for each tran-
sition ej and color l such that (ej, l) ∈E(s(0), u(0)), an initial clock reading
is selected according to the clock-setting distribution function F( · ; ej, l).
Denote by Pµ the probability law of the chain when the initial distribution
is µ.
Finally, construct a continuous-time process { Z(t): t ≥0 } from the
chain { (Sn, Un, Cn): n ≥0 } in a manner similar to the construction of
the marking process for an ordinary spn. Let ζn be the (nonnegative, real-
valued) time of the nth marking change: ζ0 = 0 and
ζn =
n−1

k=0
t∗(Sk, Uk, Ck)
for n ≥1. Let ∆= (∆1, ∆2) ̸∈H and set Z(t) =

X(t), Y (t)

, where
X(t) =

SN(t)
if N(t) < ∞;
∆1
if N(t) = ∞,
Y (t) =

UN(t)
if N(t) < ∞;
∆2
if N(t) = ∞,
and
N(t) = sup { n ≥0: ζn ≤t } .
The stochastic process { Z(t): t ≥0 } is the marking process of the cspn.
By construction, the marking process takes values in the set (H −H′) ∪
{ ∆} and has piecewise-constant, right-continuous sample paths. Observe
that Z(t) = ∆for at least one ﬁnite time t if and only if the lifetime
τ∆= sup
n≥0
ζn
is ﬁnite. We assume throughout that the lifetime is a.s. inﬁnite. Theo-
rem 1.6 below can be used to verify for speciﬁc models that this assumption
holds—the theorem can be established using arguments similar to those in
Section 3.3. We write H′ ; H −H′ if for each (s′, u′) ∈H′ there exists
(s, u) ∈H −H′ such that (s′, u′) ; (s, u).
Theorem 1.6. Suppose that
Pµ{ (Sn, Un) ∈H −H′ i.o. } = 1.
(1.7)
Then Pµ

τ∆= ∞

= 1. If H′ is ﬁnite, then the condition in (1.7) holds
for any initial distribution µ if and only if H′ ; H −H′.

9.1 The CSPN Model
401
As with ordinary spns, the marking process of a cspn is a ctmc under
appropriate assumptions on the clock-setting distribution functions. The
precise result is given by Theorem 1.8 below. Let { γ(n): n ≥0 } be the
indices of the successive marking changes at which the new marking is
timed: γ(−1) = −1 and
γ(n) = inf { j > γ(n −1): (Sj, Uj) ∈H −H′ }
for n ≥0. For timed markings (s, u), (s′, u′) ∈H−H′, let p+(s′, u′; s, u, e, i)
be the probability that the next timed marking is (s′, u′) when the current
marking is (s, u) and transition e ﬁres in color i:
p+(s′, u′; s, u, e, i) =

p(s1, u1; s, u, e, i)
k

j=2
p(sj, uj; sj−1, uj−1, E∗
j−1)

,
where E∗
j−1 = E′ ∩E(sj−1, uj−1) and the summation is over all ﬁnite
sequences (s1, u1), . . . , (sk, uk) (k ≥1) such that (sk, uk) = (s′, u′) and
(sj, uj) ∈H′ for 1 ≤j < k.
Theorem 1.8. Suppose that for each (e, i) ∈E −E′, the clock-setting dis-
tribution function has the form F(x; e, i) = 1 −exp

−v(e, i)x

for some
positive ﬁnite constant v(e, i). Also suppose that
Pµ { (Sn, Un) ∈H −H′ i.o. } = 1.
Then the marking process { Z(t): t ≥0 } is a nonexplosive time-homoge-
neous ctmc. The initial distribution is given by
ν(s, u) = Pµ

(Sγ(0), Uγ(0)) = (s, u)

for (s, u) ∈H −H′, the intensity vector is given by
q(s, u) =

(e,i)∈E(s,u)

1 −p+(s, u; s, u, e, i)

v(e, i)
for (s, u) ∈H −H′, and the transition matrix for the embedded jump chain
is given by
W

(s, u), (s′, u′)

=
	
(e,i)∈E(s,u)
v(e,i)
q(s,u)p+(s′, u′; s, u, e, i)
if (s′, u′) ̸= (s, u);
0
if (s′, u′) = (s, u)
for (s′, u′), (s, u) ∈H −H′.
Because tokens are removed and deposited in essentially a deterministic
manner, cspns appear to have less modelling power than ordinary spns.
For example, it appears impossible to model the queue with batch arrivals

402
9. Colored Stochastic Petri Nets
as a cspn, but this system can be modelled as an spn—see Example 2.4
in Chapter 2. On the other hand, a broad range of interesting models can
be speciﬁed as cspns. In particular, it can be shown that cspns have at
least the modelling power of gsmps with ﬁnite state space and unit speeds.
That is, for any gsmp with ﬁnite state space and unit speeds there exists a
cspn having a marking process that strongly mimics the gsmp in a sense
analogous to that deﬁned in Chapter 4. The proof of this result is similar
to the proof of Theorem 3.3 in Chapter 4.
9.2
Stability and Simulation
In this section we give suﬃcient conditions for stability of a cspn, as well
as conditions under which various simulation methods are applicable. We
simply state the relevant results—in all cases the proofs are similar to those
given in the setting of ordinary spns.
9.2.1
Recurrence
As with ordinary spns, recurrence arguments can be based on drift criteria
or geometric trials criteria.
Drift Criteria
We ﬁrst give a “colored” version of Assumption PD. Recall from Sec-
tion 5.1.2 that G+ is the set of distribution functions on [0, ∞) that have
a convergent LaPlace–Stieltjes transform in a neighborhood of the origin.
As with an ordinary spn, a cspn is said to be irreducible if (s, u) ; (s′, u′)
for all (s, u), (s′, u′) ∈H.
Deﬁnition 2.1. Assumption CPD is said to hold for a speciﬁed cspn if
(i) the marking set H is ﬁnite,
(ii) the cspn is irreducible, and
(iii) there exists 0 < ¯x < ∞such that each clock-setting distribution
function F( · ; e, i) with (e, i) ∈E −E′ belongs to G+ and has a density
component that is positive and continuous on (0, ¯x).
Whenever Assumption CPD holds, we can ﬁnd a real number q > 0 such
that
 ∞
0
eqx dF(x; e, i) < ∞,
(e, i) ∈E.
(2.2)
Recall that the random indices { γ(n): n ≥0 } correspond to the succes-
sive marking changes at which the new marking is timed. Deﬁne the embed-
ded chain { (S+
n , U +
n , C+
n ): n ≥0 } by setting (S+
n , U +
n , C+
n ) = (Sγ(n), Uγ(n),

9.2 Stability and Simulation
403
Cγ(n)) for n ≥0, and denote by Υ+ the state space of the embedded chain.
Theorem 2.5 below asserts that the embedded chain of a cspn satisﬁes a
drift criterion for stability provided that Assumption CPD holds. When
Assumption CPD holds, let ¯φ be the unique measure on subsets of Υ+
such that
¯φ(A) =

{(j,l): (ej,l)∈E(s,u)}
min(xj,l, ¯x)
(2.3)
for all sets
A = { s } × { u } × { c ∈C(s, u): 0 ≤cj(l) ≤xj,l for (ej, l) ∈E(s, u) } .
Set
hq(s, u, c) = exp

q
max
(ej,i)∈E(s,u) cj(i)

and
Hb =

(s, u, c) ∈Υ+ :
max
(ej,i)∈E(s,u) cj(i) ≤b

.
(2.4)
Theorem 2.5. If Assumption CPD holds, then
(i) the embedded chain { (S+
n , U +
n , C+
n ): n ≥0 } is ¯φ-irreducible, where ¯φ
is deﬁned by (2.3), and
(ii) for each b > 0 the set Hb deﬁned by (2.4) is petite with respect to
{ (S+
n , U +
n , C+
n ): n ≥0 }.
Moreover, for some m ≥1, all q satisfying (2.2), and all suﬃciently large
b,
(iii) sup(s,u,c)∈Hb E(s,u,c)

hq(S+
m, U +
m, C+
m) −hq(S+
0 , U +
0 , C+
0 )

< ∞, and
(iv) there exists β ∈(0, 1) such that
E(s,u,c)

hq(S+
m, U +
m, C+
m) −hq(S+
0 , U +
0 , C+
0 )

≤−βhq(s, u, c)
for (s, u, c) ∈Υ+ −Hb.
Corollary 2.6. Suppose that Assumption CPD holds for a cspn. Then
the embedded chain of the marking process is positive Harris recurrent with
recurrence measure ¯φ given by (2.3) and hence admits a stationary distri-
bution π. Moreover, if q satisﬁes (2.2), then π(|f|) < ∞for any function
f such that f = O(hq).
Geometric Trials Criteria
Recurrence properties can also be established by means of geometric trials
arguments. Set E∗
n = E∗(Sn, Un, Cn) and t∗
n = t∗(Sn, Un, Cn) for n ≥0, and
deﬁne the partial history Fn of the underlying chain up to the nth marking
change by setting F0 = { S0, U0 } and
Fn =

S0, U0, E∗
0 , t∗
0, S1, U1, E∗
1 , t∗
1, . . . , Sn−1, Un−1, E∗
n−1, t∗
n−1, Sn, Un

for n ≥1.

404
9. Colored Stochastic Petri Nets
Lemma 2.7. Let { β(n): n ≥1 } and { α(n): n ≥1 } be increasing sequen-
ces of a.s. ﬁnite random indices such that each α(n) and β(n) is a stopping
time with respect to { Fn : n ≥0 } and, moreover, β(n −1) ≤α(n) < β(n)
for n ≥1. [Take β(0) = 0.] Suppose that
Pµ

(Sβ(n), Uβ(n)) ∈¯H
 Fα(n)

≥δ a.s.
for some δ > 0 and all n ≥1. Then Pµ

(Sβ(n), Uβ(n)) ∈¯H i.o.

= 1.
As with ordinary spns, representations of conditional clock-reading dis-
tributions play a key role when establishing the foregoing geometric trials
criterion. The basic result in the cspn setting is as follows. For n ≥0 and
a pair (ei, l) ∈E(Sn, Un), denote by Qn,i(l) the amount of time elapsed
on the clock for (ei, l) between the most recent time prior to ζn at which
this clock was set and time ζn itself. Observe that the value of Qn,i(l) is
determined by Fn for n ≥0.
Lemma 2.8. Let γ be an a.s. ﬁnite stopping time with respect to { Fn : n ≥
0 }. Then
Pµ { Cγ,i(l) > xi,l for (ei, l) ∈H | Fγ }
=
 
(ei,l)∈H F(xi,l + Qγ,i(l); ei, l)/F(Qγ,i(l); ei, l)
if H ⊆E(Sγ, Uγ);
0
otherwise
with probability 1 for any subset H ⊆E −E′ and nonnegative numbers
{ xi,l : (ei, l) ∈H }.
Using the foregoing result and its extensions, we can establish the fol-
lowing cspn analogs of Theorems 2.21 and 2.29 in Chapter 5. For ease of
exposition, we assume that F( · ; e, i) ̸= F( · ; e′, i′) whenever (e, i) ̸= (e′, i′)
with (e, i), (e′, i′) ∈E −E′, and we enumerate the clock-setting distri-
butions corresponding to the timed transitions as F1, F2, . . . , FJ, where
J = |E −E′|. For a sequence { α(n): n ≥0 } as in Lemma 2.7, we deﬁne Hα
to be the state space of the process

(Sα(n), Uα(n)): n ≥1

. In addition,
{ k(i, j, s, u): (s, u) ∈Hα, 1 ≤i, j ≤J } is a collection of ﬁnite nonnegative
integers such that
k(i, j)
def
=
sup
(s,u)∈Hα
k(i, j, s, u) < ∞
(2.9)
for each i and j. Denote by α(n, j, l) the random index of the lth marking
change after α(n) at which a new clock reading is generated from Fj and
by An,j,l the value of this new clock reading. For (s, u) ∈Hα, denote by
I(s, u) the unique subset of { 1, 2, . . . , J } such that i ∈I(s, u) if and only
if (e, l) ∈E(s, u) and F( · ; e, l) = Fi( · ). Finally, for i ∈I(Sα(n), Uα(n)),
denote by Bn,i the clock reading at time α(n) corresponding to the unique
pair (e, l) such that F( · ; e, l) = Fi( · ).

9.2 Stability and Simulation
405
Theorem 2.10. Let ˜I ⊆{ 1, 2, . . . , J }, q ∈{ 1, 2, . . . , J }, and ¯H ⊆H,
and let { x∗
i : i ∈˜I } be a collection of nonnegative numbers. Also let { β(n) :
n ≥1 } and { α(n): n ≥0 } be as in Lemma 2.7 and { k(i, j, s, u): (s, u) ∈
Hα, 1 ≤i, j ≤J } be nonnegative integers satisfying (2.9). Set ˜In =
˜I ∩I(Sα(n), Uα(n)) and Kn(i, j) = k(i, j, Sα(n), Uα(n)), and suppose that
(i) for each i ∈˜I, the clock-setting distribution function Fi is gnbu with
lower bound x∗
i ,
(ii) a new clock reading is generated from Fq at the α(n)th marking change
for n ≥0 and
Pµ

(Sβ(n), Uβ(n)) ∈¯H | Fα(n)

≥Pµ

Bn,i +
J

j=1
Kn(i,j)

l=1
An,j,l < Bn,q, i ∈˜In
 Fα(n)

a.s.
for n ≥0, and
(iii) the positivity condition
x∗
i +
J

j=1
k(i, j)yj < z
for i ∈˜I
holds, where z = ess sup Fq and yj = ess inf Fj for 1 ≤j ≤J.
Then Pµ{ (Sβ(n), (Uβ(n)) ∈¯H i.o. } = 1.
In Theorem 2.12 below { k(j, s, u): (s, u) ∈Hα, 1 ≤j ≤J } is a collec-
tion of ﬁnite nonnegative integers such that, for each j,
k(j)
def
=
sup
(s,u)∈Hα
k(j, s, u) < ∞.
(2.11)
Theorem 2.12. Let ˜I, q, ¯H, and { x∗
i : i ∈˜I } be as in Theorem 2.10.
Also let { β(n): n ≥1 } and { α(n): n ≥0 } be sequences of random in-
dices as in Lemma 2.7 and { k(j, s, u): (s, u) ∈Hα, 1 ≤j ≤J } be
nonnegative integers satisfying (2.11). Set ˜In = ˜I ∩I(Sα(n), Uα(n)) and
Kn(j) = k(j, Sα(n), Uα(n)), and suppose that
(i) for each i ∈˜I, the clock-setting distribution function Fi is gnbu with
lower bound x∗
i ,
(ii) a new clock reading is generated from Fq at the α(n)th marking change
for n ≥0 and
Pµ

(Sβ(n), Uβ(n)) ∈¯H | Fα(n)

≥Pµ
 
i∈˜In
Bn,i +
J

j=1
Kn(j)

l=1
An,j,l < Bn,q
 Fα(n)

a.s.
for n ≥0, and

406
9. Colored Stochastic Petri Nets
(iii) the positivity condition

i∈˜I
x∗
i +
J

j=1
k(j)yj < z
holds, where z = ess sup Fq and yj = ess inf Fj for 1 ≤j ≤J.
Then Pµ{ (Sβ(n), Uβ(n)) ∈¯H i.o. } = 1.
9.2.2
CSPNs and Regeneration
In this section we give conditions on the building blocks of a cspn under
which there exists a sequence of regeneration points for the marking pro-
cess or underlying chain or both, and under which the integral or sum of
the output process over a cycle has ﬁnite moments. Under these conditions,
estimation methods as in Section 6.3 can be used to obtain strongly consis-
tent point estimates and asymptotic conﬁdence intervals for time-average
limits. As with ordinary spns, we ﬁrst give general suﬃcient conditions for
regenerative structure and then reﬁne these conditions for cspns in which
either Assumption CPD or a geometric trials recurrence criterion holds.
General Conditions for Regenerative Structure
For a marking (¯s, ¯u) ∈H and set ¯E ⊆E(¯s, ¯u), denote by { θ(k): k ≥0 }
the indices of the successive marking changes at which the marking is (¯s, ¯u)
and the clocks corresponding to the (transition, color) pairs in ¯E run down
to 0 simultaneously: θ(−1) = 0 and
θ(k) = inf

n > θ(k −1): (Sn−1, Un−1) = (¯s, ¯u) and E∗
n−1 = ¯E

. (2.13)
Theorem 2.14. Let (¯s, ¯u) ∈H and ¯E ⊆E(¯s, ¯u), and suppose that
Pµ

(Sn, Un, E∗
n) = (¯s, ¯u, ¯E) i.o.

= 1.
Also suppose that for all (¯e,¯ı) ∈¯E with q(¯e,¯ı; ¯E) > 0 either
(a) O(¯s, ¯u, ¯e,¯ı) = ∅, or
(b) O(¯s, ¯u, ¯e,¯ı) ̸= ∅and F(x; e, i) = 1 −exp

−v(e, i)x

for each pair
(e, i) ∈O(¯s, ¯u, ¯e,¯ı), where v(e, i) is a positive ﬁnite constant.
Then the random times { ζθ(k) : k ≥0 } deﬁned via (2.13) form a sequence
of regeneration points for { Z(t): t ≥0 }. If, in particular, the condition
in (a) holds for all (¯e,¯ı) ∈¯E with q(¯e,¯ı; ¯E) > 0, then the random indices
{ θ(k): k ≥0 } form a sequence of regeneration points (in discrete time) for
{ (Sn, Un, Cn): n ≥0 }.
As with ordinary spns, the condition in (a) holds if (¯s, ¯u) is a single state—
that is, if E(¯s, ¯u) = { (¯e,¯ı) } for some (¯e,¯ı) ∈E.

9.2 Stability and Simulation
407
CSPNs with Positive Clock-Setting Densities
We now reﬁne the foregoing result when Assumption CPD holds. To this
end, we ﬁrst deﬁne the notion of a polynomially dominated function in the
setting of cspns. Set
˜gq(s, u, c) =

1 + max(ej,i)∈E cq
j(i)
if (s, u, c) ∈Υ+;
1
if (s, u, c) ∈Υ −Υ+
for (s, u, c) ∈Υ and q ≥0.
Deﬁnition 2.15. A real-valued function ˜f deﬁned on Υ is polynomially
dominated if ˜f = O(˜gq) for some q ≥0.
For a sequence of random indices { θ(k): k ≥0 } deﬁned as in (2.13), set
Yk(f) =
 ζθ(k)
ζθ(k−1)
f

Z(u)

du
(2.16)
for each real-valued function f deﬁned on H −H′ and
˜Y k( ˜f) =
θ(k)−1

j=θ(k−1)
˜f(Sj, Uj, Cj).
(2.17)
for each real-valued function ˜f deﬁned on Υ.
Theorem 2.18. Let (¯s, ¯u) ∈H −H′ and (¯e,¯ı) ∈E(¯s, ¯u). Suppose that
Assumption CPD holds and that either
(a) O(¯s, ¯u, ¯e,¯ı) = ∅, or
(b) O(¯s, ¯u, ¯e,¯ı) ̸= ∅and F(x; e, i) = 1 −exp

−v(e, i)x

for each pair
(e, i) ∈O(¯s, ¯u, ¯e,¯ı), where v(e, i) is a positive ﬁnite constant.
Then
(i) The random times { ζθ(k) : k ≥0 } deﬁned via (2.13) with ¯E = { (¯e,¯ı) }
form a sequence of regeneration points for the marking process { Z(t) :
t ≥0 }.
(ii) Eµ [Y r
1 (|f|)] < ∞for r ≥0 and any real-valued function f deﬁned on
H −H′, where Y1(f) is deﬁned by (2.16).
(iii) Eµ [ ˜Y r
1(| ˜f|)] < ∞for r ≥0 and any polynomially dominated function
˜f deﬁned on Υ, where ˜Y1( ˜f) is deﬁned by (2.17).
If, in particular, the condition in (a) holds, then also
(iv) The random indices { θ(k): k ≥0 } form a sequence of regeneration
points for { (Sn, Un, Cn) : n ≥0 }.
The assumption that (¯s, ¯u) is a timed marking can be relaxed, similarly to
the way in which Theorem 2.31 in Chapter 6 is obtained from Theorem 2.24
in the same chapter.

408
9. Colored Stochastic Petri Nets
CSPNs Satisfying Geometric Trials Criteria
We now reﬁne Theorem 2.14 when a geometric trials recurrence criterion
holds. For a ﬁxed set of pairs ¯E ⊆E, set β(−1) = −1 and
β(n) = inf

k > β(n −1): E∗(Sk, Uk, Ck) = ¯E

(2.19)
for n ≥0. For a marking (¯s, ¯u) ∈H with ¯E ⊆E(¯s, ¯u), deﬁne { θ(k): k ≥0 }
as in (2.13) to be the random indices of the successive marking changes at
which the marking is (¯s, ¯u) and the clocks corresponding to the (transition,
color) pairs in ¯E run down to 0 simultaneously. Thus { θ(k): k ≥0 } is
a random subsequence of { β(n) + 1: n ≥0 }. In the following, Y1(f) is
deﬁned as in (2.16) and, as before, Fn denotes the partial history of the
underlying chain up to the nth marking change.
Theorem 2.20. Let (¯s, ¯u) ∈H and ¯E ⊆E(¯s, ¯u). Suppose that each ran-
dom index β(n) deﬁned in (2.19) is a.s. ﬁnite. Let { α(n): n ≥1 } be an
increasing sequence of random indices such that each α(n) is a stopping
time with respect to { Fk : k ≥0 } and β(n −1) ≤α(n) < β(n). Suppose
that
Pµ

(Sβ(n), Uβ(n)) = (¯s, ¯u)
 Fα(n)

> δ a.s.
for some δ > 0 and all n ≥0. Also suppose that for all (¯e,¯ı) ∈¯E with
q(¯e,¯ı; ¯E) > 0 either
(a) O(¯s, ¯u, ¯e,¯ı) = ∅, or
(b) O(¯s, ¯u, ¯e,¯ı) ̸= ∅and F(x; e, i) = 1 −exp

−v(e, i)x

for each pair
(e, i) ∈O(¯s, ¯u, ¯e,¯ı), where v(e, i) is a positive ﬁnite constant.
Then the random times { ζθ(k) : k ≥0 } deﬁned via (2.13) form a sequence
of regeneration points for the marking process { Z(t): t ≥0 }. Moreover,
for any bounded real-valued function f deﬁned on H −H′, the cycle sum
Y1(|f|) has ﬁnite mean if
lim inf
n≥0 Eµ

ζβ(n+1)+1 −ζβ(n)+1

< ∞
and ﬁnite rth moment (r > 1) if
lim inf
n≥0 Eµ

(ζβ(n+1)+1 −ζβ(n)+1)r+ϵ
< ∞
(2.21)
for some ϵ > 0.
The following analog to Lemma 2.39 in Chapter 6 can be useful when
verifying that (2.21) holds.
Lemma 2.22. Let (ei, l) ∈E −E′ and β be an a.s. ﬁnite stopping time
with respect to the sequence { Fn : n ≥0 } of partial histories of the under-
lying chain. Suppose that the clock-setting distribution function F( · ; ei, l)
is gnbu. Then Eµ[Cr
β,i(l)] < ∞for r ≥0.

9.2 Stability and Simulation
409
As with ordinary spns, sometimes a discrete-time version of the condition
in (2.21) is easier to verify than (2.21) itself.
Theorem 2.23. Suppose that the conditions of Theorem 2.20 hold. Also
suppose that the marking set H is ﬁnite. Then, for any real-valued function
f deﬁned on H −H′, the cycle sum Y1(|f|) has ﬁnite mean if each clock-
setting distribution has ﬁnite mean and
sup
n≥0
Eµ

β(n + 1) −β(n)

< ∞,
and Y1(|f|) has ﬁnite rth moment (r > 1) if each clock-setting distribution
has ﬁnite rth moment and
sup
n≥0
Eµ

β(n + 1) −β(n)
r+ϵ
< ∞
for some ϵ > 0.
We conclude this subsection by giving the discrete-time analog of Theo-
rem 2.20.
Theorem 2.24. Let (¯s, ¯u) ∈H and ¯E ⊆E(¯s, ¯u). Suppose that each ran-
dom index β(n) deﬁned in (2.19) is a.s. ﬁnite. Let { α(n): n ≥1 } be an
increasing sequence of random indices such that each α(n) is a stopping
time with respect to { Fk : k ≥0 } and β(n −1) ≤α(n) < β(n). Suppose
that
Pµ

(Sβ(n), Uβ(n)) = (¯s, ¯u)
 Fα(n)

> δ a.s.
for some δ > 0 and all n ≥0. Also suppose that O(¯s, ¯u, ¯e,¯ı) = ∅for
all (¯e,¯ı) ∈¯E with q(¯e,¯ı; ¯E) > 0. Then the random indices { θ(k): k ≥0 }
deﬁned via (2.13) form a sequence of regeneration points for the underly-
ing chain { (Sn, Un, Cn) : n ≥0 }. Moreover, for any bounded real-valued
function ˜f deﬁned on Υ, the cycle sum ˜Y 1(| ˜f|) has ﬁnite mean if
sup
n≥0
Eµ

β(n + 1) −β(n)

< ∞
and ﬁnite rth moment (r > 1) if
sup
n≥0
Eµ

β(n + 1) −β(n)
r+ϵ
< ∞
for some ϵ > 0.
9.2.3
CSPNs and STS Estimation Methods
In this section we provide sllns and fclts for the marking process and
underlying chain of a cspn. When such limit theorems hold, methods based

410
9. Colored Stochastic Petri Nets
on standardized time series—see Section 7.2—can be used to obtain point
estimates and conﬁdence intervals for time-average limits and functions of
such limits.
Lemma 2.25 asserts that—in analogy to ordinary spns—the underlying
chain for a cspn is an od-regenerative process in discrete time under As-
sumption CPD, and a broad class of cycle sums have ﬁnite moments of all
orders.
Lemma 2.25. Suppose that Assumption CPD holds. Then there exists a
sequence { θ(k): k ≥0 } of od-regeneration points for the underlying chain
{ (Sn, Un, Cn): n ≥0 }. Moreover, the cycle sum
˜Y 1( ˜f) =
θ(1)−1

n=θ(0)
˜f(Sn, Un, Cn)
(2.26)
has ﬁnite moments of all orders for any polynomially dominated real-valued
function ˜f deﬁned on Υ.
It follows from Lemma 2.25 that the chain { (Sn, Un, Cn): n ≥0 } is positive
Harris recurrent whenever Assumption CPD holds. Moreover, the desired
sllns and fclts for the marking process and underlying chain can be
obtained by applying the results in Section 7.2.1.
We ﬁrst state an slln for the underlying chain. In the theorem an ℜl-
valued function ˜f = ( ˜f 1, ˜f 2, . . . , ˜f l) deﬁned on Υ is said to be polynomially
dominated if each ˜f j is polynomially dominated in the sense of Deﬁni-
tion 2.15. Given such a function together with a sequence { θ(k): k ≥0 }
of od-regeneration points for the chain, set
˜r( ˜f) = Eµ [ ˜Y 1( ˜f)]
Eµ [˜τ1]
,
(2.27)
where
˜Y 1( ˜f) =
θ(1)−1

j=θ(0)
˜f(Sj, Uj, Cj)
and ˜τ1 = θ(1) −θ(0).
Theorem 2.28. Suppose that Assumption CPD holds, so that there exists
a sequence { θ(k): k ≥0 } of od-regeneration points for the underlying chain
{ (Sn, Un, Cn): n ≥0 }. Then ˜r(| ˜f|) < ∞and
lim
n→∞
1
n
n−1

j=0
˜f(Sj, Uj, Cj) = ˜r( ˜f) a.s.
for any polynomially dominated ℜl-valued function ˜f deﬁned on Σ, where
˜r( ˜f) is deﬁned by (2.27).

9.2 Stability and Simulation
411
We next give an fclt for the underlying chain. Recall that Cl[0, 1] (l ≥1)
is the space of continuous ℜl-valued functions on [0, 1]. Whenever there ex-
ists a sequence { θ(k): k ≥0 } of od-regeneration points for the underlying
chain and the quantity ˜r( ˜f) given by (2.27) is well deﬁned and ﬁnite, we
can deﬁne a sequence of Cl[0, 1]-valued random functions ˜R1( ˜f), ˜R2( ˜f), . . .
by setting
˜Rn( ˜f)(t) =
1
√n
 nt
0

˜f(S⌊u⌋, U⌊u⌋, C⌊u⌋) −˜r( ˜f)

du
for 0 ≤t ≤1 and n ≥1. In the following, denote by ⇒weak convergence
on Cl[0, 1] and by W (l) a standard l-dimensional Brownian motion on [0, 1].
Theorem 2.29. Suppose that Assumption CPD holds—so that there ex-
ists a sequence { θ(k): k ≥0 } of od-regeneration points for the underlying
chain—and let ˜f be a polynomially dominated ℜl-valued function deﬁned
on Υ. Then there exists an l × l matrix Q( ˜f) such that ˜Rn( ˜f) ⇒Q( ˜f)W (l)
as n →∞for any initial distribution µ.
As usual,
1
√n
n−1

j=0
 ˜f(Sj, Uj, Cj) −˜r( ˜f)

⇒˜σ( ˜f)N(0, 1)
under the conditions of Theorem 2.29, where ˜σ( ˜f) is a nonnegative constant
and ⇒denotes ordinary convergence in distribution. That is, the foregoing
fclt implies an ordinary clt.
As with ordinary spns, both sllns and fclts for processes of the form

f

Z(t)

: t ≥0

can be obtained from the corresponding results for the
underlying chain. For a sequence { θ(k): k ≥0 } of od-regeneration points
for the underlying chain, set
r(f) = Eµ [ ˜Y 1(ft∗)]
Eµ[ ˜Y1(t∗)]
(2.30)
for each ℜl-valued function f deﬁned on H −H′, where (ft∗)(s, u, c) =
f(s, u)t∗(s, u, c) for (s, u, c) ∈Υ and ˜Y 1( ˜f) is deﬁned in (2.26).
Theorem 2.31. Suppose that Assumption CPD holds, so that there ex-
ists a sequence { θ(k): k ≥0 } of od-regeneration points for the underlying
chain. Then r(|f|) < ∞and
lim
t→∞
1
t
 t
0
f

Z(u)

du = r(f) a.s.
for any ℜl-valued function f deﬁned on H −H′, where r(f) is deﬁned by
(2.30).

412
9. Colored Stochastic Petri Nets
When there exists a sequence { θ(k): k ≥0 } of od-regeneration points for
the underlying chain and the quantity r(f) given by (2.30) is well deﬁned
and ﬁnite, set
Rν(f)(t) =
1
√ν
 νt
0

f

Z(u)

−r(f)

du
for 0 ≤t ≤1 and ν > 0.
Theorem 2.32. Suppose that Assumption CPD holds, and let f be an
arbitrary ℜl-valued function deﬁned on H −H′. Then there exists an l ×
l matrix Q(f) such that Rν(f) ⇒Q(f)W (l) as ν →∞for any initial
distribution µ.
9.2.4
Consistent Estimation Methods
In this subsection we give conditions on the building blocks of a cspn
under which variable batch-means and spectral methods are valid. The
development, which parallels that in Section 7.3 for ordinary spns, applies
to other consistent estimation methods as well.
Consider a cspn with an underlying chain { (Sn, Un, Cn): n ≥0 } having
state space Υ, together with a real-valued function ˜f deﬁned on Υ, such
that
lim
n→∞¯r(n; ˜f) = ˜r( ˜f) a.s.
for some ﬁnite constant ˜r( ˜f) and
√n

¯r(n; ˜f) −˜r( ˜f)

˜σ( ˜f)
⇒N(0, 1)
(2.33)
as n →∞for some constant ˜σ( ˜f) ∈(0, ∞), where
¯r(n; ˜f) = 1
n
n−1

j=0
˜f(Sj, Uj, Cj).
(2.34)
If we can ﬁnd an estimator Vn that is consistent for ˜σ2( ˜f) in (2.33), then
the random interval

¯r(n; ˜f) −zp V 1/2
n
√n
, ¯r(n; ˜f) + zp V 1/2
n
√n

is an asymptotic 100p% conﬁdence interval for ˜r( ˜f), where zp is the (1+p)/2
quantile of the standard normal distribution as before; cf. Section 7.3.

9.2 Stability and Simulation
413
Aperiodicity and Harris Ergodicity
As with ordinary spns, the ﬁrst step is to obtain conditions under which
the underlying chain is Harris ergodic. A d-cycle of a cspn is a ﬁnite col-
lection { H1, H2, . . . , Hd } of disjoint subsets of H such that (s′, u′) ∈Hi+1
whenever (s, u) ∈Hi and (s, u) →(s′, u′). (Take Hd+1 = H1.) The period
of the cspn is the largest d for which a d-cycle exists; the cspn is called
aperiodic if d = 1 and periodic if d > 1.
Theorem 2.35. Let { (Sn, Un, Cn): n ≥0 } be the underlying chain of an
aperiodic cspn. If Assumption CPD holds, then { (Sn, Un, Cn): n ≥0 } is
aperiodic.
Corollary 2.36. Let { (Sn, Un, Cn): n ≥0 } be the underlying chain of an
aperiodic cspn. If Assumption CPD holds, then { (Sn, Un, Cn): n ≥0 } is
Harris ergodic.
Consistent Estimation in Discrete Time
Let ¯r(n; ˜f) be deﬁned as in (2.34). As discussed previously, if Assump-
tion CPD holds, then for any polynomially dominated function ˜f there
exist constants ˜r( ˜f) and ˜σ( ˜f) such that limn→∞¯r(n; ˜f) = ˜r( ˜f) a.s. and
√n

¯r(n; ˜f) −˜r( ˜f)

⇒˜σ( ˜f)N(0, 1) as n →∞. As with ordinary spns, we
assume that ˜σ2( ˜f) > 0, and consider quadratic-form estimators, that is,
estimators of the form
Vn = Vn( ˜f) =
n

i=0
n

j=0
˜f(Si, Ui, Ci) ˜f(Sj, Uj, Cj)q(n)
i,j ,
where each q(n)
i,j is a ﬁnite constant and q(n)
i,j = q(n)
j,i for all i, j.
When Assumption CPD holds, there exists an invariant probability mea-
sure π for the underlying chain { (Sn, Un, Cn): n ≥0 }. By applying general
results on consistent variance estimation for stationary processes, it some-
times can be established that Vn( ˜f) ⇒˜σ2( ˜f) for a speciﬁed estimator Vn( ˜f)
when the initial distribution of the underlying chain is π. To this end, we
have the following analogs of Propositions 3.10 and 3.12 in Chapter 7.
Proposition 2.37. Let { (Sn, Un, Cn): n ≥0 } be the underlying chain of
an aperiodic cspn, and let ˜f be a polynomially dominated real-valued func-
tion deﬁned on Υ. Suppose that Assumption CPD holds, so that there exists
an invariant distribution π for the chain and { ˜f(Sn, Un, Cn): n ≥0 } obeys
a clt with variance constant ˜σ2( ˜f). Then ˜σ2( ˜f) has the representation
˜σ2( ˜f) = lim
n→∞nVarπ

1
n
n−1

j=0
˜f(Sj, Uj, Cj)

.

414
9. Colored Stochastic Petri Nets
Proposition 2.38. Suppose that Assumption CPD holds for an aperiodic
cspn. Then there exist ρ ∈(0, 1) and c ∈[0, ∞) such that
Covπ [ ˜f 1(S0, U0, C0), ˜f 2(Sk, Uk, Ck)]
 ≤cρk
for k ≥0 and any polynomially dominated functions ˜f 1 and ˜f 2.
Theorem 2.40 below can be used to extend consistency results from
the stationary to the nonstationary setting. Recall from Deﬁnition 3.13
in Chapter 7 that a quadratic-form estimator is localized if there exist
a1 ∈(0, ∞) and sequences { a2(n): n ≥0 } and { m(n): n ≥0 } of non-
negative constants with a2(n) →0 and m(n)/n →0 such that
|q(n)
i,j | ≤

a1/n
if |i −j| ≤m(n);
a2(n)/n
if |i −j| > m(n).
(2.39)
Theorem 2.40. Let { (Sn, Un, Cn): n ≥0 } be the underlying chain of an
aperiodic cspn, and let ˜f be a polynomially dominated real-valued function
deﬁned on Υ. Suppose that Assumption CPD holds, so that there exists an
invariant distribution π for the chain and { ˜f(Sn, Un, Cn): n ≥0 } obeys a
clt with variance constant ˜σ2( ˜f). If a localized quadratic-form estimator
Vn( ˜f) satisﬁes Vn( ˜f) ⇒˜σ2( ˜f) when the initial distribution equals π, then
Vn( ˜f) ⇒˜σ2( ˜f) for any initial distribution.
Applications to Batch-Means and Spectral Methods
For a cspn with underlying chain { (Sn, Un, Cn): n ≥0 } and a speciﬁed
function ˜f, consider the batch-means estimator based on b batches of length
m:
V (B)
n
=
m
b −1
b

j=1
 ¯Xn(j) −¯Xn
2,
(2.41)
where n = bm,
¯Xn(j) = 1
m
jm−1

i=(j−1)m
˜f(Sn, Un, Cn),
(2.42)
and ¯Xn = (1/b) 	b
j=1 ¯Xn(j). Also consider the spectral estimator
V (S)
n
= 1
n
m−1

h=−(m−1)
λ(h/m) ˆRh,
(2.43)
where
ˆRh = 1
n
n−|h|−1

i=0
(Zi −¯Zn)(Zi+|h| −¯Zn),
(2.44)

9.2 Stability and Simulation
415
with Zi = ˜f(Si, Ui, Ci) for 0 ≤i ≤n and ¯Zn = (1/n) 	n−1
i=0 Zi. We assume
throughout that the lag window λ belongs to the class Λ deﬁned in Sec-
tion 7.3.3. Arguing as in Section 7.3.3, we can establish the following two
results.
Theorem 2.45. Let { (Sn, Un, Cn): n ≥0 } be the underlying chain of an
aperiodic cspn, and let V (B)
n
be given by (2.41) and (2.42), where ˜f is
a polynomially dominated real-valued function deﬁned on Υ. Suppose that
Assumption CPD holds, so that { ˜f(Sn, Un, Cn): n ≥0 } obeys a clt with
variance constant ˜σ2( ˜f). Also suppose that the batch size b = b(n) and
batch length m = m(n) satisfy b(n) →∞and m(n) →∞as n →∞. Then
V (B)
n
⇒˜σ2( ˜f) as n →∞.
Theorem 2.46. Let { (Sn, Un, Cn): n ≥0 } be the underlying chain of an
aperiodic cspn. Also let V (S)
n
be deﬁned by (2.43) and (2.44) with λ ∈
Λ and Zn = ˜f(Sn, Un, Cn), where ˜f is a polynomially dominated real-
valued function deﬁned on Υ. Suppose that Assumption CPD holds, so that
{ ˜f(Sn, Un, Cn): n ≥0 } obeys a clt with variance constant ˜σ2( ˜f). Also
suppose that the spectral window length m = m(n) satisﬁes m(n) →∞and
m2(n)/n →0. Then V (S)
n
⇒˜σ2( ˜f) as n →∞.
Functions of Time-Average Limits
Fix l ≥1 and let ˜f = ( ˜f 1, ˜f 2, . . . , ˜f l) be a polynomially dominated ℜl-
valued function deﬁned on Υ. If Assumption CPD holds, then there exists
an l-vector ˜r( ˜f) =

˜r( ˜f 1), ˜r( ˜f 2), . . . , ˜r( ˜f l)

such that ¯r(n; ˜f) →˜r( ˜f) a.s.,
where
¯r(n; ˜f) = 1
n
n−1

j=0
˜f(Sn, Un, Cn).
We now consider estimation methods for quantities of the form
r = g

˜r( ˜f)

= g

˜r( ˜f 1), ˜r( ˜f 2), . . . , ˜r( ˜f l)

,
(2.47)
where g: ℜl →ℜis diﬀerentiable in a neighborhood of ˜r( ˜f). The quantity
˜r( ˜f) exists whenever Assumption CPD holds and the cspn is aperiodic. As
with ordinary spns, we deﬁne a point estimator of r by rn = g

¯r(n; ˜f)

.
Letting the matrix W = ∥ws,t∥given by
ws,t = lim
n→∞nCovπ

¯r(n; ˜f s), ¯r(n; ˜f t)

,
(2.48)
we have the following result.

416
9. Colored Stochastic Petri Nets
Theorem 2.49. Let { (Sn, Un, Cn): n ≥0 } be the underlying chain of an
aperiodic cspn, and let ˜f = ( ˜f 1, ˜f 2, . . . , ˜f l) be polynomially dominated.
Suppose that Assumption CPD holds, so that there exists an invariant mea-
sure π for the chain and ¯r(n; ˜f) →˜r( ˜f) a.s. for some ﬁnite l-vector ˜r( ˜f).
Then rn →r a.s. and
√n(rn −r) ⇒σN(0, 1)
as n →∞, where
σ2 = ∇g

˜r( ˜f)
t W ∇g

˜r( ˜f)

.
We now consider the problem of consistently estimating σ2.
As in Section 7.3.4, deﬁne an l × l matrix Wn = ∥Vn(s, t)∥, where
Vn(s, t) =
n

i=1
n

j=1
˜f s(Si, Ui, Ci) ˜f t(Sj, Uj, Cj)q(n)
i,j
for s, t ∈{ 1, 2, . . . , n } and the q(n)
i,j are coeﬃcients of a quadratic-form es-
timator. For the batch-means and spectral estimators described previously,
we can show that Wn ⇒W when the initial distribution is π and the
conditions of Theorems 2.45 and 2.46 hold, respectively.
As for ordinary spns, the coupling argument used to establish Theo-
rem 2.40 can be extended to obtain a multidimensional limit result. In the
following theorem the matrix Wn is said to be a localized estimator of W
if and only if each q(n)
i,j satisﬁes (2.39).
Theorem 2.50. Let { (Sn, Un, Cn): n ≥0 } be the underlying chain of an
aperiodic cspn, and let ˜f = ( ˜f 1, ˜f 2, . . . , ˜f l) be a polynomially dominated
ℜl-valued function deﬁned on Υ. Suppose that Assumption CPD holds, so
that there exists an invariant distribution π for the chain and the process
{ ˜f(Sn, Un, Cn): n ≥0 } obeys a clt with covariance matrix W. If a local-
ized estimator Wn satisﬁes Wn ⇒W when the initial distribution equals
π, then Wn ⇒W for any initial distribution.
The foregoing results can be combined to yield conﬁdence intervals for
r = g

˜r( ˜f)

. Suppose, for example, that Wn is the batch-means estimator
of W and the conditions of Theorem 2.45 hold, or that Wn is a spectral
estimator of W and the conditions of Theorem 2.46 hold. Set
σ2
n = ∇g

¯r(n; ˜f)
t Wn ∇g

¯r(n; ˜f)

for n ≥1. Arguing as in Section 7.3.4, we ﬁnd that σ2
n ⇒σ2, which implies
that
!
rn −zp σn
√n , rn + zp σn
√n
"
is an asymptotic 100p% conﬁdence interval for r, where zp is the (1 + p)/2
quantile of the standard normal distribution.

9.2 Stability and Simulation
417
Consistent Estimation in Continuous Time
Consider an aperiodic spn and suppose that Assumption CPD holds. It
follows that ¯r(t; f) →r(f) a.s. for some ﬁnite constant r(f) and any real-
valued function f deﬁned on H; here
¯r(t; f) = 1
t
 t
0
f

Z(u)

du.
As with ordinary spns, the foregoing methodology for functions of time-
average limits in discrete time leads to conﬁdence-interval procedures for
r(f). Fix f and recall that (ft∗)(s, u, c) = f(s, u)t∗(s, u, c), where t∗is the
holding-time function. The idea, as before, is to express r(f) in the form
(2.47) with ˜f = (ft∗, t∗) and g(x, y) = x/y.
Let ∥q(n)
i,j ∥be a set of coeﬃcients such that, for any polynomially domi-
nated functions ˜f s and ˜f t deﬁned on Υ, the quadratic-form estimator
Vn( ˜f s, ˜f t) =
n

i=0
n

j=0
˜f s(Si, Ui, Ci) ˜f t(Sj, Uj, Cj)q(n)
i,j
is consistent for ws,t, where ws,t is given by (2.48). Then
!
ˆrn −zp σn
√n , ˆrn + zp σn
√n
"
is an asymptotic 100p% conﬁdence interval for r(f), where
ˆrn = ¯r(n; ft∗)
¯r(n; t∗)
and
σ2
n =
1
¯r2(n; t∗)

Vn(1, 1) −2ˆrnVn(1, 2) + ˆr2
nVn(2, 2)

.
Here ¯r(n; ˜f) is deﬁned as in (2.34),
Vn(1, 1) =
n

i=0
n

j=0
(ft∗)(Si, Ui, Ci) (ft∗)(Sj, Uj, Cj) q(n)
i,j ,
Vn(1, 2) =
n

i=0
n

j=0
(ft∗)(Si, Ui, Ci) t∗(Sj, Uj, Cj) q(n)
i,j ,
and
Vn(2, 2) =
n

i=0
n

j=0
t∗(Si, Ui, Ci) t∗(Sj, Uj, Cj) q(n)
i,j .

418
9. Colored Stochastic Petri Nets
9.2.5
Delays
Delays in cspns are speciﬁed similarly to delays in ordinary spns. A se-
quence { Dj : j ≥0 } of delays in a cspn is speciﬁed in terms of starts
{ Aj : j ≥0 } and terminations { Bj : j ≥0 } deﬁned on the same probabil-
ity space as the underlying chain { (Sn, Un, Cn): n ≥0 } (via the relation
Dj = Bj−Aj). As always, we restrict attention to delays that start and ter-
minate only at marking changes—thus we have Aj = ζα(j) and Bj = ζβ(j)
for j ≥0, where α(j) and β(j) are a.s. ﬁnite random indices. We also focus
on sequences for which the α(j)’s are nondecreasing, so that delays are
enumerated in start order.
Start Vectors
As in Chapter 8, a recursively generated sequence of start vectors provides
the link between the starts and terminations of individual delay intervals.
For cspns, the sequence { Vn : n ≥0 } of start vectors is determined by the
sample paths of the chain { (Sn, Un, Cn): n ≥0 }. In particular, we assume
that the current marking determines the length of the start vector and
denote this length by ψ(s, u) when the current marking is (s, u). The nth
start vector Vn records the starts of delay intervals for all ongoing and
newly started delays (of positive duration) at time ζn. Some components
of Vn may be equal to −1; as before, lengths are never computed for delay
intervals with negative starts. The initial start vector is a speciﬁed vector,
denoted v0(S0, U0), that is determined by the initial marking (S0, U0) and
has components equal to 0 or −1. Take v0(S0, U0) to be the empty vector
∅when ψ(S0, U0) = 0.
Whenever the clocks corresponding to the (transition, color) pairs in a
set E∗run down to 0 simultaneously and trigger a marking change from
(s, u) to (s′, u′), a new start vector is obtained from the current start vector
by
1. Inserting the current time at zero or more positions speciﬁed by an
index vector iα(s′, u′; s, u, E∗)
2. Deleting components at zero or more positions speciﬁed by an index
vector iβ(s′, u′; s, u, E∗)
3. Permuting the components according to an index vector iπ(s′, u′; s, u,
E∗)
Components are deleted one at a time in the order in which the indices
appear in the vector iβ(s′, u′; s, u, E∗). For each nonnegative component
that is deleted, the length of a delay interval is computed by subtracting
the deleted component from the current time.
The formal deﬁnitions of the sequences { Vn : n ≥0 }, { An : n ≥0 },
{ Bn : n ≥0 }, and { Dn : n ≥0 } are completely analogous to those in

9.2 Stability and Simulation
419
Section 8.1.2. Denote by Vn,i the ith component of the vector Vn for
1 ≤i ≤ψ(Sn, Un), and set
K = inf { n ≥0: Vn,i ̸= −1 for 0 ≤i ≤ψ(Sn, Un) } .
(2.51)
When E∗= { (e∗, i∗) } for some (e∗, i∗) ∈E(s, u), we often write iα(s′, u′;
s, u, e∗, i∗) for iα(s′, u′; s, u, E∗), and so forth.
Regenerative Methods for Delays
We now consider methods for estimating general time-average limits of the
form limn→∞(1/n) 	n−1
j=0 f(Dj), where the sequence of delays { Dj : j ≥0 }
is determined from the marking changes of a cspn by means of start vectors.
We ﬁrst suppose that there exists a recurrent single state (¯s, ¯u), so that
E(¯s, ¯u) = { (¯e,¯ı) } for some (¯e,¯ı) ∈E and Pµ { (Sn, Un) = (¯s, ¯u) i.o. } = 1.
Then the successive times at which the marking is (¯s, ¯u) and transition ¯e
ﬁres in color ¯ı form a sequence of regeneration points. More speciﬁcally, if
we set θ(0) = 0 and
θ(k) = inf{ n > θ(k −1): (Sn−1, Un−1) = (¯s, ¯u) }
for k ≥1, then the random indices { θ(k): k ≥0 } form a sequence of regen-
eration points for { (Sn, Un, Cn): n ≥0 } and the random times { ζθ(k) : k ≥
0 } form a sequence of regeneration points for { Z(t): t ≥0 }.
We assume throughout that the system behaves as if a regeneration oc-
curs at time 0—cf. the discussion at the beginning of Section 8.2—and that
the starts { Aj : j ≥0 }, the terminations { Bj : j ≥0 }, and the random in-
dex K deﬁned by (2.51) satisfy
Pµ { K < ∞} = 1
(2.52)
Pµ { Aj < ∞} = Pµ { Bj < ∞} = 1,
(2.53)
for j ≥0 and
Pµ

lim
j→∞Aj = ∞

= 1.
(2.54)
As in Section 8.2.1, we can construct a sequence { ˇγ(k): k ≥0 } of
random indices that decomposes sample paths of { Dj : j ≥0 } into one-
dependent stationary cycles. Start with the sequence { ζθ(k) : k ≥0 } of
regeneration points for the marking process and recursively construct a
subsequence { ζˇθ(k) : k ≥0 }. To do this, take ˇθ(0) = θ(0) = 0 and then,
given ˇθ(k), wait until the ﬁrst marking change ˇν(k) at which all the ongoing
delays at the ˇθ(k)th marking change have terminated, and take as ˇθ(k + 1)
the smallest θ(l) such that θ(l) ≥ˇν(k). If there are no ongoing delays at
the ˇθ(k)th marking change, take as ˇθ(k + 1) the smallest θ(l) such that
θ(l) > ˇθ(k). For k = 0, take as ˇθ(1) the smallest θ(l) such that θ(l) ≥K.
To complete the construction, set ˇγ(0) = 0 and
ˇγ(k) = inf

j > ˇγ(k−1): α(j−1) < ˇθ(m) ≤α(j) for some m ≥0

(2.55)

420
9. Colored Stochastic Petri Nets
for k ≥1. Denote by δk (k ≥1) the number of delays that start during the
interval [ζθ(k−1), ζθ(k)) and set τk = ζθ(k) −ζθ(k−1).
Theorem 2.56. Let { Dj : j ≥0 } be a sequence of delays determined from
the underlying chain of a marking process using the method of start vec-
tors. Suppose that there exists a recurrent single state (¯s, ¯u) and that the
conditions in (2.52)–(2.54) hold. Then
(i) The random indices { ˇγ(k): k ≥0 } deﬁned by (2.55) form a sequence
of od-equilibrium points for { Dj : j ≥0 }.
(ii) The random indices { ˇγ(k): k ≥0 } also form a sequence of regen-
eration points for { Dj : j ≥0 }, provided that there are no ongoing
delays at the θ(k)th marking change for k ≥0.
(iii) The cycle sum ˇY1(|f|) = 	ˇγ(1)−1
j=ˇγ(0) |f(Dj)| has ﬁnite rth moment for
any real-valued function f that is polynomially dominated to degree b
(where r, b ≥1), provided that Eµ [δrp
1 ] < ∞and Eµ[τ rbq
1
] < ∞for
nonnegative real numbers p and q with p−1 + q−1 = 1.
Under the conditions of Theorem 2.56, both the extended regenerative
method for delays (as in Section 8.2.2) and the multiple-runs method (as
in Section 8.2.3) can be used to obtain strongly consistent point estimates
and asymptotic conﬁdence intervals.
Remark 2.57. Observe that there is no need for an analog of the condition in
(2.6) of Chapter 8, because there is only one possible new marking whenever
the current marking is the single state (¯s, ¯u) and transition ¯e ﬁres in color
¯ı.
Limiting Average Delays
Under appropriate conditions, the limiting average delay
r = lim
n→∞
1
n
n−1

j=0
Dj
exists a.s., and estimates for r can be obtained without measuring the
lengths of individual delay intervals. Recall that ψ(s, u) is the length of
the start vector when the marking is s. Denote by nα(s′, u′; s, u, E∗) the
length of the vector iα(s′, u′; s, u, E∗). Thus nα(s′, u′; s, u, E∗) is the num-
ber of newly started delays whenever the clocks corresponding to the (tran-
sition, color) pairs in a set E∗run down to 0 simultaneously and trigger
a marking change from (s, u) to (s′, u′). When E∗= { (e∗, i∗) } for some
(e∗, i∗) ∈E(s, u), we often write nα(s′, u′; s, u, e∗, i∗) for nα(s′, u′; s, u, E∗).
As before, we assume that clocks for timed transitions never run down to

9.2 Stability and Simulation
421
0 simultaneously. Set
Zk =
 ζθ(k)
ζθ(k−1)
ψ

X(t), Y (t)

dt =
θ(k)−1

n=θ(k−1)
ψ(Sn, Un)t∗(Sn, Un, Cn),
τk = ζθ(k) −ζθ(k−1),
and
δk =
θ(k)−1

n=θ(k−1)
nα(Sn, Un; Sn−1, Un−1, E∗
n−1)
for k ≥1. Since Zk, τk, and δk are determined by { (Sn, Un, Cn): θ(k−1) ≤
n < θ(k) } for k ≥1, it follows that the sequence { (Zk, τk, δk): k ≥1 }
consists of i.i.d. random vectors.
Theorem 2.58. Suppose that Eµ [Z1] < ∞and Eµ [δ1] < ∞and that
(2.52)–(2.54) hold. Then
lim
n→∞
1
n
n−1

j=0
Dj = Eµ [Z1]
Eµ[δ1] a.s..
It follows from the foregoing result that a version of the standard regen-
erative method can be used to obtain strongly consistent point estimates
and asymptotic conﬁdence intervals for the limiting average delay. This
algorithm is almost identical to Algorithm 2.34 in Chapter 8.
STS Methods for Delays
We now consider sts methods for estimating time-average limits of a se-
quence of delays { Dj : j ≥0 } determined from the underlying chain
{ (Sn, Un, Cn): n ≥0 } of a cspn using the method of start vectors. As with
ordinary spns, we give conditions on the cspn building blocks, start-vector
mechanism, and function f under which the output process { f(Dj): j ≥0 }
obeys an fclt. It follows that sts methods such as the method of batch
means can be used to obtain strongly consistent point estimates and asymp-
totic conﬁdence intervals for time-average limits and functions of time-
average limits.
Denote by X the set of all inﬁnite-length sequences (s(0), u(0), E(0), s(1),
u(1), E(1), . . .) such that p(s(k+1), u(k+1); s(k), u(k), E(k)) > 0 for k ≥0. For
an element x = (s(0), u(0), E(0), s(1), u(1), E(1), . . .) ∈X, recursively deﬁne a
sequence of vectors v0, v1, . . . by setting v0(x) equal to the vector of length
ψ(s(0), u(0)) whose components are all equal to −1, and then setting
v′
n(x) = Ins

vn−1(x), iα(s(n), u(n); s(n−1), u(n−1), E(n−1)), 0

,
v′′
n(x) = Del

v′
n(x), iβ(s(n), u(n); s(n−1), u(n−1), E(n−1))

,

422
9. Colored Stochastic Petri Nets
and
vn(x) = Per

v′′
n(x), iπ(s(n), u(n); s(n−1), u(n−1), E(n−1))

for n ≥1. Denote by ι(x) the smallest integer n such that vn(x) =
(0, 0, . . . , 0); if such an integer n does not exist, then set ι(x) = ∞.
Deﬁnition 2.59. A start-vector mechanism for a speciﬁed cspn is said to
be regular if
(i) there exist (s, u) ∈H −H′ and (e∗, i∗) ∈E(s, u) such that nα(s′, u′; s,
u, e∗, i∗) > 0, where (s′, u′) = g(s, u, e∗, i∗), and
(ii) there exists x = (s(0), u(0), E(0), s(1), u(1), E(1), . . .) ∈X such that
ι(x) < ∞.
Theorem 2.60. Let { Dj : j ≥0 } be a sequence of delays determined from
the underlying chain of a marking process by means of a regular start-vector
mechanism, and let f be a polynomially dominated ℜl-valued function de-
ﬁned on ℜ+ (l ≥1). Suppose that Assumption CPD holds. Then
(i) There exists a ﬁnite constant r(f) ∈ℜl such that
lim
n→∞
1
n
n−1

j=0
f(Dj) = r(f) a.s..
(ii) There exists an l×l matrix Q(f) such that Rn(f) ⇒Q(f)W (l) as n →
∞for any initial distribution µ, where ⇒denotes weak convergence
on Cl[0, 1], W (l) is a standard l-dimensional Brownian motion, and
Rn(f)(t) =
1
√n
 nt
0

f(D⌊u⌋) −r(f)

du
(2.61)
for 0 ≤t ≤1 and n ≥0.
The proof of Theorem 2.60 is similar to that of Corollary 3.9 in Chap-
ter 8. The idea is to show that there exists a sequence of od-regeneration
points that decompose the underlying chain { (Sn, Un, Cn): n ≥0 } into
o.d.s. cycles. Under Assumption CPD, and the regularity condition on the
start-vector mechanism, the output process { f(Dj): j ≥0 } inherits the
od-regenerative property. If, moreover, the function f is polynomially dom-
inated, then the sum of the process over a cycle has ﬁnite moments of all
orders. The conclusion of the theorem then follows from the limit theorems
for od-regenerative processes given in Section 7.2.1.
Thus, when the start-vector mechanism is regular and Assumption CPD
holds, the time-average limit r(f) of the output process { f(Dj): j ≥0 } is

9.3 Symmetric CSPNs
423
well deﬁned and ﬁnite for any polynomially dominated real-valued function
f. Moreover, we can obtain point estimates and conﬁdence intervals for r(f)
using sts methods. Fix f and set
¯Yn(t) = 1
n
 nt
0
f(D⌊u⌋) du
for 0 ≤t ≤1 and n ≥1. Also set
ˆrn = ¯Yn(1) = 1
n
n−1

j=0
f(Dj).
By Theorem 2.60(i), the point estimator ˆrn is strongly consistent for r(f).
To obtain asymptotic conﬁdence intervals for r(f), we proceed as in Sec-
tion 8.3.2. Deﬁne the set Ξ of mappings from C[0, 1] to ℜas in Sec-
tion 7.2.2 and ﬁx ξ ∈Ξ. Let σ(f) be a nonnegative constant such that
Rn(f) ⇒σ(f)W as n →∞, where Rn(f) is given by (2.61) and W is a
standard one-dimensional Brownian motion. The existence of σ(f) follows
from Theorem 3.9(ii) with l = 1, and we assume throughout that σ(f) > 0.
Finally, set ξn = ξ( ¯Yn). Arguing as in Section 7.2.2, we ﬁnd that
[ˆrn −ξnzp, ˆrn + ξnzp]
is an asymptotic 100p% conﬁdence interval for r(f), where p ∈(0, 1) and
zp is a positive constant such that P{ −zp ≤W(1)/ξ(W) ≤zp } = p.
As discussed previously, the foregoing estimation procedure reduces to the
method of batch means for an appropriate choice of the mapping ξ. We
can use a “jackknifed” extension of the batch-means method to estimate
functions of time-average limits of a sequence of delays—the development
is identical to that in Section 8.3.2. Also as discussed in Section 8.3.2, the
task of measuring individual delays can be avoided when the performance
measure of interest is the limiting average delay limn→∞(1/n) 	n−1
j=0 Dj.
9.3
Symmetric CSPNs
In this section we introduce the class of symmetric cspns and illustrate two
ways in which symmetry can be exploited in the context of regenerative
simulation.1
9.3.1
The Symmetry Conditions
Heuristically, a cspn is symmetric if its building blocks are invariant under
certain permutations of the colors. We formalize this notion as follows. For
1A third technique that involves “permuted regenerative estimators” is brieﬂy dis-
cussed in the notes at the end of the chapter.

424
9. Colored Stochastic Petri Nets
a permutation λ of the set U of colors and a subset ˜U ⊆U, write λ( ˜U) =
{ λ(i): i ∈U }. Also write E∗
λ =

 
e, λ(i)

: (e, i) ∈E∗
for E∗⊆E. For
(s, u) ∈H, denote by ξλ(s, u) the marking (s, u′) such that u′
j

λ(i)

= uj(i)
for i ∈U and 1 ≤j ≤L.
Deﬁnition 3.1. A set Λ of permutations of the set U is complete if
(i) ξλ(s, u) ∈H for λ ∈Λ and (s, u) ∈H, and
(ii) for each pair of markings (s, u), (s, u′) ∈H, there exists a permutation
λ ∈Λ such that (s, u′) = ξλ(s, u).
Deﬁnition 3.2. The symmetry conditions are said to hold for a cspn if
there exists a complete set Λ of permutations of the set U of colors such
that
(i) λ

UD(d)

= UD(d) and λ

UE(e)

= UE(e),
(ii) w−(e, i, d, l) = w−
e, λ(i), d, λ(l)

and w+(e, i, d, l) = w+
e, λ(i), d,
λ(l)

,
(iii) q(e′, i′; E∗) = q

e′, λ(i′); E∗
λ

, and
(iv) F( · ; e, i) = F

· ; e, λ(i)

for λ ∈Λ, (e, i), (e′, i′) ∈E, (d, l) ∈D, and E∗⊆E.
Example 3.3 (Symmetric machine repair).
Consider the system of Ex-
ample 1.1, but now suppose that, at the start of each repair, each of the
stopped machines is equally likely to be selected for repair. Also suppose
that the repair times for the N machines are stochastically identical in that
P { R1 ≤x } = P { R2 ≤x } = · · · = P { RN ≤x } for x ≥0. Similarly, sup-
pose that the lifetimes for the N machines are stochastically identical. The
cspn speciﬁcation for this system is as in Figure 9.1, but now the ﬁring
probabilities are given by
q(e2, i; E∗) =
1
|E∗|
for E∗⊆{ (e2, 1), (e2, 2), . . . , (e2, N) } and (e2, i) ∈E∗. The symmetry
conditions hold for this cspn, where Λ is the set of all permutations of
U = { 0, 1, . . . , N } such that λ(0) = 0.
Example 3.4 (Cyclic queues with feedback). Consider the cyclic queues
of Example 1.3, but now suppose that the jobs are stochastically identical:
F1,j = F2,j = · · · = FN,j for j = 1, 2. The cspn speciﬁcation for this system
is as in Figure 9.3. The symmetry conditions hold for this cspn, where Λ
is the set of all permutations of U = { 0, 1, . . . , N } such that λ(0) = 0.

9.3 Symmetric CSPNs
425
Example 3.5 (Symmetric token ring). Consider the token ring of Exam-
ple 1.2, but now suppose that there exist a positive constant R and positive
random variables A and L such that, for each port j,
• The time for the ring token to propagate to the next port is equal to
R.
• The successive times from the end of transmission until the arrival of
the next packet for transmission are i.i.d. as the random variable A.
• The successive times to transmit a packet are i.i.d. as the random
variable L.
The cspn speciﬁcation for this system is as in Figure 9.2. The symmetry
conditions hold for this cspn, where Λ is the set of all cyclic permutations
of U = { 1, 2, . . . , N }; that is, Λ = { λ1, λ2, . . . , λN }, where
λj(i) =

(i + j −1) mod N

+ 1.
9.3.2
Exploiting Symmetry: Shorter Cycle Lengths
It can be diﬃcult in practice to apply the standard regenerative method to
a speciﬁed cspn when the number of marking changes between successive
regeneration points is large—see Section 7.1 for a discussion in the context
of ordinary spns. Theorem 3.8 below can be used to alleviate this situation
when the cspn satisﬁes the symmetry conditions. The idea is to simulate
the marking process in independent, nonidentically distributed blocks; the
blocks are in general much shorter than the original regenerative cycles.
A similar idea can be applied when estimating long-run averages for a
sequence of delays. In this latter setting we can exploit symmetry in order
to obtain od-equilibrium cycles having shorter lengths than the usual cycles.
Simulation of the Marking Process
Recall from Section 9.2.2 that a marking (¯s, ¯u) is said to be a single state if
|E(¯s, ¯u)| = 1. Consider a cspn that has a recurrent single state (¯s, ¯u), and
suppose that the net behaves as if the marking is (¯s, ¯u) just before time 0.
Set θ′(0) = 0 and
θ′(k) = { n > θ′(k −1): (Sn−1, Un−1) = (¯s, ¯u) }
(3.6)
for k ≥1. It then follows from Theorem 2.14 that the random indices
{ θ′(k): k ≥0 } form a sequence of regeneration points for the process
{ (Sn, Un, Cn): n ≥0 }. Moreover, the random times

ζθ′(k) : k ≥0

form
a sequence of regeneration points for the process { Z(t): t ≥0 }. Under
appropriate regularity conditions, the standard regenerative method can

426
9. Colored Stochastic Petri Nets
therefore be used to obtain strongly consistent point estimates and asymp-
totic conﬁdence intervals for time-average limits of the form
˜r( ˜f) = lim
n→∞
1
n
n−1

j=0
˜f(Sj, Uj, Cj)
or
r(f) = lim
t→∞
1
t
 t
0
f

Z(t)

dt,
where ˜f and f are real-valued functions deﬁned on Υ and H −H′.
In the presence of symmetry, an alternative simulation method is avail-
able, based on Theorem 3.8 below. A vector of token counts ¯s is a sin-
gle state if |E(¯s, u)| = 1 for all u such that (¯s, u) ∈H—we require that
(¯s, u) ∈H for at least one u. Observe that if (¯s, ¯u) is a single state (in the
original sense) and the symmetry conditions hold, then ¯s is a single state
(in the modiﬁed sense). Denote by ˜ξλ(s, u, c) the state (s, u′, c′) ∈Υ such
that (s, u′) = ξλ(s, u) and c′
j

λ(i)

= cj(i) for i ∈U and 1 ≤j ≤M. A real-
valued function ˜f deﬁned on Υ is said to be symmetric with respect to a
complete set Λ of permutations if ˜f(s, u, c) = ˜f
˜ξλ(s, u, c)

for (s, u, c) ∈Υ
and λ ∈Λ. Similarly, a real-valued function f deﬁned on H −H′ is said to
be symmetric with respect to Λ if f(s, u) = f

ξλ(s, u)

for (s, u) ∈H −H′
and λ ∈Λ.
As before, consider a cspn that behaves as if the marking just before
time 0 is of the form (¯s, ¯u), where (¯s, ¯u) is a recurrent single state. If the
symmetry conditions hold, then ¯s also is a recurrent single state. Set θ(0) =
0 and
θ(k) = { n > θ(k −1): Sn−1 = ¯s }
(3.7)
for k ≥1.
Theorem 3.8. Suppose that there exists a single state (¯s, ¯u) such that
Pµ{ (Sn, Un) = (¯s, ¯u) i.o. } = 1. Also suppose that the symmetry conditions
hold with permutation set Λ. Then
(i) the random indices { θ(k): k ≥0 } form a sequence of regeneration
points for the process { ˜f(Sn, Un, Cn): n ≥0 }, where ˜f is any real-
valued function deﬁned on Υ that is symmetric with respect to Λ,
and
(ii) the random times { ζθ(k) : k ≥0 } form a sequence of regeneration
points for the process

f

Z(t)

: t ≥0

, where f is any real-valued
function deﬁned on H −H′ that is symmetric with respect to Λ.
Proof. Fix a symmetric function ˜f : Υ →ℜ. An argument similar to
the proof of Theorem 2.2 in Chapter 6 shows that the random indices
{ θ(k): k ≥0 } decompose sample paths of the chain { (Sn, Un, Cn): n ≥

9.3 Symmetric CSPNs
427
0 }, and hence of the output process { ˜f(Sn, Un, Cn): n ≥0 }, into indepen-
dent cycles. It remains only to show that the cycles of the output process
are identically distributed. To this end, set µ0( · ) = P

(¯s, ¯u, ¯c), · ), where
P is the transition kernel for the underlying chain and ¯c is an arbitrary but
ﬁxed clock-reading vector such that (¯s, ¯u, ¯c) ∈Υ—the probability measure
µ0 is well deﬁned because (¯s, ¯u) is a single state. Next, consider an arbitrary
element u ∈U L such that (¯s, u) ∈H, and set µ( · ) = P

(¯s, u, c), · ) for an
arbitrary but ﬁxed clock-reading vector c. It suﬃces to show that
Pµ0

 
θ(1), ˜f(S0, U0, C0), . . . , ˜f(Sθ(1), Uθ(1), Cθ(1))

∈A

= Pµ

 
θ(1), ˜f(S0, U0, C0), . . . , ˜f(Sθ(1), Uθ(1), Cθ(1))

∈A

for A ⊆∞
k=1 { k } × ℜk. Let λ ∈Λ be the unique permutation such that
ξλ(¯s, u) = (¯s, ¯u)—such a permutation exists because Λ is complete. It fol-
lows from the symmetry conditions that µ0(A) = µ(˜ξ−1
λ A) and
P
˜ξλ(˜s, ˜u, ˜c), A

= P

(˜s, ˜u, ˜c), ˜ξ−1
λ A

for all A ⊆Υ and (˜s, ˜u, ˜c) ∈Υ, where ˜ξ−1
λ A = { (s, u, c): ˜ξλ(s, u, c) ∈A }.
An argument similar to the proof of Theorem 2.10 in Chapter 4 then
shows that { (Sn, Un, Cn): n ≥0 } and { ˜ξλ(Sn, Un, Cn): n ≥0 } have the
same ﬁnite-dimensional distributions when the initial distributions of the
processes are µ0 and µ, respectively. Since each θ(k) is a stopping time
with respect to the underlying chain and is invariant under the permuta-
tion λ, it follows that the cycles

θ(1), (S0, U0, C0), . . . , (Sθ(1), Uθ(1), Cθ(1))

and

θ(1), ˜ξλ(S0, U0, C0), . . . , ˜ξλ(Sθ(1), Uθ(1), Cθ(1))

are identically distrib-
uted under respective initial distributions µ0 and µ. The ﬁrst assertion of
the theorem then follows from the symmetry of ˜f. The second assertion
follows from the ﬁrst by considering the symmetric function ˜f(s, u, c) =
f(s, u)t∗(s, u, c).
Under the conditions of Theorem 3.8, we can use the standard regener-
ative method—but with regeneration points replaced by the random in-
dices deﬁned by (3.7)—to obtain point estimates and conﬁdence inter-
vals for time-average limits ˜r( ˜f) and r(f) as given previously. The key
point is that the random indices { θ(k): k ≥0 } deﬁned by (3.7) are typ-
ically much more frequent than the original indices { θ′(k): k ≥0 } de-
ﬁned by (3.6). Moreover, a.s.-ﬁniteness can often be more easily estab-
lished for the former random indices. We emphasize that the random in-
dices { θ(k): k ≥0 } do not form a sequence of regeneration points for the
chain { (Sn, Un, Cn): n ≥0 }, and the random times { ζθ(k) : k ≥0 } do not
form a sequence of regeneration points for the process { Z(t): t ≥0 }. The
random indices { θ(k): k ≥0 } do, however, decompose the sample paths of
{ (Sn, Un, Cn): n ≥0 } into independent, nonidentically distributed blocks,
and similarly for the random times { ζθ(k) : k ≥0 }.

428
9. Colored Stochastic Petri Nets
Example 3.9 (Symmetric token ring).
For the cspn of Example 3.5,
suppose that we wish to estimate the long-run average utilization—that
is, we wish to estimate the time-average limit r(f) with f(s, u) = s3.
Take ¯s = (0, N, 0, 1, 0) and let ¯u be the unique element of U |¯s| such that
(¯s, ¯u) ∈H and u4(N) = 1. Thus, whenever the marking is (¯s, ¯u), the ring
token is propagating to port 1 and each port has a packet awaiting transmis-
sion. This marking is a recurrent single state and, under appropriate mo-
ment conditions, the standard regenerative method can be used to obtain
point estimates and conﬁdence intervals for r(f). The regeneration points
{ ζθ′(k) : k ≥0 } correspond to the successive times at which port 1 observes
the ring token with each port having a packet awaiting transmission. Ob-
serve that the function f is symmetric, so that, by Theorem 3.8, we can
also estimate r(f) based on simulation of the marking process in indepen-
dent, nonidentically distributed blocks. The random times { ζθ(k) : k ≥0 }
that demarcate these blocks correspond to the successive times at which
some port observes the ring token with each port having a packet awaiting
transmission. These random times are about N times as frequent as the
original regeneration points.
Remark 3.10. The foregoing results can be extended to more general types
of regenerative structure as in Theorem 2.14, for example.
Simulation of Delays
Time-average limits for a sequence of delays in a symmetric cspn can also
be estimated by decomposing the sample paths of the underlying chain into
independent, nonidentically distributed blocks. This decomposition leads
to od-equilibrium points for the output process { f(Dj): j ≥0 } that are
more frequent than the usual od-equilibrium points. The idea is to impose
symmetry conditions not only on the cspn building blocks, but also on
the associated start-vector mechanism. In the following deﬁnition we set
E∗
λ =

 
e, λ(i)

: (e, i) ∈E∗
for E∗⊆E as before.
Deﬁnition 3.11. The extended symmetry conditions are said to hold for a
cspn if there exists a complete set Λ of permutations of the set U of colors
such that the symmetry conditions of Deﬁnition 3.2 hold and, moreover,
(i) ψ(s, u) = ψ

ξλ(s, u)

,
(ii) iα(s′, u′; s, u, E∗) = iα

ξλ(s′, u′); ξλ(s, u), E∗
λ

,
(iii) iβ(s′, u′; s, u, E∗) = iβ

ξλ(s′, u′); ξλ(s, u), E∗
λ

, and
(iv) iπ(s′, u′; s, u, E∗) = iπ

ξλ(s′, u′); ξλ(s, u), E∗
λ

for λ ∈Λ, E∗⊆E(s, u), and (s, u), (s′, u′) ∈H.

9.3 Symmetric CSPNs
429
We consider a sequence of delays { Dj : j ≥0 } deﬁned for a speciﬁed
cspn using the method of start vectors and satisfying the regularity con-
ditions in (2.52)–(2.54). Suppose that there exists a recurrent single state
(¯s, ¯u), and deﬁne a sequence of regeneration points { θ′(k): k ≥0 } for
the marking process as in (3.6). As in Section 9.2.5, deﬁne a subsequence
{ ˇθ′(k): k ≥0 } of the regeneration points so that a delay that starts in
one of the resulting longer cycles terminates before the end of the next
such cycle. Then deﬁne a sequence of random indices { ˇγ′(k): k ≥0 } as in
(2.55): ˇγ′(0) = 0 and
ˇγ′(k) = inf

j > ˇγ′(k −1): α(j −1) < ˇθ′(m) ≤α(j) for some m ≥0

.
It follows from Theorem 2.56 that the random indices { ˇγ′(k): k ≥0 } form
a sequence of od-equilibrium points for the process { Dj : j ≥0 } and, more-
over, form a sequence of regeneration points for { Dj : j ≥0 } if there are no
ongoing delays at the θ′(k)th marking change for k ≥0. We can then use
the extended regenerative method for delays or the multiple-runs method
to obtain strongly consistent point estimates and asymptotic conﬁdence
intervals for time-average limits.
When the cspn and start-vector mechanism are symmetric, we can apply
the foregoing estimation techniques using od-equilibrium points { ˇγ(k): k ≥
0 } that are more frequent than the points { ˇγ′(k): k ≥0 }. The idea is to
deﬁne a sequence of blocking points { θ(k): k ≥0 } for the underlying chain
as in (3.7). Then, in the usual manner, deﬁne a subsequence

 ˇθ(k): k ≥0

of the blocking points so that a delay that starts in one of the cycles demar-
cated by the points { ζˇθ(k) : k ≥0 } always terminates before the end of the
next such cycle. Finally, deﬁne a sequence of random indices { ˇγ(k): k ≥0 }
as in (2.55): ˇγ(0) = 0 and
ˇγ(k) = inf

j > ˇγ(k−1): α(j−1) < ˇθ(m) ≤α(j) for some m ≥0

(3.12)
for k ≥1. This procedure is justiﬁed by the following result.
Theorem 3.13. Let { Dj : j ≥0 } be a sequence of delays determined from
the underlying chain of a marking process using the method of start vectors.
Suppose that there exists a recurrent single state ¯s and that the conditions
in (2.52)–(2.54) hold. Also suppose that the extended symmetry conditions
hold with permutation set Λ. Then
(i) the random indices { ˇγ(k): k ≥0 } deﬁned by (3.12) form a sequence
of od-equilibrium points for { Dj : j ≥0 }, and
(ii) the random indices { ˇγ(k): k ≥0 } also form a sequence of regenera-
tion points for { Dj : j ≥0 }, provided that there are no ongoing delays
at the θ(k)th marking change for k ≥0.
The proof of Theorem 3.13 is similar to the proof of Theorem 3.8. The
idea is to mimic the proof of Theorem 2.8 in Chapter 8 to show that

430
9. Colored Stochastic Petri Nets
the random indices { ˇγ(k): k ≥0 } decompose sample paths { Dj : j ≥0 }
into one-dependent cycles. We then use an argument as in the proof of
Theorem 3.8 to show that the cycles are identically distributed under the
extended symmetry conditions.
Example 3.14 (Symmetric token ring).
For the cspn of Example 3.5,
consider the delay intervals from whenever a packet arrives at a port for
transmission until the end of transmission of the packet. Suppose that
we wish to estimate time-average limits of the sequence of delays for all
ports. The method of start vectors can be used to specify and measure
individual delays in the cspn of Figure 9.2. The start vector Vn records
the arrival time for each packet awaiting or under transmission at time
ζn. A start corresponding to a packet at port i appears to the left of a
start corresponding to a packet at port j if and only if, at time ζn, the next
observation of the ring token by port i will occur before the next observation
by port j. It follows that if a transmission by port i is underway at time
ζn, then the start corresponding to the packet at port i appears as the
rightmost component of the start vector Vn.
To formally specify the start-vector mechanism, we need to introduce
some notation. First, let d(i, j) be the clockwise “distance” from port i to
port j:
d(i, j) =

j −i
if i ≤j;
N −(i −j)
if i > j.
Next, denote by n(s, u) the next port to observe the ring token when the
marking is (s, u):
n(s, u) =

i such that u3(i −1) = 1
if s3 = 1;
i such that u4(i −1) = 1
if s4 = 1.
Also let I(s, u) = u2

n(s, u)

be the indicator variable that equals 1 if the
next port to observe the ring token has a packet awaiting transmission and
equals 0 otherwise. Finally, denote by p(j) = p(j; s, u) the index of the port
that corresponds to the jth component of the start vector, and set
j(s, u, i∗) = max

j : d

n(s, u), p(j)

< d

n(s, u), i∗ 
,
where we take j(s, u, i∗) = 0 if the maximization is over an empty set. In
terms of this notation, set ψ(s, u) = s2 + s3,
iα(s′, u′; s, u, e∗, i∗) =

j(s, u, i∗)

if e∗= e1;
∅
otherwise,
iβ(s′, u′; s, u, e∗, i∗) =

ψ(s, u)

if e∗= e2;
∅
otherwise,

9.3 Symmetric CSPNs
431
and
iπ(s′, u′; s, u, e∗, i∗) =

2, 3, . . . , ψ(s, u), 1

if e∗= e3 and I(s, u) = 1;
∅
otherwise
for (s, u), (s′, u′) ∈H and (e∗, i∗) ∈E(s, u).
This cspn satisﬁes the extended symmetry conditions, so that a sequence
of od-equilibrium points { ˇγ(k): k ≥0 } for the process { Dj : j ≥0 } can
be constructed based on the random indices { θ(k): k ≥0 } deﬁned in
Example 3.9. Indeed, the random indices { ˇγ(k): k ≥0 } form a sequence
of regeneration points for { Dj : j ≥0 } because there are no ongoing delays
at any point ζθ(k). The regenerative cycles are shorter by roughly a factor
of N than the “naive” cycles based on the random indices { θ′(k): k ≥0 }
deﬁned in Example 3.9.
Observe that the start-vector mechanism given here diﬀers from that
given in Example 1.7 in Chapter 8. If we were to use the latter start-
vector mechanism (adapted to the cspn setting), the extended symmetry
conditions would not hold, because, for example,
iα(s′, u′; s, u, E∗) ̸= iα

ξλ(s′, u′); ξλ(s, u), E∗
λ

.
9.3.3
Exploiting Symmetry: Increased Eﬃciency
Suppose that, for the token ring model of Example 3.14, we wish to estimate
the long-run average delay between the arrival of a packet at port 1 for
transmission and the end of transmission of the packet. We can observe the
successive delays for port 1 and use the regenerative method to obtain point
estimates and conﬁdence intervals. If the cspn and start-vector mechanism
are symmetric, however, it is intuitively plausible that a valid estimate
can also be obtained from observation of the combined delays for all the
ports. Indeed, one might expect the resulting estimation procedure to be
statistically more eﬃcient than the ﬁrst approach, because more delays
are observed for a ﬁxed simulation run length. In this subsection we give
conditions under which symmetry in a cspn can be exploited in this manner
to yield more eﬃcient estimates.
Associating Colors with Delays
We associate a color with each simulated delay by slightly modifying the
previously described start-vector mechanism for cspns. Denote by ˜U (⊆U)
the set of possible colors for the delays. Each component of the start vector
is no longer simply a start ζ, but a pair (ζ, i), where i ∈˜U. The color
i is assigned when the corresponding delay starts and remains ﬁxed until
the delay terminates; we denote by Cj the color associated with delay Dj.
To eﬀect this modiﬁcation, we redeﬁne iα(s′, u′; s, u, E∗) to be a vector of

432
9. Colored Stochastic Petri Nets
(index, color) pairs, that is, a vector of elements of { 0, 1, . . . , ψ(s, u) } × ˜U.
For example, suppose that the clocks associated with the (transition, color)
pairs in set E∗simultaneously run down to 0 and trigger a marking change
from (s, u) to (s′, u′) and that this is the nth marking change. Also suppose
that ζn = 5.3,
Vn−1 =

(3.2, 6), (1.2, 4), (4.8, 2)

,
iα(s′, u′; s, u, E∗) =

(0, 7), (2, 9)

,
iβ(s′, u′; s, u, E∗) = (5),
and iπ(s′, u′; s, u, E∗) = ∅. Finally, suppose that no delays have terminated
so far. Then, using notation as in Section 8.1.2, we have
V ′
n =

(5.3, 7), (3.2, 6), (1.2, 4), (5.3, 9), (4.8, 2)

,
V ′′
n =

(5.3, 7), (3.2, 6), (1.2, 4), (5.3, 9)

,
and Vn = V ′′
n ; the latter equality follows because the start-vector compo-
nents are not permuted. This marking change corresponds to the termi-
nation B2—recall that we enumerate delays D0, D1, . . . in start order—so
that D2 = 5.3 −4.8 = 0.5, and the associated color is C2 = 2.
We now deﬁne a strengthened version of the extended symmetry condi-
tions. For a vector iα =

(i1, j1), (i2, j2), . . . , (im, jm)

, and a permutation
λ of the colors in U, set
iλ
α =

i1, λ(j1)

,

i2, λ(j2)

, . . . ,

im, λ(jm)

.
Deﬁnition 3.15. The expanded symmetry conditions are said to hold for
a cspn if there exists a complete set Λ of permutations of the set U of
colors such that (a) for each i, j ∈˜U, there exists λ ∈Λ such that λ(i) = j
and (b) the extended symmetry conditions in Deﬁnition 3.11 hold with the
condition in (ii) modiﬁed to read
(ii′) iλ
α(s′, u′; s, u, E∗) = iα

ξλ(s′, u′); ξλ(s, u), E∗
λ

.
An Estimation Procedure That Ignores Symmetry
Consider a sequence { (Dj, Cj): j ≥0 } deﬁned for a speciﬁed cspn us-
ing the method of start vectors and satisfying the regularity conditions in
(2.52)–(2.54). For ease of exposition, we assume that the color set U =
{ 1, 2, . . . , N } is enumerated such that the set of colors ˜U associated with
the delays is ˜U = { 1, 2, . . . , N0 } for some N0 ≤N. For 1 ≤q ≤N0,
let Dq
1, Dq
2, . . . be an enumeration, in start order, of those delays in the se-
quence { Dj : j ≥0 } that have an associated color equal to q. Suppose that
there are inﬁnitely many delays of each color and that we are interested in

9.3 Symmetric CSPNs
433
Figure 9.5. Cycles for delays in a cspn (two colors).

434
9. Colored Stochastic Petri Nets
estimating a time-average limit of the form
r(f) = lim
n→∞
1
n
n−1

j=1
f(D1
j),
(3.16)
where f is a speciﬁed real-valued function.
We assume that there exists a recurrent single state (¯s, ¯u) with E(¯s, ¯u) =
{ (¯e,¯ı) } for some (¯e,¯ı) ∈E and that the net behaves as if, at time 0, the
marking is (¯s, ¯u) and transition ¯e ﬁres in color ¯ı. Recall that g is the new-
marking function, and suppose that either
ψ(¯s, ¯u) = 1
and
ψ

g(¯s, ¯u, ¯e,¯ı)

= 0
(3.17)
or
ψ(¯s, ¯u) = 0
and
ψ

g(¯s, ¯u, ¯e,¯ı)

= 1.
(3.18)
Set θ1(0) = 0 and
θ1(k) =

n > θ1(k −1): (Sn−1, Un−1) = (¯s, ¯u)

(3.19)
for k ≥1. The conditions in (3.17) and (3.18) ensure that there are no
ongoing delays at the θ1(k)th marking change for k ≥0 and that each
θ1(k)-cycle contains at least one start.
We suppose throughout that the expanded symmetry conditions hold,
and ﬁrst present an estimation method for r(f) that does not try to ex-
ploit this symmetry. The method rests on Theorem 2.14, which implies
that the random indices { θ1(k): k ≥0 } form a sequence of regenera-
tion points for the chain { (Sn, Un, Cn): n ≥0 }, and the random times

ζθ1(k) : k ≥0

form a sequence of regeneration points for the marking
process { Z(t): t ≥0 }.
Using the regeneration points { θ1(k): k ≥0 }, we can deﬁne—in analogy
to (2.55)—a sequence of random indices

γ1(k): k ≥0

for the process
{ D1
j : j ≥0 }: γ1(0) = 0 and
γ1(k) = inf

j > γ1(k −1): α1(j −1) < θ1(m) ≤α1(j) for some m ≥0

for k ≥1, where

α1(k): k ≥0

are the start indices corresponding to
{ D1
j : j ≥0 }. It follows from Theorem 2.56 that these random indices
form a sequence of regeneration points for { D1
j : j ≥0 }—see Figure 9.5(b)
for an illustration of the various regenerative cycles when | ˜U| = 2. Theo-
rem 1.12 in Chapter 6 then implies that, under mild regularity conditions,
the quantity r(f) in (3.16) is well deﬁned and ﬁnite. Moreover, strongly
consistent point estimates and asymptotic conﬁdence intervals for r(f) can
be based on simulation of the cspn over a ﬁxed time interval [0, t]—we
focus on simulation until a ﬁxed time to facilitate comparison with other
estimation methods.

9.3 Symmetric CSPNs
435
Denote by m1(t) the number of delays { D1
j : j ≥0 } that terminate in
the interval [0, t], and set
¯r1(t) =
1
m1(t)
m1(t)

j=1
f(D1
j).
Also set
Y 1
k (f) =
γ1(k)−1

j=γ1(k−1)
f(D1
j),
δ1
k = γ1(k) −γ1(k −1),
and
τ 1
k = ζθ1(k) −ζθ1(k−1)
for k ≥1. Finally, set
σ1(f) = Var1/2
µ

Y 1
1 (f) −r(f)δ1
1

.
Estimation of r(f) is based on the following result.
Theorem 3.20. Suppose that Eµ[τ 1
1 ] < ∞, that δ1
1 and Y 1
k (|f|) each have
ﬁnite second moment, and that (2.52)–(2.54) hold. Then limt→∞¯r1(t) =
r(f) a.s. and
t1/2
¯r1(t) −r(f)

e1(f)
⇒N(0, 1)
at t →∞, where
e1(f) = E1/2
µ
[τ 1
1 ]σ1(f)
Eµ[δ1
1]
.
Proof. The ﬁrst assertion of the theorem follows from Theorem 1.12 in
Chapter 6 and the fact that limt→∞m1(t) = ∞a.s.; the latter convergence
is a consequence of (2.53) and the expanded symmetry conditions. To prove
the second assertion, use essentially a discrete-time analog of the proof of
Theorem 3.51 in Chapter 6 to show that
m1/2
m−1 	m
j=1 f(D1
j) −r(f)

σ1(f)/E1/2
µ
[δ1
1]
⇒N(0, 1)
(3.21)
at m →∞. It is straightforward to show that
lim
t→∞
m1(t)
t
= Eµ[δ1
1]
Eµ[τ 1
1 ] a.s.

436
9. Colored Stochastic Petri Nets
using, for example, the regenerative structure of the marking process to-
gether with Theorem 2.14 in Chapter 3. An argument similar to the proof
of Theorem 3.18 in Chapter 6 then shows that m can be replaced by m1(t)
in (3.21), so that

m1(t)
1/2
¯r1(t) −r(f)

σ1(f)/E1/2
µ
[δ1
1]
⇒N(0, 1)
at t →∞. To complete the proof, write
t1/2
¯r1(t) −r(f)

e1(f)
=
)
t
m1(t) · Eµ[δ1
1]
Eµ[τ 1
1 ]
*1/2 
m1(t)
1/2
¯r1(t) −r(f)

σ1(f)/E1/2
µ
[δ1
1]
and apply Slutsky’s theorem.
Thus the estimator ¯r1(t) is strongly consistent for r(f). Moreover, we can
obtain asymptotic conﬁdence intervals in the usual manner. Speciﬁcally,
denote by K1(t) the number of regeneration points

ζθ1(k) : k ≥1

that
lie in the interval (0, t], and set
¯τ 1(t) =
1
K1(t)
K1(t)

k=1
τ 1
k,
¯δ1(t) =
1
K1(t)
K1(t)

k=1
δ1
k,
and
s1(t) =
)
1
K1(t) −1
K1(t)

k=1

Y 1
k (f) −¯r(t)τ 1
k
2
*1/2
.
The estimator
ˆe1(t) =

¯τ 1(t)
1/2s1(t)
¯δ1(t)
is strongly consistent for e1(f), and
J1(t; p) =
!
¯r1(t) −zp ˆe1(t)
√
t
, ¯r1(t) + zp ˆe1(t)
√
t
"
is an asymptotic 100p% conﬁdence interval for r(f), where zp is the (1+p)/2
quantile of the standard normal distribution.

9.3 Symmetric CSPNs
437
An Estimation Procedure That Exploits Symmetry
We now give an alternative estimation procedure that exploits symmetry
(in the foregoing expanded sense) of a cspn model. This procedure not only
uses shorter cycles than the estimation procedure outlined above, but also
is statistically more eﬃcient. The idea is to exploit the fact—which is clear
from symmetry considerations and not hard to prove rigorously—that
lim
n→∞
1
n
n−1

j=0
f(Dj) = r(f) a.s.,
where r(f) is deﬁned by (3.16), so that the time-average limit for the com-
bined sequence of delays of all colors coincides with the time-average limit
for the sequence of delays of color 1.
First, deﬁne a sequence { θ(k): k ≥0 } as in (3.7). Then, using these
blocking points, deﬁne a sequence of random indices { γ(k): k ≥0 } for the
combined sequence { Dj : j ≥0 } of delays of all colors: γ(0) = 0 and
γ(k) = inf

j > γ(k −1): α(j −1) < θ(m) ≤α(j) for some m ≥0

for k ≥1. Since we assume that either (3.17) or (3.18) holds, it fol-
lows from Theorem 3.13 that the random indices { γ(k): k ≥0 } form
a sequence of regeneration points for the process { Dj : j ≥0 }—see Fig-
ure 9.5(a) for an illustration of the cycles when | ˜U| = 2. In the ﬁgure the
solid vertical lines correspond to time points in the set

ζθ(k) : k ≥0

∩

ζθ1(k) : k ≥0

and the dashed vertical lines correspond to time points in
the set

ζθ(k) : k ≥0

−

ζθ1(k) : k ≥0

.
Theorem 3.22 below leads to an estimation procedure based on simula-
tion of the cspn over a ﬁxed time interval [0, t]. Denote by m(t) the number
of delays { Dj : j ≥0 } that terminate in the interval (0, t], and set
¯r(t) =
1
m(t)
m(t)

j=1
f(Dj).
Also set
Yk(f) =
γ(k)−1

j=γ(k−1)
f(Dj),
δk = γ(k) −γ(k −1),
and
τk = ζθ(k) −ζθ(k−1)
for k ≥1. Finally, set
σ2(f) = Varµ [Y1(f) −r(f)δ1] .

438
9. Colored Stochastic Petri Nets
Theorem 3.22. Suppose that Eµ[τ1] < ∞, that δ1 and Yk(|f|) each have
ﬁnite second moment, and that (2.52)–(2.54) hold. Then limt→∞¯r(t) =
r(f) a.s. and
t1/2
¯r(t) −r(f)

e(f)
⇒N(0, 1)
(3.23)
at t →∞, where
e(f) = E1/2
µ
[τ1]σ(f)
Eµ[δ1]
.
The proof of Theorem 3.22 is almost identical to that of Theorem 3.20.
Theorem 3.22 asserts that the estimator ¯r(t) is strongly consistent for
r(f); the theorem also leads to a conﬁdence interval for r(f). Denote by
K(t) the number of regeneration points

ζθ(k) : k ≥1

that lie in the in-
terval (0, t], and set
¯τ(t) =
1
K(t)
K(t)

k=1
τk,
¯δ(t) =
1
K(t)
K(t)

k=1
δk,
and
s(t) =
)
1
K(t) −1
K(t)

k=1

Yk(f) −¯r(t)τk
2
*1/2
.
The estimator
ˆe(t) =

¯τ(t)
1/2s(t)
¯δ(t)
is strongly consistent for e(f), and
J(t; p) =
!
¯r(t) −zp ˆe(t)
√
t
, ¯r(t) + zp ˆe(t)
√
t
"
is an asymptotic 100p% conﬁdence interval for r(f).
Comparison of Estimation Procedures
We now compare the two estimation procedures described above. Analo-
gously to the discussion in Chapter 8, for a ﬁxed value of p ∈(0, 1) we take
the asymptotic relative eﬃciency (are) of the two procedures to be the
limiting ratio of the lengths of the 100p% conﬁdence intervals for r(f) as
the simulated time becomes large. Denote by I1(t; p) and I(t; p) the lengths
of the intervals J1(t; p) and J(t; p), and observe that
lim
t→∞
I(t; p)
I1(t; p) = e(f)
e1(f) a.s.

9.3 Symmetric CSPNs
439
for all p ∈(0, 1). The next result asserts that the are is less than or equal
to 1, so that the second of the two estimation methods—which exploits
symmetry in the cspn model—is always at least as eﬃcient as the ﬁrst
estimation method.
Theorem 3.24. Under the assumptions of this section, e(f) ≤e1(f) for
all functions f such that both quantities are well deﬁned.
To prove Theorem 3.24, we need the following result for “cumulative
processes.” A real-valued stochastic process { Y (t): t ≥0 } is a cumulative
process if
1. There exists a sequence T0 = 0, T1, T2, . . . of increasing a.s. ﬁnite
random times such that the sequence { (Yn, τn): n ≥1 } consists of
i.i.d. random pairs, where Yn = Y (Tn)−Y (Tn−1) and τn = Tn−Tn−1
for n ≥1.
2. The process { Y (t): t ≥0 } is, with probability 1, of bounded varia-
tion over every ﬁnite interval—see Deﬁnition 1.6 in the Appendix.
If { X(t): t ≥0 } is a regenerative process with piecewise-constant sample
paths and Y (t) =
 t
0 f

X(u)

du for t ≥0 and some real-valued function
f, then { Y (t): t ≥0 } is a cumulative process.
Lemma 3.25. Let { Y (t): t ≥0 } be a cumulative process and set σ2 =
Var [Y1]. Suppose that E [Y1] = 0, σ2 < ∞and that E [τ1] < ∞. Then
lim
t→∞
Var [Y (t)]
t
=
σ2
E [τ1].
Although a complete proof of the lemma uses techniques from renewal
theory (see Section A.2.3) and is beyond the scope of the current dis-
cussion, the following argument shows why the result is plausible. Let
N(t) = sup { n: Tn ≤t } for t ≥0. Using Theorem 2.9(ii) in Chapter 3
together with the slln for i.i.d. random variables, it is easy to show that
limt→∞N(t)/t = 1/E [τ1] a.s.. In light of this result, it is plausible that
lim
t→∞
E [N(t)]
t
→
1
E [τ1],
(3.26)
and the elementary renewal theorem (Proposition 2.13 in the Appendix)
asserts that the convergence in (3.26) does indeed hold. Setting Sn =
	n
k=1 Yk, we can write
Var [Y (t)]
t
= Var

SN(t)

E [N(t)]
· E [N(t)]
t
+ r(t)
t
(3.27)
for t ≥0, where
r(t) = Var

Y (t) −SN(t)

+ 2 Cov

SN(t), Y (t) −SN(t)

.

440
9. Colored Stochastic Petri Nets
Since { Yn : n ≥1 } is an i.i.d. sequence, we have Var [Sn] = nσ2 for n ≥1.
By Wald’s second moment identity [Proposition 1.19(ii) in the Appendix]
we can replace the deterministic index n by the random index N(t) to
obtain Var

SN(t)

= E [N(t)] σ2. Substituting this expression into (3.27),
taking limits, and applying (3.26), we obtain
lim
t→∞
Var [Y (t)]
t
=
σ2
E [τ1] + lim
t→∞
r(t)
t .
Observe that, by the Cauchy–Schwarz inequality,
|r(t)| ≤Var

Y (t) −SN(t)

+ 2Var1/2 
Y (t) −SN(t)

Var1/2 
SN(t)

.
Because the sample paths of { Y (t): t ≥0 } are well behaved, we do not
expect the variance of Y (t) −SN(t) to increase systematically, and so it is
plausible that Var

Y (t) −SN(t)

/t →0 as t →∞. This latter convergence
can indeed be established, and it follows that limt→∞r(t)/t = 0.
Proof of Theorem 3.24. Fix a function f, and observe that both the
numerator on the left side of (3.23) and the limit N(0, 1) are independent
of the particular choice of cycle boundaries for the marking process, and
hence of the choice of cycles for the process { Dj : j ≥0 }. It follows easily
that e(f) is independent of the choice of cycle boundaries. In particular,
we have e(f) = ˜e(f), where the latter quantity is deﬁned as follows. Recall
the sequence of regeneration points { θ1(k): k ≥0 } for the underlying
chain deﬁned previously via (3.19). Using these points, deﬁne a sequence
of random indices { ˜γ(k): k ≥0 } for the process2 { Dj : j ≥0 } in what is,
by now, the usual way: ˜γ(0) = 0 and
˜γ(k) = inf

j > ˜γ(k −1): α(j −1) < θ1(m) ≤α(j) for some m ≥0

for k ≥1—see Figure 9.5(c). Set
˜Y k(f) =
˜γ(k)−1

j=˜γ(k−1)
f(Dj),
˜δk = ˜γ(k) −˜γ(k −1),
and
˜τk = τ 1
k = ζθ1(k) −ζθ1(k−1)
2In contrast, the random indices

γ1(k): k ≥0

, though also speciﬁed using the
regeneration points { θ1(k): k ≥0 }, are deﬁned for the process { D1
j : j ≥0 } as in
Figure 9.5(b).

9.3 Symmetric CSPNs
441
for k ≥1, and then set
˜σ(f) =

Varµ [ ˜Y 1(f) −r(f)˜δ1]
1/2
and
˜e(f) = E1/2
µ
[˜τ1]˜σ(f)
Eµ[˜δ1]
.
Thus e(f) is based on cycles as in Figure 9.5(a), whereas ˜e(f) is based on
cycles as in Figure 9.5(c). Because e(f) = ˜e(f), it suﬃces to show that
˜σ(f) ≤N0 σ1(f)
(3.28)
and
Eµ [˜δ1] = N0Eµ

δ1
1

,
(3.29)
where, as before, N0 is the number of possible colors for the delays.
To establish (3.28), set
W(t) =
m(t)

j=1

f(Dj) −r(f)

for t ≥0. For 1 ≤q ≤N0, denote by mq(t) the number of delays { Dq
j : j ≥
0 } that terminate in the interval [0, t], and set
W q(t) =
mq(t)

j=1

f(Dq
j) −r(f)

for t ≥0. For each q, ﬁx a permutation λ ∈Λ such that λ(1) = q; the
existence of such a permutation follows from the expanded symmetry con-
ditions. Next, set (¯s, ¯uq) = ξλ(¯s, ¯u) and observe that, by the expanded
symmetry conditions, (¯s, ¯uq) is a single state. We can therefore deﬁne ran-
dom indices { θq(k): k ≥0 } and { γq(k): k ≥0 } in a manner completely
analogous to the deﬁnitions of { θ1(k): k ≥0 } and { γ1(k): k ≥0 }. In
Figure 9.5(a), for example, the vertical solid lines correspond to the time
points { ζθ1(k) : k ≥0 } and the vertical dashed lines correspond to the time
points { ζθ2(k) : k ≥0 }. We can also deﬁne quantities Y q
k (f), δq
k, τ q
k, σq(f),
and so forth. Using Lemma 3.25, we have
lim
t→∞
)Varµ [W(t)]
t
*1/2
=
˜σ(f)
E1/2
µ
[˜τ1]
=
˜σ(f)
E1/2
µ
[τ 1
1 ]
and, for each q,
lim
t→∞
)Varµ [W q(t)]
t
*1/2
=
σq(f)
E1/2
µ
[τ q
1 ]
=
σ1(f)
E1/2
µ
[τ 1
1 ]
,

442
9. Colored Stochastic Petri Nets
where the second equality follows by symmetry. Observe that W(t) =
	N0
q=1 W q(t) and apply the Cauchy–Schwarz inequality to obtain
Var1/2
µ
[W(t)] ≤
) N0

q=1
Varµ [W q(t)] +

p̸=q
Var1/2
µ
[W p(t)] Var1/2
µ
[W q(t)]
*1/2
=
N0

q=1
Var1/2
µ
[W q(t)] .
Dividing the leftmost and rightmost terms in the above inequality by t1/2
and then letting t →∞yields (3.28).
The equality in (3.29) is established in a similar manner. As in the proof
of Theorem 3.20, we have
lim
t→∞
m(t)
t
= Eµ[˜δ1]
Eµ[˜τ1] = Eµ[˜δ1]
Eµ[τ 1
1 ]
and, for each q,
lim
t→∞
mq(t)
t
= Eµ[δq
1]
Eµ[τ q
1 ] = Eµ[δ1
1]
Eµ[τ 1
1 ],
where we have again used symmetry. Observe that
m(t) =
N0

q=1
mq(t)
for t ≥0. Dividing both sides of the above equality by t and then letting
t →∞yields (3.29).
The following example shows that the diﬀerence in eﬃciency between
the symmetric and nonsymmetric estimation methods can be signiﬁcant.
Example 3.30 (Symmetric token ring with ﬁxed-sized packets). Similarly
to Example 3.17 in Chapter 6, suppose that, for each port, the time to
transmit a package is a deterministic constant L and the time for the ring
token to propagate to the next port is a deterministic constant R. Also
suppose that the successive times from the end of transmission until the
arrival of the next packet for transmission are i.i.d. as an exponential ran-
dom variable with intensity q. Finally, suppose that we wish to estimate
the access time for port 1, that is, the time from when a packet arrives at
port 1 for transmission until the start of transmission of the packet.
Assuming that the system is modelled by a cspn as in Figure 9.2, we can
specify the sequence of access times for all ports using a start-vector mech-
anism very similar to that in Example 3.14. We modify this start-vector
mechanism as described at the beginning of this subsection and associate a
color with each delay—the color associated with a delay is the number of the

9. Notes
443
Table 9.3. Simulation Results for Symmetric Token Ring with Fixed-Sized Packets
Number of Jobs
Access Time
are
4
0.5819±0.0005
0.6020
8
1.9549±0.0006
0.4123
12
3.5140±0.0005
0.3115
port at which the corresponding packet arrived. It is easy to show that the
expanded symmetry conditions hold, and we can estimate the access time
for port 1 using either of the two estimation methods described previously.
To this end, we deﬁne the sequences

θ1(k): k ≥0

and { θ(k): k ≥0 }
using the single state (¯s, ¯u) given in Example 3.9. Thus θ1(k) is the ran-
dom index of the kth marking change at which port 1 observes the ring
token with each port having a packet awaiting transmission and θ(k) is
the index of the kth marking change at which some port observes the ring
token with each port having a packet awaiting transmission.
Table 9.3 displays point estimates and 95% conﬁdence intervals for the
port 1 access time; these estimates were computed using the symmetric
estimation method. Also displayed is the estimate are—that is, the ra-
tio e(f)/e1(f)—for the symmetric and nonsymmetric estimation methods.
The parameter values used in the simulation are L = 0.3, R = 0.1, and
q = 1. Results are reported for several values of N, the number of ports.
All estimates are based on 104 cycles demarcated by the random times

ζθ1(k) : k ≥0

. As the total number of ports increases, the access time
for port 1 increases, which is to be expected. As can be seen from the right-
most column, the asymptotic conﬁdence-interval length for the symmetric
estimation method is signiﬁcantly shorter than the interval length for the
nonsymmetric method. The diﬀerence in eﬃciency between the methods
becomes increasingly pronounced as N increases. This trend also is to be
expected, since the symmetric estimation method observes roughly N times
as many delays as the nonsymmetric estimation method does.
Notes
The notion of associating colors with the tokens and transitions of an (or-
dinary) Petri net dates back to a paper by Jensen (1981). This work can
be viewed as a speciﬁc variation on the general theme of assigning “in-
scriptions” to the various components of a net model, thereby obtaining
a “high-level” Petri net; see, for example, the discussion in Genrich and
Lautenbach (1981). Zenie (1985) proposes augmenting the spn formalism
of Molloy (1981) with colors, Chiola, Bruno, and Demaria (1988) makes
a similar proposal in the setting of gspns, and Lin and Marinescu (1988)

444
9. Colored Stochastic Petri Nets
proposes “stochastic high-level Petri nets.” Our deﬁnition of cspns follows
Haas and Shedler (1993b).
With the exception of Haas and Shedler (1993b), the foregoing work em-
phasizes computation of reachability sets and exact computation of steady-
state probabilities for the marking process when all clock-setting distribu-
tion functions for timed transitions are exponential. The authors of these
papers provide techniques for aggregation of markings to reduce the com-
plexity of the computations; these techniques exploit various symmetries in
the net model. More recently, attention has focused on spns in which the
color mechanism has additional structure that facilitates automatic detec-
tion and exploitation of model symmetry. A notable example is provided
by the “stochastic well-formed colored nets” (swns) introduced by Chiola
et al. (1993). Gaeta and Chiola (1995) discuss methods for exploiting model
symmetry to eﬃciently generate sample paths of the marking process of an
swn; the authors provide techniques both for reducing the amount of work
needed to schedule or cancel the ﬁring of a transition and for reducing the
length of the “event list” of transitions currently scheduled to ﬁre. Chiola
(1995) has initiated an extension of the “recursion equation” approach to
the analysis and parallel simulation of nets—as in Baccelli et al. (1993)—to
the setting of swns.
The complaint processing system of Example 1.4 is based on an example
in van der Aalst (1998). The results in Section 9.3.3 are adapted from
Prisgrove and Shedler (1986). Lemma 3.25 is contained in Theorem 8 of
Smith (1955). As mentioned at the end of Chapter 6, discussions of renewal
theory can be found, for example, in the books of Asmussen (1987a), C¸inlar
(1975), Karlin and Taylor (1975), and Ross (1983).
Besides the methods discussed in Section 9.3, an additional technique
for exploiting symmetry can be found in the work of Calvin and Nakayama
(2000). Their methodology is applicable when the underlying chain of a
cspn is regenerative and the performance measure of interest is one of the
following:
• The variance of the reward earned over a regenerative cycle—for ex-
ample, the variance of the busy period in a single-server queue
• The variance constant of the process { ˜f(Sn, Un, Cn): n ≥0 }, where
˜f is a suitable reward function
• The reward earned before the chain hits a speciﬁed set—for example,
the mean time to failure
The idea is as follows. If there exists a sequence of regeneration points
for the underlying chain of the marking process and the symmetry con-
ditions hold, then there typically exist multiple sequences of regenera-
tion points—each sequence corresponds to some permutation of the colors.
Suppose that there are m such sequences, denoted Θ1, Θ2, . . . , Θm, with

9. Notes
445
Θi =

θi(0), θi(1), . . .

for 1 ≤i ≤m. Simulate a ﬁnite sample path that
corresponds to a ﬁxed number of regenerative cycles demarcated by the
regeneration points in Θ1. Starting with this sample path, generate a “per-
muted” sample path by ﬁrst permuting the segments of the sample path
demarcated by the Θ1-regeneration points, then permuting the segments
of the resulting path demarcated by the Θ2-regeneration points, and so
forth, for a total of m permutation steps. Conceptually, we can obtain an
estimator of the performance measure of interest by generating all pos-
sible permuted paths, computing the value of the standard regenerative
estimator of the speciﬁed performance measure over each such path, and
then averaging these values. Calvin and Nakayama (2000) show how to
compute such a “permuted regenerative estimator” estimator eﬃciently—
without actually materializing all the permuted paths. The authors also
show that for any ﬁnite-length simulation the mean-square error (mse) of
the permuted regenerative estimator is less than or equal to the mse of
the standard regenerative estimator (applied to the original sample path).
Finally, the authors also show that the permuted regenerative estimator
is strongly consistent, and they obtain a clt that permits construction of
asymptotic conﬁdence intervals.

This page intentionally left blank 

Appendix A
Selected Background
In the following sections we summarize various results on probability and
stochastic processes that are used in the text. The notes at the end of the
Appendix give references for further reading.
A.1
Probability, Random Variables, Expectation
A.1.1
Probability Spaces
We start with a set Ω, called the sample space, that represents the possible
elementary outcomes of a probabilistic experiment. A subset A ⊆Ωis
called an event—if the outcome of the experiment is an element of A, then
we say that “event A has occurred.” Associated with Ωis a σ-ﬁeld F of
events, that is, a collection F of events such that
1. ∅∈F and Ω∈F.
2. Ac ∈F whenever A ∈F, where Ac = Ω−A = { ω ∈Ω: ω ̸∈A }.
3. ∞
i=1 Ai ∈F whenever A1, A2, . . . ∈F.
A probability measure P is a nonnegative real-valued function on F that
satisﬁes P(∅) = 0, P(Ω) = 1, and
P
)
n
An
*
=

n
P(An)

448
Appendix A. Selected Background
whenever A1, A2, . . . form a ﬁnite or countably inﬁnite collection of dis-
joint sets in F. The triple (Ω, F, P) is called a probability space.1 The
pair (Ω, F) is called a measurable space, and the elements of F are called
measurable sets or measurable events. In general, a σ-ﬁeld G (⊆F) can
be interpreted as a speciﬁed “body of information” about the underlying
probabilistic experiment—being “given” the information in G means being
told for each A ∈G whether or not event A has occurred. Thus F repre-
sents the “maximal” body of information available about the experiment.
The σ-ﬁeld generated by a collection A (⊆F) of events is deﬁned as the
smallest σ-ﬁeld containing A or, equivalently, the intersection of all σ-ﬁelds
containing A.
Some elementary properties of probability measures are given in Propo-
sition 1.1—all sums, limits, unions, and intersections are taken over a ﬁnite
or countably inﬁnite collection of events.
Proposition 1.1. Let (Ω, F, P) be a probability space. Then
(i) 0 ≤P(A) ≤1,
(ii) P(Ac) = 1 −P(A),
(iii) P(A) ≤P(B) whenever A ⊆B,
(iv) (Continuity) if An ↑A or An ↓A then P(An) →P(A),
(v) (Boole’s inequality) P(
n An) ≤	
n P(An), and
(vi) (Bonferroni’s inequality) P(9
n An) ≥1 −	
n P(Ac
n),
where all sets are elements of F.
Events A1, A2, . . . , An are mutually independent if
P(An1 ∩An2 ∩· · · ∩Ank) = P(An1)P(An2) · · · P(Ank)
for 2 ≤k ≤n and 1 ≤n1 < n2 < · · · < nk ≤n. The events in a
countably inﬁnite collection are said to be mutually independent if the
events in every ﬁnite subcollection are mutually independent. The σ-ﬁelds
{ Gn : n ∈N }—where N is ﬁnite or countably inﬁnite—are said to be mu-
tually independent if the events { An : n ∈N } are mutually independent
for each possible choice of An from Gn.
For a countably inﬁnite sequence of events A1, A2, . . ., set
lim sup
n
An =
∞
:
n=1
∞

k=n
Ak.
1The reader may wonder why we do not simply deﬁne a probability measure on all
of the subsets of Ω—it can be shown that, in general, such a deﬁnition is not possible.

A.1 Probability, Random Variables, Expectation
449
Intuitively, the event lim supn An occurs if and only if events A1, A2, . . .
occur inﬁnitely often, and we write “An i.o.” for lim supn An. The events
A1, A2, . . . are then said to be recurrent.
Proposition 1.2. Let A1, A2, . . . be a countably inﬁnite sequence of (ar-
bitrary) events. If 	∞
n=1 P(An) < ∞, then P { An i.o. } = 0.
Proposition 1.3. Let A1, A2, . . . be a countably inﬁnite sequence of mu-
tually independent events. If 	∞
n=1 P(An) = ∞, then P { An i.o. } = 1.
Propositions 1.2 and 1.3 are known as the ﬁrst and second Borel–Cantelli
lemmas. A reference to “the” Borel–Cantelli lemma is a reference to the
second result, Proposition 1.3.
A.1.2
General Measures
A general measure µ deﬁned on a σ-ﬁeld F satisﬁes the deﬁning require-
ments of a probability measure, except that we do not require that µ(Ω) =
1, or even that µ(Ω) < ∞. If µ(A) > 0 for some A ∈F, then µ is called
nontrivial. A triple (Ω, F, µ) is called a measure space.
The most well-known example of an unbounded measure is Lebesgue
measure µLeb. Let B be the σ-ﬁeld generated by the class of ﬁnite open
intervals of the form (a, b)—the elements of B are called the Borel sets.
Then µLeb is the unique measure on (ℜ, B) such that
µLeb
(a, b)

= b −a
for each interval (a, b). Thus µLeb corresponds to the usual intuitive notion
of length, but is well deﬁned for a much wider class of sets than just the
intervals. As might be expected, µLeb is translation invariant:
µLeb(A + x) = µLeb(A)
for all A ∈B and x ∈ℜ, where A + x = { a + x: a ∈A }.
We also deﬁne k-dimensional Lebesgue measure as the unique measure
µLeb on (ℜk, Bk) such that
µLeb(A) =
k

i=1
(bi −ai)
for all sets of the form
A = (a1, b1) × (a2, b2) × · · · × (ak, bk),
(1.4)
with a1, b1, . . . , ak, bk ∈ℜ. Here Bk is the “product” σ-ﬁeld of k-dimension-
al Borel sets—Bk is generated by the “rectangle sets” as in (1.4). Equiva-
lently, Bk is generated by the collection of sets of the form A1×A2×· · ·×Ak,
where Ai ∈B for 1 ≤i ≤k. Just as Lebesgue measure in ℜextends the
usual notion of length, Lebesgue measure in ℜ2 and ℜ3 extends the usual
notions of area and volume.

450
Appendix A. Selected Background
A.1.3
Random Variables
A random variable X on a probability space (Ω, F, P) is a real-valued
function deﬁned on Ωand measurable with respect to F in the sense that
{ ω: X(ω) ≤x } ∈F for all x ∈ℜ. That is, X is a variable whose value is
determined by the outcome ω of the probabilistic experiment. The σ-ﬁeld
generated by X, denoted by σ⟨X⟩, is the smallest σ-ﬁeld that contains all
sets of the form { ω: X(ω) ≤x }. In light of our previous interpretation of
a σ-ﬁeld, σ⟨X⟩can be viewed as “complete information about X”—that
is, if we know for each A ∈σ⟨X⟩whether or not event A has occurred, we
can precisely determine the value of X. Note that σ⟨X⟩⊆F: the σ-ﬁeld F
may contain “more information” about the probabilistic experiment than
merely information about X. In general, we say that a random variable X
is measurable with respect to a σ-ﬁeld G if the value of X is determined
by G in the foregoing manner, that is, if { ω: X(ω) ≤x } ∈G for x ∈ℜ.
For a (possibly uncountably inﬁnite) collection of random variables H =
{ Xθ : θ ∈Θ }, the σ-ﬁeld generated by the random variables in H is the
smallest σ-ﬁeld that contains 
θ∈Θ σ⟨Xθ⟩.
The distribution of a random variable X is the unique probability mea-
sure µ deﬁned on (ℜ, B) by
µ(A) = P { X ∈A } = P({ ω: X(ω) ∈A })
for A ∈B. The right-continuous function F deﬁned by
F(x) = P { X ≤x } = µ

(−∞, x]

for x ∈ℜis the (cumulative) distribution function of X. Provided that
P { X < ∞} = 1, the distribution function F is proper in that
lim
x→∞F(x) = 1.
As indicated above, µ determines F. Conversely, F determines µ as the
unique measure on (ℜ, B) that satisﬁes µ

(a, b]

= F(b) −F(a) for each
interval (a, b]. A distribution function F is discrete if it is constant except at
a ﬁnite or countably inﬁnite sequence of jump points. If F is discrete, then
X takes on some set of values { an : n ∈N } with respective probabilities
{ pn : n ∈N }, where N is ﬁnite or countably inﬁnite and pn = F(an) −
F(an−) for n ∈N. In this case X is also said to be discrete. We say that
F is continuous if limy→x F(y) = F(x) at each point x and is absolutely
continuous if it has the following property: for every ϵ > 0, there exists
δ > 0 such that for each collection { [ai, bi]: 1 ≤i ≤k } of nonoverlapping
intervals
k

i=1
|F(bi) −F(ai)| < ϵ
if
k

i=1
(bi −ai) < δ.

A.1 Probability, Random Variables, Expectation
451
It can be shown that F is absolutely continuous if and only if µ(A) = 0
whenever µLeb(A) = 0. An absolutely continuous distribution function is
continuous, but the converse assertion is not true in general. The notion
of absolute continuity is important because of the result in Proposition 1.5
below. We say that f is a density function of the distribution function F if
F(x) =
 x
−∞f(x) dx for all x ∈ℜ. In the following, set F ′(x) = dF(x)/dx
for all x such that the derivative is deﬁned.
Proposition 1.5. A distribution function F possesses a density f if and
only if F is absolutely continuous, in which case f = F ′ except on a set of
Lebesgue measure 0.
A distribution function F is singular if the derivative F ′(x) exists and is
equal to 0 except on a set of Lebesgue measure 0. We say that F is a
convex combination of distribution functions G1, G2, . . . , Gk if F = p1G1 +
p2G2 + · · · + pkGk for some nonnegative numbers p1, p2, . . . , pk with p1 +
p2 + · · · + pk = 1. An arbitrary distribution function F can be represented
as a convex combination of distribution functions Fd, Fac, and Fs, where Fd
is discrete, Fac is absolutely continuous, and Fs is singular and continuous.
For most distribution functions encountered in practice, the component Fs
is not actually present (i.e., has a weight of 0).2
Proposition 1.5 can easily be extended to general unbounded functions
and can be further extended to functions that are not necessarily nonde-
creasing by using the notion of bounded variation. For a partition
∆: a = a0 < a1 < · · · < ak = b
of a ﬁnite interval [a, b] and a real-valued function F, set
∥F∥∆=
k

i=1
|F(ai) −F(ai−1)|.
Deﬁnition 1.6. A real-valued function F is of bounded variation on [a, b]
if sup∆∥F∥∆< ∞, where the supremum runs over all partitions of [a, b].
It can be shown that (1) an absolutely continuous function is of bounded
variation and (2) a function of bounded variation is expressible as the
diﬀerence between two nondecreasing functions. Thus, if a function F (not
necessarily nondecreasing) is absolutely continuous, then it can be written
as F = G −H, where G and H are nondecreasing. The argument leading
to Proposition 1.5 can be applied to G and H separately to show that F
2It is perhaps counterintuitive that a continuous function can increase from 0 to
1 while having a derivative that equals 0 except on a set of Lebesgue measure 0. Such
functions exist, however. An example is given by the distribution function of the random
variable X = ∞
n=1 Xn2−n, where { Xn : n ≥1 } is a sequence of i.i.d. random variables
with P { Xn = 1 } = 1 −P { Xn = 0 } = p for some p ∈(0, ∞) with p ̸= 1/2.

452
Appendix A. Selected Background
can be expressed as the integral of a function f. The converse assertion can
also be established: F can be expressed as the integral of a function f only
if F is absolutely continuous.
Deﬁnition 1.7. A random variable X is dominated by a random variable
Y if P { X ≤Y } = 1. A random variable X is stochastically dominated by
a random variable Y (or is stochastically smaller than Y ) if FX(u) ≥FY (u)
for u ∈ℜ, where FX and FY are the distribution functions of X and Y .
Observe that for X to be dominated by Y , the random variables X and
Y must be deﬁned on the same probability space—this requirement can
be dropped in the case of stochastic domination. If X is stochastically
dominated by Y , then we can construct random variables X′ and Y ′ on a
common probability space (Ω, F, P) such that X′ is distributed as X, Y ′
is distributed as Y , and X′ is dominated by Y ′. The idea is as follows. For
a distribution function F, set
F −1(u) = inf { x: F(x) ≥u }
for u ∈[0, 1]. A simple computation shows that if U is a random variable
uniformly distributed on [0, 1], then the random variable Z = F −1(U) has
distribution function F. Thus X′ and Y ′ can be obtained by constructing
a probability space (Ω, F, P) together with a uniform random variable U
deﬁned on (Ω, F, P), and then setting X′ = F −1
X (U) and Y ′ = F −1
Y (U).
The real-valued random variables X1, X2, . . . , Xn are mutually indepen-
dent if the σ-ﬁelds generated by these random variables are mutually inde-
pendent. To establish mutual independence, it suﬃces to show that
P { X1 ∈A1, X2 ∈A2, . . . , Xn ∈An }
= P { X1 ∈A1 } P { X2 ∈A2 } · · · P { Xn ∈An }
for all Borel sets A1, A2, . . . , An ∈B, or that
P { X1 ≤x1, X2 ≤x2, . . . , Xn ≤xn }
= P { X1 ≤x1 } P { X2 ≤x2 } · · · P { Xn ≤xn }
for all x1, x2, . . . , xn ∈ℜ. A countably inﬁnite collection of random vari-
ables is said to be mutually independent if the random variables in each
ﬁnite subcollection are independent. A random variable X is said to be
independent of a σ-ﬁeld G if σ⟨X⟩and G are independent.
A.1.4
Expectation
The expectation of a random variable X on a probability space (Ω, F, P) is
most generally deﬁned as the “Lebesgue integral of X with respect to P.”
We ﬁrst deﬁne such an integral and relate our general deﬁnition to various

A.1 Probability, Random Variables, Expectation
453
elementary deﬁnitions of expectation. First consider a random variable X ≥
0, that is, X(ω) ≥0 for ω ∈Ω. Then

X dP = sup
P

A∈P

inf
ω∈A X(ω)

P(A),
where P (⊆F) is a ﬁnite partition of Ωinto disjoint subsets and the
supremum is taken over all ﬁnite partitions. In general, this integral can
equal +∞. For an arbitrary random variable X, we set X+ = max(X, 0)
and X−= max(−X, 0), so that X = X+ −X−, and deﬁne

X dP =

X+ dP −

X−dP.
This integral is well deﬁned (though perhaps equal to +∞or −∞) provided
that at least one of the two integrals on the right is ﬁnite. If both integrals
on the right are ﬁnite, then

X dP is both well deﬁned and ﬁnite, and X is
said to be integrable (with respect to P). We sometimes write

X(ω) P(dω)
for

X dP. We usually denote the expectation of X by E [X], that is,
E [X] =

X dP.
The expectation operator also has a representation as an integral with
respect to the distribution µ of X:
E [X] =

x µ(dx).
(1.8)
The right-hand integral is sometimes written as

x dF(x), where F is the
distribution function of X; in this form it is called the Stieltjes integral
with respect to F. If F is absolutely continuous with density function f,
then we have the representation
E [X] =
 ∞
−∞
xf(x) dx,
which is familiar from elementary probability. If X is discrete, taking on
values { an : n ∈N } with respective probabilities { pn : n ∈N }, then
E [X] =

n∈N
anpn.
The next results summarize basic properties of the expectation operator
that are used in the text.

454
Appendix A. Selected Background
Proposition 1.9. Let X and Y be random variables and a and b be real-
valued constants.
(i) X is integrable if and only if E [|X|] < ∞.
(ii) If X = 0 a.s., then E [X] = 0.
(iii) If X and Y are integrable with X ≤Y a.s., then E [X] ≤E [Y ].
(iv) If X and Y are integrable, then E [aX + bY ] = aE [X] + bE [Y ].
(v) |E [X] | ≤E [|X|].
(vi) If X and Y are independent, then E [XY ] = E [X] E [Y ].
Note that, in general, the converse to Proposition 1.9(vi) does not hold.
To state our next result, we recall the notation
lim inf
n
xn = lim
n→∞

inf
m≥n xm

,
where x1, x2, . . . is a sequence of real numbers.
Proposition 1.10 (Fatou’s lemma). Let { Xn : n ≥0 } be a sequence of
nonnegative random variables. Then
E

lim inf
n
Xn

≤lim inf
n
E [Xn] .
The rth moment of a random variable X is E [Xr] and the rth central
moment is E [(X −µ)r], where µ = E [X]—the second central moment is
called the variance of X and denoted Var [X]. There are many identities
and inequalities for moments of random variables—a very useful inequality
for our purposes is H¨older’s inequality: let X and Y be random variables,
and let p and q be constants such that 1 < p < ∞and 1/p+1/q = 1. Then
E [|XY |] ≤E1/p [|X|p] E1/q [|Y |q] .
(1.11)
Take p = q = 2 to obtain the Cauchy–Schwarz inequality:
E [|XY |] ≤E1/2 
X2
E1/2 
Y 2
.
In particular, E2 [X] ≤E

X2
—take Y ≡1 and use the fact that E [X] ≤
E [|X|]. Next, ﬁx 0 < α ≤β and take X = |Z|α, Y ≡1, and p = β/α in
(1.11) to obtain
E1/α [|Z|α] ≤E1/β 
|Z|β
,
which is Lyapunov’s inequality. Observe that if a nonnegative random vari-
able X has a ﬁnite rth moment for some r > 0, then Lyapunov’s inequality
implies that X has a ﬁnite qth moment for q ∈(0, r]. Now ﬁx r ≥1 and
let a, b ≥0. Applying Lyapunov’s inequality with α = 1 and β = r to the

A.1 Probability, Random Variables, Expectation
455
random variable that equals a or b with probability 1/2 each, we ﬁnd that
(a + b)r ≤2r−1(ar + br). An easy argument shows that (a + b)r ≤ar + br
for 0 < r < 1. Thus, if X and Y are nonnegative random variables with
ﬁnite rth moments (r > 0), then
E [(X + Y )r] ≤crE [Xr + Y r] = cr

E [Xr] + E [Y r]

,
(1.12)
where cr equals 2r−1 or 1, depending on the value of r. The inequality
in (1.12) is sometimes called the cr-inequality. This result can easily be
generalized to n > 2 nonnegative random variables:
E [(X1 + X2 + · · · + Xn)r] ≤crE [Xr
1 + Xr
2 + · · · + Xr
n] ,
where cr = nr−1 if r ≥1 and cr = 1 if r ≤1. We also refer to this extension
as the cr-inequality.
A useful representation of the rth moment (r ≥1) of a nonnegative
random variable X is as follows:
E [Xr] =
 ∞
0
rxr−1F(x) dx,
(1.13)
where F is the distribution function of X and F = 1 −F. Taking r = 1,
we ﬁnd that
E [X] =
 ∞
0
F(x) dx.
(1.14)
Proposition 1.15. X is stochastically dominated by Y if and only if
E [h(X)] ≤E [h(Y )]
for every nondecreasing function h.
Proving the “if” direction of Proposition 1.15 is easy—let3 h(u) = 1(x,∞)(u)
for each x ∈ℜ. The “only if” direction can be proved either by using an
argument based on (1.14) or by using the fact—discussed previously—that
if X is stochastically dominated by Y , then there exist random variables X′
and Y ′, deﬁned on the same probability space, such that X′ is distributed
as X, Y ′ is distributed as Y , and X′ is dominated by Y ′. It follows from
Proposition 1.15 that if X is stochastically dominated by Y and Y has
ﬁnite rth moment (r ≥0), then X has ﬁnite rth moment.
Fix r ≥1 and observe that
 ∞
0
rxr−1F(x) dx =
∞

n=1
 n
n−1
rxr−1F(x) dx
3Here and elsewhere, 1A denotes the indicator function of the set A, that is, 1A(x) = 1
if x ∈A and 1A(x) = 0 if X ̸∈A. In the special case where 1A is deﬁned on a probability
space (Ω, F, P), so that 1A = 1A(ω), then 1A is interpreted as a random variable that
equals 1 if event A occurs and equals 0 otherwise.

456
Appendix A. Selected Background
and
r(n −1)r−1F(n) ≤
 n
n−1
rxr−1F(x) dx ≤rnr−1F(n −1)
for n ≥1. Combining these results with (1.13), we ﬁnd that
r
∞

n=1
(n −1)r−1P { |X| > n } ≤E [|X|r] ≤r
∞

n=1
nr−1P { |X| > n −1 }
(1.16)
for any random variable X.
A useful tool for analyzing a random variable X having distribution
function F is the LaPlace–Stieltjes transform LF , deﬁned by
LF (s) =

esx dF(x) = E

esX
for all s such that the expectation is ﬁnite—the domain of deﬁnition always
takes the form of a (possibly degenerate) interval that contains the origin.
We often write LX instead of LF when there is no ambiguity. If X is,
for example, an exponential random variable with intensity q > 0, then
LX(s) = q/(q −s) for s < q. If X is a geometric random variable with
parameter p ∈(0, 1), so that P { X = k } = p(1 −p)k−1 for k ≥1, then
LX(s) =
pes
1 −(1 −p)es
for s < −log(1 −p). The LaPlace–Stieltjes transform uniquely determines
the distribution of a random variable. If X has a ﬁnite LaPlace–Stieltjes
transform in some neighborhood of the origin, then X has ﬁnite moments of
all orders. The function LX(s) is sometimes called the moment generating
function of X, because L(k)
X (0) = E

Xk
for k ≥0, where L(k)
X
is the
kth derivative of LX. The following result illustrates the usefulness of the
transform.
Proposition 1.17. Let X, X1, X2, . . . be a sequence of i.i.d. random vari-
ables and let N be a random variable that takes values in { 1, 2, . . . } and
is independent of { Xn : n ≥1 }. Suppose that the LaPlace–Stieltjes trans-
forms LX and LN are both ﬁnite in some neighborhood of the origin, and
set SN = X1 + X2 + · · · + XN. Then LSN (s) = LN

log LX(s)

whenever
the left side is ﬁnite.
Proof. Set pn = P { N = n } for n ≥1. Observe that, by the i.i.d. prop-
erty, LSn(s) = Ln
X(s) for n ≥1, where Sn = X1 + X2 + · · · + Xn. Since N
is independent of { Xn : n ≥1 }, we have
LSN (s) = E

esSN 
=

n≥1
E

esSn
pn =

n≥1
Ln
X(s)pn.

A.1 Probability, Random Variables, Expectation
457
But

n≥1
Ln
X(s)pn =

n≥1
en log LX(s)pn = LN

log LX(s)

.
For example, if X is an exponential random variable with intensity q and if
N is a geometric random variable with parameter p, then Proposition 1.17
implies that SN is exponential with intensity pq.
A.1.5
Moment Results for Random Sums
In this section we give some useful moment equalities and inequalities for
sums of the form SN = X1 + X2 + · · · + XN, where X1, X2, . . . are in-
dependent and identically distributed (i.i.d.) random variables and N is a
random variable taking values in { 1, 2, . . . }. These results all concern an
increasing sequence of σ-ﬁelds { Fn : n ≥1 } such that each Xn is measur-
able with respect to Fn. Intuitively, the “information” embodied in Fn is
suﬃcient to determine the values of X1, X2, . . . , Xn, and Fn may contain
some additional information (perhaps about some auxiliary random vari-
ables Y1, Y2, . . . , Yn). When Fn = σ⟨X1, X2, . . . , Xn⟩, so that Fn is the σ-
ﬁeld generated by X1, X2, . . . , Xn, then Fn consists precisely of information
about X1, X2, . . . , Xn and does not contain any additional information.
Deﬁnition 1.18. An integer-valued random variable N is a stopping time
with respect to an increasing sequence of σ-ﬁelds { Fn : n ≥1 } if and only
if { N ≤n } ∈Fn for n ≥1.
Roughly speaking, the “information” in Fn is enough to determine whether
or not the event { N ≤n } has occurred. Equivalently, the information in
Fn determines whether or not the event { N = n } has occurred. Typically,
N denotes the random time at which some event happens, and N is a
stopping time if, at any time point, the occurrence or nonoccurrence of the
event can be determined from observation of the past and present, without
needing to look into the future. For example, the random index N = “the
ﬁrst time at which the state of the system changes to s” is a stopping
time, whereas the random index N −2 = “two state transitions before the
ﬁrst time at which the state of the system changes to s” is not. If Fn =
σ⟨X1, X2, . . . , Xn⟩for n ≥1, then N is said to be a stopping time with
respect to { Xn : n ≥1 }. In this case the occurrence or nonoccurrence of the
event { N = n } is completely determined by the values of X1, X2, . . . , Xn.
Part (i) of Proposition 1.19 below is known as Wald’s moment identity
and part (ii) as Wald’s second moment identity. In the proposition denote
by µ the common mean and by σ2 the common variance of X1, X2, . . .
whenever these quantities exist.
Proposition 1.19. Let SN = 	N
n=1 Xn, where { Xn : n ≥1 } is a se-
quence of i.i.d. random variables and N is a stopping time with respect

458
Appendix A. Selected Background
to an increasing sequence of σ-ﬁelds { Fn : n ≥1 } such that Xn is mea-
surable with respect to Fn for n ≥1 and independent of Fn−1 for n ≥2.
Then
(i) E [SN] = µ·E [N] if either E [|X1|] < ∞and E [N] < ∞or if X1 ≥0,
and
(ii) E

(SN −Nµ)2
= σ2 · E [N] if σ2 < ∞and E [N] < ∞.
The next result gives an inequality rather than an equality, but applies
to moments of SN higher than the second moment.
Proposition 1.20. Let SN = 	N
n=1 Xn, where { Xn : n ≥1 } is a se-
quence of i.i.d. random variables and N is a stopping time with respect
to an increasing sequence of σ-ﬁelds { Fn : n ≥1 } such that Xn is measur-
able with respect to Fn for n ≥1 and independent of Fn−1 for n ≥2. Then
for r ≥0 there exists a constant br (depending only on r) such that
E[|SN|r] ≤brE [|X1|r] E [N r] .
Remark 1.21. When N is independent of { Xn : n ≥1 }, we can apply
Proposition 1.20 by taking Fn = σ⟨X1, Y1, . . . , Xn, Yn⟩, where Yk = 1{N≤k}
for 1 ≤k ≤n.
A.1.6
General Integrals
The foregoing development of the integral can be generalized to an arbitrary
measure space (Ω, F, µ); that is, µ need not be a probability measure. In
this general setup, the integral

f dµ or, equivalently,

f(ω) µ(dω) can be
deﬁned almost exactly as before for each measurable real-valued function
f. We also deﬁne

A
f dµ =

f1A dµ
for A ∈F.
Lemma 1.22. Let f be a nonnegative measurable function deﬁned on a
measure space (Ω, F, µ) and let A ∈F satisfy µ(A) < ∞. Suppose that

A f dµ > 0. Then there exist a measurable set Q ⊆A and a number γ > 0
such that µ(Q) > 0 and f(ω) > γ for ω ∈Q.
Proof. Fix γ > 0 and set Qγ = { ω: f(ω) > γ }. Suppose that µ(Qγ) = 0
for γ > 0. Then

A
f dµ =

A∩Qc
γ
f dµ ≤γµ(A)
for γ > 0. Because µ(A) < ∞and γ is arbitrary, it follows that

A f dµ = 0,
a contradiction. Thus µ(Qγ) > 0 for at least one value of γ.

A.1 Probability, Random Variables, Expectation
459
Lemma 1.23. For a measure space (Ω, F, µ), let A ∈F satisfy µ(A) > 0
and let f be a nonnegative measurable function such that f(ω) > 0 for
ω ∈A. Then

A f du > 0.
Proof. Set Aγ = { ω ∈A: f(ω) ≥γ }. Since Aγ ↑A as γ ↓0, it follows
from Proposition 1.1(iv) that P(Aγ) →P(A) > 0, and hence that P(Aγ) >
0 for some γ > 0. For this value of γ,

A
f dµ ≥

Aγ
f dµ ≥γµ(Aγ) > 0.
To compare the modelling power of diﬀerent formalisms for discrete-event
systems in Chapter 4, we use the following “change of variable” result. Let
(Ω, F) and (Ω′, F′) be measurable spaces and let φ be a mapping from Ω
to Ω′. We assume that φ is measurable in that φ−1A′ ∈F for all A′ ∈F′,
where φ−1A′ = { x ∈Ω: φx ∈A′ }. For a measure µ on F, we deﬁne a
measure ν on F′ by setting ν(A′) = µ(φ−1A′) for A′ ∈F′, and for a
measurable real-valued function f on Ω′, we deﬁne the function f ◦φ on Ω
by setting (f ◦φ)(ω) = f(φω) for ω ∈Ω.
Proposition 1.24 (Change of variable). Let f be a measurable real-
valued function deﬁned on (Ω′, F′) and φ a measurable mapping from (Ω, F,
µ) to (Ω′, F′). Then f is integrable with respect to ν if and only if f ◦φ is
integrable with respect to µ, in which case

φ−1A′ f ◦φ dµ =

A′ f dν.
We sometimes express the conclusion of Proposition 1.24 using the following
notation:

φ−1A′ f(φω) µ(dω) =

A′ f(ω) µ(φ−1dω′).
The representation of expected value as in (1.8) is a consequence of this
result, where we take f as the identity function, (Ω′, F′) = (ℜ, B), A′ = Ω′,
µ = P, and φω = X(ω).
The next result concerns integrals of functions deﬁned on a product space
(X×Y, X ×Y, π) composed from the measure spaces (X, X, µ) and (Y, Y, ν).
Here X × Y is the usual Cartesian product of X and Y , the σ-ﬁeld X × Y
is the σ-ﬁeld generated by A = { A × B : A ∈X and B ∈Y }, and π is the
unique measure that satisﬁes π(A×B) = µ(A) ν(B) for A ∈X and B ∈Y.
The measure π is often called the product measure of µ and ν.
Proposition 1.25 (Fubini’s theorem). Let f be a function deﬁned on
the product space (X × Y, X × Y, π), and suppose that either f ≥0 or f is
integrable with respect to π. Then

X×Y
f dπ =

X

Y
f(x, y)ν(dy)

µ(dx) =

Y

X
f(x, y)µ(dx)

ν(dy).
(1.26)

460
Appendix A. Selected Background
Under the conditions of the proposition, the leftmost double integral is
equal to each of the two iterated integrals. This result is usually used to
justify the interchange of the order of integration in an iterated integral.
The assertion that (1.26) holds when f is nonnegative is known as Tonelli’s
theorem. Proposition 1.25 can be used to obtain the identity in (1.13).
A.1.7
Conditional Expectation and Probability
Consider a probabilistic experiment that is described by a probability space
(Ω, F, P), along with an “observer” who has some degree of information
about the experiment. First suppose that the observer has no information.
If we ask the observer to assess the probability that event A has occurred—
in other words, that the outcome ω is an element of A—then the answer
is P(A). Now suppose that the observer knows that event B has occurred,
where P(B) > 0. Then the answer is P(A | B) = P(A∩B)/P(B), the “con-
ditional probability” of event A, given that event B has occurred. Similarly,
knowing that B has occurred, the observer computes the expected value of
a random variable X deﬁned on (Ω, F, P) as E [X | B] = E [X1B] /P(B).
Before we conduct the experiment, and knowing that we will tell the ob-
server whether or not B has occurred, we can view the observer’s future
assessment of the probability of A as a random variable Z, where
Z(ω) =

P(A ∩B)/P(B)
if ω ∈B;
P(A ∩Bc)/P(Bc)
if ω ∈Bc.
Denote by G = { Ω, ∅, B, Bc } the σ-ﬁeld that represents “complete infor-
mation about whether or not B has occurred.” Then the random variable
Z is said to be the “conditional probability of A, given G,” and we write
P(A | G) for Z—sometimes we write P(A | G)ω to emphasize the depen-
dence on ω. We can similarly deﬁne the conditional expectation E [X | G]
as
E [X | G] = E [X | G]ω =

E [X1B] /P(B)
if ω ∈B;
E [X1Bc] /P(Bc)
if ω ∈Bc.
An easy calculation shows that
E [X] = E

E [X | G]

= E [X | B] P(B) + E [X | Bc] P(Bc).
Now consider an arbitrary random variable X deﬁned on a probability
space (Ω, F, P), along with a σ-ﬁeld G ⊆F. Motivated by the above discus-
sion, we deﬁne a conditional expectation E [X | G] to be a random variable
such that
1. E [X | G] is measurable with respect to G and integrable.
2. For all A ∈G, E [X | G] satisﬁes the functional equation
E

1AE [X | G]

= E [1AX] .
(1.27)

A.1 Probability, Random Variables, Expectation
461
Setting A = Ωin (1.27), we obtain the law of total expectation: E [X] =
E

E [X | G]

. To establish the condition in (2) for all A ∈G, it suﬃces to
show that (1.27) holds for all A belonging to a “π-system” that generates
G. A collection P of subsets of Ωis a π-system if it is closed under ﬁnite
intersections: A ∩B ∈P whenever A, B ∈P. In general, many random
variables satisfy the conditions in (1) and (2) above, but any two such
random variables diﬀer only on a set of probability 0. Unless otherwise
noted, by “the” conditional probability we mean an arbitrary member of the
foregoing collection of random variables. For most purposes, the particular
version of conditional expectation that is chosen is immaterial.
The following proposition gives some elementary properties of conditional
expectation, many of which coincide with properties of ordinary expecta-
tion.
Proposition 1.28. Let X and Y be random variables, and let a, b, and c
be real-valued constants.
(i) If X = c a.s., then E [X | G] = c a.s..
(ii) If X and Y are integrable with X ≤Y a.s., then E [X | G] ≤E [Y | G]
a.s..
(iii) |E [X | G] | ≤E [|X| | G] a.s..
(iv) If X and Y are integrable, then E [aX + bY | G] = aE [X | G] +
bE [Y | G] a.s..
The next two results give key properties of conditional expectation that
we use repeatedly throughout the text.
Proposition 1.29. Suppose that X is measurable with respect to G and
that both Y and XY are integrable. Then
E [XY | G] = XE [Y | G] a.s..
Thus, if X is determined by the information in G, it can be “pulled out”
of a conditional expectation with respect to G.
Proposition 1.30. Let X be an integrable random variable, and let G1
and G2 be σ-ﬁelds such that G1 ⊆G2. Then
E

E [X | G1]
 G2

= E

E [X | G2]
 G1

= E [X | G1] a.s..
The conditional probability P(A | G) is deﬁned by
P(A | G) = E [1A | G]
for A ∈F, and the basic properties of conditional probability follow from
the corresponding properties of conditional expectation. The reader may

462
Appendix A. Selected Background
wonder whether, for a given σ-ﬁeld G ⊆F, we can choose a version of
P(A | G) for each A ∈F such that, for ﬁxed ω, the set function P( · | G)ω
is a probability measure. In general, such a choice is impossible. For a given
σ-ﬁeld G and random variable X, however, we can deﬁne a function µ on
B × Ωsuch that (1) µ( · , ω) is a probability measure for each ω ∈Ωand
(2) µ(H, · ) is a version of P { X ∈H | G } for each H ∈B. The probability
measure µ( · , ω) is a conditional distribution of X, given G.
If X is a random variable and H is a collection of random variables,
then we use the notation E [X | H] to denote the conditional expectation
E [X | G], where G is the σ-ﬁeld generated by the random variables in H.
For example, E [X | Y ] is interpreted as E [X | σ⟨Y ⟩].
All of the classical conditional probability formulas follow from the fore-
going general framework. For example, suppose that the real-valued random
vector (X, Y ) has a joint density function f. Then E [X | Y ] = g(Y ) a.s.,
where
g(y) =

xf(x, y) dx

f(x, y) dx .
Since g(Y ) is clearly measurable with respect to σ⟨Y ⟩, showing that g(Y ) is
a version of E [X | Y ] amounts to showing that g(Y ) satisﬁes the relation in
(1.27). Thus it suﬃces to show that E

1Ag(Y )

= E [1AX] for all A ∈σ⟨Y ⟩.
Fix a set A of the form A = { Y ∈E }, where E is a Borel set. Using Fubini’s
theorem, we have
E

1Ag(Y )

=

1E(y)g(y)f(x, y) dx dy
=

1E(y)g(y)

f(x, y) dx

dy
=

1E(y)xf(x, y) dx dy
= E [1AX] ,
and the desired result follows.
A.1.8
Stochastic Convergence
Limit theorems for random variables involve several diﬀerent modes of con-
vergence.
Deﬁnition 1.31. Let X and { Xn : n ≥1 } be random variables deﬁned
on a common probability space (Ω, F, P). Then Xn converges with proba-
bility 1 to X if
P

lim
n→∞Xn = X

= 1.
We also say that Xn converges to X almost surely (a.s.), and we often write
“Xn →X a.s. as n →∞” or “limn→∞Xn = X a.s..” It can be shown that

A.1 Probability, Random Variables, Expectation
463
limn→∞Xn = X a.s. if and only if, for all ϵ > 0,
lim
m→∞P { |Xn −X| ≤ϵ for all n ≥m } = 1.
The following result, due to Kolmogorov, gives necessary and suﬃcient
conditions for a.s. convergence of { Sn : n ≥0 } when each Sn is a partial
sum: Sn = 	n
i=1 Xi. Denote by X(c) the random variable X truncated at
c: X(c) = X1{|X|≤c}.
Proposition 1.32 (Three-series theorem). Let { Xn : n ≥1 } be a se-
quence of mutually independent random variables, and consider the three
series

n
P { |Xn| > c } ,

n
E[X(c)
n ],

n
Var[X(c)
n ].
In order that 	
n Xn converge with probability 1, it is necessary that the
three series converge for all positive c and suﬃcient that they converge for
some positive c.
The next result relates a.s. convergence to convergence of moments.
Proposition 1.33. Let X, X1, X2, . . . be random variables deﬁned on a
probability space (Ω, F, P).
(i) (Monotone convergence) If each Xn is nonnegative and Xn ↑X a.s.,
then E [Xn] →E [X].
(ii) (Dominated convergence) If supn |Xn| ≤Y a.s. for some integrable
random variable Y and Xn →X a.s., then X and the Xn are inte-
grable and E [Xn] →E [X].
(iii) (Bounded convergence) If supn |Xn| ≤c a.s. for some ﬁnite constant
c, then X and the Xn are integrable and E [Xn] →E [X].
Deﬁnition 1.34. Let X and { Xn : n ≥1 } be random variables deﬁned on
a common probability space (Ω, F, P). Then Xn converges in probability to
X if
lim
n→∞P { |Xn −X| ≤ϵ } = 1
for ϵ > 0, and we write Xn
pr
→X.
We write X ∈Lp (p ≥0) if E [|X|p] < ∞.
Deﬁnition 1.35. Let X and { Xn : n ≥1 } be random variables deﬁned
on a common probability space (Ω, F, P) such that X, X1, X2, . . . ∈Lp.
Then Xn converges in Lp to X if
lim
n→∞E [|Xn −X|p] = 0.

464
Appendix A. Selected Background
For random variables X and { Xn : n ≥1 }, set F(x) = P { X ≤x } and
Fn(x) = P { Xn ≤x }.
Deﬁnition 1.36. A sequence { Xn : n ≥1 } converges in distribution to X
(or converges weakly to X) if
lim
n→∞Fn(x) = F(x)
for all x at which the function F is continuous, and we write Xn ⇒X.
Observe that the random variables involved in the foregoing deﬁnition need
not be deﬁned on the same probability space.
Proposition 1.37. Xn ⇒X if and only if E [h(Xn)] →E [h(X)] for
every bounded continuous function h.
The above characterization can serve as a deﬁnition of weak convergence
in settings more complicated than that of real-valued random variables.
For example, we can easily extend the notion of weak convergence to the
setting of ℜl-valued random vectors—see also Section A.2.5.
Let µ and ν be probability measures deﬁned on a common measurable
space (Ω, F). The total variation distance between µ and ν, denoted by
∥µ −ν∥, is deﬁned as
∥µ −ν∥= sup
A∈F
|µ(A) −ν(A)|.
The following deﬁnition applies to random variables X, X1, X2, . . ., having
respective distributions µ, µ1, µ2, . . ..
Deﬁnition 1.38. A sequence { Xn : n ≥1 } converges in total variation to
X if
lim
n→∞∥µn −µ∥= 0,
and we write Xn
tv
→X.
Convergence in total variation can be viewed as a uniform version of con-
vergence in distribution. If the random variables X, X1, X2, . . . take values
in a ﬁnite or countably inﬁnite state space, then the notions of convergence
in distribution and total variation convergence coincide.
The following result gives some key relationships between the various
modes of convergence. Recall that X is dominated by Y if X ≤Y a.s..
We say that the sequence { Xn : n ≥0 } is dominated by Y if each Xn is
dominated by Y .
Proposition 1.39. Let X and { Xn : n ≥0 } be random variables, and let
c be a real-valued constant.
(i) If Xn →X a.s., then Xn
pr
→X.

A.1 Probability, Random Variables, Expectation
465
(ii) If Xn
pr
→X, then Xn ⇒X.
(iii) If Xn ⇒c, then X
pr
→c.
(iv) If Xn
tv
→X, then Xn ⇒X.
(v) If Xn →X in Lp, then Xn
pr
→X, and hence Xn ⇒X.
(vi) If Xn
pr
→X and { |Xn −X|: n ≥1 } is dominated by some random
variable Y ∈Lp, then Xn →X in Lp.
Remark 1.40.
The goal in a simulation experiment usually is to estimate
some unknown constant c that quantiﬁes the performance of the system
under study. Suppose that { Xn : n ≥1 } is a sequence of estimators of c,
indexed by the length n of the simulation. If Xn →c a.s., then we say that
“Xn is strongly consistent for c.” If Xn ⇒c or, equivalently, Xn →c in
probability, then we say that “Xn is (weakly) consistent for c.” Finally, if
E [Xn] = c for each n, then we say that “Xn is unbiased for c.”
The following propositions, which pertain speciﬁcally to convergence in
distribution, are used frequently in the text.
Recall that if U is a random variable uniformly distributed on [0, 1] and
F is a distribution function with inverse F −1 deﬁned by
F −1(u) = inf { x: F(x) > u }
for u ∈[0, 1], then the random variable Z = F −1(U) has distribution
function F. Use of this trick leads to the following result.
Proposition 1.41 (Skorohod’s theorem). If Xn ⇒X, then there ex-
ist random variables X′, X′
1, X′
2, . . . deﬁned on a common probability space
(Ω, F, P) such that X′ is distributed as X, X′
n is distributed as Xn for
n ≥1, and X′
n(ω) →X(ω) for each ω ∈Ω.
The idea is to set X′
n = F −1
n (U) for n ≥1, where Fn is the distribution
function of Xn and U is uniformly distributed on [0, 1]. Skorohod’s theorem
can be extended to random vectors X, X1, X2, . . . ∈ℜl (l > 1), but a more
complicated argument is required.
The following result on continuous mappings follows almost immediately
from Skorohod’s theorem. Denote by D(h) the set of discontinuity points
for the real-valued function h, so that x ∈D(h) if and only if there exists
a sequence x1, x2, . . . such that xn →x but h(xn) ̸→h(x).
Proposition 1.42 (Continuous mapping theorem). If Xn ⇒X and
P { X ∈D(h) } = 0, then h(Xn) ⇒h(X).
Observe that P { X ∈D(h) } = 0 trivially whenever h is a continuous func-
tion. It can be shown that the set D(h) is at most countably inﬁnite, and it
follows that P { X ∈D(h) } = 0 whenever the distribution function of X is

466
Appendix A. Selected Background
absolutely continuous. Finally, if the state space S of the random variables
X, X1, X2, . . . is ﬁnite or countably inﬁnite, then P { X ∈D(h) } = 0 auto-
matically4. As with Skorohod’s theorem, Proposition 1.42 can be extended
to random variables taking values in ℜl for l > 1.
It can be shown that if { (Xn, Yn): n ≥1 } is a sequence of random pairs
such that Xn ⇒X and Yn ⇒c for some random variable X and real-
valued constant c, then (Xn, Yn) ⇒(X, c). This fact, combined with the
continuous mapping theorem, leads to the following result.
Proposition 1.43 (Slutsky’s theorem). If Xn ⇒X and if Y ⇒c for
some real-valued constant c, then
(i) Xn + Yn ⇒X + c;
(ii) YnXn ⇒cX; and
(iii) Xn/Yn ⇒X/c provided c ̸= 0.
The following important corollary to Slutsky’s theorem is obtained by tak-
ing Yn = X′
n −Xn, where Xn −X′
n ⇒0 and applying the result in (i).
Proposition 1.44 (Converging-together lemma). If Xn ⇒X and
Xn −X′
n ⇒0, then X′
n ⇒X.
Next, using Skorohod’s theorem together with standard results for Taylor
series, we obtain Proposition 1.45, which can be viewed as complementary
to the continuous mapping theorem. Given a real-valued function f deﬁned
on ℜl (l ≥1), we denote by ∇f(α) the gradient of f at the point α ∈ℜl.
We assume that elements of ℜl are column vectors and denote by xt the
transpose of x ∈ℜl.
Proposition 1.45 (The delta method). Let X, X1, X2, . . . be random
vectors taking values in ℜl for some l ≥1, and suppose that
γn(Xn −α) ⇒X
for some constant α ∈ℜl and sequence { γn : n ≥1 } of nonnegative con-
stants such that γn →∞. Let f be a real-valued function that is diﬀeren-
tiable at α. Then
γn

f(Xn) −f(α)

⇒∇f(α)tX.
The “Cram´er–Wold theorem” can be used to extend weak-convergence
results for real-valued random variables to corresponding results for ℜl-
valued random vectors. In the following, { Xn : n ≥0 } and Y are ℜl-valued
4Here S is viewed as being endowed with the “discrete topology” in which all subsets
of S are open and all functions deﬁned on S are continuous. S can be metrized by
deﬁning a distance function ρ such that ρ(x, y) equals 0 if x = y and equals 1 otherwise.

A.2 Limit Theorems for Stochastic Processes
467
random vectors for some l > 1, and we write Xn = (Xn,1, Xn,2, . . . , Xn,l)
for n ≥0 and Y = (Y1, Y2, . . . , Yl).
Proposition 1.46 (Cram´er–Wold theorem). Xn ⇒Y in ℜl if and
only if
l

i=1
uiXn,i ⇒
l

i=1
uiYi
in ℜfor each (u1, u2, . . . , ul) ∈ℜl.
Limit theorems in discrete time often can be converted to limit theorems
in continuous time by invoking the following result.
Proposition 1.47. The stochastic process { X(t): t ≥0 } converges in dis-
tribution to X at t →∞if and only if X(tn) ⇒X for every subsequence
tn →∞.
The next two results relate convergence in distribution to convergence
of moments. The ﬁrst result combines Skorohod’s theorem with Fatou’s
lemma (Proposition 1.10) to yield a version of Fatou’s lemma for weak
convergence.
Proposition 1.48. If Xn ⇒X, then E [|X|] ≤lim infn E [|Xn|].
To state the second result, we need to introduce the notion of “uniform
integrability.”
Deﬁnition 1.49. A sequence of random variables { Xn : n ≥1 } is uni-
formly integrable if
lim
x→∞sup
n≥0
E

|Xn| 1{|Xn|>x}

= 0.
Suﬃcient conditions for uniform integrability are that
sup
n≥0
E[ |Xn|1+ϵ ] < ∞
for some ϵ > 0 or that { Xn : n ≥1 } is stochastically dominated by an
integrable random variable X.
Proposition 1.50. If Xn ⇒X and { Xn : n ≥1 } is uniformly integrable,
then X is integrable and E [Xn] →E [X].
A.2
Limit Theorems for Stochastic Processes
A.2.1
Deﬁnitions and Existence Theorem
A stochastic process { X(t): t ∈T } is an indexed collection of random vari-
ables taking values in a set S, where either T = [0, ∞) or T = { 0, 1, 2, . . . }.

468
Appendix A. Selected Background
In the latter case, we usually use the notation { Xn : n ≥0 } for a discrete-
time process. A realization { x(t): t ∈T } of a stochastic process is called
a sample path of the process. We focus throughout on processes with a
state space (S, S) that is a well-behaved subset of (ℜl, Bl) for some l ≥1;
recall from Section A.1.2 that Bl are the l-dimensional Borel sets. More
speciﬁcally, we require that S be a complete, separable metric space.5
A stochastic process { X(t): t ∈T } typically is deﬁned in one of two
ways. The ﬁrst approach is to construct { X(t): t ∈T } in terms of a pre-
viously deﬁned stochastic process. For example, in Chapter 3 the marking
process of an spn is deﬁned in terms of an underlying general state-space
Markov chain. Also in that chapter, a ctmc is constructed from the pro-
cess { (Yn, Tn): n ≥0 }, where { Yn : n ≥0 } is a dtmc and { Tn : n ≥0 }
is a sequence of exponential random variables with intensities that depend
on { Yn : n ≥0 }.
The other approach is to specify a set of ﬁnite-dimensional distributions
and then show that there exists a process having these distributions. We
outline this approach in the setting of discrete-time processes. Recall from
Section A.1.6 the deﬁnition of the product space (Sk, Sk), where k ≥2. For
a discrete-time process { Xn : n ≥0 }, the ﬁnite-dimensional distributions
are given by
Pn0···nk(A) = P { (Xn0, . . . , Xnk) ∈A } ,
where k ≥0, A ∈Sk, and n0, . . . , nk are distinct indices. Proposition 2.1 be-
low, known as the Kolmogorov existence theorem, gives some suﬃcient “con-
sistency conditions” on the ﬁnite-dimensional distributions under which the
existence of { Xn : n ≥0 } is guaranteed.
The version of { Xn : n ≥0 } guaranteed by the proposition is deﬁned on
the product space (S∞, S∞). Here the notion of product space extends
the deﬁnition given in Section A.1.6. An element of S∞is a sequence
(ω0, ω1, . . .) with each ωi an element of S. In other words, an element of S∞
is a possible sample path of the process. For ω ∈S∞and n ≥0, deﬁne the
coordinate projection function Zn : S∞→S by Zn(ω) = ωn. Then S∞is
deﬁned as σ⟨Zn : n ≥0⟩, that is, as the σ-ﬁeld generated by the coordinate
projection functions.
Proposition 2.1. Suppose that for any integer k ≥0, indices 0 ≤n0 <
n1 < · · · < nk, events A0, A1, . . . , Ak ∈S, and permutation π of { 0, 1, . . . ,
k },
Pn0···nk(A0 × · · · × Ak) = Pnπ0···nπk(Aπ0 × · · · × Aπk)
5For a metric space S with metric ρ, recall that a Cauchy sequence { xn : n ≥1 }
has the property that, for ϵ > 0, ρ(xn, xm) < ϵ for all suﬃciently large n and m. The
space S is complete if every Cauchy sequence converges to a limit in S. If there exists a
countable subset S0 ⊆S such that every point in S is the limit of a sequence of points
in S0, then S is said to be separable. For the space ℜ, the rationals play the role of the
points in S0.

A.2 Limit Theorems for Stochastic Processes
469
and
Pn0···nk−1(A1 × · · · × Ak−1) = Pn0···nk−1nk(A1 × · · · × Ak−1 × S).
Then there exists a probability measure P on the product space (S∞, S∞)
such that the coordinate-projection process { Zn : n ≥0 } deﬁned on (S∞,
S∞, P) has the Pn0···nk as its ﬁnite-dimensional distributions.
Example 2.2 (Underlying chain of an spn). To illustrate the application
of Proposition 2.1, we consider in detail the construction of the underlying
chain { (Sn, Cn): n ≥0 } for an spn with marking set G and with M tran-
sitions; see the discussion in Section 3.1.1. The chain takes values in the
measurable space (Σ, S), where Σ = 
s∈G

{ s } × C(s)

and C(s) is the
set of possible clock-reading vectors when the marking is s. In this setting,
S is taken as the σ-ﬁeld generated by sets of the form { s } ×

C(s) ∩B

with s ∈S and B ∈BM. Recall that the underlying chain is speciﬁed by
giving the initial distribution µ and the transition kernel6 P. We can then
deﬁne a set of ﬁnite-dimensional distributions Pn0···nk as follows. Set
P ∗
n(A) =

A0
µ

d(s0, c0)
 
A1
P

(s0, c0), d(s1, c1)

· · ·

An−1
P

(sn−2, cn−2), d(sn−1, cn−1)

P

(sn−1, cn−1), An

for n ≥0 and A = A0 × A1 × · · · × An. For k ≥0, distinct indices
n0, n1, . . . , nk and event A = A0 × A1 × · · · × Ak, set Pn0···nk(A) = P ∗
m(B),
where m = max(n0, n1, . . . , nk) and B = B0 × B1 × · · · × Bm with Bl =
Aj if l = nj for some j and Bn = Σ otherwise. It follows from stan-
dard measure-theoretic arguments that Pn0···nk can be uniquely extended
to a probability measure on (Σk, Sk)—this probability measure consti-
tutes the desired ﬁnite-dimensional distribution for the speciﬁed values
of k and n0, n1, . . . , nk. The conditions of Proposition 2.1 hold almost by
deﬁnition, so that there exists a measure P as in the conclusion of the
proposition—write Pµ for P to emphasize the dependence on µ. Thus the
chain { (Sn, Cn): n ≥0 } can be deﬁned on the probability space (Σ∞, S∞,
Pµ) as the coordinate projection function.7
6In general, a transition kernel on a measurable space (S, S) is a mapping P from
S × S to [0, 1] such that, for ﬁxed x ∈S, the mapping P(x, · ) is a probability measure
and, for ﬁxed A ∈S, the function P( · , A) is measurable.
7Other deﬁnitions of the underlying chain are possible. One common construction
deﬁnes the chain on the probability space ([0, 1]∞, B∞
0 , µLeb
∞), where B0 is the σ-ﬁeld
generated by the open subsets of [0, 1] and µLeb
∞
= µLeb
0
× µLeb
0
× · · · with µLeb
0
equal
to Lebesgue measure on [0, 1]. This probability space corresponds to the probabilistic
experiment in which we generate a sequence U0, U1, . . . of mutually independent random

470
Appendix A. Selected Background
As discussed previously, the σ-ﬁeld Fk = σ⟨X0, X1, . . . , Xk⟩represents
“complete information” about the process { Xn : n ≥0 } until time k. For a
random variable K that is a stopping time with respect to { Xn : n ≥0 }, we
deﬁne FK as the σ-ﬁeld generated by sets of the form { K ≤k }∩Ak, where
k ≥0 and Ak ∈Fk. Informally, FK represents “complete information”
about { Xn : n ≥0 } until the random time K.
A.2.2
I.I.D., O.I.D., and Stationary Sequences
Perhaps the simplest stochastic process is a sequence { Xn : n ≥0 } of i.i.d.
random variables. We now state the key limit theorems for such a process.
In the following, set ¯Xn = (1/n) 	n−1
i=0 Xi and, as usual, denote by N(0, 1)
a standard normal random variable.
Proposition 2.3 (Strong law of large numbers). Let
{ Xn : n ≥0 }
be a sequence of i.i.d. random variables, and suppose that µ = E [X0] < ∞.
Then
lim
n→∞
¯Xn = µ a.s..
Proposition 2.4 (Central limit theorem). Let { Xn : n ≥0 } be a se-
quence of i.i.d. random variables with common mean µ, and suppose that
σ2 = Var [X0] < ∞. Then
√n( ¯Xn −µ) ⇒σN(0, 1)
as n →∞.
An important variant of the foregoing result replaces the deterministic in-
dex n by the random index N(t), where { N(t): t ≥0 } is an integer-valued
stochastic process.
Proposition 2.5 (Random-index central limit theorem). Let { Xn :
n ≥0 } be a sequence of i.i.d. random variables. Suppose that σ2 =
Var [X0] < ∞and that N(t)/t
pr
→c as t →∞for some constant c ∈(0, ∞).
Then
4
N(t)( ¯XN(t) −µ) ⇒σN(0, 1)
as t →∞.
An easy application of the Cram´er–Wold theorem (Proposition 1.46)
extends Proposition 2.4 to ℜl for l > 1. Speciﬁcally, let { Xn : n ≥0 } be
a sequence of i.i.d. ℜl-valued random vectors for some l > 1, and write
variables, each of which is uniformly distributed on [0, 1]. This setup is characteristic of
discrete-event simulation, where each Un represents the output of a uniform random-
number generator. We focus on the construction that uses Proposition 2.1 because it is
better suited to our discussion of modelling power in Chapter 4.

A.2 Limit Theorems for Stochastic Processes
471
Xn = (Xn,1, Xn,2, . . . , Xn,l) for n ≥0. Denote the common mean vector
by µ = (µ1, µ2, . . . , µl) and the common covariance matrix by Σ = ∥σij∥;
that is, µi = E [X0,i] and σi,j = Cov [X0,i, X0,j]. As before, set ¯Xn =
(1/n) 	n−1
i=0 Xi.
Proposition 2.6 (Multivariate central limit theorem). Suppose that
Var [X0,i] < ∞for 1 ≤i ≤l. Then
√n( ¯Xn −µ) ⇒N(0, Σ)
as n →∞, where ⇒denotes weak convergence in ℜl and N(0, Σ) is an
l-dimensional normal random vector with mean vector (0, 0, . . . , 0) and co-
variance matrix Σ.
A sequence of random variables { Xn : n ≥0 } is one-dependent if Xn+j
is independent of { X0, X1, . . . , Xn } for each n ≥0 and j > 1. We now
consider a stochastic process that comprises a sequence { Xn : n ≥0 } of
one-dependent and identically distributed (o.i.d.) random variables. By ap-
plying Proposition 2.3 separately to the odd and even terms of an o.i.d.
sequence, we obtain the following result.
Proposition 2.7 (SLLN for o.i.d. sequences). Let { Xn : n ≥0 } be a
sequence of o.i.d. random variables, and suppose that µ = E [X0] < ∞.
Then
lim
n→∞
¯Xn = µ a.s..
Deﬁnition 2.8. A sequence { Xn : n ≥0 } is (strictly) stationary if (X0,
X1, . . . , Xk) and (Xn, Xn+1, . . . , Xn+k) are identically distributed for all
k, n ≥0.
For a stationary process { Xn : n ≥0 } and k, l ≥0, set Fk
0 = σ⟨X0, . . . ,
Xk⟩and F∞
l
= σ⟨Xl, Xl+1, . . .⟩. Then { Xn : n ≥0 } is said to be φ-mixing
if
sup
A∈Fk
0 ,B∈F∞
k+n
|P(B | A) −P(B)| ≤φn
for k, n ≥0, where limn→∞φn = 0. Heuristically, { Xn : n ≥0 } is φ-mixing
if the behavior of the process at widely separated points in time is approx-
imately independent. The following result extends both the standard and
random-index central limit theorems for i.i.d. random variables.
Proposition 2.9 (CLT for stationary sequences). Let { Xn : n ≥0 }
be a stationary sequence of random variables. Suppose that Var [X0] < ∞
and that the sequence is φ-mixing with 	
n φ1/2
n
< ∞. Then
∞

k=1
|Cov [X0, Xk] | < ∞

472
Appendix A. Selected Background
and
√n( ¯Xn −µ) ⇒σN(0, 1)
as n →∞, where σ2 = Var [X0] + 2 	∞
k=1 Cov [X0, Xk]. If, moreover,
N(t)/t
pr
→c as t →∞for some constant c ∈(0, ∞), then
4
N(t)( ¯XN(t) −µ) ⇒σN(0, 1)
as t →∞.
An important special case of the above result is the following limit the-
orem for one-dependent stationary (o.d.s.) sequences, which are trivially
φ-mixing.
Corollary 2.10 (CLT for o.d.s. sequences). Let { Xn : n ≥0 } be a
stationary sequence of one-dependent random variables, and suppose that
σ2 = Var [X0] < ∞. Then
√n( ¯Xn −µ) ⇒σN(0, 1)
as n →∞, where σ2 = Var [X0]+2 Cov [X0, X1]. If, moreover, N(t)/t
pr
→c
as t →∞for some constant c ∈(0, ∞), then
4
N(t)( ¯XN(t) −µ) ⇒σN(0, 1)
as t →∞.
Remark 2.11. Observe that o.d.s. sequences are a subclass of o.i.d. se-
quences: for the former class of sequences, the random vectors { (Xn, Xn+1,
. . . , Xn+k): n ≥0 } must be identically distributed for each k ≥0, whereas
for the latter class of sequences, this requirement need only hold for k = 0.
A.2.3
Renewal Processes
Consider a machine that fails after a random time and is immediately re-
placed (renewed), and suppose that the successive lifetimes of the machines
are i.i.d.. The associated “renewal counting process” counts the number of
renewals in the interval (0, t] and the “renewal process” is the sequence of
random times at which the renewals occur. Formally, let { Xn : n ≥0 } be
a sequence of i.i.d. random variables (the lifetimes) with common mean
µ and distribution function F. Set S0 = 0 and form the partial sums
Sn = X1 + · · · + Xn for n ≥1.
Deﬁnition 2.12. The process { Sn : n ≥0 } is a renewal process, and the
process { N(t): t ≥0 } deﬁned by
N(t) = sup { n ≥0: Sn ≤t }
is a renewal counting process.

A.2 Limit Theorems for Stochastic Processes
473
In a delayed renewal process, the distribution of X1, the time until the ﬁrst
renewal, may diﬀer from the common distribution of { Xn : n ≥2 }.
The partial sum Sn is distributed as the n-fold convolution8 F ∗n of F
with itself, and P { N(t) = n } = F ∗n(t) −F ∗(n+1)(t) for n, t ≥0. Set
m(t) = E [N(t)] =
∞

n=1
F ∗n(t)
for t ≥0. The renewal function m(t) is ﬁnite for t ≥0.
Proposition 2.13 (Elementary renewal theorem).
lim
t→∞
m(t)
t
= 1
µ.
Deﬁnition 2.14. Let h be a function deﬁned on ℜ+, and let
mn(δ) = inf { h(t): (n −1)δ ≤t ≤nδ }
and
mn(δ) = sup { h(t): (n −1)δ ≤t ≤nδ }
for δ > 0 and n ∈{ 1, 2, . . . }. The function h is directly Riemann integrable
(d.R.i.) if 	∞
n=1 |mn(δ)| < ∞and 	∞
n=1 |mn(δ)| < ∞for all δ > 0 and
lim
δ→0 δ
∞

n=1
mn(δ) = lim
δ→0 δ
∞

n=1
mn(δ).
A d.R.i. function is bounded and continuous almost everywhere with re-
spect to Lebesgue measure. A function h deﬁned on ℜ+ is d.R.i. if (1) h ≥0,
(2) h is nonincreasing, and (3)
 ∞
0
h(t) dt < ∞. Other suﬃcient conditions
for a function h that is bounded and continuous almost everywhere to be
d.R.i. are (1) h ≤g with g d.R.i., or (2) h(t) = 0 for all t outside of a
bounded set.
Deﬁnition 2.15. A distribution function F is spread out if F ∗n ≥G for
some n ≥1, where G is nonnegative, not identically zero, and absolutely
continuous.
In the terminology of Section 5.1.2, F is spread out if F ∗n has a density
component for some n ≥1. If F is spread out, then F is aperiodic as in
Deﬁnition 1.19 in Chapter 6.
8For distribution functions F and G of nonnegative random variables X and Y , the
convolution of F and G, denoted F ∗G, is deﬁned by (F ∗G)(t) =
 t
0 F(t −x) dG(x)
and is the distribution function of the random variable X + Y .

474
Appendix A. Selected Background
Proposition 2.16 (Key renewal theorem). Let m be a renewal func-
tion for a renewal process with interrenewal-time distribution function F,
and let h be a function deﬁned on ℜ+. Suppose that either
(i) F is aperiodic and h is directly Riemann integrable; or
(ii) F is spread out and h is bounded and integrable with limx→∞h(x) =
0.
Then
 t
0
h(t −x) dm(x) →1
µ
 ∞
0
h(x) dx
as t →∞, where µ =
 ∞
0
x dF(x).
A.2.4
Discrete-Time Markov Chains
To motivate the results for general state-space Markov chains that are given
in the text, we brieﬂy review some key results for chains evolving in discrete
time and having a ﬁnite or countably inﬁnite state space.
Deﬁnition 2.17. The stochastic process { Xn : n ≥0 } taking values in a
ﬁnite or countably inﬁnite state space S is a discrete-time Markov chain
(dtmc) if
P { Xn+1 = j | Xn, Xn−1, . . . , X0 } = P { Xn+1 = j | Xn } a.s.
for n ≥0 and j ∈S.
The above Markov property asserts that the future evolution of the process
depends on its past and its present only through the current state. Deﬁne
a vector µ whose ith entry is µi = P { X0 = i } for i ∈S. If, as we assume
throughout, there exists a matrix P = ∥pij∥such that
P { Xn+1 = j | Xn = i } ≡pij
for n ≥0 and i, j ∈S, then the dtmc is said to be time-homogeneous with
transition matrix P and initial probability vector µ. We often write Pµ for
the probability law of the chain to emphasize the dependence on the initial
probability vector µ. When µi = 1 for some i ∈S, then we write Pi instead
of Pµ. Similarly, we write Eµ and Ei to denote expectations.
A dtmc is irreducible if any state can be reached from any other state
in a ﬁnite number of state transitions: for each i, j ∈S, there exists an
integer n = n(i, j) ∈(0, ∞) such that pn
ij > 0, where pn
ij is the (i, j)th
entry of the nth power P n of the transition matrix P. State i is said to be
periodic with period d if pn
ii = 0 whenever n is not divisible by d, and d is
the greatest integer having this property. A state with period 1 is aperiodic.

A.2 Limit Theorems for Stochastic Processes
475
State i is recurrent if Pi { Xn = i i.o. } = 1; otherwise, state i is transient.
It can be shown that state i is recurrent if and only if Pi { τi < ∞} = 1,
where τi is the ﬁrst hitting time of state i: τi = inf { n > 0: Xn = i }. A
recurrent state i is positive recurrent if Ei [τi] < ∞; otherwise, state i is
null recurrent. If a dtmc is irreducible, then all states are transient, or all
states are null recurrent, or all states are positive recurrent; either all states
are aperiodic or, if one state is periodic with period d, then all states are
periodic with period d. If all states are transient, then the entire chain is
said to be transient, and similarly for other properties.
Proposition 2.18 (Foster’s criterion for recurrence). Let { Xn : n ≥
0 } be an irreducible dtmc with state space S and let S0 be a ﬁnite sub-
set of S. Then the chain is positive recurrent if there exist a nonnegative
real-valued function g deﬁned on S and a constant ϵ > 0 such that

j∈S
pij g(j) < ∞
for i ∈S0 and

j∈S
pij g(j) < g(i) −ϵ
for i ∈S −S0.
Observe that the two conditions in the theorem can be rewritten as
sup
i∈S0
Ei [g(X1) −g(X0)] < ∞
and
Ei [g(X1) −g(X0)] ≤−ϵ
for all i ∈S −S0.
A vector π = { πi : i ∈S } is a stationary distribution of a dtmc with
transition matrix P if π is a solution of πP = π and 	
i∈S πi = 1.
Proposition 2.19. Let { Xn : n ≥0 } be an irreducible positive recurrent
dtmc with state space S. Then there exists a unique stationary distribution
π given by
πi =
1
Ei [τi].
An irreducible, aperiodic, and positive recurrent dtmc is called ergodic.
Proposition 2.20. Let { Xn : n ≥0 } be an ergodic dtmc with state space
S and stationary distribution π. Then
lim
n→∞pn
ij = πj
for i, j ∈S.

476
Appendix A. Selected Background
Proposition 2.21. Let { Xn : n ≥0 } be an irreducible positive recurrent
dtmc with state space S and stationary distribution π. Also, let f be a
real-valued function deﬁned on S such that

i∈S
πi|f(i)| < ∞.
Then
lim
n→∞
1
n
n−1

i=0
f(Xi) = π(f) a.s.
for any initial distribution µ, where π(f) = 	
i∈S πif(i). If, moreover,
σ2(f) < ∞, where
σ2 = πiEi
!)τi−1

j=0

f(Xj) −π(f)
*2"
and i is a ﬁxed element of S, then
1
√n
n−1

j=0

f(Xj) −π(f)

⇒σN(0, 1)
as n →∞for any initial distribution µ.
A.2.5
Brownian Motion and FCLTs
The central limit theorems given so far assert the convergence of a sequence
of random variables to a limiting normal random variable. Typically, each
random variable in the sequence is a suitably normalized partial sum. A
functional central limit theorem (fclt) is a generalization of a clt and
asserts the convergence of a sequence of random functions to a limiting
random process. In our setting the limiting random process is always a
Brownian motion. In this subsection we deﬁne what “convergence in dis-
tribution” means in this more general setting, give some basic properties
of Brownian motion, and discuss Donsker’s theorem. This latter result is
the simplest fclt and generalizes the central limit theorem for i.i.d. ran-
dom variables. We also give extensions of Donsker’s theorem to dependent
random variables and random numbers of random variables.
Recall that for real-valued random variables X, X1, X2, . . . with corre-
sponding distributions µ, µ1, µ2, . . . we have Xn ⇒X if and only if
E [f(Xn)] →E [f(X)]
for every bounded continuous real-valued function f. We now take this
latter condition as the deﬁnition of convergence in distribution for random

A.2 Limit Theorems for Stochastic Processes
477
variables X, X1, X2, . . . that take values in an arbitrary metric space S.
In this setting we say that the probability measures { µn : n ≥0 } converge
weakly to µ and that the “random elements” { Xn : n ≥0 } converge weakly
to X.
For our purposes, the space S of interest is the space of continuous real-
valued functions deﬁned on [0, 1]—we denote this space by C[0, 1]. The
space C[0, 1] can be metrized by the uniform metric:
ρ(x, y) = sup
0≤t≤1
|x(t) −y(t)|
for x, y ∈C[0, 1]. Thus a sequence of elements x1, x2, . . . ∈C[0, 1] converges
to x ∈C[0, 1] if and only if limn→∞sup0≤t≤1 |xn(t) −x(t)| = 0. We denote
by C[0, 1] the Borel sets of C[0, 1], that is, the σ-ﬁeld generated by the
open9 subsets of C[0, 1] with respect to ρ.
Wiener measure is deﬁned to be the unique probability measure W on
(C[0, 1], C[0, 1]) having the following properties.
1. W { x: x(0) = 0 } = 1.
2. For all t ∈(0, 1] and a ∈ℜ,
W { x: x(t) ≤a } =
1
√
2πt
 a
−∞
e−u2/2t du.
3. For 0 ≤t0 ≤t1 ≤· · · ≤tk ≤1 and a1, . . . , ak ∈ℜ,
W
) k:
i=1

x: x(ti) −x(ti−1) ≤ai
*
=
k

i=1
W { x: x(ti) −x(ti−1) ≤ai } .
A random element taking values in (C[0, 1], C[0, 1]) and having distribution
W is called a one-dimensional Brownian motion or Wiener process. With
a slight abuse of notation, we denote this process by W = { W(t): 0 ≤
t ≤1 }. It follows from the properties of Wiener measure that a Brownian
motion W satisﬁes the following conditions.
1. W(0) = 0 with probability 1.
2. W has continuous sample paths.
3. W(t) is distributed as N(0, t) for each t ∈(0, 1].
9Recall that a set A ⊆S is open if for each x ∈A there exists r > 0 such that
Br(x) ⊆A, where Br(x) = { y ∈S : ρ(x, y) ≤r }.

478
Appendix A. Selected Background
Figure A.1. The function Un(t) in Donsker’s theorem.

A.2 Limit Theorems for Stochastic Processes
479
4. For 0 ≤t0 ≤t1 ≤· · · ≤tk ≤1, the increments W(t1) −W(t0), . . . ,
W(tk) −W(tk−1) are mutually independent.
We are now ready to state Donsker’s theorem. Let { Xn : n ≥0 } be a
sequence of i.i.d. random variables with common mean 0. Deﬁne a sequence
of random functions, each with sample paths in C[0, 1], by setting
Un(t) =
1
√n
 nt
0
X⌊u⌋du
(2.22)
for 0 ≤t ≤1 and n ≥1, where ⌊x⌋is the greatest integer less than or equal
to x. Setting S−1 = 0 and Si = X0 + X1 + · · · + Xi for i ≥0, we observe
that Un(t) = Si−1/√n for t = i/n (i = 0, 1, . . . , n). If i/n < t < (i + 1)/n
for some i, then the value of Un(t) is obtained by linearly interpolating
between Si−1/√n and Si/√n. The function Un is sometimes expressed
using a slightly more cumbersome notation:
Un(t) =
1
√n
⌊nt⌋−1

i=0
Xi + (nt −⌊nt⌋) 1
√nX⌊nt⌋.
Some sample paths of Un are shown in Figure A.1 for n = 1, 2, 3, and 10,
based on a hypothetical realization of { Xn : n ≥0 }.
Proposition 2.23 (Donsker’s theorem). Let { Un : n ≥1 } and W be
deﬁned as above. If σ2 = Var [X0] < ∞, then Un ⇒σW as n →∞, where
⇒denotes weak convergence in C[0, 1].
The power of Donsker’s theorem derives from that fact that many of the
key results for convergence in distribution, such as the continuous mapping
theorem, carry over to the setting of C[0, 1]. It can be shown, for exam-
ple, that the coordinate projection mapping x →x(1) is continuous on
C[0, 1], so that Un(1) ⇒σW(1), where ⇒denotes convergence in distri-
bution for ordinary random variables. Since, as discussed above, W(1) is
distributed as N(0, 1), we recover the central limit theorem for i.i.d. ran-
dom variables. As another example, the limiting distribution of a quantity
such as max0≤k≤n Sn can be obtained by analyzing the relatively tractable
random variable
M = sup
0≤t≤1
W(t),
because the mapping x →sup0≤t≤1 x(t) is continuous on C[0, 1].
Proposition 2.24 extends Donsker’s theorem to φ-mixing sequences of
stationary random variables. In the proposition, ⇒denotes weak conver-
gence in C[0, 1].
Proposition 2.24. Let { Xn : n ≥0 } be a stationary sequence of random
variables with common mean 0, and deﬁne functions { Un : n ≥1 } as in
(2.22). If Var [X0] < ∞and { Xn : n ≥0 } is φ-mixing with 	
n φ1/2
n
< ∞,

480
Appendix A. Selected Background
then 	∞
k=1 |Cov [X0, Xk] | < ∞and Un ⇒σW as n →∞, where σ2 =
Var [X0] + 2 	∞
k=1 Cov [X0, Xk].
Donsker’s theorem can also be extended to a sequence of ℜl-valued i.i.d.
random vectors X1, X2, . . . having common mean vector µ and common
covariance matrix Σ. In this setting, convergence occurs in Cl[0, 1], the
space of ℜl-valued functions on [0, 1] having continuous sample paths. When
Σ is equal to the l × l identity matrix I(l), the limiting random function is
easily seen to be an l-dimensional standard Brownian motion
W (l) =
 
W (l)
1 (t), . . . , W (l)
l
(t)

: 0 ≤t ≤1

in which the component processes W (l)
1 , W (l)
2 , . . . , W (l)
l
are mutually inde-
pendent one-dimensional Brownian motions. For a general covariance ma-
trix Σ, we can write Σ = QQt for some matrix Q, and the limiting random
function is given by QW (l). Proposition 2.24 can similarly be extended.
The following result can be used to extend both Donsker’s theorem and
Proposition 2.24 to permit a random index in the partial sums.
Proposition 2.25. Suppose that
Un ⇒QW (l)
as n →∞, where { Un : n ≥0 } is a sequence of random elements of Cl[0, 1]
for some l ≥1 and W (l) is a standard l-dimensional Brownian motion. Also
suppose that N(t)/t
pr
→c as t →∞for some constant c ∈(0, ∞). Then
UN(t) ⇒QW (l)
as t →∞.
A.3
Terminology Used in the Text
In the main text we suppress measure-theoretic terminology wherever pos-
sible. To do this, the following conventions are used:
• Whenever, for instance, a result on a probability space (Ω, F, P) is
said to hold for “all subsets A” or “all functions” f, we mean that
the result holds for all measurable subsets A ∈F or all measurable
functions f.
• As mentioned previously, a conditional expectation such as E [X | Y ]
is interpreted as E [X | σ⟨Y ⟩], and this convention carries over to con-
ditional probabilities. For a random variable Y , a process { Xn : n ≥
0 }, and a nonnegative random index K that is a stopping time with
respect to { Xn : n ≥0 }, an expression such as E[Y | X0, X1, . . . , XK]

A. Notes
481
or E[Y | K, X0, X1, . . . , XK] is interpreted as E [Y | FK], where the
σ-ﬁeld FK is deﬁned as in Section A.2.1. As a special case, the no-
tation E[Y | X0, X1, . . . , Xn] is interpreted to mean E [Y | F], where
F = σ⟨X0, X1, . . . , Xn⟩.
Notes
Billingsley (1986), Breiman (1968), Chung (1974), Durrett (1991), and
Lo´eve (1977) provide excellent treatments of probability and measure at
the level given in this Appendix. Texts on stochastic processes include As-
mussen (1987a), C¸inlar (1975), Doob (1953), Karlin and Taylor (1975), and
Ross (1983). Gut (1988) studies sums of random numbers of i.i.d. random
variables—in particular, the proof of Proposition 1.20 is contained in the
proof of Gut’s Theorem I.5.2. Discussions of weak convergence, Brownian
motion, and fclts can be found in Billingsley (1968), Ethier and Kurtz
(1986), and Whitt (2002). Glasserman and Yao (1994) discuss the use of
the space ([0, 1]∞, B∞
0 , µLeb
∞), deﬁned in Example 2.2, for construction of
stochastic processes associated with discrete-event systems. Serﬂing (1980)
surveys basic limit theorems that arise in mathematical statistics, including
many of the results discussed in this appendix.

This page intentionally left blank 

References
Aggarwal, S., Garay, J., and Herzberg, A. (1995). Adaptive video-on-
demand. In Algorithms - ESA ’95 (Proc. Third Annual European
Symposium on Algorithms), Vol. 979 of Lecture Notes in Com-
puter Science, 538–553. Springer-Verlag.
Ajmone Marsan, M., Balbo, G., Chiola, G., and Conte, G. (1987).
Generalized stochastic Petri nets revisited: Random switches and
priorities. In Intl. Workshop Petri Nets Performance Models, 44–
53. IEEE Computer Society Press.
Ajmone Marsan, M., Balbo, G., Donatelli, S., and Franceschinis, G.
(1995). Modelling with Generalized Stochastic Petri Nets. Wiley,
New York.
Ajmone Marsan, M., Conte, G., and Balbo, G. (1984). A class of
generalized stochastic Petri nets for the performance evaluation
of multiprocessor systems. ACM Trans. Comput. Sys. 2, 93–122.
Altman, E., Konstantopoulos, P., and Liu, Z. (1992). Stability,
monotonicity and invariant quantities in general polling systems.
Queueing Sys. Theory Appl. 11, 35–57.
Anderson, T. W. (1971). The Statistical Analysis of Time Series.
Wiley, New York.
Andradottir, S. (1998). Simulation optimization. In J. Banks (ed.),
Handbook of Simulation. Wiley, New York.

484
References
Andradottir, S., Calvin, J. M., and Glynn, P. W. (1994). Increasing
the frequency of regeneration for Markov processes. In Proc. 1994
Winter Simulation Conference, 320–323.
Archibald, G., Karabakal, N., and Karlsson, P. (1999). Supply chain
vs. supply chain: Using simulation to compete beyond the four
walls. In Proc. 1999 Winter Simulation Conference, 1207–1214.
Asmussen, S. (1987a). Applied Probability and Queues. Wiley, New
York.
Asmussen, S. (1987b). Validating the heavy traﬃc performance of
regenerative simulation. Comm. Statist. Stochastic Models 5, 617–
628.
Asmussen, S. and Foss, S. G. (1993). Renovation, regeneration, and
coupling in multiple-server queues in continuous time. Frontiers
Pure Appl. Probab. 1, 1–6.
Athreya, K. B. and Ney, P. (1978). A new approach to the limit
theory of recurrent Markov chains. Trans. Amer. Math. Soc. 245,
493–501.
Baccelli, F. (1992). Ergodic theory of stochastic Petri networks. Ann.
Probab. 20, 375–396.
Baccelli, F. and Canales, M. (1993). Parallel simulation of stochastic
Petri nets using recurrence equations. ACM Trans. Model. Com-
put. Simul. 3, 20–41.
Baccelli, F., Cohen, G., Olsder, G. J., and Quadrat, J.-P. (1993). Syn-
chronization and Linearity: An Algebra for Discrete Event Sys-
tems. Wiley, Chichester, England.
Baccelli, F., Foss, S., and Gaujal, B. (1996). Free-choice Petri nets—
An algebraic approach. IEEE Trans. Automatic Control 41,
1751–1778.
Baccelli, F. and Schmidt, V. (1996). Taylor series expansions for
Poisson-driven (max, +)-linear systems. Ann. Applied Probab. 6,
138–185.
Banks, J. (ed.) (1998). Handbook of Simulation. Wiley, New York.
Barlow, R. E. and Proschan, F. (1975). Statistical Theory of Reli-
ability and Life Testing: Probability Models. Holt, Reinhart and
Winston, New York.
Bergman, C. D. and Shedler, G. S. (1993). Estimation procedures for
discrete event simulations using SPSIM. IBM Research Report
RJ 9317, IBM Almaden Research Center, San Jose, CA.
Billingsley, P. (1968). Convergence of Probability Measures. Wiley,
New York.

References
485
Billingsley, P. (1986). Probability and Measure. Wiley, New York.
Bobbio, A., Kulkarni, V. G., Puliaﬁto, A., Telek, M., and Trivedi,
K. S. (1995). Preemptive repeat identical transitions in Markov
regenerative stochastic Petri nets. In Proc. Sixth Intl. Workshop
Petri Nets Performance Models, 113–123. IEEE Computer Soci-
ety Press.
Borovkov, A. A. (1984). Asymptotic Methods in Queueing Theory.
Wiley, New York.
Borovkov, A. A. (1986). Limit theorems for queuing networks I. The-
ory Probab. Appl. 31, 413–427.
Borovkov, A. A. and Foss, S. G. (1992). Stochastically recursive se-
quences and their generalizations. Siberian Adv. Math. 2, 16–81.
Boucherie, R. J. (1994). A characterization of independence for com-
peting Markov chains with applications to stochastic Petri nets.
IEEE Trans. Software Engrg. 20, 536–544.
Bratley, P., Fox, B. L., and Schrage, L. E. (1987). A Guide to Simu-
lation, 2nd ed. Springer-Verlag, New York.
Breiman, L. (1968). Probability. Addison-Wesley, Reading, MA.
Brillinger, D. R. (1973). Estimation of the mean of a stationary time
series by sampling. J. Appl. Probab. 10, 419–431.
Brockwell, P. J. and Davis, R. A. (1987). Time Series: Theory and
Methods. Springer-Verlag, New York.
Brown, M. and Ross, S. M. (1972). Asymptotic properties of cumu-
lative processes. SIAM J. Appl. Math. 22, 93–105.
Buzacott, J. A. and Shanthikumar, G. S. (1993). Stochastic Models
of Manufacturing Systems. Prentice Hall, Englewood Cliﬀs, NJ.
Calvin, J. (1994). Return state independent quantities in regenerative
simulation. Oper. Res. 42, 531–542.
Calvin, J. and Nakayama, M. (2000). Simulation of processes with
multiple regeneration points. Probab. Engrg. Inform. Sci. 14, 179–
201.
Campos, J., Colom, J. M., Chiola, G., and Silva, M. (1989).
Tight polynomial bounds for steady-state performance of marked
graphs. In Proc. Third Intl. Workshop Petri Nets Performance
Models, 200–209. IEEE Computer Society Press.
Campos, J., Colom, J. M., Jungnitz, H., and Silva, M. (1994). Ap-
proximate throughput computation for stochastic marked graphs.
IEEE Trans. Software Engrg. 20, 526–535.

486
References
Carlstein, E. (1986). The use of subseries for estimating the variance
of a general statistic from a stationary sequence. Ann. Statist. 14,
1171–1179.
Cassandras, C. G. and LaFortune, S. (1999). Introduction to Discrete
Event Systems. Kluwer Academic, Boston.
Chan, T. F., Golub, G. H., and LeVeque, R. J. (1983). Algorithms for
computing the sample variance: Analysis and recommendation.
Amer. Statist. 37, 242–247.
Chien, C. (1989). Small sample theory for steady state conﬁdence in-
tervals. Tech. Rep. 37, Depatment of Operations Research, Stan-
ford University, Stanford, CA.
Chien, C., Goldsman, D., and Melamed, B. (1997). Large-sample re-
sults for batch means. Management Sci. 43, 1288–1295.
Chiola, G. (1991). Simulation framework for timed and stochastic
Petri nets. Intl. J. Comput. Simulation 1, 153–168.
Chiola, G. (1995). Characterization of timed well-formed Petri nets
behavior by means of occurrence equations. In Proc. Sixth Intl.
Workshop Petri Nets Performance Models, 127–136. IEEE Com-
puter Society Press.
Chiola, G., Bruno, G., and Demaria, T. (1988). Introducing a color
formalism into generalized stochastic Petri nets. In Proc. 9th Eu-
ropean Workshop Appl. Theory Petri Nets.
Chiola, G., Dutheillet, C., Franceschinis, G., and Haddad, S. (1993).
Stochastic well-formed colored nets and symmetric modeling ap-
plications. IEEE Trans. Comput. 42, 1343–1360.
Choi, H., Kulkarni, V. G., and Trivedi, K. S. (1994). Markov regener-
ative stochastic Petri nets. Performance Evaluation 20, 337–357.
Erratum: Performance Evaluation, vol. 21, p. 271, 1995.
Chung, K. L. (1967). Markov Chains with Stationary Transition Prob-
abilities, 2nd ed. Springer-Verlag, Berlin.
Chung, K. L. (1974). A Course in Probability Theory, 2nd ed. Aca-
demic Press, New York.
C¸inlar, E. (1975). Introduction to Stochastic Processes. Prentice Hall,
Englewood Cliﬀs, NJ.
Coleman, J. L. (1993). Algorithms for product-form stochastic Petri
nets—A new approach. In Proc. Fifth Intl. Workshop Petri Nets
Performance Models. IEEE Computer Society Press.
Conway, R. W. (1963). Some tactical problems in digital simulation.
Management Sci. 10, 47–61.

References
487
Cox, D. R. (1952). Estimation by double sampling. Biometrika 39,
217–227.
Coyle, A. J. and Taylor, P. G. (1995). Tight bounds on the insensitiv-
ity of generalized semi-Markov processes with a single generally
distributed lifetime. J. Appl. Probab. 32, 63–73.
Crane, M. A. and Iglehart, D. L. (1975). Simulating stable stochastic
systems: III, regenerative processes and discrete event simulation.
Oper. Res. 23, 33–45.
Crane, M. A. and Lemoine, A. J. (1977). An Introduction to the
Regenerative Method for Simulation Analysis. Lecture Notes in
Control and Information Sciences. Springer-Verlag, New York.
Dai, J. G. (1995). On positive Harris recurrence of multiclass queue-
ing networks: A uniﬁed approach via ﬂuid limit models. Ann.
Applied Probab. 5, 49–77.
Damerdji, H. (1991). Strong consistency and other properties of the
spectral variance estimator. Management Sci. 37, 1424–1440.
Damerdji, H. (1994). Strong consistency of the variance estimator
in steady-state simulation output analysis. Math. Oper. Res. 19,
494–512.
Damerdji, H. (1995). Mean-square consistency of the variance esti-
mator in steady-state simulation output analysis. Oper. Res. 43,
282–291.
Damerdji, H. and Goldsman, D. (1995). Consistency of several vari-
ants of the standardized time series area variance estimator. Naval
Res. Logist. Quart. 42, 1161–1176.
Doob, J. L. (1953). Stochastic Processes. Wiley, New York.
Durrett, R. (1991). Probability: Theory and Examples. Wadsworth
and Brooks/Cole, Paciﬁc Grove, CA.
Efron, B. and Tibshirani, R. J. (1993). An Introduction to the Boot-
strap. Chapman and Hall, London.
Eswaran, K. P., Hamacher, V. C., and Shedler, G. S. (1978). Collision-
free access control for computer communication bus networks.
IEEE Trans. Software Engrg. SE-7, 574–582.
Ethier, S. N. and Kurtz, T. G. (1986). Markov Processes: Character-
ization and Convergence. Wiley, New York.
Ferscha, A. and Richter, M. (1997). Time Warp simulation of timed
Petri nets: Sensitivity of adaptive methods. In Proc. Seventh Intl.
Workshop Petri Nets Performance Models, 205–216. IEEE Com-
puter Society Press.

488
References
Foss, S. G. and Kalashnikov, V. (1991). Regeneration and renovation
in queues. Queueing Sys. Theory Appl. 8, 211–224.
Fox, B. L. and Glynn, P. W. (1985). Discrete-time conversion for
simulating semi-Markov processes. Oper. Res. Lett. 5, 191–196.
Fox, B. L. and Glynn, P. W. (1987). Estimating time averages via
randomly-spaced observations. SIAM J. Appl. Math. 47, 186–200.
Fox, B. L. and Glynn, P. W. (1989). Simulating discounted costs.
Management Sci. 35, 1297–1315.
Fox, B. L., Goldsman, D., and Swain, J. J. (1991). Spaced batch
means. Oper. Res. Lett. 10, 255–263.
Gaeta, R. and Chiola, G. (1995). Eﬃcient simulation of SWN models.
In Proc. Sixth Intl. Workshop Petri Nets Performance Models,
137–146. IEEE Computer Society Press.
Genrich, H. J. and Lautenbach, K. (1981). System modelling with
high-level Petri nets. Theoret. Comput. Sci. 13, 109–136.
Glasserman, P. (1991). Gradient Estimation via Perturbation Analy-
sis. Kluwer Academic, Boston.
Glasserman, P. and Glynn, P. W. (1992). Gradient estimation for
regenerative processes. In Proc. 1992 Winter Simulation Confer-
ence, 280–288.
Glasserman, P. and Yao, D. D. (1994). Monotone Structure in
Discrete-Event Systems. Wiley, New York.
Glynn, P. W. (1982a). Asymptotic theory for nonparametric con-
ﬁdence intervals. Tech. Rep. 63, Department of Operations Re-
search, Stanford University, Stanford, CA.
Glynn, P. W. (1982b). Simulation output analysis for general state
space Markov chains. Ph.D. Dissertation, Department of Opera-
tions Research, Stanford University, Stanford, CA.
Glynn, P. W. (1987). A low bias steady-state estimator for equi-
librium processes. Tech. Rep. 47, Department of Operations Re-
search, Stanford University, Stanford, CA.
Glynn, P. W. (1989a). The covariance function of a regenerative pro-
cess. Tech. Rep. 49, Department of Operations Research, Stanford
University, Stanford, CA.
Glynn, P. W. (1989b). A GSMP formalism for discrete event systems.
Proc. IEEE 77, 14–23.
Glynn, P. W. (1989c). Likelihood ratio derivative estimators for sto-
chastic systems. In Proc. 1989 Winter Simulation Conference,
374–380.

References
489
Glynn, P. W. (1994). Some topics in regenerative steady-state simu-
lation. Acta Appl. Math. 34, 225–236.
Glynn, P. W. and Haas, P. J. (2002a). Consistent estimation of the
variance in steady-state simulation output analysis. IBM Research
Report, IBM Almaden Research Center, San Jose, CA.
Glynn, P. W. and Haas, P. J. (2002b). Laws of large numbers and
central limit theorems for discrete-event systems. IBM Research
Report, IBM Almaden Research Center, San Jose, CA.
Glynn, P. W. and Heidelberger, P. (1990). Bias properties of budget
constrained simulations. Oper. Res. 38, 801–814.
Glynn, P. W. and Heidelberger, P. (1992). Jackkniﬁng under a budget
constraint. ORSA J. Comput. 4, 226–234.
Glynn, P. W. and Iglehart, D. L. (1986a). Consequences of uniform
integrability for simulation. Tech. Rep. 15, Department of Oper-
ations Research, Stanford University, Stanford, CA.
Glynn, P. W. and Iglehart, D. L. (1986b). Estimation of steady state
central moments by the regenerative method of simulation. Oper.
Res. Lett. 5, 271–276.
Glynn, P. W. and Iglehart, D. L. (1987). A joint central limit theorem
for the sample mean and regenerative variance estimator. Ann.
Oper. Res. 8, 41–55.
Glynn, P. W. and Iglehart, D. L. (1988). Simulation methods for
queues: An overview. Queueing Sys. Theory Appl. 3, 221–256.
Glynn, P. W. and Iglehart, D. L. (1989). Smoothed limit theorems
for equilibrium processes. In T. W. Anderson, K. B. Athreya,
and D. L. Iglehart (eds.), Probability, Statistics, and Mathematics:
Papers in Honor of Samuel Karlin. Academic Press, New York.
Glynn, P. W. and Iglehart, D. L. (1990). Simulation output analysis
using standardized time series. Math. Oper. Res. 15, 1–16.
Glynn, P. W. and Iglehart, D. L. (1993). Conditions for the applicabil-
ity of the regenerative method. Management Sci. 39, 1108–1111.
Glynn, P. W. and L’Ecuyer, P. (1995). Likelihood ratio gradient es-
timation for stochastic recursions. Adv. Appl. Probab. 27, 1019–
1053.
Glynn, P. W. and Meyn, S. P. (1996). A Lyapunov bound for solutions
of Poisson’s equation. Ann. Probab. 24, 916–931.
Glynn, P. W. and Sigman, K. (1992). Uniform cesaro limit theorems
for synchronous processes with applications to queues. Stochastic
Process. Appl. 40, 29–44.

490
References
Glynn, P. W. and Whitt, W. (1986). A central-limit-theorem version
of L = λW. Queueing Sys. Theory Appl. 2, 191–215.
Glynn, P. W. and Whitt, W. (1987). Suﬃcient conditions for the
functional-central-limit-theorem versions of L = λW. Queueing
Sys. Theory Appl. 1, 279–287.
Glynn, P. W. and Whitt, W. (1988). Ordinary CLT and WLLN ver-
sions of L = λW. Math. Oper. Res. 13, 693–710.
Glynn, P. W. and Whitt, W. (1989). Indirect estimation via L = λW.
Oper. Res. 37, 82–103.
Glynn, P. W. and Whitt, W. (1992a). The asymptotic eﬃciency of
simulation estimators. Oper. Res. 40, 505–520.
Glynn, P. W. and Whitt, W. (1992b). The asymptotic validity of
sequential stopping rules for stochastic simulation. Ann. Applied
Probab. 2, 180–198.
Gnedenko, B. V. and Kovalenko, I. N. (1974). Introduction to Queue-
ing Theory, German ed. Akademie-Verlag, Berlin.
Goldsman, D., Meketon, M. S., and Schruben, L. W. (1990). Proper-
ties of standardized time series weighted area variance estimators.
Management Sci. 36, 602–612.
Goldsman, D. and Nelson, B. L. (1998). Comparing systems via sim-
ulation. In J. Banks (ed.), Handbook of Simulation. Wiley, New
York.
Goldsman, D. and Schruben, L. (1990). New conﬁdence interval esti-
mators using standardized time series. Management Sci. 36, 393–
397.
Goyal, A., Shahabuddin, P., Heidelberger, P., Nicola, V., and Glynn,
P. (1992). A uniﬁed framework for simulating Markovian models
of highly dependable systems. IEEE Trans. Comput. 41, 36–51.
Grenander, U. and Rosenblatt, M. (1984). Statistical Analysis of Sta-
tionary Time Series, 2nd ed. Chelsea, New York.
Gut, A. (1988). Stopped Random Walks: Limit Theorems and Appli-
cations. Springer-Verlag, New York.
Haas, P. J. (1999a). Estimation methods for non-regenerative sto-
chastic Petri nets. IEEE Trans. Software Engrg. 25, 218–236.
Haas, P. J. (1999b). Estimation of delays in non-regenerative stochas-
tic Petri nets. IBM Research Report RJ 10138, IBM Almaden
Research Center, San Jose, CA.
Haas, P. J. (1999c). On simulation output analysis for generalized
semi-Markov processes. Comm. Statist. Stochastic Models 15, 53–
80.

References
491
Haas, P. J. and Shedler, G. S. (1985a). Regenerative simulation meth-
ods for local area computer networks. IBM J. Res. Develop. 29,
194–205.
Haas, P. J. and Shedler, G. S. (1985b). Regenerative simulation of
stochastic Petri nets. In Intl. Workshop Timed Petri Nets, 14–23.
IEEE Computer Society Press.
Haas, P. J. and Shedler, G. S. (1986). Regenerative stochastic Petri
nets. Performance Evaluation 6, 189–204.
Haas, P. J. and Shedler, G. S. (1987a). Recurrence and regeneration
in non-Markovian networks of queues. Comm. Statist. Stochastic
Models 3, 29–52.
Haas, P. J. and Shedler, G. S. (1987b). Regenerative generalized semi-
Markov processes. Comm. Statist. Stochastic Models 3, 409–438.
Haas, P. J. and Shedler, G. S. (1987c). Stochastic Petri nets with
simultaneous transition ﬁrings. In Intl. Workshop Petri Nets Per-
formance Models, 24–32. IEEE Computer Society Press.
Haas, P. J. and Shedler, G. S. (1988). Modelling power of stochastic
Petri nets for simulation. Probab. Engrg. Inform. Sci. 2, 435–459.
Haas, P. J. and Shedler, G. S. (1989a). Stochastic Petri net represen-
tation of discrete event simulations. IEEE Trans. Software Engrg.
15, 381–393.
Haas, P. J. and Shedler, G. S. (1989b). Stochastic Petri nets with
timed and immediate transitions. Comm. Statist. Stochastic Mod-
els 5, 563–600.
Haas, P. J. and Shedler, G. S. (1991). Stochastic Petri nets: Modeling
power and limit theorems. Probab. Engrg. Inform. Sci. 5, 477–498.
Haas, P. J. and Shedler, G. S. (1992). Simulation methods for manu-
facturing systems using stochastic Petri nets. IBM Research Re-
port RJ 8672, IBM Almaden Research Center, San Jose, CA.
Haas, P. J. and Shedler, G. S. (1993a). Estimation of passage times
via equilibrium processes with one-dependent cycles. IBM Re-
search Report RJ 9520, IBM Almaden Research Center, San Jose,
CA.
Haas, P. J. and Shedler, G. S. (1993b). Passage times in colored
stochastic Petri nets. Comm. Statist. Stochastic Models 9, 31–79.
Haas, P. J. and Shedler, G. S. (1995). One-dependent cycles and pas-
sage times in stochastic Petri nets. In Proc. Sixth Intl. Workshop
Petri Nets Performance Models, 191–202. IEEE Computer Soci-
ety Press.

492
References
Haas, P. J. and Shedler, G. S. (1996). Estimation methods for passage
times using one-dependent cycles. Discrete Event Dynam. Sys.
Theory Appl. 6, 43–72.
Hack, M. (1975). Decidability questions for Petri nets. Ph.D. Dis-
sertation, Department of Electrical Engineering, Massachusetts
Institute of Technology, Cambridge, MA.
Hall, P. and Heyde, C. C. (1980). Martingale Limit Theory and Its
Application. Academic Press, New York.
Heidelberger, P. (1979). A variance reduction technique that increases
regeneration frequency. In N. Adam and A. Dogramaci (eds.),
Current Issues in Computer Simulation. Academic Press, New
York.
Heidelberger, P. and Iglehart, D. L. (1979). Comparing stochastic
systems using regenerative simulation with common random num-
bers. Adv. Appl. Probab. 11, 804–819.
Heidelberger, P. and Lewis, P. A. W. (1981). Regression-adjusted es-
timates for regenerative simulations, with graphics. Comm. ACM
24, 260–273.
Heidelberger, P., Shahabuddin, P., and Nicola, V. (1994). Bounded
relative error in estimating transient measures of highly depend-
able non-Markovian systems. ACM Trans. Model. Comput. Simul.
4, 137–164.
Heidelberger, P. and Welch, P. D. (1981). A spectral method for con-
ﬁdence interval generation and run length control in simulation.
Comm. ACM 24, 233–245.
Henderson, S. G. and Glynn, P. (1999a). Can the regenerative method
be applied to discrete-event simulation? In Proc. 1999 Winter
Simulation Conference, 367–373.
Henderson, S. G. and Glynn, P. (1999b). Derandomizing variance
estimators. Oper. Res. 47, 907–916.
Henderson, S. G. and Glynn, P. (2001). Regenerative steady-state
simulation of discrete-event stochastic systems. ACM Trans.
Model. Comput. Simul. 11.
Hordijk, A., Iglehart, D. L., and Schassberger, R. (1976). Discrete
time methods for simulating continuous time Markov chains. Adv.
Appl. Probab. 8, 772–788.
Iglehart, D. L. (1975). Simulating stable stochastic systems, V: Com-
parison of ratio estimators. Naval Res. Logist. Quart. 22, 554–565.
Iglehart, D. L. (1976). Simulating stable stochastic systems, VI:
Quantile estimation. J. ACM 23, 347–360.

References
493
Iglehart, D. L. (1977). Simulating stable stochastic systems, VII: Se-
lecting the best system. In M. F. Neuts (ed.), Algorithmic Methods
in Probability, 37–50. North Holland, Amsterdam.
Iglehart, D. L. and Lewis, P. A. W. (1979). Regenerative simulation
with internal controls. J. ACM 26, 271–282.
Iglehart, D. L. and Shedler, G. S. (1980). Regenerative Simulation of
Response Times in Networks of Queues, Vol. 26 of Lecture Notes
in Control and Information Sciences. Springer-Verlag, Berlin.
Iglehart, D. L. and Shedler, G. S. (1983). Simulation of non-
Markovian systems. IBM J. Res. Develop. 27, 472–480.
Iglehart, D. L. and Shedler, G. S. (1984). Simulation output analysis
for local area computer networks. Acta Inform. 21, 321–338.
Iglehart, D. L. and Stone, M. (1983). Regenerative simulation for
estimating extreme values. Oper. Res. 31, 1145–1166.
Ingalls, R. G. and Kasales, C. (1999). CSCAT: The Compaq supply
chain analysis tool. In Proc. 1999 Winter Simulation Conference,
1201–1206.
Janˇcar, P. (2000). Bouziane’s algorithm for the Petri net reachability
problem is incorrect. Unpublished manuscript, Technical Univer-
sity of Ostrava, Czech Reublic.
Jensen, K. (1981). Coloured Petri nets and the invariant-method.
Theoret. Comput. Sci. 14, 317–336.
Jochens, H. W. and Shedler, G. S. (1989). Modelling and simulation
of stochastic systems with SPSIM. IBM Research Report RJ 6825,
IBM Almaden Research Center, San Jose, CA.
Kalashnikov, V. (1994). Topics on Regenerative Processes. CRC
Press, Boca Raton, FL.
Karlin, S. and Taylor, H. M. (1975). A First Course in Stochastic
Processes, 2nd ed. Academic Press, New York.
Kaspi, H. and Mandelbaum, A. (1992). Regenerative closed queueing
networks. Stochastics Stochastics Rep. 39, 239–258.
Kohlas, J. (1982). Stochastic Methods of Operations Research. Cam-
bridge University Press, Cambridge, England.
K¨onig, D., Matthes, K., and Nawrotzki, K. (1967). Verallgemein-
erungen der Erlangschen und Engsetschen Formeln. Akademie-
Verlag, Berlin.
K¨onig, D., Matthes, K., and Nawrotzki, K. (1974). Unempﬁndlich-
keitseigenshaften von Bedienungsprozessen. Appendix to Gne-
denko and Kovalenko (1974).

494
References
Kosaraju, S. (1973). Limitations of Dijkstra’s semaphore primitives
and Petri nets. Tech. rep., Computer Science Program, Johns
Hopkins University, Baltimore, MD.
Kosten, A. E. and Tchoudaikina, S. V. (1998). Yet another reacha-
bility algorithm for Petri nets. SIGACT News 29, 98–110.
Lavenberg, S. and Sauer, C. H. (1977). Sequential stopping rules for
the regenerative method of simulation. IBM J. Res. Develop. 21,
545–558.
Law, A. M. and Kelton, D. W. (2000). Simulation Modeling and Anal-
ysis, 3rd ed. McGraw-Hill, New York.
Lin, C. and Marinescu, D. C. (1988). Stochastic high-level Petri nets
and applications. IEEE Trans. Comput. 37, 815–825.
Lindemann, C. and Shedler, G. S. (1996). Numerical analysis of deter-
ministic and stochastic Petri nets with concurrent deterministic
transitions. Performance Evaluation 27/28, 565–582.
Lo´eve, M. (1977). Probability Theory, 4th ed. Springer-Verlag, New
York.
Loucks, W. M., Hamacher, V. C., and Preiss (1982). Performance of
short packet local area rings. Tech. Rep. 25, Departments of Elec-
trical Engineering and Computer Science, University of Toronto,
Toronto.
Matthes, K. (1962). Zur Theorie der Bedienungsprozessen. In Trans.
3rd Prague Conf. Inform. Theory Statist. Decision Functions, 39–
42.
Meketon, M. S. and Heidelberger, P. (1982). A renewal theoretic ap-
proach to bias reduction in regenerative simulations. Management
Sci. 28, 173–181.
Meketon, M. S. and Schmeiser, B. (1984). Overlapping batch means:
Something for nothing? In Proc. 1984 Winter Simulation Confer-
ence, 227–230.
Meyn, S. P. and Tweedie, R. L. (1993a). Markov Chains and Stochas-
tic Stability. Springer-Verlag, London.
Meyn, S. P. and Tweedie, R. L. (1993b). Stability of Markov processes
II: Continuous time processes and sampled chains. Adv. Appl.
Probab. 25, 487–517.
Meyn, S. P. and Tweedie, R. L. (1993c). Stability of Markov processes
III: Foster–Lyapunov criteria for continuous time processes. Adv.
Appl. Probab. 25, 518–548.
Miller, D. R. (1972). Existence of limits in regenerative processes.
Ann. Math. Statist. 43, 1275–1282.

References
495
Miller, D. R. (1974a). Limit theorems for path-functionals of regen-
erative processes. Stochastic Process. Appl. 2, 141–161.
Miller, R. G. (1974b). The jackknife—A review. Biometrika 61, 1–15.
Minh, D. L. (1987). Simulating GI/G/k queues in heavy traﬃc. Man-
agement Sci. 33, 1192–1199.
Miyazawa, M. (1993). Insensitivity and product-form decomposabil-
ity of reallocatable GSMP. Adv. Appl. Probab. 25, 415–437.
Molloy, M. K. (1981). On the integration of delay and throughput
measures in distributed processing models. Ph.D. Dissertation,
Department of Computer Science, University of California, Los
Angeles, CA.
Molloy, M. K. (1982). Performance analysis using stochastic Petri
nets. IEEE Trans. Comput. C-31, 913–917.
Morozov, E. V. (1994a). Regeneration of closed queueing networks.
J. Math. Sci. 69, 1186–1192.
Morozov, E. V. (1994b). Wide sense regenerative processes with
applications to multi-channel queues and networks. Acta Appl.
Math. 34, 189–212.
Morozov, E. V. (1998). Weak regenerative structure of open Jackson
queueing networks. J. Math. Sci. 91, 2956–2961.
Morozov, E. V. and Sigovtsev, S. G. (2000). Queueing process simu-
lation based on weak regeneration. Unpublished manuscript.
Motwani, R. and Raghavan, P. (1995). Randomized Algorithms. Cam-
bridge University Press, Cambridge, England.
Mu˜noz, D. F. and Glynn, P. W. (1997). A batch means methodology
for estimation of a nonlinear function of a steady-state mean.
Management Sci. 43, 1121–1135.
Mu˜noz, D. F. and Glynn, P. W. (2001). Multivariate standardized
time series for steady-state simulation output analysis. Oper. Res.
49, 413–422.
Muppala, J. K., Trivedi, K. S., Mainkar, V., and Kulkarni, V. G.
(1994). Numerical computation of response time distributions us-
ing stochastic reward nets. Ann. Oper. Res. 48, 155–184.
Murata, T. (1989). Petri nets: Properties, analysis, and applications.
Proc. IEEE 77, 541–580.
Nakayama, N. K. and Shahabuddin, P. (1998). Likelihood ratio gradi-
ent estimation for ﬁnite-time performance measures in generalized
semi-Markov processes. Management Sci. 44, 1426–1441.

496
References
Natkin, S. (1980). Les r´eseaux de Petri stochastiques et leur applica-
tion a l’evaluation des systemes informatiques. Th`ese de Docteur
Ing´enieur, Conservatoire National des Arts et Metier, Paris.
Natkin, S. (1985). Les r´eseaux de Petri stochastiques. Technique et
Science Informatiques 4, 143–160.
Nummelin, E. (1978). A splitting technique for Harris recurrent
chains. Z. Wahrscheinlichtkeitstheorie und Ver. Geb. 43, 309–318.
Nummelin, E. (1984). General Irreducible Markov Chains and Non-
Negative Operators. Cambridge University Press, Cambridge,
England.
´Olafsson, S. and Shi, L. (1999). Optimization via adaptive sampling
and regenerative simulation. In Proc. 1999 Winter Simulation
Conference, 666–672.
Peterson, J. L. (1981). Petri Net Theory and the Modeling of Systems.
Prentice Hall, Englewood Cliﬀs, NJ.
Prisgrove, L. A. and Shedler, G. S. (1986). Symmetric stochastic Petri
nets. IBM J. Res. Develop. 30, 278–293.
Puliaﬁto, A., Scarpa, M., and Trivedi, K. S. (1998). Petri nets with
K simultaneously enabled generally distributed timed transitions.
Performance Evaluation 32, 1–34.
Pyssysalo, T. and Ojala, L. (1995). A high-level net model of a video
on demand system. Research Report A36, Digital Systems Labo-
ratory, Helsinki University of Technology, Otaniemi, Finland.
Reisig, W. (1985). Petri Nets: An Introduction. EATCS Monographs
on Theoretical Computer Science. Springer-Verlag, Berlin.
Roberts, G. O. and Tweedie, R. L. (1999). Bounds on regeneration
times and convergence rates for Markov chains. Stochastic Pro-
cess. Appl. 80, 211–229.
Ross, S. M. (1983). Stochastic Processes. Wiley, New York.
Rubinstein, R. and Melamed, B. (1998). Modern Simulation and
Modeling. Wiley, New York.
Rubinstein, R. and Shapiro, A. (1993). Discrete Event Systems: Sen-
sitivity Analysis and Stochastic Optimization by the Score Func-
tion Method. Wiley, New York.
Schmeiser, B. (1982). Batch size eﬀects in the analysis of simulation
output. Oper. Res. 30, 556–568.
Schruben, L. W. (1983). Conﬁdence interval estimation using stan-
dardized time series. Oper. Res. 31, 1090–1108.
Seila, A. F. (1982). A batching approach to quantile estimation in
regenerative processes. Management Sci. 28, 573–581.

References
497
Serﬂing, R. J. (1980). Approximation Theorems of Mathematical
Statistics. Wiley, New York.
Shedler, G. S. (1987). Regeneration and Networks of Queues.
Springer-Verlag, New York.
Shedler, G. S. (1993). Regenerative Stochastic Simulation. Academic
Press, New York.
Shedler, G. S. (1994). Estimation of delay distributions with SPSIM.
IBM Research Report RJ 9874, IBM Almaden Research Center,
San Jose, CA.
Sigman, K. (1990a). Correction: Notes on the stability of closed
queueing systems. J. Appl. Probab. 27, 735.
Sigman, K. (1990b). One-dependent regenerative processes and
queues in continuous time. Math. Oper. Res. 15, 175–189.
Sigman, K. and Wolﬀ, R. (1993). A review of regenerative processes.
SIAM Rev. 2, 269–288.
Smith, W. L. (1955). Regenerative stochastic processes. Proc. Roy.
Soc. London Ser. A 232, 6–31.
Smith, W. L. (1958). Renewal theory and its ramiﬁcations. J. Roy.
Statist. Soc. Ser. B 20, 243–302.
Song, W. T. and Schmeiser, B. W. (1993). Variance of the sample
mean: Properties and graphs of quadratic-form estimators. Oper.
Res. 41, 501–517.
Song, W. T. and Schmeiser, B. W. (1995). Optimal mean-squared-
error batch sizes. Management Sci. 41, 110–123.
Symons, F. J. W. (1978). Modelling and analysis of communication
protocols using numerical Petri nets. Ph.D. Thesis, Department
of Electrical Engineering Science, University of Essex, Essex, Eng-
land.
Symons, F. J. W. (1980). The description and deﬁnition of queueing
systems by numerical Petri nets. Austral. J. Telecom. Res. 13,
20–31.
Thorisson, H. (2000). Coupling, Stationarity, and Regeneration.
Springer-Verlag, New York.
van der Aalst, W. M. P. (1998). The application of Petri nets to
workﬂow management. J. Circuits Sys. Comput. 8, 21–66.
Viswanadham, N. and Narahari, Y. (1988). Stochastic Petri net mod-
els for performance evaluation of automated manufacturing sys-
tems. Inform. Decision Tech. 14, 125–142.

498
References
Viswanadham, N. and Raghavan, N. S. (2000). Performance analysis
and design of supply chains: A Petri net approach. J. Operational
Res. Soc. 51, 1158–1169.
Welch, P. D. (1987). On the relationship between batch means, over-
lapping batch means, and spectral estimation. In Proc. 1987 Win-
ter Simulation Conference, 320–323.
Whitt, W. (1980). Continuity of generalized semi-Markov processes.
Math. Oper. Res. 5, 494–501.
Whitt, W. (2002). Stochastic-Process Limits. Springer-Verlag, New
York.
Xie, A., Kim, S., and Beerel, P. A. (1999). Bounding average time
separations of events in stochastic timed Petri nets with choice. In
Proc. 5th Intl. Sympos. Adv. Res. Asynchronous Circuits Systems
(ASYNC ’99), 94–107. IEEE Computer Society Press.
Zenie, A. (1985). Colored stochastic Petri nets. In Proc. Intl. Work-
shop Timed Petri Nets, 262–271. IEEE Computer Society Press.

Index
Airport shuttle, 335, 381, 382
Aperiodic
spn, 413
cycle length, 196, 197, 204,
231, 265, 354
distribution function, 196,
473
dtmc, 474
gssmc, 148, 300, 413
spn, 285, 300
vs. nonlattice and
nonarithmetic, 269
are, see Asymptotic relative
eﬃciency
Assumption CPD, 402
and aperiodicity, 413
and covariance function, 413
and drift criterion, 403
and fclt, 411, 412
and fclt for delays, 422
and Harris recurrence, 403,
410
and od-regeneration points,
410
and regeneration points, 407
and slln, 410, 411
and slln for delays, 422
Assumption PD, 151
and airport shuttle, 381
and aperiodicity, 285, 300
and batch means, 290
and covariance function, 302
and cyclic queues with four
servers, 380
and drift criterion, 152
and fclt, 286, 287
and fclt for delays, 373
and ﬂexible manufacturing
system, 157
and gradient estimation, 257
and Harris recurrence, 153,
284
and jackknifed batch means,
294
and jackknifed batch means
for delays, 376
and limiting average delay,
377
and machine repair system,
211

500
Index
and od-equilibrium points,
212, 284
and od-regeneration points,
284
and od-regeneration points
for delays, 367
and producer–consumer
system, 211
and regeneration points,
209, 212
and regenerative variance
constant, 229
and slln, 285, 286
and slln for delays, 373
and sts methods, 275, 288
and sts methods for delays,
366
and telephone system, 156,
211
and video on demand, 296
weakening of, 187, 318, 383
Asymptotic relative eﬃciency
of delay-estimation methods
in cspn, 438–443
of extended regenerative
and multiple-runs
methods, 268, 356
of low-bias regenerative
estimator, 241
Batch means
convergence of variance
estimators, 305, 306,
415
ﬁxed number of batches, 11,
289, 292
for delays, 374–376, 423
jackknifed estimator,
293–297, 375–376, 423
overlapping, 317
variable number of batches,
12, 305–306, 312, 414
Blocks
simulation of delays in,
428–431
simulation of marking
process in, 425–428
Bonferroni’s inequality, 80, 88,
352, 448
Boole’s inequality, 448
Borel sets, 449, 452, 468
of C[0, 1], 477
Borel–Cantelli
ﬁrst lemma, 216, 449
generalization, 88
second lemma, 185, 205, 449
Bounded variation, 439, 451
Brownian motion, 12, 275, 283,
289, 477
Cl[0, 1], 283, 288, 372, 411, 423,
477
Central limit theorem
for dtmcs, 476
for i.i.d. random vectors,
471
for i.i.d. sequences, 470
for o.d.s. sequences, 267, 472
for regenerative processes,
262
for stationary sequences,
471
multivariate, 471
random-index, 240, 287,
470, 471
Change of variable, 122, 459
Chapman–Kolmogorov
equations, 71, 159, 160
Clock-reading vectors, 72, 399
Clock-setting distribution, 22
class G+, 151, 402
continuous, 50
exponential, 70, 100, 103,
203, 209, 212, 217,
406–408
for cspn, 389
gnbu, see gnbu
distribution
initial, 22, 74

Index
501
uniformly bounded away
from origin, 91
Clocks, 5, 21, 389
clt, see Central limit theorem
Collision-free bus network, 58,
179
Color domains, 387
Colored spn, 8, 15, 385
aperiodic, 413
conditions for regenerative
structure, 406–409
d-cycle, 413
formal-sum notation, 388
new-marking function, 389,
434
symmetric, 15, 423–443
Complaint processing, 394
Complete set of color
permutations, 424, 427
Compound events, 47
Conditional distribution of clock
readings, 95–102
and ﬁnite cycle moments,
219, 220, 223
and geometric trials, 173,
176, 182, 183
and manufacturing cell with
robots, 183
and Markov property, 103
and producer–consumer
system, 223
and regenerative variance
constant, 230
and token ring, 173
for cspn, 404
for gsmp, 116
Conditional expectation,
460–462
Conﬁdence interval, 11
regenerative, 233
sts, see Standardized time
series, conﬁdence
interval
Conﬂict sets, 51
Consistent estimation methods,
12, 276, 412
and regenerative method,
262–265
continuous-time, 311–313,
417
discrete-time, 302–311,
413–416
Consistent estimators, 465
strongly, 465
Continuous mapping theorem,
196, 289, 310, 465
Continuous-time Markov chain,
93–95
construction of, 94
embedded jump chain, 94,
192
inﬁnitesimal generator
matrix, 95
minimal, 94
regenerative property, 192
structure of, 93
Convergence in distribution, 464
Convergence in Lp, 306, 463
Convergence in probability, 306,
463
Converging-together lemma, 304,
466
Coupling of gssmcs, 148, 303
Covariance function
of underlying chain, 302,
413
Cram´er–Wold theorem, 309, 467
cspn, see Colored spn
ctmc, see Continuous-time
Markov chain
Cumulative process, 439
Cycle, 11, 189, 190
Cycle moments, 209, 213, 218,
271, 407–409
for delays, 343, 350, 369,
372, 420
Cyclic queues, 176
gsmp model of, 115
three service centers, 180

502
Index
Cyclic queues with feedback, 19,
21, 117
comparison of estimators,
313, 359
four servers, 377, 382
geometric trials argument,
184
gradient estimation, 259
mimicry, 117
nonidentical jobs, 393
od-equilibrium points for
delays, 344
regeneration points, 226
start-vector speciﬁcation,
328
strong mimicry, 118
symmetry conditions, 424
tagging for delays, 324
types of delays in, 341
d-cycle
of cspn, 413
of gssmc, 148
of spn, 285
Delay, 12, 15, 321, 418
associating color with,
431–432
cycle moments, 343, 350,
369, 372, 420
extended regenerative
method, 352–354, 420
ﬁctitious, 350
functional central limit
theorem, 373, 422
interval, 12
limiting average, 12,
360–365, 377, 420, 423
methods for estimating in
symmetric cspns,
431–443
multiple-runs method,
354–357, 420
od-equilibrium points,
341–352, 419, 429
sequence, 323
slln, 373, 422
speciﬁcation and
measurement, 323–340
start vectors, 326–340, 418
starts, 321, 418
sts methods, 365–382, 421
tagging, 324
terminations, 321, 418
Delta method, 247, 310, 466
Density component, 150
Discounted reward, 249
Discrete-event system, 2
Discrete-time Markov chain,
474–476
null recurrent, 475
od-equilibrium points, 199
positive recurrent, 475
regenerative property, 192
transient, 475
Disjoint clock readings, 102
Distribution function, 450
absolutely continuous, 450
aperiodic, 196, 473
proper, 450
spread out, 473
Dominated, 452
Donsker’s theorem, 479
Drift conditions, 14, 149,
161–163, 402
dtmc, see Discrete-time Markov
chain
Embedded chain, 75
Harris recurrent, 153, 403
Ergodic dtmc, 475
Essential inﬁmum, 167
Essential supremum, 167
Expectation, 452–457
Explosion
of ctmc, 93
of spn, 13, 90–91
Extended regenerative method
for delays, 352–354, 420
for od-regenerative
processes, 267

Index
503
Fatou’s lemma, 454
for weak convergence, 218,
467
fclt, see Functional central
limit theorem
Flexible manufacturing system,
41, 157, 165, 204
alternative model, 44
Formal-sum notation, 388
Foster’s criterion, 475
generalization, 150n
Fubini’s theorem, 158, 459
Functional central limit theorem,
12, 476
for delays, 373, 422
for marking process, 287,
412
for od-regenerative process,
283
for underlying chain, 286,
411
General state-space Markov
chain, 8, 70–72,
146–150
aperiodic, 148
C-set, 201, 367
d-cycle, 148
decomposition of kernel,
201, 367
drift conditions, 149
Harris ergodic, 148, 276, 300
Harris recurrent, 147, 200
invariant measure, 147
periodic, 148
petite set for, 149
φ-irreducible, 146
positive Harris recurrent,
147
transition kernel, 469n
Generalized semi-Markov
process, 8, 66, 113–116,
163, 270, 382, 402
Geometric trials
arguments, 164–186,
403–406
lemma, 88, 166, 404
recurrence criterion, 14, 88
GI/G/1 queue, 3, 6, 9, 18, 21, 23
gnbu distribution, 166–171
ﬁnite moments, 169
ﬁnite moments of clock
reading, 219, 408
in cyclic queues with
feedback, 184, 226, 344
in cyclic queues with three
service centers, 180
in geometric trials
arguments, 14,
174–182, 405
in producer–consumer
system, 223
in telephone system, 183,
224
Graph
of cspn, 387, 388
of spn, 3, 17
gsmp, see Generalized
semi-Markov process
gssmc, see General state-space
Markov chain
Harris ergodic, see General
state-space Markov
chain, Harris ergodic
Harris recurrent, see General
state-space Markov
chain, Harris recurrent
Holding-time function t∗, 72
polynomially dominated
property, 208
Inequalities
Cauchy–Schwarz, 213, 228,
305, 440, 442, 454
cr, 213, 220, 222, 224,
226–228, 351, 370, 455
H¨older’s, 218, 454
Lyapunov, 454

504
Index
Initial distribution, 5, 73, 399
Initial-marking distribution, 22,
74
Input incidence function, 15, 387
Integrable random variable, 453
Interactive video on demand, see
Video on demand
Invariant measure
of gssmc, 147
Irreducible
cspn, 402
ctmc, 95
dtmc, 474
spn, 142, 153, 287
Jackknife method
and batch means, 293–297
and batch means for delays,
375–376, 423
for functions of cycle means,
248
for ratio estimator, 238
Kolmogorov’s existence theorem,
72, 94, 468
LaPlace–Stieltjes transform, 150,
225, 456
Lebesgue integral, 452
Lebesgue measure, 158, 449
Likelihood-ratio method for
gradient estimation,
251–262
Little’s law, 364, 377
Machine repair system, 210
cspn representation, 390,
398
gradient estimation, 250
regeneration points, 210
symmetric, 424
Manufacturing cell with robots,
53
delays in, 333
nondeterministic, 64
od-regeneration points for
delays, 346
recurrence, 182
regeneration points, 224
relative utilization of
robots, 78
throughput, 86
Manufacturing ﬂow-line, see
Shunt bank
Marking, 2, 18
immediate, 6, 18, 398
of cspn, 388
tangible, see Marking,
timed
timed, 6, 18, 398
vanishing, see Marking,
immediate
Marking process, 8
deﬁnition, 74
fclt, 287, 412
lifetime, 87–92, 400
Markovian, 92–107
of cspn, 400
sample path generation, 77
single state of, 204, 406
slln, 286, 411
stationary version, 264
time-average limits, 81
Mean time to failure, 249
Measurable
mapping, 459
sets, 448
space, 448
Measure
deﬁned, 449
nontrivial, 449
Memoryless property, 100
Mimicry, 116
by gsmp, 139
by countable-state spn, 132
by deterministic spn, 66,
142
by ﬁnite-state spn, 128, 131
of spn with dependent clock
readings, 136, 139

Index
505
of irreducible spn, 142
strong, 13, 119, 137
suﬃcient conditions, 121,
126
Modelling power, 13
in recurrence proof, 163
of cspns, 402
Moment generating function, see
LaPlace–Stieltjes
transform
Multiple-runs method
for delays, 354–357, 420
for od-regenerative
processes, 267
nbu distribution, 167
New-marking function, see
Colored spn,
new-marking function
New-marking probabilities, 19
concise speciﬁcation, 49–64
for cspn, 397
Non-Markovian spn with
exponential clocks, 103
Nonarithmetic, see Aperiodic
Nonlattice, see Aperiodic
O.d.s., see One-dependent and
stationary
Od-equilibrium points
for delays, 341–352, 419, 429
for embedded chain, 212
for underlying chain, 284
Od-equilibrium process, 199
property of Harris chain,
200
Od-regeneration points
for delays, 367–372
for underlying chain, 284,
410
Od-regenerative process, 198
extended regenerative
method for, 267
fclt, 283
multidimensional slln, 283
multiple-runs method for,
267
One-dependent, 471
and stationary, 198, 472
Output incidence function, 15,
387
Partial history, see Underlying
chain, partial history
Particle counter, 45
and mimicry, 138
Periodic
gssmc, 148
Permuted regenerative
estimator, 445
Petite set for gssmc, 149
φ-mixing process, 318, 471
Place
inhibitor input, 2, 18
normal input, 2, 18
of cspn, 387
output, 2, 18
Polynomially dominated
function
and fclt, 286
and ﬁnite cycle moments,
209, 212, 214, 284, 369,
407, 410
and regenerative variance
constant, 229
and slln, 285, 410
and sts methods, 288, 373
of delays, 369, 373, 376, 381,
422
on ℜ, 369
on Σ, 208
on Υ, 407
ℜl-valued, 285, 410
to degree b, 343, 420
Positive density conditions, 14,
150–164
Positivity condition
for recurrence, 173, 175, 180
Preemptive-repeat priority

506
Index
approximate model of pri
preemption, 30, 37
in producer–consumer
system, 29
prn vs. pri, 30
Preemptive-resume priority
in producer–consumer
system, 30
zero speeds for modelling,
21
Priorities (numerical), 51–64
Probability measure, 447
Probability space, 447
Producer–consumer system,
24–31
channel utilization, 77
inﬁnite lifetime, 92
no absorption into
immediate markings, 88
preemptive-repeat priority,
29
preemptive-resume priority,
30
recurrence, 178, 211
regeneration points, 222
strong mimicry of gsmp
representation, 124
Product space, 459
Quadratic-form estimators, 15,
276, 302, 413
convergence of, 303, 414
localized, 303, 414
Queue
in heavy traﬃc, 281
with batch arrivals, 31
Random sums
moments, 348, 370, 457–458
Random walk, 146
Reachability set, 67
Recurrence arguments, 14,
145–186, 402–406
Recurrent
ctmc, 95
dtmc, 475
marking, 165
set of markings, 165
set of states for underlying
chain, 164
Regeneration points, 11
and cspns, 406–409
for delays, 343, 420
for embedded chain, 206
for marking process, 209,
212, 217, 407, 408
for underlying chain, 206,
209, 212, 221, 407, 409
multiple sequences, 265, 444
Regenerative method, 11
as consistent estimation
method, 262–265
bias of point estimator,
238–240
ﬁxed-precision estimation,
242–245
for limiting average delays,
361
for marking process,
231–235
for underlying chain,
235–237
functions of cycle means,
245–246
gradient estimation,
250–262
limitations, 276–282
one-pass variance
computation, 234, 361
pilot runs, 242
ratio estimation, 248
sequential estimation, 243
simulation until a ﬁxed
time, 240–241, 262
Tin estimator, 238
Regenerative process, 11,
190–202
deﬁnition, 190, 192
delayed, 205

Index
507
estimating long-run
variance, 246
limiting distributions, 195
pairwise mapping, 200
ratio formula, 196
stability of, 193–197
time-average limits, 193
variance constant, 228–230
Renewal process, 190, 472–474
alternating, 119
Renewal theorem
elementary, 439, 473
key, 196, 473
Rewards, 81–86, 298
Robbins–Monro algorithm, 251,
273
Sample path condition
for recurrence, 173
Sequential estimation
for regenerative method, 243
Shunt bank, 330, 345
σ-ﬁeld, 447
product, 449
Simultaneous transition ﬁring,
47, 49–64
Single state, 204, 406, 425, 441
Single-server queue
waiting time, 193
Skorohod’s theorem, 465
slln, see Strong law of large
numbers
Slotted ring, 47
Slutsky’s theorem, 233, 247, 263,
299, 436, 466
Spectral methods, 12, 306–309,
414
continuous time, 312
convergence of variance
estimators, 307, 308,
415
lag windows, 307
Speeds, 5, 21
state-dependent, 21
spn, see Stochastic Petri net
Spread out
cycle length, 197, 264
distribution function, 473
spsim, 39–41
Stability, 11, 145, 193
Standardized time series, 11
area method, 290, 293
area method for delays, 374
as cancellation method, 289
conﬁdence interval, 289,
374, 423
for delays, 365–382, 421
in continuous time, 288–292
in discrete time, 292–293
maximum method, 291, 293
maximum method for
delays, 375
Start vectors, 326–340
for cspns, 418
recursive deﬁnition, 327
regular, 366, 422
Stationary distribution
of ctmc, 95
of dtmc, 475
of gssmc, 147
Stationary sequence, 471
Steady-state mean
for delays, 354
for marking processes, 285
for regenerative processes,
195, 198
Stochastic convergence, 462–467
relationship between modes
of, 464
Stochastic Petri net
alternative building blocks,
64–66
aperiodic, 285, 300
conditions for regenerative
structure, 202–230
d-cycle, 285
deterministic, 66
irreducible, 142
k-bounded, 18
live, 66

508
Index
restricted, 65
with long cycles, 280
Stochastic process, 467
existence theorem, 468
Stochastically dominated, 167,
452
Stochastically smaller, see
Stochastically
dominated
Stopping time
and ﬁnite cycle moments,
220
and ﬁnite moments of clock
reading, 408
and geometric trials, 217,
219, 221, 404, 408, 409
and moments of random
sums, 348, 370
regeneration point, 191
w.r.t. continuous-time
process, 191n
w.r.t. ctmc, 192
w.r.t. gssmc, 72
w.r.t. partial histories, 96,
207, 404
w.r.t. σ-ﬁelds, 457
w.r.t. underlying chain, 206,
207, 348, 427
Strong approximation, see
Strong invariance
principle
Strong invariance principle, 317,
319
Strong law of large numbers
for dtmcs, 476
for delays, 373, 422
for i.i.d. sequences, 195, 232,
470
for marking process, 286,
411
for o.i.d. sequences, 267,
365, 471
for od-regenerative process,
283
for underlying chain, 285,
410
Strong Markov property, 72,
192, 193, 202, 205, 207,
349, 371
sts, see Standardized time series
Supply chain, 82
Symmetric function, 426
Symmetry conditions, 424
expanded, 432, 441
extended, 428, 432
System availability, 78
Telephone system, 153
recurrence, 156, 183
regeneration points, 211,
224
Three-series theorem, 90, 463
Throughput, 81–86
Time-average limit, 9
as function of cycle means,
245
Token ring, 33
bias of regenerative
estimators, 239, 241
comparison of estimation
methods for delays, 442
cspn representation, 392
delays in, 335
deterministic spn model of,
36
eﬃcient estimation of
delays, 431
recurrence, 172, 185
regeneration points, 225
sequential estimation, 244
simulation in blocks, 428
simulation of delays in
blocks, 430
symmetry conditions, 425
transmission probability, 78
with ﬁxed-sized packets,
239, 241, 244, 442
Tokens, 2
distinguishable, 8, 15, 385

Index
509
graphical representation, 3
interpretation of, 8
removing and depositing, 2,
19, 21, 385, 387
Total variation, 187, 197, 464
Transition
deterministic, 21, 51
disabled, 2, 18, 389
enabled, 2, 18, 389
ﬁring of, 2, 19, 389
immediate, 5, 18, 387
marking-dependent, 31, 41
new, 5, 22, 389
newly disabled, 5, 22, 389
of cspn, 387
old, 5, 22, 389
qualifying, 386, 390
simple, 24
simultaneous ﬁring of, 47,
49–64
timed, 5, 18
Unbiased estimators, 465
Undercoverage, 243
Underlying chain, 8, 73
aperiodic, 300, 413
construction, 469
covariance function, 302,
413
fclt, 286, 411
Harris ergodic, 300, 413
Harris recurrent, 284, 410
initial distribution, 73
od-regeneration points, 284,
366, 410
partial history, 96, 166, 403,
408
recurrent set of states, 164
sample path generation, 75
slln, 285, 410
transition kernel, 73, 399
Uniform integrability, 196, 197,
467
Video on demand, 277, 296, 298
Wald’s identities, 364, 440, 457
Weak convergence, 464
in C[0, 1], 477
Wiener measure, 477
Workﬂow system, 394

