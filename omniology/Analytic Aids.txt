Leif Mejlbro
Analytic Aids
Probability Examples c-7
Download free books at

2 
Leif Mejlbro
Probability Examples c-7
Analytic Aids
Download free eBooks at bookboon.com

3 
Probability Examples c-7 â€“ Analytic Aids
Â© 2009 Leif Mejlbro & Ventus Publishing ApS
ISBN 978-87-7681-523-3
Download free eBooks at bookboon.com

Analytic Aids
 
4 
Contents
 
Introduction  
5
1  
Generating functions; background  
6
1.1  
Denition of the generating function of a discrete random variable   
6
1.2  
Some generating functions of random variables  
7
1.3  
Computation of moments  
8
1.4  
Distribution of sums of mutually independent random variables  
8
1.5  
Computation of probabilities  
9
1.6  
Convergence in distribution  
9
2  
The Laplace transformation; background  
10
2.1  
Denition of the Laplace transformation  
10
2.2  
Some Laplace transforms of random variables  
11
2.3  
Computation of moments   
12
2.4  
Distribution of sums of mutually independent random variables  
12
2.5  
Convergence in distribution  
13
3  
Characteristic functions; background  
14
3.1  
Denition of characteristic functions  
14
3.2  
Characteristic functions for some random variables  
16
3.3  
Computation of moments  
17
3.4  
Distribution of sums of mutually independent random variables  
18
3.5  
Convergence in distribution  
19
4  
Generating functions  
20
5  
The Laplace transformation  
48
6  
The characteristic function  
85
 
Index  
110
Contents
Download free eBooks at bookboon.com

Analytic Aids
 
5 
Introduction
Introduction
This is the eight book of examples from the Theory of Probability. In general, this topic is not my
favourite, but thanks to my former colleague, Ole JÃ¸rsboe, I somehow managed to get an idea of what
it is all about. We shall, however, in this volume deal with some topics which are closer to my own
mathematical ï¬elds.
The prerequisites for the topics can e.g. be found in the Ventus: Calculus 2 series and the Ventus:
Complex Function Theory series, and all the previous Ventus: Probability c1-c6.
Unfortunately errors cannot be avoided in a ï¬rst edition of a work of this type. However, the author
has tried to put them on a minimum, hoping that the reader will meet with sympathy the errors
which do occur in the text.
Leif Mejlbro
27th October 2009
Download free eBooks at bookboon.com

Analytic Aids
 
6 
1. Generating functions; background
1
Generating functions; background
1.1
Deï¬nition of the generating function of a discrete random variable
The generating functions are used as analytic aids of random variables which only have values in N0,
e.g. binomial distributed or Poisson distributed random variables.
In general, a generating function of a sequence of real numbers (ak)+âˆ
k=0 is a function of the type
A(s) :=
+âˆ

k=0
ak sk,
for |s| < Ï±,
provided that the series has a non-empty interval of convergence ] âˆ’Ï±, Ï±[, Ï± > 0.
Since a generating function is deï¬ned as a convergent power series, the reader is referred to the Ventus:
Calculus 3 series, and also possibly the Ventus: Complex Function Theory series concerning the theory
behind. We shall here only mention the most necessary properties, because we assume everywhere
that A(s) is deï¬ned for |s|Ï±.
A generating function A(s) is always of class Câˆ(] âˆ’Ï±, Ï±[). One may always diï¬€erentiate A(s) term
by term in the interval of convergence,
A(n)(s) =
+âˆ

k=n
k(k âˆ’1) Â· Â· Â· (k âˆ’n + 1)akskâˆ’n,
for s âˆˆ] âˆ’Ï±, Ï±[.
We have in particular
A(n)(0) = n! Â· an,
i.e.
an = A(n)(0)
n!
for every n âˆˆN0.
Download free eBooks at bookboon.com
Click on the ad to read more
www.sylvania.com
We do not reinvent  
the wheel we reinvent 
light.
Fascinating lighting offers an infinite spectrum of 
possibilities: Innovative technologies and new  
markets provide both opportunities and challenges. 
An environment in which your expertise is in high 
demand. Enjoy the supportive working atmosphere 
within our global group and benefit from international 
career paths. Implement sustainable ideas in close 
cooperation with other specialists and contribute to 
influencing our future. Come and join us in reinventing 
light every day.
Light is OSRAM

Analytic Aids
 
7 
1. Generating functions; background
Furthermore, we shall need the well-known
Theorem 1.1 Abelâ€™s theorem. If the convergence radius Ï± > 0 is ï¬nite, and the series +âˆ
k=0 ak Ï±k
is convergent, then
+âˆ

k=0
ak Ï±k = lim
sâ†’Ï±âˆ’A(s).
In the applications all elements of the sequence are typically bounded. We mention:
1) If |ak| â‰¤M for every k âˆˆN0, then
A(s) =
+âˆ

k=0
ak sk
convergent for s âˆˆ] âˆ’Ï±, Ï±[, where Ï± â‰¥1.
This means that A(s) is deï¬ned and a Câˆfunction in at least the interval ] âˆ’1, 1[, possibly in a
larger one.
2) If ak â‰¥0 for every k âˆˆN0, and +âˆ
k=0 ak = 1, then A(s) is a Câˆfunction in ] âˆ’1, 1[, and it follows
from Abelâ€™s theorem that A(s) can be extended continuously to the closed interval [âˆ’1, 1].
This observation will be important in the applications her, because the sequence (ak) below is
chosen as a sequence (pk) of probabilities, and the assumptions are fulï¬lled for such an extension.
If X is a discrete random variable of values in N0 and of the probabilities
pk = P{X = k},
for k âˆˆN0,
then we deï¬ne the generating function of X as the function P : [0, 1] â†’R, which is given by
P(s) = E

sX
:=
+âˆ

k=0
pk sk.
The reason for introducing the generating function of a discrete random variable X is that it is
often easier to ï¬nd P(s) than the probabilities themselves. Then we obtain the probabilities as the
coeï¬ƒcients of the series expansion of P(s) from 0.
1.2
Some generating functions of random variables
We shall everywhere in the following assume that p âˆˆ]0, 1[ and q := 1 âˆ’p, and Î¼ > 0.
1) If X is Bernoulli distributed, B(1, p), then
p0 = 1 âˆ’p = q
and
p1 = p,
and
P(s) = 1 + p(s âˆ’1).
2) If X is binomially distributed, B(n, p), then
pk =

n
k

pkqnâˆ’k,
and
P(s) = {1 + p(s âˆ’1)}n.
Download free eBooks at bookboon.com

Analytic Aids
 
8 
1. Generating functions; background
3) If X is geometrically distributed, Pas(1, p), then
pk = pqkâˆ’1,
and
P(s) =
ps
1 âˆ’qs.
4) If X is negative binomially distributed, NB(Îº, p), then
pk = (âˆ’1)k
 âˆ’Îº
k

pÎºqk,
and
P(s) =

p
1 âˆ’qs
	Îº
.
5) If X is Pascal distributed, Pas(r, p), then
pk =

k âˆ’1
r âˆ’1

prqkâˆ’r,
and
P(s) =

ps
1 âˆ’qs
	r
.
6) If X is Poisson distributed, P(Î¼), then
pk = Î¼k
k! eâˆ’Î¼,
and
P(s) = exp(Î¼(s âˆ’1)).
1.3
Computation of moments
Let X be a random variable of values in N0 and with a generating function P(s), which is continuous
in [0, 1] (and Câˆin the interior of this interval).
The random variable X has a mean, if and only the derivative P â€²(1) := limsâ†’1âˆ’P â€²(s) exists and is
ï¬nite. When this is the case, then
E{X} = P â€²(1).
The random variable X has a variance, if and only if P â€²â€²(1) := limsâ†’1âˆ’P â€²â€²(s) exists and is ï¬nite.
When this is the case, then
V {X} = P â€²â€²(1) + P â€²(1) âˆ’{P â€²(1)}2 .
In general, the n-th moment E {Xn} exists, if and only if P (n)(1) := limsâ†’1âˆ’P (n)(s) exists and is
ï¬nite.
1.4
Distribution of sums of mutually independent random variables
If X1, X2, . . . , Xn are mutually independent discrete random variables with corresponding generating
functions P1(s), P2(s), . . . , Pn(s), then the generating function of the sum
Yn :=
n

i=1
Xi
is given by
PYn(s) =
n

i=1
Pi(s),
for s âˆˆ[0, 1].
Download free eBooks at bookboon.com

Analytic Aids
 
9 
1. Generating functions; background
1.5
Computation of probabilities
Let X be a discrete random variable with its generating function given by the series expansion
P(s) =
+âˆ

k=1
pksk.
Then the probabilities are given by
P{X = k} = pk = P (k)(0)
k!
.
A slightly more sophisticated case is given by a sequence of mutually independent identically dis-
tributed discrete random variables Xn with a given generating function F(s).
Let N be another
discrete random variable of values in N0, which is independent of all the Xn. We denote the generat-
ing function for N by G(s).
The generating function H(s) of the sum
YN := X1 + X2 + Â· Â· Â· + XN,
where the number of summands N is also a random variable, is then given by the composition
PYN (s) := H(s) = G(F(s)).
Notice that if follows from Hâ€²(s) = Gâ€²(F(s)) Â· F â€²(s), that
E {YN} = E{N} Â· E {X1} .
1.6
Convergence in distribution
Theorem 1.2 The continuity theorem. Let Xn be a sequence of discrete random variables of
values in N0, where
pn,k := P {Xn = k} , for n âˆˆN and k âˆˆN0,
and
Pn(s) :=
+âˆ

k=0
pn,k sk,
for s âˆˆ[0, 1] og n âˆˆN.
Then
lim
nâ†’+âˆpn,k = pk
for every k âˆˆN0,
if and only if
lim
nâ†’+âˆPn(s) = P(s)

=
+âˆ

k=0
pk sk

for all s âˆˆ[0, 1[.
If furthermore,
lim
sâ†’1âˆ’P(s) = 1,
then P(s) is the generating function of some random variable X, and the sequence (Xn) converges in
distribution towards X.
Download free eBooks at bookboon.com

Analytic Aids
 
10 
2. The Laplace transformation; background
2
The Laplace transformation; background
2.1
Deï¬nition of the Laplace transformation
The Laplace transformation is applied when the random variable X only has values in [0, +âˆ[, thus
it is non-negative.
The Laplace transform of a non-negative random variable X is deï¬ned as the function L : [0, +âˆ[ â†’R,
which is given by
L(Î») := E

eâˆ’Î»X
.
The most important special results are:
1) If the non-negative random variable X is discrete with P {xi} = pi, for all xi â‰¥0, then
L(Î») :=

i
pi eâˆ’Î» xi,
for Î» â‰¥0.
2) If the non-negative random variable X is continuous with the frequency f(x), (which is 0 for
x < 0), then
L(Î») :=
 +âˆ
0
eâˆ’Î»x f(x) dx
for Î» â‰¥0.
We also write in this case L{f}(Î»).
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
360Â°
thinking.
Â© Deloitte & Touche LLP and affiliated entities.
Discover the truth at www.deloitte.ca/careers 

Analytic Aids
 
11 
2. The Laplace transformation; background
In general, the following hold for the Laplace transform of a non-negative random variable:
1) We have for every Î» â‰¥0,
0 < L(Î») â‰¤1,
with L(0) = 1.
2) If Î» > 0, then L(Î») is of class Câˆand the n-th derivative is given by
(âˆ’1)nL(n)(Î») =
â§
â¨
â©

i xn
i eâˆ’Î»xi pi,
when X is discrete,
 +âˆ
0
xn eâˆ’Î»x f(x) dx,
when X is continuous.
Assume that the non-negative random variable X has the Laplace transform LX(Î»), and let a, b â‰¥0
be non-negative constants. Then the random variable
Y := aX + b
is again non-negative, and its Laplace transform LY (Î») is, expressed by LX(Î»), given by
LY (Î») = E

eâˆ’Î»(aX+b)
= eâˆ’Î»b LX(aÎ»).
Theorem 2.1 Inversion formula. If X is a non-negative random variable with the distribution
function F(x) and the Laplace transform L(Î»), then we have at every point of continuity of F(x),
F(x) =
lim
Î»â†’+âˆ
[Î»x]

k=0
(âˆ’Î»)k
k!
L(k)(Î»),
where [Î»x] denotes the integer part of the real number Î»x. This result implies that a distribution is
uniquely determined by its Laplace transform.
Concerning other inversion formulÃ¦ the reader is e.g. referred to the Ventus: Complex Function Theory
series.
2.2
Some Laplace transforms of random variables
1) If X is Ï‡2(n) distributed of the frequency
f(x) =
1
Î“
n
2

2n/2 xn/2âˆ’1 exp

âˆ’x
2

.
x > 0,
then its Laplace transform is given by
LX(Î») =

1
2Î» + 1
	n
2 .
Download free eBooks at bookboon.com

Analytic Aids
 
12 
2. The Laplace transformation; background
2) If X is exponentially distributed, Î“

1 , 1
a

, a > 1, of the frequency
f(x) = a eâˆ’ax
for x > 0,
then its Laplace transform is given by
LX(Î») =
a
Î» + a.
3) If X is Erlang distributed, Î“(n, Î±) of frequency
1
(n âˆ’1)! Î±n xnâˆ’1 exp

âˆ’x
Î±

,
for n âˆˆN, Î± > 0 and x > 0,
then its Laplace transform is given by
LX(Î») =

1
Î±Î» + 1
	n
.
4) If X is Gamma distributed, Î“(Î¼, Î±), with the frequency
1
Î“(Î¼) Î±Î¼ xÎ¼âˆ’1 exp

âˆ’x
Î±

for Î¼, Î± > 0 and x > 0,
then its Laplace transform is given by
LX(Î») =

1
Î±Î» + 1
	Î¼
.
2.3
Computation of moments
Theorem 2.2 If X is a non-negative random variable with the Laplace transform L(Î»), then the n-th
moment E {Xn} exists, if and only if L(Î») is n times continuously diï¬€erentiable at 0. In this case we
have
E {Xn} = (âˆ’1)nL(n)(0).
In particular, if L(Î») is twice continuously diï¬€erentiable at 0, then
E{X} = âˆ’Lâ€²(0),
and
E

X2
= Lâ€²â€²(0).
2.4
Distribution of sums of mutually independent random variables
Theorem 2.3 Let X1, . . . , Xn be non-negative, mutually independent random variable with the cor-
responding Laplace transforms L1(Î»), . . . Ln(Î»). Let
Yn =
n

i=1
Xi
and
Zn = 1
n Yn = 1
n
n

i=1
Xi.
Then
LYn(Î») =
n

i=1
Li(Î»),
and
LZn(Î») = LYn
Î»
n

=
n

i=1
Li
Î»
n

.
Download free eBooks at bookboon.com

Analytic Aids
 
13 
2. The Laplace transformation; background
If in particular X1 and X2 are independent non-negative random variables of the frequencies f(x) and
g(x), resp., then it is well-known that the frequency of X1 + X2 is given by a convolution integral,
(f â‹†g)(x) =
 +âˆ
âˆ’âˆ
f(t)g(x âˆ’t) dt.
In this case we get the well-known result,
L{f â‹†g} = L{f} Â· L{g}.
Theorem 2.4 Let Xn be a sequence of non-negative, mutually independent and identically distributed
random variables with the common Laplace transform L(Î»). Furthermore, let N be a random variable
of values in N0 and with the generating function P(s), where N is independent of all the Xn.
Then YN := X1 + Â· Â· Â· + XN has the Laplace transform
LYN (Î») = P(L(Î»)).
2.5
Convergence in distribution
Theorem 2.5 Let (Xn) be a sequence of non-negative random variables of the Laplace transforms
Ln(Î»).
1) If the sequence (Xn) converges in distribution towards a non-negative random variable X with the
Laplace transform L(Î»), then
lim
nâ†’+âˆLn(Î») = L(Î»)
for every Î» â‰¥0.
2) If
L(Î») :=
lim
nâ†’+âˆLn(Î»)
exists for every Î» â‰¥0, and if L(Î») is continuous at 0, then L(Î») is the Laplace transform of some
random variable X, and the sequence (Xn) converges in distribution towards X.
Download free eBooks at bookboon.com

Analytic Aids
 
14 
3. Characteristic functions; background
3
Characteristic functions; background
3.1
Deï¬nition of characteristic functions
The characteristic function of any random variable X is the function k : R â†’C, which is deï¬ned by
k(Ï‰) := E

eiÏ‰X
.
We have in particular:
1) If X has a discrete distribution, P {X = xj} = pj, then
k(Ï‰) =

i
pjeiÏ‰xj.
2) If X has its values in N0, then X has also a generating function P(s), and we have the following
connection between the characteristic function and the generating function,
k(Ï‰) =
+âˆ

k=0
pk

eiÏ‰k = P

eiÏ‰
.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
We will turn your CV into 
an opportunity of a lifetime
Do you like cars? Would you like to be a part of a successful brand?
We will appreciate and reward both your enthusiasm and talent.
Send us your CV. You will be surprised where it can take you.
Send us your CV on
www.employerforlife.com

Analytic Aids
 
15 
3. Characteristic functions; background
3) Finally, if X has a continuous distribution with the frequency f(x), then
k(Ï‰) =
 +âˆ
âˆ’âˆ
eiÏ‰x f(x) dx,
which is known from Calculus as one of the possible deï¬nition of the Fourier transform of f(x),
cf. e.g. Ventus: the Complex Function Theory series.
Since the characteristic function may be considered as the Fourier transform of X in some sense, all
the usual properties of the Fourier transform are also valid for the characteristic function:
1) For every Ï‰ âˆˆR,
|k(Ï‰)| â‰¤1,
in particular, k(0) = 1.
2) By complex conjugation,
k(Ï‰) = k(âˆ’Ï‰)
for ever Ï‰ âˆˆR.
3) The characteristic function k(Ï‰) of a random variable X is uniformly continuous on all of R.
4) If kX(Ï‰) is the characteristic function of X, and a, b âˆˆR are constants, then the characteristic
function of Y := aXS + b is given by
kY (Ï‰) = E

eiÏ‰(aX+b)
= eiÏ‰b kX(aÏ‰).
Theorem 3.1 Inversion formula
1) Let X be a random variable of distribution function F(x) and characteristic function k(Ï‰). If
F(x) is continuous at both x1 and x2 (where x1 < x2), then
F (x2) âˆ’F (x1) = 1
2Ï€
lim
Aâ†’+âˆ
 A
âˆ’A
eâˆ’iÏ‰x1 âˆ’eâˆ’iÏ‰x2
iÏ‰
k(Ï‰) dÏ‰.
In other words em a distribution is uniquely determined by its characteristic function.
2) We now assume that the characteristic function k(Ï‰) of X is absolutely integrable, i.e.
 +âˆ
âˆ’âˆ
|k(Ï‰)| dÏ‰ < +âˆ.
Then X has a continuous distribution, and the frequency f(x) of X is given by
f(x) = 1
2Ï€
 +âˆ
âˆ’âˆ
eâˆ’iÏ‰x k(Ï‰) dÏ‰.
In practice this inversion formula is the most convenient.
Download free eBooks at bookboon.com

Analytic Aids
 
16 
3. Characteristic functions; background
3.2
Characteristic functions for some random variables
1) If X is a Cauchy distributed random variable, C(a, b), a, b > 0, of frequency
f(x) =
b
Ï€ {b2 + (x âˆ’a)2}
for x âˆˆR,
then it has the characteristic function
k(Ï‰) = exp(i a Ï‰ âˆ’|Ï‰|).
2) If X is a Ï‡2(n) distributed random variable, n âˆˆN of frequency
1
Î“
n
2

2n/2 xn/2âˆ’1 exp

âˆ’x
2

for x > 0,
then its characteristic function is given by
k(Ï‰) =

1
1 âˆ’2iÏ‰
	n/2
.
3) If X is double exponentially distributed with frequency
f(x) = a
2 eâˆ’a|x|,
for x âˆˆR, where the parameter a > 0,
then its characteristic function is given by
k(Ï‰) =
a2
a2 + Ï‰2 .
4) If X is exponentially distributed, Î“

1 , 1
a

, a > 0, with frequency
f(x) = a eâˆ’ax
for x > 0,
then its characteristic function is given by
k(Ï‰) =
a
a âˆ’iÏ‰ .
5) If X is Erlang distributed, Î“(n, Î±), where n âˆˆN and Î± > 0, with frequency
f(x) =
xnâˆ’1 exp

âˆ’x
Î±

(n âˆ’1)! Î±n
for x > 0,
then its characteristic function is
k(Ï‰) =

1
1 âˆ’iÎ±Ï‰
	n
.
Download free eBooks at bookboon.com

Analytic Aids
 
17 
3. Characteristic functions; background
6) If X is Gamma distributed, Î“(Î¼, Î±), where Î¼, Î± > 0, with frequency
f(x) =
xÎ¼âˆ’1 exp

âˆ’x
Î±

Î“(Î¼) Î±Î¼
,
for x > 0,
then its characteristic function is given by
k(Ï‰) =

1
1 âˆ’iÎ±Ï‰
	Î¼
.
7) If X is normally distributed (or GauÃŸian distributed), N

Î¼ , Ïƒ2
, Î¼ âˆˆR and Ïƒ > 0, with frequency
1
âˆš
2Ï€Ïƒ2 exp

âˆ’(x âˆ’Î¼)2
2Ïƒ2

,
for x âˆˆR,
then its characteristic function is given by
k(Ï‰) = exp

iÎ¼Ï‰ âˆ’Ïƒ2Ï‰2
2

.
8) If X is rectangularly distributed, U(a, b), where a < b, with frequency
f(x) =
1
b âˆ’a
for a < x < b,
then its characteristic function is given by
k(Ï‰) = eiÏ‰b âˆ’eiÏ‰a
iÏ‰(b âˆ’a) .
3.3
Computation of moments
Let X be a random variable with the characteristic function k(Ï‰). If the n-th moment exists, then
k(Ï‰) is a CÏ‰ function, and
k(n)(0) = in E {Xn} .
In particular,
kâ€²(0) = i E{X}
and
kâ€²â€²(0) = âˆ’E

X2
.
We get in the special cases,
1) If X is discretely distributed and E {|X|n} < +âˆ, then k(Ï‰) is a Cn function, and
k(n)(Ï‰) = in 
j
xn
j exp (iÏ‰xj) pj.
2) If X is continuously distributed with frequency f(x) and characteristic function
k(Ï‰) =
 +âˆ
âˆ’âˆ
eiÏ‰x f(x) dx,
Download free eBooks at bookboon.com

Analytic Aids
 
18 
3. Characteristic functions; background
and if furthermore,
E {|X|n} =
 +âˆ
âˆ’âˆ
|x|n f(x) dx < +âˆ,
then k(Ï‰) is a Cn function, and we get by diï¬€erentiation of the integrand that
k(n)(Ï‰) = in
 +âˆ
âˆ’âˆ
xn eiÏ‰x f(x) dx.
3.4
Distribution of sums of mutually independent random variables
Let X1, . . . , Xn be mutually independent random variables, with their corresponding characteristic
functions k1(Ï‰), . . . , kn(Ï‰). We introduce the random variables
Yn :=
n

i=1
Xi
and
Zn = 1
n Yn = 1
n
n

i=1
Xi.
The characteristic functions of Yn and Zn are given by
kYn(Ï‰) =
n

i=1
ki(Ï‰)
and
kZn(Ï‰) =
n

i=1
ki
Ï‰
n

.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
AXA Global 
Graduate Program
Find out more and apply

Analytic Aids
 
19 
3. Characteristic functions; background
3.5
Convergence in distribution
Let (Xn) be a sequence of random variables with the corresponding characteristic functions kn(Ï‰).
1) Necessary condition. If the sequence (Xn) converges in distribution towards the random vari-
able X of characteristic function k(Ï‰), then
lim
nâ†’+âˆkn(Ï‰) = k(Ï‰)
for every Ï‰ âˆˆR.
2) Suï¬ƒcient condition. If
k(Ï‰) =
lim
nâ†’+âˆkn(Ï‰)
exists for every Ï‰ âˆˆR, and if also k(Ï‰) is continuous at 0, then k(Ï‰) is the characteristic function
of some random variable X, and the sequence (Xn) converges in distribution towards X.
Download free eBooks at bookboon.com

Analytic Aids
 
20 
4. Generating functions
4
Generating functions
Example 4.1 Let X be geometrically distributed,
(1) P{X = k} = pqkâˆ’1,
k âˆˆN,
where p > 0, q > 0 and p + q = 1.
Find the generating function of X.
Let X1, X2, . . . , Xr be mutually independent, all of distribution given by (1), and let
Yr = X1 + X2 + Â· Â· Â· + Xr.
Find the generating function of Yr, and prove that Yr has the distribution
P {Yr = k} =
 k âˆ’1
r âˆ’1

prqkâˆ’r,
k = r, r + 1, . . . .
It follows by insertion that
PX(s) = E

sX
=
âˆ

n=1
pqnâˆ’1sn = ps
âˆ

n=1
(qs)nâˆ’1 =
ps
1 âˆ’qs,
s âˆˆ[0, 1].
The generating function Qr(s) for Yr = X1 + X2 + Â· Â· Â· + Xr is
Qr(s)
=
r

i=1
PXi(s) =

ps
1 âˆ’qs
r
= prsr(1 âˆ’qs)âˆ’s = prsr
âˆ

m=0
 âˆ’r
m

(âˆ’1)mqmsm
=
âˆ

m=0

r + m âˆ’1
m

prqmsm+r =
âˆ

n=r

n âˆ’1
r âˆ’1

prqnâˆ’rsr
for s âˆˆ[0, 1].
Since also
Qr(s) =

n
P {Yr = n} sn,
we conclude that
P {Yr = n} =
 n âˆ’1
r âˆ’1

prqnâˆ’r,
n = r, r + 1, . . . .
Download free eBooks at bookboon.com

Analytic Aids
 
21 
4. Generating functions
Example 4.2 Given a random variable X of values in N0 of the probabilities pk = P{X = k},
k âˆˆN0, and with the generating function P(s). We put qk = P{X > k}, k âˆˆN0, and
Q(s) =
âˆ

k=0
qksk,
s âˆˆ[0, 1[.
Prove that
Q(s) = 1 âˆ’P(s)
1 âˆ’s
for s âˆˆ[0, 1[.
We have
qk = P{X > k} =
âˆ

n=k+1
P{X = n} =
âˆ

n=k+1
pn = 1 âˆ’
k

n=0
pn.
Thus if s âˆˆ[0, 1[, then
Q(s)
=
âˆ

k=0
qksk =
âˆ

k=0
sk âˆ’
âˆ

k=0
k

n=0
pnsk =
1
1 âˆ’s âˆ’
âˆ

n=0
âˆ

k=n
pnsk
=
1
1 âˆ’s âˆ’
âˆ

n=0
pn Â·
sn
1 âˆ’s =
1
1 âˆ’s

1 âˆ’
âˆ

n=0
pnsn

= 1 âˆ’P(s)
1 âˆ’s
.
Example 4.3 We throw a coin, where the probability of obtaining head in a throw is p, where p âˆˆ]0, 1[.
We let the random variable X denote the number of throws until we get the results headâ€“tail in the
given succession (thus we have X = n, if the pair headâ€“tail occurs for the ï¬rst time in the experiments
of numbers n âˆ’1 and n).
Find the generating function of X and use it to ï¬nd the mean and variance of X. For which value of
p is the mean smallest?
If n = 2, 3, . . . and p Ì¸= 1
2, then
P{X = n}
=
P {Xi = head, i = 1, . . . , Xn = tail}
+P {X1 = tail, Xi = head, i = 2, . . . , n âˆ’1, Xn = tail}
+P {Xj = tail, j = 1, 2; Xi = head, i = 3, . . . , n âˆ’1, Xn = tail}
+ Â· Â· Â· + P {Xj = tail, j = 1, . . . , n âˆ’2; Xnâˆ’1 = head, Xn = tail}
=
pnâˆ’1(1 âˆ’p) + (1 âˆ’p)pnâˆ’2(1 âˆ’p) + (1 âˆ’p)2pnâˆ’3(1 âˆ’p)
Â· Â· Â· + (1 âˆ’p)nâˆ’2p(1 âˆ’p)
=
nâˆ’1

j=1
pnâˆ’j(1 âˆ’p)j = pnâˆ’1(1 âˆ’p)
nâˆ’1

j=1
1 âˆ’p
p
	jâˆ’1
=
pnâˆ’1(1 âˆ’p) Â·
1 âˆ’
1 âˆ’p
p
nâˆ’1
1 âˆ’1 âˆ’p
p
= p(1 âˆ’p) Â· pnâˆ’1 âˆ’(1 âˆ’p)nâˆ’1
2p âˆ’1
=
p(1 âˆ’p)
2p âˆ’1

pnâˆ’1 âˆ’(1 âˆ’p)nâˆ’1
,
n âˆˆN \ {1}.
Download free eBooks at bookboon.com

Analytic Aids
 
22 
4. Generating functions
If p = 1
2 then we get instead
P{X = n} =
nâˆ’1

j=1
1
2
nâˆ’j 1
2
j
= n âˆ’1
2n
,
which can also be obtained by taking the limit in the result above for p Ì¸= 1
2.
We have to split into the two cases 1. p = 1
2 and 2. p Ì¸= 1
2.
1) If p = 1
2, then the generating function becomes
P(s)
=
âˆ

n=2
n âˆ’1
2n
sn =
s
2
2
âˆ

n=1
n
s
2
nâˆ’1
=
s
2
2
Â·
1

1 âˆ’s
2
2 =

s
2 âˆ’s
2
=

2
2 âˆ’s âˆ’1
2
=
4
(2 âˆ’s)2 âˆ’
4
2 âˆ’s + 1
for s âˆˆ[0, 2[.
2) If p âˆˆ]0, 1[ and p Ì¸= 1
2, we get instead
P(s)
=
âˆ

n=2
p(1 âˆ’p)
2p âˆ’1

pnâˆ’1 âˆ’(1 âˆ’p)nâˆ’1
sn = p(1 âˆ’p)
2p âˆ’1 Â· s
 âˆ

n=1
(ps)n âˆ’
âˆ

n=1
(1 âˆ’p)nsn

=
p(1 âˆ’p)
2p âˆ’1 Â· s

ps
1 âˆ’ps âˆ’
(1 âˆ’p)s
1 âˆ’(1 âˆ’p)s
	
= p(1 âˆ’p)
2p âˆ’1 Â· s

1
1 âˆ’ps âˆ’
1
1 âˆ’(1 âˆ’p)s
	
=
1 âˆ’p
2p âˆ’1 Â·
ps
1 âˆ’ps âˆ’
p
2p âˆ’1 Â·
(1 âˆ’p)s
1 âˆ’(1 âˆ’p)s
=
1 âˆ’p
2p âˆ’1 Â·
1
1 âˆ’ps âˆ’1 âˆ’p
2p âˆ’1 Â· âˆ’
p
2p âˆ’1 Â·
1
1 âˆ’(1 âˆ’p)s +
p
2p âˆ’1
=
1 + 1 âˆ’p
2p âˆ’1 Â·
1
1 âˆ’ps âˆ’
p
2p âˆ’1 Â·
1
1 âˆ’(1 âˆ’p)s,
for s âˆˆ

0, min
1
p ,
1
1 âˆ’p
	
.
In both cases P (n)(1) exists for all n. It follows from
E{X} = P â€²(1)
and
V {X} = P â€²â€²(1) + P â€²(1) âˆ’{P â€²(1)}2,
that
1) If p = 1
2, then
P â€²(s) =
8
(2 âˆ’s)3 âˆ’
4
(2 âˆ’s)2
Download free eBooks at bookboon.com

Analytic Aids
 
23 
4. Generating functions
and
P â€²â€²(s) =
24
(2 âˆ’s)4 âˆ’
8
(2 âˆ’s)3 ,
hence
E{X} = P â€²(1) = 4,
and
V {X} = P â€²â€²(1) + P â€²(1) âˆ’{P â€²(1)}2 = 16 + 4 âˆ’16 = 4.
2) If p âˆˆ]0, 1[, p Ì¸= 1
2, then
P â€²(s) = (1 âˆ’p)p
2p âˆ’1

1
(1 âˆ’ps)2 âˆ’
1
{1 âˆ’(1 âˆ’p)s}2
	
,
hence
E{X}
=
(1 âˆ’p)p
2p âˆ’1

1
(1 âˆ’p)2 âˆ’
1
{1 âˆ’(1 âˆ’p)}2
	
=
1
2p âˆ’1

p
1 âˆ’p âˆ’1 âˆ’p
p
	
=
1
2p âˆ’1 Â· 2p âˆ’1
(1 âˆ’p)p =
1
p(1 âˆ’p).
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
ibili
because 
e Graduate Programme  
for Engineers and Geoscientists
Month 16
I was a construction
supervisor in 
the North Sea 
advising and 
helping foremen 
solve problems
I was a
he
s
Real work 
International opportunities 

ree work placements
al 
Internationa
or

ree wo
I wanted real responsibili 
 I joined MITAS because 
www.discovermitas.com

Analytic Aids
 
24 
4. Generating functions
Furthermore,
P â€²â€²(s) = 2(1 âˆ’p)p
2p âˆ’1

p
(1 âˆ’ps)3 âˆ’
1 âˆ’p
{1 âˆ’(1 âˆ’p)s}3
	
,
thus
V {X}
=
2
2p âˆ’1

p
1 âˆ’p
2
âˆ’
1 âˆ’p
p
2
+
1
p(1 âˆ’p) âˆ’
1
p2(1 âˆ’p)2
=
2
2p âˆ’1

p
1 âˆ’p + 1 âˆ’p
p
	 
p
1 âˆ’p âˆ’1 âˆ’p
p
	
+
1
p(1 âˆ’p) âˆ’
1
p2(1 âˆ’p)2
=
4p2 âˆ’4p + 2 + p âˆ’p2 âˆ’1
p2(1 âˆ’p)2
= 3p2 âˆ’3p + 1
p2(1 âˆ’p)2
= p3 + (1 âˆ’p)3
p2(1 âˆ’p)2
=
p
(1 âˆ’p)2 + 1 âˆ’p
p2
.
Now, p(1 âˆ’p) has its maximum for p = 1
2 (corresponding to E{X} = 4), so p = 1
2 gives the
minimum of the mean, which one also intuitively would expect.
An alternative solution which uses quite another idea, is the following: Put
pn = P{HT occurs in the experiments of numbers n âˆ’1 and n},
fn = P{HT occurs for the ï¬rst time in the experiments of numbers n âˆ’1 and n}.
Then
(2) pn = f2pnâˆ’2 + f3pnâˆ’3 + Â· Â· Â· + fnâˆ’2p2 + fn.
We introduce the generating functions
P(s) =
âˆ

n=2
pnsn = pq
âˆ

n=2
snpq Â·
s2
1 âˆ’s,
s âˆˆ[0, 1],
F(s) =
âˆ

n=2
fnsn.
When (2) is multiplied by sn, and we sum with respect to n, we get alternatively
P(s)
=
âˆ

n=2
pnsn =
âˆ

n=2
nâˆ’2

k=2
fkpnâˆ’k

sn +
âˆ

n=2
fnsn =
âˆ

k=2
fk

âˆ

n=k+2
pnâˆ’ksnâˆ’k

sk + F(s)
=
âˆ

k=2
fksk Â· P(s) + F(s) = F(s){P(s) + 1},
and we derive that
F(s)
=
P(s)
P(s) + 1 = 1 âˆ’
1
P(s) + 1 = 1 âˆ’
1
pq
s2
1 âˆ’s + 1
= 1 âˆ’
1 âˆ’s
pqs2 + 1 âˆ’s
=
1 âˆ’
1 âˆ’s
(1 âˆ’ps)(1 âˆ’qs) = 1 + 1
pq
s âˆ’1

s âˆ’1
p
 
s âˆ’1
q

=
1 + 1
pq
â§
âª
âª
â¨
âª
âª
â©
1
p âˆ’1
1
p âˆ’1
q
Â·
1
s âˆ’1
p
+
1
q âˆ’1
1
q âˆ’1
p
Â·
1
s âˆ’1
q
â«
âª
âª
â¬
âª
âª
â­
.
Download free eBooks at bookboon.com

Analytic Aids
 
25 
4. Generating functions
By diï¬€erentiation,
F â€²(s)
=
1
pq
â§
âª
âª
âª
â¨
âª
âª
âª
â©
1
p âˆ’1
1
q âˆ’1
p
Â·
1

s âˆ’1
p
2 âˆ’
1
q âˆ’1
1
q âˆ’1
p
Â·
1

s âˆ’1
q
2
â«
âª
âª
âª
â¬
âª
âª
âª
â­
=
1
p âˆ’q
â§
âª
âª
âª
â¨
âª
âª
âª
â©
1 âˆ’p
p
Â·
1

s âˆ’1
p
2 âˆ’1 âˆ’q
q
Â·
1

s âˆ’1
q
2
â«
âª
âª
âª
â¬
âª
âª
âª
â­
=
pq
p âˆ’q

1
(1 âˆ’ps)2 âˆ’
1
(1 âˆ’qs)2
	
,
hence
E{X} = F â€²(1) =
pq
p âˆ’q
 1
q2 âˆ’1
p2
	
=
pq
p âˆ’q Â· p2 âˆ’q2
p2q2
= 1
pq =
1
p(1 âˆ’p).
Now, p(1 âˆ’p) is largest for p = 1
2, where E{X} is smallest, corresponding to E{X} = 4.
Furthermore,
F â€²â€²(s) =
pq
p âˆ’q

2p
(1 âˆ’ps)3 âˆ’
2q
(1 âˆ’qs)3
	
,
so
F â€²â€²(1)
=
pq
p âˆ’q
2p
q3 âˆ’2q
p3
	
=
2
p2q2 Â· p4 âˆ’q4
p âˆ’q
Â· p2 âˆ’q2
p2 âˆ’q2
=
2
p2q2 Â·

p2 + q2
= 2

(p + q)2 âˆ’2pq

p2q2
= 2(1 âˆ’2pq)
p2q2
,
and
V {X} = F â€²â€²(1) + F â€²(1) âˆ’{F â€²(1)}2 = 2 âˆ’4pq
p2q2
+ pq
p2q2 âˆ’
1
p2q2 = 1 âˆ’3pq
p2q2
,
which can be reduced to the other possible descriptions
p
q2 + q
p2 =
p
(1 âˆ’p)2 + 1 âˆ’p
p2
.
Download free eBooks at bookboon.com

Analytic Aids
 
26 
4. Generating functions
Example 4.4 1) The distribution of a random variable X is given by
P{X = k} = (âˆ’1)k
 âˆ’Î±
k

pÎ±qk,
k âˆˆN0,
where Î± âˆˆR+, p âˆˆ]0, 1[ and q = 1 âˆ’p. (Thus X âˆˆNB(Î±, p).) Prove that the generating function
of the random variable X is given by
P(s) = pÎ±(1 âˆ’qs)âˆ’Î±,
s âˆˆ[0, 1],
and use it to ï¬nd the mean of X.
2) Let X1 and X2 be independent random variables
X1 âˆˆNB (Î±1, p) ,
X2 âˆˆNB (Î±2, p) ,
Î±1, Î±2 âˆˆR+,
p âˆˆ]0, 1[.
Find the distribution function of the random variable X1 + X2.
3) Let (Yn)âˆ
n=3 be a sequence of random variables, where Yn âˆˆNB

n, 1 âˆ’2
n

.
Prove that the
sequence (Yn) converges in distribution towards a random variable Y , and ï¬nd the distribution
function of Y .
4) Compute P{Y > 4} (3 decimals).
1) The generating function for X for s âˆˆ[0, 1] is given by
P(s) =
âˆ

k=0
(âˆ’1)k
 âˆ’Î±
k

pÎ±qksk = pÎ±
âˆ

k=0
 âˆ’Î±
k

(âˆ’qs)k =
pÎ±
(1 âˆ’qs)Î± .
It follows from
P â€²(s) =
Î± q pÎ±
(1 âˆ’qs)Î±+1 ,
that
E{X} = P â€²(1) =
Î± q pÎ±
(1 âˆ’q)Î±+1 = Î± pÎ±q
pÎ±+1 = Î± Â· q
p.
2) Since X1 and X2 are independent, the generated function for X1 + X2 is given by
PX1+X2(s) =

p
1 âˆ’qs
	Î±1
Â·

p
1 âˆ’qs
	Î±2
=

p
1 âˆ’qs
	Î±1+Î±2
,
and we conclude that X1 + X2 âˆˆNB (Î±1 + Î±2, p), thus the distribution is given by
P {X1 + X2 = k} = (âˆ’1)k
 âˆ’Î±1 âˆ’Î±2
k

pÎ±1+Î±2qk,
k âˆˆN0,
Download free eBooks at bookboon.com

Analytic Aids
 
27 
4. Generating functions
3) The generating function Pn(s) for Yn is according to 1. given by
Pn(s) =

1 âˆ’2
n
n

1 âˆ’2
n s
n â†’eâˆ’2
eâˆ’2s = eâˆ’2(1âˆ’s) = P(s)
for n â†’âˆ.
Now, limsâ†’1âˆ’P(s) = e0 = 1, so it follows from the continuity theorem that (Yn) converges in
distribution towards a random variable Y of generating function
P(s) = eâˆ’2(1âˆ’s) = eâˆ’2e2s = eâˆ’2
âˆ

n=0
2n
n! sn =
âˆ

n=0
P{Y = n} sn.
When we identify the coeï¬ƒcients of sn, we see that the distribution is given by
P{Y = n} = 2n
n! eâˆ’2,
n âˆˆN0,
which we recognize as a Poisson distribution, Y âˆˆP(2).
4) Finally,
P{Y > 4}
=
1 âˆ’P{Y = 0} âˆ’P{Y = 1} âˆ’P{Y = 2} âˆ’P{Y = 3} âˆ’P{Y âˆ’4}
=
1 âˆ’eâˆ’2

1 + 2 + 2 + 4
3 + 2
3
	
= 1 âˆ’7
e2 â‰ˆ0.05265.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
MASTER IN MANAGEMENT
mim.admissions@ie.edu
Follow us on IE MIM Experience
www.ie.edu/master-management
#10 WORLDWIDE
MASTER IN MANAGEMENT 
FINANCIAL TIMES
55 Nationalities
in class
5 Specializations
Personalize your program 
Length: 1O MONTHS
Av. Experience: 1 YEAR
Language: ENGLISH / SPANISH
Format: FULL-TIME
Intakes: SEPT / FEB
â€¢ STUDY IN THE CENTER OF MADRID AND TAKE ADVANTAGE OF THE UNIQUE OPPORTUNITIES
  THAT THE CAPITAL OF SPAIN OFFERS
â€¢ PROPEL YOUR EDUCATION BY EARNING A DOUBLE DEGREE THAT BEST SUITS YOUR
  PROFESSIONAL GOALS
â€¢ STUDY A SEMESTER ABROAD AND BECOME A GLOBAL CITIZEN WITH THE BEYOND BORDERS
  EXPERIENCE
93%
OF MIM STUDENTS ARE
WORKING IN THEIR SECTOR 3 MONTHS
FOLLOWING GRADUATION

Analytic Aids
 
28 
4. Generating functions
Example 4.5 Consider a random variable X with its distribution given by
P{X = k} =
1
ea âˆ’1
ak
k! ,
k âˆˆN,
where a is a positive constant.
1. Find the generating function for X and ï¬nd the mean of X.
Let X1 and X2 be independent random variables, both having the same distribution as X.
2. Find the generating function for X1 + X2, and then ï¬nd the distribution of X1 + X2.
The distribution of X is a truncated Poisson distribution.
1) The generating function P(s) is
P(s) =
âˆ

k=1
P{X = k} sk =
1
ea âˆ’1
âˆ

k=1
(as)k
k!
= eas âˆ’1
ea âˆ’1 .
It follows from
P â€²(s) = a eas
ea âˆ’1,
that
E{X} = P â€²(s) =
a ea
ea âˆ’1.
2) Since X1 and X2 are independent, both of the same distribution as X, the generating function is
given by
P(s) = PX1+X2(s) = P1(s) Â· P2(s) =
1
(ea âˆ’1)2 (eas âˆ’1) ,
s âˆˆ[0, 1].
Then we perform a power expansion of those terms which contain s,
P(s)
=
1
(ea âˆ’1)2

e2as âˆ’2 eas + 1

=
1
(ea âˆ’1)2
âˆ

k=1(2)
1
k!

(2a)k âˆ’2ak
sk
=
1
(ea âˆ’1)2
âˆ

k=2
ak
k!

2k âˆ’2

sk =
âˆ

k=2
P {X1 + X2 = k} sk.
By identiï¬cation of the coeï¬ƒcients it follows that X1 + X2 has the distribution
P {X1 + X2 = k} =
1
(ea âˆ’1)2
ak
k!

2k âˆ’2

,
k = 2, 3, 4, . . . .
Remark 4.1 This result can - though it is very diï¬ƒcult â€“ also be found in the traditional way by
computation and reduction of
P {X1 + X2 = k} =
kâˆ’1

i=1
P {X1 = i} Â· P {X2 = k âˆ’i} .
â™¦
Download free eBooks at bookboon.com

Analytic Aids
 
29 
4. Generating functions
Example 4.6 A random variable X has the values 0, 2, 4, . . . of the probabilities
P{X = 2k} = p qk,
k âˆˆN0,
where p > 0, q > 0 and p + q = 1.
1. Find the generating function for X.
2. Find, e.g. by applying the result of 1., the mean E{X}.
We deï¬ne for every n âˆˆN a random variable Yn by
Yn = X1 + X2 + Â· Â· Â· + Xn,
where the random variables Xi are mutually independent and all of the same distribution as X.
3. Find the generating function for Yn.
Given a sequence of random variables (Zn)âˆ
n=1, where for every n âˆˆN the random variable Zn has
the same distribution as Yn corresponding to
p = 1 âˆ’1
2n,
q = 1
2n.
4. Prove, e.g. by applying the result of 3. that the sequence (Zn) converges in distribution towards a
a random variable Z, and ï¬nd the distribution of Z.
5. Is it true that E {Zn} â†’E{Z} for n â†’âˆ?
1) The generating function is
PX(s) =
âˆ

k=0
p qks2k = p
âˆ

k=0

q s2k =
p
1 âˆ’qs2
for s âˆˆ[0, 1].
2) It follows from
P â€²
X(s) =
2qps
(1 âˆ’qs2)2 ,
that
E{X} = P â€²
X(1) = 2pq
p2 = 2q
p .
Alternatively we get by the traditional computation that
E{X} =
âˆ

k=1
2kpqk = 2pq
âˆ

k=1
kqkâˆ’1 = 2pq
p2 = 2q
p .
3) The generating function for Yn = n
i=1 Xi is
PYn = {PX(s)}n =

p
1 âˆ’qs2
2
for s âˆˆ[0, 1].
Download free eBooks at bookboon.com

Analytic Aids
 
30 
4. Generating functions
4) If we put p = 1 âˆ’1
2n, q = 1
2n, then Zn has according to 3. the generating function
PZn(s) =

1 âˆ’1
2n
n

1 âˆ’s2
2n
n .
Since

1 + a
n
n
â†’ea for n â†’âˆ, we get
PZn(s) â†’
exp

âˆ’1
2

exp

âˆ’s2
2
 = exp
1
2

s2 âˆ’1

,
for n â†’âˆ,
where the limit function is continuous. This means that (Zn) converges in distribution towards a
random variable Z, the generating function of which is given by
PZ(s) = exp
1
2

s2 âˆ’1

.
We get by expanding this function into a power series that
PZ(s) = 1
âˆše exp
1
2 s2

= 1
âˆše
âˆ

k=0
1
k!
1
2
k
s2k.
It follows that Z has the distribution
P{Z = 2k} = 1
k!
1
2
k
1
âˆše
for k âˆˆN0,
thus Z
2 is Poisson distributed with parameter 1
2.
5) From
E {Zn} = n Â·
2 Â· 1
2n
1 âˆ’1
2n
=
1
1 âˆ’1
2n
â†’1 = E{Z}
for n â†’âˆ,
follows that the answer is â€œyesâ€.
Download free eBooks at bookboon.com

Analytic Aids
 
31 
4. Generating functions
Example 4.7 A random variable U, which is not causally distributed, has its distribution given by
P{U = k} = pk,
k âˆˆN0,
and its generating function is
P(s) =
âˆ

k=0
pksk,
s âˆˆ[0, 1].
The random variable U1 has its distribution given by
P {U1 = 0} = 0,
P {U1 = k} =
pk
1 âˆ’p0
,
k âˆˆN.
1. Prove that U1 has its generating function P1(s) given by
P1(s) = P(s) âˆ’p0
1 âˆ’p0
,
s âˆˆ[0, 1].
We assume that the number of persons per household residential neighbourhood is a random variable
X with its distribution given by
P{X = k} =
3k
k! (e3 âˆ’1),
k âˆˆN,
(a truncated Poisson distribution).
2. Compute, e.g. by using the result of 1., the generating function for X. Compute also the mean of
X.
Let the random variable Y be given by Y =
1
2
X
.
3. Compute, e.g. by using the result of 2., the mean and variance of Y .
The heat consumption Z per quarter per house (measured in m3 district heating water) is assumed to
depend of the number of persons in the house in the following way:
Z = 200

1 âˆ’
1
2
X
= 200(1 âˆ’Y ).
4. Compute the mean and the dispersion of Z. The answers should be given with 2 decimals.
1) A direct computation gives
P1(s) =
âˆ

k=1
pk
1 âˆ’p0
sk =
1
1 âˆ’p0
 âˆ

k=0
pksk âˆ’p0

= P(s) âˆ’p0
1 âˆ’p0
.
Download free eBooks at bookboon.com

Analytic Aids
 
32 
4. Generating functions
2) Also here be direct computation,
PX(s) =
1
e3 âˆ’1
âˆ

k=1
1
k! (3s)k = e3s âˆ’1
e3 âˆ’1 .
Alternatively we can apply 1., though this is far more diï¬ƒcult, because one ï¬rst have to realize
that we shall choose
pk = 1
e3 Â· 3k
k! ,
k âˆˆN0,
with
P(s) = e3(sâˆ’1).
Then we shall check that these candidates of the probabilities are added up to 1, and then prove
that
P {U1 = k} =
pk
1 âˆ’p0
,
k âˆˆN,
and ï¬nally insert
P1(s) = PX(s) = e3(sâˆ’1) âˆ’eâˆ’3
1 âˆ’eâˆ’3
= e3s âˆ’1
e3 âˆ’1 .
The mean is
E{X} = P(1) =
 3e3s
e3 âˆ’1

s=1
=
3e3
e3 âˆ’1 = 3 +
3
33 âˆ’1 â‰ˆ3.15719.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more

Analytic Aids
 
33 
4. Generating functions
3) We get by the deï¬nition,
E

sX
= PX(s) = e3s âˆ’1
e3 âˆ’1 ,
where we obtain the mean of Y =
1
2
X
by putting s = 1
2, thus
E{Y } = E
1
2
X
=
exp
3
2

âˆ’1
e3 âˆ’1
=
1
exp
3
2

+ 1
â‰ˆ0, 18243.
Analogously,
E

Y 2
= E
1
2
2X
= E
1
4
X
= PX
1
4

=
exp
3
4

âˆ’1
e3 âˆ’1
,
hence
V {Y } =
exp
3
4

âˆ’1
e3 âˆ’1
âˆ’
â§
âª
âª
â¨
âª
âª
â©
exp
3
2

âˆ’1
e3 âˆ’1
â«
âª
âª
â¬
âª
âª
â­
2
â‰ˆ0.02525.
4) The mean of Z is obtained by a direct computation,
E{Z} = 200 E{Y } = 163.514.
The corresponding dispersion is
s =
 
V {Z} = 200
 
V {Y } = 31.7786.
Download free eBooks at bookboon.com

Analytic Aids
 
34 
4. Generating functions
Example 4.8 Let X1, X2, . . . be mutually independent random variables, all of distribution given by
P {Xi = k} = p qkâˆ’1,
k âˆˆN,
where p > 0, q > 0 and p + q = 1.
Furthermore, let N be a random variable, which is independent of the Xi and which has its distribution
given by
P{N = n} = an
n! eâˆ’a,
n âˆˆN0,
where a is a positive constant.
1. Find the generating function P(s) for the random variable X1.
2. Find the generating function for the random variable n
i=1 Xi, n âˆˆN.
3. Find the generating function for the random variable N.
We introduce another random variable Y by
(3) Y = X1 + X2 + Â· Â· Â· + XN,
where N denotes the random variable introduced above, and where the number of random variables on
the right hand side of (3) is itself a random variable (for N = 0 we interpret (3) as Y = 0).
4. Prove that the random variable Y has its generating function PY (s) given by
PY (s) = exp
a(s âˆ’1)
1 âˆ’qs

,
0 â‰¤s â‰¤1.
Hint: One may use that
P{Y = 0} = P{N = 0},
P{Y = k} =
âˆ

n=1
P{N = n} Â· P {X1 + X2 + Â· Â· Â· + Xn = k} ,
k âˆˆN.
5. Compute the mean E{Y }.
1) The generating function for X1 is
P(s) =
âˆ

k=1
pqkâˆ’1sk = ps
âˆ

k=1
(qs)kâˆ’1 =
ps
1 âˆ’qs,
s âˆˆ[0, 1].
2) The generating function for n
i=1 Xi is
Pn(s) = P(s)n =

ps
1 âˆ’qs
n
,
s âˆˆ[0, 1] og n âˆˆN.
Download free eBooks at bookboon.com

Analytic Aids
 
35 
4. Generating functions
3) The generating function for N is
Q(s) =
âˆ

n=0
an
n! eâˆ’asn = eâˆ’1 Â· eas = ea(sâˆ’1).
4) Now,
P{Y = 0} = P{N = 0} = eâˆ’a,
so the generating function for YN is
PY (s)
=
P{Y = 0} +
âˆ

k=1
P{Y = k} sk
=
eâˆ’a +
âˆ

k=1
 âˆ

m=1
P{N = n} Â· P {X1 + X2 + Â· Â· Â· + Xn = k}

sk
=
eâˆ’a +
âˆ

n=1
 âˆ

k=1
P {X1 + X2 + Â· Â· Â· + Xn = k} sk

=
âˆ

n=0
P{N = n} (Pn(s)) = Q(P(s))
=
Q

ps
1 âˆ’qs

= exp

a

ps
1 âˆ’qs âˆ’1
	
=
exp

a ps âˆ’1 + qs
1 âˆ’qs

= exp
a(s âˆ’1)
1 âˆ’qs

.
5) It follows from
P â€²
Y (s) = PY (s) Â· a

1
1 âˆ’qs + q(s âˆ’1)
(1 âˆ’qs)2
	
,
that the mean is
E{Y } = P â€²
Y (1) = PY (1) Â· a Â·
1
1 âˆ’q = a
p.
Download free eBooks at bookboon.com

Analytic Aids
 
36 
4. Generating functions
Example 4.9 Let X1, X2, . . . be mutually independent random variables, all of distribution given by
P {Xi = k} =
1
ln 3 Â· 1
k
2
3
k
,
k âˆˆN.
Furthermore, let N be a random variable, which is independent of the Xi and Poisson distributed with
parameter a = ln 9.
1. Find the mean of X1.
2. Find the generating function for the random variable X1.
3. Find the generating function for the random variable n
i=1 Xi, n âˆˆN.
4. Find the generating function for the random variable N.
Introduce another random variable Y by
(4) Y = X1 + X2 + Â· Â· Â· + XN,
where N denotes the random variable introduced above, and where the number of random variables on
the right hand side of (4) also is a random variable (for N = 0 we interpret (4) as Y = 0).
5. Find the generating function for Y , and then prove that Y is negative binomially distributed.
Hint: One may use that
P{Y = 0} = P{N = 0},
P{Y = k} =
âˆ

n=1
P{N = n} Â· P {X1 + X2 + Â· Â· Â· + Xn = k} ,
k âˆˆN.
6. Find the mean of Y .
1) The mean is
E {X1} =
1
ln 3
âˆ

k=1
k Â· 1
k
2
3
k
=
1
ln 3 Â·
2
3
1 âˆ’2
3
=
1
ln 3 Â· 2
3 Â· 1
1
3
=
2
ln 3.
2) The generating function for X1 is
PX1(s) =
1
ln 3
âˆ

k=1
1
k
2
3
k
sk =
1
ln 3
âˆ

k=1
1
k
2s
3
k
=
1
ln 3 ln
â›
âœ
â
1
1 âˆ’2s
3
â
âŸ
â =
1
ln 3 ln

3
3 âˆ’2s

.
3) Since the Xi are mutually independent, we get
Pn(s) = {PX1(s)}n =
 1
ln 3 ln

3
3 âˆ’2s
	n
.
Download free eBooks at bookboon.com

Analytic Aids
 
37 
4. Generating functions
4) Since N âˆˆP(ln 9), we obtain the generating function either by using a table or by the computation
PN(s) =
âˆ

n=0
(ln 9)n
n!
eâˆ’ln 9sn = 1
9
âˆ

n=0
1
n! (s ln 9)n = 1
9 es ln 9 = 9sâˆ’1.
5) First compute
P{Y = 0} = P{N = 0} = 1
9
[= PN(0)].
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
â€œThe perfect start 
of a successful, 
international career.â€
CLICK HERE 
to discover why both socially 
and academically the University 
of Groningen is one of the best 
places for a student to be 
www.rug.nl/feb/education
Excellent Economics and Business programmes at:

Analytic Aids
 
38 
4. Generating functions
This implies that the generating function for Y is
PY (s)
=
1
9 +
âˆ

k=1
P{Y = k}sk = 1
9 +
âˆ

k=1
âˆ

n=1
P{N = n} Â· P {X1 + Â· Â· Â· + Xn = k} sk
=
1
9 +
âˆ

n=1
P{N = n} Â·
âˆ

k=1
P
 n

i=1
Ci = k

sk = 1
9 +
âˆ

n=1
P{N = n} Â· (PX1(s))n
=
âˆ

n=0
P{N = n} (PX1(s))n = PN (PX1(s)) = 1
9
âˆ

n=0
1
n!

ln 9 Â·
1
ln 3 ln

3
3 âˆ’2s
n
=
1
9 exp

2 ln

3
3 âˆ’2s

= 1
9
1

1 âˆ’2
3 s
2 =
â§
âª
â¨
âª
â©
1
3
1 âˆ’2
3 s
â«
âª
â¬
âª
â­
2
,
which according to the table corresponds to Y âˆˆNB

2, 1
3

.
6) We get by using a table,
E{Y } = 2 Â·
1 âˆ’1
3
1
3
= 4.
Alternatively,
P â€²
Y (s) = 1
9 Â· 22
3 Â·
1

1 âˆ’2
3 s
3 = 4
27 Â·
1

1 âˆ’2
3 s
3 ,
hence
E{Y } = P â€²
Y (1) = 4
27 Â·
1
1
3
3 = 4.
Download free eBooks at bookboon.com

Analytic Aids
 
39 
4. Generating functions
Example 4.10 The number N of a certain type of accidents in a given time interval is assumed to
be Poisson distributed of parameter a, and the number of wounded persons in the i-th accident is
supposed to be a random variable Xi of the distribution
(5) P {Xi = k} = (1 âˆ’q)qk,
k âˆˆN0,
where 0 < q < 1. We assume that the Xi are mutually independent and all independent of the random
variable N.
1. Find the generating function for N.
2. Find the generating function for Xi and the generating function for n
i=1 Xi, n âˆˆN.
The total number of wounded persons is a random variable Y given by
(6) Y = X1 + X2 + Â· Â· Â· + XN,
where N denotes the random variable introduced above, and where the number of random variables on
the right hand side of (6) is itself a random variable.
3. Find the generating function for Y , and ï¬nd the mean E{Y }.
Given a sequence of random variables (Yn)âˆ
n=1, where for each n âˆˆN the random variable Yn has the
same distribution as Y above, corresponding to a = n and q = 1
3n.
4. Find the generating function for Yn, and prove that the sequence (Yn) converges in distribution
towards a random variable Z.
5. Find the distribution of Z.
1) If N âˆˆP(a), then
P{N = n} = an
n! eâˆ’a,
n âˆˆN0,
and its generating function is
PN(s) = exp(a(s âˆ’1)).
2) The generating function for Xi is
PXi(s) =
âˆ

k=0
(1 âˆ’q)qksk = (1 âˆ’q)
âˆ

k=0
(qs)k = 1 âˆ’q
1 âˆ’qs.
The generating function for n
i=1 Xi is given by
PPn
i=1 Xi(s) =
 1 âˆ’q
1 âˆ’qs
n
.
3) Since all the random variables are mutually independent, the generating function for Y = X1 +
X2 + Â· Â· Â· + XN is given by
PY (s) = PN (PXi(s)) = exp

a
 1 âˆ’q
1 âˆ’qs âˆ’1

= exp

aq s âˆ’1
1 âˆ’qs

.
Download free eBooks at bookboon.com

Analytic Aids
 
40 
4. Generating functions
4) The generating function for Yn is given by
PYn(s) = exp
â›
ân Â· 1
3n Â· s âˆ’1
1 âˆ’s
3n
â
â = exp
â›
â1
3 Â· s âˆ’1
1 âˆ’s
3n
â
â .
When n â†’âˆwe see that
PYn(s) â†’P(s) = exp
s âˆ’1
3

.
Since limsâ†’1âˆ’P(s) = 1, we conclude that P(s) is the generating function for some random variable
Z, thus
PZ(s) = exp
s âˆ’1
3

.
5) It follows immediately from 4. that Z âˆˆP
1
3

is Poisson distributed with parameter a = 1
3.
Example 4.11 Let X1, X2, X3, . . . be mutually independent random variables, all of distribution
given by
P {Xi = k} = p1 (1 âˆ’p1)kâˆ’1 ,
k âˆˆN,
hvor p1 âˆˆ]0, 1[,
and let N be a random variable, which is independent of all the Xi-erne, and which has its distribution
given by
P{N = n} = p2 (1 âˆ’p1)nâˆ’1 ,
n âˆˆN,
p2 âˆˆ]0, 1[.
1. Find the generating function PX1(s) for X1 and the generating function PN(s) for N.
2. Find the generating function for the random variable n
i=1 Xi, n âˆˆN.
Introduce another random variable Y by
(7) Y = X1 + X2 + Â· Â· Â· + XN,
where N denotes the random variable introduced above, and where the number of random variables on
the right hand side of (7) is itself a random variable.
3. Find the generating function for Y , and then prove that Y is geometrically distributed.
4. Find mean and variance of Y .
1) We get either by using a table or by a simple computation that
PX1(s) =
âˆ

k=1
p1 (1 âˆ’p1)kâˆ’1 sk = p1s Â·
âˆ

k=1
{(1 âˆ’p1) s}kâˆ’1 =
p1s
1 âˆ’(1 âˆ’p1) s,
s âˆˆ[0, 1].
We get analogously,
PN(s) =
p2s
1 âˆ’(1 âˆ’p2) s
for s âˆˆ[0, 1].
Download free eBooks at bookboon.com

Analytic Aids
 
41 
4. Generating functions
2) The generating function for n
i=1 Xi is
(PX1(s))n =

p1s
1 âˆ’(1 âˆ’p1) s
n
,
s âˆˆ[0, 1].
3) The generating function for Y is
PY (s)
=
PN (PX1(s)) =
p2 Â·
p1s
1 âˆ’(1 âˆ’p1) s
1 âˆ’(1 âˆ’p2) Â·
p1s
1 âˆ’(1 âˆ’p1) s
=
p1p2s
1 âˆ’(1 âˆ’p1) s âˆ’(1 âˆ’p2) p1s
=
(p1p2) s
1 âˆ’(1 âˆ’p1p2) s,
s âˆˆ[0, 1].
This is the generating function for a geometric distribution of parameter p1p2, so Y is geometrically
distributed.
4) From Y being geometrically distributed of parameter p1p2 it follows that
E{Y } =
1
p1p2
and
V {Y } = 1 âˆ’p1p2
(p1p2)2 .
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
American online      
LIGS University 
â–¶â–¶enroll by September 30th, 2014 and 
â–¶â–¶save up to 16% on the tuition!
â–¶â–¶pay in 10 installments / 2 years
â–¶â–¶Interactive Online education
â–¶â–¶visit www.ligsuniversity.com to 
      find out more!
is currently enrolling in the
Interactive Online BBA, MBA, MSc, 
DBA and PhD  programs:
Note: LIGS University is not accredited by any 
nationally recognized accrediting agency listed 
by the US Secretary of Education. 
More info here. 

Analytic Aids
 
42 
4. Generating functions
Remark 4.2 The distribution of Y may also be found without using the generating function. In fact,
P{Y = k} =
k

n=1
P{N = n} Â· P {X1 + X2 + Â· Â· Â· + Xn = k} .
Since X1 + X2 + Â· Â· Â· + Xn âˆˆPas (n, p1), we get
P{Y = k}
=
k

n=1
p2 (1 âˆ’p2)nâˆ’1

k âˆ’1
n âˆ’1

pn
1 (1 âˆ’p1)kâˆ’n
=
p1p2 (1 âˆ’p1)kâˆ’1
k

n=1

k âˆ’1
n âˆ’1
 
p1
1 âˆ’p2
1 âˆ’p1
	nâˆ’1
=
p1p2 (1 âˆ’p1)kâˆ’1
kâˆ’1

â„“=0
 k âˆ’1
â„“
 p1 (1 âˆ’p2)
1 âˆ’p1
	â„“
=
p1p2 (1 âˆ’p1)kâˆ’1

1 + p1 (1 âˆ’p2)
1 âˆ’p1
	kâˆ’1
=
p1p2 {1 âˆ’p1 + p1 âˆ’p1p2}kâˆ’1 = (p1p2) Â· (1 âˆ’p1p2)kâˆ’1 ,
and we have given an alternative proof of the claim that Y is geometrically distributed of param-
eter p1p2. â–¡
Download free eBooks at bookboon.com

Analytic Aids
 
43 
4. Generating functions
Example 4.12 1. Let U be a random variable with values only in N0, and let V = 3U. Prove the
following connection between the generating functions of U and V ,
PV (s) = PU

s3
,
0 â‰¤s â‰¤1.
Let the random variable X have its distribution given by
P{X = 3k} = p(1 âˆ’p)kâˆ’1,
k âˆˆN,
where p is a constant, 0 < p < 1.
2. Prove, e.g. by using the result of 1. that X has the generating function
pX(s) =
ps3
1 âˆ’(1 âˆ’p)s3 ,
0 â‰¤s â‰¤1,
and then ï¬nd the Laplace transform LX(Î») of X.
A sequence of random variables (Xn)âˆ
n=1 is deï¬ned by Xn taking the values 3
n, 6
n, 9
n, . . . of the
probabilities
P

Xn = 3k
n
	
= 1
3n

1 âˆ’1
3n
kâˆ’1
,
k âˆˆN.
3. Find the Laplace transform LXn(Î») of the random variable Xn.
4. Prove that the sequence (Xn) converges in distribution towards some random variable Y , and ï¬nd
the distribution function of Y .
1) By the deï¬nition,
PU(s) =
âˆ

k=0
P{U = k} sk.
From V = 3U follows that
PV (s) =
âˆ

k=0
P{V = 3U = 3s} s3k =
âˆ

k=0
P{U = k} s3k = PU

s3
.
2) Let Y âˆˆPas(1, p) be geometrically distributed. Then
PY (s) =
ps
1 âˆ’qs =
ps
1 âˆ’(1 âˆ’p)s.
From X = 3Y and 1. we get
PX(s) =
ps3
1 âˆ’(1 âˆ’p)s3 .
The Laplace transform of X is
LX(Î»)
=
âˆ

k=1
P{X = 3k} eâˆ’3kÎ» =
âˆ

k=1
p(1 âˆ’o)kâˆ’1eâˆ’3kÎ»
=
p Â· eâˆ’3Î»
âˆ

k=1

(1 âˆ’p)eâˆ’3Î»kâˆ’1 =
p eâˆ’3Î»
1 âˆ’(1 âˆ’p)eâˆ’3Î» .
Download free eBooks at bookboon.com

Analytic Aids
 
44 
4. Generating functions
3) We derive the Laplace transform of Xn from the Laplace transform of X by putting p = 1
3n and
by replacing Î» by Î»
n, thus
LXn(Î») =
1
3n exp

âˆ’3Î»
n

1 âˆ’

1 âˆ’1
3n

exp

âˆ’3Î»
n
 =
1
3n
exp

+3Î»
n

âˆ’1 + 1
3n
.
4) Now,
exp
3Î»
n

âˆ’1 + 1
3n = 1 + 3Î»
n + 1
n Îµ
 1
n

âˆ’1 + 1
3n = 1
3n (1 + 9Î») + 1
n Îµ
 1
n

,
so
LXn(Î») =
1
1 + 9Î» + Îµ
 1
n
 â†’
1
1 + 9Î» = LZ(Î»),
where Z âˆˆÎ“

1, 1
9

is exponentially distributed, thus (Xn) converges in distribution towards
Z âˆˆÎ“

1, 1
9

.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more

Analytic Aids
 
45 
4. Generating functions
Example 4.13 A football team shall play 5 tournament matches.
The coach judges that in each
match there is the probability 2
5 for victory, 2
5 for defeat, and 1
5 for draw, and that the outcome of a
match does not inï¬‚uence on the probabilities of the following matches.
A victory gives 2 points, a draw gives 1 point, and a defeat gives 0 point.
Let the random variable X indicate the number of victories in the 5 matches, and let Y indicate the
number of obtained points in the 5 matches. Then we can also write
X =
5

i=1
Xi
and
Y =
5

i=1
Yi,
where
Xi =
â§
â¨
â©
1,
if victory in match number i,
0,
otherwise,
and
Yi =
â§
âª
âª
âª
âª
â¨
âª
âª
âª
âª
â©
2,
if victory in match number i,
1,
if draw in match number i,
0,
if defeat in match number i.
1) Compute P{X = k}, k = 0, 1, 2, 3, 4, 5, and the mean E{X}.
2) Find the mean and variance of Y .
3) Compute P{Y = 10}.
4) Compute P{Y = 8}.
5) Find the generating function for Yi, and then ï¬nd (use a pocket calculator) the generating function
for
Y =
5

i=1
Yi.
Compute also the probabilities P{Y = k}, k = 0, 1, 2, . . . , 10.
6) In the Danish tournament league a victory gives 3 points, a draw gives 1 point, and a defeat gives
0 point. Let Z denote the number of obtained points in the 5 matches (all other assumptions are
chosen as the same as above). Then Z can as value have all integers between 0 and 15, with one
exception (which one?). Find all the probabilities by using generating functions in the same way
as in 5..
1) Since X âˆˆB

5, 2
5

is binomially distributed, we get
pk = P{X = k} =
 5
k
 2
5
k 3
5
5âˆ’k
,
k = 0, 1, 2, 3, 4, 5,
Download free eBooks at bookboon.com

Analytic Aids
 
46 
4. Generating functions
We get more explicitly,
p0 =
3
4
5
= 243
3125,
p1 = 5 Â· 2
5
3
5
4
= 810
3125 = 162
625,
p2 = 10 Â·
2
5
2 3
5
3
= 1080
2125 = 216
625,
p3 = 10 Â·
2
5
3 3
5
2
= 720
3125 = 144
625,
p4 = 5 Â·
2
5
3
4 Â· 3
5
= 240
3125 = 48
625,
p5 =
2
5
5
=
32
3125.
The mean is
E{X} = 5 Â· 2
5 = 2.
2) The mean of Yi is
E {Yi} = 2 Â· 2
5 + 1 Â· 1
5 + 0 Â· 2
5 = 1
for i = 1, . . . , 5,
and since
E

Y 2
i

= 4 Â· 2
5 + 1 Â· 1
5 + 0 Â· 2
5 = 9
5
for i = 1, . . . , 5,
the variances are
V {Yi} = 9
5 âˆ’12 = 4
5.
Now the Yi are mutually independent, so it follows that
E{Y } =
5

i=1
E {Yi} = 5
and
V {Y } =
5

i=1
V {Yi} = 4.
3) If Y = 10, then the team must have won all 5 matches, thus
P{Y = 10} = P{X = 5} =
2
5
5
=
32
3125.
4) The case Y = 8 occurs if either we have 4 victories and 1 defeat, or 3 victories and 2 draws. Hence
P{Y = 8} = 5 Â·
2
5
4
Â· 2
5 +
 5
3
 2
5
3 1
5
2
= 5 Â· 25 + 10 Â· 23
55
= 240
3125 = 48
625.
Download free eBooks at bookboon.com

Analytic Aids
 
47 
4. Generating functions
5) From
p0 = 2
5,
p1 = 1
5
and
p2 = 2
5,
follows that the generating function for each Yi is given by
a(s) = 2
5 s2 + 1
5 s + 2
5 = 1
5

2s2 + s + 2

.
This implies that the generating function for Y = 5
i=1 Yi is given by (either by using a pocket
calculator or MAPLE)
PY (s)
=
a(s)5 =
2
5 s2 + 1
5 s + 2
5
5
=
32
3125 s10 + 16
625 s9 + 48
625 s8 + 72
625 s7 + 114
625 s6 + 561
3125 s5 + 114
625 s4 + 72
625 s3
+ 48
625 s2 + 16
625 s +
32
3125.
It follows that P{Y = k} is the coeï¬ƒcient of sk.
6) Clearly, P{Z = 14} = 0. In fact, 5 victories gives 15 points, and the second best result is described
by 4 victories and 1 draw, corresponding to k = 4 Â· 3 + 1 Â· 1 = 13.
In this new case the generating function for each Zi is given by
b(s) = 2
5 s3 + 1
5 s + 2
5 = 1
5

2s3 + s + 2

,
where we have replaced s2 by s3.
Thus the generating function for Z = 5
i=1 Zi is given by
PZ(s)
=
b(s)5 =
2
5 s3 + 1
5 s + 2
5
5
=
32
3125 s15 + 0 Â· s14 + 16
625 s13 + 32
625 s12 + 16
625 s11 + 64
625 s10 + 72
625 s9 + 48
625 s8
+ 98
625 s7 + 16
125 s6 + 241
3125 s5 + 66
625 s4 +
8
125 s3 + 16
625 s20 16
625 s +
32
3125,
which can also be written in the following way, in which it is easier to evaluate the magnitudes of
the coeï¬ƒcients,
PZ(s)
=
1
3125

32s15 + 80s13 + 160s12 + 80s11 + 320s10
+360s9 + 240s8 + 490s7 + 400s6 + 241s5 +330s4 + 200s3 + 80s2 + 80s + 32

.
Since P{Z = k} is the coeï¬ƒcient of sk in PZ(s), we conclude that under the given assumptions
there is the biggest chance for obtaining 7 points,
P{Z = 7} = 490
3125 = 98
625.
Download free eBooks at bookboon.com

Analytic Aids
 
48 
5. the Laplace transformation
5
The Laplace transformation
Example 5.1 Let X be exponentially distributed of the frequency
f(x) =
â§
â¨
â©
a eâˆ’ax,
x > 0,
0,
x â‰¤0.
Find LX(Î»), and use it to ï¬nd E{X} and V {X}.
We ï¬rst note that
LX(Î») =
 âˆ
0
a eâˆ’axeâˆ’Î»x dx = a
 âˆ
0
eâˆ’(Î»+a)x dx =
a
Î» + a.
Hence
E{X} = [âˆ’Lâ€²
X(Î»)]Î»=0 =

âˆ’

âˆ’
a
(Î» + a)2

Î»=0
= a
a2 = 1
a,
and
E

X2
) [Lâ€²â€²
X(Î»)]Î»=0 =

2a
(Î» + a)3

Î»=0
= 2a
a3 = 2
a2 ,
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
 
  
 
                . 

Analytic Aids
 
49 
5. the Laplace transformation
from which
V {X} = E

X2
âˆ’(E{X})2 = 2
a2 âˆ’1
a2 = 1
a2 ,
in accordance with previous results.
Example 5.2 Let X1, X2, . . . be mutually independent random variables, where Xk is Gamma dis-
tributed with form parameter k and scale parameter 1, thus Xk âˆˆÎ“(k, 1), k âˆˆN. Deï¬ne
Yn =
n

k=1
Xk
and
Zn = 1
n2 Yn,
n âˆˆN.
1) Find the means E {Yn} and E {Zn}.
2) Find the Laplace transform of Yn and the Laplace transform of Zn.
3) Prove, e.g. by using the result of 2., that the sequence (Zn)âˆ
n=1 converges in distribution towards a
random variable Z, and ï¬nd the distribution function of Z.
We get from Xk âˆˆÎ“(k, 1) that
E {Xk} = k
and
LXk(Î») =

1
1 + Î»
k
.
1) The means are
E {Yn} =
n

k=1
E {Xk} =
n

k=1
k = 1
2 n(n + 1),
E {Zn} = 1
n2 E {Yn} = n + 1
2n
= 1
2 + 1
2n.
2) From
Yn âˆˆÎ“
 n

k=1
k , 1

= Î“
n(n + 1)
2
, 1

,
follows that
LYn(Î») =

1
1 + Î»
 n(n+1)
2
.
Alternatively,
LYn(Î») =
n

k=1
LXk(Î») =
n

k=1

1
1 + Î»
k
=

1
1 + Î»
 n(n+1)
2
,
thus the same result.
Download free eBooks at bookboon.com

Analytic Aids
 
50 
5. the Laplace transformation
Since LZn(Î») is obtained from LYn(Î») by replacing Î» by Î»
n2 , we get
LZn(Î») = LYn
 Î»
n2

=
1

1 + Î»
n2
 n(n+1)
2
.
3) Since the denominator converges for n â†’âˆ,

1 + Î»
n2
 n(n+1)
2
=

1 + Î»
n2
n2
Â·

1 + Î»
n2
n 1
2
â†’

eÎ» Â· 1
 1
2 = exp
Î»
2

for n â†’âˆ,
we get
LZn(Î») â†’exp

âˆ’Î»
2

= LZ(Î»)
for n â†’âˆ,
so (Zn) converges in distribution towards a causally distributed random variable Z with the dis-
tribution function
FZ(z) =
â§
âª
âª
â¨
âª
âª
â©
0
for z < 1
2,
1
for z â‰¥1
2.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
www.mastersopenday.nl
Visit us and find out why we are the best!
Masterâ€™s Open Day: 22 February 2014
Join the best at
the Maastricht University
School of Business and
Economics!
Top masterâ€™s programmes
â€¢ 33rd place Financial Times worldwide ranking: MSc 
International Business
â€¢ 1st place: MSc International Business
â€¢ 1st place: MSc Financial Economics
â€¢ 2nd place: MSc Management of Learning
â€¢ 2nd place: MSc Economics
â€¢ 2nd place: MSc Econometrics and Operations Research
â€¢ 2nd place: MSc Global Supply Chain Management and 
Change
Sources: Keuzegids Master ranking 2013; Elsevier â€˜Beste Studiesâ€™ ranking 2012; 
Financial Times Global Masters in Management ranking 2012
Maastricht
University is
the best specialist
university in the
Netherlands
(Elsevier)

Analytic Aids
 
51 
5. the Laplace transformation
Example 5.3 A random variable Z has the values 1, 2, . . . with the probabilities
P{Z = k} = âˆ’1
ln p Â· qk
k ,
where p > 0, q > 0 and p + q = 1. We say that Z has a logarithmic distribution.
1. Find the Laplace transform LZ(Î») of Z.
2. Find the mean of the random variable Z.
We consider a sequence of random variables (Xn)âˆ
n=2, where Xn has the values 1, 2, . . . of the
probabilities
P {Xn = k} = âˆ’
1
ln pn
Â· qk
n
k ,
where qn = 1
n and pn + qn = 1.
3. Prove that the sequence (Xn) converges in distribution towards a random variable X, and ï¬nd the
distribution function of X.
1) The Laplace transform is
LZ(Î») =
âˆ

n=1
P{Z = n}eÎ»n = âˆ’1
ln p
âˆ

n=1
qn
n eâˆ’Î»n = âˆ’1
ln p
âˆ

n=1

qeâˆ’Î»n
n
= ln

1 âˆ’qeâˆ’Î»
ln p
.
2) By a straightforward computation,
E{Z} = âˆ’1
ln p
âˆ

k=1
k Â· qk
k = âˆ’1
ln p Â·
q
1 âˆ’q = âˆ’
q
p ln p.
Alternatively,
E{Z} = âˆ’Lâ€²
Z(0) = âˆ’1
ln p Â·

qeâˆ’Î»
1 âˆ’qeâˆ’Î»

Î»=0
= âˆ’1
ln p Â·
q
1 âˆ’q = âˆ’
q
p ln p.
3) It follows from 1. that
LXk(Î») = ln

1 âˆ’qkeâˆ’Î»
ln pk
=
ln

1 âˆ’1
k eâˆ’Î»

ln

1 âˆ’1
k

.
For every ï¬xed Î» > 0 we get by lâ€™Hospitalâ€™s rule, where we put x = 1
k ,
lim
kâ†’âˆLXk(Î») = lim
kâ†’âˆ
ln

1 âˆ’1
k eâˆ’Î»

ln

1 âˆ’1
k

= lim
xâ†’0
ln

1 âˆ’x eâˆ’Î»
ln(1 âˆ’x)
= lim
xâ†’0
âˆ’eâˆ’Î»
1 âˆ’x eâˆ’Î»
âˆ’
1
1 âˆ’x
= eâˆ’Î».
Download free eBooks at bookboon.com

Analytic Aids
 
52 
5. the Laplace transformation
If Î» = 0, then LXk = eâˆ’0 for every k, so
LX(Î») =
â§
â¨
â©
for Î» > 0,
1
for Î» = 0,
and LX(Î») exists for all Î» â‰¥0, and it is continuous at Î» = 0. This implies that (Xn) converges
in distribution towards some random variable X, which has the Laplace transform LX(Î») = eâˆ’Î»,
from which we conclude that X is causally distributed with a = 1, thus P{X = 1} = 1.
Example 5.4 A random variable X has the values 1, 2, . . . of the probabilities
P{X = k} = pqkâˆ’1,
hvor p > 0, q > 0, p + q = 1.
1. Find the Laplace transform of X.
We consider a sequence of random variables (Xn)âˆ
n=1, where Xn has the values 1
n, 2
n, . . . of the
probabilities
P

Xn = k
n
	
= a
n

1 âˆ’a
n
kâˆ’1
,
k âˆˆN
(here a âˆˆ]0, 1[ is a constant).
2. Prove that the mean of Xn does not depend on n.
3. Find the Laplace transform of Xn.
4. Prove that the sequence (Xn) converges in distribution towards a random variable Y , and ï¬nd the
distribution function of Y .
1. The Laplace transform is
LX(Î») =
âˆ

n=1
eâˆ’Î»npqnâˆ’1 = p
q
âˆ

n=1

qeâˆ’Î»n = p
q Â·
q Â· eâˆ’Î»
1 âˆ’qeâˆ’Î» =
p eâˆ’Î»
1 âˆ’qeâˆ’Î» .
2. and 3. The Laplace transform of Xn is
LX(Î»)
=
âˆ

n=1
exp

âˆ’Î» k
n

Â· a
n

1 âˆ’a
n
kâˆ’1
=
a
n
1 âˆ’a
n
âˆ

k=1

exp

âˆ’Î»
n

1 âˆ’a
n
	k
=
a
k
1 âˆ’a
n
Â·

1 âˆ’a
n

exp

âˆ’Î»
n

1 âˆ’

1 âˆ’a
n

exp

âˆ’Î»
n
 =
a
n exp

âˆ’Î»
n

1 âˆ’Î»

1 âˆ’a
n

exp

âˆ’Î»
n

=
a
n
1 âˆ’a
n
Â·
1
1 âˆ’

1 âˆ’a
n

exp

âˆ’âˆ’Î»
n
 âˆ’
a
n
1 âˆ’a
n
,
Download free eBooks at bookboon.com

Analytic Aids
 
53 
5. the Laplace transformation
hence
E {Xn}
=
âˆ’Lâ€²
Xn(0) = âˆ’
a
n
1 âˆ’a
n
Â·

1 âˆ’a
n

Â·

âˆ’1
n

exp

âˆ’Î»
n


1 âˆ’

1 âˆ’a
n

exp

âˆ’Î»
n
	2
â¤
â¥â¥â¥â¦
Î»=0
=
a
n
1 âˆ’a
n
Â·

1 âˆ’a
n

Â· 1
n
 a
n
2
= 1
a,
which is independent of n.
4. It follows by lâ€™Hospitalâ€™s rule that
lim
nâ†’âˆLXn(Î»)
=
lim
nâ†’âˆ
a
n exp

âˆ’Î»
n

1 âˆ’

1 âˆ’a
n

exp

âˆ’Î»
n
 = lim
xâ†’0
a x eâˆ’Î»x
1 âˆ’(1 âˆ’a x)eâˆ’Î»x
=
a lim
xâ†’0
eâˆ’Î»x âˆ’Î» x eâˆ’Î»x
Î»(1 âˆ’a x)eâˆ’Î»x + a eâˆ’Î»x = a lim
xâ†’0
1 âˆ’Î» x
Î»(1 âˆ’a x) + a =
a
Î» + a = LY (Î»),
and we get by using a table that Y âˆˆÎ“

1, 1
a

is exponentially distributed. This proves that (Xn)
converges in distribution towards Y .
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more

Analytic Aids
 
54 
5. the Laplace transformation
Example 5.5 A random variable X has the values 1, 2, . . . of the probabilities
P{X = k} =
akâˆ’1
(k âˆ’1)! eâˆ’a,
k âˆˆN,
where a is some positive constant.
1. Find the Laplace transform of X.
2. Find the mean of X.
We consider a sequence of random variables (Yn)âˆ
n=1, where for each n âˆˆN the random variable Yn
has its distribution given by
P

Yn = k
2n
	
= (2n)kâˆ’1
(k âˆ’1)! eâˆ’2n,
k âˆˆN.
3. Find the Laplace transform of Yn.
4. Prove, e.g. by using the result of 3., that the sequence (Yn)âˆ
n=1 converges in distribution towards a
random variable Y , and ï¬nd the distribution function of Y .
5. Is it true that E {Yn} â†’E{Y } for n â†’âˆ?
1) The Laplace transform of X is
LX(Î»)
=
âˆ

k=1
akâˆ’1
(k âˆ’1)! eâˆ’a Â· eâˆ’Î»k = eâˆ’a Â· eâˆ’Î»
âˆ

k=0
ak
k!

eâˆ’Î»k = eâˆ’aâˆ’Î» Â· exp

a eâˆ’Î»
=
exp

âˆ’a âˆ’Î» + a eâˆ’Î»
= exp

a

eâˆ’Î» âˆ’1

âˆ’Î»

,
Î» â‰¥0.
2) The mean is
E{X} =
âˆ

k=1
kÂ· akâˆ’1
(k âˆ’1)! eâˆ’a = eâˆ’a
âˆ

k=0
k + 1
k!
ak = eâˆ’a
 âˆ

k=1
ak
(k âˆ’1)! +
âˆ

k=0
1
k! ak

= eâˆ’a(a+1)ea = a+1.
Alternatively,
Lâ€²
X(Î») =

âˆ’1 âˆ’a eâˆ’Î»
exp

âˆ’a âˆ’Î» + a eâˆ’Î»
,
sËša
E{X} = âˆ’Lâ€²
X(0) = 1 + a.
3) The Laplace transform of Xn with a = 2n is
LX
 Î»
2n; a = 2n

= exp

âˆ’2n âˆ’Î» + 2n exp

âˆ’Î»
2n

= exp

2n

exp

âˆ’Î»
2n

âˆ’1
	
âˆ’Î»

.
Since Xn = 2nYn, the Laplace transform of Yn is given by
LYn(Î») = LXn
 Î»
2n

= exp

2n

exp

âˆ’Î»
2n

âˆ’1
	
âˆ’Î»
2n

,
Î» â‰¥0.
Download free eBooks at bookboon.com

Analytic Aids
 
55 
5. the Laplace transformation
4) It follows from
LYn(Î»)
=
exp

2n

1 âˆ’Î»
2n + Î»
2n Îµ
 Î»
2n

âˆ’1
	
âˆ’Î»
2n

=
exp

âˆ’Î» + Î» Îµ
 Î»
2n

âˆ’Î»
2n

â†’eâˆ’Î»
for n â†’âˆ,
that Yn
D
âˆ’â†’Y , where Y has the distribution function
FY (y) =
â§
â¨
â©
1
for y â‰¥1,
0
for y < 1.
5) Since
E {Yn} = 1
2n (2n + 1) = 1 + 1
2n â†’1 = E{Y },
we conclude that the answer is â€œyesâ€.
Example 5.6 A random variable X has the values 1, 3, 5, . . . of probabilities
P{X = 2k + 1} = p(1 âˆ’p)k,
k âˆˆN0,
where p is a constant, 0 < p < 1.
1. Find the Laplace transform LX(Î») of the random variable X.
2. Find the mean of the random variable X.
We consider a sequence of random variables (Xn)âˆ
n=1 , where Xn has the values 1
n, 3
n, 5
n, . . . of the
probabilities
P

Xn = 2k + 1
n
	
= 1
2n

1 âˆ’1
2n
k
,
k âˆˆN0.
3. Find the Laplace transform LXn(Î») of the random variable Xn.
4. Find the mean of the random variable Xn.
5. Prove that the sequence (Xn) converges in distribution towards a random variable Y , and ï¬nd the
distribution function of Y .
1) The Laplace transform is
LX(Î»)
=
âˆ

k=0
p(1 âˆ’p)k exp(âˆ’Î»(2k + 1)) = p eâˆ’Î»
âˆ

k=0

(1 âˆ’p)eâˆ’2Î»k
=
p eâˆ’Î»
1 âˆ’(1 âˆ’p)eâˆ’2Î» =
p eÎ»
e2Î» âˆ’(1 âˆ’p).
Download free eBooks at bookboon.com

Analytic Aids
 
56 
5. the Laplace transformation
2) The mean is
E{X}
=
âˆ

k=0
(2k + 1)p(1 âˆ’p)k = 2p(1 âˆ’p)
âˆ

k=1
k(1 âˆ’p)kâˆ’1 + p
âˆ

k=0
(1 âˆ’p)k
=
2p(1 âˆ’p) Â·
1
{1 âˆ’(1 âˆ’p)}2 + p Â·
1
1 âˆ’(1 âˆ’p)
=
2p(1 âˆ’p)
p2
+ p
p = 2 1 âˆ’p
p
+ 1 = 2
p âˆ’1.
Alternatively,
Lâ€²
X(Î») = LX(Î») Â·

p eÎ»
e2Î» âˆ’(1 âˆ’p) âˆ’
2p eÎ»
{e2Î» âˆ’(1 âˆ’p)}2

,
thus
E{X} = âˆ’Lâ€²
X(0) = âˆ’1 + 2p
p2 = 2
p âˆ’1.
3) If we put p = 1
2n, then we get LXn(Î») from LX(Î») by replacing Î» by Î»
n, thus
LXn(Î») = LX
Î»
n

=
1
2n exp
Î»
n

exp
2Î»
n

âˆ’

1 âˆ’1
2n
 =
exp
Î»
n

2n

exp
2Î»
n

âˆ’1
	
+ 1
.
4) It follows from
Lâ€²
Xn(Î») = 1
n mLXn(Î») âˆ’
exp
Î»
n


2n

exp
2Î»
n

âˆ’1

+ 1
	2 Â· 2n Â· 2
n,
that
E {Xn} = âˆ’Lâ€²
Xn(0) = âˆ’1
n + 4 = 4 âˆ’1
n.
Alternatively,
E {Xn}
=
âˆ

k=0
2k + 1
n
Â· 1
2n

1 âˆ’1
2n
k
=
1
n2

1 âˆ’1
2n
 âˆ

k=1
k

1 âˆ’1
2n
kâˆ’1
+ 1
n Â· 1
2n
âˆ

k=0

1 âˆ’1
2n
k
=
1
n2

1 âˆ’1
2n

Â·
1

1 âˆ’

1 âˆ’1
2n
	2 +
1
2n2 Â·
1
1 âˆ’

1 âˆ’1
2n

=
1
n2

1 âˆ’1
2n

Â·
1
 1
2n
2 +
1
2n2 Â· 1
1
2n
= 4

1 âˆ’1
2n

+ 1
n = 4 âˆ’1
n.
Download free eBooks at bookboon.com

Analytic Aids
 
57 
5. the Laplace transformation
5) It follows from
2n

exp
2Î»
n

âˆ’1
	
+ 1 = 2n

1 + 2Î»
n + 2Î»
n Îµ
2Î»
n

âˆ’1
	
+ 1 = 1 + 4Î» + 4Î» Îµ
2Î»
n

,
that
LXn(Î») =
exp
Î»
n

2n

exp
2Î»
n

âˆ’1
	
+ 1
=
exp
Î»
n

1 + 4Î» + 4Î» Îµ
2Î»
n
 â†’
1
1 + 4Î»
for n â†’âˆ.
Now,
1
1 + 4Î» is continuous for Î» âˆˆ[0, âˆ[. Hence (Xn) converges in distribution towards a random
variable Y , where LY (Î») =
1
1 + 4Î» corresponds to Y âˆˆÎ“(1, 4), i.e. an exponential distribution of
frequency
fY (y) =
â§
âª
â¨
âª
â©
1
4 exp

âˆ’y
4

for y > 0,
0
for y â‰¤0.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Get Help Now
Go to www.helpmyassignment.co.uk for more info
Need help with your
dissertation?
Get in-depth feedback & advice from experts in your 
topic area. Find out what you can do to improve
the quality of your dissertation!

Analytic Aids
 
58 
5. the Laplace transformation
Example 5.7 The random variables X1, X2 and X3 are assumed to be mutually independent and
each of them following a rectangular distribution over the interval ]0, 1[.
Let X denote the random variable
X = X1 + X2 + X3.
1) Find the mean and variance of the random variable X.
Hint: Find ï¬rst the frequency of X1 + X2.
2) Find the Laplace transform L(Î») of the random variable X, and prove that
L(Î») = 1 âˆ’3
2 Î» + 5
4 Î»2 + Î»2Îµ(Î»).
1) We conclude from
E {X1} = E {X2} = E {X3} = 1
2,
that
E{X} = E {X1} + E {X2} + E {X3} = 3
2.
Since
V {X1} = V {X2} = V {X3} = 1
12,
and X1, X2 and X3 are mutually independent, we get
V {X} = V {X1} + V {X2} + V {X3} = 3 Â· 1
12 = 1
4.
0
0.2
0.4
0.6
0.8
1
1.2
0.5
1
1.5
2
Figure 1: The graph of g(y).
Download free eBooks at bookboon.com

Analytic Aids
 
59 
5. the Laplace transformation
2) The frequency g(y) of Y = X1 + X2 is 0 for y /âˆˆ]0, 2[. If 0 < y < 2, then
g(y) =
 y
0
f(y âˆ’s)f(s) ds.
Hence, for 0 < y < 1,
g(y) =
 y
0
f(y âˆ’s)f(s) ds =
 y
0
1 Â· 1 ds = y.
If 1 â‰¤y < 2, then we get instead
g(y) =
 y
0
f(y âˆ’s)f(s) ds =
 1
yâˆ’1
1 Â· 1 ds = 2 âˆ’y.
Summing up, the frequency of Y = X1 + X2 is given by
g(y) =
â§
âª
âª
âª
âª
â¨
âª
âª
âª
âª
â©
y
for y ]0, 1[,
2 âˆ’y
for y âˆˆ[1, 2[
0
otherwise.
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.5
1
1.5
2
2.5
3
Figure 2: The graph of h(x).
The frequency h(x) of X = X1 + X2 + X3 = Y + X3 is 0 for x /âˆˆ]0, 3[.
If 0 < x < 3, then
h(x) =
 x
0
g(s)f(x âˆ’s) ds =
 x
0
g(x âˆ’s)f(s) ds.
We shall now split the investigation into the cases of the three intervals ]0, 1[, [1, 2[ and [2, 3[.
a) If x âˆˆ]0, 1[, then
h(x) =
 x
0
g(x âˆ’s) Â· 1 ds =
 x
0
(x âˆ’s) ds =

âˆ’1
2 (x âˆ’s)2
x
s=0
= x2
2 .
Download free eBooks at bookboon.com

Analytic Aids
 
60 
5. the Laplace transformation
b) If x âˆˆ[1, 2[, then
h(x)
=
 x
0
g(x âˆ’s)f(s) ds =
 1
0
g(x âˆ’s) Â· 1 ds
=
 xâˆ’1
0
g(x âˆ’s) ds +
 1
xâˆ’1
g(x âˆ’s) ds
=
 xâˆ’1
0
{2 âˆ’(x âˆ’s)} ds +
 1
xâˆ’1
(x âˆ’s) ds
=
1
2 (2 âˆ’x + s)2
xâˆ’1
s=0
+

âˆ’1
2 (x âˆ’s)2
2
s=xâˆ’1
=
1
2

(2 âˆ’x + x âˆ’1)2 âˆ’(2 âˆ’x)2 + (x âˆ’x + 1)2 âˆ’(x âˆ’1)2
=
1
2

1 âˆ’(x âˆ’s)2 + 1 âˆ’(x âˆ’1)2
=
1
2

2 âˆ’x2 + 4x âˆ’4 âˆ’x2 + 2x âˆ’1

= 1
2

âˆ’2x2 + 6x âˆ’3

=
3
4 âˆ’

x âˆ’3
2
2
.
c) If x âˆˆ[2, 3[, then
h(x)
=
 x
0
g(x âˆ’s)f(s) ds =
 1
0
g(x âˆ’s) Â· 1 ds =
 x
xâˆ’1
g(t) dt =
 2
xâˆ’1
g(t) dt
=
 2
xâˆ’1
(2 âˆ’t) dt =

âˆ’1
2 (2 âˆ’t)2
2
xâˆ’1
= 1
2
(2 âˆ’x + 1)2
2
= 1
2 (3 âˆ’x)2.
Summing up, the frequency h(x) of X is given by
h(x) =
â§
âª
âª
âª
âª
âª
âª
âª
âª
âª
âª
âª
âª
âª
â¨
âª
âª
âª
âª
âª
âª
âª
âª
âª
âª
âª
âª
âª
â©
1
2 x2
for x âˆˆ]0, 1[,
3
4 âˆ’

x âˆ’3
2
2
for x âˆˆ[1, 2[,
1
2 (3 âˆ’x)2
for x âˆˆ[2, 3[,
0
otherwise.
3) When Î» â‰¥0 and i = 1, 2, 3, then
LXi(Î») =
 âˆ
0
eâˆ’Î»tf(t) dt =
 1
0
eâˆ’Î»t dt =

âˆ’1
Î» eâˆ’Î»t
1
0
= 1 âˆ’eâˆ’Î»
Î»
.
Download free eBooks at bookboon.com

Analytic Aids
 
61 
5. the Laplace transformation
Since X1, X2 and X3 are mutually independent, we get
LX(Î»)
=
1 âˆ’eâˆ’Î»
Î»
3
= 1
Î»3

1 âˆ’
âˆ

n=0
(âˆ’1)n
n!
Î»n
3
=

1
Î»
âˆ

n=1
(âˆ’1)n+1
n!
Î»n
3
=
 âˆ

n=1
(âˆ’1)nâˆ’1
n!
Î»nâˆ’1
3
=
 âˆ

n=0
(âˆ’1)n
(n + 1)! Î»n
3
=

1 âˆ’Î»
2 + Î»2
6 + Î»2Îµ(Î»)
	3
=

1 + Î»4
4 âˆ’Î» + Î»2
3 + Î»2Îµ(Î»)
	
Â·

1 âˆ’Î»
2 + Î»2
6 + Î»2Îµ(Î»)
	
=

1 âˆ’Î» + 7
12 Î»2 + Î»2Îµ(Î»)
	
Â·

1 âˆ’Î»
2 + Î»2
6 + Î»2Îµ(Î»)
	
=
1 âˆ’
1
2 + 1

Î» +
1
6 + 1
2 + 7
12

Î»2 + Î»2Îµ(Î») = 1 âˆ’3
2 Î» + 2 + 6 + 7
12
Î»2 + Î»2Îµ(Î»)
=
1 âˆ’3
2 Î» + 5
4 Î»2 + Î»2Îµ(Î»).
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
By 2020, wind could provide one-tenth of our planetâ€™s 
electricity needs. Already today, SKFâ€™s innovative know-
how is crucial to running a large proportion of the 
worldâ€™s wind turbines. 
Up to 25 % of the generating costs relate to mainte-
nance. These can be reduced dramatically thanks to our 
systems for on-line condition monitoring and automatic 
lubrication. We help make it more economical to create 
cleaner, cheaper energy out of thin air. 
By sharing our experience, expertise, and creativity, 
industries can boost performance beyond expectations. 
Therefore we need the best employees who can 
meet this challenge!
The Power of Knowledge Engineering
Brain power
Plug into The Power of Knowledge Engineering. 
Visit us at www.skf.com/knowledge

Analytic Aids
 
62 
5. the Laplace transformation
Example 5.8 A random variable Y has the frequency
f(y) =
â§
â¨
â©
a2y eâˆ’ay,
y â‰¥0
0,
y < 0,
where a is a positive constant.
1. Find the Laplace transform LY (Î») of the random variable Y .
2. Find the mean of the random variable Y .
A random variable Y has the values 0, 1, 2, 3, . . . of the probabilities
P{X = k} = (k + 1)p2qk,
where p > 0, q > 0, p + q = 1.
3. Find the Laplace transform LX(Î») of X.
Find the mean of X.
A sequence of random variables (Xn) is given by Xn having the values 0, 1
n, 2
n, . . . of the probabilities
P

Xn = k
n
	
= (k + 1)
 a
n
2 
1 âˆ’a
n
k
,
where a is a constant, 0 < a < 1.
5. Find the Laplace transform of Xn.
6. Find the mean of the random variable Xn.
7. Prove that the sequence (Xn) converges in distribution towards a random variable Y (as deï¬ned
above).
8. Prove that E {Xn} â†’E{Y } for n â†’âˆ.
1) If Î» â‰¥0, then
LY (Î») =
 âˆ
0
a2y eâˆ’ayeâˆ’Î»y dy =
a2
(Î» + a)2
 âˆ
0
(a + Î»)2y eâˆ’(a+Î»y) dy =
a2
(Î» + a)2 =
1

1 + Î»
a
2 .
2) The mean is
E{Y } = âˆ’Lâ€²
Y (0) = âˆ’
âˆ’2

1 + Î»
a
3 Â· 1
a
â¤
â¥â¥â¥â¦
Î»=0
= 2
a.
Download free eBooks at bookboon.com

Analytic Aids
 
63 
5. the Laplace transformation
3) If Î» â‰¥0, then
LX(Î») =
âˆ

n=0
eâˆ’Î»n(n + 1)p2qn =
âˆ

n=0
(n + 1)p2 
q eâˆ’Î»n =
p2
(1 âˆ’q eâˆ’Î»)2 .
4) The mean is
E{X} = âˆ’Lâ€²
X(0) = âˆ’lim
Î»â†’0
âˆ’2p2
(1 âˆ’q eâˆ’Î»)3 Â·

âˆ’q eâˆ’Î»
Â· (âˆ’1) =
2p2q
(1 âˆ’q)3 = 2 q
p.
5) If Xn, then
LXn(Î») =
âˆ

k=0
exp

âˆ’Î» k
n

(k + 1)
 a
n
2 
1 âˆ’a
n
k
=
 a
n
2

1 âˆ’exp

âˆ’Î»
n
 
1 âˆ’a
n
	2 .
6) The mean is
E {Xn}
=
âˆ’Lâ€²
Xn(0) = âˆ’lim
Î»â†’0
 a
n
2
Â· (âˆ’2)
âˆ’

1 âˆ’a
n

exp

âˆ’Î»
n

Â·

âˆ’1
n


1 âˆ’exp

âˆ’Î»
n
 
1 âˆ’a
n
	3
=
 a
n
2
Â·
2

1 âˆ’

1 âˆ’a
n
3 Â·

1 âˆ’a
n

Â· 1
n = 2
n Â·
1 âˆ’a
n
a
n
= 2
a âˆ’2
n.
7) We get by a rearrangement,
LXn(Î») =
 a
n
2

1 âˆ’exp

âˆ’Î»
n
 
1 âˆ’a
n
	2 =
a2

n âˆ’exp

âˆ’Î»
n

(n âˆ’a)
	2 ,
where
n âˆ’exp

âˆ’Î»
n

Â· (n âˆ’a) = n

1 âˆ’exp

âˆ’Î»
n
	
+ a Â· exp

âˆ’Î»
n

= n

1 âˆ’

1 âˆ’Î»
n + Î»
n Îµ
Î»
n
	
+ a exp

âˆ’Î»
n

= Î» + n Â· Î»
n Îµ
Î»
n

+ a Â· exp

âˆ’Î»
n

â†’Î» + a
for n â†’âˆ.
Hence
lim
nâ†’âˆLXn(Î») =
a2
(Î» + a)2 = LY (Î»).
Since LY (Î») is continuous at 0, it follows that {Xn} converges in distribution towards Y .
Download free eBooks at bookboon.com

Analytic Aids
 
64 
5. the Laplace transformation
8) The claim follows trivially from
lim
nâ†’âˆE {Xn} = 2 lim
nâ†’âˆ
1
a

1 âˆ’a
n

= 2
a = E{Y }.
Example 5.9 A random variable X has the frequency
fX(x) =
â§
â¨
â©
a eâˆ’ax,
x â‰¥0,
0,
x < 0,
where a is a positive constant.
1) Find for every n âˆˆN the mean E {Xn}.
2) Find the Laplace transform LX(Î») of X and show that it is given by
LX(Î») = 1 âˆ’Î»
a âˆ’
Î»
a
2
âˆ’
Î»
a
3
+
Î»
a
4
+ Î»4Îµ(Î»).
3) A random variable Y is given by U = kX, where k is a positive constant. Find the distribution
function of Y .
4) Let U and V be independent random variables of the frequencies
fU(u) =
â§
â¨
â©
2a eâˆ’2au,
u â‰¥0,
0,
u < 0,
fV (v) =
â§
â¨
â©
3a eâˆ’3av,
v â‰¥0,
0,
v < 0.
The random variable Z is given by Z = 2U + 3V .
Find the frequency of Z.
1) We get by a straightforward computation,
E {Xn} =
 âˆ
0
a xneâˆ’ax dx = 1
an
 âˆ
0
tneâˆ’n dt = n!
an .
2) If Î» â‰¥0, then
LX(Î») =
 âˆ
0
a eâˆ’axeâˆ’Î»x dx = a
 âˆ
0
eâˆ’(a+Î»)x dx =
a
a + Î» =
1
1 + Î»
a
.
If 0 â‰¤Î» < a, then
LX(Î») =
1
1 + Î»
a
= 1 âˆ’Î»
a +
Î»
a
2
âˆ’
Î»
a
3
+
Î»
a
4
+ Î»4Îµ(Î»).
Download free eBooks at bookboon.com

Analytic Aids
 
65 
5. the Laplace transformation
3) The distribution of Y for y > 0 is given by
P{Y â‰¤y} = P{kX â‰¤y} =

X â‰¤y
k

=

y
k
0
a aâˆ’ax dx = 1 âˆ’exp

âˆ’a
k y

,
hence the frequency is
fY (y) =
â§
âª
âª
âª
â¨
âª
âª
âª
â©
a
k exp

âˆ’a
k y

for y â‰¥0,
0
for y < 0.
4) It follows from 3. that 2U has the frequency fX(u), and that 3V has the frequency fX(v). (In the
former case k = 2, and in the latter case k = 3).
This means that 2U, 3V âˆˆÎ“

1, 1
a

, so
Z = 2U + 3V âˆˆÎ“

1 + 1, 1
a

= Î“

2, 1
a

,
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more

Analytic Aids
 
66 
5. the Laplace transformation 
5. the Laplace transformation
and the frequency of Z is given by
fZ(z) =
â§
â¨
â©
a2z eâˆ’az
for z > 0,
0
for z â‰¤0.
Example 5.10 Given a sequence of random variables (Xn)âˆ
n=1, where Xn has the distribution func-
tion
Fn(x) =
â§
âª
âª
âª
âª
âª
âª
â¨
âª
âª
âª
âª
âª
âª
â©
0
for x < 0,
n2x2
for 0 â‰¤x â‰¤1
n,
1
for x > 1
n
1) Find for every n âˆˆN the mean E {Xn} and variance V {Xn}.
2) Prove that the sequence (Xn) converges in probability towards a random variable X, and ï¬nd the
distribution function of X.
3) Find the Laplace transform Ln(Î») of the random variable Xn.
Is the sequence of functions (Ln(Î»)) convergent?
4) Find the distribution function of Yn = X2
n.
5) Assuming that the random variables X1 and X2 are independent, we shall ï¬nd the frequency of the
random variable Z = X1 + X2.
1) The frequencies are obtained by diï¬€erentiation,
fn(x) =
â§
âª
âª
âª
âª
âª
âª
â¨
âª
âª
âª
âª
âª
âª
â©
0
for x â‰¤0,
2n2x
for 0 < x < 1
n,
0
for x â‰¥1
n,
hence
E {Xn} =

1
n
0
2n2x2 dx = 2n2
x3
3
 1
n
0
= 2
3n,
and
E

X2
n

=

1
n
0
2n2x3 dx = 2n2
x4
4
 1
n
0
=
1
2n2 ,
whence
V {Xn} = E

X2
n

âˆ’(E {Xn}) =
1
2n2 âˆ’
4
9n2 =
1
18n2 .
Download free eBooks at bookboon.com

Analytic Aids
 
67 
5. the Laplace transformation
2) If x â‰¤0, then of course Fn(x) = 0 â†’0 for n â†’âˆ.
If x > 0, then there is an N, such that x > 1
n for every n â‰¥N, thus Fn(x) = 1 for n â‰¥N, and
Fn(x) â†’1 for n â†’âˆ. We conclude that (Fn(x)) converges in distribution towards the causal
distribution
F(x) =
â§
â¨
â©
0
for x â‰¤0,
1
for x > 1.
3) If Î» > 0, then
Ln(Î»)
=
 âˆ
0
eâˆ’Î»xfn(x) dx = 2n2

1
n
0
eâˆ’Î»xx dx = 2n2 *
âˆ’x
Î» eâˆ’Î»x+ 1
n
0 + 2n2
Î»

1
n
0
eâˆ’Î»x dx
=
âˆ’2n2 Â· 1
Î»n Â· exp

âˆ’Î»
n

+ 2n2
Î»

âˆ’1
Î» eâˆ’Î»x
 1
n
0
= âˆ’2n
Î» exp

âˆ’Î»
n

+ 2n2
Î»2

1 âˆ’exp

âˆ’Î»
n

.
Then by a series expansion,
Ln(Î»)
=
âˆ’2n
Î»

1 âˆ’Î»
n + 1
2!
Î»2
n2 + Î»2
n2 Îµ
Î»
n
	
+ 2n2
Î»2

1 âˆ’

1 âˆ’Î»
n + 1
2 Â· Î»2
n2 + Î»2
n2 Îµ
Î»
n
	
=
âˆ’2n
Î» + 2 âˆ’Î»
n + Î»
n Îµ
Î»
n

+ 2n
Î» âˆ’1 + 2 Îµ
Î»
n

= 1 âˆ’Î»
n + Îµ1
Î»
n

,
and we conclude that Ln(Î») â†’1 for Î» â†’0+ and n â†’âˆ.
4) If y > 0, then
P {Yn â‰¤y} = P

(Xn)2 â‰¤y

= P {Xn â‰¤âˆšy} = Fn (âˆšy) ,
hence
P {Yn â‰¤y} =
â§
âª
âª
âª
âª
âª
âª
â¨
âª
âª
âª
âª
âª
âª
â©
0
for y â‰¤0,
n2y
for 0 â‰¤y â‰¤1
n2 ,
1
for y > 1
n2 .
5) We ï¬rst note that
fZ(z) =
 âˆ
0
f1(x)f2(z âˆ’x) dx =
 1
0
2x Â· f2(z âˆ’x) dx.
If fZ(z) Ì¸= 0, then z âˆ’x âˆˆ

0, 1
2

, thus x âˆˆ[0, 1] âˆ©

z âˆ’1
2, z

.
In particular, fZ(z) = 0 if either z â‰¤0 or z â‰¥3
2.
Download free eBooks at bookboon.com

Analytic Aids
 
68 
5. the Laplace transformation
If z âˆˆ

0, 1
2

, then
fZ(z)
=
 z
0
2x Â· 2 Â· 4 Â· (z âˆ’x) dx = 16
 z
0

zx âˆ’x2
dx
=
16

z Â· x2
2 âˆ’x3
3
z
x=0
= 16
z3
2 âˆ’z3
3

= 8
3 z3.
If z âˆˆ
1
2, 1

, then
fZ(z)
=
 z
zâˆ’1
2
16

zx âˆ’x2
dx = 16

z Â· x2
2 âˆ’x3
3
z
zâˆ’1
2
=
8
3 z3 âˆ’8

z âˆ’1
2
2
z + 16
3

z âˆ’1
2
3
=
8
3 z3 âˆ’8z3 + 8z2 âˆ’2z + 16
3 z3 âˆ’8z2 + 4z âˆ’2
3 = 2z âˆ’2
3.
Finally, if z âˆˆ

1, 3
2

, then
fZ(z =
=
 1
zâˆ’1
2
16

zx âˆ’x2
dx = 16

z x2
2 âˆ’x3
3
1
zâˆ’1
2
=
16
1
2 z âˆ’1
3

âˆ’16
,
z
2

z âˆ’1
2
2
âˆ’1
3

z âˆ’1
2
3-
=
8z âˆ’16
3 âˆ’8z3 + 8z2 âˆ’2z + 16
3 z3 âˆ’8z2 + 4z âˆ’2
3
=
âˆ’8
3 z3 + 10z âˆ’6.
Summing up,
fZ(z) =
â§
âª
âª
âª
âª
âª
âª
âª
âª
âª
âª
âª
âª
âª
âª
â¨
âª
âª
âª
âª
âª
âª
âª
âª
âª
âª
âª
âª
âª
âª
â©
8
3 z3
for z âˆˆ

0, 1
2

,
2z âˆ’2
3
for z âˆˆ
1
2, 1

,
âˆ’8
3 z3 + 10z âˆ’6
for z âˆˆ

1, 3
2

,
0
otherwise.
Download free eBooks at bookboon.com

Analytic Aids
 
69 
5. the Laplace transformation
Example 5.11 Let X1, X2, . . . be mutually independent and identically distributed random variables
of values in [0, âˆ[, and let L(Î») denote the Laplace transform of Xi.
Let N be a random variable, independent of all the Xi-erne and of values in N0, and let P(s) be the
generating function of N.
Let the random variable YN be given by
YN = X1 + X2 + Â· Â· Â· + XN
(where the number of random variables on the right hand side is itself a random variable).
1. Prove that YN has the Laplace transform LYN (Î») given by
LYN (Î») = P(L(Î»)),
Î» â‰¥0.
Assume in particular that all Xi are exponentially distributed of parameter a, and let N be Poisson
distributed of parameter b.
2. Find in this special case LYN (Î»), and the mean and variance of YN.
3. Find also in this special case the distribution function of Y .
1) We apply
P {YN â‰¤y} =
âˆ

n=0
P{N = n} Â· P {Yn â‰¤y} .
(8)
Then
LYN (Î»)
=
 âˆ
0
eâˆ’Î»y d
dy P {YN â‰¤y} dy =
 âˆ
0
eâˆ’Î»y
âˆ

n=0
P{N = n} Â· d
dy P {Yn â‰¤y} dy
=
âˆ

n=0
P{N = n}
 âˆ
0
eâˆ’Î»yfn(y) dy =
âˆ

n=0
P{N = n}
 âˆ
0
eâˆ’Î»yf(y) dy
n
=
âˆ

n=0
P{N = n} (L(Î»))n = P(L(Î»)).
2) When Xi âˆˆÎ“

1, 1
a

, then
L(Î») =
a
Î» + a.
When N âˆˆP(b), then
P(s) = exp(b{s âˆ’1}).
Then it follows from 1. that
LYN (Î») = P(L(Î»)) = exp

b

a
Î» + a âˆ’1

= exp

âˆ’b Â·
Î»
Î» + a

.
Download free eBooks at bookboon.com

Analytic Aids
 
70 
5. the Laplace transformation
Since
Lâ€²
YN (Î») = âˆ’
ba
(Î» + a)2 exp

âˆ’b Â·
Î»
Î» + a

,
we get
E{X} = âˆ’Kâ€²
YN (0) = ba
a2 = b
a.
From
Lâ€²â€²
YN (Î») =

ba
(Î» + a)2
2
exp

âˆ’b Â·
Î»
Î» + a

+
2ba
(Î» + a)3 exp

âˆ’b Â·
Î»
Î» + a

,
follows that
E

X2
= Lâ€²â€²
YN (0) = b2
a2 + 2b
a2 ,
and we conclude that
V {X} = 2b
a2 .
3) This question is underhand, because one is led to consider LYN (Î»), which does not give easy
computation. We shall instead apply that if y > 0, then
G(y) = P{Y â‰¤y} = P{N = 0} +
âˆ

k=1
P{N = k} Â· P {X1 + Â· Â· Â· + Xk â‰¤y} .
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more

Analytic Aids
 
71 
5. the Laplace transformation
We see that G(y) has a jump at y = 0 of the size
P{N = 0} = eâˆ’b,
and that G(y) for y > 0 is diï¬€erentiable with the derivative
Gâ€²(y) = fYn(y) =
âˆ

n=1
P{N = n} Â· fYn(y).
Since N âˆˆP(b), we get
P{N = n} = bn
n! eâˆ’b.
Since
Yn =
n

j=1
Xj âˆˆÎ“

n, 1
a

,
we get
fYn(y) =
an
(n âˆ’1)! ynâˆ’1eâˆ’ay.
Hence, Y has a jump at y = 0 of the size eâˆ’b, and if y > 0, then
Gâ€²(y) = fYN (y) =
âˆ

n=1
bn
n! eâˆ’b Â·
an
(n âˆ’1)! yneâˆ’ay.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
EXPERIENCE THE POWER OF 
FULL ENGAGEMENTâ€¦
     RUN FASTER.
          RUN LONGER..
                RUN EASIERâ€¦
READ MORE & PRE-ORDER TODAY 
WWW.GAITEYE.COM
Challenge the way we run

Analytic Aids
 
72 
5. the Laplace transformation
Example 5.12 Let X1, X2, X3, . . . be mutually independent random variables, all of the distribution
given by
P {Xi = k} = ak
k! eâˆ’a,
k âˆˆN0;
i âˆˆN
(here a is a positive constant).
Let N be another random variable, which is independent of all the Xi and which has its distribution
given by
P{N = n} = p qnâˆ’1,
n âˆˆN,
where p > 0, q > 0, p + q = 1.
1. Find the Laplace transform L(Î») of the random variable X1.
2. Find the Laplace transform of the random variable n
i=1 Xi, n âˆˆN.
3. Find the generating function P(s) of the random variable N.
We introduce another random variable Y by
(9) Y = X1 + X2 + Â· Â· Â· + XN,
where N denotes the random variable introduced above, and where the number of random variables on
the right hand side of (9) is also a random variable.
4. Prove that the random variable Y has its Laplace transform LY (Î») given by the composite function
LY (Î») = P(L(Î»)),
and ï¬nd explicitly LY (Î»).
Hint: One may use that we have for k âˆˆN0,
P{Y = k} =
âˆ

n=1
P{N = n} Â· P {X1 + X2 + Â· Â· Â· + Xn = k} .
5. Compute the mean E{Y }.
1) The Laplace transform of X1 âˆˆP(a) is given by
L(Î») =
âˆ

k=0
ak
k! eâˆ’a Â· eâˆ’kÎ» = eâˆ’a
âˆ

k=0
1
k!

a eâˆ’Î»k = exp

a eâˆ’Î»
exp(a)
= exp

a

eâˆ’Î» âˆ’1

.
2) The Laplace transform of n
i=1 Xi is given by
{L(Î»)}n = exp

na

eâˆ’Î» âˆ’1

.
Download free eBooks at bookboon.com

Analytic Aids
 
73 
5. the Laplace transformation
3) The generating function for N âˆˆPas(1, p) is found by means of a table,
P(s) =
ps
1 âˆ’qs.
Alternatively,
P(s) = p
âˆ

n=1
qnâˆ’1sn = ps
âˆ

n=1
(qs)nâˆ’1 =
ps
1 âˆ’qs.
4) It follows from
P{Y = k} =
âˆ

n=1
P{N = n} Â· P {X1 + X2 + Â· Â· Â· + Xn = k} ,
that
LY (Î»)
=
âˆ

k=0
âˆ

n=1
P{N = n} Â· P {X1 + X2 + Â· Â· Â· + Xn = k} Â· eâˆ’kÎ»
=
âˆ

n=1
P{N = n}
âˆ

k=0
P {X1 + X2 + Â· Â· Â· + Xn = k} eâˆ’Î»k
=
âˆ

n=1
P{N = n} Â· (L(Î»))n = P(L(Î»)) =
p Â· exp

a

eâˆ’Î» âˆ’1

1 âˆ’q Â· exp (a (eâˆ’Î» âˆ’1))
=
p
q Â· q Â· exp

a

eâˆ’Î» âˆ’1

âˆ’1 + 1
1 âˆ’q Â· exp (a (eâˆ’Î» âˆ’1))
= p
q Â·
1
1 âˆ’q Â· exp (a (eâˆ’Î» âˆ’1)) âˆ’p
q .
5) Since
Lâ€²
Y (Î») = âˆ’p
q Â·
1
{1 âˆ’q exp (a (eâˆ’Î» âˆ’1))}2 Â· q exp

a

eâˆ’Î» âˆ’1

Â· a eâˆ’Î»,
the mean is
E{X} = âˆ’Lâ€²
Y (0) =
pa
(1 âˆ’q)2 = pa
p2 = a
p.
Download free eBooks at bookboon.com

Analytic Aids
 
74 
5. the Laplace transformation
Example 5.13 Let X1, X2, X3, . . . be mutually independent random variables, all with the frequency
f(x) =
â§
â¨
â©
4x eâˆ’2x,
x > 0,
0,
x â‰¤0.
Let N be another random variable, which is independent of all the Xi, and which has its distribution
given by
P{N = n} = 3
4 Â·
1
4
nâˆ’1
,
n âˆˆN.
1. Find the Laplace transform L(Î») of the random variable X1.
2. Find the Laplace transform of the random variable n
i=1 Xi, n âˆˆN.
3. Find the generating function of the random variable N.
Then introduce a random variable Y by
(10) Y = X1 + X2 + Â· Â· Â· + XN,
where N denotes the random variable introduced above, and where the number of random variables on
the right hand side in (10) also is a random variable.
4. Find the Laplace transform of Y and the mean E{X}.
5. Prove that the frequency of Y is given by
g(y) =
â§
â¨
â©
k

eâˆ’y âˆ’eâˆ’3y
,
y > 0,
0,
y â‰¤0,
and ï¬nd k.
1) Since X âˆˆÎ“

2, 1
2

, get by using a table that
L(Î») =
â§
âª
â¨
âª
â©
1
1
2 Î» + 1
â«
âª
â¬
âª
â­
2
=

2
Î» + 2
2
.
Alternatively,
L(Î») =
 âˆ
0
4x eâˆ’2xeâˆ’Î»x dx = 4
 âˆ
0
x eâˆ’(Î»+2)x dx =
4
(Î» + 2)2 .
2) Since the Xi are mutually independent and identically distributed, the Laplace transform of
n
i=1 Xi, n âˆˆN, is given by
(L(Î»))n =

2
Î» + 2
2n
.
Download free eBooks at bookboon.com

Analytic Aids
 
75 
5. the Laplace transformation
3) Since N âˆˆPas

1, 3
4

, we get from a table that the generating function is
P(s) =
3
4 s
1 âˆ’1
4 s =
3s
4 âˆ’s.
Alternatively,
P(s) = 3
4
âˆ

n=1
1
4
nâˆ’1
sn = 3s
4
âˆ

n=1
s
4
nâˆ’1
=
3s
4
1 âˆ’s
4
=
3s
4 âˆ’s.
4) The Laplace transform of Y is given by (cf. e.g. the previous examples)
LY (Î»)
=
P(L(Î»)) =
3

2
Î» + 2
2
4 âˆ’

2
Î» + 2
2 =
12
4(Î» + 2)2 âˆ’4
=
3
(Î» + 1)(Î» + 3) = 3
2
1
Î» + 1 âˆ’3
2
1
Î» + 3.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
PDF components for PHP developers
www.setasign.com
SETASIGN
This e-book  
is made with 
SetaPDF

Analytic Aids
 
76 
5. the Laplace transformation
Now,
Lâ€²
Y (Î») = âˆ’3
2 Â·
1
(Î» + 1)2 + 3
2 Â·
1
(Î» + 3)2 ,
so the mean is
E{X} = âˆ’Lâ€²
Y (0) = 3
2 âˆ’3
2 Â· 1
9 = 3
2 âˆ’1
6 = 4
3.
5) Since g(y) is the frequency of some random variable ËœY , where
L ËœY (Î»)
=
k
 âˆ
0

eâˆ’y âˆ’eâˆ’3y
eâˆ’2y dy = k
 âˆ
0
eâˆ’(Î»+1)y dy âˆ’k
 âˆ
0
eâˆ’(Î»+3)y dy
=
k

1
Î» + 1 âˆ’
1
Î» + 3
	
has the same structure as LY (Î»), we conclude from the uniqueness that Y = ËœY and that k = 3
2,
and the frequency of Y is g(y) with k = 3
2.
Test:
 âˆ
âˆ’âˆ
g(y) dy = k
 âˆ
0

eâˆ’y âˆ’eâˆ’3y
dy = k

1 âˆ’1
3
	
= 2
3 k = 1
for k = 3
2. â™¦
Download free eBooks at bookboon.com

Analytic Aids
 
77 
5. the Laplace transformation
Example 5.14 Let X be a normally distributed random variable of mean 0 and variance 1.
1. Find the frequency and mean of X2.
2. Find the Laplace transform of X2.
Now let X1, X2, . . . be mutually independent random variables, Xi âˆˆN(0, 1), and let a1, a2, . . . be
given constants, and deï¬ne
Yn =
n

k=1
akX2
k,
n âˆˆN.
3. Find the Laplace transform of Yn.
4. Prove that the sequence {Yn}âˆ
n=1 converges in distribution towards a random variable Y , if and
only if
lim
nâ†’âˆE {Yn} < âˆ.
By the assumption the frequency of X is given by
Ï•(x) =
1
âˆš
2Ï€ exp

âˆ’1
2 x2

,
x âˆˆR.
1) The distribution function of Y = X2 is 0 for y â‰¤0.
If y > 0, then
P

X2 â‰¤y

= P {âˆ’âˆšy â‰¤X â‰¤âˆšy} = Î¦ (âˆšy) âˆ’Î¦ (âˆ’âˆšy) = 2 Î¦ (âˆšy) âˆ’1.
When y > 0, the corresponding frequency is found by diï¬€erentiation,
f(y) = 2 Î¦â€² (âˆšy) Â·
1
2âˆšy =
1
âˆšy Ï• (âˆšy) =
1
âˆš2Ï€y exp

âˆ’1
2 y

.
The mean is
E

X2
=
1
âˆš
2Ï€
 âˆ
âˆ’âˆ
x2 exp

âˆ’1
2 x2

dx =
1
âˆš
2Ï€
 âˆ
x=âˆ’âˆ
x d

âˆ’exp

âˆ’1
2 x2

=
1
âˆš
2Ï€

âˆ’x exp

âˆ’1
2 x2
âˆ
âˆ’âˆ
+
1
âˆš
2Ï€
 âˆ
âˆ’âˆ
exp

âˆ’1
2 x2

dx = 0 + 1 = 1.
2) Since X2 â‰¥0, we can ï¬nd its Laplace transform. If Î» â‰¥0, then
LX2(Î»)
=
 âˆ
0
1
âˆš2Ï€y exp

âˆ’1
2 y

exp(âˆ’Î»y) dy =
2
âˆš
2Ï€
 âˆ
0
exp

âˆ’1
2

Î» + 1
2

y

d (âˆšy)
=
2
âˆš
2Ï€
 âˆ
0
exp

âˆ’1
2 Â·
t2
1
2Î»+1

dt =
1
âˆš
2Î» + 1
.
2Î» + 1
2Ï€
 âˆ
âˆ’âˆ
exp

âˆ’1
2 (2Î» + 1)t2

dt
=
1
âˆš
2Î» + 1.
Download free eBooks at bookboon.com

Analytic Aids
 
78 
5. the Laplace transformation
3) We get the Laplace transform of a X2 = a Y1 from LX(Î») by replacing Î» by aÎ», i.e.
LaX2(Î») = LX2(a Î») =
1
âˆš
2Î»a + 1.
Now, the Xk are mutually randomly independent, so
LYn(Î») =
n

k=1
LakX2
k(Î») =
n

k=1
LX2 (akÎ») =
1
 /n
k=1 (1 + 2Î»ak)
.
4) We get by using the result of 1.,
E {Yn} =
n

k=1
akE

X2
k

=
âˆ

k=1
ak,
thus
lim
nâ†’âˆE {Yn} =
âˆ

k=1
ak.
Then we get for Î» â‰¥0,
ln
n

k=1
(1 + 2Î»ak) =
n

k=1
ln (1 + 2Î» ak) =
n

k=1
(2Î»ak + Î»akÎµ (Î»ak)) ,
where we by considering a graph can get more precisely that
0 â‰¤
n

k=1
ln (1 + 2Î»ak) â‰¤
n

k=1
2Î» ak,
and
âˆ

k=1
ln (1 + 2Î» ak) âˆ¼
âˆ

k=1
2Î» ak.
It follows from the equivalence of the two series that
1 â‰¤
âˆ

k=1
(1 + 2Î» ak) < âˆ,
if and only if
âˆ

k=1
ak < âˆ.
If therefore
lim
nâ†’âˆE {Yn} < âˆ,
then in particular limnâ†’âˆ

âˆ’Lâ€²
Yn(Î»)

is convergent and continuous for Î» â‰¥0, hence by rewriting
the expression, followed by a reduction, âˆ
k=1 ak < âˆ, which according to the above implies that
lim
nâ†’âˆLYn(Î») =
1
 /âˆ
k=1 (1 + 2Î» ak)
is continuous for Î» â‰¥0. Then (Yn) converges in distribution towards a random variable Y .
Download free eBooks at bookboon.com

Analytic Aids
 
79 
5. the Laplace transformation
Conversely, if limnâ†’âˆE {Yn} = âˆ, then we get by the same argument that âˆ
k=1 ak = âˆimplies
that /âˆ
k=1 (1 + 2Î» ak) = âˆfor Î» > 0, and of course 1 for Î» = 0, hence
lim
nâ†’âˆLYn(Î») =
â§
â¨
â©
1
for Î» = 0,
0
for Î» > 0,
corresponding to the zero function, which is not the Laplace transform of any random variable.
This shows that (Xn) does not converge in distribution.
Example 5.15 We say that a function Ï• : ]0, âˆ[ â†’R is completely monotone, if Ï• is a Câˆfunction,
and
(âˆ’1)nÏ•(n)(Î») â‰¥0 for every n âˆˆN0 and every Î» > 0.
Prove that if X is a non-negative random variable, then the Laplace transform L(Î») of X is completely
monotone.
Remark 5.1 Conversely, it can be proved that if Ï• : ]0, âˆ[ â†’R is completely monotone, and
Î»Î»â†’0+Ï•(Î») = 1,
then Ï•(Î») is the Laplace transform of some random variable X.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
www.sylvania.com
We do not reinvent  
the wheel we reinvent 
light.
Fascinating lighting offers an infinite spectrum of 
possibilities: Innovative technologies and new  
markets provide both opportunities and challenges. 
An environment in which your expertise is in high 
demand. Enjoy the supportive working atmosphere 
within our global group and benefit from international 
career paths. Implement sustainable ideas in close 
cooperation with other specialists and contribute to 
influencing our future. Come and join us in reinventing 
light every day.
Light is OSRAM

Analytic Aids
 
80 
5. the Laplace transformation
When X is non-negative, its Laplace transform exists, and
1)
L(Î») = 
i pieâˆ’Î»xi,
(discrete),
2)
L(Î») =
 âˆ
0
eâˆ’Î»x f(x) dx,
(continuous),
3)
L(Î») = E

eâˆ’Î»x
,
(in general).
Due to the exponential function and the law of magnitudes we may for Î» > 0 diï¬€erentiate 1) under
the sum, 2) under the integral, and 3) under the symbol E, with respect to Î». Hence we get in general
[i.e. in case 3)] for Î» > 0 and n âˆˆN0,
(âˆ’1)nL(n)(Î») = Î»nE

Xneâˆ’Î»X
.
Since Xneâˆ’Î»X â‰¥0, the right hand side is always â‰¥0, and the claim is proved.
Clearly,
L(0) = lim
Î»â†’0+ L(Î») = lim
Î»â†’0+ E

eâˆ’Î»X
= E{1} = 1,
and
0 < L(Î») = E

eâˆ’Î»X
â‰¤E{1} = 1,
because 0 â‰¤eâˆ’Î»X â‰¤1, nËšar X â‰¥0.
A loose argument shows that the last claim follows from the fact, that if (âˆ’1)nÏ•(n)(Î») â‰¥0 for all
n âˆˆN, then we get in e.g. the continuous case that
 âˆ
0
eâˆ’Î»xxnf(x) dx â‰¥0 for all Î» > 0 and all n âˆˆN0,
thus
xnf(x) â‰¥0 for all n âˆˆN0 and x â‰¥0,
and hence f(x) â‰¥0. Finally,
 âˆ
0
f(x) dx = lim
Î»â†’0+ Ï•(Î») = 1.
Download free eBooks at bookboon.com

Analytic Aids
 
81 
5. the Laplace transformation
Example 5.16 A random variable X has the values 2, 3, 4, . . . of the probabilities
P{X = k} = (k âˆ’1)p2(1 âˆ’p)kâˆ’2,
where 0 < p < 1, thus X âˆˆPas(2, p).
1. Find the generating function and the Laplace transform of X.
2. Find the mean of X.
Given a sequence of random variable (Xn)âˆ
n=1, where Xn has the values 2
n, 3
n, 4
n, . . . of the probabil-
ities
P

Xn = k
n
	
= (k âˆ’1)
 1
3n
2 
1 âˆ’1
3n
kâˆ’2
.
3. Find the Laplace transform of Xn.
4. Prove that the sequence (Xn) converges in distribution towards a random variable Y , which is
Gamma distributed, and ï¬nd its frequency of Y .
1) The generating function of X is given by
P(s)
=
âˆ

k=2
P{X = k}sk =
âˆ

k=2
(k âˆ’1)p2(1 âˆ’p)kâˆ’2sk
=
p2s2
âˆ

k=2
(k âˆ’1){(1 âˆ’p)s}kâˆ’2 = p2s2
âˆ

â„“=1
â„“{(1 âˆ’p)s}â„“âˆ’1
=
p2s2 Â·
1
{1 âˆ’(1 âˆ’p)s}2 =

ps
1 âˆ’(1 âˆ’p)s
	2
for s âˆˆ[0, 1].
Then by a simple substitution,
L(Î») = P

eâˆ’Î»
=

p eâˆ’Î»
1 âˆ’(1 âˆ’p)eâˆ’Î»
	2
=

p
eÎ» âˆ’(1 âˆ’p)
	2
.
2) Here there are several possibilities, of which we indicate four:
First variant. It follows from
P â€²(s) = 2 Â·
ps
1 âˆ’(1 âˆ’p)s Â· {1 âˆ’(1 âˆ’p)s}p + p(1 âˆ’p)s
{1 âˆ’(1 âˆ’p)s}2
,
that
E{X} = P â€²(1) = 2 Â· 1 Â· p
p2 = 2
p.
Download free eBooks at bookboon.com

Analytic Aids
 
82 
5. the Laplace transformation
Second variant. It follows from
Lâ€²(Î») = p2(âˆ’1)

eÎ» âˆ’(1 âˆ’p)
âˆ’3 Â· eÎ»,
that
E{X} = âˆ’Lâ€²(0) = 2p2
p3 = 2
p.
Third variant. By a straightforward computation,
E{X}
=
âˆ

k=2
k P{X = k} =
âˆ

k=2
k(k âˆ’1)p2(1 âˆ’p)kâˆ’2
=
p2
âˆ

k=2
k(k âˆ’1)(1 âˆ’p)kâˆ’2 = p2 Â·
2
{1 âˆ’(1 âˆ’p)}3 = 2
p.
Fourth variant. (The easiest one!) Since X âˆˆPas(2, p), er have of course E{X} = 2
p.
3) If we put p = 1
3n, then nXn has the same distribution as X. Now, Xn is obtained by diminishing
the values by a factor 1
n, so Xn has the Laplace transform
LXn(Î») =

1
3n
eÎ»/n âˆ’

1 âˆ’
1
3n

2
=
1

3n

exp
Î»
n

âˆ’1

+ 1
	2 .
4) It follows from
exp
Î»
n

= 1 + Î»
n + Î»
n Îµ
Î»
n

,
that
LXn(Î») =
1

3n
Î»
n + Î»
n Îµ
Î»
n

+ 1
	2 =
1

3Î» + 3Î» Îµ
Î»
n

+ 1
	2 â†’
1
(3Î» + 1)2
for Î» â‰¥0.
Clearly, the limit function is continuous, so it follows that the sequence (Xn) converges in distri-
bution towards Y , where Y has the Laplace transform
LY (Î») =
1
(3Î» + 1)2 ,
Î» â‰¥0.
If Y âˆˆÎ“(Î¼, Î±), then its Laplace transform is
1
(Î±Î» + 1)Î¼ .
Then by comparison Î± = 3 and Î¼ = 2, so Y âˆˆÎ“(2, 3), and Y has the frequency
f(y) =
â§
âª
â¨
âª
â©
1
9 y exp

âˆ’y
3

,
y > 0,
0,
y â‰¤0.
Download free eBooks at bookboon.com

Analytic Aids
 
83 
5. the Laplace transformation
Example 5.17 A random variable X has the values 0, 2, 4, . . . of the probabilities
P{X = 2k} = p(1 âˆ’p)k,
k âˆˆN0,
where p is a constant, 0 < p < 1.
1. Find the Laplace transform LX(Î») of the random variable X.
2. Find the mean of the random variable X.
A sequence of random variables (Xn)âˆ
n=1 is determined by that Xn has the values 0, 2
n, 4
n, . . . of the
probabilities
P

Xn = 2k
n
	
= 1
4n

1 âˆ’1
4n
k
,
k âˆˆN0.
3. Find the Laplace transform LXn(Î») of the random variable Xn.
4. Find the mean of the random variable Xn.
5. Prove that the sequence (Xn) converges in distribution towards a random variable Y , and ï¬nd the
distribution function of Y .
1) The Laplace transform is
LX(Î»)
=
âˆ

k=0
P{X = 2k} eâˆ’2Î»k =
âˆ

k=0
p(1 âˆ’p)keâˆ’2Î»k
=
p
âˆ

k=0

(1 âˆ’p)eâˆ’2Î»k =
p
1 âˆ’(1 âˆ’p)eâˆ’2Î» ,
Î» â‰¥0.
2) The mean can be found in two ways:
a) By the usual deï¬nition,
E{X} =
âˆ

k=1
2kp(1 âˆ’p)k = 2p(1 âˆ’p)
âˆ

k=1
k(1 âˆ’p)kâˆ’1 = 2p(1 âˆ’p) 1
p2 = 2 1 âˆ’p
p
.
b) By means of the Laplace transform,
E{X} = âˆ’Lâ€²
X(0) =
,
p
{1 âˆ’(1 âˆ’p)eâˆ’2Î»}2 Â· 2(1 âˆ’p)eâˆ’2Î»
-
Î»=0
= 2p(1 âˆ’p)
p2
= 2 1 âˆ’p
p
.
3) The Laplace transform of Xn is obtained from the Laplace transform of X by replacing Î» by Î»
n,
and p by 1
4n,
LXn(Î»)=
1
4n
1âˆ’

1âˆ’1
4n

exp

âˆ’2 Î»
n
 =
1
4n

1âˆ’exp

âˆ’2Î»
n

+exp

âˆ’2 Î»
n
.
Download free eBooks at bookboon.com

Analytic Aids
 
84 
5. the Laplace transformation
4) Since
âˆ’Lâ€²
Xn(Î») =
8 exp

âˆ’2Î»
n

âˆ’2
n exp

âˆ’2Î»
n


4n

1 âˆ’exp

âˆ’2 Î»
n

+ exp

âˆ’2 Î»
n
	2 ,
we get the mean
E{X} = âˆ’Lâ€²
Xn(0) =
1
{0 + 1}2 Â·

8 âˆ’2
n
	
= 8

1 âˆ’1
4n

.
5) Then by a Taylor expansion, et = 10t + t Îµ(t), so it follows from 3. that
LXn(Î»)
=
1
4n

1 âˆ’1 + 2Î»
n + 2Î»
n Îµ
2Î»
n
	
+ exp

âˆ’2 Î»
n
 =
1
8Î» + 8Î» Îµ
2Î»
n

+ exp

âˆ’2 Î»
n

â†’
1
8Î» + 1
for n â†’âˆ.
Since
1
8Î» + 1 is continuous, this shows that (Xn) converges in distribution towards a random
variable Y , where the Laplace transform of Y is LY (Î») =
1
8Î» + 1, hence
Y âˆˆÎ“(1, 8).
Thus the frequency of Y is
fY (y) =
â§
âª
â¨
âª
â©
1
8 exp

âˆ’y
8

,
y > 0,
0,
y â‰¤0,
so we have obtained an exponential distribution.
Download free eBooks at bookboon.com

Analytic Aids
 
85 
6. The characteristic function
6
The characteristic function
Example 6.1 Find the characteristic function for a random variable, which is Poisson distributed of
mean a.
It follows from
P{X = k} = ak
k! eâˆ’a,
k âˆˆN0,
that the characteristic function for X is given by
k(Ï‰) =
âˆ

k=0
eiÏ‰k ak
k! eâˆ’a = eâˆ’a
âˆ

k=0
1
k!

a eiÏ‰k = eâˆ’a exp

a eiÏ‰
= exp

a

eiÏ‰ âˆ’1

.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
360Â°
thinking.
Â© Deloitte & Touche LLP and affiliated entities.
Discover the truth at www.deloitte.ca/careers 

Analytic Aids
 
86 
6. The characteristic function
Example 6.2 Let X have the frequency
f(x) =
â§
â¨
â©
1 âˆ’|x|,
|x| < 1,
0,
|x| â‰¥1.
Find the characteristic function for X.
Let X1 and X2 be independent random variables, which are rectangularly distributed over

âˆ’1
2, 1
2

.
Prove that X has the same distribution as X1 + X2,
1) by a straightforward computation of the frequency of X1 + X2,
2) by using characteristic functions.
The characteristic function for Ï‰ Ì¸= 0 is
k(Ï‰)
=
 âˆ
âˆ’âˆ
eiÏ‰tf(t) dt =
 1
âˆ’1
{cos Ï‰x + i sin Ï‰x}(1 âˆ’|x|) dx = 2
 1
0
cos Ï‰x Â· (1 âˆ’|x|) dx
=
2
 1
Ï‰ (1 âˆ’x) sin Ï‰x
1
0
+ 2
Ï‰
 1
0
sin Ï‰x dx = 2
Ï‰
*
âˆ’cos Ï‰x
Ï‰
+1
0 = 2
Ï‰2 (1 âˆ’cos Ï‰).
If Ï‰ = 0, then k(0) = 1.
1) The frequency for both X1 and X2 is given by
f(t) =
â§
âª
âª
â¨
âª
âª
â©
1
for t âˆˆ

âˆ’1
2, 1
2

,
0
otherwise,
hence the frequency of X1 + X2 is given by
g(s) =
 âˆ
âˆ’âˆ
f(t)f(s âˆ’t) dt =

1
2
âˆ’1
2
f(s âˆ’t) dt.
If s /âˆˆ] âˆ’1, 0[, then g(s) = 0.
If s âˆˆ] âˆ’1, 0], then
g(s) =

1
2
âˆ’1
2
f(s âˆ’t) dt =
 s+ 1
2
âˆ’1
2
1 dt = s + 1 = 1 âˆ’|s|.
If s âˆˆ]0, 1[, then
g(s) =

1
2
âˆ’1
2
f(s âˆ’t) dt =

1
2
sâˆ’1
2
1 dt = 1 âˆ’s = 1 âˆ’|s|,
and the claim follows.
Download free eBooks at bookboon.com

Analytic Aids
 
87 
6. The characteristic function
2) If Ï‰ Ì¸= 0, then we get the characteristic function for Xi,
h(Ï‰)
=

1
2
âˆ’1
2
eiÏ‰t dt = 1
iÏ‰

exp

i Ï‰
2

âˆ’exp

âˆ’i Ï‰
2

=
2
Ï‰ Â· 1
2i

exp

i Ï‰
2

âˆ’exp

âˆ’i Ï‰
2

= 2
Ï‰ sin Ï‰
2 .
Hence, the characteristic function for X1 + X2 is
{h(Ï‰)}2 = 4
Ï‰2 sin2 Ï‰
2 = 4
Ï‰2 Â· 1 âˆ’cos Ï‰
2
= 2
Ï‰2 (1 âˆ’cos Ï‰) = k(Ï‰).
Since X and X1 + X2 have the same characteristic function, they are identical.
Example 6.3 Let X have the frequency
f(x) =
a
Ï€ (a2 + x2),
x âˆˆR,
where a is a positive constant.
Prove by applying the inversion formula that X has the characteristic function
k(Ï‰) = eâˆ’a|Ï‰|.
Then prove that if X1, X2, . . . , Xn are mutually independent all of the frequency f(x), then
Zn = 1
n (X1 + Â· Â· Â· + Xn)
also has the frequency f(x).
When we apply the inversion formula on k(Ï‰), we get
1
2Ï€
 âˆ
âˆ’âˆ
eâˆ’iÏ‰xeâˆ’a|Ï‰| dÏ‰ = 1
2Ï€
 0
âˆ’âˆ
e(aâˆ’ix)Ï‰ dÏ‰ + 1
2Ï€
 0
âˆ’âˆ
eâˆ’(a+ix)Ï‰ dÏ‰
= 1
2Ï€
e(aâˆ’ix)Ï‰
a âˆ’ix
0
âˆ’Ï‰
+ 1
2Ï€
eâˆ’(a+ix)Ï‰
a âˆ’ix
âˆ
0
= 1
2Ï€

1
a âˆ’ix +
1
a + ix

= 1
2Ï€ Â· a + ix + a âˆ’ix
a2 + x2
=
a
Ï€ (a2 + x2),
and the claim follows from the uniqueness of the characteristic function.
The characteristic function for
Yn = 1
n (X1 + Â· Â· Â· + Xn)
is
kYn(Ï‰) =
n

i=1
ki
Ï‰
n

=
n

i=1
exp

âˆ’a
000Ï‰
n
000

= eâˆ’a|Ï‰| = kX(Ï‰),
showing that Yn has the same frequency as X.
Download free eBooks at bookboon.com

Analytic Aids
 
88 
6. The characteristic function
Example 6.4 Let X1, X2, . . . be mutually independent, identically distributed random variables all
of mean Î¼. Let
Zn = 1
n (X1 + Â· Â· Â· + Xn) ,
n âˆˆN.
Prove that the sequence (Zn) converges in distribution towards Î¼.
Given Î¼ = E{X} exists, we must have the following
(11)
 âˆ
âˆ’âˆ
|x| f(x) dx < âˆ,
which shall be used later.
Let k(Ï‰) denote the characteristic function for Xi. Then the characteristic function for Zn is given by
kn(Ï‰) =

k
Ï‰
n
n
.
It follows from (11) that
k(Ï‰) =
 âˆ
âˆ’âˆ
eiÏ‰x d(x) dx
and
kâ€²(Ï‰) = i
 âˆ
âˆ’âˆ
eiÏ‰x x f(x) dx
are both deï¬ned and bounded.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
We will turn your CV into 
an opportunity of a lifetime
Do you like cars? Would you like to be a part of a successful brand?
We will appreciate and reward both your enthusiasm and talent.
Send us your CV. You will be surprised where it can take you.
Send us your CV on
www.employerforlife.com

Analytic Aids
 
89 
6. The characteristic function
It follows from
k(Ï‰) = k(0) + 1
1! kâ€²(0) Ï‰ + Ï‰ Îµ(Ï‰) = 1 + i Î¼ Â· Ï‰ + Ï‰ Îµ(Ï‰),
that
kn(Ï‰) =

k
Ï‰
n
n
=

1 + i Î¼ Ï‰
n
+ Ï‰
n Îµ
Ï‰
n
	n
=

1 + 1
n

i Î¼ Ï‰ + Ï‰ Îµ
Ï‰
n
n
.
Hence, by taking the limit,
lim
nâ†’âˆkn(Ï‰) = ei Î¼ Ï‰,
which is the characteristic function for the causal distribution Î¼.
In particular, ei Î¼ Ï‰ is continuous at Ï‰ = 0. Hence it follows that the sequence (Zn) converges in
distribution towards Î¼.
Example 6.5 Let X have the mean 0 and variance Ïƒ2.
Prove that
k(Ï‰) = 1 âˆ’1
2 Ïƒ2Ï‰2 + Ï‰2Îµ(Ï‰)
for Ï‰ â†’0.
Then prove the following special case of the Central Limit Theorem:
Let X1, 2, . . . be mutually independent, identically distributed random variables of mean 0 and variance
Ïƒ2. Deï¬ne
Zn = 1
2Ïƒ âˆšn (X1 + Â· Â· Â· + Xn) ,
n âˆˆN.
Then for every z âˆˆR,
P {Zn â‰¤z} â†’Î¦(z)
for n â†’âˆ.
We see that
k(Ï‰)
=
 âˆ
âˆ’âˆeiÏ‰xf(x) dx,
k(â€²Ï‰)
=
 âˆ
âˆ’âˆeiÏ‰xi x f(x) dx,
kâ€²â€²(Ï‰)
=
âˆ’
 âˆ
âˆ’âˆx2eiÏ‰xf(x) dx,
are all absolutely convergent, and
k(0) = 1,
kâ€²(0) = i
 âˆ
âˆ’âˆ
x f(x) dx = i Î¼ = 0,
kâ€²â€²(0) = âˆ’
 âˆ
âˆ’âˆ
x2f(x) dx = âˆ’
 âˆ
âˆ’âˆ
(x âˆ’Î¼)2f(x) dx = Ïƒ2,
hence by a Taylor expansion,
k(Ï‰)
=
k(0) + 1
1! kâ€²(0) Ï‰ + 1
2! kâ€²â€²(0) Ï‰2 + Ï‰2Îµ(Ï‰)
=
1 âˆ’Ïƒ2Ï‰2
2
+ Ï‰2Îµ(Ï‰).
Download free eBooks at bookboon.com

Analytic Aids
 
90 
6. The characteristic function
The characteristic function kn(Ï‰) for Zn is given by
kn(Ï‰)
=
E

eiÏ‰Zn
= E

exp

i Ï‰
n

k=1
1
Ïƒâˆšn Xn

=
n

k=1
E

exp
 i Ï‰
Ïƒâˆšn Xk
	
=

E

exp
 i Ï‰
Ïƒâˆšn X
	n
,
where
E

exp
 i Ï‰
Ïƒâˆšn X
	
=
 âˆ
âˆ’âˆ
exp

i Ï‰
x
Ïƒâˆšn

f(x) dx = k

Ï‰
Ïƒâˆšn

= 1 âˆ’Ïƒ2
2
Ï‰2
Ïƒ2n + Ï‰2
Ïƒ2n Îµ

Ï‰
Ïƒâˆšn

=
1 âˆ’1
n Â· Ï‰2
2 + Ï‰2
Ïƒ2n Îµ

Ï‰
Ïƒâˆšn

.
Hence by insertion,
kn(Ï‰)
=

1 âˆ’Ïƒ2
2
Ï‰2
Ïƒ2n + Ï‰2
Ïƒ2n Îµ

Ï‰
Ïƒâˆšn

= 1 âˆ’1
n Â· Ï‰2
2 + Ï‰2
Ïƒ2n Îµ

Ï‰
Ïƒâˆšn
	n
â†’
exp

âˆ’Ï‰2
2

for n â†’âˆ.
Now, exp

âˆ’Ï‰2
2

is the characteristic function for Î¦(x), so we conclude that (Zn) converges in
distribution towards the normal distribution,
lim
nâ†’âˆP {Zn â‰¤x} = Î¦(x).
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
AXA Global 
Graduate Program
Find out more and apply

Analytic Aids
 
91 
6. The characteristic function
Example 6.6 1) A random variable X has the frequency
f(x) =
1
Ï€ (1 + x2),
x âˆˆR.
Prove by e.g. applying the inversion formula that X has the characteristic function
k(Ï‰) = eâˆ’|Ï‰|.
2) A random variable Y has the frequency
g(y) =
a
Ï€ (a2 + (y âˆ’b)2),
y âˆˆR,
where a > 0 and b âˆˆR. Find the characteristic function for Y .
3) Let (Yj) be a sequence of mutually independent random variables, where each random variable Yj
has the frequency
gj(y) =
aj
Ï€

a2
j + (y âˆ’bj)2,
y âˆˆR,
where aj > 0 and bj âˆˆR, and let Zn denote the random variable
Zn =
n

j=1
Yj.
Find the characteristic function for Zn.
4) Find a necessary and suï¬ƒcient condition, which the constants aj and bj must fulï¬l in order that
the sequence (Zn)âˆ
n=1 converges in distribution. In case of convergence, ï¬nd the limit distribution.
1) It follows by the inversion formula that
1
2Ï€
 âˆ
âˆ’âˆ
eâˆ’i Ï‰ xeâˆ’|Ï‰| dÏ‰ = 1
2Ï€
 0
âˆ’Ï‰
e(1âˆ’ix)Ï‰ dÏ‰ + 1
2Ï€
 âˆ
0
eâˆ’(1+ix)Ï‰ dÏ‰
= 1
2Ï€
e(1âˆ’ix)Ï‰
1 âˆ’ix
0
âˆ’Ï‰
+ 1
2Ï€
 eâˆ’(1+ix)Ï‰
âˆ’(1 + ix)
âˆ
0
= 1
2Ï€

1
1 âˆ’ix +
1
1 + ix
	
= 1
2Ï€ Â· 1 + ix + 1 âˆ’ix
1 + x2
1
Ï€ Â·
1
1 + x2 = f(x).
This shows that k(Ï‰) = eâˆ’|Ï‰| is the characteristic function for
f(x) = 1
Ï€ Â·
1
1 + x2 .
2) The characteristic function for Y is
kY (Ï‰)
=
 âˆ
âˆ’âˆ
eiÏ‰y Â· 1
Ï€ Â·
a
a2 + (y âˆ’b)2 dy = eiÏ‰b
 âˆ
âˆ’âˆ
eiÏ‰y Â· 1
Ï€ Â·
a
a2 + y2 dy
=
eiÏ‰b
 âˆ
âˆ’âˆ
ei a Ï‰Â· 1
a y Â· 1
Ï€ Â·
1
1 +
y
a
2 d
y
a

= eiÏ‰ bk(aÏ‰) = eiÏ‰ beâˆ’a|Ï‰|.
Download free eBooks at bookboon.com

Analytic Aids
 
92 
6. The characteristic function
3) It follows from 2. that
kZn(Ï‰) =
n

j=1
kYj(Ï‰) =
n

j=1
ei Ï‰ bj Â· eâˆ’aj|Ï‰| = exp
â›
âi Ï‰
n

j=1
bj
â
â Â· exp
â›
ââˆ’|Ï‰|
n

j=1
aj
â
â .
4) The sequence (Zn) converges min distribution if and only if limnâ†’âˆkZn(Ï‰) is convergent for all
Ï‰ with a limit function h(Ï‰), d which is continuous at 0.
Clearly, the only possible candidate is
h(Ï‰) = exp

i Ï‰
âˆ

n=1
bn

Â· exp

âˆ’|Ï‰|
âˆ

n=1
an

.
It is in fact the limit function, if the right hand side is convergent for every Ï‰ âˆˆR. This is fulï¬lled,
if and only if
(12)
âˆ

n=1
an = a
and
âˆ

n=1
bn = b
are both convergent. When this is the case, then
h(Ï‰) = ei Ï‰ beâˆ’a|Ï‰| = kY (Ï‰)
by 2..
This shows that (Zn) converges in distribution towards a random variable Y , if and only if the
series of (12) are convergent, and when this is the case, the frequency of Y is
fY (y) = 1
Ï€ Â·
a
a2 + (y âˆ’b)2 ,
y âˆˆR.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
ibili
because 
e Graduate Programme  
for Engineers and Geoscientists
Month 16
I was a construction
supervisor in 
the North Sea 
advising and 
helping foremen 
solve problems
I was a
he
s
Real work 
International opportunities 

ree work placements
al 
Internationa
or

ree wo
I wanted real responsibili 
 I joined MITAS because 
www.discovermitas.com

Analytic Aids
 
93 
6. The characteristic function
Example 6.7 Let X1, X2, . . . be mutually independent random variables. where
P

Xj =
 
j

= P

Xj = âˆ’
 
j

= 1
2,
j âˆˆN,
and let
Zn = 1
n
n

j=1
Xj,
n âˆˆN.
Prove that the sequence (Zn)âˆ
n=1 converges in distribution, and ï¬nd the limit distribution
1) either by applying the Central Limit Theorem;
2) or by computing limnâ†’âˆkn(Ï‰), where kn(Ï‰) is the characteristic function for Zn.
Hint: Use that
cos x = 1 âˆ’x2
2 + x4
24 + x4 Îµ(x)
for x â†’0
and
âˆ’ln(1 âˆ’x) = x + x2
2 + x2 Îµ(x)
for x â†’0.
1) From E {Xj} = 0 follows that
E {Zn} = 1
n
n

j=1
E {Xj} = 0,
and
s2
n
=
V {Zn} = 1
n2
n

j=1
V {Xj} = 1
n2
n

j=1

E

X2
j

âˆ’(E {Xj})2
= 1
n2
n

j=1
E

X2
j

=
1
n2
n

j=1
 
j
2
Â· 1
2 +

âˆ’
 
j
2
Â· 1
2
	
= 1
n2
n

j=1
j = 1
n2 Â· 1
2 n(n + 1) = 1
2
n + 1
n
.
Now,
Zn âˆ’E {Zn}
sn
=
Zn
.
n + 1
n
=
.
2n
n + 1 Â· Zn,
so by the Central Limit Theorem,
lim
nâ†’âˆP

Zn â‰¤x
.
n + 1
2n

= Î¦(x)
for every x âˆˆR.
We get from
.
n + 1
2n
â†’
1
âˆš
2 for n â†’âˆthat
FZ(x) = lim
nâ†’âˆP {Zn â‰¤x} = Î¦
âˆš
2 Â· x

,
hence Z =
1
âˆš
2 Y , where Y âˆˆN(0, 1).
Download free eBooks at bookboon.com

Analytic Aids
 
94 
6. The characteristic function
2) It follows from
kZn(Ï‰)
=
n

j=1
E

exp

i Ï‰
n Xj

=
n

j=1
1
2 exp

i Ï‰
n
 
j

+ 1
2 exp

i Ï‰
n

âˆ’
 
j
	
=
n

j=1
cos
âˆšj
n Ï‰

,
by taking the logarithm and using the Taylor expansions given in the hint,
ln kZn(Ï‰) =
n

j=1
ln

cos
âˆšj
n Ï‰

=
n

j=1
ln

1 âˆ’1
2
âˆšj Â· Ï‰
n
2
+ 1
24
âˆšj Â· Ï‰
n
4
+
âˆšj Â· Ï‰
n
4
Îµ
âˆšj Â· Ï‰
n

=
n

j=1
ln

1 âˆ’Ï‰2
2 Â· j
n2 + Ï‰4
24 Â· j2
n4 + Ï‰4 Â· j2
n4 Îµ
âˆšj Â· Ï‰
n
	
= âˆ’
n

j=1
Ï‰2
2 Â· j
n2 âˆ’Ï‰4
24 Â· j2
n4 + Ï‰4j2
n4
Îµ
âˆšj Ï‰
n

+ 1
2
Ï‰2
2 Â· j2
n4 âˆ’Ï‰4
24 Â· j2
n4 + Ï‰4 j2
n4
Îµ
Ï‰âˆšj
n
2
+ Ï‰4j2
n4
Îµ
Ï‰âˆšj
n

= âˆ’
n

j=1
Ï‰2
2n2 Â· j +
Ï‰4
24n4
n

j=1
j2 + 1
n Îµ
 1
n

+ 1
2
Ï‰4
4n4
n

j=1
j2 + 1
n Îµ
 1
n

= âˆ’Ï‰2
2n2 Â· 1
2 n(n + 1) + 1
n Îµ
 1
n

= âˆ’Ï‰2
4 + 1
n Îµ
 1
n

â†’âˆ’1
2
 Ï‰
âˆš
2
2
for n â†’âˆ.
Hence,
kZn(Ï‰) â†’exp

âˆ’1
2
 Ï‰
âˆš
2
2
for n â†’âˆ.
If Y is normally distributed, then of course
kY (Ï‰) = exp

âˆ’1
2 Ï‰2

,
and thus
Z =
1
âˆš
2 Y âˆˆN

0, 1
âˆš
2

.
Download free eBooks at bookboon.com

Analytic Aids
 
95 
6. The characteristic function
Example 6.8 A random variable X has the frequency
f(x) =
â§
âª
âª
â¨
âª
âª
â©
1
Ï€ Â· 1 âˆ’cos x
x2
,
x Ì¸= 0,
1
2Ï€ ,
x = 0.
1. Prove by using the inversion formula that X has the characteristic function
k(Ï‰) =
â§
â¨
â©
1 âˆ’|Ï‰|,
|Ï‰| â‰¤1,
0,
|Ï‰| > 1.
2. Prove by e.g. using the result of 1. that X does not have a mean.
Let (Xn)âˆ
n=1 be a sequence of random variables, where each Xn has the frequency
fn(x) = n f(nx) =
â§
âª
âª
â¨
âª
âª
â©
1
Ï€
1 âˆ’cos nx
nx2
,
x Ì¸= 0,
n
2Ï€ ,
x = 0,
n âˆˆN.
3. Find the characteristic function kn(Ï‰) for Xn.
4. Show, e.g. by using the result of 3. that the sequence (Xn) converges in distribution towards a
random variable Y , and ï¬nd the distribution function of Y .
1) According to the inversion formula we shall only prove that
1
2Ï€
 âˆ
âˆ’âˆ
eâˆ’i x Ï‰k(Ï‰) dÏ‰ = f(x).
Now, 1 âˆ’|Ï‰|, |Ï‰| â‰¤1, is an even function, hence by insertion,
1
2Ï€
 âˆ
âˆ’âˆ
eâˆ’i x Ï‰k(Ï‰) dÏ‰ = 1
2Ï€
 1
âˆ’1
eâˆ’i x Ï‰(1 âˆ’|Ï‰|) dx = 1
Ï€
 1
0
(1 âˆ’Ï‰) cos Ï‰ x dÏ‰.
We ï¬nd for x = 0,
1
Ï€
 1
0
(1 âˆ’Ï‰) dÏ‰ = 1
Ï€

1 âˆ’1
2

= 1
2Ï€ = f(0).
If x Ì¸= 0, then we get by partial integration,
1
Ï€
 1
0
(1 âˆ’Ï‰) cos Ï‰ x dx
=
1
Ï€

(1 âˆ’Ï‰) sin Ï‰ x
x
1
0
+ 1
Ï€ x
 1
0
sin Ï‰ x dx =
1
Ï€ x
*
âˆ’cos Ï‰ x
x
+1
0
=
1 âˆ’cos x
Ï€ x2
= f(x),
and the claim is proved.
Download free eBooks at bookboon.com

Analytic Aids
 
96 
6. The characteristic function
2) We know that if E{X} exists, then k(Ï‰) is diï¬€erentiable at 0.
Since, however, k(Ï‰) is not diï¬€erentiable at Ï‰ = 0, we conclude by contraposition that E{X} does
not exist, so we conclude that X does not have a mean.
3) Then by a simple transformation,
kn(Ï‰)
=
 âˆ
âˆ’âˆ
ei Ï‰ xfn(x) dx =
 âˆ
âˆ’Ï‰
ei Ï‰ xf(nx)n dx =
 âˆ
âˆ’âˆ
exp

i Ï‰
n t

f(t) dt = k
Ï‰
n

=
â§
âª
â¨
âª
â©
1 âˆ’
000Ï‰
n
000 ,
|Ï‰| â‰¤n,
0,
|Ï‰| > n.
4) It follows from 3. that
lim
nâ†’âˆkn(Ï‰) = 1 = k0(Ï‰)
for ethvert Ï‰ âˆˆR,
where k0(Ï‰) â‰¡1 is the characteristic function for the causal distribution P{Y = 0} = 1.
Since k0(Ï‰) = 1 is continuous, it follows that (Xn) converges in distribution towards the causal
distribution Y .
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
MASTER IN MANAGEMENT
mim.admissions@ie.edu
Follow us on IE MIM Experience
www.ie.edu/master-management
#10 WORLDWIDE
MASTER IN MANAGEMENT 
FINANCIAL TIMES
55 Nationalities
in class
5 Specializations
Personalize your program 
Length: 1O MONTHS
Av. Experience: 1 YEAR
Language: ENGLISH / SPANISH
Format: FULL-TIME
Intakes: SEPT / FEB
â€¢ STUDY IN THE CENTER OF MADRID AND TAKE ADVANTAGE OF THE UNIQUE OPPORTUNITIES
  THAT THE CAPITAL OF SPAIN OFFERS
â€¢ PROPEL YOUR EDUCATION BY EARNING A DOUBLE DEGREE THAT BEST SUITS YOUR
  PROFESSIONAL GOALS
â€¢ STUDY A SEMESTER ABROAD AND BECOME A GLOBAL CITIZEN WITH THE BEYOND BORDERS
  EXPERIENCE
93%
OF MIM STUDENTS ARE
WORKING IN THEIR SECTOR 3 MONTHS
FOLLOWING GRADUATION

Analytic Aids
 
97 
6. The characteristic function
Remark 6.1 In Distribution Theory, which is a mathematical discipline dealing with generalized
functions, one expresses this by (fn) â†’Î´, where Î´ is Diracâ€™s Î´ â€œfunctionâ€. â™¦
Example 6.9 A random variable Y has the frequency
f(y) = a
2 eâˆ’a|y|,
y âˆˆR,
where a > 0 is a positive constant.
1. Find the characteristic function for Y .
2. Find the mean and variance of Y .
A random variable X has the values Â±1, Â±2, . . . of the probabilities
P{X = k} = P{X = âˆ’k} = 1
2 p qkâˆ’1,
k âˆˆN,
where p > 0, q > 0, p + q = 1.
3. Prove that the characteristic function for X is given by
kX(Ï‰) =
p(cos Ï‰ âˆ’q)
1 + q2 âˆ’2q cos Ï‰ ,
Ï‰ âˆˆR.
Then consider a sequence of random variables (Xn)<infty
n=1
, where Xn has the values Â± 1
n, Â± 2
n, . . . of
the probabilities
P

Xn = k
n
	
= P

Xn = âˆ’k
n
	
= 1
2 Â· 1
3n

1 âˆ’1
3n
kâˆ’1
,
k âˆˆN.
4. Find by using the result of 3. the characteristic function kn(Ï‰) for Xn.
5. Prove that the sequence (Xn) converges in in distribution towards a random variable Z, and ï¬nd
the frequency of Z.
1) The characteristic function is
kY (Ï‰)
=
 âˆ
âˆ’âˆ
ei Ï‰ y Â· a
2 Â· eâˆ’a|y| dy = a
2
 0
âˆ’âˆ
e(a+iÏ‰)y dy + a
2
 âˆ
0
e(âˆ’a+iÏ‰)y dy
=
a
2
e(a+i Ï‰)y
a + i Ï‰
0
âˆ’Ï‰
+ a
2
e(âˆ’a+i Ï‰)y
âˆ’a + i Ï‰
âˆ
0
= a
2

1
a + i Ï‰ +
1
a âˆ’i Ï‰

=
a2
a2 + Ï‰2 .
2) By the symmetry, E{Y } = 0. The variance is then
V {Y } = E

Y 2
= a
2
 âˆ
âˆ’âˆ
y2eâˆ’a|y| dy = 1
a2
 âˆ
0
t2eâˆ’t dt = 2!
a2 = 2
a2 .
Download free eBooks at bookboon.com

Analytic Aids
 
98 
6. The characteristic function
3) The characteristic function for X is
kX(Ï‰)
=
âˆ

k=1
P{X = âˆ’k} Â· eâˆ’i k Ï‰ +
âˆ

k=1
P{X = k} Â· ei k Ï‰
=
p
2
âˆ

k=1
qkâˆ’1 Â·

eâˆ’i Ï‰k + p
2
âˆ

k=1
qkâˆ’1 
ei Ï‰k
=
p
2eâˆ’i Ï‰
âˆ

k=1

q eâˆ’i Ï‰kâˆ’1 + p
2 ei Ï‰
âˆ

k=1

q ei Ï‰k = p
2 Â·
eâˆ’i Ï‰
1 âˆ’q eâˆ’i Ï‰ + p
2 Â·
ei Ï‰
1 âˆ’q ei Ï‰
=
p Re

ei Ï‰
1 âˆ’q ei Ï‰ Â·
1 âˆ’q eâˆ’i Ï‰
1 âˆ’q eâˆ’i Ï‰
	
= p Re

ei Ï‰ âˆ’q
1 âˆ’2q cos Ï‰ + q2
	
=
p(cos Ï‰ âˆ’1)
1 + q2 âˆ’2q cos Ï‰ .
4) We put p = 1
3n and q = 1 âˆ’1
3n. The characteristic function for Xn is obtained by replacing Ï‰ by
Ï‰
n, thus
kn(Ï‰) =
1
3n

cos Ï‰
n âˆ’1 + 1
3n

1 +

1 âˆ’1
3n
2
âˆ’2

1 âˆ’1
3n

cos
Ï‰
n
,
n âˆˆN.
5) It follows by insertion of
cos Ï‰
n = 1 âˆ’1
2 Â· Ï‰2
n2 + Ï‰2
n2 Îµ
Ï‰
n

,
that
kn(Ï‰)
=
1
3n

1âˆ’Ï‰2
2n2 + Ï‰2
n2 Îµ
 Ï‰
n

âˆ’1+ 1
3n

1+1âˆ’2
3n +
1
9n2 âˆ’2

1âˆ’1
3n
 
1âˆ’Ï‰2
n2 + Ï‰2
2n2 Îµ
 Ï‰
n
 = 1
3n
1
3n + 1
n Îµ
 1
n

2âˆ’2
3n +
1
9n2 âˆ’2+ 2
3n + Ï‰2
n2 + Ï‰2
n2 Îµ
 Ï‰
n

=
1
9n2 Â·
1 + Îµ
 1
n

1
9n2 + 1
n2 Ï‰2 + Ï‰2
n2 Îµ
Ï‰
n
 =
1 + Îµ
 1
n

1 + 9 Ï‰2 + Îµ
Ï‰
n
,
hence
lim
nâ†’âˆkn(Ï‰) =
1
1 + 9 Ï‰2 =
1
9
1
9 + Ï‰2
= ky(Ï‰),
where Y is the random variable from 1., corresponding to a = 1
3.
Since ky(Ï‰) is continuous, (Xn) converges in distribution towards Y for a = 1
3, thus
fY (y) = 1
6 exp

âˆ’|y|
3

,
y âˆˆR.
Download free eBooks at bookboon.com

Analytic Aids
 
99 
6. The characteristic function
Example 6.10 1. Let X be a random variable with the characteristic function k(Ï‰).
Prove that the random varible Y = âˆ’X has the characteristic function
kY (Ï‰) = k(Ï‰).
Let X1 and X2 be independent random variables, both of the distribution given by
P {Xi = j} =
1
2
j
,
j âˆˆN;
i = 1, 2.
2. Find the characteristic function k1(Ï‰) for X1.
3. Find the distribution of the random variable Z = X1 âˆ’X2.
4. Find, e.g. by using the result of 1., the characteristic function for Z.
Let Z1, Z2, . . . be mutually independent random variables, all of the same distribution as Z, and let
Un =
1
âˆšn
n

i=1
Zi,
n âˆˆN.
5. Prove e.g. by using characteristic functions that the sequence (Un)âˆ
n=1 converges in distribution
towards a random variable U, and ï¬nd the distribution function of U.
1) Since X is real, it immediately follows that
kY (Ï‰) = E

ei Ï‰ Y 
= E

eâˆ’i Ï‰ X
= E {ei Ï‰ X} = kX(Ï‰).
Alternatively,
kY (Ï‰)
=
E{cos(Ï‰Y ) + i sin(Ï‰Y )} = E{cos(âˆ’Ï‰X) + i sin(âˆ’Ï‰X)}
=
E{cos(Ï‰X) âˆ’i sin(Ï‰X)} = kX(Ï‰).
2) The characteristic function is
kX1(Ï‰) =
âˆ

j=1
1
2
j
ei Ï‰ j =
Ï‰

j=1
ei Ï‰
2
j
=
1
2 ei Ï‰
1 âˆ’1
2 ei Ï‰
=
ei Ï‰
2 âˆ’ei Ï‰ .
3) The distribution function is
FZ(z)
=
P {X1 âˆ’X2 â‰¤z} =
 
jâˆ’kâ‰¤[z]P {X1 = j} Â· P {X2 = k}
=
âˆ

k=max{1,1âˆ’[z]}
k+[z]

j=1
1
2
j
Â·
1
2
k
=
âˆ

k=max{1,1âˆ’[z]}
1
2
k
Â·
1
2 âˆ’
1
2
k+[z]+1
1 âˆ’1
2
=
âˆ

k=max{1,1âˆ’[z]}
1
2
k
âˆ’
1
2
2k+[z]
.
Download free eBooks at bookboon.com

Analytic Aids
 
100 
6. The characteristic function
If z < 0, then
FZ(z)
=
âˆ

k=1âˆ’[z]
1
2
k
âˆ’
1
2
2k+[z]
=
âˆ

k=1
1
2
kâˆ’[z]
âˆ’
1
2
2kâˆ’[z]
=
1
2
âˆ’[z] âˆ

k=1
1
2
k
âˆ’
1
4
k
=
1
2
âˆ’[z] 
1 âˆ’1
3

= 2
3
1
2
âˆ’[z]
.
If z â‰¥0, then
FZ(z) =
âˆ

k=1
1
2
k
âˆ’
1
2
2k+[z]
= 1 âˆ’
1
2
[z] âˆ

k=1
1
4
k
= 1 âˆ’1
3
1
2
[z]
.
Summing up,
FZ(z) =
â§
âª
âª
âª
âª
âª
â¨
âª
âª
âª
âª
âª
â©
2
3
1
2
âˆ’[z]
,
hvis z < 0,
1 âˆ’1
3
1
2
[z]
,
if z â‰¥0,
[z] integer part of z.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more

Analytic Aids
 
101 
6. The characteristic function
Alternatively, Z = X1 âˆ’X2 is its values in R. By the symmetry,
P{Z = k} = P{Z = âˆ’k}.
If k â‰¥0, then
P{Z = k}
=
P{Z = âˆ’k} =
âˆ

j=1
P {X1 = j + k} Â· P {X2 = j} =
âˆ

j=1
1
2
j+k 1
2
j
=
1
2
k âˆ

j=1
1
4
j
=
1
2
k
Â·
1
4
1 âˆ’1
4
= 1
3 Â·
1
2
k
,
k âˆˆN0,
where we describe the distribution by the probabilities of the points.
4) It follows from 1. and 2. that
kZ(Ï‰) =
ei Ï‰
2 âˆ’ei Ï‰ Â·
eâˆ’i Ï‰
2 âˆ’eâˆ’i Ï‰ =
1
5 âˆ’4 cos Ï‰ .
Alternatively, kZ(Ï‰) is computed in the following way,
kZ(Ï‰)
=
âˆ

k=0
P{Z = k}eikÏ‰ +
âˆ

k=0
P{Z = âˆ’k}eâˆ’ikÏ‰ = 1
3
âˆ

k=0
1
2 eiÏ‰
k
+ 1
3
âˆ

k=1
1
2 eâˆ’iÏ‰
k
=
1
3
â§
âª
â¨
âª
â©
1
1 âˆ’1
2 eiÏ‰
+
1
2 eâˆ’iÏ‰
1 âˆ’1
2 eâˆ’iÏ‰
â«
âª
â¬
âª
â­
= 1
3 Â·
1 âˆ’1
2 eâˆ’iÏ‰ + 1
2 eâˆ’iÏ‰ âˆ’1
4
5
4 âˆ’cos Ï‰
= 1
4 Â·
1
5
4 âˆ’cos Ï‰
=
1
5 âˆ’4 cos Ï‰ ,
Ï‰ âˆˆR.
5) The characteristic function for Un is
kUn(Ï‰) =

kZ
 Ï‰
âˆšn
n
=
1

5 âˆ’4 cos Ï‰
âˆšn
n .
We conclude from

5 âˆ’4 cos Ï‰
âˆšn
n
=

5 âˆ’4

1 âˆ’1
2
Ï‰2
n + 1
n Îµ
 1
n
	n
=

1 + 2Ï‰2
n
+ 1
n Îµ
 1
n
n
,
that
kUn(Ï‰) â†’lim
nâ†’âˆ

1 + 2Ï‰2
n
+ 1
n Îµ
 1
n
	âˆ’n
= eâˆ’2Ï‰2 = exp

âˆ’1
2 4Ï‰2

.
We see that kU(Ï‰) = exp

âˆ’1
2 Â· 4Ï‰2

is continuous, hence U âˆˆN(0, 4), and Un â†’U in distribu-
tion, where U âˆˆN(0, 4) is normally distributed.
Download free eBooks at bookboon.com

Analytic Aids
 
102 
6. The characteristic function
Alternatively we may use that X1 and X2 are both geometrically distributed of variance 2,
hence the Zi have the variance 4. Then it follows from the Central Limit Theorem that
1
2 Un =
1
2âˆšn
n

i=1
Zn
for n â†’âˆconverges in distribution towards V âˆˆN(0, 1).
Then
Un
D
âˆ’â†’U âˆˆN(0, 4).
Example 6.11 Let X1 and X2 be independent random variables of distribution given by
P {X1 = j} = P {X2 = j} = p qj,
j âˆˆN0,
where p > 0, q > 0, p + q = 1, and let Y = X1 âˆ’X2.
1. Find the mean and variance of Y .
2. Find P{Y = j} for every j âˆˆZ.
3. Find the characteristic function for X1 and the characteristic function for âˆ’X2, and thus this to
ï¬nd the characteristic function for Y .
Given a sequence of random variables (Yn)âˆ
n=1, where for each n âˆˆN, the random variable Yn has a
distribution as Y corresponding to p = 1
2n, q = 1 âˆ’1
2n. Let Zn = 1
n Yn.
4. Prove, e.g. by using 3. that the sequence (Zn)âˆ
n=1 converges in distribution towards a random
variable Z, and ï¬nd distribution of Z.
1) Using that X1 and X2 are identically distributed and that both the mean and the variance exist,
we get
E{Y } = E {X1} âˆ’E {X2} = 0,
andd
V {Y }
=
2 V {X1} = 2 E

X2
1

= 2 E {X1 (X1 âˆ’1)} + 2 E {X1}
=
2
âˆ

j=2
j(j âˆ’1)p qj + 2
âˆ

j=1
jpqj = 2pq2

1
1 âˆ’q
2
+ 2pq Â·
1
1 âˆ’q = 2
q2
p2 + q
p

=
2 q
p2 (q + p) = 2q
p2 .
2) The probability is
P{Y = j} =

â„“âˆ’k=j
â„“â‰¥0, kâ‰¥0
P {X1 = â„“} Â· P {X2 = k} = p2

â„“âˆ’k=j
â„“â‰¥0, kâ‰¥0
qj Â· qk.
If j â‰¥0, then â„“= k + j, hence by the symmetry,
P{Y = j} = P{Y = âˆ’j} = p2
âˆ

k=0
qk+j Â· qk = p2qj
âˆ

k=0

q2k = p2 Â· qj
1 âˆ’q2 = pqj
1 + q .
Download free eBooks at bookboon.com

Analytic Aids
 
103 
6. The characteristic function
3) he characteristic function for X1 is
kX1(Ï‰) =
âˆ

k=0
P {X1 = k} ei k Ï‰ = p
âˆ

k=0
qk 
ei Ï‰k =
p
1 âˆ’q ei Ï‰ .
The characteristic function for âˆ’X2 is
Kâˆ’X2(Ï‰) = kX1(âˆ’Ï‰) =
p
1 âˆ’q eâˆ’i Ï‰ .
The characteristic function for Y = X1 âˆ’X2 is
kY (Ï‰) = kX1(Ï‰) Â· kâˆ’X2(Ï‰) =
p
1 âˆ’q ei Ï‰ Â·
p
1 âˆ’q eâˆ’i Ï‰ =
p2
1 + q2 âˆ’2q cos Ï‰ .
4) The characteristic function for Zn = 1
n Yn is
kZn(Ï‰) =
 1
2n
2
1 +

âˆ’1
2n
2
âˆ’2

1 âˆ’1
2n

cos
Ï‰
n
 =
1
4n2 + (2n âˆ’1)2 âˆ’4n(2n âˆ’1) cos
Ï‰
n
.
Using an expansion of the denominator we get
8n2 âˆ’4n + 1 âˆ’

8n2 âˆ’4n
 
1 âˆ’1
2
Ï‰2
n2 + 1
n2 Îµ
 1
n

= 8n2 âˆ’4n + 1 âˆ’8n2 + 4n + 4Ï‰2 âˆ’2 Ï‰2
n + Îµ
 1
n

= 1 + 4Ï‰2 + Îµ
 1
n

,
hence
lim
nâ†’âˆkZn(Ï‰) = lim
nâ†’âˆ
1
1 + 4Ï‰2 + Îµ
 1
n
 =
1
1 + 4 Ï‰2 .
Since the double exponentially distributed random variable Z with a = 1
2 has the characteristic
function
kZ(Ï‰) =
1
2
2
1
2
2
+ Ï‰2
=
1
1 + 4 Ï‰2 ,
we conclude that (Zn) converges in distribution towards Z.
Download free eBooks at bookboon.com

Analytic Aids
 
104 
6. The characteristic function
Example 6.12 A random variable X has the frequency
f(x) =
â§
âª
âª
âª
â¨
âª
âª
âª
â©
1
Ï€
sin2 x
x2
,
x Ì¸= 0,
1
Ï€ ,
x = 0.
1. Find the median of X.
It can be shown (shall not be proved) that X has the characteristic function
k(Ï‰) =
â§
âª
â¨
âª
â©
1 âˆ’|Ï‰|
2 ,
|Ï‰| â‰¤2,
0,
|Ï‰| > 2.
2. Prove that X does not have a mean.
Let X1, X2, X3, . . . be mutually independent random variables, all of the same distribution as X. Let
Zn = 1
n
n

j=1
Xj,
n âˆˆN.
3. Find the characteristic function for Zn.
4. Prove that the sequence (Zn)âˆ
n=1 converges in distribution towards a random variable Z, and ï¬nd
the distribution of Z.
5. Compute the probability P

âˆ’1
2 < Z < 1
2
	
.
1) It follows from f(âˆ’x) = f(x) that the median is âŸ¨XâŸ©= 0.
2) Since k(Ï‰) is not diï¬€erentiable at Ï‰ = 0, the random variable X does not have a mean.
3) The characteristic function for Zn is
kZn(Ï‰) =

k
Ï‰
n
n
=
â§
âª
âª
â¨
âª
âª
â©

1 âˆ’|Ï‰|
2n
n
for |Ï‰| â‰¤2n,
0
for |Ï‰| > 2n.
4) Now, kZn(Ï‰) â†’exp

âˆ’|Ï‰|
2

for n â†’âˆand every ï¬xed Ï‰ âˆˆR. Since exp

âˆ’|Ï‰|
2

is continuous,
(Zn) converges in distribution towards Z. Using a table we see that Z âˆˆC

0, 1
2

is Cauchy
distributed of the frequency
fZ(z) =
1
2
Ï€
1
4 + z2
 = 2
Ï€ Â·
1
1 + (2z)2
for z âˆˆR.
Download free eBooks at bookboon.com

Analytic Aids
 
105 
6. The characteristic function
5) The probability is
P

âˆ’1
2 < Z < 1
2
	
= 2
Ï€

1
2
âˆ’1
2
dz
1 + (2z)2 = 1
Ï€
 1
âˆ’1
dt
1 + t2 = 2
Ï€ [Arctan t]1
0 = 1
2.
Example 6.13 We say that a random variable X has a symmetric distribution, if X and âˆ’X have
the same distribution.
Assume that X has the characteristic function kX(Ï‰). Prove that âˆ’X has the characteristic function
kâˆ’X(Ï‰) = kX(Ï‰).
Prove that the characteristic function for X is a real function, is and only if X has a symmetric
distribution.
The ï¬rst question is almost trivial,
kâˆ’X(Ï‰) = E

eâˆ’i Ï‰ X
= E {ei Ï‰ X} = kX(Ï‰).
1) If X has a symmetric distribution, then
kâˆ’X(Ï‰) = kX(Ï‰) = kX(Ï‰),
and we conclude that kX(Ï‰) is real.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
â€œThe perfect start 
of a successful, 
international career.â€
CLICK HERE 
to discover why both socially 
and academically the University 
of Groningen is one of the best 
places for a student to be 
www.rug.nl/feb/education
Excellent Economics and Business programmes at:

Analytic Aids
 
106 
6. The characteristic function
2) Conversely, if kX(Ï‰) is real, then
kâˆ’X(Ï‰) = kX(Ï‰) = kX(Ï‰),
from which follows that âˆ’X and X have the same characteristic function, and hence the same
distribution. This proves that X has a symmetric distribution.
Example 6.14 Prove that the characteristic function for the distribution given by
P{X = âˆ’n} = P{X = n} =
c
n2 ln n,
n = 2, 3, . . . ,
where
c Â·
+âˆ

n=2
1
n2 ln n = 1
2,
is of class C1.
Hint: The problem is to prove that the termwise diï¬€erentiated series
âˆ’2c
âˆ

n=2
sin n Ï‰
n ln n
is uniformly convergent on R. Show this by successively proving that
1)
00000
q

n=p
sin n Ï‰
00000 â‰¤
1
000sin Ï‰
2
000
,
Ï‰ Ì¸= 2m Ï€,
p, q âˆˆN,
p < q.
2)
00000
N

n=p
1
n sin n Ï‰
00000 â‰¤Ï€ + 1,
Ï‰ âˆˆR,
p, N âˆˆN,
p < N.
3)
00000
q

n=p
sin n Ï‰
n
Â·
1
ln n
00000 â‰¤(Ï€ + 1) Â·
1
ln p,
Ï‰ âˆˆR,
p, q âˆˆN,
2 â‰¤p < q.
Here we shall also use Abelâ€™s formula for partial summation, which is written
q

n=p
anbn =
qâˆ’1

n=p
An (bn âˆ’bn+1) + Aqbq,
where
An =
n

k=p
ak.
Abelâ€™s formula above is similar to partial integration; â€™ here we use sums instead of integrals.
The claim follows easily from the estimate in 3., because the right hand side tends towards 0 for
p â†’âˆ, independently of Ï‰ âˆˆR.
Download free eBooks at bookboon.com

Analytic Aids
 
107 
6. The characteristic function
1) If p < q and Ï‰ Ì¸= 2m pi, then
q

n=p
sin n Ï‰
=
Im
q

n=p
ei n Ï‰ = Im eo p Ï‰ âˆ’ei(q+1)Ï‰
1 âˆ’ei Ï‰
=
Im exp

i

q + 1
2

Ï‰

âˆ’exp

i

p âˆ’1
2

Ï‰

1
2i

exp

i Ï‰
2

âˆ’exp

âˆ’i Ï‰
2

Â· 2i
=
1
2 sin Ï‰
2
Â·

cos

p âˆ’1
2

Ï‰ âˆ’cos

q + 1
2

Ï‰
	
,
thus we get the estimate
00000
q

n=p
sin n Ï‰
00000 â‰¤
1 + 1
2
00sin Ï‰
2
00 =
1
00sin Ï‰
2
00
for Ï‰ Ì¸= 2m Ï€,
m âˆˆZ.
Notice that the left hand side is 0 for Ï‰ = 2m Ï€, m âˆˆZ.
2) Due to the periodicity it suï¬ƒces to consider Ï‰ âˆˆ[âˆ’Ï€, Ï€]. Using that sinus is an odd function, it
follows that it even suï¬ƒces to consider Ï‰ âˆˆ[0, Ï€]. Finally, if follows from 1. that we can restrict
ourselves to Ï‰ âˆˆ]0, Ï‰0], where
Ï‰0 = 2 Arcsin
1
Ï€ + 1.
Let N > p, and choose Ï‰p = Ï€
p . We group the terms in the following way,
N

n=1
1
n sin

n Ï€
p

=
k0âˆ’1

k=0
(k+1)p

n=kp+1
1
n sin

n Ï€
p

+
N

n=k0p+1
1
n sin

n Ï€
p

,
where
k0 =
N âˆ’1
p

denotes the integer part of (N âˆ’1)/p. We note that the sequence (in k)
â›
â
(k+1)p

n=k+1
1
n sin

n Ï€
p
â
â 
is alternating and that the corresponding sequence of absolute values tends decressingly towards
0. Thus we get the following estimate,
00000
N

n=p
1
n sin

n Ï€
p
00000
â‰¤
p

n=1
1
n sin

n Ï€
p

â‰¤2
[ p
2]

n=1
1
n sin

n Ï€
p

01
â‰¤
2
[ p
2]

n=1
1
n Â· n Ï€
p + 1 â‰¤2 Â· p
2 Â· Ï€
p + 1 = Ï€ + 1.
Download free eBooks at bookboon.com

Analytic Aids
 
108 
6. The characteristic function
If
Ï€
p + 1 < Ï‰ < Ï€
p , then we estimate upwards by
sin n Ï‰ < sin

n Ï€
p

for n â‰¤
*p
2
+
.
Hence
00000
N

n=p
1
n sin nÏ‰
00000 â‰¤Ï€ + 1,
Ï‰ âˆˆR,
p, N âˆˆN,
p < N.
3) Let 2 â‰¤p < q, and choose
an = sin n Ï‰
n
with
An =
n

k=p
sin k Ï‰
k
,
|An| â‰¤Ï€1
according to 2.. Finally, choose bn =
1
ln n. Then it follows by an application of Abelian summation
that
q

n=p
sin n Ï‰
n
Â·
1
ln n =
qâˆ’1

n=p
An Â·
 1
ln n âˆ’
1
ln(n + 1)

+ Aq Â·
1
ln q .
Thus we get the estimate
00000
q

n=p
sin n Ï‰
n
Â·
1
ln n
00000
â‰¤
qâˆ’1

n=p
|An| Â·
 1
ln n âˆ’
1
ln(n + 1)

+ |Aq| Â·
1
ln q
â‰¤
(Ï€ + 1)
qâˆ’1

n=1
 1
ln n âˆ’
1
ln(n + 1)

+
1
ln q

= Ï€ + 1
ln p
as required.
As mentioned above it then follows that the termwise diï¬€erentiated series is uniformly convergent,
and the characteristic function is of class C1.
Download free eBooks at bookboon.com

Analytic Aids
 
109 
Index
Index
Abelâ€™s formula for partial summation, 104
Abelâ€™s theorem, 5
Bernoulli distribution, 5
binomial distribution, 4, 5, 43
Cauchy distribution, 14, 102
causal distribution, 48, 50, 65, 87, 94
Central Limit Theorem, 87, 91, 100
characteristic function, 12, 83
completely monotone function, 77
continuity theorem, 7
convergence in distribution, 11, 17, 49, 50, 52,
53, 60, 65, 75, 79, 81, 86, 88, 89, 91,
93, 95, 97, 100, 102
convergence in probability, 64
Diracâ€™s Î´ â€œfunctionâ€, 95
double exponential distribution, 14, 101
Erlang distribution, 10, 14
exponential distribution, 10, 14, 42, 46, 51, 55,
67, 82
Fourier transform, 13
Gamma distribution, 10, 15, 47, 72, 79
GauÃŸian distribution, 15
generating function, 4, 5, 18
geometric distribution, 6, 18, 38, 41, 100
inversion formula, 9, 13, 85, 89, 93
Laplace transformation, 8, 46
logarithmic distribution, 49
mean, 6
moment, 6, 10, 15
negative binomial distribution, 6, 24, 34
normal distribution, 15, 75, 88, 91, 99
Pascal distribution, 6, 37, 40, 73, 79
Poisson distribution, 4, 6, 25, 28, 37, 34, 38,
67, 83
rectangular distribution, 15, 56, 84
symmetric distribution, 103
truncated Poisson distribution, 26, 29
variance, 6
Ï‡2 distribution, 9, 14
Download free eBooks at bookboon.com

