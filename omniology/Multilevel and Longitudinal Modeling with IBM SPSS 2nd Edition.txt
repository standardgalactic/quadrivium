www.allitebooks.com

 Multilevel and 
Longitudinal 
Modeling with 
IBM SPSS 
 Th is book demonstrates how to use multilevel- and longitudinal-modeling techniques avail-
able in the IBM SPSS mixed-eﬀ ects program (MIXED). Annotated screen shots provide read-
ers with a step-by-step understanding of each technique and navigating the program. Readers 
learn how to set up, run, and interpret a variety of models. Diagnostic tools, data management 
issues, and related graphics are introduced throughout. Annotated syntax is also available for 
those who prefer this approach. Extended examples illustrate the logic of model development 
to show readers the rationale of the research questions and the steps around which the analyses 
are structured. Th e data used in the text and syntax examples are available at www.routledge.
com/9780415817110. 
 Highlights of the new edition include the following: 
 • Updated throughout to reﬂ ect IBM SPSS Version 21. 
 •  Further coverage of growth trajectories, coding time-related variables, covariance structures, 
individual change, and longitudinal experimental designs. 
 •  Extended discussion of other types of research designs for examining change (e.g., regression 
discontinuity, quasi-experimental) over time. 
 • New examples specifying multiple latent constructs and parallel growth processes. 
 •  Discussion of alternatives for dealing with missing data and the use of sample weights within 
multilevel data structures. 
 Th e book opens with the conceptual and methodological issues associated with multilevel and 
longitudinal modeling, followed by a discussion of SPSS data management techniques that fa-
cilitate working with multilevel, longitudinal, and cross-classiﬁ ed data sets. Chapters 3 and 4 in-
troduce the basics of multilevel modeling: developing a multilevel model, interpreting output, 
and trouble-shooting common programming and modeling problems. Models for investigating 
individual and organizational change are presented in Chapters 5 and 6, followed by models with 
multivariate outcomes in Chapter 7. Chapter 8 provides an illustration of multilevel models with 
cross-classiﬁ ed data structures. Th e book concludes with ways to expand on the various multilevel- 
and longitudinal-modeling techniques and issues when conducting multilevel analyses. 
 Ideal as a supplementary text for graduate courses on multilevel and longitudinal modeling, 
multivariate statistics, and research design taught in education, psychology, business, and sociol-
ogy, this book’s practical approach also appeals to researchers in these ﬁ elds. Th e book provides 
an excellent supplement to Heck and Th omas’s  An Introduction to Multilevel Modeling Techniques 
www.allitebooks.com

(2nd ed.); however, it can also be used with any multilevel- and/or longitudinal-modeling book 
or as a stand-alone text. 
 Ronald H. Heck  is professor of education at the University of Hawai‘i at Mānoa. His areas of 
interest include organizational theory, leadership, policy, and quantitative research methods. 
 Scott L. Th omas  is professor and dean of the School of Educational Studies at Claremont Grad-
uate University. His specialties include sociology of education, policy, and quantitative research 
methods. 
 Lynn N. Tabata  is an aﬃ  liate graduate faculty member and research consultant at the University 
of Hawai‘i at Mānoa. Her research interests focus on faculty, distance learning, and technology 
issues in higher education. 
www.allitebooks.com

 Quantitative Methodology Series
George A. Marcoulides, Series Editor
T
his series presents methodological techniques to investigators and students. Th e goal is to 
provide an understanding and working knowledge of each method with a minimum of 
mathematical derivations. Each volume focuses on a speciﬁ c method (e.g. Factor Analysis, Mul-
tilevel Analysis, Structural Equation Modeling). 
Proposals are invited from interested authors. Each proposal should consist of: a brief de-
scription of the volume’s focus and intended market; a table of contents with an outline of each 
chapter; and a curriculum vita. Materials may be sent to Dr. George A. Marcoulides, University 
of California – Riverside, george.marcoulides@ucr.edu.
Marcoulides • Modern Methods for Business Research
Marcoulides/Moustaki • Latent Variable and Latent Structure Models
Heck • Studying Educational and Social Policy: Th eoretical Concepts and Research Methods
Van der Ark/Croon/Sijtsma • New Developments in Categorical Data Analysis for the Social 
and Behavioral Sciences
Duncan/Duncan/Strycker • An Introduction to Latent Variable Growth Curve Modeling: 
Concepts, Issues, and Applications, Second Edition
Heck/Th omas • An Introduction to Multilevel Modeling Techniques, Second Edition
Cardinet/Johnson/Pini • Applying Generalizability Th eory Using EduG
Creemers/Kyriakides/Sammons • Methodological Advances in Educational Eﬀ ectiveness 
Research
Hox • Multilevel Analysis: Techniques and Applications, Second Edition
Heck/Th omas/Tabata • Multilevel Modeling of Categorical Outcomes Using IBM SPSS
Heck/Th omas/Tabata • Multilevel and Longitudinal Modeling with IBM SPSS, Second 
Edition
McArdle/Ritschard • Contemporary Issues in Exploratory Data Mining in the Behavioral 
Sciences 
www.allitebooks.com

              This page intentionally left blank
www.allitebooks.com

 Multilevel and 
Longitudinal 
Modeling with 
IBM SPSS 
 Second Edition 
 Ronald H. Heck 
 University of Hawai‘i at Ma- noa 
 Scott L. Thomas 
 Claremont Graduate University 
 Lynn N. Tabata 
 University of Hawai‘i at Ma- noa 
www.allitebooks.com

 First published 2014 
 by Routledge 
 711 Th ird Avenue, New York, NY 10017  
 Simultaneously published in the UK 
by Routledge
27 Church Road, Hove, East Sussex BN3 2FA
   Routledge is an imprint of the Taylor & Francis Group, an informa business 
 © 2014 Taylor & Francis 
 Th e right of Ronald H. Heck, Scott L. Th omas, and Lynn N. Tabata to be identiﬁ ed as authors of this work has been 
asserted by them in accordance with sections 77 and 78 of the Copyright, Designs and Patents Act 1988. 
 All rights reserved. No part of this book may be reprinted or reproduced or utilised in any form or by any electronic, 
mechanical, or other means, now known or hereafter invented, including photocopying and recording, or in any 
information storage or retrieval system, without permission in writing from the publishers. 
 Trademark notice : Product or corporate names may be trademarks or registered trademarks, and are used only for 
identiﬁ cation and explanation without intent to infringe. 
 Reprinted IBM SPSS Screenshots Courtesy of International Business Machines Corporation, © SPSS, Inc., an 
IBM Company* 
 Library of Congress Cataloging in Publication Data 
Heck, Ronald H.
 Multilevel and longitudinal modeling with IBM SPSS / Ronald H. Heck, Th e University of Hawaii at Manoa, Scott 
L. Th omas, Claremont Graduate University, Lynn N. Tabata, Th e University of Hawaii at Manoa.—Second edition.
  pages cm. — (Quantitave methodology series)
 Includes bibliographical references and index.
1. Social sciences—Longitudinal studies. 2. Social sciences—Statistical methods. 3. PASW (Computer ﬁ le) 
4. SPSS (Computer ﬁ le) I. Th omas, Scott L. II. Tabata, Lynn Naomi. III. Title. 
 HA32.H39 2013
 005.5'5—dc23   2013004161
 ISBN: 978-0-415-81710-3 (hbk) 
 ISBN: 978-0-415-81711-0 (pbk) 
 ISBN: 978-0-203-70124-9 (ebk) 
 Typeset in ACaslon Pro 
 by  Apex CoVantage, LLC
 *SPSS was acquired by IBM in October 2009. 
Please visit the eResources site at
www.routledge.com/9780415817110
www.allitebooks.com

 Contents 
 Preface  
xv
 Chapter 1  Introduction to Multilevel Modeling with IBM SPSS  
1
 Our Intent  
2
 Overview of  Topics  
4
 Analysis of Multilevel Data Structures  
4
 Partitioning Variation in an Outcome  
8
 Developing a General Multilevel-Modeling Strategy  
9
 Illustrating the Steps in Investigating a Proposed Model  
10
 1. One-Way ANOVA (No Predictors) Model  
11
 2. Analyze a Level 1 Model with Fixed Predictors  
12
 3. Add the Level 2 Explanatory Variables  
13
 4. Examine Whether a Particular Slope Coeﬃ  cient Varies Between Groups  
14
 5. Adding Cross-Level Interactions to Explain Variation in the Slope  
15
 Syntax Versus IBM SPSS Menu Command Formulation  
16
 Model Estimation and Other Typical Multilevel-Modeling Issues  
18
 Sample Size 
20
 Power  
20
 Diﬀ erences Between Multilevel Software Programs  
21
 Standardized and Unstandardized Coeﬃ  cients  
21
 Missing Data  
22
 Missing Data at Level 2  
26
 Missing Data in Vertical Format in IBM SPSS MIXED  
28
 Design Eﬀ ects, Sample Weights, and the Complex Samples Routine 
in IBM SPSS 
30
 An Example Using Multilevel Weights  
32
 Summary  
34
 Chapter 2  Preparing and Examining the Data for Multilevel Analyses  
35
 Data Requirements  
35
 File Layout 
36
 Getting Familiar with Basic IBM SPSS Data Commands  
38
 Recode: Creating a New Variable Th rough Recoding 
39
 Recoding Old Values to New Values  
39
 Recoding Old Values to New Values Using “Range”  
41
 Compute: Creating a New Variable Th at Is a Function of Some Other Variable  
44
 Match Files: Combining Data From Separate IBM SPSS Files  
46
 Aggregate: Collapsing Data Within Level 2 Units  
52
 VARSTOCASES: Vertical Versus Horizontal Data Structures  
53
 Using “Compute” and “Rank” to Recode the Level 1 or Level 2 Data 
for Nested Models  
59
 Creating an Identiﬁ er Variable  
59
 Creating an Individual-Level Identiﬁ er Using “Compute”  
60
 Creating a Group-Level Identiﬁ er Using “Rank Cases”  
61
 Creating a Within-Group-Level Identiﬁ er Using “Rank Cases”  
63
 Centering  
65
vii
www.allitebooks.com

viii  Contents
 Grand-Mean Centering  
67
 Group-Mean Centering  
69
 Checking the Data  
72
 A Note About Model Building 
73
 Summary 
73
 Chapter 3  Deﬁ ning a Basic Two-Level Multilevel Regression Model  
75
 From Single-Level to Multilevel Analysis  
75
 Building a Two-Level Model  
77
 Research Questions  
78
 Th e Data  
78
 Specifying the Model  
78
 Graphing the Relationship Between SES and Math Test Scores 
with IBM SPSS Menu Commands  
80
 Graphing the Subgroup Relationships Between SES and Math Test Scores 
with IBM SPSS Menu Commands  
86
 Building a Multilevel Model with IBM SPSS MIXED  
88
 Step 1: Examining Variance Components Using the Null Model  
89
 Deﬁ ning Model 1 (Null) with IBM SPSS Menu Commands  
90
 Interpreting the Output From Model 1 (Null)  
93
 Step 2: Building the Individual-Level (or Level 1) Random Intercept Model  
95
 Deﬁ ning Model 2 with IBM SPSS Menu Commands  
96
 Interpreting the Output From Model 2  
98
 Step 3: Building the Group-Level (or Level 2) Random Intercept Model  
101
 Deﬁ ning Model 3 with IBM SPSS Menu Commands  
102
 Interpreting the Output From Model 3  
104
 Deﬁ ning Model 3A ( Public  as Covariate) with IBM SPSS 
Menu Commands  
108
 Step 4: Adding a Randomly Varying Slope (the Random Slope and 
Intercept Model)  
110
 Deﬁ ning Model 4 with IBM SPSS Menu Commands  
111
 Interpreting the Output From Model 4  
113
 Step 5: Explaining Variability in the Random Slope (More Complex 
Random Slopes and Intercept Models)  
115
 Deﬁ ning Model 5 with IBM SPSS Menu Commands  
116
 Add First Interaction to Model 5:  ses_mean*ses  
118
 Add Second Interaction to Model 5:  pro4yrc*ses  
118
 Add Th ird Interaction to Model 5:  public*ses  
118
 Interpreting the Output From Model 5  
119
 Deﬁ ning Model 5A with IBM SPSS Menu Commands  
121
 Graphing a Cross-Level Interaction (SES-Achievement Relationships 
in High- and Low-Achieving Schools) with IBM SPSS Menu Commands 
123
 Centering Predictors  
126
 Centering Predictors in Models with Random Slopes  
128
 Summary 
130
 Chapter 4  Th ree-Level Univariate Regression Models  
131
 Th ree-Level Univariate Model  
131
 Research Questions  
131
 Th e Data  
132
www.allitebooks.com

Contents  ix
 Deﬁ ning the Th ree-Level Multilevel Model  
133
 Th e Null Model (No Predictors)  
134
 Deﬁ ning Model 1 (Null) with IBM SPSS Menu Commands  
135
 Interpreting the Output From Model 1 (Null)  
138
 Model 2: Deﬁ ning Predictors at Each Level  
139
 Deﬁ ning Model 2 with IBM SPSS Menu Commands  
142
 Interpreting the Output From Model 2  
144
 Model 3: Group-Mean Centering  
145
 Deﬁ ning Model 3 with IBM SPSS Menu Commands  
145
 Interpreting the Output From Model 3  
147
 Covariance Estimates  
148
 Model 4: Does the Slope Vary Randomly Across Schools?  
149
 Deﬁ ning Model 4 with IBM SPSS Menu Commands  
150
 Interpreting the Output From Model 4  
153
 Developing an Interaction Term  
154
 Preliminary Investigation of the Interaction  
155
 Deﬁ ning Models A and B (Preliminary Testing of Interactions) 
with IBM SPSS Menu Commands  
156
 Model A Test Interaction:  teacheﬀ ect*classlowses_mean 
158
 Model B Test Interaction:  gmteacheﬀ ect*gmclasslowses_mean  
159
 Model 5: Examining a Level 2 Interaction  
161
 Deﬁ ning Model 5 with IBM SPSS Menu Commands  
161
 Add Interaction to Model 5:  gmclasslowses_mean*gmteacheﬀ ect  
163
 Interpreting the Output From Model 5  
163
 Comparing the Fit of Successive Models  
164
 Summary  
166
 Chapter 5  Examining Individual Change with Repeated Measures Data  
167
 Ways to Examine Repeated Observations on Individuals  
167
 Considerations in Specifying a Linear Mixed Model  
168
 An Example Study  
171
 Research Questions 
171
 Th e Data  
171
 Examining the Shape of Students’ Growth Trajectories  
173
 Graphing the Linear and Nonlinear Growth Trajectories 
with IBM SPSS Menu Commands  
175
 Select Subset of Individuals 
176
 Generate Figure 5.3 (Linear Trajectory)  
178
 Generate Figure 5.4 (Nonlinear Quadratic Trajectory)  
180
 Coding the Time-Related Variables  
181
 Coding Time Interval Variables ( time to  quadtime ) 
with IBM SPSS Menu Commands  
182
 Coding Time Interval Variables ( time to  orthtime ,  orthquad  ) 
with IBM SPSS Menu Commands  
184
 Specifying the Two-Level Model of Individual Change  
186
 Level 1 Covariance Structure  
188
 Repeated Covariance Dialog Box  
188
 Model 1.1: Model with No Predictors  
191
 Deﬁ ning Model 1.1 (Null) with IBM SPSS Menu Commands  
192
 Interpreting the Output From Model 1.1 (Null)  
195
 Model 1.1A: What Is the Shape of the Trajectory?  
196
www.allitebooks.com

x  Contents
 Deﬁ ning Model 1.1A with IBM SPSS Menu Commands  
197
 Interpreting the Output From Model 1.1A  
199
 Does the Time-Related Slope Vary Across Groups?  
200
 Level 2 Covariance Structure  
201
 Deﬁ ning Model 1.1B with IBM SPSS Menu Commands  
201
 Interpreting the Output From Model 1.1B  
203
 Examining Orthogonal Components  
204
 Deﬁ ning Model 1.2 with IBM SPSS Menu Commands  
205
 Interpreting the Output From Model 1.2  
207
 Specifying the Level 1 Covariance Structure  
208
 Investigating Other Level 1 Covariance Structures  
209
 Deﬁ ning Other Level 1 Covariance Structures Using IBM SPSS 
Menu Commands  
210
 Model 1: ID (Level 1), UN (Level 2)  
210
 Scaled Identity Covariance Matrix at Level 1  
210
 Unstructured Covariance Matrix at Level 2  
211
 Model 2: DIAG (Level 1), DIAG (Level 2)  
211
 Diagonal Covariance Matrix at Level 1  
211
 Diagonal Covariance Matrix at Level 2  
212
Model 3: DIAG (Level 1), UN (Level 2)  
212
 Diagonal Covariance Matrix at Level 1  
212
 Unstructured Covariance Matrix at Level 2  
213
 Model 4: AR1 (Level 1), DIAG (Level 2)  
213
 Autoregressive Errors (AR1) Covariance Matrix at Level 1  
213
 Diagonal Covariance Matrix at Level 2  
214
 Model 1.3: Adding the Between-Subjects Predictors  
214
 Deﬁ ning Model 1.3 with IBM SPSS Menu Commands  
215
 Add First Cross-Level Interaction to Model 1.3:  ses*orthtime 
218
 Add Second Cross-Level Interaction to Model 1.3:  eﬀ ective*orthtime  
218
 Interpreting the Output From Model 1.3  
219
 Graphing the Results  
222
 Graphing the Growth Rate Trajectories with SPSS Menu Commands  
223
 Examining Growth Using an Alternative Speciﬁ cation of the 
Time-Related Variable  
224
 Coding Time Interval Variables ( time to  timenonlin  Variations) 
with IBM SPSS Menu Commands  
225
 Estimating the Final Time-Related Model  
227
 Deﬁ ning Model 2.1 with IBM SPSS Menu Commands  
227
 Adding the Two Predictors  
229
 Deﬁ ning Model 2.2 with IBM SPSS Menu Commands  
229
 Add First Interaction to Model 2.2:  ses*timenonlin  
230
 Add Second Interaction to Model 2.2:  eﬀ ective*timenonlin  
231
 Interpreting the Output From Model 2.2  
231
 An Example Experimental Design  
233
 Summary 
238
 Chapter 6  Applications of Mixed Models for Longitudinal Data  
239
 Examining Growth in Undergraduate Graduation Rates  
239
 Research Questions  
240

Contents  xi
 Th e Data  
240
 Deﬁ ning the Model  
242
 Level 1 Model  
243
 Level 2 Model  
244
 Level 3 Model  
244
 Th e Null Model: No Predictors  
245
 Level 1 Error Structures  
246
 Deﬁ ning Model 1.1 (Null) with IBM SPSS Menu Commands  
248
 Interpreting the Output From Model 1.1 (Null)  
252
 Model 1.2: Adding Growth Rates  
252
 Level 1 Model  
253
 Coding the Time Variable  
254
 Deﬁ ning Model 1.2 with IBM SPSS Menu Commands  
256
 Interpreting the Output From Model 1.2  
259
 Model 1.3: Adding Time-Varying Covariates  
260
 Deﬁ ning Model 1.3 with IBM SPSS Menu Commands  
261
 Interpreting the Output From Model 1.3  
263
 Model 1.4: Explaining Diﬀ erences in Growth Trajectories Between Institutions  
263
 Deﬁ ning Model 1.4 with IBM SPSS Menu Commands  
264
 Add First Interaction to Model 1.4:  time1*mathselect  
266
 Add Second Interaction to Model 1.4:  time1*percentFTfaculty 
266
 Interpreting the Output From Model 1.4  
267
 Model 1.5: Adding a Model to Examine Growth Rates at Level 3  
268
 Deﬁ ning Model 1.5 with IBM SPSS Menu Commands  
269
 Add First Interaction to Model 1.5:  time1*aveFamilyshare 
270
 Add Second Interaction to Model 1.5:  time1*aveRetention  
270
 Add Th ird Interaction to Model 1.5:  time1*mathselect  
270
 Add Fourth Interaction to Model 1.5:  time1*percentFTfaculty 
271
 Interpreting the Output From Model 1.5  
271
 A Regression Discontinuity Analysis of a Math Treatment  
272
 Th e Data and Design  
273
 Assumptions of the Design  
274
 Steps in the Regression Discontinuity Analysis  
275
 Predictors in the Models  
275
 Specifying the Model  
275
 Regression Discontinuity Models to Explain Learning Diﬀ erences  
277
 Deﬁ ning Model 2.1 with IBM SPSS Menu Commands  
277
 Interpreting the Output From Model 2.1  
280
 Adding Explanatory Variables at Level 2  
282
 Deﬁ ning Model 2.2 with IBM SPSS Menu Commands  
282
 Add First Interaction to Model 2.2:  teachqual*treatment 
283
 Add Second Interaction to Model 2.2:  classcomp*treatment 
283
 Interpreting the Output From Model 2.2  
284
 Investigating a Change Due to Policy Implementation  
284
 Th e Data  
286
 Model 3.1: Establishing the Prepolicy and Policy Trends  
287
 Deﬁ ning Model 3.1 with IBM SPSS Menu Commands  
288
 Interpreting the Output From Model 3.1  
291
 Final Model with Covariates Added  
292
 Deﬁ ning Model 3.2 with IBM SPSS Menu Commands  
293

xii  Contents
 Add First Interaction to Model 3.2:  implement0*private 
294
 Add Second Interaction to Model 3.2:  implement0*prestige 
294
 Add Th ird Interaction to Model 3.2:  implement1*private 
294
 Add Fourth Interaction to Model 3.2:  implement1*prestige 
294
 Interpreting the Output From Model 3.2  
295
 Summary 
295
 Chapter 7  Multivariate Multilevel Models  
297
 Multilevel Latent-Outcome Model  
297
Th e Data 
298
 Research Questions  
299
 Deﬁ ning the Constructs  
299
 Organizing the Data Set  
300
 Specifying the Model  
301
 Model 1.1: Th e Null or “No-Predictors” Model  
302
 Deﬁ ning the Model 1.1 (Null) with IBM SPSS Menu Commands  
304
 Interpreting the Output From Model 1.1 (Null)  
309
 Conducting a Likelihood Ratio Test  
311
 Deﬁ ning Model 1.2 (Final Null Model) with IBM SPSS Menu Commands  
312
 Model 1.3: Adding Level 2 Predictors  
315
 Deﬁ ning Model 1.3 with IBM SPSS Menu Commands  
316
 Add First Interaction to Model 1.3:  stability*assessjob  
318
 Add Second Interaction to Model 1.3:  female*assessjob  
318
 Interpreting the Output From Model 1.3  
319
 Model 1.4: Adding the Organizational Predictors  
320
 Deﬁ ning Model 1.4 with IBM SPSS Menu Commands  
321
 Add First Interaction to Model 1.4:  gmorgprod*assessjob  
323
 Add Second Interaction to Model 1.4:  gmresources*assessjob 
323
 Add Th ird Interaction to Model 1.4:  stability*assessjob  
323
 Add Fourth Interaction to Model 1.4:  female*assessjob 
323
 Interpreting the Output From Model 1.4  
325
 Examining Equality Constraints  
326
 Deﬁ ning Model 1.5 with IBM SPSS Menu Commands  
326
 Investigating a Random Level 2 Slope  
328
 Deﬁ ning Models 1.6 and 1.7 with IBM SPSS Menu Commands  
329
 Model 1.6  
329
 Model 1.7  
330
 Add First Interaction to Model 1.7:  gmorprod*assessjob  
330
 Add Second Interaction to Model 1.7:  gmresources*assessjob 
331
 Add Th ird Interaction to Model 1.7:  stability*assessjob  
331
 Add Fourth Interaction to Model 1.7:  female*assessjob  
331
 Multivariate Multilevel Model for Correlated Observed Outcomes  
331
 Th e Data  
331
 Research Questions  
331
 Formulating the Basic Model  
332
 Model 2.1: Null Model (No Predictors)  
334
 Deﬁ ning Model 2.1 (Null) with IBM SPSS Menu Commands  
334
 Examining the Syntax Commands  
339
 Interpreting the Output From Model 2.1  
339
 Model 2.2: Building a Complete Model (Predictors and Cross-Level 
Interactions)  
340

Contents  xiii
 Deﬁ ning Model 2.2 with IBM SPSS Menu Commands  
340
 Add First Interaction to Model 2.2:  Index1*gmacadpress  
342
 Add Second Interaction to Model 2.2:  Index1*female  
342
 Interpreting the Output From Model 2.2  
342
 Testing the Hypotheses  
344
 Correlations Between Tests at Each Level  
344
 Deﬁ ning Model 2.3 with IBM SPSS Menu Commands  
345
 Investigating a Random Slope  
346
 Deﬁ ning a Parallel Growth Process  
346
 Th e Data  
346
 Research Questions  
347
 Preparing the Data  
347
 Model 3.1: Specifying the Time Model  
348
 Deﬁ ning Model 3.1 with IBM SPSS Menu Commands  
350
 Add First Interaction to Model 3.1:  math*orthtime 
352
 Add Second Interaction to Model 3.1:  math*orthquadtime  
352
 Interpreting the Output From Model 3.1  
354
 Model 3.2: Adding the Predictors  
355
 Deﬁ ning Model 3.2 with IBM SPSS Menu Commands  
355
 Add First Interaction to Model 3.2:  math*schcontext  
356
 Add Second Interaction to Model 3.2:  math*female  
357
 Add Th ird Interaction to Model 3.2:  math*orthtime 
357
 Add Fourth Interaction to Model 3.2:  math*orthquadtime  
357
 Add Fifth Interaction to Model 3.2:  schcontext*math*orthtime  
357
 Add Sixth Interaction to Model 3.2:  female*math*orthtime  
358
 Interpreting the Output From Model 3.2  
358
 Further Considerations  
359
 Deﬁ ning Model 3.3 with IBM SPSS Menu Commands  
360
 Summary 
361
 Chapter 8  Cross-Classiﬁ ed Multilevel Models  
363
 Students Cross-Classiﬁ ed in High Schools and Postsecondary 
Institutions  
363
 Research Questions  
364
 Th e Data  
364
 Descriptive Statistics  
366
 Deﬁ ning Models in IBM SPSS  
367
 Model 1.1: Adding a Set of Level 1 and Level 2 Predictors  
369
 Deﬁ ning Model 1.1 with IBM SPSS Menu Commands  
370
 Interpreting the Output From Model 1.1  
374
 Model 1.2: Investigating a Random Slope  
375
 Deﬁ ning Model 1.2 with IBM SPSS Menu Commands  
376
 Interpreting the Output From Model 1.2  
378
 Model 1.3: Explaining Variation Between Variables  
378
 Deﬁ ning Model 1.3 with IBM SPSS Menu Commands  
379
 Add Interaction to Model 1.3:  gmlowSES_mean*gmfemale 
380
 Interpreting the Output From Model 1.3  
382
 Developing a Cross-Classiﬁ ed Teacher Eﬀ ectiveness Model 
383
 Th e Data Structure and Model  
383
 Research Questions  
384
 Model 2.1: Intercept-Only Model (Null)  
385

xiv  Contents
 Deﬁ ning Model 2.1 (Null) with IBM SPSS Menu Commands  
386
 Interpreting Output From Model 2.1 (Null)  
390
 Model 2.2: Deﬁ ning the Cross-Classiﬁ ed Model with 
Previous Achievement  
390
 Deﬁ ning Model 2.2 with IBM SPSS Menu Commands  
391
 Interpreting the Output From Model 2.2  
393
 Model 2.3: Adding Teacher Eﬀ ectiveness and a Student Background 
Control  
394
 Deﬁ ning Model 2.3 with IBM SPSS Menu Commands  
395
 Interpreting the Output From Model 2.3  
397
 Model 2.4: Adding a School-Level Predictor and a Random Slope  
398
 Deﬁ ning Model 2.4 with IBM SPSS Menu Commands  
398
 Interpreting the Output From Model 2.4  
401
 Model 2.5: Examining Level 3 Diﬀ erences Between Institutions  
401
 Deﬁ ning Model 2.5 with IBM SPSS Menu Commands  
402
 Interpreting the Output From Model 2.5  
405
 Model 2.6: Adding a Level 3 Cross-Level Interaction  
405
 Deﬁ ning Model 2.6 with IBM SPSS Menu Commands  
406
 Add Interaction to Model 2.6:  eﬀ math2*schqual  
407
 Interpreting the Output From Model 2.6  
408
 Summary 
408
 Chapter 9 Concluding Th oughts  
409
 References 
413
 Appendices 
 Appendix A: Syntax Statements  
417
 Appendix B: Model Comparisons Across Software Applications  
435
 Appendix C: Syntax Routine to Estimate Rho From Model’s Variance 
Components  
437
 Author Index 
439
 Subject Index 
441

xv
 Preface 
 Multilevel modeling has become a mainstream data analysis tool over the past decade, emerging 
from a somewhat niche technique in the late 1980s to a technique now ﬁ guring prominently in 
a range of social and behavioral science disciplines. As the approach gained popularity over the 
1990s, specialty software programs began to appear addressing the needs of an ever-widening 
group of users. Eventually, mainstream statistics packages such as SAS, SPSS, and Stata began to 
include routines for multilevel modeling in their programs. 
 Although some devotees of the various mainstream packages began making use of this new 
multilevel-modeling functionality, progress toward carefully documenting these routines was 
slow, thereby hindering meaningful access to the average user. In the meantime, the specialty 
software packages were becoming increasingly reﬁ ned and accessible, oﬀ ering users a growing 
number of generalizations of the traditional multilevel model. In some ways, the software proved 
to be both driving and limiting the development of the ﬁ eld. 
 Th e various approaches to multilevel modeling represented in these packages have in some 
ways made it diﬃ  cult for a clear lingua franca to emerge and have long challenged those inter-
ested in teaching these techniques. In addition to the considerable expense of purchasing the 
better-documented specialty software programs, there is also the additional challenge of master-
ing the new programming logic, syntax, and ﬁ le structure unique to each program. Our second 
edition demonstrates how to use the multilevel- and longitudinal-modeling techniques available 
in IBM SPSS (Version 21). We have devoted most of our energy to providing both new and sea-
soned multilevel analysts with a set of concepts and programming skills to enable the develop-
ment, speciﬁ cation, and testing of a broad range of multilevel models using a statistical program 
that is standard in many graduate programs and organizations around the world. 
 Drawing on our own teaching and workshop experience with graduate students and research-
ers from diverse ﬁ elds (e.g., education, management, sociology, psychology, and public health) 
and our work explicating the multilevel approach (Heck & Th omas,  An Introduction to Multilevel 
Modeling Techniques , 2nd ed., 2009), we have chosen to adopt a workbook format here. Our in-
tent is to help readers set up, run, and interpret a variety of diﬀ erent types of multilevel and longi-
tudinal models using the linear mixed-eﬀ ects models (MIXED) procedure in SPSS. Th e routine 
enables users to ﬁ t linear mixed-eﬀ ects models with continuous outcomes. Readers interested 
in estimating single-level and multilevel models with categorical outcomes in IBM SPSS might 
consult our recently completed workbook on that topic (Heck, Th omas, & Tabata,  Multilevel 
Modeling of Categorical Outcomes Using IBM SPSS , 2012). In that volume, we provide a concep-
tual treatment of single-level and multilevel models for categorical outcomes (i.e., dichotomous, 
multinomial, ordinal, and count) and then walk readers in a step-by-step fashion through data 
management, model conceptualization, and model speciﬁ cation issues related to these types of 
quantitative models. 
 New to This Edition 
 In the second edition of  Multilevel and Longitudinal Modeling with IBM SPSS , we have broad-
ened our presentation to consider a number of diﬀ erent types of research designs and model 
speciﬁ cations than can be readily adapted to multilevel analyses. Th ese more complex models are 
included in Chapters 5–7, after we present our basic multilevel-modeling material in Chapters 
1–4. Highlights include the following: 
 •  A signiﬁ cant reworking of Chapter 5 to reduce coverage of repeated measures ANOVA 
and provide more coverage of deﬁ ning various types of growth trajectories using MIXED. 

xvi  Preface
Discussion and annotated illustrated instruction is provided for alternative ways of coding 
the time-related variables and specifying various covariance structures. Th e chapter presents 
the basic two-level approach for examining individual change and includes a new example 
illustrating a simple longitudinal experimental design with treatment and control groups. 
 •  In Chapter 6, extending the individual-change model to organizational settings and to other 
types of research designs, more speciﬁ cally, illustrating the applicability of MIXED for con-
ducting regression-discontinuity analyses and for specifying a quasi-experimental design to 
investigate the eﬀ ects of policy implementation over time. In this latter example, we develop a 
piecewise growth model, which provides a means of examining two or more diﬀ erent growth 
trends within one model. 
 •  In Chapter 7, introducing the multilevel multivariate approach in MIXED with expanded 
examples including deﬁ ning multiple latent constructs and parallel growth processes. 
 •  Updating our earlier coverage of missing data and the use of sample weights by oﬀ ering some 
considerations of diﬀ erent alternatives for dealing with these issues within multilevel data 
structures. As these issues can be problematic when working with multilevel models in IBM 
SPSS, we oﬀ er some guidance regarding the program’s limitations and possible options for 
analyzing multilevel data in each case. 
 Similar to the ﬁ rst edition, we continue to oﬀ er multiple examples of several types of multi-
level models with continuous outcomes, carefully showing how to set up each model and how to 
interpret the output. Most chapters feature one or more extended examples illustrating the logic 
of model development. Th ese examples show readers the context and rationale of the research 
questions and the steps around which the analyses are structured. Annotated screen shots from 
SPSS are provided to help readers navigate the software program and facilitate learning the vari-
ous techniques developed sequentially in each chapter. 
 We also provide an introduction to data management, diagnostic tools, and relevant graphics. 
Readers can work with the various examples developed in each chapter by using the correspond-
ing data and syntax ﬁ les on the Web site at http://www.routledge.com/9780415817110. 
 Th e workbook begins with an introductory chapter highlighting several relevant conceptual 
and methodological issues associated with deﬁ ning and investigating multilevel and longitudinal 
models, followed by a chapter highlighting available IBM SPSS data management techniques 
that we have found facilitate working with various combinations of multilevel, longitudinal, and 
cross-classiﬁ ed data sets. In our experience, the ﬁ rst challenge in undertaking multilevel analyses 
is properly organizing the data we wish to examine. In Chapters 3 and 4, we detail the basics of 
multilevel modeling including how to develop two- and three-level multilevel models, how to 
interpret relevant output, and how to solve common programming and modeling problems. We 
develop several basic models for investigating individual and organizational change in Chapters 5 
and 6, followed by an introduction to multilevel models with multivariate outcomes in Chapter 7. 
Chapter 8 illustrates SPSS’s facility for examining models with cross-classiﬁ ed data structures, a 
type of hierarchical structure that greatly expands the possibilities for following subjects through 
multiple organizational units or subunits over time. We conclude with thoughts about ways to 
expand on the various multilevel- and longitudinal-modeling techniques introduced and issues 
to keep in mind in conducting multilevel analyses. 
 Intended Audience 
 We hope the workbook is a useful guide to readers’ eﬀ orts to learn more about the basics of 
multilevel and longitudinal modeling and the expanded range of research problems that can be 
addressed through their application. Ideal as a supplementary text for graduate-level courses on 
multilevel, longitudinal, and latent variable modeling; multivariate statistics; and/or advanced 
quantitative techniques taught in departments of psychology, business, education, health, and 

Preface  xvii
sociology, we hope the workbook’s practical approach will also appeal to researchers in these 
ﬁ elds. We believe the workbook provides an excellent supplement to our other workbook,  Multi-
level Modeling of Categorical Outcomes Using IBM SPSS , and our earlier volume,  An Introduction to 
Multilevel Modeling Techniques  (2nd ed.); however, it can also be used with any multilevel- and/
or longitudinal-modeling book or as a stand-alone text. 
 Acknowledgments 
 We would like to thank several individuals for their input in putting this second edition together. 
We oﬀ er thanks to our reviewers who helped us sharpen our focus on categorical models: Kevin 
Grimm, University of California, Davis; George Marcoulides, University of California, River-
side; and Timothy Teo, University of Auckland. We also extend our thanks to the reviewers from 
the ﬁ rst edition: Karen A. Barrett, Colorado State University; Jason T. Newsom, Portland State 
University; Debbie L. Hahs-Vaughn, University of Central Florida; and Dick Carpenter, Uni-
versity of Colorado, Colorado Springs. We also thank Alberto Cabrera, Gamon Savatsomboon, 
Dwayne Schindler, and Hongwei Yang for helpful comments on the text and our presentation 
of multilevel models. George Marcoulides, our series editor; Debra Riegert, our senior editor; 
Jessica Lauﬀ er, our editorial assistant, as well as Sheri Sipka, our project manager, and the team 
at Apex CoVantage, have all been very supportive throughout the process. We would also like to 
thank our students and readers, who have provided value feedback on “what works” and where 
we might additionally clarify concepts presented. Although we remain responsible for any errors 
remaining in the text, the book is much stronger as a result of their support and encouragement. 
 Ronald H. Heck 
 Scott L. Th omas 
 Lynn N. Tabata 
 

              This page intentionally left blank

1
 CHAPTER 1 
 Introduction to Multilevel Modeling 
with IBM SPSS 
 S
ocial science research presents an opportunity to study phenomena that are multilevel, or hi-
erarchical, in nature. Examples might be college students nested in institutions within states 
or elementary-school-aged students nested in classrooms within schools. Attempting to under-
stand individuals’ behavior or attitudes in the absence of group contexts known to inﬂ uence those 
behaviors or attitudes can severely handicap one’s ability to explicate the underlying processes 
of interest. People within particular organizations may share certain properties including social-
ization patterns, traditions, attitudes, and goals. Th e interactions between individuals and their 
social groups within various settings therefore lend themselves to numerous investigations. 
 For studying the relationships between individuals and their social groupings, multilevel mod-
eling is an attractive approach because it allows the incorporation of substantive theory about 
individual and group processes into the clustered sampling schemes of many research studies 
(e.g., repeated measures designs or multistage stratiﬁ ed samples) or into the hierarchical data 
structures found in many existing data sets. Consider, as a diﬀ erent example, the examination of 
individual-level change within speciﬁ c social or organizational settings. Th is becomes a problem 
of understanding change over time where a series of repeated measurements (Level 1) are nested 
within individuals (Level 2) who may be associated with particular groups (Level 3) that are also 
undergoing change over time. We could extend the analysis of such change trajectories to include 
situations where individual change processes accelerate or decelerate after the introduction of 
group-level treatments or where there are parallel change processes occurring (e.g., where people 
are changing in two or more domains simultaneously). 
 Multilevel modeling is fast becoming the standard analytic approach for examining data in 
many ﬁ elds (e.g., sociology, education, psychology, and management) due to its applicability to a 
broad range of research designs and data structures (e.g., nested, cross-classiﬁ ed, cross- sectional, 
and longitudinal data). It is referred to by a variety of diﬀ erent names including random- 
coeﬃ  cient models, mixed-eﬀ ect models, multilevel regression models, hierarchical linear models, 
and multilevel covariance structure (or structural equation) models. Th is diversity of names is an 
artifact of the statistical theory underlying multilevel models, theory that has developed out of 
methodological work in several diﬀ erent ﬁ elds, and this has led to diﬀ erences in the manner in 
which the methods (and software) are used in various ﬁ elds. At the core of these types of proce-
dures, however, is an interest in the decomposition of variance in outcomes across several hierar-
chical levels and the explanation of this variance with variables speciﬁ ed at corresponding levels. 
 Despite a growing recognition of the promise and importance of this approach, multilevel-
modeling procedures have not yet been fully integrated into research and statistics texts used in 
typical ﬁ rst- or second-year graduate courses. Two major obstacles are responsible for this reality. 
First, no standard language has emerged from this work. Second, until recently, the speciﬁ cation 
of multilevel models has generally required special software programs. With respect to the ﬁ rst 
www.allitebooks.com

2  Introduction to Multilevel Modeling with IBM SPSS
obstacle, despite the varied ways in which multilevel models are conceptualized, notated, and 
speciﬁ ed, they focus on the relationships between variables within and across multiple levels of 
a data hierarchy. Such potentially complex sets of empirical relationships must be explained by 
multilevel theories, a conceptual limitation that has not kept equal pace with advances in quanti-
tative modeling incorporated into various computer software packages (Hox, 2002). Th eories for 
dealing with the complexity of the multilevel features of organizations, for example, have been 
somewhat limited historically in terms of deﬁ ning direct, mediating, or moderating relationships 
both within and between organizational layers (MacKinnon, 2008). 
 Available software, the second obstacle, has been largely an artiﬁ cial barrier resulting from 
the increasing use of multilevel modeling in many areas of the social, behavioral, and health sci-
ences. Simply put, our interpretation is that there have been several camps of scholars who have 
popularized these methods through the development of their own software and approach. Th ree 
of the best known of these packages are HLM (Raudenbush, Bryk, Cheong, & Congdon, 2004), 
MLwiN (Goldstein, 2003), and Mplus (Muthén & Muthén, 1998–2006). Although the main-
stream emergence and acceptance of these methods is in large part due to the work and activity of 
these researchers, other more widely used statistical programs have implemented routines over 
the years that enable the development and speciﬁ cation of a wide variety of multilevel models. 
IBM SPSS, SAS, and Stata all have such routines (see Albright & Marinova, 2010, for an over-
view of each package’s oﬀ ering). 
 Despite the widespread availability of these packages, there is little available to help the re-
searcher align the concepts and methods popularized through the specialty programs with the 
terminology and conceptualization used within these mainstream statistical packages. Important 
exceptions to this can be found in Rabe-Hesketh and Skondral’s (2008)  Multilevel and Longi-
tudinal Modeling Using Stata  (2nd ed.) and in Singer and Willett’s (2003)  Applied Longitudinal 
Data Analysis , which provides detailed setups for examples in their book using procedures in 
these widely available statistical packages. Also noteworthy are the resources available through 
the University of California at Los Angeles’ Academic Technology Services Statistical Comput-
ing Web site (http://www.ats.ucla.edu/stat/) that have used a wide variety of statistical pack-
ages and developed annotated output for a number of multilevel texts. Few resources, however, 
provide a start-to-ﬁ nish overview of how to actually carry out a multilevel analysis. Th is is the 
relative void that we hope to address. 
 Our Intent 
 IBM SPSS MIXED is a very ﬂ exible modeling routine that can be used to estimate a wide 
variety of multilevel, multilevel cross-classiﬁ ed, and multilevel repeated measures designs with 
continuous and categorical outcomes. Th is makes the program quite useful in estimating a wide 
variety of models with single or multivariate outcomes from numerous sampling distributions 
(e.g., normal, binomial, multinomial, and Poisson). Th e term  mixed  model implies the existence 
of data in which individual observations on an outcome are distributed (or vary at random) across 
identiﬁ able groups. Th e variance of the random eﬀ ect indicates its distribution in the population 
and therefore describes the degree of heterogeneity present (Hedeker, 2005). 
 Our intent is to help you conceptualize, set up, estimate, and interpret the output from a vari-
ety of diﬀ erent types of multilevel and longitudinal models with continuous outcomes using the 
linear mixed-eﬀ ects (MIXED) procedure available in IBM SPSS. In this second edition, we have 
also attempted to broaden our presentation to consider a number of diﬀ erent types of research 
designs than can be readily adapted to multilevel analyses. Some of these include a typical treat-
ment intervention, an example of a regression-discontinuity design, a parallel growth model, and 
a piecewise growth model. Th ese more complex models are included in Chapters 5–7, after we 
present our basic multilevel-modeling material in Chapters 1–4. We assume readers have had at 
least an introductory statistics course (e.g., descriptive statistics, analysis of variance, and multiple 

Introduction to Multilevel Modeling with IBM SPSS  3
regression) prior to using this workbook. It is intended for use in a second course (e.g., multi-
variate statistics) or a third course (e.g., introduction to multilevel and longitudinal models). In 
our own series of courses, we have used the materials presented in this workbook in multivariate 
statistics courses (i.e., after presenting multivariate analysis of variance [MANOVA], exploratory 
factor analysis, and repeated measures analyses) and in beginning multilevel-modeling courses. 
 Mixed, or multilevel, models are diﬀ erentiated from more familiar linear models (e.g., 
ANOVA and multiple regression) through their capability of examining correlated data and 
unequal variances. Such data are commonly encountered where subjects are nested in groups 
within a data hierarchy or as repeated measures nested within individuals. Where designs are 
unbalanced (i.e., having diﬀ erent numbers of participants within groups), estimation procedures 
available in multilevel-modeling routines yield asymptotically eﬃ  cient estimates of a model’s 
structural parameters and covariance components. We run the examples in this workbook using 
IBM SPSS Version 21 and Windows 7 Professional, both in the 64-bit version. Users running 
the models with earlier versions of MIXED or with IBM SPSS/SPSS for Mac or Windows 
(e.g., XP and Vista) may notice slight diﬀ erences between their screens and our text screen shots, 
as well as slight diﬀ erences in output appearance (and perhaps even estimates). 
 For our second edition, there are a few updates regarding multilevel-modeling procedures 
available in SPSS to note. Most important, at the time we ﬁ nished our ﬁ rst edition (April 2010), 
a major limitation of the MIXED routine was that dependent variables had to be continuous. 
Th is precluded many situations where researchers might be interested in applying multilevel ana-
lytic procedures to various types of categorical (e.g., dichotomous, ordinal, and count) outcomes. 
Since then, the MIXED routine has been expanded to include procedures for modeling several 
diﬀ erent types of multilevel models with categorical outcomes (which are referred to as general-
ized linear mixed models). Th e routine is referred to as GENLINMIXED in IBM SPSS termi-
nology. Th is capability begins with Version 19, which was introduced in Fall 2010 and is reﬁ ned 
in Versions 20 and 21 (introduced in Fall 2012). Th e inclusion of this new categorical multilevel-
modeling capability in MIXED prompted us to develop a companion workbook focused on es-
timating single-level and multilevel models with categorical outcomes (Heck, Th omas, & Tabata, 
2012). We refer readers to that volume for an applied treatment of single-level and multilevel 
models with categorical outcomes using IBM SPSS. 
 A second issue concerns the SPSS program’s features to deal with missing data. For examin-
ing models with missing data, there are several diﬀ erent approaches that can be used to estimate 
model parameters in the presence of missing data. Some of the traditional approaches include 
listwise deletion (i.e., eliminating any case with at least one missing value), pairwise deletion 
(e.g., eliminating pairs of cases when missing data are present, as in calculating a correlation), 
mean substitution, and various regression-based approaches. Th ese approaches will lead to biased 
parameter estimation under most conditions that analysts encounter with real data. Two newer 
approaches are full information maximum likelihood (FIML) estimation with the partially com-
plete data included in the analysis and multiple imputation (MI) of plausible values (Peugh & 
Enders, 2004). FIML estimation with missing data present is not presently available in IBM 
SPSS for typical multilevel models where there is a single data row for each subject. An indi-
vidual with any missing data will be dropped from the analysis. For situations where the data are 
vertically arranged (i.e., as in a growth model), however, the information on the  Y outcome will 
only be dropped for that occasion or occasions where the data are missing. 
 IBM SPSS has a missing data module that can be used to impute values for missing data; 
however, users should check whether or not it is included in the particular SPSS package they 
purchase or have available to use by licensing agreement. In some cases, the missing data mod-
ule may have to be purchased as an add-on program. It is important to note, however, that MI 
routines are typically designed for single-level analyses of data with missing observations. It is 
important for the analyst to be aware of how missing data may aﬀ ect the analysis. Th e MIXED 
routine in SPSS does a good job of accounting for the clustering eﬀ ects present in the data (i.e., 

4  Introduction to Multilevel Modeling with IBM SPSS
where individuals within a unit share some common characteristics) but does not necessarily ad-
dress the patterns of missing data that may be present in various types of hierarchical data struc-
tures. Given these concerns, we suggest that users consider carefully the nature of their missing 
data and devise an appropriate strategy for dealing with data shortcomings. We spend some time 
later in this chapter discussing how to develop a strategy to deal with missing data. 
 A ﬁ nal issue concerns the program’s limited capability to incorporate sample weights for 
multilevel data. Currently, the basic IBM SPSS software does not support techniques for the 
adjustment of design eﬀ ects, although there is an add-on module that can be used for conduct-
ing  single-level  analyses of continuous and (some) categorical outcomes from complex survey 
designs. As Kish (1987) notes, traditional methods for statistical analysis are based on simple 
random sampling, which assumes independence of observations. Th is assumption seldom holds 
with most data sets that are encountered. Sample weights used in most secondary data sets have 
been devised to deal with more complex sampling designs than simple random sampling, but 
they treat the clustering of individuals within higher level units as “noise” to be ﬁ ltered out, rather 
than as the focus of the analysis. For example, two-stage sampling involves ﬁ rst selecting a ran-
dom sample of units (e.g., universities) from a population of universities having the individuals 
one is interested in studying. At the second step, a random sample of individuals (e.g., students) 
is drawn from within the sampled institutions. Th e unit selection process will inﬂ uence the char-
acteristics of the student sample. 
 At present, sample weights at two (or more) levels cannot be incorporated into multilevel 
analyses using MIXED. In the last section of the chapter, we update our earlier coverage of 
sample weights, oﬀ ering some considerations of diﬀ erent weighting schemes that help guide the 
use of sample weights at diﬀ erent levels in the analysis. Th is is an area in which we feel more at-
tention needs to be focused in subsequent versions of IBM SPSS and other software programs 
designed to analyze multilevel data structures. Population estimates can be aﬀ ected by the vari-
ous sample-weighting options in each software program and their underlying assumptions. We 
attempt to oﬀ er some clear guidance in the interim. 
 Overview of Topics 
 In this chapter, we provide a number of conceptual and methodological issues associated with 
multilevel modeling, which foreshadows our further development of these issues in subse-
quent chapters. In Chapter 2, we present several issues to deal with in structuring and working 
with various types of multilevel, longitudinal, and cross-classiﬁ ed data sets. Chapter 3 develops 
the basics of two-level multilevel regression models. Chapter 4 extends this general two-level 
model to three-level, cross-sectional models. Chapter 5 presents the basic two-level approach 
for examining individual change. In this edition, we have also included a new example illus-
trating a simple experimental design with treatment and control groups. Chapter 6 extends 
the individual-change model to organizational settings and to other types of research designs, 
more speciﬁ cally, its applicability for conducting regression-discontinuity analyses and piece-
wise growth models. Chapter 7 introduces the multilevel multivariate approach in IBM SPSS. 
In this second edition, we have expanded the examples presented to include multiple latent 
outcome variables and parallel growth models. Chapter 8 presents examples of two-level and a 
three-level cross-classiﬁ ed data structures. Finally, Chapter 9 provides a short synthesis of our 
presentation. 
 Analysis of Multilevel Data Structures 
 We begin with the principle that theoretical frameworks are essential guides to empirical inves-
tigation and suggest that quantitative analysis concerns the translation (or operationalization) 
of abstract theories into concrete models. Our statistical models represent a set of proposed 

Introduction to Multilevel Modeling with IBM SPSS  5
theoretical relations that are thought to exist in a population—a set of theoretical relationships 
that account for relationships actually observed in the sample data from that population (Singer & 
Willett, 2003). Decisions about analysis therefore are located within the researcher’s method-
ological framework that begins with research questions, designs, data structures, and methods of 
analysis (Raudenbush, 1988). Th ese decisions about how to conceptualize and conduct a study 
are critical to the credibility of one’s results and the study’s overall contribution to the relevant 
knowledge base. 
 Clearly there is also a place for less theoretically bound exploratory work, and we believe that 
these models can provide a powerful platform for this purpose. Th e multilevel framework opens 
up a range of new possibilities for exploratory analyses. With opportunities to examine relation-
ships at multiple levels of analysis, to specify cross-level relationships between higher and lower 
levels of a hierarchical data structure, to include multiple group membership, and to incorporate 
a time dimension, the potential for exploratory work is great. Th at opportunity also presents a 
risk, however. With multiple levels within which one could test for speciﬁ c relationships and 
a wide range of potential interactions, there is much to explore, and the models can easily bog 
down. Th is can yield questionable and perhaps even nonsensical results. Multilevel models are 
very data demanding. Adequate sample sizes are needed at each level to ensure suﬃ  cient power 
to detect eﬀ ects, and, as a result, the models can very quickly become quite complicated, diﬃ  cult 
to estimate, and even more diﬃ  cult to interpret. Even in a simple two-level model, one might 
allow the intercept and multiple slopes to vary across groups, while sets of variables from the 
higher level are used to explain the variances in this set of intercepts and slopes. Correct model 
speciﬁ cation in a single-level framework is one thing; correct speciﬁ cation with a multilevel 
context is quite another (Goldstein, 1995). It is for this reason that we place an emphasis on the 
importance of sound conceptual frameworks to guide multilevel model development, even if it 
is largely exploratory in nature. 
 One’s choice of analytic strategy and model speciﬁ cation is therefore critical to whether the 
research questions can be appropriately answered. More complete modeling formulations may 
suggest inferences based on relationships in the sample data that are not revealed in more sim-
plistic models. At the same time, however, better modeling formulations may lead to fewer ﬁ nd-
ings of substance than have often been claimed in studies that employ more simplistic analytic 
methods (Pedhazur & Schmelkin, 1991). We feel it is important to draw a clear distinction 
between concerns over model speciﬁ cation limited to the exclusion or inclusion of theoretically 
relevant variables and model speciﬁ cation related to the mathematical explication of the relation-
ships among these variables. Although theory should guide both considerations, the former con-
cern deals with the availability of the relevant variables in the data set, while the latter deals with 
the structure of the data itself and the choice of modeling approach used to exploit theoretically 
important relationships presumed to exist in the population (Heck & Th omas, 2009). Th is is im-
portant to keep in mind because compromise is often necessary, since the complexity of proposed 
theoretical models (e.g., multiple levels and multiple random intercepts and slopes) can at times 
overwhelm the capability of the statistical software to estimate the model. We recall one example 
in Chapter 7 where simply changing the structure of the covariance matrix of random eﬀ ects in 
a three-level model from a more simpliﬁ ed structure to one that might be considered as optimal 
resulted in lengthening the time it took to estimate the model by approximately two hours. At 
the end of that, the model estimation procedure failed to reach a viable solution that converged. 
In short, this is a case where our data and model speciﬁ cation failed to meet the demands of the 
propositions we attempted to test. 
 Besides the choices we make about methods of analysis, our inferences are also aﬀ ected in 
practice by potential biases in our sample (e.g., size, sampling variation, and missing data). An-
other of our guiding principles is that when making decisions about analytic methods, the re-
sponsible researcher should consider approaches that are likely to take full advantage of the 
features of particular data structures and the goals of the overall research. 

6  Introduction to Multilevel Modeling with IBM SPSS
 Multilevel data sets are distinguished from single-level data sets by the nesting of individual 
observations within higher level groups. In single-level data sets, participants are typically selected 
through simple random sampling. Each individual is assumed to have an equal chance of selec-
tion, and, at least in theory, the participants do not belong to any groups that might inﬂ uence their 
responses. For example, individuals can be diﬀ erentiated by variables such as gender, religious 
aﬃ  liation, and participation in a treatment or control group. However, in practice, in single-level 
analyses individual variation within and between a large number of these types of subgroups 
cannot be considered simultaneously—for example, cell means consisting of diﬀ erences due to 
gender, religious aﬃ  liation, an intervention, their various interactions, and perhaps even a number 
of separate workplace settings. Th e number of groups created will quickly overwhelm the capacity 
of the analytic technique. In contrast, in multilevel (or nested) data sets, the groupings of partici-
pants may result from the overall sampling scheme used to select participants in a large study (e.g., 
neighborhoods may be selected ﬁ rst, and then individuals are selected second), or the social group-
ing of participants (i.e., their degree of common experiences due to closeness in space or time) is 
the primary focus of the theory and conceptual model proposed in the study (Kreft & de Leeuw, 
1998). For example, we might be interested in whether diﬀ erences in organizations’ productivity 
can be explained by their employee and management value and decision-making structures. 
 We refer to the lowest level of a data hierarchy (Level 1) as the  microlevel , with all successive 
levels in the data structure referred to as  macrolevels . Th e relationships among variables observed 
for the microlevel often refer to individuals within a number of macrolevel groups or contexts 
(Kreft & de Leeuw, 1998). Within a contextual model, therefore, one could envision successive 
levels extending well beyond an organization (e.g., region, state, nation, etc.). Each of these suc-
cessive groupings might exert eﬀ ects on organizational productivity. Organizational outcomes 
may be inﬂ uenced by combinations of variables related to the backgrounds and attitudes of indi-
viduals (demographics, experience, education, work-related skills, attitudes, etc.), the processes of 
organizational work (e.g., leadership, decision making, professional development, organizational 
values, resource allocation, etc.), the context of the organization, or the cross-level interactions 
of these variables within the structure of the organization (e.g., size, management arrangements 
within its clustered groupings, etc.). We summarize some of these possible relationships within 
and between levels in  Figure 1.1 . 
 FIGURE 1.1  Deﬁ ning variables in a multilevel model. 

Introduction to Multilevel Modeling with IBM SPSS  7
 In the past, analytic strategies for dealing with the complexity of the multilevel, or contex-
tual, features of organizations were somewhat limited. Researchers did not always consider the 
implications of the assumptions they make about measuring variables at their natural levels, or 
about moving them from one level to another level through aggregation or disaggregation. Th ese 
 possible choices are summarized in  Figure 1.1  with two-headed arrows.   Aggregation , for example, 
meant that the productivity level of individuals within departments or organizations would be 
combined at a higher level of the data hierarchy (e.g., the organizational unit). Th e comparison 
is then made between organizations’ mean productivity outcomes. Failing to acknowledge the 
potential variability present among individuals within groups, however, can bias estimates of pa-
rameters between such units, a situation Robinson (1950) called the ecological fallacy. Averaging 
estimates over groups also drastically reduces the statistical power to detect proposed relation-
ships by ignoring the number of individuals in a study (Tabachnick, 2008). 
 In contrast,  disaggregation refers to moving a variable conceptualized at a higher level to a 
lower level of the data hierarchy. For example, in a diﬀ erent analysis we might have productivity 
measured at the organizational level but also have information about employee job satisfaction, 
motivation, and intention to leave the workplace. In this type of analysis, we might intend to 
analyze the data at the individual-employee level to see whether employees’ perceptions inﬂ uence 
their productivity. If we assign all employees the same value on the productivity outcome (and 
possibly other organizational variables), we attribute properties of the organization to individu-
als. Th is can also bias the estimation of model parameters since we are basing analyses of some of 
the variables on the number of individuals in the study instead of the number of groups. 
 Examples such as these suggest that analyses conducted at the microlevel or macrolevels 
may produce diﬀ erent results. Treating individuals as if they were independent of their orga-
nizational groupings ignores the complexity inherent in the data and introduces a potentially 
important source of bias into the analysis. Th is is because individuals in a group or context tend 
to be more similar on many important variables (e.g., attitudes, socialization processes, percep-
tions about the workplace, etc.) compared with individuals in other contexts. With hierarchi-
cal data, therefore, a more complex error structure must be added to the model to account for 
the dependence among observations within groups. Such dependencies violate key assump-
tions of single-level multiple regression models (e.g., simple random sampling that provides 
independent errors) and will lead to underestimated variances and standard errors, which, in 
turn, may lead to erroneous conclusions (Th omas & Heck, 2001). As we have noted, eliminat-
ing within-group variability also biases relationships observed between groups. One important 
contribution of multilevel modeling is that it allows the researcher to avoid the aggregation or 
disaggregation problem. 
 Developing a multilevel conceptual framework of relationships to guide the analysis also helps 
the researcher avoid another potential source of bias in the analysis—that of ignoring the dif-
ferent levels of the explanatory (independent) variables. As the reader may surmise, it is impor-
tant to develop a conceptual scheme to place the explanatory variables hypothesized to aﬀ ect 
individuals and other types of processes in their proper hierarchical locations (Hox, 2002). In a 
single-level model, we are faced with the problem of whether the outcome variable (or other pre-
dictors) should be deﬁ ned as aggregate, or collective, measures or as individual (or disaggregated) 
measures. In a multilevel formulation, analysts must consider the implications of how they deﬁ ne 
variables within the proposed model before actually testing the model. Th is preliminary process 
of building a model helps clarify the organizational, or contextual, level to which they rightly 
belong. Examining variability in an outcome present at each level of the data hierarchy implies 
diﬀ erent types of research questions that can be asked, as summarized in  Figure 1.1 . Th ese po-
tential relationships are represented by horizontal arrows in the ﬁ gure. A second contribution of 
multilevel modeling, therefore, is that through investigating the variation in outcomes that exists 
at diﬀ erent levels of the data hierarchy we can develop more reﬁ ned conceptual models about 
how explanatory variables at each level contribute to variation in outcomes. 

8  Introduction to Multilevel Modeling with IBM SPSS
 Finally, multilevel procedures also facilitate the investigation of variability in regression coef-
ﬁ cients (slopes) across higher order units in the study. Cross-level interaction involves the eﬀ ects 
of explanatory variables at a higher level of the data hierarchy on a relationship at a lower level 
(e.g., employee motivation and productivity). Cross-level interactions are shown in  Figure 1.1  
with arrows that extend from the macrolevels toward the microlevel. To illustrate, we might 
ask whether the relative degree of departmental teamwork moderates the relationship between 
employee motivation and productivity. In the past, mapping these sorts of relations has often 
been problematic, frequently focusing on single, discrete elements while ignoring the multi-
dimensional and interrelated aspects of broader sets of organizational processes that inﬂ uence 
subgroups or individuals within organizations. 
 Partitioning Variation in an Outcome 
 Generally, the ﬁ rst step in a multilevel analysis is partitioning the variance (referred to as   2 ) in 
an outcome variable into its within- and between-group components. If it turns out that there 
is little or no variation (perhaps less than 5%) in outcomes between groups, there would be no 
compelling need for conducting a multilevel analysis. In this case, a simple ordinary least squares 
(OLS) regression analysis conducted at the microlevel (individual) would be adequate. Th e pro-
portion of variance that exists between groups compared to the total variation is described by an 
intraclass correlation (  ), or the proportion of variance explained by the grouping structure in the 
population. It is deﬁ ned as 
 
        
2
 b  /(   
2
 b     
2
 w ), 
(1.1) 
 where   2  b  is the between-group variance and   2  w  is the within-group variance. Th e intraclass 
correlation (also referred to as the ICC) can also be interpreted as the expected correlation be-
tween any two randomly chosen individuals in the same group (Hox, 2002). If it is substantial, 
therefore, it suggests that the groups are relatively homogeneous and likely quite diﬀ erent from 
each other. 
 Th ere are at least two ways to think about the relative homogeneity of groups. Th e ﬁ rst is in 
terms of the potential remedies required for conducting a conventional single-level analysis of 
data that are hierarchically diﬀ erentiated. A common example is the multistage type of sampling 
strategy used in large-scale surveys (where higher units may be sampled ﬁ rst and then individuals 
within these units). Th e focus in this type of analysis to remedy possible bias due to multistage 
sampling is on statistical adjustments to yield unbiased estimates of variances and standard er-
rors. Acknowledging the ICC is important because it changes the error variance in single-level 
regression analyses. When clusters and nontrivial ICCs are present, the OLS regression assump-
tion of independent errors resulting from simple random sampling will likely be violated. Th is 
problem results in a downward bias in the estimation of standard errors (i.e., the errors calculated 
will be too small). 
 Let’s develop this important point. Because statistical tests of model parameters are based on 
the ratio of an estimate to its standard error, the underestimation of standard errors will often 
lead to more ﬁ ndings of signiﬁ cance than would be observed if clustering were considered. Sup-
pose in a single-level analysis we observe that the estimate of the eﬀ ect of gender on achieve-
ment is 4.0 points, and the standard error is estimated as 2.0. Th is would result in a  t -ratio of 2.0 
(i.e., the ratio of the estimate to its standard error). At a commonly adopted signiﬁ cance level of 
 p  .05 and a sample size of 500 individuals, the required  t -ratio would be 2.0. Suppose the same 
analysis conducted as a two-level analysis (e.g., individuals clustered in schools) results in an 
estimated standard error of 2.5. Now when we calculate the  t -ratio (4.0/2.5), the result would be 
1.6, which would not be signiﬁ cant at  p  .05. Single-level analytic approaches, such as multiple 

Introduction to Multilevel Modeling with IBM SPSS  9
regression, ignore the clustered nature of individuals within higher level groupings; therefore, 
in the presence of similarities among individuals within groups, estimated parameters may be 
biased. Although there are various ways to adjust the estimates produced by these analytic tech-
niques, these remedies do not facilitate the investigation of models that specify presumed eﬀ ects 
at diﬀ erent levels of the data hierarchy. 
 To address this shortcoming, the second way to think about group-level homogeneity in hi-
erarchical data is in terms of the opportunities it presents to specify conceptual models designed 
to operationalize organizational processes at more than a single level. After determining that an 
outcome varies across units, the analyst can investigate how various within-group and between-
group variables explain variance in the outcome at each successive level. As readers may notice in 
 Figure 1.1 , with horizontal arrows we can model variability in intercepts; that is, the predictors 
at each level will account for variability in the outcome at that level. Moreover, the concept of in-
vestigating random slope coeﬃ  cients across groups is also central to multilevel modeling. As we 
noted, the cross-level arrows in  Figure 1.1  suggest how higher level explanatory variables might 
explain random variability in slopes at that speciﬁ c level. 
 Multilevel modeling, then, also contributes to our understanding of hierarchical data struc-
tures by allowing the analyst to estimate structural and variance/covariance parameters (e.g., 
residual variance in intercepts or slopes at Level 2 and covariance between intercepts and slopes 
at Level 2) more eﬃ  ciently and accurately. In a multilevel model, we typically focus on output 
concerning two types of model parameters. Structural parameters are referred to as the model’s 
 ﬁ xed eﬀ ects . Th ese include intercept coeﬃ  cients (e.g., a group mean) or slope coeﬃ  cients (e.g., the 
relationship between gender and achievement). Th e complete set of variances and covariances in 
model parameters is referred to as its  covariance components  (Singer & Willett, 2003). Speciﬁ c 
parameters can be designated as  randomly varying , which means that the sizes of the estimates 
are allowed to vary across groups. Investigating these randomly varying intercepts and slopes is at 
the center of our general multilevel-modeling strategy presented in subsequent chapters. 
 Developing a General Multilevel-Modeling Strategy 
 In this workbook, we apply a general strategy for examining multilevel models (e.g., Bryk & 
Raudenbush, 1992; Heck & Th omas, 2009; Hox, 2010; Raudenbush & Bryk, 2002). Multilevel 
models are useful and necessary only to the extent that the data being analyzed provide suﬃ  cient 
variation at each level. “Suﬃ  ciency” of variation is relative and depends as much on theoreti-
cal concerns as it does on the structure and quality of data. Multilevel modeling can be used to 
specify a hierarchical system of regression equations that takes advantage of the clustered data 
structure (Heck & Th omas, 2009). Multilevel models can be formulated in two ways: (a) by pre-
senting separate equations for each of the levels in a data hierarchy (e.g., employees, workgroups, 
departments, divisions, corporations, etc.) or (b) by laying out the separate equations and then 
combining all equations through substitution into a single-model equation. 
 For readers familiar with HLM (Raudenbush et al., 2004), the software uses separate equa-
tions speciﬁ ed at each level to build the multilevel model. Th is approach results in the need to 
generate separate data sets at each level ﬁ rst (e.g., individuals, classrooms, schools, etc.), which 
then are “combined” within the software program to make the ﬁ nal data ﬁ le (called a multivari-
ate data matrix or .mdm ﬁ le). Th e user can neither see nor edit the case-speciﬁ c contents of this 
ﬁ nal data set. Most other software packages, such as IBM SPSS MIXED, use single-equation 
representation (through algebraic substitution), so all analyses can be conducted from within one 
data set. As we will show in Chapter 2, however, we sometimes need to reorganize the single data 
set for particular types of analyses (e.g., longitudinal and multivariate analyses). 
 As Hox (2002) describes, both ways of specifying multilevel models have advantages and 
disadvantages. Th e separate-equation approach such as that used in HLM has the advantage of 
being clear about how the proposed model is built up from Level 1 through successive levels. 

10  Introduction to Multilevel Modeling with IBM SPSS
Th e disadvantage of this approach is that it hides from view the fact that modeling a cross-level 
interaction on a Level 1 regression slope results in adding an interaction to the overall model 
(Hox, 2002). Th e single-equation approach makes the existence of interactions obvious, but it is 
a little more diﬃ  cult to see the sets of predictors that may be explaining each of the randomly 
varying slopes. We will walk readers through this process for one example in the following sec-
tion. In successive chapters, however, we primarily adopt the approach of laying out separate 
equations by level for clarity in building models and often leave it to users to recognize that the 
sets of equations are reduced to single-model equations in MIXED when substitution is applied. 
 Illustrating the Steps in Investigating a Proposed Model 
 We have found that in many instances multilevel investigations unfold as a series of analytic 
steps. Of course, there may be times when the analyst might change the speciﬁ c steps, but, in 
general, we have found that this overall model development strategy works pretty well. In  Figure 
1.2 , we provide an illustration of what a simple two-level model to explore a random intercept 
describing productivity and a random slope describing the eﬀ ect of employee attitudes on their 
productivity might look like. We use this model to provide a conceptual overview of the model-
ing strategy we adopt in successive chapters. 
 In a single-level model we could focus on the overall relationship between employee attitudes 
and their productivity. In the traditional OLS model, we would get a slope expressing the re-
lationship between the two variables and an intercept representing some adjusted value of the 
outcome. Th is would be ﬁ ne if our interests were limited to an overall relationship. But if we were 
interested in understanding how employee groupings (e.g., workgroups or departments) might 
moderate that relationship (or even controlling for such a possibility), we would need to incorpo-
rate information about the organization or grouping of employees in our sample. Once we shift 
into thinking about such multilevel relationships, where employees are now nested within groups 
of some kind, a range of new analytic possibilities emerges. 
 Within groups we might deﬁ ne a randomly varying intercept (productivity) and randomly 
varying slope (i.e., the eﬀ ect of employee attitudes on productivity). Th e random slope is shown 
in the ﬁ gure with a ﬁ lled dot on the line representing the relationship between attitudes and 
productivity. Th e Greek symbol beta (  ), which is often used to describe a slope or regression 
parameter at Level 1, is above the line. Between groups, we might propose that diﬀ erences in 
resource allocation aﬀ ect levels of organizational productivity. Additionally, we might propose 
that these variables also moderate the size of the eﬀ ect of employee attitudes on productivity. 
 FIGURE 1.2  Proposed two-level model examining a random intercept and slope. 

Introduction to Multilevel Modeling with IBM SPSS  11
Th is type of eﬀ ect, which is referred to as a cross-level interaction, implies that the magnitude 
of a relationship observed within groups is dependent on contextual or organizational features 
deﬁ ned by higher level units. We therefore formulate a Level 2 model to explain variability in 
intercepts and variability in slopes (shown as ovals representing  unknowns , or latent variables, 
in  Figure 1.2 ) across organizations. 
 1. One-Way ANOVA (No Predictors) Model 
 A good ﬁ rst step is to examine the extent to which variation in a Level 1 outcome exists  within 
Level 2 units relative to its variation  between  Level 2 units. In our example, we want to know if 
there exists signiﬁ cant variance in productivity across groups—something that would be invisible 
to us in a single-level model. Little variability within the Level 2 units suggests greater homo-
geneity among all Level 1 observations than exists among Level 1 observations from diﬀ erent 
Level 2 groups—that is, such evidence suggests that the nesting of Level 1 observations is not 
systematically associated with levels of an outcome. Th e partitioning of outcome variance into 
Level 1 and Level 2 components without other predictors in the model allows the researcher 
to test the validity of this assumption and provides important information about the sources of 
variation in the outcome variable, productivity in our example here. 
 Notice that in Equation 1.2, we add a subscript for individuals ( i ) and for organizations (   j ). 
Th e null model for individual  i in organization  j can be represented as: 
 
  Y ij     0  j    ij , 
(1.2) 
 where   0 j  is the mean of productivity (intercept) for the  j th group, and the Greek lowercase letter 
epsilon (  ij  ) represents the errors in estimating individual productivity within groups. In a two-
level model, Level 1 ﬁ xed eﬀ ects are typically expressed as unstandardized   coeﬃ  cients.  Unstan-
dardized  means the coeﬃ  cients are in their original metrics. Th e subscript  j indicates that the 
intercept represents the mean outcome for groups. Individual-level error (referred to as residual 
in the MIXED output) is also considered a random component. 
 Between groups, variation in intercepts (  0 j  ) can be represented as 
 
   0 j     00    u 0  j . 
(1.3) 
 Level 2 ﬁ xed-eﬀ ect coeﬃ  cients (which are also unstandardized) are generally expressed as the 
Greek lowercase letter gamma (  ). Variation in estimating organizational intercepts is repre-
sented as  u 0 j  , which is considered a Level 2 random eﬀ ect. Th rough substituting Equation 1.3 
into Equation 1.2, we arrive at the single-equation model, which can be written as 
 
  Y ij    00    u 0  j    ij  . 
(1.4) 
 Th e null model therefore provides an estimated mean productivity score for all organizations. 
It also provides a partitioning of the variance between Level 1 (  ij  ) and Level 2 ( u 0 j  ). Altogether, 
Equation 1.4 suggests that there are three parameters to estimate: the intercept; the between-
organization error, or deviation, from the average intercept ( u 0 j  ); and the individual-level residual, 
or variation in individual scores within organizations (  ij  ). 
 We can conﬁ rm this speciﬁ cation by examining the output from the intercept-only model in 
IBM SPSS. Th e average intercept is considered a ﬁ xed eﬀ ect, while the between-group variation 
www.allitebooks.com

12  Introduction to Multilevel Modeling with IBM SPSS
in average intercepts is referred to as a random eﬀ ect. Th e Level 1, or individual-level, error is 
referred to as residual in the output. We note that the “Number of Levels” column in  Table 1.1  
refers to whether the predictors are deﬁ ned as continuous (number of levels  1) or categorical. 
If a predictor such as gender is deﬁ ned as categorical (i.e., as a  factor ) in building the model, the 
number of levels will be two, which refers to the categories of female and male. If it is deﬁ ned as a 
 covariate (i.e., because it is a dichotomous variable), as in a typical multiple regression model, the 
number of levels in the table will be one instead of two. Of course, predictors with three or more 
categories must be deﬁ ned as factors (or else dummy coded). Information about the model’s 
parameters in the model dimension table is also useful in examining the baseline (no predictors) 
model with three estimated parameters against subsequent models with more estimated param-
eters. It is good practice to always check this output to ensure that the model estimated was the 
one that the analyst intended. 
 2. Analyze a Level 1 Model with Fixed Predictors 
 Assuming that suﬃ  cient levels of variance in  Y exist at each level, we can investigate a model with 
only ﬁ xed predictors at Level 1. Level 1 predictors are often referred to as  X . For each individual  i 
in organization  j , a proposed model similar to Equation 1.1 (summarizing the eﬀ ect of employee 
attitudes on productivity) can be expressed as 
 
  Y ij    0 j    1j   X ij      ij  . 
(1.5) 
 Equation 1.5 suggests that, within groups,  X ij  (employee attitude) is related to productivity levels. 
Often, the unstandardized within-group predictors (  1 X ij  ) are either grand-mean or group-mean 
centered to facilitate interpretation of the coeﬃ  cients. Grand-mean centering indicates that the 
variable is compared against the mean for the sample. For example, if the sample mean for em-
ployee attitude were 4.4 (on a 7-point scale), an individual on the grand mean would have her or 
his score rescaled to 0. In contrast, group-mean centering implies that the individual’s attitude 
score is rescaled against the mean for her or his group, with the group mean now equal to 0. We 
describe in Chapter 2 how grand-mean and group-mean centered predictors can be developed 
in IBM SPSS. 
 At Level 2, Equation 1.6 implies that variation in intercepts can be described by an organi-
zation-level intercept (  00 ), or grand mean, and a random parameter capturing variation in indi-
vidual organization means ( u 0 j  ) from the grand mean: 
 
   0 j     00    u 0 j . 
(1.6) 
 TABLE 1.1  Model Dimension a 
Number 
of Levels
Covariance 
Structure
Number of 
Parameters
Subject 
Variables
Fixed Effects
Intercept
1
1
Random Effects
Intercept
1
Identity
1
orgid
Residual
1
Total
2
3
 a Dependent variable: productivity.

Introduction to Multilevel Modeling with IBM SPSS  13
 In the case where we wish to specify the within-group slope as ﬁ xed (i.e., it does not vary across 
organizations), we can express the Level 2 slope equation as follows: 
 
   1 j     10 . 
(1.7) 
 Th is suggests that the variance component of the slope is ﬁ xed at 0. Because there is no random 
eﬀ ect ( u 1 j  ) in Equation 1.7, the slope coeﬃ  cient is therefore ﬁ xed to one value for the sample. 
Th rough substitution of   0 j  and  1 j  into Equation 1.5, the single-equation model can be sum-
marized as the following: 
 
  Y ij     00    u 0 j     10 X ij    ij   
(1.8) 
 and then reorganized with ﬁ xed parameters (  s) and variance parameters ( u 0 j     ij  ) as follows: 
 
 Y ij     00    10  attitude ij     u 0 j     ij  , 
(1.9) 
 where we have replaced  X with the individual-level variable name. Equation 1.9 and the follow-
ing output in  Table 1.2  suggest that there are four parameters to estimate. Th e two ﬁ xed eﬀ ects 
are the intercept and the Level 1 predictor  attitude . Th e third parameter is the randomly varying 
intercept between groups (referred to as the  random eﬀ ect  in the table). Th e fourth parameter is 
the Level 1 residual variance. With one random eﬀ ect in the model, the default covariance ma-
trix is an identity covariance matrix (ID). Th is is because there is only one Level 2 variance in 
the model (i.e., variability due to diﬀ erences in outcome means between groups). We note that 
if other covariance structures are speciﬁ ed (e.g., variance components or diagonal), they will be 
ignored, which results in the same output. 
 3. Add the Level 2 Explanatory Variables 
 At the third step, it is often useful to add the between-group predictors of variability in inter-
cepts. Group variables are often referred to as  W (or  Z ). From  Figure 1.2 , the Level 2 model with 
resources added will look like the following: 
 
   0 j     00     01 Wj      u 0 j , 
(1.10) 
 TABLE 1.2 Model Dimension a 
Number 
of Levels
Covariance 
Structure
Number of 
Parameters
Subject 
Variables
Fixed Effects
Intercept
1
1
attitude
1
1
Random Effects
Intercept
1
Identity
1
orgid
Residual
1
Total
3
4
 a Dependent variable: productivity. 

14  Introduction to Multilevel Modeling with IBM SPSS
 where  W j  refers to the level of resources in the organization. When we substitute the new Level 
2 intercept equation (Eq. 1.10) and the previous ﬁ xed slope for attitude (Eq. 1.7) into the Level 
1 equation (Eq. 1.5), we obtain the new combined equation: 
 
  Y ij      00     01 resources j      10  attitude ij     u 0 j     ij  , 
(1.11) 
 where we have included the names of the individual- and group-level predictors for  W and  X , 
respectively. We ﬁ nd that it is sometimes useful to write in the variable names to provide easy 
recognition of the predictors in the model. Readers will notice that in a two-level model, after 
substitution, all estimates of group-level and individual-level predictors are expressed as   coeﬃ  -
cients. Equation 1.11 suggests that there are ﬁ ve parameters to be estimated in this model.  Table 
1.3 conﬁ rms that there are three ﬁ xed eﬀ ects, one random eﬀ ect (i.e., the intercept), and the 
residual to be estimated, since the Level 1 slope (attitude) is still considered as ﬁ xed at Level 2. 
 4. Examine Whether a Particular Slope Coefﬁ cient Varies Between Groups 
 We may next assess whether key slopes of interest have a signiﬁ cant variance component be-
tween the groups. Our theoretical model ( Figure 1.2 ) proposes that the relationship between 
employee attitudes and productivity may vary across organizations. Testing random slopes is best 
accomplished systematically, one variable at a time, since if we test several slopes simultaneously, 
we are unlikely to achieve a solution that converges (Hox, 2002). As we suggested previously, if 
the within-unit slope (e.g., attitude-productivity) is deﬁ ned to be randomly varying across units, 
the Level 2 slope model can be written as follows: 
 
   1 j     10    u 1 j . 
(1.12) 
 Equation 1.12 suggests variability in slopes can be described by a group-level intercept coef-
ﬁ cient (  10 ), often centered on the grand mean or the group mean, and a random parameter 
capturing variation in individual organization coeﬃ  cients ( u 1 j  ) from the mean. 
 Th rough substitution, the combined model will be 
 
  Y ij    00     01 resources j      10 attitude ij   u 1 j attitude ij     u 0 j     ij . 
(1.13) 
 As we suggested earlier, notice the substitution of   1 j  in the within-group (Level 1) model 
 (Eq. 1.5) results in the addition of the interaction  u 1 j  X 1 ij  (i.e., where X 1 ij  is employee attitude) to 
 TABLE 1.3 Model Dimension a 
Number 
of Levels
Covariance 
Structure
Number of 
Parameters
Subject 
Variables
Fixed Effects
Intercept
1
1
resources
1
1
attitude
1
1
Random Effects
Intercept
1
Identity
1
orgid
Residual
1
Total
4
5
 a Dependent variable: productivity.

Introduction to Multilevel Modeling with IBM SPSS  15
the single-equation model. Th is interaction is considered to be a random eﬀ ect, which is deﬁ ned 
as the deviation in slope for cases in group  j multiplied by the Level 1 predictor score ( X 1 ) for 
the  i th case in group  j (Tabachnick, 2008). With a random slope and intercept, we typically ﬁ rst 
specify a diagonal (DIAG) covariance matrix at Level 2. A diagonal covariance matrix provides 
an estimate of the variance for each random eﬀ ect, but the covariance between the two random 
eﬀ ects is restricted to be 0. Specifying variance components (VC) will also provide this same 
diagonal covariance matrix speciﬁ cation. We can conﬁ rm in  Table 1.4  that there are six param-
eters to estimate. Th e three ﬁ xed eﬀ ects are the intercept, the Level 2 predictor ( resources ), and 
the Level 1 predictor ( attitude ). Th e two random eﬀ ects are the variability in intercepts ( u 0 j  ) and 
the variability in the attitude-productivity slope ( u 1 j  X 1 ij  ). Th e Level 1 residual variance is the ﬁ nal 
estimated parameter. 
 5. Adding Cross-Level Interactions to Explain Variation in the Slope 
 Finally, we would build a Level 2 model to explain variation in the Level 1 randomly varying 
slope of interest (i.e., assuming the slope has signiﬁ cant variance across groups). Our simpliﬁ ed 
model in  Figure 1.2  suggests that organizational resource levels may moderate the within-unit 
(e.g., attitude-productivity) slope: 
 
   1 j     10     11 resources j     u 1 j . 
(1.14) 
 Th is cross-level interaction term is built during the model speciﬁ cation phase in IBM SPSS. 
 Substitution of the previous   1   j  equation and the previous intercept equation (Eq. 1.10) into 
Equation 1.5 results in the ﬁ nal single-equation model to be estimated: 
 
  Y ij      00    01 resources j    10 attitude ij      11 resources j     *    attitude ij     u 1   j attitude ij     u 0 j    ij  . 
(1.15) 
 Th e model represented in Equation 1.15 results in seven parameters to estimate. Th e four ﬁ xed 
eﬀ ects are the intercept, resources, attitudes, and the cross-level interaction ( attitude * resources ). 
Th e two random eﬀ ects at the organizational level (Level 2) are the intercept ( u 0   j  ) and the 
attitude-productivity slope ( u 1 j   attitude ij  ). Th e ﬁ nal parameter is the individual-level residual (  ij  ). 
We can conﬁ rm this from the model dimensions output in  Table 1.5 . 
 When investigating the covariance structures associated with random eﬀ ects, we adopt a simi-
lar strategy. One of the advantages of IBM SPSS MIXED is the ease in which users can specify 
alternative covariance structures for random eﬀ ects. If this model converges, or reaches a solu-
tion without any warnings in the output, we can also try using a completely unstructured (UN) 
 TABLE 1.4 Model Dimensiona
Number of 
Levels
Covariance 
Structure
Number of 
Parameters
Subject 
Variables
Fixed Effects
Intercept
1
1
resources
1
1
attitude
1
1
Random Effects
Intercept  attitude
2
Diagonal
2
orgid
Residual
1
Total
5
6
 a Dependent variable: productivity. 

16  Introduction to Multilevel Modeling with IBM SPSS
covariance matrix of random eﬀ ects. Specifying an unstructured covariance matrix the Level 2 
provides an additional covariance term in the estimated model, which represents the covariance 
between the random intercept and random slope (i.e., there are three random parameters to be 
estimated in the unstructured covariance matrix in  Table 1.6 ). Th is additional term in the covari-
ance structure of the model will result in eight total parameters estimated, instead of the seven 
speciﬁ ed in Equation 1.15. We note, however, that specifying this type of covariance matrix for 
random eﬀ ects sometimes results in models that fail to converge. 
 We can then use various objective tests (e.g., likelihood ratio test) to determine which covari-
ance structure best describes the data. Th is allows the analyst to compare several models before 
arriving at a model that provides the closest ﬁ t to the observed data. It is generally best to keep 
models simpliﬁ ed, for example, by including only random eﬀ ects that are of strong theoreti-
cal or empirical interest. Th ree-level models are more complicated to specify and estimate than 
two-level models because of the possibility of more cross-level interactions, random eﬀ ects, and 
diﬀ ering sample sizes; however, the strategy for building models is basically the same. We will 
address these issues more completely in subsequent chapters. 
 Syntax Versus IBM SPSS Menu Command Formulation 
 In IBM SPSS MIXED, we can formulate models using either syntax statements or menu com-
mands. We suspect most users are more familiar with the menu framework since they have likely 
used that to examine single-level models (e.g., analysis of variance, multiple regression, and factor 
analysis). We have chosen the menu-command approach, but we also provide examples of syntax 
 TABLE 1.5 Model Dimension a 
Number of 
Levels
Covariance 
Structure
Number of 
Parameters
Subject 
Variables
Fixed Effects
Intercept
1
1
resources
1
1
attitude
1
1
attitude * resources
1
1
Random Effects
Intercept  attitude
2
Diagonal
2
orgid
Residual
1
Total
6
7
 a Dependent variable: productivity. 
 TABLE 1.6 Model Dimension a 
Number of 
Levels
Covariance 
Structure
Number of 
Parameters
Subject 
Variables
Fixed Effects
Intercept
1
1
resources
1
1
attitude
1
1
attitude * resources
1
1
Random Effects
Intercept  attitude
2
Unstructured
3
orgid
Residual
1
Total
6
8
 a Dependent variable: productivity. 

Introduction to Multilevel Modeling with IBM SPSS  17
in an appendix for each chapter. Readers should keep in mind that with more complex models, 
it is often beneﬁ cial to use the syntax to formulate and run models for a couple of reasons. First, 
the syntax statements provide a nice record of a progression of models (if you save the syntax ﬁ les 
and label them according to the general modeling steps we have laid out). Th is is helpful if you 
close the IBM SPSS program. You can return later and easily start up from where you left oﬀ . 
 Second, we have found that it is easier to reorganize the syntax statements than to rebuild the 
whole model from the menu commands if you wish to change the order of the variables in your 
output tables. Generally, we like to organize the output such that the predictors explaining inter-
cepts are organized by levels of the data hierarchy, and predictors that explain variation in slopes 
(i.e., cross-level interactions) can be similarly organized. In the IBM SPSS Windows format, one 
can always use the PASTE function (within the IBM SPSS MIXED dialog box) to generate 
the underlying syntax before actually running the model. Th e syntax is sent to its own window 
within IBM SPSS and can be saved for future use. We ﬁ nd this is a good way to check whether 
the model you are running actually corresponds with the model that you had in mind. Often, we 
ﬁ nd doing this helps us see where we have forgotten or incorrectly speciﬁ ed something. Th is gets 
more important when the multilevel models that one is investigating take a considerable amount 
of time to produce a solution. 
 For readers unaccustomed to the syntax approach, following is an example of the syntax gen-
erated by IBM SPSS MIXED when we built the model within the menu system to produce the 
model in Equation 1.15. 
 MIXED 
 productivity WITH attitude resources 
 /CRITERIA  CIN(95) MXITER(100) MXSTEP(5) SCORING(1) 
 SINGULAR(0.000000000001) HCONVERGE(0, ABSOLUTE) LCONVERGE(0, ABSOLUTE) 
 PCONVERGE(0.000001, ABSOLUTE) 
 /FIXED  resources attitude resources*attitude | SSTYPE(3) 
 /RANDOM INTERCEPT attitude | SUBJECT(orgid) COVTYPE(DIAG) 
 /METHOD  REML 
 /PRINT  SOLUTION TESTCOV. 
 Th e initial syntax lines provide the dependent variable (productivity) and identify covari-
ates in the analysis (signiﬁ ed by the key word “WITH”). Categorical variables (variables with 
two or more categories) can be speciﬁ ed with the key word “By,” with the last category serving 
as the reference group. Note that dichotomous variables (0, 1) can be deﬁ ned as continuous 
(covariate) variables as in multiple regression. Th e criteria command (/CRITERIA) provides 
information concerning IBM SPSS default values (e.g., conﬁ dence intervals for estimates, itera-
tion information, and convergence criteria) for the estimation algorithm. Th e statements can be 
excluded if the analyst chooses to maintain the default criteria. We recommend that the analyst 
exercise caution in reﬂ exively adopting the IBM SPSS defaults as these will sometimes intro-
duce problematic conditions on the models being estimated. Regardless of the type of model 
being developed, it is always good practice to review the default settings to ensure that they are 
appropriate for your purposes. Following this, the ﬁ xed eﬀ ects (/FIXED  resources, attitudes, 
resources * attitudes) in the model are deﬁ ned, with the intercept also included as a default, and 
the random eﬀ ects (/RANDOM  intercept, attitude). Th e Level 1 residual is also estimated as 
a default. Th e syntax also identiﬁ es the Level 2 cluster (SUBJECT) variable (orgid) and the type 
of covariance matrix used for the random eﬀ ects (DIAG). If UN is speciﬁ ed for the covariance 
matrix instead of DIAG, the additional covariance between the intercept and random slope will 
be estimated. Finally, the syntax includes the default estimation procedure used (/METHOD  
REML), which is restricted maximum likelihood, default model convergence criteria, and user-
speciﬁ ed output (/PRINT  G SOLUTION TESTCOV). SOLUTION provides the tests of 

18  Introduction to Multilevel Modeling with IBM SPSS
ﬁ xed eﬀ ects and TESTCOV the tests of random variances and covariances. Predicted values and 
residuals can be saved using the /SAVE command. 
 One can easily change the method of estimation (/METHOD), for example, from restricted 
maximum likelihood (REML) to maximum likelihood (ML) by just typing ML to replace 
REML in the appropriate syntax line. Th e order of the ﬁ xed eﬀ ects (FIXED  resources attitude 
resources * attitude) in the output can easily be changed by switching the order of the variables in 
that command line. Keep in mind that you can also add information to the IBM SPSS output 
tables (by using the Chart Editor) to help readers understand your presentation of output. We 
will explore many of these options in subsequent chapters. 
 Model Estimation and Other Typical Multilevel-Modeling Issues 
 We now turn our attention to several important issues related to model estimation (see Heck & 
Th omas, 2009; Hox, 2010; Marcoulides & Hershberger, 1997; or Raudenbush & Bryk, 2002, for 
further discussion). Model estimation attempts to determine the extent to which the sample co-
variance matrix representing our model speciﬁ cation is a good approximation of the true popula-
tion covariance matrix. Th is determination is made through a formal test of a null hypothesis that 
the data are consistent with the model we have proposed. Note that, in general, conﬁ rmation of 
a proposed model relies on a failure to reject the null hypothesis. In contrast to the common use 
of the null hypothesis that readers may be more familiar with (e.g., rejecting the null hypothesis 
that two means are the same), here one wishes to accept the null hypothesis that the model can-
not be rejected on statistical grounds alone. Th is implies that the model is a plausible represen-
tation of the data (although it is important to emphasize that it may not be the only plausible 
representation). 
 Unlike traditional single-level approaches using OLS, IBM SPSS MIXED (and other mul-
tilevel-modeling programs) employs maximum likelihood (ML) estimation. Th is is necessary 
where individuals are clustered within groups of diﬀ ering size and, therefore, we have to deal 
with more than one set of residuals and distinguish between multiple levels (Hox, 2010). While 
we could certainly estimate a large number of single-level OLS regression models (i.e., one for 
each group), multilevel modeling is a more eﬃ  cient approach that proceeds by estimating a single 
average intercept (or slope) and then a variance component describing the variance in intercepts 
or slopes across the Level 2 units in the study (Hox, 2010). Diﬀ ering sample sizes, however, aﬀ ect 
the reliability of the individual estimates produced for each unit (i.e., with estimates produced 
from smaller units being less reliable) and, hence, the overall reliability for that unit within the 
complete set of Level 2 units. Units where the group estimate is further from the overall grand-
mean estimate of units tend to be estimated less reliably than units closer to the grand mean, 
other factors being equal (Hox, 2010). 
 In the past, multilevel models were limited by the need to have balanced sample size designs, 
which were required for using closed-form mathematical formulas to estimate the variance and 
covariance components (Raudenbush & Bryk, 2002). For designs with unbalanced sample sizes, 
what is needed is an iterative process that incorporates information about each group to obtain 
eﬃ  cient estimates of the model’s ﬁ xed and random parameters. Most often, maximum likeli-
hood estimation (ML) is used for this purpose. Because of the relative complexity added with 
models where there are several predictors and potential random parameters, we often start with 
relatively simple models that estimate ﬁ xed eﬀ ects and then add random components, in steps, 
one at a time. 
 Maximum likelihood determines the optimal population values for parameters in a model that 
maximize the probability or likelihood function—that is, the function that gives the probability 
of ﬁ nding the observed sample data given the current parameter estimates (Hox, 2002). Th is in-
volves an iterative process that determines a set of weights for random parameters in the model 
that minimizes the negative of the natural logarithm multiplied by the likelihood of the data. 

Introduction to Multilevel Modeling with IBM SPSS  19
Because the likelihood, or probability, can vary from 0 to 1, minimizing this discrepancy function 
amounts to maximizing the likelihood of the observed data. Since the process is iterative (i.e., 
beginning with a set of starting values and proceeding through rounds of parameter adjusting to 
reach an optimal set of estimates where further adjustment would not improve the estimates), it 
is not guaranteed to stop. Most programs, therefore, put limits on the number of iterations since 
most “good” models will converge within a relatively short number of iterations (e.g., perhaps 
20–50 iterations). Often, making a change in the proposed model (e.g., eliminating a random 
slope or a covariance between an intercept and a slope) will result in the model converging. At 
other times, the small sample size (e.g., available number of Level 2 units) may be the culprit 
(Hox, 2010) since the data in such cases may not be relatively normally distributed. 
 If we consider the sample covariance matrix ( S ) to represent the population covariance matrix 
(), then the diﬀ erence between the observed sample matrix  S and the model-implied covariance 
matrix ( S ) should be small if the proposed model ﬁ ts the data. Th e evaluation of the diﬀ erence 
between these two matrices depends on the estimation method used to solve for the model’s 
parameters (Marcoulides & Hershberger, 1997). Th e mathematical relationships implied by the 
model are solved iteratively until the estimates are optimized. As suggested, the diﬀ erence be-
tween  S and  S is described as a discrepancy function—that is, the actual diﬀ erence in the two 
estimates based on a likelihood. Th e greater the diﬀ erence between these two covariance ma-
trices, the larger the discrepancy in the function becomes (Marcoulides & Hershberger, 1997). 
ML estimation produces a model deviance statistic, deﬁ ned as ‒2*log likelihood (‒2LL), where 
likelihood is the value of the likelihood function at convergence and log is the natural logarithm. 
Th e deviance is an indicator of how well the model ﬁ ts the data. Models with lower deviance (i.e., 
a smaller discrepancy function) ﬁ t better than models with higher deviance. Nested models (i.e., 
where a more speciﬁ c model is formed from a more general one) can be compared by examining 
diﬀ erences in these deviance coeﬃ  cients under speciﬁ ed conditions (e.g., changes in deviance 
between models per diﬀ erences in degrees of freedom). 
 IBM SPSS MIXED currently oﬀ ers two estimation choices: full information ML estimation 
(which we will abbreviate as ML) and REML estimation, which is the default setting. In ML 
estimation, both regression coeﬃ  cients and variance components are included in the likelihood 
function, while in REML, only the variance components are included in the likelihood function 
(Hox, 2002). REML, therefore, is referred to as a  restricted solution. One of the shortcomings of 
ML estimation is that the estimates of variances and covariances depend on the point estimates 
obtained for the regression coeﬃ  cients. As there are more parameters in the model and smaller 
sample sizes, the variance estimates obtained through ML may be too small, which leads to 
overly liberal hypothesis tests (Raudenbush & Bryk, 2002). In contrast, REML considers the 
regression coeﬃ  cients to be unknowns to be estimated, which can lead to better estimates when 
there are small numbers of groups in the study (Raudenbush & Bryk, 2002). In other words, 
REML takes into account the loss in degrees of freedom due to the estimation of the  P  1 
regression coeﬃ  cients in the model in order to obtain unbiased estimation of the variance 
components (Snijders & Bosker, 1999). 
 To illustrate this concept, in a simple model for estimating the variance in a sample mean, 
the REML approach amounts to dividing the sum of the squared deviations about the mean by 
the total sample size minus 1 ( n ‒ 1) instead of  n (Hox, 2002). Th is correction in the denomina-
tors used to calculate the variance will be greatest when the sample size is small. As described 
previously, when a series of nested models is to be compared in terms of ﬁ xed eﬀ ects (e.g., 
regression coeﬃ  cients), ML should be used because the approach takes into consideration the 
regression coeﬃ  cients in solving the likelihood function (Hox, 2002). In later chapters, we show 
that MIXED also provides other ﬁ t indices that can be used to compare various models. 
 We note in passing that for the GENLINMIXED program, the available estimation proce-
dure for models with continuous outcomes (i.e., which result from normal versus other types of 
probability distributions) is REML. Th is means that currently the GENLINMIXED estimation 

20  Introduction to Multilevel Modeling with IBM SPSS
option for continuous outcomes is limited to the REML approach used in MIXED. We there-
fore recommend estimating multilevel models with continuous outcomes using MIXED, even 
though they can also be estimated in the GENLINMIXED routine with REML. As mentioned 
previously, the REML approach would not be optimal when the research focus is on comparing 
successive models with both ﬁ xed regression coeﬃ  cients and random coeﬃ  cients. 
 Sample Size 
 Under various sampling conditions (size of sample and normality of data) there has been con-
siderable debate among methodologists about the eﬃ  ciency of maximum likelihood estima-
tion, given nonnormal features of the data (Goldstein, 1995; Longford, 1993; Morris, 1995). An 
important conceptual diﬀ erence between single-level and multilevel approaches is that sample 
size considerations are quite diﬀ erent. With the multilevel approach, a suﬃ  cient sample size 
is required at each level of analysis. In smaller group samples, the diﬀ erence in estimation be-
tween ML and REML results in a downward bias in variance components estimated with ML 
compared to REML. With small group samples, therefore, we generally prefer REML estima-
tion. With large sample sizes, there should be no diﬀ erence in the estimates produced by either 
method. It is important to keep in mind that under less-than-ideal sampling conditions (e.g., 
small numbers of groups and convenience samples), it may be diﬃ  cult to determine whether 
model results might be replicated in other samples. IBM SPSS applies the Satterthwaite (1946) 
correction to standard errors, which provides more conservative estimates of standard errors, 
especially in small groups (e.g., Loh, 1987). We note that it is often more eﬃ  cient to add higher 
level units than to add individuals within in groups since this former approach generally reduces 
that need for sizable samples within the groups and tends to be more eﬃ  cient in estimating 
random coeﬃ  cients. 
 Power 
 Power refers to the ability to detect an eﬀ ect, should one exist. In the single-level analysis, most 
researchers know that the signiﬁ cance level (  ), the eﬀ ect size (i.e., with larger eﬀ ects easier 
to detect), and the sample size are determinants of power. Multilevel models raise a number 
of additional issues involving power. Issues about power typically concern the appropriate (or 
minimum) sample size needed for various types of multilevel analyses (e.g., determining whether 
an intercept or a slope varies across groups). As we suggested previously, one issue refers to the 
sample size required to ensure that estimates of ﬁ xed eﬀ ects (e.g., at Level 1 and Level 2) and 
variances are unbiased (i.e., sampling bias). In most multilevel studies, the estimation of Level 
2 eﬀ ects is generally of greater concern as the number of groups available may be limited. As 
Snijders (2005) shows, when ﬁ xed eﬀ ects are the focus, characteristics of the groups themselves 
have little bearing on the precision of Level 1 estimates. In general, we prefer adding groups (as 
opposed to individuals) to reduce parameter bias. 
 Another issue refers to the minimum sample size required to ensure that an eﬀ ect would be 
detected if, in fact, one exists (i.e., power). In addition to these two determinants of power, in 
multilevel analyses there are at least two other considerations that inform estimates of power: 
sample size at each level (i.e., the number of individuals  i within each group  j , and the number 
of  j groups) and the intraclass correlation (see Muthén & Satorra, 1995, for further discussion). 
With higher ICCs, the power to detect Level 1 eﬀ ects will be lower (since the groups are more 
homogeneous), holding sample size constant at all levels. Th is suggests that the power to detect 
Level 2 eﬀ ects is much more sensitive to the number of groups in the sample, as opposed to the 
number of observations within groups. 
 As designs become more complex, the need for larger samples at both levels increases. For 
example, in a given sample of individuals within groups, slopes in some units may be less reli-
ably estimated than intercepts because, while intercepts depend only on the average level (mean) 

Introduction to Multilevel Modeling with IBM SPSS  21
of a variable within each group, slope estimates depend both on the levels of an outcome and a 
particular covariate, as well as the variability of their covariance among individuals within each 
group (Mehta & Neale, 2005). Th is means that estimating variability in random slopes across 
units generally requires larger sample sizes for more stable estimates than simply estimating ran-
dom intercepts. Complications can also arise due to correlations between random eﬀ ects and the 
investigation of cross-level interactions (Raudenbush & Bryk, 2002). As this limited discussion 
of power suggests, a number of considerations must take place to assess potential bias in param-
eter estimates and power in various types of multilevel designs. Readers can consult Scherbaum 
and Ferreter (2009), Snijders and Bosker (1999), and Snijders (2005) for further discussion of 
issues related to power. 
 Differences Between Multilevel Software Programs 
 In preparing this workbook, we compared models estimated in IBM SPSS with models esti-
mated with other multilevel software with which we are familiar (e.g., HLM and Mplus). Dif-
ferent software programs use slightly diﬀ erent algorithms to estimate models, for example, in 
calculating standard errors, especially in small groups. Th ere are also diﬀ erences in the means 
of testing the variance components. For example, IBM SPSS uses a Wald Z test, and HLM 
uses a chi-square test. In general, however, we have found that the diﬀ erences between software 
programs are generally small—that is, output will carry the same substantive interpretation. We 
provide several examples in Appendix B. 
 Standardized and Unstandardized Coefﬁ cients 
 We present the analyses in subsequent chapters using unstandardized regression coeﬃ  cients. 
Unstandardized coeﬃ  cients provide estimates of changes in the dependent variable associated 
with a unit change in the explanatory variable (e.g., male versus female; a standard-deviation 
increase in motivation). Standardizing variables is useful in comparing the size of eﬀ ects due to 
several variables measured on diﬀ erent scales within a sample. If the goal is to compare estimates 
across samples, one should use unstandardized estimates (Hox, 2010). Standardizing estimates is 
more complicated in multilevel modeling, however, due to the presence of variance components 
for outcomes at diﬀ erent levels of the data hierarchy. Because standardizing variables depends 
on their standard deviations, in multilevel modeling the analyst faces the issue of using Level 1 
standard deviations and Level 2 standard deviations to compute standardized eﬀ ects of predic-
tors (Bloom, Hill, Black, & Lipsey, 2008). 
 Th ere are a number of diﬀ erent ways to approach standardizing variables in multilevel model-
ing. Some software programs (e.g., Mplus and LISREL) provide a variety of diﬀ erent standard-
izations. For example, standardizing estimates to the within-group variance implies a focus on 
within-group relations without concern for how large or small the portion is of the within-group 
variance to the total variance. Mplus standardizes estimates within each level (which requires 
the between-group and within-group covariance matrices in order to construct accurate esti-
mates). Other programs (e.g., HLM and SPSS MIXED) currently do not provide standardized 
solutions. 
 One can standardize all the indicators in the model ﬁ rst (e.g., by saving standardized estimates 
of each variable, which can be obtained using the Descriptives command in IBM SPSS). Essen-
tially, this amounts to modeling with all  z -scores. Th is approach succeeds in putting the variables 
in the same metric, but it does have a few drawbacks. First, it does not completely resolve the 
issue about the “proper” size of the coeﬃ  cients in relation to an assumption about decomposing 
variance in the model. Second, as Hox (2002) notes, this type of linear transformation of the 
ﬁ xed coeﬃ  cients in a model through standardizing also has the eﬀ ect of changing estimates of 
the random part of the model (i.e., the model’s variance components). If one has random slopes 
www.allitebooks.com

22  Introduction to Multilevel Modeling with IBM SPSS
in the model, standardizing the estimates can alter the calculation of the variance components at 
each level. Standardizing tends to reduce variability at diﬀ erent levels, which is often important 
in the focus of the multilevel analysis—and maybe even the theory underlying the relationships 
in a proposed model. Th ird, in the process of standardizing things, we usually ﬁ nd that  p values 
can be changed slightly. So for example, something signiﬁ cant in a raw metric may or may not 
be signiﬁ cant when everything is standardized. Interactions are more challenging to standardize 
since standardizing before the analysis can change the size of the interaction, the model’s vari-
ance components, and also signiﬁ cance levels of variables (Hox, 2010; Preacher, 2003). 
 We have found that various assumptions about standardizing variables (i.e., standardizing 
with respect to within-group variance only, the between-group variance only, within each level of 
the data hierarchy, or with respect to total variance) can lead to very diﬀ erent sets of coeﬃ  cients 
and interpretations of the results, such that it can be diﬃ  cult to determine what each stan-
dardization means (Heck & Th omas, 2009). It is important to understand the assumptions and 
possible consequences of providing standardized solutions. Despite these cautions, we do favor 
providing a standardized solution in many instances since an audience may well understand the 
eﬀ ect of a predictor as producing a 0.6 standard deviation ( SD ) increase in the dependent vari-
able. In such cases, however, we recommend examining both unstandardized and standardized 
results and then comparing the pattern of signiﬁ cant and nonsigniﬁ cant eﬀ ects of predictors and 
variance components for consistency. Th ese choices about the presentation of empirical results 
need to be considered in terms of both the technical and substantive issues they raise, as well as 
with respect to the overall goals of the research study. 
 Missing Data 
 It is often the case that the weakest point of a study is the quality of the data that can be brought 
to bear on the research problem. Missing data can be a problem in multilevel applications, de-
pending on the sampling design underlying the data set, the extent to which the data are missing 
at each level, and whether or not the data can be assumed to be missing at random. Th e more 
one can ﬁ nd out about why the data are “as they are,” the more one can develop a case about the 
patterns of missing data, as well as a rationale about why the pattern may or may not matter. In 
some modeling situations, there may be considerable missing data. 
 Users should consider data preparation and data analysis as two separate steps. In preparing 
the data for analysis, it is often useful ﬁ rst to determine the amount of missing data present, as 
well as the number of missing data patterns (e.g., For which variables do missing values occur? 
Are there speciﬁ c patterns of missing data?). It is important to keep in mind that the reality is 
that there is no real way to get data that are missing back (short of actually following up with 
subjects in a study). In a sense, then, we are always dealing with the problem of missing informa-
tion to some extent when we use actual data. Th e quality of our analysis depends on assumptions 
we make about the patterns of missing responses present and what is reasonable to conclude 
about those patterns in relation to the study’s design (e.g., experimental or quasi-experimental 
and survey) and data collection (e.g., cross-sectional and longitudinal). 
 What we do about the missing data we have becomes a more pressing concern. Th ere are a 
number of available options for dealing with missing data. It helps to know what the defaults 
and options are for handling missing data in the software programs that we are considering to 
use in each given research situation. Typically used approaches such as listwise or pairwise dele-
tion, mean substitution, or simple imputation using regression-based techniques (e.g., estimating 
outcomes with dummy-coded missing data ﬂ ags to determine whether there were diﬀ erences in 
outcomes associated with individuals with missing versus complete data) lead to biased results in 
most situations (Acock, 2005; Allison, 2002; Larsen, 2011; Peugh & Enders, 2004). Currently, 
for single-level models, acceptable approaches include full information maximum likelihood 
(FIML) estimation with the partial data included and multiple imputation (MI) of plausible 

Introduction to Multilevel Modeling with IBM SPSS  23
values (Asparouhov, 2006; Enders, 2011; Enders & Bandalos, 2001; Peugh & Enders, 2004). 
Additionally, as Enders notes, inverse probability weighting methods are also gaining attention 
in the statistics literature (e.g., Little & Rubin, 2002; Robins & Rotnitzky, 1995). It is impor-
tant to note that few studies have examined the use of these commonly accepted, single-level 
approaches with multilevel data structures (e.g., see Larsen, 2011; van Buuren, 2011). 
 Handling missing data in an appropriate manner depends on one’s knowledge of the data set 
and why particular values may be missing. In general, there are three main types of missing data 
(see Hox, 2010; or Little & Rubin, 2002, for further discussion). Rubin (1976) introduced the 
notion of the distribution of ‘‘missingness’’ as a way to classify the probability conditions under 
which missing data can be ignored. Th ese include data that are missing completely at random 
(MCAR), missing at random (MAR), and nonignorable missing (NIM), which is also referred 
to as missing not at random (MNAR). For data to be MCAR, strong assumptions must hold. 
Th e missing data on a given outcome should be unrelated to either a subject’s standing on the 
outcome or to other observed data or unobserved (missing) data in the analysis. Th is is the as-
sumption underlying listwise deletion. Typically, this assumption is only met when the data are 
missing by design, as in the situation where we draw a random sample of the studied population. 
 In contrast, if the probability of data being missing on the outcome is related to missing data 
on a covariate, but not to subjects’ standing on the outcome, then the data are MAR (Little & 
Rubin, 2002). It is reasonable to assume there will be some relationships between data that are 
missing on two or more variables in a study. For example, if students have missing data on at-
tendance for a number of diﬀ erent reasons such as changing schools, having a health condition, 
or living in a particular region, they may also have missing data on math outcomes. Th ese other 
variables provide a mechanism for explaining the missing values present. Th e MAR assumption 
underlies the MI and FIML approaches to dealing with missing data. Although it is often rea-
sonable to assume that data are MAR, under some circumstances, this assumption may not hold 
(Enders, 2011). 
 More problematic is the situation where the probability of missing data on the outcome is re-
lated to standing on the outcome for individuals with the  same value on a covariate. For example, 
if there is more missing low-math data than missing average- and high-math data among stu-
dents with the same attendance level, then the data are NIM. Suppose we have 500 students who 
take a test, but 150 have missing data, and these missing individuals also tend to have relatively 
high absenteeism (e.g., 20 or more days). Th en we might have to acknowledge there is some bias 
present. Perhaps two thirds of the missing data are students who are in the high-absenteeism 
group and low-math achievement group. It will now be hard to argue that the missing data on 
the student absenteeism predictor will not aﬀ ect the estimation of students’ math test scores for 
the population. Th is latter type of missing data can produce more bias for model estimation than 
either of the other situations because the missing data on math achievement are related to actual 
values of individual achievement for those subjects who do not take the test. We would prefer to 
be able to say the pattern of missing data on student outcomes is relatively similar for students 
with high, average, and low absenteeism. Th is would then indicate data that are MAR. 
 Other techniques have been developed for data that are NIM. Enders (2011) demonstrates the 
usefulness of two of the NIM approaches for longitudinal data (i.e., selection models and pattern 
mixture models) and demonstrates their use on a real data set. More speciﬁ cally, selection models 
for longitudinal data combine a substantive model (i.e., a growth curve model) with a set of re-
gression equations that predict missingness, while a pattern mixture analysis stratiﬁ es the sample 
into subgroups that share the same missing data pattern and estimates a growth model separately 
within each pattern. Interested readers can consult Hedeker and Gibbons (1997, 2006) for one 
example of a pattern mixture–modeling approach that uses the missing data pattern (represented 
by one or more dummy variables) as a predictor in the growth model. Th eir approach can be 
estimated with standard mixed-modeling procedures (e.g., the MIXED procedures in SPSS and 
SAS). Choosing an approach for handling missing data (whether assuming MAR or NIM) is a 

24  Introduction to Multilevel Modeling with IBM SPSS
matter of choosing among competing assumptions. As Enders (2011) concludes, “Researchers 
should choose a model with the most defensible set of assumptions, and they should provide a 
logical argument that supports this choice” (p. 15). 
 As we have cautioned, IBM SPSS is limited in its ability to deal with various patterns of 
missing data. As a default, the program uses listwise deletion of cases when there is any miss-
ing data. Th is means any individual with data missing on any variable will be dropped from the 
analysis. As a ﬁ rst step, we suggest examining the amount of missing data on each variable. Even 
with 5% or less per variable, in some situations, listwise deletion can result in a tremendous loss 
of data and biased parameter estimation. IBM SPSS does provide a number of options for ex-
amining missing data. Th e standard solutions provided in most routines are listwise, pairwise, or 
mean substitution. In most situations, however, none of these would be considered as optimal 
(or acceptable) approaches (Enders & Bandalos, 2001; Peugh & Enders, 2004). For example, 
listwise deletion leads to inﬂ ated standard errors when the data are MCAR and biased param-
eter estimates when the data are MAR (Allison, 2002; Larsen, 2011). Mean substitution treats 
individuals with missing data as if they were on the “grand mean” (MCAR), which is also likely 
to introduce bias in most situations (e.g., by reducing variance). Th e IBM SPSS Base Statistics 
program also provides a basic program that provides several replacement methods (e.g., series 
mean, mean of nearby points, median of nearby points, and linear interpolation). We also note 
that although “user-missing” values can be speciﬁ ed in IBM SPSS, this approach is typically 
used for categorical responses, where some possible responses are coded as missing (e.g., “not 
applicable” in survey questions). If these user-deﬁ ned missing values are included in the analysis, 
however, they will also bias parameter estimates. 
 For users who have access to the SPSS multiple imputation (MI) data module, patterns of 
missing data can ﬁ rst be identiﬁ ed, and then plausible values can be imputed using the expec-
tation maximization (EM) algorithm. EM is a common method for obtaining ML estimates 
with incomplete data that has been shown to reduce bias due to missing data (Peugh & Enders, 
2004). Obtaining estimates involves an iterative, two-step process where missing values are ﬁ rst 
imputed and then a covariance matrix and mean vector are estimated. Th is repeats until the 
diﬀ erence between covariance matrices from adjacent iterations diﬀ ers by a trivial amount (see 
Peugh and Enders, 2004, for further discussion). Th e imputed data sets can be saved as separate 
data sets and then analyzed. It is often the case, for example, that even with 25–35% missing, 
one can impute plausible values into a number of data sets and do a reasonable job of creating a 
complete data set with the missing values given random values. 
 One of the advantages of this approach is that other variables can also be used to supply 
information about missing data, but they need not be included in the actual model estimation. 
Th is approach to missing data is recommended when the assumption that the data are MAR is 
plausible. Th e analyst can generate a relatively large number of imputed data sets (Bodner, 2008) 
and then analyze the complete data sets and report the mean estimates and standard errors across 
several imputations. Th e values imputed through MI represent draws from a distribution; in 
other words, they inherently contain some variation. Th is parameter variation across multiple im-
putations is important for creating reasonable distributions of plausible values for variables with 
missing values. If we assume some degree of normality, we can average the parameter estimates 
over the imputed data sets. Our practical experience with MI approaches suggests they do pretty 
well at estimating the total data set where missing values are randomly dispersed across a sizable 
number of individuals (100–200 or more) found in most published studies. It is important to 
keep in mind, however, that the MI approach as implemented in SPSS does not assume missing 
values on  group-level (Level 2) variables. 
 For multilevel data, there is less guidance available from previous research (e.g., Daniels & 
Hogan, 2008; Larsen, 2011; van Buuren, 2011). Larsen recently conducted a study comparing 
MI and FIML approaches in situations where there were individuals nested within groups. Both 
approaches were relatively similar in handling Level 1 estimates under the diﬀ erent conditions 

Introduction to Multilevel Modeling with IBM SPSS  25
examined. More importantly, however, as missing data increased at Level 2, the estimates of the 
Level 2 predictor from imputed data sets displayed increased parameter bias and decreased stan-
dard errors compared to the estimates predicted from the full data set. For Level 2 estimation, 
Larsen found that FIML estimation with the missing data performed much better than the MI 
approach. Th is is because the MI procedure used in his study did not account for random eﬀ ects. 
More speciﬁ cally, the student-level data (Level 1) were assumed to be “randomly sampled” from 
the same population (i.e., in this case, a classroom), rather than to come from diﬀ erent class-
rooms (Larsen, 2011). 
 Van Buuren (2011) provides an introduction to a number of diﬀ erent missing data situations 
encountered with multilevel data. Where data are missing for Level 2 predictors (e.g., as for a 
school covariate), for programs defaulting to listwise deletion such as IBM SPSS, this will result 
in losing all the individuals within those units. Th ese individuals may not have any missing data 
on the outcome or the Level 1 predictors. Th is may also complicate the estimate of group-level 
eﬀ ects (van Buuren, 2011). We reiterate that the sampling frame through which the data were 
generated may have an impact on assumptions we make about the distribution of the data at each 
level. Th is implies that the nature of missing data at Level 2 in relation to the manner in which 
the units were selected—whether units themselves were randomly sampled from a population of 
units or were just an unspeciﬁ ed “collection” of available units—can further complicate the in-
terpretation of the Level 1 results. As van Buuren (2011) notes, although ML methods are quite 
good at estimating repeated measures values of  Y in longitudinal studies, no generally accept-
able approach has been developed for handing missing values on Level 1 and Level 2 predictors 
(i.e., since the data are assumed to be MAR). If MAR is correct, van Buuren cautions that the 
variables governing the probability of the missing data should be included in the analysis, for 
example, in order not to bias the estimate of a treatment eﬀ ect. 
 Much of our discussion about missing data suggests that dealing with missing data is not so 
much about how much missing data is allowable, but rather how to develop a process to deal 
with the missing data. We favor a strategy of triangulating our results with diﬀ erent approaches 
that are currently recommended for examining missing data. One possible approach is to do 
something like the following. First, one can try running the model using listwise deletion (which 
assumes MCAR). Th is data set will likely be considerably smaller than the “partially complete” 
data, but it gives the analyst a baseline view (albeit likely a biased one) for comparing subsequent 
results. With MIXED, the results with listwise deletion should match the results of the existing 
(partially complete) data set since the variables with missing values are listwise deleted, unless the 
data are vertically arranged as in a growth model. 
 Second, if there is not too much missing data per variable, the listwise results can be compared 
against a number of complete data sets generated using an MI program, which can be applied to 
hierarchical data structures (e.g., Mplus or HLM). Some have discussed the use of single-level 
MI, which ignores the grouping structure in multilevel data; however, this approach may under-
estimate standard errors (Cheung, 2007; Gibson & Olejnik, 2003). In contrast, Zhang (2005) 
found it worked reasonably well with missing data up to about 30%. As van Buuren (2011) cau-
tions, there is no consensus yet, and further work is needed in this area. Others have suggested 
using an individual and group data set to perform separate imputations, while using information 
from one level to inform the other (Gelman & Hill, 2007; Petrin, 2006). 
 Analysts may wish to keep in mind the cautions we have mentioned about estimating plau-
sible values when individuals are nested within groups. Th ere are a number of sources that can 
be consulted for dealing with missing data under MAR and NIM in growth-modeling studies 
(e.g., see Enders, 2011; Muthén & Muthén, 1998–2006). We also note that van Buuren (2011) 
examined several types of missing multilevel data situations and found the multilevel multiple 
imputation used (i.e., which generated multiple imputations from prior distributions of the pa-
rameters using the Gibbs sampler) worked generally the best of several approaches (e.g., listwise, 
single-level MI, and MI with separate groups), but it was not optimal in all situations with 

26  Introduction to Multilevel Modeling with IBM SPSS
respect to recovering true values by 95% conﬁ dence intervals across diﬀ erent cluster sizes and 
numbers of individuals within clusters. 
 Th ird, if the analyst has access to an SEM program (or special multilevel software such as 
HLM) that will perform multilevel analyses, she or he can also try estimating the model with 
FIML with the cases with partial data included in the analysis and then comparing these results 
with the other approaches. If sample weights are available in existing data sets, users should 
check whether they include adjustments for nonresponse. If so, making use of sample weights at 
two levels will facilitate accurate estimation, but this option is currently only available in a limited 
number of multilevel software with which we are familiar. We contrast some of these problems 
brieﬂ y in the next section with two short examples where missing data are encountered. 
 Missing Data at Level 2 
 It is clear that more work needs to be done on the use of multiple imputation procedures for 
hierarchical data structures (Larsen, 2011; van Buuren, 2011). We caution in this situation that 
users should be careful about imputing values for Level 2 variables within the larger data set that 
contains missing values. Th is is because the program will create  diﬀ erent  “group” values on Level 
2 variables for individuals in the same group. Th is happens because the imputation routine will 
borrow information from similar individuals who are  not  in the same group. In this case, if data 
are missing at the group level (Level 2) for individuals in the data set, we must ensure that the 
same value is imputed for the group variable for all individuals within the group. We recommend 
that analysts ﬁ rst check the data for “stray” missing values for Level 2 variables for individuals at 
Level 1. Values for Level 2 covariates for individuals within each unit should be inserted where 
they are missing, so that no individuals will be dropped from the unit where that information is 
available for other subjects within the unit. 
 Th e bigger problem is where data on a Level 2 covariate is missing for all members of a par-
ticular unit. In two-level designs, the selection of students within a school cannot be considered 
as independent observations, since the students selected within the school will likely have some 
common characteristics (Organization for Economic Cooperation and Development, 2009). As-
suming independence of observations (i.e., simple random sampling) simpliﬁ es analyses but gen-
erally tends to lead to mild to severe underestimation of standard errors (Kish, 1987). In  Table 
1.7 we provide a simple multilevel analysis to illustrate the potential eﬀ ects of missing data at 
Level 2 on the analysis. In this case, we start with a complete sample of 1,000 students randomly 
selected from within 139 schools, which were randomly selected from some 180 schools in the 
database. We speciﬁ ed a two-level simple model with one predictor at each level and a random 
intercept. 
 Th e coeﬃ  cients in column 1 of  Table 1.7  suggest that community socioeconomic status 
( CSES ), which is reverse coded, and  lowSES  are statistically signiﬁ cant ( p  .05) in explaining 
students’ reading scores. In columns 2–5, we illustrate several possible approaches for dealing 
with missing data. In column 2, we eliminated data regarding school SES composition in 24 of 
the 139 schools (17.3%). We assume the school-level data are MAR. To simplify matters, at the 
individual level, there was no missing data. Because of the missing data on the Level 2 covariate, 
however, we lose nearly 30% of the Level 1 student data (i.e., 289/1,000  28.9%). In columns 
3–5, we used FIML estimation or MI to deal with the missing Level 2 data. 
 In column 2, we can see the listwise results indicate that both  CSES  and  lowSES  aﬀ ect stu-
dents’ reading scores ( p  .05); however, with nearly 20% missing data at Level 2 and a result-
ing 30% missing data at Level 1, the listwise analysis appears to be a bit further away from the 
original estimates than the other approaches we demonstrated in estimating both the  CSES 
and  lowSES  parameters. We suspect this is due to the eﬀ ect of the missing data on the school 
SES variable, which we can see may inﬂ uence both Level 2 and Level 1 estimates. We note that 
listwise results will typically produce the largest errors in estimating the parameters (since the 

Introduction to Multilevel Modeling with IBM SPSS  27
sample size may be severely reduced), as well as reduced power, which can both lead to errors in 
interpreting the results. 
 In column 3, we present the results of FIML estimation with missing data (estimated with 
Mplus), which appears to do a reasonable job of recapturing the original estimates in the com-
plete data set presented in column 1. In addition to the intercept, the FIML approach accurately 
estimates  lowSES . In contrast, however, the estimate for the  CSES  covariate (–7.39) is not as 
close to the estimate in column 1, since it was generated from nearly 20% missing data on the 
covariate at Level 2. In this speciﬁ c example, we suspect this estimate is a bit stronger because the 
reverse-coded mean  CSES  of the missing schools was about 0.37 of a standard deviation higher 
than the set of schools with complete data on this covariate. What this means is that there were 
higher percentages of students participating in the federal free/reduced lunch program in those 
schools. Th is would overattend to the schools where there are lower percentages of low-income 
students in generating the school-level estimate. 
 In column 4, we report results using ﬁ ve imputed data sets at Level 2 with specialized multi-
level software to estimate the missing data at that level (i.e., Mplus). We obtained these estimates 
by specifying our multilevel model in Mplus and then using the MI routine to impute missing 
values (assuming the data at Level 2 were MAR). Th e estimates in column 4 represent the aver-
aged output from the ﬁ ve data imputations we conducted (Muthén & Muthén, 1998–2006). 
Mplus has this MI capability beginning in Version 6. We can see that the averaged results across 
ﬁ ve data imputations produce an estimate of the Level 2 ﬁ xed eﬀ ect for  CSES  that is quite close 
to the actual estimate with the complete data. 
 Finally, in column 5, we present results from SPSS using the MI routine for our Level 2 
school sample (estimated separately). We remind readers that if they attempt to impute plausible 
values using the MI routine in IBM SPSS without ﬁ rst separating the Level 2 variables from 
the larger database, the program will impute diﬀ erent “random” values for the group covariate for 
individuals within the same unit since it does not recognize “random eﬀ ects” due to clustering. 
Th is, of course, would be impossible in terms of producing an accurate analysis of the eﬀ ects of 
Level 2 predictors on the outcomes in a study since the deﬁ nition of clustering within multilevel 
analysis is that all individuals within a given unit are assigned the same values on Level 2 predic-
tors. Imputing values into the Level 2 data set might be viable if we know the process through 
which units were selected at Level 2 (e.g., simple random sample or stratiﬁ ed random sample). 
 TABLE 1.7 Comparison of SPSS and Mplus Results 
Variables
SPSS 
Complete
 SPSS 
Listwise
Mplus FIML
Mplus 
Impute 
(N = 5)
SPSS 
Impute
(N = 5)
Between Schools
  Intercept
642.58*
641.86*
642.05*
641.88*
642.26*
  CSES
–6.09*
–7.73*
–7.39*
–6.05*
–6.09*
Within Schools
  Low SES
–12.22*
–10.41*
–12.16*
–12.49*
–12.37*
Variance Components
  Level 2 Intercept
45.83 
60.24
52.70
49.82
54.14
  Residual 
1,654.55* 
1,627.85*
1,643.28*
1,645.73*
1,645.59*
Sample Size
  Level 1 Students
1,000.00
711.00
1,000.00
1,000.00
1,000.00
  Level 2 Schools 
139.00
115.00
139.00
139.00
139.00
 * p  .01. 

28  Introduction to Multilevel Modeling with IBM SPSS
A common problem, however, is that in many multilevel studies the number of Level 2 units 
available tends to be considerably smaller and, therefore, less likely to represent a “randomly 
sampled” population of units. We therefore need to keep the likely  distribution  of Level 2 units 
in mind since our assumption about the nature of the Level 2 units will certainly aﬀ ect estimates 
that might be generated. If we can assume the data at Level 2 are MCAR (or more likely MAR), 
we may be able to provide reasonable estimates for missing data on one or more covariates. 
 In order to impute plausible values for the Level 2 covariate, we used existing information 
about  CSES  drawn from the 115 schools with existing data on this variable, as well as informa-
tion from aggregated unit means for each unit that we created from the complete Level 1 data 
set. More speciﬁ cally, we aggregated student data on reading scores and individual SES to gener-
ate means on these variables for each unit. Using Level 1 information about each unit helped in 
generating better “plausible” values for community SES at Level 2 in those units that were miss-
ing data. It is generally important to include information about the dependent variable in the 
imputation model; otherwise, the imputed values will not have the same strength of relationship 
to the dependent variable that the observed values do. 
 We reiterate the point that the MI approach has the advantage of incorporating some vari-
ability in the Level 2 estimates that are saved into separate data sets. Readers should keep in 
mind that imputing values at Level 2 may not adequately deal with the nature of the random ef-
fects present. Again, this relates back to assumptions about the sampling process through which 
units and individuals were selected. Even in this simple case, we noted considerable variation in 
the size of the estimates, their standard errors, and their statistical signiﬁ cance. We suspect that 
in many situations, it is probably reasonable to consider the Level 2 units as comprising a ran-
dom sample of a population (i.e., each unit has an equal probability of being selected), even if in 
practice this assumption may be violated, which can lead to some underestimation of sampling 
variance (Kish, 1987). Sample weights at Level 2 are created to deal with these types of selection 
probability issues, but they are not available in many multilevel data sets. Our practical experi-
ence with imputing plausible values suggests that this problem can become more important 
where there are small numbers of Level 2 units available for analysis (or where there are only a 
few individuals within each unit). For example, smaller samples will lead to greater imputation 
errors, which necessitate increasing the number of imputations conducted (OECD, 2009). Ac-
curately estimating variance parameters typically takes much more data than estimating ﬁ xed 
eﬀ ects. Using MI procedures in some fashion would certainly require imputing a sizable number 
of Level 2 sets of estimates (perhaps 30 or more) where there is 20% or so missing data (e.g., see 
Bodner, 2008; Larsen, 2011). Th is would provide a broader distribution of values. Th is might be 
a reasonable approach for Level 2 data, where there are a relatively large number of units in the 
study (as in our example) and the assumption of MAR can be made. 
 No deﬁ nitive conclusion should be drawn from this simple illustration in  Table 1.7 . Our point 
is simply to suggest that missing data can have a considerable inﬂ uence on the credibility of our 
modeling results. It is a problem that should be addressed in preparing the data for analysis. On 
a positive note, in this example, the estimates for the three ﬁ xed parameters and variance compo-
nents in columns 2–5 all covered the 95% conﬁ dence intervals in the original set of estimates in 
column 1. From this preliminary analysis, if we were preparing the data for further analysis, we 
would likely conclude that the data are MAR instead of MCAR since the listwise results were 
diﬀ erent substantively. We might choose either the MI or FIML estimation with missing data 
as viable approaches to use in examining these data. 
 Missing Data in Vertical Format in IBM SPSS MIXED 
 As we noted in the previous section, at present IBM SPSS does not generally support FIML es-
timation in situations where there may be observations missing, as is found in typical SEM soft-
ware programs. What this means is that the cases with missing values are simply dropped from 

Introduction to Multilevel Modeling with IBM SPSS  29
the analysis. Where the data set is vertically arranged (e.g., where a single individual may have 
repeated observations that comprise several rows in the data set), however, only that particular 
occasion will be dropped if there is a missing value present on the outcome. We also illustrate this 
situation in the next section. If covariates are missing, however, the subject will also be listwise 
deleted, which will lead to bias if the data are in fact MAR (Larsen, 2011). 
 Besides repeated measures data, arranging the outcome data vertically can also be useful in 
situations where an analyst may wish to examine several univariate outcomes (e.g., results on a 
reading, math, and language test). If there are considerable missing data on each outcome, treat-
ing the outcome as multivariate (i.e., with vertical arrangement of the data at Level 1) can result 
in keeping most of the missing data since only cases where data are missing on all outcomes 
will be dropped. We note that keeping participants with partial data is important for justifying 
the MAR assumption (Hox, 2010). We provide a simple illustration of retaining missing cases 
due to vertical arrangement in  Table 1.8 , where there are three observations per individual (e.g., 
three successive math scores) and diﬀ erent patterns of missing data for each particular individual. 
SPSS can handle diﬀ erent missing data patterns (i.e., missing on the ﬁ rst occasion, the second 
or third occasion, or various multiple occasions) and amounts of missing data. Some individuals 
 TABLE 1.8 Vertical Data Format 
Subject
Time
Score
01
0
4
01
1
01
2
6
02
0
5
02
1
8
02
2
03
0
6
03
1
8
03
2
9
04
0
04
1
04
2
7
 TABLE 1.9  Model Dimension a Table
Number of 
Levels
Covariance 
Structure
Number of 
Parameters
Subject 
Variables
Number of 
Subjects
Fixed Effects
Intercept
1
1
time
1
1
Random Effects
Intercept
1
Variance 
Components
1
Subject
Repeated Effects
time
3
Identity
1
Subject
4
Total
6
4
 a Dependent variable: score. 

30  Introduction to Multilevel Modeling with IBM SPSS
have no missing observations, some have missing data on one occasion, and some have missing 
data on two occasions. As long as  Y is not missing on all occasions, the program will come up 
with an “estimated” growth over each time interval, as well as an initial status (intercept) estimate, 
even though the initial data point is missing for subject 4. 
 We provide the model dimension table from this model in  Table 1.9 . It shows that all four 
subjects are retained in the analysis. Th is can be important information for analysts concerning 
how many individuals in the data set are actually being included in the analysis. 
 Design Effects, Sample Weights, and the Complex Samples Routine in IBM SPSS 
 When working with secondary data sets, applying sample weights is important to correct the 
analyses for features of the sampling design (e.g., probability of selection at multiple levels of the 
data hierarchy) and data collection problems (Th omas & Heck, 2001). Procedures for the selec-
tion of Level 2 units and individuals within those units can vary from being simple (e.g., simple 
random sampling at each level) to relatively complex. Weights may be available only at the indi-
vidual level (Level 1) or the group level (Level 2), or they may be available at both levels. Cur-
rently, there are no commonly established procedures for applying weights in multilevel analyses, 
although a considerable number of diﬀ erent approaches have been proposed (e.g., Asparouhov, 
2005, 2006; Grilli & Pratesi, 2004; Jia, Stokes, Harris, & Wang, 2011; Pfeﬀ ermann, Skinner, 
Holmes, Goldstein, & Rasbash, 1998; Stapleton, 2002). 
 Th e consideration of sample weights and design eﬀ ects are vitally important in analyses using 
disproportionate sampling and multistage cluster samples. Disproportionate sampling will lead 
to samples that overrepresent certain segments of the populations of interest. Typically, this re-
sults from the researcher’s interest in including a suﬃ  cient number of subjects (or objects) from 
smaller but important subpopulations. Sampling members of such groups proportionally often 
results in too few sample members to allow meaningful analyses. We therefore oversample many 
groups to ensure suﬃ  cient numbers in the ﬁ nal sample. Th e result is that the analytic sample is 
not representative of the true populations since it has too many sample members from the overs-
ampled groups. Sample weights, typically probability or frequency weights, are used to readjust 
the sample to be representative of the population from which it was drawn. Failure to use a 
sample weight in these instances can result in incorrect parameter estimates, biased in the direc-
tion of the oversampled members of the population (Th omas & Heck, 2001). 
 Disproportionate sampling is often found in multistage cluster samples. Cluster sampling is 
simply where the researcher ﬁ rst draws a sample at a higher level—organizations, for example—
and then draws a sample of lower level units within each organization—employees, for example. 
Th e units at each level may or may not be drawn proportionate to their presence in the larger 
population. To illustrate this point, if one were to sample organizations, for some substantive 
reason related to the research purposes, it might be desirable to oversample rural organizations. 
If this were to occur, one would want to be sure to adjust for this at the organizational level by 
using a Level 2 (organizational) weight in the same fashion that the Level 1 individual weight 
discussed previously was used. Hence, there can be sampling weights for each level of the data, 
although we note that many currently available data sets do not include weights at multiple levels 
of the data hierarchy. 
 To the degree that the observations within each of the higher order clusters are more similar 
to each other, there will be a  design eﬀ ect  present that biases the estimated standard errors down-
ward. Because hypothesis tests are based on the ratio of the estimate to its standard error, having 
standard errors that are too small will lead to a greater propensity to commit a Type I error (i.e., 
falsely concluding that an eﬀ ect is statistically signiﬁ cant when it is not) than if the sample were 
drawn through a simple random-sampling procedure. Th e design eﬀ ect is deﬁ ned as the ratio 
of the biased standard error to the standard error that would be estimated under a true random 
sample design. So, for example, if we know that the true standard error was 1.5, but the biased 

Introduction to Multilevel Modeling with IBM SPSS  31
standard error estimated from the data collected through the multistage cluster sample was 1.2, 
the calculated design eﬀ ect would be 1.5/1.2  1.25. 
 One standard measure of this within-unit (dis)similarity is the intraclass correlation. As we 
have noted earlier in the chapter, the ICC is the proportion of total variance in the outcome due 
to within-unit diﬀ erences at higher levels. Th e higher the ICC, the larger will be the design ef-
fect. Hox (2010) notes that the ICC can be viewed as another way to think about the degree of 
correlation within clusters. An ICC of 0.165, which suggests that 16.5% of the variance in the 
individual-level outcome exists  between  clusters, could also be viewed as an indication that one 
might expect a within-cluster correlation of 0.165 between individuals. Th is conceptual con-
nection between the ICC and within-cluster correlation is important in understanding design 
eﬀ ects. In short, the greater the between-cluster variance in the individual-level outcome, the 
more homogenous will be the individual observations within each of the clusters. To the extent 
that there exist within-cluster similarities, estimates of the Level 1 variances will be smaller than 
they would be if the sample were collected through a simple random sample design (where such 
clustering would be irrelevant to the variance structure). Th e implication central to our interests 
is that ignoring the clustering that is part of the sample design will yield downwardly biased 
estimates of the standard error. 
 Th e last several versions of SPSS have made available a COMPLEX SAMPLES module that 
allows the user to incorporate design information into the model to adjust for the design eﬀ ects 
described previously. Th is module produces results for single-level models incorporating design 
information and sample weights. As such, the parameter estimates are adjusted for both dispro-
portionate sampling and cluster sampling. In the single-level context, this is the appropriate way 
to analyze data collected through complex sample designs. In this type of approach, similarities 
among individuals due to clustering are treated as “noise,” which is adjusted out of the analysis, 
rather than considered as the focus of the analysis. 
 Multilevel models, by design, capitalize on the clustered nature of data, and it is quite common 
to see these models used with large-scale survey data that have been collected through complex 
sample designs. Th e same cautions outlined previously apply to estimates produced using vari-
ous forms of multilevel models. Although multilevel models capitalize on the clustered nature of 
the data, they do nothing to address disproportionate sampling, and, without proper weighting, 
they will produce incorrect parameter estimates. Sample weights are often essential to generate 
accurate estimates. 
 Weighting for unequal selection is relatively well established for single-level analyses. Th e 
COMPLEX SAMPLES module allows adjustments to be made for sample design eﬀ ects 
(which can include clustering)—but maintains a single-level analysis after adjustment for fea-
tures of the sampling scheme. In this type of approach, similarities among individuals due to 
clustering are treated as unwanted variance that is adjusted out of the analysis. In contrast, 
standard two-level models can result from two-stage cluster sampling designs (rather than the 
basic simple random or stratiﬁ ed samples that comprise the majority of single-level analyses). 
One document that does discuss multilevel models as complex sampling models within IBM 
SPSS is the  PISA Data Analysis Manual (OECD, 2009). Because SPSS cannot at present deal 
with sample weights at two-level results from these types of sampling designs, it can give a 
preliminary indication of relationships in models where sample weights exist but should not be 
relied on to provide ﬁ nal, unbiased estimates, even when using plausible values as the dependent 
variable (OECD, 2009). 
 In contrast to weighting in single-level analyses, developing weighted analyses in the multi-
level context presents a number of more complicated challenges and limitations. Research in this 
area is ongoing, and important advances have been made over the past 10 years. Most multilevel 
software programs now include one or more weighting options. Several programs with which 
we are familiar (HLM 7, LISREL 8.8, and Mplus 7) incorporate design weights that combine 
information on clustering, the degree of intraclass correlation, and disproportionate sampling 
www.allitebooks.com

32  Introduction to Multilevel Modeling with IBM SPSS
to create a set of scaled weights that will produce accurate estimates at each level of analysis. 
Although IBM SPSS allows for the incorporation of simple sample weights (an approximate 
frequency weight) in the MIXED and GENLINMIXED routines, the current version does not 
enable a scaling adjustment that accommodates the eﬀ ects of clustering in the sample design. As 
we noted earlier in this chapter, this is an important limitation of the IBM SPSS program for 
conducting multilevel analyses. 
 A number of factors can inﬂ uence the estimation of model parameters. Th ese factors include 
the method of scaling the weights at Level 1 (i.e., how weights are scaled within the clusters), the 
size of the clusters, the relative invariance of the selection method applied to clusters (referred 
to as informativeness), the presence of missing data, and the intraclass correlation (Asparouhov, 
2006). Th e scaling of Level 1 sample weights is very important in the multilevel context, helping 
to improve eﬃ  ciency and decrease bias in estimation (Pfeﬀ erman et al., 1998; Skinner, 2005). 
Asparouhov explains that the scaling of the weights at Level 1 involves multiplying the weights 
by a scaling constant, so that the sum of the weights is equal to some kind of characteristic of the 
cluster (e.g., cluster size). 
 An Example Using Multilevel Weights 
 We provide one simple example of a comparison between results we obtained with Mplus, which 
has the capability of incorporating Level 1 and Level 2 weights into multilevel analyses, and the 
unweighted estimates obtained through using MIXED. In the example, there are 5,952 students 
nested in 185 schools with a continuous outcome. In  Table 1.10 , we ﬁ rst provide unweighted 
estimates for the within- and between-group variables using IBM SPSS MIXED. We next 
provide unweighted estimates and weighted estimates using Mplus. For Mplus, Level 1 weights 
were scaled within Level 2 units such that the sum of these weights equals the size of the respec-
tive Level 2 unit (Asparouhov, 2006). 
 Th e results suggest that providing proper weights can aﬀ ect both the size of the estimated 
coeﬃ  cients as well as the calculation of the standard errors at both Level 1 and Level 2. First, the 
estimates of average school achievement are quite diﬀ erent in the unweighted versus weighted 
estimates. For example, the unweighted SPSS and Mplus estimates of the adjusted level of 
achievement are very similar (543.02 and 542.94, respectively). Th e weighted estimates, which 
take into consideration the proper representation of the schools in the stratiﬁ ed sample drawn 
from the population, are considerably lower at 515.03 than the unweighted estimates. 
 Second, at the school level, we notice one diﬀ erence in the pattern of hypothesis testing. Be-
cause hypothesis tests are based on the ratio of the estimate to its standard error, on many occa-
sions we can note diﬀ erences in signiﬁ cance testing of estimates in unweighted versus weighted 
solutions. In the unweighted solutions, school SES and school type (i.e., private or public) are 
the only signiﬁ cant predictors of math scores. In the weighted solution, however, the hypothesis 
test for curriculum orientation ( academic ) is signiﬁ cant (15.60,   p < .05), but it is not in the two 
unweighted solutions provided. Regarding the slope model, we can see that students who receive 
outside tutoring have signiﬁ cantly lower math scores in both the unweighted and weighted so-
lutions. Th ere is a considerable diﬀ erence in the size of the randomly varying slope (regarding 
students who receive outside tutoring in math). More speciﬁ cally, the unweighted estimates are 
approximately ‒17.4 versus the weighted estimate of ‒24.0. Similarly, the cross*level interaction 
( tutoring*School SES ) is also diﬀ erent—that is, approximately 31.0 in the unweighted sample and 
42.6 in the weighted sample. Th ese results suggest that students who are likely to get tutoring 
in high SES school settings are more highly achieving than their peers in schools at the grand 
mean of school achievement. For example, at 1  SD above the grand mean, the advantage would 
be about 18.7 points in the standardized math test (–23.98  42.63  18.65). 
 Finally, we note considerable diﬀ erences in calculating the variance components in the 
weighted and unweighted models in  Table 1.10 . Despite these diﬀ erences, however, in all three 

Introduction to Multilevel Modeling with IBM SPSS  33
 TABLE 1.10 Unweighted and Weighted Level 1 and Level 2 Estimates Explaining Math 
IBM SPSS
Mplus
Unweighted
Estimates
SE
Unweighted
Estimates
SE
  Weighted
Estimates
SE
School Model
 Intercept
543.02**
7.97
542.94**
7.56
515.03**
7.75
 SchSES
141.80**
9.95
141.82**
9.88
131.36**
11.87
 Public
–57.08**
7.18
–57.11**
6.75
–55.57**
6.91
 Academic
10.25
7.81
10.41
7.25
15.60*
7.76
 City
–2.37
6.94
–2.30
7.06
5.23
8.82
 Large City
6.93
8.25
6.82
8.03
8.40
9.23
Individual
 SES
7.75**
1.33
7.76**
1.54
6.87**
2.08
 Female
–16.40**
1.81
–16.42**
1.96
–14.04**
2.66
Slope Model
 Tutoring
–17.42**
2.87
–17.41**
2.96
–23.98**
4.58
 Tutoring*SchSES
31.02**
7.72
31.10**
7.56
42.63**
8.40
Random Effects
 Residual
3,693.79**
69.59
3,692.37**
89.82
3,849.48**
128.24
 Level 2(I)
1,466.58**
168.27
1,413.14**
166.00
1,360.03**
195.40
 Level 2(S)
173.09
120.46
158.05
109.05
284.20
188.17
 * p   .05; ** p  .01. 
models, after accounting for school SES, we note there is not signiﬁ cant random variance in 
slopes left to explain across schools ( p > .05). We emphasize that no deﬁ nitive conclusions should 
be drawn from this one simple comparison of unweighted and weighted multilevel results. We 
provide these results only to make the point that using sample weights, and using them correctly, 
does make a diﬀ erence in the accuracy of the estimates obtained and certainly can aﬀ ect the as-
sociated hypothesis tests in multilevel analyses. 
 Although many of the software programs used for estimating multilevel models enable the 
appropriate scaling, IBM SPSS does not yet include this feature. If sample weighting is essential 
to the analysis, it will likely be better currently to use another of the available programs or to 
revert to a single-level formulation within SPSS through its COMPLEX SAMPLES module. 
More speciﬁ cally, as Asparouhov (2006) suggests, if sampling weights present in a secondary data 
set are designed for a single-level analysis, it may be best to stick with that type of design and 
conduct a single-level analysis designed for stratiﬁ ed- and cluster-sampling designs. Asparouhov 
provides two contrasting situations illustrating this point. First, he suggests that when weights 
are only present at Level 2 (i.e., where clusters have been sampled with unequal probability), we 
can identify this situation as being within the framework of single-level weighted modeling, and 
methods available for single-level weighted analysis can be applied with consistent estimations 
regardless of the size of the clusters. Although the model is multilevel, the nature of the weight-
ing is not. Of course, if sample weights are also provided at Level 1, this will change. Second, he 
cautions that the situation is diﬀ erent when weights are only provided at Level 1, as the unequal 
probability of selection is applied to dependent units, and, therefore, the assumptions of the 
single-level method of analysis will be violated. 
 Th e bottom line is that if the single-level sample weights cannot be properly scaled to the 
multilevel context, it may be better to use the single-level approach. Th is threat may be more 

34  Introduction to Multilevel Modeling with IBM SPSS
severe when estimating models with categorical outcomes (Rabe-Hesketh & Skrondal, 2006). 
We are hopeful that the application of multilevel sampling weights will be included in future 
versions of the software. In the interim, we call attention to recent work by Chantala, Blanchette, 
and Suchinindran (2011) providing SAS and Stata routines to generate scaled weights that could 
be imported into other multilevel software programs (such as IBM SPSS). 
 Summary 
 In this chapter, we have developed a context and rationale for the use of multilevel models in 
the social and behavioral sciences. Th e use of multilevel analysis can add substantive information 
about how processes unfold at various levels of a data hierarchy. We suggested that multilevel 
techniques support the speciﬁ cation of more complex theoretical relationships than is possible 
using traditional single-level regression analyses. Analytic approaches that can be used to model 
complex relationships have greatly expanded over the past couple of decades, and these analytic 
alternatives allow us to investigate social processes in more theoretically and methodologically 
appropriate ways. Substantive progress in a ﬁ eld is often achieved when headway occurs simul-
taneously on conceptual and methodological fronts. 
 One attractive feature of SPSS MIXED is that it is not limited in terms of the number of 
levels in a nested or cross-classiﬁ ed data structure that can be analyzed simultaneously. Th e abil-
ity to specify multiple RANDOM (i.e., randomly varying intercept and slopes) commands at 
successive levels of a data hierarchy facilitates investigating a variety of multilevel models that 
are diﬃ  cult, or not currently possible, to estimate optimally in other software packages. As with 
most current software programs, however, adding levels to examine in a data hierarchy, randomly 
varying parameters, and cross-level interactions can greatly increase the amount of time it takes 
to produce a solution (i.e., from seconds to several hours) and will require increasingly large 
amounts of memory and disk space as models become more complex. 
 We see another advantage in MIXED concerning the easy manner in which various types of 
covariance structures can be speciﬁ ed at diﬀ erent levels of the data hierarchy. Our comparison of 
IBM SPSS MIXED with other multilevel software suggests that the program produces results 
substantively consistent with other programs, given similar model speciﬁ cation. Given our as-
sessment of these limitations and several advantages, we feel that using IBM SPSS to investigate 
multilevel and longitudinal models is a useful way in which to introduce researchers to the uses 
and beneﬁ ts of multilevel modeling since it takes immediate advantage of a software program 
they are likely to have encountered already in their quantitative preparation. 
 In the next chapter, we take care of a bit of housekeeping by providing an overview of some 
important data management techniques. Arranging the data for analysis in IBM SPSS is fairly 
straightforward. We provide readers with a few essential steps necessary to put their data sets in 
proper order for analysis using MIXED.  

35
 CHAPTER 2 
 Preparing and Examining the Data 
for Multilevel Analyses 
 E
ssential to any type of analysis is the organization and vetting of the data that will be ana-
lyzed. In this chapter, we identify a number of practical and substantive issues associated 
with preparing data for analysis in IBM SPSS MIXED and assessing the adequacy of those data 
for a variety of multilevel analyses. 
 Data Requirements 
 In this workbook, we deal exclusively with multilevel models using continuous-level outcomes. 
While other multilevel statistical programs including IBM SPSS can accommodate binary or 
ordinal outcomes, MIXED is restricted to outcomes measured on a continuous scale. Although 
we deal only with continuously measured outcomes, predictors can be continuous, ordinal, or 
dichotomous. 
 Th e sample sizes we employ throughout our examples are large at each level of the analysis. 
Th e variables used may come from a variety of diﬀ erent sources, many of which are speciﬁ c 
to a particular level of analysis. One might, for example, draw on student-level attitudinal, 
behavioral, or performance data from national surveys such as the  National Educational Lon-
gitudinal Study of 1988 (Curtin, Ingels, Wu, & Heuer, 2002). If an objective were to under-
stand the eﬀ ects of school settings on these individual characteristics, we might assemble 
school-level data drawing on information from the Common Core of Data (Sable & Noel, 
2008). School-level data might include school size, demographic composition, ﬁ nancial char-
acteristics such as state dollars per enrolled student, on-time progression or graduation rates, 
teacher and administrative numbers, and the like. To carry this to a third level, we could draw 
on U.S. Census data to deﬁ ne characteristics of the school districts in which the schools at 
Level 2 were located (e.g., household income, number of people in the household, their levels 
of education, etc.). 
 We will show that there are many variants on this modeling framework. We might, for ex-
ample, want to understand change in some outcome over time. In such an instance, we might 
conceptualize time points across which we presume change to occur within students who could, 
in turn, be nested within schools, and so on. However the nesting is conceptualized, each level 
of analysis will have its own set of variables deﬁ ning features of the units being measured at that 
level. While conceptualizing data at discrete levels of the hierarchy may be relatively straightfor-
ward, organizing the data set requires an understanding of how the data need to be arranged to 
represent that hierarchical conceptualization correctly. In the next section, we outline the main 
organizational features of data sets that can be used in a multilevel analysis. We return to data 
requirements in more detail in a subsequent section. 

36  Preparing and Examining the Data for Multilevel Analyses
 File Layout 
 We described in the previous chapter an important diﬀ erence between the single-equation and 
multiple-equation approaches to estimating multilevel models. Th e multiple-equation approach 
(e.g., used in HLM) requires a separate data set for each level of data being analyzed. Th is can 
make conceptualization of the diﬀ erent levels clear. If Level 1 consisted of 6,871 students, for ex-
ample, the Level 1 ﬁ le would contain student data, including information about higher order group 
membership (e.g., the classroom or school membership for each of the 6,871 students in the ﬁ le). 
 Figure 2.1  shows what such a Level 1 ﬁ le might look like based on the data set used in Chapter 3.
In this particular example ( ch2level-1data.sav ), we have included a student identity (ID) 
variable ( id  ), a school ID variable ( schcode ), and three variables describing student characteristics, 
gender (   female ), socioeconomic status on a normalized scale ( ses ), and a raw math score ( math ). 
 If Level 2 in the analysis consisted of schools of which students were members, the Level 2 
data set would contain all information about those 419 schools, including a unique school identi-
ﬁ er, and perhaps aggregated data from the Level 1 student ﬁ le given previously. 
 Th e Level 2 ﬁ le ( ch2level-2data.sav ) shown in  Figure 2.2  contains a unique school identiﬁ er 
( schcode ) and two variables describing the characteristics of the school, average socioeconomic status 
( ses_mean ) and the proportion of students planning to attend a 4-year college ( per4yrC ). Th e data 
sets are linked through a group-level identiﬁ er (in this case,  schcode ) during the multilevel analysis. 
 In contrast, the single-level approach makes use of one ﬁ le that combines data from each 
level ( Figure 2.3 ). In the univariate multilevel model, the ﬁ le will consist of one record for each 
Level 1 unit. Values for variables from higher levels will be constant within groups. For example, 
in a data set ( ch2level-1&2data.sav ) with 6,871 students from 419 schools, there would be a 
single ﬁ le of 6,871 records. Th e values for the student-level variables would vary across all 6,871 
students. However, values on the school-level variables would be constant within each of the 
419 schools—that is, students within each school would all have the same value on each of the 
school-level variables. 
FIGURE 2.1 A Level 1 data ﬁ le (multiple-equation approach, N = 6,871).

FIGURE 2.2 A Level 2 data ﬁ le (multiple-equation approach, N = 419).
FIGURE 2.3 Combined multilevel data ﬁ le (single-equation approach, N = 6,871).

38  Preparing and Examining the Data for Multilevel Analyses
 IBM SPSS MIXED uses the single-equation approach and one omnibus ﬁ le containing data on 
each level of the analysis. In the sections that follow, we provide an overview of some of the data 
management steps within IBM SPSS that will help you organize and prepare your data and ﬁ les 
for use within the MIXED routine. 
 Getting Familiar with Basic IBM SPSS Data Commands 
 Organizing and managing the data at various levels is accomplished through ﬁ ve basic IBM SPSS 
procedures. Th ere are, of course, many other procedures that can be used to modify a data set, but we 
feel that these are primary to the data management tasks associated with organizing ﬁ les for multi-
level analyses within IBM SPSS. We will have much more to say about the IBM SPSS commands 
and the menu system itself in the chapters that follow. Here, however, we wish only to introduce these 
commands and a few principles of data management that we think will prove helpful for getting the 
most out of the workbook. Th e ﬁ ve primary procedures are (in order of importance) the following: 
 1.  RECODE : Changes, rearranges, or consolidates the values of an existing variable. 
 2.  COMPUTE : Creates new numeric variables or modiﬁ es the values of existing string or 
numeric variables. 
 3.  MATCH FILES : Combines variables from IBM SPSS-format data ﬁ les. 
 4.  AGGREGATE : Aggregates groups of cases in the active data set into single cases and cre-
ates a new aggregated ﬁ le or creates new variables in the active data set that contain aggre-
gated data. Th e values of one or more variables in the active data set deﬁ ne the case groups. 
 5.  VARSTOCASES : Restructures complex data structures (i.e., in which information about 
a variable is stored in more than one column) into a data ﬁ le in which those measurements 
are organized into separate rows of a single column. 
 In this section, we will build a multilevel data set using each of the primary commands identiﬁ ed 
previously. 
 Th e data set we use here ( ch2multivarML1.sav ) is based on the example used in Chapter 5 
but is modiﬁ ed to exclude missing data. Th e data set contains three raw test scores taken over 
time ( test1 ,  test2 , and  test3 ), dichotomous indicators of teacher eﬀ ectiveness ( eﬀ ective ) and gender 
( female ), a continuous variable capturing the number of Advanced Placement courses a student 
has taken ( courses ), and a continuous measure of family socioeconomic status ( ses ). Th ere is also 
an identiﬁ er for students ( id ) and for the schools in which they are enrolled ( nschcode ). Th e de-
scriptive statistics in  Table 2.1  show that there are 8,335 records in the data set. Each record 
represents a single student.  Figure 2.4  displays a partial view of the data structure. 
TABLE 2.1 Descriptive Statistics
N
Minimum
Maximum
Mean
Std. Deviation
id
8,335
1.000
8,670.000
4,308.352
2,510.578
nschcode
8,335
1.000
525.000
261.976
152.817
test1
8,335
24.350
69.250
47.644
6.325
test2
8,335
27.480
74.780
52.379
7.781
test3
8,335
26.960
79.720
57.109
9.450
effective
8,335
0.000
1.000
0.562
0.496
courses
8,335
0.000
4.000
0.748
0.790
female
8,335
0.000
1.000
0.505
0.500
ses
8,335
–2.410
1.870
0.034
0.784
Valid N (Listwise)
8,335

Preparing and Examining the Data for Multilevel Analyses  39
 Recode: Creating a New Variable Through Recoding 
 We begin by demonstrating recoding old values to new values. For the ﬁ rst example, we recode 
the variable  time , which is measured on three linear occasions (0,1,2), to  quadtime , which is a 
“squared” quadratic sequence (0,1,4), to capture any changes (acceleration or deceleration) in the 
rate of change that might occur over the three measurement occasions. 
 Recoding Old Values to New Values 
 Th is example uses a trun-
cated version of a data set 
from Chapter 5 ( ch5growth-
data-vertical.sav ). (Refer to 
Chapter 5 for further discus-
sion and examples on coding 
time-related variables.) 
 Launch the IBM SPSS 
application program, and se-
lect the data ﬁ le  ch2growth-
data-verticalAbbr.sav . 
FIGURE 2.4 Horizontal data matrix.

40  Preparing and Examining the Data for Multilevel Analyses
  1. Go to the toolbar and select TRANSFORM, RECODE INTO DIFFERENT VARIABLES. 
 Th is command will open the  Recode into Diﬀ erent Variables dialog box. 
 
 2a.  Recode into Dif-
ferent Variables 
enables creating a 
new variable using 
a variable from the 
current data set. 
Click to select  time 
from the left col-
umn, and then click 
the right-arrow 
button to move the 
variable into the 
 Input Variable  
Output Variable box. 
 
 b. Now enter the new 
variable name by 
typing  quadtime into the  Output Variable Name box. 
 
 c.  Th en click the CHANGE button, which will add  quadtime  and complete the RECODE com-
mand for  time  quadtime . 
 
 d.  Click the OLD AND NEW VALUES button, which will then display the  Recode into Diﬀ erent 
Variables: Old and New Values screen. 
  3. Within the  Recode 
into Diﬀ erent 
Variables: Old and 
New Values , we 
will begin chang-
ing the  time values 
(0,1,2) to reﬂ ect 
 quadtime (0,1,4). 
 
 a.  Begin by enter-
ing the ﬁ rst 
value for  time 
(0) in the  Value 
(old) box. 
 
 b.  Next, enter the 
new value (0) 
for  quadtime in 
the  Value (new) 
box. 
 
 c.  Click the but-
ton to place the ﬁ rst command  0  0 into the  Old  New  box. 
 
 d.  Repeat steps 3a to 3c to complete the remaining coding changes for  quadtime values: 
  1  1 
  2  4 

Preparing and Examining the Data for Multilevel Analyses  41
  5. Th e new variable  quad-
time with its recoded 
values will be found in 
the last column of the 
data window. 
 (Th e two-decimal placement 
for  quadtime  may be changed 
in the  Variable View  window.) 
 Note: Th e asterisk displayed 
next to the ﬁ lename at the 
top of the display window is a 
reminder that the original ﬁ le 
has been changed. If you wish 
to save the modiﬁ cations made 
here, go to the toolbar and 
select FILE, SAVE. 
 Recoding Old Values to New Values Using “Range” 
 Our second task will be to create a new categorical SES variable by recoding  ses into a variable 
called  ses4cat  (suggesting that we are going to recode this into a four-category variable). We will 
use the  Range feature to recode three somewhat arbitrary cut points and create four categories 
for our recoded variable: ‒0.5180, 0.0250, and 0.6130 (these actually represent the 25th, 50th, 
and 75th percentiles, respectively). 
 Click the CONTINUE button to return to the  Recode into Diﬀ erent Variables main dialog box. 
  4. Click the OK but-
ton to generate the 
recoded variable 
 quadtime and corre-
sponding time values 
(0,1,4). 
www.allitebooks.com

42  Preparing and Examining the Data for Multilevel Analyses
 
 2a.  Recode into Diﬀ erent 
Variables enables creating 
a new variable using a 
variable from the current 
data set. Click to select 
 ses from the left column, 
and then click the right-
arrow button to move the 
variable into the  Input 
Variable  Output Vari-
able box. 
 
 b.  Now enter the new 
variable name by typing 
 ses4cat into the  Output 
Variable Name box. 
 
 c.  Th en click the CHANGE button, which will add  ses4cat  and complete the RECODE com-
mand for  ses  ses4cat . 
 
 d.  Click the OLD AND NEW VALUES button, which will then display the  Recode into Diﬀ erent 
Variables: Old and New Values screen. 
 
 3a.  Th e  Recode into Diﬀ erent 
Variables: Old and New Values 
screen displays multiple op-
tions. To deﬁ ne the ﬁ rst cut 
point (-.5180), click to select 
the option  Range, LOWEST 
through value . 
 
 b.  Now enter the value: -.5180. 
 
 c.  Next, enter “1” as the  New 
Value . 
 
 d.  Th en click the ADD button, 
which will place the ﬁ rst range 
command  Lowest thru -.5180 
 1 into the  Old  New box. 
 Launch the IBM SPSS application 
program and select the data ﬁ le  ch2multi-
varML1.sav 
  1.  Go to the toolbar and select 
TRANSFORM, RECODE INTO 
DIFFERENT VARIABLES. 
 Th is command will open the  Recode into 
Diﬀ erent Variables dialog box. 

Preparing and Examining the Data for Multilevel Analyses  43
 
 e.  Enter the second range of 
values by ﬁ rst clicking the 
 Range option. 
 
 f.  Now enter the low value of 
-.5181 and then the upper 
value limit of .0250. 
 
 g.  Next, enter “2” as the  New 
Value. 
 
 h.  Th en click the ADD 
button, which will place 
the ﬁ rst range command 
- .5181 thru .0250  2 into 
the  Old  New box. 
 
 i.  Th e third value also uses a 
range of values, but since 
the  Range option was se-
lected previously, only the 
values need to be entered. 
First, enter .0251 and then 
.6130. 
 
 j.  Next, enter “3” as the  New 
Value. 
 
 k.  Th en click the ADD but-
ton, which will place the 
range command  .0251 thru 
.6130  3 in the  Old  
New box. 
 
 l.  To deﬁ ne the ﬁ nal cut-
point value, click to select 
the  Range, value through 
HIGHEST  option. 
 
 m.  Now enter the value: .6131. 
 
 n.  Next, enter “4” as the  New 
Value . 
 
 o.  Th en click the ADD but-
ton, which will place the 
range command . 6131 thru 
Highest  4 into the  Old  
New box. 
 Click the CONTINUE button to 
return to the  Recode into Diﬀ erent 
Variables main dialog box. 

44  Preparing and Examining the Data for Multilevel Analyses
  4. Click the OK button 
to generate the recoded 
variable  ses4cat and cor-
responding values. 
  5. Th e new variable  ses4cat 
with its recoded cat-
egorical scores will be 
found in the last column 
of the data window. 
 You may also verify that the 
raw  ses scores conform to the 
categories deﬁ ned through 
the RECODE process. 
 Note: Th e asterisk located 
next to the data ﬁ le name at 
the top of the screen indi-
cates changes were made to 
the data. At the conclusion 
of each of the following nine 
tutorials, we will save the 
changes by overwriting the 
 ch2multivarML1.sav data 
ﬁ le (although you may prefer 
renaming the saved ﬁ le to 
preserve the original data 
ﬁ le). To save these changes, 
go to the toolbar, select 
FILE, SAVE. 
 Compute: Creating a New 
Variable That Is a Function 
of Some Other Variable 
 Suppose that we wanted to 
create a variable that was a 
summary of the three exist-
ing test scores. Using the 
TRANSFORM, COM-
PUTE VARIABLE menu 
command, we call up the 
COMPUTE VARIABLE 
dialog box. 

Preparing and Examining the Data for Multilevel Analyses  45
 Continue using the  ch2multivarML1.sav data ﬁ le. 
  1.  Go to the toolbar 
and select TRANS-
FORM, COMPUTE 
VARIABLE. 
 Th is command will open the 
 Compute Variable dialog box. 
 
 a.  Enter  testmean as the 
 Target Variable . 
 
 b.  Scroll down the 
 Function group list to 
locate, and then click 
to select the  Statistical 
group, which displays 
assorted statistical 
 Functions and Special 
Variables. 
 
 c.  Click to select the 
 Mean function, and 
then click the up-arrow button, which will place it in the  Numeric Expression box formatted as: 
MEAN(?,?). Th e question marks indicate the placement for a variable. 
 
 d.  Th e mean will be computed from three variables:  test1 ,  test2 , and  test3. To build the correspond-
ing numeric expression, click  test1 , and then click the right-arrow button to place the variable 
in the box. Note that a comma must appear following the variable: MEAN(test1,?). 
 
 e.  Continue to build the numeric expression by next clicking  test2 and then the right-arrow but-
ton to move the variable into the box: MEAN(test1,test2,?). 
 
 f.  Complete the numeric expression by clicking  test3 and then the right-arrow button to move the 
variable into the box: MEAN(test1,test2, test3). 
 Click the OK button to per-
form the function. 
  2. Scroll across the col-
umns, and the new 
variable  testmean with 
its computed mean from 
the three test scores is 
found in the last column 
of the data window. 
 You may also verify that the 
raw  testmean values represent 
the average of the three test 
scores for each individual in 
the data set. 

46  Preparing and Examining the Data for Multilevel Analyses
 Although we have created two new variables using the RECODE and COMPUTE com-
mands, our data ﬁ le is still strictly an individual-level (Level 1) ﬁ le. More speciﬁ cally, aside from 
the school ID,  nschcode , we do not have any variables that are school speciﬁ c and therefore do not 
have anything to analyze at Level 2. Typically, data from other sources would be brought in and 
merged with our Level 1 ﬁ le. If we had information about the schools these students attend (e.g., 
public or private control, etc.), we could very easily merge those data with the individual-level ﬁ le 
with which we have been working. 
 Match Files: Combining Data From Separate IBM SPSS Files 
 Th e MATCH FILES command allows us to combine data from diﬀ erent sources. To demon-
strate one use of this command, we will use the existing Level 1 ﬁ le with which we have been 
working. MATCH FILES can combine data in two general ways: by adding variables to the 
existing data set or by adding cases to the data set. We will limit our interest here to the addition 
of variables that are found in a separate data set. For our example, we are going to show how to 
merge a ﬁ le containing school-level information with our existing ﬁ le containing student-level 
data. We want to add information about the frequency of Advanced Placement testing at each 
school. Th e ﬁ le containing this information ( apexams.sav ) has two variables in it. Th e ﬁ rst is a 
school identiﬁ er that is the same as the school identiﬁ er used in our Level 1 data ﬁ le ( nschcode ). 
Th e second variable is named  apexams . It is a ratio of the number of Advanced Placement exams 
taken by students at the school to the total number of students in the 12th grade at the school. 
While our student-level (Level 1) ﬁ le contains 8,335 observations (i.e., the number of students), 
as shown in  Table 2.2 , the school-level (Level 2) ﬁ le shown in  Table 2.3  contains 525 observa-
tions representing the schools that the 8,335 students attend. Consider the contents of each 
ﬁ le given subsequently. Th e Level 1 ﬁ le will be the target for the data contained in the Level 2 
( apexams.sav ) ﬁ le; that is, we are going to merge the data from the Level 2 ﬁ le onto the records 
in the Level 1 ﬁ le. 
TABLE 2.2 Descriptive Statistics
N
Minimum
Maximum
Mean
Std. Deviation
id
8,335
1.000
8,670.000
4,308.352
2,510.578
nschcode
8,335
1.000
525.000
261.976
152.817
test1
8,335
24.350
69.250
47.644
6.325
test2
8,335
27.480
74.780
52.379
7.781
test3
8,335
26.960
79.720
57.109
9.450
effective
8,335
0.000
1.000
0.562
0.496
courses
8,335
0.000
4.000
0.748
0.790
female
8,335
0.000
1.000
0.505
0.500
ses
8,335
–2.410
1.870
0.034
0.784
Valid N (Listwise)
8,335
TABLE 2.3 Descriptive Statistics
N
Minimum
Maximum
Mean
Std. Deviation
nschcode
525
1.000
525.000
263.000
151.699
apexams
525
0.000
0.800
0.164
0.133
Valid N (Listwise)
525

Preparing and Examining the Data for Multilevel Analyses  47
 
 2a.  Within the  Sort Cases dialog box, 
select  nschcode from the left column, 
and then click the right-arrow button 
to transfer the variable into the  Sort 
by box. 
 
 b.  Th e default  Sort Order setting is  As-
cending  (low to high), which we will 
retain. 
 
 c.  Later versions of IBM SPSS (version 
20.0 forward) provide an option for 
saving the sorted data directly to a 
ﬁ le. We will forgo using this option 
for the current example. 
 Click the OK button to begin sorting the 
cases. Th e next step is to sort the cases for the 
secondary ﬁ le,  apexams.sav. 
 Because this is not a one-to-one match (i.e., there are not the same number of records in each 
ﬁ le), we will have to identify a “key” to be used to match the data from the schools to the data 
from the students. Notice that matching student data to the schools would require aggregating 
student-level variables because there are fewer schools than students in this case. We will use the 
single common identiﬁ er variable,  nschcode , which represents the schools in both ﬁ les. Both data 
sets will need to be sorted on the key variable. Th is can be accomplished by opening each data set 
and choosing the DATA, SORT CASES menu and dialog box. For each ﬁ le, the sort should be 
on the variable  nschcode , and each ﬁ le needs to be saved after sorting. 
 Th is example will combine data 
from two ﬁ les:  ch2multivarML1.
sav (primary ﬁ le) and  apexams.sav 
(secondary ﬁ le). When combining 
data from separate ﬁ les, we recom-
mend that the cases are sorted 
before you begin this procedure 
to prevent interruption of the 
workﬂ ow. 
 If you are continuing from 
the prior section concerning 
the COMPUTE function, the 
 ch2multivarML1.sav ﬁ le is already 
open. If not, locate and open the 
data ﬁ le. 
  1. Go to the toolbar and select 
DATA, SORT CASES. 
 Th is command will open the  Sort 
Cases dialog box. 

48  Preparing and Examining the Data for Multilevel Analyses
  3. Begin by opening the secondary ﬁ le 
( apexams.sav ) while keeping the 
 ch2multivarML1.sav ﬁ le open. 
 Go to the toolbar and select FILE, OPEN, 
DATA. 
 Th is command will then display the  Open 
Data screen. 
  5. With the data ﬁ le  apexams.sav opened, 
go to the toolbar and select DATA, 
SORT CASES. 
 Th is command will open the  Sort Cases 
dialog box. 
 
 4a. Locate and click to select the data 
ﬁ le ( apexams.sav ). 
 
 b. Th en click the OPEN button. 

Preparing and Examining the Data for Multilevel Analyses  49
 
 6a. Within the  Sort Cases dialog box, select 
 nschcode from the left column, and then 
click the right-arrow button to transfer the 
variable into the  Sort by box. 
 
 b. Th e default setting for sorting is the 
 Ascending order, which we will retain. 
 
 c. Later versions of IBM SPSS (version 20.0 
forward) provide an option for saving the 
sorted data directly to a ﬁ le. We will forgo 
using this option for the current example. 
 Click the OK button to begin sorting the cases. 
  7. Once the ﬁ les are sorted, then 
merging may begin. 
 Return to the primary data ﬁ le 
( ch2multivarML1.sav ). Th en go to the 
toolbar and select DATA, MERGE 
FILES, ADD VARIABLES. 
 Th is command will open the  Add 
Variables dialog box. 
  8.  Since the data ﬁ le  apexams.sav 
is an opened ﬁ le, the option  An 
open dataset is preselected and 
displays the ﬁ le name in the 
box below. If  apexams.sav had 
not been opened, the option  An 
external SPSS Statistics data ﬁ le 
would have been preselected 
instead, requiring you to locate 
and identify the ﬁ le using the 
BROWSE button. 
 Now click to select  apexams.sav(DataSet2) , and then click the CONTINUE button to access the  Add 
Variables from DataSet2 screen. 

50  Preparing and Examining the Data for Multilevel Analyses
 
 9a. Within the  Add Variables from 
DataSet2  display screen, click to 
select  nschcode(+) from the  Ex-
cluded Variables box. Th is action 
will activate the  Match cases on 
key variables in sorted ﬁ les  option 
below, enabling the box to be 
checked. 
 
 b. Click to select the  Non-active 
dataset is keyed table option. 
 Note: A “keyed” table or table lookup 
ﬁ le is a ﬁ le that contains data for each 
case that can be applied to numerous 
cases in another data ﬁ le. 
 
 c. Now click the right-arrow but-
ton to move  nschcode(+) into the 
 Key Variables box. 
 Click the OK button to process this function. 
  10. A warning to presort the 
data appears but may be dis-
regarded since the data from 
both ﬁ les had been sorted 
using the  nschcode variable at 
the outset. 
 Click the OK button. 
  11. Scroll across the col-
umns, and the merged 
variable  apexams taken 
from the  apexams.sav 
data ﬁ le is found in 
the last column of the 
 ch2multivarML1.sav data 
window. 

Preparing and Examining the Data for Multilevel Analyses  51
 Once the merge is complete, the new variable,  apexams , will appear in the active data set 
window as shown in  Figure 2.5 . Notice that while the individual-level variables vary across all 
cases within the window, the new school-level variable,  apexams is constant within each school 
(compare  nschcode 4 with  nschcode 5 in the subsequent screen shot). 
 Descriptive statistics on the data set, summarized in  Table 2.4 , will now show a value for 
 apexams for each of the 8,335 Level 1 observations. Notice that the descriptive statistics provide 
no hint of the lack of variance within each  nschcode  for the  apexams variable. It now looks like an 
individual-level variable. 
FIGURE 2.5 Data matrix after performing the MATCH FILES function.
TABLE 2.4 Descriptive Statistics
N
Minimum
Maximum
Mean
Std. Deviation
id
8,335
1.000
8,670.000 4,308.352
2,510.578
nschcode
8,335
1.000
525.000
261.976
152.817
test1
8,335
24.350
69.250
47.644
6.325
test2
8,335
27.480
74.780
52.379
7.781
test3
8,335
26.960
79.720
57.109
9.450
effective
8,335
0.000
1.000
0.562
0.496
courses
8,335
0.000
4.000
0.748
0.790
female
8,335
0.000
1.000
0.505
0.500
ses
8,335
–2.410
1.870
0.034
0.784
apexams
8,335
0.000
0.800
0.166
0.130
Valid N (Listwise)
8,335
www.allitebooks.com

52  Preparing and Examining the Data for Multilevel Analyses
 Aggregate: Collapsing Data Within Level 2 Units 
 Many times the analyst will be interested in creating group-level measures by aggregating the 
characteristics of individuals within each group. One candidate variable might be student socio-
economic status ( ses ). Another might be gender ( female ) (aggregating this to the mean will yield 
the proportion of students at Level 1 who are female). In this section, we will use the AGGRE-
GATE command to create both of these variables. 
 Th e objective in this in-
stance is to take the within-
school means of the variables 
 female  and  ses . Th is will yield 
the proportion of females in 
the sample for each school 
and the average socioeco-
nomic status of students in 
the sample for each school. 
 If you are continuing from the prior 
section concerning the MERGE 
FILES function, the  ch2multi-
varML1.sav ﬁ le is already open. If 
not, locate and open the data ﬁ le. 
  1. Go to the toolbar and select 
DATA, AGGREGATE. 
 Th is command will open the  Ag-
gregate Data dialog box. 
 
 2a. Click to select  nschcode from the left col-
umn of the  Aggregate Data dialog box, and 
then click the right-arrow button to move 
the variable into the  Break Variable(s) box. 
 
 b. Now click to select  female and  ses from 
the left column, and then click the right-
arrow button to move the variables into 
the  Summaries of Variable(s) box. 
 Note: IBM SPSS uses MEAN as the default 
function, which will be used for this example. 
Other functions besides MEAN are also available 
to generate a variety of aggregated data. 
 
 c. Click the option  Add aggregated vari-
ables to active dataset , which will add the 
two variables  female_mean and  ses_mean 
directly into the active Level 1 data set. 
 Note: Besides the  Add aggregated variables to the 
active dataset  option, we could also choose two 
other options:  Create a new dataset containing only 
the aggregated variables or  Write a new data ﬁ le 

Preparing and Examining the Data for Multilevel Analyses  53
containing only the aggregated variables. Th e latter choices would require us to use the MATCH FILES 
routine to merge the new aggregated variables back onto the individual-level data set. Choosing to have 
the variables written straight to the active data set is much more eﬃ  cient and reduces the risk of errors. 
 Click the OK button to run the aggregation and merge the new variables to the student-level data set 
(shown in the active data window). 
  3. Scroll across the col-
umns, and the new 
aggregated variables 
 female_mean and 
 ses_mean appear in the 
last two columns of the 
 ch2multivarML1.sav 
data window. 
 Notice that school 4 ( nschcode  = 
4) has an all-female sample 
( female_mean = 1.00) while 
less than half of the school 5 
sample was female ( female_
mean = .47). Th e SES average 
for school 4 was also higher 
than the average for school 5 
(.82 vs. -.39, respectively). 
 Th e RECODE, COMPUTE, MATCH FILES, and AGGREGATE commands provide all 
the tools necessary for structuring our IBM SPSS ﬁ les for a multilevel analysis within IBM SPSS 
MIXED. We will expand on some of the commands in subsequent sections to create variables 
that can be very useful in multilevel analyses. Before turning our attention to those additional 
examples, however, we introduce a diﬀ erent data structure that enables multivariate analyses and 
analyses of change over time using the multilevel model through IBM SPSS MIXED. 
 VARSTOCASES: Vertical Versus Horizontal Data Structures 
 Th e data sets we created in the previous sections are arranged horizontally; that is, each observa-
tion is contained on a single row with variables arrayed across the columns. In the horizontal 
data sets, we have the variables arranged in such a way that the lower level units can be seen as 
nested within high-level units (e.g., students within schools where student values vary within and 
between schools while school-level values vary only between schools). 
 In multivariate and time-varying models, we reconceptualize the nesting and deal with verti-
cal rather than horizontal data structures. Instead of students being our Level 1 unit of analysis, 
we might nest time periods or indicator variables within students who could, in turn, be nested 
within schools. In this case, our time periods or indicator variables become Level 1, students be-
come Level 2, and schools become Level 3. In terms of the data structure, what this means is that 
each individual (i.e., students, to continue our example) will have multiple records. If there are 
three occasions of interest, each student will have three records, one for each occasion. Similarly, 

54  Preparing and Examining the Data for Multilevel Analyses
if we are interested in deﬁ ning a latent variable with ﬁ ve indicators, each student would have ﬁ ve 
records. So if we have a data set with 1,000 students and we are interested in looking at change, 
say in test scores, over three occasions, our data set will have three occasions × 1,000 students = 
3,000 records. Using the latent variable example, if we had 1,000 students and ﬁ ve indicators, 
we would have 5,000 records in the data set. Th is is quite in contrast to the univariate outcome 
models in which individuals are nested in successively higher organizational levels. In those 
models, the individual deﬁ nes Level 1 of the analysis, and there are as many records as there are 
individuals. 
 Rearranging the data to accommodate the change and multivariate models is quite straight-
forward. Let’s refresh our memory of the data set we have been using. Note that in the subse-
quent data view illustrated in  Figure 2.6  there is a single record for each student, and we have 
three test scores across successive time periods. 
 Our objective is to create three records for each student, each representing a distinct time 
point for each individual in the sample. In other words, we are going to nest these three testing 
occasions within each student (students will still be nested within their schools). To accomplish 
this, we will use the VARSTOCASES routine that is contained in the  Restructure Data Wizard . 
 If you are continuing from the prior section concerning the MERGE FILES function, the 
 ch2multivarML1.sav ﬁ le is already open. If not, locate and open the data ﬁ le. 
FIGURE 2.6 Horizontal data matrix.

Preparing and Examining the Data for Multilevel Analyses  55
  1. Go to the toolbar 
and select DATA, 
RESTRUCTURE. 
 Note: If you’re prompted to 
save the ﬁ le before proceeding, 
you may save it or elect not to 
do so. 
 Th is command will open the 
 Welcome to the Restructure Data 
Wizard dialog box. 
  2. Th e  Restructure Data 
Wizard presents three 
options:  Restructure 
selected variables into 
cases, Restructure selected 
cases into variables, and 
 Transpose all data. 
 For this situation, we want 
to treat the three test vari-
ables ( test1 ,  test2 , and  test3) 
as a single grouped vari-
able, so will use the default 
setting:  Restructure selected 
variables into cases. 
 Click the NEXT button to 
go to the  Variables to Cases 
screen. 

56  Preparing and Examining the Data for Multilevel Analyses
  3. Th e  Variables to Cases: Num-
ber of Variable Groups display 
screen allows deﬁ ning the 
number of variable groups to 
create in the new data ﬁ le. 
 In this case, the three tests ( test1 , 
 test2 , and  test3 ) are to be treated as 
a single group, so the default setting 
of  One  will be used. 
 Click the NEXT button to 
continue to the next screen. 
  4. Th e  Variables to Cases: Select 
Variables screen allows deﬁ n-
ing the variables for the new 
data. Th is includes specifying 
a new group ID ( Case Group 
Identiﬁ cation ), the variables to 
deﬁ ne the transposition ( Vari-
ables to be Transposed ), and the 
variables to include with each 
new record [ Fixed Variable(s) ]. 
 
 a. Begin by entering  Rid 
(recoded ID) as the  Case 
Group Identiﬁ er Name. 
 
 b. Enter  test as the  Target 
Variable. 
 
 c. Click to select  test1 ,  test2 , 
and  test3 from the left 
column, and then click 
the right-arrow button to 
move the variables into the 
 Variables to be Transposed 
box. Th e three variables will 
be combined to form a single variable ( test ) that is related to each record (row). 
 
 d. Click to select all the remaining variables (excluding  test1 ,  test2 , and  test3 ) from the left column, 
and then click the right-arrow button to move them into the  Fixed Variable(s)  box. [Refer to 
the  Fixed Variable(s)  boxed insert.] Th ese variables will then be appended to each of the new 
rows in the data set. 
 Click the NEXT button to continue to the  Variables to Cases: Create Index Variables screen. 

Preparing and Examining the Data for Multilevel Analyses  57
  5. Th e  Variables to Cases: Cre-
ate Index Variables screen 
allows for creating one or 
more index variables. 
 In this case, we want to create 
one indexed variable encom-
passing the “timing” of each 
test. Since  One is the default 
option, click the NEXT button 
to continue to the  Variables to 
Cases: Create One Index Variable 
screen. 
  6. Further information 
may be speciﬁ ed for the 
indexed variable. 
 
 a.  Sequential numbers is 
the default setting, 
which will be retained 
for this example. 
 
 b. Th e variable name may 
be changed by click-
ing on  Index1 and then 
changing it to  time. 
 Click the FINISH button to 
indicate that no further changes 
will be made. 

58  Preparing and Examining the Data for Multilevel Analyses
  7. After clicking the FINISH button, a mes-
sage immediately appears warning that 
some of the original data will remain in use 
and that care should be administered to 
ensure use of the appropriate data set for 
subsequent analyses. 
 Click the OK button to proceed with generating the new data set. 
  8. Th e new data set appears, and 
scrolling across the columns, the 
 time and  test variables are found 
in the last two columns. A trun-
cated view of the data set shows 
that each student (as identiﬁ ed 
by  Rid and  id ) now has three 
lines of data, one line for each of 
the three tests and time peri-
ods. A more complete picture is 
presented in  Figure 2.7 . 
 Notice that each student now has 
three lines of data—one for each test. 
Th e test scores (Level 1) vary across 
all respondents, student characteris-
tics vary across all students (Level 2) 
but are constant within the group of 
three test scores, and school characteristics vary across all schools (Level 3) but are constant within the 
group of students attending each school. 
FIGURE 2.7 Data matrix after performing the VARSTOCASES function.

Preparing and Examining the Data for Multilevel Analyses  59
 Notice also that when looking at the descriptive statistics for the new data set in  Table 2.5 , there are 
25,005 observations. Th e original data set had 8,335 observations. From our earlier description, we can 
see that 8,335 (students) multiplied by 3 (test scores) equals 25,005 records in the new data set. 
 Using “Compute” and “Rank” to Recode the Level 1 or Level 2 Data for Nested Models 
 From this it becomes apparent how quickly data sets can expand as models become more compli-
cated. As the models become more complicated, the computing time necessary for the solution 
to converge within each level can become substantial. Th is is especially true in the multivariate 
and change models where variables or time periods are nested within individuals. Leyland (2004) 
notes that one can save a great deal of the time it takes to estimate a proposed model by rein-
dexing the Level 1 (and, in some cases, the Level 2) identiﬁ ers within each school. Reindexing 
the individual-level data in these models can yield signiﬁ cant savings in run time and, in some 
cases, may make a diﬀ erence in whether the model can even be estimated within the conﬁ nes of 
the computer’s available memory. Th e objective of reindexing is to create a new set of individual 
identiﬁ ers that are numbered only with reference to each group. So, for example, the 10 individu-
als in group 1 would be numbered from 1 to 10 (assuming there were only 10 in the group), and 
the 14 individuals in group 2 would be numbered from 1 through 14, and so forth (1,2,…,  n ). 
 Situations in which this may prove beneﬁ cial will be identiﬁ ed in later chapters. For now, 
however, we want to introduce the steps involved. Th is reindexing can be easily accomplished 
using the IBM SPSS RANK command. From the TRANSFORM > RANK CASES menu 
within IBM SPSS, we can call up the  Rank Cases dialog box. 
 Creating an Identiﬁ er Variable 
 Creating identiﬁ cation variables is straightforward in IBM SPSS. We will ﬁ rst show how to 
generate an ID variable for each case. Th is can be useful in those instances when an identiﬁ er is 
not found in the ﬁ le being used. For this ﬁ rst example, we will use the  ch2level-1data.sav ﬁ le we 
introduced at the beginning of this chapter (see  Figure 2.1 on page 36 ). You may recall that this 
data set is single-level and cross-sectional with 6,871 observations. We have removed the  id vari-
able that appeared in the version of the data set we used earlier. Our ﬁ rst task will be to recreate 
an individual-level identiﬁ er using the COMPUTE command. 
TABLE 2.5 Descriptive Statistics
N
Minimum
Maximum
Mean
Std. Deviation
Rid
25,005
1.000
8,335.000
4,168.000
2,406.155
id
25,005
1.000
8,670.000
4,308.352
2,510.477
nschcode
25,005
1.000
525.000
261.976
152.811
effective
25,005
0.000
1.000
0.562
0.496
courses
25,005
0.000
4.000
0.748
0.790
female
25,005
0.000
1.000
0.505
0.500
ses
25,005
–2.410
1.870
0.034
0.784
ses4cat
25,005
1.000
4.000
2.496
1.118
testmean
25,005
28.027
74.583
52.377
6.964
apexams
25,005
0.000
0.800
0.166
0.130
female_mean
25,005
0.000
1.000
0.505
0.153
ses_mean
25,005
–1.297
1.416
0.034
0.500
time
25,005
1.000
3.000
2.000
0.817
test
25,005
24.350
79.720
52.377
8.843
Valid N (Listwise)
25,005

60  Preparing and Examining the Data for Multilevel Analyses
  2. After removing  id from the data 
set, go to the toolbar and select 
TRANSFORM, COMPUTE 
VARIABLE. 
 Th is command will open the  Compute 
Variable dialog box. 
 Creating an Individual-Level Identiﬁ er Using “Compute” 
 Continue using the  ch2multivarML1.sav data set. 
  1. Begin by deleting the current  id 
variable from the data set. 
 
 a. First, click on the  Variable View 
tab, which displays the variables 
in the data set. 
 
 b. To delete  id , ﬁ rst locate and 
click to select the row (2). You 
may then delete  id by one of 
two methods: Right-click your 
mouse to display the submenu, 
and select  Clear , which will 
delete the variable; or 
 
 c. An alternative method to 
deleting the variable is to go to 
the toolbar and select EDIT, 
CLEAR. 
 
 3a. Enter  id as the  Target Variable. 
 
 b. Within the  Function group list, 
click to select  All , which will 
display assorted functions in the 
 Functions and Special Variables 
box. 
 
 c. Click to select the  $Casenum 
function, and then click the 
up-arrow button, which will 
place the term into the  Numeric 
Expression box. 
 Click the OK button to perform the 
function. 

Preparing and Examining the Data for Multilevel Analyses  61
 Once a Level 1 identiﬁ er exists, it is quite easy to create a variety of diﬀ erent within-group 
identiﬁ ers. Th ese within-group identiﬁ ers will become very important in later chapters where 
we use more complex models. Using the TRANSFORM, RANK CASES commands from the 
IBM SPSS menu, we will now create another identiﬁ er assigning a sequential ID variable  Rid 
within each group. Th e  Rid variable will range from 1 through  n within each Level 2 unit. 
 Creating a Group-Level Identiﬁ er Using “Rank Cases” 
 Continue using the  ch2multivarML1.sav data set. 
  1. Begin by deleting the 
current  Rid  variable from 
the data set. 
 
 a. First, click on the  Vari-
able View  tab, which 
displays the variables 
in the data set. 
 
 b. To delete  Rid , ﬁ rst 
locate and click to 
select the row (1). You 
may then delete  Rid 
by one of two meth-
ods: Right-click your 
mouse to display the 
submenu, and select 
 Clear , which will delete 
the variable; or 
 
 c. An alternative method to deleting the variable is to go to the toolbar and select EDIT, 
CLEAR. 
  4. Scroll across the columns, 
and the new variable  id is 
found in the last column 
of the data window and 
corresponds to the case 
number (or row number) 
for each case. 
 Note:  Th e decimal place set-
ting may be adjusted by click-
ing on the  Variable View tab 
and changing the number to 
the desired setting (i.e., “0”). 

62  Preparing and Examining the Data for Multilevel Analyses
  2. After removing  Rid  from the 
data set, go to the IBM SPSS 
toolbar and select TRANS-
FORM, RANK CASES. 
 Th is command will open the  Rank 
Cases dialog box, which enables 
creating new variables containing 
ranks, normal and Savage scores, 
and percentile values for numeric 
variables (IBM Corporation, 2012). 
 
 3a. Click to select the Level 1 
identiﬁ er ( id ) from the left 
column, and then click the 
right-arrow button to move it 
into the  Variable(s) box. 
 
 b. Next, click to select group 
identiﬁ er ( nschcode) from the 
left column, and then click the 
right-arrow button to move 
the variable into the  By box. 
 
 c. In the  Assign Rank 1 to  section, 
conﬁ rm that  Smallest value 
(default setting) is selected. 
 
 d. Click the RANK TYPES but-
ton, which will open the  Rank 
Cases: Types dialog box. 
 
 e. Th ere are several ranking 
methods with a simple  Rank 
as the default setting. We will 
use  Rank , so click the CONTINUE button to 
close the dialog box. 
 
 f. Now click the TIES button, which will open the 
 Rank Cases: Ties dialog box; this box controls the 
method for assigning rankings to cases with the 
same value on the original variable (IBM Corpo-
ration, 2012). 
 
 g. Among the options listed for  Rank Assigned to 
Ties , click to select  Sequential ranks to unique 
values.  Th e option must be selected to ensure that 
each person is assigned an identiﬁ er within each unit. Th en click the CONTINUE button to 
close the box. 
 Now click the OK button to create the  Rid Level 1 group identiﬁ er. 

Preparing and Examining the Data for Multilevel Analyses  63
  4. Scroll across the columns, 
and the  Rid Level 1 
group identiﬁ er variable 
is located in the last col-
umn of the data window. 
 Note that each Level 2 unit 
( nschcode ) will have its own 
sequence of  Rid beginning 
with 1. 
 Finally, we will take this one step further by creating a new within-group id ( Rid ) variable for the 
multivariate data set shown in  ch2multivarML1.sav (see  Figure 2.7 on page 58 ). 
 Creating a Within-Group-Level Identiﬁ er Using “Rank Cases” 
 Continue using the  ch2multivarML1.sav data set. 
  1. Begin by deleting the 
current  Rid  variable from 
the data set. 
 
 a. First, click on the  Vari-
able View  tab, which 
displays the variables 
in the data set. 
 
 b. To delete  Rid , ﬁ rst 
locate and click to se-
lect the row (14). You 
may then delete  Rid 
by one of two meth-
ods: Right-click your 
mouse to display the 
submenu, and select 
 Clear , which will delete 
the variable; or 
 
 c. An alternative method to deleting the variable is to go to the toolbar and select EDIT, 
CLEAR. 

64  Preparing and Examining the Data for Multilevel Analyses
  3. Th e default settings from the 
prior example display  id within 
the  Variable(s) box and  nschcode 
in the  By box. 
 In the previous example, we selected 
only one group identiﬁ er,  nschcode . 
Since the data in the multivariate 
example are vertically arranged (i.e., 
there are multiple records for each 
individual), we need to generate 
sequential, within-group identiﬁ ers 
for each person, constant across the 
three time points (recall that we had 
three time points nested within each 
person). 
 We will now add the other grouping 
variable ( time ) to the  By box. Th is 
will generate a sequential identiﬁ er 
for each person across the three time 
periods within each group. 
 Th e settings for  Rank Types and  Ties remain the same as the prior example, so skip over these buttons 
and click OK. 
  2. After removing  Rid  from 
the data set, go to the 
IBM SPSS toolbar and 
select TRANSFORM, 
RANK CASES. 
 Th is command will open the 
 Rank Cases dialog box. 

Preparing and Examining the Data for Multilevel Analyses  65
  4. Scroll across the columns, 
and the  Rid variable is 
shown in the last column 
of the data viewer. 
 Notice that the  Rid variable 
reﬂ ects the number of observa-
tions in the data set but not 
the number of individuals. 
 Note: If you would like to 
view the changes made to 
the  ch2multivarML1.sav 
data set after completing the 
tutorial sections to this point, 
please view  ch2multivarML1- 
tutorials.sav. 
 In this section we have shown the primary commands necessary to create new variables, re-
code existing variables, merge new data onto the existing data set, create group-level aggregates 
from individual-level variables, and restructure the data set for multivariate analyses using IBM 
SPSS MIXED. In the sections that follow, we use these data management procedures to oﬀ er 
instruction on the creation of new variables that will be needed for the analyses presented in 
subsequent chapters. 
 Centering 
 Th e basic multilevel model (i.e., a random intercept model) treats the Level 1 intercept as an 
outcome with variance that can be explained using variables from a higher level. While we de-
velop this model in some detail in the following chapter, we want to convey the importance of 
the intercept here. Consider as a starting point the traditional ﬁ xed-eﬀ ect ordinary least squares 
(OLS) regression model using  test1  as a predictor for some outcome. 
 
  Y i =   0 +   1 test1 i =  	 i 
(2.1) 
 From the earlier descriptive statistics table ( Table 2.2 ), we know that values on  test1 range 
from 24.35 to 69.25 with a mean of 47.64. Recall that the intercept in a model such as that in 
Equation 2.1 is the value of the outcome ( Y ) when the predictor ( test1 in this example) is equal 
to 0. When additional terms are added to the model, the interpretation generalizes to the value of 
the outcome ( Y ) when each of the predictors in the model is equal to 0. So in instances where the 
predictor cannot be 0 (such as this example with the test score), the intercept is of little substan-
tive use. Th is is ﬁ ne when the emphasis is on the interpretation of slopes that are constant across 
groups that may exist in the sample. 
 But imagine a scenario in which, for some reason, we did have an interest in an interpretable 
slope. One way to ensure a meaningful and interpretable intercept is to alter the predictor in a 
way that makes 0 a meaningful value. Th is is often accomplished by “centering” the predictor on 
0 (or some other value). First, consider the results of the OLS model speciﬁ ed previously. We will 
use scores on  test1 to predict scores on  test3 (which has a mean of 57.11). 

66  Preparing and Examining the Data for Multilevel Analyses
 From these results in  Table 2.6 , we can see that a 1-point increase in performance on  test1 is as-
sociated with a 0.92-point increase on  test3 . Th e intercept value is 13.272. With these two values, 
one could calculate a predicted value for  test3 given knowledge of performance on  test1 . Th e 
intercept is used only to generate that predicted value for  test3 and has no real interpretative use 
because 0 is not a valid option for  test1 performance. 
 By centering the  test1 variable on 0, we can make the intercept more interpretable. To do this, 
we simply subtract the mean of  test1 from the  test1 score for each student in the data set; that is, 
 
 (
..)
ij
X
X

 
(2.2) 
 We will show how to do this in a moment. For now, let us just consider the change in the OLS 
results. 
 In  Table 2.7 , notice that the  test1 slope coeﬃ  cient (and standard error) remains the same as 
in the previous model but that the intercept is now 57.11 or the raw mean for  test3 (see previous 
discussion). So when  test1 is equal to 0 (and 0 is now the overall mean for  test1 ),  test3 is equal to 
its overall mean. Th e intercept now has a useful interpretation. 
 Because the multilevel model treats the intercept as an outcome, as we will show in the next 
chapter, it is very important that the Level 1 model yield an interpretable value for   0 . Center-
ing makes this possible and therefore is an important feature of the multilevel model. Th ere are 
two types of centering that we will be concerned with throughout the workbook: grand-mean 
centering, such as that used in the previous example; and group-mean centering, which centers 
the variable on the mean of each higher level group. In the sections that follow, we demonstrate 
how to create these within IBM SPSS MIXED. We further develop the rationale of each of 
these methods at length in subsequent chapters. Here, however, we focus on how to compute the 
variables that will be needed. 
TABLE 2.6 Coefﬁ cientsa
Model
Unstandardized 
Coefﬁ cients
Standardized 
Coefﬁ cients
t
Sig.
B
Std. Error
Beta
1
(Constant)
13.272
0.620
21.414
.000
test1
0.920
0.013
0.616
71.351
.000
a Dependent variable: test3.
TABLE 2.7 Coefﬁ cientsa
Model
Unstandardized 
Coefﬁ cients
Standardized 
Coefﬁ cients
t
Sig.
B
Std. Error
Beta
1
(Constant)
57.108
0.082
700.254 .000
gmtest1
0.920
0.013
0.616
71.351 .000
a Dependent variable: test3.

Preparing and Examining the Data for Multilevel Analyses  67
 TABLE 2.8 Descriptive Statistics 
N
Minimum
Maximum
Mean
Std. Deviation
test1
8,335
24.350
69.250
47.644
6.325
gmtest1
8,335
–23.294
21.606
0.000
6.325
Valid N (Listwise)
8,335
 Grand-Mean Centering 
 As in our previous example, variables in a multilevel model are most frequently grand-mean cen-
tered. For example, in  Table 2.8  the grand mean for  test1 is 47.64. Using COMPUTE in IBM 
SPSS, one can name the new variable  gmtest1 and then compute the new variable by subtract-
ing the grand mean of  test1 from students’ scores on that variable (i.e.,  test1 ‒ 47.64). Th is will 
transform the scores in terms of the grand mean of the sample. So, if a student has a  test1 score 
of 50.64, her new score will be 3 (50.64 ‒ 47.64 = 3), which carries the meaning that its rela-
tive position is three points above the grand mean with respect to other students in the sample. 
Grand-mean centering results in unit-level means that have been adjusted for diﬀ erences among 
individuals within the units. Notice that the distribution remains exactly the same when we cen-
ter. Th e only thing that shifts is the scale itself. 
 For this tutorial we will use the original nine-variable “horizontal”  ch2multivarML1.sav  data 
ﬁ le for this section. 
  1. Go to the toolbar 
and select TRANS-
FORM, COMPUTE 
VARIABLE. 
 Th is command will open the 
 Compute Variable dialog box. 

68  Preparing and Examining the Data for Multilevel Analyses
 
 2a. In the  Compute Variable 
display screen, enter 
 gmtest1 as the  Target 
Variable. 
 
 b. Now select  test1 , and 
click the right-arrow 
button to move the vari -
able into the  Numeric 
Expression box.  Use 
the numeric keypad 
(or enter from your 
keyboard) to complete 
the equation:  test1 - 
47.6439. Insert a minus 
sign (-) by clicking on 
the key. 
 Note: Use ANALYZE, DE-
SCRIPTIVE STATISTICS, 
DESCRIPTIVES to obtain the 
mean of  test1 (47.6439). 
 Click the OK button to create the computed variable  gmtest1. 
  3. Scroll across the columns, 
and the computed variable 
 gmtest1 is found in the last 
column of the  ch2multi-
varML1.sav  data window. 
 A quick look at the descriptive statistics of the original  test1 variable and its grand-mean cen-
tered counterpart in  Table 2.8  show that although the standard deviation remains the same, the 
means and ranges stay the same while the minimum and maximum values have changed. Again, 
this simply demonstrates that only the scale has changed and that the distribution (or variability 
around the mean) itself remains the same. Note that we have not standardized the variable, but 
rather we have simply readjusted it so its mean is equal to 0. 

Preparing and Examining the Data for Multilevel Analyses  69
 Group-Mean Centering 
 Group-mean centering of variables yields values that represent the unadjusted mean for group  j . 
So rather than using the overall mean as the reference, the group mean is used instead. 
 
 
j
ij
X
X

 
(2.3) 
 Group-mean centering of variables is a two-step process that ﬁ rst involves the aggregation of 
the focal variable to the group level and then follows a logic similar to that used for grand-mean 
centering described previously. We will use the AGGREGATE and COMPUTE commands to 
accomplish this. 
 Continue using the  ch2multivarML1.sav  data ﬁ le, which now contains 10 variables at the 
conclusion of the prior tutorial. 
  1. Go to the toolbar 
and select DATA, 
AGGREGATE. 
 Th is command opens the 
 Aggregate Data dialog box. 

70  Preparing and Examining the Data for Multilevel Analyses
 
 2a. Within the  Aggregate Data 
dialog box, click to select  nschcode 
from the left column, and then 
click the right-arrow button to 
move the variable into the  Break 
Variable(s) box. 
 
 b. Next, click to select  test1 from 
the left column, and then click 
the right-arrow button to move 
the variable into the  Summaries 
of Variable(s) box. (IBM SPSS 
uses MEAN as the default func-
tion, which will be used for this 
example.) 
 
 c. Change the output variable 
name by clicking on the NAME 
& LABEL button, which will 
open the  Aggregate Data: Variable 
Name and Label box. Th en replace 
the initial variable name  test1_
mean with the current  test1gpm . 
Click the CONTINUE button 
to close the box when completed 
to return to the  Aggregate Data 
main dialog box. 
 Click the OK button to perform the ag-
gregation and create the new  test1gpm . 
  3. Scroll across the columns, and 
the new aggregated variable 
 test1gpm appears in the last 
column of the  ch2multivarML1.
sav data window. 
 Notice that this new variable is 
constant within each Level 2 unit 
(schools); that is, the value repre-
sents the mean  test1 score within 
each school. Th ese values provide 
the reference value for the group 
centering of  test1 (just as the overall 
mean provided the reference value 
for grand-mean centering). With the 
group-mean value known, it is easy 
to calculate the group-centered  test1 
variable, which we will call  grouptest1 . 
 We will specify the target variable we wish to create ( grouptest1 ) and create the Numeric Ex-
pression  test1 -  test1gpm . 

Preparing and Examining the Data for Multilevel Analyses  71
 Continue using the  ch2multi-
varML1.sav data ﬁ le. 
  1. Go to the toolbar 
and select TRANS-
FORM, COMPUTE 
VARIABLE. 
 Th e command opens the 
 Compute Variable dialog box. 
 Note: Th e formula ( test1 - 
47.6439 ) used in the preced-
ing exercise may appear in the 
 Numeric Expression box. To 
remove the formula, click the 
RESET button at the bottom 
of the screen. 
 
 2a. Enter  grouptest1 as 
the  Target Variable . 
 
 b. Click to select  test1 
from the left column, 
and then click the 
right-arrow button 
to move the variable 
into the  Numeric 
Expression box. Insert 
a minus sign (-) by 
clicking on the key. 
 
 c. To complete the 
numeric expression, 
click  test1gpm  from the left column, and then click the right-arrow button to move the variable 
into the box. Th is completes the  Numeric Expression of subtracting  test1gpm  from  test1 . 
 Click the OK button to perform the function. 

72  Preparing and Examining the Data for Multilevel Analyses
  3. Scroll across the columns, 
and the new  grouptest1 
variable appears in the last 
column of the data window. 
 We will specify the target variable 
we wish to create ( grouptest1 ) and 
create the Numeric Expression 
 test1 -  test1gpm . 
 We can now compare the three 
variables: (a)  test1 , (b)  gmtest1 , and 
(c)  grouptest1. 
 Notice in  Table 2.9  that while the uncentered  test1 and the grand-mean-centered  test1 variables 
share the same distribution (but diﬀ erent means), the group-mean-centered  test1 variable has 
a mean of 0 (like the grand-mean version) but a diﬀ erent standard deviation. Th is results from 
the variance in  test1 means across the schools in the sample—an artifact that will become very 
important in subsequent analyses. 
 For reasons we will discuss in Chapter 4, researchers often enter dummy variables in the model 
as uncentered (although there are occasions when analysts may also wish to grand-mean center 
them), and they grand-mean center the continuous variables at Level 1 and Level 2. We will also 
show how this logic generalizes to situations in which there are more than two levels of analysis. 
 Checking the Data 
 Th e diligent analyst always takes great care to examine the data thoroughly. As data sets for mul-
tilevel analyses can become quite complex, in terms of structure and content, great attention to 
detail should be given when reviewing the contents of the data set. IBM SPSS has a rich set of 
tools for the exploratory analysis of the data. Th e IBM SPSS EXPLORE routine, for example, 
can provide rich detail on data coding, distributions, missing data, and the like (this can be 
accessed through the ANALYZE, DESCRIPTIVE STATISTICS, EXPLORE menu). From 
 TABLE 2.9 Descriptive Statistics
N
Minimum
Maximum
Mean
Std. Deviation
test1
8,335
24.350
69.250
47.644
6.325
gmtest1
8,335
–23.294
21.606
0.000
6.325
grouptest1
8,335
–22.897
22.904
0.000
5.879
Valid N (Listwise)
8,335

Preparing and Examining the Data for Multilevel Analyses  73
Chapter 1, it should be clear that missing data can prove to be a real headache when using IBM 
SPSS MIXED or any other multilevel-modeling routine. We highly recommend that missing 
data be carefully assessed to determine any patterns that may exist and to ﬁ nd remedies where 
at all possible. 
 Beyond a careful examination of the data, thought should be given to model speciﬁ cation and 
the distribution of residuals. Raudenbush and Bryk (2002, p. 253) point out that model speciﬁ ca-
tion assumptions apply at each level and that misspeciﬁ cation at one level can impact the results 
at other levels. Moreover, as with OLS regression at a single level, there are assumptions about 
the distribution of the residuals that apply at each level in the multilevel model. Although we 
do not spend a great amount of time addressing these important issues in this workbook, we do 
recommend that the reader familiarize him- or herself with the possibilities that exist for model 
checking in the multilevel framework. 
 A Note About Model Building 
 As will become clear in the chapters that follow, developing and testing multilevel models re-
quires a great deal of thought as well as trial and error. Even with a basic two-level model, there 
are many intermediate steps over which the model evolves. Keeping track of this evolution is 
essential for understanding the way the model is behaving and for replicating the models in 
subsequent steps. 
 We have over the years developed a fairly simple naming scheme for our models and take 
care to document each model as fully as possible. Moreover, while we may use the IBM SPSS 
graphical user interface to develop the model, we always have IBM SPSS export the syntax so 
we can save it for future reference. Our naming scheme is applied to the syntax ﬁ les themselves. 
At a glance, we can determine the type of model speciﬁ ed through the syntax (e.g., from a simple 
ANOVA model to a fully speciﬁ ed three-level, random-slopes and intercept model). With the 
syntax for each model saved and annotated, we can always document the evolution of model 
speciﬁ cation and easily modify models at any point in the future. We will have more to say about 
this throughout the workbook. 
 Summary 
 Th is chapter has provided an overview of the data management tools necessary for understand-
ing and working with the hierarchical data ﬁ les used in multilevel modeling. We have introduced 
ﬁ ve primary commands for manipulating data ﬁ les to suit the needs of univariate and multi-
variate analyses using IBM SPSS MIXED. Th ere is, of course, a great deal more than could be 
presented. Our main purpose in this workbook is, however, the modeling techniques themselves 
rather than treating the more universal data management skills used to structure data within 
IBM SPSS. Th e treatment provided in this chapter is designed to highlight the elementary skills 
associated with data management relating to the speciﬁ cation of the multilevel model within 
IBM SPSS. 

              This page intentionally left blank

75
 CHAPTER 3 
 Deﬁ ning a Basic Two-Level Multilevel 
Regression Model 
 T
his chapter introduces the basic approach to two-level multilevel modeling. Th e material 
is challenging because the models are more complex than the general linear model, which 
most readers will be familiar with from their basic statistics courses. Like everything else, how-
ever, one has to start somewhere. Th e general concepts we present in this chapter become more 
familiar as one reads more research that makes use of multilevel techniques. After ﬁ rst reviewing 
some basic concepts of the single-level multiple regression model, we develop the basic steps of 
conducting a multilevel regression analysis using an extended example. Our intent is to develop 
the rationale behind the speciﬁ cation of this general class of models in a relatively nontechnical 
manner and to illustrate its use in an applied research situation. Th e methods presented in this 
chapter should provide a basis for the application of these techniques to a wider set of research 
problems in the chapters that follow. 
 From Single-Level to Multilevel Analysis 
 Statistical modeling depends on a family of probability distributions for outcome variables 
(Agresti, 2007). We often use the term  random variable to describe possible values that an out-
come may have. A probability distribution is a mathematical function that links a particular 
observed outcome obtained in a sample to the probability of its occurrence in a speciﬁ c popula-
tion. Th e most common example involves the sampling distribution of the mean from which 
the probability of obtaining particular samples with a particular mean can be estimated (Azen 
& Walker, 2011). Most commonly, the observed mean is assumed to result from a normal dis-
tribution of possible values around the population mean, which has some variance. We assume 
that the general shape of this distribution resembles a bell-shaped curve; that is, the majority 
of individuals are closer to the mean, and there are fewer individuals as the distance from the 
mean increases. Th e normal distribution is commonly associated with continuous outcomes (i.e., 
variables measured on an interval or ratio scale). Other types of categorical (discrete) variables 
(e.g., nominal, ordinal, and count) have diﬀ erent probability distributions and require other types 
of analytic methods for optimal analysis. Examples include being proﬁ cient or not proﬁ cient in 
reading, purchasing a sports car (among several possible types of cars), expressing a level of agree-
ment or disagreement on a political issue, or receiving a number of traﬃ  c tickets during a speci-
ﬁ ed interval of time. Random values of these diﬀ erent types of categorical outcomes are obtained 
from probability distributions (i.e., binomial, multinomial, and Poisson) other than the normal 
distribution (for further discussion, see Agresti, 2007; Azen & Walker, 2011; Heck, Th omas, & 
Tabata, 2012; Hox, 2010). 

76  Deﬁ ning a Basic Two-Level Multilevel Regression Model
 Linear models (e.g., analysis of variance [ANOVA], analysis of covariance, multiple regres-
sion, and multivariate analysis of variance [MANOVA]) have long been used in the social sci-
ences to analyze data from experimental, quasi-experimental, and nonexperimental designs. 
Univariate analysis, such as multiple regression, is concerned with examining the variability in a 
single continuous outcome (or dependent) variable from information provided by one or more 
predictor (or independent) variables. Multivariate analysis (e.g., MANOVA and factor analysis) 
is the more general case of univariate analysis; that is, it facilitates the examination of multiple 
independent and dependent variables in one simultaneous model. A commonality between these 
univariate and multivariate approaches, however, is that they are conﬁ ned to single-level analyses; 
that is, either individuals are the unit of analysis or groups are the unit of analysis. 
 Multiple linear regression requires a continuous dependent variable (i.e., measured on an in-
terval or ratio scale) and can handle both continuous and dichotomous (e.g., gender) indepen-
dent variables. It cannot handle categorical variables (i.e., referred to as factors in analysis of 
variance terminology) without recoding them in some way. Th ere are two broad conceptual ap-
proaches to the regression model, predictive and explanatory. Th rough the predictive approach, 
the analyst uses the multiple regression model to optimize predictions about an outcome based 
on values of a set of independent variables. Th e linear regression model assumes that a unit in-
crease in the independent variable is related to an expected constant change in the dependent 
variable. For example, we might wish to predict someone’s likely starting salary in a new job if she 
or he has a certain level of education and experience. For the linear model to hold, it is assumed 
that an increase in education (or experience) will bring an expected similar change in starting 
salary, regardless of where someone starts in terms of education. In this type of single-level 
regression model, the coeﬃ  cients that describe the prediction equation (i.e., the intercept and 
slope coeﬃ  cients for each predictor in the model) are generally considered as ﬁ xed values in the 
population estimated from the sample data. For this type of research purpose, the focus of the 
analysis is primarily on the eﬃ  ciency of the prediction and the parsimony of variables included 
in the prediction equation. In other words, the analyst hopes to make the best predictions using 
the smallest number of variables. 
 Th e second broad approach is explanatory rather than predictive. Th rough the explanatory 
approach, the analyst sets out to determine how a set of independent variables aﬀ ects a de-
pendent variable and to estimate the magnitude of the eﬀ ects for each independent variable. 
For example, existing research may suggest that a particular model (e.g., consisting of iden-
tiﬁ ed market processes, individual background, and perhaps organizational factors) interacts 
in a way that inﬂ uences beginning salary. Th e focus in this type of study rests on the correct 
speciﬁ cation and testing of a theoretical model that is under consideration. In this case, it is 
important to include in the model a set of variables identiﬁ ed as important by theory and previ-
ous research. More speciﬁ cally, the researcher formulates a model from theory, tests the model 
against the data, and determines how well the empirical test of the model conforms to theoretical 
expectations. 
 Of course, these goals are not mutually exclusive. We distinguish between these two goals, 
however, because in predictive studies variables might be retained in a model only because they 
are statistically signiﬁ cant and dropped simply because they are not (Heck & Th omas, 2009). 
In other words, theory would not enter into decisions about model eﬃ  ciency. In contrast, in the 
explanatory approach, the speciﬁ cation of the theoretical model should be carefully considered, 
and subsequent changes (i.e., whether to add or remove a variable from a model) should be made 
sparingly with careful attention to theory. Otherwise, it may be diﬃ  cult to attach any substan-
tive meaning to the ﬁ nal model. Th is latter point has particular relevance to the investigation of 
multilevel data (i.e., data on individuals and the groups they deﬁ ne) that tend to go with more 
complex theories about how processes operate across multiple social groupings. 
 Although researchers were aware of problems due to the nesting of individuals within higher 
level units of the data hierarchy in the past, the presence of similarities among individuals in the 

Deﬁ ning a Basic Two-Level Multilevel Regression Model  77
same groups did not enter directly into single-level analyses. For example, in analyses of large-
scale survey data, the analyst typically applied sample weights to address the oversampling of 
some subgroups in the data set (e.g., by socioeconomic status [SES] or by ethnicity). Failure to 
account for similarities among individuals (due to grouping) within the study, however, can lead 
to biased estimates of model parameters and therefore erroneous conclusions about the eﬀ ects of 
some predictors in the model (Th omas & Heck, 2001). 
 Multilevel modeling represents a compromise between modeling each unit separately and 
modeling all unit contexts simultaneously within the same model (Kreft & de Leeuw, 1998). 
Th ese models obviate the forced choice of conducting either an individual-level analysis or a 
group-level analysis. We use the term  multilevel model with respect to two separate statistical ob-
jectives described within one model. Th e ﬁ rst objective concerns inferences made about a model’s 
structural parameters (Morris, 1995), often referred to as the model’s ﬁ xed eﬀ ects. Th e second 
objective concerns inferences about the unknown variance parameters in the model, referred to as 
the random parameters (Morris, 1995). Although researchers are generally most interested in the 
model’s structural parameters, the distribution of a model’s random parameters (e.g., variances 
and covariances) is also of interest. 
 Th ere are several advantages of multilevel analysis over traditional single-level univariate and 
multivariate approaches (Heck & Th omas, 2009). First, as we have stated, multilevel analysis 
helps researchers avoid the choice of individuals or groups as the unit of analysis. Second, it allows 
researchers to deal with more complicated sampling strategies. Single-level analyses are based on 
the assumption of simple random samples. In many data collection strategies, however, individu-
als may be sampled within the same neighborhoods or schools, or subgroups of individuals (e.g., 
by ethnicity or SES) may be oversampled compared with their representation in the population. 
Such complex sampling strategies create clustering eﬀ ects that violate the assumptions of simple 
random sampling (i.e., that every individual has an equal chance of being selected in the sample). 
Th ird, where similarities among individuals are present (e.g., clustering eﬀ ects due to sharing 
similar circumstances), multilevel models are acknowledged to provide more accurate estimates 
of model parameters than single-level analyses (Hox, 2002). Th is is primarily due to their greater 
accuracy in calculating standard errors associated with parameter estimates. Because hypothesis 
tests are based on the ratio of the unstandardized estimate to its standard error, ignoring the 
presence of nested data structures can lead to underestimating standard errors and, therefore, 
false inferences about the signiﬁ cance of model parameters (Th omas & Heck, 2001). Fourth, 
multilevel analysis allows the researcher to deﬁ ne variables at their correct theoretical level of 
the data hierarchy. So, for example, in a two-level hierarchy, a variable such as school size can be 
determined with respect to the number of schools in the sample, while a variable like gender can 
be evaluated with respect to the number of individuals in the sample. Finally, multilevel modeling 
allows researchers to ask more complex questions about the data. One is about the distribution of 
outcomes (e.g., means or regression slopes) across a sample of groups (such as schools). We may 
attempt to determine what types of school variables might reduce gaps in student learning due 
to socioeconomic status or previous skill levels. Examples might include the quality of a school’s 
teachers, its leadership practices, and its classroom learning activities. 
 Building a Two-Level Model 
 Th e basics of multilevel modeling involve the investigation of randomly varying outcome param-
eters. Th ese typically include variation in the levels of the outcome (intercepts) and the strength 
of within-group relationships indicated by regression coeﬃ  cients (slopes) across groups. Once 
we identify that variation exists in the parameters of interest, we can build models to explain this 
variation. As we suggested in Chapter 1, in some cases, we may have a speciﬁ c theoretical model 
in mind that we wish to test; in others, however, we might be trying to explore possible new 
mechanisms that explain this variation. 

78  Deﬁ ning a Basic Two-Level Multilevel Regression Model
 Consider an analysis where the researcher wishes to determine whether there is an associa-
tion between a predictor,  X , such as SES, and an outcome,  Y , such as a math test score. Because 
the current educational policy context in the United States demands increasing accountability 
for student outcomes, schools are accountable for reducing gaps in achievement due to students’ 
social backgrounds. Such concerns are related to the social distribution of learning within schools 
(e.g., see Lee & Bryk, 1989). Ideally, we may wish to identify school settings where achievement 
is generally high for all the students in the school and where there is little or no relationship 
between student SES and outcomes. Such schools would be considered both eﬀ ective (i.e., pro-
ducing high achievement outcomes) and equitable (i.e., having little or no social distribution of 
learning due to students’ social backgrounds). In contrast, we may also wish to identify schools 
where achievement is consistently low for students and where student SES background is conse-
quential for their outcome levels. We might be able to intervene eﬀ ectively (e.g., increase teacher 
quality and reallocate resources) if we could identify such settings that are ineﬀ ective and ineq-
uitable for students. 
 Research Questions 
 Our ﬁ rst research question focuses on whether student achievement in math varies across schools. 
We can ask simply: Does student math achievement vary across schools? We might then inves-
tigate the relationship between students’ socioeconomic status and their math achievement. Sec-
ond, we might ask whether the eﬀ ects of individual SES tend to compound at the school level 
to inﬂ uence student math achievement; that is, do both individual-level SES and school-level 
aggregate (or average) student SES inﬂ uence math achievement? Th ird, we investigate whether 
features of schools’ contexts (i.e., student composition and type of school) and their academic 
environments (i.e., the proportion of students planning to attend 4-year universities after they 
graduate from high school) aﬀ ect the relationship between individual student SES and math 
achievement. More speciﬁ cally, we ask: Do features of schools’ contexts and academic environ-
ments moderate the relationship between individual student SES and math achievement? Our 
research questions, therefore, provide an illustration of building a two-level model to investigate 
(a) a randomly varying intercept (math achievement level) and, subsequently, (b) a randomly 
varying slope (i.e., the individual SES–math achievement relationship). 
 The Data 
 Th e data set used in this example consists of 6,871 secondary students in 419 schools (see 
 Table 3.1 ). 
 Specifying the Model 
 We will begin with a single-level analysis (i.e., considering only the students and not their nest-
ing within schools) as a starting point. One typical research question for a single-level analysis 
might be: Is there a relationship between students’ SES background and their achievement levels 
in math? We might hypothesize that socioeconomic status is positively related to the subject’s 
score on the math test. Th e single-level multiple regression model to explain an individual’s ( i ) 
math achievement outcome would be 
 
  Yi =   0    1 SESi    i  , 
(3.1) 
 where   0 is the intercept,   1 is a slope parameter, and   i  represents error in predicting individual 
outcomes from the equation. Th e intercept represents the expected math achievement score for 
a student whose SES is 0. It is important to consider the scaling of the independent variable 
or variables in a model. In this simple case, because SES (which is a continuous variable) was 

Deﬁ ning a Basic Two-Level Multilevel Regression Model  79
standardized (i.e., rescaled into a standardized score, or  z -score), the mean is 0 and the standard 
deviation ( SD ) is 1.0. Th is is often a convenient scale for continuous variables in multilevel model-
ing, since a score of 0 on SES, therefore, represents the score for a person whose SES background 
is equal to the SES grand mean for the sample. We discuss these types of centering options in 
further detail at the end of this chapter and also in Chapter 4. Th e slope coeﬃ  cient (  1 ) represents 
the expected change in math achievement for a 1-unit (in this case, 1  SD ) change in SES. 
 Th e key point about a single-level model is that the estimates of the intercept and slope are 
each ﬁ xed to one value that describes the average for the sample. For example, the slope express-
ing the relationship between SES and math scores will be the same across all cases. Th is also 
means that the errors () in estimating the intercept and slope parameters are assumed to be 
independent, to be normally distributed, to have constant variance, and to have a mean of 0. 
 To examine her research question preliminarily, the researcher might ﬁ rst develop a scatterplot 
of the relationship between student SES and math achievement. To illustrate this in relation to 
single and multilevel designs, we will develop a scatterplot for the ﬁ rst 80 students in the data 
set. Th e resulting graph is summarized in  Figure 3.1 . Th e ﬁ gure suggests that as student SES 
increases, so do math scores. Th e goal of the overall analysis is to determine the best-ﬁ tting line 
that describes the relationship between student SES and test scores in this sample. Th is is ac-
complished by estimating values for the intercept and slope. Of course, once we estimate the 
predicted values for each subject on the two variables, there will be a discrepancy between the 
predicted values (which would lie on the line) and subjects’ actual values on the SES and math 
test score measures. Th e diﬀ erence between observed and predicted values is represented as error. 
Th e intercept coeﬃ  cient represents the average level of student scores when SES is 0 (which 
represents a mean adjusted for SES), and the slope represents the average eﬀ ect of SES on the 
math score across the sample of students. Th ese values become “ﬁ xed” for the entire sample; that 
is, because individuals are randomly sampled, it is assumed that the value represents population 
averages. 
TABLE 3.1 Data Deﬁ nition of ch3multilevel.sav (N = 6,871)
Variable
Levela
Description
Values
Measurement
schcode
School
School identiﬁ er (419 schools).
Integer
Ordinal
Rid
Individual
A within-group level identiﬁ er representing a sequential 
identiﬁ er for each student within 419 schools.
1 to 37
Ordinal
id
Individual
Student identiﬁ er (6,871 students).
Integer
Ordinal
female
Individual
Demographic predictor variable representing 
student’s gender.
0 = Male
1 = Female
Scale
ses
Individual
Predictor interval variable (z-score) measuring student 
socioeconomic status composition within the schools.
–2.41 to 
1.87
Scale
femses
Individual
Predictor variable (grand-mean centered) measuring 
student socioeconomic status by gender (female).
–2.41 to 
1.85
Scale
math
Individual
Student math achievement test score.
27.42 to 
99.98
Scale
ses_mean School
Predictor variable (grand-mean centered) 
measuring student socioeconomic status.
–1.30 to 
1.44
Scale
pro4yrc
School
Variable measuring the school’s academic 
program (i.e., aggregate percentage of students 
who intend to study at 4-year universities).
0.00 to 
1.00
Scale
public
School
Dichotomous variable identifying school type.
0 = Other
1 = Public 
School
Scale
a Individual = Level 1; school = Level 2.

80  Deﬁ ning a Basic Two-Level Multilevel Regression Model
 Fixing the values of the intercept and slope results in the regression line in  Figure 3.1  that sum-
marizes the relationship between SES and math test scores. Th e principle of least squares states 
that the correct regression line is the one that best ﬁ ts the data points. Model ﬁ t is assessed by 
summing the squared distances of each observed value from the predicted value that rests on the 
regression line. Th e line that minimizes the sum of these squared distances (they are squared to 
cancel out positive and negative errors above or below the line) is said to ﬁ t the data best; hence, 
the term  least squares regression (Neter, Kutner, Nachtsheim, & Wasserman, 1996). In the linear 
regression model, the error term is a random source of variation, which we assume is 0 on average 
and normally distributed, varies independently of  X and has constant variance across all levels of 
 X . Interested readers can reproduce the scatterplot in  Figure 3.1  in IBM SPSS menu commands. 
 Graphing the Relationship Between SES and Math Test Scores with IBM SPSS Menu Commands 
 Launch the IBM SPSS application 
and select the data ﬁ le:  ch3multilevel.sav. 
 1. Go to the toolbar and select DATA, 
SELECT CASES. 
 Th is command will open the  Select Cases 
dialog box. 
 FIGURE 3.1  Regression line describing the ﬁ xed intercept and slope for student SES and math achievement.

Deﬁ ning a Basic Two-Level Multilevel Regression Model  81
 
 2a. Within the  Select Cases dialog box, 
select the option  Based on time or 
case range , which will activate the 
RANGE button. 
 
 b. Click on the RANGE button, 
which will open the  Select Cases: 
Range box. 
 
 c. Enter “1” as the  First Case and “80” 
as the  Last Case . Th is setting will 
select the ﬁ rst 80 individuals in the 
study. Th en click the CONTINUE 
button, which will close the  Select 
Cases: Range box. 
 Click the OK button to close the main 
 Select Cases dialog box and return to the 
IBM SPSS main screen. 
  3. In the IBM SPSS tool-
bar, select GRAPHS, 
LEGACY DIALOGS, 
SCATTER/DOT. 
 Th is command will open the 
 Scatter/Dot box. 
  4. Click the SIMPLE SCATTER option in the 
 Scatter/Dot box. Th en click the DEFINE button to 
open the  Simple Scatterplot box. 

82  Deﬁ ning a Basic Two-Level Multilevel Regression Model
 
 5a. Within the  Simple Scatterplot 
box, click to select the  math 
variable from the left column. 
Th en click the right-arrow 
button to move  math into the 
 Y Axis box. 
 
 b. Next, click  ses to select the 
variable from the left column, 
and then click the right-
arrow button to move the 
variable into the  X Axis box. 
 Click OK to generate the scatterplot. 
  6. Th e IBM SPSS 
output will display the 
scatterplot. 
 Place your cursor on the 
image and double-click to 
open the  Chart Editor. 

Deﬁ ning a Basic Two-Level Multilevel Regression Model  83
  7. On the  Chart Editor  short-cut icon 
bar, click the ADD FIT LINE AT 
TOTAL icon that has the  X and  Y 
axes. Th is will generate the ﬁ t line 
and the linear  R -square of 0.387 for 
this subset of the sample. 
 As  Figure 3.1  emphasizes, in a single-level linear model, the coeﬃ  cients describing the in-
tercept and slope are generally considered as ﬁ xed values in the population estimated from the 
sample data. As shown in  Table 3.2 on page 84 (based on an analysis of the full sample), the in-
tercept is estimated as 57.598. Th is can be interpreted as the sample mean adjusted for individual 
SES (note that, while not shown, the sample mean unadjusted for SES is 57.734). Referring back 
to Equation 3.1, we obtain the following estimated linear relationships to explain achievement: 
 Y i  = 57.798  4.255 *  SES , 
 where  Y i  (or  Y hat) indicates that the  predicted  value of  Y i  is equal to the estimated intercept plus 
the coeﬃ  cient for SES (plus some unknown error). Th e unstandardized regression coeﬃ  cient 
describing the eﬀ ect of individual SES (  1 ) on math achievement is 4.255. Th e slope coeﬃ  cient 
suggests that, on average, as student SES goes up by 1 unit (in this example, 1  SD ), the predicted 
student test score would be expected to increase by 4.255 points to 62.053 [57.798 + 4.255(1)]. 
Th is is arrived at by multiplying the regression weight (4.255) by the desired 1-unit increase in 
SES. If we wanted to know the predicted value, a student’s test score for a 2-unit increase in SES 
(i.e., in this case, a 2- SD increase), we would multiply as follows: 
 Y i    = 57.798  4.255(2), 
 where the predicted of  Y i  would then be 66.308 [57.798 + (4.255)(2) = 57.798 + 8.510]. We 
note in the output that in the single-level analysis we also have a standardized regression weight 
(0.378), which provides a common metric for examining the eﬀ ects of predictors on the outcome. 

84  Deﬁ ning a Basic Two-Level Multilevel Regression Model
For a continuous predictor, such as SES in this case, this can be interpreted as a 1- SD increase 
in the predictor producing a 0.378- SD increase in the math outcome. As we noted in Chapter 1, 
most multilevel software programs do not produce standardized estimates as part of the output, 
given various ways of standardizing estimates and the changes in the model’s variance compo-
nents that can result from standardizing estimates when there are random slopes in the model 
(Heck & Th omas, 2009; Hox, 2010). 
 Th e analysis also provides a table describing the variability in math achievement accounted for 
by the predictors in the model ( Table 3.3 ). Th is can be used to estimate the variance accounted 
for in achievement by mean student composition and individual SES. From the table, we can 
calculate  R 2 as the ratio of the regression variance to the total variance (75813.3/530078.8 = 
0.143). 
 As we have noted, however, there would likely be problems in the accuracy of this analysis. 
Th e assumptions necessary for multiple regression models to yield the best, unbiased estimates 
are most realistic when the data have been collected through simple random sampling. Random 
sampling assumes that subjects in a study are independent of each other. As groups are added as 
a feature of a study, however, this assumption becomes more tenuous. In large-scale educational 
research, for example, simple random sampling would rarely be used. Instead, various types of 
complex sampling strategies are employed to select schools, classrooms, and students. Th ese can 
include multistage-sampling strategies where individuals may be sampled within various groups 
and the likely oversampling of some groups. Clustered data, therefore, result from the strate-
gies used in large-scale databases, as well as the natural groupings of students in classrooms and 
schools. 
 Single-level analyses are appropriate when there is little interest in considering group-level 
inﬂ uences on the outcomes. Th e key point about a single-level model is that the estimates of the 
intercept and slope are each ﬁ xed to one value that describes the average for the sample. 
 Th e single-level regression model cannot take into consideration that the students may be 
clustered within a number of schools with other students having similar backgrounds and math 
TABLE 3.3 ANOVAa
Model
Sum of Squares
df
Mean Square
F
Sig.
1
Regression
75,813.316
1
75,813.316
1146.382
.000b
Residual
454,265.500
6,869
66.133
Total
530,078.816
6,870
a Dependent variable: math.
b Predictors: (Constant), ses.
TABLE 3.2 Coefﬁ cientsa
Unstandardized Coefﬁ cients
Standardized 
Coefﬁ cients
Model
B
Std. Error
Beta
t
Sig.
1
(Constant)
57.598
0.098
586.608
.000
ses
4.255
0.126
0.378
33.858
.000
a Dependent variable: math.

Deﬁ ning a Basic Two-Level Multilevel Regression Model  85
scores. In our example, the multiple regression analysis does not take into consideration that 
students are nested within the 419 schools in the sample (or that the estimated slope might 
be diﬀ erent between these schools). Multilevel models imply that individuals are “clustered” 
in higher order social groupings (a department, a school, or some other type of organization). 
In these types of studies, simple random sampling does not hold because people clustered in 
groups will tend to be “similar” in some ways. In this example, the size of the student samples 
within their schools ranges from 12 to 37 (mean = 17.4,  SD  = 4.74). If the clustering of stu-
dents is ignored, it is likely that bias will be introduced in estimating the coeﬃ  cients and their 
standard errors. 
 We can again develop a scatterplot of the relationship between students’ SES and math 
achievement from  Figure 3.1 , this time taking into consideration their schools (i.e., in this case 
the 80 students are in six schools). We can therefore estimate a separate regression equation 
for each school. Each school would have its own intercept (describing the level of its students’ 
outcomes adjusted for SES) and a slope (describing the relationship between SES and math 
achievement within that school). Where data hierarchies exist, the school intercepts (i.e., average 
math scores adjusted for student SES) would likely vary across the sample of schools in the study. 
Moreover, there might be some schools where the eﬀ ect of student SES on math achievement 
(represented by the slope of regression line) is greater than or less than the average (or ﬁ xed) 
eﬀ ect. Th ere might also be some schools where there is no relationship at all. In other words, 
where there are clustered data, it is likely that there is a distribution of both intercepts and slopes 
around their respective average ﬁ xed eﬀ ects. In this situation, we might wish to investigate the 
“random” variability in intercepts and slopes across the sample of higher level units in the study 
(e.g., classrooms, schools). 
 Figure 3.2  presents the relationship between SES and math achievement for the previous 
subset of 80 individuals nested in six schools. Th e ﬁ gure suggests that the slope relationship 
accounts for diﬀ ering amounts of variance within each unit (i.e., with  R 2 coeﬃ  cients ranging 
from 0.02 to 0.205). Th is suggests considerable social distribution of math learning within 
these six schools. 
 FIGURE 3.2  Randomly varying SES-achievement slopes in six schools.

86  Deﬁ ning a Basic Two-Level Multilevel Regression Model
 Graphing the Subgroup Relationships Between SES and Math Test Scores 
with IBM SPSS Menu Commands 
 (Settings will default to the prior 
scatterplot.) 
  1. In the IBM SPSS toolbar, 
select GRAPHS, LEGACY 
DIALOGS, SCATTER/
DOT. 
 Th is command will open the 
 Scatter/Dot box. 
  2. Th e default selection from the prior scatterplot is 
set to  Simple Scatter. 
 Click the DEFINE button to open the  Simple Scatterplot 
box. 
  3. Th e  Simple Scatterplot box displays the 
variables  math ( Y Axis ) and  ses ( X Axis ). 
 Click to select  schcode from the left column. 
Th en click the right-arrow button to move 
 schcode into the  Set Markers by box. 
 Click OK to generate the scatterplot. 

Deﬁ ning a Basic Two-Level Multilevel Regression Model  87
 Multilevel modeling can be used to specify a hierarchical system of regression equations that 
take advantage of the clustered data structure (Heck & Th omas, 2009). Multilevel regression 
modeling involves ﬁ rst estimating a Level 1 model within each higher level unit (e.g., schools) 
and then estimating a series of between-unit models using the within-unit estimates (i.e., inter-
cepts or slopes) as dependent variables. In contrast to a single-level regression model, where the 
impact of a variable like SES is assumed to be ﬁ xed across all individuals in the sample, within 
multilevel regression modeling one can specify a single-level regression equation that can be 
estimated within each school (as shown in  Figure 3.2 ). In this way, the researcher can determine 
whether the eﬀ ect of SES on math achievement is stronger or weaker in some schools. Th e for-
mal test of this is whether the distribution of slopes (i.e., the  R 2 coeﬃ  cients in  Figure 3.2 ) varies 
signiﬁ cantly diﬀ erent across units. 
 In this case, the researcher might be interested in estimating the average intercept and the 
SES eﬀ ect on math achievement across the set of schools, as well as determining how particular 
schools deviate from the overall average intercept and average SES-achievement slope. Although 
the researcher’s primary concern is usually with a model’s structural parameters (e.g., the level of 
achievement and the average eﬀ ect of SES on achievement), in some cases examining the ap-
propriateness and distribution of the random variance parameters (e.g., variance associated with 
intercepts, slopes, and covariances between intercepts and slopes) may be of equal interest to the 
researcher. In a multilevel model, the math achievement intercept and the SES-achievement 
slope can be deﬁ ned to vary as probability distributions across the set of schools. Th e variability 
of intercepts (i.e., where each unit’s regression line crosses the  Y axis) and slopes (the steepness 
of each institution’s regression line) gives rise to diﬀ erent types of questions that can be asked of 
the data. In addition to our initial research question (Is there a relationship between student SES 
and math achievement?), we can now ask other questions of the data. 
 If we inspect  Figure 3.2  visually, it looks like the levels of the intercepts vary considerably 
across the six schools. For example, in one school, a student somewhat below 2  SD in SES would 
have a math score of about 34.0. In contrast, in another school, a similar student (somewhat 
below 2  SD in SES) would score approximately 61.0 in math. Th is observed variability in in-
tercepts gives rise to a second question: Do the average math scores students receive vary across 
schools in the sample? Answering this question would provide information about each school’s 
eﬀ ectiveness, given the SES background of its students. Th e ﬁ gure also suggests the possibility of 
randomly varying slopes in the data set. Five of the six schools in our illustrative subsample have 
positive slope relationships, and one school has a negative slope relationship. One can also notice 
that the  R 2 coeﬃ  cients associated with the slope relationship within each unit, which summarize 
the strength of the relationship between student SES and math, also vary considerably in the 
ﬁ rst six schools (i.e., from 0.02 to 0.21). Th is small data set suggests that there may be schools 
where there is little gap in math achievement due to students’ SES background. Th ese schools 
could be viewed as more equitable in terms of the social distribution of learning due to students’ 
social backgrounds (e.g., SES or perhaps gender and race/ethnicity if we were to include those 
variables). 
 In other schools, students’ social background might be very consequential in determining their 
achievement. A second question that could be posed is the following: Do the slopes (i.e., the 
strength of relationship between student SES and math achievement) vary across schools? An-
swering this question would provide information about schools’ equity in producing outcomes, 
given the social backgrounds of their students. We might examine whether the relationship be-
tween individual SES and math achievement is stronger or weaker in schools of diﬀ ering average 
social composition. Moreover, we can investigate whether there is a diﬀ erence in the strength of 
association between individual SES and achievement in public and private schools or in schools 
having a stronger academic focus, after controlling for the mean SES level at the school. 
 Parameters that are proposed to vary randomly across units are referred to as random eﬀ ects or 
random coeﬃ  cients from various statistical perspectives. In experimental research, for example, 
a  random eﬀ ect  describes a situation where the levels of a treatment are assumed to represent a 

88  Deﬁ ning a Basic Two-Level Multilevel Regression Model
sample drawn from a universe of treatments or treatment levels. Because the eﬀ ect is considered 
as randomly varying across a universe of treatment levels, the intent is to make inferences be-
yond the speciﬁ c treatment levels included in the study. Th e eﬀ ects, therefore, are not assumed 
to be constant. In contrast, a  ﬁ xed eﬀ ect  describes the situation where all possible treatments are 
present in the experiment (Kreft & de Leeuw, 1998). In this latter case, inferences can only be 
made about the speciﬁ c treatments used. Th e eﬀ ects are considered to be constant and measured 
without error because all possible cases are included. 
 Unlike single-level (ordinary least squares [OLS]) regression, where random errors are as-
sumed to be independent, to be normally distributed, and to have constant variance, in multilevel 
models the error structures are more complex. Th e individual-level errors are dependent within 
each unit because they are common to every individual within that unit (Heck & Th omas, 2009). 
Errors do not have constant variance because the residual components describing intercepts 
and slopes may also vary across units. Th e estimation of these unknown random parameters as-
sociated with intercepts or slopes may also depend on characteristics of the data (e.g., sample 
size, degree of imbalance in sample sizes of higher level units, and degree of similarity among 
individuals within groups), the type of analysis conducted, and the measurement scale of the 
dependent variables (Muthén & Muthén, 1998–2006; Raudenbush & Bryk, 2002). Because the 
model’s random parameters must be estimated with group samples containing diﬀ ering numbers 
of individuals, iterative estimation procedures must be used to obtain eﬃ  cient estimates (Muthén 
& Muthén, 1998–2006). 
 Building a Multilevel Model with IBM SPSS MIXED 
 We can use IBM SPSS MIXED to run a variety of diﬀ erent multilevel cross-sectional and lon-
gitudinal (e.g., growth) models. Th e program is ﬂ exible and can be used to estimate a number of 
diﬀ erent types of models with random intercepts (i.e., means that vary across groups) and ran-
dom slopes (i.e., within-group regression coeﬃ  cients that vary across groups). It is also useful in 
looking at individual change over repeated measurements or in studies of changes of individuals 
within organizations over time. In addition, it can also be applied to situations where individu-
als may be cross-classiﬁ ed by higher level groupings (e.g., in several diﬀ erent classrooms within 
schools or within various high schools and subsequent universities). In the chapters that follow, 
we develop each of these possibilities in more detail. In the remainder of this chapter, we focus 
on the univariate cross-sectional multilevel model. 
 Th ere are several ways to develop models using IBM SPSS MIXED. Some users prefer the 
IBM SPSS graphical user interface (GUI), while others favor using syntax statements to deﬁ ne 
the model. We will build models in the chapters that follow using the GUI, and we also provide 
some of the key syntax in Appendix A. As we mentioned in Chapter 2, syntax can be very use-
ful on occasions since one does not have to return to the speciﬁ c window to make successive 
changes in a model that is being investigated. Syntax also provides a record of what has been 
done previously. Th is record can be saved and used on subsequent occasions without having to 
set the model up again through the IBM SPSS menu system (i.e., GUI). We have found that 
small diﬀ erences may result depending on whether models are developed with syntax commands 
or the GUI (e.g., owing to some default commands that users may not specify with the syntax 
commands). Also, we note that if users have diﬀ erent versions of IBM SPSS (e.g., Version 15 
forward), estimates may be slightly diﬀ erent (owing to diﬀ erent default rounding procedures). 
In this chapter, we take the reader through the steps in the IBM SPSS GUI to develop the basic 
two-level regression model. An alternative to writing your own syntax is to develop models using 
the IBM SPSS GUI and then tell IBM SPSS to generate the syntax (which is then pasted into 
a syntax window). Although we use the GUI interface, we will also demonstrate how to gener-
ate syntax through the menu system. We follow this convention throughout the remainder of 

Deﬁ ning a Basic Two-Level Multilevel Regression Model  89
the book. Note that all screen shots from the IBM SPSS GUI provided here are based on IBM 
SPSS for Windows Version 21.0.0.1 (64 bit). 
 Step 1: Examining Variance Components Using the Null Model 
 Th ere are three distinct steps in developing the multilevel model. We develop these in this chap-
ter in the following order: (a) speciﬁ cation of the null, or no predictors, model; (b) speciﬁ cation 
of the Level 1 model; and (c) speciﬁ cation of the Level 2 model. Th is latter step can include the 
model to explain intercepts and the model or models to explain randomly varying slopes. Th e 
ﬁ rst step in a multilevel analysis usually is to develop a null (or no predictors) model to partition 
the variance in the outcome into its within- and between-groups components. Th is will help the 
researcher determine how much of the variance in math achievement lies between the schools 
in the sample. Notice that in Equation 3.2, we add a subscript for schools ( j ). Th e null model for 
individual  i in school  j can be represented as 
Y ij  =   0 j     ij  , 
(3.2) 
 where   0 j  is the intercept and   ij  represents variation in estimating individual achievement within 
groups. Between groups, variation in intercepts can be represented as 
 0 j  =   00   u 0 j  . 
(3.3) 
 Th rough substitution, the null model can be written as 
 
  Y ij  =   00   u 0 j     ij  . 
(3.4) 
 Th e null model therefore provides an estimated mean achievement score for all schools. It also 
provides a partitioning of the variance between Level 1 (  ij  ) and Level 2 ( u 0 j  ). Altogether there 
are three eﬀ ects to estimate: the intercept, the between-school variation in intercepts ( u 0 j  ), and 
the variation in individual scores within schools (  ij  ). 
 Th is model also provides a measure of dependence within each Level 2 unit by way of the 
intraclass correlation (  ). Th e intraclass correlation (or ICC) describes the proportion of vari-
ance that is common to each unit, as opposed to variation that is associated with individuals 
within their units. It can be thought of as the population estimate of the amount of variance in 
the outcome explained by the grouping structure (Hox, 2002). Th e proportion of variance found 
between groups can be calculated in IBM SPSS by using either the Variance Components or 
MIXED procedures. Both will give the same estimation of within-groups and between-groups 
variance components. As we noted in Chapter 1, the ICC can be represented as 
2
2
2 )
2
2
B
B
W

 B
B
/(
2
2
 2 /(
2
B /(
, 
(3.5) 
 where   2 represents the variance and  B and  W stand for between groups and within groups, re-
spectively. (Refer to Appendix C for a syntax routine that enables calculating rho from a model’s 
variance components.) Stated diﬀ erently, the ICC is the ratio of between-groups variance to the 
total variance. Th e higher the ICC, the more homogeneous are the units (i.e., there exists sub-
stantial variability between schools). In contrast, if the ICC is quite small (i.e., researchers often 

90  Deﬁ ning a Basic Two-Level Multilevel Regression Model
use 0.05 as a rough “cutoﬀ ” point), then there would be little advantage to conducting a multi-
level analysis. Simply put, the higher level grouping does not aﬀ ect the estimates in any mean-
ingful way. In these cases, a single-level analysis conducted at the individual level would suﬃ  ce. 
 Deﬁ ning Model 1 (Null) with IBM SPSS Menu Commands 
 Launch the IBM SPSS pro-
gram application and select the 
 ch3multilevel.sav data ﬁ le. 
  1. Go to the toolbar and 
select ANALYZE, 
MIXED MODELS, 
LINEAR. 
 Th is command enables access 
to the  Linear Mixed Models: 
Specify Subjects and Repeated 
dialog box. 
  2. Th e  Linear Mixed Models: Specify Subjects and 
Repeated screen displays options for deﬁ ning 
variables as subjects, repeated observations, and 
type of covariance structure in a model. 
 A subject is an observational unit that may be 
independent of other subjects. For this model, we 
will designate  schcode as a subject identiﬁ er for the 
model. 
 Click to select  schcode from the  Variables column 
and then click the right-arrow button to move the 
variable into the  Subjects box. 
 Click the CONTINUE button to display the 
 Linear Mixed Models dialog box. 

Deﬁ ning a Basic Two-Level Multilevel Regression Model  91
  3. Th e  Linear Mixed Models main screen 
enables specifying the dependent 
variable; factors; covariates; access 
to dialog boxes for deﬁ ning  Fixed 
and  Random eﬀ ects; and options for 
 Estimation ,  Statistics ,  EM Means , and 
 Save. 
 At Level 1, we will use  math as the de-
pendent variable. Click to select the  math 
variable from the left column listing. Th en 
click the right-arrow button to transfer 
 math into the  Dependent Variable box. 
 Since this ﬁ rst model (null) excludes 
predictor variables, as summarized by Equation 
3.2, we will skip over the FIXED button, which 
enables adding ﬁ xed eﬀ ects to a model. 
 Next, we will add random intercept eﬀ ect at Level 2 to this model. Click the RANDOM button to 
 access the  Linear Mixed Models: Random Eﬀ ects dialog box. 
  4. Th e  Linear Mixed Models: Random 
Eﬀ ects  displays the  Random Eﬀ ect 
1 of 1 screen. Th is is the default 
screen when creating a model for 
the ﬁ rst time. Th e random-eﬀ ects 
screen allows specifying random 
eﬀ ects, interactions, intercept 
terms, and subject groupings. 
 
 a. Th e default covariance structure 
is  Variance Components  (VC). 
 VC is the default covariance 
structure for random eﬀ ects. 
Th is speciﬁ es a diagonal cova-
riance matrix for the random 
eﬀ ects; that is, it provides a sepa-
rate variance estimate for each 
random eﬀ ect, but not covari-
ances between random eﬀ ects. 
 In this case, there is only one random eﬀ ect (the intercept), so we can use the default VC. 
For models with random intercepts and slopes, a common choice is an “unstructured” (UN), 
or a completely general, covariance matrix, which ﬁ ts all variances and covariances between ran-
dom eﬀ ects. 
 
 b. We want the intercept to be included in the model, so click the  Include intercept option. 
 
 c. Th e  Subject Groupings box displays the  schcode variable that was speciﬁ ed as a subject variable 
in the  Specify Subjects and Repeated dialog box shown in step 2. We will specify  schcode as the 
subject for the random-eﬀ ects Level 1 part of this model. Click to select  schcode then click the 
right-arrow button to move the variable into the  Combinations box. 
 Click the CONTINUE button to return to the  Linear Mixed Models dialog box. 

92  Deﬁ ning a Basic Two-Level Multilevel Regression Model
 5.  In the  Linear Mixed Models dia-
log box, click the ESTIMATION 
button to access the  Linear Mixed 
Models: Estimation dialog box. Th e 
estimation method choices are 
maximum likelihood (ML) or 
restricted maximum likelihood 
(REML). In ML, both regression 
coeﬃ  cients and variance compo-
nents are included in maximizing 
the likelihood function—that is, the 
process of minimizing the diﬀ er-
ence between the sample covariance 
matrix and the model-implied co-
variance matrix. In REML, only the 
variance components are included in 
estimating the likelihood function; 
thus, REML is a restricted solution. 
 Because in REML the regression coef-
ﬁ cients are considered to be unknowns, 
taking the loss in degrees of freedom due 
to estimating  P + 1 regression coeﬃ  cients 
in the model results in unbiased estimates 
of variance components when there are 
small numbers of groups (Snijders & 
Bosker, 1999). With suﬃ  cient numbers 
of groups, the diﬀ erences in estimation methods are negligible. In this chapter and subsequent chapters, 
we will use REML to estimate the models when we are not making comparisons between successive 
models using modeling ﬁ t criteria involving both regression coeﬃ  cients and variance components. In 
this latter situation, ML estimation should be used (Hox, 2010). 
 Click the CONTINUE button to return to the  Linear Mixed Models dialog box. 
  6. In the  Linear Mixed Models dialog 
box, click the STATISTICS button 
to access the  Linear Mixed Models: 
Statistics dialog box. 
 Click and select the following three 
statistics to be included in the output: 
 Parameter estimates, Tests for covariance 
parameters , and  Covariances of random 
eﬀ ects . 
 Click the CONTINUE button to return 
to the  Linear Mixed Models dialog box. 

Deﬁ ning a Basic Two-Level Multilevel Regression Model  93
  7. Finally, in the  Linear Mixed Models 
dialog box, click the OK button to 
run the model. 
 Interpreting the Output From Model 1 (Null) 
 Th e ﬁ rst table ( Table 3.4 ) in the resulting output summarizes the total number of parameters 
being estimated (three). Th is is the same as we noted in Equation 3.4. Th e total parameters esti-
mated include the ﬁ xed-eﬀ ect value for the intercept, random Level 2 variance, and the Level 1 
variance (referred to as “Residual” in the IBM SPSS output). 
 Th e column referred to as “Number of Levels” describes the ﬁ xed eﬀ ects (1) and the number 
of random eﬀ ects (1). Th ere is one ﬁ xed eﬀ ect to be estimated (the intercept) and one random ef-
fect (the randomly varying intercept). Th e column referred to as “Subject Variables” indicates the 
number of levels in the analysis (i.e., in this case,  schcode  [the school identiﬁ er] implies a two-level 
analysis). Th e covariance structure describes the way the covariance matrix of random eﬀ ects is 
dimensionalized at the group level. In this case, we use the default (VC), which provides an esti-
mate of the intercept variance ( 
2
I
  ). However, in this ﬁ rst example, at Level 2 there is no random 
slope variance ( 
2
S
  ) or covariance between the intercept and slope. In this case, the VC covariance 
matrix will be the same as an identity matrix. 
 Th e next MIXED output describes model-ﬁ tting criteria ( Table 3.5 ). Th e ‒2 * log likelihood 
can be useful in examining the improvement of model ﬁ t when comparing two successive (or 
TABLE 3.4 Model Dimensiona
Number 
of Levels
Covariance 
Structure
Number of 
Parameters
Subject 
Variables
Fixed Effects
Intercept
1
1
Random Effects
Intercept
1
Variance 
Components
1
schcode
Residual
1
Total
2
3
a Dependent variable: math.
TABLE 3.5 Information Criteriaa
–2 Restricted Log Likelihood
48,877.256
Akaike’s Information Criterion (AIC)
48,881.256
Hurvich and Tsai’s Criterion (AICC)
48,881.257
Bozdogan’s Criterion (CAIC)
48,896.925
Schwarz’s Bayesian Criterion (BIC)
48,894.925
The information criteria are displayed in smaller-is-better forms.
a Dependent variable: math.

94  Deﬁ ning a Basic Two-Level Multilevel Regression Model
nested) models (i.e., by constructing a likelihood ratio test). Note that comparing nested models 
with this test should only be done when using ML estimation (and not REML, unless only the 
random parameters are compared). Th is output also includes other types of information about 
overall model ﬁ t. We will discuss model ﬁ t in further detail in Chapter 4. 
 Table 3.6  reports the estimates of ﬁ xed eﬀ ects in the model. Th e intercept (or grand mean for 
school outcomes) is estimated as 57.674. Th is represents the average level of math outcomes in the 
419 schools (and is close to the unadjusted mean of 57.734 for the 6,871 students in the sample). 
 Th e variance component output ( Table 3.7 ) indicates that the proportion of variance in achieve-
ment that lies between schools is 0.138. Th is can be calculated from Equation 3.5 [10.642/
(10.642 + 66.551) = 10.642/77.193], or 13.8%. Th e intraclass correlation provides a sense of the 
degree to which diﬀ erences in the outcome  Y exist between Level 2 units; that is, it helps answer 
the question of the existence or nonexistence of meaningful diﬀ erences in outcomes between 
the Level 2 units. Th e results of the null or no-predictors model (basically a one-way ANOVA 
analysis) suggest that the development of a multilevel model is warranted. Because intercepts 
vary signiﬁ cantly across schools (Wald  Z = 10.346,  p  .001), and the ICC suggests that about 
13.8% of the total variability in math scores lies between schools, we can develop a multilevel 
model ﬁ rst to explain this variability in intercepts within and between schools. 
 Th e reliability of the sample mean for any unit as an estimate for its population mean can also 
be assessed with information drawn from the variance components. Th is can provide the analyst 
with a means by which the assumption of diﬀ erences in outcomes across units can be checked. 
Because sample sizes are likely to diﬀ er within each unit  j , this reliability will vary across the 
Level 2 units. Reliability within any particular unit can be estimated as 
 
 
2
2
2
[
(
/
)]
2
2
B
B
W
j
(
/
(
//


(
2
(

 
(3.6) 
 In this example, the within-group sample sizes range from 12 to 37. Using the within-group sam-
ple sizes, we can estimate the reliability for the smallest unit as 10.64/[10.64 + (66.55/12)] = 0.657. 
Th is is contrasted with the school that has 37 students tested: 10.64/[10.64 + (66.55/37)] = 0.855. 
 Our ﬁ rst type of multilevel question was the following: Do the average math scores students 
receive vary across schools in the sample? We can answer that question from  Table 3.7 . Th e 
TABLE 3.7 Estimates of Covariance Parametersa
Parameter
Estimate
Std. Error
Wald Z
Sig.
95% Conﬁ dence Interval
Lower Bound
Upper Bound
Residual
66.551
1.172
56.802 .000
64.293
68.887
Intercept [subject = schcode]
Variance
10.642
1.029
10.346 .000
8.806
12.862
a Dependent variable: math.
TABLE 3.6 Estimates of Fixed Effectsa
Parameter
Estimate
Std. Error
df
t
Sig.
95% Conﬁ dence Interval
Lower Bound
Upper Bound
Intercept
57.674
0.188
416.066
306.344
.000
57.304
58.044
a Dependent variable: math.

Deﬁ ning a Basic Two-Level Multilevel Regression Model  95
Residual parameter describes the variance due to diﬀ erences among individuals within their 
respective units. As the table suggests, there is signiﬁ cant variance to be explained within groups 
(Wald  Z = 56.802,  p  .001). Similarly, the intercept parameter indicates that the intercepts vary 
signiﬁ cantly across the sample of schools (Wald  Z = 10.346,  p  .001). Th e Wald  Z test provides 
a  Z statistic summarizing the ratio of the estimate to its standard error. 
 Researchers have noted several problems with this statistic, which analysts may want to keep 
in mind. First, the Wald  Z test is a two-tailed test. Because variances cannot be smaller than 0 
(i.e., the null hypothesis is that the parameter = 0), when using the Wald Z to test a variance 
component, the test can be conducted as a one-tailed test (Hox, 2010). Th is means that when 
testing variances (as in  Table 3.7 ), the signiﬁ cance level can be divided by 2 to reﬂ ect a one-tailed 
probability level. Of course, in this instance this will not make a diﬀ erence, since the two-tailed 
 p value is very small. Note that for testing covariances between random eﬀ ects (which can take 
on positive or negative values), the two-tailed signiﬁ cance test can be maintained. Second, for a 
large estimated variance coeﬃ  cient, the standard error can be inﬂ ated, which lowers the Wald 
statistic value and, therefore, can make it overly conservative. Th ird, the Wald  Z test can also 
perform poorly under conditions of extreme multicollinearity or where there are small sample 
sizes and a variance component close to 0 since the test is based on a normal distribution (Hox, 
2010). In situations with small samples, the likelihood-ratio test (which can be constructed from 
IBM SPSS output) tends to be more reliable than the Wald test. Th is test, which is based on a 
chi-square distribution, can be constructed from the diﬀ erence in model deviance (i.e., deﬁ ned as 
‒2 * log likelihood) between two models (i.e., one with the parameter in question included versus 
one with it excluded). Models with lower deviance generally ﬁ t better than models with higher 
deviance. Th e chi-square diﬀ erence test, however, is also a two-tailed test, so the signiﬁ cance level 
should be divided by 2 if a variance component is tested (Berkhof & Snijders, 2001). Where 
there may be a discrepancy between the equivalent Wald Z test and a likelihood ratio test, the 
latter is preferred (Hox, 2010). 
 Step 2: Building the Individual-Level (or Level 1) Random Intercept Model 
 We will ﬁ rst build a model to examine variability in intercepts across schools. Th e individual-
level model is represented as Equation 3.7, which suggests that students’ SES background aﬀ ects 
math achievement. In a multilevel analysis, we work primarily with three equations: a within-
group (or individual-level) equation, a between-groups intercept equation, and a between-groups 
slope equation. For each individual  i in school  j , a proposed model similar to Equation 3.1 (sum-
marizing the eﬀ ect of student SES on math achievement) can be expressed as 
 
  Y ij  =   0 j     1j SESij    ij . 
(3.7) 
 Equation 3.7 suggests that at the individual level, within-groups student SES is related to 
achievement levels. 
 Equation 3.8 (which is the same as Eq. 3.3) implies that variation in intercepts can be de-
scribed by a school-level intercept (  00 ), or grand mean, and a random parameter capturing varia-
tion in individual school means ( u 0 j  ) from the grand mean: 
 
   0 j  =   00   u 0 j  . 
(3.8) 
 Equation 3.9 indicates that a within-unit slope (e.g., SES-achievement) can also be examined as 
randomly varying across units in the sample: 
 
   1 j  =   10   u 1 j  . 
(3.9) 

96  Deﬁ ning a Basic Two-Level Multilevel Regression Model
 More speciﬁ cally, the equation suggests that variability in slopes can be described by a school-
level average slope coeﬃ  cient (  10 ), or grand mean, and a random parameter capturing variation 
in individual school coeﬃ  cients ( u 1 j  ) from the grand mean. Because the slope is considered to 
be randomly varying across schools, the corresponding test of signiﬁ cance of the parameter will 
be based on the number of schools in the sample. Often, in building models, we may treat the 
within-group slopes as ﬁ xed in preliminary analyses (i.e., in situations where we are not testing a 
particular hypothesized relationship). In the case where we wish to treat the within-group slope 
as ﬁ xed (i.e., it does not vary across schools), Equation 3.9 would be rewritten as 
 
   1 j  =   10 
 (3.10) 
 As Equation 3.10 indicates, there is no random component ( u 1 j  ), so the slope coeﬃ  cient is ﬁ xed 
to one value for the sample. In the case where the Level 1 slope coeﬃ  cient is ﬁ xed, the signiﬁ -
cance test for the slope will be based on the number of individuals in the sample. If it turns out 
that both intercepts and slopes vary randomly across schools, Equations 3.8 and 3.9 suggest that 
group-level models can subsequently be built to explain variation in the random intercept and 
slope across groups. 
 Th e school-level model is represented as Equations 3.8 and 3.10, suggesting that only the 
school-level intercepts vary randomly across schools. We discuss the school-level predictive 
model in a subsequent section. Th rough substitution of Equations 3.8 and 3.10 into Equation 
3.7, we arrive at the combined equation describing Model 1: 
 
  Y ij  =   00   u 0 j     10 SES ij     ij  , 
(3.11) 
 which reﬂ ects that the component representing the Level 1 slope (  10 ) is multiplied by  SES ij  , 
which suggests it is a cross-level interaction, but with variance ﬁ xed to 0 at Level 2. Th e terms 
can then be reorganized with ﬁ xed eﬀ ects and variance components: 
 
  Y ij  =   00    10 SES ij    u 0 j     ij  . 
(3.12) 
 Deﬁ ning Model 2 with IBM SPSS Menu Commands 
 Settings will default to those used in Model 1. 
  1. Go to the toolbar and select ANALYZE, 
MIXED MODELS, LINEAR. 
 Th is command enables access to the  Linear Mixed 
Models: Specify Subjects and Repeated dialog box. 

Deﬁ ning a Basic Two-Level Multilevel Regression Model  97
  2. Th e  Linear Mixed Models: Specify Subjects and 
Repeated screen displays the default settings 
from the prior model. 
 Click the CONTINUE button to display the  Linear 
Mixed Models dialog box. 
  3. At Level 1, we will specify a predic-
tor variable ( ses ) to be used in the 
model. Locate and click  ses  from the 
left column listing, and then click the 
right-arrow button to move the vari-
able into the  Covariate(s) box. 
 We may now proceed to deﬁ ne ﬁ xed 
eﬀ ects for the variable. 
 Click the FIXED button to access 
the  Linear Mixed Models: Fixed Eﬀ ects 
dialog box. 
 
 4a. Within the  Linear Mixed Models: 
Fixed Eﬀ ects dialog box, click the 
pull-down menu to change the 
factorial setting to  Main Eﬀ ects . 
 
 b. Click to select  ses  from the  Factors 
and Covariates box, and then click 
the ADD button to move the vari-
able into the  Model  box. We now 
have the Level 1 model speciﬁ ed 
(Eq. 3.7). 
 
 c. Note on lower left of the screen 
that the intercept and the sum of 
squares ( Type III ) are the default 
settings. 
 Click the CONTINUE button to return 
to the  Linear Mixed Models dialog box. 

98  Deﬁ ning a Basic Two-Level Multilevel Regression Model
 Finally, in the  Linear Mixed Models dialog 
box, click the OK button to run the model. 
 Note: It is possible to save predicted esti-
mates and residuals for random and ﬁ xed 
eﬀ ects using the SAVE button. Th is would 
allow us to examine their normality and 
linearity. 
 Interpreting the Output From Model 2 
 Following is the IBM SPSS output generated from the Level 1 model.  Table 3.8  summarizes the 
total number of parameters being estimated (four). Th is ﬁ ts with Equation 3.11, suggesting two 
ﬁ xed-eﬀ ect parameters to be estimated (i.e., the intercept and the within-school predictor SES) 
and two variance parameters (the random Level 2 variance and the Level 1 residual variance). 
Th e column referred to as “Number of Levels” in  Table 3.8  describes the ﬁ xed eﬀ ects (two) and 
the number of random eﬀ ects (one). Th ere are two ﬁ xed eﬀ ects to be estimated (the intercept 
and SES) and one random eﬀ ect (the Level 2 variance component describing variability in the 
intercept across schools in the sample). Th e covariance structure describes the way the covariance 
matrix of random eﬀ ects is dimensionalized at the group level. In this case, we use the default 
(VC), which provides an estimate of the intercept variance but again no slope variance because 
we opted to ﬁ x the slope (nor will there be covariance between intercept and slope). Th is is the 
same as specifying an identity covariance matrix. 
 Table 3.9  presents the typical ANOVA table for examining the signiﬁ cance of the ﬁ xed-eﬀ ect 
parameters in the model. Th e large  F -ratio associated with SES in the table suggests that student 
SES is signiﬁ cantly related to student math scores. Th e test of the signiﬁ cance of the intercept is 
generally not of interest, as it is merely a test of whether the intercept is 0 in the model. As the 
table suggests, we can reject the null hypothesis that the intercept is 0 (i.e., we already know from 
the null model and descriptive analysis that it is approximately 57.6). 
 Table 3.10  provides the estimates of the ﬁ xed-eﬀ ect coeﬃ  cients. First, we can see that the 
intercept (adjusted for student SES) is 57.596. Th is represents the average school mean adjusted 
for student SES. Th e standard error is 0.133. Once again, the  t test of the signiﬁ cance of the 
TABLE 3.8 Model Dimensiona
Number 
of Levels
Covariance 
Structure
Number of 
Parameters
Subject 
Variables
Fixed Effects Intercept
1
1
ses
1
1
Random 
Effects
Intercept
1
Variance 
Components
1
schcode
Residual
1
Total
3
4
a Dependent variable: math.

Deﬁ ning a Basic Two-Level Multilevel Regression Model  99
intercept is not really interesting, since it is a test of whether the intercept is equal to 0. Th e 
degrees of freedom reported for each ﬁ xed eﬀ ect, which reﬂ ect the Satterthwaite (1946) correc-
tion for approximating the denominator degrees of freedom for signiﬁ cance tests of ﬁ xed eﬀ ects 
in models where there are unequal variances and group sizes, are useful in determining at what 
level each variable is measured in the model. For example, we know there are 419 schools in the 
sample. Th is is consistent with the 375.7 degrees of freedom reported in  Table 3.10 . In contrast, 
we know that SES is an individual-level variable. Th ere are 6,871 individuals in the sample, so 
the degrees of freedom of 3,914.6 are consistent with a variable measured at Level 1. We note 
in passing that if we wish to estimate a model without using the Satterthwaite correction for 
degrees of freedom, we can use GENLINMIXED (instead of MIXED) and specify a continu-
ous dependent variable with normal distribution and identity link function. In the  Build Options 
dialog box, for estimating degrees of freedom it is possible to select  Residual method  instead of 
 Satterthwaite approximation . It is also possible to select  robust  (rather than  model-based ) standard 
errors. In this case, for example, with robust standard errors, the standard error of the SES pa-
rameter would be more conservatively estimated at 0.145 (not tabled) as opposed to 0.137, as 
in  Table 3.10 . Analysts should keep in mind, however, that presently only REML estimation is 
available with that routine. 
 When we compare the intercepts between this model and the single-level linear regression 
analysis at the beginning of the chapter, we ﬁ nd that they are very similar (57.598 for the OLS 
model vs. 57.596 for the multilevel model). Th e diﬀ erence in standard errors between these two 
estimates is larger, as we would expect given the clustering and associated intraclass correlation. 
More speciﬁ cally, the estimated standard error ( SE ) from the OLS model was 0.098, and the 
standard error from the Level 1 multilevel model is 0.133, which is 36% larger. In that original 
single-level OLS analysis, the intercept described the average student achievement in the sample, 
without regard for students’ school settings. 
 Second, in this case, we are more interested in the slope for SES (  = 3.874) and the standard 
error (0.137). When we compare these against the single-level model, we ﬁ nd that they are con-
siderably diﬀ erent (i.e., for the single-level analysis, the slope was 4.255 and the standard error 
was 0.126). When we test hypotheses about ﬁ xed-eﬀ ect estimates (e.g., whether an unstandard-
ized regression coeﬃ  cient is signiﬁ cantly related to the dependent variable), the hypothesis test 
(generally a  t test) is based on the ratio of the unstandardized estimate to its standard error (e.g., 
for SES in the single-level model, this is 4.255/0.126 = 33.858). If the  t -ratio is signiﬁ cantly 
TABLE 3.9 Type III Tests of Fixed Effectsa
Source
Numerator df
Denominator df
F
Sig.
Intercept
1
375.699
187,802.817
.000
ses
1
3,914.638
803.954
.000
a Dependent variable: math.
TABLE 3.10 Estimates of Fixed Effectsa
Parameter
Estimate
Std. Error
df
t
Sig.
95% Conﬁ dence Interval
Lower Bound Upper Bound
Intercept
57.596
0.133
375.699
433.362
.000
57.335
57.857
ses
3.874
0.137
3,914.638
28.354
.000
3.606
4.142
a Dependent variable: math.

100  Deﬁ ning a Basic Two-Level Multilevel Regression Model
large, given the sample under consideration, the parameter is considered statistically signiﬁ cant. 
In the multilevel analysis, the ratio of the unstandardized estimate of SES to its standard error is 
smaller ( t -ratio = 28.344, but still is signiﬁ cant as we might expect). 
 Th ese contrasting results in our example illustrate the general point that parameter estimates 
and standard errors can be diﬀ erent in single-level versus multilevel analyses. As this simple mul-
tilevel analysis suggests, standard errors are often underestimated in single-level analyses, which 
can lead to a greater number of signiﬁ cant  t -values and, hence, support for a proposed model 
than would be observed if a proposed model were tested with multilevel techniques. Directly as 
a result, in a multilevel analysis, adjusting for clustering generally results in a reduction of Type I 
errors (false rejection of the null hypothesis). 
 Th e output also provides information about the model’s random parameters. Th e output sug-
gests that the addition of the within-group predictor, SES, reduces the residual (within-group) 
variability (i.e., from 66.551 in the null model to 62.807 in the Level 1 model). Th is reduction 
in variance between the one-way ANOVA (or null) model and the current model can be used 
to calculate a reduction in variance estimate (similar to  R 2 ) estimate for the within-school and 
between-school portions of the model. For each level, it is calculated as follows: 


2
2
2

1
2
1

M 1
22




2
22 
1
22
M 1
22
, 
(3.13) 
 where  M 1 refers to the one-way ANOVA (no predictors) Level 1 or Level 2 variance compo-
nents and  M 2 refers to the current model’s variance components. For the within-groups portion, 
this is calculated as 0.056 (66.551 ‒ 62.807 = 3.744/66.551 = 0.056). Th is suggests that student 
SES background accounts for about 6% of the within-school variability in student scores. No-
tice also that the within-school predictor also aﬀ ects that residual variability in intercepts at the 
school level. In particular, the initial variance component for schools, from the null model, was 
10.642. After SES is added, however, the between-school variance in math achievement shrinks 
to 3.469 (see  Table 3.11 ). For the reduction in variance between schools, this would be calculated 
as 0.674 [(10.642 ‒ 3.469)/10.642]. Th is suggests that within-group SES accounts for almost 
two thirds (67.4%) of the between-groups variability in achievement. In other words, a full two 
thirds of the variation in means across schools can be attributed to diﬀ erences in the socioeco-
nomic status of students in those schools. Another way of looking at this is that the initial vari-
ability in math achievement observed between schools (i.e., the ICC) is reduced considerably 
after controlling for student SES. From Equation 3.2, we ﬁ nd that ICC is now a little more than 
5% [3.469/(3.469 + 62.807) = 0.052]. 
 We note, however, this reduction-in-variance type of  R 2 statistic should be interpreted cau-
tiously because it is sometimes possible to obtain negative values for  R 2 . Th is is because the vari-
ance components may be less accurately estimated when there are no predictors in the model. 
For example, when an individual variable is sampled through a multilevel-sampling process, it 
may show some between-group variability even if there is no between-group variability present 
in the population (Hox, 2010). In these cases, Hox notes that the reduction-in-variance proce-
dures described previously may work as described in our example (i.e., where the within-group 
variable reduces between-group variability). In other situations, however, there may be variables 
that have almost no variation at one of the levels in the model. For example, this might occur if 
we had exactly the same percentage of males and females (50%) in each school. If there were no 
school-level variation in average gender composition, this would be less variance than expected 
by simple random sampling and could produce negative explained variance (for further discus-
sion, see Hox, 2010; or Snijders & Bosker, 1999). Hox notes that another problem that can occur 
is that if random slopes are present, the estimated residual variances are related to the scale of 
measurement chosen for the explanatory variables (i.e., how they are centered and whether they 
might be standardized). When the interest is in the size of the variance components produced, 

Deﬁ ning a Basic Two-Level Multilevel Regression Model  101
it is therefore desirable to center the explanatory variables with random slopes on their grand 
means since this will provide estimates for an “average” sampling unit (Hox, 2002). We discuss 
centering decisions further in subsequent chapters. 
 Th e covariance parameters table ( Table 3.11 ) also suggests that after the introduction of SES 
into the model, there is still signiﬁ cant variability to be explained both within schools (Wald 
 Z = 56.640,  p  .001) and between schools (Wald  Z = 6.439,  p  .001). Th e Wald  Z test suggests 
that, even after controlling for student SES within schools, a statistically signiﬁ cant amount of 
variation in outcomes still remains both within and between schools. Th is suggests that we could 
add other predictors (e.g., gender, ethnicity, and motivation) within schools and between schools 
(e.g., student composition and school process indicators) that might explain this residual vari-
ability in intercepts. 
 Th e ﬁ nal output ( Table 3.12 ) provides the random-eﬀ ect covariance structure for Level 2. In 
this case, there is only one random eﬀ ect. Because we speciﬁ ed the SES-achievement slope to be 
ﬁ xed within schools, there is no variance component describing variability in slopes. 
 Step 3: Building the Group-Level (or Level 2) Random Intercept Model 
 Next, we will add school-level variables to explain the variability in intercepts across schools. In 
this case, our thesis is that school context variables (i.e., aggregated student SES composition 
and type of school [public = 1, other = 0]) and the focus of the school’s academic program (i.e., 
the aggregate percentage of students who intend to study at 4-year universities after high school) 
will impact the remaining variability in achievement between schools. It is important to note that 
when Level 2 predictors are added to the model, care should be taken that every individual in each 
unit has the same value on that variable. Th is will ensure that the estimates are calculated based 
on the number of Level 2 units, rather than the number of Level 1 units in the model. If there are 
diﬀ erent values or missing values for some individuals, they should be changed for consistency. 
 At the school level, we must modify the intercept equation (Eq. 3.8) to indicate the three 
predictors that we are adding to the between-group portion of the model: 
 
  0 j  =   00    01 ses_mean j     02 pro4yrc j     03 public j    u 0 j  . 
(3.14) 
TABLE 3.11 Estimates of Covariance Parametersa
Parameter
Estimate Std. Error Wald Z
Sig.
95% Conﬁ dence Interval
Lower Bound Upper Bound
Residual
62.807
1.109
56.640 .000
60.671
65.019
Intercept [subject = 
schcode]
Variance
3.469
0.539
6.439 .000
2.559
4.704
a Dependent variable: math.
TABLE 3.12 Random-Effect Covariance Structure (G)a
Intercept | schcode
Intercept | schcode
3.469
Variance Components
a Dependent variable: math.

102  Deﬁ ning a Basic Two-Level Multilevel Regression Model
 Public school is a dummy-coded variable (1 = public, 0 = private). Because it is dichotomous, we 
can add it to the model either as a factor or as a covariate. Variables with three or more categories 
should be added as factors. When categorical variables are entered as factors, the reference group 
is the last category. If the user wishes to select a diﬀ erent category as the reference group, she or 
he could recode the variable. Substituting the intercept equation (Eq. 3.14) and the ﬁ xed slope 
equation (Eq. 3.10) into the Level 1 equation (Eq. 3.7) will result in the following combined 
equation with random Level 2 intercept: 
 
 Y ij  =   00    01 ses_mean j     02 pro4yrc j     03 public j     10 SES ij    u 0 j     ij  . 
(3.15) 
 We will ﬁ rst demonstrate how to add a public school indicator to the model as a factor. Th e 
other two variables are continuous, so they are added as covariates. In all, we are adding three 
ﬁ xed eﬀ ects, but the other parameters remain the same, so we are estimating a total of seven 
parameters in this model (i.e., ﬁ ve ﬁ xed eﬀ ects, the random Level 2 residual variance, and the 
Level 1 residual variance). 
 Deﬁ ning Model 3 with IBM SPSS Menu Commands 
 Settings will default to those 
used in Model 2. 
  1. Go to the toolbar and 
select ANALYZE, 
MIXED MODELS, 
LINEAR. 
 Th is command enables access 
to the  Linear Mixed Models: 
Specify Subjects and Repeated 
dialog box. 

Deﬁ ning a Basic Two-Level Multilevel Regression Model  103
  2. Th e  Linear Mixed Models: Specify Subjects and 
Repeated screen displays the default settings 
from the prior model. 
 Click the CONTINUE button to display the  Lin-
ear Mixed Models dialog box. 
  3. Th e  Linear Mixed Models dialog box settings 
default to those used in the prior model. 
 If there is a categorical indicator, it should be added 
as a factor. Each level of a factor can have a diﬀ erent 
linear eﬀ ect on the value of the dependent variable. 
If a variable is dichotomous, however, it may be 
added as either a factor or a covariate. We will dem-
onstrate by adding  public  as a factor ﬁ rst and then as 
a covariate. We note that in MIXED, the reference 
group for a variable entered as a factor is the last 
category. Th is means the estimate will be for the cat-
egory coded 0 (i.e., in this case, private schools = 0). 
Often, we ﬁ nd it is convenient to add dichotomous variables as covariates, so that the estimate will be 
for the category coded 1 (i.e., in this case, public = 1) instead of for the category coded 0. Th is is con-
sistent with dummy coding in multiple regression models. We note in passing that in some instances 
researchers might prefer other coding schemes such as eﬀ ect coding (e.g., ‒1, +1). 
 We will now introduce three Level 2 
predictors to the previous model ( public , 
 ses_mean , and  pro4yrc ). 
 
a.  First, click to select  public , and then 
click the right-arrow button (or 
“drag”) the variable to the  Factor(s) 
box. 
 
 b. Now click to select  ses_mean and 
 pro4yrc , and then “drag” both vari-
ables above  ses in the  Covariate ( s ) 
box. 
 Th e sequence of the variables is the follow-
ing:  ses_mean ,  pro4yrc , and  ses (see insert). 
 We will now designate ﬁ xed eﬀ ects, so 
click the FIXED button to access the  Linear Mixed Models: Fixed Eﬀ ects dialog box. 

104  Deﬁ ning a Basic Two-Level Multilevel Regression Model
 
 4a. Th e  Linear Mixed Models: 
Fixed Eﬀ ects dialog box dis-
plays the default setting from 
the prior model. To facilitate 
reading the output tables, we 
will rearrange the sequence 
order of the variables. First, 
remove  ses  from the model by 
clicking to select the variable 
and then clicking the RE-
MOVE button. 
 Note:  Main Eﬀ ects is the 
default setting from the prior 
model. 
 
 b. Now click to select four vari-
ables ( public ,  ses_mean ,  pro4yrc , 
and  ses ) from the  Factors and 
Covariates box, and then click 
the ADD button to move 
the variables into the  Model box. Th rough substitution, the two levels can be summarized as a 
single-equation model with ﬁ xed and random eﬀ ects (Eq. 3.15). 
 Click the CONTINUE button to return to the  Linear Mixed Models dialog box. 
  5. Finally, in the  Linear Mixed Models 
dialog box, click the OK button to 
run the model. 
 Interpreting the Output From Model 3 
 Th e ﬁ rst IBM SPSS output table ( Table 3.13 ) conﬁ rms that we are estimating seven total pa-
rameters in this model. 
 Table 3.14  describes the ﬁ xed-eﬀ ect estimates. Level 2 predictive models describe how diﬀ er-
ences in school variables (e.g., context, resources, student composition, and educational processes) 
may inﬂ uence individual processes within each school (Raudenbush & Bryk, 2002), for example, 
students’ levels achievement outcomes or the relationships between students’ background, moti-
vation, and previous learning and their current outcomes. In order to interpret the coeﬃ  cients, 
however, we need to know how the predictors are measured. More speciﬁ cally,  ses_mean is deﬁ ned 

Deﬁ ning a Basic Two-Level Multilevel Regression Model  105
a standardized ( z ) score (mean = 0,  SD = 1). Th e measure of the school’s academic focus ( pro4yrc ) 
is deﬁ ned by the proportion of students planning to attend a 4-year university (ranging from = 
0 to 1). School type is a dummy-coded variable (coded 1 = public high school, and 0 = private 
high school), and student SES is also a  z -score. We can therefore interpret the intercept as the 
average school math achievement in  public  high schools (since the reference category in this case 
is the category coded 1), where the proportion of students planning to attend a 4-year institution 
is 0, and where school SES composition and student SES are at their respective grand means (0). 
 Regarding the school-level predictors, controlling for the other predictors in the model, we 
ﬁ rst note that school type does not aﬀ ect achievement (  03 = 0.164,  p  .05). Because school type 
has been deﬁ ned as a factor in MIXED, the second category is the reference group. In this case, 
the variable was dummy coded as “public” (i.e., private = 0; public = 1), so the second category is 
redundant. Th e output in  Table 3.14  therefore suggests that private schools have slightly higher 
math scores. If instead we wish the reference category to be “private” schools (since we coded it 
0), we might choose to enter public as a covariate or else recode the variable. Regarding the type 
of academic environment (i.e., as deﬁ ned by the proportion of students who say they plan to 
attend a 4-year institution after high school), we ﬁ nd a positive relationship with math achieve-
ment (  02 = 1.420,  p  .01). Turning to SES, aggregate student SES composition aﬀ ects math 
achievement (  01 = 2.473,  p  .001), even after controlling for individual SES within schools. 
TABLE 3.13 Model Dimensiona
Number of 
Levels
Covariance 
Structure
Number of 
Parameters
Subject 
Variables
Fixed Effects Intercept
1
1
public
2
1
ses_mean
1
1
pro4yrc
1
1
ses
1
1
Random 
Effects
Intercept
1
Variance 
Components
1
schcode
Residual
1
Total
7
7
a Dependent variable: math.
TABLE 3.14 Estimates of Fixed Effectsa
Parameter
Estimate Std. Error
df
t
Sig.
95% Conﬁ dence Interval
Lower Bound Upper Bound
Intercept
56.277
0.430
411.160 130.978 .000
55.433
57.122
[public = 0]
0.164
0.276
409.345
0.595 .552
–0.378
0.707
[public = 1]
0.000b
0.000
–
–
–
–
–
ses_mean
2.473
0.307
709.247
8.059 .000
1.871
3.076
pro4yrc
1.420
0.471
413.879
3.012 .003
0.493
2.346
ses
3.191
0.158
6,448.937
20.220 .000
2.881
3.500
a Dependent variable: math.
b This parameter is set to 0 because it is redundant.

106  Deﬁ ning a Basic Two-Level Multilevel Regression Model
 We can write the estimated predictive score for individual  i in school  j for this model as 
follows: 
 Y   ij  = 56.28  2.47( ses_mean j  )  1.42( pro4yrc j  )  0.16( private j  )  3.19( SES ij  ). 
 We can interpret the intercept as the adjusted school math score when the predictors in the 
model are all equal to 0 (i.e.,  ses_mean  = 0,  pro4yrc = 0, and  student SES  = 0). In the case of  public , 
the reference group is actually public schools (coded 1) since when a dichotomous variable is 
entered in the model as a factor, the reference group is the second category. Th is suggests that the 
average school intercept of 56.28 is the predicted score for students in public schools (coded 1) 
when average school SES ( ses_mean ) is 0, where no students plan to attend 4-year institutions, 
and where individual SES is held at the grand-mean average (0). 
 If we hold the other variables in the predictive model constant, we can estimate the likely 
school mean if one of the predictors is increased by a unit. For example, if the proportion of stu-
dents planning to go to a 4-year institution after high school changes from 0 to 1 (i.e., implying 
a strong academic focus), the relevant part of the equation is as follows, since the other variables 
are held constant at 0: 
 Y ij  = 56.28  1.42( pro 4 yrc ). 
 For schools where the proportion of students planning to attend 4-year universities after high 
school is 0, the expected achievement intercept is 56.28 [56.28 + 1.42(0.0) = 56.28]. In contrast, 
where all students are planning to attend a 4-year institution the expected math level would be 
57.69 [56.28 + 1.42(1.0) = 57.70]. Readers should keep in mind that because of the coding of 
this variable as a proportion (i.e., ranging from 0 to 1), a change from 0 to 1 represents a 1-unit 
change. Th is illustrates why it is important to know what the unit of measurement is for each pre-
dictor. For the school where 0.75 plan to attend this type of institution, the estimated intercept 
would be a little lower at 57.35 [56.28 + 1.42(0.75) = 57.35]. 
 For aggregate SES composition, controlling the other variables in the model, a 1- SD increase 
in aggregate student SES composition above the grand mean would be expected to increase 
achievement from 56.28 to 58.75 [56.28 + 2.47(1) = 58.75]. We also note in passing that the 
addition of aggregate student SES background as a school predictor reduces the size of the SES 
eﬀ ect on math achievement observed within schools (i.e., the   1 slope for SES has an average 
eﬀ ect of   10 = 3.19 vs. 3.87 in the previous model). Th e model indicates that the eﬀ ects of student 
SES background are signiﬁ cant at both the individual and school levels. Th is is an example of a 
compositional eﬀ ect, or an eﬀ ect that tends to compound across levels of the data hierarchy. Th e 
compositional eﬀ ect is deﬁ ned as the extent to which the size of the organizational eﬀ ect diﬀ ers 
from the person-level eﬀ ect. More speciﬁ cally, compositional eﬀ ects occur when the aggregate of 
a person-level characteristic (i.e.,  ses_mean ) is related to the outcome, even after controlling for 
the eﬀ ect of the individual-level characteristic ( SES ) in the Level 1 model (Raudenbush & Bryk, 
2002). Compositional eﬀ ects often represent proxies for other types of organizational processes 
that occur (e.g., curricular organization, expectations for students, etc.). We take up estimating 
these types of models further in Chapter 4. 
 We also might want to think about how the Level 2 continuous predictors are centered. 
Let’s consider the proportion of students who are planning on attending a 4-year university. 
Since the intercept is the level of the outcome when the predictors are all 0, the intercept is the 
outcome when there are no students in the school planning on attending a 4-year university. 
In the sample, there may not be any schools where no students are planning to attend a 4-year 

Deﬁ ning a Basic Two-Level Multilevel Regression Model  107
university. Instead, we may wish to center this variable on its grand mean, so the intercept would 
then be deﬁ ned as the level of math outcomes for schools at the sample average in terms of 
students planning to attend 4-year universities. Centering continuous predictors on their grand 
means (which provides a mean of 0 but maintains the original standard deviation) can provide 
some advantages in multilevel modeling for interpreting intercepts, interaction terms, and vari-
ances (Hox, 2010). Standardizing the predictor, which is a type of centering, produces the same 
mean (0) as grand-mean centering but requires an additional calculation to make the standard 
deviation equal to 1.0 which, unlike grand-mean centering, also aﬀ ects the slope and variance 
estimates. For now, however, we will leave  pro4yrc in its raw proportion metric. 
 In  Table 3.15 , we present results where we entered public as a covariate instead of a factor. 
We provide MIXED menu commands for treating public school as a covariate (Model 3A) at 
the end of this section. Readers may also notice that this change results in a slightly diﬀ erent 
intercept (  00 = 56.44 vs. 56.28 in the previous model). Th is is because the intercept in this cur-
rent model now represents the mean for  private  schools (i.e., with public schools [coded 1] now 
being 0.16 of a point lower). Note that if we add the public school intercept and private school 
estimate (56.28 + 0.16), we obtain 56.44, which is the intercept in  Table 3.14  when  public  school 
is entered in the model as a factor instead of a covariate. In  Table 3.15 , we can see that public 
schools are 0.16 of point lower than this intercept. Th is suggests the two model formulations are 
the same, as we would expect. Since the estimates are the same, we will continue to deﬁ ne school 
type as a covariate rather than a factor for the rest of the analysis. 
 Th e estimates of the variance components in  Table 3.16  suggest that student SES at Level 1 
and the three predictors at Level 2 ( public ,  ses_mean , and  pro4yrc ) reduce the variance component 
at the school level substantially (i.e., from 10.64 in the one-way ANOVA model to about 2.40 
in  Table 3.16 ). We also point out that it is often the case that adjusting Level 2 unit means by 
characteristics of individuals within the units will reduce the variance at Level 2, even before the 
Level 2 predictors are added to the model. 
 From Equation 3.13, the reduction in variance observed at Level 2 between Models 1 and 
3A can be used to calculate the amount of variance accounted for ( R 2 ) at Level 2, which is 
TABLE 3.15 (Public School Deﬁ ned as a Covariate) Estimates of Fixed Effectsa
Parameter
Estimate
Std. Error
df
t
Sig.
95% Conﬁ dence Interval
Lower Bound
Upper Bound
Intercept
56.442
0.474
421.055
118.966
.000
55.509
57.374
public
–0.164
0.276
409.345
–0.595
.552
–0.707
0.378
ses_mean
2.473
0.307
709.247
8.059
.000
1.871
3.076
pro4yrc
1.420
0.471
413.879
3.012
.003
0.493
2.346
ses
3.191
0.158
6,448.937
20.220
.000
2.881
3.500
a Dependent variable: math.
TABLE 3.16 Estimates of Covariance Parametersa
Parameter
Estimate
Std. Error
Wald Z
Sig.
95% Conﬁ dence Interval
Lower Bound Upper Bound
Residual
62.630
1.103
56.784
.000
60.505
64.830
Intercept [subject = 
schcode]
Variance
2.395
0.444
5.399
.000
1.666
3.444
a Dependent variable: math.

108  Deﬁ ning a Basic Two-Level Multilevel Regression Model
0.774 [(10.64 ‒ 2.40)/10.64], or 77.4%. We could also calculate an  R 2 coeﬃ  cient for Level 1 
using the Level 1 one-way ANOVA and current Level 1 variance components in the same man-
ner [(66.55 ‒ 62.63)/66.55 = 0.059]. Student SES therefore accounts for about 6% of the Level 
1 variance in individual math achievement (about the same as the estimate in  Table 3.11 ). 
 Deﬁ ning Model 3A ( Public as Covariate) with IBM SPSS Menu Commands 
 Settings will default to those used in 
Model 2. Th e following instructions 
generate results shown in  Table 3.15 . 
  1. Go to the toolbar and select 
ANALYZE, MIXED MOD-
ELS, LINEAR. 
 Th is command enables access to the 
 Linear Mixed Models: Specify Subjects 
and Repeated dialog box. 
  2. Th e  Linear Mixed Models: Specify Subjects and 
Repeated screen displays the default settings 
from the prior model. 
 Click the CONTINUE button to display the  Linear 
Mixed Models dialog box. 

Deﬁ ning a Basic Two-Level Multilevel Regression Model  109
  3. Th e  Linear Mixed Models dialog 
box settings default to those used in 
Model 3. 
 
 a. We will change  public  from a factor 
to a covariate. First, click to select 
 public  then click or drag to remove 
the variable from the  Factor(s) box. 
 
 b. Click to select  public , and then 
drag the variable above  ses_mean in 
the  Covariate ( s ) box. 
 Th e sequence of the variables is:  public , 
 ses_mean ,  pro4yrc , and  ses (see insert). 
 We will now designate ﬁ xed eﬀ ects, so click 
the FIXED button to access the  Linear 
Mixed Models: Fixed Eﬀ ects  dialog box. 
 
 4a. Th e  Linear Mixed Models: Fixed 
Eﬀ ects dialog box displays the 
default setting from the prior 
model. To facilitate reading of 
the output tables, we will rear-
range the sequence order of the 
variables. First, remove  ses_mean , 
 pro4yrc , and  ses from the 
model by clicking to 
select the variables and then 
clicking the REMOVE button. 
 Note:  Main Eﬀ ects  is the default setting 
from the prior model. 
 
 b. Now click to select the four 
variables ( public ,  ses_mean , 
 pro4yrc , and  ses ) from the  Factors and Covariates box, and then click the ADD button to move 
the variables into the  Model box. 
 Click the CONTINUE button to return to the  Linear Mixed Models dialog box. 
  5. Finally, in the  Linear Mixed Models 
dialog box, click the OK button to run 
the model. 

110  Deﬁ ning a Basic Two-Level Multilevel Regression Model
 Step 4: Adding a Randomly Varying Slope (the Random Slope and Intercept Model) 
 Since individual SES is signiﬁ cantly related to achievement, we might want to see if the slope 
varies across schools. Th is could help us identify schools that are more (or less) equitable in pro-
ducing outcomes for students of varying SES backgrounds. It may be that school composition, 
school type, or school academic environment interact with the size of the within-school slope. 
We would like to ﬁ nd settings where the eﬀ ect of individual SES on achievement is reduced. 
In this case, we might ask: Do the slopes vary randomly across schools, and if they do, is there a 
relationship between features of schools’ environments and the strength of the slope relationship? 
 Th e important equation in this step is Equation 3.10 (  1 j  =   10 ). First, we will examine whether 
the slope varies, so we need to specify the SES-achievement slope as a randomly varying param-
eter in the model as it was originally deﬁ ned in Equation 3.9 (  1 j  =   10 +  u 1 j  ). When we substitute 
Equation 3.12 (i.e., the random intercept equation) and Equation 3.9 (i.e., the random slope 
equation) into the Level 1 equation (Eq. 3.7), we obtain the combined equation in Equation 
3.16. In creating the random slope portion of the combined equation, we note that   10 SES ij  + 
 u 1 j  SES ij  is substituted for   1 j  , as a result of multiplying   10 +  u  1 j  in Equation 3.9 by  SES ij  in Equa-
tion 3.7: 
 
   0 j  =  00    01 ses_mean j     02 pro4yrc j     03 public j    u 0 j     10 SES ij    u 1 j  SES ij     ij  . 
(3.16) 
 We can then reorder the terms, with the ﬁ xed eﬀ ects and then the random eﬀ ects and residual: 
 
  Y ij  =   00    01 ses_mean j     02 pro4yrc j     03 public j    10 SES ij    u 1 j  SES ij    u 0 j     ij  . 
(3.17) 
 We note that the substitution results in the more complex error term ( u 1 j  SES ij  ), which represents 
the Level 2 variance for the Level 1 SES-achievement slope ( 1 j  ). 
 Second, we need to change the covariance matrix of random eﬀ ects to accommodate the 
randomly varying slope. Th e other parameters in the model will remain the same. Adding the 
randomly varying slope will change the number of random eﬀ ects in the model from one (i.e., 
the intercept) to two (i.e., the intercept and the SES-achievement slope). If we only add the 
randomly varying slope, we will have a diagonal covariance structure. We can estimate this struc-
ture using the default VC matrix or by specifying a diagonal covariance matrix (DIAG) in IBM 
SPSS. As Equation 3.18 suggests, this provides estimates of the intercept and slope variances: 
 
 


2
0
I



2
0
I





0
I



2
0





2
0






0
S

. 
(3.18) 
 In contrast, an UN covariance matrix implies that the intercept and slope variances are esti-
mated, as well as the covariance between the intercept and slope. If we also estimate the covari-
ance (  IS  ) between the intercept and slope, an additional parameter is added to the model: 
 
 


2
IS


2
I


2
I
IS
 I




IS
 I


2






2






IS
S


IS
. 
(3.19) 
 Notice that because the covariance matrix is a square matrix, the covariance appears both above 
and below the diagonal. We can also specify an unstructured covariance-correlation matrix (ab-
breviated as UNR in MIXED). Th is would provide a correlation between the intercept and slope, 
which is often easier to interpret. Where we estimated seven parameters before (i.e., ﬁ ve ﬁ xed 


Deﬁ ning a Basic Two-Level Multilevel Regression Model  111
eﬀ ects, the random Level 2 variance, and the Level 1 residual variance), we will be estimating 
nine parameters now (i.e., ﬁ ve ﬁ xed eﬀ ects, three random Level 2 eﬀ ects, and the Level 1 residual 
variance). 
 Although it is usually desirable to obtain an estimate of the covariance between the intercept 
and slope, we note that sometimes a warning is issued when an unstructured covariance structure 
is used. For example, if the covariance or slope component is small, the estimation procedure may 
not be able to estimate the parameter adequately. In this case, when we ran the model with an 
unstructured matrix (i.e., Eq. 3.19), we received an error message ( Figure 3.3 ). 
 In such cases, the user can try specifying a diagonal covariance structure for the random pa-
rameters. Th e VC speciﬁ cation used in previous models will accomplish the needed change (see 
Eq. 3.18). Th is means that we will estimate a total of eight parameters as suggested by Equation 
3.17 (i.e., ﬁ ve ﬁ xed eﬀ ects, two random eﬀ ects at Level 2, and the Level 1 residual) since we are 
eliminating the covariance between the intercept and slope at Level 2 (as would be speciﬁ ed in 
Eq. 3.19). 
 Deﬁ ning Model 4 with IBM SPSS Menu Commands 
 Settings will default to those used in 
Model 3A. 
  1. Go to the toolbar and select 
ANALYZE, MIXED MOD-
ELS, LINEAR. 
 Th is command enables access to the 
 Linear Mixed Models: Specify Subjects 
and Repeated dialog box. 
 FIGURE 3.3  Warning message.

112  Deﬁ ning a Basic Two-Level Multilevel Regression Model
  2. Th e  Linear Mixed Models: Specify Subjects and 
Repeated screen displays the default settings 
from the prior model. 
 Click the CONTINUE button to display the  Linear 
Mixed Models dialog box. 
  3. Th e  Linear Mixed Mod-
els dialog box settings 
default to those used in 
Model 3A. 
 We will change the model’s 
random eﬀ ects, so click the 
RANDOM button to access 
the  Linear Mixed Models: 
Random Eﬀ ects dialog box. 

Deﬁ ning a Basic Two-Level Multilevel Regression Model  113
 
 4a. Th e  Linear Mixed Models: 
Random Eﬀ ects  displays 
the  Random Eﬀ ect 1 of 1 
screen with the default 
model settings of a  Vari-
ance Components structure 
and intercept. 
 
 b. We will add a random 
slope ( ses ) to the random-
eﬀ ects model, so ﬁ rst 
click the pull-down menu 
and change the setting to 
 Main Eﬀ ects. 
 
 c. Now click to select  ses , 
and then click the ADD 
button to move the vari-
able into the random-
eﬀ ects  Model  box (see Eq. 
3.17). 
 Click the CONTINUE button 
to return to the  Linear Mixed Models 
dialog box. 
  5. Finally, in the  Linear Mixed Models 
dialog box, click the OK button to 
run the model. 
 Interpreting the Output From Model 4 
 We can ﬁ rst conﬁ rm that we are estimating the eight parameters we anticipated (see  Table 3.17 
on page 114 ). 
 Similar to the last model, the ﬁ xed-eﬀ ects table ( Table 3.18 ) indicates that school aggregate SES, 
percentage of students attending 4-year universities, and individual SES all impact math achieve-
ment. We can observe that deﬁ ning individual SES as randomly varying changes the estimates 
slightly (  10 = 3.16) from the previous model with a ﬁ xed SES-achievement slope (  10 = 3.19). For 
example, the intercept changes slightly from 56.44 in  Table 3.15  to 56.47, and the coeﬃ  cient for 
the proportion of students planning to attend a 4-year university changes from 1.42 to 1.36. 

114  Deﬁ ning a Basic Two-Level Multilevel Regression Model
TABLE 3.17 Model Dimensiona
Number of 
Levels
Covariance 
Structure
Number of 
Parameters
Subject 
Variables
Fixed Effects
Intercept
1
1
public
1
1
ses_mean
1
1
pro4yrc
1
1
ses
1
1
Random Effects Intercept + sesa
2
Variance 
Components
2
schcode
Residual
1
Total
7
8
a Dependent variable: math.
TABLE 3.18 Estimates of Fixed Effectsa
Parameter
Estimate Std. Error
df
t
Sig.
95% Conﬁ dence Interval
Lower Bound Upper Bound
Intercept
56.470
0.472
419.501
119.749
.000
55.543
57.397
public
–0.120
0.274
407.915
–0.437
.662
–0.659
0.419
ses_mean
2.660
0.314
698.064
8.480
.000
2.044
3.275
pro4yrc
1.360
0.468
410.212
2.907
.004
0.440
2.280
ses
3.164
0.169
635.541
18.734
.000
2.832
3.496
a Dependent variable: math.
 For this model, our primary interest is with the estimates of the variance components (see 
 Table 3.19 ). Deﬁ ning the SES-math slope as randomly varying slightly changes the variance 
remaining at Level 1 (i.e., from 62.63 to 62.11). Th e intercept variance is slightly diﬀ erent also 
(i.e., from 2.40 to 2.11). Th e remaining intercept variance is still signiﬁ cant (Wald  Z = 4.74, 
 p  .001), which indicates that even after adding the three predictors to the model, there is still 
variance in intercepts that could be explained across schools by adding additional school-level 
variables. 
 Most important for our purposes, the slope variance (1.31) is signiﬁ cant (Wald  Z = 2.32, one-
tailed  p = .01). Th is suggests that the slopes vary across schools in the sample. We note that it can 
be more challenging to identify random slopes that vary signiﬁ cantly at higher levels in multi-
level models and to explain this variation because slopes are generally less reliably estimated than 
intercepts are estimated. Because the Level 1 slope depends on the distribution of the outcome 
within each unit and the strength of correlation between the two, as well the sample size of the 
unit (i.e., with smaller within-unit samples increasing error variance in estimating slopes), this 
lower reliability can also weaken the power to detect Level 2 relationships that might explain 
variation in slopes (Raudenbush & Bryk, 2002). 
 Because we could not ﬁ t the model with a proposed covariance between the intercept and 
slope, we cannot examine their relationship with information from this model. It turns out in 
this case that the “public” school variable is the problem. If we remove that variable from the 
model, we can estimate the covariance as ‒1.59 ( p  .01). 

Deﬁ ning a Basic Two-Level Multilevel Regression Model  115
 Step 5: Explaining Variability in the Random Slope (More Complex Random Slopes and 
Intercept Models) 
 Th e results in the variance components table ( Table 3.19 ) suggest that a model could be devel-
oped to explain the variability in the SES-achievement slope across schools (instructions pro-
vided in Model 5). Building such a model requires the introduction of cross-level interactions, 
or school-level variables that moderate (i.e., enhance or diminish) the size of the within-school 
SES–math achievement slopes. In simple models, the eﬀ ects of predictors on the outcome do not 
depend on the values of other predictors in the model. Interactions indicate that the relationship 
between a predictor and the outcome depends on the value of a third variable. MIXED allows 
the analyst to build a variety of diﬀ erent interactions within the ﬁ xed-eﬀ ects syntax statements 
or within the model-building menu statements. 
 Interactions are built as product terms from two predictors in the model ( A  *  B ), so there are 
three relevant parameters in the model ( A ,  B , and  A  * B ). More speciﬁ cally, interactions estimate 
the linear impact of  A on  Y when  A increases by 1 unit and the slope of  B remains constant. 
Th is implies that the slope coeﬃ  cient of  A added to the slope coeﬃ  cient of  A  * B  should be the 
complete coeﬃ  cient for  A (Hamilton, 1992). Th e same would apply for predicting the complete 
impact of  B on  Y with the interaction. 
 Cross-level interactions indicate similar types of interactions but across levels of the data 
hierarchy. For example, assume we wish to estimate the cross-level interaction of student SES 
composition ( ses_mean ) on the individual SES-achievement slope within schools in our data set. 
Th is is an example of a covariate-covariate interaction.  Table 3.20  suggests that if the impact 
of individual SES ( A ) on math achievement ( Y ) is 3.18 and the cross-level interaction term 
( ses *  ses_mean ) is ‒0.25, then the impact of a 1- SD increase in individual SES on math achieve-
ment is actually about 2.93 [3.18 + (–0.25) = 2.93] when the slope of  ses_mean  is held constant 
(2.78). Th is result implies that math achievement advantages due to individual SES become less 
pronounced in schools where the student SES composition is higher. (Refer to Appendix A for 
Table 3.20 syntax.) 
TABLE 3.19 Estimates of Covariance Parametersa
Parameter
Estimate Std. Error
Wald Z
Sig.
95% Conﬁ dence Interval
Lower Bound
Upper Bound
Residual
62.115
1.111
55.893
.000
59.974
64.331
Intercept [subject = schcode] Variance
2.112
0.445
4.741
.000
1.397
3.194
ses [subject = schcode]
Variance
1.314
0.566
2.320
.020
0.565
3.059
a Dependent variable: math.
TABLE 3.20 Estimates of Fixed Effectsa
Parameter
Estimate
Std. Error
df
t
Sig.
95% Conﬁ dence Interval
Lower Bound
Upper Bound
Intercept
57.606
0.138
495.962
418.600
.000
57.335
57.876
ses_mean
2.782
0.309
794.877
8.997
.000
2.175
3.389
ses
3.179
0.158
6,483.723
20.088
.000
2.869
3.489
ses_mean * ses
–0.251
0.257
1,607.930
–0.976
.329
–0.756
0.254
a Dependent variable: math.

116  Deﬁ ning a Basic Two-Level Multilevel Regression Model
 A factor-covariate cross-level interaction ( public  *  ses ) implies that the linear relationship be-
tween SES ( A ) and math achievement ( Y ) changes for diﬀ erent levels of factor ( B )—that is, types 
of schools. Th e output will provide an estimate for each level of the factor except the last category 
(which is the reference group). A factor-factor cross-level interaction (e.g.,  public   *   female ) im-
plies that each combination of factor levels may have a diﬀ erent linear eﬀ ect on the outcome. For 
this interaction, the output will provide coeﬃ  cients for each nonredundant combination using 
the last category of each factor as the reference group. We will discuss how to build these types 
of models in further detail in the next chapter. 
 For our purposes here, we will simply note that we add the three school-level predictors to the 
slope model to determine whether they might account for variability in the size of the SES–math 
achievement relationships across schools. Th e model can be written as 
 
  1 j  =   10    11 ses_mean j     12 pro4yrc j     13 public j    u 1 j  . 
(3.20) 
 When we substitute Equation 3.20 and Equation 3.14 into the Level 1 model (Eq. 3.7), we ob-
tain the following combined equation: 
 Y ij  =   00    01 ses_mean j     02 pro4yrc j     03 public j    10 SES ij     11 ses_mean j   *  SES ij  
    12 pro4yrc j  * SES ij     13 public j   *  SES ij    u 1 j  SES ij    u 0 j     ij  . 
(3.21) 
 After substitution, in Equation 3.21 we can see that the ﬁ rst and second lines specify the three 
cross-level interactions explaining (  1 j  ). Th e cross-level eﬀ ects (referred to as   11 to   13 ) appear 
in the output as interactions between aggregate school SES composition and the within-school 
SES–math achievement slope (i.e.,  ses_mean *  SES ), between aggregate proportion of students 
planning to attend 4-year colleges and the within-school SES–math achievement slope (i.e., 
 pro4yrc *  SES ), and between school type and SES ( public  *  SES ). Th e random coeﬃ  cient for the 
slope  u 1 j  takes into consideration reduction in variance due to the cross-level interactions on 
the SES-math slope (  1 j  ). Th is residual variance for the slope at Level 2 will reﬂ ect a diﬀ erence 
from the previous model with random slope (but no cross-level predictors) to the current model. 
Equation 3.21 will add 3 extra parameters to be estimated, making a total of 11 parameters to 
estimate. 
 Deﬁ ning Model 5 with IBM SPSS Menu Commands 
 Settings will default to those used in Model 4. 
  1. Go to the toolbar and select ANALYZE, 
MIXED MODELS, LINEAR. 
 Th is command enables access to the  Linear Mixed 
Models: Specify Subjects and Repeated dialog box. 

Deﬁ ning a Basic Two-Level Multilevel Regression Model  117
  2. Th e  Linear Mixed Models: Specify Subjects and 
Repeated screen displays the default settings 
from the prior model. 
 Click the CONTINUE button to display the  Lin-
ear Mixed Models dialog box. 
  3. Th e  Linear Mixed Models screen 
displays the default settings from the 
prior model. 
 We will add cross-level interactions to the 
model, so click the FIXED button to dis-
play the  Linear Mixed Models: Fixed Eﬀ ects 
dialog box. 
 Th ree cross-level interactions (or nested 
terms) will be created and added to the 
model:  ses_mean * ses ,  pro4yrc * ses , and 
 public  *  ses. Th ese interactions will tell us 
if individual student socioeconomic status 
( ses ) aﬀ ects math achievement for (a) 
school aggregate student socioeconomic status within schools ( ses_mean ); (b) percentage of students 
attending 4-year universities ( pro4yrc ); and (c) school type ( public ). 
 Note: To reproduce  Table 3.19 , perform steps 4a to 4g, and then generate the model results. 

118  Deﬁ ning a Basic Two-Level Multilevel Regression Model
 Add First Interaction to Model 5:  ses_mean * ses 
 
 4a. Click to select  Build nested 
terms . 
 
 b. Now click to select the vari-
able  ses_mean from the  Fac-
tors and Covariates box. 
 
 c. Click the arrow button below 
the  Factors and Covariates 
box. Th is moves  ses_mean into 
the  Build Term box to create 
a cross-level interaction by 
linking variables and terms. 
 
 d. Next, click the BY * button, 
which will insert the com-
putation command symbol: 
 ses_mean * 
 
 e. Click to select  ses  from the 
 Factors and Covariates box. 
 
 f. Click the arrow button below 
the  Factors and Covariates box 
to move  ses into the  Build Term 
box and complete the interaction 
term:  ses_mean * ses . 
 
 g. Click the ADD button to transfer 
the interaction into the  Model 
box. 
 Add Second Interaction to Model 5:  pro4yrc * ses 
 Repeat steps 4b to 4g using  pro4yrc and  ses for the interaction. 
 Add Third Interaction to Model 5:  public * ses 
 Repeat steps 4b to 4g using  public and  ses for the interaction. 
 Th e completed model (Eq. 3.21) is shown in the insert. Click the CONTINUE button to 
return to the  Linear Mixed Models dialog box. 
  5. Finally, in the  Linear Mixed Models 
dialog box, click the OK button to 
run the model. 

Deﬁ ning a Basic Two-Level Multilevel Regression Model  119
 Interpreting the Output From Model 5 
 We can conﬁ rm in the model dimension table ( Table 3.21 ) that we estimated 11 parameters. No-
tice also that the Level 2 variance components table is designated as Variance Components (i.e., 
a diagonal matrix of random eﬀ ects). Th e table speciﬁ es the three cross-level interactions ( ses_
mean *  ses ,  public  *  ses , and  pro4yrc *  ses ) that were added to the ﬁ xed-eﬀ ect portion of the model. 
 Once again, the ﬁ xed-eﬀ ects table ( Table 3.22 ) indicates that aggregate SES and proportion 
of students planning on attending 4-year postsecondary institutions aﬀ ect achievement in math. 
School type is not related to math achievement. Within schools, individual SES remains signiﬁ -
cantly related to math achievement. 
 Regarding the slope model, the cross-level interactions suggest that the within-school 
SES-achievement slope is diﬀ erent for public and private schools. As we noted previously, 
this is an example of a factor by covariate interaction, which suggests that in public schools 
the relationship between student SES and math achievement is weaker than in private schools 
TABLE 3.21 Model Dimensiona
Number of 
Levels
Covariance 
Structure
Number of 
Parameters
Subject 
Variables
Fixed Effects
Intercept
1
1
public
1
1
ses_mean
1
1
pro4yrc
1
1
ses
1
1
ses_mean * ses
1
1
pro4yrc * ses
1
1
public * ses
1
1
Random Effects Intercept + sesa
2
Variance 
Components
2
schcode
Residual
1
Total
10
11
a Dependent variable: math.
TABLE 3.22 Estimates of Fixed Effectsa
Parameter
Estimate
Std. Error
df
t
Sig.
95% Conﬁ dence Interval
Lower Bound
Upper Bound
Intercept
56.505
0.485
450.229
116.427
.000
55.551
57.459
public
–0.120
0.274
405.467
–0.437
.662
–0.659
0.419
ses_mean
2.706
0.324
759.554
8.351
.000
2.070
3.343
pro4yrc
1.362
0.479
439.899
2.841
.005
0.420
2.304
ses
3.757
0.606
518.400
6.203
.000
2.567
4.947
ses_mean * ses
–0.137
0.299
303.798
–0.457
.648
–0.724
0.451
pro4yrc * ses
–0.130
0.592
479.307
–0.220
.826
–1.294
1.033
public * ses
–0.668
0.331
404.838
–2.018
.044
–1.319
–0.017
a Dependent variable: math.

120  Deﬁ ning a Basic Two-Level Multilevel Regression Model
(  13 = ‒0.668,  p  .05). More speciﬁ cally, in public schools (coded 1), the combined eﬀ ect of 
individual SES on math achievement would be 3.09 [3.76 + (–0.67)(1) = 3.09]. In contrast, 
in private schools (coded 0), the SES-achievement slope would be 3.76 [3.76 + (–0.67)(0) 
= 3.76]. Since the slopes are diﬀ erent, it implies that the social distribution eﬀ ects due to 
individual SES on math learning are less consequential for students in public schools (i.e., 
indicated by a ﬂ atter slope) than for students in private schools.  Table 3.22  also suggests that 
aggregate school SES composition did not moderate the within-school SES–math achieve-
ment slope (  = ‒0.14,  p  .05). Similarly, the proportion of students indicating that they 
plan to attend a 4-year college did not moderate the within-school SES-achievement slope 
(  = ‒0.13,  p  .05). Th ese ﬁ ndings provide partial support for our initial research goal of iden-
tifying school settings where the within-school relationship between SES and math achieve-
ment (i.e., our measure of the social distribution of learning) is diminished. 
 Th e variance components table ( Table 3.23 ) suggests that there is still signiﬁ cant variance in 
the intercept and the SES-achievement slope to be explained across schools, even after adding 
this set of school variables to the model. For example, the SES-achievement slope still varies 
across schools (Wald  Z = 2.375, one-tailed  p = .009). 
 We can remove the interaction terms that are not statistically signiﬁ cant if we wish to obtain 
a more parsimonious model (see  Table 3.24  and instructions for Model 5A). Th e variables that 
comprise the signiﬁ cant interaction term in the model, however, should be retained in the model 
even if they are not signiﬁ cant (e.g., public). In a subsequent chapter, we describe procedures for 
examining the ﬁ t of a comparison model against a more restricted model. We exclude the pre-
sentation of the variance components for this reduced model, as they are similar to the previous 
model. 
TABLE 3.23 Estimates of Covariance Parametersa
Parameter
Estimate
Std. Error
Wald Z
Sig.
95% Conﬁ dence Interval
Lower Bound
Upper Bound
Residual
62.101
1.111
55.882
.000
59.961
64.318
Intercept [subject = schcode]
Variance
2.087
0.445
4.687
.000
1.374
3.171
ses [subject = schcode]
Variance
1.345
0.566
2.375
.018
0.589
3.070
a Dependent variable: math.
TABLE 3.24 Estimates of Fixed Effectsa
Parameter
Estimate
Std. Error
df
t
Sig.
95% Conﬁ dence Interval
Lower Bound
Upper Bound
Intercept
56.440
0.471
418.862
119.855
.000
55.515
57.366
public
–0.123
0.274
406.624
–0.449
.653
–0.662
0.415
ses_mean
2.659
0.313
697.326
8.491
.000
2.044
3.274
pro4yrc
1.404
0.468
410.165
3.003
.003
0.485
2.323
ses
3.659
0.292
461.438
12.527
.000
3.085
4.234
public * ses
–0.682
0.328
395.850
–2.078
.038
–1.328
–0.037
a Dependent variable: math.

Deﬁ ning a Basic Two-Level Multilevel Regression Model  121
 Deﬁ ning Model 5A with IBM SPSS Menu Commands 
 Settings will default to those 
used in Model 5. 
  1. Go to the toolbar and 
select ANALYZE, 
MIXED MODELS, 
LINEAR. 
 Th is command enables access 
to the  Linear Mixed Models: 
Specify Subjects and Repeated 
dialog box. 
  2. Th e  Linear Mixed Models: Specify Subjects and 
Repeated screen displays the default settings 
from the prior model. 
 Click the CONTINUE button to display the  Lin-
ear Mixed Models dialog box. 

122  Deﬁ ning a Basic Two-Level Multilevel Regression Model
  3. We will modify the model’s ﬁ xed 
eﬀ ects, so click the FIXED button to 
access the  Linear Mixed Models: Fixed 
Eﬀ ects dialog box. 
  4. Th e  Linear Mixed Models: 
Fixed Eﬀ ects dialog box 
displays the default setting 
from the prior model. We 
will remove two cross-level 
interactions ( ses_mean * ses 
and  pro4yrc * ses ) from the 
model. 
 Click to select  ses_mean * ses and 
 pro4yrc * ses , and then click the 
REMOVE button. Th e ﬁ nal 
model is shown in the insert. 
 Click the CONTINUE button 
to return to the  Linear Mixed 
Models dialog box. 
  5. Finally, in the  Linear Mixed Models 
dialog box, click the OK button to 
run the model. 
 We next provide a simple graph to 
illustrate what the eﬀ ect of a cross-level 
interaction looks like ( Figure 3.4 ). We 
include the menu commands for creating 
the graph at the end of this section. For a 
factor * covariate interaction, the relation-
ship implies that the group regression lines 
are not parallel. A cross-level interaction 
represents the eﬀ ect of a unit-level variable 
on a within-unit relationship. 

Deﬁ ning a Basic Two-Level Multilevel Regression Model  123
 To illustrate this relationship in a rough way, we ﬁ rst aggregated individual math achieve-
ment and SES to the school level. We then created a subset of schools roughly 1  SD above and 
below the grand mean of achievement. Th is illustrates the approximate 0.7-point steeper SES-
achievement slope associated with private schools. Because we focused on groups of schools 
some distance from the grand mean, the graph also provides a sense of where the regression lines 
for public and private school SES-achievement slopes cross. 
 Graphing a Cross-Level Interaction (SES-Achievement Relationships in High- 
and Low-Achieving Schools) with IBM SPSS Menu Commands 
 Launch the IBM SPSS appli-
cation and select the data ﬁ le: 
 ch3schoolgraph.sav. 
  1. Go to the toolbar and 
select DATA, SELECT 
CASES. 
 Th is command will open the 
 Select Cases dialog box. 
 FIGURE 3.4  SES-achievement relationships in high- and low-achieving public and private schools.

124  Deﬁ ning a Basic Two-Level Multilevel Regression Model
 
 2a. Within the  Select Cases 
dialog box, select the option 
 If condition is satisﬁ ed . 
 
 b. Click the IF button, which 
will open the  Select Cases: If 
dialog box. 
 
 c. Begin deﬁ ning the condi-
tional term by clicking to 
select  graph , and then click 
the right-arrow button to 
move the variable into the 
box. 
 
 d. Next, click the equal sign 
( = ) to add the term to the 
box. 
 
 e. Finally, click “1” to complete 
the condition:  graph = 1 . 
 Click CONTINUE then OK to 
close the main  Select Cases dialog 
box and return to the IBM SPSS 
main screen. 
  3. In the IBM 
SPSS tool-
bar, select 
GRAPHS, 
LEGACY 
DIALOGS, 
SCATTER/
DOT. 
 Th is command will 
open the  Scatter/Dot 
box. 

Deﬁ ning a Basic Two-Level Multilevel Regression Model  125
  4. Click the SIMPLE SCATTER option in the 
 Scatter/Dot box. Th en click the DEFINE button to 
open the  Simple Scatterplot box. 
 
 5a. Within the  Simple Scatterplot box, click to 
select the  math_mean variable from the left 
column. Th en click the right-arrow button 
to move  math into the  Y Axis box. 
 
 b. Next, click  ses_mean to select the variable 
from the left column, and then click the 
right-arrow button to move the variable 
into the  X Axis box. 
 
 c. Finally, click  public to select the variable 
from the left column. Th en click the right-
arrow button to move the variable into the 
 Set Markers by box. 
 Click OK to generate the scatterplot. 
  6. Th e IBM SPSS output will display the 
scatterplot. 
 
 a. Place the cursor on the image and 
double-click to open the  Chart Editor. 
 
 b. On the  Chart Editor  short-cut icon bar, 
click the ADD FIT LINE AT SUB-
GROUPS icon that has the  X and  Y 
axes. Th is will generate the ﬁ t line and 
the linear  R -square of 0.387 for this 
subset of the sample. 
 
 c. Variable names appearing in the chart 
may be changed by double-clicking the 
text and typing in the preferred label or 
title. 

126  Deﬁ ning a Basic Two-Level Multilevel Regression Model
 Centering Predictors 
 In this last section of the chapter, we discuss centering the predictors in a little more detail. In 
multilevel models, it is important that the ﬁ xed eﬀ ects can be readily interpreted in relation to 
the proposed goals of the research. Centering decisions concern how to rescale the explanatory 
variables so that the intercept can be deﬁ ned most advantageously. Although there is no one cor-
rect decision in every instance, centering decisions should be made primarily on the basis of the 
conceptual questions under investigation (Hofmann & Gavin, 1998). 
 Centering provides the expected value of an outcome  Y when the covariate is equal to some 
designated value of theoretical interest (e.g., the unit mean or the overall sample mean). Mean 
centering is most commonly used in multilevel studies (e.g., grand mean and group mean). Th ere 
are, however, other options (e.g., the median and the within-group standard deviation of the 
within-group coeﬃ  cient of variation) for centering variables (Plewis, 1989). We note that cen-
tering is also required in some situations in order to achieve a solution that converges (i.e., does 
not produce an error message). Where there are widely diﬀ erent means and variances across 
groups, it may be necessary to center the raw estimates in order to achieve model convergence 
(Hox, 2010). In the examples in this workbook, for example, we encountered several situations 
when investigating random Level 1 slopes where the raw metric results would not converge, 
whereas centered results did converge. 
 As we have noted, alternative centering strategies can change the values of some parameters 
in a model. In  Table 3.25 , we illustrate the eﬀ ects of diﬀ erent centering strategies where there 
is a random intercept only (Model 1) and where there is a random intercept and random slope 
(Model 2). We used a similar data set from the extended example in this chapter with a continu-
ous Level 1 predictor (student SES) to illustrate the eﬀ ects of the centering strategies on model 
parameters. In this case, we created a natural metric for SES, which ranges from 0 to 100, with a 
mean of 50.00 and standard deviation of 28.868. Model 1 illustrates the eﬀ ects of diﬀ erent cen-
tering strategies for a random intercept and  ﬁ xed Level 1 slope. As the table suggests, the natural 
metric estimate of SES and grand-mean-centered estimate (GMSES) are the same (  = 0.082, 
 p  .05); however, the location of the respective  Y intercepts diﬀ ers. Th e raw metric produces a  Y 
intercept, which represents family SES for the lowest individual in the sample (which was coded 
SES = 0). For this individual, the expected math score would be 56.847. Keep in mind that in our 
example SES = 0 represents the individual with the lowest family income in the sample, but not 
an individual with family income of $0.00. 
 Grand-mean centering (i.e., where the grand mean is subtracted from individuals’ levels of 
family income) often facilitates the interpretation of a multilevel model since it results in an in-
tercept that can be interpreted as the expected value of  Y when the predictor is at its grand-mean 
value (0). Th e standard deviation, however, remains in the original metric. In this case, the origi-
nal grand mean for SES (50.00) is rescaled to be 0, but the standard deviation remains 28.868. 
Where Level 1 predictors are all grand-mean centered, the solution provides a Level 2 intercept 
that has been adjusted for the Level 1 predictors. One related advantage of grand-mean center-
ing is that it helps the analyst interpret the variances for the intercept and slopes as the expected 
variance when all explanatory variables are equal to 0—that is, the expected variances for the 
“average” individual (Hox, 2010). 
 In contrast, standardizing a continuous predictor ( X = 0,  SD = 1) has the same eﬀ ect on the 
intercept as grand-mean centering, but it also changes the metric of the predictor by transform-
ing the standard deviation from its original metric (in this case, 28.868) to be equal to 1.0. 
More speciﬁ cally, when the continuous predictor is standardized (i.e., a  z -score), it is in standard 
deviation units. Th erefore, as in Model 1, the predictor’s metric will be diﬀ erent from the grand-
mean-centered estimate (  = 0.082). In contrast, the standardized estimate of SES is 2.366, 
suggesting that an increase in student SES of 1  SD would produce a 2.344 increase in the math 
outcome. 

Deﬁ ning a Basic Two-Level Multilevel Regression Model  127
 In many cases, the uncentered or natural metric may be a logical choice since for the natural 
metric the intercept is deﬁ ned as the level of  Y when  X is 0 (0.0). Some natural metric solutions, 
however, may have little practical importance in organizational studies (Kreft, de Leeuw, & 
Aiken, 1995). In the example in  Table 3.25 , there might be occasions where we prefer center-
ing on the lowest individual in the sample (i.e., where SES is scaled to be equal to 0), but most 
often it is convenient to center on the average level of the predictor in the sample. Importantly, 
we draw attention to the fact that for models with a random intercept only, solutions where the 
Level 1 predictors are in their natural metrics, grand-mean centered, or standardized will produce 
equivalent models (i.e., in terms of deviance, or ‒2 log likelihood [–2LL], and residual variances) 
as shown in  Table 3.25 (for further discussion, see Hox, 2010; or Raudenbush & Bryk, 2002). 
 Group-mean centering produces an intercept equal to the expected value of  Y for an indi-
vidual when  X is equal to the group’s mean. Unlike grand-mean centering, with group-mean 
centering, the unit means are  unadjusted  for diﬀ erences among their members. Group-mean cen-
tering puts the attention more on relational advantages that some individuals may enjoy within 
their particular social group. It is important to emphasize that group-mean-centered solutions 
are not the same as grand-mean or natural metric solutions. In contrast to the previous center-
ing strategies, when we use group-mean centering of explanatory variables, the meaning of the 
TABLE 3.25 The Effects of Different Centering Strategies
Variables
SES
ZSES
GMSES
GRPSES
GRPSES(1)
Model 1: Random Intercept
Between Schools
 Intercept
56.847*
60.945*
60.945*
60.896*
53.567*
Mean SES
0.148*
Within Schools
Estimate
0.082*
2.366*
0.082*
0.065*
0.065*
Variance Components
Level 2 Variance
23.515*
23.515*
23.515*
29.957*
21.667*
Level 1 Variance
215.435*
215.435*
215.435*
215.125*
215.416*
Parameters
4.000
4.000
4.000
4.000
5.000
–2 Log Likelihood
104,289.430
104,289.430
104,289.430
104,403.419
104,246.714
Model 2: Random Slope
Between Schools
Intercept
56.862*
61.079*
61.079*
60.904*
53.587*
Mean SES
0.148*
Within Schools
Estimate
0.084*
2.434*
0.084*
0.063*
0.036
Mean SES*Estimate
0.001
Variance Components
Level 2 Slope
0.003*
2.459*
0.003*
0.003*
0.003*
Covariance
–0.375*
–6.571*
–0.228*
–0.243*
–0.249*
Level 2 Variance
53.062*
22.924*
22.924*
30.186*
21.915*
Level 1 Variance
213.682*
213.682*
213.682*
213.415*
213.660*
Parameters
6.000
6.000
6.000
6.000
8.000
–2 Log Likelihood
104,229.679
104,229.679
104,229.679
104,365.540
104,196.881
*p < .05.

128  Deﬁ ning a Basic Two-Level Multilevel Regression Model
model is changed (Hox, 2010). Th is is because group-mean centering separates the within-group 
and between-group portion of the predictor estimate; that is, the information concerning pos-
sible diﬀ erences in the predictor across Level 2 units is removed. 
 As Raudenbush and Bryk (2002) suggest, it often desirable to group-mean center a predictor 
if the focus of the analysis is on producing an unbiased estimate of the within-group (Level 1) 
eﬀ ect, since group-mean centering results in a Level 2 mean that is unadjusted for the Level 1 
predictor. If the analyst is interested in person-level variables (but where individuals are nested 
in groups), ignoring the nested structure of the data can lead to misleading results at Level 1 
(Cronbach, 1976), since slope coeﬃ  cients derived from the total covariance matrix (i.e., the 
covariance matrix based on the number of individuals in the study) will generally represent un-
interpretable blends of their within-group and between-group estimates. Similarly, in this situ-
ation, the grand-mean-centered estimates also represent a mix of the within-group slope and 
any diﬀ erence in the slopes that might exist across groups (i.e., in the case where the slope varies 
randomly across groups) since the model with grand-mean centering actually involves both the 
individual estimates of  X ij  and the Level 2 mean of  X as adjusted (Raudenbush & Bryk, 2002). 
 In  Table 3.25 , for the model with random intercept only (Model 1), we can observe that the 
group-mean-centered solution (GRPSES) results in a diﬀ erent intercept estimate (60.896), a 
diﬀ erent estimate of the Level 1 predictor (  = 0.065), as well as diﬀ erent estimates of the Level 2 
intercept variance (29.957) and model deviance, or ‒2LL. Th e Level 2 intercept variance will 
typically be larger than in the previous solutions. Th is is because the Level 2 intercepts in the 
group-centered solution are unadjusted, whereas the intercepts in the previous solutions are ad-
justed for the Level 1 predictor (Raudenbush & Bryk, 2002). As Raudenbush and Bryk note, 
because  Mean SES  is likely related to the intercept (and also the slope, as in Model 2), we might 
attempt to add  Mean SES  to the Level 2 model [as we do with GRPSES(1) in the last column] 
in an eﬀ ort to resolve the discrepancy in Level 2 intercept variance between the previous center-
ing solutions and the group-centered solution. Because group-mean centering results in a diﬀ er-
ent type of model (i.e., by isolating the within-group portion of the estimate and removing the 
between-group diﬀ erences in that portion of the estimate), however, one cannot simply add the 
mean for the variable back at the group level [as in the GRPSES(1) column], since that results 
in adding more information that is not present in the raw scores (i.e., by adding one additional 
parameter to estimate). By adding another parameter, the model deviance will be smaller than 
the previous solutions for Model 1 (Raudenbush & Bryk, 2002). For example, in  Table 3.25  we 
can observe for GRPSES(1) that the ‒2LL estimate is the lowest of the previous four centering 
decisions, reﬂ ecting the addition of the  Mean SES  parameter at Level 2. 
 Centering Predictors in Models with Random Slopes 
 Centering decisions can also be important in multilevel models where there are anticipated 
cross-level interactions—that is, where the analyst wishes to examine variability in slopes across 
groups by building a model with Level 2 predictors to explain this variability. Where the focus 
in on random slopes, grand-mean-centering and group-mean-centering approaches generally 
address diﬀ erent research questions since grand-mean centering puts the focus on Level 2 rela-
tionships after adjustment for Level 1 relationships. Moreover, the eﬀ ects of Level 2 predictors 
will be adjusted for diﬀ erences between organizations in the mean of the  X predictor (Rauden-
bush & Bryk, 2002). In contrast, group-mean centering is the better approach if the focus is on 
optimal estimation of Level 1 eﬀ ects that consider nesting since group-mean centering removes 
confounding between-group eﬀ ects in the Level 1 predictors. 
 It is important to note that modeling random slopes at Level 2 introduces modeling cross-
level interactions. Cross-level interactions refer to situations where Level 2 variables are proposed 
to moderate the strength of Level 1 relationships, such as the eﬀ ect of student SES on students’ 
achievement. Cross-level interactions can actually be proposed as moderators of randomly vary-
ing Level 1 slopes or as moderators of ﬁ xed within-group relationships. In this latter case, the 

Deﬁ ning a Basic Two-Level Multilevel Regression Model  129
slopes do vary from group to group, but rather than their variation being random, they vary as a 
function of the Level 2 moderator (Raudenbush & Bryk, 2002). Cross-level interactions intro-
duce another aspect to be considered—that is, the interpretation of the interaction. In regression 
models, the interpretation is typically the expected value of one predictor when the other one 
is equal to 0 and vice versa (Hox, 2010). Th erefore, we want to exercise some care in selecting a 
value for 0 that is meaningful and actually occurs in the data (Hox, 2010). 
 Given this, natural (or raw) metric solutions are often diﬃ  cult to interpret since the level of  Y 
(i.e., the  Y intercept) may be diﬃ  cult to interpret when  X is 0. In contrast, centering on the grand 
mean will produce an interaction coeﬃ  cient interpreted as the eﬀ ect of the ﬁ rst predictor on  Y 
for individuals who are at the grand mean (0) on the other predictor. Grand-mean centering is 
one straightforward way to facilitate the interpretation of interactions. Group-mean centering 
is also appropriate where there are hypotheses involving interactions among Level 1 variables, 
as in the case with cross-level interactions, since the Level 2 variables proposed to moderate the 
Level 1 relationship will be unaﬀ ected by adjustment within groups (as takes place in grand-
mean centering). 
 In models where there is a randomly varying Level 1 slope, diﬀ erent centering strategies will 
also produce diﬀ erent results. In  Table 3.25 , Model 2 indicates that the choice of centering will 
make a diﬀ erence in estimating the Level 2 intercept variance, as well as the slope variance and 
covariance between the intercept and slope. As we noted previously, the variance of  Y at Level 2 
will typically be larger in group-mean models than in grand-mean or raw metric models since 
the group means in the group-centered solution are unadjusted. Th e slope variance will also be 
diﬀ erent (i.e., generally larger in group-mean solutions), although that is not the case in our 
example (except for the standardized solution). Th is is likely because our sample sizes are fairly 
large for any given Level 2 unit since we have 12,600 students nested in some 400 schools. In 
such cases, centering generally does not make much diﬀ erence (Raudenbush & Bryk, 2002). 
We again note in the last column of Model 2 that incorporating mean SES as a predictor in the 
Level 2 intercept model and also in the Level 2 random-slope model does not solve the problem 
of the diﬀ erent estimates of slope variability produced by the diﬀ erent centering approaches. 
Th is actually introduces two extra parameters to be estimated, which again results in a better-
ﬁ tting model. 
 In some situations, group-mean centering may be preferable to estimate slope heterogeneity 
properly (Raudenbush & Bryk, 2002). For example, when the Level 1 sample size is small or 
moderate, or if the group mean of  X varies across units, group-mean centering should be con-
sidered as a viable alternative if the focus of the analysis is to produce more robust estimates of 
unit-speciﬁ c regression equations (Raudenbush & Bryk, 2002). Because grand-mean-centered 
models produce an adjusted intercept for the Level 1 predictors, in some cases (e.g., schools 
that are very high or very low in mean SES), the adjusted means can be estimated with little 
accuracy. Th is happens because the adjusted mean for school  j represents the expected outcome 
for a child in the school who is at the grand mean of SES, and if there are few children like 
this in a particular school, the school mean will be less reliably measured than for some other 
schools where a larger number of students have family income levels that are at the grand mean 
for SES in the sample (Raudenbush & Bryk, 2002). Th is can result in making the slope vari-
ability more homogeneous than it actually is and, therefore, results in the underestimation of 
the slope variability at Level 2. As we noted, where sample sizes are large for any given Level 
2 unit, centering will not make much diﬀ erence, as well as when the slope does not vary across 
Level 2 units. 
 At the top of the data hierarchy (e.g., schools), the centering choices are not as critical as 
for predictors at lower levels (Raudenbush & Bryk, 2002). Usually it is convenient to center 
continuous variables around their grand means, as opposed to leaving them uncentered. We 
note that variables cannot be group centered at the highest level, since their “group” at that level 
is the Level 2 sample of schools. Centering strategies are the same for dichotomous variables. 

130  Deﬁ ning a Basic Two-Level Multilevel Regression Model
Dummy-coded variables (0, 1) are often left in their natural metric, depending on the analyst’s 
choice for the meaning of the reference group (coded 0) in the unit-level model. Th ey can also 
be grand-mean or group centered. Dichotomous variables can also be eﬀ ect coded (e.g., ‒1, +1), 
which results in a type of grand-mean centering. We discuss interpreting results with dichoto-
mous outcomes in the next chapter. 
 Summary 
 We have shown in this chapter how multilevel analyses allow the analyst to investigate a wider 
range of research questions than can be addressed in single-level analyses. In Chapter 4, we con-
tinue to illustrate the ﬂ exibility of multilevel techniques by extending the basic two-level model 
to a three-level model. We also address issues regarding building a variety of within-level and 
cross-level interactions.  

131
 CHAPTER 4 
 Three-Level Univariate Regression Models 
 T
he examples presented in the previous chapter demonstrated the basic multilevel regres-
sion model for examining hierarchical data structures. Th e basic two-level model can be 
readily extended to cross-sectional models involving several levels in a data hierarchy, regres-
sion discontinuity designs, and multilevel longitudinal models involving individuals and groups. 
In this chapter, we provide an overview of three-level, cross-sectional modeling. We also intro-
duce a strategy for centering predictors in multilevel models to facilitate the interpretation of 
eﬀ ects and a strategy for comparing the ﬁ t of successive proposed models to the data. 
 Three-Level Univariate Model 
 As a ﬁ rst example, consider a three-level model with a univariate outcome,  math achievement . 
In this example, we primarily wish to examine whether classroom teaching eﬀ ectiveness (i.e., a 
characteristic of teachers at Level 2) and aggregate teaching eﬀ ectiveness (i.e., as a characteristic 
of schools at Level 3) aﬀ ect student outcomes. At the classroom level, we also focus on whether 
teacher eﬀ ectiveness may be related to student composition. Finally, at the school level, we wish 
to examine whether the size of individual teacher eﬀ ects varies across schools. 
 Research Questions 
 We investigate three research questions in this example. Th e ﬁ rst question concerns whether a 
key organizational process, in this case the eﬀ ectiveness of students’ teachers, has an individual 
and an organizational eﬀ ect on their academic outcomes, after relevant background and orga-
nizational context indicators have been controlled. Th is involves examining whether eﬀ ects at 
lower levels (i.e., the classroom) of the data hierarchy tend to compound at a higher level (i.e., 
the school). As we mentioned in the previous chapter, this type of relationship is often referred to 
as a compositional eﬀ ect. More speciﬁ cally, we might ask: At the classroom level, does having a 
more eﬀ ective teacher confer an academic advantage to those students compared with their peers 
having a teacher of average eﬀ ectiveness? Moreover, does being in a school with more eﬀ ective 
teachers on average confer any additional advantage compared with students in schools with less 
eﬀ ective teachers? 
 Th e second research question concerns whether the teacher eﬀ ectiveness slope varies across 
schools. We can address this question by examining the variance components for the slope at 
Level 3 of the model. If the slope does vary across schools, we can focus on building a model 
that explains variability in the random slope at the school level. Th is type of model concerns the 
presence of a cross-level interaction—that is, the potential eﬀ ect a variable at a higher level of the 
data hierarchy may have on a relationship at a lower level. 
 Th e third question focuses on whether teacher eﬀ ectiveness at the classroom level is contin-
gent on student composition. Addressing this question allows us to demonstrate how to inves-
tigate an interaction between two variables at the same level of the data hierarchy. Th is is also 

132  Three-Level Univariate Regression Models
TABLE 4.1 Data Deﬁ nition of ch4threelevelURM.sav (N = 9,196)
Variable
Levela
Description
Values
Measurement
schcode
School
School identiﬁ er (160 public 
schools).
Integer
Ordinal
teachid
Class
Teacher identiﬁ er (516 
teachers in their classrooms). 
(1, 2, 3, . . . 516)
Ordinal
Rteachid
Class
Recoded teachid identifying 
individual teachers within 
schools (schcode).
(1, 2, 3, . . . 29)
Ordinal
math
Individual
Dependent variable 
measuring student math 
achievement score.
 481 to 775
Scale
lowses
Individual
Dichotomous variable 
representing student 
socioeconomic status.
0 = Not Low 
Socioeconomic Status
1 = Low Socioeconomic 
Status
Scale
teacheffect
Class
A standardized measure of 
each teacher’s classroom 
teaching effectiveness.
–2.64 to 3.05
Scale
classlowses_mean
Class
Predictor variable measuring 
student socioeconomic 
composition within school 
classrooms.
.00 to 1.00
Scale
schlowses_mean
School
Predictor variable measuring 
student economic status.
0.00 to 1.00
Scale
gmlowses
Individual
Predictor variable (grand-
mean centered) measuring 
socioeconomic status.
–0.41 = Not Low 
Socioeconomic Status
0.59 = Low Socioeconomic 
Status
Scale
gmclasslowses_
mean
Class
Predictor variable (grand-
mean centered) measuring 
student socioeconomic status 
within classrooms.
–0.41 to 0.59
Scale
a common type of speciﬁ cation in a multilevel model. Interactions can be interpreted as the 
amount of change in the slope of  Y (achievement) with respect to  X (teacher eﬀ ectiveness) when 
 Z (student classroom socioeconomic status [SES] composition) changes by 1 unit. More speciﬁ -
cally, we ask: Does the dependence of a student’s achievement score on the eﬀ ectiveness of her 
teacher also depend on diﬀ ering levels of socioeconomic status in the classroom? Keep in mind 
that interactions are not simply “additive,” as are the main eﬀ ects of variables in a model (i.e., the 
additional eﬀ ect of teacher eﬀ ectiveness in explaining achievement while holding SES composi-
tion constant), but, rather, they depend on the speciﬁ c levels of the two variables from which they 
are produced (eﬀ ectiveness and classroom SES). We can then test whether the interaction term 
added to the model produces a better ﬁ t than the main-eﬀ ects-only model. 
 The Data 
 For this example, we will use a random sample of 9,196 students nested in 516 classrooms in 
160 schools. 
 Table 4.1  provides a summary of the variables used in the example. Th e outcome is student 
scaled scores on a standardized math test. Th e sample data are found in the ﬁ le  ch4threeleve-
lURM.sav . Th e data have an identiﬁ cation code for the school ( schcode ) and teacher ( teachid  ), 
(Continued )

Three-Level Univariate Regression Models  133
as well as a recoded teacher identity ( Rteachid  ). Th e recoded Level 2 identiﬁ cation code (i.e., 
individual teachers within schools) substantially reduces the amount of time it takes to run the 
model. Next is a math score, a measure of individual student socioeconomic status (coded 1 = 
low SES, 0 = else), a standardized (mean [ M ] = 0, standard deviation [ SD ] = 1) assessment of 
each teacher’s classroom teaching eﬀ ectiveness ( teacheﬀ ect ), a classroom SES composition vari-
able ( classlowses_mean ), and an aggregate (school-level) measure of student SES composition 
( schlowses_mean ). Th ese latter two variables were created from the individual-level SES variable 
( lowses ) by using the “aggregate” command within IBM SPSS (DATA, AGGREGATE) and 
teachid and  schcode as the “break” variables, respectively. 
 Deﬁ ning the Three-Level Multilevel Model 
 Our notation follows that used by Raudenbush and Bryk (2002). For three-level models, ﬁ xed-
eﬀ ect coeﬃ  cients at Level 1 are deﬁ ned as  π , so that Level 2 coeﬃ  cients can be deﬁ ned as   and 
Level 3 as   . For individual  i in class  j in school  k , the general Level 1 model can be deﬁ ned as 
,
1
P
ijk
jk
Pjk
Pijk
ijk
0
p
Y
a
ijk
	
Pjk
Pijk
Pjk
Pijk
Pjk
jk
0 jk
0


Pijk
a
Pjk
0 jk
0
 
(4.1)
 where  π 0 jk  is an intercept;  a pjk  represents Level l predictors ( p = 1, . . .,  P ), such as socioeconomic 
status, for individual  i in Level 2 unit  j and Level 3 unit  k ;  π pjk  represents corresponding Level 1 
coeﬃ  cients; and   ijk  is the Level 1 residual. Th e Level 1 residual   ijk  is assumed to be normally 
distributed with the mean equal to 0 and variance   2 . 
 At Level 2, the general classroom model can be speciﬁ ed as 
1
p
Q
pjk
p k
pqk
qjk
pjk
0
q
X
r
jk
p
jk


pjk
p k
0


p kX jk

 0
p k
0

 
(4.2) 
Variable
Levela
Description
Values
Measurement
gmteacheffect
Class
Predictor variable (grand-
mean centered) measuring 
teacher effectiveness by their 
students’ math scores. 
–2.62 to 3.06
Scale
gmschlowSES_
mean
School
Predictor variable (grand-
mean centered) measuring 
school socioeconomic status. 
–0.41 to 0.59 
Scale
gmaggtcheffect
School
Predictor variable (grand-
mean centered) measuring 
teacher effectiveness.
–0.97 to 1.57
Scale
grouplowses
Individual
Predictor variable (group-
mean centered) measuring 
socioeconomic status.
–0.95 to 0.96
Scale
groupclasslowses_
mean
Class
Predictor variable (group-
mean centered) measuring 
student socioeconomic status 
within classrooms.
–0.72 to 0.80
Scale
groupteacheffect
Class
Predictor variable (group-
mean centered) measuring 
teacher effectiveness by their 
students’ math scores.
–.3.49 to 3.41
Scale
a Individual = Level 1; Class = Level 2; School = Level 3.
Table 4.1 (Continued )

134  Three-Level Univariate Regression Models
 where   p  0 k  is the intercept for school  k in modeling the teacher eﬀ ect;  X qjk  represents Level 2 
predictors ( q = 1, . . .,  Q p  ), such as teaching eﬀ ectiveness;   pqk  represents corresponding Level 2 
coeﬃ  cients; and  r pjk  represents Level 2 random eﬀ ects. Level 1 coeﬃ  cients can be modeled at 
Level 2 as ﬁ xed at the same value for all Level 2 units (i.e.,  π pjk  =   p  0 k  ), which indicates that no 
predictors or random  r pjk  component in Equation 4.2 is included in the model; as nonrandomly 
varying among Level 2 units (i.e., Eq. 4.2 without the random  r pjk  component); or as randomly 
varying (Eq. 4.2 with the random component  r pjk  included). Th e Level 2 random eﬀ ects are 
collected in a covariance matrix whose dimensions depend on the number of random eﬀ ects 
speciﬁ ed in the Level 2 model (see Raudenbush, Bryk, Cheong, & Congdon, 2004, for further 
discussion). 
 Between schools (Level 3), a general model can be deﬁ ned as 
 
 
1
,
pq
S
pqk
pq
pqs
sk
pqk
0
s
W
u
k


pqk
pq0

p W k


0
p 0 
 
(4.3) 
 where   pq  0 is an intercept;  W sk  represents Level 3 predictors ( s = 1, . . .,  S pq  ), such as student 
composition;   pqs  represents corresponding Level 3 coeﬃ  cients; and  u pqk  represents Level 3 
random eﬀ ects. Th e dimensions of the Level 3 covariance matrix of random eﬀ ects depend on 
the number of randomly varying eﬀ ects in the model. As Raudenbush et al. (2004) suggest, 
Level 2 coeﬃ  cients can be modeled at Level 3 as ﬁ xed (  pqk  =   pq  0 ), as nonrandomly varying 
(i.e., Eq. 4.3 without the random component  u pqk  ), or as randomly varying (as speciﬁ ed in 
Eq. 4.3). 
 The Null Model (No Predictors) 
 For this ﬁ rst no-predictors, or null, model, we can examine the decomposition of variance in 
math achievement associated with students, classrooms, and schools. For a three-level model, the 
proportion of variability (intraclass correlation) in outcomes at Level 3 can be deﬁ ned as 
 
2
2
2
2
3
 1
 2
 3)
2
2
2
3
Level 3
 1
 2
 1
 2

 Level 3
1
2
1
2
1
2
2
2
22
 2
3 /(
2
2
2
2
1
2
1
2
L
l 3
1
2
1
2
 
(4.4) 
 For Level 2, the intraclass correlation (ICC) would be 
 
2
2
2
2
2
 1
 2
 3)
2
2
2
3
Level 2
 1
 2
 1
 2

 Level 2
1
2
1
2
1
2
2
2
22
 2
2 /(
2
2
2
2
1
2
1
2
L
l 2
1
2
1
2
 
(4.5) 
 and for Level 1, the ICC would be 
 
2
2
2
2
1
 1
 2
 3)
2
2
2
3
Level 1
 1
 2
 1
 2

 Level 1
1
2
1
2
1
2
2
2
22
 2
1/(
2
2
2
2
1
2
1
2
L
l 1
1
2
1
2
 
(4.6) 

Three-Level Univariate Regression Models  135
 Deﬁ ning Model 1 (Null) with IBM SPSS Menu Commands 
 Th e appropriate baseline model from which to compare subsequent models is the intercept-only, 
or no-predictors, model. 
 Launch the IBM SPSS program appli-
cation, and select the  ch4threelevelURM.
sav data ﬁ le. 
  1.  Go to the toolbar and select 
ANALYZE, MIXED MODELS, 
LINEAR. 
 Th is command enables access to the 
 Linear Mixed Models: Specify Subjects 
and Repeated dialog box. 
  2.  Th e  Linear Mixed Models: Specify Subjects and 
Repeated screen displays options for deﬁ ning 
variables as subjects, repeated observations, 
and type of covariance structure in a model. 
 A subject is an observational unit that may be in-
dependent of other subjects. For this model, we will 
designate two subject identiﬁ ers ( schcode, Rteachid  ) 
for the model. 
 Click to select  schcode and  Rteachid from the  Vari-
ables  column, and then click the right-arrow button 
to move the variables into the  Subjects box. 
 Click the CONTINUE button to display the  Lin-
ear Mixed Models dialog box. 

136  Three-Level Univariate Regression Models
 4.  Th e  Linear Mixed 
Models: Random Eﬀ ects 
displays the  Random 
Eﬀ ect 1 of 1 screen. Th is 
is the default screen 
when creating a model 
for the ﬁ rst time. Th e 
random-eﬀ ects screen 
allows specifying ran-
dom eﬀ ects, interactions, 
intercept terms, and 
subject groupings. 
 a.  Begin by specifying 
the covariance struc-
ture from the default 
variance components 
(VC) to scaled iden-
tity. Click the pull-
down menu and select 
 Scaled Identity.  
 Th e  Scaled Identity  covariance structure has constant variance and assumes no correlation between any 
elements (IBM Corporation, 2012). 
 b.  We want the intercept to be included in the model, so click the  Include intercept option. 
 c.  Th e  Subject Groupings  box displays the  schcode variable that was speciﬁ ed as a subject variable in 
the  Specify Subjects and Repeated dialog box show in step 2. We will specify  schcode as the subject 
for the random-eﬀ ects Level 1 part of this model. Click to select  schcode , and then click the 
right-arrow button to move the variable into the  Combinations box. 
 d.  After adding  schcode as a subject in the prior step, the NEXT button is activated at the top-
right section of the window. Click the NEXT button to access the  Random Eﬀ ect 2 of 2 screen. 
 3.  Th e  Linear Mixed Models main 
screen enables specifying the depen-
dent variable, factors, covariates, and 
access to dialog boxes for deﬁ ning 
 Fixed and  Random eﬀ ects, and op-
tions for  Estimation ,  Statistics ,  EM 
Means , and  Save. 
 For this model, we will use  math as the 
dependent variable. Click to select  math  
from the left column listing. Th en click 
the right-arrow button to transfer  math 
into the  Dependent Variable box. 
 Since this ﬁ rst model (null) excludes predictor variables, we will skip over the FIXED button, which 
enables adding ﬁ xed eﬀ ects to a model. 
 We will add random eﬀ ects to this model. Click the RANDOM button to access the  Linear Mixed 
Models: Random Eﬀ ects dialog box. 

Three-Level Univariate Regression Models  137
 Note: Th e NEXT button may not work in earlier or unpatched versions of IBM SPSS when creating 
multilevel models with random intercepts. An update issued by IBM SPSS for software Version 19 ad-
dressed the problem, and Version 20 appears to have resolved the issue. A workaround to activating the 
NEXT button is to either (a) add or reenter a subject variable into the  Combinations  box or (b) add a 
variable from the  Factors and Covariates column to the  Model  box and then remove it before proceeding 
to the  Random Eﬀ ect 2 of 2 screen. 
 Th e  Random Eﬀ ect 2 of 2 screen 
display is similar to the ﬁ rst 
screen and requires the following 
changes. 
 e.  Change the covariance 
type by clicking on the 
pull-down menu and 
selecting  Scaled Identity. 
 f.  We want the intercept to 
be included, so click the 
 Include intercept option. 
 g.  We will specify  schcode 
and  Rteachid as the sub-
jects for the random-
eﬀ ects Level 2 part of 
this model. Click to select 
 schcode and  Rteachid , and 
then click the right-arrow 
button to move the vari-
ables into the  Combinations box. 
 Click the CONTINUE button to return to the  Linear Mixed Models dialog box. 
 5.  In the  Linear Mixed Models dialog box, 
click the ESTIMATION button to ac-
cess the  Linear Mixed Models: Estimation 
dialog box, which displays two estimation 
method choices: maximum likelihood 
(ML) or restricted maximum likelihood 
(REML). In this chapter, we will use 
maximum likelihood to estimate the 
models, which facilitates making com-
parisons between successive models using 
model ﬁ t criteria (Hox, 2002). 
 Click to select ML, and then click the CON-
TINUE button to return to the  Linear Mixed 
Models dialog box. 

138  Three-Level Univariate Regression Models
 6.  In the  Linear Mixed Models dialog 
box, click the STATISTICS but-
ton to access the  Linear Mixed 
Models: Statistics dialog box. 
 Click and select the following three 
statistics to be included in the output: 
 Parameter estimates ,  Tests for covariance 
parameters , and  Covariances of random 
eﬀ ects . 
 Click the CONTINUE button to re-
turn to the  Linear Mixed Models dialog 
box. 
 7.  Finally, in the  Linear Mixed Models 
dialog box, click the OK button to 
run the model. 
 Interpreting the Output From Model 1 (Null) 
 Table 4.2  presents the variance decomposition for the null (no-predictors) model. Th e variance 
component associated with schools is 189.89; with classrooms, it is 131.42; and with individuals, 
it is 1,333.79. From Equation 4.4, we can calculate the proportion of variance between schools 
as 0.115 [189.8867/(1,333.7850 + 131.4211 + 189.8867)] or 11.5%. Following Equation 4.5, the 
variance is 0.079 (7.9%) between classrooms, and from Equation 4.6, the student-level variance 
is 0.806 (80.6%). Th is suggests there is adequate variability at each level to conduct a multilevel 
analysis. 
 We reiterate here that in multilevel modeling, explaining variance is more complex than in 
single-level regression models (Hox, 2010). First, there is the issue of dealing with unexplained 
variance at several levels. Second, if there are random slopes, the model becomes more complex, 
and explained variance (at each level) has no unique deﬁ nition. As we noted in Chapter 3, one 
approach often used is to examine the change in residual variance that occurs by adding predic-
tors within a sequence of models. Th e analyst begins with the intercept-only model as we have 
just presented. Th is serves as a baseline against which to evaluate subsequent reduction in the 
variance at each level as other variables are subsequently added to the model. Th e analyst should 
keep in mind, however, that when variables are added at Level 1, they can explain (i.e., reduce) 

Three-Level Univariate Regression Models  139
TABLE 4.2 Estimates of Covariance Parametersa
Parameter
Estimate
Std. Error
Wald Z
Sig.
95% Conﬁ dence Interval
Lower Bound
Upper Bound
Residual
1,333.785
20.836
64.012
.000
1,293.565
1,375.255
Intercept [subject = schcode]
Variance
189.887
27.933
6.798
.000
142.324
253.344
Intercept [subject = 
schcode * Rteachid]
Variance
131.422
15.963
8.233
.000
103.581
166.746
a Dependent variable: math.
variance at both Level 1 and at Level 2 (and perhaps even at Level 3). In contrast, variables added 
at higher levels of the model do not aﬀ ect the variance present at lower levels. In other situa-
tions, a variable added at a lower level may appear to explain negative variance. Th is may happen 
because the program may not make a very good “initial” estimate of the variance at each level, 
depending on the nature of the data (e.g., normality, sample size at each level, unequal sampling 
distribution of Level 1 variables across groups, etc.). We therefore remind analysts to be cautious 
about placing too much emphasis on variance reduction approaches in accounting for outcome 
variance. Adding random slopes can also complicate accounting for variance at each level (Hox, 
2010). For these reasons, it can be more challenging to assess the outcome variance explained in 
multilevel models. 
 Model 2: Deﬁ ning Predictors at Each Level 
 We will next illustrate the three-level model by building a simpliﬁ ed model with one or two pre-
dictors at each level. Th is results in combining a couple of general steps in the overall modeling 
strategy that we laid out previously (i.e., no-predictors model, within-group model, group-level 
model, random slope, and cross-level interactions). We illustrate two primary centering strategies 
discussed in Chapter 3 in this example. 
 As we discussed earlier, grand-mean centering (where the grand mean is subtracted from indi-
viduals’ values on the variable) results in redeﬁ ning the sample mean of the predictor to zero (0.0).
Grand-mean centering the continuous predictors produces an equivalent model to leaving the 
predictors in their natural metrics, but it has the advantage of being able to interpret the result-
ing intercept in the model as the expected value of  Y when they are at their mean values. Th is has 
the eﬀ ect of adjusting the unit intercepts for diﬀ erences in Level 1 predictors within the units. In 
contrast, group-mean centering (where each group’s mean is subtracted from individuals’ values 
on the variable) results in unit intercepts that are unadjusted for diﬀ erences within the units. 
More speciﬁ cally, it produces an intercept equal to the expected value of  Y for an individual when 
 X is equal to the group’s mean. 
 We reiterate that group-mean-centered solutions are not the same as grand-mean, standard-
ized, or raw metric solutions. In IBM SPSS, grand-mean-centered or group-mean-centered 
variables must be created using COMPUTE and saved in the data set. In our examples, we 
designate variables that we have grand-mean centered by placing “gm” in front of the variable 
(e.g.,  SES becomes  gmSES  ). We designate group-mean-centered variables as “group” (e.g.,  SES 
becomes  groupSES ). Analysts, of course, can devise their own naming schemes. 
 Categorical variables, such as dichotomous indicators, also present diﬀ erent options for cen-
tering using low SES as an example. We present some of these options in  Table 4.3 . We have 
two options if we leave a dummy-coded (coded 0, 1) predictor in its natural metric. If  lowSES is 
entered as a covariate in MIXED, as is typical in multiple regression analyses, the reference group 
for the intercept (604.315) will be the group coded 0 (did not participate). For a dummy-coded 

140  Three-Level Univariate Regression Models
variable entered into MIXED as a factor, it is important to note in  Table 4.3  that the default 
reference group is the last category (i.e., participated in free/reduced lunch program) instead of 
the ﬁ rst category. In this case, the intercept for achievement (587.538) will correspond to the 
expected scores for students who participated in the free/reduced lunch program (coded 1) in 
school  k , and the variance associated with the intercept will be interpreted as the variance in 
outcomes for that group of students across schools (Raudenbush & Bryk, 2002). 
 If we grand-mean center a dummy-coded variable (i.e., in this case, coded ‒0.41, 0.59) and 
enter it as a covariate in the model, it results in an intercept that may be deﬁ ned as the mean out-
come in school  k , adjusted for diﬀ erences among schools in the proportion of students partici-
pating in the federal free/reduced lunch program. Th is is an important distinction, for example, 
if we are concerned with making comparisons between schools after adjusting the outcomes for 
diﬀ erences due to the various backgrounds of students within each school. We can observe in 
 Table 4.3  that centering a dummy-coded variable on the grand mean or leaving it uncentered 
will result in similar slope coeﬃ  cients but diﬀ erent estimated intercepts. Leaving the SES vari-
able in its raw metric would result in the intercept representing students in the reference group, 
after adjusting for the other predictors. We can see that for a dummy-coded variable entered in 
the model as a factor, the alternative coding schemes (e.g., uncentered and grand-mean centered) 
will not make a diﬀ erence in the intercept. 
 We also point out that some ﬁ elds prefer eﬀ ect coding for dichotomous variables. As shown 
in  Table 4.3 , when a variable is eﬀ ect coded (–1, +1) and entered as a covariate, the estimate can 
be interpreted as the change above or below the grand mean for the predictor. Note that the 
coeﬃ  cient in the eﬀ ect-coded solution is half the size of the other estimates (8.389 vs. 16.778), 
and if we subtract that eﬀ ect-coded estimate from the intercept of the natural metric solution 
(604.315–8.389), we obtain the grand mean of 595.926 in the eﬀ ect-coded model in  Table 4.3  
(with slight diﬀ erence due to rounding). 
TABLE 4.3 Estimates of Fixed Effectsa
Parameter
Estimate
Std. 
Error
df
t
Sig.
Raw Metric
Intercept
604.315
1.192
183.847
506.943
0.000
lowses
–16.778
0.849
9,165.850
–19.752
0.000
Grand-Mean 
Intercept
597.437
1.138
154.141
524.936
0.000
Centered
gmlowses
–16.778
0.849
9,165.850
–19.752
0.000
Raw Metric 
Intercept
587.538
1.241
217.152
473.441
0.000
(Factor)
[lowses = 0]
16.778
0.849
9,165.850
19.752
0.000
[lowses = 1]
0b
0
.
.
.
Grand-Mean 
Intercept
587.538
1.241
217.152
473.441
0.000
Centered (Factor) 
[gmlowses = –0.41]
16.778
0.849
9,165.850
19.752
0.000
[gmlowses = 0.59]
0b
0
.
.
.
Effect Coded
Intercept
595.927
1.140
155.420
522.628
0.000
lowseseffect
–8.389
0.425
9,165.850
–19.752
0.000
Group-Mean
Intercept
597.278
1.298
156.533
460.172
0.000
Centered
grouplowses
–14.449
0.887
9,068.494
–16.286
0.000
a Dependent variable: math.
b This parameter is set to 0 because it is redundant.

Three-Level Univariate Regression Models  141
 Finally, as we have noted previously, centering the variable on the group mean produces a 
diﬀ erent intercept (597.278) and slope coeﬃ  cient (–14.449) from the other centering solutions 
presented in  Table 4.3 . Th e analyst, therefore, should keep in mind the desired interpretation 
of the intercept, especially when there are several continuous and dichotomous variables in the 
analysis. For other categorical variables entered into the model as factors, the default reference 
group is also the last category. 
 In our ﬁ rst model, we grand-mean centered the low SES predictor (though we could have just 
as easily chosen to leave it in its raw metric). At Level 1, we will propose that for individual  i in 
class  j in school  k, student SES background ( gmlowses ) aﬀ ects math achievement: 
 
Y ijk  =  π 0 jk  +  π 1 jk  gmlowses ijk  +   ijk  . 
(4.7) 
 At Level 2 (classrooms), we will add a measure of teacher eﬀ ectiveness (with higher standardized 
scores indicating greater eﬀ ectiveness) in producing student learning in the classroom and an 
aggregate measure of classroom SES composition: 
 π 0 jk  =   00 k  +   01 k    gmteacheﬀ ect jk  +   02 k  gmclasslowses_mean jk  +  r 0 jk  , 
 π 1 jk  =   10 k  . 
 
(4.8) 
 We also grand-mean centered these predictors. For this model, we will assume that student SES 
( gmses ) is ﬁ xed at the same value for all Level 2 units. Th erefore, we do not include any predictors 
or a random variance component ( r 1 jk  ) in Equation 4.8. 
 At Level 3 (schools), we will add aggregated measures of school SES and teacher eﬀ ectiveness 
(which we also grand-mean centered) to explain variation in between-school math achievement: 
  00 k  =   100 +   001  gmschlowSES_mean k  +   002 gmaggtcheﬀ ect k  +  u 00 k  , 
  10 k  =   100 , 
  01 k  =   010 , 
  02 k  =   020 . 
(4.9) 
 Equation 4.9 suggests that we will also assume that all Level 2 slopes are ﬁ xed, but the ad-
justed math intercepts vary across schools. Th e combined equation will then be the following: 
  00 k  =   000 +   100 gmlowses ijk  +   010  gmteacheﬀ ect jk  +   020 gmclasslowses_mean jk  +  
 001  gmschlowSES_mean k  +   002 gmaggtcheﬀ ect k  +  u 00 k  +  r 0 jk  +   ijk  . 
(4.10) 
 Th is suggests nine parameters to estimate (six ﬁ xed eﬀ ects, two random eﬀ ects—the intercept 
at Levels 2 and 3, and the Level 1 residual). We note that the Level 3 (school) intercepts in this 
model have been adjusted for individual SES at Level 1 and for student SES composition and 
teacher eﬀ ectiveness at Level 2. 

142  Three-Level Univariate Regression Models
 Deﬁ ning Model 2 with IBM SPSS Menu Commands 
 Note: IBM SPSS settings will default 
to those used in Model 1. 
 1.  Go to the toolbar and select 
ANALYZE, MIXED MODELS, 
LINEAR. 
 Th is command enables access to the 
 Linear Mixed Models: Specify Subjects 
and Repeated dialog box. 
 2.  Th e  Linear Mixed Models: Specify Subjects and 
Repeated screen displays the default settings 
from the prior model. 
 Click the CONTINUE button to display the 
 Linear Mixed Models dialog box. 

Three-Level Univariate Regression Models  143
 3.  Th e  Linear Mixed Models dialog box 
settings default to those used in the 
prior model. 
 a.  We will introduce ﬁ ve additional 
variables to be used in the model 
(    gmlowses, gmclasslowses_mean, 
gmteacheﬀ ect, gmschlowSES_mean, 
gmaggtcheﬀ ect ). First, click to 
select all ﬁ ve variables, and then 
“drag” them to the  Covariate(s) 
box. 
 b.  To facilitate reading of the 
output tables, we will change 
the sequence of the variables by 
dragging variables to rearrange 
them. First, click to select  gm-
schlowSES_mean and  gmaggtchef-
fect , and then drag them to the 
top of the  Covariate(s) box. Now 
the variables are listed in ﬁ rst and 
second place. Continue rearrang-
ing the variables to achieve the 
ﬁ nal sequence order (see insert): 
 gmschlowSES_mean ,  gmaggtcheﬀ ect ,  gmteacheﬀ ect ,  gmclasslowses_mean , and  gmlowses. 
 Note: An alternate method for arranging the variables in the desired sequence order is to select variables 
individually and then use the right-arrow button to move each variable into the  Covariate(s) box. 
 We may now proceed to deﬁ ne ﬁ xed eﬀ ects for the variables. 
 Click the FIXED button to access the  Linear Mixed Models: Fixed Eﬀ ects dialog box. 
 4a.  Within the  Linear Mixed 
Models: Fixed Eﬀ ects dia-
log box, click the pull-
down menu to change 
the factorial setting to 
 Main Eﬀ ects . 
 b.  Click to select the ﬁ ve 
variables from the  Fac-
tors and Covariates box, 
and then click the ADD 
button to move the vari-
able into the  Model box. 
 c.  Note on lower left of the 
screen that the intercept 
and the sum of squares 
( Type III ) are the default 
settings. 
 Click the CONTINUE button to return to the  Linear Mixed Models dialog box. 

144  Three-Level Univariate Regression Models
 5.  Finally, in the  Linear Mixed Models 
dialog box, click the OK button to 
run the model. 
 Interpreting the Output From Model 2 
 Th e ﬁ xed-eﬀ ects output for Model 2 is presented in  Table 4.4 . Th e table suggests a composition 
eﬀ ect associated with student SES; that is, there is an eﬀ ect at the individual level (  100 = ‒14.534, 
 p < .001), which compounds signiﬁ cantly at the classroom level (  020 = ‒11.073,  p < .001) and the 
school level (  011 = ‒31.138,  p < .001). 
 As we noted previously, compositional eﬀ ects refer to the extent to which the size of the 
organizational-level eﬀ ect diﬀ ers from the size of the individual-level eﬀ ect. With grand-mean 
centering, the compositional eﬀ ect for schools is estimated directly as the between-group ﬁ xed 
eﬀ ect for SES (  001 = ‒31.138). At the school level, the eﬀ ect for SES can be interpreted as the 
expected diﬀ erence in math outcomes between two students who have the same individual SES 
background (and are in classes with the same SES composition) but attend schools diﬀ ering by 
1 unit (i.e., in this case, 1  SD in mean SES). Similarly, the composition eﬀ ect at the classroom 
level (  020 = ‒11.073) is the diﬀ erence in size between the individual SES and class-level SES ef-
fects. At the classroom level, the compositional eﬀ ect for SES can be interpreted as the expected 
diﬀ erence in math outcomes between two students who have the same individual SES but who 
are in classes diﬀ ering by 1 unit (1  SD ) in mean classroom SES. 
 Th e output also provides support for our initial contention that there is an academic ad-
vantage for students that compounds due to teacher eﬀ ectiveness. First, the table suggests that 
the classroom-level eﬀ ect is signiﬁ cant (  010 = 7.571,  p < .001). Th is suggests that students in a 
classroom with a teacher whose eﬀ ectiveness is 1  SD above the grand mean would score about 
7.6 points higher than their peers in classrooms with teachers at the grand mean of eﬀ ectiveness. 
TABLE 4.4 Estimates of Fixed Effectsa
Parameter
Estimate
Std. Error
df
t
Sig.
95% Conﬁ dence Interval
Lower Bound
Upper Bound
Intercept
596.742
0.741
148.020
804.861
.000
595.277
598.208
gmschlowSES_mean
–31.138
4.565
436.869
–6.821
.000
–40.110
–22.166
gmaggtcheffect
7.448
1.963
208.719
3.794
.000
3.578
11.319
gmteacheffect
7.571
0.619
656.308
12.223
.000
6.355
8.787
gmclasslowses_mean
–11.073
3.472
1,759.121
–3.189
.001
–17.882
–4.264
gmlowses
–14.534
0.862
8,841.429
–16.868
.000
–16.222
–12.845

Three-Level Univariate Regression Models  145
Moreover, the eﬀ ect of teachers on outcomes compounds at the school level (  002 = 7.448,  p < .001). 
Th e interpretation of this school-level coeﬃ  cient is straightforward: For two students having 
teachers of average eﬀ ectiveness, attending a school diﬀ ering by 1  SD in collective teacher ef-
fectiveness is associated with a 7.45-point increase on the standardized math test. Th is output, 
therefore, provides evidence to answer our ﬁ rst research question regarding potential academic 
advantages associated with teacher eﬀ ectiveness. 
 Model 3: Group-Mean Centering 
 We contrast these results in Model 1 with a second model where we group-mean centered the 
within-school variables. It is important to keep in mind that cross-level interactions can some-
times be a source of instability in a model’s estimates. If this may be a potential problem, group-
mean centering is a good centering choice since this approach removes correlations between 
variables across levels (Kreft & de Leeuw, 1998). Group-mean centering results in an intercept 
for each unit that is unadjusted for Level 1 or Level 2 predictors. In group-mean-centered solu-
tions, the eﬀ ects of between-group predictors will also be unadjusted for within-group predictors. 
 Because grand-mean centering produces group means that are adjusted for the predictors in 
the model, in some modeling situations the adjustments for some units may not be very reliable. 
Th is can occur where there are small within-group sample sizes and considerable variability in 
slopes for particular covariates. For units with small sample sizes, the random slope may be es-
timated with little precision, which weakens the likelihood of detecting relationships between 
groups (Raudenbush & Bryk, 2002). In this situation, it can be diﬃ  cult to disentangle parameter 
variance and error variance. In cases where the slope varies considerably across units for a predic-
tor, and there is also variability across units in the levels of the predictors, resulting grand-mean-
centered estimates may be less credible than group-mean-centered estimates (Raudenbush & 
Bryk, 2002). It is also important to note that compositional eﬀ ects may change the size and 
signiﬁ cance of other parameters in the model. It is, therefore, important to give attention to 
decisions about model speciﬁ cation, especially when the focus is on the cross-level interactions. 
 Deﬁ ning Model 3 with IBM SPSS Menu Commands 
 Note: IBM SPSS settings 
will default to those used in 
Model 2. 
  1.  Go to the toolbar and select 
ANALYZE, MIXED MOD-
ELS, LINEAR. 
 Th is command enables access to the 
 Linear Mixed Models: Specify Subjects 
and Repeated dialog box. 

146  Three-Level Univariate Regression Models
 2.  Th e  Linear Mixed Models: Specify Subjects and 
Repeated screen displays the default settings 
from the prior model. 
 Click the CONTINUE button to display the  Linear 
Mixed Models dialog box. 
 3.  Th e  Linear Mixed Models dialog box set-
tings default to those used in the prior 
model. 
 a.  We will change the model by exchang-
ing the three grand-mean-centered 
variables for group-mean-centered vari-
ables. Remove the grand-mean-centered 
variables by clicking to select  gmteachef-
fect ,  gmclasslowses_mean , and  gmlowses  
and then clicking left-arrow button (or 
“drag” the variables to the left). 
 b.  Now click to select three group-mean 
variables ( grouplowses ,  groupclasslowses_
mean , and g roupteacheﬀ ect ) and drag 
them to the  Covariate(s) box. 
 c.  To facilitate reading of the output 
tables, we will change the sequence of 
the variables by dragging variables to 
rearrange them. First, click to select 
 groupteacheﬀ ect , and then drag the vari-
able below g maggtcheﬀ ect.  Continue 
rearranging the variables to achieve 
the ﬁ nal sequence order (see insert): 
 gmschlowSES_mean ,  gmaggtcheﬀ ect , 
 groupteacheﬀ ect, groupclasslowses_mean , 
and  grouplowses . 
 Note: An alternate method for arranging the 
variables in the desired sequence order is to 
select variables individually and then use the 
right-arrow button to move each variable into 
the  Covariate(s) box. 

Three-Level Univariate Regression Models  147
 We may now proceed to deﬁ ne ﬁ xed eﬀ ects for the variables. 
 Click the FIXED button to access the  Linear Mixed Models: Fixed Eﬀ ects dialog box. 
 4a.  Th e  Linear Mixed Models: 
Fixed Eﬀ ects default setting 
from the prior model is 
 Main Eﬀ ects . 
 b.  Click to select the three 
group-mean-centered 
variables ( groupteachef-
fect ,  groupclasslowses_mean , 
and  grouplowses ) from the 
 Factors and Covariates box, 
and then click the ADD 
button to move the vari-
ables into the  Model box. 
 Click the CONTINUE button to 
return to the  Linear Mixed Models 
dialog box. 
 5.  Finally, in the  Linear Mixed Models 
dialog box, click the OK button to 
run the model. 
 Interpreting the Output From Model 3 
 Given the previous grand-mean-centered estimates in Model 1, if we instead used group-mean 
centering, we should expect a classroom-level SES group-centered eﬀ ect of approximately ‒25.6 
[i.e., ‒14.5 + (–11.1) in  Table 4.3 ] and a school-level eﬀ ect of approximately ‒56.7 [i.e., ‒25.6 + 
(–31.1) in  Table 4.3 ]. For teacher eﬀ ectiveness, we would expect an aggregated Level 3 teacher 
eﬀ ectiveness coeﬃ  cient of about 15.02 (i.e., 7.57 + 7.45 in the previous table). 
 Th e group-mean-centered estimates are presented in  Table 4.5  and are consistent with our ex-
pected output translated from the grand-mean estimates. Note that the Level 3 estimates are still 
grand-mean centered. Th is is because the estimates of the highest level in the data set cannot be 
centered on a group—that is, their group is the school sample. Comparison of  Tables 4.4 and  4.5 
suggests that the only diﬀ erence between the models is related to the coeﬃ  cients for the Level 
3 composition (  001 = ‒56.744) and aggregated teacher eﬀ ectiveness (  001 = 15.019) variables and 

148  Three-Level Univariate Regression Models
the coeﬃ  cient for the Level 2 group-centered class composition eﬀ ect (  020 = ‒25.606). It would 
be easy to misinterpret the meaning of these coeﬃ  cients without a clear understanding of the 
diﬀ erence between the two centering strategies. 
 Covariance Estimates 
 Th e covariance estimates in  Table 4.6  (which are the same for the two models) suggest that the 
addition of predictors at each level reduces the proportion of variance associated with each level 
of the data hierarchy (see  Table 4.2  on page 139) substantially (i.e., from 1,333.785 to 1,288.363 
at the student level, from 131.422 to 73.310 at the classroom level, and from 189.887 to 43.369 
at the school level). Th ese reductions in variance can be used to calculate an estimate of  R 2 at each 
level. For example, at the school level (Level 3) the reduction in variance would be calculated as 
(189.887 ‒ 43.369)/189.887 and results in an  R 2 coeﬃ  cient of 0.772. 
 It is important to reiterate that predictors entered into the model can aﬀ ect variance ac-
counted for at the level at which they are entered (e.g., Level 1 or Level 2), and they may also 
aﬀ ect the variance accounted for at higher levels. For example, if grand-mean centering is used, 
adjustments for Level 1 predictors may change the level and variability in the intercept across 
higher groupings. If group-mean centering is used, however, the Level 1 predictors will not aﬀ ect 
the level of the intercept or its variance across groups. In situations where accounting for variance 
is an important aim, the analyst may want to consider developing a Level l model ﬁ rst and then 
adding Level 2 and Level 3 predictors as separate sets of variables, so that the variance accounted 
for at each subsequent level is only aﬀ ected by predictors added at that level. 
TABLE 4.5 Estimates of Fixed Effectsa
Parameter
Estimate
Std. Error
df
t
Sig.
95% Conﬁ dence Interval
Lower Bound
Upper Bound
Intercept
596.759
0.741
148.049
804.847
.000
595.294
598.224
gmschlowSES_mean
−56.744
3.698
192.134
−15.346
.000
−64.037
−49.450
gmaggtcheffect
15.019
1.882
176.732
7.978
.000
11.304
18.734
groupteacheffect
7.571
0.619
656.308
12.223
.000
6.355
8.787
groupclasslowses_mean
−25.606
3.411
1,628.983
−7.507
.000
−32.297
−18.916
grouplowses
−14.534
0.862
8,841.429
−16.868
.000
−16.222
−12.845
a Dependent variable: math.  
TABLE 4.6 Estimates of Covariance Parametersa
Parameter
Estimate
Std. Error
Wald Z
Sig.
95% Conﬁ dence Interval
Lower Bound
Upper Bound
Residual
1,288.363
19.974
64.501
.000
1,249.803
1,328.112
Intercept [subject = schcode]
Variance
43.369
9.759
4.444
.000
27.903
67.408
Intercept [subject = 
schcode * Rteachid]
Variance
73.310
11.640
6.298
.000
53.705
100.072
a Dependent variable: math.

Three-Level Univariate Regression Models  149
 Another point to keep in mind is that where there are multiple random eﬀ ects (e.g., a random 
intercept and random slope), accounting for variance at successive levels may become more com-
plicated if the slope and intercept are correlated. In this case, predictors entered into the slope 
equation, for example, may also aﬀ ect variance estimates in the intercept equation (Raudenbush 
& Bryk, 2002). Centering on the group means tends to stabilize the model because it removes 
correlations (Paccagnella, 2006), so the resulting estimates may be more accurate. Group-mean 
centering may also be advantageous where the slope varies considerably for a particular predictor, 
and there is also considerable variability in the levels of the predictors across the units (Rauden-
bush & Bryk, 2002). 
 Model 4: Does the Slope Vary Randomly Across Schools? 
 We next investigate whether the random teacher eﬀ ect varies across schools. Th is will help us 
answer our second research question. Th e appropriate baseline slope model is the model with 
random slopes but no cross-level interactions (Hox, 2002). To indicate a random slope for the 
teacher eﬀ ect, we make a change in Equation 4.9 as follows: 
 01 k  =   010 +  u 01 k  . 
(4.11) 
 In this model (Model 4), we will also need to change the covariance matrix from identity (ID) to 
unstructured (UN) at Level 3 in order to accommodate the two additional random parameters in 
the model (i.e., the randomly varying slope and the covariance between the intercept and slope). 
Th is change will be the following: 
2
IS


2
I


2
I
IS
 I




IS
 I


2






2






IS
S


IS
 
(4.12)
 We will leave the Level 2 covariance matrix as an identity matrix, since there is only one random 
eﬀ ect (the intercept) at that level. As Equation 4.10 indicated, there were nine parameters to 
estimate in the previous model. Th rough substitution, we arrive at the new combined equation, 
which adds the random slope parameter at Level 3: 
 00 k  =   000 +   100 gmlowses ijk  +   010 gmteacheﬀ ect jk  +   020 gmclasslowses_mean jk  + 
  001 gmschlowSES_mean k  +   002 gmaggtcheﬀ ect k  +  u 01 k  gmteacheﬀ ect k  +  u 00 k  +  r 0 jk  +   ijk  .   (4.13) 

150  Three-Level Univariate Regression Models
 Deﬁ ning Model 4 with IBM SPSS Menu Commands 
 Note: IBM SPSS settings 
will default to those used in 
Model 3. 
 1.  Go to the toolbar and 
select ANALYZE, 
MIXED MODELS, 
LINEAR. 
 Th is command enables access 
to the  Linear Mixed Models: 
Specify Subjects and Repeated 
dialog box. 
 2.  Th e  Linear Mixed Models: Specify Subjects and 
Repeated screen displays the default settings 
from the prior model. 
 Click the CONTINUE button to display the 
 Linear Mixed Models dialog box. 

Three-Level Univariate Regression Models  151
  3.  Th e  Linear Mixed Models dialog box 
settings default to those used in the 
prior model. 
 a.  We will change the model by 
exchanging the group-mean-
centered variables for the grand-
mean-centered variables used in 
Model 2 (   gmlowses ,  gmclasslowses_
mean , and  gmteacheﬀ ect ). Remove 
the group-mean-centered vari-
ables by clicking to select  groupt-
eacheﬀ ect ,  groupclasslowses_mean , 
and  grouplowses and then clicking 
left-arrow button (or “dragging” 
the variables). 
 b.  Now click to select three grand 
mean variables (   gmlowses ,  gm-
classlowses_mean , and  gmteachef-
fect ), and drag them to the 
 Covariate(s) box. 
 c.  To facilitate reading of the output 
tables, we will change the se-
quence of the variables by drag-
ging variables to rearrange them. 
First, click to select  gmteacheﬀ ect , 
and then drag the variable below 
 gmaggtcheﬀ ect.  Continue rear-
ranging the variables to achieve 
the ﬁ nal sequence order (see 
insert):  gmschlowSES_mean , 
 gmaggtcheﬀ ect ,  gmteacheﬀ ect , 
 gmclasslowses_mean , and  gmlowses . 
 Note: An alternate method for arranging 
the variables in the desired sequence order 
is to select variables individually and then 
use the right-arrow button (or drag the 
variable) to move each variable into the 
 Covariate(s) box. 
 We may now proceed to deﬁ ne ﬁ xed eﬀ ects for the variables. 
 Click the FIXED button to access the  Linear Mixed Models: Fixed Eﬀ ects dialog box. 

152  Three-Level Univariate Regression Models
 4a.  Th e  Linear Mixed Models: 
Fixed Eﬀ ects default 
setting from the prior 
model is  Main Eﬀ ects . 
 b.  Click to select the three 
grand-mean-centered 
variables ( gmteacheﬀ ect , 
 gmclasslowses_mean , and 
 gmlowses ) from the  Fac-
tors and Covariates box, 
and then click the ADD 
button to move the vari-
ables into the  Model box. 
 Click the CONTINUE button to 
return to the  Linear Mixed Models 
dialog box. 
 We will modify the model’s random eﬀ ects, so click the RANDOM button to access the  Linear Mixed 
Models: Random Eﬀ ects dialog box. 
 5a.  Th e  Linear Mixed Models: 
Random Eﬀ ects  displays the 
 Random Eﬀ ect 2 of 2 screen 
as it was the ﬁ nal screen 
used in an earlier model. We 
want to access the Level 1 
dialog box, so click the 
PREVIOUS button. 
 b.  From the  Random Eﬀ ect 1 of 
2 screen, change the covari-
ance type by clicking the 
pull-down menu and select-
ing  Unstructured. 
 
  
  Unstructured is a completely 
general covariance matrix 
(IBM Corporation, 2012). 
 c.  We will add a variable 
(   gmteacheﬀ ect ) to the model 
to test whether the random 
teacher eﬀ ect varies across 
schools, so ﬁ rst click the 
pull-down menu and change 
the setting to  Main Eﬀ ects. 
 d.  Now click to select  gm-
teacheﬀ ect , and then click the ADD button to move the variable into the  Model box. 
 Click the CONTINUE button to return to the  Linear Mixed Models dialog box. 

Three-Level Univariate Regression Models  153
 6.  Finally, in the  Linear Mixed Models 
dialog box, click the OK button to 
run the model. 
 Interpreting the Output from Model 4 
 Th e addition of the random slope and the covariance between the slope and intercept at Level 3 
in Model 4 makes a total of 11 parameters to estimate. We can verify this from the model dimen-
sion output for Model 3 in  Table 4.7 . To look at this table in a little more detail, there are now 
two random eﬀ ects at Level 3 (intercept and teacher eﬀ ectiveness slope) and one random eﬀ ect 
at Level 2 (intercept). In addition, there are two other random parameters (i.e., Level 1 residual, 
Level 3 slope-intercept covariance). Th e estimates for these ﬁ ve parameters are summarized in 
 Table 4.8 . 
TABLE 4.7 Model Dimensiona
Number of
Levels
Covariance 
Structure
Number of 
Parameters
Subject Variables
Fixed Effects
Intercept
1
1
gmschlowSES_mean
1
1
gmaggtcheffect
1
1
gmteacheffect
1
1
gmclasslowses_mean
1
1
gmlowses
1
1
Random Effects
Intercept + gmteacheffect
2
Unstructured
3
schcode
Intercept
1
Identity
1
schcode * Rteachid
Residual
1
Total
9
      11
a Dependent variable: math.  

154  Three-Level Univariate Regression Models
 Table 4.8  provides the new variance components for Model 4. As the table shows, however, the 
variance in teacher eﬀ ectiveness slopes (UN 2, 2) is not signiﬁ cant between schools ( 2 2,2 = 5.759, 
Wald  Z = 0.877, one-tailed  p = .1905). Th erefore, in this sample data it would not be necessary 
to try to build a Level 3 model with cross-level interactions to explain variation in the size of 
teacher classroom eﬀ ects across schools. We therefore can answer our second research question 
by noting that the size of individual teacher eﬀ ects do not seem to vary between schools. Th is 
may suggest that diﬀ erences in individual teacher eﬀ ects are more apparent between classrooms 
but within schools, rather than between schools. 
 Developing an Interaction Term 
 Because classroom teacher eﬀ ectiveness did not vary across schools, we turn our attention to 
answering our third research question. Interactions suggest that the relationship between a pre-
dictor ( A  ) and the outcome ( Y   ) is contingent on levels of another predictor ( B ). Because inter-
actions are product terms ( A   * B ), they depend on the levels of the predictors from which they 
are produced. Th is concerns whether the impact of teacher eﬀ ectiveness on student learning 
is contingent on various types of classroom composition features. In this case, we will investi-
gate a covariate*covariate interaction (class SES*teacher eﬀ ectiveness). We initially propose that 
teacher eﬀ ectiveness is a stronger predictor of achievement in classrooms with more challenging 
student composition. If this is true, then we would expect a positive interaction eﬀ ect between 
teacher eﬀ ectiveness and classroom composition. 
 We will next deﬁ ne an interaction term between teacher eﬀ ectiveness and classroom SES 
composition (deﬁ ned as the percentage of low SES students) and add it to the Level 2 
model: 
 π 0 jk  =   00k +   01 k  (   gmteacheﬀ ect )  jk  +   02 k  (   gmclasslowses _mean )  jk  + 
 
   03 k  (   gmclasslowses _mean * gmteacheﬀ ect )  jk  +  r 0 jk  . 
(4.14) 
 We call attention to the importance of thinking about the meaning of the coding of each pre-
dictor comprising an interaction. When continuous variables that are part of an interaction are 
left in natural metrics, it may make it more diﬃ  cult to interpret the meaning of the interaction 
(e.g., a motivation score of 0 or a family income score of 0). Because no one in the data set might 
have a score of 0, it is often useful to recenter the scores in a way that they can be more mean-
ingfully interpreted. Grand-mean centering continuous  A and  B covariates facilitates this type 
TABLE 4.8 Estimates of Covariance Parametersa
Parameter
Estimate
Std. Error
Wald Z
Sig.
Residual
1,288.878
19.989
64.478
.000
UN (1,1)
42.153
9.657
4.365
.000
Intercept + gmteacheffect 
[subject = schcode]
UN (2,1)
2.826
4.887
.578
.563
UN (2,2)
5.759
6.568
.877
.381
Intercept [subject = 
schcode * Rteachid]
Variance
68.701
12.359
5.559
.000
a Dependent variable: math. 

Three-Level Univariate Regression Models  155
of meaningful interpretation since if we grand-mean center each, then the interpretation of the 
interaction slope is that it is the expected value of the slope when the other variable has the value 
of 0 (i.e., the average eﬀ ect). For a factor*covariate interaction (e.g., ethnicity*family income), the 
interaction can be interpreted as a test of parallel lines (for each racial/ethnic group) regarding 
the relationship between the continuous variable (family income) across levels of the factor and  Y .
Here, grand-mean centering family income can facilitate interpreting the diﬀ erence in its “average 
eﬀ ect” across levels of the factor. For a factor*factor interaction (e.g., female*lowSES), with each 
variable coded 0 and 1, there are four possible cells (0, 0; 0, 1; 1, 0; and 1, 1). Multiplication in 
the ﬁ rst three cells will equal 0, leaving only the last cell (1, 1) as deﬁ ning the added advantage or 
disadvantage for outcomes due to the interaction eﬀ ect. Th e interpretation of the interaction will 
be the advantage or disadvantage associated with being female and low SES against the other 
three cells combined. Th is choice might be the one the analyst desires in interpreting the interac-
tion. Centering the factors ( A ,  B ) in the interaction will carry a slightly diﬀ erent interpretation of 
the intercept from leaving them in their natural metrics. 
 Preliminary Investigation of the Interaction 
 Before actually running the full model, we will pause for a moment to consider the pro-
posed interaction in a little more detail. We can create this interaction variable implied in 
Equation 4.14 using the Menu commands by combining classroom composition and class-
room teacher eﬀ ectiveness (instructions provided in Model A at the end of this section). Inter-
actions can also be computed easily using the syntax statements (or by using COMPUTE and 
saving the interaction in the data set). We focus on just the two main eﬀ ects and the interaction 
to make a point about how centering the interactions diﬀ erently can aﬀ ect the interpretation 
of the coeﬃ  cients. 
 In  Table 4.9 , we summarize the estimates for the natural metric solution. Th e intercept is 
611.325, which can be interpreted as the point where class SES is 0—that is, where there is no 
student participating in the federal free/reduced lunch program. We might be able to ﬁ nd a bet-
ter centering solution for this variable, however, since more than 40% of the sample participated 
in the free/reduced lunch program. Th e intercept can also be interpreted as the achievement level 
where teacher eﬀ ectiveness is 0. Since teacher eﬀ ectiveness is a factor score (developed from a 
separate analysis with  M = 0,  SD  = 1), this can be interpreted roughly as “average” teacher eﬀ ec-
tiveness, but it is uncentered within the current multilevel model. In the table, both of the main 
eﬀ ects (classroom SES and teacher eﬀ ectiveness) are signiﬁ cant predictors of math scores. Th e 
interaction, however, is not signiﬁ cant, so we could consider removing it if desired. When an 
interaction term ( A   * B ) is signiﬁ cant, however, we suggest leaving both the direct eﬀ ects of  A and 
 B in the model whether they are signiﬁ cant or not. 
TABLE 4.9 Estimates of Fixed Effectsa
Parameter
Estimate
Std. Error
df
t
Sig.
95% Conﬁ dence Interval
Lower Bound
Upper Bound
Intercept
611.365
1.507
420.970
405.670
.000
608.403
614.328
teacheffect
5.988
1.424
763.172
4.204
.000
3.192
8.785
classlowses_mean
−35.605
2.913
968.782
−12.225
.000
−41.321
−29.889
teacheffect * classlowses_mean
4.515
3.121
818.673
1.447
.148
−1.611
10.641
a Dependent variable: math.  

156  Three-Level Univariate Regression Models
 Next, in  Table 4.10  we provide the grand-mean-centered solution (instructions provided in 
Model B at the end of this section). Notice that the intercept is a bit lower (596.647), which 
results from  classlowses_mean  and  teacher eﬀ ectiveness  being centered around their grand means. 
Th e intercept can now be interpreted as the point where the proportion of students participat-
ing in free/reduced lunch is the average for the sample (0). Th is is a more meaningful centering 
because of the high proportion of students in the sample who participate in this program. We 
reiterate the point that grand-mean centering the interaction slope facilitates interpretation since 
it implies what the expected value of the slope is when the other variable has the value of 0 (i.e., 
the average eﬀ ect). 
 Deﬁ ning Models A and B (Preliminary Testing of Interactions) with IBM SPSS Menu Commands 
 Note: IBM SPSS settings will de-
fault to those used in Model 4. 
 1.  Go to the toolbar and select 
ANALYZE, MIXED MOD-
ELS, LINEAR. 
 Th is command enables access to the 
 Linear Mixed Models: Specify Subjects 
and Repeated dialog box. 
TABLE 4.10 Estimates of Fixed Effectsa 
Parameter
Estimate
Std. Error
df
t
Sig.
95% Conﬁ dence Interval
Lower Bound Upper Bound
Intercept
596.647
0.896
135.799
666.267
.000
594.876
598.418
gmteacheffect
7.840
0.605
680.886
12.956
.000
6.652
9.028
gmclasslowses_mean
−35.674
2.911
968.896
−12.255
.000
−41.387
−29.962
gmteacheffect * gmclasslowses_
mean
4.515
3.121
818.673
1.447
.148
−1.611
10.641
a Dependent variable: math.

Three-Level Univariate Regression Models  157
 2.  Th e  Linear Mixed Models: Specify Subjects and 
Repeated screen displays the default settings 
from the prior model. 
 Click the CONTINUE button to display the 
 Linear Mixed Models dialog box. 
 3.  Th e  Linear Mixed Models dialog 
box settings default to those used 
in Model 4. 
 a.  We will remove variables 
that aren’t needed for the 
interactions. Click to select 
 gmschlowSES_mean ,  gmag-
gtcheﬀ ect , and  gmlowses , and 
then click the left-arrow 
button (or drag the variables 
left) to remove them from the 
 Covariate(s) box. 
 b.  We will now add two variables 
( teacheﬀ ect  and  classlowses_mean ) 
that will be used to test the sec-
ond interaction. Click to select 
 teacheﬀ ect and  classlowses_mean , 
and then drag the variables 
to the  Covariate(s) box below 
 gmclasslowses_mean. 
 Th e four variables to be used for inter-
action testing are shown in the insert: 
 gmteacheﬀ ect ,  gmclasslowses_mean , 
 teacheﬀ ect , and  classlowses_mean . 
 We will introduce a ﬁ xed eﬀ ect to the 
model, so click the FIXED button to 
access the  Linear Mixed Models: Fixed 
Eﬀ ects dialog box. 

158  Three-Level Univariate Regression Models
 Model A Test Interaction:  teacheffect*classlowses_mean 
 4a.  Th e  Linear Mixed Models: 
Fixed Eﬀ ects dialog box 
displays the default setting 
from Model 4. We will clear 
the  Model box by clicking to 
select  gmclasslowses_mean and 
then clicking the REMOVE 
button. 
 b.  Note that  Main Eﬀ ects is the 
default setting. 
 c.  Click to select  teacheﬀ ect and 
 classlowses_mean , and then 
click the ADD button to 
move the variables into the 
 Model box. 
We will now add one cross-level interaction (or nested term) to the model:  teacheﬀ ect*classlowses_
mean. Th e interaction will tell us if teacher eﬀ ectiveness ( teacheﬀ ect ) predicts achievement in 
classrooms with more challenging student composition ( classlowses_mean ). 
 
 d.  Note that  Build nested terms 
is the default setting from 
the prior model. 
 
 e.  Click to select the variable 
 teacheﬀ ect  from the  Factors 
and Covariates box. 
 
 f.  Th en click the arrow but-
ton below the  Factors and 
Covariates box. Th is moves 
 teacheﬀ ect into the  Build 
Term box to create a cross-
level interaction by linking 
variables and terms. 
 
 g.  Next, click the BY* button, 
which will insert the com-
putation command symbol: 
 teacheﬀ ect* . 
 
 h.  Click to select  classlowses_mean  from the  Factors and Covariates box. 
 
 i.  Click the arrow button below the  Factors and Covariates box to move  classlowses_mean into the 
 Build Term box and complete the interaction term:  teacheﬀ ect* classlowses_mean . 
 
 j.  Click the ADD button to transfer the interaction into the  Model box. 
 Click the CONTINUE button to return to the  Linear Mixed Models dialog box. 
 We will modify the model’s random eﬀ ects, so click the RANDOM button to access the  Linear Mixed 
Models: Random Eﬀ ects dialog box. 

Three-Level Univariate Regression Models  159
 5.  Th e  Random Eﬀ ect 1 of 2 
screen is displayed ﬁ rst, as it 
was the last dialog box used 
in Model 4. 
 a.  Change the covariance 
type by clicking the pull-
down menu and selecting 
 Scaled Identity. 
 Th e  Scaled Identity  covariance 
structure has constant vari-
ance and assumes no correlation 
between any elements (IBM 
Corporation, 2012). 
 b.  We will remove  gm-
teacheﬀ ect  from the 
model. Click to select the 
variable, and then click 
the REMOVE button. 
 Click the CONTINUE button to return to the  Linear Mixed Models dialog box. 
 6.  Finally, in the  Linear Mixed 
Models dialog box, click 
the OK button to run the 
model. 
 Model B Test Interaction:  gmteacheffect*gmclasslowses_mean 
 Repeat Model A steps 1 and 2, and then click the FIXED button to access the  Linear Mixed 
Models: Fixed Eﬀ ects dialog box. 

160  Three-Level Univariate Regression Models
 3a.  Th e  Linear Mixed 
Models: Fixed Eﬀ ects  
dialog box displays the 
default setting from 
Model A. We will 
clear the  Model  box 
by clicking to select 
the ﬁ xed eﬀ ects from 
Model A ( teacheﬀ ect , 
 classlowses_mean , and 
 teacheﬀ ect*classlowses_
mean ) and then click-
ing the REMOVE 
button. 
 b.  Click to select the 
 Build terms option. 
 c.  Note that  Main Eﬀ ects 
is the default setting. 
 d.  We will now create a test model using grand-mean-centered variables. Click to select  gm-
teacheﬀ ect and  gmclasslowses_mean , and then click the ADD button to move the variables into 
the  Model box. 
 We will now add one cross-level interaction (or nested term) to the model using grand-mean-centered 
variables:  gmteacheﬀ ect*gmclasslowses_mean.  Th e interaction will tell us if teacher eﬀ ectiveness (   gmteachef-
fect ) predicts achievement in classrooms with more challenging student composition (    gmclasslowses_mean ). 
 e.  Note that  Build 
nested terms is the 
default setting from 
the prior model. 
 f.  Click to select the 
variable  gmteacheﬀ ect 
from the  Factors and 
Covariates box. 
 g.  Th en click the arrow 
button below the 
 Factors and Covari-
ates box. Th is moves 
 gmteacheﬀ ect into 
the  Build Term box 
to create a cross-
level interaction by 
linking variables and 
terms. 
 h.  Next, click the BY* button, which will insert the computation command symbol:  gmteacheﬀ ect* . 
  i.  Click to select  gmclasslowses_mean from the  Factors and Covariates box. 
  j.  Click the arrow button below the  Factors and Covariates box to move  gmclasslowses_mean into 
the  Build Term box and complete the interaction term:  gmteacheﬀ ect* classlowses_mean . 
 k.  Click the ADD button to transfer the interaction into the  Model box. 

Three-Level Univariate Regression Models  161
 Click the CONTINUE button to return to the  Linear Mixed Models dialog box. 
 4. Finally, in the  Linear Mixed Models dialog box, click the OK button to run the model. 
 Model 5: Examining a Level 2 Interaction 
 Th is investigation of adding a Level 2 interaction term to the model also allows us to demon-
strate how an analyst can compare successive models to see whether an added variable (or set of 
variables) makes a diﬀ erence in the overall ﬁ t of the proposed model to the data. We will again 
use ML estimation to facilitate the comparison of the previous model without the Level 2 inter-
action against this current model with the interaction added (which will increase the number of 
estimated parameters from 11 to 12). Using REML to compare successive models would only 
be optimal when the focus is on a diﬀ erence in random parameters between the two models. Th e 
rest of the model remains as Model 4. 
 Deﬁ ning Model 5 with IBM SPSS Menu Commands 
 Note: If continuing onward 
from the last section, “Prelim-
inary Investigation Interac-
tion,” reset the default settings 
to replicate Model 4 before 
proceeding. 
 1.  Go to the toolbar and 
select ANALYZE, 
MIXED MODELS, 
LINEAR. 
 Th is command enables access 
to the  Linear Mixed Models: 
Specify Subjects and Repeated 
dialog box. 

162  Three-Level Univariate Regression Models
 2.  Th e  Linear Mixed Models: Specify Subjects and 
Repeated screen displays the default settings 
from the prior model. 
 Click the CONTINUE button to display the  Linear 
Mixed Models dialog box. 
 3.  Th e  Linear Mixed Models dialog 
box settings default to those used in 
Model 4. 
 We will introduce a ﬁ xed eﬀ ect to the 
model, so click the FIXED button to 
access the  Linear Mixed Models: Fixed Ef-
fects dialog box. 
 One cross-level interaction (or nested 
term) will be created and added to the 
model:  gmclasslowses_mean*gmteacheﬀ ect. 
Th e interaction will tell us if there’s a 
relationship between teacher eﬀ ectiveness 
(   gmteacheﬀ ect ) and low socioeconomic 
class composition (   gmclasslowses_mean ). 
 4a.  Th e  Linear Mixed Mod-
els: Fixed Eﬀ ects dialog 
box displays the default 
setting from Model 4a. 
To facilitate reading of 
the output tables, we 
will ﬁ rst remove  gm-
lowses  and then add it 
back into the model. 
First, click to select 
 gmlowses , and then click 
the REMOVE button. 

Three-Level Univariate Regression Models  163
 Add Interaction to Model 5:  gmclasslowses_mean*gmteacheffect 
 
 b. Change the build terms option by clicking to select  Build nested terms. 
 
 c. Click to select the variable  gmclasslowses_means from the  Factors and Covariates box. 
 
 d. Th en click the arrow button below the  Factors and Covariates box. Th is moves  gmclasslowses_
means into the  Build Term box to create a cross-level interaction by linking variables and terms. 
 
 e. Next, click the BY* button, which will insert the computation command symbol: 
 gmclasslowses_means *. 
 
 f. Click to select  gmteacheﬀ ect  from the  Factors and Covariates box. 
 
 g. Click the arrow button below the  Factors and Covariates box to move  gmteacheﬀ ect into the 
 Build Term box and complete the interaction term:  gmclasslowses_means*gmteacheﬀ ect . 
 
 h. Click the ADD button to transfer the interaction into the  Model box. 
 We will now add  gmlowses 
back into the model. 
 i.  Click to select the 
 Build terms option. 
 j.  Click to select  gm-
lowses , and then click 
the ADD button to 
transfer the variable 
into the  Model box. 
 Click the CONTINUE button 
to return to the  Linear Mixed 
Models dialog box. 
 5.  Finally, in the  Linear Mixed Models 
dialog box, click the OK button to 
run the model. 
 Interpreting the Output From Model 5 
 We present the results for Model 5 in  Table 4.11 . Th e ﬁ rst two variables below the intercept are 
the between-school predictors of math outcomes. Both school SES composition and aggregate 
teacher eﬀ ectiveness are signiﬁ cant predictors of achievement. Next are the classroom variables 
(i.e., classroom composition, teacher eﬀ ectiveness, and the interaction term). Th e results suggest 

164  Three-Level Univariate Regression Models
that the interaction between teacher eﬀ ectiveness and classroom SES composition (   03 ) is sig-
niﬁ cant at  p < .10 (   030 = 5.385). Because of coding, this result suggests that in a classroom 1 
 SD above the grand mean (0) in low SES composition, the combined teacher eﬀ ect would be 
considerably larger (7.432 + 5.385 = 12.817) than the teacher eﬀ ect (7.432) in a class at the grand 
mean (0) in SES composition. Th is provides supportive evidence for answering our third research 
question, which focused on whether teacher eﬀ ectiveness might be contingent on classroom 
composition factors. 
 Table 4.12  suggests that the variance at Level 2 was little aﬀ ected by adding the interaction 
eﬀ ect to the model. 
 Comparing the Fit of Successive Models 
 We can compare model-ﬁ tting evidence from the previous model with no interaction at Level 2 
(Model 4) and the current model (Model 5) to determine whether the addition of the interaction 
term enhanced the ﬁ t of the model. Tests of nested models should be conducted with ML when 
regression coeﬃ  cients are being compared for their ﬁ t to the data. Model 4 without the interac-
tion term included (11 estimated parameters) yields the model ﬁ t criteria shown in  Table 4.13 . 
 Model 5 (estimated similarly with ID and UN matrices and the Level 2 interaction) yields the 
model ﬁ t criteria (for 12 estimated parameters) shown in  Table 4.14 . 
 With ML estimation, the probability of obtaining the observed results given the parameter 
estimates is referred to as the likelihood function. Since the likelihood is less than 1.0, it is 
TABLE 4.11 Estimates of Fixed Effectsa
Parameter
Estimate
Std. Error
df
t
Sig.
95% Conﬁ dence Interval
Lower Bound
Upper Bound
Intercept
596.859
0.733
147.494
814.737
.000
595.411
598.306
gmschlowSES_mean
−31.181
4.517
429.003
−6.903
.000
−40.059
−22.303
gmaggtcheffect
7.676
1.950
208.991
3.937
.000
3.832
11.520
gmteacheffect
7.432
0.677
74.918
10.970
.000
6.082
8.782
gmclasslowses_mean
−10.933
3.469
1,748.372
−3.152
.002
−17.736
−4.130
gmteacheffect * 
gmclasslowses_mean
5.385
3.138
373.263
1.716
.087
−0.785
11.555
gmlowses
−14.543
0.862
8,837.068
−16.880
.000
−16.232
−12.854
a Dependent variable: math.
TABLE 4.12 Estimates of Covariance Parametersa
Parameter
Estimate
Std. Error
Wald Z
Sig.
95% Conﬁ dence Interval
Lower Bound
Upper Bound
Residual
1,288.768
19.985
64.485
.000
1,250.186
1,328.540
Intercept + gmteacheffect 
[subject = schcode]
UN (1, 1)
41.227
9.544
4.320
.000
26.190
64.898
UN (2, 1)
3.041
4.932
0.617
.537
6.625
12.708
UN (2, 2)
6.201
6.536
0.949
.343
0.786
48.932
Intercept [subject = 
schcode * Rteachid]
Variance
68.321
12.279
5.564
.000
48.036
97.171
a Dependent variable: math.

Three-Level Univariate Regression Models  165
common to use ‒2 times the log of the likelihood (–2LL) as a measure of model ﬁ t to the data. 
Good models result in a high likelihood of obtaining the observed results (which corresponds to 
a small value for ‒2LL). A perfect model would have a likelihood of 1, and the log of likelihood 
would be 0 (which when multiplied by ‒2 is also 0). Th e analyst can test the diﬀ erence in ‒2LL 
(also referred to model deviance) between two models if the models are nested, which means a 
speciﬁ c model can be derived from a more general model by removing parameters from the more 
general model. Th e diﬀ erence in ‒2LL for two such models being compared can be conceptual-
ized as a likelihood ratio test, which follows a chi-square distribution, with degrees of freedom 
( df    ) equal to the diﬀ erence in the number of parameters estimated between the two models 
(Azen & Walker, 2011). 
 In this case, we will assume that the model with the interaction is more general since it has 
12 estimated parameters. We then compare it against the more restricted model, which has 
the interaction removed (i.e., 11 parameters are estimated). Th e diﬀ erence in ‒2LL between 
the two models is 2.928. Th ere is 1  df in the model test since one regression parameter is being 
removed. Th e required chi-square at  p = .05 for 1  df is 3.84. Th erefore, we can conclude that the 
model with 11 estimated parameters (i.e., without the interaction term) ﬁ ts the data the same 
as the model with the interaction term added. Another way of looking at this would be that 
adding the interaction does not “signiﬁ cantly improve” the model’s ﬁ t to the data. When the 
diﬀ erence between models is small (i.e., not statistically signiﬁ cant), we will usually accept the 
restricted model since it provides the same ﬁ t to the data with fewer parameters estimated (as 
summarized in  Table 4.8 ). In this case, the likelihood ratio test is consistent with the  t test in 
 Table 4.11  ( t  = 1.716,  p = .087), which suggests that the interaction is not signiﬁ cant at  p < .05. 
If the diﬀ erence in model deviances was statistically signiﬁ cant, we would accept that the more 
general model (with more parameters) improves the model’s ﬁ t to the data. For models that are 
not nested, we can use the Schwarz’s Bayesian criterion (BIC) or Akaike’s information criterion 
(AIC) indices in  Tables 4.13  and  4.14 to compare models. We prefer smaller values regardless of 
TABLE 4.13 Information Criteriaa
−2 Log Likelihood
92,325.317
Akaike’s Information Criterion (AIC)
92,347.317
Hurvich and Tsai’s Criterion (AICC)
92,347.346
Bozdogan’s Criterion (CAIC)
92,436.693
Schwarz’s Bayesian Criterion (BIC)
92,425.693
Note: The information criteria are displayed in 
smaller-is-better forms.
a Dependent variable: math.
TABLE 4.14 Information Criteriaa
−2 Log Likelihood
92,322.389
Akaike’s Information Criterion (AIC)
92,346.389
Hurvich and Tsai’s Criterion (AICC)
92,346.423
Bozdogan’s Criterion (CAIC)
92,443.891
Schwarz’s Bayesian Criterion (BIC)
92,431.891
Note: The information criteria are displayed in 
smaller-is-better forms.
a Dependent variable: math.

166  Three-Level Univariate Regression Models
the number of parameters estimated in the models. Other criteria presented as part of the output 
represent similar ways of comparing models (users can consult SPSS MIXED Help for further 
information). 
 Summary 
 Th e previous discussion suggests that researchers should proceed with caution when building 
multilevel models. It is often the case that diﬀ erent sets of variables are hypothesized to explain 
variation in random intercepts and slopes. Raudenbush and Bryk (2002) suggest using a com-
mon set of variables when building the models between groups. We decided to add the intercept 
predictors ﬁ rst and then to consider variation in slopes. 

167
167
 CHAPTER 5 
 Examining Individual Change with Repeated 
Measures Data 
 I
n our previous chapters, the outcome and explanatory variables were only measured on one  
 occasion. One of the limitations of such cross-sectional analyses is that they are not well 
suited to studying processes that are assumed to be developmental. Because data are collected 
only at one point in time, they are insuﬃ  cient to examine possible temporal relationships in a 
theoretical model. Time is a key factor in understanding how developmental processes unfold. 
When an outcome is measured several times for an individual, we have a repeated measures de-
sign (RMD). A simple example is the pretest and posttest design. For studying developmental 
processes, however, adding measurement occasions between the pretest and posttest can provide 
a more thorough examination and often can increase the power of the statistical test used to 
determine whether a change has taken place (Hox, 2010; Willett, 1989). 
 Ways to Examine Repeated Observations on Individuals 
 In the past, analyses of repeated observations on individuals were typically conducted using uni-
variate analysis of variance (ANOVA) or multivariate analysis of variance (MANOVA), depend-
ing on the goals of the research and the speciﬁ c features of the data. Th ere are, however, several 
limitations of both approaches that arise from assumptions underlying their appropriate use in 
longitudinal research (e.g., see Hox, 2010; Raudenbush & Bryk, 2002). One primary shortcom-
ing is that both approaches are limited to a subset of research situations involving change within 
and between individuals, where the timing of the repeated measurements is equidistant, subjects 
are independently and randomly sampled, and the change is considered as a ﬁ xed, rather than 
randomly varying, parameter between individuals. Most importantly for our purposes, analyses 
using either approach cannot be extended to include higher level groups such as classrooms or 
schools since this violates the assumption of sampling independence. 
 A second limitation concerns the normality of the data. For the univariate ANOVA approach, 
because diﬀ erences in means of an outcome are tested over levels of a within-subjects factor 
( time ), we must restrict the nature of the residual variances between the repeated measures as well 
as possible covariances between them (referred to as  sphericity ). Th e sphericity assumption im-
plies that the within-subject model consists of independent (orthogonal) components. One type 
of sphericity is  compound symmetry , which requires the repeated measures variances to be equal 
and any covariances between them to be the same. Where the assumption is not met, researchers 
can either use a degrees of freedom ( df ) correction to the  F tests for hypothesis testing (to guard 
against Type I errors), or they often use the multivariate (MANOVA) approach since it does 
not require the sphericity assumption. Repeated measures ANOVA (RM-ANOVA) also re-
quires homogeneity of variance for diﬀ erent levels of between-subjects factors such as treatment 

168  Examining Individual Change with Repeated Measures Data
and control groups, while MANOVA requires the related assumption of homogeneity of the 
 variance-covariance matrices for dependent variables across between-subjects factors. 
 A third limitation is the inability to include individuals with partial data in the analysis in 
either approach. Any individual with missing data on any occasion is eliminated from the analy-
sis through listwise deletion. Th is can result in a tremendous loss of information about indi-
viduals within a longitudinal analysis. Th erefore, we suggest having little or no missing data if 
either approach is to be used. Provided their basic assumptions are met, however, ANOVA and 
MANOVA remain viable approaches for examining repeated measures data. 
 Increasingly, however, both the concepts and methods are becoming available that can pro-
vide a more rigorous and thorough examination of repeated measures data. One well-known 
approach, which draws on structural-equation-modeling (SEM) methods, is latent change (or 
curve) analysis (LCA). In the LCA approach to examining growth, the repeated measures of 
 Y are deﬁ ned in a covariance matrix, which accommodates a single-level conﬁ rmatory factor 
analysis (CFA); that is, the repeated measures are treated as observed variables that deﬁ ne latent 
intercept and growth factors. In this way, a time dimension is incorporated into the speciﬁ cation 
of the latent variables. Th e SEM speciﬁ cation of individual latent change amounts to a multi-
variate speciﬁ cation at a single level. Change involving individuals within groups can then be 
accommodated as a two-level CFA (Muthén & Muthén, 1998–2006). 
 Repeated measures data with within-subjects and between-subjects factors can also be speci-
ﬁ ed as another type of linear mixed (or random coeﬃ  cients) model (Laird & Ware, 1982). In 
this latter approach, change involving individuals can be conceptualized as a two-level analysis, 
with the repeated measures of  Y and the change in their levels over time speciﬁ ed at Level 1 and 
random variation in the individual intercepts and growth rates examined at Level 2. Diﬀ erences 
between individuals (e.g., background or an experimental treatment) can be proposed to explain 
random variation in individuals’ growth parameters at Level 2. Moreover, in the mixed model, 
the repeated measures can be observed at ﬁ xed or varying occasions, and the approach can in-
corporate missing data on  some occasions. Th is can be beneﬁ cial if there are subjects who drop 
out during a longitudinal study. Th e mixed model can also accommodate time-varying covariates 
at Level 1. Using a multilevel framework, univariate analyses of individual growth can easily be 
extended to include more than one growth process or diﬀ erences in growth due to successive 
groupings such as classrooms (Level 3) and schools (Level 4). We note, however, that the com-
plexity of adding more analytic levels can begin to challenge available computer memory needed 
to estimate a proposed model’s parameters. 
 Models with time-ordered relationships deﬁ nitely oﬀ er increased possibilities for studying 
various types of individual change processes using either the multivariate SEM or univariate 
two-level mixed model approaches. Th ey encourage researchers to ask a number of diﬀ erent 
questions of the data: Is there a change in the level of the means over time? If so, what is the 
shape of the change trajectory? Is the change the same for diﬀ erent groups of individuals? 
 Considerations in Specifying a Linear Mixed Model 
 Th ere are a number of considerations to keep in mind in specifying a repeated measures analysis 
using a linear mixed-modeling approach. First, we should decide whether we are examining one 
or more growth processes. For our presentation in this chapter, we will use a univariate approach 
to examine our proposed research questions; that is, we assume there is only one outcome being 
examined over time. In Chapter 7, we consider a multivariate (e.g., parallel) growth model—one 
that facilitates the examination of individual changes in reading and math achievement simul-
taneously. Our primary hypothesis in a univariate RMD concerns whether or not there is a dif-
ference in the levels of the means of the dependent variable over time (Raykov & Marcoulides, 
2008). If we are able to reject the null hypothesis that the means are the same, then we can as-
sume that some change has taken place. 

Examining Individual Change with Repeated Measures Data  169
 For investigating individual development in a single outcome, we can test this assumption of 
equal means using RM-ANOVA; however, as we suggested earlier, we must assume  sphericity . 
Th e sphericity assumption refers to the structure of the repeated measures covariance matrix and 
stems from the assumption that the repeated observations should be independent and therefore 
have constant variance and ideally be uncorrelated with each other. Th is is an important assump-
tion underlying the RM-ANOVA approach (which can be tested using Mauchly’s sphericity test) 
since it aﬀ ects the calculation of signiﬁ cance levels of the related  F  tests for proposed hypotheses. 
Mauchly's test provides a test of whether the repeated measures used to deﬁ ne within-subjects 
growth are represented by a spherical covariance matrix. Th e test, however, is highly sensitive to 
even mild departures from the required covariance structure. If sphericity is not met (which is 
generally the case with real data), there are other options including adjusting the  F  tests in RM-
ANOVA for purposes of hypothesis testing or using the multivariate approach. Another alterna-
tive is the mixed model approach. A clear advantage of this latter approach is that it provides 
greater ﬂ exibility in identifying a suitable Level 1 covariance structure that captures the nature 
of the observed relationships between the repeated measures of  Y in varied longitudinal studies, 
regardless of time-trend patterns within individuals and among the groups being compared. 
 Second, after determining an approach to use, we need to consider the expected within- 
subjects (Level 1) eﬀ ect for  time , which concerns individuals’ possible change over the  temporal 
period of the study. Th e time eﬀ ect describes whether individuals are indeed changing over some 
relevant  interval of time and by  how much . Th is part of the within-subjects model represents the 
change we would anticipate that each individual would experience over the course of the study 
(Singer & Willett, 2003). For example, the relevant time interval may be days, weeks, months, or 
years. In a mixed model, the potential diﬀ erence in means across measurement occasions can be 
summarized as a time-related slope. Th e time slope is generally the most important parameter in 
the model because it provides a test of whether the outcome means are equal across occasions, as 
well as information about the  rate at which individual  i changes over a particular time interval  t . 
 If we ﬁ nd that the means of  Y are not the same across time, we next would want to investigate 
further how individuals are changing over time. Th e analysis of repeated measures facilitates the 
representation of several diﬀ erent growth trajectories. Th ese can concern, for example, a natu-
rally occurring developmental trend (e.g., students’ acquisition of vocabulary between 12 and 
36 months of age) or perhaps individuals’ reading skills before and after a classroom treatment 
is introduced. When a categorical variable represents an increasing level of a treatment dosage, 
age, or a series of successive measurements, the growth trend is often summarized using poly-
nomial curves within individuals (Level 1) because they are very adaptable to a variety of diﬀ er-
ent growth trajectories and can be estimated using standard linear-modeling procedures (Hox, 
2010). Most common is a linear growth trend, which assumes that the rate of individual change 
is the same across each interval of time ( a ). However, it is not always the case that individuals 
are changing at the same rate over time. In some cases, adding higher order polynomials to the 
model for deﬁ ning the time-related trend can improve prediction. 
 Th e polynomial equation is not nonlinear; in fact, mathematically it is linear (Hox, 2010). If 
there are  k measurements, there is a  k ‒ 1 polynomial that can be used to ﬁ t the model. A qua-
dratic trend is interpreted as a change in the rate of change (i.e., accelerating or decelerating) 
over an interval of time ( a 2 ). A cubic trend ( a 3 ) is  S -shaped, which describes changes in the rate 
of change over time such as accelerating, decelerating, and accelerating again. For example, for 
three measurement occasions, the highest degree term is  a 2 (quadratic), while for four measure-
ment occasions, the highest degree term is cubic, or one less than the number of measurement 
occasions ( k ‒ 1). Of course, we might prefer to interpret the results of a linear growth model 
for ease of interpretation, but sometimes a higher order polynomial may describe the data more 
accurately. Generally, we only include up to the highest signiﬁ cant polynomial in the model. 
In terms of actually describing the change over time, it becomes increasingly more diﬃ  cult to 
interpret models of higher polynomial degrees. Th ere also may be cases where developmental 

170  Examining Individual Change with Repeated Measures Data
processes cannot be well approximated by using a polynomial function. For example, the logistic 
curve (which cannot be transformed to a linear model) may be better in approximating a process 
that is slower in the beginning of the trend, speeds up in the middle, and then slows at the end 
(representing an  S curve). In other cases, however, a logistic or exponential function may be well 
approximated by using a cubic polynomial if there are at least four measurements (Hox, 2010). 
 It is important to note that the parameters of a higher order polynomial model (e.g., cubic) 
have no direct interpretation in the growth process over any particular interval, such that inter-
pretation must be made by looking at average plots of the growth or some more typical individual 
growth curves (Hox, 2010). To illustrate this point, in   Figure 5.1  we have plotted the actual 
growth in an academic outcome  Y (solid line) over four intervals against what the growth might 
look like if it were strictly linear, quadratic, or cubic (dotted lines). At the bottom of the ﬁ gure, 
we can observe that linear growth rises (or declines) constantly over time. In contrast, quadratic 
growth tends to rise more quickly (or decline) relative to the constant rate of growth represented 
in the linear trajectory. We can also notice that the cubic growth curve increases much more 
rapidly over the four time periods compared to linear or quadratic growth curves. Th e actual 
growth trajectory plotted in the ﬁ gure for  Y appears to have elements of linear, quadratic, and 
cubic growth. It appears to change linearly between intervals 1 and 2, to slow between intervals 
2 and 3 (quadratic trajectory), and then to accelerate more rapidly between intervals 3 and 4 
than between intervals 1 and 2. Th e cubic polynomial actually combines the eﬀ ects of four coef-
ﬁ cients (i.e., linear, quadratic, and cubic slope coeﬃ  cients, and the intercept). Diﬀ erent values 
of each coeﬃ  cient will move the average trajectory up or down with respect to the horizontal 
axis (i.e., changing the intercept) and alter the steepness of the cubic curve (changing the cubic 
coeﬃ  cient), its slope (changing the linear component), or the curvature of the parabolic element 
(changing the quadratic coeﬃ  cient). As we reiterate, when a cubic element is present in a trajec-
tory, it suggests a focus on the whole growth trend and not just any particular interval. 
 Th ird, after settling on a reasonable growth trajectory to describe individual development, 
we can consider possible between-subjects variables that might aﬀ ect individuals’ growth tra-
jectories. A third hypothesis often tested in a RMD is a test of parallelism (Raykov & Marcou-
lides, 2008); that is, are the trajectories the same for diﬀ erent levels of a factor (e.g., subjects in 
treatment or control groups)? In repeated measures multilevel designs, it is also important to 
distinguish within-subjects (Level 1) variables, which change over time, from between-subjects 
(Level 2) variables, which are considered to be static over the temporal period of the study. For 
 FIGURE 5.1  Examining several diﬀ erent individual growth curves. 

Examining Individual Change with Repeated Measures Data  171
example, we can enter motivation as a time-varying covariate at Level 1 that predicts changes in 
reading scores. In contrast, we could also enter motivation as a between-subjects covariate (i.e., 
continuous predictor), in which case it would be considered as static over the temporal period 
of the study. Covariates, which are continuous variables that might aﬀ ect the rate of growth, can 
also be added to the model. When covariates are added, the means for each occasion are adjusted 
for the presence of the covariates. 
 An Example Study 
 Consider study where we wish to examine students’ growth trajectories in math achievement 
over time (a within-subjects factor with three levels) and to assess whether their socioeconomic 
status (SES) background (a between-subjects covariate) and perceptions about their math teach-
er’s eﬀ ectiveness (a between-subjects factor) are related to diﬀ erent achievement growth patterns. 
 Research Questions 
 We may be interested ﬁ rst in whether a change takes place in student math achievement over 
time. Th is type of question addresses whether the levels of the means for the outcome are the 
same or diﬀ erent over the occasions of measurement. Th e assumption is that if we can reject the 
null hypothesis of no diﬀ erence in means across measurement occasions, it implies that a change 
in individuals has taken place. A second question concerns what the shape of the developmental 
change might look like for individuals in the study. For example, we might ask whether the rate 
of individual change per occasion is linear or whether the change might be more complex. Once 
we have described the shape of individuals’ change trajectories over time, we might ask a third 
question: Are there diﬀ erences in development between groups of individuals? Th ese diﬀ erences 
might be due to an experimental treatment or other types of factors (e.g., background). In this 
case, we examine whether student growth is related to their individual perceptions about the 
teaching skill of their teachers. We might also wish to adjust our estimates for the presence of 
covariates that might aﬀ ect individuals’ development over time. In this example, we use students’ 
SES as a covariate. 
 The Data 
 Th e data used for this study consist of 8,670 secondary students. We will assume that they have 
been randomly sampled from a larger population of students. Th e variables used in the example 
are summarized in  Table 5.1 . 
TABLE 5.1 Data Deﬁ nition of ch5growthdata-vertical.sav (N = 8,670)
Variable
Levela
Description
Values
Measurement1
id
Individual
Individual student identiﬁ er (8,670 students) across 
three time (test) occasions. 
Integer
Ordinal
nschcode
School
School identiﬁ er (515 schools).
Integer
Ordinal
Rid
Individual
A within-group level identiﬁ erb representing a 
sequential identiﬁ er for each student within each 
school.
1 to 46
Ordinal
Index1
Within 
Individual
Identiﬁ er variable resulting from indexing the math 
outcomes to create a new identiﬁ er with a number 
sequence (1, 2, 3) corresponding to the three time 
occasions measuring students‘ math achievement.
1 = First Time
2 = Second Time
3 = Third Time 
Scale
(Continued)

172  Examining Individual Change with Repeated Measures Data
TABLE 5.1 (Continued)
Variable
Levela
Description
Values
Measurement1
time
Within 
Individual
Variable representing three linear occasions in time 
measuring students math achievement.
0 = First Time
1 = Second Time
2 = Third Time 
Scale
quadtime
Within 
Individual
Recoded time variable from three occasions in 
time (0, 1, 2) into a “squared” quadratic sequence 
(0, 1, 4) to capture any changes (acceleration or 
deceleration) in the rate of change that might occur 
over the three measurement occasions. 
0 = First Time
1 = Second Time
4 = Third Time 
Scale
orthtime
Within 
Individual
Recoded time variable from three occasions in 
time (0, 1, 2) into an orthogonal linear (–1, 0, 1) 
sequence.
–1 = First Time
    0 = Second Time
    1 = Third Time 
Scale
orthquad
Within 
Individual
Recoded time variable from three occasions in time 
(0, 1, 2) into an orthogonal quadratic (1, –2, 1) 
sequence.
    1 = First Time 
–2 = Second Time 
    1 = Third Time
Scale
test
Within 
Individual
The dependent variable representing each 
students‘ individual scores on the repeated math 
measurements.
24.35 to 99.99
Scale
effective
Individual
Two-category predictor variable representing 
teachers‘ effectiveness in teaching math.
0 = Not Effective
1 = Effective
Nominal
ses
Individual
Predictor interval variable (z score) measuring student 
socioeconomic status composition within the schools.
–2.41 to 1.87
Scale
timenonlin1 Within 
Individual
Recoded time variable from three occasions in 
time (0, 1, 2) into a time sequence variation that 
encompasses the whole 3-year period of time (0.00, 
0.50, 1.00) measured from 0 to 1.
0.00 = First Time
0.50 = Second Time
1.00 = Third Time
Scale
timenonlin2 Within 
Individual
Recoded time variable from three occasions in time 
(0, 1, 2) into a time sequence variation representing 
the whole 3-year period of time (0.00, 0.60, 1.00) 
measured from 0 to 1.
0.00 = First Time
0.60 = Second Time
1.00 = Third Time 
Scale
timenonlin3 Within 
Individual
Recoded time variable from three occasions in time 
(0, 1, 2) into a time sequence variation representing 
the whole 3-year period of time (0.00, 0.70, 1.00) 
measured from 0 to 1.
0.00 = First Time
0.70 = Second Time
1.00 = Third Time 
Scale
timenonlin
Within 
Individual
Recoded time variable from three occasions in time 
(0, 1, 2) into a time sequence variation representing 
the whole 3-year period of time (0.00, 0.53, 1.00) 
measured from 0 to 1.
0.00 = First Time
0.53 = Second Time
1.00 = Third Time 
Scale
a Individual = Level 1; school = Level 2; Within Individual = repeated measures, Level 1; Individual = Level 2; School = 
Level 3. 
 b Results from ranking student cases ( id  ) with the school group identiﬁ er ( nschcode ). 
1 Measurement icon settings displayed in subsequent model screenshots may differ from Table 5.1 but will not affect 
the output.
 Using a random-coeﬃ  cients approach to investigate individual change provides considerably 
more ﬂ exibility than either the univariate ANOVA approach or the multivariate approach, espe-
cially in situations where there may be missing data, varying occasions of measurement, and more 
complex error structures. It is generally useful to spend some time examining the nature of the 
data initially. To examine individual change using MIXED, the data must ﬁ rst be organized dif-
ferently. As we noted in Chapter 2, the time-related variable describing the shape of the growth 
trajectory (e.g., linear or quadratic) is entered into the data set as a variable, with the successive 
math measurements structured vertically or stacked (i.e., instead of as a horizontal, multivariate 

Examining Individual Change with Repeated Measures Data  173
set of variables as in MANOVA or SEM) for each subject within the data set ( y 1 i  ,  y 2 i  , …,  y t i  )'. As 
this suggests, the number of lines for each individual is deﬁ ned by the number of measurement 
occasions. In this case, therefore, we will have 8,670 × 3, or 26,010 lines, in the database. We can 
use DATA and RESTRUCTURE menu commands to restructure the data vertically.   Figure 5.2  
presents data on three subjects in a hypothetical data set. 
 Closer inspection of the data suggests that there are three observations per individual on 
the math “test” outcome, and individual and school identiﬁ ers, as well as any predictors (e.g., 
perceived teacher eﬀ ectiveness), are repeated in the data set for each time interval. Th e outcome 
( test ) represents each individual’s scores on the repeated math measurements. We can also see 
that the repeated observations of  test are nested within individual identiﬁ cation ( id ) numbers, 
and student IDs are nested within school identiﬁ ers ( schcode ). Th e grouping variables ( id ,  schcode ) 
are used to identify each predictor as belonging to a particular level of the data hierarchy. As we 
noted, often a polynomial function will describe individual growth pretty well. As   Figure 5.2  
also indicates, the time-related variables (linear and quadratic) are also entered as data. Most 
often, researchers assume that individuals are changing at a constant rate over time, which can 
be represented as linear growth, especially over a short period of time, but it may also be the case 
that subjects are experiencing more complex patterns of growth over time. Since there are three 
occasions, we can also enter a quadratic component to test for the presence of a change in the 
rate of growth occurring over time. 
 Examining the Shape of Students’ Growth Trajectories 
 We will begin by examining descriptive statistics showing the level of the outcome means on 
each occasion, as summarized in   Table 5.2  . Th e table suggests that the average math achievement 
for the ﬁ rst occasion is 48.632, while for the last occasion it is 57.094, indicating considerable 
change over time. Th e table suggests that the grand mean is 52.945, which falls somewhere be-
tween the ﬁ rst and second measurement occasions. Th e grand mean is often not of much interest 
in examining growth since it just represents the average achievement level across the three mea-
surement occasions. Examining the means more closely, one can see that the change between the 
ﬁ rst two test means is about 4.5 points, while between the second two means it is about 4.0. Th is 
 FIGURE 5.2  Vertical data matrix for repeated measures analysis in IBM SPSS. 

174  Examining Individual Change with Repeated Measures Data
suggests slightly less growth during the latter part of the trend compared with the initial part. 
Th e diﬀ erences in observed means summarized in   Table 5.2  suggest that they probably are not 
the same over time (hypothesis 1). 
 Visual inspection of the data can provide important preliminary clues about the shape of 
change in math that is taking place among individuals over time.   Figure 5.3  provides a plot of 
the linear growth trajectories of the ﬁ rst 17 subjects in the data set. Th e plot of these individuals’ 
scores over time suggests that individuals are increasing in their knowledge. Readers will note 
that the intercepts (i.e., individuals’ status at Time 0) appear to vary considerably (i.e., from 
about 32 to 55) and the steepness of the growth over time also seems to vary within this subset 
of individuals. Many times, with a few waves of data, a linear model will be adequate to describe 
individuals’ growth. Notice, however, in the graph of these individuals’ growth, the linear model 
does not seem to capture the change over time of all individuals equally well; that is, not all of 
the individuals’ observed scores fall on their predicted growth lines. 
 FIGURE 5.3  Individual linear math growth trajectories. 
 TABLE 5.2 Means for Each Measurement Occasion 
Test
Mean
Std. Deviation
Std. Error
95% Conﬁ dence Interval for Mean
Lower Bound
Upper Bound
0
48.632
9.713
0.104
48.428
48.837
1
53.107
9.888
0.106
52.899
53.316
2
57.094
9.894
0.106
56.886
57.303
Total
52.945
10.421
0.065
52.818
53.071

Examining Individual Change with Repeated Measures Data  175
 FIGURE 5.4  Individual nonlinear math growth trajectories. 
 For purposes of contrast,   Figure 5.4  is a graph of the same 17 subjects, this time using a 
quadratic trajectory. With three time points, one can observe that the ﬁ t of the curved lines to 
the data points will be perfect. For some individuals, the plot of their trajectories in the ﬁ gure 
suggests that a linear shape might be adequate to describe the growth. For others, however, it 
appears that their growth might be better described by a curvilinear trajectory. Th ese plots show 
visually our preliminary interest in determining whether a linear shape, or both linear and qua-
dratic components, would be required to describe the shape of individuals’ growth trajectories 
accurately. 
 Graphing the Linear and Nonlinear Growth Trajectories with IBM SPSS Menu Commands 
 We can use the IBM SPSS menu commands to display the information for the subset of indi-
viduals in the study, as shown in   Figures 5.2 ,   5.3 , and  5.4 in the following series of instructions. 

176  Examining Individual Change with Repeated Measures Data
 
 2a. Within the  Se-
lect Cases dialog 
box, click to 
select  If condi-
tion is satisﬁ ed . 
 
 b. Th en click the 
IF button, which 
will activate the 
 Select Cases: If 
box. 
 
 c. Click the vari-
able  id from 
the left column 
listing, and then 
click the right-
arrow button to 
move  id into the 
box. 
 Use the keypad to enter 
the less than sign () 
followed by the number 
18. Th e resulting com-
mand ( id  18 ) instructs 
IBM SPSS to select 
only the ﬁ rst 17 cases of the data set. 
 Click the CONTINUE button to return to the  Select Cases dialog box. 
 Select Subset of Individuals 
 Launch the IBM SPSS 
application and select the 
 ch5growthdata-vertical.sav 
data ﬁ le. 
 We will begin by selecting the 
subset of individuals. 
  1. Go to the toolbar and 
select DATA, SELECT 
CASES. 
 Th is command will open the 
 Select Cases dialog box. 

Examining Individual Change with Repeated Measures Data  177
  3. Notice that the IF condition state-
ment  id  18 is listed. 
 Click the OK button to return to the main 
menu. 
  4. To graph the 17 
cases, go to the 
toolbar and select 
GRAPHS, LEG-
ACY DIALOGS, 
SCATTER/DOT. 
  5. Click on the SIMPLE SCATTER icon to select 
this option among those shown. 
 Click DEFINE button to open the  Simple Scatterplot 
dialog box. 

178  Examining Individual Change with Repeated Measures Data
 
 6a. Within the  Simple Scatterplot 
dialog box click to select the 
variable  test from the left 
column listing. Th en click the 
right-arrow to move the vari-
able into the  Y Axis box. 
 
 b. Click to select  time from the 
left column listing, and then 
click the right-arrow button 
to move the variable into the 
 X Axis box. 
 
 c. Click to select  id from the 
left column listing, and then 
click the right-arrow button 
to move the variable into the 
 Set Markers by box. 
 Th en click the OK button to gener-
ate the scatterplot. 
 Generate  Figure 5.3 (Linear 
Trajectory) 
 
 7a. Double-click on the graph 
in the output to select 
it and activate the  IBM 
SPSS Chart Editor. 
 
 b. In the  Chart Editor , click 
on the icon ADD FIT 
LINE OF SUBGROUPS, 
which will insert lines on 
the graph. 
 
 c. Clicking the  Add Fit Line 
of Subgroups icon also ac-
tivates the  Properties box, 
which provides assorted 
options. 

Examining Individual Change with Repeated Measures Data  179
 
 8a. IBM SPSS default 
settings insert 0.5 
increments to the 
 X axis representing 
time. To change the 
increment, double-
click the number to 
access the  Properties 
dialog box. 
 
 b. In Properties box, 
the  Scale  tab displays 
the  Range options 
for changing the 
increments. 
 
 c. Change the  Major 
Increment by un-
checking the box and 
then replacing  0.5 
with  1 . 
 
 d. Click the APPLY 
button to make the 
change and activate 
the  Close button. 
 
 e. Click the CLOSE 
button to exit from 
the  Properties box. 

180  Examining Individual Change with Repeated Measures Data
 Generate  Figure 5.4 (Nonlinear 
Quadratic Trajectory) 
 
 9a. To display the 17 subjects 
using a quadratic trajectory 
as shown in   Figure 5.4 , 
double-click the graph to 
select the graph’s ﬁ t lines, 
which will also open the 
 Properties box. 
 
 b. In the  Properties box, click 
to select  Quadratic . 
 
 c. Click the APPLY button 
to make the change and 
activate the Close button. 
 
 d. Click the CLOSE button 
to exit from the  Properties 
box. 
 10. Th e  Chart Editor displays the graph’s 
quadratic trajectory. 
 Graph labels for the  Y and  X axes may be 
changed by clicking and typing the pre-
ferred name. 
 Close the  Chart Editor box, and return to 
the IBM SPSS output document by either 
clicking the “x” located in the upper-right-
hand corner or by selecting FILE, CLOSE 
or CTRL+F4. 

Examining Individual Change with Repeated Measures Data  181
 Coding the Time-Related Variables 
 Th ere are various ways that the time-related within-subjects factor may be coded in deﬁ ning pos-
sible individual changes over time. Careful thought should be given to coding the time variable, 
as it can aﬀ ect the interpretation of the model’s parameters (Hox, 2010). We ﬁ rst illustrate the 
polynomial approach for describing individual growth in math. Where there are three repeated 
measures, the linear time variable ( time ) is most often coded 0 for year 1, 1 for year 2, and 2 for 
year 3 (0, 1, 2). Th is coding pattern is useful because it identiﬁ es the intercept as students’  initial 
( year 1 ) math achievement level. Th is approach is often preferred since the intercept can be inter-
preted as the mean when the predictors in a model are all zero (0). For linear growth, the slope 
would then be deﬁ ned as the change occurring between each interval (i.e., between 0 and 1 and 
between 1 and 2). We can also deﬁ ne a quadratic component ( quadtime ) to capture any changes 
(acceleration or deceleration) in the rate of change that might occur over the three measurement 
occasions. We simply “square” the  time  intervals; therefore,  quadtime  is correspondingly coded 0, 
1, and 4. If instead we wished to deﬁ ne the intercept as students’ ending math achievement status 
(year 3), we could instead code the linear variable ‒2, ‒1, 0, and the quadratic variable would then 
be ‒4, ‒1, 0. In some situations, we might wish to code the time-related variables such that the 
second measurement (i.e., year 2) represents the intercept. 
 We can see in   Figure 5.5  that the shape of the “average” growth trend is not quite linear. Th e 
average trend suggests a slight slowing of the growth rate between the second and third intervals. 
Th is suggests that a trajectory with both linear and quadratic components may be necessary to 
deﬁ ne student growth optimally (hypothesis 2). 
 FIGURE 5.5  Curvilinear average math growth trend. 

182  Examining Individual Change with Repeated Measures Data
 Coding Time Interval Variables (  time to  quadtime ) with IBM SPSS Menu Commands 
 Note: Continue using 
 ch5growthdata-vertical.sav . If 
continuing from the prior set 
of graphing instructions (  Fig-
ures 5.2 ,  5.3 , and  5.4 ), remove 
the  Select Cases conditional set-
ting before proceeding, as the 
following models will use all 
cases in the data set. To clear 
the ﬁ lter, go to the toolbar, se-
lect DATA, SELECT CASES, 
RESET, OK. 
  1. Go to the toolbar and 
select TRANSFORM, 
RECODE INTO DIF-
FERENT VARIABLES. 
 Th is command will open the 
 Recode into Diﬀ erent Variables 
dialog box. 
 
 2a. Th e  Recode into 
Diﬀ erent Variables 
enables creating a 
new variable using 
a variable from 
the current data 
set. First, click to 
select  time from 
the left column, 
and then click the 
right-arrow button 
to move the vari-
able into the  Input 
Variable  Output 
Variable box. 
 
 b. Now enter the new 
variable name by 
typing  quadtime into the  Output Variable Name box. 
 
 c. Th en click the CHANGE button, which will add  quadtime  and complete the RECODE com-
mand for  time  quadtime . 
 Note: A warning message appears as  quadtime is an existing variable in the data set. 
 
 d. Click OK to continue, which will overwrite the preexisting  quadtime  variable. If you prefer not 
to overwrite the original variable, rename the output variable (e.g.,  quadtime1 ). 
 
 e. Click the OLD AND NEW VALUES button, which will then display the  Recode into Diﬀ erent 
Variables: Old and New Values screen. 

Examining Individual Change with Repeated Measures Data  183
  3. Within the  Recode into 
Diﬀ erent Variables: Old and 
New Values , we will begin 
changing the  time values 
(0, 1, 2) to reﬂ ect  quadtime 
(0, 1, 4). 
 
 a. Begin by entering the 
ﬁ rst value for  time ( 0 ) in 
the  Value (old) box. 
 
 b. Next, enter the new 
value ( 0 ) for  quadtime in 
the  Value (new) box. 
 
 c. Click the button to 
place the ﬁ rst command 
 0  0 into the  Old  
New box. 
 
 d. Repeat steps 3a to 3c to 
complete the remaining 
coding changes for  quadtime values: 
 
   1  1 
 
   2  4 
 Click the CONTINUE button to return to the  Recode into Diﬀ erent Variables main dialog box. 
 Click the OK button to generate the recoded variable  quadtime  and corresponding time values (0, 1, 4). 
 One disadvantage of using polynomial functions in deﬁ ning growth trajectories, however, is 
that there are strong correlations between the components comprising the function (e.g., linear, 
quadratic, and cubic). Th is occurs because the components of the polynomial function must be 
deﬁ ned as data for each individual within the data set. As we previously described, with three 
repeated measures, the linear component would be deﬁ ned as 0, 1, 2 and the quadratic compo-
nent would be deﬁ ned as 0, 1, 4. One can see these two components required for deﬁ ning a cur-
vilinear trajectory will be highly correlated for the individuals in the study. In fact, for the linear 
and quadratic contrasts the correlation is 0.958. Readers familiar with multiple regression will 
recognize that this type of strong correlation can potentially cause problems in estimating the 
model parameters optimally. 
 If the occasions are equally spaced, as in our example, and there is little or no missing data, one 
approach for dealing with multicollinearity is to transform the polynomials to be orthogonal, or 
uncorrelated (Hox, 2010). Polynomials can be transformed to be orthogonal by recoding using 
available tables for deﬁ ning orthogonal contrasts. Recoding helps simplify calculations and inter-
pretations involved in polynomial regression. Because of the way the orthogonal polynomials are 
deﬁ ned, the intercept for the transformed model (coded 0) will be centered near the middle of 
the growth sequence (i.e., representing the grand mean instead of initial status). Readers can con-
sult a table of orthogonal polynomials for other numbers of repeated measures (e.g., Guilford & 
Frunchter, 1978). Although not required, we can then standardize the orthogonal estimates so 
that they will be on the same scale of measurement (Hox, 2010). As Hox suggests, even in 
data situations where the repeated measurements may not be exactly spaced, using orthogonal 
polynomials will tend to reduce any potential multicollinearity problem. Of course, in situations 
where the higher order polynomial components are not needed, it would not be necessary to use 
orthogonal transformation. 

184  Examining Individual Change with Repeated Measures Data
TABLE 5.3 Orthogonal Coding for Three and Four 
Measurement Occasions for Equally Spaced Intervals
Model Description
k–1 = 2
k–1 = 3
Linear
–1, 0, 1
 –3, –1, 1, 3
Quadratic
1, –2, 1
1, –1, –1, 1
Cubic
–1, 3, –3, 1
 We summarize orthogonal coding for three and four repeated measures in   Table 5.3  . For 
three repeated measures, we can simply use RECODE to transform the linear tread (0, 1, 2) to 
the orthogonal coding (–1, 0, 1), as illustrated in   Table 5.3  . Th is simple transformation creates 
a grand-mean centering. Centering at the midpoint will minimize the correlation between the 
time-related variables, which tends to stabilize the model estimation procedure (Raudenbush & 
Bryk, 2002). Th e quadratic component is then recoded from 0, 1, 4 to 1, ‒2, 1. As Raudenbush 
and Bryk indicate, for higher order polynomials, the highest order coeﬃ  cient will have an invari-
ant interpretation, while the lower order coeﬃ  cients will have meanings that depend on the cen-
tering strategy employed. We reiterate that in deﬁ ning the growth trajectory using higher order 
polynomials, we typically only include up to the highest signiﬁ cant component. 
 Coding Time Interval Variables (  time to  orthtime ,  orthquad  ) with IBM SPSS Menu Commands 
 Continue using the  ch5growthdata-vertical.sav data. 
  1. Go to the toolbar and 
select TRANSFORM, 
RECODE INTO DIF-
FERENT VARIABLES. 
 Th is command will open the 
 Recode into Diﬀ erent Variables 
dialog box. 
 Note: If continuing from 
performing the prior coding 
example ( time to  quadtime ), 
click the RESET button 
before proceeding to clear the 
default settings. 

Examining Individual Change with Repeated Measures Data  185
 
 2a. Th e  Recode into Diﬀ erent 
Variables screen enables 
creating a new variable 
using a variable from 
the current data set. 
First, click to select  time 
from the left column, 
and then click the right-
arrow button to move 
the variable into the 
 Input Variable  Output 
Variable box. 
 
 b. Now enter the new 
variable name by typing 
 orthtime into the  Output 
Variable ,  Name box. 
 
 c. Th en click the CHANGE button, which will add  orthtime and complete the RECODE com-
mand for  time  orthtime . 
 Note: A warning message appears as  orthtime is an existing variable in the data set. 
 
 d. Click OK to continue, which will overwrite the preexisting  orthtime variable. If you prefer not 
to overwrite the original variable, rename the output variable (e.g.,  orthtime1 ). 
 
 e. Click the OLD AND NEW VALUES button, which will then display the  Recode into Diﬀ erent 
Variables: Old and New Values screen. 
  3. Within the  Recode into Diﬀ erent 
Variables: Old and New Values , we 
will begin changing the  time values 
(0, 1, 2) to reﬂ ect  orthtime (–1, 0, 1). 
 
 a. Begin by entering the ﬁ rst value 
for  time ( 0 ) in the  Value (old) box. 
 
 b. Next, enter the new value ( -1 ) for 
 orthtime in the  Value (new) box. 
 
 c. Click the button to place the ﬁ rst 
command  0  -1 into the  Old  
New box. 
 
 d. Repeat steps 3a to 3c to complete 
the remaining coding changes for 
 orthtime values: 
 
  1  0 
 
   2  1 
 Click the CONTINUE button to return to the  Recode into Diﬀ erent Variables main dialog box. 
 Click the OK button to generate the recoded variable  orthtime and corresponding time values (–1, 0, 1). 
 Note: To generate  orthquad  (coded 1, ‒2, 1), repeat all steps but rename the output variable ( orthquad ) 
and code the  Old  New values as follows: 
 0  1 
 1  –2 
 2  1 

186  Examining Individual Change with Repeated Measures Data
 A second approach, which we illustrate later in the chapter, is to code the time-related vari-
able in a way that represents the growth taking place over the whole trend, rather than over a 
speciﬁ c interval. Th is is referred to as a level-and-shape model in the SEM literature on LCA 
(e.g., McArdle & Anderson, 1990; Raykov & Marcoulides, 2006). In the LCA approach, it is 
possible to estimate more general types of change, where maximum likelihood (ML) estimation 
is used to provide estimates of some of the factor loadings, which deﬁ ne the shape (or growth) 
factor (McArdle, 1988; Meredith & Tisak, 1990). One of the advantages of the latent variable 
approach to modeling change is that it permits development in the repeated measures variable 
to occur in any fashion (e.g., growth followed by decline followed by growth). Importantly, this 
makes it generally easier to ﬁ t empirical data than many other models where growth is assumed 
to follow a particular function (Raykov & Marcoulides, 2006). Although it is not possible to 
provide all of these possibilities using a mixed model approach, since the repeated measures must 
be speciﬁ ed as series of data points occurring within the speciﬁ c temporal period of the study, 
there is one often used SEM speciﬁ cation that can be adapted. More speciﬁ cally, since the slope 
is interpreted as the change in  Y for a unit change in  X , if we code the ﬁ rst measurement occa-
sion as 0 and the last measurement occasion as 1, we can then describe the slope as the change 
in  Y occurring over the entire trend for a unit change in  X . We then use the middle measures to 
estimate the general  shape of the trend in between these two endpoints. 
 If we obtain a graph of the average growth trajectory for the sample or several representative 
individual trajectories, we can often experiment a little to ﬁ nd an appropriate coeﬃ  cient for the 
middle measurement occasion (or occasions). For example, we might start by coding the middle 
measurement in our example (year 2) as 0.5 if the trend is assumed to be linear, or some other 
value (e.g., 0.7) if a nonlinear trend is hypothesized. Th is strategy can of course be adjusted if 
there are several repeated measures to be speciﬁ ed between the ﬁ rst and last measurement. We 
can save predicted values from the estimated model using various coding schemes and generate 
a new graph to see which coding scheme seems to best capture the actual shape of the observed 
data. We can also examine various model ﬁ t indices to determine which coding approach (or 
implied hypothesis about the general shape of the growth) may capture the individual growth 
trajectories most accurately. As Raykov and Marcoulides (2008) caution, the downside of this ap-
proach is that in some instances one may not be able to obtain a speciﬁ c quantitative description 
of the development occurring over the timeframe under consideration. 
 Various curved or  S -shaped polynomial growth trajectories create additional challenges in 
terms of interpretation and model building. It is also possible to treat the time variable as cat-
egorical and model each occasion separately either by using a reference occasion or by eliminat-
ing the intercept in the model so that each occasion can be modeled separately (see Hox, 2010, 
for further discussion). We emphasize that this type of examination of the time-related variable 
is typically conducted preliminarily before settling on a ﬁ nal set of coeﬃ  cients that describe indi-
vidual growth and then investigating a subsequent set of predictors that might explain variability 
in individuals’ growth trajectories. Th e important point is that various ways of deﬁ ning individu-
als’ growth trajectories (e.g., alternative ways of coding the time-related variable) may result in 
somewhat diﬀ erent estimates of individual growth, owing to the underlying assumptions of each 
type of statistical model. 
 Specifying the Two-Level Model of Individual Change 
 After setting up the data set appropriately and considering possible ways to code the time-
related variables, we are ready to build a series of models. At Level 1, each person’s successive 
measurements over time are deﬁ ned by an individual growth trajectory and random error. At 
Level 2, diﬀ erences in trajectories between groups of individuals can be examined. Following 
Raudenbush and Bryk’s (2002) notation, we will use two subscripts to describe individuals ( i ) 
and occasions of measurement ( t ). We assume the observed status,  Y ti  , at time  t for individual  i is 

Examining Individual Change with Repeated Measures Data  187
a function of a systematic growth trajectory plus random error. At Level 1, the systematic growth 
for each individual in reading can be represented as a polynomial of degree  P for  k ‒  1 repeated 
measures. In this example, with three measurements, the highest polynomial will then be 2 (3 ‒ 1 
= 2), or quadratic, with the Level 1 model at time  t for individual  i written as 
2
0
2
ti
i
i
ti
i
ti
ti
0
1
2
1
Y
a
a
ti
	
i
i
ti
i
ti
i
i
ti
i
ti
0
1
2
1
i
i
ti
i
0
1
2
1

2
a
a
a
2
ti
a
a
a
0
1
2
1
i
i
ti
i
0
1
2
1
 
(5.1) 
 where  a ti  and  a 2  ti  are time-varying variables of interest (e.g., which are coded to indicate the linear 
and quadratic components hypothesized to describe the shape of the trajectories);  π 0 i  is an in-
tercept;  π 1 i  and  π 2 i  describe the linear and quadratic growth rates, respectively; and   ti  represents 
variation in estimating growth within individuals. We note that in specifying a growth model, 
we often use the Greek letter pi to represent the Level 1 coeﬃ  cients, so that we can maintain 
the typical beta coeﬃ  cients to describe between-individual relationships and gamma coeﬃ  cients 
to describe between-group relationships. Because we have coded the ﬁ rst repeated measure as 0, 
the intercept parameter (i.e., the point where the trajectory crosses the  Y axis) is interpreted as 
the child’s true score at initial status (or the beginning) of the study. As Singer and Willet (2003) 
note, the Level 1 model assumes that all the individual change trajectories have the same alge-
braic form in Equation 5.1, but not every individual has exactly the same trajectory. 
 Th e slope parameters ( π 1 i  and  π 2 i  ) represent the predicted change in individuals over a speciﬁ ed 
time interval. Th e linear component describes the rate of change per unit of time. A quadratic 
component can be interpreted as a “change” in the rate of change (e.g., accelerating or decelerat-
ing). As shown in   Figure 5.5  , the linear component of the time-related variable ( a ) is coded 0, 1, 2 
in the data set (referred to as “ time ”), which ensures that the intercept is interpreted as students’ 
true initial status (i.e., their corrected achievement level at Time 1). We can also add a quadratic 
component to the model to test for a change in the rate of growth over time. Th is component 
is also coded as a variable ( quadtime ). Th e interval values for the variable can be generated using 
COMPUTE and multiplying the time variable by itself ( time*time ). 
 If this coding scheme is used, the linear component ( π 1 i  ) represents the yearly growth rate 
for each child in the study. Th e quadratic component ( π 2 i  ) represents any increase or decrease in 
the rate of change for each time interval. Alternatively, the time-related variable might also be 
conceptualized as students’ age in months at the time of each measurement. Th e intercept and 
slope coeﬃ  cients represent the model’s  structural , or ﬁ xed, eﬀ ects. As mentioned previously, we 
have also created orthogonal polynomials in our example data in order to remove the sizable 
correlation between the linear and quadratic components of individuals’ growth trajectories. We 
have added these orthogonal linear and quadratic components into the data set as  orthtime and 
orthquad , respectively. 
 We can also specify one or more  time-varying  covariates ( X t  ) at Level 1. Time-varying co-
variates (i.e., predictors that also change over repeated measurement occasions) provide a way 
of accounting for temporal variation that may increase (or decrease) the value of an outcome 
predicted by the individual’s growth trajectory (Raudenbush & Bryk, 2002). For example, we 
could consider a situation where a variable like motivation, which changes over time, might also 
aﬀ ect students’ learning in math or reading. Alternatively, we could also consider motivation as 
a static variable (i.e., individuals’ average motivation level), which requires only one value for the 
covariate. In this latter case, we would then enter the covariate at the between-subjects level (i.e., 
Level 2). One of the advantages of the time-varying formulation at Level 1, however, is that the 
eﬀ ect of motivation level on student achievement can then be modeled as a random parameter 
at Level 2. 

188  Examining Individual Change with Repeated Measures Data
 Level 1 Covariance Structure 
 Th e other part of the Level 1 model is the  stochastic  part, or the part that describes the variation 
in measuring each individual  i on occasion  t . Th is part of the model implies that there is some 
error (  ti  ) associated with measuring each individual’s true growth trajectory. Th e errors are  un-
observed , which means that we must make some assumptions about their distribution at Level 1 
(Singer & Willett, 2003). Often, a simple residual structure is assumed from occasion to occasion 
and person to person, with each error independently and normally distributed, a mean of 0, and 
constant variance: 
2
ti
	
	  
ti


2
	
 2  
(5.2) 
 where ~ means “distributed as,”  N refers to normal distribution, 0 refers to the mean, and  
2
0
2
ti
i
i
ti
i
ti
ti
0
1
2
1
Y
a
a
ti
	
i
i
ti
i
ti
0
1
2
i
i
ti
i
0
1
2
1

2
a
a
a
2
ti
a
a
a
0
1
2
1
i
i
ti
i
0
1
2
1
refers to the variance. One way to represent this simpliﬁ ed error structure is as a scaled identity 
matrix, which provides a single residual variance associated with measurement occasions. With 
longitudinal data, however, this type of simple Level 1 error structure may have less credibility 
(Singer & Willett, 2003). 
 Restrictions about the within-individual residuals over time can be relaxed. Th is is often nec-
essary because the error covariance matrix for the repeated measures typically will exhibit some 
correlation between occasions. For example, often the repeated measures will correlate more 
strongly when they are taken closer together and less strongly as the time interval increases. It is 
often useful to examine diﬀ erent error structures (e.g., compound symmetry, autocorrelated, or 
unstructured) in preliminary analyses, depending on the nature of the repeated measurements 
per subject. Th e ﬁ t of particular covariance structures to the data can then be compared to see 
which covariance structure provides the best overall choice. IBM SPSS provides a considerable 
number of choices for the Level 1 residual covariance matrix in a repeated measures model (a 
complete list of covariance structures can be obtained from the MIXED Commands in the IBM 
SPSS Help Menu). 
 Repeated Covariance Dialog Box 
 Th e Level 1 covariance matrix can be speciﬁ ed by opening the  Repeated Covariance  dialog box in 
the Commands menu (  Figure 5.6  ) or with a REPEATED syntax command. Th ere are actually 
a number of diﬀ erent uses for this dialog box, which we will brieﬂ y summarize. Th e ﬁ rst is the 
typical growth speciﬁ cation we have just described, where this is used to specify the individual 
variation around the repeated measures of  Y . A second use is when the focus is on deﬁ ning a 
multivariate model, for example, when we have several survey items used to deﬁ ne an underly-
ing (or latent) dependent variable such as job satisfaction. Th e individual items deﬁ ning the 
construct can be speciﬁ ed vertically for each individual in the data set using an  index variable 
and the  Repeated Covariance  dialog box used to describe variance and covariance relationships 
between the items, which is similar to representing repeated measures over time. We cover these 
multivariate situations in more detail in Chapter 7. A third use would be where the researcher 
has diﬀ erent amounts of data on an outcome for individuals at Level 1. For example, workers 
might be measured performing a series of work-related tasks. One individual might have one 
such measure of task performance, while others might have ﬁ ve or six (or even more) measures. 
Th is speciﬁ cation amounts to having multiple pieces of data nested within individuals at Level 1, 
but not incorporating a growth parameter in the sense that individuals are assumed to be chang-
ing in performance over time. In this case, the  Repeated Covariance dialog box is useful in or-
ganizing the diﬀ ering amounts of performance information regarding individuals in the study. 

Examining Individual Change with Repeated Measures Data  189
 FIGURE 5.6  Th e  Repeated Covariance Type  dialog box and available covariance structures. 
 We note that if the  Repeated Covariance  dialog box (or repeated syntax statement) is not used, 
the default Level 1 matrix will be a scaled identity covariance matrix. As Equation 5.3 indicates, 
the scaled identity matrix (abbreviated as ID in MIXED syntax) assumes a constant variance 
across occasions, where   2 is the variance, and no covariances between occasions. Th erefore, it has 
only one estimated parameter, as suggested in Equation 5.3. We note that because a covariance 
matrix is a square matrix, the same elements appear above and below the diagonals. Th is simpli-
ﬁ ed within-subject error structure may sometimes be suﬃ  cient for repeated measures studies 
of short duration, if the focus is not primarily on deﬁ ning the relationships between successive 
measurements: 
2



1
0
0


1
0
0




1
0
0


0
1
0






0
0
1






0
0
1




0
0
1






0
0
1
 
(5.3) 
 Specifying an identity covariance matrix for the repeated measures structure amounts to accept-
ing that Mauchly’s test for sphericity holds. 
 A special form of sphericity is  compound symmetry  (abbreviated CS) or uniformity (Hox, 2010). 
Conditions for compound symmetry are met if all the variances are equal in the population being 
sampled and all the covariances (the oﬀ -diagonal elements of the covariance matrix) are equal. 
Th is means there is one variance and one constant covariance in the Level 1 covariance matrix 
(or one more parameter to estimate than in Eq. 5.3). If the observed covariances are roughly 

190  Examining Individual Change with Repeated Measures Data
equal and the variances are similar too, we can generally assume that compound symmetry is 
not violated and, therefore, sphericity should not be a problem (Raykov & Marcoulides, 2008). 
It turns out that for a two-level model of repeated measures with random intercept only, the 
residual variance at any occasion can be deﬁ ned as  
2
ti
	
	  
ti


2
	
 2  (i.e., the sum of the occasion-level 
and person-level residual variances, respectively) in the diagonals of the matrix, and the covari-
ance between any two occasions (i.e., the oﬀ -diagonal elements) is  
2



1
0
0


1
0
0




1
0
0


0
1
0






0
0
1






0
0
1




0
0
1






0
0
1  . For this simple type of 
repeated measures model, the matrix of variances and covariances among occasions would then 
be deﬁ ned as follows: 


2
2




2
2


0
1
1
u
	




1







2
2
2
1


2


2
2






0
0
1
2
2
2
2
u
u0
	




1






2
2
2
2




2
2
2
2




2
2
2
2


0
0
0




0
0
0
u
u
u
0
0
	




 
(5.4) 
 Th is suggests that the typical linear trend two-level model with single residual term at the occa-
sion (Level 1) and person (Level 2) levels is the same as assuming compound symmetry in the 
univariate repeated measures ANOVA model (Hox, 2010; Raudenbush & Bryk, 2002). In fact, 
for a simple linear two-level model with random intercept only, specifying an ID covariance 
matrix at Level 1 (as in Eq. 5.3) and Level 2 (since there is one random eﬀ ect) will produce an 
identical model to specifying CS at Level 1 and ID at Level 2. 
 An alternative Level 1 structure assuming diﬀ erent variances across measurement occasions 
could also be summarized as a diagonal (DIAG) covariance matrix. Th is type of covariance ma-
trix assumes heterogeneous variances for each measurement occasion in the diagonals of the 
matrix and 0s for the oﬀ -diagonal elements, which indicates no covariances between occasions: 


2
0
0



1
0
0


0
0



2
0
0
2
2






2
2




2
0
0
2


2
0
0





2
0
0






3
0
0

 
(5.5) 
 Relative to the scaled identity or compound symmetry covariance matrices, however, the di-
agonal covariance matrix will have more parameters to estimate for the assumed heterogeneous 
variances. Th e limitation of this type of covariance structure is also that it assumes no relationship 
between measurement occasions (similar to the scaled identity matrix). 
 Often we ﬁ nd that the repeated measures structures for longitudinal data may have a complex 
covariance structure. Th is autoregressive error covariance matrix (AR1) assumes that the Level 
1 variance  


1


2


2
2


0
0
1
2
2
2
2
u
u0
	




1






2
2
2
2




2
2
2
2




2
2
2
2


0
0
0




0
0
0
u
u
u
0
0
	



 remains constant across occasions but facilitates specifying an autocorrelation 
coeﬃ  cient between occasions. Th e autocorrelation coeﬃ  cient rho (  ) represents the correlation 
between any two adjacent occasions, where |   | ≤ 1. It follows, then, that   2 represents the cor-
relation when there is a skip between occasions. Th is structure is useful when it is likely that the 
correlations become weaker as there is longer distance in time between them: 
 
 
2
	
 2
	


2
1




1

 
2
 1




1


1






2

 


1


2
1


2




2
1






1


 
(5.6) 

Examining Individual Change with Repeated Measures Data  191
 Th e autoregressive covariance structure diﬀ ers from compound symmetry, which assumes that 
the covariance between residuals is the same despite the time lag between them. One advantage 
of the autoregressive covariance structure is that it can be speciﬁ ed with only two estimated 
parameters (i.e., a variance parameter and the correlation parameter). Th is makes it a relatively 
simpliﬁ ed covariance structure, but one that does not assume that all covariances between occa-
sions are the same. We note that it is also possible to assume heterogeneity among the occasion 
variances; that is, the diagonal elements can be replaced with separate variance estimates in the 
autoregressive structure (abbreviated as ARH1). 
 In contrast to an autoregressive error structure, a completely  unstructured (UN) covariance 
matrix provides separate occasion variance estimates in the diagonals and separate covariances 
estimated for the oﬀ -diagonal elements: 
2



2


1
21
31



1
21
21









2
32



2
21
22






21
2
32
2




21
2
32
 21
22


2







2






31
32
3



31
32
32
 
(5.7) 
 Th is type of error structure, however, can become overly complex when the number of measure-
ment occasions increases beyond three or four. 
 A general goal is to identify a parsimonious covariance structure that will adequately describe 
the data, both at Level 1 and Level 2. In this example, we will ﬁ rst assume an identity Level 1 
covariance matrix within individuals to examine how much variance in the outcome lies within 
and between individuals. MIXED provides several ﬁ t indices (e.g., AIC and BIC) that can also 
be used to evaluate various combinations of ﬁ xed eﬀ ects and covariance structures. In simulation 
studies of growth curve modeling, the AIC has been noted to work well in selecting the true 
model, provided the sample size is not below 100 individuals (Liu, Rovine, & Molenaar, 2012). 
We discuss these indices later in this chapter. 
 More complex covariance structures can also make it more diﬃ  cult to arrive at a solution that 
converges (i.e., provides reasonable estimates for all proposed parameters). Often, it is necessary 
to exercise some type of compromise between the complexity of some covariance structures and 
the parsimony provided by others in arriving at solution that deﬁ nes model covariance structures 
adequately. We illustrate some of these diﬀ erences in Level 1 covariance matrices subsequently. 
As Hox (2010) notes, if the focus is primarily on the model’s ﬁ xed eﬀ ects, one can often assume a 
more simpliﬁ ed variance and covariance structure across occasions, as some misspeciﬁ cation in the 
random part of the model does not generally aﬀ ect the model’s ﬁ xed eﬀ ects (see also Verbeke & 
Lesaﬀ re, 1997). In some circumstances, however, diﬀ erent user choices regarding the error vari-
ance structure at Level 1 may aﬀ ect the outcome of tests for random eﬀ ects at higher levels. 
 Model 1.1: Model with No Predictors 
 Th ere is some diﬀ erence of opinion among researchers about what is the proper model to begin 
with in building a growth model. We can start with a “no-predictors” model if desired. However, 
when we calculate the intraclass correlation (within individuals = Level 1; between individuals = 
Level 2) we will only get a rough estimate since the within-individual variance may be diﬀ er-
ent at each measurement occasion. Moreover, this initial estimate of the variance components 
may not be very accurate. Th is is because when the variance components are initially estimated, 
the estimation procedure is assuming  random sampling  at both levels. What this means is that 
the initial estimate of the variance in the outcome at the between-individual level (Level 2) 
can ignore possible variation in the between-individual variance component that may be due 

192  Examining Individual Change with Repeated Measures Data
to additional within-individual variance that actually exists. If this occurs, the initial between-
individual estimate must be corrected by the ML estimation procedure as subsequent variables 
are added (Hox, 2010). 
 In this ﬁ rst type of null model, for example, we could test whether the grand-mean intercept 
for math varies across individuals. From Equation 5.1, this is simply deﬁ ned at Level 1 without 
the time-related variables as follows: 
 
  Y ti  =  π 0 i  +   ti  , 
(5.8) 
 where  π 0 i  is the average achievement across the three occasions, and   ti  represents errors in pre-
dicting the average achievement for individuals. Between individuals, we can describe the aver-
age growth across occasions as 
 
  π 0 i  =   00 +  u 0 i  , 
(5.9) 
 where   00 is the intercept describing the average initial status mean between individuals, and  u 0 i  
is the Level 2 random component associated with describing diﬀ erences in average achievement 
between individuals. Substituting Equation 5.9 into Equation 5.8, we would arrive at the com-
bined equation 
 
  Y ti  =   00 +  u 0 i  +   ti  , 
(5.10) 
 which indicates three parameters to estimate. Th ese include the ﬁ xed eﬀ ect describing average 
math achievement, the between-individual random variance, and the Level 1 residual variance. 
 Deﬁ ning Model 1.1 (Null) with IBM SPSS Menu Commands 
 Continue using  ch5growthdata-vertical.sav . 
  1. Go to the toolbar and select 
ANALYZE, MIXED MODELS, 
LINEAR. 
 Th is command enables access to the 
 Linear Mixed Models: Specify Subjects and 
Repeated dialog box. 

Examining Individual Change with Repeated Measures Data  193
  2. Th e  Linear Mixed Models: Specify Subjects and 
Repeated screen displays options for deﬁ ning vari-
ables as subjects, repeated observations, and type 
of covariance structure in a model. 
 
 a. A subject is an observational unit that may be 
independent of other subjects. For this model, 
we will designate  id (individual identiﬁ cation 
numbers) as the subject variable. Click to select 
 id from the  Variables column, and then click the 
right-arrow button to move the variable into 
the  Subjects box. 
 
 b. Th e  Repeated box allows specifying variables 
that identify repeated observations. For this 
model,  Index1 identiﬁ es repeated observations 
over three time periods. Click to select  Index1 , 
and then click the right-arrow button to move 
the variable into the  Repeated box. 
 
  Th e combination of values for  id and  Index1 
deﬁ nes a particular student across three time 
periods. 
 
 c. Th e  Repeated Covariance Type speciﬁ es a model’s covariance structure. For this model, we will use 
the  Scaled Identity  (ID) covariance type. Click the pull-down menu and select  Scaled Identity.  Th e 
ID structure has constant variance and assumes that no correlation occurs between elements. 
 
 d. Click the CONTINUE button to display the  Linear Mixed Models dialog box. 
  3. Th e  Linear Mixed Models main screen enables 
specifying the dependent variable, factors, co-
variates, and access to dialog boxes for deﬁ n-
ing  Fixed and  Random eﬀ ects, and options for 
 Estimation ,  Statistics ,  EM Means , and  Save. 
 
 a. For this model, we will use math achieve-
ment ( test ) as the dependent variable. Click 
to select the  test variable from the left column 
listing. Th en click the right-arrow button to 
transfer  test into the  Dependent Variable  box. 
 
 b. Th e null model does not have predictors, 
but since we will be designating a random 
eﬀ ect in step 3, we will need to introduce 
variable(s) at this point as factors or covariates as a workaround. (Omitting this step will pre-
vent specifying a random eﬀ ect.) 
 Factors and covariates may be speciﬁ ed in predicting the dependent variable. Factors are categorical 
predictors that may be numeric or string. Covariates are scale predictors that must be numeric. 
 We will designate two predictor variables, which will be used later in the upcoming model (Model 
5.1A). Locate and click the variables  time and  quadtime  from the left column listing, and then click the 
right-arrow button to move the variables into the  Covariate(s) box. 
 Since we are not deﬁ ning eﬀ ects for the two predictors, we will skip over the FIXED eﬀ ects button and 
go to set up the model’s random eﬀ ects. 
 Click the RANDOM button to access the  Linear Mixed Models: Random Eﬀ ects dialog box. 

194  Examining Individual Change with Repeated Measures Data
  4. Th e  Linear Mixed Mod-
els: Random Eﬀ ects screen 
allows specifying random 
eﬀ ects, interactions, in-
tercept terms, and subject 
groupings. 
 
 a. Begin by specifying the 
covariance structure from 
the default variance com-
ponents (VC) to scaled 
identity. Click the pull-
down menu and select 
 Scaled Identity (ID). Th e 
scaled identity structure 
has constant variance and 
assumes that no cor-
relation occurs between 
elements. 
 
 b. We want the intercept to 
be included in the model, 
so click  Include intercept . 
 
 c. Th e  Subject Groupings box displays the  id variable that was selected as a subject variable in the 
 Select Subjects and Repeated dialog box show in step 2a. We will specify  id as the subject for the 
random-eﬀ ects part of this model. Click to select  id , and then click the right-arrow button to 
move the variable into the  Combinations box. 
 Click the CONTINUE button to return to the  Linear Mixed Models main dialog box. 
  5. Th e  Linear Mixed Models: Estimation dia-
log box displays two estimation method 
choices: ML or restricted maximum 
likelihood (REML). 
 In this chapter, we will use the default setting 
of REML to estimate the models. 
 Click the CONTINUE button to return to the 
 Linear Mixed Models dialog box. 

Examining Individual Change with Repeated Measures Data  195
  7. Finally, in the  Linear Mixed Models 
dialog box, click the OK button to 
run the model. 
  6. In the  Linear Mixed Models dialog 
box, click the STATISTICS button 
to access the  Linear Mixed Models: 
Statistics dialog box. 
 Click and select the following three 
statistics to be included in the output: 
Parameter estimates ,  Tests for covariance 
parameters , and  Covariances of random 
eﬀ ects . 
 Click the CONTINUE button to return 
to the  Linear Mixed Models dialog box. 
 Interpreting the Output From Model 1.1 (Null) 
 Th e grand mean for achievement is 52.945 (not tabled), as summarized previously in   Table 5.2  . 
Th e variance component table (  Table 5.4  ) can be used to determine how much variability in 
math achievement is present at each level. At Level 1, the variance ( 


1
0
0



2
0
0
2
2






2
2




2
0
0
2


2
0
0





2
0
0






3
0
0
  ) summarizes the popu-
lation variability in the average individual’s achievement estimates around her or his own true 
growth trajectory (Singer & Willet, 2003). Th e estimate is 78.101. Th e Level 2 variance is 30.505 
(Wald  Z = 33.777,  p  .001), which suggests there is suﬃ  cient variation in intercepts across in-
dividuals. Th e null hypothesis is that the population parameter for the variance is 0 (Singer & 
Willett, 2003). Keep in mind that the Wald  Z statistic provides a two-tailed test and because the 
null hypothesis is that the population variance is 0, we should use a one-tailed test for variances. 
As a rough estimate, we can calculate the proportion of variance in math achievement that is 
between individuals as about 0.281 [30.505/(30.505 +78.101)], or 28.1%. 

196  Examining Individual Change with Repeated Measures Data
 TABLE 5.4 Initial Estimates of Covariance Parameters a 
Parameter
Estimate
Std. Error
Wald Z
Sig.
Repeated Measures
Variance
78.101
0.839
93.113
.000
Intercept [subject = id]
Variance
30.505
0.903
33.777
.000
 a Dependent variable: test. 
 Model 1.1A: What Is the Shape of the Trajectory? 
 Alternatively, we can start with Model 1.1A as a model that includes the time-related variables 
( time and  quadtime ). If one begins with the linear component and quadratic components, and 
they are not transformed, this model will provide a variance component for the intercept at Time 
0 (at initial status). Th e Level 1 model is speciﬁ ed in Equation 5.1, where we have deﬁ ned lin-
ear and quadratic time-related components describing the shape of individual growth in math 
achievement over the three time points. In describing the shape of the growth trajectory, we can 
also estimate  k − 1 random eﬀ ects. Since there are three time points in this example, we can es-
timate two random eﬀ ects. Th is allows us to estimate a Level 2 randomly varying intercept and 
either a randomly varying linear component or quadratic component. 
 In this model, we will initially treat both time-related components as ﬁ xed (i.e., with no  u 2 i  
and u 2 i  residual variances) between individuals: 
 
  π 1 i  =   10 
(5.11) 
 
  π 2 i  =   20 . 
(5.12) 
 Substituting the Level 2 equations (Eq. 5.10 for the intercept and Eqs. 5.11 and 5.12 for the 
time-related slopes) into the Level 1 equation (Eq. 5.1) results in the following combined 
equation: 
 
 
2
00
0
20
0
ti
ti
ti
i
ti
00
10
20
0
20
Yti



	
2
ti
ti
i
ti
ti
i
00
10
20
0
20
10
00
10
20
20
20
10
2
0i
0
a
a
u
a
a2
00
10
20
20
10
10
20
00
10
20
20
20
10
10
20
 
(5.13) 
 Th is suggests ﬁ ve parameters to estimate including three ﬁ xed eﬀ ects, one random intercept ( u 0 i  ), 
and the Level 1 residual (  ti  ). 

Examining Individual Change with Repeated Measures Data  197
 Deﬁ ning Model 1.1A with IBM SPSS Menu Commands 
 Continue using the  ch5growthdata-
vertical.sav  data. Settings will 
default to those used in Model 1.1 
(Null). 
  1. Go to the toolbar and select 
ANALYZE, MIXED MOD-
ELS, LINEAR. 
 Th is command enables access to the 
 Linear Mixed Models: Specify Subjects 
and Repeated dialog box. 
  2. Th e  Linear Mixed Models: Specify Subjects and 
Repeated box displays the default settings from 
the prior model. We will retain the settings, so 
click the CONTINUE button to display the 
 Linear Mixed Models dialog box. 

198  Examining Individual Change with Repeated Measures Data
  3. Th e  Linear Mixed Models main dialog 
box displays  test as the dependent 
variable and the predictor variables 
 time and  quadtime  as covariates. 
 Once the predictor variables have been 
speciﬁ ed, we may now proceed to deﬁ ne 
ﬁ xed eﬀ ects for the variables. 
 Click the FIXED button to access the 
 Linear Mixed Models: Fixed Eﬀ ects dialog 
box. 
 
 4a. Within the  Linear 
Mixed Models: Fixed 
Eﬀ ects dialog box, click 
the pull-down menu to 
change the factorial set-
ting to  Main Eﬀ ects . 
 
 b. Click to select  time and 
 quadtime  from the  Fac-
tors and Covariates box, 
and then click the ADD 
button to move the vari-
able into the  Model box. 
 
 c. Note on lower left of the 
screen that the intercept 
and the sum of squares 
( Type III ) are the default 
settings. 
 Click the CONTINUE button to return to the  Linear Mixed Models dialog box. 
  5. Finally, in the  Linear Mixed Models 
dialog box, click the OK button to 
run the model. 

Examining Individual Change with Repeated Measures Data  199
   Interpreting the Output From Model 1.1A 
 Th e ﬁ xed eﬀ ects are presented in   Table 5.5  . We can observe that both the linear and quadratic 
polynomials are signiﬁ cant in explaining student growth in math, which suggests that both should 
be retained in subsequent analyses. Th e linear component is the portion of the sum of squares 
(SS) attributable to the linear regression of  Y on  X , and the quadratic component measures the 
additional improvement in ﬁ t due to that component. Notice that the intercept corresponds to 
students’ math achievement level at the beginning of the study. We can use the estimates in   Table 
5.5 to obtain the observed means for the second and third intervals summarized in   Table 5.2 . 
 Next, readers will notice in   Table 5.6  that when we include the time-related variables in the 
initial model, the within-individual variance is reduced from 78.10 in   Table 5.4  to 60.19. Th e 
estimate of the between-individual variance, however, is actually a little larger (36.48) than the 
initial estimate in   Table 5.4  (30.51) with no time-related parameter in the model. Th is would 
seem to be explaining “negative” variance between individuals (at Level 2) since the variance 
component is reduced by adding the time-related variables. As we have noted previously, this 
problem regarding negative variance is actually quite common in multilevel analyses of repeated 
measures. It often occurs because the variability among subjects in the repeated measures por-
tion (Level 1) of the outcome is usually much larger than the sampling model assumes (Hox, 
2010). Th is leads to overestimating occasion variance and underestimating between-individual 
(Level 2) variance in the intercept-only model. If we calculated the proportion of the variance 
between individuals based on the variance components in   Table 5.6  for Model 1.1A, we would 
ﬁ nd that the between-individual proportion of the variance in math achievement is now 0.377 
(36.477/96.664), or almost 38%, rather than 28% from Model 1.1 with no predictors. 
 TABLE 5.5 Estimates of Fixed Effects a 
Parameter
Estimate
Std. Error
df
t
Sig.
95% Conﬁ dence Interval
Lower Bound
Upper Bound
Intercept
48.632
0.106
20,242.098
460.579
.000
48.425
48.839
time
4.719
0.212
17,338.000
22.216
.000
4.303
5.135
quadtime
–0.244
0.102
17,338.000
–2.391
.017
–0.444
–0.044
 a Dependent variable: test. 
TABLE 5.6 Estimates of Covariance Parameters Including Time Variablesa
Parameter
Estimate
Std. Error
Wald Z
Sig.
Repeated Measures
Variance
60.187
0.646
93.107
.000
Intercept [subject = id]
Variance
36.477
0.885
41.198
.000
 a Dependent variable: test. 

200  Examining Individual Change with Repeated Measures Data
 Does the Time-Related Slope Vary Across Groups? 
 We emphasize there is no “one way” to proceed in developing an initial growth model. We gener-
ally favor this latter approach (Model 1.1A), where the analysis begins with focusing on whether 
the means of the repeated measures diﬀ er across time and deﬁ ning the shape of the growth 
trajectory. Th is initial model could include both the linear and quadratic components since both 
were found to be signiﬁ cantly related to student growth. Th erefore, our ﬁ rst model focuses on 
deﬁ ning the shape of students’ growth trajectories and determining whether the intercept and 
slopes vary across individuals. We can now test whether the time-related slopes are randomly 
varying across individuals at Level 2: 
 
  π 1i =   10 +  u 1 i  , 
(5.14) 
 
  π 2i =   20 +  u 2 i  , 
(5.15) 
 where the   coeﬃ  cients represent the intercepts, and the  u coeﬃ  cients represent the variance 
estimates for the equations. We note that determining which time-related component or com-
ponents to use in building the Level 2 explanatory models can take a bit of trial and error. It is 
generally the case that alternative models with various trajectory shapes and covariance struc-
tures should be preliminarily investigated in order to arrive at an optimal solution (e.g., see Liu 
et al., 2012). 
 As we have noted, when we estimate a polynomial growth model, we need to keep in mind 
that we are limited in the number of random eﬀ ects by the number of repeated measures. We can 
estimate a random eﬀ ect for the intercept and linear or quadratic term, but not both. If we choose 
the linear term, this means we will need to assume that the slowing indicated by the quadratic 
parameter is the same for every person in the sample. Th erefore, it is often the choice to consider 
the quadratic as a ﬁ xed eﬀ ect within individuals in subsequent models to explain diﬀ erences in 
students’ growth trajectories. Since it does not vary across individuals, we can ﬁ x its variability at 
0 by removing the random term ( u 2 i  ), as in Equation 5.12. If we do try to estimate the quadratic 
eﬀ ect also, we receive the warning message in   Figure 5.7  regarding the model’s failure to converge 
on a solution. 
 With the quadratic component ﬁ xed, through the substitution of Equations 5.10 (intercept) 
and 5.14 and 5.12 (time-related slopes) into Equation 5.1, we arrive at the single-equation model 
for examining the ﬁ xed and random components without Level 2 predictors: 
 
  Y ti  =   00 +   10 time ti  +   20 quadtime ti  +  u 1 i  time ti  +  u 0 i  +   ti  . 
(5.16) 
 Equation 5.16 suggests that the intercept and linear component (time) are randomly varying 
across individuals. Because the quadratic component is merely deﬁ ning the shape of growth 
 FIGURE 5.7  Warning message. 

Examining Individual Change with Repeated Measures Data  201
within individuals, this suggests building the explanatory model for student growth rates on the 
randomly varying linear component. 
 Level 2 Covariance Structure 
 It is also possible to deﬁ ne diﬀ erent covariance structures at successive levels of the proposed 
model. For Level 2, the dimensionality of the covariance matrix describing the variances and 
covariances between random eﬀ ects depends on the number of random eﬀ ects in the model. In 
this case, because we are treating the quadratic component as ﬁ xed across individuals due to our 
preliminary examination, we will assume a 2 × 2  unstructured covariance matrix of random eﬀ ects 
for the intercept ( I ) and slope ( S ) at Level 2: 


2
I S


2
I


,
2
I
I S,
 I




I S
 I


2






2


,




,
I S
S
,


I S
 
(5.17) 
 Th e variances are contained in the diagonals of the matrix, and the covariance is represented by 
the oﬀ -diagonal element. When we combine the covariance parameter estimated in Equation 
5.17 with the six parameters deﬁ ned in Equation 5.16 (i.e., three ﬁ xed eﬀ ects, one random Level 
2 intercept, one random Level 2 slope, and the Level 1 residual), we will have a total of seven 
parameters to estimate in our ﬁ nal version of Model 1. 
 Deﬁ ning Model 1.1B with IBM SPSS Menu Commands 
 Continue using  ch5growthdata-
vertical.sav . Settings will 
default to those used in Model 
1.1A. 
  1. Go to the toolbar and 
select ANALYZE, 
MIXED MODELS, 
LINEAR. 
 Th is command enables access 
to the  Linear Mixed Models: 
Specify Subjects and Repeated 
dialog box. 

202  Examining Individual Change with Repeated Measures Data
  3. Th e  Linear Mixed Models main dialog box 
displays the settings used in the prior model. 
 We will now add random eﬀ ects to this model. 
 Click the RANDOM button to access the  Linear 
Mixed Models: Random Eﬀ ects dialog box. 
  2. Th e  Linear Mixed Models: Specify Subjects and Re-
peated displays the default settings from the prior 
model. We will retain the settings, so click the 
CONTINUE button to display the  Linear Mixed 
Models dialog box. 
 
 4a. Within the  Linear Mixed 
Models: Random Eﬀ ects box, 
change the covariance type 
by clicking on the pull-
down menu and selecting 
 Unstructured . 
 
 b. Click to select  Include 
intercept . 
 
 c. Change  Factorial Eﬀ ects  by 
clicking on the pull-down 
menu and selecting  Main 
Eﬀ ects . 
 
 d. Click to select  time from 
the  Factors and Covariates 
box, and then click the 
ADD button to move the 
variable into the  Model box. 
 Click the CONTINUE button to 
return to the  Linear Mixed Models 
dialog box. 

Examining Individual Change with Repeated Measures Data  203
  5. Finally, in the  Linear Mixed Models 
dialog box, click the OK button to 
run the model. 
 Interpreting the Output From 
Model 1.1B 
 Results of this ﬁ rst model test are 
presented in the following tables. 
As in previous chapters, it is often 
useful to examine the total number 
of parameters being estimated and 
the number of random and ﬁ xed ef-
fects to make sure they correspond 
with what the analyst might have in 
mind. Th e ﬁ rst output (  Table 5.7  ) 
conﬁ rms that there are seven total parameters being estimated, which is consistent with Equa-
tions 5.16 and 5.17. 
 Th e ﬁ xed-eﬀ ect results in   Table 5.8  are summarized as   parameters since they are Level 2 
parameters (as suggested in Eq. 5.16). For the true intercept ( π 0 i  ), the estimate for initial status 
(  00 in Eq. 5.16) is 48.632. Th is estimate is consistent with estimated mean for Time 0 in   Table 
5.2 . For the linear growth rate ( π 1 i  ), the estimate (  10 in Eq. 5.16) is 4.72 points per year. For 
the quadratic growth rate ( π 2 i  ), the estimate (  20 in Eq. 5.16) is ‒0.244. Th e signiﬁ cance of each 
ﬁ xed eﬀ ect is tested with a  t test (i.e., deﬁ ned as the ratio of the unstandardized estimate to its 
standard error). We note that MIXED applies the Satterthwaite (1946) correction for calculat-
ing the degrees of freedom used in testing parameter signiﬁ cance, which explains the presence 
of decimals in the degrees of freedom column in   Table 5.8  . Th e signiﬁ cant  t tests for the growth 
 TABLE 5.7 Model Dimension a 
Number of 
Levels
Covariance 
Structure
Number of 
Parameters
Subject 
Variables
Intercept
1
1
Fixed Effects
time
1
1
quadtime
1
1
Random Effects
Intercept + time
2
Unstructured
3
id
Repeated Effects
time
3
Identity
1
id
Total
8
7
 a Dependent variable: test. 
TABLE 5.8 Estimates of Fixed Effectsa
Parameter
Estimate
Std. Error
df
t
Sig.
95% Conﬁ dence Interval
Lower Bound
Upper Bound
Intercept
48.632
0.103
10,597.930
472.847
.000
48.431
48.834
time
4.719
0.206
10,329.959
22.948
.000
4.316
5.122
quadtime
–0.244
0.098
8,669.000
–2.485
.013
–0.436
–0.052
 a Dependent Variable: test. 

204  Examining Individual Change with Repeated Measures Data
terms suggest that both should be retained in the model and that, on average, individuals’ growth 
rates slow slightly over time. 
 Next, we can examine the covariance parameters in   Table 5.9  . Th e Level 1 estimate is 55.72 
(Wald  Z = 65.837,  p  .001). At Level 2, we speciﬁ ed an unstructured covariance matrix, which 
means that there are variance estimates for the random intercept (UN 1, 1), the random linear 
slope (UN 2, 2), and an estimate of the covariance between them (UN 2, 1). Th e table suggests 
that there is signiﬁ cant variability in the random intercept to be explained between individuals 
(Wald  Z = 25.048,  p  .001). Th e linear time slope also varies signiﬁ cantly across individuals 
(Wald  Z = 6.891,  p  .001). Th e third parameter represents the covariance between the Level 2 
initial status and linear growth estimates. We note that the relationship between these two pa-
rameters can depend on how the intercept is speciﬁ ed (i.e., with the intercept is deﬁ ned as initial 
status, the grand mean, or end status) as well as the presence of other variables in the model (Hox, 
2010). In this model, the results suggest that the covariance parameter between the initial status 
intercept and growth rate is not signiﬁ cantly diﬀ erent from 0 (Wald  Z = ‒1.631,  p  .05). 
 Because the covariance can be positive or negative, the two-tailed test Wald  Z test implies that 
we could ﬁ x the covariance (UN 2, 1) in subsequent models if we wished to simplify the covari-
ance structure. We also note in passing that researchers have cautioned about the use of these 
single parameter tests of signiﬁ cance of the model’s variance components (Hox, 2010; Rauden-
bush & Bryk, 2002). Th e Wald  Z test can also perform poorly under multicollinearity problems 
and in small sample sizes. For small samples, the likelihood ratio test (which can be estimated 
from MIXED output) tends to be more reliable than the Wald  Z test. 
 Examining Orthogonal Components 
 We reiterate that analysts should keep in mind that the polynomial components when untrans-
formed are highly correlated. As we have discussed previously, when repeated measures ANOVA 
is used, the program automatically transforms the polynomials to be orthogonal. When we use 
MIXED, the recommendation is that we also transform the coded polynomial components so 
that they are orthogonal, or we consider other possible ways of coding the time variables. In this 
next model, we will use the transformed polynomial contrasts for time ( orthtime and o rthquad ). 
TABLE 5.9 Estimates of Covariance Parametersa
Parameter
Estimate
Std. Error
Wald Z
Sig.
95% Conﬁ dence Interval
Lower Bound
Upper Bound
Repeated Measures
Variance
55.720
0.846
65.837
.000
54.085
57.403
Intercept + time 
[subject = id]
UN (1, 1)
35.992
1.437
25.048
.000
33.283
38.922
UN (2, 1)
–1.247
0.764
–1.631
.103
–2.745
0.251
UN (2, 2)
4.467
0.648
6.891
.000
3.361
5.936
 a Dependent variable: test. 

Examining Individual Change with Repeated Measures Data  205
 Deﬁ ning Model 1.2 with IBM SPSS Menu Commands 
 Continue using the 
 ch5growthdata-vertical.sav data. 
Settings will default to those used 
in Model 1.1B. 
  1. Go to the toolbar and select 
ANALYZE, MIXED 
MODELS, LINEAR. 
 Th is command enables access to 
the  Linear Mixed Models: Specify 
Subjects and Repeated dialog box. 
  2. Th e  Linear Mixed Models: Specify Subjects and 
Repeated box displays the default settings from 
the prior model. 
 We will retain the settings, so click the CON-
TINUE button to display the  Linear Mixed Models 
dialog box. 

206  Examining Individual Change with Repeated Measures Data
  3. We will change the predictors by using 
the transformed polynomial contrasts 
for time in the model ( orthtime and 
o rthquad ). 
 
 a. Begin by selecting  time and  quadtime 
and then clicking the left-arrow but-
ton to remove the variables from the 
 Covariate(s) box. 
 
 b. Now click to select  orthtime and 
 orthquad. Th en click the right-
arrow button to add them to the 
 Covariate(s) box. 
 Once the predictor variables have been speci-
ﬁ ed, we may now proceed to deﬁ ne ﬁ xed 
eﬀ ects for the variables. 
 Click the FIXED button to access the  Linear 
Mixed Models: Fixed Eﬀ ects dialog box. 
 
 4a. Within the  Linear 
Mixed Models: Fixed 
Eﬀ ects dialog box, 
click the pull-down 
menu to change the 
factorial setting to 
 Main Eﬀ ects . 
 
 b. Click to select  orth-
time and  orthquad 
from the  Factors and 
Covariates box, and 
then click the ADD 
button to move the 
variable into the 
 Model box. 
 
 c. Note on lower left of 
the screen that the 
intercept and the sum 
of squares ( Type III ) are the default settings. 
 Click the CONTINUE button to return to the  Linear Mixed Models dialog box. 
 Click the RANDOM button to access the  Linear Mixed Models: Random Eﬀ ects dialog box. 

Examining Individual Change with Repeated Measures Data  207
 
 5a. Within the  Linear 
Mixed Models: Ran-
dom Eﬀ ects box, the 
covariance type and 
intercept are set to 
the default settings 
of the prior model. 
 
 b. Th e  Main Eﬀ ects op-
tion is preselected. 
 
 c. Click to select  orth-
time from the  Factors 
and Covariates box, 
and then click the 
ADD button to 
move the variable 
into the  Model box. 
 Click the CONTINUE 
button to return to the  Lin-
ear Mixed Models dialog box. 
  6. Finally, in the  Linear Mixed Models 
dialog box, click the OK button to 
run the model. 
 Interpreting the Output From Model 1.2 
 When we rerun the model using these transformed polynomials, we obtain the ﬁ xed-eﬀ ects 
estimates summarized in   Table 5.10  . We can observe that both contrasts are signiﬁ cant and, 
therefore, should be retained in subsequent analyses. We can note that the intercept is now the 
grand mean of the growth trend instead of the initial status mean (see   Table 5.2  ). Adding the 
growth components to the intercept provides an estimate of ending achievement (57.095) with 
a slight diﬀ erence due to rounding (see   Table 5.2 on page 174). We note that transforming the 
polynomials places the interpretation on the overall growth trend rather than change within any 
particular interval (Hox, 2010). 

208  Examining Individual Change with Repeated Measures Data
 TABLE 5.10 Estimates of Fixed Effects a 
Parameter
Estimate
Std. Error
df
t
Sig.
95% Conﬁ dence Interval
Lower Bound Upper Bound
Intercept
52.945
0.081
8,669
655.630
.000
52.786
53.103
orthtime
4.231
0.061
8,669.000
69.291
.000
4.111
4.351
orthquad
–.081
0.033
8,669
–2.485
.013
–0.145
–0.017
 a Dependent variable: test. 
 TABLE 5.11  Repeated Measures ANOVA Tests of Within-Subjects Contrasts 
Measure:test
Source
Time
Type III Sum of 
Squares
df
Mean Square
F
Sig.
Noncent. 
Parameter
Observed 
Powera
Time
Linear
310,416.221
1
310,416.221
4,801.239
.000
4,801.239
1.000
Quadratic
344.115
1
344.115
6.176
.013
6.176
0.700
Error(time)
Linear
560,479.947
8,669
64.653
Quadratic
483,033.589
8,669
55.720
 a Computed using alpha = 0.05. 
 Readers may wish to verify that transforming the polynomials does succeed in creating no cor-
relation between them. Adding the coeﬃ  cients will provide the estimate of ending achievement 
in   Table 5.2  (57.095, with a slight diﬀ erence due to rounding). We can compare the results in 
 Table 5.10  to the similar speciﬁ cations using repeated measures ANOVA (we include the syntax 
in Appendix A). We provide the within-subjects contrasts from the same repeated measures 
ANOVA analysis in   Table 5.11  . Readers will notice that if we take the square root of the  F tests 
for the time-related contrasts (4,801.239) for the linear contrast and for the quadratic contrast 
(6.176), we obtain the  t tests for the contrasts in  Table 5.10  . Th is suggests that the MIXED solu-
tion with orthogonal polynomial linear and quadratic contrasts is consistent with the repeated 
measures ANOVA solution for the time-related eﬀ ects. 
 Specifying the Level 1 Covariance Structure 
 We also need to consider the nature of the Level 1 (within individuals) covariance matrix in a 
repeated measures design. For repeated measures ANOVA, Mauchly’s sphericity test assumes a 
speciﬁ c structure for the repeated measures covariance matrix. We note that the associated test 
for sphericity was signiﬁ cant (Mauchly’s  W = 0.977, 2  df ,  p  .001), which in a similar two-level 
model (with only random intercept) amounts to not accepting compound symmetry. In MIXED, 
there is no speciﬁ c test conducted for the covariance matrix between repeated measures. We can, 
however, begin by examining whether the Level 1 covariance matrix is consistent with a more 
simpliﬁ ed covariance structure. We will assume that the Level 1 error covariance matrix is scaled 
identity (ID) and specify an unstructured (UN) covariance structure for the Level 2 random 
eﬀ ects. 
 In   Table 5.12  , we present the covariance parameters for the Model 1.2. First, we can see that 
the linear contrast varies randomly across individuals (Wald  Z = 42.001,  p  .001). Second, we 
can also see that with transformed polynomials the covariance between the intercept and slope 

Examining Individual Change with Repeated Measures Data  209
(UN 2, 1) is signiﬁ cant and positive, which contrasts with the similar parameter using untrans-
formed polynomials (see   Table 5.9  on page 204). 
 Investigating Other Level 1 Covariance Structures 
 As we suggested previously, we can test the ﬁ t of the scaled identity covariance matrix for the 
repeated measures against other possible covariance structures. We summarize several of these 
alternative structures in   Table 5.13  . As we noted previously, often there will be little diﬀ erence in 
terms of the ﬁ xed eﬀ ects associated with diﬀ erent covariance structures. How can we then decide 
which structure to use? For nested models, one way is to conduct a likelihood ratio test using the 
diﬀ erence in deviance (–2 times the log of the likelihood [–2LL]) between models. For models 
that may not be nested, we can compare the Akaike information criterion (AIC) index for each 
model. Th e AIC index ( D + 2 p ) is computed by multiplying the number of parameters ( p ) by 2 
and adding this product to the deviance statistic, computed using FIML. Th e addition of 2 p to the 
deviance statistic provides a penalty based on the model’s complexity. We can also use the Bayes-
ian information criterion (BIC), which is deﬁ ned as the sum of the deviance and the product of 
the natural log (ln) of the sample size and the number of parameters [D + ln( n ) p ]. We prefer the 
smallest AIC or BIC among models compared, regardless of the number of parameters. 
 For Model 1, with seven estimated parameters (summarized as Model 1.2  in   Table 5.12  ), the 
AIC is 189,290.45. After examining Models 2–4, we might select Model 3, with diagonal covari-
ance structure at Level 1 and unstructured covariance structure at Level 2 as a reasonable choice 
based on available model-ﬁ tting information. For this model, the AIC is 189,125.70. 
 In   Table 5.14  , we can see that this model more adequately accounts for the diﬀ erent vari-
ances between occasions than a model that assumes constant variance across occasions. We also 
TABLE 5.12 Estimates of Covariance Parametersa
Parameter
Estimate
Std. Error
Wald Z
Sig.
95% Conﬁ dence Interval
Lower Bound
Upper Bound
Repeated Measures
Variance
55.720
0.846
65.837
.000
54.085
57.403
Intercept + orthtime 
[subject = id]
UN (1, 1)
37.965
0.904
42.001
.000
36.235
39.779
UN (2, 1)
3.220
0.460
6.993
.000
2.317
4.122
UN (2, 2)
4.467
0.648
6.891
.000
3.361
5.936
 a Dependent variable: test. 
 TABLE 5.13 Comparing Models, AIC Index, and Number of Parameters 
Model
Model Description
AIC
Parameters
Model 1
Identity Covariance Matrix, Level 1; 
Unstructured Matrix, Level 2
189,290.45
7
Model 2
Diagonal Covariance Matrix, Level 1;
Diagonal Covariance Matrix, Level 2
189,295.75
8
Model 3
Diagonal Covariance Matrix, Level 1;
Unstructured Covariance Matrix, Level 2
189,125.70
9
Model 4
Autoregressive Errors (AR1), Level 1;
Diagonal Covariance Matrix, Level 2
189,282.16*
8
 *Note: Model did not converge. 

210  Examining Individual Change with Repeated Measures Data
investigated a number of other possibilities at Level 1 (unstructured and autoregressive) but 
found that the model did not converge. We suggest, therefore, that models should generally be 
judged on various criteria including model ﬁ t indices, as well as their substance and sensibility in 
relation to the study’s research purposes. 
 Deﬁ ning Other Level 1 Covariance Structures Using IBM SPSS Menu Commands 
 (Examples in this section are based on Model 1.2, with scaled identity covariance structure at Level 
1 and unstructured covariance structure at Level 2, but illustrate changes to the Level 1 and Level 2 
covariance structures as summarized in   Table 5.13 .) 
 Model 1: ID (Level 1), UN (Level 2) 
  1. Go to the toolbar and select ANALYZE, 
MIXED MODELS, LINEAR. 
 Th is command enables access to the  Linear Mixed 
Models: Specify Subjects and Repeated dialog box. 
 Scaled Identity Covariance Matrix at Level 1 
  2. Th e  Linear Mixed Models: Specify Subjects and 
Repeated dialog box displays the default setting 
used for Model 1.2. Note that the  Repeated Co-
variance Type  function is set as  Scaled Identity . 
 Th e  Scaled Identity  covariance structure has het-
erogeneous variances and zero correlation between 
elements (IBM Corporation, 2012). 
 Click the CONTINUE button to display the  Lin-
ear Mixed Models dialog box. Click the RANDOM 
button to access the  Linear Mixed Models: Random 
Eﬀ ects dialog box. 
 TABLE 5.14 Estimates of Covariance Parameters a 
Parameter
Estimate
Std. Error
Wald Z
Sig.
95% Conﬁ dence Interval
Lower Bound
Upper Bound
Repeated Measures
Var: [Index1 = 1]
63.583
2.026
31.385
.000
59.734
67.681
Var: [Index1 = 2]
58.779
1.158
50.756
.000
56.552
61.093
Var: [Index1 = 3]
35.619
1.980
17.987
.000
31.942
39.720
Intercept + orthtime 
[subject = id]
UN (1, 1)
38.985
0.946
41.216
.000
37.175
40.884
UN (2, 1)
7.881
0.610
12.926
.000
6.686
9.076
UN (2, 2)
7.526
0.964
7.805
.000
5.855
9.675
 a Dependent variable: test. 

Examining Individual Change with Repeated Measures Data  211
 Unstructured Covariance Matrix at Level 2 
  3. Th e  Linear Mixed Models: 
Random Eﬀ ects dialog box 
displays the default set-
ting used for Model 1.2. 
Note that the  Covariance 
Type function is set as 
 Unstructured . 
 Unstructured is a completely 
general covariance matrix 
(IBM Corporation, 2012). 
 Click the CONTINUE button 
to return to the  Linear Mixed 
Models dialog box. Th en click 
OK to generate the Model 1 
results. Compare the output’s 
AIC and model parameters to 
those in  Table 5.13 . 
 (Settings default to Model 1.) 
 Model 2: DIAG (Level 1), DIAG (Level 2) 
  1. Go to the toolbar and select ANALYZE, MIXED MODELS, LINEAR. 
 Th is command enables access to the  Linear Mixed Models: Specify Subjects and Repeated dialog box. 
 Diagonal Covariance Matrix at Level 1 
  2. Th e  Linear Mixed Models: Specify Subjects and Re-
peated dialog box displays the default setting used 
for Model 1. Change the covariance setting by 
clicking the pull-down menu to select  Diagonal . 
 Th e  Diagonal covariance structure has heterogeneous 
variances and zero correlation between elements (IBM 
Corporation, 2012). 
 Click the CONTINUE button to display the  Linear 
Mixed Models dialog box. Click the RANDOM but-
ton to access the  Linear Mixed Models: Random Eﬀ ects 
dialog box. 

212  Examining Individual Change with Repeated Measures Data
 Diagonal Covariance Matrix at Level 2 
  3. Th e  Linear Mixed Models: 
Random Eﬀ ects dialog box 
displays the default set-
ting used for Model 1. 
Change the  Covari-
ance Type by clicking the 
pull-down menu to select 
 Diagonal. 
 Th e  Diagonal  covariance 
structure has heterogeneous 
variances and zero correla-
tion between elements (IBM 
Corporation, 2012).Click the 
CONTINUE button to return 
to the  Linear Mixed Models 
dialog box. Th en click OK to 
generate the Model 2 results. 
Compare the output’s AIC and 
model parameters to those in 
 Table 5.13 . 
 (Settings default to Model 2.) 
 Model 3: DIAG (Level 1), UN (Level 2) 
  1. Go to the toolbar and select ANALYZE, MIXED MODELS, LINEAR. 
 Th is command enables access to the  Linear Mixed Models: Specify Subjects and Repeated dialog box. 
 Diagonal Covariance Matrix at Level 1 
  2. Th e  Linear Mixed Models: Specify Subjects and 
Repeated dialog box displays the default set-
ting used for Model 2. Note that the  Repeated 
Covariance Type is set to  Diagonal . 
 Th e  Diagonal covariance structure has heteroge-
neous variances and zero correlation between ele-
ments (IBM Corporation, 2012). 
 Click the CONTINUE button to display the  Linear 
Mixed Models dialog box. Click the RANDOM 
button to access the  Linear Mixed Models: Random 
Eﬀ ects dialog box. 

Examining Individual Change with Repeated Measures Data  213
 Unstructured Covariance Matrix at Level 2 
  3. Th e  Linear Mixed Models: 
Random Eﬀ ects dialog box 
displays the default setting 
used for Model 2. Change the 
 Covariance Type by clicking 
the pull-down menu to select 
 Unstructured. 
 Unstructured is a completely 
general covariance matrix (IBM 
Corporation, 2012). 
 Click the CONTINUE button to 
return to the  Linear Mixed Models 
dialog box. Th en click OK to gen-
erate the Model 3 results. Com-
pare the output’s AIC and model 
parameters to those in   Table 5.13 . 
 (Settings default to Model 3.) 
 Model 4: AR1 (Level 1), DIAG (Level 2) 
  1. Go to the toolbar and select ANALYZE, 
MIXED MODELS, LINEAR. 
 Th is command enables access to the  Linear Mixed 
Models: Specify Subjects and Repeated dialog box. 
 Autoregressive Errors (AR1) Covariance Matrix at 
Level 1 
  2. Th e  Linear Mixed Models: Specify Subjects and 
Repeated dialog box displays the default setting 
used for Model 3. Change the covariance set-
ting by clicking the pull-down menu to select 
 AR(1) . 
 AR(1) is a ﬁ rst-order autoregressive structure with 
homogenous variances. Th e correlation between any 
two elements is equal to rho (  ) for adjacent ele-
ments,   2 for elements that are separated by a third, 
and so on. We note that   is constrained so that ‒1 
    1 (IBM Corporation, 2012). 
 Click the CONTINUE button to display the  Linear Mixed Models dialog box. Click the RANDOM 
button to access the  Linear Mixed Models: Random Eﬀ ects dialog box. 

214  Examining Individual Change with Repeated Measures Data
 Diagonal Covariance Matrix at Level 2 
  3. Th e  Linear Mixed 
Models: Random Eﬀ ects 
dialog box displays the 
default setting used 
for Model 3. Change 
the  Covariance Type 
by clicking the pull-
down menu to select 
 Diagonal. 
 Click the CONTINUE 
button to return to the 
 Linear Mixed Models dialog 
box. Th en click OK to gen-
erate the Model 4 results, 
which shows that the model 
does not converge. Com-
pare the output’s AIC and 
model parameters to those 
in   Table 5.13 . 
 Model 1.3: Adding the Between-Subjects Predictors 
 Th e initial results presented previously suggest that intercepts and linear growth rates vary across 
individuals. We can next proceed with explaining variability in the random parameters across 
individuals (at Level 2). Th is part of the analysis addresses the third research question: Are there 
diﬀ erences in development across groups of individuals? A ﬁ rst issue to be addressed is which of 
the polynomial coeﬃ  cients should be used to build our successive models concerning diﬀ erences 
in growth trajectories by student background factors (e.g., gender and socioeconomic status)? 
Th e best advice is that it depends on the speciﬁ cs of the data set. We suggest trying to build a 
model that is parsimonious but does justice to the particular features of the data set. Th is will 
usually require some preliminary analyses. Th is part of specifying the model can be challenging 
since it may not be immediately clear which components may be randomly varying and on which 
polynomial contrast (or contrasts) we should actually build the explanatory model. Of course, we 
have more ﬂ exibility regarding the number of time-related random eﬀ ects that can be speciﬁ ed 
if we have more time points in the study. 
 In this case, since the quadratic component is ﬁ xed within individuals, it seems clear that we 
should build the Level 2 models on the randomly varying linear component; that is, we seek to 
explain its variability across individuals. We will propose that students’ perceptions of their teach-
ers’ eﬀ ectiveness (coded 1 = eﬀ ective vs. 0 = average or below) and students’ SES might explain 
diﬀ erences in their math intercepts and linear growth rates. In order to examine the parallelism 
hypothesis regarding variability in linear growth rates for diﬀ erent student subgroups (i.e., that 
growth rates are the same for students having eﬀ ective vs. not eﬀ ective teachers), or to consider 
the impact of an interval variable such as SES on student growth rates, we need to create cross-
level interaction terms. 

Examining Individual Change with Repeated Measures Data  215
 Cross-level interactions involve the eﬀ ects of Level 2 (between-individual) variables such as 
teacher eﬀ ectiveness on a Level 1 slope coeﬃ  cient—that is, students’ growth rates. As we have 
shown in previous chapters, cross-level interaction terms can be created within SPSS MIXED 
in the menu command format. We reiterate that for this exercise, we deﬁ ne students’ percep-
tions of teacher eﬀ ectiveness as a between-student factor; that is, it is simply used as a means of 
identifying subsets of students (e.g., similar to gender) who are likely to have diﬀ erent growth 
trajectories. In this example, we do not link groups of students to their individual teachers, so 
we will not consider the more complicated nesting of students within teachers. For Level 2, the 
following equations can be formulated: 
 
 π 0 i  =   00 +   01 ses i  +   02 eﬀ ective i  +  u 0 i  , 
(5.18) 
 
 π 1 i  =   10 +   11 ses i  +   12 eﬀ ective i  +  u 1 i  , 
(5.19) 
 where  u 0 i  and  u 1 i  represent variation associated with estimating the intercept and slope param-
eters between individuals. Th e quadratic component is speciﬁ ed as ﬁ xed at Level 2 ( π 2 i  =   20 ) as in 
Equation 5.12. When we substitute the intercept and slope equations (Eqs. 5.18, 5.19, and 5.12) 
into the Level 1 model (Eq. 5.1 using the transformed components), we obtain the following 
combined equation: 
 
  Y ti  =   00 +   01 ses i  +   02 eﬀ ective i  +   10 orthtime ti  +   11 ses i  * orthtime ti  + 
  12 eﬀ ective i  * orthtime ti  +   20 orthquad ti  +  u 1 i   orthtime ti u 0 i  +   ti  . 
(5.20) 
 We note that the cross-level interaction terms in Equation 5.20 are created within SPSS MIXED 
in the menu command format. We reiterate that the Level 1 repeated measures covariance ma-
trix in Model 1.3 is diagonal (as in Eq. 5.5) and the Level 2 covariance matrix is unstructured 
(Eq. 5.17). Th e dimensionality of the Level 2 matrix depends on the number of random eﬀ ects. 
Th is makes a total of 13 parameters to estimate (i.e., seven ﬁ xed eﬀ ects, three Level 2 random 
eﬀ ects, and three Level 1 residual variances). 
 If we wished to examine possible diﬀ erences in the quadratic component (even though we 
will treat this component as ﬁ xed across individuals), we could also add the Level 2 predictors 
to that portion of the model, but the random component ( u 2 i  ) would remain 0 (Raudenbush & 
Bryk, 2002): 
 
  π 2 i  =   20 +   21 ses i  +   22 eﬀ ective i  
(5.21) 
 Th is equation could then also be substituted into the Level 1 equation. 
 Deﬁ ning Model 1.3 with IBM SPSS Menu Commands 
 In this model, we proposed that students’ initial status intercept ( π 0 i  ) will vary across individuals, 
and this variation in intercepts will in part be explained by students’ socioeconomic status and 
teacher eﬀ ectiveness. We also proposed that variation in students’ average linear growth rates 
( π 1 i  ) will be explained by the same predictors. 

216  Examining Individual Change with Repeated Measures Data
 Continue using the 
 ch5growthdata-vertical.sav 
data. If continuing from the 
“Investigating Other Level 
1 Covariance Structures” ex-
amples, please change settings 
to those used for Model 1.2 
before proceeding. 
  1. Go to the toolbar and 
select ANALYZE, 
MIXED MODELS, 
LINEAR. 
 Th is command enables access 
to the  Linear Mixed Models: 
Specify Subjects and Repeated 
dialog box. 
  2. Th e  Linear Mixed Models: Specify Subjects and 
Repeated displays the default settings from 
Model 1.2.  
 Change the covariance setting by clicking the 
 Repeated Covariance Type pull-down menu to select 
 Diagonal . 
 Click the CONTINUE button to display the  Lin-
ear Mixed Models dialog box 

Examining Individual Change with Repeated Measures Data  217
  3. Th e  Linear Mixed Models dialog box 
displays test in the  Dependent Variable 
box with  orthtime and  orthquad in the 
 Covariate(s) box. 
 
 a. We will add two variables ( ses and 
 eﬀ ective) into the model. Entering 
variables in sequential order helps 
facilitate reading of the output tables. 
So ﬁ rst click to select  ses , and then 
click the right-arrow button to add 
the variable the  Covariate(s) box. 
 
 b. Click to select  eﬀ ective , and then click 
the right-arrow button to add the 
variable the  Covariate(s) box. 
 Th e variable sequence is  orthtime ,  orthquad ,  ses , and  eﬀ ective . 
 Note: An alternative method is to select both variables simultaneously and then “drag” them into the 
 Covariate(s) box. Th e variables may be rearranged by clicking to select a variable and then dragging it 
upward or downward to change the order of the sequence. 
 Click the FIXED button to access the  Linear Mixed Models: Fixed Eﬀ ects dialog box. 
 
 4a. Within the 
 Linear Mixed 
Models: Fixed 
Eﬀ ects dialog 
box, conﬁ rm 
that  Main Ef-
fects is selected. 
 
 b. Conﬁ rm that 
 Include intercept 
is selected. 
 
 c. To facilitate 
reading the 
output tables, 
click to select 
a variable, and 
then click the 
ADD button 
to move it into 
the  Model box 
in the follow-
ing order:  ses ,  eﬀ ective ,  orthtime , and  orthquad . 
 Th ese variables are the “main eﬀ ects” in the model and will modify the intercept. 
 Two cross-level interactions (or nested terms) will be created and added to the model:  ses*orthtime and 
 eﬀ ective*orthtime . Th ese interactions will tell us if the growth trajectories are parallel for diﬀ erent groups 
of students. 

218  Examining Individual Change with Repeated Measures Data
 Add First Cross-Level Interaction to Model 1.3:  ses*orthtime 
 
 d. Click to select  Build nested 
terms. 
 
 e. Click to select the variable 
 ses from the  Factors and 
Covariates box. 
 
 f. Th en click the arrow button 
below the  Factors and Co-
variates box. Th is moves  ses 
into the  Build Term box to 
create a cross-level interac-
tion by linking variables 
and terms. 
 
 g. Next, click the BY* button, 
which will insert the com-
putation command symbol: 
 ses* . 
 
 h. Click to select  orthtime 
from the  Factors and Covariates box. 
 
 i. Click the arrow button below the  Factors and Covariates box to move  orthtime into the  Build 
Term box and complete the interaction term:  ses*orthtime. 
 
 j. Click the ADD button to transfer the interaction into the  Model box. 
 Add Second Cross-Level Interaction to Model 1.3:  effective*orthtime 
 
 k. Click to select the vari-
able  eﬀ ective from the 
 Factors and Covariates  box. 
 
 l. Next, click the arrow 
button below the  Factors 
and Covariates box. Th is 
moves  eﬀ ective into the 
 Build Term box. 
 
 m. Now click the BY* but-
ton, which will insert the 
computation command 
symbol:  eﬀ ective* . 
 
 n. Click to select  orthtime 
from the  Factors and Co-
variates box. 
 
 o. Click the arrow button 
below the  Factors and 
Covariates box to move  orthtime into the  Build Term box and complete the interaction term: 
 eﬀ ective*orthtime. 
 
 p. Click the ADD button to transfer the interaction into the  Model box. 
 Click the CONTINUE button to return to the  Linear Mixed Models dialog box. 

Examining Individual Change with Repeated Measures Data  219
  5. Finally, in the  Linear Mixed Models dialog 
box, click the OK button to run the model. 
 Interpreting the Output From Model 1.3 
 Results of the second model test are presented next. Once again, it is useful to examine the 
random eﬀ ects and total parameters estimated summarized in   Table 5.15  . Th ere are seven ﬁ xed 
eﬀ ects estimated. In addition, there are six variance-covariance parameters to be estimated. At 
Level 1 (within individuals), there are three variance parameters (i.e., the variances for each oc-
casion). Th ese are listed in the diagonal covariance matrix at Level 1. In addition, there are three 
random eﬀ ects at Level 2 (i.e., the intercept, the linear time slope, and the covariance between 
them). Th is suggests 13 total parameters to be estimated. 
 Th e ﬁ xed-eﬀ ect estimates are summarized in   Table 5.16  . Students’ achievement intercept (  00 ) 
is 49.672. Th is can be described as students’ true grand-mean achievement adjusted for SES and 
perceptions of teacher eﬀ ectiveness. Th e intercept in this case can be interpreted as the grand-
mean test score for students who perceived that they did not have an eﬀ ective teacher (coded 0) 
and whose SES status was 0.00 (since SES was deﬁ ned as a  z -score). 
 Th e ﬁ rst question we can ask is whether the predictors are related to diﬀ erences in average 
achievement. We can see that perceived teacher eﬀ ectiveness is related to students’ achievement 
level ( p  .001). Th e coeﬃ  cient for eﬀ ectiveness (  02 = 5.944) suggests that students with eﬀ ec-
tive teachers would have an estimated grand-mean achievement level of about 55.616 (49.672 + 
5.944). In this model, student SES is not a signiﬁ cant predictor of average achievement level 
( p  .10). 
 Th e second question we can ask is whether there are diﬀ erences in student growth rates re-
lated to the predictors. Th e average linear growth rate ( orthtime ) increases signiﬁ cantly over time 
( p  .001). Keep in mind that the actual polynomial contrast coeﬃ  cients do not have direct 
TABLE 5.15 Model Dimensiona
Number of 
Levels
Covariance 
Structure
Number of 
Parameters
Subject 
Variables
Number 
of Subjects
Fixed Effects
Intercept
1
1
ses
1
1
effective
1
1
orthtime
1
1
orthquad
1
1
orthtime * ses
1
1
orthtime * effective
1
1
Random Effects
Intercept  orthtimea
2
Unstructured
3
id
Repeated Effects
Index1
3
Diagonal
3
id
8,670
Total
12
13
 a Dependent variable: test. 

220  Examining Individual Change with Repeated Measures Data
meaning regarding a particular time interval after they have been transformed. Because the linear 
contrast was speciﬁ ed as a random eﬀ ect, we are primarily interested in whether it varies between 
individuals in the study. Th e variation in the size of the within-individual growth parameter 
across individuals (UN 2, 2) can be examined by referring to Wald  Z test (Wald  Z = 8.547,  
p  .001) in the variance components table (  Table 5.17  ). Th e signiﬁ cant test suggests we can re-
ject the null hypothesis that the population growth parameter is 0, and we can infer that growth 
varies signiﬁ cantly across the population of individuals. 
 Regarding variables that might explain variability in math growth rates between individu-
als, we can see that the linear interaction ( orthtime * ses ) is signiﬁ cant at  p  .05 (  11 = ‒0.154, 
 p = .037). Th is coeﬃ  cient can be interpreted as students at higher SES levels demonstrate slightly 
less growth over time compared with students at the grand mean for SES. Th e test for students’ 
perceptions of teacher eﬀ ectiveness is also signiﬁ cant (  12 = 3.508,  p  .001). Th is suggests that 
students with teachers they perceived as eﬀ ective have a higher growth rate over time compared 
to their peers who perceive their teachers to be average or below in eﬀ ectiveness (since they are 
coded 0). Th e quadratic polynomial is also signiﬁ cant, which implies that student growth rates 
slow slightly over time (  20 = ‒0.081,  p  .001). In this model, we did not propose any cross-level 
interaction related to explaining the slowing of math growth rates. 
 After the addition of the predictors,   Table 5.17  suggests that there is still signiﬁ cant residual 
variance in intercepts to be explained (Wald  Z = 37.906,  p  .001). Th ere is also signiﬁ cant re-
sidual variance in slopes left to be explained across individuals (Wald  Z = 8.547,  p  .001). Th e 
covariance between the intercept and slope is positive (4.159) and also signiﬁ cant ( p  .001). If 
desired, we could select an unstructured covariance matrix with a correlation for the slope pa-
rameter (UNR). In this case, the correlation between students’ initial status (i.e., intercept) and 
growth of time is 0.27 (not tabled). We reiterate that while this correlation is often of interest in 
growth models, it can be diﬀ erent depending on how the intercept and slope are deﬁ ned and the 
other variables added to the model. 
 For comparative purposes in   Table 5.18  , we also provide the repeated measures ANOVA 
solution that we would obtain for the polynomial contrasts. Th e relevant output is the tests of 
within-subject contrasts. Th at solution also has additional tests of contrasts for the quadratic 
time-related component and the predictors in the model (i.e., SES and teacher eﬀ ectiveness). We 
can see that the linear eﬀ ect is also signiﬁ cant for individual SES in the ANOVA formulation 
(but the quadratic eﬀ ect is not), and the linear and quadratic eﬀ ects are both signiﬁ cant for  eﬀ ec-
tive ( p  .001) We could of course provide this same set of model tests using MIXED by adding 
the two quadratic contrasts to the ﬁ xed-eﬀ ect model. 
 TABLE 5.16 Estimates of Fixed Effects a 
Parameter
Estimate
Std. Error
df
t
Sig.
95% Conﬁ dence Interval
Lower Bound
Upper Bound
Intercept
49.672
0.111
8,701.861
447.802
.000
49.455
49.890
ses
0.074
0.095
8,667.000
0.784
.433
–0.112
0.260
effective
5.944
0.149
8,667.000
39.838
.000
5.652
6.237
orthtime
2.307
0.086
8,795.556
26.693
.000
2.138
2.477
orthquad
–0.081
0.033
8,669.000
–2.485
.013
–0.145
–0.017
orthtime * ses
–0.154
0.074
8,667.000
–2.090
.037
–0.298
–0.010
orthtime * effective
3.508
0.116
8,667.000
30.324
.000
3.281
3.735
 a Dependent variable: test. 

Examining Individual Change with Repeated Measures Data  221
 In   Table 5.19  , we provide a summary of the various models we have tested using untrans-
formed and transformed polynomials. Model 1 summarizes the initial results for time with the 
polynomial contrasts untransformed. In Model 1, without transformed time-related contrasts, 
the intercept (48.632) corresponds to student achievement at the beginning of the study. Model 3 
is the same model as Model 1 but with orthogonal polynomial contrasts. In Model 3, the inter-
cept (52.945) now corresponds to the grand mean for the trend, which is somewhere between 
interval 1 and interval 2. We can see that the polynomial components are signiﬁ cant ( p  .05), 
again suggesting they should be retained in subsequent analyses. Because the intercept is now 
the grand mean, however, the time-related estimates no longer correspond to any particular time 
interval in the study. 
 Readers can see that the pattern of results is the same despite the strong correlation between 
the linear and quadratic polynomial components in Model 1. Model 2 in   Table 5.19  summarizes 
the Level 2 eﬀ ects built only on the randomly varying linear time eﬀ ect. Model 4 presents those 
same results but with transformed time-related components. Once again, the pattern of results 
is almost the same for Models 3 and 4 (with only slight diﬀ erences in the variance parameters). 
Model 5 represents the MIXED speciﬁ cation of the repeated measures ANOVA analysis, which 
is in the last column of the table. Regarding the ANOVA results in the last column, as noted 
previously, the predictors enter in as interactions with growth over time (i.e.,  linear eﬀ ect*SES , 
 TABLE 5.17 Estimates of Covariance Parameters a 
Parameter
Estimate
Std. Error
Wald Z
Sig.
95% Conﬁ dence Interval
Lower Bound
Upper Bound
Repeated Measures
Var: [Index1=1]
61.400
2.004
30.641
.000
57.595
65.456
Var: [Index1=2]
61.448
1.156
53.158
.000
59.224
63.756
Var: [Index1=3]
27.124
1.727
15.708
.000
23.942
30.729
Intercept + orthtime 
[subject = id]
UN (1, 1)
31.503
0.831
37.906
.000
29.915
33.174
UN (2, 1)
4.159
0.566
7.343
.000
3.049
5.269
UN (2, 2)
7.465
0.873
8.547
.000
5.935
9.389
 a Dependent variable: test. 
 TABLE 5.18 Tests of Within-Subjects Contrasts 
Measure:test
Source
Time
Type III Sum of 
Squares
df
Mean Square
F
Sig.
Noncent. 
Parameter
Observed 
Powera
time
Linear
283,779.090
1
283,779.090 4,795.547
.000
4,795.547
1.000
Quadratic
637.493
1
637.493
11.551
.001
11.551
0.925
time * ses
Linear
244.668
1
244.668
4.135
.042
4.135
0.529
Quadratic
1.270
1
1.270
0.023
.879
0.023
0.053
time * 
effective
Linear
47,359.971
1
47,359.971
800.330
.000
800.330
1.000
Quadratic
4,712.361
1
4,712.361
85.386
.000
85.386
1.000
Error(time)
Linear
512,874.459
8,667
59.176
Quadratic
478,319.939
8,667
55.189
 a Computed using alpha = 0.05. 

222  Examining Individual Change with Repeated Measures Data
 linear eﬀ ect*teacher eﬀ ectiveness ,  quadratic eﬀ ect*SES , and  quadratic eﬀ ect*teacher eﬀ ectiveness ). As 
shown in the last column, ﬁ ve of the six eﬀ ects speciﬁ ed are signiﬁ cant, which exactly matches 
the MIXED results in Model 5, as well as the repeated measures within-subject contrasts sum-
marized in  Table 5.18 . 
 Graphing the Results 
 We can summarize the initial diﬀ erence in growth trajectories with a graph of diﬀ erent growth 
rates by teacher eﬀ ectiveness (  Figure 5.8  ). Th e trajectories are best interpreted as not parallel over 
time; that is, the initial observed gap in test learning between students with eﬀ ective and inef-
fective teachers widens over time. Th is graph will look slightly diﬀ erent from the one produced 
in  Repeated Measures  (MANOVA) since there is no control for student SES in the latter graph. 
Th is graph can be produced using the following IBM SPSS commands.  
 TABLE 5.19  Comparing Results of Untransformed Polynomial Models (1–2) and Orthogonal Polynomial 
Models (3–5) with Repeated Measures ANOVA 
Variables
Model 1
Model 2
Model 3
Model 4
Model 5
Within-Subjects 
ANOVA
Intercept
48.632*
47.284*
time
4.719*
2.795*
time quadratic
−0.244*
−0.244*
SES
0.228
effective
2.436*
time*SES
−0.154*
time*effective
3.508*
Intercept
52.945*
49.672*
49.741*
NA
orthtime
4.231*
2.307*
2.409*
*
orth quadratic
−0.081*
−0.081*
−0.414*
*
SES
0.074
0.076
NA
effective
5.944*
5.820*
NA
orthtime*SES
−0.154*
−0.152*
*
orth quadratic*effective
3.508*
3.322*
*
orth quadratic*SES
−0.006
orth quadratic*effective
0.605*
*
AIC
189,123.5
186,832.7
189,125.7
186,834.9
186,758.0
NA
 * p < .05; NA = parameter is not applicable to the ANOVA model. 

Examining Individual Change with Repeated Measures Data  223
 Graphing the Growth Rate Trajectories with SPSS Menu Commands 
  1. Go to the toolbar and select 
GRAPHS, LEGACY DIA-
LOGS, LINE. 
 Th is command will open the  Line 
Charts dialog box. 
 FIGURE 5.8  Individual growth trajectories diﬀ erentiated by teacher eﬀ ectiveness.
  2. In the  Line Charts dialog box, click to select  Multiple . 
 Conﬁ rm that  Summaries for groups of cases is selected. 
 Click the DEFINE button to continue, which will open the  Deﬁ ne 
Multiple Line: Summaries for Groups of Cases dialog box. 

224  Examining Individual Change with Repeated Measures Data
 
 3a. Within the  Deﬁ ne Multiple 
Line: Summaries for Groups 
of Cases dialog box, click to 
select  Other statistic (e.g., 
mean) . 
 
 b. Click to select the variable 
 test from the left column, and 
then click the right- arrow 
button to move  test into the 
 Variable  box. Th e setting 
 MEAN(test) deﬁ nes the use 
of mean values for  test.  
 
 c. Click to select  time from the 
left column. Th en click the 
right-arrow button to move 
the variable into the  Cat-
egory Axis box. 
 
 d. Click to select  eﬀ ective from 
the left column. Next, click 
the right-arrow button to 
move the variable into the 
 Deﬁ ne Lines by box. 
 Click the OK button, which will 
generate the plot graph. 
 Note: Th e resulting plot graph’s 
labels and lines may be edited or 
changed through the  Chart Editor . 
To activate the  Chart Editor , double-
click on the plot graph in the output (Fig. 5.8). 
 Examining Growth Using an Alternative Speciﬁ cation of the Time-Related Variable 
 Since we know that the growth trajectory slows slightly between the second and third measure-
ment occasions, we might consider a diﬀ erent manner of coding the repeated measures to repre-
sent the growth occurring over the entire period under consideration. To determine the growth 
that occurs over the entire trend, we can code the ﬁ rst measurement as 0 and the last one as 1. 
Since the meaning of the slope is the change in  Y for a unit change in  X , coding the time-related 
variable in this manner will capture the growth over the entire trend regardless of whether the 
growth dips or spikes between the beginning and ending intervals. Steps for coding four varia-
tions (i.e.,  timenonlin1 ,  timenonlin2 ,  timenonlin3 , and  timenonlin ) of the time-related variable are 
provided at the end of this section. Th is is similar to the level-and-shape approach discussed pre-
viously for estimating a latent growth factor. With a little trial and error, it is possible to obtain 
a variety of growth curves that may match the actual data quite well. More speciﬁ cally, if we see 
that the relationship is linear (perhaps by inspecting several individuals’ growth trajectories or 
the average individual trajectory), we could code the middle interval as 0.5 (i.e., 0.0, 0.5, 1.0). We 
can then test this hypothesized linear formulation against the data. If we specify the time-related 
variable in this way ( timenonlin1 ), we obtain an AIC coeﬃ  cient of 189,125.5. We provide the 
model syntax in Appendix A. 

Examining Individual Change with Repeated Measures Data  225
 Coding Time Interval Variables (  time to  timenonlin Variations) with IBM SPSS Menu Commands 
 Continue using the  ch5growthdata-
vertical.sav data. 
  1. Go to the toolbar and se-
lect TRANSFORM, RE-
CODE INTO DIFFERENT 
VARIABLES. 
 Th is command will open the  Recode 
into Diﬀ erent Variables dialog box. 
 Note: If continuing from performing 
the prior coding example ( time to  orth-
time or  orthquad ), click the RESET 
button before proceeding to clear the 
default settings. 
 
 2a. Th e  Recode into Dif-
ferent Variables box 
enables creating a 
new variable using 
a variable from the 
current data set. First, 
click to select  time 
from the left column, 
and then click the 
right-arrow button 
to move the vari-
able into the  Input 
Variable  Output 
Variable box. 
 
 b. Now enter the new 
variable name by typ-
ing  timenonlin1 into 
the  Output Variable ,  Name box. 
 
 c. Th en click the CHANGE button, which will add  timenonlin1  and complete the RECODE 
command for  time  timenonlin1 . 
 Note: A warning message appears as  timenonlin1 is an existing variable in the data set. 
 
 d.  Click OK to continue, which will overwrite the preexisting  timenonlin1  variable. If you prefer 
not to overwrite the original variable, rename the output variable (e.g.,  timenonlin1a ). 
 
 e. Click the OLD AND NEW VALUES button, which will then display the  Recode into Diﬀ erent 
Variables: Old and New Values screen. 

226  Examining Individual Change with Repeated Measures Data
  3. Within the  Recode into 
Diﬀ erent Variables: Old and 
New Values dialog box, we 
will begin changing the  time 
values (0, 1, 2) to reﬂ ect 
 timenonlin1 (0, 0.5, 1). 
 
 a. Begin by entering the ﬁ rst 
value for  time ( 0 ) in the 
 Value (old) box. 
 
 b. Next, enter the new value 
( 0 ) for  timenonlin1 in the 
 Value (new) box. 
 
 c. Click the ADD button to 
place the ﬁ rst command  0 
 0 into the  Old  New 
box. 
 
 d. Repeat steps 3a to 3c to 
complete the remaining 
coding changes for  timenonlin1 values: 
 1  0.5 
 2  1 
 Click the CONTINUE button to return to the  Recode into Diﬀ erent Variables main dialog box. 
 Click the OK button to generate the recoded variable  timenonlin1  and corresponding time values (0, 
0.5, 1). 
 Note: To generate variations of  timenonlin , repeat all steps but change the output variable and  Old  
New values as follows: 
 timenonlin2 (0, 0.6, 1) 
 0   0 
 1  0.6 
 2  1 
 timenonlin3 (0, 0.7, 1) 
 0  0 
 1  0. 7 
 2  1 
 timenonlin (0, 0.53, 1) 
 0  0 
 1  0.53 
 2  1 

Examining Individual Change with Repeated Measures Data  227
 Because we have some evidence that the growth is slightly greater between the ﬁ rst and 
second intervals and slows between the second and third intervals, we might instead try cod-
ing the middle interval as 0.6 (i.e., 0.0, 0.6, 1.0). Th is coding will represent a slightly slowing 
trend ( timenonlin2 ). When we code the time variable like this, we obtain an AIC coeﬃ  cient of 
189,157.5 (model syntax is provided in Appendix A). If, instead, we thought the slowing might 
be a bit more extreme, we could code the middle interval as 0.7 (0.0, 0.7, 1.0). In this case ( time-
nonlin3 ), however, we obtain an AIC of 189,335.3 (model syntax is provided in Appendix A). So 
clearly, coding the middle interval as 0.7 does not ﬁ t the data as well as either the ﬁ rst (linear) or 
second (slightly slowing) coding schemes. In   Table 5.20  , we provide the estimates of the linear 
example where we coded the time-related variable as 0.0, 0.5, 1.0. Th e initial status intercept is 
estimated to be 48.725, which is a bit higher than the initial intercept of 48.632 in   Table 5.2  . 
Th e growth over the entire trend is estimated as 8.421. In this case, then, we would estimate the 
ending achievement level as 57.146 (48.725 + 8.421 = 57.146), which is close to the observed 
intercept of 57.094 in   Table 5.2  . Th e linear model estimates in   Table 5.20  , therefore, ﬁ t the data 
quite well.  
 Estimating the Final Time-Related Model 
 We note that the optimal estimate for the middle interval is actually 0.529 (which does suggest 
a bit of slowing over time). We obtained this optimal estimate using SEM software, as the level-
and-shape LCA approach provides the exact, model-estimated parameter for the middle interval 
of the latent growth factor (see comparison in Appendix B). In this ﬁ nal IBM SPSS model, the 
initial intercept was estimated as 48.632, and the time-related estimate ( timenonlin ) was 8.462. 
Th e key modeling changes for this model are illustrated in Model 2.1. If we add those, we obtain 
the intercept estimate for Time 3 in   Table 5.2  (57.094). Th is model also had the lowest AIC 
coeﬃ  cient compared with the other coding schemes. 
 Deﬁ ning Model 2.1 with IBM SPSS Menu Commands 
 Continue using the  ch5growthdata-vertical.sav data. Settings default to those used for Model 1.3. 
  1. Go to the toolbar and select ANALYZE, MIXED MODELS, LINEAR. Th is command enables 
access to the  Linear Mixed Models: Specify Subjects and Repeated dialog box. 
  2. Th e  Linear Mixed Models: Specify Subjects and Repeated box displays the default settings from 
Model 1.3. Place the variables  id and  time within the  Subjects and  Repeated boxes. Th e  Repeated 
Covariance Type is speciﬁ ed as  Diagonal . Click the CONTINUE button to display the  Linear 
Mixed Models dialog box. 
 TABLE 5.20 Estimates of Fixed Effects a 
Parameter
Estimate Std. Error
df
t
Sig.
95% Conﬁ dence Interval
Lower Bound Upper Bound
Intercept
48.725
.097
8,669.000 500.287
.000
48.534
48.916
timenonlin1
8.421
.121
8,669.000
69.589
.000
8.184
8.658
 a Dependent variable: test. 

228  Examining Individual Change with Repeated Measures Data
  3. Th e  Linear Mixed Models dialog box 
displays  test in the  Dependent Variable 
box with  orthtime ,  orthquad ,  ses , and 
 eﬀ ective in the  Covariate(s) box. 
 
 a. Remove all variables from the 
 Covariate(s) box by clicking to 
select them and then clicking the 
left-arrow button. 
 
 b. Click to select  timenonlin , and 
then click the right-arrow but-
ton to move the variable into the 
 Covariate(s) box. 
 Click the FIXED button to access the 
 Linear Mixed Models: Fixed Eﬀ ects dialog 
box. 
 
 4a. Within the  Linear 
Mixed Models: Fixed 
Eﬀ ects dialog box, 
conﬁ rm that  Main 
Eﬀ ects is selected. 
 
 b. Conﬁ rm that  Include 
intercept is selected. 
 
 c. Click to select 
 timenonlin , and then 
click the ADD but-
ton to move it into 
the  Model box. 
 Click the CONTINUE 
button to return to the  Lin-
ear Mixed Models dialog box. 
 Click the RANDOM but-
ton to access the  Linear 
Mixed Models: Random Eﬀ ects dialog box. 

Examining Individual Change with Repeated Measures Data  229
  5. Within the  Linear Mixed 
Models: Random Eﬀ ects  box, the 
covariance type and intercept 
are set to the default settings 
of the prior model. 
 
 a. Th e  Main Eﬀ ects  option is 
preselected. 
 
 b. Click to select  timenonlin  
from the  Factors and Covari-
ates box, and then click the 
ADD button to move the 
variable into the  Model  box. 
 Click the CONTINUE button to 
return to the  Linear Mixed Models 
dialog box. 
 Finally, in the  Linear Mixed Models 
dialog box, click the OK button to 
run the model. 
 Adding the Two Predictors 
 Finally, we add the two between-individual predictors. In this case, we use the optimal estimate 
for Time 2 (0.529). Key modeling changes are illustrated in Model 2.2. 
 Deﬁ ning Model 2.2 with IBM SPSS Menu Commands 
 Continue using the  ch5growthdata-vertical.sav data. Settings default to those used for Model 2.1. 
  1. Go to the toolbar and select ANALYZE, MIXED MODELS, LINEAR. Th is command enables 
access to the  Linear Mixed Models: Specify Subjects and Repeated dialog box. 
  2. Th e  Linear Mixed Models: Specify Subjects and Repeated box displays the default settings from 
Model 2.1. Place the variables  id and  time within the  Subjects and  Repeated boxes. Th e  Repeated 
Covariance Type is speciﬁ ed as  Diagonal . Click the CONTINUE button to display the  Linear 
Mixed Models dialog box. 
  3. Th e  Linear Mixed Models dialog 
box displays the default settings for 
Model 2.1. 
 
 a. Click to select  ses , and then click 
the right-arrow button to move the 
variable into the  Covariate(s) box. 
 
 b. Click to select  eﬀ ective , and 
then click the right-arrow but-
ton to move the variable into the 
 Covariate(s) box. 
 Click the FIXED button to access the 
 Linear Mixed Models: Fixed Eﬀ ects 
dialog box. 

230  Examining Individual Change with Repeated Measures Data
 
 4a. To facilitate read-
ing of the output 
tables, we will 
change the se-
quence order of 
the model vari-
ables. Click to 
select  timenonlin , 
and then click the 
REMOVE button. 
 
 b. Click to select  ses 
and  eﬀ ective , and 
then click the 
ADD button to 
move the variables 
into the  Model box. 
 
 c. Click to select 
 timenonlin , and 
then click the 
ADD button to move it into the  Model box. 
 Two cross-level interactions (or nested terms) will be created and added to the model:  ses*timenonlin 
and  eﬀ ective*timenonlin . Th ese interactions will tell us if the growth trajectories are parallel for diﬀ erent 
groups of students. 
 Add First Interaction to Model 2.2:  ses*timenonlin 
 
 d. Click to select  Build 
nested terms. 
 
 e. Click to select the 
variable  ses  from the 
 Factors and Covari-
ates box. 
 
 f. Th en click the arrow 
button below the 
 Factors and Covari-
ates box. Th is moves 
 ses into the  Build 
Term box to create 
a cross-level inter-
action by linking 
variables and terms. 
 
 g. Next, click the BY* 
button, which will 
insert the compu-
tation command 
symbol:  ses* . 
 
 h. Click to select  timenonlin from the  Factors and Covariates box. 
 
 i. Click the arrow button below the  Factors and Covariates box to move  timenonlin into the  Build 
Term box and complete the interaction term:  ses*timenonlin. 
 
 j. Click the ADD button to transfer the interaction into the  Model box. 

Examining Individual Change with Repeated Measures Data  231
 Add Second Interaction to Model 2.2:  effective*timenonlin 
 
 k. Click to select the vari-
able  eﬀ ective from the 
 Factors and Covariates 
box. 
 
 l. Next, click the arrow 
button below the  Factors 
and Covariates box. Th is 
moves  eﬀ ective into the 
 Build Term box. 
 
 m. Now click the BY* but-
ton, which will insert the 
computation command 
symbol:  eﬀ ective* . 
 
 n. Click to select  timenon-
lin from the  Factors and 
Covariates box. 
 
 o. Click the arrow button 
below the  Factors and 
Covariates box to move  timenonlin into the  Build Term box and complete the interaction term: 
 eﬀ ective*timenonlin. 
 
 p. Click the ADD button to transfer the interaction into the  Model box. 
 Click the CONTINUE button to return to the  Linear Mixed Models dialog box. Finally, click OK to 
run the model. 
 Interpreting the Output From Model 2.2 
 Th e ﬁ xed eﬀ ects for the MIXED solution are presented in   Table 5.21  . Th e adjusted initial status 
intercept is estimated as 47.300. We can see that perceived teacher eﬀ ectiveness aﬀ ects the in-
tercept (2.406,  p  .001). Student SES is again not signiﬁ cantly related to initial status ( p  .05). 
Turning to growth, we can see that the  ses*timenonlin  eﬀ ect is negative and signiﬁ cant (–.308, 
 p  .05), once again suggesting that students with higher SES demonstrated less growth over the 
time of the study. Similar to the polynomial model, we can also note that students with teachers 
who are rated as eﬀ ective demonstrated more growth over time (6.976,  p  .001), compared to 
their peers who rated their teachers as average or ineﬀ ective.  
 TABLE 5.21 Estimates of Fixed Effects a 
Parameter
Estimate
Std. Error
df
t
Sig.
95% Conﬁ dence Interval
Lower Bound Upper Bound
Intercept
47.300
0.145
8,667.000
325.943
.000
47.015
47.584
ses
0.231
0.124
8,667.000
1.856
.063
−0.013
0.475
effective
2.406
0.196
8,667.000
12.302
.000
2.022
2.789
timenonlin
4.637
0.173
8,667.000
26.861
.000
4.298
4.975
ses * timenonlin
–0.308
0.148
8,667.000
–2.084
.037
–0.598
–0.018
effective * 
timenonlin
6.976
0.233
8,667.000
29.989
.000
6.520
7.432
 a Dependent variable: test.   

232  Examining Individual Change with Repeated Measures Data
 We can also save mean predicted values from the ﬁ xed-eﬀ ect model in the data set. In   Figure 
5.9 , we can see that the average predicted trajectory appears to slow a bit between the second and 
third intervals.  
 We also provide the variance components in   Table 5.22  . We can see that there is still signiﬁ -
cant variation in both intercepts and slopes left to be explained between individuals. In this for-
mulation, we note that the covariance between the intercept and slope is signiﬁ cant and negative 
(–6.917,  p = .001). In this case, this negative relationship represents the well-known tendency for 
students who start with higher achievement to demonstrate less growth over time and vice versa. 
We again make the point that it is typically the case in growth modeling that when the coding of 
the growth parameters is changed, the relationship between the intercept and slope also changes.  
 We also draw attention to the fact that this latter solution using SPSS MIXED produces 
results almost identical to the level-and-shape speciﬁ cation estimated using Mplus. We note 
that there are some advantages to deﬁ ning growth models in this manner. One of the main 
advantages is that it is easier to build models on one randomly varying time slope parameter, as 
opposed to sometimes building them on two or more polynomials (depending on the number of 
 FIGURE 5.9  Mean predicted values from nonlinear growth model.
 TABLE 5.22 Estimates of Covariance Parameters a 
Parameter
Estimate
Std. Error
Wald Z
Sig.
95% Conﬁ dence Interval
Lower Bound Upper Bound
Repeated 
Measures
Var: [Index1 = 1]
61.090
2.107
28.993
.000
57.097
65.363
Var: [Index1 = 2]
61.343
1.153
53.212
.000
59.125
63.644
Var: [Index1 = 3]
28.489
1.633
17.450
.000
25.463
31.876
Intercept + 
timenonlin 
[subject = id]
UN (1, 1)
30.968
1.943
15.934
.000
27.384
35.022
UN (2, 1)
–6.917
2.154
–3.211
.001
–11.139
–2.695
UN (2, 2)
28.798
3.506
8.214
.000
22.685
36.559
 a Dependent variable: test.   

Examining Individual Change with Repeated Measures Data  233
random eﬀ ects that can be supported by the repeated measures). Th is alternative to polynomial 
growth models tends to simplify the model-building process. It does, however, take some work in 
ﬁ nding a coding of the time-related variable that is consistent with the observed data. 
 An Example Experimental Design 
 Before we leave the individual growth-modeling approach, we provide an example illustrating 
a comparison of individual growth trajectories using an experimental design. Consider a study 
to examine whether or not students’ participation in a treatment designed to target their deﬁ -
ciencies in solving math problems helps increase their math scores over time. Th e variables are 
summarized in   Table 5.23  . Th e data in this study consist of 55 middle-school students who were 
randomly assigned to either a control ( N = 30) group or a treatment ( N = 25), where they received 
individualized instruction with a math tutor over a semester.  
 Th e students were measured on four occasions (one pretest) regarding their math achievement 
during the period of the study. Th e design is speciﬁ ed as follows: 
 R 
O 1 
O 2 
O 3 
O 4 
 R 
O 1 X 
O 2 
O 3 
O 4 
 Th e Rs refer to random assignment. Fixed eﬀ ects include the treatment (coded = 1) versus con-
trol (coded 0), time (coded 0–3 for the four occasions), and the treatment-by-time interaction. 
 TABLE 5.23  Data Deﬁ nition of  ch5experimentaldesigndata.sav ( N = 55) 
Variable
Levela
Description
Values
Measurement
id
Individual
Student identiﬁ er (55 students across four time 
[test] occasions).
Integer
Ordinal
treatment
Individual
Two-category predictor variable representing 
students assigned for nontreatment (control) or 
treatment. 
0 = No Treatment, (No 
Tutor),1 = Treatment 
(Tutored)
Scale
time
Within 
Individual
Variable representing four linear occasions in time 
(0, 1, 2, 3) measuring students math achievement.
0 = First Time, 1 = Second 
Time, 2 = Third Time, 3 = 
Fourth Time 
Scale
timenonlin Within 
Individual
Recoded time variable from four occasions in 
time (0, 1, 2, 3) into a time sequence variation 
representing the whole four time occasions (0.00, 
0.50, 0.70, 1.00) measured from 0 to 1.
0.00 = First Time, 0.50 = 
Second Time, 0.70 = Third 
Time, 1.00 = Fourth Time 
Scale
math
Within 
Individual
The dependent variable representing each 
students individual scores on the repeated math 
measurements.
523 to 856
Scale
orthtime
Within 
Individual
Recoded time variable from four occasions in time 
(0, 1, 2, 3) into a different time sequence (–3, –1, 
1, 3).
–3 = First Time, –1 = 
Second Time, 1 = Third 
Time, 3 = Fourth Time
Scale
orthquad
Within 
Individual
Recoded time variable from four occasions in time 
(0, 1, 2, 3) into a time sequence 
variation(1, –1, –1,1).
1 = First Time, –1 = 
Second Time, –1 = Third 
Time, 1 = Fourth Time
Scale
orthcubic
Within 
Individual
Recoded time variable from four occasions in time 
(0, 1, 2, 3) into a time sequence variation 
(–1, 3, –3,1).
–1 = First Time, 3 = 
Second Time, –3 = Third 
Time, 1 = Fourth Time
Scale
 a Individual = Level 2; Within individual = repeated measures, Level 1.   

234  Examining Individual Change with Repeated Measures Data
Th e initial O 1 coeﬃ  cients refer to students’ initial status achievement. We expect no initial diﬀ er-
ence between the treatment and control groups. Th is is captured by the relationship between the 
treatment variable and the students’ initial status intercept at the beginning of the study (where 
time is coded 0). After implementing the treatment after the initial pretest measurement, we 
propose that the treatment group will increase more in math achievement over time than the 
control group. Th is will be tested by a treatment-by-time interaction; that is, we would expect 
diﬀ erent growth trends for the control and treatment groups. 
 We can specify the Level 1 model for individual  i measured at time occasion  t as follows: 
 
  Y ti  =  π 0 i  +  π 1 i  time ti  +   ti  . 
(5.22) 
 Since the time period for the study is short (i.e., one semester), we might assume a linear model 
as ﬁ tting reasonably well. We note that we could ﬁ t the model to a higher order polynomial 
function. One complication with that approach, however, is that transforming higher order poly-
nomials will shift the intercept to the grand mean. Th is will obscure the achievement level where 
each group started before the intervention. We illustrate the two diﬀ erent growth trajectories 
in   Figure 5.10  . Th e ﬁ gure suggests that the two groups are close before the treatment begins 
(Time 0). We can see that the treatment growth is closer to a linear growth model over time; 
however, the control group deﬁ nitely slows in its progress over the semester. 
 We ﬁ rst provide results using the model with time speciﬁ ed as linear to describe growth over 
the short period of time of the study. At Level 2, we assume that the intercept varies between 
subjects: 
 
  π 0 i  =   00 +   01 treatment i  +  u 0 i  . 
(5.23) 
 FIGURE 5.10  Examining treatment and control growth trends.

Examining Individual Change with Repeated Measures Data  235
 We will also model that the time slope is randomly varying: 
π 1 i  =   10 +   11 treatment i  +  u 1 i  . 
(5.24) 
 After substituting the Level 2 equations into the Level 1 equation, the combined model will then 
be the following: 
 
  Y ti  =   00 +   01 treatment i  +   10 time ti  +   11 time ti  * treatment i  +  u 1 i  time ti  +  u 0 i  +   ti  . 
(5.25) 
 We can see that the key parameter in this simple illustration is the  time*treatment  interaction. 
Th is is used to determine if there are diﬀ erent growth trajectories for individuals in the treat-
ment and control groups. We will also specify a diagonal matrix for the residual error structure 
at Level 1: 
 


2
1
0
0
0



1
2
0
0
0





1
0
0
0



2
0
0
0
2
2




2
0
0
0
2


2
0
0
0
2




2


3
0
0
0
3




0
0
0


2
0
0
0







4
0
0
0
 
4
 0
0
0

 
(5.26) 
 At Level 2, we will specify an unstructured covariance matrix: 
 
 


2
1 2


2
1 1


1,1
1,2
2
 1 1




1 2
 1 1


2






2


,
,




2,1
2,2


2 1
 
(5.27) 
 We present the ﬁ xed-eﬀ ects estimates in   Table 5.24  and syntax to replicate the analysis in Ap-
pendix A. We note in passing that we investigated several diﬀ erent covariance structures for the 
Level 1 repeated measures, but we decided to stay with a diagonal structure, which ﬁ t slightly 
better than the simple scaled identity covariance structure since the within-subject covariance 
structure was really not the focus of the study. Th e ‒2LL for this model with 11 parameters was 
2,054.67, and the AIC was 2,068.67.  
 Th e ﬁ xed-eﬀ ect estimates suggest that the students in the control group started with a mean 
score of 609.057. Th is linear model seems to slightly overestimate the control group’s starting 
achievement in   Figure 5.10  (as well as its ending achievement). Over each interval, individuals’ 
 TABLE 5.24 Estimates of Fixed Effects a 
Parameter
Estimate
Std. Error
df
t
Sig.
95% Conﬁ dence Interval
Lower Bound Upper Bound
Intercept
609.057
6.636
51.556
91.782
.000
595.738
622.376
time
23.813
2.500
47.331
9.525
.000
18.785
28.842
treatment
0.664
9.843
51.556
0.067
.946
–19.091
20.419
time * 
treatment
12.996
3.708
47.331
3.505
.001
5.538
20.454
a Dependent variable: math.   

236  Examining Individual Change with Repeated Measures Data
scores in the control group increased by 23.813 points on average. We can also conﬁ rm that there 
was no diﬀ erence between the treatment and control groups initially (  = 0.664,  p = .946). Over 
time, however, we can observe that students who received the targeted intervention increased 
their scores over each interval at a greater rate (12.996 points) than their peers in the control 
group. 
 We present the covariance parameter estimates in   Table 5.25  . We can see that the correlation 
between initial status and growth was negative (–0.266), suggesting that students who started 
higher in achievement demonstrated a bit less growth over time (and vice versa), but it was not 
signiﬁ cant ( p > .05). 
 One problem with this speciﬁ cation, however, is that we do not take in the curvilinear nature 
of the growth occurring over time. Alternatively, as we mentioned earlier, if we were to treat the 
time variable as categorical, we could also specify the model to determine the diﬀ erence between 
treatment and control group at  each occasion, instead of assuming a polynomial growth curve over 
the entire temporal sequence. Th is model, summarized in   Table 5.26  , ﬁ ts the data slightly better 
than the previous one, using AIC as an index of model ﬁ t (2,013.91 to 2,068.67, respectively). 
 TABLE 5.25 Estimates of Covariance Parameters a 
Parameter
Estimate
Std. Error
Wald Z
Sig.
95% Conﬁ dence Interval
Lower Bound Upper Bound
Repeated 
Measures
Var: [time = 0]
305.773
188.462
1.622
.105
91.362
1,023.373
Var: [time = 1]
421.087
104.377
4.034
.000
259.048
684.485
Var: [time = 2]
150.015
55.704
2.693
.007
72.454
310.604
Var: [time = 3]
251.289
118.592
2.119
.034
99.646
633.701
Intercept + 
time [subject 
= id]
Var(1)
1,099.161
290.476
3.784
.000
654.807
1,845.054
Var(2)
131.754
37.409
3.522
.000
75.523
229.851
Corr(2, 1)
–0.266
0.179
–1.480
.139
–0.572
0.106
 a Dependent variable: math. 
TABLE 5.26 Estimates of Fixed Effectsa
Parameter
Estimate
Std. Error
df
t
Sig.
95% Conﬁ dence Interval
Lower Bound Upper Bound
Intercept
674.900
8.595
94.019
78.524
.000
657.835
691.965
[time = 0]
–75.286
6.832
58.889
–11.019
.000
–88.958
–61.614
[time = 1]
–25.400
6.412
51.339
–3.961
.000
–38.270
–12.530
[time = 2]
–16.167
7.879
74.257
–2.052
.044
–31.864
–0.469
[time = 3]
0.000b
0.000
.
.
.
.
.
Treatment
46.220
12.748
94.019
3.626
.000
20.908
71.532
[time = 0] * treatment
–38.685
10.134
58.889
–3.817
.000
–58.964
–18.405
[time = 1] * treatment
–40.480
9.510
51.339
–4.256
.000
–59.569
–21.391
[time = 2] * treatment
–24.033
11.686
74.257
–2.057
.043
–47.317
–0.750
[time = 3] * treatment
0b
0
.
.
.
.
.
 a Dependent variable: math. 
 b This parameter is set to 0 because it is redundant.   

Examining Individual Change with Repeated Measures Data  237
 In this case, since IBM SPSS uses the last category of  time  as the reference group, we now have 
the intercept deﬁ ned as “ending” math achievement status (674.900) for the control group (coded 
0). Th is ending achievement level for the control group is consistent with   Figure 5.10 . Th e treat-
ment group would be estimated as 721.120. We can see that students demonstrated considerable 
(but diﬀ ering) growth at each time occasion as represented by the  time eﬀ ects. Th e time coeﬃ  -
cients refer to how much lower the control group was at each interval preceding the ending status 
intercept. We can use the coeﬃ  cients to estimate achievement for each group at any occasion. For 
example, the control group’s achievement at the beginning of the study will be 674.900–75.286, 
or 599.614. As we might expect,   Table 5.26  also suggests that growth for the control group 
slows considerably over successive intervals. We can also note that at the  end  of the study, there 
is a positive eﬀ ect for being in the treatment group (46.220,  p  .001). We can also see that the 
amount of diﬀ erence at each occasion between the treatment and control groups, which is mod-
eled as the  time*treatment interactions, is signiﬁ cant for each occasion ( p  .05). In this case, the 
coeﬃ  cients for each interaction suggest a diﬀ ering achievement “advantage” for the treatment 
group at each of the preceding intervals, rather than assuming a  constant linear  eﬀ ect over time, as 
summarized in   Table 5.24  . Th e information about the treatment can be used along with the other 
relevant time-related information to calculate where the treatment group is at any occasion in the 
study. Th e pattern of results observed in   Table 5.26  reﬂ ects the diﬀ erent coding scheme between 
using initial status in the previous model (see   Table 5.24  on page 235, where there was no diﬀ er-
ence between the two groups) and ending status (  Table 5.26 ), where it is obvious in   Figure 5.10  
that there is considerable diﬀ erence in achievement between the treatment and control groups. 
 We also provide results using an alternative coding for time in   Table 5.27  . In this case, we de-
ﬁ ned the time-related variable as 0, 0.5, 0.7, 1.0 ( timenonlin ), in order to capture the change tak-
ing place over the whole study. Th is is one way we can easily deal with the curvilinear shape of the 
average growth trajectories in each group. We can simply substitute  timenonlin  for  time in Equa-
tion 5.22. Th is solution has the advantage of having an initial status (602.058) for the control 
group and illustrates that the treatment growth was not signiﬁ cantly diﬀ erent at the beginning 
of the study (3.217,  p = .742). Over the time period studied, the treatment group demonstrated 
considerably higher growth compared to the control group (31.428,  p  .01). Th e covariance pa-
rameters were similar to the previous linear growth model in   Table 5.25  , so we do not reproduce 
them here. We note also that this model ﬁ t better than the ﬁ rst model summarized in   Table 5.27  
(AIC = 2,048.35 to 2,068.67, respectively), but not as well as the previous model summarized in 
 Table 5.26  (AIC = 2,048.35 to 2,013.91, respectively). Substantively, however, all three models 
provide the same interpretation regarding the positive eﬀ ect of the educational treatment under 
consideration. At the end of the study, for example, we would estimate the math achievement 
of the control group as 602.058 + 79.072, or 681.130. We would estimate the treatment group’s 
math achievement as 602.058 + 3.217 + 79.072 + 31.428, or 715.775. 
 Th ese are slightly diﬀ erent from the previous model but certainly consistent with it substan  -
tively.  
 TABLE 5.27 Estimates of Fixed Effectsa
Parameter
Estimate
Std. Error
df
t
Sig.
95% Conﬁ dence Interval
Lower Bound Upper Bound
Intercept
602.058
6.552
50.555
91.885
.000
588.901
615.215
timenonlin
79.072
6.738
47.201
11.735
.000
65.518
92.626
treatment
3.217
9.719
50.555
0.331
.742
16.298
22.732
timenonlin * 
treatment
31.428
9.995
47.201
3.145
.003
11.324
51.532
 a Dependent variable: math.   

238  Examining Individual Change with Repeated Measures Data
 Summary 
 In this chapter, we presented a basic two-level model for investigating individual change. Lon-
gitudinal analysis represents a rapidly growing application of basic multilevel-modeling tech-
niques. In comparison to ANOVA, we suggested that multilevel modeling of growth trajectories 
is a more ﬂ exible approach because of its ability to handle a wide range of data situations (incom-
plete data and varying occasions of measurement). Th e model provides considerably more infor-
mation about students’ initial status and growth rates. Th e individual growth model can easily 
be extended to include successive grouping structures above the individual level. We investigate 
models with individual and group components in the next chapter. As we noted previously in this 
chapter, there are a considerable number of ways to investigate changes in individuals over time. 
We provided several diﬀ erent coding possibilities throughout the chapter. We encourage readers 
to consult a number of introductory sources that provide overviews of the assumptions, uses, and 
programming of longitudinal models (e.g., Duncan, Duncan, & Strycker, 2006; Raudenbush, 
Bryk, Cheong, & Congdon, 2004; Raykov & Marcoulides, 2008; Singer & Willett, 2003).   

239
 CHAPTER 6 
 Applications of Mixed Models 
for Longitudinal Data 
 I
n this chapter, we expand on our introduction to methods that can be used to examine changes 
in individuals over time. As we noted in the last chapter, time is often a key factor in under-
standing how developmental processes may unfold, as well in observing their impact. Longitu-
dinal data collection facilitates the investigation of proposed relationships whose eﬀ ects become 
more apparent over time. Presently, there is a wider set of options available for including a tem-
poral dimension in studies, depending on the speciﬁ c goals of the research and the data structure 
used to investigate proposed theoretical models. We saw in the last chapter that the mixed-model 
approach for examining individual change is quite straightforward for repeated measures that 
are continuous. We examined growth in students’ achievement scores related to diﬀ erences in 
their backgrounds and the perceived eﬀ ectiveness of their teachers. In such two-level models of 
growth, the unit of analysis is the individual student. If we had linked students to their teachers 
or to their schools, this would have necessitated a third level in the model. In fact, if we included 
both teachers and schools, we would require a four-level model to examine variability in their 
achievement—with diﬀ erences likely due to within-individual growth rates, between-individual 
variables, between-teacher variables, and between-school variables. SPSS MIXED can actually 
facilitate this type of complex analysis, although it may take a considerable amount of time and 
some eﬀ ort to reduce the computer space it takes to complete the analysis. 
 In this chapter, we consider several useful research applications of the two-level growth model 
provided in the last chapter. First, we extend the basic two-level growth model to include a 
grouping structure as a third level. Second, we provide an example of a multilevel formulation of 
a regression discontinuity design, which can be used to investigate the eﬀ ect of an intervention 
in a treatment versus a control group. Th is research design is useful in examining changes that 
occur as a result of an intervention when prior random assignment of individuals to groups is 
not possible. In this case, we use an assessment of math skills as a means of assigning individuals 
to the treatment and control groups and then examine the eﬀ ects of the treatment on students’ 
subsequent achievement. Th ird, we develop a piecewise growth model, which provides a means of 
examining two or more diﬀ erent growth trends within one model. In this illustration, we develop 
a model to investigate institutional trends in admitting freshman student athletes before and 
after a policy to raise admission standards is introduced. 
 Examining Growth in Undergraduate Graduation Rates 
 Consider a national study to investigate whether undergraduate degree completion levels are 
rising over time. In this example, we will consider an application of random-coeﬃ  cients growth 
modeling to examine between-state diﬀ erences in the proportion of undergraduates who graduate 

240  Applications of Mixed Models for Longitudinal Data 
from public universities and changes in the proportion of graduates over an 11-year period. In our 
example study, summarized in   Figure 6.1  , the within-subjects data (Level 1) consist of repeated 
measures on the proportion of undergraduate students who graduate nested within institutions. 
Th e between-subjects data (Level 2) consist of institutional variables that may explain diﬀ erences 
in graduation levels between institutions, and the group-level data (Level 3) consist of state-level 
information such as ﬁ nancial resources appropriated to support public higher education. 
 Research Questions 
 Th e three-level growth formulation facilitates investigating a number of diﬀ erent types of mul-
tilevel relationships. As the ﬁ gure indicates, within institutions (Level 1), we can examine rela-
tionships involving various time-varying covariates that might inﬂ uence institutional graduation 
rates over time. Time-varying covariates provide a way of accounting for temporal variation in 
predictors that may increase (or decrease) the value of an outcome predicted by the individual’s 
growth trajectory (Raudenbush & Bryk, 2002). For example, we could focus on how ﬂ uctuation 
in tuition levels might aﬀ ect graduation rates. Other examples of time-varying covariates that 
might inﬂ uence graduation rates include the proportion of the institution’s budget allocated to 
instructional support or the proportion of students receiving ﬁ nancial aid. 
 In contrast, we could consider the time-varying covariates as “static” variables (i.e., the aver-
age tuition level or the average proportion receiving ﬁ nancial aid), which requires only one value 
for the covariate. In this type of formulation, we would enter the static covariate as a between-
institution variable (i.e., Level 2). We note, however, that one of the advantages of the Level 1 
(time-varying) formulation is that the slope of the time-varying covariate (e.g., institutional 
tuition) on graduation rates can then be modeled as a random parameter at Level 2 (between 
institutions) and perhaps at Level 3 (between states). In the conceptual model, possible cross-
level interactions are shown with arrows extending from a higher level to a lower level. For 
example, we might propose that diﬀ erences in student selectivity moderate the eﬀ ect of resources 
spent to support student learning on graduation rates, or that diﬀ erences in student composition 
moderate the eﬀ ect of student tuition on graduation rates. 
 Between institutions (Level 2), we can investigate how various institutional characteristics 
(e.g., mission, selectivity of admissions, student composition, and faculty characteristics) are 
related to graduation rates or changes in graduation rates over time. As noted previously, we 
could also investigate a random covariate–outcome slope that might be of theoretical interest 
(e.g., tuition–graduation rate or ﬁ nancial aid–graduation rate). Finally, at the state level (Level 3), 
we can examine how diﬀ erent patterns of state economic and political activity might aﬀ ect grad-
uation outcomes. For example, we might examine how family share of higher education costs or 
legislative appropriation for higher education is related to graduation rates and change in gradu-
ation rates over time. We could also examine whether a particular type of state higher education 
policy (such as merit-based tuition support) might inﬂ uence graduation rates. 
 Th e multilevel model implies several research questions such as the following: 
 What is the average level and shape of institutions’ graduation trajectories over time? 
 Which within- and between-institutional variables explain institutional graduation levels? 
 How do graduation trajectories vary according features of states? 
 The Data 
 In this example, we focus on a subset of data from a larger study of ﬁ nancing public higher edu-
cation and changes in student graduation rates over time (Heck, Lam, & Th omas, 2012). Th e 
subset consists of undergraduate (6-year) graduation rates from 649 public 4-year institutions 
within the 50 states. Th e graduation rates were compiled over an 11-year period. Th e variables in 
the example are summarized in Table 6.1. 

 TABLE 6.1  Data Deﬁ nition of  ch6graduationdata.sav ( N  8,670) 
Variable
Levela
Description
Values
Measurement2
id
Within Individual
Student identiﬁ er (8,670 students).
Integer
Ordinal
Rid
Within Individual
A within-group level identiﬁ erb 
representing a sequential identiﬁ er for 
each student within 649 schools within 
11 time periods within 50 states.
1 to 46
Ordinal
state
State
State identiﬁ cation number.
Integer
Ordinal
time
Within Individual
Variable representing 11 linear 
occasions (years) in time measuring 
undergraduate graduation rates.
0  Time 0
1  Time 1
2  Time 2
3  Time 3
4  Time 4
5  Time 5
6  Time 6
7  Time 7
8  Time 8
9  Time 9
10  Time 10
Scale
quadtime
Within Individual
Recoded time variable from 11 
occasions in time (0, 1, 2,...,10) into 
a “squared” quadratic time sequence 
(0.1,4,...,100) to capture any changes 
(acceleration or deceleration) in the 
rate of change that might occur over 
the 11 measurement occasions.
0  Time 0
1  Time 1
4  Time 2
9  Time 3
16  Time 4
25  Time 5
36  Time 6
49  Time 7
64  Time 8
81  Time 9
100  Time 10
Scale
 FIGURE 6.1  Proposed three-level graduation trajectory model. 
(Continued)

242  Applications of Mixed Models for Longitudinal Data 
 TABLE 6.1 (Continued)
Variable
Levela
Description
Values
Measurement2
time1
Within Individual
Recoded time variable from 11 
occasions in time (0, 1, 2,...,10) into a 
time sequence variation that captures 
the whole 11-year period of time 
measured from 0 to 1.
0.00  Time 0
0.10  Time 1
0.20  Time 2
0.30  Time 3
0.40  Time 4
0.50  Time 5
0.60  Time 6
0.70  Time 7
0.80  Time 8
0.90  Time 9
1.00  Time 10
Scale
quadtime1
Within Individual
Recoded time variable from 11 
occasions in time (0, 1, 2,...,10) into 
a “squared” quadratic time sequence 
that captures the whole 11-year period 
of time measured from 0 to 1.
0.00  Time 0
0.01  Time 1
0.04  Time 2
0.09  Time 3
0.16  Time 4
0.25  Time 5
0.36  Time 6
0.49  Time 7
0.64  Time 8
0.81  Time 9
1.00  Time 10
Scale
gradproportion
School
Proportion of graduating students.
0.00 to 1.00
Scale
mathselect
Within Individual
Predictor interval variable (z-score) 
measuring percentage of students 
admitted with SAT or ACT math scores 
in the 75th percentile or above.
−2.30 to 2.94
Scale
percentFinAid
Within Individual
Predictor interval variable (z-score) 
measuring the percentage of students 
within schools receiving ﬁ nancial aid.
−5.69 to 1.67
Scale
tuition
Within Individual
Predictor interval variable (z-score) 
measuring the average tuition level at 
the school.
−1.57 to 1.64
Scale
percentFTfaculty
School
Predictor interval variable (z-score) 
measuring percentage of full-time 
faculty.
−3.56 to 1.83
Scale
aveRetention
State
Predictor interval variable (z-score) 
measuring average percentage of 
freshman retained in the state.
−2.76 to 1.55
Scale
aveFamilyshare
State
Predictor interval variable (z-score) 
measuring the percentage share 
that families have to pay for higher 
education in the state.
−2.41 to 1.87
Scale
 a Within individual schools  Level 1; School  Level 2; State  Level 3. 
 b Results from ranking student cases ( id ) with the school group identiﬁ er (not tabled). 
2 Measurement icon settings displayed in subsequent model screenshots may differ from Tables 6.1, 6.14, and 6.19 
but will not affect the output.
 Deﬁ ning the Model 
 In modeling changes in institutional graduation rates over time, we assume that a number of 
institutions have been sampled and measured on one or more variables over several occasions. 

Applications of Mixed Models for Longitudinal Data   243
Because multilevel modeling does not require balanced data, it is not a problem if all measure-
ments are not available on all participants. Th is model can be extended to include situations 
where the timing and spacing of the measurements diﬀ er across participants. As we illustrated 
in the last chapter, in random-coeﬃ  cients growth modeling, within- and between-individual 
changes are typically represented through a two-level univariate model (see also Hox, 2010; 
Raudenbush & Bryk, 2002; Singer & Willett, 2003). A third level (and successive levels) can be 
added to model changes between higher order units. 
 Level 1 Model 
 Th e Level 1 part of the model represents the change each member of the population is expected 
to experience during the time period under study (Singer & Willett, 2003). In this case, each 
institution’s successive graduation measurements can be represented by an individual growth tra-
jectory (or growth curve) and random error. Following Raudenbush and Bryk’s (2002) notation, 
the systematic growth for each individual can be represented as a polynomial of degree  P , with 
the Level 1 model for the proportion of undergraduates who graduate at time  t for institution  i 
in state  j written as 
 
2
0
1
2
,
P
tij
ij
ij
tij
ij
tij
pij
til
tij
y
a
a
a




	





 
 (6.1) 
 where  π 0 ij  is the intercept parameter (which is deﬁ ned as the level of the institution’s “true” 
status at some relevant point in the series of measurement occasions);  a tij  is a time-varying 
variable of interest, with individual  i measured on  t occasions; and  π pij  is the growth trajec-
tory parameter  p for subject  i in group  j associated with the polynomial of degree  P (i.e., 
 p  0, . . . ,  P ). One or more time-varying covariates ( X t  ) can also be added to the Level 1 
model as needed. 
 Th e growth (slope) parameters are the most important parameters because they represent 
the rate at which institution  i within state  j changes over time. Th e polynomial curves facili-
tate the representation of several diﬀ erent growth trajectories including, for example, linear 
( a ), quadratic ( a 2 ), and cubic ( a 3 ). In terms of interpretation, however, if one considers that 
the linear trajectory model represents a  constant rate of change over time and the quadratic 
trajectory models represent  change (accelerating or decelerating) in the rate of change over 
time, it becomes increasingly more diﬃ  cult to interpret models of higher polynomial de-
grees. Th e speciﬁ cation of the general Level 1 model implicitly assumes that all the change 
trajectories have a common algebraic form, but not every individual institution has the same 
trajectory (Singer & Willett, 2003). Each institution, therefore, draws its parameter values 
(i.e., intercept and slope) from an unknown (underlying) bivariate distribution of intercepts 
and slopes. 
 As we noted in the last chapter, a simple error structure is often assumed for     tij  , represented as 
 
      tij  ~  N (0,      2  ), 
(6.2) 
 which suggests that the errors are independent and normally distributed ( N ), with a mean of 
0 and constant variance across time (Raudenbush & Bryk, 2002). Th e residual variance param-
eter (    2  ) represents the variation in residuals around each individual institution’s true change 
trajectory (Singer & Willett, 2003). Restrictions about the residuals can be relaxed, however. 
We reiterate that other types of repeated measures covariance structures (e.g., autocorrelated) can 
be considered where there are many measurements per subject. 

244  Applications of Mixed Models for Longitudinal Data 
 Level 2 Model 
 At Level 2, a set of between-institution predictors (e.g., student selectivity and student com-
position) can be added to the model to explain variation in institutions’ intercepts (often de-
ﬁ ned as initial status) and growth rates. Speciﬁ cally, for each of the  P + 1 individual growth 
parameters, 
 
 
0
1
,
Qp
pij
p
j
pq
qij
pij
q
X
r








 
(6.3) 
 where  X qij  might include institutional characteristics,   pq  represents the eﬀ ect of  X qij  on the  p th 
growth parameter, and  r pij  is a matrix of random eﬀ ects. Th e set of  P + 1 random eﬀ ects for insti-
tution  i can be contained in one of several diﬀ erent types of covariance matrices at Level 2. Th e 
exact dimensionality of this covariance matrix depends on the number of random Level 2 coef-
ﬁ cients in the model. Common choices are diagonal, with variances for random eﬀ ects only and 
no covariances between intercepts and slopes, or a completely unstructured covariance matrix, 
with variances for each random eﬀ ect and covariances between each pair of random eﬀ ects. If the 
choice is an unstructured covariance matrix, it is dimensioned ( P + 1) × ( P + 1) and is assumed 
to be multivariate normally distributed, with means of 0, and some variances and covariances 
between Level 2 residuals. 
 Level 3 Model 
 At Level 3, we can model diﬀ erences in growth between states using the general modeling 
framework to examine variation in the Level 2 random intercept (  p  0 ) and slope (  pq  ) parameters. 
Th e model deﬁ ning Level 3 relationships can be written as: 
 
0
1
,
pq
S
pqj
pq
pqs
sj
pqj
s
W
u








 
 (6.4) 
 where   pq  0 is the intercept for the state-level model,  W sj  represents predictors such as level of state 
resources for public higher education,   pq  s represents structural parameters for the Level 3 predic-
tors, and  u pqj  represents the state-level random eﬀ ects. Th ere are also similar choices regarding 
the covariance matrix of residuals from the Level 3 equations (e.g., diagonal and unstructured). 
Similarly, the dimensionality of the covariance matrix at Level 3 depends on the number of ran-
dom coeﬃ  cients at that level. 
 Figure 6.2  summarizes the average of the institutional graduation rates over time, without 
regard to the nesting of institutions within states. One can see from the ﬁ gure that public under-
graduate graduation rates appear to increase over the decade by about 4%. 
 We next provide a small sample of eight individual states’ trajectories in   Figure 6.3  . Readers 
who wish to develop this graph can do so by using the “select if” command and then deﬁ ning 
the subset ( stateid > 15 &  stateid < 24). Th ere is one state trajectory considerably higher than 
the others in this subset. In general, however, it appears that most of the individual trajectories 
increase slightly over time. 
 Th e ﬁ rst concern in the analysis is whether there is any signiﬁ cant change in graduation rates 
that took place over the period studied. For example, it might be that there was no increase in 
graduation rates over time. Second, we might want to examine possible diﬀ erences in institutions’ 
and states’ graduation rates over time due to their resources (e.g., tuition levels and percentages 
of students receiving ﬁ nancial aid), institutional characteristics (selectivity and faculty character-
istics), and state characteristics (e.g., average student retention rates and family share of higher 
education). 

Applications of Mixed Models for Longitudinal Data   245
 FIGURE 6.2  Public institutional graduation level rates over time. 
 FIGURE 6.3  Graduation rates for selected states. 
 The Null Model: No Predictors 
 As we noted in the last chapter, it is possible to examine an  unconditional means  model ﬁ rst—that 
is, a simple model consisting only of the repeated measurements of  y tij  without the time-related 
parameter. Th is model can be used to partition the variance in the grand-mean estimate into its 
within-individual and between-individual components, regardless of time (see Singer & Willett, 
2003, for further discussion). Th ese components can be used to calculate an intraclass correlation 
(ICC). We begin with a simple unconditional model to examine the variance decomposition of 
graduation rates across levels of the data hierarchy: 

246  Applications of Mixed Models for Longitudinal Data 
 
  y tij    π 0 ij  +   tij  , 
(6.5) 
 where  y tij  is the graduation proportion for institution  i in state  j measured at time point  t . Th e 
intercept is  π 0 ij  , and   tij  is the error term. At Level 2, the model is 
 
  π 0 ij     00 j  +  r 0 ij  , 
(6.6) 
 where   00 j  is the intercept, and we will use  r 0 ij  as the error term for the between-individuals model. 
At Level 3, the model is 
 
  00 j     000 +  u 00 j  , 
(6.7) 
 where   000 is the intercept and  u 00 j  is the error in equations at Level 3. 
 For this ﬁ rst “no-predictors” model (i.e., with no time-related variable speciﬁ ed), we can 
examine the decomposition of variance in graduation rates associated with diﬀ erences within 
institutions, between institutions, and between states. Th e proportion of variability (intraclass 
correlation) in outcomes at Level 3 is deﬁ ned as 
 
2
2
2
2
3
1
2
3
/ (
)
Level
Level
Level
Level








 
 (6.8) 
 For Level 2, the ICC would be 
 
2
2
2
2
2
1
2
3
/ (
)
Level
Level
Level
Level








 
 (6.9) 
 and for Level 1, the ICC would be 
 
2
2
2
2
1
1
2
3
/ (
)
Level
Level
Level
Level








 
 (6.10) 
 We remind readers that this ﬁ rst estimate of the variance in graduation rates at each level 
of the data hierarchy is approximate only, owing to estimation assumptions about sampling 
variability made in the initial estimates of variance at each level (Hox, 2010; Snijders & 
Bosker, 1994). 
 Level 1 Error Structures 
 Th e Level 1 residuals (  tij  ) represent the variability in measuring individual-level outcomes at 
each occasion. Th ey are typically assumed to be independent, normally distributed, and with 
mean of 0 and common variance ( 2  ). For repeated measures models, MIXED has a variety of 
diﬀ erent error structures that can be considered. Th e default Level 1 structure in MIXED is a 
diagonal covariance matrix with heterogeneous variances in the diagonals for each measurement 
occasion, which has no oﬀ -diagonal covariances between occasions. Using just the ﬁ rst four oc-
casions for ease of presentation, the diagonal Level 1 covariance matrix would look like the fol-
lowing (with variances 
2
1
  to 
2
4
  in the diagonals and 0s representing ﬁ xed covariances between 
occasions): 

Applications of Mixed Models for Longitudinal Data   247
 
2
1
2
2
2
3
2
4
0
0
0
0
0
0
0
0
0
0
0
0


















 
  (6.11) 
 Compound symmetry (CS) assumes one equal variance across all occasions and one equal 
covariance between pairs of covariances. As we suggested in the last chapter, with a linear lon-
gitudinal model with random intercept only, this amounts to accepting homogeneity of variance 
over the repeated measures similar to the repeated measures analysis of variance (RM-ANOVA) 
formulation. At the other end of the spectrum, we could consider an unstructured (UN) covari-
ance matrix, which assumes heterogeneous variances for each occasion and heterogeneous 
covariances for pairs of occasions. Th is may be overly complex, however, in many research situa-
tions since it results in the calculation of many variances and covariances, which might not be of 
real substantive interest. 
 Another choice for repeated measures is an autoregressive covariance structure. Since we have 
reason to believe there are covariances between the oﬀ -diagonal elements in the matrix, we might 
try either a heterogeneous ﬁ rst-order autoregressive structure (i.e., with separate variances in the 
diagonals and covariances in the oﬀ -diagonals) or the more simpliﬁ ed ﬁ rst-order autoregressive 
structure with constant diagonal variance and an oﬀ -diagonal covariance. Once again, using 
the ﬁ rst four occasions as an example, we have the following (where |    | ≤ 1): 
 



























2
3
2
2
2
3
2
1
1
1
1
 
 (6.12) 
 Th e ﬁ rst-order autoregressive covariance structure therefore requires the estimation of two 
parameters (i.e., one variance and one autocorrelation). Equation 6.12 implies that the size of 
the covariance between the repeated measures depends on the number of steps between occa-
sions; that is, the strength of the relationship diminishes as the distance between measurements 
increases. Th is provides an advantage over the compound symmetry repeated measures speciﬁ ca-
tion, especially where there are more repeated measures in the study. 
 We investigated several diﬀ erent covariance structures for the repeated-measures estimates 
at Level 1. We can use restrict	 !"imum likelihood (REML) estimation to examine the ﬁ t 
of various structures since we are only comparing diﬀ erences in variance components. Because 
there are 11 years of measurements, it is quite likely that there are considerable correlations 
between occasions. Th erefore, the default diagonal covariance (i.e., with variances only and no 
covariances) would not likely capture this complexity (–2LL  ‒17,698.122). We note that 
the model ‒2LL (or deviance) in this case is negative, which can occur in model estimation if 
the probability density is greater than 1, meaning that the log of the likelihood function at the 
maximum is positive (i.e., > 0), and therefore, when multiplied by ‒2, the resulting deviance and 
Akaike’s information criterion [AIC] are negative. Th e ﬁ t of the model with a single variance at 
Level 1 (scaled identity) ﬁ t the data somewhat better (–2LL  ‒17,424.371). Th e model with 
compound symmetry (ﬁ ve estimated parameters) did not converge. Similarly, the model with an 
unstructured covariance matrix was overly complex (i.e., taking more than 2 hours to converge 
on a solution for 69 estimated parameters). It is likely that we can ﬁ nd a more parsimonious 
structure for the Level 1 repeated measures. 

248  Applications of Mixed Models for Longitudinal Data 
 We also compared the autoregressive heterogeneous structure (–2LL   ‒18,988.848) against 
the autoregressive homogeneous structure (–2LL  ‒18,776.575). We note that in evaluating 
model ﬁ t, the negative sign matters; that is, we prefer the smallest value of ﬁ t indices such as 
‒2LL or AIC. In order, the heterogeneous autoregressive covariance structure (ARH1) provided 
the best ﬁ t; the homogeneous autoregressive structure (AR1), the second best; the diagonal cova-
riance structure (DIAG), the third best; and the identity covariance structure (ID), the worst. We 
might settle, however, on the autoregressive homogeneous (AR1) structure as being a reasonable 
compromise between an identity covariance matrix and a more fully speciﬁ ed covariance struc-
ture as in the autoregressive heterogeneous structure. 
 Deﬁ ning Model 1.1 (Null) with IBM SPSS Menu Commands 
 Launch the IBM SPSS pro-
gram application, and select the 
 ch6gradu ationdata.sav data ﬁ le. 
  1. Go to the toolbar and 
select ANALYZE, 
MIXED MODELS, 
LINEAR. 
 Th is command enables access 
to the  Linear Mixed Models: 
Specify Subjects and Repeated 
dialog box. 

Applications of Mixed Models for Longitudinal Data   249
  2. Th e  Linear Mixed Models: Specify Subjects and 
Repeated screen displays options for deﬁ ning vari-
ables as subjects, repeated observations, and type 
of covariance structure in a model. 
 
 a. A subject is an observational unit that may be 
independent of other subjects. For this model, 
we will designate  rid (individual identiﬁ ca-
tion number reindexed to nest students within 
11 time periods within each state to facilitate 
model processing) and  stateid (state identiﬁ ca-
tion number) as the subject variables. Click to 
select  rid and  stateid from the  Variables col-
umn, and then click the right-arrow button to 
move the variables into the  Subjects box. 
 
 b. Th e  Repeated box allows specifying variables 
that identify repeated observations. For this 
model,  time identiﬁ es repeated observations 
over 11 time periods. Click to select  time , and 
then click the right-arrow button to move the 
variable into the  Repeated box. 
 Th e combination of values for  rid, stateid , 
and  time deﬁ nes a particular student from a 
particular state across 11 time periods. 
 
 c. Th e  Repeated Covariance Type speciﬁ es a model’s covariance structure. For this model, we will 
use the autoregressive covariance matrix,  AR(1). Click the pull-down menu to select the au-
toregressive covariance matrix,  AR(1), as the  Repeated Covariance Type. 
 AR(1) is a ﬁ rst-order autoregressive structure with homogenous variances. Th e correlation between any 
two elements is equal to rho (     ) for adjacent elements,   2 for elements that are separated by a third, and 
so on. We note that   is constrained so that ‒1 <   < 1 (IBM Corporation, 2012). 
 Click the CONTINUE button to display the  Linear Mixed Models dialog box. 
  3. Th e  Linear Mixed Models main screen 
enables specifying the dependent 
variable, factors, and covariates, as 
well as access to dialog boxes for de-
ﬁ ning  Fixed and  Random eﬀ ects, and 
options for  Estimation ,  Statistics ,  EM 
Means , and  Save. 
 For this model, we will use  gradproportion 
as the dependent variable. Click to select 
the  gradproportion variable from the left 
column listing. Th en click the right-arrow 
button to transfer  gradproportion into the 
 Dependent Variable box. 
 Th e null model does not have predictors, but we will be designating a random eﬀ ect. So skip over the 
FIXED button, and click the RANDOM button to access the  Linear Mixed Models: Random Eﬀ ects 
dialog box. 

250  Applications of Mixed Models for Longitudinal Data 
  4. Th e  Linear Mixed 
Models: Random 
Eﬀ ects  displays 
the  Random Eﬀ ect 
1 of 1 screen. Th e 
random-eﬀ ects 
screen allows 
specifying ran-
dom eﬀ ects, inter-
actions, intercept 
terms, and subject 
groupings. 
 
 a. Begin by speci-
fying the cova-
riance structure 
from the 
default vari-
ance compo-
nents (VC) to 
scaled identity. 
Click the pull-
down menu 
and select 
 Scaled Identity 
(ID). Th e scaled identity structure has constant variance and assumes that no correlation occurs 
between elements. 
 
 b. We want the intercept to be included in the model, so click  Include intercept . 
 
 c. Th e  Subject Groupings box displays the  rid and  stateid variables that were speciﬁ ed as a subject 
variable in the  Specify Subjects and Repeated dialog box show in step 2a. We will specify  stateid as 
the subject for the random-eﬀ ects part of this model. Click to select  stateid, and then click the 
right-arrow button to move the variable into the  Combinations box. 
 
 d. At the top-right section of the window, click the NEXT button to access the  Random Eﬀ ect 2 
of 2 screen. 
 Note: Th e NEXT button may not work in earlier or unpatched versions of IBM SPSS when creating 
multilevel models with random intercepts. An update issued by IBM SPSS for software Version 19 
addressed the problem, and Version 20 appears to have resolved the issue. A workaround to activating 
the NEXT button is to either (a) add or reenter a subject variable into the  Combinations  box or (b) add a 
variable from the  Factors and Covariates column to the  Model  box and then remove it before proceeding 
to the  Random Eﬀ ect 2 of 2 screen. 

Applications of Mixed Models for Longitudinal Data   251
 Th e  Random Eﬀ ect 2 of 2 
screen display is similar to the 
ﬁ rst screen and requires the 
following changes. 
 
 e. Change the covariance 
type by clicking on 
the pull-down menu 
and selecting  Scaled 
Identity. 
 
 f. Click to select the  In-
clude intercept option. 
 
 g. We will specify  rid 
and  stateid as the sub-
jects for the Level 2 
random eﬀ ects in this 
model. Click to select 
 rid and  stateid , and 
then click the right-
arrow button to move 
the variables into the 
 Combinations box. 
 Click the CONTINUE button to return to the  Linear Mixed Models dialog box. 
  5. Click the ESTIMATION button to 
access the  Linear Mixed Models: Esti-
mation dialog box, which displays two 
estimation method choices: maximum 
likelihood (ML) or REML. 
 In this chapter, we will use the default setting 
of REML to estimate the models. 
 Click the CONTINUE button to return to 
the  Linear Mixed Models dialog box. 

252  Applications of Mixed Models for Longitudinal Data 
  7. Finally, in the  Linear Mixed Models 
dialog box, click the OK button to 
run the model. 
  6. In the  Linear Mixed Models dialog 
box, click the STATI STICS button 
to access the  Linear Mixed Models: 
Statistics dialog box. 
 Click and select the following three 
statistics to be included in the output: 
 Parameter estimates, Tests for covariance 
parameters , and  Covariances of random 
eﬀ ects . 
 Click the CONTINUE button to return 
to the  Linear Mixed Models dialog box. 
 Interpreting the Output From Model 1.1 (Null) 
 Th e output for the initial “no predictors” model is summarized in   Table 6.2  . Averaging across the 
period of time, the estimates suggest that about 13.7% of the variability in graduation rates is be-
tween states (0.003255/0.004104 + 0.016397 + 0.003255  0.003255/0.023756  0.137), about 
69% of the variability is between institutions (0.016397/0.023756  0.690), and about 17.3% of 
the variability is within institutions (0.004104/0.023756  0.173). As we mentioned in the last 
chapter, if we added the time-related variables, we might have a somewhat diﬀ erent estimate of 
the proportion of variance at each level. At Level 1, rho (  ) represents the correlation between 
any two consecutive occasions across the time series (i.e., 0.513). 
 In   Table 6.3  , the grand mean for graduation rates at the state level across the 11 observations 
is 0.431, or about 43%. 
 Model 1.2: Adding Growth Rates 
 At the next step, we can add the growth rate indicators. In many situations where we examine 
change over time, it is suﬃ  cient to propose that a linear growth trajectory will describe the data 
adequately. When the time periods are reasonably short and there are not too many observations 

Applications of Mixed Models for Longitudinal Data   253
 TABLE 6.2 Estimates of Covariance Parameters a 
Parameter
Estimate
Std. Error
Wald Z
Sig.
95% Conﬁ dence Interval
Lower Bound Upper Bound
Repeated Measures
AR1 
diagonal
0.004
0.000
34.806
.000
0.004
0.004
AR1 rho
0.513
0.014
36.169
.000
0.484
0.540
Intercept [subject  stateid]
Variance
0.003
0.001
3.254
.001
0.002
0.006
Intercept [subject  rid * stateid]
Variance
0.016
0.001
16.350
.000
0.015
0.018
 a Dependent variable: gradproportion.  
 TABLE 6.3 Estimates of Fixed Effects a 
Parameter
Estimate
Std. Error
df
t
Sig.
95% Conﬁ dence Interval
Lower Bound
Upper Bound
Intercept
0.431
0.010
47.374
42.668
.000
0.411
0.451
 a Dependent variable: gradproportion. 
per individual (i.e., an individual subject or, in this case, an individual institution), the linear 
growth model will often provide a good approximation for more complex models that cannot 
be fully modeled because of the sparse number of observations (Raudenbush & Bryk, 2002). 
In this case, because we are not sure, we may wish to check for the shape of the growth trajectory 
ﬁ rst. We can deﬁ ne a quadratic component at Level 1 to take into consideration the idea that the 
growth rates may accelerate or decelerate over time. 
 Level 1 Model 
 To add a quadratic component to the model, the Level 1 equation can be written as follows: 
 
2
0
1
2
,
tij
ij
ij
tij
ij
tij
tij
y
a
a



	




 
 (6.13) 
 where  y tij  is the response variable for institution  i in state  j measured at time  t . Th e intercept is 
 π 0 ij  , and  π 1 ij  is the linear growth rate for institution  i in state  j over the data-collection period, 
representing the expected change during a ﬁ xed unit of time. Th e quadratic component  π 2 ij  repre-
sents any change in the rate of change over time. Each institution, therefore, has its own growth 
trajectory (developed from the intercept and slope), with likely variability present in the random 
coeﬃ  cients across the set of institutions. 
 At Level 2, we will have the intercept vary across institutions, but we will ﬁ rst ﬁ x the variances 
of the time-related components to 0 (shown by removing the variance parameters  r 1 ij  and  r 2 ij  , 
respectively): 
 
  π 0 ij    00 j +  r 0 ij  , 
(6.14) 
 π 1 ij     10 j  , 
 π 2 ij     20 j  . 

254  Applications of Mixed Models for Longitudinal Data 
 At Level 3, we will again allow the intercept to vary at random across states but again ﬁ x the 
variances of the time-related components to 0. 
 
   00 j    000 +  u 00 j  
(6.15) 
  10 j     100 
  20 j     200 
 Coding the Time Variable 
 It is important to note that the meaning of the intercept parameter ( π 0 i  ) depends on the scaling 
of the time variable.   Figure 6.4  illustrates two coding schemes for time. We could code the linear 
 time  variable in yearly intervals (0, 1, 2, . . . ,  N   t ). Most often, researchers code the ﬁ rst measure-
ment occasion as 0, so that the intercept parameter can be interpreted as the true initial status of 
graduation rates in institution  i in state  j at time point  a tij   0. Deﬁ ning the intercept as initial 
status serves as a baseline for interpreting the subsequent change that takes place over time for 
each individual institution in the sample. If there is a quadratic term ( quadtime ), the correspond-
ing variable would be scaled in a similar manner (i.e., 0, 1, 4, 9, . . . ,  N   t ), as shown in the table. 
Th e ﬁ gure also shows an alternative coding for the linear ( time1 ) and quadratic ( quadtime1 ) com-
ponents using 0 and 1 as the end points for the growth trajectory. We note in passing that varying 
intervals between measurement occasions can also be accommodated (e.g., 0, 1, 3, 7, . . . ,  N ). 
 As   Figure 6.4  indicates, the time intervals are again entered in the Level 1 data set in vertical 
format as a variable ( time ), and each time point corresponds to a speciﬁ c graduation proportion 
for each institution. Th is necessitates 11 data lines in the data set per institution. For example, 
for institution ID #1, the graduation proportion corresponding to  time  0 (the ﬁ rst year) is 0.35, 
and for  time  10 (the last year), it is 0.33. Th e data are linked to successive levels with unique 
identiﬁ ers (e.g., institution and state). We note that the institutional identiﬁ er ( id ) has also been 
recoded within institutions ( rid ) to reduce the time it takes to run the model. 
 We reiterate that centering the time-related variables in various ways (i.e., as initial status, end 
status, and middle status) will aﬀ ect the level of the intercept, the variance at higher levels (e.g., 
Level 2 and Level 3), and the covariance between the intercept and slope (see Raudenbush & 
Bryk, 2002, for further discussion of centering options). For example, if we deﬁ ne the intercept as 
initial status, the intercept is 0.41, and the correlation between the intercept and slope is negative. 
Selecting the last time point would result in a factor that describes the institutions’ graduation 
rates at the end of the time series (e.g.,  a it   ‒10, ‒9,. . ., 0). In this case, if we deﬁ ne graduation 
rate as end status, the intercept is about 0.44, and the correlation between the intercept and slope 
is positive. Centering in the middle of the time series may also have desirable eﬀ ects in some 
instances. We also have to keep in mind the possibility of higher order polynomials in deﬁ ning 
the growth trajectories. In general, such decisions should be made with respect to the purposes 
of the study and characteristics of the model and data. 
 Th e choice of the appropriate modeling approach and coding of time should be based on 
the ease with which model parameter estimates can be interpreted, always keeping in mind the 
substantive questions of the research study. In this example, it is convenient to code the time 
variable in the following manner (0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0). We will call this 
variable  time1 , to diﬀ erentiate it from the yearly  time  variable in the data set. Th is will allow us to 
capture the change in graduation growth over the entire period under study (i.e., the change in 
graduation proportion as  time1 changes from 0 to 1). We can create a similar quadratic compo-
nent ( quadtime1 ) by computing  time1*time1  and saving it in the database. When we estimated a 
model with both components, however, we found that the quadratic component was not signiﬁ -
cant ( p  .197). We could also recenter the linear and quadratic components at the grand mean 
(i.e., year 6 mean) of the trend ( time1mid  and  quadtime1mid ), which will remove the correlation 

Applications of Mixed Models for Longitudinal Data   255
between them ( r  0.008) and often facilitates model estimation (Hox, 2010). When we esti-
mated this model with linear and quadratic trends, however, we conﬁ rmed that the quadratic 
component was again not signiﬁ cant ( p  .197). 
 We present the ﬁ xed-eﬀ ect results of this latter model centered at the midpoint of the trend in 
 Table 6.4  . Readers should keep in mind that we are actually testing a population of universities and 
states, so statistical testing is not really needed since we are not making inferences from a sample to 
a population. For purposes of demonstration, however, we will interpret them as if we were making 
these types of inferences. Th e table indicates that the average midpoint graduation proportion is 
0.429. As expected, this is between the initial status proportion of 0.41 and the end status propor-
tion of 0.44. Th e table also suggests that the linear component is necessary in describing gradu-
ation growth over time (   0.039,  p < .001). Th e quadratic component, however, is not required 
(   0.013,  p > .10) to model growth over time. Because the quadratic component does not con-
tribute to modeling growth in graduation rates over time, we can drop it from successive models. 
 FIGURE 6.4  Level 1 data structure for graduation percentages. 
 TABLE 6.4 Estimates of Fixed Effects a 
Parameter
Estimate
Std. Error
df
t
Sig.
Intercept
0.429
0.010
48.633
42.214
.000
time1mid
0.039
0.003
1,391.355
12.407
.002
quadtime1mid
0.013
0.010
2,737.942
1.289
.197
 a Dependent variable: gradproportion. 

256  Applications of Mixed Models for Longitudinal Data 
 We note in passing that centering the time-related components at the beginning of the trend 
or in the middle results in diﬀ erent estimates of the intercept and linear time component; how-
ever, the quadratic component (as the higher order polynomial) is unaﬀ ected by the recentering. 
In this example, a linear growth model using  time1 should be suﬃ  cient to capture the change in 
graduation rates over the period of the study. Since we have settled on the shape of the trajectory, 
we can also specify the linear growth component ( time1 ) as randomly varying across institutions 
and states. At Level 1, we will have the following equation without the quadratic component: 
 
  y tij    π 0 ij  +  π 1 ij  time1 tij  +   tij  . 
(6.16) 
 Between institutions (Level 2), we will specify the linear component as randomly varying by 
adding the respective variance ( r 1 ij  ) at Level 2, as shown in Equation 6.14. At Level 3, we will 
also specify the linear component as randomly varying ( u 10 j  ), as shown in Equation 6.15. When 
we substitute the new Equations 6.14 and 6.15 into Equation 6.16, we will obtain the following 
combined equation: 
 
 y tij     000 +   100 time1 tij  +  u 10 j  time1 tij  +  u 00 j  +  r 1 ij  time1 tij  +  r 0 ij  +   tij  . 
(6.17) 
 Th is suggests a total of eight parameters to estimate. Th is includes two ﬁ xed eﬀ ects, two random 
eﬀ ects at Level 3, two random eﬀ ects at Level 2, and two repeated eﬀ ects (Level 1) parameters 
(i.e., the variance and autocorrelation). Note also that we will ﬁ rst assume diagonal covariance 
matrices for the ﬁ xed eﬀ ects at Levels 2 and 3. We could, of course, deﬁ ne those covariances as 
unstructured. 
 Deﬁ ning Model 1.2 with IBM SPSS Menu Commands 
 Note: IBM SPSS settings will de-
fault to those used in Model 1.1. 
  1. Go to the toolbar and select 
ANALYZE, MIXED MOD-
ELS, LINEAR. 
 Th is command enables access to 
the  Linear Mixed Models: Specify 
Subjects and Repeated dialog box. 

Applications of Mixed Models for Longitudinal Data   257
  2. Th e  Linear Mixed Models: Specify Subjects and Re-
peated displays the default settings from the prior 
model. We will retain the settings, so click the 
CONTINUE button to display the  Linear Mixed 
Models dialog box. 
  3. Th e  Linear Mixed Models main dialog box 
displays  gradproportion as the dependent 
variable. 
 Factors and covariates may be speciﬁ ed in 
predicting the dependent variable. Factors are 
categorical predictors that may be numeric or 
string. Covariates are scale predictors that must 
be numeric. We will designate a predictor vari-
able ( time1 ), which will be used in the model. 
Locate and click the variable  time1 from the 
left column listing, and then click the right-
arrow button to move the variable into the 
 Covariate(s) box. 
 We may now proceed to deﬁ ne ﬁ xed eﬀ ects for the variable. 
 Click the FIXED button to access the  Linear Mixed Models: Fixed Eﬀ ects dialog box. 
 
 4a. Within the  Linear Mixed Mod-
els: Fixed Eﬀ ects dialog box, click 
the pull-down menu to change 
the factorial setting to  Main 
Eﬀ ects . 
 
 b. Click to select  time1 from the 
 Factors and Covariates box, and 
then click the ADD button to 
move the variable into the  Model 
box. 
 
 c. Note on lower left of the screen 
that the intercept and the sum of 
squares ( Type III ) are the default 
settings. 

258  Applications of Mixed Models for Longitudinal Data 
 Click the CONTINUE button to return to the  Linear Mixed Models dialog box. 
 We will now add random eﬀ ects to this model. 
 Click the RANDOM button to access the  Linear Mixed Models: Random Eﬀ ects dialog box. 
  5. Th e  Random Eﬀ ect 2 of 2 screen 
display is displayed as it was the 
last. 
 
 a. Change the covariance type 
by clicking on the pull-
down menu and selecting 
 Diagonal. 
 Th e  Diagonal  covariance structure 
has heterogeneous variances and zero 
correlation between elements (IBM 
Corporation, 2012). 
 
 b. We will specify a Level 2 
random eﬀ ect ( time1 ) by ﬁ rst 
clicking the pull-down menu 
to change the factorial set-
ting to  Main Eﬀ ects . 
 
 c. Next, click to select  time1 
from the  Factors and Covari-
ates box, and then click the 
ADD button to move the variable into the  Model box. 
 
 d. Click the PREVIOUS button to access the  Random Eﬀ ect 1 of 2  screen display. 
 Th e  Random Eﬀ ect 1 of 2 screen 
displays the default settings used 
for the prior model. 
 
 e. Change the covariance 
type by clicking on the 
pull-down menu and se-
lecting  Diagonal. 
 
 f. We will specify a Level 1 
random eﬀ ect ( time1 ) by 
ﬁ rst clicking the pull-down 
menu to change the facto-
rial setting to  Main Eﬀ ects . 
 
 g. Next, click to select  time1  
from the  Factors and Covari-
ates box, and then click the 
ADD button to move the 
variable into the  Model  box. 
 Click the CONTINUE button to 
return to the  Linear Mixed Models 
dialog box. 

Applications of Mixed Models for Longitudinal Data   259
 6. Finally, in the  Linear Mixed 
Models dialog box, click the OK 
button to run the model. 
 Interpreting the Output From Model 1.2 
 We can conﬁ rm the model speciﬁ cation of eight parameters to estimate in  Table 6.5 . 
 In   Table 6.6  , we next present the ﬁ xed eﬀ ects, noting that we now have initial status deﬁ ned as 
the beginning of the time trend, suggesting that the initial state 6-year graduation rate was 0.411 
(or about 41.1%). Over the period of the study, state graduation rates grew by about 0.04 (or 4%).  
 Next, it is important to consider the nature of the deviations of the individual growth trajec-
tories from the mean growth trajectory. Th e estimates of the initial status and slope variances are 
presented in   Table 6.7  . Once again, the Wald  Z statistic is provided as a test of homogeneity; that 
is, there is no true variation in individual growth parameters (0). Since the variance cannot be 
below 0, the Wald  Z test should be conducted as a one-tailed test. For initial status, at the state 
 TABLE 6.5  Model Dimension a 
Number of 
Levels
Covariance 
Structure
Number of 
Parameters
Subject 
Variables
Number of 
Subjects
Fixed Effects
Intercept
 1
1
time 1
 1
1
Random Effects
Intercept + time1
 2
Diagonal
2
stateid
Intercept + time1
 2
Diagonal
2
rid * stateid
Repeated Effects
quadtime
11
First-Order 
Autoregressive
2
rid * statied
649
Total
17
8
 a Dependent variable: gradproportion. 
 TABLE 6.6 Estimates of Fixed Effects a 
Parameter
Estimate
Std. Error
df
t
Sig.
95% Conﬁ dence Interval
Lower Bound Upper Bound
Intercept
0.411
0.010
48.862
42.029
.000
0.392
0.431
time1
0.040
0.005
27.359
8.120
.000
0.030
0.050
 a Dependent variable: gradproportion.   

260  Applications of Mixed Models for Longitudinal Data 
level the Wald  Z is 3.206, one-tailed  p < .01. Th is leads to rejecting the null hypothesis that there 
is no variation among states’ initial status graduation proportions. At the institutional level, the 
Wald  Z was 16.357, one-tailed  p < .001, also suggesting that we should reject the null hypothesis 
of no signiﬁ cant variation in institutions’ initial graduation proportions. At Level 1, the average 
correlation between any two consecutive repeated measures across the time series was about 
0.287. Regarding growth rates, at the state level, we might have some preliminary evidence that 
graduation growth rates do vary across states (Wald  Z  1.331, one-tailed  p  .0915), keeping in 
mind that in this study we actually have a population of states instead of a small ( n  50) random 
sample. At the institutional level, the evidence is clearer that growth in graduation rates varies 
across institutions (Wald  Z  9.860, one-tailed  p < .001). 
 Th e random-coeﬃ  cients growth model can also provide an estimate of the covariance be-
tween initial status and the growth rate. In this subsequent analysis when we examined an un-
structured covariance matrix (not tabled), at the institutional level we found that the covariance 
was negative ( p  .052), which suggests some tendency for institutions with higher graduation 
rates at the beginning of the study to demonstrate less growth over time. At the state level, how-
ever, the same relationship was not statistically signiﬁ cant ( p  .383). We reiterate the importance 
of giving some attention to the deﬁ nition and scaling of the model’s initial status and growth 
parameters because this aﬀ ects the meaning one attaches to the coeﬃ  cients (for other discus-
sions, see Hox, 2002; and Singer & Willett, 2003). For this reason, we decided not to include the 
covariance between intercept and time slope in our subsequent models. 
 Model 1.3: Adding Time-Varying Covariates 
 We will next add two time-varying covariates to the model. Th ese are variables that are measured 
through the 11-year period. In this case, we will use the percentage of students within the insti-
tution receiving ﬁ nancial aid and the average tuition level at the institution. We will standardize 
each variable (mean [ M ]  1, standard deviation [ SD ]  0). 
 
  y tij    π 0 ij  +  π 1 ij  time1 tij  +  π 2 ij     ﬁ naid tij  +  π 3 ij  tuition tij  +   tij  , 
(6.18) 
 where  π 0 ij  is the intercept for institutions,  π 1 ij  is the linear growth rate,  π 2 ij  represents the coeﬃ  -
cient describing the eﬀ ect of the percentage of students receiving federal ﬁ nancial aid (standard-
ized),  π 3 ij  is the coeﬃ  cient describing the eﬀ ect of institutional tuition level (standardized), and 
  tij  is the residual variance associated with predicting institutional graduation rates. We will keep 
 TABLE 6.7 Estimates of Covariance Parameters a 
Paramenter
Estimate
Std. Error
Wald Z
Sig.
95% Conﬁ dence Interval
Lower Bound Upper Bound
Repeated Measures
AR1 Diagonal
0.003
0.000
37.747
.000
0.003
0.003
AR1 rho
0.287
0.018
16.071
.000
0.252
0.322
Intercept + time1 
[subject  stateid]
Var: Intercept
0.003
0.001
3.206
.001
0.002
0.005
Var: time1
0.000
0.000
1.331
.183
0.000
0.002
Intercept + time1
[subject  rid * stateid]
Var: Intercept
0.016
0.001
16.357
.000
0.014
0.018
Var: time1
0.005
0.001
9.860
.000
0.004
0.007
 a Dependent variable: gradproportion. 

Applications of Mixed Models for Longitudinal Data   261
Levels 2 and 3 the same as in the last model (see Eqs. 6.14 and 6.15). When we substitute those 
equations into Equation 6.18, we will have the following single-equation model: 
   y tij     000 +   100 time1 tij  +   200 ﬁ naid tij  +   300 tuition tij  +  u 10 j  timel tij  +  u 00 j  +  r 1 ij  timel tij  +  r 0 ij  +   tij  . 
(6.19) 
 Th is provides a total of 10 parameters to estimate (four ﬁ xed eﬀ ects, four random eﬀ ects, and two 
repeated eﬀ ects). 
 Deﬁ ning Model 1.3 with IBM SPSS Menu Commands 
 Note: IBM SPSS settings will default 
to those used in Model 1.2. 
  1. Go to the toolbar and select 
ANALYZE, MIXED MODELS, 
LINEAR. 
 Th is command enables access to the 
 Linear Mixed Models: Specify Subjects and 
Repeated dialog box. 
  2. Th e  Linear Mixed Models: Specify Subjects and 
Repeated displays the default settings from the 
prior model. We will retain the settings, so 
click the CONTINUE button to display the 
 Linear Mixed Models dialog box. 

262  Applications of Mixed Models for Longitudinal Data 
  3. Th e  Linear Mixed Models main dialog 
box displays default settings from the 
prior model. 
 We will introduce two additional predictors 
to be used in the model ( percentFinAid and 
 tuition ). First, click to select  percentFinAid 
and  tuition , and then “drag” both variables to 
the  Covariate(s) box above  time1. 
 Click the FIXED button to access the  Linear 
Mixed Models: Fixed Eﬀ ects dialog box. 
 
4a. Th e  Linear Mixed 
Models: Fixed Eﬀ ects 
dialog box displays 
the default setting 
from the prior model. 
To facilitate reading 
the output tables, we 
will ﬁ rst remove  time1 
by clicking to select 
the variable and then 
clicking the REMOVE 
button.
 
b.  Conﬁ rm that the fac-
torial setting is  Main 
Eﬀ ects before adding 
the predictor variables 
to the model. 
 
 c. Now click to select the 
variables  percentFinAid ,  tuition , and  time1  from the  Factors and Covariates box. Th en click the 
ADD button to move the variables into the  Model box. 
 Click the CONTINUE button to return to the  Linear Mixed Models dialog box. 
  5. Finally, in the  Linear Mixed Models dia-
log box, click the OK button to run the 
model. 

Applications of Mixed Models for Longitudinal Data   263
 Interpreting the Output From Model 1.3 
 Th e ﬁ xed-eﬀ ect estimates are provided in   Table 6.8  . After adding the time-varying covariates at 
Level 1, the new state graduation intercept was 0.469 (or about 47%). Th is can be interpreted as 
the initial graduate rate for an institution at the grand means (0) of percentage of students receiv-
ing ﬁ nancial aid and tuition levels.   Table 6.8  suggests that the average tuition level was positively 
associated with student graduation rates; that is, a 1- SD increase in institutional tuition would 
result in about a 5% (0.050) increase in initial graduation rate. Similarly, percentages of students 
receiving ﬁ nancial aid was associated with higher graduation rates ( p < .10). After adjusting for 
the covariates, state graduation rates appeared to grow about 1.6% (0.016) over the decade.  
 Again, the variance components table (  Table 6.9  ) suggests that that intercepts vary across 
institutions and states. Growth rates also varied across institutions (Wald  Z  10.076, one-tailed 
 p < .01). Th ere is some evidence suggesting that they also varied across states (Wald  Z  1.419, 
one-tailed  p  .078). 
 Model 1.4: Explaining Differences in Growth Trajectories Between Institutions 
 Because there was signiﬁ cant variation in each parameter present among individual institutions, 
both the intercept and growth parameters can be allowed to vary across institutions. Th e variation 
in each may likely be partially explained by between-institutional characteristics as in Equation 
6.3. In this example, we consider two institutional predictors that may account for systematic 
variation in the intercept and slope parameters between institutions. 
 Th e ﬁ rst is selectivity in student admissions (i.e., deﬁ ned as the percentage of students ad-
mitted with SAT or ACT math scores at the 75th percentile or above), which we standardized 
 TABLE 6.8 Estimates of Fixed Effects a 
Parameter
Estimate
Std. Error
df
t
Sig.
95% Conﬁ dence Interval
Lower Bound Upper Bound
Intercept
0.469
0.011
98.626
41.737
.000
0.447
0.492
percentFinAid
0.002
0.001
5,693.474
1.779
.075
0.000
0.003
tuition
0.049
0.005
5,044.319
9.269
.000
0.039
0.060
time1
0.016
0.005
59.168
3.063
.003
0.006
0.027
 a Dependent variable: gradproportion. 
 TABLE 6.9 Estimates of Covariance Parameters a 
Parameter
Estimate
Std. Error
Wald Z
Sig.
95% Conﬁ dence Interval
Lower Bound Upper Bound
Repeated Measures
AR1 Diagonal
0.003
0.000
38.123
.000
0.003
0.003
AR1 rho
0.276
0.018
15.391
.000
0.240
0.310
Intercept + time1
[subject  stateid]
Var: Intercept
0.003
0.001
3.143
.002
0.001
0.005
Var: time1
0.000
0.000
1.419
.156
0.000
0.001
Intercept + time1
[subject  
rid * stateid]
Var: Intercept
0.015
0.001
16.276
.000
0.014
0.017
Var: time1
0.005
0.001
10.076
.000
0.004
0.007
 a Dependent variable: gradproportion. 

264  Applications of Mixed Models for Longitudinal Data 
( M  0,  SD  1). Th e other variable is percentage of full-time faculty, which is also standardized. 
Th e two Level 2 submodels are now deﬁ ned as follows: 
 
  π 0 ij     00 j  +   01 mselect ij  +   02 fulltime ij  +  r 0 ij  , 
(6.20) 
 
  π 1 ij     10 j  +   11 mselect ij  +   12 fulltime ij  +  r 1 ij  . 
(6.21) 
 Th e covariance matrix of random eﬀ ects at Level 2 can be deﬁ ned as diagonal or unstructured; 
however, we will maintain a diagonal covariance matrix at each level. 
 At Level 3 (between states), we will also add two predictors. Th e ﬁ rst is the percentage share 
that families have to pay for higher education in the state, which we standardized. Th e second 
variable is the average percentage of freshman retained in the state (which we also standardized), 
which may serve as one proxy indicator of the quality of the state’s public higher education system. 
 
   00 j     000 +   001 avefamilyshare j  +   002 averetention j  +  u 00 j  . 
(6.22) 
 For this model, we will consider the growth rate to vary also across states but will not try to ex-
plain that variation: 
 
   10 j     100 +  u 10 j  . 
(6.23) 
 When we combine these, we will have 16 parameters to estimate (keeping in mind two repeated 
measures eﬀ ects at Level 1). 
 y tij     000 +   001 avefamilyshare j  +   002 averetention j  +   010 mselect ij  +   020 fulltime ij  
+   100 time1 tij  +   110 mselect ij  * time1 tij  +   120 fulltime ij  * time1 tij  +   200 ﬁ naid tij  
+   300 tuition tij  +  u 10 j  timel tij  +  u 00 j  +  r 1 ij  timel tij  +  r 0 ij  +   tij  
(6.24) 
 Deﬁ ning Model 1.4 with IBM SPSS Menu Commands 
 Note: IBM SPSS settings will default to 
those used in Model 1.3. 
  1. Go to the toolbar and select ANAL-
YZE, MIXED MODELS, LINEAR. 
 Th is command enables access to the  Linear 
Mixed Models: Specify Subjects and Repeated 
dialog box. 

Applications of Mixed Models for Longitudinal Data   265
  2. Th e  Linear Mixed Models: Specify Subjects and Repeated 
displays the default settings from the prior model. We 
will retain the settings, so click the CONTINUE but-
ton to display the  Linear Mixed Models dialog box. 
  3. Th e  Linear Mixed Models dialog box set-
tings default to those used in the prior 
model. 
 We will introduce four additional predictors to 
be used in the model ( mathselect ,  percentFTfac-
ulty ,  aveRetention , and  aveFamilyshare ). First, 
click to select  mathselect ,  percentFTfaculty ,  av-
eRetention , and  aveFamilyshare , and then “drag” 
the variables to the  Covariate(s) box. To facilitate 
reading of the output tables, we will rearrange 
the sequence of the variables by dragging them 
to form the following order:  aveFamilyshare ,  av-
eRetention ,  mathselect ,  percentFTfaculty, percent-
FinAid ,  tuition , and  time1. 
 Click the FIXED button to access the  Linear 
Mixed Models: Fixed Eﬀ ects dialog box. 
 
 4a. We will rearrange the se-
quence order of the variables to 
facilitate reading of the output 
tables. First, click to select  per-
centFinAid ,  tuition , and  time1 , 
and then click the REMOVE 
button to clear the  Model box. 
 
 b. Note that  Main Eﬀ ects is the 
default setting. 
 
 c. Now click to select all of the 
variables in the  Factors and Co-
variates column, and then click 
the ADD button to transfer 
the variables into the  Model 
box. 

266  Applications of Mixed Models for Longitudinal Data 
 Two cross-level interactions (or nested terms) will be created and added to the model:  time1*mathselect 
and  time1*percentFTfaculty . Th ese interactions will tell us if the growth trajectories vary between 
institutions. 
 Add First Interaction to Model 
1.4:  time1*mathselect 
 
 d. Click to select  Build 
nested terms. 
 
 e. Click to select the 
variable  time1 from 
the  Factors and Co-
variates box. 
 
 f. Th en click the arrow 
button below the 
 Factors and Covari-
ates box. Th is moves 
 time1 into the  Build 
Term box to create 
a cross-level inter-
action by linking 
variables and terms. 
 
 g. Next, click the BY* 
button, which will insert the computation command symbol:  time1 *. 
 
 h. Click to select  mathselect  from the  Factors and Covariates box. 
 
 i. Click the arrow button below the  Factors and Covariates box to move  mathselect into the  Build 
Term box and complete the interaction term:  time1 * mathselect. 
 
 j. Click the ADD button to transfer the interaction into the  Model box. 
 Add Second Interaction to Model 
1.4:  time1*percentFTfaculty 
 
 k. Click to select the vari-
able  time1 from the  Fac-
tors and Covariates box. 
 
 l. Next, click the arrow 
button below the  Factors 
and Covariates box. Th is 
moves  time1 into the 
 Build Term box. 
 
 m. Now click the BY* but-
ton, which will insert the 
computation command 
symbol:  time1 * 
 
 n.  Click to select  percent-
FTfaculty  from the  Fac-
tors and Covariates box. 
 
 o. Click the arrow button below the  Factors and Covariates box to move  percentFTfaculty into the 
 Build Term box and complete the interaction term:  time1 * percentFTfaculty. 
 
 p. Click the ADD button to transfer the interaction into the  Model box. 
 Click the CONTINUE button to return to the  Linear Mixed Models dialog box. 

Applications of Mixed Models for Longitudinal Data   267
  5. Finally, in the  Linear Mixed Models 
dialog box, click the OK button to 
run the model. 
 Interpreting the Output From Model 1.4 
 As Table 6.10 indicates, after adjusting for the institutional variables, the true initial status grad-
uation rate for states is 0.475 (or about 47.5%). At Level 3, the coeﬃ  cients suggest that aver-
age family share (   0.020,  p < .01) and average year 1 retention rates (   0.046 , p < .01) are 
both signiﬁ cant in explaining graduation rates. At Level 2, selectivity (   0.094,  p < .01) and 
percentage of full-time faculty remain signiﬁ cant predictors (   0.037,  p < .01) of graduation 
rates. Within institutions, the percentage of students receiving ﬁ nancial aid (   0.002,  p < .05) 
and tuition levels (   0.043,  p < .01) also remain signiﬁ cant predictors of graduation rates. We 
draw attention to the degrees of freedom in   Table 6.10  as a means of checking that variables are 
deﬁ ned at their correct levels of the data hierarchy (i.e., keeping in mind that they reﬂ ect adjust-
ments used in calculating signiﬁ cance tests, so they may be larger or smaller than the “exact” 
number of degrees of freedom at each level). We can see, for example, that  family share  and aver-
age  freshman retention are state-level predictors (with degrees of freedom in the range between 
40 and 50). Student  selectivity  and percentage of  full-time faculty  are institutional indicators (with 
 TABLE 6.10 Estimates of Fixed Effectsa
Parameter
Estimate
Std. Error
df
t
Sig.
95% Conﬁ dence Interval
Lower Bound Upper Bound
Intercept
0.475
0.008
166.118
57.204
.000
0.459
0.491
aveFamilyshare
0.020
0.006
47.667
3.669
.001
0.009
0.031
aveRetention
0.046
0.005
44.386
8.277
.000
0.034
0.057
mathselect
0.094
0.005
706.719
18.129
.000
0.084
0.104
percentFTfaculty
0.037
0.004
651.637
9.005
.000
0.029
0.045
percentFinAid
0.002
0.001
5,654.256
2.110
.035
0.000
0.004
tuition
0.043
0.005
4,999.898
8.253
.000
0.033
0.053
time1
0.019
0.005
66.645
3.756
.000
0.009
0.030
mathselect * time1
0.006
0.005
678.626
1.316
.189
0.003
0.016
percentFTfaculty * time1
0.019
0.004
536.271
5.131
.000
0.012
0.027
 a Dependent variable: gradproportion. 

268  Applications of Mixed Models for Longitudinal Data 
degrees of freedom between 600 and 700). Th e percentage of students receiving  ﬁ nancial aid  and 
average  tuition  are within-institutional variables (reﬂ ecting several thousand repeated measures 
observations). Regarding the growth parameters, we can also observe that the average growth 
slope ( time1 ) is deﬁ ned at the state level and the two growth cross-level interactions are speciﬁ ed 
at the institutional level.  
 Turning to the growth rate model ( time1 ), the adjusted growth in graduation rate for states 
over time was approximately 2% (0.019). Th e percentage of full-time faculty was positively re-
lated to within-institution growth in graduation rates (   0.019,  p < .01). Holding other vari-
ables in the model constant, this implies that a 1- SD increase in percentage of full-time faculty 
would be related to a 1.9% increase in graduation growth rate over the period of the study, com-
pared with institutions at the grand mean of full-time faculty. Student selectivity, however, was 
not related to growth in state graduation rates (   0.006,  p > .10). 
 Th e variance components table (  Table 6.11  ) suggests initial graduation rates still varied 
across states (Wald  Z  2.362, one-tailed  p < .05) and institutions (Wald  Z  14.951, one-tailed 
 p < .01) after inclusion of the Level 2 and Level 3 predictors. After addition of the institutional-
level predictors, graduation growth rates still varied across institutions (Wald  Z  7.984, one-
tailed  p < .01). Growth may also still vary across states (Wald  Z  1.602, one-tailed  p < .055). We 
note that because Wald  Z coeﬃ  cients are likely to be too conservative in small data sets (Hox, 
2002), it might be instructive to develop a simple model to examine growth rates across states 
using the same two predictors at Level 3.  
 Model 1.5: Adding a Model to Examine Growth Rates at Level 3 
 Th e new model for the state-level growth rate is as follows: 
 
   10 j    100 +   101 avefamilyshare j  +   102 averetention j  +  u 10 j  . 
(6.25) 
 When we combine all the predictors, we will have 18 parameters to estimate (including two 
repeated measures parameters at Level 1). 
 y tij     000 +   001 avefamilyshare j  +   002 averetention j  +   010 mselect ij  +   020 fulltime ij  +   100 time1 tij  
+   101 Zavefamilyshare j  * time1 tij  +   102 averetention j  * time1 tij  +   110 mselect ij  * timel tij  
+   120 fulltime ij  * time1 tij  +   200 ﬁ naid tij  +   300 tuition tij  +  u 10 j  timel tij  +  u 00 j  +  r 1 ij  timel tij  +  r 0 ij  +   tij  
(6.26) 
 TABLE 6.11 Estimates of Covariance Parameters a 
Paramenter
Estimate
Std. Error
Wald Z
Sig.
95% Conﬁ dence Interval
Lower Bound Upper Bound
Repeated Measures
AR1 Diagonal
0.003
0.000
34.057
.000
0.003
0.003
AR1 rho
0.312
0.019
16.269
.000
0.274
0.349
Intercept + time1 
[subject  stateid]
Var: Intercept
0.001
0.000
2.362
.018
0.000
0.002
Var: time1
0.000
0.000
1.602
.109
0.000
0.001
Intercept + time1 
[subject  rid * stateid]
Var: Intercept
0.007
0.000
14.951
.000
0.006
0.008
Var: time1
0.004
0.000
7.984
.000
0.003
0.005
 a Dependent variable: gradproportion. 

Applications of Mixed Models for Longitudinal Data   269
 Deﬁ ning Model 1.5 with IBM SPSS Menu Commands 
 Note: IBM SPSS settings 
will default to those used in 
Model 1.4. 
  1. Go to the toolbar and 
select ANALYZE, 
MIXED MODELS, 
LINEAR. 
 Th is command enables access 
to the  Linear Mixed Models: 
Specify Subjects and Repeated 
dialog box. 
  2. Th e  Linear Mixed Models: Specify Subjects and 
Repeated displays the default settings from the 
prior model. We will retain the settings, so 
click the CONTINUE button to display the 
 Linear Mixed Models dialog box. 

270  Applications of Mixed Models for Longitudinal Data 
  3. Th e  Linear Mixed Models main screen 
displays the default settings from the 
prior model. 
 We will add four cross-level interactions 
as ﬁ xed eﬀ ects to the model, so click the 
FIXED button to access the  Linear Mixed 
Models: Fixed Eﬀ ects dialog box. 
 Four cross-level interactions (or nested 
terms) will be created and added to 
the model:  time1*aveFamilyshare , 
 time1*aveRetention ,  time1*mathselect , and 
 time1*percentFTfaculty. Th ese interactions 
will tell us about the growth trajectories 
for states. (Th e ﬁ nal model is shown in the 
image insert.) 
 Add First Interaction to Model 1.5: 
 time1*aveFamilyshare 
 
 4a. Th e  Linear Mixed Models: 
Fixed Eﬀ ects dialog box 
displays the default setting 
from the prior model. To 
facilitate reading the output 
tables, we will ﬁ rst remove 
the two ( percentFinAid 
and  tuition ) interactions 
by clicking to select them 
and then clicking the 
REMOVE button. 
 
 b. Click to select Build nested 
terms. 
 
 c. Click to select the variable 
 time1 from the  Factors and 
Covariates box. 
 
 d. Th en click the arrow button below the  Factors and Covariates box. Th is moves  time1 into the 
 Build Term box to create a cross-level interaction by linking variables and terms. 
 
 e. Next, click the BY* button, which will insert the computation command symbol:  time1* . 
 
 f. Click to select  aveFamilyshare from the  Factors and Covariates box. 
 
 g. Click the arrow button below the  Factors and Covariates box to move  aveFamilyshare into the 
 Build Term box and complete the interaction term:  time1*aveFamilyshare. 
 
 h. Click the ADD button to transfer the interaction into the  Model box. 
 Add Second Interaction to Model 1.5:  time1*aveRetention 
 Repeat steps 4c to 4h using  time1 and  aveRetention. 
 Add Third Interaction to Model 1.5:  time1*mathselect 
 Repeat steps 4c to 4h using  time1 and  mathselect. 

Applications of Mixed Models for Longitudinal Data   271
 Add Fourth Interaction to Model 1.5:  time1*percentFTfaculty 
 Repeat steps 4c to 4h using  time1 and  percentFTfaculty. 
 Th e complete model with the four interactions is displayed in the  Model  box insert. Click the 
CONTINUE button to return to the  Linear Mixed Models dialog box. 
  5. Finally, in the  Linear Mixed Models 
dialog box, click the OK button to 
run the model. 
 Interpreting the Output From Model 1.5 
 Our primary interest is the growth rate portion of the model in   Table 6.12  . Once again, the aver-
age state growth rate is estimated as about 0.020. Average family share of higher education costs 
did not aﬀ ect growth in state graduation rates over time (   ‒0.002,  p > .10). In contrast, how-
ever, average retention of freshman students was signiﬁ cantly related to increases in graduation 
growth rates (   0.011,  p < .05). Th is suggests that a 1- SD increase in year 1 student retention 
rates would result in about a 1% increase in graduation growth rate over time, compared with 
states at the grand mean for retention rate, holding the  time1 slope and other variables constant. 
Th e other ﬁ xed eﬀ ects remained consistent with the previous model. 
 TABLE 6.12 Estimates of Fixed Effects a 
Parameter
Estimate
Std. Error
df
t
Sig.
95% Conﬁ dence Interval
Lower Bound Upper Bound
Intercept
0.475
0.008
166.959
57.074
.000
0.458
0.491
aveFamilyshare
0.020
0.006
49.395
3.666
.001
0.009
0.032
aveRetention
0.044
0.006
46.191
7.846
.000
0.032
0.055
mathselect
0.094
0.005
707.405
18.178
.000
0.084
0.105
percentFTfaculty
0.037
0.004
653.623
8.960
.000
0.029
0.045
percentFinAid
0.002
0.001
5,655.894
2.136
.033
0.000
0.004
tuition
0.043
0.005
5,100.035
8.186
.000
0.032
0.053
time1
0.020
0.005
60.234
4.015
.000
0.010
0.030
aveFamilyshare * time1
−0.002
0.004
39.421
−0.372
.712
−0.010
0.007
aveRetention * time1
0.011
0.004
40.280
2.575
.014
0.002
0.020
mathselect * time1
0.005
0.005
671.231
1.077
.282
−0.004
0.015
percentFTfaculty * time1
0.020
0.004
514.186
5.303
.000
0.013
0.027
 a Dependent variable: gradproportion. 

272  Applications of Mixed Models for Longitudinal Data 
 Th e variance components table (  Table 6.13  ) suggests there is still Level 3 and Level 2 vari-
ance in initial status graduation levels to be explained. After adding the state-level variables to 
explain growth in graduation rates over time, there is not suﬃ  cient variability left to be explained 
(Wald  Z  1.263, one-tailed  p  .1035). Th ere is, however, suﬃ  cient variability in growth rates 
still across institutions (Wald  Z  14.954, one-tailed  p < .001). We could include other predictors 
at the institutional level to model this variability if we desired. 
 We can also determine how much variance in the random coeﬃ  cients was accounted for by 
the predictors, keeping in mind our previous cautions about variance reduction in multilevel 
models. Th e proportion of variance explained is the ratio of the diﬀ erence between the total 
parameter variance estimated from the unconditional model and the residual parameter vari-
ance from the ﬁ tted model relative to the total parameter variance. For intercepts, the amount of 
variance accounted for is reduced from 0.004 (Table 6.2) to 0.003 in Table 6.13 (0.004–0.003  
0.001/0.004), or about 25% of the variance accounted for within institutions. At Level 2, the 
variance component is reduced from 0.016 in Table 6.2 to 0.007 (or  R 2 of 0.563), or about 56.3% 
of the variance accounted for at Level 2. At the state level (Level 3), the variance is reduced from 
0.003 to 0.001 (or  R 2 of 0.667), or about 67.7% of the variance at that level. Of course, these 
estimates would be a bit diﬀ erent if we began with a baseline model that included  time1 . 
 A Regression Discontinuity Analysis of a Math Treatment 
 Other types of models to examine change over time can also be formulated in SPSS MIXED. In 
the remaining part of the chapter, we focus on two types of research designs for investigating ef-
fects of interventions over time. Both models involve the observation of a discontinuity, or “jump” 
in repeated measurements. In the next example, we illustrate how the regression discontinuity 
(RD) design can be used to examine the impact of a hypothetical classroom treatment in math 
on students. Th e design provides a strong, reliable alternative to the randomized experiment 
(Shadish, Cook, & Campbell, 2002). Th e RD design is a type of pre- and posttest design, which 
makes it possible to assess the impact of a treatment accurately by establishing a precise prein-
tervention criterion for assigning individuals to treatment and control groups. In an RD design, 
individuals above the chosen cut point are assigned to one group, those below to another, and the 
treatment assigned to either group. 
 Th e RD design compares the outcomes of individuals on either side of the selection cutoﬀ  point 
but who are similar on other baseline covariates. Th e observed treatment eﬀ ects are expected to 
be most easily discerned for individuals near the cut point; that is, one can control for confound-
ing factors by simply contrasting participants close to the treatment cut point to nonparticipants 
 TABLE 6.13 Estimates of Covariance Parameters a 
Parameter
Estimate
Std. Error
Wald Z
Sig.
95% Conﬁ dence Interval
Lower Bound Upper Bound
Repeated Measures
AR1 Diagonal
0.003
0.000
34.100
.000
0.003
0.003
AR1 rho
0.311
0.019
16.266
.000
0.273
0.348
Intercept + time1 
[subject  stateid]
Var: Intercept
0.001
0.000
2.368
.018
0.000
0.002
Var: time1
0.000
0.000
1.263
.207
0.000
0.001
Intercept + time1 
[subject  rid * stateid]
Var: Intercept
0.007
0.000
14.954
.000
0.006
0.008
Var: time1
0.004
0.000
7.985
.000
0.003
0.005
 a Dependent variable: gradproportion. 

Applications of Mixed Models for Longitudinal Data   273
close to the cut point. In most situations, however, researchers look beyond this examination of 
individuals only around the cut point and use all the data they have (or at least data covering a 
much broader range of individuals in the study). As Cain (1975, in Pedhazur & Schmelkin, 1991) 
noted, “Th e critical diﬀ erence for avoiding bias is not whether the assignments are random or 
nonrandom, but whether the investigator has knowledge of and can model this selection process” 
(p. 304). Th us, estimation bias may be avoided in the RD design, not because of random assign-
ment of subjects, but because the covariate used to assign subjects is known beforehand (see Cook 
& Campbell, 1979; Pedhazur & Schmelkin, 1991). We encourage readers to investigate additional 
sources on the RD design for further information about the uses of this design. 
 The Data and Design 
 In our illustration, we have 4,591 students who were assigned to one of two instructional con-
ditions—we will say one being a more traditional instructional approach consisting of teacher 
lecturing and students reading the supporting text material (coded 0), or an alternative approach, 
where students work more collaboratively with their peers and the teacher using a lab-based, 
problem-solving approach. In our example, 53 math teachers implement the traditional and 
alternative approaches within the basic math courses they teach. Th e treatment, therefore, is 
implemented at the individual student level (Level 1) since students assigned to a particular 
teacher could have received either instructional approach. At the teacher level (Level 2), covari-
ates related to teacher eﬀ ectiveness and class composition serve as controls for peer and teacher 
eﬀ ects that might interact with the treatment eﬀ ects. Th e variables used in the example are sum-
marized in Table 6.14. 
 TABLE 6.14  Data Deﬁ nition of  ch6RDdata.sav ( N  4,591) 
Variable
Levela
Description
Values
Measurement
subjectid
Individual
Student identiﬁ er (4,591 students across three 
time occasions).
Integer
Ordinal
teachcode
Teacher
Teacher identiﬁ er (53 math teachers).
Integer
Ordinal
pretest
Individual
Math placement test score used to divide students 
into a treatment or control group.
148 to 171
Scale
npretest
Individual
The transformed measure of the student’s pretest 
math placement test score (pretest) in relation to 
the cut point for group assignment.
−11 to 12
Scale
treatment
Individual
Dichotomous variable indicating students 
assigned to the control group (coded 0) or the 
treatment group (coded 1).
0  Control group
1  Treatment Groups
Scale
nmath
Individual
Dependent variable representing student 
performance in math.
561 to 856
Scale
teachqual
Teacher
Standardized composite score (M  0, SD  1) 
of the teacher’s overall teaching effectiveness.
−2.67 to 340
Scale
classcomp
Teacher
Factor score (M  0, SD  1) representing the 
weighted percentage of students in each class 
who are low SES, receiving English language 
services, and receiving special education services.
−1.11 to 2.16
Scale
npretest2
Individual
Quadratic pretest component (npretest*npretest)
0 to 144
Scale
npretest3
Individual
Cubic pretest component (npretest2*npretest)
−1331 to 1728
Scale
 a Individual  Level 1; teacher  Level 2. 

274  Applications of Mixed Models for Longitudinal Data 
 Students are assigned to the treatment and control conditions based on a math pretest score. 
In our example, we set a cut score on the pretest of 159. Th erefore, students with scores of 160 
or higher are assigned to the treatment, and those with scores of 159 or lower are assigned to 
the control (although this assignment can also be reversed). If the treatment has no eﬀ ect (i.e., 
assuming a linear relationship between the covariate and outcome), a single regression line is 
expected; that is, there would be no discontinuity between students who scored 159 or below and 
those who scored 160 and above. If the treatment is eﬀ ective, a discontinuity in the regression 
line reﬂ ects the size of the treatment eﬀ ect (Shadish et al., 2002). 
 Several advantages and cautions regarding the design have been noted (Cook & Campbell, 
1979). First, RD can produce an unbiased causal inference, if it is precisely implemented with 
correct modeling of the relation between the assignment criterion (i.e., age) and the inde-
pendent variable (i.e., achievement). Its major drawback is the possibility that eﬀ ects may 
be biased if the relationship between the assignment covariate and the outcome variable is 
incorrectly modeled (e.g., nonlinear relationship or possible interactions ignored). A second 
advantage is that, in principle, controlling various background variables to assess the eﬀ ect of 
the treatment is not required. Th is is because the exact criterion of assignment to treatment 
or control group is known, and its eﬀ ect is accounted for in the analysis. We do have the ﬂ ex-
ibility, however, to include student-level covariates as a check for the robustness of treatment 
estimates. 
 Misclassiﬁ cation can sometimes be a problem, if other factors besides the criterion used to 
assign individuals also inﬂ uence assignment decisions (e.g., self-selection and individuals who 
are eligible to participate but choose not to participate). When other factors may potentially 
inﬂ uence treatment eﬀ ects, this is referred to as a  fuzzy discontinuity. In practice, this potential 
problem is sometimes addressed by comparing subgroups of eligible versus noneligible partici-
pants. Moreover, the RD design identiﬁ es the mean impact of the treatment at the cut point for 
selection (versus an experimental design that provides the average treatment eﬀ ect for all indi-
viduals). Th e RD design, therefore, does not directly inform us about the impact for individuals 
who might be further away from the cut point. Individuals at the extreme ends of the distribu-
tion on the assignment criterion are unlikely to be comparable, which can make the analyst rely 
more on covariates to control for the diﬀ erences between individuals. 
 Assumptions of the Design 
 As Trochim (1984) notes, interpreting results of studies using the RD design depends on the 
support of three assumptions. Th ese assumptions were met in conducting the analyses presented 
in the following section. 
 1.  Th e assignment of participants according to the cut score must be followed. 
 2.  Th e pattern of pretest scores must be speciﬁ ed correctly by the statistical model used . Models can 
be tested initially for possible higher order polynomial eﬀ ects related to the pretest scores 
(i.e., quadratic and cubic) and for interactions between the higher order polynomials and 
the treatment. Th is amounts to testing for higher order terms above and below the cut 
point (i.e., including higher order polynomials and interactions between the polynomials 
and the treatment). As Shadish et al. (2002) note, if interactions or nonlinear eﬀ ects are 
suspected, the analysis should be conducted with the higher order terms in the model, and 
then nonsigniﬁ cant terms should be dropped from higher to lower order. When there is 
doubt, the terms should be kept in the model because this overﬁ tting will yield unbiased 
coeﬃ  cients. 
 3.  Th ere is no coincidental factor at the chosen cut score that would result in program eﬀ ects.  Th is as-
sumption can be tested by conducting a study over a repeated number of semesters and with 
situations where students above the cut score were assigned to the treatment group and with 
situations where students above the cut score were assigned to the control group. 

Applications of Mixed Models for Longitudinal Data   275
 Steps in the Regression Discontinuity Analysis 
 In the RD approach, an important ﬁ rst step is to determine the functional relationship between 
the assignment variable and the outcome variable (Shadish et al., 2002). In this case, the assign-
ment variable is students’ scores on a math pretest. Determining the functional relationship (i.e., 
whether it is linear or curvilinear) between the assignment and outcome variable is important 
in order to ensure unbiased treatment eﬀ ects (Shadish et al., 2002). Th is can be accomplished 
by initially including higher order (i.e., quadratic and cubic) assignment (pretest) eﬀ ects and 
possible interactions with the treatment and then removing the nonsigniﬁ cant eﬀ ects (Moss & 
Yeaton, 2006). In our example, we created the higher order terms but found that none of them 
were signiﬁ cant in explaining the relationship between the pretest, treatment, and outcome. 
Th erefore, we eliminated them. We retained the  treatment x pretest  interaction to illustrate that 
this might mean there was an advantage or disadvantage associated with the treatment depen-
dent on students’ pretest scores. If this were signiﬁ cant, it would suggest that the treatment 
worked diﬀ erentially for students with diﬀ ering levels of prior math ability. 
 In the multilevel analysis of a RD design, there are three primary equations to consider: the 
student-level equation to model individuals’ pretest and treatment eﬀ ects on an achievement 
intercept, the equation to explain variation in between-teacher intercepts, and the equation to 
explain variability in between-teacher treatment slopes. 
 Predictors in the Models 
 Treatment eﬀ ect.  Th is variable is simply an indicator of the student being assigned to the control 
group (coded 0) or the treatment group (coded 1). 
 Pretest. Students took a math placement test before entering the developmental math sequence. 
Th e variable  npretest represents the transformed measure of the student’s pretest in relation to the 
cut point for group assignment. Student math placement test scores were used for purposes of as-
signment to the traditional or redesigned course sequence. Th e highest score at the cut point (159) 
was coded 0, which with respect to the intercept in the model equation represents the achieve-
ment of the students with most prior ability in either the control or treatment group, depending 
on whether the treatment is assigned to the set of students with lower math prior skills or higher 
prior math skills. In this case, we assigned the students with scores of 159 or lower to the control 
group. Prior math scores of 160 or above were assigned to the treatment group. Th e scores were 
then recoded to be centered on the cut score such that scores below 159 were negatively coded 
(e.g., 158  ‒1; 157  ‒2) and scores above 159 are positively coded (e.g., 160  1; 161  2). 
 Classroom composition . Th is is the factor score ( M  0,  SD  1) describing the weighted per-
centage of students in each class who are low socioeconomic status (SES), receive English lan-
guage services, and receive special education services. 
 Teacher quality . Th is is a standardized composite score ( M  0,  SD  1) of the teacher’s over-
all teaching eﬀ ectiveness considering several domains (e.g., academic expectations, monitor-
ing of student process, implementation of curriculum standards, and classroom performance 
evaluations). 
 Specifying the Model 
 Equation 6.27 represents the reduced RD model examined after testing for higher order treat-
ment eﬀ ects and interactions: 
 
  Y ij     0 j  +   1 npretest ij  +   2 treatment ij  +   ij  . 
(6.27) 
 Covariates ( X ) can be added to the model to increase the precision of the treatment by account-
ing for additional residual variance. It should be noted that in the RD equation, the pretest score 

276  Applications of Mixed Models for Longitudinal Data 
is transformed by taking into consideration the cut point, or highest score that will separate the 
groups, which is transformed to 0. Th is deﬁ nes the intercept in the model as the mean math 
achievement score for students with the highest pretest score in the control group. Th e coef-
ﬁ cients   1 and   2 represent the potential eﬀ ects of the pretest and the eﬀ ect of the treatment, 
respectively, on math achievement. 
 At Level 2, we will allow the achievement intercept and the treatment slope to vary at random: 
 
   0 j     00 +  u 0 j  , 
(6.28) 
 
   2 j     20 +  u 2 j  . 
(6.29) 
 We will also ﬁ x the pretest slope (  1 j     10 ). Th rough substitution, we arrive at the combined 
model: 
 
  Y ij     00 +   10 npretest ij  +  20 treatment ij  +  u 2 j  treatment ij  +  u 0 j  +   ij  . 
(6.30) 
 We note that we also speciﬁ ed the covariance between the intercept and treatment slope Level 
2 by specifying a UN covariance matrix. Th is suggests seven parameters to estimate in the initial 
model (i.e., three ﬁ xed eﬀ ects, three random eﬀ ects at Level 2, and one residual). 
 In   Table 6.15  , we provide the preliminary models where we examined possible nonlinearities 
in the eﬀ ects of students’ entrance pretest scores and treatment eﬀ ects. As those can be removed, 
it strengthens the case for the diﬀ erence in eﬀ ect on either side of the cut point. We note that in 
the preliminary two models having higher order polynomial terms, no predictor was signiﬁ cant. 
We then eliminated the cubic and quadratic terms. We can see in the last model (with linear 
term) that the interaction between the pretest and treatment was nonsigniﬁ cant, suggesting it 
could also be removed from subsequent models.  
 TABLE 6.15 Examination of Higher Order Polynomial Interactions 
Variables
Cubic  Term
Quadratic Term
Linear Term
Between Teachers
 Intercept
672.648*
672.267*
671.466*
 treatment
5.563
3.702
4.661**
Student Level
 npretest
1.450
0.900
0.400**
 treatment*npretest
−2.501
−0.314
0.125
 npretest2
 0.179
0.047
 treatment*npretest2
0.112
−0.051
 npretest3
−0.008
 treatment*npretest3
−0.023
Variance Components
 Level 2 Intercept
148.48*
148.51*
148.17*
 Level 2 Slope
25.49**
25.47**
25.45**
 Covariance
5.88
5.86
6.08
 Residual 
1,340.22*
1,339.78*
1,339.32*
 *p < .05; ** p < .10. 

Applications of Mixed Models for Longitudinal Data   277
 Regression Discontinuity Models to Explain Learning Differences 
 Th e initial research question asked if there is a diﬀ erence in learning outcomes between students 
in traditional and problem-based learning groups. 
 Deﬁ ning Model 2.1 with IBM SPSS Menu Commands 
 Launch the IBM SPSS pro-
gram application, and select 
the  ch6RD-1data.sav data ﬁ le. 
  1. Go to the toolbar and 
select ANALYZE, 
MIXED MODELS, 
LINEAR. 
 Th is command enables access 
to the  Linear Mixed Models: 
Specify Subjects and Repeated 
dialog box. 
 
 2. Within the  Linear Mixed Models: Specify 
Subjects and Repeated dialog box, click to 
select  teachcode from the left column. Th en 
click the arrow button to transfer the vari-
able into the  Subjects dialog box. 
 Click the CONTINUE button to display the  Lin-
ear Mixed Models dialog box. 

278  Applications of Mixed Models for Longitudinal Data 
 
 3a. In the  Linear Mixed Models dialog 
box, click to select the  nmath vari-
able from the left column listing, 
and then click the right-arrow but-
ton to move it into the  Dependent 
Variable box. 
 
 b. Click to select  npretest and  treat-
ment and then click the right-
arrow button (or “drag them”) to 
move them into the  Covariate(s) 
box. 
 Click the FIXED button to access the 
 Linear Mixed Models: Fixed Eﬀ ects dialog 
box. 
 
 4a. Within the 
 Linear Mixed 
Models: Fixed 
Eﬀ ects dialog 
box, click the 
pull-down 
menu to change 
the factorial 
setting to  Main 
Eﬀ ects . 
 
 b. Click to select 
 npretest and 
 treatment  from 
the  Factors and 
Covariates box, 
and then click 
the ADD but-
ton to move the 
variables into 
the  Model  box. 
 
 c. Note on lower left of the screen that the intercept and the sum of squares ( Type III ) are the 
default settings. 
 Click the CONTINUE button to return to the  Linear Mixed Models dialog box. 
 We will now add random eﬀ ects to this model. 
 Click the RANDOM button to access the  Linear Mixed Models: Random Eﬀ ects dialog box 

Applications of Mixed Models for Longitudinal Data   279
 
 5a. Within the  Lin-
ear Mixed Models: 
Random Eﬀ ects box, 
change the covari-
ance type by clicking 
on the pull-down 
menu and selecting 
 Unstructured . 
 
 b. Click to select:  Include 
intercept . 
 
 c.  Change  Factorial Ef-
fects by clicking on the 
pull-down menu and 
selecting  Main Eﬀ ects . 
 
 d. Click to select  treat-
ment from the  Factors 
and Covariates box, 
and then click the 
ADD button to move 
the variable into the 
 Model box. 
 
 e. Click  teachcode from 
the  Subjects  box, and then click the right-arrow button to add the variable to the  Combinations 
box. 
 Click the CONTINUE button to return to the  Linear Mixed Models dialog box. 
  6. Th e  Linear Mixed Models: Estimation 
dialog box displays two estimation 
method choices: ML or REML. 
 In this chapter, we will use the default setting 
of REML to estimate the models. 
 Click the CONTINUE button to return to 
the  Linear Mixed Models dialog box. 

280  Applications of Mixed Models for Longitudinal Data 
  7. In the  Linear Mixed Models dialog 
box, click the STATISTICS button 
to access the  Linear Mixed Models: 
Statistics dialog box. 
 Click and select the following three 
statistics to be included in the output: 
 Parameter estimates, Tests for covariance 
parameters , and  Covariances of random 
eﬀ ects . 
 Click the CONTINUE button to return 
to the  Linear Mixed Models dialog box. 
  8. Finally, in the  Linear Mixed Models 
dialog box, click the OK button to 
run the model. 
 Interpreting the Output From Model 2.1 
 Th e ﬁ xed-eﬀ ect estimates in   Table 6.16  suggest that the mean for students in the control group 
(holding other variables at 0) was 671.818. Higher pretest scores tend to be related to higher 
scores (0.465,  p < .01). Students in the treatment group also have signiﬁ cantly higher scores than 
students in the control group (   4.710,  p < .05). 
 TABLE 6.16 Estimates of Fixed Effects a 
Parameter
Estimate
Std. Error
df
t
Sig.
95% Conﬁ dence Interval
Lower Bound Upper Bound
Intercept
671.818
2.126
76.299
316.041
.000
667.584
676.051
npretest
0.465
0.161
4,540.936
2.889
.004
0.150
0.781
treatment
4.710
2.382
397.711
1.978
.049
0.028
9.392
 a Dependent variable: nmath.   

Applications of Mixed Models for Longitudinal Data   281
 Table 6.17  presents the summary of the covariance parameters. Th e table suggests that math 
achievement varies across teachers in the study, as we might expect. Th ere is some evidence that 
the treatment also varies across teachers (Wald  Z  1.603, one-tailed  p < .06). 
 Th e results suggest we might build a model to examine variability in the math achievement 
intercepts and the treatment eﬀ ect across teachers in the study. 
 In   Figure 6.5  , we summarize the predicted scores of individuals based on their pretest and 
membership in the treatment or control group. Th e ﬁ gure illustrates the discontinuity present 
between the pretest scores (i.e., with 159 describing the highest score in the control group and 
160 the lowest score in the treatment group).  
 As noted, we transformed the pretest variable ( npretest ) so that it is centered on 159 (i.e., the 
highest score in the control group). Th is suggests that individuals in the treatment group with the 
lowest scores on the pretest (i.e., 160) will have predicted scores of about 5.18 points higher (i.e., 
4.71 + 0.47  5.18) than their immediate peers in the control group, as summarized in Table 6.16. 
 TABLE 6.17 Estimates of Covariance Parameters a 
Parameter
Estimate
Std. Error
Wald Z
Sig.
95% Conﬁ dence Interval
Lower Bound Upper Bound
Residual
1,339.071
28.210
47.469
.000
1,284.907
1,395.519
Intercept + treatment
[subject  teachcode]
UN (1, 1)
148.064
36.588
4.047
.000
91.224
240.320
UN (2, 1)
6.180
17.257
0.358
.720
−27.643
40.002
UN (2, 2)
25.430
15.859
1.603
.109
7.490
86.336
 a Dependent variable: nmath. 
 FIGURE 6.5  Regression discontinuity design illustrating treatment eﬀ ect.

282  Applications of Mixed Models for Longitudinal Data 
 Adding Explanatory Variables at Level 2 
 We might add two explanatory predictors at Level 2 (i.e., a classroom composition variable and 
a teacher quality variable). For the intercept model, we propose that the student composition 
( classcomp ) in each class aﬀ ects overall classroom achievement. We also propose that teacher 
quality ( teachqual ) inﬂ uences student progress in each class. 
 
  0 j     00 +   01 teachqual j  +   02 classcomp j  +  u 0 j  
(6.31) 
 
   2 j     20 +   21 teachqual j  +   22 classcomp j  +  u 2 j  
(6.32) 
 When we substitute these into the Level 1 equation (Eq. 6.27), we will have a combined equa-
tion with 11 parameters to estimate (i.e., seven ﬁ xed eﬀ ects, three random eﬀ ects, and one Level 
1 residual). 
 Y ij     00 +   01 teachqual j  +   02 classcomp j  +   10 npretest ij  +   20 treatment ij  
+   21 teachqual j  * treatment ij  +   22 classcomp j  * treatment ij  +  u 2 j  treatment ij  +  u 0 j  +   ij  
(6.33) 
 Deﬁ ning Model 2.2 with IBM SPSS Menu Commands 
 Continue using the  ch6RD-1data.sav  data. Settings default to those used for Model 2.1. 
  1. Go to the toolbar and select ANALYZE, MIXED MODELS, LINEAR. Th is command enables 
access to the  Linear Mixed Models: Specify Subjects and Repeated dialog box. 
  2. Th e  Linear Mixed Models: Specify 
Subjects and Repeated displays the 
default settings from Model 2.1. Th e 
variable  teachcode is within the  Subject 
box. Click the CONTINUE button 
to display the  Linear Mixed Models 
dialog box. 
  3. Th e  Linear Mixed Models dialog box 
settings default to those used in the 
prior model. 
 We will introduce two additional predic-
tors to be used in the model ( teachqual and 
 classcomp ). First, click to select  teachqual 
and  classcomp , and then “drag” the variables 
to the  Covariate(s) box above  npretest.  Th e 
sequence of the variables is the following: 
 teachqual ,  classcomp ,  npretest , and  treatment. 
 Click the FIXED button to access the  Linear Mixed Models: Fixed Eﬀ ects dialog box. 

Applications of Mixed Models for Longitudinal Data   283
 
 4a. Th e  Linear Mixed 
Models: Fixed Eﬀ ects  
dialog box displays 
the default setting 
from the prior model. 
To facilitate reading 
the output tables, we 
will ﬁ rst remove the 
two variables ( npretest 
and  treatment ) by 
clicking to select the 
variables and then 
clicking the RE-
MOVE button. 
 
 b. Conﬁ rm that the 
factorial setting is 
 Main Eﬀ ects  before 
adding the predictor 
variables to the model. 
 
 c. Now click to select all the variables from the  Factors and Covariates box, and then click the ADD 
button to move the variables into the  Model  box. 
 Two cross-level interactions (or nested terms) will be created and added to the model:  classcomp * treat-
ment and  teachqual * treatment . Th ese interactions will tell us whether (a) teacher quality ( teachqual ) 
inﬂ uences the strength of the treatment eﬀ ect in each class and (b) student composition ( classcomp ) in 
each class inﬂ uences the treatment eﬀ ect. 
 Add First Interaction to Model 2.2: 
 teachqual*treatment 
 
 d. Click to select  Build nested terms.  
 
 e. Click to select the variable 
 teachqual from the  Factors and 
Covariates box. 
 
 f. Th en click the arrow button 
below the  Factors and Covariates 
box. Th is moves  teachqual into 
the  Build Term box to create a 
cross-level interaction by linking 
variables and terms. 
 
 g. Next, click the BY * button, 
which will insert the computa-
tion command symbol:  teachqual* . 
 
 h. Click to select  treatment  from the  Factors and Covariates box. 
 
 i. Click the arrow button below the  Factors and Covariates box to move  treatment into the  Build 
Term box and complete the interaction term:  teachqual*treatment. 
 
 j. Click the ADD button to transfer the interaction into the  Model box. 
 Add Second Interaction to Model 2.2:  classcomp*treatment 
 Repeat steps 4d to 4j using  classcomp  and  treatment  for the interaction. Th e ﬁ nal model is shown in the insert. 
 Click the CONTINUE button to return to the  Linear Mixed Models dialog box. 

284  Applications of Mixed Models for Longitudinal Data 
  5. Finally, in the  Linear Mixed Models 
dialog box, click the OK button to 
run the model. 
 TABLE 6.18 Estimates of Fixed Effects a 
Parameter
Estimate
Std. Error
df
t
Sig.
95% Conﬁ dence Interval
Lower Bound Upper Bound
Intercept
671.918
1.679
85.023
400.185
.000
668.579
675.256
teachqual
3.418
1.476
62.980
2.316
.024
0.468
6.368
classcomp
−15.644
2.419
45.706
−6.466
.000
−20.514
−10.773
npretest
0.462
0.161
4,544.787
2.865
.004
0.146
0.777
treatment
4.912
2.406
360.340
2.042
.042
0.180
9.644
teachqual*treatment
0.542
1.521
68.353
0.356
.723
−2.493
3.578
classcomp*treatment
−0.756
2.362
43.662
−0.320
.751
−5.517
4.006
 a Dependent variable: nmath. 
 Interpreting the Output From Model 2.2 
 We provide the ﬁ xed eﬀ ects in   Table 6.18  . Th e results suggest that teacher quality aﬀ ects achieve-
ment levels (  01  3.418,  p < .05) and, as we might expect, classroom composition does aﬀ ect 
achievement levels (  02  ‒15.644,  p < .001). With respect to the treatment, however, neither 
teacher quality nor classroom composition aﬀ ects the strength of the treatment eﬀ ect. In terms 
of our research goals, we can interpret these results in positive terms by suggesting that the prob-
lem-based treatment appeared to enhance student learning, regardless of the speciﬁ c classroom 
composition or teacher quality.  
 Investigating a Change Due to Policy Implementation 
 In this ﬁ nal example, we examine whether a policy, or some other type of intervention, has an 
impact on its intended targets. One design that is useful in examining trends before and after 
a policy is introduced is a time series design. Th e essence of a time series design is the presence 
of periodic measurements and the introduction of an experimental change into this time series 
of measurements. Th e introduction of the treatment is expected to produce a discontinuity in 
the series of measurements at some hypothesized interval after its introduction. Consider an 
example concerning the introduction of a policy to increase the academic standards for freshman 
student athletes and institutions’ responses to recruiting freshman student athletes before and 
after the policy was introduced (e.g., see Heck & Takahashi, 2006, a more extended treatment of 
this approach). In this case, we examine whether the introduction of Proposition 48 during the 

Applications of Mixed Models for Longitudinal Data   285
mid-1980s had any impact on institutional behavior regarding freshman student athletes. Propo-
sition 48 was implemented to increase institutions’ graduation rates by upgrading their academic 
standards for admitting student athletes. 
 A thorough test of the policy’s impact on changing institutions’ recruiting behavior would require 
the analyst to compare the behavioral trend before and after the policy was introduced. A piecewise 
growth model—where the growth trajectories are split into two or more trends—can be used to 
compare growth rates during two diﬀ erent prepolicy and policy implementation periods. In our 
example, we study freshman student athletes admitted to Division 1A football programs during a 
9-year period. More speciﬁ cally, 3 years of data were collected before the introduction of the policy, 
and 6 years of data were collected after the policy’s implementation. In a time series design, evidence 
of a treatment’s eﬀ ect is indicated by a discontinuity in the measurements recorded in the time series 
(Campbell & Stanley, 1966). In this example, the time series design may be diagrammed as follows: 
 0 1 0 2 0 3 X 0 4 0 5 0 6 0 7 0 8 0 9 , 
 where the three 0s preceding the  X represent a yearly trend in freshman athletes admitted be-
fore the introduction of the policy. Th e design is a sound quasi-experimental design, provided 
certain threats to internal validity can be successfully argued away (Campbell & Stanley, 1966). 
Basically, the problem of internal validity reduces to the question of whether plausible compet-
ing hypotheses oﬀ er likely alternative explanations for any shift in the time series other than the 
introduction of the policy (Campbell & Stanley, 1966). 
 Th e major threats to the internal validity of the single-group time series design are instru-
mentation, testing, and history. Instrumentation and testing can be argued away more easily in 
this case because the data were collected utilizing the same variables and no repeated testing 
on individuals was done, as might be the case if the data were collected from individuals who 
received a treatment of some type. Th e determination of change is considered solely on the 
ﬂ uctuations in the institutional data prior to policy implementation and the years following its 
implementation. Th reats due to history, however, could be a potential problem. Rival explana-
tions could include changes in the institutional norms within the set of schools (that may or 
may not correspond to the policy’s introduction) or perhaps cyclical events. Th e observational 
series can be arranged to hold these types of cycles relatively constant (e.g., the data are col-
lected at the same time and over a relatively long period of time). Th is lessens the possibility that 
some other corresponding extraneous event would produce the expected trends other than the 
implementation of the policy (or other type of treatment). To deal with history as a rival expla-
nation, however, it is important for the researcher to specify in advance the expected relation-
ship between the introduction of the treatment and the manifestation of an eﬀ ect (Campbell 
& Stanley, 1966)—that is, how soon the eﬀ ect would be seen. Importantly, as the time between 
implementation and resultant eﬀ ects increases, the eﬀ ects of extraneous events become more 
plausible. 
 By raising institutions’ academic standards to increase graduation rates (i.e., the policy’s 
intended eﬀ ect), it is likely that the policy also resulted in a reduction of freshman athletes 
being admitted to programs, especially in some types of institutions. If this were true, over 
the course of data collection, ﬁ rst, we should note a discontinuity of measurements (i.e., the 
decline of freshman being admitted) after the policy was introduced. Second, it is likely that 
a shrinking pool of student athletes might aﬀ ect the football recruiting practices of some 
schools more than others. We might hypothesize that schools with greater prestige (deﬁ ned as 
schools with outstanding on-ﬁ eld performance and frequent bowl appearances) would be less 
aﬀ ected in their eﬀ orts to recruit freshman athletes than would less prestigious schools. We 
might also test whether the policy aﬀ ected public and private institutions diﬀ erently in terms 
of recruiting. 

286  Applications of Mixed Models for Longitudinal Data 
 We can formulate a piecewise growth model to test these hypotheses against the data. In our 
formulation, we ﬁ rst focus on comparing the growth trend before the policy was implemented 
versus the growth trend after it was implemented. We will assume that the eﬀ ects of the policy 
will be seen immediately after the policy was introduced (since compliance was immediate). It 
is possible, however, to investigate lagged (or delayed) eﬀ ects. Th e second part of the analysis 
involves examining how covariates such as institutional prestige and institutional type (i.e., 
public or private) might aﬀ ect the key initial status and growth coeﬃ  cients before and after 
the policy was introduced. Piecewise growth models can be used to represent diﬀ erent phases 
of development or change. One way to do this is to examine whether there is a “discontinuity,” 
or change, in the time series at the point where the policy is introduced ( X ) or at some speci-
ﬁ ed point afterward. In this example, it is likely that the growth (slope) parameter of freshman 
admits in Division I football programs would be negatively aﬀ ected by the introduction of 
Proposition 48. Th erefore, we can develop separate growth slopes before and after the policy 
was introduced. Covariates can be added to the model to help reﬁ ne the examination of the 
contrasting trends. 
 The Data 
 Th e data in this example consist of outcome data on the number of freshman student athletes 
admitted to 105 Division 1A football programs over a 9-year period (i.e., 3 years before the 
introduction of the policy and 6 years after its implementation). Data were also collected on pro-
gram prestige (i.e., program success over a 5-year period of time) and institutional type (public 
or private). Th e variables are presented in Table 6.19. 
 TABLE 6.19  Data Deﬁ nition of  ch6RD-2data.sav ( N  105) 
Variable
Levela
Description
Values
Measurement
schid
Individual
School identiﬁ er (105 schools). 
Integer
Ordinal
private
School
Dichotomous variable identifying institutions as 
private or public.
0  Not Private
1  Private
Scale
prestige
School
Predictor variable measuring program success. 2.00 to 4.551
Scale
Index1
Individual
Variable represents the nine repeated 
measures of graduation status.
(1 , 2, 3, 4, 5, 6, 7, 
8, 9)
Nominal
freshadmit
Individual
Dependent variable representing the number 
of freshman student athletes admitted to 
football programs.
1 to 38
Scale
implement
Individual
Independent variable representing the 
prepolicy and policy periods.
0  No Policy
1  Policy
Scale
time
Individual
Preliminary variable representing the pre-policy 
and policy time periods (0,1,2,0,1,2,3,4,5).
(0, 1, 2, 3, 4, 5) 
Nominal
implement0
Individual
Recoded Index1 variable to a time-related 
variable representing the prepolicy period's 
yearly growth 
(0, 1, 2, 2, 2, 2, 2, 2, 2). 
(0, 1, 2, 2, 2, 2, 2, 
2, 2)
Nominal
implement1
Individual
Recoded Index1 variable to a time-related 
variable representing the policy period's 
yearly growth (0, 0, 0, 1, 2, 3, 4, 5, 6).
(0, 0, 0, 1, 2, 3, 4, 
5, 6).
Nominal
 a Individual  Level 1; school  Level 2.   

Applications of Mixed Models for Longitudinal Data   287
 Model 3.1: Establishing the Prepolicy and Policy Trends 
 Model 3.1 consists of one intercept and two growth trends. Th e data were coded such that the 
intercept represents initial status (i.e., Year 1). Th e ﬁ rst growth parameter then describes the 
 change per year  over the 3 years before the policy was implemented. Th e second growth trend 
represents change taking place after the policy was implementation (i.e., Year 4). Once again, 
we can open the  Repeated dialog box using the  Index1  variable, which represents the nine re-
peated measures of graduation status. We then can recode this variable into two time-related 
variables, which we named  implement0 (representing the prepolicy period) and  implement1 
(representing the policy implementation period). Readers may wish to examine the data set 
to see how the two time-related variables are coded.  Implement0 is coded to indicate yearly 
growth during the prepolicy period (0, 1, 2, 2, 2, 2, 2, 2, 2). Th e ﬁ rst measurement is coded 0, 
so it will be interpreted as the intercept, or the average number of freshman student athletes 
admitted to Division 1A football programs at the beginning of the study. Th e 2s from Year 4 
to the end of the study indicate that the prepolicy period ends after Year 3. Th e policy imple-
mentation variable is coded to indicate no growth during the prepolicy period (0, 0, 0, 1, 2, 3, 
4, 5, 6) and then captures the yearly change beginning at Year 4. Interested readers can consult 
Raudenbush and Bryk (2002) or Orsuwan and Heck (2009) for further information about 
coding piecewise growth models. 
 From Equation 6.1, at Level 1, for institution  i at time  t we have the following model: 
 
  Y ti    π 0 i  +  π 1 i  implement0 ti  +  π 2 i  implement1 ti  +   ti  , 
(6.34) 
 where  π 0 i  is the initial status intercept in terms of entering freshman student athletes,  π 1 i  is 
the yearly rate of change before the policy was implemented ( implement0 ),  π 2 i  is the yearly 
rate of change after the policy was implemented ( implement1 ), and   ti  represents errors in 
estimating each institution’s growth trajectory, which are assumed to be normally distrib-
uted with a mean of 0 and some variance. We note that it is possible to add a second inter-
cept for the policy implementation trend, which requires defining a multivariate model (see 
Chapter 7). 
 Th e Level 2 (between institutions) model is deﬁ ned as 
 π 0 i     00 +  u 0 i  , 
 
  π 1 i     10 , 
 
  π 2 i     20 , 
(6.35) 
 where   10 and   20 are the prepolicy implementation and policy implementation intercepts and  u 0 i  
is a random initial status intercept. In preliminary analyses, we found that the policy slopes did 
not vary across institutions, so we ﬁ xed those parameters ( u 1 i  ,  u 2 i  ) between institutions in Equa-
tion 6.35. Th rough substitution, the combined model is then 
 
  Y ti   +   00 i  +   10 i  implement0 ti  +   20 i  implement1 ti  +  u 0 i  +   ti  . 
(6.36) 
 We found in preliminary investigation that a diagonal covariance structure ﬁ t the data well at 
Leve1, and there is only a single random intercept at Level 2. 

288  Applications of Mixed Models for Longitudinal Data 
 Deﬁ ning Model 3.1 with IBM SPSS Menu 
Commands 
 Launch the IBM SPSS program application, 
and select the  ch6RD-2data.sav data ﬁ le. 
  1. Go to the toolbar and select ANALYZE, 
MIXED MODELS, LINEAR. 
 Th is command enables access to the  Linear 
Mixed Models: Specify Subjects and Repeated 
dialog box. 
 
 3a. In the  Linear Mixed Models dialog box, 
click to select the  freshadmit variable 
from the left column listing, and then 
click the right-arrow button to move it 
into the  Dependent Variable box. 
 
 b. Click to select  implement0 and  imple-
ment1 , and then click the right-arrow 
button (or “drag them”) to move them 
into the  Covariate(s) box. 
 Click the FIXED button to access the  Linear 
Mixed Models: Fixed Eﬀ ects dialog box. 
 
 2a. Within the  Linear Mixed Models: Specify Subjects 
and Repeated dialog box, click to select the  schid 
variable from the left column, and then click the 
arrow button to transfer the variable into the  Sub-
jects dialog box. 
 
 b. Th e  Repeated box allows specifying variables that 
identify repeated observations. For this model, 
 Index1 identiﬁ es repeated observations over nine 
time periods. Click to select  Index1 , and then 
click the right-arrow button to move the variable 
into the  Repeated box. 
 
 c. Th e  Repeated Covariance Type speciﬁ es a model’s 
covariance structure. For this model, we will use the 
 Diagonal  covariance matrix. Click the pull-down 
menu to select the  Diagonal  covariance matrix as 
the  Repeated Covariance Type. 
 Click the CONTINUE button to display the  Linear Mixed 
Models dialog box. 

Applications of Mixed Models for Longitudinal Data   289
 
 4a. Within the  Linear Mixed 
Models: Fixed Eﬀ ects dialog 
box, click the pull-down 
menu to change the facto-
rial setting to  Main Eﬀ ects . 
 
 b. Click to select  implement0 
and  implement1  from the 
 Factors and Covariates box, 
and then click the ADD 
button to move the vari-
ables into the  Model box. 
 
 c. Note on lower left of the 
screen that the intercept 
and the sum of squares 
( Type III ) are the default 
settings. 
 Click the CONTINUE button to return to the  Linear Mixed Models dialog box. 
 We will now add random eﬀ ects to this model. 
 Click the RANDOM button to access the  Linear Mixed Models: Random Eﬀ ects dialog box. 
 
 5a. Within the  Linear Mixed 
Models: Random Eﬀ ects box, 
change the covariance type 
by clicking on the pull-down 
menu and selecting  Scaled 
Identity . 
 
 b. Click to select  Include 
intercept . 
 
 c. Click  schid  from the  Subjects 
box, and then click the right-
arrow button to add the 
variable to the  Combinations 
box. 
 Click the CONTINUE button to 
return to the  Linear Mixed Models 
dialog box. 

290  Applications of Mixed Models for Longitudinal Data 
  6. In the  Linear Mixed Models dialog box, 
click the ESTIMATION button to 
access the  Linear Mixed Models: Esti-
mation dialog box. 
 Th e  Linear Mixed Models: Estimation dialog 
box displays two estimation method choices: 
ML or REML. 
 In this chapter, we will use the default 
setting of REML to estimate the models. 
Readers should keep in mind that if they 
compare models with regression slopes and 
covariance parameters, ML estimation is 
preferred (Hox, 2010). 
 Click the CONTINUE button to return to 
the  Linear Mixed Models dialog box. 
  7. In the  Linear Mixed Models dialog 
box, click the STATISTICS button 
to access the  Linear Mixed Models: 
Statistics dialog box. 
 Click and select the following three 
statistics to be included in the output: 
 Parameter estimates ,  Tests for covariance pa-
rameters , and  Covariances of random eﬀ ects . 
 Click the CONTINUE button to return 
to the  Linear Mixed Models dialog box. 
 8. Finally, in the  Linear Mixed Mod-
els dialog box, click the OK button 
to run the model.

Applications of Mixed Models for Longitudinal Data   291
 Interpreting the Output From Model 3.1 
 Th is proposed model suggests 13 parameters to estimate (three ﬁ xed eﬀ ects, one random eﬀ ect, 
and nine diagonal variances at Level 1). Th is can be conﬁ rmed in   Table 6.20  , which summarizes 
the model dimensions.  
 We present the ﬁ xed eﬀ ects in   Table 6.21  on page 292. We can see that the ﬁ rst slope (before the 
policy was introduced) is negative but not declining signiﬁ cantly (  10  ‒0.441,  p > .05). Th e slope 
after the introduction of the policy, however, does decline signiﬁ cantly (  20  ‒0.585 ,  p < .001). 
 We present the variance components in   Table 6.22  . We can see that there is signiﬁ cant vari-
ance in initial status intercepts across institutions (Wald  Z  5.317,  p < .001). Th e variances for 
the repeated measures are considerably diﬀ erent, providing some evidence for why in our pre-
liminary models the diagonal structure ﬁ t the data better than an autoregressive or compound 
symmetry covariance structure.  
 TABLE 6.20 Model Dimension a 
Number of 
Levels
Covariance 
Structure
Number of 
Parameters
Subject 
Variables
Number of 
Subjects
Fixed Effects
Intercept
 1
 1
implement0
 1
 1
implement1
 1
 1
Random Effects
Intercept
 1
Identity
 1
schid
Repeated Effects
Index1
 9
Diagonal
 9
schid
105
Total
13
13
 a Dependent variable: freshadmit.   
 TABLE 6.21 Estimates of Fixed Effects a 
Parameter
Estimate
Std. Error
df
t
Sig.
95% Conﬁ dence Interval
Lower Bound Upper Bound
Intercept
22.206
0.444
176.312
49.978
.000
21.329
23.083
implement0
−0.441
0.251
224.738
−1.755
.081
−0.935
0.054
implement1
−0.585
0.070
357.231
−8.391
.000
−0.722
−0.448
 a Dependent variable: freshadmit.   

292  Applications of Mixed Models for Longitudinal Data 
 Final Model with Covariates Added 
 Our ﬁ nal model adds school type (  01 ), deﬁ ned as private (coded 1) versus (public  0), and in-
stitutional prestige (  02 ) at Level 2 for the intercept model: 
 
  π 0    00 +   01 private i  +   02 prestige i  +  u 0 i  . 
(6.37) 
 Th e nonrandomly varying slope models will be the following: 
 
  π 1 i     10 +   11 private i  +   12 prestige i  +  u 1 i  , 
(6.38) 
 π 2 i     20 +   21 private i  +   22 prestige i  +  u 2 i  . 
 TABLE 6.22 Estimates of Covariance Parameters a 
Parameter
Estimate
Std. Error
Wald Z
Sig.
95% Conﬁ dence Interval
Lower Bound Upper Bound
Repeated Measures
Var: [Index1  1]
18.209
2.729
6.671
.000
13.573
24.427
Var: [Index1  2]
23.806
3.487
6.827
.000
17.865
31.722
Var: [Index1  3]
19.046
2.846
6.692
.000
14.210
25.527
Var: [Index1  4]
24.754
3.644
6.792
.000
18.549
33.034
Var: [Index1  5]
20.872
3.084
6.768
.000
15.624
27.882
Var: [Index1  6]
15.408
2.341
6.583
.000
11.441
20.752
Var: [Index1  7]
12.117
1.888
6.417
.000
8.928
16.445
Var: [Index1  8]
12.287
1.909
6.436
.000
9.061
16.661
Var: [Index1  9]
9.960
1.599
6.228
.000
7.271
13.644
Intercept 
[subject  schid]
Variance
5.230
0.984
5.317
.000
3.617
7.561
 a Dependent variable: freshadmit.   
TABLE 6.23 Model Dimensiona
Number of 
Levels
Covariance 
Structure
Number of 
Parameters
Subject 
Variables
Number of 
Subjects
Fixed Effects
Intercept
 1
 1
private
 1
 1
prestige
 1
 1
implement0
 1
 1
implement1
 1
 1
private * implement0
 1
 1
prestige * implement0
 1
 1
private * implement1
 1
 1
prestige * implement1
 1
 1
Random Effects
Intercept
 1
Identity
 1
schid
Repeated Effects
Index1
 9
Diagonal
 9
schid
105
Total
19
19
 a Dependent variable: freshadmit.   

Applications of Mixed Models for Longitudinal Data   293
 Th e Level 1 model remains the same as Equation 6.34. Th ough substitution of Equations 
6.37 and 6.38 into Equation 6.34, we obtain the combined model (we leave this last step to 
readers). As the previous equations suggest, this model will add six more parameters to be 
estimated (i.e., two eﬀ ects on the intercept, two eﬀ ects on the prepolicy trend, and two eﬀ ects 
on the policy implementation trend), which can be conﬁ rmed in the model dimension table 
( Table 6.23 ).  
 Deﬁ ning Model 3.2 with IBM SPSS Menu Commands 
 Continue using the  ch6RD-2data.sav  data. Settings default to those used for Model 3.1. 
  1. Go to the toolbar and select ANALYZE, MIXED MODELS, LINEAR. Th is command enables 
access to the  Linear Mixed Models: Specify Subjects and Repeated dialog box. 
  2. Th e  Linear Mixed Models: Specify Subjects and Repeated displays the default settings from Model 3.1. 
Th e variables  schid  and  Index1  are in the  Subject  and  Repeated box, respectively. Th e chosen covariance 
type is  Diagonal. Click the CONTINUE button to display the  Linear Mixed Models dialog box. 
  3. Th e  Linear Mixed Models dialog box 
settings default to those used in the 
prior model. 
 We will introduce two additional predic-
tors to be used in the model ( private and 
 prestige ). First, click to select  private and 
 prestige , and then “drag” the variables to 
the  Covariate(s) box above  implement0. 
Th e sequence of the variables is the fol-
lowing:  private ,  prestige ,  implement0 , and 
 implement1. 
 Click the FIXED button to access the 
 Linear Mixed Models: Fixed Eﬀ ects dialog 
box. 
 
 4a. Th e  Linear Mixed Models: 
Fixed Eﬀ ects dialog box 
displays the default setting 
from the prior model. To 
make reading the output 
tables easier, we will rear-
range the sequence order 
of the variables by ﬁ rst 
removing the two variables 
( implement0 and  imple-
ment1 ). Click both variables 
to select them, and then 
click the REMOVE button. 
 
 b. Conﬁ rm that the facto-
rial setting is  Main Eﬀ ects 
before adding the predictor 
variables to the model. 
 
 c. Now click to select all the variables from the  Factors and Covariates box, and then click the 
ADD button to move the variables into the  Model box. 

294  Applications of Mixed Models for Longitudinal Data 
 Four cross-level interactions (or nested terms) will be created and added to the model: 
 implement0*private ,  implement0*prestige ,  implement1*private , and  implement1*prestige . 
 Add First Interaction to Model 3.2: 
 implement0*private 
 
 d. Click to select  Build nested 
terms. 
 
 e. Click to select the variable 
 implement0 from the  Factors 
and Covariates box. 
 
 f. Th en click the arrow button 
below the  Factors and Covari-
ates box. Th is moves  implement0 
into the  Build Term box to cre-
ate a cross-level interaction by 
linking variables and terms. 
 
 g. Next, click the BY* button. Th is 
will insert the computation 
command symbol:  implement0* . 
 
 h. Click to select  private from the  Factors and Covariates box. 
 
 i. Click the arrow button below the  Factors and Covariates box to move  private into the  Build 
Term box and complete the interaction term:  implement0*private. 
 
 j. Click the ADD button to transfer the interaction into the  Model box. 
 Add Second Interaction to Model 3.2:  implement0*prestige 
 Repeat steps 4d to 4j using  implement0 and  prestige for the interaction. 
 Add Third Interaction to Model 3.2:  implement1*private 
 Repeat steps 4d to 4j using  implement1 and  private for the interaction. 
 Add Fourth Interaction to Model 3.2:  implement1*prestige 
 Repeat steps 4d to 4j using  implement1 and  prestige for the interaction. 
 Th e completed model is shown in the insert. Click the CONTINUE button to return to the  Linear 
Mixed Models dialog box. 
  5. Finally, in the  Linear Mixed 
Models dialog box, click 
the OK button to run the 
model. 

Applications of Mixed Models for Longitudinal Data   295
 Interpreting the Output From Model 3.2 
 We next provide the ﬁ xed-eﬀ ects results in   Table 6.24  . Th e intercept model suggests that initially 
schools with higher prestige got more freshman athletes (  02  0.904,  p  .01). School type, how-
ever, did not inﬂ uence freshman athletes admitted initially. Moreover, neither predictor aﬀ ected 
the institutional growth trend before the policy was implemented ( p > .05). After implementa-
tion, however, private schools got increased numbers of students over each yearly interval (  21  
0.374,  p < .05). In contrast, higher prestige schools did not appear to receive more freshmen after 
implementation (  22  ‒0.008,  p > .05). We could, of course, also add other variables to the model, 
but our analysis seems to suggest the policy did result in fewer freshman student athletes being 
entered to Division 1A programs (  20  ‒0.651,  p < .001), after controlling for other variables 
that might also aﬀ ect the admission of freshman student athletes. Th e variance components are 
similar to previous models, so we do not provide them here.  
 Summary 
 Longitudinal analysis represents a rapidly growing application of multilevel-modeling tech-
niques. Because they provide stronger ways for dealing with causal relationships between vari-
ables than cross-sectional analyses, they should continue to draw the increased attention of 
researchers. In this chapter, we introduced a basic multilevel model considering change at several 
levels of a data hierarchy. Th e approach is very ﬂ exible for ﬁ tting a number of research purposes 
and designs (e.g., experimental, time series, and nonexperimental).  
 TABLE 6.24 Estimates of Fixed Effectsa
Parameter
Estimate
Std. Error
df
t
Sig.
95% Conﬁ dence Interval
Lower Bound Upper Bound
Intercept
22.147
0.485
171.064
45.660
.000
21.190
23.105
private
−0.426
1.138
171.064
−0.374
.709
−2.672
1.821
prestige
0.904
0.346
171.064
2.611
.010
0.221
1.588
implement0
−0.447
0.278
224.030
−1.607
.109
−0.995
0.101
implement1
−0.651
0.077
355.077
−8.434
.000
−0.802
−0.499
private * implement0
0.189
0.652
224.030
0.290
.772
−1.096
1.475
prestige * implement0
−0.203
0.199
224.030
−1.025
.307
−0.595
0.188
private * implement1
0.374
0.181
355.077
2.064
.040
0.018
0.730
prestige * implement1
−0.008
0.055
355.077
−0.144
.886
−0.116
0.100
 a Dependent variable: freshadmit.  

              This page intentionally left blank

297
 CHAPTER 7 
 Multivariate Multilevel Models 
 I
 n the last chapter, we introduced a three-level modeling framework for examining change in 
 individuals and groups over time. Another variation on the basic three-level modeling frame-
work is a multivariate multilevel model—that is, a model that has more than one dependent 
variable (deﬁ ned at Level 1), with individuals at Level 2 and groups at Level 3. Th e multivariate 
multilevel model follows directly from the traditional single-level multivariate analysis of vari-
ance (MANOVA) model. One of the advantages of the multilevel formulation is that subjects 
with partial data on outcomes can be included in the analysis, which is a limitation of MANOVA 
(Hox, 2010). A second advantage is that the multivariate approach facilitates the development of 
more ﬂ exible models with multiple response variables, which can have diﬀ erent sets of explana-
tory variables (Wright, 1998). A third advantage is that the multivariate provides simultaneous 
estimation of the outcomes and adjustment for correlations between them. Moreover, it facili-
tates the use diﬀ erent covariance structures at multiple levels along with a choice in methods to 
estimate them (Wright, 1998). 
 Th ere are a number of diﬀ erent ways to specify and set up multilevel models with multivariate 
outcomes. In this chapter, we provide three examples of two- and three-level models with mul-
tivariate outcomes. Th e ﬁ rst example is where several survey items are combined to deﬁ ne one or 
more latent constructs at the lowest level of the model. Th is type of latent variable formulation al-
lows the incorporation of measurement error, as well as possible missing data on items, in the anal-
ysis of diﬀ erences in the constructs within and between groups. Th e second is where there are two 
or more observed outcomes, for example, where we might examine students’ reading, math, and 
language test scores simultaneously, rather than modeling each outcome separately. Th is formula-
tion is useful in adjusting parameters for the expected correlation between students’ performance 
on each test. Th e third example is where we are interested in examining individual development 
in two or more domains simultaneously, rather than examining each growth trajectory separately. 
 We hope that our basic introduction to these types of models will encourage readers to think 
about situations in their own research where they might examine several outcomes simultane-
ously. Multilevel models with multivariate outcomes can be constructed much like the univariate 
growth models presented in Chapters 5 and 6. We do caution, however, that multivariate formu-
lations can be more complicated to specify and to interpret than their univariate counterparts. 
Th ey may also require more computer memory space and, therefore, be more challenging to esti-
mate. Readers can also consult Raudenbush and Bryk (2002) or Hox (2010) for other examples 
of multivariate multilevel models. 
 Multilevel Latent-Outcome Model 
 Our ﬁ rst example focuses on using a set of observed indicators (e.g., survey items) to measure 
an underlying construct (e.g., job satisfaction or motivation). We propose a model consisting of 
two latent constructs measured with three survey items each (with items measured on ﬁ ve-point 

298  Multivariate Multilevel Models 
scales). Individuals were asked several questions about their  job satisfaction  (i.e., my work is chal-
lenging and varied; I feel my work is valued; I feel like I am a member of a team) and the evalu-
ation of their  work performance  (i.e., my work is regularly assessed; I am provided with feedback 
regarding my progress; I am evaluated according to clearly known evaluation standards). We 
assume the two constructs are positively correlated at the individual and organizational levels. 
We will next build a three-level model to examine variability in employee perceptions within and 
between organizations. We note in passing that this same model could also be deﬁ ned as a two-
level structural equation model (i.e., individuals nested in organizations). 
The Data
 Th e data consist of 650 employees in 105 organizations who were asked several questions about 
their work lives. At Level 1, there are six survey items nested within 650 individuals. Th e basic 
means of specifying multivariate models in MIXED is to deﬁ ne the multiple response ( Y ) vari-
ables vertically in the same manner that the growth models in Chapters 5 and 6 were deﬁ ned. In 
this case, when the items are stacked vertically within individuals, we have 3,900 data lines. We 
use the  Repeated  dialog box to deﬁ ne the measurement model at Level 1. We can use an  index 
variable to deﬁ ne the set of items measuring the constructs and a dichotomous indicator ( assess-
job ) to deﬁ ne each construct (i.e., with  assessjob  0 referring to job satisfaction and  assessjob  1 
referring to job performance). In our example, each construct is measured by three items, but it is 
easy to vary the number of items that would deﬁ ne each factor. At Level 2, we obtain background 
TABLE 7.1 Data Deﬁ nition of ch7worklifeorg.sav (N = 650)
Variable
Levela
Description
Values
Measurement3
id
Individual
Employee identiﬁ er (650 employees). Integer
Ordinal
orgcode
Organization
Organization identiﬁ er (150 
organizations).
Integer
Ordinal
Rid
Individual
A within-group level identiﬁ er 
representing recoded employee 
identiﬁ ers (id  ) rankingwith the 
organizational identiﬁ er (orgcode). 
(1, 2, 3,. . ., 12)
Ordinal
Index1
Within Individual
Identiﬁ er variable resulting from 
indexing the id individual identiﬁ er 
(1 to 650) to create a new identiﬁ er 
to deﬁ ne each of the six items.
(1, 2, 3, 4, 5, 6)
Nominal
work
Within Individual
Dependent variable measuring 
work life (scale).
(1, 2, 3, 4, 5)
Nominal
assessjob
Within Individual
Dichotomous indicator variable 
measuring job assessment.
0 = Job Satisfaction
1 = Job Performance
Nominal 
female
Individual
Demographic predictor variable 
representing gender.
0 = Male
1 = Female
Nominal
stability
Individual
Dichotomous variable representing 
years employed. 
0 =  5 Years
1 = ≥ 5 Years
Nominal
gmorgprod
Organization
Predictor interval variable (grand-
mean centered) measuring 
organizational productivity.
–0.54 to 1.30
Scale
gmresources
Organization
Predictor interval variable grand-
mean centered) measuring 
resource allocation.
–3.17 to 2.18
Scale
a Within Individual = repeated measures, Level 1; Individual = Level 2; Organization = Level 3.
3 Measurement icon settings displayed in subsequent model screenshots may differ from Tables 7.1, 7.17, and 7.24, 
but will not affect the output

Multivariate Multilevel Models  299
TABLE 7.2 Descriptive Statistics
N
Mean
Std. Deviation
Skewness
Kurtosis
Statistic
Statistic
Statistic
Statistic
Std. Error
Statistic
Std. Error
W1varied
650
3.96
1.058
–0.892
0.096
0.128
0.191
W2value
650
4.21
0.847
–1.099
0.096
1.339
0.191
W3team
650
3.56
1.096
–0.524
0.096
–0.396
0.191
P1assess
650
3.94
1.028
–0.680
0.096
–0.401
0.191
P2progress
650
3.76
0.917
–0.422
0.096
–0.114
0.191
P3evstand
650
3.78
1.137
–0.722
0.096
–0.248
0.191
Valid N (Listwise)
650
data on the 650 individuals in the study. We include two predictors—gender (coded male  0, 
and female  1) and stability (coded 0  less than 5 years with company, and 1  5 years or more). 
At Level 3, we also include two organizational predictors (resource allocation and organizational 
productivity). A complete description of the data used in the example is provided in   Table 7.1 . 
 Research Questions 
 Th e ﬁ rst research question concerns whether individuals’ perceptions diﬀ er according to their 
backgrounds and experience working in their organizations. We might ask: Are individuals’ per-
ceptions of their job satisfaction and job performance diﬀ erentiated by gender and their length 
of time working in their workplace? Th e second research question concerns whether the slope 
describing the proposed positive relationship between the length of time individuals have been 
employed in their workplace and their perceptions of the work life constructs speciﬁ ed varies 
across organizations. Th is research question focuses on whether the size of a within-group slope 
varies randomly across organizations; that is, do organizational variables moderate the eﬀ ect of 
length of service within the organization on individuals’ workplace perceptions? 
 Deﬁ ning the Constructs 
 We note that there are a number of potential problems to consider when measuring underly-
ing constructs with observed ordinal indicators. One common problem is the situation where 
individuals are bunched at the top or the bottom of an ordinal scale. Although with ordinal data 
from ﬁ ve-point scales acceptable solutions can be generated where data do not depart too much 
from normality (Boomsma, 1987; Rigdon, 1998), we suggest that researchers check the prop-
erties of their data in each speciﬁ c instance (Flora & Curran, 2004). Alternatively, we can also 
estimate such models using a multilevel ordinal formulation. For dichotomous items, multilevel 
logistic regression can be used (Hox, 2010). In   Table 7.2  , we provide a summary of the descrip-
tive statistics on the individual items across the 650 individuals. We can see that the means 
are relatively high (ranging from 3.56 to 4.21) and, therefore, the items are negatively skewed. 
Skewness ranges from ‒1.10 to ‒0.422 and kurtosis ranges from ‒0.401 to 1.34. Th is suggests 
more responses in the higher categories (i.e., four and ﬁ ve). Although there may be some bias 
in calculating correlations based on the assumption that the data are interval, our preliminary 
investigations suggest we should be able to obtain a satisfactory solution. 
     Th e goal of the analysis is to examine individual and organizational predictors of employees’ 
beliefs about their work life and evaluation of their productivity. Our ﬁ rst concern is whether 
there is evidence that the six items in the study do indeed deﬁ ne two separate latent dimen-
sions. To build our case, we ﬁ rst used exploratory factor analysis (i.e., principal axis factoring 

300  Multivariate Multilevel Models 
with oblimin rotation) to examine whether the six items deﬁ ne the two proposed constructs. In 
 Table 7.3  , we provide the pattern (or weighted loading) matrix. As the table indicates, the three 
performance assessment items load primarily on Factor 1 (with hypothesized loadings ranging 
from 0.720 to 0.836, while the three workplace items (W1–W3) load highly on Factor 2 (with 
hypothesized loadings ranging from 0.474 to 0.768). 
    We can also note that the correlation between the two factors for the 650 individuals (ignor-
ing clustering) is 0.823 (see Table 7.4). Given this preliminary evidence, we can proceed with 
developing our model with the two correlated latent factors as outcomes in our proposed study 
of employees’ work lives. 
   Organizing the Data Set 
 In this type of latent variable multilevel formulation, the  Repeated dialog box in IBM SPSS 
MIXED can be used to deﬁ ne a measurement model at Level 1 that consists of multiple mea-
sures of an outcome  Y nested within individuals, similar to the multiple measurement occasions 
of  Y that are used to deﬁ ne growth trajectories (Leyland, 2004; Raudenbush & Bryk, 2002). 
Closer inspection of the data in   Figure 7.1  suggests there are six survey items per individual and 
that individuals’ identity (ID) and organizational code must be repeated in the data set for each 
individual. Th e grouping variables ( id and  orgcode ) are used to identify the other predictors as 
belonging to a particular level of the data hierarchy. Th e individual responses to the survey items 
comprising the work life responses ( work ) are nested within individual identiﬁ cation numbers, 
and recoded employee IDs ( Rid ) are nested within organizations ( orgcode ). Th e variable  Index1 
is used to identify the items used in deﬁ ning the latent constructs. Similar to our discussion of 
growth models, this vertical format will accommodate individuals with partial data on the items 
comprising the constructs as long as at least one measure is included. 
 After creating the  Index1  variable, we can also use it to deﬁ ne a dummy-coded job assessment 
( assessjob ) variable (with 0  job satisfaction, and 1  job performance). Th is variable is used to 
TABLE 7.3 Factor Matrix
Factor
1
2
W1varied
–0.035
0.768
W2value
–0.003
0.617
W3team
0.241
0.474
P1assess
0.720
0.069
P2progress
0.836
–0.044
P3evstand
0.764
0.018
Extraction method: principal axis 
factoring.
Rotation method: oblimin with Kaiser 
normalization.
TABLE 7.4 Factor Correlation Matrix
Factor
1
2
1
1.000
0.823
2
0.823
1.000
Extraction method: principal axis 
factoring with oblimin rotation.  

Multivariate Multilevel Models  301
diﬀ erentiate the two constructs. We recode  Index1  into  assessjob  by specifying 1–3 on  Index1  as 0 
to deﬁ ne job satisfaction and 4–6 on  Index1  as 1 to deﬁ ne job performance. Other predictors (i.e., 
resources and organizational productivity), which are grand-mean centered, are repeated on each 
of the six lines comprising each student’s data since they will be deﬁ ned at levels above Level 1. 
 Specifying the Model 
 Following Raudenbush and Bryk’s (2002) general notation, a general multilevel, multivariate 
model can be formulated to specify one or more latent constructs. As we have noted previously, 
we use the  Repeated  dialog box to represent variation among the items deﬁ ning the constructs 
within each individual at Level 1. We also note that we must designate individuals as nested 
in organizations ( orgcode  *  Rid ) on the REPEATED command line (if we refer to the syntax 
statements). We again use the recoded individual identities ( Rid   ) to reduce the required time it 
takes to estimate the model. In this case, we use Level 1 to deﬁ ne the measurement part of the 
model—that is, to link the observed items to their underlying constructs. Th e items measuring 
 Y are deﬁ ned as a vector ( y 1 jk  ,  y 2 jk  ,. . .,  y Ijk  ,) for individual  j in school  k measured on item  i and, as 
we noted, are stacked vertically in the data set. Th e general Level l model may then be written as 
 
1
P
ijk
pjk
pijk
ijk
p
Y
a
ijk
	
pjk
pijk
pjk
pijk
pjk


a pijk
a
pjk

 , 
(7.1) 
FIGURE 7.1 Data matrix for latent variable analysis.

302  Multivariate Multilevel Models 
 where  Y ijk  is the observed score on item  i for individual  j in organization  k ,  π pjk  is the latent true 
score for individual  j in organization  k on construct  p , and   ijk  is an error associated with indi-
vidual  jk ’s response to item  i (assumed to be normally distributed with a mean of 0 and a variance 
of    2 ). Th e key to specifying a multivariate analysis in MIXED is to create an indicator variable 
( a pijk  ), which can link the multiple observed items to each construct ( p ). Th e constructs are speci-
ﬁ ed through using a set of dummy variables speciﬁ ed at Level 1, where  a pijk  takes on the value of 
1 if the indicator  i measures construct  p and 0 otherwise for constructs  p  1, . . .,  P . In this case, 
the dummy-coded variable we use to deﬁ ne the constructs is  assessjob . 
 As Equation 7.1 indicates, in order to incorporate the multiple measures in deﬁ ning each 
construct, as well as specifying more than one construct in the model, we must exclude the usual 
intercept term at the lowest level. In general, the function of the Level 1 model for a multivariate 
formulation is to aggregate the separate indicators into one or more constructs. In accomplish-
ing this, we can specify a relatively simpliﬁ ed covariance structure (e.g., scaled identity) or more 
complete covariance structure (diagonal or unstructured) to describe relationships among the six 
items within individuals (Raudenbush & Bryk, 2002). We caution that when deﬁ ning constructs 
in this vertical manner, it is best if the items or subtests are measured on the same scale (e.g., Lik-
ert-type scales or scaled scores) and have similar variances (Hox, 2010). Variables can be rescaled 
as needed prior to the analyses, however, to achieve more similar error variances. Analysts should 
also keep in mind that ordinal data may not meet the assumptions of continuous normal data. 
 Th e Level 2 model describes the distribution of true scores  π p  across individuals within orga-
nizations, including any predictors that are proposed to explain this variation. Th e general model 
can be written as 
 
  π pjk     p  0 k    r pjk  , 
(7.2) 
 where   p  0 k  is the true score mean of construct  p in organization  k , and  r pjk  is the Level 2 random 
coeﬃ  cient for individual  j in organization  k on construct  p . 
 At Level 3, we represent the organizational-level model. Th e intercept model with no predic-
tors would be 
 
  p  0 k     p  00   u pk  0 , 
(7.3) 
 where   p  00 is the Level 3 intercept for construct  p and  u p  0 k  is the Level 3 random eﬀ ect capturing 
variation in organizational means for construct  p . Th e dimensionality of the covariance matrices 
of random eﬀ ects at Levels 2 and 3 depends on the number of random eﬀ ects at each level. We 
note that when predictors are entered into the model at Levels 2 or 3 in multivariate formula-
tions with no intercept at Level 1, they are added as interactions with the variable that is used to 
deﬁ ne the constructs. In this example, the variable is  assessjob . Th is will provide a set of estimates 
for each construct. If we wish to impose equality constraints across the two constructs, we simply 
enter the predictors into the model as ﬁ xed eﬀ ects. Th is latter formulation tests the hypothesis 
that the eﬀ ects of the predictors are the same in explaining variation in each construct in the 
model (see Hox, 2010, for further discussion). 
 Model 1.1: The Null or “No-Predictors” Model 
 For the null model, we can examine the variability in the constructs that exists at each level. Be-
cause there are two constructs within individuals (Level 1), we can simply deﬁ ne the performance 
variable with its six component measures ( i  1, 2, 3, 4, 5, 6), as specifying the dummy-coded 

Multivariate Multilevel Models  303
job assessment variable ( assessjob ). By declaring no intercept at Level 1 (NOINT), we can obtain 
estimates for each construct separately. Following Equation 7.1, the ﬁ rst set of three items com-
prises the job satisfaction construct (which we have coded 0), and the second set of three items 
comprises the evaluation of performance construct (which we have coded 1): 
Y ijk    π pjk assessjob jk     ijk  , 
(7.4) 
 where  assessjob takes on the value of 1 if item  i measures construct  p (in this case, evaluation 
of performance) and 0 when it measures the other construct (job satisfaction);  π pjk  is the latent 
true score for person  j in school  k on construct  p , and   ijk  is an error term assumed to be nor-
mally distributed with a mean of 0 and variance  
2
	
  (see Raudenbush & Bryk, 2002, for further 
discussion). 
 At Level 1, we will ﬁ rst assume a simple covariance structure by specifying an identity co-
variance matrix at Level 1. Th is implies one constant variance for all items comprising the two 
constructs. If this does not appear to be a reasonable assumption, another possibility might be a 
diagonal covariance matrix, which would provide a separate variance for each item. Th e Level 1 
portion of the model, however, is generally not the focus of the analysis. 
 By not specifying an intercept at Level 1 (NOINT) and specifying the  assessjob  dummy-coded 
variable as randomly varying at Level 2, we can obtain separate intercepts for each construct. In 
our example, since we have two latent constructs, the Level 2 model will simply represent the 
grand mean for each construct. We will label the constructs  π 1 jk  (job satisfaction) and  π 2 jk  (evalu-
ation of performance). Th e Level 2 (between individuals) model can then be deﬁ ned as 
 π 1  jk     10 k    r 1  jk  , 
 
  π 2  jk     20 k    r 2  jk, 
 (7.5) 
 where   10 k  and   20 k  are intercepts and  r 1 jk  and  r 2 jk  are person-speciﬁ c, random eﬀ ects. Th e random 
eﬀ ects are assumed to be multivariate normal with means of 0 and contained in a covariance ma-
trix whose dimensions depend on the number of random eﬀ ects speciﬁ ed (Raudenbush & Bryk, 
2002). We will ﬁ rst assume a diagonal covariance at Level 2. 
 Similarly, the intercepts at Level 3 are the grand mean of the items deﬁ ning each construct at 
the organizational level. Between organizations, the model with random intercepts is deﬁ ned as 
 
   10 k     100   u 10 k  , 
 
   20 k     200   u 20 k  .  
(7.6) 
 We will also assume a diagonal matrix of random eﬀ ects at Level 3. Substituting the Level 2 
and Level 3 equations into Equation 7.4, we arrive at the single-equation model, which includes 
the two organizational-level intercepts and the variance components for each level of the model: 
 
  Y ijk     100    200   u 10 k    u 20 k    r 1 jk    r 2 jk     ijk  . 
(7.7) 
 Th is suggests, in its basic format, seven parameters to estimate (i.e., two ﬁ xed Level 3 intercepts, 
four random eﬀ ects, and one residual variance at Level 1). We can conﬁ rm this familiar speci-
ﬁ cation by examining the model dimensions for the null model in   Table 7.5  . Th e ﬁ xed-eﬀ ect 
intercepts are deﬁ ned along with the random eﬀ ects at Level 3 ( u 0 k  ) and Level 2 ( r jk  ), and the 
Level 1 residual (  ijk  ). 

304  Multivariate Multilevel Models 
   Deﬁ ning the Model 1.1 (Null) with IBM SPSS Menu Commands 
 Launch the IBM SPSS pro-
gram application, and select the 
 ch7worklifeorg.sav data ﬁ le. 
  1.  Go to the toolbar and 
select ANALYZE, 
MIXED MODELS, 
LINEAR. 
 Th is command enables access to 
the  Linear Mixed Models: Specify 
Subjects and Repeated dialog box. 
TABLE 7.5 Model Dimensiona
Number of 
Levels
Covariance 
Structure
Number of 
Parameters
Subject 
Variables
Number of 
Subjects
Fixed Effects
assessjob
2
2
Random Effects
assessjob
2
Diagonal
2
orgcode
assessjob
2
Diagonal
2
Rid * orgcode
Repeated Effects
Index1
6
Identity
1
orgcode * Rid
650
Total
12
7
a Dependent variable: work.  

Multivariate Multilevel Models  305
 2.  Th e  Linear Mixed Models: Specify Subjects and 
Repeated screen displays options for deﬁ ning 
variables as subjects, repeated observations, 
and type of covariance structure in a model. 
 
 a.  A subject is an observational unit that may 
be independent of other subjects. For this 
model, we will designate two subject iden-
tiﬁ ers for the model ( Rid and  orgcode ). To 
facilitate reading the output tables, we will 
enter the variables in sequence. Click to 
select  Rid  from the  Variables column, and 
then click the right-arrow button to move 
the variable into the  Subjects box. 
 
 b.  Next, click to select  orgcode from the 
 Variables column, and then click the right-
arrow button to move the variable into the 
 Subjects box. 
 
 c.  Th e  Repeated box allows specifying vari-
ables that identify repeated observations. 
For this model,  Index1 identiﬁ es the six 
items that measure the constructs. Click 
to select  Index1 , and then click the right-
arrow button to move the variable into the 
 Repeated box. 
 
   Th e combination of values for  Rid ,  orgcode , and  Index1 deﬁ nes a particular employee from a 
particular organization with data from one to six items (i.e., individuals with partial data will be 
included in the analysis). 
 
 d.  Th e  Repeated Covariance Type speciﬁ es a model’s covariance structure. For this model, at Level 
1 we will use scaled identity. Click the pull-down menu to select the autoregressive covariance 
matrix,  Scaled Identity , as the  Repeated Covariance Type. 
 Th e  Scaled Identity  covariance structure has constant variance and assumes that no covariance 
exists between any elements (IBM Corporation, 2012). 
 Click the CONTINUE button to display the  Linear Mixed Models dialog box. 

306  Multivariate Multilevel Models 
 
 4a.  Within the  Linear 
Mixed Models: 
Fixed Eﬀ ects dialog 
box, we will retain 
the default  Facto-
rial setting, which 
creates all possible 
interactions and 
main eﬀ ects of the 
speciﬁ ed variable 
(IBM Corporation, 
2012). 
 
 b.  Now click to select 
 assessjob from the 
 Factors and Covari-
ates box. Th en click 
the ADD button to 
move the variable 
into the  Model box. 
 
 c.  To create the no-intercept model, uncheck the  Include intercept option. 
 Click the CONTINUE button to return to the  Linear Mixed Models dialog box. 
 We will now add random eﬀ ects to this model. 
 Click the RANDOM button to access the  Linear Mixed Models: Random Eﬀ ects dialog box. 
  3.  Th e  Linear Mixed Models main 
screen enables specifying the depen-
dent variable, factors, and covariates, 
as well as access to dialog boxes for 
deﬁ ning  Fixed and  Random eﬀ ects, 
and options for  Estimation ,  Statistics , 
 EM Means , and  Save. 
 
 a.  For this model, we will use  work 
as the dependent variable. Click 
to select the  work variable from 
the left column listing. Th en click 
the right-arrow button to transfer 
 work into the  Dependent Variable 
box. 
 
 b.  We will create a no-intercept null model that deﬁ nes the observed measures of  assessjob ( assess-
job0 and  assessjob1 ). Click to select the  assessjob  variable from the left column listing. Th en click 
the right-arrow button to transfer  assessjob into the  Factor(s) box. 
 Click the FIXED button to access the  Linear Mixed Models: Fixed Eﬀ ects dialog box. 

Multivariate Multilevel Models  307
 5.  Th e  Linear Mixed 
Models: Random Eﬀ ects 
displays the  Random Ef-
fect 1 of 1 screen, which 
is the default when 
creating a model for the 
ﬁ rst time. Th e random-
eﬀ ects screen allows 
specifying random ef-
fects, interactions, inter-
cept terms, and subject 
groupings. 
 
 a.  Begin by specifying 
the covariance struc-
ture from the default 
variance components 
(VC) to diagonal. 
To do so, click the 
pull-down menu 
and select  Diagonal 
(DIAG). 
 Th e  Diagonal  covariance type has heterogeneous variances and zero correlation between the elements 
(IBM Corporation, 2012). 
 
 b.  We want the intercept to be excluded from the model, so the model will deﬁ ne the measures of 
 assessjob . Th erefore, we will retain the current default setting. 
 
 c.  We will retain the default  Factorial setting as this will be a null model (no-predictor, no-intercept), 
so the setting will have no eﬀ ect. 
 
 d.  Click to select  assessjob , and then click the ADD button to move the variable into the  Model 
box. 
 
 e.  Th e  Subject Groupings box displays the  orgcode and  Rid variables that were speciﬁ ed as subject 
variables in the  Specify Subjects and Repeated dialog box show in step 2a. We will specify  orgcode 
as the subject for the random-eﬀ ects Level 1 part of this model. Click to select  orgcode , and 
then click the right-arrow button to move the variable into the  Combinations box. 
 
 f.  At the top-right section of the window, click the NEXT button to access the  Random Eﬀ ect 2 
of 2 screen. 

308  Multivariate Multilevel Models 
 6.  Click the ESTIMATION button to 
access the  Linear Mixed Models: Esti-
mation dialog box, which displays two 
estimation method choices: maximum 
likelihood (ML) or restricted maximum 
likelihood (REML). 
 In this chapter, we will primarily use the de-
fault setting of REML to estimate the models. 
Where nested models are compared in terms 
of both variance components and regression 
components, however, ML estimation should 
be used (Hox, 2010). 
 Click the CONTINUE button to return to 
the  Linear Mixed Models dialog box. 
 Th e  Random Eﬀ ect 2 of 2  screen 
display is similar to the ﬁ rst 
screen and requires the following 
changes. 
 
 g.  Change the covariance 
type by clicking on the 
pull-down menu and 
selecting  Diagonal. 
 
 h.  We want the intercept 
to be excluded from the 
model so that separate 
constructs comprising 
 assessjob will be speci-
ﬁ ed. Th erefore, we will 
retain the current default 
setting. 
 
 i.  Retain the default  Facto-
rial setting. 
 
 j.  Click to select  assessjob , 
and then click the ADD 
button to move the variable into the  Model box. 
 
 k.  We will specify  orgcode and  Rid  as the subjects for the random-eﬀ ects Level 2 part of this 
model. Click to select  orgcode and  Rid , and then click the right-arrow button to move the vari-
ables into the  Combinations box. 
 Click the CONTINUE button to return to the  Linear Mixed Models dialog box. 

Multivariate Multilevel Models  309
  8.  Finally, in the  Linear Mixed Models 
dialog box, click the OK button to 
run the model. 
  7.  In the  Linear Mixed Models dialog 
box, click the STATISTICS but-
ton to access the  Linear Mixed 
Models: Statistics dialog box. 
 Click and select the following three 
statistics to be included in the output: 
 Parameter estimates ,  Tests for covariance 
parameters , and  Covariances of random 
eﬀ ects . 
 Click the CONTINUE button to re-
turn to the  Linear Mixed Models dialog 
box. 
 Interpreting the Output From Model 1.1 (Null) 
 In this case, we ﬁ rst used a scaled identity (ID) covariance matrix at Level 1 and a diagonal cova-
riance matrix at Levels 2 and 3 since there were two random eﬀ ects at those levels (i.e., the work 
life intercept and the evaluation of performance intercept).   Table 7.6  suggests that the grand 
mean for work life was 3.926 (i.e., the mean of the ﬁ rst set of items across the organizations) and 
3.845, which represents the grand mean of the second set of items across organizations. 

310  Multivariate Multilevel Models 
 Th e variance components associated with each level are summarized in   Table 7.7  . Th e table sug-
gests a single variance at Level 1 (0.544), separate intercept variances for the job satisfaction and 
evaluation of performance constructs at Level 3 (0.123 and 0.192, respectively), and separate 
variances for the same two constructs at Level 2 (0.336 and 0.413, respectively). 
 We might next examine the correlation between each construct at the individual employee 
level (Level 2) and at the organizational level (Level 3). We can specify the relevant covariance 
matrices of random eﬀ ects at each level as unstructured (UN) and designate (R) to obtain a 
correlation (UNR). When we do this, we will now have nine parameters to estimate since we 
are adding a correlation each at Level 2 and Level 3. In   Table 7.8  , we provide the relevant cor-
relations (model syntax is provided in Appendix A). Th e table suggests that the items are more 
strongly correlated at the individual level ( r  0.953) than at the organizational level ( r  0.773). 
TABLE 7.6 Estimates of Fixed Effectsa
Parameter
Estimate
Std. Error
df
t
Sig.
95% Conﬁ dence Interval
Lower Bound
Upper Bound
[assessjob = 0]
3.926
0.045
105.724
87.347
.000
3.837
4.015
[assessjob = 1]
3.845
0.053
104.133
72.509
.000
3.739
3.950
a Dependent variable: work.  
TABLE 7.7 Estimates of Covariance Parametersa
Paramenter
Estimate
Std. Error
Wald Z
Sig.
95% Conﬁ dence Interval
Lower Bound
Upper Bound
Repeated Measures
Variance
0.544
0.015
36.056
.000
0.515
0.574
assessjob [subject = 
orgcode]
Var: [accessjob = 0]
0.123
0.029
4.238
.000
0.077
0.195
Var: [accessjob = 1]
0.192
0.041
4.707
.000
0.127
0.291
assessjob [subject = 
Rid * orgcode]
Var: [accessjob = 0]
0.336
0.032
10.635
.000
0.279
0.404
Var: [accessjob = 1]
0.413
0.036
11.385
.000
0.347
0.490
a Dependent variable: work.
TABLE 7.8 Estimates of Covariance Parametersa
Parameter
Estimate
Std. Error
Wald Z
Sig.
95% Conﬁ dence Interval
Lower Bound
Upper Bound
Repeated Measures
Variance
0.544
0.015
36.056
.000
0.515
0.574
assessjob [subject = 
orgcode]
Var(1)
0.124
0.029
4.249
.000
0.078
0.196
Var(2)
0.192
0.041
4.707
.000
0.127
0.291
Corr(2, 1)
0.773
0.070
10.995
.000
0.595
0.879
assessjob [subject = 
Rid * orgcode]
Var(1)
0.335
0.032
10.637
.000
0.279
0.403
Var(2)
0.413
0.036
11.385
.000
0.347
0.490
Corr(2, 1)
0.953
0.034
27.766
.000
0.812
0.989
a Dependent variable: work.  

Multivariate Multilevel Models  311
 Conducting a Likelihood Ratio Test 
 We can formulate at likelihood ratio test to evaluate the two added correlation parameters. Any 
model where one or more parameters are ﬁ xed to zero can be referred to as a  restricted model  ( L 0 ), 
which can then be compared to an alternative model ( L 1 ) where the parameter or parameters are 
estimated. Th e change in model likelihoods can then be compared as long as the restricted model 
is nested in the alternative model (i.e., can be obtained from the unrestricted model by setting 
parameters to zero). Th e second (alternative) model with more parameters estimated will always 
ﬁ t at least as well (have a greater log likelihood) as the ﬁ rst model with restricted parameters. 
Th e ratio of the two likelihoods ( L 0 /L 1 ) is referred to as the likelihood ratio. Where there is no 
diﬀ erence between models (i.e., the log likelihoods are the same), the likelihood ratio will be 1.0, 
and the test statistic will be 0. A larger, more positive test result provides evidence against the null 
hypothesis that there is no diﬀ erence between models. Th e likelihood ratio statistic (referred to 
as  LR ,  G 2 , or  	 ) can then be formulated as follows: 
2
0
1
0
1
2log
2[log(
)
log(
)]
[ 2log(
)]
[ 2log(
)]
0
1
0
1
1
0
2[log(
)
log(
)]
[ 2log(
)]
[ 2log(
)
log(
)]
[ 2log(
)]
[ 2log(
0
1
0
1
0
1
0
G 2
2log#
$
0
L
2[log(
)
log(
)]
[ 2log(
)]
[
)
log(
)]
[ 2log(
2[log(
)
log(
)]
[ 2log(
)]
[
2log
0
#
$
#
$
0
L0
%
&
1
L
 
(7.8) 
 Th e diﬀ erence between two models has a chi-square distribution with degrees of freedom ( df  ) 
of the test equal to the diﬀ erence in the number of parameters being tested. 
 We summarize the tests for these two models in   Table 7.9  . We estimated both models using 
REML estimation since we were only examining diﬀ erences between variance components. If re-
gression parameters are also included, we remind readers that ML should be used to conduct the 
likelihood ratio test between the two competing models (Hox, 2010). Th e original ‒2LL (–2*log 
likelihood) for 7 estimated parameters was 10,358.406. Th e ‒2LL with 9 estimated parameters 
was 9,995.447. Th e relevant degrees of freedom, then, is 2 for this test (i.e., from 7 to 9 param-
eters estimated). Th e required chi-square coeﬃ  cient for 2 degrees of freedom at  p  .05 is 5.99. 
In this case, the likelihood ratio test easily exceeded 5.99. Th is suggests that the alternative model 
with 9 parameters ﬁ t the data better than the restricted model with only 7 parameters estimated. 
 We can also test the assumption that there is a single variance at Level 1 to describe the items 
comprising the latent constructs. We might also examine whether a diagonal covariance matrix 
ﬁ ts better at Level 1. In changing from a scaled identity covariance matrix to a diagonal covari-
ance matrix, we will add 5 estimated parameters (i.e., resulting in 14 parameters to estimate). To 
conduct a likelihood ratio test, we can use Model 2 as our nested model (–2LL  9,995.447, for 
9 estimated parameters). Th e new model (Model 3) has 14 estimated parameters and a ‒2LL of 
9,871.989. Th e relevant degrees of freedom is 5 (which at  p  .05 requires a coeﬃ  cient of at least 
11.07). We can see the resulting likelihood ratio coeﬃ  cient describing the diﬀ erence in deviance 
between Model 2 and Model 3 easily exceeds the required coeﬃ  cient. We can therefore accept 
that a diagonal covariance structure at Level 1 ﬁ ts the data better than a single variance estimate. 
TABLE 7.9 Likelihood Ratio Tests (REML Estimation)
Variables
–2LL
Parameters
G2
df
p
Models
Model 1 (No Correlations)
10,358.406
7
NA
NA
NA
Model 2 (Correlations)
 9,995.447
9
362.959
2
< .001
Model 3 (Diagonal Covariance 
Matrix)
 9,871.989
14
123.458
5
< .001

312  Multivariate Multilevel Models 
 We provide the covariance parameter estimates for this ﬁ nal null model (Model 1.2) in 
 Table 7.10  . As noted in   Table 7.10  , this current model now has 14 estimated parameters. Th ese 
include the two ﬁ xed-eﬀ ect intercepts and the 12 variance components summarized in the table. 
We can see, for example, that there is some inconsistency in the items measuring the constructs 
at Level 1. 
TABLE 7.10 Estimates of Covariance Parametersa
Parameter
Estimate
Std. Error
Wald Z
Sig.
95% Conﬁ dence Interval
Lower Bound
Upper Bound
Repeated Measures
Var: [Index1 = 1]
0.587
0.041
14.383
.000
0.512
0.672
Var: [Index1 = 2]
0.534
0.039
13.829
.000
0.464
0.616
Var: [Index1 = 3]
0.863
0.056
15.409
.000
0.760
0.980
Var: [Index1 = 4]
0.420
0.030
13.892
.000
0.365
0.484
Var: [Index1 = 5]
0.298
0.024
12.243
.000
0.254
0.350
Var: [Index1 = 6]
0.565
0.037
15.067
.000
0.496
0.643
assessjob [subject = 
orgcode]
Var(1)
0.123
0.029
4.288
.000
0.078
0.194
Var(2)
0.181
0.039
4.653
.000
0.119
0.276
Corr(2, 1)
0.758
0.074
10.249
.000
0.572
0.869
assessjob [subject = 
Rid * orgcode]
Var(1)
0.285
0.031
9.118
.000
0.230
0.354
Var(2)
0.442
0.035
12.575
.000
0.379
0.517
Corr(2, 1)
0.943
0.038
24.989
.000
0.799
0.985
a Dependent variable: work.  
 Deﬁ ning Model 1.2 (Final Null Model) with IBM SPSS Menu Commands 
 Settings will default to those used in 
Model 1.1. 
  1.  Go to the toolbar and select 
ANALYZE, MIXED MOD-
ELS, LINEAR. 
 Th is command enables access to the 
 Linear Mixed Models: Specify Subjects 
and Repeated dialog box. 

Multivariate Multilevel Models  313
  3.  We will change the random-eﬀ ects 
covariance type, so from the  Linear 
Mixed Models main screen, click the 
RANDOM button to access the 
 Linear Mixed Models: Random Eﬀ ects 
dialog box. 
 2.  Th e  Linear Mixed Models: Specify Subjects 
and Repeated  screen displays the default 
settings from the prior model. 
 We will change the Level 1 covariance type 
by clicking the pull-down menu and selecting 
 Diagonal. 
 Th e  Diagonal covariance type has heteroge-
neous variances and zero correlation between 
the elements (IBM Corporation, 2012). 
 Click the CONTINUE button to display the 
 Linear Mixed Models dialog box. 

314  Multivariate Multilevel Models 
  4.  Th e  Random Eﬀ ect 2 of 2 
screen is displayed ﬁ rst as 
it was the last dialog box 
used in the prior model. 
 
 a.  Change the covariance 
type by clicking the 
pull-down menu and 
selecting  Unstructured: 
Correlation Metric. 
 The  Unstructured: 
Correlation Metric  co-
variance structure has 
both heterogeneous 
variances and correla-
tions (IBM Corpora-
tion, 2012). 
 
 b.  Click the PREVIOUS 
button to access the 
 Random Eﬀ ect 1 of 2 
screen. 
 
 c.  From the  Random 
Eﬀ ect 1 of 2 screen, 
change the covariance 
type by clicking the 
pull-down menu and 
selecting  Unstructured: 
Correlation Metric. 
 Click the CONTINUE but-
ton to return to the  Linear 
Mixed Models dialog box. 

Multivariate Multilevel Models  315
  5.  Finally, in the  Linear Mixed Models 
dialog box, click the OK button to 
run the model (Table 7.10). 
 Model 1.3: Adding Level 2 Predictors 
 For the next model, we will add the individual background variables. At Level 2, we propose 
that employee gender ( female ) may result in diﬀ erent perceptions about work life and evaluation 
of performance. We will also propose that employees who have been in the organization longer 
( stability ) will have more favorable perceptions about work life issues and performance evalua-
tion. We can deﬁ ne the model to estimate perceptions for individual  j in organization  k on the 
two constructs as follows: 
 
 π 1 jk     10 k     11 k   female jk     12 k   stability jk    r 1 jk  , 
 
  π 2 jk     20 k     21 k   female jk     22 k   stability jk    r 2 jk  . 
(7.9) 
 Equation 7.9 indicates that individuals’ perceptions vary across individuals. Th e model remains 
the same at the organizational level (Level 3) as in Equation 7.6, with the intercepts varying at 
that level also. We will assume the slopes for female and stability are ﬁ xed at Level 3. 
 For the single-equation (or combined) model, when we add the predictors to the model we 
multiply them by the dummy indicators: 
 Y ijk     100    200    110 assessjob jk   *    female jk     210 assessjob jk   *    female jk   
  120 assessjob jk   *   stability jk     220 assessjob jk   *   stability jk    u 10 k    u 20 k    r 1 jk    r 2 jk     ijk  .  
(7.10) 
 Th is makes a total of 18 parameters to estimate. Th ese include six ﬁ xed eﬀ ects, six random eﬀ ects 
combined at Levels 2 and 3 (including covariances), and six Level 1 residual variances. Th is can 
be conﬁ rmed in   Table 7.11 . 
 As we noted previously, multiplying the set of dummy outcome variables ( assessjob ) by each 
Level 2 (or Level 3) predictor results in a separate regression coeﬃ  cient for each response vari-
able. If we wish to impose an equality constraint across the response variables (i.e., assume the 
eﬀ ect of the predictor is the same on each), we would add the predictor directly to the model 
instead of multiplying it by the dummy indicators. In our speciﬁ c case, this would amount to one 
parameter describing the eﬀ ect of  gender and one for the eﬀ ect of  stability . One can then test the 
ﬁ t of this “nested” model speciﬁ cation against the model as speciﬁ ed in Equation 7.10. 

316  Multivariate Multilevel Models 
 Deﬁ ning Model 1.3 with IBM SPSS Menu Commands 
 Settings will default to those used 
in Model 1.2. 
 1.  Go to the toolbar and select 
ANALYZE, MIXED 
MODELS, LINEAR. 
 Th is command enables access to 
the  Linear Mixed Models: Specify 
Subjects and Repeated dialog box. 
TABLE 7.11 Model Dimensiona
Number 
of Levels
Covariance 
Structure
Number of 
Parameters
Subject 
Variables
Number 
of Subjects
Fixed Effects
assessjob
2
2
assessjob * stability
2
2
assessjob * female
2
2
Random Effects
assessjob
2
Unstructured 
Correlations
3
orgcode
assessjob
2
Unstructured 
Correlations
3
Rid * orgcode
Repeated Effects
Index1
6
Diagonal
6
orgcode * Rid
650
Total
16
18
a Dependent variable: work.  

Multivariate Multilevel Models  317
 2.  Th e  Linear Mixed Models: Specify Subjects and 
Repeated screen displays the default settings 
from the prior model. 
 Click the CONTINUE button to display the  Lin-
ear Mixed Models dialog box. 
 3.  We will designate two variables to 
be used in the model. Locate and 
click  female and  stability  from the 
left column listing, and then click 
the right-arrow button to move the 
variable into the  Covariate(s) box. 
 We may now proceed to deﬁ ne ﬁ xed ef-
fects for the variable. 
 Click the FIXED button to access the 
 Linear Mixed Models: Fixed Eﬀ ects dialog 
box. 
 Two cross-level interactions (or nested terms) will be created and added to the model:  stability*assessjob 
and  female*assessjob . Th ese interactions will tell us if (a) employees who have been with the organization 
longer ( stability ) have more favorable perceptions about work life issues ( assessjob ) and (b) employee 
gender ( female ) may result in diﬀ erent perceptions about work life ( assessjob ). 

318  Multivariate Multilevel Models 
 Add First Interaction to Model 1.3:  stability*assessjob 
 
 4a.  Click to select  Build 
nested terms . 
 
 b.  Now click to select the 
variable  stability  from 
the  Factors and Covari-
ates box. 
 
 c.  Click the arrow but-
ton below the  Factors 
and Covariates box. Th is 
moves  stability into the 
 Build Term box to create 
a cross-level interaction 
by linking variables and 
terms. 
 
 d.  Next, click the BY* but-
ton, which will insert the 
computation command 
symbol:  stability* . 
 
 e.  Click to select  assessjob from the  Factors and Covariates box. 
 
 f.  Click the arrow button below the  Factors and Covariates box to move  assessjob into the  Build 
Term box and complete the interaction term:  stability*assessjob . 
 
 g.  Click the ADD button to transfer the interaction into the  Model box. 
 Add Second Interaction to Model 1.3:  female*assessjob 
 Repeat steps 4a to 4g using  female and  assessjob  to create the interaction. 
 Click the CONTINUE button to return to the  Linear Mixed Models dialog box. 
 5.  Finally, in the  Linear Mixed Models 
dialog box, click the OK button to 
run the model. 

Multivariate Multilevel Models  319
 Interpreting the Output From Model 1.3 
 Th e ﬁ xed-eﬀ ect estimates for Model 1.3 are summarized in   Table 7.12  . After adjusting for the 
within-organization background controls, the intercepts of the two constructs are 3.939 for job 
satisfaction ( assessjob  0) and 3.762 for evaluation of performance ( assessjob  1). Th e table in-
dicates that gender does not signiﬁ cantly aﬀ ect either job satisfaction (   ‒0.031,  p  .05) or 
performance (   0.005,  p  .05) perceptions. Employee stability is positively related to job satis-
faction perceptions (   0.125,  p  .05) and perceptions about the assessment of their performance 
(   0.171,  p  .05). 
 Th e variance component output (  Table 7.13  ) suggests that after addition of the set of indi-
vidual predictors, there is still variance in the constructs to be explained at both the individual 
and organizational levels. 
TABLE 7.12 Estimates of Fixed Effectsa
Parameter
Estimate
Std. Error
df
t
Sig.
95% Conﬁ dence Interval
Lower Bound
Upper Bound
[assessjob = 0]
3.939
0.059
253.776
66.480
.000
3.822
4.055
[assessjob = 1]
3.762
0.067
243.767
56.240
.000
3.631
3.894
[assessjob = 0] * stability
0.125
0.063
609.739
1.968
.050
0.000
0.249
[assessjob = 1] * stability
0.171
0.069
640.637
2.474
.014
0.035
0.307
[assessjob = 0] * female
–0.031
0.058
595.213
–0.532
.595
–0.144
0.083
[assessjob = 1] * female
0.005
0.063
601.425
0.079
.937
–0.118
0.128
a Dependent variable: work.  
TABLE 7.13 Estimates of Covariance Parametersa
Parameter
Estimate
Std. Error
Wald Z
Sig.
95% Conﬁ dence Interval
Lower Bound
Upper Bound
Repeated Measures
Var: [Index1 = 1]
0.588
0.041
14.340
.000
0.513
0.674
Var: [Index1 = 2]
0.533
0.039
13.782
.000
0.462
0.614
Var: [Index1 = 3]
0.864
0.056
15.399
.000
0.761
0.981
Var: [Index1 = 4]
0.418
0.030
13.872
.000
0.363
0.482
Var: [Index1 = 5]
0.300
0.024
12.260
.000
0.255
0.352
Var: [Index1 = 6]
0.564
0.037
15.065
.000
0.496
0.643
assessjob [subject = 
orgcode]
Var(1)
0.114
0.028
4.103
.000
0.071
0.183
Var(2)
0.170
0.038
4.525
.000
0.110
0.262
Corr(2, 1)
0.738
0.080
9.185
.000
0.537
0.859
assessjob [subject = 
Rid * orgcode]
Var(1)
0.287
0.031
9.126
.000
0.232
0.356
Var(2)
0.442
0.035
12.543
.000
0.378
0.517
Corr(2, 1)
0.943
0.038
25.038
.000
0.800
0.984
a Dependent variable: work.  

320  Multivariate Multilevel Models 
 Model 1.4: Adding the Organizational Predictors 
 Model 1.4 adds two organizational predictors at Level 3. Th ese include a measure describing the 
level of each organization’s productivity and a measure of its resources allocated to support em-
ployees. Both were grand-mean centered. Th ey are each proposed to aﬀ ect work life perceptions 
of job satisfaction and evaluation of performance: 
 
   10 k     100    101 gmorgprod k     102 gmresource k    u 10 k  , 
 
   20 k     200    201 gmorgprod k     202 gmresource k    u 20 k  . 
(7.11) 
 Th is combined model will add 4 more parameters to estimate (i.e., from 18 parameters in the 
last model to 22 parameters), since we are specifying a separate predictor for each outcome vari-
able at Level 3: 
 Y ijk     100    200    101 assessjob jk  * gmorgprod k     201 assessjob jk  * gmorgprod k  
   102 assessjob jk  * gmresources k     202 assessjob jk  * gmresources k     110 assessjob jk  * female jk  
   210 assessjob jk  * female jk     120 assessjob jk  * stability jk     220 assessjob jk  * stability jk  
  u 10 k    u 20 k    r 1 jk    r 2 jk     ijk  . 
(7.12) 
 Th is can be conﬁ rmed in the model dimension table (  Table 7.14  ). We note that we also had 
to change from an unstructured correlation covariance matrix (UNR) to an unstructured covari-
ance matrix (UN) in order for the model to converge. We estimated this model and the following 
model with equality constraints with ML estimation (instead of REML) since we are subse-
quently going to compare the ﬁ t of the model in Equation 7.12 against a model with equality 
constraints added for the ﬁ xed-eﬀ ect regression slopes. 
TABLE 7.14 Model Dimensiona
Number 
of Levels
Covariance 
Structure
Number of 
Parameters
Subject 
Variables
Number of 
Subjects
Fixed Effects
assessjob
2
2
assessjob * gmorgprod
2
2
assessjob * gmresources
2
2
assessjob * stability
2
2
assessjob * female
2
2
Random Effects
assessjob
2
Unstructured
3
Orgcode
assessjob
2
Unstructured
3
orgcode * Rid
Repeated Effects
Index1
6
Diagonal
6
orgcode * Rid
650
Total
20
22
a Dependent variable: work.  

Multivariate Multilevel Models  321
   Deﬁ ning Model 1.4 with IBM SPSS Menu Commands 
 Settings will default to those used 
in Model 1.3. 
  1.  Go to the toolbar and select 
ANALYZE, MIXED 
MODELS, LINEAR. 
 Th is command enables access to 
the  Linear Mixed Models: Specify 
Subjects and Repeated dialog box. 
  2.  Th e  Linear Mixed Models: Specify Subjects and 
Repeated screen displays the default settings 
from the prior model. 
 Click the CONTINUE button to display the 
 Linear Mixed Models dialog box. 

322  Multivariate Multilevel Models 
  3.  Th e  Linear Mixed Models dialog box 
settings default to those used in the 
prior model. 
 We will introduce two new variables to 
be used in the model ( gmorgprod and  gm-
resources ). First, click to select  gmorgprod 
and  gmresources , and second, “drag” the 
variables to the  Covariate(s) box below 
 stability . 
 Th e sequence of the variables is as fol-
lows:  female ,  stability ,  gmorgprod , and 
 gmresources . 
 Click the FIXED button to access the 
 Linear Mixed Models: Fixed Eﬀ ects dialog 
box. 
 Two new cross-level interactions (or nested terms) will be created and added to the model: 
 gmordprod*assessjob and  gmresources*assessjob . Th ese interactions will tell us if (a) each organization’s pro-
ductivity ( gmorgprod ) supports employees’ perceptions of job satisfaction and performance evaluation 
( assessjob ) and (b) each organization’s resource allocation ( gmresources ) supports employees’ job satisfac-
tion and performance evaluation ( assessjob ). 
 
 4a.  Th e  Linear Mixed 
Models: Fixed Eﬀ ects 
dialog box displays 
the default set-
ting from the prior 
model. To facili-
tate reading of the 
output tables, we 
will ﬁ rst remove the 
two interactions to 
clear the model and 
then later add them 
back into the model. 
First, click to select 
 stability*assessjob and 
 female*assessjob , and 
second, click the 
REMOVE button. 

Multivariate Multilevel Models  323
 Add First Interaction to Model 1.4:  gmorgprod*assessjob 
 Note:  Build nested terms is the default setting from the prior model. 
 
 b.  Click to select the variable  gmorgprod  from the  Factors and Covariates box. 
 
 c. Th en click the arrow button below the  Factors and Covariates box. Th is moves  gmorgprod into 
the  Build Term box to create a cross-level interaction by linking variables and terms. 
 
 d. Next, click the BY* button, which will insert the computation command symbol:  gmorgprod* . 
 
 e. Click to select  assessjob from the  Factors and Covariates box. 
 
 f. Click the arrow button below the  Factors and Covariates box to move  assessjob into the  Build 
Term box and complete the interaction term:  gmorgprod*assessjob . 
 
 g. Click the ADD button to transfer the interaction into the  Model box. 
 Add Second Interaction to Model 1.4:  gmresources*assessjob 
 Repeat steps 4b to 4g using  gmresources and  assessjob  to create the interaction. 
 Add Third Interaction to Model 1.4:  stability*assessjob 
 Repeat steps 4b to 4g using  stability and  assessjob  to create the interaction. 
 Add Fourth Interaction to Model 1.4:  female*assessjob 
 Repeat steps 4b to 4g using  female and  assessjob  to create the interaction. 
 Th e completed model is shown in the insert. Click the CONTINUE button to return to the 
 Linear Mixed Models dialog box. 
 Click the RANDOM button to access the  Linear Mixed Models: Random Eﬀ ects dialog box. 
  5.  Th e  Random Eﬀ ect 1 of 2 
screen is displayed ﬁ rst, 
as it was the last dialog 
box used in the prior 
model. 
 
 a.  Change the covari-
ance type by click-
ing the pull-down 
menu and selecting 
 Unstructured. 
 Th e  Unstructured covariance 
structure has a completely 
general covariance matrix 
(IBM Corporation, 2012). 
 
 b.  Click the NEXT 
button to access the 
 Random Eﬀ ect 2 of 2 
screen. 

324  Multivariate Multilevel Models 
 
 c.  From the  Random 
Eﬀ ect 2 of 2 screen, 
change the covari-
ance type by click-
ing the pull-down 
menu and selecting 
 Unstructured. 
 Click the CONTINUE but-
ton to return to the  Linear 
Mixed Models dialog box. 
  6.  Click the ESTIMATION button 
to access the  Linear Mixed Mod-
els: Estimation  dialog box. We will 
change the estimation method by 
clicking to select ML. 
 Click the CONTINUE button to return 
to the  Linear Mixed Models dialog box. 

Multivariate Multilevel Models  325
  7.  Finally, in the  Linear Mixed Models 
dialog box, click the OK button to 
run the model. 
 Interpreting the Output from Model 1.4 
 Th e ﬁ xed-eﬀ ect results are presented in   Table 7.15  . Th e table suggests that between individuals 
(Level 2), gender once again does not aﬀ ect individual perceptions, but employee stability does. 
Between organizations (Level 3), resource adequacy aﬀ ects perceptions of job satisfaction ( as-
sessjob  0) but not perceptions about the assessment of individuals’ performance ( assessjob  1). 
Finally, organizational performance positively aﬀ ects both organizational job satisfaction ( assess-
job  0) and organizational evaluation of employee performance ( assessjob  1). 
 Because the covariance parameters are very similar to the previous model, we do not reproduce 
them here. 
TABLE 7.15 Estimates of Fixed Effectsa
Parameter
Estimate
Std. Error
df
t
Sig.
95% Conﬁ dence Interval
Lower Bound
Upper Bound
[assessjob = 0]
3.909
0.056
266.183
69.537
.000
3.798
4.019
[assessjob = 1]
3.738
0.065
250.718
57.681
.000
3.610
3.865
[assessjob = 0] * gmorgprod
0.344
0.119
106.311
2.878
.005
0.107
0.581
[assessjob = 1] * gmorgprod
0.383
0.144
106.371
2.666
.009
0.098
0.668
[assessjob = 0] * gmresources
0.101
0.044
108.941
2.273
.025
0.013
0.188
[assessjob = 1] * gmresources
0.060
0.053
108.492
1.124
.263
–0.046
0.165
[assessjob = 0] * stability
0.129
0.062
599.753
2.071
.039
0.007
0.251
[assessjob = 1] * stability
0.171
0.069
639.944
2.493
.013
0.036
0.306
[assessjob = 0] * female
–0.038
0.057
604.741
–0.666
.506
–0.151
0.075
[assessjob = 1] * female
–0.001
0.062
608.417
–0.016
.988
–0.123
0.121
a Dependent variable: work.  

326  Multivariate Multilevel Models 
 Examining Equality Constraints 
 We can compare the model in Table 7.15 (which has a separate estimate for each predictor on 
each construct) against a model with equality constraints on the predictors (Hox, 2010). Th is 
type of model makes the assumption that the eﬀ ects of predictors are the same on the constructs. 
Th is proposed model has only 18 parameters instead of 22 since 1 parameter is removed for 
each of the four predictors in the model. We estimated both models with ML to facilitate the 
comparison of models with diﬀ erent numbers of regression slope coeﬃ  cients. Th e model with 
equality constraints added has a deviance (–2LL) of 9,837.799 and Akaike’s information crite-
rion (AIC) of 9,873.799. Th e model with 22 parameters in Table 7.15 has a deviance 9,835.713. 
We can estimate the likelihood ratio test coeﬃ  cient as 2.086 (which is not signiﬁ cant for 4  df ). 
Since the reduced model does not worsen the ﬁ t, however, it could be accepted on the grounds 
that it is more parsimonious (i.e., having only 18 vs. 22 parameters). It also has a smaller AIC. 
 We present the ﬁ xed eﬀ ects for this model in   Table 7.16  (instructions for Model 1.5 shown 
after the table). Similar to the previous model, it suggests that resources and productivity aﬀ ect 
perceptions at the organizational level and stability aﬀ ects perceptions at the individual level. 
TABLE 7.16 Estimates of Fixed Effectsa
Parameter
Estimate
Std. Error
df
t
Sig.
95% Conﬁ dence Interval
Lower Bound
Upper Bound
[assessjob = 0]
3.896
0.055
247.746
70.822
.000
3.788
4.005
[assessjob = 1]
3.758
0.061
216.609
61.204
.000
3.637
3.879
female
–0.024
0.054
602.279
–0.437
.662
–0.129
0.082
stability
0.143
0.059
614.094
2.426
.016
0.027
0.258
gmorgprod
0.352
0.118
103.555
2.984
.004
0.118
0.586
gmresources
0.091
0.044
105.907
2.077
.040
0.004
0.177
a Dependent variable: work.  
   Deﬁ ning Model 1.5 with IBM SPSS Menu Commands 
 Note: Settings will default to those used in 
Model 1.4. 
  1.  Go to the toolbar and select ANA-
LYZE, MIXED MODELS, LINEAR. 
 Th is command enables access to the  Linear 
Mixed Models: Specify Subjects and Repeated 
dialog box. 

Multivariate Multilevel Models  327
  2.  Th e  Linear Mixed Models: Specify Subjects and Re-
peated screen displays the default settings from the 
prior model. We will retain the default settings. 
 Click the CONTINUE button to display the  Linear 
Mixed Models dialog box. 
  3.  Th e  Linear Mixed Models dialog box settings 
default to those used in the prior model. 
 We will modify the ﬁ xed eﬀ ects so click the 
FIXED button to access the  Linear Mixed Models: 
Fixed Eﬀ ects dialog box. 
 
 4a.  Th e  Linear Mixed 
Models: Fixed Eﬀ ects 
dialog box displays 
the default setting 
from the prior model. 
We will ﬁ rst remove 
the four cross-level 
interactions from the 
model by clicking to 
select them and then 
clicking the RE-
MOVE button. 
 
 b.  Click to select the 
 Build terms option, 
which enables adding 
nonnested terms to 
the model. 
 
 c.  Change the factorial setting by clicking the pull-down menu and selecting  Main Eﬀ ects. 
 
 d.  Now click to select four variables ( female ,  stability ,  gmorgprod , and  gmresources ) from the  Factors 
and Covariates box, and then click the ADD button to move the variables into the  Model box. 
 Click the CONTINUE button to return to the  Linear Mixed Models dialog box. 

328  Multivariate Multilevel Models 
  5.  Finally, in the  Linear Mixed Models 
dialog box, click the OK button to run 
the model (Table 7.16). 
 Investigating a Random Level 2 Slope 
 Another of our research goals was to determine whether the eﬀ ects of particular individuals’ 
background variables (e.g., gender and stability) on perceptions might vary across organizations 
at Level 3. If a slope parameter does vary across organizations, we can build a model to explain 
this variation in slopes at Level 3. To illustrate this, we will propose that the slope describing the 
eﬀ ect of individuals’ stability in the organization on their perceptions of the two constructs varies 
across organizations (instructions provided in Model 1.6). Th e stability slopes from Equation 
7.9 (  12 k  and   22 k  ) can be designated as randomly varying at Level 3 (between organizations) as 
follows: 
 
   12 k     120   u 12 k  , 
 
   22 k     220   u 22 k  , 
(7.13) 
 where   120 and   220 are the average slope eﬀ ects at the organizational level and  u 12 j  and  u 22 j  repre-
sent variation in the female-work life and female-performance slopes across organizations. We 
can summarize this combined model as follows: 
 Y ijk     100    200    101 assessjob jk  * gmorgprod k     201 assessjob jk  * gmorgprod k  
   102 assessjob * gmresources k     202 assessjob jk  * gmresources k     110 assessjob jk  * female jk  
   210 assessjob jk  * female jk     120 assessjob jk  * stability jk     220 assessjob jk  * stability jk  
  u 10 k    u 20 k    u 12 k  assessjob jk  * stability jk    u 22 k  assessjob jk  * stability jk    r 1 jk    r 2 jk     ijk  . 
(7.14) 
 At Level 3, we can specify a UN covariance matrix to capture variability in intercepts, slopes, 
and the covariance between the intercept and slope. We note that in order to specify each sta-
bility slope as randomly varying, we have to create an interaction term ( assessjob*stability ) in 
the Random command (instructions provided in Model 1.7). Th is creates a relatively complex 
covariance matrix of random eﬀ ects. If instead we wanted to build a random slope on the model 
with quality constraints, as in Table 7.16, we would not need to specify an interaction term in 
the Random command. At Level 2, we can also continue to use a UN covariance matrix at the 
between-individual level. 
 When we actually speciﬁ ed the model in Table 7.15 as having a random slope, however, we 
found that the eﬀ ect of individuals’  stability  on the constructs did not vary signiﬁ cantly across 
organizations. We also received a warning message that the model did not converge. For the 
model with equality constraints (Table 7.16), we found we could obtain a solution by specifying 

Multivariate Multilevel Models  329
the random-eﬀ ects covariance matrices to be diagonal at Levels 2 and 3, but, even so, the ef-
fect of employee stability on the two constructs did not vary across organizations ( p  .751). 
We therefore stopped our model investigation at this point. For interested readers, we provide 
a comparison of the estimates produced with Mplus (using a two-level latent variable analysis) 
and the MIXED speciﬁ cation in Table 7.15 in Appendix B. As we might expect, the analyses 
produce very similar results. We note in passing that for models where there are several latent 
constructs under consideration, multilevel structural equation modeling may be an approach that 
is easier to implement. Th is latter approach requires specialized software that is not available in 
IBM SPSS, however. 
 Deﬁ ning Models 1.6 and 1.7 with IBM SPSS Menu Commands 
 Note: IBM SPSS settings will default to those used in Model 1.5. 
  1. Go to the toolbar and select ANALYZE, MIXED MODELS, LINEAR. 
 Th is command enables access to the  Linear Mixed Models: Specify Subjects and Repeated 
dialog box. 
  2. Th e  Linear Mixed Models: Specify Subjects and Repeated screen displays the default settings from the 
prior model. We will retain the default settings. 
 Click the CONTINUE button to display the  Linear Mixed Models dialog box. We will change the 
model’s random eﬀ ects, so click the  Random Eﬀ ects  button to access the random-eﬀ ects main screen. 
 Model 1.6 
  3. Th e  Random Eﬀ ect 2 of 2 
screen is displayed ﬁ rst, as it 
was the last dialog box used 
in the prior model. 
 
 a.  Change the covariance 
type by clicking the pull-
down menu and selecting 
 Diagonal. 
 Th e  Diagonal  covariance type has 
heterogeneous variances and zero 
correlation between the elements 
(IBM Corporation, 2012). 
 
 b.  Click the PREVIOUS 
button to access the  Ran-
dom Eﬀ ect 1 of 2 screen. 

330  Multivariate Multilevel Models 
 
 c.  From the  Random 
Eﬀ ect 1 of 2 screen 
change the covariance 
type by clicking the 
pull-down menu and 
selecting  Diagonal. 
 
 d.  Click to select  stabil-
ity , and then click the 
ADD button to move 
the variable into the 
 Model box. 
 Click the CONTINUE but-
ton to return to the  Linear 
Mixed Models dialog box. 
Click the OK button to run 
the model. 
 Model 1.7 
 Repeat steps 1 and 2 from 
Model 1.6, and then click the 
FIXED button to access the 
 Linear Mixed Models: Fixed 
Eﬀ ects dialog box. 
 Add First Interaction to Model 1.7:  gmorprod*assessjob 
 
 4a. Th e  Linear Mixed Models: Fixed Eﬀ ects  dialog box displays the default setting from the prior 
model. We will modify the model by ﬁ rst removing four variables ( female ,  stability ,  gmorprod , 
and  gmresources ). Click to select  female ,  stability ,  gmorprod , and  gmresources , and then click the 
REMOVE button. 
 
 b. Click to select  Build nested terms . 
 
 c. Now click to select the variable  gmorprod  from the  Factors and Covariates box. 
 
 d.  Click the arrow button below the  Factors and Covariates box. Th is moves  gmorprod into the 
 Build Term box to create a cross-level interaction by linking variables and terms. 
 
 e. Next, click the BY* button, which will insert the computation command symbol:  gmorprod * 

Multivariate Multilevel Models  331
 
 f.  Click to select  assessjob from the  Factors and Covariates box. 
 
 g.  Click the arrow button below the  Factors and Covariates box to move  assessjob into the  Build 
Term box and complete the interaction term:  gmorprod*assessjob 
 
 h.  Click the ADD button to transfer the interaction into the  Model box. 
 Add Second Interaction to Model 1.7:  gmresources*assessjob 
 Repeat steps 4c to 4h using  gmresources and  assessjob for the interaction. 
 Add Third Interaction to Model 1.7:  stability*assessjob 
 Repeat steps 4c to 4h using  stability and  assessjob for the interaction. 
 Add Fourth Interaction to Model 1.7:  female*assessjob 
 Repeat steps 4c to 4h using  female and  assessjob for the interaction. 
 Th e completed model is shown in the insert. Click the CONTINUE button to return to the 
 Linear Mixed Models dialog box. 
 Finally, in the  Linear Mixed Models dialog box, click the OK button to run the model. 
 Multivariate Multilevel Model for Correlated Observed Outcomes 
 In our second example, we use the multivariate multilevel formulation to deﬁ ne separate outcome 
models that take into consideration the correlation between the multiple outcomes. Th is formu-
lation is similar to the previous model, with the major diﬀ erence being there are no underlying 
constructs to deﬁ ne. In this example, we have three tests summarizing individual achievement 
in reading, math, and language. Th e goal is to build a model where the ﬁ xed eﬀ ects are used to 
control for diﬀ erences in the means between individual responses and the random eﬀ ects can be 
used to model the diﬀ erent variances for the outcomes, as well as the covariances (or correlations) 
between the outcome measures (Leyland, 2004). One beneﬁ t of this speciﬁ c type of model is in 
testing the equality of the size of eﬀ ect of a speciﬁ c predictor on each of the outcomes. 
 We note that in this multivariate formulation, the repeated measures (Level 1) speciﬁ cation 
is again used to collect three subtest measures within individuals; however, we do not include 
an error term at the lowest level. At Level 2 (between individuals), we specify the individual 
background variables in the model. Th ese estimates are considered as “ﬁ xed” (i.e., not varying) 
at the individual level. At the school level (Level 3), we can deﬁ ne possible random eﬀ ects (e.g., 
variation in the achievement scores across schools and variation in the eﬀ ects of background vari-
ables). We can also consider the eﬀ ects of school predictors on the randomly varying outcomes. 
 The Data 
 Th e data set consists of 2,715 students (Level 1,  N  8,145 observations) nested in 353 schools 
( Table 7.17  ). Between individuals, we will investigate the eﬀ ect of  gender (coded 1  female, 0  
male) on the three achievement outcomes. Between schools, we investigate the eﬀ ect of  academic 
press (i.e., the same school variable indicating the relative focus on academic outcomes) on the 
set of correlated subtests. 
   Research Questions 
 In this example, the primary research question concerns whether gender aﬀ ects students’ achieve-
ment on each test. In this instance, we wish to control for the likely correlation between stu-
dent performance on each test. We then can ask whether the size of the gender eﬀ ect is the 
same across all three tests. In answering this latter question, we are interested in investigating 

332  Multivariate Multilevel Models 
hypotheses about the eﬀ ect of gender on each of the student subtests comprising the multivariate 
outcome. More speciﬁ cally, we wish to determine whether the eﬀ ect of gender is the same across 
the correlated subtest outcomes or whether it may be related to some subtests but not others. 
In each case, the hypothesis proposed is that the strength of the eﬀ ect of the predictor on the 
three outcomes is the same. For example, for gender, the null hypothesis would be that the three 
unstandardized betas (  1 ) would be the same: 
 H 0    1 Read     1 Math     1 Language  . 
 We will also pose a question about whether the eﬀ ect of the school’s academic press is the same 
across the three subtests. 
 Formulating the Basic Model 
 Similar to our previous multivariate formulation, we do not specify an intercept in the  Random 
dialog box (or syntax subcommand) for the lowest level of the model. We note in passing that we 
could deﬁ ne the three observed outcomes as a latent achievement variable at Level 1 and exam-
ine variation due to individuals at Level 2 and variation due to schools at Level 3. Th is would be 
TABLE 7.17 Data Deﬁ nition of ch7achievement.sav (N = 8,670)
Variable
Levela
Description
Values
Measurement
schcode
School
School identiﬁ er (353 schools).
Integer
Ordinal
id
Individual
Individual student identiﬁ er (2,715 
students).
Integer
Ordinal
Rid
Individual
Recoded individual student identiﬁ ers 
(id   ) with the school identiﬁ er (schcode ) 
identifying students within their school 
groups (1,2,. . .,30). 
1,2,. . .,30
Ordinal
female
Individual
Demographic predictor variable 
representing students gender
0 = Male
1 = Female
Scale
Index1
Within Individual
Identiﬁ er variable resulting from 
representing the three tests comprising 
achievement within individuals.
(1, 2, 3)
Nominal
achieve
Within Individual
Dependent variable measuring 
achievement on three achievement 
outcomes for math and reading.
25.29 to 99.98
Scale
gmses
Individual
Predictor variable (grand-mean centered) 
measuring the socioeconomic status of 
students within schools.
–2.05 to 1.52
Scale
gmacademic
School
Predictor variable (grand-mean centered) 
representing average years of teaching 
experience of the staff
–2.61 to 339
Scale
gmses_mean
School
Predictor variable (grand-mean centered) 
representing average years of teaching 
experience of the staff.
–0.83 to 1.52
Scale
gmacadpress
School
Predictor variable (grand-mean centered) 
measuring each schools academic 
outcomes.
–2.51 to 1.22
Scale
a Within individual = Level 1; Individual = Level 2; School = Level 3.

Multivariate Multilevel Models  333
similar to our previous three-level formulation with measurement model at Level 1. If we were 
to do this, we should have variables measured on the same scale (e.g., scaled scores) and with 
similar variance. 
 As we have suggested previously, the multivariate linear model is commonly formulated as a 
single-level model speciﬁ ed in matrix notation (e.g., see Leyland, 2004). To deﬁ ne this type of 
model in MIXED, we stack the single-level model with reading, math, and language subtests in a 
single variable column ( Y ijk  ), where  i refers to the particular subtest ( i  1, 2, 3) for individual  j in 
school  k . As we noted, instead of creating a latent achievement construct at Level 1, in this exam-
ple we will again use a categorical indicator ( Index1 ) to open up the  Repeated dialog box for the 
Menu commands. At the lowest level, the categorical indicator is used to identify each response 
variable. In this case, it is used to generate three design matrix columns corresponding to three 
intercept terms (Leyland, 2004). Specifying the ﬁ xed-eﬀ ects portion of the model as having no 
intercept (NOINT) ensures that separate intercepts are obtained for each of the three subtests 
and prevents MIXED from generating another, unnecessary, intercept column (Leyland, 2004). 
At this lowest level, we must also designate students as nested in schools [Subject ( schcode*Rid )] 
on the Repeated command line (if we refer to the syntax statements). 
 We note that this particular speciﬁ cation has the eﬀ ect of combining Levels 1 and 2 to cre-
ate a basic two-level (i.e., student and school) multivariate formulation (Leyland, 2004). As we 
indicated previously, in this formulation there is no modeling of the residual variance (  ijk  ) at 
the lowest level of the model. Moreover, because Levels 1 and 2 are combined to serve as the 
student level, we do not specify a random intercept at the individual level. By declaring  Index1  as 
the random eﬀ ect at the highest level (using  schcode as the subject variable), we can ﬁ t a random 
intercept model for each test between schools. 
 For ease of presentation, in Equation 7.15, we specify a separate, combined equation for each 
outcome (using  R for reading,  M for math, and  L for language). We can also add one or more 
student-level  X jk  predictors and school-level  W k  predictors in each combined model. In this case, 
we will add female as a student-level predictor and academic press ( gmacadpress ) as a school in-
dicator. We could add other predictors, but this should be suﬃ  cient to demonstrate this type of 
model speciﬁ cation adequately. Following Leyland (2004), the ﬁ tted two-level models are then 
as follows: 
 Y Rjk     R  00    R  01 gmacadpress k     R  10 female jk    u R  0 k    r Rjk  , 
 Y Mjk     M  00    M  01 gmacadpress k     M  10 female jk    u M  0 k    r Mjk  , 
 Y Ljk     L  00    L  01 gmacadpress k     L  10 female jk    u L  0 k    r Ljk  . 
(7.15) 
 Th is suggests that we have separate intercepts and regression coeﬃ  cients for the school-level 
intercepts and within-group and between-group predictors, with  r representing within-school 
residuals for each equation and  u representing random eﬀ ects associated with explaining school 
achievement for each subtest. For this example, we will consider the slope coeﬃ  cients describ-
ing the relationship of gender and each subtest (  1 k  ) within schools to be ﬁ xed between schools 
(  1 k     10 ). 
 Once again, we note that  Index1  is crossed with the within-school predictors ( X ) and be-
tween-school ( W ) predictors in the combined model (e.g.,  Index1*female ), if we wish to include 
a separate regression coeﬃ  cient describing the gender eﬀ ect on each outcome. Th is is important 
in our example since one of our goals is to examine whether the eﬀ ects of gender are the same or 
diﬀ erent on each outcome. If we wished to impose equality constraints on the predictor, however, 
that variable (e.g., female) could be added directly into the model (Hox, 2010). 
 We will select a UN covariance matrix where the residuals are assumed to be normally dis-
tributed ( N ) with 0 means in order to examine the variances and covariances between tests at the 
school level. 

334  Multivariate Multilevel Models 
#
$


#
'
$








 
#
















(  
 
'
'


 
(













(  
 
'
'












(
'
'


 
(













(  
 






(



%
&'
 
 
 
(









(  
(














(  
(  
 




 
(7.16) 
 We will specify a similar structure at the student level. 
#
$
2


r
# 0
'
$





2



2
 
0
# 0
R
RM
RL
r
r
r
RM
RL
RM



R
RM
RM









0
R
jk
0
rR




r
( 0
 
 
0
'
'


 
(
2



2





 ~
M
jk
0
r
0
~
M
jk
0




( 0
 
 
'
,
'
,

RM
M
ML



RM
M
RM
M



0
2
RM
M
MLr
M
M
ML
M
M

RM
M
ML
RM
M
RM
M


M
jk
0
 M
jk
0
(
'
'


2
 
0
( 0
2







2


r




( 0
 
 
0






0
L rk
0
rL
( 0



%
&'
 
 
 
( 0


r
r
r




RLr
r
r
ML
L
ML
RL
ML
Lr
ML
L
ML



RL
ML
ML
 
(7.17) 
 Th is fully speciﬁ ed model will have 21 parameters to estimate (i.e., three ﬁ xed-eﬀ ect intercepts, 
three ﬁ xed-eﬀ ect estimates for female, three ﬁ xed-eﬀ ect estimates for academic press, and 12 
covariance parameters). 
 Model 2.1: Null Model (No Predictors) 
 We will ﬁ rst deﬁ ne a simple “no-predictors” model with random intercepts for each response 
variable at Level 2. Th is combined model will have 15 parameters to estimate (i.e., three ﬁ xed 
eﬀ ects and 12 covariance parameters in the two covariance matrices as speciﬁ ed in Eqs. 7.16 
and 7.17). 
 Deﬁ ning Model 2.1 (Null) with IBM SPSS Menu Commands 
 Launch the IBM SPSS program 
application, and select the 
ch7achievement.sav data ﬁ le. 
  1.  Go to the toolbar and select 
ANALYZE, MIXED 
MODELS, LINEAR. 
 Th is command enables access to 
the  Linear Mixed Models: Specify 
Subjects and Repeated dialog box. 

Multivariate Multilevel Models  335
  2.  Th e  Linear Mixed Models: Specify Subjects and 
Repeated screen displays options for deﬁ ning 
variables as subjects, repeated observations, 
and type of covariance structure in a model. 
 
 a.  A subject is an observational unit that may 
be independent of other subjects. For this 
model, we will designate two subject identi-
ﬁ ers for the model ( schcode and  Rid    ). Click 
to select  schcode , and then click the right-
arrow button to move the variable into the 
 Subjects box. 
 
 b.  Click to select  Rid , and then click the 
right-arrow button to move the variable 
into the  Subjects box. 
 
 c.  Th e  Repeated  box allows specifying variables 
that identify repeated observations. For this 
model,  Index1  identiﬁ es indexing the  id indi-
vidual student identiﬁ er to deﬁ ne three test 
measures each in math and reading. Click to 
select  Index1 , and then click the right-arrow 
button to move the variable into the  Repeated 
box. 
 Th e combination of values for  schcode ,  Rid , and  Index1 deﬁ nes a particular student from a particular 
school group across a single measure of achievement comprising three measures each of reading and 
math scores. 
  d.  Th e  Repeated Covariance Type speciﬁ es a model’s covariance structure. For this model, we will use 
an unstructured matrix. Click the pull-down menu to select  Unstructured . 
 Unstructured is a completely general covariance matrix (IBM Corporation, 2012). 
 Click the CONTINUE button to display the  Linear Mixed Models dialog box. 
  3.  Th e  Linear Mixed Models main 
screen enables specifying the depen-
dent variable, factors, and covariates, 
as well as access to dialog boxes for 
deﬁ ning  Fixed and  Random eﬀ ects, 
and options for  Estimation ,  Statistics , 
 EM Means , and  Save. 
 
  a.  For this model, we will use 
 achieve as the dependent variable. 
Click to select the  achieve variable 
from the left column listing. Th en 
click the right-arrow button to 
transfer  achieve into the  Depen-
dent Variable box. 
 
  b.  We will create a no-intercept null model that uses  Index1 . Click to select  Index1  from the left 
column listing. Th en click the right-arrow button to transfer the variable into the  Factor(s) box. 
 Click the FIXED button to access the  Linear Mixed Models: Fixed Eﬀ ects dialog box. 

336  Multivariate Multilevel Models 
 
 4a.  Within the  Linear 
Mixed Models: Fixed 
Eﬀ ects dialog box, 
we will retain the 
default  Factorial set-
ting, which creates all 
possible interactions 
and main eﬀ ects of 
the speciﬁ ed variable 
(IBM Corporation, 
2012). 
 
 b.  Now click to select 
 Index1  from the  Fac-
tors and Covariates 
box, and then click 
the ADD button to 
move the variable 
into the  Model box. 
 
 c.  To create the no-intercept model, uncheck the  Include intercept option. 
 Click the CONTINUE button to return to the  Linear Mixed Models dialog box. 
 We will now add random eﬀ ects to this model. 
 Click the RANDOM button to access the  Linear Mixed Models: Random Eﬀ ects dialog box. 
  5.  Th e  Linear Mixed 
Models: Random Eﬀ ects 
displays the  Random Ef-
fect 1 of 1 screen, which 
is the default when 
creating a model for the 
ﬁ rst time. Th e random-
eﬀ ects screen allows 
specifying random ef-
fects, interactions, inter-
cept terms, and subject 
groupings. 
 
 a.  Begin by specifying 
the covariance struc-
ture from the default 
variance components 
(VC) to  Unstructured . 
Click the pull-down 
menu and select  Un-
structured (UN). 
 
  
  Unstructured is a 
completely general 
covariance matrix 
(IBM Corporation, 2012). 

Multivariate Multilevel Models  337
 
 b. We want the intercept to be excluded from the model, so we will retain the current default 
setting. 
 
 c. We will also retain the default  Factorial setting, which creates all possible interactions and main 
eﬀ ects of the speciﬁ ed variable (IBM Corporation, 2012). 
 
 d. Click to select  Index1 , and then click the ADD button to move the variable into the  Model box. 
 
 e. Th e  Subject Groupings  box displays the  schcode and  Rid variables that were speciﬁ ed as subject 
variables in the  Specify Subjects and Repeated dialog box show in step 2a. We will specify  schcode 
as the subject for the random-eﬀ ects Level 1 part of this model. Click to select  schcode , and then 
click the right-arrow button to move the variable into the  Combinations box. 
 Click the CONTINUE button to return to the  Linear Mixed Models dialog box. 
  6. Click the ESTIMATION 
button to access the  Linear 
Mixed Models: Estimation 
dialog box, which displays 
two estimation method 
choices: ML or REML. 
 We will use the default setting of 
REML to estimate the models. 
 Click the CONTINUE button to 
return to the  Linear Mixed Models 
dialog box. 

338  Multivariate Multilevel Models 
  8. We recommend view-
ing your syntax com-
mands before running 
the null model to ﬁ rst 
check if the model 
has been properly 
speciﬁ ed. 
 Click the PASTE but-
ton on the  Linear Mixed 
Models dialog box, which 
will open a new window 
that displays the null 
model’s syntax. Discussion 
of syntax occurs in the next 
section, “Examining the 
Syntax Commands.” 
 Note: Executing the  Paste 
command will generate the 
syntax but also close the 
 Linear Mixed Models dialog 
box. You will then need to 
repeat several steps in order 
to reaccess the  Linear Mixed Models dialog box where you may then be able to run the model: 
 
  a.  Go to the toolbar and select ANALYZE, MIXED MODELS, LINEAR. Th is command 
enables access to the  Linear Mixed Models: Specify Subjects and Repeated dialog box. 
 
  b.  Within the  Linear Mixed Models: Specify Subjects and Repeated dialog box, click the 
CONTINUE button to open the  Linear Mixed Models dialog box. 
 Now continue on to the ﬁ nal step (9). 
  7. In the  Linear Mixed Models dialog 
box, click the STATISTICS but-
ton to access the  Linear Mixed 
Models: Statistics dialog box. 
 Click and select the following three 
statistics to be included in the output: 
 Parameter estimates ,  Tests for covariance 
parameters , and  Covariances of random 
eﬀ ects . 
 Click the CONTINUE button to re-
turn to the  Linear Mixed Models dialog 
box. 

Multivariate Multilevel Models  339
  9. Finally, in the  Linear Mixed Models 
dialog box, click the OK button to 
run the model. 
 Examining the Syntax Commands 
 We suggest examining the syntax statements to see whether the model has been set up properly 
using the  Repeated Covariance Type menu option. Th e /FIXED command speciﬁ es  Index1  as 
the single predictor and no intercept (NOINT) in the ﬁ xed-eﬀ ects portion of the model. Th e /
REPEATED command line shows the variable  Index1  has been deﬁ ned to represent the subtests 
and that the proper nesting of students within schools was accomplished correctly ( schcode*Rid ). 
Next notice that the /RANDOM command includes  Index1  as a random eﬀ ect, which allows 
the intercepts for the each test to vary across schools, and the school level ( schcode ) has been 
properly deﬁ ned. We note there is no random term at the individual level. 
 MIXED 
 achieve BY Index1 
 /CRITERIA  CIN(95) MXITER(100) MXSTEP(5) SCORING(1) 
 SINGULAR(0.000000000001) HCONVERGE(0, ABSOLUTE) LCONVERGE(0, ABSOLUTE) 
 PCONVERGE(0.000001, ABSOLUTE) 
 /FIXED  Index1 |NOINT SSTYPE(3) 
 /METHOD  REML 
 /PRINT  G SOLUTION TESTCOV 
 /RANDOM Index1 |SUBJECT(schcode) COVTYPE(UN) 
 /REPEATED  Index1|SUBJECT(schcode*Rid) COVTYPE(UN). 
 Interpreting the Output From Model 2.1 
 We present the ﬁ xed eﬀ ects for a simple “no-predictors” model ﬁ rst (  Table 7.18  ). Th e school-
level means (corrected for correlations between outcomes) are as follows: reading ( R  57.421), 
math ( M  59.238), and language ( L  57.816).   
TABLE 7.18 Estimates of Fixed Effectsa
Paramenter
Estimate
Std. Error
df
t
Sig.
95% Conﬁ dence Interval
Lower Bound
Upper Bound
[Index1 = 1]
57.421
0.259
291.975
221.903
.000
56.912
57.931
[Index1 = 2]
59.238
0.284
304.979
208.703
.000
58.680
59.797
[Index1 = 3]
57.816
0.276
306.376
209.702
.000
57.274
58.359
a Dependent variable: achieve.

340  Multivariate Multilevel Models 
 We also show the speciﬁ cation of the two covariance matrices between and within schools in 
 Table 7.19  . As speciﬁ ed, the structure is fairly complex but with all the variances and covariances 
statistically signiﬁ cant within and between schools. 
 Model 2.2: Building a Complete Model (Predictors and Cross-Level Interactions) 
 We will next build the model with individual-level and school-level predictors, as speciﬁ ed in 
Eqs. 7.15–7.17. 
 Deﬁ ning Model 2.2 with IBM SPSS Menu Commands 
 Settings will default to those used in 
Model 2.1. 
  1. Go to the toolbar and select ANA-
LYZE, MIXED MODELS, 
LINEAR. 
 Th is command enables access to the  Linear 
Mixed Models: Specify Subjects and Repeated 
dialog box. 
TABLE 7.19 Estimates of Covariance Parametersa
Parameter
Estimate
Std. Error
Wald Z
Sig.
95% Conﬁ dence Interval
Lower Bound Upper Bound
Repeated Measures
UN (1, 1)
89.770
2.591
34.645
.000
84.832
94.995
UN (2, 1)
55.555
2.082
26.689
.000
51.475
59.635
UN (2, 2)
80.659
2.339
34.486
.000
76.202
85.375
UN (3, 1)
54.857
2.163
25.363
.000
50.618
59.096
UN (3, 2)
59.393
2.137
27.786
.000
55.203
63.582
UN (3, 3)
91.458
2.637
34.682
.000
86.433
96.775
Index1 
[subject = schcode]
UN (1, 1)
9.992
1.755
5.695
.000
7.083
14.097
UN (2, 1)
11.217
1.746
6.425
.000
7.795
14.639
UN (2, 2)
15.239
2.128
7.163
.000
11.591
20.035
UN (3, 1)
9.894
1.644
6.018
.000
6.671
13.116
UN (3, 2)
12.354
1.865
6.624
.000
8.699
16.010
UN (3, 3)
12.532
1.966
6.373
.000
9.214
17.044
a Dependent variable: achieve.

Multivariate Multilevel Models  341
  2. Th e  Linear Mixed Models: Specify Subjects and 
Repeated screen displays the default settings 
from the prior model. 
 Click the CONTINUE button to display the 
 Linear Mixed Models dialog box. 
  3. Th e  Linear Mixed Models dialog box 
settings default to those used in the 
prior model. 
 We will introduce two additional 
variables to be used in the model 
(      female and  gmacadpress ). 
 
 a. First, click to select  female , and 
then “drag” the variable below 
 Index1 in the  Factor(s) box. 
 
 b. Next, click to select  gmacadpress , 
and then click the arrow but-
ton or drag the variable into the 
 Covariate(s) box. 
 Click the FIXED button to access the  Linear Mixed Models: Fixed Eﬀ ects dialog box. 
 Two cross-level interactions (or nested terms) will be created and added to the model: 
 Index1*gmacadpress and  Index1*female . Th ese interactions will tell us if (a) each school’s academic 
outcomes aﬀ ect students’ achievement on each of the subtests ( Index1 ) and (b) student achievement on 
each of the subtests ( Index1 ) is aﬀ ected by gender (       female ). 

342  Multivariate Multilevel Models 
 Add First Interaction to Model 2.2:  Index1 * gmacadpress 
 
 4a. Click to select  Build nested 
terms . 
 
 b. Click to select the variable 
 Index1  from the  Factors and 
Covariates box. 
 
 c. Th en click the arrow button 
below the  Factors and Covari-
ates box. Th is moves  Index1 into 
the  Build Term box to create a 
cross-level interaction by linking 
variables and terms. 
 
 d. Next, click the BY* button, 
which will insert the computa-
tion command symbol:  Index1* . 
 
 e. Click to select  gmacadpress  from 
the  Factors and Covariates box. 
 
 f. Click the arrow button below the  Factors and Covariates box to move  gmacadpress into the  Build 
Term box and complete the interaction term:  Index1*gmacadpress . 
 
 g. Click the ADD button to transfer the interaction into the  Model box. 
 Add Second Interaction to Model 2.2:  Index1*female 
 Repeat steps 4b to 4g using  Index1 and  female  to create the interaction. 
 Th e completed model is shown in the insert. Click the CONTINUE button to return to the  Linear 
Mixed Models dialog box. 
  5. Finally, in the  Linear Mixed Models 
dialog box, click the OK button to 
run the model. 
 Interpreting the Output From Model 2.2 
 Th e second model summarized in   Table 7.20 presents the adjusted means (i.e., adjusted for gen-
der), which are as follows: reading ( R  58.319), math ( M  58.466), and language ( L  56.109). 
Because we entered female as a factor (categorical variable) in this model (instead of a covariate), 
we see in the table that there are estimates for female  0 (i.e., males), but not for female  1 
(females). Th is is because when a categorical variable is used, MIXED declares the last cat-
egory as the reference group. Th e output, therefore, will show estimates for the  k ‒ 1 categories 
comprising the variable. If one wishes to change the reference group, it is necessary to recode 

Multivariate Multilevel Models  343
the variable. Th e output suggests that males score signiﬁ cantly lower than females (   ‒1.964, 
 p  .001) in reading ( Index1  1, female  0), but signiﬁ cantly higher than females in math 
(   1.504,  p  .01) and language (   3.477,  p  .001). We can also see the redundant eﬀ ects 
from the categorical speciﬁ cation used. Turning to the school portion of the model, we can 
observe that the school’s academic press is positively related to students’ achievement on each of 
the subtests (with   coeﬃ  cients ranging from 1.149 to 1.683 and  p  .001). 
 For comparative purposes, we also provide the output for the same model if we deﬁ ned fe-
male as a covariate instead of as a factor. We provide the syntax for this model in Appendix A. 
 Table 7.21  reveals two noteworthy diﬀ erences. First, the intercepts will be diﬀ erent. If we take 
the intercept from Table 7.20 for reading (58.319) and subtract the coeﬃ  cient for males (1.963), 
we get a coeﬃ  cient of 56.356, which represents the reading intercept for males in Table 7.21 
(with slight diﬀ erence due to rounding)  . Second, the direction of the coeﬃ  cients regarding 
TABLE 7.20 Estimates of Fixed Effectsa
Parameter
Estimate
Std. Error
df
t
Sig.
95% Conﬁ dence Interval
Lower Bound Upper Bound
[Index1=1]
58.319
0.306
588.784
190.818
0.000
57.719
58.919
[Index1=2]
58.466
0.320
550.415
182.866
0.000
57.838
59.094
[Index1=3]
56.109
0.322
594.823
174.051
0.000
55.476
56.742
[Index1=1] * gmacadpress
1.590
0.268
289.596
5.929
0.000
1.062
2.118
[Index1=2] * gmacadpress
1.683
0.291
303.129
5.786
0.000
1.111
2.256
[Index1=3] * gmacadpress
1.149
0.289
314.798
3.973
0.000
0.580
1.717
[Index1=1] * [female=0]
–1.964
0.375
2715.088
–5.240
0.000
–2.699
–1.229
[Index1=2] * [female=0]
1.504
0.362
2692.912
4.149
0.000
0.793
2.214
[Index1=3] * [female=0]
3.477
0.378
2706.867
9.197
0.000
2.736
4.218
[Index1=1] * [female=1]
0.000b
0.000
–
–
–
–
–
[Index1=2] * [female=1]
0.000b
0.000
–
–
–
–
–
[Index1=3] * [female=1]
0.000b
0.000
–
–
–
–
–
a Dependent variable: achieve.
b This parameter is set to 0 because it is redundant.
TABLE 7.21 Estimates of Fixed Effectsa
Parameter
Estimate
Std. Error
df
t
Sig.
95% Conﬁ dence Interval
Lower Bound Upper Bound
[Index1 = 1]
56.356
0.315
649.589
178.770
.000
55.737
56.975
[Index1 = 2]
59.970
0.328
602.740
182.658
.000
59.325
60.615
[Index1 = 3]
59.586
0.332
653.536
179.657
.000
58.935
60.237
[Index1 = 1] * gmacadpress
1.590
0.268
289.596
5.929
.000
1.062
2.118
[Index1 = 2] * gmacadpress
1.683
0.291
303.129
5.786
.000
1.111
2.256
[Index1 = 3] * gmacadpress
1.149
0.289
314.798
3.973
.000
0.580
1.717
[Index1 = 1] * female
1.964
0.375
2,715.088
5.240
.000
1.229
2.699
[Index1 = 2] * female
–1.504
0.362
2,692.912
4.149
.000
–2.214
–0.793
[Index1 = 3] * female
–3.477
0.378
2,706.867
9.197
.000
–4.218
–2.736
a Dependent variable: achieve.

344  Multivariate Multilevel Models 
gender is diﬀ erent, reﬂ ecting that when female (coded 1) is deﬁ ned as a covariate, the reference 
group will now be males (coded 0). Th e coeﬃ  cients in the model in Table 7.21 will now refer to 
females instead of males. 
 Testing the Hypotheses 
 We can examine whether the eﬀ ect of gender and academic press are the same across the three 
subtests. In   Table 7.22  , we present results from Model 2.2, where female is treated as categorical 
rather than as a covariate (which produces diﬀ erent coeﬃ  cients for  Index1  but the same inter-
pretation). Th e Type III (sum of squares) tests of the ﬁ xed eﬀ ects provide this information. Th e 
signiﬁ cant  F ratios for female and academic press suggest the impact of each predictor is not the 
same across the subtests. We would, therefore, reject the null hypothesis for each variable. 
 Correlations Between Tests at Each Level 
 Finally, we turn our attention to the covariance components table (  Table 7.23  from Model 2.3). 
We can specify the UN covariance matrices as unstructured with a correlation metric (UNR) 
and examine the correlations between the tests in the oﬀ -diagonals of the matrix at each level. 
Within schools, the correlations between the subtests are all moderate and signiﬁ cant (ranging 
from 0.64 to 0.69 and  p  .001). Between schools, the correlations between subtests are also 
signiﬁ cant ( p  .001) and are considerably stronger than the individual-level correlations (with 
coeﬃ  cients ranging from 0.86 to 0.89). 
TABLE 7.22 Model 2.2 (Female Treated as Categorical) Type III Tests of Fixed Effectsa
Source
Numerator df
Denominator df
F
Sig.
Index1
3
294.230
19,787.638
.000
Index1 * gmacadpress
3
296.041
14.037
.000
Index1 * female
3
2,703.990
103.927
.000
a Dependent variable: achieve.
TABLE 7.23 Estimates of Covariance Parametersa
Parameter
Estimate
Std. Error
Wald Z
Sig.
95% Conﬁ dence Interval
Lower Bound
Upper Bound
Repeated Measures
Var(1)
88.632
2.558
34.651
.000
83.758
93.790
Var(2)
80.281
2.327
34.495
.000
75.847
84.975
Var(3)
88.533
2.550
34.722
.000
83.674
93.674
Corr(2, 1)
0.666
0.011
58.781
.000
0.644
0.688
Corr(3, 1)
0.638
0.012
52.958
.000
0.614
0.661
Corr(3, 2)
0.691
0.011
64.875
.000
0.669
0.711
Index1 [subject = 
schcode]
Var(1)
8.297
1.598
5.192
.000
5.688
12.103
Var(2)
12.569
1.902
6.608
.000
9.343
16.909
Var(3)
11.302
1.815
6.226
.000
8.250
15.484
Corr(2, 1)
0.894
0.038
23.424
.000
0.789
0.948
Corr(3, 1)
0.862
0.045
19.014
.000
0.742
0.928
Corr(3, 2)
0.875
0.034
25.704
.000
0.790
0.928
a Dependent variable: achieve.

Multivariate Multilevel Models  345
 Deﬁ ning Model 2.3 with IBM SPSS Menu Commands 
  1. Go to the toolbar and select ANALYZE, MIXED MODELS, LINEAR. 
 Th is command enables access to the  Linear Mixed Models: Specify Subjects and Repeated dialog box. 
  2. Th e  Linear Mixed Models: Specify Subjects and 
Repeated screen displays the default settings 
from the prior model. 
 We will change the  Repeated Covariance Type by 
clicking the pull-down menu and selecting  Unstruc-
tured: Correlation Metric (UNR). 
 Th e  Unstructured: Correlation Metric has heteroge-
neous variances and correlations (IBM Corporation, 
2012). 
 Click the CONTINUE button to display the  Linear 
Mixed Models dialog box. 
  3. Th e  Linear Mixed Models dialog box settings default to those used in the prior model. 
 Click the RANDOM button to access the random-eﬀ ects main screen. 
  4. From the  Random Eﬀ ect 
1 of 1 screen, change the 
covariance type by click-
ing the pull-down menu 
and selecting  Unstruc-
tured: Correlation Metric. 
 Click the CONTINUE but-
ton to return to the  Linear 
Mixed Models dialog box. 
Click the OK button to run 
the model. 

346  Multivariate Multilevel Models 
 Investigating a Random Slope 
 As in our other models, it is easy to investigate a random gender slope across schools using the 
previous model formulation. We can specify female as randomly varying by adding it as a random 
eﬀ ect at the school level (/RANDOM Index1 female). When we do so, we can obtain a covari-
ance estimate for gender with each outcome in the model, as well as a variance component for 
the gender slope, which is signiﬁ cant ( p  .05). We might then investigate whether other school 
predictors (e.g.,  gmcadpress  or  gmses_mean ) explain variation in this slope. We can add such cross-
level interactions into the model as three-way interactions ( gmacadpress*female*Index1 ). If we 
instead add a school-level predictor as a typical cross-level interaction ( gmacadpress*female ), this 
speciﬁ cation becomes a test of an equality constraint across the three outcomes. Tests of ﬁ t be-
tween the two formulations should be conducted with ML estimation. We leave this investiga-
tion to interested readers to conduct (see syntax in Appendix A). 
 Deﬁ ning a Parallel Growth Process 
 Our third example concerns specifying two growth processes within one model. Similar to our 
other multivariate models in this chapter, this can be accomplished by stacking the measures 
of reading and math in one “ achievement ” column. Once again, we can use an  index variable to 
specify the repeated measures and then we can diﬀ erentiate the reading or math repeated mea-
sures by using a dichotomous variable to deﬁ ne each achievement domain. In this case, we will 
develop an achievement variable consisting of three repeated measures of students’ reading and 
math scores. We can specify each type of achievement outcome by using a dummy coded variable 
which we will call math (coded 0  read, 1  math). Th is Level 1 speciﬁ cation facilitates building 
a separate explanatory model for each outcome. 
 The Data 
 For purposes of demonstration, in this example we use a subset of our data (see   Table 7.24  ), 
as it is relatively easy to run into problems of “insuﬃ  cient” computer memory because of the 
complexity of the data structure (i.e., six lines of data for each individual, and 1,836 individuals 
nested within 30 schools). We also recoded the individual identiﬁ ers ( Rid ) within their school 
groups (1,2,. . ., n ) in order to reduce required computer memory space to estimate the model. We 
provide the observed means for the reading and math indicators in   Table 7.25 . 
 TABLE 7.24  Data Deﬁ nition of  ch7PGachievement.sav  ( N = 1,836) 
Variable
Levela
Description
Values
Measurement
id
Individual
Individual student identiﬁ er (1,836 
students).
Integer
Ordinal
Rid
Individual
Recoded individual student identiﬁ ers 
(id  ) with the school identiﬁ er (schcode) 
identifying students within their school 
groups (1,2,. . .,30). 
(1,2, 3,. . .,30)
Ordinal
schcode
School
School identiﬁ er (30 schools).
Integer
Ordinal
female
Individual
Demographic predictor variable 
representing students gender.
0 = Male
1 = Female
Scale
schcontext
School
Variable measuring school composition.
–1.87 to 1.85
Scale
Index1
Within Individual
Identiﬁ er variable resulting from indexing 
the id individual identiﬁ er (1 to 1,836) to 
create a new identiﬁ er to deﬁ ne reading 
(1-3) and math (4-6).
(1, 2, 3, 4, 5, 6)
Ordinal
(Continued)

Multivariate Multilevel Models  347
 Research Questions 
 One advantage of specifying a parallel growth model is that researchers can examine the extent 
to which concurrent individual changes in math and reading are mutually interrelated, as well as 
the extent to which these changes may be explained by the hypothesized individual- and school-
level factors in the model. In particular, the goal was to deﬁ ne a single simultaneous model of 
parallel student growth in reading and math and to investigate how the speciﬁ c school factors 
might moderate student growth. Th e study addresses one primary research question: Do school 
measures of teaching eﬀ ectiveness and school instructional practices moderate student growth 
trajectories in reading and math? 
 Preparing the Data 
 In specifying this type of stacked outcome, we generally would begin with a horizontal data 
set with the three repeated measures of reading ( Read1 ,  Read2 , and  Read3 ) and three repeated 
measures of math ( Math1 ,  Math2 , and  Math3 ) speciﬁ ed horizontally. We then use the  Data: 
Restructure  procedure in IBM SPSS to create a single measure of achievement that is stacked 
vertically with an  index variable that speciﬁ es the six measures of reading and math, which will 
now comprise that achievement dependent variable (see Chapter 2). Th e restructuring procedure 
 TABLE 7.24 (Continued) 
Variable
Levela
Description
Values
Measurement
achieve
Within Individual
Dependent variable measuring 
achievement on three achievement 
outcomes for math and reading.
480 to 849
Scale
math
Within Individual
Dichotomous variable specifying student 
achievement in math or reading. 
 0 = Read
 1 = Math
Nominal
time
Within Individual
Variable representing three linear 
occasions in time measuring students math 
achievement.
 0 = First Time
 1 = Second Time
 2 = Third Time 
Scale
orthtime
Within Individual
Recoded time variable from three 
occasions in time (0, 1, 2) into an 
orthogonal linear –(1, 0, 1) sequence.
–1 = First Time
 0 = Second Time
 1 = Third Time 
Scale
orthquadtime
Within Individual
Recoded time variable from three 
occasions in time (0, 1, 2) into an 
orthogonal quadratic (1, –2, 1) sequence.
 1 = First Time
–2 = Second Time
 1 = Third Time 
Scale
 a Within Individual = Level 1; Individual = Level 2; School = Level 3. 
 TABLE 7.25 Observed Reading and Math 
Achieve
Index
Mean
N
Std. Deviation
Read1
589.44
1,836
34.426
Math1
600.25
1,836
39.638
Read2
648.24
1,836
29.929
Math2
652.06
1,836
30.240
Read3
650.99
1,836
33.720
Math3
661.38
1,836
39.874
Total
633.73
11,016
44.686

348  Multivariate Multilevel Models 
will automatically refer to this new index variable as  Index1 . Th e ﬁ rst three numbers of the  Index1 
variable (1–3) will represent reading, while the last three numbers (4–6) will represent math. 
 After the data are restructured, we can use the  Index1  variable to create two other necessary 
variables for deﬁ ning the parallel growth model. First, we create a dummy variable to deﬁ ne the 
two outcomes (read, math), which we label  math . Using the recode command, from the  Index1 
variable, we can recode 1–3 to 0 to represent the  reading  indicators ( math  0), and we can recode 
4–6 to 1 to represent the math indicators ( math  1). We also need to deﬁ ne the time-related 
polynomials (remembering that we can have  k –1 polynomials, or two in this example). In growth 
modeling, we can also estimate  k –1 random eﬀ ects. Since there are three time points in this 
example, we can estimate two random eﬀ ects. Th is allows us to estimate a random eﬀ ect for the 
intercept and a random eﬀ ect for either the linear component or the quadratic component. 
 Once again using the  Index1  variable, we can recode 1–3 into a linear  time  variable coded as 
0, 1, 2 to deﬁ ne the repeated measures for reading. Th en we also recode 4–6 as 0, 1, 2 to deﬁ ne 
the repeated measures of math. Readers can conﬁ rm for themselves the coding of the variables 
 Index1  (coded 1–6),  math  (coded 0–1), and  time  (coded 0–2) in the data set for this example. We 
also created some additional variables (i.e., a quadratic time component and orthogonal poly-
nomials) to use as we develop our analyses, but this should be suﬃ  cient to get started with the 
model speciﬁ cation of a parallel growth process. 
 We illustrate the actual growth trajectories in   Figure 7.2  . From the trajectories, we can see 
there is considerable slowing over time (between the second and third observations). Th is sug-
gests we should add a quadratic component to the model. 
 Model 3.1: Specifying the Time Model 
 To ﬁ t our proposed model, we can declare a three-level model, with schools at the highest level 
[Subject( schcode )] and the repeated measures on students combined at Levels 1 and 2 (Leyland, 
2004). At the lowest level, we use the  Repeated dialog box to specify the repeated measures 
of achievement using the  Index1  variable. Th is addresses the nesting of the repeated measures 
within individuals [Subject( schcode*Rid )]. We can make use of an indicator variable (i.e., in this 
case, a dummy-coded variable to deﬁ ne the multivariate response structure; Hox, 2010). We can 
deﬁ ne the indicator variable ( I ijk  ) as follows: 
 FIGURE 7.2  Observed math and reading trajectories. 

Multivariate Multilevel Models  349
Y ijk    I ijk Y Mjk   (1 ‒  I ijk  ) Y Rjk  , 
(7.18) 
 where the indicator takes on a value of 1 if  i is the math test and 0 otherwise (Leyland, 2004; 
Raudenbush & Bryk, 2002) for individual  j in school  k . By using a “no intercept” designation 
( NOINT   ) in specifying the model’s ﬁ xed eﬀ ects, we ensure that an intercept is estimated for each 
response variable. 
 As in the previous example, we do not model variance at the student level in this formula-
tion. More speciﬁ cally, we do not include a Random subcommand with subjects ( schcode*Rid  ) 
speciﬁ ed. By specifying the dummy-coded indicator as randomly varying (Random   math ) and 
specifying the Subject subcommand schcode [Subject( schcode )], we can deﬁ ne the two achieve-
ment intercepts at the school level. In Equation 7.19, we deﬁ ne a separate model for each out-
come, which includes the time-related orthogonal polynomials at the individual level ( orthtime
and  orthquadtime ) and the randomly varying reading and math variance parameters (uR0k and 
uM 0k) at the school level. For individual  j in school  k at time  t , then, we have the following equa-
tions for reading and math: 
 
  Y Rtkj     R00     R 10 orthtime tjk     R  20 orthquadtime tjk   u  R 0 k  , 
 Y Mtjk     M 00    M 10 orthtime tjk    M 20 orthquadtime tjk    u M 0 k . 
(7.19) 
 Because the outcomes are represented as a dummy variable in the multivariate formu-
lation, if we do not multiply the predictors by the dummy outcome (e.g.,  math*orthtime and 
 math*orthquadtime ) in specifying the combined, single-equation model, we will obtain only one 
set of coeﬃ  cients, which amounts to imposing equality constraints that the regression coeﬃ  -
cients are the same for both outcomes. 
 At the school level, we assume the intercept residual variances for reading and math are nor-
mally distributed with means of 0. Th e time-related polynomials are ﬁ xed at the school level. We 
will select a UN covariance matrix to examine the variances and covariances between tests at the 
school level. 
 
#
$
2


2


0
R k
0
u
# 0
'
$

RM
R
RM


R
0
# 0
2
R
RM
u
u
RM
RM
R

R
RM
R


0
~
R k
0
N

R k
0
(
'
'
,

2






2


u




( 0






0
M k
0
u
( 0


%
&'
 
 
 
( 0


u
u




RMu
u
M
M
M
M
RM
Mu
M
M


RM
 
(7.20) 
 Within individuals, we will specify the covariance structure as autoregressive (AR1), with the 
constraint |  | ≤ 1 imposed for stationarity. Th is will include an estimated correlation between 
repeated measures over time, but result in only two parameters to estimate (the variance   2 and 
the   correlation). Of course, we could also investigate other possible covariance structures. 
 
2



2
3
4
5
1





2
3
4
3
4


2
3
4









1







2
3
4
1





2
33
1




2
3
4
1


2
2
3





2
22
1











1









1


3
2
2





3
22
1






4
3
2





1









1


4
3
2
1





4
3
2
3
1




4
3
2


5
4
3
2
1











1









5
4
3
2
1





5
4
3
2
4
3






1





 
(7.21) 

350  Multivariate Multilevel Models 
 Deﬁ ning Model 3.1 with IBM SPSS Menu Commands 
 Launch the IBM SPSS program 
application, and select the  ch7PG-
achievement.sav data ﬁ le. 
  1. Go to the toolbar and select 
ANALYZE, MIXED MOD-
ELS, LINEAR. 
 Th is command enables access to the 
 Linear Mixed Models: Specify Subjects 
and Repeated dialog box. 
 
 2. Th e  Linear Mixed Models: Specify Subjects 
and Repeated  screen displays options for de-
ﬁ ning variables as subjects, repeated obser-
vations, and type of covariance structure in a 
model. 
 
 a. For this model, we will designate two 
subject identiﬁ ers for the model ( schcode 
and  Rid ). To facilitate reading of the output 
tables, we will enter the variables in a par-
ticular sequence. First, click to select  schcode , 
and then click the right-arrow button to 
move the variable into the  Subjects box. 
 
 b. Next, click to select  Rid , and then click the 
right-arrow button to move the variable 
into the  Subjects box. 
 
 c. Th e  Repeated  box allows specifying variables 
that identify repeated observations. For 
this model,  Index1  identiﬁ es the repeated 
measures, which deﬁ ne the math and read 
achievement. Click to select  Index1 , and 
then click the right-arrow button to move 
the variable into the  Repeated  box. 
 
  Th e combination of values for  schcode ,  Rid , and  Index1  deﬁ nes a particular student from a par-
ticular school across the three math and reading measures. 

Multivariate Multilevel Models  351
 
 d. Th e  Repeated Covariance Type speciﬁ es a model’s covariance structure. For this model, we will 
use the autoregressive covariance matrix,  AR(1). Click the pull-down menu to select the au-
toregressive covariance matrix,  AR(1) , as the  Repeated Covariance Type. 
 AR(1) is a ﬁ rst-order autoregressive structure with homogenous variances. Th e correlation between any 
two elements is equal to rho (  ) for adjacent elements,   2 for elements that are separated by a third, and 
so on. Rho is constrained so that ‒1    1 (IBM Corporation, 2012). 
 Click the CONTINUE button to display the  Linear Mixed Models dialog box. 
  3. Th e  Linear Mixed Models main screen 
enables specifying the dependent variable, 
factors, and covariates, as well as access to 
dialog boxes for deﬁ ning  Fixed and  Random 
eﬀ ects, and options for  Estimation ,  Statistics , 
 EM Means , and  Save. 
 
 a. For this model, we will use  achieve as 
the dependent variable. Click to select 
the  achieve variable from the left column 
listing. Th en click the right-arrow button 
to transfer  achieve into the  Dependent 
Variable box. 
 Now we will introduce three additional variables to be used in the model ( math ,  orthtime , and 
 orthquadtime ). 
 
 b. First, click to select  math , and then click the right-arrow button (or “drag” the variable) to move 
the variable into the  Factor(s) box. 
 
 c. Next, click to select  orthtime and  orthquadtime.  Th en click the right-arrow button (or “drag” the 
variables) to move them into the  Covariate(s) box. 
 Click the FIXED button to access the  Linear Mixed Models: Fixed Eﬀ ects dialog box. 
 
 4a. Within the  Linear 
Mixed Models: Fixed 
Eﬀ ects dialog box, we 
will retain the default 
 Factorial  setting, which 
creates all possible inter-
actions and main eﬀ ects 
of the speciﬁ ed variable 
(IBM Corporation, 
2012). 
 
 b. Now click to select  math 
from the  Factors and 
Covariates box, and then 
click the ADD button 
to move the variable into 
the  Model box. 
 
 c. To create the no-inter-
cept model, uncheck the  Include intercept option. 

352  Multivariate Multilevel Models 
 Two interactions (or nested terms) will be created and added to the model:  math*orthtime and 
 math*orthquadtime . Th ese interactions will tell us if each student’s achievement ( math ) trajectories have 
linear ( orthtime ) and quadratic ( orthquadtime ) components. 
 Add First Interaction to Model 3.1:  math*orthtime 
 
 d. Click to select  Build nested 
terms . 
 
 e. Click to select the variable 
 math  from the  Factors and 
Covariates box. 
 
 f. Th en click the arrow but-
ton below the  Factors and 
Covariates box. Th is moves 
 math into the  Build Term 
box to create a cross-level 
interaction by linking vari-
ables and terms. 
 
 g. Next, click the BY* button, 
which will insert the com-
putation command symbol: 
 math *. 
 
 h. Click to select  orthtime  from the  Factors and Covariates box. 
 
 i. Click the arrow button below the  Factors and Covariates box to move  orthtime into the  Build 
Term box and complete the interaction term:  math*orthtime . 
 
 j. Click the ADD button to transfer the interaction into the  Model box. 
 Add Second Interaction to Model 3.1:  math*orthquadtime 
 Repeat steps 4e to 4j using  math and  orthquadtime for the interaction. 
 Th e completed model is shown in the insert. Click the CONTINUE button to return to the  Linear 
Mixed Models dialog box. 
 Click the RANDOM button to access the  Linear Mixed Models: Random Eﬀ ects dialog box. 
  5. Th e  Linear Mixed Models: Ran-
dom Eﬀ ects  displays the  Random 
Eﬀ ect 1 of 1 screen, which is the 
default when creating a model for 
the ﬁ rst time. Th e random-eﬀ ects 
screen allows specifying random 
eﬀ ects, interactions, intercept 
terms, and subject groupings. 
 
 a. Begin by specifying the 
covariance structure from the 
default variance components 
(VC) to  Unstructured . Click 
the pull-down menu and 
select  Unstructured (UN). 
 Unstructured is a completely general 
covariance matrix (IBM Corporation, 
2012). 

Multivariate Multilevel Models  353
 
 b. We want the intercept to be excluded from the model, so we will retain the current default 
setting. 
 
 c. We will also retain the default  Factorial setting, which creates all possible interactions and main 
eﬀ ects of the speciﬁ ed variable (IBM Corporation, 2012). 
 
 d. Click to select  math , and then click the ADD button to move the variable into the  Model box. 
 
 e. Th e  Subject Groupings  box displays the  schcode and  Rid variables that were speciﬁ ed as subject 
variables in the  Specify Subjects and Repeated dialog box show in step 2a. We will specify  schcode 
as the subject for the random-eﬀ ects Level 1 part of this model. Click to select  schcode , and then 
click the right-arrow button to move the variable into the  Combinations box. 
 Click the CONTINUE button to return to the  Linear Mixed Models dialog box. 
  6. Click the ESTIMATION button to ac-
cess the  Linear Mixed Models: Estimation 
dialog box, which displays two estima-
tion method choices: ML or REML. 
 We will use the default setting of REML to 
estimate the models. 
 Click the CONTINUE button to return to 
the  Linear Mixed Models dialog box. 
  7. In the  Linear Mixed Models dialog box, 
click the STATISTICS button to ac-
cess the  Linear Mixed Models: Statistics 
dialog box. 
 Click and select the following three statis-
tics to be included in the output:  Parameter 
estimates ,  Tests for covariance parameters , and 
 Covariances of random eﬀ ects . 
 Click the CONTINUE button to return to 
the  Linear Mixed Models dialog box. 

354  Multivariate Multilevel Models 
  8. Finally, in the  Linear Mixed Models 
dialog box, click the OK button to 
run the model. 
 Interpreting the Output From Model 3.1 
 Th e model with then have 11 parameters to estimate. Th is is conﬁ rmed in the model dimension 
table ( Table 7.26 ). 
 We will specify an unstructured covariance matrix at Level 2 and a ﬁ rst-order autoregressive 
covariance matrix to simplify the structure at Level 1.   Table 7.27  presents the results of this ﬁ rst 
parallel growth model with orthogonal time-related polynomials. We can see that polynomials 
are signiﬁ cant for both reading and math, suggesting they should be retained in further analyses. 
 We provide the variance components for this initial model in  Table 7.28 . 
TABLE 7.26 Model Dimensiona
Number 
of Levels
Covariance 
Structure
Number of 
Parameters
Subject 
Variables
Number 
of Subjects
Fixed Effects
math
2
2
math * orthtime
2
2
math * orthquadtime
2
2
Random Effects
math
2
Unstructured
3
schcode
Repeated Effects
Index1
6
First-Order 
Autoregressive
2
schcode * Rid
1,836
Total
14
11
a Dependent variable: achieve.
TABLE 7.27 Estimates of Fixed Effectsa
Parameter
Estimate
Std. Error
df
t
Sig.
95% Conﬁ dence Interval
Lower Bound Upper Bound
[math = 0]
635.213
3.016
29.105
210.611
.000
629.046
641.381
[math = 1]
643.254
3.319
28.977
193.810
.000
636.465
650.042
[math = 0] * orthtime
30.770
0.436
10,678.551
70.591
.000
29.916
31.625
[math = 1] * orthtime
30.562
0.436
10,678.551
70.113
.000
29.707
31.416
[math = 0] * orthquadtime
–9.341
0.180
8,582.880
–51.880
.000
–9.694
–8.988
[math = 1] * orthquadtime
–7.080
0.180
8,582.880
–39.323
.000
–7.433
–6.727
a Dependent variable: achieve.

Multivariate Multilevel Models  355
 Model 3.2: Adding the Predictors 
 We can also add one or more student-level  X jk  predictors and school-level  W k  predictors. In this 
case, we will add female as a student-level predictor and school composition ( schcontext ). Th e 
combined models for reading and math are summarized in Equation 7.22. 
 Y Rtjk      R 00     R 01 schcontext k      R 10 orthtime tjk      R 20 orthquadtime tjk      R 30         female jk  
    R 11 schcontext k  * orthtime tjk      R 31           female ik  * orthtime tjk    u  R 0 k  
 Y Mtjk      M 00     M 01 schcontext k      M 10 orthtime tjk      M 20 orthquadtime tjk      M 30         female jk  
    M 11 schcontext k  * orthtime tjk      M 31        female jk  * orthtime tjk    u  M 0 k  
(7.22)
 Th is suggests we have separate intercepts and regression coeﬃ  cients for the school-level models 
and within-group and between-group predictors, again with representing random eﬀ ects as-
sociated with explaining school achievement for each subtest. In Equation 7.22, we have added 
ﬁ xed-eﬀ ect interactions for  female and school context ( schcontext ) and linear growth ( orthtime ), 
but we again consider linear and quadratic growth as ﬁ xed between schools. We also consider 
the slope coeﬃ  cients describing the relationship between female and each subtest to be ﬁ xed 
between schools. 
 Deﬁ ning Model 3.2 with IBM SPSS Menu Commands 
 Note: Settings will default to those used in 
Model 3.1. 
  1. Go to the toolbar and select ANA-
LYZE, MIXED MODELS, LINEAR. 
 Th is command enables access to the  Linear 
Mixed Models: Specify Subjects and Repeated 
dialog box. 
 TABLE 7.28 Estimates of Covariance Parameters a 
Parameter
Estimate
Std. Error
Wald Z
Sig.
95% Conﬁ dence Interval
Lower Bound
Upper Bound
Repeated Measures
AR1 Diagonal
1,046.835
23.142
45.234
.000
1,002.445
1,093.190
AR1 rho
0.760
0.006
130.537
.000
0.748
0.771
math [subject = 
schcode]
UN (1, 1)
255.352
71.433
3.575
.000
147.579
441.831
UN (2, 1)
274.344
77.453
3.542
.000
122.539
426.150
UN (2, 2)
312.753
86.732
3.606
.000
181.613
538.587
 a Dependent variable: achieve. 

356  Multivariate Multilevel Models 
 Add First Interaction to Model 3.2:  math*schcontext 
 
 4a. Th e  Linear Mixed Models: 
Fixed Eﬀ ects dialog box 
displays the default set-
ting from the prior model. 
To facilitate reading of the 
output tables, we will rear-
range the sequence order of 
the variables by removing 
the interactions. Click to 
select them and then click 
the REMOVE button. 
 
 b. Click to select  Build nested 
terms . 
  2. Th e  Linear Mixed Models: Specify Subjects and 
Repeated screen displays the default settings from 
the prior model. 
 Click the CONTINUE button to display the  Linear 
Mixed Models dialog box. 
  3. Within the  Linear Mixed Models main screen 
we will introduce two additional variables to 
be used in the model (            female and  schcontext ). 
 Click to select  female and  schcontext , and then click 
the right-arrow button (or “drag” the variables) to 
move them into the  Covariate(s) box. 
 Click the FIXED button to access the  Linear Mixed 
Models: Fixed Eﬀ ects dialog box. 
 Two new interactions (or nested terms) will be 
created and added to the model:  math*schcontext 
and  math*female . Th ese interactions will tell us if:(a) 
students’ achievement ( math ) is aﬀ ected by school composition ( schcontext ) and (b) students’ achieve-
ment ( math ) is aﬀ ected by gender ( female ). 

Multivariate Multilevel Models  357
 
 c. Click to select the variable  math  from the  Factors and Covariates box. 
 
 d. Th en click the arrow button below the  Factors and Covariates box. Th is moves  math into the 
 Build Term box to create a cross-level interaction by linking variables and terms. 
 
 e. Next, click the BY* button, which will insert the computation command symbol:  math *. 
 
 f. Click to select  schcontext  from the  Factors and Covariates box. 
 
 g. Click the arrow button below the  Factors and Covariates box to move  schcontext into the  Build 
Term box and complete the interaction term:  math*schcontext . 
 
 h. Click the ADD button to transfer the interaction into the  Model box. 
 Add Second Interaction to Model 3.2:  math*female 
 Repeat steps 4c to 4h using  math and  female for the interaction. 
 We will now reinstate two interactions used in the prior model:  math*orthtime and 
 math*orthquadtime. 
 Add Third Interaction to Model 3.2:  math*orthtime 
 Repeat steps 4c to 4h using  math and  orthtime for the interaction. 
 Add Fourth Interaction to Model 3.2:  math*orthquadtime 
 Repeat steps 4c to 4h using  math and  orthquadtime for the interaction. 
 Th e partially completed model is shown in the insert. 
 Add Fifth Interaction to Model 3.2: 
 schcontext*math*orthtime 
 
 i. Click to select the variable 
 schcontext  from the  Factors 
and Covariates box. 
 
 j. Th en click the arrow but-
ton below the  Factors and 
Covariates box. Th is moves 
 schcontext into the  Build 
Term box to create a cross-
level interaction by linking 
variables and terms. 
 
 k. Next, click the BY* but-
ton, which will insert the 
computation command 
symbol:  schcontext* . 
 
 l. Click to select  math from the  Factors and Covariates box. 
 
 m. Th en click the arrow button below the  Factors and Covariates box. Th is moves  math into the 
 Build Term box to create a cross-level interaction by linking variables and terms. 
 
 n. Next, click the BY* button, which will insert the computation command symbol: 
 schcontext*math* . 
 
 o. Click to select  orthtime  from the  Factors and Covariates box. 
 
 p. Th en click the arrow button below the  Factors and Covariates box. Th is moves  orthtime into the 
 Build Term box to complete the interaction:  schcontext*math*orthtime . 
 
 q. Click the ADD button to transfer the interaction into the  Model box. 

358  Multivariate Multilevel Models 
 Add Sixth Interaction to Model 3.2:  female*math*orthtime 
 Repeat steps 4j to 4q using  female ,  math , 
and  orthtime for the interaction. 
 Th e completed model is shown in the 
insert. 
 Click the CONTINUE button to return 
to the  Linear Mixed Models dialog box. 
  5. Finally, in the  Linear Mixed Models 
dialog box, click the OK button to 
run the model. 
 TABLE 7.29  Model Dimension a 
Number 
of Levels
Covariance 
Structure
Number of 
Parameters
Subject 
Variables
Number 
of Subjects
Fixed Effects
math
2
2
math * schcontext
2
2
math * female
2
2
math * orthtime
2
2
math * orthquadtime
2
2
math * orthtime * schcontext
2
2
math * orthtime * female
2
2
Random Effects
math
2
Unstructured
3
schcode
Repeated Effects Index1
6
First-Order 
Autoregressive
2
schcode * Rid
1,836
Total
22
19
 a Dependent variable: achieve. 
 Interpreting the Output From Model 3.2 
 Once again, we note that the multivariate outcome  math  is crossed with the within-school pre-
dictors ( X ) and between-school ( W ) predictors in the combined model (e.g.,  math  * female ), if we 
wish to have a separate term for each outcome. Th is is important in our example since one of our 
goals is to examine whether the eﬀ ects of gender are the same or diﬀ erent on each outcome. If 
we wished to impose equality constraints on the predictor, however, that variable (e.g., female) 
could be added directly into the model. Readers will recall that we provided an example of this 
type of speciﬁ cation in our previous example. Th e ﬁ nal model as estimated has 19 parameters, 
which we can conﬁ rm in   Table 7.29 . 
 We present the ﬁ xed eﬀ ects in   Table 7.30  . Because of the coding of the orthogonal time vari-
ables, the intercepts can be interpreted as the adjusted grand means for reading and math. Both 
gender and school composition aﬀ ected levels of reading and math signiﬁ cantly ( p  .001). We 
can also observe that gender had a signiﬁ cant eﬀ ect on growth over time; that is, females experi-
enced greater growth in both subject areas than their male peers ( p  .001). 

Multivariate Multilevel Models  359
 TABLE 7.31 Estimates of Covariance Parameters a 
Parameter
Estimate
Std. Error
Wald Z
Sig.
95% Conﬁ dence Interval
Lower Bound
Upper Bound
Repeated Measures
AR1 diagonal
1,033.054
22.766
45.377
0.000
989.384
1,078.652
AR1 rho
0.758
0.006
129.376
0.000
0.746
0.769
math [subject = schcode]
UN (1, 1)
58.311
19.721
2.957
0.003
30.052
113.144
UN (2, 1)
68.404
23.636
2.894
0.004
22.078
114.730
UN (2, 2)
98.797
31.117
3.175
0.001
53.291
183.164
a Dependent Variable: achieve.
TABLE 7.30 Estimates of Fixed Effectsa
Parameter
Estimate
Std. Error
df
t
Sig.
95% Conﬁ dence Interval
Lower Bound Upper Bound
[math=0]
627.765
1.707
34.232
367.771 0.000
624.297
631.233
[math=1]
636.377
2.086
31.171
305.101 0.000
632.124
640.630
[math=0] * schcontext
–12.006
1.354
29.039
–8.864 0.000
–14.776
–9.236
[math=1] * schcontext
–12.759
1.678
27.933
–7.601 0.000
–16.197
–9.320
[math=0] * female
8.094
1.208
2235.499
6.700 0.000
5.725
10.463
[math=1] * female
6.675
1.209
2237.038
5.523 0.000
4.305
9.045
[math=0] * orthtime
29.674
0.587
10678.166
50.525 0.000
28.523
30.825
[math=1] * orthtime
29.577
0.587
10678.166
50.360 0.000
28.426
30.729
[math=0] * orthquadtime
–9.341
0.180
8583.859
–51.979 0.000
–9.694
–8.989
[math=1] * orthquadtime
–7.080
0.180
8583.859
–39.398 0.000
–7.433
–6.728
[math=0] * orthtime * schcontext
–1.270
0.404
10696.211
–3.140 0.002
–2.062
–0.477
[math=1] * orthtime * schcontext
–0.485
0.404
10696.211
–1.199 0.231
–1.277
0.308
[math=0] * orthtime * female
2.260
0.834
10696.211
2.709 0.007
0.625
3.895
[math=1] * orthtime * female
2.057
0.834
10696.211
2.466 0.014
0.422
3.692
a Dependent Variable: achieve.
 Between schools, there is some evidence in this small school sample that students in schools 
with more challenging student composition demonstrated signiﬁ cantly less growth in reading 
over time than their peers in schools at the grand mean of composition (   ‒1.270,  p  .01); 
however, school composition did not aﬀ ect student growth in math over time ( p  .05). 
 Table 7.31 provides the variance component estimates for this model. 
 Figure 7.3  provides the predicted values of achievement (which we can save within the data 
set) to illustrate that the model captures the shape of the observed growth trajectories quite well.  
 Further Considerations 
 We note that we can also specify the  orthtime  parameter as randomly varying. Freeing this pa-
rameter will add two estimated parameters to estimate. Th e resulting covariance parameters in 
 Table 7.32  indicate that the random parameter is signiﬁ cant (one-tailed tests,  p  .05), which 

360  Multivariate Multilevel Models 
suggests that we could continue to build random slope and intercept models to explain this 
variation across schools. Readers will note we had to change the Level 2 covariance matrix [het-
erogeneous compound symmetry (CSH)] to simplify model estimation, given the small number 
of schools in our example (instructions provided at the end of this section). We will stop our 
investigation at this point.  
 Deﬁ ning Model 3.3 with IBM SPSS Menu Commands 
 Settings will default to those used in Model 3.2. 
  1. Go to the toolbar and select ANALYZE, MIXED MODELS, LINEAR. 
 Th is command enables access to the  Linear Mixed Models: Specify Subjects and Repeated dialog box. 
 FIGURE 7.3  Predicted achievement values.
 TABLE 7.32 Estimates of Covariance Parameters a 
Parameter
Estimate
Std. Error
Wald Z
Sig.
95% Conﬁ dence Interval
Lower 
Bound
Upper 
Bound
Repeated 
Measures
AR1 Diagonal
1,033.674
22.847
45.244
.000
989.851
1,079.437
AR1 rho
0.759
0.006
129.797
.000
0.747
0.770
math + 
math * orthtime 
[subject = 
schcode]
Var: [math = 0]
41.234
14.873
2.772
.006
20.334
83.615
Var: [math = 1]
79.831
26.117
3.057
.002
42.043
151.583
Var: [math = 0] * orthtime
3.287
1.911
1.720
.085
1.052
10.272
Var: [math = 1] * orthtime
6.726
3.440
1.955
.051
2.468
18.328
CSH rho
0.770
0.103
7.508
.000
0.483
0.907
 a Dependent variable: achieve. 

Multivariate Multilevel Models  361
  2. Th e  Linear Mixed Models: Specify Subjects and Repeated screen displays the default settings from the 
prior model. 
 Click the CONTINUE button to display the  Linear Mixed Models dialog box. 
  3. Th e  Linear Mixed Models main screen displays the default settings from the prior model. 
 Click the RANDOM button to access the  Linear Mixed Models: Random Eﬀ ects dialog box. 
  4. Th e  Linear Mixed Models: 
Random Eﬀ ects  displays 
the  Random Eﬀ ect 1 of 
1 screen with default 
settings from the prior 
model. 
 
 a. Change the covariance 
structure by click-
ing the pull-down 
menu and selecting 
 Compound Symmetry: 
Heterogeneous . 
 Th e  Compound Symmetry: Het-
erogeneous  covariance structure 
has heterogeneous variances and 
constant correlations between 
elements (IBM Corporation, 
2012). 
 
 b. Click the  Build nested 
terms option. 
 
 c. Click to select the variable  math  from the  Factors and Covariates box. 
 
 d. Th en click the arrow button below the  Factors and Covariates box. Th is moves  math into the 
 Build Term box to create a cross-level interaction by linking variables and terms. 
 
 e. Next, click the BY* button, which will insert the computation command symbol:  math *. 
 
 f. Click to select  orthtime  from the  Factors and Covariates box. 
 
 g. Click the arrow button below the  Factors and Covariates box to move  orthtime into the  Build 
Term box and complete the interaction term:  math * orthtime . 
 
 h. Click the ADD button to transfer the interaction into the  Model box. 
 Click the CONTINUE button to display the  Linear Mixed Models dialog box. 
 Click the OK button to generate the model results. 
 Summary 
 In this chapter, we presented three examples using multilevel multivariate outcomes. Th e com-
posite (or latent construct) formulation is appropriate when one wishes to incorporate multiple 
measurements in deﬁ ning constructs. Our ﬁ rst example provided a case where we estimated a 
construct with a simple error structure within individuals. Since the multilevel (i.e., vertical) for-
mulation does not assume that all outcome data must be available for each individual, it provides 
another way for incorporating missing data into the analysis (Hox, 2010). We next showed how 
the repeated measures format at Level 1 can be used to deﬁ ne a multivariate type of model. We 

362  Multivariate Multilevel Models 
also demonstrated how it is possible to test the equality of regression coeﬃ  cients across outcome 
measures in this type of modeling formulation. In our last example, we showed that this type of 
multilevel model can be generalized to situations where the analyst wishes to examine parallel 
growth processes. We illustrated what that might look like for examining growth in reading and 
math simultaneously. Th is type of growth model can be speciﬁ ed by stacking the reading and 
math repeated measures in one achievement outcome. As we showed, if each variable has three 
repeated observations, the  Index1  variable will have six lines. A dummy indicator (i.e., math) 
can then be deﬁ ned to specify each outcome. Linear and quadratic time-related variables can be 
added as needed to deﬁ ne each trajectory and, ﬁ nally, predictors can then be added within and 
between groups to explain variation in individuals’ growth processes.  

363
 CHAPTER 8 
 Cross-Classiﬁ ed Multilevel Models 
 I
n the models we have previously presented, the data structures have been purely hierarchical; 
that is, each individual was in only one Level 2 setting (e.g., a classroom) and only one Level 
3 setting (e.g., a school). In this chapter, we present situations where the nesting of subjects 
within groups is more complicated. Cross-classiﬁ ed data structures represent a special type of 
multilevel model. In school settings, for example, researchers are often interested in monitoring 
student progress longitudinally. Th is has proven diﬃ  cult, however, since students move regularly 
(and irregularly) between classrooms and schools. Students may belong to more than one unit 
(e.g., classrooms) over time at a particular level of the data hierarchy. Another use of a cross-
classiﬁ ed model might be where we are interested in studying how students transition from high 
schools to postsecondary institutions. In this latter case, within a particular state, students from 
several hundred high schools transition to various 2-year and 4-year institutions. Each student 
in the study, therefore, would be cross-classiﬁ ed by a high school and postsecondary institution 
entered after high school. Cross-classiﬁ ed hierarchical models extend the analytic tools available 
for studying student progress (Hill & Goldstein, 1998). Beretvas (2011), Goldstein (1987), Hox 
(2010), Raudenbush and Bryk (2002), and Snijders and Bosker (1999) provide general overviews 
of cross-classiﬁ ed models. 
 Multiple-membership models extend the cross-classiﬁ ed model to situations where students 
might be members of more than one unit at the highest level. More speciﬁ cally, students might 
attend more than one postsecondary institution in the particular study described previously, for 
example, depending on whether they entered a 2-year institution and then transferred to a 4-year 
institution to ﬁ nish their undergraduate degree. A smaller number may also have entered one 
4-year institution and then transferred to another, perhaps if they switched majors. In either case, 
we might assign Level 1 weights, which describe student membership in one or more postsec-
ondary institutions (Rasbash & Browne, 2001). For interested readers, Beretvas (2011) provides 
an accessible overview of multiple-membership models. 
 Students Cross-Classiﬁ ed in High Schools and Postsecondary Institutions 
 Consider the contribution of students’ high school and college settings to their undergraduate 
educational attainment. Students from any particular public high school may attend a number 
of diﬀ erent college campuses within a state’s higher education system. In this ﬁ rst example, we 
examine whether student background and features of their high school and college entry point 
inﬂ uence their college attainment. We will use students’ cumulative grade point average (GPA) 
at the time they earned their highest undergraduate degree (i.e., associate or bachelor’s). We 
could extend this basic model to a multiple-membership model, if we also wanted to consider 
whether students transferred from one entry campus to another before graduating with a 4-year 
degree. 

364  Cross-Classiﬁed Multilevel Models
 Research Questions 
 Our ﬁ rst research question might ask simply: Do features of students’ high school and college 
entry campuses aﬀ ect their educational attainment, after controlling for student background? 
Second, we ask: Does the slope describing the eﬀ ect of individual socioeconomic status (SES) 
on student college attainment vary randomly across either or both Level 2 units? Th ird, if it 
does vary randomly across units, are there high school and college variables that explain this 
variation? 
 The Data 
 In this subset of a larger data set (  Table 8.1  ), we randomly selected 1,767 students within 30 pub-
lic high schools who entered college at 10 diﬀ erent campuses within a state’s higher education 
system. Th is type of data is considered a two-level cross-classiﬁ ed data set since we have students 
at Level 1 cross-classiﬁ ed in high schools and colleges at Level 2.  
 Using Raudenbush and Bryk’s (2002) cross-classiﬁ ed terminology, in our example data matrix 
summarized in   Table 8.2  , at Level 2 we will consider high schools as the  row data set (i.e., the 
larger number of Level 2 units) and colleges as the  column  data set. In the data matrix, therefore, 
 TABLE 8.1  Data Deﬁ nition of  ch8crossclass1.sav ( N = 1,767) 
Variable
Levela
Description
Values
Measurement4
schcode
School
School identiﬁ er (30 public high schools).
Integer
Ordinal
nschcode
School
Recoded school identiﬁ er for high schools.
(1, 2, 3,...,30)
Ordinal
campus
School
College campus identiﬁ er (10 campuses 
within a state’s higher education system).
(1, 2, 3,...,10)
Scale
female
Individual
Demographic predictor variable 
representing student’s gender.
0 = Male1 = Female
Scale
lowses
Individual
Dichotomous variable representing 
student socioeconomic status.
0 = Did Not Participate,1 = 
Participant in Federal Free/
Reduced Lunch Program
Scale
CUM_GPR
Individual
Dependent variable measuring students’ 
cumulative GPA.
0.0 to 4.00
Scale
lowses_mean
School
Predictor variable (grand-mean centered) 
measuring student socioeconomic status.
0.02 to 0.46
Scale
fouryear
School
Dichotomous variable representing the 
institutional type students attended.
0 = Not 4-Year1 = 4-Year
Scale
gmfemale
Individual
Predictor variable (grand-mean centered) 
measuring student cumulative GPA by 
gender (female).
−0.51 to 0.49
Scale
gmlowses
Individual
Predictor variable (grand-mean centered) 
measuring student cumulative GPA by 
socioeconomic status.
−0.17 to 0.83
Scale
gmLowSES_
mean
School
Predictor variable (grand-mean centered) 
representing an aggregate measure of 
socioeconomic composition for high school.
−0.15 to 0.29
Scale
gmfouryear
School
Predictor variable (grand-mean centered) 
measuring student cumulative GPA by 
institutional type (4-year).
−0.30 to 0.70
Scale
 a Individual = Level 1; school = Level 2. 
4 Measurement icon settings displayed in subsequent model screenshots may differ from Tables 8.1 and 8.13 but will 
not affect the output.

Cross-Classiﬁ ed Multilevel Models  365
each student at Level 1 is cross-classiﬁ ed by a row (high school) and column (college). Th e data 
set is considered cross-classiﬁ ed at Level 2 because students attend diﬀ erent high schools and 
diﬀ erent colleges. Readers will notice that the data in   Table 8.2  are not balanced in either rows 
or columns. For example, in High School 1, 58 students entered the higher education system, 
primarily enrolling at College Campus 3. Moreover, there were ﬁ ve college campus cells that had 
small numbers of students (one to three students) and two campuses that did not receive any 
students from this particular high school. In this type of data conﬁ guration, the sample sizes vary 
considerably, and there are many cells with missing data. Typically, in a cross-classiﬁ ed model, the 
goal is to generalize from the sample to a population of high schools and college campuses. So 
the high school and college eﬀ ects are treated as randomly varying. 
 TABLE 8.2  schcode*campus Cross-Tabulation 
Count
Campus
Total
1
2
3
4
5
6
7
8
9
10
schcode
1
2
1
41
9
0
1
1
0
0
3
58
2
1
1
20
47
0
1
7
0
0
0
77
3
1
0
16
41
0
0
1
0
0
0
59
4
2
2
47
43
0
0
4
0
0
0
98
5
1
1
40
25
0
0
5
0
0
0
72
6
1
3
17
54
0
0
5
0
2
2
84
7
2
0
26
25
1
29
2
0
0
1
86
8
4
2
18
3
0
11
3
0
0
0
41
9
3
6
27
15
1
68
7
0
0
2
129
10
5
4
79
24
0
29
9
0
2
2
154
11
0
0
14
7
0
3
2
0
0
1
27
12
0
1
9
5
1
1
0
0
0
0
17
13
1
3
17
8
0
13
1
0
0
2
45
14
1
0
4
3
0
0
0
0
0
1
9
15
1
4
35
16
0
58
6
0
0
1
121
16
2
1
11
9
0
12
0
0
0
1
36
17
0
2
33
13
0
26
3
0
0
1
78
18
1
1
37
24
0
3
4
0
7
2
79
19
2
1
8
2
0
3
1
0
4
0
21
20
0
2
15
16
0
1
2
0
8
1
45
21
1
0
17
7
0
1
2
0
3
0
31
22
72
6
0
0
0
0
3
1
0
0
82
23
23
3
1
0
0
0
0
1
0
0
28
24
12
1
1
1
0
0
0
0
0
0
15
25
9
0
2
0
0
0
0
0
0
0
11
26
53
0
3
3
1
0
0
0
0
1
61
27
5
2
0
0
0
0
0
0
0
0
7
28
10
0
1
0
0
0
0
0
0
0
11
29
107
8
0
0
0
0
2
0
0
1
118
30
3
3
6
7
0
2
28
16
0
2
67
Total
325
58
545
407
4
262
98
18
26
24
1,767

366  Cross-Classiﬁed Multilevel Models
 Th e structure of the data allows us to examine the variance components in student attainment 
that exist  between high schools ,  between colleges , and  within high school ×  college cells. Within each 
high school–college cell, or the cross-classiﬁ cation, is a unique set of students. For example, 41 
students attended High School 1 and College Campus 3. Th e within-cell model describes the 
variation among these students on an outcome of interest. 
 At Level 2, variation in outcomes between cells of students can be attributed to high school 
eﬀ ects, college eﬀ ects, or perhaps a school-by-college interaction. At this level, we can also de-
velop a model to examine high school and college features on students’ college attainment. In this 
case, we will use the mean percentage of low SES students as a high school composition variable 
that may inﬂ uence student attainment, and a dummy variable for institutional type (i.e., 2-year or 
4-year institution) as a possible college predictor of cumulative GPA. Of course, in this example 
the data set is a little small ( N = 10 colleges), but it will suﬃ  ce for purposes of our demonstration. 
We are limited, however, in the number of predictors we could use because of the small size of 
the college data set. 
 Descriptive Statistics 
 Th e descriptive statistics at the student level and for the cross-classiﬁ ed Level 2 units are sum-
marized in   Tables 8.3  ,   8.4 , and   8.5 . We note in   Table 8.3  that CUM_GPR refers to students’ 
cumulative GPA in subsequent analyses.  
 As a ﬁ rst model, we might examine the variance components in students’ cumulative GPA 
that lie between high schools, between colleges, and within cells (i.e., high school × college 
 TABLE 8.3  Descriptive Statistics
N
Minimum
Maximum
Mean
Std. Deviation
female
1,767
0.000
1.000
0.512
0.500
lowses
1,767
0.000
1.000
0.169
0.375
CUM_GPR
1,767
0.000
4.000
2.903
0.633
Valid N (Listwise)
1,767
 TABLE 8.4  Descriptive Statistics 
N
Minimum
Maximum
Mean
Std. Deviation
lowses_mean
30
0.022
0.462
0.175
0.115
Valid N (Listwise)
30
 TABLE 8.5  Descriptive Statistics 
N
Minimum
Maximum
Mean
Std. Deviation
fouryear
10
0
1
0.300
0.483
Valid N (Listwise)
10

Cross-Classiﬁ ed Multilevel Models  367
cells). Following Goldstein (1995) and Hox (2010), at Level 1, this unconditional (no predictors) 
model can be deﬁ ned as follows: 
 
  Y i  ( jk ) =   0( jk ) +   i  ( jk ) , 
(8.1) 
 where  Y i  ( jk ) is the cumulative GPA of student  i within the cross-classiﬁ cation of high school  j 
and college  k ,   0( jk ) is the intercept (overall mean GPA) of students in cell  jk  (i.e., students who 
attended high school  j and college  k ), and   i  ( jk ) is the with-cell residual that represents the devia-
tion of student  ijk ’s GPA from the cell mean. Th e residual is assumed to be normally distributed 
with the mean equal to 0 and some variance ( 2
	
  ). Th e Level 1 residual can be further modeled 
to reﬂ ect more complex Level 1 variation if desired (Hill & Goldstein, 1998). Th e subscripts ( jk ) 
suggest that we assume that the intercept varies independently across both high schools and col-
leges that are conceptually at the same level (Hox, 2002). 
 Th e Level 2, or “between cells,” model is as follows: 
 
   0( jk ) =   00  +  u 0  j  +  
 0  k  +   0  jk  , 
(8.2) 
 where   00  is the grand mean GPA for all students,  u 0  j  is the residual random eﬀ ect for high 
school  j (i.e., the contribution of high school  j averaged over all colleges),  
 0  k  is the residual 
random eﬀ ect for college  k (i.e., the contribution of college  k averaged over all high schools), 
and   0  jk  represents a residual random eﬀ ect for school-by-college cells. Th is latter component 
speciﬁ es a possible random eﬀ ect due to being in the two cross-classiﬁ ed units (high school 
 j and college  k ). As Raudenbush and Bryk (2002) note, however, without suﬃ  ciently large 
within-cell sizes, it is diﬃ  cult to separate the variance associated with students at Level 1 (i.e., 
student  i in cell  jk ) and the variance due to this particular Level 2 interaction eﬀ ect (i.e., high 
school–college  jk ). Th erefore, this potential random eﬀ ect is typically set to 0 (Beretvas, 2011; 
Raudenbush & Bryk, 2002). We follow that suggestion for specifying cross-classiﬁ ed models 
in this chapter. 
 After substitution (and removing the intra-cell variance component), we arrive at the inter-
cept-only model, 
 
  Y i  ( jk ) =   00  +  u 0  j  +  
 0  k  +  i( jk ), 
 (8.3) 
 where the outcome  Y i  ( jk ) is modeled with an overall intercept   00  and an error term each for high 
schools and colleges, and   i ( jk ) is the residual error term for student  i in the cross-classiﬁ cation of 
high school  j and college  k . Th e single-equation model in Equation 8.3 implies one ﬁ xed eﬀ ect 
(  00  ), two random Level 2 eﬀ ects ( u 0  j  , 
 0  k  ), and the within-cell (Level 1) residual (  i ( jk ) ). We note 
that because of the small data set for our illustration, we will assume a diagonal covariance matrix 
structure at Level 2 (i.e., no covariance between random eﬀ ects) in this model and subsequent 
models. 
 Deﬁ ning Models in IBM SPSS 
 IBM SPSS is easy to use for investigating a variety of cross-classiﬁ ed models. Compared to the 
models that we have deﬁ ned previously with nested hierarchical structures, it is relatively easy to 
deﬁ ne cross-classiﬁ ed structures. For a two-level cross-classiﬁ ed model, a random eﬀ ect across 

368  Cross-Classiﬁed Multilevel Models
high schools is referred to by using the “random” statements separately (i.e., RANDOM = high 
school identiﬁ cation code), and a random eﬀ ect across colleges is referred to in a similar manner 
(RANDOM = college identiﬁ cation code). Th is is because the cross-classiﬁ ed part of the model 
is “independent” (i.e., students can go to diﬀ erent high schools and colleges). Th e deﬁ nition of 
this type of cross-classiﬁ ed data structure is in contrast to the typical structure for a two-level 
nested model [(RANDOM = college code) and (RANDOM = college code*high school code)], 
where the statements would indicate that students are nested in high schools and colleges. Th is 
latter data set would only consider students who went to the same high school and college 
campus. 
 First, we can consider the GPA intercept and the decomposition of variance across the various 
cells in the analysis (  Table 8.6 ). Th e average mean GPA for campuses is 2.72.  
 Table 8.7  suggests that most variance in student cumulative GPA is due to diﬀ erences within 
individuals. As we might expect, college campus attended contributes more to the total variance 
in GPA than high school campus.  
 Since within Level 2 the high school and colleges are considered to be independent, we can 
simply add the estimated variances in the no-predictors model to obtain the total variance. We 
will estimate three intraunit variance components. Th e ﬁ rst is the intrarow correlation (i.e., high 
school), which represents the correlation between outcomes of any two students who attend 
the same high school but attend diﬀ erent colleges. Th e intraunit correlation for high schools 
( nschcode ) is therefore deﬁ ned as 
 
 
2
2
2
2
/ (
)
HS
HS
Student
HS
College








 
(8.4) 
 In this case, it can be calculated as 0.036/(0.331 + 0.036 + 0.142) = 0.036/0.509 = 0.071. Th is sug-
gests that 7.1% of the total variance in students’ cumulative GPA lies between the high schools 
they attended. 
 TABLE 8.6 Mean Student GPA 
Mean
Std. Error
df
Lower Bound Upper Bound
Student CUM_GPR
2.717
0.129
10.139
2.429
3.004
 TABLE 8.7 Estimates of Covariance Parameters a 
Parameter
Estimate
Std. Error
Wald Z
Sig.
95% Conﬁ dence Interval
Lower Bound
Upper Bound
Residual
0.331
0.011
29.252
.000
0.309
0.354
Intercept 
[subject = nschcode]
Variance
0.036
0.015
2.494
.013
0.017
0.080
Intercept 
[subject = campus]
Variance
0.142
0.073
1.956
.051
0.052
0.387
 a Dependent variable: CUM_GPR. 

Cross-Classiﬁ ed Multilevel Models  369
 Th e intraunit correlation for colleges is the correspondence between outcomes of any two 
students who attend the same college but who attend diﬀ erent high schools: 
 
 
2
2
2
2
/ (
)
College
College
Student
HS
College








 
(8.5) 
 Th is is estimated as 0.142/(0.331 + 0.036 + 0.142) = 0.142/0.509 = 0.279. Th is suggests that 
27.9% of the variation in students’ cumulative GPAs lies between the colleges they attend. Th e 
remaining variation represents diﬀ erences in GPA among students not accounted for by their 
high schools and colleges (roughly 65% of the variation). 
 Th ird, we can examine the correlation between outcomes of students who attended the same 
high school and college. Th is intracell component can be summarized as 
 
 
2
2
2
2
2
(
) / (
)
HS College
HS
College
Student
HS
College











 
(8.6) 
 In this case, it is estimated as (0.036 + 0.142)/(0.331 + 0.036 + 0.142) = 0.178/0.509 = 0.350. 
Taken together, the correspondence in outcomes between two students who attend the same 
high school and college is 0.35. In other words, about 35% of the variance in cumulative GPA 
can be attributed to attending the same high school and college campus. 
 Model 1.1: Adding a Set of Level 1 and Level 2 Predictors 
 Next, we can add a set of student (Level 1) predictors to the model. In this case, we will add  fe-
male (coded 1) and  lowSES  (code 1 = participation in federal free/reduced lunch program during 
high school, 0 = else). We grand-mean centered both variables and saved them in the data set. 
Th e Level 1 model is now 
 
  Y i  ( jk ) =   0( jk ) +   1( jk ) gmfemale i  ( jk ) +   2( jk ) gmlowSES i  ( jk ) +   i  ( jk ) , 
(8.7) 
 where   0( jk ) is the intercept,   1( jk ) and   2( jk ) are structural coeﬃ  cients, and   i ( jk ) represents the 
Level 1 residual (mean = 0,   2 ). Th e regression slopes for the individual-level variables can 
be allowed to vary across high schools and/or colleges (as we have shown in past examples). 
 At Level 2, we might add high school and college predictors that explain students’ grade 
point average. In this case,  gmlowSES_mean  is an aggregate measure of socioeconomic com-
position for the high school, and  gmfouryear  describes whether students were enrolled in a 
2-year (community college) or 4-year postsecondary institution. Th e Level 2 intercept model 
is now 
 
   0( jk ) =   00  +   01   gmlowSES_mean j  +   02   gmfouryear k  +  u 0  j  +  
 0  k  . 
(8.8) 
 Th e combined model with eight estimated parameters can then be written as follows: 
 Y i  ( jk ) =   00( jk ) +   01   gmloeSES_mean j  +   02   gmfouryear k  +   10   gmfemale i  ( jk ) 
 
+   20   gmlowSES i  ( jk ) +  u 0  j  +  
 0  k  +   i  ( jk ) . 
(8.9) 

370  Cross-Classiﬁed Multilevel Models
 Deﬁ ning Model 1.1 with IBM SPSS Menu Commands 
 Launch the IBM SPSS program 
application, and select the  ch8cross-
class1.sav data ﬁ le. 
  1. Go to the toolbar and select 
ANALYZE, MIXED MOD-
ELS, LINEAR. 
 Th is command enables access to 
the  Linear Mixed Models: Specify 
Subjects and Repeated dialog box. 
 2. Th e  Linear Mixed Models: Specify Subjects and 
Repeated screen displays options for deﬁ ning 
variables as subjects, repeated observations, and 
type of covariance structure in a model. 
 A subject is an observational unit that may be 
independent of other subjects. For this model, 
we will designate two subject identiﬁ ers for the 
model ( nschcode , and  campus ). Click to select 
 nschcode and  campus , and then click the right-
arrow button to move the variables into the 
 Subjects box. 
 Click the CONTINUE button to display the 
 Linear Mixed Models dialog box. 

Cross-Classiﬁ ed Multilevel Models  371
  3. Th e  Linear Mixed Models main screen 
enables specifying the dependent variable, 
factors, and covariates, as well as access-
ing the dialog boxes for deﬁ ning  Fixed and 
 Random eﬀ ects, and options for  Estimation , 
 Statistics ,  EM Means , and  Save. 
 
 a. For this model, we will use  CUM_ GPR 
as the dependent variable. Click to 
select  CUM_ GPR  from the left column 
listing, and then click the right-arrow 
button to transfer the variable into the 
 Dependent Variable box. 
 
 b. We will designate four predictor vari-
ables to be used in the model ( gmfemale , 
 gmlowses ,  gmlowSES_mean , and  gmfour-
year ). Click to select the four variables, and then “drag” them to  Covariate(s) box. To facilitate 
reading of the output tables, we will change the sequence of the variables by dragging individ-
ual variables into the following order (see insert):  gmfouryear ,  gmlowSES_mean ,  gmlowses , and 
 gmfemale. 
 Note:  An alternate method for arranging the variables in the desired sequence order is to select variables 
individually and then use the right-arrow button to move each variable into the  Covariate(s) box. 
 We may now proceed to deﬁ ne ﬁ xed eﬀ ects for the variables. 
 Click the FIXED button to access the  Linear Mixed Models: Fixed Eﬀ ects dialog box. 
 
 4a. Within the  Linear 
Mixed Models: Fixed 
Eﬀ ects dialog box, 
click the pull-down 
menu to change the 
factorial setting to 
 Main Eﬀ ects . 
 
 b. Click to select the 
four variables from 
the  Factors and Co-
variates box. Th en 
click the ADD 
button to move the 
variables into the 
 Model box. 
 
 c. Note on lower left 
of the screen that 
the intercept and 
the sum of squares 
( Type III ) are the 
default settings. 
 Click the CONTINUE button to return to the  Linear Mixed Models dialog box. 
 We will now add random eﬀ ects to this model. 
 Click the RANDOM button to access the  Linear Mixed Models: Random Eﬀ ects dialog box. 

372  Cross-Classiﬁed Multilevel Models
  5. Th e  Linear Mixed 
Models: Random 
Eﬀ ects  displays the 
 Random Eﬀ ect 1 of 
1 screen, which is 
the default when 
creating a model 
for the ﬁ rst time. 
Th e random-
eﬀ ects screen 
allows specifying 
random eﬀ ects, 
interactions, inter-
cept terms, and 
subject groupings. 
 
 a. Begin by speci-
fying the cova-
riance structure 
from the 
default variance 
components 
(VC) to scaled 
identity. Click 
the pull-down 
menu and select  Scaled Identity (ID). 
 Th e  Scaled Identity  structure has constant variance and assumes that no correlation occurs between ele-
ments (IBM Corporation, 2012). 
 
 b. We want the intercept to be included in the model, so click  Include intercept . 
 
 c. Th e  Subject Groupings box displays the  nschcode and  campus variables that were speciﬁ ed as a 
subject variable in the  Specify Subjects and Repeated dialog box show in step 2. We will specify 
 nschcode  as the subject for the random-eﬀ ects Level 1 part of this model. Click to select  nschcode , 
and then click the right-arrow button to move the variable into the  Combinations box. 
 
 d. At the top-right section of the window, click the NEXT button to access the  Random Eﬀ ect 2 
of 2 screen. 
 Note: Th e NEXT button may not work in earlier or unpatched versions of IBM SPSS when creating 
multilevel models with random intercepts. An update issued by IBM SPSS for software Version 19 ad-
dressed the problem, and Version 20 appears to have resolved the issue. A workaround to activating the 
NEXT button is to either (a) add or reenter a subject variable into the  Combinations  box or (b) add a 
variable from the  Factors and Covariates column to the  Model  box and then remove it before proceeding 
to the  Random Eﬀ ect 2 of 2 screen. 

Cross-Classiﬁ ed Multilevel Models  373
 Th e  Random Eﬀ ect 2 of 2 
screen display is similar 
to the ﬁ rst screen and 
requires the following 
changes. 
 
 e. Change the 
covariance type 
by clicking on the 
pull-down menu 
and selecting 
 Scaled Identity. 
 
 f. Click to select 
the  Include inter-
cept  option. 
 
 g. We will specify 
 campus as the 
subject for the 
random-eﬀ ects 
Level 2 part of 
this model. Click 
to select  campus , 
and then click 
the right-arrow 
button to move the variable into the  Combinations box. 
 Click the CONTINUE button to return to the  Linear Mixed Models dialog box. 
  6. Click the ESTIMATION button to 
access the  Linear Mixed Models: Esti-
mation dialog box, which displays two 
estimation method choices: maximum 
likelihood (ML) or restricted maxi-
mum likelihood (REML). 
 In this chapter, we will use the default set-
ting of REML to estimate the models. 
 Click the CONTINUE button to return to 
the  Linear Mixed Models dialog box. 

374  Cross-Classiﬁed Multilevel Models
  7. In the  Linear Mixed 
Models dialog box, 
click the STATIS-
TICS button to ac-
cess the  Linear Mixed 
Models: Statistics 
dialog box. 
 Click and select the fol-
lowing three statistics to 
be included in the output: 
 Parameter estimates, Tests 
for covariance parameters , 
and  Covariances of random 
eﬀ ects . 
 Click the CONTINUE 
button to return to the 
 Linear Mixed Models dia-
log box. 
  8. Finally, in the  Linear 
Mixed Models dialog 
box, click the OK but-
ton to run the model. 
 Interpreting the Output From Model 1.1 
 From the following ﬁ xed-eﬀ ects table (  Table 8.8  ), we can see that of the Level 1 eﬀ ects, females 
have signiﬁ cantly higher cumulative GPAs (  = 0.332,  p < .01) than males; however, individual 
SES status does not aﬀ ect cumulative GPA. At Level 2, aggregate high school social composi-
tion is signiﬁ cantly and negatively related to cumulative GPA (  = ‒1.220,  p < .01). Institutional 
type, however, is not related to cumulative GPA (  = 0.138,  p = .655). 

Cross-Classiﬁ ed Multilevel Models  375
 The variance component table (  Table 8.9  ) suggests that there is still significant variance 
in intercepts across high schools ( p < .01) left to explain after the set of predictors was en-
tered into the model. There is also still variance across colleges (Wald  Z = 1.905, one-tailed 
 p = .0285).  
 Model 1.2: Investigating a Random Slope 
 Level 2 high school or college variables can also be used to explain variation in Level 1 slopes. 
Th e Level 2 model can be expanded to include the random eﬀ ect of gender on cumulative college 
GPA across high schools ( u 1  j  ) and colleges ( 
 1  k  ). We ﬁ rst allow the female-GPA slope to vary 
randomly across both high schools and colleges as follows: 
 
   1( jk ) =  10  +  u 1  j  +  
 1  k  , 
(8.10) 
 where   10  is the intercept,  u 1  j  is the residual high school eﬀ ect, and  
 1  k  is the residual college eﬀ ect. 
In this model, however, we do not attempt to explain this variation. Th e combined model (with 
10 parameters) will then be the following: 
 Y i  ( jk ) =   00( jk ) +   01   gmlowSES_mean j  +   02  gmfouryear k  +   10  gmfemale i  ( jk ) +   20   gmlowSES i  ( jk ) 
 
+  u 1  j  gmfemalei(jk) +  
 1  k  femalei(jk) +  u 0  j  +  
 0  k  +   i  ( jk ) . 
(8.11) 
 TABLE 8.8 Estimates of Fixed Effects a 
Parameter
Estimate
Std. Error
df
t
Sig.
95% Conﬁ dence Interval
Lower Bound Upper Bound
Intercept
2.682
0.142
9.070 18.943
.000
2.363
3.002
gmfouryear
0.138
0.298
7.933
0.465
.655
−0.549
0.825
gmlowses_mean −1.220
0.371
32.478 −3.286
.002
−1.977
−0.464
gmlowses
0.017
0.037
1,728.687
0.472
.637
0.055
0.090
gmfemale
0.332
0.028
1,735.674 11.905
.000
0.277
0.386
 a Dependent variable: CUM_GPR. 
 TABLE 8.9 Estimates of Covariance Parameters a 
Parameter
Estimate
Std. Error
Wald Z
Sig.
95% Conﬁ dence Interval
Lower Bound Upper Bound
Residual
0.305
0.010
29.300
.000
0.285
0.326
Intercept [subject = nschcode]
Variance
0.031
0.012
2.602
.009
0.015
0.066
Intercept [subject = campus]
Variance
0.177
0.093
1.905
.057
0.063
0.496
 a Dependent variable: CUM_GPR. 

376  Cross-Classiﬁed Multilevel Models
 Deﬁ ning Model 1.2 with IBM SPSS Menu Commands 
 Note: Settings will default to those 
used in Model 1.1. 
 1. Go to the toolbar and 
select ANALYZE, 
MIXED MODELS, 
LINEAR. 
 Th is command enables 
access to the  Linear 
Mixed Models: Specify 
Subjects and Repeated 
dialog box. 
  2. Th e  Linear Mixed Models: Specify Subjects and 
Repeated screen displays the default settings 
from the prior model. 
 Click the CONTINUE button to display the  Linear 
Mixed Models dialog box. 
 We will change the random-eﬀ ects covariance type, 
so from the  Linear Mixed Models main screen, click 
the RANDOM button to access the  Linear Mixed 
Models: Random Eﬀ ects dialog box. 

Cross-Classiﬁ ed Multilevel Models  377
  3. Th e  Random Ef-
fect 2 of 2 screen is 
displayed ﬁ rst as it 
was the last dialog 
box used in the prior 
model. 
 
 a. Change the 
covariance type 
by clicking the 
pull-down menu 
and selecting: 
 Diagonal . 
 Th e  Diagonal  covariance 
type has heterogeneous 
variances and zero correla-
tion between the elements 
(IBM Corporation, 2012). 
 
 b. Change the 
default  Factorial 
setting by click-
ing the pull-down 
menu to select 
 Main Eﬀ ects. 
 
 c. Click to select  gmfemale , and then click the ADD button to move the variable into the  Model 
box. 
 
 d. Click the PREVIOUS button to access the  Random Eﬀ ect 1 of 1 screen. 
 
 e. From the  Ran-
dom Eﬀ ect 1 of 2 
screen, change the 
covariance type 
by clicking the 
pull-down menu 
and selecting 
 Diagonal. 
 
 f. Note the setting 
is  Main Eﬀ ects. 
 
 g. Click to select 
 gmfemale , and 
then click the 
ADD button to 
move the variable 
into the  Model 
box. 
 Click the CONTINUE 
button to return to the 
 Linear Mixed Models 
dialog box. 

378  Cross-Classiﬁed Multilevel Models
 4. Finally, in the  Linear Mixed 
Models dialog box, click the OK 
button to run the model. 
 Interpreting the Output From Model 1.2 
 Th e variance components table ( Table 8.10  ) suggests that the random slope ( gmfemale ) varies 
across high schools (Wald  Z = 2.052, one-tailed  p = .02). However, the female–cumulative GPA 
slope does not vary across campuses (Wald  Z = 1.16, one-tailed  p = .124). One explanation for 
the observed lack of variation across colleges may be the small sample size.  
 Model 1.3: Explaining Variation Between Variables 
 Since the Level 1 slope varies across high school cells, for demonstration purposes, we will pro-
pose that a Level 2 variable explains variation in the relationship between female and cumulative 
GPA. We will propose that the social composition of students’ high schools moderates (enhances 
or diminishes) the relationship between gender and cumulative GPA. Th e proposed cross-level 
interaction would look like this: 
 
   1( jk ) =   10  +  11  gmlowSES_mean j  *  gmfemale i  ( jk ) +  u 1  j  . 
(8.12) 
 Equation 8.12 assumes that the random slope varies across high schools ( u 1  j  ) but not colleges 
(i.e.,  
 1  k  from Eq. 8.10 has been removed from the equation). Th is cross-level interaction can be 
interpreted as the eﬀ ect of gender on attainment when the eﬀ ect of high school social compo-
sition is controlled. For this model, in the intercept equation (see Eq. 8.8) we will remove the 
 TABLE 8.10 Estimates of Covariance Parameters a 
Parameter
Estimate Std. Error Wald Z
Sig.
95% Conﬁ dence Interval
Lower Bound Upper Bound
Residual
0.293
0.010
28.863 .000
0.274
0.314
Intercept + gmfemale Var: Intercept
0.036
0.013
2.734 .006
0.017
0.073
[subject = nschcode]
Var: gmfemale
0.040
0.020
2.052 .040
0.016
0.105
Intercept + gmfemale 
[subject = campus]
Var: Intercept
0.194
0.102
1.908 .056
0.069
0.542
Var: gmfemale
0.038
0.033
1.155 .248
0.007
0.208
  a Dependent variable: CUM_GPR. 

Cross-Classiﬁ ed Multilevel Models  379
 gmfouryear variable since it was not signiﬁ cant in the previous model. Th e combined model with 
nine estimated parameters will then be as follows: 
 Y i  ( jk ) =   00( jk ) +   01   gmlowSES_mean j  +  gmfemale i  ( jk ) +   11   gmlowSES_mean j  *  gmfemale i  ( jk ) + 
 
  20   gmlowSES i  ( jk ) +  u 1  ji  gmfemale +  u 0  j  +  
 0  k  +   i  ( jk ) . 
(8.13) 
 Deﬁ ning Model 1.3 with IBM SPSS Menu Commands 
 Note: Settings will default to those used 
in Model 1.2. 
  1. Go to the toolbar and select 
ANALYZE, MIXED MODELS, 
LINEAR. 
 Th is command enables access to the 
 Linear Mixed Models: Specify Subjects and 
Repeated dialog box. 
  2. Th e  Linear Mixed Models: Specify Subjects and 
Repeated screen displays the default settings 
from the prior model. 
 Click the CONTINUE button to display the  Lin-
ear Mixed Models dialog box. 

380  Cross-Classiﬁed Multilevel Models
  3. From the  Linear Mixed Models main 
screen we will remove a variable from 
the analysis. Click to select  gmfour-
year , and then click the left-arrow 
button to remove the variable. 
 We will now add a ﬁ xed eﬀ ect to the 
model, so click the FIXED button to ac-
cess the  Fixed Eﬀ ects main screen. 
 One cross-level interaction (or nested 
terms) will be created and added to the 
model:  gmlowSES_mean and  gmfemale . 
Th is interaction will tell us if social compo-
sition of students’ high schools moderates 
(enhances or diminishes) the relationship between gender and cumulative GPA. 
 Add Interaction to 
Model 1.3:  gmlowSES_
mean*gmfemale 
 
 4a. Click to select 
 Build nested 
terms . 
 
 b. Now click 
to select the 
variable  gm-
lowSES_mean 
from the 
 Factors and 
Covariates box. 
 
 c. Click the 
arrow but-
ton below the 
 Factors and 
Covariates box. 
Th is moves 
 gmlowSES_
mean into the  Build Term box to create a cross-level interaction by linking variables and terms. 
 
 d. Next, click the BY* button, which will insert the computation command symbol: 
 gmlowSES_mean* . 
 
 e. Click to select  gmfemale  from the  Factors and Covariates box. 
 
 f. Click the arrow button below the  Factors and Covariates box to move  gmfemale into the  Build 
Term box and complete the interaction term:  gmlowSES_mean*gmfemale . 
 
 g. Click the ADD button to transfer the interaction into the  Model box. 
 Click the CONTINUE button to return to the  Linear Mixed Models dialog box. Th en click the  RAN
DOM button to access the random-eﬀ ects main screen. 

Cross-Classiﬁ ed Multilevel Models  381
  5. Th e  Random Ef-
fect 1 of 2 screen 
is displayed ﬁ rst, 
as it was the last 
dialog box used in 
the prior model. 
 
 a. Click the 
NEXT button 
to access the 
 Random Eﬀ ect 
2 of 2 screen. 
 
 b. Change the 
covariance type 
by clicking 
the pull-down 
menu and 
selecting  Scaled 
Identity. 
 Th e  Scaled Identity 
structure has constant 
variance and assumes 
that no correlation oc-
curs between elements 
(IBM Corporation, 
2012). 
 
 c. We will 
remove  gmfe-
male from the 
model by click-
ing to select the variable and then clicking the REMOVE button. 
 Click the CONTINUE button to return to the  Linear Mixed Models dialog box. 
  6. Finally, in the  Linear Mixed Models 
dialog box, click the OK button to 
run the model. 

382  Cross-Classiﬁed Multilevel Models
 Interpreting the Output From Model 1.3 
 Th e ﬁ xed-eﬀ ects table (  Table 8.11  ) suggests that the intercept model remains about the same as 
before. Regarding the model to explain random slopes, the positive Level 1 female–cumulative 
GPA slope is moderated by high school social composition (  = ‒1.400,  p < .01). Th is ﬁ nding 
is consistent with factor*covariate interactions, suggesting that slopes diﬀ er across levels of the 
factor. In this case, we can interpret the result as the impact of gender on cumulative GPA when 
the social composition in students’ high school is held constant. Th is indicates that the impact 
of the female slope (  = 0.28,  p < .05) on cumulative GPA also depends on high school com-
position (  = ‒1.40,  p < .05). Combining the coeﬃ  cients suggests that the female coeﬃ  cient is 
‒1.12 (–1.40 + 0.28 = ‒1.12), when low social composition is high. Th erefore, when high school 
social composition is increased by a unit (i.e., from the grand mean of 0), the advantage in cu-
mulative GPA for females reported in the table (i.e., 0.28) actually disappears. Of course, this 
type of social composition variable is likely a proxy for more complex relationships in students’ 
academic preparation for doing postsecondary work that might exist across high school settings 
within the state.  
 Th e variance component table (  Table 8.12  ) suggests that there is still intercept variance (aver-
age GPA) to be explained between high schools (Wald  Z = 2.663, one-tailed  p < .01) and col-
leges (Wald  Z = 2.006, one-tailed  p < .05). After adding the random slope, there is still signiﬁ cant 
variance to be explained in the gender-GPA slopes across high schools (Wald  Z = 1.601, one-
tailed  p = .0495). 
 TABLE 8.11 Estimates of Fixed Effects a 
Parameter
Estimate
Std. Error
df
t
Sig.
95% Conﬁ dence Interval
Lower Bound Upper Bound
Intercept
2.677
0.140
10.201
19.125
.000
2.366
2.989
gmlowses_mean
−1.201
0.384
32.258
−3.131
.004
−1.982
−0.420
gmlowses
0.014
0.037
1,718.681
.394
.693
−0.058
0.086
gmfemale
0.275
0.042
25.535
6.496
.000
0.188
0.362
gmlowses_mean * gmfemale
−1.400
0.428
26.800
−3.270
.003
−2.279
−0.521
 a Dependent variable: CUM_GPR. 
 TABLE 8.12 Estimates of Covariance Parameters a 
Parameter
Estimate
Std. Error
Wald Z
Sig.
95% Conﬁ dence Interval
Lower Bound Upper Bound
Residual
0.297
0.010
29.017
.000
0.278
0.318
Intercept + gmfemale
Var: Intercept
0.034
0.013
2.663
.008
0.016
0.071
[subject = nschcode]
Var: gmfemale
0.020
0.013
1.601
.109
0.006
0.070
Intercept [subject = 
campus]
Variance
0.172
0.086
2.006
.045
0.065
0.456
 a Dependent variable: CUM_GPR. 

Cross-Classiﬁ ed Multilevel Models  383
 Developing a Cross-Classiﬁ ed Teacher Effectiveness Model 
 Our second example considers the eﬀ ects of teacher eﬀ ectiveness on students’ outcomes in math. 
It is similar to our example in Chapter 4, except this time we examine the eﬀ ects of successive 
teachers’ eﬀ ectiveness on students’ current math scores. Multilevel models hold promise for ex-
amining the contributions of successive teachers and schools to student learning because they 
make better use of the available information than more simpliﬁ ed analyses (Th um, 2003). More 
speciﬁ cally, over time, students are clustered in classrooms with teachers of diﬀ ering skills and 
eﬀ ectiveness, and in schools with diﬀ ering community expectations, teacher skills, and academic 
processes. School factors can moderate learning conditions within classrooms (e.g., prolonged 
grouping assignments, diﬀ erential access to curriculum, and inconsistent academic experiences 
for students within a particular grade level). Students, therefore, share similarities with peers 
within these hierarchical social groupings. Th e sum of these varied learning contexts enhances or 
diminishes students’ academic outcomes in direct and indirect ways. 
 The Data Structure and Model 
 In this example, we use a subset of student data ( N = 4,136) cross-classiﬁ ed by two successive 
classrooms at Level 2 (i.e., identiﬁ ed by 324 Year 1 teachers and 259 Year 2 teachers). At Level 
3, the students attend 81 elementary schools. Th e data structure is diﬀ erent from the three-level 
model in Chapter 4 (i.e., students nested within classrooms within schools) because at the class-
room level the data are “cross-classiﬁ ed”; that is, any two students in the cohort can have diﬀ erent 
combinations of Year 1 and Year 2 teachers (i.e., both teachers in common, one teacher in com-
mon, or no teachers in common). Th e variables are summarized in  Table 8.13 . 
 TABLE 8.13  Data Deﬁ nition of  ch8crossclass2.sav ( N = 4,136) 
Variable
Levela
Description
Values
Measurement
schcode
School
School identiﬁ er (40 schools).
Integer
Ordinal
teach1id Class
Identiﬁ er for students‘ ﬁ rst-year classroom teacher 
(324 teachers).
Integer
Scale
teach2id Class
Identiﬁ er for students‘ second-year classroom teacher 
(259 teachers).
Integer
Scale
math1
Individual Student math achievement scores from ﬁ rst-year classroom.
499 to 775
Scale
math2
Individual Student math achievement scores from second-year 
classroom.
523 to 770
Scale
female
Individual Demographic predictor variable representing students gender. 0 = Male1 = Female Scale
lowses
Individual Dichotomous variable representing student socioeconomic 
status.
0 = Did Not 
Participate,1 = 
Participant in Federal 
Free/Reduced Lunch 
Program 
Scale
Zmath1
Individual Standardized variable measuring math achievement.
−2.41 to 4.33
Scale
effmath1 Class
Predictor variable measuring ﬁ rst-year teacher effectiveness 
in classroom1 on a scale of 0 to 10 in terms of their 
classroom effectiveness in facilitating student learning.
(0, 2, 4, 6, 8, 10)
Scale
effmath2 Class
Predictor variable measuring ﬁ rst-year teacher effectiveness 
in classroom 2 on a scale of 0 to 10 in terms of their 
classroom effectiveness in facilitating student learning.
(0, 2, 4, 5, 6, 7, 8, 
10)
Scale
schqual
School
Variable measuring the quality of the schools educational 
processes (e.g., leadership, academic expectations, and 
climate).
−4.8 to 1.8
Scale
 a Individual = Level 1; Class = Level 2; School = Level 3.   

384  Cross-Classiﬁed Multilevel Models
 Th e cross-classiﬁ cation of students by their previous and current teachers facilitates the ac-
curacy of estimating the eﬀ ects of successive teachers on student outcomes within the same 
model. One limitation to keep in mind about cross-classiﬁ ed models in examining the eﬀ ects 
of successive teachers, however, is that the model assumes that the eﬀ ects of previous teachers 
do not diminish (i.e., since each classroom contributes independently) in explaining the current 
achievement level (McCaﬀ rey, Lockwood, Koretz, Louis, & Hamilton, 2004). Th e data structure 
in this example is similar to that in  Figure 8.1 . 
 Figure 8.1  indicates Student 1 and Student 2 have the same ﬁ rst-year teacher and second-year 
teacher. Students 3 and 4 have the same ﬁ rst-year teacher as the previous two students but dif-
ferent second-year teachers. Students 5 and 6 have diﬀ erent ﬁ rst-year and second-year teachers 
from each other, but Student 5 has the same second-year teacher as Student 4. All six of the 
students (with diﬀ erent conﬁ gurations of ﬁ rst and second teachers) attend the same school (1). 
Student 7 begins a diﬀ erent school (2) and combination of teachers. Because we are focusing on 
two measurement occasions, this approach is similar to a type of gain score achievement model 
or a model that uses previous achievement as a control variable. 
 We reiterate that for cross-classiﬁ ed models, each RANDOM command identiﬁ es a separate 
cell or level. Th eir order does not matter. With cross-classiﬁ ed data structures, we need to use the 
unique Teacher 1 and Teacher 2 identiﬁ ers at Level 2 and not recode (i.e., rank) them within each 
school (1, …,  n k  ). Th e use of unique teacher identiﬁ ers generally will result in a longer computing 
time needed for estimating cross-classiﬁ ed models compared with similar nested multilevel mod-
els. For this example, we reduced the student part of the data set substantially (i.e., from more than 
9,000 students to 4,136 students) and also reduced the number of Year 1 and Year 2 teachers and 
schools in order to decrease the time it takes to run the model from well over 1 hour to the present 
4 to 5 minutes (on the ﬁ nal models). We note that the cost of reducing the data for demonstrating 
the approach, however, is a model that is a bit more challenging to ﬁ t optimally in terms of the our 
substantive goals (e.g., the variability in intercepts and slopes across units is reduced). 
 Research Questions 
 In this cross-classiﬁ ed example, we can address a number of diﬀ erent types of research questions. 
For example, we might ﬁ rst consider: How much variance in students’ math achievement is due 
to their previous and current classroom settings? In examining this question, we can consider 
whether the intercepts describing levels of Year 2 student achievement vary across classrooms 
and schools. A second question we might investigate is the following: Does the eﬀ ectiveness of 
 FIGURE 8.1  Horizontal data matrix for cross-classiﬁ cation analysis in IBM SPSS.

Cross-Classiﬁ ed Multilevel Models  385
successive teachers have a measurable eﬀ ect on students’ Year 2 achievement levels? Subsequently, 
we could also investigate whether teacher eﬀ ectiveness varies across schools. Th ird, we might ask: 
Does a particular variable (or set) explain possible variation in teacher eﬀ ectiveness? 
 Model 2.1: Intercept-Only Model (Null) 
 We will begin with an intercept-only model. Th is model represents the average achievement 
score across all individuals and occasions. It provides a preliminary estimate of the repeated mea-
sures variance, the classroom-level variance, and the school-level variance. Within individuals 
(Level 1), the model is the following: 
 
  Y i  ( j 1  j 2) k  =  π 0( j 1  j 2) k  +   i  ( j 1  j 2) k  , 
(8.14) 
 where  Y i  ( j 1  j 2) k  is the math outcome for individual  i cross-classiﬁ ed in classrooms  j 1  and  j 2  in school 
 k , π 0( j 1  j 2) k  is the intercept, and   i ( j 1  j 2) k  is the residual term for individual-level model. 
 At Level 2, the intercept model is 
 
  π 0( j 1  j 2) k  =   00  k  +  u j  1  k  +  u j  2  k  , 
(8.15) 
 where   00  k  is the intercept,  u j  1  k  and  u j  2  k  are residuals associated with Classroom 1 and Classroom 
2 in school  k . 
 At Level 3, the basic model is 
 
   00  k  =   000  +  
 00  k  . 
(8.16) 
 Th rough substitution, the basic random-intercept model can be speciﬁ ed as follows: 
 
  Y i  ( j 1  j 2) k  =   000  +   00  k  +  u j  1  k  +  u j  2  k  +   i  ( j 1  j 2) k  , 
(8.17) 
 where   000  is the grand mean of achievement for schools, and  v ,  u , and  represent residuals (i.e., 
normally and independently distributed in the population with an expected mean equal to 0 and 
some variance) associated with schools, classrooms, and students, respectively. For demonstra-
tion purposes, we note that we assume a scaled identity covariance structure at Level 2, with no 
covariance between random eﬀ ects at that level. Equation 8.17 therefore implies ﬁ ve parameters 
that must be estimated (i.e., four variance components and one ﬁ xed eﬀ ect). We can conﬁ rm the 
ﬁ ve estimated eﬀ ects from the printout from Model 2.1 (  Table 8.14 ). 
 TABLE 8.14  Model Dimension a 
Number of 
Levels
Covariance 
Structure
Number of 
Parameters
Subject 
Variables
Fixed Effects
Intercept
1
1
Random Effects
Intercept
1
Identity
1
schcode
Intercept
1
Identity
1
teach2id
Intercept
1
Identity
1
teach1id
Residual
1
Total
4
5
 a Dependent variable: math2. 

386  Cross-Classiﬁed Multilevel Models
 Deﬁ ning Model 2.1 (Null) with IBM SPSS Menu Commands 
 Launch the IBM SPSS program 
application, and select the  ch8cross-
class2.sav data ﬁ le. 
  1. Go to the toolbar and select 
ANALYZE, MIXED MOD-
ELS, LINEAR. 
 Th is command enables access to 
the  Linear Mixed Models: Specify 
Subjects and Repeated dialog box. 
  2. Th e  Linear Mixed Models: Specify Subjects and 
Repeated screen displays options for deﬁ ning 
variables as subjects, repeated observations, and 
type of covariance structure in a model. 
 A subject is an observational unit that may be 
independent of other subjects. For this model, we 
will designate three subject identiﬁ ers for the model 
( schcode ,  teach1id ,  teach2id ). Click to select  schcode , 
 teach1id , and  teach2id , and then click the right-arrow 
button to move the variables into the  Subjects box. 
 Click the CONTINUE button to display the  Lin-
ear Mixed Models dialog box. 

Cross-Classiﬁ ed Multilevel Models  387
  3. Th e  Linear Mixed Models main screen en-
ables specifying the dependent variable, 
factors, and covariates, as well as access-
ing dialog boxes for deﬁ ning  Fixed and 
 Random eﬀ ects, and options for  Estima-
tion ,  Statistics ,  EM Means , and  Save. 
 For this model, we will use  math2 as the 
dependent variable. Click to select  math2 from 
the left column listing, and then click the 
right-arrow button to transfer the variable into 
the  Dependent Variable box. 
 We will now add random eﬀ ects to this model. 
Click the RANDOM button to access the  Linear Mixed Models: Random Eﬀ ects dialog box. 
  4. Th e  Linear Mixed 
Models: Random Eﬀ ects 
displays the  Random Ef-
fect 1 of 1 screen, which is 
the default when creat-
ing a model for the ﬁ rst 
time. Th e random-eﬀ ects 
screen allows specifying 
random eﬀ ects, interac-
tions, intercept terms, 
and subject groupings. 
 
 a. Begin by specifying 
the covariance struc-
ture from the default 
(VC) to scaled iden-
tity. Click the pull-
down menu and select 
 Scaled Identity  (ID). 
 Th e scaled identity structure 
has constant variance and 
assumes that no correlation 
occurs between elements (IBM Corporation, 2012). 
 
 b. We want the intercept to be included in the model, so click  Include intercept . 
 
 c. Th e  Subject Groupings box displays the  schcode ,  teach1id , and  teach2id variables that were speci-
ﬁ ed as a subject variable in the  Specify Subjects and Repeated dialog box shown in step 2. We will 
specify  schcode as the subject for the random-eﬀ ects Level 3 part of this model. Click to select 
 schcode , and then click the right-arrow button to move the variable into the  Combinations box. 
 
 d. At the top-right section of the window, click the NEXT button to access the  Random Eﬀ ect 2 
of 2 screen. 
 Note: Th e NEXT button may not work in earlier or unpatched versions of IBM SPSS when creating 
multilevel models with random intercepts. An update issued by IBM SPSS for software Version 19 ad-
dressed the problem, and Version 20 appears to have resolved the issue. A workaround to activating the 
NEXT button is to either (a) add or reenter a subject variable into the  Combinations  box or (b) add a 
variable from the  Factors and Covariates column to the  Model  box and then remove it before proceeding 
to the  Random Eﬀ ect 2 of 2 screen. 

388  Cross-Classiﬁed Multilevel Models
 Th e  Random Eﬀ ect 2 of 2 screen 
display is similar to the ﬁ rst 
screen and requires the following 
changes. 
 
 e. Change the covariance 
type by clicking on the 
pull-down menu and 
selecting  Scaled Identity. 
 
 f. Click to select the  Include 
intercept option. 
 
 g. We will specify  teach2id 
as the subject for the 
random-eﬀ ects Level 2 
part of this model. Click 
to select  teach2id , and 
then click the right-arrow 
button to move the vari-
able into the  Combina-
tions box. 
 
 h. At the top-right section 
of the window, click the 
NEXT button to access the  Random Eﬀ ect 3 of 3 screen. 
 Note: Th e NEXT button may not work in earlier or unpatched versions of IBM SPSS when creating 
multilevel models with random intercepts. An update issued by IBM SPSS for software Version 19 ad-
dressed the problem, and Version 20 appears to have resolved the issue. A workaround to activating the 
NEXT button is to either (a) add or reenter a subject variable into the  Combinations  box or (b) add a 
variable from the  Factors and Covariates column to the  Model  box and then remove it before proceeding 
to the  Random Eﬀ ect 3 of 3 screen. 
 Th e  Random Eﬀ ect 3 of 3 screen 
display is similar to the prior 
screen and requires the follow-
ing changes. 
 
 i. Change the covariance 
type by clicking on the 
pull-down menu and 
selecting  Scaled Identity. 
 
 j. Click to select the 
 Include intercept option. 
 
 k. We will specify  teach1id 
as the subject for the 
random-eﬀ ects Level 
3 part of this model. 
Click to select  teach1id , 
and then click the 
right-arrow button to 
move the variable into 
the  Combinations box. 
 Click the CONTINUE button 
to return to the  Linear Mixed 
Models dialog box. 

Cross-Classiﬁ ed Multilevel Models  389
  5. Click the ESTIMATION button to 
access the  Linear Mixed Models: Es-
timation dialog box, which displays 
two estimation method choices: ML 
or REML. 
 In this chapter, we will use the default 
setting of REML to estimate the models. 
 Click the CONTINUE button to return 
to the  Linear Mixed Models dialog box. 
  6. In the  Linear Mixed Models dialog 
box, click the STATISTICS button 
to access the  Linear Mixed Models: 
Statistics dialog box. 
 Click and select the following three 
statistics to be included in the output: 
 Parameter estimates, Tests for covariance 
parameters , and  Covariances of random 
eﬀ ects . 
 Click the CONTINUE button to return 
to the  Linear Mixed Models dialog box. 

390  Cross-Classiﬁed Multilevel Models
  7. Finally, in the  Linear Mixed Models dialog 
box, click the OK button to run the model. 
 Interpreting Output From Model 2.1 (Null) 
 Our ﬁ rst model facilitates examining the distribution of math achievement in the data ﬁ le with 
4,136 students. Th e ﬁ xed-eﬀ ect part of the model (  Table 8.15  ) includes only the Level 3 inter-
cept (or grand mean) for Year 2 math. Th e grand mean is 654.131 ( SE = 2.047). 
 Th e variance components table (  Table 8.16  ) suggests that most of the variance is due to diﬀ er-
ences in individuals (residual = 1,482.261), with about 14.7% of the total variation due to schools 
(i.e., 266.734/1,810.801 = 0.147), and trivial amounts of variance (about 2%) due to Teacher 2 
and Teacher 1 in this subset of the data. As a comparison, in the full data set, the initial estimates 
for Classroom 1 variance was 4%, and for Classroom 2 variance, it was 7%.  
TABLE 8.15 Estimates of Fixed Effectsa
Parameter
Estimate
Std. Error
df
t
Sig.
95% Conﬁ dence Interval
Lower Bound Upper Bound
Intercept
654.131
2.047
77.947
319.509
.000
650.055
658.207
 a Dependent variable: math2.   
 TABLE 8.16 Estimates of Covariance Parameters a 
Parameter
Estimate
Std. Error
Wald Z
Sig.
95% Conﬁ dence Interval
Lower Bound Upper Bound
Residual
1,482.261
34.592
42.850
.000
1,415.989
1,551.635
Intercept 
[subject = schcode]
Variance
266.734
52.720
5.059
.000
181.066
392.934
Intercept 
[subject = teach2id]
Variance
35.184
15.158
2.321
.020
15.123
81.858
Intercept 
[subject = teach1id]
Variance
26.622
12.915
2.061
.039
10.288
68.893
 a Dependent variable: math2. 
 Model 2.2: Deﬁ ning the Cross-Classiﬁ ed Model with Previous Achievement 
 For Model 2.2, we will add a covariate for previous achievement with a ﬁ xed (i.e., the same) coeﬃ  cient 
for all persons; that is, we will ﬁ rst treat the eﬀ ect as ﬁ xed across classrooms and schools. In deﬁ ning 
the Level 1 model, we now account for previous achievement at Level 1. Th e Level 1 model is now 
 
  Y i  ( j 1  j 2  k ) =  π 0( j 1  j 2) k  +  π 1( j 1  j 2) k  Zmath1  i ( j 1  j 2) k  +   i  ( j 1  j 2) k  , 
(8.18) 

Cross-Classiﬁ ed Multilevel Models  391
 where, in addition to the parameters previously described,  π 1( j 1  j 2) k  represents the eﬀ ect of begin-
ning math achievement on Year 2 achievement. Entering previous achievement as a covariate is 
similar to creating a gain score model since there are only two achievement measurements in the 
model (see McCaﬀ rey et al., 2004, for further discussion of teacher eﬀ ectiveness models). 
 At the classroom level, we will consider beginning math achievement as ﬁ xed across classrooms: 
 
  π 1( j 1  j 2) k  =   10  k  . 
(8.19) 
 At Level 3 (school level), the equation with a ﬁ xed slope for previous achievement is the following: 
 
   10  k  =   100  . 
(8.20) 
 From Equation 8.18, after substitution, the basic random-intercept model can be speciﬁ ed as follows: 
 
  Y i  ( j 1  j 2) k  =   000  +   100  Zmath1 i  ( j 1  j 2) k  +   00  k  +  u j  1  k  +  u j  2  k  +   i  ( j 1  j 2  )k  , 
(8.21) 
 where   000  is the grand mean of achievement for schools adjusted for initial scores;   100  is the eﬀ ect 
for previous achievement for schools; and  v ,  u , and  represent residuals (i.e., normally and inde-
pendently distributed in the population with expected mean values equal to 0 and some variance) 
associated with schools, classrooms, and students, respectively. Th is model speciﬁ es six estimated 
parameters (i.e., two ﬁ xed eﬀ ects, three random variance components, and one residual variance). 
 Deﬁ ning Model 2.2 with IBM SPSS Menu Commands 
 Settings will default to those used 
in Model 2.1. 
  1. Go to the toolbar and select 
ANALYZE, MIXED MOD-
ELS, LINEAR. 
 Th is command enables access to 
the  Linear Mixed Models: Specify 
Subjects and Repeated dialog box. 

392  Cross-Classiﬁed Multilevel Models
  2. Th e  Linear Mixed Models: Specify Subjects and Re-
peated screen displays the default settings from the 
prior model. 
 Click the CONTINUE button to display the  Linear 
Mixed Models dialog box. 
  3. From the  Linear Mixed Models main 
screen, we will add a variable to the 
analysis. Click to select  Zmath1 , and 
then click the right-arrow button to 
move the variable to the  Covariate(s) 
box. 
 We will now add a ﬁ xed eﬀ ect to the 
model, so click the FIXED button to ac-
cess the  Fixed Eﬀ ects main screen. 
 
 4a. Within the  Linear 
Mixed Models: Fixed 
Eﬀ ects dialog box, click 
the pull-down menu 
to change the factorial 
setting to  Main Eﬀ ects . 
 
 b. Click to select  Zmath1 
from the  Factors and 
Covariates box, and then 
click the ADD button 
to move the variable 
into the  Model box. 
 
 c. Note on lower left of 
the screen that the 
intercept and the sum 
of squares ( Type III ) are 
the default settings. 
 Click the CONTINUE button to return to the  Linear Mixed Models dialog box. 

Cross-Classiﬁ ed Multilevel Models  393
  5. Finally, in the  Linear Mixed Models 
dialog box, click the OK button to 
run the model. 
 Interpreting the Output From Model 2.2 
 In Model 2.2, we added a standardized (mean [ M ] = 0, standard deviation [ SD ] = 1) previous 
achievement variable, which changes the intercept (which now represents achievement at Time 2 
adjusted for beginning achievement) to 653.48.   Table 8.17  suggests that previous math achieve-
ment aﬀ ects subsequent achievement (  100  = 28.62,  p < .01). Th is coeﬃ  cient suggests that a 1- SD 
increase in  Zmath1 would produce a 28.62-point increase in the Math 2 score. 
 If we compare the variance components of Model 2.1 (  Table 8.16  ) and Model 2.2 (  Table 
8.18 ), we see that entering the previous achievement variable into the model decreases the Level 
1 variance considerably (i.e., from 1,482.26 to 767.06). Th is represents a reduction in variance 
(or  R 2 ) of about 48.3% (715.2/1,482.26 = 0.483). Notice also, however, that the size of the 
Classroom 1 variance (  2  class 1  = 54.16) and Classroom 2 variance (  2  class 2  = 38.20) components are 
somewhat larger than in Model 2.1.  
 TABLE 8.17 Estimates of Fixed Effects a 
Parameter
Estimate
Std. Error
df
t
Sig.
95% Conﬁ dence Interval
Lower Bound Upper Bound
Intercept
653.482
1.313
82.082
497.571
.000
650.869
656.094
Zmath1
28.620
0.473
4,066.184
60.542
.000
27.693
29.547
 a Dependent variable: math2. 
 TABLE 8.18 Estimates of Covariance Parameters a 
Parameter
Estimate
Std. Error
Wald Z
Sig.
95% Conﬁ dence Interval
Lower Bound Upper Bound
Residual
767.060
17.907
42.835
.000
732.753
802.973
Intercept [subject = schcode]
Variance
83.983
20.879
4.022
.000
51.591
136.711
Intercept [subject = teach2id]
Variance
38.202
9.855
3.876
.000
23.040
63.339
Intercept [subject = teach1id]
Variance
54.160
11.229
4.823
.000
36.074
81.314
 a Dependent variable: math2.   

394  Cross-Classiﬁed Multilevel Models
 As Hox (2010) notes, this often occurs in multilevel analyses, but makes it unclear which vari-
ance components to use in establishing a baseline model. As we noted in Chapter 1, this result 
can occur because the amount of variance explained is not a simple concept in multilevel mod-
eling (Snijders & Bosker, 1994). Hox explains that the sampling process in multilevel designs 
creates some between-group variability in all Level 1 variables, even if there are, in fact, no real 
group diﬀ erences in the population. Th e variability at successive levels (e.g., Level 2 or Level 3) 
may be much greater than the model assumes in calculating initial variance components, such 
that the intercept-only model (Model 1.1) can overestimate the variance at Level 1 and may 
underestimate the variance at Level 2 (Hox, 2010). 
 Model 2.2, with the previous achievement variable added, estimates the variance accounted 
for in the dependent variable, and, conditional on this eﬀ ect, the variance components estimated 
for Level 2 may be a bit more accurately estimated. Hox (2010) suggests using the classroom 
variance components from Model 2.2 as the baseline from which to make comparisons in vari-
ance reduction. We note in passing that after accounting for previous achievement in our ex-
ample, the variance in math achievement at the classroom level is about 6% for Class 1 and 4% 
for Class 2. 
 Model 2.3: Adding Teacher Effectiveness and a Student Background Control 
 We can next add the teacher eﬀ ectiveness variables to the model. Individual teachers were 
evaluated from 0 to 10 in terms of their classroom eﬀ ectiveness in facilitating student learn-
ing (after adjustment for student composition) based on their previous student cohort. Th e 
eﬀ ectiveness scores were then transferred into the current student cohort. We display the 
variation in eﬀ ectiveness scores in the following tables.   Tables 8.19  and   8.20  suggest that 
teacher eﬀ ectiveness was distributed similarly across both sets of classrooms in this sample 
data set.   
 In Model 2.2, at Level 1 we will add a control for student SES: 
 
  Y i  ( j 1  j 2) k  =  π 0( j 1  j 2) k  +  π 1( j 1  j 2) k  Zmath1 i  ( j 1  j 2) k  +  π 2( j 1  j 2) k  lowses  i ( j 1  j 2) k  +   i  ( j 1  j 2) k  . 
(8.22) 
 At Level 2, the model to explain intercepts can now be deﬁ ned as 
 
  π 0( j 1  j 2) k  =   00  k  +   01  k  teacheﬀ 1 ( j 1  j 2) k  +   02  k  teacheﬀ 2 ( j 1  j 2) k  +  u j  1  k  +  u j  2  k  . 
(8.23) 
 TABLE 8.20  Descriptive Statistics 
N
Minimum Maximum Mean Std. Deviation
effmath2
259
0
10
5.01
2.293
Valid N (Listwise)
259
TABLE 8.19 Descriptive Statistics
N
Minimum Maximum Mean Std. Deviation
effmath1
324
0
10
5.15
2.959
Valid N (Listwise)
324

Cross-Classiﬁ ed Multilevel Models  395
 In this model, we will ﬁ rst assume that teacher eﬀ ects do not vary randomly across schools: 
 
   01  k  =   010  , 
(8.24) 
 
   02  k  =   020  . 
(8.25) 
 We might also consider any number of classroom controls at this level (e.g., aggregated so-
cioeconomic status of students in the classroom, aggregated academic background of students, 
and information about teachers’ experience and other background characteristics). Because the 
teacher eﬀ ectiveness scores were previously adjusted for student composition, we note that it 
is generally redundant to add similar background controls (e.g., SES) at both the student and 
classroom levels or to add similar controls (e.g., SES) for both classrooms since it would not be 
expected that there would be much diﬀ erence in the classroom demographics within schools (or 
over time). Th is could change if schools grouped students within classrooms in some particular 
manner (e.g., by previous math ability). 
 Th e combined model with nine estimated parameters will now be the following: 
 Y i  ( j 1  j 2) k  =   000  +   010   teacheﬀ 1 ( j 1  j 2) k  +   020  k  teacheﬀ 2 ( j 1  j 2) k  +   100  Zmath1 i  ( j 1  j 2) k  +   200   lowses i  ( j 1  j 2) k  
 
+   00  k  +  u j  1  k  +  u j  2  k  +   i  ( j 1  j 2) k  . 
(8.26) 
 Deﬁ ning Model 2.3 with IBM SPSS Menu Commands 
 Note: Settings will default to those 
used in Model 2.2. 
  1. Go to the toolbar and select 
ANALYZE, MIXED MOD-
ELS, LINEAR. 
 Th is command enables access to 
the  Linear Mixed Models: Specify 
Subjects and Repeated dialog box. 

396  Cross-Classiﬁed Multilevel Models
  2. Th e  Linear Mixed Models: Specify Subjects and Re-
peated screen displays the default settings from the 
prior model. 
 Click the CONTINUE button to display the  Linear 
Mixed Models dialog box. 
  3. Th e  Linear Mixed Models dialog box dis-
plays the default settings for Model 2.2. 
 We will add three predictors to the model 
( lowses ,  eﬀ math1 , and  eﬀ math2 ). Click to select 
the three variables, and then “drag” them to 
 Covariate(s) box. To facilitate reading of the 
output tables we will change the sequence of 
the variables by dragging individual variables 
into the following order (see insert):  eﬀ math2 , 
 eﬀ math1 ,  Zmath1 , and  lowses. 
 We may now proceed to deﬁ ne ﬁ xed eﬀ ects 
for the variable. 
 Click the FIXED button to access the  Linear 
Mixed Models: Fixed Eﬀ ects dialog box. 
 
 4a. Th e  Linear Mixed Models: 
Fixed Eﬀ ects  dialog box dis-
plays the default  Main Eﬀ ects  
setting used in the prior model. 
 
 b. We will rearrange the se-
quence order of the variables, 
so click to select  Zmath1 , and 
then click the REMOVE 
button to clear the  Model box. 
 
 c. Now click to select the four 
variables ( eﬀ math2 ,  eﬀ math1 , 
 Zmath1 , and  lowses ) from the 
 Factors and Covariates box, 
and then click the ADD but-
ton to move the variables into 
the  Model box. 
 Click the CONTINUE button to return to the  Linear Mixed Models dialog box. 

Cross-Classiﬁ ed Multilevel Models  397
  5. Finally, in the  Linear Mixed Models 
dialog box, click the OK button to 
run the model. 
 Interpreting the Output From Model 2.3 
 Th e ﬁ xed-eﬀ ect estimates (  Table 8.21  ) suggest that in this subset of the data, the eﬀ ectiveness of 
the ﬁ rst teacher (  = 1.09,  p < .01) contributed slightly more to ending math outcomes than the 
eﬀ ectiveness of the second teacher (  = 0.73,  p = .01). Both eﬀ ects, however, would be considered 
relatively small.  
 Th e variance components table (  Table 8.22  ) suggests that after adding the teacher eﬀ ects for 
Classroom 1 and Classroom 2 to the model, there is still variance in Year 2 achievement levels 
to be explained at the classroom and school levels. Adding the Level 2 eﬀ ectiveness variables 
reduces the variance for each classroom, especially in the ﬁ rst classroom (from about 54.16 to 
44.60 or  R 2 = 0.177). Th e school-level variance is also reduced slightly from adding the teacher 
eﬀ ectiveness variables to the model (from 83.98 to 73.81, or  R 2 = 0.121). 
 TABLE 8.21 Estimates of Fixed Effects a 
Parameter
Estimate
Std. Error
df
t
Sig.
95% Conﬁ dence Interval
Lower Bound Upper Bound
Intercept
646.389
2.261
361.609
285.919
.000
641.943
650.835
effmath2
0.733
0.283
175.141
2.590
.010
0.174
1.292
effmath1
1.093
0.225
225.841
4.856
.000
0.649
1.536
Zmath1
28.426
0.487
4,077.812
58.317
.000
27.470
29.381
lowses
−4.498
0.974
4,090.252
−4.619
.000
−6.408
−2.589
 a Dependent variable: math2. 
 TABLE 8.22 Estimates of Covariance Parameters a 
Parameter
Estimate
Std. Error
Wald Z
Sig.
95% Conﬁ dence Interval
Lower Bound Upper Bound
Residual
764.150
17.823
42.875
.000
730.005
799.893
Intercept [subject = schcode]
Variance
73.806
18.827
3.920
.000
44.767
121.681
Intercept [subject = teach2id] Variance
35.451
9.493
3.734
.000
20.974
59.918
Intercept [subject = teach1id] Variance
44.595
10.065
4.431
.000
28.653
69.407
 a Dependent variable: math2. 

398  Cross-Classiﬁed Multilevel Models
 Model 2.4: Adding a School-Level Predictor and a Random Slope 
 Next, we might investigate whether teacher eﬀ ectiveness varies across schools. At the school 
level, the model with random eﬀ ectiveness slopes would be the following: 
 
   01k =   010  +  
 01  k  , 
(8.27) 
 
   02  k  =   020  +  
 02  k  , 
(8.28) 
 where   010  and   020  are the average teacher eﬀ ectiveness means for Classroom 1 and Classroom 
2, respectively, and we will use  
 01  k  and  
 02  k  as the respective school residuals for the slope eﬀ ects. 
At Level 3, we will deﬁ ne a diagonal covariance matrix for the intercept and slope (i.e., because 
we determined that the unstructured covariance matrix did not converge in this model). Th e 
combined model with 11 estimated parameters will then be the following: 
 Y i  ( j 1  j 2) k  =   000  +   010  teacheﬀ 1 ( j 1  j 2) k  +   020  k  teacheﬀ 2 ( j 1  j 2) k  +   100  Zmath1 ( j 1  j 2) k  +   200  lowses i  ( j 1  j 2) k  +   00  k  
 
+  
 01  k  teacheﬀ 1 ( j 1  j 2) k  +  
 02  k  teacheﬀ 2 ( j 1  j 2) k  +  u j  1  k  +  u j  2  k  +   i  ( j 1  j 2) k  . 
(8.29) 
 Deﬁ ning Model 2.4 with IBM SPSS Menu Commands 
 Note: Settings will default to those 
used in Model 2.3. 
  1. Go to the toolbar and select 
ANALYZE, MIXED MOD-
ELS, LINEAR. 
 Th is command enables access to 
the  Linear Mixed Models: Speciﬁ ed 
Subjects and Repeated dialog box. 

Cross-Classiﬁ ed Multilevel Models  399
 2. Th e  Linear Mixed Models: Specify Sub-
jects and Repeated  screen displays the 
default settings from the prior model. 
 Click the CONTINUE button to display 
the  Linear Mixed Models dialog box. 
  3. Th e  Linear Mixed Mod-
els dialog box displays 
default settings from 
the prior model. 
 We will now modify the 
random eﬀ ects to this model. 
Click the RANDOM button 
to access the  Linear Mixed 
Models: Random Eﬀ ects dialog 
box. 

400  Cross-Classiﬁed Multilevel Models
 
 4a. Th e  Linear 
Mixed Models: 
Random Eﬀ ects 
displays the  Ran-
dom Eﬀ ect 3 of 3 
screen, which is 
the default from 
the prior model. 
We will change 
the Level 3 ran-
dom eﬀ ects but 
need to access 
the  Random Ef-
fect 1 of 3 dialog 
screen. First, 
click the PRE-
VIOUS button 
to access the 
 Random Eﬀ ect 2 
of 3 main screen. 
 
 b. From the  Ran-
dom Eﬀ ect 2 of 
3 screen, click 
the PREVIOUS 
button to access 
the  Random Ef-
fect 1 of 3 main 
screen. 
 
 c. From the  Ran-
dom Eﬀ ect 1 of 3 
screen, change 
the covariance 
type by clicking 
the pull-down 
menu and selecting  Diagonal . 
 Th e  Diagonal covariance structure has heterogeneous variances and zero correlation between elements 
(IBM Corporation, 2012). 
 
 d. Change the default factorial setting by clicking the pull-down menu and selecting  Main Eﬀ ects . 
 
 e. We will add two variables to the model ( eﬀ math2 and  eﬀ math1 ). Click to select both variables, 
and then click the ADD button to move them to the  Model box. 
 Click the CONTINUE button to return to the  Linear Mixed Models dialog box. 

Cross-Classiﬁ ed Multilevel Models  401
 Interpreting the Output From Model 2.4 
 We ﬁ rst examine whether eﬀ ectiveness varies across schools. We provide the variance compo-
nents table ﬁ rst (  Table 8.23  ). Th e table suggests that the eﬀ ectiveness of Teacher 1 did not seem 
to vary across schools (one-tailed  p = .205). It may be, however, that the eﬀ ectiveness of Teacher 
2 does vary across schools (one-tailed  p = .055). Given these results, we can reformulate the Level 
2 model by removing the random eﬀ ect for Teacher 1 eﬀ ectiveness ( 
 01  k  ) in Equation 8.27. 
 Model 2.5: Examining Level 3 Differences Between Institutions 
 We will then add a school-level variable that may explain diﬀ erences in math achievement be-
tween schools. In this example, we will use the quality of the school’s educational processes (e.g., 
the school’s leadership, academic expectations, and climate) as a possible predictor of diﬀ erences 
in school math outcomes. At Level 3, the intercept model is the following: 
 
   00  k  =   000  +   001  schqual k  +  
 00  k  , 
(8.30) 
 where   000  is the adjusted school-level mean,   001  is the coeﬃ  cient representing the impact of the 
school-level predictor (school quality) on math outcomes, and  
 00  k  is the school-level residual. We 
could, of course, add other relevant school predictors to the model (e.g., school size, staﬀ  stability, and 
wstudent composition). Th e combined model with 11 estimated parameters will then be as follows: 
 Y  i ( j 1  j 2) k  =   000  +   001  schqual k  +   010  teacheﬀ 1 ( j 1  j 2) k  +   020  k  teacheﬀ 2 ( j 1  j 2) k  +   100   Zmath1 i  ( j 1  j 2)k 
 
+   200  lowses i  ( j 1  j 2) k  +   00  k  +  
 02  k  teacheﬀ 2 ( j 1  j 2) k  +  u j  1  k  +  u j  2  k  +   i  ( j 1  j 2) k  . 
(8.31) 
  5. Finally, in the  Linear Mixed Models dia-
log box, click the OK button to run the 
model. 
TABLE 8.23 Estimates of Covariance Parametersa
Parameter
Estimate
Std. Error
Wald Z
Sig.
95% Conﬁ dence Interval
Lower Bound Upper Bound
Residual
764.311
17.834
42.857
  .000
730.144
800.076
Intercept + effmath2 + effmath1Var: Intercept
46.838
21.193
2.210
0.027
19.295
113.695
[subject = schcode]
Var: effmath2
0.788
0.493
0.493
0.110
0.231
2.687
Var: effmath1
0.343
0.427
0.804
0.421
0.030
3.929
Intercept [subject = teach2id]
Variance
29.796
9.257
3.219
0.001
16.207
54.780
Intercept [subject = teach1id]
Variance
41.053
10.449
3.929
0.000
24.928
67.608
a Dependent variable: math2. 

402  Cross-Classiﬁed Multilevel Models
 Deﬁ ning Model 2.5 with IBM SPSS Menu Commands 
 Note: Settings will default to those 
used in Model 2.4. 
  1. Go to the toolbar and select 
ANALYZE, MIXED MOD-
ELS, LINEAR. 
 Th is command enables access to 
the  Linear Mixed Models: Specify 
Subjects and Repeated dialog box. 
  2. Th e  Linear Mixed Models: Specify Subjects and 
Repeated screen displays the default settings 
from the prior model. 
 Click the CONTINUE button to display the  Lin-
ear Mixed Models dialog box. 

Cross-Classiﬁ ed Multilevel Models  403
  3. Th e  Linear Mixed Models dia-
log box displays the default 
settings for Model 2.4. 
 We will add one predictor ( schqual ) 
to the model. Click to select 
 schqual , and then “drag” the vari-
able to  Covariate(s) box above 
 eﬀ math . Th is changes the sequence 
order of the variables (see insert) 
to the following:  schqual ,  eﬀ math2 , 
 eﬀ math1 ,  Zmath1 , and  lowses.  We 
may now proceed to deﬁ ne ﬁ xed 
eﬀ ects for the variable. 
 Click the FIXED button to access 
the  Linear Mixed Models: Fixed Ef-
fects dialog box. 
 
 4a. Th e  Linear 
Mixed Models: 
Fixed Eﬀ ects 
dialog box 
displays the 
default  Main 
Eﬀ ects setting 
used in the 
prior model. 
 We will rearrange the 
sequence order of the 
variables, so click to 
select  eﬀ math2 ,  ef-
fmath1 ,  Zmath1 , and 
 lowses.  Th en click the 
REMOVE button to 
clear the  Model box. 
 
 b. Th e default 
setting is  Main 
Eﬀ ects . 
 
 c. Now click to select the ﬁ ve variables ( schqual ,  eﬀ math2 ,  eﬀ math1 ,  Zmath1 , and  lowses ) from the 
 Factors and Covariates box, and then click the ADD button to move the variable into the  Model 
box. 
 Click the CONTINUE button to return to the  Linear Mixed Models dialog box. We will now modify 
the Level 1 random eﬀ ects to this model. Click the RANDOM button to access the  Linear Mixed 
Models: Random Eﬀ ects dialog box. 

404  Cross-Classiﬁed Multilevel Models
  5. Th e  Linear Mixed 
Models: Random 
Eﬀ ects  displays the 
 Random Eﬀ ect 1 
of 3 screen, which 
is the default 
from the prior 
model. We will 
change the Level 
3 random eﬀ ects 
by removing a 
variable from the 
model. 
 Click to select  ef-
fmath1 , and then click 
the REMOVE button. 
 Click the CON-
TINUE button to 
return to the  Linear 
Mixed Models dialog 
box. 
  6. Finally, in the  Linear Mixed Models 
dialog box, click the OK button to 
run the model. 

Cross-Classiﬁ ed Multilevel Models  405
 Interpreting the Output From Model 2.5 
 Table 8.24  provides some preliminary evidence that school quality is related to ending math 
achievement ( = 2.28,  p < .10), remembering that we have a relatively small subset of 81 schools. 
Th e variance component table (  Table 8.25  ) suggests that Teacher 2 eﬀ ectiveness varies across 
schools (Wald  Z = 1.765, one-tailed  p = .039). 
 Model 2.6: Adding a Level 3 Cross-Level Interaction 
 Finally, we will add a school-level variable that might moderate the relationship between Teacher 
2 eﬀ ectiveness and Year 2 math achievement. In this case, we will use quality of the school’s edu-
cational processes (e.g., the school’s leadership, academic expectations, and climate). Th e Level 3 
model for explaining the slope is now the following: 
 
   02  k  =  020  +  021  schqual k  +  
 02  k  . 
(8.32) 
 Th e combined model with 12 estimated parameters will then be 
 Y i  ( j 1  j 2) k  =   000  +   001  schqual k  +   010  teacheﬀ 1 ( j 1  j 2) k  +   020  teacheﬀ 2 ( j 1  j 2) k  +   021  schqual k  *  teacheﬀ 2 ( j 1  j 2) k  
 
+   100   Zmath1 i  ( j 1  j 2) k  +   200  lowses i  ( j 1  j 2) k  +   00  k  +  
 02  k   teacheﬀ 2 ( j 1  j 2) k  +  u j  1  k  +  u j  2  k  +   i  ( j 1  j 2) k  . 
(8.33) 
 TABLE 8.24  Estimates of Fixed Effects a 
Parameter
Estimate
Std. Error
df
t
Sig.
95% Conﬁ dence Interval
Lower Bound Upper Bound
Intercept
646.029
2.195
306.310
294.294
.000
641.709
650.348
schqual
2.278
1.303
89.300
1.748
.084
−0.311
4.867
effmath2
0.735
0.309
120.918
2.377
.019
0.123
1.347
effmath1
1.109
0.225
224.520
4.926
.000
0.665
1.552
Zmath1
28.386
0.488
4,075.644
58.202
.000
27.430
29.343
lowses
−4.426
0.974
4,087.879
−4.543
.000
−6.337
−2.516
 a Dependent variable: math2. 
 TABLE 8.25 Estimates of Covariance Parameters a 
Parameter
Estimate
Std. Error
Wald Z
Sig.
95% Conﬁ dence Interval
Lower Bound Upper Bound
Residual
763.940
17.818
42.875
.000
729.804
799.672
Intercept + effmath2 
Var: Intercept
49.916
19.584
2.549
.011
23.136
107.694
[subject = schcode]
Var: effmath2
0.911
0.516
1.765
.078
0.300
2.764
Intercept [subject = teach2id]
Variance
29.650
9.231
3.212
.001
16.108
54.578
Intercept [subject = teach1id]
Variance
44.841
10.111
4.435
.000
28.823
69.762
 a Dependent variable: math2. 

406  Cross-Classiﬁed Multilevel Models
 Deﬁ ning Model 2.6 with IBM SPSS Menu Commands 
 Note: Settings will default to those 
used in Model 2.5. 
  1. Go to the toolbar and select 
ANALYZE, MIXED MOD-
ELS, LINEAR. 
 Th is command enables access to 
the  Linear Mixed Models: Specify 
Subjects and Repeated dialog box. 
  2. Th e  Linear Mixed Models: Specify Subjects and 
Repeated screen displays the default settings 
from the prior model. 
 Click the CONTINUE button to display the  Lin-
ear Mixed Models dialog box. 

Cross-Classiﬁ ed Multilevel Models  407
  3. Th e  Linear Mixed Models dialog 
box displays the default settings for 
Model 2.5. 
 We will now add a ﬁ xed eﬀ ect to the 
model, so click the FIXED button to ac-
cess the  Fixed Eﬀ ects main screen. 
 One cross-level interaction (or nested 
terms) will be created and added to the 
model:  eﬀ math2*schqual . Th is interaction 
will tell us the relationship between qual-
ity of the school’s educational processes 
( schqual ) and math achievement ( eﬀ math2 ). 
 Add Interaction to Model 2.6: 
 effmath2*schqual 
 
 4a. Click to select  Build nested 
terms . 
 
 b. Now click to select the 
variable  eﬀ math2  from the 
 Factors and Covariates box. 
 
 c. Click the arrow but-
ton below the  Factors and 
Covariates box. Th is moves 
 eﬀ math2 into the  Build Term 
box to create a cross-level in-
teraction by linking variables 
and terms. 
 
 d. Next, click the BY* button, 
which will insert the compu-
tation command symbol:  eﬀ math2* . 
 
 e. Click to select  schqual  from the  Factors and Covariates box. 
 
 f. Click the arrow button below the  Factors and Covariates box to move  schqual into the  Build 
Term box and complete the interaction term:  eﬀ math2*schqual . 
 
 g. Click the ADD button to transfer the interaction into the  Model box. 
 Click the CONTINUE button to return to the  Linear Mixed Models dialog box. 
  5. Finally, in the  Linear Mixed Models 
dialog box, click the OK button to 
run the model. 

408  Cross-Classiﬁed Multilevel Models
 Interpreting the Output From Model 2.6 
 Th e ﬁ xed-eﬀ ects table (  Table 8.26  ) suggests that the quality of the school’s key educational 
processes does not moderate the relationship between Teacher 2 eﬀ ectiveness and achievement 
levels in math ( = ‒0.46,  p > .10). Th e eﬀ ects of the other variables on Year 2 achievement remain 
about the same as the previous model. Given that the cross-level interaction is not signiﬁ cant, for 
parsimony we should remove it from the ﬁ nal model.  
 Th e variance component table (  Table 8.27  ) suggests that at Level 3, after adding the cross-
level interaction, there may still be some slope variance left to explain at the school level (Wald 
 Z = 1.765, one-tailed  p = .039). Th ere is also still signiﬁ cant intercept variance in ending achieve-
ment to be explained across schools and classrooms. We could continue to add predictors to the 
model that might explain this variation in school and classroom intercepts.  
 Summary 
 IBM SPSS MIXED proves very ﬂ exible in handling a variety of multilevel cross-classiﬁ ed data 
sets. Th ey extend the types of data structures and problems that can be investigated with multi-
level modeling. Cross-classiﬁ ed models also open up additional opportunities to investigate in-
dividuals’ growth over time within their organizational settings. It is important to keep in mind, 
however, that their complexity and size will add to the challenge of trying to estimate these types 
of partly hierarchical data structures.  
 TABLE 8.26 Estimates of Fixed Effects a 
Parameter
Estimate
Std. Error
df
t
Sig.
95% Conﬁ dence Interval
Lower Bound Upper Bound
Intercept
645.718
2.201
307.461
293.367
.000
641.387
650.049
schqual
4.221
1.905
183.148
2.215
.028
0.462
7.980
effmath2
0.814
0.314
120.484
2.591
.011
0.192
1.437
effmath1
1.110
0.225
224.367
4.933
.000
0.666
1.553
Zmath1
28.378
0.488
4,074.882
58.186
.000
27.422
29.334
lowses
–4.433
0.974
4,087.802
–4.550
.000
–6.344
–2.523
schqual * effmath2
–0.458
0.330
90.252
–1.389
.168
–1.113
0.197
 a Dependent variable: math2. 
 TABLE 8.27 Estimates of Covariance Parameters a 
Parameter
Estimate
Std. Error
Wald Z
Sig.
95% Conﬁ dence Interval
Lower Bound Upper Bound
Residual
763.956
17.819
42.874
.000
729.818
799.690
Intercept + effmath2 
[subject = schcode]
Var: Intercept
48.876
19.509
2.505
.012
22.353
106.871
Var: effmath2
0.925
0.524
1.765
.078
0.305
2.808
Intercept [subject = teach2id] Variance
29.528
9.218
3.203
.001
16.015
54.445
Intercept [subject = teach1id] Variance
44.688
10.099
4.425
.000
28.696
69.591
 a Dependent variable: math2. 

409
 CHAPTER 9 
 Concluding Thoughts 
 I
n our 2009 book,  An Introduction to Multilevel Modeling Techniques (2nd ed.), we sought to 
expand the application of multilevel-modeling techniques to a new range of research ques-
tions. In that book, we argued that most of the new variants of the simple multilevel model 
could, in fact, be subsumed under a general modeling framework of latent variables and simul-
taneous equations. Th e modeling we present in that book uses two popular multilevel statistical 
programs: HLM and Mplus. Although we are very satisﬁ ed with those excellent programs, their 
cost and the learning curve associated with their use present barriers to many colleagues who 
wanted to use the book in their graduate research courses. Unfortunately, relatively few social sci-
ence computing labs make these programs available for student and classroom use. Th e problem 
makes it challenging to take full advantage of these software programs in introducing multilevel-
modeling techniques to students. 
 Our own initial solution to this problem was to generate sets of handouts we could use with 
our students that made use of the familiar IBM SPSS modeling framework to introduce multi-
level modeling. As we began to reﬁ ne some of these materials, we realized there might be wider 
interest in having a set of hands-on activities that would illustrate major concepts in multilevel 
and longitudinal models. In this resulting workbook, we have tried to provide an applied intro-
duction to multilevel modeling along with instruction for managing multilevel data, specifying 
a range of multilevel models, and interpreting output generated through the SPSS MIXED 
procedure. After “driving it around the block” a few times, we feel that it has deﬁ nite utility for 
investigating a variety of multilevel and longitudinal models with continuous outcomes. We also 
noted a few cautions along the way. In compiling the workbook, we triangulated many of our 
results with other software and sometimes found small diﬀ erences in individual parameters but, 
overall, a high level of substantive convergence. Our goal has been to widen exposure to and un-
derstanding of some general multilevel-modeling principles and applications. Th e workbook was 
designed as a complement to our more in-depth treatment of the statistical and conceptual issues 
surrounding multilevel modeling provided in our introductory multilevel book. 
 With an eye toward the how-to aspect of setting up a study to investigate a research prob-
lem, in the ﬁ rst chapter of the second edition of the workbook we introduced a number of key 
conceptual and methodological issues. Several elements have to be brought together including 
knowledge of previous research, the deﬁ nition and development of the speciﬁ c research prob-
lem, the goals of the research, the consideration of various appropriate methods of investigation 
(including their advantages and shortcomings) in light of the structure of the available data, and 
the means of communication with potential users of the study’s results. Our presentation there 
was designed to set the stage for the subsequent development of several diﬀ erent multilevel 
models that are the focus of the following chapters. We also brieﬂ y updated readers regarding 
issues of potential importance for model building including options for categorical outcomes, 
working with missing data, and sample weights. We devoted Chapter 2 to discussing a number 

410   Concluding Thoughts
of conceptual and practical issues associated with the management of multilevel data. We believe 
readers will ﬁ nd the material useful in setting up their own data analyses since each study seems 
to bring its own unique challenges in preparing the data for the intended analyses. Our objective 
there was to highlight the diﬀ erent ways that hierarchical data can be structured, while oﬀ ering 
a general introduction to essential data management procedures available within IBM SPSS. 
 Each of the remaining chapters dealt with various types of multilevel models for diﬀ erent 
types of data structures (cross-sectional, growth, and cross-classiﬁ ed) to cover a broad number 
of research possibilities. In particular, in this second edition we expanded the types of multilevel 
models that readers might ﬁ nd useful in various situations (e.g., piecewise and parallel growth 
models, latent variable outcomes, and regression discontinuity design). Although the traditional 
two- or three-level multilevel cross-sectional model has become a more common feature in social 
science research over the past decade, the other formulations that we introduced here are rapidly 
growing in their popularity and use. It is our hope that making these modeling capabilities avail-
able through SPSS will make them more accessible to a wider audience, even though we only 
scratched the surface regarding the use of these techniques with longitudinal and cross-classiﬁ ed 
data structures and more complex research designs that can be speciﬁ ed in SPSS MIXED, albeit 
with a bit more creativity required in setting up the data set. 
 As the reader can tell from the treatment we provide in this workbook, multilevel models 
can get quite complex. It is one thing to dump a set of variables into a single-level ordinary least 
squares (OLS) regression model but quite another to adopt a recklessly exploratory approach in 
a multilevel framework. Although exploratory analysis is an important and necessary feature of 
empirical research, the models we covered in this workbook demand a more disciplined approach 
to model conceptualization and speciﬁ cation. With multiple levels of analysis and the possibil-
ity for numerous cross-level interactions, choices about ﬁ xed or random slopes and intercepts, 
centering, weighting, and estimation algorithms, as well as the interpretation of the results from 
these models, can quickly become bogged down and rendered useless or, worse, misleading. 
 In this workbook, we began with the principle that quantitative analysis represents the trans-
lation of abstract theories into concrete models and that conceptual frameworks are essential 
guides to empirical investigation. Th e statistical model is therefore designed to represent a set 
of proposed theoretical relationships that are thought to exist in a population from which we 
have a sample of data. With this as a guiding principle, the researcher makes conscious deci-
sions about the analysis that deﬁ ne research questions, design, data structures, and methods of 
analysis. Th e potential complexity of the multilevel model thus demands the careful attention 
of the analyst. 
 As we pointed out in Chapter 1, this does not ignore the importance of exploratory work. We 
recognize its place and suggest only that such work be conducted with careful thought about the 
possible relationships one might expect to see. Th e myriad combinations of model speciﬁ cation 
rule out the multilevel model as an eﬀ ective “data-mining” tool. In fact, the models are very data 
demanding and will perform poorly without adequate data at each level of interest. But with 
an ample framework for organizing the analysis, adequate data, and careful thought to sensible 
model speciﬁ cation, the multilevel framework opens up dramatic new possibilities for explor-
atory work. 
 Th is workbook is written at a time when multilevel statistical models are better able to capture 
the complex contextual or environmental factors that condition the behaviors and attitudes of 
lower level units operating within those contexts or environments. Coincidently, we also ﬁ nd 
ourselves at a moment where large-scale hierarchical data are more readily available than they 
were even 10 years ago. Although it would seem to be an incredibly exciting time for social 
science researchers (and indeed it is), we still ﬁ nd ourselves in want of data to drive empirical 
models suggested by our conceptual frameworks. Perhaps satisfaction on this front will be ever 
elusive; that is, as our modeling ability and statistical knowledge expand, so will our need for data 
to drive ever more demanding models. 

Concluding Thoughts  411
 One issue we call attention to through the activities we provided in this workbook is that 
multilevel models are quite demanding of data, and the analyst should be very aware of the limi-
tations that exist as model speciﬁ cation becomes more complicated. As an example, our initial 
data sets (e.g., 100 to 200 individuals in 25 or 30 units) that we selected were ﬁ ne for illustrating 
ﬁ xed eﬀ ects; however, the moment we wished to illustrate random slopes, we needed much larger 
data sets to identify signiﬁ cant diﬀ erences across groups. Th ey often required 20 to 30 individuals 
within groups and 200 or more groups to be able to detect variability in the slopes. Th is gave us 
pause to consider that many published multilevel studies may report nonsigniﬁ cant results due 
primarily to making Type II errors (i.e., failure to reject the null hypothesis) related to not having 
adequate data to detect the eﬀ ects to begin with; that is, the available data are not up to the task 
of suﬃ  ciently supporting the complexity of the desired analyses. Th is suggests that the failure 
may not always be the proposed conceptual model but, rather, the shortcomings of the data and, 
perhaps, their measurement qualities. Hence, we emphasize that just because a model can be 
complex does not mean it should be complex. Parsimony is one indicator of a good empirical 
application of theory. 
 Another issue we touched on in Chapter 1 concerns the sampling scheme for the data used in 
multilevel studies. Researchers have for some time now been concerned about so-called design 
eﬀ ects resulting from complex sampling schemes—that is, where a combination of multistage 
cluster sampling and disproportionate stratiﬁ ed sampling is used. Th e multilevel model actually 
capitalizes on such sample designs, incorporating the nesting of data that result from multistage 
clustering. Although the multilevel model incorporates this important sample design feature, it 
does not address the disproportionate stratiﬁ ed sampling that generally occurs with such sam-
pling. Th is aspect of the design is usually dealt with through the application of sampling weights 
during the model speciﬁ cation stage. Weighting is pretty routine and straightforward in single-
level analyses but becomes more challenging in the multilevel framework. Although some pro-
grams such as Mplus and HLM can now accommodate weights at multiple levels of analysis 
(e.g., student-level weights and school-level weights), SPSS uses a global weight and, therefore, 
forces the researcher to choose between weights that may exist across levels. 
 Th e eﬃ  cacy of various weighting schemes used in diﬀ erent software programs is an issue that 
needs further research. Applying or not applying sample weights can change model estimates 
of standard errors considerably. Failure to take sample design into account by applying the ap-
propriate weights can bias estimates of standard errors downward. Because standard errors are 
used in determining hypothesis tests about individual parameters, downward-biased estimates 
can lead to more ﬁ ndings of signiﬁ cance than should be the case. For the time being, if sample 
weighting is essential to the analysis, it will likely be better currently to use another of the avail-
able programs or to revert to a single-level formulation within SPSS through its COMPLEX 
SAMPLES module (see Asparouhov, 2006; and Rabe-Hesketh & Skrondal, 2006). 
 A third issue we ask readers to consider is missing data. Missing data can present serious 
challenges for the researcher and should be dealt with as forthrightly as possible. Rarely are data 
missing completely at random (MCAR). If one were to go with the IBM SPSS defaults regard-
ing missing data, any case with even one piece of missing data would be eliminated from the 
analysis (i.e., where data are not vertically organized). We emphasize that researchers need to be 
aware of this and, where possible, seek viable solutions for data sets that contain considerable 
amounts of missing data. We favor situations where the software will actually estimate model pa-
rameters in the presence of the missing data (e.g., where variables are arranged vertically in IBM 
SPSS) since, in truth, there is no way of completely compensating for the fact that data have been 
irreversibly lost (Raykov & Marcoulides, 2008). We can try to obtain further information about 
the patterns of missing data and use this information to help devise a manner for dealing with 
the missing data. We do not recommend regression-based missing data substitution, which is an 
option within SPSS. For SPSS MIXED, we instead encourage the analyst to employ multiple 
imputation strategies, which produce multiple imputed data sets by repeatedly drawing values for 

412   Concluding Thoughts
each missing datum from a distribution (Peugh & Enders, 2004). Unfortunately, this procedure 
is not available in the IBM SPSS Base or Advanced program module, but it can be added sepa-
rately. At a minimum, we encourage the analyst to become very familiar with the data being used, 
to identify where data are missing, and to develop a strategy for testing the eﬀ ects of missing data 
on the results generated by the model. 
 Finally, as should be very clear from the models we have developed throughout the workbook, 
there is a logical process underlying the development of the models and a series of steps involved 
for moving from the partitioning of variance between levels to the speciﬁ cation of models that 
may have random intercepts and slopes. We strongly encourage readers to devise their own 
naming system to keep track of the various models used in any given analysis. Without a clear 
history of model speciﬁ cation, it is sometimes very diﬃ  cult to understand how one arrived at a 
ﬁ nal model. At the risk of twisting an old saw, it is often the journey that is more telling than the 
ﬁ nal destination. 
 Multilevel modeling provides us with another powerful means for investigating the types of 
processes referred to by our theories in more reﬁ ned ways. Although the models presented in this 
workbook were simpliﬁ ed for purposes of demonstrating the techniques, we hope that our step-
by-step guide serves as a foundation for the more thorough models that can be formulated and 
tested. We encourage the reader searching for more detail to consult the many other excellent 
resources available and referenced throughout this workbook. 

413
 References 
 Acock, A. C. (2005). Working with missing values.  Journal of Marriage and Family, 67 , 1012–1028. 
 Agresti, A. (2007).  An introduction to categorical data analysis . Hoboken, NJ: John Wiley & Sons. 
 Albright, J. J., & Marinova, D. M. (2010). Estimating multilevel models using SPSS, Stata, and SAS. 
 Retrieved from http://www.indiana.edu/˜statmath/stat/all/hlm/hlm.pdf 
 Allison, P. (2002).  Missing data . Th ousand Oaks, CA: Sage. 
 Asparouhov, T. (2005). Sampling weights in latent variable modeling.  Structural Equation Modeling, 12 (3), 
411–434. 
 Asparouhov, T. (2006). General multilevel modeling with sampling weights.  Communications in Statistics: 
Th eory & Methods, 35 (3), 439–460. 
 Azen, R., & Walker, C. M. (2011).  Categorical data analysis for the behavioral and social sciences . New York, 
NY: Routledge. 
 Beretvas, S. N. (2011). Cross-classiﬁ ed and multiple-membership models. In J. J. Hox & J. K. Roberts 
(Eds.),  Handbook of advanced multilevel analysis (pp. 313–334). New York, NY: Routledge. 
 Berkhof, J., & Snijders, T. A. B. (2001). Variance component testing in multilevel models.  Journal of Edu-
cational and Behavioral Statistics, 26 , 133–152. 
 Bloom, H. S., Hill, C. J., Black, A. R., & Lipsey, M. W. (2008). Performance trajectories and performance 
gaps as achievement eﬀ ect-size benchmarks for educational interventions.  Journal of Research on Edu-
cational Eﬀ ectiveness, 1 , 289–328. 
 Bodner, T. E. (2008). What improves with missing data imputations?  Structural Equation Modeling, 15 , 
651–675. 
 Boomsma, A. (1987). Th e robustness of maximum likelihood estimation in structural equation mod-
els. In P. Cuttance & R. Ecobe (Eds.),  Structural modeling by example  (pp. 160–188). Cambridge:  
Cambridge University Press. 
 Bryk, A. S., & Raudenbush, S. W. (1992).  Hierarchical linear models: Applications and data analysis methods . 
Newbury Park, CA: Sage. 
 Campbell, D. T., & Stanley, J. C. (1966).  Experimental and quasi-experimental designs for research . Chicago, 
IL: Rand McNally. 
 Chantala, K., Blanchette, D., & Suchinindran, C. M. (2011, April 28). Software to compute sampling 
weights for multilevel analysis. Retrieved from http://www.cpc.unc.edu/research/tools/data_analysis/
ml_sampling_weights 
 Cheung, M. W. L. (2007). Comparison of methods of handling missing time-invariant covariates in latent 
growth models under the assumption of missing completely at random.  Organizational Research 
Methods, 10 , 609–634. 
 Cook, T. D., & Campbell, D. T. (1979).  Quasi-experimentation: Design and analysis for ﬁ eld settings . Chi-
cago, IL: Rand McNally. 
 Cronbach, L. J. (1976).  Research on classrooms and schools: Formulation of questions, designs and analysis. 
 Occasional paper, Stanford Evaluation Consortium, Stanford University, Stanford, CA. 
 Curtin, T. R., Ingels, S. J., Wu, S., & Heuer, R. (2002).  National educational longitudinal study of 1988: 
 Base-year to fourth follow-up data ﬁ le user’s manual (NCES 2002–323).  Washington, DC: U.S. Depart-
ment of Education, National Center for Education Statistics. 
 Daniels, M. J., & Hogan, J. W. (2008).  Missing data in longitudinal studies: Strategies for Bayesian modeling 
and sensitivity analysis . Boca Raton, FL: Chapman & Hall/CRS. 
 Duncan, T. E., Duncan, S. C., & Strycker, L. A. (2006).  An introduction to latent variable growth curve 
 modeling: Concepts, issues and applications (2nd ed.). Mahwah, NJ: Lawrence Erlbaum. 
 Enders, C. K. (2011). Missing not at random models for latent growth curve analyses.  Psychological 
Methods, 16 (1), 1–16. 
 Enders, C. K., & Bandalos, D. (2001). Th e relative performance of full information maximum likelihood 
estimation for missing data in structural equation models.  Structural Equation Modeling, 8 , 430–457. 
 Flora, D. B., & Curran, P. J. (2004). An empirical evaluation of alternative methods of estimation for con-
ﬁ rmatory factor analysis with ordinal data.  Psychological Methods, 94 (4), 446–491. 
413

414  References
414  References
 Gelman, A., & Hill, J. (2007).  Data analysis using regression and multilevel hierarchical models . New York, 
NY: Cambridge University Press. 
 Gibson, N. M., & Olejnik, S. (2003). Treatment of missing data at the second level of hierarchical models. 
 Educational and Psychological Measurement, 63 , 204–238. 
 Goldstein, H. (1987).  Multilevel models in educational and social research . London: Oxford University Press. 
 Goldstein, H. (1995).  Multilevel statistical models . New York, NY: Halsted. 
 Goldstein, H. (2003).  Multilevel statistical models  (3rd ed.). New York, NY: Oxford University Press 
[Distributor]. 
 Grilli, L., & Pratesi, M. (2004). Weighted estimation in multilevel ordinal and binary models in the pres-
ence of informative sampling designs.  Survey Methodology, 30 , 93–103. 
 Guilford, J. P., & Frunchter, B. (1978).  Fundamental statistics in psychology and education . Singapore: 
McGraw-Hill. 
 Hamilton, L. C. (1992).  Regression with graphics: A second course in applied statistics . Paciﬁ c Grove, CA: 
Brooks/Cole. 
 Heck, R. H., Lam, W., & Th omas, S. L. (2012). State political culture, higher education spending indica-
tors, and undergraduate outcome.  Educational Policy, 27 , 1–37. 
 Heck, R. H., & Takahashi, R. (2006). Examining the impact of proposition 48 on graduation rates in 
Division 1A football and program recruiting behavior.  Educational Policy, 20 (4), 587–614. 
 Heck, R. H., & Th omas, S. L. (2009).  An introduction to multilevel modeling techniques (2nd ed.). New York, 
NY: Psychology Press. 
 Heck, R. H., Th omas, S. L., & Tabata, L. N. (2012).  Multilevel modeling of categorical outcomes using IBM 
SPSS . New York, NY: Routledge Academic. 
 Hedeker, D. (2005). Generalized linear mixed models. In B. Everitt & D. Howell (Eds.),  Encyclopedia of 
statistics in behavioral science  (pp. 727–738). New York, NY: Wiley. 
 Hedeker, D., & Gibbons, R. D. (1997). Application of random-eﬀ ects pattern-mixture models for missing 
data in longitudinal studies.  Psychological Methods, 2 , 64–78. 
 Hedeker, D., & Gibbons, R. D. (2006).  Longitudinal data analysis . Hoboken, NJ: Wiley. 
 Hill, P. W., & Goldstein, H. (1998). Multilevel modeling of educational data with cross-classiﬁ cation and 
missing identiﬁ cation for units.  Journal of Educational and Behavioral Statistics, 23 (2), 117–128. 
 Hofmann, D., & Gavin, M. (1998). Centering decisions in hierarchical models: Th eoretical and method-
ological decisions for organizational science.  Journal of Management, 24 , 623–644. 
 Hox, J. (2002).  Multilevel analysis: Techniques and applications . Mahwah, NJ: Lawrence Erlbaum. 
 Hox, J. (2010).  Multilevel analysis: Techniques and applications  (2nd ed.). New York, NY: Routledge 
Academic. 
 IBM Corporation. (2012) .  IBM SPSS advanced statistics 21 . Chicago, IL: Author. 
 Jia, Y., Stokes, L., Harris, I., & Wang, Y. (2011, April).  Th e evaluation of bias of the weighted random eﬀ ects 
model estimators  (ETS RR-11–13). Princeton, NJ: Educational Testing Service. 
 Kish, L. (1987).  Statistical design for research . New York, NY: Wiley. 
 Kreft, I., & de Leeuw, J. (1998).  Introducing multilevel modeling . Th ousand Oaks, CA: Sage. 
 Kreft, I., de Leeuw, J., & Aiken, L. S. (1995). Th e eﬀ ect of diﬀ erent forms of centering in hierarchical linear 
models.  Multivariate Behavioral Research, 30 (1), 1–22. 
 Laird, N. M., & Ware, J. H. (1982). Random-eﬀ ects models for longitudinal data.  Biometrics, 38 , 963–974. 
 Larsen, R. (2011). Missing data imputation versus full information maximum likelihood with second-level 
dependencies.  Structural Equation Modeling, 18A , 649–662. 
 Lee, V. E., & Bryk, A. S. (1989). A multilevel model of the social distribution of high school achievement. 
 Sociology of Education, 62 (3), 172–192. 
 Leyland, A. H. (2004). A review of multilevel modelling in SPSS. Retrieved from http://stat.gamma.rug.
nl/reviewspss.pdf 
 Little, R., & Rubin, D. B. (2002).  Statistical analysis with missing data (2nd ed.). Hoboken, NJ: Wiley. 
 Liu, S., Rovine, M., & Molennar, P.C.M. (2012). Selecting a linear mixed model for longitudinal data: 
Repeated measures ANOVA, covariance pattern model, and growth curve approaches.  Psychological 
Methods, 17, 15–30. 
 Loh, W. Y. (1987). Some modiﬁ cations of Levene’s test of variance homogeneity.  Journal of Statistical 
Computation and Simulation, 28 (3), 213–226. 
 Longford, N. T. (1993).  Random coeﬃ  cients models . Oxford: Clarendon Press. 

References  415
References  415
 MacKinnon, D. F. (2008).  Introduction to statistical mediation analysis . New York, NY: Psychology Press. 
 Marcoulides, G. A., & Hershberger, S. L. (1997).  Multivariate statistical methods: A ﬁ rst course . Mahwah, 
NJ: Lawrence Erlbaum. 
 McArdle, J. J. (1988). Latent variable growth within behavior genetic models.  Behavior Genetics, 16 (1), 
163–200. 
 McArdle, J. J., & Anderson, E. (1990). Latent variable growth models for research on aging. In J. E. Bir-
ren & K. W. Schaie (Eds.),  Handbook of the psychology of aging  (3rd ed., pp. 21–44). New York, NY: 
Academic Press. 
 McCaﬀ rey, D. F., Lockwood, J. R., Koretz, D., Louis, T. A., & Hamilton, L. (2004). Models for value-
added modeling of teacher eﬀ ects.  Journal of Educational and Behavioral Statistics, 291 (1), 67–101. 
 Mehta, P. D., & Neale, M. C. (2005). People are variables too: Multilevel structural equation modeling. 
 Psychological Methods, 10 (3), 259–284. 
 Meredith, W., & Tisak, J. (1990). Latent curve analysis.  Psychometrika, 55 , 107–122. 
 Morris, C. N. (1995). Hierarchical models for educational data: An overview.  Journal of Educational and 
Behavioral Statistics, 20 (2), 190–200. 
 Moss, B. G., & Yeaton, M. H. (2006). Shaping policies related to developmental education: An evaluation 
using the regression-discontinuity design.  Educational Evaluation and Policy Analysis, 28 (3), 215–229. 
 Muthén, B. O., & Satorra, A. (1995). Complex sample data in structural equation modeling. In P. V. 
Marsden (Ed.),  Sociological methodology 1995  (pp. 267–316). Boston, MA: Blackwell. 
 Muthén, L. K., & Muthén, B. O. (1998–2006).  Mplus user’s guide  (4th ed.). Los Angeles, CA: Authors. 
 Neter, N., Kutner, M., Nachtsheim, C., & Wasserman, W. (1996).  Applied linear statistical models . Chicago: 
Irwin. 
 Organization for Economic Cooperation and Development. (2009).  PISA data analysis manual  (2nd ed.). 
Paris: OECD Publishing. 
 Orsuwan, M., & Heck, R. H. (2009). Merit-based student aid and freshman interstate college migration: 
Testing a dynamic model of policy change.  Research in Higher Education, 50 , 24–51. 
 Paccagnella, O. (2006). Centering or not centering in multilevel models? Th e role of the group mean and 
the assessment of group eﬀ ects.  Evaluation Review, 30 (1), 66–85. 
 Pedhazur, E. J., & Schmelkin, L. P. (1991).  Measurement, design, and analysis: An integrated approach . Hill-
sdale, NJ: Lawrence Erlbaum. 
 Petrin, R. A. (2006).  Item nonresponse and multiple imputation for hierarchical linear models . Paper presented 
at the Annual Meeting of the American Sociological Association, Montreal, Canada. 
 Peugh, J. L., & Enders, C. K. (2004). Missing in educational research: A review of reporting practices and 
suggestions for improvement.  Review of Educational Research, 74 , 525–556. 
 Pfeﬀ ermann, D., Skinner, C. J., Holmes, D. J., Goldstein, H., & Rasbash, J. (1998). Weighting for unequal 
selection probabilities in multilevel models.  Journal of the Royal Statistical Society: Series B (Statistical 
Methodology), 60 (1), 23–40. 
 Plewis, I. (1989). Comment on “centering” predictors in multilevel analysis.  Multilevel Modeling Newsletter, 
6 , 6, 11. 
 Preacher, K. J. (2003). A primer on interaction eﬀ ects in multiple linear regression. Retrieved from http://
www.quantpsy.org/interact/interactions.htm 
 Rabe-Hesketh, S., & Skrondal, A. (2006). Multilevel modelling of complex survey data.  Journal of the Royal 
Statistical Society: Series A, 169 , 805–827. 
 Rabe-Hesketh, S., & Skrondal, A. (2008).  Multilevel and longitudinal modeling using Stata (2nd ed.). Col-
lege Station, TX: Stata Press. 
 Rasbash, J., & Browne, W. J. (2001). Modeling non-hierarchical structures. In A. H. Leyland & H. Gold-
stein (Eds.),  Multilevel modeling of health statistics (pp. 93–105). Chichester, UK: John Wiley & Sons. 
 Raudenbush, S. W. (1988). Educational applications of hierarchical linear models: A review.  Journal of 
Educational Statistics, 13 (2), 85–116. 
 Raudenbush, S. W., & Bryk, A. S. (2002).  Hierarchical linear models: Applications and data analysis methods 
(2nd ed.). Th ousand Oaks, CA: Sage. 
 Raudenbush, S. W., Bryk, A. S., Cheong, Y. F., & Congdon, R. T., Jr. (2004).  HLM 6: Hierarchical linear 
and nonlinear modeling . Lincolnwood, IL: Scientiﬁ c Software International. 
 Raykov, T., & Marcoulides, G. A. (2006).  A ﬁ rst course in structural equation modeling . Mahwah, NJ: 
 Lawrence Erlbaum. 

416  References
416  References
 Raykov, T., & Marcoulides, G. A. (2008).  An introduction to applied multivariate analysis (2nd ed.). New 
York, NY: Routledge. 
 Rigdon, E. (1998). Structural equation models. In G. Marcoulides (Ed.),  Modern methods for business research 
(pp. 251–294). Mahwah, NJ: Lawrence Erlbaum. 
 Robins, J. M., & Rotnitzky, A. (1995). Semiparametric eﬃ  ciency in multivariate regression models with 
missing data.  Journal of the American Statistical Association, 90 , 122–129. 
 Robinson, W. S. (1950). Ecological correlations and the behavior of individuals.  Sociological Review, 15 , 
351–357. 
 Rubin, D. B. (1976). Inference and missing data.  Biometrika, 63 , 581–592. 
 Sable, J., & Noel, A. (2008).  Documentation to the common core of data state nonﬁ scal survey of public elementary/
secondary education: School year 2006–07 (NCES 2009–300) . Washington, DC: National Center for 
Education Statistics, Institute of Education Sciences, U.S. Department of Education. 
 Satterthwaite, F. E. (1946). An approximate distribution of estimates of variance components.  Biometrics 
Bulletin ,  2 (6), 110–114. 
 Scherbaum, C. A., & Ferreter, J. M. (2009). Estimating statistical power and sample size requirement 
for organizational research using hierarchical linear models.  Organizational Research Methods, 12 , 
347–367. 
 Shadish, W. R., Cook, T. D., & Campbell, D. T. (2002).  Experimental and quasi-experimental designs for 
generalized causal inference . Boston, MA: Houghton Miﬄ  in. 
 Singer, J. D., & Willett, J. B. (2003).  Applied longitudinal data analysis: Modeling change and event occurrence . 
New York, NY: Oxford University Press. 
 Skinner, C. J. (2005).  Th e use of survey weights in multilevel modelling . Paper presented at the Workshop on 
Latent Variable Models and Survey Data for Social Science Research, Montreal, Canada. 
 Snijders, T. A. B. (2005). Power and sample size in multilevel linear models. In B. S. Everitt & D. C. Howell 
(Eds.),  Encyclopedia of statistics in behavioral sciences (Vol. 3, pp. 1570–1573). New York, NY: Wiley. 
 Snijders, T. A. B., & Bosker, R. (1999).  Multilevel analysis: An introduction to basic and advanced multilevel 
modeling . Th ousand Oaks, CA: Sage. 
 Snijders, T. A. B., & Bosker, R. J. (1994). Modeled variance in two-level models.  Sociological Methods & 
Research, 22 (3), 342–363. 
 Stapleton, L. M. (2002). Th e incorporation of sample weights into multilevel structural equation models. 
 Structural Equation Modeling, 9 (4), 475–502. 
 Tabachnick, B. G. (2008, March).  Multivariate statistics: An introduction and some applications . Workshop 
presented to the American Psychology-Law Society, Jacksonville, FL. 
 Th omas, S. L., & Heck, R. H. (2001). Analysis of large-scale secondary data in higher education research: 
Potential perils associated with complex sampling designs.  Research in Higher Education, 42 (5), 
517–540. 
 Th um, Y. M. (2003). Examining teacher productivity using a multivariate multilevel model for value-
added analysis.  Sociological Methods and Research, 32 (2), 153–207. 
 Trochim, W. M. K. (1984).  Research designs for program evaluation . Beverly Hills, CA: Sage. 
 van Buuren, S. (2011). Multiple imputation of multilevel data. In J. J. Hox & J. K. Roberts (Eds.),  Handbook 
of advanced multilevel analysis  (pp. 173–196). New York, NY: Routledge. 
 Verbeke, G., & Lesaﬀ re, E. (1997). Th e eﬀ ect of misspecifying the random-eﬀ ects distribution in linear 
mixed models for longitudinal data.  Computational Statistics and Data Analysis, 23 , 541–556. 
 Willett, J. B. (1989). Some results on the reliability for the longitudinal measurement of change: Implica-
tions for the design of studies of individual growth.  Educational and Psychological Measurement, 49 , 
587–602. 
 Wright, S. P. (1998).  Multivariate analysis using the MIXED procedure . Paper presented at the Twenty-Th ird 
Annual Meeting of the SAS Users Group International Conference 23, March 22–25, Nashville, 
TN. Retrieved from http:/ww2.sas.com/proceedings/sugi23/Stats/p229.pdf 
 Zhang, D. (2005).  A Monte Carlo investigation of robustness to nonnormal incomplete data of multilevel modeling 
(unpublished doctoral dissertation). Texas A&M University, College Station, TX. Retrieved from 
http://repository.tamu.edu/handle/1969.1/4405 

417
 Appendix A: Syntax Statements 
 Please note that syntax statements may be obtained through the “Paste” feature in the IBM SPSS 
menu interface. Th e syntax statements give information about the model such as the routine and 
the dependent variable (MIXED math) and the grouping variable [SUBJECT(schcode)]. Th e /
FIXED command speciﬁ es the ﬁ xed eﬀ ects in the model (i.e., achievement and the intercept), 
the random eﬀ ects (/RANDOM = INTERCEPT), the type of covariance matrix (COVTYPE = 
VARIANCE COMPONENTS), and the estimation method (METHOD = MAXIMUM 
LIKELIHOOD). When using the “Paste” command, the estimation method will display a /
CRITERIA command line 1 detailing settings for the method, iterations, log-likelihood con-
vergence, parameter convergence, Hessian convergence, maximum scoring steps, and singularity 
tolerance. Th is line has been omitted for the models in this section but may be viewed in the 
syntax ﬁ les (.sps) accompanying the data sets for each chapter and is available for downloading 
from the publisher’s Web site. 
 Using the syntax can be useful in making quick changes to the model as well as helping to 
keep a record of what models have been developed. Th ey should be saved in a manner that allows 
easy referencing for future use (e.g., RprofMod1.sps and RprofMod2.sps). 
 Chapter 3: Deﬁ ning a Basic Two-Level Multilevel Regression Model ( ch3multilevel.sav ) 
 Tables 3.2 and  3.3 ( ch3multilevel.sav ) 
 REGRESSION 
 /MISSING LISTWISE 
 /STATISTICS COEFF OUTS R ANOVA 
 /CRITERIA = PIN(.05) POUT(.10) 
 /NOORIGIN 
 /DEPENDENT math 
 /METHOD = ENTER ses. 
 Step 1: Examining Variance Components Using the Null Model 
 Model 1 (Null):  Tables 3.4 ,  3.5 ,  3.6 , and  3.7 ( ch3multilevel.sav ) 
 MIXED math 
 /FIXED = | SSTYPE(3) 
 /METHOD = REML 
 /PRINT = G SOLUTION TESTCOV 
 /RANDOM = INTERCEPT | SUBJECT(schcode) COVTYPE(VC). 
 Step 2: Building the Individual-Level (or Level 1) Random Intercept Model 
 Model 2:  Tables 3.8 ,  3.9 ,  3.10 ,  3.11 , and  3.12 ( ch3multilevel.sav ) 
 MIXED math WITH ses 
 /FIXED = ses | SSTYPE(3) 
 /METHOD = REML 
 /PRINT = G SOLUTION TESTCOV 
 /RANDOM = INTERCEPT | SUBJECT(schcode) COVTYPE(VC). 
1. CRITERIA = CIN(95) MXITER(100) MXSTEP(10) SCORING(1) SINGULAR(0.000000000001) HCONVERGE(0, AB-
SOLUTE) LCONVERGE(0, ABSOLUTE) PCONVERGE(0.000001, ABSOLUTE)

418  Appendix A: Syntax Statements
418   Appendix A: Syntax Statements 
 Step 3: Building the Group-Level (or Level 2) Random Intercept Model 
 Model 3:  Tables 3.13 and  3.14 ( ch3multilevel.sav ) 
 MIXED math BY public WITH ses_mean pro4yrc ses 
 /FIXED = public ses_mean pro4yrc ses | SSTYPE(3) 
 /METHOD = REML 
 /PRINT = G SOLUTION TESTCOV 
 /RANDOM = INTERCEPT | SUBJECT(schcode) COVTYPE(VC). 
 Treat “Public” Variable as a Covariate 
 Model 3A:  Tables 3.15 and  3.16 ( ch3multilevel.sav ) 
 MIXED math WITH public ses_mean pro4yrc ses 
 /FIXED = public ses_mean pro4yrc ses | SSTYPE(3) 
 /METHOD = REML 
 /PRINT = G SOLUTION TESTCOV 
 /RANDOM = INTERCEPT | SUBJECT(schcode) COVTYPE(VC). 
 Step 4: Adding a Randomly Varying Slope (the Random Slope and Intercept Model) 
 Model 4:  Tables 3.17 ,  3.18 , and  3.19 ( ch3multilevel.sav ) 
 MIXED math WITH public ses_mean pro4yrc ses 
 /CRITERIA = CIN(95) MXITER(100) MXSTEP(10) SCORING(1) SINGULAR(0.000000000001) 
HCONVERGE(0, ABSOLUTE) LCONVERGE(0, ABSOLUTE) PCONVERGE(0.000001, ABSOLUTE) 
 /FIXED = public ses_mean pro4yrc ses | SSTYPE(3) 
 /METHOD = REML 
 /PRINT = G SOLUTION TESTCOV 
 /RANDOM = INTERCEPT ses | SUBJECT(schcode) COVTYPE(VC). 
 Step 5:  Explaining Variability in the Random Slope (More Complex Random Slopes and Intercept 
Models) 
 Table 3.20 ( ch3multilevel.sav ) 
 MIXED math WITH ses_mean ses 
 /FIXED = ses_mean ses ses*ses_mean | SSTYPE(3) 
 /METHOD = REML 
 /PRINT = G SOLUTION TESTCOV 
 /RANDOM = INTERCEPT | SUBJECT(schcode) COVTYPE(ID). 
 Step 5:  Explaining Variability in the Random Slope (More Complex Random Slopes and Intercept 
Models) 
 Model 5:  Tables 3.21 ,  3.22 , and  3.23 ( ch3multilevel.sav ) 
 MIXED math WITH public ses_mean pro4yrc ses 
 /FIXED = public ses_mean pro4yrc ses ses_mean*ses pro4yrc*ses public*ses | 
SSTYPE(3) 
 /METHOD = REML 
 /PRINT = G SOLUTION TESTCOV 
 /RANDOM = INTERCEPT ses | SUBJECT(schcode) COVTYPE(VC). 

Appendix A: Syntax Statements  419
 Removed Nonsigniﬁ cant Interactions (ses_mean*ses, pro4yrc*ses) 
 Model 5A:  Table 3.24 ( ch3multilevel.sav ) 
 MIXED math WITH public ses_mean pro4yrc ses 
 /FIXED = public ses_mean pro4yrc ses public*ses | SSTYPE(3) 
 /METHOD = REML 
 /PRINT = G SOLUTION TESTCOV 
 /RANDOM = INTERCEPT ses | SUBJECT(schcode) COVTYPE(VC). 
 Chapter 4: Three-Level Univariate Regression Models ( ch4threelevelURM.sav ) 
 Model 1 (Null):  Table 4.2 ( ch4threelevelURM.sav ) 
 MIXED math 
 /FIXED = | SSTYPE(3) 
 /METHOD = ML 
 /PRINT = G SOLUTION TESTCOV 
 /RANDOM = INTERCEPT | SUBJECT(schcode) COVTYPE(ID) 
 /RANDOM = INTERCEPT | SUBJECT(schcode*Rteachid) COVTYPE(ID). 
 Deﬁ ning Predictors at Each Level 
 Model 2:  Table 4.4 ( ch4threelevelURM.sav ) 
 MIXED math WITH gmschlowSES_mean gmaggtcheffect gmteacheffect gmclasslowses_
mean gmlowses 
 /FIXED = gmschlowSES_mean gmaggtcheffect gmteacheffect gmclasslowses_mean gm-
lowses | SSTYPE(3) 
 /METHOD = ML 
 /PRINT = G SOLUTION TESTCOV 
 /RANDOM = INTERCEPT | SUBJECT(schcode) COVTYPE(ID) 
 /RANDOM = INTERCEPT | SUBJECT(schcode*Rteachid) COVTYPE(ID). 
 Group-Mean Centering 
 Model 3:  Tables 4.5 and  4.6 ( ch4threelevelURM.sav ) 
 MIXED math WITH gmschlowSES_mean gmaggtcheffect groupteacheffect groupclass-
lowses_mean grouplowses 
 /FIXED = gmschlowSES_mean gmaggtcheffect groupteacheffect groupclasslowses_
mean grouplowses | SSTYPE(3) 
 /METHOD = ML 
 /PRINT = G SOLUTION TESTCOV 
 /RANDOM = INTERCEPT | SUBJECT(schcode) COVTYPE(ID) 
 /RANDOM = INTERCEPT | SUBJECT(schcode*Rteachid) COVTYPE(ID). 
 Does the Slope Vary Randomly Across Schools? 
 Model 4:  Tables 4.7 ,  4.8 , and  4.13 ( ch4threelevelURM.sav ) 
 MIXED math WITH gmschlowSES_mean gmaggtcheffect gmteacheffect gmclasslowses_
mean gmlowses 

420  Appendix A: Syntax Statements
420   Appendix A: Syntax Statements 
 /FIXED = gmschlowSES_mean gmaggtcheffect gmteacheffect gmclasslowses_mean gm-
lowses | SSTYPE(3) 
 /METHOD = ML 
 /PRINT = G SOLUTION TESTCOV 
 /RANDOM = INTERCEPT gmteacheffect | SUBJECT(schcode) COVTYPE(UN) 
 /RANDOM = INTERCEPT | SUBJECT(schcode*Rteachid) COVTYPE(ID). 
 Preliminary Investigation of the Interaction 
 Test Interaction Model A:  Table 4.9 ( ch4threelevelURM.sav ) 
 MIXED math WITH teacheffect classlowses_mean 
 /FIXED = teacheffect classlowses_mean teacheffect*classlowses_mean | SSTYPE(3) 
 /METHOD = ML 
 /PRINT = G SOLUTION TESTCOV 
 /RANDOM = INTERCEPT | SUBJECT(schcode) COVTYPE(ID) 
 /RANDOM = INTERCEPT | SUBJECT(schcode*Rteachid) COVTYPE(ID). 
 Table 4.10 : Test Interaction Model B (Grand-Mean-Centered Variables) ( ch4threelevelURM.sav ) 
 MIXED math WITH gmteacheffect gmclasslowses_mean 
 /FIXED = gmteacheffect gmclasslowses_mean gmteacheffect*gmclasslowses_mean | 
SSTYPE(3) 
 /METHOD = ML 
 /PRINT = G SOLUTION TESTCOV 
 /RANDOM = INTERCEPT | SUBJECT(schcode) COVTYPE(ID) 
 /RANDOM = INTERCEPT | SUBJECT(schcode*Rteachid) COVTYPE(ID). 
 Examining a Level 2 Interaction 
 Model 5:  Tables 4.11 ,  4.12 , and  4.14 ( ch4threelevelURM.sav ) 
 MIXED math WITH gmschlowSES_mean gmaggtcheffect gmteacheffect gmclasslowses_
mean gmlowses 
 /FIXED = gmschlowSES_mean gmaggtcheffect gmteacheffect gmclasslowses_mean gm-
classlowses_mean*gmteacheffect gmlowses | SSTYPE(3) 
 /METHOD = ML 
 /PRINT = G SOLUTION TESTCOV 
 /RANDOM = INTERCEPT gmteacheffect | SUBJECT(schcode) COVTYPE(UN) 
 /RANDOM = INTERCEPT | SUBJECT(schcode*Rteachid) COVTYPE(ID). 
 Chapter 5: Examining Individual Change with Repeated Measures 
Data ( ch5growthdata-vertical.sav ,  ch5growthdata-horizontal.sav , and 
 ch5experimentaldesigndata.sav ) 
 Graphing the Linear and Nonlinear Growth Trajectories 
 Figures 5.2 ,  5.3 , and  5.4 (Select Cases and Generate Graph) ( ch5growthdata-vertical.sav ) 
 Select Subset of Individuals 
 USE ALL. 
 COMPUTE  lter_$ = (id < 18). 

Appendix A: Syntax Statements  421
 VARIABLE LABELS  lter_$ ‘id < 18 (FILTER)’. 
 VALUE LABELS  lter_$ 0 ‘Not Selected’ 1 ‘Selected’. 
 FORMATS  lter_$ (f1.0). 
 FILTER BY  lter_$. 
 EXECUTE. 
 Figures 5.2 ,  5.3 , and  5.4 ( ch5growthdata-vertical.sav ) 
 (Variations are achieved by changing the Chart Editor’s Properties options.) 
 GRAPH 
 /SCATTERPLOT(BIVAR) = time WITH test BY id 
 /MISSING = LISTWISE. 
 Coding Time Interval Variables (time to quadtime) ( ch5growthdata-vertical.sav ) 
 RECODE time (0 = 0) (1 = 1) (2 = 4) INTO quadtime. 
 EXECUTE. 
 Coding Time Interval Variables (time to orthtime and orthquad) ( ch5growthdata-vertical.sav ) 
 orthtime 
 RECODE time (0 = 1) (1 = 0) (2 = 1) INTO orthtime. 
 EXECUTE. 
 orthquad 
 RECODE time (0 = 1) (1 = -2) (2 = 1) INTO orthquad. 
 EXECUTE. 
 Model with No Predictors 
 Model 1.1:  Table 5.4 ( ch5growthdata-vertical.sav ) 
 MIXED test WITH time quadtime 
 /FIXED = | SSTYPE(3) 
 /METHOD = REML 
 /PRINT = G SOLUTION TESTCOV 
 /RANDOM = INTERCEPT | SUBJECT(id) COVTYPE(ID) 
 /REPEATED = Index1 | SUBJECT(id) COVTYPE(ID). 
 What Is the Shape of the Trajectory? 
 Model 1.1A:  Tables 5.5 and  5.6 ( ch5growthdata-vertical.sav ) 
 MIXED test WITH time quadtime 
 /FIXED = time quadtime | SSTYPE(3) 
 /METHOD = REML 
 /PRINT = G SOLUTION TESTCOV 
 /RANDOM = INTERCEPT | SUBJECT(id) COVTYPE(ID) 
 /REPEATED = Index1 | SUBJECT(id) COVTYPE(ID). 
 Does the Time-Related Slope Vary Across Groups? 
 Model 1.1B:  Tables 5.7 ,  5.8 , and  5.9 ( ch5growthdata-vertical.sav ) 

422  Appendix A: Syntax Statements
422   Appendix A: Syntax Statements 
 MIXED test WITH time quadtime 
 /FIXED = time quadtime | SSTYPE(3) 
 /METHOD = REML 
 /PRINT = G SOLUTION TESTCOV 
 /RANDOM = INTERCEPT time | SUBJECT(id) COVTYPE(UN) 
 /REPEATED = Index1 | SUBJECT(id) COVTYPE(ID). 
 Examining Orthogonal Components 
 Model 1.2:  Tables 5.10 and  5.12 ( ch5growthdata-vertical.sav ) 
 MIXED test WITH orthtime orthquad 
 /FIXED = orthtime orthquad | SSTYPE(3) 
 /METHOD = REML 
 /PRINT = G SOLUTION TESTCOV 
 /RANDOM = INTERCEPT orthtime | SUBJECT(id) COVTYPE(UN) 
 /REPEATED = Index1 | SUBJECT(id) COVTYPE(ID). 
 Investigating Other Level 1 Covariance Structures 
 Repeated Measures ANOVA Tests of Within-Subjects Contrasts 
 Table 5.11 ( ch5growthdata-horizontal.sav ) 
 GLM test1 test2 test3 
 /WSFACTOR = time 3 Polynomial 
 /MEASURE = test 
 /METHOD = SSTYPE(3) 
 /EMMEANS = TABLES(OVERALL) 
 /EMMEANS = TABLES(time) 
 /PRINT = OPOWER HOMOGENEITY 
 /CRITERIA = ALPHA(.05) 
 /WSDESIGN = time. 
 Investigating Other Level 1 Covariance Structures 
 Model 1:  Table 5.13 Identity Covariance Matrix, Level 1; Unstructured Covariance Matrix, Level 2 
( ch5growthdata-vertical.sav ) 
 MIXED test WITH orthtime orthquad 
 /FIXED = orthtime orthquad | SSTYPE(3) 
 /METHOD = REML 
 /PRINT = G SOLUTION TESTCOV 
 /RANDOM = INTERCEPT orthtime | SUBJECT(id) COVTYPE(UN) 
 /REPEATED = Index1 | SUBJECT(id) COVTYPE(ID). 
 Investigating Other Level 1 Covariance Structures 
 Model 2:  Table 5.13 Diagonal Covariance Matrix, Level 1; Diagonal Covariance Matrix, Level 2 
( ch5growthdata-vertical.sav ) 
 MIXED test WITH orthtime orthquad 
 /FIXED = orthtime orthquad | SSTYPE(3) 
 /METHOD = REML 

Appendix A: Syntax Statements  423
 /PRINT = G SOLUTION TESTCOV 
 /RANDOM = INTERCEPT orthtime | SUBJECT(id) COVTYPE(DIAG) 
 /REPEATED = Index1 | SUBJECT(id) COVTYPE(DIAG). 
 Investigating Other Level 1 Covariance Structures 
 Model 3:  Table 5.13 Diagonal Covariance Matrix, Level 1; Unstructured Covariance Matrix, 
Level 2 ( ch5growthdata-vertical.sav ) 
 MIXED test WITH orthtime orthquad 
 /FIXED = orthtime orthquad | SSTYPE(3) 
 /METHOD = REML 
 /PRINT = G SOLUTION TESTCOV 
 /RANDOM = INTERCEPT orthtime | SUBJECT(id) COVTYPE(UN) 
 /REPEATED = Index1 | SUBJECT(id) COVTYPE(DIAG). 
 Investigating Other Level 1 Covariance Structures 
 Model 4:  Table 5.13 Autoregressive Covariance Matrix, Level 1; Diagonal Covariance Matrix, 
Level 2 ( ch5growthdata-vertical.sav ) 
 MIXED test WITH orthtime orthquad 
 /FIXED = orthtime orthquad | SSTYPE(3) 
 /METHOD = REML 
 /PRINT = G SOLUTION TESTCOV 
 /RANDOM = INTERCEPT orthtime | SUBJECT(id) COVTYPE(DIAG) 
 /REPEATED = Index1 | SUBJECT(id) COVTYPE(AR1). 
 Adding the Between-Subjects Predictors 
 Model 1.3:  Tables 5.15 ,  5.16 , and  5.17 ( ch5growthdata-vertical.sav ) 
 MIXED test WITH orthtime orthquad ses effective 
 /FIXED = ses effective orthtime ses*orthtime effective*orthtime orthquad | 
SSTYPE(3) 
 /METHOD = REML 
 /PRINT = G SOLUTION TESTCOV 
 /RANDOM = INTERCEPT orthtime | SUBJECT(id) COVTYPE(UN) 
 /REPEATED = Index1 | SUBJECT(id) COVTYPE(DIAG). 
 Tests of within-Subjects Contrasts (Repeated Measures ANOVA, Tests of within-Subject 1`
Contrasts) 
 Table 5.18 ( ch5growthdata-horizontal.sav ) 
 GLM test1 test2 test3 BY effective WITH ses 
 /WSFACTOR = time 3 Polynomial 
 /MEASURE = test 
 /METHOD = SSTYPE(3) 
 /EMMEANS = TABLES(OVERALL) WITH(ses = MEAN) 
 /EMMEANS = TABLES(time) WITH(ses = MEAN) 
 /PRINT = OPOWER HOMOGENEITY 
 /CRITERIA = ALPHA(.05) 
 /WSDESIGN = time 
 /DESIGN = ses effective. 

424  Appendix A: Syntax Statements
424   Appendix A: Syntax Statements 
 Graphing the Growth Rate Trajectories 
 Figure 5.8 : Growth Rate Trajectories by Teacher Effectiveness ( ch5growthdata-vertical.sav ) 
 GRAPH 
 /LINE(MULTIPLE) = MEAN(test) BY time BY effective. 
 Recoding time to timenonlin1 
 Examining Growth Using an Alternative Speciﬁ cation of the Time-Related Variable 
 Coding Time Interval Variables 
 Recoding time to timenonlin1 ( ch5growthdata-vertical.sav ) 
 RECODE time (0 = 0) (1 = 0.5) (2 = 1) INTO timenonlin1. 
 EXECUTE. 
 Recoding time to timenonlin2 ( ch5growthdata-vertical.sav ) 
 RECODE time (0 = 0) (1 = 0.6) (2 = 1) INTO timenonlin2. 
 EXECUTE. 
 Recoding time to timenonlin3 ( ch5growthdata-vertical.sav ) 
 RECODE time (0 = 0) (1 = 0.7) (2 = 1) INTO timenonlin3. 
 EXECUTE. 
 Recoding time to timenonlin ( ch5growthdata-vertical.sav ) 
 RECODE time (0 = 0) (1 = .53) (2 = 1) INTO timenonlin. 
 EXECUTE. 
 Table 5.20 ( ch5growthdata-vertical.sav ) 
 MIXED test WITH timenonlin1 
 /FIXED = timenonlin1 | SSTYPE(3) 
 /METHOD = REML 
 /PRINT = G SOLUTION TESTCOV 
 /RANDOM = INTERCEPT timenonlin1 | SUBJECT(id) COVTYPE(UN) 
 /REPEATED = Index1 | SUBJECT(id) COVTYPE(DIAG). 
 Estimating the Final Time-Related Model 
 Model 2.1: ( ch5growthdata-vertical.sav ) 
 MIXED test WITH timenonlin 
 /FIXED = timenonlin | SSTYPE(3) 
 /METHOD = REML 
 /PRINT = G SOLUTION TESTCOV 
 /RANDOM = INTERCEPT timenonlin | SUBJECT(id) COVTYPE(UN) 
 /REPEATED = Index1 | SUBJECT(id) COVTYPE(DIAG). 
 Adding the Two Predictors 
 Model 2.2:  Tables 5.21 and  5.22 ( ch5growthdata-vertical.sav ) 
 MIXED test WITH timenonlin ses effective 

Appendix A: Syntax Statements  425
 /FIXED = ses effective timenonlin ses*timenonlin effective*timenonlin | 
SSTYPE(3) 
 /METHOD = REML 
 /PRINT = G SOLUTION TESTCOV 
 /RANDOM = INTERCEPT timenonlin | SUBJECT(id) COVTYPE(UN) 
 /REPEATED = Index1 | SUBJECT(id) COVTYPE(DIAG). 
 An Example Experimental Design 
 Tables 5.24 and  5.25 ( ch5experimentaldesigndata.sav ) 
 MIXED math WITH time treatment 
 /FIXED = treatment time time*treatment | SSTYPE(3) 
 /METHOD = REML 
 /PRINT = G SOLUTION TESTCOV 
 /RANDOM = INTERCEPT time | SUBJECT(id) COVTYPE(UNR) 
 /REPEATED = time | SUBJECT(id) COVTYPE(DIAG). 
 Table 5.26 ( ch5experimentaldesigndata.sav ) 
 MIXED math By time WITH treatment 
 /FIXED = treatment time time*treatment | SSTYPE(3) 
 /METHOD = REML 
 /PRINT = G SOLUTION TESTCOV 
 /RANDOM = INTERCEPT | SUBJECT(id) COVTYPE(UNR) 
 /REPEATED = time | SUBJECT(id) COVTYPE(DIAG). 
 Table 5.27 ( ch5experimentaldesigndata.sav ) 
 MIXED math WITH timenonlin treatment 
 /FIXED = treatment timenonlin timenonlin*treatment | SSTYPE(3) 
 /METHOD = REML 
 /PRINT = G SOLUTION TESTCOV 
 /RANDOM = INTERCEPT timenonlin | SUBJECT(id) COVTYPE(VC) 
 /REPEATED = time | SUBJECT(id) COVTYPE(DIAG). 
 Chapter 6: Methods for Examining Organizational-Level Change ( ch6graduationdata.sav 
and  ch6RD-1data.sav ) 
 Model 1.1 (Null):  Tables 6.2 and  6.3 ( ch6graduationdata.sav ) 
 MIXED gradproportion 
 /FIXED = | SSTYPE(3) 
 /METHOD = REML 
 /PRINT = COVB SOLUTION TESTCOV 
 /RANDOM = INTERCEPT | SUBJECT(stateid) COVTYPE(ID) 
 /RANDOM = INTERCEPT | SUBJECT(rid*stateid) COVTYPE(ID) 
 /REPEATED = time | SUBJECT(rid*stateid) COVTYPE(AR1). 
 Adding Growth Rates 
 Model 1.2:  Tables 6.6 and  6.7 ( ch6graduationdata.sav ) 
 MIXED gradproportion WITH time1 
 /FIXED = time1 | SSTYPE(3) 
 /METHOD = REML 

426  Appendix A: Syntax Statements
426   Appendix A: Syntax Statements 
 /PRINT = COVB SOLUTION TESTCOV 
 /RANDOM = INTERCEPT time1 | SUBJECT(stateid) COVTYPE(DIAG) 
 /RANDOM = INTERCEPT time1 | SUBJECT(rid*stateid) COVTYPE(DIAG) 
 /REPEATED = time | SUBJECT(rid*stateid) COVTYPE(AR1). 
 Adding Time-Varying Covariates 
 Model 1.3:  Tables 6.8 and  6.9 ( ch6graduationdata.sav ) 
 MIXED gradproportion WITH percentFinAid tuition time1 
 /FIXED = percentFinAid tuition time1 | SSTYPE(3) 
 /METHOD = REML 
 /PRINT = COVB SOLUTION TESTCOV 
 /RANDOM = INTERCEPT time1 | SUBJECT(stateid) COVTYPE(DIAG) 
 /RANDOM = INTERCEPT time1 | SUBJECT(rid*stateid) COVTYPE(DIAG) 
 /REPEATED = time | SUBJECT(rid*stateid) COVTYPE(AR1). 
 Explaining Differences in Growth Trajectories Between Institutions 
 Model 1.4:  Tables 6.10 and  6.11 ( ch6graduationdata.sav ) 
 MIXED gradproportion WITH aveFamilyshare aveRetention mathselect percentFTfac-
ulty percentFinAid tuition time1 
 /FIXED = aveFamilyshare aveRetention mathselect percentFTfaculty percentFi-
nAid tuition time1 time1*mathselect time1*percentFTfaculty | SSTYPE(3) 
 /METHOD = REML 
 /PRINT = COVB SOLUTION TESTCOV 
 /RANDOM = INTERCEPT time1 | SUBJECT(stateid) COVTYPE(DIAG) 
 /RANDOM = INTERCEPT time1 | SUBJECT(rid*stateid) COVTYPE(DIAG) 
 /REPEATED = time | SUBJECT(rid*stateid) COVTYPE(AR1). 
 Adding a Model to Examine Growth Rates at Level 3 
 Model 1.5:  Tables 6.12 and  6.13 ( ch6graduationdata.sav ) 
 MIXED gradproportion WITH aveFamilyshare aveRetention mathselect percentFTfac-
ulty percentFinAid tuition time1 
 /FIXED = aveFamilyshare aveRetention mathselect percentFTfaculty percentFi-
nAid tuition time1 time1*aveFamilyshare time1*aveRetention time1*mathselect 
time1*percentFTfaculty | SSTYPE(3) 
 /METHOD = REML 
 /PRINT = COVB SOLUTION TESTCOV 
 /RANDOM = INTERCEPT time1 | SUBJECT(stateid) COVTYPE(DIAG) 
 /RANDOM = INTERCEPT time1 | SUBJECT(rid*stateid) COVTYPE(DIAG) 
 /REPEATED = time | SUBJECT(rid*stateid) COVTYPE(AR1). 
 Regression Discontinuity Models to Explain Learning Differences 
 Model 2.1:  Tables 6.16 and  6.17 ( ch6RD-1data.sav ) 
 MIXED nmath WITH npretest treatment 
 /FIXED = npretest treatment | SSTYPE(3) 
 /METHOD = REML 
 /PRINT = COVB SOLUTION TESTCOV 
 /RANDOM = INTERCEPT treatment | SUBJECT(teachcode) COVTYPE(UN). 

Appendix A: Syntax Statements  427
 Adding Explanatory Variables at Level 2 
 Model 2.2:  Table 6.18 ( ch6RD-1data.sav ) 
 MIXED nmath WITH teachqual classcomp npretest treatment 
 /FIXED 
= 
teachqual 
classcomp 
npretest 
treatment 
teachqual*treatment 
classcomp*treatment | SSTYPE(3) 
 /METHOD = REML 
 /PRINT = COVB SOLUTION TESTCOV 
 /RANDOM = INTERCEPT treatment | SUBJECT(teachcode) COVTYPE(UN). 
 Establishing the Prepolicy and Policy Trends 
 Model 3.1:  Tables 6.20 ,  6.21 , and  6.22 ( ch6RD-2data.sav ) 
 MIXED freshadmit WITH implement0 implement1 
 /FIXED = implement0 implement1 | SSTYPE(3) 
 /METHOD = REML 
 /PRINT = COVB SOLUTION TESTCOV 
 /RANDOM = INTERCEPT | SUBJECT(schid) COVTYPE(ID) 
 /REPEATED = Index1 | SUBJECT(schid) COVTYPE(DIAG). 
 Final Model with Covariates Added 
 Model 3.2:  Tables 6.23 and  6.24 ( ch6RD-2data.sav ) 
 MIXED freshadmit WITH private prestige implement0 implement1 
 /FIXED 
= 
private 
prestige 
implement0 
implement1 
implement0*private 
implement0*prestige implement1*private implement1*prestige | SSTYPE(3) 
 /METHOD = REML 
 /PRINT = COVB SOLUTION TESTCOV 
 /RANDOM = INTERCEPT | SUBJECT(schid) COVTYPE(ID) 
 /REPEATED = Index1 | SUBJECT(schid) COVTYPE(DIAG). 
 Chapter 7: Multivariate Multilevel Models ( ch7latentconstructs.sav ,  ch7worklifeorg.sav , 
 ch7achievement.sav , and  ch7PGachievement.sav ) 
 Table 7.2 ( ch7latentconstructs.sav ) 
 DESCRIPTIVES VARIABLES = W1varied W2value W3team P1assess P2progress P3evstand 
 /STATISTICS = MEAN STDDEV KURTOSIS SKEWNESS. 
 Table 7.3 ( ch7latentconstructs.sav ) 
 FACTOR 
 /VARIABLES W1varied W2value W3team P1assess P2progress P3evstand 
 /MISSING LISTWISE 
 /ANALYSIS W1varied W2value W3team P1assess P2progress P3evstand 
 /PRINT INITIAL EXTRACTION 
 /CRITERIA FACTORS(2) ITERATE(25) 
 /EXTRACTION PAF 
 /ROTATION NOROTATE 
 /METHOD = CORRELATION. 

428  Appendix A: Syntax Statements
428   Appendix A: Syntax Statements 
 Table 7.4 ( ch7latentconstructs.sav ) 
 FACTOR 
 /VARIABLES W1varied W2value W3team P1assess P2progress P3evstand 
 /MISSING LISTWISE 
 /ANALYSIS W1varied W2value W3team P1assess P2progress P3evstand 
 /PRINT INITIAL EXTRACTION ROTATION 
 /CRITERIA FACTORS(2) ITERATE(25) 
 /EXTRACTION PAF 
 /CRITERIA ITERATE(25) DELTA(0) 
 /ROTATION OBLIMIN 
 /METHOD = CORRELATION. 
 Model 1.1 (Null):  Tables 7.5 ,  7.6 , and  7.7 ( ch7worklifeorg.sav ) 
 MIXED work by assessjob 
 /FIXED = assessjob | noint SSTYPE(3) 
 /METHOD = REML 
 /PRINT = G SOLUTION TESTCOV 
 /Random = assessjob | Subject (orgcode) COVTYPE(DIAG) 
 /Random = assessjob | Subject(Rid*orgcode) COVTYPE(DIAG) 
 /REPEATED = Index1 | SUBJECT(orgcode*Rid) COVTYPE(ID). 
 Table 7.8 ( ch7worklifeorg.sav ) 
 MIXED work by assessjob 
 /FIXED = assessjob | noint SSTYPE(3) 
 /METHOD = REML 
 /PRINT = G SOLUTION TESTCOV 
 /Random = assessjob | Subject (orgcode) COVTYPE(UNR) 
 /Random = assessjob | Subject(Rid*orgcode) COVTYPE(UNR) 
 /REPEATED = Index1 | SUBJECT(orgcode*Rid) COVTYPE(ID). 
 Model 1.2 (Final Null Model):  Table 7.10 ( ch7worklifeorg.sav ) 
 MIXED work by assessjob 
 /FIXED = assessjob | noint SSTYPE(3) 
 /METHOD = REML 
 /PRINT = G SOLUTION TESTCOV 
 /Random = assessjob | Subject (orgcode) COVTYPE(UNR) 
 /Random = assessjob | Subject(Rid*orgcode) COVTYPE(UNR) 
 /REPEATED = Index1 | SUBJECT(orgcode*Rid) COVTYPE(DIAG). 
 Adding Level 2 Predictors 
 Model 1.3:  Tables 7.11 ,  7.12 , and  7.13 ( ch7worklifeorg.sav ) 
 MIXED work by assessjob with stability female 
 /FIXED = assessjob stability*assessjob female*assessjob | noint SSTYPE(3) 
 /METHOD = REML 
 /PRINT = G SOLUTION TESTCOV 
 /Random = assessjob | Subject (orgcode) COVTYPE(UNR) 
 /Random = assessjob | Subject(Rid*orgcode) COVTYPE(UNR) 
 /REPEATED = Index1 | SUBJECT(orgcode*Rid) COVTYPE(DIAG). 

Appendix A: Syntax Statements  429
 Adding the Organizational Predictors 
 Model 1.4:  Tables 7.14 and  7.15 ( ch7worklifeorg.sav ) 
 MIXED work by assessjob with female stability gmresources gmorgprod 
 /FIXED = assessjob gmorgprod*assessjob gmresources*assessjob stability*assessjob 
female*assessjob| noint SSTYPE(3) 
 /METHOD = ML 
 /PRINT = G SOLUTION TESTCOV 
 /Random = assessjob | Subject (orgcode) COVTYPE(UN) 
 /Random = assessjob | Subject(orgcode*Rid) COVTYPE(UN) 
 /REPEATED = Index1 | SUBJECT(orgcode*Rid) COVTYPE(DIAG). 
 Examining Equality Constraints 
 Table 7.16 ( ch7worklifeorg.sav ) 
 MIXED work by assessjob with female stability gmresources gmorgprod 
 /FIXED = assessjob female stability gmorgprod gmresources| noint SSTYPE(3) 
 /METHOD = ML 
 /PRINT = G SOLUTION TESTCOV 
 /Random = assessjob | Subject (orgcode) COVTYPE(UN) 
 /Random = assessjob | Subject(orgcode*Rid) COVTYPE(UN) 
 /REPEATED = Index1 | SUBJECT(orgcode*Rid) COVTYPE(DIAG). 
 Investigating a Random Level 2 Slope 
 Deﬁ ning Models 1.6 and 1.7 with IBM SPSS Menu Commands 
 Model 1.6 ( ch7worklifeorg.sav ) 
 MIXED work by assessjob with female stability gmresources gmorgprod 
 /FIXED = assessjob female stability gmorgprod gmresources| noint SSTYPE(3) 
 /METHOD = ML 
 /PRINT = G SOLUTION TESTCOV 
 /Random = assessjob stability | Subject (orgcode) COVTYPE(DIAG) 
 /Random = assessjob | Subject(orgcode*Rid) COVTYPE(UN) 
 /REPEATED = Index1 | SUBJECT(orgcode*Rid) COVTYPE(DIAG). 
 Model 1.7 ( ch7worklifeorg.sav ) 
 MIXED work by assessjob with female stability gmresources gmorgprod 
 /FIXED = assessjob gmorgprpd*assessjob gmresources*assessjob stability*assessjob 
female*assessjob| noint SSTYPE(3) 
 /METHOD = ML 
 /PRINT = G SOLUTION TESTCOV 
 /Random = assessjob stability | Subject (orgcode) COVTYPE(DIAG) 
 /Random = assessjob | Subject(orgcode*Rid) COVTYPE(UN) 
 /REPEATED = Index1 | SUBJECT(orgcode*Rid) COVTYPE(DIAG). 
 Multivariate Multilevel Model for Correlated Observed Outcomes 
 Model 2.1 (Null):  Tables 7.18 and  7.19 ( ch7achievement.sav ) 

430  Appendix A: Syntax Statements
430   Appendix A: Syntax Statements 
 MIXED achieve BY Index1 
 /FIXED = Index1 | NOINT SSTYPE(3) 
 /METHOD = REML 
 /PRINT = G SOLUTION TESTCOV 
 /RANDOM = Index1 | SUBJECT(schcode) COVTYPE(UN) 
 /REPEATED = Index1 | SUBJECT(schcode*Rid) COVTYPE(UN). 
 Building a Complete Model (Predictors and Cross-Level Interactions) 
 Model 2.2:  Table 7.20 ( ch7achievement.sav ) 
 MIXED achieve BY female Index1 WITH gmacadpress 
 /FIXED = Index1 Index1*gmacadpress Index1*female | NOINT SSTYPE(3) 
 /METHOD = REML 
 /PRINT = G SOLUTION TESTCOV 
 /RANDOM = Index1 | SUBJECT(schcode) COVTYPE(UN) 
 /REPEATED = Index1 | SUBJECT(schcode*Rid) COVTYPE(UN). 
 Table 7.21 : Treating Female as a Covariate ( ch7achievement.sav ) 
 MIXED achieve BY Index1 WITH gmacadpress female 
 /FIXED = Index1 Index1*gmacadpress Index1*female | NOINT SSTYPE(3) 
 /METHOD = REML 
 /PRINT = G SOLUTION TESTCOV 
 /RANDOM = Index1 | SUBJECT(schcode) COVTYPE(UN) 
 /REPEATED = Index1 | SUBJECT(schcode*Rid) COVTYPE(UNR). 
 Table 7.22 : Treating Female as Categorical (Factor) ( ch7achievement.sav ) 
 MIXED achieve BY female Index1 WITH gmacadpress 
 /FIXED = Index1 Index1*gmacadpress Index1*female | NOINT SSTYPE(3) 
 /METHOD = REML 
 /PRINT = G SOLUTION TESTCOV 
 /RANDOM = Index1 | SUBJECT(schcode) COVTYPE(UN) 
 /REPEATED = Index1 | SUBJECT(schcode*Rid) COVTYPE(UNR). 
 Correlations Between Tests at Each Level 
 Model 2.3:  Table 7.23 ( ch7achievement.sav ) 
 MIXED achieve BY Index1 with gmacadpress female 
 /FIXED = Index1 gmacadpress*Index1 index1*female | NOINT SSTYPE(3) 
 /METHOD = REML 
 /PRINT = G SOLUTION TESTCOV 
 /RANDOM = Index1 | SUBJECT(schcode) COVTYPE(UNR) 
 /REPEATED = Index1 | SUBJECT(schcode*Rid) COVTYPE(UNR). 
 Deﬁ ning a Parallel Growth Process Specifying the Time Model 
 Model 3.1:  Tables 7.25 ,  7.26 , and  7.27 ( ch7PGachievement.sav ) 
 MIXED achieve by math with orthtime orthquadtime 
 /FIXED = math math*orthtime math*orthquadtime | noint SSTYPE(3) 
 /METHOD = REML 
 /PRINT = G SOLUTION TESTCOV 

Appendix A: Syntax Statements  431
 /Random = math | Subject (schcode) COVTYPE(UN) 
 /REPEATED = Index1 | SUBJECT(schcode*Rid) COVTYPE(AR1). 
 Adding the Predictors 
 Model 3.2:  Tables 7.29 ,  7.30 , and  7.31 ( ch7PGachievement.sav ) 
 MIXED achieve by math with orthtime orthquadtime female schcontext 
 /FIXED = math math*schcontext math*female math*orthtime math*orthquadtime 
schcontext*math*orthtime female*math*orthtime| noint SSTYPE(3) 
 /METHOD = REML 
 /PRINT = G SOLUTION TESTCOV 
 /Random = math | Subject (schcode) COVTYPE(UN) 
 /REPEATED = Index1 | SUBJECT(schcode*Rid) COVTYPE(AR1). 
 Table 7.32 ( ch7PGachievement.sav ) 
 MIXED achieve BY math WITH orthtime orthquadtime female schcontext 
 /FIXED = math math*schcontext math*female math*orthtime math*orthquadtime 
schcontext*math*orthtime female*math*orthtime | NOINT SSTYPE(3) 
 /METHOD = REML 
 /PRINT = G SOLUTION TESTCOV 
 /RANDOM = math math*orthtime | SUBJECT(schcode) COVTYPE(CSH) 
 /REPEATED = Index1 | SUBJECT(schcode*Rid) COVTYPE(AR1). 
 Chapter 8: Cross-Classiﬁ ed Multilevel Models ( ch8crossclass1.sav  and 
 ch8crossclass2.sav ) 
 Table 8.7 ( ch8crossclass1.sav ) 
 MIXED CUM_GPR 
 /FIXED = | SSTYPE(3) 
 /METHOD = REML 
 /PRINT = G SOLUTION TESTCOV 
 /RANDOM = INTERCEPT | SUBJECT(nschcode) COVTYPE(ID) 
 /RANDOM = INTERCEPT | SUBJECT(campus) COVTYPE(ID). 
 Adding a Set of Level 1 and Level 2 Predictors 
 Model 1.1:  Tables 8.8 and  8.9 ( ch8crossclass1.sav ) 
 MIXED CUM_GPR WITH gmfouryear gmlowSES_mean gmlowses gmfemale 
 /FIXED = gmfouryear gmlowSES_mean gmlowses gmfemale | SSTYPE(3) 
 /METHOD = REML 
 /PRINT = G SOLUTION TESTCOV 
 /RANDOM = INTERCEPT | SUBJECT(nschcode) COVTYPE(ID) 
 /RANDOM = INTERCEPT | SUBJECT(campus) COVTYPE(ID). 
 Investigating a Random Slope 
 Model 1.2:  Table 8.10 ( ch8crossclass1.sav ) 
 MIXED CUM_GPR WITH gmfouryear gmlowSES_mean gmlowses gmfemale 
 /FIXED = gmfouryear gmlowSES_mean gmlowses gmfemale | SSTYPE(3) 

432  Appendix A: Syntax Statements
432   Appendix A: Syntax Statements 
 /METHOD = REML 
 /PRINT = G SOLUTION TESTCOV 
 /RANDOM = INTERCEPT gmfemale | SUBJECT(nschcode) COVTYPE(DIAG) 
 /RANDOM = INTERCEPT gmfemale | SUBJECT(campus) COVTYPE(DIAG). 
 Explaining Variation Between Variables 
 Model 1.3:  Tables 8.11 and  8.12 ( ch8crossclass1.sav ) 
 MIXED CUM_GPR WITH gmlowSES_mean gmlowses gmfemale 
 /FIXED = gmlowSES_mean gmlowses gmfemale gmlowSES_mean*gmfemale | SSTYPE(3) 
 /METHOD = REML 
 /PRINT = G SOLUTION TESTCOV 
 /RANDOM = INTERCEPT gmfemale | SUBJECT(nschcode) COVTYPE(DIAG) 
 /RANDOM = INTERCEPT | SUBJECT(campus) COVTYPE(ID). 
 Intercept-Only Model 
 Model 2.1:  Tables 8.14 ,  8.15 , and  8.16 ( ch8crossclass2.sav ) 
 MIXED math2 
 /FIXED = | SSTYPE(3) 
 /METHOD = REML 
 /PRINT = G SOLUTION TESTCOV 
 /RANDOM = INTERCEPT | SUBJECT(schcode) COVTYPE(ID) 
 /RANDOM = INTERCEPT | SUBJECT(teach2id) COVTYPE(ID) 
 /RANDOM = INTERCEPT | SUBJECT(teach1id) COVTYPE(ID). 
 Deﬁ ning the Cross-Classiﬁ ed Model with Previous Achievement 
 Model 2.2:  Tables 8.17 and  8.18 ( ch8crossclass2.sav ) 
 MIXED math2 WITH Zmath1 
 /FIXED = Zmath1 | SSTYPE(3) 
 /METHOD = REML 
 /PRINT = G SOLUTION TESTCOV 
 /RANDOM = INTERCEPT | SUBJECT(schcode) COVTYPE(ID) 
 /RANDOM = INTERCEPT | SUBJECT(teach2id) COVTYPE(ID) 
 /RANDOM = INTERCEPT | SUBJECT(teach1id) COVTYPE(ID). 
 Adding Teacher Effectiveness and a Student Background Control 
 Model 2.3:  Tables 8.21 and  8.22 ( ch8crossclass2.sav ) 
 MIXED math2 WITH effmath2 effmath1 Zmath1 lowses 
 /FIXED = effmath2 effmath1 Zmath1 lowses | SSTYPE(3) 
 /METHOD = REML 
 /PRINT = G SOLUTION TESTCOV 
 /RANDOM = INTERCEPT | SUBJECT(schcode) COVTYPE(ID) 
 /RANDOM = INTERCEPT | SUBJECT(teach2id) COVTYPE(ID) 
 /RANDOM = INTERCEPT | SUBJECT(teach1id) COVTYPE(ID). 

Appendix A: Syntax Statements  433
 School-Level Predictor and Random Slope 
 Model 2.4:  Table 8.23 ( ch8crossclass2.sav ) 
 MIXED math2 WITH effmath2 effmath1 Zmath1 lowses 
 /FIXED = effmath2 effmath1 Zmath1 lowses | SSTYPE(3) 
 /METHOD = REML 
 /PRINT = G SOLUTION TESTCOV 
 /RANDOM = INTERCEPT effmath2 effmath1 | SUBJECT(schcode) COVTYPE(DIAG) 
 /RANDOM = INTERCEPT | SUBJECT(teach2id) COVTYPE(ID) 
 /RANDOM = INTERCEPT | SUBJECT(teach1id) COVTYPE(ID). 
 Level 3 Differences Between Institutions 
 Model 2.5:  Tables 8.24 and  8.25 ( ch8crossclass2.sav ) 
 MIXED math2 WITH schqual effmath2 effmath1 Zmath1 lowses 
 /FIXED = schqual effmath2 effmath1 Zmath1 lowses | SSTYPE(3) 
 /METHOD = REML 
 /PRINT = G SOLUTION TESTCOV 
 /RANDOM = INTERCEPT effmath2 | SUBJECT(schcode) COVTYPE(DIAG) 
 /RANDOM = INTERCEPT | SUBJECT(teach2id) COVTYPE(ID) 
 /RANDOM = INTERCEPT | SUBJECT(teach1id) COVTYPE(ID). 
 Adding a Level 3 Cross-Level Interaction 
 Model 2.6:  Tables 8.26 and  8.27 ( ch8crossclass2.sav ) 
 MIXED math2 WITH schqual effmath2 effmath1 Zmath1 lowses 
 /FIXED = schqual effmath2 effmath1 Zmath1 lowses effmath2*schqual | SSTYPE(3) 
 /METHOD = REML 
 /PRINT = G SOLUTION TESTCOV 
 /RANDOM = INTERCEPT effmath2 | SUBJECT(schcode) COVTYPE(DIAG) 
 /RANDOM = INTERCEPT | SUBJECT(teach2id) COVTYPE(ID) 
 /RANDOM = INTERCEPT | SUBJECT(teach1id) COVTYPE(ID).  

              This page intentionally left blank

435
 Appendix B: Model Comparisons Across 
Software Applications 
 For comparative purposes, as mentioned in Chapters 5 and 7, we provide the results generated 
by IBM SPSS and Mplus. Th e estimation procedures provide substantial agreement of ﬁ xed 
eﬀ ects, robust standard errors, and variance components in the model. Th ese Mplus estimates 
( Table B.1  ) are with the middle interval “freely estimated” as 0.529. Th is provided the opti-
mal estimate for the SPSS MIXED results (  Table B.2  ) and provides an estimate of the initial 
status the same as in   Table 5.2  . If we add those, we obtain the intercept estimate for time 3 in 
 Table 5.2  (57.094). 
 Table B.3  is a comparison of the estimates produced with Mplus (using a two-level latent 
variable analysis) and the MIXED speciﬁ cation in chapter 7,  Table 7.15 . 
TABLE B.2 SPSS Estimates
Parameter
Estimate
Std. Error
t
Sig.
Model with T2 = 0.529 Intercept
48.632
0.098
495.049
.000
Time (Nonlinear)
8.462
0.122
69.564
.000
Level 2 Variance 
Intercept
31.283
0.949
32.973*
.000
Slope
29.461
2.082
14.150*
.000
*Wald Z coefﬁ cient.
TABLE B.1 Mplus Estimates
Parameter
Estimate
Std. Error
Est./SE
Sig.
Model with T2 = 0.529 Intercept
48.632
0.104
466.258
.000
Time (Nonlinear)
8.462
0.122
69.294
.000
Level 2 Variance 
Intercept
30.703
2.853
10.763
.000
Slope
28.377
5.593
5.073
.000
435

436  Appendix B: Model Comparisons Across Software Applications
436  Appendix B: Model Comparisons Across Software Applications
TABLE B.3 Comparison of SPSS Unstandardized Estimates in Table 7.15 with Mplus Unstandardized 
Estimates
SPSS Estimates
Mplus Estimates
Parameter
Estimate
Std. Error
t
Sig.
Estimate
Std. Error
[assessjob=0]
3.909
0.056
69.537
0.000
3.923
0.077
[assessjob=1]
3.738
0.065
57.681
0.000
3.869
0.083
[assessjob=0] * gmorgprod
0.344
0.119
2.878
0.005
0.306
0.113
[assessjob=1] * gmorgprod
0.383
0.144
2.666
0.009
0.379
0.140
[assessjob=0] * gmresources
0.101
0.044
2.273
0.025
0.086
0.040
[assessjob=1] * gmresources
0.060
0.053
1.124
0.263
0.051
0.052
[assessjob=0] * stability
0.129
0.062
2.071
0.039
0.155
0.067
[assessjob=1] * stability
0.171
0.069
2.493
0.013
0.193
0.072
[assessjob=0] * female
−0.038
0.057
−0.666
0.506
−0.029
0.057
[assessjob=1] * female
−0.001
0.062
−0.016
0.988
0.000
0.064
Table B.3  is a comparison of the estimates with produced with Mplus (using a two-level latent  vari-
able analysis) and the MIXED speciﬁ cation in chapter 7, Table 7.15.

437
 Appendix C: Syntax Routine to Estimate Rho 
From Model’s Variance Components 
 We developed a syntax routine that estimates a two-level intraclass correlation (rho) from the 
null model’s variance components. Th e ﬁ rst part generates the variance components and saves the 
ﬁ le to the “C:\Program Files” path noted in the syntax but may be changed to a diﬀ erent location 
on your computer’s hard drive. Th e second part of the routine retrieves the variance component 
ﬁ le estimates, then computes and displays rho on-screen. In this example, we use  read as the 
outcome and  schcode as the grouping (Level 2) variable. 
 **Part 1: Set Up the Variance Components Model 
 VARCOMP read BY schcode 
 /RANDOM = schcode 
 /OUTFILE = VAREST (‘C:\Program Files\IBM\VAREST.sav’) 
 /METHOD = REML 
 /CRITERIA = ITERATE(50) 
 /CRITERIA = CONVERGE(1.0E-8) 
 /DESIGN 
 /INTERCEPT = INCLUDE. 
 **Part 2: Retrieve the Variance Component Estimates and Compute and Display Rho 
 Get  le = “C:\Program Files\IBM\VAREST.sav” /Drop = ROWTYPE_ VARNAME_. 
 Rename Var (VC1 VC2 = Between Within). 
 Compute rho = Between/(Between+Within). 
 SAVE OUTFILE = ”C:\Program Files\IBM\VAREST.sav”. 
 LIST. 
437

              This page intentionally left blank

439
Author Index
Acock, A. C., 22
Agresti, A., 75
Aiken, L. S., 127
Albright, J. J., 2
Allison, P., 22, 24
Anderson, E., 186
Asparouhov, T., 23, 30, 32, 33, 411
Azen, R., 75, 165
Bandalos, D., 23, 24
Beretvas, S. N., 363, 367
Berkhof, J., 95
Birren, J. E., 186
Black, A. R., 21
Blanchette, D., 34
Bloom, H. S., 21
Bodner, T. E., 24, 28
Boomsma, A., 298
Bosker, R. J., 19, 21, 92, 100, 246, 363, 394
Browne, W. J., 363
Bryk, A. S., 2, 9, 18, 19, 21, 73, 78, 88, 104, 106, 114, 127, 128, 129, 
133, 134, 140, 145, 149, 166, 167, 184, 186, 187, 190, 204, 
215, 238, 240, 243, 253, 254, 287, 297, 300, 301, 302, 303, 
349, 363, 364, 367
Campbell, D. T., 272, 273, 274, 275, 285
Chantala, K., 34
Cheong, Y. F., 2, 9, 134, 238
Cheung, M. W. L., 25
Congdon, R. T., Jr., 2, 9, 134, 238
Cook, T. D., 272, 273, 274, 275
Cronbach, L. J., 128
Curran, P. J., 298
Curtin, T. R., 35
Cuttance, P., 298
Daniels, M. J., 24
de Leeuw, J., 6, 77, 88,145
Duncan, S. C., 238
Duncan, T. E., 238
Ecobe, R., 298
Enders, C. K., 3, 22, 23, 24, 25, 412
Everitt, B. S., 2
Ferreter, J. M., 21
Flora, D. B., 299
Frunchter, B., 183
Gavin, M., 126
Gelman, A., 25
Gibbons, R. D., 23
Gibson, N. M., 25
Goldstein, H., 2, 5, 20, 30, 363, 367
Grilli, L., 30
Guilford, J. P., 183
Hamilton, L. C., 384
Harris, I., 30
Heck, R. H., 3, 5, 9, 18, 22, 75, 76, 77, 84, 87, 88, 284, 287
Hedeker, D., 2, 23
439
Hershberger, S. L., 18, 19
Heuer, R., 35
Hill, C. J., 21, 25
Hill, P. W., 363, 367
Hofmann, D., 126
Hogan, J. W., 24
Holmes, D. J., 30
Hox, J. J., 2, 7, 8, 9, 10, 14, 18, 19, 21, 22, 23, 29, 31, 75, 77, 84, 89, 
92, 95, 100, 101, 107, 126, 127, 128, 129, 137, 138, 139, 149, 
167, 169, 170, 181, 183, 186, 189, 190, 191, 192, 200, 204, 
207, 243, 246, 255, 260, 268, 290, 297, 298, 302, 308, 311, 
326, 333, 348, 361, 363, 367, 394
IBM Corporation, 335, 345, 351, 352, 353, 361, 372, 377, 381, 387, 
400
Ingels, S. J., 35
Jia, Y., 30
Kish, L., 4, 26, 28
Koretz, D., 384
Kreft, I., 6, 77, 88, 127, 145
Kutner, M., 80
Laird, N. M., 168
Lam, W., 115
Larsen, R., 22, 23, 24, 25, 26, 28, 29
Lee, V. E., 78
Lesaﬀ re, E., 191
Leyland, A. H., 59, 300, 331, 333, 348, 349
Lipsey, M. W., 21
Little, R., 11, 23
Liu, S., 191, 200
Lockwood, J. R., 384
Loh, W. Y., 20
Longford, N. T., 20
Louis, T. A., 384
MacKinnon, D. F., 2
Marcoulides, G. A., 18, 19, 168, 170, 186, 190, 238, 
411
Marinova, D. M., 2
Marsden, P. V., 20, 275
McArdle, J. J., 186
McCaﬀ rey, D. F., 384
Mehta, P. D., 21
Meredith, W., 186
Molenaar, P. C. M., 191, 200
Morris, C. N., 20, 77
Moss, B. G., 275
Muthén, B. O., 2, 20, 25, 27, 88, 275
Muthén, L. K., 2, 25, 27, 88, 168
Nachtsheim, C., 80
Neale, M. C., 21
Neter, N., 80
Noel, A., 35
Olejnik, S., 25
Organization for Economic Cooperation and Development, 26, 28, 31
Orsuwan, M., 287

440  Author Index
Paccagnella, O., 149
Pedhazur, E. J., 5, 273
Petrin, R. A., 25
Peugh, J. L., 3, 22, 23, 24, 412
Pfeﬀ ermann, D., 30
Plewis, I., 126
Pratesi, M., 30
Preacher, K. J., 22
Rabe-Hesketh, S., 2, 34, 411
Rasbash, J., 30, 363
Raudenbush, S. W., 2, 5, 9, 18, 19, 21, 73, 88, 104, 106, 114, 127, 128, 
129, 133, 134, 140, 145, 149, 166, 167, 184, 186, 187, 190, 
204, 215, 238, 240, 243, 253, 254, 287, 297, 300, 301, 302, 
303, 349, 363, 364, 367
Raykov, T., 168, 170, 186, 190, 238, 411
Rigdon, E., 298
Roberts, J. K., 274
Robins, J. M., 23
Robinson, W. S., 7
Rotnitzky, A., 23
Rovine, M., 191, 200
Rubin, D. B., 11, 23
Sable, J., 35
Satterthwaite, F. E., 20, 99, 203
Satorra, A., 20, 275
Schaie, K. W., 186
Scherbaum, C. A., 21
Schmelkin, L. P., 5, 273
Shadish, W. R., 272, 274, 275
Singer, J. D., 2, 5, 9, 169, 187, 188, 195, 238, 243, 245, 260
Skinner, C. J., 30, 32
Skrondal, A., 2, 34, 411
Snijders, T. A. B., 19, 20, 21, 92, 95, 100, 246, 394, 363
Stanley, J. C., 272, 273, 274, 285
Stapleton, L. M., 30
Stokes, L., 30
Strycker, L. A., 238
Suchinindran, C. M., 34
Tabachnick, B. G., 7, 15
Tabata, L. N., 3, 75
Takahashi, R., 284
Th omas, S. L., 3, 5, 9, 18, 22, 75, 76, 77, 84, 87, 88, 115, 287
Th um, Y. M., 383
Tisak, J., 186
Trochim, W. M. K., 274
van Buuren, S., 23, 24, 25, 26
Verbeke, G., 191
Walker, C. M., 75, 165
Wang, Y., 30
Ware, J. H., 168
Wasserman, W. , 80
Willett, J. B., 2, 5, 9, 167, 169, 187, 188, 195, 238, 243, 
245, 260
Wright, S. P., 297
Wu, S., 35
Yeaton, M. H., 275
Zhang, D., 25

441
Subject Index
Aggregation, 7, 53, 69, 70
Akaike Information Criterion (AIC), see Evaluation of model ﬁ t
ANOVA, see Linear models
Between-group variance, 8, 22
Between-subjects factors, 167,168
Categorical variables, 17, 76, 102, 139, 141 
Centering, 65–67 
 grand mean, 67–72
 group mean, 12, 69, 127–129, 139, 145, 147–149
 natural metric, 126–127, 129, 139, 140, 154–155 
 raw metric, 22, 126, 129, 139–140, 141 
 uncentered, 72, 127, 129, 140, 155
Change trajectory, see Growth models
Chi-square, see Evaluation of model ﬁ t
Coding 
 dummy, 12, 22, 23, 72, 102, 103, 105, 129 139–140, 300, 302–
303, 315, 346, 348–349, 362, 366  
 reverse, 26–27, 274  
 time-related variables, 39, 173, 181–186, 254–256, 287, 362 
Control group, 4, 6, 168, 170, 234–237, 239, 272–276, 280–281 
Covariance matrix
 autoregressive (AR1), 190–192, 213, 247–249, 291, 349, 351, 
354
 compound symmetry (CS), 167, 188–190, 208, 247, 360–361 
 diagonal (DIAG), 13, 15, 17, 110–111, 190–191, 211–213, 
248–260, 302–309, 311, 328–329
 identity or scaled identity (ID), 13, 36, 164, 188–190, 193–194, 
208, 209, 210, 235, 247–248, 302, 309–310, 311, 385, 
 unstructured covariance (UN), 15–16, 110–111, 149, 191, 
201–204, 208–211, 213, 220, 235, 244, 247, 260, 310, 320, 
354, 398 
 unstructured covariance-correlation (UNR), 110, 320, 344 
 variance components (VC), 15, 89–94, 119
Covariance structure, 1, 15–16, 93, 98, 169, 188–190, 191, 204, 208, 
302 
Data 
 clustered, 1, 6, 8–9, 18, 31, 84–85, 87, 383 
 dichotomous, 3, 12, 17, 35, 38, 76, 102–103, 106, 129, 130, 
139–141, 298, 346, 
 hierarchical, 1, 4, 5, 7, 9, 25, 26, 35, 73, 87, 131, 363, 367, 383, 
408, 410
 hierarchy, 2–3, 6–9, 17, 21–22, 30, 34–35, 76–77, 106, 115, 
129–130, 131, 148, 173, 245–246, 267, 295, 300, 363 
 
 horizontal, 38, 53–54, 67, 172–173, 347, 384
 longitudinal, 1, 2–3, 4, 9, 22–25, 34, 88, 131, 167, 168, 169, 188, 
190, 238, 239, 247, 295, 409
 management, 34, 38–73, 410 
 mining, 410
 missing, 3–4, 5, 22–30, 32, 38, 72–73, 101, 168, 172, 183, 297, 
361, 365, 409, 411–412, 
 normally distributed, 19, 79–80, 88, 133, 188, 244, 246, 287, 
302, 
 user missing values, 24
 vertical, 29, 53, 173, 254, 300, 302, 361
Degrees of freedom, 19, 99, 165, 167, 203, 267–268, 311, 
Dependent variable, 17, 21, 22, 28, 31, 76, 99, 168, 188, 297, 347–
348, 394 
441
Descriptive statistics, 2, 38, 51, 59, 65, 68, 173, 298, 366
Design eﬀ ects, 30–32
Deviance, 19, 95, 127, 128, 165, 209, 247, 311, 326
Disaggregation, 7 
Discrepancy function, 19
Ecological fallacy, 7
Errors 
 error structure, 7, 188, 189, 191, 243, 361
 error term, 80, 110, 246, 303, 331, 367
 error variance, 8, 114, 145, 191
 independent errors, 7, 8
 random errors, 8, 88
 standard errors, 7, 8, 20, 21, 24–25, 26, 28, 30, 32, 77, 85, 
99–100, 411, 
 Type I error, 30
 Type II errors, 411
Estimation methods 
 full information maximum likelihood (FIML), 3, 22, 23, 24–25, 
26–28, 209
 Mauchly’s test of sphericity, 169, 189, 208
 maximum likelihood (ML), 18–19, 20, 24, 25, 94, 161, 164–165, 
186, 192, 311, 320, 326, 346
 ordinary least squares (OLS), 8, 10, 18, 65–66, 73, 88, 99, 410
 restricted maximum likelihood (REML), 17–18, 19–20, 94, 99, 
161, 247, 311, 320
Evaluation of model ﬁ t
 Akaike Information Criterion (AIC), 165, 191, 209, 224, 227, 
235, 236–237, 247–248, 326 
 Bayesian Information Criterion (BIC), 165–166, 191, 209
 chi-square, 21, 95, 165, 311
 compare models, 16, 19, 161, 164–166, 208–211, 285, 320, 326
 Satterthwaite, 20, 99, 203 
 Wald statistic or Wald Z test, 21, 94–95, 101, 114, 130, 154, 
195–196, 204, 208–210, 220, 259–260, 263, 268   
Experimental or experimental design, 4, 22, 76, 87–88, 168, 171, 
233–237, 274, 284, 295 
Exploratory factor analysis, 3, 299–300
Factor , 12, 102–103, 105, 106, 107, 140, 
Factor analysis, 3, 16–17, 76, 168 
Graphing, see SPSS menu commands 
Growth models, 4, 88, 220, 232–233, 286–287, 297, 298, 300, 410 
 change trajectory, 168, 243
 cubic growth, 169–170, 183–184, 243, 274, 275–276, 
 curve, 23, 75, 168, 170, 191, 236 
 curvilinear trajectory, 175, 183
 gain score, 384, 391 
 growth rates, 168, 214, 222, 238, 244, 252–254, 260–263, 268, 
285
 growth trajectories, 169–171, 173–175, 183, 186, 187, 200, 
214–215, 217–224, 233–234, 235, 237, 238, 243, 254, 259, 
263–264, 285, 300, 347, 348, 359 
 individual development, 169–170, 297 
 linear growth rates, 169–170, 173–174, 181, 203–204, 214–215, 
219, 234, 237, 252–253, 256, 260, 355
 longitudinal analysis, 168, 238, 295
 parallel growth, 2, 4, 168, 346–349, 351, 362, 410
 piecewise growth, 2, 4, 239, 285–287 
 polynomial growth, 186, 200, 233, 236

442  Subject Index
 quadratic growth, 187, 170, 187, 203, 355
 quadratic term, 200, 254, 276
 quadratic trajectory, 170, 175, 243 
 repeated measures, 1–3, 25, 29, 167–170, 181, 183–184, 186–
190, 199, 200, 204, 208, 209, 215, 222, 224, 235, 239–240, 
247, 260, 268, 287, 291
 three-level model, 4, 5, 73, 130–134, 240–241, 297–298, 333, 
348, 383, 410H
Heterogeneity, 2, 129, 191
Heterogeneous variances, 190, 246–247
HLM, see Software programs
Homogeneity, 8–9, 11, 167, 259
Homogeneous, 8, 20, 89, 129 
IIBM SPSS menu commands  
 ADD FIT LINE OF SUBGROUPS, 125, 178
 AGGREGATE, 34, 52–53, 69–70, 
 Chart Editor, 18, 82–83, 125, 178–180, 224 
 COMPUTE, 38, 44–46, 59–61, 67–68, 71–72
 EXPLORE, 72
 MATCH FILES, 38, 46–51
 RANK CASES, 59, 61–65
 RECODE, 38, 39–43 
 SCATTER/DOT, 81–83, 86–87, 124–126, 177–181
 SELECT CASES, 80–81, 123–124, 176–177 
 VARSTOCASES, 38, 53–59
IBM SPSS MIXED, 2, 9, 15, 16, 17, 18, 19, 21, 28, 32, 34, 35, 38, 
53, 65, 66, 73, 88, 166, 215, 232, 239, 272, 300, 408, 409, 410, 
411 
 COVARIATE(S) dialog box, 91 
 CRITERIA command, 17
 DEPENDENT VARIABLE, 91
 ESTIMATION dialog box, 92 
 FACTORS AND COVARIATES dialog box, 91
 FIXED EFFECTS dialog box, 92
 LINEAR MIXED MODELS dialog screen, 91
 LINEAR MIXED MODELS: SPECIFY SUBJECTS AND 
REPEATED dialog screen, 90
 MODEL dialog box, 91 
 MODEL DIMENSION table, 93 
 RANDOM EFFECT 1 OF 1 dialog screen, 91, 137 
 SPECIFIED SUBJECTS AND REPEATED dialog box, 90 
 STATISTICS, 92 
 SUBJECT GROUPINGS, 91 
Individual change, individual development, see Growth models
Interaction, 14. 15, 22, 107, 115, 119–120, 129, 131–132. 154–156, 
161–164, 215–222, 233–234, 275–276, 328, 346, 366–367, 
405–408 
 cross-level, 8, 10, 11, 15, 32, 96, 115–116, 131, 214–215, 230, 
378, 
 factor*covariate interaction, 116, 119, 115, 155, 382
 factor* factor interaction, 155
 term, 15, 107, 115, 120, 132, 154–156, 161, 163, 164, 165, 214, 
215 
 time, 234, 234 
Intraclass correlation (ICC), 8, 20, 31, 32, 89, 94, 99, 100, 134, 191, 
245, 246
Iterative process, 18, 19, 24, 88
Latent variable, 11, 54, 168, 186, 297, 300–301, 329, 409, 410 
Likelihood function, 18, 19, 164, 247
Likelihood-ratio test, 95
Linear models 
 analysis of covariance, 76 
 analysis of variance ANOVA, 2, 3, 11, 16, 76, 94, 167
 hierarchical linear models, 1
 multilevel structural equation modeling, 329
 multiple regression, 3, 7, 12, 16, 17, 75, 76, 78, 84, 85, 139, 
183
 multivariate analysis of variance (MANOVA), 3, 76. 167, 222, 
297
 multivariate approach, 4, 76, 77, 169, 172, 297
 multivariate multilevel, 297–299, 
 repeated measures ANOVA, 167, 190, 204, 208, 220, 221 
Listwise deletion, see Missing data
Longitudinal analysis, see Growth models
Macrolevels, 6, 7, 8
Maximum likelihood (ML), see Estimation method
Measurement error, 297
Measurement model, 298, 300, 333
Measurement occasions, 39, 167, 169, 171–173, 181, 187, 188, 190, 
191, 224, 243, 254, 300, 384 
Microlevels, 7
Missing data
 listwise deletion, 3, 23, 24, 25, 168
 missing at random (MAR), 22, 23–29, 
 missing completely at random (MCAR), 23, 24, 25, 28, 411
 multiple imputation, 3, 22, 24, 25, 26, 411
 pairwise deletion, 3, 22, 24
Model
 baseline, 12, 25, 138, 149, 254, 272, 394
 comparison, see Evaluation of model ﬁ t
 conceptual, 2, 4, 5, 6, 7, 9, 10, 20, 31, 34, 35, 76, 168, 187, 240, 
409–410, ,411
 convergence criteria, 17
 covariance components, 3, 9, 18, 344
 equivalent, 127, 139
 group level, 1, 9, 14, 24, 25, 26, 30, 36, 65, 69, 77, 84, 93, 96, 98, 
101, 128, 139, 240
 intercept-only, 11, 135, 138,199, 367, 385, 394 
 longitudinal, see Growth models, repeated measures
 multilevel, 1–5, 7, 9, 17, 18–19, 21, 27, 31–36, 65, 73, 77, 85, 87, 
88–89, 138, 238, 297, 409–411, 
 parsimony, 76, 191, 408, 411 
 random intercept, 5, 10, 16, 21, 26, 65, 88, 91, 95–96, 101–102, 
110, 126, 127, 149, 166, 190, 196, 204, 208, 247, 303, 333, 
334, 391
 random parameter, 12, 14, 16, 18, 77, 88, 94, 95, 96, 111, 149, 
153, 161, 214, 240, 359
 random slope, 9, 10, 14–17, 19, 21, 73, 84, 88, 100, 101, 110, 
113–116, 126, 128–130, 131, 138–139, 145, 149, 153, 328, 
346, 360, 375, 378, 382, 398, 410, 411
 single-equation approach, 10, 37, 38  
 single-level, 7, 10, 11, 16, 22, 31, 79, 84, 99, 333
 slope equation, 95, 102, 110, 149, 215
 slope variance, 93, 98, 110, 114, 129, 259, 408 
 unconditional model, 245, 272
 univariate, 36, 54, 88, 131–134, 168, 243, 297 
Mplus, see Software programs
Multicollinearity, 95, 183, 204
Multilevel approaches, 20
Multilevel software, see Software programs
Multipe regression, see Regression
Multivariate analysis of variance (MANOVA), s
ee Linear models 
Nested data structure, see Data, clustered 
One-tailed test, 95, 195, 259
Ordinary least squares (OLS), see Estimation methods

Subject Index  443
Pairwise deletion, see Missing data
Parallel lines, 155
Parallelism, 170, 214 
Parameter estimates, 18, 21, 24, 30, 31, 77, 100, 164, 254
Parameter variance, 145, 272
Policy implementation, 284–295
Polynomial contrast, 204, 206, 214, 219, 220–221, 
Polynomial curves, 169, 243
Power, 7, 20–21, 27, 114, 167
Predicted values, 18, 79, 186, 232, 359
Prediction equation, 76
Proportion of variance, 8, 89, 94, 138, 148, 195, 252, 272
Quasi-experimental, 22, 76, 285 
Random coeﬃ  cients, see Model
Random eﬀ ect, see Model
Random intercepts, 5, 21, 88, 137, 166, 250, 334, 412
Random sampling, see Sampling
Regression
 regression coeﬃ  cients, 
 regression line, 80, 85. 87, 122, 274, 
 regression slope, 10, 77, 320. 326, 369
Regression discontinuity analysis, 2, 4, 131, 239, 272–384
Reliability, 18, 94, 114
Residuals, 18, 73, 188, 191, 243, 244, 246, 333, 385, 391, 398 
Restricted model, 120, 165, 311
Rho, 89, 190, 252
Sample
 complex sample, 30, 33, 411 
 random, 4, 23, 27, 28, 30, 31, 77, 132, 260
 sample data, 5, 18, 76, 83, 132, 154, 394
 sample mean, 12, 19, 83, 94, 126, 139
 sample size, 5, 8, 16, 18, 19, 20, 21, 27, 35, 88, 94, 95, 114, 120, 
129, 139, 145, 191, 204, 209, 365, 378
 small sample sizes, 95, 145, 204 
Software programs
 HLM, 2, 9. 21, 25, 26, 31, 36, 409, 411
 MLwiN, 2
 Mplus, 2, 21, 25, 27, 31, 32, 33, 232, 329, 409, 411
 SAS, 2, 23, 34
 Stata, 2, 34
Speciﬁ cation, see Model
Sphericity, 167, 169, 189, 
Standard deviation, 21, 22, 27, 68, 72, 79, 107, 126 
Standardizing variables, 21, 22
Stata, see Software programs
Stochastic, 188
Structural equation modeling, 168, 329
Structural parameters, 3, 9, 77, 87, 244
Syntax statements, 16–17, 88, 155, 301, 333, 339 
Th eoretical model, 5, 14, 76, 77, 167, 239
Th eoretical relationships, 5, 34, 410
Th eory, 1, 5, 6, 22, 76, 411
Time
 time-related variables, 173, 181, 184, 192, 196, 199, 252, 254, 
287, 362
 time series, 252, 254, 260, 284–285, 286, 295
 time-varying covariates, 168, 187, 240, 243, 260–261, 263 
T-ratio, 8, 
Treatment, 2, 4, 6, 25, 87, 167–168, 169, 170, 171, 233–237, 239, 
272–273, 275–276, 281
Unit of analysis, 53, 76, 77, 239
Univariate analysis of variance (ANOVA), see Linear Models
Unstandardized estimate, 21, 77, 99–100, 203 
Variance components, 13, 15, 18, 19, 20, 21, 22, 28, 32, 84, 89–90, 
94, 96, 100, 107, 114, 115, 119, 120, 131, 191, 204, 232, 247, 
303, 311. 366, 368, 394,
Variance decomposition, 1, 134, 138, 245, 246, 368 
Variance reduction, 139, 272, 394
Wald statistic or Wald Z test, see Evaluation of model ﬁ t 
Weights
 multilevel weights, 32–34 
 sample weights, 4, 18, 26, 28, 30–32, 77, 411 
X axis, 82, 86, 125, 178, 179
Y axis, 82, 86–87, 125, 178, 187, 224

