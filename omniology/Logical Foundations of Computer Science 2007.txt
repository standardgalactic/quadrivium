
Lecture Notes in Computer Science
4514
Commenced Publication in 1973
Founding and Former Series Editors:
Gerhard Goos, Juris Hartmanis, and Jan van Leeuwen
Editorial Board
David Hutchison
Lancaster University, UK
Takeo Kanade
Carnegie Mellon University, Pittsburgh, PA, USA
Josef Kittler
University of Surrey, Guildford, UK
Jon M. Kleinberg
Cornell University, Ithaca, NY, USA
Friedemann Mattern
ETH Zurich, Switzerland
John C. Mitchell
Stanford University, CA, USA
Moni Naor
Weizmann Institute of Science, Rehovot, Israel
Oscar Nierstrasz
University of Bern, Switzerland
C. Pandu Rangan
Indian Institute of Technology, Madras, India
Bernhard Steffen
University of Dortmund, Germany
Madhu Sudan
Massachusetts Institute of Technology, MA, USA
Demetri Terzopoulos
University of California, Los Angeles, CA, USA
Doug Tygar
University of California, Berkeley, CA, USA
Moshe Y. Vardi
Rice University, Houston, TX, USA
Gerhard Weikum
Max-Planck Institute of Computer Science, Saarbruecken, Germany

Sergei N. Artemov Anil Nerode (Eds.)
Logical Foundations
of Computer Science
International Symposium, LFCS 2007
New York, NY, USA, June 4-7, 2007
Proceedings
1 3

Volume Editors
Sergei N. Artemov
CUNY Graduate Center
Computer Science
365 Fifth Ave., New York City, NY 10016, USA
E-mail: Sartemov@gc.cuny.edu
Anil Nerode
Cornell University
Department of Mathematics
545 Malott Hall, Ithaca NY 14853, USA
E-mail: anil@math.cornell.edu
Library of Congress Control Number: 2007927056
CR Subject Classiﬁcation (1998): F.4.1, F.4, F.3, I.2.2-4
LNCS Sublibrary: SL 1 – Theoretical Computer Science and General Issues
ISSN
0302-9743
ISBN-10
3-540-72732-9 Springer Berlin Heidelberg New York
ISBN-13
978-3-540-72732-3 Springer Berlin Heidelberg New York
This work is subject to copyright. All rights are reserved, whether the whole or part of the material is
concerned, speciﬁcally the rights of translation, reprinting, re-use of illustrations, recitation, broadcasting,
reproduction on microﬁlms or in any other way, and storage in data banks. Duplication of this publication
or parts thereof is permitted only under the provisions of the German Copyright Law of September 9, 1965,
in its current version, and permission for use must always be obtained from Springer. Violations are liable
to prosecution under the German Copyright Law.
Springer is a part of Springer Science+Business Media
springer.com
© Springer-Verlag Berlin Heidelberg 2007
Printed in Germany
Typesetting: Camera-ready by author, data conversion by Scientiﬁc Publishing Services, Chennai, India
Printed on acid-free paper
SPIN: 12067930
06/3180
5 4 3 2 1 0

Preface
The Symposium on Logical Foundations of Computer Science series provides a
forum for the fast-growing body of work in the logical foundations of computer
science, e.g., those areas of fundamental theoretical logic related to computer
science. The LFCS series began with “Logic at Botik,” Pereslavl-Zalessky, 1989,
which was co-organized by Albert R. Meyer (MIT) and Michael Taitslin (Tver).
After that, organization passed to Anil Nerode.
Currently, LFCS is governed by a Steering Committee consisting of Anil
Nerode, Cornell (General Chair); Stephen Cook, Toronto; Dirk van Dalen, Utrecht;
Yuri Matiyasevich, St. Petersburg; John McCarthy, Stanford; J. Alan Robinson,
Syracuse; Gerald Sacks, Harvard; and Dana Scott, Carnegie-Mellon.
The 2007 Symposium on Logical Foundations of Computer Science took place
in New York, USA at the Graduate Center of the City University of New York
during June 4 - 7. This volume contains the extended abstracts of talks selected
by the Program Committee for presentation at LFCS 2007.
The scope of the symposium is broad and contains constructive mathematics
and type theory; logical foundations of programming; logical aspects of compu-
tational complexity; logic programming and constraints; automated deduction
and interactive theorem proving; logical methods in protocol and program veri-
ﬁcation; logical methods in program speciﬁcation and extraction; domain theory
logics; logical foundations of database theory; equational logic and term rewrit-
ing; lambda and combinatory calculi; categorical logic and topological semantics;
linear logic; epistemic and temporal logics; intelligent and multiple agent system
logics; logics of proof and justiﬁcation; nonmonotonic reasoning; logic in game
theory and social software; logic of hybrid systems; distributed system logics;
system design logics; other logics in computer science.
We thank the authors and reviewers for their contributions. We acknowledge
the support of the Graduate Center of the City University of New York, the Mid-
Atlantic Mathematical Logic Seminar, the New York Logic Colloquium, and the
CUNY Computer Science Colloquium.
We are grateful to Evan Goris, Bryan Renne, and Roman Kuznets for prepar-
ing this volume for Springer.
March 2007
Anil Nerode
Sergei Artemov

Organization
Steering Committee
Stephen Cook (Toronto)
Dirk van Dalen (Utrecht)
Yuri Matiyasevich (St. Petersburg)
John McCarthy (Stanford)
Anil Nerode (Cornell) - General Chair
J. Alan Robinson (Syracuse)
Gerald Sacks (Harvard)
Dana Scott (Carnegie-Mellon)
Program Committee
Samson Abramsky (Oxford)
Sergei Artemov (New York) - PC Chair
Matthias Baaz (Vienna)
Lev Beklemishev (Moscow)
Andreas Blass (Ann Arbor)
Lenore Blum (Carnegie-Mellon)
Samuel Buss (San Diego)
Thierry Coquand (G¨oteborg)
Ruy de Queiroz (Recife, Brazil)
Denis Hirschfeldt (Chicago)
Bakhadyr Khoussainov (Auckland)
Yves Lafont (Marseille)
Joachim Lambek (McGill)
Daniel Leivant (Indiana)
Victor Marek (Kentucky)
Anil Nerode (Cornell) - General LFCS Chair
Philip Scott (Ottawa)
Anatol Slissenko (Paris)
Alex Simpson (Edinburgh)
V.S. Subrahmanian (Maryland)
Michael Rathjen (Leeds)
Alasdair Urquhart (Toronto)
Additional Reviewers
Alexandru Baltag
Jan Broersen

VIII
Organization
Arnaud Carayol
Walter Carnielli
Robin Cockett
Melvin Fitting
Rosalie Iemhoﬀ
Max Kanovich
Vladimir Krupski
Larisa Maksimova
Joao Marcos
Edwin Mares
Joel Oaknine
Rohit Parikh
Valery Plisko
Jeﬀrey Remmel
Andre Scedrov
Sven Schewe
Subash Shankar
Valentin Shehtman
Mirek Truszczynski
Sergei Tupailo
James Worrell

Table of Contents
Justiﬁed and Common Knowledge: Limited Conservativity . . . . . . . . . . . .
1
Evangelia Antonakos
The Intensional Lambda Calculus . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
12
Sergei Artemov and Eduardo Bonelli
Generalized Non-deterministic Matrices and (n,k)-ary Quantiﬁers . . . . . .
26
Arnon Avron and Anna Zamansky
Elementary Diﬀerential Calculus on Discrete and Hybrid Structures . . . .
41
Howard A. Blair, David W. Jakel, Robert J. Irwin, and Angel Rivera
Weighted Distributed Systems and Their Logics . . . . . . . . . . . . . . . . . . . . .
54
Benedikt Bollig and Ingmar Meinecke
Weighted O-Minimal Hybrid Systems Are More Decidable Than
Weighted Timed Automata! . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
69
Patricia Bouyer, Thomas Brihaye, and Fabrice Chevalier
On Decidability and Expressiveness of Propositional Interval
Neighborhood Logics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
84
Davide Bresolin, Valentin Goranko, Angelo Montanari, and
Guido Sciavicco
Reasoning About Sequences of Memory States . . . . . . . . . . . . . . . . . . . . . . .
100
R´emi Brochenin, St´ephane Demri, and Etienne Lozes
Cut Elimination in Deduction Modulo by Abstract Completion . . . . . . . .
115
Guillaume Burel and Claude Kirchner
Density Elimination and Rational Completeness for First-Order
Logics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
132
Agata Ciabattoni and George Metcalfe
Extracting the Resolution Algorithm from a Completeness Proof for
the Propositional Calculus . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
147
Robert Constable and Wojciech Moczydlowski
Topological Semantics and Bisimulations for Intuitionistic Modal
Logics and Their Classical Companion Logics . . . . . . . . . . . . . . . . . . . . . . . .
162
J.M. Davoren
A Decidable Temporal Logic of Repeating Values . . . . . . . . . . . . . . . . . . . .
180
St´ephane Demri, Deepak D’Souza, and R´egis Gascon

X
Table of Contents
Model Checking Knowledge and Linear Time: PSPACE Cases . . . . . . . . .
195
Kai Engelhardt, Peter Gammie, and Ron van der Meyden
Realizations and LP . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
212
Melvin Fitting
Successive Abstractions of Hybrid Automata for Monotonic CTL Model
Checking . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
224
R. Gentilini, K. Schneider, and B. Mishra
Explicit Proofs in Formal Provability Logic . . . . . . . . . . . . . . . . . . . . . . . . . .
241
Evan Goris
A Synthesis Algorithm for Hybrid Systems . . . . . . . . . . . . . . . . . . . . . . . . . .
254
Srikanth Gottipati and Anil Nerode
Including the Past in ‘Topologic’ . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
269
Bernhard Heinemann
A Note on Rewriting Proofs and Fibonacci Numbers . . . . . . . . . . . . . . . . .
284
Max Kanovich
On Complexity of Ehrenfeucht-Fra¨ıss´e Games . . . . . . . . . . . . . . . . . . . . . . .
293
Bakhadyr Khoussainov and Jiamou Liu
The Law of the Iterated Logarithm for Algorithmically Random
Brownian Motion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
310
Bjørn Kjos-Hanssen and Anil Nerode
Hypersequent Calculus for Intuitionistic Logic with Classical Atoms . . . .
318
Hidenori Kurokawa
Proof Identity for Classical Logic: Generalizing to Normality . . . . . . . . . .
332
Roman Kuznets
On the Constructive Dedekind Reals: Extended Abstract . . . . . . . . . . . . .
349
Robert S. Lubarsky and Michael Rathjen
Verifying Balanced Trees . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
363
Zohar Manna, Henny B. Sipma, and Ting Zhang
Compactness Properties for Stable Semantics of Logic Programs . . . . . . .
379
Victor W. Marek and Jeﬀrey B. Remmel
Uniform Circuits,  Boolean Proof Nets . . . . . . . . . . . . . . . . . . . . . . . . . . . .
401
Virgile Mogbil and Vincent Rahli
Finite Automata Presentable Abelian Groups. . . . . . . . . . . . . . . . . . . . . . . .
422
Andr´e Nies and Pavel Semukhin

Table of Contents
XI
Embeddings into Free Heyting Algebras and Translations into
Intuitionistic Propositional Logic. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
437
Michael O’Connor
Some Puzzles About Probability and Probabilistic Conditionals . . . . . . . .
449
Rohit Parikh
A Temporal Dynamic Logic for Verifying Hybrid System Invariants . . . .
457
Andr´e Platzer
Multiplexor Categories and Models of Soft Linear Logic . . . . . . . . . . . . . . .
472
Brian F. Redmond
Until-Since Temporal Logic Based on Parallel Time with Common
Past. Deciding Algorithms . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
486
V. Rybakov
Total Public Announcements . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
498
David Steiner and Thomas Studer
Author Index . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
513

Justiﬁed and Common Knowledge:
Limited Conservativity
Evangelia Antonakos
CUNY Graduate Center
Ph.D. Program in Mathematics
365 Fifth Avenue
New York, NY 10016, USA
Eva@Antonakos.net
Abstract. We consider the relative strengths of three formal approaches
to public knowledge: “any fool” knowledge by McCarthy (1970), Com-
mon Knowledge by Halpern and Moses (1990), and Justiﬁed Knowledge
by Artemov (2004). Speciﬁcally, we show that epistemic systems with
the Common Knowledge modality C are conservative with respect to
Justiﬁed Knowledge systems on formulas χ ∧Cϕ →ψ, where χ, ϕ, and
ψ are C-free.
Keywords:
justiﬁed
knowledge,
common
knowledge,
Artemov,
conservative.
1
Multi-agent Logics
The logics Tn, S4n, and S5n are logics in which each of the ﬁnitely many (n)
agents has a knowledge operator Ki which is T, or S4, or S5 respectively. We
only consider cases where all agents’ modalities are of the same logical strength.
Deﬁnition 1. The formal systems for Tn, S4n, and S5n are as follows:
Propositional Logic plus for Ki, i = 1, 2, . . ., n we have
Axioms for S4n:
K : Ki(ϕ →ψ) →(Kiϕ →Kiψ)
each agent can do modus ponens
T : Kiϕ →ϕ
agents can know only true propositions
4 : Kiϕ →KiKiϕ
agents have positive introspection
Rules:
Necessitation: ⊢ϕ ⇒⊢Kiϕ, for i = 1, 2, . . ., n
For Tn, omit the ﬁnal axiom.
For S5n, add negative introspection: ¬Kiϕ →Ki¬Kiϕ.
Deﬁnition 2. Kripke models for S4n: M = ⟨W, R1, R2, . . . , Rn, ⊩⟩where
• W is a non-empty set of worlds
• Ri ⊆W × W is agent i’s accessability relation. Ri is reﬂexive and transitive.
S. Artemov and A. Nerode (Eds.): LFCS 2007, LNCS 4514, pp. 1–11, 2007.
c
⃝Springer-Verlag Berlin Heidelberg 2007

2
E. Antonakos
• ⊩⊆W × V ar where V ar is the set of propositional variables. The forcing
relation ⊩is naturally extended to all formulas so that Ri corresponds to Ki:
M, u ⊩Kiϕ ⇔(∀v ∈M)[uRiv →M, v ⊩ϕ] .
For Tn-models, each Ri is reﬂexive while for S5n-models, each Ri is an equiva-
lence relation.
Theorem 1. Tn, S4n, and S5n are sound and complete with respect to their
models (cf. [10]).
Multi-agent systems are enhanced by the addition of modalities which take into
account shared or public knowledge of agents. Three such modalities C, J, and
O will be discussed, all of which model variations of public information. We will
compare their logical strengths, semantics, and complexity and will see why Jus-
tiﬁed Knowledge (J) systems are suﬃcient to solve classical epistemic scenarios,
a role usually designated for Common Knowledge (C).
2
Common Knowledge
The most recognized concept of public knowledge is common knowledge, and
the literature addressing it, both philosophical and mathematical, is vast. The
initial investigation was philosophical: Lewis’s book [15] on convention. The in-
tuition behind the informal deﬁnition of common knowledge below derives from
Aumann’s oft-cited [5], where it was used in the context of agents having com-
mon priors. McCarthy’s ‘any fool’ operator of 1970 ([10], p. 13) is closely related
to common knowledge and his systems in [16] (see section 4 of this paper) may
be the ﬁrst to address it axiomatically . Rigorous work on common knowledge
in the context of multi-agent systems was done by Halpern and Moses in [13]
(an expansion of a 1984 work of the same title) and Lehmann [14]. Much of the
work by Halpern and Moses appears in [10]. Common knowledge continues to
be actively investigated.
Informally, the epistemic operator Cϕ, to be read ‘ϕ is common knowledge,’
can be given as inﬁnite conjunction:
Cϕ ↔ϕ ∧Eϕ ∧EEϕ ∧EEEϕ ∧E4ϕ ∧· · · ∧Enϕ ∧· · ·
(1)
where Eϕ = K1ϕ∧K2ϕ∧· · ·∧Knϕ (‘everyone knows ϕ’) and Ki is an individual
agent’s knowledge operator corresponding to T, S4 or S5 as appropriate. One
formal characterization which [10] and [7] take is via the Fixed Point Axiom
Cϕ ↔E (ϕ ∧Cϕ)
(2)
and the Induction Rule
ϕ →E (ϕ ∧ψ)
ϕ →Cψ
(3)
yielding Common Knowledge to be the greatest ﬁxed point solution to X ↔
E(ϕ ∧X) [10]. Common Knowledge does not take into account the means by

Justiﬁed and Common Knowledge: Limited Conservativity
3
which the knowledge is acquired. As we will see, this is in contrast to Justiﬁed
Knowledge. The distinction between the inﬁnite conjunction, the ﬁxed point
axiom, and how common knowledge is achieved is addressed in [6]. [12] too,
provides a survey with examples but does not include a distinct formalism.
There is also an equivalent axiomatic formulation of common knowledge which
replaces the induction rule with the induction axiom in [17], which, for technical
convenience, we will use.
Deﬁnition 3. TC
n , S4C
n , and S5C
n axiom systems:
Propositional Logic plus
Axioms:
T, S4, or S5 axioms for Ki, i = 1, 2, . . . , n, respectively;
K: C(ϕ →ψ) →(Cϕ →Cψ) ;
T: Cϕ →ϕ ;
Cϕ →E(Cϕ), where Eϕ = K1ϕ ∧K2ϕ ∧. . . ∧Knϕ ;
Induction Axiom: ϕ ∧C(ϕ →Eϕ) →Cϕ .
Rules:
Necessitation: ⊢ϕ ⇒⊢Kiϕ , for i = 1, 2, . . . , n
Necessitation: ⊢ϕ ⇒⊢Cϕ .
Deﬁnition 4. Models for TC
n , S4C
n , and S5C
n : M = ⟨W, R1, R2, . . . , Rn, RC, ⊩⟩
where
•M = ⟨W, R1, R2, . . . , Rn, ⊩⟩is a Tn, S4n, or S5n model, respectively
• RC = (
n
i=1
Ri)∗, that is the transitive closure of all the agents’ relations
• The forcing relation ⊩is extended to all formulas so RC corresponds to C:
M, u ⊩Cϕ ⇔(∀v ∈M)[uRCv →M, v ⊩ϕ] .
Theorem 2. TC
n , S4C
n , and S5C
n are sound and complete with respect to their
models (cf. [10], p. 70ﬀ, [17], p. 47ﬀ).
The agents’ logic plays a role in determining the strength of the common knowl-
edge operator C. In the systems deﬁned above, C is always at least as strong as
Ki. Showing that in TC
n , S4C
n , and S5C
n , C satisﬁes the T, S4, and S5 axioms,
respectively, is given as an exercise in [10], p. 93.
3
Justiﬁed Knowledge
Justiﬁed Knowledge was introduced by Artemov in [3,4] as the forgetful projec-
tion of the evidence-based knowledge represented by an appropriate adaptation
of LP (Logic of Proofs). In LP systems (TnLP, S4nLP, S5nLP), each formula /
subformula carries with it a proof term representing a particular proof of the
formula / subformula from the axioms. Justiﬁed knowledge systems are ones in
which all proofs are identiﬁed as one. Whereas Cϕ asserts that ϕ is common

4
E. Antonakos
knowledge, Jϕ asserts that ϕ is common knowledge arising from a proof of ϕ
or some other agreed-upon acceptable set of evidences. Though the proof of ϕ
is not explicitly presented with the assertion Jϕ, it is reproducible. This is the
important Realization Theorem which provides an algorithm to reconstruct LP
proof terms. For more details on this, the reader should consult [4].
As with the common knowledge logics, the construction of the justiﬁed knowl-
edge logics TJ
n, S4J
n, and S5J
n builds on the multi-agent logics. In C systems the
agents’ logic determines the strength of C while in J systems the strength of J is
chosen independently to be weaker, stronger, or the same as that of the agents’.
In the aforementioned logics, the modality J will be assumed to be S4 unless
otherwise speciﬁed.
Deﬁnition 5. TJ
n, S4J
n, and S5J
n axiom systems:
Propositional Logic plus
Axioms:
T, S4, or S5 axioms for Ki, i = 1, 2, . . . , n;
S4 axioms for J ;
Connection Principle: Jϕ →Kiϕ .
Rules:
Necessitation for all Ki: ⊢ϕ ⇒⊢Kiϕ ;
Necessitation for J: ⊢ϕ ⇒⊢Jϕ .
Deﬁnition 6. Models for TJ
n, S4J
n, and S5J
n: M = ⟨W, R1, R2, . . . , Rn, RJ, ⊩⟩
where
• M = ⟨W, R1, R2, . . . , Rn, ⊩⟩is a Tn, S4n, or S5n model, respectively
• RJ ⊆W × W is reﬂexive and transitive relation such that RJ ⊇(
n
i=1
Ri)∗
(where ∗is transitive closure)
• The forcing relation ⊩is extended to all formulas so RJ corresponds to J:
M, u ⊩Jϕ ⇔(∀v ∈M)[uRJv →M, v ⊩ϕ] .
Theorem 3. TJ
n, S4J
n, and S5J
n are sound and complete with respect to their
models, as shown in [4].
Recall that in common knowledge models, RC = (
n
i=1
Ri)∗and so RC ⊆RJ.
Thus in a context where we can compare the two, i.e. a hybrid model with both
RC and RJ, it seems (if ϕ contains no Js) Jϕ ⇒Cϕ but not vice versa. More
formally, we have the following proposition.
Deﬁnition 7. Let ϕ∗be ϕ with each instance of a J replaced by a C.
Proposition 1. (S4J
n)∗⊂S4C
n but (S4J
n)∗̸= S4C
n .

Justiﬁed and Common Knowledge: Limited Conservativity
5
Proof. It needs to be shown that the ∗-translation of each each rule and axiom
of S4J
n is provable in S4C
n . Artemov shows this in [4] using the equivalent axiom-
atization of S4C
n from [10]. It is only the Induction Axiom of S4C
n which is not
provable in (S4J
n)∗, yielding the strict inclusion.
⊓⊔
The case in which the J of S5J
n is an S5 modality, that is S5J(S5)
n
, is considered in
[18] (where she names it S5nS5). An S5J(S5)
n
-model is like an S5J
n model except
that RJ will now be an equivalence relation.
Corollary 1. Let I.A. be the induction axiom. Then
S4C
n ≡(S4J
n)∗+ I.A. ,
TC
n ≡(TJ
n)∗+ I.A. ,
S5C
n ≡(S5J(S5)
n
)∗+ I.A. .
Proof. The strict inclusion of the J systems follows from Proposition 1 and
noticing that C satisﬁes the 4 axiom in TC
n and the 5 axiom in S5C
n . When the
induction axiom is added, the equivalence is clear.
⊓⊔
Indeed, from Corollary 1, in any of the justiﬁed knowledge systems mentioned,
Jϕ ⇒Cϕ∗.
The evidence-based common knowledge semantics for J systems are further
enriched by Artemov’s Realization Theorem mentioned at the start of the sec-
tion. This gives a constructive approach to recovering or realizing the full proof
terms of the evidence-based knowledge systems.
Theorem 4 (Realization Theorem). There is an algorithm that, given an
S4J
n-derivation of a formula ϕ, retrieves an S4nLP-formula ψ, a realization of
ϕ, such that ϕ is ψ◦, where ◦replaces all proof terms with J, and S4nLP proves
ψ.
This theorem and a realization theorem for S5J
n (where J is an S4-modality) is
established in [4] while a realization theorem for S5J(S5)
n
is given in [18].
Other major advantages to justiﬁed knowledge are
• proofs in S4J
n are normalizable ([4]), but those in S4C
n are not
• S4J
2 is PSPACE-complete [9], whereas for n ≥2, S4C
n is EXPTIME-
complete [10].
These features have been exploited by Bryukhov in [8] to develop an auto-
mated theorem prover for S4J
n. Justiﬁed Knowledge oﬀers simpler, more con-
structive, and more automation-friendly approach to common knowledge.
4
Any Fool’s Knowledge
McCarthy’s model of common knowledge via “any fool knows” apparently goes
back to roughly 1970 ([10], p. 13), though its ﬁrst published appearance is in [16].
In this epistemic multi-agent system, the modality for each agent is denoted by S,
with an additional virtual agent, “any fool” denoted by O. In [16] p. 2, whatever

6
E. Antonakos
any fool knows, “everyone knows that everyone else knows,” and so someone
knows. Thus we may add an additional axiom linking the fool to the other people:
Oϕ →Sϕ. Call this the linking axiom. This corresponds exactly to Artemov’s
connection principle: Jϕ →Kiϕ. When McCarthy et al. use subscripted modals,
Si, to specify individual agents, S0 is the distinguished any fool operator O. Thus
we see that the “fool” is a particular agent, hence in any axiom, we may replace
all S modals by Os, though not vice versa.
Deﬁnition 8. The McCarthy et al. axioms are based on propositional logic plus:
linking axiom: Oϕ →Sϕ
K0: Sϕ →ϕ
K1: O(Sϕ →ϕ)
K2: O(Oϕ →OSϕ)
K3: O(Sϕ ∧S(ϕ →ψ) →Sψ)
K4: O(Sϕ →SSϕ)
K5: O(¬Sϕ →S¬Sϕ) .
We will look at three systems identiﬁed in [16] given by axioms K0-K3, K0-K4,
and K0-K5.1 These will be referred to as MT, M4, and M5 respectively. Model
semantics and completeness results for a variant of M5 is stated in [16]. From
this and Lemma 3 below, it follows that S5J(S5)
n
is also sound and complete.
These logics immediately lend themselves to epsitemic scenarios, of which
Wise Men and Unfaithful Wives are addressed in [16]. These particular axioms
do not seem to be built on standard formulations of modal logics yet we can
see that Artemov’s justiﬁed knowledge operator J plays a role equivalent to
McCarthy’s any fool operator O. In particular, we have the following theorem.
Deﬁnition 9. Let ϕ⋆be ϕ with each instance of a J replaced by an O and each
Ki replaced by an Si.
Theorem 5. (TJ
n)⋆≡MT , (S4J
n)⋆≡M4 , and (S5J(S5)
n
)⋆≡M5 .
Proof. Immediate from the following three lemmas.
⊓⊔
Lemma 1. (TJ
n)⋆≡MT.
Proof. Recall that J is an S4 modality while the Ki are T modalities.
(⇐) To show (TJ
n)⋆⊃MT, TJ
n must satisfy MT axioms (K0-K3 and the link-
ing axiom), where Os are Js and Sis are Kis.
Linking axiom: TJ
n ⊢Jϕ →Kiϕ ;
the connection principle
K0: TJ
n ⊢Kiϕ →ϕ ;
T axiom for Ki
K1: TJ
n ⊢J(Kiϕ →ϕ) ;
J necessitation of T axiom of Ki
K2: TJ
n ⊢J(Jϕ →JKiϕ) ;
1 In [16], K0 is omitted from these lists. Given other statements in the paper, this
clearly is just an oversight.

Justiﬁed and Common Knowledge: Limited Conservativity
7
1. TJ
n ⊢Jϕ →JJϕ
4 axiom for J
2. TJ
n ⊢Jϕ →Kiϕ
the connection principle
3. TJ
n ⊢J(Jϕ →Kiϕ)
from 2. by J necessitation
4. TJ
n ⊢JJϕ →JKiϕ
from 3. by K axiom for J
5. TJ
n ⊢Jϕ →JKiϕ
from 1. and 4.
6. TJ
n ⊢J(Jϕ →JKiϕ)
from 5. by J necesitation
K3: TJ
n ⊢J(Kiϕ ∧Ki(ϕ →ψ) →Kiψ) ;
J necessitation of K axiom for Ki.
As mentioned above, “any fool” is a particular agent and so in any axiom all
the Ss may be replaced by Os. Consider K0′-K3′ and the linking axiom′ where
we do just that:
Linking axiom′: TJ
n ⊢Jϕ →Jϕ ;
propositional tautology
K0′: TJ
n ⊢Jϕ →ϕ ;
T axiom for J
K1′: TJ
n ⊢J(Jϕ →ϕ) ;
J necessitation of T axiom of J
K2′: TJ
n ⊢J(Jϕ →JJϕ) ;
J necessitaton of 4 axiom for J
K3′: TJ
n ⊢J(Jϕ ∧J(ϕ →ψ) →Jψ) ;
J necessitation of K axiom for J.
(⇒) (TJ
n)⋆⊂MT. We must show that MT satisﬁes the (TJ
n)⋆axioms and
rules. Remember that “any fool” O is a particular S agent.
S axioms:
K: MT ⊢Sϕ ∧S(ϕ →ψ) →Sψ ;
by K3, linking axiom, K0
T: MT ⊢Sϕ →ϕ ;
K0
O axioms:
T: MT ⊢Oϕ →ϕ ;
by K0, O is a particular S
K: MT ⊢Oϕ ∧O(ϕ →ψ) →Oψ ;
by K axiom for S, O is a an S
4: MT ⊢Oϕ →OOϕ ;
by K2, T axiom for O, O is an S
Connection axiom: MT ⊢Oϕ →Sϕ ;
the linking axiom
O necessitation: This follows from the fact that each S and O axiom is ne-
sessitated.
K axiom for S and O is necessitated by K3.
T axiom for S and O is necessitated by K1.
4 axiom for O is necessitated by K2.
S necessitation: This follows from O necessitation and the linking axiom.
⊓⊔
Lemma 2. (S4J
n)⋆≡M4 .
Proof. Recall that J and Ki are S4 modalities.
(⇐) (S4J
n)⋆⊃M4 follows from Lemma 1 and
K4: S4J
n ⊢J(Kiϕ →KiKiϕ) ;
by J necessitation of 4 axiom for Ki
K4′ = K2′
(⇒) (S4J
n)⋆⊂M4 follows from Lemma 1 and
S axioms:
4: M4 ⊢Sϕ →SSϕ ;
by K4, T axiom for O.
O necessitation: 4 axiom for S is necessitated by K4.
⊓⊔

8
E. Antonakos
Lemma 3. (S5J(S5)
n
)⋆≡M5 .
Proof. Recall that J and Ki are S5 modalities.
(⇐) (S5J(S5)
n
)⋆⊃M5 follows from Lemma 2 and
K5: S5J(S5)
n
⊢J(¬Kiϕ →Ki¬Kiϕ) ;
by J necessitation of 5 axiom for Ki.
K5′: S5J(S5)
n
⊢J(¬Jϕ →J¬Jϕ) ;
by J necessitation of 5 axiom for J.
(⇒) (S5J(S5)
n
)⋆⊂M5 follows from Lemma 2 and
S axioms:
5: M5 ⊢¬Sϕ →S¬Sϕ ;
by K5, T axiom for O
O axioms:
5: M5 ⊢¬Oϕ →O¬Oϕ ;
by K5, T axiom for O, O is an S.
O necessitation: 5 axiom for O and S necessitated by K5.
⊓⊔
Lemma 3 completes the proof of Theorem 5. Despite quite diﬀerent motiva-
tions and technical backgrounds, McCarthy’s “any fool” and Artemov’s justiﬁed
knowledge approaches lead to the same multi-modal logics.
Corollary 2. There is a Realization Theorem for MT, M4, and M5 providing
evidence-based semantics for McCarthy’s “any fool” knowledge operator O.
5
Limited Conservativity
A logic T with language L is a conservative extension of a logic T′ with language
L′ ⊆L if for sentences ϕ of L′, T proves ϕ if and only if T′ proves ϕ.
Recall
the deﬁnition for ∗from Section 3 which renames J to C. As the logics (S4J
n)∗
and S4C
n have the same language and yet are not equal, it is clear that S4C
n can
not be a conservative extension of (S4J
n)∗, it is however a conservative extension
over all formulas in which C occurs only negatively. We say that a symbol or
subformula X occurs negatively in a formula F if, when F is rewritten to have no
implication symbols, X is in the scope of a negation symbol (or an odd number
of negations). For example, X occurs only negatively in these ﬁrst two formulas
and both positively and negatively in the last: X →Y , (¬(A ∧X) →B) →Y ,
A ∧X →B ∨X.
Theorem 6. If ϕ is a formula of S4J
n such that all occurrences of J in ϕ are
negative, then S4J
n ⊢ϕ
⇔
S4C
n ⊢(ϕ)∗.
In some sense this result is tight as the induction axiom (ϕ∧J(ϕ →Eϕ) →Jϕ)
which distinguishes (S4J
n)∗from S4C
n has, along with a negative occurrence of J,
a single positive occurrence of J.
Proof. (⇒) is secured by the inclusion (S4J
n)∗⊂S4C
n of Proposition 1.
(⇐) This direction is a consequence of the Main Lemma which follows. We
show this direction by proving the contrapositive. Suppose ϕ is a formula of S4J
n
such that all occurrences of J in ϕ are negative and S4J
n ̸⊢ϕ. By completeness,

Justiﬁed and Common Knowledge: Limited Conservativity
9
there is a model M and a world x such that M, x ⊩¬ϕ. By the Main Lemma,
M C, x ⊩C ¬(ϕ)∗, hence S4C
n ̸⊢(ϕ)∗, since M C (with RJ ignored) is a model for
S4C
n .
⊓⊔
Lemma 4 (Main Lemma). Let M be a S4J
n-model. Add the relation RC of
reachability along R1, . . . , Rn to M and get the augmented model M C, where ⊩C
coincides with ⊩on variables, and the modality C corresponds to RC. Let ϕ be
a formula of S4J
n. Then
if all occurrences of J in ϕ are positive, then x ⊩ϕ
⇒
x ⊩C (ϕ)∗;
if all occurrences of J in ϕ are negative, then x ̸⊩ϕ
⇒
x ̸⊩C (ϕ)∗.
Proof. By induction on ϕ.
Base case is secured by the deﬁnition of ⊩C.
Boolean case: ϕ ≡ψ →θ.
Subcase: all occurrences of J in ϕ are positive and x ⊩ϕ. Then x ̸⊩ψ or
x ⊩θ. In the former case all occurrences of J in ψ are negative and, by the
induction hypothesis, x ̸⊩C (ψ)∗. In the latter case all occurrences of J in θ are
positive and, by the induction hypothesis, x ⊩C (θ)∗. In either case, x ⊩C (ϕ)∗.
Subcase: all occurrences of J in ϕ are negative and x ̸⊩ϕ. Then x ⊩ψ and
x ̸⊩θ. Since all occurrences of J in ψ are positive and all occurrences of J in
θ are negative, by the induction hypothesis, x ⊩C (ψ)∗and x ̸⊩C (θ)∗, hence
x ̸⊩C (ϕ)∗.
Case: ϕ ≡Kiψ.
Subcase: all occurrences of J in ϕ are positive and x ⊩ϕ. Then all occurrences
of J in ψ are positive and y ⊩ψ, for all y such that xRiy. By the induction
hypothesis, y ⊩C (ψ)∗, for all y such that xRiy, hence x ⊩C (Kiψ)∗, i.e., x ⊩C
(ϕ)∗.
Subcase: all occurrences of J in ϕ are negative and x ̸⊩ϕ. Then for some y
such that xRiy, y ̸⊩ψ. Since all occurrences of J in ψ are also negative, by the
induction hypothesis, y ̸⊩C (ψ)∗, hence x ̸⊩C (Kiψ)∗, i.e., x ̸⊩C (ϕ)∗.
Case: ϕ ≡Jψ.
Subcase: all occurrences of J in ϕ are positive and x ⊩ϕ. Then all occurrences
of J in ψ are also positive and y ⊩ψ, for all y such that xRJy. Since RC ⊆RJ,
y ⊩ψ, for all y such that xRCy. By the induction hypothesis, y ⊩C (ψ)∗, for all
y such that xRCy. Hence x ⊩C C(ψ)∗, i.e., x ⊩C (Jψ)∗, i.e., x ⊩C (ϕ)∗.
Subcase: ‘all occurrences of J in ϕ are negative and x ̸⊩ϕ’ is impossible, since
ϕ ≡Jψ and the displayed occurrence of J is positive in Jψ.
⊓⊔
Corollary 3. If χ, ϕ and ψ are formulas in the language of S4n, then
S4C
n ⊢χ ∧Cϕ →ψ ⇔S4J
n ⊢χ ∧Jϕ →ψ.
Proof. As per Theorem 6, χ ∧Jϕ →ψ has J only in negative position.
⊓⊔
Corollary 4. If χ, ϕ and ψ are formulas in the language of Tn, then
TC
n ⊢χ ∧Cϕ →ψ ⇔TJ
n ⊢χ ∧Jϕ →ψ.

10
E. Antonakos
Proof. Analogous to the proof of Theorem 6 if the Main Lemma starts with
TJ
n-models (J is an S4 modality) and completeness for TJ
n.
⊓⊔
Corollary 5. If χ, ϕ and ψ are formulas in the language of S5n, then
S5C
n ⊢χ ∧Cϕ →ψ ⇔S5J(S5)
n
⊢χ ∧Jϕ →ψ.
Proof. Analogous to the proof of Theorem 6. if the Main Lemma starts with
S5J(S5)
n
-models (J is an S5 modality) and completeness for S5J(S5)
n
.
⊓⊔
In fact, in Corollary 5, the justiﬁed knowledge system can be weakened to S5J
n,
where J is an S4 modality. Note that in the proof of Theorem 6, the case of ϕ ≡
Jψ requires only that RC ⊆RJ and not that RJ be of the same logical strength.
The proof will actually go through with any modality whose accessibility relation
contains RC. However, if J is to be knowledge, RJ is semantically required to
be reﬂexive and transitive. Thus for all formulas with only negative occurences
of C, S5C
n is a conservative extension of (S5J
n)∗.
6
Conclusions
This conservativity of C over J limited to formulas with C in negative position
would seem to lend itself to uses of J in place of C in situations in which common
knowledge is applied or assumed, rather than derived or concluded.
We have also seen that Artemov’s evidence-based approach to common knowl-
edge leads to the same multi-modal logic systems as McCarthy’s ‘any fool’ ax-
iomatic approach. This points towards applications of J and endows the O sys-
tems with a constructive, evidence-based semantics via the Realization Theorem.
We may also care to consider whether conservativity holds for a larger class of
formulas and what beneﬁts there may be to considering a logic which contains
both J and C modalities.
Acknowledgements
Gratitude is due to Sergei Artemov for his guidance and for pointing me towards
this problem. Thanks are due to Melvin Fitting for providing a preprint of his
article referenced and to those who oﬀered suggestions to drafts of this paper,
including the reviewers of this volume.
References
1. L. Alberucci, G. Jaeger. About cut elimination for logics of common knowledge.
Annals of Pure and Applied Logic, 133:73-99, 2005.
2. S. Artemov. Explicit provability and constructive semantics. Bulletin of Symbolic
Logic, 7(1): 1-36, 2001.
3. S. Artemov. Evidence-Based Common Knowledge. Technical Report TR-2004018,
CUNY Ph.D. Program in Computer Science, 2004.
4. S. Artemov. Justiﬁed Common Knowledge. Theoretical Computer Science, 357
(1-3): 4-22, 2006.
5. R. J. Aumann. Agreeing to Disagree. Annals of Statistics, 4(6): 1236-1239, 1976.
6. J. Barwise. Three Views of Common Knowledge. TARK 1988: 365-379.

Justiﬁed and Common Knowledge: Limited Conservativity
11
7. J. van Benthem, D Sarenac. The Geometry of Knowledge. ILLC Report PP-2004-
21, University of Amsterdam, 2004.
8. Y. Bryukhov. Integration of decision procedures into high-order interactive provers.
Ph.D. thesis, CUNY Graduate School, 2005.
9. S. Demri. Complexity of Simple Dependent Bimodal Logics. Laboratoire LEIBNIZ-
CNRS, U.M.R. 5522, manuscript, 2005.
10. R. Fagin, J. Halpern, Y. Moses, and M. Vardi. Reasoning About Knowledge. MIT
Press, 1995.
11. M. Fitting. Modal Proof Theory. In Handbook of Modal Logic, Patrick Blackburn
and Johan van Benthem and Frank Wolter, editors, Elsevier, 2006.
12. J. Geanakoplos. Common Knowledge. TARK 1992: 254-315.
13. J. Halpern and Y. Moses. Knowledge and common knowledge in a distributed
environment. Journal of the ACM, 37(3): 549-587, 1990. (A preliminary version
appeared in 1984.)
14. D. Lehmann. Knowledge, common knowledge, and related puzzles. Proc.3rd ACM
Symposium on Principles of Distributed Computing, 62-67, 1984.
15. D. Lewis. Convention, A Philosophical Study. Harvard University Press, 1969.
16. J. McCarthy, M. Sato, T. Hayashi, and S. Igarishi. On the Model Theory of Knowl-
edge. Technical Report STAN-CS-78-657, Stanford University, 1978.
17. J.-J. Ch. Meyer and W. van der Hoek. Epistemic Logic of AI and Computer Sci-
ence. Cambridge Tracts in Theoretical Computer Science, 41. Cambridge Univer-
sity Press, 1995.
18. N. Rubtsova. On realization of S5 modalitiy by evidence terms. Journal of Logic
and Computation, 16: 671-684, 2006.

The Intensional Lambda Calculus
Sergei Artemov1 and Eduardo Bonelli2
1 Graduate Center CUNY, PhD Program in Computer Science, 365 Fifth Ave.,
New York, NY 10016, U.S.A.
sartemov@gc.cuny.edu
2 LIFIA, Fac. de Inform´atica, UNLP, Argentina and CONICET
eduardo@lifia.info.unlp.edu.ar
Abstract. We introduce a natural deduction formulation for the Logic
of Proofs, a reﬁnement of modal logic S4 in which the assertion 2A
is replaced by [[s]]A whose intended reading is “s is a proof of A”. A
term calculus for this formulation yields a typed lambda calculus λI that
internalises intensional information on how a term is computed. In the
same way that the Logic of Proofs internalises its own derivations, λI
internalises its own computations. Conﬂuence and strong normalisation
of λI is proved. This system serves as the basis for the study of type
theories that internalise intensional aspects of computation.
1
Introduction
This paper introduces a typed lambda calculus that internalises its own com-
putations. Such a system is obtained by a propositions-as-types [GLT89] inter-
pretation of a logical system for provability which internalises its own proofs,
namely the Logic of Proofs LP [Art95, Art01]. Proofs are represented as combi-
natory terms (proof polynomials). In the minimal propositional logic fragment
of LP proof polynomials are constructed from proof variables and constants
using two operations: application “·” and proof-checker “!”. The usual proposi-
tional connectives are augmented by a new one: given a proof polynomial s and
a proposition A build [[s]]A. The intended reading is: “s is a proof of A”. The
axioms and inference schemes of LP are:
A0. Axiom schemes of minimal logic in the language of LP
A1. [[s]]A ⊃A
“veriﬁcation”
A2. [[s]](A ⊃B) ⊃([[t]]A ⊃[[s · t]]B)
“application”
A3. [[s]]A ⊃[[!s]][[s]]A
“proof checker”
R1. Γ ⊢A ⊃B and Γ ⊢A implies Γ ⊢B
“modus ponens”
R2. If A is an axiom A0-A3, and c is a proof constant,
then ⊢[[c]]A
“necessitation”
For veriﬁcation one reads:“if s is a proof of A, then A holds”. As regards the
proof polynomials the standard interpretation is as follows. For application one
reads: “if s is a proof of A ⊃B and t is a proof of A, then s · t is a proof of B”.
Thus “·” represents composition of proofs. For proof checking one reads: “if s is
S. Artemov and A. Nerode (Eds.): LFCS 2007, LNCS 4514, pp. 12–25, 2007.
c
⃝Springer-Verlag Berlin Heidelberg 2007

The Intensional Lambda Calculus
13
a proof of A, then !s is a proof of the sentence ‘s is a proof of A’ ”. Thus !s is
seen as a computation that veriﬁes [[s]]A.
First we introduce a natural deduction (ND) formulation LP−
nd for LP.
Following recent work on judgemental reconstruction [ML83] of intuitionistic
S4 [DP96, DP01b, DP01a], judgements are introduced in which a distinction is
made between propositions whose truth is assumed from those whose validity is
assumed. Judgements in LP−
nd are of the form:
v1 : A1 valid, . . . , vn : An valid; a1 : B1 true, . . . , am : Bm true ⊢A true | s
which expresses “s is evidence that A is true, assuming that for each i ∈1..n, vi
is evidence that Ai is valid and assuming that for each j ∈1..m, aj is evidence
that Bj is true”. Such judgements are called hypothetical judgements [ML83].
Evidence s is a constituent part of the judgement without which the proposed
reading is no longer possible. Its importance is reﬂected in the following intro-
duction rule for the [[s]] connective:
Δ; · ⊢A | s
2I
Δ; Γ ⊢[[s]]A |!s
This scheme internalises proofs of validity: If s is evidence that A is uncondition-
ally true (“·” indicates an empty set of hypothesis of truth), then it is true that
s is a proof of A. The new witness to this fact is registered as the evidence !s.
The “!” operator is reminiscent of that of proof polynomials. However, in LP−
nd,
proof terms such as s encode ND derivations and thus are no longer the proof
polynomials of LP.
At the basis of the meaning of hypothetical judgements (provided by the ax-
ioms and inference schemes presented in Sec. 2) is the notion of substitution.
The following two principles, the Substitution Principle for Truth with Evidence
and the Substitution Principle for Validity with Evidence, reﬂect the true hypo-
thetical nature of hypothesis.
– If Δ; Γ ⊢A | s and Δ; Γ, a : A, Γ ′ ⊢B | t, then Δ; Γ, Γ ′ ⊢B | ta
s
– If Δ; · ⊢A | s and Δ, v : A, Δ′; Γ ⊢B | t, then Δ, Δ′; Γ ⊢Bv
s | tv
s
These principles allow derivations to be composed, a fundamental operation
on which the process of normalisation of derivations relies on. In fact, composi-
tion of derivations suﬃces, in general, to formulate rules for eliminating redun-
dancy in derivations. However, the fact that LP−
nd internalises its own proofs
presents a complication in this respect. For example, the na¨ıve simpliﬁcation
step depicted in Fig. 1 which relies on the Substitution Principle for Truth with
Evidence fails given that it modiﬁes the judgement that was originally justi-
ﬁed. On a more pragmatical level, such a normalisation process may produce
invalid derivations [AB06]. The problem stems in that the normalisation step
is attempting to identify, at the meta-level, the two derivations and LP−
nd hap-
pens to internalise its own derivations. As a consequence, the normalisation step
must be reﬂected in the logic too. More precisely, a new judgement expressing
the equality on evidence must be introduced. Accordingly, in Sec. 2.2 we extend

14
S. Artemov and E. Bonelli
Δ; Γ, a : A ⊢B | s
⊃I
Δ; Γ ⊢A ⊃B | λa : A.s
Δ; Γ ⊢A | t
⊃E
Δ; Γ ⊢B | (λa : A.s) · t
;
Δ; Γ ⊢B | sa
t
Fig. 1. Na¨ıve simpliﬁcation
our ND presentation LP−
nd with hypothetical judgements for evidence equality.
The normalisation process is thus internalised into the logic. For this amended
system, LPnd, the set of derivations is seen to be closed under normalisation.
In Sec. 4 we study a term assignment for LPnd, namely the intensional lambda
calculus (λI). λI results from extending the propositions-as-types correspondence
to LPnd. The normalisation process of derivations in LPnd yields a notion of
reduction on the typed lambda calculus terms. Just as LPnd internalises its own
derivations, the operational counterpart of this logic is seen to internalise the
reduction of derivations. We show that λI is strongly normalising and conﬂuent
by applying properties of higher-order rewrite systems.
Related work. S. Artemov introduced the Logic of Proofs in [Art95, Art01].
A ND presentation for LP is provided in [Art01]. This presentation relies on
combinatory terms as proof terms (proof polynomials). It is a ND system for
a logic that internalises Hilbert style proofs. As a consequence, the presence of
normalisation is not felt at the level of proof terms. Since we use proof terms
that encode ND proofs, the internalisation scheme implemented by 2I together
with the normalisation process on derivations has a visible impact in the design
of the inference schemes for our system LPnd.
V. Brezhnev [Bre01] formulates a system of labeled sequents. Roughly, a re-
ﬁnement of the sequent presentation of LP [Art01] is presented in which la-
beled sequents are derived rather than the sequents themselves. It has been
proved [Art95, Art01] that LP is a reﬁnement of S4 in the sense that any
cut-free derivation of S4 can be realized by one of LP. A realization of an S4
derivation is the process of appropriately ﬁlling in all occurrences of boxes 2
with proof polynomials such that a valid LP derivation is obtained. The aim of
the work of Brezhnev is to make this correspondence explicit. Also, he extends
the correspondence to other modal logics such as K, K4, D, D4 and T.
From a type theoretic perspective we should mention the theory of dependent
types [Bar92]. Dependent type theory is the type-theoretic counterpart of ﬁrst-
order logic via the propositions-as-types correspondence. Types may depend on
terms, in much the same way that a type [[s]]A depends on the proof term s.
In contrast to λI, dependent type theory lacks a notion of internalisation of
derivations.
More closely related to λI is the reﬂective λ-calculus (λ∞) [AA01]. λ∞is
a rigidly typed (all variables and subterms carry a ﬁxed type) lambda calcu-
lus which essentially results from a term assignment of the aforementioned ND

The Intensional Lambda Calculus
15
presentation of [Art01]. The diﬀerence with the approach of this paper is that in
the reﬂective λ-calculus [[s]]A is read as “s has type A”. Accordingly, hypothesis
are not labeled with variables, rather they are part of the formula. For example,
x : A ⊢x : A becomes [[x]]A ⊢[[x]]A. An unwanted complication is that the
desired internalisation property (namely, A1, A2, . . . , An ⊢B implies that for
fresh variables x1, x2, . . . , xn there exists a term t(x1, x2, . . . , xn) such that we
can prove [[x1]]A1, [[x2]]A2, . . . , [[xn]]An ⊢[[t(x1, x2, . . . , xn)]]B) changes the types
of the assumptions. As a consequence, operations on types having nested copies
of proof terms are required for typing. This also complicates the deﬁnition of
reduction on terms.
Note: For further details and full proofs see [AB06].
2
Natural Deduction for LP
Following [DP01b] we distinguish the following judgements: “A is a proposition”
(“A proposition” for short), “A true” and “A valid”. In the case of the second
and third judgements we assume that it is already known that “A proposition”.
The inference schemes deﬁning the meaning of “A proposition” are the usual
well-formedness conditions and hence are omitted. Our interest lies in providing
meaning to the following hypothetical judgements with explicit evidence:
v1 : A1 valid, . . . , vn : An valid; a1 : B1 true, . . . , am : Bm true ⊢A true | s
by a set of axiom schemes and inference schemes, where vi, i ∈1..n, and aj, j ∈
1..m, range over some given some set of evidence (of proof) variables {x1, x2, . . .}.
To the left of the semi-colon we place the assumptions of validity and to the
right the assumptions of truth. For the sake of readability, we drop the qualiﬁers
“valid” and “true”. Consequently, these judgements take the form:
v1 : A1, . . . , vn : An; a1 : B1, . . . , am : Bm ⊢A | s
In addition to the usual requirement that the vi and ai be distinct, we must also
require that they be fresh (i.e. that they do not occur in the Ai and Bi). Note also
that since we assume J1 through Jn, in a hypothetical proof of a hypothetical
judgement with explicit evidence, we may use the Ji as if we knew them. As a
consequence we can substitute an arbitrary derivation of Ji for all its uses by
means of the two aforementioned substitution principles.
2.1
Axiom and Inference Schemes
It is convenient to introduce ﬁrst a preliminary ND system (LP−
nd), point out its
weaknesses and then introduce the ﬁnal ND system LPnd. We begin by deﬁning
the set of Proof Terms, Propositions, Truth Contexts and Validity Contexts.
Proof Terms
s ::= x | s · s | λa : A.s | !s | Xtrt s as v : A in s
Propositions
A ::= P | A ⊃A | [[s]]A
Truth Contexts
Γ ::= · | Γ, a : A
Validity Contexts Δ ::= · | Δ, v : A

16
S. Artemov and E. Bonelli
Minimal Propositional Logic Fragment
oVar
Δ; Γ, a : A, Γ ′ ⊢A | a
Δ; Γ, a : A ⊢B | s
⊃I
Δ; Γ ⊢A ⊃B | λa : A.s
Δ; Γ ⊢A ⊃B | s
Δ; Γ ⊢A | t
⊃E
Δ; Γ ⊢B | s · t
Provability Fragment
mVar
Δ, v : A, Δ′; Γ ⊢A | v
Δ; · ⊢A | s
2I
Δ; Γ ⊢[[s]]A |!s
Δ; Γ ⊢[[r]]A | s
Δ, v : A; Γ ⊢C | t
2E
Δ; Γ ⊢Cv
r | Xtrt s as v : A in t
Fig. 2. Explanation for Hypothetical Judgements with Explicit Evidence
We write fv(s) for the set of free variables of a proof term. All free occurrences
of a (resp. v) in s are bound in λa : A.s (resp. Xtrt t as v : A in s). A propo-
sition is either a propositional variable P, an implication A ⊃B or a validity
proposition [[s]]A. Truth and validity contexts are sequences of labeled proposi-
tions; “·” denotes the empty context. We write sx
t for the result of substituting
all free occurrences of x in s by t and assume that bound variables are renamed
whenever necessary; likewise for Ax
t .
Deﬁnition 1. LP−
nd is deﬁned by the schemes of Fig. 2.
An informal explanation of some of these schemes follows. The axiom scheme
oVar states that the judgement “Δ; Γ, a : A, Γ ′ ⊢A | a” is evident in itself.
Indeed, if we assume that a is evidence that proposition A is true, then we may
immediately conclude that A is true with evidence a. The introduction scheme
for the [[s]]modality internalises metalevel evidence into the object logic. It states
that if s is unconditional evidence that A is true, then A is in fact valid with
witness s (i.e. [[s]]A is true). Evidence for the truth of [[s]]A is constructed from
the (veriﬁed) evidence that A is unconditionally true by preﬁxing it with a bang
constructor. Finally, 2E allows the discharging of validity hypothesis. In order
to discharge the validity hypothesis v : A, a proof of the validity of A is required.
In our system, this requires proving that [[r]]A is true with evidence s, for some
evidence of proof r and s. Note that r is evidence that A is unconditionally true
(i.e. valid) whereas s is evidence that [[r]]A is true. The former is then substituted
in the place of all free occurrences of v in the proposition C. This construction
is recorded with evidence Xtrt s as v : A in t in the conclusion. The mnemonic
symbols “Xtrt” stand for “extract” since, intuitively, evidence of the validity
of A may be seen to be extracted from evidence of the truth of [[r]]A. A sample
derivation in LP−
nd of [[s]]A⊃[[!s]][[s]]A follows.

The Intensional Lambda Calculus
17
oVar
·; a : [[s]]A ⊢[[s]]A | a
mVar
w : A; · ⊢A | w
2I
w : A; · ⊢[[w]]A |!w
2I
w : A; a : [[s]]A ⊢[[!w]][[w]]A |!!w
2E
·; a : [[s]]A ⊢[[!s]][[s]]A | Xtrt a as w : A in !!w
⊃I
·; · ⊢[[s]]A ⊃[[!s]][[s]]A | λa : [[s]]A.Xtrt a as w : A in !!w
The standard structural properties of judgements (weakening, contraction and
exchange) hold. Also, the substitution principles for truth with evidence and
validity with evidence may be proved by induction on the derivation. A more
interesting property is that LP−
nd internalises its own proofs of unconditional
truth.
Lemma 1 (Lifting [Art95]). Let Δ = u1 : A1, . . . , un : An and Γ = b1 :
B1, . . . , bm : Bm. If Δ; Γ ⊢A | r, then Δ, v1 : B1, . . . , vm : Bm; · ⊢[[s(u, v)]]A |
t(u, v) where s(u, v) = (λb : B.r) · v1 · v2 · . . . · vm and t(u, v) = Xtrt !λb :
B.r as u : (B ⊃A) in !(u · v1 · v2 . . . · vm).
2.2
Normalisation and Evidence Equality
As mentioned above a na¨ıve approach to normalisation is doomed to fail unless
our attempt to simplify (hence equate) derivations is reﬂected in the object logic.
Indeed, a new judgement must be considered, namely hypothetical judgements
for evidence equality:
Δ; Γ ⊢s ≡t : A
Read: “s and t are provably equal evidence of the truth of A under the validity
assumptions of Δ and the truth assumptions of Γ”. This judgement internalises
at the object level the equality of derivations induced by the normalisation steps.
Note that evidence for provable equality is not considered in hypothetical judge-
ments for evidence equality. Although this could be an interesting route for
exploration, in our setting we would then be forced to deﬁne a notion of equality
on this new kind of evidence, thus leading to an inﬁnite regression.
In addition to deﬁning the meaning of this new judgement by means of new
axiom and inference schemes, we must indicate how it aﬀects the meaning of
hypothetical judgements with explicit evidence.
Δ; Γ ⊢A | s
Δ; Γ ⊢s ≡t : A
EqEvid
Δ; Γ ⊢A | t
The upper left judgement of EqEvid is called the minor premise and the one on the
right the major premise. Fig. 3 deﬁnes the meaning of hypothetical judgement
for evidence equality1.
1 We omit the standard inference schemes for symmetry, transitivity and congruence
of evidence equality [AB06].

18
S. Artemov and E. Bonelli
Δ; Γ ⊢A | s
EqReﬂ
Δ; Γ ⊢s ≡s : A
Δ; Γ, a : A ⊢B | s
Δ; Γ ⊢A | t
EqBeta
Δ; Γ ⊢sa
t ≡(λa : A.s) · t : B
Δ; · ⊢A | s
Δ, v : A; Γ ⊢C | t
Eq2Beta
Δ; Γ ⊢tv
s ≡Xtrt !s as v : A in t : Cv
s
Δ; Γ ⊢A ⊃B | s
a /∈fv(s)
EqEta
Δ; Γ ⊢λa : A.(s · a) ≡s : A ⊃B
Δ; Γ ⊢[[s]]A | t
u /∈fv(t)
Eq2Eta
Δ; Γ ⊢Xtrt t as u : A in !u ≡t : [[s]]A
Fig. 3. Axioms for evidence equality
Deﬁnition 2. LPnd is obtained by augmenting the schemes of Fig. 2 with
EqEvid and the schemes of Fig. 3.
In the sequel we study hypothetical judgements derivable in LPnd. Note that
the structural properties of LP−
nd extend to LPnd.
We now return to normalisation of derivations. Two groups2 of contractions
of derivations are deﬁned: principal contractions and silent permutative contrac-
tions. The ﬁrst is internalised by the inference schemes deﬁning provable equality
of evidence. Permutative conversions need not be internalised since, in contrast
to principal contractions, they do not alter the end judgement. They are thus
dubbed silent permutative conversions. By deﬁning an appropriate notion of cut
segment one can show that contraction is weakly normalising: there is a sequence
of contractions to normal form [AB06].
Lemma 2. Contraction in LPnd is weakly normalising.
More importantly, we shall see shortly that contraction is in fact strongly nor-
malising. The proof of this is established via weak normalisation.
3
Provability Semantics
Rules of LPnd can be interpreted as admissible rules of LP, hence supplied with
a natural provability semantics. Interpretation of all rules other then ⊃I and
2E are straightforward. The rule ⊃I corresponds to the Abstraction Rule which
is admissible in LP [Art96]. There are two LP-compliant interpretations of the
rule 2E, cf. Fig. 4. The left one, which we suggest calling internalized reading
is self-explanatory. The right one, which we call leveled requires that a proof
constant d is speciﬁed as d : (r : A ⊃A). We leave a more detailed investigation
of the provability semantics of LPnd to further studies.
2 We ignore principal expansions in this extended abstract (see [AB06]).

The Intensional Lambda Calculus
19
Γ ⊢s : r : A
Γ, v : A ⊢t : C
Γ ⊢tv
r : Cv
r
Γ ⊢s : r : A
Γ, v : A ⊢t : C
Γ ⊢tv
d·s : Cv
d·s
Fig. 4. Interpretations of 2E
4
The Intensional Lambda Calculus
This section introduces the intensional lambda calculus (λI) and studies conﬂu-
ence and strong normalisation. We begin by deﬁning the set of raw terms of
λI:
Proper Terms
M ::= x | M · M | λa : A.M
|
!M | Xtrt M as v : A in M | e ▶M
Reduction Evidence
e ::= β([a : A]M, N) | β2([v : A]M, N)
|
Refl(M) | Sym(e) | e; e
|
Abs([a : A]e) | App(e, e)
|
BoxL(e) | BoxR(e) | xtrt(e, [v : A]e)
A raw term of the form M · N is an application, λa : A.M is an abstraction, !M
is a bang term, Xtrt M as v : A in N is an extraction and e ▶M is a registered
term. Reduction evidence β([a : A]M, N) is used to register that a principal ⊃
contraction was applied together with the actual parameters (λa : A.M and N)
and β2([v : A]M, N) is for principal 2 contractions. The remaining reduction
evidence terms are for the congruence inference schemes of evidence equality.
Let P range over an enumerable set of type variables. The set of raw types is
the set of propositions of LPnd. In λI proper terms are assigned pointed types
⟨A, s⟩and reduction evidence is assigned equality types s ≡t : A. Since the
typing schemes follow the axiom and inference schemes of LPnd, there are two
typing judgements:
1. Δ; Γ ⊢M  ⟨A, s⟩, read: “Proper term M has pointed type ⟨A, s⟩under type
assumptions Δ and Γ” and
2. Δ; Γ ⊢e  s ≡t : A, read: “Reduction evidence e has equality type s ≡t : A
under type assumptions Δ and Γ”.
Deﬁnition 3. A proper term M is typable if there exist type assumptions Δ
and Γ and a pointed type ⟨A, s⟩such that Δ; Γ ⊢M  ⟨A, s⟩is derivable using
the typing schemes presented in Fig. 5. Typability of reduction evidence (Δ; Γ ⊢
es ≡t : A) is deﬁned similarly [AB06]. A λI-term is a raw term that is typable.
The contractions deﬁning normalisation on derivations of LPnd induce a corre-
sponding reduction relation on the λI-terms that encode the derivations.
Deﬁnition 4 (λI-reduction). The λI-reduction relation (→) is obtained by
taking the contextual closure of the reduction axioms:

20
S. Artemov and E. Bonelli
Minimal Propositional Logic Fragment
oVar
Δ; Γ, a : A, Γ ′ ⊢a  ⟨A, a⟩
Δ; Γ, a : A ⊢M  ⟨B, s⟩
⊃I
Δ; Γ ⊢λa : A.M  ⟨A ⊃B, λa : A.s⟩
Δ; Γ ⊢M  ⟨A ⊃B, s⟩
Δ; Γ ⊢N  ⟨A, t⟩
⊃E
Δ; Γ ⊢M · N  ⟨B, s · t⟩
Provability Fragment
mVar
Δ, v : A, Δ′; Γ ⊢v  ⟨A, v⟩
Δ; · ⊢M  ⟨A, s⟩
2I
Δ; Γ ⊢!M  ⟨[[s]]A, !s⟩
Δ; Γ ⊢M  ⟨[[s]]A, s′⟩
Δ, v : A; Γ ⊢N  ⟨C, t⟩
2E
Δ; Γ ⊢Xtrt M as v : A in N  ⟨Cv
s , Xtrt s′ as v : A in t⟩
Δ; Γ ⊢M  ⟨A, s⟩
Δ; Γ ⊢e  s ≡t : A
EqEvid
Δ; Γ ⊢e ▶M  ⟨A, t⟩
Fig. 5. Typing schemes for proper terms
(λa : A.M) · N
→β
β([a : A]M, N) ▶M a
N
Xtrt !N as v : A in M
→β2
β2([v : A]M, N) ▶M v
N
(e ▶M) · N
→▶L
App(e, Refl(N)) ▶M · N
Xtrt e ▶N as v : A in M →▶xtr xtrt(e, [v : A]Refl(M)) ▶Xtrt N as v : A in M
Note that, just as proof terms are internalised as part of the process of proving
a formula in LP, so the process of reducing a λI-term internalises evidence of
reduction. Indeed, an application of the β reduction rule results in a λI-term
that incorporates a witness to the fact that such a reduction step was applied.
This reduction evidence provides intensional information on how the result was
computed.
Consider the term from the ordinary typed lambda calculus I · (I · b) (which
is also a term in λI) where I abbreviates λa : A.a. In the typed lambda calculus
it reduces in two diﬀerent ways to I · b (we underline the contracted redex):
1. I · (I · b) →I · b
2. I · (I · b) →I · b
The fact that both these reductions reach the same term is known as a “syntactic
coincidence” [HL91] in the rewriting/lambda calculus community. Although the
same term is reached they are computed in rather diﬀerent ways in the sense that
unrelated redexes are contracted. Note, however, that in λI these two derivations
now end in diﬀerent terms:
1. I · (I · b) →I · (β([a : A]a, b) ▶b)
2. I · (I · b) →β([a : A]a, (I · b)) ▶I · b

The Intensional Lambda Calculus
21
Since reduction is obtained as a straightforward mapping of contraction of
derivations, the following type-soundness result holds.
Lemma 3 (Subject Reduction). If M →λI N and Δ; Γ ⊢M  ⟨A, s⟩, then
Δ; Γ ⊢N  ⟨A, s⟩.
4.1
Conﬂuence and Strong Normalisation for λI
Higher-order term rewrite systems (HORS) [Klo80, Nip91, TER03] extend ﬁrst-
order term rewrite systems by allowing terms with binders. The λ-calculus is
the prototypical example of a HORS. λI can also be presented as a HORS -
we’ll present it as an HRS [Nip91]. In HRS the simply typed lambda calculus is
used as a meta-language for writing the left and right-hand side of rewrite rules.
Boldface is used for constants, x, y, . . . for variables, x.M for abstraction and
M(N) for application. The rewrite rules for λI are (the signature of the symbols
involved is straightforward and hence omitted):
app(abs(x.z(x)), y)
→β
evid(betaE(x.z(x), y), z(y))
xtrt(bang(y), x.z(x))
→β2
evid(betaBoxE(x.z(x), y), z(y))
app(evid(x, y), z)
→▶L
evid(appE(x, reﬂE(z)), app(y, z)
xtrt(evid(w, y), x.z(x)) →▶xtr evid(xtrtE(w, x.reﬂE(z(x))),xtrt(y, x.z(x)))
The interest in HOR is that general results on combinatorial properties of
rewriting can be established. Two such results are of use to us. The ﬁrst states
that orthogonal, pattern HRS are conﬂuent. Orthogonal means that rewrite steps
are independent: If two redexes in a term may be reduced, the reduction of one
of them does not “interfere” with the other one except possibly by duplicating or
erasing it. Pattern means that in the left-hand sides of rewrite rules free variables
can only be applied to distinct bound variables (modulo η-equivalence). This
guarantees that higher-order pattern matching behaves similar to the ﬁrst-order
case: uniﬁcation of higher-order patterns is decidable and most general uniﬁers
can be computed. We write PRS for pattern HRS.
Proposition 1 ([Nip91]). Orthogonal PRS are conﬂuent.
The λI-calculus is easily seen to be an orthogonal PRS: it is left-linear and
non-overlapping. We may thus immediately conclude, from Prop. 1, that it is
conﬂuent.
Proposition 2. λI is conﬂuent.
The other interesting property is that of uniform normalisation. First we intro-
duce some terminology. A rewrite step M →N is perpetual if whenever M has
an inﬁnite reduction, N has one too. A rewrite system is uniformly normalis-
ing if all its steps are perpetual. An example is the λI-calculus [CR36] which is
the standard λ-calculus in which the set of terms is restricted to those M such
that λx.N ⊆M implies x ∈fv(N). The proof of this fact for λI relies on two

22
S. Artemov and E. Bonelli
properties: (1) all reduction steps are non-erasing and (2) it is orthogonal. It
turns out that this result can be extended to arbitrary higher-order rewrite
systems.
Proposition 3 ([KOvO01]).
Non-erasing, orthogonal and fully-extended 3
second-order4 PRS are uniformly normalising.
A close look at the HRS presentation of λI reveals that it is in fact a non-erasing,
fully-extended, second-order PRS. Furthermore, we have already mentioned that
it is orthogonal. As a consequence, we conclude the following from Prop. 3.
Proposition 4. λI is uniformly normalising.
The interesting thing about uniformly normalisable rewrite systems is that weak
normalisation is equivalent to strong normalisation. Therefore, since we have
proved that λI is weakly normalising, we conclude that:
Proposition 5. λI is strongly normalising.
5
Conclusions
A study of the computational interpretation of the Logic of Proofs via the
propositions-as-types correspondence requires an appropriate ND presentation.
This paper presents one such system, LPnd, resulting from a judgemental analy-
sis [ML83, DP01a] of LP. The term assignment yields a typed lambda calculus,
called the intensional lambda calculus (λI), that is capable of internalising com-
putation evidence, in much the same way that LP is capable of internalising
derivability evidence. Computations in λI yield terms that include information
on how this computation is performed.
As mentioned, the fact that I · (I · b) →I · b and I · (I · b) →I · b reduce
to the same term in the standard lambda calculus is known as a “syntactic
coincidence” [HL91] since these terms are computed in diﬀerent ways. In λI the
corresponding reductions are no longer coﬁnal given that intensional information
on how the term was computed is part of the result. Further investigation on
the relation with equivalence of reductions as deﬁned by L´evy [L´ev78, TER03]
is left to future work.
Other interesting directions are the formulation of intensional calculi for linear
and classical logic given their tight connections with resource conscious computing
and control operators and the analysis of the explicit modality and how it relates
to staged computation and run-time code generation [DP96, WLPD98].
3 A rewrite system is said to be fully-extended if each of its rewrite rules (l, r) veriﬁes
the following: for every occurrence x(P1, . . . , Pn) in l of a free variable x, P1, . . . , Pn
is the list of all bound variables above it.
4 Deﬁne the order of a type A of the simply typed lambda calculus, written ord(A), to
be 1 if the type is a base type and max(ord(A1) + 1, A2) if A = A1 →A2. The order
of rewrite system is the maximum order of the types of the variables that occur in
its rewrite rules.

The Intensional Lambda Calculus
23
References
[AA01]
Jesse Alt and Sergei Artemov. Reﬂective λ-calculus. In Proceedings of the
Dagstuhl-Seminar on Proof Theory in Computer Science, volume 2183 of
LNCS, 2001.
[AB06]
Sergei Artemov and Eduardo Bonelli. The intensional lambda calcu-
lus. Technical report, December 2006. http://www.liﬁa.info.unlp.edu.ar/˜
eduardo/lamIFull.pdf.
[Art95]
Sergei Artemov. Operational modal logic. Technical Report MSI 95-29,
Cornell University, 1995.
[Art96]
Sergei Artemov. Proof realization of intuitionistic and modal logics. Tech-
nical Report MSI 96-06, Cornell University, 1996.
[Art01]
Sergei Artemov.
Uniﬁed semantics of modality and λ-terms via proof
polynomials. Algebras, Diagrams and Decisions in Language, Logic and
Computation, pages 89–118, 2001.
[Bar92]
Henk P. Barendregt. Lambda Calculi with Types. In S. Abramsky, D.M.
Gabbay, and T.S.E. Maibaum, editors, Handbook of Logic in Computer
Science, volume 2. Oxford University Press, 1992.
[Bre01]
Vladimir Brezhnev. On the logic of proofs. In Kristina Striegnitz, editor,
Proceedings of the Sixth ESSLLI Student Session, pages 35–45, 2001.
[CR36]
Alonzo Church and John B. Rosser. Some properties of conversion. Trans-
actions of the American Mathematical Society, 39:472–482, 1936.
[DP96]
Rowan Davies and Frank Pfenning. A modal analysis of staged computa-
tion. In Jr. Guy Steele, editor, Proceedings of the 23rd Annual Symposium
on Principles of Programming Languages, pages 258–270, St. Petersburg
Beach, Florida, January 1996. ACM Press.
[DP01a]
Rowan Davies and Frank Pfenning. A judgmental reconstruction of modal
logic. Mathematical Structures in Computer Science, 11:511–540, 2001.
[DP01b]
Rowan Davies and Frank Pfenning. A modal analysis of staged computa-
tion. Journal of the ACM, 48(3):555–604, May 2001.
[GLT89]
Jean-Yves Girard, Yves Lafont, and Paul Taylor. Proofs and Types. Cam-
bridge Tracts in Theoretical Computer Science. Cambridge University
Press, 1989.
[HL91]
G´erard Huet and Jean-Jacques L´evy. Computations in orthogonal rewrit-
ing systems.
In J.L. Lassez and G.D. Plotkin, editors, Computational
Logic; Essays in honor of Alan Robinson, pages 394–443. MIT Press, 1991.
[Klo80]
Jan W. Klop. Combinatory Reduction Systems. PhD thesis, CWI, Ams-
terdam, 1980. Mathematical Centre Tracts n.127.
[KOvO01]
Zurab Khasidashvili, Mizuhito Ogawa, and Vincent van Oostrom. Per-
petuality and uniform normalization in orthogonal rewrite systems. In-
formation and Computation, 164:118–151, 2001.
[L´ev78]
Jean-Jacques L´evy.
R´eductions correctes et optimales dans le lambda-
calcul. PhD thesis, Universit´e Paris VII, 1978.
[ML83]
Per Martin-L¨of. On the meaning of the logical constants and the justi-
ﬁcations of the logical laws. Lectures given at the meeting Teoria della
Dimostrazione e Filosoﬁa della Logica, in Siena, 6-9 April 1983, by the
Scuola di Specializzazione in Logica Matematica of the Universit`a degli
Studi di Siena., 1983.

24
S. Artemov and E. Bonelli
[Nip91]
Tobias Nipkow. Higher-order critical pairs. In Proceedings of the Sixth
Annual IEEE Symposium on Logic in Computer Science. IEEE Computer
Society Press, July 1991.
[TER03]
TERESE. Term Rewriting Systems, volume 55 of Cambridge Tracts in
Theoretical Computer Science. Cambridge University Press, March 2003.
[WLPD98]
Philip Wickline, Peter Lee, Frank Pfenning, and Rowan Davies. Modal
types as staging speciﬁcations for run-time code generation. ACM Com-
puting Surveys, 30(3es), September 1998.
A
Contractions for LPnd
1. Principal Contractions
Δ; Γ, a : A ⊢B | s
⊃I
Δ; Γ ⊢A ⊃B | λa : A.s
Δ; Γ ⊢A | t
⊃E
Δ; Γ ⊢B | (λa : A.s) · t
;
π
Δ; Γ ⊢B | sa
t
Δ; Γ, a : A ⊢B | s
Δ; Γ ⊢A | t
EqBeta
Δ; Γ ⊢sa
t ≡(λa : A.s) · t : B
EqEvid
Δ; Γ ⊢B | (λa : A.s) · t
Δ; · ⊢A | s
2I
Δ; Γ ⊢[[s]]A |!s
Δ, v : A; Γ ⊢C | t
2E
Δ; Γ ⊢Cv
s | Xtrt !s as v : A in t
;
π
Δ; Γ ⊢Cv
s | tv
s
Δ; · ⊢A | s
Δ, v : A; Γ ⊢C | t
Eq2Beta
Δ; Γ ⊢tv
s ≡Xtrt !s as v : A in t : Cv
s
EqEvid
Δ; Γ ⊢Cv
s | Xtrt !s as v : A in t
where π results from the Substitution Principle for Validity with Evidence.
2. Silent Permutative Contractions
Δ; Γ ⊢A1 ⊃A2 | s
Δ; Γ ⊢s ≡t : A1 ⊃A2
EqEvid
Δ; Γ ⊢A1 ⊃A2 | t
Δ; Γ ⊢A1 | r
⊃E
Δ; Γ ⊢A2 | t · r
;
Δ; Γ ⊢A1 ⊃A2 | s
Δ; Γ ⊢A1 | r
⊃E
Δ; Γ ⊢A2 | s · r
Δ; Γ ⊢s ≡t : A1 ⊃A2
Δ; Γ ⊢A1 | r
EqReﬂ
Δ; Γ ⊢r ≡r : A1
Eq ⊃E
Δ; Γ ⊢s · r ≡t · r : A2
EqEvid
Δ; Γ ⊢A2 | t · r

The Intensional Lambda Calculus
25
Δ; Γ ⊢[[s1]]A | s2
Δ; Γ ⊢s2 ≡r : [[s1]]A
EqEvid
Δ; Γ ⊢[[s1]]A | r
Δ, v : A; Γ ⊢C | t
2E
Δ; Γ ⊢Cv
s1 | Xtrt r as v : A in t
;
Δ; Γ ⊢[[s1]]A | s2
Δ, v : A; Γ ⊢C | t
2E
Δ; Γ ⊢Cv
s1 | Xtrt s2 as v : A in t
2E
Δ; Γ ⊢Cv
s1 | q
Δ; Γ ⊢s2 ≡r : [[s1]]A
Δ, v : A; Γ ⊢C | t
EqReﬂ
Δ, v : A; Γ ⊢t ≡t : C
Eq2E
Δ; Γ ⊢q ≡Xtrt r as v : A in t : Cv
s1 EqEvid
Δ; Γ ⊢Cv
s1 | Xtrt r as v : A in t
where q is the proof term Xtrt s2 as v : A in t

Generalized Non-deterministic Matrices and
(n,k)-ary Quantiﬁers
Arnon Avron and Anna Zamansky
Tel Aviv University, Ramat Aviv, Israel
{aa,annaz}@post.tau.ac.il
Abstract. An (n, k)-ary quantiﬁer is a generalized logical connective,
binding k variables and connecting n formulas. Canonical Gentzen-type
systems with (n, k)-ary quantiﬁers are systems which in addition to the
standard axioms and structural rules have only logical rules in which
exactly one occurrence of an (n, k)-ary quantiﬁer is introduced. The se-
mantics of such systems for the case of k ∈{0, 1} are provided in [16] us-
ing two-valued non-deterministic matrices (2Nmatrices). A constructive
syntactic coherence criterion for the existence of a 2Nmatrix for which
a canonical system is strongly sound and complete, is formulated there.
In this paper we extend these results from the case of k ∈{0, 1} to the
general case of k ≥0. We show that the interpretation of quantiﬁers in
the framework of Nmatrices is not suﬃcient for the case of k > 1 and in-
troduce generalized Nmatrices which allow for a more complex treatment
of quantiﬁers. Then we show that (i) a canonical calculus G is coherent
iﬀthere is a 2GNmatrix, for which G is strongly sound and complete,
and (ii) any coherent canonical calculus admits cut-elimination.
1
Introduction
Propositional canonical Gentzen-type systems, introduced in [2,3], are systems
which in addition to the standard axioms and structural rules have only logi-
cal rules in which exactly one occurrence of a connective is introduced and no
other connective is mentioned. Intuitively, the term “canonical systems” refers
to systems in which the introduction rules of a logical connective determine the
semantic meaning of that connective1. A natural constructive coherence criterion
can be deﬁned for the non-triviality of such systems, and it can be shown that
a canonical system admits cut-elimination iﬀit is coherent. The semantics of
such systems are provided by two-valued non-deterministic matrices (2Nmatri-
ces), which form a natural generalization of the classical matrix. A characteristic
2Nmatrix can be constructed for every coherent canonical propositional system.
In [16] the notion of a canonical system is extended to languages with (n, k)-
ary quantiﬁers. An (n, k)-ary quantiﬁer (for n > 0, k ≥0) is a generalized logical
connective, which binds k variables and connects n formulas. Any n-ary propo-
sitional connective can be thought of as an (n, 0)-ary quantiﬁer: for instance,
1 This is according to a long tradition in the philosophy of logic, established by Gentzen
in his classical paper “Investigations Into Logical Deduction” ([11]).
S. Artemov and A. Nerode (Eds.): LFCS 2007, LNCS 4514, pp. 26–40, 2007.
c
⃝Springer-Verlag Berlin Heidelberg 2007

Generalized Non-deterministic Matrices and (n,k)-ary Quantiﬁers
27
the standard ∧connective is an (2, 0)-ary quantiﬁer, as it binds no variables and
connects two formulas: ∧(ψ1, ψ2). The standard ﬁrst-order quantiﬁers ∃and ∀
are (1, 1)-quantiﬁers, while the simplest Henkin quantiﬁer QH ([13]) is a (4,1)-
quantiﬁer, as it binds 4 variables and connects one formula2:
QHx1x2y1y2ψ(x1, x2, y1, y2) := ∀x1 ∃y1
∀x2 ∃y2 ψ(x1, x2, y1, y2)
Non-deterministic matrices (Nmatrices) are a natural generalization of the
standard multi-valued matrix introduced in [2,3] and extended in [4,16]. In
these structures the truth-value assigned to a complex formula is chosen non-
deterministically out of a given non-empty set of options. [16] use two-valued
Nmatrices (2Nmatrices) extended to languages with (n, k)-ary quantiﬁers to pro-
vide non-deterministic semantics for canonical systems for the case of k ∈{0, 1}.
It is shown that there is a strong connection between the coherence of a canon-
ical calculus G and the existence of a 2Nmatrix, for which G is strongly sound
and complete.
In this paper we extend these results from the case of k ∈{0, 1} to the general
case of k ≥0. We show that the interpretation of quantiﬁers used in [16] is not
suﬃcient for the case of k > 1 and conclude that a more general interpretation
of quantiﬁers is needed. Then we introduce generalized Nmatrices (GNmatri-
ces), a generalization of Nmatrices, in which the approach to quantiﬁers used in
Church’s type theory ([10]) is adapted. Then it is shown that the following state-
ments concerning a canonical calculus G with (n, k)-ary quantiﬁers for k ≥0
and n > 0 are equivalent: (i) G is coherent, and (ii) there exists a 2GNmatrix,
for which G is strongly sound and complete. Finally, we show that any coherent
canonical calculus with (n, k)-ary quantiﬁers admits cut-elimination.
2
Preliminaries
In what follows, L is a language with (n, k)-ary quantiﬁers, that is with quanti-
ﬁers Q1, ..., Qm with arities (n1, k1), ..., (nm, km) respectively. For any n > 0 and
k ≥0, if a quantiﬁer Q in a language L is of arity (n, k), then Qx1...xk(ψ1, ..., ψn)
is an L-formula whenever x1, ..., xk are distinct variables and ψ1, ..., ψn are formu-
las of L. Denote by FrmL (Frmcl
L) the set of L-formulas (closed L-formulas). De-
note by T rmL (T rmcl
L) the set of L-terms (closed L-terms). V ar = {v1, v2, ..., }
is the set of variables of L. We use the metavariables x, y, z to range over el-
ements of V ar. Given an L-formula A, Fv[A] is the set of variables occurring
free in A. ≡α is the α-equivalence relation between formulas, i.e identity up to
the renaming of bound variables. We use [ ] for application of functions in the
meta-language, leaving the use of ( ) to the object language. We write Q−→x A
instead of Qx1...xkA, and ψ{−→t /−→z } instead of ψ{t1/z1, ..., tk/zk}.
2 In this way of recording combinations of quantiﬁers, dependency relations between
variables are expressed as follows: an existentially quantiﬁed variable depends on
those universally quantiﬁed variables which are on the left of it in the same row.

28
A. Avron and A. Zamansky
In the following two subsections, we brieﬂy reproduce the relevant deﬁnitions
from [16] of canonical systems with (n, k)-ary quantiﬁers and of the semantic
framework of Nmatrices.
2.1
Canonical Systems with (n, k)-ary Quantiﬁers
We use a simpliﬁed representation language from [16] for a schematic represen-
tation of canonical rules.
Deﬁnition 1. For k ≥0, n ≥1 and a set of constants Con, Ln
k(Con) is the
language with n k-ary predicate symbols p1, ..., pn and the set of constants Con
(and no quantiﬁers or connectives). The set of variables of Ln
k(Con) is V ar =
{v1, v2, ..., }.
Note that Ln
k(Con) and L share the same set of variables. Henceforth we also
assume3 that for every (n, k)-ary quantiﬁer Q of L, Ln
k(Con) is a subset of L.
Deﬁnition 2. Let Con be some set of constants. A canonical quantiﬁcational rule
of arity (n, k) is an expression of the form {Πi ⇒Σi}1≤i≤m/C, where m ≥0, C
is either ⇒Qv1...vk(p1(v1, ..., vk), ..., pn(v1, ..., vk)) or Qv1...vk(p1(v1, ..., vk), ...,
pn(v1, ..., vk)) ⇒for some (n, k)-ary quantiﬁer Q of L and for every 1 ≤i ≤m:
Πi ⇒Σi is a clause4 over Ln
k(Con).
Henceforth, in cases where the set of constants Con is clear from the context (it
is the set of all constants occurring in a canonical rule), we will write Ln
k instead
of Ln
k(Con).
A canonical rule is a schematic representation of the actual rule, while for a
speciﬁc application of the rule we need to instantiate the schematic variables by
the terms and formulas of L. This is done using a mapping function:
Deﬁnition 3. Let R = Θ/C be an (n, k)-ary canonical rule, where C is of one
of the forms (Q−→v (p1(−→v ), ..., pn(−→v )) ⇒) or (⇒Q−→v (p1(−→v ), ..., pn(−→v ))). Let Γ
be a set of L-formulas and z1, ..., zk - distinct variables of L. An ⟨R, Γ, z1, ..., zk⟩-
mapping is any function χ from the predicate symbols, terms and formulas of
Ln
k to formulas and terms of L, satisfying the following conditions:
– For every 1 ≤i ≤n, χ[pi] is an L-formula. χ[y] is a variable of L, and
χ[x] ̸= χ[y] for every two variables x ̸= y. χ[c] is an L-term, such that χ[x]
does not occur in χ[c] for any variable x occurring in Θ.
– For every 1 ≤i ≤n, whenever pi(t1, ..., tk) occurs in Θ, for every 1 ≤j ≤k:
χ[tj] is a term free for zj in χ[pi], and if tj is a variable, then χ[tj] does not
occur free in Γ ∪{Qz1...zk(χ[p1], ..., χ[pn])}.
– χ[pi(t1, ..., tk)] = χ[pi]{χ[t1]/z1, ..., χ[tk]/zk}.
χ is extended to sets of Ln
k-formulas as follows: χ[Δ] = {χ[ψ] | ψ ∈Δ}.
3 This assumption is not necessary, but it makes the presentation easier, as will be
explained in the sequel.
4 By a clause we mean a sequent containing only atomic formulas.

Generalized Non-deterministic Matrices and (n,k)-ary Quantiﬁers
29
Deﬁnition 4. An application of a canonical rule of arity (n, k)
R = {Πi ⇒Σi}1≤i≤m/Q−→v (p1(−→v ), ..., pn(−→v )) ⇒is any inference step of the
form:
{Γ, χ[Πi] ⇒Δ, χ[Σi]}1≤i≤m
Γ, Qz1...zk (χ[p1], ..., χ[pn]) ⇒Δ
where z1, ..., zk are variables, Γ, Δ are any sets of L-formulas and χ is some
⟨R, Γ ∪Δ, z1, ..., zk⟩-mapping.
An application of a canonical quantiﬁcational rule of the form
{Πi ⇒Σi}1≤i≤m/ ⇒Q−→v (p1(−→v ), ..., pn(−→v )) is deﬁned similarly.
For example, the two standard introduction rules for the (1, 1)-ary quantiﬁer
∀can be formulated as follows: {p(c) ⇒}/∀v1 p(v1) ⇒and {⇒p(v1)}/ ⇒
∀v1 p(v1). Applications of these rules have the forms:
Γ, A{t/w} ⇒Δ
Γ, ∀w A ⇒Δ
(∀⇒)
Γ ⇒A{z/w}, Δ
Γ ⇒∀w A, Δ
(⇒∀)
where z is free for w in A, z is not free in Γ ∪Δ ∪{∀wA}, and t is any term free
for w in A.
Notation: (Following [3,16]). Let −t = f, −f = t. Let ite(t, A, B) = A and
ite(f, A, B) = B. Let Φ, As (where Φ may be empty) denote ite(s, Φ ∪{A}, Φ).
For instance, the sequents A ⇒and ⇒A are denoted by A−a ⇒Aa for a = f
and a = t respectively. With this notation, an (n, k)-ary canonical rule has the
form {Σj ⇒Πj}1≤j≤m/Q−→z (p1(−→z ), ..., pn(−→z ))−s ⇒Q−→z (p1(−→z ), ..., pn(−→z ))s
for some s ∈{t, f}. For further abbreviation, we denote such rule by {Σj ⇒
Πj}1≤j≤m/Q(s).
Deﬁnition 5. A Gentzen-type calculus G is canonical if in addition to the α-
axiom A ⇒A′ for A ≡α A′ and the standard structural rules, G has only
canonical rules.
Deﬁnition 6. Two (n, k)-ary canonical introduction rules Θ1/C1 and Θ2/C2
for Q are dual if for some s ∈{t, f}: C1 = A−s ⇒As and C2 = As ⇒A−s,
where A = Qv1...vk(p1(v1, ..., vk), ..., pn(v1, ..., vk)).
Deﬁnition 7. For two sets of clauses Θ1, Θ2 over Ln
k, Rnm(Θ1 ∪Θ2) is a set
Θ1 ∪Θ′
2, where Θ′
2 is obtained from Θ2 by a fresh renaming of constants and
variables which occur in Θ1.
Deﬁnition 8 (Coherence)5. A canonical calculus G is coherent if for every
two dual canonical rules Θ1/ ⇒A and Θ2/A ⇒, the set of clauses Rnm(Θ1 ∪Θ2)
is classically inconsistent.
5 The coherence criterion for the propositional case was ﬁrst introduced in [2,3] and
then extended to the ﬁrst-order case in [16]. A strongly related coherence criterion
was also used in [14], where linear logic is used to reason about various sequent
systems. Also, the coherence criterion deﬁned in this paper can be shown to be
equivalent in the context of canonical calculi to the reductivity condition of [9]
(deﬁned for Gentzen-type systems with (n, k)-ary quantiﬁers which are more general
than the canonical calculi), as will be explained in the sequel.

30
A. Avron and A. Zamansky
Proposition 9 (Decidability of coherence). ([16]) The coherence of a
canonical calculus G is decidable.
2.2
Non-deterministic Matrices
Non-deterministic matrices6 (Nmatrices), were ﬁrst introduced in [2,3] and ex-
tended to the ﬁrst-order case in [4,17]. These structures are a generalization of
the standard concept of a many-valued matrix, in which the truth-value of a for-
mula is chosen non-deterministically from a given non-empty set of truth-values.
For interpretation of quantiﬁers, generalized distribution quantiﬁers7 are used.
Deﬁnition 10 ([16]) (Non-deterministic matrix). A non-deterministic ma-
trix (Nmatrix) for L is a tuple M =< V, D, O >, where: (i) V is a non-empty set
of truth values, (ii) D (designated truth values) is a non-empty proper subset of
V, and (iii) O is a set of interpretation functions: for every (n, k)-ary quantiﬁer
Q of L, O includes the corresponding distribution function ˜QM : P +(Vn) →
P +(V). A 2Nmatrix is any Nmatrix with V = {t, f} and D = {t}.
The notion of an L-structure is deﬁned standardly (see, e.g. [16,4]). In order to
interpret quantiﬁers, the substitutional approach is used, which assumes that
every element of the domain has a term referring to it. Thus given a structure
S = ⟨D, I⟩, the language L is extended with individual constants: {a | a ∈D}.
Call the extended language L(D). The interpretation function I is extended as
follows: I[a] = a.
An L-substitution σ is any function from variables to T rmcl
L(D). For an L-
substitution σ and a term t (a formula ψ), the closed term σ[t] (the sentence
σ[ψ]) is obtained from t (ψ) by substituting every variable x for σ[x].
Deﬁnition 11 (Congruence of terms and formulas)8. Let S be an L-
structure for an Nmatrix M. The relation ∼S between terms of L(D) is deﬁned
inductively as follows: (i) x ∼S x, (ii) For closed terms t, t′ of L(D): t ∼S t′
when I[t] = I[t′], (iii) If t1 ∼S t′
1, ..., tn ∼S t′
n, then f(t1, ..., tn) ∼S f(t′
1, ..., t′
n).
The relation ∼S between formulas of L(D) is deﬁned as follows:
– If t1 ∼S t′
1, t2 ∼S t′
2, ..., tn ∼S t′
n, then p(t1, ..., tn) ∼S p(t′
1, ..., t′
n).
– If ψ1{−→z /−→x } ∼S ϕ1{−→z /−→y }, ..., ψn{−→z /−→x } ∼S ϕn{−→z /−→y }, where −→x
=
x1...xk and −→y = y1...yk are distinct variables and −→z = z1...zk are new dis-
tinct variables, then Q−→x (ψ1, ..., ψn) ∼S Q−→y (ϕ1, ..., ϕn) for any (n, k)-ary
quantiﬁer Q of L.
6 For the connection between Nmatrices and other abstract semantics, see e.g. [7].
7 Distribution quantiﬁers were introduced in [6], with the intention to generalize
Mostowski’s proposal.
8 The motivation for this deﬁnition is purely technical and is related to extending the
language with the set of individual constants {a | a ∈D}. Suppose we have a closed
term t, such that I[t] = a ∈D. But a also has an individual constant a referring to
it. We would like to be able to substitute t for a in every context.

Generalized Non-deterministic Matrices and (n,k)-ary Quantiﬁers
31
The following is a straightforward generalization of Lemma 3.6 from [16].
Lemma 12. Let S be an L-structure for an Nmatrix M. Let ψ, ψ′ be formulas
of L(D). Let t1, ..., tn, t′
1, ..., t′
n be closed terms of L(D), such that ti ∼S t′
i for
every 1 ≤i ≤n. Then (1) If ψ ≡α ψ′, then ψ ∼S ψ′, and (2) If ψ ∼S ψ′, then
ψ{−→t /−→x } ∼S ψ′{−→
t′ /−→x }.
Deﬁnition 13 (Legal valuation). Let S = ⟨D, I⟩be an L-structure for a
Nmatrix M. An S-valuation v : Frmcl
L(D) →V is legal in M if it satisﬁes the
following conditions:
– v[ψ] = v[ψ′] for every two sentences ψ, ψ′ of L(D), such that ψ ∼S ψ′.
– v[p(t1, ..., tn)] = I[p][I[t1], ..., I[tn]].
– v[Qx1, ..., xk(ψ1, ..., ψn) is in the set
˜QM[{⟨v[ψ1{a1/x1, ..., ak/xk}], ..., v[ψn{a1/x1, ..., ak/xk}]⟩| a1, ..., ak ∈D}]
for every (n, k)-ary quantiﬁer Q of L.
Deﬁnition 14. Let S = ⟨D, I⟩be an L-structure for an Nmatrix M.
1. An M-legal S-valuation v is a model of a sentence ψ in M, denoted by
S, v |=M ψ, if v[ψ] ∈D.
2. Let v be an M-legal S-valuation. A sequent Γ ⇒Δ is M-valid in ⟨S, v⟩if
for every S-substitution σ: if S, v |=M σ[ψ] for every ψ ∈Γ, then there is
some ϕ ∈Δ, such that S, v |=M σ[ϕ]. A sequent Γ ⇒Δ is M-valid if for
every L-structure S and every M-legal S-valuation v, Γ ⇒Δ is M-valid in
⟨S, v⟩.
3. The consequence relation ⊢M between sets of L-formulas is deﬁned as fol-
lows: Γ ⊢M Δ if Γ ⇒Δ is M-valid.
Deﬁnition 15. A system G is sound for an Nmatrix M if ⊢G⊆⊢M. A system
G is complete for an Nmatrix M if ⊢M⊆⊢G. An Nmatrix M is characteristic
for G if G is sound and complete for M.
A system G is strongly sound for M if for every set of sequents S: if Γ ⇒Δ
is derivable in G from S, then for every L-structure S and every S-substitution
v, whenever S is M-valid in ⟨S, v⟩, Γ ⇒Δ is M-valid in ⟨S, v⟩.
Note that strong soundness implies (weak) soundness.
In addition to L-structures for languages with (n, k)-ary quantiﬁers, we will also
use Ln
k-structures for the simpliﬁed languages Ln
k, using which the canonical rules
are formulated. To make the distinction clearer, we shall use the metavariable S
for the former and N for the latter. Since the formulas of Ln
k are always atomic,
the speciﬁc 2Nmatrix for which N is deﬁned is immaterial, and can be omitted.
Henceforth we may speak simply of validity of sets of sequents over Ln
k.
Deﬁnition 16. ([16]) Let N = ⟨D, I⟩be an Ln
k-structure. DistN (the distribu-
tion of N) is the set {⟨I[p1][a1, ..., ak], ..., I[pn][a1, ..., ak]⟩| a1, ..., ak ∈D}.

32
A. Avron and A. Zamansky
3
Generalizing the Framework of Nmatrices
It is shown in [16] for the case of k ∈{0, 1} that a canonical calculus has a
strongly characteristic 2Nmatrix iﬀit is coherent. Moreover, if a 2Nmatrix M
is suitable for a calculus G, then G is strongly sound for M:
Deﬁnition 17 ([16]). Let G be a canonical calculus over L. A 2Nmatrix M is
suitable for G if for every (n, k)-ary canonical rule Θ/Q(s) of G, it holds that
for every Ln
k-structure N in which Θ is valid: ˜QM[DistN ] = {s}.
We will now show that the above property does not hold for the case of k > 1.
We ﬁrst prove that the suitability of M for G is not only a suﬃcient, but also
a necessary condition for the strong soundness of G for M for any k ≥0.
Then we will construct a coherent calculus with a (2,1)-ary quantiﬁer, for which
there is no suitable 2Nmatrix. This immediately implies that G has no strongly
characteristic 2Nmatrix.
Proposition 18. If a canonical calculus G is strongly sound for a 2Nmatrix
M, then M is suitable for G.
Proof: Let G be a canonical calculus which is strongly sound for M and suppose
for contradiction that M is not suitable for G. Then there is some (n, k)-ary
canonical rule R = Θ/Q(s) of G, such that there is some Ln
k-structure N in
which Θ is valid, but ˜QM[DistN ] ̸= {s}. Suppose that s = t. Then R = Θ/ ⇒
Q−→v (p1(−→v ), ..., pn(−→v )) and (∗) f ∈˜QM[DistN ]. Let S be any extension of N to
L (recall that we assume for simplicity that Ln
k is a subset of L). It is easy to see
that Θ is also M-valid in ⟨S, v⟩for every S-valuation v (note that Θ only contains
atomic formulas). Obviously, ⇒Q−→v (p1(−→v ), ..., pn(−→v )) is derivable from Θ in
G. Now since G is strongly sound for M, (∗∗) Q−→v (p1(−→v ), ..., pn(−→v )) should also
be M-valid in ⟨S, v⟩for every S-valuation v. Let v0 be any M-legal S-valuation,
such that v0[Q−→v (p1(−→v ), ..., pn(−→v ))] = f (the existence of such a valuation fol-
lows from (∗) and the fact that {⟨v0[p1{−→a /−→v }], ..., v[pn{−→a /−→v }]⟩| a1, ..., ak ∈
D} = DistN ). Obviously ⇒Q−→v (p1(−→v ), ..., pn(−→v )) is not M-valid in ⟨S, v0⟩, in
contradiction to (∗∗).
⊓⊔
Next, consider the calculus G, which consists of the following two dual intro-
duction rules Θ1/ ⇒Qv1v2p(v1, v2) and Θ2/Qv1v2p(v1, v2) ⇒, where Θ1 =
{p(c, v1) ⇒} and Θ2 = {⇒p(v1, c)}. The set of clauses Rnm(Θ1 ∪Θ2) =
{p(c, v1) ⇒, ⇒p(v2, d)} is classically inconsistent, and so G is coherent. Sup-
pose by contradiction that there is a 2Nmatrix M suitable for G. Consider the
Ln
k-structures N1 = ⟨D1, I1⟩and N2 = ⟨D2, I2⟩, deﬁned as follows. D1 = D2 =
{a1, a2}, I1[p][a1, a1] = I1[a1, a2] = f, I1[p][a2, a1] = I1[p][a2, a2] = t, I1[c] = a1.
I2[p][a1, a1] = I2[a1, a2] = t, I2[p][a2, a1] = I2[p][a2, a2] = f, I2[c] = a1. Obvi-
ously, Θ1 is valid in N1, and so by suitability of M, ˜QM[DistN1] = t. Θ2 is
valid in N2, and so ˜QM[DistN2] = f. But this is impossible, since DistN1 =
DistN2 = {t, f}. Thus G has no suitable 2Nmatrix, although it is coherent. By
Prop. 18 above, G has no strongly characteristic 2Nmatrix.

Generalized Non-deterministic Matrices and (n,k)-ary Quantiﬁers
33
We conclude that the interpretation of (n, k)-ary quantiﬁers using distribu-
tions is not suﬃcient for the case of k > 1. Using them, we cannot capture any
kind of dependencies between elements of the domain. For instance, there is no
way we can express the fact that there exists an element b in the domain, such
that for every element a, p(a, b) holds. It is clear that a more general interpre-
tation of a quantiﬁer is needed.
We will generalize the interpretation of quantiﬁers as follows. Given an L-
structure S = ⟨D, I⟩, an interpretation of an (n, k)-ary quantiﬁer Q in S is
an operation ˜QS : (Dk →Vn) →P +(V), which for every function (from k-
ary vectors of the domain elements to n-ary vectors of truth-values) returns a
non-empty set of truth-values.
Deﬁnition 19. A generalized non-deterministic matrix (henceforth GNmatrix)
for L is a tuple M =< V, D, O >, where:
– V is a non-empty set of truth values.
– D is a non-empty proper subset of V.
– For every (n, k)-ary quantiﬁer Q of L, O9 includes a corresponding operation
˜QS : (Dk →Vn) →P +(V) for every L-structure S = ⟨D, I⟩. A 2GNmatrix
is any GNmatrix with V = {t, f} and D = {t}.
Examples:
1. Given an L-structure S = ⟨D, I⟩, the standard (1, 1)-ary quantiﬁer ∀is
interpreted as follows for any g ∈D →{t, f}: ˜∀S[g] = {t} if for every a ∈D,
g[a] = t, and ˜∀S[g] = {f} otherwise. The standard (1, 1)-ary quantiﬁer ∃is
interpreted as follows for any g ∈D →{t, f}: ˜∃S[g] = {t} if there exists
some a ∈D, such that g[a] = t, and ˜∃S[g] = {f} otherwise.
2. Given an L-structure S = ⟨D, I⟩, the (1, 2)-ary bounded universal10 quan-
tiﬁer ∀is interpreted as follows: for any g ∈D →{t, f}2, ˜∀S[g] = {t} if for
every a ∈D, g[a] ̸= ⟨t, t⟩, and ˜∀S[g] = {f} otherwise. The (1, 2)-ary bounded
existential11 quantiﬁer ∃is interpreted as follows: for any g ∈D →{t, f}2,
˜∀S[g] = {t} if there exists some a ∈D, such that g[a] = ⟨t, t⟩, and ˜∀S[g] =
{f} otherwise.
3. Consider the (2, 2)-aryquantiﬁer Q, with the intended meaning of Qxy(ψ1, ψ2)
as ∃y∀x(ψ1(x, y) ∧¬ψ2(x, y)). Its interpretation for every L-structure S =
⟨D, I⟩, every g ∈D2 →{t, f}2 is as follows: ˜QS[g] = t iﬀthere exists some
a ∈D, such that for every b ∈D: g[a, b] = ⟨t, f⟩.
4. Consider the (4, 1)-ary Henkin quantiﬁer12 QH discussed in section 1. Its
interpretation for for every L-structure S = ⟨D, I⟩and every g ∈D4 →{t, f}
9 In the current deﬁnition, O is a class and the tuple ⟨V, D, O⟩is not well-deﬁned.
We can overcome this technical problem by assuming that the domains of all the
structures are preﬁxes of the set of natural numbers. A more general solution to this
problem is a question for further research.
10 The intended meaning of ∀x(p1(x), p2(x)) is ∀x(p1(x) →p2(x)).
11 The intended meaning of ∃x(p1(x), p2(x)) is ∃x(p1(x) ∧p2(x)).
12 We note that the current framework of canonical systems is not adequate to handle
such quantiﬁers.

34
A. Avron and A. Zamansky
is as follows: ˜QH
S [g] = {t} if for every a ∈D there exists some b ∈D and for
every c ∈D there exists some d ∈D, such that g[a, b, c, d] = t. ˜QH
S [g] = {f}
otherwise.
Deﬁnition 20 (Legal valuation). Let S = ⟨D, I⟩be an L-structure for a GN-
matrix M. An S-valuation v : Frmcl
L(D) →V is legal in M if it satisﬁes the fol-
lowing conditions: v[ψ] = v[ψ′] for every two sentences ψ, ψ′ of L(D), such that
ψ ∼S ψ′, v[p(t1, ..., tn)] = I[p][I[t1], ..., I[tn]], and v[Qx1, ..., xk(ψ1, ..., ψn) is in
the set ˜QS[λa1, ..., ak ∈D.⟨v[ψ1{a1/x1, ..., ak/xk}], ..., v[ψn{a1/x1, ..., ak/xk}]⟩]
for every (n, k)-ary quantiﬁer Q of L.
The semantic notions from Defn. 14 and 15 are deﬁned similarly for the case of
GNmatrices.
Next we generalize the notion of a distribution of Ln
k-structures (see Defn. 16).
Deﬁnition 21. Let N = ⟨D, I⟩be a structure for Ln
k. The functional distri-
bution of N is a function FDistN ∈Dk →{t, f}n, such that: FDistN =
λa1, ..., ak ∈D.⟨I[p1][a1, ..., ak], ..., I[pn][a1, ..., ak]⟩.
4
Semantics for Canonical Calculi
In this section we show that a canonical calculus G with (n, k)-ary quantiﬁers is
coherent iﬀit has a strongly characteristic 2GNmatrix.
First we construct a strongly characteristic 2GNmatrix for every coherent canon-
ical calculus.
Deﬁnition 22. Let G be a coherent canonical calculus. For every L-structure
S = ⟨D, I⟩, the GNmatrix MG contains the operation ˜QS deﬁned as follows. For
every (n, k)-ary quantiﬁer Q of L, every r ∈{t, f} and every g ∈Dk →{t, f}n:
˜QS[g] =
⎧
⎪
⎨
⎪
⎩
{r}
Θ/Q(r) ∈G and there is an Ln
k −structure N = ⟨DN , IN ⟩
such that DN = D, FDistN = g and Θ is valid in N.
{t, f}
otherwise
It should be noted that as opposed to the deﬁnition of the Nmatrix MG in [16]
(see Defn. 4.2 there), the above deﬁnition is not constructive. This is because
the question whether Θ is valid in some Ln
k-structure with a given functional
distribution is not generally decidable. Next, let us show that MG is well-deﬁned.
Assume by contradiction that there are two dual rules Θ1/ ⇒A and Θ2/A ⇒,
such that there exist two Ln
k-structures N1 = ⟨D, I1⟩and N2 = ⟨D, I2⟩, which
satisfy: FDistN1 = FDistN2 and Θi is valid in Ni for i ∈{1, 2}. But then N1 and
N2 only diﬀer in their interpretations of constants from Θ1 and Θ2. Then we can
easily construct an Ln
k-structure N3 = ⟨D, I3⟩, such that Rnm(Θ1 ∪Θ2) is valid
in N3 (the renaming is essential since it may be the case that the same constant
occurs both in Θ1 and Θ2). And so Rnm(Θ1 ∪Θ2) is classically consistent, in
contradiction to the coherence of G.

Generalized Non-deterministic Matrices and (n,k)-ary Quantiﬁers
35
Theorem 23. Any coherent canonical calculus G is strongly sound for MG.
Proof: Let S = ⟨D, I⟩be some L-structure and v - an M-legal S-valuation.
Let S be any set of sequents closed under substitution. We will show that if the
sequents of S are M-valid in ⟨S, v⟩, then any sequent provable from S in G is M-
valid in ⟨S, v⟩. Obviously, the axioms of G are M-valid, and the structural rules,
including cut, are strongly sound. It remains to show that for every application
of a canonical rule R of G: if the premises of R are M-valid in ⟨S, v⟩, then
its conclusion is M-valid in ⟨S, v⟩. Let R be an (n, k)-ary rule of G of the
form: R = ΘR/ ⇒Q−→v (p1(−→v ), ..., pn(−→v )), where ΘR = {Σj ⇒Πj}1≤j≤m. An
application of R is of the form:
{Γ, χ[Σj] ⇒χ[Πj], Δ}1≤j≤m
Γ ⇒Δ, Q−→z (χ[p1], ..., χ[pn])
where χ is some ⟨R, Γ ∪Δ, −→z ⟩-mapping. Let {Γ, χ[Σj] ⇒χ[Πj], Δ}1≤j≤m be
M-valid in ⟨S, v⟩. Let σ be an S-substitution, such that S, v |=M σ[Γ] and for
every ψ ∈Δ: S, v̸|=Mσ[ψ]. Denote by ψ the L-formula obtained from a for-
mula ψ by substituting every free occurrence of w ∈Fv[ψ] −{z} for σ[w].
Construct the Ln
k-structure N = ⟨DN , IN ⟩as follows: DN = D, for every
a1, ..., ak ∈D: IN [pi][a1, ..., ak] = v[ 
χ[pi]{−→a /−→z }], and for every constant c oc-
curring in ΘR, IN [c] = I[σ[χ[c]]]. It is not diﬃcult to show that ΘR is valid
in N. Thus by deﬁnition of MG, ˜QS[FDistN ] = {t}. Finally, by deﬁnition of
N, FDistN = λa1, ..., ak ∈D.{⟨v[ 
χ[p1]{−→a /−→z }], ..., v[ 
χ[pn]{−→a /−→z }]⟩}. Since v is
M-legal, v[σ[Q−→z (χ[p1], ..., χ[pn])]] = v[Q−→z ( 
χ[p1], ..., 
χ[pn])] ∈FDistN = {t}.
And so Γ ⇒Δ, Q−→z (χ[p1], ..., χ[pn]) is M-valid in ⟨S, v⟩.
⊓⊔
Example 1. The canonical calculus G1 consists of (1,1)-ary rule ⇒p(v1)/ ⇒
∀v1p(v1). Clearly, G1 is coherent. For every L-structure S = ⟨D, I⟩, MG1 con-
tains the operation ˜∀S deﬁned as follows for every g ∈D →V:
˜∀S[g] =

{t}
if for all a ∈D : g[a] = t
{t, f}
otherwise
Example 2. The canonical calculus G2 consists of the following rules: (i) {p1(v1)
⇒p2(v1)}/ ⇒∀v1 (p1(v1), p2(v1)), (ii) {p2(c) ⇒, ⇒p1(c)}/∀v1(p1(v1), p2(v1))
⇒and (iii) {⇒p1(c) , ⇒p2(c)}/ ⇒∃v1(p1(v1), p2(v1)). G′ is obviously co-
herent. The operations ˜∀S and ˜∃S in MG2 are deﬁned as follows for every
g ∈D →{t, f}2:
˜∀S[g] =

{t}
if there are no such a, b ∈D, that g[a, b] = ⟨t, f ⟩
{f}
otherwise
˜∃S[g] =

{t}
if there are a, b ∈D, s.t. g[a, b] = ⟨t, t⟩
{t, f}
otherwise

36
A. Avron and A. Zamansky
The rule (i) dictates the condition that ∀S[g] = {t} for the case that there
are no a, b ∈D, s.t. g[a, b] = ⟨t, f⟩. The rule (ii) dictates the condition that
∀S[g] = {f} for the case that there are such a, b ∈D. Since G2 is coherent, the
dictated conditions are non-contradictory. The rule (iii) dictates the condition
that ∃S[g] = {t} in the case that there are a, b ∈D, s.t. g[a, b] = ⟨t, t⟩. There is no
rule which dictates conditions for the case of ⟨t, t⟩̸∈H, and so the interpretation
in this case is non-deterministic.
Example 3. Consider the canonical calculus G3 consisting of the following (2, 2)-
ary rule: {p1(v1, v2) ⇒; ⇒p2(c, v1)}/ ⇒Qv1v2(p1(v1, v2), p2(v1, v2)). G3 is
(trivially) coherent. For a tuple v = ⟨a1, ..., an⟩, denote by (v)i the i-th element
of v. For every L-structure S = ⟨D, I⟩, MG3 contains the operation ˜QS deﬁned
as follows for every g ∈D2 →{t, f}2:
˜QS[g] =
⎧
⎪
⎨
⎪
⎩
{t}
if there is some a ∈D, s.t. for every b, c ∈D
(g[b, c])1 = f and (g[a, b])2 = t
{t, f}
otherwise
Next we show that for every canonical calculus G: (i) MG is a characteristic
2Nmatrix for G, and (ii) G admits cut-elimination. For this we ﬁrst prove the
following proposition.
Proposition 24. Let G be a coherent calculus. Let Γ ⇒Δ be a sequent which
satisﬁes the free-variable condition13. If Γ ⇒Δ has no cut-free proof in G, then
Γ̸⊢MGΔ.
Proof: Let Γ ⇒Δ be a sequent which satisﬁes the free-variable condition.
Suppose that Γ ⇒Δ has no cut-free proof from in G. To show that Γ ⇒Δ is
not MG-valid, we will construct an L-structure S, an S-substitution σ∗and an
MG-legal valuation v, such that v[σ∗[ψ]] = t for every ψ ∈Γ, while v[σ∗[ϕ]] = f
for every ϕ ∈Δ.
It is easy to see that we can limit ourselves to the language L∗, which is a
subset of L, consisting of all the constants and predicate and function symbols,
occurring in Γ ⇒Δ.
Let T be the set of all the terms in L∗which do not contain variables occurring
bound in Γ ⇒Δ. It is a standard matter to show that Γ, Δ can be extended
to two (possibly inﬁnite) sets Γ ′, Δ′ (where Γ ⊆Γ ′ and Δ ⊆Δ′), satisfying the
following properties:
1. For every ﬁnite Γ1 ⊆Γ ′ and Δ1 ⊆Δ′, Γ1 ⇒Δ1 has no cut-free proof in G.
2. There are no ψ ∈Γ ′ and ϕ ∈Δ′, such that ψ ≡α ϕ. n
3. If {Πj ⇒Σj}1≤j≤m/Q(r) is an (n, k)-ary rule of G and Qz1...zk (A1, ..., An) ∈
ite(r, Δ′, Γ ′), then there is some 1 ≤j ≤m satisfying the following condition.
Let t1, ..., tm be the Ln
k-terms occurring in Πj ∪Σj, where tj1, ..., tjl are con-
stants and tjl+1, ..., tjm are variables. Then for every s1, ..., sl ∈T there are
13 A sequent S satisﬁes the free-variable condition if the set of variables occurring free
in S and the set of variables occurring bound in S are disjoint.

Generalized Non-deterministic Matrices and (n,k)-ary Quantiﬁers
37
some14 sl+1, ..., sm ∈T, such that whenever pi(tn1, ..., tnk) ∈ite(r, Πj, Σj)
for some 1 ≤n1, ..., nk ≤m: Ai{sn1/z1, ..., snk/zk} ∈ite(r, Γ ′, Δ′).
Let S = ⟨D, I⟩be the L∗-structure deﬁned as follows: D = T, I[c] = c for every
constant c of L∗; I[f][t1, ..., tn] = f(t1, ..., tn) for every n-ary function symbol
f; I[p][t1, ..., tn] = t iﬀp(t1, ..., tn) ∈Γ ′ for every n-ary predicate symbol p. It
is easy to show by induction on t that: (∗) For every t ∈T: I[σ∗[t]] = t.
Let σ∗be any S-substitution satisfying σ∗[x] = x for every x ∈T. (Note that
every x ∈T is also a member of the domain and thus has an individual constant
referring to it in L∗(D)).
For an L(D)-formula ψ (an L(D)-term t), we will denote by 	ψ (	t) the L-
formula (L-term) obtained from ψ (t) by replacing every individual constant of
the form s for some s ∈T by the term s. Then the following property can be
proved by an induction on ψ: (∗∗) For every ψ ∈Γ ′ ∪Δ′: 
σ∗[ψ] = ψ.
Deﬁne the S-valuation v as follows: (i) v[p(t1, ..., tn)] = I[p][I[t1], ..., I[tn]], (ii)
If there is some C ∈Γ ′∪Δ′, s.t. C ≡α

Q−→z (ψ1, ..., ψn), then v[Q−→z (ψ1, ..., ψn)] = t
iﬀC ∈Γ ′. Otherwise v[Q−→z (ψ1,...,ψn)]=t iﬀ˜QS[λa1...ak ∈D.{⟨v[ψ1{−→a /−→z }], ...,
v[ψn{−→a /−→z }]⟩}] = {t}.
It is not diﬃcult to show that v is legal in MG.
Next we show that for every ψ ∈Γ ′ ∪Δ′: v[σ∗[ψ]] = t iﬀψ ∈Γ ′. If ψ =
p(t1, ..., tn), then v[σ∗[ψ]] = I[p][I[σ∗[t1]], ..., I[σ∗[tn]]]. Note15 that for every
1 ≤i ≤n, ti ∈T. By (∗), I[σ∗[ti]] = ti, and by the deﬁnition of I, v[σ∗[ψ]] = t
iﬀp(t1, ..., tn) ∈Γ ′. Otherwise ψ = Q−→z (ψ1, ..., ψn). If ψ ∈Γ ′, then by (∗∗):

σ∗[ψ] = ψ ∈Γ ′ and so v[σ∗[ψ]] = t. If ψ ∈Δ′ then by property 2 of Γ ′ ∪Δ′ it
cannot be the case that there is some C ∈Γ ′, such that C ≡α 
σ∗[ψ] = ψ and so
v[σ∗[ψ]] = f.
We have constructed an L-structure S, an S-substitution σ∗and an MG-legal
valuation v, such that v[σ∗[ψ]] = t for every ψ ∈Γ ′, while v[σ∗[ϕ]] = f for every
ϕ ∈Δ′. Since Γ ⊆Γ ′ and Δ ⊆Δ′, Γ ⇒Δ is not MG-valid.
⊓⊔
Theorem 25. Let G be a canonical calculus. Then the following statements
concerning G are equivalent:
1. G is coherent.
2. There exists a 2GNmatrix M, such that G is strongly sound and complete
for M.
Proof: (1) ⇒(2):
Suppose that G is coherent. By theorem 23, G is strongly sound for MG. For
completeness, let Γ ⇒Δ be a sequent which has no proof in G. If it does not
satisfy the free-variable condition, obtain a sequent Γ ′ ⇒Δ′ which does satisfy
this condition by renaming the bound variables. (Otherwise, set Γ ′ = Γ and
14 Note that in contrast to t1, ..., tm, s1, ..., sm are L-terms and not Ln
k-terms.
15 This is obvious if ti does not occur in Γ ⇒Δ. If it occurs in Γ ⇒Δ, then since
Γ ⇒Δ satisﬁes the free-variable condition, ti does not contain variables bound in
this set and so ti ∈T by deﬁnition of T.

38
A. Avron and A. Zamansky
Δ′ = Δ). Then also Γ ′ ⇒Δ′ has no proof in G (otherwise we could obtain a
proof of Γ ⇒Δ from a proof of Γ ′ ⇒Δ′ by using cuts on logical axioms). By
proposition 24, Γ ′̸⊢MGΔ′. That is, there is an L-structure S, an S-substitution
σ and an MG-legal valuation v, such that v[σ[ψ]] = t for every ψ ∈Γ ′, while
v[σ[ϕ]] = f for every ϕ ∈Δ′. By lemma 12-1, v respects the ≡α-relation, and so
v[σ[ψ]] = t for every ψ ∈Γ, while v[σ[ϕ]] = f for every ϕ ∈Δ. Hence, Γ̸⊢MGΔ,
and G is complete (and strongly sound) for MG.
(2) ⇒(1):
Suppose that G is strongly sound and complete for some 2GNmatrix M. Assume
by contradiction that G is not coherent. Then there exist two dual (n, k)-ary rules
R1 = Θ1/ ⇒A and R2 = Θ2/A ⇒in G, such that Rnm(Θ1 ∪Θ2) is classically
consistent. Recall that Rnm(Θ1 ∪Θ2) = Θ1 ∪Θ′
2, where Θ′
2 is obtained from
Θ2 by renaming constants and variables that occur also in Θ1 (see defn. 7). For
simplicity16 we assume that the fresh constants used for renaming are all in L.
Since Θ1 ∪Θ′
2 is classically consistent, there exists an Ln
k-structure N = ⟨D, I⟩,
in which both Θ1 and Θ′
2 are valid. Recall that we also assume that Ln
k is a subset
of L17 and so
Θ1
⇒A
and
Θ′
2
A ⇒
are applications of R1 and R2 respectively. Let
S be any extension of N to L and v - any M-legal S-valuation. It is easy to see
that Θ1 and Θ′
2 are M-valid in ⟨S, v⟩(since they only contain atomic formulas).
Since G is strongly sound for M, both ⇒A and A ⇒should also be M-valid
in ⟨S, v⟩, which is of course impossible.
⊓⊔
Corollary 26. The existence of a strongly characteristic 2GNmatrix for a
canonical calculus G is decidable.
Proof: By Theorem 25, the question whether G has a strongly characteris-
tic 2Nmatrix is equivalent to the question whether G is coherent, and this, by
Proposition 9, is decidable.
Corollary 27. If G is a coherent canonical calculus then it admits cut-
elimination.
As was shown in [16], the opposite does not hold: a canonical calculus which is
not coherent can still admit cut-elimination.
Remark: The above results are related to the results in [9], where a general class
of sequent calculi with (n, k)-ary quantiﬁers, called standard calculi is deﬁned.
Standard calculi may include any set of structural rules, and so canonical calculi
are a particular instance of standard calculi which include all of the standard
structural rules. [9] formulate syntactic suﬃcient and (under some limitations)
necessary conditions for modular cut-elimination, a particular version of cut-
elimination with non-logical axioms consisting only of atomic formulas. The
16 This assumption is not necessary and is used only for simpliﬁcation of presentation,
since we can instantiate the constants by any L-terms.
17 This assumption is again not essential for the proof, but it simpliﬁes the presentation.

Generalized Non-deterministic Matrices and (n,k)-ary Quantiﬁers
39
reductivity condition of [9] can be shown to be equivalent to our coherence
criterion in the context of canonical systems. Thus from the results of [9] it
follows that coherence is a necessary condition for modular cut-elimination in
canonical calculi.
5
Summary and Further Research
In this paper we have extended the results of [16] for canonical systems with
(n, k)-ary quantiﬁers from the case of k ∈{0, 1} to the general case of k ≥0
(while preserving the decidability of coherence). We have demonstrated that
the framework of Nmatrices is not suﬃcient to provide semantics for canonical
systems for the case of k > 1, and generalized the framework of Nmatrices by
introducing more general interpretations of quantiﬁers. Then we have shown that
a canonical calculus G is coherent iﬀthere is a 2GNmatrix M for which G is
strongly sound and complete. Furthermore, any coherent calculus admits cut-
elimination. However, the opposite direction does not hold: we have seen that
coherence is not a necessary condition for (standard) cut-elimination in canonical
calculi. From the results of [9] it follows that coherence is a necessary condition
for modular cut-elimination. Whether it is possible to extend these results to
more general forms of cut-elimination, is a question for further research.
Other research directions include extending the results of this paper to more
general systems, such as the standard calculi of [9], which use non-standard
sets of structural rules, and treating more complex quantiﬁer extensions, such
as Henkin quantiﬁers. Although the syntactic formulation of canonical systems
given in this paper is not expressible enough to deal with Henkin quantiﬁers,
the proposed semantic framework of GNmatrices provides an adequate inter-
pretation of such quantiﬁers. This might be a promising starting point for a
proof-theoretical investigation of canonical systems with Henkin quantiﬁers.
Yet another research direction is gaining an insight into the connection be-
tween non-determinism and axiom expansion in canonical systems. In [5] it is
shown (on the propositional level) that any many-sided calculus which satisﬁes:
(i) a condition similar to coherence and (ii) axiom expansion18 (i.e axioms can
be reduced to atomic axioms), has a deterministic characteristic matrix. We
conjecture that there is a direct connection between axiom expansion in a co-
herent canonical system, and the degree of non-determinism in its characteristic
2Nmatrix.
Acknowledgement
This research was supported by the Israel Science Foundation founded by the
Israel Academy of Sciences and Humanities (grant No 809/06).
18 This is also closely connected to the criterion of rigidity of [8] for propositional simple
calculi.

40
A. Avron and A. Zamansky
References
1. Avron, A., ‘Gentzen-Type Systems, Resolution and Tableaux’, Journal of Auto-
mated Reasoning, vol. 10, 265–281, 1993.
2. Avron, A. and I. Lev, ‘Canonical Propositional Gentzen-type Systems’, Proceed-
ings of the 1st International Joint Conference on Automated Reasoning (IJCAR
2001), R. Gore, A. Leitsch, T. Nipkow, eds., Springer Verlag, LNAI 2083, 529-544,
Springer Verlag, 2001.
3. Avron, A. and I. Lev, ‘Non-deterministic Multi-valued Structures’, Journal of Logic
and Computation, vol. 15, 241–261, 2005.
4. Avron, A. and A. Zamansky, ‘Quantiﬁcation in Non-deterministic Multi-valued
Structures’, Proceedings of the 35th IEEE International Symposium on Multiple-
Valued Logics, 296–301, IEEE Computer Society Press, 2005.
5. Baaz M., C.G. Ferm¨uller, G. Salzer and R.Zach, ‘Labeled Calculi and Finite-valued
Logics’, Studia Logica, vol. 61, 7–33, 1998.
6. Carnielli W.A., ‘Systematization of Finite Many-valued Logics through the method
of Tableaux’, Journal of Symbolic Logic, vol. 52 (2), 473–493, 1987.
7. Carnielli W.A. and M.E. Conglio,‘Splitting Logics’, in We Will Show Them!, Es-
says in Honour of Dov Gabbay, Artemov, Barringer, Garcez and Lamb eds., Woods
College Publications, vol. 1, 389–414, 2005.
8. Ciabattoni A. and Terui K., ‘Towards a semantic characterization of cut elimina-
tion’, Studia Logica, vol. 82(1), 95–119, 2006.
9. Ciabattoni A. and Terui K., ‘Modular cut-elimination: ﬁnding proofs or counter-
examples’, Proceedings of the 13-th International Conference of Logic for Program-
ming AI and Reasoning (LPAR06), LNAI 4246, 135–149, 2006.
10. Church A., ‘A formulation of the simple theory of types’, Journal of Symbolic Logic,
vol. 5, 56–68, 1940.
11. Gentzen, G., ‘Investigations into Logical Deduction’, in The collected works of
Gerhard Gentzen (M.E. Szabo, ed.), 68–131, North Holland, Amsterdam , 1969.
12. H¨ahnle, R., ‘Commodious Axiomatization of Quantiﬁers in Many-valued Logic’,
Studia Logica, vol. 61, 101–121, 1998.
13. Krynicki, M. and M.Mostowski, ‘Henkin Quantiﬁers’, Quantiﬁers: logics, models
and computation, M. Krynicki, M. Mostowski and L. Szcerba eds., vol. 1, 193–263,
Kluwer Academic Publishers, 1995.
14. Miller, D. and E. Pimentel, ‘Using Linear logic to reason about sequent systems’,
Tableaux’02, LNAI, 2–23, 2002.
15. Avron, A. and A. Zamansky, ‘Quantiﬁcation in Non-deterministic Multi-valued
Structures’, Proceedings of the 35th IEEE International Symposium on Multiple-
Valued Logics, 296–301, 2005.
16. Zamansky, A. and A. Avron, ‘Canonical Gentzen-type calculi with (n,k)-ary quan-
tiﬁers ’, Proceedings of the Third International Joint Conference in Automated
Reasoning (IJCAR06), 251 – 265, Furbach and Shankar eds, LNAI 4130, Springer,
2006.
17. Zamansky, A. and A. Avron, ‘Cut Elimination and Quantiﬁcation in Canonical
Systems’, Studia Logica (special issue on Cut Elimination), vol. 82(1), 157–176,
2006.

Elementary Diﬀerential Calculus on Discrete
and Hybrid Structures
Howard A. Blair1, David W. Jakel1, Robert J. Irwin1, and Angel Rivera2
1 Syracuse University, Syracuse NY 13244-4100 USA
{blair,dwjakel,rjirwin}@ecs.syr.edu
http://www.cis.syr.edu/~blair
2 Utica College, Utica, NY 13502 USA
arivera@utica.edu
Abstract. We set up diﬀerential calculi in the Cartesian-closed category
CONV of convergence spaces. The central idea is to uniformly deﬁne the
3-place relation
is a diﬀerential of
at
for each pair of
convergence spaces X, Y in the category, where the ﬁrst and second argu-
ments are elements of Hom(X, Y ) and the third argument is an element
of X, in such a way as to (1) obtain the chain rule, (2) have the relation
be in agreement with standard deﬁnitions from real and complex anal-
ysis, and (3) depend only on the convergence structures native to the
spaces X and Y . All topological spaces and all reﬂexive directed graphs
(i.e. discrete structures) are included in CONV. Accordingly, ramiﬁed
hybridizations of discrete and continuous spaces occur in CONV. More-
over, the convergence structure within each space local to each point,
individually, can be discrete, continuous, or hybrid.
Keywords: Diﬀerential, convergence space, discrete structure, hybrid
structure.
1
Introduction
With topology, continuity of functions generalizes from the contexts of classical
analysis to a huge collection of structures, the topological spaces. The purpose
here is to do the same for diﬀerentiability and also to allow for diﬀerentiation of
such functions as, for example, functions between discrete structures (represented
as reﬂexive directed graphs) as well as functions between discrete structures
and topological spaces, particularly continua commonly occurring in elementary
analysis.
Just as continuity itself neither presupposes any separation strength nor any
notion of linearity, neither does diﬀerentiability. The familiar diﬀerential calculus
on Euclidean spaces is of course intrinsically dependent on the vector space
structure, but this is due to the choice of functions used to serve as diﬀerentials,
and the consequent determination of the conditions under which functions are
diﬀerentiable. What matters is the diﬀerentiability relation “diﬀerential g is a
diﬀerential of f at x”. Unless we demand of g that it satisfy some kind of
linearity property, linearity does not intrinsically enter into the relation.
S. Artemov and A. Nerode (Eds.): LFCS 2007, LNCS 4514, pp. 41–53, 2007.
c
⃝Springer-Verlag Berlin Heidelberg 2007

42
H.A. Blair et al.
A word about derivatives: The derivative of a function at a point is a diﬀer-
ential. For example, the derivative of λx . x2 at 1 is λx . 2x, the linear function
with slope 2. The derivative of a function f on a subset of the function’s domain
is another function that maps each point x of the subset to the derivative of f at
x. The point is that derivatives are diﬀerential-valued. In the case of E1, the real
numbers with the standard Euclidean topology, the space of linear functions,
i.e. the space of diﬀerentials, is taken with a topology making it homeomorphic
to E1. For situations where no such homeomorphism is available, we expect the
codomain of a derivative of f to be diﬀerent from the codomain of f. This is
evident already with 2-dimensional vector spaces over the reals.
We will set up diﬀerential calculi in the Cartesian-closed category CONV of
convergence spaces. The central idea is to uniformly deﬁne the 3-place relation
is a diﬀerential of
at
for each pair of convergence spaces X, Y in the category, where the ﬁrst and
second arguments are elements of Hom(X, Y ) and the third argument is an
element of X, in such a way as to (1) obtain the chain rule, (2) have the relation
be in agreement with standard deﬁnitions in real and complex analysis, and (3)
depend only on the convergence structure native to the spaces X and Y .
Plan of the papers: In section 2 we deﬁne convergence spaces and the notion of
continuity of functions at a point and discuss some of relevant properties of the
resulting category CONV. The representation of reﬂexive digraphs and topolog-
ical spaces as convergence structures is discussed in section 3. Section 4 presents
the algebraic ideas that constitute the extraction of linear structure from the
symmetries of a convergence space’s convergence structure. Section 5 gives the
deﬁnition of a diﬀerential calculus involving homogeneous spaces and the deﬁ-
nition of the 3-place diﬀerentiability relation. Section 5 includes the statement
and proof of the chain rule and identiﬁes the diﬀerential calculi associated with
CONV. Section 6 presents examples of diﬀerential calculi. Section 7 concludes
the paper by extending the ideas to diﬀerential calculi that include nonhomoge-
neous spaces.
It is important to note that the spaces and functions of interest are natu-
rally organized into categories and to note the nature of the containments and
embeddings that are involved. In particular, any method for constructing a dif-
ferential calculus for mappings between arbitrary convergence spaces gives such
a method for all reﬂexive digraphs and all topological spaces. The results of this
paper should thus be seen as constituing a tool-kit for setting up mathematical
structures that import techniques from continuous mathematics into discrete
contexts.
2
Convergence Spaces, CONV and Prior Work
There is a beautiful paper including a brief but powerful tutorial on convergence
spaces due to R. Heckmann [2003]. We present a few of the fundamental ideas
necessary for our work.

Elementary Diﬀerential Calculus on Discrete and Hybrid Structures
43
A ﬁlter on a set X is a collection of subsets of X closed under ﬁnite intersection
and reverse inclusion. F is a proper ﬁlter if the empty set is not a member of F.
Let Φ(X) denote the set of all ﬁlters on X. For a subset A of X, { B | A ⊆B ⊆
X } is a member of Φ(X). We denote this ﬁlter by [A]. In the special case where
A is a singleton {x} we denote [A] by [x] and call this the point ﬁlter at x.
Deﬁnition 1. [1964, 2003] A convergence structure on X is a relation ↓(read
as “converges to”) between members of Φ(X) and members of X such that for
each x ∈X: (1) [x] converges to x, and (2) the set of ﬁlters converging to x
is closed under reverse inclusion. A pair (X, ↓) consisting of a set X and a
convergence structure ↓on X is called a convergence space.
A function f : X −→Y where X and Y are sets, induces functions ˆf : 2X −→2Y
and ˆˆf : Φ(X) −→Φ(Y ). ˆf is deﬁned by ˆf(A) = {f(a) | a ∈A}, which we call
the f-image of A. For F ∈Φ(X) note that the collection of all supersets of f-
images of members of F forms a ﬁlter which we call ˆˆf(F). Hereafter we overload
notation and drop the ˆand ˆˆannotations.
When convenient, we will refer to a convergence space (X, ↓) by its carrier,
X.
Deﬁnition 2. [1964, 2003] Let f : X −→Y where X and Y are convergence
spaces, and let x0 ∈X. f is continuous at x0 iﬀfor each F ∈Φ(X), if F ↓x0
in X, then f(F) ↓f(x0) in Y . f is continuous iﬀf is continuous at every point
of X.
Continuity can be characterized in terms of ﬁlter members, which play a role
analogous to the role played by neighborhoods, as supersets of open sets, in
topological spaces.
Proposition 1. Let f : X −→Y where X and Y are convergence spaces,
and let x0 be a point of X. f is continuous at x0 iﬀfor every ﬁlter F con-
verging to x0 in X, there is a ﬁlter G converging to f(x0) in Y such that
(∀V ∈G)(∃U ∈F)[f(U) ⊆V ].
Deﬁnition 3. [1964] A homeomorphism between two convergence spaces is a
continuous bijection whose inverse is continuous.
The objects of the category of convergence spaces CONV are the convergence
spaces. For convergence spaces X and Y , HOM(X, Y ) is the set of continuous
functions from X to Y .
The category CONV includes all topological spaces but enjoys several sub-
stantial advantages over the category TOP of topological spaces. Importantly
for computation, CONV contains multiple representations of all reﬂexive di-
rected graphs (ﬁnite and inﬁnite). Among digraphs, continuity is the property
of being edge-preserving, i.e. a digraph homomorphism. But, powerfully, and
unlike TOP, CONV is a Cartesian-closed category. Several immediate conse-
quences of Cartesian-closure and the relationship between TOP and CONV are:
(1) convergence spaces preserve the notion of continuity on topological spaces;

44
H.A. Blair et al.
(2) convergence spaces allow ﬁne control over continuity, and in various circum-
stances allow for strengthening the conditions for continuity; (3) at one’s option,
there is a uniform way of regarding all spaces of continuous functions as conver-
gence spaces, but other topological structures, (for example, a structure derived
from a norm) are available, and (4) function composition and application are
continuous.
Over time, a number of researchers have sought to generalize diﬀerentiability
to spaces where the generalization is non-obvious. Some of the more serious and
sophisticated results in this direction have employed one or another restriction
of the notion of convergence space, often near to pre-topological spaces, or else
stayed within TOP [1946, 1968, 1966, 1966, 1945, 1966, 1974, 1983, 1963, 1940].
These explorations assumed the existence of additional structure characterizing
linearity. [1983] recognized the importance of Cartesian-closure for obtaining a
robust chain-rule.
3
Reﬂexive Digraphs and Topological Spaces as
Convergence Spaces
Deﬁnition 4. Let x be a point of a convergence space X, and let U be a subset
of X. U is said to be a neighborhood of x iﬀU belongs to every ﬁlter converging
to x.
Deﬁnition 5. [1947] A convergence space (X, ↓) is said to be a pretopological
space if and only if ↓is a pretopology, i.e. for each x ∈X, the collection of all
neighborhoods of x converges to x.
Proposition 2. Let f : X −→Y where X and Y are pretopological spaces, and
let x0 ∈X. f is continuous at x0 iﬀfor every neighborhood V of f(x0), there is
a neighborhood U of x0 such that f(U) ⊆V .
It is evident that every topological space is a pretopological space (cf. [1947, 1940,
1955]), and that the convergence space notion of continuity and the topological
space notion of continuity coincide for topological spaces. As indicated in the
introduction, the spaces and functions of interest to us are naturally organized
as categories. The main categories of interest in this paper are:
CONV
the category of convergence spaces and continuous functions
PreTOP
the category of pretopological spaces and continuous functions
TOP
the category of topological spaces and continuous functions
ReRe
the category of reﬂexive digraphs (i.e. directed graphs
with a loop at each vertex) and edge-preserving functions
PostD
the full subcategory of CONV whose objects are the
postdiscrete (see below) convergence spaces
TOP is a full subcategory of PreTOP, which, in turn, is a full subcategory
of CONV. Both of these full inclusions are reﬂective, via induced pretopology

Elementary Diﬀerential Calculus on Discrete and Hybrid Structures
45
and induced topology operations, respectively. ReRe is isomorphic to PostD,
which, in turn, embeds into PreTOP.1
The reﬂection functor PreT from CONV to PreTOP can be realized by
letting the carrier of PreT(X) be the carrier of X, and and letting a ﬁlter F
converge to a point x in PreT(X) iﬀthe collection of all neighborhoods of x in
X is a subcollection of F.
Similarly, the reﬂection functor T from PreTOP to TOP can be realized by
letting the carrier of T(X) be the carrier of X, and deﬁning the topology on
T(X) as {U ⊆X |U is a neighborhood in X of each point of U}.
ReRe can be embedded, in more than one way, as a full subcategory of
CONV.
Deﬁnition 6. A convergence space X will be said to be postdiscrete if and only
if every convergent proper ﬁlter is a point ﬁlter.
Proposition 3. The postdiscrete pretopological spaces are precisely the discrete
topological spaces.
Deﬁnition 7. Let (V, E) be a reﬂexive digraph. Induce a convergence structure
on V by letting a proper ﬁlter F converge to a vertex x iﬀF = [y] for some
vertex y with an edge in E from x to y.
It is readily veriﬁed that if (V1, E1) and (V2, E2) are reﬂexive digraphs, then a
function f : V1 −→V2 is continuous (with respect to the induced convergence
structures on V1 and V2) iﬀ, for all edges (x, y) in E1, the edge (f(x), f(y)) is
present in E2.
Proposition 4. The construction in Deﬁnition 7 embeds ReRe as a full sub-
category of CONV, namely the full subcategory whose objects are the post-
discrete spaces where this embedding is coreﬂective. The coreﬂection functor
ReR : CONV −→ReRe can be obtained letting the vertices of ReR(X) be
the members of X, and letting an ordered pair (x, y) be an edge of ReR(X) iﬀ
[y] ↓x in X.
Alternatively, ReRe can be embedded as a full subcategory of PreTOP, and
thence as a full subcategory of CONV [2001, 2003], by letting a ﬁlter F converge
to a vertex x iﬀ{ y | (x, y) ∈E } is a member of F.
In general, this embedding of ReRe into PreTOP imposes a weaker conver-
gence structure on reﬂexive digraphs than the embedding in Deﬁnition 7.
Proposition 5. The embedding of ReRe into PreTOP [2001, 2003] is the
composite of the embedding in Deﬁnition 7 of ReRe into CONV with the re-
ﬂection functor from CONV to PreTOP, and embeds ReRe as a full, core-
ﬂective subcategory of PreTOP, and thence as a full, coreﬂective subcategory of
CONV. The coreﬂection functor from PreTOP to ReRe (and the coreﬂection
functor from CONV to ReRe via PreTOP) can be obtained in precisely the
same way as in Proposition 4.
1 The embedding is the restriction of the induced pretopology reﬂection from CONV
to PostD.

46
H.A. Blair et al.
The reﬂexive digraphs whose induced pretopologies are topological are precisely
those in which the underlying binary relation is transitive as well as reﬂexive.
[2001, 2003] Unlike TOP and PreTOP, CONV is a Cartesian closed category
([1971, 1975, 1990, 2001, 1965]):
Deﬁnition 8. [1965]
Let X and Y be convergence spaces. The function space Y X is the set of all
continuous functions from X to Y , equipped with the convergence structure ↓
deﬁned as follows: For each H ∈Φ(Y X) and each f0 ∈Y X, let H ↓f0 if, and
only if, for each x0 ∈X and each F ↓x0, { { f(x) | f ∈H, x ∈F } | H ∈H, F ∈
F } is a base for a ﬁlter which converges to f(x0) in Y .
4
Translation Groups and Homogeneous Convergence
Spaces
Deﬁnition 9. An automorphism of a convergence space X is a homeomorphism
f : X −→X.
Deﬁnition 10. A translation group on a convergence space X is a group T of
automorphisms of X such that, for each pair of points p and q of X, there is at
most one member of T which maps p to q. In general, we will denote this unique
member of T (if it exists) by (q −p).
Notation: The group operation of a translation group T on a convergence space
X will be written additively, whether or not T is Abelian. Furthermore, for all
τ ∈T and all x ∈X, we will write τ(x) as x + τ.
In this notation, the requirement that the translation (q−p) (if it exists) maps
p to q becomes the familiar requirement that if (q−p) exists, then p+(q−p) = q.
A full translation group on a convergence space X is a translation group on
X which contains a translation (q −p) for each pair of points p and q.
Proposition 6
i. Every convergence space X can be embedded as a subspace of a convergence
space HX which has a full translation group.
ii. X and HX have the same cardinality if and only if the cardinality of X is
either zero or inﬁnite.
iii. The embedding of X into HX is onto HX if and only if X is empty.
iv. If X and Y are arbitrary convergence spaces then every continuous function
f : X −→Y can be be extended to a continuous function Hf : HX −→HY .
v. If f is a homeomorphism, then so is Hf.
An immediate consequence of (ii) in Proposition 6 is that, if X is a non-empty
ﬁnite space with (or without) a full translation group, then HX cannot be
homomeomorphic to X. It should also be noted that, given a particular f, the
continuous extention Hf need not be unique.

Elementary Diﬀerential Calculus on Discrete and Hybrid Structures
47
Deﬁnition 11. A convergence space X is homogeneous iﬀfor each pair of
points x1 and x2 of X, there is an automorphism of X which maps x1 to x2
Observation 1. A convergence space which has a full translation group must be
homogeneous. Furthermore, a full translation group on a nonempty convergence
space X must have the same cardinality as X.
5
Diﬀerential Calculi
Deﬁnition 12. A diﬀerential calculus is a category D in which
i. every object of D is a triple X = (X, 0, T ) such that X is a convergence
space, 0 is a point of X (called the origin of X), and T is a full translation
group on X.
ii. every arrow in D from an object (X, 0X, TX) to an object (Y, 0Y , TY ) is a
continuous function from X to Y which maps 0X to 0Y
iii. composition of arrows in D is function composition.
iv. for every object X = (X, 0X, TX), the identity function on X is an arrow in
D from X to X
v. for each pair of objects X = (X, 0X, TX) and Y = (Y, 0Y , TY ), the constant
function mapping every point of X to 0Y is an arrow in D from X to Y.
In view of Proposition 6, the requirement that each object have a full translation
group is not unduly restrictive. We are now in a position to deﬁne the diﬀeren-
tiability relation. Let a ∈A ⊆X and let B ⊆Y , where X = (X, 0X, TX) and
Y = (Y, 0Y , TY ) are objects of a diﬀerential calculus D. Let f : A −→B be an
arbitrary function.
Let L ∈D(X, Y), where D(X, Y) is the set of all arrows in D from X to Y,
equipped with the subspace convergence structure inherited from the function
space Y X in CONV.
Deﬁnition 13. L is a diﬀerential of f at a iﬀ
for every F ↓a in A, there is some H ↓L in D(X, Y) such that
i. H ⊆[L], and
ii. for every H ∈H, there is some F ∈F such that
for every point x ∈F, there is at least one function t ∈H such that
t(x −a) = f(x) −f(a))
In Deﬁnition 13, (f(a) −0Y ) ◦t ◦(0X −a) is called an extrapolant of f through
(a, f(a)) and (x, f(x)).
Deﬁnition 14. A function from A to B is diﬀerentiable (respectively, uniquely
diﬀerentiable) at a point a iﬀit has at least one (respectively, precisely one)
diﬀerential at a. A function from A to B is diﬀerentiable (respectively, uniquely
diﬀerentiable) iﬀit is diﬀerentiable (respectively, uniquely diﬀerentiable) at each
point of A.

48
H.A. Blair et al.
We next obtain the chain rule. As we indicated in the introduction, the chain
rule plays a central role in diﬀerential calculi. In elementary real and complex
analysis, for example, the product rule follows from the chain rule after obtaining
the diﬀerential of the multiplication operation.
Example 1. Expressed in terms of diﬀerentials, the product rule for real-valued
functions of a real variable reduces to matrix multiplication (i.e. composition of
linear functions).
Dx(mult ◦(f, g)) = D(f,g)(x)mult ◦Dx(f, g)
= D(f(x),g(x))mult ◦(Dxf, Dxg)
= [g(x)f(x)]
 Dxf
Dxg

= g(x)Dxf + f(x)Dxg
Returning to our more general setting, let a ∈A ⊆X, let B ⊆Y , and
let C ⊆Z, where X = (X, 0X, TX), Y = (Y, 0Y , TY ), and Z = (Z, 0Z, TZ) are
objects of a diﬀerential calculus D. Let f : A −→B and g : B −→C be arbitrary
functions. Let K : X −→Y and L : Y −→Z be arrows of D.
Theorem 2. (Chain Rule) Suppose that f is continuous at a. Also suppose
that K is a diﬀerential of f at a, and L is a diﬀerential of g at f(a). Then L◦K
is a diﬀerential of g ◦f at a.
Proof:
Let F be a ﬁlter converging to a in X. Since K is a diﬀerential of f
at a, there is some G ↓K in D(X, Y) such that G ⊆[K] and, for every G ∈G,
there is some F1,G ∈F such that for each point x ∈F1,G there is some function
sG,x ∈G such that
sG,x(x −a) = f(x) −f(a)
(1)
On the other hand, since f is continuous at a, we have f(F) ↓f(a) in B.
Since L is a diﬀerential of g at f(a), there is some ﬁlter H ↓L in D(Y, Z) such
that H ⊆[L] and, for every H ∈H, there is some NH ∈f(F) such that for each
point y ∈NH, there is some function tH,y ∈H such that
tH,y(y −f(a)) = g(f(x)) −g(f(a))
(2)
Consider such a set NH. By deﬁnition, NH ∈f(F), i.e. there is some F2,H ∈F
such that
f(F2,H) ⊆NH
By (2), for each point x ∈F2,H, we have
tH,f(x)(f(x) + (0Y −f(a))) = g(f(x)) + (0Z −g(f(a)))
(3)
Next, note that { { h2 ◦h1 | h1 ∈G, h2 ∈H } | G ∈G, H ∈H } is a basis for a
ﬁlter J on D(X, Z), and that J ⊆[L ◦K].
By joint continuity of composition, J ↓L ◦L in D(X, Z).

Elementary Diﬀerential Calculus on Discrete and Hybrid Structures
49
Let J be an arbitrary member of J . There exist G ∈G and H ∈H such that
{ h2 ◦h1 | h1 ∈G, h2 ∈H } ⊆J
Let F = F1,G ∩F2,H. Then F ∈F. For each point x ∈F, we have sG,x ∈G
and tH,f(x) ∈H, and therefore tH,f(x) ◦sG,x ∈J. Furthermore, by (1) and (3),
tH,f(x)(sG,x(x+(0X−a))) = tH,f(x)(f(x)+(0Y −f(a))) = g(f(x))+(0Z−g(f(a)))
(4)
Thus, (g(f(a))−0Z)◦tH,f(x) ◦sG,x ◦(0X −a) is the required extrapolant of g ◦f
through (a, g(f(a)) and (x, g(f(x)).
Since the selection of x is arbitrary (once G and H have been chosen), L ◦K
is indeed a diﬀerential of g ◦f at a.
6
Examples
Throughout, let R be the real line (equipped with its Euclidean topology), and
let N be the set of all natural numbers.
Example 2. The classical diﬀerential calculus of real variables: The ob-
jects of this diﬀerential calculus are the spaces Rn (n ∈N), equipped with their
respective Euclidean topologies, with their respective zero vectors as origins, and
with their usual translation groups. The arrows of this calculus are the R-linear
functions. In this calculus, diﬀerentiability and unique diﬀerentiability are equiv-
alent, and a function f has a diﬀerential at a point p iﬀf is diﬀerentiable (in
the usual sense) at p.
Example 3. The directional calculus of real variables: Again, the objects
are the sets Rn (n ∈N), with their respective zero vectors as origins, and with
their usual translation groups. Again, R is equipped with its Euclidean topology.
However, for n > 1, the convergence structure imposed on Rn is stronger than
the (Euclidean) product structure. In the directional calculus of real variables, a
ﬁlter F will be said to converge to a point p iﬀthere is some unit vector q such
that { p + αq | α ∈R, |α| < ϵ } ∈F for every real number ϵ > 0.
The arrows of this calculus are the R-homogeneous functions of degree one.
In this calculus, diﬀerentiabilty and unique diﬀerentiabilty are equivalent, but
a function f has a diﬀerential at a point p iﬀf has directional derivatives in all
directions at p.
Example 4. Boolean diﬀerential calculus (cf. Boolean derivatives [1954, 1959,
1990]): Let B be a complete digraph with two vertices, F and T , and equipped with
the induced postdiscrete convergence structure (cf. Deﬁnition 7).
Both of the point ﬁlters on B converge both to F and to T . (This convergence
structure diﬀers from the induced pretopological structure (namely, the indis-
crete structure) in that the ﬁlter {F, T } does not converge in B, but converges
to both points in the indiscrete structure.)

50
H.A. Blair et al.
In this calculus, the carriers of objects are the spaces Bn
( n ∈N). Each
carrier is equipped with the product convergence structure (which coincides with
the postdiscrete convergence structure induced by the complete digraph on the
carrier).
For each n, the bit vector (F, F, . . . , F) of length n is taken as the origin of
Bn.
The group generated by the ﬂips h1, h2, . . . , hn is taken as the translation
group of Bn, where (as one would expect) hk(b) is obtained from bit vector b
by changing the kth bit of b (and leaving every other bit unchanged).
For each m and n, the arrows from Bm to Bn are deﬁned to be all origin-
preserving functions from Bm to Bn. (This is compatible with our deﬁnition of
a diﬀerential calculus, since every function between complete digraphs preserves
edges.)
In particular, there are precisely two arrows between B and itself, namely, the
identity function, and the constant function which returns F.
In the Boolean diﬀerential calculus, every function between B and itself is
uniquely diﬀerentiable.
Example 5. Diﬀerentiating a function from 3R to K−
3 :
K−
3 is the complete
directed graph on 3 vertices, but with one edge from one vertex to another
removed. It is universal for the all pretopological convergence spaces in the sense
that every pretopological space embeds in some Cartesian power of it, (Bourdaud
[1976]). The space 3R is our designation for the set of real numbers equipped
with Euclidean ﬁlter structure at each real number r, and in addition at r, all
ﬁlters containing the ﬁlters generated by the open intervals whose right end point
is r, and all ﬁlters containing the ﬁlters generated by the open intervals whose
left end point is r. Take all functions from 3R to K−
3 that are piecewise constant
at 0 for diﬀerentials. Then g : 3R −→K−
3 is a diﬀerential of f : 3R −→K−
3 at
x0 iﬀf is constant on an open interval whose right end point is r and constant
on an open interval whose left end point is r.
7
Diﬀerential Calculi with Nonhomogeneous Objects
In the preceding development, convergence spaces without full translation groups
are “second class citizens” in the sense that they cannot be the carriers of objects
of a diﬀerential calculus. A somewhat more general (and slightly more compli-
cated) concept of “diﬀerential calculus” permits all convergence spaces to be
carriers of objects.
Observation 3. Let T be a translation group on a convergence space X. For
each point x of X, let [x]T be the T -orbit of x, i.e. [x]T = { x + τ | τ ∈T }.
If X is nonempty, then the set of all T orbits partitions X into homogeneous
subspaces. For each T -orbit [x]T , the restrictions of the members of T to [x]T
form a full translation group T[x] on [x]T .
Each T[x] is a quotient group of T .

Elementary Diﬀerential Calculus on Discrete and Hybrid Structures
51
Deﬁnition 15. A system of origins for a convergence space X with respect to
a translation group T is a set of representatives of the T -orbits, i.e., a subset O
of X containing precisely one member of each T -orbit.
For each point x of X, let 0x be the unique member of O belonging to the
same T -orbit as x.
Deﬁnition 16. Let f : X −→Y be a function between convergence spaces. Let
OX (OY , respectively) be a system of origins for X with respect to a translation
group S (for Y with respect to a translation group T , respectively).
i. f will be said to respect orbits iﬀ, for each pair of points p and q of X, if p
and q lie in the same S-orbit, then f(p) and f(q) lie in the same T -orbit.
ii. f will be said to be preserve origins iﬀf(OX) ⊆OY .
Deﬁnition 17. A generalized diﬀerential calculus is a category D in which
i. every object of D is a triple X = (X, T, O) such that X is a convergence
space, T is a translation group on X, and O is a system of origins for X
with respect to T .
ii. every arrow in D from an object (X, S, OX) to an object (Y, T, OY ) is a
continuous, orbit-respecting, origin-preserving function from X to Y .
iii. composition of arrows in D is function composition.
iv. for every object X = (X, T, O), the identity function on X is an arrow in D
from X to X
v. for each pair of objects X = (X, S, OX) and Y = (Y, T, OY ) and each ζ in
OY , the constant function mapping every point of X to ζ is an arrow in D
from X to Y
A diﬀerential calculus (in the sense of Deﬁnition 12) is essentially the same
notion as a generalized diﬀerential calculus in which the translation group of
every object is a full translation group.
At the opposite extreme, there are generalized diﬀerential calculii in which the
translation group of every object is trivial (and hence all orbits are singletons).
Example 6. CONV as a generalized diﬀerential calculus
The objects of the trivial generalized diﬀerential calculus are all convergence
spaces, equipped with trivial translation groups. The arrows from an object X
to an object Y are all continuous functions from X to Y . (Since all orbits are
singletons, every function is orbit-respecting and origin-preserving.)
Let a ∈X and let b ∈Y , where X = (X, S, OX) and Y = (Y, T, OY ) are
objects of a generalized diﬀerential calculus D. Let f : A −→B be an arbitrary
function.
Let L ∈D(X, Y), where, again, D(X, Y) is the set of all arrows in D from
X to Y, equipped with the subspace convergence structure inherited from the
function space Y X in CONV.

52
H.A. Blair et al.
Deﬁnition 18. L is a diﬀerential of f at a iﬀ
for every F ↓a in X, there is some H ↓L in D(X, Y) such that
i. H ⊆[{L}], and
ii. for every H ∈H, there is some F ∈F such that
for every point x ∈F, there is at least one function t ∈H such that
t(x + (0x −a)) = f(x) + (0f(x) −f(a))
Diﬀerentiability and unique diﬀerentiability are deﬁned exactly as before.
Example 7. The classical aﬃne diﬀerential calculus of real variables
The objects of this generalized diﬀerential calculus are the Euclidean spaces,
equipped with trivial translation groups. The arrows from Rm to Rn are all
aﬃne functions from Rm to Rn
As in the classical linear diﬀerential calculus, a function f has a diﬀerential
at a point p iﬀf is diﬀerentiable (in the usual sense) at p.
Let Epf be the diﬀerential of f at p in the classical aﬃne diﬀerential calculus
of real variables. That is, Ep(f) is the aﬃne function which best approximates
f in arbitrarily small neighhborhoods of p.
Then the diﬀerential of f at p in the classical linear diﬀerential calculus is the
unique linear function which can be obtained from Epf by composing it on both
sides with translations (in the usual sense), i.e. the function which maps each
point q to f(p) + (Epf)(q −p).
Next, we obtain the chain rule for generalized diﬀerential calculi. Let a ∈X,
where X = (X, R, OX), Y = (Y, S, OY ), and Z = (Z, T, OZ) are objects of a
generalized diﬀerential calculus D. Let f : X −→Y and g : Y −→Z be arbitrary
functions. Let K : X −→Y and L : Y −→Z be arrows of D.
Theorem 4. (Chain Rule)
Suppose that f is continuous at a. Also suppose that K is a diﬀerential of f at
a, and L is a diﬀerential of g at f(a).
Then L ◦K is a diﬀerential of g ◦f at a.
Proof: Similar to the proof of Theorem 2, but with the obvious modiﬁcations.
References
[1990] J. Ad´amek, H. Herrlich, and G. E. Strecker, Abstract and Concrete Categories,
Wiley Interscience, 1990.
[1959] S. B. Akers Jr., On a theory of Boolean functions, J. SIAM 7, no. 4 (1959), pp.
487-498.
[1946] R. F. Arens, A Topology for Spaces of Transformations. Annals of Mathematics
(2) 47 (1946), 480-495.
[1975] M. A. Arbib and E. Manes, Arrows, Structures, and Functors: The categorical
imperative, Academic Press, 1975.
[1968] W. I. Averbukh and O. G. Smolyanov, The various deﬁnitions of the derivative
in linear topological spaces, Russian Math. Surveys 23 (1968), no. 4, pp. 67-113.

Elementary Diﬀerential Calculus on Discrete and Hybrid Structures
53
[1966] E. Binz, Ein Diﬀerenzierbarkeitsbegriﬀlimitieren Vektorra¨aume, Comment.
Math. Helv. 41 (1966), pp. 137-156.
[1966] E. Binz and E. Keller, Functionenr¨aume in der Kategorie der Limesr¨aume, Ann.
Acad. Sci. Fenn., Ser. A.I., 1966, pp. 1-21.
[1940] N. Bourbaki, Topologie G´en´erale, Actualit´es Sci. Ind. 858 (1940), 916 (1942),
1029 (1947), 1045 (1948), 1084 (1949).
[1976] Bourdaud, G., Some cartesian closed categories of convergence spaces, in: Cate-
gorical Topology (Proc. Conf. Mannheim 1975), Lecture Notes in Mathematics
540 (1976), pp. 93108.
[1947] C. Choquet, Convergences, Ann. Univ. Grenoble 23 (1947), pp. 55-112.
[1945] R. H. Fox, On topologies for function spaces, Bull. Amer. Math. Soc. 51 (1945),
pp. 429-432.
[1966] A. Fr¨olicher and W. Bucher, Calculus in Vector Spaces without Norm, Lecture
Notes in Math. 30, Springer-Verlag, 1966.
[2003] R. Heckmann, A non-topological view of dcpo’s as convergence spaces, Theo-
retical Computer Science 305 (2003), pp. 159 - 186.
[1965] M. Kat˘etov, On continuity structures and spaces of mappings, Comm. Math.
Univ. Carol. 6, no. 2 (1965), pp. 257-279.
[1974] E. Keller, Diﬀerential Calculus in Locally Convex Spaces, Lecture Notes in
Math. 417, Springer-Verlag, 1974.
[1955] J. L. Kelley, General Topology, Van Nostrand Reinhold, 1955.
[1964] D. C. Kent, Convergence functions and their related topologies, Fund. Math.
54 (1964), pp. 125-133.
[1983] A. Kriegl, Eine kartesische abgeschlossene Kategorie glatter Abbildungen Zwis-
chen beleibigen lokalkonvexen Vektor¨aumen, Monatsh. Math. 95 (1983), pp.
287-309.
[1971] S. MacLane, Categories for the Working Mathematician, Graduate Texts in
Mathematics 5, Springer Verlag (1971).
[1963] G. Marinescu, Espaces Vectoriels Pseudo Topologique et le Th´eorie de Distribu-
tions, Deutcshe Verlag d. Wiss., 1963.
[1940] A. D. Michal, Diﬀerential calculus in linear topological spaces, Proc. Nat. Acad.
Sci. 24 (1938), no. 8, pp. 340-342.
[1954] I. S. Reed, A class of multiple-error-correcting codes and the decoding scheme.
IRE Trans. Inform. Theory IT-4, no. 9 (1954), pp. 38-49.
[2003] C. M. Reidys and P. F. Stadler, Combinatorial landscapes,
http://www.santafe.edu/sﬁ/publications/Working−Papers/01−03−014.pdf
http://www.santafe.edu/sﬁ/publications/Working−Papers/01−03−014.ps
[2001] L. Schr¨oder, Categories: a free tour, in Categorical Perspectives (J. Kozlowski
and A. Melton, ed.), Birkh¨auser, 2001, pp. 1-27.
[2001] B. M. R. Stadler, P. F. Stadler, G. P. Wagner, and W. Fontana, The topology of
the possible: Formal spaces underlying patterns of evolutionary change, Journal
of Theoretical Biology 213 (2001) no. 2, pp. 241-274.
[1990] G. Y. Vichniac, Boolean derivatives on cellular automata, in Cellular automata:
theory and experiment, (H. Gutowitz, ed.), MIT Press, 1991, (Physica D 45
(1990) no. 1-3, pp. 63-74).

Weighted Distributed Systems and Their Logics
Benedikt Bollig1 and Ingmar Meinecke2
1 LSV, CNRS UMR 8643 & ENS de Cachan
61 Av. du Pr´esident Wilson, F-94235 Cachan Cedex, France
bollig@lsv.ens-cachan.fr
2 Institut f¨ur Informatik, Universit¨at Leipzig
Johannisgasse 26, D-04103 Leipzig, Germany
meinecke@informatik.uni-leipzig.de
Abstract. We provide a model of weighted distributed systems and give a logical
characterization thereof. Distributed systems are represented as weighted asyn-
chronous cellular automata. Running over directed acyclic graphs, Mazurkiewicz
traces, or (lossy) message sequence charts, they allow for modeling several com-
munication paradigms in a unifying framework, among them probabilistic shared-
variable and probabilistic lossy-channel systems. We show that any such system
can be described by a weighted existential MSO formula and, vice versa, any
formula gives rise to a weighted asynchronous cellular automaton.
1
Introduction
Classical automata theory has become an indispensable tool in many modern areas of
computer science, supporting, for example, programming languages and speciﬁcation
and veriﬁcation techniques. In some applications, automata need to cope with quantita-
tive phenomena. Then, taking a transition in an automaton is accompanied by measuring
its cost or weight. For example, a system might provide a counter tracking the number of
occurrences of a given pattern; or its behavior might depend on probability laws so that
the outcome of a transition is generally uncertain and depends on a probability distri-
bution. Actually, automata with weights enjoy manifold applications in numerous areas
such as speech recognition [18], probabilistic systems [12,1], and image compression
[4].
Formally, the behavior of a weighted automaton is no longer characterized by the
pure existence of an accepting run. Rather, a weighted automaton comes up with a
formal power series assigning to any possible execution sequence a value from a semi-
ring. More precisely, the values collected along an automaton execution are multiplied,
whereas nondeterminism is resolved by summation therewith generalizing the two op-
erations of the two-valued Boolean algebra, cf. [13].
For a long time, the correspondence of automata and logic has been a captivating
research direction in computer science. The probably most famous result goes back to
B¨uchi and Elgot, who discovered a precise correspondence between ﬁnite automata and
the logical formalism of monadic second-order (MSO) formulas [3,11]. In particular,
any system description formalized in the MSO language comes up with an implementa-
tion in terms of a ﬁnite automaton. Concerning weighted automata, most results estab-
lish Kleene-like theorems stating that a formal power series is described by a weighted
S. Artemov and A. Nerode (Eds.): LFCS 2007, LNCS 4514, pp. 54–68, 2007.
c⃝Springer-Verlag Berlin Heidelberg 2007

Weighted Distributed Systems and Their Logics
55
automaton iff it is rational [21,6,15]. A logical characterization of weighted automata
has been achieved only recently: Droste and Gastin opened a new research direction by
providing a weighted MSO logic to deﬁne formal power series over words [7]. Their
achievements have been extended, among others, to automata on inﬁnite words [9],
trees [10], pictures [16], and traces [17].
In this paper, we deal with a model for weighted distributed systems that uniﬁes
many communication paradigms such as shared-memory systems, (lossy) channel sys-
tems, etc. It is constituted by asynchronous cellular automata (ACAs) [8] running on
directed acyclic graphs (dags) without auto-concurrency. Unlike ﬁnite automata, which
process their input words in a sequential fashion, ACAs are appropriate to concurrent
executions. Accordingly, the assignment of weights does not depend on the order in
which independent events are executed. ACAs have already been equipped with weights
by Kuske to recognize formal power series over traces [15]. Generalizing results by
Ochma´nski [19] and Droste and Gastin [6], he showed that a series is regular iff it is
recognized by some weighted ACA. Actually, we provide an even more general model
subsuming Kuske’s automata. Running over dags rather than traces, our weighted ACA
can cope with many common domains for concurrency, not only traces but also message
sequence charts which play a prominent role in telecommunication. As we will dis-
cuss in the course of this paper, the latter domain allows an embedding of probabilistic
lossy-channel systems. Our main result states that weighted ACAs recognize precisely
the formal power series that are deﬁnable in an existential fragment of a weighted MSO
logic over dags. This result cannot be obtained by a translation of the word setting as
it was done for traces [17]. On the other hand, a lot of technical difﬁculties arise in
our setting compared to this of words. Especially, we have to prove an unambiguity re-
sult for ﬁrst-order deﬁnable languages before establishing the main theorem. For words
such an unambiguity result is for free since deterministic devices sufﬁce to recognize
all regular languages. Moreover, the construction of a weighted formula from a given
weighted asynchronous cellular automaton is much more tricky than for words.
The paper is structured as follows: in Section 2, we introduce our notion of a dag over
a distributed alphabet. Hereby, a distributed alphabet constitutes the system architecture
by assigning to any process its supply of actions. Section 3 introduces ACAs ﬁrst in
their classical, then in their weighted form. The behavior of a weighted ACA will be
described in terms of a formal power series over (a subset of) the class of dags. Having
introduced weighted MSO logic over dags in Section 4, Sections 5 and 6 derive our
main result, the precise correspondence between weighted ACAs and the existential
fragment of weighted MSO logic.
2
Dags over Distributed Alphabets
We ﬁx a nonempty ﬁnite set Ag of agents, a distributed alphabet Σ, which is a tuple
(Σi)i∈Ag of (not necessarily disjoint) alphabets Σi, and an alphabet C. Elements from
Σi are understood to be actions that are performed by agent i. Let Σ = 
i∈Ag Σi
denote the set of all the actions. The actions will label the nodes of a graph, which
we will later refer to as events. Elements from C label edges of a graph to provide
a kind of control information. For example, they might reﬂect the type of a message

56
B. Bollig and I. Meinecke
represented by an edge between communicating events. A (directed) graph over (Σ, C)
is a structure (V, {◁ℓ}ℓ∈C, λ) where V is its ﬁnite set of nodes, ◁ℓ⊆V ×V are disjoint
binary relations on V , and λ : V →Σ is the labeling function. We call ◁:= 
ℓ∈C ◁ℓ
the edge relation and set ≤= ◁∗and < = ◁+. For u, v ∈V , we deﬁne the cover
relation u ⋖v of ≤by u < v and, for any w ∈V , u < w ≤v implies w = v. A
directed acyclic graph (dag) over (Σ, C) is a graph (V, {◁ℓ}ℓ∈C, λ) over (Σ, C) such
that ◁is irreﬂexive and ≤is a partial order. The set of all those dags is denoted by
 (Σ, C). For a ∈Σ, we put loc(a) := {i ∈Ag | a ∈Σi}. Then, a and b are
independent, writing a I
 Σ b, if loc(a) ∩loc(b) = Ø. Otherwise, we say a and b are
dependent, writing a D
 Σ b.
We now introduce the models representing the behavior of a system of communicat-
ing agents. In doing so, we combine and extend the models from [8,14,2].
Deﬁnition 2.1. A ( Σ, C)-dag is a dag (V, {◁ℓ}ℓ∈C, λ) ∈
 (Σ, C) where
– for any i ∈Ag, λ−1(Σi) is totally ordered by ≤and
– for any ℓ∈C and (u, v), (u′, v′) ∈◁ℓwith λ(u)D
 Σλ(u′) and λ(v)D
 Σλ(v′), we
have u ≤u′ iff v ≤v′.
The set of all ( Σ, C)-dags is denoted by
 ( Σ, C).
The ﬁrst condition reﬂects that a single agent is considered to operate sequentially. Es-
pecially, there is no auto-concurrency. The second condition ensures a FIFO architec-
ture of communicating systems. Messages (u, v) and (u′, v′) of the same type between
the same agents are received in the same order as they have been sent. Because of the
FIFO-architecture and the absence of auto-concurrency, we conclude that, in a ( Σ, C)-
dag (V, {◁ℓ}ℓ∈C, λ), for any u ∈V , ℓ∈C, and a ∈Σ, there is at most one vertex
v ∈V such that both u ◁ℓv (or v ◁ℓu) and λ(v) = a.1 If C is a singleton, we actually
deal with structures (V, ◁, λ) and we speak of Σ-dags.
The automaton model as introduced in the next section monitors for every node
u ∈V of a ( Σ, C)-dag (V, {◁ℓ}ℓ∈C, λ) the direct neighborhood of u. Therefore, we
introduce the following abbreviations: For u ∈V , we denote by Read(u) := {(a, ℓ) ∈
Σ × C | ∃v ∈V : v ◁ℓu ∧λ(v) = a} the read domain of u and, given (a, ℓ) ∈
Read(u), let (a, ℓ)-pred(u) be the unique vertex v such that both v ◁ℓu and λ(v) = a.
Similarly, let Write(u) := {(a, ℓ) ∈Σ × C | ∃v ∈V : u ◁ℓv ∧λ(v) = a} be the
write domain of u and, for (a, ℓ) ∈Write(u), (a, ℓ)-succ(u) denote the unique vertex
v such that both u ◁ℓv and λ(v) = a. For i ∈Ag and Vi = {u ∈V | λ(u) ∈Σi},
sequential progress of an agent i ∈Ag is reﬂected by ◁i := ◁∩(Vi × Vi) and the
total order ≤i := ≤∩(Vi × Vi) (do not mistake relation ◁i of agent i for edge relation
◁ℓfor ℓ∈C). For u ∈V and i ∈Ag, u is Σi-maximal if u ∈Vi and there is no v ∈Vi
such that u < v. Obviously, there is at most one Σi-maximal vertex.
Dags over distributed alphabets subsume popular domains of concurrency:
Example 2.1 (Mazurkiewicz Traces [5]). We consider distributed systems where an ac-
tion a ∈Σ is executed simultaneously by any component i ∈loc(a). The behavior of
1 As a consequence, the underlying graph has bounded degree. This property is essential in
establishing the coincidence between recognizability and logical deﬁnability [2].

Weighted Distributed Systems and Their Logics
57
such a “shared-memory” system is described naturally by a set of traces. Commonly,
traces are deﬁned as congruence classes of words or as dependence graphs. In our set-
ting, we model a trace as the union of the Hasse diagrams of the total orders of the
different agents. Moreover, the labeling of an edge between two nodes u and v provides
information about which agents execute u and v consecutively. In detail, a trace over
Σ is a dag (V, {◁ℓ}ℓ∈2Ag, λ) from
 ( Σ, 2Ag) such that both ◁= 
i∈Ag ⋖i and,
for any (u, v) ∈◁and ℓ∈2Ag, u ◁ℓv iff ℓ= {i ∈Ag | u ⋖i v} (recall that
⋖i is the cover relation of ≤i). This modeling of a trace will turn out to be tremen-
dously helpful when simulating shared-memory systems in terms of asynchronous cel-
lular automata, as the edge relation will be used to access, for any event u and any agent
i ∈loc(λ(u)), the current state of i ∈Ag right before executing u. A sample trace over
Σ = ({a, b, c}, {a, b, d}, {a, b}) (with Ag = {1, 2, 3}) is depicted in Fig. 1(a).
Example 2.2 ((Lossy) Message Sequence Charts). Another communication paradigm
is that of channel systems: several components i ∈Ag communicate by sending and
receiving messages through channels. So let Ch = (Ag × Ag) \ idAg be the set of
channels. To model the behavior of such a system, we need to ﬁx supplies of send and
receive actions: for i ∈Ag, let Γi denote {i!j | (i, j) ∈Ch} ∪{i?j | (i, j) ∈Ch}, the
set of (communication) actions of agent i. Action i!j reads as “i sends a message to j”.
Accordingly, j?i is the complementary receive action. Let Γ be the distributed alphabet
(Γi)i∈Ag. A message sequence chart (MSC) over Ag is a Γ-dag (V, ◁, λ) such that,
for any i ∈Ag, ◁i is the cover relation of ≤i, for any (u, v) ∈◁with λ(u) I
 Γ λ(v),
λ(u) = i!j and λ(v) = j?i for some i, j, and, for any u ∈V , there is v ∈V satisfying
both λ(u) I
 Γ λ(v) and either u ◁v or v ◁u. Observe that, due to the general deﬁnition
of a Γ-dag, we deal with a model for FIFO communication. If we do not require a send
event to be followed by a corresponding receive event, we deal with a lossy MSC. More
precisely, the last condition in the deﬁnition of an MSC is weakened as follows: for any
v ∈V with λ(v) a receive action, there is u ∈V satisfying λ(u) I
 Γ λ(v) and u ◁v.
Figure 1(b) depicts an MSC over {1, 2}, whereas the structure from Fig. 1(c) is not an
MSC but a lossy MSC.
{1}
{2}
{2}
{1, 3}
{2}
c
a
d
d
b
(a)
1!2
1?2
1!2
2!1
2?1
2?1
(b)
1!2
1!2
1!2
2?1
2?1
(c)
Fig. 1. A trace over ({a, b, c}, {a, b, d}, {a, b}), an MSC over {1, 2}, and a lossy MSC over
{1, 2} that is not an MSC

58
B. Bollig and I. Meinecke
3
Weighted Asynchronous Cellular Automata
First we provide the unweighted model of an asynchronous cellular automaton, similar
to the one proposed in [2]. Actually, we deal with asynchronous cellular automata with
types (ACATs) over ( Σ, C)-dags, which have limited access to the future. To express
“communication requests”, a type function associates with any action a and any state q
the set of actions that henceforth “communicate” with a, provided executing a results in
state q. Regarding lossy MSCs, for example, we might require an event labeled with a
send action 1!2 to be followed by the suitable receive event, which is then labeled with
the communication action 2?1. For some classes the expressive power of ACAs with
and without types coincide. But in general, omitting the type function severely restricts
the expressive power of ACATs [2].
Deﬁnition 3.1. An asynchronous cellular automaton with types (ACAT) over ( Σ, C) is
a structure A = (Q, Δ, T, F) where
– Q is the nonempty ﬁnite set of states,
– Δ ⊆Trans(
 Σ,C)(Q) := (Q ·∪{−})Σ×C × Σ × Q is the set of transitions,
– T : (Σ × Q) →2Σ×C is the type function, and
– F ⊆(Q ·∪{ı})Ag is the set of global ﬁnal states.
We often write (q, a, q) ∈Δ with q ∈(Q ·∪{−})Σ×C as q −→(a, q). Note that
q[(b, ℓ)] = −means that there is no (b, ℓ)-predecessor. Hence, we will sometimes write
q as an element from P(Σ × C × Q). The idea of a run of an asynchronous cellular
automaton A on a ( Σ, C)-dag D = (V, {◁ℓ}ℓ∈C, λ) is an additional labeling of the
nodes u ∈V with states q ∈Q such that the local neighborhoods match the transitions,
after executing D the system is in a ﬁnal state, and the requests of the type function are
satisﬁed.
First, let us consider the following example: A = (Q, Δ, T, F) running on lossy
MSCs over agents {1, 2}, cf. Example 2.2. We put Q = {q0, q1}. Now, the follow-
ing transitions are in Δ: Ø →(1!2, q0), (1!2, q0) →(1!2, q1), (1!2, q1) →(1!2, q0),
q0
q1
q0
q0
q1
1!2
1!2
1!2
2?1
2?1
(1!2, q0) →(2?1, q0), {(1!2, q0), (2?1, q0)} →(2?1, q1),
and {(1!2, q1), (2?1, q0)} →(2?1, q1). Moreover, we put
T (1!2, q0) = {2?1} and F = {(1, q0), (2, q1)}. Then the
picture on the left hand side depicts a successful run of A on
the lossy MSC from Figure 1(c). For every node, the node
itself together with its read domain is covered by a transi-
tion. Furthermore, agent 1 stops in q0 and agent 2 in q1. Last
but not least, every send event 1!2 in state q0 is followed by
a receive event 2?1 as imposed by the type function.
To be precise, let ρ : V →Q. We write (D, ρ) to denote the dag (V, {◁ℓ}ℓ∈C, (λ, ρ))
over (Σ × Q, C). For (D, ρ), let trans(D,ρ) : V →Trans(
 Σ,C)(Q) describe the down-
ward local neighborhood, i.e., for any u ∈V let trans(D,ρ)(u) = (q, λ(u), ρ(u))
where, for any (b, ℓ) ∈Σ × C,
q[(b, ℓ)] =

−
if (b, ℓ) ̸∈Read(u),
ρ((b, ℓ)-pred(u)) if (b, ℓ) ∈Read(u).

Weighted Distributed Systems and Their Logics
59
Moreover, we deﬁne ﬁnal (D,ρ) ∈(Q ·∪{ı})Ag by ﬁnal (D,ρ)[i] = ı for any agent
i ∈Ag with Vi = Ø. Otherwise, ﬁnal(D,ρ)[i] = ρ(u) where u is Σi-maximal in V .
Thus, if the system starts in the global state (ı)i∈Ag and executes D, then it ends up in
the global state ﬁnal(D,ρ). Now a run of A on D is a mapping ρ : V →Q such that,
for any u ∈V , trans(D,ρ)(u) ∈Δ. Moreover, ρ is accepting if both ﬁnal(D,ρ) ∈F
and, for any u ∈V , we have T (λ(u), ρ(u)) ⊆Write(u). The intuition behind the latter
condition is that we require Write(u) to contain at least the communication requests
imposed by the type function of the automaton. The language L(A) is the set of all D
such that there is at least one accepting run of A on D. We call A unambiguous if, for
any ( Σ, C)-dag D and any two accepting runs ρ, ρ′ of A on D, we have ρ = ρ′.
A set L ⊆
 ( Σ, C) is called recognizable if L(A) = L for some ACAT A over
( Σ, C). Similarly, we say that L is unambiguously recognizable if L(A) = L for some
unambiguous ACAT A over ( Σ, C).
A weighted automaton is no longer characterized by the set of accepted executions.
Rather, it assigns to any possible execution a value from a semiring. A semiring is a
structure
 = (K, ⊕, ◦,
,
) with two binary operations, addition and multiplication,
and constants
 and
, such that (K, ⊕,
) is a commutative monoid, (K, ◦,
) is a
monoid, multiplication distributes over addition, and
 ◦k = k ◦
 for any k ∈K.
We say
 is commutative if the multiplication ◦is commutative. Sample semirings are
(IN, +, ·, 0, 1), the 2-valued Boolean algebra
 = ({ ,
}, ∨, ∧,
,
), and the proba-
bilistic semiring
 = ([0, 1], max, ·, 0, 1). Throughout this paper, we ﬁx a commutative
semiring
 = (K, ⊕, ◦,
,
). Commutativity is needed for a proper deﬁnition of au-
tomata behavior and several closure properties.
Deﬁnition 3.2. A weighted asynchronous cellular automaton with types (wACAT) over
 and ( Σ, C) is a structure (Q, μ, T, γ) where
– Q is the nonempty ﬁnite set of states,
– μ : Trans(
 Σ,C)(Q) →
 is the transition weight function,
– T : (Σ × Q) →2Σ×C is the type function, and
– γ : (Q ·∪{ı})Ag →
 is the ﬁnal weight function.
In a wACAT, the values of a semiring that are collected along an execution of the au-
tomaton are multiplied, whereas nondeterminism is resolved by summation. The behav-
ior of such an automaton will be a function S :
 ( Σ, C) →
, also called a formal
power series. The collection of all these functions is denoted by
⟨⟨ ( Σ, C)⟩⟩.
More precisely: let D = (V, {◁ℓ}ℓ∈C, λ) be a ( Σ, C)-dag. In the weighted setting,
every mapping ρ : V →Q is referred to as a run. The weight of ρ is the product
weight(D, ρ) :=
 
u∈V
μ(trans(D,ρ)(u))

◦γ(ﬁnal(D,ρ)) .
We call ρ successful if T (λ(u), ρ(u)) ⊆Write(u) for any u ∈V . We thus can assign
to A a formal power series ∥A∥∈
⟨⟨ ( Σ, C)⟩⟩by
(∥A∥, D) :=

ρ:V →Q
ρ successful
weight(D, ρ)

60
B. Bollig and I. Meinecke
for any D = (V, {◁ℓ}ℓ∈C, λ) ∈
 ( Σ, C). Note that, in the context of formal power
series, (∥A∥, D) is a common notation for ∥A∥(D).
For L ⊆
 ( Σ, C), the characteristic series
L :
 ( Σ, C) →
 is given by
(L, D) =
 if D ∈L and (L, D) =
 if D ̸∈L. We say that S ∈
⟨⟨ ( Σ, C)⟩⟩is
recognizable if there is a wACAT A with ∥A∥= S.
Example 3.1 (Probabilistic Lossy-Channel Systems [20]). Aprobabilisticlossy-channel
system is a tuple P = ((Qi, δi)i∈Ag, qin, (rij(q))(i,j)∈Ch,q∈Qi): with any agent i, we
associate a sequential process, which is composed of a ﬁnite state space Qi and a tran-
sition relation δi ⊆Qi × Γi × Qi. Recall that Γi comprises the set of communication
actions executed by agent i, i.e., actions of the form i!j or i?j with i ̸= j. We shall
assume δi to be deterministic, i.e., for any q ∈Qi and σ ∈Γi, there is at most one
q′ ∈Qi such that (q, σ, q′) ∈δi. Moreover, the system is equipped with a global initial
state qin ∈	
i∈Ag Qi. There is an unreliable channel in between any two agents i and j
with i ̸= j, i.e., depending on a state q ∈Qi in which a message is sent, a channel (i, j)
has a reliability rij(q) ∈[0, 1]. Thus, the message arrives at agent j with probability
rij(q) and is lost with probability 1 −rij(q).
We will give the probabilistic lossy-channel system P a semantics in terms of a
wACAT AP = (Q, μ, T, γ) over
 = ([0, 1], max, ·, 0, 1) and Γ reading lossy MSCs
where Q = (
i∈Ag Qi) × {success, failure, rec}. Here, we give just the idea of the
construction. Roughly speaking, we shift the reliabilities of the channels to the sequen-
tial processes. Then a state with second component success is assigned to a send event
that succeeds in delivering a message, which is guaranteed by the type function, i.e.,
T maps a pair of the form (i!j, (q, success)) to {j?i} and any other pair to the empty
set. Such a success-state is entered with the probability that the transmission succeeds.
In contrast, a send event that is equipped with a state that carries the attribute failure is
entered with the probability that the transmission fails. Thus, it cannot be followed by
a corresponding receive. Any other event will carry rec to indicate that we deal with a
receive event. As we do not explicitly deal with ﬁnal states, γ maps any possible ﬁnal
conﬁguration to 1. For a lossy MSC M, (∥AP ∥, M) ∈[0, 1] might now be interpreted
to be the probability of acceptance of M by P.
Example 3.2 (Probabilistic Asynchronous Automata [12]). The model of asynchronous
automata [22] over Mazurkiewicz traces represents shared-memory systems rather than
channel systems. In an asynchronous automaton running on traces, any action a has to
be executed simultaneously by any component i ∈loc(a). Probabilistic asynchronous
automata have been introduced by Jesi, Pighizzini, and Sabadini [12]. In a probabilistic
asynchronous automaton, the outcome of a transition depends on a probability distri-
bution on the set of global states of the system. Formally, a probabilistic asynchronous
automaton over Σ is a structure B = ((Si)i∈Ag, (Pa)a∈Σ, q0, η) where
– for each i ∈Ag, Si is a nonempty ﬁnite set of (i-)local states,
– for each a ∈Σ, Pa is a mapping Sa × Sa →[0, 1] such that, for any s ∈Sa,
Pa(s, .) is a probability distribution on Sa where Sa := {s ∈	
i∈Ag(Si ·∪{∗}) |
for any i ∈Ag, s[i] = ∗iff i ̸∈loc(a)},
– q0 ∈	
i∈Ag Si is the global initial state, and
– η : 	
i∈Ag Si →{0, 1} assigns a weight to any possible ﬁnal conﬁguration.

Weighted Distributed Systems and Their Logics
61
A probability distribution Pa(s) reﬂects that, in a global conﬁguration from 	
i∈Ag Si
that coincides with s with respect to the locations from loc(a), executing an a will alter
at most the local states s of agents from loc(a).
We provide the reader with a rather intuitive semantics of B and refer to [12] for
details. Roughly speaking, B assigns to any trace a probability of acceptance. To de-
termine the acceptance probability of a trace T = (V, {◁ℓ}ℓ∈2Ag, λ) over Σ (see Ex-
ample 2.1), B will ﬁx an arbitrary linear extension w = (V, ≤′, λ) of T, i.e., ≤′ is a
total-order relation containing ≤. As usual, w can be seen as a word a1 . . . an ∈Σ∗
with n = |V |. Then, starting in the global initial state q0, B reads w letter by letter and
assigns to any position k = 1, . . . , n a global state qk ∈	
i∈Ag Si such that going from
qk−1 to qk changes at most the components from loc(ak), i.e., qk−1[i] = qk[i] for any
i ̸∈loc(ak). A step from qk−1 to qk uniquely determines a pair (sk−1, sk) ∈Sak ×Sak
with sk−1[i] = sk[i] = ∗for any i ̸∈loc(ak) and sk−1[i] = qk−1[i] and sk[i] = qk[i]
for any other i. The sequence q0, . . . , qn might be called a run of B on w. The weight
of this particular run is the product 	
k=1,...,n Pak(sk−1, s′
k) · η(qn) (if n = 0, then
we set its weight to be η(q0)). Summing up the weights of all possible runs of B on w
determines the value PB(T) ∈[0, 1], the probability that T is accepted by B.
Lemma 3.1. There is a wACAT A = (Q, μ, T, γ) over (	≥0, +, ·, 0, 1) and ( Σ, 2Ag)
such that |Q| ≤|Σ| × | 	
i∈Ag Si| and (∥A∥, T) = PB(T) for any trace T.2
Proof. Let Q = 
a∈Σ Sa and T (a, s) = Ø for any (a, s) ∈Σ × Q.
– Suppose t = {((a1, s1), ℓ1), . . . , ((an, sn), ℓn)} −→(a, s) ∈Trans(
 Σ,2Ag)(Q). If
sk ∈Sak, k = 1, . . . , n, s ∈Sa, and the sets ℓk ∈2Ag are pairwise disjoint, then
μ(t) is set to be Pa(s′, s) where s′ is determined as follows: for any i ∈loc(a),
s′[i] = q0[i] if i ̸∈
k=1,...,n ℓk, and, otherwise, s′[i] = sk[i] for the unique k ∈
{1, . . . , n} with i ∈ℓk. Any other transition is mapped to 0.
– Suppose q ∈(Q ·∪{ı})Ag. If there is q′ ∈	
i∈Ag Si such that, for any i ∈Ag,
q[i] = ı implies q′[i] = q0[i] and q[i] ∈Q implies q′[i] = q[i][i], then set γ(q) to
be η(q′). Otherwise, set γ(q) to be 0.
□
Note that (weighted) ACATs relative to traces can actually do without types. By
Lemma 3.1 and Theorem 4.2, we will give, as a byproduct, a weighted formula deﬁning
the behavior of a probabilistic asynchronous automaton B.
We collect some closure properties of recognizable series needed to show that deﬁnable
series are recognizable. Let S, S′ ∈
⟨⟨ ( Σ, C)⟩⟩. Then, we deﬁne k ◦S for k ∈
,
S + S′, and S ⊙S′ by (k ◦S, D) = k ◦(S, D), (S + S′, D) = (S, D) ⊕(S′, D), and
(S ⊙S′, D) = (S, D) ◦(S′, D) for any D ∈
 ( Σ, C).
Proposition 3.1. Let S, S′ :
 ( Σ, C) →
 be recognizable and k ∈
. Then, k ◦S,
S + S′, and S ⊙S′ are recognizable.
2 Note that we calculate values in the interval [0, 1] only. But unfortunately, ([0, 1], +, ·, 0, 1) is
not a semiring. Therefore, we turn to ( ≥0, +, ·, 0, 1).

62
B. Bollig and I. Meinecke
Now let Σi, Γi be arbitrary alphabets for i ∈Ag with Σ = 
i∈Ag Σi and Γ =

i∈Ag Γi. Moreover, let πv : Σ →Γ such that πv(Σi) ⊆Γi for all i ∈Ag and
(a, b) ∈D
 Σ iff (πv(a), πv(b)) ∈D
 Γ . Then, we call π :
 ( Σ, C) →
 ( Γ, C)
with π(D) = (V, {◁l}l∈C, πv ◦λ) for D = (V, {◁l}l∈C, λ) ∈
 ( Σ, C) a projec-
tion from
 ( Σ, C) to
 ( Γ, C). Note that π(D) is indeed a ( Γ, C)-dag because
of the properties of πv. For S ∈
⟨⟨ ( Σ, C)⟩⟩, let π(S) be the series deﬁned for
every D′ ∈
 ( Γ, C) by (π(S), D′) = 
D∈π−1(D′)(S, D).
Proposition 3.2. Let S ∈
⟨⟨ ( Σ, C)⟩⟩and π :
 ( Σ, C) →
 ( Γ, C) be a
projection. If S is recognizable, then π(S) ∈
⟨⟨ ( Γ, C)⟩⟩is recognizable.
Proposition 3.3. Let L ⊆
 ( Σ, C) be an unambiguously recognizable language.
Then, the characteristic series
L over
 is recognizable.
4
Weighted Monadic Second-Order Logic
We ﬁx sets Var = {x, y, . . .} of ﬁrst-order and VAR = {X, Y, . . .} of second-order
variables. Still, we assume the semiring
 being commutative.
Deﬁnition 4.1. The set wMSO(, ( Σ, C)) of weighted monadic second-order (wMSO)
formulas over
 and ( Σ, C) is given by (let k ∈K, a ∈Σ, and ℓ∈C):
ϕ ::=k | λ(x) = a | ¬(λ(x) = a) | x ◁ℓy | ¬(x ◁ℓy) | x = y | ¬(x = y) |
x ∈X | ¬(x ∈X) | ϕ1 ∨ϕ2 | ϕ1 ∧ϕ2 | ∃x.ϕ | ∃X.ϕ | ∀x.ϕ | ∀X.ϕ
The formulas k, λ(x) = a, x ◁ℓy, x = y and x ∈X are called atomic. Negation
of k has no reasonable semantics for general semirings. Thus, to obtain an intuitive
interpretation of negation in terms of
 and
, it is pushed to the atomic level, omitting k.
In exchange, we have to enrich the syntax by conjunction and universal quantiﬁcation,
cf. [7]. Let Free(ϕ) be the set of free variables of ϕ and V ∈2Var∪VAR a ﬁnite set of
variables. We say that D = (V, {◁ℓ}ℓ∈C, (λ, ρ)) with ρ : V →{0, 1}V is valid if, for
any ﬁrst-order variable x ∈V, there is a unique node u ∈V such that ρ(u)[x] = 1.
In that case, ρ(x) shall refer to u. Given x ∈V and u ∈V , we deﬁne the update
ρ[x/u] = ρ′ : V →{0, 1}V such that ρ′(u)[x] = 1, ρ′(v)[x] = 0 for any v ∈V \ {u},
and ρ′(v)[x] = ρ(v)[x] for any v ∈V and x ∈V \ {x}. Similarly, ρ[X/V ′] is deﬁned
for X ∈V and V ′ ⊆V .
Note that, given a set V of variables, (weighted) ACATs can be extended to run on
dags over (Σ × {0, 1}V, C): We deﬁne a distributed alphabet ΣV = ( ΣV
i )i∈Ag by
ΣV
i = Σi × {0, 1}V.
Deﬁnition 4.2. Suppose ϕ ∈wMSO(, ( Σ, C)) and suppose V ∈2Var∪VAR is ﬁnite
with Free(ϕ) ⊆V. The semantics of ϕ wrt. V is a series ϕV ∈
⟨⟨ ( ΣV, C)⟩⟩,
given as follows: if D = (V, {◁ℓ}ℓ∈C, (λ, ρ)) ∈
 ( ΣV, C) is not valid, we set
ϕV(D) =
. Otherwise, ϕV(D) is determined inductively as shown in Table 1.

Weighted Distributed Systems and Their Logics
63
Table 1. The semantics of wMSO-formulas
kV(D) = k
λ(x) = aV(D) =
 
if λ(ρ(x)) = a

otherwise
x ◁ℓyV(D) =
 
if ρ(x) ◁ℓρ(y)

otherwise
x = yV(D) =
 
if ρ(x) = ρ(y)

otherwise
x ∈XV(D) =
 
if ρ(x) ∈ρ(X)

otherwise
¬ϕV(D) =
 
if ϕV(D) =


if ϕV(D) =

ϕ1 ∨ϕ2V(D) = ϕ1V(D) ⊕ϕ2V(D)
ϕ1 ∧ϕ2V(D) = ϕ1V(D) ◦ϕ2V(D)
∃x.ϕV(D) =

u∈V
ϕV(D[x/u]])
∀x.ϕV(D) =

u∈V
ϕV(D[x/u])
∃X.ϕV(D) =

V ′⊆V
ϕV(D[X/V ′])
∀X.ϕV(D) =

V ′⊆V
ϕV(D[X/V ′])
We abbreviate ϕFree(ϕ) by ϕ. For
 being the 2-valued Boolean algebra
 = { ,
},
wMSO(, ( Σ, C)) reduces to the usual MSO logic. Accordingly, L ⊆
 ( Σ, C)
is FO-deﬁnable if its support is deﬁnable in FO(, ( Σ, C)), i.e., in the fragment of
wMSO(, ( Σ, C)) in which no second-order quantiﬁer occurs. We say that the series
S ∈
⟨⟨ ( Σ, C)⟩⟩is an FO-deﬁnable step function if S = 
n
i=1 ki ◦
Li for some
n ∈IN, ki ∈K, and FO-deﬁnable languages Li. We call ϕ ∈wMSO(, ( Σ, C))
restricted if it contains no universal second-order quantiﬁcation and, for any subformula
∀x.ψ of ϕ, ψ is an FO-deﬁnable step function. We denote the set of restricted wMSO-
formulas over
 and ( Σ, C) by wRMSO(, ( Σ, C)). Finally, let wREMSO(, ( Σ, C))
be the existential fragment of wRMSO(, ( Σ, C)), which contains the formulas of the
form ∃X1 . . . ∃Xn.ϕ where the kernel formula ϕ ∈wRMSO(, ( Σ, C)) contains no
second-order quantiﬁer.3
Even for words, wMSO has to be restricted because, otherwise, deﬁnability exceeds
recognizability. While, in their logic, Droste and Gastin [7] deal with recognizable step
functions exploiting the notion of determinism for ﬁnite automata, we have to cope with
FO-deﬁnable functions in the context of dags. Fortunately, we can show unambiguity of
L for FO-deﬁnable L, which is a cornerstone in establishing a logical characterization
of wACATs.
Theorem 4.1. Any FO-deﬁnable set of ( Σ, C)-dags is unambiguously recognizable.
Proof (Sketch). It is well-known that any ﬁrst-order formula can be written as the
Boolean combination of statements “the pattern P occurs at least n times”. Here, P
is meant to be the (isomorphism type of the) environment of a node bounded by some
radius R ∈IN, also called an R-sphere. In [2], an ACAT AR over dags detects the R-
environment of any node. To transform the formula into an equivalent ACAT, we need
to equip AR with a (deterministic) threshold counting procedure to count how often a
sphere is used in a run. However, AR from [2] is not unambiguous due to some coloring
3 It is not trivial to rewrite every wRMSO-formula into a wREMSO-formula. The problem is
that it is not clear if for an FO-deﬁnable language L (as used in an FO-deﬁnable step function)
the characteristic series
L is again wFO-deﬁnable (see also the discussion in Section 6).

64
B. Bollig and I. Meinecke
of spheres that is not unique. Such a coloring can be performed unambiguously so that
any ﬁrst-order formula can be simulated by an unambiguous ACAT.
□
Corollary 4.1. {D ∈
 ( ΣV, C) | D valid} is unambiguously recognizable.
Proof. It sufﬁces to show FO-deﬁnability. In fact, it is easy to provide an FO formula
requiring that, for any ﬁrst-order variable x, there is exactly one node whose labeling is
1 in the component that corresponds to x.
□
Example 4.1. Consider the ring

 = (
, +, ·, 0, 1) and the class of lossy message se-
quence charts with Ag = {1, 2}, cf. Example 2.2. Then the formula
ϕ = (∃x.λ(x) = 1!2) ∨(∃y. −1 ∧λ(y) = 2?1)
deﬁnes a series ϕ which maps every lossy MSC M to the number of messages from
process 1 to 2 that are lost.
The remainder of this paper is dedicated to the proof of our main theorem:
Theorem 4.2. Let
 be a commutative semiring and S ∈
⟨⟨ ( Σ, C)⟩⟩. Then, the
following are equivalent:
1. S is recognizable,
2. S is wRMSO-deﬁnable, and
3. S is wREMSO-deﬁnable.
5
Deﬁnable Series Are Recognizable
In this section we show that series deﬁned by restricted formulas are recognizable. Due
to Corollary 4.1 and Propositions 3.1 and 3.3, we can restrict to valid ( Σ, C)-dags.
By the closure properties of wACATs as stated in Propositions 3.1 and 3.2, we get:
Proposition 5.1. Let ϕ, ψ ∈wMSO(, ( Σ, C)).
(a) If ϕ is atomic or the negation of an atomic formula, then [[ ϕ ]] is recognizable.
(b) If [[ ϕ ]] and [[ ψ ]] are recognizable, then [[ ϕ ∨ψ ]] and [[ ϕ ∧ψ ]] are recognizable.
(c) If [[ ϕ ]] is recognizable, then [[ ∃x.ϕ ]] and [[ ∃X.ϕ ]] are recognizable.
Proposition 5.2. Let ϕ ∈wMSO(, ( Σ, C)) with [[ ϕ ]] = n
i=1 ki ◦
Li an FO-
deﬁnable step function. Then, [[ ∀x.ϕ ]] is recognizable.
Proof (Sketch). Let W = free(ϕ) and V = free(∀x.ϕ) = W \ {x}. Furthermore,
[[ ϕ ]] = n
i=1 ki
Li with ki ∈
 and Li ⊆
 ( ΣW, C) FO-deﬁnable languages for
i = 1, . . . , n. By Theorem 4.1, every Li is recognized by an unambiguous ACAT. FO-
deﬁnable languages are closed under union, complement and intersection. Therefore,
{Li | i = 1, . . . , n} can be assumed being a partition of
 ( ΣW, C) with ki ̸= kj
for i ̸= j. First, let x ∈W. We put Γ = Σ × {1, . . . , n} and consider ( Γ V, C)-
dags D = (V, {◁l}l∈C, (λ, σ, ρ)) with λ : V →Σ, σ : V →{1, . . . , n}, and ρ :

Weighted Distributed Systems and Their Logics
65
V →{0, 1}V. Let L ⊆
 ( Γ V, C) such that, for any D ∈L, any v ∈V , and any
i ∈{1, . . ., n}, we have (σ(v) = i) ⇐⇒(V, {◁l}l∈C, (λ, ρ[x/v])) ∈Li. Note that
ρ[x/v] : V →{0, 1}W.
Since the Li are FO-deﬁnable, one can build an FO-formula ϕ deﬁning L (we omit
the details). As ϕ is an FO-formula, the language L = L(ϕ) is recognizable by an
unambiguous ACAT 
A = (Q, Δ, T, F) by Theorem 4.1. Let t = (q, (a, σt, ρt), q) ∈
Trans(
 Γ V,C)(Q) with a ∈Σ, σt ∈{1, . . ., n}, and ρt ∈{0, 1}V. We transform 
A =
(Q, Δ, T, F) into a wACAT A = (Q, μ, T, γ) by adding weights as follows: set μ(t)
to be ki if t ∈Δ and σt = i. Otherwise, μ(t) =
. Moreover, γ(q1, . . . , q|Ag|) =
 if
(q1, . . . , q|Ag|) ∈F, and γ(q1, . . . , q|Ag|) =
 otherwise. Since 
A is unambiguous and
recognizes L, the weight of an extended dag D ∈L in A is 	
1≤i≤n k|σ−1(i)|
i
and for
D /∈L we have (∥A∥, D) =
. Now we consider the projection h :
 ( Γ V, C) →
 ( ΣV, C) mapping D = (V, {◁l}l∈C, (λ, σ, ρ)) to D = (V, {◁l}l∈C, (λ, ρ)). Note
that for D ∈
 ( ΣV, C) there is a unique D ∈L with h( D) = D. Hence, we have

h(∥A∥), D

=

 D∈h−1(D)∩
 L

∥A∥, D

=

∥A∥, D

=

1≤i≤n
k|σ−1(i)|
i
=

v∈V

[[ ϕ ]], (D, ρ[x/v])

=

[[ ∀x.ϕ ]], D

.
By Proposition 3.2, [[ ∀x.ϕ ]] is recognizable. The case x /∈W is derived easily.
□
By Propositions 5.1 and 5.2, we have immediately:
Theorem 5.1. Let
 be a commutative semiring and let S ∈
⟨⟨ ( Σ, C)⟩⟩. If S is
wRMSO-deﬁnable, then S is also recognizable.
6
Recognizable Series Are Deﬁnable
For S ∈
⟨⟨ ( Σ, C)⟩⟩, let Supp(S) = {D ∈
 ( Σ, C) | (S, D) ̸=
}. We adopt
the notion of an unambiguous FO(, ( Σ, C))-formula [7]:
– All atomic formulas apart from k and their negations are unambiguous.
– If ϕ and ψ are unambiguous, then so are ϕ ∧ψ, ∀x.ϕ, and ∀X.ϕ.
– If ϕ and ψ are unambiguous and Supp(ϕ) ∩Supp(ψ) = Ø, then ϕ ∨ψ is
unambiguous.
– If, ﬁnally, ϕ is unambiguous and, for any (D, ρ) with ρ : V →{0, 1}Free(ϕ), there
is at most one vertex u of D such that ϕFree(ϕ)∪{x}(D, ρ[x/u]) ̸=
, then ∃x.ϕ
is unambiguous.
Observe that, though, syntactically, we deal with ordinary MSO formulas, an unam-
biguous formula is primarily a weighted formula, as unambiguousness is deﬁned in
terms of its series. Let ϕ ∈FO(, ( Σ, C)). If ϕ is unambiguous, then ϕ is an FO-
deﬁnable step function. We know from [7] that certain simple formulas can be made
unambiguous:

66
B. Bollig and I. Meinecke
Proposition 6.1 ([7]). Let ϕ ∈FO(, ( Σ, C)) be a (positive) Boolean combination
of atomic formulas apart from k and their negations. Then, there is an unambiguous
formula ϕ+ ∈FO(, ( Σ, C)) such that ϕ+ = ϕ.
Proof. We proceed by induction and simultaneously deﬁne formulas ϕ+ and ϕ−. If
ϕ ∈FO(, (Σ, C)) is atomic or the negation of an atomic formula, we set ϕ+ = ϕ and
ϕ−= ¬ϕ (where ¬¬ψ is reduced to ψ). Moreover, we let
– (ϕ ∨ψ)+ = ϕ+ ∨(ϕ−∧ψ+),
– (ϕ ∨ψ)−= ϕ−∧ψ−,
– (ϕ ∧ψ)−= ϕ−∨(ϕ+ ∧ψ−), and
– (ϕ ∧ψ)+ = ϕ+ ∧ψ+.
□
In the context of words and an (E)MSO logic that employs the predicate ≤instead of the
direct successor relation, Droste and Gastin need to transform an ordinary MSO formula
ϕ into an unambiguous weighted MSO formula ϕ′ such that ϕ′ is the characteristic
series of the language of ϕ [7]. To this aim, they identify the unique least position
of a word (wrt. ≤) that satisﬁes a given property. In our logic, such an identiﬁcation
is no longer feasible. Nevertheless, we can transform any wACAT into an equivalent
weighted formula.
Theorem 6.1. Let A be a wACAT over commutative
 and ( Σ, C). There is a sentence
ψ from wREMSO(, ( Σ, C)) such that ψ = ∥A∥.
Proof. Let A = (Q, μ, T, γ) be a wACAT over
 and ( Σ, C). In the following, t and t′
will range over Trans(
 Σ,C)(Q). Set X to be a collection (Xt) of second-order variables
and suppose Ag = {1, . . . , N} for some N ∈IN. The construction of a wREMSO
sentence from A follows the route of transforming a ﬁnite automaton into a formula
where an interpretation of second-order variables reﬂects an assignment of vertices to
transitions. We ﬁrst provide some building blocks of the desired wREMSO formula.
The unambiguous formula
Partition(X) := ∀x.

t
(x ∈Xt ∧

t′̸=t
¬(x ∈Xt′))
claims that X actually represents a run, i.e., an assignment of vertices to transitions.
Given a ∈Σ and q ∈Q, ϕ+
(a,q)(x) (ϕ−
(a,q)(x)) shall denote the disjunction (conjunc-
tion) of formulas x ∈Xt (¬(x ∈Xt)) such that t = (q, a, q) for some q, respectively.
Now let t = {((a1, q1), ℓ1), . . . , ((am, qm), ℓm)} −→(a, q). To ensure that x is
contained in Xt only if the transition taken at x corresponds to t, we use
Transt(x, X) :=
x ∈Xt ∧λ(x) = a ∧

k∈{1,...,m}
∃y.

y ◁ℓk x ∧ϕ+
(ak,qk)(y)
+
∧∀y.
 
ℓ∈C
¬(y ◁ℓx) ∨

k∈{1,...,m}

y ◁ℓk x ∧λ(y) = ak
+
.

Weighted Distributed Systems and Their Logics
67
Another difﬁculty is to determine the weight of a global ﬁnal state q with respect
to an extended dag. We would like to identify, for any agent i ∈Ag with q[i] ̸= ı,
the Σi-maximal node. For this purpose, we demand the unique upwards-closed set of
nodes Y that contains a single minimal element x such that x is the only node executed
by agent i. Then, x is Σi-maximal and shall be contained in Xt for some transition
t = q −→(a, q[i]). Therefore, we deﬁne maxi(x, Y )
maxi(x, Y ) :=
 
a∈Σi
λ(x) = a
+
∧x ∈Y
∧∀y.∀z.

¬(y ∈Y ) ∨¬(y ◁z) ∨z ∈Y
+
∧∀y.

¬(y ∈Y ) ∨

a∈Σi
¬(λ(y) = a) ∨y = x
+
∧∀y.(¬ϕ1 ∨(ϕ1 ∧ϕ2) ∨(ϕ1 ∧¬ϕ2 ∧ϕ3))
where ϕ1 = (y ∈Y ), ϕ2 = (y = x), and ϕ3 = ∃z.(z ∈Y ∧[
(a,ℓ)∈Σ×C (z ◁ℓy ∧
λ(z) = a)]+). Hereby, the last conjunct ensures unambiguity of maxi(x, Y ) by requir-
ing that x is the only minimal event in Y .
To collect the weights of global ﬁnal states, we require, for any q ∈(Q ·∪{ı})Ag, a
formula Finalq(X, Y1, . . . , YN) :=

i∈Ag
q[i]∈Q
∃x.

maxi(x, Yi) ∧
 
a∈Σ
ϕ+
(a,q[i])(x)
+
∧

i∈Ag
q[i]=ı
∀x.

a∈Σi
¬(λ(x) = a) .
To simulate the type function T , we make use of the unambiguous formula Type(X) :=
∀x.

(a,q)∈Σ×Q

ϕ−
(a,q)(x) ∨

[ϕ+
(a,q)(x)]+ ∧

(b,ℓ)∈T (a,q)
∃y.(x ◁ℓy ∧λ(y) = b)
+
.
We are now prepared to specify the desired formula ψ. Namely, setting
ψ′(X) =∃Y1 . . . ∃YN.
Partition(X) ∧

t
∀x.(¬(x ∈Xt) ∨Transt(x, X))
∧

i∈Ag

∃x.maxi(x, Yi)

∨∀x.

¬(x ∈Yi) ∧

a∈Σi
¬(λ(x) = a)

∧

t
∀x.(¬(x ∈Xt) ∨((x ∈Xt) ∧μ(t)))
∧Type(X) ∧

q∈F

Finalq(X, Y1, . . . , YN) ∧γ(q)

,
we ﬁnally let ψ = ∃X.ψ′ ∈wREMSO(, ( Σ, C)). Observe that the subformula
¬(x ∈Xt) ∨((x ∈Xt) ∧μ(t)) of ψ is an FO-deﬁnable step function.
In fact, for any D = (V, {◁ℓ}ℓ∈C, λ) ∈
 ( Σ, C), we have ψ(D) = (∥A∥, D).
Thus, we obtain ψ = ∥A∥.
□

68
B. Bollig and I. Meinecke
References
1. C. Baier and M. Gr¨oßer. Recognizing omega-regular languages with probabilistic automata.
In Proceedings of LICS 2005. IEEE Computer Society Press, 2005.
2. B. Bollig. On the expressiveness of asynchronous cellular automata. In Proceedings of FCT
2005, volume 3623 of Lecture Notes in Comp. Sc., pages 528–539. Springer, 2005.
3. J. B¨uchi. Weak second order arithmetic and ﬁnite automata. Z. Math. Logik, Grundlag.
Math., 5:66–62, 1960.
4. K. Culik and J. Kari. Image compression using weighted ﬁnite automata. Computer and
Graphics, 17(3):305–313, 1993.
5. V. Diekert and G. Rozenberg, editors. The Book of Traces. World Scientiﬁc, Singapore,
1995.
6. M. Droste and P. Gastin. The Kleene-Sch¨utzenberger theorem for formal power series in
partially commuting variables. Inform. and Comp., 153:47–80, 1999.
7. M. Droste and P. Gastin. Weighted automata and weighted logics. In Proceedings of ICALP
2005, volume 3580 of Lecture Notes in Comp. Sc., pages 513–525. Springer, 2005.
8. M. Droste, P. Gastin, and D. Kuske. Asynchronous cellular automata for pomsets. Theoret.
Comp. Sc., 247(1-2):1–38, 2000.
9. M. Droste and G. Rahonis. Weighted automata and weighted logics on inﬁnite words. In
10th Int. Conf. on Developments in Language Theory (DLT), volume 4036 of Lecture Notes
in Comp. Sc., pages 49–58. Springer, 2006.
10. M. Droste and H. Vogler. Weighted tree automata and weighted logics. Theoret. Comp. Sc.,
366:228–247, 2006.
11. C. C. Elgot. Decision problems of ﬁnite automata design and related arithmetics. Trans.
Amer. Math. Soc., 98:21–52, 1961.
12. S. Jesi, G. Pighizzini, and N. Sabadini. Probabilistic asynchronous automata. Mathematical
Systems Theory, 29(1):5–31, 1996.
13. W. Kuich. Semirings and Formal Power Series. In G. Rozenberg and A. Salomaa, editors,
Handbook of Formal Languages, volume 1, chapter 9, pages 609–677. Springer, 1997.
14. D. Kuske. Emptiness is decidable for asynchronous cellular machines. In Proceedings of
CONCUR 2000, volume 1877 of Lecture Notes in Comp. Sc., pages 536–551. Springer, 2000.
15. D. Kuske. Weighted asynchronous cellular automata. In Proceedings of STACS 2006, volume
3884 of Lecture Notes in Comp. Sc., pages 685–696. Springer, 2006.
16. I. M¨aurer. Weighted picture automata and weighted logics. In Proceedings of STACS 2006,
volume 3884 of Lecture Notes in Comp. Sc., pages 313–324. Springer, 2006.
17. I. Meinecke.
Weighted logics for traces. In Proceedings of CSR 2006, volume 3967 of
Lecture Notes in Comp. Sc., pages 235–246. Springer, 2006.
18. M. Mohri. Finite-state transducers in language and speech processing. Computational Lin-
guistics, 23(2):269–311, 1997.
19. E. Ochma´nski. Regular behaviour of concurrent systems. Bulletin of the EATCS, 27:56–67,
1985.
20. Ph. Schnoebelen.
The veriﬁcation of probabilistic lossy channel systems.
In Valid. of
Stochastic Systems, volume 2925 of Lecture Notes in Comp. Sc., pages 445–465. Springer,
2004.
21. M.P. Sch¨utzenberger. On the deﬁnition of a family of automata. Information and Control,
4:245–270, 1961.
22. W. Zielonka. Notes on ﬁnite asynchronous automata. R.A.I.R.O. — Informatique Th´eorique
et Applications, 21, 1987.

Weighted O-Minimal Hybrid Systems Are More
Decidable Than Weighted Timed Automata!⋆
Patricia Bouyer, Thomas Brihaye, and Fabrice Chevalier
LSV - CNRS & ENS de Cachan
61, avenue du Pr´esident Wilson, 94230 Cachan, France
{bouyer,brihaye,chevalie}@lsv.ens-cachan.fr
Abstract. We consider weighted o-minimal hybrid systems, which ex-
tend classical o-minimal hybrid systems with cost functions. These cost
functions are “observer variables” which increase while the system evolves
but do not constrain the behaviour of the system. In this paper, we prove
two main results: (i) optimal o-minimal hybrid games are decidable; (ii)
the model-checking of WCTL, an extension of CTL which can constrain the
cost variables, is decidable over that model. This has to be compared with
the same problems in the framework of timed automata where both prob-
lems are undecidable in general, while they are decidable for the restricted
class of one-clock timed automata.
1
Introduction
O-minimal hybrid systems. Hybrid systems are ﬁnite-state machines where each
state is equipped with a continuous dynamics. In the last thirty years, for-
mal veriﬁcation of such systems has become a very active ﬁeld of research in
computer science. In this context, hybrid automata, an extension of timed au-
tomata [AD94], have been intensively studied [Hen95, Hen96], and decidable
subclasses of hybrid systems have been identiﬁed like initialized rectangular hy-
brid automata [Hen96] or o-minimal hybrid automata. This latter model has
been pointed out in [LPS00] as an interesting class of systems with very rich
continuous dynamics, but limited discrete steps (at each discrete step, all vari-
ables have to be reset, independently from their initial values). Behaviours of
such a system can be decoupled into continuous and discrete parts, properties
of a global o-minimal system can thus be deduced directly from properties of
the continuous parts of the system. This property and properties of o-minimal
structures (see [vdD98] for an overview) are exploited in the word encoding
techniques, which have been developed in [BMRT04] for (ﬁnitely) abstracting
behaviours of the system. Using techniques based on this abstraction, reachabil-
ity properties [BM05], reachability control properties [BBC06] have been proved
decidable for o-minimal hybrid systems. This technique was also used in order
to compute a (tight) exponential bound on the size of the coarsest ﬁnite bisim-
ulation of Pfaﬃan hybrid systems (see [KV06]).
⋆Work partly supported by ACI S´ecurit´e Informatique CORTOS.
S. Artemov and A. Nerode (Eds.): LFCS 2007, LNCS 4514, pp. 69–83, 2007.
c
⃝Springer-Verlag Berlin Heidelberg 2007

70
P. Bouyer, T. Brihaye, and F. Chevalier
Models for resource consumption. A research direction which has recently re-
ceived substantial attention is the twist or extension of (decidable) models for
representing more fairly interesting properties of embedded systems, for instance
resource consumption. In that context, timed automata [AD94] have been ex-
tended with cost information bringing the model of weighted (or priced) timed
automata [ALP01, BFH+01]. A timed automaton is a ﬁnite automaton with
clock variables (i.e. variables which increase as global time) that can be tested
towards constants or reset. In the model of weighted timed automata, an extra
cost variable is added, which is used as an observer variable (it does not con-
strain the behaviour of the system), evolving linearly while time elapses, and
subject to discrete jumps when discrete transitions are taken. This model was
appealing for expressing quantitative properties of real-time systems, which was
concretized by the decidability of the optimal reachability problem (ﬁnd the best
way — in terms of cost — of reaching a given state) [ALP01, BFH+01, BBBR06]
together with the development of the tool Uppaal Cora [cor06], and then by the
computability of the optimal mean-cost (ﬁnd the best way for the system to have
a “cost per time unit” as low as possible) [BBL04]. However, more involved prop-
erties like cost-optimal reachability control (ﬁnd the minimum cost that can be
ensured for reaching a given state, whatever does the environment in which the
system is embedded) or WCTL model-checking (WCTL extends the branching-
time temporal logic CTL with cost constraints on modalities [BBR04, BBR06])
have been proved undecidable for weighted timed automata with three clocks or
more, see [BBR04, BBR05, BBM06]. Though both problems have recently been
proved decidable for one-clock weighted timed automata [BLMR06, BLM07]
these undecidability results are nevertheless disappointing, because the one-clock
assumption is rather restrictive.
Our contributions. In this paper, we propose a natural extension of o-minimal
hybrid systems with (deﬁnable) positive cost functions which increase while time
progresses and which can be used in an optimization criterion, as in the case of
weighted timed automata. It is worth noticing here that though the underly-
ing system is o-minimal, this extended model, called weighted o-minimal hybrid
automaton, is not o-minimal as we do not require that the cost is reset when a
discrete transition is taken. However, we prove in this paper that the cost-optimal
reachability control problem and the WCTL model-checking problem are both
decidable for this class of systems. Because of the existing results on weighted
timed automata, this is really a surprise, and makes o-minimal hybrid systems
an analyzable, though powerful model. The decidability results of course partly
rely on the word encoding techniques that we mentioned earlier, but also require
reﬁnements and involved techniques, speciﬁc to each of the two problems.
2
General Background
Let M be a structure. In this paper when we say that some relation, subset
or function is deﬁnable, we mean it is ﬁrst-order deﬁnable in the sense of the

Weighted O-Minimal Hybrid Systems
71
structure M. A general reference for ﬁrst-order logic is [Hod97]. We denote by
Th(M) the theory of M. In the sequel we only consider structures M that
are expansions of ordered groups containing two constant symbols, i.e. M =
⟨M, +, 0, 1, <, . . .⟩.
2.1
O-Minimality
Let us recall the deﬁnition of o-minimal structures [PS86] and give some ex-
amples of such structures. The reader interested in o-minimality should refer
to [vdD98] for further results and an extensive bibliography on this subject. In
the sequel of the paper we focus on o-minimal structures with a decidable theory
in order to obtain decidability and computability results.
Deﬁnition 1. A totally ordered structure M = ⟨M, <, . . .⟩is o-minimal if every
deﬁnable subset of M is a ﬁnite union of points and open intervals (possibly
unbounded).
Example 1. Examples of o-minimal structures are the ordered group of rationals
⟨Q, <, +, 0, 1⟩, the ordered ﬁeld of reals ⟨R, <, +, ·, 0, 1⟩, the ﬁeld of reals with
restricted pfaﬃan functions and the exponential function [Wil96].
2.2
O-Minimal Dynamical Systems
In this subsection we deﬁne the notion of o-minimal dynamical systems.
Deﬁnition 2 (O-minimal dynamical system). An o-minimal dynamical
system is a pair (M, γ) where:
– M = ⟨M, +, 0, 1, <, . . .⟩is an o-minimal expansion of an ordered group,
– γ : V1 × V →V2 is a function deﬁnable in M (where V1 ⊆M k1, V ⊆M,
and V2 ⊆M k2).1 The function γ is called the dynamics of the system.
Classically, when M is the set of the real numbers, we see V as the time, V1 × V
as the space-time, V2 as the (output) space and V1 as the input space. We keep
this terminology in the more general context of a structure M.
Example 2. We can view the continuous dynamics of timed automata [AD94] as
an o-minimal dynamical system. In this case, we have that M = ⟨R, <, +, 0, 1⟩
and the dynamics γ : (R+)n × R+ →(R+)n is deﬁned by γ(x1, ..., xn, t) =
(x1 + t, ..., xn + t).
We deﬁne a transition system associated with the dynamical system, this deﬁni-
tion is an adaptation to our context of the classical continuous transition system
in the case of hybrid systems (see [LPS00] for example).
Deﬁnition 3. Given (M, γ) a dynamical system, we deﬁne a transition system
Tγ = (Q, Σ, →γ) associated with (M, γ) by: the set Q of states is V2; the set Σ of
1 We use these notations in the rest of the paper.

72
P. Bouyer, T. Brihaye, and F. Chevalier
events is M + = {m ∈M | m ≥0}; the transition relation y1
τ−→γ y2 is deﬁned by:
∃x ∈V1, ∃t1, t2, ∈V s.t. t1 ≤t2, γ(x, t1) = y1, γ(x, t2) = y2 and τ = t2 −t1.
2.3
O-Minimal Hybrid Systems and Games
In this subsection, we deﬁne o-minimal hybrid systems and games
Deﬁnition 4 (O-minimal hybrid systems). Let M = (M, +, 0, 1, <, · · ·)
be an o-minimal structure. An M-hybrid system (or simply o-minimal hybrid
system) H is a tuple (Q, Σ, δ, γ) where Q is a ﬁnite set of locations, Σ is a
ﬁnite set of actions, δ consists in a ﬁnite number of transitions (q, g, a, R, q′) ∈
Q × 2V2 × Σ × 2V2 × Q where the guard g and the reset R are deﬁnable in M,
and γ maps every location q ∈Q to a dynamic γq : V1 × V →V2 deﬁnable
in M.
An M-hybrid system H = (Q, Σ, δ, γ) deﬁnes a mixed transition system TH =
(S, Γ, →) where:
– the set S of states is Q × V2;
– the set Γ of labels is M + ∪Σ;
– the transition relation (q, y)
e−→(q′, y′) is deﬁned when:
• e ∈Σ and there exists (q, g, e, R, q′) ∈δ with y ∈g and y′ ∈R(y), or
• e ∈M +, q = q′, and y
e−→γq y′ where γq is the dynamic in location q.
We will also need more precise notions of transitions. When (q, y)
τ−→(q, y′)
with τ ∈M +, this is due to some choice of (x, t) ∈V1 ×V such that γq(x, t) = y.
We say that (q, x, t, y)
τ−→(q′, x′, t′, y′) if q = q′, x = x′, t′ = t + τ, γq(x, t) = y
and γ′
q(x′, t′) = y′. We say that an action (τ, a) ∈M + × Σ is enabled in a state
(q, x, t, y) if there exists (q′, x′, t′, y′) and (q′′, x′′, t′′, y′′) such that (q, x, t, y)
τ−→
(q′, x′, t′, y′)
a−→(q′′, x′′, t′′, y′′). We then write (q, x, t, y)
τ,a
−−→(q′′, x′′, t′′, y′′). We
note Enb(q, x, t, y) the set of actions enabled in (q, x, t, y).
A run of H is a(n) (in)ﬁnite sequence ϱ = (q0, x0, t0, y0)
τ1,a1
−−−→(q1, x1, t1, y1) · · ·
A position π along ϱ is a pair (i, τ) ∈N × M + such that τ ≤τi+1. We deﬁne
ϱ[(i, τ)] = (qi, γqi(xi, ti + τ)). Let us notice that the positions of a given run are
totally ordered in a natural way. If ϱ is ﬁnite we deﬁne last(ϱ) = (qn, xn, tn, yn).
We note Runsf(H) the set of ﬁnite runs in H.
An interesting tool to study hybrid systems is the (time-abstract) bisimula-
tion2 (see [Hen95]). One of the main results concerning o-minimal hybrid systems
is that they admit ﬁnite bisimulation quotient. This result has been ﬁrst proved
in [LPS00], it was reproved in [Dav99] in a more topological way, amongst a lot
of other interesting results. In [Bri06a], the existence of ﬁnite bisimulations for
o-minimal hybrid systems is proved by means of the suﬃx partition, a technique
initiated in [BMRT04, BM05, Bri06b].
2 Two systems are time-abstract bisimilar whenever they can both do the same actions
and wait some delay.

Weighted O-Minimal Hybrid Systems
73
Theorem 5. ([Bri06a, Theorem 12.6.14])
Let H be an o-minimal hybrid system and PH be a ﬁnite and deﬁnable partition
of Q×V2 respecting the guards and the resets of H. There is a ﬁnite and deﬁnable
partition, noted Suf (PH), inducing a bisimulation on H.
O-minimal hybrid systems are models for closed systems, where all transitions
are controlled. If we want to consider open systems where we distinguish between
the actions of a controller and of an environment, we need to consider games on
o-minimal hybrid systems. We are now going to deﬁne this notion.
Deﬁnition 6 (O-minimal game). Let M=(M, +, 0, 1, <, · · ·) be an o-minimal
structure. An M-game (or simply an o-minimal game) is a tuple (Q, Goal, Σ, δ, γ)
where Goal ⊆Q is a subset of winning locations, (Q, Σ, δ, γ) is an M-hybrid system
and Σ is partitioned into two subsets Σc and Σu corresponding to controllable and
uncontrollable actions.
Let H be an o-minimal game. The game is played by two players, the controller
and the environment; the goal of the controller is to reach a winning state what-
ever the environment does. In every state s, the controller picks a delay τ and
an action a ∈Σc such that there is a transition s
τ,a
−−→s′. The environment has
two choices:
– either it waits τ and executes a transition s
τ,a
−−→s′ proposed by the controller,
– or it waits τ′, 0 ≤τ′ ≤τ, and executes a transition s
τ ′,u
−−→s′′ with u ∈Σu.
The game then evolves to a new state (according to the choice of the environ-
ment) and the two players proceed to play as before.
We will now formalize the semantic through the concept of strategy.
Deﬁnition 7 (Strategy). A (controller) strategy3 is a partial function λ from
Runsf(H) to M + × Σc such that for all runs ϱ in Runsf(H), if λ(ϱ) is deﬁned,
then λ(ϱ) is enabled in last(ϱ).
Intuitively, the strategy tells what needs to be done for controlling the system:
at each instant it tells how much time we need to wait and which controllable
action needs to be done after this delay. Note that even when the environment
follows the controller’s choice, it has to choose between several edges, each one
labeled by the action given by the strategy (because the original game is not
supposed to be deterministic).
Let ϱ = (q0, x0, t′
0, y0)
τ1,a1
−−−→. . . be a run, and set for every i, ϱi the preﬁx of ϱ
ending at position (i, 0). The run ϱ is said to be consistent with a strategy λ when
for all i, if λ(ϱi) = (τ, a) then either τi+1 = τ and ai+1 = a, or τi+1 ≤τ and
ai+1 ∈Σu. We denote by Outcome(s, λ) the set of runs starting from a state s of
the (output) space consistent with the strategy λ. A run ϱ = (q0, x0, t0, y0)
τ1,a1
−−−→
. . .
τp,ap
−−−→(qp, xp, tp, yp) is said winning if qi ∈Goal for some i. A run ϱ is said
maximal with respect to a strategy λ if it is inﬁnite or if λ(ϱ) is not deﬁned. A
strategy λ is winning from a state (q, y) if for all (x, t) such that γ(x, t) = y, all
maximal runs starting in (q, x, t, y) compatible with λ are winning.
3 In the context of control problems, a strategy is also called a controller.

74
P. Bouyer, T. Brihaye, and F. Chevalier
3
Weighted O-Minimal Hybrid Systems and Games
In this section, we deﬁne the weighted o-minimal hybrid systems and games,
which extend the two models of the previous section with cost functions. These
cost functions give a quantitative information on the behaviours of the sys-
tems, which allows to give a measure of the performance of the system. These
models are respectively inspired by the model of weighted (resp. priced) timed
automata [ALP01, BFH+01] and the model of weighted (resp. priced) timed
games [ABM04, BCFL04].
3.1
Deﬁnitions
We consider cost functions which are non-negative and time-non-decreasing.
Note that cost functions in weighted timed automata [ALP01, BFH+01] satisfy
these hypotheses.
A non-negative and time-non-decreasing cost function is a deﬁnable function
Cost : Q × V1 × V × M + →M + such that for all q ∈Q, x ∈V1, t ∈V and
τ1, τ2 ∈M + with τ1 ≤τ2 we have that Cost(q, x, t, τ1) ≤Cost(q, x, t, τ2).
Deﬁnition 8 (Weighted o-minimal hybrid system and game). An M-
weighted hybrid system (resp. game) is an M-hybrid system (resp. game) H =
(Q, Σ, δ, γ) with a deﬁnable non-negative and time-non-decreasing cost function
Cost.
The semantics of an o-minimal weighted hybrid system (resp. game) is the
one of the underlying o-minimal hybrid system (resp. game). Hence, the cost
function does not aﬀect the behaviours of the system; it gives for every single
step of the system a non-negative value, which represents the cost of evolv-
ing following that step. It naturally extends to a run in the system: let ϱ =
(q0, x0, t0, y0)
τ1,a1
−−−→. . .
τp,ap
−−−→(qp, xp, tp, yp) be a ﬁnite run in H. The cost of ϱ
is Cost(ϱ) = p
i=1 Cost(qi−1, xi−1, ti−1, τi).
Let us give an example of weighted o-minimal hybrid system.
Example 3 ([BLM07]). The weighted o-minimal hybrid system of Figure 1 mod-
els a never-ending process of repairing problems. The repair of a problem has
a certain cost, captured in the model by the cost function Cost. As soon as a
problem occurs (modeled by the pb transition) the value of the cost grows with
rate 1, until actual repair is taking place by one of the transitions rp1 (cheap
but long repair) or rp2 (expensive but quick repair). At most 24 time units after
the occurrence of a problem it will have been repaired one way or another.
3.2
Related Problems and Results
In this subsection we deﬁne the two problems we are interested in: the cost-
optimal control problem and the WCTL model-checking problem.

Weighted O-Minimal Hybrid Systems
75
q0
γq0(x, t) = x + t
Cost(q0, x, t, τ) = 0
q1
γq1(x, t) = x + t
Cost(q1, x, t, τ) = τ
q2
γq2(x, t) = x + t
Cost(q2, x, t, τ) = 2 · τ
q3
γq3(x, t) = x + t
Cost(q3, x, t, τ) = 5 · τ
y ≥5 ; pb
y := 0
y ≥4 ; rp1
y := 0
y ≥2 ; rp2
y := 0
y = 20 ; OK1
y := 0
y = 10 ; OK2
y := 0
Fig. 1. A repair problem example
The Cost-Optimal Control Problem. The cost-optimal reachability control
problem was ﬁrst considered on weighted timed automata in [ABM04, BCFL04].
However it has been shown in [BBR05, BBM06] that the cost-optimal reacha-
bility control problem for weighted timed automata is undecidable.
In our context of weighted o-minimal games, the cost-optimal control problem
asks what is the optimal cost for the controller to reach Goal whatever the
environement does. In order to take the cost function into account, we now need
to deﬁne the cost of a strategy from a state and the optimal cost from a state.
Deﬁnition 9 (Cost of a strategy from a state). Let (H, Cost) be a weighted
o-minimal game, Goal be a subset of winning locations, s be a state of the (output)
space V2 and λ be a strategy. The cost Cost(s, λ) of λ from s is deﬁned by:
Cost(s, λ) = sup

Cost(ϱ) | ϱ ∈Outcome(s, λ)

.
Intuitively the presence of the supremum is explained by the fact that the envi-
ronment tries to maximize the cost.
Deﬁnition 10 (Optimal cost from a state). Let (H, Cost) be a weighted
o-minimal game, Goal be a subset of winning locations and s be a state of the
(output) space V2. The optimal cost OptCost(q) associated with s is deﬁned by:
OptCost(s) = inf

Cost(s, λ) | λ is a winning strategy

.
A winning strategy from s is called optimal whenever Cost(s, λ) = OptCost(s).
Problem 1 (Cost-optimal control problem). Given a weighted o-minimal game
H, a deﬁnable state s and a deﬁnable constant c, decide if there exists a winning
strategy λ from q such that Cost(s, λ) ≤c.
Problem 2 (Computation of the optimal cost). Given a weighted o-minimal game
H and a deﬁnable state s, compute the optimal cost OptCost(s).

76
P. Bouyer, T. Brihaye, and F. Chevalier
Remark 1. There is an optimal winning strategy from state s iﬀthe inﬁmum can
be replaced by a minimum in the deﬁnition of OptCost(s). If we solve problem 1
and 2, we can also determine if there is an optimal winning strategy by asking
if there is a strategy λ with Cost(s, λ) ≤OptCost(s). In [BBR05, BBM06], it
has been shown that the variant of Problem 1 for weighted timed automata is
undecidable.
The WCTL Model-Checking Problem. The logic WCTL 4 has been proposed
in the context of (weighted) timed systems as an extension of CTL with cost
constraints on modalities [BBR04, BBM06, BLM07]. In our context, we deﬁne
for every structure M the logic WCTLM over Σ inductively as follows:
WCTLM ∋ϕ ::= a | ϕ ∨ϕ | ¬ϕ | E ϕU∼cϕ | A ϕU∼cϕ
where a ∈Σ, ∼∈{<, ≤, =, ≥, >} and c is an M-deﬁnable constant.
Let (H, Cost) be an M-hybrid system. The semantics of WCTLM is deﬁned
for every state (q, y) ∈Q × V2 of (H, Cost) as follows:
(q, y) |= a ⇔(q, y)
a−→(q′, y′) for some (q′, y′) ∈Q × V2 5
(q, y) |= ¬ϕ ⇔(q, y) ̸|= ϕ
(q, y) |= ϕ1 ∨ϕ2 ⇔(q, y) |= ϕ1 or (q, y) |= ϕ2
(q, y) |= E ϕ1U∼cϕ2 ⇔there is an inﬁnite run ϱ in H from (q, y)
s.t. ϱ |= ϕ1U∼cϕ2
(q, y) |= A ϕ1U∼cϕ2 ⇔every inﬁnite run ϱ in H from (q, y)
satisﬁes ϱ |= ϕ1U∼cϕ2
ϱ |= ϕ1U∼cϕ2 ⇔there exists π ≥0 position along ϱ s.t.
ϱ[π] |= ϕ2, for all positions 0 ≤π′ < π on ϱ,
ϱ[π′] |= ϕ1 ∨ϕ2, and Cost(ϱ≤π) ∼c6
We use true for a ∨¬a, and classical “eventually” and “always” operators:
E F∼cφ (resp. A F∼cφ) stands for E trueU∼cφ (resp. A trueU∼cφ) and A G∼cφ
(resp. E G∼cφ) stands for ¬E F∼c¬φ (resp. ¬A F∼c¬φ).
Let us give an example of WCTL formulae on the repair problem of Example 3.
Example 4. [BLM07] An example of a property that can be expressed with
WCTL is “Whenever a problem occurs it can be repaired within a total cost of 55”.
It can be expressed with the following formula:
A G

pb =⇒E F≤55(OK1 ∨OK2)

.
One can easily check that this formula holds for every state of the weighted
o-minimal hybrid system of Figure 1.
Problem 3 (Model-checking of WCTL). Given (H, Cost) an M-weighted hybrid
system, ϕ a WCTLM-formula and (q, y) ∈Q × V2 a deﬁnable state of H, decide
whether (q, y) |= ϕ.
4 WCTL stands for “Weighted CTL.”
5 This can be viewed equivalently as atomic propositions.
6 Following [Ras99] we use ϕ1 ∨ϕ2 to handle open intervals in timed models.

Weighted O-Minimal Hybrid Systems
77
Remark 2. Note that classical results on o-minimal hybrid systems cannot be
used to solve the two problems presented above (for instance, weighted o-minimal
hybrid systems do not have a ﬁnite bisimulation), and hence, ad-hoc proofs have
to be developed.
4
Solving the Cost-Optimal Control Problem
In this section we prove the decidability of Problem 1.
Deﬁnition 11. Let (H, Cost) be a weighted o-minimal game. We say that a
run (q0, x0, t0, y0)
τ1,a1
−−−→. . . crosses the transition e = (q, g, a, R, q′) at step i if
q = qi−1, q′ = qi, a = ai, γqi−1(xi−1, ti−1 + τi) ∈g and yi ∈R.
We are now going to prove a key proposition: we can restrict to winning strategies
that cross each edge at most once. In order to prove this proposition we use the
fact that the cost functions have non-negative values.
Proposition 12. Let H be a weighted o-minimal game and (q, y) a state of
H. If there exists a winning strategy λ from (q, y) then there exists a winning
strategy λnew with Cost((q, y), λnew) ≤Cost((q, y), λ) such that every run starting
in (q, y) compatible with λnew crosses each transition at most once.
Proof (Sketch). The idea of the proof is the following: for each transition e, we
iteratively ensure that there is a winning strategy (of cost c′ ≤c) crossing e at
most once. See Outcome((q, y), λ) as a(n inﬁnitely branching) tree: every path in
this tree is ﬁnite and reaches Goal, but it may cross e several times. We construct
a new strategy λnew which short-cuts λ in the following sense: it simulates λ until
e is crossed for the ﬁrst time and then switches to a descendant in the tree from
which all paths do not cross e anymore (this is possible as λ is winning). Such a
strategy crosses e at most once, its cost is smaller than that of λ as its compatible
runs are “shorter” than ones of λ and the cost function is non-negative.
□
We now give a backward algorithm which computes the optimal cost, based on
the formulation of the problem given in [LMM02, ABM04]. The termination of
the algorithm relies on Proposition 12. For this, given (q, y) ∈Q × V2 and n ∈N
we deﬁne cn(q, y), the optimal cost of reaching Goal from (q, y) in at most n
steps. Formally we have that:
– c0(q, y)=0 if q ∈Goal, +∞if q /∈Goal.
– cn+1(q, y)=
sup
γq(x,t)=y
inf
(τ,a)∈Enb(q,x,t,y) max
Costτ,a
cn (q, x, t, y)
sup{Costτ ′,u
cn (q, x, t, y) | (τ ′,u)∈Enb(q,x,t,y),τ ′≤τ}
where (τ, e) ∈Enb(q, x, t, y) iﬀe ∈Enb(q, x, t + τ, γq(x, t + τ)), and Costτ,e
c
(q, x, t, y)=Cost(q, x, t, y, τ)+ sup{c(q′, y′)|(q, x, t, y)
τ,a
−−→(q′, x′, t′, y′)}.
Deﬁnition 13. A strategy λ is said n-bounded from (q, y) if every run compat-
ible with λ starting from (q, y) has length at most n.

78
P. Bouyer, T. Brihaye, and F. Chevalier
Lemma 14. For every ε > 0, for every (q, y) ∈Q×V2 s.t. cn(q, y) < +∞, there
exists a deﬁnable n-bounded strategy λ from (q, y) such that Cost((q, y), λ) ≤
cn(q, y) + ε.
Lemma 15. If λ is an n-bounded strategy from (q, y) then Cost((q, y), λ) ≥
cn(q, y).
Theorem 16. Let M = ⟨M, +, 0, 1, . . .⟩be an o-minimal structure such that
Th(M) is decidable. The cost-optimal control problem over M-weighted hybrid
systems is decidable.
Proof. Let H be a weighted o-minimal game and s a state of H. Lemmas 14 and
15 imply that ck(s) = inf

Cost(s, λ) | λ is a k-bounded strategy strategy

.
Let n be the number of transitions of H. Proposition 12 shows that for
every winning strategy from s there is an (n + 1)-bounded winning strategy
from s with smallest cost. Thus OptCost(s) = inf

Cost(s, λ)
|
λ is an (n +
1)-bounded strategy

= cn+1(s). Note that cn+1(s) is computable since Th(M)
is decidable.
We can moreover decide if the optimal cost can be achieved by a strategy: by
Proposition 12 it is suﬃcient to enumerate all (n + 1)-bounded strategies using
τi’s as parameters and check if the cost of one of them is equal to cn+1(s).
□
Remark 3. Let us notice that Theorem 16 encompasses the decidability of the
time-bounded reachability problem considered in [Gen05]. Moreover, a conse-
quence of Theorem 16 is the decidability of the (cost-)optimal reachability prob-
lem formulated in [ALP01, BFH+01] for weighted timed automata.
5
Solving the WCTL Model-Checking Problem
The aim of this section is to prove the following decidability theorem. The tech-
niques that we will develop for proving this result are partly inspired by the recent
decidability proof for WCTL over one-clock weighted timed automata [BLM07].
Theorem 17. Let M = ⟨M, +, 0, 1, <, . . .⟩be an o-minimal structure such that
M is Archimedian7 and Th(M) is decidable. The model-checking of WCTLM
over M-weighted hybrid systems is decidable.
If P and P′ are two partitions, we write P ⊓P′ for the joint partition,i.e. the
smallest partition that reﬁnes both P and P′. Let us notice that if P and P′ are
both ﬁnite and deﬁnable the joint partition P ⊓P′ is also ﬁnite and deﬁnable.
Let H = (Q, Goal, Σ, δ, γ) be an M-weighted hybrid system. On each location
q ∈Q, let us denote by Pq the partition induced by the guards and the resets
associated with location q. We denote by PH the partition of state space S
= Q × V2 induced by the Pq’s. PH is a ﬁnite deﬁnable partition of S.
7 A structure is Archimedian whenever for every pair (a, b) ∈M 2 such that a ̸= 0,
there exists some integer n such that n · a > b.

Weighted O-Minimal Hybrid Systems
79
Two states of the same piece P of PH agree on all atomic formulae a ∈Σ.
We will now inductively construct for every WCTLM-formula ϕ a reﬁned (ﬁnite
and deﬁnable) partition Pϕ of PH such that two states of a piece of Pϕ agree on
formula ϕ. We will proceed in three steps: from partitions for φ and ψ we will
successively construct a partition for E φUψ and A φUψ, then for E φU∼cψ and
ﬁnally for A φU∼cψ.
The ﬁrst step is achieved using the following lemma, which applies the con-
struction of a ﬁnite and deﬁnable partition (the so-called suﬃx-partition) cor-
rect w.r.t. bisimulation (see Theorem 5), and thus for CTL-formulae [AHLP00,
HMR05].
Lemma 18. Let Pφ (resp. Pψ) be a partition for φ (resp. ψ). The partition
Suf(Pφ⊓Pψ) is a time-abstract bisimulation and is a partition for formula E φUψ.
That is, if P is a piece of Suf(Pφ ⊓Pψ), then all states (q, y) with y ∈P either
satisfy E φUψ or do not satisfy this formula. The same holds for A φUψ.
The second step, the construction of a (ﬁnite and deﬁnable) partition respecting
E φU∼cψ, is more involved.
Let us denote by P the partition Suf(Pφ ⊓Pψ). Let q and q′ be two locations
of H. Let P and P ′ be two pieces of P. We give formulae which deﬁne the set
of possible costs of paths from a state (or a piece of P) to another one:
– θφ∨ψ
(q,P )→(q′,P ′)(c, y) expresses that it is possible to go from some (q, y) with
y ∈P to some (q′, y′) with y′ ∈P ′ by a continuous step followed by a
discrete action, with cost c, and always satisfying φ ∨ψ.
– θφ∨ψ
(q,P ⇝P ′)(c, y) expresses that it is possible to go from (q, y) with y ∈P to
some (q, y′) with y′ ∈P ′ by a continuous step (and no discrete action), with
cost c, and always satisfying φ ∨ψ.
From the two previous formulae, we deﬁne the following deﬁnable sets:
κφ∨ψ
(q,P )→(q′,P ′) = {c ∈M + | ∃y ∈P s.t. θφ∨ψ
(q,P )→(q′,P ′)(c, y)} ;
κφ∨ψ
(q,P ⇝P ′) = {c ∈M + | ∃y ∈P s.t. θφ∨ψ
(q,P ⇝P ′)(c, y)} ;
λφ∨ψ
(q,P )→(q′,P ′)(y) = {c ∈M + | θφ∨ψ
(q,P )→(q′,P ′)(c, y)} ;
λφ∨ψ
(q,P ⇝P ′)(y) = {c ∈M + | θφ∨ψ
(q,P ⇝P ′)(c, y)}.
We then construct a ﬁnite graph which abstracts away all dynamical parts
of H and which will be restricted to parts of H which satisfy formula E φUψ.
Each edge of this graph will be labeled with a weight (indeed a deﬁnable set)
which will represent the set of costs of all paths in H witnessing formula E φUψ.
More formally, we construct a (deﬁnable) weighted ﬁnite graph Gφ,ψ = (V, E) as
follows:
– its set of vertices V is
{(q, P), (q, P, init) | (q, P) |= φ ∨ψ}8
∪
{(q, P, ﬁnal) | (q, P) |= ψ}

80
P. Bouyer, T. Brihaye, and F. Chevalier
– its set of edges E is
{(q, P,init)
λφ∨ψ
(q,P )→(q′,P ′)(y)
−−−−−−−−−−−→(q′, P ′)} ∪{(q, P, init)
λφ∨ψ
(q,P ⇝P ′′)(y)
−−−−−−−−−→(q, P ′′, ﬁnal)}
∪
{(q, P, init)
[0]
−→(q, P, ﬁnal)} ∪{(q, P)
κφ∨ψ
(q,P )→(q′,P ′)
−−−−−−−−−→(q′, P ′)}
∪
{(q, P)
κφ∨ψ
(q,P )→(q′,P ′)
−−−−−−−−−→(q′, P ′, ﬁnal)} ∪{(q, P)
κφ∨ψ
(q,P ⇝P ′′)
−−−−−−−→(q, P ′′, ﬁnal)}
Let ϱ = (q0, P0, init)
λ(y)
−−−→(q1, P1)
κ1
−→. . .
κn
−−→(qn, Pn, ﬁnal) be a ﬁnite path of
Gφ,ψ. Then we deﬁne Kϱ(y) to be the set of all possible costs of the path ϱ:
Kϱ(y) = {λ(y) + c2 + · · · + cn | ci ∈κi}.
The following proposition shows that the graph Gφ,ψ can be used to model-
check the formula E φU∼cψ.
Proposition 19. Let q0 ∈Q, P0 ∈P and y0 ∈P0. Then, (q0, y0) |= E φU∼cψ
iﬀthere exists a path ϱ = (q0, P0, init)
λ(y)
−−−→(q1, P1)
κ1
−→. . .
κn
−−→(qn, Pn, ﬁnal) in
Gφ,ψ, there exists ζ ∈M such that ζ ∈Kϱ(y0) and ζ ∼c.
We prove that, under the Archimedian hypothesis, we can bound the length of
witnessing paths in the graph Gφ,ψ. This hypothesis has not been used yet, as
everything holds without it, but is required by the next proposition. For every
(m, c) ∈M 2 such that m ̸= 0, we note
 c
m
	
the smallest integer k such that
k · m > c.
Proposition 20. We assume that (q0, y0) |= E φU∼cψ, and we deﬁne N = 2 +
(|Q| · |P| + 1) ·
 c
m
	
+ 2

where m is the smallest positive constant deﬁning an
interval of some weight labelling the transitions of Gφ,ψ. Then there exists a
path ϱ = (q0, P0, init)
λ(y)
−−−→(q1, P1)
κ1
−→. . .
κn
−−→(qn, Pn, ﬁnal) in Gφ,ψ such that
y0 ∈P0, n ≤N, and there exists ζ ∈M such that ζ ∈Kϱ(y0) and ζ ∼c.
Proof (Sketch). By Proposition 19, there exists a path ϱ = (q0, P0, init)
λ(y)
−−−→
(q1, P1)
κ1
−→. . .
κn
−−→(qn, Pn, ﬁnal) in Gφ,ψ s.t. ∃ζ ∈Kϱ(y0), ζ ∼c. From ϱ, we
will construct a run of length smaller than N which witnesses the formula.
By o-minimality, each κi is a ﬁnite union of intervals. We ﬁrst choose accu-
rately one such interval per κi and obtain a realisation of ϱ noted ϱ[I], so that
the accumulated union of all intervals along ϱ[I] contains ζ such that ζ ∼c. We
call [0]-cycle a cycle labeled only by the interval [0]. We can suppose that there
is no [0]-cycle in ϱ[I] otherwise we can remove this cycle and get a shorter path
also witnessing the formula.
If the length of ϱ[I] is shorter than N then we are done. Otherwise ϱ contains
at least
  c
m
	
+ 2

simple cycles (see Fig. 2), each of which is labeled by an
(accumulated) interval whose right bound is greater than m. Thus, Kϱ[I](y0) =
⟨a, b⟩9 with b ≥c + 2m. By hypothesis, there exists ζ ∈⟨a, b⟩such that ζ ∼c.
8 This is a notation misuse, but (q, P) |= φ ∨ψ means that for all y ∈P, (q, y) |= φ ∨ψ,
which is equivalent to the property that (q, y) |= φ ∨ψ for some y ∈P.
9 ⟨a, b⟩stands for either [a, b] or [a, b) or (a, b] or (a, b).

Weighted O-Minimal Hybrid Systems
81
ϱ[I]
|Q|·|P|+1 states
cycle
ϱ′[I]
there may be [0]-cycles
ϱ′′[I]
[0]-cycles have been removed
Fig. 2. The construction in the proof of Proposition 20
We then remove the ﬁrst cycle of the run and remove [0]-cycles that can have
been potentially created (see Fig. 2). We obtain ϱ′′[I] a strictly smaller run. Note
that Kϱ′′[I](y0) might be diﬀerent from Kϱ[I](y0); nevertheless ϱ′′[I] still has at
least
 c
m
	
simple cycles so Kϱ′′[I](y0) = ⟨a′, b′⟩with b′ > c (as previously). It
proves that there exists ζ ∈Kϱ′′[I](y0) with ζ ∼c (since c < b′ ≤b and a′ ≤a).
We iterate this process until we ﬁnd a run smaller than N with this property.
□
Applying the previous proposition, we can build a ﬁrst-order formula which
checks if a given state (q, y) satisﬁes the WCTL formula E φU∼cψ, and we thus
get the following corollary.
Corollary 21. Let M = ⟨M, +, 0, 1, <, . . .⟩be an o-minimal structure such that
M is Archimedian and Th(M) is decidable. Let H be an M-weighted hybrid
system and φ and ψ be two WCTL formulae. Assume we have built two ﬁnite
and deﬁnable partitions Pφ and Pψ for φ and ψ, then we can compute a deﬁnable
ﬁnite partition correct for the formula E φU∼cψ.
We do not enter into the details of the third step. However, the construction of
the partition respecting A φU∼cψ (from the partition Pφ and Pψ) shares ideas
with the construction of the partition respecting E φU∼cψ that we have described.
In particular, the idea exploited in the proof of Proposition 20 plays an important
role.
References
[ABM04]
Rajeev Alur, Mikhail Bernadsky, and Parthasarathy Madhusudan. Op-
timal reachability for weighted timed games.
In ICALP’04: Automata,
Languages, and Programming, vol. 3142 of LNCS, pp. 122–133. Springer,
2004.
[AD94]
Rajeev Alur and David Dill. A theory of timed automata. Theoretical
Computer Science, 126(2):183–235, 1994.
[AHLP00]
Rajeev Alur, Thomas A. Henzinger, Gerardo Laﬀerriere, and George J.
Pappas.
Discrete abstractions of hybrid systems.
Proc. of the IEEE,
88:971–984, 2000.

82
P. Bouyer, T. Brihaye, and F. Chevalier
[ALP01]
Rajeev Alur, Salvatore La Torre, and George J. Pappas. Optimal paths
in weighted timed automata. In HSCC’01: Hybrid Systems, Computation
and Control, vol. 2034 of LNCS, pp. 49–62. Springer, 2001.
[BBBR06]
Patricia Bouyer, Thomas Brihaye, V´eronique Bruy`ere, and Jean-Fran¸cois
Raskin. On the optimal reachability problem. Submitted, 2006.
[BBC06]
Patricia Bouyer, Thomas Brihaye, and Fabrice Chevalier. Control in o-
minimal hybrid systems.
In LICS’06: Logic in Computer Science, pp.
367–378. IEEE Computer Society Press, 2006.
[BBL04]
Patricia Bouyer, Ed Brinksma, and Kim G. Larsen.
Staying alive as
cheaply as possible. In HSCC’04: Hybrid Systems, Computation and Con-
trol, vol. 2993 of LNCS, pp. 203–218. Springer, 2004.
[BBM06]
Patricia Bouyer, Thomas Brihaye, and Nicolas Markey. Improved unde-
cidability results on weighted timed automata.
Information Processing
Letters, 98(5):188–194, 2006.
[BBR04]
Thomas Brihaye, V´eronique Bruy`ere, and Jean-Fran¸cois Raskin. Model-
checking for weighted timed automata. In FORMATS-FTRTFT’04: For-
mal Modelling and Analysis of Timed Systems and Formal Techniques in
Real-Time and Fault-Tolerant Systems, vol. 3253 of LNCS, pp. 277–292.
Springer, 2004.
[BBR05]
Thomas Brihaye, V´eronique Bruy`ere, and Jean-Fran¸cois Raskin. On op-
timal timed strategies. In FORMATS’05: Formal Modelling and Analysis
of Timed Systems, vol. 3829 of LNCS, pp. 49–64. Springer, 2005.
[BBR06]
Thomas Brihaye, V´eronique Bruy`ere, and Jean-Fran¸cois Raskin.
On
model-checking timed automata with stopwatch observers. Information
and Computation, 204(3):408–433, 2006.
[BCFL04]
Patricia Bouyer, Franck Cassez, Emmanuel Fleury, and Kim G. Larsen.
Optimal strategies in priced timed game automata. In FSTTCS’04: Foun-
dations of Software Technology and Theoretical Computer Science, vol.
3328 of LNCS, pp. 148–160. Springer, 2004.
[BFH+01]
Gerd Behrmann, Ansgar Fehnker, Thomas Hune, Kim G. Larsen, Paul
Pettersson, Judi Romijn, and Frits Vaandrager. Minimum-cost reachabil-
ity for priced timed automata. In HSCC’01: Hybrid Systems, Computation
and Control, vol. 2034 of LNCS, pp. 147–161. Springer, 2001.
[BLM07]
Patricia Bouyer, Kim G. Larsen, and Nicolas Markey. Model-checking one-
clock priced timed automata. In FoSSaCS’07: Foundations of Software
Science and Computation Structures, vol. 4423 of LNCS, pp. 108–122.
Springer, 2007.
[BLMR06]
Patricia Bouyer, Kim G. Larsen, Nicolas Markey, and Jacob Illum Ras-
mussen. Almost optimal strategies in one-clock priced timed automata.
In FSTTCS’06: Fundations of Software Technology and Theoretical Com-
puter Science, vol. 4337 of LNCS, pp. 346–357. Springer, 2006.
[BM05]
Thomas Brihaye and Christian Michaux. On the expressiveness and decid-
ability of o-minimal hybrid systems. Journal of Complexity, 21(4):447–478,
2005.
[BMRT04]
Thomas Brihaye, Christian Michaux, C´edric Rivi`ere, and Christophe
Troestler. On o-minimal hybrid systems. In HSCC’04: Hybrid Systems,
Computation and Control, vol. 2993 of LNCS, pp. 219–233. Springer, 2004.
[Bri06a]
Thomas Brihaye. Veriﬁcation and Control of O-Minimal Hybrid Systems
and Weighted Timed Automata.
Th`ese de doctorat, Universit´e Mons-
Hainaut, Belgium, 2006.

Weighted O-Minimal Hybrid Systems
83
[Bri06b]
Thomas Brihaye. Words and bisimulation of dynamical systems. Journal
of Automata, Languages and Combinatorics, 2006. To appear.
[cor06]
Uppaal Cora, 2006. http://www.cs.aau.dk/~behrmann/cora/.
[Dav99]
Jennifer M. Davoren. Topologies, continuity and bisimulations. Theoretical
Informatics and Applications, 33(4-5):357–382, 1999.
[Gen05]
Raﬀaella Gentilini. Reachability problems on extended o-minimal hybrid
automata.
In FORMATS’05: Formal Modeling and Analysis of Timed
Systems, vol. 3829 of LNCS, pp. 162–176. Springer, 2005.
[Hen95]
Thomas A. Henzinger.
Hybrid automata with ﬁnite bisimulations.
In
ICALP’95: Automata, Languages, and Programming, vol. 944 of LNCS,
pp. 324–335. Springer-Verlag, 1995.
[Hen96]
Thomas A. Henzinger. The theory of hybrid automata. In LICS’96: Logic
in Computer Science, pp. 278–292. IEEE Computer Society Press, 1996.
[HMR05]
Thomas A. Henzinger, Rupak Majumdar, and Jean-Fran¸cois Raskin. A
classiﬁcation of symbolic transition systems. ACM Transactions on Com-
putational Logic, 6(1):1–32, 2005.
[Hod97]
Wilfrid Hodges. A Shorter Model Theory. Cambridge University Press,
1997.
[KV06]
Margarita V. Korovina and Nicolai Vorobjov. Upper and lower bounds on
sizes of ﬁnite bisimulations of Pfaﬃan hybrid systems. In CiE, vol. 3988
of Lecture Notes in Computer Science, pp. 267–276. Springer, 2006.
[LMM02]
Salvatore La Torre, Supratik Mukhopadhyay, and Aniello Murano.
Optimal-reachability and control for acyclic weighted timed automata. In
TCS’02: Theoretical Computer Science, vol. 223 of IFIP Conf. Proc., pp.
485–497. Kluwer, 2002.
[LPS00]
Gerardo Laﬀerriere, George J. Pappas, and Shankar Sastry. O-minimal
hybrid systems. Mathematics of Control, Signals, and Systems, 13(1):1–
21, 2000. Appeared as a preprint in 1998.
[PS86]
Anand Pillay and Charles Steinhorn. Deﬁnable sets in ordered structures.
Transactions of the American Mathematical Society, 295(2):565–592, 1986.
[Ras99]
Jean-Fran¸cois Raskin. Logics, Automata and Classical Theories for De-
ciding Real-Time. Th`ese de doctorat, Universit´e Namur, Belgium, 1999.
[vdD98]
Lou van den Dries. Tame Topology and O-Minimal Structures, vol. 248 of
London Mathematical Society Lecture Note Series. Cambridge University
Press, 1998.
[Wil96]
Alex J. Wilkie. Model completeness results for expansions of the ordered
ﬁeld of real numbers by restricted Pfaﬃan functions and the exponential
function. Journal of the AMS, 9(4):1051–1094, 1996.

On Decidability and Expressiveness of
Propositional Interval Neighborhood Logics
Davide Bresolin1,⋆, Valentin Goranko2,
Angelo Montanari1, and Guido Sciavicco3
1 Department of Mathematics and Computer Science,
University of Udine, Udine, Italy
2 School of Mathematics, University of the Witwatersrand,
Johannesburg, South Africa
3 Department of Information Engineering and Communications,
University of Murcia, Murcia, Spain
{bresolin,montana}@dimi.uniud.it, goranko@maths.wits.ac.za, guido@um.es
Abstract. Interval-based temporal logics are an important research area
in computer science and artiﬁcial intelligence. In this paper we investigate
decidability and expressiveness issues for Propositional Neighborhood
Logics (PNLs). We begin by comparing the expressiveness of the diﬀer-
ent PNLs. Then, we focus on the most expressive one, namely, PNLπ+,
and we show that it is decidable over various classes of linear orders by
reducing its satisﬁability problem to that of the two-variable fragment of
ﬁrst-order logic with binary relations over linearly ordered domains, due
to Otto. Next, we prove that PNLπ+ is expressively complete with respect
to such a fragment. We conclude the paper by comparing PNLπ+ expres-
siveness with that of other interval-based temporal logics.
Keywords: neighbourhood interval logics, decidability, expressiveness.
1
Introduction
Interval-based temporal logics over ordered domains are an important research
area in various ﬁelds of computer science and artiﬁcial intelligence. Unfortu-
nately, even when restricted to the case of propositional languages and linear
time, they usually exhibit a bad computational behavior where undecidability
rules. The main species of studied propositional interval temporal logics include
Moszkowski’s Propositional Interval Logic (PITL) [17], Halpern and Shoham’s
modal logic of time intervals (HS) [12], Venema’s CDT logic [22] (extended to
branching-time frames with linear intervals by Goranko, Montanari and Sci-
avicco [9]), Lodaya’s Begins/Ends fragment of HS (BE) [15], and Montanari,
Goranko and Sciavicco’s Propositional Neighborhood Logics [7]. Many expres-
siveness and (un)decidability results for these logics substantially depend on the
assumptions about the class of frames over which they are interpreted. Typical
classes of frames are the class of all (resp., dense, discrete, Dedekind complete)
⋆Current aﬃliation: Dept. of Computer Science, University of Verona, Verona, Italy.
S. Artemov and A. Nerode (Eds.): LFCS 2007, LNCS 4514, pp. 84–99, 2007.
c
⃝Springer-Verlag Berlin Heidelberg 2007

On Decidability and Expressiveness
85
linear frames, and of speciﬁc linear orders such as N, Z, Q, and R. Basic results
about these logics are the undecidability of HS and CDT over most of classes of
frames, of PITL over dense and discrete frames, and of BE over dense frames.
A comprehensive survey of the main developments, results, and open problems
in the area of propositional interval temporal logics can be found in [8].
In this paper we focus our attention on expressiveness and decidability is-
sues for Propositional Neighborhood Logics (PNLs) over various classes of linear
orders. PNLs are fragments of HS which feature two modalities, correspond-
ing to Allen’s relations meets and met by, and (possibly) the interval operator
π. Sound and complete axiomatic systems for PNLs and a tableau-based semi-
decision procedure for them have been developed in [7]. A tableau-based decision
procedure for the future fragments of PNLs, interpreted over N, together with
a proof of NEXPTIME-completeness, have been given in [2,4] and later ex-
tended to full PNLs over Z [3]. To the best of our knowledge, these are the ﬁrst
non-trivial decidability results for propositional interval logics interpreted over
fully-instantiated temporal structures, that is, temporal structures containing all
intervals that can be built up from a given linearly ordered set of points, which
do not resort to any projection principle, such as locality or homogeneity [12].
Here is a summary of the paper. First, we compare the expressive power of
three PNLs, namely, PNLπ+, PNL+, and PNL−, and we show that PNLπ+ is
strictly more expressive than PNL+ and PNL−. Then, we prove that the satisﬁ-
ability problem for PNLπ+ over the classes of all linear orders, of all well-orders,
and of all ﬁnite linear orders, can be decided in NEXPTIME by reducing it to the
satisﬁability problem for the two-variable fragment of ﬁrst-order logic over the
same classes of structures [18]. Next, we focus on expressive completeness, in
the spirit of Kamp’s theorem [14]. Kamp proved the functional completeness of
the Since (S) and Until (U) temporal logic with respect to ﬁrst-order deﬁnable
connectives over Dedekind-complete linear orders. This result has been later re-
proved and generalized in several ways (see [13,6]). In particular, Stavi extended
Kamp’s result to the class of all linear orders by adding the binary operators S′
and U ′ (see
[6] for details), while Etessami et al. proved the functional com-
pleteness of the future (F) and past (P) temporal logic (TL[F,P] for short) with
respect to the monadic two-variable fragment of ﬁrst-order logic MFO2[<] over
N [5]. As for interval-based logics, Venema showed the functional completeness of
CDT with respect to the three-variable (with at most two of them free) fragment
of ﬁrst-order logic FO3
x,y[<] over all linear orders. In this paper we prove the ex-
pressive completeness of PNLπ+ with respect to the full two-variable fragment
of ﬁrst-order logic over various classes of linear orders. We conclude the paper
with a comparison of PNLπ+ expressive power with that of other HS fragments.
2
Basics
Propositional Neighborhood Logics. The syntax and semantics of proposi-
tional neighborhood logics (PNLs for short), interpreted over linear orders, are
deﬁned as follows. Let D = ⟨D, <⟩be a linearly ordered set. An interval over
D is an ordered pair [a, b], where a, b ∈D and a ≤b. An interval [a, b] is a

86
D. Bresolin et al.
strict interval if a < b, while it is a point interval if a = b. We denote the set of
all (resp., strict) intervals over D by I(D)+ (resp., I(D)−). The language of Full
Propositional Neighborhood Logic (PNLπ+) consists of a set AP of propositional
letters, the propositional connectives ¬, ∨, the modal constant π, and the modal
operators 3r and 3l. The other propositional connectives, as well as the logical
constants ⊤(true) and ⊥(false) and the dual modal operators 2r and 2l,
are deﬁned as usual. Formulas of PNLπ+, denoted by ϕ, ψ, . . ., are recursively
deﬁned by the following grammar: ϕ ::= p | ¬ϕ | ϕ ∨ϕ | π | 3rϕ | 3lϕ. The
language of Non-strict Propositional Neighborhood Logic (PNL+) is the frag-
ment of PNLπ+ devoid of the modal constant π, while the language of Strict
Propositional Neighborhood Logic (PNL−) is obtained from that of PNL+ by
replacing the modalities 3r and 3l with the modalities ⟨A⟩and ⟨A⟩(with dual
modalities [A] and [A]), respectively. We adopt diﬀerent notations for the modal-
ities of PNLπ+ /PNL+ and PNL−to reﬂect their historical links and to make
it easier to distinguish between their non-strict/strict semantics from the syn-
tax. We will write PNLs when referring to either PNLπ+, PNL+, or PNL−.
The semantics of PNLπ+ /PNL+ is given in terms of non-strict interval mod-
els M+ = ⟨I(D)+, V +⟩, while that of PNL−is given in terms of strict interval
models M−= ⟨I(D)−, V −⟩. The valuation function V + : AP 	→2I(D)+ (resp.,
V −: AP 	→2I(D)−) assigns to every propositional variable p the set of (all, resp.
strict) intervals V (p) over which p holds. Instead of V + and V −, we will write
just V whenever there is no risk of confusion; likewise we will write I(D) for
either I(D)+ or I(D)−. Note that for every p, V (p) can be viewed as a binary
relation on D, and we will use that later on. When referring to either the strict
or the non-strict interval model, we will use M. The truth relation of a formula
at a given interval in a model M is deﬁned by structural induction on formulas:
– M, [a, b] ⊩p iﬀ[a, b] ∈V (p), for all p ∈AP;
– M, [a, b] ⊩¬ψ iﬀit is not the case that M, [a, b] ⊩ψ;
– M, [a, b] ⊩ϕ ∨ψ iﬀM, [a, b] ⊩ϕ or M, [a, b] ⊩ψ;
– M, [a, b] ⊩3rψ (resp., ⟨A⟩ψ) iﬀthere exists c such that c ≥b (resp., c > b)
and M, [b, c] ⊩ψ;
– M, [a, b] ⊩3lψ (resp., ⟨A⟩ψ) iﬀthere exists c such that c ≤a (resp., c < a)
and M, [c, a] ⊩ψ;
– M+, [a, b] ⊩π iﬀa = b.
A formula is satisﬁable if it is true over some interval in some interval model
(for the respective language) and it is valid if it is true over every interval in
every interval model. As shown in [7], PNLs are powerful enough to express
interesting temporal properties, e.g., they allow one to constrain the structure
of the underlying linear ordering. In particular, PNLπ+ and PNL−allow one to
express the diﬀerence operator and thus to simulate nominals.
The two-variable fragment of ﬁrst-order logic. In this section we give
some basic deﬁnitions about fragments of ﬁrst-order logic. Let us denote by FO2
(resp., FO2[=]) the fragment of ﬁrst-order logic (resp., ﬁrst-order logic with

On Decidability and Expressiveness
87
equality) whose language uses only two distinct (possibly reused) variables. We de-
note its formulas by α, β, . . .. For example, the formula ∀x(P(x) →∀y∃xQ(x, y))
belongs to FO2, while the formula ∀x(P(x) →∀y∃z(Q(z, y) ∧Q(z, x))) does not.
We focus our attention on the logic FO2[<] over a purely relational vocabulary
{=, <, P, Q, . . .} including equality and a distinguished binary relation < inter-
preted as a linear ordering. Since atoms in the two-variable fragment can involve
at most two distinct variables, we may further assume without loss of generality
that the arity of every relation is exactly 2.
Let x and y be the two variables of the language. The formulas of FO2[<] can
be deﬁned recursively as follows:
α ::= A0 | A1 | ¬α | α ∨β | ∃xα | ∃yα
A0 ::= x = x | x = y | y = x | y = y | x < y | y < x
A1 ::= P(x, x) | P(x, y) | P(y, x) | P(y, y),
where A1 deals with (uninterpreted) binary predicates. For technical conve-
nience, we assume that both variables x and y occur as (possibly vacuous) free
variables in every formula α ∈FO2[<], that is, α = α(x, y).
Formulas of FO2[<] are interpreted over relational models of the form A =
⟨D, VA⟩, where D is a linear ordering and VA is a valuation function that assigns
to every binary relation P a subset of D×D. When we evaluate a formula α(x, y)
on a pair of elements a, b, we write α(a, b) for α[x := a, y := b].
The satisﬁability problem for FO2 without equality was proved decidable by
Scott [19] by a satisﬁability preserving reduction of any FO2-formula to a formula
of the form ∀x∀yψ0 ∧
m
i=1
∀x∃yψi, which belongs to the G¨odel’s preﬁx-deﬁned
decidable class of ﬁrst-order formulas [1]. Later, Mortimer extended this result by
including equality in the language [16]. More recently, Gr¨adel, Kolaitis, and Vardi
improved Mortimer’s result by lowering the complexity bound [11]. Finally, by
building on techniques from [11] and taking advantage of an in-depth analysis of
the basic 1-types and 2-types in FO2[<]-models, Otto proved the decidability of
FO2[<] over the class of all linear orderings as well as on some natural subclasses
of it [18].
Theorem 1 ([18]). The satisﬁability problem for formulas in FO2[<] is decid-
able in NEXPTIME on each of the classes of structures where < is interpreted
as (i) any linear ordering, (ii) any well-ordering, (iii) any ﬁnite linear ordering,
and (iv) the linear ordering on N.
Comparing the expressive power of interval logics. In the following we
will compare the expressive power of PNLπ+ with that of PNL+ and PNL−
as well as with that of other classical/temporal logics. There are several ways
to compare the expressive power of diﬀerent modal languages/logics, e.g., they
can be compared with respect to frame validity, that is, with respect to the
properties of frames that they can express (such a comparison for PNLs has
been done in [7]). Here we compare the considered logics with respect to truth
at a given element of a model. We distinguish three diﬀerent cases: the case in

88
D. Bresolin et al.
which we compare two interval logics over the same class of models, e.g., PNLπ+
and PNL+, the case in which we compare strict and non-strict interval logics,
e.g., PNL−and PNLπ+, and the case in which we compare an interval logic with
a ﬁrst-order logic, e.g., PNLπ+ and FO2[<].
Given two interval logics L and L’ interpreted over the same class of models
C, we say that L’ is at least as expressive as L (with respect to C), denoted
by L ⪯C L′ (C is omitted if clear from the context), if there exists an eﬀective
translation τ from L to L’ (inductively deﬁned on the structure of formulas) such
that for every model M in C, any interval [a, b] in M, and any formula ϕ of L,
M, [a, b] ⊩ϕ iﬀM, [a, b] ⊩τ(ϕ). Furthermore, we say that L is as expressive as
L’, denoted by L ≡C L′, if both L ⪯C L′ and L′ ⪯C L, while we say that L is
strictly more expressive than L’, denoted by L′ ≺C L, if L′ ⪯C L and L ̸⪯C L′.
When comparing an interval logic L−interpreted over strict interval models
with an interval logic L+ interpreted over non-strict ones, we need to slightly
revise the above deﬁnitions. Given a strict interval model M−= ⟨I(D)−, V −⟩, we
say that a non-strict interval model M+ = ⟨I(D)+, V +⟩is a non-strict extension
of M−(and that M−is the strict restriction of M+) if V −and V + agree on the
valuation of strict intervals, that is, if for every strict interval [a, b] ∈I(D)−and
propositional letter p ∈AP, [a, b] ∈V −(p) if and only if [a, b] ∈V +(p). We say
that L+ is at least as expressive as L−, and we denote it by L−⪯I L+, if there
exists an eﬀective translation τ from L−to L+ such that for any strict interval
model M−, any interval [a, b] in M−, and any formula ϕ of L−, M−, [a, b] ⊩ϕ
iﬀM+, [a, b] ⊩τ(ϕ) for every non-strict extension M+ of M−. Conversely, we
say that L−is at least as expressive as L+, and we denote it by L+ ⪯I L−, if
there exists an eﬀective translation τ′ from L+ to L−such that for any non-strict
interval model M+, any strict interval [a, b] in M+, and any formula ϕ of L+,
M+, [a, b] ⊩ϕ iﬀM−, [a, b] ⊩τ ′(ϕ), where M−is the strict restriction of M+.
L−≡I L+, L−≺I L+, and L+ ≺I L−are deﬁned in the usual way.
Finally, we compare interval logics with ﬁrst-order logics interpreted over re-
lational models. In this case, the above criteria are no longer adequate, since we
need to compare logics which are interpreted over diﬀerent types of models (in-
terval models and relational models). We deal with this complication by following
the approach outlined by Venema in [22]. First, we deﬁne suitable model trans-
formations (from interval models to relational models and vice versa); then, we
compare the expressiveness of interval and ﬁrst-order logics modulo these trans-
formations. To deﬁne the mapping from interval models to relational models, we
associate a binary relation P with every propositional variable p ∈AP of the
considered interval logic [22].
Deﬁnition 1. Given an interval model M = ⟨I(D), VM⟩, the corresponding re-
lational model η(M) is a pair ⟨D, Vη(M)⟩, where for all p ∈AP, Vη(M)(P) =
{(a, b) ∈D × D : [a, b] ∈VM(p)}.
As a matter of fact, the above relational models can be viewed as ‘point’ models
for logics over D2 and the above transformation as a mapping of propositional
letters of the interval logic, interpreted over I(D), into propositional letters of
the target logic, interpreted over D2 [21,20].

On Decidability and Expressiveness
89
To deﬁne the mapping from relational models to interval ones, we have to
solve a technical problem: the truth of formulas in interval models is evaluated
only on ordered pairs [a, b], with a ≤b, while in relational models there is not
such a constraint. To deal with this problem, we associate two propositional
letters p≤and p≥of the interval logic with every binary relation P.
Deﬁnition 2. Given a relational model A = ⟨D, VA⟩, the corresponding non-
strict interval model ζ(A) is a pair ⟨I(D)+, Vζ(A)⟩such that for any binary
relation P and any interval [a, b], [a, b] ∈Vζ(A)(p≤) iﬀ(a, b) ∈VA(P) and
[a, b] ∈Vζ(A)(p≥) iﬀ(b, a) ∈VA(P).
Given an interval logic LI and a ﬁrst-order logic LF O, we say that LF O is at
least as expressive as LI, denoted by LI ⪯R LF O, if there exists an eﬀective
translation τ from LI to LF O such that for any interval model M, any interval
[a, b], and any formula ϕ of LI, M, [a, b] ⊩ϕ iﬀη(M) |= τ(ϕ)(a, b). Conversely,
we say that LI is at least as expressive as LF O, denote by LF O ⪯R LI, if there
exists an eﬀective translation τ′ from LF O to LI such that for any relational
model A, any pair (a, b) of elements, and any formula ϕ of LF O, A |= ϕ(a, b) iﬀ
ζ(A), [a, b] ⊩τ′(ϕ) if a ≤b or ζ(A), [b, a] ⊩τ ′(ϕ) otherwise. We say that LI is
as expressive as LF O, denoted by LI ≡R LF O, if LI ⪯R LF O and LF O ⪯R LI.
LI ≺R LF O and LF O ≺R LI are deﬁned in the usual way.
3
PNLπ+, PNL+, and PNL−Expressiveness
In this section we compare the relative expressive power of PNLπ+, PNL+,
and PNL−. The comparison of the expressive power of PNLπ+ and PNL+ is
based on an application of the bisimulation game for modal logics [10]. More
precisely, we exploit a game-theoretic argument to show that there exist two
models that can be distinguished by a PNLπ+ formula, but not by a PNL+
formula. To this end, we deﬁne the notion of k-round PNL+- bisimulation game
to be played on a pair of PNL+ models (M0
+, M1
+), with M0
+ = ⟨I(D0)+, V0⟩
and M1
+ = ⟨I(D1)+, V1⟩, which starts from a given initial conﬁguration, where
a conﬁguration is a pair of intervals ([a0, b0], [a1, b1]), with [a0, b0] ∈I(D0)+ and
[a1, b1] ∈I(D1)+. The game is played by two players, Player I and Player II. If
after any given round the current position is not a local isomorphism between
the submodels of M0
+ and M1
+ induced by the corresponding conﬁguration,
Player I wins the game; otherwise, Player II wins. At every round, given a current
conﬁguration ([a0, b0], [a1, b1]), Player I plays one of the following two moves:
3r-move: Player I chooses Mi
+, with i ∈{0, 1}, and an interval [bi, ci];
3l-move: Player I chooses Mi
+, with i ∈{0, 1}, and an interval [ci, ai].
In the ﬁrst case, Player II replies by choosing an interval [b1−i, c1−i], which leads
to the new conﬁguration ([b0, c0], [b1, c1]); in the other case, Player II chooses
an interval [c1−i, a1−i], which leads to the new conﬁguration ([c0, a0], [c1, a1]).

90
D. Bresolin et al.
Roughly speaking, Player II has a winning strategy in the k-round PNL+-
bisimulation game on the models M0
+ and M1
+ with a given initial conﬁg-
uration if she can win regardless of the moves played by Player I; otherwise,
Player I has a winning strategy. A formal deﬁnition of winning strategy can
be found in [10]. The following key property of the k-round PNL+-bisimulation
game directly follows from standard results for bisimulation games in modal
logics [10].
Proposition 1. Let P be a ﬁnite set of propositional letters. For all k ≥0,
Player II has a winning strategy in the k-round PNL+-bisimulation game on
M0
+ and M1
+, with initial conﬁguration ([a0, b0], [a1, b1]), iﬀ[a0, b0] and [a1, b1]
satisfy the same PNL+-formulas over P with operator depth at most k.
We exploit Proposition 1 to prove that the π operator of PNLπ+ cannot be
expressed in PNL+. We choose two models M0
+ and M1
+ that can be distin-
guished with a PNLπ+ formula which makes an essential use of π, but not by a
PNL+ formula. The claim is proved by showing that for all k, Player II has a
winning strategy in the k-round PNL+-bisimulation game on M0
+ and M1
+.
Theorem 2. The interval operator π cannot be deﬁned in PNL+.
Proof. Let M+ = ⟨I(Z)+, V ⟩, where V is such that p holds everywhere, be a
non-strict model. Consider the k-round PNL+-bisimulation game on (M+, M+)
with initial conﬁguration ([0, 1], [1, 1]). The intervals [0, 1] and [1, 1] can be easily
distinguished in PNLπ+, since π holds in [1, 1] but not in [0, 1]. We show that this
pair of intervals cannot be distinguished in PNL+ by providing a simple winning
strategy for Player II in the k-round PNL+-bisimulation game on (M+, M+)
with initial conﬁguration ([0, 1], [1, 1]), as follows: if Player I plays a 3r-move
on a given structure, then Player II arbitrarily chooses a right-neighbor of the
current interval on the other structure. Likewise, if Player I plays a 3l-move
on a given structure, then Player II arbitrarily chooses a left-neighbor of the
current interval on the other structure. Since the valuation V is such that p
holds everywhere, in any case the new conﬁguration is a local isomorphism.
⊓⊔
The next theorem shows that PNL−is strictly less expressive than PNLπ+.
Theorem 3. PNL−≺I PNLπ+.
Proof. We prove the claim by showing that PNL−⪯I PNLπ+ and PNLπ+ ̸⪯I
PNL−. To prove the former, we provide a translation τ from PNL−to PNLπ+.
Consider the mapping τ0 deﬁned as follows:
τ0(p) = p
τ0(⟨A⟩ϕ) = 3r(¬π ∧τ0(ϕ))
τ0(¬ϕ) = ¬τ0(ϕ)
τ0(⟨A⟩ϕ) = 3l(¬π ∧τ0(ϕ))
τ0(ϕ1 ∨ϕ2) = τ0(ϕ1) ∨τ0(ϕ2)
For every PNL−-formula ϕ, let τ(ϕ) = ¬π ∧τ0(ϕ). Given a strict model M−=
⟨I(D)−, V −⟩, let M+ = ⟨I(D)+, V +⟩be a non-strict extension of M−. It is im-
mediate to show that for any interval [a, b] in M−and any PNL−-formula ϕ,

On Decidability and Expressiveness
91
M−, [a, b] ⊩ϕ if and only if M+, [a, b] ⊩τ(ϕ). The proof is an easy induction
on the structure of ϕ. This proves that PNL−⪯I PNLπ+.
To prove that PNLπ+ ̸⪯I PNL−, suppose by contradiction that there exists a
translation τ′ from PNLπ+ to PNL−such that, for any non-strict model M+, any
strict interval [a, b], and any formula ϕ of PNLπ+, M+, [a, b] ⊩ϕ iﬀM−, [a, b] ⊩
τ′(ϕ), where M−is the strict restriction of M+. Consider the non-strict models
M+
0 = ⟨I(Z)+, V0⟩and M+
1 = ⟨I(Z)+, V1⟩, where V0(p) = {[a, b] ∈I(Z)+ : a ≤b}
and V1(p) = {[a, b] ∈I(Z)+ : a < b}. It is immediate to see that M+
0 , [0, 1] ⊩2rp,
while M+
1 , [0, 1] ̸⊩2rp. Let M−= ⟨I(Z)−, V −⟩be a strict interval model such
that p holds everywhere in I(Z)−. We have that M−is the strict restriction
of both M+
0 and M+
1 . Hence, we may conclude that M−, [0, 1] ⊩τ′(2rp) and
M−, [0, 1] ̸⊩τ ′(2rp), which is a contradiction.
⊓⊔
Finally, we show that neither PNL+ ⪯I PNL−nor PNL−⪯I PNL+.
Theorem 4. The expressive powers of PNL+ and PNL−are incomparable,
namely, PNL−̸⪯I PNL+ and PNL+ ̸⪯I PNL−.
Proof. We ﬁrst prove that PNL−̸⪯I PNL+. Let M0
+ = ⟨I(Z)+, V0⟩and M1
+ =
⟨I(Z\{2})+, V1⟩, where V0 is such that V0(p) = {[1, 1], [1, 2], [2, 2]} and V1 is such
that V1(p) = {[1, 1]}, be two PNL+-models. For any k ≥0, consider the k-round
PNL+-bisimulation game between M0
+ and M1
+, with initial conﬁguration
([0, 1], [0, 1]). Player II has the following winning strategy: at any round, if Player
I chooses an interval [a, b] ∈I(Z \ {2})+ in one of the models, then Player II
chooses the same interval on the other model, while if Player I chooses an interval
[a, 2] (resp., [2, b]) in M0
+, then Player II chooses the interval [a, 1] (resp., [1, b])
in M1
+. On the contrary, the strict restrictions M0
−of M0
+ and M1
−of M1
+
can be easily distinguished by PNL−: we have that M0
−, [0, 1] ⊩⟨A⟩p, while
M1
−, [0, 1] ̸⊩⟨A⟩p. Since M0
+ and M1
+ satisfy the same formulas over the
interval [0, 1], there cannot exist a translation τ′ from PNL−to PNL+ such that
M0
+, [0, 1] ⊩τ ′(⟨A⟩p) and M1
+, [0, 1] ̸⊩τ ′(⟨A⟩p).
As for PNL+ ̸⪯I PNL−, we can exploit the very same proof we gave to show
that PNLπ+ ̸⪯I PNL−(it suﬃces to notice that 2rp is a PNL+ formula).
⊓⊔
4
Decidability of PNLs
In this section we prove the decidability of PNLπ+, and thus that of its proper
fragments PNL+ and PNL−, by embedding it into the two-variable fragment
of ﬁrst-order logic interpreted over linearly ordered domains. PNLπ+ can be
translated into FO2[<] as follows. Let AP be the set of propositional letters
in PNLπ+. The signature for FO2[<] includes a binary relational symbol P for
every p ∈AP. The translation function STx,y is deﬁned as follows:
STx,y(ϕ) = x ≤y ∧ST ′
x,y(ϕ),

92
D. Bresolin et al.
where x, y are two ﬁrst-order variables and
ST ′
x,y(p) = P(x, y)
ST ′
x,y(ϕ ∨ψ) = ST ′
x,y(ϕ) ∨ST ′
x,y(ψ)
ST ′
x,y(π) = (x = y)
ST ′
x,y(3rϕ) = ∃x(y ≤x ∧ST ′
y,x(ϕ))
ST ′
x,y(¬ϕ) = ¬ST ′
x,y(ϕ)
ST ′
x,y(3lϕ) = ∃y(y ≤x ∧ST ′
y,x(ϕ))
Two variables are thus suﬃcient to translate PNLπ+ into FO2[<]. As we will
show later, this is not the case with other interval temporal logics, such as, for
instance, HS and CDT. The next theorem proves that that FO2[<] is at least as
expressive as PNLπ+ (η is the model transformation deﬁned in Section 2).
Theorem 5. For any PNLπ+-formula ϕ, any non-strict interval model M+ =
⟨I(D)+, V ⟩, and any interval [a, b] in M+:
M+, [a, b] ⊩ϕ iﬀη(M+) |= STx,y(ϕ)[x := a, y := b].
Proof. The proof is by structural induction on ϕ. The base case, as well as
the cases of Boolean connectives, are straightforward, and thus omitted. Let
ϕ = 3rψ. From M+, [a, b] ⊩ϕ, it follows that there exists an element c such
that c ≥b and M+, [b, c] ⊩ψ. By inductive hypothesis, we have that η(M+) |=
STy,x(ψ)[y := b, x := c]. By deﬁnition of STy,x(ψ), this is equivalent to η(M+) |=
y ≤x ∧ST ′
y,x(ψ)[y := b, x := c]. This implies that η(M+) |= ∃x(y ≤x ∧
ST ′
y,x(ψ))[y := b]. Since a ≤b ([a, b] in M+), we can conclude that η(M+) |=
STx,y(3rψ)[x := a, y := b]. The converse direction can be proved in a similar
way. The case ϕ = 3lψ is completely analogous and thus omitted.
⊓⊔
Corollary 1. A PNLπ+-formula ϕ is satisﬁable in a class of non-strict interval
structures built over a class of linear orderings C iﬀSTx,y(ϕ) is satisﬁable in the
class of all FO2[<]-models expanding linear orderings from C.
Since the above translation is polynomial in the size of the input formula, de-
cidability of PNLπ+ follows from Theorem 1.
Corollary 2. The satisﬁability problem for PNLπ+ is decidable in NEXPTIME
for each of the classes of non-strict interval structures built over (i) the class of
all linear orderings, (ii) the class of all well-orderings, (iii) the class of all ﬁnite
linear orderings, and (iv) the linear ordering on N.
This result can be extended to decide the satisﬁability problem for PNLπ+ over
any class of linear orderings, deﬁnable in FO2[<] within any of the above, e.g.,
the class of all (un)bounded (above, below) linear orderings or all (un)bounded
above well-orderings, etc. On the contrary, the decidability of the satisﬁability
problem for PNLπ+ on any of the classes of all discrete, dense, or Dedekind
complete linear orderings is still open.
Since PNL+ ≺PNLπ+ and PNL−≺I PNLπ+, both PNL+ and PNL−are
decidable in NEXPTIME (at least) over the same classes of orderings as PNLπ+.
Moreover, a translation from PNL+ to FO2[<] can be obtained from that for
PNLπ+ by simply removing the rule for π, while a translation from PNL−to

On Decidability and Expressiveness
93
FO2[<] can be obtained from that for PNLπ+ by removing the rule for π, by
substituting < for ≤, and by replacing 3r (resp., 3l) with ⟨A⟩(resp., ⟨A⟩).
The NEXPTIME-hardness of the satisﬁability problem for PNLπ+, PNL+,
and PNL−can be proved by exploiting the very same reduction from the expo-
nential tiling problem given by Bresolin et al. for PNLs future fragments [4].
Theorem 6. The satisﬁability problem for PNL−, PNL+, and PNLπ+ inter-
preted in the class of all linear orderings, the class of all well-orderings, the
class of all ﬁnite linear orderings, and the linear ordering on N is NEXPTIME-
complete.
5
Expressive Completeness
In this section, we show that PNLπ+ is at least as expressive as FO2[<], that
is, we show that every formula of FO2[<] can be translated into an equivalent
formula of PNLπ+ (see Section 2). This allows us to conclude that PNLπ+ is
as expressive as FO2[<]. A similar result for CDT was given by Venema in [22],
where the expressive completeness of CDT with respect to FO3
x,y[<] (the frag-
ment of ﬁrst-order logic interpreted over linear orderings whose language features
only three, possibly reused variables and at most two of them, x and y, can be
free) was proved. Both results can be viewed as interval-based counterparts of
Kamp’s theorem for propositional point-based linear time temporal logic [14].
The translation τ from FO2[<] to PNLπ+ is given in the following table:
Basic formulas
Non-basic formulas
τ[x, y](x = x) = τ[x, y](y = y) = ⊤τ[x, y](¬α) = ¬τ[x, y](α)
τ[x, y](x = y) = τ[x, y](y = x) = π τ[x, y](α ∨β) = τ[x, y](α) ∨τ[x, y](β)
τ[x, y](y < x) = ⊥
τ[x, y](∃xβ) =
τ[x, y](x < y) = ¬π
3r(τ[y, x](β)) ∨2r3l(τ[x, y](β))
τ[x, y](P(x, x)) = 3l(π ∧p≤∧p≥) τ[x, y](∃yβ) =
τ[x, y](P(y, y)) = 3r(π ∧p≤∧p≥)
3l(τ[y, x](β)) ∨2l3r(τ[x, y](β))
τ[x, y](P(x, y)) = p≤
τ[x, y](P(y, x)) = p≥
As formally stated by Theorem 7 below, every FO2[<]-formula α(x, y) is
mapped into two distinct PNLπ+-formulas τ[x, y](α) and τ[y, x](α). The ﬁrst
one captures all and only the models of α(x, y) where x ≤y (if any), while the
second one captures all and only the models of α(x, y) where y ≤x (if any).
Example 1. Consider the formula α = ∃x¬∃y(x < y), which constrains the
model to be right-bounded. Let β = ∃y(x < y). We have that
τ[x, y](β) = 3l(τ[y, x](x < y)) ∨2l3r(τ[x, y](x < y)) =
= 3l⊥∨2l3r¬π (≡2l3r¬π)
and that
τ[y, x](β) = 3r(τ[x, y](x < y)) ∨2r3l(τ[y, x](x < y)) =
= 3r¬π ∨2r3l⊥(≡3r¬π)

94
D. Bresolin et al.
The resulting translation of α is:
τ[x, y](α) = 3r(τ[y, x](¬β)) ∨2r3l(τ[x, y](¬β)) =
= 3r(¬τ[y, x](β)) ∨2r3l(¬τ[x, y](β)) =
= 3r¬3r¬π ∨2r3l¬2l3r¬π =
= 3r2rπ ∨2r3l3l2rπ (≡3r2rπ ∨2rπ)
which is a PNLπ+-formula which constrains the model to be right-bounded.
Let A = ⟨D, VA⟩be a FO2[<]-model and let ζ(A) = ⟨I(D)+, Vζ(A)⟩be the
corresponding PNLπ+-model (see Section 2).
Theorem 7. For every FO2[<]-formula α(x, y), every FO2[<]-model A = ⟨D,
VA⟩, and every pair a, b ∈D, with a ≤b, (i) A |= α(a, b) if and only if ζ(A), [a, b] ⊩
τ[x, y](α) and (ii) A |= α(b, a) if and only if ζ(A), [a, b] ⊩τ[y, x](α).
Proof. The proof is by simultaneous induction on the complexity of α.
– α = (x = x) or α = (y = y). Both α and τ[x, y](α) = ⊤are true.
– α = (x < y). As for claim (i), A |= α(a, b) iﬀa < b iﬀζ(A), [a, b] ⊩¬π. As
for claim (ii) A ̸|= α(b, a), since a ≤b, and ζ(A), [a, b] ̸⊩τ[y, x](x < y)(= ⊥).
Likewise, for α = (y < x).
– α = P(x, y) or α = P(y, x). Both claims follow from the valuation of p≤and
p≥(given in Section 2).
– α = P(x, x). As for claim (i), A |= α(a, b) iﬀA |= P(a, a) iﬀζ(A), [a, a] ⊩
π ∧p≤∧p≥iﬀζ(A), [a, b] ⊩3l(π ∧p≤∧p≥). A similar argument can be used
to prove claim (ii). Likewise for α = P(y, y).
– The Boolean cases are straightforward.
– α = ∃xβ. As for claim (i), suppose that A |= α(a, b). Then, there is c ∈A
such that A |= β(c, b). There are two (non-exclusive) cases: b ≤c and c ≤b.
If b ≤c, by the inductive hypothesis, we have that ζ(A), [b, c] ⊩τ[y, x](β)
and thus ζ(A), [a, b] ⊩3r(τ[y, x](β)). Likewise, if c ≤b, by the inductive hy-
pothesis, we have that ζ(A), [c, b] ⊩τ[x, y](β) and thus for every d such that
b ≤d, ζ(A), [b, d] ⊩3l(τ[x, y](β)), that is, ζ(A), [a, b] ⊩2r3l(τ[x, y](β)).
Hence ζ(A), [a, b] ⊩3r(τ[y, x](β)) ∨2r3l(τ[x, y](β)), that is, ζ(A), [a, b] ⊩
τ[x, y](α). For the converse direction, it suﬃces to note that the interval [a, b]
has at least one right neighbor, viz. [b, b], and thus the above argument can
be reversed. Claim (ii) can be proved in a similar way.
– α = ∃yβ. Analogous to the previous case.
⊓⊔
Corollary 3. For every formula α(x, y) and every FO2[<]-model A = ⟨D, VA⟩,
A |= ∀x∀yα(x, y) if and only if ζ(A) ⊩τ[x, y](α) ∧τ[y, x](α).
Deﬁnition 3. We say that a PNLπ+-model M of the considered language is
synchronized on a pair of variables (p≤, p≥) if these variables are equally true at
any point interval [a, a] in M; M is synchronized for a FO2[<]-formula α if it is
synchronized on every pair of variables (p≤, p≥) corresponding to a predicate p
occurring in α; M is synchronized if it is synchronized on every pair (p≤, p≥).

On Decidability and Expressiveness
95
It is immediate to see that every model ζ(A), where A is a FO2[<]-model,
is synchronized. Conversely, every synchronized PNLπ+-model M can be repre-
sented as ζ(A) for some model A for FO2[<]: the linear ordering of A is inherited
from M and the interpretation of every binary predicate P is deﬁned in accor-
dance with Theorem 7, that is, for any a, b ∈A we set P(a, b) to be true precisely
when a ≤b and M, [a, b] ⊩p≤or b ≤a and M, [b, a] ⊩p≥. Due to the synchro-
nization, these two conditions agree when a = b. Furthermore, the condition
that a PNLπ+-model M is synchronized on a pair of variables p≤and p≥can be
expressed by the validity in M of the formula [U](π →(p≤↔p≥)), where [U]
is the universal modality, which is deﬁnable in PNLπ+ as follows [7]:
[U]ϕ ::= 2r2r2lϕ ∧2r2l2lϕ ∧2l2l2rϕ ∧2l2r2rϕ.
Building on this observation, we associate with every FO2[<]-formula α the
formulas
σv(α) =
⎛
⎝
p≤,p≥
[U](π →(p≤↔p≥))
⎞
⎠→(τ[x, y](α) ∧τ[y, x](α))
and
σs(α) =
⎛
⎝
p≤,p≥
[U](π →(p≤↔p≥))
⎞
⎠∧(τ[x, y](α) ∨τ[y, x](α)),
where the conjunctions range over all pairs p≤, p≥corresponding to predicates
occurring in α.
Corollary 4. For any FO2[<]-formula α, (i) α is valid in all FO2[<]-models iﬀ
σv(α) is a valid PNLπ+-formula, and (ii) α is satisﬁable in some FO2[<]-model
iﬀσs(α) is a satisﬁable PNLπ+-formula.
Notice that the proposed translation from FO2[<] to PNLπ+ is exponential, due
to the clause for the existential quantiﬁer. We do not know whether there exists
a polynomial translation or not.
CDT
FO3
x,y[<]
PNLπ+
FO2[<]
@@
@@
≡R
≡R
≺
≺
Fig. 1. Expressive completeness results for interval logics
In Figure 1 we put together the expressive completeness results for CDT and
PNLπ+, using the notation introduced in Section 2. Since FO2[<] is a proper
fragment of FO3
x,y[<], from the equivalences between CDT and FO3
x,y[<] and
between PNLπ+ and FO2[<] it immediately follows that CDT is strictly more
expressive than PNLπ+.

96
D. Bresolin et al.
6
PNLπ+ and Other HS Fragments
In this section we explore the relationships between PNLπ+ and other fragments
of HS. More precisely, we describe the fragments of HS which are fragments
of PNLπ+ as well. To this end, we consider all other interval modalities of
HS, namely, ⟨B⟩, ⟨E⟩, ⟨O⟩, ⟨D⟩, ⟨L⟩, and their transposes, which correspond
to Allen’s relations begins, ends, overlaps, during, and after, and their inverse
relations. The semantics of such modalities can be given by their standard trans-
lations into ﬁrst-order logic:
STx,y(⟨B⟩ϕ) = x ≤y ∧∃z(z < y ∧STx,z(ϕ))
STx,y(⟨E⟩ϕ) = x ≤y ∧∃z(x < z ∧STz,y(ϕ))
STx,y(⟨O⟩ϕ) = x ≤y ∧∃z(x < z < y ∧∃y(y < x ∧STy,z(ϕ)))
STx,y(⟨D⟩ϕ) = x ≤y ∧∃z(x < z < y ∧∃y(x < y ∧STy,z(ϕ)))
STx,y(⟨L⟩ϕ) = x ≤y ∧∃x(y < x ∧∃ySTx,y(ϕ))
The standard translation of ⟨L⟩is a two-variable formula, while the standard
translations of the other modalities are three-variable formulas. By taking ad-
vantage of the translation from FO2[<] to PNLπ+, ⟨L⟩can be deﬁned in PNLπ+
as follows: ⟨L⟩ϕ = 3r(¬π ∧3rϕ). We show that the other interval modalities
cannot be deﬁned in PNLπ+ by a game-theoretic argument similar to the one
of Theorem 2. To this end, we deﬁne the k-round PNLπ+-bisimulation game
played on a pair of PNLπ+ models (M0
+, M1
+) starting from a given initial
conﬁguration as follows: the rules of the game are the same of the k-round PNL+-
bisimulation game described in Section 3; the only diﬀerence is that a conﬁgura-
tion ([a0, b0], [a1, b1]) constitutes a local isomorphism between M0
+ and M1
+ if
and only if (i) [a0, b0] and [a1, b1] share the same valuation of propositional vari-
ables, and (ii) a0 = b0 iﬀa1 = b1, that is, M0
+, [a0, b0] ⊩π iﬀM1
+, [a1, b1] ⊩π.
The following proposition is analogous to Proposition 1.
Proposition 2. Let P be a ﬁnite set of propositional letters. For all k ≥0,
Player II has a winning strategy in the k-round PNLπ+-bisimulation game on
M0
+ and M1
+ with initial conﬁguration ([a0, b0], [a1, b1]) iﬀ[a0, b0] and [a1, b1]
satisfy the same formulas of PNLπ+ over P with operator depth at most k.
We exploit Proposition 2 to prove that none of the interval modalities ⟨B⟩,
⟨E⟩, ⟨O⟩, and ⟨D⟩is expressible in PNLπ+. The proof structure is always the
same: for every operator ⟨X⟩, we choose two models M0
+ and M1
+ that can
be distinguished with a formula containing ⟨X⟩and we prove that Player II has
a winning strategy in the k-rounds PNLπ+-bisimulation game.
Theorem 8. Neither of ⟨B⟩, ⟨E⟩, ⟨O⟩, and ⟨D⟩can be deﬁned in PNLπ+.
Proof. We prove the claim for ⟨B⟩and ⟨D⟩; the other cases are analogous. Con-
sider the PNLπ+-models M0
+ = ⟨I(Z \ {1, 2})+, V0⟩and M1
+ = ⟨I(Z)+, V1⟩,

On Decidability and Expressiveness
97
where V1 is such that p holds for all intervals [a, b] such that a < b and V0
is the restriction of V1 to I(Z \ {1, 2})+. Note that M1
+, [0, 3] ⊩⟨B⟩p, while
M0
+, [0, 3] ̸⊩⟨B⟩p; likewise for ⟨D⟩p. Thus, to prove the claims it suﬃces to
show that Player II has a winning strategy for the k-round PNLπ+-bisimulation
game between M0
+ and M1
+, with initial conﬁguration ([0, 3], [0, 3]). In fact,
Player II has a uniform strategy to play forever that game: at any position,
assuming that Player I has not won yet, if he chooses a 3r-move then Player II
arbitrarily chooses a right-neighbor of the current interval on the other structure,
with the only constraint to take a point-interval if and only if Player I has taken
a point-interval as well. If Player I chooses a 3l-move, Player II acts likewise.
⊓⊔
7
Conclusions
In this paper we explored expressiveness and decidability issues for PNLs. First,
we compared PNLπ+ with PNL+ and PNL−, and we showed that the former
is strictly more expressive than the other two. Then, we proved that PNLπ+
is decidable by embedding it into FO2[<]. Next, we proved that PNLπ+ is as
expressive as FO2[<]. Finally, we compared PNLπ+ with other interval logics.
A number of open questions remain. To mention just two: Is the satisﬁability
problem for PNLπ+ over the classes of all discrete, dense, or Dedekind complete
linear orders decidable? Can we extend PNLπ+ with any modality in the set
{⟨B⟩, ⟨E⟩, ⟨O⟩, ⟨D⟩} to preserve decidability? We can foresee various natural
further developments stemming from the present work. In particular, the tableau
systems that have been developed in [2,3,4] for PNLs over speciﬁc structures,
such as N and Z, can be considered for adaptation to deal with FO2[<] over
these and related classes of linear orders. As for expressiveness, here we have only
partially explored the relationships between PNLs and other fragments of HS.
A comparison with instant-based temporal logics can be of interest as well. For
example, there is an obvious embedding of the standard instant-based temporal
logic TL[F,P] into PNLπ+. The (non-)existence of the opposite embedding is
more interesting, but also more diﬃcult to state in a precise way.
Acknowledgements
This work has been funded by the bilateral project “Temporal logics in com-
puter and information sciences”, supported by the Italian Ministero degli Af-
fari Esteri and the National Research Foundation of South Africa, under the
Joint Italy/South Africa Science and Technology Agreement. In addition, Da-
vide Bresolin and Angelo Montanari have been supported by the European IN-
TAS project on “Algebraic and Deduction Methods in Non Classical Logics and
their Applications to Computer Science” and the Italian PRIN project on “Con-
straints and preferences as a unifying formalism for system analysis and solution
of real-life problems”, while Guido Sciavicco has been funded by the Spanish

98
D. Bresolin et al.
Ministry of Education and Science (MEC) and the European Regional Develop-
ment Fund of the European Commission (FEDER), project IDEATIO, Ref. No.
TIN2006-15460-C04-01.
References
1. E. B¨orger, E. Gr¨adel, and Y. Gurevich. The Classical Decision Problem. Perspec-
tives of Mathematical Logic. Springer, 1997.
2. D. Bresolin and A. Montanari. A tableau-based decision procedure for Right Propo-
sitional Neighborhood Logic. In Proceedings of TABLEAUX 2005, volume 3702 of
LNAI, pages 63–77. Springer, 2005.
3. D. Bresolin, A. Montanari, and P. Sala.
An optimal tableau-based decision al-
gorithm for Propositional Neighborhood Logic. In Proceedings of STACS 2007,
volume 4393 of LNCS, pages 549–560. Springer, 2007.
4. D. Bresolin, A. Montanari, and G. Sciavicco. An optimal decision procedure for
Right Propositional Neighborhood Logic. Journal of Automated Reasoning, 2006.
DOI10.1007/s10817-006-9051-0.
5. K. Etessami, M. Y. Vardi, and T. Wilke. First-order logic with two variables and
unary temporal logic. Information and Computation, 179(2):279–295, 2002.
6. D. M. Gabbay, I. M. Hodkinson, and M. Reynolds. Temporal Logic: Mathematical
Foundations and Computational Aspects. Oxford University Press, 1994.
7. V. Goranko, A. Montanari, and G. Sciavicco. Propositional interval neighborhood
temporal logics. Journal of Universal Computer Science, 9(9):1137–1167, 2003.
8. V. Goranko, A. Montanari, and G. Sciavicco. A road map of interval temporal
logics and duration calculi. J. of Applied Non-Classical Logics, 14(1–2):9–54, 2004.
9. V. Goranko, A. Montanari, G. Sciavicco, and P. Sala. A general tableau method
for propositional interval temporal logics: Theory and implementation. Journal of
Applied Logic, 4(3):305–330, 2006.
10. V. Goranko and M. Otto. Model theory of modal logic. In P. Blackburn et al.,
editor, Handbook of Modal Logic, pages 249–329. Elsevier, 2007.
11. E. Gr¨adel, P. G. Kolaitis, and M. Y. Vardi.
On the decision problem for two-
variable ﬁrst-order logic. Bulletin of Symbolic Logic, 3(1):53–69, 1997.
12. J. Halpern and Y. Shoham. A propositional modal logic of time intervals. Journal
of the ACM, 38(4):935–962, 1991.
13. N. Immerman and D. Kozen. Deﬁnability with bounded number of bound variables.
Information and Computation, 83(2):121–139, 1989.
14. H. Kamp. Events, instants and temporal reference. In R. B¨auerle, U. Egli, and
C. Schwarze, editors, Semantics from diﬀerent points of view, pages 376–417. de
Gruyter, 1979.
15. K. Lodaya. Sharpening the undecidability of interval temporal logic. In Proc. of
6th Asian Computing Science Conference, volume 1961 of LNCS, pages 290–298.
Springer, 2000.
16. M. Mortimer. On languages with two variables. Zeitschr. f. math. Logik u. Grund-
lagen d. Math, 21:135–140, 1975.
17. B. Moszkowski. Reasoning about digital circuits. Tech. rep. stan-cs-83-970, Dept.
of Computer Science, Stanford University, Stanford, CA, 1983.
18. M. Otto. Two variable ﬁrst-order logic over ordered domains. Journal of Symbolic
Logic, 66(2):685–702, 2001.

On Decidability and Expressiveness
99
19. D. Scott. A decision method for validity of sentences in two variables. Journal of
Symbolic Logic, 27:377, 1962.
20. I. Shapirovsky and V. Shehtman.
Chronological future modality in Minkowski
spacetime. In P. Balbiani, N. Y. Suzuki, F. Wolter, and M. Zakharyaschev, editors,
Advances in Modal Logic, volume 4, pages 437–459. King’s College Publications,
London, 2003.
21. Y. Venema.
Expressiveness and completeness of an interval tense logic.
Notre
Dame Journal of Formal Logic, 31(4):529–547, 1990.
22. Y. Venema. A modal logic for chopping intervals. Journal of Logic and Computa-
tion, 1(4):453–476, 1991.

Reasoning About Sequences of Memory States⋆
Rémi Brochenin, Stéphane Demri, and Etienne Lozes
LSV, ENS Cachan, CNRS, INRIA
{brocheni,demri,lozes}@lsv.ens-cachan.fr
Abstract. In order to verify programs with pointer variables, we intro-
duce a temporal logic LTLmem whose underlying assertion language is
the quantiﬁer-free fragment of separation logic and the temporal logic on
the top of it is the standard linear-time temporal logic LTL. We analyze
the complexity of various model-checking and satisﬁability problems for
LTLmem, considering various fragments of separation logic (including
pointer arithmetic), various classes of models (with or without constant
heap), and the inﬂuence of ﬁxing the initial memory state. We provide
a complete picture based on these criteria. Our main decidability re-
sult is pspace-completeness of the satisﬁability problems on the record
fragment and on a classical fragment allowing pointer arithmetic. Σ0
1-
completeness or Σ1
1-completeness results are established for various prob-
lems by reducing standard problems for Minsky machines, and underline
the tightness of our decidability results.
1
Introduction
Veriﬁcation of programs with pointers. Model-checking of inﬁnite-state systems
is a very active area of formal veriﬁcation [BCMS01] even though in full gener-
ality, simple reachability questions are undecidable. Nevertheless, many classes
of inﬁnite-state systems can be analyzed, such as Petri nets, timed automata,
etc. Programs with pointer variables suﬀer the same drawback since reachability
problems are also undecidable, see e.g. [BFN04, BBH+06]. It is worth noting
that speciﬁc properties need to be veriﬁed for such programs, such as the exis-
tence of memory leaks, memory violation, or shape analysis. Prominent logics
for analyzing such programs are Separation Logic [Rey02], pointer assertion logic
PAL [JJKS97], TVLA [LAS00] and alias logic [BIL04], to quote a few examples.
Temporal Separation Logic: what for? Since [Pnu77], temporal logics are also
used as languages for formal speciﬁcation of programs. General and powerful
automata-based techniques for veriﬁcation have been developed, see e.g. [VW94].
On the other hand, Separation Logic is a static logic for program annota-
tion [Rey02], and more recently for symbolic computation [BCO05]. Extending
the scope of application of Separation Logic to standard temporal logic-based
veriﬁcation techniques has many potential interests. First, it provides a rich un-
derlying assertion language where properties more complex than accessibility
⋆Work supported by the RNTL project “AVERILES”. The ﬁrst author is supported
by a fellowship from CNRS/DGA.
S. Artemov and A. Nerode (Eds.): LFCS 2007, LNCS 4514, pp. 100–114, 2007.
c
⃝Springer-Verlag Berlin Heidelberg 2007

Reasoning About Sequences of Memory States
101
can be stated. Second, this probably yields a signiﬁcant feedback for the purely
static Separation Logic extended with general recursion, which has not been very
studied up to now. For instance, if we write Xx to denote the next value of x
(also sometimes written x′), the formula (x →Xx)U(x →null), understood
on a model with constant heap, characterises the existence of a simple ﬂat list,
which is usually written μL(x). x →null ∨∃x′.x →x′ ∧L(x′). Third, temporal
logics allow to work in the very convenient framework of "programs-as-formulae"
and decision procedures for logical problems can be directly used for program
veriﬁcation. For instance, the previous formula can be seen as a program walk-
ing on a list, and more generally programs without destructive updates can be
expressed as formulae. Some programs with destructive updates that perform a
simple pass on the heap, have an input-output relation that may be described by
a formula. For instance, the formula (x →0 Xx∧Xx →1 x)Ux →0 null expresses
broadly that the list in initial heap h0 is reversed in ﬁnal heap h1. Fourth, pointer
arithmetic has been poorly studied until now, whereas arithmetical constraints
in temporal logics are known to lead to undecidability, see e.g. [CC00]. Actually,
there is a growing interest in understanding the interplay of pointer arithmetic,
temporal reasoning, and non aliasing properties.
Our contribution. We introduce a linear-time temporal logic LTLmem to spec-
ify sequences of memory states with underlying assertion language based on
quantiﬁer-free Separation Logic [Rey02]. From a logical perspective, the logic
LTLmem can be viewed as a many-dimensional logic [GKWZ03] since LTLmem
contains a temporal dimension and the spatial dimension for memory states.
Our logic addresses a very general notion of models, including the aspects of
pointer arithmetic and recursive structures with records. We distinguish the
satisﬁability problems from the model-checking problems, as well as distinct
subclasses of interesting programs, like for instance the programs without de-
structive update. The result that is the most promising for future implemen-
tation is the pspace-completeness of the satisﬁability problems SAT(CL) and
SAT(RF) where CL is the classical fragment without separation connectives and
RF is the record fragment with no pointer arithmetic but with separation connec-
tives. This result is very tight, as both propositional LTL and static Separation
Logic are already pspace-complete [SC85, CYO01]. These results are obtained
by reduction to the nonemptiness problem for Büchi automata on an alphabet
of symbolic memory states obtained by an abstraction that we show sound and
complete, see e.g. [Loz04, CGH05]. Such abstractions are similar to resource
graphs from [GM05]. This is a variant of the automata-based approach intro-
duced in [VW94] for plain LTL and further developed with concrete domains of
interpretation in [DD07]. Surprisingly, the abstraction method used to establish
these results does not scale to the whole logic, due to a subtle interplay between
separation connectives and pointer arithmetic. Moreover, we provide new un-
decidability results for several problems, for instance SATct(LF) (satisﬁability
with constant heap on the list fragment).

102
R. Brochenin, S. Demri, and E. Lozes
Related work. Previous temporal logics designed for pointer veriﬁcation include
Evolution Temporal Logic [YRSW03], based on the three-valued logic abstrac-
tion method that made the success of TVLA [LAS00], and Navigation temporal
logic [DKR04], based on a tableau method quite similar to our automaton-based
reduction. In these works, the assertion language for states is quite rich, as it
includes for instance list predicate, quantiﬁcation over adresses, and a freshness
predicate. Because of this high expressive power, only incomplete abstractions
are proposed, whereas we stick to exact methods. More importantly, our work
addresses models with constant heaps and pointer arithmetic, which has not
been done so far, and leads to a quite diﬀerent perspective.
Omitted proofs can be found in the report [BDL07].
2
Memory Model and Speciﬁcation Language
In this section, we introduce a separation logic dealing with pointer arithmetic
and record values, and a temporal logic LTLmem. Unlike BI’s pointer logic from
[IO01], we allow pointer arithmetic. Model-checking programs with pointer vari-
ables over LTLmem speciﬁcations is our main problem of interest.
2.1
A Separation Logic with Pointer Arithmetic
Memory states. Let us introduce our model of memory. It captures features of
programs with pointer variables that use pointer arithmetic and records. We
assume a countably inﬁnite set Var of variables (as usual, for a ﬁxed formula we
need only a ﬁnite amount), and an inﬁnite set Val of values containing the set N
of naturals, thought as address indexes, and a special value nil. For simplicity, we
assume that Val = N⊎{nil}. In order to model ﬁeld selectors, we consider some
inﬁnite set Lab of labels. We will usually range over values with u, v, over naturals
with i, j, over labels with l, r, next, prev, and over variables with x, y. In the
remainder, we will assume some ﬁxed injection (x, i) ∈Var × N →⟨x, i⟩∈Var.
We use the notation E ⇀fin F for the set of partial functions from E to F
of ﬁnite domain; and E ⇀fin+ F for the set of partial functions from E to F
of ﬁnite and nonempty domain. The sets S of stores and H of heaps are then
deﬁned as follows: S
def
≡Var →Val and H
def
≡N ⇀fin (Lab ⇀fin+ Val). We will
range over a store with s, s′ and over a heap with h, h′, h1, h2. We call memory
state a couple (s, h) ∈S × H.
We will refer to the domain of a heap h by dom(h) ⊆N. Intuitively, in our
memory model, each index is thought as an entry point on some record cell
containing several ﬁelds. Cells are either not allocated, or allocated with some
record stored in. In a memory state (s, h), the memory cell at index i is allocated
if i ∈dom(h); in this case the stored record is h(i) = {l1 →v1, .., ln →vn}.
Note that the size of the information held in a memory cell is not ﬁxed,
nor bounded. Our models could be more concrete considering labels as oﬀsets
and relying on pointer arithmetic. But for our purpose, it will be convenient to
consider pointer arithmetic independently.

Reasoning About Sequences of Memory States
103
Table 1. The syntax and semantics of SL with pointer arithmetic and records
Expressions
e ::= x | null
Atomic formulae
π ::= e = e′ | e + i
l→e
State Formulae
A ::= π
| A ∗B | A−∗B | emp
(spatial fragment)
| A ∧B | A →A | ⊤| ⊥(classical fragment)
Satisfaction
(s, h) |=SL e = e′
iﬀ e s =  e′ s, with  x s = s(x) and  null s = nil
(s, h) |=SL e + i
l→e iﬀ e s ∈N and  e  + i ∈dom(h) and h(s(x) + i)(l) =  e s
(s, h) |=SL emp
iﬀdom(h) = ∅
(s, h) |=SL A1 ∗A2
iﬀ∃h1, h2 s.t. h = h1 ∗h2, (s, h1) |=SL A1 and (s, h2) |=SL A2
(s, h) |=SL A′−∗A
iﬀfor all h′, if h ⊥h′ and (s, h′) |=SL A′ then (s, h ∗h′) |=SL A
(s, h) |=SL A1 ∧A2
iﬀ(s, h) |=SL A1 and (s, h) |=SL A2
(s, h) |=SL A′ →A
iﬀ(s, h) |=SL A′ implies (s, h) |=SL A
(s, h) |=SL ⊥
never and (s, h) |=SL ⊤always
Separation Logic. We now introduce the separation logic (SL) on top of which
we will deﬁne our temporal logic. The syntax of the logic is given in Table 1.
In short, Separation logic is about reasoning on disjoint heaps, and we need
to deﬁne what we mean by “disjoint heaps” in our model. We choose to allow
to reason at the granularity of record cells, so that a record cell cannot be
decomposed in disjoint parts. Let h1 and h2 be two heaps; we say that h1 and
h2 are disjoint, noted h1⊥h2, if dom(h1) ∩dom(h2) = ∅. The operation h1 ∗h2
is deﬁned for disjoint heaps as the disjoint union of the two partial functions.
Semantics of formulae is deﬁned by the satisfaction relation |=SL (see Table 1).
Formulae A of SL are called state formulae. The size of the state formula A,
written |A|, is the length of the string A for some reasonably succinct encoding of
variables and integers (binary representation). We will use the map | · | for other
syntactic objects such as LTLmem formulae. A formula A∗B with the separation
conjunction states that A holds on some portion of the memory heap and B
holds on a disjoint portion. A formula A−∗B states that the current heap, when
extended with any disjoint heap verifying A, will verify B. Boolean operators are
understood as usual. In the remainder, we focus on several speciﬁc fragments
of this separation logic. We say that a formula is in the record fragment (RF)
if all subformulae x + i
l→e use i = 0. In that case, we write x
l→e. We say
that a formula is in the classical fragment (CL) if it does not use the connectives
∗, −∗. Finally, we say that a formula is in the list fragment (LF) if it is in the
classical fragment and all subformulae x + i
l→e use i = 0 and l = next, and
we may simply write x →e. Clearly, the classical and record fragments are
incomparable, while the list fragment is included in both of them.
Let us illustrate the expressive power of SL on examples. The formula ¬emp ∗
¬emp means that at least two memory cells are allocated. The formula x
l→e,
deﬁned as ¬(¬emp ∗¬emp) ∧x
l→e, is the local version of x
l→e: s, h |=SL x
l→e
iﬀdom(h) = {s(x)} and h(s(x))(l) =  e s. The formula (x
l→null)−∗⊥is

104
R. Brochenin, S. Demri, and E. Lozes
satisﬁed at (s0, h0) whenever there is no heap h1 with h1⊥h0 that allocates the
variable x to nil on l ﬁeld, that is x is allocated in h0.
A is valid iﬀfor every memory state (s, h), we have (s, h) |=SL A (written
|=SL A). Satisﬁability is deﬁned dually.
Proposition 1. The model-checking, satisﬁability and validity problems for SL
are pspace-complete.
pspace-hardness results are consequences of [CYO01, Sect. 5.2]. The pspace up-
per bound for model-checking for SL is obtained by reduction to model-checking
for RF that is shown in pspace thanks to forthcoming Lemma 2. Satisﬁability
for SL is reduced to model-checking for SL thanks to a small memory state prop-
erty: every satisﬁable state formulae A can be satisﬁed by a memory state that
can be encoded in polynomial size in A.
2.2
Temporal Extension
Memory states sequences. Models of the logic LTLmem are ω-sequences of mem-
ory states, that is elements in (S × H)ω and they are understood as inﬁnite
computations of programs with pointer variables. In order to analyze computa-
tions from programs without destructive update, we shall also consider models
with constant heap, that is elements in Sω × H.
The logic LTLmem. Formulae of LTLmem are deﬁned in Table 2. Atomic formulae
of LTLmem are state formulae from SL except that variables can be preﬁxed
by the symbol “X”. For instance, Xx is interpreted by the value of x at the
next memory state. We use the notation Xix for
i times
  
X . . . X x (but keep in mind
that encoding Xix requires memory space in O(i)). The temporal operators are
the standard next-time operator X and until operator U present in LTL, see
e.g. [SC85]. The satisfaction relation ρ, t |= φ where ρ is a model of LTLmem,
t ∈N and φ is a formula is also deﬁned in Table 2. We use standard abbreviations
such as Fφ, Gφ . . .
We freely use propositional variables p, q, having in mind that the proposi-
tional variable p should be understood as xp = x⊤for some ﬁxed extra variables
xp, xq, . . . , x⊤.
Given a fragment Frag of SL, LTLmem(Frag) is the restriction of LTLmem
to formulae in which occur only state formulae built over Frag (with extended
variables Xix), and we write SAT(Frag) to denote the satisﬁability problem for
LTLmem(Frag): given a temporal formula φ in LTLmem(Frag), is there a model
ρ such that ρ, 0 |= φ? The variant problem in which we require that the model
has a constant heap [resp. that the initial memory state is ﬁxed, say (s, h)] is
denoted by SATct(Frag) [resp. SATinit(Frag)]. The problem SATct
init(Frag) is
deﬁned analogously.

Reasoning About Sequences of Memory States
105
Table 2. The syntax and semantics of LTLmem
Enriched expressions η ::= x | Xη | null
Atomic formulae
π ::= η = η′ | η + i
l→η′
State formulae
A ::= π | emp | A ∗B | A−∗B | A ∧B | A →B | ⊥
Temporal formulae
φ ::= A | Xφ | φUφ′ | φ ∧φ′ | ¬φ
Semantics
ρ, t |= Xφ
iﬀρ, t + 1 |= φ.
ρ, t |= φUφ′ iﬀthere is t1 ≥t s.t. ρ, t1 |= φ′ and ρ, t′ |= φ for all t′ ∈{t, .., t1 −1}.
ρ, t |= φ ∧ψ iﬀρ, t |= φ and ρ, t |= ψ.
ρ, t |= ¬φ
iﬀρ, t ̸|= φ.
ρ, t |= A
iﬀs′
t, ht |=SL A[Xkx ←(x, k)]
where ρ = (st, ht)t≥0 and
s′
t is deﬁned by s′
t(⟨x, k⟩) = st+k(x).
2.3
Programs with Pointer Variables
In this section, we deﬁne the model-checking problems for programs with pointer
variables over LTLmem speciﬁcations. The set I of instructions used in the pro-
grams is deﬁned by the grammar below:
instr ::= x := y | skip
| x := y →l | x →l := y | x := cons(l1 : x1, .., lk : xk) | free x
| x := y[i] | x[i] := y | x = malloc(i) | free x, i
The denotational semantics of an instruction instr is deﬁned as a partial
function  instr  : S × H →S × H, undeﬁned when the instruction would
cause a memory violation. We list in Table 3 the formal denotational semantics
of our instruction set. Boolean combinations of equalities between expressions
are called guards and its set is denoted by G. A program is deﬁned as a triple
(Q, δ, qI) such that Q is a ﬁnite set of control states, qI is the initial state and δ
is the transition relation, a subset of Q×G×I×Q. We use q
g,instr
−−−→q′ to denote
a transition. We say that a program is without destructive update if transitions
are labeled only with instructions of the form x := y, x := y →l, and x := y[i].
We write P to denote the set of programs and Pct to denote the set of programs
without destructive update.
A program is a ﬁnite object whose interpretation can be viewed as an inﬁnite-
state system. More precisely, given a program p = (Q, δ, qI), the transition sys-
tem Sp = (S, →) is deﬁned as follows: S = Q × (S × H) (set of conﬁgurations)
and (q, (s, h)) →(q′, (s′, h′)) iﬀthere is a transition q
g,instr
−−−→q′ ∈δ such that
(s, h) |= g and (s′, h′) =  instr (s, h). Note that Sp is not necessarily linear.
A computation (or execution) of p is deﬁned as an inﬁnite path in Sp starting
with control state qI. Computations of p can be viewed as LTLmem models, using
propositional variables to encode the extra information about the control states
(details are omitted herein).

106
R. Brochenin, S. Demri, and E. Lozes
Table 3. Semantics for instructions
 x := y  (s, h)
def
≡
(s[x →s(y)], h).
 x := y →l  (s, h ∗{i →{l →v, . . . }})
def
≡
(s[x →v], h ∗{i →{l →v, . . . }})
with s(y) = i
 x →l := y  (s, h ∗{i →{l →v, . . . }})
def
≡
(s, h ∗{i →{l →s(y), . . . }})
with s(x) = i
 x := cons(l1 : x1, .., lk : xk)  (s, h)
def
≡

s[x →i], h ∗{i →{l1 →s(x1),
. . . , lk →s(xk)}}

with i ̸∈dom(h)
 free x, l  (s, h ∗{i →{l →v, . . . }})
def
≡
(s, h ∗{i →{. . . }})
with s(x) = i
 skip  (s, h)
def
≡
(s, h)
 x := y[i]  (s, h ∗{i + i′ →{next →v}})
def
≡
(s[x →v], h ∗{i →{next →v}}))
with s(y) = i′
 x[i] := y  (s, h ∗{i′ + i →{next →v}})
def
≡
(s, h ∗{i + i′ →{next →s(y)}})
with s(x) = i′
 x := malloc(i) (s, h)
def
≡

s[x →i′], h ∗{i′ →{next →nil}}
∗. . . ∗{i′ + i →{next →nil}

with i′, .., i′ + i ̸∈dom(h)
 free x, i  (s, h ∗{i′ + i →f})
def
≡
(s, h) with s(x) = i′
Model-checking aims at checking properties expressible in LTLmem along com-
putations of programs. To a logical fragment (SL, CL, RF, or LF), we associate
a set of programs : all programs for SL and CL, programs with instructions hav-
ing i = 0 for RF, and moreover with only the label next for LF. Given one of
these fragments Frag of SL, we write MC(Frag) to denote the model-checking
problem for Frag: given a temporal formula φ in LTLmem with state formulae
built over Frag and a program p of the associated fragment, is there an inﬁnite
computation ρ of p such that ρ, 0 |= φ (which we write p |= φ)? The variant
problem in which we require that the program is without destructive update
[resp. that the initial memory state is ﬁxed, say (s, h)] is denoted by MCct(Frag)
[resp. MCinit(Frag)]. The problem MCct
init(Frag) is deﬁned analogously. We may
write p, (s, h) |= φ to emphasize what is the initial memory state.
All the model-checking and satisﬁability problems deﬁned above can be placed
in Σ1
1 in the analytical hierarchy. Additionnally, all the above problems can easily
be shown pspace-hard since they all generalize LTL satisﬁability and model-
checking [SC85].
Using extended variables Xx, we may express some programs as formulae.
This actually holds only for programs without update, for the semantics with
constant heap. Intuitively, we express the control of the program with propo-
sitional variables, and deﬁne a formula that encode the transitions. To do so,
we translate instructions of the form x := y into Xx = y, x := y →l into

Reasoning About Sequences of Memory States
107
y
l→Xx, and x := y[i] into y + i →Xx. Guards are translated accordingly. As a
consequence, the following result can be derived:
Lemma 1. Let Frag be a fragment among SL, CL, RF, or LF. There is a
logspace reduction from MCct(Frag) to SATct(Frag) (resp. from MCct
init(Frag)
to SATct
init(Frag)).
3
Decidable Satisﬁability Problems by Abstracting
Computations
In this section we establish the pspace-completeness of the problems SAT(CL)
and SAT(RF). To do so, we abstract memory states whose size is a priori un-
bounded by ﬁnite symbolic memory states. As usual, temporal inﬁnity in mod-
els is handled by Büchi automata recognizing ω-sequences. We propose below
an abstraction that is correct for CL (allowing pointer arithmetic) and for RF
(allowing all operators from Separation Logic) taken separately but that is not
exact for the full language SL.
3.1
Syntactic Measures
The main approach to get decision procedures to verify inﬁnite-state systems
consists in introducing a symbolic representation for inﬁnite sets of conﬁgura-
tions. The symbolic representation deﬁned below plays a similar role and has
similarities with symbolic heaps for Separation Logic in Smallfoot [BCO05]. Let
us start by some useful deﬁnitions. Following [Loz04], we introduce the set of
test formulae that are formulae from SL of the forms below:
– alloc x
def
≡(x
next
→null)−∗⊥(x is allocated).
– size ≥k
def
≡
k times



¬emp ∗. . . ∗¬emp (at least k indices are allocated).
– e + i
l→e, e = e′.
Given a formula φ of LTLmem, we deﬁne its measure μφ understood as some
pieces of information about the syntactic resources involved in φ. Indeed, forth-
coming symbolic states are ﬁnite objects parameterized by such syntactic
measures.
For a state formula A of LTLmem, the size of memory examined by A, written
wA, is inductively deﬁned as follows: wA is 1 for atomic formulae, max{wA1, wA2}
for A1 ∧A2 or A1 →A2 or A1−∗A2, and wA1 + wA2 for A1 ∗A2. Observe that
wA ≤|A|. Other simple sets about the syntactic resources of A need to be deﬁned:
LabA is the set of labels from Lab occurring in A, VarA is the set of variables from
Var occurring in A, ϵA is the set of natural numbers i such that e + i
l→e′ occurs
in A and mA is the maximal k such that Xkx occurs in A for some variable x. A
measure is deﬁned as an element of N × Pf(N) × N × Pf(Lab) × Pf(Var) where
Pf(X) denotes the set of ﬁnite subsets of some set X. The set of measures has
a natural lattice structure for the pointwise order, noted below μ ≤μ′. We also
write μ[w ←0] to denote the measure μ except that w = 0.

108
R. Brochenin, S. Demri, and E. Lozes
The measure for A, written μA, is the tuple (mA, ϵA, wA, LabA, VarA). The
measure of some formula φ of LTLmem, written μφ, is sup{μA : A occurs in φ}.
Deﬁnition 1. Given a measure μ = (m, ϵ, w, X, Y ), we write Tμ to denote the
ﬁnite set of test formulae ψ of the grammar:
e ::= ⟨x, u⟩| null
f ::= e + i
ψ ::= f
l→e | alloc f | e = e′ | size ≥k
with u ≤m, i ∈ϵ, l ∈X, k < w and x ∈Y .
Observe that the cardinal of Tμφ is polynomial in |φ|. Given a measure μ =
(m, ϵ, w, X, Y ) and a memory state (s, h), we write Absμ(s, h) = {A ∈Tμ :
(s, h) |=SL A} to denote the abstraction of (s, h) wrt μ. Given a measure μ and
two memory states (s, h) and (s′, h′), we write (s, h) ≃μ (s′, h′) iﬀAbsμ(s, h) =
Absμ(s′, h′), that is formulae in Tμ cannot distinguish the two memory states.
Lemma 2 below states that our abstraction is correct for CL and RF.
Lemma 2. Let (s, h) and (s′, h′) be two memory states such that (s, h) ≃μ
(s′, h′) [resp. (s, h) ≃μ[w←0] (s′, h′)]. For any state formula A such that μA ⩽μ
and A belongs to RF [resp. CL], we have (s, h) |=SL A iﬀ(s′, h′) |=SL A.
Note that we can extend this result to the whole SL by considering test formulae
of the form e + i = e′ + j.
3.2
Symbolic Models
We write Σμ to denote the powerset of Tμ; Σμ is thought as an alphabet, and
elements a ∈Σμ are called letters. A symbolic model wrt μ is deﬁned as an
inﬁnite sequence σ ∈Σω
μ. Symbolic models are abstractions of models from
LTLmem: given a model ρ : N →S × H and a measure μ, we write Absμ(ρ) :
N →Σμ to denote the symbolic model wrt μ such that for any t, Absμ(ρ)(t)
def
=
{A ∈Tμ : ρ, t |= A[⟨x, u⟩←Xux]}.
To a letter a, we associate the formula Aa = 
A∈a A ∧
A̸∈a ¬A. For σ a
symbolic model, and φ a formula such that μφ ≤μ, we deﬁne the symbolic sat-
isfaction relation σ, t |=μ φ as satisfaction for models except for the clause about
atomic subformulae that becomes: σ, t |=μ A iﬀ|=SL Aσ(t) ⇒A[Xux ←⟨x, u⟩].
We write Lμ(φ) to denote the set of symbolic models σ wrt μ such that σ, 0 |=μ φ.
As a corollary of Lemma 2, we get a soundness result for our abstraction:
Proposition 2. Let φ be a formula of LTLmem(RF) [resp. of LTLmem(CL)]
and μφ ≤μ. For any model ρ, we have that ρ |= φ iﬀAbsμ(ρ) |= φ [resp.
Absμ[w←0](ρ) |= φ].
Note that Absμ is not surjective; we note Lμ
sat the set of symbolic models wrt μ
that are abstractions of some model of LTLmem. Consequently, φ in LTLmem(RF)
is satisﬁable iﬀLμφ(φ) ∩Lμφ
sat is nonempty.

Reasoning About Sequences of Memory States
109
3.3
ω-Regularity and pspace Upper Bound
In order to show that SAT(RF) and SAT(CL) are in pspace we shall explain why
testing the nonemptiness of Lμφ(φ)∩Lμφ
sat can be done in pspace. Below we treat
explicitly the case for RF. For CL, replace every occurrence of μφ by μφ[w ←0].
To do so, we show that each language can be recognized by an exponential-size
Büchi automaton satisfying the good properties to establish the pspace upper
bound. If A is a Büchi automaton, we note L(A) the language recognized by A.
Following [VW94, DD07], let A be the generalized Büchi automaton deﬁned by
the structure (Σ, Q, δ, I, F) s.t.:
– Q is the set of so-called atoms of φ, that are sets of temporal formulae
included in the so-called closure set cl(φ) (see [VW94]), I = {X ∈Q : φ ∈
X}, and Σ = Σμ.
– X
a−→Y iﬀ1. for every atomic formula A of X, |=SL Aa⇒A[Xux ←⟨x, u⟩].
2. for every Xφ′ ∈cl(φ), Xφ′ ∈X iﬀφ′ ∈Y .
– Let {φ1Uφ′
1, . . . , φnUφ′
n} be the set of until formulae in cl(φ). We pose F =
{F1, . . . , Fn} where Fi = {X ∈Q : φiUφ′
i ̸∈X or φ′
i ∈X} for i ∈{1, . . ., n}.
Let Aμ
φ be the Büchi automaton equivalent to the generalized Büchi automaton
A. It is easy to observe that Aμφ
φ
has an exponential amount of states in the size
of φ and its transition relation can be checked in polynomial space in the size of
φ. Moreover,
Lemma 3. Let φ in LTLmem(RF) [resp. LTLmem(CL)] and μ ≥μφ [resp. μ ≥
μφ[w ←0]]. Then, L(Aμ
φ) = Lμ(φ).
We can also build a Büchi automaton Aμ
sat such that L(Aμ
sat) = Lμ
sat. Aμ
sat is
deﬁned as (Σ, Q, δ, I, F), where Σ = Σμ, Q = Σμ, F = I = Q and a
a′
−→a′′ iﬀ:
1. Aa, Aa′′ are satisﬁable, and a = a′,
2. for every formula ⟨x, u⟩= ⟨x′, u′⟩∈Tμ with u, u′ ≥1, ⟨x, u⟩= ⟨x′, u′⟩∈a iﬀ
⟨x, u −1⟩= ⟨x′, u′ −1⟩∈a′′.
If μ = μφ, then Aμ
sat is of exponential-size in |φ| and the transition relation
can be checked in polynomial space in |φ|. More importantly, this automaton
recognizes satisﬁable symbolic models.
Lemma 4. Let φ in LTLmem(RF) [resp. LTLmem(CL)] and μ = μφ [resp. μ =
μφ[w ←0]]. Then, L(Aμ
sat) = Lμ
sat.
This lemma is essential and it is not possible to extend it to the whole logic
LTLmem even by allowing test formulae of the form x + i = y + j since we would
need automata with counters. Now, we can state our main complexity result.
Theorem 1. SAT(RF) and SAT(CL) are pspace-complete.
Proof. (sketch) The lower bound is from LTL [SC85]. Let φ be an instance
formula of SAT(RF) (for SAT(CL) replace below μφ by μφ[w ←0]). As seen

110
R. Brochenin, S. Demri, and E. Lozes
earlier, φ is satisﬁable iﬀLμφ(φ) ∩Lμφ
sat is nonempty. Hence, φ is satisﬁable iﬀ
L(Aμφ
φ ) ∩L(Aμφ
sat) ̸= ∅. The intersection automaton is of exponential size in the
size of φ and can be checked nonempty by a nondeterministic on-the-ﬂy algo-
rithm. Since nonemptiness problem for Büchi automata is nlogspace-complete
and the transition relation in the intersection automaton can be checked in poly-
nomial space in |φ|, we obtain a nondeterministic polynomial space algorithm
for testing satisﬁability of φ. By Savitch’s theorem, we get the pspace upper
bound.
⊓⊔
3.4
Other Problems in pspace
Let Frag be either the classical fragment or the record fragment. Lemma 1 pro-
vides a reduction from MCct
init(Frag) to SATct
init(Frag) based on a program-as-
formula encoding. As we will see now, we may also reduce SATct
init(Frag) to
SAT(Frag) internalizing an approximation of the initial memory state whose
logical language cannot distinguish from the initial memory state. As a conse-
quence, the pspace upper bound for SAT(Frag) entails the pspace upper bound
for both SATct
init(Frag) and MCct
init(Frag).
Proposition 3. The problems SATct
init(RF), MCct
init(RF), SATct
init(CL) and
MCct
init(CL) are pspace-complete.
Proof. By Lemma 1 and since SATct
init(RF) is known to be pspace-hard, it
remains to establish the pspace upper bound for SATct
init(RF).
Given a formula φ and an initial memory state (s, h), we shall build in
polynomial-time a formula φct
s,h in SAT(RF) such that φ is satisﬁable in a model
with initial memory state (s, h) and constant heap iﬀφct
s,h is satisﬁable by a
general model. Since we have shown that SAT(RF) is in pspace, this guarantees
that SATct
init(RF) is in pspace. The idea of the proof is to internalize the initial
memory state and the fact that the heap is constant in the logic SAT(RF). Ac-
tually, one cannot exactly express that the heap is constant (see details below)
but the approximation we use will be suﬃcient for our purpose.
Apart from the variables of φ, the formula φct
s,h is built over additional variables
in V = {xi : i ∈dom(h) ∪Im(s)} ∪{xi,l : i ∈dom(h), l ∈dom(h(i))}. The formula
φct
s,h is of the form G(ψ1 ∧ψ2 ∧ψ3) ∧ψs ∧ψ′, where the subformulae are deﬁned
as follows.
– ψ1 states that the heap is almost equal to h since we cannot forbid in the
logical language additional labels (dom(h) = {i1, . . . , ik}):
ψ1
def
= (
l∈dom(h(i1)) xi1
l→xi1,l) ∗. . . ∗(
l∈dom(h(ik)) xik
l→xik,l).
– ψ2 states which variables are equal and which ones are not, depending on
the initial memory state. By way of example, for i ̸= j ∈dom(h), a conjunct
of ψ2 is xi ̸= xj. Similarly, if h(i)(l) = j and j ∈dom(h) then xi,l = xj is a
conjunct of ψ2. Details are omitted.
– ψ3 states that the auxiliary variables remain constant: 
x∈V x = Xx.

Reasoning About Sequences of Memory States
111
– The formula ψ′ is obtained from φ by replacing each occurrence of x
l→e by
x
l→e ∧
	
i∈dom(h),l̸∈dom(h(i))
x ̸= xi.
The additional conjunct is useful because our logical language cannot state
that a label is not in the domain of some allocated address.
– ψs states constraints about the initial store s: ψs
def
= 
x∈φ x = xs(x).
It is then easy to check that φ is satisﬁable in a model with initial memory
state (s, h) with constant heap iﬀφct
s,h is satisﬁable by a general model.
As far as the results for the classical fragment are concerned, by Lemma 1,
there is a logspace reduction from MCct
init(CL) to SATct
init(CL) and as done above
one can reduce SATct
init(CL) to SAT(CL).
⊓⊔
4
Undecidability Results
In this section, we show several undecidability results by using reduction from
problems for Minsky machines. So, ﬁrst, we recall that a Minsky machine M
consists of two counters C1 and C2, and a sequence of n ≥1 instructions, each
of which may increment or decrement one of the counters, or jump conditionally
upon of the counters being zero. The lth instruction (l is its location counter)
has one of the following forms either “l: Ci := Ci + 1 ; goto l′” or “l: if Ci = 0
then goto l′ else Ci := Ci −1; goto l′′”. In a nondeterministic machine, after an
incrementation or a decrementation a nondeterministic choice of the form “goto
l1 or goto l2” is performed.
The conﬁgurations of M are triples (l, c1, c2), where 1 ≤l ≤n, c1 ≥0, and
c2 ≥0 are the current values of the location counter and the two counters C1
and C2, respectively. The consecution relation on conﬁgurations is deﬁned in
the obvious way. A computation of M is a sequence of related conﬁgurations,
starting with the initial conﬁguration (1, 0, 0).
Diﬀerent encodings of counters are used here. For instance, in [BFLS06], a
counter C with value n is represented by a list of length n pointed to by a x
dedicated to C. The same idea is used in the proof of Proposition 4 below. In order
to show undecidability of SAT(SL) we alternatively encode counters by relying
on pointer arithmetic and properties of heaps. Programs without destructive
updates can simulate ﬁnite computations of Minsky machines by guessing at the
start of the computation the maximal value of counters (encoded by a list of the
length of the maximal value). As a consequence,
Proposition 4. SATct(LF) and MCct(LF) are Σ0
1-complete.
By constrast, programs with destructive update can work with unbounded heaps,
and by using the representation of counters as above, they can faithfully simulate
a Minsky machine even if an empty heap is the initial heap. Because LTL can
express repeated accessibility, Σ1
1-hardness can be obtained.

112
R. Brochenin, S. Demri, and E. Lozes
Proposition 5. The problems MC(LF) and MCinit(LF) are Σ1
1-complete.
Let us brieﬂy explain how to encode incrementation and decrementation with
separating connectives and pointer arithmetic. Observe that expressions of the
form x = y + 1 are not allowed in the logical language. We solve this point in
two diﬀerent ways: using non-aliasing expressed by the separating conjunction,
and using the precise pointing assertion x
next
→η stating that the heap contains
only one cell, in conjunction with the −∗operator.
φ∗
x++ = (Xx
next
→null ∧x + 1
next
→null) ∧¬(Xx
next
→null ∗x + 1
next
→null)
φ∗
x−−= (Xx + 1
next
→null ∧x
next
→null) ∧¬(Xx + 1
next
→null ∗x
next
→null)
φ−∗
x++ = emp
∧

(Xx
next
→null)−∗x + 1
next
→null

φ−∗
x−−= emp
∧

(x
next
→null)−∗Xx + 1
next
→null

The formulae based on the separating conjunction correctly express incremen-
tation and decrementation when the cells at index x, x + 1, x −1 are allocated,
whereas formulae based on the operator −∗do not need the same assumption.
Let SAT?
?(SL) be any satisﬁability problem among the four variants.
Proposition 6. SAT?
?(SL) is Σ1
1-complete.
Proof. We reduce the recurrence problem for nondeterministic Minsky machines
[AH94] to SAT?
?(SL). Let φ0 be the formula G(emp ∧2
i=1(xi ̸= null)). In-
crementation and decrementation are performed thanks to φ−∗
x++ and φ−∗
x−−,
respectively. For any model ρ such that ρ, 0 |= φ0, and for any t, we have
ρ, t |= φ−∗
xi++ iﬀst(xi) + 1 = st+1(xi). Hence, we have a means to encode in-
crementation. Similarly, ρ, t |= φ−∗
xi−−and st(xi) > 0 iﬀst(xi) −1 = st+1(xi).
The fact that a counter does not change is encoded by xi = Xxi. Given that
φ1 = G(xzero = Xxzero ∧xzero ̸= null) holds, zero tests are encoded by
xi = xzero.
Given a nondeterministic Minsky machine M, we write ψl to denote the for-
mula encoding instruction l. For intance for the instruction “l: if C1 = 0 then goto
l′ else C1 := C1 −1; goto l′
1 or goto l′
2” ψl is equal to G((l ∧x1 ̸= xzero) ⇒(x2 =
Xx2 ∧(Xl′
1 ∨Xl′
2) ∧φ−∗
x1−−)) ∧G((l ∧x1 = xzero) ⇒(x1 = Xx1 ∧x2 = Xx2 ∧Xl′)).
Hence, (x1 = x2 = xzero) ∧φ0 ∧φ1 ∧
l ψl ∧GFn is satisﬁable iﬀM has a com-
putation with location counter n repeated inﬁnitely often.
⊓⊔
Proposition 7. The problem SAT(SL \ {−∗}) is Σ1
1-complete.
The proof of Proposition 7 is similar to the proof of Theorem 6 except that
incrementation and decrementation are performed with the formulae φ∗
x++ and
φ∗
x−−, respectively.
5
Conclusion
In the paper, we have introduced a temporal logic LTLmem for which assertion
language is quantiﬁer-free separation logic. Figure 1 contains a summary of the

Reasoning About Sequences of Memory States
113
SAT(LF)
SATct
init(LF)
MCct
init(LF)
SATct(LF)
SATct
init(CL)
MCct
init(CL)
SATct
init(RF)
MCct
init(RF)
SATct(CL)
SATct(RF)
MCct(LF)
MCct(CL)
MCct(RF)
SAT(CL)
SAT(RF)
Prop. 3
Prop. 3
Prop. 3
Prop. 4
Theo. 1
pspace-complete problems
Σ0
1-complete problems
Fig. 1. Complexity of reasoning tasks with LTLmem
complexity results about satisﬁability and model-checking problems for the frag-
ments LF, CL and RF. Σ1
1-completeness results for SAT?
?(SL), SAT(SL \ {−∗})
and MC(LF) can be found in Propositions 6, 7, and 5, respectively. A thin and
straight [resp. bold and curved] arrow between a source problem and a target
problem means that the upper [resp. lower] bound for the target problem is
shown thanks to the upper [resp. lower] bound for the source problem.
Finally, extending LTLmem with a special propositional variable heap= stating
that the current heap is equal to the next one, can lead to undecidability (look at
the problems of the form SATct
? (Frag)). However, it is open whether satisﬁability
becomes decidable if we restrict the interplay between the “until” operator U and
heap=, for instance to forbid subformulae of the form G heap= with positive
polarity.
References
[AH94]
R. Alur and T.A. Henzinger. A really temporal logic. JACM, 41:181–204,
1994.
[BBH+06]
A. Bouajjani, M. Bozga, P. Habermehl, R. Iosif, P. Moro, and T. Vojnar.
Programs with lists are counter automata. In CAV’06, volume 4144 of
LNCS, pages 517–531. Springer, 2006.
[BCMS01]
O. Burkart, D. Caucal, F. Moller, and B. Steﬀen. Veriﬁcation of inﬁnite
structures. In Handbook of Process Algebra, pages 545–623. Elsevier, 2001.
[BCO05]
J. Berdine, C. Calcagno, and P. W. O’Hearn. Symbolic execution with
separation logic. APLAS’05, 3780:52–68, 2005.
[BDL07]
R. Brochenin, S. Demri, and E. Lozes.
Reasoning about sequences of
memory states. Technical report, LSV, ENS de Cachan, 2007.
[BFLS06]
S. Bardin, A. Finkel, E. Lozes, and A. Sangnier. From pointer systems
to counter systems using shape analysis. 5th International Workshop on
Automated Veriﬁcation of Inﬁnite-State Systems (AVIS’06), 2006.
[BFN04]
S. Bardin, A. Finkel, and D. Nowak.
Toward symbolic veriﬁcation of
programs handling pointers. In 3rd International Workshop on Automated
Veriﬁcation of Inﬁnite-State Systems (AVIS’04), 2004.
[BIL04]
M. Bozga, R. Iosif, and Y. Lakhnech. On logics of aliasing. In SAS’04,
volume 3148 of LNCS, pages 344–360. Springer, 2004.

114
R. Brochenin, S. Demri, and E. Lozes
[CC00]
H. Comon and V. Cortier. Flatness is not a weakness. CSL’00, 1862:262–
276, 2000.
[CGH05]
C. Calcagno, Ph. Gardner, and M. Hague.
From separation logic to
ﬁrst-order logic. In FOSSACS’05, volume 3441 of LNCS, pages 395–409.
Springer, 2005.
[CYO01]
C. Calcagno, H. Yang, and P. O’Hearn. Computability and complexity re-
sults for a spatial assertion language for data structures. In FST&TCS’01,
volume 2245 of LNCS, pages 108–119. Springer, 2001.
[DD07]
S. Demri and D. D’Souza. An automata-theoretic approach to constraint
LTL. Information and Computation, 205(3):380–415, 2007.
[DKR04]
D. Distefano, J.-P. Katoen, and A. Rensink.
Who is pointing when
to whom? on the automated veriﬁcation of linked list structures.
In
FST&TCS’04, volume 3328 of LNCS, pages 250–262. Springer, 2004.
[GKWZ03]
D. Gabbay, A. Kurucz, F. Wolter, and M. Zakharyaschev.
Many-
dimensional modal logics: theory and applications. CUP, 2003.
[GM05]
D. Galmiche and D. Mery. Characterizing provability in BI’s pointer logic
through resource graphs. In LPAR’05, volume 3835 of LNCS, pages 459–
473. Springer, 2005.
[IO01]
S. Ishtiaq and P. O’Hearn. BI as an assertion language for mutable data
structures. In POPL’01, pages 14–26, 2001.
[JJKS97]
J. Jensen, M. Jorgensen, N. Klarlund, and M. Schwartzbach. Automatic
veriﬁcation of pointer programs using monadic second-order logic.
In
PLDI’97, pages 226–236. ACM, 1997.
[LAS00]
T. Lev-Ami and M. Sagiv.
TVLA: A system for implementing static
analyses. In SAS’00, pages 280–301, 2000.
[Loz04]
E. Lozes.
Separation logic preserves the expressive power of classical
logic. In 2nd Workshop on Semantics, Program Analysis, and Computing
Environments for Memory Management (SPACE’04), 2004.
[Pnu77]
A. Pnueli. The temporal logic of programs. In FOCS’77, pages 46–57.
IEEE, 1977.
[Rey02]
J.C. Reynolds. Separation logic: a logic for shared mutable data struc-
tures. In LICS’02, pages 55–74. IEEE, 2002.
[SC85]
A. Sistla and E. Clarke. The complexity of propositional linear temporal
logic. JACM, 32(3):733–749, 1985.
[VW94]
M. Vardi and P. Wolper. Reasoning about inﬁnite computations. Infor-
mation and Computation, 115:1–37, 1994.
[YRSW03]
E. Yahav, Th. Reps, M. Sagiv, and R. Wilhelm. Verifying temporal heap
properties speciﬁed via evolution logic.
In ESOP’03, volume 2618 of
LNCS, pages 204–22. Springer, 2003.

Cut Elimination in Deduction Modulo by
Abstract Completion
Guillaume Burel1 and Claude Kirchner2
1 Universit´e Henri Poincar´e & LORIA3
guillaume.burel@ens-lyon.org
2 INRIA & LORIA3
Claude.Kirchner@loria.fr
3 UMR 7503 CNRS-INPL-INRIA-Nancy2-UHP
Abstract. Deduction Modulo implements Poincar´e’s principle by iden-
tifying deduction and computation as diﬀerent paradigms and making
their interaction possible. This leads to logical systems like the sequent
calculus or natural deduction modulo. Even if deduction modulo is log-
ically equivalent to ﬁrst-order logic, proofs in such systems are quite
diﬀerent and dramatically simpler with one cost: cut elimination may
not hold anymore. We prove ﬁrst that it is even undecidable to know,
given a congruence over propositions, if cuts can be eliminated in the
sequent calculus modulo this congruence.
Second, to recover the cut admissibility, we show how computation
rules can be added following the classical idea of completion a la Knuth
and Bendix. Because in deduction modulo, rewriting acts on terms as
well as on propositions, the objects are much more elaborated than for
standard completion. Under appropriate hypothesis, we prove that the
sequent calculus modulo is an instance of the powerful framework of
abstract canonical systems and that therefore, cuts correspond to critical
proofs that abstract completion allows us to eliminate.
In addition to an original and deep understanding of the interactions
between deduction and computation and of the expressivity of abstract
canonical systems, this provides a mechanical way to transform a
sequent calculus modulo into an equivalent one admitting the cut rule,
therefore extending in a signiﬁcant way the applicability of mechanized
proof search in deduction modulo.
Keywords: Knuth-Bendix completion, automated deduction and inter-
active theorem proving, cut elimination, deduction modulo, proof order-
ing, abstract canonical system.
1
Introduction
The complementarity and interaction between computation and deduction is
known since at least Henri Poincar´e, and deduction modulo [16] is a way to
present ﬁrst-order logic taking advantage from this complementarity. Deduc-
tion modulo is at the heart of proof assistants and proof search methods, either
S. Artemov and A. Nerode (Eds.): LFCS 2007, LNCS 4514, pp. 115–131, 2007.
c
⃝Springer-Verlag Berlin Heidelberg 2007

116
G. Burel and C. Kirchner
implicitly or explicitly (see for instance [24,3,16,5]) and getting a deep under-
standing of its logical behavior is of prime interest either for theoretical or prac-
tical purposes.
In deduction modulo, computations are modeled by a congruence relation be-
tween terms and between propositions. The logical deductions are done modulo
this congruence that is often better represented by a rewrite relation over ﬁrst-
order terms and propositions, leading to the asymmetric sequent calculus [14].
In the sequent calculus modulo, the Hauptsatz, i.e. the fact that cuts are not
needed to build proofs, is no longer true as one can see from an example derived
from Crabb´e’s proof of the non-normalization of Zermelo’s theory [8] (see for
instance [16]). But we know that the admissibility of the cut rule is fundamental
for at least two related reasons: ﬁrst, if a system admits the cut rule, then the
formulæ needed to build a sequent calculus proof of some sequent are subfor-
mulæ1 of the ones appearing in it, so that the search space is, in a sense, limited.
Such proofs are sometimes called analytic [14]. The tableaux method is based
on this fact, and for instance TaMeD [5], a tableaux method based on deduction
modulo, is shown to be complete only for cut-free systems. On the other hand,
it has been shown [21] that a proof search method for deduction modulo like
ENAR [16]—which generalizes resolution and narrowing—is equivalent to the
cut-free fragment of deduction modulo. ENAR is therefore complete if and only
if the cut rule is admissible.
So on the one hand, we like to have a powerful congruence but this may be
at the price of loosing cut admissibility. How can we get both? Gilles Dowek has
shown [14] that cut admissibility is equivalent to the conﬂuence of the rewrite
system, provided only ﬁrst-order terms are rewritten. It is no longer true when
propositions are also rewritten, and the cut admissibility is in that case a stronger
notion than conﬂuence. Therefore he wanted to build a generalized completion
procedure whose input is a rewrite system over ﬁrst-order terms and propositions
and that computes a rewrite system such that the associated sequent calculus
modulo admits the cut rule. Such a completion procedure was proposed for the
quantiﬁer free case in [13], based on the construction of a model for the theory
associated with the rewrite system.
To fully solve this question, including unlimited use of quantiﬁers, we propose
here a quite diﬀerent approach based on the notion of abstract canonical system
and inference introduced in [12,4]. This abstract framework is based on a proof
ordering whose goal is to apprehend the notion of proof quality from which the
notions of canonicity, completeness and redundancy follow up. It is shown to be
adapted to existing completion procedures such as ground completion [10] and
standard (a.k.a. Knuth-Bendix [23]) completion [6].
To present the general idea of our approach, let us consider the simple example
of Crabb´e’s axiom [8] A ⇔B ∧¬A.2 Can we ﬁnd, for the sequent calculus
1 In the case of deduction modulo, the intuitive notion of subformula must of course
take into account the equivalence relation.
2 In [8], A represents rs ∈rs and B is rs ∈s where rs
!={x ∈s : x ̸∈x}. Then, there
is a proof of rs ̸∈s in Zermelo’s set theory that is not normalizing.

Cut Elimination in Deduction Modulo by Abstract Completion
117
modulo the rewrite system A →B ∧¬A, a provable sequent without any cut-
free proof? Indeed, let us try to build a minimal example. We will show in Prop. 4
that such a proof, in its simplest form, is necessarily of the shape:
....
A, B ∧¬A ⊢
A ⊢
↑-l
....
⊢B ∧¬A, A
⊢A
↑-r
⊢
Cut(A)
where the rules labeled “↑-r” and “↑-l” allow to apply the oriented axioms re-
spectively on the right or on the left. In order to validate this proof pattern,
we have to check if it is possible to close both sides of the proof tree, possibly
adding informations in the initial sequent.
First, we can trivially close the left part as follows:
A, B ⊢A Axiom
A, B, ¬A ⊢¬-l
A, B ∧¬A ⊢∧-l
.
Second, to close the right part, we must have a proof in the form:
⊢B, A
A ⊢A Axiom
⊢¬A, A ¬-r
⊢B ∧¬A, A
∧-r
.
To enforce the proof of ⊢B, A, we must add either A or B to the left of the
sequent, and we only have to consider B, since we have cut around A. We obtain
the critical proof:
A, B ⊢A Axiom
A, B, ¬A ⊢¬-l
B, A, B ∧¬A ⊢∧-l
B, A ⊢
↑-l
B ⊢B, A Axiom
B, A ⊢A Axiom
B ⊢¬A, A ¬-r
B ⊢B ∧¬A, A
∧-r
B ⊢A
↑-r
B ⊢
Cut(A)
.
We can also easily show that there is no cut-free proof of B ⊢, simply because no
inference rule is applicable to it except Cut. If we want to have a cut-free proof,
we need to make B reducible by the congruence, hence the idea to complete
the initial system with a new rule which is a logical consequence of the current
system. In our case, we must therefore add the rule B →⊥.
With this new rule, we will show that there is no more critical proof and that
therefore the sequent calculus modulo the proposition rewrite system
A →B ∧¬A
B →⊥
admits the cut rule and has the same expressive power as the initial one.
The study of this question indeed reveals general properties of the sequent
calculus modulo and our contributions are the following:

118
G. Burel and C. Kirchner
– We provide an appropriate Noetherian ordering on the proofs of the sequent
calculus modulo a rewrite system; This ordering allows us to set on the proof
space of sequent calculus modulo a structure of abstract canonical system;
– We characterize the critical proofs in deduction modulo as simple cuts;
– By an appropriate correspondence between sequents and rewrite systems, we
establish a precise correspondence between the limit of a completion process
and a cut free sequent calculus;
– We show the applicability of the general results, in particular on sequent
calculus modulo rewrite systems involving quantiﬁers, therefore generalizing
all previously known results;
– We establish the limits of our approach by proving the undecidability of cut
admissibility and of the search for critical proofs.
As an important by-product of these results, we demonstrate the expressive
power of abstract canonical systems (ACS for short).
The next section will present the minimal knowledge needed on deduction
modulo and abstract canonical systems to make the paper self-contained, and
states the undecidability of the admissibility of the cut rule in deduction modulo.
In Sect. 3, we show how to set, on the proof space of sequent calculus modulo,
a structure of abstract canonical system. In particular we make precise why the
postulates of ACS are fulﬁlled. This allows us in Sect. 4 to characterize the
critical proofs of deduction modulo and to set-up the completion process as the
appropriate (and indeed non-trivial) instance of the abstract completion pro-
cess. We also provide an algorithm to systematically transform a set of sequents
into an appropriate set of proposition rewrite rules, therefore making the whole
framework operational. We conclude after presenting in more details Crabb´e’s
example as well as several examples involving quantiﬁers. All proofs can be found
in the full version of this paper [7].
2
Prerequisites
2.1
Rewritings
We deﬁne here how propositions are rewritten in deduction modulo.
We use standard deﬁnitions for terms, predicates, propositions (with connec-
tors ¬, ⇒, ∧, ∨and quantiﬁers ∀, ∃), substitutions, term rewrite rules and term
rewriting, as can be found in [2,19]. The set of terms built from a signature Σ
and a set of variables V is denoted by T (Σ, V ), the replacement of a variable x
by a term t in a proposition P by {t/x}P, the application of a substitution σ in
a proposition P by σP.
An atomic proposition A(s1, . . . , si, . . . , sn) can be rewritten to the atomic
proposition A(s1, . . . , ti, . . . , sn) by a term rewrite rule l →r if si can be rewrit-
ten to ti by l →r.
A proposition rewrite rule is the pair of an atomic proposition A and a propo-
sition P, such that all free variables of P appear in A. It is denoted A →P.

Cut Elimination in Deduction Modulo by Abstract Completion
119
A proposition rewrite system is a set of proposition rewrite rules. The set of all
proposition rewrite systems is denoted PRS.
An atomic proposition A can be rewritten to a proposition P by a proposition
rewrite rule B →Q if there exists some substitution σ such that σB = A and
σQ = P. Semantically, this proposition rewrite relation must be seen as a logical
equivalence between propositions.
Note that we do not deﬁne how to rewrite non-atomic propositions by propo-
sition rewrite rules, as in [16], because this can be simulated in the sequent
calculus modulo we present in the next section.
In the following, the term rewrite system used in addition to all the proposition
rewrite systems we will consider is ﬁxed. It is supposed to be terminating and
conﬂuent. It will be denoted RT (Σ,V ).
The subformula relation ≻is the least transitive relation such that:
– P ≻Pi if P = P1 ∧P2, P = P1 ∨P2 or P = ¬P1;
– P ≻{t/x}Q if P = ∀x. Q or P = ∃x. Q;
– P ≻Q if P can be rewritten to Q by RT (Σ,V )
for all terms t, variables x and propositions P, Q, P1, P2. It is well-founded be-
cause of the termination of RT (Σ,V ).
2.2
Sequent Calculus Modulo
Sequent calculus modulo can be seen as an extension of the sequent calculus of
Gentzen [20]. We will use the denominations of [19].
A sequent is a pair of multisets of propositions Γ, Δ. It is denoted by Γ ⊢Δ.
The sets of all sequents will be denoted S. For a sequent Γ ⊢Δ, if x1, . . . , xn
are the free variables of Γ, Δ, we will denote by P(Γ ⊢Δ) the proposition
∀x1, . . . , xn. ( Γ ⇒ Δ).
In Fig. 1 we present some inference rules of our sequent calculus modulo. They
diﬀer from the ones of [14] because the congruence is externalized through speciﬁc
inference rules ↑-l and ↑-r (as can be found in [21]), but there is no contraction
or weakening rules. The other logical rules are the one of the standard sequent
calculus. For ∀-l and ∃-r, the quantiﬁed formula that is decomposed is kept.
Proofs are trees labeled by sequents built using these rules, and where all leaves
are Axioms. The root sequent is called the conclusion. A proof is said to be built
in the proposition rewrite system R if all ↑-l and ↑-r use only rules that appear
in R ∪RT (Σ,V ). The set of all proofs will be denoted by SQM.
Cut(P) permits essentially to extend the proof search space with the proposi-
tion P. Logical Rules decompose some proposition which is called principal.
Rewrite Rules, that do not appear in Gentzen’s sequent calculus, introduce
proposition rewriting into the proof system. Note that only atomic propositions
are rewritten, and that we keep the original formula in the sequent.
A proposition rewrite system R is said to admit Cut if for all sequents s ∈S,
s has a proof in R if and only if s has a proof in R without using Cut. It is well-
known (Gentzen’s Hauptsatz [20], or more accurately [14] because of RT (Σ,V ))
that ∅admits Cut.

120
G. Burel and C. Kirchner
Identity Group:
Γ, P ⊢P, Δ Axiom
Γ, P ⊢Δ
Γ ⊢P, Δ
Γ ⊢Δ
Cut(P)
Logical Rules:
Γ ⊢P, Δ
Γ, ¬P ⊢Δ ¬-l
Γ ⊢P, Δ
Γ, Q ⊢Δ
Γ, P ⇒Q ⊢Δ
⇒-l
Γ ⊢{c/x}P, Δ
Γ ⊢∀x. P, Δ
∀-r
Γ ⊢∃x. P, {t/x}P, Δ
Γ ⊢∃x. P, Δ
∃-r
c free in Γ, Δ
t ∈T (Σ, V )
Rewrite Rules: if A can be rewritten to P, either by a term or a proposition
rewrite rule (in one step),
Γ, A, P ⊢Δ
Γ, A ⊢Δ
↑-l
Γ ⊢A, P, Δ
Γ ⊢A, Δ
↑-r
Fig. 1. Some inference rules of the sequent calculus modulo
It is important to be aware that free variables appearing in a sequent play
the same role as fresh constants, because no inference rules can modify them.
As a consequence, one can restrict oneself to closed sequents, as indicated in [16,
Proposition 1.5].
Proposition 1 (Equivalence). The sequent calculus modulo (partly) presented
in Fig. 1 is equivalent to the Asymmetric Sequent Calculus Modulo of [14].
In particular, our system has the weakening and the contraction properties:
– if there exists a proof of Γ ⊢Δ, then for all propositions P there exist proofs
of Γ, P ⊢Δ and Γ ⊢P, Δ;
– there exists a proof of Γ, P ⊢Δ if and only if there exists a proof of Γ, P, P ⊢
Δ, and there exists a proof of Γ ⊢P, Δ if and only if there exists a proof of
Γ ⊢P, P, Δ.
Our sequent calculus also satisﬁes Kleene’s Lemma:
Lemma 1 (Kleene Lemma [21, Lemme 3.3]). If a sequent, containing the
non-atomic formula P, has a proof (resp. cut-free proof) in R, then it has a
proof (resp. cut-free proof) in R whose ﬁrst rule is a logical rule with principal
proposition P.
We prove also the following new result:
Theorem 1 (Undecidability of the Cut Admissibility). Given a proposi-
tional rewrite system R, it is undecidable to know if R admits Cut.
2.3
Abstract Canonical Systems and Inference
The results in this section are extracted from [11,12,4], which should be consulted
for motivations, details and proofs.

Cut Elimination in Deduction Modulo by Abstract Completion
121
Let A be the set of all formulæ over some ﬁxed vocabulary. Let P be the set
of all proofs. These sets are linked by two functions: [·]Pm : P →2A gives the
premises in a proof, and [·]Cl : P →A gives its conclusion. Both are extended to
sets of proofs in the usual fashion. The set of proofs built using assumptions in
A ⊆A is denoted by
Pf (A)
!=

p ∈P : [p]Pm ⊆A

.
The framework described here is predicated on two well-founded partial or-
derings over P: a proof ordering > and a subproof relation . They are related
by a monotonicity requirement (postulate E). We assume for convenience that
the proof ordering only compares proofs with the same conclusion (p > q ⇒
[p]Cl = [q]Cl), rather than mention this condition each time we have cause to
compare proofs.
We will use the term presentation to mean a set of formulæ, and justiﬁca-
tion to mean a set of proofs. We reserve the term theory for deductively closed
presentations:
Th A
!=
[Pf (A)]Cl
=
{[p]Cl : p ∈P, [p]Pm ⊆A}.
Presentations A and B are equivalent (A ≡B) if their theories are identical:
Th A = Th B. In addition to this, we assume the two following postulates:
Postulate A (Reﬂexivity) For all presentations A:
A ⊆Th A
Postulate B (Closure) For all presentations A:
Th Th A ⊆Th A
We call a proof trivial when it proves only its unique assumption and has no
subproofs other than itself, that is, if [p]Pm = {[p]Cl} and p  q ⇒p = q, where
 is the reﬂexive closure of the subproof ordering . We denote by a such a
trivial proof of a ∈A and by A the set of trivial proofs of each a ∈A.
We assume that proofs use their assumptions (postulate C), that subproofs
don’t use non-existent assumptions (postulate D), and that proof orderings are
monotonic with respect to subproofs (postulate E):
Postulate C (Trivia) For all proofs p and formulæ a:
a ∈[p]Pm ⇒p  a
Postulate D (Subproofs Premises Monotonicity) For all proofs p and q:
p  q ⇒[p]Pm ⊇[q]Pm
Postulate E (Replacement) For all proofs p, q and r:
p  q > r ⇒∃v ∈Pf ([p]Pm ∪[r]Pm). p > v  r

122
G. Burel and C. Kirchner
Postulate E essentially says that replacing one of its subproof by a smaller proof
makes a proof smaller. However, the proof v is not necessarily obtained by syn-
tactically replacing q by r in p.
We make no other assumptions regarding proofs or their structure and the
proof ordering > is lifted to a quasi-ordering ≿over presentations:
A ≿B if A ≡B and ∀p ∈Pf (A). ∃q ∈Pf (B). p ≥q .
We deﬁne what a normal-form proof is, i.e. one of the minimal proofs of
Pf (Th A):
Nf (A)
!=
μPf (Th A)
!=
{p ∈Pf (Th A) : ¬∃q ∈Pf (Th A). p > q}
The canonical presentation contains those formulæ that appear as assump-
tions of normal-form proofs:
A♯
!=
[Nf (A)]Pm .
So, we will say that A is canonical if A = A♯.
A presentation A is complete if every theorem has a normal-form proof:
Th A = [Pf (A) ∩Nf (A)]Cl
Canonicity implies completeness, but the converse is not true.
We now consider inference and deduction mechanisms. A deduction mecha-
nism ; is a function from presentations to presentations and we call the relation
A ; B a deduction step. A sequence of presentations A0 ; A1 ; · · · is called
a derivation. The result of the derivation is, as usual, its persisting formulæ:
A∞
!=
lim infj→∞Aj =

j>0
	
i>j
Ai .
A deduction mechanism is completing if for each step A ; B, A ≿B and the
limit A∞is complete.
A completing mechanism can be used to build normal-form proofs of theorems
of the initial presentation:
Theorem 2 ([4, Lemma 5.13]). A deduction mechanism is completing if and
only if for all derivations A0 ; A1 ; · · · ,
Th A0 ⊆[Pf (A∞) ∩Nf (A0)]Cl .
A critical proof is a minimal proof which is not in normal form, but whose strict
subproofs are:
Crit(A)
!=
{p ∈μPf (A) \ Nf (A) : ∀q ∈Pf (A). p  q ⇒q ∈Nf (A)}
Completing formulæ are conclusions of proofs smaller than critical proofs:
Comp(A)
!=

p∈Crit(A) ∧p′ is some proof such that p>p′
[p′]Pm

Cut Elimination in Deduction Modulo by Abstract Completion
123
In this paper, we use a completing deduction mechanism in the following way:
A ; A ∪C(A)
where Comp(A) ⊆C(A) ⊆Th A.
Proposition 2 ([11, Lemma 10]). This deduction mechanism is completing.
3
Deduction Modulo Is an Instance of ACS
We want to show that the sequent calculus modulo can be seen as an instance
of ACS. For this purpose, we have to deﬁne what the formulæ, the proofs, the
premises and conclusions are, and to give the appropriate orderings. After this,
we need to check that the postulates are veriﬁed by the deﬁned instance.
3.1
Proofs and Formulae
We aim to obtain cut-free proofs, so that the natural candidate for ACS proofs
are sequent calculus proofs. Because of the weakening and contraction proper-
ties, we can restrict ourselves to proofs using minimal sets of propositions in their
conclusions. More precisely, we can consider only proofs where all the proposi-
tions appearing in the conclusion are used as principal propositions somewhere
in the proof, or in one of the Axioms.
The completion procedure we want to establish deals with rewrite rules over
atomic propositions. Nevertheless, the conclusions of the proofs, from which we
want to generate the rewrite rules added by the completion mechanism, are
sequents. In other words, sequents must be identiﬁed with proposition rewrite
systems.
Therefore we suppose that there exists a function between sequents and propo-
sition rewrite systems Rew : S →PRS such that:
Property 1. For all sequents Γ ⊢Δ, R = Rew(Γ ⊢Δ) and P(Γ ⊢Δ) are
strongly compatible:
(a) for all propositions P, Q, P
∗
←→
R Q implies that there exists a proof of
P(Γ ⊢Δ) ⊢P ⇔Q in ∅(i.e. without rewrite rules);
(b) there exists a cut-free proof of ⊢P(Γ ⊢Δ) in R.
Property 2. For all proposition rewrite systems R, for all sequents s and s′, if
Rew(s) = Rew(s′), then s has a proof (resp. cut-free proof) in R iﬀs′ has a
proof (resp. cut-free proof) in R.
Property 1 implies compatibility in the sense of Deﬁnition 1.4 of [16], which is
the same except that we need here a cut-free proof in b).
Section 4.3 provides an instance of such a function Rew.

124
G. Burel and C. Kirchner
With respect to the deﬁnitions of ACSs (see Sect. 2.3) deduction modulo can
be seen as an ACS, in the following way:
— P: proofs are sequent calculus proofs using minimal sets of propositions in
their conclusion:
P
!=
{p ∈SQM : ¬ (∃q ∈SQM. Weak(q, p))}
where Weak(q, p) says that the proof p can be obtained from q by weakening.
— A: formulæ are proposition rewrite systems corresponding to some sequent:
A
!=
Rew(S) ⊆PRS .
— The conclusion of an ACS proof is the rewrite system associated by Rew
to the conclusion of the sequent calculus proof: for all proofs p,
[p]Cl
!=
Rew(Γ ⊢Δ) when p =
...
...
Γ ⊢Δ .
— The premises of a proof are the rewrite systems consisting of the proposition
rewrite rules appearing in the proof or its subproofs: for all proofs p,
[p]Pm
!=
⎧
⎨
⎩

A →P :
there exists a ↑-l or
↑-r using A →P in q

:
q is a subproof of p
⎫
⎬
⎭
This deﬁnition implies that we consider only proofs using proposition rewrite
systems corresponding to some sequent.
3.2
Orderings on Proofs
We deﬁne the following (inﬁnite, but Noetherian) precedence > : for all formulæ
P, Q, if P is greater than Q for the subformula relation, then Cut(P) > Cut(Q),
and for all other inference rules r of Fig. 1, Cut(P) > r.
We order proofs using the RPO [9] based on this precedence. Since the prece-
dence is well-founded, so is the RPO [9]. We restrict this ordering to proofs which
have the same sequent as conclusion, modulo weakening.
Because we work modulo weakening and contraction, it is important to note
that a proof and its weakened and contracted versions are equivalent with respect
to the ordering we have just deﬁned, because they have the same cuts and the
same labeled tree structure.
Notice also that with this ordering, a cut-free proof is always strictly smaller
than a proof with at least one cut at root.
Subproofs of a proof p are deﬁned as the subproofs of p for the sequent cal-
culus, modulo weakening and contraction (subproofs may use less propositions
than their parents).
Unfortunately, this deﬁnition is not suﬃcient to deﬁne trivial proofs, because
if we use a premise through a ↑-l or ↑-r rule, there will always be a strict subproof,
so that there is no proofs using premises without strict subproofs.

Cut Elimination in Deduction Modulo by Abstract Completion
125
To solve this problem, we can add manually the trivial proofs, i.e. P is in fact
P ∪A, where formulæ are identiﬁed with their trivial proof.
We have to extend the ordering > to trivial proofs: it can be simply done by
saying that they cannot be compared with other proofs. (> over P ∪A is the
same relation as > over the original P.)
For Postulate C to be veriﬁed, we have to extend the subproof relation:
p  q
if – q is a subproof modulo weakening of p in SQM, or
– if q = a with a ∈[p]Pm.
This relation is well-founded because of the wellfoundedness of the sub-
proof relation in sequent calculus, and because trivial proofs cannot have strict
subproofs.
With these deﬁnitions we can prove the main theorem of this section:
Theorem 3 (Instance of ACS). The sequent calculus modulo is an instance
of ACS, with the deﬁnitions of A, P, [·]Pm, [·]Cl, > and  given above.
4
A Generalized Completion Procedure
We want to deﬁne a completion procedure through critical proofs. For this,
we ﬁrst need some characterizations of the normal-form proofs and the critical
proofs. The limit of this completion procedure will be an equivalent rewrite
system which admits Cut.
4.1
Normal-Form Proofs and Critical Proofs in Deduction Modulo
Proposition 3 (Characterization of Normal-Form Proofs). A proof in
deduction modulo is in normal form iﬀit is either a trivial proof or a cut-free
proof with no useless logical rules.
We give now a characterization of the critical proofs in deduction modulo.
Proposition 4 (Critical Proofs in Deduction Modulo). Critical proofs in
deduction modulo are of the form
π....
Γ, A, P ⊢Δ
Γ, A ⊢Δ
↑-l
π′....
Γ ⊢Q, A, Δ
Γ ⊢A, Δ
↑-r
Γ ⊢Δ
Cut(A)
where π and π′ are cut-free and do not use unneeded logical rules, and at least
one of A →P or A →Q is not a term rewriting.

126
G. Burel and C. Kirchner
Note 1. If we suppose, as in the order condition of [22], that the proposition
rewrite system is conﬂuent, and that it is included in a well-founded ordering
compatible with the subformula relation, then we can take this ordering instead
of the subformula relation to compare cuts in the precedence. Doing this, we can
prove that there are no minimal proofs of this form, and consequently no critical
proofs. Therefore the admissibility of Cut is veriﬁed.
The main diﬀerence with [22] is that Hermant gives a semantic proof of the cut
admissibility, whereas we have here a cut-elimination algorithm, i.e. a terminat-
ing syntactical process that transforms a proof into a cut-free one. It remains to
be investigated how this process is related with normalization, i.e. β-reduction.
(The last case corresponds in fact to an η-expansion.) It is proved in [17] that
such an order condition provides normalization in the quantiﬁer-free case.
This result was also independently found by [1], with the same kind of ordering
over proofs.
4.2
The Completion Procedure
As we wrote in Sect. 2.3, we want to deﬁne a completing deduction mechanism
by adding to a presentation A a presentation C(A) such that Comp(A) ⊆C(A) ⊆
Th A. So we have to ﬁnd proofs smaller than critical proofs. Here, using Property
1(b) and Lemma 1, we can ﬁnd for all sequents Γ ⊢Δ a cut-free proof in
Rew(Γ ⊢Δ) with conclusion Γ ⊢Δ, which will be smaller than any proof
containing a cut proving the same sequent, in particular any critical proof. The
premises of this proof are in Rew(Γ ⊢Δ) = [p]Cl. The best procedure is thus to
add only the conclusions of critical proofs. Nevertheless, this is not possible:
Theorem 4 (Undecidability of Critical Proof Search). Given a proposi-
tional rewrite system R and a sequent Γ ⊢Δ, it is undecidable to know if Γ ⊢Δ
is the conclusion of a critical proof in R.
We must therefore add a superset of these conclusions. Here we will add the
conclusion of the proofs in the form of Proposition 4, except the one that we
know for sure that they are not minimal (for instance if A ∈Γ ∪Δ).
We must consider proofs of the form of Proposition 4. As π and π′ are cut-free
and do not use unneeded logical rules, they could be found using for instance a
tableaux method modulo, like TaMeD [5], which is complete with respect to cut-
free proofs, if we knew Γ and Δ, hence the idea to apply the tableaux method
to A, P ⊢and ⊢Q, A, and to complete Γ and Δ in order to close the remaining
tableaux. Because we work modulo weakening, we can restrict ourselves to the
minimal Γ and Δ closing the tableaux. We can then sort the obtained Γ ⊢Δ to
remove sequents where A ∈Γ ∪Δ. The resulting rewrite system is obtained by
adding all Rew(Γ ⊢Δ) to our rewrite system.
Theorem 5 (Cut Admissibility of the Limit). For all sequents Γ ⊢Δ, for
all proposition rewrite systems R0, Γ ⊢Δ has a proof in R0 if and only if it has
a cut-free proof in R∞.

Cut Elimination in Deduction Modulo by Abstract Completion
127
4.3
Sequents and Rewrite Systems
For deduction modulo to be an instance of ACS, we have to deﬁne some function
Rew having Properties 1 and 2. We also want to know how to build proofs that
use the rewrite system associated with some sequent, and therefore this function
has to be eﬀective.
If we consider only propositional logic (i.e. without quantiﬁers), we can use
the following (non-deterministic) algorithm to transform a set of sequents Γ ⊢Δ
into a set of rewrite rules:
Step 1. Choose a sequent. Push all negated formulæ on the other side of the
sequent. For instance, A, ¬B ⊢¬C, D becomes A, C ⊢B, D. If the new
Γ is empty, go to step 2. If the new Δ is empty, go to step 3. If neither
is empty, go to either Step 2 or Step 3.
Step 2. Decompose the last proposition iteratively:
P1, . . . , Pn ⊢Q1, . . . , Qm becomes P1, . . . , Pn, ¬Q1, . . . , ¬Qm−1 ⊢Qm
P1, . . . , Pn ⊢Q1 ∧Q2
”
P1, . . . , Pn ⊢Q1 ; P1, . . . , Pn ⊢Q2
P1, . . . , Pn ⊢Q1 ∨Q2
”
P1, . . . , Pn, ¬Q1 ⊢Q2
P1, . . . , Pn ⊢Q1 ⇒Q2
”
P1, . . . , Pn, Q1 ⊢Q2
P1, . . . , Pn ⊢A
”
A →A ∨∃x1, . . . , xp. (P1 ∧· · · ∧Pn)
(A atomic, and the xi are the free variables appearing in P1, . . . , Pn but
not in A)
for P1, . . . , Pn ⊢¬Q, return to Step 1
Step 3. Decompose the ﬁrst proposition iteratively, dually from step 2. For in-
stance,
P1 ⇒P2 ⊢Q1, . . . , Qm becomes P2 ⊢Q1, . . . , Qm ; ¬P1 ⊢Q1, . . . , Qm
A ⊢Q1, . . . , Qm
”
A →A ∧∀x1, . . . , xp. (Q1 ∨· · · ∨Qm)
(A atomic, and the xi are the free variables appearing in Q1, . . . , Qm
but not in A)
for ¬P ⊢Q1, . . . , Qm, return to Step 1.
This algorithm clearly terminates, because each time a step 2 or 3 begins,
either the rewrite rule is generated, or a formula is decomposed into subformulæ,
so that the number of connectors diﬀerent from ¬ strictly diminishes. Of course,
we do not pretend that this algorithm is the most optimized for our purpose.
Rew(Γ ⊢Δ) will be the function returning the rewrite system obtained by
applying the algorithm to

Γ ⊢Δ

.
This algorithm can be extended to the case with quantiﬁers. In the case of
a ∀on the left of the sequent, or a ∃on the right, we will keep the formula in
the sequent, but will not decompose it further. We will therefore denote by P
the fact that P was already decomposed. Then we do not consider underlined
formulæ in Step 1 to choose between Step 2 or Step 3, and at the beginning of
Step 2 (resp. Step 3), one keep a non-underlined formula to the right (resp. left)
side.
We also have to add the following decomposition steps:
– (2) P1, . . . , Pn ⊢∀x. Q becomes P1, . . . , Pn ⊢{y/x}Q where y does not ap-
pear in P1, . . . , Pn;

128
G. Burel and C. Kirchner
– (2) P1, . . . , Pn ⊢∃x. Q becomes P1, . . . , Pn, ¬∃x. Q ⊢{t/x}Q where t can be
any ground term;
– (3) ∃x. P ⊢Q1, . . . , Qm becomes {y/x}P ⊢Q1, . . . , Qm where y does not
appear in Q1, . . . , Qm.
– (3) ∀x. QP1, . . . , Pn ⊢becomes {t/x}P ⊢¬∀x. Q, Q1, . . . , Qm where t can
be any ground term.
Of course, at the end, the underlines are removed.
Proposition 5. The function Rew has the Properties 1 and 2.
This algorithm does not allow all rewrite systems to be considered as formulæ.
Nevertheless, one can transform all rewrite systems to equivalent rewrite systems
that are images of sequents by Rew, by splitting the rules: A →P becomes
A →A ∨P and A →A ∧P. This is equivalent to the polarized rewrite systems
of [13].
This algorithm can be seen as the attempt to build a cut-free proof of the
conclusion of a critical proof, adding rewrite rules to close the branches were an
atomic formula appears.
4.4
Examples
In the case of Crabb´e’s example presented in the introduction, the input is the
rewrite system A →B ∧¬A and the completion procedure generates B →B ∧⊥
which is equivalent to B →⊥.
With this new rule, we can show that there is no more critical proofs. There-
fore, the proposition rewrite system

A →B ∧¬A
B →⊥
admits Cut.
The next example deals with quantiﬁers and is extracted from [22]:
R ∈R →∀y. y ≃R ⇒y ∈R ⇒C
where y ≃z
!=
∀x. (y ∈x ⇒z ∈x). It is terminating and conﬂuent, but
does not admits Cut.
The critical proofs have the form
....
R ∈R, ∀y. y ≃R ⇒y ∈R ⇒C ⊢
R ∈R ⊢
↑-l
....
⊢R ∈R, ∀y. y ≃R ⇒y ∈R ⇒C
⊢R ∈R
↑-l
⊢
Cut(R ∈R)
The left part can be developed as
R ∈R, C ⊢
R ∈R ⊢t1 ∈R
R ∈R, t1 ∈R ⇒C ⊢
⇒-l
R ∈R, t1 ∈c1 ⊢R ∈c1
R ∈R ⊢t1 ∈c1 ⇒R ∈c1
⇒-r
R ∈R ⊢t1 ≃R
∀-r
R ∈R, t1 ≃R ⇒t1 ∈R ⇒C ⊢
⇒-l
R ∈R, ∀y. y ≃R ⇒y ∈R ⇒C ⊢∀-l

Cut Elimination in Deduction Modulo by Abstract Completion
129
and the right part as
R ∈t0, c0 ∈R ⊢R ∈R, C
c0 ∈R ⊢c0 ∈t0, R ∈R, C
c0 ∈t0 ⇒R ∈t0, c0 ∈R ⊢R ∈R, C
⇒-l
c0 ≃R, c0 ∈R ⊢R ∈R, C
∀-l
c0 ≃R ⊢R ∈R, c0 ∈R ⇒C ⇒-r
⊢R ∈R, c0 ≃R ⇒c0 ∈R ⇒C ⇒-r
⊢R ∈R, ∀y. y ≃R ⇒y ∈R ⇒C ∀-r
.
To close the proofs, we can for instance have t0 = R = t1, and C in the right
part of the sequent (to close R ∈R, C ⊢). One can see that other choices will
not produce critical proofs. The resulting sequent is therefore ⊢C, and the
added rule is C →C ∨⊤. This rule does not generate new critical proofs, and
consequently, the proposition rewrite system
R ∈R →∀y. y ≃R ⇒y ∈R ⇒C
C →C ∨⊤
admits Cut.
One can also think of another example, where there remains quantiﬁers
in the conclusion: consider the following rule derived from Crabb´e’s example
A →(∃x. ∀y. B ∧P(x, y)) ∧¬A where A and B are atomic propositions, and P
a predicate of arity 2. For more convenience we will denote by Q(x) the formula
∀y. B ∧P(x, y). We have exactly the same critical proof than in the case of
Crabb´e, but where B is replaced by ∃x. Q(x). The sequent of its conclusion is
transformed into a rewrite rule:
∃x. Q(x) ⊢becomes Q(z) ⊢
becomes B ∧P(z, a) ⊢¬Q(z)
becomes B ⊢¬P(z, a), ¬Q(z)
becomes B →B ∧∀z. (¬P(z, a) ∨¬Q(z)) .
Then, the resulting systems admits Cut, and a cut free proof of ∃x. Q(x) ⊢
can be:
Q(c), B, P(c, a) ⊢P(c, a) Axiom
Q(c), B, ¬P(c, a), P(c, a) ⊢¬-l
Q(c), B, P(c, a) ⊢Q(c) Axiom
Q(c), B, ¬Q(c), P(c, a) ⊢¬-l
Q(c), B, ¬P(c, a) ∨¬Q(c), P(c, a) ⊢
∨-l
Q(c), B, ∀z. (¬P(z, a) ∨¬Q(z)) , P(c, a) ⊢∀-l
Q(c), B, B ∧∀z. (¬P(z, a) ∨¬Q(z)) , P(c, a) ⊢∧-l
Q(c), B, P(c, a) ⊢
↑-l
Q(c), B ∧P(c, a) ⊢∧-l
Q(c) ⊢
∀-l
∃x. Q(x) ⊢∃-l
It remains to be investigated, as for Knuth-Bendix completion, for which con-
ditions the completion procedure we have deﬁned is terminating. We conjecture
that it is the case if the original proposition rewrite system is conﬂuent.

130
G. Burel and C. Kirchner
5
Conclusion and Perspectives
We have shown how, by setting the right abstract canonical system structure
on the proof space of a sequent calculus modulo, we can use abstract comple-
tion to obtain an equivalent theory modulo which deduction admits Cut. This
abstract completion is precise enough to be operational, and it is actually imple-
mented. It also reveals an original and deep logical correspondence between the
sequent calculus, proof orderings and rewriting completion. This opens several
new challenging questions.
The ordering on proofs we are using is adapted to consider cut admissibility
as a normal-form property of an ACS, but produces many critical proofs, in par-
ticular when quantiﬁers are involved. This is because some of the rules produced
by the completion procedure subsumes others: for instance A →A ∨∃x. P(x)
subsumes A →A∨P(t) for a particular t ∈T (Σ, V ). It is therefore a challenging
goal to understand if this ordering could beneﬁt of reﬁnements allowing to target
the more relevant critical proofs.
Our saturation procedure only guarantees cut admissibility, not normaliza-
tion. For instance, with Crabb´e’s rule, once the system is completed, the initial
proof of B ⊢can still be constructed, and it is still not normalizing, i.e. the λ-
term that is associated to the proof can be inﬁnitely β-reduced. In other words,
we do not have a process that transforms proofs with cuts to cut-free ones. The
introduction of simpliﬁcation rules as in standard completion may allow us to
suppress the possibility to build non-normalizing proofs. Moreover, with such
simpliﬁcation rules, the canonical presentation of the system may be obtained.
Let us ﬁnally remark that as an interesting consequence of our results, our
procedure can be used to determine if a system admits Cut. Indeed, if a proposi-
tion rewrite system is a ﬁxpoint of this procedure, then we know that it admits
Cut. The converse is not true, essentially because the procedure uses a superset
of the critical proofs. It will be interesting to check what results this procedure
will give on systems that are proved to admit Cut, like Higher Order Logic [15]
or arithmetic [18].
References
1. Aiguier, M., Boin, C., Longuet, D.: On generalized theorems for normalization
of proofs. Technical report, LaMI - CNRS and Universit´e d’Evry Val d’Essonne
(2005)
2. Baader, F., Nipkow, T.: Term Rewriting and all That. Cambridge University Press
(1998)
3. Barendregt, H., Barendsen, E.: Autarkic computations in formal proofs. Journal
of Automated Reasoning 28 (2002) 321–336
4. Bonacina, M.P., Dershowitz, N.: Abstract canonical inference. ACM Trans. Com-
put. Logic 8 (2007)
5. Bonichon, R.: TaMeD: A tableau method for deduction modulo. In: Basin, D.A.,
Rusinowitch, M. (eds.): IJCAR. Lecture Notes in Computer Science, Vol. 3097.
Springer-Verlag (2004) 445–459

Cut Elimination in Deduction Modulo by Abstract Completion
131
6. Burel, G., Kirchner, C.: Completion is an instance of abstract canonical system
inference.
In: Futatsugi, K., et al. (eds.): Algebra, Meaning and Computation.
Lecture Notes in Computer Science, Vol. 4060. Springer-Verlag (2006) 497–520
7. Burel, G., Kirchner, C.: Cut elimination in deduction modulo by abstract comple-
tion (full version). Research report (2007) http://hal.inria.fr/inria-00132964.
8. Crabb´e, M.: Non-normalisation de la th´eorie de Zermelo. Manuscript (1974)
9. Dershowitz, N.: Orderings for term-rewriting systems. Theoretical Computer Sci-
ence 17 (1982) 279–301
10. Dershowitz, N.: Canonicity. In: Dahn, I., Vigneron, L. (eds.): FTP. Electronic
Notes in Theoretical Computer Science, Vol. 86. Elsevier Science Publishers B. V.
(North-Holland) (2003)
11. Dershowitz, N., Kirchner, C.: Abstract saturation-based inference. In: LICS. IEEE
Computer Society (2003) 65–74
12. Dershowitz, N., Kirchner, C.: Abstract Canonical Presentations. Theoretical Com-
puter Science 357 (2006) 53–69
13. Dowek, G.: What is a theory? In: Alt, H., Ferreira, A. (eds.): STACS. Lecture
Notes in Computer Science, Vol. 2285. Springer-Verlag (2002) 50–64
14. Dowek, G.: Conﬂuence as a cut elimination property. In: Nieuwenhuis, R. (ed.):
RTA. Lecture Notes in Computer Science, Vol. 2706. Springer-Verlag (2003) 2–13
15. Dowek, G., Hardin, T., Kirchner, C.: HOL-λσ an intentional ﬁrst-order expression
of higher-order logic.
Mathematical Structures in Computer Science 11 (2001)
1–25
16. Dowek, G., Hardin, T., Kirchner, C.: Theorem proving modulo. Journal of Auto-
mated Reasoning 31 (2003) 33–72
17. Dowek, G., Werner, B.: Proof normalization modulo. The Journal of Symbolic
Logic 68 (2003) 1289–1316
18. Dowek, G., Werner, B.: Arithmetic as a theory modulo. In: Giesl, J. (ed.): RTA.
Lecture Notes in Computer Science, Vol. 3467. Springer-Verlag (2005) 423–437
19. Gallier,
J.H.:
Logic
for
Computer
Science:
Foundations
of
Automatic
Theorem
Proving.
Computer
Science
and
Technology
Series,
Vol.
5.
Harper
&
Row,
New
York
(1986)
Revised
On-Line
Version
(2003),
http://www.cis.upenn.edu/∼jean/gbooks/logic.html.
20. Gentzen, G.:
Untersuchungen ¨uber das logische Schliessen.
Mathematische
Zeitschrift 39 (1934) 176–210, 405–431 Translated in Szabo, editor., The Collected
Papers of Gerhard Gentzen as “Investigations into Logical Deduction”.
21. Hermant, O.: M´ethodes S´emantiques en D´eduction Modulo. PhD thesis, ´Ecole
Polytechnique (2005)
22. Hermant, O.: Semantic cut elimination in the intuitionistic sequent calculus. In:
Urzyczyn, P. (ed.): TLCA. Lecture Notes in Computer Science, Vol. 3461. Springer-
Verlag (2005) 221–233
23. Knuth, D.E., Bendix, P.B.: Simple word problems in universal algebras. In: Leech,
J. (ed.): Computational Problems in Abstract Algebra. Pergamon Press, Oxford
(1970) 263–297
24. Peterson, G., Stickel, M.E.: Complete sets of reductions for some equational theo-
ries. Journal of the ACM 28 (1981) 233–264

Density Elimination and Rational Completeness for
First-Order Logics⋆
Agata Ciabattoni1 and George Metcalfe2
1 Institute of Discrete Mathematics and Geometry, Technical University Vienna,
Wiedner Hauptstrasse 8-10, A-1040 Wien, Austria
agata@logic.at
2 Department of Mathematics, Vanderbilt University
1326 Stevenson Center, Nashville TN 37240, USA
george.metcalfe@vanderbilt.edu
Abstract. Density elimination by substitutions is introduced as a uniform me-
thod for removing applications of the Takeuti-Titani density rule from proofs in
ﬁrst-order hypersequent calculi. For a large class of calculi, density elimination
by this method is guaranteed by known sufﬁcient conditions for cut-elimination.
Moreover, adding the density rule to any axiomatic extension of a simple ﬁrst-
order logic gives a logic that is rational complete; i.e., complete with respect to
linearly and densely ordered algebras: a precursor to showing that it is a fuzzy
logic (complete for algebras with a real unit interval lattice reduct). Hence the
sufﬁcient conditions for cut-elimination guarantee rational completeness for a
large class of ﬁrst-order substructural logics.
1
Introduction
Elimination of the cut-rule is a fundamental topic in proof theory, corresponding to
the removal of lemmas in proofs. However, the addition and subsequent elimination of
other rules can also be of considerable interest. In this paper we consider one such rule
of importance in Fuzzy Logic: the so-called “density rule” of Takeuti and Titani [14]:
T ⊢(A →p) ∨(p →B) ∨C
T ⊢(A →B) ∨C
(density)
where p is a propositional variable not occurring in T , A, B, or C. Ignoring T and
C, the negation of the conclusion may (roughly) be interpreted as “A > B” and the
negation of the premise as “for some p: A > p and p > B”. That is, between every two
elements there exists another element. Note that adding this rule to any axiomatization
of Classical Logic leads to inconsistency (e.g. take A to be ⊤and B to be ⊥).
The density rule was used by Takeuti and Titani to axiomatize Intuitionistic Fuzzy
Logic [14], better known as ﬁrst-order G¨odel logic, one of the main formalizations
of Fuzzy Logic [8]. Alternative axiomatizations by Horn and Takano [13] show that
(density) is not required; giving a kind of “semantic elimination” of the rule. Baaz
and Zach [2] have also provided a syntactic elimination of (density) using a proof
⋆Work Supported by FWF Project P18731.
S. Artemov and A. Nerode (Eds.): LFCS 2007, LNCS 4514, pp. 132–146, 2007.
c⃝Springer-Verlag Berlin Heidelberg 2007

Density Elimination and Rational Completeness for First-Order Logics
133
system for ﬁrst-order G¨odel logic in the framework of hypersequents, a generalization
of Gentzen sequents introduced by Avron [1]. This elimination procedure follows the
spirit of Gentzen’s cut-elimination method, proceeding by induction on the height of a
proof of the premise and shifting applications of the rule upwards.
In [10], Metcalfe and Montagna recognized that these two steps - adding and elimi-
nating the density rule - provide a general method for establishing the so-called “stan-
dard completeness” of t-norm1 based (and related) fuzzy logics: that is, completeness
of axiomatic systems with respect to algebras whose lattice reduct is the real unit in-
terval [0, 1]. In particular, it was shown that any axiomatic extension of the elemen-
tary propositional fuzzy logic UL extended with (density) is complete with respect
to corresponding linearly and densely ordered algebras. This constitutes the so-called
“rational completeness” step of the proof. Standard completeness may then be obtained
in many cases (but not in general) by means of the Dedekind-MacNeille completion. It
was also shown in [10] that for particular propositional logics possessing a suitable hy-
persequent calculus, density elimination can be established (Gentzen-style, following
[2]) thereby giving standard completeness for the original logic without density. This
general approach is in contrast to more logic-speciﬁc “semantic” techniques for proving
standard completeness [8,9,6,11].
The contribution of this paper is in two parts. First, we introduce a new general
method for density elimination. In this approach, similar to normalization for natu-
ral deduction systems, applications of the density rule are removed by making suit-
able substitutions for the new propositional variables. This avoids the combinatorial
difﬁculties of the Gentzen-style proofs in [2,10]. Applying this method to ﬁrst-order
single-conclusion hypersequent calculi with weakening rules, we are able to show that
the syntactic conditions deﬁned in [3] for cut-elimination also guarantee density elim-
ination. In the second part of the paper we show that adding the density rule to any
axiomatic extension of the ﬁrst-order version of UL, gives a logic that is complete with
respect to linearly and densely ordered algebras. Combining the two parts we obtain
rational completeness for a wide class of ﬁrst-order fuzzy logics with weakening (see
[5] for details). These include the ﬁrst-order versions of (the logic of left-continuous
t-norms) Monoidal t-norm based logic MTL [7] (proved standard complete in [11] by
a different method) and its extensions SMTL [6] and CnMTL (with n ≥2) [4].
2
(Hyper)Sequent Calculi
We consider formulae built over a vocabulary V consisting of (countably many): (term)
variables x, y, z, . . ., for each n ≥0, constants c, d, . . ., n-ary predicate symbols, as
well as m-ary connectives ⋆1, ⋆2, . . . for each m ≥0 and the quantiﬁers ∀and ∃. Terms
are deﬁned in the usual way. A formula (in the vocabulary V) is either an atomic formula
or a compound formula of the form ⋆i(A) or QxA with ⋆i an m-ary connective, which
connect formulae A ≡A1, . . . , An and Q ∈{∀, ∃}. For convenience we call nullary
predicate symbols, propositional variables, denoted by p, q, . . ..
We indicate with Γ, Δ, Π, Σ, . . . (possibly empty) multisets of formulae. To spec-
ify inference rules we use meta-variables X, Y, Z standing for arbitrary formulae and
1 t-norms are the main tool in Fuzzy Logic for conjunctively combining vague information.

134
A. Ciabattoni and G. Metcalfe
Θ, Ξ, Φ, Ψ, Υ, . . . standing for (possibly empty) multisets of meta-variables. When λ ≥
0, Γ λ (resp. Θλ) denotes Γ, . . . , Γ (resp. Θ, . . . , Θ), λ times. A (meta)sequent Γ ⇒Δ
(Θ ⇒Ξ), where Γ (Θ) is said to be antecedent and Δ (Ξ) consequent, is single-
conclusion if Δ (Ξ) contains at most one formula (meta-variable). A sequent calculus
is single-conclusion if all its sequents are single-conclusion.
Deﬁnition 1. We call any propositional single-conclusion sequent calculus LL sim-
ple whenever LL consists of the identity axiom of the form X ⇒X, together with:
the (multiplicative version of the) cut rule (CUT ), structural rules {(ri)}i∈Λ0 and
for each logical connective ⋆, left logical rules {(⋆, l)j}j∈Λ1 and right logical rules
{(⋆, r)k}k∈Λ2 (Λ0, Λ1, Λ2 can be empty):
Θ ⇒X
Θ′, X ⇒Ξ
Θ, Θ′ ⇒Ξ
(CUT)
Υ1 ⇒Ψ1
· · ·
Υn ⇒Ψn
Θ ⇒Ξ
(ri)
Υ1 ⇒Ψ1
· · ·
Υn ⇒Ψn
Θ, ⋆(X) ⇒Ξ
(⋆, l)j
Υ1 ⇒Ψ1
· · ·
Υn ⇒Ψn
Θ ⇒⋆(X)
(⋆, r)k
In the rules (ri), (⋆, l)j, and (⋆, r)k, n ≥0 and the meta-variables in Θ (called left
context meta-variables), those in Ξ (called right context meta-variables), and the meta-
variables in X ≡X1, . . . , Xm, m ≥0 (called active meta-variables) are mutually
disjoint. In addition, the structural (and logical) rules satisfy the following condition:
(∗) Any meta-variable in Υ1, . . . , Υn is a left context meta-variable (or an active meta-
variable), and any meta-variable in Ψ1, . . . , Ψn is a right context meta-variable (or an
active meta-variable).
As usual, an instance of a logical or structural rule is obtained by substituting arbitrary
formulae for meta-variables. In an instance of a logical or structural rule, the formulae
replacing context meta-variables (active meta-variables, respectively) are called context
formulae (active formulae, respectively) and formulae of the form ⋆(A) as well as the
formulae replacing X in identity axioms are called principal formulae. The two oc-
currences of the formula instantiating X in (CUT ) are called cut formulae. Proofs (or
derivations) are deﬁned in the usual way.
Deﬁnition 2. A w-simple calculus is a simple sequent calculus containing the weak-
ening rules (w, l) and (w, r) of Fig. 1. A ﬁrst-order (w-)simple sequent calculus is a
(w-)simple sequent calculus extended with the rules for quantiﬁers in Gentzen’s calcu-
lus LJ for intuitionistic logic.
Hypersequent calculi arise by extending Gentzen calculi to refer to many (a multiset of)
sequents, instead of just one. Introduced by Avron in [1], they are particularly suitable
for dealing with logics with the linearity axiom (lin) (A →B)∨(B →A), prominent
examples being t-norm based fuzzy logics [8].
Deﬁnition 3. A hypersequent is a multiset S1 | . . . | Sn where each Si for i = 1 . . . n
is a sequent, called a component of the hypersequent. A hypersequent is called single-
conclusion if all its components are single-conclusion.
We will assume from now on that we deal only with single-conclusion (hyper)sequent
calculi. Like sequent calculi, hypersequent calculi consist of initial hypersequents, log-
ical rules, and structural rules, where we write rules using meta-sequents and a variable

Density Elimination and Rational Completeness for First-Order Logics
135
X ⇒X (ID)
Θ, ⊥⇒Ξ (⊥)
Θ ⇒X
Φ, X ⇒Ξ
Θ, Φ ⇒Ξ
(CUT)
Θ ⇒Ξ
Θ, X ⇒Ξ (w, l)
Θ ⇒
Θ ⇒X (w, r)
Θ, X, Y ⇒Ξ
Θ, X ⊙Y ⇒Ξ (⊙, l)
Θ ⇒X
Θ′ ⇒Y
Θ, Θ′ ⇒X ⊙Y
(⊙, r)
Θ, Xi ⇒Ξ
Θ, X1 ⊙X2 ⇒Ξ (∧, l)i=1,2
Θ ⇒X
Θ ⇒Y
Θ ⇒X ∧Y
(∧, r)
Θ, Y ⇒Ξ
Θ′ ⇒X
Θ, Θ′, X →Y ⇒Ξ
(→, l)
Θ, X ⇒Y
Θ ⇒X →Y (→, r)
Θ, X ⇒Ξ
Θ, Y ⇒Ξ
Θ, X ∨Y ⇒Ξ
(∨, l)
Θ ⇒Xi
Θ ⇒X1 ∨X2 (∨, r)i=1,2
Fig. 1. The sequent calculus FLew
G (with an instance G) standing for an arbitrary hypersequent. Logical rules for connec-
tives are then the same as those in sequent calculi, except that a “side hypersequent”may
occur, denoted by G. Structural rules are divided into two categories. Internal rules deal
with formulae within sequents as in sequent calculi. External rules manipulate whole
sequents. For example, external weakening and contraction rules (EW) and (EC) add
and contract components respectively:
G
G | Θ ⇒Ξ (EW )
G | Θ ⇒Ξ | Θ ⇒Ξ
G | Θ ⇒Ξ
(EC)
while the key rule to deal with the axiom (lin) is Avron’s communication rule (COM)
which permits interaction between sequents:
G | Θ, Θ′ ⇒Ξ
G | Θ1, Θ′
1 ⇒Ξ′
G | Θ, Θ1 ⇒Ξ | Θ′, Θ′
1 ⇒Ξ′
(COM)
For a sequent rule with premises S1 . . . Sn and conclusion S, its hypersequent ver-
sion is the rule with premises G | S1 . . . G | Sn and conclusion G | S. E.g., the hyperse-
quent version of the quantiﬁer rules (∃, l) and (∀, r) are:
G | Θ ⇒Y (a)
G | Θ ⇒(∀x)Y (x) (∀, r)
G | Y (a), Θ ⇒Ξ
G | (∃x)Y (x), Θ ⇒Ξ (∃, l)
where the eigenvariable condition (on the rules’ instances) applies to the whole hyper-
sequent conclusions of the rules.
Deﬁnition 4. Let LL be any (ﬁrst-order) w-simple sequent calculus. HLC
L , the hyper-
sequent version of LL extended with (COM), consists of the hypersequent versions of
the axioms and rules of LL plus (EC), (EW), and (COM).

136
A. Ciabattoni and G. Metcalfe
Example 1. Let ∀FLew be the ﬁrst-order multiset version of the Full Lambek calculus
with exchange and weakening [12] (see Fig. 1), roughly speaking a calculus for ﬁrst-
order intuitionistic logic without contraction with an internalized exchange rule. We
illustrate the use of (COM) with a proof of (lin) in H∀FLC
ew, a hypersequent calculus
for the ﬁrst-order version of the logic of left-continuous t-norms MTL [7,11]:
A ⇒A (ID)
B ⇒B (ID)
A ⇒B | B ⇒A
(COM)
⇒A →B | ⇒B →A (→, r) × 2
⇒(A →B) ∨(B →A) | ⇒(A →B) ∨(B →A) (∨, r) × 2
⇒(A →B) ∨(B →A)
(EC)
3
Criteria for Cut-Elimination
Syntactic criteria for the preservation of cut-elimination when a sequent calculus LL
is “lifted” to the hypersequent calculus HLC
L were introduced in [3]. The criteria in-
tuitively say that (a) any application of (CUT ) can be shifted upwards over each
premise’s rule (i.e. rules are substitutive) and (b) each (CUT ) in which the cut formula
is principal in both premises can be replaced by applications of (CUT ) over smaller
cut-formulae (i.e. logical rules are reductive).
Deﬁnition 5. Let LL be a simple sequent calculus. We call its logical rules {(⋆, r)k}k∈Λ
and {(⋆, l)l}l∈Λ′ for introducing a logical connective ⋆reductive in LL if either Λ or
Λ′ is empty, or for any k ∈Λ, l ∈Λ′, and instances :
Γ1 ⇒Δ1
· · ·
Γn ⇒Δn
Σ ⇒⋆(A1, . . . , Ap)
(⋆, r)k
Γ ′
1 ⇒Δ′
1
· · ·
Γ ′
m ⇒Δ′
m
Σ′, ⋆(A1, . . . , Ap) ⇒Π
(⋆, l)l
the sequent Σ, Σ′ ⇒Π is derivable from {Γi ⇒Δi}1≤i≤n and {Γ ′
i ⇒Δ′
i}1≤i≤m
using only (CUT ) with cut formulae in {A1, . . . , Ap} and the structural rules of LL.
Example 2. The logical rules for the connectives ⊙(multiplicative ”and”), ∧(additive
”and”), ∨, and →in the calculus FLew (see Fig. 1) are reductive.
Let S be a sequent and A a formula; we deﬁne:
[S ←r
A (Σ, A ⇒Π)] = {Γ, Σ ⇒Π | S ≡Γ ⇒A}
[S ←l
A (Σ ⇒A)] = {Γ, Σλ ⇒Δ | S ≡Γ, Aλ ⇒Δ}
Deﬁnition 6. Let LL be a (ﬁrst-order) simple sequent calculus. A rule (r) is said to be
substitutive in LL if for each instance of (r) with premises S1, . . . , Sn and conclusion
S0 the following condition holds:
(*) for any c ∈{r, l}, context formula A (right or left context formula, depending on
c) and single-conclusion sequent S′ (which does not contain any eigenvariable of
(r)), every U ∈[S0 ←c
A S′] has a derivation from [S1 ←c
A S′] . . . [Sn ←c
A S′]
using only the structural rules of LL and (r).

Density Elimination and Rational Completeness for First-Order Logics
137
Example 3. All the rules of the calculus ∀FLew (see Fig. 1 for FLew) are substitutive
in ∀FLew, as are, e.g. the following forms of weak contraction (n ≥2):
Θ, X, X ⇒
Θ, X ⇒
(wc)
Θ, Ψ n
1 ⇒Ξ
. . .
Θ, Ψ n
n−1 ⇒Ξ
Θ, Ψ1, . . . , Ψn−1 ⇒Ξ
(nc)
Theorem 1 ([3]). Let LL be a (ﬁrst-order) simple calculus in which (a) logical rules
are reductive and (b) rules are substitutive, then HLC
L admits cut-elimination.
4
Density Elimination by Substitutions
Instances of the density rule for hypersequent calculi are of the form:
G | Σ, p ⇒Δ | Γ ⇒p
G | Σ, Γ ⇒Δ
(D)
where p is a propositional variable not occurring in Σ, Γ, Δ, or G. We show here that
the conditions given above for cut elimination also guarantee density elimination for
the hypersequent version of any w-simple sequent calculus extended with (COM) and
(D). We introduce for this purpose density elimination by substitutions: a density elim-
ination method that, similarly to normalization for natural deduction systems, removes
applications of (D) by making suitable substitutions in the proof for the introduced vari-
ables. Proceeding “by substitutions” instead of shifting applications of (D) upwards
in the proof (as e.g. in [2,10]) avoids the need for more complicated combinatorial
(“Gentzen’s mix”-style) rules as induction hypotheses.
First some notation. Let HL be any (hyper)sequent calculus. d, S1, . . . , Sn ⊢HL S
stands for a derivation d in HL of the (hyper)sequent S from the assumptions
S1, . . . , Sn. Let H be a hypersequent. H[Σ/pl,Γ⇒Δ /pr] is the hypersequent obtained
by replacing in H all the left occurrences of p with Σ and all the components Π ⇒p
with Π, Γ ⇒Δ. d(s) and H(s) denote the results of substituting the term s for all
free occurrences of x in the derivation d(x) and in the (hyper)sequent H(x), respec-
tively. The length |d| of a derivation d in HL is (the maximal number of inference rules
occurring on any branch of d) + 1.
We require the following crucial lemma (proved by easy inductions on the lengths of
derivations) asserting the “substitutivity” of calculi with substitutive rules:
Lemma 1. Let LL be a (ﬁrst-order) simple sequent calculus with substitutive rules:
(1) If d1(x) ⊢HLC
L H(x), then d1(y) ⊢HLC
L H(y) where y does not occur in d1(x).
(2) If ⊢HLC
L H, then ⊢HLC
L H[A/pl,⇒A /pr] for any formula A and propositional
variable p.
Our density elimination method proceeds by removing applications of (D) which are
topmost in the proof. Let, e.g. d be:
··· d′
G | Γ ⇒p | Σ, p ⇒Δ
(D)
G | Γ, Σ ⇒Δ

138
A. Ciabattoni and G. Metcalfe
a subderivation ending in such an application of (D). The idea is to replace the occur-
rences of p in d in an “asymmetric” way, according to whether p occurs in the antecedent
or consequent of a sequent (component of the hypersequent). Roughly speaking, in d
each sequent Π, p ⇒Π′ is replaced by Π, Γ ⇒Π′ and each Π ⇒p by Π, Σ ⇒Δ.
(Note that condition (∗) in Deﬁnition 1 prevents p’s from jumping from one side of a
sequent in a rule’s premise, to the other in the rule’s conclusion.) The resulting tree is
then transformed into a density-free derivation by replacing:
(a) the application of (D) above by (EC).
(b) each application of a substitutive rule by suitable inferences.
(c) each subproof ending in an application of (COM) and containing one occurrence
of the axiom p ⇒p, as e.g. in
··· d1
G | Γ ′, Π ⇒Π′
G | Γ, Σ ⇒Δ
(COM)
G | Γ, Π ⇒Π′ | Γ ′, Σ ⇒Δ
by a suitable derivation of the form
··· d1
G | Γ ′, Π ⇒Π′
···
G | Γ, Π ⇒Π′ | Γ ′, Σ ⇒Δ
Theorem 2 (Density Elimination). Let LL be a (ﬁrst-order) w-simple sequent calcu-
lus whose rules are reductive and substitutive. If LL includes the rules (⊙, l) and (⊙, r)
in Fig. 1 then HLC
L plus (D) admits density elimination.
Proof. W.l.o.g. consider the above (sub)derivation d in HLC
L plus (D) ending in a
topmost application of (D). By Theorem 1 we can assume that d is cut-free. We ﬁrst
show that for each hypersequent H in d′ in which no component has the form Π, pj ⇒
p, with j ≥1, one can ﬁnd d′
H such that
d′
H ⊢HLC
L G | H[Γ /pl,Σ⇒Δ /pr]
The proof proceeds by induction on the length of the cut-free derivation dH of H in
HLC
L . We distinguish cases according to the last rule (r) applied in dH.
– If |dH| = 0, i.e. H is G′ | B ⇒B, then the claim holds by applying (EW).
– If (r) is (EC) or (EW), then the claim follows by the i.h. and applying (r).
– Let (r) be a rule other than (EC), (EW), or (COM), w.l.o.g. of the form:
G′ | S1 . . . G′ | Sm
G′ | S
Since G′ | S does not contain any component of the form Π, pj ⇒p, with j ≥1,
by condition (∗) in Def. 1 and the absence of cuts, no G′ | Si (with i ∈{1, . . . , m})
contains any Π, pj ⇒p, with j ≥1. Hence by the i.h.:
⊢HLC
L G | (G′ | S1)[Γ /pl,Σ⇒Δ /pr]
. . .
⊢HLC
L G | (G′ | Sm)[Γ /pl,Σ⇒Δ /pr]

Density Elimination and Rational Completeness for First-Order Logics
139
Since the rules of LL are substitutive, using Lemma 1.(1) to take care of renaming
variables, there exists a derivation for:
S1[Γ /pl,Σ⇒Δ /pr], . . . , Sm[Γ /pl,Σ⇒Δ /pr] ⊢LL S[Γ /pl,Σ⇒Δ /pr]
that uses only the structural rules of LL and (possibly) (r). The claim then follows
by (EW), lifting the above derivation from LL to HLL.
– If (r) is (COM), two cases can occur: (a) none of its premises contains any
Π, pj ⇒p, with j ≥1 or (b) one of the premises does. For (a), the claim holds by
applying the i.h. followed by an application of (COM). As an example, consider
the application of (COM):
··· d1
G′ | Γ ′, Π ⇒p
··· d2
G′ | Σ′, pk, Π′ ⇒B
(COM)
G′ | Γ ′, Σ′, pk ⇒B | Π, Π′ ⇒p
Let G∗= G′[Γ /pl,Σ⇒Δ /pr]. By the i.h.:
⊢HLC
L G | G∗| Γ ′, Π, Σ ⇒Δ
and ⊢HLC
L G | G∗| Σ′, Γ k, Π′ ⇒B
Hence by (COM), ⊢HLC
L G | G∗| Γ ′, Σ′, Γ k ⇒B | Π, Π′, Σ ⇒Δ.
For (b), we have an application of (COM):
G′ | Γ ′, Π, pl ⇒p
G′ | Σ′, p(k−l), Π′ ⇒B
(COM)
G′ | Γ ′, Σ′, pk ⇒B | Π, Π′ ⇒p
Letting again G∗= G′[Γ /pl,Σ⇒Δ /pr], by the i.h.:
d1 ⊢HLC
L G | G∗| Σ′, Γ (k−l), Π′ ⇒B.
Our aim is to show ⊢HLC
L G | G∗| Γ ′, Σ′, Γ k ⇒B | Π, Π′, Σ ⇒Δ. If Π′ = ∅,
then the result follows by (w, l) so assume that Π′ = A1, . . . , Am. Let d′
1 be the
derivation obtained by m applications of (⊙, l) to the end-hypersequent of d1, i.e.
··· d1
G | G∗| Σ′, Γ (k−l), Π′ ⇒B
(⊙,l)×m
G | G∗| Σ′, Γ (k−l), A1 ⊙. . . ⊙Am ⇒B
Denote (A1⊙. . .⊙Am) by ⊙Π′. Consider the proof d′ above ending in the premise
G | Γ ⇒p | Σ, p ⇒Δ of the (D) rule. By Lemma 1.(2), d2 ⊢HLC
L (G | Γ ⇒
p | Σ, p ⇒Δ)[⊙Π′/pl,⊙Π′ /pr] for some derivation d2, that is:
d2 ⊢HLC
L G | Γ ⇒⊙Π′ | Σ, ⊙Π′ ⇒Δ.
The desired derivation is then obtained by applying (CUT) to the easily derived
sequent Π′ ⇒⊙Π′ and the end sequent of the following derivation:
··· d2
G | Γ ⇒⊙Π′ | Σ, ⊙Π′ ⇒Δ
(EW)
G | G∗| Γ ⇒⊙Π′ | Σ, ⊙Π′ ⇒Δ
··· d′
1
G | G∗| Σ′, Γ (k−l), ⊙Π′ ⇒B
(CUT)
G | G∗| Σ′, Γ (k−l), Γ ⇒B | Σ, ⊙Π′ ⇒Δ
with subsequent applications of (w, l).

140
A. Ciabattoni and G. Metcalfe
Finally, let H be the premise G | Γ ⇒p | Σ, p ⇒Δ of the (D) rule in d. We have
shown that ⊢HLC
L G | G | Γ, Σ ⇒Δ | Γ, Σ ⇒Δ. (Note that G[Γ /pl,Σ⇒Δ /pr] = G).
The desired proof of G | Γ, Σ ⇒Δ follows by multiple applications of (EC).
⊓⊔
Theorem 3. Let LL be a (ﬁrst-order) w-simple sequent calculus whose rules are reduc-
tive and substitutive. HLC
L plus (D) admits cut elimination and density elimination.
Proof. Let ⋆be a new 2-ary connective. Let L′
L be LL extended with the following
(reductive and substitutive) rules:
Θ, X, Y ⇒Ξ
Θ, X ⋆Y ⇒Ξ (⋆, l)
Θ ⇒Y
Θ′ ⇒X
Θ, Θ′ ⇒X ⋆Y
(⋆, r)
HL′C
L admits cut elimination by Theorem 1. Also, as ⋆has the rules of ⊙, HL′C
L plus
(D) admits density elimination by Theorem 2. Then since HL′C
L has the subformula
property, HLC
L plus (D) admits cut elimination and density elimination.
⊓⊔
5
Axiomatizations
We use density elimination to establish so-called “rational completeness” for a wide
class of ﬁrst-order substructural logics described below. Our vocabulary is assumed to
include the binary connectives ∧, ∨, ⊙, →; the constants f, t, ⊤, ⊥; and the deﬁned
connective A ↔B =def (A →B) ∧(B →A). A logic L is treated as a Hilbert
system, where T ⊢L A if there exists a derivation (in the usual sense) of a formula A
from a set of formulae T in L. We begin by recalling the (propositional) Uninorm logic
UL of [10] (an axiomatization for FLe plus (L5)), given by the axiom schema:
(L1) X →X
(L8) X →(X ∨Y )
(L2) (X →Y ) →((Y →Z) →(X →Z))
(L9) Y →(X ∨Y )
(L3) (X →(Y →Z)) →(Y →(X →Z))
(L10) (X ∧Y ) →Y
(L4) ((X ⊙Y ) →Z) ↔(X →(Y →Z))
(L11) (X ∧Y ) →X
(L5) ((X →Y ) ∧t) ∨((Y →X) ∧t)
(L12) X ↔(t →X)
(L6) ((X →Z) ∧(Y →Z)) →((X ∨Y ) →Z)
(L13) ⊥→X
(L7) ((X →Y ) ∧(X →Z)) →(X →(Y ∧Z))
(L14) X →⊤
together with the inference rules:
X
X →Y
Y
(mp)
X
Y
X ∧Y (adj)
Deﬁnition 7. We call any logic L resulting from UL by adding “extra” propositional
axioms (possibly with “extra” connectives), and satisfying for all formulae A, B, C:
A ↔B ⊢L C(A) ↔C(B)
a core UL-expansion.2
2 A related notion of a “core fuzzy logic”, restricted to logics with weakening, is used in [5].

Density Elimination and Rational Completeness for First-Order Logics
141
Deﬁnition 8. For any core UL-expansion L, ∀L consists of L plus:
(∀1) ∀xY →Y (x/t) (t substitutable for x in Y )
(∀2) ∀x(Y →Z) →(Y →∀xZ) (x not free in Y )
(∀3) ∀x(Y ∨Z) →(Y ∨∀xZ) (x not free in Y )
(∃1) Y (x/t) →∃xY
(t substitutable for x in Y )
(∃2) ∀x(Y →Z) →(∃xY →Z) (x not free in Z)
Y
∀xY (gen)
Semantics for these logics are based on pointed bounded commutative residuated lat-
tices: algebras ⟨L, ∧, ∨, ⊙, →, t, f, ⊥, ⊤⟩with binary operations ∧, ∨, ⊙, →, and con-
stants t, f, ⊥, ⊤such that ⟨L, ∧, ∨, ⊥, ⊤⟩is a bounded lattice; ⟨L, ⊙, t⟩is a commuta-
tive monoid; and z ≤x →y iff x ⊙z ≤y for all x,y,z ∈L.
A UL-algebra is a pointed bounded commutative residuated lattice satisfying:
t ≤((x →y) ∧t) ∨((y →x) ∧t)
If A is an algebra such that each connective of a language L occurs as an operation
of A, then (L-)valuations for A with (non-empty) domain D are deﬁned as partial
functions v from sentences of L with parameters in D into A, total on atomic sentences,
where:
1. If v(Ai) is deﬁned for i = 1. . .m, then v(⋆(A1, . . . , Am)) = ⋆(v(A1), . . . , v(Am))
for each m-ary connective ⋆of L.
2. If for all c ∈D, v(A(x/c)) is deﬁned and inf({v(A(x/c)) : c ∈D}) exists, then
v(∀xA) = inf({v(A(x/c)) : c ∈D}).
3. If for all c ∈D, v(A(x/c)) is deﬁned and sup({v(A(x/c)) : c ∈D}) exists, then
v(∃xA) = sup({v(A(x/c)) : c ∈D}).
A valuation v for A with domain D is safe if v(A) is deﬁned for every sentence with
parameters in D. A formula A is valid in A (assuming that A contains the constant t)
iff for every non-empty set D and for every safe valuation v with domain D, v(A) ≥t.
Deﬁnition 9. For a core UL-expansion L with extra connectives I, an L-algebra is an
algebra A = ⟨L, ∧, ∨, ⊙, →, t, f, ⊥, ⊤, (c)c∈I⟩such that ⟨L, ∧, ∨, ⊙, →, t, f, ⊥, ⊤⟩is
a UL-algebra and each additional axiom of L is valid in A. An L-algebra is called an
L-chain if it is linearly ordered, and a dense L-chain if it is linearly and densely ordered.
Recall that a ﬁrst-order theory T is a set of sentences:
1. T is linear if for each pair A, B of sentences, either A →B ∈T or B →A ∈T .
2. T is ∀L-dense if for each pair A, B of sentences, whenever T ̸⊢∀L A →B, then
for some sentence C, T ̸⊢∀L A →C and T ̸⊢∀L C →B.
3. T is ∀L-Henkin if for each sentence of the form ∀xA(x) where T ̸⊢∀L ∀xA(x),
there is a constant c in the language of T such that T ̸⊢∀L A(c).
The Lindenbaum algebra of a theory T is deﬁned as follows, justiﬁed by the fact that
the connective ↔has the property of a “congruence” for any core UL-expansion:

142
A. Ciabattoni and G. Metcalfe
Deﬁnition 10. Let L be a core UL-expansion L and T a theory. The Lindenbaum
algebra A∀L
T
of a theory T has universe LT = {[A]T : A a sentence} where [A]T =
{B : T ⊢∀L A ↔B}, and operations ⋆([A1]T , . . . , [An]T ) = [⋆(A1, . . . , An)] for
each n-ary connective ⋆of L .
The proof of the following lemma then proceeds exactly as for Lemma 5.2.6 in [8]:
Lemma 2. Let L be a core UL-expansion L and T a ∀L-Henkin theory. Then for
any formula A(x) with one free variable x: [∀xA]T = infc[A(c)]T and [∃xA]T =
supc[A(c)]T where c runs over all constants of T .
6
Adding Density
Here we show that adding the density rule to any ﬁrst-order core UL-expansion L
gives a logic that is complete with respect to dense L-chains. To add the density rule to
our axiomatizations, we explicitly deﬁne derivations from a set of formulae T to take
account of the fact that applications of (density) are sensitive to T and might therefore
require new propositional variables.
Deﬁnition 11. For L a core UL-expansion, let ∀LD be ∀L extended with the rule
(density) (see Section 1). A ∀LD-derivation of a formula C from a set of formulae
T , written T ⊢∀LD C, consists of a sequence of formulae in the vocabulary of ∀LD
extended with countably many new constants and propositional variables, ending with
C and such that each member A of the sequence satisﬁes one of the following:
(1) A ∈T or A is an axiom of ∀L for the extended language.
(2) A is obtained from previous members of the sequence by (mp), (adj), or (gen) i.e.
either B and B →A, B and C (where A is B ∧C), or B(a) (where A is ∀xB(x)
and the eigenvariable condition for T is satisﬁed) occur earlier in the sequence.
(3) A is obtained from a previous member of the sequence by (density), i.e. A is
(B →C) ∨D and (B →p) ∨(p →C) ∨D occurs earlier in the sequence, where
p is a new propositional variable not occurring in T , B, C, or D.
Soundness for ∀LD with respect to dense L-chains is established as follows.
Lemma 3. Let L be a core UL-expansion. If T ⊢∀LD A, then for every dense L-chain
and safe valuation v with non-empty domain D, if v(B) ≥t for all B ∈T , then
v(A) ≥t. In particular, if ⊢∀LD A, then A is valid in all dense L-chains.
Proof. We proceed by induction on the height of a ∀LD-derivation for T ⊢∀LD A,
checking the validity of axioms and soundness of rules in the usual manner, the only
novel case being (density). Suppose contrapositively that there is a dense L-chain and
non-empty domain D with a safe valuation v such that v(D) ≥t for all D ∈T , and
v((A →B) ∨C) < t. It follows that v(A →B) < t and v(C) < t, and hence
also that v(A) > v(B). Since the algebra is dense, there exists an element w such that
v(A) > w > v(B). Recall that the propositional variable p in (density) does not occur
in T , A, B, or C. Hence we can extend the valuation v with v(p) = w. It follows that
v((A →p) ∨(p →B) ∨C) < t.
⊓⊔

Density Elimination and Rational Completeness for First-Order Logics
143
We require the following properties (established as in the propositional case in [10]):
Lemma 4. Let L be a core UL-expansion:
(a) If T, A ⊢∀LD C and T, B ⊢∀LD C, then T, A ∨B ⊢∀LD C.
(b) If T, A ⊢∀LD C and T ⊢∀LD A ∨C, then T ⊢∀LD C.
Deﬁnition 12. A confusion of a set of formulae T is deﬁned inductively as follows:
1. t, ⊤, and any element of T are confusions of T .
2. If C1 and C2 are confusions of T , then so are C1 ⊙C2 and C1 ∧C2.
Lemma 5. Let L be a core UL-expansion:
(a) If T ⊢∀LD A, then T0 ⊢∀LD A for some ﬁnite subset T0 of T .
(b) If T is ﬁnite, then T ⊢∀LD A iff ⊢∀LD C →A for some confusion C of T .
(c) If A is a confusion of T , then T ⊢∀L A.
We are now in a position to establish our key lemmas.
Lemma 6. Let L be a core UL-expansion and T a countable theory. If T ̸⊢∀LD A,
then there exists a countable linear ∀L-dense ∀L-Henkin theory ˆT such that T ⊆ˆT
and ˆT ̸⊢∀LD A.
Proof. We construct ˆT in countably many steps. First we extend the vocabulary with
countably many new propositional variables and constants not occurring in T or A. In
the construction of ˆT we have to: (1) deal with linearity and ∀L-density for each pair of
sentences (in the extended vocabulary), and (2) deal with the ∀L-Henkin property for
each sentence of the form ∀xA (in the extended vocabulary). Since these are countably
many tasks we can interleave them.
We begin by deﬁning T0 = T and C0 = A, noting that T0 ̸⊢∀LD C0. Now for the
induction step, assume that Tn and Cn have been constructed such that Tn ̸⊢∀LD Cn.
We construct Tn+1 and Cn+1 such that Tn ⊆Tn+1; Tn+1 ̸⊢∀LD Cn+1; Tn+1 ⊢∀LD
Cn →Cn+1; and Tn+1 fulﬁlls the n-th task. We have two cases:
(1) The n-th task is dealing with linearity and ∀L-density for the sentences A, B.
– If Tn ∪{A →B, B →A} ̸⊢∀LD Cn, then it is sufﬁcient to deﬁne:
Tn+1 = Tn ∪{A →B, B →A} and Cn+1 = Cn
– Suppose that the previous case does not apply. Let q be a propositional variable not
occurring in Tn, A, B, or Cn. We claim that one of the following conditions holds:
(a) Tn ∪{A →B} ̸⊢∀LD Cn ∨(B →q) ∨(q →A).
(b) Tn ∪{B →A} ̸⊢∀LD Cn ∨(A →q) ∨(q →B).
Suppose that (a) does not hold. Then by the density rule:
Tn ∪{A →B} ⊢∀LD Cn ∨(B →A)
and since Tn ∪{A →B, B →A} ⊢∀LD Cn, by Lemma 4 (b):
Tn ∪{A →B} ⊢∀LD Cn

144
A. Ciabattoni and G. Metcalfe
If (b) also does not hold, Tn ∪{B →A} ⊢∀LD Cn, so by Lemma 4 (a):
Tn ∪{(A →B) ∨(B →A)} ⊢∀LD Cn
But since ⊢UL (A →B) ∨(B →A) (see e.g. [10]), we get Tn ⊢LD Cn which
contradicts the induction hypothesis. Hence, if (a) holds, let:
Tn+1 = Tn ∪{A →B} and Cn+1 = Cn ∨(B →q) ∨(q →A)
and if (b) holds, let:
Tn+1 = Tn ∪{B →A} and Cn+1 = Cn ∨(A →q) ∨(q →B)
Clearly Tn+1 is linear in both cases, Tn+1 ̸⊢∀LD Cn+1, and Tn+1 ⊢∀LD Cn →
Cn+1. Moreover, if Tn+1 ̸⊢∀L A →B, then Tn+1 ̸⊢∀LD Cn∨(A →q)∨(q →B),
so Tn+1 ̸⊢∀L A →q and Tn+1 ̸⊢∀L q →B. Similarly, if Tn+1 ̸⊢∀L B →A, then
Tn+1 ̸⊢∀L B →q and Tn+1 ̸⊢∀L q →A, so ∀L-density holds.
(2) Suppose that the n-th task is dealing with the ∀L-Henkin property for ∀xA(x).
Let c be a new constant not occurring in Tn, Cn, or A(x).
– If Tn ̸⊢∀L Cn ∨A(c), then Tn ̸⊢∀L ∀xA(x), and let Tn+1 = Tn, and Cn+1 =
Cn ∨A(c).
– If Tn ⊢∀L Cn ∨A(c), then Tn ⊢∀L Cn ∨A(x) (replacing c in the proof by a
variable x not occurring in Cn). Hence Tn ⊢∀L ∀x(Cn ∨A(x)) by (gen), and by
(∀3), Tn ⊢∀L Cn ∨∀xA(x). So Tn ∪{∀xA(x) →Cn} ⊢∀L Cn. It follows that
Tn ∪{Cn →∀xA(x)} ̸⊢∀L Cn (since otherwise Tn ⊢∀LD Cn a contradiction)
and Tn ∪{Cn →∀xA(x)} ⊢∀L ∀xA(x) (using Tn ⊢∀L Cn ∨A(c)). So let
Tn+1 = Tn ∪{Cn →∀xA(x)} and Cn+1 = Cn.
Now take ˆT = 
n∈N Tn. ˆT is linear and ∀L-dense by construction. Also ˆT ̸⊢∀LD A
since otherwise Tn ⊢∀LD A for some n, and since Tn ⊢∀LD Ci →Ci+1 for i =
1 . . . n, Tn ⊢∀LD Cn, a contradiction. Finally to see that ˆT is ∀L-Henkin, suppose
that ˆT ̸⊢∀L ∀xA(x) where ∀xA(x) is a sentence dealt with in step n. It follows that
Tn+1 ̸⊢∀L ∀xA(x). But then for step n in the above construction, we must have the ﬁrst
possibility Tn ̸⊢∀L Cn ∨A(c) where Cn+1 = Cn ∨A(c). Hence also ˆT ̸⊢∀L Cn ∨A(c).
So ˆT ̸⊢∀L A(c).
⊓⊔
Lemma 7. Let L be a core UL-expansion and T a countable linear ∀L-dense ∀L-
Henkin theory. If T ̸⊢∀LD A, then there exists a countable dense L-chain and safe
valuation v with non-empty domain D, such that v(B) ≥t for all B ∈T , and v(A) < t.
Proof. A∀L
T
is an L-algebra. Moreover, A∀L
T
is linearly and densely ordered, since for
all sentences A, B: (1) either A →B ∈T or B →A ∈T , and (2) if T ̸⊢∀L A →B,
then T ̸⊢∀L A →C and T ̸⊢∀L C →B for some sentence C. Let D be the set of all
constants of the vocabulary of T (adding one if necessary so that D is non-empty) and
A. Deﬁne a valuation v with domain D such that v(p(c1, . . . , cm)) = [p(c1, . . . , cm)]T
for each m-ary predicate p. We claim that v(B) = [B]T for all formulae B and hence in
particular v(B) ≥t for all B ∈T , and v(A) = [A]T < [t]T as required. We proceed by
induction on the complexity of B, the atomic case holding by deﬁnition and the case of
propositional connectives being easy. The quantiﬁer cases follow using Lemma 2.
⊓⊔

Density Elimination and Rational Completeness for First-Order Logics
145
Combining Lemmas 6 and 7 with Lemma 3 we obtain the following result:
Theorem 4. Let L be a core UL-expansion and T a countable theory. The following
are equivalent:
(1) T ⊢∀LD A.
(2) For every dense L-chain and safe valuation v with non-empty domain D, if v(B) ≥
t for all B ∈T , then v(A) ≥t.
In particular, ⊢∀LD A iff A is valid in all dense L-chains.
As an interesting aside, note that C = ∀x(A(x) ⊙B) →(∀xA(x) ⊙B) is valid in all
dense BL-chains [8], where BL is H´ajek’s Basic fuzzy logic, the logic of continuous
t-norms. So by the preceding theorem C is derivable in ∀BLD. However, C is not valid
in all BL-chains [7] and hence not derivable in ∀BL. The density rule is therefore not
admissible for ∀BL, and it remains an intriguing question as to whether ∀BLD can be
obtained as an axiomatic extension of this logic.
7
Rational Completeness
We are ready now to put together the various pieces and establish rational complete-
ness for a wide class of ﬁrst-order logics; i.e. show completeness with respect to dense
chains. First, we need a way of connecting axiomatizations with hypersequent calculi.
Deﬁnition 13. The standard interpretation function I is deﬁned as follows:
1. I(Γ ⇒C) = ⊙Γ →C, I(⇒C) = C, I(Γ ⇒) = ⊙Γ →⊥, and I(⇒) = ⊥.
2. I(Γ1 ⇒Δ1 | . . . | Γn ⇒Δn) = I(Γ1 ⇒Δ1) ∨. . . ∨I(Γn ⇒Δn).
Lemma 8. Let L be a core UL-expansion and LL a (ﬁrst-order) w-simple sequent
calculus whose rules are reductive and substitutive, such that ⊢HLC
L G iff ⊢∀L I(G):
(a) ⊢HLC
L +(D) G iff
⊢∀LD I(G).
(b) ⊢∀L A iff
⊢∀LD A.
Proof. (a) For the left-to-right direction, suppose that ⊢∀L I(G) ∨I(Γ1, p ⇒Δ) ∨
I(Γ2 ⇒p) where p does not occur in G, Γ1, Γ2, or Δ. It follows easily that ⊢∀L I(G)∨
(p →I(Γ1 ⇒Δ))∨I(Γ2 ⇒p), and hence by (density), that ⊢∀LD I(G)∨I(Γ1, Γ2 ⇒
Δ) as required. For the right-to-left direction, it is sufﬁcient to show that (density)
(with T = ∅) is admissible for HLC
L + (D). If ⊢HLC
L +(D)⇒(A →p) ∨(p →B) ∨C
where p does not occur in A, B, or C, then (easily) ⊢HLC
L +(D) A ⇒p | p ⇒B | ⇒C.
Hence by (D), ⊢HLC
L +(D) A ⇒B | ⇒C. Using (EC), (∨, r)1, (∨, r)2, and (→, r),
it follows that ⊢HLC
L +(D)⇒(A →B) ∨C as required.
(b) The left-to-right direction is trivial. For the right-to-left direction, suppose that
⊢∀LD A. Then by (a), ⊢HLC
L +(D)⇒A, and by Theorem 2, ⊢HLC
L ⇒A. Hence by
hypothesis and Deﬁnition 13, ⊢∀L A.
⊓⊔
Our main theorem now states that the ﬁrst order version of any core UL-expansion
which has a suitable hypersequent calculus is rational complete.

146
A. Ciabattoni and G. Metcalfe
Theorem 5. Let L be a core UL-expansion and LL a (ﬁrst-order) w-simple sequent
calculus whose rules are reductive and substitutive, such that ⊢HLC
L G iff ⊢∀L I(G).
Then ∀L is rational complete, i.e. the following are equivalent:
(1) T ⊢∀L A.
(2) For every dense L-chain and safe valuation v with non-empty domain D, if v(B) ≥
t for all B ∈T , then v(A) ≥t.
In particular, ⊢∀L A iff A is valid in all dense L-chains.
Proof. From (1) to (2) is easy. If (2) holds, then by Theorem 4, T ⊢∀LD A. By Lemma
5 (a), there is a ﬁnite subset T0 of T such that T0 ⊢∀LD A, and by Lemma 5 (b),
⊢∀LD C →A for some confusion C of T0. By Lemma 8 (b), ⊢∀L C →A and, by
Lemma 5 (c), T0 ⊢∀L C. Hence, by (mp), T0 ⊢∀L A and therefore also T ⊢∀L A.
⊓⊔
For example, let ∀SMTL and ∀CnMTL (n ≥2) be the ﬁrst-order versions of the
logics SMTL [6] and CnMTL (n ≥2) [4]. Hypersequent calculi for these logics,
HLC
SMTL and HLC
CnMTL are obtained by adding hypersequent versions of the rules
(wc) and (nc) to the calculus H∀FLC
ew for ∀MTL (see Examples 1 and 3). Hence:
Corollary 1. ∀MTL , ∀SMTL, and ∀CnMTL (n ≥2) are rational complete.
References
1. A. Avron. A constructive analysis of RM. Journal of Symbolic Logic, 52(4):939–951, 1987.
2. M. Baaz and R. Zach. Hypersequents and the proof theory of intuitionistic fuzzy logic. In
Proceedings of CSL 2000, pages 187–201. LNCS, Springer-Verlag, 2000.
3. A. Ciabattoni. Automated generation of analytic calculi for logics with linearity. CSL04:
Computer Science Logic. LNCS, 3210:503–517, 2004.
4. A. Ciabattoni, F. Esteva, and L. Godo. T-norm based logics with n-contraction. Neural
Network World, 12(5):441–453, 2002.
5. P. Cintula and P. H´ajek. On theories and models in fuzzy predicate logics. Journal of Sym-
bolic Logic, 71(3):832–863, 2006.
6. F. Esteva, J. Gispert, L. Godo, and F. Montagna. On the standard and rational completeness
of some axiomatic extensions of the monoidal t-norm logic. Studia Logica, 71(2):199–226,
2002.
7. F. Esteva and L. Godo. Monoidal t-norm based logic: towards a logic for left-continuous
t-norms. Fuzzy Sets and Systems, 124:271–288, 2001.
8. P. H´ajek. Metamathematics of Fuzzy Logic. Kluwer, Dordrecht, 1998.
9. S. Jenei and F. Montagna. A proof of standard completeness for Esteva and Godo’s MTL
logic. Studia Logica, 70(2):183–192, 2002.
10. G. Metcalfe and F. Montagna. Substructural fuzzy logics. To appear in Journal of Symbolic
Logic. http://www.math.vanderbilt.edu/people/metcalfe/publications.
11. F. Montagna and H. Ono. Kripke semantics, undecidability and standard completeness for
Esteva and Godo’s logic MTL∀. Studia Logica, 71(2):227–245, 2002.
12. H. Ono and Y. Komori. Logic without the contraction rule. Journal of Symbolic Logic,
50:169–201, 1985.
13. M. Takano.
Another proof of the strong completeness of the intuitionistic fuzzy logic.
Tsukuba J. Math., 11:851–866, 1984.
14. G. Takeuti and T. Titani. Intuitionistic fuzzy logic and intuitionistic fuzzy set theory. Journal
of Symbolic Logic, 49(3):851–866, 1984.

Extracting the Resolution Algorithm from a
Completeness Proof for the Propositional
Calculus
Robert Constable and Wojciech Moczydlowski⋆
Department of Computer Science, Cornell University, Ithaca, NY 14853, USA
{rc,wojtek}@cs.cornell.edu
Abstract. We prove constructively that for any propositional formula φ
in Conjunctive Normal Form, we can either ﬁnd a satisfying assignment
of true and false to its variables, or a refutation of φ showing that it is
unsatisﬁable. This refutation is a resolution proof of ¬φ. From the for-
malization of our proof in Coq, we extract Robinson’s famous resolution
algorithm as a Haskell program correct by construction. The account is
an example of the genre of highly readable formalized mathematics.
1
Introduction
Recently Jean Gallier [1] gave a simple constructive proof that the resolution
method for the propositional calculus is complete – noting that other proofs in
the literature [2,3,4,5] are by contradiction, hence weaker. Gallier’s method is to
provide an explicit resolution algorithm and a correctness proof for it.
We establish a slightly stronger result in a diﬀerent way, by giving a simple
constructive proof, formalized in Coq. The Coq system enforces constructiv-
ity and extracts from this proof an eﬃcient resolution program (in Haskell or
OCaml). Our proof is the kind of argument one would see in a logic textbook. Coq
guarantees that it is constructive – which is not as well established in Gallier’s
presentation. The result is also stronger because executable code is extracted.
Our presentation is an instance of the new genre of formalized mathematics
which we have been promoting, in both type theory [6,7] and set theory [8]. A
salient feature of this genre is precise clarity. Moreover, the deﬁnitions serve a
dual purpose, deﬁning data types as well as mathematical concepts. Likewise,
the proofs provide justiﬁcations as well as algorithms. We strive to make the
account more readable than ordinary mathematical texts. If we succeed, then
there will be no question that formal text is a more useful way to present certain
results in mathematics. The reader can judge these claims directly.
2
The Resolution Method
The resolution method applies to formulas in Constructive Normal Form (CNF),
such (P ∨Q) ∧(¬P) ∧(¬Q ∨P). These are built from variables (atoms) such
⋆The authors have been partly supported by NSF grant CNS-0614790.
S. Artemov and A. Nerode (Eds.): LFCS 2007, LNCS 4514, pp. 147–161, 2007.
c
⃝Springer-Verlag Berlin Heidelberg 2007

148
R. Constable and W. Moczydlowski
as P, Q, R, . . . or negations of them. These positive or negative variables are
called literals. Disjunctions of them are called clauses, so a CNF formula is a
conjunction of clauses built out of literals.
Resolution is an attempt to refute a CNF formula φ. To refute is to show
that the formula cannot be true no matter what truth values, true or false,
are assigned to the variables. What is so noteworthy is that a formula can be
refuted by systematically applying one rule to its clauses over and over. The rules
is called resolution; it resolves two clauses into a new one. Refutation starts with
two clauses of φ and produces a new one by resolution and then is applied to
either original clauses from φ or newly created ones.
Our result is that given a CNF formula φ, we can either refute it by producing
a refutation r or show that it is satisﬁable by producing an assignment of truth
values, true, false, to the variables. We also show that if r refutes φ, then φ is
not satisﬁable. Thus ¬φ is valid, and indeed, the refutation r can be seen as a
proof of ¬φ.
2.1
Prerequisites
Booleans, denoted by bool, consist of two elements: false and true. Natural num-
bers are denoted by nat. The standard operations on booleans are called andb,
orb and negb. The notation list A stands for lists with elements coming from A.
We denote the empty list by [] and a list consisting of elements a1, a2, ..., ak by
[a1, . . ., ak]. The concatenation of lists l1 and l2 is denoted by l1@l2.
We will use the typewriter font for concepts in Coq. Our choice of names
mostly coincides with its standard library. Lists are an important exception: in
Coq, the list [a1, a2, . . ., ak] is denoted by a1::a2::...::ak::nil and l1@l2 by
l1 ++ l2. Thus in particular [a]@l is rendered in Coq as a::l and the empty
list [] by nil,
2.2
Literals, Clauses, Formulas and Valuations
We are interested in formulas in Conjunctive Normal Form (CNF). To build their
representation in Coq, we represent propositional variables P, Q, . . . as natural
numbers. To ﬁx our attention, in the examples P, Q, R are represented by 1, 2
and 3, respectively. A literal is either an atom or its negation. We represent the
former case by labelling the atom with a tag pos and the latter by labelling it with
a tag neg. A clause is a list of literals and a (CNF) formula is a list of clauses. For
example, the formula φ ≡(P ∨R)∧¬P ∧Q∧(P ∨¬Q∨¬R) is represented by the
list [[pos 1, pos 3], [neg 1], [pos 2], [pos 1, neg 2, neg 3]]. The function notlit for a
given literal returns its negation: notlit(pos n) = neg n, notlit(neg n) = pos n.
The formalization of these deﬁnitions in Coq follows. Anything between
(* *) characters is a comment.
(* lit is a disjoint union nat + nat.
Its components are natural numbers labelled by pos and neg *)

Extracting the Resolution Algorithm from a Completeness Proof
149
Inductive lit : Set :=
pos : nat -> lit
| neg : nat -> lit.
Definition notLit (l : lit) : lit :=
match l with
pos n => neg n
| neg n => pos n
end.
Definition clause := list lit.
Definition form := list clause.
Definition P : nat := 1.
Definition Q : nat := 2.
Definition R : nat := 3.
Definition phi : form := (pos
P:: (pos R) :: nil) ::
(neg P :: nil) ::
(pos Q:: nil) ::
(pos P :: (neg Q) ::(neg R) :: nil) ::
nil.
A valuation assigns booleans to atoms in a formula. We represent valua-
tions as lists of natural numbers. The intended meaning, captured in the for-
mal deﬁnitions below, is that the valuation v assigns true to the atom rep-
resented by a number n, if n is an element of v. For example, the valuation
{P →false, Q →true, R →true} is represented as [2, 3].
Definition val := list nat.
The value of a literal pos n under a valuation v is equal to true if n is an
element of v. The value of a negated literal, neg n, is equal to false if n is not
an element of v.
(* valLit : lit -> val -> bool *)
Definition valLit (l : lit) (v : val) :=
match l with
pos n => elemL nat eqNat n v
| neg n => negb (elemL nat eqNat n v)
end.
The value of a clause c under the valuation v is an element of bool. It is deﬁned
by recursion on c. If c is empty, the value is false. Otherwise, if c is a list with

150
R. Constable and W. Moczydlowski
the ﬁrst element x and the rest of its elements denoted by xs, it is a disjunction
of the value of the literal x and the value of xs. The value of a formula f is
deﬁned similarly.
(* valClause : clause -> val -> bool
valClause nil v = false
valClause (x::xs) v = orb (valLit x v) (valClause xs v)
*)
Fixpoint valClause (c : clause) (v : val) { struct c } : bool :=
match c with
nil => false
| x :: xs => orb (valLit x v) (valClause xs v)
end.
Fixpoint valForm (f : form) (v : val) { struct f } : bool :=
match f with
nil => true
| x :: xs => andb (valClause x v) (valForm xs v)
end.
Note that the “empty” formula is always true, while the “empty” clause is
always false. We will sometimes say that the valuation v falsiﬁes a formula f to
mean that valForm(f)(v) = false.
A formula f is satisﬁable if there is a valuation which sets it to true. Or,
in other words, if the set of valuations v such that valForm(f)(v) = true is
not empty. In Coq’s type theory, truth of a proposition is equivalent to the
non-emptiness of a corresponding type, so the following deﬁnition captures sat-
isﬁability correctly.
Definition satisfiable (f : form):= { v : val| valForm f v = true }.
A reader unfamiliar with type theory can think about { v : val | valForm
f v = true } as a (witness-providing) existential quantiﬁer:
{ v : val | valForm f v = true } ≈∃v : val. valForm(f)(v) = true
2.3
Resolutions
The deﬁnition of the resolution tree we use is taken from [1]. Structurally, it is a
binary tree. Its leaves are labelled with clauses. Its nodes are labelled with pairs
consisting of a literal and a clause.
Inductive resol : Set :=
leaf : clause -> resol
| node : lit -> clause -> resol -> resol -> resol.

Extracting the Resolution Algorithm from a Completeness Proof
151
For example, the tree T deﬁned as1:
(R, [])







(P, [R])


(Q, [¬R])







(P, ¬Q ∨¬R)

	
	
	
	
	
P ∨R
[¬P]
[Q]
P ∨¬Q ∨¬R
[¬P]
is represented as:
(* The prefix ex stands for ’’example’’ *)
Definition exTree : resol :=
node (pos R) (nil)
(node (pos P) (pos R::nil)
(leaf (pos P::(pos R)::nil))
(leaf (neg P::nil))
)
(node (pos Q) (neg R::nil)
(leaf (pos Q::nil))
(node (pos P) (neg Q::(neg R)::nil)
(leaf (pos P::(neg Q)::(neg R)::nil))
(leaf (neg P::nil))
)
).
Note that each node in a tree is labelled with a clause. Let us denote this
clause by clauseR:
Definition clauseR (r:resol) : clause := match r with
leaf c => c
| node l c r1 r2 => c
end.
The premises of a tree are the clauses at its nodes.
Fixpoint premises (r : resol) {struct r}: list clause:= match r with
leaf c => c::nil
| node l c r1 r2 => (premises r1) ++ (premises r2)
end.
So the premises of T are [P ∨R, [¬P], [Q], P ∨¬Q ∨¬R, [¬P]]:
1 To increase readability, we render clauses with more than one element in a traditional
way instead of their list representation.

152
R. Constable and W. Moczydlowski
Lemma ex1 :
premises exTree =
(pos P::(pos R)::nil)::
(neg P::nil)::
(pos Q::nil)::
(pos P::(neg Q)::(neg R)::nil)::
(neg P::nil)::
nil.
The correctness restriction makes the trees more meaningful. Intuitively, each
node should correspond to a resolution step. A clause c at the node results from
the clauses c1, c2 at its children by removing l form c1, the negation of l from c2
and retaining the rest of c1, c2. So c = (c1 −{l}) ∪(c2 −{¬l}).
In the formal deﬁnition, eqCS denotes equality of clauses treated as ﬁnite sets
and elemC l c checks whether the literal l is an element of the clause c.
Fixpoint correctR (r : resol) : bool := match r with
leaf c => true
| node l c r1 r2 =>
andb (andb (correctR r1) (correctR r2))
(andb
(andb (elemC l (clauseR r1))
(elemC (notLit l) (clauseR r2)))
(eqCS c (removeC l (clauseR r1) ++
(removeC (notLit l) (clauseR r2)))))
end.
Resolutions therefore are these trees that satisfy the correctness condition.
Definition res : Set := { r : resol | correctR r = true }.
We can easily show that correctR(exT ree) = true and deﬁne an element
exRes of res corresponding to the tree exT ree.
(* p denotes the proof that correctR exTree = true *)
Definition exRes : res := exist
exTree p.
Having deﬁned the resolution trees, we need to relate them to formulas. A
tree r corresponds to a formula f if the premises of r are a subset of the clauses
of f. A tree r refutes a formula f if it corresponds to f and its root is labelled
with the empty clause. We call a formula refutable, if there is a resolution tree
which refutes it.
(* subL clause eqC f1 f2 checks whether f1 is a subset of f2 *)
(* proj1 sig, given a resolution, returns the underlying tree.
So proj1 sig exRes = exTree. *)
Definition corresponds (r : res) (f : form) :=
subL clause eqC (premises (proj1 sig r)) f.

Extracting the Resolution Algorithm from a Completeness Proof
153
Definition refutes (r: res) (f : form) :=
andb (corresponds r f)
(eqC (clauseR (proj1 sig r)) nil).
The proof that the resolution tree exRes refutes φ is straightforward.
Lemma ex2 : refutes exRes phi = true.
2.4
Refuted Formulas Are Unsatisﬁable
To show that we have chosen our deﬁnitions correctly, we prove the following
theorem:
Theorem 1. For all resolutions r and formulas f, if r refutes f, then f is not
satisﬁable.
In other words:
Theorem resres : forall (r : res) (f : form),
refutes r f = true ->
satisfiable f -> False.
Proof (Sketch). Take a resolution r, suppose that r refutes f and take a valuation
v which sets f to true. We know that the root of r is labelled by the empty clause.
In this situation we can ﬁnd a clause c in the premises of r such that v sets c to
false. We do this by starting from the root of r and proceeding down, choosing at
the node labelled by l the left child if v(l) = false and the right one otherwise.
We take c to be the clause labelling the leaf we end at. Furthermore, we collect on
the way literals in the following way: if a node is labelled by l and v(l) = false,
we collect l; otherwise we collect the negation of l. Let d denote the resulting
clause. We can easily prove that c is a subclause of d and that v falsiﬁes d. Thus
also v(c) = false.
Since r refutes f, the clause c is among the clauses of f. It is therefore easy to
see that the value of f under v must be false as well. Therefore valForm(f)(v) =
false, by the assumption about v we also have valForm(f)(v) = true and since
true ̸= false, we get the claim.
We will now show how to make this proof precise. First, we formalize the process
of “proceeding down, starting from the root of r”, which resulted in the clause
c. For the examples, we use our valuation {P →false, Q →true, R →true}.
Fixpoint contraClause (r : resol) (v : val) { struct r} : clause :=
match r with
leaf c => c
|node l c r1 r2 =>
if valLit l v then contraClause r2 v
else contraClause r1 v
end.

154
R. Constable and W. Moczydlowski
Definition exVal : val := Q::R::nil.
Lemma ex3:contraClause exTree exVal = pos P::(neg Q)::(neg R)::nil.
Lemma 1. If r corresponds to f, then the clause picked using contraClause is
equal to one of the clauses of f.
Lemma cc1 : forall (r : res) (f : form) (v : val),
corresponds r f = true ->
elemL
eqC (contraClause (proj1 sig r) v) f = true.
Second, we formalize “collecting literals on the way”:
Fixpoint lontraClause (r : resol) (v : val) { struct r} : clause :=
match r with
leaf c => nil
|node l c r1 r2 =>
if valLit l v then (notLit l)::lontraClause r2 v
else l::(lontraClause r1 v)
end.
Lemma ex4 : lontraClause exTree exVal = neg R::(neg Q)::(pos P)::nil.
Lemma 2. For any resolution r and valuation v, v falsiﬁes lontraClause r v.
Lemma lv1 : forall (r : res) (v : val),
valClause (lontraClause (proj1 sig r) v) v = false.
These deﬁnitions enable us to state and prove the main lemma:
Lemma lc1 : forall (r : res) (f : form) (v : val),
let tree := proj1 sig r in
subL
eqLit (contraClause tree v)
((clauseR tree) ++ (lontraClause tree v)) = true.
Proof. Straightforward induction on r.
With Lemma lc1 at hand, we show
Lemma lv2 : forall (r : res) (f : form) (v : val),
refutes r f = true ->
valClause (contraClause (proj1 sig r) v) v = false.
Proof. Since r refutes f, the root of r is labelled by the empty clause. Let c
denote contraClause(r)(v) and let l denote lontraClause(r)(v). By Lemma lc1,
c ⊆l. By Lemma lv1, valClause(l)(v) = false. The claim easily follows.

Extracting the Resolution Algorithm from a Completeness Proof
155
Now we can show formally what we just sketched at the beginning of this section:
The proof of Theorem 1. Take any f, r refuting f and a valuation v. Suppose
the value of f under v is true. Let c denote contraClause(r, v). By Lemma lv2,
the value of c under v is false. By Lemma cc1, c is one of the clauses of f, thus
also the value of f under v is false, which contradicts our assumption. Therefore
f is not satisﬁable.
2.5
Graft and Percolate
There are two operations on the trees which we will use in the proof of the ﬁnal
theorem. Both are taken from [1].
The percolate function takes a tree r, a clause c and a literal l as its argu-
ments. It appends l to all clauses in the premises r which are equal (as ﬁnite
sets) to c. It further “percolates” l up the tree: it travels towards the root and
appends l to all clauses labelling nodes on the way. It stops when it either
reaches the root or the node which utilizes l in the resolution step. The for-
mal deﬁnition follows; the helper function percolate0 returns additionally a
boolean value, set to false if the percolating process is to continue and to true
otherwise.

156
R. Constable and W. Moczydlowski
Definition percolate (r : resol) (a : clause) (l : lit) : resol :=
fst (percolate0 r a l).
Definition exPerc := percolate exTree (neg P::nil) (neg Q).
For example, exPerc is the following tree. The ¬Q attached to the left [¬P]
clause percolated to the top, while the process of percolating the one attached to
the right [¬P] clause was stopped at the node labelled with (P, ¬Q ∨¬Q ∨¬R).
(R, [¬Q])

















(P, ¬Q ∨R)












(Q, [¬R])








(P, ¬Q ∨¬Q ∨¬R)








P ∨R
¬Q ∨¬P
[Q]
P ∨¬Q ∨¬R
¬Q ∨¬P
The main fact about the percolate operation is that it preserves the correctness
condition of resolution trees:
Lemma percolateCorrect : forall (r : resol) (a : clause) (l : lit),
correctR r = true -> correctR (percolate r a l) = true.
The graft operation takes two trees r, s and attaches s to any leaf of r labelled
with the clause equal to the root clause of r.
Fixpoint graft (r s : resol) { struct r} : resol :=
match r with
leaf c => if eqC (clauseR s) c then s else r
|node l c r1 r2 => node l c (graft r1 s) (graft r2 s)
end.
Grafting preserves the correctness condition as well.
Lemma graftCorrect : forall (r s : resol),
correctR r = true ->
correctR s = true ->
correctR (graft r s) = true.
2.6
The Completeness Theorem
We are now ready to present the completeness theorem. It will be proved by
measure induction on formulas. The measure of a formula f = [c1, . . ., ck] is
deﬁned as the number of disjunction symbols in the formula: measure(f) =
Σi=1...kpred(length(ck)), where length for a given list returns its length and pred
denotes the total predecessor function on natural numbers: pred(0) = 0, pred(n+
1) = n.

Extracting the Resolution Algorithm from a Completeness Proof
157
Fixpoint measure (f : form) : nat :=
match f with
nil => 0
| x :: xs => pred (length x) + (measure xs)
end.
We call a formula one-literal if all its clauses have at most one literal. Any
formula of measure 0 is one-literal:
Lemma l0 : forall f : form, measure f = 0 -> onelL lit f = true.
For any formula f, we provide a deﬁnition of a predicate stating that either f is
satisﬁable or refutable:
Definition fPred (f : form) : Set :=
sum (satisfiable f) ({ r : res | refutes r f
= true}).
We ﬁrst tackle the base case of the inductive argument:
Lemma l3 : forall f : form, onelL lit f = true
-> fPred f.
Proof. By induction on f (as a list). If f is empty, then it is trivially satisﬁable
with any valuation as a witness. For the inductive step, suppose we have the
claim for f. We need to show it for f extended with any clause a. So suppose
[a]@f is one-literal. Then obviously so is f, so fPred(f) holds. We have two
cases to consider:
– f is satisﬁable. Let v be the valuation which sets f to true. We know that a
has at most one literal. If a is empty, then the resolution tree consisting of
a single leaf labelled with the empty clause refutes f (recall that the value
of the empty clause is false). Otherwise, it consists of a single literal l. Let
notl denote the negation of l. We have 3 subcases to consider:
• [notl] is one of the clauses of f. Then the resolution tree with two leaves
labelled by [l] and [notl] and the node labelled with the pair (l, []) refutes
f.
• [l] is one of the clauses of f. Then [a]@f is satisﬁable by v as well, as v
must set the value of [l] to true.
• Neither [notl] nor [l] is a clause of f. Then [a]@f is satisﬁable by v
extended to set a to true.
– There is a resolution r refuting f. Then it is easy to see that r refutes [a]@f
as well.
Finally, we prove the main theorem.
Theorem 2. Any formula is either satisﬁable or refutable.
Theorem t : forall f : form, fPred f.

158
R. Constable and W. Moczydlowski
Proof. We proceed by measure induction on f using the function measure.
The case where measure(f) = 0 is handled by Lemmas l0 and l3. Otherwise,
measure(f) > 0. This implies that there is a clause c in f with at least two
literals. Thus we can write c as [l1, l2]@x0 for some literals l1, l2 and clause x0.
Let Δ denote the formula resulting by removing all occurences of c from f. Let
f1 denote the formula [l1]@Δ and let f2 denote the formula [l2, x0]@Δ. It is easy
to see that the measures of both f1 and f2 are smaller than the measure of f.
By the inductive hypothesis, we therefore have several cases to consider.
– f1 is satisﬁable. Then there is a valuation v setting f1 to true. Thus v must
set [l1] and Δ to true, so it also sets [l1, l2]@x0 and Δ to true, which implies
that the value of f under v is true, so f is satisﬁable.
– f2 is satisﬁable. Reasoning in the same way, we can derive satisﬁability of f.
– There are resolution trees r1, r2 refuting f1 and f2, respectively. Let rp denote
percolate(r2)([l2]@x0)(l1). Therefore, rp results from r2 by appending l1 to
all leaves labelled by [l2]@x0 and percolating it up. Since r2 is a refutation
tree, this means that the clause at the root of rp is either the empty clause
or the clause [l1]. In the former case, by Lemma percolateCorrect, it is easy
to see that rp refutes f. In the latter, we have two subcases to consider:
• [l1] is not among the premises of r1. In this case, the premises of r1 are
a subset of Δ, so also a subset of f, so r1 already refutes f.
• [l1] is among the premises of r1. Let rg denote graft(r1)(rp). Therefore,
rg results by replacing every leaf in r1 labelled with [l1] by rp. Then rg
refutes f. To show this, we need to show that:
∗rg corresponds to f. This means that the premises of rg are a subset
of the clauses of f. But note that the premises of r1 are a subset of
Δ ∪[l1]. By grafting rp onto r1, the leaves labelled by [l1] disappear
replaced by rp. As the premises of rp are a subset of Δ ∪[l1, l2]@x0,
the premises of rg are a subset of Δ ∪[l1, l2]@x0 and thus also a
subset of f.
∗The root of rg is labelled by the empty clause. This follows trivially
by r1 refuting f1 and the deﬁnition of the grafting function.
∗The tree rg is a correct resolution tree. This follows easily by Lemmas
graftCorrect and percolateCorrect.
Let us see how the proof works for the formula f ≡(P ∨Q) ∧(¬P) ∧(¬Q).
Obviously, φ is not one-literal. We take c = P ∨Q. Then l1 = P, l2 = Q, x0 = [],
Δ = (¬P) ∧(¬Q), f1 = P ∧¬P ∧¬Q, f2 = Q ∧¬P ∧¬Q. The application of
the inductive hypothesis to f2 and f1 results in two refutation tree r2 and r1:
r2
r1
(Q, [])


(P, [])


[Q]
[¬Q]
[P]
[¬P]

Extracting the Resolution Algorithm from a Completeness Proof
159
Then the tree rp is:
(Q, [P])





P ∨Q
[¬Q]
Since the clause [P] is obviously not empty, we need to perform the graft oper-
ation which results in a tree g, which can be easily seen to refute f.
(P, [])


(Q, [P])





[¬P]
P ∨Q
[¬Q]
3
Extraction
Now we can reap the beneﬁts of the constructive proof and formalization in a
theorem prover as Underwood did for the tableaux method [9]. Coq provides
a program extraction capability, which makes it possible to extract a program
from our proof. The program, given a representation of a formula f in a CNF
form, returns either a valuation satisfying f or a resolution tree refuting f. The
extracted program is correct by construction — there is no need for testing for
eventual bugs, as the program is guaranteed to compute the refuting resolution
or the satisfying valuation.
We have chosen to extract a program in a functional programming language
Haskell. Coq also oﬀers choices of other programming languages (Scheme, ML).
We now show examples of interaction with our program loaded in a Haskell inter-
preter. The examples correspond to the lemmas and theorems we have proven.
We can check directly the truth of several lemmas in the interpreter. To make
the output more readable, we have added a function which renders lists in the
style used in this paper. We use standard notation for natural numbers, rendering
S(S(0)) as simply 2. The Main> string in the examples is the standard prompt
of the Haskell interpreter.

160
R. Constable and W. Moczydlowski
Finally, let us see the application of the completeness theorem:
To give the reader a glimpse of the actual Haskell code, we show the Haskell
deﬁnition of the function t corresponding to Theorem 2.

Extracting the Resolution Algorithm from a Completeness Proof
161
4
Conclusion
While proofreading this paper, we have discovered several times mistakes in our
informal presentation thanks to the included Coq and Haskell code. This is an
example of successful paper veriﬁcation using a proof assistant.
Richard Eaton and the second author have also done this proof in Nuprl
[6] and are writing a comparison of the systems in their ability to support read-
able formalized mathematics. This forthcoming article will discuss several subtle
points about extraction and how to guide it to produce code as eﬃcient as what
can be written directly. At this point, we only mention that one of the most im-
portant diﬀerences between Coq and Nuprl, namely the treatment of equality,
played no role in our developments. As the proofs use only very basic proper-
ties of equality, the extensionality of Nuprl and intensionality of Coq did not
inﬂuence our development.
References
1. Gallier, J.H.: The completeness of propositional resolution: A simple and construc-
tive proof. Logical Methods in Computer Science 2(5) (2006) 1–7
2. Chang, C.C., Keisler, H.J.: Model Theory. Volume 73 of Studies in Logic and the
Foundations of Mathematics. North-Holland, Netherlands (1973)
3. Robinson, J.: A machine oriented logic based on the resolution principle. Journal
of the Association of Computing Machinery 12 (1965) 23–41
4. Lewis, H.R., Papadimitriou, C.H.:
Elements of the Theory of Computation.
Prentice-Hall, Englewood Cliﬀs, New Jersey (1994)
5. Gallier, J.H.:
Logic for Computer Science, Foundations of Automatic Theorem
Proving. Harper and Row, NY (1986)
6. Constable, R.L., Allen, S.F., Bromley, H.M., Cleaveland, W.R., Cremer, J.F.,
Harper, R.W., Howe, D.J., Knoblock, T.B., Mendler, N.P., Panangaden, P., Sasaki,
J.T., Smith, S.F.: Implementing Mathematics with the Nuprl Proof Development
System. Prentice-Hall, NJ (1986)
7. Constable, R.L., Howe, D.J.: Implementing metamathematics as an approach to
automatic theorem proving. In Banerji, R.B., ed.: Formal Techniques in Artiﬁcial
Intelligence: A Source Book. Elsevier Science Publishers (North-Holland) (1990)
45–76
8. Constable, R., Moczydlowski, W.: Extracting Programs from Constructive HOL
Proofs via IZF Set-Theoretic Semantics. In: Proceedings of 3rd International Joint
Conference on Automated Reasoning (IJCAR 2006). Volume 4130 of Lecture Notes
in Computer Science., Springer (2006) 162–176
9. Underwood, J.L.: The tableau algorithm for intuitionistic propositional calculus as
a constructive completeness proof. In: Proceedings of the Workshop on Theorem
Proving with Analytic Tableaux, Marseille, France. (1993) 245–248 Available as
Technical Report MPI-I-93-213 Max-Planck-Institut f¨ur Informatik, Saarbr¨ucken,
Germany.

Topological Semantics and Bisimulations
for Intuitionistic Modal Logics
and Their Classical Companion Logics⋆
J.M. Davoren
Department of Electrical & Electronic Engineering,
The University of Melbourne, VIC 3010 Australia
davoren@unimelb.edu.au
Abstract. We take the well-known intuitionistic modal logic of Fischer
Servi with semantics in bi-relational Kripke frames, and give the natural
extension to topological Kripke frames. Fischer Servi’s two interaction
conditions relating the intuitionistic pre-order (or partial-order) with the
modal accessibility relation generalise to the requirement that the rela-
tion and its inverse be lower semi-continuous with respect to the topol-
ogy. We then investigate the notion of topological bisimulation relations
between topological Kripke frames, as introduced by Aiello and van Ben-
them, and show that their topology-preserving conditions are equivalent
to the properties that the inverse-relation and the relation are lower semi-
continuous with respect to the topologies on the two models. Our ﬁrst
main result is that this notion of topological bisimulation yields semantic
preservation w.r.t. topological Kripke models for both intuitionistic tense
logics, and for their classical companion multi-modal logics in the setting
of the G¨odel translation. After giving canonical topological Kripke mod-
els for the Hilbert-style axiomatizations of the Fischer Servi logic and
its classical multi-modal companion logic, we show that the syntactic
G¨odel translation induces a natural semantic map from the intuitionis-
tic canonical model into the canonical model of the classical companion
logic, and this map is itself a topological bisimulation.
1
Introduction
Topological semantics for intuitionistic logic and for the classical modal logic
S4 have a long history going back to Tarski and co-workers in the 1930s and
40s, predating the relational Kripke semantics for both [25,31]. A little earlier
again is the 1933 G¨odel translation GT [21] of intuitionistic logic into classical
S4. The translation makes perfect sense within the topological semantics: where
□is interpreted by topological interior, the translation GT(¬ϕ) = □¬ GT(ϕ)
⋆Partially
supported by Australian
Research Council
grants DP0208553
and
LX0242359. The author acknowledges valuable discussions with R.P. Gor´e, B.D.
Humberstone, S. Demri, J. Goubault-Larrecq, A. Nerode, T. Moor and V. Coulthard.
The workshop paper [12] (available only in a tech report) is a precursor to this paper.
S. Artemov and A. Nerode (Eds.): LFCS 2007, LNCS 4514, pp. 162–179, 2007.
c
⃝Springer-Verlag Berlin Heidelberg 2007

Topological Semantics and Bisimulations for Intuitionistic Modal Logics
163
says that intuitionistic negation calls for the interior of the complement, and not
just the complement. In the topological semantics, a basic semantic object is the
denotation set  ϕ M of a formula ϕ, consisting of the set of all states/worlds of
the model M at which the formula is true, and the semantic clauses of the logic
are given in terms of operations on sets of states. The intuitionistic requirement
on the semantics is that all formulas must denote open sets: that is, sets that
are equal to their own interior. Any formula ϕ partitions the state space X into
three disjoint sets: the two open sets  ϕ M and  ¬ ϕ M, and the closed set
bd( ϕ M), with the points in the topological boundary set bd( ϕ M) falsifying
the law of excluded middle, since they neither satisfy nor falsify ϕ.
For the extension from intuitionistic propositional logics to intuitionistic
modal logics, Fischer Servi in the 1970s [16,17,18] developed semantics over
bi-relational Kripke frames, and this work has generated a good deal of research
[15,20,22,29,32,36,37]. In bi-relational frames (X, ≼, R) where ≼is a pre-order
(quasi-order) for the intuitionistic semantics, and R is a binary accessibility
relation on X for the modal operators, the two Fischer Servi conditions are
equivalent to the following relation inclusions [18,29,32]:
(R−1◦≼) ⊆(≼◦R−1)
and
(R ◦≼) ⊆(≼◦R)
(1)
where ◦is relational/sequential composition, and (·)−1 is relational inverse. Ax-
iomatically, the base Fischer Servi modal logic IK has normality axioms for
both the modal box □· and the diamond
 · , as well as the additional two axiom
schemes:
FS1 :
 · (ϕ →ψ) →(□·ϕ →
 · ψ) and FS2 : (
 · ϕ →□·ψ) →□·(ϕ →ψ) (2)
A study of various normal extensions of IK is given in [32]. Earlier, starting from
the 1950s, the intuitionistic S5 logic MIPC [30,8] was given algebraic semantics
in the form of monadic Heyting algebras [4,27,28,34,35]1 and later as bi-relational
frames with an equivalence relation for the S5 modality [5,14,28,34]. This line of
work has focused on MIPC = IK ⊕T□·
 · ⊕5□·
 · and its normal extensions2,
and translations into intuitionistic and intermediate predicate logics. Within
algebraic semantics, topological spaces arise in the context of Stone duality, and
in [4,5,14], the focus restricts to Stone spaces (compact, Hausdorﬀand having
as a basis the Boolean algebra of closed-and-open sets).
In this paper, following [12], we give semantics for intuitionistic modal logic
over topological Kripke frames F = (X, T , R), where (X, T ) is a topological
space and R ⊆X × X is an accesibility relation for the modalities; the Fisher
Servi bi-relational semantics are straight-forwardly extended from pre-orders ≼
on X and their associated Alexandrov topology T≼, to arbitrary topological spaces
1 The additional monadic operators are ∀and ∃unary operators behaving as S5 box
and diamond modalities, and come from Halmos’ work on monadic Boolean algebras.
2 Here, T□·
 · is the conjunction of the separate □· and
 · characteristic schemes
for reﬂexivity, and likewise 5□·
 · for Euclideanness, so together they characterize
equivalence relations.

164
J.M. Davoren
(X, T )3. Over topological Kripke frames, the two Fischer Servi bi-relational con-
ditions on the interaction between modal and intuitionistic semantics ((1) above)
generalize to semi-continuity properties of the relation R, and of its inverse R−1,
with respect to the topology. As for the base logic, Fischer Servi’s extension of
the G¨odel translation reads as a direct transcription of the topological semantics.
The translation GT( □·ϕ ) = □□· GT(ϕ) says that the intuitionistic box requires
the interior of the classical box operator, since the latter is deﬁned by an inter-
section and may fail to preserve open sets. In contrast, the translation clause
GT(
 · ϕ ) =
 · GT(ϕ) says that, semantically, the operator
 · preserves open
sets. This condition is exactly the lower semi-continuity (l.s.c.) condition on the
accessibility relation, and corresponds to the ﬁrst Fischer Servi bi-relational in-
clusion R−1◦≼⊆≼◦R−1 in (1), and it is this condition that is required to verify
topological soundness of the axiom scheme FS1 in (2)4. Similarly, Fischer Servi’s
second bi-relational inclusion R ◦≼⊆≼◦R generalizes to the l.s.c. property of
the R−1 relation, where the latter is required to verify topological soundness of
the axiom scheme FS2 in (2).
The symmetry of the interaction conditions on the modal relation R and
its inverse R−1 means that we can – with no additional semantic assumptions
– lift the topological semantics to intuitionistic tense logics extending Fischer
Servi’s modal logic (introduced by Ewald in [15]), with modalities in pairs
 · ,
□·, and
· , ■·, for future and past along the accessibility relation. It soon becomes
clear that the resulting semantics and metatheoretic results such as completeness
come out cleaner and simpler for the tense logic than they do for the modal
logic. We can often streamline arguments involving the box modality □· by using
its adjoint diamond
· , which like
 · , preserves open sets. Furthermore, with
regard to applications of interest, the ﬂexibility of having both forwards and
backwards modalities is advantageous. For example, if X ⊆Rn is equipped
with the Euclidean topology, and R ⊆X × X is the reachability relation of a
continuous or hybrid dynamical system [2,3,11], then the formula
· p denotes
the set of states reachable from the p states, with p considered as a source or
initial state set, while the forward modal diamond formula
 · p denotes the set of
states from which p states can be reached, here p denoting a target or goal state
set. Under some standard regularity assumptions on the diﬀerential inclusions
or equations, [2,3], the reachability relation R and its inverse will be l.s.c. (as
3 Other work giving topological semantics for intuitionistic modal logics is [36], further
investigated in [23]. This logic is properly weaker than Fischer Servi’s as its intuition-
istic diamond is not required to distribute over disjunction (hence is sub-normal).
Both the bi-relational and topological semantics in [36] and the relational spaces in
[23] have no conditions on the interaction of the intuitionistic and modal semantic
structures, and the semantic clauses for both box and diamond require application
of the interior operator to guarantee open sets.
4 In the algebraic setting of Monteiro and Varsavsky’s work [27] w.r.t. the logic MIPC,
a special case of the l.s.c. property is anticipated: the lattice of open sets of a topolog-
ical space is a complete Heyting algebra, and the structure yields a monadic Heyting
algebra when the space is further equipped with an equivalence relation R with the
property that the “R-saturation” or R-expansion of an open set is open.

Topological Semantics and Bisimulations for Intuitionistic Modal Logics
165
well as reﬂexive and transitive), while further assumptions are required for the
u.s.c. property (e.g. R is a closed set in the product topology on X × X).
We continue on the theme of semi-continuity properties of relations in our
second topic of investigation, namely that of topological bisimulations between
topological Kripke models. A bisimulation notion for topological spaces (X, T )
has recently been developed by Aiello and van Benthem (e.g. [1], Def. 2.1).
We show below that their forth and back topology-preserving conditions are
equivalent to the lower semi-continuity of the inverse relation and of the relation,
respectively. The ﬁrst main result of the paper is that this notion of topological
bisimulation yields the semantic preservation property w.r.t. topological Kripke
models for both intuitionistic tense logics, and for their classical companion
multi-modal logics in the setting of the G¨odel translation.
In the last part of the paper, we give canonical topological Kripke models for
the Hilbert-style axiomatizations of the Fischer Servi logics and their classical
companions logics – over the set of prime theories of the intuitionistic logic
and the set of ultraﬁlters of the companion classical logic, respectively, with
topologies on the spaces that are neither Alexandrov nor Stone. We conclude
the paper with the second main result: the syntactic G¨odel translation induces
a natural semantic map from the intuitionistic canonical model to a sub-model
of the canonical model of the classical companion logic, and this map is itself a
topological bisimulation.
2
Preliminaries from General Topology
We adopt the notation from set-valued analysis [2] in writing r : X ; Y to
mean both that r : X →2Y is a set-valued map, with (possibly empty) set-values
r(x) ⊆Y for each x ∈X, and equivalently, that r ⊆X × Y is a relation. The
expressions y ∈r(x), (x, y) ∈r and x r y are synonymous. For a map r : X ; Y ,
the inverse r−1 : Y ; X given by: x ∈r−1(y) iﬀy ∈r(x); the domain is
dom(r) := {x ∈X | r(x) ̸= ∅}, and the range is ran(r) := dom(r−1) ⊆Y . A
map r : X ; Y is total on X if dom(r) = X, and surjective on Y if ran(r) = Y .
We write (as usual) r : X →Y to mean r is a function, i.e. a single-valued map
total on X with values written r(x) = y (rather than r(x) = {y}). For r1 : X ;
Y and r2 : Y ; Z, we write their relational composition as r1 ◦r2 : X ; Z
given by (r1 ◦r2)(x) := {z ∈Z | (∃y ∈Y ) [(x, y) ∈r1 ∧(y, z) ∈r2]}. Recall that
(r1 ◦r2)−1 = r−1
2
◦r−1
1 . A pre-order (quasi-order) is a reﬂexive and transitive
binary relation, and a partial-order is a pre-order that is also anti-symmetric.
A relation r : X ; Y determines two pre-image operators (predicate trans-
formers). The existential (or lower) pre-image is of type r−∃: 2Y →2X and the
universal (or upper) pre-image r−∀: 2Y →2X is its dual w.r.t. set-complement:
r−∃(W) := {x ∈X | (∃y ∈Y )[ (x, y) ∈r
∧y ∈W]}
= {x ∈X | W ∩r(x) ̸= ∅}
r−∀(W) := X −r−∃(Y −W) = {x ∈X | r(x) ⊆W}

166
J.M. Davoren
for all W ⊆Y . The operator r−∃distributes over arbitrary unions, while r−∀dis-
tributes over arbitrary intersections: r−∃(∅) = ∅, r−∃(Y ) = dom(r), r−∀(∅) =
X −dom(r), and r−∀(Y ) = X. Note that when r : X →Y is a function,
the pre-image operators reduce to the standard inverse-image operator; i.e.
r−∃(W) = r−∀(W) = r−1(W). The pre-image operators respect relational in-
clusions: if r1 ⊆r2 ⊆X × Y , then for all W ⊆Y , we have r−∃
1 (W) ⊆r−∃
2 (W),
but reversing to r−∀
2 (W) ⊆r−∀
1 (W). For the case of binary relations r: X ; X
on a space X, the pre-images express in operator form the standard relational
Kripke semantics for the (future) diamond and box modal operators determined
by r. The operators on sets derived from the inverse relation r−1 are usually
called the post-image operators r∃, r∀: 2X →2Y deﬁned by r∃:= (r−1)−∃
and r∀:= (r−1)−∀; these arise in the relational Kripke semantics for the past
diamond and box operators in tense and temporal logics. The fundamental re-
lationship between pre- and post-images is the adjoint property:
∀W1 ⊆X, ∀W2 ⊆Y,
W1 ⊆r−∀(W2)
iﬀ
r∃(W1) ⊆W2 .
(3)
A topology T ⊆2X on a set X is a family of subsets of X closed under arbitrary
unions and ﬁnite intersections. The extreme cases are the discrete topology TD =
2X, and the trivial (or indiscrete) topology T∅= {∅, X}. The interior operator
intT : 2X →2X determined by T is given by int T (W) :=  {U ∈T | U ⊆W}.
Sets W ∈T are called open w.r.t. T , and this is so iﬀW = int T (W). Let
−T := {W ⊆X | (X −W) ∈T } denote the dual lattice under set-complement.
Sets W ∈−T are called closed w.r.t. T , and this is so iﬀW = cl T (W), where the
dual closure operator cl T : 2X →2X is given by clT (W) := X −cl T (X −W),
and the topological boundary is bd T (W) := cl T (W) −int T (W). A family of
open sets B ⊆T constitutes a basis for a topology T on X if every open set
W ∈T is a union of basic opens in B, and for every x ∈X and every pair of
basic opens U1, U2 ∈B such that x ∈U1 ∩U2, there exists U3 ∈B such that
x ∈U3 ⊆(U1 ∩U2).
The purely topological notion of continuity for a function f : X →Y is that
the inverse image f −1(U) is open whenever U is open. Analogous notions for
relations/set-valued maps were introduced by Kuratowski and Bouligand in the
1920s. Given two topological spaces (X, T ) and (Y, S), a map R : X ; Y is
called: lower semi-continuous (l.s.c.) if for every S-open set U in Y , R−∃(U)
is T -open in X; upper semi-continuous (u.s.c.) if for every S-open set U in
Y , R−∀(U) is T -open in X; and (Vietoris) continuous if it is both l.s.c. and
u.s.c. [2,7,24,33]. The u.s.c. condition is equivalent to R−∃(V ) is T -closed in
X whenever V is S-closed in Y . Moreover, we have:
R : X ; Y is l.s.c. iﬀ
R−∃(int S(W)) ⊆int T (R−∃(W)) for all W ⊆Y ; and R : X ; Y is u.s.c.
iﬀR−∀(int S(W)) ⊆int T (R−∀(W)) for all W ⊆Y ([24], Vol. I, §18.I, p.173).
The two semi-continuity properties reduce to the standard notion of continuity
for functions R : X →Y . Both semi-continuity properties are preserved under
relational composition, and also under ﬁnite unions of relations.
We note the subclass of Alexandrov topologies because of their correspon-
dence with Kripke relational semantics for classical S4 and intuitionistic logics.
e.g. [1,26]. A topological space (X, T ) is called Alexandrov if for every x ∈X,

Topological Semantics and Bisimulations for Intuitionistic Modal Logics
167
there is a smallest open set U ∈T such that x ∈U. In particular, every
ﬁnite topology (i.e. only ﬁnitely many open sets) is Alexandrov. There is a
one-to-one correspondence between pre-orders on X and Alexandrov topologies
on X. Any pre-order ≼on X induces an Alexandrov topology T≼by taking
intT≼(W) := (≼)−∀(W), which means U ∈T≼iﬀU is upwards-≼-closed. In
particular, T≼is closed under arbitrary intersections as well as arbitrary unions,
and −T≼= T≽. Conversely, for any topology, deﬁne a pre-order ≼T
on X,
known as the specialisation pre-order:
x ≼T y iﬀ(∀U ∈T ) [x ∈U ⇒y ∈U].
For any pre-order, ≼T≼= ≼, and for any topology, T≼T = T iﬀT is Alexandrov
(e.g. see [1], pp. 893-894). For further concepts in topology, see, e.g. [33].
3
Intuitionistic Modal and Tense Logics, and Their
Classical Companion Logics: Syntax and Topological
Semantics
Fix a countably inﬁnite set AP of atomic propositions. The propositional lan-
guage L0 is generated from p ∈AP using the connectives ∨, ∧, →and the
constant ⊥. As usual, deﬁne further connectives: ¬ ϕ := ϕ →⊥and ϕ1 ↔ϕ2 :=
(ϕ1 →ϕ2)∧(ϕ2 →ϕ1), and ⊤:= ⊥→⊥. Let L0,□be the mono-modal language
extending L0 with the addition of the unary modal operator □. A further modal
operator 3 can be deﬁned as the classical dual: 3ϕ := ¬□¬ϕ.
For the intuitionistic modal and tense languages, let Lm (Lt) be the modal
(tense) language extending L0 with the addition of two (four) modal operators
 · and □· (and
· and ■·) , generated by the grammar:
ϕ ::= p | ⊥| ϕ1 ∨ϕ2 | ϕ1 ∧ϕ2 | ϕ1 →ϕ2 |
 · ϕ | □·ϕ ( |
· ϕ | ■·ϕ )
for p ∈AP. Likewise, for the classical topological modal and tense logics, let Lm
□
(Lt
□) be the modal (tense) language extending L0,□with the addition of
 · and
□· (and
· and ■·).
The original G¨odel translation [21], as a function GT : L0 →L0,□, simply
preﬁxes □to every subformula of a propositional formula. Reading the S4 □as
topological interior, this means we force every propositional formula to intuition-
istically denote an open set. In Fischer Servi’s extension of the G¨odel translation
[18,16], the clauses for the propositional fragment are from a variant translation
used by Fitting [19], who shows it to be equivalent to G¨odel’s original ([19], Ch.
9, # 20). Deﬁne the function GT : Lt →Lt
□by induction on formulas as follows:
GT(p) := □p for p ∈AP
GT(ϕ1 →ϕ2) := □(GT(ϕ1) →GT(ϕ2))
GT(⊥) := ⊥
GT(ϕ1 ∨ϕ2) := GT(ϕ1) ∨GT(ϕ2)
GT(ϕ1 ∧ϕ2) := GT(ϕ1) ∧GT(ϕ2)
GT(
 · ϕ ) :=
 · GT(ϕ)
GT(
· ϕ ) :=
· GT(ϕ)
GT( □·ϕ ) := □□· GT(ϕ)
GT( ■·ϕ ) := □■· GT(ϕ)
In topological terms, the only clauses in the translation where it is essential
to have an explicit □to guarantee openness of denotation sets are for atomic

168
J.M. Davoren
propositions, for implication →, and for the box modalties □· and ■·. There is no
such need in the clauses for ∨and ∧because ﬁnite unions and ﬁnite intersections
of open sets are open. For the diamond modalties, the semi-continuity conditions
that R and its inverse R−1 are both l.s.c. ensure that the semantic operators
R−∃and R∃interpretting
 · and
· must preserve open sets. We now explain
this generalization, which was ﬁrst presented in [12].
The bi-relational semantics of Fischer Servi [16,17], and Plotkin and Stirling
[29,32] are over Kripke frames F = (X, ≼, R), where ≼is a pre-order on X and
R : X ; X is the modal accessibility relation. Using the induced Alexandrov
topology T≼, a bi-relational Kripke frame F is equivalent to the topological
frame (X, T≼, R). A set is open in T≼exactly when it is ≼-persistent or upward-
≼-closed. The four bi-relational conditions identiﬁed in [29], and also familiar
as the forth (“Zig”) and back (“Zag”) conditions for bisimulations (e.g. [6], Ch.
2), can be cleanly transcribed as semi-continuity conditions on the relations
R : X ; X and R−1 : X ; X with respect to the topology T≼.
Deﬁnition 1. Let F = (X, ≼, R) be a bi-relational frame. Four conditions ex-
pressing interaction between ≼and R are identiﬁed as follows:
Zig(≼, R) :
if
x ≼y and x R x′ then (∃y′ ∈X)

y R y′ and
x′ ≼y′ 
Zag(≼, R) :
if
x ≼y and y R y′ then (∃x′ ∈X)

x R x′ and
x′ ≼y′ 
Zig(≼, R−1) : if
x ≼y and
x′R x then (∃y′ ∈X)

y′ R y and
x′ ≼y′ 
Zag(≼, R−1) : if
x ≼y and y′ R y then (∃x′ ∈X)

x′R x
and
x′ ≼y′ 
y
x′
R
x
R
y′
y
x′
R
x
R
y′
y
x′
R
x
R
y′
y
x′
R
x
R
y′
Zig(≼, R)
Zag(≼, R)
Zig(≼, R−1)
Zag(≼, R−1)
From earlier work [9], we know these bi-relational conditions correspond to semi-
continuity properties of R with respect to the Alexandrov topology T≼.
Proposition 1. ([9])
Let F = (X, ≼, R) be a bi-relational frame, with T≼it
induced topology. The conditions in each row below are equivalent.
1. Zig(≼, R)
(R−1◦≼) ⊆(≼◦R−1)
R is l.s.c. in T≼
2. Zag(≼, R)
(≼◦R) ⊆(R ◦≼)
R is u.s.c. in T≼
3. Zig(≼, R−1)
(R ◦≼) ⊆(≼◦R)
R−1 is l.s.c. in T≼
4. Zag(≼, R−1)
(≼◦R−1) ⊆(R−1◦≼)
R−1 is u.s.c. in T≼
The Fischer Servi interaction conditions between the intuitionistic and modal
relations, introduced in [17] and used in [15,18,22,29,32], are the ﬁrst and third
bi-relational conditions Zig(≼, R) and Zig(≼, R−1). In Kripke frames meeting
these conditions, one can give semantic clauses for the diamond and box that are

Topological Semantics and Bisimulations for Intuitionistic Modal Logics
169
natural under the intuitionistic reading of the restricted ∃and ∀quantiﬁcation
with respect to R-successors. More precisely, the resulting logic is faithfully em-
bedded into intuitionistic ﬁrst-order logic by the standard modal to ﬁrst-order
translation, and a natural extension of the G¨odel translation faithfully embeds
it into the classical bi-modal logic combining S4□with K or extensions.
Since the Fischer Servi interaction conditions for the forward or future modal
operators
 · and □· for R require the same l.s.c. property of both R and R−1,
this means that, at no extra cost in semantic assumptions, we can add on the
backward or past modal operators
· and ■· for R−1, and obtain the desired
interaction condition for R−1 for free.
Deﬁnition 2. A topological frame is a structure F = (X, T , R) where (X, T ) is
a topological space and R : X ; X is a binary relation. F is an l.s.c. topological
frame if both R and R−1 are l.s.c. in T . A model over F is a structure M =
(F, v) where v : AP ; X is an atomic valuation relation. A model M is an
open model if for each p ∈AP, the denotation set v(p) is open in T . For open
models M over l.s.c. frames F, the intuitionistic denotation map ·M
I
: Lt ; X
(or ·M
I
: Lm ; X) is deﬁned by:
pM
I
:= v(p)
for p ∈AP
⊥M
I
:= ∅
ϕ1 →ϕ2M
I
:= int T ((X −ϕ1M
I ) ∪ϕ2M
I )
ϕ1 ∨ϕ2M
I
:= ϕ1M
I
∪ϕ2M
I
ϕ1 ∧ϕ2M
I
:= ϕ1M
I
∩ϕ2M
I

 · ϕM
I
:= R−∃(ϕM
I )
 □·ϕM
I
:= intT

R−∀(ϕM
I )


· ϕM
I
:= R∃(ϕM
I )
 ■·ϕM
I
:= intT

R∀(ϕM
I )

A formula ϕ ∈Lt (or ϕ ∈Lm ) is int-modal-top valid in an open model M,
written M ⊩ϕ , if ϕM
I
= X, and is int-modal-top valid in an l.s.c. frame F =
(X, T , R), written F ⊩ϕ , if M ⊩ϕ for all open models M over F. Formula
ϕ is satisﬁable in M if ϕM
I
̸= ∅, and ϕ is falsiﬁable in M if ϕM
I
̸= X. Let
IKtT ( IKmT ) be the set of all ϕ ∈Lt ( ϕ ∈Lm ) such that F ⊩ϕ in every
l.s.c. topological frame F.
The property that every denotation set  ϕ M
I
is open in T follows immediately
from the openness condition on v(p), the l.s.c. properties of R−∃and R∃, and
the extra interior operation in the semantics for →, □· and ■·.
Deﬁnition 3. For the tense (modal) language Lt
□( and Lm
□), we deﬁne the
classical denotation map ·M : Lt
□; X ( ·M : Lm
□; X ) with respect to ar-
bitrary topological models M = (X, T , R, v), where v : AP ; X is unrestricted.
The map ·M is deﬁned the same way as ·M
I
for atomic p ∈AP, ⊥, ∨, ∧,
 ·
and
· , but diﬀers on the following clauses:
ϕ1 →ϕ2M := (X −ϕ1M) ∪ϕ2M
 □ϕ M := intT ( ϕ M)
 □·ϕM := R−∀(ϕM)
 ■·ϕM := R∀(ϕM)
A formula ϕ ∈Lt
□(or ϕ ∈Lm
□) is modal-top valid in M, written M |= ϕ, if
ϕM = X, and is modal-top valid in a topological frame F = (X, T , R), written

170
J.M. Davoren
F |= ϕ, if M |= ϕ for all models M over F. Let KtT (KmT) be the set of all
ϕ ∈Lt
□(ϕ ∈Lm
□) such that F |= ϕ for every topological frame F. Let KtLSC
(KmLSC) be the set of all ϕ ∈Lt
□(ϕ ∈Lm
□) such that F |= ϕ in every l.s.c.
topological frame F.
For Fischer Servi’s extension of G¨odel’s translation, Deﬁnitions 2 and 3 imply
that for any model M = (F, v) over an l.s.c. topological frame F, if M′ = (F, v′)
is the variant open model with v′(p) := int T (v(p)), then ∀ϕ ∈Lt:
ϕ
M′
I
=  GT(ϕ) 
M =  □GT(ϕ) 
M.
(4)
Consequently, we have semantic faithfulness, as well as the openness property:
for all ϕ ∈Lt, the formula GT(ϕ) ↔□GT(ϕ) is in KtLSC.
Proposition 2. [Extended G¨odel translation: semantic faithfulness]
For all ϕ ∈Lt,
ϕ ∈IKtT iﬀGT(ϕ) ∈KtLSC.
The semi-continuity conditions can be cleanly characterized in the companion
classical multi-modal logics, as given in [13].
Proposition 3. [[13] Modal characterization of semi-continuity conditions]
Let F = (X, T , R) be a topological frame and let p ∈AP. In the following table,
the conditions listed across each row are equivalent.
(1.) R is l.s.c. in T
F |=
 · □p →□
 · p F ⊨
 · □p ↔□
 · □p
(2.) R is u.s.c. in T
F |= □·□p →□□·p
(3.) R−1 is l.s.c. in T F |= □□·p →□·□p F ⊨
· □p ↔□
· □p
(4.) R−1 is u.s.c. in T F |= □
 · p →
 · □p
4
Topological Bisimulations
Aiello and van Benthem’s notions of topological simulation and bisimulation
between classical S4 topological models are as follows.
Deﬁnition 4. [[1], Deﬁnition 2.1] Let (X1, T1) and (X2, T2) be two topological
spaces, let v1 : AP ; X1 and v2 : AP ; X2 be valuations of atomic propositions,
and let M1 = (X1, T1, v1) and M2 = (X2, T2, v2) be topological models.
A relation B : X1 ; X2 is a topo-bisimulation between M1 and M2 if
(i.a) ∀x ∈X1, ∀y ∈X2, ∀p ∈AP, if x B y and x ∈v1(p) then y ∈v2(p) ;
(i.b) ∀x ∈X1, ∀y ∈X2, ∀p ∈AP, if x B y and y ∈v2(p) then x ∈v1(p) ;
(ii.a) ∀x ∈X1, ∀y ∈X2, ∀U ∈T1, if x B y and x ∈U
then ∃V ∈T2 with y ∈V and ∀y′ ∈V, ∃x′ ∈U such that x′ B y′ ;
(ii.b) ∀x ∈X1, ∀y ∈X2, ∀V ∈T2, if x B y and y ∈V
then ∃U ∈T1 with x ∈U and ∀x′ ∈U, ∃y′ ∈V such that x′ B y′ .
If only conditions (i.a) and (ii.a) hold of a relation B : X1 ; X2, then B is
called a topo-simulation of M1 by M2.

Topological Semantics and Bisimulations for Intuitionistic Modal Logics
171
Proposition 4. Given a map B : X1 ; X2 between (X1, T1) and (X2, T2),
(1.) B satisﬁes condition (ii.a) of Deﬁnition 4
iﬀ
B−1 is l.s.c.;
(2.) B satisﬁes condition (ii.b) of Deﬁnition 4
iﬀ
B is l.s.c..
Proof. By rewriting in terms of the pre- and post-image set operators, it is easy
to show that conditions (ii.a) and (ii.b) are equivalent to the following:
(ii.a♯)
∀U ∈T1,
B∃(U) ⊆int T2

B∃(U)

(ii.b♯)
∀V ∈T2, B−∃(V ) ⊆int T1

B−∃(V )

Clearly, (ii.a♯) says that B∃(U) is open in X2 whenever U open in X1, while
(ii.b♯) says that B−∃(V ) is open in X1 whenever V open in X2.
⊣
For the appropriate notion of topological bisimulation between topological
Kripke models for the intuitionistic and classical companion modal and tense
logics under study here, we need to put together the topology-preserving con-
ditions (ii.a) and (ii.b) above with the standard clauses for preservation of the
modal/tense semantic structure.
Deﬁnition 5. Let M1 = (X1, T1, R1, v1) and M2 = (X2, T2, R2, v2) be two
topological models. A map B : X1 ; X2 will be called a tense topo-bisimulation
between M1 and M2 if for all atomic p ∈AP:
(i.a)
B∃(v1(p)) ⊆v2(p)
(i.b)
B−∃(v2(p)) ⊆v1(p)
(ii.a)
B−1 : X2 ; X1 is l.s.c.
(ii.b)
B : X1 ; X2 is l.s.c.
(iii.a) (B−1 ◦R1) ⊆(R2 ◦B−1)
(iii.b) (B ◦R2) ⊆(R1 ◦B)
(iv.a) (B−1 ◦R−1
1 ) ⊆(R−1
2
◦B−1)
(iv.b) (B ◦R−1
2 ) ⊆(R−1
1
◦B)
If only conditions (i.a), (ii.a) and (iii.a) hold of the map B : X1 ; X2, then B
is called a modal topo-simulation of M1 by M2; if all but conditions (iv.a) and
(iv.b) hold, then B is a modal topo-bisimulation between M1 and M2.
Combining all the conditions (iii) and (iv), one obtains two equalities:
(R1 ◦B) = (B ◦R2) and (R2 ◦B−1) = (B−1 ◦R1). The set-operator form of the
semantic preservation conditions are:
B∃( ϕ 
M1
I
) ⊆ ϕ 
M2
I
and
B−∃( ϕ 
M2
I
) ⊆ ϕ 
M1
I
(5)
and likewise for classical denotation maps  ϕ Mi. We will also use the dual
versions under the adjoint equivalence (3). These are:
 ϕ 
M1
I
⊆B−∀( ϕ 
M2
I
)
and
 ϕ 
M2
I
⊆B∀( ϕ 
M1
I
)
(6)
and likewise for  ϕ Mi. Note also that B−1 : X2 ; X1 being l.s.c. has a further
equivalent characterization: int T1(B−∀(W)) ⊆B−∀(int T2(W)), for all W ⊆X2;
this is a generalization of the characterization for binary relations on a single
space X that is formalized in Proposition 3, Row (3.).
What we discover is that exactly the same notion of a bisimulation between
models yields the same semantic preservation property for both the intuitionistic
and the classical semantics. Otherwise put, the speciﬁcally topological require-
ment that the operators B∃and B−∃preserve open sets is enough to push
through the result for intuitionistic modal and tense logics.

172
J.M. Davoren
Theorem 1. [Semantic preservation for tense topo-bisimulations] Let M1 =
(X1, T1, R1, v1) and M2 = (X2, T2, R2, v2) be any two topological models, and let
B : X1 ; X2 be a tense topo-bisimulation between M1 and M2.
(1.) If M1 and M2 are open and l.s.c., then for all x ∈X1 and y ∈X2:
x B y
implies
(∀ϕ ∈Lt ) [ x ∈ ϕ 
M1
I
⇔y ∈ ϕ 
M2
I
]
(2.) For all x ∈X1 and y ∈X2:
x B y
implies
(∀ϕ ∈Lt
□) [ x ∈ ϕ 
M1 ⇔y ∈ ϕ 
M2 ]
Proof. The proof proceeds as usual, by induction on the structure of formulas,
to establish the two inclusions displayed in (5), or their analogs for the classical
denotation maps. The base case for atomic propositions is given by conditions
(i.a) and (i.b). For the classical semantics in Part (2.), the argument is com-
pletely standard for the propositional and modal/tense operators, and the case
for topological □is made in [1]. For the intuitionistic semantics in Part (1.), we
give the cases for implication →and for box □·. Assume the result holds for ϕ1
and ϕ2 in Lt. In particular, from Assertions (5) and (6), we have:
(X1 −ϕ1M1
I
) ⊆(X1 −B−∃(ϕ1M2
I
)), and ϕ2M1
I
⊆B−∀( ϕ2 M2
I
). Now:
B∃( ϕ1 →ϕ2 M1
I
)
= B∃(int T1 ( ( X1 −ϕ1M1
I
) ∪ϕ2M1
I
))
⊆B∃
int T1

X1 −B−∃(ϕ1M2
I
) ∪B−∀(ϕ2M2
I
)

by induction hypothesis
= B∃
int T1

B−∀(X2 −ϕ1M2
I
) ∪B−∀(ϕ2M2
I
)

by duality B−∀/ B−∃
⊆int T2

B∃
B−∀(X2 −ϕ1M2
I
) ∪B−∀(ϕ2M2
I
)

by B−1 being l.s.c.
⊆int T2

B∃
B−∀( (X2 −ϕ1M2
I
) ∪ϕ2M2
I
)

by monotonicity of B−∀
⊆int T2 ( ( X2 −ϕ1M2
I
) ∪ϕ2M2
I
)
by adjoint property
=  ϕ1 →ϕ2 M2
I
Verifying that B−∃( ϕ1 →ϕ2 M2
I
) ⊆ ϕ1 →ϕ2 M1
I
proceeds similarly, us-
ing from the induction hypothesis: (X2 −ϕ1M2
I
) ⊆(X2 −B∃(ϕ1M1
I
)), and
ϕ2M2
I
⊆B∀( ϕ2 M1
I
).
For the □· case:
 □·ϕ M1
I
= int T1

R−∀
1
( ϕ M1
I
)

⊆int T1

R−∀
1

B−∀( ϕ M2
I
)

by induction hypothesis
⊆int T1

B−∀
R−∀
2
( ϕ M2
I
)

since R1 ◦B = B ◦R2
⊆B−∀
int T2

R−∀
2
( ϕ M2
I
)

by B−1 being l.s.c. (dual B−∀form)
= B−∀( ϕ M2
I
)
The argument for ■· symmetrically appeals to B being l.s.c. (dual B∀form). ⊣
In a sequel paper, [10], we give a partial converse (Hennessy-Milner type result)
by proving that a certain class of open l.s.c. models has the property that for
any two models M1 and M2 in the class, there is a total and surjective tense

Topological Semantics and Bisimulations for Intuitionistic Modal Logics
173
topo-bisimulation B between them that maximally preserves the intuitionistic
semantics, in the sense that for all x ∈X1 and y ∈X2:
x B y
iﬀ
(∀ϕ ∈Lt ) [ x ∈ ϕ 
M1
I
⇔y ∈ ϕ 
M2
I
] .
5
Axiomatizations and Canonical Models
Let IPC ⊆L0 be the set of intuitionistic propositional theorems, and abusing
notation, let IPC also denote a standard axiomatisation for that logic. Likewise,
let S4□⊆L0,□be the set of theorems of classical S4, and let S4□also denote
any standard axiomatisation of classical S4. To be concrete, let S4□contain
all instances of classical propositional tautologies in the language L0,□, and the
axiom schemes:
N□: □⊤
T□: □ϕ →ϕ
R□: □(ϕ1 ∧ϕ2) ↔□ϕ1 ∧□ϕ2
4□: □ϕ →□□ϕ
and be closed under the inference rules of modus ponens (MP), uniform sub-
stitution (Subst) (of formulas for atomic propositions), and □-monotonicity
(Mono□): from ϕ1 →ϕ2 infer □ϕ1 →□ϕ2.
On notation, for any axiomatically presented logic Λ in a language L, set of
formulas A ⊆L and formula ϕ ∈L, we write A ⊢Λ ϕ to mean that there exists
a ﬁnite set {ψ1, . . . , ψn} ⊆A of formulas such that (ψ1 ∧· · · ∧ψn) →ϕ is a
theorem of Λ (allowing n = 0 and ϕ is a theorem of Λ). The relation ⊢Λ ⊆2L×L
is the consequence relation of Λ. We will abuse notation (as we have with IPC
and S4□) and identify Λ with its set of theorems: i.e. Λ = {ϕ ∈L | ∅⊢Λ ϕ }.
Let IK be the axiomatic system of Fischer Servi [18,15,22], which is equivalent
to an alternative axiomatisation given in [29,32]; IK also goes by the name FS
in [22] and [20,37,38]. IK has as axioms all instances in the language Lm of the
axiom schemes of IPC, and further axiom schemes:
R
 · :
 · (ϕ ∨ψ) ↔(
 · ϕ ∨
 · ψ)
N
 · : ¬
 · ⊥
R□· : □·(ϕ ∧ψ) ↔(□·ϕ ∧□·ψ)
N□· : □·⊤
F1□·
 · :
 · (ϕ →ψ) →(□·ϕ →
 · ψ)
F2□·
 · : (
 · ϕ →□·ψ) →□·(ϕ →ψ)
and is closed under the inference rules (MP) and (Subst), and the rule (Mono
 · ):
from ϕ1 →ϕ2 infer
 · ϕ1 →
 · ϕ2, and likewise (Mono□·).
With regard to notation for combinations of modal logics, we follow that of
[20]. If Λ1 and Λ2 are axiomatically presented modal logics in languages L1 and
L2 respectively, then the fusion Λ1 ⊗Λ2 is the smallest multi-modal logic in the
language L1 ⊗L2 containing Λ1 and Λ2, and closed under all the inference rules
of Λ1 and Λ2, where L1⊗L2 denotes the least common extension of the languages
L1 and L2. If Λ is a logic in language L, and Γ is a ﬁnite list of schemes in L, then
the extension Λ⊕Γ is the smallest logic in L extending Λ, containing the schemes
in Γ as additional axioms, and closed under the rules of Λ. The basic system in

174
J.M. Davoren
[37], under the name IntK, is such that: IK = IntK ⊕F1□·
 · ⊕F2□·
 · . The
latter two schemes were identiﬁed by Fischer Servi in [18]5.
For the extension to tense logics with forwards and backwards modalities, let
IKt be Ewald’s [15] deductive system, which is the fusion of IK
 · □· := IK with
the “mirror” system IK
· ■· having axiom schemes R
· , N
· , R■·, N■·, F1■·
·
and F2■·
· , and inference rules (Mono
· ) and (Mono■·), which is then further
extended with four axiom schemes expressing the adjoint property (Assertion (3))
of the operators interpreting the tense modalities:
Ad1 : ϕ →□·
· ϕ
Ad2 : ϕ →■·
 · ϕ
Ad3 :
 · ■·ϕ →ϕ
Ad4 :
· □·ϕ →ϕ
Thus IKt := (IK
 · □· ⊗IK
· ■·) ⊕Ad1 ⊕Ad2 ⊕Ad3 ⊕Ad4.
We now identify the companion classical logics. Let K□· be the minimal nor-
mal modal logic (over a classical propositional base), and let (S4□⊗K□·) be the
bi-modal fusion of S4□and K□·, and let KmLSC := (S4□⊗K□·) ⊕(
 · □ϕ →
□
 · ϕ) ⊕(□□·ϕ →□·□ϕ) be the extension of (S4□⊗K□·) with characteristic
modal schemes for the R-l.s.c. and R−1-l.s.c. frame conditions, from Proposi-
tion 3 (and as identiﬁed in [16]). Likewise, Kt := (K□· ⊗K■·) ⊕Ad1 ⊕Ad2
is the minimal normal tense logic, and KtLSC := (S4□⊗Kt) ⊕(
 · □ϕ →
□
 · ϕ) ⊕(
· □ϕ →□
· ϕ), here using instead the tense scheme for R−1-l.s.c.
from Proposition 3.
In what follows, we will deal generically with extensions IK ⊕Γ or IKt ⊕Γ
for subsets Γ of the ﬁve axiom schemes below or their ■·-
· mirror images:
T□·
 · : (□·ϕ →ϕ) ∧(ϕ →
 · ϕ)
B□·
 · : (ϕ →□·
 · ϕ) ∧(
 · □·ϕ →ϕ)
D
 · :
 · ⊤
4□·
 · : (□·ϕ →□·□·ϕ) ∧(
 ·
 · ϕ →
 · ϕ) 5□·
 · : (
 · □·ϕ →□·ϕ) ∧(
 · ϕ →□·
 · ϕ)
(7)
where the schemes characterize, in turn, the properties of relations R : X ; X of
reﬂexivity, symmetry, totality (seriality), transitivity and Euclideanness, and the
mirror image scheme characterize relations R such that R−1 has the property6.
For a set Γ of schemes, let C(Γ) be the set of all formulas ϕ ∈Lt that are
int-modal-top valid in every l.s.c. topological frame whose relation R has the
properties corresponding to the schemes in Γ, and let C□(Γ) be the set of all
formulas ϕ ∈Lt
□that are modal-top valid in every topological frame whose
relation R has the properties corresponding to the schemes in Γ.
The topological soundness of IKt and of KtLSC are easy veriﬁcations. For
example, the soundness of the Fischer Servi scheme F1□·
 · is equivalent to the
assertion that, for all open sets U, V ∈T :
R−∃(int T (−U ∪V )) ⊆int T

−int T (R−∀(U)) ∪R−∃(V )

.
5 The intuitionistic modal logics considered in [36] and [23] are yet weaker sub-systems:
they have the normality schemes R□· and N□· for □·, but
 · is sub-normal – they
include the scheme N
 · , but R
 · is replaced by (□·ϕ ∧
 · ψ) →
 · (ϕ ∧ψ).
6 Note that R has reﬂexivity, symmetry or transitivity iﬀR−1 has the same property,
so the mirrored tense schemes T■·
· , B■·
· and 4■·
· are semantically equivalent
to their un-mirrored modal versions.

Topological Semantics and Bisimulations for Intuitionistic Modal Logics
175
The inclusion R−∃(intT (−U ∪V )) ⊆intT

R−∃(−U ∪V )

follows from R be-
ing l.s.c. Applying distribution over unions, duality, and monotonicity, we can
get intT

R−∃(−U ∪V )

⊆intT

−intT (R−∀(U)) ∪R−∃(V )

, so we are done. R
being l.s.c. is also used for soundness of the adjoint axioms Ad2 and Ad3.
From Proposition 2 and topological completeness in Proposition 6 below, we
can derive deductive faithfulness of the extended G¨odel translation.
Proposition 5. [Extended G¨odel translation: deductive faithfulness]
Let Γ be any ﬁnite set of schemes in Lt from the list in (7) above.
For all ϕ ∈Lt,
ϕ ∈IKt ⊕Γ
iﬀGT(ϕ) ∈KtLSC ⊕Γ.
This result can also be derived from a general result for (an equivalent) G¨odel
translation given in [38], Theorem 8, on the faithful embedding of modal logics
L = IntK ⊕Γ1 (including IK ⊕Γ = IntK ⊕F1□·
 · ⊕F2□·
 · ⊕Γ) into bi-
modal logics in the interval between (S4□⊗K□·)⊕GT(Γ1) and (Grz□⊗K□·)⊕
GT(Γ1) ⊕mix, where Grz□= S4□⊕□(□(ϕ →□ϕ) →ϕ) →ϕ and mix =
(□□·ϕ ↔□·ϕ) ∧(□·□ϕ ↔□ϕ). We have restricted the schemes in Γ to those
from a “safe” list of relational properties that don’t require translating, since
the schemes characterize the same relations in the intuitionistic and classical
semantics.
Recall that for a logic Λ in a language L with deductive consequence relation
⊢Λ, a set of formulas x ⊆L is said to be Λ-consistent if x ⊬Λ ⊥; x is Λ-
deductively closed if x ⊢Λ ϕ implies ϕ ∈x for all formulas ϕ ∈L; and x
is maximal Λ-consistent if x is Λ-consistent, and no proper superset of x is Λ-
consistent. A set x ⊆L is a prime theory of Λ if Λ ⊆x, and x has the disjunction
property, and is Λ-consistent, and Λ-deductively closed.
Completeness w.r.t. bi-relational frames for IK and IKt is proved in [18,32]
and [15] by building a canonical model over the state space Xip deﬁned to be the
set of all sets of formulas x ⊆Lt that are prime theories of IKt. The space Xip is
partially ordered by inclusion, so we have available an Alexandrov topology T⊆.
One then deﬁnes the modal accessibility relation R0 in an “almost classical” way,
the only concession to intuitionistic semantics being clauses in the deﬁnition for
both
 · and □·. As veriﬁed in [18] and [32] for the modal logic, and [15] for the
tense logic, the relations R0 and R−1
0
satisfy the frame conditions Zig(⊆, R0)
and Zig(⊆, R−1
0 ). So we get an l.s.c. topological frame F0 = (Xip, T⊆, R0), and
with the canonical valuation u : AP ; Xip given by u(p) = {x ∈Xip | p ∈x};
one then proves of the model M0 = (F0, u) the “Truth Lemma”: for all ϕ ∈Lt
and x ∈Xip, x ∈ ϕ
M0
I
iﬀϕ ∈x.
Adapting [1], Sec. 3, on classical S4, to the classical companion logics here,
we can go beyond pre-orders by equipping the space of maximal consistent sets
of formulas with a topology that is neither Alexandrov nor Stone, but rather is
the intersection of those two topologies.
Proposition 6. [Topological soundness and completeness]
Let Γ be any ﬁnite set of axiom schemes from Lt from the list in (7) above.
(1.) For all ψ ∈Lt
□, ψ is a theorem of KtLSC ⊕Γ
iﬀψ ∈KtLSC ∩C□(Γ).
(2.) For all ϕ ∈Lt, ϕ is a theorem of IKt ⊕Γ
iﬀϕ ∈IKtT ∩C(Γ).

176
J.M. Davoren
In what follows, we use IL and L□, respectively, as abbreviations for the ax-
iomatically presented logics IKt ⊕Γ and KtLSC ⊕Γ. Taking soundness as
established, we sketch completeness by describing the canonical models.
For the classical companion L□, deﬁne a model M□= (Y□m, S□, Q□, v□):
Y□m := {y ⊆Lt
□| y is a maximal L□-consistent set of formulas};
S□is the topology on Y□m which has as a basis the family
{ V (□ψ) | ψ ∈Lt
□} where V (□ψ) := {y ∈Y□m | □ψ ∈y};
Q□: Y□m ; Y□m deﬁned for all y ∈Y□m by
Q□(y) := { y′ ∈Y□m | {
 · ψ | ψ ∈y′} ⊆y and {
· ψ | ψ ∈y} ⊆y′ } ;
v□: AP ; Y□m deﬁned for all p ∈AP by v□(p) := {y ∈Y□m | p ∈y}.
As noted in [1], the topology S□on Y□m is the intersection the “default” Alexan-
drov topology from the canonical relational Kripke model, and the standard
Stone topology on Y□m which has as a basis all sets of the form V (ψ) for all
formulas ψ ∈Lt
□, not just the V (□ψ) ones. Moreover, the space (Y□m, S□) is
compact and dense-in-itself (has no isolated points). Veriﬁcation that Q□and
Q−1
□
are l.s.c. reduces to establishing that for all ψ ∈Lt
□:
Q−∃
□(V (□ψ)) = V (□
 · □ψ)
and
Q∃
□(V (□ψ)) = V (□
· □ψ).
The “Truth Lemma” is y ∈ ϕM□iﬀψ ∈y, for all ψ ∈Lt
□and y ∈Y□m.
For the intuitionistic logic IL, deﬁne an open model M⋆= (Xip, Tsp, R⋆, u⋆):
Xip := {x ⊆Lt | x is a prime IL-theory };
Tsp is the topology on Xip which has as a basis the family
{ U(ϕ) | ϕ ∈Lt } where U(ϕ) := {x ∈Xip | ϕ ∈x};
R⋆: Xip ; Xip deﬁned for all x, x′ ∈Xip by R⋆:= R0;
i.e. x R⋆x′ iﬀ
{
 · ψ | ψ ∈x′} ⊆x and {ψ | □·ψ ∈x} ⊆x′ and
{
· ψ | ψ ∈x} ⊆x′ and {ψ | ■·ψ ∈x′} ⊆x ;
u⋆: AP ; Xip deﬁned for all p ∈AP by u⋆(p) := U(p).
Here, the toplogical space (Xip, Tsp) has a spectral topology (e.g. [33], Sec.4),
which means it is compact and T0; the family of compact and open sets in Tsp
gives a basis for the toplogy; and Tsp is sober, i.e. for every completely prime
ﬁlter F of Tsp, there exists a (unique) point x ∈Xip such that F = Fx :=
{U ∈Tsp | x ∈U}, the ﬁlter of neighbourhoods of x. The hardest parts of the
veriﬁcation are the l.s.c. properties for R⋆and R−1
⋆, and the task reduces to
establishing that for all ϕ ∈Lt:
R−∃
⋆(U(ϕ)) = U(
 · ϕ)
and
R∃
⋆(U(ϕ)) = U(
· ϕ)
To prove the right-to-left inclusions, a recursive Henkin-style construction can
be used to produce a prime IL-theory x′ such that x R⋆x′ and ϕ ∈x′, to
derive x ∈R−∃
⋆(U(ϕ)) given x ∈U(
 · ϕ), and symmetrically for the R∃
⋆(U(ϕ))
inclusion. The required “Truth Lemma” is x ∈ ϕM⋆
I
iﬀϕ ∈x for all ϕ ∈Lt
and x ∈Xip.

Topological Semantics and Bisimulations for Intuitionistic Modal Logics
177
6
Topological Bisimulation Between Canonical Models
The G¨odel translation is a syntactic function GT : Lt →Lt
□, which naturally
gives rise to a semantic relationship between the canonical model spaces Xip and
Y□m. Deﬁne a set-valued map G : Xip ; Y□m by:
G(x) := { y ∈Y□m | GT(x) ⊆y }
Note that the image GT(x) of an intuitionistic prime theory x ∈Xip will in
general have many classical maximal consistent extensions y ∈Y□m.
Let M∗
□= (Y□m, S∗
□, Q□, v∗
□) be the open and l.s.c. model obtained from M□
by taking S∗
□to be the proper sub-topology of S□having as a basis the open
sets { V (□GT(ϕ)) | ϕ ∈Lt }7, with valuation v∗
□(p) := intS∗
□(v□(p)) = V (□p).
Theorem 2. The maps G : Xip ; Y□m and G−1 : Y□m ; Xip are such that:
(1.) both G and G−1 are l.s.c. with respect to Tsp and S∗
□;
(2.) both G and G−1 are total and surjective;
(3.) R⋆◦G = G ◦Q□and Q□◦G−1 = G−1 ◦R⋆; and
(4.) G∃(u⋆(p)) ⊆v□(p) and G−∃(v□(p)) ⊆u⋆(p) for all atomic p ∈AP.
Hence G is a tense topo-bisimulation between M⋆and M∗
□.
Proof. For Part (1.), the l.s.c. properties, we need only look at the basic opens
in Tsp and S∗
□. Using the openness theorem □GT(ϕ) ↔GT(ϕ), it is readily
established that for all ϕ ∈Lt:
G−∃(V (□GT(ϕ))) = U(ϕ)
and
G∃(U(ϕ)) = V (□GT(ϕ)).
For Part (2.), the totality of G, note that every prime theory x ∈Xip is IL-
consistent, hence the image GT(x) ⊆L□is L□-consistent, and so has a maximal
L□-consistent superset y ⊇GT(x) with y ∈Y□m, by Lindenbaum’s Lemma. For
the surjectivity of G (equivalently, the totality of G−1), deﬁne as follows the
(proper) subset G∗of formulas L□-equivalent to the image under GT of some
□-free formula: G∗:= {ψ ∈Lt
□| (∃ϕ ∈Lt) ⊢L□ψ ↔GT(ϕ) }. Now for any
maximal L□-consistent theory y ∈Y□m, deﬁne the subset y∗:= y ∩G∗. Deﬁne
Xm
ip := {x0 ∈Xip | (∀x ∈Xip) x0 ⊈x } to be the (proper) subset of prime IL
theories that are ⊆-maximal. Then every x0 ∈Xm
ip is a maximal IL-consistent
theory, and is also a classical L□-consistent theory that is maximal within the
□-free language Lt. So by the deductive faithfulness of the G¨odel translation,
for every y ∈Y□m, there is a maximal x0 ∈Xm
ip such that GT(x0) = y∗, and
hence GT(x0) ⊆y. Hence G is surjective. The veriﬁcations for the remaining
Parts (3.) and (4.) are somewhat lengthy, but straight-forward.
⊣
In a sequel [10], we return to the intuitionistic canonical model M⋆, and use
it to give a Hennessy-Milner type result on maximal topological bisimulations
preserving the intuitionistic semantics. For both the intuitionistic and classical
7 M∗
□will be an l.s.c. model, as Q□and Q−1
□
will still be l.s.c. w.r.t. the sub-topology
S∗
□; using Q−∃
□(V (□ψ)) = V (□
 · □ψ) and Q∃
□(V (□ψ)) = V (□
· □ψ) and the open-
ness property GT(ϕ) ↔□GT(ϕ), we have Q−∃
□(V (□GT(ϕ))) = V (□GT(
 · ϕ)) and
Q∃
□(V (□GT(ϕ))) = V (□GT(
· ϕ)).

178
J.M. Davoren
semantics, the classes of models identiﬁed have suitable ‘saturation’ properties
w.r.t. the semantics, and the maximal topo-bisimulations are constructed via
natural maps into the canonical models. Within these Hennessy-Milner classes,
we identify some subclasses of models of continuous, discrete and hybrid dynam-
ical systems.
References
1. M. Aiello, J. van Benthem, and G. Bezhanishvili.
Reasoning about space: the
modal way. J. Logic and Computation, 13:889–920, 2003.
2. J-P. Aubin and H. Frankowska. Set-Valued Analysis. Birkh¨auser, Boston, 1990.
3. J.-P. Aubin, J. Lygeros, M. Quincampoix, S. Sastry, and N. Seube. Impulse diﬀer-
ential inclusions: A viability approach to hybrid systems. IEEE Trans. Automatic
Control, 47:2–20, 2002.
4. G. Bezhanishvili. Varieties of monadic Heyting algebras. part I. Studia Logica,
61:362–402, 1999.
5. G. Bezhanishvili. Varieties of monadic Heyting algebras. part II: Duality theory.
Studia Logica, 62:21–48, 1999.
6. P. Blackburn, M. de Rijke, and Y. Venema. Modal Logic. Cambridge University
Press, 2001.
7. Marcello M. Bonsangue and Joost N. Kok.
Relating multifunctions and predi-
cate transformers through closure operators. In Theoretical Aspects of Computer
Software (TACS ’94), pages 822–843, 1994.
8. R.A. Bull.
MIPC as a formalization of an Intuitionist concept of modality.
J.
Symbolic Logic, 31:609–616, 1966.
9. J.M. Davoren. Topologies, continuity and bisimulations. Theoretical Informatics
and Applications, 33:357–381, 1999.
10. J.M. Davoren. Topological bisimulations and Hennessy-Milner classes for intuition-
istic and classical spatio-temporal modal logics. Technical report, Department of
Electrical & Electronic Engineering, University of Melbourne, January 2007.
11. J.M. Davoren, V. Coulthard, N. Markey, and T. Moor. Non-deterministic temporal
logics for general ﬂow systems. In R. Alur and G.J. Pappas, editors, Hybrid Sys-
tems: Computation and Control (HSCC’04), LNCS 2993, pages 280–295. Springer,
2003.
12. J.M. Davoren, V. Coulthard, T. Moor, R.P. Gor´e, and A. Nerode. Topological
semantics for intuitionistic modal logics, and spatial discretisation by A/D maps.
In Workshop on Intuitionistic Modal Logic and Applications (IMLA), Copenhagen,
Denmark, 2002. Proceedings available as Technical Report No. 61, University of
Bamberg, Faculty of Information Systems and Applied Computer Sciences.
13. J.M. Davoren and R.P. Gor´e. Bimodal logics for reasoning about continuous dy-
namics. In Advances in Modal Logic 3, pages 91–110. World Scientiﬁc, 2002.
14. L. Esakia. Topological kripke models. Soviet Mathematics: Doklady, 15:147–151,
1974. English Translation.
15. W.B. Ewald. Intuitionistic tense and modal logic. J. of Symbolic Logic, 51:166–179,
1986.
16. G. Fischer Servi. On modal logic with an Intuitionistic base. Studia Logica, 36:141–
149, 1977.
17. G. Fischer Servi. Semantics for a class of Intuitionistic modal calculi. In Italian
Studies in the Philosophy of Science, pages 59–72. D. Reidel, 1981.

Topological Semantics and Bisimulations for Intuitionistic Modal Logics
179
18. G. Fischer Servi. Axiomatizations for some Intuitionistic modal logics. Rend. Sem.
Mat. Univers. Politecn. Torino, 42:179–194, 1984.
19. M.C. Fitting.
Intuitionistic Logic, Model Theory and Forcing.
North Holland,
1968.
20. D.M. Gabbay, A. Kurucz, F. Wolter, and M. Zakharyaschev. Many-Dimensional
Modal Logics: Theory and Applications, volume 148 of Studies in Logic. Elsevier,
2003.
21. K. G¨odel. An interpretation of the Intuitionistic propositional calculus (1933). In
S. Feferman, editor, Collected Works, volume 1, pages 301–303. Oxford UP, 1989.
Publications 1929-1936.
22. C. Grefe. Fischer Servi’s intuitionistic modal logic has the ﬁnite model property.
In Advances in Modal Logic, volume 1. CSLI, Stanford, 1998.
23. B.P. Hilken. Topological duality for intuitionistic modal algebras. J. of Pure and
Applied Algebra, 148:171–189, 2000.
24. K. Kuratowski. Topology. Academic Press, New York, 1966.
25. J.C.C. McKinsey and A. Tarski. The algebra of topology. Annals of Mathematics,
pages 141–191, 1944.
26. G. Mints. A Short Introduction to Intuitionistic Logic. Kluwer, New York, 2000.
27. A. Monteiro and O. Varsavsky. Algebras de Heyting monadicas. Actas de las X
Jornadas de la Union Matematica Argentina, pages 52–62, 1957.
28. H. Ono. On some Intuitionistic modal logics. Publications of the Research Institute
for Mathematical Science, Kyoto University, 13:55–67, 1977.
29. G. Plotkin and C. Stirling. A framework for intuitionistic modal logics. In J. Y.
Halpern, editor, Proc. 1986 Conference: Theoretical Aspects of Reasoning About
Knowledge, 1986.
30. A. Prior. Time and Modality. Clarendon Press, Oxford, 1957.
31. H. Rasiowa and R. Sikorski. Mathematics of Metamathematics. PWN Warsaw,
1963.
32. A.K. Simpson.
The Proof Theory and Semantics of Intuitionistic Modal Logic.
PhD thesis, Department of Computer Science, University of Edinburgh, 1994.
33. M.B. Smyth. Topology.
In S. Abramsky, D.M. Gabbay, and T.S.E. Maibaum,
editors, Handbook of Logic in Computer Science, Vol 1, pages 641–751. Oxford
Science, 1992.
34. N.-Y. Suzuki. An algebraic approach to Intuitionistic modal logics in connection
with Intuitionistic predicate logic. Studia Logica, 48:141–155, 1988.
35. O. Varsavsky. Quantiﬁers and equivalence relations. Revista Matematica Cuyana,
2:29–51, 1956.
36. D. Wijesekera. Constructive modal logics I. Annals of Pure and Applied Logic,
50:271–301, 1990.
37. F. Wolter and M. Zakharyaschev. Intuitionistic modal logic. In Logic and Foun-
dations of Mathematics, pages 227 – 238. Kluwer Academic Publishers, 1995.
38. F. Wolter and M. Zakharyaschev. Intuitionistic modal logics as fragments of classi-
cal bimodal logics. In E. Orlowska, editor, Logic at Work, pages 168 – 186. Kluwer
Academic Publishers, 1998.

A Decidable Temporal Logic of Repeating
Values⋆
St´ephane Demri1, Deepak D’Souza2, and R´egis Gascon1
1 LSV, ENS Cachan, CNRS, Inria
{demri,gascon}@lsv.ens-cachan.fr
2 Dept. of Computer Science & Automation,
Indian Institute of Science, Bangalore, India
deepakd@csa.iisc.ernet.in
Abstract. Various logical formalisms with the freeze quantiﬁer have
been recently considered to model computer systems even though this is
a powerful mechanism that often leads to undecidability. In this paper, we
study a linear-time temporal logic with past-time operators such that the
freeze operator is only used to express that some value from an inﬁnite
set is repeated in the future or in the past. Such a restriction has been
inspired by a recent work on spatio-temporal logics. We show decidability
of ﬁnitary and inﬁnitary satisﬁability by reduction into the veriﬁcation
of temporal properties in Petri nets. This is a surprising result since
the logic is closed under negation, contains future-time and past-time
temporal operators and can express the nonce property and its negation.
These ingredients are known to lead to undecidability with a more liberal
use of the freeze quantiﬁer.
1
Introduction
Temporal logic with freeze. In logical languages, the freeze mechanism al-
lows to store a value in a register and to test later the value in the register with
a current value. This operator is useful to compare values at distinct states of
Kripke-like structures. The freeze quantiﬁer has found applications in real-time
logics [Hen90], in hybrid logics [Gor96, ABM01], in modal logics with predi-
cate λ-abstraction [Fit02] and for the speciﬁcation of computations of systems
with unboundedly many locations as resources [LP05]. Although it is known
that the freeze operator can lead to undecidability (even with only equality on
data [LP05, DLN07]), many decidable temporal logics have a freeze mechanism,
sometimes implicitly, see e.g. [AH94, LMS02, KV06]. Recent developments have
shown the ubiquity of the freeze operator [LP05, tCF05, DLN07, Laz06, Seg06]
and its high expressive power as witnessed by the Σ1
1-completeness results shown
in [DLN07].
⋆Work supported by the Indo-French project “Timed-DISCOVERI” (P2R/RNP
scheme).
S. Artemov and A. Nerode (Eds.): LFCS 2007, LNCS 4514, pp. 180–194, 2007.
c
⃝Springer-Verlag Berlin Heidelberg 2007

A Decidable Temporal Logic of Repeating Values
181
The need to design decidable fragments of simple linear-time temporal logic
LTL with the freeze quantiﬁer stems from [DLN07, Laz06] and most known de-
cidable fragments in [DLN07, Laz06] does not allow unrestricted use of negation.
Still, ﬁnitary and inﬁnitary satisﬁability for Boolean combinations of safety for-
mulae (with a unique register) is decidable [Laz06]. Potential applications range
from the veriﬁcation of inﬁnite-state systems [Hen90, DLN07] to querying XML
documents or more modestly data strings [BMS+06, Seg06]. In the paper, we
are interested in studying fragments of LTL with the freeze operator that are
decidable in the ﬁnitary and inﬁnitary cases, that allow unrestricted use of nega-
tion (by contrast to the ﬂat fragments in [DLN07]) and that allow all standard
past-time operators (by constrast to what is done in [BMS+06, DL06]). Even in
terms of expressive power, the fragment newly shown decidable in the paper can
express the “nonce property” and its negation (all the values of a variable are
diﬀerent at every position). Moreover, in [WZ00, Sect. 7], the authors advocate
the need to consider inﬁnitary disjunction of the form 
i>0 x = Xiy where Xiy
refers to the value of y at the ith next position. This states that a future value
of y is equal to the current value of x. Our fragment can express this property,
with the formula x = ♦y, as well as the dual one: 
i>0 x = Xiy can be ex-
pressed by the formula ¬(x ̸= ♦y). In the paper we introduce the constraint
logic CLTL(N, =) with atomic formulae x = ♦y and past-time operators X−1
and S. This logic is denoted by CLTL♦. Hence, in CLTL♦, the freeze quantiﬁer
is only used to specify that some values are repeated. Even though CLTL♦does
not enjoy ﬁrst-order completeness, see e.g. [Rab06], it satisﬁes interesting com-
putational properties as shown below.
Our contribution. We show that ﬁnitary and inﬁnitary satisﬁability for CLTL♦
with temporal operators {X, X−1, S, U} is decidable. We provide a uniform proof
for the ﬁnite and inﬁnite cases based on some substantial extension of the
automaton-based approach for (constraint) LTL from [VW94, DD07]. The pos-
sibility to compare two values at unbounded distance requires a special class
of counter automata for which ﬁnitary and inﬁnitary nonemptiness is shown
decidable. To do so, we take advantage of a deep result from [Jan90] estab-
lishing that verifying fairness properties based on the temporal operator GF
(“always eventually”) in Petri nets is decidable. By contrast model-checking for
full LTL over Petri nets is undecidable [HR89] (see also [Esp94] with linear-
time mu-calculi). Observe that inﬁnitary CLTL♦is the ﬁrst decidable fragment
of CLTL↓
1(N, =) [DLN07] with an unrestricted use of negation and that con-
tains all the temporal operators from {X, X−1, S, U}. A nice by-product of our
technique is that the extensions with temporal operators deﬁnable in Monadic
Second Order Logic (MSOL) or with x = ♦−1y (“a value of y in the past
is equal to the current value of x”) are also decidable. Finally, we show that
ﬁnitary and inﬁnitary satisﬁability for CLTL♦restricted to one variable is
pspace-complete.
Because of lack of space, omitted proofs can be found in [DDG07].

182
S. Demri, D. D’Souza, and R. Gascon
2
Preliminaries
2.1
Temporal Logic with Repeating Values
Let VAR = {x1, x2, . . .} be a countably inﬁnite set of variables. The formulae of
the logic CLTL♦are deﬁned as follows:
φ ::= x = Xiy | x = ♦y | φ ∧φ | ¬φ | Xφ | φUφ | X−1φ | φSφ
where x, y ∈VAR and i ∈N. Formulae of the form either x = Xiy or x = ♦y are
said to be atomic and an expression of the form Xix (i next symbols followed
by a variable) is called a term. Given a set of temporal operators deﬁnable from
those in {X, X−1, S, U} and k ≥0, we write CLTL♦
k (O) to denote the fragment
of CLTL♦restricted to formulae with temporal operators from O and with at
most k variables.
A valuation is a map VAR →N and a model σ is a non-empty sequence of
valuations either ﬁnite or inﬁnite. All the subsequent developments can be equiv-
alently done with the domain N replaced by an inﬁnite set D since only equality
tests are performed. We write |σ| to denote the length of σ. The satisfaction
relation is deﬁned inductively as follows where σ is a model and 0 ≤i ≤|σ| −1:
– σ, i |= x = Xjy iﬀi + j ≤|σ| −1 and σ(i)(x) = σ(i + j)(y),
– σ, i |= x = ♦y iﬀthere exists j > 0 s.t. i+j ≤|σ|−1 and σ(i)(x) = σ(i+j)(y),
– σ, i |= φ ∧φ′ iﬀσ, i |= φ and σ, i |= φ′,
σ, i |= ¬φ iﬀσ, i ̸|= φ,
– σ, i |= Xφ iﬀi + 1 ≤|σ| −1 and σ, i + 1 |= φ,
– σ, i |= X−1φ iﬀi > 0 and σ, i −1 |= φ,
– σ, i |= φUφ′ iﬀthere is i ≤j ≤|σ| −1 s.t. σ, j |= φ′ and for every i ≤l <
j, σ, l |= φ.
– σ, i |= φSφ′ iﬀthere is 0 ≤j ≤i s.t. σ, j |= φ′ and for j ≤l < i, σ, l |= φ.
We write σ |= φ if σ, 0 |= φ. We shall use the standard abbreviations about
the temporal operators (G, F, F−1, . . . ) and Boolean operators (∨, ⇒, . . . ). We
use the notation Xix = Xjy as an abbreviation for Xi(x = Xj−iy) (when i ≤j).
The ﬁnitary [resp. inﬁnitary] satisﬁability problem consists in checking whe-
ther given a formula φ, there is a ﬁnite [resp. inﬁnite] model such that σ |= φ.
It is known that ﬁnitary satisﬁability for LTL can be easily reduced in logspace
to inﬁnitary satisﬁability by introducing for instance an additional propositional
variable p and by requiring that pUG¬p holds true. In that way, p holds true at
every state of a preﬁx and p does not hold on the complement suﬃx. The same
principle does not apply to reduce ﬁnitary satisﬁability for CLTL♦to inﬁni-
tary satisﬁability even by introducing additional variables in order to simulate a
propositional variable. This is due to the additional atomic formulae of the form
x = ♦y. That is why we distinguish the two problems in this paper.
We note that a constraint of the form x diﬀ♦y (“the value of x diﬀers from
some future value of y”) can be expressed in CLTL♦:
x diﬀ♦y ⇔(¬(x = Xy)∧X⊤)∨((x = Xy)∧X(y = Xy)U((y ̸= Xy)∧X⊤))) (1)

A Decidable Temporal Logic of Repeating Values
183
With inﬁnite models, the conjunct X⊤can be deleted. We could also introduce
constraints of the form x = X−iy but this can be expressed in the language
using the equivalence x = X−iy ⇔X−i⊤∧X−i(y = Xix). Similarly, CLTL♦can
express whether a variable is a nonce by the formula G¬(x = ♦x). The formula
below states a valid property when x and y are nonces:
(G¬(x = ♦x) ∧G¬(y = ♦y)) ⇒G(x = y ⇒¬(x = ♦y)).
Other properties witnessing the high expressive power of CLTL♦can be found
in [LP05, Sect.3] about systems of pebbles evolving in time.
Apart from the above-mentioned problems, we could also consider standard
model-checking problems that can be reduced to the satisﬁability problem. In-
deed, we can deﬁne a suitable class of automata such that the execution of any
automaton of this class can be encoded into a CLTL♦formula.
2.2
Known Extensions of CLTL♦
In this section, we recall the deﬁnition of a few known extensions of CLTL♦
which is useful for future comparisons. The logic CLTL♦is clearly a fragment
of the logic CLTL↓(N, =) introduced in [DLN07] and restricted to one register.
An equivalent logic of CLTL↓(N, =) is denoted by CLTL↓in this paper and it is
deﬁned as follows. We consider an additional set of registers REG = {r1, r2, . . .}
and the formulae of CLTL↓are deﬁned as those of CLTL♦except that we allow
only atomic formulae of the form r = x where r ∈REG and x ∈VAR, and we
add the inductive clause ↓r=x φ. The satisfaction relation is parameterized by a
register assignment ρ : REG →N with σ, i |=ρ↓r=x φ iﬀσ, i |=ρ[r→σ(i)(x)] φ and
σ, i |=ρ r = x iﬀρ(r) = σ(i)(x). Consequently, the atomic formula x = ♦y in
CLTL♦can be naturally encoded in CLTL↓by ↓r=x XF(r = y) and x = Xiy by
↓r=x Xi(r = y).
We write CLTL↓
(k,k′)(O) to denote the fragment of CLTL↓restricted to the
temporal operators from O with at most k variables and k′ registers. Following
the notation from [DL06], for α ≥0 we write LTL↓
α(∼, O) to denote the fragment
CLTL↓
(1,α)(O) restricted to atomic formulae of the form r = x.
2.3
A Decidable Fragment of Finitary Satisﬁability
It is shown in [DLN07] that CLTL↓is strictly more expressive than its freeze-
free fragment. The same argument applies to show that CLTL♦is strictly more
expressive than its fragment without atomic formulae of the form x = ♦y. Ob-
serve also that CLTL♦is neither a fragment of the pure-future safety fragment
in [Laz06] (where occurrences of U formulae are never in the scope of an even
number of negations) nor a fragment of the ﬂat fragment of CLTL↓. Unlike
these fragments, CLTL♦contains past-time operators and negation can be used
without any restriction. Inﬁnitary satisﬁability for safety LTL↓
1(∼, X, U) is ex-
pspace-complete [Laz06], for full LTL↓
1(∼, X, U) is Π0
1-complete and, ﬁnitary
and inﬁnitary satisﬁability for ﬂat CLTL↓are pspace-complete. By contrast, in

184
S. Demri, D. D’Souza, and R. Gascon
this paper we show that ﬁnitary and inﬁnitary satisﬁability for CLTL♦(with
full past-time temporal operators) are decidable problems. By taking advan-
tage of [DLN07, DL06], it is already possible to establish decidability of ﬁnitary
satisﬁability for strict fragments of CLTL♦.
Theorem 1. (I) Finitary satisﬁability for CLTL♦(X, U) is decidable.
(II) Finitary satisﬁability for CLTL♦(X, X−1, F, F−1) is decidable.
In the paper we shall show much stronger results: ﬁnitary and inﬁnitary satisﬁa-
bility for full CLTL♦even augmented with MSOL deﬁnable temporal operators
are decidable. In the rest of the paper, we systematically treat the ﬁnitary and
inﬁnitary cases simultaneously. However, we provide the full technical details for
the inﬁnitary case only and we sketch the main ideas for the ﬁnitary case. This
latter case cannot be reduced in the obvious way to the inﬁnitary case but its
solution is close to the one for the inﬁnitary case.
3
Automata-Based Approach with Symbolic Models
In this section we explain how satisﬁability can be solved using symbolic models
which are abtractions of concrete CLTL♦models. We provide the outline of our
automata-based approach, and consider the technical details in Sects. 4 and 5.
3.1
Symbolic Models
Let φ be a CLTL♦formula with k variables {x1, . . . xk} and we write l (the “X-
length” of φ) to denote the maximal i such that a term of the form Xix occurs
in φ. In order to deﬁne the set of atomic formulae that are helpful to determine
the satisﬁability status of φ, we introduce the set of constraints Ωl
k that contains
constraints of the form either Xix = Xjy or Xi(x = ♦y) and their negation with
x, y ∈{x1, . . . xk} and i, j ∈{0, . . . , l}. Models are abstracted as sequences of
frames that are deﬁned as maximally consistent subsets of Ωl
k.
An l-frame is a set fr ⊆Ωl
k that is maximally consistent in that it satisﬁes
the conditions below:
(F1) For every constraint ϕ ∈Ωl
k, either ϕ or ¬ϕ belongs to fr but not both.
(F2) For all i ∈{0, . . ., l} and x ∈{x1, . . . xk}, Xix = Xix ∈fr.
(F3) For all i, j ∈{0, . . . , l} and x, y ∈{x1, . . . xk}, Xix = Xjy ∈fr iﬀXjy =
Xix ∈fr.
(F4) For all i, j, j′ ∈{0, . . . , l} and x, y, z ∈{x1, . . . , xk}, {Xix = Xjy, Xjy =
Xj′z} ⊆fr implies Xix = Xj′z ∈fr.
(F5) For all i, j ∈{0, . . ., l} and x, y ∈{x1, . . . xk} such that Xix = Xjy ∈fr:
– if i = j, then for every z ∈{x1, . . . , xk} we have Xi(x = ♦z) ∈fr iﬀ
Xj(y = ♦z) ∈fr;
– if i < j then Xi(x = ♦y) ∈fr, and for z ∈{x1, . . . , xk}, Xi(x = ♦z) ∈fr
iﬀeither Xj(y = ♦z) ∈fr or there exists i < j′ ≤j such that Xix =
Xj′z ∈fr.
Conditions (F2)–(F4) simply encode that equality is an equivalence relation.

A Decidable Temporal Logic of Repeating Values
185
For an l-frame fr, x ∈{x1, . . . , xk} and i ∈{0, . . ., l}, we deﬁne
– the set of future obligations for x at level i in fr as ♦fr(x, i)
def
= {y | Xi(x =
♦y) ∈fr},
– the equivalence class of x at level-i in fr as [(x, i)]fr
def
= {y | Xix = Xiy ∈fr}.
An l-frame fr can be represented as an annotated undirected graph Gfr which
has vertices (x, i) for x ∈{x1, . . . , xk} and i ∈{0, . . . , l}, and an edge between
(x, i) and (y, j) iﬀthe constraint Xix = Xjy belongs to fr. A vertex (x, i) in the
graph is annoted with an “open” arc labelled by the set of future obligations
♦fr(x, i) for that vertex. Fig. 1 shows an example of a 3-frame over the variables
{x, y, z}. For convenience we avoid showing transitively inferable edges.
1
5
5
1
1
5
6
6
6
5
8
8
9
9
2
3
0
6
0
7
0
y, z
y, z
x
y
z
z
z
x
y
x
x
y
z
y, z
x
z
x
y
x
y
z
y, z
x
z
x
y
z
z
Gfr
σ
Gρ
Fig. 1. Example 3-frame graph, concrete model σ, and its induced 3-frame graph Gρ
We denote by Framel
k the set of such frames built w.r.t. k and l. We say that
a model σ satisﬁes a frame fr at position i (denoted σ, i |= fr) iﬀσ, i |= ϕ for
every constraint ϕ in fr.
Since a frame can be viewed as a set of constraints about l + 1 consecutive
positions, for ﬁnitary satisﬁability we need to add an information about the
possibility to end the model before the end of the current window of length l+1.
This can be done with O(l) bits and then the conditions (F1)–(F5) need to be
updated accordingly in order to take into account this possibility. Note that this
method allows to handle the particular case where there exists a model whose
size is smaller than the X-length of the formula.
Lemma 1. For all models σ with k variables and 0 ≤i ≤|σ| −1, there exists a
unique frame fr ∈Framel
k such that σ, i |= fr.
A pair of l-frames ⟨fr, fr ′⟩is said to be one-step consistent
def
⇔
– for all 0 < i, j ≤l, Xix = Xjy ∈fr iﬀXi−1x = Xj−1y ∈fr ′,
– for all 0 < i ≤l, Xi(x = ♦y) ∈fr iﬀXi−1(x = ♦y) ∈fr ′.
A symbolic model of X-length l is a (ﬁnite or inﬁnite) sequence of l-frames ρ
such that for 0 ≤i < |ρ| −1, ⟨ρ(i), ρ(i + 1)⟩is one-step consistent. We deﬁne
the symbolic satisfaction relation ρ, i |=symb φ, for a formula φ of X-length l and

186
S. Demri, D. D’Souza, and R. Gascon
a symbolic model ρ of X-length l, as done for CLTL♦except that for atomic
formulas ϕ we have: ρ, i |=symb ϕ
def
⇔ϕ ∈ρ(i). We say a model σ realizes
a symbolic model ρ (or equivalently that ρ admits a model σ)
def
⇔for every
0 ≤i ≤|σ| −1, we have σ, i |= ρ(i).
A symbolic model ρ of X-length l can also be represented as an annotated
graph Gρ in a similar manner to l-frames. Thus the vertices of Gρ are of the
form (x, i) with an edge between (x, i) and (y, j) with 0 ≤j −i ≤l iﬀthere was
an edge between (x, 0) and (y, j −i) in the frame graph Gρ(i). The annotations
for future obligations are added similarly. Fig. 1 shows the graph representation
of a symbolic model ρ of X-length 3, and a model it admits. By a path p in Gρ
we will mean as usual a (ﬁnite or inﬁnite) sequence of vertices v0, v1 . . . in Gρ
such that each vi, vi+1 is connected by an edge in Gρ. We call p a forward path
if each vi+1 is at a level strictly greater than vi.
3.2
Automata for Symbolic Models
In order to check whether a CLTL♦formula is satisﬁable we use Lemma 2 below
based on the approach developed in [DD07].
Lemma 2. A CLTL♦formula φ of X-length l is satisﬁable iﬀthere exists a
symbolic model ρ of X-length l such that ρ |=symb φ and ρ admits a model.
In order to take advantage of Lemma 2, we use the automaton-based approach
from [VW94]. We build an automaton Aφ as the intersection of two automata
Asymb and Asat such that the language recognized by Asymb is the set of symbolic
models satisfying φ and the language recognized by Asat is the set of symbolic
models that are realized by some models.
We deﬁne the automaton Asymb by adapting the construction from [VW94] for
LTL. We deﬁne cl(φ) the closure of φ as usual, and an atom of φ is a maximally
consistent subset of cl(φ). For the inﬁnitary case, Asymb is the generalized B¨uchi
automaton (Q, Q0, →, F) such that:
– Q is the set of atoms of φ and Q0 = {At ∈Q | φ ∈At, X−1⊤̸∈At},
– At
fr−→At′ iﬀ
(atomic constraints) for every atomic formula ϕ in At, ϕ ∈fr,
(one step) for every Xψ ∈cl(φ), Xψ ∈At iﬀψ ∈At′, and for every
X−1ψ ∈cl(φ), ψ ∈At iﬀX−1ψ ∈At′
– let {ψ1Uφ1, . . . , ψrUφr} be the set of until formulae in cl(φ). We pose F =
{F1, . . . , Fr} where for every i ∈{1, . . ., r}, Fi = {At ∈Q : ψiUφi ̸∈
At or φi ∈At}.
For the ﬁnitary case, the ﬁnite-state automaton Asymb accepting ﬁnite words is
deﬁned as above except that F is a set of states At such that no atomic formula
of the form x = ♦y occurs in At and no formula of the form either Xφ or x = Xiy
with i > 0 occurs in At. Moreover, such ﬁnal states can only be reached when
the frame labelling the last transition contains proper information about the end
of the model.

A Decidable Temporal Logic of Repeating Values
187
In the next section, we explain how one can build the automaton Asat that
recognizes the set of satisﬁable symbolic models. Since Aφ is the automaton
recognizing the intersection of the languages accepted by Asymb and Asat, the
following result is a direct consequence of Lemma 2.
Theorem 2. A CLTL♦formula φ is satisﬁable iﬀthe language recognized by
Aφ is nonempty.
Note that we separate the temporal logic part and the constraint part by deﬁning
two diﬀerent automata. This allows to extend the decidability results to any
extension of LTL that induces an ω-regular class of models. We only need to
change the deﬁnition of Asymb.
4
Characterization of Satisﬁable Symbolic Models
In order to determine whether a symbolic model ρ is “satisﬁable” (i.e. it admits a
model), we introduce counters that remember the satisfaction of constraints x =
♦y. If x = ♦y1 ∧· · · ∧x = ♦yn needs to be satisﬁed at the current position, then
we shall increment a counter indexed by {y1, . . . , yn} that remembers this set of
obligations. In a ﬁnite model, all the obligations need to be fulﬁlled before the
last position whereas in an inﬁnite model either no more unsatisﬁed obligations
arise after a point, or they are essentially fulﬁlled inﬁnitely often. The exact
conditions will be spelt out soon.
4.1
Counting Sequence
For each X ∈P+({x1, . . . , xk}) (set of non-empty subsets of {x1, . . . , xk}), we
introduce a counter that keeps track of the number of obligations that need to
be satisﬁed by X. We identify the counters with elements of P+({x1, . . . , xk}).
A counter valuation c is a map c : P+({x1, . . . , xk}) →N. For instance, we
write c({x, y}) to denote the value of the counter {x, y}, which will stand for
the number of obligations to repeat a distinct value in x and y.
We will deﬁne a canonical sequence of counter valuations along a sym-
bolic model. We introduce some deﬁnitions ﬁrst. For an l-frame fr and X ∈
P+({x1, . . . , xk}), we deﬁne a point of increment for X in fr to be an equiv-
alence class of the form [(x, 0)]fr such that ♦fr(x, 0) = X and (x, 0) is not
connected by a forward edge to a node in fr (i.e. there is no edge between (x, 0)
and (y, j) for any j ∈{1, . . .l}). A point of decrement for X in fr is deﬁned to be
an equivalence class of the form [(x, l)]fr such that ♦fr(x, l) ∪[(x, l)]fr = X, and
(x, l) is not connected by a backward edge to another node in fr (i.e. there is no
edge between (x, l) and (y, j) for any j ∈{0, . . .l −1}). Let u+
fr denote a counter
valuation which records the number of points of increment for each counter X,
in fr. Similarly let u−
fr denote the counter valuation which records the number
of points of decrement for each counter X in fr.
Now let ρ be a symbolic model of X-length l. We carry over the notations for
the set of future obligations and the equivalence class for x at level i to symbolic

188
S. Demri, D. D’Souza, and R. Gascon
models as well. Thus ♦ρ(x, i) is equal to ♦ρ(i)(x, 0) and [(x, i)]ρ is [(x, 0)]ρ(i). For
X ∈P+({x1, . . . , xk}), a point of increment for X in ρ is an equivalence class of
the form [(x, i)]ρ such that [(x, 0)]ρ(i) is a point of increment for X in the frame
ρ(i). Similarly, a point of decrement for X in ρ is an equivalence class of the
form [(x, i)]ρ such that i ≥l + 1 and [(x, l)] is a point of decrement for X in the
frame ρ(i −l).
We can now deﬁne a canonical counter valuation sequence α along ρ, called
the counting sequence along ρ, which counts the number of “unsatisﬁed” points
of increments for each counter X. Let
˙+ denote the “proper addition” of in-
tegers, deﬁned by n ˙+ m = max(0, n + m). We deﬁne α inductively for each
X ∈P+({x1, . . . , xk}) and 0 ≤i < |ρ| as: α(0)(X) = 0; and α(i + 1)(X) =
α(i)(X) ˙+ (u+
ρ(i)(X) −u−
ρ(i+1)(X)).
4.2
Sequences for Satisﬁable Symbolic Models
We characterize satisﬁable symbolic models using their counting sequences.
Lemma 3. A ﬁnite symbolic model ρ is satisﬁable (i.e. admits a model) iﬀthe
ﬁnal value of the counting sequence α along ρ has value 0 for each counter X
(i.e. α(|ρ| −1)(X) = 0) and in the last frame fr of ρ, there are no “unsatis-
ﬁed”obligations – i.e. no node (x, i) in Gfr and variable y ∈♦fr(x, i), with no
edge between (x, i) and (y, j) for j > i.
An inﬁnite symbolic model ρ is satisﬁable iﬀthe following conditions are
satisﬁed:
(C1) There does not exist an inﬁnite forward path p in ρ and a counter X, such
that every node in the path has future obligation X, and there is a variable
y in X which is never connected by a forward edge from a node in p (i.e.
no node in p is connected by a forward edge to a node of the form (y, i)).
(C2) In the counting sequence along ρ, each counter X satisﬁes one of the
condtions:
(a) there is a point after which the value of counter X is always zero and
after which we never see a point of increment for X,
(b) inﬁnitely often we see a point of decrement for X of the form [(x, i)]
with ♦ρ(x, i) ⊂X, or,
(c) for each x ∈X, we inﬁnitely often see a point of decrement for X,
which is connected by a forward path to an x node (i.e a node of the
form (x, i)).
In Sect. 5 we show that we can check these conditions on counting sequences
using counter automata with a decidable nonemptiness problem.
5
Decidability
We introduce a class of counter automata with a disjunctive variant of general-
ized B¨uchi acceptance condition in which, along any run, a zero test is performed
at most once for each counter.

A Decidable Temporal Logic of Repeating Values
189
5.1
Simple Counter Automata
A simple counter automaton A is a tuple ⟨Σ, C, Q, F, I, →⟩such that
– Σ is a ﬁnite alphabet, C is a ﬁnite set of counters,
– Q is a ﬁnite set of locations, I ⊆Q is the set of initial locations,
– F = {F0, F1, . . . , FK} for some K ≥0 where Fi ⊆P(Q) for each i = 1 . . . K,
– →is a ﬁnite subset of Q × P(C) × ZC × Σ × Q.
Elements of →are also denoted by q
Y,up,a
−−−→q′ where Y is interpreted as zero
tests on all counters in Y . A conﬁguration ⟨q, c⟩is an element of Q × NC and,
⟨q, c⟩→⟨q′, c′⟩iﬀthere is a transition q
Y,up,a
−−−→q′ in A s.t. for c ∈Y , c(c) = 0
and for c ∈C, c′(c) = c(c) + up(c). As usual, a run is a sequence of conﬁgura-
tions ruled by the transitions of A. An inﬁnite run is accepting iﬀthere exists
a set F ∈F such that every set Y ∈F is visited inﬁnitely often. Elements
of Σω labeling accepting runs deﬁne the language accepted by A. In order to
accept ﬁnite words, we suppose that F deﬁnes a single set of ﬁnal states and a
ﬁnite run is accepting iﬀit ends at a ﬁnal state with all the counters equal to
zero.
However, we require additional conditions on the control graph of A to be
declared as simple. We require that there is a partition {Q0, . . . , QK} of Q and
corresponding sets of counters C0, C1, . . . , CK with C0 = ∅such that I ⊆Q0
and for i ∈{1, . . . , K}, a transition from a location in Q0 to a location in Qi
can be ﬁred only if the counters of Ci are equal to zero and all the transitions
from a location in Qi go to another location of Qi. Moreover every transition
from a location of Qi does not modify the value of the counters in Ci. As a
consequence, when we enter in the component made of the locations of Qi the
counters in Ci are equal to zero forever. Finally, for i ∈{0, . . . , K}, Fi ⊆P(Qi).
Let us summarize the conditions:
1. Q = Q0 ⊎· · · ⊎QK and I ⊆Q0,
2. F = {F0, F1, . . . , FK} where each Fi ⊆P(Qi),
3. there exist K + 1 sets of counters C0, . . . , CK ⊆C with C0 = ∅such that
the transition relation →⊆Q × P(C) × ZC × Σ × Q veriﬁes the conditions
below: for all i, i′ ∈{0, . . ., K}, q ∈Qi and q′ ∈Qi′, the transitions from q
to q′ are of the form q
Y,up,a
−−−→q′ where
(a) i ̸= i′ implies i = 0 and Y = Ci′,
(b) i = i′ implies Y = ∅,
(c) for c ∈Ci′, up(c) = 0.
In the sequel we consider simple counter automata with C = P+({x1, . . . , xk}),
K = 2k −1 and each set Fi contains sets of states reached by decrementing the
counters in Ci. Lemma 4 below states that simplicity implies decidability of the
nonemptiness problem thanks to [Jan90].
Lemma 4. The nonemptiness problem for simple counter automata is decidable.

190
S. Demri, D. D’Souza, and R. Gascon
5.2
Automata Recognizing Satisﬁable Counting Sequences
Now, we can build a simple counter automaton Al
k recognizing the set of satisﬁ-
able symbolic models of X-length l. We describe the construction for the inﬁnite
case and the automaton that recognizes ﬁnite satisﬁable symbolic models can be
deﬁned similarly.
The simple counter automaton Al
k is deﬁned to be the intersection of the
automata A1 and A2 which check conditions (C1) and (C2) respectively. Au-
tomaton A1 is a B¨uchi automaton and is easy to deﬁne. We focus on deﬁning the
counter automaton A2. We deﬁne A2 = ⟨Σ, C, Q, F, s, →⟩, where Σ = Framel
k,
C = P+({x1, . . . , xk}), Q = {s} ∪Framel
k ∪
Z⊆C QAZ, where QAZ is the set of
states of the automaton AZ which we deﬁne below, →is given by
– s
∅,up0,fr
−−−−→fr
– fr
∅,up,fr′
−−−−→fr ′
– fr
Z,up,fr ′
−−−−→sAZ
where up0 is the zero update (i.e. up0(X) = 0 for each X ∈C), u+
fr(X) ≤
up(X) ≤u+
fr(X) −u−
fr ′(X) for each X ∈C, and sAZ is the start state of au-
tomaton AZ. Moreover, we require in the last rule that for every counter X ∈Z
(i.e. every counter that is tested to zero) we have up(X) = 0.
The B¨uchi automaton AZ is given by:
AZ = A2a
Z ∩

X∈C\Z
(A2b
X ∪A2c
X )
A2c
X =

x∈X
AX,x
where the automaton A2a
Z accepts symbolic models in which there are no points
of increment for any X in Z; the automaton A2b
X checks that inﬁnitely often
there is a point of decrement for X of the form [(x, i)] such that the set of
future obligations of (x, i) is a strict subset of X; and the automaton AX,x
checks condition C2(c) for X and a variable x ∈X. The automaton AX,x is
the complement of the B¨uchi automaton BX,x which accepts symbolic models in
which there is a point after which we never see an x-node reachable by a forward
path from a point of decrement for X. The automaton BX,x has states of the
form (fr, S) where fr is a frame and S is a subset of nodes in fr. We have a
transition from (fr, S) to (fr ′, S′) iﬀS′ is the set of nodes in fr ′ which are either
a point of decrement for X in fr ′ or are connected by a forward edge to a node
in S in fr ′. The automaton non-deterministically moves to a second copy where
it allows the above transitions only if S′ does not contain a node of the form
(x, i). All states in the second copy are ﬁnal.
We can easily check that all the properties of simple counter automata are
veriﬁed by this construction. For the ﬁnite case, Al
k is similar to A2 above, except
that a word is accepted when the run ends with all the counters equal to zero.
Lemma 5. Let ρ be a symbolic model of X-length l. Then ρ is accepted by Al
k
iﬀρ is satisﬁable.
We are now in position to state the main result of the paper.

A Decidable Temporal Logic of Repeating Values
191
Theorem 3. Finitary and inﬁnitary satisﬁability for CLTL♦is decidable.
Proof. Let φ be a CLTL♦formula over k variables with X-length l. Let Aφ be
the simple counter automaton built as the intersection of Asymb, Al
k and Alc
that accepts sequences in which consecutive frames are one-step consistent. We
can check whether the language accepted by Aφ is non-empty (Lemma 4). Thus,
by Theorem 2, checking the satisﬁability of φ is decidable.
According to the acceptance condition of Al
k in the ﬁnite case, ﬁnitary satis-
ﬁability reduces to the reachability problem in Petri nets.
⊓⊔
Theorems 2 and 3 entail that this decidability result can be extended to any
extension of LTL as soon as the temporal operators as deﬁnable in MSOL, see
for instance [GK03].
Corollary 1. Finitary and inﬁnitary satisﬁability for CLTL♦augmented with
MSOL deﬁnable temporal operators is decidable.
5.3
A PSPACE Fragment of CLTL♦
In this section, we consider the fragment CLTL♦
1 with a unique variable x. The
models are sequences of natural numbers and the only counter in counting se-
quences α is {x} (we identify α(i)({x}) with α(i)). Given a symbolic model ρ over
the alphabet Framel
1 and the counting sequence α along ρ, for every 0 ≤i < |ρ|,
α(i + 1) = α(i) ˙+ u+
i −u−
i+1 with u+
i , u−
i+1 ∈{0, 1}. By Lemma 3, when ρ is
satisﬁable, in the counting sequence along ρ either the unique counter remains
equal to zero after a ﬁnite number of steps or it is decremented inﬁnitely often.
Moreover, the value of the unique counter in the counting sequence is nicely
bounded unlike in general with strictly more than one variable.
Lemma 6. Let ρ be a symbolic model and α be the counting sequence along ρ.
For 0 ≤i < |ρ|, α(i) ≤l.
Boundedness entails the possibility to use automata without counters.
Lemma 7. The set of satisﬁable symbolic models over the alphabet Framel
1 can
be recognized by a standard B¨uchi automaton Al
1 for the inﬁnite case, or by a
ﬁnite-state automaton for the ﬁnite case.
The automaton Al
1 has an exponential size and can be built in polynomial space
in l. Checking nonemptiness for this automaton can be done in non deterministic
logarithmic space which allows to establish Theorem 4 below.
Theorem 4. Finitary and inﬁnitary satisﬁability for CLTL♦
1 is pspace-complete.
The models for CLTL♦
1 corresponds to models of LTL↓(∼, X, U). Therefore,
ﬁnitary and inﬁnitary satisﬁability for LTL↓
1(∼, X, X−1, U, S) restricted to for-
mulae such that the freeze operator is restricted to subformulae of the form
↓r=x XF(r = x) and ↓r=x Xi(r = x) is decidable in polynomial space (r is the
unique register and x the unique variable).

192
S. Demri, D. D’Souza, and R. Gascon
5.4
Repeating Values in the Past Is Still Decidable
In this section we explain why we can allow the constraints of the language to
state properties about past repetitions of a value without loosing decidability.
Let CLTL♦,♦−1 be the extension of CLTL♦with atomic formulae of the form
x = ♦−1y. The satisfaction relation is extended as follows: σ, i |= x = ♦−1y iﬀ
there is j > 0 s.t. x = σ(i −j)(y) and 0 ≤i −j. Similarly to what is done in
Section 2.1, x diﬀ♦−1y can be omitted since it can be deﬁned from x = ♦−1y
(a variant of the equivalence (1)).
In order to deal with satisﬁability for CLTL♦,♦−1 we need to extend the sym-
bolic representation of models. In addition of the conditions(F1)–(F5) deﬁned
in Sect. 3.1, a frame fr has to verify the following property (the ﬁnitary case
admits a similar update):
(F6) for all i, j ∈{0, . . ., l} and x, y ∈{x1, . . . xk}, if Xix = Xjy is in fr then
– if i = j, then for every z ∈{x1, . . . , xk} we have Xi(x = ♦−1z) ∈fr iﬀ
Xj(y = ♦−1z) ∈fr (we extend the notion of frames);
– if i > j then Xi(x = ♦−1y) ∈fr, and for every z ∈{x1, . . . , xk}, Xi(x =
♦−1z) ∈fr iﬀeither Xj(y = ♦−1z) ∈fr or there exists i > j′ ≥j such
that Xix = Xj′z is in fr.
We pose ♦−
fr(Xix)
def
= {y | Xi(x = ♦−y) ∈fr}. Since we need to deal with past
obligations, a counter is a pair ⟨Xp, Xf⟩in P+({x1, . . . , xk})×P+({x1, . . . , xk})
where Xp is for past obligations and Xf for future obligations. We update the
notion of counter valuations accordingly. A value n for ⟨Xp, Xf⟩is the number
of values that occurred in a past state of every variable of Xp and that have to
be repeated in a future state of every variable in Xf.
We extend some earlier deﬁnitions. For an l-frame fr and counter ⟨Xp, Xf⟩,
we deﬁne a point of increment for ⟨Xp, Xf⟩in fr to be an equivalence class of
the form [(x, 0)]fr such that ♦fr(x, 0) = Xf, (x, 0) is not connected by a forward
edge to a node in fr and [(x, 0)]fr ∪♦−1
fr (x, 0) = Xp. A point of decrement for
⟨Xp, Xf⟩in fr is deﬁned to be an equivalence class of the form [(x, l)]fr such that
♦fr(x, l) ∪[(x, l)]fr = Xf, (x, l) is not connected by a backward edge to another
node in fr and ♦−1(x, l) = Xp. Let u+
fr denote a counter valuation which records
the number of points of increment for each counter ⟨Xp, Xf⟩, in fr. Similarly let
u−
fr denote the counter valuation which records the number of points of decre-
ment for each counter ⟨Xp, Xf⟩in fr. We can now deﬁne a canonical counter
valuation sequence α along ρ, called the counting sequence along ρ, which counts
the number of “unsatisﬁed” points of increments for each counter ⟨Xp, Xf⟩with
Xp ̸= ∅. We deﬁne α inductively: α(0)(⟨Xp, Xf⟩) = 0 and for 0 ≤i < |ρ|,
α(i+1)(⟨Xp, Xf⟩) = α(i)(⟨Xp, Xf⟩)+(u+
ρ(i)(⟨Xp, Xf⟩)−u−
ρ(i+1)(⟨Xp, Xf⟩)). Note
that decrementations are this time compulsory and we allow α(i)(⟨Xp, Xf⟩) to be
negative (but not in the acceptance condition). Though we need more counters,
dealing with past repeating values, does not introduce real complications. This

A Decidable Temporal Logic of Repeating Values
193
is analogous to the passage from LTL to LTL with past-time operators since
past is ﬁnite and information about past can be accumulated smoothly.
Lemma 8. A symbolic model ρ for the logic CLTL♦,♦−1 is satisﬁable iﬀthe
counting sequence along ρ satisﬁes the conditions from Lemma 3 for the future
part of the counters and for 0 ≤i < |ρ|, α(i)(⟨Xp, Xf⟩) ≥0.
The proof is similar to the proof of Lemma 3. We just need more registers to
store the diﬀerent values that have to be repeated.
As a consequence, we can easily update the construction of Aφ in order to deal
with past repeating values. The deﬁnition of the automata Asymb and Al
k are
just extended by considering the new deﬁnition for frames. It is also important to
observe that the automaton Aφ obtained by synchronization of these automata
still belongs to the class of simple counter automata and the decidability result
also holds for CLTL♦,♦−1 satisﬁability problem.
Theorem 5. Finitary and inﬁnitary satisﬁability for CLTL♦,♦−1
[resp. CLTL♦,♦−1
1
] is decidable [resp. pspace-complete].
6
Concluding Remarks
We have shown that satisﬁability for CLTL♦with operators in {X, X−1, S, U}
is decidable by reduction into the veriﬁcation of fairness properties in Petri
nets [Jan90]. The proof is uniform for the ﬁnitary and inﬁnitary cases and
it can be extended to atomic constraints of the form x = ♦−1y and to any
set of MSOL deﬁnable temporal operators. Moreover, satisﬁability for CLTL♦
restricted to one variable is shown pspace-complete. Hence, we have deﬁned
and studied a well-designed decidable fragment of LTL with the freeze quan-
tiﬁer answering some question from [WZ00] and circumventing some undecid-
ability results from [DL06]. Finally, as done also in [DL06, Laz06, BMS+06],
we show relationships between fragments of LTL with freeze and counter
automata.
The main question left open by our work is the complexity of satisﬁability for
CLTL♦and more precisely we do not know whether CLTL♦satisﬁability has
elementary complexity. Similarly, are there natural fragments of CLTL♦that
are of lower complexity, for instance the one involved in Theorem 1? Another
promising extension consists in considering other concrete domains as ⟨R, <, =⟩
and to allow atomic formulae of the form x < ♦y. The decidability status of
such a variant is still open.
Acknowledgements. We are grateful to Petr Janˇcar (TU Ostrava) for pointing
us to [Jan90] in order to solve the nonemptiness problem for simple counter
automata and for suggesting the proof of Lemma 4 and Ranko Lazi´c (U. of
Warwick) for remarks about a preliminary version.

194
S. Demri, D. D’Souza, and R. Gascon
References
[ABM01]
C. Areces, P. Blackburn, and M. Marx. Hybrid logics: characterization,
interpolation and complexity. JSL, 66(3):977–1010, 2001.
[AH94]
R. Alur and Th. Henzinger. A really temporal logic. JACM, 41(1):181–204,
1994.
[BMS+06]
M. Boja´nczyk, A. Muscholl, Th. Schwentick, L. Segouﬁn, and C. David.
Two-variable logic on words with data. In LICS’06, pages 7–16. IEEE, 2006.
[DD07]
S. Demri and D. D’Souza. An automata-theoretic approach to constraint
LTL. I & C, 205(3):380–415, 2007.
[DDG07]
S. Demri, D. D’Souza, and R. Gascon.
A decidable temporal logic of
repeating values. Technical report, LSV, 2007.
[DL06]
S. Demri and R. Lazi´c. LTL with the freeze quantiﬁer and register au-
tomata. In LICS, pages 17–26. IEEE, 2006.
[DLN07]
S. Demri, R. Lazi´c, and D. Nowak. On the freeze quantiﬁer in constraint
LTL: decidability and complexity. I & C, 205(1):2–24, 2007.
[Esp94]
J. Esparza. On the decidability of model checking for several μ-calculi and
Petri nets. In CAAP’94, volume 787 of LNCS, pages 115–129. Springer,
1994.
[Fit02]
M. Fitting.
Modal logic between propositional and ﬁrst-order.
JLC,
12(6):1017–1026, 2002.
[GK03]
P. Gastin and D. Kuske.
Satisﬁability and model checking for MSO-
deﬁnable temporal logics are in PSPACE. In CONCUR’03, volume 2761
of LNCS, pages 222–236. Springer, 2003.
[Gor96]
V. Goranko.
Hierarchies of modal and temporal logics with references
pointers. Journal of Logic, Language, and Information, 5:1–24, 1996.
[Hen90]
Th. Henzinger. Half-order modal logic: how to prove real-time properties.
In PODC’90, pages 281–296. ACM, 1990.
[HR89]
R.R. Howell and L.E. Rosier. Problems concerning fairness and temporal
logic for conﬂict-free Petri nets. TCS, 64:305–329, 1989.
[Jan90]
P. Janˇcar. Decidability of a temporal logic problem for Petri nets. TCS,
74(1):71–93, 1990.
[KV06]
O. Kupferman and M. Vardi.
Memoryful Branching-Time Logic.
In
LICS’06, pages 265–274. IEEE, 2006.
[Laz06]
R. Lazi´c. Safely freezing LTL. In FST&TCS’06, volume 4337, pages 381–
392. LNCS, 2006.
[LMS02]
F. Laroussinie, N. Markey, and Ph. Schnoebelen.
Temporal logic with
forgettable past. In LICS’02, pages 383–392. IEEE, 2002.
[LP05]
A. Lisitsa and I. Potapov. Temporal logic with predicate λ-abstraction. In
TIME’05, pages 147–155. IEEE, 2005.
[Rab06]
A. Rabinovich. Decidability and expressive power of real time logics. In
FORMATS’06, volume 4202 of LNCS, page 32. Springer, 2006. Invited talk.
[Seg06]
L. Segouﬁn.
Automata and logics for words and trees over an inﬁnite
alphabet. In CSL’06, volume 4207 of LNCS, pages 41–57. Springer, 2006.
[tCF05]
B. ten Cate and M. Franceschet. On the complexity of hybrid logics with
binders. In CSL’05, volume 3634 of LNCS, pages 339–354. Springer, 2005.
[VW94]
M. Vardi and P. Wolper. Reasoning about inﬁnite computations. I & C,
115:1–37, 1994.
[WZ00]
F. Wolter and M. Zakharyaschev. Spatio-temporal representation and rea-
soning based on RCC-8. In KR’00, pages 3–14. Morgan Kaufmann, 2000.

Model Checking Knowledge and Linear Time:
PSPACE Cases
Kai Engelhardt⋆, Peter Gammie, and Ron van der Meyden⋆
School of Computer Science and Engineering, The University of New South Wales,
and National ICT Australia⋆⋆, Sydney, NSW 2052, Australia
{kaie|peteg|meyden}@cse.unsw.edu.au
Abstract. We present a general algorithm scheme for model checking
logics of knowledge, common knowledge and linear time, based on bisim-
ulations to a class of structures that capture the way that agents update
their knowledge. We show that the scheme leads to PSPACE implemen-
tations of model checking the logic of knowledge and linear time in sev-
eral special cases: perfect recall systems with a single agent or in which
all communication is by synchronous broadcast, and systems in which
knowledge is interpreted using either the agents’ current observation only
or its current observation and clock value. In all these results, common
knowledge operators may be included in the language. Matching lower
bounds are provided, and it is shown that although the complexity bound
matches the PSPACE complexity of the linear time temporal logic LTL,
as a function of the model size the problems considered have a higher
complexity than LTL.
1
Introduction
The logic of knowledge [5] has been proposed as a formalism to express informa-
tion theoretic properties in distributed and multi-agent systems, and has been
shown to be useful for the analysis of distributed systems protocols [9], informa-
tion ﬂow security properties [10, 20, 24], as well as for problems such as diagnosis
and recoverability [3, 4].
The semantics for knowledge operators can be deﬁned in a variety of ways,
depending on what information agents use when computing what they know. At
one extreme (the “observational semantics”) agents rely only on their current
observation, at the other (the “synchronous perfect recall semantics”) agents
rely on the log of all their past observations. In between lies a “clock seman-
tics” in which agents rely on their current observation plus a clock value. These
semantics have diﬀerent motivations: the perfect recall semantics is most appro-
priate for security analyses and derivation of protocols that make optimal use of
information; the other semantics are closer to system implementations.
⋆Work was partially supported by ARC Discovery Grant RM02036.
⋆⋆National ICT Australia is funded through the Australian Government’s Backing
Australia’s Ability initiative, in part through the Australian Research Council. The
third author thanks the Courant Institute, New York University for their hospitality
in hosting a sabbatical visit during which this work was conducted.
S. Artemov and A. Nerode (Eds.): LFCS 2007, LNCS 4514, pp. 195–211, 2007.
c
⃝Springer-Verlag Berlin Heidelberg 2007

196
K. Engelhardt, P. Gammie, and R. van der Meyden
A number of model checkers for the logic of knowledge have been recently de-
veloped, which embody diﬀerent choices of semantics for the knowledge operators
and diﬀerent types of expressiveness for the temporal dynamics. MCMAS [13]
deals with the observational interpretation of knowledge and the branching time
logic CTL. DEMO [27] deals with the dynamic logic based “update logic” [1],
which handles what is in eﬀect the perfect recall semantics for knowledge. The
system MCK [7] covers a broad spectrum of deﬁnitions of knowledge (obser-
vational, clock, perfect recall), as well as dealing with both linear time and
branching time temporal logic.
Where they deal with the perfect recall semantics for knowledge, these systems
place severe constraints on the interaction between knowledge and temporal
operators, for reasons of inherent complexity. The complexity of model checking
the combination of the linear time temporal logic LTL with knowledge operators
interpreted according to the perfect recall semantics has been studied by van der
Meyden and Shilov [23], who show that this problem is decidable but with a non-
elementary lower bound, and undecidable when operators for common knowledge
(a type of ﬁxpoint over knowledge operators) are added to the language. (Shilov
et al [16, 17, 8] have also studied branching time versions of these results.)
However, as we show in this paper, this general result does not preclude the
existence of special cases in which this model checking problem has lower com-
plexity, even when common knowledge operators are included in the language.
We identify a number of cases where the problem (including common knowledge)
is solvable in PSPACE. These include systems with a single agent (discussed in
Section 5.1) and systems in which all communication is by synchronous broad-
cast (treated in Section 5.2). The result concerning a single agent improves the
nonelementary upper bound for the single agent case obtained from the algo-
rithm of van der Meyden and Shilov.
Our approach to the proof of these results is by means of a general algorithm
scheme (presented in Section 4) that relies upon the existence of a bisimulation
from the (in eﬀect, inﬁnite) systems being checked to a ﬁnite structure that rep-
resents the way that agents update their knowledge in the system. In addition
to the results about the perfect recall semantics, we show that this scheme can
be used to obtain PSPACE complexity results for model checking the logic of
knowledge and linear time for other interpretations for knowledge: in particu-
lar, we show that this complexity bound applies in the case of both the clock
semantics and the observational semantics (see Section 6).
As the complexity of model checking the linear time temporal logic LTL alone
is already PSPACE-complete, it may seem from these results that the extra
expressiveness of the logic of knowledge in these cases comes at no extra cost.
In fact, we show that there is a sense in which these model checking problems
are harder than model checking LTL alone, by focussing on the complexity of
model checking a ﬁxed formula as a function of the size of the model. For LTL,
this “model complexity” is linear-time for each formula [11]. We show that the
model complexity can be as high as PSPACE-complete once the formula includes
knowledge operators.

Model Checking Knowledge and Linear Time: PSPACE Cases
197
2
Basic Deﬁnitions
In this section we deﬁne the semantic framework with respect to which we study
the model checking problem. The deﬁnitions closely follow [23], which dealt
with model checking knowledge and linear time in multi-agent systems for a
“perfect recall” interpretation of knowledge. We also deﬁne an alternate “clock”
interpretation of knowledge, in which agents reason on the basis of their current
observation and knowledge of the time.
Let Prop be a set of atomic propositional constants, n > 0 be a natural
number, and let A = {1, . . . , n} be a set of agents. We will be concerned with
model checking a propositional multi-modal language for knowledge and linear
time based on the set Prop of atomic propositional constants, with formulae
generated by the modalities
 (next), U (until), a knowledge operator Ki for
each agent i ∈A, and a common knowledge operator CG for each group of
agents G ⊆A. Formulae of the language are deﬁned as follows: each atomic
propositional constant p ∈Prop is a formula, and if ϕ and ψ are formulae,
then so are ¬ϕ, ϕ ∧ψ,
  ϕ, ϕ U ψ, Kiϕ and CGϕ for each i ∈A and group
G ⊆A. We write L{  , U,K1,...,Kn,C} for the set of formulae. We will refer to
sublanguages of this language by a similar expression that lists the operators
generating the language. For example, L{  , U,K} refers to the sublanguage with
just a single agent (in which case we may drop the subscript on the knowledge
operator). As usual in temporal logic, we use the abbreviations
 ϕ for trueU ϕ,
and
 ϕ for ¬ ¬ϕ. The knowledge depth of a formula ϕ, denoted depth(ϕ), is
deﬁned to be the maximal depth of nesting of K operators in ϕ. For example,
depth(K(p ∧¬Kq)) = 2.
The semantics of this language is deﬁned with respect to the following class
of structures. Deﬁne an interpreted environment (for A) to be a tuple E of the
form (S, I, →, (Oi)i∈A, π, α) where the components are as follows:
1. S is a set of states of the environment,
2. I is a subset of S, representing the possible initial states,
3. →⊆S2 is a transition relation,
4. for each i ∈A the component Oi : S −→O, where O is a set of uninterpreted
observations, is called the observation function of agent i,
5. π : S −→P(Prop) is an interpretation,
6. α ⊆S is an acceptance condition.
Intuitively, an environment is a transition system where states encode values of
local variables, messages in transit, failure of components, etc. For states s, s′
the relation s →s′ means that if the system is in state s, then at the next tick of
the clock it could be in state s′. We call E ﬁnite whenever S is. If s is a state and
i an agent then Oi(s) represents the observation agent i makes when the system
is in state s, i.e., the information about the state that is accessible to the agent.
The interpretation π maps a state s to the set of propositional constants in Prop
that hold at s. The acceptance conditions are essentially B¨uchi conditions which
model fairness requirements on evolutions of the environment.

198
K. Engelhardt, P. Gammie, and R. van der Meyden
A path p of E from a state s in S is a ﬁnite or inﬁnite sequence of states
s0s1 . . . such that s0 = s and sj →sj+1 for all j. We write p(m) for sm when m
is an index of p. A path p is said to be initialized if p(0) ∈I. We call an initialized
ﬁnite path a trace. A path p is fair if it is inﬁnite and p(i) ∈α for inﬁnitely many
i. Note that we do not assume that S is ﬁnite, but when so, this formulation
is equivalent to the usual formulation of acceptance for B¨uchi automata: some
s ∈α occurs inﬁnitely often. We say that the acceptance condition of E is trivial
if α = S. We assume that environments satisfy the following well-formedness
condition: for every state s, there exists a fair path with initial state s. A run of
E is a fair, initialized path, and we write r[0..m] for the trace that is the preﬁx
of run r up to time m. Let runs(E) be the set of all runs of E. A point of E is a
pair (r, m), where r is a run of E and m a natural number. Intuitively, a point
identiﬁes a particular moment in time along the history described by the run.
Individual runs of an environment provide suﬃcient structure for the inter-
pretation of formulae of linear temporal logic. To interpret formulae involving
knowledge, we use the agents’ observations to determine the points they consider
possible. There are many ways one could do this. The particular approaches used
in this paper model a synchronous perfect-recall, an observational, and a clock
semantics of knowledge, each deﬁned using a notion of local state. We deﬁne
the synchronous perfect recall local state of agent i at a point (r, m) to be the
sequence1 {(r, m)}pr
i = Oi(r[0..m]). That is, the synchronous perfect recall local
state of an agent at a point in a run consists of a complete record of the ob-
servations the agent has made up to that point. The clock local state of agent
i at a point (r, m) is deﬁned by {(r, m)}clk
i
= (m, Oi(r(m))). That is, in this
deﬁnition, the agent’s local state is taken to be the current time, together with
the agent’s current observation. Finally, the observational local state of agent i
at a point (r, m) is {(r, m)}obs
i
= Oi(r(m)). Eﬀectively, an agent with this view
of the world considers any reachable state giving the same observation to be
possible. To distinguish these local state assignments, we deﬁne a view v to be
one of the three possibilities pr, clk, and obs.
Given a view v, the corresponding local state assignment may be used to deﬁne
for each agent i a relation
v∼i of indistinguishability on points (r, m), (r′, m′) of E,
by (r, m)
v∼i (r′, m′) if {(r, m)}v
i = {(r′, m′)}v
i . Intuitively, when (r, m)
v∼i (r′, m′),
agent i’s local state according to the view v does not contain enough information
for the agent to determine whether it is at one point or the other. Clearly, each
v∼i
is an equivalence relation. Both the synchronous perfect recall view and the clock
view are “synchronous” in the sense that if (r, m)
v∼i (r′, m′), then we must have
m = m′. Intuitively, this means that the agent “knows the time”. The relations
v∼i will be used to deﬁne the semantics of knowledge for individual agents. By
P v
i (E, r, m) we denote the set { r′(m′) | r′ ∈runs(E), m′ ∈N, (r′, m′)
v∼i (r, m)}
of possible states for agent i at point (r, m).
To interpret the common knowledge operators, we use another relation. If
G ⊆A is a group of agents (i.e., two or more) then we deﬁne the relation
v∼G on
1 We adopt the convention that functions lift to sequences and sets in a pointwise
fashion.

Model Checking Knowledge and Linear Time: PSPACE Cases
199
points to be the reﬂexive transitive closure of the union of all indistinguishability
relations
v∼i for i ∈G, i.e.,
v∼G = (
i∈G
v∼i)∗.
The semantics of this language is deﬁned as follows. Suppose we are given an
environment E with interpretation π. We deﬁne satisfaction of a formula ϕ at
a point (r, m) of a run of E with respect to a view v, denoted E, (r, m) |=v ϕ,
inductively on the structure of ϕ. The cases for the temporal fragment of the
language are standard, and independent of v:
E, (r, m) |=v p
if p ∈π(r(m)), where p ∈Prop,
E, (r, m) |=v ϕ1 ∧ϕ2
if E, (r, m) |=v ϕ1 and E, (r, m) |=v ϕ2,
E, (r, m) |=v ¬ϕ
if not E, (r, m) |=v ϕ,
E, (r, m) |=v
  ϕ
if E, (r, m + 1) |=v ϕ,
E, (r, m) |=v ϕ1 U ϕ2
if there exists m′′ ≥m such that E, (r, m′′) |=v ϕ2
and E, (r, m′) |=v ϕ1 for all m′ with m ≤m′ < m′′.
The semantics of the knowledge and common knowledge operators is deﬁned by:
E, (r, m) |=v Kiϕ
if E, (r′, m′) |=v ϕ for all points (r′, m′) of E
satisfying (r′, m′)
v∼i (r, m)
E, (r, m) |=v CGϕ
if E, (r′, m′) |=v ϕ for all points (r′, m′) of E
satisfying (r′, m′)
v∼G (r, m)
These deﬁnitions can be viewed as an instance of the “interpreted systems”
framework for the semantics of the logic of knowledge proposed in [9]. Intuitively,
an agent knows a formula to be true if this formula holds at all points that the
agent is unable to distinguish from the actual point. Common knowledge may
be understood as follows. For G a group of agents, deﬁne the operator EG,
read “everyone in G knows” by EGϕ ≡
i∈G Kiϕ. Then CGϕ is equivalent to
the inﬁnite conjunction of the formulae Ek
Gϕ for k ≥1. That is, ϕ is common
knowledge if everyone knows ϕ, everyone knows that everyone knows ϕ, etc. We
refer the reader to [5] for further motivation and background.
3
Main Results
We may now deﬁne the model checking problem we consider in this paper and
state our main results.
Say that formula ϕ is realized in the environment E with respect to a view v,
denoted E |=v ϕ, if, for all runs r of E, we have E, (r, 0) |=v ϕ. Our interest is
in the following problem, which we call the realization problem with respect to a
view v: given an an environment E and a formula ϕ of a language L, determine
if ϕ is realized in E with respect to v.
The realization problem for the logic of knowledge and linear time has been
studied by van der Meyden and Shilov [23], who show that for the perfect recall
view, the problem is undecidable for the language L{  , U,K1,...,Kn,C} when n ≥2,
and decidable for the language L{  , U,K1,...,Kn}, but with nonelementary com-
plexity. More speciﬁcally, for L{  , U,K1,...,Kn} their approach runs in space poly-
nomial in f(depth(ϕ), O(|E|)), where the function f is deﬁned by f(0, m) = m

200
K. Engelhardt, P. Gammie, and R. van der Meyden
and f(k+1, m) = 2f(k,m). It is also shown by van der Meyden and Shilov that there
is a similar lower bound on the complexity when there is more than one agent.
Our main contribution in this paper is to develop a general algorithm scheme
for model checking the logic of knowledge and time based on a notion of
bisimulation of environments, and to show that this scheme yields improved
complexity bounds in a number of special cases. The scheme itself is presented
in Section 4, and parameterizes a procedure for model checking with respect to
the observational view. In particular, this procedure yields the following result
for the observational view.2
Theorem 1. The problem of determining if a given formula in the language
L{  , U,K1,...,Kn,C} is realized in a given environment E with respect to the obser-
vational view is decidable in PSPACE.
By showing the existence of bisimulation from an enviroment representing the
perfect recall semantics for a single agent to a suitable ﬁnite environment, we
obtain the following result:
Theorem 2. The problem of determining if a given formula in L{  , U,K} is
realized in a given environment E with respect to the perfect recall view is in
PSPACE.
This shows that the complexity of the realization problem for formulae with
a single agent with perfect recall is strictly lower than the general case, and
signiﬁcantly improves upon the complexity bound of van der Meyden and Shilov
in this case.
By ﬁnding other suitable structures we may derive complexity bounds on sev-
eral other cases of the realization problem, as stated in the following results.
First, although with respect to the perfect recall view, the realization problem
is non-elementary for L{  , U,K1,...,Kn}, there exist classes of environments with
respect to which the problem has lower complexity, even if we add the common
knowledge operators. In particular, this holds for broadcast environments [21].
Intuitively, these are environments in which the only communication mechanism
available to agents is to broadcast to all agents in the system. The formal def-
inition will be given in section 5.2. For broadcast environments we show the
following.
Theorem 3. The problem of determining if a given formula in the language
L{  , U,K1,...,Kn,C} is realized in a given broadcast environment E with respect to
the perfect recall view is decidable in PSPACE.
Realization for the clock view may also handled using the bisimulation technique
and again the common knowledge operator may be included in the language.
2 This result does not appear to have been previously stated in the literature, but we
note that results of Vardi [28] on the problem of verifying that a concrete protocol
implements a knowledge-based program are very closely related. Lomuscio and Rai-
mondi have studied the complexity of model checking the combination of the logic
of knowledge with the braching time logic CTL with respect to the observational
semantics [12].

Model Checking Knowledge and Linear Time: PSPACE Cases
201
Theorem 4. The problem of determining if a given formula in the language
L{  , U,K1,...,Kn,C} is realized in a given environment E with respect to the clock
view is decidable in PSPACE.
Note that the complexity of model checking linear time temporal logic (i.e. re-
alization for the language L{  , U}) is PSPACE-complete [18]. Since L{  , U} is a
sublanguage of the languages in the above results, these results show that the
above bounds are tight, in the sense that the problems are in fact PSPACE-
complete.
That some of our complexity bounds are no more than the PSPACE com-
plexity of the linear time temporal logic LTL may at ﬁrst suggest that model
checking these cases of the logic and knowledge and time could be as eﬀective in
practice as model checking LTL. However, a closer inspection indicates that it is
not obvious that this will be case. The time complexity of LTL model checking a
ﬁxed formula is linear in the size of the model. The time complexity is exponen-
tial in the size of the formula. This exponential bound is not an impediment in
practice since the formulas of interest tend to be small. The models, on the other
hand, may be very large. We show that as a function of model size, the complex-
ity of model checking ﬁxed formulas of the logic of knowledge and time falling
within our PSPACE cases can be be as high as PSPACE-hard (for L{  , U,K}
with respect to perfect recall) and at any level of the polynomial hierarchy for
the clock view.3
Theorem 5. There exists a formula ϕ of L{  , U,K} such that the problem of
deciding if ϕ is realized in a given environment E with respect to the perfect
recall view is PSPACE-hard.
In the case of the clock semantics, we may obtain the following lower bound.
Theorem 6. For each level Πp
k of the polynomial hierarchy, there exists a for-
mula ϕ of L{  , U,K1,...,Kn} such that the problem of deciding, given an environ-
ment E, whether E |=clk ϕ, is Πp
k-hard.
The proof involves a reduction from Πk formulas of quantiﬁed boolean logic.
Note that this implies PSPACE-hardness of the version of the problem in which
the formula is given.
4
An Algorithm Scheme
We approach the model checking problem in three stages. First, given a ﬁnite
environment E and a view v, we construct an inﬁnite environment Ev that
reduces the model checking problem with respect to v in E to one of model
checking Ev with respect to obs. Second, we introduce bisimulations between
environments, which, together with the previous step, may enable the problem
of model checking E with respect to v to be reduced to model checking with
3 For reasons of space we refer the reader to a longer version of the paper available at
http//www.cse.unsw.edu.au/∼meyden for proofs.

202
K. Engelhardt, P. Gammie, and R. van der Meyden
respect to obs in ﬁnite state environment E′ (which is of exponential size in
our applications). Finally, we combine alternating Turing machine techniques
with standard B¨uchi automata techniques to obtain the general model checking
procedure (which runs in PSPACE in our applications).
Let E = (S, I, →, (Oi)i∈A, π, α) be a ﬁnite environment and let v be a view.
Deﬁne Ev, the v-environment for E, to be (Sv, Iv, →v, (Ov
i )i∈A, πv, αv) where:
– Sv = runs(E) × N,
– Iv = runs(E) × {0},
– (r, m) →v (r′, m′) if r′ = r and m′ = m + 1,
– Ov
i (r, m) = {(r, m)}v
i ,
– πv(r, m) = π(r(m)), and
– (r, m) ∈αv iﬀr(m) ∈α.
The following lemma states that the observational view on this (inﬁnite) en-
vironment coincides with the view v on the original (ﬁnite) environment. Given
a run r of E, write rv for the run of Ev deﬁned by rv(n) = (r, n) for all n ∈N.
Lemma 7. Let ϕ ∈L{  , U,K1,...,Kn,C} and let (r, m) be a point of E. Then
E, (r, m) |=v ϕ iﬀEv, (rv, m) |=obs ϕ.
Since every run of Ev has the form rv for some run of E, it follows that E |=v ϕ
iﬀEv |=obs ϕ.
Let fpaths(E) be the set of all fair paths of E. For ρ ∈fpaths(E) and m ∈N
let ρ|m be the fair path with ρ|m(j) = ρ(m + j), for j ∈N.
Observe that the semantics of E, (r, n) |=v ϕ refers only to the future of
the points considered in unfolding the deﬁnition. To formalise this, consider
the following alternate deﬁnition of a relation E, ρ |=∗ϕ, deﬁned for all ρ ∈
fpaths(E), not just the initialized ones:
E, ρ |=∗p
if p ∈π(ρ(0)), where p ∈Prop,
E, ρ |=∗ϕ1 ∧ϕ2
if E, ρ |=∗ϕ1 and E, ρ |=∗ϕ2,
E, ρ |=∗¬ϕ
if not E, ρ |=∗ϕ,
E, ρ |=∗
  ϕ
if E, ρ|1 |=∗ϕ,
E, ρ |=∗ϕ1 U ϕ2
if there exists m′′ ≥0 such that E, ρ|m′′ |=∗ϕ2
and E, ρ|m′ |=∗ϕ1 for all m′ with 0 ≤m′ < m′′.
E, ρ |=∗Kiϕ
if E, ρ′ |=∗ϕ for all ρ′ ∈fpaths(E) with Oi(ρ′(0)) = Oi(ρ(0))
E, ρ |=∗CGϕ
if for all sequences of states s0, s1, . . . , sk such that
(i) s0 = ρ(0), (ii) for all j < k there exists an i ∈G
such that Oi(sj) = Oi(sj+1), and (iii) for all
ρ′ ∈fpaths(E) with ρ′(0) = sk, we have E, ρ′ |=∗ϕ.
We write E |=∗ϕ if E, r |=∗ϕ for all runs r of E.
For an environment E, deﬁne a state to be reachable if it occurs in some run
of E. Say that observations in E preserve reachability if for all states s, t of E
and all agents i, if s is reachable and Oi(s) = Oi(t) then t is reachable.4
4 We remark that it is always possible to ensure this by deleting the unreachable states
from E, an operation that preserves satisfaction of formulas. However, this operation
is undesirable in our applications since we will deal with exponential size structures,
in which observations already preserve reachability.

Model Checking Knowledge and Linear Time: PSPACE Cases
203
Lemma 8. If observations in E preserve reachability then E, (r, m) |=obs ϕ iﬀ
E, r|m |=∗ϕ.
Next, we introduce a notion of bisimulation on environments (cf. [14]) in order
to reduce the inﬁnite state space of Ev to a ﬁnite one while preserving validity
of formulae with respect to obs. For environments E = (S, I, →, (Oi)i∈A, π, α)
and E′ = (S′, I′, →′, (O′
i)i∈A, π′, α′), a function σ : S −→S′ is said to be a
bisimulation from E to E′ if the following hold:
1. I′ = σ(I),
2. if s →s′ then σ(s) →′ σ(s′),
3. if σ(s) →′ u then there exists s′ ∈S such that σ(s′) = u and s →s′,
4. if Oi(s) = Oi(t) then O′
i(σ(s)) = O′
i(σ(t)),
5. if O′
i(σ(s)) = O′
i(u) then there exists a state t ∈S such that Oi(s) = Oi(t)
and σ(t) = u.
6. π′ ◦σ = π, and
7. σ(s) ∈α′ iﬀs ∈α.
Lemma 9. Suppose that σ is a bisimulation from E to E′. Then
1. for all (initialised) ρ ∈fpaths(E), σ(ρ) is a (initialised) fair path of E′;
2. for all ρ′ ∈fpaths(E′) and (initial) states s of E, if σ(s) = ρ′(0), then there
exists a (initialised) ρ ∈fpaths(E) with ρ(0) = s such that σ(ρ) = ρ′;
3. for all ρ ∈fpaths(E) we have E, ρ |=∗ϕ iﬀE′, σ(ρ) |=∗ϕ.
Noting that all states of Ev are reachable, we obtain the following:
Corollary 10. For all environments E and E′, if there exists a bisimulation
from Ev to E′, then E |=v ϕ iﬀE′ |=∗ϕ.
This result provides the basic reduction that we use to obtain our complexity
results. We now show that the relation E′ |=∗ϕ is decidable for ﬁnite environ-
ments E′. However, we will need to deal with the fact that the structure E′
will be of size exponential in the size of E in our applications. For this reason,
we express our decision procedure for |=∗as an alternating computation [2], in
which we guess and verify the components of E′.
We begin with a reduction to well-known techniques for LTL. Say that a formula
is a pure knowledge formula if it is of the one of the forms Kiψ or CGψ, or their
negation. Note that for formulas ϕ that are either atomic propositions or their
negation, or pure knowledge formulas, we have that if ρ(0) = ρ′(0), then E, ρ |=∗ϕ
iﬀE, ρ′ |=∗ϕ. Thus, for such formulas ϕ, we may deﬁne E, s |=∗ϕ, where s is a
state of E, to hold if E, ρ |=∗ϕ for some (equivalently, every) path ρ with ρ(0) = s.
We may use this state-dependence property to transform the L{  , U,K1,...,Kn,C}
model checking problem with respect to |=∗into a problem of model checking
L{  , U}, by replacing the pure knowledge subformulas by atomic propositions.
Introduce a new atomic proposition qKiψ for each formula Kiψ and qCGψ for
each formula CGψ. Let L∗
{  , U} be the language of temporal logic over the set
of atomic propositions Prop together with these new atomic propositions. Given

204
K. Engelhardt, P. Gammie, and R. van der Meyden
a formula ϕ of L{  , U,K1,...,Kn,C} and an occurrence of a pure knowledge for-
mula as a subformula of ϕ, say this occurrence is maximal if it does not lie
within the scope of a knowledge or common knowledge operator. For example,
in (K2
  K1p)∨K1p, the maximal occurrences of knowledge subformulas are the
occurrence of K2
  K1p and the second (but not the ﬁrst) occurrence of K1p.
Deﬁne ϕ∗to be the formula of L∗
{  , U} obtained by replacing each maximal oc-
currence of a knowledge formula Kiψ by the proposition qKiψ and similarly for
the maximal occurrences of CGψ.
More precisely,
p∗= p
(ϕ1 ∧ϕ2)∗= ϕ1∗∧ϕ2∗
(¬ϕ)∗= ¬(ϕ∗)
(  ϕ)∗=
  (ϕ∗)
(ϕ1 U ϕ2)∗= ϕ1
∗U ϕ2
∗
Kiϕ∗= qKiψ
CGϕ∗= qCGψ
Thus, ((K2
  K1p)∨K1p)∗= qK2
  K1p ∨qK1p. Write Propϕ∗for the set of atomic
propositions occuring in ϕ∗and KPropϕ∗for the set of atomic propositions of
the form qKiψ and qCGψ that occur in ϕ∗.
Suppose we enrich the structure E by extending the valuation π so that qKiψ ∈
π(s) iﬀE, s |=∗Kiψ and qCGψ ∈π(s) iﬀE, s |=∗CGψ. Call the resulting
structure E∗. Then we have E, ρ |=∗ϕ iﬀE∗, ρ |= ϕ∗. This turns the problem
of model checking L{  , U,K1,...,Kn,C} in E into the problem of model checking
L∗
{  , U} in E∗. Of course, to apply this technique, we need to have the appropriate
extension E∗of E. We may deal with this in an NPSPACE computation by
guessing the extension E∗, iteratively verifying its correctness over larger and
larger pure knowledge subformulas of ϕ (using LTL model checking techniques),
and then model checking the formula ϕ∗. Since NPSPACE = PSPACE, this
already yields a proof of Theorem 1.5
However, in our applications, we will not be interested in a given structure
E, but in a structure E′ of size exponential in the size of E. This means that
the cost of guessing (E′)∗is exponential. We will handle this by guessing the
extension not upfront, but on the ﬂy, for each state of E′ as it arises during
the veriﬁcation, and using an APTIME computation that incorporates a B¨uchi
automaton emptiness check for the LTL parts of the veriﬁcation.
Let Mϕ∗be the nondeterministic B¨uchi automaton for the L∗
{  , U} formula
ϕ∗over propositions Propϕ∗, with states Sϕ∗, initial states Iϕ∗, transitions ⇒a
(where a ∈P(Propϕ∗)) and acceptance condition αϕ∗. We make use of the
following properties of this automaton [29]: (1) The automaton is of size O(2|ϕ∗|),
where each state is of size O(|ϕ|). (2) Deciding Sϕ∗, Iϕ∗, ⇒a, and αϕ∗can be
done in ATIME(log2 |ϕ|).
For a ﬁnite environment E = (S, I, →, (Oi)i∈A, π, α), we deﬁne the product
E × Mϕ∗(a transition system with B¨uchi acceptance condition) as follows.
– The transition system has states ⟨b, s, v⟩, where b ∈P({0, 1}), s ∈S and
v ∈Sϕ∗. Intuitively, 0 ∈b (1 ∈b) represents that E (resp., Mϕ∗), has
passed through an accepting state since the most recent accepting state of
the product.
5 The guess and verify technique discussed here is essentially that used in Vardi’s
results on verifying implementations of knowledge-based programs [28].

Model Checking Knowledge and Linear Time: PSPACE Cases
205
– The set of initial states consists of all ⟨∅, s, v⟩where s ∈I and v ∈Iϕ∗.
– There is a transition ⟨b, s, v⟩⇒k ⟨b′, s′, v′⟩for a set k ⊆KPropϕ∗when:
• s →s′,
• v ⇒π(s)∪k v′, and
• b′ = b0 ∪b1 ∪b2, where if b = {0, 1} then b0 = ∅, else b0 = b; if s ∈α
then b1 = {0}, else b1 = ∅; and if v ∈αϕ∗then b2 = {1}, else b2 = ∅;
– the automaton has as accepting states the states ⟨b, s, v⟩with b = {0, 1}.
Intuitively, this transition system represents running Mϕ∗as a monitor on runs
of E, with the values of the propositions KPropϕ∗chosen arbitrarily. Thus,
there exists a fair path ρ = s0s1 . . . of E such that E, ρ |=∗ϕ iﬀthere exists an
accepting run ⟨b0, s0, v0⟩⇒k0 ⟨b1, s1, v1⟩⇒k1 ⟨b2, s2, v2⟩⇒k2 . . . of E × M¬ϕ∗
such that for all j ≥0, we have E, sj |=∗kj. Applying the usual emptiness check
for B¨uchi automata, such a path exists iﬀwe can ﬁnd a ﬁnite such sequence with
⟨bl, sl, vl⟩an accepting state and ﬁnal element ⟨bl′, sl′, vl′⟩= ⟨bl, sl, vl⟩for some
l′ > l, where both l and l′ −l are at most |E × Mϕ∗|. Our decision procedure
searches for such paths using a Savitch-style reachability procedure [15] in order
to deal with the exponential size of the search-space.
For the veriﬁcation that E, s |=∗k, it suﬃces to check, for each maximal
knowledge subformula Kiψ of ϕ, that qKiψ ∈k iﬀOi(s) = Oi(t) implies that for
all fair paths ρ = t0t1 . . . with t0 = t, we have E, ρ |= ψ∗. For this, we recursively
apply the above ideas on E × M¬ψ∗. Since ψ is a strict subformula of ϕ, the
recursion is well founded. A similar check is applied for the common knowledge
subformulas.
We are now ready to present our general algorithm scheme as an alternating
computation [2]. Suppose that we are given a ﬁnite environment E, for which
it is known that there exists a bisimulation from Ev to a ﬁnite environment
E′ = (S′, I′, →′, (O′
i)i∈A, π′, α′). We assume that there is a representation of E′
such that the states and other components of E′ can be represented and veriﬁed
within known space and alternating time complexity bounds. (That is, given E,
the states of E′ are representable as strings of length bounded by some known
function of |E|, in such a way that we can decide whether such a string repre-
sents a state of E′, whether s →′ s′ etc. with some known complexity bounds.)
We deﬁne the following alternating procedure that searches for such runs by
operating over the states ⟨b, s, v⟩of the automata E′ × Mψ∗for subformulas ψ
of ϕ and their negations. For clarity, we write expressions referring to the com-
ponents of E′ (such as “choose s ∈I′ and do X”) which need to be expanded to
expressions (“choose s and universally (1) verify s ∈I′ and (2) do X”) that use
the veriﬁcation routines assumed to exist.
VERIFY(E, ϕ): Universally choose s ∈I′ and call ¬FALSIFY(E, s, ϕ)
FALSIFY(E, s, ψ): Existentially choose k ⊆KPropψ∗, an initial state v of M¬ψ∗,
an accepting state ⟨b0, s0, v0⟩and a state ⟨b1, s1, v1⟩of E′ ×M¬ψ∗such that
(b0, s0, v0) ⇒k (b1, s1, v1).
Let N = ⌈log2 |states(E′ × M¬ψ∗)|⌉.

206
K. Engelhardt, P. Gammie, and R. van der Meyden
Universally call:
– REACH(E, (∅, s, v), (b0, s0, v0), N, ¬ψ),
– CHECK(E, s0, k, ψ), and
– REACH(E, (b1, s1, v1), (b0, s0, v0), N, ¬ψ)
CHECK(E, s, k, ψ): Universally,
– for each pKiψ′ in KPropψ∗,
if pKiψ′ ∈k then call KCHECK(E, s, Kiψ′) else call ¬KCHECK(E, s, Kiψ′)
– for each pCGψ′ in KPropψ∗,
if pCGψ′ ∈k then call CKCHECK(E, s, CGψ′) else call ¬CKCHECK(E, s, CGψ′)
KCHECK(E, s, Kiψ): Universally, for each s′ ∈S′ where O′
i(s) = O′
i(s′), call
¬FALSIFY(E, s′, ψ)
CKCHECK(E, s, CGψ): Universally, for each s′ ∈S′: (1) verify6 there is a sequence
s = s0, . . . , sk = s′ with k ≤|S′| and for each j < k there is an i ∈G such
that O′
i(sj) = O′
i(sj+1). (2) call ¬FALSIFY(E, s′, ψ)
REACH(E, (b0, s0, v0), (b1, s1, v1), N, ψ): Accept if (b0, s0, v0) = (b1, s1, v1).
Otherwise if N = 0, existentially guess k ⊆KPropψ∗then
– universally verify that (b0, s0, v0) ⇒k (b1, s1, v1) and CHECK(E, s0, k, ψ).
If N > 0, existentially guess a state (b2, s2, v2) of E ×Mψ∗, then universally
call:
– REACH(E, (b0, s0, v0), (b2, s2, v2), N −1, ψ) and
– REACH(E, (b2, s2, v2), (b1, s1, v1), N −1, ψ).
An analysis of the complexity of the algorithm scheme yields the following.
Theorem 11. Let v be a view. Suppose that C is a class of environments such
that for each environment E ∈C there exists an environment E′ with states
that can be represented in space f(|E|) and components that can be veriﬁed
in ATIME(g(|E|)), such that there is a bisimulation σ from Ev to E′. Then

(E, ϕ) ∈C × L{  , U,K1,...,Kn,C} | E |=v ϕ

is in ATIME(p(f(|E|), g(|E|), |ϕ|))
for some polynomial p.
We remark that since the procedure REACH has an alternation before the recursive
call, the number of alternations is also polynomial in |E|. Theorem 5 can be
understood as asserting that this is inherently so.
In the following sections, we apply Theorem 11 to obtain complexity bounds
for model checking the logic of knowledge and linear time in a number of cases.
In each case, we identify an appropriate environment E′ where the states can be
represented and veriﬁed in polynomial space and time, respectively, hence the
complexity of the alternating procedure is APTIME. By [2], this is equivalent
to PSPACE. The environments E′ and the bisimulations we use are extensions
(by the addition of transition relations →′) of similar structures that have been
used elsewhere in the literature [21] for another problem (existence of ﬁnite-state
implementations of knowledge-based programs).
6 In general, this may require another Savitch-style search. In fact, in our applications,
k ≤|S|2, i.e., the square of the number of states of E, will suﬃce, so this is not
necessary.

Model Checking Knowledge and Linear Time: PSPACE Cases
207
5
Model Checking with Respect to Perfect Recall
In this section we consider several special cases of model checking with respect to
perfect recall. The ﬁrst restricts formulas to refer only to the knowledge of a single
agent, and the latter concerns model checking the full language L{  , U,K1,...,Kn,C}
in restricted environments.
5.1
Formulas of L{  , U,K}
We ﬁrst treat the case of model checking formulas of a single agent (agent 1)
using the perfect recall view. (This case may also be applied to model checking
formulas that refer only to a single agent’s knowledge, simply by dropping the
other agents’ observation functions from the environment.)
In this setting it suﬃces to track the set of states the agent considers possible
at each point in time. We deﬁne the environment E′ = (S′, I′, →′, O′
1, π′, α′) by:
– S′ = { (s, P) | s ∈S, P ⊆S, s ∈P }
– I′ = { (s, P0(s)) | s ∈I } where P0(s) = { s′ ∈I | O1(s) = O1(s′) }
– (s, P) →′ (s′, P ′) iﬀs →s′ and P ′ = { t′ | t ∈P, t →t′, O1(t′) = O1(s′) },
and
– O′
1(s, P) = P.
with bisimulation from Epr given by σ(r, m) = (r(m), P pr
1 (E, r, m)). Observe
that a state of E′ can be represented in space O(log2 |S| + |S|). States of E′ can
be seen to be a special case (1-trees) of data structures previously used in [22] for
model checking L{K1,...,Kn}. That σ is a bisimulation can be seen by arguments
in that work. It is easy to check that observations preserve reachability. By
Theorem 11 we conclude that this model checking problem can be decided in
PSPACE, which completes the proof of Theorem 2.
5.2
Multi-agent Broadcast and L{  , U,K1,...,Kn,C} with Perfect
Recall Semantics
Broadcast environments [21, 25] model situations in which agents may maintain
private information, but where the only means by which this information can be
communicated is by synchronous simultaneous broadcast to all agents.
We give a deﬁnition of broadcast environments here that is slightly more
abstract than previous formulations, which dealt with a notion of environment
in which agents are equipped with actions that they may perform. Formally, we
deﬁne a broadcast environment to be an environment E = (S, I, →, (Oi)i∈A, π, α)
in which the states and observation functions and transition relation have a
particular structure.
– The set S of states of E is a subset of S0 × S1 × . . .× Sn, where S0 is a ﬁnite
set of shared states, and for each agent i a set Si of private states. If s =
⟨s0, . . . , sn⟩denotes a state, we write pi(s) to denote agent i’s private state
si. For each agent i, deﬁne the binary function ▷◁i on S by ⟨s0, s1, . . . sn⟩▷◁i
⟨t0, . . . tn⟩= ⟨s0, s1 . . . si−1, ti, si+1, . . . sn⟩. We require that S is closed under
the functions ▷◁i.

208
K. Engelhardt, P. Gammie, and R. van der Meyden
– The observation functions are given by Oi(s) = (Oc(s0), pi(s)) , where Oc :
S0 −→O is a common observation function.
– The transition relation has the property that for each agent i = 1 . . . n, if
Oi(s) = Oi(t) and s →s′ and t →t′ and Oc(s′) = Oc(t′), then s →s′ ▷◁i t′.
There is no constraint on the set of initial states. Intuitively, the common obser-
vation function models the information that is being broadcast, and the private
states model private information that is being maintained by the agents. An
agent’s observation consists of the broadcast information and its private infor-
mation. The condition on the transition relation can be understood as saying
that an agent’s choice of update on its private state (1) may depend only on
the current observation and the incoming common observation and (2) does not
aﬀect the update on the common state or any of the other agents’ updates.
Paradigmatic examples of broadcast systems are card games such as bridge
(where both bidding and playing of cards can be viewed as a broadcast) and
systems composed of processes attached to bus, with all processes receiving every
communication (as in “snoopy cache coherence protocols” [19]).
Note that every single agent system E is isomorphic to a broadcast system
E′. For, if we represent a state s of E by a state ⟨s, O1(s)⟩of E′, and view
the ﬁrst component as being the shared state and the second component as the
private state of the single agent, and take Oc(s) = O1(s), then the constraint
on the transition relation is trivially satisﬁed, because if O1(s) = O1(t) then
(s, O1(s)) ▷◁(t, O1(t)) = (s, O1(s)).
For the broadcast, perfect recall case, we use the following environment E′:
– S′ is the set of elements (s, f, t) ∈I × (I −→P(S)) × S such that t ∈f(s),
– (s, f, t) ∈I′ iﬀs ∈I, f is given by f(s′) = { t ∈I | Oc(t) = Oc(s′) } for all
s′ ∈I, and t ∈f(s),
– (s, f, t) →′ (s, f ′, t′) if f ′(s′) = { u′ | u ∈f(s′), u →u′, Oc(u′) = Oc(t′) }
and t →t′,
– O′
i(s, f, t) = (Oi(s), f, Oi(t)),
and the bisimulation σ given by σ(r, m) = (r(0), f, r(m)), where f(s) is the set
of states t such that there exists a trace r′[0 . . . m] of E with Oc(r′[0..m]) =
Oc(r[0..m]) and t = r′(m). Observations preserve reachability in this environ-
ment. The states of E′ can be represented in size O(log2 |S|+|I|·|S|+log2 |S|) =
O(|S|2), and applying Theorem 11 shows once again that this model checking
problem is in PSPACE, completing the proof of Theorem 3. Note also that in
this structure, if (s, f, t)
obs
∼G (s′, f ′, t′), then it does so by means of a sequence of
states all of which have second component f, and also f ′ = f. Thus a maximal
path length of |S|2 suﬃces in CKCHECK.
6
Formulas of L{
  , U,K1,...,Kn,C} for the Clock and
Observational Views
In order to model check formulas with respect to the clock view, the image of a
point (r, m) in the simulating environment E′ needs to keep track of the set of
states that are reachable in exactly m steps. We deﬁne E′ by

Model Checking Knowledge and Linear Time: PSPACE Cases
209
– S′ = { (s, P) | s ∈S, P ⊆S, s ∈P }
– I′ = I × {I},
– (s, P) →′ (s′, P ′) if s →s′ and P ′ = {t′ | t ∈P, t →t′}.
– O′
i(s, P) = (Oi(s), P)
The bisimulation is given by σ(r, m) = (r(m), { r′(m) | r′ ∈runs(E) }). Ob-
servations can be seen to preserve reachability. The states in the constructed
environment can be represented in space O(log |S| + |S|). This problem is again
in PSPACE by Theorem 11. This yields a proof of Theorem 4. In this structure,
if (s, P)
obs
∼G (s′, P ′), then it does so by means of a sequence of states all of which
have second component P, and also P ′ = P. Thus a maximal path length of |S|
suﬃces in CKCHECK.
We can already decide realization in a ﬁnite environment E with respect to
the observational semantics by furnishing a standard LTL model checker with
the equivalence classes induced by the observation function. To remain within
our framework, it suﬃces to use an environment identical to E with bisimulation
σ(r, m) = r(m) from Eobs to E. Its states can be represented in size O(log |S|).
However, in order for observations to preserve reachability in this case, we need
to ﬁrst remove unreachable states from the environment. Here also a maximal
path length of |S| suﬃces in CKCHECK.
7
Conclusion
We have shown that our general bisimulation-based scheme for model checking
the logic of knowledge and linear time yields PSPACE complexity bounds in
a number of interesting cases of the general problem (which has much higher
complexity).
Our notion of bisimulation allows reductions on the temporal structure of
environments, but we have not exploited this in our applications. It could be
worth exploring this observation in practice. Experiments conducted by Fisler
and Vardi [6] suggest that bisimulation reduction is of limited utility for temporal
logic model checking, but arguments of van der Meyden and Zhang [26] suggest
such reductions might be eﬀective for the much larger search spaces produced
when dealing with information ﬂow properties.
The techniques are also applicable to show decidability for certain other classes
of environments (with higher complexity bounds). We leave the details for else-
where. We believe that the techniques we have developed can also be adapted
to deal with the combination of branching time and the logic of knowledge: we
leave this for future work.
Wozna et al have studied model checking a logic of knowledge and branching
time in a real time systems modelled using timed automata [30]. Their semantics
is close to our clock semantics, but we note that their until operator is bounded
to a speciﬁc interval, so the closest appropriate comparison is to our language
L{⃝,K1,...,Kn,C}. They give decidability but not complexity results, but study
bounded model checking techniques for their logic.

210
K. Engelhardt, P. Gammie, and R. van der Meyden
References
[1] A. Baltag, L. S. Moss, and S. Solecki. The logic of public announcements, common
knowledge, and private suspicions.
In TARK ’98: Proc. 7th Conf. Theoretical
Aspects of Rationality and Knowledge, pages 43–56, 1998.
[2] A. K. Chandra, D. C. Kozen, and L. J. Stockmeyer.
Alternation.
J. ACM,
28(1):114–133, 1981.
[3] A. Cimatti, C. Pecheur, and R. Cavada. Formal veriﬁcation of diagnosability via
symbolic model checking. In IJCAI, pages 363–369, 2003.
[4] A. Cimatti, C. Pecheur, and A. Lomuscio. Applications of model checking for
multi-agent systems: Veriﬁcation of diagnosability and recoverability. In CS&P
’05: Proc. Int. Work. Concurrency, Speciﬁcation, and Programming, 2005.
[5] R. Fagin, J. Y. Halpern, Y. Moses, and M. Y. Vardi. Reasoning About Knowledge.
MIT-Press, 1995.
[6] K. Fisler and M. Y. Vardi. Bisimulation and model checking. In CHARME ’99:
Conf. Correct Hardware Design and Veriﬁcation Methods, pages 338–341, 1999.
[7] P. Gammie and R. van der Meyden. MCK: Model checking the logic of knowledge.
In R. Alur and D. Peled, editors, CAV, volume 3114 of LNCS, pages 479–483.
Springer-Verlag, 2004. http://www.cse.unsw.edu.au/ mck/.
[8] N. O. Garanina and N. V. Shilov. Well-structured model checking of multiagent
systems.
In Sixth Int. Andrei Ershov Memorial Conf. Perspectives of System
Informatics, LNCS. Springer-Verlag, 2006. to appear.
[9] J. Y. Halpern and Y. Moses. Knowledge and Common Knowledge in a Distributed
Environment. J. ACM, 37(3), 1990.
[10] J. Y. Halpern and K. R. O’Neill. Anonymity and information hiding in multiagent
systems. In CSFW, pages 75–88. IEEE Computer Society, 2003.
[11] O. Lichtenstein and A. Pnueli. Checking that ﬁnite state concurrent programs sat-
isfy their linear speciﬁcation. In POPL ’85: Proc. 12th ACM SIGACT-SIGPLAN
Symp. Principles of Programming Languages, pages 97–107, New York, NY, USA,
1985. ACM Press.
[12] A. Lomuscio and F. Raimondi. The complexity of model checking concurrent pro-
grams against CTLK speciﬁcations. In H. Nakashima, M. P. Wellman, G. Weiss,
and P. Stone, editors, AAMAS, pages 548–550. ACM, 2006.
[13] A. Lomuscio and F. Raimondi. MCMAS: A model checker for multi-agent systems.
In H. Hermanns and J. Palsberg, editors, TACAS, volume 3920 of LNCS, pages
450–454. Springer-Verlag, 2006.
[14] D. M. R. Park. Concurrency and automata on inﬁnite sequences. In P. Deussen,
editor, Theoretical Computer Science: 5th GI-Conf., Karlsruhe, volume 104 of
LNCS, pages 167–183. Springer-Verlag, Mar. 1981.
[15] W. J. Savitch. Relationships between nondeterministic and deterministic tape
complexities. J. Comput. Syst. Sci., 4(2):177–192, 1970.
[16] N. V. Shilov and N. O. Garanina. Model checking knowledge and ﬁxpoints. In
Z. ´Esik and A. Ing´olfsd´ottir, editors, FICS, volume NS-02-2 of BRICS Notes
Series, pages 25–39. University of Aarhus, 2002.
[17] N. V. Shilov, N. O. Garanina, and K.-M. Choe.
Update and abstraction in
model checking of knowledge and branching time.
Fundamenta Informaticae,
72(1–3):347–361, 2006.
[18] A. P. Sistla and E. M. Clarke. The complexity of propositional linear temporal
logics. J. ACM, 32(3):733–749, 1985.

Model Checking Knowledge and Linear Time: PSPACE Cases
211
[19] P. Sweazey and A. J. Smith. A class of compatible cache consistency protocols and
their support by the IEEE futurebus. In ISCA ’86: Proc. 13th Int. Symp. Com-
puter Architecture, pages 414–423, Los Alamitos, CA, USA, 1986. IEEE Computer
Society Press.
[20] P. F. Syverson. Knowledge, belief, and semantics in the analysis of cryptographic
protocols. J. Computer Security, 1(3–4):317–334, 1992.
[21] R. van der Meyden. Finite state implementations of knowledge-based programs.
In V. Chandru and V. Vinay, editors, FSTTCS, volume 1180 of LNCS, pages
262–273. Springer-Verlag, 1996.
[22] R. van der Meyden.
Common knowledge and update in ﬁnite environments.
Information and Computation, 140(2):115–157, Feb. 1998.
[23] R. van der Meyden and N. Shilov. Model checking knowledge and time in systems
with perfect recall (extended abstract). In FSTTCS ’99: Proc. Conf. Foundations
of Software Technology and Theoretical Computer Science, volume 1738 of LNCS.
Springer-Verlag, Dec. 1999.
[24] R. van der Meyden and K. Su. Symbolic model checking the knowledge of the
dining cryptographers. In CFSW 2004: Proc. 17th IEEE Computer Security Foun-
dations Workshop. IEEE Computer Society, 2004.
[25] R. van der Meyden and T. Wilke.
Synthesis of distributed systems from
knowledge-based speciﬁcations.
In M. Abadi and L. de Alfaro, editors, CON-
CUR, volume 3653 of LNCS, pages 562–576. Springer-Verlag, 2005.
[26] R. van der Meyden and C. Zhang. Algorithmic veriﬁcation of noninterference
properties. In Proceedings Workshop on Views on Designing Complex Systems,
ENTCS, Bertinoro, Italy, Sept. 2006. to appear.
[27] J. van Eijck and S. Orzan.
Modelling the epistemics of communication with
functional programming. In M. van Eekelen, editor, TFP ’05: 6th Symp. Trends
in Functional Programming, pages 44–59, 2005.
[28] M. Y. Vardi. Implementing knowledge-based programs. In Y. Shoham, editor,
TARK ’96: Proc. 6th Conf. Theoretical Aspects of Rationality and Knowledge,
pages 15–30. Morgan Kaufmann, 1996.
[29] M. Y. Vardi and P. Wolper. Automata theoretic techniques for modal logics of
programs (extended abstract). In STOC, pages 446–456. ACM, 1984.
[30] B. Wozna, A. Lomuscio, and W. Penczek. Bounded model checking for knowl-
edge and real time. In AAMAS ’05: 4th Int. J. Conf. Autonomous Agents and
Multiagent Systems, pages 165–172, Utrecht, 25–29 July 2005. ACM.

Realizations and LP
Melvin Fitting
Lehman College, Cuny
melvin.fitting@lehman.cuny.edu
Abstract. LP can be seen as a logic of knowledge with justiﬁcations.
Artemov’s Realization Theorem says justiﬁcations can be extracted from
validities in the Hintikka-style logic of knowledge S4, where they are not
explicitly present. We provide tools for reasoning about justiﬁcations
directly. Among other things, we provide machinery for combining two
realizations of the same formula, and for replacing subformulas by equiv-
alent subformulas. The results are algorithmic in nature—semantics for
LP plays no role. We apply our results to provide a new algorithmic proof
of Artemov’s Realization Theorem itself.
1
Introduction
The logic LP (logic of proofs) is a propositional modal-like logic introduced by
Artemov, [1], to solve a problem originating with G¨odel: provide a natural arith-
metic foundation for intuitionistic logic, [2]. It also is an interesting logic for its own
sake, a logic of justiﬁcations that is closely related to a standard logic of knowl-
edge, S4, and generalizable to analogs of the usual variety of logics of knowledge.
But it is a diﬃcult logic to work with. Semantics, see [3], is more complex than
that of standard modal logics, and the same applies to its proof theory. The LP
advantage lies in its representation of explicit justiﬁcations, originally intended to
be proofs in the mathematical sense. Justiﬁcations provide a mechanism for deal-
ing with logical omniscience problems—they supply a measure of how hard it is to
know something. It should be possible to reason about justiﬁcations themselves
in useful ways but it turns out that doing so presents considerable technical diﬃ-
culties. We provide some tools, algorithms, for manipulating formulas containing
justiﬁcations. Since this is a short version of my results, only the algorithms are
given—proofs that they are correct can be found on my web site.
A central result concerning LP is Artemov’s Realization Theorem 3—any the-
orem of S4 can be realized, which means modal operators can be replaced with
explicit justiﬁcations to produce a theorem of LP, and these justiﬁcations can
be calculated. It is as if the modal operator of S4 was a quantiﬁer, ‘there exists
a reason. . . ’, and these quantiﬁers were constructive. At the end of this paper
we sketch a new proof of the Realization Theorem. The general plan of this pa-
per is as follows. There is a brief proof-theoretic presentation of LP—semantics
plays no role here. An annotated version of S4 is given, in which distinct oc-
currences of modal operators are syntactically distinguished. Then realizations
become ﬁrst-class objects, as realization functions. A Realization Modiﬁcation
S. Artemov and A. Nerode (Eds.): LFCS 2007, LNCS 4514, pp. 212–223, 2007.
c
⃝Springer-Verlag Berlin Heidelberg 2007

Realizations and LP
213
Theorem is proved, and a number of consequences are derived from it, all con-
structive in nature. As remarked earlier, here only the algorithms can be given,
while correctness proofs are relegated to my web site.
Since Artemov’s original work, LP has been generalized to a family of logics
called Justiﬁcation Logics. Thus LP is one among many—indeed various multi-
modal logics of knowledge have also been brought into the picture. I do not
address the whole family of justiﬁcation logics in detail here—things are com-
plicated enough—but it is clear that my methods do extend beyond LP itself.
2
The Logic LP
This section contains a brief formulation of LP axiomatically. A semantics will
not be needed in this paper. The language of LP, denoted LLP here, is built
from the following basic machinery: propositional variables, P, Q, P1, P2, . . . ; a
propositional constant, ⊥; a logical connective, ⊃; proof variables, x, y, x1, x2,
. . . ; proof constants, c, d, c1, c2, . . . ; function symbols ! (monadic), ·, + (binary);
and an operator symbol of the type ⟨term⟩:⟨formula⟩.
Proof. polynomials are built up from proof variables and proof constants, using
the function symbols. Ground proof polynomials are those without variables. For-
mulas are built up from propositional variables and the propositional constant ⊥
using ⊃(with other connectives deﬁned in the usual way), and an extra rule of
formation: if t is a proof polynomial and X is a formula then t:X is a formula.
The formula t:X can be read: “t is a proof of X.” Proof constants intuitively
represent proofs of basic, assumed truths. Proof variables in a formula can be
thought of as justiﬁcations supplied by the outside—by the world, if you like.
If t is a proof of X ⊃Y and u is a proof of X, we should think of t · u, the
application of t to u, as a proof of Y . The operation ! is a proof-checker: if t
is a proof of X then !t is a veriﬁcation that t is such a proof. The operation +
combines proofs in the sense that t + u proves all the things that t proves plus
all the things that u proves.
The following axiom system for LP is from [1]. Axioms are speciﬁed by giving
axiom schemas, and these are:
A0. Classical
Classical propositional axiom schemes
A1. Application
t:(X ⊃Y ) ⊃(s:X ⊃(t·s):Y )
A2. Reﬂexivity
t:X ⊃X
A3. Proof Checker t:X ⊃!t:(t:X)
A4. Sum
s:X ⊃(s+t):X
t:X ⊃(s+t):X
Rules of inference are modus ponens, and a version of the necessitation rule
for axioms only.
R1. Modus Ponens
⊢Y provided ⊢X and ⊢X ⊃Y
R2. Axiom Necessitation ⊢c:X where X is an axiom A0 – A4
and c is a proof constant.

214
M. Fitting
As usual, a proof is a ﬁnite sequence of formulas each of which is an axiom or
comes from earlier terms by one of the rules of inference. A notion of derivation
can be introduced by deﬁning Γ ⊢X to mean that (G1 ∧. . . ∧Gn) ⊃X is a
theorem for some ﬁnite subset {G1, . . . , Gn} of Γ.
The speciﬁcation of which constants are associated with which axioms for
rule R2 applications is called a constant speciﬁcation. A constant speciﬁcation is
injective if each proof constant is used for at most one axiom. Injective constant
speciﬁcations suﬃce, but are not required. If a proof uses an injective constant
speciﬁcation, I will say the proof is injective, and what it proves is injectively
provable. In [3] constant speciﬁcations were assumed to be given beforehand,
and their properties were investigated in some detail. Computational complexity
is dependent on details of the constant speciﬁcation. In [1] things were more
ﬂexible, and constants were generally assigned during the course of a proof, as
will be done here.
Deﬁnition 1. A substitution maps proof variables to proof polynomials. If σ
is a substitution and X is a formula, Xσ is the result of replacing each proof
variable x in X with the proof polynomial xσ. Similarly for substitution in proof
polynomials.
Theorem 1 (Substitution Lemma). If X is a theorem of LP, so is Xσ.
Further, if X has an injective proof, so does Xσ.
This result and the following are from [1]. The Lifting Lemma says that proofs
and derivations in LP can be internalized.
Theorem 2 (Lifting Lemma). Suppose
s1:X1, . . . , sn:Xn, Y1, . . . , Yk ⊢Z
then there is a proof polynomial t(s1, . . . , sn, y1, . . . , yk) (where the yi are vari-
ables) such that
s1:X1, . . . , sn:Xn, y1:Y1, . . . , yk:Yk ⊢t(s1, . . . , sn, y1, . . . , yk):Z.
If the original derivation was injective, the same is the case for the later derivation.
Corollary 1. If Z has an LP proof, then for some ground proof polynomial t,
t:Z will have an LP proof, injective if the proof of Z was injective.
3
Annotations and Realizations
Let L□be the usual language of propositional modal logic, built up from propo-
sitional letters using ⊥, ⊃, and □, with other connectives and ♦deﬁned as usual.
In the LP Realization Theorem negative □occurrences are replaced by proof
variables while positives need not be, and diﬀerent negative occurrences are
replaced with distinct variables. To keep track of this we introduce an annotated
version, La
□, of the language L□, intermediate between L□and LLP.

Realizations and LP
215
Deﬁnition 2. The language La
□and its features are introduced as follows.
1. There is an inﬁnite family of indexed modal operators, □1, □2, . . . . Formu-
las of La
□are built up as in L□, but using indexed modal operators instead of
□. Formulas of La
□are called annotated formulas.
2. If X is an annotated formula, and X′ is the result of replacing all indexed
modal operators, □n, with □, then X′ is a formula of L□. We say X is an
annotated version of X′, and X′ is an unannotated version of X.
3. A properly annotated formula is an annotated formula in which no indexed
modal operator occurs twice, and if □n occurs in a negative position n is
even, and if it occurs in a positive position n is odd.
Example 1. Here is an example of a properly annotated formula.
□2(□1U ⊃□4(□3P ⊃□6V )) ⊃□5W
(1)
Annotation is a bookkeeping device to keep track of occurrences of modal
operators and their polarities. Properly annotated formulas are fundamental,
but formulas that are annotated but not properly so also arise naturally. If
X is properly annotated and Y is a negative subformula of X it will not be
properly annotated because polarities have been reversed in passing from X
to Y . Generally we will ﬁx a properly annotated formula X and work with
subformulas of it, all of which are annotated, and properly so when considered
as subformulas of X.
In an S4 model M = ⟨G, R, ⊩⟩we use the following rule of evaluation:
M, Γ ⊩□nX ⇐⇒M, Δ ⊩X for every Δ ∈G with ΓRΔ
Then in a model, an annotated formula X and its unannotated version X′
behave alike at each world. Likewise proof-theoretically annotations play no
special role. They are only for syntactic bookkeeping.
Now realizations can be deﬁned functionally, but ﬁrst, a comment. Call the dis-
played occurrence of t in the formula t:Z self-referential if t also has an occurrence
in Z. It is shown in [4] that one must admit self-referential proof constants in or-
der to have the Realization Theorem hold. Here we will sometimes need to exercise
control over the self-referentiality of proof variables, hence item 3 below.
Deﬁnition 3. Realization functions and related notions are deﬁned as follows.
1. A realization function is a mapping from positive integers to proof polynomi-
als that maps even integers to LP variables. It is assumed that all realization
functions behave the same on the even integers: if r is any realization func-
tion, r(2n) = xn, where x1, x2, . . . is the list of proof variables arranged in a
standardized order.
2. If X is a formula of La
□, an annotated formula, and r is a realization func-
tion, r(X) is the result of replacing each modal operator □i in X with the
proof polynomial r(i). The result, r(X) is formula of LP.
3. Realization function r is non self-referential on variables over annotated for-
mula X provided, for each subformula □2nY of X the variable r(2n) = xn
does not occur in r(Y ).

216
M. Fitting
Example 2. Let f, g, h, and k be particular proof polynomials, and let r be a
realization function such that the following holds.
r(1) = g(x2, x3, x5)
r(4) = x2
r(2) = x1
r(5) = h(x1, x2, x3)
r(3) = f(x3)
r(6) = x3
(2)
Let X be formula (1) from Example 1. Then we have the following. Note that r
is non self-referential on variables over X.
r(X) = x1:[g(x2, x3, x5):U ⊃x2:(f(x3):P ⊃x3:V )] ⊃h(x1, x2, x3):W
(3)
Deﬁnition 4. If X is a formula of L□, a conventional modal formula, a real-
ization of X is any formula of LP of the form r(X′) where r is a realization
function and X′ is any properly annotated version of X.
Theorem 3 (Artemov’s Realization Theorem). If Z0 is a theorem of S4,
there is a realization of Z0 that is an injectively provable theorem of LP. In fact,
if Z0 is a theorem of S4, then for any properly annotated version Z of Z0 there
is a realization function r such that r(Z) is injectively provable in LP.
4
Realization Modiﬁcation
Our results concern the combination and modiﬁcation of realization functions.
Full statements are rather complex and technical, but the following may help
make it clear why the complexity is arises.
In normal modal logics one can show a Replacement result: If X(B) is like
X(A) except that some occurrence of A has been replaced with B, then if A ≡B
is provable so is X(A) ≡X(B). In the LP Realization Theorem positive and neg-
ative occurrences of proof polynomials are treated diﬀerently, and the connective
≡blurs the positive/negative distinction. There is another version of Replace-
ment that respects polarity of subformula occurrence: If X(B) is like X(A) ex-
cept that some positive occurrence of A has been replaced with B, then if A ⊃B
is provable so is X(A) ⊃X(B). This too is correct for normal modal logics. But
one would not expect a simple analog of such a result for LP. Proof polynomials
represent justiﬁcations. If A is replaced with B inside a more complex LP for-
mula, justiﬁcations for A must be adjusted to incorporate a justiﬁcation for the
passage from A to B, justiﬁcations for subformulas containing justiﬁcations for
A need adjustment, and so on up. The fact that reasons are explicit makes life
harder in some ways: we care not only about truth but also about the reasons
for that truth. Here is an example to illustrate the complexity.
Example 3. In the modal formula
□(□U ⊃□(□P ⊃□V ))
(4)
we can replace P successively by □R and □□R. In S4, □R ⊃□□R is provable,
and it follows that so is
[□(□U ⊃□(□□R ⊃□V ))] ⊃[□(□U ⊃□(□□□R ⊃□V ))]
(5)

Realizations and LP
217
In LP, x1:[g(x2, x3, x5):U ⊃x2:(f(x3):P ⊃x3:V )] ⊃h(x1, x2, x3):W comes from
(4) by substituting distinct variables for negative occurrences of □and other
proof polynomials for positive occurrences—it is a realization of it. Likewise
k(x3):R is a realization of □R and !k(x3):k(x3):R is a realization of □□R, and
k(x3):R ⊃!k(x3):k(x3):R is a theorem of LP. But replacing P by k(x3):R and
!k(x3):k(x3):R to produce an analog of (5) gives us
{x1:[g(x2, x3, x5):U ⊃x2:(f(x3):k(x3):R ⊃x3:V )]
⊃h(x1, x2, x3):W}
⊃
{x1:[g(x2, x3, x5):U ⊃x2:(f(x3):!k(x3):k(x3):R ⊃x3:V )]
⊃h(x1, x2, x3):W}
(6)
and this is not a theorem of LP. Reasons need adjustment. Instead the following
is an LP theorem,where c, d, and e are particular constants. Note that the form
of this is similar to the form of (6), but details diﬀer signiﬁcantly.
{(e · x1):[g(d · x2, x3, x5):U ⊃(d · x2):(f(x3):k(x3):R ⊃x3:V )]
⊃h(e · x1, d · x2, x3):W}
⊃
{x1:[g(d · x2, x3, x5):U ⊃x2:((c · f(x3)):!k(x3):k(x3):R ⊃x3:V )]
⊃h(e · x1, d · x2, x3):W}
(7)
This example will be continued in Example 4.
Our basic construction provides an algorithm for computing formulas like (7).
There is also provision for the merging of separate realizations into a single one.
Details are complex and in this short paper we only have space to state the
algorithms, and not to prove correctness. That can be found on my web page.
Terms introduced in the following deﬁnition are primarily for use in proving
correctness of our algorithm.
Deﬁnition 5. Let X be an annotated formula and let σ be a substitution.
1. σ meets the no new variable condition provided, for each variable x, the proof
polynomial xσ contains no variables other than x.
2. An indexed modal operator □2n that occurs in X is an input operator in X.
If □2n is an input operator, xn is an input variable of r(X), where r is any
proper realization function.
3. σ lives on input positions in X provided the only variables xn for which
xnσ ̸= xn are such that □2n occurs in X .
In what follows, if ψ(P) is an annotated formula and P is a propositional letter,
ψ(A) is the result of replacing all occurrences of P in ψ(P) with occurrences of
the annotated formula A. We care about proper annotation but subformulas of
a properly annotated formula need not be properly annotated. To deal with this
we ﬁx a formula X(P) that is properly annotated and work with subformulas of
X(P).

218
M. Fitting
Deﬁnition 6. Let X(P) be an annotated formula in which the propositional
letter P has at most one positive occurrence, let A and B be annotated formulas,
let r0 be a realization function, and let ϕ(P) be a subformula of X(P).
1. For a subformula ϕ(P) of X(P), we say a realization/substitution pair ⟨r, σ⟩
replaces r0(A) with r0(B) at P in ϕ(P) within X(P) provided:
(a) if ϕ(P) is a positive subformula of X(P) then r0(ϕ(A))σ ⊃r(ϕ(B)) has
an injective LP proof;
(b) if ϕ(P) is a negative subformula of X(P) then r(ϕ(B)) ⊃r0(ϕ(A))σ has
an injective LP proof.
2. ⟨r, σ⟩hereditarily replaces r0(A) with r0(B) at P in X(P) if, for each sub-
formula ϕ(P) of X(P), ⟨r, σ⟩replaces r0(A) with r0(B) at P in ϕ(P) within
X(P).
In the deﬁnition above one can see the beginnings of applicability to Example 3.
A replacement in an LP formula can be speciﬁed by giving a replacement to
carry out in an S4 formula and a mapping, that is a realization function, to LP.
Now, here is our central construction.
Theorem 4 (Realization Modiﬁcation). Assume all of the following: X(P)
is a properly annotated formula in which the propositional letter P has at most
one positive occurrence, A and B are properly annotated formulas, A and X(P)
share no indexes, and B and X(P) share no indexes; r1 and r2 are realization
functions, both non self-referential on variables over X(A); r1(A) ⊃r1(B) and
r2(A) ⊃r2(B) both have injective proofs; and r1(B) = r2(B).
Then there is a realization/substitution pair ⟨r, σ⟩such that: ⟨r, σ⟩hereditarily
replaces r1(A) with r1(B) and r2(A) with r2(B) at P in X(P). In addition σ lives
on input positions in X(P); σ meets the no new variable condition; and if r1 and
r2 are non self-referential on variables over X(B) then r is non self-referential
on variables over X(B).
The proof is constructive; here is the algorithm involved. A (lengthy) proof of
correctness for the algorithm can be found on my web site.
Begin Algorithm. First we construct, for each subformula ϕ(P) of X(P), a
pair ⟨rϕ, σϕ⟩that replaces r1(A) with r1(B) and r2(A) with r2(B) at P in ϕ(P)
within X(P). The algorithm proceeds recursively on the structure of ϕ(P).
Base Case: ϕ(P) is atomic. Set rϕ = r1 and σϕ to be the identity substitution.
Modal Case: ϕ(P) is □iθ(P), and ⟨rθ, σθ⟩has been constructed.
ϕ(P) positive: By hypothesis, the following are provable.
r1(θ(A))σθ ⊃rθ(θ(B))
(8)
r2(θ(A))σθ ⊃rθ(θ(B))
(9)
Use the Lifting Lemma to produce proof polynomials u and v that
“prove” (8) and (9) respectively. Then set σϕ = σθ and deﬁne rϕ as
follows.
rϕ(n) =
u · (r1(n)σθ) + v · (r2(n)σθ) if n = i
rθ(n)
otherwise

Realizations and LP
219
ϕ(P) negative: In this case i is even. By hypothesis, the following are
provable.
rθ(θ(B)) ⊃r1(θ(A))σθ
(10)
rθ(θ(B)) ⊃r2(θ(A))σθ
(11)
Use the Lifting Lemma to produce proof polynomials u and v that
“prove” (10) and (11) respectively. Then set rϕ = rθ and deﬁne σϕ
as follows, where i = 2j.
xnσϕ =

u · xj + v · xj if n = i
xnσθ
otherwise
Implication Case: ϕ(P) is θ(P) ⊃η(P) and ⟨rθ, σθ⟩and ⟨rη, ση⟩have been con-
structed. It is shown that the two substitutions commute. Set σϕ = σθση =
σησθ, and deﬁne rϕ as follows.
rϕ(n) =
⎧
⎨
⎩
rθ(n)ση if □n in θ(B)
rη(n)σθ if □n in η(B)
r1(n)
otherwise
Now the pair ⟨rX, σX⟩can be shown to provide an hereditary replacement.
End Algorithm.
5
The Replacement Theorem
In Example 3 the complexity of adapting the Replacement Theorem to LP was
illustrated. In Theorem 4, if we take both r1 and r2 to be the same, what results
is an algorithm to eﬀect a replacement and which gives the results found in the
earlier example. The following illustrates how.
Example 4. Continuing Examples 2 and 3, take A to be □7R and B to be
□9□11R, so A ⊃B is □7R ⊃□9□11R. A and B are properly annotated, as was
X(P) from (1), and there is no annotation overlap. Then X(A) is □2(□1U ⊃
□4(□3□7R ⊃□6V )) ⊃□5W and X(B) is □2(□1U ⊃□4(□3□9□11R⊃□6V ))⊃
□5W. Specifying more of the realization function r that was partly given in (2):
r(7) = k(x3), r(9) =!k(x3), and r(11) = k(x3). Then r is non self-referential
on variables over X(A), and r(A) ⊃r(B) is k(x3):R ⊃!k(x3):k(x3):R, which
has an injective LP proof. Carrying out a naive replacement, we might expect
r(X(A)) ⊃r(X(B)) to have an injective LP proof, but this is the formula (6),
which was earlier seen to be incorrect.
Let c, d, and e be ground proof polynomials such that the following have
injective proofs.
c:[k(x3):R ⊃!k(x3):k(x3):R]
d:{[(c · f(x3)):!k(x3):k(x3):R ⊃x3:V ] ⊃[f(x3)):k(x3):R ⊃x3:V ]}
e:{[g(d · x2, x3, x5):U ⊃x2:((c · f(x3)):!k(x3):k(x3):R ⊃x3:V )] ⊃
[g(d · x2, x3, x5):U ⊃(d · x2):(f(x3):k(x3):R ⊃x3:R)]}

220
M. Fitting
Following the algorithm of Theorem 4, a realization/substitution pair that
hereditarily replaces r(A) with r(B) at P in X(P) is ⟨r∗, σ∗⟩, speciﬁed as follows.
σ∗is the identity substitution except that σ∗(x1) = e · x1 and σ∗(x2) = d · x2,
and
r∗(1) = g(d · x2, x3, x5)
r∗(6) = x3
r∗(2) = x1
r∗(7) = k(x3)
r∗(3) = c · f(x3)
r∗(9) = !k(x3)
r∗(4) = x2
r∗(11) = k(x3).
r∗(5) = h(e · x1, d · x2, x3)
The formula r(X(A))σ∗is
(e·x1):(g(d·x2, x3, x5):U ⊃(d·x2):(f(x3):k(x3):R ⊃x3:V )) ⊃h(e·x1, d·x2, x3):W
and r∗(X(B)) is
x1:(g(d·x2, x3, x5):U ⊃x2:((c·f(x3)):!k(x3):k(x3):R⊃x3:V )) ⊃h(e·x1, d·x2, x3):W
and r∗(X(A))σ∗⊃r∗(X(B))σ∗is the formula (7) seen earlier. This example is
worked out in greater detail in [5].
6
Realization Weakening
When replacing t:F and u:F with the weaker (t + u):F it is possible to drop
the non self-referentiality condition. This plays an important role in our proof
of Artemov’s Realization Theorem.
Theorem 5 (Realization Weakening). Assume the following: X(P) is a
properly annotated formula in which the propositional letter P has at most one
positive occurrence; □pK and □qK are both are properly annotated, there is no
annotation overlap between X(P) and □pK, and X(P) and □qK, and p and
q are diﬀerent; r1 and r2 are realization functions with r1(K) = r2(K); and
r1(q) = r2(q) = r1(p) + r2(p).
Then there is a realization/substitution pair ⟨r, σ⟩that hereditarily replaces
r1(□pK) with r1(□qK) at P in X(P), and hereditarily replaces r2(□pK) with
r2(□qK) at P in X(P). Also, σ will live on the input positions in X(P) and
will meet the no new variable condition.
If we set r1(K) = r2(K) = F, r1(p) = t, r2(p) = u, and r1(q) = r2(q) = t + u,
this theorem provides a replacement of t:F and u:F with (t + u):F, as promised.
Begin Algorithm. Call an index n in a properly annotated formula Z self-
referential with respect to a realization function r if □n occurs in Z within the
scope of □2k and xk occurs in r(n).
Deﬁne new realization functions r′
1 and r′
2 as follows. For each index ni in
X(□pK) outside K that is self-referential with respect to r1, introduce a new
variable uni and set r′
1(n1) = uni. For each index mi in X(□pK) outside K

Realizations and LP
221
that is self-referential with respect to r2, introduce a new variable vmi and set
r′
2(mi) = vmi. For each index pi in K that is self-referential with respect to
r1 and r2 (these go together within K), introduce a new variable wpi and set
r′
1(pi) = r′
2(pi) = wpi. Set r′
1(q) = r′
2(q) = r′
1(p) + r′
1(q). Otherwise r′
1 and r1
agree, and r′
2 and r2 agree.
r′
1 and r′
2 are realizaion functions that are non self-referential on variables
over X(□pK). Now apply the algorithm of Theorem 4, getting a realization/
substitution pair ⟨r∗, σ∗⟩.
Deﬁne an ‘undoing’ substitution σ′ as follows.
xσ′ =
⎧
⎪
⎪
⎨
⎪
⎪
⎩
r1(ni)σ∗
if x = uni
r2(mi)σ∗
if x = umi
r1(pi)σ∗= r2(pi)σ∗if x = upi
x
otherwise
The realization/substitution pair ⟨r, σ⟩we want is given by: r(n) = r∗(n)σ′ and
σ = σ∗.
End Algorithm.
7
The Realization Merging Theorem
We show how two realization functions may be merged into one. Note that again
there is no non self-referentiality condition on variables.
Deﬁnition 7. Let X be an annotated formula and r1 and r2 be realization
functions.
1. For a subformula ϕ of X, we say a realization/substitution pair ⟨r, σ⟩merges
r1 and r2 on ϕ in X provided:
(a) if ϕ is a positive subformula of X then both r1(ϕ)σ ⊃r(ϕ) and r2(ϕ)σ ⊃
r(ϕ) are injective theorems of LP;
(b) if ϕ is a negative subformula of X then both r(ϕ) ⊃r1(ϕ)σ and r(ϕ) ⊃
r2(ϕ)σ are injective theorems of LP.
2. We say ⟨r, σ⟩hereditarily merges r1 and r2 on X provided, for each subfor-
mula ϕ of X, ⟨r, σ⟩merges r1 and r2 on ϕ in X.
Theorem 6 (Realization Merging). Let X be a properly annotated formula,
and r1 and r2 be realization functions. Then there is a realization/substitution
pair ⟨r, σ⟩that hereditarily merges r1 and r2 on X. Further, σ will live on the
input positions in X, and will meet the no new variable condition.
Begin Algorithm. Let P be a propositional letter not in X, let p and q be
distinct odd indexes not in X, and let K be P. Now apply the algorithm of
Theorem 5.
End Algorithm.

222
M. Fitting
Example 5. Suppose (A ∨B) ⊃C is a properly annotated formula, and suppose
we have realization functions r1 and r2 such that r1(A ⊃C) and r2(B ⊃C) are
both theorems of LP. We explicitly produce a realization function r such that
r((A ∨B) ⊃C) is a theorem of LP.
By Theorem 6 there is a realization/substitution pair ⟨r, σ⟩that hereditarily
merges r1 and r2 on (A ∨B) ⊃C. We claim r((A ∨B) ⊃C) is a theorem
of LP. Note that since A and B are negative subformulas of X, and C is a
positive subformula, the following are theorems of LP: r(A) ⊃r1(A)σ, r(B) ⊃
r2(B)σ, r1(C)σ ⊃r(C), r2(C)σ ⊃r(C). By assumption, we have as LP theorems
r1(A) ⊃r1(C) and r2(B) ⊃r2(C) and hence by Theorem 1, we also have
r1(A)σ ⊃r1(C)σ and r2(B)σ ⊃r2(C)σ. Putting all this together, we have the
following derivation.
r(A ∨B) ⊃r(A) ∨r(B)
⊃r1(A)σ ∨r2(B)σ
⊃r1(C)σ ∨r2(C)σ
⊃r(C) ∨r(C)
⊃r(C)
8
The Realization Theorem
Here is my construction for the Artemov Realization Theorem, stated earlier as
Theorem 3.
Begin Algorithm. We use a standard cut-free sequent calculus for S4, say the
one used in [1], except that annotations are carried along from premise sequents
to conclusion sequent; an explicit formulation is on my web page. If Z is a
properly annotated version of Z0, and Z0 is a theorem of S4, Z will have a
sequent calculus proof in this system. A realization function is constructed for
each sequent in a proof P of Z, and the function for the ﬁnal sequent is the
desired realization function.
For sequents that are axioms, any realization function will do.
For all rules except L ⊃and R □, if r realizes the premise of a sequent rule,
r will also realize the conclusion.
For the L ⊃rule, if r1 realizes Γ, Y →Δ and r2 realizes Γ →Δ, X, then
r will realize Γ, X ⊃Y →Δ, where r is the merging of r1 and r2 using the
algorithm of Theorem 6.
For the R □rule, suppose r0 realizes □2n1Y1, . . . , □2nkYk −→X. We must re-
alize □2n1Y1, . . . , □2nkYk −→□mX. By the Lifting Lemma, there is a proof poly-
nomial t(xn1, . . . , xnk) such that (xn1:r0(Y1)∧. . .∧xnk:r0(Yk)) ⊃t(xn1, . . . , xnk):
r0(X) is provable. Let p and q be distinct odd new indexes. Let r1 and r2
be the same as r0 except that r1(p) = r0(m), r2(p) = t(xn1, . . . , xnk), and
r1(q) = r2(q) = r1(p) + r2(p). Let P be a new propositional letter, and let Z(P)
be Z with □mX replaced with P. Use the algorithm of Theorem 5 to hereditar-
ily replace r1(□pX) with r1(□qX) and r2(□pX) with r2(□qX) at P in Z(P),

Realizations and LP
223
getting a realization/substitution pair ⟨r∗, σ∗⟩. Finally, let r be like r∗except
that r(m) = r∗(q). Then r realizes □2n1Y1, . . . , □2nkYk −→□mX.
End Algorithm.
9
Conclusion
The logic LP is one of a family of justiﬁcation logics. It can be weakened by
dropping the ! operator and its axiom. It can be strengthened by adding a
negative proof checker, dual to !, see [6]. The work in this paper extends to these
logics. LP can also be extended to incorporate multiple agents, and even common
knowledge. It is not yet known if the present work extends to the multiple agent
versions. A Realization Theorem for LP with an added negative proof checker,
?, was recently shown in [6] by a semantic argument. Present methods provide
a second, proof-theoretic, argument as well.
S4 is a well-known logic of knowledge in the Hintikka tradition—a logic with
a single knower having positive introspection. Then LP can be seen as that logic
of knowledge made explicit, with “known to be the case” replaced by “known
because of such-and-such evidence”. The Realization Theorem is a way of ex-
tracting the explicit content of a knowledge statement in which justiﬁcations are
present only implicitly. One can think of the whole LP/S4 package as a kind of
labor-saving device. We can reason more easily about knowledge if we don’t make
things explicit, but when we need explicit justiﬁcations, they can be calculated.
Perhaps the major drawback to the present methods, and to all constructive
methods in this area, is that computing provable realizations for theorems of
logics of knowledge requires cut-free proofs. Modus Ponens is the stumbling
block. It does not preserve polarities, and thus the methods of this paper do not
apply to it. How to deal with this remains a major open question.
References
1. Artemov, S.:
Explicit provability and constructive semantics.
The Bulletin for
Symbolic Logic 7(1) (2001) 1–36
2. G¨odel, K.: Eine Interpretation des intuitionistischen Aussagenkalk¨uls. Ergebnisse
eines mathematischen Kolloquiums 4 (1933) 39–40 English translation in [7].
3. Fitting, M.C.: The logic of proofs, semantically. Annals of Pure and Applied Logic
132 (2005) 1–25
4. Kuznets, R.: On self-referentiality in modal logic. The Bulletin of Symbolic Logic
12(3) (2006) 510
5. Fitting, M.C.:
A replacement theorem for LP.
Technical report, CUNY Ph.D.
Program in Computer Science (2006) http://www.cs.gc.cuny.edu/tr/.
6. Rubtsova, N.: Evidence reconstruction of epistemic modal logic S5. In Grigoriev,
D., Harrison, J., Hirsch, E.A., eds.: Computer Science — Theory and Applications,
Springer-Verlag (2006) 313–321 LNCS, No. 3967.
7. Feferman, S., Jr., J.D., Kleene, S.C., Moore, G.H., Solovay, R.M., Heijenoort, J.v.,
eds.: Kurt G¨odel Collected Works. Volume I. Oxford University Press, New York
(1986)

Successive Abstractions of Hybrid Automata for
Monotonic CTL Model Checking
R. Gentilini2, K. Schneider2, and B. Mishra1,3
1 Courant Institute, New York University, New York, NY, U.S.A.
2 University of Kaiserslautern, Department of Computer Science, Germany
3 NYU School of Medicine, New York University, New York, NY, U.S.A.
{gentilin,Klaus.Schneider}@informatik.uni-kl.de,
mishra@nyu.edu
Abstract. Current symbolic techniques for the automated reasoning over unde-
cidable hybrid automata, force one to choose between the reﬁnement of either an
overapproximation or an underapproximation of the set of reachable states. When
the analysis of branching time temporal properties is considered, the literature has
developed a number of abstractions techniques based on the simulation preorder,
that allow the preservation of only true universally quantiﬁed formulæ.
This paper suggests a way to surmount these difﬁculties by deﬁning a succes-
sion of abstractions of hybrid automata, which not only (1) allow the detection
and the reﬁnement of both over- and under-approximated reachable sets symmet-
rically, but also (2) preserves the full set of branching time temporal properties
(when interpreted on a dense time domain). Moreover, our approach imposes on
the corresponding set of abstractions a desirable monotonicity property with re-
spect to the set of model-checked formulaæ.
1
Introduction
Over the past few years, questions related to the analysis of hybrid automata [10] have
occupied a considerable amount of attention and interest within the automatic veriﬁca-
tion research community, since the consequent models provide a high ﬁdelity represen-
tation of real world (embedded) systems, and yet the nontrivial computational problems
they raise do not yield to the classical techniques either of applied mathematics or of
theoretical computer science.
As originally envisioned in [10,9], hybrid automata have aspired to combine the
traditional automata tools from logic and computer science with differential equa-
tion systems, and their long tradition in mathematics. In this respect, the enormous
potentials of hybrid automata in challenging applications ﬁelds—namely, the analysis
of embedded, real time, and biological systems, to cite only a few of them—were im-
mediately recognized. However, the trade-off between the representational ﬁdelity of
hybrid automata and the solvability of related decidability problems addressing proper-
ties such as reachability, was also immediately apparent. Hence, the major effort of the
hybrid automata research community, to date, has been devoted to the study of decid-
able classes of hybrid automata, for which at least the reachability problem remains de-
cidable [10,9,13,14,2]. Listed in their chronological order, the (main) decidable families
S. Artemov and A. Nerode (Eds.): LFCS 2007, LNCS 4514, pp. 224–240, 2007.
c⃝Springer-Verlag Berlin Heidelberg 2007

Successive Abstractions of Hybrid Automata for Monotonic CTL Model Checking
225
in the literature are the ones corresponding to timed automata [1], singular automata
[10,9], rectangular automata [9], and o-minimal automata [13]. Unfortunately, for each
one of the above families, the sacriﬁce in the expressiveness of either the discrete or the
continuous dynamics [2] that has to be exacted in exchange for the decidability result,
strongly casts doubt on the possibility of faithfully capturing complex hybrid dynamics
arising, for example, in the system biology area [16,8].
Motivated by the reasons listed above, many authors have recently focused on
developing techniques for the symbolic analysis of undecidable—and yet reasonably
expressive—hybrid automata [16,8,19,6,17]. However, any method developed so far
relies either on the deﬁnition of abstractions simulating the underlying hybrid automata
[8,19,17] or on symbolic bounded reachability techniques [16,6]. In the ﬁrst case, only
an overapproximationof the reachable state-space is possible. Usually, those techniques
target the proof of safety property, stating that something undesirable should never hap-
pen on any reachable state of the system. In general, the simulation preorder from the
abstraction to the hybrid automaton allows for preservation of only true formulæ in the
universal fragment of a branching time temporal logic. In the second case, only an un-
derapproximation of the reachable state-space can be explored and used for generating
counterexamples to the reactive system properties of interest (e.g. safety).
In this paper we develop a framework to both prove and disprove reactive system
properties expressed by means of CTL logic [4,18] on (undecidable) hybrid automata.
To the best of authors’ knowledge, no other symbolic technique for the analysis of unde-
cidable hybrid automata can be claimed to preserve both true and false reactive systems
properties simultaneously. Our framework is based on the design of a succession of ab-
straction and a corresponding three valued semantics for the logic CTL, allowing for
the monotonic preservation of true/false formulæ along the succession of abstractions.
Given a structure A in our succession, we ﬁnally show that the three valued CTL model
checking problem on A is linear in the length of the formula and in the size of the
abstraction. Because of the space constraints, we omit the proofs of the results shown
here, but collect them in [7].
2
Preliminaries
In this section, we introduce the basic deﬁnitions and the notations used in the remainder
of the paper.
Deﬁnition 1 (Hybrid Automata [2]). A Hybrid Automaton is a tuple H = (L, E, X,
Init, Inv, F, G, R) with the following components:
• a ﬁnite set of locations L
• a ﬁnite set of discrete transitions (or jumps) E ⊆L × L
• a ﬁnite set of continuous variables X = {x1, . . . xn} that take values in R
• an initial set of conditions: Init ⊆L × Rn
• Inv: L →2Rn, the invariant location labeling
• F : L × Rn →Rn, assigning to each location ℓ∈L a vector ﬁeld F(ℓ, ·) that
deﬁnes the evolution of continuous variables within ℓ
• G : E →2Rn, the guard edge labeling
• R : E × Rn →2Rn, the reset edge labeling.

226
R. Gentilini, K. Schneider, and B. Mishra
We write v to represent a valuation (v1, . . . , vn) ∈Rn of the variables’ vector x =
(x1, . . . , xn), whereas ˙x denotes the ﬁrst derivatives of the variables in x (they all de-
pend on the time, and are therefore rather functions than variables). A state in H is a
pair s = (ℓ, v), where ℓ∈L is called the discrete component of s and v is called the
continuous component of s. A run of H = (L, E, X, Init, Inv, F, G, R), starts at any
(ℓ, v) ∈Init and consists of continuous evolutions (within a location) and discrete
transitions (between two locations). Formally, a run of H is a path with alternating con-
tinuous and discrete steps in the time abstract transition system of H, deﬁned below:
Deﬁnition 2. The time abstract transition system of the hybrid automaton H = (L, E,
X, Init, Inv, F, G, R) is the transition system TH =(Q,Q0, ℓ→, →), where:
• Q ⊆L × Rn and (ℓ, v) ∈Q if and only if v ∈Inv(ℓ)
• Q0 ⊆Q and (ℓ, v) ∈Q0 if and only if v ∈Init(ℓ) ∩Inv(ℓ)
• E ∪{δ} is the set of edge labels, that are determined as follows:
– there is a continuous transition (ℓ, v)
δ→(ℓ, v′), if and only if there is a differ-
entiable function f : [0, t] →Rn, with ˙f : [0, t] →Rn such that:
1. f(0) = v and f(t) = v′
2. for all ε ∈(0, t), f(ε) ∈Inv(ℓ), and ˙f(ε) = F(ℓ, f(ε)).
– there is a discrete transition (ℓ, v)
e→(ℓ′, v′) if and only if there exists an edge
e = (ℓ, ℓ′) ∈E, v ∈G(ℓ) and v′ ∈R((ℓ, ℓ′), v).
A region is a subset of the states Q of TH =(Q,Q0, ℓ→, →). Given a region B and
a transition label a ∈ℓ→, the predecessor region Prea(B) is deﬁned as the region
{q ∈Q | ∃q′ ∈B.q
a→q′}. The bisimulation and the simulation relations are two
fundamental tools in the context of hybrid automata abstraction.
Deﬁnition 3 (Bisimulation ). Let T 1 = (Q1, Q1
0, ℓ1
→, →1), T 2 = (Q2, Q2
0, ℓ2
→, →2)
be two edge-labeled transition systems and let P be a partition on Q1 ∪Q2. A bisimu-
lation for T1, T2 is a nonempty relation on ≡B⊆Q1 × Q2 such that, for all p ≡B q it
holds:
• p ∈Q1
0 iff q ∈Q2
0 and [p]P = [q]P, where [p]P denotes the class of q in P.
• for each label a ∈ℓ→, if there exists p′ such that p
a→p′, then there exists q′ such
that p′ ≡B q′ and q
a→q′.
• for each label a ∈ℓ→, if there exists q′ such that q
a→q′, then there exists p′ such
that p′ ≡B q′ and p
a→p′.
If there exists a bisimulation relation for T1, T2, then T1 and T2 are bisimilation equiv-
alent (or bisimilar), denoted T1 ≡B T2.
Deﬁnition 4 (Simulation). Let T 1 = (Q1, Q1
0, ℓ1
→, →1), T 2 = (Q2, Q2
0, ℓ2
→, →2) be
two edge-labeled transition systems and let P be a partition on Q1 ∪Q2. A simulation
from T1 to T2 is a nonempty relation on ≤S⊆Q1 × Q2 such that, for all p ≤S q:
• p ∈Q1
0 iff q ∈Q2
0 and [p]P = [q]P.
• for each label a ∈ℓ→, if there exists p′ such that p
a→p′, then there exists q′ such
that p′ ≤S q′ and q
a→q′.

Successive Abstractions of Hybrid Automata for Monotonic CTL Model Checking
227
If there exists a simulation from T1 to T2, then we say that T2 simulates T1, denoted
T1 ≤S T2. If T1 ≤S T2 and T2 ≤S T1, then T1 and T2 are said to be similation
equivalent (or similar) and we write T1 ≡S T2.
Deﬁnition 6 recapitulates the semantics of the temporal logic CTL (where the neXt
temporal operator is omitted because of the density of the underlying time framework)
on hybrid automata [1,10].
Deﬁnition 5 (CTL for Hybrid Automta). Let AP be a ﬁnite set of propositional letters
and p ∈AP. CTL is the set of formulæ deﬁned by the following syntax:
φ ::= p | ¬φ | φ1 ∧φ2 | Eφ1Uφ2 | Aφ1Uφ2 | Eφ1Rφ2 | Aφ1Rφ2
Deﬁnition 6 (CTL Semantics). Let H = (L, E, X, Init, Inv, F, G, R) be a hybrid
automaton, and let AP be a set of propositional letters. Consider ℓAP : L × X →2AP.
Given φ ∈CTL and s ∈Q, s |= φ is inductively deﬁned as follows:
• s |= p if and only if p ∈ℓAP(s)
• s |= ¬φ if and only if not s |= φ
• s |= φ1 ∨φ2 if and only if s |= φ1 or s |= φ2
• s |= Eφ1Uφ2 if and only if there exists a run ρ and a time t such that:
· ρ(t) |= φ2
· ∀t′ ≤t (ρ(t′) |= φ1 ∨φ2)
• s |= Aφ1Uφ2 if and only if for each run ρ there exists a time t such that:
· ρ(t) |= φ2
· ∀t′ ≤t (ρ(t′) |= φ1 ∨φ2)
• s |= Eφ1Rφ2
iff
s |= ¬(A¬φ1U¬φ2)
• s |= Aφ1Rφ2
iff
s |= ¬(E¬φ1U¬φ2)
H |= φ iff for each s ∈Q0, s |= φ.
2.1
O-Minimal Theories and O-Minimal Hybrid Automata
In this subsection, we give a brief introduction to order minimality (o-minimality) which
is used to deﬁne o-minimal hybrid automata. We refer to [21,20,22] for a more compre-
hensive introduction to o-minimality.
Consider a structure over the reals, M = ⟨R, <, . . .⟩, where the underlying language
includes at least a binary relation interpreted as the usual total order over R. The theory
Th(M) associated to M is the set of ﬁrst order sentences that hold in M. A set Y ⊆Rn
is deﬁnable in M if and only if there exists a ﬁrst order formula ψ(x1, . . . , xn) such
that Y = {(a1, . . . , an) | M |= ψ(a1, . . . , an)}. A map f : A →Rn with A ⊆Rm is
deﬁnable in M if and only if its graph Γ(f) ⊆Rm × Rn is deﬁnable in M.
Deﬁnition 7 (O-Minimal Structure). The structure M = ⟨R, <, . . .⟩is o-minimal if
and only if every deﬁnable subset of R is a ﬁnite union of points and (possibly un-
bounded) intervals. In this case, the theory Th(M) is also said to be o-minimal.

228
R. Gentilini, K. Schneider, and B. Mishra
Given an o-minimal structure M = ⟨R, <, . . .⟩, the notion of set deﬁnability is closed
under each boolean set composition operation, cartesian product, and projection. The
notion of map deﬁnability is closed under composition, cartesian product, and projec-
tion. In the following, we will use the same symbol to denote both a given o-minimal
structure and the corresponding theory, omitting the term Th(·).
The class of o-minimal structures over the reals is quite rich: both the structure
Li(R) = (R, <, +, −, 0, 1), used to express linear constraints over the reals, and
the ordered real ﬁeld OF(R) = (R, <, +, −, ∗, 0, 1) are o-minimal. The extensions of
the above structures by the exponential function are also o-minimal. Another important
extension is obtained by restricted analytic functions. Further extensions are discussed
in [13]. The variety of o-minimal theories over the reals ensures that the family of o-
minimal hybrid automata as introduced in [13,14] (cf. Deﬁnition 9, below) constitutes
a large and important family of hybrid automata, admitting powerful continuous evolu-
tions. In the following deﬁnitions, we will adopt the notation used in [13].
Deﬁnition 8. Let F : Rn →Rn be a smooth vector ﬁeld on Rn. For each v ∈Rn,
let γv(t) denote the integral curve of F which passes through v at t = 0, that is
˙γv(t) = F(γv(t)) and γv(0) = v. We say that F is complete if, for each v ∈Rn,
γv(t) is deﬁned for all t. For such an F, the ﬂow of F is the function φ : Rn ×R →Rn
given by φ(v, t) = γv(t).
Deﬁnition 9 (O-Minimal Hybrid Automata [13]). The hybrid automaton H = (L,
E, X, Init, Inv, F, G, R) is o-minimal if the following holds:
a) for each ℓ∈L the smooth vector ﬁeld F(ℓ, ·) is complete
b) for each (ℓ, ℓ′) ∈E, the reset function R : E →Rn does not depend on continuous
variables (constant resets)
c) for each ℓ∈L and (ℓ, ℓ′) ∈E, the sets Inv(ℓ), R(ℓ, ℓ′), G(ℓ), Init(ℓ), and the
ﬂow of F(ℓ, ·) are deﬁnable in the same o-minimal structure.
Given an o-minimal structure M, the o-minimal hybrid automata induced by M
are called o-minimal(M) hybrid automata. O-minimal hybrid automata admit a ﬁnite
bisimulation quotient [13]. Computability of such a bisimulation quotient (and hence
decidability) depends on the underlying o-minimal structure: in [14], the class of o-
minimal (OF(R)) hybrid automata and various subclasses of o-minimal (OFexp(R))
automata were proven to be decidable with respect to reachability.
3
A Succession of Abstractions for Monotonic CTL Model
Checking on Hybrid Automata
Throughout this section and Section 4, we solve the problem of deﬁning a succession of
abstractions for hybrid automata and a corresponding three valued semantics for CTL
formulæ with the following property: whenever a CTL formula is true (false) on a given
abstraction, its value is preserved on the hybrid automaton. Moreover, we require that
the set of formulæ evaluating to ⊥(according to the three valued semantics over the
abstractions) decreases monotonically in its size along the succession of abstractions.

Successive Abstractions of Hybrid Automata for Monotonic CTL Model Checking
229
Such a requirement is reminiscent of the usual regularity property for Kleene three
valued logics [12] (and its many variants [5]), according to which the behavior of the
third value is compatible with any increase of information1.
The ﬁrst idea we exploit is based on the classical notion of n-bounded bisimula-
tion. In fact, a simulation preorder relates successively ﬁner bounded bisimulations,
thus enabling the establishment of a ”monotonic truth-preservation result” for the set
of true universally quantiﬁed formulæ along this succession of abstractions. Since the
n-bounded bisimulation is characterized by the n-bounded modal logic (where at most
n neXt operators are admitted in the formulæ), it is possible to recover preservation for
non universal CTL formulæ, by evaluating them on n-bounded paths. The preceding
ideas can be effectively developed for the analysis of inﬁnite discrete transition systems.
However, in our context inﬁnite transition systems represent mixed continuous/discrete
systems. Hence, ﬁrst the neXt temporal operator is meaningless in the corresponding
logics. Second, a query such as s |= Eφ1Uφ2 can never be checked by considering
only a ﬁnite path departing from s in the time abstract transition system TH of a hybrid
automaton H. In fact, due to the dense nature of the underlying time framework, each
ﬁnite path of the kind z
δ→z′ subsumes an uncountable number of continuous transi-
tions’ inﬁnite paths in TH, on which Eφ1Uφ2 needs to be established. In other words,
while for Kripke structures modelling (inﬁnite) discrete dynamical systems, there is a
nice correspondence between the index of the bounded bisimulation and the length of
path that can be trusted, in the case of hybrid automata this is lost. More precisely, runs
that can be trusted in successive ﬁner bounded bisimulations could be never allowed to
traverse more than two locations, since they are abstracted by paths containing more
and more continuous transitions.
3.1
Discrete Bounded Bisimulation Abstraction
Motivated by the discussion above, we develop here a new succession of hybrid au-
tomata abstractions suitable for our purposes, and refer to them as discrete bounded
bisimulation abstractions. It is well known that the classic bisimulation equivalence can
be characterized as a coarsest partition stable with respect to a given transition relation
[11]. Bounded bisimulation imposes a bound on the number of times each edge can
be used for partition reﬁnement purposes. For discrete bounded bisimulation, the lat-
ter bound applies only to discrete edges. Formally, our discrete bounded bisimulation
abstractions are inductively deﬁned in Deﬁnition 10.
Deﬁnition 10 (Discrete Bounded Bisimulation (DBB)). Consider the time abstract
transition system TH = (Q, Q0, ℓ→, →) of a hybrid automaton H, and let P be a
partition on Q:
1. ≡0∈Q × Q is the maximum relation on Q such that for all p, q ∈Q:
if p ≡0 q then (a) [p]P = [q]P and p ∈Q0 iff q ∈Q0
(b) ∀p′(p
δ→p′ ⇒∃q′(p′ ≡0 q′ ∧q
δ→q′)
(c) ∀q′(q
δ→q′ ⇒∃p′(p′ ≡0 q′ ∧p
δ→p′)
1 Note that, in our framework, the lack of information is inherent in the abstraction of the hybrid
automaton model, rather than in the (indeﬁnite) value of some propositional letter.

230
R. Gentilini, K. Schneider, and B. Mishra
2. Given n ∈N+, ≡n is the maximum relation on Q such that for all p, q ∈Q:
if p ≡n q then (a) p ≡n−1 q
(b) ∀p′(p
δ→p′ ⇒∃q′(p′ ≡n q′ ∧q
δ→q′)
(c) ∀q′(q
δ→q′ ⇒∃p′(p′ ≡n q′ ∧p
δ→p′)
(d) ∀p′(p
e→p′ ⇒∃q′(p′ ≡n−1 q′ ∧q
e→q′)
(e) ∀q′(q
e→q′ ⇒∃p′(p′ ≡n−1 q′ ∧p
e→p′)
Given n ∈N, the relation ≡n will be referred to as n-DBB equivalence.
Deﬁnition 11 (Succession of DBB Abstractions ). Let TH = (Q, Q0, ℓ→, →) be the
time abstract transition system of the hybrid automaton H, let P be a partition on Q,
and consider the n-DBB equivalence ≡n. The n-DBB abstraction structure H/≡n =
(Q′, Q′
0, ℓ′
→, →) is deﬁned as:
– Q′ = Q/≡n, Q′
0 = Q0/≡n and ℓ′
→= ℓ→.
– ∀α, β ∈Q′:
• α
e→β iff ∃s ∈α, ∃q ∈β(s
e→q))
• α
δ→β iff ∃s ∈α, ∃q ∈β(s
δ→q by traversing the only regions α and β)
Lemma 1 establishes some folk theorems describing few properties of discrete bounded
bisimulation, and can be easily proved using an inductive argument. Among them, we
remark the existence of a simulation preorder relating successive elements in our suc-
cession of DBB abstractions. The latter property allows one to use the succession of
DBB structures to reﬁne an overapproximation of the underlying hybrid automaton
reachable set.
Lemma 1. Let H be a hybrid automaton, and consider the succession of n-DBB ab-
stractions ⟨H/≡n⟩n∈N. For all n ∈N:
– TH ≤S H/≡n and H/≡n+1 ≤S H/≡n.
– If H/≡n coincides with H/≡n+1, then TH ≡B H/≡n.
As a consequence of Lemma 2, it is also possible to use the succession of DBB abstrac-
tions to obtain ⊆-monotonic underapproximations of the underlying hybrid automaton
reachable set. More precisely, H/≡n preserves the reachability of a given region of in-
terest (in the initial partition), whenever the latter can be established on H following a
path that traverses at most n locations. Given two states in a hybrid automaton H, we
use the notation q
n⇝q′ to state that q′ is reachble from q following a run that contains
at most n discrete edges (i.e. traverses at most n locations of H).
Lemma 2. Let p and q be two states in a hybrid automaton H and let ≡n be the n-DBB
equivalence on TH with respect to a partition P. If p ≡n q, then for all m ≤n it holds
that:
– For all p′ such that p
m
⇝p′, there exists q′ such that p′ ≡n−m q′ and q
m
⇝q′.
– For all q′ such that q
m
⇝q′, there exists p′ such that p′ ≡n−m q′ and p
m
⇝p′.

Successive Abstractions of Hybrid Automata for Monotonic CTL Model Checking
231
3.2
Finiteness and Computability of DBB Abstractions
Figure 1 presents a semi-decision procedure to obtain the n-DBB equivalence on the
time-abstract transition system of a hybrid automaton H. Such a semi-decision proce-
dure takes as input the hybrid automaton H, the bound n, and an initial (ﬁnite) par-
tition P0 over the state-space of H. As stated in Lemma 3, it constitutes an effective
algorithm for n-DBB equivalence whenever it is computable and gets to termination.
Clearly, while computability depends on disposing of opportune symbolic techniques
to represent and manipulate sets of states, termination is related to the n-DBB quotient
ﬁniteness.
Lemma 3. Let n∈N; let H be a hybrid automaton; and let P0 be a ﬁnite partition over
the state-space of H. If DBB(n, H,P0) terminates, then algorithm DBB(n, H, P0)
computes the quotient of the n-DBB equivalence with respect to P0 on TH.
Using a number of techniques developed in [13,14], it is rather easy to obtain n-DBB
ﬁniteness and computability results for the broad undecidable family of fully o-minimal
hybrid automata (cfr. Deﬁnition 12). The latter extends the o-minimal based systems
in [13] by admitting arbitrary o-minimal functions as resets, in place of constant func-
tions. Such a relaxation in the formulation of the discrete dynamics allows the family to
encompass several classes of hybrid automata for which the reachability problem has
been proven undecidable (e.g. the class of uninitialized rectangular automata [10,9], or
the undecidable classes studied in [3,15]).
Deﬁnition 12 (Fully O-Minimal Hybrid Automata). The hybrid automaton H = (L,
E, X, Init, Inv, F, G, R) is fully o-minimal iff:
a) for each ℓ∈L the smooth vector ﬁeld F(ℓ, ·) is complete
b) for each ℓ∈L and (ℓ, ℓ′) ∈E, the sets Inv(ℓ), G(ℓ), Init(ℓ), the reset function
R(ℓ, ℓ′) : R|X| →R|X| and the ﬂow of F(ℓ, ·) are deﬁnable in the same o-minimal
structure.
Theorem 1. Let H be a fully o-minimal(M) hybrid automaton, and let P be an ini-
tial ﬁnite partition over the state-space of H deﬁnable in M. Then, the algorithm
DBB(n, H, ℓQ) terminates for any n ∈N.
By Theorem 1, the whole family of fully o-minimal automata have for all n ∈N a
ﬁnite n-DBB abstraction structure. Computability of such a ﬁnite abstraction is instead
parameterized with respect to the theory underlying fully o-minimal automata. In par-
ticular, as stated in Corollary 1, the class of fully o-minimal (OF(R)) hybrid automata
has a ﬁnite and effectively computable n-DBB abstraction. The result depends on the
fact that OF(R) is a decidable theory admitting quantiﬁer elimination. Therefore, the
theory OF(R) provides the means for representing sets, computing post-images and
boolean compositions, as well as checking for set emptiness. Techniques similar to the
ones adopted in [13] can be used to obtain further computability results on subclasses
of o-minimal(OFexp(R)) hybrid automata.
Corollary 1. Given n ∈N, the n-DBB abstraction on fully o-minimal (OF(R)) hybrid
automata is ﬁnite and computable.

232
R. Gentilini, K. Schneider, and B. Mishra
DBB(n, H, P0)
(1)
Let P be the coarsest partition reﬁning P0 compatible with Q0
/*————–Compute 0-DBB equivalence quotient—————————————*/
(2)
while (∃B, B′ ∈P such that ∅̸= B ∩Preτ(B′) ̸= B)
(3)
B1 ←B ∩Preτ(B′); B2 ←B \ Preτ(B′);
(4)
P ←(P \ {B}) ∪{B1, B2};
/*————–Perform n reﬁnement steps to obtain n-DBB equivalence quotient—*/
(5)
while (n > 0)
(6)
n ←n −1; Pold ←P;
(7)
for each (e = (ℓ, ℓ′) ∈E)
(8)
for each (B′ ∈Pold, B ∈P such that ∅̸= B ∩Pree(B′) ̸= B)
(9)
B1 ←B ∩Pree(B′); B2 ←B \ Pree(B′);
(10)
P ←(P \ {B}) ∪{B1, B2};
(11)
while (∃B, B′ ∈P such that ∅̸= B ∩Preτ(B′) ̸= B)
(12)
B1 ←B ∩Preτ(B′); B2 ←B \ Preτ(B′)
(13)
P ←(P \ {B}) ∪{B1, B2};
(14) return P
Fig. 1. Partition reﬁnement algorithm for n-DBB equivalence
Corollary 2. Let H be a fully o-minimal(OFexp(R)) hybrid automaton in which:
– for each ℓ∈L, the vector ﬁeld is of the form F(ℓ, x) = Ax, where:
1. A ∈Q × Q is nilpotent or
2. A ∈Q × Q is diagonalizable with rational eigenvalues or
3. A ∈Q × Q has purely imaginary eigenvalues of the form ir, r ∈Q, with
diagonal real Jordan form.
– for each ℓ∈L and (ℓ, ℓ′) ∈E, the sets Inv(ℓ), G(ℓ), Init(ℓ), and the reset
function R(ℓ, ℓ′) : X →X are deﬁnable inside OF(R).
Then, for all n ∈N, ≡n is ﬁnite and computable on H.
4
3-Valued CTL Semantics over DBB Abstractions
In this section we introduce a 3-valued semantics for the logic CTL on n-DBB ab-
stractions. Such a three valued semantics exploits, besides the inductive deﬁnition of
DBB abstractions, the simulation preorder relating successive DBB abstractions in the
succession ⟨H/≡n ⟩n∈N. The latter allows us to use unbounded runs in the evaluation
of (not purely existential) CTL properties. In other words, each CTL\ECTL formula
is not constrained to be evaluated by looking exclusively at paths in H/≡n abstracting
bounded runs of H, to obtain a value in {tt, ﬀ, ⊥} \ {⊥}. This key point needs to be
emphasized, since it endows our framework with the abilities to handle both refutations
as well as proof of safety or liveness properties over a hybrid automaton H. In fact,
such properties intrinsically model some conditions that need to be maintained along
the whole evolution of any run in H.

Successive Abstractions of Hybrid Automata for Monotonic CTL Model Checking
233
Deﬁnition 13. Let H be a hybrid automaton having state space Q, let AP be a ﬁnite
set of atomic propositions, and let P be the partition on Q induced by the labelling
function ℓAP : Q →2|AP|. Consider the n-DBB abstraction of H with respect to P,
H/≡n. Given the node [s]≡n in H/≡n, the value [[s]≡n|=3φ] ∈{tt, ﬀ, ⊥} is inductively
deﬁned on n as follows:
– If φ = p, then [[s]≡n|=3φ] is deﬁned as:
tt
iff
p ∈ℓAP([s]≡n))
ﬀ
iff
p /∈ℓAP([s]≡n))
– If φ = ¬φ1, then [[s]≡n|=3φ] is deﬁned as:
⎧
⎨
⎩
tt
iff
[[s]≡n|=3φ1] = ﬀ;
ﬀ
iff
[[s]≡n|=3φ1] = tt;
⊥
otherwise.
– If φ = φ1 ∧φ2, then [[s]≡n|=3φ] is deﬁned as:
⎧
⎨
⎩
tt
iff
[[s]≡n|=3φ1] = tt ∧[[s]≡n|=3φ2] = tt;
ﬀ
iff
[[s]≡n|=3φ1] = ﬀ∨[[s]≡n|=3φ2] = ﬀ;
⊥
otherwise
– If φ = Eφ1Uφ2, then [[s]≡n|=3φ] is deﬁned as:
⎧
⎪
⎪
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎪
⎪
⎩
tt
iff there exists a path ⟨[si]≡n⟩0≤i≤k such that:
(1) ∀i < k ([si]≡n
δ→[si+1]≡n ∧[[si]≡n|=3φ1 ∨φ2] = tt)
(2) [[sk]≡n|=3φ2] = tt ∨([sk]≡n
e→[sk+1]≡n ∧[[sk+1]≡n−1|=3φ] = tt)
ﬀ
iff for each path ⟨[si]≡n⟩i∈N it holds:
∀i ∈N ([[si]≡n|=3φ2] = tt →(∃j < i([[sj]≡n|=3¬φ1 ∧¬φ2] = tt)))
⊥
otherwise
– If φ = Aφ1Uφ2, then [[s]≡n|=3φ] is deﬁned as:
⎧
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎩
tt
iff for each path ⟨[si]≡n⟩i∈N there exists an index k such that:
(1) ∀i < k ([[si]≡n|=3φ1 ∨φ2] = tt)
(2) [[sk]≡n|=3φ2] = tt
ﬀ
iff there exists a path ⟨[si]≡n⟩i≤k such that:
(1) ∀i < k ([si]≡n
δ→[si+1]≡n ∧[[si]≡n|=3¬φ1 ∨¬φ2] = tt)
(2) [[sk]≡n|=3¬φ1] = tt ∨([sk]≡n
e→[sk+1]≡n ∧[[sk+1]≡n−1|=3φ] = ﬀ)
⊥
otherwise
– If φ = Eφ1Rφ2, then [[s]≡n|=3φ] = [[s]≡n|=3¬(A¬φ1U¬φ2)].
– If φ = Aφ1Rφ2, then [[s]≡n|=3φ] = [[s]≡n|=3¬(E¬φ1U¬φ2)].
Finally, H/≡n|=3φ is deﬁned as:
⎧
⎨
⎩
tt
iff
∀[s]≡n ∈Q0
/≡n([[s]≡n|=3φ1] = tt);
ﬀ
iff
∃[s]≡n ∈Q0
/≡n([[s]≡n|=3φ1] = ﬀ);
⊥
otherwise

234
R. Gentilini, K. Schneider, and B. Mishra
Theorem 2 (Preservation). Let H/≡n be the n-DBB abstraction for a hybrid automa-
ton H, and let φ be a CTL formula. If [H/≡n|=3φ] = tt, then H |= φ; If [H/≡n |=3φ] =
ﬀ, then ¬(H |= φ).
Theorem 3 (Monotonicity). Let ⟨H/≡n⟩n∈N be the succession of DBB abstractions
for a hybrid automaton H. For any CTL formula φ, for any n ∈N it holds:
([H/≡n|=3φ] = b ∧b ∈{tt, ﬀ}) →∀m > n([H/≡m |=3φ] = b)
5
A Linear Algorithm for 3-Valued CTL Model Checking on
Discrete Bounded Bisimulation Abstractions
In this Section we deﬁne an efﬁcient algorithm for the three valued CTL model check-
ing on bounded bisimulation abstractions, assuming the latter to be ﬁnite. Classical
CTL model checking over Kripke structures is known to be linear in the size of the
structure and in the length of the formula; analogously the complexity of our three val-
ued model checking procedure is linear in the size of the abstraction and in the length
of the formula.
5.1
The Case of 3-Valued ECTL∪ACTL Model Checking
We start solving a simpler problem: Namely, the deﬁnition of a procedure for the eval-
uation of [H/≡n|=3φ], where φ is either a universal or an existential formula of CTL.
Let φ be an ACTL formula, and let α be a node in H/≡n. According to Deﬁnition 13,
[α|=3φ] = tt iff α |= φ (with respect to the classical 2-valued semantics for CTL on
the ﬁnite transition system H/≡n). Hence, it is sufﬁcient to use a classical (2-valued)
CTL model checking algorithm on H/≡n to detect those nodes in H/≡n for which
[α|=3φ] = tt in time O(|H/≡n | ∗|φ|).
The problem of collecting the nodes α in H/≡n for which [α|=3φ] = ﬀreduces to
the problem of (1) rewriting ¬φ as a formula γ in ECTL (2) determining the set of states
α in H/≡n for which [α|=3γ] = tt.
Summarizing the above observations, we can derive an overall O(|H/≡n | ∗|φ|) al-
gorithm for computing H/≡n|=3φ, if we prove that it is possible to recognize all those
nodes α for which [α|=3γ] = tt, γ ∈ECTL, in time O(|H/≡n | ∗|γ|).
Let γ be an ECTL formula: we solve the above subproblem by employing an efﬁcient
(O(|H/≡n|∗|γ|)) strategy to distribute on the nodes in H/≡n the set of labels ⟨ψ, tt, m⟩,
where:
– ψ is a subformula of γ and m ≤n.
– α = [s]n receives the label ⟨ψ, tt, m⟩if and only if
[[s]m|=3ψ] = tt ∧∀m′ < m([[s]m′|=3ψ] = ⊥)
Our strategy uses a structural induction on γ. The cases in which γ is either a propo-
sitional letter or a boolean composition of subformulæ are easily dealt with (cfr. lines
(1.1)–(2.4) of the procedure PROCESSE in Figure 2).

Successive Abstractions of Hybrid Automata for Monotonic CTL Model Checking
235
Fig. 2. The linear algoithm for ACTL∪ECTL 3-valued Model Checking on H/≡n

236
R. Gentilini, K. Schneider, and B. Mishra
The case for which γ = Eγ1Uγ2 requires instead more attention. As illustrated in
Figure 2 (cfr. lines (3.1)–(3.12) of the procedure PROCESSE), given N = |H/≡n|,
we ﬁrst build the two vectors A1[1, . . . , N], A2[1, . . . , N] of lists of nodes in H/≡n,
where α ∈Aj[i] iff the label ⟨γj, tt, i⟩has been inductively associated to α. Note that,
A1[1 . . . N] (resp. A2[1 . . . N]) requires space O(|H/≡n|), since the lists in each slot of
the array A are disjoint. Then, by induction on i = 0 . . . n, we build the sets S0, . . . , Sn,
where Si contains all the nodes of H/≡n that need to be labeled with ⟨γ, tt, i⟩. More
precisely, such a building process is supported by a coloring marking in which a node
is red if it has been already assigned to some Sj<i; A node is yellow if it admits a
transition to a red node; A node is green otherwise. Given the above coloring we let Si
to contain:
– Each not red node in the list A2[i].
– Each yellow node in the list A1[i].
– Each node β ∈H/≡n admitting a path p to Si−1 such that:
1. p contains at most one edge labeled e
2. the label ⟨γ1 ∨γ2, tt, i⟩is associated to each node of p.
Finally, if γ = Eγ1Rγ2, we can reduce to process the formula γ′ = Eγ2Uγ1 according
to the three-valued CTL semantics in Deﬁnition 13. The pseudocode of the overall
algorithm above sketched for determining [H/≡n|=3φ], φ ∈ECTL∪ACTL, is reported
in Figure 2. Given the formula φ ∈ECTL ∪ACTL in negation normal form, Theorem
4 states that our procedure ALGO1(H/≡n, φ) computes the value [H/≡n|=3φ] in time
O(|H/≡n | ∗|φ|) and space O(|H/≡n|).
Theorem 4. The algorithm ALGO1(H/≡n, n, φ) computes [H/≡n|=3φ] ∈{tt, ﬀ⊥} in
time O(|H/≡n| ∗|φ|) and space O(|H/≡n|).
5.2
3-Valued CTL Model Checking
In this Subsection we extend the techniques outlined in Subsection 5.1 to design a
O(|H/≡n |∗|φ|) algorithm for computing H/≡n|=3φ, where φ is a general CTL formula.
We start with some preliminary observations to illustrate the bottlenecks related to the
above extension. Let φ1 = EpUq, let φ2 = ApUq, and consider the two formulæ
belonging to CTL \ (ECTL ∪ACTL): ψ1 = ArUφ1 and ψ2 = ErUφ2.
Since φ1, φ2, and r belong to ECTL∪ACTL, we can assume to have determined with
ALGO1 the set of nodes α in H/≡n for which [α|=3ς] = tt, ς ∈{φ1, φ2, r}. Then, the
task of processing the formula ψ1 = ArUφ1 according to Deﬁnition 13 does not present
any problem. In fact, determining each node β for which [β|=3φ] = tt boils down to
applying a classical model checking subprocedure targeting the operator AU (where
the precomputed labelling is interpreted in a 2-valued fashion and ⊥corresponds to ﬀ,
according to a ’pessimistic view’).
Instead, we face the following problem in processing the formula ψ2 = ErUφ2
above, according to the 3-valued semantics in Deﬁnition 13. Namely, for each α =
[s]≡n such that [α|=3φ2] = tt, we need to know the least m ≤n for which [[s]≡m|=3φ2] =
tt. If φ2 were a formula having an existential main path quantiﬁer, say φ2 = ∃φ3Uφ4,
then such minimum indexes would have been dependent on the number of discrete

Successive Abstractions of Hybrid Automata for Monotonic CTL Model Checking
237
Fig. 3. The linear CTL 3-valued Model Checking on H/≡n
edges that one needs to traverse to evaluate φ2 (assuming a previous labeling relative to
φ3 and φ42). However, formulæ having a main universal path quantiﬁer are evaluated
by considering any path in H/≡n, regardless of the number of discrete edges traversed.
Our solution to recover the required minimum indexes for formulæ having a main uni-
versal path quantiﬁer, is that of disposing of a data structure that we call compact par-
tition tree, requiring space O(|H/≡n |). The formal description of a compact partition
tree is given in Deﬁnition 14.
Deﬁnition 14 (Compact Partition Tree associated to H/≡n). Let H be a hybrid au-
tomaton. The compact partition tree Tn associated to H/≡n is inductively deﬁned as:
– T0 is a tree of depth one in which each leaf f is associated to a distinct node
α ∈H/≡n and is labeled with the triple ℓ(f) = ⟨0, 0, α⟩.
– Tn+1 is obtained from Tn processing each leaf f in Tn according to the following
procedure:
2 In fact, the indices m are determined ’on the ﬂy’ in our procedure PROCESSE for ECTL.

238
R. Gentilini, K. Schneider, and B. Mishra
• If f is labeled with the triple ⟨m, n −1, α⟩, and α is a class of H/≡n, then let
ℓ(f) = ⟨m, n, α⟩.
• Otherwise, substitute the label of f with the pair ℓ(f) = ⟨m, n −1⟩. For each
αi ⊆α, αi ∈H/≡n, create a new successor of f, fi, and associate to fi the
label ⟨n, n, αi⟩.
Lemma 4. Let H be a hybrid automaton. The space complexity of the compact parti-
tion tree associated to H/≡n is O(|H/≡n |).
Compact partition trees can be easily computed along discrete bounded bisimulations.
Let φ ∈CTL, and assume that the main path quantiﬁer in φ is universal. Suppose having
determined the set of nodes S = {[s]≡n ∈H/≡n |[[s]≡n|=3φ] = tt}. Then, the compact
partition tree Tn can be used as follows to associate to each node α = [[s]≡n ∈S (in
time O(|H/≡n |)) the required label ⟨φ, tt, m⟩, where m is the minimum index such that
[[s]≡m|=3φ] = tt. First we use a depth ﬁrst search-like algorithm to discover each node
k of Tn satisfying the two conditions listed below:
1. any leaf of Tn which is a descendant of the node k is associated to a class α ∈H/≡n
for which α|=3φ] = tt
2. k is a node of minimal depth having property 1.
If [m, m′] is the interval labeling k, then each class α associated to a leaf-descendant of
k needs to be labeled by the triple ⟨φ, tt, m⟩.
The ideas sketched above lead to the ﬁnal algorithm3 reported in Figure 3, which
computes [H/≡n|=3φ], where φ ∈CTL, in time O(|H/≡n|∗|φ|) and space O(|H/≡n |).
Theorem 5. The algorithm ALGO2(H/≡n, Tn, n, φ, γ) computes [H/≡n|=3φ] ∈{tt,
ff⊥} in time O(|H/≡n | ∗|φ|) and space O(|H/≡n |).
6
Conclusions
This paper has proposed a novel framework to extend the power of automated reasoning
over hybrid automata, even when those automata are undecidable in classical CTL. In
this framework, it is possible to both prove and disprove reactive system properties
expressed by means of CTL logic on (undecidable) hybrid automata. To the best of
authors’ knowledge, this research is novel and points to a fresh approach, as no other
currently available symbolic technique analyzing undecidable hybrid automata can cope
with both proofs and refutations of such general reactive systems properties as safety
or liveness. The key ingredients of this innovative framework consist of proof systems,
built upon a succession of abstractions and a corresponding three valued semantics for
the CTL logic, which in turn allows for the monotonic preservation of true and false
properties along these successive abstractions. This paper further proves that the new
three valued model checking problem is not only decidable on our DBB abstractions,
but is as efﬁcient as the classical model checking of discrete Kripke structures, as it is
linear in the length of the formula and in the size of the abstraction.
3 The subprocedures used in the main algorithm ALGO2 are illustrated in the Appendix.

Successive Abstractions of Hybrid Automata for Monotonic CTL Model Checking
239
References
1. R. Alur and D. L. Dill.
A theory of timed automata.
Theoretical Computer Science,
126(2):183–235, 1994.
2. R. Alur, T. Henzinger, G. Lafferriere, and G. Pappas. Discrete abstractions of hybrid systems.
Proceedings of the IEEE, 88:971–984, 2000.
3. T. Brihaye, C. Michaux, C. Rivie, and C. Troestler. On o-minimal hybrid systems. In Proc.
of the 7th Int. Workshop on Hybrid Systems, pages 219–233, 2004.
4. E. Clarke, O. Grumberg, and D. Peled. Model Checking. MIT Press, 1999.
5. M. Fitting. Kleene’s three valued logics and their children. Fundam. Inf., 20(1-3):113–131,
1994.
6. M. Fr¨anzle. What will be eventually true of polynomial hybrid automata? In Proc. of Int.
Symp. on Theoretical Aspects of Computer Software, volume 2215 of LNCS, pages 340–359.
Springer, 2001.
7. R. Gentilini, B. Mishra, and K. Schneider. Successive abstractions of hybrid automata for
monotonic CTL model checking. Technical report, Kaiserslautern University, 2007.
8. R. Ghosh, A. Tiwari, and C. Tomlin. Automated symbolic reachability analysis with applica-
tion to delta-notch signaling automata. In Hybrid Systems: Computation and Control HSCC,
volume 2623 of LNCS, pages 233–248. Springer, 2003.
9. T. Henzinger, P. Kopke, A. Puri, and P. Varaiya. What’s decidable about hybrid automata?
In Proc. of the 27th Symposium on Theory of Computing, pages 373–382. ACM Press, 1995.
10. T. A. Henzinger. The theory of hybrid automata. In Proc. of the 11th IEEE Symp. on Logic
in Computer Science, pages 278–292. IEEE Computer Society, 1996.
11. P. C. Kannellakis and S. A. Smolka. CCS expressions, ﬁnite state processes, and three prob-
lems of equivalence. Information and Computation, 86(1):43–68, 1990.
12. S. C. Kleene. Introduction to Metamathematics. Wolters-Noordhoff, Groningen, 1971.
13. G. Lafferriere, G. Pappas, and S. Sastry. O-minimal hybrid systems. Mathematics of Control,
Signals, and Systems, 13:1–21, 2000.
14. G. Lafferriere, J. Pappas, and S. Yovine. A new class of decidable hybrid systems. In Proc.
of the 2nd Int. Workshop on Hybrid Systems, pages 137–151. Springer, 1999.
15. J. Miller. Decidability and complexity results for timed automata and semi-linear hybrid
automata. In Proc. of the 3th Int. Workshop on Hybrid Systems, pages 296–309, 2000.
16. C. Piazza, M. Antoniotti, V. Mysore, A. Policriti, F. Winkler, and B. Mishra. Algorithmic
algebraic model checking i: Challenges from systems biology. In Proc. of the 17th Int. Conf.
on Computer Aided Veriﬁcation, volume 3576 of LNCS, pages 5–19. Springer, 2005.
17. S. Ratschan and Z. She. Safety veriﬁcation of hybrid systems by constraint propagation based
abstraction reﬁnement. In Proc. of the 8th Int. Workshop on Hybrid Systems: Computation
and Control, volume 3414 of LNCS, pages 573–589. Springer, 2005.
18. K. Schneider. Veriﬁcation of Reactive Systems. Springer Verlag, 2004.
19. A. Tiwari and G. Khanna. Series of abstractions for hybrid automata. In Proc. of the 5th
International Workshop on Hybrid Systems, pages 465–478. Springer-Verlag, 2002.
20. L. van den Dries. O-minimal structures. In W. Hodges, editor, Logic: From Foundations to
Applications, pages 99–108. Clarendon Press, 1996.
21. L. van den Dries. Tame topology and o-minimal structures, volume 248 of London Math.
Soc. Lecture Note Ser. Cambridge University Press, 1998.
22. A. J. Wilkie. Schanuel conjecture and the decidability of the real exponential ﬁeld. Algebraic
Model Theory, pages 223–230, 1997.

240
R. Gentilini, K. Schneider, and B. Mishra
Appendix
Fig. 4. The four subrocedures used within the algorithm ALGO2, in Figure 3

Explicit Proofs in Formal Provability Logic
Evan Goris
The Graduate Center of the City University of New York
365 Fifth Avenue, 10016 New York, NY, U.S.A.
evangoris@gmail.com
Abstract. In this paper we answer the question what implicit proof
assertions in the provability logic GL can be realized by explicit proof
terms. In particular we show that the fragment of GL which can be
realized by generalized proof terms of GLA is exactly S4 ∩GL and equals
the fragment that can be realized by proof-terms of LP. In the ﬁnal
sections of this paper we establish the disjunction property for GLA and
give an axiomatization for GL ∩S4.
1
Introduction
One of the most striking applications of classical propositional modal logic to
mathematics is without much doubt the interpretation of □as ‘provable in Peano
Arithmetic PA’ (for a neat introduction to the purpose of this see [6], we will
aim here at a quick technical treatment). The normality axiom (1) below is a
a most simple and clear example of a modal formula with an intuitively clear
‘provable in PA’ interpretation:
□(A →B) →(□A →□B).
(1)
Clearly this scheme expresses the rule of modus ponens. The project of studying
provability (and other meta-mathematical notions) in an axiomatic setting using
modal logic, originally suggested by G¨odel, really came to ﬂourish after the
arithmetical completeness theorem of Solovay [15]. This theorem identiﬁes the
logic GL as the logic of provability, see also [8]. GL is a remarkable system of
modal logic that not only proofs G¨odel’s second incompleteness theorem, and
more generally a formalized version of L¨ob’s Theorem, but even satisﬁes a ﬁxed-
point theorem, very much in the spirit of G¨odel’s ﬁxed-point lemma but in a
purely propositional setting.
However, G¨odel originally suggested the modal logic S4 as the logic of prov-
ability. This is indeed a most natural candidate for a provability logic but as it
turns out incompatible with GL (the least normal modal logic extending both is
the inconsistent one). Basically when the □is read as provable the schemes ex-
pressed by S4 are both too strong (reﬂection) and too weak (no L¨ob’s Theorem).
Artemov’s Logic of Proofs LP was invented to tackle this problem [5,1]. In
LP the □’s are replaced by proof-terms and the notion under study switched
from is provable to is proved by. These proof-terms are build up from axiom-
constants, proof-variables and function symbols that represent eﬀective opera-
tions on proofs. For example there is a binary function symbol · that constructs
S. Artemov and A. Nerode (Eds.): LFCS 2007, LNCS 4514, pp. 241–253, 2007.
c
⃝Springer-Verlag Berlin Heidelberg 2007

242
E. Goris
from a proof x of A →B and a proof y of A a proof x·y of B. Which gives a
means to express the rule of modus ponens, just as (1) but now in an explicit way:
x:(A →B) →(y:A →(x·y):B).
There are natural translations between modal formulas and LP-formulas. In
one direction we can ‘forget’ the proof-terms in an LP formula by substituting
□’s for them (forgetful-projection) and in the other direction we can substitute
proof-terms for the □’s in a modal formula (realizations). The link of LP with
S4 is as follows. For any theorem F of LP, the forgetful projection of F is a
theorem of S4 and for any theorem A of S4 there exists a realization of A that is
a theorem of LP. The latter is nicely formulated as LP can realize all theorems of
S4. This, together with the arithmetical completeness theorem for LP does give
a provability reading to S4 for which S4 is complete.
In [16] and [12] (cf. also [4]) the axiomatic study of provability (Provability
Logic) and the axiomatic study of proofs (Logic of Proofs) are combined in a
single logic that contains both the □for formal provability and proof-terms for
explicit proofs. The logic LPP from [16] contains a richer language of proof-
terms than LP. In [12] this is shown to be not necessary, there an arithmetically
complete logic GLA 1 has been recovered that has exactly the same term language
as LP.
Recently F. Montagna posed the question whether GLA allows for the real-
ization of more modal formulas than just S4 (given what we know about LP it
is immediate that GLA realizes at least S4). A negative answer to this question
is the main contribution of this paper.
This paper is organized as follows. In Section 2 we deﬁne the Logic of Proofs
LP. In Section 3 we deﬁne the Logic of Proofs and Formal Provability GLA and
formulate the main research question addressed in this paper. In Section 4 we
give an answer to these questions. In the ﬁnal sections of this paper we consider
some related issues and give some directions for further research.
2
Logic of Proofs
See [3] for an extensive overview of LP. Here we only state the basic deﬁnitions
and theorems relevant to this paper. The language of LP is two-sorted. We have
proofs terms that are build up using
– Countably many proofs variables x, y, z, . . . and countably many axiom con-
stants a, b, c, . . .
and two binary function symbols +, · and a unary one !:
– if t and s are proof terms then so are t+s, t·s and !t.
1 GLA was ﬁrst introduced (under the name LPGL) supplied with Kripke-style seman-
tics and proved to be arithmetically complete in E. Nogina’s part of [4].

Explicit Proofs in Formal Provability Logic
243
And we have LP formulas, which are generated by the following clauses.
– ‘Propositional Logic’,
– If F is a formula and t a proof term then t:F is a formula.
We say that an LP formula F is normal when all negative occurrences oﬀsub-
formulas t:G of F are of the form x:G, where x is a proof variable.
The logic LP is axiomatized by the following schemata and rules.
A0 ‘Classical Propositional Logic’ (with Modus Ponens),
A1 t:A →A,
A2 s:(A →B) →t:A →(s·t):B,
A3 s:A →(s + t):A, s:A →(t + s):A,
A4 t:A →!t:(t:A),
A5 c:A, c an axiom constant and A an instance of A0-A4.
If F is an LP formula then its forgetful projection F ◦is obtained by replacing
all the proof terms by □’s. More formally:
– p◦≡p and ⊥◦≡⊥,
– (A →B)◦≡(A◦→B◦),
– (t:A)◦≡□(A◦).
A realization of a modal formula F is an LP formula G for which G◦≡F.
One of the fundamental theorems concerning LP is the following.
Theorem 1 (Artemov[1]). S4 ⊢G iﬀthere exists a normal F such that LP ⊢
F and F ◦≡G.
Anther fundamental theorem concerning LP is its arithmetical completeness the-
orem [1]. See also [2,9]. In the spirit of the arithmetical reading of modal formulas
□F as ‘F is provable’ ([15,8]), formulas of the form t:F are read as ‘t is a proof
of F’. By Theorem 1 this provides us with a natural provability semantics for
modal logic for which S4 is complete. Given this interpretation of LP it is natu-
ral to consider a system that includes both expressions of the form □F and t:F.
This has been done in detail in [16,12]. However natural liftings of Theorem 1
have not been addressed yet and one of those liftings is the main topic of this
paper.
3
The System GLA
In this section we present the logic GLA from [12] and formulate two questions
that will be answered in the remainder of the paper.
A joint logic of formal provability and explicit proofs has ﬁrst been studied in
[16]. The logic there however has a richer language of explicit proofs than LP. In
[12] (cf. also [4]) a logic GLA, also a joint logic of formal provability and explicit
proofs has been recovered in which the language of explicit proofs is exactly that
of LP. This is the system we will study here.

244
E. Goris
The language of GLA is that of LP enriched with the modal operator □. The
formulas of the system GLA are generated by the following rules.
– ‘Propositional Logic’,
– if A is a formula and t is a proof term then t:A is a formula,
– if A is a formula then □A is a formula.
The logic GLA is axiomatized by the following axiom schemata and rules.
– ‘Classical Propositional Logic’,
– Provability Logic GL:
L1 □(A →B) →(□A →□B),
L2 □A →□□A,
L3 □(□A →A) →□A,
• ⊢A implies ⊢□A.
– Logic of Proofs LP:
A1 t:A →A,
A2 s:(A →B) →t:A →(s·t):B,
A3 s:A →(s + t):A, s:A →(t + s):A,
A4 t:A →!t:(t:A),
A5 c:A, c an axiom constant and A an instance of A0-A4, L1-L3 or C1-C3.
– Connecting principles:
C1 t:A →□A,
C2 ¬t:A →□¬t:A,
C3 t:□A →A.
Notice that A5 is richer than its analog in LP. The forgetful projection of an
LP formula obviously generalizes to GLA formulas by setting (□A)◦≡□A◦. The
following question about GLA will be addressed.
For which modal formulas A can we ﬁnd □-free GLA formulas B with B◦≡A
and GLA ⊢B.
As we will argue in the next subsection, the obvious generalization of the forgetful
projection to GLA formulas as given above does not give us much to work with
for solving this question. But ﬁrst we ﬁnish this section with a few lemmata from
[12] that will be of interest later.
In what follows we write
GLA : X1, . . . , Xn ⊢Y1, . . . , Yk
for the assertion that Y1 ∨· · ·∨Yk is provable using modus ponens only from the
theorems of GLA and X1, . . . , Xn.
Lemma 1. For any formula A there exists a term t such that
GLA ⊢x:A →t:□A
Proof. We have GLA ⊢c:(x:A →□A) and GLA ⊢x:A →!x:(x:A). Thus GLA ⊢
x:A →(c·!x):□A

Explicit Proofs in Formal Provability Logic
245
Lemma 2 (Constructive necessitation). If GLA ⊢A then for some ground
term t we have GLA ⊢t:A.
Proof. Induction on a GLA derivation of A. If A is one of the axioms other than
A5 we can take any axiom constant for t. If A is an instance of A5, say A ≡a:B,
then we can take !a for t. Suppose A is obtained by modus ponens from B →A
and B. Thus GLA ⊢B →A and GLA ⊢B. By (IH) we have terms t1 and
t2 such that GLA ⊢t1:(B →A) and GLA ⊢t2:B. And thus for t we can take
t1·t2. Suppose that A is obtained from B using necessitation. Thus GLA ⊢B.
By (IH) we have GLA ⊢t:B for some t. By Lemma 1 we that have for some s
that GLA ⊢s:□B.
Lemma 3 (Lifting lemma). If
GLA : x1:X1, . . . , xn:Xn ⊢Y
then for some term t we have
GLA :
x1:X1, . . . , xn:Xn ⊢t:Y.
Moreover the proof-variables in t are all among {x1, . . . , xn}.
Proof. Induction on a derivation of Y from the xi:Xi’s. If Y is one of the Xi’s,
say Xi0 then for t we can take xi0. If Y is a theorem of GLA the required t is
given by Lemma 2. The inductive case when Y is obtained by modes ponens
from previously obtained formulas is similar as in Lemma 2.
3.1
The Trouble with the Forgetful Projection in GLA
Obviously, since LP is a sub-system of GLA we have that LP ⊢A implies GLA ⊢A.
And thus in particular by Theorem 1 we have the following. (Recall that an LP
formula is normal when all negative occurrences of proof-terms are variables, we
use the same terminology for the more general formulas of GLA.)
Theorem 2. If S4 ⊢A then for some normal B with B◦≡A we have GLA ⊢B.
It is also true that GLA does not realize all the theorems of GL. For suppose that
for some terms t and r we have
GLA ⊢x:(r:⊥→⊥) →t:⊥.
Since GLA ⊢c:(r:⊥→⊥) we thus have GLA ⊢t[x/c]:⊥and by reﬂection GLA ⊢
⊥. A contradiction.
As we will see below the theorems of GL that can be realized in GLA are pre-
cisely those formulas that are also theorems of S4. Clearly to show this it suﬃces
to show the the other direction of Theorem 2, this however is less straightfor-
ward then in the S4/LP case. One easily sees that if LP ⊢A then S4 ⊢A◦. If
we however in the most straightforward way extend the deﬁnition of forgetful
projection to formulas in the language of GLA, then the set of theorems of GLA

246
E. Goris
under this projection is not even closed under modus ponens. For the following
three formulas are theorems of GLA.
– □(□p →p) →□p,
– x:p →p,
– □(x:p →p).
Their forgetful projections are respectively
– □(□p →p) →□p,
– □p →p,
– □(□p →p).
From which p follows using modus ponens. Obviously p is not the forgetful
projection of any theorem of GLA. The trick is to not study the ‘plain’ forgetful
projection but a variant that remembers which □’s came from proof terms and
which where already there. This is what we will carry out in the coming sections.
4
The System EI
In this section we will show that only the theorems of S4 can be realized in
GLA. The main tool is a modal propositional logic with two modalities □and ⊠.
In particular we will be interested in the modal formulas in this language that
constitute images of the following generalization of forgetful projection to GLA
formulas.
Deﬁnition 1 (Forgetful projection). For an GLA formula A we deﬁne the
forgetful projection A◦with induction on A as follows.
– p◦≡p and ⊥◦≡⊥,
– (A →B)◦≡(A◦→B◦),
– (□A)◦≡□(A◦),
– (t:A)◦≡⊠(A◦).
Let EI (for Explicit/Implicit) be the normal bi-modal logic axiomatized by the
following axiom schemata and rules.
CP ‘Classical Propositional Logic’,
L1 □(A →B) →(□A →□B),
L2 □A →□□A,
L3 □(□A →A) →□A,
S1 ⊠(A →B) →(⊠A →⊠B),
S2 ⊠A →⊠⊠A,
S3 ⊠A →A,
C1 ⊠A →□A,
C2 ¬ ⊠A →□¬ ⊠A,
C3 ⊠□A →A,
R ⊢A implies ⊢⊠A.
Lemma 4. GLA ⊢A implies EI ⊢A◦.

Explicit Proofs in Formal Provability Logic
247
Proof. Induction on a GLA derivation of A. If A is an instance of A5 then A
is of the form c:B, B◦is an axiom of EI and ⊠B◦(≡(c:B)◦) is derivable using
⊠necessitation. If A is an instance of any of the other axiom schemata then
A◦is an axiom of EI. Suppose A ≡□B, and the last step in the derivation of
A is necessitation. By (IH) we obtain EI ⊢B◦. By ⊠necessitation we obtain
EI ⊢⊠B◦and by C1 and modus ponens we get EI ⊢□B◦. The case ‘the last
step is modus ponens’ is trivial.
Next we formulate a Kripke semantics for EI. A binary relation R is conversely
well-founded when every R increasing path x0Rx1Rx2 · · · is ﬁnite.
Deﬁnition 2 (EI-frame). A bi-modal Kripke frame ⟨W, R□, R⊠⟩is an EI-frame
if
1. R□is transitive and conversely well-founded,
2. R⊠is transitive and reﬂexive,
3. xR□y implies xR⊠y,
4. xR□y and xR⊠z implies yR⊠z,
5. for all x there exists y such that xR⊠y and yR□x.
Notice that no ﬁnite frames satisfying both 1 and 5 exist. For if 5 holds then one
inductively constructs a sequence
x1R⊠x2R⊠x3 · · ·
For which we in addition have · · · x3R□x2R□x1. Thus by transitivity of R□we
have for all i < j
xjR□xi.
But if the frame is ﬁnite then for some i < j we must have xi = xj, contradicting
the conversely well-foundedness of R□.
Nevertheless, as is shown in [10], EI can be embedded in a sub-logic that does
have ﬁnite models and is complete for a class of ﬁnite frames.
Lemma 5 (Modal soundness). If EI ⊢A then A is valid on any EI-frame.
Proof. As usual it suﬃces to show the lemma for A an axiom of EI. All instances
of GL and S4 are well-known to hold because of properties 1 and 2 of EI-frames.
We show that ⊠A →□A is valid. Suppose w ⊩⊠A and suppose wR□x. By
3 we have wR⊠x and thus x ⊩A.
To show that also ⊠A →□⊠A is valid, suppose that in addition xR⊠y then
by 2 wR⊠y and thus y ⊩A as well.
Now we show that ¬ ⊠A →□¬ ⊠A is valid. Suppose w ⊩¬ ⊠A and wR□x.
For some y with wR⊠y we have y ⊩¬A. By 4 we have xR⊠y and thus x ⊩¬⊠A.
Finally we show that ⊠□A →A is valid. Suppose w ⊩⊠□A. By 5 there exists
some x with wR⊠x and xR□w. We thus have x ⊩□A and thus w ⊩A.
We aim at showing that the □-free fragment of EI coincides with S4. One direc-
tion, namely that S4 is a subset of the □-free fragment is obvious. For the other
direction we will make use of the completeness of S4 with respect to transitive
and reﬂexive Kripke frames [7]. We will use bounded morphisms to connect these
frames with our EI-frames.

248
E. Goris
Deﬁnition 3 (Bounded morphism). Let M and M ′ be two Kripke models.
A bounded morphism from M to M ′ is a surjective mapping M −→M ′ such
that for all x, y ∈M we have
– x ⊩p iﬀf(x) ⊩′ p,
– xRy implies f(x)R′f(y),
– If f(x)R′y′ then for some y we have f(y) = y′ and xRy.
The following lemma is well-known, see [7].
Lemma 6. If f is a bounded morphism from M to M ′ then for all w ∈M,
M, w is bi-similar with M ′, f(w). Consequently for any formula A, M |= A iﬀ
M ′ |= A.
Proposition 1. For any transitive and reﬂexive Kripke model M there exists
an EI model Mω = ⟨Wω, R□, R⊠, ⊩⟩such that there exists a bounded morphism
from ⟨Wω, R⊠, ⊩⟩to M.
Proof. Let M = ⟨W, R, ⊩⟩be an S4 model. Let W1, W2, . . . be countably many
disjoint copies of W. For x ∈W we denote with xi the copy of x in Wi. Deﬁne
Mω = ⟨Wω, R⊠, R□, ⊩⟩as follows.
– Wω = 
i≥1 Wi,
– xiR⊠yj iﬀxRy,
– xiR□yj iﬀx = y and j < i,
– xi ⊩p iﬀx ⊩p.
First we will show that Mω is based on an EI-frame. That R⊠is transitive and
reﬂexive is immediate. That R□is transitive and conversely well-founded is also
easy to see. Suppose that xiR□yj. Then we thus have in particular that x = y
and by reﬂexivity of R we get xiR⊠yj. Suppose that xiR□yj and xiR⊠zk. We
have to show that yRz. But this follows immediately since from our assumptions
it follows that y = x and xRz. Let xi ∈Wω. We have to show that for some
yj ∈Wω we have xiR⊠yj and yjR□xi. Just take yj = xi+1. This completes the
proof that Mω is based on an EI-frame.
We show that the mapping f deﬁned by f(xi) = x is a bounded morphism
from ⟨Wω, R⊠, ⊩⟩to M. f is clearly surjective and by deﬁnition of ⊩we have
xi ⊩p iﬀf(xi) ⊩p. Suppose xiR⊠yj. Then xRy and thus f(xi)Rf(yj). Suppose
f(xi)Ry. f(xi) = x, thus xRy. By deﬁnition of R⊠we have xiR⊠yi. And by
deﬁnition of f we have f(yi) = y.
Theorem 3. If A is □-free and EI ⊢A then S4 ⊢A.
Proof. We show that any A satisfying the assumptions of the theorem is valid
on all transitive and reﬂexive frames. The theorem then follows from the modal
completeness of S4 ([7]). So let F be some S4 frame and let M be a model based
on F. Let Mω be the EI-model from Proposition 1. By Lemma 5 of EI we have
that Mω |= A. And since M is a bounded morphic image from Mω we also have
by Lemma 6 that M |= A.

Explicit Proofs in Formal Provability Logic
249
Theorem 4. Any modal formula that is realizable in GLA is a theorem of S4.
Proof. Let B be a realization of A (that is B is □-free and B◦≡A) such that
GLA ⊢B. By Lemma 4 EI ⊢B◦and thus by Theorem 3 S4 ⊢B◦.
5
The Disjunction Property for GLA
In this section we will prove the disjunction property for GLA. The analog for
LP was ﬁrst established in [11] using a minimal model construction for LP and
we will use the same technique here.
With a constant speciﬁcation we mean a set CS of pairs ⟨c, A⟩where c:A is
an instance of A5. With GLA(CS) we denote the fragment of GLA where A5 is
restricted to c:A for ⟨c, A⟩∈CS. For the sake of completeness we repeat some
deﬁnitions from [4].
Deﬁnition 4 (GLA-model). A GLA-model is a structure ⟨W, R, ⊩⟩where
1. R is a transitive conversely well-founded relation on W,
2. ⊩is a forcing relation satisfying for all w, v ∈W,
(a) the usual constraint on boolean connectives and □,
(b) for all t:F, w ⊩t:F iﬀv ⊩t:F,
(c) w ⊩t:F implies w ⊩F,
(d) w ⊩s:(F →G) and w ⊩t:F implies w ⊩(s·t):G,
(e) w ⊩t:F implies w ⊩(t + s):F and w ⊩(s + t):F,
(f) w ⊩t:F implies w ⊩!t:(t:F).
Let F be a formula and let Sub(F) be the set of sub-formulas of F. Put
S(F) =

{□A →A | □A ∈Sub(F)}.
We say that a rooted GLA-model ⟨W, R, ⊩⟩with root r is F-sound when
r ⊩S(F).
A rooted GLA-model is a CS-model when it is A-sound for all ⟨c, A⟩∈CS and
c:A holds in the whole model. The following theorem is shown in [4].
Theorem 5 (Modal completeness). GLA(CS) ⊢A iﬀA is valid in all A-
sound CS-models.
For the remainder of this section we ﬁx a ﬁnite constant speciﬁcation CS. Let ∗
be the least map
∗: GLA-terms −→P(GLA-formulas)
for which
– ∗(c) = {A | ⟨c, A⟩∈CS},
– F →G ∈∗(s) and F ∈∗(t) implies G ∈∗(s·t),
– F ∈∗(s) implies F ∈∗(s + t) and F ∈∗(t + s),
– F ∈∗(t) implies t:F ∈∗(!t).

250
E. Goris
The following lemma follows immediately from minimality of ∗.
Lemma 7.
1. For all variables x, ∗(x) = ∅,
2. for all constants c, ∗(c) = {A | ⟨c, A⟩∈CS},
3. F ∈∗(t + s) implies F ∈∗(t) or F ∈∗(s),
4. F ∈∗(s·t) implies that for some G, G ∈∗(t) and G →F ∈∗(s),
5. F ∈∗(!t) implies that for some G ∈∗(t), F ≡t:G.
Corollary 1. If F ∈∗(t) then GLA(CS) ⊢t:F.
Proof. Induction on the complexity of t using Lemma 7.
Now given this map ∗we deﬁne a GLA-model M = ⟨W, R ⊩⟩as follows.
– W = {w0, w1, w2, . . .},
– wiRwj iﬀi > j,
– w ⊩p for all w ∈W and all p,
– w ⊩t:A iﬀA ∈∗(t) and for all v ∈W, v ⊩A.
Lemma 8. M is a GLA-model. Moreover it is a GLA-model in which c:A holds
for all ⟨c, A⟩∈CS.
Proof. R is clearly transitive and conversely well-founded. All constraints on ⊩
hold by deﬁnition and the properties of the map ∗. For ⟨c, A⟩∈CS we have by
Theorem 5 that A holds in M. We also have that A ∈∗(c) and thus c:A holds
in M.
The next lemma implies that for any F there exists some w ∈W such that w
generates an F-sound CS-model.
Lemma 9. Let X = {□Fi →Fi | 0 ≤i < n}. There exists some k ≤n such
that wk ⊩ X.
Proof. If not then by a pigeon hole argument it follows that for some i < n
and r < s ≤n we have wr ⊩□Fi ∧¬Fi and ws ⊩□Fi ∧¬Fi. But wsRwr. A
contradiction.
Theorem 6 (Disjunction property). If GLA(CS) ⊢t:A ∨s:B then
GLA(CS) ⊢t:A or GLA(CS) ⊢s:B.
Proof. Suppose GLA(CS) ⊢t:A ∨s:B. Let M be the model deﬁned above. For
any i ≥0 let Mi be the sub-model of M generated by wi. Since CS is ﬁnite
by Lemma 9 there exists an i ≥0 such that Mi is an (t:A ∨s:B)-sound CS-
model. By Theorem 5 we have wi ⊩t:A ∨s:B. But then wi ⊩t:A or wi ⊩s:B.
In the ﬁrst case by Corollary 1 we get GLA(CS) ⊢t:A and in the second case
GLA(CS) ⊢s:B.
Notice that Theorem 6 generalizes to arbitrary constant speciﬁcations.

Explicit Proofs in Formal Provability Logic
251
6
The Intersection of S4 and GL
We give an axiomatization of all formulas in the intersection of S4 with GL. We
show that this normal modal logic has the Craig-interpolation property.
We follow the terminology from [14]. That is, a modal logic is a proper subset
of the set of all modal formulas closed under substitution and modes ponens. A
modal logic is normal when it is also closed under necessitation and contains all
instances of □(A →B) →(□A →□B). The following lemmata are folklore.
Lemma 10. S4 is the smallest modal logic that contains all the theorems of K4
and all instances of □A →A and □(□A →A).
Lemma 11. GL is the smallest modal logic that contains all the theorems of K4
and all instances of □(□A →A) →□A and □(□(□A →A) →□A).
In what follows we abbreviate
L(p) ≡□(□p →p) →□p,
R(p) ≡□p →p.
Lemma 12. S4 ⊢¬L(⊥) and GL ⊢L(⊥).
Proof. We have S4 ⊢□♦⊤and S4 ⊢♦⊤and thus S4 ⊢¬L(⊥). GL ⊢L(⊥) is
clear.
For F a formula we write ⊡F for □F ∧F. Let K4L0T0 be the smallest normal
modal logic that contains all the instances of
4 □A →□□A,
L0 L(⊥) →⊡L(A),
T0 ¬L(⊥) →⊡R(A).
We write S4 ∩GL ⊢A for S4 ⊢A and GL ⊢A.
Theorem 7. S4 ∩GL ⊢A iﬀK4L0T0 ⊢A
Proof. The right to left direction is immediate from Lemma 12. To show the
other direction let A be a theorem of both S4 and GL. Then by Lemma 10 we
get some X1, . . . Xk such that
K4 ⊢

1≤i≤k
⊡(□Xi →Xi) →A.
And by Lemma 11 we get some Y1, . . . , Yn such that
K4 ⊢

1≤i≤n
⊡(□(□Yi →Yi) →□Yi) →A.
As K4 ⊆K4L0T0 and
K4L0T0 ⊢¬L(⊥)∨L(⊥) →

1≤i≤k
⊡(□Xi →Xi)∨

1≤i≤n
⊡(□(□Yi →Yi) →□Yi)
we have K4L0T0 ⊢¬L(⊥) ∨L(⊥) →A and thus K4L0T0 ⊢A.

252
E. Goris
Theorem 8. K4L0T0 enjoys the Craig-interpolation property.
Proof. Suppose K4L0T0 ⊢A →B. Then both GL ⊢A →B and S4 ⊢A →B.
By the interpolation theorems for GL ([8]) and S4 ([7]) we ﬁnd I1 and I2, in the
common language of A and B such that GL ⊢A →I1 →B and S4 ⊢A →I2 →
B. Now put
I ≡(I1 ∧L(⊥)) ∨(I2 ∧¬L(⊥)).
Since GL ⊢L(⊥) we have GL ⊢I ↔I1 and since S4 ⊢¬L(⊥) we have S4 ⊢I ↔
I2. Thus I is an interpolant for A →B in both S4 and GL.
We have shown in the main body of this paper that the intersection of S4 with
GL is of interest when studying combined logics of explicit and formal proofs.
Therefore the standard questions in the studies of modal logic are in order.
However, intersections of modal logics are in general not the nicest objects in
existence [13]. Apparently, by Theorem 8 with GL and S4 we might be more
lucky and therefore desirable and well-behaved answers to the questions below
are plausible.
Question 1. Is there a nice cut-free formulation of K4L0T0?
Question 2. What is the explicit version of K4L0T0?
Question 3. What is the closed fragment of K4L0T0?
Acknowledgements
The author would like to thank Professor Sergei Artemov and the anonymous
referees for useful comments and suggestions.
References
1. Artemov, S.N.: Operational modal logic. Technical Report MSI 95-29, Cornell
University (1995)
2. Artemov, S.N.: Explicit provability and constructive semantics. Bulletin of Sym-
bolic Logic 7(1) (2001) 1–36
3. Artemov, S.N., Beklemishev, L.D.: Provability logic. In Gabbay, D., Guenthner,
F., eds.: Handbook of Philosophical Logic. Volume 13. 2nd edn. Kluwer (2004)
229–403
4. Artemov, S.N., Nogina, E.: Logic of knowledge with justiﬁcations from the provabil-
ity perspective. Technical Report TR-2004011, CUNY Ph.D. Program in Computer
Science (2004)
5. Artemov, S.N., Straßen, T.: The basic logic of proofs. In B¨orger, E., J¨ager, G.,
Kleine B¨uning, H., Martini, S., Richter, M.M., eds.: Selected papers of the 6th
Workshop on Computer Science Logic (CSL-1992), San Miniato, Italy, September
28–October 2, 1992. Volume 702 of Lecture Notes in Computer Science., Springer-
Verlag (1993) 14–28

Explicit Proofs in Formal Provability Logic
253
6. Beklemishev, L.D., Visser, A.:
Problems in the logic of provability.
Technical
Report Logic Group Preprint Series 235, Department of Philosophy of Utrecht
University, Utrecht (2005)
7. Blackburn, P., de Rijke, M., Venema, Y.: Modal logic. Cambridge University Press,
New York, NY, USA (2001)
8. Boolos, G.:
The Logic of Provability.
Cambridge University Press, Cambridge
(1993)
9. Goris, E.: Logic of proofs for bounded arithmetic. In Dima Grigoriev, J.H., Hirsch,
E.A., eds.: Computer Science - Theory and Applications: First International Com-
puter Science Symposium in Russia, CSR 2006, St. Petersburg, Russia, June 8-12.
2006. Volume 3967 of Lecture Notes in Computer Science., Elsevier (2006) 191–201
10. Goris, E.: Explicit proofs in formal provability logic. Technical Report TR-2006003,
CUNY Ph.D. Program in Computer Science (2006)
11. Krupski, N.V.: On the complexity of the reﬂected logic of proofs. Technical Report
TR-2003007, CUNY Ph.D. Program in Computer Science (2003)
12. Nogina, E.:
On logic of proofs and provability.
Bulletin of Symbolic Logic 12
(2006) 2005 Summer Meeting of the ASL.
13. Schumm, G.F.: Some failures of interpolation in modal logic. Notre Dame Journal
of Formal Logic 27(1) (1986) 108–110
14. Segerberg, K.: Post completeness in modal logic. Journal of Symbolic Logic 37
(1972) 711–715
15. Solovay, R.M.: Provability interpretations of modal logic. Israel Journal of Math-
ematics 25 (1976) 287–304
16. Yavorskaya-Sidon, T.L.:
Logic of proofs and provability.
Annals of Pure and
Applied Logic 113(1–3) (2002) 345–372

A Synthesis Algorithm for Hybrid Systems
Srikanth Gottipati1 and Anil Nerode2
1 The Graduate Center, CUNY, New York, NY 10016
2 Cornell University, Ithaca, NY 14853
Abstract. Hybrid systems are systems of continuous plants, subject to distur-
bances, interacting with sequential automata in a network. By the synthesis
problem for hybrid systems we mean extracting a ﬁnite state digital controller au-
tomaton from the system equations, constraints, and cost function which deﬁne
the hybrid system. This automaton senses system state, and on the basis of its state,
changes state and issues a chattering control to the actuators to control the system
with epsilon optimal control for a ﬁxed epsilon in real time. We address this prob-
lem by extracting a local cost function for the control system which transforms
the inﬁnite-dimensional optimization problem into a ﬁnite-dimensional problem.
1
Introduction
Hybrid systems are complex dynamic systems composed of an interacting network of
subsystems with continuous dynamics (we refer to them as plants) and subsystems with
discrete dynamics (we refer to them as digital controllers). The continuous and dis-
crete dynamics interact. Changes occur in the plant states in response to changes in the
environment and changes in states of the digital controllers. Changes in the states of
the digital controllers occur due to changes in the plant state and the environment. The
digital controllers are ﬁnite state real time input-output devices, the plant evolutions
are governed by differential or difference equations. The hybrid system is the coupled
system of discrete and continuous elements (see Figure 1).
Hybrid systems arise in many contexts, both in man-made systems and in nature.
Continuous systems which have a phased operation, such as walking robots, insect mo-
tion, or biological cell growth and division, are well-suited to be modeled as hybrid
systems, as are continuous systems which are controlled by a discrete logic, such as a
chemical plant controlled with valves and pumps, or the autopilot modes for control-
ling an aircraft. Hybrid systems are also natural models for systems comprised of many
interacting subsystems or processes, such as air or ground transportation systems. In
these examples, the continuous dynamics model system state evolution, biochemical
or chemical reactions, while the discrete dynamics control the sequence of contacts or
collisions in the gait cycle, cell divisions, valves and pumps switching, and coordina-
tion protocols. In all of these examples, the system dynamics are complex enough that
traditional analysis and control methods based solely on differential equations have not
been computationally feasible for complex systems. Another important way in which
hybrid systems arise is from the hierarchial organization of complex systems. In these
systems, a hierarchial organization helps manage complexity and higher levels in the
S. Artemov and A. Nerode (Eds.): LFCS 2007, LNCS 4514, pp. 254–268, 2007.
c⃝Springer-Verlag Berlin Heidelberg 2007

A Synthesis Algorithm for Hybrid Systems
255
hierarchy require less detailed models of the functioning of the lower levels, necessi-
tating the interaction of discrete and continuous components. Example of such systems
include ﬂexible manufacturing and chemical process control systems, intelligent high-
way systems, air trafﬁc management systems, etc.
To understand the behavior of hybrid systems, to simulate, and to control these sys-
tems, theoretical advances and analytical tools are needed. Recent developments in-
clude building theory and analytical tools, and applying them to interesting and large
scale systems which are currently not known how to analyze, control, or simulate like
an automated air trafﬁc system, biological control circuit, etc. The predominant model
being used in the literature for hybrid systems is to partition the entire state space into
ﬁnite regions, possibly overlapping, where in each region has its own invariant. Once
the evolved state of the system in a particular region violates this invariant condition,
the state of the system is thrown by the digital control program into a different region
with possible reset of the state and from then on evolves according to the state dynamics
speciﬁed for that region, as long as the invariant for that region is maintained.
Continuous Dynamics
Automata/Logic
AD
DA
Digital Controller
Plant(System)
Exogenous Inputs
Exogenous Inputs
Sensor Measurements
Control
Digital Outputs
Discrete Inputs
Interface
Fig. 1. Hybrid system
The other modeling perspective is that the state space has a ﬁnite number of open
regions which are represented by logical propositions which involve systems of differ-
ential equalities and inequalities. When the state enters one of these regions one of the
logical rules might ﬁre in which case the system dynamics and constraints might change
and this in effect is reﬂected in the change in control policy. When several of the rules
ﬁre, there is supposed to be consistent behavior.
The analysis of behavior of classes hybrid systems has become quite popular, there
are many meetings now. We are primarily interested in extraction of controls which
guarantee epsilon optimal control relative to a cost function and constraints. We are

256
S. Gottipati and A. Nerode
less concerned with taking a given hybrid system (with controls given too) and trying
to ﬁgure out its behavior as a dynamical system, which is a principal focus of much
current research.
1.1
History of Control
Here is some background. We ﬁrst recapitulate some of the evolution of control the-
ory for continuous plants. The modern control of industrial devices by feedback goes
back at least to the steam engine governor of James Watt (1787), the feedback linear
ampliﬁers of E. H.Armstrong’s patent (1914), the theory of stability of linear feedback
ampliﬁer developed at Bell Labs by H. S. Black (1927), H. Nyquist (1932), H. W. Bode
(1940) (Laplace transform frequency domain analysis), the theory of linear servomech-
anisms, developed at MIT Radiation labs, during World War II, emerging in the book
“Theory of Servomechnisms” by James, Nichols, and Phillips, 1947. Complex inter-
acting linear systems can be represented in matrix form, giving rise to linear control
theory. In 1960 Kalman gave a straightforward matrix calculus algorithm for ﬁnding
optimal linear controllers for linear models with a linear quadratic cost function when
they exist, based on simple facts about matrices and quadratic forms. This remains the
principal optimal control tool for the control engineer to this day, especially for process
control.
For non-linear optimization in the 1950’s Richard Bellman [1] invented dynamic
programming for ﬁnding paths satisfying constraints and minimizing a cost function
assuming his “principle of optimality”, based on backwards search for an optimal tra-
jectory starting at the goal. In the 1950’s L.S. Pontryagin [12] developed a differential
equation necessary condition for optimal trajectories subject to differential equality and
inequality constraints. His maximum principle can be expressed in terms of an asso-
ciated symplectic geometry. His principle, earlier discovered by Hestenes in 1950, in
the context of the calculus of variations, is a local necessary condition for a minimum,
just as in calculus setting a derivative equal to zero is a local necessary condition for a
minimum. The purpose of local necessary conditions is to cut down the set of controls
that have to be considered to ﬁnd an optimal control. Pontryagin’s maximum principle
plays for optimality the same role that the ﬁrst and second derivative tests for minima
do in calculus. It is a variant and generalization of the ﬁrst and second variation neces-
sary tests of the calculus of variations. Most calculus of variation books explore local
necessary conditions and local sufﬁcient conditions for minima, but go no further.
What are the mathematical theorems that prove the existence of optimal curves from
start to goal? In calculus we use Weierstrass’s sufﬁciency theorem where the varia-
tional operator operates on f and converge to a point where the minimum is achieved
(Specker, 1959). But if we say that in practice, we only need to be within epsilon of
the minimum, there are algorithms, even efﬁcient algorithms when some smoothness
is assumed. The situation is similar in the calculus of variations and optimal control.
Hilbert’s “direct method” (1901) proves the existence of curves minimizing from start
to goal by application of Arzela-Ascoli lemma on uniformly bounded equicontinuous
families. Application of this to suitable function spaces produces a compact function
space such that, on applying the theorem that an upper semicontinuous function on
a compact set attains its minimum, one gets the minimizing curve. Compactness is

A Synthesis Algorithm for Hybrid Systems
257
achieved by extending the space of piecewise smooth curves to a completion using the
method ﬁrst introduced in the calculus of variations by E. J. MacShane (1939-41).These
are the “weak solutions”, also called relaxed solutions, or measure valued solutions ac-
cording to the Riesz representation theorem. This was developed further by L.C. Young,
Pontryagin, and their followers. Here too algorithms do not exist which will in general
compute optimal measure-valued controls. But, just as in calculus, if one asks only for
controls which yield trajectories with cost within a prescribed epsilon of optimal cost,
there are such algorithms yielding piecewise smooth epsilon optimal control functions,
and becomes a question of developing efﬁcient algorithms. Wolf Kohn and Anil Nerode
in 1992-4 began the development and implementation of efﬁcient real time algorithms
for epsilon optimal control of complex systems. They founded a company, Clearsight
Systems, which has demonstrated the real time feasibility of using such chattering ap-
proximations to optimal control for many applications such as logistics enterprize sys-
tems, ﬁnancial analysis, and many other areas.
What does this have to do with hybrid systems? The algorithms for real time epsilon
optimal control for a ﬁxed epsilon extract a ﬁnite state digital controller automaton
from the system equations, constraints, and cost function. This automaton senses sys-
tem state, and on the basis of its state, changes state and issues a chattering control to the
actuators to control the system. This was the motivation for Kohn-Nerode deﬁning hy-
brid automata in the 1992 volume “Hybrid Systems”, LNCS, [11]. So hybrid automata
and hybrid systems emerge when one extracts epsilon optimal control for continuous
non-linear systems and implements it.
There is a second place where the hybrid system concept is important. In many com-
plex systems, behavior is constrained by logical rules. If an order is given by a comman-
der to troops or by a high business administrator to his organization, the course of action
must satisfy doctrine, regulations, and other constraints which are expressed in logic.
Traditional control theory simply does not deal with this. Those who study planning do
deal with this, but primarily by logical deduction of a plan meeting logical constraints
and achieving a goal. Prolog is suited to this. But when the system being controlled is a
physical system like an airplane or a chemical process plant, we now have purely digi-
tal rules in logical form interacting with an evolving physical dynamical system, a hy-
brid system. The Kohn-Nerode approach converts the logical constraints and goals into
(generally non-convex) continuous constraints and goals, and couples the continuous
constraints on the controlled physical system with the continualization of the discrete
constraints.
Our intention, following Kohn-Nerode [7], [11], is to cut down the search space and
to improve the algorithms for computing optimal trajectories using Finsler geometries
associated with optimal control problems, speciﬁcally to introduce use of Finsler cur-
vature formulas to guide computations. This entails an extensive analysis of Finsler
geometry in control theory.
1.2
Optimal Control: Synthesis
Optimal control theory could be viewed as a generalization of Calculus of Variations
problems. The problem of optimal plant control is that of constructing a control law or
policy u(t) ∈U, where is the set of admissible controls, which will drive the plant from

258
S. Gottipati and A. Nerode
its initial state, x0 ∈M, into some set of goal states, G ⊂M, along an optimal path
x(t). Optimality is generally formulated as minimizing some cost functional on paths,
which we label J(x). In this proposal, the cost functionals will always be assumed to
be of the form
J(x) :=
 t1
t0
L(x(t), u(t))dt,
(1)
where L is the cost function. In practice, moreover, the plant dynamics are constrained
to take place on a constraint sub-manifold N ⊂M. In our work, N is determined by
differential-algebraic constraints of the form F(x, ˙x, u) = 0. These constraints arise
from dynamic concerns and from performance speciﬁcations. For a particular problem
we will have to specify the set of admissible paths from which we will draw candidates
for optimality. We shall work with piecewise smooth paths. We shall also assume con-
trollability, i.e., we will assume the existence of a path on the constraint sub-manifold
which connects x0 to G.
In conventional optimal control theory two methods for computing optimal controls
stand out. One is the Bellman’s Hamilton-Jacobi-Bellman (HJB) method and the other
is the Pontryagin’s Maximum Principle method. From an engineer’s perspective, the
HJB framework is preferred for solving optimal control problems since it naturally leads
to a design of optimal feedback (or closed-loop) controllers, i.e. control laws as a func-
tion of state. However, except for some very simple problems, this approach is bereft
with major theoretical and numerical difﬁculties. The alternative framework avoids the
pitfalls associated with the HJB theory but generates open-loop controls, i.e. control
laws as a function of time. However, it has been known since the birth of optimal con-
trol that if open-loop controls can be generated in real-time, they are basically equiva-
lent to feedback controls. In modern terminology this is model-predictive control(MPC)
with the horizon being time-to-go. In a later chapter we shall give a full account of the
state-of-art methods for computing optimal controls for practical nonlinear systems.
With respect to types of Hybrid models that we described above, they require only
open-loop controls if we have full knowledge of the system at the time of computation
of optimal controls. With any unforeseen contingencies, for example disturbances or
changes in the logic database, one needs to develop feedback controls. Control laws are
implemented via a ﬁnite state machine. The following simple example shows how the
feedback law could be represented by a hybrid automaton.
1.3
An Intuitive Example: Double Integrator Problem
Consider the control system
d2x
dt2 = u,
(2)
where u is a real control parameter constrained by the condition that |u| ≤1. In the
phase coordinates x1 = x and x2 = dx/dt, this equation may be rewritten in the form
of the following system:
dx1
dt = x2,
dx2
dt = u.
(3)
Let us consider the problem of getting to the origin (0, 0) from a given initial state xinit
in the shortest time. In other words, we shall consider the time-optimal problem for the

A Synthesis Algorithm for Hybrid Systems
259
˙x1 = x2
s−1
˙x2 = −1
˙x1 = x2
˙x2 = 1
s1
˙x1 = 0
˙x2 = 0
s0
x1 < −1
2x2|x2|
x1 > −1
2x2|x2|
x1 = 0 ∧x2 = 0
x1 = 0 ∧x2 = 0
Fig. 2. Hybrid Automaton: Double Integrator
case where the origin (0, 0) is the terminal position. The feedback control for the double
integrator problem is given by
u(t, x1, x2) =
⎧
⎪
⎪
⎨
⎪
⎪
⎩
−1, if x1 > −1
2x2|x2|,
1, if x1 > 0 and x1 = −1
2x2|x2|,
1, if x1 < −1
2x2|x2|,
−1, if x1 < 0 and x1 = −1
2x2|x2|.
(4)
Current numerical techniques for the Dynamic Programming method cannot be im-
plemented to problems of high dimensions due to the “curse of dimensionality”. Hence
numerical computation of feedback control laws seems to be a far-fetched proposition
at the moment. We need more information on the geometric structure of our optimal
control problem. The hope is that it would be possible to derive feedback controls from
geometrical objects like curvature, torsion, etc which are measures of deviation from
ﬂat Euclidean spaces. Physics has especially beneﬁted from the study of curved mani-
folds through Riemannian geometry. However, optimal control problems do not lie on
Riemannian manifolds but on more general spaces called Finsler spaces.
In this paper we develop a synthesis algorithm by transforming the optimal control
problem into an ﬁnite dimensional optimization problem. The paper is organized as
follows: section 2 introduces sprays, section 3 gives a detailed study of the inverse
problem of the calculus of variations, and section 4 outlines the synthesis algorithm.
2
Sprays
Second order ordinary differential equations (SODEs) arise in many areas of natural
science. A special class of SODEs come from the variational problems of Lagrange
metrics including Finsler metrics. Many geometers like L. Berwald, T. Y. Thomas, O.
Veblen, J. Douglas, D. Kosambi and E. Cartan, have studied SODEs using geometric
methods. SODEs in general are given in the following form
d2xi
ds2 = Φi

s, x, dx
ds

,
i = 2, . . . , n .
(5)

260
S. Gottipati and A. Nerode
Riemannian and Finsler geodesics are given as solutions of a homogeneous system
of SODEs which are known in the differential geometry literature as sprays. One can
study such SODEs which are more general than the geodesic equations obtained from
Riemannian or Finsler metrics, see [15]. We ﬁrst deﬁne a spray as follows:
Deﬁnition 1. Let M be a manifold. A spray on M is a smooth vector ﬁeld G on T M \
{0} expressed in a standard local coordinate system (xi, vi) in T M as follows
G = vi ∂
∂xi −2Gi(x, v) ∂
∂vi ,
(6)
where Gi(x, v) are local functions on T M satisfying
Gi(x, λv) = λ2Gi(x, v),
λ > 0 .
(7)
A manifold with a spray is called a spray space.
Deﬁnition 2. A regular curve c in M is called a geodesic of G if it is the projection of
an integral curve of G. We shall call Gi the spray coefﬁcients of G.
For a vector v ∈TxM, let γ : (−ε, ε) →M be the curve in G with ˙γ(0) = v. Deﬁne
Gi(v) := −1
2
d2γi
dt2 (0),
(8)
where (γi(t)) are the local coordinates of the curve γ(t) and Gi(v) are positive homo-
geneous of degree 2 in v. It is then easy to prove that any curve c : (a, b) →M in G
satisﬁes the following system,
d2γi
dt2 + 2Gi
dc
dt

= 0 .
(9)
Every system of SODEs (also called a semispray) can be studied via the associated
system of sprays, and every Lagrange metric can be studied via the associated Finsler
metric. Let us assume that a system of semisprays and sprays are related by
Φi(s, x, ˙x) = 2 ˙xiG1(s, x, 1, ˙x) −2Gi(s, x, 1, ˙x).
(10)
Clearly, for a given set of functions Φi, there inﬁnitely many sets of homogeneous
functions Gi satisfying (). A special case is when Gi are given by
	
G1(x, y) = 0
Gi(x, y) = −1
2y1y1Φi(s, η, ξ)
(11)
where s = x1, ηi = xi, and ξi = yi/y1.

A Synthesis Algorithm for Hybrid Systems
261
3
Inverse Problem of the Calculus of Variations
The inverse problem in the calculus of variations involves deciding whether the solu-
tions of a given system of second-order ordinary differential equations
¨xi = F i(t, xb, ˙xb),
a, b = 1, . . . , n,
(12)
are the solutions of a set of Euler-Lagrange equations
∂L
∂xj −d
dt
∂L
∂˙xj = ∂L
∂xj −
∂2L
∂˙xk∂˙xj ¨xj −
∂2L
∂xk∂˙xj ˙xj −∂2L
∂t∂˙xj = 0
(13)
for some Lagrangian L(t, x, ˙x).
This problem, referred to as the inverse problem of the calculus of variations was
ﬁrst posed by H. von Helmholtz in 1887. In his paper [3], Helmholtz studied a system
of n second order differential equations of the form
Bjk(t, xi, ˙xi)¨xk + Aj(t, xi, ˙xi) = 0,
(14)
where 1 ≤i, j, k ≤n. He found necessary conditions for the existence of a Lagrange
function L such that
Bjk¨xk + Aj = ∂L
∂xj −d
dt
∂L
∂˙xj .
(15)
These conditions, referred to as Helmholtz conditions, are of the form
Bjk = Bkj
(16)
∂Bjk
∂˙xi
= ∂Bji
∂˙xk
(17)
∂Aj
∂˙xk + ∂Ak
∂˙xj = 2

d
dtBjk
(18)
∂Aj
∂xk −∂Ak
∂xj = 1
2

d
dt
∂Aj
∂˙xk −∂Ak
∂˙xj

(19)
where 1 ≤j, k ≤n, and the operator 
d/dt is deﬁned by

d
dt = ∂
∂t + ˙xi ∂
∂xi .
(20)
In 1896 Mayer [10] has proved that the Helmholtz conditions are also sufﬁcient for (14)
to be variational.
The inverse problem originally posed by Helmholtz is naturally generalized to the
following question: which also is referred to as inverse problem of the calculus of vari-
ations: Under what conditions are the SODE (12) equivalent to some Euler-Lagrange
equations? In other words, one asks whether there exist Euler-lagrange equations the
solutions of which coincide with the solutions of equations (12). In this formulation the

262
S. Gottipati and A. Nerode
problem is very general and its solution is not yet known. However, one can simplify
this problem restricting the class of equivalent equations, namely, to equations of the
form
fij(¨xj −F j) = d
dt
∂L
∂˙xi −∂L
∂xi ,
(21)
where fij are functions of (t, x, ˙x). Such a matrix fij is called a variational multiplier
and the problem is often called the multiplier problem. Hirsch [5] was the ﬁrst person to
pose the multiplier problem. Hirsch produced certain self-adjointness conditions which,
of themselves, are not particularly useful in classifying SODEs according to the exis-
tence and uniqueness of the corresponding multipliers. The most commonly used set of
necessary and sufﬁcient conditions for the existence of the multiplier fij are also called
Helmholtz conditions due to Fields medalist J. Douglas, who in his landmark paper [2]
goes on to completely solve the problem for n = 2 case, and put in the following form
by Sarlet [14]:
fij = fji
(22)
Γ(fij) = fikΓ k
j + fjkΓ k
i
(23)
fikΦk
j = fjkΦk
i
(24)
∂fij
∂˙xk = ∂fik
∂˙xj
(25)
where
Γ i
j := −1
2
∂F i
∂˙xj ,
Φi
j := −∂F i
∂xj −Γ k
j Γ i
k −Γ

Γ i
j

,
(26)
and the operator Γ is deﬁned by
Γ := ∂
∂t + ˙xi ∂
∂xi + F i ∂
∂˙xi .
(27)
In [2], Douglas does a painstaking study of four main cases and many subcases. These
cases are distinguished by the vanishing or otherwise of quantities constructed from F i.
Douglas expresses the necessary conditions to be satisﬁed by the multiplier matrix as
partial differential equations and uses Riquier-Janet theory to solve them. In most cases,
Douglas decides the existence question and gives all the possible Lagrangians; in the
remaining cases the problem becomes a question of the closure of a certain 1-form. In
his paper Douglas also avoids the Hirsch’s self-adjointness conditions. Douglas’s solu-
tion is so comprehensive that his conditions formed the basis for subsequent attempts
on the 3 and higher-degrees of freedom cases. Following Douglas the next signiﬁcant
contribution to solving the Helmholtz conditions was that of the Henneaux. Henneaux
[4] developed an algorithm for solving the Helmholtz conditions for any given system
of SODEs, and in particular, he solved the problem for spherically symmetric problems
in dimension 3.

A Synthesis Algorithm for Hybrid Systems
263
Example 3. For an arbitrary linear 1-dimensional SODE of the form
¨y + a(x) ˙y + b(x)y = f(x)
(28)
the Lagrangian is given by
L(x, y, ˙y) =
1
2 ˙y2 + b(x)
2 y2 −f(x)y

e
 a(x)dx
(29)
Example 4. For a linear control spray of the following form;
¨x = A · x + B · u,
x ∈Rn, u ∈Rm
(30)
where A is symmetric and u is assumed to be a parameter, we get the following
Lagrangian
L = 1
2 ˙x⊤˙x + 1
2x⊤Ax + x⊤Bu
(31)
3.1
Finsler Metrizability
In Finsler geometry, the geodesics of a Finsler function, parametrized so that the tangent
vector has constant Finsler length, deﬁne a spray, see [9], [13], [15]. However, not
every spray is obtainable in this way. The inverse problem for sprays is the problem of
determining, for a given spray, whether or not there exists a Finsler function of which it
is the geodesic spray; or more broadly, of giving criteria for distinguishing those sprays
which are geodesic. In fact the inverse problem in the broad sense refers to a whole
projective class of sprays rather an individual one. The inverse problem for sprays, or
the Finsler-metrizability problem as it is sometimes called, is thus a special case of the
inverse problem of calculus of variations for arbitrary systems of SODEs, or in other
words for semi-sprays.
Curvature terms play an important role in the Finsler-metrizability problem. Those
sprays with n > 1 degrees of freedom which have vanishing Riemann curvature (
also called R-ﬂat ) are Finsler-metrizable. Moreover, if any particular spray is Finsler-
metrizable one can conclude that all sprays projectively equivalent to it are also metriz-
able. It turns out that the isotropic sprays are projectively equivalent to R-ﬂat sprays.
The Riemann curvature Ri
jkl of a spray determines and is determined by the type
(1, 1) tensor Ri
j = Ri
kjlukul; the spray is isotropic if there is a function λ and a vector
ﬁeld μi such that
Ri
j = λδi
j + μjui .
(32)
The property of being isotropic is easily seen to be projectively invariant. One can
construct from the Riemann curvature a projectively invariant tensor P i
jkl, related to
it in much the same way as the projective curvature is to the Riemann curvature of
an afﬁne connection. Douglas has also studied such tensors with respect to the inverse
problem and has called it the Weyl tensor. It turns out that for n > 2 a spray is isotropic
iff P i
jkl = 0.
Another important class of sprays are the projectively afﬁne sprays which are deﬁned
to be those sprays whose Douglas curvature vanishes. The Douglas curvature tensor

264
S. Gottipati and A. Nerode
deﬁned on sprays is projective invariant constructed from the Berwald curvature of
sprays. These curvatures are non-Riemannian. A spray is called projectively R-ﬂat iff
both the Douglas and Weyl curvatures vanish. A nice theorem by Berwald shows that
the structure of projectively afﬁne sprays should be a polynomial of ˙x of degree ≤3,
i.e.,
F i(t, x, ˙x) = Ai(t, x) + Bi
j(t, x) ˙xj + Ci
jk(t, x) ˙xj ˙xk + Di
jkl(t, x) ˙xj ˙xk ˙xl,
(33)
where 1 ≤i, j, k, l ≤n.
One possible method for solving the inverse problem for a system of SODEs is to
construct the spray by passing to the homogeneous formalism; if this spray is pro-
jectively Finslerian then the original equations are variational. Of course this will in
general be only a local construction: that is to say, the spray is only locally deﬁned, and
one cannot expect to do more than ﬁnd a local Finsler function.
Since any isotropic spray is projectively Finslerian, it is natural to ask for the condi-
tions under which a system of SODEs give rise to an isotropic spray. For this purpose it
is necessary to express the Riemann curvature of the spray in term of quantities derived
from the differential equations, that is from the coefﬁcients F i. It turns out that
R0
0 = R0
i = 0
(34)
Ri
0 = ˙x0 ˙xjΦi
j
(35)
Ri
j = −( ˙x0)2Φi
j,
(36)
where Φi
j is the so-called Jacobi endomorphism of the system of differential equations,
Φi
j = ∂F i
∂xj + dγi
j
dt + γi
kγk
j ,
γi
j = −1
2
∂F i
∂˙xj .
(37)
It turns out that when SODEs are expressed in terms of spray geometry, Douglas’s case
I criterion corresponds exactly to the condition for a spray to be isotropic. It follows
that systems of SODEs in case I are variational.
4
Synthesis
Given a control SODE system
¨x = f(t, x, ˙x, u),
u ∈U ⊆Rm,
x ∈M ⊆Rn
(38)
the objective is to synthesize feedback control policies u(t, x, ˙x) to steer the system
from any given initial point x ∈M to desired goal xg ∈M. The goal is to synthe-
size a feedback controller u(t, x, ˙x) for the above optimal control problem. For the sake
of clarity we shall initially consider time-optimal control problems. However it should
be noted that all optimal control problems could be transformed to time-optimal con-
trol problems. The algorithm involves the construction of an inverse Lagragian for the
control system which is used to construct local goals. Before we outline our synthesis
algorithm we shall give two motivating examples.

A Synthesis Algorithm for Hybrid Systems
265
Example 5. The control SODE for the double integrator problem as shown before is
given by
¨x = u,
|u| ≤1,
x ∈R.
(39)
The objective is to steer the system to x = 0 with zero terminal velocity ˙x = 0 in
minimum possible time. Let us assume the control parameter u to be a constant for the
synthesis purposes. We know that the ﬁrst order Lagrangian for the SODE is given by
L(t, x, ˙x, u) = 1
2 ˙x2 + ux
(40)
The ﬁrst step for any feedback control u(t, x, ˙x) synthesis is to ﬁnd the optimal controls
u(t, x, ˙x) = arg min
u∈U L(t, x, ˙x, u)
(41)
The extremal controls u∗are given by
u∗(x, ˙x) =
	
1,
x > 0,
−1,
x < 0.
(42)
The trajectories that lead us to the goal should be the minimal curves which are the
curves in the (x, ˙x) plane given by the following equations
1
2 ˙x2 + x = 0,
1
2 ˙x2 −x = 0,
(43)
the solutions to which are parabolas. The complete synthesis is shown in Figure 3.
−80
−60
−40
−20
0
20
40
60
80
−15
−10
−5
0
5
10
15
x
y
u = 1
u = −1
Fig. 3. Double Integrator optimal paths

266
S. Gottipati and A. Nerode
Example 6. For the SODE
¨x = x + u,
|u| ≤1,
x ∈R,
(44)
the inverse Lagrangian is given by
L(t, x, ˙x, u) = 1
2 ˙x2 + 1
2x2 + ux
(45)
The extremal controls u∗in order to steer the system to the point (x, ˙x) = (0, 0), are
given by
u∗(x, ˙x) =
	
1,
x > 0,
−1,
x < 0.
(46)
The trajectories that lead us to the goal should be the minimal curves which are given
by the following equations
1
2 ˙x2 + 1
2x2 + x = 0,
1
2 ˙x2 + 1
2x2 −x = 0
(47)
the solutions to which are circles with centers (1, 0) and (−1, 0) and radius 1.
It is quite evident from the above examples that the chief ingredient for the synthesis
of feedback optimal controls is the inverse Lagrangian for the control SODEs. Given an
optimal control problem as following:
min
u∈U
 T
0
L(t, x, u)dt
(48)
subject to the constraints
˙x = f(t, x, u),
g1(x, ˙x, u) ≤0,
x(T ) = 0.
(49)
1. Reduction to a time-optimal control problem: The following idea of transforming
the variational problem into a time-optimal control problem was used earlier by
Gamkralidze to prove some existence results. We ﬁrst reparametrize the time vari-
able t with a new variable s
s(t) =
 t
0
L(τ, x(τ), u(τ))dτ,
t ∈[a, b],
(50)
which is a strictly monotonous continuous function of t, for any pair (x(t), u(t))
satisfying ˙x(t) = F(t, x(t), u(t)). As far as
ds(t)
dt
= L(t, x(t), u(t)) > 0,
(51)
then s(·) admits a monotonous inverse function t(·) deﬁned on [0, T ], such that
dt
ds(s) =
1
L(t(s), x(s), u(s)) .
(52)

A Synthesis Algorithm for Hybrid Systems
267
Obviously
dx(t(s))
ds
= dx(t(s))
dt
dt(s)
ds
= F(t(s), x(s), u(s))
L(t(s), x(s), u(s))
(53)
We can transform the original problem into the following time-optimal problem
min
u∈U T
(54)
subject to
˙t =
1
L(t, x, u)
(55)
˙x = f(t, x, u)
L(t, x, u)
(56)
g(x, ˙x, u) ≤0
(57)
2. Construct a ﬁrst-order inverse Lagrangian Linv(t, x, ˙x, u) for the control system
(assuming u to be a constant parameter), such that the control system is indeed its
Euler-Lagrange equations.
3. Having thus derived a inverse Lagrangian for the dynamic optimal control problem,
we have essentially transformed the problem into the following ﬁnite dimensional
optimization problem
u∗(t, x, ˙x) = arg min
u∈U

V ⊂R2n Linv(t, z, u)dz,
(58)
where z = (x, ˙x), and U = {u|g(z, u) ≤0}. If the inverse Lagrangian Linv is
convex in u, then we have an unique extremal control u∗, otherwise, one will have
to optimize a relaxed inverse Lagrangian. The relaxation could be done by twice
applying the Young-Fenchel transform on the inverse Lagrangian.
Cu(L(z, u)) = L∗∗(z, u) = max
u∗{u∗· u∗−L∗(z, u∗)}
(59)
where L∗is deﬁned as the conjugate of L by
L∗(z, u∗) = max
u {u∗· u −L(z, u)} .
(60)
When L(z, u) is not convex in u then the transform Cu when applied on L gives
the convex envelope of L.
4. Finally we compute the optimal trajectories which steer the system towards the goal
by solving for z in the following equation
L(z, u∗) = 0.
(61)
The hypersurfaces which satisfy the above condition bifurcate the extremal trajec-
tories computed in step 3 and steer the system towards its goal in an optimal sense.
This concludes the synthesis algorithm.

268
S. Gottipati and A. Nerode
We have sketched an algorithm which synthesizes feedback controls along the lines
of Hilbert’s direct method for the multidimensional calculus of variations problems.
The algorithm needs to be developed to include state constraints (physical) and logical
constraints. This would probably require introducing potential ﬁelds into system. The
challenging part though of this algorithm is the computation of the inverse Lagrangian.
However, we believe that the computation of a symbolic inverse Lagrangian would
greatly help in the modeling and design of hybrid systems.
References
1. R. Bellman, Dynamic Programming, Princeton Un iversity Press, Princeton, N.J., 1957.
2. J. Douglass, Solution of the inverse problem of the calculus of variations, Trans. Am. Math.
Soc.,50, 71-128. 1941.
3. H. Helmholtz, Uber der physikalische Bedeutung des Princips der kleinsten Wirkung, J.
Reine Angew. Math., 100, 137-166. 1957.
4. M. Henneaux, On the inverse problem of the calculus of variations, J. Phys. A: Math. Gen.
15, L93-L96, 1957.
5. A. Hirsch, Die Existenzbedingungen des verallgemeinerten kinetischen Potentials, Math.
Ann., 50, 429-441. 1957.
6. W. Kohn, A. Nerode, J. Remmel, Hybrid systems as Finsler manifolds: ﬁnite state control
as approximation to connections, Hybrid systems, II (Ithaca, NY, 1994), 294-321, Lecture
Notes in Comput. Sci., 999, Springer, Berlin, 1995.
7. W. Kohn, V. Brayman, and A. Nerode, Control synthesis in Hybrid systems with Finsler
dynamics, Houston Journal of Mathematics, Vol.28, No. 2, 2002.
8. W. Kohn, V. Brayman, P. Cholewinski and A. Nerode, Control in Hybrid Systems, Interna-
tional Journal of Hybrid Systems, Volume 3, No 2 & 3, 2003.
9. M. Matsumoto, Foundations of Finsler geometry and special Finsler spaces, Kaiseicha Press,
Otsu, 1986.
10. A. Mayer, Die Existenzbedingungen ines kinetischen potentiales, Berich. Verh. Konig. Sach.
Gesell. wissen, Leipzig, Math. Phys, Kl. 84, 519-529 1957.
11. A. Nerode and W. Kohn, Models for Hybrid Systems: Automata, Topologies, Controllability,
Observability, LNCS Hybrid Systems, 1993.
12. L.S. Pontryagin, V.G. Boltyanskii, R.V. Gamkrelidze, and E.F. Michenko, The Mathematical
Theory of Optimal Processes, John-Wiley Interscience publishers 1962.
13. H. Rund, The differential geometry of Finsler spaces, Springer-Verlag, Berlin-Gottingen-
Heidelberg, 1959.
14. W. Sarlet, The Helmholtz conditions revisited. A new approach to the inverse problem of
Lagrangian dynamics, J. Phys. A: Math. Gen. 15, 1503-1517, 1993.
15. Z. Shen, Differential Geometry of Spray and Finsler Spaces, Kluwer Academic Publishers,
2001.

Including the Past in ‘Topologic’
Bernhard Heinemann
Fakult¨at f¨ur Mathematik und Informatik,
FernUniversit¨at in Hagen,
58084 Hagen, Germany
bernhard.heinemann@fernuni-hagen.de
Abstract. In this paper, we extend Moss and Parikh’s topo-logical view
of knowledge. We incorporate a further modality, denoted P, into the
original system. This operator describes the increase of sets. Regarding
the usual logic of knowledge, P corresponds to no learning of agents. In
the context of ‘topologic’, however, P represents the reverse eﬀort oper-
ator and is related to the past therefore. It is our objective to prove nice
properties of the accompanying logic like soundness and completeness
with respect to the intended class of structures, or decidability. To this
end, we take up a hybrid logic point of view, among other things. This
not only yields the desired results, but also has some interesting conse-
quences with regard to applications.
Keywords: modal logic, the logic of knowledge, topological reasoning,
hybrid logic, temporal operators
1
Introduction
In the paper [1], Moss and Parikh presented a certain bi-modal logic of knowledge
and eﬀort. On the one hand, the language underlying that logic makes possible a
qualitative description of procedures gaining knowledge, and on the other hand
some expressive power concerning spatial concepts is provided. In fact, since
knowledge is represented through knowledge states, which are the sets of states
an agent in question considers possible at a time, knowledge acquisition appears
as a shrinking procedure regarding the space of all such sets. Thus ideas from
topology like closeness or neighbourhood turn up together with knowledge in a
natural way.
Moss and Parikh suggestively called their system topologic, and we adopt this
naming here. In the following, we brieﬂy recall the basics of the language of
topologic. As it has just been indicated, formulas may contain two one-place
operators: a modality K describing the knowledge of an agent and another one,
□, describing (e.g., computational) eﬀort. The domains for evaluating formu-
las are subset spaces (X, O, V ) consisting of a non-empty set X of states, a set
O of subsets of X representing the knowledge states of the agent, and a val-
uation V determining the states where the atomic propositions are true. The
S. Artemov and A. Nerode (Eds.): LFCS 2007, LNCS 4514, pp. 269–283, 2007.
c
⃝Springer-Verlag Berlin Heidelberg 2007

270
B. Heinemann
operator K then quantiﬁes across any U ∈O, whereas □quantiﬁes ‘down-
ward’ across O since shrinking and acquiring knowledge correspond to each
other.
After [1] was published, several classes of subset spaces, including the ordi-
nary topological ones, could be characterized within the framework of topologic;
cf [2,3,4,5]. Actually, the topological language proved to be quite suitable for
dealing with ‘local’ properties of points and sets (whereas more expressive power
is needed to capture ‘non-local’ notions); see the corresponding chapter of the
handbook [6] for more details regarding this and an overview of the current state
of the art.
In the present paper, we are less interested in spatial aspects than in those
related to time. Note that a temporal dimension already inheres in the eﬀort
modality □since □quantiﬁes across future knowledge states; this was made
more explicit, e.g., in the paper [7]. The new operator we consider, P, is the
converse of □. Thus P refers to properties in the past by quantifying ‘upward’
across O, i.e., over all knowledge states that contain the actual one. We shall,
therefore, call P the past operator more often than not, and only sometimes
emphasize its connection with the increase of sets.1
The epistemic relevance of P (in case this operator is regarded independent of
□) is worth mentioning. While the eﬀort operator is associated with no forgetting
of agents (also called perfect recall in the literature), the increase operator P
comes along with no learning; cf [10].
Integrating the past operator into topologic seems to be very natural. The
reader might wonder why this has not been done up to now. However, sometimes
this modality turns out to be temperamental, and we must use methods going
beyond ordinary modal logic for taming it. But it is worth doing this since we
really get a useful means of expression; e.g., the overlap operator studied in the
paper [11] will be deﬁnable then. This was the main motivation for us to examine
the properties of P. In retrospect, the promising results we obtained justify our
approach.
The subsequent technical part of the paper is organized as follows. In the
next section we recapitulate the language of topologic from [12] (which is the
journal version of [1]), and we deﬁne the semantics of the past operator at the
same time. We then give some examples of valid formulas of the extended lan-
guage. Moreover, we touch on the question of the expressiveness of P. In Section
3, we present a list of axioms for topologic including the past operator. Unfor-
tunately, we do not have a corresponding completeness theorem. However, as
the ﬁrst of the main issues of this paper we prove that the resulting logic is
at least decidable. In Section 4, we deal with a certain hybridization of topo-
logic including the past. Concerning the concepts from basic hybrid logic we
need for that, see, e.g., [13], Sec. 7.3. In this case we actually obtain the desired
1 It should be noted that a related modality was examined in the paper [8] with regard
to certain systems of linear time. However, the framework here is much more general,
and the technical details are completely diﬀerent from those there. – For a treatment
of the past in temporal logic of concurrency, see the paper [9].

Including the Past in ‘Topologic’
271
meta-theorems for the arising logic, i.e., soundness and completeness with respect
to subset spaces, and decidability. Furthermore, we point to a nice application of
that system. Finally, we give a brief summary of the paper and mention future
research.
2
The Extended Modal Language
In this section, we ﬁrst deﬁne the modal language, including the past operator,
for subset spaces. Second, we give some examples of valid formulas. Finally, the
expressive power of the new language is compared to that of a previous extension
of topologic.
Let PROP = {A, B, . . .} be a denumerable set of symbols. The elements
of PROP are called proposition letters. We deﬁne the set WFF of well-formed
formulas over PROP by the rule
α ::= A | ¬α | α ∧β | Kα | □α | Pα.
The operators K and □represent knowledge and eﬀort, respectively, as it is com-
mon for topologic. The operator P is the counterpart of □. Since P is, therefore,
related to the past we call this modality the past operator. The duals of K, □
and P are denoted L, 3 and ⟨P⟩, respectively. The missing boolean connectives
⊤, ⊥, ∨, →, ↔are treated as abbreviations, as needed.
We now turn to semantics. First, we deﬁne the domains for interpreting for-
mulas. Given a set X, let P(X) be the powerset of X.
Deﬁnition 1 (Subset frames and subset spaces)
1. Let X ̸= ∅be a set and O ⊆P(X) a set of subsets of X. Then, F := (X, O)
is called a (general) subset frame.
2. A subset frame F = (X, O) satisfying {∅, X} ⊆O is called special.
3. Let F = (X, O) be a subset frame. The set NF of neighbourhood situations of
F is deﬁned by NF := {(x, U) | x ∈U and U ∈O} . (Mostly, neighbourhood
situations are written without brackets later on.)
4. Let F be a subset frame. A mapping V : PROP −→P(X) is called an
F–valuation.
5. A subset space is a triple M := (X, O, V ) , where F = (X, O) is a subset
frame and V an F–valuation; M is called based on F.
The requirement ‘{∅, X} ⊆O’ from item 2 of this deﬁnition is convenient, but
in a sense insigniﬁcant for topologic because of the forward looking nature of the
eﬀort operator; cf [12], Sec. 1.1. This is no longer true for the extended system,
as one will see later on. Nevertheless, we continue to deal with special subset
frames in this paper as long as it is possible.
The next deﬁnition concerns the relation of satisfaction, which is deﬁned with
regard to subset spaces now.

272
B. Heinemann
Deﬁnition 2 (Satisfaction and validity). Let M = (X, O, V ) be a subset
space.
1. Let x, U be a neighbourhood situation of F = (X, O) . Then
x, U |=M A
: ⇐⇒x ∈V (A)
x, U |=M ¬α
: ⇐⇒x, U ̸|=M α
x, U |=M α ∧β : ⇐⇒x, U |=M α and x, U |=M β
x, U |=M Kα
: ⇐⇒∀y ∈U : y, U |=M α
x, U |=M □α
: ⇐⇒∀U ′ ∈O : (x ∈U ′ ⊆U ⇒x, U ′ |=M α)
x, U |=M Pα
: ⇐⇒∀U ′ ∈O : (U ′ ⊇U ⇒x, U ′ |=M α) ,
where A ∈PROP and α, β ∈WFF. In case x, U |=M α is true we say that
α holds in M at the neighbourhood situation x, U.
2. A formula α is called valid in M (written ‘M |= α’), iﬀit holds in M at
every neighbourhood situation of the frame M is based on.
Note that the meaning of proposition letters is independent of neighbourhoods
by deﬁnition, thus ‘stable’ with respect to □and P. This fact is reﬂected by a
special axiom below; see Section 3.
We now look for the formulas which are valid in all subset spaces. It is a
known fact that the schema
K□α →□Kα
is a typical validity of topologic. This schema was called the Cross Axiom in the
paper [12] and plays a key role in the completeness and the decidability proof for
that logic. The Cross Axiom describes the basic interaction between knowledge
and eﬀort. It is not very surprising that there is a complementary schema for P.
Proposition 1. Let M be any subset space. Then, for all α ∈WFF we have
that
M |= PKα →KPα.
The easy proof of Proposition 1 is omitted here. – Quite recently, a modal oper-
ator O was considered which describes overlapping of sets within the framework
of topologic; cf [11]. With the aid of O, it is possible to access also points that
are distant from the actual one. The precise semantics of O in subset spaces
M = (X, O, V ) at neighbourhood situations is as follows:
x, U |=M Oα : ⇐⇒∀U ′ ∈O : if x ∈U ′, then x, U ′ |=M α
where α ∈WFF. Compared to the semantics of the eﬀort operator, the condition
U ′ ⊆U obviously was left out; cf Deﬁnition 2. Thus shrinking appears as a special
case of overlapping. It turned out that O is rather strong. In fact, with the aid
of O even the global modality A (cf [13], Sec. 7.1) is deﬁnable in subset spaces
based on special subset frames, actually through
Aα :≡OK□α.

Including the Past in ‘Topologic’
273
Note that this is true since X ∈O. But now the overlap operator itself can be
deﬁned with regard to such subset spaces. The deﬁning clause reads
Oα :≡P□α.
Consequently, the approach from [11] is subsumed under the present one in a
sense. (For a fair comparison, however, one should take into account the issues
of the next section as well.)
3
A Decidable Fragment of the Logic
Our starting point to this section is the system of axioms for topologic from [12].
We then add several schemata involving the new modality. After that we derive
some auxiliary theorems of the resulting logic, topP, which are used for the proof
of the decidability of topP. This proof makes up the main part of Section 3.
Unless otherwise noted, all subset spaces occurring in this section are based
on special subset frames.
The complete list of axioms for topologic reads as follows:
1. All instances of propositional tautologies.
2. K(α →β) →(Kα →Kβ)
3. Kα →(α ∧KKα)
4. Lα →KLα
5. □(α →β) →(□α →□β)
6. (A →□A) ∧(3A →A)
7. □α →(α ∧□□α)
8. K□α →□Kα,
where A ∈PROP and α, β ∈WFF. In this way, it is expressed that for every
Kripke model M validating these axioms
– the accessibility relation
K
−→of M belonging to the knowledge operator is
an equivalence,
– the accessibility relation
□
−→of M belonging to the eﬀort operator is reﬂexive
and transitive,
– the composite relation
□
−→◦
K
−→is contained in
K
−→◦
□
−→(this is usually
called the cross property), and
– the valuation of M is constant along every
□
−→–path, for all propositional
letters.
We now turn to the axioms in which P occurs:
9. P(α →β) →(Pα →Pβ)
10. α →□⟨P⟩α
11. α →P3α
12. ⟨P⟩Pα →P⟨P⟩Lα,

274
B. Heinemann
where A and α, β are as above. – Some comments on these axioms seem to be
appropriate. Item 9 contains the usual distribution schema being valid for every
normal modality. The schemata 10 and 11 say that the accessibility relations
belonging to □and P, respectively, are inverse to each other. Note that the latter
relation is reﬂexive and transitive, which follows logically from the respective
property of the former one. All this is well-known from usual tense logic; cf, e.g.,
[14], § 6. The ﬁnal schema is to capture the property ‘X ∈O’ of subset spaces
axiomatically; cf the remark following Deﬁnition 1.
We obtain a logical system by adding the standard proof rules of modal logic,
i.e., modus ponens and necessitation with respect to each modality. We call this
system topP, indicating both topologic and the past operator.
Deﬁnition 3 (The logic). Let topP be the smallest set of formulas which con-
tains the axiom schemata 1 – 12 and is closed under the application of the
following rule schemata:
(modus ponens)
α →β, α
β
(Δ–necessitation)
α
Δα ,
where α, β ∈WFF and Δ ∈{K, □, P}. Then we let ⊢denote topP–derivability.
Some useful derivations are contained in the following lemma.
Lemma 1. For all A ∈PROP and α ∈WFF, we have that
1. ⊢(A →PA) ∧(⟨P⟩A →A)
2. ⊢LPα →PLα
3. ⊢PKα →KPα.
Proof.
1. From the second conjunct of Axiom 6 we get ⊢P3A →PA with
the aid of P–necessitation, Axiom 9 and propositional reasoning. Axiom 11
yields ⊢A →P3A. This gives us the ﬁrst conjunct of the desired schema.
From the ﬁrst conjunct of Axiom 6 we infer ⊢⟨P⟩A →⟨P⟩□A. The dual
of Axiom 11 and propositional reasoning then imply that ⊢⟨P⟩A →A, as
desired.
2. The formula LPα →P3LPα is an instance of Axiom 11. By using, among
other things, the dual of Axiom 8 we get ⊢P3LPα →PL3Pα. As a conse-
quence of the dual of Axiom 10, we have that ⊢PL3Pα →PLα. Proposi-
tional reasoning now yields ⊢LPα →PLα.
3. From Axiom 3 we infer (∗) ⊢Kα →α, for all α ∈WFF. Thus ⊢α →Lα,
for all formulas α. From that we get ⊢PKα →LPKα since this formula is
an instance of the just derived schema. Axiom 4 implies ⊢LPKα →KLPKα.
With the aid of item 2 of this lemma we obtain ⊢KLPKα →KPLKα. The
dual of Axiom 4 gives us ⊢KPLKα →KPKα, and (∗) ﬁnally implies ⊢
KPKα →KPα. It follows that ⊢PKα →KPα, as desired.
The schema from item 1 of this lemma is complementary to Axiom 6. Both
schemata together correspond to the stability condition mentioned in Section 2,

Including the Past in ‘Topologic’
275
right after Deﬁnition 2. The schema contained in item 3 is the one from Proposi-
tion 1 and will be called the Reverse Cross Axiom; see the discussion preceding
Proposition 1.
The next proposition is quite obvious.
Proposition 2 (Soundness). Let α ∈WFF be formula. If α is topP–derivable,
then α is valid in all subset spaces.
A possible proof of completeness must use the canonical model of topP in some
way. We ﬁx several notations concerning this model. Let C be the set of all
maximal topP–consistent sets of formulas. Furthermore, let
K
−→,
□
−→and
P
−→
be the accessibility relations on C induced by the modalities K, □and P,
respectively.
Three useful properties of the canonical model are listed in the subsequent
lemma.
Lemma 2.
1. For all Ψ, Γ, Θ ∈C satisfying Ψ
K
−→Γ
P
−→Θ there exists Ξ ∈C
such that Ψ
P
−→Ξ
K
−→Θ.
2. For all Ψ, Γ, Θ ∈C satisfying Ψ
P
−→Γ and Ψ
P
−→Θ there exist Ξ, Φ ∈C such
that Γ
P
−→Ξ and Θ
P
−→Φ
L
−→Ξ.
3.
 K
−→∪
□
−→∪
P
−→
∗
⊆
P
−→◦
K
−→◦
□
−→.
We only give some ideas, but not a detailed proof of Lemma 2 here. (The missing
details will be contained in the full version of this paper.) The condition stated in
item 1 follows from the Reverse Cross Axiom (see Lemma 1.3) and is, therefore,
called the reverse cross property. The condition from item 2 is, among other
things, a consequence of Axiom 12. Since a kind of conﬂuence of the accessibility
relation
P
−→is forced, we call item 2 the pseudo Church-Rosser property. Quite
some modal proof theory has to be applied in the proofs of items 1 and 2 of the
lemma. Item 3 ensues from an iterated application of the previous items and the
usual cross property, respectively.
Unfortunately, we do not have a proof of the completeness of topP with respect
to the class of all subset spaces based on special frames. An adaption to the new
system, including a suitable extension, of the corresponding proof for topologic
(cf [12], Sec. 2.2) does not work anyhow.2 This seems to be true even if the
speciality condition (item 2 of Deﬁnition 1) is weakened a little, in the following
way.
2 If we drop Axiom 12, then completeness for subset spaces based on general frames can
be proved in the just indicated way; cf [15]. The presence of that axiom, however, may
be viewed as an indication of incompleteness. This is due to the formal similarity of
Axiom 12 to the Weak Directedness Axiom for intersection spaces from [12], Sec. 2.4.
It is a known fact that the latter is incomplete. In particular, the question arises
whether all formulas of the form ⟨P⟩Pα →P⟨P⟩α, which are sound for special subset
spaces, are topP–derivable.

276
B. Heinemann
Deﬁnition 4 (Past-directed subset frames). A (general) subset frame F =
(X, O) is called past-directed, iﬀfor all U1, U2 ∈O there exists some U ∈O
such that U ⊇U1 ∪U2.
On the other hand, Lemma 2.2 suggests that completeness could hold for the
larger class of all spaces based on past-directed frames. We will refer to this class
of structures in the next section.
Contrasting those bad news, we at least can show that topP is decidable. This
is done in the following.
Since topologic does not satisfy the ﬁnite model property with respect to
subset spaces (cf [12], Sec. 1.3), topP too lacks this property. However, as in the
former case this deﬁciency can be circumvented by a detour via suitable Kripke
models.
Subsequently, let R and K, S and □, and T and P, respectively, correspond
to each other.
Deﬁnition 5 (topP–model). Let M := (W, {R, S, T }, V ) be a trimodal model,
i.e., R, S, T ⊆W × W are binary relations and V is a valuation in the usual
sense. Then, M is called a topP–model iﬀthe following conditions are satisﬁed:
1. R is an equivalence relation, and S is reﬂexive and transitive,
2. S and T are inverse to each other,
3. S ◦R ⊆R ◦S,
4. M satisﬁes the pseudo Church-Rosser property with respect to T and R,
5. for all w, w′ ∈W and A ∈PROP : if w S w′, then w ∈V (A) iﬀw′ ∈V (A).
It is easy to see that all the axioms considered above are sound with respect
to the class of all topP–models. Furthermore, the canonical model of topP is an
example of a topP–model. (As to item 4 from Deﬁnition 5, cf Lemma 2.2). This
gives us the following theorem.
Theorem 1 (Kripke completeness). The logic topP is sound and complete
with respect to the class of all topP–models.
We now use the method of ﬁltration for proving the ﬁnite model property of
topP with respect to topP–models. The proceeding here follows the one from
[12], Sec. 3.3, to a large degree. Thus we may be brief regarding this and stress
the new aspects only.
For a given topP–consistent formula α ∈WFF, we deﬁne a ﬁlter set Σ ⊆WFF
as follows. We ﬁrst let
Σ0 := sf(α) ∪{¬β | β ∈sf(α)},
where sf(α) denotes the set of all subformulas of α. Second, we form the closure
of Σ0 under ﬁnite conjunctions of pairwise distinct elements of Σ0. Third, we
close under single applications of the operator L. And ﬁnally, we form the set of
all subformulas of the formulas obtained up to now.3 Let Σ denote the resulting
set. Then Σ is ﬁnite and subformula closed.
3 Note that this step is really necessary since L is an abbreviation.

Including the Past in ‘Topologic’
277
We consider the respective smallest ﬁltrations of the accessibility relations
K
−→,
□
−→, and
P
−→, of the canonical model of topP; cf [14], § 4. Let
M := (W, {R, S, T }, V )
be the corresponding ﬁltration of a suitably generated submodel M ′ of that
model in which the valuation V assigns the empty set to all proposition letters
not occurring in Σ. Then we have the following lemma.
Lemma 3. The structure M is a ﬁnite topP–model of which the size depends
computably on the length of α.
Proof. Most of it is clear from the deﬁnitions and the proof of [12], Theorem
2.11. In particular, the ﬁniteness of W follows from the ﬁniteness of Σ. Only
items 2 and 4 of Deﬁnition 5 have to be checked yet.
For item 2, let Γ, Θ be two points of the canonical model such that [Γ] S [Θ],
where the brackets [. . .] indicate the respective classes. Due to the deﬁnition of
the minimal ﬁltration there are Γ ′ ∈[Γ] and Θ′ ∈[Θ] such that Γ ′
□
−→Θ′. Since
Θ′
P
−→Γ ′ then holds because of the dual of Axiom 10, we conclude [Θ] T [Γ]
from that with the aid of the ﬁrst ﬁltration condition (marked (F1) in [14],
§ 4). This shows S−1 ⊆T . By interchanging the roles of S and T , the property
T −1 ⊆S can be established in a similar manner. Now, the condition stated in
item 2 of Deﬁnition 5 easily follows.
Item 4 is a bit harder to prove. We make use of the following property (∗) of
the intermediate model M ′ introduced above:
(∗) For every ﬁnite set {Γ1, . . . , Γn} of points of M ′ there exists a point Γ
of M ′ such that (Γ, Γi) ∈
K
−→◦
□
−→for all i = 1, . . . , n (where n ≥1).
This is consequence of Lemma 2.3 and the fact that M ′ is generated. Now, it is
clear from the ﬁrst ﬁltration condition again that the property
(Ψ, Θ) ∈
K
−→◦
□
−→
passes down to the ﬁltration (where Ψ, Θ are any maximal topP–consistent sets).
Thus M is generated in the following sense. For all classes [Φ] ∈W we have that
([Γ], [Φ]) ∈R ◦S,
where Γ is obtained according to (∗) after arbitrary representatives of the ﬁnitely
many classes contained in W have been chosen. From that, the properties of R,
and item 2, the validity of the pseudo Church-Rosser property for M is clear.
Since the topP–model M from Lemma 3 realizes α, the claimed decidability
result follows readily.
Theorem 2 (Decidability). The set of all topP–derivable formulas is decidable.
Concerning the complexity of the topP–satisﬁability problem, we only mention
that this problem is very likely hard for EXPTIME. This is due to the (implicit)
presence of the global modality (see Section 2); cf [16], Ch. 2.2.

278
B. Heinemann
4
Hybridization
Concluding the technical part of the paper, we develop a hybrid logic version
of topP. This extension, HtopP, rectiﬁes the shortcomings of the former sys-
tem to some extent and simultaneously generalizes previous hybridizations of
topologic (e.g., the one from [11]). By enriching the language once again we
ﬁrst obtain much more expressive power concerning properties of relations, and
this can already be achieved by simply adding suitable sets of nominals to the
ground language; see the just cited paper for some examples. Second, HtopP
turns out to be sound and complete for subset spaces based on past-directed
frames. And ﬁnally, HtopP is decidable, too. We outline only the completeness
proof in this section.4 Actually, we will have ‘almost canonical’ completeness. As
an application, we show that the hybrid logic of directed spaces, cf [5], is ﬁnitely
axiomatizable and decidable.5 The ﬁrst property is false for the modal fragment,
and the second one apparantly was unknown before the hybrid methods came
into play.
We now carry out all these things. For a start, we deﬁne the extended lan-
guage. As we already indicated above, we merely add two sets of nominals to
the language underlying topP. If the denotation of a nominal is non-empty, then
it should be either a unique state or a distinguished set of states. Let
Nstat = {i, j, . . .} and Nsets = {I, J, . . .}
be the corresponding sets of symbols, which we call names of states and names of
sets, respectively. We assume that PROP, Nstat and Nsets are mutually disjoint.
Deﬁnition 6 (Subset spaces with names)
1. Let F = (X, O) be a past-directed subset frame. A hybrid F–valuation is a
mapping
V : PROP ∪Nstat ∪Nsets −→P(X)
such that
(a) V (i) is either ∅or a singleton subset of X, for every i ∈Nstat, and
(b) V (A) ∈O for every A ∈Nsets.
2. A subset space with names (or, in short, an SSN) is a triple (X, O, V ), where
F = (X, O) is a subset frame as in item 1 and V a hybrid F–valuation.
Note that nominals may have an empty denotation. This is appropriate for our
purposes since it simpliﬁes the proof of the subsequent Theorem 3 a little, but
not common in standard hybrid logic.
4 In order to establish decidability, the techniques from the previous section have to
be tailored to the hybrid context. Due to space limitations we cannot give too many
details regarding this here.
5 A subset frame F = (X, O) is called directed, iﬀ∀U1, U2 ∈O, ∀x ∈X : if x ∈
U1 ∩U2, then ∃U ∈O : x ∈U ⊆U1 ∩U2.

Including the Past in ‘Topologic’
279
Deﬁnition 7 (Satisfaction for nominals). Let M := (X, O, V ) be an SSN
and x, U a neighbourhood situation of the underlying frame. Then
x, U |=M i : ⇐⇒x ∈V (i)
x, U |=M I : ⇐⇒V (I) = U,
for all i ∈Nstat and I ∈Nsets.
We now turn to the axioms for nominals. These axioms are divided into two
groups. The formulas of the ﬁrst group provide for the right interpretation of
the names of states and sets, respectively, in the canonical model which is used
for the proof of completeness below.
13. i ∧α →K(i →α)
14. I →KI
15. K2 (I ∧α →Lβ) ∨K2 (I ∧β →Lα) ,
where i ∈Nstat, I ∈Nsets and α, β ∈WFF.6 The schema 13 says that only
one point of any
K
−→–equivalence class can be named by a ﬁxed state name.
And the schema 14 guarantees that a set name of such a class is valid across the
whole class. Finally, Axiom 15 captures the property that every element of Nsets
denotes at most one
K
−→–class. Note the formal similarity of this schema to the
linearity schema L from classical modal logic (cf [14], p 22).
The following two axioms are responsible for the fact that really a structure
of subset space can be ensured with the aid of that model.
16. i ∧I →□(3(i ∧I) →i ∧I)
17. K(3J →3I) ∧L3J →□(I →L3J) ,
where i, j ∈Nstat and I, J ∈Nsets. Axiom 16 corresponds to the antisymmetry of
the relation
□
−→on the canonical model we construct later on. The part Axiom
17 plays is less obvious. Roughly speaking, the inclusion relation of subsets is
arranged correctly by this axiom.
By ﬁxing the hybrid proof rules we get to the logical system HtopP. The new
rules are called name and enrichment, respectively. We comment on these
rules right after the next deﬁnition.
Deﬁnition 8 (The hybrid logic). Let HtopP be the smallest set of formulas
which contains the axiom schemata 1 – 17 and is closed under the application
of the standard modal rule schemata and the following ones:
(namestat)
j →β
β
(namesets)
J →β
β
(∇–enrichment)
⟨P⟩L3 (i ∧I ∧∇(j ∧J ∧α)) →β
⟨P⟩L3 (i ∧I ∧∇α) →β
,
where α, β ∈WFF, i, j ∈Nstat, I, J ∈Nsets, ∇∈{L, 3, ⟨P⟩}, and j, J are new
each time, i.e., do not occur in any other syntactic building block of the respective
rule.
6 From now on, WFF denotes the set of formulas of the enriched language.

280
B. Heinemann
For the reader being not familiar with these unorthodox proof rules a ‘contra-
pository’ reading is suggested; e.g., the rule (namestat) is to be read ‘if β is
satisﬁable, then j ∧β is satisﬁable, too’ (provided that the nominal j does not
occur in β). The soundness of the hybrid rules should be apparent from that
now. Technically, the name and enrichment rules are used for establishing an
appropriate Lindenbaum Lemma, which makes up the ﬁrst step in the proof of
the following theorem.
Theorem 3 (Hybrid completeness). HtopP is sound and complete with re-
spect to the class of all subset spaces with names.
Proof. The proof of Theorem 3 goes along the lines of the proof of Theorem 3.2
from [17], but some modiﬁcations are required during the construction of the
model refuting a given non-derivable formula α. We start oﬀwith the canonical
model of HtopP. Let us retain the designations C,
K
−→,
□
−→, and
P
−→from the
previous section, and let Γ0 be a maximal consistent set containing ¬α. If Γ is
any element of C, then Γ is called
– named iﬀΓ contains some i ∈Nstat and some I ∈Nsets, and
– enriched iﬀ, for every ∇∈{L, 3, ⟨P⟩}, whenever ⟨P⟩L3 (i ∧I ∧∇α) ∈Γ,
then there are j ∈Nstat and J ∈Nsets such that
⟨P⟩L3 (i ∧I ∧∇(j ∧J ∧α)) ∈Γ.
Now, it is our ﬁrst task to extend Γ0 to a named and enriched maximal con-
sistent set Γ ′ in the language to which enough new constants have been added.
This can be achieved in the usual way by means of the Lindenbaum Lemma
mentioned above.
Secondly, we consider the canonical model of HtopP which is formed with re-
spect to the latter language. Let M0 be the submodel generated by Γ ′ of this
model. We then have that the interpretation of the set names in M0 is uniquely
determined.7
Lemma 4. Let D be the domain of M0 and let I be a set name. Assume that
both of Γ, Γ ′ ∈D contain I. Then Γ
K
−→Γ ′.
Proof. Suppose on the contrary that there are two points Γ, Γ ′ ∈D such that
I ∈Γ ∩Γ ′, but not Γ
K
−→Γ ′. Then there is some n ∈N and a sequence
Γ0, Γ1, . . . , Γn of elements of D such that Γ0 = Γ, Γn = Γ ′, and Γi, Γi+1 are
connected by either
K
−→,
□
−→, or
P
−→, for all i = 0 . . . n −1. This is true since
M0 is generated. Now, Lemma 2.3 implies that there exist Ψ, Θ ∈D such that
Γ
P
−→Ψ
K
−→Θ
□
−→Γ ′.
The desired contradiction then follows with the aid of Axiom 15.
7 We exemplarily focus on this point of the completeness proof a little more detailedly.

Including the Past in ‘Topologic’
281
Let D′ be the set of all points of D that are named, and let M′ be the cor-
responding substructure of M0. M′ is the model we want to operate on. The
subsequent Existence Lemma is due to our special notion of enrichment.
Lemma 5. Assume that Γ ∈D′ contains ∇α, where ∇∈{L, 3, ⟨P⟩} is the
respective dual of Δ ∈{K, □, P}. Then there exists some Θ ∈D′ satisfying
Γ
Δ
−→Θ and α ∈Θ.
The desired model falsifying α can be obtained as a certain space of partial
functions, X, over the model M′ now. The domain dom(h) of every such function
h ∈X is a subset of the set
Q := {[Γ] | Γ ∈D′}
of all equivalence classes [Γ] := {Γ ′ ∈D′ | Γ
K
−→Γ ′} of the accessibility relation
induced by the modality K. Actually, dom(h) is maximal in Q with regard to
the following two conditions:
1. h([Γ]) ∈[Γ] for all [Γ] ∈dom(h), and
2. h([Γ])
□
−→h([Θ]) for all [Γ], [Θ] ∈dom(h) satisfying [Γ] ≼[Θ];
the precedence relation ≼occurring in the second item is deﬁned by
[Γ] ≼[Θ] : ⇐⇒∃Γ ′ ∈[Γ], Θ′ ∈[Θ] : Γ ′
□
−→Θ′,
for all points Γ, Θ ∈D′.8 We write hΓ := h([Γ]) in case h([Γ]) exists. Further-
more, we let
– U[Γ] := {h ∈X | hΓ exists}, for all Γ ∈D′,
– O := {U[Γ] | Γ ∈D′}, and
– V : PROP ∪Nstat ∪Nsets −→P(X) be deﬁned by
h ∈V (c) : ⇐⇒c ∈hΓ for some Γ ∈D′ for which hΓ exists,
for all c ∈PROP ∪Nstat ∪Nsets.
We then get that M := (X, O, V ) is a past-directed subset space for which the
relevant Truth Lemma is valid. With that, the completeness of the system HtopP
with respect to the intended class of structures can be concluded in a standard
manner.
In addition, we obtain that the hybrid logic of past-directed subset spaces is
decidable.
Theorem 4 (Hybrid decidability). The set of all HtopP–derivable formulas
is decidable.
8 Note that again quite some proof theory has to be used for establishing that h is
well-deﬁned.

282
B. Heinemann
As aforementioned, we have to skip the proof of this theorem here. For getting an
idea of the proceeding the reader is referred to [17], proof of Theorem 4.4. But we
at least want to emphasize the point crucial to hybrid decidability. This concerns
the veriﬁcation of the ﬁnal group of axioms (16 and 17 above) with regard to a
ﬁltration. Actually, it is not necessary to establish the corresponding property
on the ﬁltrated model, but only to validate those instances of the schemata in
which nominals from the ﬁlter set occur. This can be achieved by modifying that
ﬁlter set appropriately.
At the end of this section, we revisit the ‘guarded jump’–operators investigated
in the paper [18]. For convenience, we remind the reader of the semantics of these
operators. Let M = (X, O, V ) be an SSN and x, U a neighbourhood situation
of the underlying frame. Then
x, U |=M [ϵI]α : ⇐⇒if x ∈V (I), then x, V (I) |=M α,
for all I ∈Nsets and α ∈WFF. The ‘guarded jump’–operators are, therefore,
named variants of the overlap operator considered in Section 2. Thus it is hardly
surprising [ϵI] can be deﬁned as well:
[ϵI]α :≡P2(I →α),
for all α ∈WFF. As a consequence, we get that all the results obtained in
the paper [18] can be inferred from the theorems of the present section. This
applies to the hybrid logic of directed SSNs9 and, in particular, the modal logic
of directed spaces; cf [18], Theorem 20 and Corollary 21, and the discussion in
the introduction to this section.
Theorem 5 (The logic of directed spaces)
1. The hybrid logic of directed SSNs is ﬁnitely axiomatizable and decidable.
2. The topo-logic of directed spaces is decidable.
More details concerning this application of the hybrid formalism will be con-
tained in the full version of this paper.
5
Concluding Remarks
In this paper, Moss and Parikh’s topologic was extended by a modality reversing
the eﬀort operator. While this goes smoothly for general subset frames, some
complications arise if special frames form the semantic basis. In this case we
could identify a natural fragment, topP, of the accompanying logic and prove its
decidability. Incorporating concepts from hybrid logic then yielded more satis-
factory results. We established the soundness, completeness, and decidability, of
the hybrid logic of past-directed subset spaces. From that, the decidability of
the logic of directed spaces was obtained as a corollary.
It remains to solve the completeness problem for topP. Moreover, the com-
plexity of the logics must be determined each time. All this is postponed to
future research.
9 The axiom capturing directedness reads 3I ∧3J →3K (⟨ϵI⟩⊤∧⟨ϵJ⟩⊤) , where
I, J ∈Nsets and ⟨ϵI⟩denotes the dual of [ϵI].

Including the Past in ‘Topologic’
283
References
1. Moss, L.S., Parikh, R.:
Topological reasoning and the logic of knowledge.
In
Moses, Y., ed.: Theoretical Aspects of Reasoning about Knowledge (TARK 1992),
Los Altos, CA, Morgan Kaufmann (1992) 95–105
2. Georgatos, K.: Knowledge theoretic properties of topological spaces. In Masuch,
M., P´olos, L., eds.: Knowledge Representation and Uncertainty, Logic at Work.
Volume 808 of Lecture Notes in Artiﬁcial Intelligence., Springer (1994) 147–159
3. Georgatos, K.: Knowledge on treelike spaces. Studia Logica 59 (1997) 271–301
4. Heinemann, B.:
Topological Modal Logics Satisfying Finite Chain Conditions.
Notre Dame Journal of Formal Logic 39 (1998) 406–421
5. Weiss, M.A., Parikh, R.: Completeness of certain bimodal logics for subset spaces.
Studia Logica 71 (2002) 1–30
6. Aiello, M., Pratt-Hartmann, I., van Benthem, J.: The logic of space (2007?) To
appear. See URL http://dit.unitn.it/ aiellom/hsl/.
7. Heinemann, B.: Temporal Aspects of the Modal Logic of Subset Spaces. Theoretical
Computer Science 224 (1999) 135–155
8. Heinemann, B.: Linear tense logics of increasing sets. Journal of Logic and Com-
putation 12 (2002) 583–606
9. Lichtenstein, O., Pnueli, A., Zuck, L.: The glory of the past. In Parikh, R., ed.:
Logics of Programs. Volume 193 of Lecture Notes in Computer Science., Berlin,
Springer (1985) 196–218
10. Halpern, J.Y., van der Meyden, R., Vardi, M.Y.: Complete Axiomatizations for
Reasoning about Knowledge and Time. SIAM Journal on Computing 33 (2004)
674–703
11. Heinemann, B.: Regarding overlaps in ‘topologic’. In Governatori, G., Hodkinson,
I., Venema, Y., eds.: Advances in Modal Logic 6, London, College Publications
(2006) 259–277
12. Dabrowski, A., Moss, L.S., Parikh, R.:
Topological reasoning and the logic of
knowledge. Annals of Pure and Applied Logic 78 (1996) 73–110
13. Blackburn, P., de Rijke, M., Venema, Y.: Modal Logic. Volume 53 of Cambridge
Tracts in Theoretical Computer Science. Cambridge University Press, Cambridge
(2001)
14. Goldblatt, R.: Logics of Time and Computation. second edn. Volume 7 of CSLI
Lecture Notes. Center for the Study of Language and Information, Stanford, CA
(1992)
15. Heinemann, B.:
Some spatial and spatio-temporal operators derived from the
topological view of knowledge. In Wilson, D., Sutcliﬀe, G., eds.: Proceedings 20th
International Florida Artiﬁcial Intelligence Research Society Conference (FLAIRS
2007), Menlo Park, CA, AAAI Press (2007) To appear.
16. Spaan, E.: Complexity of Modal Logics. PhD thesis, ILLC, Universiteit van Ams-
terdam (1993)
17. Heinemann, B.:
A hybrid logic for reasoning about knowledge and topology
(2005) Under review for journal publication. For a preliminary version see URL
http://www.informatik.fernuni-hagen.de/thi1/ber.ps.
18. Heinemann, B.: A two-sorted hybrid logic including guarded jumps. In Schmidt,
R., Pratt-Hartmann, I., Reynolds, M., Wansing, H., eds.: Advances in Modal Logic
5, London, King’s College Publications (2005) 73–92

A Note on Rewriting Proofs and Fibonacci
Numbers
Max Kanovich
Computer Science Dept., Queen Mary, University of London,
Mile End Road, London, E1 4NS, UK
mik@dcs.qmul.ac.uk
Abstract. One basic activity in combinatorics is to establish combina-
torial identities by so-called ‘bijective proofs,’ which amounts to con-
structing explicit bijections between two types of the combinatorial ob-
jects in question.
The aim of this paper is to show how techniques from the formal
logic world can be applied directly to such problems studied completely
independently in the world of combinatorics.
The basic idea is to characterize equinumerous partition ideals in
terms of the minimal elements generating the order ﬁlters, the comple-
ments to the original ideals.
For the case where the minimal elements of each of these order ﬁlters
are disjoint, we have developed a general automated method to remove
the mystery of certain known results and establish new results in the
theory of integer partitions: Kanovich [Finding direct partition bijec-
tions by two-directional rewriting techniques. Discrete Math., 285 (1-3)
(2004) 151-166], and Kanovich [The two-way rewriting in action: Re-
moving the mystery of Euler-Glaisher’s map. Discrete Math., (2006),
doi:10.1016/j.disc.2006.10.005].
Here we address the case of ﬁlters having overlapping minimal
elements. Essentially this is a case study related to the Fibonacci nu-
meration system.
In addition to a ‘bijective proof’ for Zeckendorf’s theorem - that every
positive integer is uniquely representable within the Fibonacci numera-
tion system, we establish ‘bijective proofs’ for a new series of partition
identities related to Fibonacci and Lucas numbers.
The main result is proved using the idea of ﬁlter supports, and
rewriting systems on multisets having overlapping patterns.
The main technical step is a suitable construction of such a rewrit-
ing system and then a proof that this rewriting system and the system
consisting of its reverse rewriting rules, both have the Church-Rosser
property, with providing the bijections we are looking for.
Keywords: multiset rewriting, Church-Rosser property, conﬂuence,
termination, strong normalization, combinatorics, integer partitions, par-
tition identities, Fibonacci numbers.
S. Artemov and A. Nerode (Eds.): LFCS 2007, LNCS 4514, pp. 284–292, 2007.
c
⃝Springer-Verlag Berlin Heidelberg 2007

A Note on Rewriting Proofs and Fibonacci Numbers
285
1
Motivating Examples and Summary
One basic activity in combinatorics is to establish partition identities by so-called
‘bijective proofs,’ which amounts to constructing explicit bijections between two
classes of the partitions at hand.
Forming an interdisciplinary bridge between Theoretical Computer Science
and Combinatorics, the aim of this paper is to show how techniques from the
formal logic world can be applied directly to speciﬁc problems studied completely
independently in the theory of integer partitions.
The basic idea is to characterize equinumerous partition ideals in terms of the
minimal elements generating the order ﬁlters, the complements to the original
ideals.
The novelty of our approach to the combinatorics of partitions is in the use
of rewriting techniques (two-directional in the sense that forward and backward
applications of rewrite rules head respectively for two diﬀerent normal forms)
for the purpose of establishing explicit relevant bijections between partitions of
two diﬀerent types (represented by these normal forms).
The case where the minimal elements of each of the order ﬁlters mentioned
above are disjoint is fully covered by a general approach developed in Kanovich
[7,8].
Here we will address the challenging case of ﬁlters having overlapping minimal
elements.
An inspiring example is the Fibonacci numeration system:
Theorem 1 (Zeckendorf [14]). Every positive integer is uniquely representable
as a sum of distinct Fibonacci numbers, but where no two consecutive Fibonacci
numbers are used.
We will use the two-directional rewriting technique to construct a ‘bijective
proof’ for Zeckendorf’s theorem and to establish ‘bijective proofs’ for a new
series of partition identities related to Fibonacci and Lucas numbers.
The Fibonacci numbers ui and Lucas numbers li are deﬁned as
u1 = 1, u2 = 1, ui+2 = ui+ui+1
(i = 1, 2, 3, . . .),
l1 = 2,
l2 = 1,
li+2 = li+li+1
(i = 1, 2, 3, . . .),
2
Backgrounds
Let us recall the background material with which we are dealing (see, for in-
stance, Andrews[1]).
An integer partition of
n = m1 + m2 + · · · + mk
can be identiﬁed as a multiset M consisting of positive integers m1, m2,. . . , mk.
We will represent this M as
M = {m1, m2, . . . , mk},

286
M. Kanovich
where the number of copies of some m shows the multiplicity of the m within M.
Each mi is called a part of the partition. This sum
m1+m2+· · ·+mk will
be also denoted by ∥M∥:
∥M∥= m1 + m2 + · · · + mk.
Deﬁnition 1. Let p(C, n) stand for the number of partitions of n that belong to
a given class C.
Two classes of partitions C1 and C2 are called equinumerous, if for all n:
p(C1, n) = p(C2, n).
Example 1. Zeckendorf’s theorem says that:
For any positive integer n, the number of partitions of n into ones equals
the number of partitions of n into distinct Fibonacci parts with no con-
secutive Fibonacci parts (both numbers are equal to 1).
Deﬁnition 2. (Andrews[1]) Generally, the classes C of partitions considered in
the literature have the ‘local’ property that if M is a partition in C and one or
more parts are removed from M to form a new partition M ′, then M ′ is also
in C.
Such a class C is called a partition ideal, or an order ideal in terms of the
lattice P of ﬁnite multisets of positive integers, ordered by ⊆.
1
Dually, a class F ⊆P is an order ﬁlter if M ′ ∈F, whenever M ∈F and
M ⊆M ′.
It is readily seen that C is a partition ideal if and only if its complement C is an
order ﬁlter.
Deﬁnition 3. M is minimal in an order ﬁlter F, if M ∈F and M ′ = M, for
any multiset M ′ ∈F such that M ′ ⊆M.
The support of F is deﬁned as the set of all its minimal elements.
The case where the minimal elements of certain order ﬁlters are disjoint is covered
by the following general criterion from Kanovich[7].
Theorem 2 (Kanovich[7]). Let C and C′ be partition ideals such that the
support of the ﬁlter C (the ﬁlter which is the complement to C) is made of
pairwise disjoint multisets, say
C1, C2, . . . , Ci, . . . ,
and the support of the ﬁlter C′ (the ﬁlter which is the complement to C′) is made
of pairwise disjoint multisets
C′
1, C′
2, . . . , C′
i, . . . .
1 We say that M ′ ⊆M if M ′ can be formed by removing a number of parts from M.
For instance,
{1, 5} ⊆{1, 1, 3, 5, 5, 5}.

A Note on Rewriting Proofs and Fibonacci Numbers
287
Assume that these supports are sorted as lists so that the sequence of integers
∥C1∥, ∥C2∥, . . . , ∥Ci∥, . . .
is non-decreasing, and the sequence of integers
∥C′
1∥, ∥C′
2∥, . . . , ∥C′
i∥, . . .
is non-decreasing.
Then C and C′ are equinumerous if and only if:
∥Ci∥= ∥C′
i∥,
for all i.
In addition to that, the system Γ consisting of the following multiset rewriting
rules:
γ1 : C1 →C′
1,
γ2 : C2 →C′
2,
. . . ,
γi : Ci →C′
i,
. . .
provides2 a bijection h between C′ and C.
Moreover, the inverse bijection h−1 from C onto C′ is computed here with the
help of the system Γ −1 consisting of the ‘reverse’ rewriting rules:
γ−1
1
: C′
1 →C1,
γ−1
2
: C′
2 →C2,
. . . ,
γ−1
i
: C′
i →Ci,
. . .
3
The Main Result
We introduce a two-directional rewriting scheme in the following way.
Deﬁnition 4. Let Γ be a set of reduction rules:
γ1 : A1 →B1, γ2 : A2 →B2, . . . ,
γi : Ai →Bi, . . . .
The reversed rules γ−1
i
: Bi →Ai form Γ −1:
γ−1
1
: B1 →A1, γ−1
2
: B2 →A2, . . . ,
γ−1
i
: Bi →Ai, . . . .
The A-normal forms are the Γ-irreducible forms, i.e. the forms that do not
contain any of the following list:
A = A1, A2, . . . , Ai, . . . ,
and the B-normal forms are the Γ −1-irreducible forms, i.e. the forms that do not
contain any of the following list:
B = B1, B2, . . . , Bi, . . . .
An intended bijection h between B-normal forms and A-normal forms is de-
ﬁned as follows:
h(M) := 
M, if 
M is an A-normal form, and
M is Γ-reducible to 
M.
(1)
2 We say “provides a bijection h between two classes of integer partitions C1 and C2”
meaning that, for any n, function h is a bijection between the partitions of n that
belong to C1 and the partitions of the n that belong to C2.

288
M. Kanovich
Deﬁnition 5. We will say that Γ is B-terminating if every sequence of
Γ-
reductions must terminate in a ﬁnite number of steps, whenever it started from
a B-normal form.
Proposition 1. Let both Γ and Γ −1 be conﬂuent, and Γ be B-terminating,
and Γ −1 be A-terminating.
Then the above h is a well-deﬁned bijection between B-normal forms and
A-normal forms.
Remark 1. As a matter of fact, we need a strong “stratiﬁed” version of the
conclusion of Proposition 1 to supply a bijection between two sets of partitions
of a ﬁxed n, and to show thereby that the two sets of partitions of the n are
equinumerous:
For any ﬁxed n, the above h should be a bijection between B-normal partitions
of the n and A-normal partitions of the same n.
The most natural way to guarantee this property is to invoke the following
‘balance conditions’ - that for all i,

a∈Ai
a =

b∈Bi
b .
In this ‘balanced case’ only partitions of one and the same n may appear within
any sequence of Γ-reductions.
3.1
The ‘bijective proof’ for Zeckendorf’s Theorem
Within Zeckendorf’s theorem we are dealing with a partition ideal consisting of
partitions into distinct Fibonacci numbers with no consecutive Fibonacci parts.
The order ﬁlter, the complement to this ideal, is generated by its minimal
elements:
{1, 1}, {1, 2}, {2, 2}, {2, 3}, {3, 3}, {3, 5}, {5, 5}, . . ., {4}, {6}, {7}, . . .,
Since some of these minimal elements overlap, general ‘non-overlapping’ the-
orems, like Theorem 2, do not work, and we have to treat such an ‘overlapping
case’ in a speciﬁc way.
Below we give a ‘bijective proof’ for Zeckendorf’s theorem.
Theorem 3. Let C be a partition ideal consisting of partitions with no Fibonacci
parts being repeated or consecutive Fibonacci numbers, and C′ be a partition ideal
consisting of partitions that have no Fibonacci parts but 1; in both cases non-
Fibonacci parts may appear without restriction.
We can construct an explicit bijection between C′ and C.
Proof Sketch.
Call the A-normal forms the multisets that do not have any of the minimal
elements of the order ﬁlter C (which is the complement to C):
{1, 1}, {1, 2}, {2, 2}, {2, 3}, {3, 3}, {3, 5}, . . ., {ui, ui}, {ui, ui+1}, . . .

A Note on Rewriting Proofs and Fibonacci Numbers
289
As the B-normal forms, we take the multisets that do not have any of the
minimal elements of the order ﬁlter C′ (which is the complement to C′):
{2}, {3}, {5}, {8}, {13}, . . ., {ui+1}, . . .
We introduce the following system of rewriting rules Γ(2):
γ1: {1, 1} →{2}, γ′
1: {2, 2} →{1, 3},
γ2: {1, 2} →{3}, γ′
2: {3, 3} →{1, 5},
γ3: {2, 3} →{5}, γ′
3: {5, 5} →{2, 8}, . . . ,
γi: {ui, ui+1} →{ui+2}, γ′
i: {ui+2, ui+2} →{ui, ui+3}, . . . (i = 1, 2, . . .)
(2)
Accordingly, the ‘reverse’ system Γ −1
(2) will consist of the following reverse
rewriting rules:
γ−1
1 : {2} →{1, 1}, γ′
1
−1: {1, 3} →{2, 2},
γ−1
2 : {3} →{1, 2}, γ′
2
−1: {1, 5} →{3, 3},
γ−1
3 : {5} →{2, 3}, γ′
3
−1: {2, 8} →{5, 5}, . . . ,
γ−1
i
: {ui+2} →{ui, ui+1}, γ′
i
−1: {ui, ui+3} →{ui+2, ui+2}, . . . (i = 1, 2, . . .)
(3)
Example 2. We illustrate the proof of Theorem 3 by applying Γ(2) to the parti-
tion of 7:
M = {1, 1, 1, 1, 1, 1, 1}.
We can proceed, for instance, in the following way:
{1, 1, 1, 1, 1, 1, 1} γ1
−→{2, 1, 1, 1, 1, 1} γ1
−→{2, 2, 1, 1, 1} γ1
−→
{2, 2, 2, 1} γ2
−→{2, 2, 3} γ′
1
−→{1, 3, 3} γ′
2
−→{1, 1, 5} γ1
−→{2, 5}
terminating in {2, 5}, the correct representation of 7 in the Fibonacci numeration
system.
On the reverse, starting from a partition of the form {2, 5}, Γ −1
(2) terminates
in the original {1, 1, 1, 1, 1, 1, 1}.
Lemma 1. Systems Γ(2) and Γ −1
(2) are conﬂuent and strongly normalizing.
Proof. Here we suppose that partitions are thought of as non-increasing se-
quences of integers.
(a) For the forward direction, notice that each of the rules (2) yields a partition
that takes a higher position in the lexicographical order.
On the other hand, each of the rules (2) preserves the partition norm ∥M∥.

290
M. Kanovich
Since this ‘combined’ ordering is well-founded, any sequence of Γ(2)-reductions
must terminate.
On a case-by-case basis, Γ(2) is proved to be locally conﬂuent.
These two facts - that Γ(2) is strongly normalizing and locally conﬂuent,
imply that Γ(2) is conﬂuent (cf. Newman’s Lemma [3,9]).
(b) For the reverse direction, notice that the reverse rules reduce any partition M
lexicographically down to a partition with no Fibonacci parts but 1.
Therefore, any sequence of Γ −1
(2)-reductions terminates with a unique normal
form.
Now we can complete the prove of Theorem 3.
Since our A-normal forms turn out to be exactly the Γ(2)-irreducible forms,
and our B-normal forms turn out to be exactly the Γ −1
(2)-irreducible forms, Propo-
sition 1 provides a bijection h between C′ and C.
Remark 2. Theorem 3 is not within reach of known ‘bijective’ methods [13].
In particular
(a) There is no way to sort these two lists
{1, 1}, {1, 2}, {2, 2}, {2, 3}, {3, 3}, {3, 5}, . . ., {ui, ui}, {ui, ui+1}, . . .
and
{2}, {3}, {5}, {8}, {13}, . . ., {ui+1}, . . .
to be suited for Remmel’s algorithm[11].
(b) Similarly, the sieve method from Wilf [13] cannot be applied to Theorem 3.
3.2
The ‘bijective proofs’ for New Partition Identities Related to
Generalized Fibonacci Numbers
The rewriting construction introduced in the proof of Theorem 3 can be easily
generalized for Fibonacci-like numbers produced by the following scheme:
Deﬁnition 6. Given positive integers a and b, let deﬁne F-numbers vi as
follows:
v1 = a, v2 = b, vi+2 = vi+vi+1
(i = 1, 2, 3, . . .)
(4)
For a = b = 1, we have Fibonacci numbers: 1, 1, 2, 3, 5, . . .
For a = 2, b = 1, we get Lucas numbers: 2, 1, 3, 4, 7, . . .
Our goal is to prove the following:
Theorem 4. For any n, the number of partitions of n into F-numbers whose
parts are neither repeated F-numbers with indices greater than 2 nor consecutive
F-numbers equals the number of partitions of n into a’s and b’s.

A Note on Rewriting Proofs and Fibonacci Numbers
291
Proof. Similar to the bijective proof of Theorem 3, we introduce the following
system Γ(5) consisting of the rewriting rules:
γ1: {v1, v2} →{v3}, γ′
1: {v3, v3} →{v1, v4},
γ2: {v2, v3} →{v4}, γ′
2: {v4, v4} →{v2, v5},
γ3: {v3, v4} →{v5}, γ′
3: {v5, v5} →{v3, v6}, . . . ,
γi: {vi, vi+1} →{vi+2}, γ′
i: {vi+2, vi+2} →{vi, vi+3}, . . . (i = 1, 2, 3, . . .)
(5)
Accordingly, the ‘reverse’ system Γ −1
(5) will consist of the reverse rewriting
rules:
γ−1
1 : {v3} →{v1, v2}, γ′
1
−1: {v1, v4} →{v3, v3},
γ−1
2 : {v4} →{v2, v3}, γ′
2
−1: {v2, v5} →{v4, v4},
γ−1
3 : {v5} →{v3, v4}, γ′
3
−1: {v3, v6} →{v5, v5}, . . . ,
γ−1
i
: {vi+2} →{vi, vi+1}, γ′
i
−1: {vi, vi+3} →{vi+2, vi+2}, . . . (i = 1, 2, . . .)
(6)
By the same token of Lemma 1, we prove that both systems Γ(5) and Γ −1
(5)
are conﬂuent and strongly normalizing.
The eﬀect is that Proposition 1 provides a bijection h between the partition
ideals in question.
Theorem 4 yields a series of new partition identities.
For instance, by taking a = 2, b = 1, and a = 1, b = 2, respectively, Theorem 4
yields the following Corollary 1:
Corollary 1. The following classes of partitions are pairwise equinumerous:
(a) The class of partitions into ones and twos.
(b) The class of partitions into Lucas parts whose parts are neither repeated
Lucas numbers greater than 2 nor consecutive Lucas numbers.
(c) The class of partitions into Fibonacci parts whose parts are neither repeated
Fibonacci numbers greater than 2 nor distinct consecutive Fibonacci num-
bers.
Proof
(i)
Take a = 2, b = 1, to cover the case of partitions into Lucas parts.
(ii) Take a = 1, b = 2, to cover the case of partitions into Fibonacci parts.
4
Concluding Remarks
The novelty of our formal systems approach to the combinatorics is in the use
of rewriting techniques (two-directional in the sense that forward and backward
applications of rewrite rules head respectively for two diﬀerent normal forms)

292
M. Kanovich
for the purpose of establishing explicit relevant bijections between combinatorial
objects of two diﬀerent types (represented by these normal forms).
As compared to Kanovich[7,8], here we have discussed the challenges of the
‘overlapping’ multiset rewriting systems.
As a possible step towards the much loftier goal of classifying all equinumerous
partition ideals, we have shown the ‘bijective proofs’ of a new series of partition
identities related to Fibonacci and Lucas numbers.
Acknowledgments
I owe special thanks to George Andrews and Herb Wilf for their inspiring intro-
duction to the world of integer partitions and for valuable discussions on how
techniques from the rewriting world can be useful to sort out speciﬁc mathemat-
ical problems studied completely independently in the world of combinatorics.
References
1. G.E.Andrews. The Theory of Partitions, Cambridge University Press, 1998.
2. F.Baader and T.Nipkow. Term Rewriting and All That. Cambridge University
Press, 1998.
3. N.Dershowitz and J.-P.Jouannaud. Rewrite systems. In J.van Leeuwen, ed., Hand-
book of Theoretical Computer Science, volume B, pp 243–320. Elsevier, 1990.
4. A.M.Garsia and S.C.Milne, Method for constructing bijections for classical parti-
tion identities. Proc. Nat. Acad. Sci. U.S.A. 78 (1981), no. 4(1), 2026–2028.
5. Basil Gordon, Sieve-equivalence and explicit bijections, J. Combin. Theory Ser. A
34 (1983), no. 1, 90–93.
6. K.M. O’Hara, Bijections for partition identities. J. Combin. Theory Ser. A 49
(1988), no. 1, 13–25.
7. M.Kanovich. Finding direct partition bijections by two-directional rewriting tech-
niques. Discrete Mathematics, Volume 285, Issues 1-3, 6 August 2004, pp. 151-166.
The preliminary version: Bijections between partitions by two-directional rewriting
techniques. In: Proc. Annual Conference of the European Association for Computer
Science Logic, CSL’02, September 22-25, 2002 Edinburgh, Scotland, Lecture Notes
in Computer Science 2471, J.Bradﬁeld (Ed.), pp. 44–58, 2002.
8. M.Kanovich. The two-way rewriting in action: Removing the mystery of Euler-
Glaisher’s map. Discrete Mathematics (2006), doi:10.1016/j.disc.2006.10.005, 27p.
9. J.W.Klop.
Term
rewriting
systems.
In:
S.Abramsky,
D.M.Gabbay,
and
T.S.E.Maibaum, ed., Handbook of Logic in Computer Science, volume 2, pp 1–
116. Oxford University Press, New York, 1992.
10. D.Knuth. The Art of Computer Programming, Volume 2: Seminumerical Algo-
rithms, Addison-Wesley, 1997.
11. J.B.Remmel, Bijective proofs of some classical partition identities, J. Combin. The-
ory Ser. A 33 (1982), 273–286.
12. H.S.Wilf, Sieve equivalence in generalized partition theory, J. Combin. Theory
Ser. A 34 (1983), 80–89.
13. H.S.Wilf, Lectures on Integer Partitions, University of Victoria, Victoria, B.C.,
Canada, 2000, (<http://cis.upenn.edu/~wilf>).
14. E. Zeckendorf, A Generalized Fibonacci Numeration, Fibonacci Quarterly, vol 10
(1972), 365–372.

On Complexity of Ehrenfeucht-Fra¨ıss´e Games
Bakhadyr Khoussainov1 and Jiamou Liu2
1 Department of Computer Science
University of Auckland
New Zealand
2 Department of Computer Science
University of Auckland
New Zealand
Abstract. In this paper we initiate the study of Ehrenfeucht-Fra¨ıss´e games for
some standard ﬁnite structures. Examples of such standard structures are equiv-
alence relations, trees, unary relation structures, Boolean algebras, and some of
their natural expansions. The paper concerns the following question that we call
Ehrenfeucht-Fra¨ıss´e problem. Given n ∈ω as a parameter, two relational struc-
tures A and B from one of the classes of structures mentioned above, how eﬃcient
is it to decide if Duplicator wins the n-round EF game Gn(A, B)? We provide al-
gorithms for solving the Ehrenfeucht-Fra¨ıss´e problem for the mentioned classes
of structures. The running times of all the algorithms are bounded by constants.
We obtain the values of these constants as functions of n.
1
Introduction
Ehrenfeucht-Fra¨ıss´e (EF) games constitute an important tool in both ﬁnite and inﬁnite
model theory. For example, in inﬁnite model theory these games can be used to prove
Scott Isomorphism Theorem showing that all countable structures are described (up
to isomorphism) in Lω1,ω-logic. In ﬁnite model theory these games and their diﬀerent
versions are used for establishing expressibility results in the ﬁrst order logic and its
extensions. These results can be found in standard books in ﬁnite and inﬁnite model
theory (e.g. [6], [11]) or relatively recent papers (e.g. [2], [12]). In this paper all EF
games are considered on ﬁnite structures.
Despite signiﬁcant use of EF games in ﬁnite and inﬁnite model theory there has not
been, with some exceptions, much work in addressing eﬃciency of these games. M.
Grohe studied EF games with ﬁxed number of pebbles and showed that the problem
of deciding the winner is complete for PTIME [5]. E. Pezzoili showed that deciding
the winner of EF games is PSPACE-complete [14]. In [9] P. Kolaitis and J. Panttaja
prove that the following problem is EXPTIME-complete: given a natural number k and
structures A and B, does Duplicator win the k pebble existential EF game on A and B?
In [1] suﬃcient conditions are provided for Duplicator to win EF games. These condi-
tions are then used to prove some inexpressibility results, e.g reachability in undirected
graphs is not in monadic NP. These results suggest that developing tools and algorithms
for ﬁnding winners of EF are of interest. We also point out that there has recently been
an interest in EF games to collapse results in database theory [16]. In addition, we think
S. Artemov and A. Nerode (Eds.): LFCS 2007, LNCS 4514, pp. 293–309, 2007.
c⃝Springer-Verlag Berlin Heidelberg 2007

294
B. Khoussainov and J. Liu
that algorithms that solve EF games can be used in data matching and data transforma-
tion problems in databases.
In this paper we initiate the study of EF games for some standard ﬁnite structures.
Examples of such standard structures are equivalence relations, trees, unary relation
structures, Boolean algebras, and some of their natural expansions. The paper concerns
the following question that we call the Ehrenfeucht-Fra¨ıss´e problem. Given n ∈ω as
a parameter, two relational structures A and B, how eﬃcient is it to decide if Du-
plicator wins the n-round EF game Gn(A, B)? We provide algorithms for solving the
Ehrenfeucht-Fra¨ıss´e problem for the structures mentioned above. The running times of
all the algorithms are bounded by constants. We obtain the values of these constants as
functions of n.
By a structure we always mean a ﬁnite relational structure over a language with-
out functional symbols. Let A and B be structures and n ∈ω. EF game, denoted by
Gn(A, B), on these two structures is played as follows. There are two players, Duplica-
tor and Spoiler, both provided with A and B. The game consists of n rounds. Informally,
Duplicator’s goal is to show that these two structures are similar, while Spoiler needs
to show the opposite. At round i, Spoiler selects structure A or B, and then takes an
element from the selected structure. Duplicator responds by selecting element from the
other structure. Say, the players have produced the following play consisting of pairs
of elements (a1, b1), . . ., (an, bn), where ai ∈A and bi ∈B for i = 1, . . ., n. Note that
if Spoiler selected ai (or bi) then Duplicator selected bi (or ai, respectively). Duplicator
wins the play if the mapping ai →bi, i = 1, . . ., n, extended by mapping the values of
constant symbols cA to cB, is a partial isomorphism between A and B. It is clear that
if A and B are isomorphic then Duplicator wins the game Gn(A, B) no matter what n
is. The opposite is not always true. However, for large n if Duplicator wins the game
Gn(A, B) then A and B are isomorphic. Thus, solving the EF problem can be thought
as an approximation to the isomorphism problem.
One can do the following rough estimates for ﬁnding the winner of the game
Gn(A, B). There are ﬁnitely many, up to logical equivalence, formulas φ1, . . ., φk of
quantiﬁer rank n (see for example [11]). It is well known that Duplicator wins Gn(A, B)
if and only if for all φi ( with i = 1, . . ., k) the structure A satisﬁes φi if and only if B
satisﬁes φi [11]. Thus, the question if Duplicator wins Gn(A, B) can be solved in poly-
nomial time. However, there are two important issues here. The ﬁrst issue concerns the
number k that depends on n; k is approximately bounded by the n-repeated exponentia-
tions of 2. The second issue concerns the degree of the polynomial for the running time
that is bounded by n. Thus, the questions arise as to for which standard structures the
value of k is feasible as a function of n, and whether the degree of the polynomial for the
running time can be pushed down. As an example consider the class of linear orders.
It is well-known that Duplicator wins Gn(A, B), where A and B are linear orders, if
and only if either |A| = |B| or both |A| > 2n and |B| > 2n (e.g. [11]). In this example,
the number k, roughly, equals to 2n. The degree of polynomial for the running time is
0. Thus, when n is ﬁxed the winner of the game can be found in constant time, and the
constant that bounds the time is 2n.
A brief overview of this paper is as follows. The next section gives an elementary
solution to EF games in the case when the language contains unary predicates only. The

On Complexity of Ehrenfeucht-Fra¨ıss´e Games
295
third, fourth and ﬁfth sections are quite technical and devoted to solving EF games for
equivalence structures and some of their extensions. Equivalence structures are natural
models of university or large company databases. For example, in a university database
there could be the SameFaculty and the SameDepartment relations. The ﬁrst relation
stores all tuples (x, y) such that x and y belong to the same faculty; similarly, the second
relation stores all tuples (u, v) such that u and v are in the same department. These re-
lations are equivalence relations. Moreover, the set-theoretic connection between these
relations is that the relation SameDepartment is a subset of the SameFaculty relation.
We call such structures embedded equivalence relation structures. Section 6 reduces the
question of deciding EF games for trees of a given height to solving the EP games for
embedded equivalence structures introduced in the previous sections. Finally, the main
structures in the last section are Boolean algebras with distinguished ideals.
Each of these sections provides an algorithm that decides EF games Gn(A, B), where
A and B are structures considered in the section. These algorithms run in constant
times with n being a parameter. We also bound the value of the constants as a function
of n. Clearly, the constants obtained depend on the representations of the structures.
In each case, it will be clear from the content how we represent our structures. As an
example we state two results of Sections 4 and 5. Section 4 is devoted to structures
of the type (A; E, P1, ..., Ps), where E is an equivalence relation on A and P1, ..., Ps are
unary predicates. We call these structures equivalence structures with s colors. The main
result of Section 4 is the following:
Theorem 1. Fix n ∈ω. There exists an algorithm that runs in constant time and decides
whether Duplicator wins the game Gn(A, B) on equivalence structures with s colors.
The constant that bounds the running time is n2s+1.
Section 5 is devoted to the structures of type (A; E1, . . ., Eh), where each Ei is an equiv-
alence relation on A and E1 ⊆E2 ⊆. . . ⊆Eh. These structures are called embedded
equivalence structures of height h. The main result of Section 5 is:
Theorem 2. Fix n ∈ω. There exists an algorithm that runs in constant time and decides
whether Duplicator wins the game Gn(A, B) on embedded equivalence structures of
height h. The constant that bounds the running time is (n + 1)...(n+1)n where the tower has
height h.
2
Simple Example: Structures with Unary Predicates
This is an elementary section that gives a full solution for EF games in the case when
the language contains unary predicates only. Here is the main result of this section.
Theorem 3. Fix the language L = (P1, . . ., Ps), where each Pi is a unary predicate
symbol. Let n ∈ω. There exists an algorithm that runs in constant time and decides
whether Duplicator wins the game Gn(A, B) on structures A and B of the language.
The constant that bounds the running time is 2s · n.
Proof. Let A = (A; P1, P2, ..., Ps) and B = (B; P1, P2, ..., Ps) be structures of the lan-
guage given. For structure A = (A; P1, P2, ..., Ps), we set Ps+1 = 
i ¬Pi.

296
B. Khoussainov and J. Liu
Lemma 1. Suppose P1, P2, ..., Ps are pairwise disjoint. Then Duplicator wins Gn(A, B)
if and only if for all 1 ≤i ≤s + 1 if |PA
i | < n or |PB
i | < n then |PA
i | = |PB
i |. In particular,
when Duplicator wins it is the case that for all 1 ≤i ≤s + 1, |PA
i | ≥n if and only if
|PB
i | ≥n.
To prove the lemma suppose that there is 1 ≤i ≤k+1 such that |PA
i | < n but |PA
i |  |PB
i |.
Assume |PB
i | < |PA
i |. Then Spoiler selects |PA
i | elements from PA
i . This strategy is clearly
a winning strategy for Spoiler. For the other direction, assume that hypothesis of the
lemma holds. Duplicator has a winning strategy as follows. At round k, assume that the
players have produced the k-round play (a1, b1), ..., (ak, bk) such that for each 1 ≤i ≤k,
ai ∈A, bi ∈B. If Spoiler selects ak+1 ∈A, then Duplicator responds by selecting
bk+1 ∈B as follows: If ak+1 = ai for some i then bk+1 = bi. Otherwise if ak+1 ∈PA
j
for some 1 ≤j ≤k, then bk+1 ∈PB
j so that bk+1  {b1, . . . , bk}. The case when Spoiler
selects an element from B is treated similarly. The strategy is clearly winning.
⊓⊔
Now assume that for a structure A, the unary predicates P1, P2, ..., Ps are not necessarily
pairwise disjoint. For each element x ∈A, deﬁne the characteristic of x, ch(x), as a
binary sequence (t1, t2, ..., ts) such that for each 1 ≤i ≤s, ti ∈{0, 1} if x ∈Pi and
ti = 0 otherwise. There are 2s pairwise distinct characteristics, and we order them in
lexicographic order: ch1, ..., ch2s. Construct the structure A′ = (A; Q1, ..., Q2s) such
that for all 1 ≤i ≤2s, Qi = {x ∈A | ch(x) = chi}. The following is now an easy lemma.
Lemma 2. Duplicator wins Gn(A, B) if and only if Duplicator wins Gn(A′, B′).
⊓⊔
We now represent A and B by 2s lists, and the ith list lists all elements with characteristic
chi. To solve the game Gn(A′, B′), the algorithm checks the conditions in Lemma 1 by
reading the lists. The process takes time bounded by 2s · n as required.
⊓⊔
3
Equivalence Structures
An equivalence structure is a structure A of the type (A; E) where E is an equivalence
relation on A. We list all the equivalence classes of A as A1, ..., Ak such that |Ai| ≤|Ai+1|
for all 1 ≤i < k. Let qA be the number of equivalent classes in A; for each t < n,
let qA
t be the number of equivalence classes in A with size t. Finally, let qA
≥r be the
number of equivalence classes in A of size at least r. For an equivalence structure B we
have similar notations as B1, B2, . . . to denote its equivalence classes, and the associated
numbers qB, qB
t , and qB
≥r.
Lemma 3. If Duplicator wins the game Gn(A, B) on equivalence structures A and B,
then the following must be true:
1. If qA < n or qB < n then qA = qB; and
2. qA ≥n if and only if qB ≥n.
⊓⊔
In our analysis below, by the above lemma, we always assume that qA = qB or qA ≥n
if and only if qB ≥n. We need the following notation for the next lemma and deﬁnition.
For t ≤n, let qt = min{qA
≥t, qB
≥t}. Let At and Bt be equivalence structures obtained by
taking out exactly qt equivalence classes of size ≥t from A and B respectively. We also
set n −qt to be 0 in case qt ≥n; and otherwise n −qt has its natural meaning.

On Complexity of Ehrenfeucht-Fra¨ıss´e Games
297
Lemma 4.
1. Assume that there is a t < n such that qA
t
 qB
t and n −qt > t. Then
Spoiler wins the game Gn(A, B).
2. Assume that there is a t ≤n such that n −qt > 0 and one of the structures At or
Bt has an equivalence class of size ≥n −qt and the other structure does not. Then
Spoiler wins the game Gn(A, B).
Proof. We prove the ﬁrst part of the lemma. The second part is proved similarly. As-
sume, without loss of generality, that qA
t > qB
t and n −qB
t > t. Spoiler’s strategy is the
following. First, select elements a1, . . . , aqB
t from distinct equivalence classes of size t
in A. Next, select t distinct elements in the equivalence class of size t in A. This leads
Spoiler to win.
⊓⊔
Deﬁnition 1.
1. We say that Gn(A, B) has small disparity if there is a t < n such that
either qA
t  qB
t and n −qt > t.
2. We say that Gn(A, B) has large disparity if there exists a t ≤n such that n −qt > 0
and one of the structures At or Bt has an equivalence class of size ≥n −qt and the
other structure does not.
Lemma 5. Duplicator wins the game Gn(A, B) if and only if the game Gn(A, B) has
neither small nor large disparity.
Proof. The previous lemma proves one direction. For the other, we assume that nei-
ther small nor large disparity occurs in the game. We describe a winning strategy for
Duplicator.
Let us a assume that the players have produced a k-round play (a1, b1), (a2, b2), ...,
(ak, bk). In case k = 0, we are at the start of the game Gn(A, B). Our inductive assump-
tions on this k-round play are the following:
1. E(ai, a j) is true in A if and only if E(bi, b j) is true in B, and the map ai →bi is
one-to-one.
2. For all ai, |[ai]| ≥n−i if and only if |[bi]| ≥n−i, where [x] denotes the equivalence
class of x.
3. For ai if |[ai]| < n −i then |[ai]| = |[bi]|.
4. Let A′ and B′ be the equivalence structures obtained by removing the equivalence
classes [a1], . . ., [ak] from A and the equivalence classes [b1], . . ., [bk] from B,
respectively. We assume that A′ and B′ satisfy the following conditions:
(a) In game Gn−k(A′, B′) no small disparity occurs.
(b) In game Gn−k(A′, B′) no large disparity occurs.
Assume that Spoiler selects ak+1 ∈A. Duplicator responds by choosing bk+1 as fol-
lows. If ak+1 = ai then bk+1 = bi. Otherwise, if E(ai, ak+1) is true in A then Duplicator
chooses a new bk+1 such that E(bi, bk+1) is true in B. Assume ak+1 is not equivalent to
any of the elements a1, . . ., ak. If |[ak+1]| ≥n −k then Duplicator chooses bk+1 such
that bk+1 is not equivalent to any of the elements b1, . . . , bk and |[bk+1]| ≥n −k. Dupli-
cator can select such an element as otherwise large disparity would occur in the game.
If |[ak+1]| < n−k then Duplicator chooses bk+1 such that |[bk+1]| = |[ak+1]| and bk+1 is not

298
B. Khoussainov and J. Liu
equivalent to any of the elements b1, . . ., bk. The case when Spoiler selects an element
from B is treated similarly.
Now we show that the (k + 1)-round play (a1, b1), (a2, b2), ..., (ak, bk), (ak+1, bk+1) sat-
isﬁes the inductive assumptions. The inductive assumptions (1), (2), and (3) can easily
be checked to be preserved. To show that the assumption (4) is preserved, consider the
equivalence structures A′′ and B′′ obtained by removing the equivalence classes [a1],
. . ., [ak], [ak+1] from A and the equivalence classes [b1], . . ., [bk], [bk+1] from B, respec-
tively. In game Gn−k−1(A′′, B′′) small disparity does not occur as otherwise the game
Gn−k(A′, B′) would have small disparity. Thus, assumption (4a) is also preserved. Simi-
larly, if Gn−k−1(A′′, B′′) had large disparity then the game Gn−k(A′, B′) would also have
large disparity contradicting the inductive assumption. Hence, the strategy described
must be a winning strategy due to the fact that Duplicator preserves the inductive as-
sumption (1) at each round.
⊓⊔
For the next theorem, we represent each equivalence structure A and B in two lists. For
example, the ﬁrst list for the structure A lists all equivalence classes of A in increas-
ing order; the second list is qA, qA
1 , qA
≥1, qA
2 , qA
≥2, . . .. The lemmas above give us the
following:
Theorem 4. Fix n ∈ω. There exists an algorithm that runs in constant time and decides
whether Duplicator wins the game Gn(A, B) on equivalence structures A = (A; E) and
B = (B; E). The constant that bounds the running time is n.
⊓⊔
We can extend the above theorem by deﬁning the following structures:
Deﬁnition 2. A homogeneous equivalence structure is (A; E, P1, . . ., Ps) such that
– (A; E) is an equivalence structure; and
– Each Pi is a homogeneous unary relation on A meaning that for all x, y ∈A if
E(x, y) then x ∈Pi if and only if y ∈Pi.
For a homogeneous equivalence structure A, deﬁne the characteristic ch(x) of an ele-
ment x ∈A as in Section 2. Represent A as a disjoint union of equivalence structures
A1, . . ., A2s, where Aϵ consists of elements with characteristic ϵ. The above theorem is
thus extended to:
Theorem 5. There exists an algorithm that runs in constant time and decides whether
Duplicator wins the game Gn(A, B) on homogeneous equivalence structures A and B.
The constant that bounds the running time is 2s · n.
⊓⊔
4
Equivalence Structures with Colors
In this section structures A are of the form (A; E, P1, ..., Ps), where E is an equivalence
relation on A and P1, ..., Ps are unary predicates on A. We call these equivalence struc-
tures with s colors. We start with the case when s = 1. The case for s > 2 will be
explained later.

On Complexity of Ehrenfeucht-Fra¨ıss´e Games
299
Let A = (A; E, P) be a equivalence structure with one color. Say x ∈A is colored if
P(x) is true; otherwise x is non-colored. An equivalence class X has type tp(X) = (i, j),
if the number of colored elements of X is i, non-colored elements is j; thus, i + j = |X|.
Deﬁnition 3. Given two types (i, j) and (i′, j′) respectively. We say that (i, j) is colored
n-equivalent to (i′, j′), denoted by (i, j) ≡C
n (i′, j′), if the following holds.
1. If i < n then i′ = i; otherwise i′ ≥n.
2. If j < n −1 then j′ = j; otherwise j′ ≥n −1.
We say that (i, j) is non-colored n-equivalent to (i′, j′), denoted by (i, j) ≡N
n (i′, j′), if
the following holds.
1. If j < n then j′ = j; otherwise j′ ≥n.
2. If i < n −1 then i′ = i; otherwise i′ ≥n −1.
For X ⊆A, we use (X; E ↾X, P ↾X) to denote the equivalence structure obtained by
restricting E and P on X. Note that given two equivalence classes X and Y of types
(i, j) and (i′, j′) respectively, if (i, j) is colored (non-colored) n-equivalent to (i′, j′),
then Duplicator wins the n-round game played on structures (X; E ↾X, P ↾X) and
(Y, E ↾Y, P ↾Y), given the fact that Spoiler chooses a colored (non-colored) element in
the ﬁrst round.
Lemma 6. If either (i′, j′) ≡C
n (i, j) or (i′, j′) ≡N
n (i, j), then (i′, j′) ≡C
n−1 (i, j) and
(i′, j′) ≡N
n−1 (i, j).
⊓⊔
For an equivalence structure A = (A; E, P), we need the following notations:
– For type (i, j) and k ≥1, Set CA
(i, j),k be the set {X | X is an equivalence class of A
and tp(X) ≡C
k (i, j)}. Set NA
(i, j),k be the set {X | X is an equivalence class of A and
tp(X) ≡N
k (i, j)}
– For type (i, j) and k ≥1, set qA,C
(i, j),k = |CA
(i, j),k|, and set qA,N
(i, j),k = |NA
(i, j),k|.
– For A and B, set qC
(i, j),k = min{qA,C
(i, j),k, qB,C
(i, j),k} and qN
(i, j),k = min{qA,N
(i, j),k, qB,N
(i, j),k}
– Set AC((i, j), k) be the structure obtained from A by removing qC
(i, j),k equivalence
classes in CA
(i, j),k.
– Set AN((i, j), k) be the structure obtained from A by removing qN
(i, j),k equivalence
classes in NA
(i, j),k.
Observe the following. If Spoiler selects a colored element from an equivalence class
X in A, and Duplicator responds by selecting a colored element from an equivalence
class Y such that tp(Y) ≡C
n tp(X), there is no point for Spoiler to play inside X because
this will guarantee a win for Duplicator. Conversely, suppose Spoiler selects a colored
element from an equivalence class X in A, and there is no equivalence class in B whose
type is colored n-equivalent to tp(X). Then Spoiler has a winning strategy by playing
inside X and Y.

300
B. Khoussainov and J. Liu
Deﬁnition 4. Consider the game Gn(A, B) played on equivalence structures with one
color. We say that a colored disparity occurs if there exists a type (i, j) and n > k ≥0
such that the following holds:
1. k = qC
(i, j),n−k.
2. In one of AC((i, j), n −k) and BC((i, j), n −k), there is an equivalence class whose
type is colored (n −k)-equivalent to (i, j), and no such equivalence class exists in
the other structure.
We say that a non-colored disparity occurs if there exists a type (i, j) and n > k ≥0
such that the following holds:
1. k = qN
(i, j),n−k.
2. In one of AN((i, j), n −k) and BN((i, j), n −k), there is an equivalence class whose
type is non-colored (n −k)-equivalent to (i, j), and no such equivalence class exists
in the other structure.
Lemma 7. Suppose A and B are two equivalence structures with one color. Duplica-
tor wins the game Gn(A, B) if and only if neither colored disparity nor non-colored
disparity occurs in the game.
Proof. If either colored or non-colored disparity occurs in the game, then it is not too
hard to see that Spoiler wins the game. Suppose that neither colored disparity nor non-
colored disparity occurs in the game Gn(A, B), we describe a strategy for Duplicator.
Let us assume that the players have produced a k-round play (a1, b1), (a2, b2), ..., (ak, bk).
Let (il, jl) and (i′
l, j′
l) be the types of al and bl,respectively with 1 ≤l ≤k. Our inductive
assumptions on this k-round play are the following:
1. For any 1 ≤l ≤k, al is a colored element if and only if bl is a colored element.
2. For any 1 ≤l, m ≤k, E(al, am) if and only if E(bl, bm).
3. For any 1 ≤l ≤k, (il, jl) ≡C
n−l (i′
l, j′
l) and (il, jl) ≡N
n−l (i′
l, j′
l).
4. Let A′ and B′ be the equivalence structures obtained by removing equivalence
classes [a1], ..., [ak] from A and [b1], ..., [bk] from B, respectively. We assume in
game Gn−k neither colored disparity nor non-colored disparity occurs.
Assume that Spoiler selects an element ak+1 ∈A. Duplicator responds to this move
by choosing bk+1 as follows. If ak+1 = al then bk+1 = bl. Otherwise, if E(ak+1, al) is
true in A, then Duplicator chooses a new bk+1 such that E(bk+1, bl) and ak+1 is a colored
element if and only if bk+1 is a colored element. By (3) of the inductive assumption,
Duplicator can always select such an element bk+1.
Assume ak+1 is not equivalent to any of the element a1, ..., ak. Let X be the equiva-
lence class of ak+1 in A. If ak+1 is a colored element, then Duplicator chooses a colored
element bk+1 from an equivalence class Y of B such that tp(X) ≡C
n−k tp(Y). If ak+1 is a
non-colored element, then Duplicator chooses a non-colored bk+1 from an equivalence
class Y of B such that tp(X) ≡N
n−k tp(Y). Note that such an equivalence class Y must exist
in B as otherwise either colored or non-colored disparity would occur in Gn−k(A′, B′)
as witnessed by tp(X) and 0. The case when Spoiler selects an element from B is treated
in a similar manner.

On Complexity of Ehrenfeucht-Fra¨ıss´e Games
301
On the play (a1, b1), ..., (ak, bk), (ak+1, bk+1), the inductive assumption (1) and (2) can
be easily checked to hold. To prove that inductive assumption (3) holds, let (ik+1, jk+1)
and (i′
k+1, j′
k+1) be the type of [ak+1] and [bk+1] respectively. The strategy ensures one
of (ik+1, jk+1) ≡C
n−k (i′
k+1, j′
k+1) and (ik+1, jk+1) ≡N
n−k (i′
k+1, j′
k+1) is true, and by Lemma
6, (ik+1, jk+1) ≡C
n−k−1 (i′
k+1, j′
k+1) and (ik+1, jk+1) ≡N
n−k−1 (i′
k+1, j′
k+1). It is now routine to
show, by using Lemma 6, that inductive assumption (4) is preserved.
Thus, the strategy is winning for Duplicator by inductive assumptions (1) and (2).
⊓⊔
For the next theorem we represent colored equivalence structures A in three lists. The
ﬁrst one lists equivalence classes of A in increasing order of their types; the second and
the third list the sequences {qA,C
(i, j),k}0≤i, j,k≤n and {qA,N
(i, j),k}0≤i, j,k≤n respectively:
Theorem 6. Fix n ∈ω. There exists an algorithm that runs in constant time and decides
whether Duplicator wins the game Gn(A, B) on equivalence structures with one color
A and B. The constant that bounds the running time is n3.
⊓⊔
Fix s > 1, let A be an equivalence structure with s many colors. For each element x
of A, deﬁne the characteristic of x as deﬁned in the previous sections. There are 2s
distinct characteristics. Order them in lexicographic order: ch1, ..., ch2s. Construct the
structure A′ = (A; E, Q1, ..., Q2s) such that for all 1 ≤i ≤2s, Qi = {x ∈A | ch(x) = chi}.
Clearly, for distinct characteristics chi and ch j we have Qi ∩Q j = ∅. Moreover, A and
B are isomorphic if and only if A′ and B′ are isomorphic.
For an equivalence class X, we deﬁne the type of X, tp(X), as a sequence (i1, i2, ..., i2s)
such that in X the number of element with characteristic ch j is i j for all 1 ≤j ≤2s.
Deﬁnition 5. Let κ = (i1, ..., i2s) and λ = (i′
1, ..., i′
2s) be two types of equivalence classes.
For 1 ≤j ≤2s, we say that κ is (j, n)-equivalent to λ, denoted by κ ≡j
n λ, if the following
holds.
1. If i j < n then i′
j = i j, otherwise i′
j ≥n; and
2. For all 1 ≤l ≤2s where l  j, if il < n −1 then i′
l = il, otherwise i′
l ≥n −1.
Let X and Y be equivalence classes of types κ and λ respectively. If κ ≡j
n λ, then Du-
plicator wins the n-round EF game played on structures (X; E ↾X, P1 ↾X, ..., Ps ↾X)
and (Y; E ↾Y, P1 ↾Y, ..., Ps ↾Y), given that Spoiler selects an element x ∈X with
characteristic ch j.
For type λ, 1 ≤j ≤2s and k ≥1, we set CA, j
λ,k be the set {X | X is an equivalence class
of A and tp(X) ≡j
k λ}. Similar to the case of equivalence structures with one color, one
introduces notations qA, j
λ,k, q j
λ,k, and A j(λ, k).
Deﬁnition 6. Consider the game Gn(A, B) played on equivalence structures with s
colors. For 1 ≤j ≤2s, we say that a disparity occurs with respect to ch j if there
exists a type λ = (i1, ..., i2s) and n > k ≥0 such that the following holds:
1. k = q j
λ,n−k
2. In one of A j(λ, n−k), there is an equivalence class whose type is (j, n−k)-equivalent
to λ, and no such equivalence class exists in the other structure.

302
B. Khoussainov and J. Liu
The proof of the following are similar to Lemma 7 and Theorem 6:
Lemma 8. Let A and B be equivalence structures with s colors. Duplicator wins the
game Gn(A, B) if and only if no disparity occurs with respect to ch j for any 1 ≤j ≤2s.
⊓⊔
Theorem 7. Fix n ∈ω. There exists an algorithm that runs in constant time and decides
whether Duplicator wins the game Gn(A, B) on equivalence structures with s colors.
The constant that bounds the running time is n2s+1.
⊓⊔
5
Embedded Equivalence Structures
An embedded equivalence structure of height h is a structure A = (A; E1, E2, ..., Eh)
such that each Ei, 1 ≤i ≤h, is an equivalence relation, and Ei ⊆E j for i < j. In this
section we give a full solution for EF played on embedded equivalence structures of
height h. We start with the case when h = 2. The case for h > 2 will be explained later.
Let A = (A; E1, E2) be an embedded equivalence structure of height 2. We say that
an E2-equivalence class X has type tp(X) = (q1, . . ., qt) if the largest E1-equivalence
class contained in X has size t and for all 1 ≤i ≤t, qi is the number of E1-equivalence
classes of size i contained in X. Thus, t
i=1(qi × i) = |X|. For two types σ = (q1, . . . , qt1)
and τ = (q′
1, . . . , q′
t2), we say σ = τ if t1 = t2 and qi = q′
i for all 1 ≤i ≤t1.
For X ⊆A, we use (X; E1 ↾X) to denote the equivalence structure obtained by
restricting E1 on X. Given two E2-equivalence classes X and Y of types σ and τ respec-
tively, we say that σ is n-equivalent to τ, denoted by σ ≡n τ, if Duplicator wins the
n-round game played on structures (X; E1 ↾X) and (Y; E1 ↾Y). Note that if σ ≡n τ,
then σ ≡i τ for all i ≤n.
We need the following notations:
– For type σ and i ≥1, set CA
σ,i be the set {X | X is an E2-equivalence class of A and
tp(X) ≡i σ}.
– Set qA
σ,i = |CA
σ,i|.
– For embedded equivalence structure A and B, set qσ,i = min{qA
σ,i, qB
σ,i}
– Set A(σ, i) be the embedded equivalence structure of height 2 obtained from A by
removing qσ,i equivalence classes whose types are i-equivalent to σ.
Observe in round k of the game Gn(A, B), if Spoiler selects an element from an E2-
equivalence class X in A, and Duplicator responds by selecting another element from
an E2-equivalence class Y in B such that tp(Y) ≡n−k tp(X), there is no point for Spoiler
to keep playing inside X because this will guarantee a win for Duplicator. Intuitively,
A(σ, n −k) contains all the E2-equivalence classes for Spoiler to choose elements from
after qσ,n−k many E2-equivalence classes whose types are (n −k)-equivalent to σ have
been chosen.
Deﬁnition 7. Consider the game Gn(A, B) played on embedded equivalence structures
of height 2. We say that a disparity occurs if there exists a type σ and n > k ≥0 such
that the following holds.

On Complexity of Ehrenfeucht-Fra¨ıss´e Games
303
1. k = qσ,n−k.
2. In one of A(σ, n −k) and B(σ, n −k), there is an E2-equivalence class whose type
is (n −k)-equivalent to σ, and no such E2-equivalence class exists in the other
structure.
Lemma 9. Suppose A and B are two embedded equivalence structures of height 2.
Duplicator wins the game Gn(A, B) if and only if no disparity occurs.
Proof. Suppose disparity occurs in Gn(A, B) witnessed by σ and k, in A(σ, n −k)
there is an E2-equivalence class whose type is (n −k)-equivalent to σ, and no such E2-
equivalence class exists in B(σ, n −k). Using these, it is not hard to prove that Spoiler
wins the game.
Suppose that no disparity occurs in the game Gn(A, B), we describe a strategy for
Duplicator. Let us assume that the players have produced a k-round play (a1, b1),
(a2, b2), . . ., (ak, bk). Let σi and τi be the types of ai and bi, respectively with 1 ≤i ≤k.
Our inductive assumptions on this k-round play are the following:
1. The map ai →bi is partial isomorphism.
2. For all 1 ≤i ≤k, σi ≡n−i τi.
3. Let A′ and B′ be the equivalence structures obtained by removing the E2-
equivalence classes [a1]E2, . . ., [ak]E2 from A and the equivalence classes [b1]E2, . . .,
[bk]E2 from B, respectively. We assume in game Gn−k(A′, B′) no disparity occurs.
Assume that Spoiler selects an element ak+1 ∈A. The case when Spoiler selects
an element from B is treated as below. Duplicator responds to this move by choosing
bk+1 as follows. If ak+1 = ai then bk+1 = bi. Otherwise, if E1(ai, ak+1) is true in A,
then Duplicator chooses a new bk+1 such that E1(bi, bk+1). If E2(ai, ak+1) is true in A
and there is no j such that E1(a j, ak+1), then Duplicator chooses a new bk+1 such that
E2(bi, bk+1) and there is no j such that E1(b j, bk+1). By (2) of the inductive assumption
Duplicator can always select such an element bk+1 by following its winning strategies.
Assume ak+1 is not equivalent to any of the elements a1, ..., ak. Let X be the E2-
equivalenceclass in A that contains ak+1. Duplicatorselects bk+1 froman E2-equivalence
class Y in B such that tp(X) ≡n−k tp(Y). Duplicator is able to select such an element as
otherwise disparity would occur as witnessed by the type of X and 0.
The inductive assumption (1) and (2) can be easily checked to hold on the play
(a1, b1), . . ., (ak, bk), (ak+1, bk+1). To show that the assumption (3) is preserved, con-
sider the structures A′′ and B′′ obtained by removing [a1]E2, . . ., [ak]E2, [ak+1]E2 and
[b1]E2, . . . , [bk]E2, [bk+1]E2 from A and B, respectively. Suppose disparity occurs in
Gn−k−1(A′′, B′′) as witnessed by some type τ and t < n −k −1. There are two cases. If
tp([ak+1])
≡n−k−t−1
τ, then tp([bk+1])
≡n−k−t−1
τ, and disparity must occur in
Gn−k(A′, B′) as witnessed by τ and t+1. If tp([ak+1]) n−k−t−1 τ, then tp([bk+1]) n−k−t−1
τ, and disparity must occur in Gn−k(A′, B′) as witnessed by τ and t, contradicting our
assumption. Hence the strategy is a winning strategy.
⊓⊔
Theorem 8. Fix n ∈ω. There exists an algorithm that runs in constant time and decides
whether Duplicator wins the game Gn(A, B) on embedded equivalence structures of
height 2. The constant that bounds the running time is (n + 1)n.

304
B. Khoussainov and J. Liu
Proof. We represent structure A = (A; E1, E2) by a tree and a list. The tree has height
3. The leaves of the tree are all elements in A. Two leaves x, y have the same parent if
E1(x, y), and x, y have the same ancestor at level 1 if E2(x, y). Intuitively, we can view
the root of tree as A, the internal nodes at level 1 represent all E2-equivalence classes
on A, and the children of each E2-equivalence class X at level 2 are all E1-equivalence
classes contained in X. We further require that representations of E2 and E1-equivalence
classes are put in left-to-right order according to their cardinalities.
The list is qA
σ1,1, . . . , qA
σt,1, . . ., qA
σ1,n, . . ., qA
σt,n where each σi is a type of E2-equivalence
class, and qA
σi, j is as deﬁned above. Each qA
σi, j has a value between 0 and n and if it is
greater than n, we set it to n. The algorithm checks whether disparity occurs in Gn(A, B)
by examining the list. There can be at most (n + 1)n pairwise non-n-equivalent types.
Therefore, checking disparity requires a time bounded by (n + 1)n+1.
⊓⊔
For the case when A and B are two embedded equivalence structures of height h, where
h > 2, we give a similar deﬁnition of the type of an Eh-equivalence class. We can then
describe the winning conditions for Spoiler and Duplicator in a similar way.
Let A be an embedded equivalence structure of height h where h > 2. For an Eh-
equivalence class X, we recursively deﬁne tp(X), the type of X. Set tp(X) be
(qσ1, . . ., qσt) that satisﬁes the following property.
1. Each σi is the type of an Eh−1-equivalence class.
2. σt is the maximum type in lexicographic order among all types of Eh−1-equivalence
classes contained in X.
3. The list σ1, ..., σt contains all possible types of Eh−1-equivalence classes less or
equal to σt ordered lexicographically.
4. For all 1 ≤i ≤t, qσi is the number of all Eh−1-equivalence classes contained in X
whose type are σi.
We note that these types allow us to solve the isomorphism problem for embedded
equivalence structures of height h in linear time on the size of the structures.
Let κ = (qσ1, ..., qσs) and λ = (q′
σ1, ..., q′
σt) be types of two Eh-equivalence classes
X and Y, respectively. We say κ = λ if s = t and qσi = q′
σi for all 1 ≤i ≤s. We say
κ ≡n λ if the structures (X; E1 ↾X, . . . , Eh−1 ↾X) and (Y; E1 ↾Y, . . ., Eh−1 ↾Y) are
n-equivalent.
Similarly to the case of embedded equivalence structures of height 2, we re-introduce
the notions CA
σ,i, qA
σ,i, qσ,i, A(σ, i) and disparity in the game Gn(A, B).
Lemma 10. Suppose A and B are two embedded equivalence structures of height h
where h ≥2. Duplicator wins the game Gn(A, B) if and only if no disparity occurs.
⊓⊔
The number of pairwise non-n-equivalent types of Eh-equivalence classes is at most
(n + 1)...(n+1)n
where the tower of (n + 1) has height h. Thus, by the lemma above, we
have:
Theorem 9. Fix n ∈ω. There is an algorithm that runs in constant time and decides if
Duplicator wins the game Gn(A, B) on embedded equivalence structures A and B of
height h. The constant that bounds the running time is (n + 1)...((n+1) where the tower has
height h.
⊓⊔

On Complexity of Ehrenfeucht-Fra¨ıss´e Games
305
6
Trees
In this section we are interested in trees; these are ﬁnite structures of the type T =
(T, ≤), where the relation ≤is a partial order on T such that T has the greatest element
(the root), and the set {y | x ≤y} for any given x ∈T is a linearly ordered set under
≤. We call an element a leaf of the tree T if it is a minimal element; otherwise we call
it an internal node. A path in T is a maximal linearly order subset of T. The length
of a given path is the number of elements in the path. The height of T is the length of
the largest path in T . We say that the level of a node x ∈T is j if the distance from
x to the root is j. We ﬁx number h ≥2, and restrict ourselves to the class Kh of all
trees of height at most h. Deciding Ehrenfeucht-Fra¨ıss´e games on trees from Kh can
be done directly by using the techniques from the previous section. Instead, we reduce
the problem of deciding Ehrenfeucht-Fra¨ıss´e games on trees in Kh to one for embedded
equivalence structures of height h + 1.
We transform trees from the class Kh into the class of embedded equivalence struc-
tures of height h in the following manner. Let T be a tree in Kh. We now deﬁne an em-
bedded equivalence structure A(T ) as follows. The domain D of A(T) is now T ∪{ax | x
is a leaf of T }. We deﬁne the equivalence relation Ei , 1 ≤i ≤h, on the domain as fol-
lows. The relation E1 is the minimal equivalence relation that contains {(x, ax) | x is a
leaf of T }. Let x1, . . ., xs be all elements of T at level h−i+1, where 1 ≤i < h. Let T1 ,
. . ., Ts be the subtrees of T whose roots are x1, . . ., xs , respectively. Set Ei be the mini-
mal equivalence relation that contains Ei−1 ∪T 2
1 ∪. . . ∪T 2
s . It is clear that Ei ⊆Ei+1 for
all 1 ≤i ≤h. Thus we have the embedded equivalence structure A(T) = (D; E1, ..., Eh).
Lemma 11. For trees T1 and T2 , T1  T2 if and only if A(T1)  A(T2). In particular,
Duplicator wins Gn(T1, T2) if and only if Duplicator wins Gn(A(T1), A(T2)).
Proof. Suppose T is a tree in the class Kh. Take an element x ∈T. By construction of
A(T ), the following statements are true.
– x is a leaf in T if and only if |{y | E1(x, y)}| = 2 in A(T ).
– x is the root of T if and only if |{y | Eh(x, y)}| = 1 in A(T ).
We deﬁne the level of x in A(T ) as follows. If x is the root of T , the level of x is
0. Otherwise, if x is an internal node, the level of x in A(T ) is the largest l such that
|{y | Eh−l+1(x, y)}| > 1. If x is a leaf, we deﬁne the level of x in A(T ) to be the largest
l + 1 such that there is an internal node y such that Eh−l+1(x, y).
By deﬁnition, for all x ∈T, the level of x in T is the level of x in A(T ). For x, y ∈T,
x ≤y in T if and only in A(T ) x has level s and y has level t such that s ≥t and
Eh−t+1(x, y). Thus, for two trees from Kh, T1 and T2, and a mapping f : T1 →T2, f is
an isomorphism between T1 and T2 if and only if f is an isomorphism between A(T1)
and A(T2).
To prove the second part of the lemma, one direction is clear. For the other direc-
tion, assume that there is a winning strategy for Duplicator on the game Gn(T1, T2).
We describe a strategy for Duplicator on the game Gn(A(T1), A(T2)) where A(T1) =
(D1; E1, ..., Eh) and A(T2) = (D2; E1, ..., Eh). Let us assume that the players have pro-
duced a k-round play (x1, y1), (x2, y2), . . ., (xk, yk). Assume on this k-round play the map
xi →yi is a partial isomorphism between A(T1) and A(T2).

306
B. Khoussainov and J. Liu
Assume that Spoiler selects an element xk+1 ∈D1. Duplicator responds to this move
by choosing xk+1 as follows. If xk+1 = xi then yk+1 = yi. Otherwise, if xk+1 ∈T1, then
Duplicator selects an element yk+1 ∈T2 according to its winning strategy on Gn(T1, T2).
If xk+1 = ax for some leaf x ∈T1. Then Duplicator responds by selecting yk+1 =
ay where y is the leaf in T2 that corresponds to x in Duplicator’s winning strategy in
Gn(T1, T2). It is clear that xi →yi where 1 ≤i ≤k + 1 is also a partial isomorphism
between A(T1) and A(T2). Therefore the strategy described is a winning strategy for
Duplicator on game Gn(A(T1), A(T2)).
⊓⊔
Using the lemma above, one can now prove this:
Theorem 10. Fix n ∈ω. There is an algorithm that runs in constant time and decides
if Duplicator wins the game Gn(T1, T2), where T1, T2 ∈Kh. The constant that bounds
the running time is (n + 1)...(n+1)(n+1) where the tower has height h.
⊓⊔
7
Boolean Algebras with Distinguished Ideals
A Boolean algebra (BA) with distinguished ideals is a structure A
=
(A; ≤, 0, 1, I1, . . ., Is), where (A; ≤, 0, 1) forms a BA and each I j is an ideal of the al-
gebra (A; ≤, 0, 1). The set of atoms of A, denoted At(A), is the set {a | ∀y(0 ≤y ≤
a →y = 0 ∨y = a)}. Since we restrict ourselves to ﬁnite structures, the BA (A; ≤, 0, 1)
can be identiﬁed with the structure (2XA; ⊆, ∅, XA), where XA = At(A) and 2XA is the
collection of all subsets of XA. Moreover, for each ideal I j there exists a set A j ⊂At(A)
such that I j = 2A j. Hence the original structure A can be identiﬁed with the structure:
(2XA; ⊆, ∅, XA, 2A1, . . . , 2As). For each element x ∈At(A), deﬁne the characteristic of
x, ch(x), as a binary sequence (t1, t2, ..., ts) such that for each 1 ≤i ≤s, ti ∈{0, 1},
ti = 1 if x ∈Ai and ti = 0 otherwise. For each characteristic ϵ ∈{0, 1}s consider
the set Aϵ = {x ∈At(A) | ch(x) = ϵ)}. This deﬁnes the ideal Iϵ in the Boolean alge-
bra (2XA; ⊆, ∅, XA). Moreover, we can also identify this ideal with the Boolean algebra
(2Aϵ; ⊆, ∅, Aϵ). There are 2s pairwise distinct characteristics. Let ϵ1, . . ., ϵ2s be the list of
all characters. We denote by A′ the following structure: (2X; ⊆, ∅, X, 2Aϵ1, . . ., 2Aϵ2s ).
Lemma 12. Let A = (2XA; ⊆, ∅, XA, 2A1, . . ., 2As) be a Boolean algebra with distin-
guished ideals
1. For any two distinct characteristics ϵ and δ we have Iϵ ∩Iδ = {∅}.
2. For any element a ∈2X there are elements aϵ ∈Iϵ such that a = ∪ϵaϵ.
3. The Boolean algebra (2XA; ⊆, ∅, XA) is isomorphic to the Cartesian product of the
Boolean algebras Iϵ.
4. A and B are isomorphic if and only if A′ and B′ are isomorphic.
⊓⊔
The next lemma connects the structure A′ and A in terms of characterizing the winner
of the game Gn(A, B).
Lemma 13. Duplicator wins the game Gn+1(A, B) if and only if each of the following
two conditions are true:
1. For each characteristic ϵ, |Aϵ| ≥2n if and only if |Bϵ| ≥2n.
2. For each characteristic ϵ, if |Aϵ| < 2n then |Aϵ| = |Bϵ|.

On Complexity of Ehrenfeucht-Fra¨ıss´e Games
307
Proof. Assume that for some ϵ, we have |Aϵ|  |Bϵ| and |Bϵ| < 2n. Let us assume that
|Aϵ| ≥2n. The case when |Aϵ| < 2n is treated in a similar manner. We describe a winning
strategy for Spoiler. Spoiler starts by taking elements a1, a2, . . . in Aϵ. For each i ≤n
the element ai is such that |At(ai)| ≥2n−i, where At(a) denotes the set of atoms below
a. The elements a1, a2, . . . are such that for each i, either ai ⊂ai−1 or ai ∩ai−1 = ∅.
Consider the k round play (a1, b1), . . ., (ak, bk) where k < n. Let e < k be the last round
for which ak ⊂ae. If no such e exists, let ae = 2Aϵ and be = 2Bϵ. We have the following
inductive assumptions.
– |At(ak)| ≥2n−k and |At(ae \ (ae+1 ∪. . . ∪ak))| ≥2n−k.
– Either |At(bk)| < 2n−k or |At(be \ (be+1 ∪. . . ∪bk))| < 2n−k.
There are two cases.
Case 1. Assume that |At(bk)| < 2n−k and |At(ak)| ≥2n−k. In this case Spoiler selects
ak+1 such that ak+1 ⊂ak, ak+1  ∅, |At(ak+1)| ≥2n−k−1 and |At(ak \ ak+1)| ≥2n−k−1. Note
that Duplicator must choose bk+1 strictly below bk. Then either |At(bk+1)| < 2n−k−1 or
|At(bk \ bk+1)| < 2n−k−1
Case 2. Assume that |At(bk)| ≥2n−k and |At(ak)| ≥2n−k. In this case, Spoiler selects
ak+1 such that ak+1 ⊂ae, ak+1  ∅, ak+1 ∩(ae+1 ∪. . . ∪ak) = ∅, |At(ak+1)| ≥2n−k−1, and
|At(ae \ (ae+1 ∪. . . ∪ak+1))| ≥2n−k−1. Note that by deﬁnition of e, |At(be)| < 2n−k and
for each e + 1 ≤i ≤k −1, |At(bi)| ≥2n−i as otherwise bk would be below bi. Hence
|At(bk \ (be+1 ∪. . . ∪bk))| < 2n−k. Duplicator must choose bk+1 strictly below be and
disjoint with be+1, . . ., bk. Therefore either |At(bk+1)| < 2n−k−1 or |At(be)\ At(be+1 ∪. . .∪
bk+1)| < 2n−k−1.
After n rounds, by the inductive assumption, it is either |At(bn)| = 0 or |At(be\(be+1∪
. . . ∪bn))| = 0. If the former, then Spoiler wins by selecting an+1 ⊂At(an);otherwise,
Spoiler wins by selecting an+1 ⊂ae \ (ae+1 ∪. . . ∪an).
Now we prove that the conditions stated in the lemma suﬃce Duplicator to win the
(n+1)-round game Gn+1(A, B). Let us assume that the players have produced a k-round
play (a1, b1), (a2, b2), ..., (ak, bk). Our inductive assumptions on this k-round play are the
following:
1. The map ai →bi is a partial isomorphism.
2. For each ai, 1 ≤i ≤k, let ai = ∪ϵaϵ be as stipulated in Lemma 12(2). For each
aϵ, let e be the last round such that aϵ ⊆ae, if there is no such round, then assume
ae = At(Iϵ). Let d be the last round such that ad ⊆aϵ, if there is no such round, then
assume ad = ∅. Let bi = ∪ϵbϵ. The conditions for bϵ are the following:
– |At(aϵ \ ad)| ≥2n−i if and only if |At(bϵ \ ad)| ≥2n−i; |At(ae \ aϵ)| ≥2n−i if and
only if |At(be \ bϵ)| ≥2n−i.
– If |At(aϵ \ ad)| < 2n−i then |At(bϵ \ ad)| = |At(aϵ \ ad)|; If |At(ae \ aϵ)| < 2n−i then
|At(be \ bϵ)| = |At(ae \ aϵ)|.
Assume that Spoiler selects an element ak+1 ∈A. Duplicator responds to this move
by choosing bk+1 as follows. If ak+1 = ai then bk+1 = bi. Otherwise, suppose ak+1 = ∪aϵ
as stipulated in Lemma 12(2). For each aϵ, let d, e be as described in the inductive
assumptions. We select each bϵ by the following rules.

308
B. Khoussainov and J. Liu
– If |At(aϵ \ad)| ≥2n−k−1 then select bϵ such that |At(bϵ \ad)| ≥2n−k−1; If |At(ae\aϵ)| ≥
2n−k−1 then |At(be \ bϵ)| ≥2n−k−1.
– If |At(aϵ \ ad)| < 2n−k−1 then select bϵ such that |At(bϵ \ ad)| = |At(aϵ \ ad)|; If
|At(ae \ aϵ)| < 2n−k−1 then |At(be \ bϵ)| = |At(ae \ aϵ)|.
Finally, Duplicator selects bk+1 ∈B such that bk+1 = ∪ϵbϵ.
Note the inductive assumptions guarantee that Duplicator is able to make such a
move. It is clear that the inductive assumptions also hold on the (k + 1)-round play
(a1, b1), . . ., (ak+1, bk+1). Hence, the strategy described must be a winning strategy due
to the fact that Duplicator preserves the inductive assumption (1) at each round. The
lemma is proved.
⊓⊔
For the next result, we represent the Boolean algebras by listing their atoms in 2s lists,
where the ith list lists all atoms with characteristic ϵi:
Theorem 11. Fix n ∈ω. There exists an algorithm that runs in constant time and
decides whether Duplicator wins the game Gn+1(A, B) on BAs A and B with s distin-
guished ideals. The constant that bounds the running time is 2s · 2n.
⊓⊔
References
1. S. Arora, R. Fagin, On winning strategies in EF games. Theoretical Computer Science 174,
97-121, 1997.
2. A. Dawar, Inﬁnitary logic and inductively deﬁnability over ﬁnite structures. Information and
Computation, volume 119, 2:160-175, 1995.
3. A. Ehrenfeucht, An appliction of games to the completeness problem for formalized theories.
Fundamenta Mathematicae,49:129-141,1961.
4. R. Fra¨ıss´e, Sur quelques classﬁcations des syst`em de relations. Universit´e d Alger, Publica-
tion Scientiﬁques, S´er. A,1:35-182, 1954.
5. M. Grohe. Equivalence in ﬁnite-variable logics is complete for polynomial time. Proceeding
FOCS 96.
6. W. Hodeges, Model theory, Combridge University Press, 1993.
7. N. Immerman, D. Kozen, Deﬁnability with bounded number of bounded variables. Logic in
Computer Science, 236-244, 1987.
8. C. Karp, Finite quantiﬁer equivalence, In J.W. Addison, L. Henkin, and A. Tarski, editors,
The Theory of Models, 407-412. North Holland, 1965.
9. P. Kolaitis, J. Panttaja, On the complexity of existential pebble games. In M. Baaaz and J.A.
Makowsky (Eds): CSL 2003, LNCS2803, pp. 314-329, 2003.
10. C. Lautemann, N. Schweikardt, An EF approach to collapse results for ﬁrst-order queries
over embedded databases. In A. Ferreira and H. Reichel, editors, STACS’01:18th Annual
Symposium on Theoretical Aspects of Computer Science, volume 2010 of Lecture Notes in
Computer Science, 455-466, Dresden, Germany, Springer, 2001.
11. L. Libkin, Elements of ﬁnite model theory. Springer-Verlag, 2004.
12. J. Marcinkowski, Directed Reachability: From Ajtai-Fagin to Ehrenfeucht-Fra¨ıss´e games.
Proceedings of CSL99, Springer LNCS, 1999.
13. A. Mekler, S. Shelah, J. V¨a¨an¨anen, The EF-game of length ω1. Transactions of the American
mathematical Society, Volume 339, Number 2, 1993.

On Complexity of Ehrenfeucht-Fra¨ıss´e Games
309
14. E. Pezzoli, Computational complexity of EF games on ﬁnite structures. In Computer Science
Logic, 12th International Workshop, CSL’98, 159-170, 1999.
15. D. Scott, Logic with denumerable long formulas and ﬁnite strings of quantiﬁers. In J.W.
Addison, L. Henkin, and A. Tarski, editors, The Theory of Models, 329-341. North Holland,
1965.
16. N. Schweikardt, An EF game appraoch to collapse results in database theory. To appear in
Information and Computation, 2006.

The Law of the Iterated Logarithm for
Algorithmically Random Brownian Motion
Bjørn Kjos-Hanssen and Anil Nerode
Department of Mathematics, Cornell University,
Ithaca, NY 14853, U.S.A.
{bjoern,anil}@math.cornell.edu
Abstract. Algorithmic randomness is most often studied in the setting
of the fair-coin measure on the Cantor space, or equivalently Lebesgue
measure on the unit interval. It has also been considered for the Wiener
measure on the space of continuous functions. Answering a question of
Fouch´e, we show that Khintchine’s law of the iterated logarithm holds
at almost all points for each Martin-L¨of random path of Brownian mo-
tion. In the terminology of Fouch´e, these are the complex oscillations.
The main new idea of the proof is to take advantage of the Wiener-
Carath´eodory measure algebra isomorphism theorem.
Keywords: Brownian motion, randomness, law of the iterated loga-
rithm, Kolmogorov complexity.
1
Introduction
Algorithmic randomness for Brownian motion was introduced by Asarin and
Pokrovskii. They deﬁned what they called (according to the English translation
[1]) truly random continuous functions. Fouch´e [3] called these functions complex
oscillations.
In this article we answer a question of Fouch´e (see [5]) by showing that for each
complex oscillation, Khintchine’s law of the iterated logarithm holds at almost
every point. To that end, in Section 2 we will borrow a construction from the
proof of the Wiener-Carath´eodory measure algebra isomorphism theorem. For
the full statement of this theorem, the reader may consult for example Royden
[6], Theorem 15.3.4; we shall not need it. We believe our method based on this
isomorphism theorem can be used to yield other results than the one presented
here. Namely, algorithmic randomness for the unit interval [0, 1] has been studied
more extensively than algorithmic randomness for the space C[0, 1] of continuous
functions, and the isomorphism theorem allows a transfer of some results. For
a general introduction to computability theory and algorithmic randomness on
[0, 1], the reader may consult [2].
Deﬁnition 1. Suppose Ω is a set, F = {Ti : i ∈N} a countable Boolean algebra
of subsets of Ω, μ a probability measure on the σ-algebra generated by F. Let
t ∈[0, 1]. Suppose φ : N2 →N is a total function Turing reducible to t.
S. Artemov and A. Nerode (Eds.): LFCS 2007, LNCS 4514, pp. 310–317, 2007.
c
⃝Springer-Verlag Berlin Heidelberg 2007

The Law of the Iterated Logarithm
311
The sequence Un = 
m Tφ(n,m), n ∈N is called a t-uniform sequence of
Σt
1(F) sets.
A t-eﬀective F-null set is a set A ⊆Ω such that for some such φ,
1. A ⊂
n Un, and
2. μUn goes eﬀectively to 0 as n →∞. That is, there is a computable function
ψ such that whenever n ≥ψ(k), we have μUn ≤2−k.
We review the Wiener measure W on Ω = C[0, 1]. It is such that for ω ∈Ω,
and t0 < t1 < · · · < tn, the values of ω(t0) and ω(ti+1 −ti) are independent
random variables. Moreover, the probability that ω(s+t)−ω(s) ∈A, where A is
some set of reals, is

A(2πt)−1/2 exp(−x2/2t)dx. This says that ω(t) is normally
distributed with standard deviation
√
t (variance t) and mean 0. Informally, a
suﬃciently random member of Ω with respect to W is called a path of Brownian
motion.
Let G denotes the closure of G, and let G0 denotes the complement of G;
moreover, Oϵ(G) is the open ϵ-ball around G.
Deﬁnition 2 (Fouch´e [3]). A sequence F0 = (Fi : i < ω) of Borel subsets of
Ω is a t-eﬀective generating sequence if
(1) for F ∈F0, for ϵ > 0 and δ ∈{0, 1}, if G = Oϵ(F δ) or if G = F δ, then
W(G) = W(G);
(2) there is a t-eﬀective procedure that yields, for each sequence 0 ≤i1 < · · · <
in < ω and k < ω, a binary number βk such that |W(
1≤k≤n Fik) −βk| <
2−k; and
(3) for n, i < ω, for rational numbers ϵ > 0 and for x ∈Cn, both the relations
x ∈Oϵ(Fi) and x ∈Oϵ(F 0
i ) are t-recursive in x, ϵ, i and n.
A t-eﬀectively generated algebra is the Boolean algebra generated from an t-
eﬀective generating sequence.
A set A ⊂C[0, 1] is of t-constructive measure 0 if, for some t-eﬀectively
generated algebra F, A is a t-eﬀective F-null set.
If ω belongs to no t-eﬀective F-null set, then we say that ω is t-F-random
or F-random relative to t. (This also applies when F is not eﬀective.) If t is
computable then we may omit mention of t.
Finally, if there exists a t such that F0 is a t-eﬀective generating sequence,
then F0 is called a generating sequence. The algebra it generates is similarly
called a generated algebra.
The precise deﬁnition of complex oscillations is immaterial to the present paper,
but we include it for completeness.
Deﬁnition 3. For n ≥1, we write Cn for the class of continuous functions
on [0, 1] that vanish at 0 and are linear with slope ±√n on the intervals [(i −
1)/n, i/n], i = 1, . . . , n.
To every x ∈Cn one can associate a binary string in {1, −1}∗, a1 · · · an,
of length n by setting ai = 1 or ai = −1 according to whether x increases or

312
B. Kjos-Hanssen, A. Nerode
decreases on the interval [(i −1)/n, i/n]. We call the word a1 · · · an the code of
x and denote it by c(x).
A sequence {xn}n∈N in C[0, 1] is complex if xn ∈Cn for each n and there
is some constant d > 0 such that K(c(xn)) ≥n −d for all n, where K denotes
preﬁx-free Kolmogorov complexity.
A function x ∈C[0, 1] is a complex oscillation if there is a complex sequence
{xn}n∈N such that xn −x converges eﬀectively to 0 as n →∞, in the uniform
norm.
The only use we make of Deﬁnition 3 is to quote the following result.
Theorem 1 (Fouch´e [3]; see also [4]). Each complex oscillation is in the
complement of each set of constructive measure 0.
Let LIL(ω, t) be the statement that
lim sup
h→0
|ω(t + h) −ω(t)|

2|h| log log(1/|h|)
= 1.
Thus LIL(ω, t) says that Khintchine’s Law of the Iterated Logarithm holds for
ω at t.
Theorem 2 (following Fouch´e [5]). If t ∈[0, 1], and f is t-F-random for
each t-eﬀectively generated algebra F, then the Law of the Iterated Logarithm
holds for f at t.
The proof is a straightforward relativization to t of Fouch´e’s argument (which
covers the case where t is computable).
2
Isomorphism Theorem
Let A0 be a generating sequence. Write A0 = {An}n∈N.
– Let An be the Boolean algebra generated by {A1, . . . , An}.
– Let A = A∞= 
n An, the Boolean algebra generated by A0.
– Let I be the Boolean algebra of ﬁnite unions of half-open intervals [a, b) in
[0, 1).
A Boolean measure algebra homomorphism is a map that preserves measure,
unions, and complements.
Theorem 3 (Wiener, Carath´eodory). There is a Boolean measure algebra
homomorphism Φ : A →I.
Proof. To start, since A1 = {∅, A1, A′
1, Ω} and μA1 + μA′
1 = μΩ = 1, we let
Φ(A1) = [0, μA1), Φ(A′
1) = [μA1, 1), Φ(∅) = ∅, and Φ(Ω) = [0, 1). Then Φ is
clearly a Boolean measure algebra homomorphism from A1 into I.

The Law of the Iterated Logarithm
313
Suppose now that Φ has been deﬁned on An−1 so that it is a Boolean measure
algebra homomorphism from An−1 onto the algebra generated by k ∈N many
half open intervals [x0, x1), [x1, x2), . . . , [xk−1, xk), where x0 = 0 and xk = 1.
We wish to extend the mapping Φ to An. Let Bi be the set in An−1 which is
mapped onto the interval [xj, xj+1), for j < k. Then An−1 consists of all ﬁnite
unions of the sets Bj, j < k, and An consists of all ﬁnite unions from the 2k sets
An ∩Bj, A0
n ∩Bj, j < k. Let
Φ(An ∩Bj) = [xj, xj + μ(An ∩Bj))
Φ(A0
n ∩Bj) = [xj + μ(An ∩Bj), xj+1)
This might deﬁne Φ of some sets to be of the form [xj, xj) = ∅.
Clearly Φ as so deﬁned is measure-preserving, Φ(An ∩Bj) ∪Φ(A′
n ∩Bj) =
[xj, xj+1) = Φ(Bj), and μ(An ∩Bj) + μ(A′
n ∩Bj) = μ(Bj) = xj+1 −xj. From
this it follows that we can extend Φ to all of An so that it is a Boolean measure
algebra homomorphism. Since A∞= 
n An, we have thus deﬁned Φ on all of A∞.
Remark 1. The function Φ is eﬀective in the following sense: if F = {Tk : k ∈N}
is a t-eﬀectively generated algebra, then the measure of Φ(Tk) can be computed
t-eﬀectively, uniformly in k.
Lemma 1. Suppose In = (an, bn), n ∈N, is a sequence of open intervals
with (an+1, bn+1) ⊆(an, bn). Suppose 
n(an, bn) = ∅. Then either {an}n∈N
or {bn}n∈N is an eventually constant sequence.
The proof is routine. The set of Martin-L¨of real numbers in [0, 1] is denoted
RAND, and relativized to t, RANDt.
An eﬀectively generated algebra F = {Tk : k ∈N} is non-atomic if for any
b : N →{0, 1}, we have W(
k T b(k)
k
) = 0. Here T 1
k = Tk and as before T 0
k is the
complement of Tk.
Lemma 2. Let t ∈[0, 1] and let F = {Tk : k ∈N} be a non-atomic, t-eﬀectively
generated algebra. Let a function ϕ from C[0, 1] to 2ω be deﬁned by: ϕ(ω) = the
unique member of ∩{Φ(Tk) : ω ∈Tk}, if it exists.
(1) The domain of ϕ includes all t-F-randoms.
(2) If ϕ(ω) is deﬁned then for each k,
ω ∈Tk ↔ϕ(ω) ∈Φ(Tk).
Proof. (1): Suppose ω is not in the domain of ϕ. That is, S = ∩{Φ(Tk) : ω ∈Tk}
does not have a unique element. It is clear that S is an interval. Since F is
non-atomic, this interval must have measure zero. Thus, since S does not have
exactly one element, S must be empty.
By Remark 1 and Lemma 1, there is a t-computable point a or b such that
an →a or bn →b, where (an, bn) = ∩k≤nΦ(Tk). Using this point a or b one
can t-eﬀectively determine whether ω ∈Tk, given any k ∈N. Thus ω is not
t-F-random.
(2)←: Since {Tk}k∈N is a Boolean algebra and so closed under complements.
(2)→: By deﬁnition of ϕ.

314
B. Kjos-Hanssen, A. Nerode
2.1
Eﬀectiveness Lemmas
A presentation of a real number a is a sequence of open intervals In with rational
endpoints, containing a, such that In has diameter ≤2−n.
Lemma 3. There is a Turing machine which, given a presentation of a = a0⊕a1
as oracle, terminates iﬀa0 < a1.
Proof (Proof sketch.). The presentation provides some information about a0 and
a1. The machine terminates once enough information has been found to conclude
that a0 < a1.
On the other hand, it is well known that if a = b then no algorithm will be able
to verify this in general. For intervals (a, b), (c, d), we say (a, b) is bi-properly
contained in (c, d) if c < a ≤b < d.
Lemma 4. (1) The set of pairs σ, k such that Φ(Tk) is bi-properly contained in
i([σ]), is computably enumerable.
(2) The set of pairs σ, k such that i([σ]) is bi-properly contained in Φ(Tk) is
computably enumerable.
Proof. The endpoints of Φ(Tk) and i([σ]) have computable presentations. Thus
the result follows from Lemma 3.
Lemma 5. Let t ∈[0, 1] and let F = {Tk : k ∈N} be a t-eﬀectively generated
algebra.
(1) If F is non-atomic, then for each t-ML-test {Un}n∈N there is a t-computable
function f : N2 →N such that
Un ∩RAND =

m
Φ(Tf(n,m)) ∩RAND.
(2) If for a t-computable function f : N2 →N, we have Un = 
m Φ(Tf(n,m))
then Un has a subset U ′
n such that Un ∩RAND = U ′
n ∩RAND and {U ′
n}n∈N
is uniformly Σ0
1(t).
Proof. (1): We can enumerate the cones [σ] contained in Un. Once we see some
[σ] get enumerated and then see (using Lemma 4(1)) that some Φ(Tk) is bi-
properly contained in [σ], we can enumerate Φ(Tk). Since F is non-atomic,
we will gradually enumerate all of [σ] except for possibly one or more of its
computable endpoints.
(2): By Lemma 4(2). Given an enumeration of the sets Φ(Tf(n,m)), m ∈N,
we can enumerate sets [σn,m,p] that are bi-properly contained in Φ(Tf(n,m)) to
ensure that 
m Φ(Tf(n,m) ∩RAND = 
p,m[σn,m,p] ∩RAND. The endpoints of
Φ(Tk) are computable and hence not in RAND.

The Law of the Iterated Logarithm
315
The only result of this section that will be used in the next is the following:
Theorem 4. Let ω ∈Ω, t ∈[0, 1], and let F0 = {Tk : k ∈N} be a non-atomic
t-eﬀective generating sequence, and F its generated algebra. The following are
equivalent:
(1) ω is t-F-random;
(2) ϕ(ω) ∈RANDt.
Proof. (2) implies (1): Suppose ω is not t-F-random, so ω ∈
n Vn, a t-F-null
set. Then Vn = 
m Tf(n,m) for some t-computable f.
Let Un = 
m Φ(Tf(n,m)). Note
(a) Un is uniformly Σ0
1(t) by Lemma 5(2).
(b) Since Φ is measure preserving on F and is a Boolean algebra homomorphism
by Theorem 3,
μ(∪n
i=1Φ(Tai)) = μ(Φ(∪n
i=1Tai)) = μ(∪n
i=1Tai)
Since the measure of a countable union is the limit of the measures of ﬁnite
unions, μUn = μVn ≤2−n.
By (a) and (b), {Un}n∈ω is a t-ML-test.
If ω is not in the domain of ϕ then ω is not F-random, by Lemma 2(1); so
we may assume ϕ(ω) exists. Hence, since ω ∈
n Vn, by deﬁnition of ϕ, we have
ϕ(ω) ∈
n Un. Thus ϕ(ω) ̸∈RANDt.
(1) implies (2): Suppose ϕ(ω) is not 1-t-random, so ϕ(ω) ∈
n Un, for some
t-Martin-L¨of test {Un}n∈N. Let Vn := ∪mTf(n,m) with f as in Lemma 5. So by
its deﬁnition, Vn is uniformly Σt
1(F0). As in the proof that (2) implies (1), Vn
and Un have the same measure. Since ϕ(ω) ∈
n Un, by Lemma 2(2) we have
ω ∈
n Vn.
Remark 2. Our identiﬁcation of binary sequences with numbers in [0, 1] deserves
some comment. A number t ∈[0, 1] is a dyadic rational if it is of the form
p
2n , for p, n ∈N; otherwise, t is called a dyadic irrational. The set of dyadic
irrationals can be identiﬁed with a full-measure subset of 2N via the map ι
such that ι(
i≥1 bi2−i) = {bi}i≥1. This also gives an identiﬁcation of cones
[σ] = {A ∈2N : ∀n < |σ| A(n) = σ(n)} for σ ∈{0, 1}∗with intervals in the
dyardic irrationals. Formally, we can let i(2ω) = (0, 1) and if i([σ]) = (a, b) then
i([σ0]) = (a, a+(b−a)/2) and i([σ1] = (a+(b−a)/2, b), but we leave i implicit.
We only need ϕ restricted to the F-random functions ω ∈Ω. By Theorem 4, ϕ
maps such functions ω into RAND and in particular into the dyadic irrationals.
3
Khintchine’s Law for Complex Oscillations
It is common in probability theory to write, for ω ∈Ω and x ∈[0, 1], Bx(ω) =
ω(x). This allows us to refer to the set {ω ∈Ω : ω(x) < y}, for example (where x,
y are ﬁxed rational numbers) as the event that Bx < y, and as a set this is written
[Bx < y]. In words, the value of the Brownian motion at time x is less than y.

316
B. Kjos-Hanssen, A. Nerode
Let, for each t ∈[0, 1], Ft be an t-eﬀectively generated algebra that con-
tains the one used in Theorem 2, and that moreover is non-atomic. The latter is
achieved by including all events of the form [Bx < y] for rational x ∈[0, 1] and ar-
bitrary rational y. Note that if F and F ′ are eﬀectively generated algebras, and
F ⊆F ′, then each F ′-random function ω ∈Ω is also F-random, since adding
elements to an eﬀective generating sequence only adds new eﬀective null sets.
Lemma 6. For each t ∈[0, 1] and each ω with ϕ(ω) ∈RANDt, we have
LIL(ω, t). In particular, for each t ∈RAND and each ω with ϕ(ω) ∈RANDt,
we have LIL(ω, t).
Proof. Suppose t ∈[0, 1] and ϕ(ω) ∈RANDt. By Theorem 4, ω belongs to no
t-eﬀective Ft-null set. Hence by Theorem 2, LIL(ω, t).
The point now is that in the image of ϕ, we already know more of what is going
on. Let A ⊕B = {2n : n ∈A} ∪{2n + 1 : n ∈B}, for reals A, B (equivalently,
A, B ⊆N).
Theorem 5 (van Lambalgen’s Theorem). Let A, B be reals. The following
are equivalent.
– A ∈RAND and B ∈RANDA;
– A ⊕B ∈RAND;
– B ∈RAND and A ∈RANDB.
We can now approach our desired result:
Lemma 7. If ϕ(ω) ∈RAND and t ∈RANDϕ(ω) then LIL(ω, t).
Proof. Suppose ϕ(ω) ∈RAND and t ∈RANDϕ(ω). By Theorem 5 with A =
ϕ(ω) and B = t, we have that t ∈RAND and ϕ(ω) ∈RANDt. Hence by Lemma
6, we have LIL(ω, t).
Theorem 6. If ω is a complex oscillation, then for almost all t, LIL(ω, t).
Proof. Suppose ω is a complex oscillation. By Theorem 4, ϕ(ω) ∈RAND. By
Lemma 7, LIL(ω, t) holds for each t ∈RANDϕ(ω). Since RANDA has measure
1 for each A ∈2ω, we are done.
Finally, we remark that our main result can be extended from Martin-L¨of ran-
domness to Schnorr randomness, using a weak version of van Lambalgen’s the-
orem that holds for Schnorr randomness.
References
1. E.A. Asarin and A.V. Pokrovskii, Use of the Kolmogorov complexity in analyzing
control system dynamics, Automation and Remote Control 47, 21-28 (1986).
2. R.G. Downey and D.R. Hirschfeldt, Algorithmic Randomness and Complexity, to
appear. Available on the home page of the ﬁrst author: http://www.mcs.vuw.ac.nz/
people/Rod-Downey

The Law of the Iterated Logarithm
317
3. W. Fouch´e, Arithmetic Representations of Brownian Motion I, J. Symbolic Logic 65
No. 1 (2000), 421-442.
4. W. Fouch´e, The descriptive complexity of Brownian motion, Adv.Math. 155 (2000),
no. 2, 317–343.
5. W. Fouch´e, Dynamics of a Generic Brownian Motion: Recursive Aspects. To appear
in A. Beckmann, E. Beggs, B. L¨owe (eds.), From G¨odel to Einstein: Computability
between Logic and Physics at CiE 2006. Special issue of the journal Theoretical
Computer Science A, 2007.
6. H.L. Royden, Real Analysis, third edition, Prentice-Hall, 1988.

Hypersequent Calculus for Intuitionistic
Logic with Classical Atoms
Hidenori Kurokawa
Department of Philosophy
The City University of New York, Graduate Center
365 Fifth Avenue New York, NY 10016
hkurokawa@gc.cuny.edu
Abstract. We introduce a hypersequent calculus for intuitionistic logic
with classical atoms, i.e. intuitionistic logic augmented with a special
class of propositional variables for which we postulate the decidability
property. This system combines classical logical reasoning with construc-
tive and computationally oriented intuitionistic logic in one system. Our
main result is the cut-elimination theorem with the subformula property
for this system. We show this by a semantic method, namely via proving
the completeness theorem of the hypersequent calculus without the cut
rule. The cut-elimination theorem gives a semantic completeness of the
system, decidability, and some form of the disjunction property.
1
Introduction
Combining logics is a widely discussed topic in logical studies these days, and
combining intuitionistic logic and classical logic is no exception. Several ways
of combining the two logics have been proposed. One way is to introduce two
(intuitionistic and classical) implications or negations in one system, [10], [6] and
[13], and another is to introduce a two-sorted language of propositional logic
with two diﬀerent kinds (intuitionistic and classical) of propositional variables,
and the law of excluded middle is postulated only for classical variables, [16],
[18], [17] and [12].1 Combining intuitionistic and classical logic in the second
way above can be motivated by the following consideration: even in constructive
mathematics some formulas are decidable, so we may need some logic that can
have both decidable propositions and not necessarily decidable ones anyway.
Also, our two-sorted approach has some connection to the proof theory of basic
intuitionistic logic of proofs (iBLP) [1]. iBLP has formulas of the form “x : F”
that read “x is a proof of F,” which are decidable.
In this paper, we present a Gentzen-style sequent calculus in which we can
combine intuitionistic propositional logic (IPC) and classical propositional logic
1 Strictly speaking, [16] does not discuss a two-sorted language, but it is obvious that
we can expand the language of their logic to a two-sorted one to obtain a combined
system for IPC and CPC. Also, there are yet other ways of combining logics. See
[9],[14] and [8].
S. Artemov and A. Nerode (Eds.): LFCS 2007, LNCS 4514, pp. 318–331, 2007.
c
⃝Springer-Verlag Berlin Heidelberg 2007

Hypersequent Calculus for Intuitionistic Logic with Classical Atoms
319
(CPC) in the second way. It is not entirely trivial to formulate such a system
especially if you want to formulate a system where cut-elimination and the full
subformula property holds. We extend the framework of sequent calculus to a
hypersequent calculus, which has already been used in many contexts in non-
classical logics. We show cut-elimination by a semantical method and some other
properties of the hypersequent system for IPCCA.
2
Hypersequent Calculus
First, we give a speciﬁcation of our language and ﬁx some notational conventions.
The language of IPCCA, LIP CCA, consists of the usual intuitionistic propositional
connectives and two sets of propositional variables: intuitionistic propositional
variables, V arI := {p1, . . . , pn, ...}, and classical propositional variables V arC :=
{X1, . . . , Xn, . . . }. The latter variables will satisfy an additional constraint that
will provide their classical behavior. A formula F in LIP CCA is speciﬁed as
follows.2 F ::= pi|Xi|⊥|F1 →F2|F1 ∧F2|F1 ∨F2.
We use the following notational convention: 1) B◦is a formula containing only
classical variables. 2) A,B,C,... (without any extra symbol) can be any formula.
We adopt a multi-conclusion intuitionistic sequent calculus where only R →
lacks symmetry. We assume that our sequents are sets of formulas and our hyper-
sequents are multisets of sequents. Here is the system of mLIC (multi-conclusion
logical calculus for intuitionistic logic with classical atoms).
1) Axioms:
A ⇒A
⊥⇒
2) External structural rules:
EW
G
G|H
EC
G|Γ ⇒Δ|Γ ⇒Δ|H
G|Γ ⇒Δ|H
3) Internal structural rules:
LW
G|Γ ⇒Δ
G|A, Γ ⇒Δ
RW
G|Γ ⇒Δ
G|Γ ⇒Δ, A
4)Logical rules
L∧G|A, B, Γ ⇒Δ
G|A ∧B, Γ ⇒Δ
R∧G|Γ ⇒Δ, A
G|Γ ⇒Δ, B
G|Γ ⇒Δ, A ∧B
L∨G|A, Γ ⇒Δ
G|B, Γ ⇒Δ
G|A ∨B, Γ ⇒Δ
R∨G|Γ ⇒Δ, A, B
G|Γ ⇒Δ, A ∨B
L →G|Γ ⇒Δ, A
G|B, Γ ⇒Δ
G|A →B, Γ ⇒Δ
R →
G|A, Γ ⇒B
G|Γ ⇒A →B, Δ
2 We take ¬ϕ as an abbreviation of ϕ →⊥.

320
H. Kurokawa
5) Classical Splitting
G|Γ1, Γ ◦
2 ⇒Δ1, Δ◦
2|H
G|Γ1 ⇒Δ1|Γ ◦
2 ⇒Δ◦
2|H
6) Cut
G1|Γ1 ⇒Δ1, A|H1
G2|A, Γ2 ⇒Δ2|H2
G1|G2|Γ1, Γ2 ⇒Δ1, Δ2|H1|H2
Remark 1. Hypersequents are introduced by Avron to formulate cut-free se-
quent calculi for various non-classical logics, in particular G¨odel-Dummett logic.
2. This Splitting would give classical logic if we did not have any restriction of
the language of formulas. (See [4].) Without Classical Splitting, the hypersequent
calculus would be a hypersequent for IPC in LIP CCA ([5]).
3. (X →p) ∨(p →X) is valid w.r.t. the class of Kripke models for IPCCA
(cf.[11]). However, it seems diﬃcult to add a rule to an ordinary cut-free sequent
calculus so that the above formula can be derived in it. Due to Classical Splitting,
we have a cut-free proof of the formula in mLIC.
X ⇒X
Classical Splitting
X ⇒| ⇒X
LW , RW
X ⇒p|p ⇒X
R →
⇒X →p, p →X| ⇒X →p, p →X
R∨
⇒(X →p) ∨(p →X)| ⇒(X →p) ∨(p →X)
EC
⇒(X →p) ∨(p →X)
3
Kripke Models for Intuitionistic Logic with Classical
Atoms
Now we state the main theorem. mLIC−means mLIC without Cut.
Theorem 1. If mLIC⊢Γ1 ⇒Δ1| . . . |Γn ⇒Δn, then mLIC−⊢Γ1 ⇒Δ1| . . . |Γn ⇒
Δn.
We show this theorem by a semantic method, using ﬁnite tree Kripke models for
IPCCA. A Kripke model K for the language of IPCCA is deﬁned as an ordered
triple (K, ≤, ⊩), where K is a nonempty set and called a set of states, ≤is a
partial order of the states, and ⊩is a forcing relation. The ordered pair of the
ﬁrst two components (K, ≤) is called a Kripke frame. A forcing relation satisﬁes
the condition of “monotonicity” propositional variables: for any s, t ∈K and for
any propositional variable p, if s ≤t and s ⊩p, then t ⊩p.
Also, ⊩satisﬁes the standard inductive clauses for logical connectives →, ∧,∨
for intuitionistic logic.3 Without loss of generality, we only think about ﬁnite
tree Kripke models. In addition to these, we have the following condition.
The new condition for classical atoms (Stability) : Let s0 be the root node
of a ﬁnite Kripke tree model. For each Xi ∈V arC, one of the following holds:
sj ⊩Xi for all sj ≥s0 or sj ⊮Xi for all sj ≥s0
3 We have ⊥in the language, and ⊥is never forced at any state.

Hypersequent Calculus for Intuitionistic Logic with Classical Atoms
321
Here K, s ⊩ψ means that a formula ψ is forced at state s in a Kripke model K.
Also, K ⊩ψ means that a formula ψ is valid in K, which means that ψ is forced
in all the states in K. A formula ψ is “valid” if it is valid in all Kripke models.
We extend our forcing relation and the notion of validity to hypersequents.
Deﬁnition 1. 1. K, s ⊮Γ ⇒Δ, if ∃s′ ∈K, s′ ≥s, s.t. for any ϕ ∈Γ, K, s′ ⊩ϕ
and for any ψ ∈Δ, K, s′ ⊮ψ.
2. K, s ⊩Γ ⇒Δ, otherwise.
Deﬁnition 2. K, s ⊩Γ1 ⇒Δ1| . . . |Γn ⇒Δn iﬀK, s ⊩Γ1 ⇒Δ1 or . . . or
K, s ⊩Γn ⇒Δn. Also, a hypersequent G = Γ1 ⇒Δ1| . . . |Γn ⇒Δn is valid if
for any K and any s ∈K, K, s ⊩Γ1 ⇒Δ1| . . . |Γn ⇒Δn.
4
The Completeness Theorem for the Multi-conclusion
Hypersequent Calculus Without the Cut-Rule
Cut-elimination is obtained as a consequence of the following theorem.
Theorem 2. mLIC−⊢Γ1 ⇒Δ1| . . . |Γn ⇒Δn if Γ1 ⇒Δ1| . . . |Γn ⇒Δn is
valid in any Kripke model of mLIC.
To show cut-elimination, we also need to show the soundness theorem “mLIC⊢
Γ1 ⇒Δ1| . . . |Γn ⇒Δn only if Γ1 ⇒Δ1| . . . |Γn ⇒Δn is valid.” However,
since we already proved that Hilbert-style system of IPCCA is sound with re-
spect to the relevant class of Kripke models in [11], our proof of soundness is
done, provided that the provability of a hypersequent in mLIC implies that of
the translated formula in IPCCA.4 Now we prove the contrapositive of the com-
pleteness theorem of hypersequent calculus mLIC−.
4.1
Saturation Lemma
Deﬁnition 3. A saturated hypersequent G′ = Γ ′
1 ⇒Δ′
1| . . . |Γ ′
n ⇒Δ′
n for
mLIC−is a hypersequent satisfying the following conditions.5
1. For any component Γ ′
i ⇒Δ′
i of G′, if A ∨B ∈Γ ′
i, then A ∈Γ ′
i or B ∈Γ ′
i.
2. For any component Γ ′
i ⇒Δ′
i of G′, if A ∨B ∈Δ′
i, then A ∈Δ′
i and B ∈Δ′
i.
3. For any component Γ ′
i ⇒Δ′
i of G′, if A∧B ∈Γ ′
i, then A ∈Γ ′
i and B ∈Γ ′
i.
4 This fact, i.e. the translation is sound, has to be shown. The proof is given by
induction on the length of proof. The crucial case is Classical Splitting. We have to
show that the soundness of the translation has to be preserved under the application
of the rule. Assuming that IPCCA⊢( Γ1 ∧ Γ ◦
2 ) →( Δ1 ∨ Δ◦
2), we want to
show that IPCCA⊢( Γ1 → Δ1)∨( Γ ◦
2 → Δ◦
2). The inference here is obviously
valid with respect to the semantics of IPCCA, so by soundness and completeness of
IPCCA, the proof is essentially done and the translation is sound.
5 In general, we call each sequent Γi ⇒Δi of a hypersequent G a component of G.
Here i is an index for a component in a hypersequent. ′ means that the sequent is
saturated.

322
H. Kurokawa
4. For any component Γ ′
i ⇒Δ′
i of G′, if A∧B ∈Δ′
i, then A ∈Δ′
i or B ∈Δ′
i.
5. For any component Γ ′
i ⇒Δ′
i of G′, if A →B ∈Γ ′
i, then A ∈Δ′
i or B ∈Γ ′
i.
6. For any component Γ ′
i ⇒Δ′
i of G′, if A →B ∈Δ′
i, then there exists a
component Γ ′
iσ ⇒Δ′
iσ of G′, s.t. A ∈Γ ′
iσ and B ∈Δ′
iσ.6
Also, if the conditions 1-5 are satisﬁed for a component, we call the component
“saturated component.”7
Deﬁnition 4. A hypersequent Γ1 ⇒Δ1| . . . |Γi ⇒Δi|Γi ∪{A} ⇒B| . . . |Γn ⇒
Δnis an associated hypersequent of a hypersequentΓ1 ⇒Δ1|. . . |Γi ⇒Δi| . . . |Γn ⇒
Δn with respect to Γi ⇒Δi, s.t. A →B ∈Δi. Also, we call this Γi ∪{A} ⇒B
an associated component of Γi ⇒Δi, s.t. A →B ∈Δi.
Lemma 1 (Saturation Lemma)
For any hypersequent G=Γ1 ⇒Δ1|. . . |Γn ⇒Δn, s.t. mLIC−⊬Γ1 ⇒Δ1| . . . |Γn ⇒
Δn, there exists a saturated hypersequent8 G′ = Γ ′
1 ⇒Δ′
1| . . . |Γ ′
nσn ⇒Δ′
nσn sat-
isfying the following conditions.
(α) For each component Γi ⇒Δi and its associated components Γiσ ⇒Δiσ,9
(α1) Γiσ ⊆Γ ′
iσ; (α2) Δiσ ⊆Δ′
iσ; (α3) Γ ′
iσ ∩Δ′
iσ = ∅and ⊥/∈Γ ′
iσ.
(β) Let P and N be the following.
P := {Γ ′
iσ|(Γ ′
iσ ⇒Δ′
iσ) is a component of saturated hypersequent G′}
N := {Δ′
iσ|(Γ ′
iσ ⇒Δ′
iσ) is a component of saturated hypersequent G′}.
Then {X ∈V arC|X ∈P} ∩{X ∈V arC|X ∈N} = ∅.
Proof. The proof is done by describing the saturation procedure.
1) We start from the leftmost component Γ1 ⇒Δ1 of the original hyper-
sequent G = Γ1 ⇒Δ1| . . . |Γn ⇒Δn, and we continue to construct saturated
components and associated components for “→” formulas on the succedent of
components until we develop all the saturated components. The following rules
give us how to construct a saturated component of a saturated hypersequent.
For Γi ⇒Δi in G, go through all of the following steps.
1. If A ∨B ∈Γi, then put A into Γi or put B into Γi.
2. If A ∨B ∈Δi then put A into Δi and put B into Δi.
3. If A ∧B ∈Γi, then put A into Γi and put B into Γi.
4. If A ∧B ∈Δi, then put A into Δi or put B into Δi.
6 σ stands for a ﬁnite sequence of numbers. When we have an implication on the
succedent, we will have a new sequent and we name it by an appropriate number. So,
we have some sequence of number. The particular construction of a new component
will be given below. σ’s are convenient labels. The construction does not essentially
depends on the labels.
7 We call this “saturated component” regardless of whether it has A →B in Δ′
i or
not.
8 Here σn stands for a sequence for n-th component.
9 We identify Γi ⇒Δi with Γi0 ⇒Δi0, and once saturated, it becomes Γ ′
i0 ⇒Δ′
i0. An
index of an associated component starts with 1. Also, the notion of “associatedness”
is transitive.

Hypersequent Calculus for Intuitionistic Logic with Classical Atoms
323
5. If A →B ∈Γi, then put A into Δi or put B into Γi.
6. If Γi ∩Δi ̸= ∅or ⊥∈Γi, then backtrack.
2) We go through the procedure until we can no longer parse any formula
in the set,10 except for implicational formulas on the succedent. If we obtain
a sequent that satisﬁes all the conditions, then we can terminate.11 If we have
the case 6, then we backtrack. For Γ1 ⇒Δ1, we may terminate with “success,”
i.e. terminate by constructing a saturated component without any application
of 1-6 anymore, or terminate with “failure,” i.e. terminate with no possibility of
backtracking any more and have only the cases where Γ ′
1 ∩Δ′
1 ̸= ∅or ⊥∈Γ ′
1. If
Γ ′
1 ⇒Δ′
1 does not have A →B in Δ′
1, then we are done with Γ ′
1 ⇒Δ′
1.
3) If there is a saturated component Γ ′
1 ⇒Δ′
1 for Γ1 ⇒Δ1 satisfying all
the conditions listed above and that A1 →B1, . . . , Ak →Bk ∈Δ′
1, then we
construct k-many associated components for Γ1 ⇒Δ1. Let Γ1j ⇒Δ1j be as
Γ1j = Γ ∪{Aj} and Δ1j = {Bj} (1 ≤j ≤k). So, our new hypersequent looks
like Γ ′
1 ⇒Δ′
1|Γ11 ⇒Δ11| . . . |Γ1k ⇒Δ1k| . . . |Γn ⇒Δn.
4) By going through from 1) to 3) for Γ11 ⇒Δ11, we get Γ ′
11 ⇒Δ′
11. If
there is any A →B ∈Δ′
11, then we have to construct an associated component
Γ111 ⇒Δ111 (possibly Γ112 ⇒Δ112, . . . , Γ11l ⇒Δ11l) for Γ11 ⇒Δ11. We
also saturate Γ111 ⇒Δ111, . . . , Γ11l ⇒Δ11l.12 So, we get Γ ′
1 ⇒Δ′
1|Γ ′
11 ⇒
Δ′
11|Γ ′
111 ⇒Δ′
111| . . . |Γ ′
1k ⇒Δ′
1k|Γ ′
1k1 ⇒Δ′
1k1| . . . |Γn ⇒Δn.
5) We go through all the steps in 1)-4) until we ﬁnish saturating all the
associated components for Γn ⇒Δn. Since the number of A →B formulas on
the succedents is ﬁnite, our procedure terminates in a ﬁnite number of steps.13
6) After we systematically construct all the saturated components (including
all associated ones), we take the union of Γ ′
iσ and the union of Δ′
iσ (P and N)
and check whether the condition of disjointness of the classical variables (β) in
P and N. If (β) is violated, then we backtrack. We have the two possible cases of
termination: (1) We terminate with “success,” i.e. by constructing a saturated
component without violating (α3) or (β); (2) We terminate with “failure,” i.e.
violating (α3) or (β) with no case of backtracking.
If we have a successful case, then the other conditions of (α) are indeed
satisﬁed with respect to any component Γ ′
iσ ⇒Δ′
iσ. In all the steps except
the case A →B ∈Δ′
iτ we simply add some new formulas. So, once Γiσ ⇒
Δiσ is constructed, we only add formulas on Γiσ and Δiσ. Hence, the condi-
tion (α1) and (α2) of the lemma are satisﬁed for all the successful cases of
components.
On the other hand, the case (2) is impossible.
10 After a formula is used once, it becomes unavailable in one component.
11 The procedure for the component Γi ⇒Δi will terminate because we only go through
the subformulas of the component, and the complexity of them strictly goes down
at each step.
12 For any implication formula on any succedent, we unfold all associated components.
13 We may have a repetition of having the same formula every time we construct a new
associated sequent. But then we can stop whenever we get into the repetition of the
same step.

324
H. Kurokawa
Claim. If a component (or any pair of components) in a candidate of a saturated
hypersequent G′ violate(s) the condition (α3) or the condition (β) of the dis-
jointness of classical variables or both without any possibility of backtracking,
then we can construct a cut-free proof of the hypersequent G.
Proof. Essentially by tracing the saturation procedure backwards (from the
rightmost component to the leftmost one), we ﬁrst construct a cut-free deriva-
tion of the original hypersequent G from all the cases of saturation in which
the condition (α3) or (β) is violated. Assume that we have violations of (α3)
or (β) with implications on the succedent developed and we have no case of
backtracking.
We arrange all those possible alternatives of saturated hypersequents which
violate the condition (α3) or (β)14 so that we can construct a derivation tree of
G whose leaves are saturated hypersequents. We ﬁrst construct a tree labeled
by hypersequents (at this point, not necessarily a derivation tree yet) by the
rules: 1) The root is the original hypersequent G; 2)-1. if a saturation step is
deterministic, then put the resulting G2 above G1; 2)-2. if a saturation step is
non-deterministic, then put the two alternatives G2 and G3 above the previous
one G1; 2)-3. if a saturation step is A →B ∈Δ′
iσ,15 then put the hypersequents
as follows.
Γ ′
1 ⇒Δ′
1| . . . |Γ ′
i ⇒Δ′
i|Γ ′
iσ ⇒Δ′
iσ|Γ ′
iσ1, A ⇒B| . . . |Γn ⇒Δn
Γ ′
1 ⇒Δ′
1| . . . |Γ ′
iσ ⇒Δ′
iσ| . . . |Γn ⇒Δn.
3) Leaf nodes are saturated hypersequents with (α3) or (β) violated.
Subclaim 1: With some minor modiﬁcations, our ﬁnite tree of saturated hy-
persequents becomes a derivation of the original hypersequent G from all the
alternative saturated hypersequents with violation of either (α3) or (β).
Proof. About 1) and 3): ﬁrst, the construction traces saturation of G backwards,
so we end with G. By assumption, all the topmost saturated hypersequents sat-
isfy the following conditions: in case of (α3), all such saturated hypersequents
have a component Γ ′
iσ, A ⇒Δ′
iσ, A or Γ ′
iσ, ⊥⇒Δ′
iσ; in case of (β) (possibly
with (α3), all such saturated hypersequents have at least one pair of compo-
nents Γ ′
iσ, X ⇒Δ′
iσ and Γ ′
jτ ⇒Δ′
jτ, X (or a component Γ ′
iσ, A ⇒Δ′
iσ, A or
Γ ′
iσ, ⊥⇒Δ′
iσ).
About 2): (Outline) We show inductively (on the number of applications of
logical rules) that the constructed tree with some modiﬁcations is the desired
derivation. For 2)-1,2, by IH, we have a derivation up to G2 (and G3) from
the failed cases of saturated hypersequents. We can take this as a derivation
14 Even in a case with violation of (β), in some alternatives, there may be a violation
of (α3).
15 If the succedent has more than one implication formula, then we have to deal with
all of them by putting one new line of a hypersequent whenever we apply a case of
→in Δ′
iσ.

Hypersequent Calculus for Intuitionistic Logic with Classical Atoms
325
of the lower hypersequent G1 from G2 (and G3), where a principal formula is
obtained as a result of applying the rule. So, we have a desired derivation of
G1 from the failed saturated hypersequents. For 2)-3: (A →B ∈Δ′
iσ) In this
case, we need a slight modiﬁcation. In our saturation, we put some new sequents
adjacent to the component that has →on the succedent. To accommodate this,
we insert one intermediate line that has another copy of Γ ′
iσ ⇒Δ′
iσ to the
tree. So,
Γ ′
1 ⇒Δ′
1| . . . |Γ ′
iσ ⇒Δ′
iσ|Γ ′
iσ1, A ⇒B| . . . |Γn ⇒Δn
R →
Γ ′
1 ⇒Δ′
1| . . . |Γ ′
iσ ⇒Δ′
iσ|Γ ′
iσ ⇒Δ′
iσ| . . . |Γn ⇒Δn
EC
Γ ′
1 ⇒Δ′
1| . . . |Γ ′
iσ ⇒Δ′
iσ| . . . |Γn ⇒Δn
Here Γ ′
iσ1 = Γ ′
iσ, and by IH, we have a derivation up to the top line from the
failed saturated hypersequents. Note that the ﬁrst step is just R →and the
second is EC. So, we have a derivation of the bottom line.
⊠(subclaim 1)
Subclaim 2: Any hypersequent of the form Γ1 ⇒Δ1| . . . |A, Γi ⇒Δi, A| . . . |Γn
⇒Δn or Γ1 ⇒Δ1| . . . |⊥, Γi ⇒Δi, | . . . |Γn ⇒Δn is provable in mLIC−.
Subclaim 3: Any hypersequent of the form Γ1 ⇒Δ1| . . . |X, Γi ⇒Δi| . . . |Γj ⇒
Δj, X|Γn ⇒Δn is provable in mLIC−.
Proof. (For 2) The entire hypersequent can be taken as the result of applying
LW, RW and EW to an axiom. (For 3) We can have the following proof.
X ⇒X
Classical Splitting
X ⇒| ⇒X
several LW or RW
X, Γi ⇒Δi|Γj ⇒Δj, X
several EW
Γ1 ⇒Δ1| . . . |X, Γi ⇒Δi| . . . |Γj ⇒Δj, X| . . . |Γn ⇒Δn
The failed saturated hypersequents have the form of the hypersequents in
the above subclaims. So, by putting proofs in the subclaim 2, 3 on top of
our cut-free derivation from saturated hypersequents, we can construct a cut-
free proof of the original hypersequent G based on all the cases of violation
of the condition (α3) or (β) (possibly with those of (α3), respectively. This
completes transforming the cases of failure into a cut-free proof in mLIC−.
⊠(claim)
By the claim, the existence of a failed case (2) would be contradictory to the
assumption of unprovability of the original hypersequent. So, the existence of
a saturated hypersequent satisfying the conditions has been proven. ⊠(Lemma)
4.2
Constructing a Kripke Countermodel
Let G′ be a saturated hypersequent satisfying all the conditions in the lemma.
First, list up the classical variables X1, . . . , Xp, “safe variables,” that are in the
set P = {Γiσ|Γiσ ⇒Δiσ is a component of the saturated hypersequent G′}. We
consider the hypersequent all of whose components are of the form Γ +′
iσ ⇒Δ′
iσ
such that 1. Γ +′
iσ = Γ ′
iσ ∪{X1, . . . Xp} and 2. Δ′
iσ is as before. We call this
hypersequent a “modiﬁed saturated hypersequent” G+.

326
H. Kurokawa
Proposition 1. Suppose mLIC−⊬Γ1 ⇒Δ1| . . . |Γn ⇒Δn (= G), and let G′
be a saturated hypersequent satisfying the conditions of Saturation Lemma with
“safe variables” X1, . . . , Xp. Then, there is a modiﬁed saturated hypersequent
G+, s.t. for each saturated component Γ +′
iσ
⇒Δ′
iσ of G+, the following are
satisﬁed:
(α) Γ +′
iσ ∩Δ′
iσ = ∅and ⊥/∈Γ +′
iσ .
(β) Let P+ and N be the following.
• P + := {Γ +′
iσ |(Γ +′
iσ ⇒Δ′
iσ) is a component of G+}.
• N := {Δ′
iσ|(Γ +′
iσ ⇒Δ′
iσ) is a component of G+}.
Then {X ∈V arC|X ∈P +} ∩{X ∈V arC|X ∈N} = ∅.
Proof. Given a G′ and X1, . . . , Xp, add Xi’s to the antecedent of each Γ ′
iσ ⇒
Δ′
iσ in G′. We check that the resulting hypersequent satisﬁes the conditions of
G+ in the proposition. The hypersequent is still saturated even after Xi’s are
added since these are all variables and inactive in the saturation procedure.
The condition (α) is satisﬁed because, by deﬁnition, safe variables Xi’s are the
classical variables such that Xi /∈N. So, adding Xi to the antecedent keeps
the antecedent of each saturated component in G′ disjoint with its succedent.
Similarly, for the condition (β), there are no Xi’s such that Xi /∈N. Also, it
is obvious that this is a modiﬁed saturated hypersequent in the sense deﬁned
above.
⊠
Based on this modiﬁed saturated hypersequent G+, we construct a Kripke coun-
termodel for G.16 Except for classical variables, a model to be constructed from
a (modiﬁed) saturated hypersequent must have almost the same structure as a
Kripke model for intuitionistic logic. However, to construct a Kripke model from
one saturated hypersequent, we ﬁrst construct Kripke models for components,
and we glue those Kripke models to construct a Kripke model for G.
Suppose we are given a modiﬁed saturated sequent G+ = Γ +′
10 ⇒Δ′
10|Γ +′
11 ⇒
Δ′
11| . . . |Γ +′
i0 ⇒Δ′
i0| . . . |Γ +′
iσ ⇒Δ′
iσ| . . . |Γ +′
n0 ⇒Δ′
n0| . . . |Γ +′
nτ ⇒Δ′
nτ. We con-
struct Kripke models that falsify the original components Γi ⇒Δi (1 ≤i ≤n).
Let a Kripke model Ki be the following triple (S+
i , ≤i, ⊩i) based on G+:
1. S+
i = {Γ +′
i0 ⇒Δ′
i0, Γ +′
i1 ⇒Δ′
i1, . . . , Γ +′
iσ ⇒Δ′
iσ} (ﬁnite).
2. ≤i is deﬁned as: (Γ +′
iσ ⇒Δ′
iσ) ≤i (Γ +′
iτ ⇒Δ′
iτ) iﬀΓ +′
iσ ⊆Γ +′
iτ
3. ⊩i is deﬁned as follows17: for any p, X ∈
i≤n(Sb(Γi) ∪Sb(Δi)),
1) (Γ +′
iσ ⇒Δ′
iσ) ⊩i p iﬀp ∈Γ +′
iσ ;
2) (Γ +′
iσ ⇒Δ′
iσ) ⊩i X iﬀX ∈Γ +′
iσ .
For any p, X /∈
i≤n(Sb(Γi) ∪Sb(Δi)), (Γ +′
iσ
⇒Δ′
iσ) ⊮i p and (Γ +′
iσ
⇒
Δ′
iσ) ⊮i X. By this deﬁnition, we can immediately obtain some desirable prop-
erties of a model of our logic. First, ≥i is a partial order, since this is an inclusion.
Secondly, for any intuitionistic variable p ∈
i≤n(Sb(Γi)∪Sb(Δi)), monotonicity
clearly holds. Thirdly, about classical variables, the following hold.
16 In the following, we say “model” unless we emphasize that one is a countermodel.
17 Sb(Γ) stands for the set of subformulas contained in the set of formulas Γ.

Hypersequent Calculus for Intuitionistic Logic with Classical Atoms
327
Claim. For any (Γ +′
iσ ⇒Δ′
iσ) ≥i (Γ +′
i0 ⇒Δ′
i0), {X|X ∈Γ +′
i0 } = {X|X ∈Γ +′
iσ }.
Proposition 2. For any X ∈V arC, the stability holds, i.e.,
For any (Γ +′
iσ ⇒Δ′
iσ) ≥i (Γ +′
i0 ⇒Δ′
i0), (Γ +′
iσ ⇒Δ′
iσ) ⊩i X or
for any (Γ +′
iσ ⇒Δ′
iσ) ≥i (Γ +′
i0 ⇒Δ′
i0), (Γ +′
iσ ⇒Δ′
iσ) ⊮i X.
Proof. If X /∈
i≤n(Sb(Γi) ∪Sb(Δi)), then by deﬁnition, for any (Γ +′
iσ ⇒Δ′
iσ),
(Γ +′
iσ ⇒Δ′
iσ) ⊮i X. The statement easily follows. If X ∈
i≤n(Sb(Γi)∪Sb(Δi)),
then suppose that for X ∈
i≤n(Sb(Γi) ∪Sb(Δi)) of G, ∃(Γ +′
iσ
⇒Δ′
iσ) ≥i
(Γ +′
i0 ⇒Δ′
i0), (Γ +′
iσ ⇒Δ′
iσ) ⊮i X and ∃(Γ +′
iσ ⇒Δ′
iσ) ≥i (Γ +′
i0 ⇒Δ′
i0), (Γ +′
iσ ⇒
Δ′
iσ) ⊩i X. For particular ρ and τ, (Γ +′
iτ ⇒Δ′
iτ) ≥i (Γ +′
i0 ⇒Δ′
i0) and (Γ +′
iτ ⇒
Δ′
iτ) ⊮i X, and (Γ +′
iρ ⇒Δ′
iρ) ≥i (Γ +′
i0 ⇒Δ+′
i0 ) and (Γ +′
iρ ⇒Δ′
iρ) ⊩i X. So, by
deﬁnition, X /∈Γ +′
iτ and X ∈Γ +′
iρ . However, by the claim, X ∈Γ +′
i0 iﬀX ∈Γ +′
iτ
and X ∈Γ +′
i0 iﬀX ∈Γ +′
iρ . Then, X ∈Γ +′
i0 iﬀX /∈Γ +′
i0 . Contradiction.
⊠
Proposition 3. Let (Γ +′
iσ ⇒Δ′
iσ) be a component of G+ in S+
i
and (Γ +′
iσ ⇒
Δ′
iσ) ≥i (Γ +′
i0 ⇒Δ′
i0). For any X ∈Sb(Γ +
i ) ∪Sb(Δi),18
1. X ∈Γ +′
iσ =⇒∀(Γ +′
iτ ⇒Δ′
iτ) ≥i (Γ +′
i0 ⇒Δ′
i0), (Γ +′
iτ ⇒Δ′
iτ) ⊩i X and
2. X ∈Δ′
iσ =⇒∀(Γ +′
iτ ⇒Δ′
iτ) ≥i (Γ +′
i0 ⇒Δ′
i0), (Γ +′
iτ ⇒Δ′
iτ) ⊮i X
Proposition 4. For any ψ ∈Sb(Γ +
i ) ∪Sb(Δi), (Γ +′
iσ ⇒Δ′
iσ) ≤i (Γ +′
iτ ⇒Δ′
iτ)
and (Γ +′
iσ ⇒Δ′
iσ) ⊩i ψ =⇒(Γ +′
iτ ⇒Δ′
iτ) ⊩i ψ.
Proof. By induction on the complexity of formulas.
⊠
For purely classical formulas, we have another statement to show.
Proposition 5. For any formula ψ◦∈Sb(Γ +
i ) ∪Sb(Δi) and for any (Γ +′
iσ ⇒
Δ′
iσ) ≥i (Γ ′
i0 ⇒Δ′
i0), 1. ψ◦∈Γ +′
iσ
=⇒∀(Γ +′
iτ
⇒Δ′
iτ) ≥i (Γ +′
i0
⇒Δ′
i0),
(Γ +′
iτ ⇒Δ′
iτ) ⊩i ψ◦;
2. ψ◦∈Δ′
iσ =⇒∀(Γ +′
iτ ⇒Δ′
iτ) ≥i (Γ +′
i0 ⇒Δ′
i0), (Γ +′
iτ ⇒
Δ′
iτ) ⊮i ψ◦.
Proof. By induction of the complexity of ψ◦.
Lemma 2 (Semantic Lemma).
Let G+ be a modiﬁed saturated hypersequent, and let (Γ +′
i0 ⇒Δ′
i0) be a com-
ponent of G+ in S+
i . For any (Γ +′
iσ ⇒Δ′
iσ) ≥i (Γ +′
i0 ⇒Δ′
i0) and for any formula
ϕ ∈Sb(Γ +
i ) ∪Sb(Δi),
1. ϕ ∈Γ +′
iσ =⇒(Γ +′
iσ ⇒Δ′
iσ) ⊩i ϕ; 2. ϕ ∈Δ′
iσ =⇒(Γ +′
iσ ⇒Δ′
iσ) ⊮i ϕ.
Proof. By induction on the complexity of formulas.
Case 1.1) ϕ = p. For 1. By deﬁnition. For 2, suppose p ∈Δ′
iσ. By the condition
3. of Saturation Lemma , p /∈Γ +′
iσ . So, by deﬁnition, (Γ +′
iσ ⇒Δ′
iσ) ⊮i p.
Case 1.2) ϕ = X. This is a corollary of proposition 12.
18 Γ +
i is the antecedent of the original component with safe variables added. We assume
we have ﬁxed one saturated hypersequent G+ to construct a Kripke model.

328
H. Kurokawa
Case 2) ϕ = A ∗B (∗=→, ∧, ∨). We have four subcases of combinations of a
mixed formula and a classical formula (1) A = C◦and B = D◦, (2) A is mixed
and B is mixed, (3) A = C◦and B is mixed, and (4) A is mixed and B = D◦.
However, classical formulas are special cases of mixed for intuitionistic formulas,
so if the lemma holds for general cases, it obviously holds for classical formulas.
It suﬃces to prove the lemma for generic formulas without specifying whether
these are classical or not. The proof is similar to the case of IPC.
⊠.
4.3
Proof of Completeness and Cut-Elimination
Assuming mLIC−⊬Γ1 ⇒Δ1| . . . |Γn ⇒Δn, we ﬁrst construct a Kripke coun-
termodel for a component Γi ⇒Δi. Out of a modiﬁed saturated hypersequent
G+, we have constructed Kripke models Ki (1 ≤i ≤n). For each of these, by
construction, we have a (root) saturated component (Γ +′
i0 ⇒Δ′
i0) in S+
i , s.t.
{X1, ..., Xp} ∪Γi ⊆Γ +′
i0 and Δi ⊆Δ′
i0. By Semantic Lemma, deﬁnition ⊩i for
sequent and reﬂexivity of ≤i, Ki, (Γ +′
i0 ⇒Δ′
i0) ⊮i Γi ⇒Δi (1 ≤i ≤n).
Next, we show the completeness theorem of the hypersequent calculus itself.
Assume mLIC−⊬Γ1 ⇒Δ1| . . . |Γn ⇒Δn. We want to show that there is a
Kripke model K = (K, ≤, ⊩) and there is a state sr ∈K s.t. 
1≤i≤n(K, sr ⊮
Γi ⇒Δi). We construct the desired Kripke model by “gluing” constructed
Kripke models.
For all the safe variables X1, ..., Xp in G+, X1, . . . , Xp ∈Γ +′
i0 (1 ≤i ≤n). We
already have Ki = (S+
i , ≥i, ⊩i) s.t. Ki, (Γ +′
i0 ⇒Δ′
i0) ⊮i Γi ⇒Δi (1 ≤i ≤n).
Then, we ﬁrst take the disjoint union19 of the models Ki (1 ≤i ≤n) and add a
new node below the roots of the models. Let sr = (Γ ′
r ⇒Δ′
r), Γ ′
r = {X1, ..., Xp}
and Δ′
r = ∅. sr is the new root node. Let (Γ +′
iσ ⇒Δ′
iσ) be a component of G+.
Now let K = (S+, ≤, ⊩), where 1. S+ = {sr} ∪
1≤i≤n S+
i ; 2. ≤= {(sr, s) ∈
{sr} × S+|Γ ′
r ⊆Γ +′
iσ or Γ ′
r ⊆Γ ′
r} ∪
1≤i≤n(≤i), where either s = (Γ ′
r ⇒Δ′
r)
or s = (Γ +′
iσ ⇒Δ′
iσ) s.t. (Γ +′
iσ ⇒Δ′
iσ) ∈
1≤i≤n S+
i ; 3. ⊩= {(sr, Xl)|Xl ∈
Γ ′
r} ∪
1≤i≤n(⊩i). Such a model K must exist, since the only case where the
glued model does not exist is the case where we have a conﬂict among classical
variables, but by construction we never have such a case here.
Since the partial order in the new model is the inclusion on the antecedents
of the saturated sequents, monotonicity obviously holds for intuitionistic atoms.
The new condition for classical variables must be a consequence of the claim: for
any (Γ +′
iσ ⇒Δ′
iσ) ≥(Γ ′
r ⇒Δ′
r) in S+, {X|X ∈Γ ′
r} = {X|X ∈Γ +′
iσ }. The proof
is essentially the same as that given to the nodes of Ki.
Also, the following are the immediate consequences of the deﬁnition.
1. sr ⊩Xl iﬀXl ∈Γ ′
r iﬀ∀s ∈S+, s ⊩Xl.
2. ∀s ∈S+
i, s ⊩ϕ ⇐⇒s ⊩i ϕ for any formula ϕ,.
Claim. If mLIC−⊬Γ1 ⇒Δ1| . . . |Γn ⇒Δn, then 
1≤i≤n(K, sr ⊮Γi ⇒Δi).
19  stands for the disjoint union operator.

Hypersequent Calculus for Intuitionistic Logic with Classical Atoms
329
Proof. In Ki, at (Γ +′
i0 ⇒Δ′
i0), each component is falsiﬁed, respectively. So, for
each i (1 ≤i ≤n), at the state (Γ +′
i0 ⇒Δ′
i0) ∈S+, the following hold: 1) (Γ +′
i0 ⇒
Δ′
i0) ≥(Γ ′
r ⇒Δ′
r); 2) (Γ +′
i0 ⇒Δ′
i0) ⊩ϕ for all ϕ ∈Γi; 3) (Γ +′
i0 ⇒Δ′
i0) ⊮ψ for
all ψ ∈Δi. So, by deﬁnition, 
1≤i≤n(K, sr ⊮Γi ⇒Δi)
⊠(claim)
Hence, mLIC−⊬Γ1 ⇒Δ1| . . . |Γn ⇒Δn implies 
1≤i≤n(K, sr ⊮Γi ⇒Δi). So,
if mLIC−⊬Γ1 ⇒Δ1| . . . |Γn ⇒Δn, then K, sr ⊮Γ1 ⇒Δ1| . . . |Γn ⇒Δn. So, if
Γ1 ⇒Δ1| . . . |Γn ⇒Δn is valid, then mLIC−⊢Γ1 ⇒Δ1| . . . |Γn ⇒Δn.
We have shown completeness of mLIC−. On the other hand, the soundness
theorem for mLIC itself holds with respect to the same class of Kripke models,
as already discussed. Then, if there is a Kripke model K and s ∈K, s.t. K, s ⊮
Γ1 ⇒Δ1| . . . |Γn ⇒Δn, then mLIC⊬Γ1 ⇒Δ1| . . . |Γn ⇒Δn.
So, if mLIC⊢Γ1 ⇒Δ1| . . . |Γn ⇒Δn, then mLIC−⊢Γ1 ⇒Δ1| . . . |Γn ⇒Δn.
This gives a semantic proof of the cut-elimination theorem for mLIC.
As a corollary, the subformula property holds for mLIC, since Cut is the only
rule that spoils the subformula property in mLIC. Due to this corollary, IPCCA is
a conservative extension of its intuitionistic and classical fragments, respectively,
since for any purely intuitionistic (or classical) formula provable in mLIC, there
is a proof using only subformulas of the formula. The model we constructed is
ﬁnite, so we have decidability of mLIC.
We have another corollary of completeness. A sequent system S has the
disjunction property (DP) if S ⊢⇒A ∨B =⇒S ⊢⇒A or S ⊢⇒B. We have
a reﬁnement of DP. To state the proposition, we need a deﬁnition of a positive
and negative occurrence of a formula in a sequent. We put + and −symbol in
front of a formula to state that the given formula has a positive occurrence and a
negative occurrence. “+ϕ” means ϕ has a positive occurrence and “−ϕ” means
ϕ has a negative occurrence. The occurrences of a subformula of a given formula
is determined inductively as follows. For a sequent Γ ⇒Δ, 1) If ϕ ∈Γ, then
−ϕ: if −ϕ and ϕ = (A ∧B), then −A and −B; if −ϕ and ϕ = (A ∨B), then −A
and −B; if −ϕ and ϕ = (A →B), then +A and −B; 2) If ϕ ∈Δ, then +ϕ : if
+ϕ and ϕ = (A ∧B), then +A and +B; if +ϕ and ϕ = (A ∨B), then +A and
+B; if +ϕ and ϕ = (A →B), then −A and +B.
We say “the Extended Disjunction Property (EDP) holds” when the following
statement holds, since DP for IPC is a special case of this.
Proposition 6. In mLIC, if no classical subformula of A ∨B has both negative
and positive occurrences in A and B of ⇒A ∨B, then ⇒A or ⇒B holds.
Proof. Proof by contradiction. Suppose that there exists A ∨B such that not
⇒A and not ⇒B, but that ⇒A ∨B s.t. there is no classical subformula of
A ∨B whose positive and negative occurrences appear in A and B of A ∨B.
First, observe that the above inductive characterization of positive and neg-
ative occurrences of a subformula of ϕ in Γ or Δ corresponds to a step in the
saturation procedure that puts a subformula of a formula in Γ and Δ. The induc-
tive characterization obviously gives us: −ϕ in G iﬀϕ occurs in the antecedent
of some saturated component of some G′; +ϕ in G iﬀϕ occurs in the succedent
of some saturated component of some G′.

330
H. Kurokawa
By assumption, we have a case of ⇒A ∨B where we do not have any occur-
rence of a classical subformula ϕ◦in A (in B) s.t. +ϕ◦and in B (in A) s.t. −ϕ◦.
So, in particular, there is no X such that +X (−X) in mLIC−⊬⇒A and −X
(+X) in mLIC−⊬⇒B. So, we can construct saturated hypersequents G′
A of
mLIC−⊬⇒A and G′
B of mLIC−⊬⇒B such that there is no classical variable in
some succedent (antecedent) of G′
A and in some antecedent (succedent) of G′
B.
By completeness, we can construct countermodels KA and KB based on G′
A
and G′
B s.t. KA, rA ⊮⇒A and KB, rB ⊮⇒B. By construction, there is no
classical variable X such that at some sA of KA, sA ⊩X (or sA ⊮X) and at
some sB of KB, sB ⊮X (or sB ⊩X). This is obviously suﬃcient to use the
same gluing method as used in the proof of completeness. So, we can construct a
countermodel K, r ⊮⇒A∨B. So, by soundness, ⇒A∨B is not mLIC-provable,
which contradicts our assumption ⇒A ∨B.20
⊠
References
1. S. Artemov and R. Iemhoﬀ. The Basic Intuitionistic Logic of Proofs. Journal of
Symbolic Logic, to appear in 2007.
2. A. Avron. Hypersequents, Logical Consequence, and Intermediate Logics for Con-
currency. Annals of Mathematics and Artiﬁcial Intelligence, 4:225–248, 1991.
3. A. Avron. The Method of Hypersequents in the Proof Theory of Propositional Non-
classical Logics. In Wilfrid Hodges, Martin Hyland, Charles Steinhorn, and John
Truss, editors, Logic: from foundations to applications. Proc. Logic Colloquium,
Keele, UK, 1993, pages 1–32. Oxford University Press, New York, 1996.
4. A. Avron. Two Types of Multiple-Conclusion Systems. Journal of the Interest
Group in Pure and Applied Logics, 6 (5):695–717, 1998.
5. M. Baaz, A. Ciabattoni, and C. G. Ferm¨uller.
Hypersequent Calculi for G¨odel
Logics - a Survey. Jounal of Logic and Computation, 13:1–27, 2003.
6. L. Fari˜nas del Cerro and A. Herzig. Combining Classical and Intuitionistic Logic,
or: Intuitionistic Implication as a Conditional. In F. Baader and K. U. Schulz, ed-
itors, Frontiers of Combining Systems: Proceedings of the 1st International Work-
shop, Munich (Germany), pages 93–102. Kluwer Academic Publishers, 1996.
7. M. Fitting. Intuitionistic Logic, Model Theory and Forcing. North Holland, 1969.
8. R. C. Flagg. Integrating classical and intuitionistic type theory. Annals of Pure
and Applied Logic, 32:27–51, 1986.
9. J-Y. Girard. On the Unity of Logic. Annals of Pure and Applied Logic, 59:201–217,
1993.
10. L. Humberstone. Interval Semantics for Tense Logic: Some Remarks. Journal of
Philosophical Logic, 8, 1979.
11. H. Kurokawa. Intuitionistic Logic with Classical Atoms. Technical report, CUNY
Ph.D. Program in Computer Science Technical Report TR-2004003, 2004.
12. O. Laurent and K. Nour. Parametric mixed sequent calculus. Technical report,
Universit´e de Savoie, 2005. Pr´epublication du Laboratoire de Mathmatiques num
05-05a.
20 Note that the converse of the proposition does not hold. Even if there is such a
subformula in the formula, we may not have to apply Classical Splitting to get a
cut-free proof of the formula, and we have an intuitionistic proof of it. Here is a
simple example, ⇒((X ∧p) →p) ∨(p →X).

Hypersequent Calculus for Intuitionistic Logic with Classical Atoms
331
13. P. Lucio. Structured Sequent Calculi for Combining Intuitionistic and Classical
First-Order Logic. In H. Kirchner and Ch. Ringeissen, editors, Proceedings of the
Third International Workshop on Frontiers of Combining Systems, FroCoS 2000,
LNAI 1794, pages 88–104. Springer, 2000.
14. P. Miglioli, U. Moscato, M. Ornaghi, and G. Usberti. A Constructivism Based on
Classical Truth. Notre Dame Journal of Formal Logic, 30(1):67–90, 1989.
15. G. Mints. A Short Introduction to Intuitionistic Logic. Kluwer Academic - Plenum,
2000.
16. S. Negri and J. von Plato. Structural Proof Theory. Cambridge University Press,
Cambridge, UK, 2001.
17. K. Nour and A. Nour. Propositional mixed logic : its syntax and semantics. Journal
of Applied Non-Classical Logics, 13:377–390, 2003.
18. A. Sakharov. Median Logic. Technical report, St. Petersberg Mathematical Society.
http://www.mathsoc.spb.ru/preprint/2004/index.html.
19. C. Smorynski. Application of Kripke models. In A. Troelstra, editor, Metamath-
ematical Investigations of Intuitionistic Arithmetic and Analysis. Springer Verlag,
1973.

Proof Identity for Classical Logic:
Generalizing to Normality
Roman Kuznets
CUNY Graduate Center
365 Fifth Avenue, New York City, NY 10016, USA
kuznets@gmail.com
Abstract. The problem of the identity criteria for proofs can be traced
to Hilbert and Prawitz. One of the approaches, which uses the concept
of generality of proofs, was suggested in 1968 by Lambek. Following his
ideas, we propose a language and a logic to represent Hilbert-style proofs
for classical propositional logic by adapting the Logic of Proofs (LP) in-
troduced by Artemov in 1994. We prove that proof polynomials, the
objects representing Hilbert derivations in LP, are suﬃcient to realize
all propositional derivations, with or without hypotheses. We also show
that proof polynomials respect the ideas of generality and provide an al-
gorithm for determining whether two given proof polynomials represent
the same proof. These results naturally extend similar properties of com-
binatory logic demonstrated by Hindley. The language of LP allows us to
formally capture more structure of Hilbert-style proofs. In particular, we
show how the well-known phenomenon of proof composition in classical
logic manifests itself in the case of Hilbert proofs.
1
Introduction
It was recently discovered that the 24th of the famous 23 Hilbert problems, which
was dropped from the list, was to develop such a theory of proofs that would
allow to compare proofs and provide criteria for judging which is the simplest
proof of a given theorem (see [TW02]).
Several decades later, the question reappeared independently. This is how
Prawitz formulates it in [Pra71]: “In the same way as one asks when two for-
mulas deﬁne the same set or two sentences express the same proposition, one
asks when two derivations represent the same proof; in other words, one asks
for identity criteria for proofs or for a “synonymity” (or equivalence) relation
between derivations.”
In his series of papers [Lam68, Lam69, Lam72], Lambek suggested considering
two proofs identical iff they have the same generalizations; this supposition is
sometimes called Generality Conjecture. By generalization we mean here a more
S. Artemov and A. Nerode (Eds.): LFCS 2007, LNCS 4514, pp. 332–348, 2007.
c
⃝Springer-Verlag Berlin Heidelberg 2007

Proof Identity for Classical Logic: Generalizing to Normality
333
general statement that can be proven by applying the same principles in the
same order. Here is an example:
Example 1. The tautology
A →A ∨(B →B)
(1)
can be derived in several ways:
1. (a) A →A ∨(B →B)
disjunction axiom
2. (a) ...
derivation of tautology B →B
(b) B →B
(c) (B →B) →A ∨(B →B)
disjunction axiom
(d) A ∨(B →B)
modus ponens from (b) and (c)
(e) A ∨(B →B) →(A →A ∨(B →B))
implication axiom
(f) A →A ∨(B →B)
modus ponens from (d) and (e)
The two derivations are easily distinguished according to Generality Conjecture.
Indeed a more general theorem proven by derivation 1 is
A →A ∨(B →C)
(2)
(or even A →A ∨D), while a more general conclusion of derivation 2 is
A →C ∨(B →B) .
(3)
Our original tautology (1) is a substitution instance of both (2) and (3), but
neither (3) can be derived by derivation 1 nor (2) can be derived by derivation 2.
To be able to distinguish and/or identify proofs, one would need a suﬃciently
concise way of representing them that complies with the ideas of generality.
Many systems for naming and/or identifying proofs have been developed, in
particular very robust systems for intuitionistic and linear logics. Designing such
a system for classical logic, however, has presented various challenges. As a re-
sult, there exist multiple proof-naming notations based on various classical proof
systems, but none of them holds a dominant position unlike, for instance, the
uniformly accepted λ-terms for intuitionistic logic. These notations and proof
systems include, but are not limited to, Andrews’s matings method ([And76]),
Bibel’s matrix method ([Bib79]), proof-nets for a certain classical sequent calcu-
lus by Lamarche and Straßburger ([LS05]), classical implication bases method
for cut-free atomically closed tableaux by Fitting ([Fit06]), classical λ-terms by
Nour ([Nou06]). Some of these approaches, e.g. [Fit06], rely on cut-free proper-
ties. Others restrict the language, e.g. in [LS05] only formulas in negation normal
form1 are considered. Identity of proofs in these proof systems is often related to
normalization in the respective proof system rather than to generality of proofs.
1 Negation is restricted to atomic formulas.

334
R. Kuznets
We will concentrate on Hilbert-style proofs, for which few proof-naming sys-
tems have been developed. Arguably, Hilbert derivations resemble the way hu-
man mathematicians work the most. On the other hand, Hilbert-style proofs are
diﬃcult to work with because their are inherently not cut-free (the only infer-
ence rule, modus ponens, essentially is the cut); furthermore, they do not have a
precisely deﬁned notion of normalization. It would seem that combinatory logic
is a ready-made system of terms for Hilbert-style derivations. Yet applications
of combinatory logic to proof identity via generality concept are scarce.
We would further argue that combinatory logic does not, in fact, capture all
the facets of derivations from hypotheses. To substantiate this argument we will
use a richer language, namely the language of Artemov’s Logic of Proofs (LP)
developed in [Art95, Art01]. LP is equipped with a construct t:F that resembles a
combinatory statement and is read as ‘proof polynomial t is a proof of formula F.’
But LP also considers boolean combinations of such statements and allows to
iterate the :-operator, e.g. t : s : F. As a result, proof polynomials in LP are not
limited to propositional derivations only. Any derivation in LP can be represented
by a proof polynomial, thus LP is a proof-naming system for itself rather than
for classical propositional logic.
In this paper, we discuss how the machinery of proof polynomials can be ap-
plied to the problem of identifying Hilbert-style proofs in classical propositional
logic. In Sect. 2, we present LP and identify its fragment that seems to best suit
this purpose. In Sect. 3, we show that proof polynomials in the chosen fragment
comply with the idea of generality. We also describe how to extract from a proof
polynomial the most general theorem proven by it, thereby providing a decision
procedure that determines whether two given proof polynomials represent the
same proof. In Sect. 4, we suggest a natural deﬁnition of a normal form for valid
statements about Hilbert proofs in the chosen fragment of LP. In a normal for-
mula all proof polynomials occurring negatively are atomic, which is always the
case for combinatory terms in combinatory logic. This prompted Goris to formu-
late a natural conjecture about proof polynomials that every valid statement is a
substitution instance of a normal valid statement. We provide a counterexample
to this conjecture. However, we note that the conjecture does indeed hold for
formulas in Horn clause form, which can be viewed as a conservativity result
with respect to combinatory logic. Finally, in Sect. 5, we show how to reﬁne
the conjecture using the proof composition operation + explicitly present in the
language of LP, prove the amended conjecture, and discuss the impact of + on
proof identity.
2
Logic of Proofs LP: Choosing a Fragment
The system LP was originally presented in [Art95] (see also [Art01]) as a logic
of formal mathematical proofs. The idea of introducing explicit proofs into the
propositional language dates back to G¨odel’s lecture in 1938, although it was
published only in 1995 (see [G¨od95]). Independently Artemov implemented the
same idea and thus solved a long-standing problem of an adequate provability

Proof Identity for Classical Logic: Generalizing to Normality
335
semantics for modal logic S4. The success of the project was largely due to the
operation of proof composition, denoted in LP by +, which was not present in
G¨odel’s lecture.
2.1
Full LP
Proof polynomials t are built from proof constants ci and proof variables xi by
means of three operations: unary ! and binary + and ·
t ::= ci | xi | ! t | t · t | t + t
The language of LP is obtained by adding to the propositional language a new
construct, t : F, where F is a formula and t is a proof polynomial. The axioms
of LP0 are obtained by adding the following schemas to a ﬁxed ﬁnite set of axiom
schemas of classical propositional logic:
LP1
s:(F →G) →(t:F →(s · t):G)
(application)
LP2
t:F →! t:t:F
(proof checker)
LP3
s:F →(s + t):F,
t:F →(s + t):F
(proof composition)
LP4
t:F →F
(reﬂexivity)
The only inference rule of LP0 is modus ponens. The usual way to deﬁne the
full LP is to add to LP0 the rule of axiom necessitation:
If A is a propositional axiom or one of LP1–4 and c is a constant, infer c:A.
The system LP behaves in many respects as a normal propositional logic. In
particular, LP is closed under substitutions (of both formulas for sentence letters
and proof polynomials for proof variables) and enjoys the deduction theorem.
The informal semantics for proof polynomials in LP considers variables xi to be
unspeciﬁed proofs, and constants ci to be unanalyzed proofs of elementary facts,
i.e., logical axioms.
2.2
Choosing a Constant Speciﬁcation
LP has various subsystems, many of which can be created by changing the con-
stant speciﬁcation.
A constant speciﬁcation CS is a set of LP-formulas of form c:A, where c is a
proof constant and A is an axiom.
A constant speciﬁcation is called injective if no proof constant is assigned
to two diﬀerent axiom instances. In such speciﬁcations, each constant carries
complete information about the axiom instance the proof of which it represents.
A constant speciﬁcation is called schematic if every proof constant is assigned
to one or several axiom schemas ([Mil07]).
A constant speciﬁcation is called schematically injective if it is schematic and
every proof constant is assigned to at most one axiom schema ([Mil07]). Note
that a schematically injective CS is not injective unless it is empty.
A constant speciﬁcation is called axiomatically appropriate if every axiom
instance has a proof constant assigned to it ([Fit05]).

336
R. Kuznets
The maximal constant speciﬁcation is that in which each proof constant is
assigned to every axiom ([Kuz00]). This corresponds to the unrestricted use of
the axiom necessitation rule.
LPCS is deﬁned as the result of adding constant speciﬁcation CS as new axioms
to LP0. LP then is LPCS for the maximal constant speciﬁcation CS.
Using the full LP to compare proofs is not viable because the maximal con-
stant speciﬁcation erases the diﬀerences between axiom schemas. But trying to
distinguish between any two axiom instances through the use of an injective
constant speciﬁcation would go against the spirit of Lambek’s idea of general-
ity. Generality hinges on the fact that substitution instances of the same axiom
schema amount to the same proof. Hence, the best choice to tackle proof identity
is through axiomatically appropriate, schematically injective constant speciﬁca-
tions. Axiomatic appropriateness will ensure that a full scope of valid facts is
covered, whereas schematic injectivity will give the desired level of details.
2.3
Choosing a Fragment
As discussed earlier, our goal is to build a language describing proofs for classical
propositional logic, not LP itself; hence we have to restrict the scope of proof
polynomials to purely classical formulas:
Deﬁnition 1. The language of the Propositional Logic of Proofs, PLP, consists
of all LP-formulas that satisfy the following restriction: F in any subformula t:F
must be purely propositional. The only operations on proof polynomials are ·
and +.
As a consequence, we must get rid of axiom LP2 and similarly restrict the use
of the axiom necessitation rule to propositional axioms (in the propositional
language). So instead of axiomatic appropriateness, we will require propositional
appropriateness:
Deﬁnition 2. A constant speciﬁcation is propositionally appropriate if every
propositional axiom instance has a proof constant assigned to it.
We will formulate two versions of the Propositional Logic of Proofs: with and
without the +-operation, which corresponds to the union, or composition, of
proofs.
Deﬁnition 3. PLP−is a logic in the language of PLP whose axioms are a ﬁnite
set of propositional axiom schemas together with axiom schemas LP1 and LP4.
The inference rules are modus ponens and the axiom necessitation rule, the lat-
ter being restricted to a ﬁxed propositionally appropriate, schematically injective
constant speciﬁcation CS.
PLP+ is obtained by adding the axiom schema LP3 to PLP−.
PLP will be used as a generic name for both PLP−and PLP+.
Note 1. Strictly speaking, the deﬁnition above depends on the chosen axiomati-
zation of classical propositional logic and on the selected constant speciﬁcation.
In the paper, we will be working with one such axiomatization and a correspond-
ing constant speciﬁcation CS, which will be ﬁxed throughout the paper.

Proof Identity for Classical Logic: Generalizing to Normality
337
2.4
Reﬂexive Fragment of PLP
Nikolai Krupski in [Kru06] developed calculus rLPCS, which he showed to be
sound and complete with respect to the so-called reﬂexive fragment of LPCS:
rLPCS = {s:G | LPCS ⊢s:G}
The set of axioms of rLPCS coincides with CS. The rules are
(R1)s:G
r:(G →H)
(r · s):H
(R2)
si :G
(s1 + s2):G
i = 1, 2
(R3)
s:G
! s:s:G
To adapt this calculus for PLP+, we have to get rid of rule (R3). In addition,
for PLP−we also omit rule (R2). The resulting calculi for the previously ﬁxed CS
will be denoted by rPLP+ and rPLP−respectively.
Note 2. Calculus rPLP−closely resembles combinatory logic without reduction
rules. Proof constants play the role of combinators providing at least one com-
binator for each axiom schema in the chosen axiomatization of propositional
logic. The following theorem then proves conservativity of PLP−over such a
combinatory logic.
Theorem 1.
1. PLP−⊢t:F
iff
rPLP−⊢t:F
2. PLP+ ⊢t:F
iff
rPLP+ ⊢t:F
Proof. The “if” direction is trivial.
For the “only if” direction, let PLP ⊢t:F. Then LPCS ⊢t:F. By the complete-
ness theorem for rLPCS proven in [Kru06], rLPCS ⊢t:F. Since proof polynomial t
is !-free (also {+}-free in case of PLP−), this rLPCS derivation can also be per-
formed within rPLP.
⊓⊔
3
PLP and Generality Paradigm
3.1
Proof Polynomials Represent All Derivations
The following property is an analog of Curry-Howard isomorphism:
Lifting Lemma (Artemov, [Art95, Art01]). 1. If ⊢LP F, then there exists
a {+}-free ground2 proof polynomial t such that ⊢LP t:F.
2. If B1, . . . , Bn ⊢LP F, then there exists a {+}-free proof polynomial t depending
on distinct fresh proof variables xi such that
⊢LP x1 :B1 ∧. . . ∧xn :Bn →t(x1, . . . , xn):F .
Proof. The proof is by an easy induction on a Hilbert derivation of F (in the
ﬁrst part, F is a theorem; in the second part, it is derived from hypotheses Bi).
This proof also allows to introduce a “canonical” proof polynomial for each
Hilbert-style derivation:
2 Ground proof polynomial does not have proof variables occurring within it.

338
R. Kuznets
Deﬁnition 4. The proof polynomial t representing a Hilbert-style derivation D
of a formula F from hypotheses B1, . . . , Bn is deﬁned by induction on D:
1. An axiom instance is represented by a proof constant corresponding to the
axiom schema used.
2. A hypothesis Bi is represented by a fresh proof variable xi.
3. An application of modus ponens to P →Q and P is represented by the
proof polynomial t·s, where t and s are the representations of the derivations
of P →Q and P respectively.
4. An application c:A of the axiom necessitation rule is represented by ! c.
Note that the proof polynomial representation of a given derivation is {+}-free.
Also note that the last case is not required for purely propositional derivations.
Hence terms representing propositional derivations are {+, !}-free. Finally, no
proof variables are used in the absence of hypotheses, so that in this case the
representing polynomial is ground.
⊓⊔
This proof, if applied to the restricted fragment PLP−, yields the following
statement:
Theorem 2 (Suﬃciency of PLP−-proofs). 1. If D is a propositional deriva-
tion of F and t is the {+}-free3 ground proof polynomial representing D, then
⊢PLP−t:F.
2. If D is a propositional derivation of a formula F from hypotheses B1, . . . , Bn
and t(x1, . . . , xn) is the {+}-free proof polynomial representing D, then
⊢PLP−x1 :B1 ∧. . . ∧xn :Bn →t(x1, . . . , xn):F .
This theorem shows that PLP−is already suﬃcient to realize all stand-alone
Hilbert-style propositional proofs, with or without hypotheses.
3.2
Proof Polynomials Respect Proof Identity
A tautology F has many proof polynomials t such that PLP−⊢t:F:
Example 2. The two proofs of (1) from Example 1 are represented by proof poly-
nomials a and k(d((sk)k)) respectively, where a, s, k, and d are proof constants
representing the following axiom schemas a :

P →P ∨Q

, d :

Q →P ∨Q

,
s:

(P →(Q →R)) →((P →Q) →(P →R))

, and k:

P →(Q →P)

.4
We must verify that proof polynomials are faithful representations of deriva-
tions, i.e., we must ensure that distinct proofs are not represented by the same
proof polynomial.
3 Note that PLP-terms do not contain !.
4 Here proof polynomial (sk)k represents the standard derivation of P →P familiar
from combinatory logic.

Proof Identity for Classical Logic: Generalizing to Normality
339
Deﬁnition 5. A propositional formula G is called a generalization of a for-
mula F if F is obtained from G by substituting propositional formulas for sen-
tence letters: F = Gσ.
Deﬁnition 6. Two Hilbert-style derivations D and D′ of a tautology F are called
similar5 (according to the generality paradigm) if every generalization G of F
that can be derived by D (using the same axiom schemas and applying modus
ponens in the same order) can also be derived by D′, and vice versa.
Lemma 1. A derivation D proves a propositional tautology F iff PLP−⊢t : F
for the proof polynomial t representing D.
Proof. The “only if” direction follows from Theorem 2.
For the “if”-direction, let PLP−⊢t : F. By Theorem 1, rPLP−⊢t : F. Strip-
ping all proof polynomials from this rPLP−-derivation, we obtain a propositional
derivation of F. Moreover, according to Deﬁnition 4, this derivation is exactly D.
⊓⊔
The desired property follows from Lemma 1 trivially:
Theorem 3. If propositional derivations D and D′ are represented by the same
proof polynomial, they are similar.
Thus we proved that proof polynomials respect proof identity. Note that the con-
verse of Theorem 3 does not hold. For instance, as Evan Goris observed, it is easy
to add some redundancy to the standard skk derivation of P →P mentioned
in Example 2; the representing proof polynomial would expand accordingly. At
the same time, within the generality paradigm P →P cannot have more than
one proof since there are no non-trivial derivable generalization of P →P.
3.3
Proof Identity Is Decidable
PLP also allows to determine eﬀectively whether two given proof polynomials
represent similar derivations. For each proof polynomial t there exists the most
general tautology (if any) proven by t:
Lemma 2. If PLP−⊢t:F, then there exists a tautology G such that
1. PLP−⊢t:G, and
2. any tautology H such that PLP−⊢t:H is a substitution instance of G.
Moreover, this G can be eﬀectively constructed (in polynomial time).
Proof. By Theorem 1, rPLP−⊢t : F. Consider this rPLP−-derivation. By in-
duction on the derivation depth, we simultaneously construct a generalization G
and a substitution σ that maps G back to F.
Each axiom instance in a leaf can be replaced by the axiom schema corre-
sponding to the proof constant used. This axiom schema is a generalization of
5 We use the term “similar” instead of “identical” to avoid an undesirable association
with syntactical identity.

340
R. Kuznets
the original axiom instance used, as well as of any other instance of this axiom
schema. The substitution is easily read from the original axiom instance. We
use fresh sentence letters for each of the leaves, which allows to combine their
substitutions seamlessly.
When the rule (R1) is used in the original derivation for formulas A and B
s:A
r:(A →B)
(r · s):B
,
by IH, we have A replaced by its generalization A1 and A →B replaced by its
generalization A2 →B2. In order to apply the same rule, we ﬁnd the most general
uniﬁer (mgu) of A1 and A2 and apply it to all the formulas in the generalized
derivation. By IH, there exists a substitution σ that maps A1 to A and A2 →B2
to A →B (and hence A2 to A); therefore, σ is a uniﬁer of A1 and A2. Hence
mgu τ of A2 and A1 must exist, and the substitution σ must have form τθ for
some substitution θ. So B is still a substitution of B2τ. Clearly, τ is the most
general substitution under which we could apply the rule. Hence any other B′
such that rPLP−⊢r · s:B′ will be a substitution instance of B2τ.
⊓⊔
Remark 1. If the axiom schemas are written in the form of dags, the uniﬁcations
can be performed polynomially via modiﬁed Robinson’s algorithm (see [CB83]).
Remark 2. An analogous statement for combinatory logic is due to Hindley
(see [Hin69]).
Theorem 4. Given two proof polynomials t and s such that PLP−⊢t : F and
PLP−⊢s : F, it is possible to determine eﬀectively whether t and s represent
similar derivations under the generality paradigm.
Proof. Construct the most general tautology Gt proven by t and the most general
tautology Gs proven by s. If Gt and Gs are the same modulo renaming of
sentence letters (more precisely, each one is a substitution instance of the other),
then t and s represent similar derivations. Otherwise, they represent diﬀerent
derivations as either Gt or Gs will not be a substitution instance of the other.
⊓⊔
4
Normal Form for PLP
It was noted in Theorem 2.2 that each propositional derivation of F from hy-
potheses Bi can be represented by a proof polynomial t such that
⊢PLP−x1 :B1 ∧. . . ∧xn :Bn →t:F ,
(4)
which is a PLP−-theorem in Horn clause form. An arbitrary PLP−-theorem can
therefore be viewed as a statement describing the relationships between classical
Hilbert-style derivations represented by the proof polynomials occurring in the
theorem. Such a reading suggests that proof polynomials occurring negatively
signify the use of a hypothesis (similar to xi in (4)) whereas proof polynomials

Proof Identity for Classical Logic: Generalizing to Normality
341
occurring positively represent derivations from these hypotheses (similar to t
in (4)). In particular, a statement t:F →s:G should be read as ‘if t stands for
the hypothesis F, then s represents a derivation of G from F.’ Under this reading,
it seems that the structure of t should not play any role in this statement: after
all, t is nothing but a label for the place(s) where the hypothesis was used. In
that case, it would seem reasonable to denote such a label by an atomic proof
polynomial, i.e., a proof variable, as is done in (4). One would also expect to see
occurrences of t within s.
Deﬁnition 7. A PLP-formula is called normal if all proof polynomials occurring
negatively in it are distinct proof variables.
This prompted Evan Goris to formulate a conjecture that, applied to PLP,6
becomes
Goris’s Conjecture. For each PLP−-theorem F there exists a normal PLP−-
theorem N such that
F = Nσ,
where substitution σ only replaces proof variables by proof polynomials (sentence
letters remain unaﬀected).
This conjecture turns out to be true for the Horn-clause-like fragment shown
earlier to be suﬃcient for representing all classical derivations. The proof of this
statement, for which we develop an apparatus later in the paper, will be given at
the end of Sect. 5. The statement can be viewed as an extended conservativity
result with respect to combinatory logic: any PLP−statement that has combi-
natory, i.e., Horn clause, format is indeed an instance of a statement derivable
in combinatory logic.
However, as a PLP−-derivation may in fact use the inner structure of a neg-
ative proof polynomial, it is possible to construct a counterexample to Goris’s
Conjecture when applied to the full PLP−. Departing from Horn-clause-like form
allows us to combine alternative hypotheses by purely propositional methods,
without the use of +.
Theorem 5 (Counterexample to Goris’s Conjecture). The formula
F =

x:P ∧y:(P →Q)

∨(y · x):Q →(y · x):Q
(5)
is derivable in PLP−but is not a substitution of any normal derivable formula.
The formula states that a sentence letter Q can be derived either from Q itself
or by modus ponens from hypotheses P →Q and P for some sentence letter P.
Proof (by contradiction). Suppose F is a substitution instance of a normal the-
orem N. There are three occurrences of negative proof polynomials in (5):
6 Originally the conjecture was formulated for the full LP.

342
R. Kuznets
x in front of P, y in front of P →Q, and y · x in the antecedent. Polyno-
mials x and y are already proof variables, so we only need y · x to be replaced
by a proof variable z; w.l.o.g. we may assume z /∈{x, y}. Then
N =

x:P ∧y:(P →Q)

∨z :Q →t:Q
(6)
such that zσ = y·x and tσ = y·x for some substitution σ and proof polynomial t.
We will show that either (6) is not derivable or no substitution of t yields y · x.
Since x and y are both atomic, t must be either a proof variable z1 or have
form z1 · z2 for some proof variables z1 and z2. In the former case, (6) cannot be
a theorem because none of

x:P ∧y:(P →Q)

∨z :Q →x:Q

x:P ∧y:(P →Q)

∨z :Q →y:Q

x:P ∧y:(P →Q)

∨z :Q →z :Q

x:P ∧y:(P →Q)

∨z :Q →z1 :Q
is derivable, where z1 /∈{x, y, z}. Similarly, none of the 16 possibilities for t
having form z1 · z2 works.
⊓⊔
In the counterexample, for N to be a theorem, term t must combine the proof
by modus ponens from P →Q and P (represented by y · x) with the proof by
invoking the hypothesis Q (represented by z). In the absence of +, the only way
to achieve it is to match z with y·x. Alternatively, to represent this propositional
reasoning, we could use +, the operation of proof composition:
PLP+ ⊢

x:P ∧y:(P →Q)

∨z :Q →(y · x + z):Q
(7)
Note that in general, matching one derivation with another will not always be
possible. Thus PLP−lacks machinery to represent the method of case analysis:
Example 3. P ∨Q can be derived either from P or from Q, but there is no proof
polynomial t such that
PLP−⊢x:P ∨y:Q →t:(P ∨Q) .
This example shows that PLP−does not implement all facets of derivations
from hypotheses. Combinatory logic, being less expressive, is even further from
performing this function.
5
Proof Composition in PLP
There are advantages and drawbacks of adding + and switching to PLP+. The
most obvious drawback is:

Proof Identity for Classical Logic: Generalizing to Normality
343
Theorem 6. There exists a tautology F with two diﬀerent propositional deriva-
tions represented in PLP+ by the same proof polynomial.
Of course, we need to extend our deﬁnition of derivation representation to proof
polynomials with occurrences of + since all proof polynomials in Deﬁnition 4
were {+}-free. The only extension true to the meaning of + is:
Deﬁnition 8. t + s represents all derivations represented by either t or s.
Proof. Consider two distinct derivations. Find their {+}-free representations t
and s. Then PLP+ ⊢(t + s) : F. Both derivations are represented by the proof
polynomial t + s.
⊓⊔
This seems like a reincarnation of a problem pointed out in [Str05] for the se-
quent calculus (see also [GTL89]) in Hilbert derivations. As Straßburger puts it
in [Str05], “there is no clear notion of composing proofs in classical logic.” So
the composition of proofs seems to be an inherent property of classical logic.
Neither combinatory logic nor PLP−had tools to express it. On the other hand,
adding such a tool cost us correctness with respect to generality.
A possible way of straightening this out is to view a proof polynomial with +
as representing a collection of derivations rather than a single derivation. Each
derivation in such a collection will once again have the most general tautology
proven by it. To compare two such proof polynomials one will need to compute
all the most general tautologies proven by each and to compare the resulting
sets. Naturally, there will be an exponential blow-up in complexity, but the
question whether two given terms represent the same set of derivations will
remain decidable.
5.1
Normal Form Theorem for PLP+
The major advantage of using PLP+ is what we call the Normal Form Theorem
for PLP+. This is an adaptation of Bryan Renne’s patch to Goris’s formulation
of the conjecture, which proved unsuccessful for the full LP but works for PLP+.
Consider the normal form suggested in (7). After substituting y · x for z we
will not get (5). The result of this substitution yields

x:P ∧y:(P →Q)

∨(y · x):Q →(y · x + y · x):Q ,
which, nevertheless, is very close to (5). The only diﬀerence is that y · x in the
consequent is duplicated.
Normal Form Theorem (for PLP+). For each PLP+-theorem G there ex-
ists a normal PLP+-theorem N and a substitution σ of proof polynomials for
proof variables (sentence letters remain unaﬀected) such that G can be obtained
from Nσ by eliminating duplicate polynomials, i.e., replacing t + t by t (possibly
multiple times).

344
R. Kuznets
The proof of this theorem (see Section 5.3) was largely inspired by Fitting’s
method of classical implication bases (see [Fit06]), although the method itself
will not be directly used.
The only tableau system for LP in existence up until now was developed by
Renne in [Ren04]. As Fitting mentions in [Fit06], for the method of classical
implication bases to work, it is essential that the tableau system used be cut-
free. Renne’s tableau system does not have the cut rule itself. But it has the
so-called βX-rules:
F (s · t):Y
F s:(X →Y )
F t:X
These rules resemble the cut-rule in that (a) they violate the subformula prop-
erty; (b) they do not respect polarities. This makes it hard to use Renne’s
tableaux in our proof. Hence we will adopt a diﬀerent tableau system prompted
by the decision algorithm from [Mkr97, Kuz00].
5.2
Tableaux for PLP+
It is easier to devise tableaux for LPCS ﬁrst and then adapt them to PLP+. To
obtain a tableau system for LPCS, we add the following two rules to the standard
set of propositional tableau rules:
α-rule:
T s:G
T G
T s ≫G
β-rule:
F s:G
F G
F s ≫G
Here s ≫G is a notation suggested by Renne that replaces an older notation
G ∈∗(s) from [Kuz00, Mkr97]. It roughly means that s can be thought of as a
proof of G. According to Mkrtychev semantics for LP (see [Mkr97]),
s:G is true
iff
both G and s ≫G are true.
If this statement is recast in a tableau format, it yields the α- and β-rules above.
Closure conditions. Unlike in classical propositional tableaux, there is an
additional closure condition for a branch:
Deﬁnition 9. A branch of an LPCS-tableau is closed if either
1. it contains both F G and T G for some formula7 G or
2. it contains expressions T s1 ≫G1, . . . , T sn ≫Gn, and F r ≫H such that
s1 :G1, . . . , sn :Gn ⊢rLPCS r:H .
Let us call a branch that is closed according to case 1 propositionally closed;
similarly, a branch that is closed according to case 2 will be called ≫-closed.
A tableau is closed if all its branches are closed.
7 For technical reasons, we prohibit G from having form s ≫B.

Proof Identity for Classical Logic: Generalizing to Normality
345
Soundness and completeness of this tableau system with respect to LPCS was
proven in [Mkr97], although the notation was slightly diﬀerent and the word
“tableau” was never used.
It is well known that G is a propositional tautology iff there is an atomically
closed propositional tableau for FG, i.e., each branch of this tableau has a pair of
formulas F P and T P, where P is a sentence letter. The tableau system for LPCS
described above enjoys a similar property:
Deﬁnition 10. An LPCS-tableau is called pseudo-atomically closed if a) it is
closed and, in addition, b) each propositionally closed branch has a pair of for-
mulas F P and T P, where P is a sentence letter.
Lemma 3 (Mkrtychev, [Mkr97]). For each LPCS-valid formula G there ex-
ists a pseudo-atomicaly closed tableau for F G.
To adapt this tableau system to PLP, we restrict the language to that of PLP
and change the deﬁnition of a ≫-closed branch:
Deﬁnition 11. A PLP+(PLP−)-tableau is an LPCS-tableau in PLP-language.
A branch of a PLP+( PLP−)-tableau is closed if either
1. it is propositionally closed in the sense of LPCS or
2. it contains expressions T s1 ≫G1, . . . , T sn ≫Gn, and F r ≫H such that
s1 :G1, . . . , sn :Gn ⊢rPLP+(rPLP−) r:H .
Theorem 7 (Completeness Theorem for PLP-tableaux). PLP-formula G
is
derivable
in
PLP+
( PLP−)
iff
there
is
a
pseudo-atomically
closed
PLP+( PLP−)-tableau for F G.
Proof. Mkrtychev models for LPCS from [Mkr97] can be adapted to PLP+ (PLP−)
in a way similar to our adaptation of the tableau system. The completeness proof
from [Mkr97], which uses the maximal consistent sets construction, applies to
these adapted models with cosmetic changes. Then a standard proof of tableau
completeness can be used w.r.t. these adapted models.
⊓⊔
5.3
Proof of the Normal Form Theorem
Proof. Consider an arbitrary theorem G of PLP+. By Completeness Theorem 7,
there exists a pseudo-atomically closed tableau for F G. All proof polynomials
in this closed tableau can be broken into families of related occurrences:
Deﬁnition 12. The proof polynomial r in the parent formula of an α-rule
T r:B
T B
T r ≫B
is directly related to r in the second child. Note that B may not contain proof
polynomials. Cases for the β-rule and all the propositional rules are similar.
A family of occurrences is an equivalence class with respect to the transitive
reﬂexive closure of this direct relationship.

346
R. Kuznets
A direct consequence of this deﬁnition is the following
Lemma 4. The simultaneous replacement of all occurrences of a proof polyno-
mial from a given family in a given tableau by another proof polynomial produces
a new tableau.
According to the Normal Form Theorem, negative families of proof polynomials
should be replaced by distinct proof variables. By Lemma 4, this will result in a
new tableau for F N ′, where N ′ is the normal formula obtained from G in the
course of these replacements. However, simply producing a tableau for F N ′ is
insuﬃcient to show that N ′ is a theorem of PLP+. In order for N ′ to be derivable,
the tableau must be closed. The counterexample from Theorem 5 shows that this
may not be the case.
Each propositionally closed branch will remain propositionally closed after
the replacements. Indeed, the tableau was pseudo-atomically closed, i.e., each
propositionally closed branch contained a pair F P and T P for some sentence
letter P. This P will not be aﬀected by the replacements.
By contrast, ≫-closed branches may cease to be closed. Such a branch was
closed because it contained some negatively occurring expressions T si ≫Gi,
where i = 1, . . . , n and some positively occurring expression F r ≫H such that
s1 :G1, . . . , sn :Gn ⊢rPLP+ r:H .
(8)
Let us associate such a derivation with each ≫-closed branch. The replacements
of negative families by proof variables will aﬀect the leaves of these derivations
as well as their conclusions. Leaves of the derivations correspond to negative
families in the tableau; hence the replacements in the tableau will be matched in
the derivations. By contrast, conclusions of the derivations correspond to positive
families in the tableau, which are not aﬀected by the replacements at this stage.
Let r′ be obtained from r via the replacements. Since F r ≫H in the tableau
was not replaced by F r′ ≫H, (8) may cease to be a derivation, so there is no
guarantee that its associated branch will remain ≫-closed after the replacement.
We cannot replace the family of the positive occurrence of r in this F r ≫H
by r′ because F r ≫H may participate in several derivations that generate
diﬀerent r′s. Let r1, . . . , rn be all such r′s for all derivations involving F r ≫H.
Replace the family of this positive occurrence of r by r1 +. . .+rn. Let N be the
result of applying such additional replacements to N ′ for all ≫-closed branches.
Since
ri :H ⊢rPLP+ (r1 + . . . + rn):H ,
each derivation of ri : H can be appended to a derivation of (r1 + . . . + rn) : H.
Thus all branches that were ≫-closed in the original tableau will be ≫-closed
after these additional replacements.
We applied two series of replacements to the original closed tableau for F G
and obtained a closed tableau for F N, where all negative occurrences of proof
polynomials are proof variables and positive occurrences have form r1 +. . .+rn.
It follows that N is a normal theorem of PLP+. It remains to note that reversing
the replacement of negative occurrences in N will bring all the negative families

Proof Identity for Classical Logic: Generalizing to Normality
347
to the initial state, whereas in a positive family r1 + . . . + rn each of ri’s will be
mapped back to r so that the family will take form r + . . . + r.
⊓⊔
In Theorem 2, formulas of the form x1 : B1 ∧. . . ∧xn : Bn →t : G were shown
to be suﬃcient for representing all stand-alone propositional derivations from
hypotheses. If the proof of the Normal Form Theorem is restricted to theorems
of form s1 :B1 ∧. . . ∧sn :Bn →t:G, a stronger normal form can be obtained. In
this Horn-clause-like fragment, the original Goris’s Conjecture is true:
Corollary 1. For each PLP+( PLP−)-theorem H = s1 :B1 ∧. . . ∧sn :Bn →t:G
there exists a normal PLP+( PLP−)-theorem N and a substitution σ of proof
polynomials for proof variables (sentence letters remain unaﬀected) such that
H = Nσ.
Proof. Consider a completed pseudo-atomically closed PLP+(PLP−)-tableau for
F H. All ≫-closed branches in it (if any) share the same set of ≫-expressions:
{T s1 ≫B1, . . . , T sn ≫Bn, F t ≫G}
Thus one rPLP+(rPLP−)-derivation may be associated with all such branches.
Any PLP−-tableau (rPLP−-derivation) is also a PLP+-tableau (an rPLP+-deri-
vation). Hence for either theory we can apply the algorithm from the proof of
the Normal Form Theorem for PLP+. Since there is only one rPLP+-derivation,
the positive occurrences of t will be replaced by only one proof polynomial t′ so
that no duplicates will be introduced. Consequently, there is no need to eliminate
duplicates, and Nσ already equals H. It remains to note that in the case of PLP−
the original rPLP−-derivation did not contain any +’s. Since t is replaced by only
one t′ no rule for + is needed, hence the derivation remains indeed an rPLP−
one.
⊓⊔
Acknowledgements. I am deeply grateful to my research advisor Sergei Arte-
mov for many fruitful discussions. I also thank Evan Goris and Bryan Renne
for the interest they took in the problem and for many valuable comments and
suggestions. Finally, I am indebted to the anonymous referees for their insights
that helped to shape the ﬁnal version of the paper.
References
[And76]
Peter B. Andrews. Refutations by matings. IEEE Transactions on Comput-
ers, 25(8):801–807, 1976.
[Art95]
Sergei N. Artemov. Operational modal logic. Technical Report MSI 95–29,
Cornell University, 1995.
[Art01]
Sergei N. Artemov. Explicit provability and constructive semantics. Bulletin
of Symbolic Logic, 7(1):1–36, 2001.
[Bib79]
Wolfgang Bibel.
Tautology testing with a generalized matrix reduction
method. Theoretical Computer Science, 8:31–44, 1979.
[CB83]
Jacques Corbin and Michel Bidoit. A rehabilitation of Robinson’s uniﬁcation
algorithm. In R. E. A. Mason, editor, Information Processing 83, pages 909–
914. North-Holland/IFIP, 1983.

348
R. Kuznets
[Fit05]
Melvin Fitting.
The Logic of Proofs, semantically.
Annals of Pure and
Applied Logic, 132(1):1–25, 2005.
[Fit06]
Melvin Fitting. Realizing substitution instances of modal theorems. Unpub-
lished, available at http://comet.lehman.cuny.edu/fitting/, 2006.
[G¨od95]
Kurt G¨odel. Vortrag bei Zilsel (*1938a). In Solomon Feferman, John W.
Dawson, Jr., Warren Goldfarb, Charles Parsons, and Robert N. Solovay,
editors, Kurt G¨odel Collected Works, volume III, pages 86–113. Oxford Uni-
versity Press, 1995.
[GTL89]
Jean-Yves Girard, Paul Taylor, and Yves Lafont. Proofs and Types, volume 7
of Cambridge Tracts in Theoretical Computer Science. Cambridge University
Press, 1989.
[Hin69]
R. Hindley. The principal type-scheme of an object in combinatory logic.
Transactions of the American Mathematical Society, 146:29–60, 1969.
[Kru06]
Nikolai V. Krupski. On the complexity of the reﬂected logic of proofs. The-
oretical Computer Science, 357(1–3):136–142, 2006.
[Kuz00]
Roman Kuznets. On the complexity of explicit modal logics. In Peter Clote
and Helmut Schwichtenberg, editors, CSL 2000, volume 1862 of Lecture
Notes in Computer Science, pages 371–383. Springer, 2000.
[Lam68]
Joachim Lambek. Deductive systems and categories I. Syntactic calculus and
residuated categories. Mathematical Systems Theory, 2(4):287–318, 1968.
[Lam69]
Joachim Lambek. Deductive systems and categories II. Standard construc-
tions and closed categories. In Category Theory, Homology Theory and their
Applications I, volume 86 of Lecture Notes in Mathematics, pages 76–122.
Springer, 1969.
[Lam72]
Joachim Lambek. Deductive systems and categories III. Cartesian closed
categories, intuitionist propositional calculus, and combinatory logic.
In
Toposes, Algebraic Geometry and Logic, volume 274 of Lecture Notes in
Mathematics, pages 57–82. Springer, 1972.
[LS05]
Fran¸cois Lamarche and Lutz Straßburger. Naming proofs in classical propo-
sitional logic. In Pawel Urzyczyn, editor, TLCA 2005, volume 3461 of Lecture
Notes in Computer Science, pages 246–261. Springer, 2005.
[Mil07]
Robert Milnikel. Derivability in certain subsystems of the Logic of Proofs is
Πp
2-complete. Annals of Pure and Applied Logic, 145(3):223–239, 2007.
[Mkr97]
Alexey Mkrtychev. Models for the Logic of Proofs. In Sergei I. Adian and
Anil Nerode, editors, LFCS 1997, volume 1234 of Lecture Notes in Computer
Science, pages 266–275. Springer, 1997.
[Nou06]
Karim Nour. Classical combinatory logic. In Ren´e David, Dani`ele Gardy,
Pierre Lescanne, and Marek Zaionc, editors, Computational Logic and Ap-
plications 2005, pages 87–96. DMTCS proc. AF, 2006.
[Pra71]
Dag Prawitz. Ideas and results in proof theory. In J. E. Fenstad, editor,
Proceedings of the 2nd Scandinavian Logic Symposium, volume 63 of Studies
in Logic and the Foundations of Mathematics, pages 235–307. North-Holland,
1971.
[Ren04]
Bryan Renne.
Tableaux for the Logic of Proofs.
Technical Report TR–
2004001, CUNY Ph.D. Program in Computer Science, 2004.
[Str05]
Lutz Straßburger. What is a logic, and what is a proof? In Jean-Yves Beziau,
editor, Logica Universalis, pages 135–145. Birk¨auser, 2005.
[TW02]
Ruediger Thiele and Larry Wos. Hilbert’s twenty-fourth problem. Journal
of Automated Reasoning, 29(1):67–89, 2002.

On the Constructive Dedekind Reals:
Extended Abstract
Robert S. Lubarsky1 and Michael Rathjen2,⋆
1 Department of Mathematical Sciences, Florida Atlantic University
rlubarsk@fau.edu
2 Department of Pure Mathematics, University of Leeds
rathjen@math.ohio-state.edu
Abstract. In order to built the collection of Cauchy reals as a set in
constructive set theory, the only Power Set-like principle needed is Ex-
ponentiation. In contrast, the proof that the Dedekind reals form a set
has seemed to require more than that. The main purpose here is to show
that Exponentiation alone does not suﬃce for the latter, by furnishing
a Kripke model of constructive set theory, CZF with Subset Collection
replaced by Exponentiation, in which the Cauchy reals form a set while
the Dedekind reals constitute a proper class.
1
Introduction
In classical mathematics, one principal approach to deﬁning the real numbers
is to use equivalence classes of Cauchy sequences of rational numbers, and the
other is the method of Dedekind cuts wherein reals appear as subsets of Q
with special properties. Classically the two methods are equivalent in that the
resulting ﬁeld structures are easily shown to be isomorphic. As often happens in
an intuitionistic setting, classically equivalent notions fork. Dedekind reals give
rise to several demonstrably diﬀerent collections of reals when only intuitionistic
logic is assumed (cf. [17], Ch.5, Sect.5). Here we shall be concerned with the
most common and fruitful notion of Dedekind real which crucially involves the
(classically superﬂuous) condition of locatedness of cuts. These Dedekind reals
are sometimes referred to as the constructive Dedekind reals but we shall simply
address them as the Dedekind reals. Even in intuitionistic set theory, with a
little bit of help from the countable axiom of choice (AC(N, 2)1 suﬃces; see [4],
8.25), Rd and Rc are isomorphic (where Rd and Rc denote the collections of
Dedekind reals and Cauchy reals, respectively). As Rc is canonically embedded
in Rd we can view Rc as a subset of Rd so that the latter result can be stated as
Rd = Rc. The countable axiom of choice is accepted in Bishop-style constructive
mathematics but cannot be assumed in all intuitionistic contexts. Some choice
is necessary for equating Rd and Rc as there are sheaf models of higher order
intuitionistic logic in which Rd is not isomorphic to Rc (cf. [6]). This paper will
⋆This material is based upon work supported by the National Science Foundation
under Award No. DMS-0301162.
1 ∀r ⊆N × 2[∀n ∈N ∃i ∈{0, 1} ⟨n, i⟩∈r →∃f : N →2 ∀n ∈N ⟨n, f(n)⟩∈r].
S. Artemov and A. Nerode (Eds.): LFCS 2007, LNCS 4514, pp. 349–362, 2007.
c
⃝Springer-Verlag Berlin Heidelberg 2007

350
R.S. Lubarsky and M. Rathjen
show that the diﬀerence between Rd and Rc can be of a grander scale. When is
the continuum a set? The standard, classical construction of R as a set uses Power
Set. Constructively, the weaker principle of Subset Collection (in the context of
the axioms of Constructive Zermelo-Fraenkel Set Theory CZF) suﬃces, as does
even the apparently even weaker principle of Binary Reﬁnement [5]. In contrast,
we shall demonstrate that there is a Kripke model of CZF with Exponentiation
in lieu of Subset Collection in which the Cauchy reals form a set while the
Dedekind reals constitute a proper class. This shows that Exponentiation and
Subset Collection Axiom have markedly diﬀerent consequences for the theory of
Dedekind reals.
This paper proves the following theorems:
Theorem 1. (Fourman-Hyland [6]) IZFRef does not prove that the Dedekind
reals equal the Cauchy reals.
Theorem 2. CZFExp (i.e. CZF with Subset Collection replaced by Exponenti-
ation) does not prove that the Dedekind reals are a set.
Even though the proof of the ﬁrst theorem given here has the ﬂavor of the
original Fourman-Hyland proof of the same, it is still included because it is not
obvious (to us at least) how their sheaf proof could be converted to the current
Kripke model construction, which might therefore be of independent interest.
In addition, it is helpful as background to understand the construction of the
second proof, which we do not know how to convert to a purely topological or
sheaf-theoretic argument.
The paper is organized as follows. After a brief review of Constructive Zermelo-
Fraenkel Set Theory and notions of real numbers, section 2 features a Kripke
model of IZFRef in which Rd ̸= Rc. Here IZFRef denotes Intuitionistic Zermelo-
Fraenkel Set Theory with the Reﬂection schema.2
In section 3 the model of section 2 undergoes reﬁnements and pivotally tech-
niques of [8] are put to use to engender a model of CZFExp in which Rd is a
proper class.
1.1
Constructive Zermelo-Fraenkel Set Theory
In this subsection we will summarize the axioms for CZF. For more detail, see
[1], [2], [3], or [4]. Among the non-logical axioms of CZF are Extensionality,
Pairing and Union in their usual forms. CZF has additionally axiom schemata
which we will now proceed to summarize.
Inﬁnity: ∃x∀u

u ∈x ↔

∅= u ∨∃v ∈x u = v + 1

where v + 1 = v ∪{v}.
Set Induction: ∀x[∀y ∈xφ(y) →φ(x)] →∀xφ(x)
Bounded Separation:
∀a∃b∀x[x ∈b ↔x ∈a ∧φ(x)]
2 Reﬂection, Collection and Replacement are equivalent in classical set theory. In-
tuitionistically, Reﬂection implies Collection which in turn implies Replacement,
however, these implications cannot be reversed (see [7] for the latter).

On the Constructive Dedekind Reals: Extended Abstract
351
for all bounded formulae φ. A set-theoretic formula is bounded or restricted if it
is constructed from prime formulae using ¬, ∧, ∨, →, ∀x ∈y and ∃x ∈y only.
Strong Collection: For all formulae φ,
∀a

∀x ∈a∃yφ(x, y) →∃b [∀x ∈a ∃y ∈b φ(x, y) ∧∀y ∈b ∃x ∈a φ(x, y)]

.
Subset Collection: For all formulae ψ,
∀a∀b∃c∀u

∀x ∈a ∃y ∈b ψ(x, y, u) →
∃d ∈c [∀x ∈a ∃y ∈d ψ(x, y, u) ∧∀y ∈d ∃x ∈a ψ(x, y, u)]

.
An additional axiom we shall consider is:
Exponentiation: ∀x∀y∃z z = xy.
Proposition 1. CZF ⊢Exponentiation.
Proof. [1], Proposition 2.2.
⊓⊔
1.2
The Cauchy and Dedekind Reals
Deﬁnition 1. A fundamental sequence is a sequence (rn)n∈N of rationals, to-
gether with is a (Cauchy-)modulus f : N →N such that
∀k ∀mn ≥f(k) |rm −rn| < 1
2k ,
where all quantiﬁers range over N.
Two fundamental sequences (rn)n∈N, (sn)n∈N are said to coincide (in symbols
≈) if
∀k∃n∀m ≥n |rm −sm| < 1
2k .
≈is indeed an equivalence relation on fundamental sequences. The set of Cauchy
reals Rc consists of the equivalence classes of fundamental sequences relative to
≈. For the equivalence class of (rn)n∈N we use the notation (rn)n∈N/ ≈.
The development of the theory of Cauchy reals in [17], Ch.5, Sect.2-4 can be
carried out on the basis of CZFExp. Note that the axiom AC-NN! 3 is deducible
in CZFExp.
Deﬁnition 2. Let S ⊆Q. S is called a left cut or Dedekind real if the following
conditions are satisﬁed:
1. ∃r(r ∈S) ∧∃r′(r′ /∈S) (boundedness)
2. ∀r ∈S ∃r′ ∈S (r < r′) (openness)
3. ∀rs ∈Q [r < s →r ∈S ∨s /∈S] (locatedness)
Rd is the set of Dedekind reals.
Lemma 1. Rc is a subﬁeld of Rd.
Proof: Exercise or see [4], Section 8.4.
⊓⊔
3 (∀m ∈N ∃!n ∈N φ(m, n)) →(∃f : N →N ∀m ∈N φ(m, f(m))).

352
R.S. Lubarsky and M. Rathjen
2
Rd ̸= Rc
Theorem 3. (Fourman-Hyland [6]) IZFRef does not prove that the Dedekind
reals equal the Cauchy reals.
2.1
Construction of the Model
Let M0 ≺M1 ≺... be an ω-sequence of models of ZF set theory and of elementary
embeddings among them, as indicated, such that the sequence from Mn on is
deﬁnable in Mn, and such that each thinks that the next has non-standard
integers. Notice that this is easy to deﬁne (mod getting a model of ZF in the
ﬁrst place): an iterated ultrapower using any non-principal ultraﬁlter on ω will
do. The reader is invited to think of each model as being countable, in case that
makes it easier to think about. We will ambiguously use the symbol f to stand
for any of the elementary embeddings inherent in the Mn-sequence.
Deﬁnition 3. The underlying partial order of the various Kripke models M will
be a rooted tree with ω-many levels; the bottom node (level 0) will be notated by
⊥, and the branching at a node of level n will be of size continuum in the sense
of Mn+1. (For those thinking of each model as being countable, this makes the
p.o. ω<ω, that is, the countably branching tree.)
Deﬁnition 4. The ground Kripke model has, at each node of level n, a copy of
Mn. The transition functions (from a node to a following node) are the elemen-
tary embeddings given with the original sequence of models (and therefore will be
notated by f again).
Note that by the elementarity of the extensions, this Kripke model is a model
of classical ZF. More importantly, the model restricted to any node of level n is
deﬁnable in Mn, because the original M-sequence was so deﬁnable.
The ﬁnal model M will be an extension of the ground model that will be
described like a forcing extension. That is, M will consist of (equivalence classes
of) the terms from the ground model.
Deﬁnition 5. The terms are deﬁned at each node separately, inductively on the
ordinals in that model. At any stage α, a term of stage α is a set σ of the form
{⟨σi, Ji⟩| i ∈I}, where I is some index set, each σi is a term of stage < α, and
each Ji is an open subset of the real line.
As a condition, each open set J is saying “the real in question is in me”. For
each node of level n there will be an associated real r (in the sense of Mn) such
that at that node the true J’s will be those containing r. The assignment of the
r’s will happen shortly, when the motivation should be clear.
Note in any case that all sets from the ground model have canonical names,
by choosing each Ji to be the whole real line, hereditarily.
Notice also that the deﬁnition of the terms given above will be interpreted
diﬀerently at each node of the ground Kripke model, as the reals change from

On the Constructive Dedekind Reals: Extended Abstract
353
node to node. However, any term at a node gets sent by the transition function
f to a corresponding term at any given later node. The deﬁnitions given later,
such as the forcing relation ⊩, are all interpretable in each Mn, and coherently
so, via the elementary embeddings.
To make this precise, we need to deﬁne the primitive relations at each node,
=M and ∈M (the subscript being used to prevent confusion with equality and
membership of the ambient models Mn). This will be done via a forcing
relation ⊩.
Deﬁnition 6. J ⊩σ =M τ iﬀfor all ⟨σi, Ji⟩∈σ J ∩Ji ⊩σi ∈M τ and vice
versa
J ⊩σ ∈M τ iﬀfor all r ∈J there is a ⟨τi, Ji⟩∈τ and J′ ⊆J such that
r ∈J′ ∩Ji ⊩σ =M τi
(We will later extend this forcing relation to all formulas.)
Deﬁnition 7. At a node (with associated real r, as described below), for any
two terms σ and τ, σ =M τ iﬀ, for some J with r ∈J, J ⊩σ =M τ.
Also, σ ∈M τ iﬀfor some J with r ∈J, J ⊩σ ∈M τ.
Thus we have a ﬁrst-order structure at each node.
The transition functions are the same as before. That is, if σ is an object
at a node, then it’s a term, meaning in particular it’s a set in some Mn. Any
later node has for its universe the terms from some Mm, m ≥n. With f the
elementary embedding from Mn to Mm, f can also serve as the transition func-
tion between the given nodes. These transition functions satisfy the coherence
conditions necessary for a Kripke model.
To have a Kripke model, f must also respect =M and ∈M; in other words, f
must be an =M- and ∈M-homomorphism (i.e. σ =M τ →f(σ) =M f(τ), and
similarly for ∈M). In order for these to be true, we need an additional restriction
on the model. By way of motivation, one requirement is, intuitively speaking,
that the sets σ can’t shrink as we go to later nodes. That is, once σi gets into σ at
some node, it can’t be thrown out at a later node. σi gets into σ because r ∈Ji
(where ⟨σi, Ji⟩∈σ). So we need to guarantee that if r ∈J and r′ is associated
to any extending node then r′ ∈J for any open set J. This holds exactly when
r′ is inﬁnitesimally close to r. We henceforth take this as an additional condition
on the construction: once r is associated to a node, then any r′ associated to an
extending node must be inﬁnitesimally close to r. It will actually turn out to be
necessary to include all such r′ as immediate successors to r.
Deﬁnition 8. The association of reals to tree nodes: Associate 0 to the bottom
node. Inductively up the tree, at a node of level n labeled with some real r ∈Mn,
extend the labeling by bijecting r’s immediate successors in the tree with the set
of reals in Mn+1 inﬁnitesimally close to r.
Lemma 2. f is an =M and ∈M-homomorphism.
We can now conclude that we have a Kripke model.

354
R.S. Lubarsky and M. Rathjen
Lemma 3. This Kripke model satisﬁes the equality axioms:
1. ∀x x = x
2. ∀x, y x = y →y = x
3. ∀x, y, z x = y ∧y = z →x = z
4. ∀x, y, z x = y ∧x ∈z →y ∈z
5. ∀x, y, z x = y ∧z ∈x →z ∈y.
Proof. 1: It is easy to show with a simultaneous induction that, for all J and
σ, J ⊩σ =M σ, and, for all ⟨σi, Ji⟩∈σ, J ∩Ji ⊩σi ∈M σ.
2: Trivial because the deﬁnition of J ⊩σ =M τ is itself symmetric.
3: For this and the subsequent parts, we need some lemmas.
Lemma 4. If J’ ⊆J ⊩σ =M τ then J’ ⊩σ =M τ, and similarly for ∈M.
Lemma 5. If J ⊩ρ =M σ and J ⊩σ =M τ then J ⊩ρ =M τ.
These can be proven by an induction on terms. Returning to proving property
3, the hypothesis is that for some J and K containing r, J ⊩ρ =M σ and
K ⊩σ =M τ. By the ﬁrst lemma, J ∩K ⊩ρ =M σ, σ =M τ, and so by the
second, J ∩K ⊩ρ =M τ, which suﬃces.
4: Let J ⊩ρ =M σ and K ⊩ρ ∈M τ. We will show that J ∩K ⊩σ ∈M τ.
Let r ∈J ∩K. By hypothesis, let ⟨τi, Ji⟩∈τ, J′ ⊆K be such that r ∈J′ ∩Ji ⊩
ρ =M τi; WLOG J′ ⊆J. By the ﬁrst lemma, J′ ∩Ji ⊩ρ =M σ, and by the
second, J′ ∩Ji ⊩σ =M τi.
5: Similar, and left to the reader.
With this lemma in hand, we can now mod out by =M, so that the symbol
“=” is interpreted as actual set-theoretic equality. We will henceforth drop the
subscript M from = and ∈, although we will not distinguish notationally between
a term σ and the model element it represents, σ’s equivalence class.
By way of notation, a node will be named by its associated real. Hence “r |= φ”
means φ holds at the node with real r. Strictly speaking there is an ambiguity
here, as each node with real r has a successor node with real r. However, by
elementarity, anything we can express in set theory true at one node will be true
at the other, so this should lead to no confusion.
Note that, at any node of level n, the choice of r’s from that node on is
deﬁnable in Mn. This means that the evaluation of terms (at and beyond the
given node) can be carried out over Mn, and so the Kripke model (from the
given node on) can be deﬁned over Mn, truth predicate and all.
2.2
The Forcing Relation
Which J’s count as true determines the interpretation of all terms, and hence of
truth in the end model. We need to get a handle on this. As with forcing, we need
a relation J ⊩φ, which holds at r iﬀr |= φ. Note that, by elementarity, it doesn’t
matter in which classical model Mn or at what node in the ground Kripke model
⊩is being interpreted (as long as the parameters are in the interpreting model,
of course).

On the Constructive Dedekind Reals: Extended Abstract
355
Deﬁnition 9. J ⊩φ is deﬁned inductively on φ:
J ⊩σ = τ and J ⊩σ ∈τ are as above
J ⊩φ ∧ψ iﬀJ ⊩φ and J ⊩ψ
J ⊩φ ∨ψ iﬀfor all r ∈J there is a J’ containing r such that J’ ⊩φ or J’
⊩ψ
J ⊩φ →ψ iﬀfor all J’ ⊆J if J’ ⊩φ then J’ ⊩ψ
J ⊩∃x φ(x) iﬀfor all r ∈J there is a J’ containing r and a σ such that
J ∩J′ ⊩φ(σ)
J ⊩∀x φ(x) iﬀfor all r ∈J and σ there is a J’ containing r such that
J ∩J′ ⊩φ(σ)
Lemma 6.
1. For all φ ∅⊩φ.
2. If J’ ⊆J ⊩φ then J’ ⊩φ.
3. If Ji ⊩φ for all i then 
i Ji ⊩φ.
4. J ⊩φ iﬀfor all r ∈J there is a J’ containing r such that J ∩J’ ⊩φ.
5. Truth Lemma: For any node r, r |= φ iﬀJ ⊩φ for some J containing r.
Proof. Each part either is by induction or follows trivially from an earlier part.
2.3
The Final Proof
Theorem 4. This Kripke model satisﬁes IZFRef.
Proof. Inﬁnity, Pairing, and Union are easy.
– Extensionality: We need to show that ∀x ∀y [∀z (z ∈x ↔z ∈y) →x = y].
So let σ and τ be any terms at a node r such that r |= “∀z (z ∈σ ↔z ∈τ)”.
We must show that r |= “σ = τ”. By the Truth Lemma, let r ∈J ⊩“∀z (z ∈
σ ↔z ∈τ)”; i.e. for all r′ ∈J, ρ there is a J′ containing r′ such that
J ∩J′ ⊩ρ ∈σ ↔ρ ∈τ. We claim that J ⊩“σ = τ”, which again by the
Truth Lemma suﬃces. To this end, let ⟨σi, Ji⟩be in σ; we need to show that
J ∩Ji ⊩σi ∈τ. Let r′ be an arbitrary member of J ∩Ji and ρ be σi. By
the choice of J, let J′ containing r′ be such that J ∩J′ ⊩σi ∈σ ↔σi ∈τ;
in particular, J ∩J′ ⊩σi ∈σ →σi ∈τ. It has already been observed in 3,
part 1, that J ∩J′ ∩Ji ⊩σi ∈σ, so J ∩J′ ∩Ji ⊩σi ∈τ. By going through
each r′ in J ∩Ji and using 6, part 3, we can conclude that J ∩Ji ⊩σi ∈τ,
as desired. The other direction (“τ ⊆σ”) is analogous.
– Set Induction (Schema): Suppose r |= “∀x ((∀y ∈x φ(y)) →φ(x))”; by
the Truth Lemma, let J containing r force as much. We must show r |=
“∀x φ(x)”. Suppose not. Using the deﬁnition of satisfaction in Kripke models,
there is an r′ extending (i.e. inﬁnitesimally close to) r (hence in J) and a
σ such that r′ ̸|= φ(σ). By elementarity, there is such an r′ in Mn, where
n is the level of r. Let σ be such a term of minimal V-rank among all r′s
∈J. Fix such an r′. By the Truth Lemma (and the choice of J), r′ |= “(∀y ∈
σ φ(y)) →φ(σ)”. We claim that r′ |= “∀y ∈σ φ(y)”. If not, then for some r′′
extending r′ (hence in J) and τ, r′′ |= τ ∈σ and r′′ ̸|= φ(τ). Unraveling the
interpretation of ∈, this choice of τ can be substituted by a term τ of lower

356
R.S. Lubarsky and M. Rathjen
V-rank than σ. By elementarity, such a τ would exist in Mn, in violation of
the choice of σ, which proves the claim. Hence r′ |= φ(σ), again violating the
choice of σ. This contradiction shows that r |= “∀x φ(x)”.
– Separation (Schema): Let φ(x) be a formula and σ a term. Then {⟨σi, J∩Ji⟩|
⟨σi, Ji⟩∈σ and J ⊩φ(σi)} will do.
– Power Set: A term ˆσ is a canonical subset of σ if for all ⟨σi, ˆJi⟩∈ˆσ there is
a Ji ⊇ˆJi such that ⟨σi, Ji⟩∈σ. {⟨ˆσ, R⟩| ˆσ is a canonical subset of σ} is a
set (in Mn), and will do.
– Reﬂection (Schema): Recall that the statement of Reﬂection is that for every
formula φ(x) (with free variable x and unmentioned parameters) and set z
there is a transitive set Z containing z such that Z reﬂects the truth of φ(x)
in V for all x ∈Z. So to this end, let φ(x) be a formula and σ be a set at
a node r of level n (in the tree which is this Kripke model’s partial order).
Let k be such that the truth of φ(x) at node r and beyond is Σk deﬁnable
in Mn. In Mn, let X be a set containing σ, r, and φ’s parameters such that
X ≺k Mn. Let τ be {⟨ρ, R⟩| ρ ∈X is a term}. τ will do.
We are interested in the canonical term {⟨r, J⟩| r is a rational, J is an open
interval from the reals, and r < J}, where r < J if r is less than each element
of J. We will call this term X. Note that at node r (of level n), every standard
(in the sense of Mn) real less than r gets into X, and no standard real greater
than r will ever get into X. Of course, non-standard reals inﬁnitesimally close
to r are still up for grabs.
Proposition 2. ⊥|= “X is a constructive Dedekind real”.
Proof. First oﬀ, ⊥|= “ −1 ∈X ∧1 ̸∈X”. Secondly, if r |= “s < t ∈X”, then
⟨t, J⟩∈X, where t < J and r ∈J. Hence s < J, so ⟨s, J⟩∈X, and r |= s ∈X.
Finally, suppose r |= “s, t ∈Q ∧s < t”. Either s < r or r < t. Since s and t
are both standard (in the sense of Mn, n the level of r), either r |= s ∈X or
r |= t ̸∈X respectively.
Proposition 3. ⊥|= “The Dedekind real X is not a Cauchy real.”
Proof. Recall that a Cauchy real is a Dedekind real Y for which there are two
functions, f0 and f1, with domain N, such that f0 is a sequence of rationals and
f1 is a modulus of convergence (i.e. for n, m > f1(k), f0(n) and f0(m) are within
2−k of each other), and r ∈Y iﬀr < f0(f1(k)) −2−k for some k.
For notational ease we will restrict attention to what happens at node ⊥. The
argument carries over mutatis mutandis to all other nodes.
Suppose ⊥|= “f0 and f1 witness that X is a Cauchy real”. By the Truth
Lemma, there is an open set J containing 0 forcing the same. There are two
cases.
CASE I: There is some open set J′ containing 0 forcing a value f0(n) for
each (standard) integer n. In this case, f0 is a ground model function; that
is, in M0, hence in each Mn, g(n) can be deﬁned as the unique m such that
J′ ⊩f0(n) = m, and then f0 is the internalization of g. Since classical logic

On the Constructive Dedekind Reals: Extended Abstract
357
holds in the ground model, either f0 is bounded away from 0, say by 2−k, or
it’s not. If it is, then for a contradiction f0 can’t witness that X is a Cauchy
real. For indices n past f1(k), either f0(n) < −2−k for all such n or f0(n) > 2−k
for all such n. In the former case, f0 will never put −2−k itself into X, even
though ⊥|= −2−k ∈X; in the latter, f0(f1(k + 1)) would put 2−(k+1) into X,
even though ⊥|= 2−(k+1) ̸∈X. If on the other hand f0 is not bounded away
from 0, then the condition “r < f0(f1(k)) −2−k for some k” becomes simply
“r < 0”. So then f0, f1 would witness that r ∈X iﬀr < 0. But this is false: if
r is an inﬁnitesimal less than 0, then r |= r < 0 but r ̸|= r ∈X, and if r is an
inﬁnitesimal greater than 0, then r |= r/2 > 0 but r |= r/2 ∈X.
CASE II: Not case I. That means that for any interval J′ around 0, however
small, there is some argument n to f0 such that J′ does not force any value f0(n).
By elementarity, in M1 pick J′ to be some inﬁnitesimally small neighborhood
around 0, and n such an argument. Pick some value q that f0(n) could have and
the maximal (hence non-empty, proper, and open) subset of J′ forcing f0(n) = q.
Pick the maximal (hence non-empty, proper, and open) subset of J′ forcing
f0(n) ̸= q. These two subsets must be disjoint, lest the intersection force a
contradiction. But an open interval cannot be covered by two disjoint, non-
empty open sets. Hence there is an inﬁnitesimal r in neither of those two subsets.
Now consider the Kripke model at node r. f0(n) is undeﬁned at r. Otherwise,
by the Truth Lemma, there would be some interval J containing r such that
J ⊩f(n) = p for some particular rational p. Whether or not p = q would force
r into one of the subsets or the other. Therefore, the node ⊥cannot force that
f0 is total, and so f0 does not witness that X is a Cauchy real.
3
The Dedekind Reals Are Not a Set
Theorem 5. CZFExp (i.e. CZF with Subset Collection replaced by Exponenti-
ation) does not prove that the Dedekind reals form a set.
3.1
The Construction
Any model showing what is claimed must have certain properties. For one,
the Dedekind reals cannot equal the Cauchy reals (since CZFExp proves that
the Cauchy reals are a set). Hence the current model takes its inspiration from
the previous one. Also, it must falsify Subset Collection (since CZF proves that
the Dedekind reals are a set). Hence guidance is also taken from [8], where such
a model is built.
The idea behind the latter is that a relation keeps on being introduced into
the model but at a later node disappears. Since this relation is chosen so that it
doesn’t help build any functions, it can be ignored when proving Exponentiation.
On the other hand, while you’re free to include this relation in an alleged full
set of relations, that relation that you choose is gone by the next node, so when
it reappears later your attempt at a full set no longer works.
In the present context, we will do something similar. The troublesome relation
will be (essentially) the Dedekind real X from the previous construction. It will

358
R.S. Lubarsky and M. Rathjen
“disappear” in that, instead of continuing to change its mind about what it is at
all future nodes, it will settle down to one ﬁxed, standard real at all next nodes.
But then some other real just like X will appear and pull the same stunt.
We now begin with the deﬁnition of the Kripke model, which ultimately is
distributed among the next several deﬁnitions.
Deﬁnition 10. The underlying p.o. of the Kripke model is the same as above: a
tree with height ω and continuum-in-the-sense-of-M0 many nodes at each level.
There is a bijection between the nodes of height n and the reals of Mn. A node
will be identiﬁed with its corresponding real. s of height n+1 is an immediate
successor of r of height n iﬀs is inﬁnitesimally close to r.
Deﬁnition 11. A term at a node of height n is a set of the form {⟨σi, Ji⟩| i ∈
I} ∪{⟨σh, rh⟩| h ∈H}, where each σ is (inductively) a term, each J an open set
of reals, each r a real, and H and I index sets, all in the sense of Mn.
The ﬁrst part of each term is as in the ﬁrst theorem: at node r, Ji counts as true
iﬀr ∈Ji. The second part plays a role only when we decide to have the term
settle down and stop changing. This settling down in described as follows.
Deﬁnition 12. For a term σ and real r ∈Mn, σr is deﬁned inductively in Mn
on the terms as {⟨σr
i , R⟩| ⟨σi, Ji⟩∈σ ∧r ∈Ji} ∪{⟨σr
h, R⟩| ⟨σh, r⟩∈σ}.
Note that σr is a canonical term, meaning that it’s the canonical image of a set
from the ambient universe. It bears observation that (σr)s = σr.
What determines when a term settles down in this way is the transition func-
tion. In fact, from any node to an immediate successor, there will be two tran-
sition functions, one the embedding f as before and the other the settling down
function. This fact of the the current construction does not quite jive with the
standard deﬁnition of a Kripke model, which has no room for alternate ways to
go from one node to another. However, this move is standard (even tame) for
categorical models, which allow for arbitrary arrows among objects. So while
the standard categorical description of a partial order is a category where the
objects are the elements of the order and there’s an arrow from p to q iﬀp ≤q,
the category we’re working in has two arrows from p to q (for immediate succes-
sors). If you’re still uncomfortable with this double arrow, or object to calling
this object a Kripke model, then double not the arrows but the nodes. That is,
replace each node s by two nodes sold and snew, and have the two arrows go to
these two separate nodes. Now you have a very traditional Kripke model again.
To save on subscripts, we will work instead with two arrows going from r to s.
Deﬁnition 13. If s is an immediate successor of r, then there are two transition
functions from r to s, called f and g. f is the elementary embedding from Mn to
Mn+1 as applied to terms. g(σ) = f(σ)s. Transition functions to non-immediate
successors are arbitrary compositions of the immediate transition functions.
When considering g(σ), note that σ ∈Mn and s ∈Mn+1. However, for purposes
other than the transition functions, we will have occasion to look at σs for

On the Constructive Dedekind Reals: Extended Abstract
359
both σ and s from Mn. In this case, please note that, since f is an elementary
embedding, (f(σ))s = f(σs).
It’s easy to see that for σ canonical f(σ) is also canonical, and for τ canonical
(such as f(σ)) so is τr. Hence in this case f(σ) = g(σ).
We do not need to show that the transition functions are well-deﬁned, since
they are deﬁned on terms and not on equivalence classes of terms. However, once
we deﬁne =, we will show that = is an equivalence relation and that f and g
respect =, so that we can mod out by = and still consider f and g as acting on
these equivalence classes.
Deﬁnition 14. J ⊩σ =M τ iﬀfor all ⟨σi, Ji⟩∈σ J ∩Ji ⊩σi ∈M τ and for all
r ∈J σr = τr, and vice versa.
J ⊩σ ∈M τ iﬀfor all r ∈J there is a ⟨τi, Ji⟩∈τ and J’ ⊆J such that r
∈J′ ∩Ji ⊩σ =M τi, and for all r ∈J ⟨σr, R⟩∈τr.
Deﬁnition 15. At a node r, for any two terms σ and τ, r |= σ =M τ iﬀ, for
some J with r ∈J, J ⊩σ =M τ.
Also, r |= σ ∈M τ iﬀfor some J with r ∈J, J ⊩σ ∈M τ.
Thus we have a ﬁrst-order structure at each node.
Corollary 1. The model just deﬁned is a Kripke model. That is, the transition
functions are =M and ∈M-homomorphisms.
Lemma 7. This Kripke model satisﬁes the ﬁve equality axioms (as in lemma 3).
With this lemma in hand, we can now mod out by =M at each node, and have
a model in which equality is actually =.
3.2
The Forcing Relation
In the ﬁrst proof, it didn’t matter where ⊩was interpreted, whether in the Kripke
model or at any Mn, by elementarity. Here, in contrast, the transition functions
are not the elementary embeddings. So we must be more careful about where
the deﬁnition of ⊩takes place. There are two, essentially equivalent, choices.
We could work in the Kripke term model, where the terms are uninterpreted;
the condition J would mean “the cut will happen somewhere in me, and at all
future nodes the cut will be at a ﬁxed real also somewhere in me”. The choice
we will pursue is to work in the classical models Mn.
So pick a formula with parameters from Mn, and work in Mn. (One could
point out that, if the parameters are from Mn, then they are also from Mn′, for
all n′ > n, and then ask if there is any ambiguity where the following deﬁnition
takes place. If one did, the answer would be “no, by elementarity.”)
Deﬁnition 16. For φ = φ(σ0, ..., σi) a formula with parameters σ0, ..., σi, φr is
φ(σr
0, ..., σr
i ).

360
R.S. Lubarsky and M. Rathjen
Deﬁnition 17. J ⊩φ is deﬁned inductively on φ:
J ⊩σ = τ and J ⊩σ ∈τ are as above
J ⊩φ ∧ψ iﬀJ ⊩φ and J ⊩ψ
J ⊩φ ∨ψ iﬀfor all r ∈J then there is a J’ ⊆J containing r such that J’ ⊩φ
or J’ ⊩ψ
J ⊩φ →ψ iﬀfor all J’ ⊆J if J’ ⊩φ then J’ ⊩ψ, and, for all r ∈J, if R
⊩φr then R ⊩ψr
J ⊩∃x φ(x) iﬀfor all r ∈J there is a J’ containing r and a σ such that
J ∩J′ ⊩φ(σ)
J ⊩∀x φ(x) iﬀfor all r ∈J and σ there is a J’ containing r such that
J ∩J′ ⊩φ(σ), and for all r ∈J and σ there is a J’ containing r such that J’
⊩φr(σ).
(Notice that in the last clause, σ is not interpreted as σr.)
Lemma 8.
1. For all φ ∅⊩φ.
2. If J’ ⊆J ⊩φ then J’ ⊩φ.
3. If Ji ⊩φ for all i then 
i Ji ⊩φ.
4. J ⊩φ iﬀfor all r ∈J there is a J’ containing r such that J ∩J’ ⊩φ.
5. For all φ, J if J ⊩φ then for all r ∈J R ⊩φr.
6. Truth Lemma: For any node r, r |= φ iﬀJ ⊩φ for some J containing r.
Proof. Induction.
3.3
The Final Proof
Theorem 6. ⊥|= CZFExp
Proof. Inﬁnity, Pair, and Union are as in the previous section. Extensionality
and Set Induction are too, with appropriate minor changes.
– Exponentiation: Let σ and τ be terms at node r. In what follows, we will
identify sets (in an Mn) with their canonical terms. Let C be {⟨ρ, J⟩| J ⊩
ρ : σ →τ is a function} ∪{⟨h, s⟩| h : σs →τ s is a function}. We claim that
C suﬃces.
Let s be any immediate extension of r. (The case of non-immediate ex-
tensions follows directly from this case.) If s |= “ρ : f(σ) →f(τ) is a
function”, then s |= ρ ∈C by the ﬁrst clause in the deﬁnition of C. If
s |= “ρ : g(σ) →g(τ) is a function” and ρ is canonical, then s |= ρ ∈C by
the second clause. What we must show is that for any node r and sets X
and Y , if r |= “ρ : X →Y is a function”, then ρ is canonical.
By the Truth Lemma, let r ∈J ⊩“ρ : X →Y is a function”. We claim
that for all x ∈X there is a y ∈Y such that for each s ∈J s |= ρ(x) = y. If
not, let x be otherwise. Let y be such that r |= ρ(x) = y. For each immediate
successor s of r, s |= f(ρ)(f(x)) = f(y). By overspill the same holds for some
neighborhood around r (sans the f’s). If this does not hold for all s ∈J, let
s be an endpoint in J of the largest interval around r for which this does

On the Constructive Dedekind Reals: Extended Abstract
361
hold. Repeating the same argument around s, there is a y′ such that, for all
t in some neighborhood of s, t |= ρ(x) = y′. This neighborhood of s must
overlap that of r, though. So y = y′, contradicting the choice of s. So the
value ρ(x) is ﬁxed on the whole interval J, and ρ is forced by J to equal a
particular canonical function.
– Separation: Although CZF contains only Δ0 Separation, full Separation
holds here. Let φ(x) be a formula and σ a term. Then, again identifying
sets (in Mn) with their canonical terms, {⟨σi, J ∩Ji⟩| ⟨σi, Ji⟩∈σ and
J ⊩φ(σi)} ∪{⟨x, s⟩| x ∈σs and R ⊩φs(x)} will do.
– Strong Collection: If r |= ∀x ∈σ ∃y φ(x, y), let r ∈J force as much. For each
⟨σi, Ji⟩∈σ and s ∈J ∩Ji, let τi,s and Ji,s be such that s ∈Ji,s ⊩φ(σi, τi,s).
Also, for each s ∈J and x ∈σs, let τx,s be such that R ⊩φs(x, τx,s). Then
{⟨τi,s, Ji,s⟩| i ∈I, s ∈J} ∪{⟨τx,s, s⟩| s ∈J, x ∈σs} suﬃces.
Theorem 7. ⊥|= The Dedekind reals do not form a set.
Proof. Let σ be a term. At some future node s, g(σ) is a canonical term, meaning
it names a set from the ambient model. But the prototypical set from the ﬁrst
proof, {⟨r, J⟩| r is a rational, J is an open interval from the reals, and r < J},
at node s is a Dedekind real which is not from the ground model, and so is not
in g(σ). So σ cannot name the set of Dedekind reals.
References
1. P. Aczel, The type theoretic interpretation of constructive set theory, in A. Mac-
Intypre, L. Pacholski, and J. Paris (eds.), Logic Colloquium ’77 (North-Holland,
Amsterdam, 1978), p. 55-66
2. P. Aczel, The type theoretic interpretation of constructive set theory: choice prin-
ciples, in A.S. Troelstra and D. van Dalen (eds.), The L.E.J. Brouwer Centenary
Symposium (North-Holland, Amsterdam, 1982), p. 1-40
3. P. Aczel, The type theoretic interpretation of constructive set theory: inductive
deﬁnitions, in R.B. Marcus et al. (eds.), Logic, Methodology and Philosophy of
Science VII (North-Holland, Amsterdam, 1986), p. 17-49
4. P. Aczel and M. Rathjen, Notes on constructive set theory, Technical Report 40,
2000/2001, Mittag-Leﬄer Institute, Sweden, 2001.
5. L. Crosilla, H. Ishihara, and P. Schuster, On constructing completions, The Jour-
nam of Symbolic Logic, 2005, v. 70, p. 969-978
6. M.P. Fourman and J.M.E. Hyland, Sheaf models for analysis, in: M.P. Fourman,
C.J. Mulvey and D.S. Scott (eds.), Applications of sheaves (Springer, Berlin, 1979),
p. 280-301.
7. H. Friedman and A. Scedrov, The lack of deﬁnable witnesses and provably recursive
functions in intuitionistic set theories, Advances in Math, 1985, p. 1-13
8. R. Lubarsky, Independence results around Constructive ZF, Annals of Pure and
Applied Logic, 2005, v. 132, p. 209-225
9. R. Lubarsky, CZF + full Separation is equivalent to second order arithmetic, An-
nals of Pure and Applied Logic, 2006, v. 141, pp. 29-34
10. P. Martin-L¨of, An intuitionistic theory of types: predicative part, in H.E. Rose and
J. Sheperdson (eds.), Logic Colloquium ’73 (North-Holland, Amsterdam, 1975), p.
73-118

362
R.S. Lubarsky and M. Rathjen
11. P. Martin-L¨of, Intuitionistic Type Theory (Bibliopolis, Naples, 1984)
12. J. Myhill, Constructive set theory, Journal of Symbolic Logic, 1975, p. 347-382
13. M. Rathjen, The strength of some Martin–L¨of type theories, Archive for Mathe-
matical Logic, 1994, p. 347-385
14. M. Rathjen, The higher inﬁnite in proof theory, in J.A. Makowsky and E.V. Ravve
(eds.), Logic Colloquium ’95, Springer Lecture Notes in Logic, Vol. 11 (Springer,
New York, Berlin, 1998), p. 275-304
15. A. Simpson, Constructive set theories and their category-theoretic models, in
L.Crosilla and P.Schuster, eds., From Sets and Types to Topology and Analysis
(Oxford Logic Guides, Oxford University Press, forthcoming)
16. T. Streicher, Realizability Models for IZF and CZF + ¬ Pow via the Aczel Con-
struction, personal communication
17. A.S. Troelstra and D. van Dalen, Constructivism in Mathematics, Volumes I, II
(North Holland, Amsterdam, 1988).

Verifying Balanced Trees
Zohar Manna1, Henny B. Sipma1, and Ting Zhang2
1 Stanford University
{zm,sipma}@cs.stanford.edu
2 Microsoft Research Asia
tingz@microsoft.com
Abstract. Balanced search trees provide guaranteed worst-case time
performance and hence they form a very important class of data struc-
tures. However, the self-balancing ability comes at a price; balanced trees
are more complex than their unbalanced counterparts both in terms of
data structure themselves and related manipulation operations. In this
paper we present a framework to model balanced trees in decidable ﬁrst-
order theories of term algebras with Presburger arithmetic. In this frame-
work, a theory of term algebras (i.e., a theory of ﬁnite trees) is extended
with Presburger arithmetic and with certain connecting functions that
map terms (trees) to integers. Our framework is ﬂexible in the sense
that we can obtain a variety of decidable theories by tuning the con-
necting functions. By adding maximal path and minimal path functions,
we obtain a theory of red-black trees in which the transition relation
of tree self-balancing (rotation) operations is expressible. We then show
how to reduce the veriﬁcation problem of the red-black tree algorithm
to constraint satisﬁability problems in the extended theory.
1
Introduction
Balanced search trees provide guaranteed worst-case time performance and hence
they form a very important class of data structures. Also they are the basis of
eﬃcient implementations of many advanced data structures such as associative
arrays and associative sets. However, the self-balancing ability comes at a cost;
balanced trees are more complex than their unbalanced counterparts both in
terms of data structure themselves and related manipulation operations. More-
over, as balanced trees are not regular trees, their properties cannot be directly
characterized by standard tree automata techniques [4].
In this paper we present a framework to model balanced trees in decidable
ﬁrst-order theories of term algebras with Presburger arithmetic [23]. In this
framework, a theory of term algebras (i.e., a theory of ﬁnite trees) is extended
with Presburger arithmetic and certain connecting functions that map terms
(trees) to integers. Given connecting functions and a ﬁxed signature of a term
1 The ﬁrst and the second author were supported in part by NSF grants CCR-01-
21403, CCR-02-20134, CCR-02-09237, CNS-0411363, and CCF-0430102, by ARO
grant DAAD19-01-1-0723, and by NAVY/ONR contract N00014-03-1-0939.
S. Artemov and A. Nerode (Eds.): LFCS 2007, LNCS 4514, pp. 363–378, 2007.
c
⃝Springer-Verlag Berlin Heidelberg 2007

364
Z. Manna, H.B. Sipma, and T. Zhang
algebra, the corresponding extended theory is two sorted with integer sort and
term sort. The language is the set-theoretic union of the language of term al-
gebras and the language of Presburger arithmetic augmented with connecting
functions from T to N. Formulae are formed from term literals and integer literals
using logical connectives and quantiﬁcations.
Our framework is ﬂexible in the sense that we can obtain a variety of decidable
theories by varying the connecting functions. By adding maximal path and min-
imal path functions, we obtain a theory of red-black trees in which the transition
relation of tree self-balancing (color exchange and rotation) operations are ex-
pressible. We then show how to reduce the veriﬁcation problem of the red-black
tree algorithm to a constraint satisﬁability problem in the extended theory.
Related Work and Comparison. There has been a considerably amount of work
in shape analysis, a kind of pointer analysis aimed at statically inferring proper-
ties on heap allocated data structures. Shape analysis tools can partially detect
pointer linkage properties such as sharing, aliasing, cyclicity and reachability.
The property of being a balanced tree, however, is a much higher-level property
that can not be inferred from pointed-to relations on heaps. Rugina presents a
method, called quantitative shape analysis, to verify rebalancing operations on
AVL trees [19]. Based on abstract interpretation, the method performs forward
propagation in an abstract heap where each location (node) is associated with
quantitative attributes and relations to characterize the balancing property.
Tree automata techniques are widely used in solving constraints on tree
languages [4]. However, balanced trees are not regular trees (by the pumping
lemma), and hence their corresponding tree languages cannot be directly char-
acterized by standard tree automata [4]. Habermehl et al. present extended tree
automata with size constraints on transition relations (TASC) [10]. TASCs are
able to represent pre- and post-conditions of a program involving tree rotation
operations. Hence, given the right invariants, the veriﬁcation of a program re-
duces to checking the validity of Hoare triples that state that after execution of
the program from the starting state satisfying the pre-condition, the resulting
reachable states are included in the states represented by the post-condition.
However, TASCs that encode transition relations of tree operations are fairly
complicated. The lack of intuitive connections between low level program state-
ments and the corresponding automata representations makes this formalism
unattractive for use in practical veriﬁcation tools.
Baldan et al. treat red-black trees as hypergraphs and tree update operations
as rewritings on hypergraphs [2]. They use approximate unfolding to compute
the reachable states of a graph rewriting system to prove the property that no red
node has a red parent. The balancing property itself, however, is not expressible
in graph rewriting grammar and an additional type system is introduced to prove
it. Calcagno et al. present a context logic to model trees with local updates, which
are destructive operations at pointed locations [3]. They present a deductive
proof system based on Hoare triples and prove soundness and completeness of

Verifying Balanced Trees
365
the proof system. The balancing property, however, is not expressible this formal
system and the veriﬁcation of Hoare triples is not fully automatic.
Like [10] we reduce the veriﬁcation problem to checking the validity of Hoare
triples. In our approach, however, the pre- and post-conditions and transition
relations are all represented directly by the ﬁrst-order formulas in the extended
theory of term algebras. Diﬀerent from [10,2,3], we do not have an update func-
tion in the theory and hence we can not express local updates at an arbitrary
pointed location. On the other hand, local updates only aﬀect subtrees around
the focus point, and hence our theory can still express and prove veriﬁcation
conditions of step-by-step tree operations. An informal but easy induction will
give us global safety properties.
The contributions of this paper are the following: (1) we develop a ﬁrst-order
theory of red-black trees, that is, a theory of term algebras augmented with Pres-
burger arithmetic; (2) we show how to use this theory to represent the transition
relations of the tree operations directly from the program statements, and how
to use them to construct Hoare triples; (3) we provide a decision procedure for
automatically checking validity of the resulting veriﬁcation conditions. To the
best of our knowledge, this is the ﬁrst decidable logic theory for red-black trees.
Moreover, it can be easily generalized to model other balanced tree structures,
such as AVL trees and B-trees.
Paper Organization Section 2 presents the notation and terminology for term
algebras. Section 3 introduces the theory of red-black trees and states its decid-
ability result. Section 4 shows how to use the theory to analyze the red-black
tree insertion algorithm. Section 5 concludes with a discussion of future work.
Because of space limitations all decidability proofs have been omitted. They are
available for reference on the third author’s web site.
2
Preliminaries
We assume the ﬁrst-order syntactic notions of variables, parameters and quanti-
ﬁers, and semantic notions of structures, satisﬁability and validity as in [9]. We
use x to denote the value given by an assignment and ¯x to denote a sequence
of variables.
Deﬁnition 1 (Term Algebras). A term algebra TA :
⟨T; C, A, S, T ⟩con-
sists of
1. T: The term domain, which exclusively consists of terms recursively built
up from constants by applying non-nullary constructors. Objects in T are
called TA-terms. The type of a term t, denoted by type(t), is the outer-
most constructor symbol of t. We say that t is α-typed (or is an α-term) if
type(t) = α.
2. C: A set of constructors: α, β, γ, . . . The arity of α is denoted by ar(α).
3. A: A set of constants: a, b, c, . . . We require A ̸= ∅and A ⊆C. For a ∈A,
ar(a) = 0 and type(a) = a.

366
Z. Manna, H.B. Sipma, and T. Zhang
4. S: A set of selectors. For a constructor α with arity k > 0, there are k
selectors sα
1 , . . . , sα
k in S. We call sα
i (1 ≤i ≤k) the ith α-selector. For a
term x, sα
i (x) returns the ith immediate subterm of x if x is an α-term and
x itself otherwise.
5. T : A set of testers. For each constructor α there is a corresponding tester Isα.
For a term x, Isα(x) is true if and only if x is an α-term. For a constant a,
Isa(x) is just x = a. In addition there is a special tester IsA such that IsA(x)
is true if and only if x is a constant.
We use LT to denote the language of term algebras.
Term domain T consists of only ground terms built from constructors. Selectors
only exist in the formal language. In fact selectors can be deﬁned by construc-
tors in the existential fragment of the language; for a quantiﬁer-free formula
Φ(¯x) containing selectors, we can obtain an equivalent and selector-free formula
∃¯y Φ′(¯x, ¯y) where Φ′(¯x, ¯y) is quantiﬁer-free and ¯y is fresh.
A term t is called a constructor term if t is a variable or the outermost function
symbol of t is a constructor. Constants are constructor terms. A term t is called
a selector term if either t is a variable or the outermost function symbol of t is
a selector. Variables are both constructor terms and selector terms. We assume
that no constructors appear immediately inside selectors as simpliﬁcation can
always be done. A term is called proper if it is not a constant or a variable.
The ﬁrst-order theory of term algebras was shown to be decidable by Mal’cev
using quantiﬁer elimination [15]. Decision procedures for the quantiﬁer-free the-
ory were discovered by Nelson, Oppen et al. [16,17,8]. Oppen gave a linear al-
gorithm for acyclic structures [17] and (with Nelson) a quadratic algorithm for
cyclic structures [16]. If the values of the selector functions on constants are
speciﬁed, then the problem is NP-complete [17].
Presburger arithmetic is the ﬁrst-order theory of addition in the arithmetic of
integers. The corresponding structure is denoted by PA = ⟨Z; 0, +, <⟩. We use
LZ to denote the formal language of PA. The ﬁrst-order theory of Presburger
arithmetic (PA) was ﬁrst shown to be decidable in 1929 by the quantiﬁer elim-
ination method [9]. More eﬃcient algorithms were later discovered by [6] and
further improved in [18].
There has been a great interest in generalizing Mal’cev’s result on term alge-
bras. Maher showed the decidability of the theory of inﬁnite and rational trees
[14]. Comon and Delor presented an elimination procedure for term algebras
with membership predicate in the regular tree language [5]. Backofen presented
an elimination procedure for structures of feature trees with arity constraints
[1]. Rybina and Voronkov showed the decidability of term algebras with queues
[20]. Kuncak and Rinard showed the decidability of term powers, which are term
algebras augmented with coordinate-wise deﬁned predicates [13]. A combination
of Presburger arithmetic and term algebras was used by Korovin and Voronkov
to show that the quantiﬁer-free theory of term algebras with Knuth-Bendix or-
der is NP-complete [11,12]. In [21,23] we presented decision procedures both for

Verifying Balanced Trees
367
the ﬁrst-order theory and the corresponding quantiﬁer-free fragments of term
algebras with integer functions. In [22] we extended the decidability result to
the ﬁrst-order theory of term algebras with Knuth-Bendix order.
3
The Theory of Red-Black Trees
In this section we present a theory of a term algebra with two integer functions
to express the properties of red-black trees.
Deﬁnition 2 (Red-black Trees [7]). A red-black tree is a binary tree with
the following coloring properties:
1. Every node is either red or black.
2. Every leaf node is black.
3. The root is black.
4. Every red node has two black children.
5. All paths from the root to leaf nodes contain the same number of black nodes.
Properties (1)-(3) can be modeled in a theory of term algebras as follows:
Deﬁnition 3 (Structure of Colored Trees). The structure of red-black col-
ored trees is
RB = ⟨Trb; {red, black, nil}, {nil},
{carred, cdrred, carblack, cdrblack}, {Isred, Isblack, Isnil} ⟩,
where Trb denotes the domain, nil denotes a leaf, red and black are binary
constructors, car♯and cdr♯, respectively, are the left and the right ♯-selectors
(♯∈{red, black}). The corresponding language is denoted by LRB.
For notation simplicity we use car to denote either carred or carblack, which should
be clear from the context. Similar for the use of cdr. If a term t appears in a
selector, we assume either Isred(t) or Isblack(t) holds. For example, car(x) = y
should be understood as an abbreviation of
(Isred(x) ∧y = carred(x)) ∨(Isblack(x) ∧y = carblack(x)).
In the following we use terms and trees,respectively, to refer to syntactic objects
and semantic objects. We call terms (trees) of red-type (resp. of black-type)
red-terms (-trees) (resp. black-terms (-trees)).
We extend RB with PA to express balancing properties (4)-(5):
Deﬁnition 4 (Structure of Red-black Trees). The structure of red-black
trees is
RBZ = ⟨RB; PA; | · |max, | · |min : Trb →N ⟩,

368
Z. Manna, H.B. Sipma, and T. Zhang
where, | · |max and | · |min are two integer functions deﬁned recursively as
|x|⋆=
⎧
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎩
1
x = nil,
0
Vio(x),
⋆(|x1|⋆, |x2|⋆) + 1
GB(x, x1, x2),
⋆(|x1|⋆, |x2|⋆)
GR(x, x1, x2).
where ⋆∈{max, min} and GB(x, x1, x2), GR(x, x1, x2) and Vio(x) are
Vio(x)
def
== x ̸= nil ∧∀x1∀x2

¬GB(x, x1, x2) ∨¬GR(x, x1, x2)

,
GB(x, x1, x2)
def
== x = black(x1, x2) ∧|x1|max ̸= 0 ∧|x2|max ̸= 0,
GR(x, x1, x2)
def
== x = red(x1, x2) ∧|x1|max ̸= 0 ∧|x2|max ̸= 0
∧¬Isred(x1) ∧¬Isred(x2).
We denote the corresponding language by L Z
RB.
Vio(x) states that x violates property (4) of red-black trees. GB(x, x1, x2) states
x is a black tree with two good subtrees x1 and x2. Similarly for GR(x, x1,
x2). |x|max (resp. |x|min) gives the maximal (resp. minimal) number of black
nodes that x can have on a maximal path. A maximal path of x that contains
the largest (resp. smallest) number of black nodes is called a maximal black path
(resp. minimal black path) of x. We call |x|max the maximal black length of x,
|x|min the minimal black length, and the pair (|x|max, |x|min) the measure of x,
denoted by ∥x∥.
In this theory, properties (1) and (2) of Deﬁnition 2, which state that every
node is either black or red, and that a nil node is black, are trivially satisﬁed by
the choice of signature and the integer functions. Therefore x is a red-black tree
if x satisﬁes the following three conditions.
(§1) |x|max = |x|min any maximal path of x contains the same number of black nodes,
(§2) |x|max > 0
any red node of x must have two black children,
(§3) Isblack(x)
the root of x is black.
We denote by ϕ−
RB(x) the conjunction of (§1) and (§2), and by ϕRB(x) the con-
junction of (§1)-(§3). We note that ϕRB(x) deﬁnes a subdomain of Trb and the
theory of this subdomain can be obtained by relativizing quantiﬁers to ϕRB(x).
Formally, ∀x(ϕRB(x) →Φ(x)) (resp. ∃x(ϕRB(x) ∧Φ(x))) expresses that Φ(x) is
a universal (resp. existential) property of red-black trees. We have
Theorem 1 (Decidability of RBZ)
1. The ﬁrst-order theory of RBZ is decidable and admits quantiﬁer elimination.
2. The decision problem for the quantiﬁer-free fragment is NP-complete.

Verifying Balanced Trees
369
4
Analysis of Red-Black Trees
4.1
Algorithm and Example
In this section we consider the insertion-ﬁxup operation of red-black trees repre-
sented by Algorithm 2, a slightly modiﬁed version of the algorithm given in [7].
We illustrate the algorithm on the same example as in [7], inserting 4 at the
bottom of the tree and showing how the algorithm restores the red-black tree
property.
Algorithm 2 (RB-Insertion-Fixup)
Input: root, T, x.
1: while (x ̸= root and T[x-1].color = red) do
2:
if T[x-1].dir=right then
3:
if (T[x-1].tree is red) {Case 1} then
4:
T[x-1].tree := black(car(T[x-1].tree),cdr(T[x-1].tree))
5:
T[x-1].color := black
6:
T[x-2].color := red
7:
x := x-2
8:
else
9:
if (T[x].dir=left) {Case 2} then
10:
swap(T[x].tree, T[x+1].tree)
11:
T[x].dir := right
12:
T[x+1].dir := left
13:
end if
14:
T[x-1].color := black {Case 3}
15:
T[x].tree := red(T[x].tree, T[x-1].tree)
16:
T[x-1].tree := T[x-2].tree
17:
T[x-1].dir := T[x-2].dir
18:
if (x-2 ̸= root) then
19:
x-3+1:=x-1
20:
else
21:
root := x-1
22:
end if
23:
end if
24:
else if (T[x-1].dir=left) then
25:
similar code as the then clause with left and right swapped
26:
end if
27: end while
28: T[root].color := black
Recall that our language does not have an update function to express the
relation between the original tree and updated tree if the update happens at
an unbounded depth inside the tree. We know that the restoring updates will
begin at the newly inserted node and traverse upwards to the root and that
all local updates will happen on this path. We represent the tree as a sequence
of subtrees indexed by nodes on the path from the root to the newly inserted

370
Z. Manna, H.B. Sipma, and T. Zhang
11
2
1
7
5
4
nil
8
14
nil
15
11
2
1
7
5
4
nil
8
14
nil
15
(a)
(b)
11
7
2
1
5
4
nil
8
14
nil
15
7
2
1
5
4
nil
11
8
14
nil
15
(c)
(d)
Fig. 1. A run of RB-Insertion-Fixup
node. We treat the path as a doubly linked list (denoted by T in the algorithm)
in which each element contains three ﬁelds, .color, .dir and .tree. Field .color
denotes the type of the node. Field .dir indicates whether the subtree at this
node is the left child or the right child. Field .tree denotes the sibling subtree
of this node. We have root.dir = ⊥and root.tree = ⊥. For simplicity, we omit
the value ﬁeld as it has no role in restoring the red-black tree property. We treat
root and x as iterators and we use array notation T [x] to denote the element
pointed to by x. We use x + 1 and x −1 to denote previous iterator and next
iterator of x, respectively. For example, the statement x + 3 −1 = x −1 at line
19 means x.pre.pre.pre.next := x.pre.
Figure 1 shows the results of the operations performed to restore the balanced-
tree property after inserting 4. Figure 2 gives a more detailed picture of the data
structures of the nodes on the path from the root to x. Figure 1 (b) shows the
tree obtained by recoloring. The new violation now corresponds to Case 2 in
Algorithm 2. Figure 1 (c) shows the tree obtained from a left rotation. There
is still a violation which corresponds to Case 3 in Algorithm 2. Figure 1 (d)
shows a new red-black tree after a right rotation. Figures 2 (b)-(d) show the
corresponding changes of the data structure during the run1.
1 To save space, in all ﬁgures we do not draw a nil node if its sibling is not nil, and
for this reason, we do not draw nil nodes black.

Verifying Balanced Trees
371
(a)
11
2
7
5
4
⊥
−→
←−
−→
−→
⊥
14
nil
15
1
8
nil
(b)
11
2
7
5
4
⊥
−→
←−
−→
−→
⊥
14
nil
15
1
8
nil
(c)
11
7
2
5
4
⊥
−→
−→
←−
−→
⊥
14
nil
15
8
1
nil
(d)
7
2
5
4
⊥
−→
←−
−→
⊥
11
8
14
nil
15
1
nil
Fig. 2. Paths from the root of the tree to x. In each of (a)-(d), the ﬁrst row shows the
sequence of nodes from the root to x; the second row shows whether the node above it
is a left (←) or right (→) sibling; the third row shows the sibling tree of the node in
the top row.
4.2
Veriﬁcation Conditions
We now show how to use L Z
RB to express the veriﬁcation conditions for state-
ments restoring that red-black tree property in Algorithm 2. Recall that in the
algorithm x is an iterator and T [x] is a node pointed by x in a linked list and it
contains three ﬁelds, .dir, .color and .tree. At the semantic level, however, we
view x as an integer index and T [x] as a subtree indexed by x. If x ̸= root, then
T [x].tree denotes the sibling tree of T [x], and T [x −1] represents the immediate

372
Z. Manna, H.B. Sipma, and T. Zhang
super-tree containing T [x]. For example, if T [x].dir is right and T [x −1].color
is red, then T [x −1] = red(T [x], T [x].tree). We have three ﬁeld operators, .dir,
.color and .tree. Among them .dir can only take three values, left, right and
⊥, so expressions involving .dir can be removed by disjunctive splitting. Similar
for .color, but it can be directly expressed in LRB as below.
T [x].color = red
def
==
Isred(T [x]),
T [x].color = black
def
==
x = nil ∨Isblack(T [x]).
With the help of .dir, .tree can be expressed in LRB as follows.
T[x].tree = y  ⊥
def
==
x  root ∧

(y = car(T[x −1]) ∧T[x].dir = right)
∨(y = cdr(T[x −1]) ∧T[x].dir = left)

,
T[x].tree = ⊥
def
==
x = root .
Therefore from now on we treat ﬁeld access expressions as abbreviations in LRB.
Note that we use array and record notations for clarity. At the formula level terms
of index access or ﬁeld access are simply variables. For example, T [x], T [x].tree,
T [x].color and T [x].dir can be represented by variables fx, gx, hx and kx indexed
by x, respectively. Similarly for terms indexed by x −i and x + i.
Let ¯v denote the variables in the current state and ¯v′ denote the corresponding
variables in the next state. The transition relation of a statement q is denoted
by ρq(¯v, ¯v′). The post-condition post(q, ϕ) of ϕ(¯v) after executing a statement q
is
(∃¯v0)

ρq(¯v0, ¯v) ∧ϕ(¯v0)

.
The transition relation of two sequential statements can be computed as follows.
Let ρq(¯v, ¯v1) and ρr(¯v1, ¯v′) be the transition relations for statements q and r
respectively. Then the transition relation of the composite statement ⟨q; r⟩is
(∃¯v1)

ρq(¯v, ¯v1) ∧ρr(¯v1, ¯v′)

.
The validity checking of a Hoare triples {ϕ}q{ψ} is equivalent to proving that
post(q, ϕ) →ψ.
The lack of update functions makes it impossible to express the tree opera-
tional semantics precisely in a ﬁnite formula. For example, when T [x] is changed,
not only should T ′[x] appear in ρq(¯v, ¯v′), but also all ancestors of T [x]. In fact
ρq(¯v, ¯v′) has an unbounded number of conjuncts of the form car(T ′[x −i]) =
T ′[x −i + 1] or cdr(T ′[x −i]) = T ′[x −i + 1]. We can still, however, prove safety
properties about tree operations with the help of an informal induction. As an
example, we show that ϕ−
RB(T [x]), introduced in Section 3, is an invariant with
respect to each code fragment (corresponding to Case 1, 2 or 3 in Algorithm 2).
This can be obtained by establishing the Hoare triple {ϕ}Q{ψ} where ϕ is the
pre-condition
x ̸= root ∧x −1 ̸= root →

ϕ−
RB(T [x]) ∧ϕ−
RB(T [x].tree) ∧¬ϕ−
RB(T [x −1]) ∧ϕ−
RB(T [x −1].tree)


Verifying Balanced Trees
373
ψ is the post-condition ϕ−
RB(T [x]), and Q is a code fragment corresponding to
Case 1, 2 or 3. Here we need another invariant ∀x(x ̸= root →ϕ−
RB(T [x].tree)).
This invariant can not be formally proved in our theory because of the universal
quantiﬁcation on indexes. But it is easy to verify that the parametric Hoare
triples
{x ̸= root →ϕ−
RB(T [x ± i].tree)}
q
{x ̸= root →ϕ−
RB(T [x ± i].tree)}
can be established for each statement q not modifying index x (see below for the
transition relations of those statements). In the following we list local transition
relations of all statements involving tree update and use guard conditions to
simplify those transition relations.
Case 1 is implemented by statements 4-7. The guard conditions are x ̸=
root∧Isred(T [x−1]) (line 1), T [x−1].dir = right (line 2) and Isred(T [x−1].tree)
(line 3). Under these conditions the transition relations for statements 4-7 are,
respectively,
T ′[x −1].tree = cdr(T ′[x −2])
= black(car(T [x −1].tree), cdr(T [x −1].tree)),
(S-4)
car(T ′[x −2]) = T ′[x −1] = black(car(T [x −1]), cdr(T [x −1])),
(S-5)
T ′[x −2] = red(car(T [x −2]), cdr(T [x −2])),
(S-6)
x′ = x −2.
(S-7)
The composite transition relation for statements 4-7 is
T ′[x −1].tree = black(car(T [x −1].tree), cdr(T [x −1].tree))
∧
T ′[x −1] = black(car(T [x −1]), cdr(T [x −1]))
∧
T ′[x −2] = red(T ′[x −1], T ′[x −1].tree)
∧
x′ = x −2.
Recall that T [x], T [x].tree, T [x].color and T [x].dir are just more informative
aliases of indexed variables fx, gx, hx and kx, respectively. Similarly for terms
indexed by x −1 and x −2. The next state variable for T [x] should be T ′[x′],
but by default we write T ′[x] when x′ = x. When we do transition relation
composition, statement 7 requires us to hard code the integer indexing properties
in the formula by adding equalities like T ′[x −1] = T ′[x′ + 1], T ′[x −2].tree =
T ′[x′].tree and so on. To save space, however, we omit them in the above example.
Figure 3 illustrates Case 1 by a run on tree (a) in Figure 1 (copied as
(b-0)). Trees (b-1), (b-2) and (b-3) are the outcomes of statements 4, 5 and 6,
respectively.
The code fragment for Case 2 consists of statements 10-12. We take into ac-
count the conditions T [x −1].color = red (line 1), T [x −1].dir = right (line 2)

374
Z. Manna, H.B. Sipma, and T. Zhang
11
2
1
7
x −2
5
x −1
4
x
nil
8
14
nil
15
11
2
1
7
x −2
5
x −1
4
x
nil
8
14
nil
15
(b-0)
(b-1)
11
2
1
7
x −2
5
x −1
4
x
nil
8
14
nil
15
11
2
1
7
x −2
5
x −1
4
x
nil
8
14
nil
15
(b-2)
(b-3)
Fig. 3. A detailed run of RB-Insertion-Fixup step (b)
and T [x].dir = left (line 9). Under these condition the transition relations for
statements 10-12 are, respectively,
cdr(T ′[x −1]) = T ′[x] ∧(T ′[x + 1].tree = cdr(T ′[x]) = T [x].tree)
∧(T ′[x].tree = car(T ′[x −1]) = T [x + 1].tree), (S-10)
T ′[x].dir = right ∧T ′[x −1] = red(cdr(T [x −1]), car(T [x −1])),
(S-11)
T ′[x + 1].dir = left ∧car(T ′[x −1]) = T ′[x]
∧T ′[x] = red(cdr(T [x]), car(T [x])).
(S-12)
The composite transition relation for statements 10-12 is
T ′[x + 1].tree = T [x].tree ∧T ′[x].tree = T [x + 1].tree
∧
T ′[x].dir = right ∧T ′[x −1] = red(T ′[x], T [x + 1].tree)
∧
T ′[x + 1].dir = left ∧T ′[x] = red(T [x].tree, car(T [x])).
Figure 4 illustrates Case 2 by a run on tree (b) in Figure 1 (copied as (c-0)). Trees
(c-1), (c-2) and (c-3) are the outcomes of statements 10, 11 and 12, respectively.
Recall that we ignored value labels at internal nodes as they are irrelevant to the
red-black tree properties. But the binary search tree property may be violated
without adjusting the value labels. So for the sake of illustration we switched po-
sitions of 2 and 7 in Figure 4 (c-1) although statement 10 does not have this eﬀect.

Verifying Balanced Trees
375
11
2
x −1
1
7
x
5
4
nil
8
14
nil
15
11
7
x −1
8
2
x
5
4
nil
1
14
nil
15
(c-0)
(c-1)
11
7
x −1
2
x
5
4
nil
1
8
14
nil
15
11
7
x −1
2
x
1
5
4
nil
8
14
nil
15
(c-2)
(c-3)
Fig. 4. A detailed run of RB-Insertion-Fixup step (c)
Case 3 consists of statements 14-21. We take into account the conditions
T [x −1].color = red (line 1), T [x −1].dir = right (line 2) and T [x].dir = right
(line 11). Under these conditions the transition relations for statements 14-21
are, respectively,
car(T ′[x −2]) = T ′[x −1] = black(car(T [x −1]), cdr(T [x −1])),
(S-14)
cdr(T ′[x −1]) = T ′[x].tree = red(T [x].tree, T[x −1].tree),
(S-15)
T ′[x −1].tree = T [x −2].tree
∧(x −2 ̸= root →cdr(T ′[x −2]) = T [x −2].tree),
(S-16)
T ′[x −1].dir = T [x −2].dir
∧

x −2 ̸= root ∧T [x −1].dir ̸= T [x −2].dir →
T ′[x −2] = black(cdr(T [x −2]), car(T [x −2]))

,
(S-17)
x′ −2 = x −3 ∧

(cdr(T ′[x −3]) = T [x −1] ∧T [x −2].dir = left)
∨(car(T ′[x −3]) = T [x −1] ∧T [x −2].dir = right)

,
(S-19)
x′ −1 = root.
(S-21)

376
Z. Manna, H.B. Sipma, and T. Zhang
11
7
x −1
2
x
1
5
4
nil
8
14
nil
15
11
7
x −1
2
x
1
5
4
nil
8
14
nil
15
(d-0)
(d-1)
11
7
x −1
2
x
1
5
4
nil
11
8
14
nil
15
14
nil
15
11
7
x −1
2
x
1
5
4
nil
11
8
14
nil
15
nil
(d-2)
(d-3)
11
7
x −1
2
x
1
5
4
nil
11
8
14
nil
15
nil
7
2
x
1
5
4
nil
11
8
14
nil
15
(d-4)
(d-5)
Fig. 5. A detailed run of RB-Insertion-Fixup step (d) with x −2 = root
Assuming x−2=root, the composite transition relation for statements 14-21 is
car(T ′[x −2]) = T ′[x −1] = black(car(T [x −1]), T ′[x].tree)
∧
T ′[x].tree = red(T [x].tree, T[x −1].tree)
∧
T ′[x −1].tree = T [x −2].tree ∧T ′[x −1].dir = T [x −2].dir
∧
x′ −1 = root.

Verifying Balanced Trees
377
Assuming x−2 ̸= root, the composite transition relation for statements 14-21 is
car(T′[x −2]) = T′[x −1] = black(car(T[x −1]), T′[x].tree)
∧
T′[x].tree = red(T[x].tree, T[x −1].tree)
∧
T′[x −1].tree = T[x −2].tree ∧cdr(T′[x −2]) = T[x −2].tree
∧
T′[x −1].dir = T[x −2].dir ∧

T[x −1].dir  T[x −2].dir →
T′[x −2] = black(cdr(T[x −2]), car(T[x −2]))

∧
x′ −2 = x −3 ∧

(cdr(T′[x −3]) = T[x −1] ∧T[x −2].dir = left)
∨(car(T′[x −3]) = T[x −1] ∧T[x −2].dir = right)

.
Figure 5 illustrates Case 3 by a run on tree (c) in Figure 1 (copied as (d-0)).
Trees (d-1)-(d-5) are the outcomes of statements 14-17 and 21, respectively,
under the assumption that x −2 = root. Here (d-3) and (d-4) are the same
because T [x −1].dir = T [x −2].dir and hence statement 17 has no eﬀect.
5
Conclusion
We presented a decidable theory of red-black trees, which is an extension of the
theory of term algebras with two size functions. We showed how the red-black
tree insertion algorithm can be analyzed using this theory. We plan to extend
this theory to express local updates at an arbitrary pointed location in a tree.
We note that adding a standard update function easily makes the ﬁrst-order
theory undecidable. We will investigate ways to enhance the expressiveness of
the theory while maintaining the decidability.
References
1. Rolf Backofen.
A complete axiomatization of a theory with feature and arity
constraints. Journal of Logical Programming, 24(1&2):37–71, 1995.
2. Paolo Baldan, Andrea Corradini, Javier Esparza, Tobias Heindel, Barbara K¨onig,
and Vitali Kozioura. Verifying red-black trees. In Proceedings of the 1st Interna-
tional Workshop on the Veriﬁcation of Concurrent Systems with Dynamic Allocated
Heaps (COSMICAH 2005), 2005.
3. Cristiano Calcagno, Philippa Gardner, and Uri Zarfaty. Context logic and tree
update. In Proceedings of the 32nd ACM SIGPLAN-SIGACT Symposium on Prin-
ciples of Programming Languages, pages 271–282. ACM Press, 2005.
4. Hubert Comon, Max Dauchet, Remi Gilleron, Denis Lugiez, Sophie Tison, and
Marc Tommasi. Tree Automata Techniques and Applications. Electronic edition
at http://l3ux02.univ-lille3.fr/tata/tata.pdf, 2002.
5. Hubert Comon and Catherine Delor. Equational formulae with membership con-
straints. Information and Computation, 112(2):167–216, 1994.
6. D. C. Cooper. Theorem proving in arithmetic without multiplication. In Machine
Intelligence, volume 7, pages 91–99. American Elsevier, 1972.

378
Z. Manna, H.B. Sipma, and T. Zhang
7. Thomas H. Cormen, Charles E. Leiserson, Ronald L. Rivest, and Cliﬀord Stein.
Introduction to Algorithms. The MIT Press, Cambridge, Massachusetts, 2001.
8. J. Downey, R. Sethi, and R. E. Tarjan. Variations of the common subexpression
problem. Journal of the ACM, 27:758–771, 1980.
9. H. B. Enderton. A Mathematical Introduction to Logic. Academic Press, 2001.
10. Peter Habermehl, Radu Iosif, and Tomas Vojnar. Automata-based veriﬁcation of
programs with tree updates. In Proceedings of 12th International Conference on
Tools and Algorithms for the Construction and Analysis of Systems (TACAS’06),
volume 3920 of Lecture Notes in Computer Science, pages 350–364. Springer-
Verlag, 2006.
11. Konstantin Korovin and Andrei Voronkov. A decision procedure for the existential
theory of term algebras with the Knuth-Bendix ordering. In Proceedings of 15th
IEEE Symposium on Logic in Computer Science, pages 291 – 302. IEEE Computer
Society Press, 2000.
12. Konstantin Korovin and Andrei Voronkov. Knuth-Bendix constraint solving is NP-
complete. In Proceedings of 28th International Colloquium on Automata, Languages
and Programming (ICALP’01), volume 2076 of Lecture Notes in Computer Science,
pages 979–992. Springer-Verlag, 2001.
13. Viktor Kuncak and Martin Rinard.
The structural subtyping of non-recursive
types is decidable. In Proceedings of 18th IEEE Symposium on Logic in Computer
Science, pages 96–107. IEEE Computer Society Press, 2003.
14. M. J. Maher.
Complete axiomatizations of the algebras of ﬁnite, rational and
inﬁnite tree. In Proceedings of the 3rd IEEE Symposium on Logic in Computer
Science, pages 348–357. IEEE Computer Society Press, 1988.
15. A. I. Mal’cev. Axiomatizable classes of locally free algebras of various types. In
The Metamathematics of Algebraic Systems, Collected Papers, chapter 23, pages
262–281. North Holland, 1971.
16. Greg Nelson and Derek C. Oppen. Fast decision procedures based on congruence
closure. Journal of the ACM, 27(2):356–364, April 1980.
17. Derek C. Oppen. Reasoning about recursively deﬁned data structures. Journal of
the ACM, 27(3):403–411, July 1980.
18. C. R. Reddy and D. W. Loveland. Presburger arithmetic with bounded quantiﬁer
alternation. In Proceedings of the 10th Annual Symposium on Theory of Computing,
pages 320–325. ACM Press, 1978.
19. Radu Rugina. Quantitative shape analysis. In Proceedings of the 11th International
Static Analysis Symposium (SAS’04), volume 3148 of Lecture Notes in Computer
Science, pages 228–245. Springer-Verlag, 2004.
20. Tatiana Rybina and Andrei Voronkov. A decision procedure for term algebras with
queues. ACM Transactions on Computational Logic, 2(2):155–181, 2001.
21. Ting Zhang, Henny B. Sipma, and Zohar Manna. Decision procedures for recursive
data structures with integer constraints. In the 2nd International Joint Conference
on Automated Reasoning (IJCAR’04), volume 3097 of Lecture Notes in Computer
Science, pages 152–167. Springer-Verlag, 2004.
22. Ting Zhang, Henny B. Sipma, and Zohar Manna. The decidability of the ﬁrst-order
theory of term algebras with Knuth-Bendix order. In Robert Nieuwenhuis, editor,
the 20th International Conference on Automated Deduction (CADE’05), volume
3632 of Lecture Notes in Computer Science, pages 131–148. Springer-Verlag, 2005.
23. Ting Zhang, Henny B. Sipma, and Zohar Manna. Decision procedures for term
algebras with integer constraints. Information and Computation, 204:1526–1574,
October 2006.

Compactness Properties for Stable Semantics of
Logic Programs
Victor W. Marek1 and Jeﬀrey B. Remmel2
1 Department of Computer Science, University of Kentucky
Lexington, KY 40506-0046, USA
2 Department of Mathematics,
University of California at San Diego, La Jolla, CA 92093
Abstract. Logic programming with stable logic semantics (SLP) is a
logical formalism that assigns to sets of clauses in the language admitting
negations in the bodies a special kind of models, called stable models.
This formalism does not have the compactness property. We show a
number of conditions that entail a form of compactness for SLP.
1
Introduction
When logicians look at a knowledge representation formalism they ask a vari-
ety of questions. They looks at a syntax, and on the semantics. In semantical
considerations, since G¨odel and Hilbert, logicians recognize that not all models
of the formalism are intended. Quite often semantics that the agent (user of the
formalism) assigns to to the syntax require signiﬁcant restrictions. For instance
logicians will often limit the classes of intended models to ones that give in-
tended meaning to one or more predicates. An examples of this approach is in
studies of ω-models of theories interpreting the arithmetic of positive integers.
The reasoning agent may limit models by looking only at models of some size
of the universe (for instance denumerable models or ﬁnite models) or of special
form (for instance transitive models od set theories, or models that are levels
of cumulative hierarchy, Vα. The rise of Computer Science and of Artiﬁcial In-
telligence introduced new classes of formalisms and new classes of their models.
While previously, the mathematical practice and imagintion of logicians provided
the basic intuitions in selecting formalisms and their semantics, the applications
on Computer Science and Artiﬁcial Intelligence resulted in a variety of new for-
malisms with intuitions in the areas previously limited to informal, philosophical
investigations only.
It should be observed that since G¨odel [13] logicians were concerned with
the nature of computation. Related isssues, such as constructivity of argument
were also discussed by logicians, esp. intuitionists, before the advent of modern
computers. The relationship of complexity of sets of natural numbers, and ex-
istence of algorithms for deciding some mathematical theories has a very long
history, and was present in the minds of mathematicians long before the viable
computing devices were introduced.
S. Artemov and A. Nerode (Eds.): LFCS 2007, LNCS 4514, pp. 379–400, 2007.
c
⃝Springer-Verlag Berlin Heidelberg 2007

380
V.W. Marek and J.B. Remmel
Practical computing, and availability of symbolic computation in particular
revolutionized the approach to foundational issues. today we know that logic and
computation are inextricably connected. It is not our imagination only. We use
computers not only as tools for solving equations, or ﬁnding values of functions
but also as means to perform tasks that were reserved to human mental activities
not long time ago.
As more and more solving tasks associated with human mental capabilities
are delegated to computers, a variety of new formalisms for formaliztions of
these tasks are introduced. Here we will be interested in one such formalism, so
called logic programming with stable semantics which we will abbreviate SLP.
This formalism, although using the name logic programming is grounded in the
work of logicians on so-called Horn formulas. These formulas, introduced by
A. Horn in late 1940ies, has been extensively studied for a variety of reasons and
in various contexts. In the 1960ies, S.C. Kleene and R. Smullyan, showed that
partial recursive functions can be represented in Horn logic. Then R. Kowalski
introduced algorithms for testing the presence of an atom in the least model
of Horn theory. These ideas were transformed into a practical programming
language, called PROLOG by A. Colmerauer. This language one of the family
of declarative programming languages and many of its implementations resulted
in practical tools and are used in a variety of applications. The basic construct (in
a somewhat idealized PROLOG) is a clause (also known as a rule), an expression
of the form p ←l1, . . . , lk where p is an atom, and l1, . . . , lk are literals (atoms
or negated atoms). This is a step beyond Horn logic proper, where l1, . . . , lk
need to be atoms1. From the very beginning, the implementations of PROLOG
admitted admitted negated atoms among l1, . . . , lk and attempted to assign to
the clauses a meaning that may informally be stated like this: “if l1, . . . , lk have
been established then we establish p”. This works well in Horn case, resulting in
the intended semantics of the least model. But when we admit negated literals
among l1, . . . , lk then the interpretation of rules is not clear. Among a large
number of proposals, the one that, essentially, gained concensus as a correct one,
is the stable semantics due to M. Gelfond and V. Lifschitz [12]. Stable semantics
is, in eﬀect, an interpretation of rules as default rules studied by R. Reiter. The
consensus on stable semantics has been reached in the mid 1990ies. Today, stable
sematics and its extensions to so-called answer sets is a basis for so-called Answer
Set Programming (ASP) with several practical implementations.
When logicians look at a formalism such as SLP, they ask a variety of ques-
tions pertaining both to the expressive power of the formalism, and to logical
properties of its semantics. The question of expressibility has been studied early
and it turned out that the problem of existence of stable models of ﬁnite propo-
sitional logic programs (i.e. ﬁnite collections of propositional clauses) is an NP-
complete problem. For inﬁnite programs (and in particular for ﬁnite programs
admitting function symbols -such programs are interpreted as their ground ver-
sions) the SLP turned out to be overexpressive [21]. That is very complex sets of
1 We did not discuss here the issue of uniﬁcation and its role in PROLOG. We limit
ourselveds to the propositional case, although we admit inﬁnite programs.

Compactness Properties for Stable Semantics of Logic Programs
381
integers, more complex than anything considered computable, are expressed by
such models (see also remarks below). This resulted in very signiﬁcant limitations
for ASP.
One question that the logicians will ask when dealing with a formalism is
its compactness. This question has been asked in case of SLP by M. Gelfond.
Motivated by this question we quickly found counterexamples that will be pre-
sented in the next Section. But a natural way to look at negative answers is to
ask if general properties that are not true, can be approximated by some other
properties. In the case of our problem, the issue was this: compactness for SLP
does not hold in general; are there some classes of programs where compactness
is guaranteed? In fact, one such class has been found by Bonatti [5]. Those are
programs which split into two parts, lower and upper in such a way that the
upper part reduces to a Horn program on every stable model of the lower part.
Here we will discuss three diﬀerent syntactically motivated classes of programs
with the compactness property. We introduce a proof-theoretic techniques for
handling stable models. This technique uses proof schemes, an extension of the
concept of proof to non-monotonic context. The main diﬀerence betwee the proof
schemes and proofs as studied in proof theory is that proof schemes have guards
(we call them supports) that allow the proof to be executed. The support is a
set of atoms that need to be absent in the context to execute the proof scheme.
We can consider inclusion-minimal supports, and distinguish programs which
we call ﬁnite-support programs which have only ﬁnite number of such minimal
supports. One of our results is that such programs are characterized by the con-
tinuity of so-called Gelfond-Lifschitz operator, and that these programs do have
compactness property. The second class of programs is based on existence of
schemes of a certain form. This class of programs, called locally-ﬁnite programs
has been introduced by Cenzer and Remmel in [6]. We show that the programs
in this class also have compactness property. The third class considered in this
paper is based on Scott’s notion of consistency property. Again we ﬁnd that this
is syntactic property (diﬀerent from the previous two) that entail compactness.
We discuss the ramiﬁcations in the Conclusions section.
2
Motivating Examples
The Compactness Theorem for propositional logic says that if Θ is a collection of
sentences and every ﬁnite subset of Θ has a model, then Θ has a model. In this
paper, we study the analogue of compactness for the stable logic semantics of
propositional logic programs. At ﬁrst glance, there are some obvious diﬀerences
between stable models of propositional logic programs and models of sets of
sentences in a propositional logic. For example, if T is a set of sentences in a
propositional logic and S ⊆T , then it is certainly the case that every model
of T is a model of S. Thus a set of propositional sentences T has the property
that if T has a model, then every subset of T has a model. This is certainly not
true for propositional logic programs. For example, consider the following logic
example.

382
V.W. Marek and J.B. Remmel
Example 1. Let P consists of the following two clauses:
C1 = a ←¬a, ¬b and
C2 = b ←
Then it is easy to see that {b} is stable model of P. However the subprogram
P ′ consisting of just clause C1 does not have a stable model. That is b is not in
any stable model of P ′ since there is no clause in P ′ whose head is b. Thus the
only possible stable models of P ′ would be M1 = ∅and M2 = {a}. But it is easy
to see that both M1 and M2 are not stable models of P ′.
△
Thus the best that we could hope for as an analogue of compactness for proposi-
tional logic programs would be the following principle which we will call Comp:
(Comp) If for any ﬁnite program P ′ ⊆P, there exist a ﬁnite program P ′′ such
that P ′ ⊆P ′′ ⊆P such that P ′′ has a stable model, then P has a stable model.
Our next example, will show that (Comp) is not true for propositional logic
programs.
Example 2. Let P be an inﬁnite propositional program consisting of the follow-
ing clauses.
1. a ←¬a, ¬b
2. b ←¬ci, for all i ≥0
3. ci ←for all i ≥0.
Note that P has no stable model. That is, if M is a stable model of P, then
ci ∈M for all i by the clauses in the group (3). Thus b /∈M since the only way to
derive b is from one of the clauses in the group (2) and these are all blocked for
M. Now consider a. We cannot have a ∈M since the only way to derive a is via
the clause (1) but it would be blocked if a ∈M. Thus a /∈M. However if a /∈M
and b /∈M, then we must have a ∈M by clause (1). This is a contradiction so
that P has no stable model.
Now we ﬁx n ≥0 and consider a ﬁnite subprogram Pn of P. consisting of the
following clauses.
1. a ←¬a, ¬b
2. b ←¬ci, for all 0 ≤i ≤n + 1
3. ci ←, for all 0 ≤i ≤n.
It is easy to see that Pn has an exactly one stable model, namely {b, c1, . . . , cn}.
It is easy see that any ﬁnite subset F of P is contained in some Pn. Therefore
the principle (Comp) fails for P.
△
Since the analogue of compactness fails for propositional logic programs, it is nat-
ural to ask if there are certain conditions (Cond) such that whenever a proposi-
tional logic program statisﬁes (*), then (Comp) holds. In turns out that there are
several conditions that have appeared in the literature that ensure that (Comp)
holds. The main goal of this paper is survey those conditions.

Compactness Properties for Stable Semantics of Logic Programs
383
3
Stable Models and Proof Schemes
Before we can state some conditions which ensure property (Comp), we need to
formally introduce stable models and the concept of proof schemes.
For an introductory treatment of logic programs, see [1]. Here is a brief self-
contained account of their stable models [12]. Let us assume as given a ﬁxed ﬁrst
order language L based on predicate letters, constants, and function symbols.
The Herbrand base of the language is deﬁned as the set BL of all ground atoms
of the language L. A literal is an atom or its negation, a ground literal is an a
ground atom or its negation. A logic program P is a set of “program clauses”,
that is, an expression of the form:
p ←l1, . . . , lk
(1)
where p is an atom, and l1, . . . , lk is a list of literals.
Then p is called the conclusion of the clause, the list l1, . . . , lk is called the
body of the clause. Ground clauses are clauses without variables. Horn clauses
are clauses with no negated literals, that is, with atomic formulas only in the
body. We will denote by Horn(P) the part of the program P consisting of its
Horn clauses. Horn clause programs are programs P consisting of Horn clauses.
That is for Horn programs P, P = Horn(P). Each such program has a least
model in the Herbrand base determined as the least ﬁxed point of a continuous
operator TP representing 1-step Horn clause logic deduction ([16]).
Informally, the knowledge of a logic program P is the set of clauses in P with
no negated literals in the bodies, that is, the Horn clauses. The set of beliefs of a
logic program P is the set of clauses with negated literals occurring in the bodies
of clauses of P. This use of language is suﬃciently suggestive to guide the reader
to translations of many nonmonotone theories in other reasoning systems into
equivalent logic programs so that extensions as models for the non-monotonic
theory correspond to stable models as models for the logic program.
A ground instance of a clause is a clause obtained by substituting ground
terms (terms without variables) for all variables of the clause. The set of all
ground instances of the program P is called ground(P).
Let M be any subset of the Herbrand base. A ground clause is said to be M-
applicable if the atoms whose negations are literals in the body are not members
of M. Such clause is then reduced by eliminating remaining negative literals.
This monotonization GL(P, M) of P with respect to M is the propositional
Horn clause program consisting of reducts of M-applicable clauses of ground(P)
(see Gelfond-Lifschitz [12]). Then M is called a stable model for P if M is the
least model of the Horn clause program GL(M, P). We denote this least model
as FP (M). It is easy to see that a stable model for P is a minimal model of P
([12]). We denote by Stab(P) the set of all stable models of P. There may be
no, one, or many stable models of P.
We should note that the syntactical condition of stratiﬁcation of Apt, Blair,
and Walker [3] singles out programs with a well-behaved, unique stable model,
but there is no reason to think that in belief revision one could move from

384
V.W. Marek and J.B. Remmel
stratiﬁed program to stratiﬁed program; but how one might do this is an inter-
esting and challenging question.
What kind of proof theory is appropriate for logic programs? The key idea for
our proofs is that of a proof scheme with conclusion an atom p. Proof schemes
are intended to reﬂect exactly how p is a ﬁnitary but non-monotonic consequence
of P.
Proof schemes represent a form of resolution proofs tailored to ﬁt non-
monotonic proofs. Two items distinguis them from the resolution proof trees.
ﬁrst, the derivation process is represented in a linear fashion, as sequences. Sec-
ond, the negative information, controlling applicability of proof schemes is rep-
resented explicitely.
A proof scheme uses, as in Horn logic, the positive information present in the
positive literals of bodies of clauses of P, but proof schemes also have to respect
the negative information present in the negative literals of bodies of clauses.
With this motivation, here is the deﬁnition. A proof scheme for p with respect to
P is a sequence of triples < ⟨pl, Cl, Sl⟩>1≤l≤n, with n a natural number, such
that the following conditions all hold.
1. Each pl is in BL. Each Cl is in ground(P). Each Sl is a ﬁnite subset of BL.
2. pn is p.
3. The Sl, Cl satisfy the following conditions. For all 1 ≤l ≤n, one of (a),
(b), (c) below holds.
(a)Cl is pl ←, and Sl is Sl−1,
(b)Cl is pl ←¬s1, . . . , ¬sr and Sl is Sl−1 ∪{s1, . . . , sr}, or
(c)Cl is pl ←pm1, . . . , pmk, ¬s1, . . . , ¬sr, m1 < l,. . . ,mk < l, and Sl is Sl−1 ∪
{s1, . . . , sr}.
(We put S0 = ∅).
The atoms pi occur in a proof schem in the order they are derived. Because
an atom may be the head of several rules, we also list the speciﬁc rule Ci that
is used to derive pi. The sets Si control the applicability of proof scheme. The
idea here is that, unlike usual proofs, the proof schemes carry within themself
the information on its applicability with respect to potential stable models. To
have the scheme applicable with respect to M, the support of that scheme (Sn)
must be disjoint from M. Let us suppose that ϕ =< ⟨pl, Cl, Sl⟩>1≤l≤n is a
proof scheme. Then conc(ϕ) denotes atom pn and is called the conclusion of ϕ.
Also, supp(ϕ) is the set Sn and is called the support of ϕ.
Condition (3) tells us how to construct the Sl inductively, from the Sl−1 and
the Cl. The set Sn consists of the negative information of the proof scheme.
A proof scheme may not need all its lines to prove its conclusion. It may
be possible to omit some clauses and still have a proof scheme with the same
conclusion. If we omit as many clauses as possible, retaining the conclusion
but still maintaining a proof scheme, this is a minimal proof scheme with that
conclusion. It may be possible to do this with many distinct results, but obviously
there are only a ﬁnite number of ways altogether to trim a proof scheme to a
minimal proof scheme with the same conclusion, since no new clauses are ever
introduced. Of course, a given atom may be the conclusion of no, one, ﬁnitely

Compactness Properties for Stable Semantics of Logic Programs
385
many, or inﬁnitely many diﬀerent minimal proof schemes. These diﬀerences are
clearly computationally signiﬁcant if one is searching for a justiﬁcation of a
conclusion. The apparatus needed to discuss this was introduced in [17].
Formally, we preorder proof schemes ϕ, ψ by ϕ ≺ψ if
1. ϕ, ψ have same conclusion,
2. Every clause in ϕ is also a clause of ψ.
The relation ≺is reﬂexive, transitive, and well-founded. Minimal elements of
≺are called minimal proof schemes.
Here are some propositions from [17,18].
Proposition 1. Let P be a program and M ⊆BL. Let p be an atom. Then p
is in FP (M) if and only if there exists a proof scheme with conclusion p whose
support is disjoint from M.
If Z is a set of atoms we let ¬Z be the conjunction of all the negations of atoms
of Z. Now we ﬁx program P and atom p for the discussion. Associate with the
atom p a (possibly inﬁnitary) Boolean equation Ep
p ↔(¬Z1 ∨¬Z2 ∨. . .),
(2)
where the Z1, Z2 . . . is a (possibly inﬁnite) list of supports of all minimal proof
schemes with conclusion p with respect to P. In fact, for our purposes it is enough
to list only the inclusion-minimal supports. This is called a deﬁning equation for
p with respect to P. If there are inﬁnitely many distinct minimal supports for
proof schemes with conclusion p, this will be an inﬁnitary equation. We make
two other conventions about the deﬁning equation of p. Namely
1. If p is not the conclusion of any proof scheme with respect to P, then the
deﬁning equation for p is p ↔⊥, which is equivalent to ¬p. Hence in this case,
¬p must hold in every stable model of P.
2. If p has a proof scheme with empty support, that is, a proof scheme which
uses only Horn clauses, then the deﬁning equation for p is equivalent to ⊤. In
this case, p belongs to all stable models of P.
The set EqP of all equations Ep obtained as p ranges over the Herbrand base is
called a deﬁning system of equations for program P.
Example 3. Let P be a program:
p(0) ←¬q(X)
nat(0) ←
nat(s(X)) ←nat(X).
Then for each n, < ⟨p(0), p(0) ←¬q(sn(0)), {q(sn(0)}⟩> is a minimal proof
scheme with conclusion p(0). Thus atom p(0) has an inﬁnite number of minimal
proof schemes with respect to program P.
△
The deﬁning equations characterize stable models of logic programs.

386
V.W. Marek and J.B. Remmel
Proposition 2. Let P be a logic program with deﬁning system of equations EqP .
Let M be a subset of the Herbrand universe BL. Then M is a stable model for
P if and only if M ∪{¬q: q ∈BL \ M} is a solution of the system EqP .
Here is another characterization of stable models, this time via proof schemes.
Proposition 3. Let P be a program. Also, suppose that M is a subset of the
Herbrand universe BL. Then M is a stable model of P if and only if, for every
p ∈BL, it is true that p is in M if and only if there exists a proof scheme ϕ
with conclusion p such that the support of ϕ is disjoint from M.
Given a logic program P, Dung and Kanchanasut in [10] introduce a construction
of a purely negative propositional program P ′ (that is a program consisting of
clauses of the form p ←¬q1, . . . , ¬qn, n ≥0, where p, q1, . . . qn are ground atoms)
with the property that P and P ′ have the same stable models. It is very easy to
construct P ′ out of the set of proof schemes (minimal proof schemes are suﬃcient
for that purpose). Namely, let, for a given p ∈BL, Zp
1, Zp
2, . . . list the supports
of all minimal proof schemes for p in P. Then the set of purely negative clauses
{p ←¬Zp
i : p ∈BL, i ∈n}
is a purely negative program P ′ with the desired property that Stab(P) =
Stab(P ′).
4
FSP Logic Programs and Their Continuity Properties
Our ﬁrst condition that ensures a program P has property (Comp) is the notion
of ﬁnitary support programs introduced by Marek, Nerode, and Remmel [21].
That is, Marek, Nerode, and Remmel examined logic programs P such that
every deﬁning equation for every atom p is ﬁnite. We will use show in the next
section that FSP indeed the property Comp. In this section we show continuity
property of an operator associated with FSP logic programs.
The FSP property is equivalent to requiring that every atom has only a ﬁnite
number of inclusion-minimal supports of minimal proof schemes. Such a program
may have the property that there is an atom which is the conclusion of inﬁnitely
many diﬀerent minimal proof schemes, but these schemes have only ﬁnitely many
supports altogether among them.
Example 4. Let P be the program:
p(0) ←q(X)
q(X) ←¬r(0)
nat(0) ←
nat(s(X)) ←nat(X).
Then the atom p(0) is the conclusion of inﬁnitely many proof schemes:
< ⟨q(sn(0)), q(sn(0)) ←¬r(0), {r(0)}⟩, ⟨p(0), p(0) ←q(sn(0)), {r(0)}⟩>
as n ranges over ω. But the single minimal support of all these proof schemes is
{r(0)}. That is, whenever r(0) is not in M, then p(0) will be in FP (M).
△
The above program motivates the following deﬁnition.

Compactness Properties for Stable Semantics of Logic Programs
387
Deﬁnition 1. We say that a ﬁnitary support program (FSP program, for short)
is a logic program such that for every atom p, there is a ﬁnite set of ﬁnite sets
S, which are exactly the inclusion-minimal supports of all those minimal proof
schemes with conclusion p.
We now study the FSP property. It turns out that this property is equivalent to
the continuity property for a suitably deﬁned operator. This is precisely the same
operator whose square (that is two-fold application) determines the monotonic
operator whose least and largest ﬁxpoints determine the well-founded model of
the program ([25]).
We associate an operator with each logic program as follows.
Deﬁnition 2. Let P be a program. The operator FP : P(BL) →P(BL) is
deﬁned as follows: If S ⊆BL then FP (S) is the set of all atoms in BL for which
there exists a proof scheme p such that supp(p) ∩S = ∅. Thus FP assigns to S
the set FP (S).
Proposition 4. The operator FP is anti–monotonic, that is, if S1 ⊆S2, then
FP (S2) ⊆FP (S1).
Proposition 5. The operator FP is lower half-continuous; that is, if ⟨Sn⟩n∈ω is a
monotone decreasing sequence of subsets of BL then 
n∈ω FP (Sn)=FP (
n∈ω Sn).
Proposition 6. Let P
be a logic program. Then following conditions are
equivalent:
(a) P is an FSP logic program.
(b) FP is an upper half-continuous operator; that is, whenever ⟨Sn⟩n∈ω is a
monotone increasing sequence of subsets of BL, we have

n∈ω
FP (Sn) = FP (

n∈ω
Sn).
5
Coding Stable Models into Trees
The key result to prove that at FSP programs have property (Comp) is the
proof of a result of Marek, Remmel, and Nerode [18,21] to the eﬀect that for
any recursive program P, there is recursive tree TP ⊆ωω such that there is
an eﬀective one-one degree preserving correspondence between the set of stable
models of P, Stab(P), and the set of inﬁnite paths throught TP , Path(TP).
In this section, we shall give the neccessary recursion theoretic background
to make precise and to prove the result of Marek, Nerode, and Remmel that
given any recursive logic program P, there is a recursive tree T such that there
is an eﬀective 1-1 degree-preserving map between the set of stable models of P
and the set of paths through T . Then we shall show that the fact that condition
(Comp) holds for FSP programs follows from their proof.

388
V.W. Marek and J.B. Remmel
5.1
Recursive Programs
When we discuss ﬁnite programs then we can easily read oﬀa recursive rep-
resentation of the Herbrand base. The reason is that the alphabet of such a
program, that is, the set of predicate symbols and function symbols that appear
in the program, is ﬁnite. The situation changes when P is an inﬁnite predicate
logic program representable with a recursive set of G¨odel numbers. When we
read oﬀthe enumeration of the alphabet of the program from an enumeration of
the program itself, there is no guarantee that the alphabet of P is recursive. In
particular the Herbrand base of the program is recursively enumerable but may
not necessarily be recursive.
For the purposes of this paper, we deﬁne a program P to be recursive if not only
the set of its G¨odel numbers is recursive, but also the resulting representation of
the Herbrand base is recursive.
5.2
Recursively FSP Programs
A recursively FSP program is an FSP recursive program such that we can uni-
formly compute the ﬁnite family of supports of proof schemes with conclusion
p from p. The meaning of this is obvious, but we need a technical notation for
the proofs. Start by listing the whole Herbrand base of the program, BL as a
countable sequence in one of the usual eﬀective ways. This assigns an integer
(G¨odel number) to each element of the base, its place in this sequence. This
encodes ﬁnite subsets of the base as ﬁnite sets of natural numbers, all that is
left is to code each ﬁnite set of natural numbers as a single natural number, its
canonical index. To the ﬁnite set {x1, . . . , xk} we assign as its canonical index
can({x1, . . . , xk}) = 2x1 +. . .+2xk. We also set can(∅) = 0. If program P is FSP,
and the list, in order of magnitude, of G¨odel numbers of all minimal support of
schemes with conclusion p is
Zp
1, . . . , Zp
lr,
then we deﬁne a function suP : BL →ω as below.
p →can({can(Zp
1), . . . , can(Zp
lr)})
We call a logic program P a recursively FSP program if it is FSP and the
function suP is recursive.
5.3
Tools from Recursion Theory
Let ω = {0, 1, 2, . . .} denote the set of natural numbers and let <, >: ω × ω →
ω−{0} be some ﬁxed one-to-one and onto recursive pairing function such that the
projection functions π1 and π2 deﬁned by π1(< x, y >) = x and π2(< x, y >) = y
are also recursive. We extend our pairing function to code n-tuples for n > 2 by
the usual inductive deﬁnition, that is < x1, . . . , xn >=< x1, < x2, . . . , xn >>

Compactness Properties for Stable Semantics of Logic Programs
389
for n ≥3. We let ω<ω denote the set of all ﬁnite sequences from ω and 2<ω
denote the set of all ﬁnite sequences of 0’s and 1’s. Given α = (α1, . . . , αn) and
β = (β1, . . . , βk) in ω<ω, we write α ⊑β if α is initial segment of β, that is,
if n ≤k and αi = βi for i ≤n. For the rest of this paper, we identify a ﬁnite
sequence α = (α1, . . . , αn) with its code c(α) =< n, < α1, . . . , αn >> in ω. We
let 0 be the code of the empty sequence ∅. Thus, when we say a set S ⊆ω<ω
is recursive, recursively enumerable, etc., we mean the set {c(α): α ∈S} is
recursive, recursively enumerable, etc. A tree T is a nonempty subset of ω<ω
such that T is closed under initial segments. A function f : ω →ω is an inﬁnite
path through T if for all n, (f(0), . . . , f(n)) ∈T . We let [T ] denote the set of all
inﬁnite paths through T . A set A of functions is a Π0
1-class if there is a recursive
predicate R such that A = {f : ω →ω : ∀n(R(< n, < f(0), . . . , f(n −1) >>)}.
A Π0
1-class A is recursively bounded if there is a recursive function g: ω →ω
such that ∀f∈A∀n(f(n) ≤g(n)). It is not diﬃcult to see that if A is a Π0
1-class,
then A = [T ] for some recursive tree T ⊆ω<ω. We say that a tree T ⊆ω<ω
is highly recursive if T is a recursive, ﬁnitely branching tree such that there is
a recursive procedure which given α = (α1, . . . , αn) in T produces a canonical
index of the set of immediate successors of α in T , that is, produces a canonical
index of {β = (α1, . . . , αn, k): β ∈T }. If A is a recursively bounded Π0
1-class,
then A = [T ] for some highly recursive tree T ⊆ω<ω, see [14]. We let A′ denote
the jump of the set A and 0′ denote the jump of the empty set. Thus 0′ is the
degree of any complete r.e. set. We say that a tree T ⊆ω<ω is highly recursive
in 0′ if T is a ﬁnitely branching tree such that T is recursive in 0′ and there is
an eﬀective procedure which given an 0′-oracle and an α = (α1, . . . , αn) in T
produces a canonical index of the set of immediate successors of α in T , that is,
produces a canonical index of {β =< α1, . . . , αn, k): β ∈T }.
We say that there is an eﬀective one-to-one degree preserving correspondence
between the set of stable models of a recursive program P, Stab(P), and the set
of inﬁnite paths [T ] through a recursive tree T if there are indices e1 and e2 of
oracle Turing machines such that
(i) ∀f∈[T ]{e1}gr(f) = Mf ∈Stab(P),
(ii) ∀M∈Stab(P ){e2}M = fM ∈[T ], and
(iii) ∀f∈[T ]∀M∈Stab(P )({e1}gr(f) = M if and only if {e2}M = f).
Here {e}B denotes the function computed by the eth oracle machine with oracle
B. We write {e}B = A for a set A if {e}B is a characteristic function of A. If f
is a function f : ω →ω, then gr(f) = {< x, f(x) >: x ∈ω}. Condition (i) says
that the inﬁnite paths of the tree T , uniformly produce stable models via an
algorithm with index e1. Condition (ii) says that stable models of P uniformly
produce branches of the tree T via an algorithm with index e2. A is Turing
reducible to B, written A ≤T B, if {e}A = B for some e. A is Turing equivalent
to B, written A ≡T B, if both A ≤T B and B ≤T A. Thus condition (iii)
asserts that our correspondence is one-to-one and if {e1}gr(f) = Mf, then f is
Turing equivalent to Mf. Finally, given sets A and B, we let A ⊕B = {2x : x ∈
A} {2x + 1 : x ∈B}.

390
V.W. Marek and J.B. Remmel
5.4
Representing Programs by Trees
Theorem 1. We suppose that the ﬁrst order language L has inﬁnitely many
ground atoms.
1. Then for any recursive program P in L, there exists a recursive tree T ⊆
ω<ω and an eﬀective one-to-one degree preserving correspondence between the
set of all stable models of P, Stab(P) and [T ], the set of all inﬁnite paths
through T .
2. If, in addition to the hypothesis of (1), program P is FSP, then the tree
T is ﬁnite splitting.
3. If, in addition to the hypothesis of (2), program P is recursively FSP,
then the tree T is a highly recursive tree.
Theorem 1 allows us to prove that the class of denumerable FSP has the prop-
erty)Comp).
Theorem 2. Let us suppose that P is a countable FSP program. Then P satisi-
ﬁes property (Comp). That is, if for any ﬁnite program P ′ ⊆P, there exist a
ﬁnite program P ′′ such that P ′ ⊆P ′′ ⊆P such that P ′′ has a stable model, then
P has a stable model.
6
Locally Determined Logic Programs
In this section, we shall describe another condition on propositional logic pro-
grams that will ensure property (Comp) that has appeared in the literature.
Namely, we shall introduce the notion of locally determined logic programs due
to Cenzer and Remmel [6]. For the rest of this paper, we shall only consider
countable logic programs P. Thus whenever we say that P is a logic program,
we shall always assume that P is countable.
The informal notion of a locally determined logic program P is one in which
the existence of a proof scheme for an atom ai (or the lack of existence thereof)
can be determined by examining only clauses or proof schemes involving some
initial segment of the Herbrand base of P. More formally, we ﬁx some countable
logic program P and some listing a0, a1, . . . of the atoms of Herbrand base of P
without repetitions. (We shall make the convention that if P is a recursive logic
program, then there is some recursive function h : ω →ω such that h(i) = ai.)
Then given a proof scheme or a clause ψ, we write max(ψ) for the max({i :
ai occurs in ψ}). We shall write Pn for the set of all clauses C ∈P such that
max(C) ≤n and let An = {a0, . . . , an}.
Deﬁnition 3. We shall say that n is a level of P if for all S ⊆{a0, . . . , an}
and all i ≤n, whenever there exists a proof scheme φ such that cln(φ) = ai
and supp(φ) ∩S = ∅, then there exists a proof scheme ψ such that cln(ψ) = ai,
supp(ψ) ∩S = ∅and max(ψ) ≤n. Note that by deﬁnition, the Herbrand base
HPn of Pn is contained in An. We let lev(P) = {n : n is a level of P}.
The following result has essentially been proven in [9,15]

Compactness Properties for Stable Semantics of Logic Programs
391
Theorem 3. Suppose that n is a level of P and E is a stable model of P. Then
En = E ∩{a0, . . . , an} is a stable model of Pn.
Deﬁnition 4. We shall say that a logic program P is locally determined if
P is countable and there are inﬁnitely many n such that n is a level of P.
Example 5. Let P be the inﬁnite logic program with the following set of clauses.
1. a2i ←¬a2i+1, for all i ∈ω
2. a2i+1 ←¬a2i, for all i ∈ω.
Thus the Herbrand base of P is {a0, a1, . . .}. It is easy to see that S is stable
model of P if and only if |S ∩{a2i, a2i+1}| = 1 for all i ∈ω. In fact, one can
easily prove that lev(P) = {2i + 1 : i ∈ω}. Moreover, it is clear that P is locally
ﬁnite.
△
Example 6. Let Q be the logic program with the following set of clauses for all
i ∈ω.
1. a3i ←¬a3i+1, ¬a3i−2, . . . ¬a1, ¬a3i+2, ¬a3i−1, . . . ¬a2
2. a3i+1 ←¬a3i, ¬a3i−3, . . . ¬a0, ¬a3i+2, ¬a3i−1, . . . ¬a2
3. a3i+2 ←¬a3i, ¬a3i−3, . . . ¬a0, ¬a3i+1, ¬a3i−2, . . . ¬a1
4. a3i ←a3i+3
5. a3i+1 ←a3i+4
6. a3i+2 ←a3i+5
The Herbrand base of Q is {a0, a1, . . .}. It is easy to see that P has exactly 3
stable models, namely, S0 = {a3i : i ∈ω}, S1 = {a3i+1 : i ∈ω} and S2 =
{a3i+2 : i ∈ω}. In this case, Q is not locally ﬁnite since for any i > 0, the
following set of clauses can be used to construct a minimal proof scheme of a0
with support equal to
{a3i+1, a3i−2, . . . , a1, a3i+2, a3i−1, . . . , a2}.
a3i ←¬a3i+1, ¬a3i−2, . . . ¬a1, ¬a3i+2, ¬a3i−1, . . . ¬a2
a3i−3 ←a3i
a3i−6 ←a3i−3
...
a0 ←a3.
However we claim that lev(P) = {3i + 2 : i ∈ω}. That is, let us ﬁx n ≥0
and let us suppose that T ⊆{ai : i ≤3n + 2} and let us suppose that ψ is a
proof scheme with conclusion ar where supp(ψ) ∩T = ∅and r ≤3n + 2. We
shall consider three cases.
Case 1. T = ∅.
In this case it is easy to see that every element of {ai : i ≤3n + 2} which is the
conclusion of a proof scheme of P3n+2 of length one using one of the clauses (1),
(2), and (3).
Case 2. There exist a3i+s and a3j+t in T where s ̸= t and s, t ∈{0, 1, 2}.

392
V.W. Marek and J.B. Remmel
In this case all clauses of the form (1), (2) or (3) where the head of the clause
is some ak with k > 3n + 2 cannot be part of a proof scheme ψ such that
supp(ψ) ∩T = ∅. Thus the only clauses of the form (1), (2), or (3) that can be
part of ψ are clauses from P3n+2. However, in that case, the only clauses of the
form (4), (5), and (6) that can be part of ψ must also be in P3n+2 because there
is no way that we can derive an element ak with k ≥3n + 2 that is in the body
of a clause of the form (4), (5), and (6) if we can only use clauses in ψ of type
(1), (2), and (3) in ψ from P3n+2. Here we are using the fact that ψ is a minimal
proof scheme. It follows that ψ must be a proof scheme for P3n+2.
Case 3. Conditions of Case 1 or Case 2 do not hold.
In this case, T must be contained in one of the stable models S0, S1, or S2. We
shall assume that T ⊆S0 since the other two cases are similar. Since T ∩S0 ̸= ∅,
there can be no clause of type (2) and (3) in ψ which in not in P3n+2. Now we
suppose that a clause of type (3) occurs in ψ with head a3j where j > n. Then
this clause combined with clauses of type (4) in ψ can be used to derive elements
of the form a3i with i ≤n. But for all i ≤n, we can clearly immediately derive
a3i form the clause
a3i ←¬a3i+1, ¬a3i−2, . . . , ¬a1, ¬a3i+2, ¬a3i−1, . . . ¬a2
(3)
which lies in P3n+2 and whose constraints do not intersect T . It follows that we
can construct an minimal proof scheme ψ′ in P3n+2 with the same conclusion as
ψ such that supp(ψ′) ∩T = ∅.
It follows that 3n + 2 is level of P for all n. Moreover it is clear from the
clauses of type (1) and (2) that 3n and 3n + 1 are not levels of P so that
lev(P) = {3n + 2 : n ∈ω} as claimed.
△
Example 7. In this example, we give a program which is very similar to example
6, but is not locally determined. Let R be the logic program with the following
set of clauses. The parameter i ranges over ω in all six groups of clauses.
1. a3i ←¬a3i+1, ¬a3i+2
2. a3i+1 ←¬a3i, ¬a3i+2
3. a3i+2 ←¬a3i, ¬a3i+1
4. a3i ←a3i+3
5. a3i+1 ←a3i+4
6. a3i+2 ←a3i+5
Just as in example 6, the Herbrand base of R is {a0, a1, . . .} and it easy see that
P has exactly 3 stable models, namely, S0 = {a3i : i ∈ω}, S1 = {a3i+1 : i ∈ω}
and S2 = {a3i+2 : i ∈ω}. In this case, R has no levels. Again it is easy to
see that the clauses of the form (1) and (2) ensure that 3n and 3n + 1 are
not levels of P. However in this case, 3n + 2 is also not a level of P. That
is consider T = {a3n, a3n+1}. It is easy to see that there is no minimal proof
scheme ψ of P3n+2 such that supp(ψ) ∩T = ∅and the conclusion of ψ is a3n+2.
However the following is a minimal proof ψ′ of P with conclusion a3n+2 such
that supp(ψ′) ∩T = ∅.
⟨⟨a3n+5, a3n+5 ←¬a3n+3, ¬a3n+4, {a3n+3, a3n+4}⟩⟨a3n+2, a3n+2 ←a3n+5⟩, {a3n+3, a3n+4}⟩⟩.

Compactness Properties for Stable Semantics of Logic Programs
393
Example 8. Suppose that we are given a set L = {l0 < l1 < . . .}. Then we can
construct a program P such that HP = {a0, a1, . . .} and lev(P) = L as follows.
Let l−1 = −1. Then for each n ≥0, we add the clause
aln ←
to P if ln −ln−1 = 1. Otherwise we add the following clauses to P
aln−1+k ←¬aln−1+1, . . . , ¬aln−1+k−1, ¬aln−1+k+1, . . . , ¬aln−1+(ln−ln−1)
for all k = 1, . . . , ln −ln−1.
△
Deﬁnition 5. Suppose that P is a recursive logic program. Then we say that
P is eﬀectively locally determined if P is locally determined and there is a
recursive function f such that for all i, f(i) ≥i and f(i) is a level of P.
In [21], Marek, Nerode, and Remmel showed that the problem of ﬁnding a stable
model of a locally ﬁnite recursive logic program can be reduced to ﬁnding an
inﬁnite path through a ﬁnitely branching recursive tree and the problem of
ﬁnding a stable model of a highly recursive logic program can be reduced to
ﬁnding an inﬁnite path through a highly recursive tree. A locally determined
logic program is not always locally ﬁnite since it is possible that a given atom
has inﬁnitely many proof schemes which involves arbitrarily large atoms as in
Example 6 above. Vice versa, it is possible to give examples of locally ﬁnite logic
programs which is not locally determined. Nevertheless, we shall see that we get
similar results to those of Marek, Nerode, and Remmel for locally determined
and eﬀectively locally determined recursive logic programs.
Theorem 4. Let P be a recursive logic program.
1. If P is locally determined, then there is a recursive ﬁnitely branching tree
T and a one-to-one degree preserving correspondence between the set of stable
models S(P) of P and [T ] and
2. If P is eﬀectively locally determined, then there is a highly recursive
ﬁnitely branching tree T and a one-to-one degree preserving correspondence
between the set set of stable models S(P) of P and [T ].
A careful inspection of the tree T of Theorem 4 allows us to establish the fol-
lowing fact.
Corollary 1. Suppose that P is a countable locally determined logic program
such that there are inﬁnitely many n such that Pn has a stable model En. Then
P has a stable model.
We also have the following.
Corollary 2. Supose that P is inﬁnite locally determined logic program, then P
satisﬁes property (Comp).

394
V.W. Marek and J.B. Remmel
One can immediately apply a number of known results from the theory of recur-
sively bounded Π0
1 classes to derive corresponding results about the set of stable
models of an eﬀectively locally determined recursive logic program.
Corollary 3. Suppose that P is an eﬀectively locally determined recursive logic
program which has at least one stable model. Then
1.
P has a stable model whose Turing jump is recursive in
0′.
2.
If P has no recursive stable model, then P has 2ℵ0 stable
models.
3.
If P has only ﬁnitely many stable models, then each of
these stable models is recursive.
4.
There is a stable model E of P in an r.e. degree.
5.
There exist stable models E1 and E2 of P such that any
function, recursive in both E1 and E2, is recursive.
6.
If P has no recursive stable model, then there is a nonzero
r.e. degree a such that P has no stable model recursive
in a.
A similar corollary holds for locally determined recursive logic programs where
the statements in Corollary 3 are replaced by versions which are relativized to
a 0′ oracle.
7
FC-Normal Logic Programs
In this section with the notion of FC-normal logic programs as deﬁned by Marek,
Nerode, and Remmel [22]. These programs always have a stable model. In fact,
they have an even stronger property that property (Comp). Namely, an FC-
normal program P has the property that if P ′ is a ﬁnite subprogram of P which
has a stable model E, then P has a stable model S which extends E.
Recall that Horn(P) is the set of Horn clauses of a logic program P. We let
THorn(P ) denote the one-step provability operator associated with Horn(P), see
[1]. That is, if Q ⊆HP , then THorn(P )(Q) equals
{p ∈HP : (∃C = p ←q1, . . . qm ∈Horn(P)) (q1, . . . , qm ∈Q)}.
We call a family of subsets of HP , Con, a consistency property over P if it
satisﬁes the following conditions:
1. ∅∈Con.
2. If A ⊆B and B ∈Con, then A ∈Con.
3. Con is closed under directed unions.
4. If A ∈Con then A ∪THorn(P )(A) ∈Con.
Conditions (1)-(3) are Scott’s conditions for information systems. Condition
(4) connects “consistent” sets of atoms to the Horn part of the program; if A
is consistent then adding atoms provable from A preserves “consistency”. The
following fact is easy to prove.

Compactness Properties for Stable Semantics of Logic Programs
395
Proposition 7. If Con is a consistency property with respect to P and A ∈
Con, then THorn(P ) ⇑ω(A) ∈Con.
Here, for a Horn program Q, TQ ⇑ω(A) is the cumulative ﬁxpoint of TQ over A.
Proposition 7 says that our condition (4) in the deﬁnition of consistency property
implies that the cumulative closure of a “consistent” set of atoms under TH(P )
is still “consistent”.
Given a consistency property, we deﬁne the concept of an FC-normal pro-
gram with respect to that property. Here FC stands for “Forward Chaining”.
Deﬁnition 6. (a) Let P be a program, let Con be a consistency property with re-
spect to P. Call P FC-normal with respect to Con if for every clause C = p ←
q1, . . . , qn, ¬r1, . . . , ¬rm such that C ∈ground(P)−ground(Horn(P)) and every
consistent ﬁxpoint A of THorn(P ) such that q1, . . . , qn ∈A and p, r1, . . . , rm /∈A
we have
(1) A ∪{p} ∈Con and
(2) A ∪{p, ri} /∈Con for all 1 ≤i ≤m.
(b) P is called FC-normal if there exists a consistency property Con such that
P is FC-normal with respect to Con.
Example 9. Let the Herbrand base consist of atoms a, b, c, d, e, f. Let the con-
sistency property be deﬁned by the following condition:
A /∈Con if and only if either {c, d} ⊆A or {e, f} ⊆A.
Now let us consider the following program.
(1) a ←
(2) b ←c
(3) c ←b
(4) c ←a, ¬d
(5) e ←c, ¬f
It is not diﬃcult to check that this program is FC-normal with respect to the
consistency property described above. Moreover, one can easily check that P
possesses a unique stable model M = {a, b, c, e}.
If we add to this program the clause f ←c, ¬e, the resulting program is still
FC-normal but now there are two stable models, M1 = {a, b, c, e} and M2 =
{a, b, c, f}.
△
Marek, Nerode, and Remmel [22] showed that FC-normal normal programs have
many of the properties that are possessed by normal default theories.
Theorem 5. If P is an FC-normal program, then P possesses a stable model.
Theorem 6. If P is an FC-normal program with respect to the consistency prop-
erty Con and I ∈Con, then P possesses a stable model I′ such that I ⊆I′.
Marek, Nerode, and Remmel proved Theorem 5 and 6 via a generally for-
ward chaining algorithm which can be applied to FC-normal programs of any
cardinality. Since in our case, we are dealing with only recursive and hence

396
V.W. Marek and J.B. Remmel
countable programs, we shall give only the countable version of their forward
chaining construction. That is, let us suppose we ﬁx some well-ordering ≺of
ground(P) −ground(H(P)) of order type ω. Thus, the well-ordering ≺deter-
mines some listing of the clauses of ground(P) −ground(H(P)), {cn : n ∈ω}.
Their forward chaining construction then deﬁnes an increasing sequence of sets
{T ≺
n }n∈ω in stages.
The countable forward chaining construction of T ≺= 
n∈ω T ≺
n .
Stage 0. Let T ≺
0 = THorn(P ) ⇑ω(∅).
Stage n + 1. Let ℓ(n + 1) be the least s ∈ω such that
cs = ϕ ←α1, . . . , αk, ¬β1, . . . , ¬βm where α1, . . . , αk ∈T ≺
n and
β1, . . . , βm, ϕ /∈T ≺
n . If there is no such ℓ(n + 1), let T ≺
n+1 = T ≺
n . Otherwise let
T ≺
n+1 = THorn(P ) ⇑ω(T ≺
n ∪{pℓ(n+1)})
where pℓ(n+1) is the head of cℓ(n+1).
Example 10. If we consider the ﬁnal extended program of Example 9, it is easy
to check that any ordering ≺1 in which the clause C1 = e ←c, ¬f precedes the
clause C2 = f ←c, ¬e will have T ≺1 = M1 while any ordering ≺2 in which C2
precedes C1 will have T ≺2 = M2.
△
This given, Marek, Nerode, and Remmel proved the following results.
Theorem 7. If P is a countable FC-normal program and ≺is any well-ordering
of ground(P) −ground(H(P)) of order type ω, then :
(1) T ≺is a stable model of P where T ≺is constructed via the countable forward
chaining algorithm.
(2) (completeness of the construction). Every stable model model of P is of the
form T ≺for a suitably chosen ordering ≺of ground(P)−ground(H(P)) of order
type ω where T ≺is constructed via the countable forward chaining algorithm.
Theorem 8. If P is an FC-normal logic program with respect to Con, then
every stable model M of P is in Con.
Theorem 9. Let P be an FC-normal logic program with respect to a consistency
property Con. Then if E1 and E2 are two distinct stable models of P, then
E1 ∪E2 /∈Con.
Given a logic program P and a stable model M, we let NG(M, P), the set
of non-Horn generating clauses of P be equal to the set of all clauses c =
ϕ ←α1, . . . , αk, ¬β1, . . . , ¬βm in ground(P) such that α1, . . . , αk ∈M and
β1, . . . , βm /∈M.
FC-normal programs possess the following key “semi-monotonicity” property.

Compactness Properties for Stable Semantics of Logic Programs
397
Theorem 10. Let P1, P2 be two programs such that P1 ⊆P2 but H(P1) =
H(P2). Let us assume, in addition, that both are FC-normal with respect to the
same consistency property. Then for every stable model M1 of P1, there is a
stable model M2 of P2 such that:
(1) M1 ⊆M2 and
(2) NG(M1, P1) ⊆NG(M2, P2).
As mentioned in the introduction, a recursive FC-normal logic program P is
guaranteed to have at least one relatively well behaved stable model
Theorem 11. Suppose that P is a recursive logic program and P is FC-normal.
Then P has a stable model S such that S is r.e. in 0′ and hence E ≤T 0′′.
We observe that this should be contrasted with the following result from [21]
Proposition 8. There exists a recursive logic program P such that P possesses
a stable model, but no stable model of P is hyperarithmetic.
We note that Theorem 11 is in some sense the best possible. That is, results
from [22] show that the following holds. Given sets A, B ⊆ω, let A ⊕B = {2x :
x ∈A} ∪{2x + 1 : x ∈B}.
Theorem 12. Let A be any r.e. set and B be any set which is r.e. in A, i.e.
B = {x : φA
e (x) ↓}. Then there is a recursive FC-normal logic program P such P
has a unique stable model S and S ≡T A⊕B. In particular, if B is any set which
is r.e. in 0′ and B ≥T 0′, then there is an FC-normal recursive logic program P
such that P has a unique stable model S and S ≡T B.
However if either Horn(P) or P −Horn(P) is ﬁnite, then one can improve on
Theorem 11. That is, the following was proved in [22].
Theorem 13. Let P be a FC-normal recursive logic program such that P −
Horn(P) is ﬁnite, then every stable model of S is r.e..
We say that a recursive logic program P is monotonically decidable if for
any ﬁnite set F ⊆H(P), THorn(P ) ⇑ω(F) is recursive and there is a uniform
eﬀective procedure to go from a canonical index of a ﬁnite set F to a recursive
index of the THorn(P ) ⇑ω(F), i.e. if there is a recursive function f such that
for all k, φf(k) is the characteristic function of THorn(P ) ⇑ω(Dk). It is easy
to see that if Horn(P) is ﬁnite, then the recursive program P is automatically
monotonically decidable.
Theorem 14. Let P be a recursive logic program such that P is FC-normal and
monotonically decidable, then P has an stable model which is r.e.
We end this section by giving complexity results for ﬁnite FC-normal logic pro-
gram where the forward chaining algorithm runs in polynomial time.
For complexity considerations, we shall assume that the elements of HP are
coded by strings over some ﬁnite alphabet Σ. Thus every a ∈HP will have some
length which we denote by ||a||. Next, for a clause
r = c ←a1, . . . , an, ¬b1, . . . , ¬bm,

398
V.W. Marek and J.B. Remmel
we deﬁne ||r|| = (
i≤n ||ai||)+(
i≤m ||bj||)+||c||. Finally, for a set Q of clauses,
we deﬁne
||Q|| =

r∈Q
||r||.
Theorem 15. Suppose P is a ﬁnite FC-normal logic program and ≺is some
well-ordering of P −Horn(P). Then E≺as constructed via our forward chaining
algorithm can be computed in time
O(||Horn(P)|| · ||P −Horn(P)|| + ||P −Horn(P)||2).
We note that none of the theorems above make any explicit assumptions that the
underlying consistency property of a recursive FC-normal logic P is in any way
eﬀective. Indeed none of the above results require that the underlying consistency
property has any eﬀective properties.
Finally Marek, Nerode, and Remmel [22] proved the following result about
recursive FC-normal logic programs.
Theorem 16. Let T be a recursive tree in 2<ω such that [T ] ̸= ∅. Then there is
a FC-normal recursive logic program P such that there is an eﬀective one-to-one
degree preserving correspondence between [T ] and S(P).
Reiter ([23]) proved that there is a recursive normal default theory with no recur-
sive extension. Theorem 16, which was originally proved for nonmonotonic rule
systems of which logic programs and default theories are special cases, contains
Reiter’s result as special case. In addition, it gives much ﬁner information even
for recursive normal default theories since the set of degrees of paths through
highly recursive trees have been extensively studied. For example, our correspon-
dence allows us to transfer results about the possible degrees of paths through
highly recursive trees to results about the degrees of stable models of recursive
FC-normal logic programs. A number of results of this kind has been proved
in [22].
8
Conclusions
In this paper we established three classes C of logic programs such that C have
compactness property. Two of these classes are based on enforcing tighter re-
striction on proof theoretic characterizations of stable models. The third one is
based on the form of consistency property of Scott applied to logic programs.
It is likely that there are other compact classes of programs and, in fact, one
such class has been identiﬁed in [5]. The classes we found are quite rich, and it
is likely that additional strong restrictions would have to be imposed on com-
pact classes to make them a viable tool for applications. But what would be
such applications? As is clear from the results stated in this paper, unlimited
negation allows the programmer to write programs that have a unique stable
model, but that model is so complex that it cannot be eﬀectively queried. Even
the stratiﬁed negation does not prevent stable models that are too complex for

Compactness Properties for Stable Semantics of Logic Programs
399
querying [2]. The logic programming community answered these challenges by
limiting programs to DATALOG¬ programs (which essentially means eliminat-
ing untabled functions). In such setting the Herbrand base BL is ﬁnite and so
practical systms based on this mechanism can be built [24,4]. Yet, the current
implementations of PROLOG mostly work and allow for use of negation. Thus
there is hope that the quest for some reasonable and practical semantics of logic
programs with negation is not entirely futile. Our paper is a small step in this
direction.
Acknowledgements. V.W. Marek was partially supported by NSF grant no.
IIS-0325063. J.B. Remmel was partially supported by NSF grant DMS-0400507.
References
1. K. Apt. Logic programming, In: J. van Leeuven, ed, Handbook of Theoretical
Computer Science, pages 493–574, MIT Press, Cambridge, MA”, 1990.
2. K. R. Apt, H. A. Blair, Arithmetical Classiﬁcation of Perfect Models of Stratiﬁed
Programs, Fundamenta Informaticae 13 (1990) 1-17.
3. K. Apt, H. Blair, and A. Walker. Towards a Theory of Declarative Knowledge.
In J. Minker, editor, Foundations of Deductive Databases and Logic Programming,
pages 89–142, Los Altos, CA, 1987. Morgan Kaufmann.
4. Y. Babovich and V. Lifschitz.
Cmodels, 2002.
http://www.cs.utexas.edu/
users/tag/cmodels.html.
5. P.A. Bonatti. Resolution for Skeptical Stable Model Semantics. Journal of Auto-
mated Reasoning 27:391–421, 2001.
6. D. Cenzer and J. B. Remmel, Index Sets for Π0
1-classes, Annals of Pure and Applied
Logic 93 (1998), 3-61.
7. D. Cenzer and J. B. Remmel, Π0
1-classes in Mathematics, in: Handbook of Recursive
Mathematics: Volume 2, eds. Yu. L. Ershov, S.S. Goncharov, A. Nerode, and J.B.
Remmel, Studies in Logic and the Foundations of Mathematics, vol. 139, Elsevier,
1998, pp. 623-822.
8. D. Cenzer, J. B. Remmel, and A. K. C. S. Vanderbilt, Locally Determined Logic
Programs, in: Proceedings of the 6th international Conference on Logic Program-
ming and Nonmonotonic Reasoning (LPNMR99), Springer-Verlag, 1999, pp. 34-49.
9. P. Cholewi´nski, Stratiﬁed default theories, in Proceedings of CSL’94, Lecture Notes
in Computer Science, vol. 933, Springer-Verlag, 1995.
10. P.M. Dung and K. Kanchanasut. A Fixpoint Approach to Declarative Semantics
of Logic Programs, In: E.L. Lusk and R.A. Overbeek eds, Logic Programming,
Proceedings of North American Conference, pages 604–625, 1989
11. A. Ferry, A topological characterization of the stable and minimal model classes of
propositional logic programs, Ann. Math. Artiﬁcial Intelligence 15 (1995), 325-355.
12. M. Gelfond and V. Lifschitz. The Stable Semantics for Logic Programs. In Proceed-
ings of the 5th International Symposium on Logic Programming, pages 1070–1080,
Cambridge, MA., 1988. MIT Press.
13. K. G¨odel. ¨Uber formal unentscheibare S¨atze der Principia Mathemaica und ver-
wandter Systeme I. Monatshefte Math. Phys. 38:173–198, 1931.
14. C.G. Jockusch and R.I. Soare. π0
1 Classes and Degrees of Theories. Transactions
of American Mathematical Society, 173:33–56, 1972.

400
V.W. Marek and J.B. Remmel
15. V. Lifschitz and H. Turner, Splitting a logic program, in: Proceedings of the Eleventh
International Conference on Logic Programming, ed. P. Van Hentenryck, 1994, pp.
23–37.
16. J. Lloyd, Foundations of Logic Programming, Springer-Verlag, 1989.
17. W. Marek, A. Nerode, and J.B. Remmel. Nonmonotonic Rule Systems I. Annals
of Mathematics and Artiﬁcial Intelligence, 1:241–273, 1990.
18. W. Marek, A. Nerode, and J.B. Remmel. Nonmonotonic Rule Systems II. Annals
of Mathematics and Artiﬁcial Intelligence, 5:229-264, 1992.
19. W. Marek, A. Nerode, and J.B. Remmel. A Context for Belief Revision: Normal
Logic Programs (Extended Abstract) Proceedings, Workshop on Defeasible Rea-
soning and Constraint Solving, International Logic Programming Symposium, San
Diego, CA., 1991.
20. W. Marek, A. Nerode, and J.B. Remmel. How Complicated is the Set of Stable
Models of a Logic Program? Annals of Pure and Applied Logic, 56:119-136, 1992.
21. W. Marek, A. Nerode, and J. B. Remmel, The stable models of predicate logic
programs. Journal of Logic Programming 21 (1994), 129-154.
22. W. Marek, A. Nerode, and J. B. Remmel, Context for belief revision: Forward
chaining-normal nonmonotonic rule systems, Annals of Pure and Applied Logic 67
(1994), 269-324.
23. R. Reiter. A Logic for Default Reasoning. Artiﬁcial Intelligence, 13:81–132, 1980.
24. P. Simons, I. Niemel¨a, and T. Soininen. Extending and implementing the stable
model semantics. Artiﬁcial Intelligence, 138:181–234, 2002.
25. A. Van Gelder, K.A. Ross, and J.S. Schlipf.
Unfounded sets and well-founded
semantics for general logic programs. Journal of the ACM, 38:587, 1991.

Uniform Circuits,  Boolean Proof Nets
Virgile Mogbil1,⋆and Vincent Rahli2,⋆⋆
1 LIPN – UMR7030, Universit´e Paris 13 – CNRS, France
2 ULTRA, Heriot-Watt University, Scotland
Abstract. The relationship between Boolean proof nets of multiplica-
tive linear logic (APN) and Boolean circuits has been studied [Ter04]
in a non-uniform setting. We reﬁne this results by taking care of uni-
formity: the relationship can be expressed in term of the (Turing) poly-
nomial hierarchy. We give a proofs-as-programs correspondence between
proof nets and deterministic as well as non-deterministic Boolean circuits
with a uniform depth-preserving simulation of each other. The Boolean
proof nets class mBN (poly) is built on multiplicative and additive lin-
ear logic with a polynomial amount of additive connectives as the non-
deterministic circuit class NNC(poly) is with non-deterministic variables.
We obtain uniform-APN = NC and mBN (poly) = NNC(poly) = NP.
1
Introduction
Linear Logic (LL) is a reﬁnement of classical and intuitionist logic [Gir87]. The
conjunction/disjunction are split into the multiplicative (M) and additive (A)
connectives. The exponentials give a logical status to the structural rules of
classical and intuitionist sequent calculus. The study of LL revealed the proof
nets [Gir87, DR89]: a parallel syntax for logical proofs where some inessential
sequential information are removed. In this way the global and sequential se-
quent calculus cut-elimination becomes local and parallel in the proof nets. The
well known Curry-Howard isomorphism is a correspondence between proofs and
programs which associates cut-elimination in proofs and execution in programs.
We study its extension to models of parallel computation using proof nets.
Boolean circuits [Vol99, BS90] are a standard model of parallel computation
as Turing machine are a model of sequential computation. Several important
complexity classes are deﬁned in terms of Boolean circuits, including NC. NC
can be thought of as the problems being eﬃciently solved on a parallel computer
just as the class P can be thought of as the tractable problems. Because a
circuit has a ﬁxed input size, Boolean circuits are so-called non-uniform models
of computation: inputs of diﬀerent lengths are processed by diﬀerent circuits.
A uniformity condition is often imposed on circuit families so that each circuit
can be computed by some resource-bounded Turing machine. For instance NC is
deﬁned to be the set of Boolean functions that can be decided by uniform Boolean
⋆Work partially supported by projects GEOCAL (ACI) and NO-CoST (ANR).
⋆⋆Work partially supported by projects GEOCAL (ACI) and NO-CoST (ANR).
S. Artemov and A. Nerode (Eds.): LFCS 2007, LNCS 4514, pp. 401–421, 2007.
c
⃝Springer-Verlag Berlin Heidelberg 2007

402
V. Mogbil and V. Rahli
circuits of polynomial size in the length of the inputs and polylogarithmic depth.
The depth is the time on a parallel computer where the size is the number of
processors.
K. Terui (NII, Japan) introduced a proof-as-programs correspondence be-
tween a multiplicative Boolean proof nets class (APN) and Boolean circuits
such that cut-elimination corresponds to evaluation [Ter04]. Deﬁning a parallel
cut-elimination in proof nets, the Terui’s main result is APN = non-uniform
NC. This is the ﬁrst time that a logical depth is taken into account: it makes
possible to achieve a seed up over sequential computation. Without restricting
the depth in NC or non-uniform NC, one obtains respectively P or P/poly.
P/poly is the complexity class of languages recognized by a polynomial-time
Turing machine with a polynomial-bounded advice function. So K. Terui gives a
corollary: polynomially-sized multiplicative Boolean proof nets class is equivalent
to P/poly. Our paper is ﬁrstly motivated by an algorithmic point of view, and
therefore an important issue is the uniformity of circuits, because only a uniform
circuit family (Cn)n∈N can be regarded as an implementation of an algorithm.
Indeed a description of the circuit Cn for inputs of size n can be obtained easily
when the value of n is known: we need an eﬃcient algorithm to built Cn given
n, where diﬀerent notions of eﬃcient give rise to diﬀerent notions of uniformity
[Ruz81, All89, BIS90]. We introduce a suitable notion of uniformity for proof
nets and adapt the proofs between proof nets and Boolean circuits to satisfy the
uniformity condition. The method gives the uniform counter part of the Terui’s
results i.e. a proof nets characterisation of both NC and P.
Note that P/poly is not generally considered a practical class for computing.
Indeed it contains every undecidable unary language, none of which can be solved
in general by real computers. However P/poly is an important theoretical class
because of the following fact: if NP ⊆P/poly then the polynomial hierarchy
collapses to Σ2P (i.e. NP with NP Oracle), and if NP is not a subset of P/poly
then P ̸= NP [KL80, CK06]. Our work is motivated by such theoretical point of
view and the logical study of complexity classes. We study a non-deterministic
extension of the parallel Curry-Howard isomorphism in a uniform setting always
by giving a uniform depth-preserving simulation of each classes. On one hand
there are several characterizations of non-determinism in circuits [Ven92, Wol94].
We use NNC(poly) a class equivalent to NP, which is deﬁned in the same way
as NC but using at most a polynomial amount of non-deterministic variables.
On the other hand, as suggested by K. Terui we enrich proof nets with addi-
tive connectives, because additive allow us to incorporate non-determinism. An
encoding of a co-NP problem in the intuitionist fragment of MALL [MT03] illus-
trates why additives could be used. Contrary to the multiplicative case, the proof
nets with additives have never been convincing: in the original syntax [Gir87],
the additive connective  is associated to a box and the cut-elimination does
not satisfy the Church-Rosser property. Nevertheless if a such proof net does
not contain the connective  in its conclusions then it has a unique normal form
[Tor03]. Our encoding and the deﬁned Boolean proof nets satisfy this property,
so we restrict our attention to this setting. Strong normalization and conﬂuence

Uniform Circuits,  Boolean Proof Nets
403
of the additive proof nets have been studied in various directions [Tor03], in the
polarized fragment of LL [LdF04] or recently with a set of linkings on a formula
[HvG03, HvG05]. We have not yet fully explored this last approach which seems
to give another kind of speed-up.
After some background on Boolean circuits in section 2, we present the Terui’s
approach extended to the uniform case in section 3. The circuit gates are un-
bounded like (∧n)n∈N and (∨n)n∈N. In particular the stCONN2 gates which test
the reachability between two nodes of the undirected graph given in input, are
used to simulate the cut-elimination of proof nets. In the ﬁrst subsection the
deﬁnitions concerning MLLu (a n-ary variant of MLL) and Boolean type are
presented as in [Ter04]. We deﬁne the uniformity for Boolean proof net fami-
lies: the class mBN denotes just uniform-APN. Then, we improve the Terui’s
results with two theorems (Thm.2, Thm.5): the translation and simulation be-
tween NC and mBN are done in logspace. Section 4 is devoted to the uniform
non-deterministic Boolean proof nets called mBN (poly). We deﬁne the proof
nets for MuALL which is the fragment MLLu extended with additive connec-
tives. We remind the standard deﬁnitions of the additives connectives: the slices
and the cut-elimination. We easily obtain a parallel reduction theorem because of
the particular setting. We introduce an extended version of the Boolean type for
the non-deterministic variables. In the last section we establish the translation
and the simulation theorems which imply NNC(poly) = mBN (poly) = NP.
2
Background
– Boolean Circuits –
Let Fn denote the set of all Boolean functions f : {0, 1}n →{0, 1} for some
n ∈N. A basis is a ﬁnite set consisting of Boolean functions or sequences of
Boolean functions (fi)i∈N where fi ∈Fi. The standard basis are B0 = {¬, ∧, ∨}
and B1 = {¬, (∧n)n∈N, (∨n)n∈N}.
A Boolean circuit over a basis B is a directed acyclic graph with n+1 sources
or inputs (vertices with no in-going edges), one sink or output (a vertex with
no out-going edges) and all nodes in B. Sources are labelled by literals from
{x1, . . . , xn} ∪{1} and nodes of in-degree k are labelled by one of the k-ary
Boolean functions of B. A Boolean circuit (a circuit for short) computes a func-
tion in Fn in a natural way. Nodes are called gates, and in-degree and out-degree
are called fan-in and fan-out respectively. The circuits over basis without in-
ﬁnite families of Boolean functions (as B0), are called bounded fan-in circuits.
The other circuits are called unbounded fan-in circuits.
We say that a family of circuits C = (Cn)n∈N computes a function f :
{0, 1}∗→{0, 1} (or recognizes a language LC ∈{0, 1}∗) if for every n the
circuit Cn computes the restriction of f to Fn. I.e. ∀x ∈{0, 1}∗, C|x|(x) = f(x).
Let C be a circuit, the size denoted size(C) is the number of gates of C. The
depth denoted d(C) is the length of a longest directed path.
A non-deterministic Boolean circuit C with m non-deterministic variables is
a circuit with n + m + 1 sources labelled by {x1, . . . , xn} ∪{y1, . . . , ym} ∪{1}.

404
V. Mogbil and V. Rahli
It computes a function f ∈Fn as follows: for x ∈{0, 1}n, f(x) = 1 iﬀthere
exist a setting of the non-deterministic variables {y1, . . . , ym} which makes the
circuit output 1. We denote C(x, y) the same circuit as C without distinction
between non-deterministic variables and deterministic gates, x ∈LC the lan-
guage recognized by C, if ∃w ∈{0, 1}m a witness s.t. C(x, w) = 1. When needed
we abusively denote C(x) and C(x, y) the distinct circuits.
– Circuit Uniformity –
As brieﬂy presented in the introduction, there are diﬀerent notions of circuit
uniformity [Vol99]. In order to obtain a class containing P, it is necessary to
impose a ”P-uniform” condition on circuit families. That is, the description of
the nth circuit can be provided by a deterministic Turing machine operating
in polynomial time [All89]. But P-uniformity is too weak to deﬁne subclasses
of P; this leads one to consider L-uniformity [Ruz81]: the description is com-
putable in logspace. It is the same when we want to consider the subclass of
NC with O(log n) depth (called NC1): DLOGTIME-uniformity requires a some-
what more careful deﬁnition. Informally, there is a deterministic linear time in
O(log s(Cn)) Turing machine that, given n and a name of a gate g can determine
all the wanted information about gate g (like sort, predecessors, ...) belonging
to the circuit Cn of size s. Unfortunately all these notions are more and more
restrictive.
In our work we focus on a uniform approach of the well established relation-
ship between non-uniform NC and the multiplicative Boolean proof net class
APN. For the sake of simplicity we consider the L-uniformity: it is suﬃcient
to investigate all classes containing L. Actually, only NC1 and constant depth
classes of circuits and proof nets need a uniformity notion stronger than the
L-uniformity. Moreover the NC class remains the same if stronger notions of
uniformity than L-uniformity are used [Ruz81].
The direct connection language of a family C = (Cn)n∈N over basis B, de-
noted LDC(C), is the set of tuples ⟨y, g, p, b⟩, where for y = 1n, we have: g is the
number of a gate v in Cn, and p ∈{0, 1}∗is a binary word such that
- if p = ε then b is the number of the function from B labeling v,
- if p = bin(k) then b is the number of the kth predecessor gate to v.
A circuit family (Cn)n∈N is L-uniform if its direct connection language can
be recognized in logspace by a deterministic Turing machine. Without preci-
sions, we use in the rest of this paper the term uniform as a shorthand for
L-uniform.
– Circuit Classes –
The classes NCi and ACi for i ⩾0 are the functions computable by uniform
families of polynomial size, O(login) depth circuits over B0 and B1 respectively.
ACi(stCONN2) correspond to ACi over B1 ∪{stCONN2}. We denote NC the
uniform circuit families which have polynomial size and polylogarithmic depth,

Uniform Circuits,  Boolean Proof Nets
405
i.e. NC = ∪i⩾0NCi. We deﬁne AC in the same way. L, NL and P are in the
time-space hierarchy of the Turing machines. The well known hierarchy is:
AC0 ⊊NC1 ⊆L ⊆NL ⊆AC1 ⊆NC2 ⊆AC2 ⊆· · · ⊆NC ⊆P
∀i ∈N, ACi ⊆ACi(stCONN2) ⊆ACi+1
The class NNCi(f(n)) is the class of languages accepted by L-uniform-NCi
circuit families with at most O(f(n)) non-deterministic variables, where n is the
length of the input. We deﬁne NACi(f(n)) in the same way, but using ACi. We
abusively denote NNCi(poly) when f(n) is a polynomial function. If f(n) = log n
then the amount of non-deterministic variables can be described by a polynomial
number of NC gates [Wol94]:
NNCi(log n) = NCi, and then NNC(log n) = ∪i⩾0NNCi(log n) = NC.
So we don’t consider these classes but we investigate the following classes [Wol94]:
NNC(poly) = ∪j⩾0NNC(nj) = NP and ∀i ∈N∗, NNCi(poly) = NP.
NAC(poly) = ∪j⩾0NAC(nj) = NP and ∀i ∈N, NACi(poly) = NP.
3
Uniform Boolean Proof Nets
– MLLu and Boolean Type –
We recall in this section some basic deﬁnitions gave by Terui in [Ter04]. The
formulas of MLLu are built on literals by n-ary versions of multiplicative con-
junction and disjunction, for every n ⩾2. The negation of a non-literal formula
is deﬁned by de Morgan’s duality (reversing the order of subformulas).
A sequent of MLLu is of the form ⊢Γ, where Γ is a multiset of formulas. The
rules of MLLu are given in Fig.1(a) with the convention −→
A ≡A1, . . . , An and
←−
A ≡An, . . . , A1.
⊢A, A⊥(axiom)
⊢Γ, C
⊢Δ, C⊥
⊢Γ, Δ
(cut)
⊢Γ, A
⊢Γ, B
⊢Γ, AB

(a)
(b)
⊢Γ1, A1
. . .
⊢Γn, An
⊢Γ1, . . . , Γn, n(−→
A)
n
⊢Γ, An, . . . , A1
⊢Γ, n(←
−
A)
n
⊢Γ, Ai
⊢Γ, A1  A2 i
i=1,2
Fig. 1. (a) MLLu
(a+b) MuALL
The corresponding links (Fig.2(a)) are of three sorts called: axiom-link, n-
link and n-link. Each link has several ports. The ports numbered 0 are called the

406
V. Mogbil and V. Rahli
(a)
(b)
•
0
0

1
n
0

n
1
0

1
2
0
■
1
2
0
1
1
0 2
1
0
Fig. 2. (a) Multiplicative and (b) additive links
principal ports, while others are called auxiliary ports. By convention a principal
port is always written below the link whereas an auxiliary port is above it.
A pseudo net is a triple ⟨L, σ, ∼⟩s.t. L is a ﬁnite set of links, σ : L →
{•} ∪{n, n}n⩾1 and ∼is a symmetric relation on (L, N)2.
A link p with σ(p) = • (n, n, resp.) stands for an axiom-link (n-link,
n-link, resp.). When (p, n) ∼(q, m), we say that there is an edge between
(p, n) and (q, m), where (p, n) stands for the port number n of link p. A cut in
a pseudo net is an unordered pair of link p, q s.t. (p, 0) ∼(q, 0): we call it an
ax-cut when either p or q is an axiom-link, otherwise we call it a m-cut.
A proof net of type ⊢Γ is a pseudo net P inferred by a sequent calculus proof
of ⊢Γ ′ where Γ is a decoration of Γ ′ i.e. formulas of the form p : A (see Fig. 5 for
an example) (a proof net of type ⊢p : A is simply called a proof net of type A) .
The pseudo nets inferred in Fig.3(a) are respectively: tensorp1,...,pn
q
(P1, . . . , Pn),
parpn,...,p1
q
(P) and axp, cutp,q(P, Q).
(a)
(b)
P1
Pn

p1
pn
1
n
0
P

pn
p1
n 1
0
P
Q
p
q
0
0
•
P
Q
■
■

p1
p2
r1
1
r1
k
r2
1
r2
k
r1
rk
q
1 2
1 2
1 2
0
0
0
P
1
p
q
1
0
P
2
p
q
1
0
Fig. 3. (a) Multiplicative and (b) additive proof net constructors
The size |P| is the number of links in P. The depth d(A) of a formula A is given
by d(α) = d(α⊥) = 1 and d(n(−→
A)) = d(n(←−
A)) = max(d(A1), . . . , d(An)) + 1,
with −→
A ≡A1, . . . , An. Given a derivation π of ⊢Γ inferring P, its depth d(π)
is the maximal depth of cut formulas in it. The depth d(P) of a proof net P is
deﬁned to be min{d(π)|π is a derivation of ⊢Γ inferring P for some Γ}.
Boolean values are represented with the type B =3(α⊥, α⊥, 2(α, α)).
There are exactly two cut-free proof nets of this type (true and false resp.)
Fig.4(a): b1 ≡parp,q,r
s
(tensorp,q
r (axp, axq)), b0 ≡parq,p,r
s
(tensorp,q
r (axp, axq)).
A Boolean proof net with n inputs −→p
≡p1, . . . , pn and one output is a
proof net P(−→p ) of type: ⊢p1 : B⊥[A1], . . . , pn : B⊥[An], q : m+1(B, −→
C ), for
some −→
A ≡A1, . . . , An and −→
C ≡C1, . . . , Cm (garbage due to the multiplicative

Uniform Circuits,  Boolean Proof Nets
407
framework) where B[A] denote the formula B where all occurrences of α are
substituted by A. Given −→b ≡bi1, . . . , bin, P(−→b ), of type m+1(B, −→
C ), denotes
the proof net obtained by connecting, ∀j ∈{1, . . ., n} (ij ∈{0, 1}), bij to pj by a
cut. P(−→b ) reduces to a cut-free proof net of the shape tensor(bi, −→
Q), i ∈{0, 1}:
we say that P(−→b ) evaluates to bi. Let w ≡i1 . . . in ∈{0, 1}n. P(−→p ) represents
a function f : {0, 1}n →{0, 1} if P(bi1, . . . , bin) evaluates to bf(w). Thus, the
language accepted by P(−→p ) is f −1(1).
APN i for i ∈N, is the class of languages recognized by non-uniform Boolean
proof net families of polynomial size and O(logi n)-depth. APN= 
i∈N APN i.
– Uniform Proof Nets –
In the framework of polynomial size proof nets, we consider an extended descrip-
tion of a proof net P which is equivalent to the triple deﬁning a pseudo net. We
call it Conf(P), the conﬁguration of P.
Let P = {Pn}n∈N be a family of Boolean proof nets. Links are identiﬁed by
binary words. For all n ∈N, we ﬁx the inputs p1, . . . , pn of Pn to be identiﬁed by
0, . . . , bin(n −1) respectively, and the output to be identiﬁed by bin(n) (where
bin is the function which associates to a number in decimal base its value in
binary base). Conf(P) denotes the set of tuples in {1}∗×(W \{ϵ})×W 2 ×{0, 1}
(W is the set of binary words), s.t. for y = 1n:
– in ⟨y, u, ϵ, ϵ, 1⟩, u identiﬁes a Pn link.
– in ⟨y, u, s, ϵ, 1⟩, s is the sort’s identiﬁer of the link identiﬁed by u.
– in ⟨y, u, v, bin(i), 1⟩, u identiﬁes a link connected by its principal port (or
one of its two principal ports in the case of an axiom) to the port i of the
link identiﬁed by v.
– in ⟨y, u, a, b, 0⟩, u, a, b are the same informations as above but are not con-
cerned with Pn (i.e. the edges which does not appear in Pn).
Remark that if Pn ∈P then Conf(Pn) is the set of tuples that belong to
Conf(P) s.t. the ﬁrst word is of size n. A proof net family {Pn}n∈N of polynomial
size s is L-uniform (resp. P-uniform) iﬀthere is a function which computes
Conf(Pn) from 1n in space O(log s) (resp. in time sO(1)), for all n ∈N. For all
i ∈N, uniform APN i is denoted mBN i.
– Uniform Terui’s Translation of NC –
The conditional (if-then-else, Fig.4(b)) is the base of the Terui’s gates transla-
tions: given two proof nets P1 and P2 of types ⊢Γ, p1 : A and ⊢Δ, p2 : A resp.,
one can build a proof net condp1,p2
r
[P1, P2](q) of type ⊢Γ, Δ, q : B[A]⊥, r : AA.
Given a cut between bi and q we have with the convention that the ﬁrst compo-
nent is considered as the output, the rest being the garbage:
condp1,p2
r
[P1, P2](b1) →∗tensorp1,p2
r
(P1, P2),
condp1,p2
r
[P1, P2](b0) →∗tensorp2,p1
r
(P2, P1).

408
V. Mogbil and V. Rahli
(a)




•
•
••
≡b1
≡b0
(b)
P2
P1
⊗
•
p2
p1
q
r
(c)



•
•
••
•
P
Q
p
q
r
s
Fig. 4. (a) The Boolean b1 and b0 (b) The conditional (c) The composition
Disjunction, conjunction and duplication are based on the conditional: let
n ⩾2 be an integer and C ≡n(B[A1], . . . , B[An]),
or(p1, p2) ≡cond[b1, axp1](p2) of type ⊢p1 : B⊥, p2 : B[B]⊥, q : B  B,
and(p1, p2) ≡cond[axp1, b0](p2) of type ⊢p1 : B⊥, p2 : B[B]⊥, q : B  B,
copyn(p) ≡cond[tensor(−→
b1), tensor(−→
b0)](p) of type ⊢p : B⊥[C], q : C  C.
The composition (Fig.4(c)) of two translated circuits is deﬁned as follows: let
Γ ≡p′
1 : A′
1, . . . , p′
n : A′
n and Δ ≡q′
1 : B′
1, . . . , q′
n : B′
m, let P(−→
p′ ) and Q(−→
q′ ) be
proof nets of type ⊢Γ, p : 1+m(B, −→
C ) and ⊢q : B⊥[A], Δ, r : 1+m′(B, −→
D),
respectively. Then:
compp,q,r
s
[P, Q](−→
p′ , −→
q′ ) is of type ⊢Γ[A], Δ, s : 1+m′+m(B, −→
D, −−→
C[A]).
With this composition one can construct n-ary versions of conjunction and
disjunction. The translation of a Boolean circuit follows from composition of
gate translations and duplication for fan-out management:
Theorem 1 ([Ter04]). For every unbounded fan-in Boolean circuit C of size
s and depth d over the basis B1(stCONN2), there is a Boolean proof net of size
O(s5) and depth O(d), which accepts the same set as C does.
Lemma 1. Let Σ be a ﬁnite alphabet. If g : Σ∗→Σ∗and f : Σ∗→Σ∗are
computable in logspace and the f output is polynomial in its input, then g ◦f is
computable in logspace.
Theorem 2. Let i ∈N. The Terui translation of a Boolean circuit family in
ACi(stCONN2), by a Boolean proof net family in mBNi is logspace.
Remark 1. In order to simplify this result we consider a translation of a circuit
where the garbage of each translated gate is propagated directly to the output
of the proof net. This version is equivalent to the one presented by Terui but in
which some reductions have been performed.
Proof.
Let C = {Cn}n∈N be a L-uniform Boolean circuit family in ACi
(stCONN2). By uniformity, there is a logspace function f s.t. for every n ∈N,
f(1n) = LDC(Cn). Let P = {Pn}n∈N be the Boolean proof net family obtained
by translation of C. We show that there is a logspace function f ′ built from f
s.t. for every n ∈N, f ′(1n) = Conf(Pn). In order to do that, we use a function
fd→c, logspace in the inputs of f, which associates Conf(Pn) to LDC(Cn) for

Uniform Circuits,  Boolean Proof Nets
409
all n ∈N. Let fd→c = f3 ◦f2 ◦f1 where we call module the composition of the
translated gate and its translated fan-out, and (k, j ∈{1, . . ., size(Cn)}):
– f1 copies out its inputs adding to tuples which indicate that a gate v is the
kth predecessor of a gate u, that gate u is the jth successor of gate v.
Then f1 computes for every gate its module composed with a pseudo net
allowing garbage propagation, adding the identiﬁer of the translated gate,
and for each output, an identiﬁer diﬀerentiating it from others.
– f2 copies out and completes the information given by the modules created
by f1 with the help of the information added to LDC(Cn). That is, it adds
information about edges between an output of a module and an input of
another module, with the help of information added about translated gates
and edges between gates.
– f3 organizes tuples and deletes useless information.
LDC(Cn) like Conf(Pn) has a polynomial size. An identiﬁer of a gate or a
link is logspace. At each step, these functions memorize a constant number of
identiﬁers, so f1, f2 and f3 are logspace. Then fd→c is logspace. By lemma 1,
f ′ = fd→c ◦f is logspace in the inputs of f.
□
– Parallel Cut-Elimination –
The elimination of a cut between two axioms cannot always be performed in
parallel. So K. Terui considers another reduction step named tightening reduction
which reduces a maximal sequence of cut axioms to an axiom. Such maximal
sequence (ax-sequence) is deﬁned as a set of axioms, each linked with another
in this set s.t. there are not other axioms that verify this property.
If Q is obtained from P by elimination of all ax-cuts simultaneously (m-cuts,
ax-sequences, resp.) then we write P ⇒ax Q (P ⇒m Q, P ⇒t Q, resp.). We
write P ⇒Q if P ⇒ax Q or P ⇒m Q or P ⇒t Q.
Theorem 3 (parallel cut-elimination, [Ter04]). There is a sequence of par-
allel reductions P ⇒P1 · · · ⇒Pk, s.t. Pk is cut-free and k ⩽3 × d(P).
– Uniform Terui’s Simulation in NC –
We consider proof nets with links belonging to a ﬁxed set L0 with the convention
n-link is of sort , and a n-link is of sort . A conﬁguration Θ consists of the
following Boolean values : alive(p), sort(p, s), edge(p, 0, q, i), for every p, q ∈L0,
s ∈{•, , } and i < |L0|.
A link p ∈L0 is said to be alive in Θ if alive(p) = 1. Given a proof net P =
⟨L, σ, ∼⟩, we write Θ ∈Conf(P) if for every p ∈L0, alive(p) = 1 ⇐⇒p ∈L
and for every alive links p, q in Θ, the following holds : sort(p, s) = 1 ⇐⇒σ(p)
is of sort s and edge(p, 0, q, i) = 1 ⇐⇒(p, 0) ∼(q, i).
Lemma 2 ([Ter04]). There is an unbounded fan-in Boolean circuit C of size
O(|P0|3) and constant depth with stCONN2 gates s.t. whenever Θ ∈Conf(P) is
given as input of C and P ⇒P’, it outputs a conﬁguration Θ′ ∈Conf(P ′).

410
V. Mogbil and V. Rahli
Theorem 4 ([Ter04]). For every Boolean proof net P of size s and depth d,
there is a Boolean circuit C over the basis B1(stCONN2) of size O(s4) and depth
O(d) which accepts the same set as P does.
Theorem 5. Let i ∈N. The Terui simulation of a Boolean proof net family in
mBN i by a Boolean circuit family in ACi(stCONN2), is logspace.
Proof. Let P = {Pn}n∈N be a L-uniform Boolean proof net family in APN i. By
uniformity there is a logspace function f s.t. for all n ∈N, f(1n) = Conf(Pn).
Let C = {Cn}n∈N be the Boolean circuit family obtained by simulation of P.
We show that there is a logspace function f ′ built from f s.t. for every n ∈N,
f ′(1n) = LDC(Cn). In order to do that, we use a function fc→d, logspace in the
inputs of f, which associates LDC(Cn) to Conf(Pn) for all n ∈N. The simulation
introduced by Terui is divided in three steps: creation of initial conﬁguration,
simulation of parallel cuts elimination and check of the the last conﬁguration.
– fc→d builds the part of the ﬁrst conﬁguration which represents the inputs
of the proof net using the inputs of the Boolean circuit. It builds the part
which represents the proof net using its input. Only a constant number of
identiﬁers of links are memorized.
– fc→d builds the circuit which simulates parallel cuts elimination. This part is
only dependent of the size and depth of the proof net and not of its structure.
– fc→d builds the circuit which check the result contained in the last conﬁgu-
ration. This building is only dependent of the size of the proof net.
Conf(Pn) like LDC(Cn) has a polynomial size. An identiﬁer of a gate or a link
is logspace. At each step, fc→d memorizes a constant number of identiﬁers, so it
is logspace. By lemma 1, f ′ = fc→d ◦f is logspace in the inputs of f.
□
Corollary 1. mBN = NC and P is the class of those languages for which there
is a uniform polynomial size family of (multiplicative) Boolean proof nets.
4
Non-deterministic Boolean Proof Nets mBN ()
In this section we introduce the unbounded fan-in version of multiplicative lin-
ear logic (MLLu) extended with the binary additive connectives. We denote it
MuALL. The formulas of MuALL are built from literals by MLLu connectives
and by binary additive conjunction  and additive disjunction . The sequent
calculus rules are given in Fig.1(a+b).
The added links are called -link, 1-link and 2-link (Fig.2(b)). The infer-
ence rules for the new links follow the sequent calculus rules as expected. The
resulting proof nets are depicted in Fig. 3(b). In a derivation, the two premises
of a -rule, with the same context Γ, infer two proof nets called components.
Each identical conclusion coming from the two components are merged with a
binary co-additive-links (denoted ■-links or coad-links). So a -link arrives with
an additive box bounding a (possibly empty) set of coad-links and the two com-
ponents. This is described in Fig.3(b) with the associated ports. As previously
the cuts are just edges between principal ports.

Uniform Circuits,  Boolean Proof Nets
411
– Slices and Additive Cut-Elimination –
A slice of a proof net P is a proof net sl(P) which may contain some unary
1 and 2 links: for every -link one of the premises is chosen. Then the non-
corresponding component, the additive box and the coad-links are erased. In a
slice, the additive cut-elimination between a i-link and a j-link, for i, j ∈
{1, 2}, is simply to check the consistency: if i = j then the additive links are
removed propagating the cut on the unique premises.
We deﬁne as usual [Gir87] the additive cut-elimination, denoted →a. The cut-
elimination between a -link and a i-link (i ∈{1, 2}) is the choice of the ith
-link’s premise and the same erasing as a slice. A cut-elimination with a coad-
link is more complicated: the cut proof net is swallowed and duplicated in the
additive box. The duplicated conclusions are merged with coad-links.
The cut-elimination with a coad-link is not conﬂuent. A standard example
is the proof net of type ⊢AA, A⊥, cut to the proof net of type ⊢A⊥A⊥, A.
This produces two possible proof nets of type ⊢AA, A⊥A⊥where the -link
of the additive box is one of the formulas, the other being a coad-link. Nevertheless
the proof nets are stable by cut-elimination [Dan90, Tor03]. Roughly speaking if
the conclusions of the proof nets are -free then the cut-elimination is conﬂuent.
– Parallel Reduction Theorem –
It is diﬃcult to have an additive cut-elimination from a parallel point of view
(denoted ⇒a). We need a strategy e.g. as the parallel tightening reduction, one
could want to reduce ﬁrst the -links in parallel. But it is diﬃcult to bound
the number of parallel reduction steps because of the coad-links (it depends
on maximal nesting of the additive boxes it contains). In the non-deterministic
Boolean proof nets framework, it is somewhat diﬀerent as explained after in
lemma 3: proof nets are always cut against an additive witness s.t. this cut is
eliminated equivalently to a slice choice. So we start the parallel reductions by
choosing a slice, then additive cut-elimination becomes trivial and conﬂuent:
⇒a is only the disjoint consistency check done in parallel. We write ⇒if one of
the parallel reduction occurs (i.e. ⇒t, ⇒ax, ⇒m or ⇒a). Because in a slice each
sequence of all distinct parallel reductions strictly decrease the depth, we have:
Theorem 6 (parallel cut-elimination). For every consistent slice sl, there
is a sequence of parallel reductions sl(P) ⇒P1 ⇒· · · ⇒Pk s.t. Pk is cut-free
and k ⩽4 × d(P) + 1.
– Extended Boolean Type for Non-Deterministic Variables –
We deﬁne a non-deterministic Boolean type as Be = (Bα⊥), (αα). There are
four proof nets of this (yet strange) type. Two of them have the same behavior
as the (deterministic) Boolean type B. The two others can be arbitrarily used
for our purpose: let the proof net depicted in Fig.5 be our choice of one of them.
With this proof net we are able to internally choose between b0 or b1 using a slice
or equivalently by cut elimination with a witness as explained in the beginning
of this section. Without loss of generality, for an arbitrary C, we allow an input

412
V. Mogbil and V. Rahli
...
⊢B
⊢α, α⊥(ax)
⊢B  α⊥, α
()
...
⊢B
⊢α, α⊥(ax)
⊢B  α⊥, α
()
⊢B  α⊥, αα
()
→



b0
b1
■
Fig. 5. From a sequent calculus proof of Be to the chosen proof net
type to be of the form Be[C] = Be[B[C]/B, id/α] = (B[C]  id⊥)(idid)
where id = αα⊥is a technical trick to simplify reductions in the translation
and in the simulation.
– mBN () Description and Hierarchy –
A non-deterministic Boolean proof net with n inputs and O(f(n)) additive links
is a proof net P(−→b ) of type (for some −→
D = D1, . . . , Dk and m = f(n)):
⊢p1 :B⊥[A1], . . . , pn :B⊥[An], q:1+k+m(B, −→
D, −→
id), r:m(
−−−−−−→
id⊥id⊥).
Clearly, for w a proof net of type m(−−−−→
id  id) and −→b ≡bi1, . . . , bin (∀j ∈
{1, . . ., n}, ij ∈{0, 1}), the proof net cut(P(−→b ), w) reduces to a cut-free proof
net of type 1+k+m(bi, −→
D, −→
id) (i ∈{0, 1}): we say that P(−→b ) evaluates to bi if
there exists such a w. The language accepted by a non-deterministic Boolean
proof net is deﬁned in the same way as for Boolean proof nets in section 3.
Similarly to the Terui APN hierarchy and to the NNC() hierarchy, we deﬁne
the mBN () hierarchy: a uniform family (Pn)n∈N of non-deterministic Boolean
proof nets accepts a language X ⊆{0, 1}∗if Pn is n-ary and accepts X ∩{0, 1}n
for every n ⩾1. A language X ⊆{0, 1}∗belongs to the class mBN i(poly) iﬀX
is accepted by a uniform polynomial size, logi-depth family of non-deterministic
Boolean proof nets with a polynomial number of additive links.
5
NNC(poly) = mBN (poly)
In order to obtain the equality between NNC(poly) and mBN (poly), we use
the class NAC(poly) whose relations with NNC(poly) were described in section 2.
– Translation of NAC(poly) –
Let C(x) be a circuit of input length n belonging to a family in NACi(poly)
for an arbitrary i ∈N. By deﬁnition C(x, y) and C(x) have the same di-
mensions and m =| y |= nO(1). Thus C(x, y) ∈ACi w.r.t. the size of x,
if we just omit the distinction between non-deterministic variables and deter-
ministic variables. As in [Ter04] (see section 3) let P be the translation of
C(x, y). For each y we cut the builtproof net P with exactly one represen-
tation of Be. We manage the garbage as it can be seen in Fig.6 to obtain the

Uniform Circuits,  Boolean Proof Nets
413
P








b0
b1
■



b0
b1
■
Fig. 6. Translation
proof net T . Such translated proof net is in mBN i(poly). Let sl be a slice of
T . We have the following parallel reduction from sl(T ):
P





i1

bi1
im

bim
⇒m ⇒ax
P



bi1
bim
i1
im
⇒∗
B
−→
D


i1
im
Another way could be to choose a witness w, i.e a proof net of type m(−−−−→
id  id),
and then to reduce the cut between T and w. By only one additive parallel reduc-
tion we obtain conﬂuently a multiplicative proof net: it corresponds to C(−, w).
From the translation it immediately holds that to have a slice or a witness is equiv-
alent in this setting, as is stated in this lemma:
Lemma 3. Let C ∈NAC(poly) be a circuit family and let P = (Pn)n∈N be the
uniform non-deterministic Boolean proof net family obtained by the translation
of C. Let C(x, y) ∈AC be the deterministic circuit family corresponding to C
s.t. |y|= m. We have x ∈LC, the language recognized by C
⇐⇒∃w ∈{0, 1}m a witness s.t. Cn(x, w) = 1
⇐⇒∃sl a slice of Pn s.t. sl(Pn(x)) ⇒∗1+n+m(b1, −→
D, −→
α ), 1⩽j⩽m(ij(α))
⇐⇒∃w a witness of type m(−−−−→
id  id) s.t. cut(Pn(x), w) ⇒∗1+l+m(b1, −→
D, −→
id)
⇐⇒x ∈LP , which is the language recognized by P
Theorem 7 (translation). Let i ∈N. For every Boolean circuit C ∈NACi(poly)
of size s and depth d, there is a Boolean proof net in mBN i(poly) of size O(s5)
and depth O(d) which accepts the same set/language as C does.
Proof.
Let C ∈NACi(poly) be a circuit of input length n. Let s = size(C) and
d = d(C). Let m =|y|= nO(1) ⩽s be the amount of non-deterministic variables.
Following Terui’s theorem, every gate of fan-in f and fan-out o can be encoded by
a proof net of size O(f 4 + o) ⩽O(s4) and of constant depth. The depth increase
is linear in d. Because C(x, y) and C have the same dimensions, we obtain the
same result as Terui. The last construction due to the non-deterministic variables
translation doesn’t change the proof net dimensions: we add O(m + s) links and
a constant to the depth.
□

414
V. Mogbil and V. Rahli
– Cut-Elimination Simulation –
Let P ∈mBN i(poly) be a proof net of size s and depth d. Let NACi(poly)
(stCONN) corresponds to NACi(poly) over B1 ∪{stCONN}. In order to have a
corresponding non-deterministic circuit C ∈NACi(poly)(stCONN), we represent
P by a set of Boolean values: the conﬁgurations that we extend to take care
of additive sorts and a box(p, q) relation to describe that p is associated to the
additive box of the -link q. After that in the same way as [Ter04] (see section 3),
the cut-elimination in P is simulated by the construction of layers of a circuit for
each parallel cut-elimination step s.t. the evaluation of the constructed circuit C
simulates the cut-elimination procedure. For simplicity we describe it following
the parallel reductions as in lemma 3 with the help of non-deterministic variables,
one for each link of the proof net:
– The circuit simulates the choice of a slice (its edges) s.t. every distinct choice
can be done in parallel, depending on the non-deterministic variables:
- selection of one premise for each -links, with the help of a constant
depth circuit of size O(s3),
- selection of one premise for each coad-links depending on the selected
premise of the associated -links, with the help of a constant depth
circuit of size O(s4). Moreover we ”erase” the coad-links themselves: by
updating the alive value of a coad-link and the edge values concerning
its incident edges and by linking the premise and the conclusion of a
coad-link, with the help of a constant depth circuit of size O(s5),
- selection of one component associated to each -links using a stCONN
gate, with the help of a constant depth circuit of size O(s4).
– The cut between a witness (depending on the non-deterministic variables)
and the modiﬁed slice is reduced in a known result due to our choice of the
id type. This is done by a constant depth circuit of size O(s5).
– Finally as many time as 4×d(P)+1 we simulate one parallel reduction of the
modiﬁed slice (⇒, in the same way as in [Ter04] with the help of a constant
depth circuit of size O(s3) that simulate ⇒a). We check consistency at each
step with the help of a constant depth circuit of size O(s3).
The most essential cost is due to the erasing of the coad-links and the elim-
ination of the cut between a witness and a slice of a Boolean proof net. Each
small circuit used here can be found in the appendix with precise depth and size.
Theorem 8 (simulation). Let i ∈N. For every Boolean proof net P
∈
mBN i(poly) of size s and depth d, there is a Boolean circuit in NACi(poly)
(stCONN) of size O(s5) and depth O(d) which accepts the same set/language as
P does.
Since the considered non-deterministic circuit class collapse we can replace
NACi(poly)(stCONN) by NACi(poly) in the previous theorem.

Uniform Circuits,  Boolean Proof Nets
415
6
Conclusion
Focusing on uniformity, we strengthened the connection between proof nets and
deterministic Boolean circuits by giving a uniform depth-preserving simulation
of each other. This kind of Curry-Howard isomorphism for models of parallel
computation as been extended to the non deterministic case. Because the uni-
formity arguments apply to the translation and simulation theorems, we have:
Theorem 9. ∀i ∈N, mBN i(poly) = NACi(poly) = NP.
Corollary 2. mBN (poly) = NNC(poly) = NP.
The substitution on the non-deterministic Boolean type Be deals with id to
simplify the general case which can also be treated without diﬃculties. The
most simple form of non-deterministic Boolean is 1  1 i.e. just replace id =
αα⊥by 1: the semantic is clearly the same but the fragment of linear logic
considered is extended to neutrals. Even without this, the Boolean proof nets
of type ⊢B⊥, . . . , B⊥, B. . . B are in a way canonical (up to substitutions)
but the simulation is more complicated. A more general work can be done using
the additive fragment expressiveness fully: a garbage is no more needed but the
cut-elimination is no more conﬂuent. Other approaches are interesting like the
additives `a la Hughes and van Glabbeek [HvG03, HvG05]: we believe to realize
a stronger seed-up.
References
[All89]
Eric W. Allender. P-uniform circuit complexity. Journal of the Association
for Computing Machinery, 36(4):912–928, 1989.
[BIS90]
David A. Mix Barrington, Neil Immerman, and Howard Straubing. On uni-
formity within NC1. J. of Comput. and System Science, 41(3):274–306, 1990.
[BS90]
R. B. Boppana and M. Sipser. The complexity of ﬁnite functions. MIT Press,
1990.
[CK06]
S. Cook and J. Krajicek. Consequences of the provability of NP⊆P/poly,
2006.
[Dan90]
V. Danos. La logique lin´eaire appliqu´ee `a l’´etude de divers processus de nor-
malisation (et principalement du λ-calcul). PhD thesis, Univ. Paris VII, 1990.
[DR89]
Vincent Danos and Laurent Regnier.
The structure of multiplicatives.
Archive for Mathematical Logic, 28(3):181–203, 1989.
[Gir87]
Jean-Yves Girard. Linear logic. Theor. Comput. Sci., 50(1):1–102, 1987.
[HvG03]
D. J. D. Hughes and R. J. van Glabbeek.
Proof nets for unit-free
multiplicative-additive linear logic. In Proc. IEEE Logic in Comput. Sci., 2003.
[HvG05]
D. J. D. Hughes and R. J. van Glabbeek.
Proof nets for unit-free
multiplicative-additive linear logic. ACM Trans. on Comput. Logic, 2005.
[KL80]
R. Karp and R. Lipton. Some connections between nonuniform and uniform
complexity classes.
In Proc. 12th ACM Symp. on Theory of Computing,
pages 302–309, 1980.
[LdF04]
O. Laurent and L. Tortora de Falco. Slicing polarized additive normalization.
Linear Logic in Computer Science, 2004.

416
V. Mogbil and V. Rahli
[MT03]
H. Mairson and K. Terui.
On the computational complexity of cut-
elimination in linear logic. Theoretical Computer Science, 2841:23–36, 2003.
[Ruz81]
W. Ruzzo.
On uniform circuit complexity.
J. of Computer and System
Science, 21:365–383, 1981.
[Ter04]
K. Terui. Proof nets and boolean circuits. In Proc. IEEE Logic in Comput.
Sci., pages 182–191, 2004.
[Tor03]
L. Tortora De Falco. Additives of linear logic and normalization - part i: a
(restricted) church-rosser property. T.C.S., 294(3):489–524, 2003.
[Ven92]
H. Venkateswaran. Circuit deﬁnitions of nondeterministic complexity classes.
Siam J. Comput., 21(4):655–670, 1992.
[Vol99]
H. Vollmer. Introduction to Circuit Complexity – A Uniform Approach. Texts
in Theoretical Computer Science. Springer Verlag, 1999.
[Wol94]
Marty J. Wolf. Nondeterministic circuits, space complexity and quasigroups.
Theoretical Computer Science, 125(2):295–313, 1994.
A
Some Corollaries
As a corollary for the theorem 7, we have:
Corollary 3. For every Boolean circuit C ∈NNCi(poly) of size s and depth d
there is a Boolean proof net in mBN (poly) of size O(s5) and depth O(d) which
accept the same set/language as C does.
The most essential cost of the simulation of a Boolean proof net in mBN i(poly)
(i ∈N) by a boolean circuit in NNCi(poly), is due to the translates of stCONN
gates (a log-depth circuit of size O(n4) for a n-ary gate). Thus as a corollary for
the theorem 8, we have:
Corollary 4. For every Boolean proof net P ∈mBN i(poly) (i ∈N) of size
s and depth d, there is a Boolean circuit in NNCi+2(poly) of size O(s12) and
depth O(d) which accepts the same set/language as P does.
B
Non-deterministic Simulation
In this section, we adopt these conventions:
– alive(p) is write p
– sort(p, s) is write p(s)
– edge(p, 0, q, i) is write (p, q, i)
The circuit on Fig. 7, depicts the selection of one premise of a -links. The
two ouputs are the new values for the edge values. This circuit is realized for
all links p, q and r. For all links p and q, the new value of an edge(p, 0, q, 1) or
an edge(p, 0, q, 2) value corresponds to the conjunction of its values at ouputs of
these circuits. We obtain a circuit (named Sg) of size n3j and constant depth,
with nj the number of links.
It is the same for the selection of one premise of a coad-links (Fig. 8), but it
depend on the selected premise of the associated -links. The two ouputs are

Uniform Circuits,  Boolean Proof Nets
417
Gp
(q, p, 1)
(r, p, 2)
p(/)
∧
¬
¬
∧
∧
∧
∧
∨
∨
Fig. 7. Selection of one premise of a -link
Gt
(q, p, 1)
(r, p, 2)
box(p, t)
∧
¬
¬
∧
∧
∧
∧
∨
∨
Fig. 8. Selection of one premise of a coad-link
the new values for the edge values. This circuit is realized for all links p, q, r and
t. For all links p and q, the new value of an edge(p, 0, q, 1) or an edge(p, 0, q, 2)
value corresponds to the conjunction of its values at ouputs of these circuits. We
obtain a circuit of size n4j and constant depth, with nj the number of links.
The circuit on Fig. 9, depicts the erasing of information on unary coad-links.
This circuit is realized for all links p, q, r, t and i. First, the new value of
a edge value corresponds to the disjunction of its values at the ﬁrst output
(edge(q, 0, t, i) on the Fig. 9) of these circuits. Second, the new value of an edge,
a box, or an alive value corresponds to the conjunction of its values at the ﬁve
(q, t, i)
box(p, r)
(q, p, 1)
(q, p, 2)
(p, t, i)
p
∨
∧
¬
∨
∧
∧
∧
∧
∧
(q, t, i)
box(p, r)
(q, p, 1)
(q, p, 2)
(p, t, i)
p
Fig. 9. Erasing of a unary coad-link

418
V. Mogbil and V. Rahli
Sg
(r, q, i)
the entire proof net, p: the ﬁrst vertices and r: the last
stCONN(p, r)
¬
∧
∧
∨
¬
∧
∀q, r, i
initial value
new value
←
↑
used ∀
p,
(p, , ),
( , p, )
-1-
-2-
-3-
Fig. 10. Erasing of a useless component in a slice
p q t u v
p()q() t()u(•) v(•) (u, v, 0)(u, p, 1)(v, p, 2)(p, q, 1)(p, q, 2)
(q, t, i)
(t, w, i)
∧
∧
∧
∨
∨
∀i
∨
∀w, i
¬
∧
¬
∨
∧
∧
(u, v, 0) (u, p, 1)
(v, p, 2)
Fig. 11. Fast cut-elimination of a witness cut to a boolean proof net
p()
q(1)
(t, p, 2)
(p, q, 0)
∧
∨
¬
∧
∀p, q, t
old value
new value
Fig. 12. Check of consistency property

Uniform Circuits,  Boolean Proof Nets
419
last outputs of these circuits and at the output just created. We obtain a circuit
of size n5j and constant depth, with nj the number of links.
The circuit on Fig. 10, depicts the erasing of the useless components of each
additive box. The part above the mark -2- is realized for all links q, r and i. This
circuit above the mark -3- is realized for all links p. The new value of an edge or an
alive value corresponds to the conjunction of its values at ouputs of these circuits.
We obtain a circuit of size n4j and constant depth, with nj the number of links.
Since the cut between a witness and the modiﬁed slice is reduced in a known
result, the following circuit on Fig. 11 depicts elimination of this cut. This circuit
is realized for all links p, q, t, y and v. For all links p and q, the new value of
an edge(p, 0, q, 1) or an edge(p, 0, q, 2) value corresponds to the conjunction of
its values at ouputs of these circuits. For an edge(p, 0, q, 0) value, we realize a
disjunction. We obtain a circuit of size n5j and constant depth, with nj the
number of links.
The circuit on Fig. 12 allows to check consistency of a slice. It is of size n3j
and constant depth, with nj the number of links.
C
Some Proofs
– Descriptions of Proof Nets –
The description of a Boolean proof net (the triples deﬁning a pseudo net intro-
duced in section 3.3) can expressed as following:
Deﬁnition 1 (triple(P)). Let P = {Pn}n∈N be a family of Boolean proof nets.
Links are identiﬁed by binary numbers. For all n ∈N, we ﬁx the inputs p1, . . . , pn
of Pn to be identiﬁed by O, . . . , bin(n −1) respectively, and the output to be
identiﬁed by bin(n). triple(P) denotes the set of tuples in {1}∗×(W \ {ε})×W 2
(where W is the set of binary words), s.t. for y = 1n:
• ⟨y, u, ϵ, ϵ⟩, u identiﬁes a link belonging to Pn.
• ⟨y, u, s, ϵ⟩, s identiﬁes the sort of the link identiﬁed by u.
• ⟨y, u, v, bin(i)⟩, u identiﬁes a link connected by its principal port (or one of
its two principal ports in the case of an axiom) to the port i of the link
identiﬁed by v.
Let Pn be a Boolean proof net belonging to the family {Pi}i∈N. We’ll show
that there exists a function f computable in space O(log(n)), which associates
Conf(Pn) to 1n iﬀ. there exists a function g computable in space O(log(n)),
which associate triple(Pn) to 1n. In order to do that, we will use two function h
and h′, both logspace in n, which associate respectively triple(Pn) to Conf(Pn)
and Conf(Pn) to triple(Pn).
For every tuple belonging to its input, h write this tuple, without its last
word, on its ouput, if the last word is 1.
The function h′ handles the links by decreasing order on their identiﬁers,
after having found the biggest identiﬁer amoung the tuples ⟨, , ϵ, ϵ⟩, t. For all

420
V. Mogbil and V. Rahli
identiﬁer of link i ∈{0, . . ., t}, if the tuple ⟨, i, ϵ, ϵ⟩is in the input of h′, it copy
out on its output with the ﬁfth word 1, else with 0. It works similarly for the
tuples whose the forth word is ϵ (or none of the four).
Functions h and h′ memorize a constant number of tuples, of identiﬁer of links
and of counters of size logspace in n.
– Proof of Lemma 1 –
Proof. We don’t want to memorize the output of f on a input w. We have to
notice that at each step of the computation of g on f(w), it’s necessary to read
only one bit of f(w). Thus, it’s suﬃcient to maintain a counter (on the binary
base) of size O(log(n)) (where n is the size of w), because of the polynomial size
of the output of f. Then, we simulate the computation of g, in space O(log(n)),
on the input f(w) without write it entirely. Each time we need to read a bit, we
use a space O(log(n)) to ﬁnd it. Hence, we use a space O(log(n)) to compute
g ◦f.
□
– Proof of Theorem 6 –
Proof.
As in a multiplicative framework, only elimination of ax-cuts cannot
be performed in parallel in a slice of a proof-net built with multiplicative and
additive links. Hence, we’ll show that the sequence ⇒t; ⇒ax; ⇒a; ⇒m decrease
the depth a slice of a proof-net. Let P be a proof-net and sl(P) one of its
consistent slice.
– Let Q such that sl(P) ⇒t Q. If the only one cuts of sl(P) are some cuts
of ax-sequences, they are all removed. Then, the depth of Q is 0 which if
less or equal to the depth of sl(P). Else, there exist some other cuts in
sl(P). Let π be any sequentialization of sl(P)). Let {A1, . . . , Ak} (where
k ∈N), the set of ax-sequences of sl(P). For all i ∈{1, . . . , k}, the formulae
(of depth pi) associates to the ports of the axiom which substitute the ax-
sequence Ai are the same than those of any axiom in this ax-sequence. Let
p = max(p1, . . . , pk). After reduction of all the ax-sequences, the depths of
the cut-formulae (which are not between two axioms) in π remain unchanged.
If the maximal depth (q) of cuts (we deﬁne the depth of a cut as the depth of
formulae associated to the ports of the links connected by this cut) in sl(P),
which are not cuts between two axioms, is less than p, then the depth of Q
is q < p = d(sl(P)). Else, the depth of Q is the same than the one of sl(P):
q ≥p.
– Let R such that Q ⇒Ax R. If the only one cuts of Q are ax-cuts, they are all
removed. Then, the depth of R is 0 which if less than the depth of Q (since
these cuts are between two links whose one is not an axiom, see below).
Else, there exist some other cuts in Q. Let π be any sequentialization of Q.
Let {v1, . . . , vk} (where k ∈N), the set of axioms which are cut to other
links than an axiom in Q. For all i ∈{1, . . . , k}, let v1
i and v2
i be the two
principal ports of vi. Let vi cut by its port v1
i to the principal port u0
i of a
link ui (its only one principal port because ui cannot be an axiom). Let wi
the link connected to vi by v2
i . In π, the formula associated to u0
i is the same

Uniform Circuits,  Boolean Proof Nets
421
than the one associated to v2
i , the dual of the one associated to v1
i . So, they
are the same depth pi. Let p = max(p1, . . . , pk). The elimination of this cut
remove, for all i ∈{1, . . . , k}, vi and connect wi to ui. So, after elimination
of all the ax-cuts, the depths of cut-formulae (those which are not ax-cuts)
in π remain unchanged. If the maximal depth (q) of cuts in Q, which are not
ax-cuts, is less than p, then the depth of R is q < p = d(Q). Else, the depth
of R is the same than the one of Q: q ≥p.
– R do not contain cuts involving axioms any more. The only one cuts of R
are m-cuts or additive cuts.
• Let S such that R ⇒a S. Let R contain m m-cuts and n additive cuts.
Let π be any sequentialization of R. An additive cut between two additive
links, in a consistent slice of a proof net, whose the formulae associated
to their principal ports in π are i(A) and i(B, C) (i ∈{1, 2}) is
replaced by a cut between two links whose the formulae associated to
the principal ports connected by the cut in π are A and B or A and
C. The deepest formulae in π (p be the greatest depth) are formulae
associate to m-cuts or formulae F1 ∈{i1(A1), 1(B1, C1)}, . . . , Fk ∈
{ik(Ak), ik(Bk, Ck)}, where 0 ≤k ≤n and ∀j ∈{1, . . ., k}, ij ∈
{1, 2}. The set of deepest cut-formulae contain now the formulae Ai, Bi
or Ai, Ci, for all i ∈{1, . . ., k}), of depth p−1, which are cut-formulae. In
π, an additive cut of depth p generate cuts of depth at most p −1 (since
i(A) or i(B, C) (i ∈{1, 2}) are formulae of depth d(A) + 1). The
other cuts, of depth q < p, generate cuts of depth at most q −1 < p −1.
• Let T such that S ⇒m T . Let π be any sequentialization of S. By
the previous item, the deepest cut-formulae are formulae in π, asso-
ciate to m-cuts. A m-cut between two links whose the formulae asso-
ciate to their principal ports in π are (−→
A) and (←−
B), is replaced by
n cuts between pairs of links whose formulae in π associate to ports
connected by cuts are Ai and Bi, for all i ∈{1, . . . , n} where n ∈
N. The deepest cut-formulae in π (p be the greatest depth) are F1 ∈
{k1(A1
1,. . ., Ak1
1 ), k1((Ak1
1 )⊥,. . ., (A1
1)⊥)}, . . . , Fr ∈{kk(A1
r,. . ., Akr
r ),
kr((Akr
r )⊥, . . . , (A1
r)⊥)}, where r ∈N and ∀j ∈{1, . . ., r}, kj ∈N.
Then, The deepest cut-formulae are some formulae Aj
i, (Aj
i )⊥where
i ∈{1, . . . , r} and j ∈{1, . . . , kr}, of depth p −1. In π, a cut of depth
p generate some cuts of depth at most p −1. Moreover, there exit at
least one cut at this depth since (−→
A) or (←−
B) (n ∈N) are formu-
lae of depth max(d(A1), . . . , d(An)) + 1, so there exist a j ∈{1, . . . , n}
such that Aj = max(d(A1), . . . , d(An)). The other cuts of depth q < p
generate cuts of depth at most q −1 < p −1.
□

Finite Automata Presentable Abelian Groups⋆
Andr´e Nies1 and Pavel Semukhin2
1 Department of Computer Science, University of Auckland, New Zealand
andre@cs.auckland.ac.nz
2 Department of Computer Science, University of Auckland, New Zealand
pavel@cs.auckland.ac.nz
Abstract. We give new examples of FA presentable torsion-free abelian
groups. Namely, for every n ⩾2, we construct a rank n indecomposable
torsion-free abelian group which has an FA presentation. We also con-
struct an FA presentation of the group (Z, +)2 in which every nontrivial
cyclic subgroup is not FA recognizable.
1
Introduction
The study of ﬁnite-automata (FA) presentable, or automatic, structures began in
the works by Hodgson [5,6] and then carried on in Khoussainov and Nerode [7]. A
structure is called FA presented if its domain and atomic relations are recognized
by ﬁnite automata operating synchronously on their input. So, these structures
have ﬁnite presentations. The class of automatic structures is of special interest
in the ﬁeld of theoretical computer science. One of the reasons for this is that
the ﬁrst-order theory of an FA presentable structure is decidable, and in fact
the model checking problem is decidable. For instance, Hodgson [5,6] was the
ﬁrst to use this property to give a new proof of the decidability of Presburger
arithmetic Th(N, +).
There is a complete description of FA presentable structures in the classes of
Boolean algebras [9] and well-ordered sets [3], but for another classes of struc-
tures such as groups, rings, linear orders, etc., the situation is far from clear. For
example, it is unknown whether the group of rationals under addition has an FA
presentation. In [8] Khoussainov and Rubin posed the problem of characterizing
automatic abelian groups (Problem 4).
In this paper we describe a new method for constructing FA presentable
abelian groups and monoids using the notion of amalgamated product. We show
that under certain conditions the amalgamated product of FA presentable groups
or monoids is itself FA presentable. We then use this method to give new ex-
amples of FA presentable torsion-free abelian groups. The only known examples
of such groups were (Z, +), (Rp, +) (the group of rationals with denominators
powers of p), and their ﬁnite direct products. Our examples are indecomposable
and strongly indecomposable torsion-free abelian groups.
⋆This research was partially supported by the Marsden Fund of New Zealand, grant
no. 03-UOA-130.
S. Artemov and A. Nerode (Eds.): LFCS 2007, LNCS 4514, pp. 422–436, 2007.
c
⃝Springer-Verlag Berlin Heidelberg 2007

Finite Automata Presentable Abelian Groups
423
In the last section we will construct an FA presentation of the group (Z, +)2
which is new in the sense that any nontrivial cyclic subgroup in that presentation
is not FA recognizable.
We now give formal deﬁnitions that will be used in this paper.
Deﬁnition 1.1. Let Σ be a ﬁnite alphabet, and ¯a = (a1, . . . , ak) be a tuple of
words from Σ∗. A convolution of ¯a is a word in alphabet (Σ ∪{□})k which
is constructed by placing the words a1, . . . , ak one under another and adding a
special symbol □at the end of the words to get the same length. For example,
Conv(01, 1011, 100) =
0 1 □□
1 0 1 1
1 0 0 □
A convolution of a relation R ⊆(Σ∗)k is deﬁned as Conv(R) = {Conv(¯a) :
¯a ∈R}.
Deﬁnition 1.2. A relation R ⊆(Σ∗)k is FA recognizable, or regular, if
Conv(R) is recognized by a ﬁnite automaton.
Deﬁnition 1.3. A structure A = (A; R1, . . . , Rn, f1, . . . , fm) is FA presented
if, for a ﬁnite alphabet Σ, A ⊆Σ∗is an FA recognizable set of word in Σ∗, and
all the relations R1, . . . , Rn together with the graphs of operations f1, . . . , fm are
recognized by ﬁnite automata.
A structure A is FA presentable if it is isomorphic to an FA presented
structure.
In some cases to prove that a given structure is FA presentable we will not
construct its automatic presentation explicitly. Instead we give its ﬁrst-order
interpretation in a structure already known to be FA presented. The description
of this method together with formal deﬁnitions and proofs can be found in [2].
2
An FA Presentation of the Group Rp
Deﬁnition 2.1. Let Rp be the subgroup of (Q, +) consisting of elements of the
form k/pi.
In the literature Rp is also denoted by Q(p) (for example, see [4]) or Z[1/p]. The
next theorem shows that Rp is FA presentable, and we will use this particular
presentation of Rp in section 5 to construct new examples of FA presentable
abelian groups.
Theorem 2.1. Rp is FA-presentable.
First, we will construct an automatic presentation of R+
p , the submonoid of Rp
consisting of elements greater than or equal to 0. Later we describe how to obtain
an FA presentation of the entire group Rp from the one for R+
p .
The alphabet of the FA presentation for R+
p will be Σ = {
 n
m

:
n ∈
{0, 1} and m ∈{0, . . . , p −1}}. Every element z ∈R+
p will be represented by
two lines of digits,

424
A. Nies and P. Semukhin
n1 n2
· · · nk
m1 m2 · · · mk
where n1n2 . . . nk represents the integral part of z in binary presentation with
the least signiﬁcant digit ﬁrst, and m1m2 . . . mk represents the fractional part
of z in base p with the most signiﬁcant digit ﬁrst. If needed, we put additional
zeros to the right to make the lengths of integral and fractional part equal. For
example, if p = 3 then the element 1417
27 ∈R+
3 is represented by
0 1 1 1
1 2 2 0
Let the domain D of an FA presentation of R+
p consist of all words in Σ∗
not ending in
0
0

, except for
0
0

itself which represents 0. Clearly, D is FA
recognizable.
Let Add be the graph of the addition operation. We prove that Add is FA
recognizable. First, we construct an auxiliary automaton A whose alphabet is
(Σ ∪{□})3. The states of A are q0, (0, 0), (0, 1), (1, 0), (1, 1), where q0 is an
initial state and (0, 0) is a ﬁnal state. The state (α, β) means that we have a
carry bit α in the addition of integral parts, and a carry bit β in the addition of
fractional parts.
The transitions of A are deﬁned below. It is assumed there that the special
symbol □is identical to the symbol
0
0

.
There is a transition from q0 to (α, β) with the label
 n1
m1

,
 n2
m2

,
 n3
m3
⊤
if
and only if

n1 + n2 = 2α + n3
m1 + m2 + β = m3
or

n1 + n2 + 1 = 2α + n3
m1 + m2 + β = p + m3 .
This means that from the ﬁrst letter of the input A guesses the carry bit from
the fractional part to the integral part: in the ﬁrst case the carry bit is 0, while
in the second case the carry bit is 1.
There is a transition from (α, β) to (α′, β′) with the label
 n1
m1

,
 n2
m2

,
 n3
m3
⊤
if and only if

n1 + n2 + α = 2α′ + n3
m1 + m2 + β′ = pβ + m3 .
Now as one can see Conv(Add) = L(A) ∩Conv(D3). Therefore, since D3 is
FA recognizable, then so is Add.
Let us deﬁne an FA presentation for Rp. Consider the presentation of R+
p
given above; let π : D2 →D2 be the following function
π(x, y) =

(x −y, 0)
if x ⩾y,
(0, y −x)
if x < y.

Finite Automata Presentable Abelian Groups
425
Note that the graph of π is an FA recognizable subset of D4 since it can be deﬁned
in terms of Add and ⩽relations which are FA recognizable in our presentation
of R+
p . Now the domain of the FA presentation of Rp is

(x, y) : x, y ∈D and (x = 0 ∨y = 0)

with addition operation deﬁned as
(x1, y1)+(x2, y2) = (x3, y3) if and only if (x3, y3) = π(x1 +x2, y1+y2).
⊓⊔
3
Amalgamations of Monoids and Abelian Groups
Before turning to abelian groups let us consider commutative monoids which
have cancellation property, namely, a + c = b + c implies a = b for all elements
a, b, c. In what follows, by monoid we will mean commutative monoid with
cancellation property.
Proposition 3.1. Let M, N, and U be monoids, and f : U →M, g : U →N
be isomorphic embeddings. Consider the direct product M × N of the monoids
and a relation ∼U on M × N deﬁned as follows:
(x0, y0) ∼U (x1, y1)
⇐⇒
∃u, v ∈U

x0 + f(u) = x1 + f(v) ∧
y0 + g(u) = y1 + g(v)

Then ∼U is a congruence on M ×N, and M ⊕U N, the amalgamated product
of M and N over U, is the quotient structure M × N/ ∼U, which also is a
commutative monoid with cancellation property.
Proof. It is straightforward to show that ∼U is a congruence, and that M ⊕U
N is a commutative monoid. We prove that it possesses cancellation property.
Suppose (x0, y0)+(z, w) ∼U (x1, y1)+(z, w); then x0 +z +f(u) = x1 +z +f(v)
and y0 + w + g(u) = y1 + w + g(v) for some u, v ∈U. Since M and N possess
cancellation property, we have that x0 + f(u) = x1 + f(v) and y0 + g(u) =
y1 + g(v), that is (x0, y0) ∼U (x1, y1).
⊓⊔
We will use the notation ⟨x, y⟩U to denote the equivalence class of (x, y) ∈M ×N
with respect to ∼U.
Proposition 3.2. Let M ⊕U N be an amalgamated product of monoids M and
N over U. Then there are submonoids 	
M and 
N in M ⊕U N such that 	
M ∼= M,

N ∼= N, and M ⊕U N = 	
M + 
N.
Proof. Let 	
M = {⟨x, 0⟩U : x ∈M} and 
N = {⟨0, y⟩U : y ∈N}; as one can
see, 	
M and 
N are submonoids of M ⊕U N, and M ⊕U N = 	
M + 
N. Consider
the mappings ϕ : M →	
M and ψ : N →
N such that ϕ(x) = ⟨x, 0⟩U and
ϕ(y) = ⟨0, y⟩U. Clearly, ϕ and ψ are epimorphisms. Let us show, for instance,
that ϕ is one-to-one. Suppose ⟨x, 0⟩U = ⟨x′, 0⟩U; then x + f(u) = x′ + f(v) and

426
A. Nies and P. Semukhin
g(u) = g(v) for some u, v ∈U. Therefore, u = v and the cancellation property
implies that x = x′.
⊓⊔
In the case of abelian groups we can deﬁne the notion of amalgamated product
in a slightly diﬀerent manner.
Deﬁnition 3.1. Let A, B, and U be abelian groups and f : U →A, g : U →B
be isomorphic embeddings. Then A⊕U B, the amalgamated product of A and
B over U, is the quotient group A ⊕B/
U, where 
U = {(f(u), g(u)) | u ∈U}.
The next proposition is the strengthening of 3.2 for abelian groups.
Proposition 3.3. Let A ⊕U B be an amalgamated product of A and B over
U. Then there are subgroups 
A and 
B in A ⊕U B such that 
A ∼= A, 
B ∼= B,
A ⊕U B = 
A + 
B and 
A ∩
B ∼= U.
Proof. By deﬁnition A ⊕U B = A ⊕B/
U. Let 
A = {(a, 0) + 
U | a ∈A} and

B = {(0, b)+ 
U | b ∈B}. As one can see, A⊕U B = 
A+ 
B and 
A ∼= A, 
B ∼= B. We
now prove that 
A∩
B ∼= U. Let x ∈
A∩
B, then x = (a, 0)+ 
U and x = (0, b)+ 
U;
hence (a, −b) ∈
U and a = f(u), b = −g(u). Therefore, x = (f(u), 0) + 
U and

A ∩
B = {(f(u), 0) + 
U | u ∈U}, which is isomorphic to U.
⊓⊔
Remark 3.1. The intersection 	
M ∩
N of the submonoids of M ⊕U N deﬁned in
the proof of Proposition 3.2 does not necessarily isomorphic to U. To show this
let M, N, U be (N, +), and f, g be the identity embeddings. As one can see,
M ⊕U N is isomorphic to (Z, +) because ⟨x, y⟩N = ⟨x′, y′⟩N iﬀx −y = x′ −y′,
and we can identify ⟨x, y⟩N with x −y ∈Z. In this case 	
M and 
N correspond
to the submonoids of non-negative and non-positive numbers respectively. Thus
	
M ∩
N = {⟨0, 0⟩N} ̸∼= N.
The converse of 3.3 also holds.
Proposition 3.4. Let L be an abelian group, A, B subgroups of L, and U =
A ∩B. Then
A + B ∼= A ⊕U B,
where the embeddings f, g of U into A and B are the identity mappings.
Proof. In this case A ⊕U B = A ⊕B/
U, where 
U = {(u, u) | u ∈U}. Let
ϕ : A ⊕U B →A + B be deﬁned as follows:
ϕ((a, b) + 
U) = a −b.
We show that ϕ is an isomorphism. First, note that it is well deﬁned: if (a, b) +

U = (a′, b′) + 
U then (a −a′, b −b′) = (u, u) for some u ∈U; therefore a −b =
(a′ + u) −(b′ + u) = a′ −b′.
It is easy to see that ϕ is an epimorphism. We now prove that it is one-
to-one. Let a −b = a′ −b′; then a −a′ = b −b′ ∈A ∩B = U. Therefore,
(a −a′, b −b′) = (u, u) ∈
U and (a, b) + 
U = (a′, b′) + 
U.
⊓⊔

Finite Automata Presentable Abelian Groups
427
Remark 3.2. If M, N, and U are abelian groups then both deﬁnitions of amal-
gamated product, that is the one for groups and the one for monoids, give us
the same structure M ⊕U N.
4
Constructions of FA Presentable Monoids and Abelian
Groups
In this section we will prove a version of Proposition 3.2 for FA presentable
structures.
Theorem 4.1. If M, N, and U are FA presented monoids and f : U →M,
g : U →N are isomorphic embeddings that are FA recognizable subsets of U ×M
and U ×N respectively, then the amalgamated product M ⊕U N is FA presentable.
Moreover, M ⊕U N contains FA recognizable submonoids 	
M and 
N such that
	
M ∼= M, 
N ∼= M and M ⊕U N = 	
M + 
N.
Proof. We prove that M ⊕U N is FA presentable by constructing an interpreta-
tion of it in the FA presentable structure E = M ⊔N ⊔U enriched with unary
predicates for subsets M, N, U and binary predicates Rf and Rg for the graphs
of f and g. Let RM and RN be the graphs of the addition operation in M and
N respectively.
The domain for M ⊕U N is deﬁned in E2 by the formula Δ(x0, y0) = M(x0)∧
N(y0). Addition is deﬁned by
Φ(x0, y0, x1, y1, x2, y2) = RM(x0, x1, x2) ∧RN(y0, y1, y2).
Equality is deﬁned by
ϵ(x0, y0, x1, y1) = ∃u, v (U(u) ∧U(v) ∧x0 + f(u) = x1 + f(v)
∧y0 + g(u) = y1 + g(v))
or more formally
ϵ(x0, y0, x1, y1) =∃u, v, w0, w1, w2, w3, z0, z1 (U(u) ∧U(v) ∧Rf(u, w0)
∧Rf(v, w1) ∧Rg(u, w2) ∧Rg(v, w3) ∧RM(x0, w0, z0)
∧RM(x1, w1, z0) ∧RN(y0, w2, z1) ∧RN(y1, w3, z1)).
From the proof of Proposition 3.2 it follows that 	
M and 
N are deﬁned by the
formulas
(z0, z1) ∈	
M ⇐⇒∃x, u, v (M(x) ∧U(u) ∧U(v)∧
z0 + f(u) = x + f(v) ∧z1 + g(u) = g(v)),
(z0, z1) ∈
N ⇐⇒∃y, u, v (N(y) ∧U(u) ∧U(v)∧
z0 + f(u) = f(v) ∧z1 + g(u) = y + g(v)).
Therefore, 	
M and 
N are FA recognizable submonoids.
⊓⊔

428
A. Nies and P. Semukhin
Theorem 4.2. Let A and B be abelian groups such that B is a subgroup of A
and |A : B| is ﬁnite. If B is FA presentable, then so is A.
Proof. Let r0, . . . , rk be representatives of the cosets of B in A. Then there are
a function g : {0, . . ., k}2 →{0, . . ., k} and elements bij ∈B with the following
property: for every i and j,
ri + rj = rg(i,j) + bij.
We may assume that the FA presentation of B uses an alphabet Σ, such that
0, . . . , k /∈Σ, and that the domain of this presentation is D ⊆Σ∗. Let the
alphabet of the FA presentation of A be Σ ∪{0, . . ., k}. Each element of A has
the unique form ri +b for some b ∈B, and is represented by the string iv, where
v ∈D represents b. Since A is abelian,
(ri + b1) + (rj + b2) = rg(i,j) + bij + b1 + b2.
Hence the graph of addition operation can be recognized by a ﬁnite automaton.
⊓⊔
Example 4.1 (Two diﬀerent presentations of R6). Consider the presentation of
R6 described in Section 2. We will show that R6 in this presentation does not have
FA recognizable subgroup isomorphic to R2. Suppose M is an FA recognizable
subgroup of R6 and M ∼= R2. Let M + = {(x, 0) : (x, 0) ∈M}; then M + is FA
recognizable and M + ∼= R+
2 . Note that we can identify the FA presentation of
R+
6 and the FA recognizable submonoid of R6 with domain {(x, 0) : (x, 0) ∈R6}.
This implies that R+
6 has an FA recognizable submonoid isomorphic to R+
2 .
Now if M + ⩽R+
6 is isomorphic to R+
2 , then for some n0, k0 ∈N
M + = n0
6k0 · R+
2 =
n0n3k
6k0+k
: k, n ∈N

.
For each k and let αk be the smallest element of M + of the length k0 + k in this
presentation. Obviously, αk = n03k6−(k0+k) and it has the form
0 0 · · · 0 0 · · · 0
0 0 · · · 0
rk
where
lim
k→∞
length(rk)
(k + k0)
= log6 3.
(1)
Choosing suﬃciently large k we will have enough leading zeros in the presentation
of αk to pump this string. This will give us a contradiction with the formula (1).
Therefore, M + is not FA recognizable, and M is not FA recognizable too.
On the other hand, R6 is isomorphic to R+
2 ⊕N R+
3 . Indeed, R+
2 ⊕N R+
3 =
{⟨x, y⟩N : (x, y) ∈R+
2 × R+
3 } and
⟨x, y⟩N = ⟨x′, y′⟩N if and only if x −y = x′ −y′.

Finite Automata Presentable Abelian Groups
429
Let z = m/6k ∈R6; there are m0, m1 ∈Z such that m = 3km0 −2km1; then
z = m0/2k −m1/3k = (m0/2k + l) −(m1/3k + l) for any l ∈Z. Choosing
suﬃciently large l we see that z = x −y, where x ∈R+
2 , y ∈R+
3 . Therefore, the
mapping that sends ⟨x, y⟩N to x −y ∈R6 gives us desired isomorphism.
Consider FA presentations for R+
2 and R+
3 described in Section 2. Recall that
the integral part of every element is presented in base 2 both in R+
2 and R+
3 .
Thus if we take FA presentation of N in base 2, then the graphs of the identity
embeddings f : N →R+
2 and g : N →R+
3 will be FA recognizable. Therefore,
by Theorem 4.1, R6 has an FA presentation which contains FA recognizable
submonoids isomorphic to R+
2 and R+
3 . Now if M + ⊆R6 is a submonoid iso-
morphic to R+
2 then M = M + ∪−M + is a subgroup isomorphic to R2. Clearly,
M is deﬁnable in terms of M + and addition. Therefore, this presentation of
R6 contains FA recognizable subgroups isomorphic to R2 and R3. It is diﬀerent
from the presentation given in Section 2, in the sense that there is no automatic
isomorphism between them.
5
Indecomposable FA Presentable Abelian Groups
We describe rank n torsion-free abelian groups, Gn and Hn, which are indecom-
posable and strongly indecomposable respectively. We then show how to apply
the methods from the previous section to prove that they are FA presentable.
In what follows we will use expressions like p−∞a as an abbreviation for an
inﬁnite set p−1a, p−2a, · · · . For every n ⩾2, let Gn be a subgroup of Qn generated
by p−∞
1
e1, . . . , p−∞
n
en, q−1(e1 +· · ·+en), where q, p1, . . . , pn are diﬀerent primes
and e1, . . . , en are linear independent elements in Qn considered as a Q-vector
space. An example of such a group was found in [4, vol. 2, §88, Exercise 2].
Theorem 5.1. The group Gn is indecomposable for all n ⩾2.
Proof. First, note that every x ∈Gn has the form
x = (p−k1
1
m1 + q−1s)e1 + · · · + (p−kn
n
mn + q−1s)en,
where m1, . . . , mn, s ∈Z and k1, . . . , kn ∈N. Let Ej = ⟨p−∞
j
ej⟩where 1 ⩽j ⩽n.
We show that the groups Ej are fully invariant in Gn, i.e. ϕ(Ej) ⊆Ej for any
endomorphism ϕ of Gn. Let x ∈Ej and ϕ(x) =  siei. In Gn, x is divisible by
all powers of pj, and so is ϕ(x). Hence, si = 0 for i ̸= j and ϕ(x) = sjej.
Take any i ̸= j. As mentioned above, sj has the form p−kj
j
mj + q−1s and si
has the form p−ki
i
mi + q−1s. Since si = 0, q−1s must be an integer. Therefore,
ϕ(x) = sjej belongs to Ej.
Now suppose that Gn = A ⊕B. If x ∈Gn, then x has the unique form
x = a + b, where a ∈A, b ∈B. Deﬁne the following endomorphisms of Gn:
ϕA(x) = a and ϕB(x) = b, where x = a + b. Obviously, x = ϕA(x) + ϕB(x). If
x ∈Ej then ϕA(x) ∈Ej ∩A and ϕB(x) ∈Ej ∩B, since Ej is fully invariant.
This means that Ej = (Ej ∩A) ⊕(Ej ∩B).

430
A. Nies and P. Semukhin
Note that Ej is indecomposable, because it has rank 1. Therefore, Ej ⊆A
or Ej ⊆B. Assume there exists 1 ⩽k < n such that E1, . . . , Ek ⊆A and
Ek+1, . . . , En ⊆B. Let q−1(e1 + · · · + en) = a + b, where a ∈A and b ∈B.
Then e1 + · · · + ek + ek+1 + · · · + en = qa + qb. Since e1 + · · · + ek ∈A and
ek+1 + · · · + en ∈B we have that a = q−1(e1 + · · · + ek).
We show that this is impossible. Let a = (p−k1
1
m1+q−1s)e1+· · ·+(p−kn
n
mn+
q−1s)en; since p−kn
n
mn + q−1s = 0, q−1s must be an integer. Hence p−k1
1
m1 +
q−1s = 0 cannot be equal to q−1.
So we can assume that E1, . . . , En ⊆A. If B ̸= 0 then let b ∈B be a nonzero
element. Then there exists n > 0 such that nb ∈⟨e1, . . . , en⟩⊆E1+· · ·+En ⊆A,
which is impossible because nb ̸= 0 and nb is an element of B. Therefore, B = 0.
⊓⊔
Deﬁnition 5.1 ([1]). A torsion-free abelian group A is strongly indecom-
posable if whenever 0 ̸= k ∈N and kA ⩽B ⊕C ⩽A then B = 0 or C = 0.
The group Hn from the next theorem was introduced in [1, Example 2.4].
Theorem 5.2. The group Hn = ⟨p−∞
1
e1, . . . , p−∞
n
en, q−∞(e1 + · · · + en)⟩is
strongly indecomposable for all n ⩾2.
Proof. First, we show that any endomorphism of Hn is the same as multiplication
by an integer. Let x ∈Hn, by an argument similar to one in the beginning of
the proof of Theorem 5.1, one can show that if x is divisible in Hn by all powers
of pi, then x has the form mp−k
i
ei.
Now let e1 = −e1, . . . , en−1 = −en−1, en = e1+· · ·+en. Then en = e1+· · ·+en
and we can write
Hn = ⟨p−∞
1
e1, . . . , p−∞
n−1en−1, p−∞
n
(e1 + · · · + en), q−∞en)⟩.
Therefore, if x is divisible in Hn by any power of q then it has the form mq−ken =
mq−k(e1 + · · · + en).
Let ϕ be an endomorphism of Hn; ϕ(ei) = riei where ri = mip−ki
i
, because
ϕ(ei) is divisible by any power of pi. Hence ϕ(e1 + · · · + en) =  riei. On the
other hand, since ϕ(e1 + · · · + en) is divisible by all powers of q, it has the
form mq−k(e1 + · · · + en). Therefore, each ri is equal to an integer number r
and ϕ(x) = rx. Since the group is torsion-free, every nonzero endomorphism is
one-to-one.
To conclude the proof we will show that if a torsion-free abelian group A
has only one-to-one nonzero endomorphisms then it is strongly indecomposable.
Assume that there are k ̸= 0 and nonzero groups B and C such that kA ⩽
B ⊕C ⩽A. Let ψ be an endomorphism of B ⊕C deﬁned as follows: if x = b + c
where b ∈B, c ∈C then ψ(x) = b. Then the mapping ϕ deﬁned by ϕ(x) = ψ(kx)
is an endomorphism of A. Take any 0 ̸= c ∈C, then ϕ(c) = ψ(kc) = 0 and,
therefore, ϕ is not one-to-one. Note that ϕ is also nonzero, since if 0 ̸= b ∈B
then ϕ(b) = kb ̸= 0.
⊓⊔
Theorem 5.3. The group Gn is FA presentable.

Finite Automata Presentable Abelian Groups
431
Proof. Since Rp is FA presentable, the direct sum Rp1 ⊕· · · ⊕Rpn is also FA
presentable. Note that Rp1 ⊕· · ·⊕Rpn is a subgroup of ﬁnite index in Gn. Hence,
by Theorem 4.2, Gn is also FA presentable.
⊓⊔
Remark 5.1. Note that unlike Gn, the group Hn is not an extension of ﬁnite
index of any known example of an FA presentable group. To show that it is
FA presentable we will use the method of amalgamated products described in
section 4.
Theorem 5.4. The group Hn is FA presentable.
Proof. First, let us show that Hn is isomorphic to (R+
p1 × · · · × R+
pn) ⊕N R+
q , an
amalgamated product of monoids R+
p1 × · · · × R+
pn and R+
q over N, where the
isomorphic embeddings f : N →R+
p1 × · · · × R+
pn and g : N →R+
q are chosen as
follows: for all m ∈N, f(m) = (m, . . . , m) and g(m) = m.
Every element of (R+
p1 × · · · × R+
pn) ⊕N R+
q is of the form ⟨(a1, . . . , an), b⟩N,
where ai ∈R+
pi, for i = 1, . . . , n, and b ∈R+
q . Suppose that
⟨(a1, . . . , an), b⟩N = ⟨(a′
1, . . . , a′
n), b′⟩N
then there are u, v ∈N such that

(a1 + u, . . . , an + u) = (a′
1 + v, . . . , a′
n + v)
b + u = b′ + v.
This implies that ai −b = a′
i −b′ for all i = 1, . . . , n. Thus we can correctly
deﬁne a function h on (R+
p1 × · · · × R+
pn) ⊕N R+
q such that
h(⟨(a1, . . . , an), b⟩N) = (a1 −b)e1 + · · · + (an −b)en.
As one can see, the range of h is a subset of Hn, and h is a homomorphism. To
show that it is one-to-one, assume that
h(⟨(a1, . . . , an), b⟩N) = h(⟨(a′
1, . . . , a′
n), b′⟩N);
then
(a1 −b)e1 + · · · + (an −b)en = (a′
1 −b′)e1 + · · · + (a′
n −b′)en.
Therefore, ai −a′
i = b −b′ ∈Rpi ∩Rq for i = 1, . . . , n. Since Rpi ∩Rq = Z there
is w ∈Z such that

(a1, . . . , an) = (a′
1 + w, . . . , a′
n + w)
b = b′ + w.
So ⟨(a1, . . . , an), b⟩N = ⟨(a′
1, . . . , a′
n), b′⟩N.
Now to prove that h is onto, consider an element z ∈Hn; it must be of the
form
z =
m1
pk1
1
+ l
qr

e1 + · · · +
mn
pkn
n
+ l
qr

en.

432
A. Nies and P. Semukhin
for integers mi, l, and natural numbers ki, r. Obviously,
mi
pki
i
+ l
qr =
 mi
pki
i
+ t

−

−l
qr + t

for any t ∈Z. Choosing suﬃciently large t we can make all ai = mi/pki
i + t
and b = −l/qr + t to be positive. In this case ⟨(a1, . . . , an), b⟩N is an element of
(R+
p1 × · · · × R+
pn) ⊕N R+
q and h(⟨(a1, . . . , an), b⟩N) = z. Therefore, the range of h
is Hn, and hence it is an isomorphism.
Consider FA presentations of monoids R+
p1, . . . , R+
pn, and R+
q
described in
Section 2. From this we can easily construct an FA presentation of R+
p1 ×· · ·×R+
pn
by putting strings representing elements of R+
pi one under another in a column
using an extra padding symbol when necessary. Recall that the integral part of
an element of R+
pi or R+
q is presented in base 2. Therefore, if we consider the
presentation of N in base 2, then the graphs of isomorphic embeddings f : N →
R+
p1 × · · · × R+
pn and g : N →R+
q will be FA recognizable. Now, by Theorem 4.1,
the structure (R+
p1 × · · · × R+
pn) ⊕N R+
q is FA presentable, and as shown above it
is isomorphic to Hn.
⊓⊔
6
A New FA Presentation of Z2
Let (Z, +) be the group of integers under addition. In this section we will con-
struct an FA presentation of (Z, +)2 in which no nontrivial cyclic subgroup is
FA recognizable.
Consider Z[x]/⟨p3⟩, the quotient of the polynomial ring Z[x] with respect to
the ideal generated by p3(x) = x2 + x −3. We will use the notation p(x) ∼q(x)
to denote that p3(x) divides p(x) −q(x).
Remark 6.1. In the construction described below we can use any polynomial of
the form x2 + x −q, for a prime q ⩾3, instead of p3(x).
Let A = (Z[x]/⟨p3⟩, +) be the additive group of the ring Z[x]/⟨p3⟩. It is not hard
to see that A is isomorphic to Z2, since every polynomial in Z[x] is equivalent
over ⟨p3⟩to a linear polynomial kx + l, which can be identiﬁed with a pair
(k, l) ∈Z2.
We say that a polynomial anxn + · · · + a0 ∈Z[x] is in reduced form (or
brieﬂy reduced) if |ai| ⩽2 for all i ⩽n.
Proposition 6.1. For every p(x) ∈Z[x], there is a reduced polynomial 
p(x)
equivalent to it.
Proof. This can be proved by induction: assume that p(x) is in reduced form
and show that p(x) ± xn is equivalent to a reduced polynomial. It is enough to
consider p(x) ± 1. Note that if p0(x) and p1(x) are in reduced form and have
non-negative coeﬃcients then p0(x) −p1(x) is reduced. Moreover, any reduced
p(x) is equal to the diﬀerence of such p0(x) and p1(x). So, it is enough to consider

Finite Automata Presentable Abelian Groups
433
the case when p(x) is reduced and has non-negative coeﬃcients and show that
p(x) + 1 is equivalent to a reduced polynomial with non-negative coeﬃcients.
We will actually prove a stronger statement: if p(x) is a reduced polynomial
with non-negative coeﬃcients then p(x) + (a1x + a0), where 0 ⩽a0, a1 ⩽2, is
equivalent to a polynomial of the same sort. The proof is now by induction on
the degree of p(x).
Let us write p(x) as p(x) = p1(x)x2 + (b1x + b0); now using the fact that
3 ∼x2 + x we have
p(x) + (a1x + a0) = p1(x)x2 + (a1 + b1)x + (a0 + b0)
∼(p1(x) + r1x + (r0 + r1))x2 + c1x + c0,
where
c0 =

a0 + b0,
if a0 + b0 < 3
a0 + b0 −3,
otherwise
r0 =
a0 + b0
3

,
c1 =

a1 + b1 + r0,
if a1 + b1 + r0 < 3
a1 + b1 + r0 −3,
otherwise
r1 =
a1 + b1 + r0
3

.
Here [v] is the integral part of v, deﬁned by
[v] =

max{k ∈Z : k ⩽v}
if v ⩾0,
min{k ∈Z : v ⩽k}
if v < 0.
For example, [1.5] = 1 and [−1.5] = −1. Note that 0 ⩽c0, c1 ⩽2 and 0 ⩽
r0, r1 ⩽1. By induction, p1(x) + r1x + (r0 + r1) is equivalent to a reduced
polynomial with non-negative coeﬃcients; hence so is p(x).
⊓⊔
We now give an automatic presentation for the group A. The alphabet of the
presentation is Σ = {−2, −1, 0, 1, 2}. Each reduced polynomial anxn + · · · + a0
is represented by a word a0 . . . an ∈Σ∗. We say that two words a0 . . . an and
b0 . . . bm from Σ∗are equivalent if anxn + · · · + a0 ∼bmxm + · · · + b0.
This equivalence relation is FA recognizable. An algorithm for checking it is
as follows. Given two words a0 . . . an, b0 . . . bm; we can assume that n = m since
one can always add extra zeros to the right. The algorithm needs to remember
two carries r0, r1; initially r0 = r1 = 0. Note that since 3 ∼x + x2, whenever
we subtract 3 from any digit we need to add 1 to the next two digits in order to
get an equivalent word. That is why we need two carries here.
Now for every i = 0, . . . , n do the following. Check if 3 divides ai −bi + r0.
If ‘no’ then the words are not equivalent. If ‘yes’ then let rold
0
= r0, rold
1
= r1;
redeﬁne
r0 = rold
1
+ ai −bi + rold
0
3
,
r1 = ai −bi + rold
0
3
,
and go to step i+1. If we reach in this way step n then the words are equivalent
if and only if an −bn + r0 = 0 and r1 = 0.

434
A. Nies and P. Semukhin
Since at every step |r0| ⩽4 and |r1| ⩽2, this algorithm requires a constant
amount of memory. Now it is not hard to construct a ﬁnite automaton recogniz-
ing the equivalence.
Consider the following order on Σ: −2 < −1 < 0 < 1 < 2. It naturally extents
to the length-lexicographical order on Σ∗, denoted as <llex. Let the domain of
the FA presentation of A be
Dom(A) = {w ∈Σ∗: (∀u <llex w) u is not equivalent to w}.
This set is FA recognizable since <llex is an FA recognizable relation.
To deﬁne addition on Dom(A) consider the relation R(x, y, z) such that if
x = a0 . . . ak, y = b0 . . . bl then z = c0 . . . cn is obtained from x and y by applying
the following algorithm. Again, let r0, r1 be two carries that are initially zero.
At every step i starting from 0, let ci be such that |ci| < 3,
ci ≡ai + bi + r0 (mod 3)
and ci has the same sign as ai + bi + r0. Let rold
0
= r0, rold
1
= r1. Now redeﬁne
r0 = rold
1
+
ai + bi + rold
0
3

,
r1 =
ai + bi + rold
0
3

,
and go to step i + 1.
For example, if x = 2211 and y = 22 then this algorithm produces z = 120021.
By construction, if R(x, y, z) holds then the polynomial corresponding to z is
equivalent over ⟨p3⟩to the sum of polynomials represented by x and y. It is
easy to see that at every step |r0| ⩽4 and |r1| ⩽2. Thus, as before, R can be
recognized by a ﬁnite automaton.
Let Add(x, y, z) be deﬁned as
Add = {(x, y, z) : x, y, z ∈Dom(A) and
∃w (R(x, y, w) ∧w is equivalent to z)}.
Since Dom(A), R, and the equivalence relation are FA recognizable Add is also
FA recognizable. Obviously, Add is the graph of addition operation on Dom(A),
and the FA presented structure (Dom(A), Add) is isomorphic to A.
Our next goal is to show that no nontrivial cyclic subgroup in this presentation
of Z2 is FA recognizable.
Lemma 6.1. Let p(x) and q(x) be reduced polynomials such that p(x) ∼q(x)
and xk | p(x), then xk | q(x).
Proof. Suppose that xk ∤q(x); then p(x)−q(x) = xl(a0+a1x+· · · ), where l < k,
|a0| ⩽2, and a0 ̸= 0. Since 3 ∤a0, p3(x) = x2 + x −3 cannot divide p(x) −q(x),
which gives a contradiction.
⊓⊔
For p(x) ∈Z[x], consider the set of all words in Σ∗that represent polynomials
equivalent to p(x). All these words start with the same number of zeros. So
we say that p(x) starts with k zeros in reduced form if there is w ∈Σ∗
representing p(x) that starts with k zeros.

Finite Automata Presentable Abelian Groups
435
The following lemma will be used several times later on.
Lemma 6.2. Let n be an integer, then 3k | n if and only if n starts with k zeros
in reduced form.
Proof. Suppose that 3k | n; then n = 3km ∼xk(x + 1)km. Taking a reduced
form for (x+1)km and multiplying it by xk we obtain a reduced form for n that
starts with k zeros; thus n starts with k zeros in reduced form.
The other implication can be proved by induction on k. First, suppose that
n starts with 0 in reduced form and n = 3m + r, where 0 < r ⩽2. Take any
reduced form for 3m. Since it starts with 0, n = 3m + r has a reduced form that
starts with r ̸= 0. This contradicts our assumption, and hence 3 | n.
It is not hard to see that if p(x) starts with exactly k zeros in reduced form,
and q(x) starts with exactly l zeros, then a reduced form for p(x)q(x) starts with
exactly k + l zeros. Now suppose that n starts with k + 1 zeros in reduced form;
then n = 3m and m starts with k zeros, because 3 ∼011 starts with one 0. By
induction, 3k | m, and so we have 3k+1 | n.
⊓⊔
Let α = (
√
13 −1)/2 be the positive root of p3(x) = x2 + x −3. Consider a
mapping F : Z[x] →R such that F : p(x) →p(α). Obviously,
(p + q)(α) = p(α) + q(α)
and
(pq)(α) = p(α)q(α).
Furthermore, if p(x) ∼q(x) then p(α) = q(α), since p(α)−q(α) = p3(α)r(α) = 0.
Consider an arbitrary nontrivial cyclic subgroup in our presentation of Z2. It
has the form
⟨w⟩= {n · w : n ∈Z}
for some w ∈Dom(A). Let q(x) be the polynomial that corresponds to w. Note
that q(α) ̸= 0 since w represents nonzero element. Indeed, by applying the
Euclidean algorithm one can see that there are polynomials s, r with deg(r) < 2
such that q = s · p3 + r. Moreover, since the leading coeﬃcient of p3 is 1, s and
r have integer coeﬃcients. Now if q(α) = 0, then r(α) = 0, which implies that
r = 0 since α is irrational. So q = s · p3 is equivalent to 0.
Suppose that ⟨w⟩is recognized by a ﬁnite automaton with d states. We know
that 3d · w ∈⟨w⟩starts with d zeros in reduced form. So let 3d · w be equivalent
to 0dv ∈Dom(A). By pumping lemma, there are s0, s1, t ∈N with t ̸= 0 such
that 0dv = 0s00t0s1v and wk = 0tk+s0+s1v ∈⟨w⟩for all k ⩾0.
Let qk(x) be the polynomial that corresponds to wk. Since wk ∈⟨w⟩, we have
that wk ∼nk · w for some nk ∈Z. If w starts with m zeros, then nk starts with
at least tk −m + s0 + s1 zeros in reduced form; thus 3tk−m+s0+s1 | nk.
The fact that wk is equivalent to nk · w implies that qk(α) = nkq(α). Now, on
the one hand,
|qk(α)| ⩽2(1 + α + · · · + α|wk|−1)
= 2α|wk| −1
α −1
⩽8α|wk| = 8αs0+s1+|v|αtk = C0αtk.

436
A. Nies and P. Semukhin
On the other hand,
|qk(α)| = |nk||q(α)| ⩾3tk3s0+s1−m|q(α)| = C13tk.
Thus
C13tk ⩽C0αtk
for all k ⩾0,
which is impossible because α < 3. Therefore, ⟨w⟩is not FA recognizable.
References
1. D. Arnold, Finite Rank Torsion Free Abelian Groups and Rings (Springer-Verlag,
1982).
2. A. Blumensath, E. Gr¨adel, Automatic structures, 15th Annual IEEE Symposium on
Logic in Computer Science (Santa Barbara, CA, 2000), 51–62, IEEE Comput. Soc.
Press, Los Alamitos, CA, 2000.
3. C. Delhomm´e, Non-automaticity of ωω, 2001, manuscript.
4. L. Fuchs, Inﬁnite Abelian Groups, vol. 1, 2 (Academic Press, 1970, 1973).
5. B. R. Hodgson, Th´eories d´ecidables par automate ﬁni, PhD Thesis, University of
Montreal, 1976.
6. B. R. Hodgson, Th´eories d´ecidables par automate ﬁni, Annales de Sciences
Math´ematiques, 7:39–57, 1983.
7. B. Khoussainov, A. Neorde, Automatic presentations of structures, in D. Leivant
(ed.), Logic and Computational Complexity (LNCS 960, Springer-Verlag, 1995), 367–
392.
8. B. Khoussainov, S. Rubin, Automatic structures: overview and future directions.
Weighted automata: theory and applications (Dresden, 2002), J. Autom. Lang.
Comb., 2:287–301, 8 (2003).
9. B. Khoussainov, A. Nies, S. Rubin and F. Stephan, Automatic structures: richness
and limitations, Proceedings of the 19th IEEE Symposium on Logic in Computer
Science (IEEE Computer Society, 2004), 110–119.

Embeddings into Free Heyting Algebras and
Translations into Intuitionistic Propositional
Logic
Michael O’Connor
Cornell University
Abstract. We ﬁnd a translation with particularly nice properties from
intuitionistic propositional logic in countably many variables to intu-
itionistic propositional logic in two variables. In addition, the existence
of a possibly-not-as-nice translation from any countable logic into intu-
itionistic propositional logic in two variables is shown. The nonexistence
of a translation from classical logic into intuitionistic propositional logic
which preserves ∧and ∨but not necessarily ⊤is proven. These results
about translations follow from additional results about embeddings into
free Heyting algebras.
1
Introduction
Intuitionistic logic has been explored for many years as a language for com-
puter science, with a guiding principle being the Brouwer-Heyting-Kolmogorov
interpretation, under which intuitionistic proofs of implication are functions and
existence proofs require witnesses. Higher-order intuitionistic systems which can
express a great deal of mathematics, such as Girard’s System F and Martin-
L¨of’s type theory (good references are [8] and [3]), have been developed and
implemented by prominent computer scientists such as Constable, Huet and Co-
quand (see [2] and [1]). With all this development and with the existence of
well-established topological, Kripke, and categorical semantics for intuitionistic
systems, it may come as a surprise that many fundamental structural proper-
ties of intuitionistic propositional calculus have not been developed. By way of
contrast, corresponding issues for classical logics have been settled for at least
75 years.
Heyting algebras are an equationally deﬁned class of algebras with opera-
tions ∨, ∧, and →and constants ⊥and ⊤(representing “or,” “and,” “implies,”
“false,” and “true” respectively) that stand in the same relation to intuitionis-
tic propositional logic that Boolean algebras do to classical propositional logic.
What follows is a very brief introduction to free Heyting algebras and a summary
of the results that will be presented in this paper.
For each n ∈N, let Vn = {x1, . . . , xn} and let Fn be the set of propositional
sentences in variables Vn. Let ≃n
i and ≃n
c be the intuitionistic and classical logical
equivalence relations respectively.
The classical Lindenbaum algebra Bn is then deﬁned as Fn/≃n
c and the in-
tuitionistic Lindenbaum algebra Hn is deﬁned as Fn/≃n
i . The operations ∧and
S. Artemov and A. Nerode (Eds.): LFCS 2007, LNCS 4514, pp. 437–448, 2007.
c
⃝Springer-Verlag Berlin Heidelberg 2007

438
M. O’Connor
∨and the constants ⊤and ⊥are naturally deﬁned on Bn and the operations
∧, ∨, and →and the constants ⊤and ⊥are naturally deﬁned on Hn. Bn is
then isomorphic to the free Boolean algebra on n generators and Hn is the free
Heyting algebra on n generators. As usual, the order ≤may be deﬁned from ∧
(or from ∨). Like all Heyting algebras, each Hn is also a distributive lattice.
The analogous statements are true for Vω = {x1, x2, . . .}, Fω, Bω, and Hω.
The structure of each Bn and of Bω is well understood. However, among the
free Heyting algebras, only H1 is completely understood. It is known from [10]
that if we let φ1 = ¬x1, ψ1 = x1, φi+1 = φi →ψi, and ψi+1 = φi ∨ψi, then each
propositional formula in the single variable x1 is intuitionistically equivalent to
exactly one formula in {⊥} ∪{φi | i ∈ω} ∪{ψi | i ∈ω} ∪{⊤}. Further, we can
easily write down conditions characterizing the order on those formulas, so that
the structure of H1 is completely characterized.
Although the structure of Hn for n ≥2 and of Hω is not fully understood,
there are a number of facts known. Although not a complete list, the reader
is referred to [4], [7], [5], and [6]. A very useful construction is contained in [4]
which will we avail ourselves of in this paper and which is described in Section 2
below.
The results of this paper are as follows: There is a lattice-embedding from Hω
into H2. This obviously implies that there is a lattice-embedding from Hm into
Hn for any m ≥1, n ≥2, but in these cases, more is true: For any n ≥2 and
m ≥1, there is a φ and a ψ ∈Hn such that [φ, ψ] := {ρ ∈Hn | φ ≤ρ ≤ψ} and
Hm are isomorphic as lattices. In addition, the isomorphism from [φ, ψ] to Hm
can be extended to all of Hn, so that there is a surjective lattice-homomorphism
from Hn to Hm.
Furthermore, we will show that any countable partial order can be order-
embedded into H2, and that the countable atomless boolean algebra Bω cannot
be lattice-embedded into Hω.
Some of these results also have signiﬁcance in terms of translations into intu-
itionistic propositional logic, a notion which we now deﬁne.
Let ⊢be the intuitionistic consequence relation. Deﬁne a consequence-
respecting translation from n-variable intuitionistic logic into m-variable intu-
itionistic logic to be a function f : Fn →Fm such that for all ∅̸= Γ ⊆Fn,
φ ∈Fn, Γ ⊢φ iﬀf(Γ) ⊢f(φ).
Deﬁne a tautology-respecting translation from n-variable intuitionistic logic
into m-variable intuitionistic logic to be a function f : Fn →Fm such that for
all φ ∈Fn, ⊢φ iﬀ⊢f(φ).
The term “respecting” is used to emphasize that the property of being
consequence-respecting and the property of being tautology-respecting are stron-
ger than the property of being consequence-preserving and tautology-preserving
respectively.
We deﬁne a (∧, ∨)-preserving translation from n-variable propositional logic
to m-variable propositional logic to be a function f : Fn →Fm such that for all
φ, ψ ∈Fn, f(φ ∧ψ) = f(φ) ∧f(ψ) and f(φ ∨ψ) = f(φ) ∨f(ψ).

Embeddings into Free Heyting Algebras
439
We make the obvious modiﬁcations to the deﬁnitions for translations from
classical logic to intuitionistic logic and for ω-variable logics.
Thus, G¨odel’s double-negation translation (see [9] or [3]) is a tautology-
respecting but not consequence-respecting or (∧, ∨)-preserving translation from
ω-variable classical logic to ω-variable intuitionistic logic and Gentzen’s transla-
tion (again, see [9] or [3]) is a tautology-respecting and consequence-respecting
but not (∧, ∨)-preserving translation from ω-variable classical logic to ω-variable
intuitionistic logic. Both of these translations may be restricted to be from n-
variable classical logic to n-variable intuitionistic logic for any n.
Some of the results of this paper may then be restated as follows: There
is a consequence- and tautology-respecting, (∧, ∨)-preserving translation of ω-
variable intuitionistic logic into 2-variable intuitionistic logic. We also get
consequence-
and
tautology-respecting
translations
(which
aren’t
(∧, ∨)-
preserving) of ω-variable classical logic into 2-variable intuitionistic logic by com-
posing with Gentzen’s translation. This translation may be read oﬀexplicitly
from the proof contained in this paper together with the construction of [4].
The disjunction property of intuitionistic logic implies that there can be no
tautology-respecting translation of classical logic into intuitionistic logic. In ad-
dition, we will show that there is no merely consequence-respecting, (∧, ∨)-
preserving translation of ω-variable classical logic into ω-variable intuitionistic
logic (and thus not into n-variable intuitionistic logic for any n).
The result that any countable partial order can be embedded in H2 implies
that any logic may be translated in a consequence- and tautology-respecting but
not necessarily (∧, ∨)-preserving way into 2-variable intuitionistic logic, as long
as the logic is countable.
The author would like to acknowledge Richard Shore and Anil Nerode for
many useful conversations and speciﬁc comments on this paper, and his parents
for their love and guidance.
2
Notation, Terminology, and Bellissima’s Construction
As above, let Vn = {x1, x2, . . . , xn}.
We will use Bellissima’s construction ([4]) of, for each n, a Kripke model Kn
over Vn satisfying Propositions 1 and 2 below. The construction and relevant
facts about it will be stated here.
Given a Kripke model K over Vn, let Nodes(K) be the set of nodes of K
and let ≤(K) be the (non-strict) partial order on Nodes(K) given by K. If no
confusion will result, we may use K in place of Nodes(K). Given α ∈K, let
w(α) = {xi ∈Vn | α ⊩xi}.
We will deﬁne a Kripke model Kn in stages, so that Kn = 
i Ki
n where the
Ki
n are deﬁned as follows:
Nodes(K0
n) = P(Vn) and ≤(K0
n) = {(α, α) | α ∈Nodes(K0
n)}. For clarity,
when we want to emphasize that we are thinking of U ⊆Vn as a node, we may
write node(U) or nodeKn(U). If we want to also note that it is in K0
n, we may
write node0(U) or node0
Kn(U). For U ⊆Vn, we let w(node(U)) = U.

440
M. O’Connor
Given K0
n, . . . , Ki
n, let Ti+1 be the set of subsets T of i
j=0 Kj
n such that
T ∩(Ki
n −Ki−1
n
) ̸= ∅and such that the elements of T are pairwise incomparable
with respect to ≤(Ki
n). Then we deﬁne Nodes(Ki+1
n
) −Nodes(Ki
n) to be
{⟨T, U⟩| T ∈Ti+1, U ⊆Vn, U ⊆

α∈T
w(α) and if T = {β}, then U ⊊w(β)}
For clarity, when we want to emphasize that we are thinking of ⟨T, U⟩as a node,
we may write node(⟨T, U⟩) or nodeKn(⟨T, U⟩). If we want to also note that it is
in Ki+1
n
, we may write nodei+1(⟨T, U⟩) or nodei+1
Kn (⟨T, U⟩).
We declare that w(⟨T, U⟩) = U and we let ≤(Ki+1
n
) be the reﬂexive transitive
closure of ≤(Ki
n) ∪{(⟨T, U⟩, β) | ⟨T, U⟩∈Ki+1
n
−Ki
n, β ∈T }.
Let k(φ) denote the set of nodes in Kn which force φ, for φ a propositional
formula in n variables.
Proposition 1 ([4]). For φ and ψ propositional formulas in x1, . . . , xn, φ ⊢ψ
iﬀk(φ) ⊆k(ψ).
Proposition 2 ([4]). For each node α ∈Kn, there is a φα such that k(φα) =
{β ∈Kn | β ≥α} and there is a φ′
α such that k(φ′
α) = {β ∈Kn | β ̸≤α}.
We now ﬁx some terminology.
If α < β are nodes in some Kripke model, then β is called a successor of α
and α a predecessor of β. If there is no γ with α < γ < β, then β is called an
immediate successor of α. The assertions “α is above β” and “β is below α”
both mean α ≥β.
For any node α in any Kripke model, s(α) is the set of α’s immediate
successors.
If α ∈Kn, then φα and φ′
α are as in Proposition 2.
For each m, Levn
m = Km
n −Km−1
n
. This may also be called Levm if n is clear
from context and may be denoted in English as “level m.”
If α ∈Kn, then Lev(α) is the unique i such that α ∈Levn
i . Note that if α ≤β,
Lev(α) ≥Lev(β).
If T is a set of nodes in Kn, let r(T ) = {α ∈T | ¬(∃β ∈T ) (β < α)}. Thus,
for example, for any T with |T | ≥2, ⟨r(T ), ∅⟩∈Kn. The following facts will be
used below and follow without much diﬃculty directly from the construction.
Fact 1. For n ≥2 and m ≥0, |Levn
m+1| > |Levn
m|. In particular, there are
arbitrarily large levels of Kn.
The following fact is a more general version of the preceding fact.
Fact 2. Let S ⊆Kn, |S| ≥3 and let each element of S be at the same level.
Let S′ be the downward closure of S. Then |S′ ∩Levn
m+1| > |S′ ∩Levn
m| for any
m greater than or equal to the common level of the elements of S .
3
A Lattice Embedding from Hm to Hn for m ≥1, n ≥2
Theorem 3. Let n ≥2, m ≥1. Then there are φ, ψ ∈Hn such that Hm
is isomorphic to [φ, ψ]. In addition, the isomorphism from [φ, ψ] to Hm can be
extended to a surjective lattice-homomorphism from Hn to Hm.

Embeddings into Free Heyting Algebras
441
Proof. The main work is contained in the following proposition.
Proposition 4. Let m ≥2 and n be such that there is a level Levn
i of Kn and a
set A ⊆Levn
i such that |A| = m and each α ∈A has some immediate successor
not above any other α′ ∈A. Then there is a φ, ψ ∈Hn such that Hm is lattice-
isomorphic to [φ, ψ] and in addition, the isomorphism from [φ, ψ] to Hm can be
extended to a surjective lattice-homomorphism from Hn to Hm.
Proof. Fix A and i from the hypothesis.
Let A = {α1, . . . , αm}. Let φ be

i
φαi.
For each A′ ⊆A, let γA′ be the node ⟨r(T ), ∅⟩where T = A′ ∪
α/∈A′ s(α).
This is valid as the elements of r(T ) are pairwise incomparable and |r(T )| ≥2
since m ≥2.
Note that γA′ is at level i + 1 if A′ is nonempty and at level i if A′ is empty.
Since each αi has a successor not above any other αj, if A′ ̸= A′′, γA′ ̸= γA′′.
Let S = {ρ ∈Ki+1
n
| (∀A′ ⊆A) (ρ ̸≥γA′)} and let ψ be ψ0 ∧ψ1 where ψ0 is
⎡
⎣¬¬(

A′⊆A
φγA′ )
⎤
⎦
and ψ1 is
	
ρ∈S
φ′
ρ
Deﬁne a function g with domain Km as follows:
1. g(nodeKm(U)) = γA′ where A′ = {αk | xk ∈Vm −U}.
2. g(nodej+1
Km(⟨T, U⟩)) = ⟨r(T ′), ∅⟩, where T ′ = {g(δ) | δ ∈T } ∪{αk | xk ∈
Vm −U}.
We will show that the range of g is contained in Kn. By induction, what we
must show is that ⟨r(T ′), ∅⟩is in Kn, which will hold as long as |r(T ′)| ≥2.
Lemma 5. The function g is into Kn and preserves order and nonorder. For
all β ∈Km and xk ∈Vm, β ⊩xk iﬀg(β) ̸≤αk.
Proof. We will prove by induction on i that g restricted to Ki
m satisﬁes the
conditions in the statement of the lemma.
For i = 0, observe that {g(node0(U)) | U ⊆Vm} is pairwise incomparable
and that if U ̸= U ′, g(node0(U)) ̸= g(node0(U ′)) as they have diﬀerent imme-
diate successors. It is also the case that for all node0(U) ∈K0
m and xk ∈Vm,
node0(U) ⊩xk iﬀxk ∈U iﬀγA′ ̸≤αk, where A′ = {αk | xk ∈Vm −U}.
Finally, since each γA′ is in Kn, the range of g restricted to K0
m is contained
in Kn.
Now suppose g restricted to Ki
m satisﬁes the hypotheses in the statement of
the lemma.

442
M. O’Connor
We ﬁrst show that the range of g restricted to Ki+1
m
is contained in Kn. Let
⟨T, U⟩∈Levm
i+1. If |T | ≥2, then |r(T )| ≥2 and we are done. If |T | = {β}, then
U ⊊w(β) and T ′ must contain both g(β) and αk, where xk ∈w(β) −U. Since
β ⊩xk, g(β) ̸≤αk. Since it is fairly easy to see that each αk is not less than any
element of the range of g, we must have |r(T ′)| ≥2.
It is immediate then that g restricted to Ki+1
m
is preserves order and the im-
mediate successor relation. Each element of Levm
i+1 is of the form nodei+1(T, U).
Observe that if U ̸= U ′ and ⟨T, U⟩, ⟨T, U ′⟩∈Km, then g(nodei+1(⟨T, U⟩)) ̸=
g(nodei+1(⟨T, U ′⟩)) as they have diﬀerent immediate successors. Similarly, if
r(T ) ̸= r(T ′) then g(nodei+1(⟨r(T ), U⟩)) ̸= g(nodei+1(⟨r(T ′), U ′⟩)) as they have
diﬀerent immediate successors. We can now conclude that g preserves nonorder
by using the inductive hypothesis and the fact that g preserves the immediate
successor relation.
Lemma 6. The sets ran(g) and k(φ) are disjoint and ran(g) ∪k(φ) = k(ψ).
Proof. It is immediate that ran(g) and k(φ) are disjoint.
We will ﬁrst show that ran(g) ∪k(φ) ⊆k(ψ). It is clear that k(φ) ⊆k(ψ).
Since every node in ran(g) is at level ≥i + 1, every node in ran(g) forces ψ1.
Since ψ0 is doubly negated and every successor of a node in ran(g) is in ran(g)
or k(φ), by induction every element of ran(g) forces ψ0 and ran(g) ⊆k(ψ).
We will now show that k(ψ) ⊆ran(g) ∪k(φ). By construction, k(ψ) ∩Ki
n =
k(φ) ∪{γA} and k(ψ) ∩Levn
i+1 = ran(g) ∩Levn
i+1 = ran(g|Levm
0 ) −γA. We will
show that k(ψ) ∩Levn
j ⊆ran(g|Levm
j−(i+1)) for all j ≥i + 1 by induction on j.
We just observed that this holds for j = i + 1.
Suppose it holds for j. A node of k(ψ) ∩Levn
j+1 must be of the form nodej+1
(⟨T, ∅⟩) for T ⊆k(ψ) ∩Kj
n. Since T must contain an element of k(ψ) ∩Levn
j and
every such node is below every element of k(ψ) ∩Levn
i−1, T must be a subset of
k(ψ)∩(Kj
n −Ki−1
n
). Let S = g−1(T ∩(Kj
n −Ki
n)) and U = {xk | αk ∈T ∩Levi}.
Then g−1(nodej+1
Kn (⟨T, ∅⟩)) is nodej−i
Km(⟨S, 
μ∈S w(μ) −U⟩)
It follows from Lemmas 5 and 6 that g is an order-isomorphism from Km to
k(φ) −k(ψ).
Deﬁne f : Fm →Fn by:
1. f(⊥) = φ
2. f(xi) = (φ′
αi ∨φ) ∧ψ
3. f(ρ0 ∧ρ1) = f(ρ0) ∧f(ρ1).
4. f(ρ0 ∨ρ1) = f(ρ0) ∨f(ρ1).
5. f(ρ0 →ρ1) = (f(ρ0) →f(ρ1)) ∧ψ.
Lemma 7. For any ρ ∈Fm, φ ⊢f(ρ) ⊢ψ. If δ = g(γ) then γ ⊩ρ iﬀδ ⊩f(ρ).
Proof. The proof that φ ⊢f(ρ) ⊢ψ is an easy proof by induction on ρ.
We now prove the second part of the lemma by induction on ρ.
For ρ = ⊥, the result is immediate. The observation that γ ⊩xi iﬀδ ̸< αi
furnishes the case where ρ is xi. The inductive steps follow from the existence
of the order-isomorphism g from Km to k(ψ) −k(φ) and the fact that φ ⊢f(ρ)
for all ρ.

Embeddings into Free Heyting Algebras
443
Note that it follows from Lemma 7 that f is injective and hence an embedding.
We now deﬁne a function from Fn to Fm that is an inverse to f when re-
stricted to [φ, ψ]. Deﬁne h from Fn to Fm as follows:
1. h(⊥) = h(xi) = ⊥.
2. h(ρ0 ∧ρ1) = h(ρ0) ∧h(ρ1).
3. h(ρ0 ∨ρ1) = h(ρ0) ∨h(ρ1).
4. If there is some δ ∈k(φ) ∩Ki−1
n
such that δ ̸⊩ρ0 →ρ1, then h(ρ0 →ρ1) =
⊥. Otherwise,
h(ρ0 →ρ1) = (h(ρ0) →h(ρ1)) ∧
	
{xi | αi ̸⊩ρ}
Lemma 8. Let δ = g(γ). For all ρ ∈Fn, δ ⊩ρ iﬀγ ⊩h(ρ).
Proof. We will prove this by induction on the level of γ and the structure of ρ.
If ρ is ⊥or xi, then δ ̸⊩ρ and γ ̸⊩h(ρ).
The inductive step for ρ = ρ0 ∨ρ1 and ρ = ρ0 ∧ρ1 is straightforward.
Let ρ be ρ0 →ρ1. Suppose δ ⊩ρ. Then, since for every μ ∈k(φ) ∩Ki−1
n
,
δ < μ, h(ρ) = (h(ρ0) →h(ρ1)) ∧{xi | αi ̸⊩ρ}. Since δ ⊩ρ, if αi ̸⊩ρ, δ ̸< αi.
It follows that γ ⊩xi. Thus γ forces the right conjunct of h(ρ).
Suppose δ ⊩ρ0 and δ ⊩ρ1. Then we are done by the inductive hypothesis on
the structure of ρ. Otherwise, suppose δ ̸⊩ρ0. Then we are done by the inductive
hypothesis on the structure of ρ and the level of γ.
Now suppose δ ̸⊩ρ. Then there is some μ ≥δ such that μ ⊩ρ0 and μ ̸⊩ρ1. If
μ is in the range of g then we are done by induction. If μ ∈Ki−1
n
, then h(ρ) = ⊥
and we are done. Otherwise μ ∈Ki
n and is some αj. Since δ < αj, γ ̸⊩xj and
γ ̸⊩h(ρ).
It follows from Lemma 8 and Lemma 7 that if φ ⊢ρ ⊢ψ, then f(h(ρ)) = ρ.
If n ≥2, m ≥2 by Fact 1 we can ﬁnd a level in Kn satisfying the hy-
potheses of the Proposition. For example, we may pick a level in Kn of car-
dinality greater than 2m, call 2m of its elements β1, . . . , β2m, and let A =
{⟨{β1, β2}, ∅⟩, . . . , ⟨{β2m−1, β2m}, ∅⟩}.
If m = 1, then we may let φ be ⊥and ψ be x2 ∧. . . ∧xn. The embedding f
from H1 to [φ, ψ] ⊆Hn sends ρ to ρ ∧x2 ∧. . . ∧xn. We may deﬁne a surjective
lattice homomorphism h from Hn to H1 that is an inverse to f as follows:
h(x1) = x1
h(xi) = ⊤for 1 < i ≤n
h(φ ∧ψ) = h(φ) ∧h(ψ)
h(φ ∨ψ) = h(φ) ∨h(ψ)
h(φ →ψ) = h(φ) →h(ψ)
Corollary 9. There is a consequence-respecting, (∧, ∨)-preserving translation
but not tautology-respecting from m-variable intuitionistic logic to n-variable in-
tuitionistic logic for n ≥2.
Proof. Immediate.

444
M. O’Connor
Corollary 10. There is a consequence- and tautology-respecting translation
from m-variable intuitionistic logic to n-variable intuitionistic logic for n ≥2.
Proof. Let f : Fm →Fn be a consequence-respecting translation from m-variable
intuitionistic logic to n-variable intuitionistic logic. Deﬁne f ′ by f ′(φ) = f(⊤) →
f(φ).
Then f ′ is consequence- and tautology-respecting. To see that it is consequence-
respecting: If Γ ⊢φ then f(Γ) ⊢f(φ), so f(⊤) →f(Γ), f(⊤) ⊢f(φ) and f(⊤) →
f(Γ) ⊢f(⊤) →f(φ), where f(⊤) →f(Γ) is an abbreviation of {f(⊤) →ψ | ψ ∈
f(Γ)}.
Conversely, if f(⊤) →f(Γ), f(⊤) ⊢f(φ), then f(Γ) ⊢f(φ) since f(Γ) ⊢
f(⊤) →f(Γ) and f(Γ) ⊢f(⊤) (this last fact is due to the fact that f is
consequence-preserving).
Corollary 11. There is a consequence- and tautology-respecting,(∧,∨)-preserving
translation from m-variable intuitionistic logic to n-variable intuitionistic logic for
n ≥2.
Proof. Let f : Fm →Fn be a consequence-respecting and (∧, ∨)-preserving trans-
lation from m-variable intuitionistic logic to n-variable intuitionistic logic. Deﬁne
f ′ by
f ′(φ) =

f(φ)
̸⊢m
I φ
⊤
⊢m
I φ
This is clearly still consequence-respecting and ∧-preserving. The disjunction
property of intuitionistic logic implies that it is also ∨-preserving.
Note that the translations given in Corollaries 9 and 10 can be done in linear
time, while the one given in Corollary 11 cannot, as it requires deciding whether
the given formula is a tautology.
By [4], Hn for n ≥2 has an inﬁnite descending chain, while H1 does not, so
there is no embedding of Hn into H1 for n ≥2.
4
A Lattice-Embedding from Hω to Hn for n ≥2
Theorem 12. There is a lattice-embedding from Hω into H2
Proof. Pick α1, α2, α3, α4, α5 ∈K2, all at the same level, say i. This may be
done by Fact 1. Let S = {ρ ∈Ki
2 | ∀i ∈{1, 2, 3, 4} ρ ̸≥αi}. Let φ be
(¬¬(α1 ∨α2 ∨α3 ∨α4)) ∧
	
β∈S
φ′
β.
Let T = {ρ ∈Ki
2 | ∀i ∈{1, 2, 3, 4, 5} ρ ̸≥αi}. Let ψ be
(¬¬(α1 ∨α2 ∨α3 ∨α4 ∨α5)) ∧
	
β∈T
φ′
β.

Embeddings into Free Heyting Algebras
445
Deﬁne a sequence {βj
i | i ∈ω, j ∈{1, 2, 3, 4}} as follows: let βj
0 = αj. For
i ≥0, let {βj
i+1 | j = 1, 2, 3, 4} be a collection of four distinct nodes of the same
level, with Lev(β1
i+1) > Lev(β1
i ) and such that they all force ¬¬(β2
i ∨β3
i ∨β4
i ).
For example, we may take β1
i+1 = ⟨{β2
i , β3
i }, ∅⟩, β2
i+1 = ⟨{β2
i , β4
i }, ∅⟩, β3
i+1 =
⟨{β3
i , β4
i }, ∅⟩, and β4
i+1 = ⟨{β2
i , β3
i , β4
i }, ∅⟩.
As in [4] (where a very similar construction is done), the nodes of {β1
i | i ∈ω}
are pairwise incomparable, and they all force φ.
Deﬁne a Kripke model K over the language Vω = {xi | i ∈ω} as follows: The
set of nodes of K is the set k(ψ) −k(φ) and a node α forces xi iﬀα ̸≤β1
i .
For all φ ∈Fω, let k(φ) = {α ∈K | α ⊩φ}.
Lemma 13. For all φ, ψ ∈Fω, k(φ) ⊆k(ψ) iﬀφ ⊢ψ.
Proof. Since K is a Kripke model, if φ ⊢ψ, k(φ) ⊆k(ψ).
Suppose φ ̸⊢ψ. Then there is a rooted ﬁnite Kripke model K′ over Vω such
that K′ ⊩φ and K′ ̸⊩ψ. Since variables not occurring in φ or ψ are irrelevant, we
may assume that each node of K′ forces coﬁnitely many propositional variables.
Deﬁne a map a: K′ →K inductively on K′ as follows: If γ ∈K′ is a node
such that a(γ′) has deﬁned for all immediate successors of γ, then let a(γ) be
a node whose set of successors in K2 is the upward-closure of the set {β1
i | γ ̸⊩
xi} ∪{a(γ′) | γ′ ≥γ} ∪{α5}.
For each i, γ ⊩xi iﬀa(γ) ⊩xi. Since a is also order-preserving and its range is
upward-closed in K, we have that if γ is the root of K′, a(γ) ⊩φ and a(γ) ̸⊩ψ.
Now, as before, deﬁne f : Fω →F2 by:
1. f(⊥) = φ
2. f(xi) = (φ′
β1
i ∨φ) ∧ψ
3. f(ρ0 ∧ρ1) = f(ρ0) ∧f(ρ1).
4. f(ρ0 ∨ρ1) = f(ρ0) ∨f(ρ1).
5. f(ρ0 →ρ1) = (f(ρ0) →f(ρ1)) ∧ψ.
By precisely the same argument as before, this is an embedding.
Note that, by [4], in any interval [φ, ψ] ⊆Hn, there are atomic elements. As there
are no atomic elements in Hω, Hω cannot be embedded in Hn as an interval.
5
Impossibility of Lattice-Embedding Bω into Hω
Let Bω be the countable atomless Boolean algebra. We will think of it as the
Lindenbaum algebra of classical propositional logic on countably inﬁnitely many
variables.
Proposition 14. There is no lattice embedding from Bω into Hn for any n or
into Hω.
Proof. By the previous theorem, it suﬃces to prove the proposition for H2.
Suppose there is a lattice embedding of Bω into H2. Call it f.

446
M. O’Connor
Let f(⊤) have n subformulas. Consider the 2n formulas φ1 = x1 ∧· · · ∧xn,
φ2 = x1 ∧· · · ∧¬xn, . . . , φ2n = ¬x1 ∧· · · ∧¬xn. Since f preserves ∧and ∨we
must have that {k(f(φi)) | 1 ≤i ≤2n} is a partition of k(f(⊤)) −k(f(⊥)) and
that k(f(φi)) ∩(k(f(⊤)) −k(f(⊥))) is non-empty for each i.
Lemma 15. Let α be a node in a Kripke model with exactly two immediate
successors, α1 and α2. Let φ be a formula. Suppose that for each subformula φ′
of φ, α1 ⊩φ′ iﬀα2 ⊩φ′ and that for all propositional variables v appearing in
φ, if α1 and α2 force v, then α ⊩v. Then for each subformula φ′ of φ, α ⊩φ′
iﬀα1 ⊩φ′. In particular, α ⊩φ iﬀα1 ⊩φ iﬀα2 ⊩φ.
Proof. By induction on the structure of φ. The conclusion is immediate if φ is
atomic, and the ∧and ∨cases are straightforward.
Suppose φ is φ1 →φ2. By induction, we can conclude that α ⊩φ′ iﬀα1 ⊩φ′
if φ′ is a subformula of φ1 or φ2. We just have to verify that α ⊩φ iﬀα1 ⊩φ.
Suppose α ⊩φ. Then, as α1 ≥α, α1 ⊩φ.
Now suppose α ̸⊩φ. Thus, there must be some α′ ≥α such that α′ ⊩φ1
and α′ ̸⊩φ2. If α′ = α then we are done by induction. Otherwise, we must have
α′ ≥α1 or α′ ≥α2, and thus α1 ̸⊩φ.
For each i, let βi ∈k(f(φi)) ∩(k(f(⊤)) −k(f(⊥))). By the pigeonhole principle,
there must be some i and j, i ̸= j, such that βi ⊩φ′ iﬀβj ⊩φ′ for all subformulas
φ′ of f(⊤). Let β be ⟨{βi, βj}, w(βi) ∩w(βj)⟩. We can easily verify that β ∈K2.
By the lemma, β ∈f(⊤). Thus, β is in k(f(φm))∩(k(f(⊤))−k(f(⊥))) for some
m. Without loss of generality, say m ̸= i. Then βi ⊩f(φm) and βi ⊩f(φi) but
βi ̸⊩f(⊥), a contradiction.
6
Order-Embeddings
Proposition 16. Any countable partial ordering can be order-embedded into H2
(and, therefore, into Hn for any n ≥2).
Proof. We ﬁrst make the following deﬁnition:
Deﬁnition 17 (ψ(α1, . . . , αm), Permissive formulas). Let {α1, . . . , αm} be
a set of nodes of K2 all with the same level. Let S(α1, . . . , αm) = {δ ∈K2 |
Lev(δ) ≤Lev(α1) and ∀i δ ̸≥αi}.
We deﬁne ψ(α1, . . . , αm) to be

¬¬
m

i=1
φαi

∧
	
δ∈S(α1,...,αm)
φ′
δ
If T = {α1, . . . , αm} then ψ(T ) will denote ψ(α1, . . . , αm). If some αi is at a
diﬀerent level than some αj, ψ(α1, . . . , αm) is not deﬁned.
A formula of the form ψ(α1, . . . , αm) where m ≥3 will be called permissive.
The set {α1, . . . , αm} is called the set of generators of ψ(α1, . . . , αm) and Lev(α1)
is called the level of ψ(α1, . . . , αm).

Embeddings into Free Heyting Algebras
447
Lemma 18. Given any permissive formula ψ, there exist permissive formulas
ψn for n ∈{0, 1} such that for each n ∈{0, 1}, k(ψn) ⊆k(ψ) and k(ψ0) ∩k(ψ1)
is ﬁnite.
Proof. Let i be greater than the level of ψ with |Levi ∩k(ψ)| ≥6. We can ﬁnd
i by Fact 2. Let Levi ∩k(ψ) = {α1, α2, α3, β1, β2, β3, . . .}, let ψ0 = ψ(α1, α2, α3)
and ψ1 = ψ(β1, β2, β3).
Deﬁnition 19 (ψσ). We deﬁne ψσ, for σ ∈{0, 1}<ω as follows: Let ψε = ⊤.
Given φσ, deﬁne φσn for n ∈{0, 1} so that φσn is permissive, k(φσn) ⊆k(φσ),
and k(φσ0) ∩k(φσ1) is ﬁnite as in the above lemma.
Note that ψσ ⊢ψσ′ iﬀσ is an initial segment of σ′ as a binary string. Note also
that ψσ ⊢
i ψσi iﬀthere is an i such that σ = σi.
Deﬁnition 20 (Complete Sets). A set S ⊆H2 such that each element of S is
a disjunction of the form n
i=1 ψσi is called complete if it satisﬁes the following
property: Let S1, S2 be such that S1 ∪S2 = S, S1 ∩S2 = ∅, S1 is upward closed,
and S2 is downward closed. Then there is some σ(S1, S2) such that |σ(S1, S2)| >
max{|σ| | ψσ a disjunct of a formula in S}, ψσ(S1,S2) implies every element of
S1, and ψσ(S1,S2) implies no element of S2.
Note that the condition that
|σ(S1, S2)| > max{|σ| | ψσ a disjunct of a formula in S}
means that no ψσ ∈S can imply ψσ(S1,S2).
Note also that if σ1 is such that |σ1|>max{|σ| | ψσ a disjunct of a formula in S},
ψσ1 implies every element of S1, and ψσ1 implies no element of S2 then so does
σ1σ2 for any σ2 (where the juxtaposition indicates concatenation). Without loss of
generality, then, we may assume that each σ(S1, S2) has the same length.
The proposition will follow from the following lemma.
Lemma 21. Suppose P is a ﬁnite partial order, S ⊆H2 is a complete set,
and h is an isomorphism from P to (S, ≤). For any partial order P ′ such that
|P ′| = |P| + 1, there is a φ of the form 
i ψσi such that S ∪{φ} is complete,
P ′ ≃(S ∪{φ}, ≤) via an isomorphism extending h.
Proof. If P = ∅, let φ be ψ0. This is complete as we may let σ({φ}, ∅) = 00 and
σ(∅, {φ}) = 10.
Suppose S = T1 ∪T2 ∪T3 where T1 is downward closed and T2 is upward
closed, and we would like to ﬁnd φ so that φ is above all the elements of T1,
below all the elements of T2 and incomparable with the elements of T3.
Let S be the collection of all partitions (S1, S2) of S such that S1 is upward
closed and S2 is downward closed.
Let φ be

χ∈T1
χ ∨

{ψσ(S1,S2)0 | (S1, S2) ∈S and T2 ⊆S1}

448
M. O’Connor
Clearly, φ is above every χ ∈T1. We also have that φ is below every ρ ∈T2,
since every χ ∈T1 must be below every ρ ∈T2, and by deﬁnition every ψσ(S1,S2)0
with T2 ⊆S1 is below every ρ ∈T2.
φ is not above any element in T2 ∪T3: As noted above, ψσ ⊢ ψσi implies
σ = σi for some i. But the disjuncts of φ are either elements of T1 (which cannot
be implied by elements of T2 or T3) or of the form ψσ where the length of σ is
greater than the length of any σ′ for ψσ′ some disjunct of a formula in T2 ∪T3.
φ is not below any element in T1 ∪T3: Let μ ∈T1 ∪T3. Let S2 = {μ′ | μ′ ≤μ}
and S1 = S −S2. Then ψσ′(S1,S2)0 is a disjunct of φ which does not imply μ.
To see that S ∪{φ} is complete: Let (S1, S2) ∈S with φ ∈S1. Since S1 is
upward closed, we must have T2 ∪S1. Thus ψσ(S1−{φ},S2)0 is a disjunct of φ. We
may therefore take σ(S1, S2) to be σ(S1 −{φ}, S2)0 concatenated with enough
zeroes to make its length greater than max{σ | ψσ a disjunct of a formula in S∪
{φ}}.
Let (S1, S2) ∈S with φ ∈S2. Thus T1 ⊆S2. If there is any member of
T2 in S2, then we may take σ(S1, S2) to be any suﬃciently long extension of
σ(S1, S2 −{φ}), since ψσ(S1,S2−{φ}) cannot imply φ since φ implies each element
of S2.
Thus we may assume that T2 ⊆S1. Therefore, ψσ(S1,S2−{φ})0 is a disjunct of
φ. By construction, there are no disjuncts of φ above it. We may take σ(S1, S2)
to be any suﬃciently long extension of σ(S1, S2 −{φ})1.
References
1. The Coq proof assistant, http://coq.inria.fr.
2. The PRL project, http://www.nuprl.org.
3. Michael Beeson, Foundations of constructive mathematics: Metamathematical stud-
ies, Springer, Berlin/Heidelberg/New York, 1985
4. Fabio Bellissima, Finitely generated free Heyting algebras, Journal of Symbolic
Logic 51 (1986), 152–165
5. Carsten Butz, Finitely presented Heyting algebras, http://www.itu.dk/∼butz/
research/heyting.ps.gz, 1998
6. Luck Darni`ere and Markus Junker, On ﬁnitely generated Heyting algebras, http://
home.mathematik.uni-freiburg.de/junker/preprints/heyting-221005.pdf,
2005
7. Silvio Ghilardi and Marek Zawadowski, A sheaf representation and duality for
ﬁnitely presented Heyting algebras, Journal of Symbolic Logic 60 (1995), 911–939
8. Jean-Yves Girard, Yves Lafont, and Paul Taylor, Proofs and types, Cambridge
University Press, Cambridge, 1989
9. Anil Nerode, George Odifreddi, and Richard Platek, Constructive logics and lambda
calculi, in preparation
10. Iwao Nishimura, On formulas of one variable in intuitionistic propositional calcu-
lus, Journal of Symbolic Logic 25 (1960) 327–331
11. Alasdair Urquhart, Free Heyting Algebras, Algebra Universalis 3 (1973) 94–97

Some Puzzles About Probability
and Probabilistic Conditionals⋆
Rohit Parikh
City University of New York
rparikh@gc.cuny.edu
Abstract. We examine some old and new paradoxes of probability, give
a rough account of probabilistic conditionals, and prove a new result
about non-monotonicity in probabilistic conditionals. It is well known
that such conditionals are not monotonic – a conditional which is true
can become false when additional hypotheses are added. We show that
nonetheless, the conditionals are usually monotonic, or roughly speak-
ing that we do not actually have to worry about non-monotonicity in
practice.
Einstein famously said that God does not play dice. This attitude of his led to
a certain estrangement with Quantum Mechanics and even with Physics during
the last years of his life, otherwise marked by a close friendship with Kurt G¨odel.
Einstein aside, probability is a puzzling phenomenon, for what exactly does it
mean? One supposedly unproblematic way to deﬁne it is via frequencies. To say
that a coin is fair, i.e., that the probability of heads is .5, can then be interpreted
as, If we toss the coin many times, then approximately half of the results will be
heads. But how many is many? Of course, if we toss the coin a hundred times,
we probably will not get exactly ﬁfty heads, and even if we toss it a thousand
times, the proportion of heads can diverge quite a bit from .5. This is not likely,
but explaining that word likely looks like it involves probability.
Moreover, if Jack wants to insure a car, the frequency deﬁnition is no good.
The insurance company needs to know the probability that he, Jack will have an
accident. And clearly there is no frequency available for the insurance company
to resort to. Jack only wants to insure his car once. And even if he wants to insure
the car a second time, he will be a year older, and hopefully more experienced.
The probability of his having an accident, however we deﬁne it, will not be the
same the second time.
An alternative approach is that due to Ramsey, de Finetti, Savage, etc. Ram-
sey deﬁnes probability subjectively, in terms of the bets which an agent is willing
to accept. Your subjective probability of heads is .5 if you are willing to accept
a double or nothing bet in favour of heads, and also a double or nothing bet
against heads. But what bets you want to accept is up to you. There is nothing
intrinsically objective about your bet-acceptance attitudes.
⋆Dedicated to Anil Nerode on his 75th birthday. Research supported in part by a grant
from PSC-CUNY grants program. Versions of this paper were given in colloquia at
Boston University, CUNY Graduate Center, and at IHPST in Paris.
S. Artemov and A. Nerode (Eds.): LFCS 2007, LNCS 4514, pp. 449–456, 2007.
c
⃝Springer-Verlag Berlin Heidelberg 2007

450
R. Parikh
There are standards of rationality which will apply. If you think in October
2004 that the probability that Bush will win is .5 and also that the probability
that Kerry will win is .6, then bets can be placed in such a way that no matter
what happens you will lose money. For an opponent can bet $20 at even odds
against Bush winning, and also $16 at 3:2 odds against Kerry winning. Then if
Bush wins, you gain $20 from the ﬁrst bet but lose $24 on the second bet. If
Kerry wins, you gain $16 from the second bet and lose $20 from the ﬁrst, and
ﬁnally if neither wins, you lose both bets. You lose in all three cases.
In other words, a Dutch book can be made against you, a term which already
occurs with de Finetti who says that he is puzzled by the name – the Dutch are
even more puzzled! It is of course well known that an agent against whom Dutch
book cannot be made has a subjective probability which satisﬁes the Kolmogorov
axioms like 0 ≤p(E) ≤1 and p(E ∨F) = p(E) + p(F) when E ∧F is null.1
But even if two people are both rational in the sense that Dutch book cannot
be made against either of them, it need not be the case that they both have the
same subjective probability. Thus the question What is the actual probability
p(E) of the event E? cannot be answered. The only solace we have is that if
two agents start by assigning positive (but diﬀerent) probabilities to the same
events, and they have the same experiences, and they both revise using Bayes’
law, then their probabilities will converge in the long run.
So the notion of probability does have some foundational problems. But I
want to put these problems aside, and talk about some paradoxes, both old and
recent, and conclude with a new result about probabilistic conditionals.
The Saint Petersburg Paradox
“The St. Petersburg game is played by ﬂipping a fair coin until it comes up tails,
and the total number of ﬂips, n, determines the prize, which equals 2n. Thus
if the coin comes up tails the ﬁrst time, the prize (in dollars) is 21 = 2, and
the game ends. If the coin comes up heads the ﬁrst time, it is ﬂipped again. If
it comes up tails the second time, the prize is 22 = 4, and the game ends. If
it comes up heads the second time, it is ﬂipped again. And so on. There are
an inﬁnite number of possible consequences (runs of heads followed by one tail)
possible. The probability of a consequence of n ﬂips (P(n)) is 1 divided by 2n,
and the expected payoﬀof each consequence is the prize times its probability.”
Stanford Encyclopedia of Philosophy.
How much should you pay to participate in the St. Petersburg game? It is
easily calculated that the expected payoﬀis inﬁnite. You will win $2 with prob-
ability .5, $4 with probability .25, $8 with probability .125, etc, adding up in all
to ∞. Therefore any amount whatsoever is acceptable as payment to enter the
game. But most people rebel at the thought.
One possible solution to this puzzle is to use utilities rather than payoﬀs. If
we say that the utility value of a ﬁnancial payoﬀis logarithmic in the payoﬀ,
then the expected utility of the St. Petersburg game will be ﬁnite and it would
1 Isaac Levi [14] considers families of probabilities, but we shall not go into that here.

Some Puzzles About Probability and Probabilistic Conditionals
451
be a mistake to pay an amount whose utility would exceed the expected utility
of the game. This was essentially the suggestion of Daniel Bernoulli.
But Bernoulli’s suggestion would not prevent other paradoxes, for if the payoﬀ
were 22n with n = the number of heads before a tail, then the payoﬀfrom
each outcome multiplied by the probability of that outcome would again be
exponential in dollars, and hence again linear in utility. This would again give
an inﬁnite expected utility to the game. See also Paul Weirich [22].
The Sleeping Beauty
But let us go on to our second, much more modern paradox due to Adam Elga,
based on an earlier paper of Ariel Rubinstein. Sleeping Beauty (SB) is put to
sleep on a Sunday using some drug, and after that a fair coin is tossed. If the
coin comes up heads, she is woken on Monday and asked the question Q (to be
described later). If the coin comes up tails, she is woken up on Monday, asked
the question Q, and then put back to sleep, woken up again on Tuesday and
again asked the question Q. Sleeping Beauty knows this procedure and that the
coin is fair. But when she is woken, she does not know what day of the week it
is and whether she was woken before or not. Of course she does know that the
day is either Monday or Tuesday, but she does not know which.
The question Q is,
What is the probability that the coin landed heads?
One answer is that it is .5. The coin is fair and SB knows this. Moreover, she
knew all along that she would be woken up. The fact that she is woken up and
asked Q is not surprising information which might change the probability. So
the answer is .5. Or is it?
Suppose it is .5, and so she accepts a double or nothing bet on heads each time
that Q is asked. Over a hundred trials, there will be ﬁfty heads and ﬁfty tails,
roughly. When the coin lands heads, she will win one dollar (say) and when it
lands tails, she will lose two dollars, one for each time she is asked Q. So she
will end up losing $50 net. This is not compatible with a .5 probability, and the
right probability would be 1/3, or about .33.
Which is the right answer? And is there a right answer? Various people have
written on this and let me just refer you to recent papers by Halpern, and by
Bradley and Leitgeb [11,3]. Halpern claims that the problem here is asynchrony,
an issue that arises often in distributed computing. Bradley and Leitgeb claim
that the connection between betting and probability is only valid under certain
presumptions, which fail in this case.
Probabilistic Conditionals
How should we interpret a conditional like, “If John comes to the party, then so
will Mary”, i.e., of the form If A then B ? The standard interpretation used in
mathematics is to treat it as equivalent to A →B, i.e., as ¬A ∨B. See [20,17]
But often, this does not ﬁt our intuition. The following example due to
Dorothy Edgington is instructive. Clearly if God does not exist, then he

452
R. Parikh
cannot answer our prayers. Consider the statement S: If God does not exist,
then it is not the case that if I pray, my prayers will be answered. Many who
disagree about the existence of God will tend to accept S. There are two if s in S.
Can they both be expressed as material conditionals? So suppose we symbolize
S as
¬G →¬(P →A), interpreting both implications, the main one on the
outside, and the subsidiary one inside the parentheses, as material implications.
Also suppose I don’t pray. Then P is false and P →A is true. Hence ¬(P →A)
is false. But then for S to be true, ¬G must be false and hence G must be true.
I can prove the existence of God simply by not praying!
Even those who believe in God will ﬁnd this argument ﬁshy and will look
more kindly on other ways, beside the material conditional, of interpreting the
indicative conditional.2
One suggestion, associated with Ernest Adams and Edgington herself [1,5], is
to treat the conditional probabilistically. Thus asserting If A then B is tanta-
mount to saying that the probability of B given A is high. Someone who says,
“If John comes to the party, Mary will come too,” is asserting that p(M|J) is
high, perhaps more than .9.
Such probabilistic conditionals received a blow from results of David Lewis [15]
who showed that (on pain of triviality) such conditionals cannot be interpreted
as propositions. In other words, there cannot be a proposition (a set of possible
worlds) C such that p(C) = p(B|A) for all probability measures P.
But let us leave that worry aside and ask about the logic of probabilistic
conditionals interpreted not as an implication (i.e., as a connective) but instead
as a consequence relation |∼. This avoids the Lewis’ problem because we are
not saying that If A then B is a proposition. Let us say that we accept A |∼B
if p(B|A) is high, where the |∼represents the indicative conditional interpreted
probabilistically.
Horacio Arlo Costa and RP [2] looked at probabilistic conditionals in the
context of cores,3 a notion investigated by Bas van Fraasen and we looked at
some conditions on non-monotonic relations considered by Dov Gabbay, and by
Kraus, Lehmann and Magidor [8,13].
Various rules of inference apply to such consequence relations. Thus from
A |∼B and B |= C we can derive A |∼C, where |= represents the classical conse-
quence. This rule is (RW) or right weakening and is sound. So is the rule (AND)
which derives A |∼B∧C from A |∼B and A |∼C (provided we make some sacriﬁce
in probability4). But a rule which does not hold is monotonicity (M), or
Strengthening the antecedent. This would be the rule, from A |∼B and C |= A
we should be able to derive C |∼A. In particular we would like to be able to
derive (A ∧X) |∼B from A |∼B.
A |∼B
(M)
—————–
A ∧X |∼B
2 This particular variety of conditional is called the indicative conditional, to distin-
guish it from so called subjunctives or counterfactuals.
3 [2] interpret “high” as 1.
4 If p(B|A) > .95 and p(C|A) > .95, then p(B ∧C|A) > .9.

Some Puzzles About Probability and Probabilistic Conditionals
453
Alas, the rule (M) is known not to be sound. The probability of B given A
may be high, and the probability of B given A and X may be low. For instance,
if our domain is integers upto 100, then the probability that n is odd given that
it is prime is quite high. But the probability that it is odd given that it is prime
and less than 4 is only .5.
A well known example involves birds. Given that Tweety is a bird there is a
high probability that it ﬂies. But given that Tweety is a bird and a penguin, the
probability drops to 0.
What we show below is that the rule (M) is mostly sound. That is that
provided that A is large enough, for most X, the conclusion continues to hold.
Probabilistic conditionals are mostly monotonic. And this is good news, for
clearly, while accepting that the monotonicity condition does not hold univer-
sally, we do want it to hold usually.
For consider birds. If the dictum, “Birds ﬂy’” could be destroyed at the drop
of a hat, it would be useless. We could not conclude that female birds ﬂy, that
blue birds ﬂy, or that the bird sitting on the window sill is likely to ﬂy. It is
almost always the case that when we know that some creature is a bird, we also
have some additional information X. And usually, we do not drop the dictum
Birds ﬂy when we have some additional information. Thus it must be the case
that the dictum is sort of sturdy. Information like, “It is a penguin,” is unusual.
It is this sturdiness that we will prove below.
We are representing propositions as sets of possible worlds. We have ourselves
objected to this identiﬁcation [16]. But the representation is commonly accepted
and a result which uses it ought to have a relevance. The following theorem is
stated rather loosely, but will be followed up by a more precisely stated theorem.
Theorem 1. Suppose that W is a ﬁnite space, with all points equally likely.
Suppose that A, B are large subsets of W and p(B|A) > .95, then for most
randomly selected X ⊆W, p(B ∩X|A ∩X) = p(B|A ∩X) > .945.
Of course the set theoretic operation ∩corresponds to the logical operation ∧.
In terms of |∼it means that if you know A |∼B and want to know if A∧X |∼B,
the answer will be, “Most likely”.
We have used the numbers .95, .945, and the uniform distribution on W for
convenience, but of course the result holds more generally, as will be evident from
the proof. What ‘large’ B means will be made more explicit below. The technique
of proof requires the binomial theorem and its Gaussian approximation. It is
quite accessible.
We start by noting some simpliﬁcations. Since we are taking probabilities
relative to A or its subsets, the points in W which are not in A play no role.
So we shall assume that A = W. This automatically implies that B ⊆A, an
assumption which we could have justiﬁed independently.
Suppose now (using our assumption of largeness) that the set A −B has
cardinality 10,000 and hence, since p(B|A) > .95, B has cardinality (at least)
190,000. A random subset X of A has two parts: XB which is simply X ∩B,
and the remaining part XR of X, which is X ∩(A −B).

454
R. Parikh
The expected size of XB is 95,000 (half of 190,000) but it could be more or
less. But by the weak law of large numbers, the standard deviation σ of the size
of XB is .5 × √190, 000, which is between 435 and 436. Thus 95, 000 −3σ is
more than 93,682. It is unlikely that the actual value diﬀers from the expected
value by more than 3σ. Indeed, using standard tables, the probability that XB
has size more than 93,682 exceeds .9987. Similarly, the set XR has expected
size 5,000, but the standard deviation σ′ is 50. Thus with the same probability
.9987, XR has size less than 5,150. Thus with probability greater than .9974, the
ratio card(XB)/(card(XB ∪XR)) is greater than 93,682/(93,682+5,150) which
is .94789, or very nearly .95. (The ﬁgure .9974 comes from the fact that even if
both errors of .0013 (1 - .9987) were to add up, we would still only get an error
of .0026)
This means that if the sets A, B are both large, and p(B|A) > .95, then
(when a random subset X of A is chosen) with probability greater than .9974,
p(B ∩X|A ∩X) > .94789
We can show that similar results will hold if the
random set X is chosen in some other way. E.g. if we toss a die for each point
of A and put a point in X only if the die shows a 6, the results will still hold.
One could ask if the rule (M) can be called sound if it holds only for most
X. However, note that A |∼B does not say that if A is true, then B is also true
100% of the time. It only says that if A holds, then B is very likely to hold. If
the rule applies 99.74% of the time, and the premise (which we accepted) only
‘applies’ 95% of the time then it is hard to justify the premise while rejecting
the rule.
We now state a more precise result, which actually generalizes the observation
above to the case where the probability α of B relative to A is positive, but not
necessarily close to 1.5
The intuitive idea is that we can think of the set X as a random sample
from the space W, in which case X ∩A will be a random sample from A.
The expected size of X ∩A is half the cardinality ||A|| of A and its standard
deviation is .5 ×

||A||. The same holds for the expected size of X ∩B except
for the multiplier α. Now if the actual sizes of the two sets were the same as
their expected sizes, then we would get p(B ∩X|A ∩X) to be equal to p(B|A).
Of course we cannot expect to be so lucky, for actual size can deviate from the
expected size. However, as the sizes of A and B go up, the deviation matters less
and less, and so the diﬀerence between p(B ∩X|A ∩X) and p(B|A) will tend to
zero. This gives us our second result.
Theorem 2. Let α > 0 be ﬁxed and let sets An, Bn increase in size with Bn ⊆
An and |p(Bn|An) −α| →0. Let Xn be randomly chosen subsets of An and
ϵ > 0. Then as n →∞, p[ |(||Bn ∩Xn||/||An ∩Xn||) −α| > ϵ] →0.
In other words, if our prior probability of B given A was α > 0, and we received
additional information X, then provided A was large, we should expect the
5 I am using α for this probability – a number, as I am using p for the probability
function.

Some Puzzles About Probability and Probabilistic Conditionals
455
posterior probability of B given A to still be close to α, and the probability that
it diﬀers by more than ϵ goes to 0 as ||A|| goes to inﬁnity.
We have not looked at the case where A is not merely large but is actually
inﬁnite. Clearly, investigating that case will involve an excursion into measure
theory – perhaps methods from Non-standard analysis will allow a transition
from the large ﬁnite case to the inﬁnite case.
Another rule,
A |∼B
————-
¬B |∼¬A
is not capable of a similar treatment. If our universe consists solely of the innu-
merable pigeons and the relatively few penguins, then “Most birds ﬂy” will be
true, but “Most non-ﬂyers are non-birds” will be false. Indeed all non-ﬂyers will
be birds in our universe!
Acknowledgement. We thank Evan Goris, Dexter Kozen, Roman Kuznets,
Sergiu Hart, Matt Johnson, Bud Mishra and Samer Salame for comments.
References
1. E. Adams, “Probability and the logic of conditionals,” in Aspects of Inductive
Logic, edited by Suppes and Hintikka, (1968), North Holland, 265-316.
2. Horacio Arlo Costa and Rohit Parikh “Conditional probability and defeasible in-
ference,” Journal of Philosophical Logic, 34 (2005) 97-119.
3. Darren Bradley and Hannes Leitgeb, “When betting odds and credences come
apart: more worries for the Dutch book arguments,” Analysis, 66.2, 2006,
119-127.
4. The binomial theorem,
http://www.stat.yale.edu/Courses/1997-98/101/binom.htm
5. Dorothy Edgington, “On Conditionals,” Mind, 104, 1995, 235-329.
6. Adam Elga, “Self-locating belief and the Sleeping Beauty problem,” Analysis, 60,
(2000) 143-147.
7. Bruno de Finetti, “Foresight: its logical laws, its subjective sources,” in Studies in
Subjective Probability, ed. Kyburg and Smokler, Krieger (1980) pp. 53-118 (trans-
lation by Kyburg, original French version, 1937).
8. Dov Gabbay, “Theoretical foundations for nonmonotonic reasoning in expert sys-
tems,” in Proceedings NATO Advanced Study Institute on Logics and Models of
Concurrent Systems, (ed.) K.R. Apt, (1985), 439-457.
9. B.V. Gnedenko, Theory of Probability, (translated from the Russian by B.D. Seck-
ler), Chelsea 1962.
10. James Hawthorne, “Nonmonotonic Conditionals that Behave Like Conditional
Probabilities Above a Threshold,” Journal of Applied Logic, May 2006.
11. Joseph Halpern, “Sleeping Beauty reconsidered,” Oxford Studies in Epistemology,
edited by Gendler and Hawthorne, (2005), pp. 111-142.
12. H. Jeﬀreys, Theory of Probability, New York, Oxford, 3rd edition, (1961).

456
R. Parikh
13. S. Kraus, D. Lehmann, and M. Magidor, “Nonmonotonic reasoning, preferential
models and cumulative logics,” Artiﬁcial Intelligence, 44 (1990), 167-207.
14. Isaac Levi, “On indetrminate probabilities,” Journal of Philosophy, 71 (1974),
391-418.
15. David Lewis, “Probabilities of conditionals and conditional probabilities,” Philo-
sophical Review, 85 (1976) 297-315.
16. R. Parikh, “Logical omniscience and common knowledge: WHAT do we know and
what do WE know?,” Proceedings of the Tenth Conference on Theoretical Aspects
of Rationality and Knowledge - 2005, ed. Ron Meyden, National U. Singapore
Press, pp. 62-78.
17. R. Parikh, review of [20], Essays in Philosophy, 7,1, (2006).
18. F. P. Ramsey, “Truth and probability,” (1926), reprinted in F.P. Ramsey, Philo-
sophical Papers, edited by D.H.Mellor, Cambridge University Press 1990.
19. C. Schwarz, “Cumulative probability for the standard normal distribution,”
http://www.stat.sfu.ca/∼cschwarz/Stat-301/Handouts/nod122.html
20. David Sanford, If P then Q, second edition, Routledge 2003.
21. Daniel Stroock, Probability Theory: An analytic view, Cambridge U. Press, 1993.
22. Paul Weirich, “The St. Petersburg Gamble and Risk,” Theory and Decision 17,
(1984) 193-202.

A Temporal Dynamic Logic for
Verifying Hybrid System Invariants⋆
Andr´e Platzer
University of Oldenburg, Department of Computing Science, Germany
Carnegie Mellon University, Computer Science Department, Pittsburgh, PA
platzer@informatik.uni-oldenburg.de
Abstract. We combine ﬁrst-order dynamic logic for reasoning about
possible behaviour of hybrid systems with temporal logic for reasoning
about the temporal behaviour during their operation. Our logic sup-
ports veriﬁcation of hybrid programs with ﬁrst-order deﬁnable ﬂows and
provides a uniform treatment of discrete and continuous evolution. For
our combined logic, we generalise the semantics of dynamic modalities
to refer to hybrid traces instead of ﬁnal states. Further, we prove that
this gives a conservative extension of dynamic logic. On this basis, we
provide a modular veriﬁcation calculus that reduces correctness of tem-
poral behaviour of hybrid systems to non-temporal reasoning. Using this
calculus, we analyse safety invariants in a train control system and sym-
bolically synthesise parametric safety constraints.
Keywords: dynamic logic, temporal logic, sequent calculus, logic for
hybrid systems, deductive veriﬁcation of embedded systems.
1
Introduction
Correctness of real-time and hybrid systems depends on a safe operation through-
out all states of all possible trajectories, and the behaviour at intermediate states
is highly relevant [1,7,9,12,14,23].
Temporal logics (TL) use temporal operators to talk about intermediate
states [1, 10, 11, 24]. They have been used successfully in model checking [1, 6,
14,15,18] of ﬁnite-state system abstractions. Continuous state spaces of hybrid
systems, however, often do not admit equivalent ﬁnite-state abstractions [14,18].
Instead of model checking, TL can also be used deductively to prove validity of
formulas in calculi [9,8]. Valid TL formulas, however, only express very generic
facts that are true for all systems, regardless of their actual behaviour. Hence,
the behaviour of a speciﬁc system ﬁrst needs to be axiomatised declaratively
to obtain meaningful results. Then, however, the correspondence between actual
system operations and a declarative temporal representation may be questioned.
⋆This research was supported by a fellowship of the German Academic Exchange
Service (DAAD). It was also sponsored by the German Research Council (DFG)
as part of the Transregional Collaborative Research Center “Automatic Veriﬁcation
and Analysis of Complex Systems” (SFB/TR 14 AVACS, see www.avacs.org).
S. Artemov and A. Nerode (Eds.): LFCS 2007, LNCS 4514, pp. 457–471, 2007.
c
⃝Springer-Verlag Berlin Heidelberg 2007

458
A. Platzer
Dynamic logic (DL) [13] is a successful approach for deductively verifying
(inﬁnite-state) systems [2, 3, 13, 16]. Like model checking, DL can analyse the
behaviour of actual system models, which are speciﬁed operationally. Yet, op-
erational models are internalised within DL-formulas, and DL is closed under
logical operators. Thus, DL can refer to multiple systems and analyse their rela-
tionship. This can be important for verifying larger systems compositionally or
for investigating reﬁnement relations, see [22]. Further, Davoren and Nerode [9]
argue that, unlike model checking, deductive methods support formulas with free
parameters. However, DL only considers the behaviour at ﬁnal states, which is
insuﬃcient for verifying safety invariants that have to hold all the time.
We close this gap of expressivity by combining ﬁrst-order dynamic logic [13]
with temporal logic [10,11,24]. Moreover, we generalise both operational system
models and semantics to hybrid systems [14]. In this paper, we introduce a
temporal dynamic logic dTL, which provides modalities for quantifying over
traces of hybrid systems. We equip it with temporal operators to state what is
true all along a trace or at some point during a trace. As in our non-temporal
dynamic logic dL [19, 20, 22], we use hybrid programs as an operational model
for hybrid systems. They admit a uniform treatment of interacting discrete and
continuous evolution in logic.
As a semantical foundation for combined temporal dynamic formulas, we in-
troduce a hybrid trace semantics for dTL. We prove that dTL is a conservative
extension of dL: for non-temporal speciﬁcations, trace semantics is equivalent to
the non-temporal ﬁnal state semantics of [19,22].
As a means for veriﬁcation, we introduce a sequent calculus for dTL that
successively reduces temporal statements about traces of hybrid programs to
non-temporal formulas. In this way, we make the intuition formally precise
that safety invariants can be checked by augmenting proofs with appropriate
assertions about intermediate states. Like in [22], our calculus supports com-
positional reasoning. It structurally decomposes correctness statements about
hybrid programs into corresponding statements about its parts by symbolic
transformation.
Our approach combines the advantages of DL in reasoning about the be-
haviour of (multiple and parametric) operational system models with those of
TL to verify temporal statements about traces. On the downside, we show that
our logic is incomplete. Yet, reachability in hybrid systems is already unde-
cidable [14]. We argue that, despite this theoretical obstacle, dTL can verify
practical systems and demonstrate this by studying safety invariants in train
control [7,12].
The ﬁrst contribution of this paper is the logic dTL, which provides a coherent
foundation for reasoning about the temporal behaviour of operational models of
hybrid systems with symbolic parameters. The main contribution is our calculus
for deductively verifying temporal statements about hybrid systems.
Hybrid Systems. The behaviour of safety-critical systems typically depends on
both the state of a discrete controller and continuous physical quantities. Hybrid
systems are mathematical models for dynamic systems with interacting discrete

A Temporal Dynamic Logic for Verifying Hybrid System Invariants
459
and continuous behaviour [9,14]. Their behaviour combines continuous evolution
(called ﬂow) characterised by diﬀerential equations and discrete jumps.
Dynamic Logic. The principle of dynamic logic is to combine system operations
and correctness statements about system states within a single speciﬁcation
language (see [13] for a general introduction in the discrete case). By permitting
system operations α as actions of modalities, dynamic logic provides formulas
of the form [α]φ and ⟨α⟩φ, where [α]φ expresses that all terminating runs of
system α lead to ﬁnal states in which condition φ holds. Likewise, ⟨α⟩φ expresses
that it is possible for α to execute and result in a ﬁnal state satisfying φ. In
dTL, hybrid programs [19, 20, 22] play the role of α. In this paper, we modify
the semantics of [α] to refer to all traces of α rather than only all ﬁnal states
reachable with α (similarly for ⟨α⟩). For instance, the formula [α]□φ expresses
that φ is true at each state during all traces of the hybrid system α. With this,
dTL can also be used to verify temporal statements about the behaviour of α
at intermediate states during system runs.
Related Work. Based on [25], Beckert and Schlager [4] added separate trace
modalities to dynamic logic and presented a relatively complete calculus. Their
approach only handles discrete state spaces. In contrast, dTL works for hybrid
programs with continuous state spaces. There, a particular challenge is that
invariants may change their truth-value during a single continuous evolution.
Mysore et al. [18] analysed model checking of TCTL [1] properties for semi-
algebraic hybrid systems and proved undecidability. Our logic internalises oper-
ational models and supports multiple parametric systems.
Zhou et al. [26] presented a duration calculus extended by mathematical ex-
pressions with derivatives of state variables. Their calculus is unwieldy as it
uses a multitude of rules and requires external mathematical reasoning about
derivatives and continuity.
Davoren and Nerode [9] extended the propositional modal μ-calculus with a
semantics in hybrid systems and examine topological aspects. In [8], Davoren et
al. gave a semantics in general ﬂow systems for a generalisation of CTL∗[11].
In both cases, the authors of [9] and [8] provided Hilbert-style calculi to prove
formulas that are valid for all systems simultaneously using abstract actions.
The strength of our logic primarily is that it is a ﬁrst-order dynamic logic: it
handles actual hybrid programs like x := x + 1; ˙x = 2y rather than only abstract
actions of unknown eﬀect. Our calculus directly supports veriﬁcation of hybrid
programs with ﬁrst-order deﬁnable ﬂows; ﬁrst-order approximations of more
general ﬂows can be used according to [23]. First-order DL is more expressive
and calculi are deductively stronger than other approaches [4,17].
Structure of this Paper. After introducing syntax and semantics of the temporal
dynamic logic dTL in Sect. 2, we introduce a sequent calculus for verifying
temporal dTL speciﬁcations of hybrid systems in Sect. 4 and prove soundness. In
Sect. 5, we prove safety invariants of the train control system presented in Sect. 3.
Alternating path and trace quantiﬁers for liveness veriﬁcation are discussed in
Sect. 6. Finally, we draw conclusions and discuss future work in Sect. 7.

460
A. Platzer
2
Temporal Dynamic Logic for Hybrid Systems
2.1
Overview: The Basic Concepts of dTL
The temporal dynamic logic dTL extends dynamic logic [13] with three concepts
for verifying temporal speciﬁcations of hybrid systems:
Hybrid Programs. The behaviour of hybrid systems can be described by hybrid
programs [19,20,22], which generalise real-time programs [15] to hybrid change.
The distinguishing feature of hybrid programs in this context is that they provide
uniform discrete jumps and continuous evolutions along diﬀerential equations.
While hybrid automata [14] can be embedded, program structures are more
amenable to compositional symbolic processing by calculus rules [19].
Modal Operators. Modalities of dynamic logic express statements about all pos-
sible behaviour ([α]π) of a system α, or about the existence of a trace (⟨α⟩π),
satisfying condition π. As in [19, 20, 22], the system α is described as a hybrid
program. Yet, unlike in standard dynamic logic [13], π is a trace formula in dTL,
and π is allowed to refer to all states that occur during a trace using temporal
operators.
Temporal Operators. For dTL, the temporal trace formula □φ expresses that
the formula φ holds all along a trace selected by [α] or ⟨α⟩. For instance, the
state formula ⟨α⟩□φ says that the state formula φ holds at every state along at
least one trace of α. Dually, the trace formula ♦φ expresses that φ holds at some
point during such a trace. It can occur in a state formula ⟨α⟩♦φ to express that
there is such a state in some trace of α, or as [α]♦φ to say that, along each trace,
there is a state satisfying φ. In this paper, the primary focus of attention is on
homogeneous combinations of path and trace quantiﬁers like [α]□φ or ⟨α⟩♦φ.
2.2
Syntax of dTL
State and Trace Formulas. The formulas of dTL are built over a non-empty
set V of real-valued variables and a ﬁxed signature Σ of function and predicate
symbols. For simplicity, Σ is assumed to contain exclusively the usual function
and predicate symbols for real arithmetic, such as 0, 1, +, ·, =, ≤, <, ≥, >.
The set Trm(V ) of terms is deﬁned as in classical ﬁrst-order logic. The for-
mulas of dTL are deﬁned similar to ﬁrst-order dynamic logic [13]. However, the
modalities [α] and ⟨α⟩accept trace formulas that refer to the temporal behaviour
of all states along a trace. Inspired by CTL and CTL∗[10, 11], we distinguish
between state formulas, that are true or false in states, and trace formulas, that
are true or false for system traces. The sets Fml(V ) of state formulas, FmlT (V )
of trace formulas, and HP(V ) of hybrid programs with variables in V are simul-
taneously inductively deﬁned in Deﬁnition 1 and 2, respectively.

A Temporal Dynamic Logic for Verifying Hybrid System Invariants
461
Deﬁnition 1 (Formulas). The set Fml(V ) of (state) formulas is simultane-
ously inductively deﬁned as the smallest set such that:
1. If p ∈Σ is a predicate, θ1, . . . , θn ∈Trm(V ), then p(θ1, . . . , θn) ∈Fml(V ).
2. If φ, ψ ∈Fml(V ), then ¬φ, (φ ∧ψ), (φ ∨ψ), (φ →ψ) ∈Fml(V ).
3. If φ ∈Fml(V ) and x ∈V , then ∀x φ, ∃x φ ∈Fml(V ).
4. If π ∈FmlT (V ) and α ∈HP(V ), then [α]π, ⟨α⟩π ∈Fml(V ).
The set FmlT (V ) of trace formulas is the smallest set with:
1. If φ ∈Fml(V ), then φ ∈FmlT (V ).
2. If φ ∈Fml(V ), then □φ, ♦φ ∈FmlT (V ).
Formulas without □and ♦, i.e., without case 2 of the trace formulas, are called
non-temporal dL formulas [19,22]. Unlike in CTL, state formulas are true on a
trace (case 1) if they hold for the last state of a trace, not for the ﬁrst. Thus, [α]φ
expresses that φ is true at the end of each trace of α. In contrast, [α]□φ expresses
that φ is true all along all states of every trace of α. This combination gives a
smooth embedding of non-temporal dL into dTL and makes it possible to deﬁne
a compositional calculus. Like CTL, dTL allows nesting with a branching time
semantics [10], e.g., [α]□(x ≥2 →⟨γ⟩♦x ≤0).
Hybrid Programs. The hybrid programs [19, 20, 22] occurring in dynamic
modalities of dTL are built from elementary discrete jumps and continuous evo-
lutions using a regular control structure [13].
Deﬁnition 2 (Hybrid programs). The set HP(V ) of hybrid programs is
inductively deﬁned as the smallest set such that:
1. If x ∈V and θ ∈Trm(V ), then (x := θ) ∈HP(V ).
2. If x ∈V and θ ∈Trm(V ), then ( ˙x = θ) ∈HP(V ).
3. If χ ∈Fml(V ) is quantiﬁer-free and ﬁrst-order, then (?χ) ∈HP(V ).
4. If α, γ ∈HP(V ) then (α ∪γ) ∈HP(V ).
5. If α, γ ∈HP(V ) then (α; γ) ∈HP(V ).
6. If α ∈HP(V ) then (α∗) ∈HP(V ).
The eﬀect of x := θ is an instantaneous discrete jump in state space or a mode
switch. That of ˙x = θ is an ongoing continuous evolution regulated by the
diﬀerential equation with time-derivative ˙x of x and term θ (accordingly for
systems of diﬀerential equations).
Test actions ?χ are used to deﬁne conditions. Their semantics is that of
a no-op if χ is true in the current state, and that of a dead end operator
aborting any further evolution, otherwise. The sequential composition α; γ, non-
deterministic choice α ∪γ, and non-deterministic repetition α∗of system ac-
tions are as usual [13]. They can be combined with ?χ to form other control
structures [13].
In dTL, there is no need to distinguish between discrete and continuous vari-
ables or between system parameters and state variables, as they share the same
uniform semantics. For pragmatic reasons, an informal distinction can neverthe-
less improve readability. For instance, ∃x [ ˙x = −x]x ≤5 expresses that there is a
choice of the initial value for x (which could be a parameter) such that after all
evolutions along ˙x = −x, the outcome of the state variable x will be at most 5.

462
A. Platzer
2.3
Trace Semantics of dTL
In standard dynamic logic [13] and dL [22,19], modalities only refer to the ﬁnal
states of system runs and the semantics is a reachability relation on states:
State ω is reachable from state ν using α if there is a run of α which terminates
in ω when started in ν. For dTL, however, formulas can refer to intermediate
states of runs as well. Thus, the semantics of a hybrid system α is the set of its
possible traces, i.e., successions of states that occur during the evolution of α.
States contain values of system variables during a hybrid evolution. A state
is a map ν : V →R; the set of all states is denoted by Sta(V ). In addition, we
distinguish a state Λ to denote the failure of a system run when it is aborted due
to a test ?χ that yields false. In particular, Λ can only occur at the end of an
aborted system run and marks that there is no further extension.
Hybrid systems evolve along piecewise continuous traces in multi-dimensional
space as time passes. Continuous phases are governed by diﬀerential equations,
whereas discontinuities are caused by discrete jumps in state space. Unlike in
discrete cases [4,25], traces are not just sequences of states, since hybrid systems
pass through uncountably many states even in bounded time. Beyond that, con-
tinuous changes are more involved than in pure real-time [1, 15], because all
variables can evolve along diﬀerent diﬀerential equations. Generalising the real-
time traces of [15], the following deﬁnition captures hybrid behaviour by splitting
the uncountable succession of states into periods σi that are regulated by the
same control law. For discrete jumps, some periods are point ﬂows of duration 0.
Deﬁnition 3 (Hybrid Trace). A trace is a (non-empty) ﬁnite or inﬁnite se-
quence σ = (σ0, σ1, σ2, . . . ) of functions σi : [0, ri] →Sta(V ) with respective du-
rations ri ∈R (for i ∈N). A position of σ is a pair (i, ζ) with i ∈N and ζ in
the interval [0, ri]; the state of σ at (i, ζ) is σi(ζ). Positions of σ are ordered
lexicographically by (i, ζ) ≺(j, ξ) iﬀeither i < j, or i = j and ζ < ξ. Further,
for a state ν ∈Sta(V ), ˆν : 0 →ν is the point ﬂow at ν with duration 0. A trace
terminates if it is a ﬁnite sequence (σ0, σ1, . . . , σn) and σn(rn) ̸= Λ. In that case,
the last state last σ is denoted as σn(rn). The ﬁrst state ﬁrst σ is σ0(0).
Unlike in [1,15], the deﬁnition of traces also admits ﬁnite traces of bounded du-
ration, which is necessary for compositionality of traces in α; γ. The semantics
of hybrid programs α as the set τ(α) of its possible traces depends on valua-
tions val(ν, ·) of formulas and terms at intermediate states ν. The valuation of
terms [13], and interpretations of function and predicate symbols are as usual
for real arithmetic. The valuation of formulas will be deﬁned in Deﬁnition 5. We
use ν[x →d] to denote the modiﬁcation that agrees with state ν on all variables
except for the symbol x, which is changed to d ∈R.
Deﬁnition 4 (Trace semantics of hybrid programs). The trace semantics,
τ(α), of a hybrid program α, is the set of all its possible hybrid traces and is
deﬁned as follows:
1. τ(x := θ) = {(ˆν, ˆω) : ω = ν[x →val(ν, θ)] for ν ∈Sta(V )}
2. τ( ˙x = θ) = {(f) : 0 ≤r ∈R and f : [0, r] →Sta(V ) is such that the func-
tion val(f(ζ), x) is continuous in ζ on [0, r] and has a derivative of value

A Temporal Dynamic Logic for Verifying Hybrid System Invariants
463
val(f(ζ), θ) at each ζ ∈(0, r). Variables without a diﬀerential equation do
not change}
3. τ(?χ) = {(ˆν) : val(ν, χ) = true} ∪{(ˆν, ˆΛ) : val(ν, χ) = false}
4. τ(α ∪γ) = τ(α) ∪τ(γ)
5. τ(α; γ) = {σ ◦ς : σ ∈τ(α) , ς ∈τ(γ) when σ ◦ς is deﬁned}; the composition
of σ = (σ0, σ1, σ2, . . . ) and ς = (ς0, ς1, ς2, . . . ) is
σ ◦ς =
⎧
⎪
⎨
⎪
⎩
(σ0, . . . , σn, ς0, ς1, . . . )
if σ terminates at σn and last σ = ﬁrst ς
σ
if σ does not terminate
not deﬁned
otherwise
6. τ(α∗) = 
n∈N τ(αn), where αn+1 = (αn; α) for n ≥1, and α0 = (?true).
Time passes diﬀerently during discrete and continuous change. During contin-
uous evolution, the discrete step index i of positions (i, ζ) remains constant,
whereas the continuous duration ζ remains 0 during discrete point ﬂows. This
permits multiple discrete state changes to happen at the same (super-dense)
continuous time, unlike in [1].
Deﬁnition 5 (Valuation of formulas). The valuation of state and trace for-
mulas is deﬁned respectively. For state formulas, the valuation val(ν, ·) with
respect to state ν is deﬁned as follows:
1. val(ν, p(θ1, . . . , θn)) = pℓ
val(ν, θ1), . . . , val(ν, θn)

, where pℓis the relation
associated to p.
2. val(ν, φ ∧ψ) is deﬁned as usual, the same holds for ¬, ∨, →.
3. val(ν, ∀x φ) = true :⇐⇒val(ν[x →d], φ) = true for all d ∈R
4. val(ν, ∃x φ) = true :⇐⇒val(ν[x →d], φ) = true for some d ∈R
5. val(ν, [α]π) = true :⇐⇒for each trace σ ∈τ(α) that starts in ﬁrst σ = ν, if
val(σ, π) is deﬁned, then val(σ, π) = true.
6. val(ν, ⟨α⟩π) = true :⇐⇒there is a trace σ ∈τ(α) starting in ﬁrst σ = ν,
such that val(σ, π) = true.
For trace formulas, the valuation val(σ, ·) with respect to trace σ is:
1. If φ is a state formula, then val(σ, φ) = val(last σ, φ) if σ terminates,
whereas val(σ, φ) is not deﬁned if σ does not terminate.
2. val(σ, □φ) = true :⇐⇒val(σi(ζ), φ) = true for all positions (i, ζ) of σ
with σi(ζ) ̸= Λ.
3. val(σ, ♦φ) = true :⇐⇒val(σi(ζ), φ) = true for some position (i, ζ) of σ
with σi(ζ) ̸= Λ.
As usual, a (state) formula is valid if it is true in all states.
2.4
Conservative Temporal Extension
The following result shows that the extension of dTL by temporal operators does
not change the meaning of non-temporal dL formulas. The trace semantics given
in Deﬁnition 5 is equivalent to the ﬁnal state reachability relation semantics [22,
19] for the sublogic dL of dTL. A proof for this can be found in [21].

464
A. Platzer
Proposition 1. The logic dTL is a conservative extension of non-temporal dL,
i.e., the set of valid dL-formulas is the same with respect to transition reach-
ability semantics of dL [22, 19] as with respect to the trace semantics of dTL
(Deﬁnition 5).
3
Safety Invariants in Train Control
In the European Train Control System (ETCS) [12], trains are coordinated by
decentralised Radio Block Centres (RBC), which grant or deny movement au-
thorities (MA) to the individual trains by wireless communication. In emergen-
cies, trains always have to stop within the MA issued by the RBC, see Fig. 1.
Following the reasoning pattern for traﬃc agents in [7], each train negotiates
with the RBC to extend its MA when approaching the end, say m, of its cur-
rent MA. Since wireless communication takes time, this negotiation is initiated
in due time before reaching m. During negotiation, trains are assumed to keep
their desired speed as in [7]. Before entering negotiation at some point ST, the
train still has suﬃcient distance to MA (it is in far mode) and can regulate its
speed freely within the track limits.
Depending on weather conditions, slope of track etc., the local train motion
control determines a safety envelope s around the train, within which it con-
siders driving safe, and adjusts its acceleration a in accordance with s (called
correction [7]). In particular, depending on the maximum RBC response time,
this determines the latest point, SB, on the track where a response from the
RBC must have arrived to guarantee safe driving.
RBC
MA
ST
SB
negot
corr
far
Fig. 1. ETCS train coordination by movement authorities
As a model for train movements, we use the ideal-world model adapted
from [7]. It does not model friction, slopes, or mass of train but is perfectly
suitable for analysing the cooperation level of train control [7]. The local safety
properties that where used when verifying the cooperation protocol can then be
shown for more detailed models of individual components.
For a safe operation of multiple traﬃc agents, it is crucial that the MA is
respected at every point in time during this protocol, not only at its end. Hence,
we need to consider temporal safety invariants. For instance, when the train has

A Temporal Dynamic Logic for Verifying Hybrid System Invariants
465
entered the negotiation phase at its current position z, dTL can analyse the
following safety invariant of a part of the train controller:
ψ →[negot; corr; ˙z = v, ˙v = a]□(ℓ≤L →z < m)
(1)
where negot ≡˙z = v, ˙ℓ= 1
corr ≡(?m −z < s; a := −b) ∪(?m −z ≥s; a := . . . ) .
It expresses that—under a sanity condition ψ for parameters—a train will always
remain within its MA m, as long as the accumulated RBC negotiation latency ℓ
is at most L. We refer to [12] for details on what contributes to ℓ. Like in [7], we
model the train to ﬁrst negotiate while keeping a constant speed ( ˙z = v) in negot.
Thereafter, in corr, the train corrects its acceleration or brakes with force b (as
a failsafe recovery manoeuvre) on the basis of the remaining distance (m −z).
Finally, the train continues moving according to the system ( ˙z = v, ˙v = a) or,
equivalently, ¨z = a. Instead of manually choosing speciﬁc values for the free
parameters of (1) as in [7,12], we will use the techniques developed in this paper
to automatically synthesise constraints on the relationship of parameters that
are required for a safe operation of cooperative train control.
4
A Veriﬁcation Calculus for Safety Invariants
In this section, we introduce a sequent calculus for verifying temporal speciﬁca-
tions of hybrid systems in dTL. With the basic idea being to perform a sym-
bolic decomposition, hybrid programs are successively transformed into simpler
logical formulas describing their eﬀects. There, statements about the temporal
behaviour of a hybrid program are successively reduced to corresponding non-
temporal statements about the intermediate states.
For propositional logic, standard rules P1–P9 are listed in Fig. 2. The rule P10
is a shortcut to handle quantiﬁers of ﬁrst-order real arithmetic, which is decid-
able. We use P10 as a modular interface to arithmetic and refer to [19] for a
goal-oriented integration of arithmetic, which combines with dTL. Rules D1–D8
work similar to those in [13,3]. For handling discrete change, D8 inductively uses
substitutions. D9–D10 handle continuous evolutions given a ﬁrst-order deﬁnable
ﬂow yx. In particular, in conjunction with P10, they fully encapsulate handling
of diﬀerential equations within hybrid systems.
Rules T1–T10 successively transform temporal speciﬁcations of hybrid pro-
grams into non-temporal dL formulas. The idea underlying this transformation
is to decompose hybrid programs and recursively augment intermediate state
transitions with appropriate speciﬁcations. D1–D2 are identical for dTL and dL
speciﬁcations, hence they apply for all trace formulas π and not just for state
formulas. Rules for handling [α]♦φ and ⟨α⟩□φ are discussed in Sect. 6.
4.1
Rules of the Calculus
A sequent is of the form Γ ⊢Δ, where Γ and Δ are ﬁnite sets of formulas. Its
semantics is that of the formula 	
φ∈Γ φ →
ψ∈Δ ψ and will be treated as an

466
A. Platzer
(P1)
⊢φ
¬φ ⊢
(P2) φ ⊢
⊢¬φ
(P3)
φ ⊢ψ
⊢φ →ψ
(P4) φ, ψ ⊢
φ ∧ψ ⊢
(P5) ⊢φ
⊢ψ
⊢φ ∧ψ
(P6) ⊢φ
ψ ⊢
φ →ψ ⊢
(P7) φ ⊢
ψ ⊢
φ ∨ψ ⊢
(P8)
⊢φ, ψ
⊢φ ∨ψ
(P9) φ ⊢φ
(P10) F0 ⊢G0
F ⊢G
(D1) ⟨α⟩π ∨⟨γ⟩π
⟨α ∪γ⟩π
(D2) [α]π ∧[γ]π
[α ∪γ]π
(D3) ⟨[α]⟩⟨[γ]⟩φ
⟨[α; γ]⟩φ
(D4) χ ∧φ
⟨?χ⟩φ
(D5) χ →φ
[?χ]φ
(D6) φ ∨⟨α; α∗⟩φ
⟨α∗⟩φ
(D7) φ ∧[α; α∗]φ
[α∗]φ
(D8)
F θ
x
⟨[x := θ]⟩F
(D9) ∃t≥0 ⟨x := yx(t)⟩φ
⟨˙x = θ⟩φ
(D10) ∀t≥0 [x := yx(t)]φ
[ ˙x = θ]φ
(T1) [α]□φ ∧[α][γ]□φ
[α; γ]□φ
(T2)
φ
[?χ]□φ
(T3) φ ∧[x := θ]φ
[x := θ]□φ
(T4)
[ ˙x = θ]φ
[ ˙x = θ]□φ
(T5) [α; α∗]□φ
[α∗]□φ
(T6) ⟨α⟩♦φ ∨⟨α⟩⟨γ⟩♦φ
⟨α; γ⟩♦φ
(T7)
φ
⟨?χ⟩♦φ
(T8) φ ∨⟨x := θ⟩φ
⟨x := θ⟩♦φ
(T9)
⟨˙x = θ⟩φ
⟨˙x = θ⟩♦φ
(T10) ⟨α; α∗⟩♦φ
⟨α∗⟩♦φ
In these rules, φ and ψ are (state) formulas, whereas π is a trace formula. Unlike φ
and ψ, the trace formula π may thus begin with □or ♦. In D8, F is a ﬁrst-order
formula and the substitution of F θ
x , which replaces x by θ in F, does not introduce
new bindings. In D9–D10, t is a fresh variable and yv the solution of the initial value
problem ( ˙x = θ, x(0) = v). In P10, Cl∀(F0 →G0) →Cl∀(F →G) is an instance of a
ﬁrst-order tautology of real arithmetic and Cl∀the universal closure.
Fig. 2. Rule schemata of the temporal dynamic dTL veriﬁcation calculus
abbreviation. In the following, an update U is a list of discrete assignments of
the form x := θ (see [3] for advanced update techniques, which can be combined
with our calculus).

A Temporal Dynamic Logic for Verifying Hybrid System Invariants
467
Deﬁnition 6 (Provability, derivability). A formula ψ is provable from a
set Φ of formulas, denoted by Φ ⊢dTL ψ iﬀthere is a ﬁnite set Φ0 ⊆Φ for which
the sequent Φ0 ⊢ψ is derivable. In turn, a sequent of the form Γ, ⟨U⟩Φ ⊢⟨U⟩Ψ, Δ
(for some update U, including the empty update, and ﬁnite sets Γ, Δ of context
formulas) is derivable iﬀthere is an instance
Φ1 ⊢Ψ1
. . .
Φn ⊢Ψn
Φ ⊢Ψ
of a rule schema of the dTL calculus in Fig. 2 such that
Γ, ⟨U⟩Φi ⊢⟨U⟩Ψi, Δ
is derivable for each 1 ≤i ≤n. Moreover, the symmetric schemata Di and T i
can be applied on either side of the sequent (in context Γ, Δ and update ⟨U⟩).
The schematic modality ⟨[·]⟩can be instantiated with both [·] and ⟨·⟩in all rule
schemata. The same modality instance has to be chosen within a single schema
instantiation, though.
As usual in sequent calculus—although the direction of entailment is from pre-
misses (above rule bar) to conclusion (below)—the order of reasoning is goal-
directed: Rules are applied starting from the desired conclusion at the bottom
(goal) to the premisses (sub-goals).
Rule T1 decomposes invariants of α; γ into an invariant of α and an invariant
of γ that holds when γ is started in any ﬁnal state of α. T3 expresses that invari-
ants of assignments need to hold before and after the discrete change (similarly
for T2, except that tests do not lead to a state change). T4 can directly reduce
invariants of continuous evolutions to non-temporal formulas as restrictions of
solutions of diﬀerential equations are themselves solutions of diﬀerent duration.
T5 relies on T1 and is simpler than D7, because the other rules will inductively
produce a premiss that φ holds in the current state. The dual rules T6–T10
work similarly. The usual induction schemes [13, 17] can be added to the dTL
calculus. Inductive invariant properties can be handled by augmenting induction
rules with an additional branch that takes care of the temporal properties.
4.2
Soundness and Incompleteness
The following result shows that veriﬁcation with the dTL calculus always produces
correct results about safety of hybrid systems, i.e., the dTL calculus is sound.
Theorem 1 (Soundness). The dTL calculus is sound, i.e., derivable (state)
formulas are valid. (See [21] for a proof.)
Theorem 2 (Incompleteness). Fragments of dTL are inherently incomplete,
i.e. cannot have a complete calculus. (See [21] for a proof.)
5
Veriﬁcation of Train Control Safety Invariants
Continuing the ETCS study from Sect. 3, we consider a slightly simpliﬁed version
of equation (1) that gives a more concise proof. By a safe abstraction (provable

468
A. Platzer
in dTL), we simplify corr to permit braking even when m −z ≥s, since braking
remains safe with respect to z < m. We use the following abbreviations in
addition to (1):
ψ ≡z < m ∧v > 0 ∧ℓ= 0 ∧L ≥0
φ ≡ℓ≤L →z < m
corr ≡a := −b ∪(?m −z ≥s; a := . . . ) .
Within the following proof, ⟨[]⟩brackets are used instead of modalities to visually
identify the update preﬁx (Deﬁnition 6). To give shorter formulas, we generalise
update application D8 to work within quantiﬁers according to [3]. The dTL proof
of the safety invariant in (1) splits into two cases as follows:
. . .
ψ ⊢[negot]□φ
. . .
ψ ⊢[negot][corr; ˙z = v, ˙v = a]□φ
T1
ψ ⊢[negot; corr; ˙z = v, ˙v = a]□φ
P3
⊢ψ →[negot; corr; ˙z = v, ˙v = a]□φ
There, the left branch proves that φ holds while negotiating and is as follows:
ψ ⊢Lv + z < m
P10ψ ⊢∀l≥0 (l ≤L →lv + z < m)
D8 ψ ⊢∀l≥0 ⟨[z := lv + z, ℓ:= l]⟩φ
D10ψ ⊢[negot]φ
T4 ψ ⊢[negot]□φ
The right branch shows that φ continues to hold after negotiation has completed
when continuing with an adjusted acceleration a:
ψ, ℓ≥0 ⊢v2 < 2b(m −Lv −z) ∧Lv + z < m
P10 ψ, ℓ≥0 ⊢⟨[z := ℓv+z, a := -b]⟩∀t≥0 (ℓ≤L →a
2t2+vt+z<m)
D8
ψ, ℓ≥0 ⊢⟨[z := ℓv+z, a := -b]⟩∀t≥0 ⟨[z := a
2t2+vt+z]⟩φ)
T4,D10ψ, ℓ≥0 ⊢⟨[z := ℓv+z, a := -b]⟩[ ˙z = v, ˙v = a]□φ
▷
D2
ψ, ℓ≥0 ⊢⟨[z := ℓv+z]⟩[corr][ ˙z = v, ˙v = a]□φ
▷
T1
ψ, ℓ≥0 ⊢⟨[z := ℓv+z]⟩[corr; ˙z = v, ˙v = a]□φ
P3
ψ ⊢ℓ≥0 →⟨[z := ℓv+z]⟩[corr; ˙z = v, ˙v = a]□φ
P10
ψ ⊢∀ℓ≥0 ⟨[z := ℓv+z]⟩[corr; ˙z = v, ˙v = a]□φ
D10
ψ ⊢[negot][corr; ˙z = v, ˙v = a]□φ
The application of T1 in this latter case spawns a third case (marked with ▷)
to show that φ holds during corr. However, the reasoning in this third case is
subsumed by the cases above, since the changes on a in corr do not interfere
with condition φ. Generally, this optimisation of T1 is applicable whenever the
modiﬁed vocabulary is disjoint from φ. Here, D10 and P10 are implemented in
Mathematica to handle evolutions [19].
The leaves of the proof branches above can even be used to automatically
synthesise parameter constraints that are necessary to avoid MA violation. The

A Temporal Dynamic Logic for Verifying Hybrid System Invariants
469
parametric safety constraint obtained by combining the open conditions conjunc-
tively is Lv + z < m ∧v2 < 2b(m −Lv −z). It simpliﬁes to v2 < 2b(m −Lv −z)
as b > 0. This yields bounds for the speed limit and negotiation latency in or-
der to guarantee safe driving and closing of the proof. Similarly, D2 leads to a
branch for the case [?m −z ≥s; a := . . .], from which corresponding conditions
about the safety envelope s can be derived depending on the particular speed
controller. Yet, this is beyond the scope of this paper.
6
Liveness by Quantiﬁer Alternation
Liveness speciﬁcations of the form [α]♦φ or ⟨α⟩□φ are sophisticated (Σ1
1-hard
because they can express inﬁnite occurrence in Turing machines). Beckert and
Schlager [4] say they failed to ﬁnd sound rules for a discrete case that corresponds
to [α; γ]♦φ.
For ﬁnitary liveness semantics, we accomplish this as follows. In this section,
we modify the meaning of [α]♦φ to refer to all terminating traces of α. Then,
the straightforward generalisation T11 in Fig. 3 is sound, even in the hybrid
case(see [21] for proofs). But T11 still leads to an incomplete axiomatisation
as it does not cover the case where, in some traces, φ becomes true at some
point during α, and in other traces, φ only becomes true during γ. To overcome
this limitation, we use a program transformation approach. We instrument the
hybrid program to monitor the occurrence of φ during all changes: In T12, ˇα
results from replacing all occurrences of x := θ by x := θ; ?φ →t = 1 and ˙x = θ
by ˙x = θ & (φ →t = 1). The latter denotes continuous evolution restricted to the
region of the state space that satisﬁes φ →t = 1 (see [19] for details). The eﬀect
is that t detects whether φ has occurred during any change in α. In particular, t
is guaranteed to be 1 after all runs, if φ occurs at least once along all traces of α.
This trick directly works for quantiﬁer-free ﬁrst-order conditions φ. Using the
combination presented in [22], nominals can be used as state labels to address
the same issue for general φ.
(T11) ⊢[α]♦φ, [α][γ]♦φ
⊢[α; γ]♦φ
(T12) φ ∨∀t [ˇα]t = 1
[α]♦φ
Fig. 3. Transformation rules for alternating temporal path and trace quantiﬁers
7
Conclusions and Future Work
For reasoning about hybrid systems, we have introduced a temporal dynamic
logic, dTL, with modal path quantiﬁers over traces and temporal quantiﬁers
along the traces. It combines the capabilities of dynamic logic [13] to reason
about possible system behaviour with the power of temporal logic [24,10,11] in
reasoning about the behaviour along traces. Furthermore, we have presented a
calculus for verifying temporal safety speciﬁcations of hybrid programs in dTL.

470
A. Platzer
Our sequent calculus for dTL is a modular combination of temporal and non-
temporal reasoning. Temporal formulas are handled using rules that augment
intermediate state transitions with corresponding sub-speciﬁcations. Purely non-
temporal rules handle the eﬀects of discrete and continuous evolution.
As an example, we demonstrate that our logic is suitable for reasoning about
safety invariants in the European Train Control System [12]. Further, we have
successfully applied our calculus to automatically synthesise (non-linear) para-
metric safety constraints for this system.
We are currently extending our preliminary veriﬁcation tool for parametric
hybrid systems to cover the full dTL calculus. Future work includes extending
dTL with CTL∗-like [11] formulas of the form [α](ψ ∧□φ) to avoid splitting of
the proof into two very similar sub-proofs for temporal parts [α]□φ and non-
temporal parts [α]ψ arising in T1. Our combination of temporal logic with dy-
namic logic is more suitable for this purpose than the approach in [4], since dTL
has uniform modalities and uniform semantics for temporal and non-temporal
speciﬁcations. This extension will also simplify the treatment of alternating live-
ness quantiﬁers conceptually.
References
1. R. Alur, C. Courcoubetis, and D. L. Dill. Model-checking for real-time systems.
In LICS, pages 414–425. IEEE Computer Society, 1990.
2. B. Beckert, R. H¨ahnle, and P. H. Schmitt, editors. Veriﬁcation of Object-Oriented
Software: The KeY Approach, volume 4334 of LNCS. Springer-Verlag, 2007.
3. B. Beckert and A. Platzer. Dynamic logic with non-rigid functions: A basis for
object-oriented program veriﬁcation. In U. Furbach and N. Shankar, editors, IJ-
CAR, volume 4130 of LNCS, pages 266–280. Springer, 2006.
4. B. Beckert and S. Schlager. A sequent calculus for ﬁrst-order dynamic logic with
trace modalities. In R. Gor´e, A. Leitsch, and T. Nipkow, editors, IJCAR, volume
2083 of LNCS, pages 626–641. Springer, 2001.
5. A. Bemporad, A. Bicchi, and G. Buttazzo, editors. Hybrid Systems: Computation
and Control, 10th International Conference, HSCC 2007, Pisa, Italy, Proceedings,
volume 4416 of LNCS. Springer, 2007.
6. E. M. Clarke, O. Grumberg, and D. A. Peled. Model Checking. MIT Press, Cam-
bridge, MA, USA, 1999.
7. W. Damm, H. Hungar, and E.-R. Olderog. On the veriﬁcation of cooperating traﬃc
agents. In F. S. de Boer, M. M. Bonsangue, S. Graf, and W. P. de Roever, editors,
FMCO, volume 3188 of LNCS, pages 77–110. Springer, 2003.
8. J. M. Davoren, V. Coulthard, N. Markey, and T. Moor. Non-deterministic temporal
logics for general ﬂow systems. In R. Alur and G. J. Pappas, editors, HSCC, volume
2993 of LNCS, pages 280–295. Springer, 2004.
9. J. M. Davoren and A. Nerode. Logics for hybrid systems. Proceedings of the IEEE,
88(7):985–1010, July 2000.
10. E. A. Emerson and E. M. Clarke. Using branching time temporal logic to synthesize
synchronization skeletons. Sci. Comput. Program., 2(3):241–266, 1982.
11. E. A. Emerson and J. Y. Halpern. “Sometimes” and “Not Never” revisited: on
branching versus linear time temporal logic. J. ACM, 33(1):151–178, 1986.

A Temporal Dynamic Logic for Verifying Hybrid System Invariants
471
12. J. Faber and R. Meyer. Model checking data-dependent real-time properties of
the European Train Control System. In FMCAD, pages 76–77. IEEE Computer
Society Press, Nov 2006.
13. D. Harel, D. Kozen, and J. Tiuryn. Dynamic logic. MIT Press, 2000.
14. T. A. Henzinger. The theory of hybrid automata. In LICS, pages 278–292, 1996.
15. T. A. Henzinger, X. Nicollin, J. Sifakis, and S. Yovine. Symbolic model checking
for real-time systems. In LICS, pages 394–406. IEEE Computer Society, 1992.
16. D. Hutter, B. Langenstein, C. Sengler, J. H. Siekmann, W. Stephan, and
A. Wolpers. Deduction in the veriﬁcation support environment (VSE). In M.-
C. Gaudel and J. Woodcock, editors, FME, volume 1051 of LNCS, pages 268–286.
Springer, 1996.
17. D. Leivant.
Partial correctness assertions provable in dynamic logics.
In
I. Walukiewicz, editor, FoSSaCS, volume 2987 of LNCS, pages 304–317. Springer,
2004.
18. V. Mysore, C. Piazza, and B. Mishra. Algorithmic algebraic model checking II:
Decidability of semi-algebraic model checking and its applications to systems bi-
ology. In D. Peled and Y.-K. Tsay, editors, ATVA, volume 3707 of LNCS, pages
217–233. Springer, 2005.
19. A. Platzer.
Diﬀerential dynamic logic for verifying parametric hybrid systems.
2007.
20. A. Platzer. Diﬀerential logic for reasoning about hybrid systems. In Bemporad
et al. [5], pages 746–749.
21. A. Platzer. A temporal dynamic logic for verifying hybrid system invariants. Re-
ports of SFB/TR 14 AVACS 12, February 2007.
ISSN: 1860-9821, available at
http://www.avacs.org.
22. A. Platzer.
Towards a hybrid dynamic logic for hybrid dynamic systems.
In
P. Blackburn, T. Bolander, T. Bra¨uner, V. de Paiva, and J. Villadsen, editors,
Proc., LICS International Workshop on Hybrid Logic, 2006, Seattle, USA, ENTCS,
2007.
23. A. Platzer and E. M. Clarke. The image computation problem in hybrid systems
model checking. In Bemporad et al. [5], pages 473–486.
24. A. Pnueli. The temporal logic of programs. In FOCS, pages 46–57. IEEE, 1977.
25. V. R. Pratt. Process logic. In POPL, pages 93–100, 1979.
26. C. Zhou, A. P. Ravn, and M. R. Hansen. An extended duration calculus for hybrid
real-time systems. In R. L. Grossman, A. Nerode, A. P. Ravn, and H. Rischel,
editors, Hybrid Systems, volume 736 of LNCS, pages 36–59. Springer, 1992.

Multiplexor Categories and Models of
Soft Linear Logic
Brian F. Redmond
Department of Mathematics & Statistics, University of Ottawa,
585 King Edward Avenue, Ottawa ON K1N 6N5, Canada
bredm066@uottawa.ca
Abstract. We give a categorical interpretation of Lafont’s Soft Linear
Logic, a logical system complete for polynomial time computation, in
terms of multiplexor categories. We present two main classes of mod-
els and methods for constructing examples in each case. As a concrete
example of the ﬁrst type, we introduce a simple game semantics for Mul-
tiplicative Soft Linear Logic. To illustrate the second type, we give a
realizability model and a new proof of the polytime soundness of Soft
Linear Logic. These results further our semantic understanding of Soft
Linear Logic and polynomial time.
Keywords: Categorical semantics, Soft Linear Logic, Polynomial time,
Game semantics.
1
Introduction
Linear Logic was introduced by J.-Y. Girard in 1987 [6] as a logical system
for managing resources and it has attracted considerable attention from logi-
cians and computer scientists. Its novel handling of inﬁnite resources makes
Linear Logic ideal for studying aspects of time bounded computation directly
within a logical system. By a careful consideration of the exponential frag-
ment, researchers have be able to isolate subsystems complete for polynomial
and elementary time computation. The ﬁrst such system, Bounded Linear Logic
(BLL), introduced by Girard, Scedrov and Scott, is complete for polynomial
time computation [8]. Other systems include Girard’s Light Linear Logic (LLL)
and Elementary Linear Logic (ELL), complete for polynomial (resp. elementary)
time computation [7]. Lafont’s Soft Linear Logic can be seen as a subsystem of
Bounded Linear Logic which is still powerful enough to encode polynomial time
computation [10].
A good semantics for such a logic would lead to a semantic characterization
of polynomial time computation [14]. One of the main points of this paper is to
show that Soft Linear Logic possesses a very natural semantics, and therefore it is
an ideal system for investigating the semantics of polynomial time computation.
We note that there has been previous work in the ﬁeld of categorical models
of various feasible fragments of Linear Logic. We note Baillot’s stratiﬁed co-
herence spaces [3], which provides an example of a categorical model of Light
S. Artemov and A. Nerode (Eds.): LFCS 2007, LNCS 4514, pp. 472–485, 2007.
c
⃝Springer-Verlag Berlin Heidelberg 2007

Multiplexor Categories and Models of Soft Linear Logic
473
Linear Logic, Murawski and Ong’s discreet games model of the intuitionistic
multiplicative fragment of Light Aﬃne Logic [14], Hofmann and Scott’s realiz-
ability models of BLL [9], and O. Laurent and L. Tortora de Falco’s obsessional
relational models of ELL/SLL [11]. Our work on game semantics has been par-
tially motivated by discussions with O. Laurent (private communication) who
had considered an AJM-style game semantics similar to the one presented here
for Soft Linear Logic.
But we should especially mention the unpublished work of Abramsky [2],
which we were unaware of in the ﬁrst draft of this paper. In his Cliﬀord lectures
at Tulane University, Abramsky gives several results which anticipate part of
this work. In particular, he proposes the formula for !A which we use in Sect.
4, and notes that such an exponential would not satisfy contraction. He also
observes that the standard game models have suﬃcient limits for this formula
to be applied.
In this paper, we shall always work in an intuitionistic setting even if it is not
explicitly stated. Thus, for example, we shall write MELL as short for Intuition-
istic Multiplicative Exponential Linear Logic.
2
Soft Linear Logic
In this section we review the theory of second-order Soft Linear Logic (SLL2).
Formulae are given by the following syntax:
A, B ::= α|1|A&B|A ⊗B|A ⊸B|∀α.A|!A
Sequents are given intuitionistically: they have the form Γ ⊢C, where Γ is a ﬁ-
nite (possibly empty) list of formulas. If Γ is the sequence of formulas C1, . . . , Cn,
then !Γ denotes the sequence !C1, . . . , !Cn. Also, if A is a formula and n ∈N,
we write An for the formula A ⊗· · · ⊗A (n times) and A(n) for the sequence
A, . . . , A (n times). Proofs are generated by a Gentzen style sequent calculus.
The rules are the following (as originally presented in [10]):
– structural rules: exchange, identity, and cut
Γ, A, B, Δ ⊢C
Γ, B, A, Δ ⊢C
A ⊢A
Γ ⊢A
Δ, A ⊢C
Γ, Δ ⊢C
– multiplicative logical rules:
Γ, A ⊢B
Γ ⊢A ⊸B
Γ ⊢A
Δ, B ⊢C
Γ, Δ, A ⊸B ⊢C
Γ ⊢A
Δ ⊢B
Γ, Δ ⊢A ⊗B
Γ, A, B ⊢C
Γ, A ⊗B ⊢C
⊢1
Γ ⊢C
Γ, 1 ⊢C
– additive logical rules:
Γ ⊢A
Γ ⊢B
Γ ⊢A&B
Γ, A ⊢C
Γ, A&B ⊢C
Γ, B ⊢C
Γ, A&B ⊢C

474
B.F. Redmond
– exponential logical rules: soft (generic) promotion and multiplexing
Γ ⊢A
!Γ ⊢!A
Γ, A(n) ⊢C
Γ, !A ⊢C
(n is any natural number)
– quantiﬁcation logical rules:
Γ ⊢A
Γ ⊢∀α.A
(α not free in Γ)
Γ, A[B/α] ⊢C
Γ, ∀α.A ⊢C
In multiplexing, the rank n can be any natural number. The notion of rank
extends to proofs: the rank of a proof u in SLL2 is the maximal rank of mul-
tiplexing in u. If all these ranks are the same, we say that u is homogeneous,
and if there is no multiplexing, we say that u is generic. In SLL2 programming,
programs are represented by generic proofs and data by homogeneous proofs.
Note that one can derive the usual Linear Logic exponentials by adding the
digging rule:
Γ, !!A ⊢C
Γ, !A ⊢C
to the soft exponential rules above. The following results are due to Lafont [10].
Theorem 1. SLL2 satisﬁes cut-elimination.
Theorem 2. SLL2 is complete for polynomial time computation. In other words,
any polynomial time algorithm is represented by a generic proof, and conversely, a
generic proof deﬁnes a polynomial time algorithm via cut-elimination.
Lafont conjectured in [10] that Multiplicative SLL2 is also complete for polyno-
mial time computation; this was later proved by Mairson and Terui in [13].
3
Multiplexor Categories
In this section we provide a categorical interpretation of the quantiﬁer-free Mul-
tiplicative fragment of Soft Linear Logic (MSLL) in terms of multiplexor cate-
gories. We will tacitly assume that an interpretation of the additive connective
can be obtained by assuming below that our categories have ﬁnite products.
Deﬁnition 1. A multiplexor category consists of a triple (C, !, {mn}n≥0), where
C = (C, ⊗, ⊸, 1) is an autonomous category (=symmetric monoidal closed cat-
egory) with structural maps α, λ, ρ and τ (twist), ! = (!, b2, b0) is a symmetric
monoidal endofunctor on C with C-maps b2 : !A⊗!B →!(A ⊗B) and b0 : 1 →!1,
and for each natural number n,
mn : !
·→(−)⊗n
is a monoidal natural transformation from ! to the n-fold tensor product functor,
called a multiplexor of rank n. Implicit here is the commutativity of a number
of diagrams. In particular, the deﬁnitions of monoidal functor and monoidal

Multiplexor Categories and Models of Soft Linear Logic
475
natural transformation can be found in [12]. E.g., for multiplexing, in addition
to naturality the following diagrams must commute:
!A⊗!B
b2

mn⊗mn

!(A ⊗B)
mn

1
b0
 !1
mn

A⊗n ⊗B⊗n
∼
 (A ⊗B)⊗n
1
∼ 1⊗n
Many examples of multiplexor categories satisfy an additional condition.
Symmetry Condition.
For each natural number n, the following diagram
commutes:
!A
mn 
mn








A⊗n
σ

A⊗n
for each permutation σ in Sn.
Deﬁnition 2. A symmetric multiplexor category is a multiplexor category which
satisﬁes the symmetry condition.
The proof of the following is routine, but for space considerations we refer the
reader to [15] for the details.
Theorem 3. A multiplexor category provides a denotational semantics for MSLL.
In other words, every proof in MSLL has an interpretation as an arrow in the cate-
gory, and moreover, the interpretation is preserved under the cut-elimination
procedure.
For example, the interpretation of the sequent !a ⊢an, where a is an atom, is
the morphism obtained by instantiating the natural transformation mn with the
interpretation of a.
4
Product Formulas
Our ﬁrst examples of multiplexor categories come from models of Linear Logic.
Multiplexing is a derived rule in the Multiplicative Exponential fragment of
Intuitionistic Linear Logic (MELL):
A(n) ⊢An
!A(n) ⊢An
!A ⊢An
where the ﬁrst double line represents dereliction rule(s) (n ≥1), and the sec-
ond double line represents either weakening (n = 0) or n −1 contraction rule(s).

476
B.F. Redmond
In a similar way, a Linear category [4] is an example of a symmetric multiplexor
category. The symmetry condition is given by the following diagram:
!A










(!A)⊗n
σ

 A⊗n
σ

(!A)⊗n
 A⊗n
The left triangle commutes by the commutative comonoid condition on !A in a
Linear category. The right square commutes by naturality of σ.
A good approximation to the soft exponential operator is provided by the
following two theorems. In general such an interpretation satisﬁes neither the
contraction rule nor the digging rule.
Theorem 4. Let C be an autonomous category with countable products. Deﬁne:
!A =

n
A⊗n = 1 × A × (A ⊗A) × (A ⊗A ⊗A) × · · · .
(1)
Then (C, !) is a multiplexor category.
Theorem 5. Let C be an autonomous category with countable products and
equalizers of permutations (see below). Deﬁne:
!A =

n
Sn(A) = 1 × A × (A ⊗s A) × (A ⊗s A ⊗s A) × · · · .
(2)
where A ⊗s A is the following equalizer:
A ⊗s A
e2
 A ⊗A
id

τ
 A ⊗A
where τ is the twist map. The n-th symmetric power is deﬁned analogously (as
the equalizer of the set of permutations of n elements). Then (C, !) is a symmetric
multiplexor category.
Proof. (Sketch) Given object A, multiplexing !A
mn
−→A⊗n is deﬁned as the
composite !A
pn
−→A⊗sn
en
−→A⊗n, which is natural in A. A crucial part of the
argument is in the construction of the map b2 :!A⊗!B →!(A ⊗B). The following
diagram shows how this is constructed (n is any natural number):
!A⊗!B
pn⊗pn
b2

A⊗sn ⊗B⊗sn

en⊗en A⊗n ⊗B⊗n
≀

id

σ⊗σ
...
 A⊗n ⊗B⊗n
≀

!(A ⊗B)
pn
 (A ⊗B)⊗sn
en
 (A ⊗B)⊗n
id

σ
...
 (A ⊗B)⊗n

Multiplexor Categories and Models of Soft Linear Logic
477
Note that this diagram also implies the ﬁrst of the two monoidality diagrams
for multiplexing (see Deﬁnition 1). Finally, the symmetry condition is justiﬁed
by the following diagram:
!A
pn

pn








A⊗sn
id

en
 A⊗n
σ

A⊗sn
en
 A⊗n
The proof of the general case (Theorem 4) is similar.
⊓⊔
Theorems 4 and 5 lead to a large class of models. Indeed, many interesting
models of MELL also possess a separate soft exponential operator. As a concrete
example, we outline a basic game semantics for Soft Linear Logic.
Game Semantics. The simple two-player (Player vs. Opponent) game seman-
tics described by Abramsky in [1] models the negative fragment of Intuitionistic
Linear Logic. Recall:
A game G is a triple (MG, λG, PG) where
– MG is the set of moves of the game;
– λG : MG →{P, O} is a labeling function designating each move as by Player
or Opponent;
– PG (the game tree) is a non-empty, preﬁx closed subset of M alt
G , the set of
ﬁnite alternating sequences of moves in MG, each beginning with an O-move.
Games are the objects of an autonomous category G with products, with mor-
phisms given by strategies on games, as usual.
Given A, the Linear Logic exponential in G is roughly the inﬁnite tensor
product A⊗ω and validates contraction. The Soft Linear Logic exponential !A is
deﬁned by (1), and can be described as follows:
M!A = {(i, j, a)|i, j ∈N∗, j ≤i, a ∈MA}
λ!A(i, j, a) = λA(a)
P!A =

i
{s ∈M alt
!A |∀j ∈{1, . . . , i}.s ↾(i, j) ∈PA ∧∀k ̸= i.s ↾(k, ) = ϵ}
where N∗= N\{0} and s ↾(i, j) stands for the projection of s on the (i, j)-th
copy of A. One can check directly that contraction no longer holds. One can
also deﬁne !A with (2), but the result is more complicated and strategies are no
longer history-free.
5
Finitary Soft Linear Logic
In Soft Linear Logic !A is not duplicable, but it is cashable on request (using
multiplexing) for any number of copies of datum A required. (In this way !A is

478
B.F. Redmond
analogous to a blank cheque, or a promissory note [2].) But from a computational
perspective it may be useful to limit in advance the number of copies of datum
A that may be paid.
To this end, we introduce a ﬁnitary version of Soft Linear Logic (SLLf) by
replacing the soft exponential operator ! with an N-indexed family of operators
!0, !1, !2, . . . , which are reminiscent of the bounded reuse operators !x of BLL [8],
but have a diﬀerent meaning. Intuitively, !nA is cashable for no more than n
copies of datum A. Hence in the ﬁnitary version, the exponential rules of Soft
Linear Logic are replaced by the following rules:
Γ ⊢A
!nΓ ⊢!nA
Γ, A(n) ⊢C
Γ, !n+wA ⊢C
where w, n range over natural numbers. Cut-elimination works in a similar way
to Soft Linear Logic, and there is an obvious translation into Soft Linear Logic
which simply forgets the indices of the exponentials. Just as Soft Linear Logic is a
subsystem of Linear Logic, ﬁnitary Soft Linear Logic can be seen as a subsystem
of Bounded Linear Logic. We note that the following formula is provable in BLL
but not in SLLf:
!m+nA ⊸!mA⊗!nA
(3)
The categorical semantics developed for Soft Linear Logic generalizes to the
ﬁnitary case as follows.
Deﬁnition 3. A ﬁnitary multiplexor category consists of a triple of the form
(C, {!t}t≥0, {mt,n}t≥n≥0), where C = (C, ⊗, ⊸, 1) is an autonomous category,
!t = (!t, b2,t, b0,t) is a symmetric monoidal endofunctor on C for each natural
number t, and for each pair of natural numbers t ≥n ≥0,
mt,n : !t
·→(−)⊗n
is a monoidal natural transformation from !t to the n-fold tensor product functor,
called a multiplexor of rank (t, n).
Again, many ﬁnitary multiplexor categories also satisfy a further property.
Symmetry Condition. For each pair of natural numbers t ≥n ≥0, the following
diagram commutes:
!tA
mt,n 
mt,n








A⊗n
σ

A⊗n
for each permutation σ in Sn.
Deﬁnition 4. A symmetric ﬁnitary multiplexor category is a ﬁnitary multi-
plexor category which satisﬁes the symmetry condition.

Multiplexor Categories and Models of Soft Linear Logic
479
A ﬁnitary multiplexor category provides a denotational semantics for SLLf.
Moreover, any autonomous category with ﬁnite products has a canonical struc-
ture of a ﬁnitary multiplexor category (and a symmetric one if it has equalizers
of permutations) using the ﬁnitary product formulas:
!nA = 1 × A × A⊗2 × · · · × A⊗n
(general case)
!nA = 1 × A × A⊗s2 × · · · × A⊗sn
(symmetric case)
The following is a concrete example of a symmetric ﬁnitary multiplexor category
which has recently appeared in the literature [11].
Obsessional Cliques. Recall the category OREL introduced in [11], and de-
scribed as follows:
– Objects: N-sets. (A N-set is given by a set A together with a multiplicative
action (k, a) →a(k) from N∗× A to A.)
– Morphisms: A morphism from (A, ( )) to (B, ( )) is a relation R ⊆A × B
which preserves the action, i.e.,
∀k ∈N∗, ∀(a, b) ∈R.(a(k), b(k)) ∈R
Such a relation is called an obsessional clique.
– Composition: usual relational composition.
The monoidal closed structure (cartesian product, {∗}) is inherited from that
of REL with pointwise action. For t ∈N, !tA is the set of ﬁnite multisets of
elements of A with action given by:
[a1, . . . , an](k) =

[a(k)
1 , . . . , a(k)
n ]
if
n ≤t
[ka(k)
1 , . . . , ka(k)
n ]
if
n > t
where ka is short for a, . . . , a (k times). Thus for a multiset of size less than
or equal to t, the action is the usual pointwise action, allowing multiplexing of
rank ≤t. Moreover, this exponential structure rules out digging at all levels,
and it rules out contraction for t > 0. (A good exercise is to show that bounded
contraction, formula (3) above, is not valid in this category either when m, n ≥
1.) All together, OREL is a symmetric ﬁnitary multiplexor category, and a model
of ELL with the ELL-exponential interpreted at the zeroth level by !0. Finally,
note that the forgetful functor U : OREL →REL preserves the structure strictly
(see Sect. 6.1).
6
The S-Construction
Note that a multiplexor category is trivially a ﬁnitary multiplexor category in
which !n = !
for each natural number n. In this section, we are interested in
the reverse direction. We give a categorical construction for extending a ﬁnitary
multiplexor category C to a fully-ﬂedged multiplexor category Cs.

480
B.F. Redmond
The category Cs is described as follows:
– Objects: Objects are sequences of C-objects indexed by N. Notation: (Ai) =
(A0, A1, A2, . . . ).
– Morphisms: A morphism from (Ai) to (Bi) is an equivalence class of se-
quences (k : fi) = (k : fk, fk+1, . . . ), where k is a natural number and for
each i ≥k, fi : Ai →Bi in C. Sequences (k : fi) and (k′ : f ′
i) are equivalent
iﬀthere exists a natural number m ≥k, k′ such that for all i ≥m we have
fi = f ′
i in C. We shall abuse the notation and denote the equivalence class
by one of its representatives.
– Composition: (m : gi) ◦(k : fi) = (max{k, m} : gi ◦fi). One must verify that
this is well-deﬁned. The identity on (Ai) is (0 : idAi).
There is an obvious embedding J : C →Cs deﬁned by:
A →(A, A, A, . . . )
f →(0 : f)
In a similar way, the entire structure lifts from that of the base category C with
the following (well-deﬁned) deﬁnitions:
(Ai) ∗(Bi) = (Ai ∗Bi)
(k : fi) ∗(m : gi) = (max{k, m} : fi ∗gi)
!n(Ai) = (!nAi)
!n(k : fi) = (k :!nfi)
(1) = (1, 1, . . . )
for ∗∈{&, ⊗, ⊸} and n ∈N. The structural isomorphisms lift in the obvious
way to (0 : α), (0 : λ), (0 : ρ), (0 : τ) for the monoidal structure, for example.
This outlines the proof of the following proposition. We shall demonstrate one
of the less obvious parts in detail.
Proposition 1. Cs is a ﬁnitary multiplexor category. If C is symmetric, then
so is Cs.
Proof. (Monoidal closedness.) The evaluation map ev is deﬁned as (0 : evi) :
((Ai ⊸Bi) ⊗Ai) →(Bi), where evi is the corresponding evaluation map in
C. Given any morphism f = (k : fi) : (Xi ⊗Ai) →(Bi), we have a unique
morphism ˆf =def (k : ˆfi) : (Xi) →(Ai ⊸Bi) which satisﬁes ev ◦( ˆf ⊗idA) =
(k : evi ◦( ˆfi ⊗idAi)) = (k : fi) = f, where the second last equality follows from
that in the base category C. (Note that the assignment f →ˆf is well-deﬁned.)
Once again, uniqueness of ˆf follows from the uniqueness of the ˆfi in C.
⊓⊔
The soft exponential operator is (well-)deﬁned as follows:
!(Ai) = (!0A0, !1A1, !2A2, . . . )
!(k : fi) = (k :!ifi)

Multiplexor Categories and Models of Soft Linear Logic
481
The fact that this deﬁnes a symmetric monoidal endofunctor follows from the
corresponding facts about the !i’s.
We have the following proposition.
Proposition 2. Cs is a multiplexor category. If C is symmetric, then so is Cs.
Proof. (Sketch) For each natural number n, multiplexing of rank n is deﬁned as
the equivalence class of the sequence (n : mi,n) = (n : mn,n, mn+1,n, . . . ) where
mi,n : !iAi →A⊗n
i
(i ≥n) is bounded multiplexing in C. For example, let us
check the following diagram, which commutes in a multiplexor category, for any
morphism f = (k : fi) : (Ai) →(Bi),
!A
!f

m0








!B
m0

1
We have m0◦!f = (k : mi,0◦!ifi) = (k : mi,0) ∼(0 : mi,0) = m0. This shows why
the equivalence relation is necessary. In a similar way, the remaining diagrams
commute by the corresponding diagrams in the base category C. We note that
the equivalence relation is only used for multiplexing (as above, for example)
and for lifting products from the base category C.
⊓⊔
6.1
A Variant of the S-Construction
In the applications, the base category C is often of a very simple type: a category
of structured sets and structure-preserving functions (resp. relations). More ex-
plicitly, we have a ﬁnitary multiplexor category C together with a forgetful (or
faithful) functor U : C →SET (resp. U : C →REL), which preserves the
structure strictly, e.g.:
U(A ⊗B) = U(A) × U(B)
U(1) = {∗}
U(A ⊸B) = U(B)U(A)
(resp. = U(A) × U(B))
U(!nA) = U(A)
(resp. = Mf(U(A)))
where Mf(A) denotes the set of ﬁnite multisets of elements of A. Given a
C-object A, the underlying set U(A) is denoted by |A|. In this case, the S-
construction can be simpliﬁed and the category Cs is described as follows:
– Objects: Objects are sequences of C-objects indexed by N (notation: (Ai) =
(A0, A1, A2, . . . )) with constant underlying set |A|.
– Morphisms: A morphism from (Ai) to (Bi) is a function (resp. relation) f
from |A| to |B| such that there exists some t ∈N with for any n ≥t, f is a
morphism from An to Bn in C (i.e. structure-preserving at level n).
– Composition: Composition in the base category C.
Everything follows as before, but without having to explicitly track the index k
in the morphisms, and without the need of an equivalence relation. The following
is an example of this type of model.

482
B.F. Redmond
Obsessional Cliques (cont’d). Recall the category SREL introduced in [11], and
described as follows:
– Objects: an object is a set A with a family of actions indexed by N giving it
N-set structures (An)n∈N.
– Morphisms: a morphism from (An) to (Bn) is a relation R ⊆A × B such
that there exists some t ∈N with for any n ≥t, R is an obsessional clique
of An × Bn.
– Composition: usual relational composition.
There is an obvious embedding OREL →SREL, and the monoidal closed struc-
ture of OREL lifts to SREL in the obvious way (i.e., componentwise). As a
speciﬁc construction, we deﬁne:
!(An)n∈N = (!nAn)n∈N
This forms a symmetric multiplexor category. In fact SREL is the same as
the category obtained by applying the S-construction to OREL, i.e., SREL =
ORELs. This provides an alternative description of this model.
6.2
A Realizability Model for SLL2
In this section, we give a realizability model of SLL2 similar to the one for BLL
in [9]. For space considerations we can only give a brief sketch here (see [15] for
more details). It would be interesting to compare this approach to recent work
done in [5].
In this section, we shall assume familiarity with the untyped lambda calculus.
We shall also need the following preliminaries, which are taken from [9]:
Preliminaries. An untyped lambda term is aﬃne (sometimes called aﬃne linear)
if each variable (free or bound) appears at most once (up to α-congruence). Such
a term t is strongly normalizable in less than |t| steps where |t| is the size of the
term. The runtime of the computation leading to the normal form is therefore
O(|t|2). We will henceforth use the expression aﬃne lambda term for an untyped
aﬃne lambda term which is in normal form. Given aﬃne lambda terms s, t, their
application st is deﬁned as the normal form of the lambda term st. Finally, we
write Λa for the set of closed aﬃne lambda terms.
The category Rs
p is described as follows:
– Objects: A realizability set is a pair (|A|, ⊩A), where |A| is a set and ⊩A is a
ternary relation ⊩A⊆N × Λa × |A|.
– Morphisms: A morphism from (|A|, ⊩A) to (|B|, ⊩B) is a function f : |A| →
|B| such that there exists a natural number N and a sequence of terms
{ei}i≥N (in Λa) such that:
i, t ⊩A a
implies
i, eit ⊩B f(a)
for all t ∈Λa and a ∈|A| and i ≥N. In this case we say that {ei}i≥N
witnesses or realizes the function f. Moreover, we require that there exists

Multiplexor Categories and Models of Soft Linear Logic
483
a polynomial p(i) (over N) such that |ei| ≤p(i) for all i ≥N. We call p(i) a
bounding polynomial.
– Composition: Usual function composition.
Let A = (|A|, ⊩A) and B = (|B|, ⊩B) be realizability sets. We have the following
constructions on realizability sets, for example.
– Tensor Product. We deﬁne A ⊗B = (|A| × |B|, ⊩A⊗B) where:
i, t ⊩A⊗B (a, b)
iﬀ
t = λf.ft1t2
where
i, t1 ⊩A a
and
i, t2 ⊩B b
The tensor unit is 1 = ({∗}, ⊩1) where i, λx.x ⊩1 ∗for all i ∈N.
– Linear Implication. We deﬁne A ⊸B = (|B||A|, ⊩A⊸B) where:
i, e ⊩A⊸B f
iﬀ
whenever
i, t ⊩A a
then
i, et ⊩B f(a)
– Soft Exponential. We deﬁne !A = (|A|, ⊩!A) where:
i, t ⊩!A a
iﬀ
t = λf.ft1t2 . . . ti
where
∀j ∈{1, . . . i}.i, tj ⊩A a
In [15], we show that Rs
p is a symmetric multiplexor category obtained by the
S-construction. In fact, this was the original motivation for introducing the S-
construction. Moreover, this model can be used to interpret second-order Soft
Linear Logic [15]. As in [9], soundness of the model gives a new proof that all
algorithms representable in SLL2 are polynomial time. We have:
Theorem 6. (Soundness) The category Rs
p provides a realizability semantics
for SLL2.
We refer the reader to [15] for more details.
7
Conclusion
Ultimately, we are working towards a fully complete semantics of Soft Linear
Logic [15]. But the models we have considered here are not yet complete. For
example, in the product formula interpretation, there is a morphism f : !a →
!(a⊗a), but the formula !a ⊸!(a⊗a), where a is an atom, is not provable in Soft
Linear Logic. An interesting question would be to explore the eﬀects of adding
this axiom to Soft Linear Logic, especially with regards to polytime soundness.
Lafont [10] also considers a possible extension of Soft Linear Logic with a
hierarchy of modalities !e0, !e1, !e2, . . . and a hierarchical version of digging:
Γ, !en · · · !enA ⊢C
Γ, !en+1A ⊢C
This leads to a system for elementary recursive computation, as in ELL (see
[7]). Both methods described in this paper can be used to model this extension.

484
B.F. Redmond
For example, with the S-construction, one can deﬁne on objects (with a similar
deﬁnition for morphisms):
!e0(Ai) = (!0A0, !1A1, !2A2, . . . )
(zeroth level)
!e1(Ai) = (!0A0, !1!1A1, !2!2!2A2, . . . )
(ﬁrst level)
!e2(Ai) = (!(i+1)2
i
Ai)
(second level)
· · ·
Finally, it would be interesting to investigate connections with other bounded
time complexity Linear Logics. Already, this work makes more explicit connec-
tions between Soft Linear Logic and Bounded Linear Logic, and a connection
was made with Elementary Linear Logic in [11], which could be incorporated
here by adding the following rule:
Γ, !0A, !0A ⊢C
Γ, !0A ⊢C
to ﬁnitary Soft Linear Logic. (Note that OREL is also a model of this extended
system [11].) It would be interesting if one could incorporate Girard’s Light
Linear Logic [7] into this setting also.
Acknowledgements. The author would like to sincerely thank his Ph.D. ad-
visor Richard Blute and Phil Scott for their continuing encouragement and sup-
port for this project. This work has been greatly improved with suggestions by
Olivier Laurent, Patrick Baillot and others at Universit´es Paris 7 and 13. Yves
Lafont also provided helpful comments and answered many questions at the
early stages of this project. Finally, we’d like to thank the anonymous referees
for helpful comments on the draft version of this paper. This work is supported
by the OGS program and NSERC of Canada
References
1. Abramsky, S.: Semantics of Interaction: an introduction to Game Semantics. In
Proceedings of the 1996 CLiCS Summer School, Isaac Newton Institute, P. Dybjer
and A. Pitts, eds., Cambridge University Press, 1–31, 1997
2. Abramsky,
S.:
Predicative
Copying
and
Polynomial
Time.
Cliﬀord
Lec-
tures, Tulane, 2002. Slides available at: http://web.comlab.ox.ac.uk/oucl/work/
samson.abramsky/pcpt.pdf
3. Baillot, P.: Stratiﬁed coherence spaces: a denotational semantics for Light Linear
Logic. Theoretical Computer Science, 318(1-2): 29–55, 2004
4. Bierman, G.M.: What is a Categorical Model of Intuitionistic Linear Logic?. In
Proceedings of Conference on Typed lambda calculus and Applications, Springer-
Verlag, LNCS 902: 78–93, 1995
5. Dal Lago, U., Hofmann, M.: Quantitative Models and Implicit Complexity. In Pro-
ceedings of Foundations of Software Technology and Theoretical Computer Science,
Springer-Verlag, LNCS 3821: 189–200, 2005
6. Girard, J.-Y.: Linear logic. Theoretical Computer Science, 50: 1–102, 1987

Multiplexor Categories and Models of Soft Linear Logic
485
7. Girard, J.-Y.: Light Linear Logic. Information and Computation, 143: 175–204,
1998
8. Girard, J.-Y., Scedrov, A., Scott, P.J.: Bounded linear logic: a modular approach
to polynomial-time computability. Theoretical Computer Science, 97: 1–66, 1992
9. Hofmann, M., Scott, P.J.: Realizability Models for BLL-like Languages. Theoretical
Computer Science, 318(1-2): 121–137, 2004
10. Lafont, Y.: Soft linear logic and polynomial time. Theoretical Computer Science,
318: 163–180, 2004
11. Laurent, O., Tortora de Falco, L.: Obsessional cliques: a semantic characterization
of bounded time complexity. In Proceedings of LICS, IEEE Computer Society,
179–188, 2006
12. Mac Lane, S.: Categories for the Working Mathematician, 2nd Edition. Springer,
1998
13. Mairson, H., Terui, K.: On the Computational Complexity of Cut-Elimination in
Linear Logic. In Proceedings of ICTCS, Springer-Verlag, LNCS 2841: 23–36, 2003
14. Murawski, A.S., Ong, C.-H.L.: Discreet Games, Light Aﬃne Logic and PTIME
Computation. In Proceedings of CSL, Springer-Verlag, LNCS 1862: 427–441, 2000
15. Redmond, B.F.: PhD Thesis. University of Ottawa. In preparation.

Until-Since Temporal Logic Based on Parallel
Time with Common Past. Deciding Algorithms
V. Rybakov
Department of Computing and Mathematics,
Manchester Metropolitan University,
John Dalton Building, Chester Street, Manchester M1 5GD, U.K.
V.Rybakov@mmu.ac.uk
Abstract. We present a framework for constructing algorithms recog-
nizing admissible inference rules (consecutions) in temporal logics with
Until and Since based on Kripke/Hintikka structures modeling parallel
time with common past. Logics PT Lα with various branching factor
α ∈N ∪{ω} after common past are considered. The oﬀered technique
looks rather ﬂexible, for instance, with similar approach we showed [33]
that temporal logic based on sheafs of integer numbers with common
origin is decidable by admissibility. In this paper we extend obtained
algorithms to logics PT Lα. We prove that any logic PT Lα is decidable
w.r.t. admissible consecutions (inference rules), as a consequence, we
solve satisﬁability problem and show that any PT Lα itself is decidable.
Keywords: Temporal logic, linear temporal logic, branching time logic,
admissible inference rules.
1
Introduction
Temporal logic is a modern branch of mathematical logic which has diversiﬁed
application in CS and AI. Technique of Temporal Logic has been involved to
cover all approaches to the representation of temporal information within a log-
ical framework. Signiﬁcant part of this technique is based at modal-logic type of
approach introduced around 1960 by Arthur Prior. Major part of applications
was focused to reasoning about knowledge, time and computation (cf., for in-
stance, Goldblatt [9], van Benthem [36]). Semantics approach to temporal logics
has been based on Kripke/Hinttikka models and temporal algebras (cf. Thoma-
son [35]), it has been noticeably inﬂuenced by developed tools of modal logics,
which, in own turn, formed evolved branch in contemporary mathematical logic
(cf. Goldblatt [10]).
Around 1970’s multifarious variations of temporal logics focused to applica-
tions were developed (cf. Manna and Pnueli [20], Pnueli [23]). Linear temporal
logic (LTL) has been quite successful in dealing with applications to systems spec-
iﬁcations and veriﬁcation (cf. [23]), with model checking (cf. [21,23]). Temporal
logic has numerous applications to safety, liveness and fairness, to various prob-
lems arising in computing (cf. Eds. Barringer, Fisher, Gabbay and Gough, [1]).
S. Artemov and A. Nerode (Eds.): LFCS 2007, LNCS 4514, pp. 486–497, 2007.
c
⃝Springer-Verlag Berlin Heidelberg 2007

Until-Since Temporal Logic Based on Parallel Time
487
Technique for model checking in linear temporal logic, LTL, based on B¨uchi au-
tomatons and Rabin tree automatons (cf. Carsten [2], Vardi [3,37]) formed a solid
branch in computational logic. Signiﬁcant part in investigation of LTL was fo-
cused to constructions of most eﬃcient algorithms for verifying satisﬁability in
LTL, decidability of LTL (cf. [18]). E.g., the decidability of LTL can be shown by
bounded ﬁnite model property (cf. Sistla, Clark [34]). A number of distinct vari-
ations of LTL by extension of the set of logical operations were suggested, e.g.
Gabbay [5] proved that the formulas of LTL with Past can be rewritten in future
of only LTL with possible exponential blowups, and in [17] it is shown that this
exponential blow-up is necessary. Vardi [38] developed 2 way automata theory for
a logic containing LTL+Past. Lange [16] has given a decision procedure and a
complete axiomatization for LTL+Past. An axiomatization of the temporal logic
with Until and Since over the real numbers was found in Gabbay, Hodkinson [6,7].
One of less investigated areas in temporal logic is the description of admissi-
ble inference rules (consecutions), the area which has been solidly developed for
transitive modal logics and superintuitionistic logics. Admissible rules form the
greatest class of rules which derive theorems of a logic L from L-valid assump-
tions (actually, a rule is admissible in L if L, as the set of all its theorems, is
closed w.r.t. applications of this rule). Investigation of admissible rules was, in
particular, initiated by H.Friedman problem about existence algorithms recog-
nizing rules admissible in the intuitionistic logic IPC (cf. [4]).
The area of admissible inference rules was well developed for transitive modal
and superintuitionistic logics (cf. Ghilardi [8], Iemhoﬀ[13], Jer´abek [14], Mints
[22], Rybakov [24] – [30]). But for temporal logics not much is known, only I
would refer Rybakov [32] and Rybakov [31]. In [32] it is proved that the (modal)
standard linear temporal logic based on integer numbers (which does not use U
and S) is decidable w.r.t. admissible rules. In this paper we extend our previous
research to temporal logics with Until and Since.
Turning to the main subject of our paper, temporal logic is often used with a
ﬁxed semantics or ﬂow of time. Common choices include the natural numbers,
the integers, rationals, real numbers and various branching ﬂows, depending on
the application or on what time is perceived like. In [33] the almost linear logic
with Until and Since based on sheafs of integers with common origin (0) has been
studied, where an algorithm recognizing admissible rules was found. In present
paper we extend this result to Until-Since Temporal Logics PT Lα based on
Parallel Time with Common Past, that is our logics have as semantics sheafs of
integer numbers with common past - agglutinate negative numbers. Main result
of the paper is the theorem stating that all logics PT Lα are decidable w.r.t.
admissible inference rules. This implies, in particular, that all these logics are
decidable itself, and that satisﬁability problem for logics PT Lα is also decidable.
2
Notation, Preliminaries
The paper uses standard notation and known facts concerning modal, multi-
modal and temporal logics. Standard Linear Temporal logic (LTL in the sequel)

488
V. Rybakov
has the language including Boolean logical operations and the temporal oper-
ations Next and Until. Formulas of LTL are built from a set Prop of atomic
propositions and are closed w.r.t. applications of Boolean operations, the unary
operation N (next) and the binary operation U (until). We extend the language
of LTL by introduction the following counterpart operations to N and U: N−1
(previous) and S (since), so for any wﬀs ϕ and ψ, N−1ϕ and ϕSψ are also wﬀs.
This will be the language (notation Lbtl) of our temporal branching time logics.
The semantics for formulas in Lbtl is based on the set Z of all integer numbers
with the standard linear order.
Our logic is generated by the following Kripke-Hintikka structures (models).
Let Z be the set of all integer numbers, N be the set of all natural numbers,
Z−:= {m | m ∈Z, m ≤0}, and for a set of indexes I and i ∈I, Ni are disjoint
copies of positive integer numbers. Numbers m from Ni will be denoted with
subscripts, as mi.
⊗i∈INi(Z−) := ⟨

i∈I
Ni ∪Z−, R, Next, Prev, V ⟩
is the structure where relations R, Next and Prev are deﬁned as follows.
∀x, y ∈

i∈I
Ni ∪Z−[(xRy ⇔x ≤y)&(x Prev y ⇔y −1 = x)&
(x Next y ⇔x + 1 = y)].
Relations Next and Prev are mutually converse and work in accordance with
the standard intuition, and R is linear ≤on Z−and any Ni. V is a valuation of
a subset S of Prop, which assigns truth values to elements of S in 
i∈I Ni ∪Z−.
That is, for any p ∈S, V (p) ⊆
i∈I Ni ∪Z−. We will also use the notation
Next(a) := a + 1, Prev(a) := a −1, if a ̸= 0, representing Next and Prev as
functions.
The computational interpretation of 
i∈I is as follows. The world 0 is the
current time point of a computational process. The state −1 is the ﬁnal state
of the previous computation which then, in next step, results to 0 - our current
time point. Since 0, the computational run may branch into states 1i (taking
various possible options, say, nondeterministic choice of instructions, expert’s
choice, etc...). In states after 0, and before 0, the structure behaves itself as the
standard Kripke linear structure of LTL. Thus, in our interpretation, the worlds
of 
i∈I Ni ∪Z−are states, R is the transition relation and V can be interpreted
as labeling of the states with atomic propositions. If we refer to ⊗i∈INi(Z−) as
the Kripke frame, we mean ⊗i∈INi(Z−) without valuation.
For ⊗i∈INi(Z−), the truth values can be extended from propositions of S to
arbitrary formulas constructed from these propositions as follows:
∀p ∈Prop, ∀a ∈⊗i∈INi(Z−) (⊗i∈INi(Z−), a)
p ⇔a ∈V (p);
(⊗i∈INi(Z−), a)
ϕ ∧ψ ⇔(⊗i∈INi(Z−), a)
ϕ and

Until-Since Temporal Logic Based on Parallel Time
489
[(⊗i∈INi(Z−), a)
ψ;
(⊗i∈INi(Z−), a)
¬ϕ ⇔not[(⊗i∈INi(Z−), a)
ϕ];
(⊗i∈INi(Z−), a)
Nϕ ⇔∀b[(a Next b)⇒(⊗i∈INi(Z−), b)
ϕ];
(⊗i∈INi(Z−), a)
N−1ϕ ⇔∀b[(a Prev b)⇒(⊗i∈INi(Z−), b)
ϕ];
(⊗i∈INi(Z−), a)
ϕUψ ⇔∃b[(aRb) ∧((⊗i∈INi(Z−), b)
ψ)∧
∀c[(aRcRb) ∧¬(bRc)⇒(⊗i∈INi(Z−), c)
ϕ]];
(⊗i∈INi(Z−), a)
ϕSψ ⇔∃b[(bRa) ∧((⊗i∈INi(Z−), b)
ψ)∧
∀c[(bRcRa) ∧¬(cRb)⇒(⊗i∈INi(Z−), c)
ϕ]].
Note that all standard temporal or modal operations are deﬁnable through U
and S. So, in particular, all modal operations 2+, 2−, 3+ and 3−directed to
the future and to the past are deﬁnable in our language.
For a Kripke-Hintikka structure M := ⊗i∈INi(Z−) and a formula ϕ, ϕ is
true in M (denotation – M
ϕ) if ∀a ∈M (⊗i∈INi(Z−), a)
V ϕ. A formula
ϕ is satisﬁable in PT Lα iﬀthere is a Kripke structure based on ⊗i∈INi(Z−)
where ϕ is true at some world and ||I|| ≤α.
Deﬁnition 1. For a cardinal number α ≤ω, the branching time temporal logic
PT Lα is the set of all formulas (in the language of LTL) which are true in any
Kripke/Hinttikka structure based on any frame ⊗i∈INi(Z−) with ||I|| ≤α.
First we would like to discuss how to get an algorithm for checking satisﬁability
in PT Lα. The PT Lα-Kripke structures are based on Z−and Ni and are inﬁnite,
the language of PT L with U (until) and S (before) is enough expressible, so we
cannot ﬁnd easy answer to this question immediately. In [31]) we studied the
satisﬁability problem for the temporal Tomorrow/Yesterday logic TYL, which
is based on all ﬁnite intervals of integer numbers, but has no operations U and
S. In was established (Theorem 2 [31]) that for a satisﬁable formula ϕ there is a
model for ϕ of a size linear from ϕ. Also (cf. [32]) it is shown that the standard
(multi-modal) temporal logic (with only 3+ and 3−as temporal operations)
based on Z is decidable w.r.t. admissibility in spite of it has no ﬁnite model
property. So, our logics PT Lα inherit the lack of the ﬁnite model property,
which shows that the task is not so easy. The satisﬁability algorithm for PT Lα
(and decidability of PT Lα) will follow from more strong and general result –
decidability of PT Lα w.r.t. admissible consecutions – which will be presented
in the ﬁnal part of this paper.

490
V. Rybakov
3
Admissibility, Preliminary Discussion
This section contains an introductory discussion of structural logical consequence
and provides deﬁnitions and terminology essential for the main part of this paper.
The basic problem we are dealing with is how to convey that a formula (a
statement) is a logical consequence of a collection of formulas (statements). We
will study logical consequence in terms of logical consecutions. A consecution,
(or, synonymously, – a rule, inference rule) c is an expression
c := ϕ1(x1, . . . , xn), . . . , ϕm(x1, . . . , xn)
ψ(x1, . . . , xn)
,
where ϕ1(x1, . . . , xn), . . . , ϕm(x1, . . . , xn) and ψ(x1, . . . , xn) are some formulas
constructed out of letters x1, . . . , xn. Letters x1, . . . , xn are called variables of c,
for any consecution c, V ar(c) := {x1, . . . , xn}.
The formula ψ(x1, . . . , xn) is the conclusion of c, formulas ϕj(x1, . . . , xn)
are the premises of c. Consecutions are supposed to describe the logical conse-
quences, an informal meaning of a consecution is: the conclusion logically follows
from the premises. The questions what logically follows means is crucial and has
no evident and unique answer. We consider and compare below some approaches.
Let F be a Kripke frame with a valuation V of all variables from a consecution
c := ϕ1, . . . ϕn/ψ, i.e. Dom(V ) = V ar(c).
Deﬁnition 2. The consecution c is said to be valid in the Kripke structure
⟨F, V ⟩(we will use notation ⟨F, V ⟩
c, or F
V c) if (F
V

1≤i≤m ϕi) ⇒
(F
V ψ). Otherwise we say c is refuted in F, or refuted in F by V , and
write F 
 V c.
A consecution c is valid
in a frame F (notation F
c) if, for any valuation
V of V ar(c), F
V c. A consecution c := ϕ1, . . . ϕn/ψ is valid in a logic L(K)
generated by a class of frames K if ∀F ∈K(F
c). For many logics L, if c is
valid for L w.r.t. a class K generating L, c will be also valid in all L-Kripke
frames. Note that this deﬁnition of valid consecutions is equivalent to the notion
of valid modal sequent from [15], where a theory of sequent-axiomatic classes is
developed. Also the notion of valid consecutions can be reduced to validity of
formulas in the extension of the language with universal modality (cf. Goranko
and Passy, [11]). Based on these results, some relevant technique of validity for
consecutions can be constructed. This is easy to accept that valid consecutions
correctly describe logical consequence (since, in particular, L(K) is closed w.r.t.
valid consecutions). But a question is whether it is reasonable to restrict ourselves
by only such consecutions studying a given logic L(K). Another class of correct
logical consecutions consists of so called derivable consecutions. Let a logic L
with a ﬁxed axiomatic system AxL and a consecution c := ϕ1, . . . , ϕn/ψ are
given.
Deﬁnition 3. c is said to be derivable if ϕ1, . . . , ϕn ⊢AxL ψ (i.e. if we can
derive ψ from ϕ1, . . . , ϕn in the given axiomatic system AxL).

Until-Since Temporal Logic Based on Parallel Time
491
The derivable consecutions are, of course, correct, and logics are closed w.r.t.
derivable consecutions. But, for a logic L with a given axiomatic system, it can
happen, that a formula ψ is not derivable from the premises ϕ1, ..., ϕm, but
still the rule c := ϕ1, ..., ϕm/ψ is correct: c derives L-provable conclusions from
L-provable premises. Derivable consecution must be valid, the converse is not
always true. For instance, if we will take the modal logic S4 with the axiomatic
system consisting of all S4-theorems as axioms and no inference rules at all,
the consecution x/2x is evidently non-derivable but is valid. The third kind of
correct logical consecutions are admissible consecutions proposed by Lorenzen
(1955) [19]. Given a logic L, FormL is the set of all formulas in the language of
L.
Deﬁnition 4. A consecution
c := ϕ(x1, . . . , xn), . . . , ϕm(x1, . . . , xn)
ψ(x1, . . . , xn)
,
is said to be admissible for a logic L if, ∀α1 ∈FormL, . . . , ∀αn ∈FormL,
[

1≤i≤m
[ϕi(α1, . . . , αn) ∈L]] =⇒[ψ(α1, . . . , αn) ∈L].
Thus, for any admissible consecution, any instance into the premises converting
all of them into theorems of L also turns the conclusion to be a theorem. It is
most strong type of structural logical consecutions: a consecution c is admissible
in L iﬀL, as the set of its own theorems, is closed with respect to c. It is
evident that any valid consecution is admissible. The converse is, again, not
always true. Perhaps, the earliest example of a consecution which is admissible
in the intuitionistic propositional logic (IPC, in sequel) but not valid for IPC
(consequently, non-derivable in any axiomatic system for IPC) is the Harrop’s
rule (1960, [12]):
r :=
¬x →y ∨z
(¬x →y) ∨(¬x →z).
G.Mints (1976, [22]) discovered an another inference rule:
(x →y) →x ∨z
((x →y) →x) ∨((x →y) →z),
which is invalid but admissible in IPC. The Lemmon-Scott rule (cf. [27])
2(2(232p →2p) →(2p ∨2¬2p))
232p ∨2¬2p
is admissible but invalid in modal logics S4, S4.1 and Grz.
Notice that, for any temporal linear logic PT Lα there are consecutions which
are invalid (in particular, they are not derivable rules for any possible axiomatic
system for PT Lα where postulated inference rules preserve the truth values of

492
V. Rybakov
formulas in the Kripke frames ⊗i∈INi(cz−), which, nevertheless, are admissible.
For instance, the consecutions
c1 := 2+3+x ∧2+3+¬x
y
,
c2 := 2−3−x ∧2−3−¬x
y
are admissible but invalid in PT Lα (because the premises of these consecutions
are non-uniﬁable in any PT Lα). To comment satisﬁability, the connection of
admissibility with satisﬁability problem is evident: ϕ is satisﬁable in a logic L
iﬀx →x/¬ϕ is not admissible for L. Therefore we address the rest of our paper
to study of consecutions admissible in PT Lα.
4
Main Results
Our approach is based on semantic description of consecutions admissible via
special n-characterizing Kripke structures, whose wrapping algebras are free al-
gebras from the varieties corresponding to logics.
Deﬁnition 5. Given a logic L and a Kripke structure M with a valuation de-
ﬁned for a set of letters p1, . . . , pk. M is said to be k-characterizing for L if
the following holds. For any formula ϕ(p1, . . . , pk) built using letters p1, . . . , pk,
ϕ(p1, . . . , pk) ∈L iﬀM
ϕ(p1, . . . , pk).
Recall that a Kripke structure M is said to be deﬁnable if any state a ∈M is
deﬁnable in M, i.e. there is a formula φa which is true in M only at the element
a. Given a Kripke structure M := ⟨F, V ⟩based upon a Kripke frame F, and
a new valuation V1 in F of a set of propositional letters qi. The valuation V1
is deﬁnable in M if, for any propositional letter qi, V1(qi) = V (φi) for some
formula φi.
Lemma 1. (cf., for instance, [27]) A consecution c is not admissible in a logic L
iﬀ, for any sequence ChL(k), k ∈N, of k-characterizing models for L, for some
k, the frame of ChL(k) refutes c by a certain deﬁnable in ChL(k) valuation.
To use this lemma we need a sequence of k-characterizing models for PT Lα.
Take the all Kripke frames ⊗i∈INi(Z−), ||I|| ≤α, with all possible valuations
of letters p1, . . . , pk. Consider the all resulting Kripke models Mj, j ∈J and
the disjoint union 
j∈J Mj of all such non-isomorphic Kripke models, denote
this disjoint union by Chk(PT Lα). Semantics deﬁnition of PT Lα implies
Lemma 2. Chk(PT Lα) is k-characterizing for PT Lα.
Notice that any Kripke structure Chk(PT Lα) fails to be deﬁnable. Therefore
we cannot directly implement technique evolved in [27,31] to describe consecu-
tions admissible in PT Lα, we need some more subtle, sophisticated technique.

Until-Since Temporal Logic Based on Parallel Time
493
As before, a useful tool we need is reduction of consecutions to equivalent reduced
normal forms. A consecution c is said to have the reduced normal form if c =
εc/x1 where
εc :=

1≤j≤m
(

1≤i,k≤n,i̸=k
[xt(j,i,0)
i
∧(Nxi)t(j,i,1) ∧(N−1xi)t(j,i,2)∧
(xiUxk)t(j,i,k,3) ∧(xiSxk)t(j,i,k,4)]),
and xs are certain variables, t(j, i, z), t(j, i, k, z) ∈{0, 1} and, for any formula α
above, α0 := α, α1 := ¬α.
Deﬁnition 6. Given a consecution cnf in the reduced normal form, cnf is said
to be a normal reduced form for a consecution c iﬀ, for any temporal logic L, c
is admissible in L iﬀcnf is.
Based on proofs of Lemma 3.1.3 and Theorem 3.1.11 from [27], by similar tech-
nique, we obtain
Theorem 1. There exists an algorithm running in (single) exponential time,
which, for any given consecution c, constructs its normal reduced form cnf.
To describe our algorithm distinguishing consecutions admissible in PT Lα, we
need the following special ﬁnite Kripke structures.
For any natural numbers n, k and m, where k > 1, n > 3 and m > n + 1,
the Kripke structure C[−k, 0] ⊕0,1 C[1, n] ⊕n,n+1 C[n + 1, m] is based on all
integer numbers from the interval [−k, m], and the relations Next and Prev on
[−k, m] are as follows: ∀t ∈[−k, m −1](Next(t) := t + 1);
Next(m) := n + 1;
∀t ∈[−k + 1, m](Prev(t) := t −1);
Prev(−k) := 0. So, relations Next and
Prev remain to be functions though they already are not mutually converse
for all worlds of the structure. Therefore, this structure will not form PT Lα-
frame for any possible interpretation of the accessibility relation R. Standard
accessibility relation R (as in models ⊗i∈INi(Z−) before) is not deﬁned now at
all. For a family of ﬁnite Kripke frames
Fi := C[−k, 0] ⊕0,1i [1i, ni] ⊕ni,ni+1 C[ni + 1, mi],
i ∈I,
with the structure speciﬁed above, and chosen words vi ∈(1i, ni), where all vi
are equal, the frame
⊗i∈IFi
v := ⟨

|Fi|v, Next, Prev⟩
is the disjoint union of frames Fi with
(i) agglutinate worlds vi: vi = v for all i,
(ii) agglutinate components [−k, 0] and
(iii) agglutinate components [1i, vi].
In the frame ⊗i∈IFv
i the accessibility relation R is not deﬁned. But for any
formula ϕ in the language of PT Lα and any valuation V of letters of ϕ in ⊗i∈IFv
i

494
V. Rybakov
we can deﬁne truth values of ϕ in the frame ⊗i∈IFv
i w.r.t. V using inductive
steps modiﬁed as follows:
(⊗i∈IFv
i , a)
Nϕ ⇔∀b[ a Next b ⇒(⊗i∈IFv
i , b)
ϕ];
(⊗i∈IFv
i , a)
N−1ϕ ⇔∀b[ a Prev b ⇒(⊗i∈IFv
i , b)
ϕ];
(⊗i∈IFv
i , a)
ϕUψ ⇔∃t ∈N[[(⊗i∈IFv
i , Nextt(a))
ψ]∧
∀t1 ∈N[(0 ≤t1 < t)⇒(⊗i∈IFv
i , Nextt1(a))
ϕ]];
(⊗i∈IFv
i , a)
ϕSψ ⇔∃t ∈N[[(⊗i∈IFv
i , Prevt(a))
ψ]∧
∀t1 ∈N[(0 ≤t1 < t)⇒(⊗i∈IFv
i , Prevt1(a))
ϕ]].
Here we assume Next(v) to be the next to v world, Prev(v) is the previous to
v world, Nextt1(a) (Prevt1(a)) is a world at the path leading from a to Nextt(a)
(from a back to Prevt(a)). Also we will use notation aRb if a = b or there is a
path in ⊗i∈IFv
i by Next leading from a to b.
For any consecution cnf in normal reduced form, Pr(cnf) = {ϕi | i ∈I} is
the set of all disjunctive members of the premise of cnf. Sub(cnf) is the set of all
subformulas of cnf. For any Kripke frame F and any valuation V of the set of
propositional letters of a formula ϕ, the expression (F
V ϕ) is the abbreviation
for ∀a ∈F((F, a)
V ϕ).
Lemma 3. For any frame F with a valuation V , where F
V
 Pr(cnf), for
any a ∈M, there is a unique disjunct ϕi from Pr(cnf) such that (F, a)
V ϕi.
In the sequel we will denote this unique disjunct by Dcnf,V
F
(a).
Lemma 4. If a consecution cnf in the normal reduced form is not admissible
in PT Lα then, there are integer numbers k, ni, mi ∈Z, where −k < −1, 3 <
ni, ni + 1 < mi, i ∈I, ||I|| ≤α and there exists a ﬁnite Kripke structure
Kcnf := ⟨Fcnf , V1⟩which refutes cnf by a valuation V1, where Fcnf := ⊗i∈IFv
i ,
(a) Fi := C[−k, 0] ⊕0,1i [1i, ni] ⊕ni,ni+1 C[ni + 1, mi];
(b) there exists an index i and a ∈(1i, ni) where (Fcnf , a)
 V1x1;
(c) ∀i
Dcnf,V1
Fcnf
(−ki) = Dcnf,V1
Fcnf
(1i);
Dcnf,V1
Fcnf
(ni) = Dcnf,V1
Fcnf
(mi);
(d) k, ni, mi and ||I|| are linearly computable from the size of cnf.
The 3-modal frame 1 is the frame based at the single element set {a1} where
a1Next a1, a1Prev a1 and a1 ≤a1. We can deﬁne truth values of formulas in
the language of PT Lα in 1 in the evident way.

Until-Since Temporal Logic Based on Parallel Time
495
Lemma 5. If a consecution cnf in the normal reduced form is not admissible
in PT Lα then there exists a valuation V0 of variables from cnf in the frame 1
where
1
V0

{ϕi | ϕi ∈Pr(cnf)}
Lemma 6. If a consecution cnf in normal reduced form satisﬁes the conclusions
of Lemma 4 and Lemma 5 then cnf is not admissible in PT Lα.
Using Theorem 1, Lemmas 4, 5 and 6 we immediately obtain
Theorem 2. Any logic PT Lα is decidable w.r.t. admissible consecutions. There
is an algorithm recognizing consecutions admissible in PT Lα.
Notice that any formula ϕ is a theorem of PT Lα iﬀx →x/ϕ is admissible in
PT Lα. A formula ϕ is satisﬁable in PT Lα iﬀx →x/¬ϕ is not admissible in
PT Lα. Thus, as a simple consequence, this algorithm solves the satisﬁability
problem for PT Lα and shows that PT Lα itself is decidable. The complexity of
the algorithm from Theorem 2 is exponential reduction of rules (consecutions) to
reduced normal forms plus complexity of model checking in models of size linear
in obtained reduced normal forms. Using presence of the deﬁnable universal
modality in any logic PT Lα (as 2+2−) it is possible to reduce the veriﬁcation
of admissibility to the question about validity of inference rules (or just formulas)
in frames generating PT Lα. But the algorithm (which we can derive from the
one given in this paper for admissibility) will look very similar.
References
1. Barringer H, Fisher M, Gabbay D., Gough G. Advances in Temporal Logic, Vol.
16 of Applied logic series, Kluwer Academic Publishers, Dordrecht, 1999.
2. Carsten Fritz. Constructing B¨uchi Automaton from Linear Temporal Logic Using
Simulation Relations for Alternating B¨uchi Automata . - Lecture Notes in Com-
puter Science (LNCS), 2759, 2003 , pp. 35 – 48.
3. Daniele M, Giunchiglia F, Vardi M.
Improved Automata Generation for Linear
Temporal Logic. - In book: (CAV’99), International Conference on Computer-Aided
Veriﬁcation, Trento, Italy, 1999.
4. Friedman H. One Hundred and Two Problems in Mathematical Logic.- Journal of
Symbolic Logic, Vol. 40, 1975, No. 3, pp. 113 - 130.
5. Gabbay D.
The Declarative Past and Imperative Future: Executable Temporal
Logic for Interactive Systems. In: B. Banieqbal, H. Barringer, and A. Pnueli, edi-
tors, Proceedings of the 1st Conference on Temporal Logic in Speciﬁcation, volume
398 of LNCS , 1987, pp. 409 – 448.
6. Gabbay D.M., Hodkinson I.M. and Reynolds M.A. Temporal Logic: - Mathematical
Foundations and Computational Aspects, volume 1. Clarendon Press, Oxford, 1994.
7. Gabbay D.M., Hodkinson I.M. An axiomatisation of the temporal logic with Until
and Since over the real numbers. - Journal of Logic and Computation, Vol. 1 (1990),
pp. 229-260.
8. Ghilardi S. Uniﬁcation in Intuitionistic logic.
- Journal of Symbolic Logic, Vol.
64, No. 2 (1999) , pp. 859-880.

496
V. Rybakov
9. Goldblatt R. Logics of Time and Computation.- CSLI Lecture Notes, No.7, 1992.
10. Goldblatt R.
Mathematical Modal Logic: A View of its Evolution. - J. Applied
Logic, Vol 1 (5-6), 2003, pp. 309 - 392.
11. Goranko V., Passy S. Using the Universal Modality: Gains and Questions.- J. Log.
Comput., Vol 2(1), 1992, pp. 5–30.
12. Harrop R. Concerning Formulas of the Types A →B ∨C, A →∃xB(x) in Intu-
itionistic Formal System.- J. of Symbolic Logic, Vol. 25, 1960, pp. 27-32.
13. IemhoﬀR. On the admissible rules of Intuitionistic Propositional Logic. - J.of
Symbolic Logic Vol. 66, 2001, pp. 281-294.
14. Jer´abek E. Admissible Rules of Modal Logics. -J. of Logic and Computation, 2005,
Vol. 15. pp. 411-431.
15. Kapron B.M. Modal Sequents and Deﬁnability, J.of Symbolic Logic, Vol. 52(3),
1987, pp. 756 - 765.
16. Lange M. A quick axiomatisation of LTL with past. Mathematical Logic Quarterly,
V, 51, No 1, 2005, pp. 83 - 88.
17. Laroussinie F., Markey N. and Schnoebelen Ph. Temporal Logic with Forgettable
Past. In: Proceedings of the 17th Annual IEEE Symposium on Logic in Computer
Science (LICS’02), Copenhagen, Denmark, 2002, pp 383-392.
18. Lichtenstein O., Pnueli A. Propositional temporal logics: Decidability and com-
pleteness. Logic Journal of the IGPL, 8(1), 2000, pp. 55 – 85.
19. Lorenzen P.
Einf¨uhrung in die operative Logik und Mathematik. - Berlin-
G¨ottingen, Heidelberg, Springer-Verlag, 1955.
20. Manna Z., Pnueli A. The Temporal Logic of Reactive and Concurrent Systems:
Speciﬁcation. - Springer-Verlag, 1992.
21. Manna Z., Sipma H. Alternating the Temporal Picture for Safety. - In Proc. 27th
Intl. Colloq. Aut. Lang. Prog.(ICALP 2000). LNCS 1853, Springer-Verlag, pp.
429-450.
22. Mints G.E. Derivability of Admissible Rules.- J. of Soviet Mathematics, V. 6, 1976,
No. 4, pp. 417 - 421.
23. Pnueli A. The Temporal Logic of Programs.- In Proc. of the 18th Annual Symp.
on Foundations of Computer Science, IEEE, 1977, pp. 46 – 57.
24. Rybakov V.V.
A Criterion for Admissibility of Rules in the Modal System S4
and the Intuitionistic Logic. - Algebra and Logic, V.23 (1984), No 5, pp. 369 - 384
(Engl. Translation).
25. Rybakov V.V. The Bases for Admissible Rules of Logics S4 and Int.- Algebra and
Logic, V.24, 1985, pp. 55 – 68 (English translation).
26. Rybakov V.V. Rules of Inference with Parameters for Intuitionistic logic.- Journal
of Symbolic Logic, Vol. 57, No. 3, 1992, pp. 912 - 923.
27. Rybakov V.V. Admissible Logical Inference Rules. -
Studies in Logic and the
Found. of Mathematics, Vol. 136, Elsevier Sci. Publ., North-Holland, New-York-
Amsterdam, 1997.
28. Rybakov V.V., Kiyatkin V.R., Oner T., On Finite Model Property For Admissible
Rules. - Mathematical Logic Quarterly, Vol.45, No 4, 1999, pp. 505 –520.
29. Rybakov V.V. Terziler M., Rimazki V. Basis in Semi-Reduced Form for the Admis-
sible Rules of the Intuitionistic Logic IPC. - Mathematical Logic Quarterly, Vol.46,
No. 2 (2000), pp. 207 - 218.
30. Rybakov V.V. Construction of an Explicit Basis for Rules Admissible in Modal
System S4. - Mathematical Logic Quarterly, Vol. 47, No. 4 (2001), pp. 441 – 451.
31. Rybakov V.V. Logical Consecutions in Intransitive Temporal Linear Logic of Finite
Intervals. - Journal of Logic Computation, (Oxford Press, London), Vol. 15 No. 5
(2005), pp. 633 – 657.

Until-Since Temporal Logic Based on Parallel Time
497
32. Rybakov V.V. Logical Consecutions in Discrete Linear Temporal Logic. Journal
of Symbolic Logic, V.70, No 4 (2005), pp. 1137 – 1149.
33. Rybakov V.V. Branching Time Logic PT Lα with Operations Until and Since Based
on Bundles of Integer Numbers, Logical Consecutions, Deciding Algorithms, 2006,
submitted
34. Sistla A.P. and Clarke E.M.
The Complexity of Propositional Linear Temporal
Logic. Journal of the ACM, 32(3), 1985, pp. 733 – 749.
35. Thomason S.K.
Semantic Analysis of Tense Logic.- Journal of Symbolic Logic,
Vol. 37, No. 1 (1972).
36. van Benthem J.
The Logic of Time. - Reidel, Dordrecht, Synthese Library, Vol.
156, 1983.
37. Vardi M. An automata-theoretic approach to linear temporal logic.- In Proceedings
of the BanﬀWorkshop on Knowledge Acquisition (1994), (Banﬀ’94).
38. Vardi M. Reasoning about the past with two-way automata. In: Proc. 25th Int.
Coll. on Automata, Languages, and Programming, Vol. 1443 of LNCS, 1998, pp.
628–641.

Total Public Announcements
David Steiner and Thomas Studer
Universit¨at Bern, Institut f¨ur Informatik und angewandte Mathematik,
Neubr¨uckstrasse 10, CH-3012 Bern
steiner@iam.unibe.ch, tstuder@iam.unibe.ch
http://www.iam.unibe.ch/til/staff/
Abstract. We present a dynamic epistemic logic for knowledge change
of rational agents. Existing approaches only deal with partial public an-
nouncements, that means an announcement may lead to an inconsistent
state. We introduce an extension of the multi-modal logic S5n featuring
total public announcements where an update cannot result in an incon-
sistency. We also study total public announcements in the context of
common knowledge and relativized common knowledge.
1
Introduction
At the end of the eighties, Plaza published the famous article about logics of
public communications [1]. In the sequel, the theory of knowledge change caused
by incoming information has been further developed by many authors. We con-
ﬁne ourselves to mentioning just a few typical articles: Baltag et al. [2,3], van
Benthem et al. [4,5,6,7], van Ditmarsch et al. [8,9,10,11], as well as Renne [12].
The language for logics of public announcements is the language of standard
multi-modal logic augmented with announcement operators [α] for every for-
mula α. The expression [α]β then stands for after every announcement of α, it
holds that β. In the classical setting, announcement has to be read as truthful
announcement. Therefore, announcements are partial: that is
¬[α]⊥
(1)
is not valid (see [10], Proposition 4.11).
We propose a system in which announcements are total, that is (1) holds.
Therefore, in our system announcements need not be truthful; they can be true
or false. As usual, a true announcement will lead to an update of an agent’s
epistemic state. However, a false announcement will not lead to an inconsistent
epistemic state, it will automatically be ignored by the agents. That is, after a
false announcement, an agent will have the same epistemic state as before the
announcement. Because (1) holds in our system, we call it consistency preserving.
A system for consistency preserving belief change (instead of knowledge change)
is studied in [13].
A property we keep from the classical setting is
p →[α]p.
(2)
S. Artemov and A. Nerode (Eds.): LFCS 2007, LNCS 4514, pp. 498–511, 2007.
c
⃝Springer-Verlag Berlin Heidelberg 2007

Total Public Announcements
499
That means, an announcement does not change atomic facts. We call a system
that satisﬁes (2) atomic preserving.
The paper is organized as follows. In Section 2, we present an axiomatization of
a system for total public announcements which satisﬁes both (1) and (2). We also
propose a Kripke semantics for our system and show soundness and completeness
of our axiomatization. In Section 3, we extend our logic with common knowledge
operators. We show that agents can achieve common knowledge by receiving
an announcement. For this system, the completeness proof cannot make use of
a translation to a language without announcements (which is possible in the
case without common knowledge). Completeness of total public announcements
with common knowledge is established via the notion of maximal consistent
sets. Recently, relativized common knowledge has received much attention in
the context of logics for public announcements [7,5,6]. We introduce a system
of relativized common knowledge and total public announcements in Section 4.
Again, we establish soundness and completeness of our system. It follows from
the proof that the addition of total public announcements to relativized common
knowledge does not increase the expressive power of the language. We conclude
this paper with some discussion in Section 5.
2
A System for Total Public Announcements
We introduce the language LA
n of multi-modal logic with dynamic-style operators
for public announcements.
Given a natural number n ≥1, we ﬁx the set A = {1, . . . , n} of n rational
agents. Further, we take a countable non-empty set P of propositions, denoted
by p, q, . . ., possibly with subscripts. The set of LA
n formulas is deﬁned by the
following grammar (p ∈P, i ∈A),
α, β, . . . ::= p | ¬α | α ∧β | Kiα | [α]β.
The formula Kiα stands for the agent i knows α, the formula [α]β means β
holds after the public announcement of α. The L0 formulas are the proposi-
tional formulas, the Ln formulas are the modal formulas without announcement
operators.
For all formulas α, β of LA
n, we deﬁne α ∨β, α →β, and α ↔β as usual.
Further, we let
⊤:= p0 ∨¬p0
and
⊥:= p0 ∧¬p0
for some ﬁxed p0 ∈P. Iterated announcements [α]kβ are deﬁned by induction
on k. We set
[α]0β := β
and
[α]k+1β := [α][α]kβ.
The following system for total public announcements in the context of belief
change can be obtained from Gerbrandy and Groeneveld [14]. It results from
deleting edges in a Kripke structure.

500
D. Steiner and T. Studer
(PT)
Every instance of a propositional tautology,
(K)
Ki(α →β) →(Kiα →Kiβ),
(4)
Kiα →KiKiα,
(5)
¬Kiα →Ki¬Kiα,
(A1)
[α]p ↔p,
(A2)
[α](β →γ) →([α]β →[α]γ),
(A3)
[α]¬β ↔¬[α]β,
(A4.B)
[α]Kiβ ↔Ki(α →[α]β),
(MP)α
α →β
β
,
(NEC.1) α
Kiα,
(NEC.2) α
[β]α .
To obtain a system for knowledge change, we cannot just add the knowledge
axiom Kiα →α since that would lead to an inconsistency. The theory S5A
n is
obtained by changing axiom (A4.B) to (A4) and adding axioms (T) and (A5).
(T)
Kiα →α,
(A4)
α →([α]Kiβ ↔Ki(α →[α]β)),
(A5)
¬α →([α]β ↔β).
The instances of axiom (A5) of the form
¬α →([α]Kiβ ↔Kiβ)
(3)
can be seen as a necessary companion to the knowledge axiom (T), because a
false formula can never be known by an agent, thus it can never be learned.
Note that we could formulate the system S5A
n with (3) instead of (A5). Then
(A5) would be provable in the resulting system. However, later we will consider
an extension of S5A
n by common knowledge operators. There, things get much
simpler if (A5) is already included as an axiom.
By replacing (T) with the (D)-axiom ¬Ki⊥, the agents can decide whether
to accept an incoming formula or to reject it. For a detailed treatment of this
approach, see [13].
Our system is consistency preserving as well as atomic preserving. We have
the following lemma.
Lemma 1. For all LA
n formulas α and all propositions p ∈P we have
S5A
n ⊢¬[α]⊥
and
S5A
n ⊢p →[α]p.
Observe, that the public announcement operator is self-dual due to axiom (A3).
This means we do not have to distinct the statements ’β holds after every (truth-
ful) public announcement of α’ and ’β holds after some (truthful) public an-
nouncement of α’. In our setting, there is only one public announcement of a
formula. It can be truthful or not.
We will now state some properties which will be helpful for the rest of the
paper.

Total Public Announcements
501
Lemma 2. For all LA
n formulas α, β, and γ we have that S5A
n proves
[α](β ∧γ) ↔([α]β ∧[α]γ),
[α](β ∨γ) ↔([α]β ∨[α]γ),
[α]Kiβ ↔(¬α ∧Kiβ) ∨(α ∧Ki(α →[α]β)).
We now give semantics to our logic of total public announcements. Since we
deal with an extension of S5n, we will only need Kripke structures where the
accessibility relations are equivalence relations.
Deﬁnition 1. An n-Kripke structure K = (S, R1, . . . , Rn, V ) is an (n+2)-tuple,
where S ̸= ∅is a set of states, Ri ⊆S2 for all i ∈A, and V : P →Pow(S) is a
valuation function.
Since n is ﬁxed, we will drop it and use only the term Kripke structure. The set
S is called the universe of K, denoted by |K|. In the sequel, we will write Keq
n for
the class of all Kripke structures with equivalence relations exclusively.
We will now deﬁne the validity of an LA
n formula in a state s of a Kripke
structure K. The crucial point in this deﬁnition is the case of [α]β, where we
simultaneously deﬁne an operation on K, depending on α and s.
Deﬁnition 2. Let K = (S, R1, . . . , Rn, V ) be an arbitrary Kripke structure and
s ∈S be given. The validity of LA
n formulas in the Kripke-world K, s is inductively
deﬁned as follows.
K, s |= p iﬀs ∈V (p),
K, s |= ¬α iﬀK, s ̸|= α,
K, s |= α ∧β iﬀK, s |= α and K, s |= β,
K, s |= Kiα iﬀfor every t ∈S, sRit ⇒K, t |= α,
K, s |= [α]β iﬀKα,s, s |= β,
where for given α ∈LA
n and s ∈|K|, the Kripke structure Kα,s is simultaneously
deﬁned by
Kα,s := (S, Rα,s
1 , . . . , Rα,s
n , V ),
Rα,s
i
:=
Ri ∩{(u, v) ∈S2 | K, u |= α iﬀK, v |= α} if K, s |= α,
Ri
if K, s ̸|= α.
We say that an LA
n formula α is valid in the Kripke structure K (K |= α), iﬀfor
all s ∈S, K, s |= α. The formula α is valid with respect to Keq
n (Keq
n |= α), iﬀ
for all K ∈Keq
n , K |= α. Further, we say that α is satisﬁable in Keq
n , iﬀthere is a
K ∈Keq
n and an s ∈|K|, such that K, s |= α.
If all Ri in K are equivalence relations, then Kα,s belongs to Keq
n , as is stated
in the next lemma. It is an immediate consequence of the deﬁnition of Rα,s
i
.
Lemma 3. For all Kripke structures K, all LA
n formulas α, and all s ∈|K| we
have
K ∈Keq
n
⇒
Kα,s ∈Keq
n .

502
D. Steiner and T. Studer
Example 1 (Wise men puzzle). Alice, Bob, and Charlie wear a hat and cannot
see its color. But they can see, of course, the color of the others’ hats. There
are only two red and three blue hats, and every person knows that. The Kripke
structure K, which represents this situation is shown in Figure 1 (reﬂexivity and
symmetry of the relations RA, RB, and RC are self-evident).
bbb
bbr
C













brb
B
rbb
A

brr
B
C












rbr
A

C












rrb
B
A

Fig. 1. The initial structure
In the state rbb, Alice wears a red hat, whereas Bob and Charlie both wear a
blue hat. Now, Alice publicly announces, that she does not know the color of her
hat, which is true. After that, Bob announces the same true fact. This results in
the Kripke structure
(K¬KArA∧¬KAbA,rbb)¬KBrB∧¬KBbB,rbb,
which is illustrated in Figure 2.
bbb
bbr
brb
B
rbb
A

brr
rbr
A

rrb
B
A

Fig. 2. The situation after two announcements
Now Charlie knows that he is wearing a blue hat. Observe, that for a false
announcement, e.g. bA in the state rbb, we have that KbA,rbb = K.
Soundness of our system can be proved in the usual way.
Lemma 4. The system S5A
n is sound with respect to Keq
n , i.e. for all LA
n formulas
α we have
S5A
n ⊢α
⇒
Keq
n |= α.

Total Public Announcements
503
Proof. The proof is by induction on the length of the derivation. In the base
case, soundness of the axiom (A4) is proved as follows. Let K ∈Keq
n , s ∈|K|, and
i ∈A be given and assume that K, s |= α. Then we have
K, s |= [α]Kiβ iﬀKα,s, s |= Kiβ
iﬀfor all t ∈S, sRα,s
i
t ⇒Kα,s, t |= β
iﬀfor all t ∈S, sRit and K, t |= α ⇒K, t |= [α]β
iﬀK, s |= Ki(α →[α]β).
In the induction step, soundness of the rule (NEC.2) immediately follows from
Lemma 3.
2
Completeness of S5A
n can be proved via a translation from LA
n to Ln since the two
languages have the same expressive strength. As a preparation, we will deﬁne a
translation from {[α]β | α, β ∈Ln} to Ln.
Deﬁnition 3. The function h from {[α]β | α, β ∈Ln} to Ln is inductively
deﬁned by
h([α]p) := p,
h([α]¬β) := ¬h([α]β),
h([α](β ∧γ)) := h([α]β) ∧h([α]γ),
h([α]Kiβ) := (¬α ∧Kiβ) ∨(α ∧Ki(α →h([α]β))).
Of course, h eliminates the announcement operator. Its deﬁnition leads to two
important properties which we state in the following lemma.
Lemma 5. For all LA
n formulas α, β and all Ln formulas ϕ, ψ we have
S5A
n ⊢[ϕ]ψ ↔h([ϕ]ψ)
and
S5A
n ⊢α ↔β ⇒S5A
n ⊢[α]ψ ↔[β]ψ.
We are now able to deﬁne our translation t, which eliminates the announcement
operator in every LA
n formula.
Deﬁnition 4. The translation t from LA
n to Ln is inductively deﬁned by
t(p) := p,
t(¬α) := ¬t(α),
t(α ∧β) := t(α) ∧t(β),
t(Kiα) := Kit(α),
t([α]β) := h([t(α)]t(β)).
It is obvious that for every LA
n formula α, its translation t(α) is a formula of Ln.
In addition, we can prove the equivalence of α and t(α) in S5A
n.
Lemma 6. For all LA
n formulas α we have
S5A
n ⊢α ↔t(α).

504
D. Steiner and T. Studer
Lemma 6 is very helpful for proofs by induction on arbitrary LA
n formulas. Making
use of it, one can easily show the following property.
Corollary 1. For all LA
n formulas α, β, and γ we have
S5A
n ⊢α ↔β
⇒
S5A
n ⊢[α]γ ↔[β]γ.
As another consequence of Lemma 6 we get the following equivalence concerning
consecutive announcement operators.
Lemma 7. For all LA
n formulas α, β, and γ we have
S5A
n ⊢α ∧[α]β →([α][β]γ ↔[α ∧[α]β]γ).
Making use of Lemma 6, we can easily show completeness of S5A
n.
Lemma 8. The system S5A
n is complete with respect to Keq
n , i.e. for all LA
n for-
mulas α we have
Keq
n |= α
⇒
S5A
n ⊢α.
Proof. Assuming Keq
n |= α, we get Keq
n |= t(α) by soundness and Lemma 6. Due
to completeness of S5n, we have S5n ⊢t(α), which yields S5A
n ⊢t(α) because
S5n is contained in S5A
n. Now, we get S5A
n ⊢α by Lemma 6.
2
In a next step, we deﬁne announcement-resistant LA
n formulas. This notion is
inspired by – but diﬀerent than – the notion of successful formulas, see [9]. A
formula α is successful if [α]α is valid. However, in our setting not even proposi-
tions would be successful formulas. As an alternative, we introduce the class of
announcement-resistant formulas.
Deﬁnition 5. An LA
n formula α is called announcement-resistant, if for all LA
n
formulas β we have
S5A
n ⊢α →[β]α.
Observe, that S5A
n proves α →[β]kα for all k ≥0, if α is announcement-resistant.
There are many announcement-resistant formulas, as the following lemma shows.
Lemma 9.
1. All L0 formulas as well as all provable LA
n formulas are announcement-
resistant.
2. If α and β are announcement-resistant, then so also are the formulas α ∧β,
α ∨β, and Kiα.
By the previous lemma, we know that Kiα is announcement-resistant for all
L0 formulas α. That means knowledge in propositional formulas can never be
contracted by public announcements. We can therefore say that the logic of total
public announcements formalizes expansion for propositional knowledge.
As we have seen in Example 1, agents can really expand their knowledge due
to announcements. The next lemma shows that they learn true announcement-
resistant formulas by one single announcement.
Lemma 10. Let α be an announcement-resistant LA
n formula. Then for all k ≥
1, all m ≥0, and all i1, . . . , im ∈A we have
S5A
n ⊢α →[α]kKim . . . Ki1α.

Total Public Announcements
505
3
Incorporating Common Knowledge
Lemma 10 even shows that agents can acquire so-called common knowledge. In
this section, we will extend our logic of total public announcements by common
knowledge operators. To this aim we have to formalize the notion of mutual
knowledge. For every non-empty group G ⊆A of agents, the formula Ek
Gα is
inductively deﬁned by
E0
Gα := α
and
Ek+1
G
α :=

i∈G
(KiEk
Gα).
We simply write EGα for E1
Gα to express that everybody in G knows α. The
following property holds.
Lemma 11. For all LA
n formulas α and β we have
S5A
n ⊢α →([α]EGβ ↔EG(α →[α]β)).
The language LC,A
n
of common knowledge and public announcements is the lan-
guage LA
n expanded by the common knowledge operator CG for every non-empty
group G ⊆A of agents. To deﬁne the validity of LC,A
n
formulas in a Kripke-world
K, s, we add the following clause to Deﬁnition 2.
K, s |= CGα
iﬀ
for every t ∈|K|, s(RG)⋆t ⇒K, t |= α,
where (RG)⋆denotes the transitive closure of RG := {Ri | i ∈G}, see Fagin
et al. [15]. It is an easy exercise to show that
K, s |= CGα
iﬀ
for every t, there is a G-path from s to t ⇒K, t |= α.
The system S5C,A
n
is deﬁned as extension of S5A
n by an additional announcement
axiom, the axioms and rules for common knowledge, as well as a rule for common
knowledge after an announcement.
Deﬁnition 6. The theory S5C,A
n
is deﬁned to be S5A
n augmented by the following
axioms and rules.
(A6)
α ∧[α]β →([α][β]γ ↔[α ∧[α]β]γ),
(C)
CGα →EG(α ∧CGα),
(IND.1)α →EG(α ∧β)
α →CGβ
,
(IND.2)α →[β]γ
α ∧β →EG(β →α)
α ∧β →[β]CGγ
.
Axiom (A6) is provable in S5A
n, see Lemma 7. However, this is not the case for
S5C,A
n
since there is no translation available that eliminates the announcement
operators. The rule (IND.2) is a slight modiﬁcation of the action rule from Baltag
et al. in [2,3].
To show soundness and completeness, we will need the following notion of a
Gα-path.

506
D. Steiner and T. Studer
Deﬁnition 7. Let α ∈LC,A
n , K ∈Keq
n , ∅̸= G ⊆A, and s, t ∈|K|. Then we
say that there is a Gα-path from s to t, if there are states u1, u2, . . . , uk ∈|K|
s.t. sRGu1RGu2RG . . . RGuk, uk = t, and for all j, 1 ≤j ≤k ⇒K, uj |= α.
It is easy to see that K, s |= α implies
K, s |= [α]CGβ
iﬀ
for every t, there is a Gα-path from s to t ⇒K, t |= [α]β.
Lemma 12. The system S5C,A
n
is sound with respect to Keq
n , i.e. for all LC,A
n
formulas α we have
S5C,A
n
⊢α
⇒
Keq
n |= α.
Proof. The proof is by induction on the length of the derivation. In the induction
step, soundness of the rule (IND.2) is proved as follows. Suppose, the formula
α ∧β →[β]CGγ has been derived with the rule (IND.2). Then, by induction
hypothesis, we know that the formulas (a) α →[β]γ and (b) α∧β →EG(β →α)
are valid. Now, take any Kripke-world K, s such that K, s |= α ∧β. Using (b)
we get that K, t |= α in every world t ∈|K| which is reachable on a Gβ-path
from s. But then, by (a), we have that K, t |= [β]γ in every t reachable on a Gβ-
path from s. This implies, by deﬁnition of the announcement semantics, that
K, s |= [β]CGγ, and we are done.
2
Lemma 13. For all LC,A
n
formulas α, β, and γ we have
S5C,A
n
⊢α ∧CG(α →[α]β) →[α]CGβ,
S5C,A
n
⊢α ↔β ⇒S5C,A
n
⊢[α]γ ↔[β]γ.
Since the formula α∧[α]CGβ →CG(α →[α]β) is not valid (compare with (A4)),
there is no translation available that could be used to give an easy completeness
proof of S5C,A
n . Thus we have to employ maximal consistent sets to show com-
pleteness. Our argument is the same as the one presented in [15] for the logic
of common knowledge except that we have more cases in the truth lemma. We
start by deﬁning the closure cl(α) of a formula α.
Deﬁnition 8. For all LC,A
n
formulas α, sub+(α) is the smallest set which satisﬁes
the following conditions.
1. α ∈sub+(α).
2. If ¬β ∈sub+(α), then β ∈sub+(α).
3. If β ∧γ ∈sub+(α), then β, γ ∈sub+(α).
4. If Kiβ ∈sub+(α), then β ∈sub+(α).
5. If CGβ ∈sub+(α), then EGβ, EGCGβ ∈sub+(α).
6. If [β]p ∈sub+(α), then β, p ∈sub+(α).
7. If [β]¬γ ∈sub+(α), then [β]γ, ¬γ ∈sub+(α).
8. If [β](γ ∧δ) ∈sub+(α), then [β]γ, [β]δ, γ ∧δ ∈sub+(α).
9. If [β]Kiγ ∈sub+(α), then Kiγ, Ki(β →[β]γ) ∈sub+(α).
10. If [β]CGγ ∈sub+(α), then CGγ, EG(β →[β]CGγ) ∈sub+(α).
11. If [β][γ]δ ∈sub+(α), then [β]δ, [γ]δ, [β ∧[β]γ]δ ∈sub+(α).
The closure of α is deﬁned by cl(α) := sub+(α) ∪{¬β | β ∈sub+(α)}.

Total Public Announcements
507
Observe, that for α = [β]γ, we immediately get both sub+(β) ⊆sub+(α) and
sub+(γ) ⊆sub+(α).
Lemma 14. For every LC,A
n
formula α, the set cl(α) is ﬁnite.
Note that cl(α) is not closed under complements: for a given β ∈cl(α) we need
not have ¬β ∈cl(α). However, there is always a formula ∼β ∈cl(α), which is
equivalent to ¬β.
Deﬁnition 9. For every LC,A
n
formula α, the canonical structure of α is deﬁned
by Kα = (con(α), R1, . . . , Rn, V ), where
con(α) := {U ∩cl(α) | U is a maximal S5C,A
n -consistent set},
Ri := {(X, Y ) | X/Ki = Y/Ki},
V (p) := {X | p ∈X},
and X/Ki denotes the set {β | Kiβ ∈X}.
For the notion of a maximal consistent set with respect to a theory, see for
instance [15]. Observe, that Kα is in Keq
n for all LC,A
n
formulas α.
Lemma 15 (Truth Lemma). Let α be an arbitrary LC,A
n
formula and Kα be
its canonical structure. Then we have for all β ∈cl(α) and all X ∈con(α),
β ∈X
⇔
Kα, X |= β.
Proof. We prove this lemma by induction on β, and we omit the cases where β
does not begin with an announcement operator because they are standard. Hence
assume β begins with an announcement operator. We show by side induction
on δ that for any announcement operator [γ] the claim holds for β = [γ]δ. The
base case is immediate, we have [γ]p ∈X iﬀKα, X |= [γ]p by axiom (A1) and
Deﬁnition 9. The cases β = [γ]¬ϕ and β = [γ](ϕ ∧ψ) are also straightforward.
Now let β = [γ]Kiϕ. The interesting step is the case Kα, X |= γ in the
direction from right to left. First, one can show that the set
Y := {Kiξ | Kiξ ∈X} ∪{¬Kiξ | ¬Kiξ ∈X} ∪{γ, ¬[γ]ϕ}
is inconsistent, using the induction hypothesis for γ and [γ]ϕ. Using the axioms
(T), (4), and (5), we can prove the existence of a set
Z := {Kiξ1, . . . , Kiξk, ¬Kiξk+1, . . . , ¬Kiξl} ⊆Y
s.t. the set Z∪{¬Ki(γ →[γ]ϕ)} is inconsistent. Since Z ⊆X and X ∈con(α), we
have Ki(γ →[γ]ϕ) ∈X. Using axiom (A4) and again the induction hypothesis
for γ we get that [γ]Kiϕ ∈X.
For β = [γ]CGϕ, the case Kα, X |= γ in the direction from right to left
is the challenging part of the proof. For every Y ∈con(α) and for the set
B := {Z ∈con(α) | Kα, Z |= [γ]CGϕ}, we deﬁne the formulas
ψY :=

ξ∈Y
ξ
and
χB :=

Y ∈B
ψY .

508
D. Steiner and T. Studer
It is not hard to show, that the formulas χB →[γ]ϕ and χB ∧γ →EG(γ →χB)
are both derivable. Applying the rule (IND.2) we get ⊢χB ∧γ →[γ]CGϕ. Since
X ∈B by assumption, and γ ∈X by induction hypothesis, we have ⊢ψX →
[γ]CGϕ. Hence, we know that [γ]CGϕ ∈X.
The last case of our induction is β = [γ][ϕ]ψ. Here we distinct the three
cases ∼γ ∈X, ∼[γ]ϕ ∈X, and γ, [γ]ϕ ∈X. All three cases are straightforward
using the axioms (A5) and (A6), respectively. Observe, that we need the second
induction hypothesis in the third case.
2
Due to the Truth Lemma, we know that every S5C,A
n -consistent formula is satis-
ﬁable in Keq
n , thus we have completeness.
Theorem 1. The system S5C,A
n
is complete with respect to Keq
n , i.e. for all LC,A
n
formulas α we have
Keq
n |= α
⇒
S5C,A
n
⊢α.
As an immediate consequence of our completeness proof, we get the ﬁnite model
property and that the satisﬁability problem is decidable.
We now extend the deﬁnition of announcement-resistance to the richer lan-
guage. An LC,A
n
formula α is called announcement-resistant, if
S5C,A
n
⊢α →[β]α
for every LC,A
n
formula β.
It is still true, that all L0 formulas as well as all provable LC,A
n
formulas are
announcement-resistant. In addition, if α and β are announcement-resistant,
then so also are the formulas α ∧β, α ∨β, Kiα, and CGα.
Lemma 16. Let α be an announcement-resistant LC,A
n
formula and G ⊆A be
a non-empty group of agents. Then for all k ≥1 we have
S5C,A
n
⊢α →[α]kCGα.
4
Relativized Common Knowledge
In this section, we will study operators for relativized common knowledge. We
will present a sound and complete axiomatization for the logic of relativized
common knowledge augmented by total public announcements.
The notion of relativized common knowledge is a generalized version of com-
mon knowledge. The language of LRC,A
n
formulas is the language LA
n extended
by the binary operator RCG for every non-empty group G ⊆A of agents. The
validity for relativized common knowledge is deﬁned by
K, s |= RCG(α, β)
iﬀ
for every t, there is a Gα-path from s to t ⇒K, t |= β.
It is obvious that common knowledge can be deﬁned by means of relativized
common knowledge via CGα := RCG(⊤, α). It can be shown that relativized

Total Public Announcements
509
common knowledge is strictly more expressive than common knowledge, see van
Benthem et al. [5,6] for a proof. For instance, the until operator of temporal
logic can be deﬁned using the relativized common knowledge operator.
Deﬁnition 10. The theory S5RC,A
n
is deﬁned to be S5A
n augmented by the fol-
lowing axioms and rules.
(A7)
α →([α]RCG(β, γ) ↔RCG(α ∧[α]β, [α]γ)),
(RC)
RCG(α, β) →EG(α →β ∧RCG(α, β)),
(IND.3)α →EG(β →α ∧γ)
α →RCG(β, γ)
.
Lemma 17. For all LRC,A
n
formulas α, β, and γ we have
S5RC,A
n
⊢RCG(α, β) →(α →β),
S5RC,A
n
⊢RCG(α, β →γ) →(RCG(α, β) →RCG(α, γ)),
S5RC,A
n
⊢EG(α →β ∧RCG(α, β)) →RCG(α, β),
S5RC,A
n
⊢α ⇒S5RC,A
n
⊢RCG(β, α).
Theorem 2. The system S5RC,A
n
is sound and complete with respect to Keq
n ,
i.e. for all LRC,A
n
formulas α we have
S5RC,A
n
⊢α
⇔
Keq
n |= α.
Proof. Soundness is proved as usual. The completeness proof for relativized com-
mon knowledge without announcement operators is similar to the proof of The-
orem 1. The full system S5RC,A
n
can now be treated by providing a translation
which eliminates the announcements. Such a translation can easily be deﬁned:
simply observe that the axioms (A5) and (A7) imply
S5RC,A
n
⊢[α]RCG(β, γ) ↔(¬α ∧RCG(β, γ)) ∨(α ∧RCG(α ∧[α]β, [α]γ))
(compare with the case for [α]Kiβ in Lemma 2). Making use of that translation
and of the completeness for the system without announcements, we can show
completeness of S5RC,A
n
as in Lemma 8.
2
5
Discussion
In the classical setting, public announcements are considered to be truthful.
Thus, a speciﬁc announcement cannot happen in all possible worlds. If an an-
nouncement α is false in a given world, then the corresponding update action
[α] cannot be performed, formally [α]⊥holds in that world.
We have presented a semantics, and corresponding formal systems, in which
an announcement can happen in every possible world. Thus, announcements are
total, that is the formula ¬[α]⊥is valid.

510
D. Steiner and T. Studer
If an announcement is true, then an agent’s knowledge gets updated; if it is
false, then the agent’s knowledge remains unchanged. In the classical setting, a
false announcement cannot happen. In our approach it can happen but does not
change an agent’s knowledge. Thus we have a semantics which internalizes the
idea of doing nothing when a false announcement is made.
This is a step towards a system in which an agent’s knowledge and beliefs are
considered. In such a setting, every announcement has to be performed since it
may change an agent’s beliefs even if its knowledge will not be aﬀected. Thus it
is necessary that announcements are total if we talk about both knowledge and
beliefs of an agent.
In the present approach we use an alethic criterion (namely wether an an-
nouncement is true or false) to decide wether an agent’s knowledge should be
updated or not. Of course, one may argue about such a criterion. However, since
an agent’s knowledge has to be true by the knowledge axiom (T), it should only
be updated by announcements that are indeed true. Therefore, unlike in the case
of belief updates, it is not possible to use an epistemic criterion. The approach
from [13], for instance, would lead to false knowledge by already accepting an
announcement if it is consistent with the previous knowledge.
There are already languages available in which our form of announcements
can be expressed. However, they are very expressive: non-deterministic choice,
truthful public announcements, and PDL-like test operators [2] are needed in
order to model our system. We have presented a lean and direct syntax and
semantics for total public announcements which leads to new concepts such
as announcement-resistant formulas. An interesting open question is to give a
syntactic characterization of this class of formulas. As already mentioned, further
work will also be done to investigate systems for updating knowledge and beliefs
of an agent.
Acknowledgement
We would like to thank the anonymous referees for the long list of comments
which helped to improve the paper.
References
1. Plaza, J.A.:
Logics of public communications.
In Emrich, M., Pfeifer, M.,
Hadzikadic, M., Ras, Z., eds.: Proceedings of the 4th International Symposium
on Methodologies for Intelligent Systems. (1989) 201–216
2. Baltag, A., Moss, L.S.: Logics for epistemic programs. Synthese 139(2) (2004)
165–224
3. Baltag, A., Moss, L.S., Solecki, S.: The logic of public announcements, common
knowledge, and private suspicions. In: TARK ’98: Proceedings of the 7th conference
on Theoretical aspects of rationality and knowledge, Morgan Kaufmann Publishers
(1998) 43–56
4. van Benthem, J.:
One is a lonely number: on the logic of communication.
In
Chatzidakis, Z., Koepke, P., Pohlers, W., eds.: Logic Colloquium ’02. Number 27
in Lecture Notes in Logic, ASL and A. K. Peters (2006) 96–129

Total Public Announcements
511
5. van Benthem, J., van Eijck, J., Kooi, B.: Common knowledge in update logics. In:
TARK ’05: Proceedings of the 10th conference on Theoretical aspects of rationality
and knowledge, National University of Singapore (2005) 253–261
6. van Benthem, J., van Eijck, J., Kooi, B.: Logics of communication and change.
Information and Computation 204(11) (2006) 1620–1662
7. van Benthem, J., Kooi, B.: Reduction axioms for epistemic actions. In Schmidt,
R., Pratt-Hartmann, I., Reynolds, M., Wansing, H., eds.: AiML ’04: Proceedings
of Advances in Modal Logic 5. Number UMCS-04-9-1 in Technical Report Series,
University of Manchester (2004) 197–211
8. van Ditmarsch, H.: Knowledge games. PhD thesis, University of Groningen (2000)
ILLC Dissertation Series 2000-06.
9. van Ditmarsch, H.: The russian cards problem. Studia Logica 75(4) (2003) 31–62
10. van Ditmarsch, H., van der Hoek, W., Kooi, B.: Dynamic epistemic logic. Volume
337 of Synthese Library. Springer (2007)
11. van Ditmarsch, H., Kooi, B.: The secret of my success. Synthese 151(2) (2005)
202–232
12. Renne, B.:
Bisimulation and public announcements in logics of evidence-based
knowledge. In Artemov, S., Parikh, R., eds.: ESSLLI ’06: Proceedings of the Eu-
ropean Summer School in Logic, Language and Information, Workshop on Ratio-
nality and Knowledge, Association for Logic, Language and Information (2006)
112–123
13. Steiner, D.: A system for consistency preserving belief change. In Artemov, S.,
Parikh, R., eds.: ESSLLI ’06: Proceedings of the European Summer School in Logic,
Language and Information, Workshop on Rationality and Knowledge, Association
for Logic, Language and Information (2006) 133–144
14. Gerbrandy, J., Groeneveld, W.: Reasoning about information change. Journal of
Logic, Language and Information 6(2) (1997) 147–169
15. Fagin, R., Halpern, J.Y., Moses, Y., Vardi, M.Y.: Reasoning about Knowledge.
MIT Press (1995)

Author Index
Antonakos, Evangelia
1
Artemov, Sergei
12
Avron, Arnon
26
Blair, Howard A.
41
Bollig, Benedikt
54
Bonelli, Eduardo
12
Bouyer, Patricia
69
Bresolin, Davide
84
Brihaye, Thomas
69
Brochenin, R´emi
100
Burel, Guillaume
115
Chevalier, Fabrice
69
Ciabattoni, Agata
132
Constable, Robert
147
D’Souza, Deepak
180
Davoren, J.M.
162
Demri, St´ephane
100, 180
Engelhardt, Kai
195
Fitting, Melvin
212
Gammie, Peter
195
Gascon, R´egis
180
Gentilini, R.
224
Goranko, Valentin
84
Goris, Evan
241
Gottipati, Srikanth
254
Heinemann, Bernhard
269
Irwin, Robert J.
41
Jakel, David W.
41
Kanovich, Max
284
Khoussainov, Bakhadyr
293
Kirchner, Claude
115
Kjos-Hanssen, Bjørn
310
Kurokawa, Hidenori
318
Kuznets, Roman
332
Liu, Jiamou
293
Lozes, Etienne
100
Lubarsky, Robert S.
349
Manna, Zohar
363
Marek, Victor W.
379
Meinecke, Ingmar
54
Metcalfe, George
132
Mishra, B.
224
Moczydlowski, Wojciech
147
Mogbil, Virgile
401
Montanari, Angelo
84
Nerode, Anil
254, 310
Nies, Andr´e
422
O’Connor, Michael
437
Parikh, Rohit
449
Platzer, Andr´e
457
van der Meyden, Ron
195
Rahli, Vincent
401
Rathjen, Michael
349
Redmond, Brian F.
472
Remmel, Jeﬀrey B.
379
Rivera, Angel
41
Rybakov, V.
486
Schneider, K.
224
Sciavicco, Guido
84
Semukhin, Pavel
422
Sipma, Henny B.
363
Steiner, David
498
Studer, Thomas
498
Zamansky, Anna
26
Zhang, Ting
363

